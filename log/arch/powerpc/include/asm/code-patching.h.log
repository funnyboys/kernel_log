commit 94afd069d937d84fb4f696eb9a78db4084e43d21
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:31 2020 +1000

    powerpc: Use a datatype for instructions
    
    Currently unsigned ints are used to represent instructions on powerpc.
    This has worked well as instructions have always been 4 byte words.
    
    However, ISA v3.1 introduces some changes to instructions that mean
    this scheme will no longer work as well. This change is Prefixed
    Instructions. A prefixed instruction is made up of a word prefix
    followed by a word suffix to make an 8 byte double word instruction.
    No matter the endianness of the system the prefix always comes first.
    Prefixed instructions are only planned for powerpc64.
    
    Introduce a ppc_inst type to represent both prefixed and word
    instructions on powerpc64 while keeping it possible to exclusively
    have word instructions on powerpc32.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Fix compile error in emulate_spe()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-12-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 48e021957ee5..eacc9102c251 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -23,33 +23,33 @@
 #define BRANCH_ABSOLUTE	0x2
 
 bool is_offset_in_branch_range(long offset);
-int create_branch(unsigned int *instr, const unsigned int *addr,
+int create_branch(struct ppc_inst *instr, const struct ppc_inst *addr,
 		  unsigned long target, int flags);
-int create_cond_branch(unsigned int *instr, const unsigned int *addr,
+int create_cond_branch(struct ppc_inst *instr, const struct ppc_inst *addr,
 		       unsigned long target, int flags);
-int patch_branch(unsigned int *addr, unsigned long target, int flags);
-int patch_instruction(unsigned int *addr, unsigned int instr);
-int raw_patch_instruction(unsigned int *addr, unsigned int instr);
+int patch_branch(struct ppc_inst *addr, unsigned long target, int flags);
+int patch_instruction(struct ppc_inst *addr, struct ppc_inst instr);
+int raw_patch_instruction(struct ppc_inst *addr, struct ppc_inst instr);
 
 static inline unsigned long patch_site_addr(s32 *site)
 {
 	return (unsigned long)site + *site;
 }
 
-static inline int patch_instruction_site(s32 *site, unsigned int instr)
+static inline int patch_instruction_site(s32 *site, struct ppc_inst instr)
 {
-	return patch_instruction((unsigned int *)patch_site_addr(site), instr);
+	return patch_instruction((struct ppc_inst *)patch_site_addr(site), instr);
 }
 
 static inline int patch_branch_site(s32 *site, unsigned long target, int flags)
 {
-	return patch_branch((unsigned int *)patch_site_addr(site), target, flags);
+	return patch_branch((struct ppc_inst *)patch_site_addr(site), target, flags);
 }
 
 static inline int modify_instruction(unsigned int *addr, unsigned int clr,
 				     unsigned int set)
 {
-	return patch_instruction(addr, ppc_inst((*addr & ~clr) | set));
+	return patch_instruction((struct ppc_inst *)addr, ppc_inst((*addr & ~clr) | set));
 }
 
 static inline int modify_instruction_site(s32 *site, unsigned int clr, unsigned int set)
@@ -57,13 +57,13 @@ static inline int modify_instruction_site(s32 *site, unsigned int clr, unsigned
 	return modify_instruction((unsigned int *)patch_site_addr(site), clr, set);
 }
 
-int instr_is_relative_branch(unsigned int instr);
-int instr_is_relative_link_branch(unsigned int instr);
-int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
-unsigned long branch_target(const unsigned int *instr);
-int translate_branch(unsigned int *instr, const unsigned int *dest,
-		     const unsigned int *src);
-extern bool is_conditional_branch(unsigned int instr);
+int instr_is_relative_branch(struct ppc_inst instr);
+int instr_is_relative_link_branch(struct ppc_inst instr);
+int instr_is_branch_to_addr(const struct ppc_inst *instr, unsigned long addr);
+unsigned long branch_target(const struct ppc_inst *instr);
+int translate_branch(struct ppc_inst *instr, const struct ppc_inst *dest,
+		     const struct ppc_inst *src);
+extern bool is_conditional_branch(struct ppc_inst instr);
 #ifdef CONFIG_PPC_BOOK3E_64
 void __patch_exception(int exc, unsigned long addr);
 #define patch_exception(exc, name) do { \

commit 753462512868674a788ecc77bb96752efb818785
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:26 2020 +1000

    powerpc: Use a macro for creating instructions from u32s
    
    In preparation for instructions having a more complex data type start
    using a macro, ppc_inst(), for making an instruction out of a u32.  A
    macro is used so that instructions can be used as initializer elements.
    Currently this does nothing, but it will allow for creating a data type
    that can represent prefixed instructions.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Change include guard to _ASM_POWERPC_INST_H]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-7-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 351dda7215b6..48e021957ee5 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -11,6 +11,7 @@
 #include <linux/string.h>
 #include <linux/kallsyms.h>
 #include <asm/asm-compat.h>
+#include <asm/inst.h>
 
 /* Flags for create_branch:
  * "b"   == create_branch(addr, target, 0);
@@ -48,7 +49,7 @@ static inline int patch_branch_site(s32 *site, unsigned long target, int flags)
 static inline int modify_instruction(unsigned int *addr, unsigned int clr,
 				     unsigned int set)
 {
-	return patch_instruction(addr, (*addr & ~clr) | set);
+	return patch_instruction(addr, ppc_inst((*addr & ~clr) | set));
 }
 
 static inline int modify_instruction_site(s32 *site, unsigned int clr, unsigned int set)

commit 7c95d8893fb55869882c9f68f4c94840dc43f18f
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:25 2020 +1000

    powerpc: Change calling convention for create_branch() et. al.
    
    create_branch(), create_cond_branch() and translate_branch() return the
    instruction that they create, or return 0 to signal an error. Separate
    these concerns in preparation for an instruction type that is not just
    an unsigned int.  Fill the created instruction to a pointer passed as
    the first parameter to the function and use a non-zero return value to
    signify an error.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-6-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 898b54262881..351dda7215b6 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -22,10 +22,10 @@
 #define BRANCH_ABSOLUTE	0x2
 
 bool is_offset_in_branch_range(long offset);
-unsigned int create_branch(const unsigned int *addr,
-			   unsigned long target, int flags);
-unsigned int create_cond_branch(const unsigned int *addr,
-				unsigned long target, int flags);
+int create_branch(unsigned int *instr, const unsigned int *addr,
+		  unsigned long target, int flags);
+int create_cond_branch(unsigned int *instr, const unsigned int *addr,
+		       unsigned long target, int flags);
 int patch_branch(unsigned int *addr, unsigned long target, int flags);
 int patch_instruction(unsigned int *addr, unsigned int instr);
 int raw_patch_instruction(unsigned int *addr, unsigned int instr);
@@ -60,8 +60,8 @@ int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
 unsigned long branch_target(const unsigned int *instr);
-unsigned int translate_branch(const unsigned int *dest,
-			      const unsigned int *src);
+int translate_branch(unsigned int *instr, const unsigned int *dest,
+		     const unsigned int *src);
 extern bool is_conditional_branch(unsigned int instr);
 #ifdef CONFIG_PPC_BOOK3E_64
 void __patch_exception(int exc, unsigned long addr);

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 2074b40f3fb5..898b54262881 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -1,13 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 #ifndef _ASM_POWERPC_CODE_PATCHING_H
 #define _ASM_POWERPC_CODE_PATCHING_H
 
 /*
  * Copyright 2008, Michael Ellerman, IBM Corporation.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #include <asm/types.h>

commit 36b08b431e2e282f78d09921ca55652d2c55eee5
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Nov 9 17:33:17 2018 +0000

    powerpc: add modify_instruction() and modify_instruction_site()
    
    Add two helpers to avoid hardcoding of instructions modifications.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 0eeed21e4898..2074b40f3fb5 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -49,6 +49,17 @@ static inline int patch_branch_site(s32 *site, unsigned long target, int flags)
 	return patch_branch((unsigned int *)patch_site_addr(site), target, flags);
 }
 
+static inline int modify_instruction(unsigned int *addr, unsigned int clr,
+				     unsigned int set)
+{
+	return patch_instruction(addr, (*addr & ~clr) | set);
+}
+
+static inline int modify_instruction_site(s32 *site, unsigned int clr, unsigned int set)
+{
+	return modify_instruction((unsigned int *)patch_site_addr(site), clr, set);
+}
+
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);

commit 45090c26614fe991d9d5a2cd08e65c4d6680549a
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Nov 9 17:33:15 2018 +0000

    powerpc: simplify patch_instruction_site() and patch_branch_site()
    
    Using patch_site_addr() helper, patch_instruction_site() and
    patch_branch_site() can be simplified and inlined.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 3d5acd2b113a..0eeed21e4898 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -33,14 +33,22 @@ unsigned int create_cond_branch(const unsigned int *addr,
 int patch_branch(unsigned int *addr, unsigned long target, int flags);
 int patch_instruction(unsigned int *addr, unsigned int instr);
 int raw_patch_instruction(unsigned int *addr, unsigned int instr);
-int patch_instruction_site(s32 *addr, unsigned int instr);
-int patch_branch_site(s32 *site, unsigned long target, int flags);
 
 static inline unsigned long patch_site_addr(s32 *site)
 {
 	return (unsigned long)site + *site;
 }
 
+static inline int patch_instruction_site(s32 *site, unsigned int instr)
+{
+	return patch_instruction((unsigned int *)patch_site_addr(site), instr);
+}
+
+static inline int patch_branch_site(s32 *site, unsigned long target, int flags)
+{
+	return patch_branch((unsigned int *)patch_site_addr(site), target, flags);
+}
+
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);

commit 082e2869fc022de4db9977e06558da78384ea98c
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Oct 19 06:55:04 2018 +0000

    powerpc/code-patching: Add a helper to get the address of a patch_site
    
    This patch adds a helper to get the address of a patch_site.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Call it "patch site" addr]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 31733a95bbd0..3d5acd2b113a 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -36,6 +36,11 @@ int raw_patch_instruction(unsigned int *addr, unsigned int instr);
 int patch_instruction_site(s32 *addr, unsigned int instr);
 int patch_branch_site(s32 *site, unsigned long target, int flags);
 
+static inline unsigned long patch_site_addr(s32 *site)
+{
+	return (unsigned long)site + *site;
+}
+
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);

commit 06d0bbc6d0f56dacac3a79900e9a9a0d5972d818
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Jul 24 01:07:52 2018 +1000

    powerpc/asm: Add a patch_site macro & helpers for patching instructions
    
    Add a macro and some helper C functions for patching single asm
    instructions.
    
    The gas macro means we can do something like:
    
      1:    nop
            patch_site 1b, patch__foo
    
    Which is less visually distracting than defining a GLOBAL symbol at 1,
    and also doesn't pollute the symbol table which can confuse eg. perf.
    
    These are obviously similar to our existing feature sections, but are
    not automatically patched based on CPU/MMU features, rather they are
    designed to be manually patched by C code at some arbitrary point.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 9ecc7bfc8ae7..31733a95bbd0 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -33,6 +33,8 @@ unsigned int create_cond_branch(const unsigned int *addr,
 int patch_branch(unsigned int *addr, unsigned long target, int flags);
 int patch_instruction(unsigned int *addr, unsigned int instr);
 int raw_patch_instruction(unsigned int *addr, unsigned int instr);
+int patch_instruction_site(s32 *addr, unsigned int instr);
+int patch_branch_site(s32 *site, unsigned long target, int flags);
 
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);

commit ec0c464cdbf38bf6ddabec8bfa595bd421cab203
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:57 2018 +0000

    powerpc: move ASM_CONST and stringify_in_c() into asm-const.h
    
    This patch moves ASM_CONST() and stringify_in_c() into
    dedicated asm-const.h, then cleans all related inclusions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: asm-compat.h should include asm-const.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 812535f40124..9ecc7bfc8ae7 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -14,6 +14,7 @@
 #include <asm/ppc-opcode.h>
 #include <linux/string.h>
 #include <linux/kallsyms.h>
+#include <asm/asm-compat.h>
 
 /* Flags for create_branch:
  * "b"   == create_branch(addr, target, 0);

commit 8183d99f4a22c2abbc543847a588df3666ef0c0c
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Nov 24 08:31:09 2017 +0100

    powerpc/lib/feature-fixups: use raw_patch_instruction()
    
    feature fixups need to use patch_instruction() early in the boot,
    even before the code is relocated to its final address, requiring
    patch_instruction() to use PTRRELOC() in order to address data.
    
    But feature fixups applies on code before it is set to read only,
    even for modules. Therefore, feature fixups can use
    raw_patch_instruction() instead.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 2c895e8d07f7..812535f40124 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -31,6 +31,7 @@ unsigned int create_cond_branch(const unsigned int *addr,
 				unsigned long target, int flags);
 int patch_branch(unsigned int *addr, unsigned long target, int flags);
 int patch_instruction(unsigned int *addr, unsigned int instr);
+int raw_patch_instruction(unsigned int *addr, unsigned int instr);
 
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_relative_link_branch(unsigned int instr);

commit b9eab08d012fa093947b230f9a87257c27fb829b
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Thu Nov 16 11:45:37 2017 -0600

    powerpc/modules: Don't try to restore r2 after a sibling call
    
    When attempting to load a livepatch module, I got the following error:
    
      module_64: patch_module: Expect noop after relocate, got 3c820000
    
    The error was triggered by the following code in
    unregister_netdevice_queue():
    
      14c:   00 00 00 48     b       14c <unregister_netdevice_queue+0x14c>
                             14c: R_PPC64_REL24      net_set_todo
      150:   00 00 82 3c     addis   r4,r2,0
    
    GCC didn't insert a nop after the branch to net_set_todo() because it's
    a sibling call, so it never returns.  The nop isn't needed after the
    branch in that case.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Reviewed-and-tested-by: Kamalesh Babulal <kamalesh@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index abef812de7f8..2c895e8d07f7 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -33,6 +33,7 @@ int patch_branch(unsigned int *addr, unsigned long target, int flags);
 int patch_instruction(unsigned int *addr, unsigned int instr);
 
 int instr_is_relative_branch(unsigned int instr);
+int instr_is_relative_link_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
 unsigned long branch_target(const unsigned int *instr);
 unsigned int translate_branch(const unsigned int *dest,

commit 63be1a81e40733ecd175713b6a7558dc43f00851
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Mon Oct 30 20:42:08 2017 +0530

    Revert "powerpc64/elfv1: Only dereference function descriptor for non-text symbols"
    
    This reverts commit 83e840c770f2c5 ("powerpc64/elfv1: Only dereference
    function descriptor for non-text symbols").
    
    Chandan reported that on newer kernels, trying to enable function_graph
    tracer on ppc64 (BE) locks up the system with the following trace:
    
      Unable to handle kernel paging request for data at address 0x600000002fa30010
      Faulting instruction address: 0xc0000000001f1300
      Thread overran stack, or stack corrupted
      Oops: Kernel access of bad area, sig: 11 [#1]
      BE SMP NR_CPUS=2048 DEBUG_PAGEALLOC NUMA pSeries
      Modules linked in:
      CPU: 1 PID: 6586 Comm: bash Not tainted 4.14.0-rc3-00162-g6e51f1f-dirty #20
      task: c000000625c07200 task.stack: c000000625c07310
      NIP:  c0000000001f1300 LR: c000000000121cac CTR: c000000000061af8
      REGS: c000000625c088c0 TRAP: 0380   Not tainted  (4.14.0-rc3-00162-g6e51f1f-dirty)
      MSR:  8000000000001032 <SF,ME,IR,DR,RI>  CR: 28002848  XER: 00000000
      CFAR: c0000000001f1320 SOFTE: 0
      ...
      NIP [c0000000001f1300] .__is_insn_slot_addr+0x30/0x90
      LR [c000000000121cac] .kernel_text_address+0x18c/0x1c0
      Call Trace:
      [c000000625c08b40] [c0000000001bd040] .is_module_text_address+0x20/0x40 (unreliable)
      [c000000625c08bc0] [c000000000121cac] .kernel_text_address+0x18c/0x1c0
      [c000000625c08c50] [c000000000061960] .prepare_ftrace_return+0x50/0x130
      [c000000625c08cf0] [c000000000061b10] .ftrace_graph_caller+0x14/0x34
      [c000000625c08d60] [c000000000121b40] .kernel_text_address+0x20/0x1c0
      [c000000625c08df0] [c000000000061960] .prepare_ftrace_return+0x50/0x130
      ...
      [c000000625c0ab30] [c000000000061960] .prepare_ftrace_return+0x50/0x130
      [c000000625c0abd0] [c000000000061b10] .ftrace_graph_caller+0x14/0x34
      [c000000625c0ac40] [c000000000121b40] .kernel_text_address+0x20/0x1c0
      [c000000625c0acd0] [c000000000061960] .prepare_ftrace_return+0x50/0x130
      [c000000625c0ad70] [c000000000061b10] .ftrace_graph_caller+0x14/0x34
      [c000000625c0ade0] [c000000000121b40] .kernel_text_address+0x20/0x1c0
    
    This is because ftrace is using ppc_function_entry() for obtaining the
    address of return_to_handler() in prepare_ftrace_return(). The call to
    kernel_text_address() itself gets traced and we end up in a recursive
    loop.
    
    Fixes: 83e840c770f2 ("powerpc64/elfv1: Only dereference function descriptor for non-text symbols")
    Cc: stable@vger.kernel.org # v4.13+
    Reported-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 5482928eea1b..abef812de7f8 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -83,16 +83,8 @@ static inline unsigned long ppc_function_entry(void *func)
 	 * On PPC64 ABIv1 the function pointer actually points to the
 	 * function's descriptor. The first entry in the descriptor is the
 	 * address of the function text.
-	 *
-	 * However, we may also receive pointer to an assembly symbol. To
-	 * detect that, we first check if the function pointer we receive
-	 * already points to kernel/module text and we only dereference it
-	 * if it doesn't.
 	 */
-	if (kernel_text_address((unsigned long)func))
-		return (unsigned long)func;
-	else
-		return ((func_descr_t *)func)->entry;
+	return ((func_descr_t *)func)->entry;
 #else
 	return (unsigned long)func;
 #endif

commit 83e840c770f2c578bbbff478d62a4403c073b438
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Thu Jun 29 23:19:14 2017 +0530

    powerpc64/elfv1: Only dereference function descriptor for non-text symbols
    
    Currently, we assume that the function pointer we receive in
    ppc_function_entry() points to a function descriptor. However, this is
    not always the case. In particular, assembly symbols without the right
    annotation do not have an associated function descriptor. Some of these
    symbols are added to the kprobe blacklist using _ASM_NOKPROBE_SYMBOL().
    
    When such addresses are subsequently processed through
    arch_deref_entry_point() in populate_kprobe_blacklist(), we see the
    below errors during bootup:
        [    0.663963] Failed to find blacklist at 7d9b02a648029b6c
        [    0.663970] Failed to find blacklist at a14d03d0394a0001
        [    0.663972] Failed to find blacklist at 7d5302a6f94d0388
        [    0.663973] Failed to find blacklist at 48027d11e8610178
        [    0.663974] Failed to find blacklist at f8010070f8410080
        [    0.663976] Failed to find blacklist at 386100704801f89d
        [    0.663977] Failed to find blacklist at 7d5302a6f94d00b0
    
    Fix this by checking if the function pointer we receive in
    ppc_function_entry() already points to kernel text. If so, we just
    return it as is. If not, we assume that this is a function descriptor
    and proceed to dereference it.
    
    Suggested-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index abef812de7f8..5482928eea1b 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -83,8 +83,16 @@ static inline unsigned long ppc_function_entry(void *func)
 	 * On PPC64 ABIv1 the function pointer actually points to the
 	 * function's descriptor. The first entry in the descriptor is the
 	 * address of the function text.
+	 *
+	 * However, we may also receive pointer to an assembly symbol. To
+	 * detect that, we first check if the function pointer we receive
+	 * already points to kernel/module text and we only dereference it
+	 * if it doesn't.
 	 */
-	return ((func_descr_t *)func)->entry;
+	if (kernel_text_address((unsigned long)func))
+		return (unsigned long)func;
+	else
+		return ((func_descr_t *)func)->entry;
 #else
 	return (unsigned long)func;
 #endif

commit 1b32cd1715378c9a3856df4a80920f8e241f914c
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Apr 19 18:22:27 2017 +0530

    powerpc: Introduce a new helper to obtain function entry points
    
    kprobe_lookup_name() is specific to the kprobe subsystem and may not always
    return the function entry point (in a subsequent patch for KPROBES_ON_FTRACE).
    For looking up function entry points, introduce a separate helper and use it
    in optprobes.c
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 8ab937771068..abef812de7f8 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -12,6 +12,8 @@
 
 #include <asm/types.h>
 #include <asm/ppc-opcode.h>
+#include <linux/string.h>
+#include <linux/kallsyms.h>
 
 /* Flags for create_branch:
  * "b"   == create_branch(addr, target, 0);
@@ -99,6 +101,45 @@ static inline unsigned long ppc_global_function_entry(void *func)
 #endif
 }
 
+/*
+ * Wrapper around kallsyms_lookup() to return function entry address:
+ * - For ABIv1, we lookup the dot variant.
+ * - For ABIv2, we return the local entry point.
+ */
+static inline unsigned long ppc_kallsyms_lookup_name(const char *name)
+{
+	unsigned long addr;
+#ifdef PPC64_ELF_ABI_v1
+	/* check for dot variant */
+	char dot_name[1 + KSYM_NAME_LEN];
+	bool dot_appended = false;
+
+	if (strnlen(name, KSYM_NAME_LEN) >= KSYM_NAME_LEN)
+		return 0;
+
+	if (name[0] != '.') {
+		dot_name[0] = '.';
+		dot_name[1] = '\0';
+		strlcat(dot_name, name, sizeof(dot_name));
+		dot_appended = true;
+	} else {
+		dot_name[0] = '\0';
+		strlcat(dot_name, name, sizeof(dot_name));
+	}
+	addr = kallsyms_lookup_name(dot_name);
+	if (!addr && dot_appended)
+		/* Let's try the original non-dot symbol lookup	*/
+		addr = kallsyms_lookup_name(name);
+#elif defined(PPC64_ELF_ABI_v2)
+	addr = kallsyms_lookup_name(name);
+	if (addr)
+		addr = ppc_function_entry((void *)addr);
+#else
+	addr = kallsyms_lookup_name(name);
+#endif
+	return addr;
+}
+
 #ifdef CONFIG_PPC64
 /*
  * Some instruction encodings commonly used in dynamic ftracing

commit 51c9c0843993528bffc920c54c2121d9e6f8b090
Author: Anju T <anju@linux.vnet.ibm.com>
Date:   Wed Feb 8 15:20:51 2017 +0530

    powerpc/kprobes: Implement Optprobes
    
    Current infrastructure of kprobe uses the unconditional trap instruction
    to probe a running kernel. Optprobe allows kprobe to replace the trap
    with a branch instruction to a detour buffer. Detour buffer contains
    instructions to create an in memory pt_regs. Detour buffer also has a
    call to optimized_callback() which in turn call the pre_handler(). After
    the execution of the pre-handler, a call is made for instruction
    emulation. The NIP is determined in advanced through dummy instruction
    emulation and a branch instruction is created to the NIP at the end of
    the trampoline.
    
    To address the limitation of branch instruction in POWER architecture,
    detour buffer slot is allocated from a reserved area. For the time
    being, 64KB is reserved in memory for this purpose.
    
    Instructions which can be emulated using analyse_instr() are the
    candidates for optimization. Before optimization ensure that the address
    range between the detour buffer allocated and the instruction being
    probed is within +/- 32MB.
    
    Signed-off-by: Anju T Sudhakar <anju@linux.vnet.ibm.com>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 75ee4f4ac840..8ab937771068 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -35,6 +35,7 @@ int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
 unsigned long branch_target(const unsigned int *instr);
 unsigned int translate_branch(const unsigned int *dest,
 			      const unsigned int *src);
+extern bool is_conditional_branch(unsigned int instr);
 #ifdef CONFIG_PPC_BOOK3E_64
 void __patch_exception(int exc, unsigned long addr);
 #define patch_exception(exc, name) do { \

commit ebfa50df435eed18e1389a43e0596246228e7298
Author: Anju T <anju@linux.vnet.ibm.com>
Date:   Wed Feb 8 14:27:30 2017 +0530

    powerpc: Add helper to check if offset is within relative branch range
    
    To permit the use of relative branch instruction in powerpc, the target
    address has to be relatively nearby, since the address is specified in an
    immediate field (24 bit filed) in the instruction opcode itself. Here
    nearby refers to 32MB on either side of the current instruction.
    
    This patch verifies whether the target address is within +/- 32MB
    range or not.
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Anju T Sudhakar <anju@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 2015b072422c..75ee4f4ac840 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -22,6 +22,7 @@
 #define BRANCH_SET_LINK	0x1
 #define BRANCH_ABSOLUTE	0x2
 
+bool is_offset_in_branch_range(long offset);
 unsigned int create_branch(const unsigned int *addr,
 			   unsigned long target, int flags);
 unsigned int create_cond_branch(const unsigned int *addr,

commit f55d966536034d33476fdd43c45d47225344469f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Jun 6 22:26:10 2016 +0530

    powerpc: Define and use PPC64_ELF_ABI_v2/v1
    
    We're approaching 20 locations where we need to check for ELF ABI v2.
    That's fine, except the logic is a bit awkward, because we have to check
    that _CALL_ELF is defined and then what its value is.
    
    So check it once in asm/types.h and define PPC64_ELF_ABI_v2 when ELF ABI
    v2 is detected.
    
    We also have a few places where what we're really trying to check is
    that we are using the 64-bit v1 ABI, ie. function descriptors. So also
    add a #define for that, which simplifies several checks.
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 994c60a857ce..2015b072422c 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -49,8 +49,7 @@ void __patch_exception(int exc, unsigned long addr);
 
 static inline unsigned long ppc_function_entry(void *func)
 {
-#if defined(CONFIG_PPC64)
-#if defined(_CALL_ELF) && _CALL_ELF == 2
+#ifdef PPC64_ELF_ABI_v2
 	u32 *insn = func;
 
 	/*
@@ -75,14 +74,13 @@ static inline unsigned long ppc_function_entry(void *func)
 		return (unsigned long)(insn + 2);
 	else
 		return (unsigned long)func;
-#else
+#elif defined(PPC64_ELF_ABI_v1)
 	/*
 	 * On PPC64 ABIv1 the function pointer actually points to the
 	 * function's descriptor. The first entry in the descriptor is the
 	 * address of the function text.
 	 */
 	return ((func_descr_t *)func)->entry;
-#endif
 #else
 	return (unsigned long)func;
 #endif
@@ -90,7 +88,7 @@ static inline unsigned long ppc_function_entry(void *func)
 
 static inline unsigned long ppc_global_function_entry(void *func)
 {
-#if defined(CONFIG_PPC64) && defined(_CALL_ELF) && _CALL_ELF == 2
+#ifdef PPC64_ELF_ABI_v2
 	/* PPC64 ABIv2 the global entry point is at the address */
 	return (unsigned long)func;
 #else
@@ -106,7 +104,7 @@ static inline unsigned long ppc_global_function_entry(void *func)
  */
 
 /* This must match the definition of STK_GOT in <asm/ppc_asm.h> */
-#if defined(_CALL_ELF) && _CALL_ELF == 2
+#ifdef PPC64_ELF_ABI_v2
 #define R2_STACK_OFFSET         24
 #else
 #define R2_STACK_OFFSET         40

commit 153086644fd1fb07fb3af84d9f11542a19b1e8b6
Author: Torsten Duwe <duwe@suse.de>
Date:   Thu Mar 3 15:26:59 2016 +1100

    powerpc/ftrace: Add support for -mprofile-kernel ftrace ABI
    
    The gcc switch -mprofile-kernel defines a new ABI for calling _mcount()
    very early in the function with minimal overhead.
    
    Although mprofile-kernel has been available since GCC 3.4, there were
    bugs which were only fixed recently. Currently it is known to work in
    GCC 4.9, 5 and 6.
    
    Additionally there are two possible code sequences generated by the
    flag, the first uses mflr/std/bl and the second is optimised to omit the
    std. Currently only gcc 6 has the optimised sequence. This patch
    supports both sequences.
    
    Initial work started by Vojtech Pavlik, used with permission.
    
    Key changes:
     - rework _mcount() to work for both the old and new ABIs.
     - implement new versions of ftrace_caller() and ftrace_graph_caller()
       which deal with the new ABI.
     - updates to __ftrace_make_nop() to recognise the new mcount calling
       sequence.
     - updates to __ftrace_make_call() to recognise the nop'ed sequence.
     - implement ftrace_modify_call().
     - updates to the module loader to surpress the toc save in the module
       stub when calling mcount with the new ABI.
    
    Reviewed-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Torsten Duwe <duwe@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 840a5509b3f1..994c60a857ce 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -99,4 +99,25 @@ static inline unsigned long ppc_global_function_entry(void *func)
 #endif
 }
 
+#ifdef CONFIG_PPC64
+/*
+ * Some instruction encodings commonly used in dynamic ftracing
+ * and function live patching.
+ */
+
+/* This must match the definition of STK_GOT in <asm/ppc_asm.h> */
+#if defined(_CALL_ELF) && _CALL_ELF == 2
+#define R2_STACK_OFFSET         24
+#else
+#define R2_STACK_OFFSET         40
+#endif
+
+#define PPC_INST_LD_TOC		(PPC_INST_LD  | ___PPC_RT(__REG_R2) | \
+				 ___PPC_RA(__REG_R1) | R2_STACK_OFFSET)
+
+/* usually preceded by a mflr r0 */
+#define PPC_INST_STD_LR		(PPC_INST_STD | ___PPC_RS(__REG_R0) | \
+				 ___PPC_RA(__REG_R1) | PPC_LR_STKOFF)
+#endif /* CONFIG_PPC64 */
+
 #endif /* _ASM_POWERPC_CODE_PATCHING_H */

commit d997c00c5a9b61474f7ff5f27ed64173bb007987
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Jun 17 16:15:32 2014 +1000

    powerpc: Add ppc_global_function_entry()
    
    ABIv2 has the concept of a global and local entry point to a function.
    In most cases we are interested in the local entry point, and so that is
    what ppc_function_entry() returns.
    
    However we have a case in the ftrace code where we want the global entry
    point, and there may be other places we need it too. Rather than special
    casing each, add an accessor.
    
    For ABIv1 and 32-bit there is only a single entry point, so we return
    that. That means it's safe for the caller to use this without also
    checking the ABI version.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 37991e154ef8..840a5509b3f1 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -88,4 +88,15 @@ static inline unsigned long ppc_function_entry(void *func)
 #endif
 }
 
+static inline unsigned long ppc_global_function_entry(void *func)
+{
+#if defined(CONFIG_PPC64) && defined(_CALL_ELF) && _CALL_ELF == 2
+	/* PPC64 ABIv2 the global entry point is at the address */
+	return (unsigned long)func;
+#else
+	/* All other cases there is no change vs ppc_function_entry() */
+	return ppc_function_entry(func);
+#endif
+}
+
 #endif /* _ASM_POWERPC_CODE_PATCHING_H */

commit c71b7eff426fa7d8fd33e0964a7f79a3b41faff9
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Feb 4 16:09:15 2014 +1100

    powerpc: Add ABIv2 support to ppc_function_entry
    
    Skip over the well known global entry point code for ABIv2.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 97e02f985df8..37991e154ef8 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -42,15 +42,47 @@ void __patch_exception(int exc, unsigned long addr);
 } while (0)
 #endif
 
+#define OP_RT_RA_MASK	0xffff0000UL
+#define LIS_R2		0x3c020000UL
+#define ADDIS_R2_R12	0x3c4c0000UL
+#define ADDI_R2_R2	0x38420000UL
+
 static inline unsigned long ppc_function_entry(void *func)
 {
-#ifdef CONFIG_PPC64
+#if defined(CONFIG_PPC64)
+#if defined(_CALL_ELF) && _CALL_ELF == 2
+	u32 *insn = func;
+
+	/*
+	 * A PPC64 ABIv2 function may have a local and a global entry
+	 * point. We need to use the local entry point when patching
+	 * functions, so identify and step over the global entry point
+	 * sequence.
+	 *
+	 * The global entry point sequence is always of the form:
+	 *
+	 * addis r2,r12,XXXX
+	 * addi  r2,r2,XXXX
+	 *
+	 * A linker optimisation may convert the addis to lis:
+	 *
+	 * lis   r2,XXXX
+	 * addi  r2,r2,XXXX
+	 */
+	if ((((*insn & OP_RT_RA_MASK) == ADDIS_R2_R12) ||
+	     ((*insn & OP_RT_RA_MASK) == LIS_R2)) &&
+	    ((*(insn+1) & OP_RT_RA_MASK) == ADDI_R2_R2))
+		return (unsigned long)(insn + 2);
+	else
+		return (unsigned long)func;
+#else
 	/*
-	 * On PPC64 the function pointer actually points to the function's
-	 * descriptor. The first entry in the descriptor is the address
-	 * of the function text.
+	 * On PPC64 ABIv1 the function pointer actually points to the
+	 * function's descriptor. The first entry in the descriptor is the
+	 * address of the function text.
 	 */
 	return ((func_descr_t *)func)->entry;
+#endif
 #else
 	return (unsigned long)func;
 #endif

commit 1e8341ae0c0e117f0626cd6cf6732a0a9c8723f2
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sun May 12 07:26:22 2013 +0800

    powerpc: Move the patch_exception to a common place
    
    So that it can be used by other codes. No function change.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index a6f8c7a5cbb7..97e02f985df8 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -34,6 +34,13 @@ int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
 unsigned long branch_target(const unsigned int *instr);
 unsigned int translate_branch(const unsigned int *dest,
 			      const unsigned int *src);
+#ifdef CONFIG_PPC_BOOK3E_64
+void __patch_exception(int exc, unsigned long addr);
+#define patch_exception(exc, name) do { \
+	extern unsigned int name; \
+	__patch_exception((exc), (unsigned long)&name); \
+} while (0)
+#endif
 
 static inline unsigned long ppc_function_entry(void *func)
 {

commit b6e3796834faefe4b6e9a2aedfe12665cd51fbc5
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Apr 26 08:31:18 2012 +0000

    powerpc: Have patch_instruction detect faults
    
    For ftrace to use the patch_instruction code, it needs to check for
    faults on write. Ftrace updates code all over the kernel, and we need to
    know if code is updated or not due to protections that are placed on
    some portions of the kernel. If ftrace does not detect a fault, it will
    error later on, and it will be much more difficult to find the problem.
    
    By changing patch_instruction() to detect faults, then ftrace will be
    able to make use of it too.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 37c32aba79b7..a6f8c7a5cbb7 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -26,8 +26,8 @@ unsigned int create_branch(const unsigned int *addr,
 			   unsigned long target, int flags);
 unsigned int create_cond_branch(const unsigned int *addr,
 				unsigned long target, int flags);
-void patch_branch(unsigned int *addr, unsigned long target, int flags);
-void patch_instruction(unsigned int *addr, unsigned int instr);
+int patch_branch(unsigned int *addr, unsigned long target, int flags);
+int patch_instruction(unsigned int *addr, unsigned int instr);
 
 int instr_is_relative_branch(unsigned int instr);
 int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);

commit 16c57b3620d77e0bc981da5ef32beae730512684
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Tue Feb 10 20:10:44 2009 +0000

    powerpc: Unify opcode definitions and support
    
    Create a new header that becomes a single location for defining PowerPC
    opcodes used by code that is either generationg instructions
    at runtime (fixups, debug, etc.), emulating instructions, or just
    compiling instructions old assemblers don't know about.
    
    We currently don't handle the floating point emulation or alignment decode
    as both are better handled by the specific decode support they already
    have.
    
    Added support for the new dcbzl, dcbal, msgsnd, tlbilx, & wait instructions
    since older assemblers don't know about them.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
index 107d9b915e33..37c32aba79b7 100644
--- a/arch/powerpc/include/asm/code-patching.h
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -11,9 +11,7 @@
  */
 
 #include <asm/types.h>
-
-#define PPC_NOP_INSTR		0x60000000
-#define PPC_LWSYNC_INSTR	0x7c2004ac
+#include <asm/ppc-opcode.h>
 
 /* Flags for create_branch:
  * "b"   == create_branch(addr, target, 0);

commit b8b572e1015f81b4e748417be2629dfe51ab99f9
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Aug 1 15:20:30 2008 +1000

    powerpc: Move include files to arch/powerpc/include/asm
    
    from include/asm-powerpc.  This is the result of a
    
    mkdir arch/powerpc/include/asm
    git mv include/asm-powerpc/* arch/powerpc/include/asm
    
    Followed by a few documentation/comment fixups and a couple of places
    where <asm-powepc/...> was being used explicitly.  Of the latter only
    one was outside the arch code and it is a driver only built for powerpc.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h
new file mode 100644
index 000000000000..107d9b915e33
--- /dev/null
+++ b/arch/powerpc/include/asm/code-patching.h
@@ -0,0 +1,54 @@
+#ifndef _ASM_POWERPC_CODE_PATCHING_H
+#define _ASM_POWERPC_CODE_PATCHING_H
+
+/*
+ * Copyright 2008, Michael Ellerman, IBM Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <asm/types.h>
+
+#define PPC_NOP_INSTR		0x60000000
+#define PPC_LWSYNC_INSTR	0x7c2004ac
+
+/* Flags for create_branch:
+ * "b"   == create_branch(addr, target, 0);
+ * "ba"  == create_branch(addr, target, BRANCH_ABSOLUTE);
+ * "bl"  == create_branch(addr, target, BRANCH_SET_LINK);
+ * "bla" == create_branch(addr, target, BRANCH_ABSOLUTE | BRANCH_SET_LINK);
+ */
+#define BRANCH_SET_LINK	0x1
+#define BRANCH_ABSOLUTE	0x2
+
+unsigned int create_branch(const unsigned int *addr,
+			   unsigned long target, int flags);
+unsigned int create_cond_branch(const unsigned int *addr,
+				unsigned long target, int flags);
+void patch_branch(unsigned int *addr, unsigned long target, int flags);
+void patch_instruction(unsigned int *addr, unsigned int instr);
+
+int instr_is_relative_branch(unsigned int instr);
+int instr_is_branch_to_addr(const unsigned int *instr, unsigned long addr);
+unsigned long branch_target(const unsigned int *instr);
+unsigned int translate_branch(const unsigned int *dest,
+			      const unsigned int *src);
+
+static inline unsigned long ppc_function_entry(void *func)
+{
+#ifdef CONFIG_PPC64
+	/*
+	 * On PPC64 the function pointer actually points to the function's
+	 * descriptor. The first entry in the descriptor is the address
+	 * of the function text.
+	 */
+	return ((func_descr_t *)func)->entry;
+#else
+	return (unsigned long)func;
+#endif
+}
+
+#endif /* _ASM_POWERPC_CODE_PATCHING_H */
