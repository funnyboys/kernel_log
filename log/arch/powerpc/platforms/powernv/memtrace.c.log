commit ed7f9fec8c8f8227ebd1fb69feda60ce4a7df61f
Author: David Hildenbrand <david@redhat.com>
Date:   Mon Apr 6 20:07:28 2020 -0700

    powernv/memtrace: always online added memory blocks
    
    Let's always try to online the re-added memory blocks.  In case
    add_memory() already onlined the added memory blocks, the first
    device_online() call will fail and stop processing the remaining memory
    blocks.
    
    This avoids manually having to check memhp_auto_online.
    
    Note: PPC always onlines all hotplugged memory directly from the kernel as
    well - something that is handled by user space on other architectures.
    
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Wei Yang <richard.weiyang@gmail.com>
    Reviewed-by: Baoquan He <bhe@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: "Rafael J. Wysocki" <rafael@kernel.org>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: Igor Mammedov <imammedo@redhat.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: Wei Liu <wei.liu@kernel.org>
    Cc: Yumei Huang <yuhuang@redhat.com>
    Link: http://lkml.kernel.org/r/20200317104942.11178-5-david@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index d6d64f8718e6..13b369d2cc45 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -231,16 +231,10 @@ static int memtrace_online(void)
 			continue;
 		}
 
-		/*
-		 * If kernel isn't compiled with the auto online option
-		 * we need to online the memory ourselves.
-		 */
-		if (!memhp_auto_online) {
-			lock_device_hotplug();
-			walk_memory_blocks(ent->start, ent->size, NULL,
-					   online_mem_block);
-			unlock_device_hotplug();
-		}
+		lock_device_hotplug();
+		walk_memory_blocks(ent->start, ent->size, NULL,
+				   online_mem_block);
+		unlock_device_hotplug();
 
 		/*
 		 * Memory was added successfully so clean up references to it

commit f344f0ab993987ae29cb39cc52054d7346db082f
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Sun Feb 9 11:59:01 2020 +0100

    powerpc/powernv: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200209105901.1620958-6-gregkh@linuxfoundation.org

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index eb2e75dac369..d6d64f8718e6 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -187,11 +187,6 @@ static int memtrace_init_debugfs(void)
 
 		snprintf(ent->name, 16, "%08x", ent->nid);
 		dir = debugfs_create_dir(ent->name, memtrace_debugfs_dir);
-		if (!dir) {
-			pr_err("Failed to create debugfs directory for node %d\n",
-				ent->nid);
-			return -1;
-		}
 
 		ent->dir = dir;
 		debugfs_create_file("trace", 0400, dir, ent, &memtrace_fops);
@@ -314,8 +309,6 @@ static int memtrace_init(void)
 {
 	memtrace_debugfs_dir = debugfs_create_dir("memtrace",
 						  powerpc_debugfs_root);
-	if (!memtrace_debugfs_dir)
-		return -1;
 
 	debugfs_create_file("enable", 0600, memtrace_debugfs_dir,
 			    NULL, &memtrace_init_fops);

commit fbcf73ce65827c3d8935f38b832a43153a0c78d1
Author: David Hildenbrand <david@redhat.com>
Date:   Thu Jul 18 15:57:46 2019 -0700

    mm/memory_hotplug: rename walk_memory_range() and pass start+size instead of pfns
    
    walk_memory_range() was once used to iterate over sections.  Now, it
    iterates over memory blocks.  Rename the function, fixup the
    documentation.
    
    Also, pass start+size instead of PFNs, which is what most callers
    already have at hand.  (we'll rework link_mem_sections() most probably
    soon)
    
    Follow-up patches will rework, simplify, and move walk_memory_blocks()
    to drivers/base/memory.c.
    
    Note: walk_memory_blocks() only works correctly right now if the
    start_pfn is aligned to a section start.  This is the case right now,
    but we'll generalize the function in a follow up patch so the semantics
    match the documentation.
    
    [akpm@linux-foundation.org: remove unused variable]
    Link: http://lkml.kernel.org/r/20190614100114.311-5-david@redhat.com
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Rashmica Gupta <rashmica.g@gmail.com>
    Cc: Pavel Tatashin <pasha.tatashin@soleen.com>
    Cc: Anshuman Khandual <anshuman.khandual@arm.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Qian Cai <cai@lca.pw>
    Cc: Arun KS <arunks@codeaurora.org>
    Cc: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index 5e53c1392d3b..eb2e75dac369 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -70,23 +70,23 @@ static int change_memblock_state(struct memory_block *mem, void *arg)
 /* called with device_hotplug_lock held */
 static bool memtrace_offline_pages(u32 nid, u64 start_pfn, u64 nr_pages)
 {
-	u64 end_pfn = start_pfn + nr_pages - 1;
+	const unsigned long start = PFN_PHYS(start_pfn);
+	const unsigned long size = PFN_PHYS(nr_pages);
 
-	if (walk_memory_range(start_pfn, end_pfn, NULL,
-	    check_memblock_online))
+	if (walk_memory_blocks(start, size, NULL, check_memblock_online))
 		return false;
 
-	walk_memory_range(start_pfn, end_pfn, (void *)MEM_GOING_OFFLINE,
-			  change_memblock_state);
+	walk_memory_blocks(start, size, (void *)MEM_GOING_OFFLINE,
+			   change_memblock_state);
 
 	if (offline_pages(start_pfn, nr_pages)) {
-		walk_memory_range(start_pfn, end_pfn, (void *)MEM_ONLINE,
-				  change_memblock_state);
+		walk_memory_blocks(start, size, (void *)MEM_ONLINE,
+				   change_memblock_state);
 		return false;
 	}
 
-	walk_memory_range(start_pfn, end_pfn, (void *)MEM_OFFLINE,
-			  change_memblock_state);
+	walk_memory_blocks(start, size, (void *)MEM_OFFLINE,
+			   change_memblock_state);
 
 
 	return true;
@@ -242,9 +242,8 @@ static int memtrace_online(void)
 		 */
 		if (!memhp_auto_online) {
 			lock_device_hotplug();
-			walk_memory_range(PFN_DOWN(ent->start),
-					  PFN_UP(ent->start + ent->size - 1),
-					  NULL, online_mem_block);
+			walk_memory_blocks(ent->start, ent->size, NULL,
+					   online_mem_block);
 			unlock_device_hotplug();
 		}
 

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index 248a38ad25c7..5e53c1392d3b 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -1,11 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Copyright (C) IBM Corporation, 2014, 2017
  * Anton Blanchard, Rashmica Gupta.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
  */
 
 #define pr_fmt(fmt) "memtrace: " fmt

commit 98fa15f34cb379864757670b8e8743b21456a20e
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Tue Mar 5 15:42:58 2019 -0800

    mm: replace all open encodings for NUMA_NO_NODE
    
    Patch series "Replace all open encodings for NUMA_NO_NODE", v3.
    
    All these places for replacement were found by running the following
    grep patterns on the entire kernel code.  Please let me know if this
    might have missed some instances.  This might also have replaced some
    false positives.  I will appreciate suggestions, inputs and review.
    
    1. git grep "nid == -1"
    2. git grep "node == -1"
    3. git grep "nid = -1"
    4. git grep "node = -1"
    
    This patch (of 2):
    
    At present there are multiple places where invalid node number is
    encoded as -1.  Even though implicitly understood it is always better to
    have macros in there.  Replace these open encodings for an invalid node
    number with the global macro NUMA_NO_NODE.  This helps remove NUMA
    related assumptions like 'invalid node' from various places redirecting
    them to a common definition.
    
    Link: http://lkml.kernel.org/r/1545127933-10711-2-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Acked-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>    [ixgbe]
    Acked-by: Jens Axboe <axboe@kernel.dk>                  [mtip32xx]
    Acked-by: Vinod Koul <vkoul@kernel.org>                 [dmaengine.c]
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>         [powerpc]
    Acked-by: Doug Ledford <dledford@redhat.com>            [drivers/infiniband]
    Cc: Joseph Qi <jiangqi903@gmail.com>
    Cc: Hans Verkuil <hverkuil@xs4all.nl>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index 84d038ed3882..248a38ad25c7 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -20,6 +20,7 @@
 #include <linux/slab.h>
 #include <linux/memory.h>
 #include <linux/memory_hotplug.h>
+#include <linux/numa.h>
 #include <asm/machdep.h>
 #include <asm/debugfs.h>
 
@@ -223,7 +224,7 @@ static int memtrace_online(void)
 		ent = &memtrace_array[i];
 
 		/* We have onlined this chunk previously */
-		if (ent->nid == -1)
+		if (ent->nid == NUMA_NO_NODE)
 			continue;
 
 		/* Remove from io mappings */
@@ -257,7 +258,7 @@ static int memtrace_online(void)
 		 */
 		debugfs_remove_recursive(ent->dir);
 		pr_info("Added trace memory back to node %d\n", ent->nid);
-		ent->size = ent->start = ent->nid = -1;
+		ent->size = ent->start = ent->nid = NUMA_NO_NODE;
 	}
 	if (ret)
 		return ret;

commit 5666848774ef43d3db5151ec518f1deb63515c20
Author: David Hildenbrand <david@redhat.com>
Date:   Tue Oct 30 15:10:39 2018 -0700

    powerpc/powernv: hold device_hotplug_lock when calling memtrace_offline_pages()
    
    Let's perform all checking + offlining + removing under
    device_hotplug_lock, so nobody can mess with these devices via sysfs
    concurrently.
    
    [david@redhat.com: take device_hotplug_lock outside of loop]
      Link: http://lkml.kernel.org/r/20180927092554.13567-6-david@redhat.com
    Link: http://lkml.kernel.org/r/20180925091457.28651-6-david@redhat.com
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Pavel Tatashin <pavel.tatashin@microsoft.com>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Rashmica Gupta <rashmica.g@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: John Allen <jallen@linux.vnet.ibm.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Mathieu Malaterre <malat@debian.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: YASUAKI ISHIMATSU <yasu.isimatu@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index fdd48f1a39f7..84d038ed3882 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -70,6 +70,7 @@ static int change_memblock_state(struct memory_block *mem, void *arg)
 	return 0;
 }
 
+/* called with device_hotplug_lock held */
 static bool memtrace_offline_pages(u32 nid, u64 start_pfn, u64 nr_pages)
 {
 	u64 end_pfn = start_pfn + nr_pages - 1;
@@ -110,6 +111,7 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 	/* Trace memory needs to be aligned to the size */
 	end_pfn = round_down(end_pfn - nr_pages, nr_pages);
 
+	lock_device_hotplug();
 	for (base_pfn = end_pfn; base_pfn > start_pfn; base_pfn -= nr_pages) {
 		if (memtrace_offline_pages(nid, base_pfn, nr_pages) == true) {
 			/*
@@ -118,7 +120,6 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 			 * we never try to remove memory that spans two iomem
 			 * resources.
 			 */
-			lock_device_hotplug();
 			end_pfn = base_pfn + nr_pages;
 			for (pfn = base_pfn; pfn < end_pfn; pfn += bytes>> PAGE_SHIFT) {
 				__remove_memory(nid, pfn << PAGE_SHIFT, bytes);
@@ -127,6 +128,7 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 			return base_pfn << PAGE_SHIFT;
 		}
 	}
+	unlock_device_hotplug();
 
 	return 0;
 }

commit cec1680591d6d5b10ecc10f370210089416e98af
Author: David Hildenbrand <david@redhat.com>
Date:   Tue Oct 30 15:10:33 2018 -0700

    powerpc/powernv: hold device_hotplug_lock when calling device_online()
    
    device_online() should be called with device_hotplug_lock() held.
    
    Link: http://lkml.kernel.org/r/20180925091457.28651-5-david@redhat.com
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Pavel Tatashin <pavel.tatashin@microsoft.com>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Rashmica Gupta <rashmica.g@gmail.com>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: John Allen <jallen@linux.vnet.ibm.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Mathieu Malaterre <malat@debian.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: YASUAKI ISHIMATSU <yasu.isimatu@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index 773623f6bfb1..fdd48f1a39f7 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -242,9 +242,11 @@ static int memtrace_online(void)
 		 * we need to online the memory ourselves.
 		 */
 		if (!memhp_auto_online) {
+			lock_device_hotplug();
 			walk_memory_range(PFN_DOWN(ent->start),
 					  PFN_UP(ent->start + ent->size - 1),
 					  NULL, online_mem_block);
+			unlock_device_hotplug();
 		}
 
 		/*

commit d15e59260f62bd5e0f625cf5f5240f6ffac78ab6
Author: David Hildenbrand <david@redhat.com>
Date:   Tue Oct 30 15:10:18 2018 -0700

    mm/memory_hotplug: make remove_memory() take the device_hotplug_lock
    
    Patch series "mm: online/offline_pages called w.o. mem_hotplug_lock", v3.
    
    Reading through the code and studying how mem_hotplug_lock is to be used,
    I noticed that there are two places where we can end up calling
    device_online()/device_offline() - online_pages()/offline_pages() without
    the mem_hotplug_lock.  And there are other places where we call
    device_online()/device_offline() without the device_hotplug_lock.
    
    While e.g.
            echo "online" > /sys/devices/system/memory/memory9/state
    is fine, e.g.
            echo 1 > /sys/devices/system/memory/memory9/online
    Will not take the mem_hotplug_lock. However the device_lock() and
    device_hotplug_lock.
    
    E.g.  via memory_probe_store(), we can end up calling
    add_memory()->online_pages() without the device_hotplug_lock.  So we can
    have concurrent callers in online_pages().  We e.g.  touch in
    online_pages() basically unprotected zone->present_pages then.
    
    Looks like there is a longer history to that (see Patch #2 for details),
    and fixing it to work the way it was intended is not really possible.  We
    would e.g.  have to take the mem_hotplug_lock in device/base/core.c, which
    sounds wrong.
    
    Summary: We had a lock inversion on mem_hotplug_lock and device_lock().
    More details can be found in patch 3 and patch 6.
    
    I propose the general rules (documentation added in patch 6):
    
    1. add_memory/add_memory_resource() must only be called with
       device_hotplug_lock.
    2. remove_memory() must only be called with device_hotplug_lock. This is
       already documented and holds for all callers.
    3. device_online()/device_offline() must only be called with
       device_hotplug_lock. This is already documented and true for now in core
       code. Other callers (related to memory hotplug) have to be fixed up.
    4. mem_hotplug_lock is taken inside of add_memory/remove_memory/
       online_pages/offline_pages.
    
    To me, this looks way cleaner than what we have right now (and easier to
    verify).  And looking at the documentation of remove_memory, using
    lock_device_hotplug also for add_memory() feels natural.
    
    This patch (of 6):
    
    remove_memory() is exported right now but requires the
    device_hotplug_lock, which is not exported.  So let's provide a variant
    that takes the lock and only export that one.
    
    The lock is already held in
            arch/powerpc/platforms/pseries/hotplug-memory.c
            drivers/acpi/acpi_memhotplug.c
            arch/powerpc/platforms/powernv/memtrace.c
    
    Apart from that, there are not other users in the tree.
    
    Link: http://lkml.kernel.org/r/20180925091457.28651-2-david@redhat.com
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Pavel Tatashin <pavel.tatashin@microsoft.com>
    Reviewed-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Reviewed-by: Oscar Salvador <osalvador@suse.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Rashmica Gupta <rashmica.g@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Cc: John Allen <jallen@linux.vnet.ibm.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: YASUAKI ISHIMATSU <yasu.isimatu@gmail.com>
    Cc: Mathieu Malaterre <malat@debian.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index a29fdf8a2e56..773623f6bfb1 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -121,7 +121,7 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 			lock_device_hotplug();
 			end_pfn = base_pfn + nr_pages;
 			for (pfn = base_pfn; pfn < end_pfn; pfn += bytes>> PAGE_SHIFT) {
-				remove_memory(nid, pfn << PAGE_SHIFT, bytes);
+				__remove_memory(nid, pfn << PAGE_SHIFT, bytes);
 			}
 			unlock_device_hotplug();
 			return base_pfn << PAGE_SHIFT;

commit 3f7daf3d7582dc6628ac40a9045dd1bbd80c5f35
Author: Rashmica Gupta <rashmica.g@gmail.com>
Date:   Fri Aug 17 14:25:01 2018 +1000

    powerpc/memtrace: Remove memory in chunks
    
    When hot-removing memory release_mem_region_adjustable() splits iomem
    resources if they are not the exact size of the memory being
    hot-deleted. Adding this memory back to the kernel adds a new resource.
    
    Eg a node has memory 0x0 - 0xfffffffff. Hot-removing 1GB from
    0xf40000000 results in the single resource 0x0-0xfffffffff being split
    into two resources: 0x0-0xf3fffffff and 0xf80000000-0xfffffffff.
    
    When we hot-add the memory back we now have three resources:
    0x0-0xf3fffffff, 0xf40000000-0xf7fffffff, and 0xf80000000-0xfffffffff.
    
    This is an issue if we try to remove some memory that overlaps
    resources. Eg when trying to remove 2GB at address 0xf40000000,
    release_mem_region_adjustable() fails as it expects the chunk of memory
    to be within the boundaries of a single resource. We then get the
    warning: "Unable to release resource" and attempting to use memtrace
    again gives us this error: "bash: echo: write error: Resource
    temporarily unavailable"
    
    This patch makes memtrace remove memory in chunks that are always the
    same size from an address that is always equal to end_of_memory -
    n*size, for some n. So hotremoving and hotadding memory of different
    sizes will now not attempt to remove memory that spans multiple
    resources.
    
    Signed-off-by: Rashmica Gupta <rashmica.g@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index 51dc398ae3f7..a29fdf8a2e56 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -90,17 +90,15 @@ static bool memtrace_offline_pages(u32 nid, u64 start_pfn, u64 nr_pages)
 	walk_memory_range(start_pfn, end_pfn, (void *)MEM_OFFLINE,
 			  change_memblock_state);
 
-	lock_device_hotplug();
-	remove_memory(nid, start_pfn << PAGE_SHIFT, nr_pages << PAGE_SHIFT);
-	unlock_device_hotplug();
 
 	return true;
 }
 
 static u64 memtrace_alloc_node(u32 nid, u64 size)
 {
-	u64 start_pfn, end_pfn, nr_pages;
+	u64 start_pfn, end_pfn, nr_pages, pfn;
 	u64 base_pfn;
+	u64 bytes = memory_block_size_bytes();
 
 	if (!node_spanned_pages(nid))
 		return 0;
@@ -113,8 +111,21 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 	end_pfn = round_down(end_pfn - nr_pages, nr_pages);
 
 	for (base_pfn = end_pfn; base_pfn > start_pfn; base_pfn -= nr_pages) {
-		if (memtrace_offline_pages(nid, base_pfn, nr_pages) == true)
+		if (memtrace_offline_pages(nid, base_pfn, nr_pages) == true) {
+			/*
+			 * Remove memory in memory block size chunks so that
+			 * iomem resources are always split to the same size and
+			 * we never try to remove memory that spans two iomem
+			 * resources.
+			 */
+			lock_device_hotplug();
+			end_pfn = base_pfn + nr_pages;
+			for (pfn = base_pfn; pfn < end_pfn; pfn += bytes>> PAGE_SHIFT) {
+				remove_memory(nid, pfn << PAGE_SHIFT, bytes);
+			}
+			unlock_device_hotplug();
 			return base_pfn << PAGE_SHIFT;
+		}
 	}
 
 	return 0;

commit d3da701d3308ce1fa457f32c6c9e2102aedea030
Author: Rashmica Gupta <rashmica.g@gmail.com>
Date:   Fri Aug 3 16:06:00 2018 +1000

    powerpc/powernv: Allow memory that has been hot-removed to be hot-added
    
    This patch allows the memory removed by memtrace to be readded to the
    kernel. So now you don't have to reboot your system to add the memory
    back to the kernel or to have a different amount of memory removed.
    
    Signed-off-by: Rashmica Gupta <rashmica.g@gmail.com>
    Tested-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index f73101119eba..51dc398ae3f7 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -177,8 +177,11 @@ static int memtrace_init_debugfs(void)
 
 		snprintf(ent->name, 16, "%08x", ent->nid);
 		dir = debugfs_create_dir(ent->name, memtrace_debugfs_dir);
-		if (!dir)
+		if (!dir) {
+			pr_err("Failed to create debugfs directory for node %d\n",
+				ent->nid);
 			return -1;
+		}
 
 		ent->dir = dir;
 		debugfs_create_file("trace", 0400, dir, ent, &memtrace_fops);
@@ -189,18 +192,93 @@ static int memtrace_init_debugfs(void)
 	return ret;
 }
 
+static int online_mem_block(struct memory_block *mem, void *arg)
+{
+	return device_online(&mem->dev);
+}
+
+/*
+ * Iterate through the chunks of memory we have removed from the kernel
+ * and attempt to add them back to the kernel.
+ */
+static int memtrace_online(void)
+{
+	int i, ret = 0;
+	struct memtrace_entry *ent;
+
+	for (i = memtrace_array_nr - 1; i >= 0; i--) {
+		ent = &memtrace_array[i];
+
+		/* We have onlined this chunk previously */
+		if (ent->nid == -1)
+			continue;
+
+		/* Remove from io mappings */
+		if (ent->mem) {
+			iounmap(ent->mem);
+			ent->mem = 0;
+		}
+
+		if (add_memory(ent->nid, ent->start, ent->size)) {
+			pr_err("Failed to add trace memory to node %d\n",
+				ent->nid);
+			ret += 1;
+			continue;
+		}
+
+		/*
+		 * If kernel isn't compiled with the auto online option
+		 * we need to online the memory ourselves.
+		 */
+		if (!memhp_auto_online) {
+			walk_memory_range(PFN_DOWN(ent->start),
+					  PFN_UP(ent->start + ent->size - 1),
+					  NULL, online_mem_block);
+		}
+
+		/*
+		 * Memory was added successfully so clean up references to it
+		 * so on reentry we can tell that this chunk was added.
+		 */
+		debugfs_remove_recursive(ent->dir);
+		pr_info("Added trace memory back to node %d\n", ent->nid);
+		ent->size = ent->start = ent->nid = -1;
+	}
+	if (ret)
+		return ret;
+
+	/* If all chunks of memory were added successfully, reset globals */
+	kfree(memtrace_array);
+	memtrace_array = NULL;
+	memtrace_size = 0;
+	memtrace_array_nr = 0;
+	return 0;
+}
+
 static int memtrace_enable_set(void *data, u64 val)
 {
-	if (memtrace_size)
+	u64 bytes;
+
+	/*
+	 * Don't attempt to do anything if size isn't aligned to a memory
+	 * block or equal to zero.
+	 */
+	bytes = memory_block_size_bytes();
+	if (val & (bytes - 1)) {
+		pr_err("Value must be aligned with 0x%llx\n", bytes);
 		return -EINVAL;
+	}
 
-	if (!val)
-		return -EINVAL;
+	/* Re-add/online previously removed/offlined memory */
+	if (memtrace_size) {
+		if (memtrace_online())
+			return -EAGAIN;
+	}
 
-	/* Make sure size is aligned to a memory block */
-	if (val & (memory_block_size_bytes() - 1))
-		return -EINVAL;
+	if (!val)
+		return 0;
 
+	/* Offline and remove memory */
 	if (memtrace_init_regions_runtime(val))
 		return -EINVAL;
 

commit 7dea6f2f053599d90f7894216db0dd0bedeb3a1c
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Jun 29 10:12:09 2018 +1000

    powerpc/powernv/memtrace: Remove memtrace mmap()
    
    debugfs doesn't support mmap(), so this code is never used.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index b99283df8584..f73101119eba 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -47,38 +47,9 @@ static ssize_t memtrace_read(struct file *filp, char __user *ubuf,
 	return simple_read_from_buffer(ubuf, count, ppos, ent->mem, ent->size);
 }
 
-static bool valid_memtrace_range(struct memtrace_entry *dev,
-				 unsigned long start, unsigned long size)
-{
-	if ((start >= dev->start) &&
-	    ((start + size) <= (dev->start + dev->size)))
-		return true;
-
-	return false;
-}
-
-static int memtrace_mmap(struct file *filp, struct vm_area_struct *vma)
-{
-	unsigned long size = vma->vm_end - vma->vm_start;
-	struct memtrace_entry *dev = filp->private_data;
-
-	if (!valid_memtrace_range(dev, vma->vm_pgoff << PAGE_SHIFT, size))
-		return -EINVAL;
-
-	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
-
-	if (remap_pfn_range(vma, vma->vm_start,
-			    vma->vm_pgoff + (dev->start >> PAGE_SHIFT),
-			    size, vma->vm_page_prot))
-		return -EAGAIN;
-
-	return 0;
-}
-
 static const struct file_operations memtrace_fops = {
 	.llseek = default_llseek,
 	.read	= memtrace_read,
-	.mmap	= memtrace_mmap,
 	.open	= simple_open,
 };
 

commit 8ccb442dec0ab53eefb5a607e405f7f3cd02e57f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu May 10 23:09:13 2018 +1000

    powerpc/powernv: Fix memtrace build when NUMA=n
    
    Currently memtrace doesn't build if NUMA=n:
    
      In function ‘memtrace_alloc_node’:
      arch/powerpc/platforms/powernv/memtrace.c:134:6:
      error: the address of ‘contig_page_data’ will always evaluate as ‘true’
        if (!NODE_DATA(nid) || !node_spanned_pages(nid))
            ^
    
    This is because for NUMA=n NODE_DATA(nid) points to an always
    allocated structure, contig_page_data.
    
    But even in the NUMA=y case memtrace_alloc_node() is only called for
    online nodes, and we should always have a NODE_DATA() allocated for an
    online node. So remove the (hopefully) overly paranoid check, which
    also means we can build when NUMA=n.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index fc222a0c2ac4..b99283df8584 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -131,7 +131,7 @@ static u64 memtrace_alloc_node(u32 nid, u64 size)
 	u64 start_pfn, end_pfn, nr_pages;
 	u64 base_pfn;
 
-	if (!NODE_DATA(nid) || !node_spanned_pages(nid))
+	if (!node_spanned_pages(nid))
 		return 0;
 
 	start_pfn = node_start_pfn(nid);

commit 7fd6641de28fe9b5bce0c38d2adee0a72a72619e
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Fri Apr 6 15:24:24 2018 +1000

    powerpc/powernv/memtrace: Let the arch hotunplug code flush cache
    
    Don't do this via custom code, instead now that we have support in the
    arch hotplug/hotunplug code, rely on those routines to do the right
    thing.
    
    The existing flush doesn't work because it uses ppc64_caches.l1d.size
    instead of ppc64_caches.l1d.line_size.
    
    Fixes: 9d5171a8f248 ("powerpc/powernv: Enable removal of memory for in memory tracing")
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
index de470caf0784..fc222a0c2ac4 100644
--- a/arch/powerpc/platforms/powernv/memtrace.c
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -82,19 +82,6 @@ static const struct file_operations memtrace_fops = {
 	.open	= simple_open,
 };
 
-static void flush_memory_region(u64 base, u64 size)
-{
-	unsigned long line_size = ppc64_caches.l1d.size;
-	u64 end = base + size;
-	u64 addr;
-
-	base = round_down(base, line_size);
-	end = round_up(end, line_size);
-
-	for (addr = base; addr < end; addr += line_size)
-		asm volatile("dcbf 0,%0" : "=r" (addr) :: "memory");
-}
-
 static int check_memblock_online(struct memory_block *mem, void *arg)
 {
 	if (mem->state != MEM_ONLINE)
@@ -132,10 +119,6 @@ static bool memtrace_offline_pages(u32 nid, u64 start_pfn, u64 nr_pages)
 	walk_memory_range(start_pfn, end_pfn, (void *)MEM_OFFLINE,
 			  change_memblock_state);
 
-	/* RCU grace period? */
-	flush_memory_region((u64)__va(start_pfn << PAGE_SHIFT),
-			    nr_pages << PAGE_SHIFT);
-
 	lock_device_hotplug();
 	remove_memory(nid, start_pfn << PAGE_SHIFT, nr_pages << PAGE_SHIFT);
 	unlock_device_hotplug();

commit 9d5171a8f248b1b0e69329bf141e17645c0324a0
Author: Rashmica Gupta <rashmica.g@gmail.com>
Date:   Thu Jun 1 15:34:38 2017 +1000

    powerpc/powernv: Enable removal of memory for in memory tracing
    
    The hardware trace macro feature requires access to a chunk of real
    memory. This patch provides a debugfs interface to do this. By
    writing an integer containing the size of memory to be unplugged into
    /sys/kernel/debug/powerpc/memtrace/enable, the code will attempt to
    remove that much memory from the end of each NUMA node.
    
    This patch also adds additional debugsfs files for each node that
    allows the tracer to interact with the removed memory, as well as
    a trace file that allows userspace to read the generated trace.
    
    Note that this patch does not invoke the hardware trace macro, it
    only allows memory to be removed during runtime for the trace macro
    to utilise.
    
    Signed-off-by: Rashmica Gupta <rashmica.g@gmail.com>
    [mpe: Minor formatting etc fixups]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/powernv/memtrace.c b/arch/powerpc/platforms/powernv/memtrace.c
new file mode 100644
index 000000000000..de470caf0784
--- /dev/null
+++ b/arch/powerpc/platforms/powernv/memtrace.c
@@ -0,0 +1,282 @@
+/*
+ * Copyright (C) IBM Corporation, 2014, 2017
+ * Anton Blanchard, Rashmica Gupta.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#define pr_fmt(fmt) "memtrace: " fmt
+
+#include <linux/bitops.h>
+#include <linux/string.h>
+#include <linux/memblock.h>
+#include <linux/init.h>
+#include <linux/moduleparam.h>
+#include <linux/fs.h>
+#include <linux/debugfs.h>
+#include <linux/slab.h>
+#include <linux/memory.h>
+#include <linux/memory_hotplug.h>
+#include <asm/machdep.h>
+#include <asm/debugfs.h>
+
+/* This enables us to keep track of the memory removed from each node. */
+struct memtrace_entry {
+	void *mem;
+	u64 start;
+	u64 size;
+	u32 nid;
+	struct dentry *dir;
+	char name[16];
+};
+
+static u64 memtrace_size;
+
+static struct memtrace_entry *memtrace_array;
+static unsigned int memtrace_array_nr;
+
+
+static ssize_t memtrace_read(struct file *filp, char __user *ubuf,
+			     size_t count, loff_t *ppos)
+{
+	struct memtrace_entry *ent = filp->private_data;
+
+	return simple_read_from_buffer(ubuf, count, ppos, ent->mem, ent->size);
+}
+
+static bool valid_memtrace_range(struct memtrace_entry *dev,
+				 unsigned long start, unsigned long size)
+{
+	if ((start >= dev->start) &&
+	    ((start + size) <= (dev->start + dev->size)))
+		return true;
+
+	return false;
+}
+
+static int memtrace_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	unsigned long size = vma->vm_end - vma->vm_start;
+	struct memtrace_entry *dev = filp->private_data;
+
+	if (!valid_memtrace_range(dev, vma->vm_pgoff << PAGE_SHIFT, size))
+		return -EINVAL;
+
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+
+	if (remap_pfn_range(vma, vma->vm_start,
+			    vma->vm_pgoff + (dev->start >> PAGE_SHIFT),
+			    size, vma->vm_page_prot))
+		return -EAGAIN;
+
+	return 0;
+}
+
+static const struct file_operations memtrace_fops = {
+	.llseek = default_llseek,
+	.read	= memtrace_read,
+	.mmap	= memtrace_mmap,
+	.open	= simple_open,
+};
+
+static void flush_memory_region(u64 base, u64 size)
+{
+	unsigned long line_size = ppc64_caches.l1d.size;
+	u64 end = base + size;
+	u64 addr;
+
+	base = round_down(base, line_size);
+	end = round_up(end, line_size);
+
+	for (addr = base; addr < end; addr += line_size)
+		asm volatile("dcbf 0,%0" : "=r" (addr) :: "memory");
+}
+
+static int check_memblock_online(struct memory_block *mem, void *arg)
+{
+	if (mem->state != MEM_ONLINE)
+		return -1;
+
+	return 0;
+}
+
+static int change_memblock_state(struct memory_block *mem, void *arg)
+{
+	unsigned long state = (unsigned long)arg;
+
+	mem->state = state;
+
+	return 0;
+}
+
+static bool memtrace_offline_pages(u32 nid, u64 start_pfn, u64 nr_pages)
+{
+	u64 end_pfn = start_pfn + nr_pages - 1;
+
+	if (walk_memory_range(start_pfn, end_pfn, NULL,
+	    check_memblock_online))
+		return false;
+
+	walk_memory_range(start_pfn, end_pfn, (void *)MEM_GOING_OFFLINE,
+			  change_memblock_state);
+
+	if (offline_pages(start_pfn, nr_pages)) {
+		walk_memory_range(start_pfn, end_pfn, (void *)MEM_ONLINE,
+				  change_memblock_state);
+		return false;
+	}
+
+	walk_memory_range(start_pfn, end_pfn, (void *)MEM_OFFLINE,
+			  change_memblock_state);
+
+	/* RCU grace period? */
+	flush_memory_region((u64)__va(start_pfn << PAGE_SHIFT),
+			    nr_pages << PAGE_SHIFT);
+
+	lock_device_hotplug();
+	remove_memory(nid, start_pfn << PAGE_SHIFT, nr_pages << PAGE_SHIFT);
+	unlock_device_hotplug();
+
+	return true;
+}
+
+static u64 memtrace_alloc_node(u32 nid, u64 size)
+{
+	u64 start_pfn, end_pfn, nr_pages;
+	u64 base_pfn;
+
+	if (!NODE_DATA(nid) || !node_spanned_pages(nid))
+		return 0;
+
+	start_pfn = node_start_pfn(nid);
+	end_pfn = node_end_pfn(nid);
+	nr_pages = size >> PAGE_SHIFT;
+
+	/* Trace memory needs to be aligned to the size */
+	end_pfn = round_down(end_pfn - nr_pages, nr_pages);
+
+	for (base_pfn = end_pfn; base_pfn > start_pfn; base_pfn -= nr_pages) {
+		if (memtrace_offline_pages(nid, base_pfn, nr_pages) == true)
+			return base_pfn << PAGE_SHIFT;
+	}
+
+	return 0;
+}
+
+static int memtrace_init_regions_runtime(u64 size)
+{
+	u32 nid;
+	u64 m;
+
+	memtrace_array = kcalloc(num_online_nodes(),
+				sizeof(struct memtrace_entry), GFP_KERNEL);
+	if (!memtrace_array) {
+		pr_err("Failed to allocate memtrace_array\n");
+		return -EINVAL;
+	}
+
+	for_each_online_node(nid) {
+		m = memtrace_alloc_node(nid, size);
+
+		/*
+		 * A node might not have any local memory, so warn but
+		 * continue on.
+		 */
+		if (!m) {
+			pr_err("Failed to allocate trace memory on node %d\n", nid);
+			continue;
+		}
+
+		pr_info("Allocated trace memory on node %d at 0x%016llx\n", nid, m);
+
+		memtrace_array[memtrace_array_nr].start = m;
+		memtrace_array[memtrace_array_nr].size = size;
+		memtrace_array[memtrace_array_nr].nid = nid;
+		memtrace_array_nr++;
+	}
+
+	return 0;
+}
+
+static struct dentry *memtrace_debugfs_dir;
+
+static int memtrace_init_debugfs(void)
+{
+	int ret = 0;
+	int i;
+
+	for (i = 0; i < memtrace_array_nr; i++) {
+		struct dentry *dir;
+		struct memtrace_entry *ent = &memtrace_array[i];
+
+		ent->mem = ioremap(ent->start, ent->size);
+		/* Warn but continue on */
+		if (!ent->mem) {
+			pr_err("Failed to map trace memory at 0x%llx\n",
+				 ent->start);
+			ret = -1;
+			continue;
+		}
+
+		snprintf(ent->name, 16, "%08x", ent->nid);
+		dir = debugfs_create_dir(ent->name, memtrace_debugfs_dir);
+		if (!dir)
+			return -1;
+
+		ent->dir = dir;
+		debugfs_create_file("trace", 0400, dir, ent, &memtrace_fops);
+		debugfs_create_x64("start", 0400, dir, &ent->start);
+		debugfs_create_x64("size", 0400, dir, &ent->size);
+	}
+
+	return ret;
+}
+
+static int memtrace_enable_set(void *data, u64 val)
+{
+	if (memtrace_size)
+		return -EINVAL;
+
+	if (!val)
+		return -EINVAL;
+
+	/* Make sure size is aligned to a memory block */
+	if (val & (memory_block_size_bytes() - 1))
+		return -EINVAL;
+
+	if (memtrace_init_regions_runtime(val))
+		return -EINVAL;
+
+	if (memtrace_init_debugfs())
+		return -EINVAL;
+
+	memtrace_size = val;
+
+	return 0;
+}
+
+static int memtrace_enable_get(void *data, u64 *val)
+{
+	*val = memtrace_size;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(memtrace_init_fops, memtrace_enable_get,
+					memtrace_enable_set, "0x%016llx\n");
+
+static int memtrace_init(void)
+{
+	memtrace_debugfs_dir = debugfs_create_dir("memtrace",
+						  powerpc_debugfs_root);
+	if (!memtrace_debugfs_dir)
+		return -1;
+
+	debugfs_create_file("enable", 0600, memtrace_debugfs_dir,
+			    NULL, &memtrace_init_fops);
+
+	return 0;
+}
+machine_device_initcall(powernv, memtrace_init);
