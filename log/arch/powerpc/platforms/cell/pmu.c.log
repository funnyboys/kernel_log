commit de6cc6515a445d5d81cad2dee899a0be1a6317f8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:02 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 153
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 or at your option any
      later version this program is distributed in the hope that it will
      be useful but without any warranty without even the implied warranty
      of merchantability or fitness for a particular purpose see the gnu
      general public license for more details you should have received a
      copy of the gnu general public license along with this program if
      not write to the free software foundation inc 675 mass ave cambridge
      ma 02139 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 77 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.837555891@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index e3ad0c38f017..35bbd15582af 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Cell Broadband Engine Performance Monitor
  *
@@ -6,20 +7,6 @@
  * Author:
  *    David Erb (djerb@us.ibm.com)
  *    Kevin Corry (kevcorry@us.ibm.com)
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2, or (at your option)
- * any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 
 #include <linux/interrupt.h>

commit ef24ba7091517d2bbf9ba2cb4256c0dccd51d248
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Sep 6 21:53:24 2016 +1000

    powerpc: Remove all usages of NO_IRQ
    
    NO_IRQ has been == 0 on powerpc for just over ten years (since commit
    0ebfff1491ef ("[POWERPC] Add new interrupt mapping core and change
    platforms to use it")). It's also 0 on most other arches.
    
    Although it's fairly harmless, every now and then it causes confusion
    when a driver is built on powerpc and another arch which doesn't define
    NO_IRQ. There's at least 6 definitions of NO_IRQ in drivers/, at least
    some of which are to work around that problem.
    
    So we'd like to remove it. This is fairly trivial in the arch code, we
    just convert:
    
        if (irq == NO_IRQ)  to      if (!irq)
        if (irq != NO_IRQ)  to      if (irq)
        irq = NO_IRQ;       to      irq = 0;
        return NO_IRQ;      to      return 0;
    
    And a few other odd cases as well.
    
    At least for now we keep the #define NO_IRQ, because there is driver
    code that uses NO_IRQ and the fixes to remove those will go via other
    trees.
    
    Note we also change some occurrences in PPC sound drivers, drivers/ps3,
    and drivers/macintosh.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 348a27b12512..e3ad0c38f017 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -385,7 +385,7 @@ static int __init cbe_init_pm_irq(void)
 	for_each_online_node(node) {
 		irq = irq_create_mapping(NULL, IIC_IRQ_IOEX_PMI |
 					       (node << IIC_IRQ_NODE_SHIFT));
-		if (irq == NO_IRQ) {
+		if (!irq) {
 			printk("ERROR: Unable to allocate irq for node %d\n",
 			       node);
 			return -EINVAL;
@@ -412,7 +412,7 @@ void cbe_sync_irq(int node)
 			       IIC_IRQ_IOEX_PMI
 			       | (node << IIC_IRQ_NODE_SHIFT));
 
-	if (irq == NO_IRQ) {
+	if (!irq) {
 		printk(KERN_WARNING "ERROR, unable to get existing irq %d " \
 		"for node %d\n", irq, node);
 		return;

commit 51e0eaf98d48dc6fc385d1aee9e208afe3ce0cf1
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Apr 23 02:14:51 2013 +0000

    powerpc/cell: Only iterate over online nodes in cbe_init_pm_irq()
    
    None of the cell platforms support CPU hotplug, so we should iterate
    only over online nodes when setting PMU interrupts.
    
    This also fixes a warning during boot when NODES_SHIFT is large enough:
    
    WARNING: at /scratch/michael/src/kmk/linus/kernel/irq/irqdomain.c:766
    ...
    NIP [c0000000000db278] .irq_linear_revmap+0x30/0x58
    LR [c0000000000dc2a0] .irq_create_mapping+0x38/0x1a8
    Call Trace:
    [c0000003fc9c3af0] [c0000000000dc2a0] .irq_create_mapping+0x38/0x1a8 (unreliable)
    [c0000003fc9c3b80] [c000000000655c1c] .__machine_initcall_cell_cbe_init_pm_irq+0x84/0x158
    [c0000003fc9c3c20] [c00000000000afb4] .do_one_initcall+0x5c/0x1e0
    [c0000003fc9c3cd0] [c000000000644580] .kernel_init_freeable+0x238/0x328
    [c0000003fc9c3db0] [c00000000000b784] .kernel_init+0x1c/0x120
    [c0000003fc9c3e30] [c000000000009fb8] .ret_from_kernel_thread+0x64/0xac
    
    This is caused by us overflowing our linear revmap because we're
    requesting too many interrupts.
    
    Reported-by: Dennis Schridde <devurandom@gmx.net>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 59c1a1694104..348a27b12512 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -382,7 +382,7 @@ static int __init cbe_init_pm_irq(void)
 	unsigned int irq;
 	int rc, node;
 
-	for_each_node(node) {
+	for_each_online_node(node) {
 		irq = irq_create_mapping(NULL, IIC_IRQ_IOEX_PMI |
 					       (node << IIC_IRQ_NODE_SHIFT));
 		if (irq == NO_IRQ) {

commit a3a9f3b47d12b5f6dfc9c7ed9d7b193d77812195
Author: Yong Zhang <yong.zhang0@gmail.com>
Date:   Fri Oct 21 23:56:27 2011 +0000

    powerpc/irq: Remove IRQF_DISABLED
    
    Since commit [e58aa3d2: genirq: Run irq handlers with interrupts disabled],
    We run all interrupt handlers with interrupts disabled
    and we even check and yell when an interrupt handler
    returns with interrupts enabled (see commit [b738a50a:
    genirq: Warn when handler enables interrupts]).
    
    So now this flag is a NOOP and can be removed.
    
    Signed-off-by: Yong Zhang <yong.zhang0@gmail.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Geoff Levand <geoff@infradead.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 1acf36010423..59c1a1694104 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -392,7 +392,7 @@ static int __init cbe_init_pm_irq(void)
 		}
 
 		rc = request_irq(irq, cbe_pm_irq,
-				 IRQF_DISABLED, "cbe-pmu-0", NULL);
+				 0, "cbe-pmu-0", NULL);
 		if (rc) {
 			printk("ERROR: Request for irq on node %d failed\n",
 			       node);

commit 66b15db69c2553036cc25f6e2e74fe7e3aa2761e
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri May 27 10:46:24 2011 -0400

    powerpc: add export.h to files making use of EXPORT_SYMBOL
    
    With module.h being implicitly everywhere via device.h, the absence
    of explicitly including something for EXPORT_SYMBOL went unnoticed.
    Since we are heading to fix things up and clean module.h from the
    device.h file, we need to explicitly include these files now.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 69ed0d7f1646..1acf36010423 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -24,6 +24,7 @@
 
 #include <linux/interrupt.h>
 #include <linux/types.h>
+#include <linux/export.h>
 #include <asm/io.h>
 #include <asm/irq_regs.h>
 #include <asm/machdep.h>

commit e25c47ffa97ca5e4602593b03ce6d21cff652864
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Thu Jan 3 06:14:36 2008 +1100

    [POWERPC] cell: Use machine_*_initcall() hooks in platform code
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 99d688e88cbe..69ed0d7f1646 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -381,9 +381,6 @@ static int __init cbe_init_pm_irq(void)
 	unsigned int irq;
 	int rc, node;
 
-	if (!machine_is(cell))
-		return 0;
-
 	for_each_node(node) {
 		irq = irq_create_mapping(NULL, IIC_IRQ_IOEX_PMI |
 					       (node << IIC_IRQ_NODE_SHIFT));
@@ -404,7 +401,7 @@ static int __init cbe_init_pm_irq(void)
 
 	return 0;
 }
-arch_initcall(cbe_init_pm_irq);
+machine_arch_initcall(cell, cbe_init_pm_irq);
 
 void cbe_sync_irq(int node)
 {

commit 29641ce165e5f643b48988cb779c6ba97b647503
Author: Kevin Corry <kevcorry@us.ibm.com>
Date:   Tue Dec 11 13:49:17 2007 +0100

    [POWERPC] perfmon2: make pm_interval register read/write
    
    The pm_interval register in the Cell PMU is read/write, but was implemented in
    the kernel as write-only. Previously, the written value was saved in a "shadow"
    copy so calls to cbe_read_pm() could return the value.
    
    Perfmon2 needs to be able to read the current values of pm_interval, so change
    cbe_read_pm() to read the actual register instead of the "shadow" copy. There
    is currently no code in the kernel that tries to read the pm_interval register
    with cbe_read_pm() (expecting to receive the "shadow" value), so this should
    not break any existing code.
    
    Signed-off-by: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Carl Love <carll@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 1ed303678887..99d688e88cbe 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -213,7 +213,7 @@ u32 cbe_read_pm(u32 cpu, enum pm_reg_name reg)
 		break;
 
 	case pm_interval:
-		READ_SHADOW_REG(val, pm_interval);
+		READ_MMIO_UPPER32(val, pm_interval);
 		break;
 
 	case pm_start_stop:

commit eef686a0095430bdd6c1942f86dd2b543e66679f
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Oct 4 15:40:42 2007 +1000

    [POWERPC] cell: Move cbe_regs.h to include/asm-powerpc/cell-regs.h
    
    The new Cell EDAC driver needs that file, oprofile also does ugly
    path tricks to get to it, it's time to move it to asm-powerpc. While
    at it, rename it to be consistent with cell-pmu.h (and dashes look
    nicer than underscores anyway).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 66ca4b5a1dbc..1ed303678887 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -30,8 +30,8 @@
 #include <asm/pmc.h>
 #include <asm/reg.h>
 #include <asm/spu.h>
+#include <asm/cell-regs.h>
 
-#include "cbe_regs.h"
 #include "interrupt.h"
 
 /*

commit bcb63e25ed3c56ee40cca4d18fbaac1d2a40c1d6
Author: Carl Love <carll@us.ibm.com>
Date:   Tue Feb 13 22:02:02 2007 +0100

    [POWERPC] cell: PPU Oprofile cleanup patch
    
    This is a clean up patch that includes the following changes:
    
     -Some comments were added to clarify the code based on feedback
      from the community.
     -The write_pm_cntrl() and set_count_mode() were passed a
      structure element from a global variable.  The argument was
      removed so the functions now just operate on the global directly.
     -The set_pm_event() function call in the cell_virtual_cntr()
      routine was moved to a for-loop before the for_each_cpu loop
    
    Signed-off-by: Carl Love <carll@us.ibm.com>
    Signed-off-by: Maynard Johnson <mpjohn@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index d04ae1671e6c..66ca4b5a1dbc 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -345,18 +345,12 @@ EXPORT_SYMBOL_GPL(cbe_read_trace_buffer);
  * Enabling/disabling interrupts for the entire performance monitoring unit.
  */
 
-u32 cbe_query_pm_interrupts(u32 cpu)
-{
-	return cbe_read_pm(cpu, pm_status);
-}
-EXPORT_SYMBOL_GPL(cbe_query_pm_interrupts);
-
-u32 cbe_clear_pm_interrupts(u32 cpu)
+u32 cbe_get_and_clear_pm_interrupts(u32 cpu)
 {
 	/* Reading pm_status clears the interrupt bits. */
-	return cbe_query_pm_interrupts(cpu);
+	return cbe_read_pm(cpu, pm_status);
 }
-EXPORT_SYMBOL_GPL(cbe_clear_pm_interrupts);
+EXPORT_SYMBOL_GPL(cbe_get_and_clear_pm_interrupts);
 
 void cbe_enable_pm_interrupts(u32 cpu, u32 thread, u32 mask)
 {
@@ -371,7 +365,7 @@ EXPORT_SYMBOL_GPL(cbe_enable_pm_interrupts);
 
 void cbe_disable_pm_interrupts(u32 cpu)
 {
-	cbe_clear_pm_interrupts(cpu);
+	cbe_get_and_clear_pm_interrupts(cpu);
 	cbe_write_pm(cpu, pm_status, 0);
 }
 EXPORT_SYMBOL_GPL(cbe_disable_pm_interrupts);

commit a081e126e12f78651499ba0f9944a7df1e9b06b6
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Dec 5 15:54:14 2006 +1100

    [POWERPC] Fix cell pmu initialisation
    
    Make sure that the pmu is not initialised unless we are running on a cell.
    Also make the init routine static.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 99c612025e8f..d04ae1671e6c 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -382,11 +382,14 @@ static irqreturn_t cbe_pm_irq(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-int __init cbe_init_pm_irq(void)
+static int __init cbe_init_pm_irq(void)
 {
 	unsigned int irq;
 	int rc, node;
 
+	if (!machine_is(cell))
+		return 0;
+
 	for_each_node(node) {
 		irq = irq_create_mapping(NULL, IIC_IRQ_IOEX_PMI |
 					       (node << IIC_IRQ_NODE_SHIFT));

commit 18f2190d796198fbb5d4bc4c87511acf3ced7d47
Author: Maynard Johnson <maynardj@us.ibm.com>
Date:   Mon Nov 20 18:45:16 2006 +0100

    [POWERPC] cell: Add oprofile support
    
    Add PPU event-based and cycle-based profiling support to Oprofile for Cell.
    
    Oprofile is expected to collect data on all CPUs simultaneously.
    However, there is one set of performance counters per node.  There are
    two hardware threads or virtual CPUs on each node.  Hence, OProfile must
    multiplex in time the performance counter collection on the two virtual
    CPUs.
    
    The multiplexing of the performance counters is done by a virtual
    counter routine.  Initially, the counters are configured to collect data
    on the even CPUs in the system, one CPU per node.  In order to capture
    the PC for the virtual CPU when the performance counter interrupt occurs
    (the specified number of events between samples has occurred), the even
    processors are configured to handle the performance counter interrupts
    for their node.  The virtual counter routine is called via a kernel
    timer after the virtual sample time.  The routine stops the counters,
    saves the current counts, loads the last counts for the other virtual
    CPU on the node, sets interrupts to be handled by the other virtual CPU
    and restarts the counters, the virtual timer routine is scheduled to run
    again.  The virtual sample time is kept relatively small to make sure
    sampling occurs on both CPUs on the node with a relatively small
    granularity.  Whenever the counters overflow, the performance counter
    interrupt is called to collect the PC for the CPU where data is being
    collected.
    
    The oprofile driver relies on a firmware RTAS call to setup the debug bus
    to route the desired signals to the performance counter hardware to be
    counted.  The RTAS call must set the routing registers appropriately in
    each of the islands to pass the signals down the debug bus as well as
    routing the signals from a particular island onto the bus.  There is a
    second firmware RTAS call to reset the debug bus to the non pass thru
    state when the counters are not in use.
    
    Signed-off-by: Carl Love <carll@us.ibm.com>
    Signed-off-by: Maynard Johnson <mpjohn@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index f28abf2fc273..99c612025e8f 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -25,6 +25,7 @@
 #include <linux/interrupt.h>
 #include <linux/types.h>
 #include <asm/io.h>
+#include <asm/irq_regs.h>
 #include <asm/machdep.h>
 #include <asm/pmc.h>
 #include <asm/reg.h>
@@ -375,9 +376,9 @@ void cbe_disable_pm_interrupts(u32 cpu)
 }
 EXPORT_SYMBOL_GPL(cbe_disable_pm_interrupts);
 
-static irqreturn_t cbe_pm_irq(int irq, void *dev_id, struct pt_regs *regs)
+static irqreturn_t cbe_pm_irq(int irq, void *dev_id)
 {
-	perf_irq(regs);
+	perf_irq(get_irq_regs());
 	return IRQ_HANDLED;
 }
 
@@ -408,3 +409,21 @@ int __init cbe_init_pm_irq(void)
 }
 arch_initcall(cbe_init_pm_irq);
 
+void cbe_sync_irq(int node)
+{
+	unsigned int irq;
+
+	irq = irq_find_mapping(NULL,
+			       IIC_IRQ_IOEX_PMI
+			       | (node << IIC_IRQ_NODE_SHIFT));
+
+	if (irq == NO_IRQ) {
+		printk(KERN_WARNING "ERROR, unable to get existing irq %d " \
+		"for node %d\n", irq, node);
+		return;
+	}
+
+	synchronize_irq(irq);
+}
+EXPORT_SYMBOL_GPL(cbe_sync_irq);
+

commit 0443bbd3d8496f9c2bc3e8c9d1833c6638722743
Author: Kevin Corry <kevcorry@us.ibm.com>
Date:   Mon Nov 20 18:45:15 2006 +0100

    [POWERPC] cell: Add routines for managing PMU interrupts
    
    The following routines are added to arch/powerpc/platforms/cell/pmu.c:
     cbe_clear_pm_interrupts()
     cbe_enable_pm_interrupts()
     cbe_disable_pm_interrupts()
     cbe_query_pm_interrupts()
     cbe_pm_irq()
     cbe_init_pm_irq()
    
    This also adds a routine in arch/powerpc/platforms/cell/interrupt.c and
    some macros in cbe_regs.h to manipulate the IIC_IR register:
     iic_set_interrupt_routing()
    
    Signed-off-by: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Carl Love <carll@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index ae6fd1c12d4e..f28abf2fc273 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -22,9 +22,11 @@
  * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 
+#include <linux/interrupt.h>
 #include <linux/types.h>
 #include <asm/io.h>
 #include <asm/machdep.h>
+#include <asm/pmc.h>
 #include <asm/reg.h>
 #include <asm/spu.h>
 
@@ -338,3 +340,71 @@ void cbe_read_trace_buffer(u32 cpu, u64 *buf)
 }
 EXPORT_SYMBOL_GPL(cbe_read_trace_buffer);
 
+/*
+ * Enabling/disabling interrupts for the entire performance monitoring unit.
+ */
+
+u32 cbe_query_pm_interrupts(u32 cpu)
+{
+	return cbe_read_pm(cpu, pm_status);
+}
+EXPORT_SYMBOL_GPL(cbe_query_pm_interrupts);
+
+u32 cbe_clear_pm_interrupts(u32 cpu)
+{
+	/* Reading pm_status clears the interrupt bits. */
+	return cbe_query_pm_interrupts(cpu);
+}
+EXPORT_SYMBOL_GPL(cbe_clear_pm_interrupts);
+
+void cbe_enable_pm_interrupts(u32 cpu, u32 thread, u32 mask)
+{
+	/* Set which node and thread will handle the next interrupt. */
+	iic_set_interrupt_routing(cpu, thread, 0);
+
+	/* Enable the interrupt bits in the pm_status register. */
+	if (mask)
+		cbe_write_pm(cpu, pm_status, mask);
+}
+EXPORT_SYMBOL_GPL(cbe_enable_pm_interrupts);
+
+void cbe_disable_pm_interrupts(u32 cpu)
+{
+	cbe_clear_pm_interrupts(cpu);
+	cbe_write_pm(cpu, pm_status, 0);
+}
+EXPORT_SYMBOL_GPL(cbe_disable_pm_interrupts);
+
+static irqreturn_t cbe_pm_irq(int irq, void *dev_id, struct pt_regs *regs)
+{
+	perf_irq(regs);
+	return IRQ_HANDLED;
+}
+
+int __init cbe_init_pm_irq(void)
+{
+	unsigned int irq;
+	int rc, node;
+
+	for_each_node(node) {
+		irq = irq_create_mapping(NULL, IIC_IRQ_IOEX_PMI |
+					       (node << IIC_IRQ_NODE_SHIFT));
+		if (irq == NO_IRQ) {
+			printk("ERROR: Unable to allocate irq for node %d\n",
+			       node);
+			return -EINVAL;
+		}
+
+		rc = request_irq(irq, cbe_pm_irq,
+				 IRQF_DISABLED, "cbe-pmu-0", NULL);
+		if (rc) {
+			printk("ERROR: Request for irq on node %d failed\n",
+			       node);
+			return rc;
+		}
+	}
+
+	return 0;
+}
+arch_initcall(cbe_init_pm_irq);
+

commit e4f6948cfc8b9626022db0f93e7cf2ce5c0998cd
Author: Kevin Corry <kevcorry@us.ibm.com>
Date:   Mon Nov 20 18:45:14 2006 +0100

    [POWERPC] cell: Move PMU-related stuff to include/asm-powerpc/cell-pmu.h
    
    Move some PMU-related macros and function prototypes from cbe_regs.h
    and pmu.h in arch/powerpc/platforms/cell/ to a new header at
    include/asm-powerpc/cell-pmu.h
    
    This is cleaner to use from the oprofile code, since that sits in
    arch/powerpc/oprofile, not in the cell platform directory.
    
    Signed-off-by: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 22ac732b1f89..ae6fd1c12d4e 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -30,7 +30,6 @@
 
 #include "cbe_regs.h"
 #include "interrupt.h"
-#include "pmu.h"
 
 /*
  * When writing to write-only mmio addresses, save a shadow copy. All of the

commit 5231800c6fb99c106951a5e1a8e739ad9657e93f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Nov 20 18:45:12 2006 +0100

    [POWERPC] cell: Add symbol exports for oprofile
    
    Add symbol-exports for the new routines in arch/powerpc/platforms/cell/pmu.c.
    They are needed for Oprofile, which can be built as a module.
    
    Signed-off-by: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
index 30d17ce236a7..22ac732b1f89 100644
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -85,6 +85,7 @@ u32 cbe_read_phys_ctr(u32 cpu, u32 phys_ctr)
 
 	return val;
 }
+EXPORT_SYMBOL_GPL(cbe_read_phys_ctr);
 
 void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val)
 {
@@ -111,6 +112,7 @@ void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val)
 		}
 	}
 }
+EXPORT_SYMBOL_GPL(cbe_write_phys_ctr);
 
 /*
  * "Logical" counter registers.
@@ -130,6 +132,7 @@ u32 cbe_read_ctr(u32 cpu, u32 ctr)
 
 	return val;
 }
+EXPORT_SYMBOL_GPL(cbe_read_ctr);
 
 void cbe_write_ctr(u32 cpu, u32 ctr, u32 val)
 {
@@ -149,6 +152,7 @@ void cbe_write_ctr(u32 cpu, u32 ctr, u32 val)
 
 	cbe_write_phys_ctr(cpu, phys_ctr, val);
 }
+EXPORT_SYMBOL_GPL(cbe_write_ctr);
 
 /*
  * Counter-control registers.
@@ -164,12 +168,14 @@ u32 cbe_read_pm07_control(u32 cpu, u32 ctr)
 
 	return pm07_control;
 }
+EXPORT_SYMBOL_GPL(cbe_read_pm07_control);
 
 void cbe_write_pm07_control(u32 cpu, u32 ctr, u32 val)
 {
 	if (ctr < NR_CTRS)
 		WRITE_WO_MMIO(pm07_control[ctr], val);
 }
+EXPORT_SYMBOL_GPL(cbe_write_pm07_control);
 
 /*
  * Other PMU control registers. Most of these are write-only.
@@ -215,6 +221,7 @@ u32 cbe_read_pm(u32 cpu, enum pm_reg_name reg)
 
 	return val;
 }
+EXPORT_SYMBOL_GPL(cbe_read_pm);
 
 void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val)
 {
@@ -252,6 +259,7 @@ void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val)
 		break;
 	}
 }
+EXPORT_SYMBOL_GPL(cbe_write_pm);
 
 /*
  * Get/set the size of a physical counter to either 16 or 32 bits.
@@ -268,6 +276,7 @@ u32 cbe_get_ctr_size(u32 cpu, u32 phys_ctr)
 
 	return size;
 }
+EXPORT_SYMBOL_GPL(cbe_get_ctr_size);
 
 void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size)
 {
@@ -287,6 +296,7 @@ void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size)
 		cbe_write_pm(cpu, pm_control, pm_ctrl);
 	}
 }
+EXPORT_SYMBOL_GPL(cbe_set_ctr_size);
 
 /*
  * Enable/disable the entire performance monitoring unit.
@@ -304,6 +314,7 @@ void cbe_enable_pm(u32 cpu)
 	pm_ctrl = cbe_read_pm(cpu, pm_control) | CBE_PM_ENABLE_PERF_MON;
 	cbe_write_pm(cpu, pm_control, pm_ctrl);
 }
+EXPORT_SYMBOL_GPL(cbe_enable_pm);
 
 void cbe_disable_pm(u32 cpu)
 {
@@ -311,6 +322,7 @@ void cbe_disable_pm(u32 cpu)
 	pm_ctrl = cbe_read_pm(cpu, pm_control) & ~CBE_PM_ENABLE_PERF_MON;
 	cbe_write_pm(cpu, pm_control, pm_ctrl);
 }
+EXPORT_SYMBOL_GPL(cbe_disable_pm);
 
 /*
  * Reading from the trace_buffer.
@@ -325,4 +337,5 @@ void cbe_read_trace_buffer(u32 cpu, u64 *buf)
 	*buf++ = in_be64(&pmd_regs->trace_buffer_0_63);
 	*buf++ = in_be64(&pmd_regs->trace_buffer_64_127);
 }
+EXPORT_SYMBOL_GPL(cbe_read_trace_buffer);
 

commit d8bf96e0793f9576da545bac333b2de304958d68
Author: Kevin Corry <kevcorry@us.ibm.com>
Date:   Tue Oct 24 18:31:22 2006 +0200

    [POWERPC] cell: add low-level performance monitoring code
    
    Add routines for accessing the registers and counters in the performance
    monitoring unit.
    
    Signed-off-by: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pmu.c b/arch/powerpc/platforms/cell/pmu.c
new file mode 100644
index 000000000000..30d17ce236a7
--- /dev/null
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -0,0 +1,328 @@
+/*
+ * Cell Broadband Engine Performance Monitor
+ *
+ * (C) Copyright IBM Corporation 2001,2006
+ *
+ * Author:
+ *    David Erb (djerb@us.ibm.com)
+ *    Kevin Corry (kevcorry@us.ibm.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/types.h>
+#include <asm/io.h>
+#include <asm/machdep.h>
+#include <asm/reg.h>
+#include <asm/spu.h>
+
+#include "cbe_regs.h"
+#include "interrupt.h"
+#include "pmu.h"
+
+/*
+ * When writing to write-only mmio addresses, save a shadow copy. All of the
+ * registers are 32-bit, but stored in the upper-half of a 64-bit field in
+ * pmd_regs.
+ */
+
+#define WRITE_WO_MMIO(reg, x)					\
+	do {							\
+		u32 _x = (x);					\
+		struct cbe_pmd_regs __iomem *pmd_regs;		\
+		struct cbe_pmd_shadow_regs *shadow_regs;	\
+		pmd_regs = cbe_get_cpu_pmd_regs(cpu);		\
+		shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);	\
+		out_be64(&(pmd_regs->reg), (((u64)_x) << 32));	\
+		shadow_regs->reg = _x;				\
+	} while (0)
+
+#define READ_SHADOW_REG(val, reg)				\
+	do {							\
+		struct cbe_pmd_shadow_regs *shadow_regs;	\
+		shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);	\
+		(val) = shadow_regs->reg;			\
+	} while (0)
+
+#define READ_MMIO_UPPER32(val, reg)				\
+	do {							\
+		struct cbe_pmd_regs __iomem *pmd_regs;		\
+		pmd_regs = cbe_get_cpu_pmd_regs(cpu);		\
+		(val) = (u32)(in_be64(&pmd_regs->reg) >> 32);	\
+	} while (0)
+
+/*
+ * Physical counter registers.
+ * Each physical counter can act as one 32-bit counter or two 16-bit counters.
+ */
+
+u32 cbe_read_phys_ctr(u32 cpu, u32 phys_ctr)
+{
+	u32 val_in_latch, val = 0;
+
+	if (phys_ctr < NR_PHYS_CTRS) {
+		READ_SHADOW_REG(val_in_latch, counter_value_in_latch);
+
+		/* Read the latch or the actual counter, whichever is newer. */
+		if (val_in_latch & (1 << phys_ctr)) {
+			READ_SHADOW_REG(val, pm_ctr[phys_ctr]);
+		} else {
+			READ_MMIO_UPPER32(val, pm_ctr[phys_ctr]);
+		}
+	}
+
+	return val;
+}
+
+void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val)
+{
+	struct cbe_pmd_shadow_regs *shadow_regs;
+	u32 pm_ctrl;
+
+	if (phys_ctr < NR_PHYS_CTRS) {
+		/* Writing to a counter only writes to a hardware latch.
+		 * The new value is not propagated to the actual counter
+		 * until the performance monitor is enabled.
+		 */
+		WRITE_WO_MMIO(pm_ctr[phys_ctr], val);
+
+		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		if (pm_ctrl & CBE_PM_ENABLE_PERF_MON) {
+			/* The counters are already active, so we need to
+			 * rewrite the pm_control register to "re-enable"
+			 * the PMU.
+			 */
+			cbe_write_pm(cpu, pm_control, pm_ctrl);
+		} else {
+			shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);
+			shadow_regs->counter_value_in_latch |= (1 << phys_ctr);
+		}
+	}
+}
+
+/*
+ * "Logical" counter registers.
+ * These will read/write 16-bits or 32-bits depending on the
+ * current size of the counter. Counters 4 - 7 are always 16-bit.
+ */
+
+u32 cbe_read_ctr(u32 cpu, u32 ctr)
+{
+	u32 val;
+	u32 phys_ctr = ctr & (NR_PHYS_CTRS - 1);
+
+	val = cbe_read_phys_ctr(cpu, phys_ctr);
+
+	if (cbe_get_ctr_size(cpu, phys_ctr) == 16)
+		val = (ctr < NR_PHYS_CTRS) ? (val >> 16) : (val & 0xffff);
+
+	return val;
+}
+
+void cbe_write_ctr(u32 cpu, u32 ctr, u32 val)
+{
+	u32 phys_ctr;
+	u32 phys_val;
+
+	phys_ctr = ctr & (NR_PHYS_CTRS - 1);
+
+	if (cbe_get_ctr_size(cpu, phys_ctr) == 16) {
+		phys_val = cbe_read_phys_ctr(cpu, phys_ctr);
+
+		if (ctr < NR_PHYS_CTRS)
+			val = (val << 16) | (phys_val & 0xffff);
+		else
+			val = (val & 0xffff) | (phys_val & 0xffff0000);
+	}
+
+	cbe_write_phys_ctr(cpu, phys_ctr, val);
+}
+
+/*
+ * Counter-control registers.
+ * Each "logical" counter has a corresponding control register.
+ */
+
+u32 cbe_read_pm07_control(u32 cpu, u32 ctr)
+{
+	u32 pm07_control = 0;
+
+	if (ctr < NR_CTRS)
+		READ_SHADOW_REG(pm07_control, pm07_control[ctr]);
+
+	return pm07_control;
+}
+
+void cbe_write_pm07_control(u32 cpu, u32 ctr, u32 val)
+{
+	if (ctr < NR_CTRS)
+		WRITE_WO_MMIO(pm07_control[ctr], val);
+}
+
+/*
+ * Other PMU control registers. Most of these are write-only.
+ */
+
+u32 cbe_read_pm(u32 cpu, enum pm_reg_name reg)
+{
+	u32 val = 0;
+
+	switch (reg) {
+	case group_control:
+		READ_SHADOW_REG(val, group_control);
+		break;
+
+	case debug_bus_control:
+		READ_SHADOW_REG(val, debug_bus_control);
+		break;
+
+	case trace_address:
+		READ_MMIO_UPPER32(val, trace_address);
+		break;
+
+	case ext_tr_timer:
+		READ_SHADOW_REG(val, ext_tr_timer);
+		break;
+
+	case pm_status:
+		READ_MMIO_UPPER32(val, pm_status);
+		break;
+
+	case pm_control:
+		READ_SHADOW_REG(val, pm_control);
+		break;
+
+	case pm_interval:
+		READ_SHADOW_REG(val, pm_interval);
+		break;
+
+	case pm_start_stop:
+		READ_SHADOW_REG(val, pm_start_stop);
+		break;
+	}
+
+	return val;
+}
+
+void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val)
+{
+	switch (reg) {
+	case group_control:
+		WRITE_WO_MMIO(group_control, val);
+		break;
+
+	case debug_bus_control:
+		WRITE_WO_MMIO(debug_bus_control, val);
+		break;
+
+	case trace_address:
+		WRITE_WO_MMIO(trace_address, val);
+		break;
+
+	case ext_tr_timer:
+		WRITE_WO_MMIO(ext_tr_timer, val);
+		break;
+
+	case pm_status:
+		WRITE_WO_MMIO(pm_status, val);
+		break;
+
+	case pm_control:
+		WRITE_WO_MMIO(pm_control, val);
+		break;
+
+	case pm_interval:
+		WRITE_WO_MMIO(pm_interval, val);
+		break;
+
+	case pm_start_stop:
+		WRITE_WO_MMIO(pm_start_stop, val);
+		break;
+	}
+}
+
+/*
+ * Get/set the size of a physical counter to either 16 or 32 bits.
+ */
+
+u32 cbe_get_ctr_size(u32 cpu, u32 phys_ctr)
+{
+	u32 pm_ctrl, size = 0;
+
+	if (phys_ctr < NR_PHYS_CTRS) {
+		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		size = (pm_ctrl & CBE_PM_16BIT_CTR(phys_ctr)) ? 16 : 32;
+	}
+
+	return size;
+}
+
+void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size)
+{
+	u32 pm_ctrl;
+
+	if (phys_ctr < NR_PHYS_CTRS) {
+		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		switch (ctr_size) {
+		case 16:
+			pm_ctrl |= CBE_PM_16BIT_CTR(phys_ctr);
+			break;
+
+		case 32:
+			pm_ctrl &= ~CBE_PM_16BIT_CTR(phys_ctr);
+			break;
+		}
+		cbe_write_pm(cpu, pm_control, pm_ctrl);
+	}
+}
+
+/*
+ * Enable/disable the entire performance monitoring unit.
+ * When we enable the PMU, all pending writes to counters get committed.
+ */
+
+void cbe_enable_pm(u32 cpu)
+{
+	struct cbe_pmd_shadow_regs *shadow_regs;
+	u32 pm_ctrl;
+
+	shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);
+	shadow_regs->counter_value_in_latch = 0;
+
+	pm_ctrl = cbe_read_pm(cpu, pm_control) | CBE_PM_ENABLE_PERF_MON;
+	cbe_write_pm(cpu, pm_control, pm_ctrl);
+}
+
+void cbe_disable_pm(u32 cpu)
+{
+	u32 pm_ctrl;
+	pm_ctrl = cbe_read_pm(cpu, pm_control) & ~CBE_PM_ENABLE_PERF_MON;
+	cbe_write_pm(cpu, pm_control, pm_ctrl);
+}
+
+/*
+ * Reading from the trace_buffer.
+ * The trace buffer is two 64-bit registers. Reading from
+ * the second half automatically increments the trace_address.
+ */
+
+void cbe_read_trace_buffer(u32 cpu, u64 *buf)
+{
+	struct cbe_pmd_regs __iomem *pmd_regs = cbe_get_cpu_pmd_regs(cpu);
+
+	*buf++ = in_be64(&pmd_regs->trace_buffer_0_63);
+	*buf++ = in_be64(&pmd_regs->trace_buffer_64_127);
+}
+
