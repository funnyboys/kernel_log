commit 65fddcfca8ad14778f71a57672fd01e8112d30fa
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:42 2020 -0700

    mm: reorder includes after introduction of linux/pgtable.h
    
    The replacement of <asm/pgrable.h> with <linux/pgtable.h> made the include
    of the latter in the middle of asm includes.  Fix this up with the aid of
    the below script and manual adjustments here and there.
    
            import sys
            import re
    
            if len(sys.argv) is not 3:
                print "USAGE: %s <file> <header>" % (sys.argv[0])
                sys.exit(1)
    
            hdr_to_move="#include <linux/%s>" % sys.argv[2]
            moved = False
            in_hdrs = False
    
            with open(sys.argv[1], "r") as f:
                lines = f.readlines()
                for _line in lines:
                    line = _line.rstrip('
    ')
                    if line == hdr_to_move:
                        continue
                    if line.startswith("#include <linux/"):
                        in_hdrs = True
                    elif not moved and in_hdrs:
                        moved = True
                        print hdr_to_move
                    print line
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-4-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 13d8a1b087ab..9068edef71f7 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -15,11 +15,11 @@
 #include <linux/percpu.h>
 #include <linux/types.h>
 #include <linux/kallsyms.h>
+#include <linux/pgtable.h>
 
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/prom.h>
-#include <linux/pgtable.h>
 #include <asm/reg.h>
 #include <asm/cell-regs.h>
 #include <asm/cpu_has_feature.h>

commit ca5999fde0a1761665a38e4c9a72dbcd7d190a81
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:38 2020 -0700

    mm: introduce include/linux/pgtable.h
    
    The include/linux/pgtable.h is going to be the home of generic page table
    manipulation functions.
    
    Start with moving asm-generic/pgtable.h to include/linux/pgtable.h and
    make the latter include asm/pgtable.h.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 6af3a6e600a7..13d8a1b087ab 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -19,7 +19,7 @@
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/prom.h>
-#include <asm/pgtable.h>
+#include <linux/pgtable.h>
 #include <asm/reg.h>
 #include <asm/cell-regs.h>
 #include <asm/cpu_has_feature.h>

commit de6cc6515a445d5d81cad2dee899a0be1a6317f8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:02 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 153
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 or at your option any
      later version this program is distributed in the hope that it will
      be useful but without any warranty without even the implied warranty
      of merchantability or fitness for a particular purpose see the gnu
      general public license for more details you should have received a
      copy of the gnu general public license along with this program if
      not write to the free software foundation inc 675 mass ave cambridge
      ma 02139 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 77 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.837555891@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index a88944db9fc3..6af3a6e600a7 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * CBE Pervasive Monitor and Debug
  *
@@ -5,20 +6,6 @@
  *
  * Authors: Maximino Aguilar (maguilar@us.ibm.com)
  *          Michael N. Day (mnday@us.ibm.com)
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2, or (at your option)
- * any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 
 #undef DEBUG

commit 6e83985b0f6e30b928eee26eb41d276814a698aa
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Mon Mar 20 16:31:49 2017 +1000

    powerpc/cbe: Do not process external or decremeter interrupts from sreset
    
    Cell will wake from low power state at the system reset interrupt,
    with the event encoded in SRR1, rather than waking at the interrupt
    vector that corresponds to that event.
    
    The system reset handler for this platform decodes SRR1 event reason
    and calls the interrupt handler to process it directly from the system
    reset handlre.
    
    A subsequent change will treat the system reset interrupt as a Linux NMI
    with its own per-CPU stack, and this will no longer work. Remove the
    external and decrementer handlers from the system reset handler.
    
    - The external exception remains raised and will fire again at the
      EE interrupt vector when system reset returns.
    
    - The decrementer is set to 1 so it will be raised again and fire when
      the system reset returns.
    
    It is possible to branch to an idle handler from the system reset
    interrupt (like POWER does), then restore a normal stack and restore
    this optimisation. But simplicity wins for now.
    
    Tested-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index e7d075077cb0..a88944db9fc3 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -88,11 +88,14 @@ static void cbe_power_save(void)
 static int cbe_system_reset_exception(struct pt_regs *regs)
 {
 	switch (regs->msr & SRR1_WAKEMASK) {
-	case SRR1_WAKEEE:
-		do_IRQ(regs);
-		break;
 	case SRR1_WAKEDEC:
-		timer_interrupt(regs);
+		set_dec(1);
+	case SRR1_WAKEEE:
+		/*
+		 * Handle these when interrupts get re-enabled and we take
+		 * them as regular exceptions. We are in an NMI context
+		 * and can't handle these here.
+		 */
 		break;
 	case SRR1_WAKEMT:
 		return cbe_sysreset_hack();

commit b92a226e528423b8d249dd09bb450d53361fbfcb
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sat Jul 23 14:42:40 2016 +0530

    powerpc: Move cpu_has_feature() to a separate file
    
    We plan to use jump label for cpu_has_feature(). In order to implement
    this we need to include the linux/jump_label.h in asm/cputable.h.
    
    Unfortunately if we do that it leads to an include loop. The root of the
    problem seems to be that reg.h needs cputable.h (for CPU_FTRs), and then
    cputable.h via jump_label.h eventually pulls in hw_irq.h which needs
    reg.h (for MSR_EE).
    
    So move cpu_has_feature() to a separate file on its own.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    [mpe: Rename to cpu_has_feature.h and flesh out change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index d17e98bc0c10..e7d075077cb0 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -35,6 +35,7 @@
 #include <asm/pgtable.h>
 #include <asm/reg.h>
 #include <asm/cell-regs.h>
+#include <asm/cpu_has_feature.h>
 
 #include "pervasive.h"
 

commit be2cf20a5ad31ebb13562c1c866ecc626fbd721e
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 10 18:36:40 2012 +1000

    powerpc: More fixes for lazy IRQ vs. idle
    
    Looks like we still have issues with pSeries and Cell idle code
    vs. the lazy irq state. In fact, the reset fixes that went upstream
    are exposing the problem more by causing BUG_ON() to trigger (which
    this patch turns into a WARN_ON instead).
    
    We need to be careful when using a variant of low power state that
    has the side effect of turning interrupts back on, to properly set
    all the SW & lazy state to look as if everything is enabled before
    we enter the low power state with MSR:EE off as we will return with
    MSR:EE on. If not, we have a discrepancy of state which can cause
    things to go very wrong later on.
    
    This patch moves the logic into a helper and uses it from the
    pseries and cell idle code. The power4/970 idle code already got
    things right (in assembly even !) so I'm not touching it. The power7
    "bare metal" idle code is subtly different and correct. Remains PA6T
    and some hypervisor based Cell platforms which have questionable
    code in there, but they are mostly dead platforms so I'll fix them
    when I manage to get final answers from the respective maintainers
    about how the low power state actually works on them.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: stable@vger.kernel.org [v3.4]

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index efdacc829576..d17e98bc0c10 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -42,11 +42,9 @@ static void cbe_power_save(void)
 {
 	unsigned long ctrl, thread_switch_control;
 
-	/*
-	 * We need to hard disable interrupts, the local_irq_enable() done by
-	 * our caller upon return will hard re-enable.
-	 */
-	hard_irq_disable();
+	/* Ensure our interrupt state is properly tracked */
+	if (!prep_irq_for_idle())
+		return;
 
 	ctrl = mfspr(SPRN_CTRLF);
 
@@ -81,6 +79,9 @@ static void cbe_power_save(void)
 	 */
 	ctrl &= ~(CTRL_RUNLATCH | CTRL_TE);
 	mtspr(SPRN_CTRLT, ctrl);
+
+	/* Re-enable interrupts in MSR */
+	__hard_irq_enable();
 }
 
 static int cbe_system_reset_exception(struct pt_regs *regs)

commit 70694a8bab22bd0cc98ff4ee5cc75fe9be30fcd0
Author: Christian Krafft <krafft@de.ibm.com>
Date:   Wed Jul 16 05:51:44 2008 +1000

    powerpc/cell: Cleanup sysreset_hack for IBM cell blades
    
    This patch adds a config option for the sysreset_hack used for
    IBM Cell blades. The code is moves from pervasive.c into ras.c and
    gets it's own init method.
    
    Signed-off-by: Christian Krafft <krafft@de.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 8a3631ce912b..efdacc829576 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -38,8 +38,6 @@
 
 #include "pervasive.h"
 
-static int sysreset_hack;
-
 static void cbe_power_save(void)
 {
 	unsigned long ctrl, thread_switch_control;
@@ -87,9 +85,6 @@ static void cbe_power_save(void)
 
 static int cbe_system_reset_exception(struct pt_regs *regs)
 {
-	int cpu;
-	struct cbe_pmd_regs __iomem *pmd;
-
 	switch (regs->msr & SRR1_WAKEMASK) {
 	case SRR1_WAKEEE:
 		do_IRQ(regs);
@@ -98,19 +93,7 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 		timer_interrupt(regs);
 		break;
 	case SRR1_WAKEMT:
-		/*
-		 * The BMC can inject user triggered system reset exceptions,
-		 * but cannot set the system reset reason in srr1,
-		 * so check an extra register here.
-		 */
-		if (sysreset_hack && (cpu = smp_processor_id()) == 0) {
-			pmd = cbe_get_cpu_pmd_regs(cpu);
-			if (in_be64(&pmd->ras_esc_0) & 0xffff) {
-				out_be64(&pmd->ras_esc_0, 0);
-				return 0;
-			}
-		}
-		break;
+		return cbe_sysreset_hack();
 #ifdef CONFIG_CBE_RAS
 	case SRR1_WAKESYSERR:
 		cbe_system_error_exception(regs);
@@ -134,8 +117,6 @@ void __init cbe_pervasive_init(void)
 	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
 		return;
 
-	sysreset_hack = machine_is_compatible("IBM,CBPLUS-1.0");
-
 	for_each_possible_cpu(cpu) {
 		struct cbe_pmd_regs __iomem *regs = cbe_get_cpu_pmd_regs(cpu);
 		if (!regs)
@@ -144,12 +125,6 @@ void __init cbe_pervasive_init(void)
 		 /* Enable Pause(0) control bit */
 		out_be64(&regs->pmcr, in_be64(&regs->pmcr) |
 					    CBE_PMD_PAUSE_ZERO_CONTROL);
-
-		/* Enable JTAG system-reset hack */
-		if (sysreset_hack)
-			out_be32(&regs->fir_mode_reg,
-				in_be32(&regs->fir_mode_reg) |
-				CBE_PMD_FIR_MODE_M8);
 	}
 
 	ppc_md.power_save = cbe_power_save;

commit e48b1b452ff630288c930fd8e0c2d808bc15f7ad
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Sat Mar 29 08:21:07 2008 +1100

    [POWERPC] Replace remaining __FUNCTION__ occurrences
    
    __FUNCTION__ is gcc-specific, use __func__
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 0304589c0a80..8a3631ce912b 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -65,7 +65,7 @@ static void cbe_power_save(void)
 		break;
 	default:
 		printk(KERN_WARNING "%s: unknown configuration\n",
-			__FUNCTION__);
+			__func__);
 		break;
 	}
 	mtspr(SPRN_TSC_CELL, thread_switch_control);

commit eef686a0095430bdd6c1942f86dd2b543e66679f
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Oct 4 15:40:42 2007 +1000

    [POWERPC] cell: Move cbe_regs.h to include/asm-powerpc/cell-regs.h
    
    The new Cell EDAC driver needs that file, oprofile also does ugly
    path tricks to get to it, it's time to move it to asm-powerpc. While
    at it, rename it to be consistent with cell-pmu.h (and dashes look
    nicer than underscores anyway).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 4ede22d363fa..0304589c0a80 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -34,9 +34,9 @@
 #include <asm/prom.h>
 #include <asm/pgtable.h>
 #include <asm/reg.h>
+#include <asm/cell-regs.h>
 
 #include "pervasive.h"
-#include "cbe_regs.h"
 
 static int sysreset_hack;
 

commit 3addf55c9415f9da039947b33d064332137e49fe
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Aug 23 03:01:26 2007 +1000

    [POWERPC] cell: Support pinhole-reset on IBM cell blades
    
    The Cell Broadband Engine has a method of injecting a
    system-reset-exception from an external source into the
    operating system, which should trigger the regular behaviour
    of entering xmon or kdump.
    
    Unfortunately, the exception handler cannot distinguish it from
    other interrupt causes by the SRR1 register, which gets used
    for this on Power 6 and others.
    
    IBM Blade servers that want to support triggering the
    system reset exception using a pinhole button in the front
    panel therefore use an extra register to determine the
    reset cause.
    
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    
    --
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 812bf563ed65..4ede22d363fa 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -38,6 +38,8 @@
 #include "pervasive.h"
 #include "cbe_regs.h"
 
+static int sysreset_hack;
+
 static void cbe_power_save(void)
 {
 	unsigned long ctrl, thread_switch_control;
@@ -85,6 +87,9 @@ static void cbe_power_save(void)
 
 static int cbe_system_reset_exception(struct pt_regs *regs)
 {
+	int cpu;
+	struct cbe_pmd_regs __iomem *pmd;
+
 	switch (regs->msr & SRR1_WAKEMASK) {
 	case SRR1_WAKEEE:
 		do_IRQ(regs);
@@ -93,6 +98,18 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 		timer_interrupt(regs);
 		break;
 	case SRR1_WAKEMT:
+		/*
+		 * The BMC can inject user triggered system reset exceptions,
+		 * but cannot set the system reset reason in srr1,
+		 * so check an extra register here.
+		 */
+		if (sysreset_hack && (cpu = smp_processor_id()) == 0) {
+			pmd = cbe_get_cpu_pmd_regs(cpu);
+			if (in_be64(&pmd->ras_esc_0) & 0xffff) {
+				out_be64(&pmd->ras_esc_0, 0);
+				return 0;
+			}
+		}
 		break;
 #ifdef CONFIG_CBE_RAS
 	case SRR1_WAKESYSERR:
@@ -113,9 +130,12 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 void __init cbe_pervasive_init(void)
 {
 	int cpu;
+
 	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
 		return;
 
+	sysreset_hack = machine_is_compatible("IBM,CBPLUS-1.0");
+
 	for_each_possible_cpu(cpu) {
 		struct cbe_pmd_regs __iomem *regs = cbe_get_cpu_pmd_regs(cpu);
 		if (!regs)
@@ -124,6 +144,12 @@ void __init cbe_pervasive_init(void)
 		 /* Enable Pause(0) control bit */
 		out_be64(&regs->pmcr, in_be64(&regs->pmcr) |
 					    CBE_PMD_PAUSE_ZERO_CONTROL);
+
+		/* Enable JTAG system-reset hack */
+		if (sysreset_hack)
+			out_be32(&regs->fir_mode_reg,
+				in_be32(&regs->fir_mode_reg) |
+				CBE_PMD_FIR_MODE_M8);
 	}
 
 	ppc_md.power_save = cbe_power_save;

commit e1fa2e136ff64a3814a98c03d46320b9e80d29c8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu May 10 22:22:45 2007 -0700

    powerpc: fixup hard_irq_disable semantics
    
    This patch renames the raw hard_irq_{enable,disable} into
    __hard_irq_{enable,disable} and introduces a higher level hard_irq_disable()
    function that can be used by any code to enforce that IRQs are fully disabled,
    not only lazy disabled.
    
    The difference with the __ versions is that it will update some per-processor
    fields so that the kernel keeps track and properly re-enables them in the next
    local_irq_disable();
    
    This prepares powerpc for my next patch that introduces hard_irq_disable()
    generically.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 8c20f0fb8651..812bf563ed65 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -43,12 +43,10 @@ static void cbe_power_save(void)
 	unsigned long ctrl, thread_switch_control;
 
 	/*
-	 * We need to hard disable interrupts, but we also need to mark them
-	 * hard disabled in the PACA so that the local_irq_enable() done by
-	 * our caller upon return propertly hard enables.
+	 * We need to hard disable interrupts, the local_irq_enable() done by
+	 * our caller upon return will hard re-enable.
 	 */
 	hard_irq_disable();
-	get_paca()->hard_enabled = 0;
 
 	ctrl = mfspr(SPRN_CTRLF);
 

commit 5850dd8f6d4e79484d498c0d77b223d1041f9954
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Nov 23 00:46:38 2006 +0100

    [POWERPC] cell: hard disable interrupts in power_save()
    
    With soft-disabled interrupts in power_save, we can
    still get external exceptions on Cell, even if we are
    in pause(0) a.k.a. sleep state.
    
    When the CPU really wakes up through the 0x100 (system reset)
    vector, while we have already started processing the 0x500
    (external) exception, we get a panic in unrecoverable_exception()
    because of the lost state.
    
    This occurred in Systemsim for Cell, but as far as I can see,
    it can theoretically occur on any machine that uses the
    system reset exception to get out of sleep state.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index c68fabdc7874..8c20f0fb8651 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -41,6 +41,15 @@
 static void cbe_power_save(void)
 {
 	unsigned long ctrl, thread_switch_control;
+
+	/*
+	 * We need to hard disable interrupts, but we also need to mark them
+	 * hard disabled in the PACA so that the local_irq_enable() done by
+	 * our caller upon return propertly hard enables.
+	 */
+	hard_irq_disable();
+	get_paca()->hard_enabled = 0;
+
 	ctrl = mfspr(SPRN_CTRLF);
 
 	/* Enable DEC and EE interrupt request */

commit 302eca184fb844670fb128c69e22a8a28bbce48a
Author: arnd@arndb.de <arnd@arndb.de>
Date:   Tue Oct 24 18:31:26 2006 +0200

    [POWERPC] cell: use ppc_md->power_save instead of cbe_idle_loop
    
    This moves the cell idle function to use the default cpu_idle
    with a special power_save callback, like all other platforms
    except iSeries already do.
    
    It also makes it possible to disable this power_save function
    with a new powerpc-specific boot option "powersave=off".
    
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index fdcd89e99f1b..c68fabdc7874 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -38,32 +38,16 @@
 #include "pervasive.h"
 #include "cbe_regs.h"
 
-static DEFINE_SPINLOCK(cbe_pervasive_lock);
-
-static void __init cbe_enable_pause_zero(void)
+static void cbe_power_save(void)
 {
-	unsigned long thread_switch_control;
-	unsigned long temp_register;
-	struct cbe_pmd_regs __iomem *pregs;
-
-	spin_lock_irq(&cbe_pervasive_lock);
-	pregs = cbe_get_cpu_pmd_regs(smp_processor_id());
-	if (pregs == NULL)
-		goto out;
-
-	pr_debug("Power Management: CPU %d\n", smp_processor_id());
-
-	 /* Enable Pause(0) control bit */
-	temp_register = in_be64(&pregs->pmcr);
-
-	out_be64(&pregs->pmcr,
-		 temp_register | CBE_PMD_PAUSE_ZERO_CONTROL);
+	unsigned long ctrl, thread_switch_control;
+	ctrl = mfspr(SPRN_CTRLF);
 
 	/* Enable DEC and EE interrupt request */
 	thread_switch_control  = mfspr(SPRN_TSC_CELL);
 	thread_switch_control |= TSC_CELL_EE_ENABLE | TSC_CELL_EE_BOOST;
 
-	switch ((mfspr(SPRN_CTRLF) & CTRL_CT)) {
+	switch (ctrl & CTRL_CT) {
 	case CTRL_CT0:
 		thread_switch_control |= TSC_CELL_DEC_ENABLE_0;
 		break;
@@ -75,58 +59,21 @@ static void __init cbe_enable_pause_zero(void)
 			__FUNCTION__);
 		break;
 	}
-
 	mtspr(SPRN_TSC_CELL, thread_switch_control);
 
-out:
-	spin_unlock_irq(&cbe_pervasive_lock);
-}
-
-static void cbe_idle(void)
-{
-	unsigned long ctrl;
-
-	/* Why do we do that on every idle ? Couldn't that be done once for
-	 * all or do we lose the state some way ? Also, the pmcr
-	 * register setting, that can't be set once at boot ? We really want
-	 * to move that away in order to implement a simple powersave
+	/*
+	 * go into low thread priority, medium priority will be
+	 * restored for us after wake-up.
 	 */
-	cbe_enable_pause_zero();
-
-	while (1) {
-		if (!need_resched()) {
-			local_irq_disable();
-			while (!need_resched()) {
-				/* go into low thread priority */
-				HMT_low();
-
-				/*
-				 * atomically disable thread execution
-				 * and runlatch.
-				 * External and Decrementer exceptions
-				 * are still handled when the thread
-				 * is disabled but now enter in
-				 * cbe_system_reset_exception()
-				 */
-				ctrl = mfspr(SPRN_CTRLF);
-				ctrl &= ~(CTRL_RUNLATCH | CTRL_TE);
-				mtspr(SPRN_CTRLT, ctrl);
-			}
-			/* restore thread prio */
-			HMT_medium();
-			local_irq_enable();
-		}
+	HMT_low();
 
-		/*
-		 * turn runlatch on again before scheduling the
-		 * process we just woke up
-		 */
-		ppc64_runlatch_on();
-
-		preempt_enable_no_resched();
-		schedule();
-		preempt_disable();
-	}
+	/*
+	 * atomically disable thread execution and runlatch.
+	 * External and Decrementer exceptions are still handled when the
+	 * thread is disabled but now enter in cbe_system_reset_exception()
+	 */
+	ctrl &= ~(CTRL_RUNLATCH | CTRL_TE);
+	mtspr(SPRN_CTRLT, ctrl);
 }
 
 static int cbe_system_reset_exception(struct pt_regs *regs)
@@ -158,9 +105,20 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 
 void __init cbe_pervasive_init(void)
 {
+	int cpu;
 	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
 		return;
 
-	ppc_md.idle_loop = cbe_idle;
+	for_each_possible_cpu(cpu) {
+		struct cbe_pmd_regs __iomem *regs = cbe_get_cpu_pmd_regs(cpu);
+		if (!regs)
+			continue;
+
+		 /* Enable Pause(0) control bit */
+		out_be64(&regs->pmcr, in_be64(&regs->pmcr) |
+					    CBE_PMD_PAUSE_ZERO_CONTROL);
+	}
+
+	ppc_md.power_save = cbe_power_save;
 	ppc_md.system_reset_exception = cbe_system_reset_exception;
 }

commit 22b8c9f5baeb440a716ea760ff05290221565b4c
Author: David Erb <djerb@us.ibm.com>
Date:   Tue Oct 24 18:31:20 2006 +0200

    [POWERPC] cell: update Cell BE register definitions
    
    There are a few definitions that are required by subsequent patches,
    so add them here.
    
    The original patch is from David Erb, but is significantly cleaned
    up by Kevon Corry.
    
    Cc: Kevin Corry <kevcorry@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 9f2e4ed20a57..fdcd89e99f1b 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -54,9 +54,9 @@ static void __init cbe_enable_pause_zero(void)
 	pr_debug("Power Management: CPU %d\n", smp_processor_id());
 
 	 /* Enable Pause(0) control bit */
-	temp_register = in_be64(&pregs->pm_control);
+	temp_register = in_be64(&pregs->pmcr);
 
-	out_be64(&pregs->pm_control,
+	out_be64(&pregs->pmcr,
 		 temp_register | CBE_PMD_PAUSE_ZERO_CONTROL);
 
 	/* Enable DEC and EE interrupt request */
@@ -87,7 +87,7 @@ static void cbe_idle(void)
 	unsigned long ctrl;
 
 	/* Why do we do that on every idle ? Couldn't that be done once for
-	 * all or do we lose the state some way ? Also, the pm_control
+	 * all or do we lose the state some way ? Also, the pmcr
 	 * register setting, that can't be set once at boot ? We really want
 	 * to move that away in order to implement a simple powersave
 	 */

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 695ac4e1617e..9f2e4ed20a57 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -23,7 +23,6 @@
 
 #undef DEBUG
 
-#include <linux/config.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>
 #include <linux/percpu.h>

commit acf7d76827a577059636e949079021e6af6dd702
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jun 19 20:33:16 2006 +0200

    [POWERPC] cell: add RAS support
    
    This is a first version of support for the Cell BE "Reliability,
    Availability and Serviceability" features.
    
    It doesn't yet handle some of the RAS interrupts (the ones described in
    iic_is/iic_irr), I'm still working on a proper way to expose these. They
    are essentially a cascaded controller by themselves (sic !) though I may
    just handle them locally to the iic driver. I need also to sync with
    David Erb on the way he hooked in the performance monitor interrupt.
    
    So that's all for 2.6.17 and I'll do more work on that with my rework of
    the powerpc interrupt layer that I'm hacking on at the moment.
    
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 7eed8c624517..695ac4e1617e 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -37,36 +37,28 @@
 #include <asm/reg.h>
 
 #include "pervasive.h"
+#include "cbe_regs.h"
 
 static DEFINE_SPINLOCK(cbe_pervasive_lock);
-struct cbe_pervasive {
-	struct pmd_regs __iomem *regs;
-	unsigned int thread;
-};
-
-/* can't use per_cpu from setup_arch */
-static struct cbe_pervasive cbe_pervasive[NR_CPUS];
 
 static void __init cbe_enable_pause_zero(void)
 {
 	unsigned long thread_switch_control;
 	unsigned long temp_register;
-	struct cbe_pervasive *p;
-	int thread;
+	struct cbe_pmd_regs __iomem *pregs;
 
 	spin_lock_irq(&cbe_pervasive_lock);
-	p = &cbe_pervasive[smp_processor_id()];
-
-	if (!cbe_pervasive->regs)
+	pregs = cbe_get_cpu_pmd_regs(smp_processor_id());
+	if (pregs == NULL)
 		goto out;
 
 	pr_debug("Power Management: CPU %d\n", smp_processor_id());
 
 	 /* Enable Pause(0) control bit */
-	temp_register = in_be64(&p->regs->pm_control);
+	temp_register = in_be64(&pregs->pm_control);
 
-	out_be64(&p->regs->pm_control,
-		 temp_register|PMD_PAUSE_ZERO_CONTROL);
+	out_be64(&pregs->pm_control,
+		 temp_register | CBE_PMD_PAUSE_ZERO_CONTROL);
 
 	/* Enable DEC and EE interrupt request */
 	thread_switch_control  = mfspr(SPRN_TSC_CELL);
@@ -75,25 +67,16 @@ static void __init cbe_enable_pause_zero(void)
 	switch ((mfspr(SPRN_CTRLF) & CTRL_CT)) {
 	case CTRL_CT0:
 		thread_switch_control |= TSC_CELL_DEC_ENABLE_0;
-		thread = 0;
 		break;
 	case CTRL_CT1:
 		thread_switch_control |= TSC_CELL_DEC_ENABLE_1;
-		thread = 1;
 		break;
 	default:
 		printk(KERN_WARNING "%s: unknown configuration\n",
 			__FUNCTION__);
-		thread = -1;
 		break;
 	}
 
-	if (p->thread != thread)
-		printk(KERN_WARNING "%s: device tree inconsistant, "
-				     "cpu %i: %d/%d\n", __FUNCTION__,
-				     smp_processor_id(),
-				     p->thread, thread);
-
 	mtspr(SPRN_TSC_CELL, thread_switch_control);
 
 out:
@@ -104,6 +87,11 @@ static void cbe_idle(void)
 {
 	unsigned long ctrl;
 
+	/* Why do we do that on every idle ? Couldn't that be done once for
+	 * all or do we lose the state some way ? Also, the pm_control
+	 * register setting, that can't be set once at boot ? We really want
+	 * to move that away in order to implement a simple powersave
+	 */
 	cbe_enable_pause_zero();
 
 	while (1) {
@@ -152,8 +140,15 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 		timer_interrupt(regs);
 		break;
 	case SRR1_WAKEMT:
-		/* no action required */
 		break;
+#ifdef CONFIG_CBE_RAS
+	case SRR1_WAKESYSERR:
+		cbe_system_error_exception(regs);
+		break;
+	case SRR1_WAKETHERM:
+		cbe_thermal_exception(regs);
+		break;
+#endif /* CONFIG_CBE_RAS */
 	default:
 		/* do system reset */
 		return 0;
@@ -162,68 +157,11 @@ static int cbe_system_reset_exception(struct pt_regs *regs)
 	return 1;
 }
 
-static int __init cbe_find_pmd_mmio(int cpu, struct cbe_pervasive *p)
-{
-	struct device_node *node;
-	unsigned int *int_servers;
-	char *addr;
-	unsigned long real_address;
-	unsigned int size;
-
-	struct pmd_regs __iomem *pmd_mmio_area;
-	int hardid, thread;
-	int proplen;
-
-	pmd_mmio_area = NULL;
-	hardid = get_hard_smp_processor_id(cpu);
-	for (node = NULL; (node = of_find_node_by_type(node, "cpu"));) {
-		int_servers = (void *) get_property(node,
-				"ibm,ppc-interrupt-server#s", &proplen);
-		if (!int_servers) {
-			printk(KERN_WARNING "%s misses "
-				"ibm,ppc-interrupt-server#s property",
-				node->full_name);
-			continue;
-		}
-		for (thread = 0; thread < proplen / sizeof (int); thread++) {
-			if (hardid == int_servers[thread]) {
-				addr = get_property(node, "pervasive", NULL);
-				goto found;
-			}
-		}
-	}
-
-	printk(KERN_WARNING "%s: CPU %d not found\n", __FUNCTION__, cpu);
-	return -EINVAL;
-
-found:
-	real_address = *(unsigned long*) addr;
-	addr += sizeof (unsigned long);
-	size = *(unsigned int*) addr;
-
-	pr_debug("pervasive area for CPU %d at %lx, size %x\n",
-			cpu, real_address, size);
-	p->regs = ioremap(real_address, size);
-	p->thread = thread;
-	return 0;
-}
-
-void __init cell_pervasive_init(void)
+void __init cbe_pervasive_init(void)
 {
-	struct cbe_pervasive *p;
-	int cpu;
-	int ret;
-
 	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
 		return;
 
-	for_each_possible_cpu(cpu) {
-		p = &cbe_pervasive[cpu];
-		ret = cbe_find_pmd_mmio(cpu, p);
-		if (ret)
-			return;
-	}
-
 	ppc_md.idle_loop = cbe_idle;
 	ppc_md.system_reset_exception = cbe_system_reset_exception;
 }

commit 0e5519548fdc8eadc3eacb49b1908d44d347fb2b
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Tue Mar 28 14:50:51 2006 -0800

    [PATCH] for_each_possible_cpu: powerpc
    
    for_each_cpu() actually iterates across all possible CPUs.  We've had mistakes
    in the past where people were using for_each_cpu() where they should have been
    iterating across only online or present CPUs.  This is inefficient and
    possibly buggy.
    
    We're renaming for_each_cpu() to for_each_possible_cpu() to avoid this in the
    future.
    
    This patch replaces for_each_cpu with for_each_possible_cpu.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 58baeb52f6fc..7eed8c624517 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -217,7 +217,7 @@ void __init cell_pervasive_init(void)
 	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
 		return;
 
-	for_each_cpu(cpu) {
+	for_each_possible_cpu(cpu) {
 		p = &cbe_pervasive[cpu];
 		ret = cbe_find_pmd_mmio(cpu, p);
 		if (ret)

commit 47952d5ea67dc7098667a954483a82acf81eb4da
Author: Arnd Bergmann <arnd.bergmann@de.ibm.com>
Date:   Fri Mar 24 19:47:52 2006 +0100

    [PATCH] powerpc: use guarded ioremap for cell on-chip mappings
    
    I'm not sure where the information came from, but I assumed
    that doing cache-inhibited mappings for mmio regions was
    sufficient.
    
    It seems we also need the guarded bit set, like everyone
    else, which is the default for ioremap.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index e0e051c675dd..58baeb52f6fc 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -203,7 +203,7 @@ static int __init cbe_find_pmd_mmio(int cpu, struct cbe_pervasive *p)
 
 	pr_debug("pervasive area for CPU %d at %lx, size %x\n",
 			cpu, real_address, size);
-	p->regs = __ioremap(real_address, size, _PAGE_NO_CACHE);
+	p->regs = ioremap(real_address, size);
 	p->thread = thread;
 	return 0;
 }

commit 8fce10a3c9ee7f9c74d83502fd5156a8ec82c21a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Jan 11 23:07:11 2006 +0000

    [PATCH] powerpc: cell namespace cleanup
    
    These symbols are only used in the file that they are defined in,
    so they should not be in the global namespace.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
index 85152544c153..e0e051c675dd 100644
--- a/arch/powerpc/platforms/cell/pervasive.c
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -142,7 +142,7 @@ static void cbe_idle(void)
 	}
 }
 
-int cbe_system_reset_exception(struct pt_regs *regs)
+static int cbe_system_reset_exception(struct pt_regs *regs)
 {
 	switch (regs->msr & SRR1_WAKEMASK) {
 	case SRR1_WAKEEE:

commit c902be71dc6d5e8473bd021feafc8c3608e2b82a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Jan 4 19:55:53 2006 +0000

    [PATCH] cell: enable pause(0) in cpu_idle
    
    This patch enables support for pause(0) power management state
    for the Cell Broadband Processor, which is import for power efficient
    operation. The pervasive infrastructure will in the future enable
    us to introduce more functionality specific to the Cell's
    pervasive unit.
    
    From: Maximino Aguilar <maguilar@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arndb@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/platforms/cell/pervasive.c b/arch/powerpc/platforms/cell/pervasive.c
new file mode 100644
index 000000000000..85152544c153
--- /dev/null
+++ b/arch/powerpc/platforms/cell/pervasive.c
@@ -0,0 +1,229 @@
+/*
+ * CBE Pervasive Monitor and Debug
+ *
+ * (C) Copyright IBM Corporation 2005
+ *
+ * Authors: Maximino Aguilar (maguilar@us.ibm.com)
+ *          Michael N. Day (mnday@us.ibm.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#undef DEBUG
+
+#include <linux/config.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/percpu.h>
+#include <linux/types.h>
+#include <linux/kallsyms.h>
+
+#include <asm/io.h>
+#include <asm/machdep.h>
+#include <asm/prom.h>
+#include <asm/pgtable.h>
+#include <asm/reg.h>
+
+#include "pervasive.h"
+
+static DEFINE_SPINLOCK(cbe_pervasive_lock);
+struct cbe_pervasive {
+	struct pmd_regs __iomem *regs;
+	unsigned int thread;
+};
+
+/* can't use per_cpu from setup_arch */
+static struct cbe_pervasive cbe_pervasive[NR_CPUS];
+
+static void __init cbe_enable_pause_zero(void)
+{
+	unsigned long thread_switch_control;
+	unsigned long temp_register;
+	struct cbe_pervasive *p;
+	int thread;
+
+	spin_lock_irq(&cbe_pervasive_lock);
+	p = &cbe_pervasive[smp_processor_id()];
+
+	if (!cbe_pervasive->regs)
+		goto out;
+
+	pr_debug("Power Management: CPU %d\n", smp_processor_id());
+
+	 /* Enable Pause(0) control bit */
+	temp_register = in_be64(&p->regs->pm_control);
+
+	out_be64(&p->regs->pm_control,
+		 temp_register|PMD_PAUSE_ZERO_CONTROL);
+
+	/* Enable DEC and EE interrupt request */
+	thread_switch_control  = mfspr(SPRN_TSC_CELL);
+	thread_switch_control |= TSC_CELL_EE_ENABLE | TSC_CELL_EE_BOOST;
+
+	switch ((mfspr(SPRN_CTRLF) & CTRL_CT)) {
+	case CTRL_CT0:
+		thread_switch_control |= TSC_CELL_DEC_ENABLE_0;
+		thread = 0;
+		break;
+	case CTRL_CT1:
+		thread_switch_control |= TSC_CELL_DEC_ENABLE_1;
+		thread = 1;
+		break;
+	default:
+		printk(KERN_WARNING "%s: unknown configuration\n",
+			__FUNCTION__);
+		thread = -1;
+		break;
+	}
+
+	if (p->thread != thread)
+		printk(KERN_WARNING "%s: device tree inconsistant, "
+				     "cpu %i: %d/%d\n", __FUNCTION__,
+				     smp_processor_id(),
+				     p->thread, thread);
+
+	mtspr(SPRN_TSC_CELL, thread_switch_control);
+
+out:
+	spin_unlock_irq(&cbe_pervasive_lock);
+}
+
+static void cbe_idle(void)
+{
+	unsigned long ctrl;
+
+	cbe_enable_pause_zero();
+
+	while (1) {
+		if (!need_resched()) {
+			local_irq_disable();
+			while (!need_resched()) {
+				/* go into low thread priority */
+				HMT_low();
+
+				/*
+				 * atomically disable thread execution
+				 * and runlatch.
+				 * External and Decrementer exceptions
+				 * are still handled when the thread
+				 * is disabled but now enter in
+				 * cbe_system_reset_exception()
+				 */
+				ctrl = mfspr(SPRN_CTRLF);
+				ctrl &= ~(CTRL_RUNLATCH | CTRL_TE);
+				mtspr(SPRN_CTRLT, ctrl);
+			}
+			/* restore thread prio */
+			HMT_medium();
+			local_irq_enable();
+		}
+
+		/*
+		 * turn runlatch on again before scheduling the
+		 * process we just woke up
+		 */
+		ppc64_runlatch_on();
+
+		preempt_enable_no_resched();
+		schedule();
+		preempt_disable();
+	}
+}
+
+int cbe_system_reset_exception(struct pt_regs *regs)
+{
+	switch (regs->msr & SRR1_WAKEMASK) {
+	case SRR1_WAKEEE:
+		do_IRQ(regs);
+		break;
+	case SRR1_WAKEDEC:
+		timer_interrupt(regs);
+		break;
+	case SRR1_WAKEMT:
+		/* no action required */
+		break;
+	default:
+		/* do system reset */
+		return 0;
+	}
+	/* everything handled */
+	return 1;
+}
+
+static int __init cbe_find_pmd_mmio(int cpu, struct cbe_pervasive *p)
+{
+	struct device_node *node;
+	unsigned int *int_servers;
+	char *addr;
+	unsigned long real_address;
+	unsigned int size;
+
+	struct pmd_regs __iomem *pmd_mmio_area;
+	int hardid, thread;
+	int proplen;
+
+	pmd_mmio_area = NULL;
+	hardid = get_hard_smp_processor_id(cpu);
+	for (node = NULL; (node = of_find_node_by_type(node, "cpu"));) {
+		int_servers = (void *) get_property(node,
+				"ibm,ppc-interrupt-server#s", &proplen);
+		if (!int_servers) {
+			printk(KERN_WARNING "%s misses "
+				"ibm,ppc-interrupt-server#s property",
+				node->full_name);
+			continue;
+		}
+		for (thread = 0; thread < proplen / sizeof (int); thread++) {
+			if (hardid == int_servers[thread]) {
+				addr = get_property(node, "pervasive", NULL);
+				goto found;
+			}
+		}
+	}
+
+	printk(KERN_WARNING "%s: CPU %d not found\n", __FUNCTION__, cpu);
+	return -EINVAL;
+
+found:
+	real_address = *(unsigned long*) addr;
+	addr += sizeof (unsigned long);
+	size = *(unsigned int*) addr;
+
+	pr_debug("pervasive area for CPU %d at %lx, size %x\n",
+			cpu, real_address, size);
+	p->regs = __ioremap(real_address, size, _PAGE_NO_CACHE);
+	p->thread = thread;
+	return 0;
+}
+
+void __init cell_pervasive_init(void)
+{
+	struct cbe_pervasive *p;
+	int cpu;
+	int ret;
+
+	if (!cpu_has_feature(CPU_FTR_PAUSE_ZERO))
+		return;
+
+	for_each_cpu(cpu) {
+		p = &cbe_pervasive[cpu];
+		ret = cbe_find_pmd_mmio(cpu, p);
+		if (ret)
+			return;
+	}
+
+	ppc_md.idle_loop = cbe_idle;
+	ppc_md.system_reset_exception = cbe_system_reset_exception;
+}
