commit ed0bc98f8cbe4f8254759d333a47aedc816ff8c5
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Jul 11 12:24:03 2019 +1000

    powerpc/64s: Reimplement power4_idle code in C
    
    This implements the tricky tracing and soft irq handling bits in C,
    leaving the low level bit to asm.
    
    A functional difference is that this redirects the interrupt exit to
    a return stub to execute blr, rather than the lr address itself. This
    is probably barely measurable on real hardware, but it keeps the link
    stack balanced.
    
    Tested with QEMU.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Move power4_fixup_nap back into exceptions-64s.S]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190711022404.18132-1-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index a36fd053c3db..422e31d2f5a2 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -77,6 +77,31 @@ void arch_cpu_idle(void)
 
 int powersave_nap;
 
+#ifdef CONFIG_PPC_970_NAP
+void power4_idle(void)
+{
+	if (!cpu_has_feature(CPU_FTR_CAN_NAP))
+		return;
+
+	if (!powersave_nap)
+		return;
+
+	if (!prep_irq_for_idle())
+		return;
+
+	if (cpu_has_feature(CPU_FTR_ALTIVEC))
+		asm volatile("DSSALL ; sync" ::: "memory");
+
+	power4_idle_nap();
+
+	/*
+	 * power4_idle_nap returns with interrupts enabled (soft and hard).
+	 * to our caller with interrupts enabled (soft and hard). Our caller
+	 * can cope with either interrupts disabled or enabled upon return.
+	 */
+}
+#endif
+
 #ifdef CONFIG_SYSCTL
 /*
  * Register the sysctl to set/clear powersave_nap.

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index d7216c9abda1..a36fd053c3db 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Idle daemon for PowerPC.  Idle daemon will handle any action
  * that needs to be taken when the system becomes idle.
@@ -12,11 +13,6 @@
  *    Copyright (c) 2003 Dave Engebretsen <engebret@us.ibm.com>
  *
  * 32-bit and 64-bit versions merged by Paul Mackerras <paulus@samba.org>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #include <linux/sched.h>

commit cc293bf7a9aa6fad68d107c79705732bd2fc57e3
Author: Joe Perches <joe@perches.com>
Date:   Thu Jun 13 19:37:30 2013 -0700

    powerpc/idle: Convert use of typedef ctl_table to struct ctl_table
    
    This typedef is unnecessary and should just be removed.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 939ea7ef0dc8..d7216c9abda1 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -85,7 +85,7 @@ int powersave_nap;
 /*
  * Register the sysctl to set/clear powersave_nap.
  */
-static ctl_table powersave_nap_ctl_table[]={
+static struct ctl_table powersave_nap_ctl_table[] = {
 	{
 		.procname	= "powersave-nap",
 		.data		= &powersave_nap,
@@ -95,7 +95,7 @@ static ctl_table powersave_nap_ctl_table[]={
 	},
 	{}
 };
-static ctl_table powersave_nap_sysctl_root[] = {
+static struct ctl_table powersave_nap_sysctl_root[] = {
 	{
 		.procname	= "kernel",
 		.mode		= 0555,

commit 799fef06123f86ff69cf754f996219e6ad1678f8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 21 22:49:56 2013 +0100

    powerpc: Use generic idle loop
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Link: http://lkml.kernel.org/r/20130321215235.026838003@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index ea78761aa169..939ea7ef0dc8 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -33,11 +33,6 @@
 #include <asm/runlatch.h>
 #include <asm/smp.h>
 
-#ifdef CONFIG_HOTPLUG_CPU
-#define cpu_should_die()	cpu_is_offline(smp_processor_id())
-#else
-#define cpu_should_die()	0
-#endif
 
 unsigned long cpuidle_disable = IDLE_NO_OVERRIDE;
 EXPORT_SYMBOL(cpuidle_disable);
@@ -50,64 +45,38 @@ static int __init powersave_off(char *arg)
 }
 __setup("powersave=off", powersave_off);
 
-/*
- * The body of the idle task.
- */
-void cpu_idle(void)
+#ifdef CONFIG_HOTPLUG_CPU
+void arch_cpu_idle_dead(void)
 {
-	set_thread_flag(TIF_POLLING_NRFLAG);
-	while (1) {
-		tick_nohz_idle_enter();
-		rcu_idle_enter();
-
-		while (!need_resched() && !cpu_should_die()) {
-			ppc64_runlatch_off();
-
-			if (ppc_md.power_save) {
-				clear_thread_flag(TIF_POLLING_NRFLAG);
-				/*
-				 * smp_mb is so clearing of TIF_POLLING_NRFLAG
-				 * is ordered w.r.t. need_resched() test.
-				 */
-				smp_mb();
-				local_irq_disable();
-
-				/* Don't trace irqs off for idle */
-				stop_critical_timings();
-
-				/* check again after disabling irqs */
-				if (!need_resched() && !cpu_should_die())
-					ppc_md.power_save();
-
-				start_critical_timings();
-
-				/* Some power_save functions return with
-				 * interrupts enabled, some don't.
-				 */
-				if (irqs_disabled())
-					local_irq_enable();
-				set_thread_flag(TIF_POLLING_NRFLAG);
-
-			} else {
-				/*
-				 * Go into low thread priority and possibly
-				 * low power mode.
-				 */
-				HMT_low();
-				HMT_very_low();
-			}
-		}
+	sched_preempt_enable_no_resched();
+	cpu_die();
+}
+#endif
 
-		HMT_medium();
-		ppc64_runlatch_on();
-		rcu_idle_exit();
-		tick_nohz_idle_exit();
-		if (cpu_should_die()) {
-			sched_preempt_enable_no_resched();
-			cpu_die();
-		}
-		schedule_preempt_disabled();
+void arch_cpu_idle(void)
+{
+	ppc64_runlatch_off();
+
+	if (ppc_md.power_save) {
+		ppc_md.power_save();
+		/*
+		 * Some power_save functions return with
+		 * interrupts enabled, some don't.
+		 */
+		if (irqs_disabled())
+			local_irq_enable();
+	} else {
+		local_irq_enable();
+		/*
+		 * Go into low thread priority and possibly
+		 * low power mode.
+		 */
+		HMT_low();
+		HMT_very_low();
 	}
+
+	HMT_medium();
+	ppc64_runlatch_on();
 }
 
 int powersave_nap;

commit 16b86bf2520ed29712ca7462dbfe76c856b445e9
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Oct 24 17:21:09 2012 +0000

    powerpc: Remove no longer used ppc_md.idle_loop()
    
    The last user of ppc_md.idle_loop() was removed when we dropped the
    legacy iSeries code, in commit 8ee3e0d.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 2099d9a879e8..ea78761aa169 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -55,9 +55,6 @@ __setup("powersave=off", powersave_off);
  */
 void cpu_idle(void)
 {
-	if (ppc_md.idle_loop)
-		ppc_md.idle_loop();	/* doesn't return */
-
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
 		tick_nohz_idle_enter();

commit c9b92b840705542a1ae50b5407154a5595d17359
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 7 17:59:50 2012 +0000

    powerpc: Remove unused cpu_idle_wait()
    
    cpuidle uses a generic function now. Remove the cruft.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Link: http://lkml.kernel.org/r/20120507175652.330322737@linutronix.de

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 04d79093d7a1..2099d9a879e8 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -113,25 +113,6 @@ void cpu_idle(void)
 	}
 }
 
-static void do_nothing(void *unused)
-{
-}
-
-/*
- * cpu_idle_wait - Used to ensure that all the CPUs come out of the old
- * idle loop and start using the new idle loop.
- * Required while changing idle handler on SMP systems.
- * Caller must have changed idle handler to the new value before the call.
- * This window may be larger on shared systems.
- */
-void cpu_idle_wait(void)
-{
-	smp_mb();
-	/* kick all the CPUs so that they exit out of pm_idle */
-	smp_call_function(do_nothing, NULL, 1);
-}
-EXPORT_SYMBOL_GPL(cpu_idle_wait);
-
 int powersave_nap;
 
 #ifdef CONFIG_SYSCTL

commit 9cd75e13de2dcf32ecc21c7f277cff3c0ced059e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 7 17:59:47 2012 +0000

    powerpc: Fix broken cpu_idle_wait() implementation
    
    commit 771dae818 (powerpc/cpuidle: Add cpu_idle_wait() to allow
    switching of idle routines) implemented cpu_idle_wait() for powerpc.
    
    The changelog says:
     "The equivalent routine for x86 is in arch/x86/kernel/process.c
      but the powerpc implementation is different.":
    
    Unfortunately the changelog is completely useless as it does not tell
    _WHY_ it is different.
    
    Aside of being different the implementation is patently wrong.
    
    The rescheduling IPI is async. That means that there is no guarantee,
    that the other cores have executed the IPI when cpu_idle_wait()
    returns. But that's the whole purpose of this function: to guarantee
    that no CPU uses the old idle handler anymore.
    
    Use the smp_functional_call() based implementation, which fulfils the
    requirements.
    
    [ This code is going to replaced by a core version to remove all the
      pointless copies in arch/*, but this one should go to stable ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Cc: Trinabh Gupta <g.trinabh@gmail.com>
    Cc: Arun R Bharadwaj <arun.r.bharadwaj@gmail.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Link: http://lkml.kernel.org/r/20120507175651.980164748@linutronix.de
    Cc: stable@vger.kernel.org

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 6d2209ac0c44..04d79093d7a1 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -113,6 +113,9 @@ void cpu_idle(void)
 	}
 }
 
+static void do_nothing(void *unused)
+{
+}
 
 /*
  * cpu_idle_wait - Used to ensure that all the CPUs come out of the old
@@ -123,16 +126,9 @@ void cpu_idle(void)
  */
 void cpu_idle_wait(void)
 {
-	int cpu;
 	smp_mb();
-
-	/* kick all the CPUs so that they exit out of old idle routine */
-	get_online_cpus();
-	for_each_online_cpu(cpu) {
-		if (cpu != smp_processor_id())
-			smp_send_reschedule(cpu);
-	}
-	put_online_cpus();
+	/* kick all the CPUs so that they exit out of pm_idle */
+	smp_call_function(do_nothing, NULL, 1);
 }
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 

commit ae3a197e3d0bfe3f4bf1693723e82dc018c096f3
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for PowerPC
    
    Disintegrate asm/system.h for PowerPC.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    cc: linuxppc-dev@lists.ozlabs.org

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index e8e821146f38..6d2209ac0c44 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -26,11 +26,11 @@
 #include <linux/sysctl.h>
 #include <linux/tick.h>
 
-#include <asm/system.h>
 #include <asm/processor.h>
 #include <asm/cputable.h>
 #include <asm/time.h>
 #include <asm/machdep.h>
+#include <asm/runlatch.h>
 #include <asm/smp.h>
 
 #ifdef CONFIG_HOTPLUG_CPU

commit 5375871d432ae9fc581014ac117b96aaee3cd0c7
Merge: b57cb7231b2c dfbc2d75c1bd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 21 18:55:10 2012 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc merge from Benjamin Herrenschmidt:
     "Here's the powerpc batch for this merge window.  It is going to be a
      bit more nasty than usual as in touching things outside of
      arch/powerpc mostly due to the big iSeriesectomy :-) We finally got
      rid of the bugger (legacy iSeries support) which was a PITA to
      maintain and that nobody really used anymore.
    
      Here are some of the highlights:
    
       - Legacy iSeries is gone.  Thanks Stephen ! There's still some bits
         and pieces remaining if you do a grep -ir series arch/powerpc but
         they are harmless and will be removed in the next few weeks
         hopefully.
    
       - The 'fadump' functionality (Firmware Assisted Dump) replaces the
         previous (equivalent) "pHyp assisted dump"...  it's a rewrite of a
         mechanism to get the hypervisor to do crash dumps on pSeries, the
         new implementation hopefully being much more reliable.  Thanks
         Mahesh Salgaonkar.
    
       - The "EEH" code (pSeries PCI error handling & recovery) got a big
         spring cleaning, motivated by the need to be able to implement a
         new backend for it on top of some new different type of firwmare.
    
         The work isn't complete yet, but a good chunk of the cleanups is
         there.  Note that this adds a field to struct device_node which is
         not very nice and which Grant objects to.  I will have a patch soon
         that moves that to a powerpc private data structure (hopefully
         before rc1) and we'll improve things further later on (hopefully
         getting rid of the need for that pointer completely).  Thanks Gavin
         Shan.
    
       - I dug into our exception & interrupt handling code to improve the
         way we do lazy interrupt handling (and make it work properly with
         "edge" triggered interrupt sources), and while at it found & fixed
         a wagon of issues in those areas, including adding support for page
         fault retry & fatal signals on page faults.
    
       - Your usual random batch of small fixes & updates, including a bunch
         of new embedded boards, both Freescale and APM based ones, etc..."
    
    I fixed up some conflicts with the generalized irq-domain changes from
    Grant Likely, hopefully correctly.
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (141 commits)
      powerpc/ps3: Do not adjust the wrapper load address
      powerpc: Remove the rest of the legacy iSeries include files
      powerpc: Remove the remaining CONFIG_PPC_ISERIES pieces
      init: Remove CONFIG_PPC_ISERIES
      powerpc: Remove FW_FEATURE ISERIES from arch code
      tty/hvc_vio: FW_FEATURE_ISERIES is no longer selectable
      powerpc/spufs: Fix double unlocks
      powerpc/5200: convert mpc5200 to use of_platform_populate()
      powerpc/mpc5200: add options to mpc5200_defconfig
      powerpc/mpc52xx: add a4m072 board support
      powerpc/mpc5200: update mpc5200_defconfig to fit for charon board
      Documentation/powerpc/mpc52xx.txt: Checkpatch cleanup
      powerpc/44x: Add additional device support for APM821xx SoC and Bluestone board
      powerpc/44x: Add support PCI-E for APM821xx SoC and Bluestone board
      MAINTAINERS: Update PowerPC 4xx tree
      powerpc/44x: The bug fixed support for APM821xx SoC and Bluestone board
      powerpc: document the FSL MPIC message register binding
      powerpc: add support for MPIC message register API
      powerpc/fsl: Added aliased MSIIR register address to MSI node in dts
      powerpc/85xx: mpc8548cds - add 36-bit dts
      ...

commit 7230c5644188cd9e3fb380cc97dde00c464a3ba7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Mar 6 18:27:59 2012 +1100

    powerpc: Rework lazy-interrupt handling
    
    The current implementation of lazy interrupts handling has some
    issues that this tries to address.
    
    We don't do the various workarounds we need to do when re-enabling
    interrupts in some cases such as when returning from an interrupt
    and thus we may still lose or get delayed decrementer or doorbell
    interrupts.
    
    The current scheme also makes it much harder to handle the external
    "edge" interrupts provided by some BookE processors when using the
    EPR facility (External Proxy) and the Freescale Hypervisor.
    
    Additionally, we tend to keep interrupts hard disabled in a number
    of cases, such as decrementer interrupts, external interrupts, or
    when a masked decrementer interrupt is pending. This is sub-optimal.
    
    This is an attempt at fixing it all in one go by reworking the way
    we do the lazy interrupt disabling from the ground up.
    
    The base idea is to replace the "hard_enabled" field with a
    "irq_happened" field in which we store a bit mask of what interrupt
    occurred while soft-disabled.
    
    When re-enabling, either via arch_local_irq_restore() or when returning
    from an interrupt, we can now decide what to do by testing bits in that
    field.
    
    We then implement replaying of the missed interrupts either by
    re-using the existing exception frame (in exception exit case) or via
    the creation of a new one from an assembly trampoline (in the
    arch_local_irq_enable case).
    
    This removes the need to play with the decrementer to try to create
    fake interrupts, among others.
    
    In addition, this adds a few refinements:
    
     - We no longer  hard disable decrementer interrupts that occur
    while soft-disabled. We now simply bump the decrementer back to max
    (on BookS) or leave it stopped (on BookE) and continue with hard interrupts
    enabled, which means that we'll potentially get better sample quality from
    performance monitor interrupts.
    
     - Timer, decrementer and doorbell interrupts now hard-enable
    shortly after removing the source of the interrupt, which means
    they no longer run entirely hard disabled. Again, this will improve
    perf sample quality.
    
     - On Book3E 64-bit, we now make the performance monitor interrupt
    act as an NMI like Book3S (the necessary C code for that to work
    appear to already be present in the FSL perf code, notably calling
    nmi_enter instead of irq_enter). (This also fixes a bug where BookE
    perfmon interrupts could clobber r14 ... oops)
    
     - We could make "masked" decrementer interrupts act as NMIs when doing
    timer-based perf sampling to improve the sample quality.
    
    Signed-off-by-yet: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    ---
    
    v2:
    
    - Add hard-enable to decrementer, timer and doorbells
    - Fix CR clobber in masked irq handling on BookE
    - Make embedded perf interrupt act as an NMI
    - Add a PACA_HAPPENED_EE_EDGE for use by FSL if they want
      to retrigger an interrupt without preventing hard-enable
    
    v3:
    
     - Fix or vs. ori bug on Book3E
     - Fix enabling of interrupts for some exceptions on Book3E
    
    v4:
    
     - Fix resend of doorbells on return from interrupt on Book3E
    
    v5:
    
     - Rebased on top of my latest series, which involves some significant
    rework of some aspects of the patch.
    
    v6:
     - 32-bit compile fix
     - more compile fixes with various .config combos
     - factor out the asm code to soft-disable interrupts
     - remove the C wrapper around preempt_schedule_irq
    
    v7:
     - Fix a bug with hard irq state tracking on native power7

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 0a48bf5db6c8..8f7a2b62863d 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -84,7 +84,11 @@ void cpu_idle(void)
 
 				start_critical_timings();
 
-				local_irq_enable();
+				/* Some power_save functions return with
+				 * interrupts enabled, some don't.
+				 */
+				if (irqs_disabled())
+					local_irq_enable();
 				set_thread_flag(TIF_POLLING_NRFLAG);
 
 			} else {

commit ba74c1448f127649046615ec017bded7b2a76f29
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 21 13:32:17 2011 +0100

    sched/rt: Document scheduler related skip-resched-check sites
    
    Create a distinction between scheduler related preempt_enable_no_resched()
    calls and the nearly one hundred other places in the kernel that do not
    want to reschedule, for one reason or another.
    
    This distinction matters for -rt, where the scheduler and the non-scheduler
    preempt models (and checks) are different. For upstream it's purely
    documentational.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/n/tip-gs88fvx2mdv5psnzxnv575ke@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 65035141552b..c97fc60c790c 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -102,7 +102,7 @@ void cpu_idle(void)
 		rcu_idle_exit();
 		tick_nohz_idle_exit();
 		if (cpu_should_die()) {
-			preempt_enable_no_resched();
+			sched_preempt_enable_no_resched();
 			cpu_die();
 		}
 		schedule_preempt_disabled();

commit bd2f55361f18347e890d52ff9cfd8895455ec11b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 21 12:33:18 2011 +0100

    sched/rt: Use schedule_preempt_disabled()
    
    Coccinelle based conversion.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-24swm5zut3h9c4a6s46x8rws@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 0a48bf5db6c8..65035141552b 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -101,11 +101,11 @@ void cpu_idle(void)
 		ppc64_runlatch_on();
 		rcu_idle_exit();
 		tick_nohz_idle_exit();
-		preempt_enable_no_resched();
-		if (cpu_should_die())
+		if (cpu_should_die()) {
+			preempt_enable_no_resched();
 			cpu_die();
-		schedule();
-		preempt_disable();
+		}
+		schedule_preempt_disabled();
 	}
 }
 

commit a5ccfee05a439b803640e94584056204501db31c
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Jan 9 14:29:15 2012 +0000

    powerpc: Fix RCU idle and hcall tracing
    
    Tracepoints should not be called inside an rcu_idle_enter/rcu_idle_exit
    region. Since pSeries calls H_CEDE in the idle loop, we were violating
    this rule.
    
    commit a7b152d5342c (powerpc: Tell RCU about idle after hcall tracing)
    tried to work around it by delaying the rcu_idle_enter until after we
    called the hcall tracepoint, but there are a number of issues with it.
    
    The hcall tracepoint trampoline code is called conditionally when the
    tracepoint is enabled. If the tracepoint is not enabled we never call
    rcu_idle_enter. The idle_uses_rcu check was also done at compile time
    which breaks multiplatform builds.
    
    The simple fix is to avoid tracing H_CEDE and rely on other tracepoints
    and the hypervisor dispatch trace log to work out if we called H_CEDE.
    
    This fixes a hang during boot on pSeries.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 7c66ce13da89..0a48bf5db6c8 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -50,12 +50,6 @@ static int __init powersave_off(char *arg)
 }
 __setup("powersave=off", powersave_off);
 
-#if defined(CONFIG_PPC_PSERIES) && defined(CONFIG_TRACEPOINTS)
-static const bool idle_uses_rcu = 1;
-#else
-static const bool idle_uses_rcu;
-#endif
-
 /*
  * The body of the idle task.
  */
@@ -67,8 +61,7 @@ void cpu_idle(void)
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
 		tick_nohz_idle_enter();
-		if (!idle_uses_rcu)
-			rcu_idle_enter();
+		rcu_idle_enter();
 
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
@@ -106,8 +99,7 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
-		if (!idle_uses_rcu)
-			rcu_idle_exit();
+		rcu_idle_exit();
 		tick_nohz_idle_exit();
 		preempt_enable_no_resched();
 		if (cpu_should_die())

commit e4e88f31bcb5f05f24b9ae518d4ecb44e1a7774d
Merge: 9753dfe19a85 ef88e3911c0e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 6 17:58:22 2012 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (185 commits)
      powerpc: fix compile error with 85xx/p1010rdb.c
      powerpc: fix compile error with 85xx/p1023_rds.c
      powerpc/fsl: add MSI support for the Freescale hypervisor
      arch/powerpc/sysdev/fsl_rmu.c: introduce missing kfree
      powerpc/fsl: Add support for Integrated Flash Controller
      powerpc/fsl: update compatiable on fsl 16550 uart nodes
      powerpc/85xx: fix PCI and localbus properties in p1022ds.dts
      powerpc/85xx: re-enable ePAPR byte channel driver in corenet32_smp_defconfig
      powerpc/fsl: Update defconfigs to enable some standard FSL HW features
      powerpc: Add TBI PHY node to first MDIO bus
      sbc834x: put full compat string in board match check
      powerpc/fsl-pci: Allow 64-bit PCIe devices to DMA to any memory address
      powerpc: Fix unpaired probe_hcall_entry and probe_hcall_exit
      offb: Fix setting of the pseudo-palette for >8bpp
      offb: Add palette hack for qemu "standard vga" framebuffer
      offb: Fix bug in calculating requested vram size
      powerpc/boot: Change the WARN to INFO for boot wrapper overlap message
      powerpc/44x: Fix build error on currituck platform
      powerpc/boot: Change the load address for the wrapper to fit the kernel
      powerpc/44x: Enable CRASH_DUMP for 440x
      ...
    
    Fix up a trivial conflict in arch/powerpc/include/asm/cputime.h due to
    the additional sparse-checking code for cputime_t.

commit 1268fbc746ea1cd279886a740dcbad4ba5232225
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Nov 17 18:48:14 2011 +0100

    nohz: Remove tick_nohz_idle_enter_norcu() / tick_nohz_idle_exit_norcu()
    
    Those two APIs were provided to optimize the calls of
    tick_nohz_idle_enter() and rcu_idle_enter() into a single
    irq disabled section. This way no interrupt happening in-between would
    needlessly process any RCU job.
    
    Now we are talking about an optimization for which benefits
    have yet to be measured. Let's start simple and completely decouple
    idle rcu and dyntick idle logics to simplify.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 3cd73d1fc427..9c3cd490b1bd 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -62,10 +62,10 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		if (idle_uses_rcu)
-			tick_nohz_idle_enter();
-		else
-			tick_nohz_idle_enter_norcu();
+		tick_nohz_idle_enter();
+		if (!idle_uses_rcu)
+			rcu_idle_enter();
+
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 
@@ -102,10 +102,9 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
-		if (idle_uses_rcu)
-			tick_nohz_idle_exit();
-		else
-			tick_nohz_idle_exit_norcu();
+		if (!idle_uses_rcu)
+			rcu_idle_exit();
+		tick_nohz_idle_exit();
 		preempt_enable_no_resched();
 		if (cpu_should_die())
 			cpu_die();

commit a7b152d5342c06e81ab0cf7d18345f69fa7e56b5
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Thu Oct 13 19:05:12 2011 -0700

    powerpc: Tell RCU about idle after hcall tracing
    
    The PowerPC pSeries platform (CONFIG_PPC_PSERIES=y) enables
    hypervisor-call tracing for CONFIG_TRACEPOINTS=y kernels.  One of the
    hypervisor calls that is traced is the H_CEDE call in the idle loop
    that tells the hypervisor that this OS instance no longer needs the
    current CPU.  However, tracing uses RCU, so this combination of kernel
    configuration variables needs to avoid telling RCU about the current CPU's
    idleness until after the H_CEDE-entry tracing completes on the one hand,
    and must tell RCU that the the current CPU is no longer idle before the
    H_CEDE-exit tracing starts.
    
    In all other cases, it suffices to inform RCU of CPU idleness upon
    idle-loop entry and exit.
    
    This commit makes the required adjustments.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 2e782a36d8f2..3cd73d1fc427 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -46,6 +46,12 @@ static int __init powersave_off(char *arg)
 }
 __setup("powersave=off", powersave_off);
 
+#if defined(CONFIG_PPC_PSERIES) && defined(CONFIG_TRACEPOINTS)
+static const bool idle_uses_rcu = 1;
+#else
+static const bool idle_uses_rcu;
+#endif
+
 /*
  * The body of the idle task.
  */
@@ -56,7 +62,10 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		tick_nohz_idle_enter_norcu();
+		if (idle_uses_rcu)
+			tick_nohz_idle_enter();
+		else
+			tick_nohz_idle_enter_norcu();
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 
@@ -93,7 +102,10 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
-		tick_nohz_idle_exit_norcu();
+		if (idle_uses_rcu)
+			tick_nohz_idle_exit();
+		else
+			tick_nohz_idle_exit_norcu();
 		preempt_enable_no_resched();
 		if (cpu_should_die())
 			cpu_die();

commit 2bbb6817c0ac1b5f2a68d720f364f98eeb1ac4fd
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Oct 8 16:01:00 2011 +0200

    nohz: Allow rcu extended quiescent state handling seperately from tick stop
    
    It is assumed that rcu won't be used once we switch to tickless
    mode and until we restart the tick. However this is not always
    true, as in x86-64 where we dereference the idle notifiers after
    the tick is stopped.
    
    To prepare for fixing this, add two new APIs:
    tick_nohz_idle_enter_norcu() and tick_nohz_idle_exit_norcu().
    
    If no use of RCU is made in the idle loop between
    tick_nohz_enter_idle() and tick_nohz_exit_idle() calls, the arch
    must instead call the new *_norcu() version such that the arch doesn't
    need to call rcu_idle_enter() and rcu_idle_exit().
    
    Otherwise the arch must call tick_nohz_enter_idle() and
    tick_nohz_exit_idle() and also call explicitly:
    
    - rcu_idle_enter() after its last use of RCU before the CPU is put
    to sleep.
    - rcu_idle_exit() before the first use of RCU after the CPU is woken
    up.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: David Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Hans-Christian Egtvedt <hans-christian.egtvedt@atmel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 878572f70ac5..2e782a36d8f2 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -56,7 +56,7 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		tick_nohz_idle_enter();
+		tick_nohz_idle_enter_norcu();
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 
@@ -93,7 +93,7 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
-		tick_nohz_idle_exit();
+		tick_nohz_idle_exit_norcu();
 		preempt_enable_no_resched();
 		if (cpu_should_die())
 			cpu_die();

commit 280f06774afedf849f0b34248ed6aff57d0f6908
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 7 18:22:06 2011 +0200

    nohz: Separate out irq exit and idle loop dyntick logic
    
    The tick_nohz_stop_sched_tick() function, which tries to delay
    the next timer tick as long as possible, can be called from two
    places:
    
    - From the idle loop to start the dytick idle mode
    - From interrupt exit if we have interrupted the dyntick
    idle mode, so that we reprogram the next tick event in
    case the irq changed some internal state that requires this
    action.
    
    There are only few minor differences between both that
    are handled by that function, driven by the ts->inidle
    cpu variable and the inidle parameter. The whole guarantees
    that we only update the dyntick mode on irq exit if we actually
    interrupted the dyntick idle mode, and that we enter in RCU extended
    quiescent state from idle loop entry only.
    
    Split this function into:
    
    - tick_nohz_idle_enter(), which sets ts->inidle to 1, enters
    dynticks idle mode unconditionally if it can, and enters into RCU
    extended quiescent state.
    
    - tick_nohz_irq_exit() which only updates the dynticks idle mode
    when ts->inidle is set (ie: if tick_nohz_idle_enter() has been called).
    
    To maintain symmetry, tick_nohz_restart_sched_tick() has been renamed
    into tick_nohz_idle_exit().
    
    This simplifies the code and micro-optimize the irq exit path (no need
    for local_irq_save there). This also prepares for the split between
    dynticks and rcu extended quiescent state logics. We'll need this split to
    further fix illegal uses of RCU in extended quiescent states in the idle
    loop.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: David Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Hans-Christian Egtvedt <hans-christian.egtvedt@atmel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 39a2baa6ad58..878572f70ac5 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -56,7 +56,7 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		tick_nohz_stop_sched_tick(1);
+		tick_nohz_idle_enter();
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 
@@ -93,7 +93,7 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
-		tick_nohz_restart_sched_tick();
+		tick_nohz_idle_exit();
 		preempt_enable_no_resched();
 		if (cpu_should_die())
 			cpu_die();

commit 771dae81896855d25f7f8746aaf56c0238deafb6
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Wed Nov 30 02:46:31 2011 +0000

    powerpc/cpuidle: Add cpu_idle_wait() to allow switching of idle routines
    
    This patch provides cpu_idle_wait() routine for the powerpc
    platform which is required by the cpuidle subsystem. This
    routine is required to change the idle handler on SMP systems.
    The equivalent routine for x86 is in arch/x86/kernel/process.c
    but the powerpc implementation is different.
    
    cpuidle_disable variable is to enable/disable cpuidle
    framework if power_save option is set during the boot
    time.
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Signed-off-by: Arun R Bharadwaj <arun.r.bharadwaj@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 39a2baa6ad58..8574b0e81ff1 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -39,9 +39,13 @@
 #define cpu_should_die()	0
 #endif
 
+unsigned long cpuidle_disable = IDLE_NO_OVERRIDE;
+EXPORT_SYMBOL(cpuidle_disable);
+
 static int __init powersave_off(char *arg)
 {
 	ppc_md.power_save = NULL;
+	cpuidle_disable = IDLE_POWERSAVE_OFF;
 	return 0;
 }
 __setup("powersave=off", powersave_off);
@@ -102,6 +106,29 @@ void cpu_idle(void)
 	}
 }
 
+
+/*
+ * cpu_idle_wait - Used to ensure that all the CPUs come out of the old
+ * idle loop and start using the new idle loop.
+ * Required while changing idle handler on SMP systems.
+ * Caller must have changed idle handler to the new value before the call.
+ * This window may be larger on shared systems.
+ */
+void cpu_idle_wait(void)
+{
+	int cpu;
+	smp_mb();
+
+	/* kick all the CPUs so that they exit out of old idle routine */
+	get_online_cpus();
+	for_each_online_cpu(cpu) {
+		if (cpu != smp_processor_id())
+			smp_send_reschedule(cpu);
+	}
+	put_online_cpus();
+}
+EXPORT_SYMBOL_GPL(cpu_idle_wait);
+
 int powersave_nap;
 
 #ifdef CONFIG_SYSCTL

commit a7c2bb8279d20d853e43c34584eaf2b039de8026
Author: Signed-off-by: Darren Hart <dvhltc@us.ibm.com>
Date:   Wed Aug 4 18:28:33 2010 +0000

    powerpc: Re-enable preemption before cpu_die()
    
    start_secondary() is called shortly after _start and also via
    
    cpu_idle()->cpu_die()->pseries_mach_cpu_die()
    
    start_secondary() expects a preempt_count() of 0. pseries_mach_cpu_die() is
    called via the cpu_idle() routine with preemption disabled, resulting in the
    following repeating message during rapid cpu offline/online tests
    with CONFIG_PREEMPT=y:
    
    BUG: scheduling while atomic: swapper/0/0x00000002
    Modules linked in: autofs4 binfmt_misc dm_mirror dm_region_hash dm_log [last unloaded: scsi_wait_scan]
    Call Trace:
    [c00000010e7079c0] [c0000000000133ec] .show_stack+0xd8/0x218 (unreliable)
    [c00000010e707aa0] [c0000000006a47f0] .dump_stack+0x28/0x3c
    [c00000010e707b20] [c00000000006e7a4] .__schedule_bug+0x7c/0x9c
    [c00000010e707bb0] [c000000000699d9c] .schedule+0x104/0x800
    [c00000010e707cd0] [c000000000015b24] .cpu_idle+0x1c4/0x1d8
    [c00000010e707d70] [c0000000006aa1b4] .start_secondary+0x398/0x3d4
    [c00000010e707e30] [c000000000008278] .start_secondary_resume+0x10/0x14
    
    Move the cpu_die() call inside the existing preemption enabled block of
    cpu_idle(). This is safe as the idle task is affined to a single CPU so the
    debug_smp_processor_id() tests (from cpu_should_die()) won't trigger as we are
    in a "migration disabled" region.
    
    Signed-off-by: Darren Hart <dvhltc@us.ibm.com>
    Acked-by: Will Schmidt <will_schmidt@vnet.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Nathan Fontenot <nfont@austin.ibm.com>
    Cc: Robert Jennings <rcj@linux.vnet.ibm.com>
    Cc: Brian King <brking@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 049dda60e475..39a2baa6ad58 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -94,9 +94,9 @@ void cpu_idle(void)
 		HMT_medium();
 		ppc64_runlatch_on();
 		tick_nohz_restart_sched_tick();
+		preempt_enable_no_resched();
 		if (cpu_should_die())
 			cpu_die();
-		preempt_enable_no_resched();
 		schedule();
 		preempt_disable();
 	}

commit 6d4561110a3e9fa742aeec6717248a491dfb1878
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Nov 16 03:11:48 2009 -0800

    sysctl: Drop & in front of every proc_handler.
    
    For consistency drop & in front of every proc_handler.  Explicity
    taking the address is unnecessary and it prevents optimizations
    like stubbing the proc_handlers to NULL.
    
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Joe Perches <joe@perches.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index cece9e2cc5e4..049dda60e475 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -114,7 +114,7 @@ static ctl_table powersave_nap_ctl_table[]={
 		.data		= &powersave_nap,
 		.maxlen		= sizeof(int),
 		.mode		= 0644,
-		.proc_handler	= &proc_dointvec,
+		.proc_handler	= proc_dointvec,
 	},
 	{}
 };

commit 26ea51355847b5cd70b46fe9ec9c68ad067118a4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Apr 3 05:29:59 2009 -0700

    sysctl powerpc: Remove dead binary sysctl support
    
    Now that sys_sysctl is a generic wrapper around /proc/sys  .ctl_name
    and .strategy members of sysctl tables are dead code.  Remove them.
    
    Cc: Paul Mackerras <paulus@samba.org>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 88d9c1d5e5fb..cece9e2cc5e4 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -110,7 +110,6 @@ int powersave_nap;
  */
 static ctl_table powersave_nap_ctl_table[]={
 	{
-		.ctl_name	= KERN_PPC_POWERSAVE_NAP,
 		.procname	= "powersave-nap",
 		.data		= &powersave_nap,
 		.maxlen		= sizeof(int),
@@ -121,7 +120,6 @@ static ctl_table powersave_nap_ctl_table[]={
 };
 static ctl_table powersave_nap_sysctl_root[] = {
 	{
-		.ctl_name	= CTL_KERN,
 		.procname	= "kernel",
 		.mode		= 0555,
 		.child		= powersave_nap_ctl_table,

commit 6d07bb47354174a9b52d3b03f9e38b069a93d341
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Nov 14 16:21:19 2008 -0800

    powerpc: ftrace, do not latency trace idle
    
    Impact: fix for irq off latency tracer
    
    When idle is called, interrupts are disabled, but the idle function
    will still wake up on an interrupt. The problem is that the interrupt
    disabled latency tracer will take this call to idle as a latency.
    
    This patch disables the latency tracing when going into idle.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 31982d05d81a..88d9c1d5e5fb 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -69,10 +69,15 @@ void cpu_idle(void)
 				smp_mb();
 				local_irq_disable();
 
+				/* Don't trace irqs off for idle */
+				stop_critical_timings();
+
 				/* check again after disabling irqs */
 				if (!need_resched() && !cpu_should_die())
 					ppc_md.power_save();
 
+				start_critical_timings();
+
 				local_irq_enable();
 				set_thread_flag(TIF_POLLING_NRFLAG);
 

commit 61e9916eba35dfb76d38013a5aae9a59cc50877a
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Wed Sep 24 22:56:25 2008 +0000

    powerpc: Fix failure to shutdown with CPU hotplug
    
    I tracked down the shutdown regression to CPUs not dying
    when being shut down during power-off. This turns out to
    be due to the system_state being SYSTEM_POWER_OFF, which
    this code doesn't take as a valid state for shutting off
    CPUs in.
    
    This has never made sense to me, but when I added hotplug
    code to implement hibernate I only "made it work" and did
    not question the need to check the system_state. Thomas
    Gleixner helped me dig, but the only thing we found is
    that it was added with the original commit that added CPU
    hotplug support.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Acked-by: Joel Schopp <jschopp@austin.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index d308a9f70f1b..31982d05d81a 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -34,11 +34,7 @@
 #include <asm/smp.h>
 
 #ifdef CONFIG_HOTPLUG_CPU
-/* this is used for software suspend, and that shuts down
- * CPUs even while the system is still booting... */
-#define cpu_should_die()	(cpu_is_offline(smp_processor_id()) && \
-				   (system_state == SYSTEM_RUNNING     \
-				 || system_state == SYSTEM_BOOTING))
+#define cpu_should_die()	cpu_is_offline(smp_processor_id())
 #else
 #define cpu_should_die()	0
 #endif

commit b8f8c3cf0a4ac0632ec3f0e15e9dc0c29de917af
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 18 17:27:28 2008 +0200

    nohz: prevent tick stop outside of the idle loop
    
    Jack Ren and Eric Miao tracked down the following long standing
    problem in the NOHZ code:
    
            scheduler switch to idle task
            enable interrupts
    
    Window starts here
    
            ----> interrupt happens (does not set NEED_RESCHED)
                    irq_exit() stops the tick
    
            ----> interrupt happens (does set NEED_RESCHED)
    
            return from schedule()
    
            cpu_idle(): preempt_disable();
    
    Window ends here
    
    The interrupts can happen at any point inside the race window. The
    first interrupt stops the tick, the second one causes the scheduler to
    rerun and switch away from idle again and we end up with the tick
    disabled.
    
    The fact that it needs two interrupts where the first one does not set
    NEED_RESCHED and the second one does made the bug obscure and extremly
    hard to reproduce and analyse. Kudos to Jack and Eric.
    
    Solution: Limit the NOHZ functionality to the idle loop to make sure
    that we can not run into such a situation ever again.
    
    cpu_idle()
    {
            preempt_disable();
    
            while(1) {
                     tick_nohz_stop_sched_tick(1); <- tell NOHZ code that we
                                                      are in the idle loop
    
                     while (!need_resched())
                           halt();
    
                     tick_nohz_restart_sched_tick(); <- disables NOHZ mode
                     preempt_enable_no_resched();
                     schedule();
                     preempt_disable();
            }
    }
    
    In hindsight we should have done this forever, but ...
    
    /me grabs a large brown paperbag.
    
    Debugged-by: Jack Ren <jack.ren@marvell.com>,
    Debugged-by: eric miao <eric.y.miao@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index c3cf0e8f3ac1..d308a9f70f1b 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -60,7 +60,7 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		tick_nohz_stop_sched_tick();
+		tick_nohz_stop_sched_tick(1);
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 

commit fb293ae1c02dab78e714d50f2c37d7852d6f328a
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Sun Oct 28 05:34:53 2007 +1100

    [POWERPC] Fix sysctl table check failure on PowerMac
    
    kernel was marked with 0755. Everywhere else it's 0555.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index abd2957fe537..c3cf0e8f3ac1 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -122,7 +122,7 @@ static ctl_table powersave_nap_sysctl_root[] = {
 	{
 		.ctl_name	= CTL_KERN,
 		.procname	= "kernel",
-		.mode		= 0755,
+		.mode		= 0555,
 		.child		= powersave_nap_ctl_table,
 	},
 	{}

commit 1ad749980a5fda46f7ec920d8409ddcc89b38714
Author: Tony Breeds <tony@bakeyournoodle.com>
Date:   Fri Sep 21 13:26:03 2007 +1000

    [POWERPC] Enable tickless idle and high res timers for powerpc
    
    Signed-off-by: Tony Breeds <tony@bakeyournoodle.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index a9e9cbd32975..abd2957fe537 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -24,6 +24,7 @@
 #include <linux/smp.h>
 #include <linux/cpu.h>
 #include <linux/sysctl.h>
+#include <linux/tick.h>
 
 #include <asm/system.h>
 #include <asm/processor.h>
@@ -59,6 +60,7 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
+		tick_nohz_stop_sched_tick();
 		while (!need_resched() && !cpu_should_die()) {
 			ppc64_runlatch_off();
 
@@ -90,6 +92,7 @@ void cpu_idle(void)
 
 		HMT_medium();
 		ppc64_runlatch_on();
+		tick_nohz_restart_sched_tick();
 		if (cpu_should_die())
 			cpu_die();
 		preempt_enable_no_resched();

commit 543b9fd3528f64c4b20439de0edb453764482de7
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Thu May 3 22:31:38 2007 +1000

    [POWERPC] powermac: Suspend to disk on G5
    
    Powermac G5 suspend to disk implementation.  The code is platform
    agnostic but only tested on powermac, no other 64-bit powerpc
    machines.
    
    Because nvidiafb still breaks suspend I have marked it EXPERIMENTAL on
    powermac and because I can't test it and some lowlevel code will need
    changes it is BROKEN on all other 64-bit platforms.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 6e7f50967bab..a9e9cbd32975 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -33,8 +33,11 @@
 #include <asm/smp.h>
 
 #ifdef CONFIG_HOTPLUG_CPU
+/* this is used for software suspend, and that shuts down
+ * CPUs even while the system is still booting... */
 #define cpu_should_die()	(cpu_is_offline(smp_processor_id()) && \
-				 system_state == SYSTEM_RUNNING)
+				   (system_state == SYSTEM_RUNNING     \
+				 || system_state == SYSTEM_BOOTING))
 #else
 #define cpu_should_die()	0
 #endif

commit 0b4d414714f0d2f922d39424b0c5c82ad900a381
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 14 00:34:09 2007 -0800

    [PATCH] sysctl: remove insert_at_head from register_sysctl
    
    The semantic effect of insert_at_head is that it would allow new registered
    sysctl entries to override existing sysctl entries of the same name.  Which is
    pain for caching and the proc interface never implemented.
    
    I have done an audit and discovered that none of the current users of
    register_sysctl care as (excpet for directories) they do not register
    duplicate sysctl entries.
    
    So this patch simply removes the support for overriding existing entries in
    the sys_sysctl interface since no one uses it or cares and it makes future
    enhancments harder.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: David Howells <dhowells@redhat.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Corey Minyard <minyard@acm.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: "John W. Linville" <linville@tuxdriver.com>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: Mark Fasheh <mark.fasheh@oracle.com>
    Cc: David Chinner <dgc@sgi.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Patrick McHardy <kaber@trash.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 8b27bb1a5b31..6e7f50967bab 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -125,7 +125,7 @@ static ctl_table powersave_nap_sysctl_root[] = {
 static int __init
 register_powersave_nap_sysctl(void)
 {
-	register_sysctl_table(powersave_nap_sysctl_root, 0);
+	register_sysctl_table(powersave_nap_sysctl_root);
 
 	return 0;
 }

commit f5f106784eba94a00bbe73be651e423386ebe6d4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 14 00:33:46 2007 -0800

    [PATCH] sysctl: C99 convert ctl_tables in arch/powerpc/kernel/idle.c
    
    This was partially done already and there was no ABI breakage what a relief.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 8994af327b47..8b27bb1a5b31 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -110,11 +110,16 @@ static ctl_table powersave_nap_ctl_table[]={
 		.mode		= 0644,
 		.proc_handler	= &proc_dointvec,
 	},
-	{ 0, },
+	{}
 };
 static ctl_table powersave_nap_sysctl_root[] = {
-	{ 1, "kernel", NULL, 0, 0755, powersave_nap_ctl_table, },
- 	{ 0,},
+	{
+		.ctl_name	= CTL_KERN,
+		.procname	= "kernel",
+		.mode		= 0755,
+		.child		= powersave_nap_ctl_table,
+	},
+	{}
 };
 
 static int __init

commit 302eca184fb844670fb128c69e22a8a28bbce48a
Author: arnd@arndb.de <arnd@arndb.de>
Date:   Tue Oct 24 18:31:26 2006 +0200

    [POWERPC] cell: use ppc_md->power_save instead of cbe_idle_loop
    
    This moves the cell idle function to use the default cpu_idle
    with a special power_save callback, like all other platforms
    except iSeries already do.
    
    It also makes it possible to disable this power_save function
    with a new powerpc-specific boot option "powersave=off".
    
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index 4180c3998b39..8994af327b47 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -39,6 +39,13 @@
 #define cpu_should_die()	0
 #endif
 
+static int __init powersave_off(char *arg)
+{
+	ppc_md.power_save = NULL;
+	return 0;
+}
+__setup("powersave=off", powersave_off);
+
 /*
  * The body of the idle task.
  */

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index d491052c8e0c..4180c3998b39 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -19,7 +19,6 @@
  * 2 of the License, or (at your option) any later version.
  */
 
-#include <linux/config.h>
 #include <linux/sched.h>
 #include <linux/kernel.h>
 #include <linux/smp.h>

commit ddafddcfc78aab994cf95922befc54d98aaf371b
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Apr 2 19:54:09 2006 +1000

    [PATCH] powerpc: Ensure runlatch is off in the idle loop
    
    Since external and decrementer interrupts set the runlatch on, we need
    to ensure its set off again in the idle loop. At the moment we dont turn
    it off in the inner loop.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
index e9f321d74d85..d491052c8e0c 100644
--- a/arch/powerpc/kernel/idle.c
+++ b/arch/powerpc/kernel/idle.c
@@ -50,9 +50,9 @@ void cpu_idle(void)
 
 	set_thread_flag(TIF_POLLING_NRFLAG);
 	while (1) {
-		ppc64_runlatch_off();
-
 		while (!need_resched() && !cpu_should_die()) {
+			ppc64_runlatch_off();
+
 			if (ppc_md.power_save) {
 				clear_thread_flag(TIF_POLLING_NRFLAG);
 				/*

commit a0652fc9a28c3ef8cd59264bfcb089c44d1b0e06
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Mar 27 15:03:03 2006 +1100

    powerpc: Unify the 32 and 64 bit idle loops
    
    This unifies the 32-bit (ARCH=ppc and ARCH=powerpc) and 64-bit idle
    loops.  It brings over the concept of having a ppc_md.power_save
    function from 32-bit to ARCH=powerpc, which lets us get rid of
    native_idle().  With this we will also be able to simplify the idle
    handling for pSeries and cell.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/idle.c b/arch/powerpc/kernel/idle.c
new file mode 100644
index 000000000000..e9f321d74d85
--- /dev/null
+++ b/arch/powerpc/kernel/idle.c
@@ -0,0 +1,122 @@
+/*
+ * Idle daemon for PowerPC.  Idle daemon will handle any action
+ * that needs to be taken when the system becomes idle.
+ *
+ * Originally written by Cort Dougan (cort@cs.nmt.edu).
+ * Subsequent 32-bit hacking by Tom Rini, Armin Kuster,
+ * Paul Mackerras and others.
+ *
+ * iSeries supported added by Mike Corrigan <mikejc@us.ibm.com>
+ *
+ * Additional shared processor, SMT, and firmware support
+ *    Copyright (c) 2003 Dave Engebretsen <engebret@us.ibm.com>
+ *
+ * 32-bit and 64-bit versions merged by Paul Mackerras <paulus@samba.org>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/smp.h>
+#include <linux/cpu.h>
+#include <linux/sysctl.h>
+
+#include <asm/system.h>
+#include <asm/processor.h>
+#include <asm/cputable.h>
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/smp.h>
+
+#ifdef CONFIG_HOTPLUG_CPU
+#define cpu_should_die()	(cpu_is_offline(smp_processor_id()) && \
+				 system_state == SYSTEM_RUNNING)
+#else
+#define cpu_should_die()	0
+#endif
+
+/*
+ * The body of the idle task.
+ */
+void cpu_idle(void)
+{
+	if (ppc_md.idle_loop)
+		ppc_md.idle_loop();	/* doesn't return */
+
+	set_thread_flag(TIF_POLLING_NRFLAG);
+	while (1) {
+		ppc64_runlatch_off();
+
+		while (!need_resched() && !cpu_should_die()) {
+			if (ppc_md.power_save) {
+				clear_thread_flag(TIF_POLLING_NRFLAG);
+				/*
+				 * smp_mb is so clearing of TIF_POLLING_NRFLAG
+				 * is ordered w.r.t. need_resched() test.
+				 */
+				smp_mb();
+				local_irq_disable();
+
+				/* check again after disabling irqs */
+				if (!need_resched() && !cpu_should_die())
+					ppc_md.power_save();
+
+				local_irq_enable();
+				set_thread_flag(TIF_POLLING_NRFLAG);
+
+			} else {
+				/*
+				 * Go into low thread priority and possibly
+				 * low power mode.
+				 */
+				HMT_low();
+				HMT_very_low();
+			}
+		}
+
+		HMT_medium();
+		ppc64_runlatch_on();
+		if (cpu_should_die())
+			cpu_die();
+		preempt_enable_no_resched();
+		schedule();
+		preempt_disable();
+	}
+}
+
+int powersave_nap;
+
+#ifdef CONFIG_SYSCTL
+/*
+ * Register the sysctl to set/clear powersave_nap.
+ */
+static ctl_table powersave_nap_ctl_table[]={
+	{
+		.ctl_name	= KERN_PPC_POWERSAVE_NAP,
+		.procname	= "powersave-nap",
+		.data		= &powersave_nap,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec,
+	},
+	{ 0, },
+};
+static ctl_table powersave_nap_sysctl_root[] = {
+	{ 1, "kernel", NULL, 0, 0755, powersave_nap_ctl_table, },
+ 	{ 0,},
+};
+
+static int __init
+register_powersave_nap_sysctl(void)
+{
+	register_sysctl_table(powersave_nap_sysctl_root, 0);
+
+	return 0;
+}
+__initcall(register_powersave_nap_sysctl);
+#endif
