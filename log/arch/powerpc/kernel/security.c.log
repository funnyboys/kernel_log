commit 753462512868674a788ecc77bb96752efb818785
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:26 2020 +1000

    powerpc: Use a macro for creating instructions from u32s
    
    In preparation for instructions having a more complex data type start
    using a macro, ppc_inst(), for making an instruction out of a u32.  A
    macro is used so that instructions can be used as initializer elements.
    Currently this does nothing, but it will allow for creating a data type
    that can represent prefixed instructions.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Change include guard to _ASM_POWERPC_INST_H]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-7-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 479325baf6a9..d86701ce116b 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -16,6 +16,7 @@
 #include <asm/debugfs.h>
 #include <asm/security_features.h>
 #include <asm/setup.h>
+#include <asm/inst.h>
 
 
 u64 powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
@@ -439,9 +440,11 @@ static void toggle_count_cache_flush(bool enable)
 		enable = false;
 
 	if (!enable) {
-		patch_instruction_site(&patch__call_flush_count_cache, PPC_INST_NOP);
+		patch_instruction_site(&patch__call_flush_count_cache,
+				       ppc_inst(PPC_INST_NOP));
 #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
-		patch_instruction_site(&patch__call_kvm_flush_link_stack, PPC_INST_NOP);
+		patch_instruction_site(&patch__call_kvm_flush_link_stack,
+				       ppc_inst(PPC_INST_NOP));
 #endif
 		pr_info("link-stack-flush: software flush disabled.\n");
 		link_stack_flush_enabled = false;
@@ -464,7 +467,8 @@ static void toggle_count_cache_flush(bool enable)
 
 	// If we just need to flush the link stack, patch an early return
 	if (!security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE)) {
-		patch_instruction_site(&patch__flush_link_stack_return, PPC_INST_BLR);
+		patch_instruction_site(&patch__flush_link_stack_return,
+				       ppc_inst(PPC_INST_BLR));
 		no_count_cache_flush();
 		return;
 	}
@@ -475,7 +479,7 @@ static void toggle_count_cache_flush(bool enable)
 		return;
 	}
 
-	patch_instruction_site(&patch__flush_count_cache_return, PPC_INST_BLR);
+	patch_instruction_site(&patch__flush_count_cache_return, ppc_inst(PPC_INST_BLR));
 	count_cache_flush_type = COUNT_CACHE_FLUSH_HW;
 	pr_info("count-cache-flush: hardware assisted flush sequence enabled\n");
 }

commit d93e5e2d03d4f41dfedb92200a2c0413ab8ee4e7
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Apr 2 23:49:29 2020 +1100

    powerpc/64: Update Speculation_Store_Bypass in /proc/<pid>/status
    
    Currently we don't report anything useful in /proc/<pid>/status:
    
      $ grep Speculation_Store_Bypass /proc/self/status
      Speculation_Store_Bypass:       unknown
    
    Our mitigation is currently always a barrier instruction, which
    doesn't map that well onto the existing possibilities for the PR_SPEC
    values.
    
    However even if we added a "barrier" type PR_SPEC value, userspace
    would still need to consult some other source to work out which type
    of barrier to use. So reporting "vulnerable" seems sufficient, as
    userspace can see that and then consult its source to determine what
    barrier to use.
    
    Signed-off-by: Gustavo Walbon <gwalbon@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200402124929.3574166-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index bd70f5be1c27..479325baf6a9 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -7,6 +7,8 @@
 #include <linux/cpu.h>
 #include <linux/kernel.h>
 #include <linux/device.h>
+#include <linux/nospec.h>
+#include <linux/prctl.h>
 #include <linux/seq_buf.h>
 
 #include <asm/asm-prototypes.h>
@@ -353,6 +355,40 @@ ssize_t cpu_show_spec_store_bypass(struct device *dev, struct device_attribute *
 	return sprintf(buf, "Vulnerable\n");
 }
 
+static int ssb_prctl_get(struct task_struct *task)
+{
+	if (stf_enabled_flush_types == STF_BARRIER_NONE)
+		/*
+		 * We don't have an explicit signal from firmware that we're
+		 * vulnerable or not, we only have certain CPU revisions that
+		 * are known to be vulnerable.
+		 *
+		 * We assume that if we're on another CPU, where the barrier is
+		 * NONE, then we are not vulnerable.
+		 */
+		return PR_SPEC_NOT_AFFECTED;
+	else
+		/*
+		 * If we do have a barrier type then we are vulnerable. The
+		 * barrier is not a global or per-process mitigation, so the
+		 * only value we can report here is PR_SPEC_ENABLE, which
+		 * appears as "vulnerable" in /proc.
+		 */
+		return PR_SPEC_ENABLE;
+
+	return -EINVAL;
+}
+
+int arch_prctl_spec_ctrl_get(struct task_struct *task, unsigned long which)
+{
+	switch (which) {
+	case PR_SPEC_STORE_BYPASS:
+		return ssb_prctl_get(task);
+	default:
+		return -ENODEV;
+	}
+}
+
 #ifdef CONFIG_DEBUG_FS
 static int stf_barrier_set(void *data, u64 val)
 {

commit 7794b1d4185e2587af46435e3e2f6696dae314c7
Merge: 9dd0013824fc 2807273f5e88
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 30 14:35:43 2019 -0800

    Merge tag 'powerpc-5.5-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
    
       - Infrastructure for secure boot on some bare metal Power9 machines.
         The firmware support is still in development, so the code here
         won't actually activate secure boot on any existing systems.
    
       - A change to xmon (our crash handler / pseudo-debugger) to restrict
         it to read-only mode when the kernel is lockdown'ed, otherwise it's
         trivial to drop into xmon and modify kernel data, such as the
         lockdown state.
    
       - Support for KASLR on 32-bit BookE machines (Freescale / NXP).
    
       - Fixes for our flush_icache_range() and __kernel_sync_dicache()
         (VDSO) to work with memory ranges >4GB.
    
       - Some reworks of the pseries CMM (Cooperative Memory Management)
         driver to make it behave more like other balloon drivers and enable
         some cleanups of generic mm code.
    
       - A series of fixes to our hardware breakpoint support to properly
         handle unaligned watchpoint addresses.
    
      Plus a bunch of other smaller improvements, fixes and cleanups.
    
      Thanks to: Alastair D'Silva, Andrew Donnellan, Aneesh Kumar K.V,
      Anthony Steinhauser, Cédric Le Goater, Chris Packham, Chris Smart,
      Christophe Leroy, Christopher M. Riedl, Christoph Hellwig, Claudio
      Carvalho, Daniel Axtens, David Hildenbrand, Deb McLemore, Diana
      Craciun, Eric Richter, Geert Uytterhoeven, Greg Kroah-Hartman, Greg
      Kurz, Gustavo L. F. Walbon, Hari Bathini, Harish, Jason Yan, Krzysztof
      Kozlowski, Leonardo Bras, Mathieu Malaterre, Mauro S. M. Rodrigues,
      Michal Suchanek, Mimi Zohar, Nathan Chancellor, Nathan Lynch, Nayna
      Jain, Nick Desaulniers, Oliver O'Halloran, Qian Cai, Rasmus Villemoes,
      Ravi Bangoria, Sam Bobroff, Santosh Sivaraj, Scott Wood, Thomas Huth,
      Tyrel Datwyler, Vaibhav Jain, Valentin Longchamp, YueHaibing"
    
    * tag 'powerpc-5.5-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (144 commits)
      powerpc/fixmap: fix crash with HIGHMEM
      x86/efi: remove unused variables
      powerpc: Define arch_is_kernel_initmem_freed() for lockdep
      powerpc/prom_init: Use -ffreestanding to avoid a reference to bcmp
      powerpc: Avoid clang warnings around setjmp and longjmp
      powerpc: Don't add -mabi= flags when building with Clang
      powerpc: Fix Kconfig indentation
      powerpc/fixmap: don't clear fixmap area in paging_init()
      selftests/powerpc: spectre_v2 test must be built 64-bit
      powerpc/powernv: Disable native PCIe port management
      powerpc/kexec: Move kexec files into a dedicated subdir.
      powerpc/32: Split kexec low level code out of misc_32.S
      powerpc/sysdev: drop simple gpio
      powerpc/83xx: map IMMR with a BAT.
      powerpc/32s: automatically allocate BAT in setbat()
      powerpc/ioremap: warn on early use of ioremap()
      powerpc: Add support for GENERIC_EARLY_IOREMAP
      powerpc/fixmap: Use __fix_to_virt() instead of fix_to_virt()
      powerpc/8xx: use the fixmapped IMMR in cpm_reset()
      powerpc/8xx: add __init to cpm1 init functions
      ...

commit af2e8c68b9c5403f77096969c516f742f5bb29e0
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Nov 13 21:05:44 2019 +1100

    KVM: PPC: Book3S HV: Flush link stack on guest exit to host kernel
    
    On some systems that are vulnerable to Spectre v2, it is up to
    software to flush the link stack (return address stack), in order to
    protect against Spectre-RSB.
    
    When exiting from a guest we do some house keeping and then
    potentially exit to C code which is several stack frames deep in the
    host kernel. We will then execute a series of returns without
    preceeding calls, opening up the possiblity that the guest could have
    poisoned the link stack, and direct speculative execution of the host
    to a gadget of some sort.
    
    To prevent this we add a flush of the link stack on exit from a guest.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index a3138e7d71bb..bd91dceb7010 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -400,6 +400,9 @@ static void toggle_count_cache_flush(bool enable)
 
 	if (!enable) {
 		patch_instruction_site(&patch__call_flush_count_cache, PPC_INST_NOP);
+#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+		patch_instruction_site(&patch__call_kvm_flush_link_stack, PPC_INST_NOP);
+#endif
 		pr_info("link-stack-flush: software flush disabled.\n");
 		link_stack_flush_enabled = false;
 		no_count_cache_flush();
@@ -410,6 +413,12 @@ static void toggle_count_cache_flush(bool enable)
 	patch_branch_site(&patch__call_flush_count_cache,
 			  (u64)&flush_count_cache, BRANCH_SET_LINK);
 
+#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+	// This enables the branch from guest_exit_cont to kvm_flush_link_stack
+	patch_branch_site(&patch__call_kvm_flush_link_stack,
+			  (u64)&kvm_flush_link_stack, BRANCH_SET_LINK);
+#endif
+
 	pr_info("link-stack-flush: software flush enabled.\n");
 	link_stack_flush_enabled = true;
 

commit 39e72bf96f5847ba87cc5bd7a3ce0fed813dc9ad
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Nov 13 21:05:41 2019 +1100

    powerpc/book3s64: Fix link stack flush on context switch
    
    In commit ee13cb249fab ("powerpc/64s: Add support for software count
    cache flush"), I added support for software to flush the count
    cache (indirect branch cache) on context switch if firmware told us
    that was the required mitigation for Spectre v2.
    
    As part of that code we also added a software flush of the link
    stack (return address stack), which protects against Spectre-RSB
    between user processes.
    
    That is all correct for CPUs that activate that mitigation, which is
    currently Power9 Nimbus DD2.3.
    
    What I got wrong is that on older CPUs, where firmware has disabled
    the count cache, we also need to flush the link stack on context
    switch.
    
    To fix it we create a new feature bit which is not set by firmware,
    which tells us we need to flush the link stack. We set that when
    firmware tells us that either of the existing Spectre v2 mitigations
    are enabled.
    
    Then we adjust the patching code so that if we see that feature bit we
    enable the link stack flush. If we're also told to flush the count
    cache in software then we fall through and do that also.
    
    On the older CPUs we don't need to do do the software count cache
    flush, firmware has disabled it, so in that case we patch in an early
    return after the link stack flush.
    
    The naming of some of the functions is awkward after this patch,
    because they're called "count cache" but they also do link stack. But
    we'll fix that up in a later commit to ease backporting.
    
    This is the fix for CVE-2019-18660.
    
    Reported-by: Anthony Steinhauser <asteinhauser@google.com>
    Fixes: ee13cb249fab ("powerpc/64s: Add support for software count cache flush")
    Cc: stable@vger.kernel.org # v4.4+
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 7cfcb294b11c..a3138e7d71bb 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -24,6 +24,7 @@ enum count_cache_flush_type {
 	COUNT_CACHE_FLUSH_HW	= 0x4,
 };
 static enum count_cache_flush_type count_cache_flush_type = COUNT_CACHE_FLUSH_NONE;
+static bool link_stack_flush_enabled;
 
 bool barrier_nospec_enabled;
 static bool no_nospec;
@@ -212,11 +213,19 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 
 		if (ccd)
 			seq_buf_printf(&s, "Indirect branch cache disabled");
+
+		if (link_stack_flush_enabled)
+			seq_buf_printf(&s, ", Software link stack flush");
+
 	} else if (count_cache_flush_type != COUNT_CACHE_FLUSH_NONE) {
 		seq_buf_printf(&s, "Mitigation: Software count cache flush");
 
 		if (count_cache_flush_type == COUNT_CACHE_FLUSH_HW)
 			seq_buf_printf(&s, " (hardware accelerated)");
+
+		if (link_stack_flush_enabled)
+			seq_buf_printf(&s, ", Software link stack flush");
+
 	} else if (btb_flush_enabled) {
 		seq_buf_printf(&s, "Mitigation: Branch predictor state flush");
 	} else {
@@ -377,18 +386,40 @@ static __init int stf_barrier_debugfs_init(void)
 device_initcall(stf_barrier_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
 
+static void no_count_cache_flush(void)
+{
+	count_cache_flush_type = COUNT_CACHE_FLUSH_NONE;
+	pr_info("count-cache-flush: software flush disabled.\n");
+}
+
 static void toggle_count_cache_flush(bool enable)
 {
-	if (!enable || !security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE)) {
+	if (!security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE) &&
+	    !security_ftr_enabled(SEC_FTR_FLUSH_LINK_STACK))
+		enable = false;
+
+	if (!enable) {
 		patch_instruction_site(&patch__call_flush_count_cache, PPC_INST_NOP);
-		count_cache_flush_type = COUNT_CACHE_FLUSH_NONE;
-		pr_info("count-cache-flush: software flush disabled.\n");
+		pr_info("link-stack-flush: software flush disabled.\n");
+		link_stack_flush_enabled = false;
+		no_count_cache_flush();
 		return;
 	}
 
+	// This enables the branch from _switch to flush_count_cache
 	patch_branch_site(&patch__call_flush_count_cache,
 			  (u64)&flush_count_cache, BRANCH_SET_LINK);
 
+	pr_info("link-stack-flush: software flush enabled.\n");
+	link_stack_flush_enabled = true;
+
+	// If we just need to flush the link stack, patch an early return
+	if (!security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE)) {
+		patch_instruction_site(&patch__flush_link_stack_return, PPC_INST_BLR);
+		no_count_cache_flush();
+		return;
+	}
+
 	if (!security_ftr_enabled(SEC_FTR_BCCTR_FLUSH_ASSIST)) {
 		count_cache_flush_type = COUNT_CACHE_FLUSH_SW;
 		pr_info("count-cache-flush: full software flush sequence enabled.\n");
@@ -407,11 +438,20 @@ void setup_count_cache_flush(void)
 	if (no_spectrev2 || cpu_mitigations_off()) {
 		if (security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED) ||
 		    security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED))
-			pr_warn("Spectre v2 mitigations not under software control, can't disable\n");
+			pr_warn("Spectre v2 mitigations not fully under software control, can't disable\n");
 
 		enable = false;
 	}
 
+	/*
+	 * There's no firmware feature flag/hypervisor bit to tell us we need to
+	 * flush the link stack on context switch. So we set it here if we see
+	 * either of the Spectre v2 mitigations that aim to protect userspace.
+	 */
+	if (security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED) ||
+	    security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE))
+		security_ftr_set(SEC_FTR_FLUSH_LINK_STACK);
+
 	toggle_count_cache_flush(enable);
 }
 

commit 090d5ab93d0b8a079dd516c16649bd00ba4f7302
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Nov 29 13:35:18 2018 +0000

    powerpc/64s: Fix debugfs_simple_attr.cocci warnings
    
    Use DEFINE_DEBUGFS_ATTRIBUTE rather than DEFINE_SIMPLE_ATTRIBUTE
    for debugfs files.
    
    Semantic patch information:
    Rationale: DEFINE_SIMPLE_ATTRIBUTE + debugfs_create_file()
    imposes some significant overhead as compared to
    DEFINE_DEBUGFS_ATTRIBUTE + debugfs_create_file_unsafe().
    
    Generated by: scripts/coccinelle/api/debugfs/debugfs_simple_attr.cocci
    
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1543498518-107601-1-git-send-email-yuehaibing@huawei.com

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index faff8c2a0e2f..7d4b2080a658 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -94,13 +94,14 @@ static int barrier_nospec_get(void *data, u64 *val)
 	return 0;
 }
 
-DEFINE_SIMPLE_ATTRIBUTE(fops_barrier_nospec,
-			barrier_nospec_get, barrier_nospec_set, "%llu\n");
+DEFINE_DEBUGFS_ATTRIBUTE(fops_barrier_nospec, barrier_nospec_get,
+			 barrier_nospec_set, "%llu\n");
 
 static __init int barrier_nospec_debugfs_init(void)
 {
-	debugfs_create_file("barrier_nospec", 0600, powerpc_debugfs_root, NULL,
-			    &fops_barrier_nospec);
+	debugfs_create_file_unsafe("barrier_nospec", 0600,
+				   powerpc_debugfs_root, NULL,
+				   &fops_barrier_nospec);
 	return 0;
 }
 device_initcall(barrier_nospec_debugfs_init);
@@ -368,11 +369,13 @@ static int stf_barrier_get(void *data, u64 *val)
 	return 0;
 }
 
-DEFINE_SIMPLE_ATTRIBUTE(fops_stf_barrier, stf_barrier_get, stf_barrier_set, "%llu\n");
+DEFINE_DEBUGFS_ATTRIBUTE(fops_stf_barrier, stf_barrier_get, stf_barrier_set,
+			 "%llu\n");
 
 static __init int stf_barrier_debugfs_init(void)
 {
-	debugfs_create_file("stf_barrier", 0600, powerpc_debugfs_root, NULL, &fops_stf_barrier);
+	debugfs_create_file_unsafe("stf_barrier", 0600, powerpc_debugfs_root,
+				   NULL, &fops_stf_barrier);
 	return 0;
 }
 device_initcall(stf_barrier_debugfs_init);
@@ -443,13 +446,14 @@ static int count_cache_flush_get(void *data, u64 *val)
 	return 0;
 }
 
-DEFINE_SIMPLE_ATTRIBUTE(fops_count_cache_flush, count_cache_flush_get,
-			count_cache_flush_set, "%llu\n");
+DEFINE_DEBUGFS_ATTRIBUTE(fops_count_cache_flush, count_cache_flush_get,
+			 count_cache_flush_set, "%llu\n");
 
 static __init int count_cache_flush_debugfs_init(void)
 {
-	debugfs_create_file("count_cache_flush", 0600, powerpc_debugfs_root,
-			    NULL, &fops_count_cache_flush);
+	debugfs_create_file_unsafe("count_cache_flush", 0600,
+				   powerpc_debugfs_root, NULL,
+				   &fops_count_cache_flush);
 	return 0;
 }
 device_initcall(count_cache_flush_debugfs_init);

commit 4e706af3cd8e1d0503c25332b30cad33c97ed442
Author: Gustavo L. F. Walbon <gwalbon@linux.ibm.com>
Date:   Thu May 2 18:09:07 2019 -0300

    powerpc/security: Fix wrong message when RFI Flush is disable
    
    The issue was showing "Mitigation" message via sysfs whatever the
    state of "RFI Flush", but it should show "Vulnerable" when it is
    disabled.
    
    If you have "L1D private" feature enabled and not "RFI Flush" you are
    vulnerable to meltdown attacks.
    
    "RFI Flush" is the key feature to mitigate the meltdown whatever the
    "L1D private" state.
    
    SEC_FTR_L1D_THREAD_PRIV is a feature for Power9 only.
    
    So the message should be as the truth table shows:
    
      CPU | L1D private | RFI Flush |                sysfs
      ----|-------------|-----------|-------------------------------------
       P9 |    False    |   False   | Vulnerable
       P9 |    False    |   True    | Mitigation: RFI Flush
       P9 |    True     |   False   | Vulnerable: L1D private per thread
       P9 |    True     |   True    | Mitigation: RFI Flush, L1D private per thread
       P8 |    False    |   False   | Vulnerable
       P8 |    False    |   True    | Mitigation: RFI Flush
    
    Output before this fix:
      # cat /sys/devices/system/cpu/vulnerabilities/meltdown
      Mitigation: RFI Flush, L1D private per thread
      # echo 0 > /sys/kernel/debug/powerpc/rfi_flush
      # cat /sys/devices/system/cpu/vulnerabilities/meltdown
      Mitigation: L1D private per thread
    
    Output after fix:
      # cat /sys/devices/system/cpu/vulnerabilities/meltdown
      Mitigation: RFI Flush, L1D private per thread
      # echo 0 > /sys/kernel/debug/powerpc/rfi_flush
      # cat /sys/devices/system/cpu/vulnerabilities/meltdown
      Vulnerable: L1D private per thread
    
    Signed-off-by: Gustavo L. F. Walbon <gwalbon@linux.ibm.com>
    Signed-off-by: Mauro S. M. Rodrigues <maurosr@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190502210907.42375-1-gwalbon@linux.ibm.com

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index a3021e6faed8..faff8c2a0e2f 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -141,26 +141,22 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 	thread_priv = security_ftr_enabled(SEC_FTR_L1D_THREAD_PRIV);
 
-	if (rfi_flush || thread_priv) {
+	if (rfi_flush) {
 		struct seq_buf s;
 		seq_buf_init(&s, buf, PAGE_SIZE - 1);
 
-		seq_buf_printf(&s, "Mitigation: ");
-
-		if (rfi_flush)
-			seq_buf_printf(&s, "RFI Flush");
-
-		if (rfi_flush && thread_priv)
-			seq_buf_printf(&s, ", ");
-
+		seq_buf_printf(&s, "Mitigation: RFI Flush");
 		if (thread_priv)
-			seq_buf_printf(&s, "L1D private per thread");
+			seq_buf_printf(&s, ", L1D private per thread");
 
 		seq_buf_printf(&s, "\n");
 
 		return s.len;
 	}
 
+	if (thread_priv)
+		return sprintf(buf, "Vulnerable: L1D private per thread\n");
+
 	if (!security_ftr_enabled(SEC_FTR_L1D_FLUSH_HV) &&
 	    !security_ftr_enabled(SEC_FTR_L1D_FLUSH_PR))
 		return sprintf(buf, "Not affected\n");

commit 3b05a1e517e1a8cfda4866ec31d28b2bc4fee4c4
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Mon Oct 21 16:23:09 2019 +0200

    powerpc/security: Fix debugfs data leak on 32-bit
    
    "powerpc_security_features" is "unsigned long", i.e. 32-bit or 64-bit,
    depending on the platform (PPC_FSL_BOOK3E or PPC_BOOK3S_64).  Hence
    casting its address to "u64 *", and calling debugfs_create_x64() is
    wrong, and leaks 32-bit of nearby data to userspace on 32-bit platforms.
    
    While all currently defined SEC_FTR_* security feature flags fit in
    32-bit, they all have "ULL" suffixes to make them 64-bit constants.
    Hence fix the leak by changing the type of "powerpc_security_features"
    (and the parameter types of its accessors) to "u64".  This also allows
    to drop the cast.
    
    Fixes: 398af571128fe75f ("powerpc/security: Show powerpc_security_features in debugfs")
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20191021142309.28105-1-geert+renesas@glider.be

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index ad7f4bf8447c..a3021e6faed8 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -16,7 +16,7 @@
 #include <asm/setup.h>
 
 
-unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
+u64 powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
 enum count_cache_flush_type {
 	COUNT_CACHE_FLUSH_NONE	= 0x1,
@@ -108,7 +108,7 @@ device_initcall(barrier_nospec_debugfs_init);
 static __init int security_feature_debugfs_init(void)
 {
 	debugfs_create_x64("security_features", 0400, powerpc_debugfs_root,
-			   (u64 *)&powerpc_security_features);
+			   &powerpc_security_features);
 	return 0;
 }
 device_initcall(security_feature_debugfs_init);

commit 8e6b6da91ac9b9ec5a925b6cb13f287a54bd547d
Author: Anthony Steinhauser <asteinhauser@google.com>
Date:   Tue Oct 29 12:07:59 2019 -0700

    powerpc/security/book3s64: Report L1TF status in sysfs
    
    Some PowerPC CPUs are vulnerable to L1TF to the same extent as to
    Meltdown. It is also mitigated by flushing the L1D on privilege
    transition.
    
    Currently the sysfs gives a false negative on L1TF on CPUs that I
    verified to be vulnerable, a Power9 Talos II Boston 004e 1202, PowerNV
    T2P9D01.
    
    Signed-off-by: Anthony Steinhauser <asteinhauser@google.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    [mpe: Just have cpu_show_l1tf() call cpu_show_meltdown() directly]
    Link: https://lore.kernel.org/r/20191029190759.84821-1-asteinhauser@google.com

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 7cfcb294b11c..ad7f4bf8447c 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -167,6 +167,11 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 	return sprintf(buf, "Vulnerable\n");
 }
+
+ssize_t cpu_show_l1tf(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	return cpu_show_meltdown(dev, attr, buf);
+}
 #endif
 
 ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)

commit d8f0e0b073e1ec52a05f0c2a56318b47387d2f10
Author: Christopher M. Riedl <cmr@informatik.wtf>
Date:   Thu May 23 21:46:48 2019 -0500

    powerpc/64s: support nospectre_v2 cmdline option
    
    Add support for disabling the kernel implemented spectre v2 mitigation
    (count cache flush on context switch) via the nospectre_v2 and
    mitigations=off cmdline options.
    
    Suggested-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Christopher M. Riedl <cmr@informatik.wtf>
    Reviewed-by: Andrew Donnellan <ajd@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190524024647.381-1-cmr@informatik.wtf

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index e1c9cf079503..7cfcb294b11c 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -28,7 +28,7 @@ static enum count_cache_flush_type count_cache_flush_type = COUNT_CACHE_FLUSH_NO
 bool barrier_nospec_enabled;
 static bool no_nospec;
 static bool btb_flush_enabled;
-#ifdef CONFIG_PPC_FSL_BOOK3E
+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_BOOK3S_64)
 static bool no_spectrev2;
 #endif
 
@@ -114,7 +114,7 @@ static __init int security_feature_debugfs_init(void)
 device_initcall(security_feature_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
 
-#ifdef CONFIG_PPC_FSL_BOOK3E
+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_BOOK3S_64)
 static int __init handle_nospectre_v2(char *p)
 {
 	no_spectrev2 = true;
@@ -122,6 +122,9 @@ static int __init handle_nospectre_v2(char *p)
 	return 0;
 }
 early_param("nospectre_v2", handle_nospectre_v2);
+#endif /* CONFIG_PPC_FSL_BOOK3E || CONFIG_PPC_BOOK3S_64 */
+
+#ifdef CONFIG_PPC_FSL_BOOK3E
 void setup_spectre_v2(void)
 {
 	if (no_spectrev2 || cpu_mitigations_off())
@@ -399,7 +402,17 @@ static void toggle_count_cache_flush(bool enable)
 
 void setup_count_cache_flush(void)
 {
-	toggle_count_cache_flush(true);
+	bool enable = true;
+
+	if (no_spectrev2 || cpu_mitigations_off()) {
+		if (security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED) ||
+		    security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED))
+			pr_warn("Spectre v2 mitigations not under software control, can't disable\n");
+
+		enable = false;
+	}
+
+	toggle_count_cache_flush(enable);
 }
 
 #ifdef CONFIG_DEBUG_FS

commit b970afcfcabd63cd3832e95db096439c177c3592
Merge: 8ea5b2abd07e 8150a153c013
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 10 05:29:27 2019 -0700

    Merge tag 'powerpc-5.2-1' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Slightly delayed due to the issue with printk() calling
      probe_kernel_read() interacting with our new user access prevention
      stuff, but all fixed now.
    
      The only out-of-area changes are the addition of a cpuhp_state, small
      additions to Documentation and MAINTAINERS updates.
    
      Highlights:
    
       - Support for Kernel Userspace Access/Execution Prevention (like
         SMAP/SMEP/PAN/PXN) on some 64-bit and 32-bit CPUs. This prevents
         the kernel from accidentally accessing userspace outside
         copy_to/from_user(), or ever executing userspace.
    
       - KASAN support on 32-bit.
    
       - Rework of where we map the kernel, vmalloc, etc. on 64-bit hash to
         use the same address ranges we use with the Radix MMU.
    
       - A rewrite into C of large parts of our idle handling code for
         64-bit Book3S (ie. power8 & power9).
    
       - A fast path entry for syscalls on 32-bit CPUs, for a 12-17% speedup
         in the null_syscall benchmark.
    
       - On 64-bit bare metal we have support for recovering from errors
         with the time base (our clocksource), however if that fails
         currently we hang in __delay() and never crash. We now have support
         for detecting that case and short circuiting __delay() so we at
         least panic() and reboot.
    
       - Add support for optionally enabling the DAWR on Power9, which had
         to be disabled by default due to a hardware erratum. This has the
         effect of enabling hardware breakpoints for GDB, the downside is a
         badly behaved program could crash the machine by pointing the DAWR
         at cache inhibited memory. This is opt-in obviously.
    
       - xmon, our crash handler, gets support for a read only mode where
         operations that could change memory or otherwise disturb the system
         are disabled.
    
      Plus many clean-ups, reworks and minor fixes etc.
    
      Thanks to: Christophe Leroy, Akshay Adiga, Alastair D'Silva, Alexey
      Kardashevskiy, Andrew Donnellan, Aneesh Kumar K.V, Anju T Sudhakar,
      Anton Blanchard, Ben Hutchings, Bo YU, Breno Leitao, Cédric Le Goater,
      Christopher M. Riedl, Christoph Hellwig, Colin Ian King, David Gibson,
      Ganesh Goudar, Gautham R. Shenoy, George Spelvin, Greg Kroah-Hartman,
      Greg Kurz, Horia Geantă, Jagadeesh Pagadala, Joel Stanley, Joe
      Perches, Julia Lawall, Laurentiu Tudor, Laurent Vivier, Lukas Bulwahn,
      Madhavan Srinivasan, Mahesh Salgaonkar, Mathieu Malaterre, Michael
      Neuling, Mukesh Ojha, Nathan Fontenot, Nathan Lynch, Nicholas Piggin,
      Nick Desaulniers, Oliver O'Halloran, Peng Hao, Qian Cai, Ravi
      Bangoria, Rick Lindsley, Russell Currey, Sachin Sant, Stewart Smith,
      Sukadev Bhattiprolu, Thomas Huth, Tobin C. Harding, Tyrel Datwyler,
      Valentin Schneider, Wei Yongjun, Wen Yang, YueHaibing"
    
    * tag 'powerpc-5.2-1' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (205 commits)
      powerpc/64s: Use early_mmu_has_feature() in set_kuap()
      powerpc/book3s/64: check for NULL pointer in pgd_alloc()
      powerpc/mm: Fix hugetlb page initialization
      ocxl: Fix return value check in afu_ioctl()
      powerpc/mm: fix section mismatch for setup_kup()
      powerpc/mm: fix redundant inclusion of pgtable-frag.o in Makefile
      powerpc/mm: Fix makefile for KASAN
      powerpc/kasan: add missing/lost Makefile
      selftests/powerpc: Add a signal fuzzer selftest
      powerpc/booke64: set RI in default MSR
      ocxl: Provide global MMIO accessors for external drivers
      ocxl: move event_fd handling to frontend
      ocxl: afu_irq only deals with IRQ IDs, not offsets
      ocxl: Allow external drivers to use OpenCAPI contexts
      ocxl: Create a clear delineation between ocxl backend & frontend
      ocxl: Don't pass pci_dev around
      ocxl: Split pci.c
      ocxl: Remove some unused exported symbols
      ocxl: Remove superfluous 'extern' from headers
      ocxl: read_pasid never returns an error, so make it void
      ...

commit 0a499fc5c37e6db096969a83534fd98a2bf2b36c
Merge: e50c5d2e725e 0336e04a6520
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 6 13:01:16 2019 -0700

    Merge branch 'core-speculation-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull speculation mitigation update from Ingo Molnar:
     "This adds the "mitigations=" bootline option, which offers a
      cross-arch set of options that will work on x86, PowerPC and s390 that
      will map to the arch specific option internally"
    
    * 'core-speculation-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      s390/speculation: Support 'mitigations=' cmdline option
      powerpc/speculation: Support 'mitigations=' cmdline option
      x86/speculation: Support 'mitigations=' cmdline option
      cpu/speculation: Add 'mitigations=' cmdline option

commit 398af571128fe75f07343f929975b26d57eafd18
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Apr 9 23:14:20 2019 +1000

    powerpc/security: Show powerpc_security_features in debugfs
    
    This can be helpful for debugging problems with the security feature
    flags, especially on guests where the flags come from the hypervisor
    via an hcall and so can't be observed in the device tree.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Joel Stanley <joel@jms.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index b33bafb8fcea..d6ba696d0ed0 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -104,6 +104,14 @@ static __init int barrier_nospec_debugfs_init(void)
 	return 0;
 }
 device_initcall(barrier_nospec_debugfs_init);
+
+static __init int security_feature_debugfs_init(void)
+{
+	debugfs_create_x64("security_features", 0400, powerpc_debugfs_root,
+			   (u64 *)&powerpc_security_features);
+	return 0;
+}
+device_initcall(security_feature_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
 
 #ifdef CONFIG_PPC_FSL_BOOK3E

commit 782e69efb3dfed6e8360bc612e8c7827a901a8f9
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Fri Apr 12 15:39:30 2019 -0500

    powerpc/speculation: Support 'mitigations=' cmdline option
    
    Configure powerpc CPU runtime speculation bug mitigations in accordance
    with the 'mitigations=' cmdline option.  This affects Meltdown, Spectre
    v1, Spectre v2, and Speculative Store Bypass.
    
    The default behavior is unchanged.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Jiri Kosina <jkosina@suse.cz> (on x86)
    Reviewed-by: Jiri Kosina <jkosina@suse.cz>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: "H . Peter Anvin" <hpa@zytor.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Jiri Kosina <jikos@kernel.org>
    Cc: Waiman Long <longman@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Jon Masters <jcm@redhat.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux-s390@vger.kernel.org
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-arch@vger.kernel.org
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Tyler Hicks <tyhicks@canonical.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Steven Price <steven.price@arm.com>
    Cc: Phil Auld <pauld@redhat.com>
    Link: https://lkml.kernel.org/r/245a606e1a42a558a310220312d9b6adb9159df6.1555085500.git.jpoimboe@redhat.com

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 9b8631533e02..cdf3e73000e9 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -57,7 +57,7 @@ void setup_barrier_nospec(void)
 	enable = security_ftr_enabled(SEC_FTR_FAVOUR_SECURITY) &&
 		 security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR);
 
-	if (!no_nospec)
+	if (!no_nospec && !cpu_mitigations_off())
 		enable_barrier_nospec(enable);
 }
 
@@ -116,7 +116,7 @@ static int __init handle_nospectre_v2(char *p)
 early_param("nospectre_v2", handle_nospectre_v2);
 void setup_spectre_v2(void)
 {
-	if (no_spectrev2)
+	if (no_spectrev2 || cpu_mitigations_off())
 		do_btb_flush_fixups();
 	else
 		btb_flush_enabled = true;
@@ -307,7 +307,7 @@ void setup_stf_barrier(void)
 
 	stf_enabled_flush_types = type;
 
-	if (!no_stf_barrier)
+	if (!no_stf_barrier && !cpu_mitigations_off())
 		stf_barrier_enable(enable);
 }
 

commit 92edf8df0ff2ae86cc632eeca0e651fd8431d40d
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 21 15:24:33 2019 +1100

    powerpc/security: Fix spectre_v2 reporting
    
    When I updated the spectre_v2 reporting to handle software count cache
    flush I got the logic wrong when there's no software count cache
    enabled at all.
    
    The result is that on systems with the software count cache flush
    disabled we print:
    
      Mitigation: Indirect branch cache disabled, Software count cache flush
    
    Which correctly indicates that the count cache is disabled, but
    incorrectly says the software count cache flush is enabled.
    
    The root of the problem is that we are trying to handle all
    combinations of options. But we know now that we only expect to see
    the software count cache flush enabled if the other options are false.
    
    So split the two cases, which simplifies the logic and fixes the bug.
    We were also missing a space before "(hardware accelerated)".
    
    The result is we see one of:
    
      Mitigation: Indirect branch serialisation (kernel only)
      Mitigation: Indirect branch cache disabled
      Mitigation: Software count cache flush
      Mitigation: Software count cache flush (hardware accelerated)
    
    Fixes: ee13cb249fab ("powerpc/64s: Add support for software count cache flush")
    Cc: stable@vger.kernel.org # v4.19+
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Reviewed-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 9b8631533e02..b33bafb8fcea 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -190,29 +190,22 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 	bcs = security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED);
 	ccd = security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED);
 
-	if (bcs || ccd || count_cache_flush_type != COUNT_CACHE_FLUSH_NONE) {
-		bool comma = false;
+	if (bcs || ccd) {
 		seq_buf_printf(&s, "Mitigation: ");
 
-		if (bcs) {
+		if (bcs)
 			seq_buf_printf(&s, "Indirect branch serialisation (kernel only)");
-			comma = true;
-		}
 
-		if (ccd) {
-			if (comma)
-				seq_buf_printf(&s, ", ");
-			seq_buf_printf(&s, "Indirect branch cache disabled");
-			comma = true;
-		}
-
-		if (comma)
+		if (bcs && ccd)
 			seq_buf_printf(&s, ", ");
 
-		seq_buf_printf(&s, "Software count cache flush");
+		if (ccd)
+			seq_buf_printf(&s, "Indirect branch cache disabled");
+	} else if (count_cache_flush_type != COUNT_CACHE_FLUSH_NONE) {
+		seq_buf_printf(&s, "Mitigation: Software count cache flush");
 
 		if (count_cache_flush_type == COUNT_CACHE_FLUSH_HW)
-			seq_buf_printf(&s, "(hardware accelerated)");
+			seq_buf_printf(&s, " (hardware accelerated)");
 	} else if (btb_flush_enabled) {
 		seq_buf_printf(&s, "Mitigation: Branch predictor state flush");
 	} else {

commit dfa88658fb0583abb92e062c7a9cd5a5b94f2a46
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Wed Dec 12 16:03:09 2018 +0200

    powerpc/fsl: Update Spectre v2 reporting
    
    Report branch predictor state flush as a mitigation for
    Spectre variant 2.
    
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 9ab771b1aebb..9b8631533e02 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -213,8 +213,11 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 
 		if (count_cache_flush_type == COUNT_CACHE_FLUSH_HW)
 			seq_buf_printf(&s, "(hardware accelerated)");
-	} else
+	} else if (btb_flush_enabled) {
+		seq_buf_printf(&s, "Mitigation: Branch predictor state flush");
+	} else {
 		seq_buf_printf(&s, "Vulnerable");
+	}
 
 	seq_buf_printf(&s, "\n");
 

commit f633a8ad636efb5d4bba1a047d4a0f1ef719aa06
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Wed Dec 12 16:03:04 2018 +0200

    powerpc/fsl: Add nospectre_v2 command line argument
    
    When the command line argument is present, the Spectre variant 2
    mitigations are disabled.
    
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 9e5f949a7ed8..9ab771b1aebb 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -27,6 +27,10 @@ static enum count_cache_flush_type count_cache_flush_type = COUNT_CACHE_FLUSH_NO
 
 bool barrier_nospec_enabled;
 static bool no_nospec;
+static bool btb_flush_enabled;
+#ifdef CONFIG_PPC_FSL_BOOK3E
+static bool no_spectrev2;
+#endif
 
 static void enable_barrier_nospec(bool enable)
 {
@@ -102,6 +106,23 @@ static __init int barrier_nospec_debugfs_init(void)
 device_initcall(barrier_nospec_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
 
+#ifdef CONFIG_PPC_FSL_BOOK3E
+static int __init handle_nospectre_v2(char *p)
+{
+	no_spectrev2 = true;
+
+	return 0;
+}
+early_param("nospectre_v2", handle_nospectre_v2);
+void setup_spectre_v2(void)
+{
+	if (no_spectrev2)
+		do_btb_flush_fixups();
+	else
+		btb_flush_enabled = true;
+}
+#endif /* CONFIG_PPC_FSL_BOOK3E */
+
 #ifdef CONFIG_PPC_BOOK3S_64
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {

commit 7d8bad99ba5a22892f0cad6881289fdc3875a930
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Wed Dec 12 16:03:02 2018 +0200

    powerpc/fsl: Fix spectre_v2 mitigations reporting
    
    Currently for CONFIG_PPC_FSL_BOOK3E the spectre_v2 file is incorrect:
    
      $ cat /sys/devices/system/cpu/vulnerabilities/spectre_v2
      "Mitigation: Software count cache flush"
    
    Which is wrong. Fix it to report vulnerable for now.
    
    Fixes: ee13cb249fab ("powerpc/64s: Add support for software count cache flush")
    Cc: stable@vger.kernel.org # v4.19+
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 9703dce36307..9e5f949a7ed8 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -23,7 +23,7 @@ enum count_cache_flush_type {
 	COUNT_CACHE_FLUSH_SW	= 0x2,
 	COUNT_CACHE_FLUSH_HW	= 0x4,
 };
-static enum count_cache_flush_type count_cache_flush_type;
+static enum count_cache_flush_type count_cache_flush_type = COUNT_CACHE_FLUSH_NONE;
 
 bool barrier_nospec_enabled;
 static bool no_nospec;

commit 42e2acde1237878462b028f5a27d9cc5bea7502c
Author: Breno Leitao <leitao@debian.org>
Date:   Mon Oct 22 11:54:12 2018 -0300

    powerpc/64s: Include cpu header
    
    Current powerpc security.c file is defining functions, as
    cpu_show_meltdown(), cpu_show_spectre_v{1,2} and others, that are being
    declared at linux/cpu.h header without including the header file that
    contains these declarations.
    
    This is being reported by sparse, which thinks that these functions are
    static, due to the lack of declaration:
    
            arch/powerpc/kernel/security.c:105:9: warning: symbol 'cpu_show_meltdown' was not declared. Should it be static?
            arch/powerpc/kernel/security.c:139:9: warning: symbol 'cpu_show_spectre_v1' was not declared. Should it be static?
            arch/powerpc/kernel/security.c:161:9: warning: symbol 'cpu_show_spectre_v2' was not declared. Should it be static?
            arch/powerpc/kernel/security.c:209:6: warning: symbol 'stf_barrier' was not declared. Should it be static?
            arch/powerpc/kernel/security.c:289:9: warning: symbol 'cpu_show_spec_store_bypass' was not declared. Should it be static?
    
    This patch simply includes the proper header (linux/cpu.h) to match
    function definition and declaration.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index f6f469fc4073..9703dce36307 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -4,6 +4,7 @@
 //
 // Copyright 2018, Michael Ellerman, IBM Corporation.
 
+#include <linux/cpu.h>
 #include <linux/kernel.h>
 #include <linux/device.h>
 #include <linux/seq_buf.h>

commit ee13cb249fabdff8b90aaff61add347749280087
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Jul 24 01:07:54 2018 +1000

    powerpc/64s: Add support for software count cache flush
    
    Some CPU revisions support a mode where the count cache needs to be
    flushed by software on context switch. Additionally some revisions may
    have a hardware accelerated flush, in which case the software flush
    sequence can be shortened.
    
    If we detect the appropriate flag from firmware we patch a branch
    into _switch() which takes us to a count cache flush sequence.
    
    That sequence in turn may be patched to return early if we detect that
    the CPU supports accelerating the flush sequence in hardware.
    
    Add debugfs support for reporting the state of the flush, as well as
    runtime disabling it.
    
    And modify the spectre_v2 sysfs file to report the state of the
    software flush.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 206488603b66..f6f469fc4073 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -8,6 +8,8 @@
 #include <linux/device.h>
 #include <linux/seq_buf.h>
 
+#include <asm/asm-prototypes.h>
+#include <asm/code-patching.h>
 #include <asm/debugfs.h>
 #include <asm/security_features.h>
 #include <asm/setup.h>
@@ -15,6 +17,13 @@
 
 unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
+enum count_cache_flush_type {
+	COUNT_CACHE_FLUSH_NONE	= 0x1,
+	COUNT_CACHE_FLUSH_SW	= 0x2,
+	COUNT_CACHE_FLUSH_HW	= 0x4,
+};
+static enum count_cache_flush_type count_cache_flush_type;
+
 bool barrier_nospec_enabled;
 static bool no_nospec;
 
@@ -159,17 +168,29 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 	bcs = security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED);
 	ccd = security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED);
 
-	if (bcs || ccd) {
+	if (bcs || ccd || count_cache_flush_type != COUNT_CACHE_FLUSH_NONE) {
+		bool comma = false;
 		seq_buf_printf(&s, "Mitigation: ");
 
-		if (bcs)
+		if (bcs) {
 			seq_buf_printf(&s, "Indirect branch serialisation (kernel only)");
+			comma = true;
+		}
+
+		if (ccd) {
+			if (comma)
+				seq_buf_printf(&s, ", ");
+			seq_buf_printf(&s, "Indirect branch cache disabled");
+			comma = true;
+		}
 
-		if (bcs && ccd)
+		if (comma)
 			seq_buf_printf(&s, ", ");
 
-		if (ccd)
-			seq_buf_printf(&s, "Indirect branch cache disabled");
+		seq_buf_printf(&s, "Software count cache flush");
+
+		if (count_cache_flush_type == COUNT_CACHE_FLUSH_HW)
+			seq_buf_printf(&s, "(hardware accelerated)");
 	} else
 		seq_buf_printf(&s, "Vulnerable");
 
@@ -326,4 +347,71 @@ static __init int stf_barrier_debugfs_init(void)
 }
 device_initcall(stf_barrier_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
+
+static void toggle_count_cache_flush(bool enable)
+{
+	if (!enable || !security_ftr_enabled(SEC_FTR_FLUSH_COUNT_CACHE)) {
+		patch_instruction_site(&patch__call_flush_count_cache, PPC_INST_NOP);
+		count_cache_flush_type = COUNT_CACHE_FLUSH_NONE;
+		pr_info("count-cache-flush: software flush disabled.\n");
+		return;
+	}
+
+	patch_branch_site(&patch__call_flush_count_cache,
+			  (u64)&flush_count_cache, BRANCH_SET_LINK);
+
+	if (!security_ftr_enabled(SEC_FTR_BCCTR_FLUSH_ASSIST)) {
+		count_cache_flush_type = COUNT_CACHE_FLUSH_SW;
+		pr_info("count-cache-flush: full software flush sequence enabled.\n");
+		return;
+	}
+
+	patch_instruction_site(&patch__flush_count_cache_return, PPC_INST_BLR);
+	count_cache_flush_type = COUNT_CACHE_FLUSH_HW;
+	pr_info("count-cache-flush: hardware assisted flush sequence enabled\n");
+}
+
+void setup_count_cache_flush(void)
+{
+	toggle_count_cache_flush(true);
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int count_cache_flush_set(void *data, u64 val)
+{
+	bool enable;
+
+	if (val == 1)
+		enable = true;
+	else if (val == 0)
+		enable = false;
+	else
+		return -EINVAL;
+
+	toggle_count_cache_flush(enable);
+
+	return 0;
+}
+
+static int count_cache_flush_get(void *data, u64 *val)
+{
+	if (count_cache_flush_type == COUNT_CACHE_FLUSH_NONE)
+		*val = 0;
+	else
+		*val = 1;
+
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_count_cache_flush, count_cache_flush_get,
+			count_cache_flush_set, "%llu\n");
+
+static __init int count_cache_flush_debugfs_init(void)
+{
+	debugfs_create_file("count_cache_flush", 0600, powerpc_debugfs_root,
+			    NULL, &fops_count_cache_flush);
+	return 0;
+}
+device_initcall(count_cache_flush_debugfs_init);
+#endif /* CONFIG_DEBUG_FS */
 #endif /* CONFIG_PPC_BOOK3S_64 */

commit 406d2b6ae3420f5bb2b3db6986dc6f0b6dbb637b
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Sat Jul 28 09:06:36 2018 +1000

    powerpc/64: Make meltdown reporting Book3S 64 specific
    
    In a subsequent patch we will enable building security.c for Book3E.
    However the NXP platforms are not vulnerable to Meltdown, so make the
    Meltdown vulnerability reporting PPC_BOOK3S_64 specific.
    
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 8ee1ade845c6..206488603b66 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -92,6 +92,7 @@ static __init int barrier_nospec_debugfs_init(void)
 device_initcall(barrier_nospec_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
 
+#ifdef CONFIG_PPC_BOOK3S_64
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	bool thread_priv;
@@ -124,6 +125,7 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 	return sprintf(buf, "Vulnerable\n");
 }
+#endif
 
 ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)
 {

commit 6453b532f2c8856a80381e6b9a1f5ea2f12294df
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Sat Jul 28 09:06:33 2018 +1000

    powerpc/64: Make stf barrier PPC_BOOK3S_64 specific.
    
    NXP Book3E platforms are not vulnerable to speculative store
    bypass, so make the mitigations PPC_BOOK3S_64 specific.
    
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 79f9397998ed..8ee1ade845c6 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -176,6 +176,7 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 	return s.len;
 }
 
+#ifdef CONFIG_PPC_BOOK3S_64
 /*
  * Store-forwarding barrier support.
  */
@@ -323,3 +324,4 @@ static __init int stf_barrier_debugfs_init(void)
 }
 device_initcall(stf_barrier_debugfs_init);
 #endif /* CONFIG_DEBUG_FS */
+#endif /* CONFIG_PPC_BOOK3S_64 */

commit cf175dc315f90185128fb061dc05b6fbb211aa2f
Author: Diana Craciun <diana.craciun@nxp.com>
Date:   Sat Jul 28 09:06:32 2018 +1000

    powerpc/64: Disable the speculation barrier from the command line
    
    The speculation barrier can be disabled from the command line
    with the parameter: "nospectre_v1".
    
    Signed-off-by: Diana Craciun <diana.craciun@nxp.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 4cb8f1f7b593..79f9397998ed 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -16,6 +16,7 @@
 unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
 bool barrier_nospec_enabled;
+static bool no_nospec;
 
 static void enable_barrier_nospec(bool enable)
 {
@@ -42,9 +43,18 @@ void setup_barrier_nospec(void)
 	enable = security_ftr_enabled(SEC_FTR_FAVOUR_SECURITY) &&
 		 security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR);
 
-	enable_barrier_nospec(enable);
+	if (!no_nospec)
+		enable_barrier_nospec(enable);
 }
 
+static int __init handle_nospectre_v1(char *p)
+{
+	no_nospec = true;
+
+	return 0;
+}
+early_param("nospectre_v1", handle_nospectre_v1);
+
 #ifdef CONFIG_DEBUG_FS
 static int barrier_nospec_set(void *data, u64 val)
 {

commit 6d44acae1937b81cf8115ada8958e04f601f3f2e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Jul 9 16:25:21 2018 +1000

    powerpc64s: Show ori31 availability in spectre_v1 sysfs file not v2
    
    When I added the spectre_v2 information in sysfs, I included the
    availability of the ori31 speculation barrier.
    
    Although the ori31 barrier can be used to mitigate v2, it's primarily
    intended as a spectre v1 mitigation. Spectre v2 is mitigated by
    hardware changes.
    
    So rework the sysfs files to show the ori31 information in the
    spectre_v1 file, rather than v2.
    
    Currently we display eg:
    
      $ grep . spectre_v*
      spectre_v1:Mitigation: __user pointer sanitization
      spectre_v2:Mitigation: Indirect branch cache disabled, ori31 speculation barrier enabled
    
    After:
    
      $ grep . spectre_v*
      spectre_v1:Mitigation: __user pointer sanitization, ori31 speculation barrier enabled
      spectre_v2:Mitigation: Indirect branch cache disabled
    
    Fixes: d6fbe1c55c55 ("powerpc/64s: Wire up cpu_show_spectre_v2()")
    Cc: stable@vger.kernel.org # v4.17+
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index a8b277362931..4cb8f1f7b593 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -117,25 +117,35 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)
 {
-	if (!security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR))
-		return sprintf(buf, "Not affected\n");
+	struct seq_buf s;
+
+	seq_buf_init(&s, buf, PAGE_SIZE - 1);
 
-	if (barrier_nospec_enabled)
-		return sprintf(buf, "Mitigation: __user pointer sanitization\n");
+	if (security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR)) {
+		if (barrier_nospec_enabled)
+			seq_buf_printf(&s, "Mitigation: __user pointer sanitization");
+		else
+			seq_buf_printf(&s, "Vulnerable");
 
-	return sprintf(buf, "Vulnerable\n");
+		if (security_ftr_enabled(SEC_FTR_SPEC_BAR_ORI31))
+			seq_buf_printf(&s, ", ori31 speculation barrier enabled");
+
+		seq_buf_printf(&s, "\n");
+	} else
+		seq_buf_printf(&s, "Not affected\n");
+
+	return s.len;
 }
 
 ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, char *buf)
 {
-	bool bcs, ccd, ori;
 	struct seq_buf s;
+	bool bcs, ccd;
 
 	seq_buf_init(&s, buf, PAGE_SIZE - 1);
 
 	bcs = security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED);
 	ccd = security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED);
-	ori = security_ftr_enabled(SEC_FTR_SPEC_BAR_ORI31);
 
 	if (bcs || ccd) {
 		seq_buf_printf(&s, "Mitigation: ");
@@ -151,9 +161,6 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 	} else
 		seq_buf_printf(&s, "Vulnerable");
 
-	if (ori)
-		seq_buf_printf(&s, ", ori31 speculation barrier enabled");
-
 	seq_buf_printf(&s, "\n");
 
 	return s.len;

commit c90fca951e90ba470a3dc6087667edffcf8db21b
Merge: c0ab85267e25 ff5bc793e47b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 7 10:23:33 2018 -0700

    Merge tag 'powerpc-4.18-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Support for split PMD page table lock on 64-bit Book3S (Power8/9).
    
       - Add support for HAVE_RELIABLE_STACKTRACE, so we properly support
         live patching again.
    
       - Add support for patching barrier_nospec in copy_from_user() and
         syscall entry.
    
       - A couple of fixes for our data breakpoints on Book3S.
    
       - A series from Nick optimising TLB/mm handling with the Radix MMU.
    
       - Numerous small cleanups to squash sparse/gcc warnings from Mathieu
         Malaterre.
    
       - Several series optimising various parts of the 32-bit code from
         Christophe Leroy.
    
       - Removal of support for two old machines, "SBC834xE" and "C2K"
         ("GEFanuc,C2K"), which is why the diffstat has so many deletions.
    
      And many other small improvements & fixes.
    
      There's a few out-of-area changes. Some minor ftrace changes OK'ed by
      Steve, and a fix to our powernv cpuidle driver. Then there's a series
      touching mm, x86 and fs/proc/task_mmu.c, which cleans up some details
      around pkey support. It was ack'ed/reviewed by Ingo & Dave and has
      been in next for several weeks.
    
      Thanks to: Akshay Adiga, Alastair D'Silva, Alexey Kardashevskiy, Al
      Viro, Andrew Donnellan, Aneesh Kumar K.V, Anju T Sudhakar, Arnd
      Bergmann, Balbir Singh, Cédric Le Goater, Christophe Leroy, Christophe
      Lombard, Colin Ian King, Dave Hansen, Fabio Estevam, Finn Thain,
      Frederic Barrat, Gautham R. Shenoy, Haren Myneni, Hari Bathini, Ingo
      Molnar, Jonathan Neuschäfer, Josh Poimboeuf, Kamalesh Babulal,
      Madhavan Srinivasan, Mahesh Salgaonkar, Mark Greer, Mathieu Malaterre,
      Matthew Wilcox, Michael Neuling, Michal Suchanek, Naveen N. Rao,
      Nicholas Piggin, Nicolai Stange, Olof Johansson, Paul Gortmaker, Paul
      Mackerras, Peter Rosin, Pridhiviraj Paidipeddi, Ram Pai, Rashmica
      Gupta, Ravi Bangoria, Russell Currey, Sam Bobroff, Samuel
      Mendoza-Jonas, Segher Boessenkool, Shilpasri G Bhat, Simon Guo,
      Souptick Joarder, Stewart Smith, Thiago Jung Bauermann, Torsten Duwe,
      Vaibhav Jain, Wei Yongjun, Wolfram Sang, Yisheng Xie, YueHaibing"
    
    * tag 'powerpc-4.18-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (251 commits)
      powerpc/64s/radix: Fix missing ptesync in flush_cache_vmap
      cpuidle: powernv: Fix promotion from snooze if next state disabled
      powerpc: fix build failure by disabling attribute-alias warning in pci_32
      ocxl: Fix missing unlock on error in afu_ioctl_enable_p9_wait()
      powerpc-opal: fix spelling mistake "Uniterrupted" -> "Uninterrupted"
      powerpc: fix spelling mistake: "Usupported" -> "Unsupported"
      powerpc/pkeys: Detach execute_only key on !PROT_EXEC
      powerpc/powernv: copy/paste - Mask SO bit in CR
      powerpc: Remove core support for Marvell mv64x60 hostbridges
      powerpc/boot: Remove core support for Marvell mv64x60 hostbridges
      powerpc/boot: Remove support for Marvell mv64x60 i2c controller
      powerpc/boot: Remove support for Marvell MPSC serial controller
      powerpc/embedded6xx: Remove C2K board support
      powerpc/lib: optimise PPC32 memcmp
      powerpc/lib: optimise 32 bits __clear_user()
      powerpc/time: inline arch_vtime_task_switch()
      powerpc/Makefile: set -mcpu=860 flag for the 8xx
      powerpc: Implement csum_ipv6_magic in assembly
      powerpc/32: Optimise __csum_partial()
      powerpc/lib: Adjust .balign inside string functions for PPC32
      ...

commit a377514519b9a20fa1ea9adddbb4129573129cef
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Mon May 28 15:19:14 2018 +0200

    powerpc/64s: Enhance the information in cpu_show_spectre_v1()
    
    We now have barrier_nospec as mitigation so print it in
    cpu_show_spectre_v1() when enabled.
    
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 06d5195f6729..3eb9c45f28d7 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -120,6 +120,9 @@ ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, c
 	if (!security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR))
 		return sprintf(buf, "Not affected\n");
 
+	if (barrier_nospec_enabled)
+		return sprintf(buf, "Mitigation: __user pointer sanitization\n");
+
 	return sprintf(buf, "Vulnerable\n");
 }
 

commit cb3d6759a93c6d0aea1c10deb6d00e111c29c19c
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Tue Apr 24 14:15:57 2018 +1000

    powerpc/64s: Enable barrier_nospec based on firmware settings
    
    Check what firmware told us and enable/disable the barrier_nospec as
    appropriate.
    
    We err on the side of enabling the barrier, as it's no-op on older
    systems, see the comment for more detail.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 39cc9eae8d7f..06d5195f6729 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -8,6 +8,7 @@
 #include <linux/device.h>
 #include <linux/seq_buf.h>
 
+#include <asm/debugfs.h>
 #include <asm/security_features.h>
 #include <asm/setup.h>
 
@@ -22,6 +23,65 @@ static void enable_barrier_nospec(bool enable)
 	do_barrier_nospec_fixups(enable);
 }
 
+void setup_barrier_nospec(void)
+{
+	bool enable;
+
+	/*
+	 * It would make sense to check SEC_FTR_SPEC_BAR_ORI31 below as well.
+	 * But there's a good reason not to. The two flags we check below are
+	 * both are enabled by default in the kernel, so if the hcall is not
+	 * functional they will be enabled.
+	 * On a system where the host firmware has been updated (so the ori
+	 * functions as a barrier), but on which the hypervisor (KVM/Qemu) has
+	 * not been updated, we would like to enable the barrier. Dropping the
+	 * check for SEC_FTR_SPEC_BAR_ORI31 achieves that. The only downside is
+	 * we potentially enable the barrier on systems where the host firmware
+	 * is not updated, but that's harmless as it's a no-op.
+	 */
+	enable = security_ftr_enabled(SEC_FTR_FAVOUR_SECURITY) &&
+		 security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR);
+
+	enable_barrier_nospec(enable);
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int barrier_nospec_set(void *data, u64 val)
+{
+	switch (val) {
+	case 0:
+	case 1:
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!!val == !!barrier_nospec_enabled)
+		return 0;
+
+	enable_barrier_nospec(!!val);
+
+	return 0;
+}
+
+static int barrier_nospec_get(void *data, u64 *val)
+{
+	*val = barrier_nospec_enabled ? 1 : 0;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_barrier_nospec,
+			barrier_nospec_get, barrier_nospec_set, "%llu\n");
+
+static __init int barrier_nospec_debugfs_init(void)
+{
+	debugfs_create_file("barrier_nospec", 0600, powerpc_debugfs_root, NULL,
+			    &fops_barrier_nospec);
+	return 0;
+}
+device_initcall(barrier_nospec_debugfs_init);
+#endif /* CONFIG_DEBUG_FS */
+
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	bool thread_priv;

commit 815069ca57c142eb71d27439bc27f41a433a67b3
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Tue Apr 24 14:15:56 2018 +1000

    powerpc/64s: Patch barrier_nospec in modules
    
    Note that unlike RFI which is patched only in kernel the nospec state
    reflects settings at the time the module was loaded.
    
    Iterating all modules and re-patching every time the settings change
    is not implemented.
    
    Based on lwsync patching.
    
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index b963eae0b0a0..39cc9eae8d7f 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -14,7 +14,7 @@
 
 unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
-static bool barrier_nospec_enabled;
+bool barrier_nospec_enabled;
 
 static void enable_barrier_nospec(bool enable)
 {

commit 2eea7f067f495e33b8b116b35b5988ab2b8aec55
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Tue Apr 24 14:15:55 2018 +1000

    powerpc/64s: Add support for ori barrier_nospec patching
    
    Based on the RFI patching. This is required to be able to disable the
    speculation barrier.
    
    Only one barrier type is supported and it does nothing when the
    firmware does not enable it. Also re-patching modules is not supported
    So the only meaningful thing that can be done is patching out the
    speculation barrier at boot when the user says it is not wanted.
    
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index bab5a27ea805..b963eae0b0a0 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -9,10 +9,19 @@
 #include <linux/seq_buf.h>
 
 #include <asm/security_features.h>
+#include <asm/setup.h>
 
 
 unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
+static bool barrier_nospec_enabled;
+
+static void enable_barrier_nospec(bool enable)
+{
+	barrier_nospec_enabled = enable;
+	do_barrier_nospec_fixups(enable);
+}
+
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	bool thread_priv;

commit a048a07d7f4535baa4cbad6bc024f175317ab938
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue May 22 09:00:00 2018 +1000

    powerpc/64s: Add support for a store forwarding barrier at kernel entry/exit
    
    On some CPUs we can prevent a vulnerability related to store-to-load
    forwarding by preventing store forwarding between privilege domains,
    by inserting a barrier in kernel entry and exit paths.
    
    This is known to be the case on at least Power7, Power8 and Power9
    powerpc CPUs.
    
    Barriers must be inserted generally before the first load after moving
    to a higher privilege, and after the last store before moving to a
    lower privilege, HV and PR privilege transitions must be protected.
    
    Barriers are added as patch sections, with all kernel/hypervisor entry
    points patched, and the exit points to lower privilge levels patched
    similarly to the RFI flush patching.
    
    Firmware advertisement is not implemented yet, so CPU flush types
    are hard coded.
    
    Thanks to Michal Suchánek for bug fixes and review.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Mauricio Faria de Oliveira <mauricfo@linux.vnet.ibm.com>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michal Suchánek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index bab5a27ea805..b98a722da915 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -8,6 +8,7 @@
 #include <linux/device.h>
 #include <linux/seq_buf.h>
 
+#include <asm/debugfs.h>
 #include <asm/security_features.h>
 
 
@@ -86,3 +87,151 @@ ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c
 
 	return s.len;
 }
+
+/*
+ * Store-forwarding barrier support.
+ */
+
+static enum stf_barrier_type stf_enabled_flush_types;
+static bool no_stf_barrier;
+bool stf_barrier;
+
+static int __init handle_no_stf_barrier(char *p)
+{
+	pr_info("stf-barrier: disabled on command line.");
+	no_stf_barrier = true;
+	return 0;
+}
+
+early_param("no_stf_barrier", handle_no_stf_barrier);
+
+/* This is the generic flag used by other architectures */
+static int __init handle_ssbd(char *p)
+{
+	if (!p || strncmp(p, "auto", 5) == 0 || strncmp(p, "on", 2) == 0 ) {
+		/* Until firmware tells us, we have the barrier with auto */
+		return 0;
+	} else if (strncmp(p, "off", 3) == 0) {
+		handle_no_stf_barrier(NULL);
+		return 0;
+	} else
+		return 1;
+
+	return 0;
+}
+early_param("spec_store_bypass_disable", handle_ssbd);
+
+/* This is the generic flag used by other architectures */
+static int __init handle_no_ssbd(char *p)
+{
+	handle_no_stf_barrier(NULL);
+	return 0;
+}
+early_param("nospec_store_bypass_disable", handle_no_ssbd);
+
+static void stf_barrier_enable(bool enable)
+{
+	if (enable)
+		do_stf_barrier_fixups(stf_enabled_flush_types);
+	else
+		do_stf_barrier_fixups(STF_BARRIER_NONE);
+
+	stf_barrier = enable;
+}
+
+void setup_stf_barrier(void)
+{
+	enum stf_barrier_type type;
+	bool enable, hv;
+
+	hv = cpu_has_feature(CPU_FTR_HVMODE);
+
+	/* Default to fallback in case fw-features are not available */
+	if (cpu_has_feature(CPU_FTR_ARCH_300))
+		type = STF_BARRIER_EIEIO;
+	else if (cpu_has_feature(CPU_FTR_ARCH_207S))
+		type = STF_BARRIER_SYNC_ORI;
+	else if (cpu_has_feature(CPU_FTR_ARCH_206))
+		type = STF_BARRIER_FALLBACK;
+	else
+		type = STF_BARRIER_NONE;
+
+	enable = security_ftr_enabled(SEC_FTR_FAVOUR_SECURITY) &&
+		(security_ftr_enabled(SEC_FTR_L1D_FLUSH_PR) ||
+		 (security_ftr_enabled(SEC_FTR_L1D_FLUSH_HV) && hv));
+
+	if (type == STF_BARRIER_FALLBACK) {
+		pr_info("stf-barrier: fallback barrier available\n");
+	} else if (type == STF_BARRIER_SYNC_ORI) {
+		pr_info("stf-barrier: hwsync barrier available\n");
+	} else if (type == STF_BARRIER_EIEIO) {
+		pr_info("stf-barrier: eieio barrier available\n");
+	}
+
+	stf_enabled_flush_types = type;
+
+	if (!no_stf_barrier)
+		stf_barrier_enable(enable);
+}
+
+ssize_t cpu_show_spec_store_bypass(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	if (stf_barrier && stf_enabled_flush_types != STF_BARRIER_NONE) {
+		const char *type;
+		switch (stf_enabled_flush_types) {
+		case STF_BARRIER_EIEIO:
+			type = "eieio";
+			break;
+		case STF_BARRIER_SYNC_ORI:
+			type = "hwsync";
+			break;
+		case STF_BARRIER_FALLBACK:
+			type = "fallback";
+			break;
+		default:
+			type = "unknown";
+		}
+		return sprintf(buf, "Mitigation: Kernel entry/exit barrier (%s)\n", type);
+	}
+
+	if (!security_ftr_enabled(SEC_FTR_L1D_FLUSH_HV) &&
+	    !security_ftr_enabled(SEC_FTR_L1D_FLUSH_PR))
+		return sprintf(buf, "Not affected\n");
+
+	return sprintf(buf, "Vulnerable\n");
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int stf_barrier_set(void *data, u64 val)
+{
+	bool enable;
+
+	if (val == 1)
+		enable = true;
+	else if (val == 0)
+		enable = false;
+	else
+		return -EINVAL;
+
+	/* Only do anything if we're changing state */
+	if (enable != stf_barrier)
+		stf_barrier_enable(enable);
+
+	return 0;
+}
+
+static int stf_barrier_get(void *data, u64 *val)
+{
+	*val = stf_barrier ? 1 : 0;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_stf_barrier, stf_barrier_get, stf_barrier_set, "%llu\n");
+
+static __init int stf_barrier_debugfs_init(void)
+{
+	debugfs_create_file("stf_barrier", 0600, powerpc_debugfs_root, NULL, &fops_stf_barrier);
+	return 0;
+}
+device_initcall(stf_barrier_debugfs_init);
+#endif /* CONFIG_DEBUG_FS */

commit e7347a86830f38dc3e40c8f7e28c04412b12a2e7
Author: Mauricio Faria de Oliveira <mauricfo@linux.vnet.ibm.com>
Date:   Fri Mar 30 14:28:24 2018 -0300

    powerpc: Move default security feature flags
    
    This moves the definition of the default security feature flags
    (i.e., enabled by default) closer to the security feature flags.
    
    This can be used to restore current flags to the default flags.
    
    Signed-off-by: Mauricio Faria de Oliveira <mauricfo@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 2cee3dcd231b..bab5a27ea805 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -11,12 +11,7 @@
 #include <asm/security_features.h>
 
 
-unsigned long powerpc_security_features __read_mostly = \
-	SEC_FTR_L1D_FLUSH_HV | \
-	SEC_FTR_L1D_FLUSH_PR | \
-	SEC_FTR_BNDS_CHK_SPEC_BAR | \
-	SEC_FTR_FAVOUR_SECURITY;
-
+unsigned long powerpc_security_features __read_mostly = SEC_FTR_DEFAULT;
 
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {

commit d6fbe1c55c55c6937cbea3531af7da84ab7473c3
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:01:53 2018 +1100

    powerpc/64s: Wire up cpu_show_spectre_v2()
    
    Add a definition for cpu_show_spectre_v2() to override the generic
    version. This has several permuations, though in practice some may not
    occur we cater for any combination.
    
    The most verbose is:
    
      Mitigation: Indirect branch serialisation (kernel only), Indirect
      branch cache disabled, ori31 speculation barrier enabled
    
    We don't treat the ori31 speculation barrier as a mitigation on its
    own, because it has to be *used* by code in order to be a mitigation
    and we don't know if userspace is doing that. So if that's all we see
    we say:
    
      Vulnerable, ori31 speculation barrier enabled
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 0eace3cac818..2cee3dcd231b 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -58,3 +58,36 @@ ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, c
 
 	return sprintf(buf, "Vulnerable\n");
 }
+
+ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	bool bcs, ccd, ori;
+	struct seq_buf s;
+
+	seq_buf_init(&s, buf, PAGE_SIZE - 1);
+
+	bcs = security_ftr_enabled(SEC_FTR_BCCTRL_SERIALISED);
+	ccd = security_ftr_enabled(SEC_FTR_COUNT_CACHE_DISABLED);
+	ori = security_ftr_enabled(SEC_FTR_SPEC_BAR_ORI31);
+
+	if (bcs || ccd) {
+		seq_buf_printf(&s, "Mitigation: ");
+
+		if (bcs)
+			seq_buf_printf(&s, "Indirect branch serialisation (kernel only)");
+
+		if (bcs && ccd)
+			seq_buf_printf(&s, ", ");
+
+		if (ccd)
+			seq_buf_printf(&s, "Indirect branch cache disabled");
+	} else
+		seq_buf_printf(&s, "Vulnerable");
+
+	if (ori)
+		seq_buf_printf(&s, ", ori31 speculation barrier enabled");
+
+	seq_buf_printf(&s, "\n");
+
+	return s.len;
+}

commit 56986016cb8cd9050e601831fe89f332b4e3c46e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:01:52 2018 +1100

    powerpc/64s: Wire up cpu_show_spectre_v1()
    
    Add a definition for cpu_show_spectre_v1() to override the generic
    version. Currently this just prints "Not affected" or "Vulnerable"
    based on the firmware flag.
    
    Although the kernel does have array_index_nospec() in a few places, we
    haven't yet audited all the powerpc code to see where it's necessary,
    so for now we don't list that as a mitigation.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 865db6f8bcca..0eace3cac818 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -50,3 +50,11 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 	return sprintf(buf, "Vulnerable\n");
 }
+
+ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	if (!security_ftr_enabled(SEC_FTR_BNDS_CHK_SPEC_BAR))
+		return sprintf(buf, "Not affected\n");
+
+	return sprintf(buf, "Vulnerable\n");
+}

commit ff348355e9c72493947be337bb4fae4fc1a41eba
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:01:49 2018 +1100

    powerpc/64s: Enhance the information in cpu_show_meltdown()
    
    Now that we have the security feature flags we can make the
    information displayed in the "meltdown" file more informative.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 564e7f182a16..865db6f8bcca 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -6,6 +6,7 @@
 
 #include <linux/kernel.h>
 #include <linux/device.h>
+#include <linux/seq_buf.h>
 
 #include <asm/security_features.h>
 
@@ -19,8 +20,33 @@ unsigned long powerpc_security_features __read_mostly = \
 
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {
-	if (rfi_flush)
-		return sprintf(buf, "Mitigation: RFI Flush\n");
+	bool thread_priv;
+
+	thread_priv = security_ftr_enabled(SEC_FTR_L1D_THREAD_PRIV);
+
+	if (rfi_flush || thread_priv) {
+		struct seq_buf s;
+		seq_buf_init(&s, buf, PAGE_SIZE - 1);
+
+		seq_buf_printf(&s, "Mitigation: ");
+
+		if (rfi_flush)
+			seq_buf_printf(&s, "RFI Flush");
+
+		if (rfi_flush && thread_priv)
+			seq_buf_printf(&s, ", ");
+
+		if (thread_priv)
+			seq_buf_printf(&s, "L1D private per thread");
+
+		seq_buf_printf(&s, "\n");
+
+		return s.len;
+	}
+
+	if (!security_ftr_enabled(SEC_FTR_L1D_FLUSH_HV) &&
+	    !security_ftr_enabled(SEC_FTR_L1D_FLUSH_PR))
+		return sprintf(buf, "Not affected\n");
 
 	return sprintf(buf, "Vulnerable\n");
 }

commit 8ad33041563a10b34988800c682ada14b2612533
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:01:48 2018 +1100

    powerpc/64s: Move cpu_show_meltdown()
    
    This landed in setup_64.c for no good reason other than we had nowhere
    else to put it. Now that we have a security-related file, that is a
    better place for it so move it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
index 4ccba00d224c..564e7f182a16 100644
--- a/arch/powerpc/kernel/security.c
+++ b/arch/powerpc/kernel/security.c
@@ -5,6 +5,8 @@
 // Copyright 2018, Michael Ellerman, IBM Corporation.
 
 #include <linux/kernel.h>
+#include <linux/device.h>
+
 #include <asm/security_features.h>
 
 
@@ -13,3 +15,12 @@ unsigned long powerpc_security_features __read_mostly = \
 	SEC_FTR_L1D_FLUSH_PR | \
 	SEC_FTR_BNDS_CHK_SPEC_BAR | \
 	SEC_FTR_FAVOUR_SECURITY;
+
+
+ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	if (rfi_flush)
+		return sprintf(buf, "Mitigation: RFI Flush\n");
+
+	return sprintf(buf, "Vulnerable\n");
+}

commit 9a868f634349e62922c226834aa23e3d1329ae7f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:01:44 2018 +1100

    powerpc: Add security feature flags for Spectre/Meltdown
    
    This commit adds security feature flags to reflect the settings we
    receive from firmware regarding Spectre/Meltdown mitigations.
    
    The feature names reflect the names we are given by firmware on bare
    metal machines. See the hostboot source for details.
    
    Arguably these could be firmware features, but that then requires them
    to be read early in boot so they're available prior to asm feature
    patching, but we don't actually want to use them for patching. We may
    also want to dynamically update them in future, which would be
    incompatible with the way firmware features work (at the moment at
    least). So for now just make them separate flags.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/security.c b/arch/powerpc/kernel/security.c
new file mode 100644
index 000000000000..4ccba00d224c
--- /dev/null
+++ b/arch/powerpc/kernel/security.c
@@ -0,0 +1,15 @@
+// SPDX-License-Identifier: GPL-2.0+
+//
+// Security related flags and so on.
+//
+// Copyright 2018, Michael Ellerman, IBM Corporation.
+
+#include <linux/kernel.h>
+#include <asm/security_features.h>
+
+
+unsigned long powerpc_security_features __read_mostly = \
+	SEC_FTR_L1D_FLUSH_HV | \
+	SEC_FTR_L1D_FLUSH_PR | \
+	SEC_FTR_BNDS_CHK_SPEC_BAR | \
+	SEC_FTR_FAVOUR_SECURITY;
