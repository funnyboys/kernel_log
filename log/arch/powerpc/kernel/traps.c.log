commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 067e501f2202..97413a385720 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -39,7 +39,6 @@
 #include <linux/kmsg_dump.h>
 
 #include <asm/emulated_ops.h>
-#include <asm/pgtable.h>
 #include <linux/uaccess.h>
 #include <asm/debugfs.h>
 #include <asm/io.h>

commit 7ae77150d94d3b535c7b85e6b3647113095e79bf
Merge: 084623e468d5 1395375c5927
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 5 12:39:30 2020 -0700

    Merge tag 'powerpc-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
    
     - Support for userspace to send requests directly to the on-chip GZIP
       accelerator on Power9.
    
     - Rework of our lockless page table walking (__find_linux_pte()) to
       make it safe against parallel page table manipulations without
       relying on an IPI for serialisation.
    
     - A series of fixes & enhancements to make our machine check handling
       more robust.
    
     - Lots of plumbing to add support for "prefixed" (64-bit) instructions
       on Power10.
    
     - Support for using huge pages for the linear mapping on 8xx (32-bit).
    
     - Remove obsolete Xilinx PPC405/PPC440 support, and an associated sound
       driver.
    
     - Removal of some obsolete 40x platforms and associated cruft.
    
     - Initial support for booting on Power10.
    
     - Lots of other small features, cleanups & fixes.
    
    Thanks to: Alexey Kardashevskiy, Alistair Popple, Andrew Donnellan,
    Andrey Abramov, Aneesh Kumar K.V, Balamuruhan S, Bharata B Rao, Bulent
    Abali, CÃ©dric Le Goater, Chen Zhou, Christian Zigotzky, Christophe
    JAILLET, Christophe Leroy, Dmitry Torokhov, Emmanuel Nicolet, Erhard F.,
    Gautham R. Shenoy, Geoff Levand, George Spelvin, Greg Kurz, Gustavo A.
    R. Silva, Gustavo Walbon, Haren Myneni, Hari Bathini, Joel Stanley,
    Jordan Niethe, Kajol Jain, Kees Cook, Leonardo Bras, Madhavan
    Srinivasan., Mahesh Salgaonkar, Markus Elfring, Michael Neuling, Michal
    Simek, Nathan Chancellor, Nathan Lynch, Naveen N. Rao, Nicholas Piggin,
    Oliver O'Halloran, Paul Mackerras, Pingfan Liu, Qian Cai, Ram Pai,
    Raphael Moreira Zinsly, Ravi Bangoria, Sam Bobroff, Sandipan Das, Segher
    Boessenkool, Stephen Rothwell, Sukadev Bhattiprolu, Tyrel Datwyler,
    Wolfram Sang, Xiongfeng Wang.
    
    * tag 'powerpc-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (299 commits)
      powerpc/pseries: Make vio and ibmebus initcalls pseries specific
      cxl: Remove dead Kconfig options
      powerpc: Add POWER10 architected mode
      powerpc/dt_cpu_ftrs: Add MMA feature
      powerpc/dt_cpu_ftrs: Enable Prefixed Instructions
      powerpc/dt_cpu_ftrs: Advertise support for ISA v3.1 if selected
      powerpc: Add support for ISA v3.1
      powerpc: Add new HWCAP bits
      powerpc/64s: Don't set FSCR bits in INIT_THREAD
      powerpc/64s: Save FSCR to init_task.thread.fscr after feature init
      powerpc/64s: Don't let DT CPU features set FSCR_DSCR
      powerpc/64s: Don't init FSCR_DSCR in __init_FSCR()
      powerpc/32s: Fix another build failure with CONFIG_PPC_KUAP_DEBUG
      powerpc/module_64: Use special stub for _mcount() with -mprofile-kernel
      powerpc/module_64: Simplify check for -mprofile-kernel ftrace relocations
      powerpc/module_64: Consolidate ftrace code
      powerpc/32: Disable KASAN with pages bigger than 16k
      powerpc/uaccess: Don't set KUEP by default on book3s/32
      powerpc/uaccess: Don't set KUAP by default on book3s/32
      powerpc/8xx: Reduce time spent in allow_user_access() and friends
      ...

commit 69ea03b56ed2c7189ccd0b5910ad39f3cad1df21
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Feb 19 09:46:47 2020 +0100

    hardirq/nmi: Allow nested nmi_enter()
    
    Since there are already a number of sites (ARM64, PowerPC) that effectively
    nest nmi_enter(), make the primitive support this before adding even more.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Marc Zyngier <maz@kernel.org>
    Acked-by: Will Deacon <will@kernel.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lkml.kernel.org/r/20200505134100.864179229@linutronix.de

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 3fca22276bb1..b44dd75de517 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -441,15 +441,9 @@ void hv_nmi_check_nonrecoverable(struct pt_regs *regs)
 void system_reset_exception(struct pt_regs *regs)
 {
 	unsigned long hsrr0, hsrr1;
-	bool nested = in_nmi();
 	bool saved_hsrrs = false;
 
-	/*
-	 * Avoid crashes in case of nested NMI exceptions. Recoverability
-	 * is determined by RI and in_nmi
-	 */
-	if (!nested)
-		nmi_enter();
+	nmi_enter();
 
 	/*
 	 * System reset can interrupt code where HSRRs are live and MSR[RI]=1.
@@ -521,8 +515,7 @@ void system_reset_exception(struct pt_regs *regs)
 		mtspr(SPRN_HSRR1, hsrr1);
 	}
 
-	if (!nested)
-		nmi_exit();
+	nmi_exit();
 
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
@@ -823,9 +816,8 @@ int machine_check_generic(struct pt_regs *regs)
 void machine_check_exception(struct pt_regs *regs)
 {
 	int recover = 0;
-	bool nested = in_nmi();
-	if (!nested)
-		nmi_enter();
+
+	nmi_enter();
 
 	__this_cpu_inc(irq_stat.mce_exceptions);
 
@@ -851,8 +843,7 @@ void machine_check_exception(struct pt_regs *regs)
 	if (check_io_access(regs))
 		goto bail;
 
-	if (!nested)
-		nmi_exit();
+	nmi_exit();
 
 	die("Machine check", regs, SIGBUS);
 
@@ -863,8 +854,7 @@ void machine_check_exception(struct pt_regs *regs)
 	return;
 
 bail:
-	if (!nested)
-		nmi_exit();
+	nmi_exit();
 }
 
 void SMIException(struct pt_regs *regs)

commit 9409d2f9dad2f0679d67dc24d8116dd3e837b035
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:48 2020 +1000

    powerpc: Support prefixed instructions in alignment handler
    
    If a prefixed instruction results in an alignment exception, the
    SRR1_PREFIXED bit is set. The handler attempts to emulate the
    responsible instruction and then increment the NIP past it. Use
    SRR1_PREFIXED to determine by how much the NIP should be incremented.
    
    Prefixed instructions are not permitted to cross 64-byte boundaries. If
    they do the alignment interrupt is invoked with SRR1 BOUNDARY bit set.
    If this occurs send a SIGBUS to the offending process if in user mode.
    If in kernel mode call bad_page_fault().
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-29-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e37bf7945d27..051d7028e71f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -588,6 +588,8 @@ static inline int check_io_access(struct pt_regs *regs)
 #define REASON_ILLEGAL		(ESR_PIL | ESR_PUO)
 #define REASON_PRIVILEGED	ESR_PPR
 #define REASON_TRAP		ESR_PTR
+#define REASON_PREFIXED		0
+#define REASON_BOUNDARY		0
 
 /* single-step stuff */
 #define single_stepping(regs)	(current->thread.debug.dbcr0 & DBCR0_IC)
@@ -602,12 +604,16 @@ static inline int check_io_access(struct pt_regs *regs)
 #define REASON_ILLEGAL		SRR1_PROGILL
 #define REASON_PRIVILEGED	SRR1_PROGPRIV
 #define REASON_TRAP		SRR1_PROGTRAP
+#define REASON_PREFIXED		SRR1_PREFIXED
+#define REASON_BOUNDARY		SRR1_BOUNDARY
 
 #define single_stepping(regs)	((regs)->msr & MSR_SE)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #define clear_br_trace(regs)	((regs)->msr &= ~MSR_BE)
 #endif
 
+#define inst_length(reason)	(((reason) & REASON_PREFIXED) ? 8 : 4)
+
 #if defined(CONFIG_E500)
 int machine_check_e500mc(struct pt_regs *regs)
 {
@@ -1610,11 +1616,20 @@ void alignment_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
 	int sig, code, fixed = 0;
+	unsigned long  reason;
 
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
+	reason = get_reason(regs);
+
+	if (reason & REASON_BOUNDARY) {
+		sig = SIGBUS;
+		code = BUS_ADRALN;
+		goto bad;
+	}
+
 	if (tm_abort_check(regs, TM_CAUSE_ALIGNMENT | TM_CAUSE_PERSISTENT))
 		goto bail;
 
@@ -1623,7 +1638,8 @@ void alignment_exception(struct pt_regs *regs)
 		fixed = fix_alignment(regs);
 
 	if (fixed == 1) {
-		regs->nip += 4;	/* skip over emulated instruction */
+		/* skip over emulated instruction */
+		regs->nip += inst_length(reason);
 		emulate_single_step(regs);
 		goto bail;
 	}
@@ -1636,6 +1652,7 @@ void alignment_exception(struct pt_regs *regs)
 		sig = SIGBUS;
 		code = BUS_ADRALN;
 	}
+bad:
 	if (user_mode(regs))
 		_exception(sig, regs, code, regs->dar);
 	else

commit 2aa6195e43b3740258ead93aee42ac719dd4c4b0
Author: Alistair Popple <alistair@popple.id.au>
Date:   Wed May 6 13:40:41 2020 +1000

    powerpc: Enable Prefixed Instructions
    
    Prefix instructions have their own FSCR bit which needs to enabled via
    a CPU feature. The kernel will save the FSCR for problem state but it
    needs to be enabled initially.
    
    If prefixed instructions are made unavailable by the [H]FSCR, attempting
    to use them will cause a facility unavailable exception. Add "PREFIX" to
    the facility_strings[].
    
    Currently there are no prefixed instructions that are actually emulated
    by emulate_instruction() within facility_unavailable_exception().
    However, when caused by a prefixed instructions the SRR1 PREFIXED bit is
    set. Prepare for dealing with emulated prefixed instructions by checking
    for this bit.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Link: https://lore.kernel.org/r/20200506034050.24806-22-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 477befcda8d3..e37bf7945d27 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1737,6 +1737,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		[FSCR_TAR_LG] = "TAR",
 		[FSCR_MSGP_LG] = "MSGP",
 		[FSCR_SCV_LG] = "SCV",
+		[FSCR_PREFIX_LG] = "PREFIX",
 	};
 	char *facility = "unknown";
 	u64 value;

commit 265d6e588d87194c2fe2d6c240247f0264e0c19b
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri May 8 14:34:07 2020 +1000

    powerpc/traps: Make unrecoverable NMIs die instead of panic
    
    System Reset and Machine Check interrupts that are not recoverable due
    to being nested or interrupting when RI=0 currently panic. This is not
    necessary, and can often just kill the current context and recover.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Link: https://lore.kernel.org/r/20200508043408.886394-16-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ee209c5a1ad7..477befcda8d3 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -513,11 +513,11 @@ void system_reset_exception(struct pt_regs *regs)
 #ifdef CONFIG_PPC_BOOK3S_64
 	BUG_ON(get_paca()->in_nmi == 0);
 	if (get_paca()->in_nmi > 1)
-		nmi_panic(regs, "Unrecoverable nested System Reset");
+		die("Unrecoverable nested System Reset", regs, SIGABRT);
 #endif
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
-		nmi_panic(regs, "Unrecoverable System Reset");
+		die("Unrecoverable System Reset", regs, SIGABRT);
 
 	if (saved_hsrrs) {
 		mtspr(SPRN_HSRR0, hsrr0);
@@ -875,7 +875,7 @@ void machine_check_exception(struct pt_regs *regs)
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
-		nmi_panic(regs, "Unrecoverable Machine check");
+		die("Unrecoverable Machine check", regs, SIGBUS);
 
 	return;
 

commit bbbc8032b00f8ef287894425fbdb691049e28d39
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri May 8 14:34:06 2020 +1000

    powerpc/traps: Do not trace system reset
    
    Similarly to the previous patch, do not trace system reset. This code
    is used when there is a crash or hang, and tracing disturbs the system
    more and has been known to crash in the crash handling path.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Acked-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Link: https://lore.kernel.org/r/20200508043408.886394-15-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9f6852322e59..ee209c5a1ad7 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -443,6 +443,9 @@ void system_reset_exception(struct pt_regs *regs)
 	unsigned long hsrr0, hsrr1;
 	bool nested = in_nmi();
 	bool saved_hsrrs = false;
+	u8 ftrace_enabled = this_cpu_get_ftrace_enabled();
+
+	this_cpu_set_ftrace_enabled(0);
 
 	/*
 	 * Avoid crashes in case of nested NMI exceptions. Recoverability
@@ -524,6 +527,8 @@ void system_reset_exception(struct pt_regs *regs)
 	if (!nested)
 		nmi_exit();
 
+	this_cpu_set_ftrace_enabled(ftrace_enabled);
+
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
 

commit 116ac378bb3ff844df333e7609e7604651a0db9d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri May 8 14:34:03 2020 +1000

    powerpc/64s: machine check interrupt update NMI accounting
    
    machine_check_early() is taken as an NMI, so nmi_enter() is used
    there. machine_check_exception() is no longer taken as an NMI (it's
    invoked via irq_work in the case a machine check hits in kernel mode),
    so remove the nmi_enter() from that case.
    
    In NMI context, hash faults don't try to refill the hash table, which
    can lead to crashes accessing non-pinned kernel pages. System reset
    still has this potential problem.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Drop change in show_regs() which breaks Book3E]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200508043408.886394-12-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 3fca22276bb1..9f6852322e59 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -823,7 +823,19 @@ int machine_check_generic(struct pt_regs *regs)
 void machine_check_exception(struct pt_regs *regs)
 {
 	int recover = 0;
-	bool nested = in_nmi();
+	bool nested;
+
+	/*
+	 * BOOK3S_64 does not call this handler as a non-maskable interrupt
+	 * (it uses its own early real-mode handler to handle the MCE proper
+	 * and then raises irq_work to call this handler when interrupts are
+	 * enabled). Set nested = true for this case, which just makes it avoid
+	 * the nmi_enter/exit.
+	 */
+	if (IS_ENABLED(CONFIG_PPC_BOOK3S_64) || in_nmi())
+		nested = true;
+	else
+		nested = false;
 	if (!nested)
 		nmi_enter();
 

commit 860286cf33963fa8a0fe542995bdec2df5cb3abb
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Sun Feb 9 11:58:56 2020 +0100

    powerpc/kernel: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200209105901.1620958-1-gregkh@linuxfoundation.org

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 82a3438300fd..3fca22276bb1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -2278,35 +2278,20 @@ void ppc_warn_emulated_print(const char *type)
 
 static int __init ppc_warn_emulated_init(void)
 {
-	struct dentry *dir, *d;
+	struct dentry *dir;
 	unsigned int i;
 	struct ppc_emulated_entry *entries = (void *)&ppc_emulated;
 
-	if (!powerpc_debugfs_root)
-		return -ENODEV;
-
 	dir = debugfs_create_dir("emulated_instructions",
 				 powerpc_debugfs_root);
-	if (!dir)
-		return -ENOMEM;
 
-	d = debugfs_create_u32("do_warn", 0644, dir,
-			       &ppc_warn_emulated);
-	if (!d)
-		goto fail;
+	debugfs_create_u32("do_warn", 0644, dir, &ppc_warn_emulated);
 
-	for (i = 0; i < sizeof(ppc_emulated)/sizeof(*entries); i++) {
-		d = debugfs_create_u32(entries[i].name, 0644, dir,
-				       (u32 *)&entries[i].val.counter);
-		if (!d)
-			goto fail;
-	}
+	for (i = 0; i < sizeof(ppc_emulated)/sizeof(*entries); i++)
+		debugfs_create_u32(entries[i].name, 0644, dir,
+				   (u32 *)&entries[i].val.counter);
 
 	return 0;
-
-fail:
-	debugfs_remove_recursive(dir);
-	return -ENOMEM;
 }
 
 device_initcall(ppc_warn_emulated_init);

commit 3978eb78517c1fc06dd75405d732af45c80f5bd2
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Dec 21 08:32:29 2019 +0000

    powerpc/32: Add early stack overflow detection with VMAP stack.
    
    To avoid recursive faults, stack overflow detection has to be
    performed before writing in the stack in exception prologs.
    
    Do it by checking the alignment. If the stack pointer alignment is
    wrong, it means it is pointing to the following or preceding page.
    
    Without VMAP stack, a stack overflow is catastrophic. With VMAP
    stack, a stack overflow isn't destructive, so don't panic. Kill
    the task with SIGSEGV instead.
    
    A dedicated overflow stack is set up for each CPU.
    
      lkdtm: Performing direct entry EXHAUST_STACK
      lkdtm: Calling function with 512 frame size to depth 32 ...
      lkdtm: loop 32/32 ...
      lkdtm: loop 31/32 ...
      lkdtm: loop 30/32 ...
      lkdtm: loop 29/32 ...
      lkdtm: loop 28/32 ...
      lkdtm: loop 27/32 ...
      lkdtm: loop 26/32 ...
      lkdtm: loop 25/32 ...
      lkdtm: loop 24/32 ...
      lkdtm: loop 23/32 ...
      lkdtm: loop 22/32 ...
      lkdtm: loop 21/32 ...
      lkdtm: loop 20/32 ...
      Kernel stack overflow in process test[359], r1=c900c008
      Oops: Kernel stack overflow, sig: 6 [#1]
      BE PAGE_SIZE=4K MMU=Hash PowerMac
      Modules linked in:
      CPU: 0 PID: 359 Comm: test Not tainted 5.3.0-rc7+ #2225
      NIP:  c0622060 LR: c0626710 CTR: 00000000
      REGS: c0895f48 TRAP: 0000   Not tainted  (5.3.0-rc7+)
      MSR:  00001032 <ME,IR,DR,RI>  CR: 28004224  XER: 00000000
      GPR00: c0626ca4 c900c008 c783c000 c07335cc c900c010 c07335cc c900c0f0 c07335cc
      GPR08: c900c0f0 00000001 00000000 00000000 28008222 00000000 00000000 00000000
      GPR16: 00000000 00000000 10010128 10010000 b799c245 10010158 c07335cc 00000025
      GPR24: c0690000 c08b91d4 c068f688 00000020 c900c0f0 c068f668 c08b95b4 c08b91d4
      NIP [c0622060] format_decode+0x0/0x4d4
      LR [c0626710] vsnprintf+0x80/0x5fc
      Call Trace:
      [c900c068] [c0626ca4] vscnprintf+0x18/0x48
      [c900c078] [c007b944] vprintk_store+0x40/0x214
      [c900c0b8] [c007bf50] vprintk_emit+0x90/0x1dc
      [c900c0e8] [c007c5cc] printk+0x50/0x60
      [c900c128] [c03da5b0] recursive_loop+0x44/0x6c
      [c900c338] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c548] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c758] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c968] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cb78] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cd88] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cf98] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d1a8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d3b8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d5c8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d7d8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d9e8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900dbf8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900de08] [c03da67c] lkdtm_EXHAUST_STACK+0x30/0x4c
      [c900de18] [c03da3e8] direct_entry+0xc8/0x140
      [c900de48] [c029fb40] full_proxy_write+0x64/0xcc
      [c900de68] [c01500f8] __vfs_write+0x30/0x1d0
      [c900dee8] [c0152cb8] vfs_write+0xb8/0x1d4
      [c900df08] [c0152f7c] ksys_write+0x58/0xe8
      [c900df38] [c0014208] ret_from_syscall+0x0/0x34
      --- interrupt: c01 at 0xf806664
          LR = 0x1000c868
      Instruction dump:
      4bffff91 80010014 7c832378 7c0803a6 38210010 4e800020 3d20c08a 3ca0c089
      8089a0cc 38a58f0c 38600001 4ba2d494 <9421ffe0> 7c0802a6 bfc10018 7c9f2378
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1b89c121b4070c7ee99e4f22cc178f15a736b07b.1576916812.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 014ff0701f24..82a3438300fd 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1637,6 +1637,15 @@ void StackOverflow(struct pt_regs *regs)
 	panic("kernel stack overflow");
 }
 
+void stack_overflow_exception(struct pt_regs *regs)
+{
+	enum ctx_state prev_state = exception_enter();
+
+	die("Kernel stack overflow", regs, SIGSEGV);
+
+	exception_exit(prev_state);
+}
+
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();

commit d7e02f7b7991dbe14a2acfb0e53d675cd149001c
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Thu Jul 11 20:28:14 2019 +0530

    powerpc/book3s/mm: Update Oops message to print the correct translation in use
    
    Avoids confusion when printing Oops message like below
    
     Faulting instruction address: 0xc00000000008bdb4
     Oops: Kernel access of bad area, sig: 11 [#1]
     LE PAGE_SIZE=64K MMU=Radix MMU=Hash SMP NR_CPUS=2048 NUMA PowerNV
    
    This was because we never clear the MMU_FTR_HPTE_TABLE feature flag
    even if we run with radix translation. It was discussed that we should
    look at this feature flag as an indication of the capability to run
    hash translation and we should not clear the flag even if we run in
    radix translation. All the code paths check for radix_enabled() check and
    if found true consider we are running with radix translation. Follow the
    same sequence for finding the MMU translation string to be used in Oops
    message.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Acked-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190711145814.17970-1-aneesh.kumar@linux.ibm.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 82f43535e686..014ff0701f24 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -250,15 +250,22 @@ static void oops_end(unsigned long flags, struct pt_regs *regs,
 }
 NOKPROBE_SYMBOL(oops_end);
 
+static char *get_mmu_str(void)
+{
+	if (early_radix_enabled())
+		return " MMU=Radix";
+	if (early_mmu_has_feature(MMU_FTR_HPTE_TABLE))
+		return " MMU=Hash";
+	return "";
+}
+
 static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 
-	printk("%s PAGE_SIZE=%luK%s%s%s%s%s%s%s %s\n",
+	printk("%s PAGE_SIZE=%luK%s%s%s%s%s%s %s\n",
 	       IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN) ? "LE" : "BE",
-	       PAGE_SIZE / 1024,
-	       early_radix_enabled() ? " MMU=Radix" : "",
-	       early_mmu_has_feature(MMU_FTR_HPTE_TABLE) ? " MMU=Hash" : "",
+	       PAGE_SIZE / 1024, get_mmu_str(),
 	       IS_ENABLED(CONFIG_PREEMPT) ? " PREEMPT" : "",
 	       IS_ENABLED(CONFIG_SMP) ? " SMP" : "",
 	       IS_ENABLED(CONFIG_SMP) ? (" NR_CPUS=" __stringify(NR_CPUS)) : "",

commit e7ca44ed3ba77fc26cf32650bb71584896662474
Author: Ganesh Goudar <ganeshgr@linux.ibm.com>
Date:   Wed Sep 4 13:29:49 2019 +0530

    powerpc: dump kernel log before carrying out fadump or kdump
    
    Since commit 4388c9b3a6ee ("powerpc: Do not send system reset request
    through the oops path"), pstore dmesg file is not updated when dump is
    triggered from HMC. This commit modified system reset (sreset) handler
    to invoke fadump or kdump (if configured), without pushing dmesg to
    pstore. This leaves pstore to have old dmesg data which won't be much
    of a help if kdump fails to capture the dump. This patch fixes that by
    calling kmsg_dump() before heading to fadump ot kdump.
    
    Fixes: 4388c9b3a6ee ("powerpc: Do not send system reset request through the oops path")
    Reviewed-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Ganesh Goudar <ganeshgr@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190904075949.15607-1-ganeshgr@linux.ibm.com

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 11caa0291254..82f43535e686 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -472,6 +472,7 @@ void system_reset_exception(struct pt_regs *regs)
 	if (debugger(regs))
 		goto out;
 
+	kmsg_dump(KMSG_DUMP_OOPS);
 	/*
 	 * A system reset is a request to dump, so we always send
 	 * it through the crashdump code (if fadump or kdump are

commit 5ad18b2e60b75c7297a998dea702451d33a052ed
Merge: 92c1d6522135 318759b4737c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:48:15 2019 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull force_sig() argument change from Eric Biederman:
     "A source of error over the years has been that force_sig has taken a
      task parameter when it is only safe to use force_sig with the current
      task.
    
      The force_sig function is built for delivering synchronous signals
      such as SIGSEGV where the userspace application caused a synchronous
      fault (such as a page fault) and the kernel responded with a signal.
    
      Because the name force_sig does not make this clear, and because the
      force_sig takes a task parameter the function force_sig has been
      abused for sending other kinds of signals over the years. Slowly those
      have been fixed when the oopses have been tracked down.
    
      This set of changes fixes the remaining abusers of force_sig and
      carefully rips out the task parameter from force_sig and friends
      making this kind of error almost impossible in the future"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (27 commits)
      signal/x86: Move tsk inside of CONFIG_MEMORY_FAILURE in do_sigbus
      signal: Remove the signal number and task parameters from force_sig_info
      signal: Factor force_sig_info_to_task out of force_sig_info
      signal: Generate the siginfo in force_sig
      signal: Move the computation of force into send_signal and correct it.
      signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
      signal: Remove the task parameter from force_sig_fault
      signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
      signal: Explicitly call force_sig_fault on current
      signal/unicore32: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from ptrace_break
      signal/nds32: Remove tsk parameter from send_sigtrap
      signal/riscv: Remove tsk parameter from do_trap
      signal/sh: Remove tsk parameter from force_sig_info_fault
      signal/um: Remove task parameter from send_sigtrap
      signal/x86: Remove task parameter from send_sigtrap
      signal: Remove task parameter from force_sig_mceerr
      signal: Remove task parameter from force_sig
      signal: Remove task parameter from force_sigsegv
      ...

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 83e59fdaa62d..47df30982de1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1,12 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  *  Copyright (C) 1995-1996  Gary Thomas (gdt@linuxppc.org)
  *  Copyright 2007-2010 Freescale Semiconductor, Inc.
  *
- *  This program is free software; you can redistribute it and/or
- *  modify it under the terms of the GNU General Public License
- *  as published by the Free Software Foundation; either version
- *  2 of the License, or (at your option) any later version.
- *
  *  Modified by Cort Dougan (cort@cs.nmt.edu)
  *  and Paul Mackerras (paulus@samba.org)
  */

commit 2e1661d2673667d886cd40ad9f414cb6db48d8da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 11:04:24 2019 -0500

    signal: Remove the task parameter from force_sig_fault
    
    As synchronous exceptions really only make sense against the current
    task (otherwise how are you synchronous) remove the task parameter
    from from force_sig_fault to make it explicit that is what is going
    on.
    
    The two known exceptions that deliver a synchronous exception to a
    stopped ptraced task have already been changed to
    force_sig_fault_to_task.
    
    The callers have been changed with the following emacs regular expression
    (with obvious variations on the architectures that take more arguments)
    to avoid typos:
    
    force_sig_fault[(]\([^,]+\)[,]\([^,]+\)[,]\([^,]+\)[,]\W+current[)]
    ->
    force_sig_fault(\1,\2,\3)
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 83e59fdaa62d..dfc61f2f69a0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -301,7 +301,7 @@ NOKPROBE_SYMBOL(die);
 
 void user_single_step_report(struct pt_regs *regs)
 {
-	force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)regs->nip, current);
+	force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)regs->nip);
 }
 
 static void show_signal_msg(int signr, struct pt_regs *regs, int code,
@@ -367,7 +367,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	if (!exception_common(signr, regs, code, addr))
 		return;
 
-	force_sig_fault(signr, code, (void __user *)addr, current);
+	force_sig_fault(signr, code, (void __user *)addr);
 }
 
 /*

commit de6da1e8bcf0dd2058b950b127491821207679dc
Author: Feng Tang <feng.tang@intel.com>
Date:   Fri May 17 14:31:50 2019 -0700

    panic: add an option to replay all the printk message in buffer
    
    Currently on panic, kernel will lower the loglevel and print out pending
    printk msg only with console_flush_on_panic().
    
    Add an option for users to configure the "panic_print" to replay all
    dmesg in buffer, some of which they may have never seen due to the
    loglevel setting, which will help panic debugging .
    
    [feng.tang@intel.com: keep the original console_flush_on_panic() inside panic()]
      Link: http://lkml.kernel.org/r/1556199137-14163-1-git-send-email-feng.tang@intel.com
    [feng.tang@intel.com: use logbuf lock to protect the console log index]
      Link: http://lkml.kernel.org/r/1556269868-22654-1-git-send-email-feng.tang@intel.com
    Link: http://lkml.kernel.org/r/1556095872-36838-1-git-send-email-feng.tang@intel.com
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Cc: Aaro Koskinen <aaro.koskinen@nokia.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Borislav Petkov <bp@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 665f294725cb..83e59fdaa62d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -179,7 +179,7 @@ extern void panic_flush_kmsg_end(void)
 	kmsg_dump(KMSG_DUMP_PANIC);
 	bust_spinlocks(0);
 	debug_locks_off();
-	console_flush_on_panic();
+	console_flush_on_panic(CONSOLE_FLUSH_PENDING);
 }
 
 static unsigned long oops_begin(struct pt_regs *regs)

commit ef4291243f51d0a69899ee2025de09578c0fcba8
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Apr 30 12:38:57 2019 +0000

    powerpc/fsl_booke: ensure SPEFloatingPointException() reenables interrupts
    
    SPEFloatingPointException() is the only exception handler which 'forgets' to
    re-enable interrupts. This patch makes sure it does.
    
    Suggested-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1fd45a8650e1..665f294725cb 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -2088,6 +2088,10 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	int code = FPE_FLTUNK;
 	int err;
 
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
 	flush_spe_to_thread(current);
 
 	spefscr = current->thread.spefscr;
@@ -2133,6 +2137,10 @@ void SPEFloatingPointRoundException(struct pt_regs *regs)
 	extern int speround_handler(struct pt_regs *regs);
 	int err;
 
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
 	preempt_disable();
 	if (regs->msr & MSR_SPE)
 		giveup_spe(current);

commit de3c83c2fd2b87cf68214eda76dfa66989d78cb6
Author: Mathieu Malaterre <malat@debian.org>
Date:   Tue Mar 12 21:18:23 2019 +0100

    powerpc/64s: Include <asm/nmi.h> header file to fix a warning
    
    Make sure to include <asm/nmi.h> to provide the following prototype:
    hv_nmi_check_nonrecoverable.
    
    Remove the following warning treated as error (W=1):
    
      arch/powerpc/kernel/traps.c:393:6: error: no previous prototype for 'hv_nmi_check_nonrecoverable'
    
    Fixes: ccd477028a20 ("powerpc/64s: Fix HV NMI vs HV interrupt recoverability test")
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a21200c6aaea..1fd45a8650e1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -71,6 +71,7 @@
 #include <sysdev/fsl_pci.h>
 #include <asm/kprobes.h>
 #include <asm/stacktrace.h>
+#include <asm/nmi.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC_CORE)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;

commit bd3524feac214f0ab9693c6d4c0cb5be8e1318b9
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Mar 1 22:56:36 2019 +1000

    powerpc/64s: Fix unrelocated interrupt trampoline address test
    
    The recent commit got this test wrong, it declared the assembler
    symbols the wrong way, and also used the wrong symbol name
    (xxx_start rather than start_xxx, see asm/head-64.h).
    
    Fixes: ccd477028a ("powerpc/64s: Fix HV NMI vs HV interrupt recoverability test")
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a5757bef03cd..a21200c6aaea 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -419,12 +419,13 @@ void hv_nmi_check_nonrecoverable(struct pt_regs *regs)
 		goto nonrecoverable;
 	if ((nip >= 0xf80 && nip < 0xfa0) || (nip >= 0x4f80 && nip < 0x4fa0))
 		goto nonrecoverable;
+
 	/* Trampoline code runs un-relocated so subtract kbase. */
-	if (nip >= real_trampolines_start - kbase &&
-			nip < real_trampolines_end - kbase)
+	if (nip >= (unsigned long)(start_real_trampolines - kbase) &&
+			nip < (unsigned long)(end_real_trampolines - kbase))
 		goto nonrecoverable;
-	if (nip >= virt_trampolines_start - kbase &&
-			nip < virt_trampolines_end - kbase)
+	if (nip >= (unsigned long)(start_virt_trampolines - kbase) &&
+			nip < (unsigned long)(end_virt_trampolines - kbase))
 		goto nonrecoverable;
 	return;
 

commit cbf2ba952a70399c972f2a2126a4ac6f79437f37
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Feb 26 18:51:08 2019 +1000

    powerpc/64s: system reset interrupt preserve HSRRs
    
    Code that uses HSRR registers is not required to clear MSR[RI] by
    convention, however the system reset NMI itself may use HSRR
    registers (e.g., to call OPAL) and clobber them.
    
    Rather than introduce the requirement to clear RI in order to use
    HSRRs, have system reset interrupt save and restore HSRRs.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index eee8f843f3d6..a5757bef03cd 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -435,14 +435,32 @@ void hv_nmi_check_nonrecoverable(struct pt_regs *regs)
 
 void system_reset_exception(struct pt_regs *regs)
 {
+	unsigned long hsrr0, hsrr1;
+	bool nested = in_nmi();
+	bool saved_hsrrs = false;
+
 	/*
 	 * Avoid crashes in case of nested NMI exceptions. Recoverability
 	 * is determined by RI and in_nmi
 	 */
-	bool nested = in_nmi();
 	if (!nested)
 		nmi_enter();
 
+	/*
+	 * System reset can interrupt code where HSRRs are live and MSR[RI]=1.
+	 * The system reset interrupt itself may clobber HSRRs (e.g., to call
+	 * OPAL), so save them here and restore them before returning.
+	 *
+	 * Machine checks don't need to save HSRRs, as the real mode handler
+	 * is careful to avoid them, and the regular handler is not delivered
+	 * as an NMI.
+	 */
+	if (cpu_has_feature(CPU_FTR_HVMODE)) {
+		hsrr0 = mfspr(SPRN_HSRR0);
+		hsrr1 = mfspr(SPRN_HSRR1);
+		saved_hsrrs = true;
+	}
+
 	hv_nmi_check_nonrecoverable(regs);
 
 	__this_cpu_inc(irq_stat.sreset_irqs);
@@ -492,6 +510,11 @@ void system_reset_exception(struct pt_regs *regs)
 	if (!(regs->msr & MSR_RI))
 		nmi_panic(regs, "Unrecoverable System Reset");
 
+	if (saved_hsrrs) {
+		mtspr(SPRN_HSRR0, hsrr0);
+		mtspr(SPRN_HSRR1, hsrr1);
+	}
+
 	if (!nested)
 		nmi_exit();
 

commit ccd477028a202993b9ddca5d2404fdaca3b7a55c
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Feb 26 18:51:07 2019 +1000

    powerpc/64s: Fix HV NMI vs HV interrupt recoverability test
    
    HV interrupts that use HSRR registers do not enter with MSR[RI] clear,
    but their entry code is not recoverable vs NMI, due to shared use of
    HSPRG1 as a scratch register to save r13.
    
    This means that a system reset or machine check that hits in HSRR
    interrupt entry can cause r13 to be silently corrupted.
    
    Fix this by marking NMIs non-recoverable if they land in HV interrupt
    ranges.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b25bc8af7d38..eee8f843f3d6 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -369,6 +369,70 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	force_sig_fault(signr, code, (void __user *)addr, current);
 }
 
+/*
+ * The interrupt architecture has a quirk in that the HV interrupts excluding
+ * the NMIs (0x100 and 0x200) do not clear MSR[RI] at entry. The first thing
+ * that an interrupt handler must do is save off a GPR into a scratch register,
+ * and all interrupts on POWERNV (HV=1) use the HSPRG1 register as scratch.
+ * Therefore an NMI can clobber an HV interrupt's live HSPRG1 without noticing
+ * that it is non-reentrant, which leads to random data corruption.
+ *
+ * The solution is for NMI interrupts in HV mode to check if they originated
+ * from these critical HV interrupt regions. If so, then mark them not
+ * recoverable.
+ *
+ * An alternative would be for HV NMIs to use SPRG for scratch to avoid the
+ * HSPRG1 clobber, however this would cause guest SPRG to be clobbered. Linux
+ * guests should always have MSR[RI]=0 when its scratch SPRG is in use, so
+ * that would work. However any other guest OS that may have the SPRG live
+ * and MSR[RI]=1 could encounter silent corruption.
+ *
+ * Builds that do not support KVM could take this second option to increase
+ * the recoverability of NMIs.
+ */
+void hv_nmi_check_nonrecoverable(struct pt_regs *regs)
+{
+#ifdef CONFIG_PPC_POWERNV
+	unsigned long kbase = (unsigned long)_stext;
+	unsigned long nip = regs->nip;
+
+	if (!(regs->msr & MSR_RI))
+		return;
+	if (!(regs->msr & MSR_HV))
+		return;
+	if (regs->msr & MSR_PR)
+		return;
+
+	/*
+	 * Now test if the interrupt has hit a range that may be using
+	 * HSPRG1 without having RI=0 (i.e., an HSRR interrupt). The
+	 * problem ranges all run un-relocated. Test real and virt modes
+	 * at the same time by droping the high bit of the nip (virt mode
+	 * entry points still have the +0x4000 offset).
+	 */
+	nip &= ~0xc000000000000000ULL;
+	if ((nip >= 0x500 && nip < 0x600) || (nip >= 0x4500 && nip < 0x4600))
+		goto nonrecoverable;
+	if ((nip >= 0x980 && nip < 0xa00) || (nip >= 0x4980 && nip < 0x4a00))
+		goto nonrecoverable;
+	if ((nip >= 0xe00 && nip < 0xec0) || (nip >= 0x4e00 && nip < 0x4ec0))
+		goto nonrecoverable;
+	if ((nip >= 0xf80 && nip < 0xfa0) || (nip >= 0x4f80 && nip < 0x4fa0))
+		goto nonrecoverable;
+	/* Trampoline code runs un-relocated so subtract kbase. */
+	if (nip >= real_trampolines_start - kbase &&
+			nip < real_trampolines_end - kbase)
+		goto nonrecoverable;
+	if (nip >= virt_trampolines_start - kbase &&
+			nip < virt_trampolines_end - kbase)
+		goto nonrecoverable;
+	return;
+
+nonrecoverable:
+	regs->msr &= ~MSR_RI;
+#endif
+}
+
 void system_reset_exception(struct pt_regs *regs)
 {
 	/*
@@ -379,6 +443,8 @@ void system_reset_exception(struct pt_regs *regs)
 	if (!nested)
 		nmi_enter();
 
+	hv_nmi_check_nonrecoverable(regs);
+
 	__this_cpu_inc(irq_stat.sreset_irqs);
 
 	/* See if any machine dependent calls */

commit 0bbea75c476b77fa7d7811d6be911cc7583e640f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Jan 22 14:11:24 2019 +0000

    powerpc/traps: fix recoverability of machine check handling on book3s/32
    
    Looks like book3s/32 doesn't set RI on machine check, so
    checking RI before calling die() will always be fatal
    allthought this is not an issue in most cases.
    
    Fixes: b96672dd840f ("powerpc: Machine check interrupt is a non-maskable interrupt")
    Fixes: daf00ae71dad ("powerpc/traps: restore recoverability of machine_check interrupts")
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: stable@vger.kernel.org
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 040b60293613..b25bc8af7d38 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -756,15 +756,15 @@ void machine_check_exception(struct pt_regs *regs)
 	if (check_io_access(regs))
 		goto bail;
 
-	/* Must die if the interrupt is not recoverable */
-	if (!(regs->msr & MSR_RI))
-		nmi_panic(regs, "Unrecoverable Machine check");
-
 	if (!nested)
 		nmi_exit();
 
 	die("Machine check", regs, SIGBUS);
 
+	/* Must die if the interrupt is not recoverable */
+	if (!(regs->msr & MSR_RI))
+		nmi_panic(regs, "Unrecoverable Machine check");
+
 	return;
 
 bail:

commit 9bf3d3c4e4fd82c7174f4856df372ab2a71005b9
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Jan 29 16:37:55 2019 +0000

    powerpc/traps: Fix the message printed when stack overflows
    
    Today's message is useless:
    
      [   42.253267] Kernel stack overflow in process (ptrval), r1=c65500b0
    
    This patch fixes it:
    
      [   66.905235] Kernel stack overflow in process sh[356], r1=c65560b0
    
    Fixes: ad67b74d2469 ("printk: hash addresses printed with %p")
    Cc: stable@vger.kernel.org # v4.15+
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Use task_pid_nr()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5e917a84f949..040b60293613 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1535,8 +1535,8 @@ void alignment_exception(struct pt_regs *regs)
 
 void StackOverflow(struct pt_regs *regs)
 {
-	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",
-	       current, regs->gpr[1]);
+	pr_crit("Kernel stack overflow in process %s[%d], r1=%lx\n",
+		current->comm, task_pid_nr(current), regs->gpr[1]);
 	debugger(regs);
 	show_regs(regs);
 	panic("kernel stack overflow");

commit 16842516ea9cb237079cb9ffcb6466ce760fc37d
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jan 10 22:57:37 2019 +1100

    powerpc/64s: Add MMU type to __die() output
    
    On Power9 machines (64-bit Book3S), we can be running with either the
    Hash table or Radix tree MMU enabled. So add some text to the __die()
    output to tell us which is enabled, for the case where all you have is
    the oops output and no other information.
    
    Example output:
    
      kernel BUG at drivers/misc/lkdtm/bugs.c:63!
      Oops: Exception in kernel mode, sig: 5 [#1]
      LE PAGE_SIZE=64K MMU=Hash SMP NR_CPUS=2048 NUMA pSeries
      Modules linked in: kvm vmx_crypto binfmt_misc ip_tables x_tables
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a872c64618ad..5e917a84f949 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -257,9 +257,11 @@ static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 
-	printk("%s PAGE_SIZE=%luK%s%s%s%s%s %s\n",
+	printk("%s PAGE_SIZE=%luK%s%s%s%s%s%s%s %s\n",
 	       IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN) ? "LE" : "BE",
 	       PAGE_SIZE / 1024,
+	       early_radix_enabled() ? " MMU=Radix" : "",
+	       early_mmu_has_feature(MMU_FTR_HPTE_TABLE) ? " MMU=Hash" : "",
 	       IS_ENABLED(CONFIG_PREEMPT) ? " PREEMPT" : "",
 	       IS_ENABLED(CONFIG_SMP) ? " SMP" : "",
 	       IS_ENABLED(CONFIG_SMP) ? (" NR_CPUS=" __stringify(NR_CPUS)) : "",

commit 184051396b9d75a2a9ae64f134f3ee9d7250801c
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jan 10 22:57:36 2019 +1100

    powerpc: Show PAGE_SIZE in __die() output
    
    The page size the kernel is built with is useful info when debugging a
    crash, so add it to the output in __die().
    
    Result looks like eg:
    
      kernel BUG at drivers/misc/lkdtm/bugs.c:63!
      Oops: Exception in kernel mode, sig: 5 [#1]
      LE PAGE_SIZE=64K SMP NR_CPUS=2048 NUMA pSeries
      Modules linked in: vmx_crypto kvm binfmt_misc ip_tables
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 164fc92895be..a872c64618ad 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -257,8 +257,9 @@ static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 
-	printk("%s %s%s%s%s%s %s\n",
+	printk("%s PAGE_SIZE=%luK%s%s%s%s%s %s\n",
 	       IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN) ? "LE" : "BE",
+	       PAGE_SIZE / 1024,
 	       IS_ENABLED(CONFIG_PREEMPT) ? " PREEMPT" : "",
 	       IS_ENABLED(CONFIG_SMP) ? " SMP" : "",
 	       IS_ENABLED(CONFIG_SMP) ? (" NR_CPUS=" __stringify(NR_CPUS)) : "",

commit 782274434d6f2e8aa8c573cb24fef94a164f2ce0
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jan 10 22:57:35 2019 +1100

    powerpc: Stop using pr_cont() in __die()
    
    Using pr_cont() risks having our output interleaved with other output
    from other CPUs. Instead print everything in a single printk() call.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 64936b60d521..164fc92895be 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -257,24 +257,14 @@ static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 
-	if (IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN))
-		printk("LE ");
-	else
-		printk("BE ");
-
-	if (IS_ENABLED(CONFIG_PREEMPT))
-		pr_cont("PREEMPT ");
-
-	if (IS_ENABLED(CONFIG_SMP))
-		pr_cont("SMP NR_CPUS=%d ", NR_CPUS);
-
-	if (debug_pagealloc_enabled())
-		pr_cont("DEBUG_PAGEALLOC ");
-
-	if (IS_ENABLED(CONFIG_NUMA))
-		pr_cont("NUMA ");
-
-	pr_cont("%s\n", ppc_md.name ? ppc_md.name : "");
+	printk("%s %s%s%s%s%s %s\n",
+	       IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN) ? "LE" : "BE",
+	       IS_ENABLED(CONFIG_PREEMPT) ? " PREEMPT" : "",
+	       IS_ENABLED(CONFIG_SMP) ? " SMP" : "",
+	       IS_ENABLED(CONFIG_SMP) ? (" NR_CPUS=" __stringify(NR_CPUS)) : "",
+	       debug_pagealloc_enabled() ? " DEBUG_PAGEALLOC" : "",
+	       IS_ENABLED(CONFIG_NUMA) ? " NUMA" : "",
+	       ppc_md.name ? ppc_md.name : "");
 
 	if (notify_die(DIE_OOPS, str, regs, err, 255, SIGSEGV) == NOTIFY_STOP)
 		return 1;

commit 96d4f267e40f9509e8a66e2b39e8b95655617693
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 3 18:57:57 2019 -0800

    Remove 'type' argument from access_ok() function
    
    Nobody has actually used the type (VERIFY_READ vs VERIFY_WRITE) argument
    of the user address range verification function since we got rid of the
    old racy i386-only code to walk page tables by hand.
    
    It existed because the original 80386 would not honor the write protect
    bit when in kernel mode, so you had to do COW by hand before doing any
    user access.  But we haven't supported that in a long time, and these
    days the 'type' argument is a purely historical artifact.
    
    A discussion about extending 'user_access_begin()' to do the range
    checking resulted this patch, because there is no way we're going to
    move the old VERIFY_xyz interface to that model.  And it's best done at
    the end of the merge window when I've done most of my merges, so let's
    just get this done once and for all.
    
    This patch was mostly done with a sed-script, with manual fix-ups for
    the cases that weren't of the trivial 'access_ok(VERIFY_xyz' form.
    
    There were a couple of notable cases:
    
     - csky still had the old "verify_area()" name as an alias.
    
     - the iter_iov code had magical hardcoded knowledge of the actual
       values of VERIFY_{READ,WRITE} (not that they mattered, since nothing
       really used it)
    
     - microblaze used the type argument for a debug printout
    
    but other than those oddities this should be a total no-op patch.
    
    I tried to fix up all architectures, did fairly extensive grepping for
    access_ok() uses, and the changes are trivial, but I may have missed
    something.  Any missed conversion should be trivially fixable, though.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 00af2c4febf4..64936b60d521 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -837,7 +837,7 @@ static void p9_hmi_special_emu(struct pt_regs *regs)
 	addr = (__force const void __user *)ea;
 
 	/* Check it */
-	if (!access_ok(VERIFY_READ, addr, 16)) {
+	if (!access_ok(addr, 16)) {
 		pr_devel("HMI vec emu: bad access %i:%s[%d] nip=%016lx"
 			 " instr=%08x addr=%016lx\n",
 			 smp_processor_id(), current->comm, current->pid,

commit 11be39584a2e283d2b2bc45f3202519aef703b7c
Author: Breno Leitao <leitao@debian.org>
Date:   Mon Nov 26 18:11:59 2018 -0200

    powerpc/tm: Print scratch value
    
    Usually a TM Bad Thing exception is raised due to three different problems.
    a) touching SPRs in an active transaction; b) using TM instruction with the
    facility disabled and c) setting a wrong MSR/SRR1 at RFID.
    
    The two initial cases are easy to identify by looking at the instructions.
    The latter case is harder, because the MSR is masked after RFID, so, it is
    very useful to look at the previous MSR (SRR1) before RFID as also the
    current and masked MSR.
    
    Since MSR is saved at paca just before RFID, this patch prints it if a TM
    Bad thing happen, helping to understand what is the invalid TM transition
    that is causing the exception.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9a86572db1ef..00af2c4febf4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1434,7 +1434,8 @@ void program_check_exception(struct pt_regs *regs)
 			goto bail;
 		} else {
 			printk(KERN_EMERG "Unexpected TM Bad Thing exception "
-			       "at %lx (msr 0x%lx)\n", regs->nip, regs->msr);
+			       "at %lx (msr 0x%lx) tm_scratch=%llx\n",
+			       regs->nip, regs->msr, get_paca()->tm_scratch);
 			die("Unrecoverable exception", regs, SIGABRT);
 		}
 	}

commit 685f7e4f161425b137056abe35ba8ef7b669d83d
Merge: c7a2c49ea6c9 58cfbac25b1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 26 14:36:21 2018 -0700

    Merge tag 'powerpc-4.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - A large series to rewrite our SLB miss handling, replacing a lot of
         fairly complicated asm with much fewer lines of C.
    
       - Following on from that, we now maintain a cache of SLB entries for
         each process and preload them on context switch. Leading to a 27%
         speedup for our context switch benchmark on Power9.
    
       - Improvements to our handling of SLB multi-hit errors. We now print
         more debug information when they occur, and try to continue running
         by flushing the SLB and reloading, rather than treating them as
         fatal.
    
       - Enable THP migration on 64-bit Book3S machines (eg. Power7/8/9).
    
       - Add support for physical memory up to 2PB in the linear mapping on
         64-bit Book3S. We only support up to 512TB as regular system
         memory, otherwise the percpu allocator runs out of vmalloc space.
    
       - Add stack protector support for 32 and 64-bit, with a per-task
         canary.
    
       - Add support for PTRACE_SYSEMU and PTRACE_SYSEMU_SINGLESTEP.
    
       - Support recognising "big cores" on Power9, where two SMT4 cores are
         presented to us as a single SMT8 core.
    
       - A large series to cleanup some of our ioremap handling and PTE
         flags.
    
       - Add a driver for the PAPR SCM (storage class memory) interface,
         allowing guests to operate on SCM devices (acked by Dan).
    
       - Changes to our ftrace code to handle very large kernels, where we
         need to use a trampoline to get to ftrace_caller().
    
      And many other smaller enhancements and cleanups.
    
      Thanks to: Alan Modra, Alistair Popple, Aneesh Kumar K.V, Anton
      Blanchard, Aravinda Prasad, Bartlomiej Zolnierkiewicz, Benjamin
      Herrenschmidt, Breno Leitao, CÃ©dric Le Goater, Christophe Leroy,
      Christophe Lombard, Dan Carpenter, Daniel Axtens, Finn Thain, Gautham
      R. Shenoy, Gustavo Romero, Haren Myneni, Hari Bathini, Jia Hongtao,
      Joel Stanley, John Allen, Laurent Dufour, Madhavan Srinivasan, Mahesh
      Salgaonkar, Mark Hairgrove, Masahiro Yamada, Michael Bringmann,
      Michael Neuling, Michal Suchanek, Murilo Opsfelder Araujo, Nathan
      Fontenot, Naveen N. Rao, Nicholas Piggin, Nick Desaulniers, Oliver
      O'Halloran, Paul Mackerras, Petr Vorel, Rashmica Gupta, Reza Arbab,
      Rob Herring, Sam Bobroff, Samuel Mendoza-Jonas, Scott Wood, Stan
      Johnson, Stephen Rothwell, Stewart Smith, Suraj Jitindar Singh, Tyrel
      Datwyler, Vaibhav Jain, Vasant Hegde, YueHaibing, zhong jiang"
    
    * tag 'powerpc-4.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (221 commits)
      Revert "selftests/powerpc: Fix out-of-tree build errors"
      powerpc/msi: Fix compile error on mpc83xx
      powerpc: Fix stack protector crashes on CPU hotplug
      powerpc/traps: restore recoverability of machine_check interrupts
      powerpc/64/module: REL32 relocation range check
      powerpc/64s/radix: Fix radix__flush_tlb_collapsed_pmd double flushing pmd
      selftests/powerpc: Add a test of wild bctr
      powerpc/mm: Fix page table dump to work on Radix
      powerpc/mm/radix: Display if mappings are exec or not
      powerpc/mm/radix: Simplify split mapping logic
      powerpc/mm/radix: Remove the retry in the split mapping logic
      powerpc/mm/radix: Fix small page at boundary when splitting
      powerpc/mm/radix: Fix overuse of small pages in splitting logic
      powerpc/mm/radix: Fix off-by-one in split mapping logic
      powerpc/ftrace: Handle large kernel configs
      powerpc/mm: Fix WARN_ON with THP NUMA migration
      selftests/powerpc: Fix out-of-tree build errors
      powerpc/time: no steal_time when CONFIG_PPC_SPLPAR is not selected
      powerpc/time: Only set CONFIG_ARCH_HAS_SCALED_CPUTIME on PPC64
      powerpc/time: isolate scaled cputime accounting in dedicated functions.
      ...

commit daf00ae71dad8aa05965713c62558aeebf2df48e
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Oct 13 09:16:22 2018 +0000

    powerpc/traps: restore recoverability of machine_check interrupts
    
    commit b96672dd840f ("powerpc: Machine check interrupt is a non-
    maskable interrupt") added a call to nmi_enter() at the beginning of
    machine check restart exception handler. Due to that, in_interrupt()
    always returns true regardless of the state before entering the
    exception, and die() panics even when the system was not already in
    interrupt.
    
    This patch calls nmi_exit() before calling die() in order to restore
    the interrupt state we had before calling nmi_enter()
    
    Fixes: b96672dd840f ("powerpc: Machine check interrupt is a non-maskable interrupt")
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f1629a8acc4b..47904cd1ff46 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -763,12 +763,17 @@ void machine_check_exception(struct pt_regs *regs)
 	if (check_io_access(regs))
 		goto bail;
 
-	die("Machine check", regs, SIGBUS);
-
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		nmi_panic(regs, "Unrecoverable Machine check");
 
+	if (!nested)
+		nmi_exit();
+
+	die("Machine check", regs, SIGBUS);
+
+	return;
+
 bail:
 	if (!nested)
 		nmi_exit();

commit bd03fd84a53ac9ddaeb0a0fc4c4c9836e12f3ab9
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Oct 15 07:38:10 2018 +0000

    powerpc/traps: remove redundant in_interrupt panic in die()
    
    do_exit() already includes a test to panic() is in_interrupt()
    
    This patch removes powerpc one which is redundant.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c8559b2c2c81..f1629a8acc4b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -247,8 +247,6 @@ static void oops_end(unsigned long flags, struct pt_regs *regs,
 		mdelay(MSEC_PER_SEC);
 	}
 
-	if (in_interrupt())
-		panic("Fatal exception in interrupt");
 	if (panic_on_oops)
 		panic("Fatal exception");
 	do_exit(signr);

commit 422123ccb9a13dcea2e008194ae6c262fbb64604
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Oct 15 07:20:45 2018 +0000

    powerpc/traps: fix machine check handlers to use pr_cont()
    
    When printing the machine check cause, the cause appears on the
    following line due to bad use of printk without \n:
    
    [   33.663993] Machine check in kernel mode.
    [   33.664011] Caused by (from SRR1=9032):
    [   33.664036] Data access error at address c90c8000
    
    This patch fixes it by using pr_cont() for the second part:
    
    [  133.258131] Machine check in kernel mode.
    [  133.258146] Caused by (from SRR1=9032): Data access error at address c90c8000
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index fd58749b4d6b..c8559b2c2c81 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -535,10 +535,10 @@ int machine_check_e500mc(struct pt_regs *regs)
 	printk("Caused by (from MCSR=%lx): ", reason);
 
 	if (reason & MCSR_MCP)
-		printk("Machine Check Signal\n");
+		pr_cont("Machine Check Signal\n");
 
 	if (reason & MCSR_ICPERR) {
-		printk("Instruction Cache Parity Error\n");
+		pr_cont("Instruction Cache Parity Error\n");
 
 		/*
 		 * This is recoverable by invalidating the i-cache.
@@ -556,7 +556,7 @@ int machine_check_e500mc(struct pt_regs *regs)
 	}
 
 	if (reason & MCSR_DCPERR_MC) {
-		printk("Data Cache Parity Error\n");
+		pr_cont("Data Cache Parity Error\n");
 
 		/*
 		 * In write shadow mode we auto-recover from the error, but it
@@ -575,38 +575,38 @@ int machine_check_e500mc(struct pt_regs *regs)
 	}
 
 	if (reason & MCSR_L2MMU_MHIT) {
-		printk("Hit on multiple TLB entries\n");
+		pr_cont("Hit on multiple TLB entries\n");
 		recoverable = 0;
 	}
 
 	if (reason & MCSR_NMI)
-		printk("Non-maskable interrupt\n");
+		pr_cont("Non-maskable interrupt\n");
 
 	if (reason & MCSR_IF) {
-		printk("Instruction Fetch Error Report\n");
+		pr_cont("Instruction Fetch Error Report\n");
 		recoverable = 0;
 	}
 
 	if (reason & MCSR_LD) {
-		printk("Load Error Report\n");
+		pr_cont("Load Error Report\n");
 		recoverable = 0;
 	}
 
 	if (reason & MCSR_ST) {
-		printk("Store Error Report\n");
+		pr_cont("Store Error Report\n");
 		recoverable = 0;
 	}
 
 	if (reason & MCSR_LDG) {
-		printk("Guarded Load Error Report\n");
+		pr_cont("Guarded Load Error Report\n");
 		recoverable = 0;
 	}
 
 	if (reason & MCSR_TLBSYNC)
-		printk("Simultaneous tlbsync operations\n");
+		pr_cont("Simultaneous tlbsync operations\n");
 
 	if (reason & MCSR_BSL2_ERR) {
-		printk("Level 2 Cache Error\n");
+		pr_cont("Level 2 Cache Error\n");
 		recoverable = 0;
 	}
 
@@ -616,7 +616,7 @@ int machine_check_e500mc(struct pt_regs *regs)
 		addr = mfspr(SPRN_MCAR);
 		addr |= (u64)mfspr(SPRN_MCARU) << 32;
 
-		printk("Machine Check %s Address: %#llx\n",
+		pr_cont("Machine Check %s Address: %#llx\n",
 		       reason & MCSR_MEA ? "Effective" : "Physical", addr);
 	}
 
@@ -640,29 +640,29 @@ int machine_check_e500(struct pt_regs *regs)
 	printk("Caused by (from MCSR=%lx): ", reason);
 
 	if (reason & MCSR_MCP)
-		printk("Machine Check Signal\n");
+		pr_cont("Machine Check Signal\n");
 	if (reason & MCSR_ICPERR)
-		printk("Instruction Cache Parity Error\n");
+		pr_cont("Instruction Cache Parity Error\n");
 	if (reason & MCSR_DCP_PERR)
-		printk("Data Cache Push Parity Error\n");
+		pr_cont("Data Cache Push Parity Error\n");
 	if (reason & MCSR_DCPERR)
-		printk("Data Cache Parity Error\n");
+		pr_cont("Data Cache Parity Error\n");
 	if (reason & MCSR_BUS_IAERR)
-		printk("Bus - Instruction Address Error\n");
+		pr_cont("Bus - Instruction Address Error\n");
 	if (reason & MCSR_BUS_RAERR)
-		printk("Bus - Read Address Error\n");
+		pr_cont("Bus - Read Address Error\n");
 	if (reason & MCSR_BUS_WAERR)
-		printk("Bus - Write Address Error\n");
+		pr_cont("Bus - Write Address Error\n");
 	if (reason & MCSR_BUS_IBERR)
-		printk("Bus - Instruction Data Error\n");
+		pr_cont("Bus - Instruction Data Error\n");
 	if (reason & MCSR_BUS_RBERR)
-		printk("Bus - Read Data Bus Error\n");
+		pr_cont("Bus - Read Data Bus Error\n");
 	if (reason & MCSR_BUS_WBERR)
-		printk("Bus - Write Data Bus Error\n");
+		pr_cont("Bus - Write Data Bus Error\n");
 	if (reason & MCSR_BUS_IPERR)
-		printk("Bus - Instruction Parity Error\n");
+		pr_cont("Bus - Instruction Parity Error\n");
 	if (reason & MCSR_BUS_RPERR)
-		printk("Bus - Read Parity Error\n");
+		pr_cont("Bus - Read Parity Error\n");
 
 	return 0;
 }
@@ -680,19 +680,19 @@ int machine_check_e200(struct pt_regs *regs)
 	printk("Caused by (from MCSR=%lx): ", reason);
 
 	if (reason & MCSR_MCP)
-		printk("Machine Check Signal\n");
+		pr_cont("Machine Check Signal\n");
 	if (reason & MCSR_CP_PERR)
-		printk("Cache Push Parity Error\n");
+		pr_cont("Cache Push Parity Error\n");
 	if (reason & MCSR_CPERR)
-		printk("Cache Parity Error\n");
+		pr_cont("Cache Parity Error\n");
 	if (reason & MCSR_EXCP_ERR)
-		printk("ISI, ITLB, or Bus Error on first instruction fetch for an exception handler\n");
+		pr_cont("ISI, ITLB, or Bus Error on first instruction fetch for an exception handler\n");
 	if (reason & MCSR_BUS_IRERR)
-		printk("Bus - Read Bus Error on instruction fetch\n");
+		pr_cont("Bus - Read Bus Error on instruction fetch\n");
 	if (reason & MCSR_BUS_DRERR)
-		printk("Bus - Read Bus Error on data load\n");
+		pr_cont("Bus - Read Bus Error on data load\n");
 	if (reason & MCSR_BUS_WRERR)
-		printk("Bus - Write Bus Error on buffered store or cache line push\n");
+		pr_cont("Bus - Write Bus Error on buffered store or cache line push\n");
 
 	return 0;
 }
@@ -705,30 +705,30 @@ int machine_check_generic(struct pt_regs *regs)
 	printk("Caused by (from SRR1=%lx): ", reason);
 	switch (reason & 0x601F0000) {
 	case 0x80000:
-		printk("Machine check signal\n");
+		pr_cont("Machine check signal\n");
 		break;
 	case 0:		/* for 601 */
 	case 0x40000:
 	case 0x140000:	/* 7450 MSS error and TEA */
-		printk("Transfer error ack signal\n");
+		pr_cont("Transfer error ack signal\n");
 		break;
 	case 0x20000:
-		printk("Data parity error signal\n");
+		pr_cont("Data parity error signal\n");
 		break;
 	case 0x10000:
-		printk("Address parity error signal\n");
+		pr_cont("Address parity error signal\n");
 		break;
 	case 0x20000000:
-		printk("L1 Data Cache error\n");
+		pr_cont("L1 Data Cache error\n");
 		break;
 	case 0x40000000:
-		printk("L1 Instruction Cache error\n");
+		pr_cont("L1 Instruction Cache error\n");
 		break;
 	case 0x00100000:
-		printk("L2 data cache parity error\n");
+		pr_cont("L2 data cache parity error\n");
 		break;
 	default:
-		printk("Unknown values in msr\n");
+		pr_cont("Unknown values in msr\n");
 	}
 	return 0;
 }

commit 8a03e81cb14712f986c5d5fa42a30ff2cbe3237c
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Wed Sep 26 14:24:30 2018 +0200

    powerpc/64s: consolidate MCE counter increment.
    
    The code in machine_check_exception excludes 64s hvmode when
    incrementing the MCE counter only to call opal_machine_check to
    increment it specifically for this case.
    
    Remove the exclusion and special case.
    
    Fixes: a43c1590426c ("powerpc/pseries: Flush SLB contents on SLB MCE
                    errors.")
    
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5ef85ab49dc3..fd58749b4d6b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -741,9 +741,7 @@ void machine_check_exception(struct pt_regs *regs)
 	if (!nested)
 		nmi_enter();
 
-	/* 64s accounts the mce in machine_check_early when in HVMODE */
-	if (!IS_ENABLED(CONFIG_PPC_BOOK3S_64) || !cpu_has_feature(CPU_FTR_HVMODE))
-		__this_cpu_inc(irq_stat.mce_exceptions);
+	__this_cpu_inc(irq_stat.mce_exceptions);
 
 	add_taint(TAINT_MACHINE_CHECK, LOCKDEP_NOW_UNRELIABLE);
 

commit 51303113e32fd92d327b3c441c45e235642fa69c
Author: Breno Leitao <leitao@debian.org>
Date:   Tue Aug 7 10:35:00 2018 -0300

    powerpc/tm: Print 64-bits MSR
    
    On a kernel TM Bad thing program exception, the Machine State Register
    (MSR) is not being properly displayed. The exception code dumps a 32-bits
    value but MSR is a 64 bits register for all platforms that have HTM
    enabled.
    
    This patch dumps the MSR value as a 64-bits value instead of 32 bits. In
    order to do so, the 'reason' variable could not be used, since it trimmed
    MSR to 32-bits (int).
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a29575215198..5ef85ab49dc3 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1433,7 +1433,7 @@ void program_check_exception(struct pt_regs *regs)
 			goto bail;
 		} else {
 			printk(KERN_EMERG "Unexpected TM Bad Thing exception "
-			       "at %lx (msr 0x%x)\n", regs->nip, reason);
+			       "at %lx (msr 0x%lx)\n", regs->nip, regs->msr);
 			die("Unrecoverable exception", regs, SIGABRT);
 		}
 	}

commit 51423a9c9b09352bea1c53b8324db78bf3b170d1
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Sep 25 14:10:04 2018 +0000

    powerpc/traps: merge unrecoverable_exception() and nonrecoverable_exception()
    
    PPC32 uses nonrecoverable_exception() while PPC64 uses
    unrecoverable_exception().
    
    Both functions are doing almost the same thing.
    
    This patch removes nonrecoverable_exception()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6ab66a88db14..a29575215198 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1547,14 +1547,6 @@ void StackOverflow(struct pt_regs *regs)
 	panic("kernel stack overflow");
 }
 
-void nonrecoverable_exception(struct pt_regs *regs)
-{
-	printk(KERN_ERR "Non-recoverable exception at PC=%lx MSR=%lx\n",
-	       regs->nip, regs->msr);
-	debugger(regs);
-	die("nonrecoverable exception", regs, SIGKILL);
-}
-
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
@@ -2090,8 +2082,8 @@ void SPEFloatingPointRoundException(struct pt_regs *regs)
  */
 void unrecoverable_exception(struct pt_regs *regs)
 {
-	printk(KERN_EMERG "Unrecoverable exception %lx at %lx\n",
-	       regs->trap, regs->nip);
+	pr_emerg("Unrecoverable exception %lx at %lx (msr=%lx)\n",
+		 regs->trap, regs->nip, regs->msr);
 	die("Unrecoverable exception", regs, SIGABRT);
 }
 NOKPROBE_SYMBOL(unrecoverable_exception);

commit 77c70728db9fb2d7698e8228f9978197c8f4f411
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 18 11:26:32 2018 +0200

    signal/powerpc: Simplify _exception_pkey by using force_sig_pkuerr
    
    Call force_sig_pkuerr directly instead of rolling it by hand
    in _exception_pkey.
    
    Reviewed-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e5ea69222459..ab1bd06d7c44 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -364,18 +364,10 @@ static bool exception_common(int signr, struct pt_regs *regs, int code,
 
 void _exception_pkey(struct pt_regs *regs, unsigned long addr, int key)
 {
-	siginfo_t info;
-
 	if (!exception_common(SIGSEGV, regs, SEGV_PKUERR, addr))
 		return;
 
-	clear_siginfo(&info);
-	info.si_signo = SIGSEGV;
-	info.si_code = SEGV_PKUERR;
-	info.si_addr = (void __user *) addr;
-	info.si_pkey = key;
-
-	force_sig_info(info.si_signo, &info, current);
+	force_sig_pkuerr((void __user *) addr, key);
 }
 
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)

commit 5d8fb8a58659098a845235f08c1f69de0c96297c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 18 10:56:25 2018 +0200

    signal/powerpc: Specialize _exception_pkey for handling pkey exceptions
    
    Now that _exception no longer calls _exception_pkey it is no longer
    necessary to handle any signal with any si_code.  All pkey exceptions
    are SIGSEGV with paired with SEGV_PKUERR.  So just handle
    that case and remove the now unnecessary parameters from _exception_pkey.
    
    Reviewed-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c38bec51dd84..e5ea69222459 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -362,20 +362,20 @@ static bool exception_common(int signr, struct pt_regs *regs, int code,
 	return true;
 }
 
-void _exception_pkey(int signr, struct pt_regs *regs, int code, unsigned long addr, int key)
+void _exception_pkey(struct pt_regs *regs, unsigned long addr, int key)
 {
 	siginfo_t info;
 
-	if (!exception_common(signr, regs, code, addr))
+	if (!exception_common(SIGSEGV, regs, SEGV_PKUERR, addr))
 		return;
 
 	clear_siginfo(&info);
-	info.si_signo = signr;
-	info.si_code = code;
+	info.si_signo = SIGSEGV;
+	info.si_code = SEGV_PKUERR;
 	info.si_addr = (void __user *) addr;
 	info.si_pkey = key;
 
-	force_sig_info(signr, &info, current);
+	force_sig_info(info.si_signo, &info, current);
 }
 
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)

commit c1c7c85ceafe5a96c4d5fc648ff42a7102838dd7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 18 09:43:32 2018 +0200

    signal/powerpc: Call force_sig_fault from _exception
    
    The callers of _exception don't need the pkey exception logic because
    they are not processing a pkey exception.  So just call exception_common
    directly and then call force_sig_fault to generate the appropriate siginfo
    and deliver the appropriate signal.
    
    Reviewed-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f6c778b5144f..c38bec51dd84 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -380,7 +380,10 @@ void _exception_pkey(int signr, struct pt_regs *regs, int code, unsigned long ad
 
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 {
-	_exception_pkey(signr, regs, code, addr, 0);
+	if (!exception_common(signr, regs, code, addr))
+		return;
+
+	force_sig_fault(signr, code, (void __user *)addr, current);
 }
 
 void system_reset_exception(struct pt_regs *regs)

commit 2c44ce285fdd21713769bace4c27336d134be8a5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 18 09:37:28 2018 +0200

    signal/powerpc: Factor the common exception code into exception_common
    
    It is brittle and wrong to populate si_pkey when there was not a pkey
    exception.  The field does not exist for all si_codes and in some
    cases another field exists in the same memory location.
    
    So factor out the code that all exceptions handlers must run
    into exception_common, leaving the individual exception handlers
    to generate the signals themselves.
    
    Reviewed-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f651fa91cdc9..f6c778b5144f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -338,14 +338,12 @@ static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 	show_user_instructions(regs);
 }
 
-void _exception_pkey(int signr, struct pt_regs *regs, int code,
-		     unsigned long addr, int key)
+static bool exception_common(int signr, struct pt_regs *regs, int code,
+			      unsigned long addr)
 {
-	siginfo_t info;
-
 	if (!user_mode(regs)) {
 		die("Exception in kernel mode", regs, signr);
-		return;
+		return false;
 	}
 
 	show_signal_msg(signr, regs, code, addr);
@@ -361,6 +359,16 @@ void _exception_pkey(int signr, struct pt_regs *regs, int code,
 	 */
 	thread_pkey_regs_save(&current->thread);
 
+	return true;
+}
+
+void _exception_pkey(int signr, struct pt_regs *regs, int code, unsigned long addr, int key)
+{
+	siginfo_t info;
+
+	if (!exception_common(signr, regs, code, addr))
+		return;
+
 	clear_siginfo(&info);
 	info.si_signo = signr;
 	info.si_code = code;

commit efc463adbccf709c5dbaf6cfbf84b7e94b62810a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 16 14:18:26 2018 -0500

    signal: Simplify tracehook_report_syscall_exit
    
    Replace user_single_step_siginfo with user_single_step_report
    that allocates siginfo structure on the stack and sends it.
    
    This allows tracehook_report_syscall_exit to become a simple
    if statement that calls user_single_step_report or ptrace_report_syscall
    depending on the value of step.
    
    Update the default helper function now called user_single_step_report
    to explicitly set si_code to SI_USER and to set si_uid and si_pid to 0.
    The default helper has always been doing this (using memset) but it
    was far from obvious.
    
    The powerpc helper can now just call force_sig_fault.
    The x86 helper can now just call send_sigtrap.
    
    Unfortunately the default implementation of user_single_step_report
    can not use force_sig_fault as it does not use a SIGTRAP si_code.
    So it has to carefully setup the siginfo and use use force_sig_info.
    
    The net result is code that is easier to understand and simpler
    to maintain.
    
    Ref: 85ec7fd9f8e5 ("ptrace: introduce user_single_step_siginfo() helper")
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c85adb858271..f651fa91cdc9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -307,12 +307,9 @@ void die(const char *str, struct pt_regs *regs, long err)
 }
 NOKPROBE_SYMBOL(die);
 
-void user_single_step_siginfo(struct task_struct *tsk,
-				struct pt_regs *regs, siginfo_t *info)
+void user_single_step_report(struct pt_regs *regs)
 {
-	info->si_signo = SIGTRAP;
-	info->si_code = TRAP_TRACE;
-	info->si_addr = (void __user *)regs->nip;
+	force_sig_fault(SIGTRAP, TRAP_TRACE, (void __user *)regs->nip, current);
 }
 
 static void show_signal_msg(int signr, struct pt_regs *regs, int code,

commit 96695563cebfb810b09479a9951ebbc466fa4c68
Author: Breno Leitao <leitao@debian.org>
Date:   Mon Jun 18 19:59:42 2018 -0300

    powerpc/tm: Fix HTM documentation
    
    This patch simply fix part of the documentation on the HTM code.
    
    This fixes reference to old fields that were renamed in commit
    000ec280e3dd ("powerpc: tm: Rename transct_(*) to ck(\1)_state")
    
    It also documents better the flow after commit eb5c3f1c8647 ("powerpc:
    Always save/restore checkpointed regs during treclaim/trecheckpoint"),
    where tm_recheckpoint can recheckpoint what is in ck{fp,vr}_state
    blindly.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Acked-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c85adb858271..6ab66a88db14 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1750,16 +1750,20 @@ void fp_unavailable_tm(struct pt_regs *regs)
          * checkpointed FP registers need to be loaded.
 	 */
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
-	/* Reclaim didn't save out any FPRs to transact_fprs. */
+
+	/*
+	 * Reclaim initially saved out bogus (lazy) FPRs to ckfp_state, and
+	 * then it was overwrite by the thr->fp_state by tm_reclaim_thread().
+	 *
+	 * At this point, ck{fp,vr}_state contains the exact values we want to
+	 * recheckpoint.
+	 */
 
 	/* Enable FP for the task: */
 	current->thread.load_fp = 1;
 
-	/* This loads and recheckpoints the FP registers from
-	 * thread.fpr[].  They will remain in registers after the
-	 * checkpoint so we don't need to reload them after.
-	 * If VMX is in use, the VRs now hold checkpointed values,
-	 * so we don't want to load the VRs from the thread_struct.
+	/*
+	 * Recheckpoint all the checkpointed ckpt, ck{fp, vr}_state registers.
 	 */
 	tm_recheckpoint(&current->thread);
 }

commit 997dd26cb3c8b7c9b8765751cc1491ad33b2024f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Aug 16 15:27:47 2018 +1000

    powerpc/traps: Avoid rate limit messages from show unhandled signals
    
    In the recent commit to add an explicit ratelimit state when showing
    unhandled signals, commit 35a52a10c3ac ("powerpc/traps: Use an
    explicit ratelimit state for show_signal_msg()"), I put the check of
    show_unhandled_signals and the ratelimit state before the call to
    unhandled_signal() so as to avoid unnecessarily calling the latter
    when show_unhandled_signals is false.
    
    However that causes us to check the ratelimit state on every call, so
    if we take a lot of *handled* signals that has the effect of making
    the ratelimit code print warnings that callbacks have been suppressed
    when they haven't.
    
    So rearrange the code so that we check show_unhandled_signals first,
    then call unhandled_signal() and finally check the ratelimit state.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 070e96f1773a..c85adb858271 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -315,22 +315,21 @@ void user_single_step_siginfo(struct task_struct *tsk,
 	info->si_addr = (void __user *)regs->nip;
 }
 
-static bool show_unhandled_signals_ratelimited(void)
+static void show_signal_msg(int signr, struct pt_regs *regs, int code,
+			    unsigned long addr)
 {
 	static DEFINE_RATELIMIT_STATE(rs, DEFAULT_RATELIMIT_INTERVAL,
 				      DEFAULT_RATELIMIT_BURST);
-	return show_unhandled_signals && __ratelimit(&rs);
-}
 
-static void show_signal_msg(int signr, struct pt_regs *regs, int code,
-			    unsigned long addr)
-{
-	if (!show_unhandled_signals_ratelimited())
+	if (!show_unhandled_signals)
 		return;
 
 	if (!unhandled_signal(current, signr))
 		return;
 
+	if (!__ratelimit(&rs))
+		return;
+
 	pr_info("%s[%d]: %s (%d) at %lx nip %lx lr %lx code %x",
 		current->comm, current->pid, signame(signr), signr,
 		addr, regs->nip, regs->link, code);

commit a99b9c5ed43ecfff5c47c558cc0fcbf8c6503f4c
Author: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
Date:   Wed Aug 1 18:33:20 2018 -0300

    powerpc/traps: Show instructions on exceptions
    
    Call show_user_instructions() in arch/powerpc/kernel/traps.c to dump
    instructions at faulty location, useful to debugging.
    
    Before this patch, an unhandled signal message looked like:
    
      pandafault[10524]: segfault (11) at 100007d0 nip 1000061c lr 7fffbd295100 code 2 in pandafault[10000000+10000]
    
    After this patch, it looks like:
    
      pandafault[10524]: segfault (11) at 100007d0 nip 1000061c lr 7fffbd295100 code 2 in pandafault[10000000+10000]
      pandafault[10524]: code: 4bfffeec 4bfffee8 3c401002 38427f00 fbe1fff8 f821ffc1 7c3f0b78 3d22fffe
      pandafault[10524]: code: 392988d0 f93f0020 e93f0020 39400048 <99490000> 39200000 7d234b78 383f0040
    
    Signed-off-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 171c504d78fb..070e96f1773a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -70,6 +70,7 @@
 #include <asm/hmi.h>
 #include <sysdev/fsl_pci.h>
 #include <asm/kprobes.h>
+#include <asm/stacktrace.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC_CORE)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -337,6 +338,8 @@ static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 	print_vma_addr(KERN_CONT " in ", regs->nip);
 
 	pr_cont("\n");
+
+	show_user_instructions(regs);
 }
 
 void _exception_pkey(int signr, struct pt_regs *regs, int code,

commit 0f642d616b8b15647ca34786877b298ff2970713
Author: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
Date:   Wed Aug 1 18:33:18 2018 -0300

    powerpc/traps: Print VMA for unhandled signals
    
    This adds VMA address in the message printed for unhandled signals,
    similarly to what other architectures, like x86, print.
    
    Before this patch, a page fault looked like:
    
      pandafault[61470]: unhandled signal 11 at 100007d0 nip 1000061c lr 7fff8d185100 code 2
    
    After this patch, a page fault looks like:
    
      pandafault[6303]: segfault 11 at 100007d0 nip 1000061c lr 7fff93c55100 code 2 in pandafault[10000000+10000]
    
    Signed-off-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index eb83cf6b5cb2..171c504d78fb 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -96,6 +96,19 @@ EXPORT_SYMBOL(__debugger_fault_handler);
 #define TM_DEBUG(x...) do { } while(0)
 #endif
 
+static const char *signame(int signr)
+{
+	switch (signr) {
+	case SIGBUS:	return "bus error";
+	case SIGFPE:	return "floating point exception";
+	case SIGILL:	return "illegal instruction";
+	case SIGSEGV:	return "segfault";
+	case SIGTRAP:	return "unhandled trap";
+	}
+
+	return "unknown signal";
+}
+
 /*
  * Trap & Exception support
  */
@@ -317,9 +330,13 @@ static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 	if (!unhandled_signal(current, signr))
 		return;
 
-	pr_info("%s[%d]: unhandled signal %d at %lx nip %lx lr %lx code %x\n",
-		current->comm, current->pid, signr,
+	pr_info("%s[%d]: %s (%d) at %lx nip %lx lr %lx code %x",
+		current->comm, current->pid, signame(signr), signr,
 		addr, regs->nip, regs->link, code);
+
+	print_vma_addr(KERN_CONT " in ", regs->nip);
+
+	pr_cont("\n");
 }
 
 void _exception_pkey(int signr, struct pt_regs *regs, int code,

commit 49d8f2011dddac642a20491a698ad07059ed6096
Author: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
Date:   Wed Aug 1 18:33:17 2018 -0300

    powerpc/traps: Use %lx format in show_signal_msg()
    
    Use %lx format to print registers.  This avoids having two different
    formats and avoids checking for MSR_64BIT, improving readability of the
    function.
    
    Even though we could have used %px, which is functionally equivalent to %lx
    as per Documentation/core-api/printk-formats.rst, it is not semantically
    correct because the data printed are not pointers.  And using %px requires
    casting data to (void *).
    
    Besides that, %lx matches the format used in show_regs().
    
    Before this patch:
    
      pandafault[4808]: unhandled signal 11 at 0000000010000718 nip 0000000010000574 lr 00007fff935e7a6c code 2
    
    After this patch:
    
      pandafault[4732]: unhandled signal 11 at 10000718 nip 10000574 lr 7fff86697a6c code 2
    
    Signed-off-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 47c6620d1609..eb83cf6b5cb2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -311,20 +311,15 @@ static bool show_unhandled_signals_ratelimited(void)
 static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 			    unsigned long addr)
 {
-	const char fmt32[] = KERN_INFO "%s[%d]: unhandled signal %d " \
-		"at %08lx nip %08lx lr %08lx code %x\n";
-	const char fmt64[] = KERN_INFO "%s[%d]: unhandled signal %d " \
-		"at %016lx nip %016lx lr %016lx code %x\n";
-
 	if (!show_unhandled_signals_ratelimited())
 		return;
 
 	if (!unhandled_signal(current, signr))
 		return;
 
-	printk(regs->msr & MSR_64BIT ? fmt64 : fmt32,
-	       current->comm, current->pid, signr,
-	       addr, regs->nip, regs->link, code);
+	pr_info("%s[%d]: unhandled signal %d at %lx nip %lx lr %lx code %x\n",
+		current->comm, current->pid, signr,
+		addr, regs->nip, regs->link, code);
 }
 
 void _exception_pkey(int signr, struct pt_regs *regs, int code,

commit 35a52a10c3ac5b425ff85c12913458b4741ab866
Author: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
Date:   Wed Aug 1 18:33:16 2018 -0300

    powerpc/traps: Use an explicit ratelimit state for show_signal_msg()
    
    Replace printk_ratelimited() by printk() and a default rate limit
    burst to limit displaying unhandled signals messages.
    
    This will allow us to call print_vma_addr() in a future patch, which
    does not work with printk_ratelimited().
    
    Signed-off-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index cbd3dc365193..47c6620d1609 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -301,6 +301,13 @@ void user_single_step_siginfo(struct task_struct *tsk,
 	info->si_addr = (void __user *)regs->nip;
 }
 
+static bool show_unhandled_signals_ratelimited(void)
+{
+	static DEFINE_RATELIMIT_STATE(rs, DEFAULT_RATELIMIT_INTERVAL,
+				      DEFAULT_RATELIMIT_BURST);
+	return show_unhandled_signals && __ratelimit(&rs);
+}
+
 static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 			    unsigned long addr)
 {
@@ -309,11 +316,15 @@ static void show_signal_msg(int signr, struct pt_regs *regs, int code,
 	const char fmt64[] = KERN_INFO "%s[%d]: unhandled signal %d " \
 		"at %016lx nip %016lx lr %016lx code %x\n";
 
-	if (show_unhandled_signals && unhandled_signal(current, signr)) {
-		printk_ratelimited(regs->msr & MSR_64BIT ? fmt64 : fmt32,
-				   current->comm, current->pid, signr,
-				   addr, regs->nip, regs->link, code);
-	}
+	if (!show_unhandled_signals_ratelimited())
+		return;
+
+	if (!unhandled_signal(current, signr))
+		return;
+
+	printk(regs->msr & MSR_64BIT ? fmt64 : fmt32,
+	       current->comm, current->pid, signr,
+	       addr, regs->nip, regs->link, code);
 }
 
 void _exception_pkey(int signr, struct pt_regs *regs, int code,

commit 658b0f92bc7003bc734471f61bf7cd56339eb8c3
Author: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
Date:   Wed Aug 1 18:33:15 2018 -0300

    powerpc/traps: Print unhandled signals in a separate function
    
    Isolate the logic of printing unhandled signals out of _exception_pkey().
    No functional change, only code rearrangement.
    
    Signed-off-by: Murilo Opsfelder Araujo <muriloo@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0e17dcb48720..cbd3dc365193 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -301,26 +301,32 @@ void user_single_step_siginfo(struct task_struct *tsk,
 	info->si_addr = (void __user *)regs->nip;
 }
 
+static void show_signal_msg(int signr, struct pt_regs *regs, int code,
+			    unsigned long addr)
+{
+	const char fmt32[] = KERN_INFO "%s[%d]: unhandled signal %d " \
+		"at %08lx nip %08lx lr %08lx code %x\n";
+	const char fmt64[] = KERN_INFO "%s[%d]: unhandled signal %d " \
+		"at %016lx nip %016lx lr %016lx code %x\n";
+
+	if (show_unhandled_signals && unhandled_signal(current, signr)) {
+		printk_ratelimited(regs->msr & MSR_64BIT ? fmt64 : fmt32,
+				   current->comm, current->pid, signr,
+				   addr, regs->nip, regs->link, code);
+	}
+}
 
 void _exception_pkey(int signr, struct pt_regs *regs, int code,
-		unsigned long addr, int key)
+		     unsigned long addr, int key)
 {
 	siginfo_t info;
-	const char fmt32[] = KERN_INFO "%s[%d]: unhandled signal %d " \
-			"at %08lx nip %08lx lr %08lx code %x\n";
-	const char fmt64[] = KERN_INFO "%s[%d]: unhandled signal %d " \
-			"at %016lx nip %016lx lr %016lx code %x\n";
 
 	if (!user_mode(regs)) {
 		die("Exception in kernel mode", regs, signr);
 		return;
 	}
 
-	if (show_unhandled_signals && unhandled_signal(current, signr)) {
-		printk_ratelimited(regs->msr & MSR_64BIT ? fmt64 : fmt32,
-				   current->comm, current->pid, signr,
-				   addr, regs->nip, regs->link, code);
-	}
+	show_signal_msg(signr, regs, code, addr);
 
 	if (arch_irqs_disabled() && !arch_irq_disabled_regs(regs))
 		local_irq_enable();

commit e821fa42452508bba34be6e54ec58cd2ee23626c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 17 17:10:34 2018 -0500

    signal/powerpc: Replace TRAP_FIXME with TRAP_UNK
    
    Using an si_code of 0 that aliases with SI_USER is clearly the wrong
    thing todo, and causes problems in interesting ways.
    
    For use in unknown_exception the recently defined TRAP_UNK
    semantically is a perfect fit.  For use in RunModeException it looks
    like something more specific than TRAP_UNK could be used.  No one has
    bothered to find a better fit than the broken si_code of 0 in all of
    these years and I don't see an obvious better fit so TRAP_UNK is
    switching RunModeException to return TRAP_UNK is clearly an
    improvement.
    
    Recent history suggests no actually cares about crazy corner
    cases of the kernel behavior like this so I don't expect any
    regressions from changing this.  However if something does
    happen this change is easy to revert.
    
    Though I wonder if SIGKILL might not be a better fit.
    
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Kumar Gala <kumar.gala@freescale.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Fixes: 9bad068c24d7 ("[PATCH] ppc32: support for e500 and 85xx")
    Fixes: 0ed70f6105ef ("PPC32: Provide proper siginfo information on various exceptions.")
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index fdf9400beec8..0e17dcb48720 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -969,7 +969,7 @@ void unknown_exception(struct pt_regs *regs)
 	printk("Bad trap at PC: %lx, SR: %lx, vector=%lx\n",
 	       regs->nip, regs->msr, regs->trap);
 
-	_exception(SIGTRAP, regs, TRAP_FIXME, 0);
+	_exception(SIGTRAP, regs, TRAP_UNK, 0);
 
 	exception_exit(prev_state);
 }
@@ -991,7 +991,7 @@ void instruction_breakpoint_exception(struct pt_regs *regs)
 
 void RunModeException(struct pt_regs *regs)
 {
-	_exception(SIGTRAP, regs, TRAP_FIXME, 0);
+	_exception(SIGTRAP, regs, TRAP_UNK, 0);
 }
 
 void single_step_exception(struct pt_regs *regs)

commit aeb1c0f6ff18f5ec1fe23421bd844d017bb364df
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 17 15:30:54 2018 -0500

    signal/powerpc: Replace FPE_FIXME with FPE_FLTUNK
    
    Using an si_code of 0 that aliases with SI_USER is clearly the
    wrong thing todo, and causes problems in interesting ways.
    
    The newly defined FPE_FLTUNK semantically appears to fit the
    bill so use it instead.
    
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Kumar Gala <kumar.gala@freescale.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc:  linuxppc-dev@lists.ozlabs.org
    Fixes: 9bad068c24d7 ("[PATCH] ppc32: support for e500 and 85xx")
    Fixes: 0ed70f6105ef ("PPC32: Provide proper siginfo information on various exceptions.")
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 087855caf6a9..fdf9400beec8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1031,7 +1031,7 @@ static void emulate_single_step(struct pt_regs *regs)
 
 static inline int __parse_fpscr(unsigned long fpscr)
 {
-	int ret = FPE_FIXME;
+	int ret = FPE_FLTUNK;
 
 	/* Invalid operation */
 	if ((fpscr & FPSCR_VE) && (fpscr & FPSCR_VX))
@@ -1972,7 +1972,7 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	extern int do_spe_mathemu(struct pt_regs *regs);
 	unsigned long spefscr;
 	int fpexc_mode;
-	int code = FPE_FIXME;
+	int code = FPE_FLTUNK;
 	int err;
 
 	flush_spe_to_thread(current);
@@ -2041,7 +2041,7 @@ void SPEFloatingPointRoundException(struct pt_regs *regs)
 		printk(KERN_ERR "unrecognized spe instruction "
 		       "in %s at %lx\n", current->comm, regs->nip);
 	} else {
-		_exception(SIGFPE, regs, FPE_FIXME, regs->nip);
+		_exception(SIGFPE, regs, FPE_FLTUNK, regs->nip);
 		return;
 	}
 }

commit 3eb0f5193b497083391aa05d35210d5645211eef
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 17 15:26:37 2018 -0500

    signal: Ensure every siginfo we send has all bits initialized
    
    Call clear_siginfo to ensure every stack allocated siginfo is properly
    initialized before being passed to the signal sending functions.
    
    Note: It is not safe to depend on C initializers to initialize struct
    siginfo on the stack because C is allowed to skip holes when
    initializing a structure.
    
    The initialization of struct siginfo in tracehook_report_syscall_exit
    was moved from the helper user_single_step_siginfo into
    tracehook_report_syscall_exit itself, to make it clear that the local
    variable siginfo gets fully initialized.
    
    In a few cases the scope of struct siginfo has been reduced to make it
    clear that siginfo siginfo is not used on other paths in the function
    in which it is declared.
    
    Instances of using memset to initialize siginfo have been replaced
    with calls clear_siginfo for clarity.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0904492e7032..087855caf6a9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -296,7 +296,6 @@ NOKPROBE_SYMBOL(die);
 void user_single_step_siginfo(struct task_struct *tsk,
 				struct pt_regs *regs, siginfo_t *info)
 {
-	memset(info, 0, sizeof(*info));
 	info->si_signo = SIGTRAP;
 	info->si_code = TRAP_TRACE;
 	info->si_addr = (void __user *)regs->nip;
@@ -334,7 +333,7 @@ void _exception_pkey(int signr, struct pt_regs *regs, int code,
 	 */
 	thread_pkey_regs_save(&current->thread);
 
-	memset(&info, 0, sizeof(info));
+	clear_siginfo(&info);
 	info.si_signo = signr;
 	info.si_code = code;
 	info.si_addr = (void __user *) addr;

commit 709b973c844c0b4d115ac3a227a2e5a68722c912
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Thu Mar 29 11:53:37 2018 +0530

    powerpc/fscr: Enable interrupts earlier before calling get_user()
    
    The function get_user() can sleep while trying to fetch instruction
    from user address space and causes the following warning from the
    scheduler.
    
    BUG: sleeping function called from invalid context
    
    Though interrupts get enabled back but it happens bit later after
    get_user() is called. This change moves enabling these interrupts
    earlier covering the function get_user(). While at this, lets check
    for kernel mode and crash as this interrupt should not have been
    triggered from the kernel context.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a2ef0c0e6c31..0904492e7032 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1613,6 +1613,22 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		value = mfspr(SPRN_FSCR);
 
 	status = value >> 56;
+	if ((hv || status >= 2) &&
+	    (status < ARRAY_SIZE(facility_strings)) &&
+	    facility_strings[status])
+		facility = facility_strings[status];
+
+	/* We should not have taken this interrupt in kernel */
+	if (!user_mode(regs)) {
+		pr_emerg("Facility '%s' unavailable (%d) exception in kernel mode at %lx\n",
+			 facility, status, regs->nip);
+		die("Unexpected facility unavailable exception", regs, SIGABRT);
+	}
+
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
 	if (status == FSCR_DSCR_LG) {
 		/*
 		 * User is accessing the DSCR register using the problem
@@ -1679,25 +1695,11 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		return;
 	}
 
-	if ((hv || status >= 2) &&
-	    (status < ARRAY_SIZE(facility_strings)) &&
-	    facility_strings[status])
-		facility = facility_strings[status];
-
-	/* We restore the interrupt state now */
-	if (!arch_irq_disabled_regs(regs))
-		local_irq_enable();
-
 	pr_err_ratelimited("%sFacility '%s' unavailable (%d), exception at 0x%lx, MSR=%lx\n",
 		hv ? "Hypervisor " : "", facility, status, regs->nip, regs->msr);
 
 out:
-	if (user_mode(regs)) {
-		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-		return;
-	}
-
-	die("Unexpected facility unavailable exception", regs, SIGABRT);
+	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 }
 #endif
 

commit 0e524e761fc2157f1037e0f5d616cd39e468d89c
Author: Matt Evans <matt@ozlabs.org>
Date:   Mon Mar 26 17:55:21 2018 +0100

    powerpc: Clear branch trap (MSR.BE) before delivering SIGTRAP
    
    When using SIG_DBG_BRANCH_TRACING, MSR.BE is left enabled in the
    user context when single_step_exception() prepares the SIGTRAP
    delivery.  The resulting branch-trap-within-the-SIGTRAP-handler
    isn't healthy.
    
    Commit 2538c2d08f46141550a1e68819efa8fe31c6e3dc broke this, by
    replacing an MSR mask operation of ~(MSR_SE | MSR_BE) with a call
    to clear_single_step() which only clears MSR_SE.
    
    This patch adds a new helper, clear_br_trace(), which clears the
    debug trap before invoking the signal handler.  This helper is a
    NOP for BookE as SIG_DBG_BRANCH_TRACING isn't supported on BookE.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2c1a1d24f0ab..a2ef0c0e6c31 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -471,7 +471,7 @@ static inline int check_io_access(struct pt_regs *regs)
 /* single-step stuff */
 #define single_stepping(regs)	(current->thread.debug.dbcr0 & DBCR0_IC)
 #define clear_single_step(regs)	(current->thread.debug.dbcr0 &= ~DBCR0_IC)
-
+#define clear_br_trace(regs)	do {} while(0)
 #else
 /* On non-4xx, the reason for the machine check or program
    exception is in the MSR. */
@@ -484,6 +484,7 @@ static inline int check_io_access(struct pt_regs *regs)
 
 #define single_stepping(regs)	((regs)->msr & MSR_SE)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
+#define clear_br_trace(regs)	((regs)->msr &= ~MSR_BE)
 #endif
 
 #if defined(CONFIG_E500)
@@ -999,6 +1000,7 @@ void single_step_exception(struct pt_regs *regs)
 	enum ctx_state prev_state = exception_enter();
 
 	clear_single_step(regs);
+	clear_br_trace(regs);
 
 	if (kprobe_post_handler(regs))
 		return;

commit d40b6768e45bd9213139b2d91d30c7692b6007b1
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Mar 27 01:01:16 2018 +1000

    powerpc/64s: sreset panic if there is no debugger or crash dump handlers
    
    system_reset_exception does most of its own crash handling now,
    invoking the debugger or crash dumps if they are registered. If not,
    then it goes through to die() to print stack traces, and then is
    supposed to panic (according to comments).
    
    However after die() prints oopses, it does its own handling which
    doesn't allow system_reset_exception to panic (e.g., it may just
    kill the current process). This patch causes sreset exceptions to
    return from die after it prints messages but before acting.
    
    This also stops die from invoking the debugger on 0x100 crashes.
    system_reset_exception similarly calls the debugger. It had been
    thought this was harmless (because if the debugger was disabled,
    neither call would fire, and if it was enabled the first call
    would return). However in some cases like xmon 'X' command, the
    debugger returns 0, which currently causes it to be entered
    again (first in system_reset_exception, then in die), which is
    confusing.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f200bfd98b17..2c1a1d24f0ab 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -208,6 +208,12 @@ static void oops_end(unsigned long flags, struct pt_regs *regs,
 	}
 	raw_local_irq_restore(flags);
 
+	/*
+	 * system_reset_excption handles debugger, crash dump, panic, for 0x100
+	 */
+	if (TRAP(regs) == 0x100)
+		return;
+
 	crash_fadump(regs, "die oops");
 
 	if (kexec_should_crash(current))
@@ -272,8 +278,13 @@ void die(const char *str, struct pt_regs *regs, long err)
 {
 	unsigned long flags;
 
-	if (debugger(regs))
-		return;
+	/*
+	 * system_reset_excption handles debugger, crash dump, panic, for 0x100
+	 */
+	if (TRAP(regs) != 0x100) {
+		if (debugger(regs))
+			return;
+	}
 
 	flags = oops_begin(regs);
 	if (__die(str, regs, err))

commit f384796c40dc55b3dba25e0ee9c1afd98c6d24d1
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Mon Mar 26 15:34:48 2018 +0530

    powerpc/mm: Add support for handling > 512TB address in SLB miss
    
    For addresses above 512TB we allocate additional mmu contexts. To make
    it all easy, addresses above 512TB are handled with IR/DR=1 and with
    stack frame setup.
    
    The mmu_context_t is also updated to track the new extended_ids. To
    support upto 4PB we need a total 8 contexts.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    [mpe: Minor formatting tweaks and comment wording, switch BUG to WARN
          in get_ea_context().]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1e48d157196a..f200bfd98b17 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1495,18 +1495,6 @@ void alignment_exception(struct pt_regs *regs)
 	exception_exit(prev_state);
 }
 
-void slb_miss_bad_addr(struct pt_regs *regs)
-{
-	enum ctx_state prev_state = exception_enter();
-
-	if (user_mode(regs))
-		_exception(SIGSEGV, regs, SEGV_BNDERR, regs->dar);
-	else
-		bad_page_fault(regs, regs->dar, SIGSEGV);
-
-	exception_exit(prev_state);
-}
-
 void StackOverflow(struct pt_regs *regs)
 {
 	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",

commit 03f51d4efa2287cc628bb20b0c032036d2a9e66a
Merge: 367b0df173b0 015eb1b89e95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 2 10:01:04 2018 -0800

    Merge tag 'powerpc-4.16-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
    
       - Enable support for memory protection keys aka "pkeys" on Power7/8/9
         when using the hash table MMU.
    
       - Extend our interrupt soft masking to support masking PMU interrupts
         as well as "normal" interrupts, and then use that to implement
         local_t for a ~4x speedup vs the current atomics-based
         implementation.
    
       - A new driver "ocxl" for "Open Coherent Accelerator Processor
         Interface (OpenCAPI)" devices.
    
       - Support for new device tree properties on PowerVM to describe
         hotpluggable memory and devices.
    
       - Add support for CLOCK_{REALTIME/MONOTONIC}_COARSE to the 64-bit
         VDSO.
    
       - Freescale updates from Scott: fixes for CPM GPIO and an FSL PCI
         erratum workaround, plus a minor cleanup patch.
    
      As well as quite a lot of other changes all over the place, and small
      fixes and cleanups as always.
    
      Thanks to: Alan Modra, Alastair D'Silva, Alexey Kardashevskiy,
      Alistair Popple, Andreas Schwab, Andrew Donnellan, Aneesh Kumar K.V,
      Anju T Sudhakar, Anshuman Khandual, Anton Blanchard, Arnd Bergmann,
      Balbir Singh, Benjamin Herrenschmidt, Bhaktipriya Shridhar, Bryant G.
      Ly, CÃ©dric Le Goater, Christophe Leroy, Christophe Lombard, Cyril Bur,
      David Gibson, Desnes A. Nunes do Rosario, Dmitry Torokhov, Frederic
      Barrat, Geert Uytterhoeven, Guilherme G. Piccoli, Gustavo A. R. Silva,
      Gustavo Romero, Ivan Mikhaylov, Joakim Tjernlund, Joe Perches, Josh
      Poimboeuf, Juan J. Alvarez, Julia Cartwright, Kamalesh Babulal,
      Madhavan Srinivasan, Mahesh Salgaonkar, Mathieu Malaterre, Michael
      Bringmann, Michael Hanselmann, Michael Neuling, Nathan Fontenot,
      Naveen N. Rao, Nicholas Piggin, Paul Mackerras, Philippe Bergheaud,
      Ram Pai, Russell Currey, Santosh Sivaraj, Scott Wood, Seth Forshee,
      Simon Guo, Stewart Smith, Sukadev Bhattiprolu, Thiago Jung Bauermann,
      Vaibhav Jain, Vasyl Gomonovych"
    
    * tag 'powerpc-4.16-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (199 commits)
      powerpc/mm/radix: Fix build error when RADIX_MMU=n
      macintosh/ams-input: Use true and false for boolean values
      macintosh: change some data types from int to bool
      powerpc/watchdog: Print the NIP in soft_nmi_interrupt()
      powerpc/watchdog: regs can't be null in soft_nmi_interrupt()
      powerpc/watchdog: Tweak watchdog printks
      powerpc/cell: Remove axonram driver
      rtc-opal: Fix handling of firmware error codes, prevent busy loops
      powerpc/mpc52xx_gpt: make use of raw_spinlock variants
      macintosh/adb: Properly mark continued kernel messages
      powerpc/pseries: Fix cpu hotplug crash with memoryless nodes
      powerpc/numa: Ensure nodes initialized for hotplug
      powerpc/numa: Use ibm,max-associativity-domains to discover possible nodes
      powerpc/kernel: Block interrupts when updating TIDR
      powerpc/powernv/idoa: Remove unnecessary pcidev from pci_dn
      powerpc/mm/nohash: do not flush the entire mm when range is a single page
      powerpc/pseries: Add Initialization of VF Bars
      powerpc/pseries/pci: Associate PEs to VFs in configure SR-IOV
      powerpc/eeh: Add EEH notify resume sysfs
      powerpc/eeh: Add EEH operations to notify resume
      ...

commit 47355040d2760566901057287b35d5f10e217e12
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Jan 16 16:12:38 2018 -0600

    signal/powerpc: Remove unnecessary signal_code parameter of do_send_trap
    
    signal_code is always TRAP_HWBKPT
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f2e6e1838952..c93f1e6a9fff 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1750,34 +1750,34 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 #ifdef CONFIG_PPC_ADV_DEBUG_DAC_RANGE
 		current->thread.debug.dbcr2 &= ~DBCR2_DAC12MODE;
 #endif
-		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status,
 			     5);
 		changed |= 0x01;
 	}  else if (debug_status & (DBSR_DAC2R | DBSR_DAC2W)) {
 		dbcr_dac(current) &= ~(DBCR_DAC2R | DBCR_DAC2W);
-		do_send_trap(regs, mfspr(SPRN_DAC2), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_DAC2), debug_status,
 			     6);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC1) {
 		current->thread.debug.dbcr0 &= ~DBCR0_IAC1;
 		dbcr_iac_range(current) &= ~DBCR_IAC12MODE;
-		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status,
 			     1);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC2) {
 		current->thread.debug.dbcr0 &= ~DBCR0_IAC2;
-		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status,
 			     2);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC3) {
 		current->thread.debug.dbcr0 &= ~DBCR0_IAC3;
 		dbcr_iac_range(current) &= ~DBCR_IAC34MODE;
-		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status,
 			     3);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC4) {
 		current->thread.debug.dbcr0 &= ~DBCR0_IAC4;
-		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status, TRAP_HWBKPT,
+		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status,
 			     4);
 		changed |= 0x01;
 	}

commit 35adacd6fc48d658419522f192a3c8b2785612da
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Dec 24 02:49:23 2017 +1000

    powerpc/pseries, ps3: panic flush kernel messages before halting system
    
    Platforms with a panic handler that halts the system can have problems
    getting kernel messages out, because the panic notifiers are called
    before kernel/panic.c does its flushing of printk buffers an console
    etc.
    
    This was attempted to be solved with commit a3b2cb30f252 ("powerpc: Do
    not call ppc_md.panic in fadump panic notifier"), but that wasn't the
    right approach and caused other problems, and was reverted by commit
    ab9dbf771ff9.
    
    Instead, the powernv shutdown paths have already had a similar
    problem, fixed by taking the message flushing sequence from
    kernel/panic.c. That's a little bit ugly, but while we have the code
    duplicated, it will work for this case as well. So have ppc panic
    handlers do the same flushing before they terminate.
    
    Without this patch, a qemu pseries_le_defconfig guest stops silently
    when issued the nmi command when xmon is off and no crash dumpers
    enabled. Afterwards, an oops is printed by each CPU as expected.
    
    Fixes: ab9dbf771ff9 ("Revert "powerpc: Do not call ppc_md.panic in fadump panic notifier"")
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index cb07d6519783..4260c73461a3 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -39,6 +39,8 @@
 #include <linux/ratelimit.h>
 #include <linux/context_tracking.h>
 #include <linux/smp.h>
+#include <linux/console.h>
+#include <linux/kmsg_dump.h>
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
@@ -143,6 +145,28 @@ static int die_owner = -1;
 static unsigned int die_nest_count;
 static int die_counter;
 
+extern void panic_flush_kmsg_start(void)
+{
+	/*
+	 * These are mostly taken from kernel/panic.c, but tries to do
+	 * relatively minimal work. Don't use delay functions (TB may
+	 * be broken), don't crash dump (need to set a firmware log),
+	 * don't run notifiers. We do want to get some information to
+	 * Linux console.
+	 */
+	console_verbose();
+	bust_spinlocks(1);
+}
+
+extern void panic_flush_kmsg_end(void)
+{
+	printk_safe_flush_on_panic();
+	kmsg_dump(KMSG_DUMP_PANIC);
+	bust_spinlocks(0);
+	debug_locks_off();
+	console_flush_on_panic();
+}
+
 static unsigned long oops_begin(struct pt_regs *regs)
 {
 	int cpu;

commit 57ad583f2086d55ada284c54bfc440123cf73964
Author: Russell Currey <ruscur@russell.cc>
Date:   Thu Jan 12 14:54:13 2017 +1100

    powerpc: Use octal numbers for file permissions
    
    Symbolic macros are unintuitive and hard to read, whereas octal constants
    are much easier to interpret.  Replace macros for the basic permission
    flags (user/group/other read/write/execute) with numeric constants
    instead, across the whole powerpc tree.
    
    Introducing a significant number of changes across the tree for no runtime
    benefit isn't exactly desirable, but so long as these macros are still
    used in the tree people will keep sending patches that add them.  Not only
    are they hard to parse at a glance, there are multiple ways of coming to
    the same value (as you can see with 0444 and 0644 in this patch) which
    hurts readability.
    
    Signed-off-by: Russell Currey <ruscur@russell.cc>
    Reviewed-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 122a3c883f4e..cb07d6519783 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -2130,13 +2130,13 @@ static int __init ppc_warn_emulated_init(void)
 	if (!dir)
 		return -ENOMEM;
 
-	d = debugfs_create_u32("do_warn", S_IRUGO | S_IWUSR, dir,
+	d = debugfs_create_u32("do_warn", 0644, dir,
 			       &ppc_warn_emulated);
 	if (!d)
 		goto fail;
 
 	for (i = 0; i < sizeof(ppc_emulated)/sizeof(*entries); i++) {
-		d = debugfs_create_u32(entries[i].name, S_IRUGO | S_IWUSR, dir,
+		d = debugfs_create_u32(entries[i].name, 0644, dir,
 				       (u32 *)&entries[i].val.counter);
 		if (!d)
 			goto fail;

commit c5cc1f4df6b16646f8fae7aab523c1820bf916e8
Author: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
Date:   Thu Jan 18 17:50:43 2018 -0800

    powerpc/ptrace: Add memory protection key regset
    
    The AMR/IAMR/UAMOR are part of the program context.
    Allow it to be accessed via ptrace and through core files.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4b1a8e2ec023..122a3c883f4e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -292,6 +292,13 @@ void _exception_pkey(int signr, struct pt_regs *regs, int code,
 		local_irq_enable();
 
 	current->thread.trap_nr = code;
+
+	/*
+	 * Save all the pkey registers AMR/IAMR/UAMOR. Eg: Core dumps need
+	 * to capture the content, if the task gets killed.
+	 */
+	thread_pkey_regs_save(&current->thread);
+
 	memset(&info, 0, sizeof(info));
 	info.si_signo = signr;
 	info.si_code = code;

commit 99cd1302327a2ccaedf905e9f6a8d8fd234bd485
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Thu Jan 18 17:50:42 2018 -0800

    powerpc: Deliver SEGV signal on pkey violation
    
    The value of the pkey, whose protection got violated,
    is made available in si_pkey field of the siginfo structure.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d139117d3339..4b1a8e2ec023 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -20,6 +20,7 @@
 #include <linux/sched/debug.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
+#include <linux/pkeys.h>
 #include <linux/stddef.h>
 #include <linux/unistd.h>
 #include <linux/ptrace.h>
@@ -266,7 +267,9 @@ void user_single_step_siginfo(struct task_struct *tsk,
 	info->si_addr = (void __user *)regs->nip;
 }
 
-void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
+
+void _exception_pkey(int signr, struct pt_regs *regs, int code,
+		unsigned long addr, int key)
 {
 	siginfo_t info;
 	const char fmt32[] = KERN_INFO "%s[%d]: unhandled signal %d " \
@@ -293,9 +296,16 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	info.si_signo = signr;
 	info.si_code = code;
 	info.si_addr = (void __user *) addr;
+	info.si_pkey = key;
+
 	force_sig_info(signr, &info, current);
 }
 
+void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
+{
+	_exception_pkey(signr, regs, code, addr, 0);
+}
+
 void system_reset_exception(struct pt_regs *regs)
 {
 	/*

commit 4552d128c26e0f0f27a5bd2fadc24092b8f6c1d7
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Dec 24 02:49:22 2017 +1000

    powerpc: System reset avoid interleaving oops using die synchronisation
    
    The die() oops path contains a serializing lock to prevent oops
    messages from being interleaved. In the case of a system reset
    initiated oops (e.g., qemu nmi command), __die was being called
    which lacks that synchronisation and oops reports could be
    interleaved across CPUs.
    
    A recent patch 4388c9b3a6ee7 ("powerpc: Do not send system reset
    request through the oops path") changed this to __die to avoid
    the debugger() call, but there is no real harm to calling it twice
    if the first time fell through. So go back to using die() here.
    This was observed to fix the problem.
    
    Fixes: 4388c9b3a6ee7 ("powerpc: Do not send system reset request through the oops path")
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d61989be28e1..d139117d3339 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -337,7 +337,7 @@ void system_reset_exception(struct pt_regs *regs)
 	 * No debugger or crash dump registered, print logs then
 	 * panic.
 	 */
-	__die("System Reset", regs, SIGABRT);
+	die("System Reset", regs, SIGABRT);
 
 	mdelay(2*MSEC_PER_SEC); /* Wait a little while for others to print */
 	add_taint(TAINT_DIE, LOCKDEP_NOW_UNRELIABLE);

commit 2271db20e4b362405bacc0e4095df4177d38129e
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jan 12 13:28:49 2018 +1100

    powerpc: Use the TRAP macro whenever comparing a trap number
    
    Trap numbers can have extra bits at the bottom that need to
    be filtered out. There are a few cases where we don't do that.
    
    It's possible that we got lucky but better safe than sorry.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f3eb61be0d30..d61989be28e1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1564,7 +1564,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	u8 status;
 	bool hv;
 
-	hv = (regs->trap == 0xf80);
+	hv = (TRAP(regs) == 0xf80);
 	if (hv)
 		value = mfspr(SPRN_HFSCR);
 	else

commit cf4674c46c66e45f238f8f7e81af2a444b970c0a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Aug 19 15:26:01 2017 -0500

    signal/powerpc: Document conflicts with SI_USER and SIGFPE and SIGTRAP
    
    Setting si_code to 0 results in a userspace seeing an si_code of 0.
    This is the same si_code as SI_USER.  Posix and common sense requires
    that SI_USER not be a signal specific si_code.  As such this use of 0
    for the si_code is a pretty horribly broken ABI.
    
    Further use of si_code == 0 guaranteed that copy_siginfo_to_user saw a
    value of __SI_KILL and now sees a value of SIL_KILL with the result
    that uid and pid fields are copied and which might copying the si_addr
    field by accident but certainly not by design.  Making this a very
    flakey implementation.
    
    Utilizing FPE_FIXME and TRAP_FIXME, siginfo_layout() will now return
    SIL_FAULT and the appropriate fields will be reliably copied.
    
    Possible ABI fixes includee:
    - Send the signal without siginfo
    - Don't generate a signal
    - Possibly assign and use an appropriate si_code
    - Don't handle cases which can't happen
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Kumar Gala <kumar.gala@freescale.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc:  linuxppc-dev@lists.ozlabs.org
    Ref: 9bad068c24d7 ("[PATCH] ppc32: support for e500 and 85xx")
    Ref: 0ed70f6105ef ("PPC32: Provide proper siginfo information on various exceptions.")
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f3eb61be0d30..f2e6e1838952 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -917,7 +917,7 @@ void unknown_exception(struct pt_regs *regs)
 	printk("Bad trap at PC: %lx, SR: %lx, vector=%lx\n",
 	       regs->nip, regs->msr, regs->trap);
 
-	_exception(SIGTRAP, regs, 0, 0);
+	_exception(SIGTRAP, regs, TRAP_FIXME, 0);
 
 	exception_exit(prev_state);
 }
@@ -939,7 +939,7 @@ void instruction_breakpoint_exception(struct pt_regs *regs)
 
 void RunModeException(struct pt_regs *regs)
 {
-	_exception(SIGTRAP, regs, 0, 0);
+	_exception(SIGTRAP, regs, TRAP_FIXME, 0);
 }
 
 void single_step_exception(struct pt_regs *regs)
@@ -978,7 +978,7 @@ static void emulate_single_step(struct pt_regs *regs)
 
 static inline int __parse_fpscr(unsigned long fpscr)
 {
-	int ret = 0;
+	int ret = FPE_FIXME;
 
 	/* Invalid operation */
 	if ((fpscr & FPSCR_VE) && (fpscr & FPSCR_VX))
@@ -1929,7 +1929,7 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	extern int do_spe_mathemu(struct pt_regs *regs);
 	unsigned long spefscr;
 	int fpexc_mode;
-	int code = 0;
+	int code = FPE_FIXME;
 	int err;
 
 	flush_spe_to_thread(current);
@@ -1998,7 +1998,7 @@ void SPEFloatingPointRoundException(struct pt_regs *regs)
 		printk(KERN_ERR "unrecognized spe instruction "
 		       "in %s at %lx\n", current->comm, regs->nip);
 	} else {
-		_exception(SIGFPE, regs, 0, regs->nip);
+		_exception(SIGFPE, regs, FPE_FIXME, regs->nip);
 		return;
 	}
 }

commit 6f700d38a8c9dc4d786ac4a831073194f17c5076
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Thu Nov 2 14:09:06 2017 +1100

    powerpc: Remove facility loadups on transactional {fp, vec, vsx} unavailable
    
    After handling a transactional FP, Altivec or VSX unavailable exception.
    The return to userspace code will detect that the TIF_RESTORE_TM bit is
    set and call restore_tm_state(). restore_tm_state() will call
    restore_math() to ensure that the correct facilities are loaded.
    
    This means that all the loadup code in {fp,altivec,vsx}_unavailable_tm()
    is doing pointless work and can simply be removed.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4e5a543d0b74..f3eb61be0d30 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1663,12 +1663,6 @@ void facility_unavailable_exception(struct pt_regs *regs)
 
 void fp_unavailable_tm(struct pt_regs *regs)
 {
-	/*
-	 * Save the MSR now because tm_reclaim_current() is likely to
-	 * change it
-	 */
-	unsigned long orig_msr = regs->msr;
-
 	/* Note:  This does not handle any kind of FP laziness. */
 
 	TM_DEBUG("FP Unavailable trap whilst transactional at 0x%lx, MSR=%lx\n",
@@ -1694,24 +1688,10 @@ void fp_unavailable_tm(struct pt_regs *regs)
 	 * so we don't want to load the VRs from the thread_struct.
 	 */
 	tm_recheckpoint(&current->thread);
-
-	/* If VMX is in use, get the transactional values back */
-	if (orig_msr & MSR_VEC) {
-		msr_check_and_set(MSR_VEC);
-		load_vr_state(&current->thread.vr_state);
-		/* At this point all the VSX state is loaded, so enable it */
-		regs->msr |= MSR_VSX;
-	}
 }
 
 void altivec_unavailable_tm(struct pt_regs *regs)
 {
-	/*
-	 * Save the MSR now because tm_reclaim_current() is likely to
-	 * change it
-	 */
-	unsigned long orig_msr = regs->msr;
-
 	/* See the comments in fp_unavailable_tm().  This function operates
 	 * the same way.
 	 */
@@ -1723,12 +1703,6 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 	current->thread.load_vec = 1;
 	tm_recheckpoint(&current->thread);
 	current->thread.used_vr = 1;
-
-	if (orig_msr & MSR_FP) {
-		msr_check_and_set(MSR_FP);
-		load_fp_state(&current->thread.fp_state);
-		regs->msr |= MSR_VSX;
-	}
 }
 
 void vsx_unavailable_tm(struct pt_regs *regs)
@@ -1753,10 +1727,6 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 	current->thread.load_fp = 1;
 
 	tm_recheckpoint(&current->thread);
-
-	msr_check_and_set(MSR_FP | MSR_VEC);
-	load_fp_state(&current->thread.fp_state);
-	load_vr_state(&current->thread.vr_state);
 }
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 

commit eb5c3f1c86470fc1a57ab28cce15c12e4d6cdf8b
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Thu Nov 2 14:09:05 2017 +1100

    powerpc: Always save/restore checkpointed regs during treclaim/trecheckpoint
    
    Lazy save and restore of FP/Altivec means that a userspace process can
    be sent to userspace with FP or Altivec disabled and loaded only as
    required (by way of an FP/Altivec unavailable exception). Transactional
    Memory complicates this situation as a transaction could be started
    without FP/Altivec being loaded up. This causes the hardware to
    checkpoint incorrect registers. Handling FP/Altivec unavailable
    exceptions while a thread is transactional requires a reclaim and
    recheckpoint to ensure the CPU has correct state for both sets of
    registers.
    
    tm_reclaim() has optimisations to not always save the FP/Altivec
    registers to the checkpointed save area. This was originally done
    because the caller might have information that the checkpointed
    registers aren't valid due to lazy save and restore. We've also been a
    little vague as to how tm_reclaim() leaves the FP/Altivec state since it
    doesn't necessarily always save it to the thread struct. This has lead
    to an (incorrect) assumption that it leaves the checkpointed state on
    the CPU.
    
    tm_recheckpoint() has similar optimisations in reverse. It may not
    always reload the checkpointed FP/Altivec registers from the thread
    struct before the trecheckpoint. It is therefore quite unclear where it
    expects to get the state from. This didn't help with the assumption
    made about tm_reclaim().
    
    These optimisations sit in what is by definition a slow path. If a
    process has to go through a reclaim/recheckpoint then its transaction
    will be doomed on returning to userspace. This mean that the process
    will be unable to complete its transaction and be forced to its failure
    handler. This is already an out if line case for userspace. Furthermore,
    the cost of copying 64 times 128 bits from registers isn't very long[0]
    (at all) on modern processors. As such it appears these optimisations
    have only served to increase code complexity and are unlikely to have
    had a measurable performance impact.
    
    Our transactional memory handling has been riddled with bugs. A cause
    of this has been difficulty in following the code flow, code complexity
    has not been our friend here. It makes sense to remove these
    optimisations in favour of a (hopefully) more stable implementation.
    
    This patch does mean that some times the assembly will needlessly save
    'junk' registers which will subsequently get overwritten with the
    correct value by the C code which calls the assembly function. This
    small inefficiency is far outweighed by the reduction in complexity for
    general TM code, context switching paths, and transactional facility
    unavailable exception handler.
    
    0: I tried to measure it once for other work and found that it was
    hiding in the noise of everything else I was working with. I find it
    exceedingly likely this will be the case here.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e099e61c702b..4e5a543d0b74 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1693,7 +1693,7 @@ void fp_unavailable_tm(struct pt_regs *regs)
 	 * If VMX is in use, the VRs now hold checkpointed values,
 	 * so we don't want to load the VRs from the thread_struct.
 	 */
-	tm_recheckpoint(&current->thread, orig_msr | MSR_FP);
+	tm_recheckpoint(&current->thread);
 
 	/* If VMX is in use, get the transactional values back */
 	if (orig_msr & MSR_VEC) {
@@ -1721,7 +1721,7 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 		 regs->nip, regs->msr);
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 	current->thread.load_vec = 1;
-	tm_recheckpoint(&current->thread, orig_msr | MSR_VEC);
+	tm_recheckpoint(&current->thread);
 	current->thread.used_vr = 1;
 
 	if (orig_msr & MSR_FP) {
@@ -1733,8 +1733,6 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 
 void vsx_unavailable_tm(struct pt_regs *regs)
 {
-	unsigned long orig_msr = regs->msr;
-
 	/* See the comments in fp_unavailable_tm().  This works similarly,
 	 * though we're loading both FP and VEC registers in here.
 	 *
@@ -1748,29 +1746,17 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 
 	current->thread.used_vsr = 1;
 
-	/* If FP and VMX are already loaded, we have all the state we need */
-	if ((orig_msr & (MSR_FP | MSR_VEC)) == (MSR_FP | MSR_VEC)) {
-		regs->msr |= MSR_VSX;
-		return;
-	}
-
 	/* This reclaims FP and/or VR regs if they're already enabled */
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 
 	current->thread.load_vec = 1;
 	current->thread.load_fp = 1;
 
-	/* This loads & recheckpoints FP and VRs; but we have
-	 * to be sure not to overwrite previously-valid state.
-	 */
-	tm_recheckpoint(&current->thread, orig_msr | MSR_FP | MSR_VEC);
-
-	msr_check_and_set(orig_msr & (MSR_FP | MSR_VEC));
+	tm_recheckpoint(&current->thread);
 
-	if (orig_msr & MSR_FP)
-		load_fp_state(&current->thread.fp_state);
-	if (orig_msr & MSR_VEC)
-		load_vr_state(&current->thread.vr_state);
+	msr_check_and_set(MSR_FP | MSR_VEC);
+	load_fp_state(&current->thread.fp_state);
+	load_vr_state(&current->thread.vr_state);
 }
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 

commit 91381b9cb1c3afc162f830ebf698721402c7d577
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Thu Nov 2 14:09:04 2017 +1100

    powerpc: Force reload for recheckpoint during tm {fp, vec, vsx} unavailable exception
    
    Lazy save and restore of FP/Altivec means that a userspace process can
    be sent to userspace with FP or Altivec disabled and loaded only as
    required (by way of an FP/Altivec unavailable exception). Transactional
    Memory complicates this situation as a transaction could be started
    without FP/Altivec being loaded up. This causes the hardware to
    checkpoint incorrect registers. Handling FP/Altivec unavailable
    exceptions while a thread is transactional requires a reclaim and
    recheckpoint to ensure the CPU has correct state for both sets of
    registers.
    
    tm_reclaim() has optimisations to not always save the FP/Altivec
    registers to the checkpointed save area. This was originally done
    because the caller might have information that the checkpointed
    registers aren't valid due to lazy save and restore. We've also been a
    little vague as to how tm_reclaim() leaves the FP/Altivec state since it
    doesn't necessarily always save it to the thread struct. This has lead
    to an (incorrect) assumption that it leaves the checkpointed state on
    the CPU.
    
    tm_recheckpoint() has similar optimisations in reverse. It may not
    always reload the checkpointed FP/Altivec registers from the thread
    struct before the trecheckpoint. It is therefore quite unclear where it
    expects to get the state from. This didn't help with the assumption
    made about tm_reclaim().
    
    This patch is a minimal fix for ease of backporting. A more correct fix
    which removes the msr parameter to tm_reclaim() and tm_recheckpoint()
    altogether has been upstreamed to apply on top of this patch.
    
    Fixes: dc3106690b20 ("powerpc: tm: Always use fp_state and vr_state to
    store live registers")
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 863c6858ed0f..e099e61c702b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1663,6 +1663,12 @@ void facility_unavailable_exception(struct pt_regs *regs)
 
 void fp_unavailable_tm(struct pt_regs *regs)
 {
+	/*
+	 * Save the MSR now because tm_reclaim_current() is likely to
+	 * change it
+	 */
+	unsigned long orig_msr = regs->msr;
+
 	/* Note:  This does not handle any kind of FP laziness. */
 
 	TM_DEBUG("FP Unavailable trap whilst transactional at 0x%lx, MSR=%lx\n",
@@ -1687,10 +1693,10 @@ void fp_unavailable_tm(struct pt_regs *regs)
 	 * If VMX is in use, the VRs now hold checkpointed values,
 	 * so we don't want to load the VRs from the thread_struct.
 	 */
-	tm_recheckpoint(&current->thread, MSR_FP);
+	tm_recheckpoint(&current->thread, orig_msr | MSR_FP);
 
 	/* If VMX is in use, get the transactional values back */
-	if (regs->msr & MSR_VEC) {
+	if (orig_msr & MSR_VEC) {
 		msr_check_and_set(MSR_VEC);
 		load_vr_state(&current->thread.vr_state);
 		/* At this point all the VSX state is loaded, so enable it */
@@ -1700,6 +1706,12 @@ void fp_unavailable_tm(struct pt_regs *regs)
 
 void altivec_unavailable_tm(struct pt_regs *regs)
 {
+	/*
+	 * Save the MSR now because tm_reclaim_current() is likely to
+	 * change it
+	 */
+	unsigned long orig_msr = regs->msr;
+
 	/* See the comments in fp_unavailable_tm().  This function operates
 	 * the same way.
 	 */
@@ -1709,10 +1721,10 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 		 regs->nip, regs->msr);
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 	current->thread.load_vec = 1;
-	tm_recheckpoint(&current->thread, MSR_VEC);
+	tm_recheckpoint(&current->thread, orig_msr | MSR_VEC);
 	current->thread.used_vr = 1;
 
-	if (regs->msr & MSR_FP) {
+	if (orig_msr & MSR_FP) {
 		msr_check_and_set(MSR_FP);
 		load_fp_state(&current->thread.fp_state);
 		regs->msr |= MSR_VSX;
@@ -1751,7 +1763,7 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 	/* This loads & recheckpoints FP and VRs; but we have
 	 * to be sure not to overwrite previously-valid state.
 	 */
-	tm_recheckpoint(&current->thread, regs->msr & ~orig_msr);
+	tm_recheckpoint(&current->thread, orig_msr | MSR_FP | MSR_VEC);
 
 	msr_check_and_set(orig_msr & (MSR_FP | MSR_VEC));
 

commit a7771176b4392fbc3a17399c51a8c11f2f681afe
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Thu Nov 2 14:09:03 2017 +1100

    powerpc: Don't enable FP/Altivec if not checkpointed
    
    Lazy save and restore of FP/Altivec means that a userspace process can
    be sent to userspace with FP or Altivec disabled and loaded only as
    required (by way of an FP/Altivec unavailable exception). Transactional
    Memory complicates this situation as a transaction could be started
    without FP/Altivec being loaded up. This causes the hardware to
    checkpoint incorrect registers. Handling FP/Altivec unavailable
    exceptions while a thread is transactional requires a reclaim and
    recheckpoint to ensure the CPU has correct state for both sets of
    registers.
    
    Lazy save and restore of FP/Altivec cannot be done if a process is
    transactional. If a facility was enabled it must remain enabled whenever
    a thread is transactional.
    
    Commit dc16b553c949 ("powerpc: Always restore FPU/VEC/VSX if hardware
    transactional memory in use") ensures that the facilities are always
    enabled if a thread is transactional. A bug in the introduced code may
    cause it to inadvertently enable a facility that was (and should remain)
    disabled. The problem with this extraneous enablement is that the
    registers for the erroneously enabled facility have not been correctly
    recheckpointed - the recheckpointing code assumed the facility would
    remain disabled.
    
    Further compounding the issue, the transactional {fp,altivec,vsx}
    unavailable code has been incorrectly using the MSR to enable
    facilities. The presence of the {FP,VEC,VSX} bit in the regs->msr simply
    means if the registers are live on the CPU, not if the kernel should
    load them before returning to userspace. This has worked due to the bug
    mentioned above.
    
    This causes transactional threads which return to their failure handler
    to observe incorrect checkpointed registers. Perhaps an example will
    help illustrate the problem:
    
    A userspace process is running and uses both FP and Altivec registers.
    This process then continues to run for some time without touching
    either sets of registers. The kernel subsequently disables the
    facilities as part of lazy save and restore. The userspace process then
    performs a tbegin and the CPU checkpoints 'junk' FP and Altivec
    registers. The process then performs a floating point instruction
    triggering a fp unavailable exception in the kernel.
    
    The kernel then loads the FP registers - and only the FP registers.
    Since the thread is transactional it must perform a reclaim and
    recheckpoint to ensure both the checkpointed registers and the
    transactional registers are correct. It then (correctly) enables
    MSR[FP] for the process. Later (on exception exist) the kernel also
    (inadvertently) enables MSR[VEC]. The process is then returned to
    userspace.
    
    Since the act of loading the FP registers doomed the transaction we know
    CPU will fail the transaction, restore its checkpointed registers, and
    return the process to its failure handler. The problem is that we're
    now running with Altivec enabled and the 'junk' checkpointed registers
    are restored. The kernel had only recheckpointed FP.
    
    This patch solves this by only activating FP/Altivec if userspace was
    using them when it entered the kernel and not simply if the process is
    transactional.
    
    Fixes: dc16b553c949 ("powerpc: Always restore FPU/VEC/VSX if hardware
    transactional memory in use")
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0e4099fef198..863c6858ed0f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1679,7 +1679,7 @@ void fp_unavailable_tm(struct pt_regs *regs)
 	/* Reclaim didn't save out any FPRs to transact_fprs. */
 
 	/* Enable FP for the task: */
-	regs->msr |= (MSR_FP | current->thread.fpexc_mode);
+	current->thread.load_fp = 1;
 
 	/* This loads and recheckpoints the FP registers from
 	 * thread.fpr[].  They will remain in registers after the
@@ -1708,7 +1708,7 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 		 "MSR=%lx\n",
 		 regs->nip, regs->msr);
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
-	regs->msr |= MSR_VEC;
+	current->thread.load_vec = 1;
 	tm_recheckpoint(&current->thread, MSR_VEC);
 	current->thread.used_vr = 1;
 
@@ -1745,8 +1745,8 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 	/* This reclaims FP and/or VR regs if they're already enabled */
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 
-	regs->msr |= MSR_VEC | MSR_FP | current->thread.fpexc_mode |
-		MSR_VSX;
+	current->thread.load_vec = 1;
+	current->thread.load_fp = 1;
 
 	/* This loads & recheckpoints FP and VRs; but we have
 	 * to be sure not to overwrite previously-valid state.

commit 632f0574167ad3f5d646dad6af87d976a703d93e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Oct 12 15:45:25 2017 +1100

    powerpc/tm: Don't check for WARN in TM Bad Thing handling
    
    Currently when we take a TM Bad Thing program check exception, we
    search the bug table to see if the program check was generated by a
    WARN/WARN_ON etc.
    
    That makes no sense, the WARN macros use trap instructions, which
    should never generate a TM Bad Thing exception. If they ever did that
    would be a bug and we should oops.
    
    We do have some hand-coded bugs in tm.S, using EMIT_BUG_ENTRY, but
    those are all BUGs not WARNs, and they all use trap instructions
    anyway. Almost certainly this check was incorrectly copied from the
    REASON_TRAP handling in the same function.
    
    Remove it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Acked-By: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9ae1924c7d1a..0e4099fef198 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1337,13 +1337,8 @@ void program_check_exception(struct pt_regs *regs)
 		 * -  A treclaim is attempted when non transactional.
 		 * -  A tend is illegally attempted.
 		 * -  writing a TM SPR when transactional.
-		 */
-		if (!user_mode(regs) &&
-		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
-			regs->nip += 4;
-			goto bail;
-		}
-		/* If usermode caused this, it's done something illegal and
+		 *
+		 * If usermode caused this, it's done something illegal and
 		 * gets a SIGILL slap on the wrist.  We call it an illegal
 		 * operand to distinguish from the instruction just being bad
 		 * (e.g. executing a 'tend' on a CPU without TM!); it's an

commit 5080332c2c893118dbc18755f35c8b0131cf0fc4
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Sep 15 15:25:48 2017 +1000

    powerpc/64s: Add workaround for P9 vector CI load issue
    
    POWER9 DD2.1 and earlier has an issue where some cache inhibited
    vector load will return bad data. The workaround is two part, one
    firmware/microcode part triggers HMI interrupts when hitting such
    loads, the other part is this patch which then emulates the
    instructions in Linux.
    
    The affected instructions are limited to lxvd2x, lxvw4x, lxvb16x and
    lxvh8x.
    
    When an instruction triggers the HMI, all threads in the core will be
    sent to the HMI handler, not just the one running the vector load.
    
    In general, these spurious HMIs are detected by the emulation code and
    we just return back to the running process. Unfortunately, if a
    spurious interrupt occurs on a vector load that's to normal memory we
    have no way to detect that it's spurious (unless we walk the page
    tables, which is very expensive). In this case we emulate the load but
    we need do so using a vector load itself to ensure 128bit atomicity is
    preserved.
    
    Some additional debugfs emulated instruction counters are added also.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    [mpe: Switch CONFIG_PPC_BOOK3S_64 to CONFIG_VSX to unbreak the build]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 13c9dcdcba69..9ae1924c7d1a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -37,6 +37,7 @@
 #include <linux/kdebug.h>
 #include <linux/ratelimit.h>
 #include <linux/context_tracking.h>
+#include <linux/smp.h>
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
@@ -699,6 +700,187 @@ void SMIException(struct pt_regs *regs)
 	die("System Management Interrupt", regs, SIGABRT);
 }
 
+#ifdef CONFIG_VSX
+static void p9_hmi_special_emu(struct pt_regs *regs)
+{
+	unsigned int ra, rb, t, i, sel, instr, rc;
+	const void __user *addr;
+	u8 vbuf[16], *vdst;
+	unsigned long ea, msr, msr_mask;
+	bool swap;
+
+	if (__get_user_inatomic(instr, (unsigned int __user *)regs->nip))
+		return;
+
+	/*
+	 * lxvb16x	opcode: 0x7c0006d8
+	 * lxvd2x	opcode: 0x7c000698
+	 * lxvh8x	opcode: 0x7c000658
+	 * lxvw4x	opcode: 0x7c000618
+	 */
+	if ((instr & 0xfc00073e) != 0x7c000618) {
+		pr_devel("HMI vec emu: not vector CI %i:%s[%d] nip=%016lx"
+			 " instr=%08x\n",
+			 smp_processor_id(), current->comm, current->pid,
+			 regs->nip, instr);
+		return;
+	}
+
+	/* Grab vector registers into the task struct */
+	msr = regs->msr; /* Grab msr before we flush the bits */
+	flush_vsx_to_thread(current);
+	enable_kernel_altivec();
+
+	/*
+	 * Is userspace running with a different endian (this is rare but
+	 * not impossible)
+	 */
+	swap = (msr & MSR_LE) != (MSR_KERNEL & MSR_LE);
+
+	/* Decode the instruction */
+	ra = (instr >> 16) & 0x1f;
+	rb = (instr >> 11) & 0x1f;
+	t = (instr >> 21) & 0x1f;
+	if (instr & 1)
+		vdst = (u8 *)&current->thread.vr_state.vr[t];
+	else
+		vdst = (u8 *)&current->thread.fp_state.fpr[t][0];
+
+	/* Grab the vector address */
+	ea = regs->gpr[rb] + (ra ? regs->gpr[ra] : 0);
+	if (is_32bit_task())
+		ea &= 0xfffffffful;
+	addr = (__force const void __user *)ea;
+
+	/* Check it */
+	if (!access_ok(VERIFY_READ, addr, 16)) {
+		pr_devel("HMI vec emu: bad access %i:%s[%d] nip=%016lx"
+			 " instr=%08x addr=%016lx\n",
+			 smp_processor_id(), current->comm, current->pid,
+			 regs->nip, instr, (unsigned long)addr);
+		return;
+	}
+
+	/* Read the vector */
+	rc = 0;
+	if ((unsigned long)addr & 0xfUL)
+		/* unaligned case */
+		rc = __copy_from_user_inatomic(vbuf, addr, 16);
+	else
+		__get_user_atomic_128_aligned(vbuf, addr, rc);
+	if (rc) {
+		pr_devel("HMI vec emu: page fault %i:%s[%d] nip=%016lx"
+			 " instr=%08x addr=%016lx\n",
+			 smp_processor_id(), current->comm, current->pid,
+			 regs->nip, instr, (unsigned long)addr);
+		return;
+	}
+
+	pr_devel("HMI vec emu: emulated vector CI %i:%s[%d] nip=%016lx"
+		 " instr=%08x addr=%016lx\n",
+		 smp_processor_id(), current->comm, current->pid, regs->nip,
+		 instr, (unsigned long) addr);
+
+	/* Grab instruction "selector" */
+	sel = (instr >> 6) & 3;
+
+	/*
+	 * Check to make sure the facility is actually enabled. This
+	 * could happen if we get a false positive hit.
+	 *
+	 * lxvd2x/lxvw4x always check MSR VSX sel = 0,2
+	 * lxvh8x/lxvb16x check MSR VSX or VEC depending on VSR used sel = 1,3
+	 */
+	msr_mask = MSR_VSX;
+	if ((sel & 1) && (instr & 1)) /* lxvh8x & lxvb16x + VSR >= 32 */
+		msr_mask = MSR_VEC;
+	if (!(msr & msr_mask)) {
+		pr_devel("HMI vec emu: MSR fac clear %i:%s[%d] nip=%016lx"
+			 " instr=%08x msr:%016lx\n",
+			 smp_processor_id(), current->comm, current->pid,
+			 regs->nip, instr, msr);
+		return;
+	}
+
+	/* Do logging here before we modify sel based on endian */
+	switch (sel) {
+	case 0:	/* lxvw4x */
+		PPC_WARN_EMULATED(lxvw4x, regs);
+		break;
+	case 1: /* lxvh8x */
+		PPC_WARN_EMULATED(lxvh8x, regs);
+		break;
+	case 2: /* lxvd2x */
+		PPC_WARN_EMULATED(lxvd2x, regs);
+		break;
+	case 3: /* lxvb16x */
+		PPC_WARN_EMULATED(lxvb16x, regs);
+		break;
+	}
+
+#ifdef __LITTLE_ENDIAN__
+	/*
+	 * An LE kernel stores the vector in the task struct as an LE
+	 * byte array (effectively swapping both the components and
+	 * the content of the components). Those instructions expect
+	 * the components to remain in ascending address order, so we
+	 * swap them back.
+	 *
+	 * If we are running a BE user space, the expectation is that
+	 * of a simple memcpy, so forcing the emulation to look like
+	 * a lxvb16x should do the trick.
+	 */
+	if (swap)
+		sel = 3;
+
+	switch (sel) {
+	case 0:	/* lxvw4x */
+		for (i = 0; i < 4; i++)
+			((u32 *)vdst)[i] = ((u32 *)vbuf)[3-i];
+		break;
+	case 1: /* lxvh8x */
+		for (i = 0; i < 8; i++)
+			((u16 *)vdst)[i] = ((u16 *)vbuf)[7-i];
+		break;
+	case 2: /* lxvd2x */
+		for (i = 0; i < 2; i++)
+			((u64 *)vdst)[i] = ((u64 *)vbuf)[1-i];
+		break;
+	case 3: /* lxvb16x */
+		for (i = 0; i < 16; i++)
+			vdst[i] = vbuf[15-i];
+		break;
+	}
+#else /* __LITTLE_ENDIAN__ */
+	/* On a big endian kernel, a BE userspace only needs a memcpy */
+	if (!swap)
+		sel = 3;
+
+	/* Otherwise, we need to swap the content of the components */
+	switch (sel) {
+	case 0:	/* lxvw4x */
+		for (i = 0; i < 4; i++)
+			((u32 *)vdst)[i] = cpu_to_le32(((u32 *)vbuf)[i]);
+		break;
+	case 1: /* lxvh8x */
+		for (i = 0; i < 8; i++)
+			((u16 *)vdst)[i] = cpu_to_le16(((u16 *)vbuf)[i]);
+		break;
+	case 2: /* lxvd2x */
+		for (i = 0; i < 2; i++)
+			((u64 *)vdst)[i] = cpu_to_le64(((u64 *)vbuf)[i]);
+		break;
+	case 3: /* lxvb16x */
+		memcpy(vdst, vbuf, 16);
+		break;
+	}
+#endif /* !__LITTLE_ENDIAN__ */
+
+	/* Go to next instruction */
+	regs->nip += 4;
+}
+#endif /* CONFIG_VSX */
+
 void handle_hmi_exception(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs;
@@ -706,6 +888,21 @@ void handle_hmi_exception(struct pt_regs *regs)
 	old_regs = set_irq_regs(regs);
 	irq_enter();
 
+#ifdef CONFIG_VSX
+	/* Real mode flagged P9 special emu is needed */
+	if (local_paca->hmi_p9_special_emu) {
+		local_paca->hmi_p9_special_emu = 0;
+
+		/*
+		 * We don't want to take page faults while doing the
+		 * emulation, we just replay the instruction if necessary.
+		 */
+		pagefault_disable();
+		p9_hmi_special_emu(regs);
+		pagefault_enable();
+	}
+#endif /* CONFIG_VSX */
+
 	if (ppc_md.handle_hmi_exception)
 		ppc_md.handle_hmi_exception(regs);
 
@@ -1924,6 +2121,10 @@ struct ppc_emulated ppc_emulated = {
 	WARN_EMULATED_SETUP(mfdscr),
 	WARN_EMULATED_SETUP(mtdscr),
 	WARN_EMULATED_SETUP(lq_stq),
+	WARN_EMULATED_SETUP(lxvw4x),
+	WARN_EMULATED_SETUP(lxvh8x),
+	WARN_EMULATED_SETUP(lxvd2x),
+	WARN_EMULATED_SETUP(lxvb16x),
 #endif
 };
 

commit b134165eadd6dd07c49f8db40b218185ca3130b0
Merge: 5d298baa4188 a4e89ffb5923
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Sep 20 20:05:24 2017 +1000

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into fixes
    
    Merge one commit from Scott which I missed while away.

commit b96672dd840f2231c3e0804842d380c401739733
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jul 19 16:59:12 2017 +1000

    powerpc: Machine check interrupt is a non-maskable interrupt
    
    Use nmi_enter similarly to system reset interrupts. This uses NMI
    printk NMI buffers and turns off various debugging facilities that
    helps avoid tripping on ourselves or other CPUs.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6858d910b47e..ec74e203ee04 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -644,8 +644,10 @@ int machine_check_generic(struct pt_regs *regs)
 
 void machine_check_exception(struct pt_regs *regs)
 {
-	enum ctx_state prev_state = exception_enter();
 	int recover = 0;
+	bool nested = in_nmi();
+	if (!nested)
+		nmi_enter();
 
 	/* 64s accounts the mce in machine_check_early when in HVMODE */
 	if (!IS_ENABLED(CONFIG_PPC_BOOK3S_64) || !cpu_has_feature(CPU_FTR_HVMODE))
@@ -677,10 +679,11 @@ void machine_check_exception(struct pt_regs *regs)
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
-		panic("Unrecoverable Machine check");
+		nmi_panic(regs, "Unrecoverable Machine check");
 
 bail:
-	exception_exit(prev_state);
+	if (!nested)
+		nmi_exit();
 }
 
 void SMIException(struct pt_regs *regs)

commit 6fcd6baa90aeec9dcbe30786e15c125bf50503b2
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jul 19 16:59:11 2017 +1000

    powerpc/powernv: Use kernel crash path for machine checks
    
    There are quite a few machine check exceptions that can be caused by
    kernel bugs. To make debugging easier, use the kernel crash path in
    cases of synchronous machine checks that occur in kernel mode, if that
    would not result in the machine going straight to panic or crash dump.
    
    There is a downside here that die()ing the process in kernel mode can
    still leave the system unstable. panic_on_oops will always force the
    system to fail-stop, so systems where that behaviour is important will
    still do the right thing.
    
    As a test, when triggering an i-side 0111b error (ifetch from foreign
    address) in kernel mode process context on POWER9, the kernel currently
    dies quickly like this:
    
      Severe Machine check interrupt [Not recovered]
        NIP [ffff000000000000]: 0xffff000000000000
        Initiator: CPU
        Error type: Real address [Instruction fetch (foreign)]
      [  127.426651616,0] OPAL: Reboot requested due to Platform error.
          Effective[  127.426693712,3] OPAL: Reboot requested due to Platform error. address: ffff000000000000
      opal: Reboot type 1 not supported
      Kernel panic - not syncing: PowerNV Unrecovered Machine Check
      CPU: 56 PID: 4425 Comm: syscall Tainted: G   M            4.12.0-rc1-13857-ga4700a261072-dirty #35
      Call Trace:
      [  128.017988928,4] IPMI: BUG: Dropping ESEL on the floor due to
        buggy/mising code in OPAL for this BMC
        Rebooting in 10 seconds..
      Trying to free IRQ 496 from IRQ context!
    
    After this patch, the process is killed and the kernel continues with
    this message, which gives enough information to identify the offending
    branch (i.e., with CFAR):
    
      Severe Machine check interrupt [Not recovered]
        NIP [ffff000000000000]: 0xffff000000000000
        Initiator: CPU
        Error type: Real address [Instruction fetch (foreign)]
          Effective address: ffff000000000000
      Oops: Machine check, sig: 7 [#1]
      SMP NR_CPUS=2048
      NUMA
      PowerNV
      Modules linked in: iptable_mangle ipt_MASQUERADE nf_nat_masquerade_ipv4 ...
      CPU: 22 PID: 4436 Comm: syscall Tainted: G   M            4.12.0-rc1-13857-ga4700a261072-dirty #36
      task: c000000932300000 task.stack: c000000932380000
      NIP: ffff000000000000 LR: 00000000217706a4 CTR: ffff000000000000
      REGS: c00000000fc8fd80 TRAP: 0200   Tainted: G   M             (4.12.0-rc1-13857-ga4700a261072-dirty)
      MSR: 90000000001c1003 <SF,HV,ME,RI,LE>
        CR: 24000484  XER: 20000000
      CFAR: c000000000004c80 DAR: 0000000021770a90 DSISR: 0a000000 SOFTE: 1
      GPR00: 0000000000001ebe 00007fffce4818b0 0000000021797f00 0000000000000000
      GPR04: 00007fff8007ac24 0000000044000484 0000000000004000 00007fff801405e8
      GPR08: 900000000280f033 0000000024000484 0000000000000000 0000000000000030
      GPR12: 9000000000001003 00007fff801bc370 0000000000000000 0000000000000000
      GPR16: 0000000000000000 0000000000000000 0000000000000000 0000000000000000
      GPR20: 0000000000000000 0000000000000000 0000000000000000 0000000000000000
      GPR24: 0000000000000000 0000000000000000 0000000000000000 0000000000000000
      GPR28: 00007fff801b0000 0000000000000000 00000000217707a0 00007fffce481918
      NIP [ffff000000000000] 0xffff000000000000
      LR [00000000217706a4] 0x217706a4
      Call Trace:
      Instruction dump:
      XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX
      XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX XXXXXXXX
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5e4db2fc2add..6858d910b47e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -114,6 +114,28 @@ static void pmac_backlight_unblank(void)
 static inline void pmac_backlight_unblank(void) { }
 #endif
 
+/*
+ * If oops/die is expected to crash the machine, return true here.
+ *
+ * This should not be expected to be 100% accurate, there may be
+ * notifiers registered or other unexpected conditions that may bring
+ * down the kernel. Or if the current process in the kernel is holding
+ * locks or has other critical state, the kernel may become effectively
+ * unusable anyway.
+ */
+bool die_will_crash(void)
+{
+	if (should_fadump_crash())
+		return true;
+	if (kexec_should_crash(current))
+		return true;
+	if (in_interrupt() || panic_on_oops ||
+			!current->pid || is_global_init(current))
+		return true;
+
+	return false;
+}
+
 static arch_spinlock_t die_lock = __ARCH_SPIN_LOCK_UNLOCKED;
 static int die_owner = -1;
 static unsigned int die_nest_count;

commit 4388c9b3a6ee7d6afc36c8a0bb5579b1606229b5
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jul 5 13:56:27 2017 +1000

    powerpc: Do not send system reset request through the oops path
    
    A system reset is a request to crash / debug the system rather than
    necessarily caused by encountering a BUG. So there is no need to
    serialize all CPUs behind the die lock, adding taints to all
    subsequent traces beyond the first, breaking console locks, etc.
    
    The system reset is NMI context which has its own printk buffers to
    prevent output being interleaved. Then it's better to have all
    secondaries print out their debug as quickly as possible and the
    primary will flush out all printk buffers during panic().
    
    So remove the 0x100 path from die, and move it into system_reset. Name
    the crash/dump reasons "System Reset".
    
    This gives "not tained" traces when crashing an untainted kernel. It
    also gives the panic reason as "System Reset" as opposed to "Fatal
    exception in interrupt" (or "die oops" for fadump).
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f77d954f6622..5e4db2fc2add 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -162,21 +162,9 @@ static void oops_end(unsigned long flags, struct pt_regs *regs,
 
 	crash_fadump(regs, "die oops");
 
-	/*
-	 * A system reset (0x100) is a request to dump, so we always send
-	 * it through the crashdump code.
-	 */
-	if (kexec_should_crash(current) || (TRAP(regs) == 0x100)) {
+	if (kexec_should_crash(current))
 		crash_kexec(regs);
 
-		/*
-		 * We aren't the primary crash CPU. We need to send it
-		 * to a holding pattern to avoid it ending up in the panic
-		 * code.
-		 */
-		crash_kexec_secondary(regs);
-	}
-
 	if (!signr)
 		return;
 
@@ -303,17 +291,44 @@ void system_reset_exception(struct pt_regs *regs)
 			goto out;
 	}
 
-	die("System Reset", regs, SIGABRT);
+	if (debugger(regs))
+		goto out;
+
+	/*
+	 * A system reset is a request to dump, so we always send
+	 * it through the crashdump code (if fadump or kdump are
+	 * registered).
+	 */
+	crash_fadump(regs, "System Reset");
+
+	crash_kexec(regs);
+
+	/*
+	 * We aren't the primary crash CPU. We need to send it
+	 * to a holding pattern to avoid it ending up in the panic
+	 * code.
+	 */
+	crash_kexec_secondary(regs);
+
+	/*
+	 * No debugger or crash dump registered, print logs then
+	 * panic.
+	 */
+	__die("System Reset", regs, SIGABRT);
+
+	mdelay(2*MSEC_PER_SEC); /* Wait a little while for others to print */
+	add_taint(TAINT_DIE, LOCKDEP_NOW_UNRELIABLE);
+	nmi_panic(regs, "System Reset");
 
 out:
 #ifdef CONFIG_PPC_BOOK3S_64
 	BUG_ON(get_paca()->in_nmi == 0);
 	if (get_paca()->in_nmi > 1)
-		panic("Unrecoverable nested System Reset");
+		nmi_panic(regs, "Unrecoverable nested System Reset");
 #endif
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
-		panic("Unrecoverable System Reset");
+		nmi_panic(regs, "Unrecoverable System Reset");
 
 	if (!nested)
 		nmi_exit();

commit a4e89ffb59235fd11d27107dea3efa4562ac0a12
Author: Matt Weber <matthew.weber@rockwellcollins.com>
Date:   Wed Jun 28 11:14:29 2017 -0500

    powerpc/e6500: Update machine check for L1D cache err
    
    This patch updates the machine check handler of Linux kernel to
    handle the e6500 architecture case. In e6500 core, L1 Data Cache Write
    Shadow Mode (DCWS) register is not implemented but L1 data cache always
    runs in write shadow mode. So, on L1 data cache parity errors, hardware
    will automatically invalidate the data cache but will still log a
    machine check interrupt.
    
    Signed-off-by: Ronak Desai <ronak.desai@rockwellcollins.com>
    Signed-off-by: Matthew Weber <matthew.weber@rockwellcollins.com>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 675d5d2bfcde..410352acfa38 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -393,6 +393,7 @@ static inline int check_io_access(struct pt_regs *regs)
 int machine_check_e500mc(struct pt_regs *regs)
 {
 	unsigned long mcsr = mfspr(SPRN_MCSR);
+	unsigned long pvr = mfspr(SPRN_PVR);
 	unsigned long reason = mcsr;
 	int recoverable = 1;
 
@@ -434,8 +435,15 @@ int machine_check_e500mc(struct pt_regs *regs)
 		 * may still get logged and cause a machine check.  We should
 		 * only treat the non-write shadow case as non-recoverable.
 		 */
-		if (!(mfspr(SPRN_L1CSR2) & L1CSR2_DCWS))
-			recoverable = 0;
+		/* On e6500 core, L1 DCWS (Data cache write shadow mode) bit
+		 * is not implemented but L1 data cache always runs in write
+		 * shadow mode. Hence on data cache parity errors HW will
+		 * automatically invalidate the L1 Data Cache.
+		 */
+		if (PVR_VER(pvr) != PVR_VER_E6500) {
+			if (!(mfspr(SPRN_L1CSR2) & L1CSR2_DCWS))
+				recoverable = 0;
+		}
 	}
 
 	if (reason & MCSR_L2MMU_MHIT) {

commit 1c56cd8ee945abdf955ad28a1f5c7576cd288be2
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Aug 23 23:56:22 2017 +1000

    powerpc/oops: Use IS_ENABLED() for oops markers
    
    Just because it looks less gross.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5a54a6f54f70..f77d954f6622 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -208,17 +208,18 @@ static int __die(const char *str, struct pt_regs *regs, long err)
 	else
 		printk("BE ");
 
-#ifdef CONFIG_PREEMPT
-	pr_cont("PREEMPT ");
-#endif
-#ifdef CONFIG_SMP
-	pr_cont("SMP NR_CPUS=%d ", NR_CPUS);
-#endif
+	if (IS_ENABLED(CONFIG_PREEMPT))
+		pr_cont("PREEMPT ");
+
+	if (IS_ENABLED(CONFIG_SMP))
+		pr_cont("SMP NR_CPUS=%d ", NR_CPUS);
+
 	if (debug_pagealloc_enabled())
 		pr_cont("DEBUG_PAGEALLOC ");
-#ifdef CONFIG_NUMA
-	pr_cont("NUMA ");
-#endif
+
+	if (IS_ENABLED(CONFIG_NUMA))
+		pr_cont("NUMA ");
+
 	pr_cont("%s\n", ppc_md.name ? ppc_md.name : "");
 
 	if (notify_die(DIE_OOPS, str, regs, err, 255, SIGSEGV) == NOTIFY_STOP)

commit 2e82ca3c3978d441ab272a7a964d03c6d2ee2bf3
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Aug 23 23:56:21 2017 +1000

    powerpc/oops: Print the kernel's endian in the oops
    
    Although the MSR tells you what endian you're in it's possible that
    isn't the same endian the kernel was built for, and if that happens
    you're usually having a very bad day. So print a marker to make
    it 100% clear which endian the kernel was built for.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 82d0ce236f9d..5a54a6f54f70 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -202,6 +202,12 @@ NOKPROBE_SYMBOL(oops_end);
 static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
+
+	if (IS_ENABLED(CONFIG_CPU_LITTLE_ENDIAN))
+		printk("LE ");
+	else
+		printk("BE ");
+
 #ifdef CONFIG_PREEMPT
 	pr_cont("PREEMPT ");
 #endif

commit 72c0d9ee4abc44c82a00eadebe08a740645ad8a0
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Aug 23 23:56:20 2017 +1000

    powerpc/oops: Fix the oops markers to use pr_cont()
    
    When we oops we print a few markers for significant config options
    such as PREEMPT, SMP etc. Currently these appear on separate lines
    because we're not using pr_cont() properly. Fix it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 675d5d2bfcde..82d0ce236f9d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -203,17 +203,17 @@ static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT
-	printk("PREEMPT ");
+	pr_cont("PREEMPT ");
 #endif
 #ifdef CONFIG_SMP
-	printk("SMP NR_CPUS=%d ", NR_CPUS);
+	pr_cont("SMP NR_CPUS=%d ", NR_CPUS);
 #endif
 	if (debug_pagealloc_enabled())
-		printk("DEBUG_PAGEALLOC ");
+		pr_cont("DEBUG_PAGEALLOC ");
 #ifdef CONFIG_NUMA
-	printk("NUMA ");
+	pr_cont("NUMA ");
 #endif
-	printk("%s\n", ppc_md.name ? ppc_md.name : "");
+	pr_cont("%s\n", ppc_md.name ? ppc_md.name : "");
 
 	if (notify_die(DIE_OOPS, str, regs, err, 255, SIGSEGV) == NOTIFY_STOP)
 		return 1;

commit fbbcc3bb139e044653b47f183ac9189c31895f23
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 8 13:58:44 2017 +0200

    powerpc/8xx: Remove SoftwareEmulation()
    
    Since commit aa42c69c67f82 ("[POWERPC] Add support for FP emulation
    for the e300c2 core"), program_check_exception() can be called for
    math emulation. In that case, 'reason' is 0.
    
    On the 8xx, there is a Software Emulation interrupt which is
    called for all unimplemented and illegal instructions. This
    interrupt calls SoftwareEmulation() which does almost the
    same as program_check_exception() called with reason = 0.
    
    The Software Emulation interrupt sets all reason bits to 0,
    it is therefore possible to call program_check_exception()
    directly from the interrupt handler.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ce10a3cc860f..675d5d2bfcde 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1522,24 +1522,6 @@ void performance_monitor_exception(struct pt_regs *regs)
 	perf_irq(regs);
 }
 
-#ifdef CONFIG_8xx
-void SoftwareEmulation(struct pt_regs *regs)
-{
-	CHECK_FULL_REGS(regs);
-
-	if (!user_mode(regs)) {
-		debugger(regs);
-		die("Kernel Mode Unimplemented Instruction or SW FPU Emulation",
-			regs, SIGFPE);
-	}
-
-	if (!emulate_math(regs))
-		return;
-
-	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-}
-#endif /* CONFIG_8xx */
-
 #ifdef CONFIG_PPC_ADV_DEBUG_REGS
 static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 {

commit f70b1e8d17ce93fc963936aee144f54a4530172f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 8 13:58:42 2017 +0200

    powerpc/8xx: Move 8xx machine check handlers into platforms/8xx
    
    In the same spirit as what was done for 4xx and 44x, move
    the 8xx machine check into platforms/8xx
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c567d706a7ed..ce10a3cc860f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -560,31 +560,6 @@ int machine_check_e200(struct pt_regs *regs)
 
 	return 0;
 }
-#elif defined(CONFIG_PPC_8xx)
-int machine_check_8xx(struct pt_regs *regs)
-{
-	unsigned long reason = regs->msr;
-
-	pr_err("Machine check in kernel mode.\n");
-	pr_err("Caused by (from SRR1=%lx): ", reason);
-	if (reason & 0x40000000)
-		pr_err("Fetch error at address %lx\n", regs->nip);
-	else
-		pr_err("Data access error at address %lx\n", regs->dar);
-
-#ifdef CONFIG_PCI
-	/* the qspan pci read routines can cause machine checks -- Cort
-	 *
-	 * yuck !!! that totally needs to go away ! There are better ways
-	 * to deal with that than having a wart in the mcheck handler.
-	 * -- BenH
-	 */
-	bad_page_fault(regs, regs->dar, SIGBUS);
-	return 1;
-#else
-	return 0;
-#endif
-}
 #elif defined(CONFIG_PPC32)
 int machine_check_generic(struct pt_regs *regs)
 {

commit d30a5a5262ca64d58aa07fb2ecd7f992df83b4bc
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:25 2017 +1000

    powerpc/traps: Use SRR1 defines for program check reasons
    
    Currently we open code the reason codes for program checks. Instead use
    the existing SRR1 defines.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a891c277040b..c567d706a7ed 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -379,11 +379,11 @@ static inline int check_io_access(struct pt_regs *regs)
 /* On non-4xx, the reason for the machine check or program
    exception is in the MSR. */
 #define get_reason(regs)	((regs)->msr)
-#define REASON_TM		0x200000
-#define REASON_FP		0x100000
-#define REASON_ILLEGAL		0x80000
-#define REASON_PRIVILEGED	0x40000
-#define REASON_TRAP		0x20000
+#define REASON_TM		SRR1_PROGTM
+#define REASON_FP		SRR1_PROGFPE
+#define REASON_ILLEGAL		SRR1_PROGILL
+#define REASON_PRIVILEGED	SRR1_PROGPRIV
+#define REASON_TRAP		SRR1_PROGTRAP
 
 #define single_stepping(regs)	((regs)->msr & MSR_SE)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)

commit ccd3cd361341b71ae2afa596f6b470fcb32a916e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:24 2017 +1000

    powerpc/mce: Move 64-bit machine check code into mce.c
    
    We already have mce.c which is built for 64bit and contains other parts
    of the machine check code, so move these bits in there too.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ef957c28bbc4..a891c277040b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -314,39 +314,6 @@ void system_reset_exception(struct pt_regs *regs)
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
 
-#ifdef CONFIG_PPC64
-/*
- * This function is called in real mode. Strictly no printk's please.
- *
- * regs->nip and regs->msr contains srr0 and ssr1.
- */
-long machine_check_early(struct pt_regs *regs)
-{
-	long handled = 0;
-
-	__this_cpu_inc(irq_stat.mce_exceptions);
-
-	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
-		handled = cur_cpu_spec->machine_check_early(regs);
-	return handled;
-}
-
-long hmi_exception_realmode(struct pt_regs *regs)
-{
-	__this_cpu_inc(irq_stat.hmi_exceptions);
-
-	wait_for_subcore_guest_exit();
-
-	if (ppc_md.hmi_exception_early)
-		ppc_md.hmi_exception_early(regs);
-
-	wait_for_tb_resync();
-
-	return 0;
-}
-
-#endif
-
 /*
  * I/O accesses can cause machine checks on powermacs.
  * Check if the NIP corresponds to the address of a sync

commit 7f3f819e94415b7c6d9bcd2d818595504069eae4
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:23 2017 +1000

    powerpc/traps: machine_check_generic() is only used on 32-bit
    
    Make it clear that the fallback version of machine_check_generic() is
    only used on 32-bit configs.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1b1ae799e2f2..ef957c28bbc4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -618,7 +618,7 @@ int machine_check_8xx(struct pt_regs *regs)
 	return 0;
 #endif
 }
-#else
+#elif defined(CONFIG_PPC32)
 int machine_check_generic(struct pt_regs *regs)
 {
 	unsigned long reason = regs->msr;

commit 42bff234be3bb05b74001a108004ced8407a6068
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:22 2017 +1000

    powerpc/traps: Inline get_mc_reason()
    
    get_mc_reason() no longer provides (if it ever really did) any
    meaningful abstraction, so remove it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 8d1f79b30ff2..1b1ae799e2f2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -399,11 +399,6 @@ static inline int check_io_access(struct pt_regs *regs)
 /* On 4xx, the reason for the machine check or program exception
    is in the ESR. */
 #define get_reason(regs)	((regs)->dsisr)
-#ifndef CONFIG_FSL_BOOKE
-#define get_mc_reason(regs)	((regs)->dsisr)
-#else
-#define get_mc_reason(regs)	(mfspr(SPRN_MCSR))
-#endif
 #define REASON_FP		ESR_FP
 #define REASON_ILLEGAL		(ESR_PIL | ESR_PUO)
 #define REASON_PRIVILEGED	ESR_PPR
@@ -417,7 +412,6 @@ static inline int check_io_access(struct pt_regs *regs)
 /* On non-4xx, the reason for the machine check or program
    exception is in the MSR. */
 #define get_reason(regs)	((regs)->msr)
-#define get_mc_reason(regs)	((regs)->msr)
 #define REASON_TM		0x200000
 #define REASON_FP		0x100000
 #define REASON_ILLEGAL		0x80000
@@ -530,7 +524,7 @@ int machine_check_e500mc(struct pt_regs *regs)
 
 int machine_check_e500(struct pt_regs *regs)
 {
-	unsigned long reason = get_mc_reason(regs);
+	unsigned long reason = mfspr(SPRN_MCSR);
 
 	if (reason & MCSR_BUS_RBERR) {
 		if (fsl_rio_mcheck_exception(regs))
@@ -577,7 +571,7 @@ int machine_check_generic(struct pt_regs *regs)
 #elif defined(CONFIG_E200)
 int machine_check_e200(struct pt_regs *regs)
 {
-	unsigned long reason = get_mc_reason(regs);
+	unsigned long reason = mfspr(SPRN_MCSR);
 
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from MCSR=%lx): ", reason);
@@ -602,7 +596,7 @@ int machine_check_e200(struct pt_regs *regs)
 #elif defined(CONFIG_PPC_8xx)
 int machine_check_8xx(struct pt_regs *regs)
 {
-	unsigned long reason = get_mc_reason(regs);
+	unsigned long reason = regs->msr;
 
 	pr_err("Machine check in kernel mode.\n");
 	pr_err("Caused by (from SRR1=%lx): ", reason);
@@ -627,7 +621,7 @@ int machine_check_8xx(struct pt_regs *regs)
 #else
 int machine_check_generic(struct pt_regs *regs)
 {
-	unsigned long reason = get_mc_reason(regs);
+	unsigned long reason = regs->msr;
 
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from SRR1=%lx): ", reason);

commit 0d0935b367b41394aae9d9ee45fb9a2317b8baf7
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:21 2017 +1000

    powerpc/4xx: Move machine_check_4xx() into platforms/4xx
    
    Now that we have 4xx platform directory we can move the 4xx machine
    check handler in there. Again we drop get_mc_reason() and replace it
    with regs->dsisr directly (which is actually SPRN_ESR).
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 69b54abfc89e..8d1f79b30ff2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -428,23 +428,7 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
-#if defined(CONFIG_4xx)
-int machine_check_4xx(struct pt_regs *regs)
-{
-	unsigned long reason = get_mc_reason(regs);
-
-	if (reason & ESR_IMCP) {
-		printk("Instruction");
-		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
-	} else
-		printk("Data");
-	printk(" machine check in kernel mode.\n");
-
-	return 0;
-}
-
-
-#elif defined(CONFIG_E500)
+#if defined(CONFIG_E500)
 int machine_check_e500mc(struct pt_regs *regs)
 {
 	unsigned long mcsr = mfspr(SPRN_MCSR);

commit 5b4e28577b16941ec24ec07611642ddae62f1870
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:19 2017 +1000

    powerpc/44x: Move 44x machine check handlers into platforms/44x
    
    We have several 44x machine check handlers defined in traps.c. It would
    be preferable if they were split out with the platforms that use them.
    Do that.
    
    In the process, drop get_mc_reason() and instead just open code the
    lookup of reason from regs->dsisr. This avoids a pointless layer of
    abstraction.
    
    We know to use regs->dsisr because 44x enables BOOKE which enables
    PPC_ADV_DEBUG_REGS, and FSL_BOOKE is not enabled on 44x builds.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ec1557f1b157..69b54abfc89e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -443,81 +443,7 @@ int machine_check_4xx(struct pt_regs *regs)
 	return 0;
 }
 
-int machine_check_440A(struct pt_regs *regs)
-{
-	unsigned long reason = get_mc_reason(regs);
-
-	printk("Machine check in kernel mode.\n");
-	if (reason & ESR_IMCP){
-		printk("Instruction Synchronous Machine Check exception\n");
-		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
-	}
-	else {
-		u32 mcsr = mfspr(SPRN_MCSR);
-		if (mcsr & MCSR_IB)
-			printk("Instruction Read PLB Error\n");
-		if (mcsr & MCSR_DRB)
-			printk("Data Read PLB Error\n");
-		if (mcsr & MCSR_DWB)
-			printk("Data Write PLB Error\n");
-		if (mcsr & MCSR_TLBP)
-			printk("TLB Parity Error\n");
-		if (mcsr & MCSR_ICP){
-			flush_instruction_cache();
-			printk("I-Cache Parity Error\n");
-		}
-		if (mcsr & MCSR_DCSP)
-			printk("D-Cache Search Parity Error\n");
-		if (mcsr & MCSR_DCFP)
-			printk("D-Cache Flush Parity Error\n");
-		if (mcsr & MCSR_IMPE)
-			printk("Machine Check exception is imprecise\n");
-
-		/* Clear MCSR */
-		mtspr(SPRN_MCSR, mcsr);
-	}
-	return 0;
-}
-
-int machine_check_47x(struct pt_regs *regs)
-{
-	unsigned long reason = get_mc_reason(regs);
-	u32 mcsr;
 
-	printk(KERN_ERR "Machine check in kernel mode.\n");
-	if (reason & ESR_IMCP) {
-		printk(KERN_ERR
-		       "Instruction Synchronous Machine Check exception\n");
-		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
-		return 0;
-	}
-	mcsr = mfspr(SPRN_MCSR);
-	if (mcsr & MCSR_IB)
-		printk(KERN_ERR "Instruction Read PLB Error\n");
-	if (mcsr & MCSR_DRB)
-		printk(KERN_ERR "Data Read PLB Error\n");
-	if (mcsr & MCSR_DWB)
-		printk(KERN_ERR "Data Write PLB Error\n");
-	if (mcsr & MCSR_TLBP)
-		printk(KERN_ERR "TLB Parity Error\n");
-	if (mcsr & MCSR_ICP) {
-		flush_instruction_cache();
-		printk(KERN_ERR "I-Cache Parity Error\n");
-	}
-	if (mcsr & MCSR_DCSP)
-		printk(KERN_ERR "D-Cache Search Parity Error\n");
-	if (mcsr & PPC47x_MCSR_GPR)
-		printk(KERN_ERR "GPR Parity Error\n");
-	if (mcsr & PPC47x_MCSR_FPR)
-		printk(KERN_ERR "FPR Parity Error\n");
-	if (mcsr & PPC47x_MCSR_IPR)
-		printk(KERN_ERR "Machine Check exception is imprecise\n");
-
-	/* Clear MCSR */
-	mtspr(SPRN_MCSR, mcsr);
-
-	return 0;
-}
 #elif defined(CONFIG_E500)
 int machine_check_e500mc(struct pt_regs *regs)
 {

commit ca41ad4377072e3e51593a2a9593c6cdbf4a5c0d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Aug 1 22:00:53 2017 +1000

    powerpc: Add irq accounting for system reset interrupts
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d42c567e3c29..ec1557f1b157 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -288,6 +288,8 @@ void system_reset_exception(struct pt_regs *regs)
 	if (!nested)
 		nmi_enter();
 
+	__this_cpu_inc(irq_stat.sreset_irqs);
+
 	/* See if any machine dependent calls */
 	if (ppc_md.system_reset_exception) {
 		if (ppc_md.system_reset_exception(regs))

commit f886f0f6e0e20d53dc36421c2ee83fb9277554af
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Aug 1 22:00:51 2017 +1000

    powerpc/64s: Fix mce accounting for powernv
    
    On 64-bit Book3s, when we're in HV mode, we have already counted the
    machine check exception in machine_check_early().
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Use IS_ENABLED() rather than an #ifdef]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bfcfd9ef09f2..d42c567e3c29 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -755,7 +755,9 @@ void machine_check_exception(struct pt_regs *regs)
 	enum ctx_state prev_state = exception_enter();
 	int recover = 0;
 
-	__this_cpu_inc(irq_stat.mce_exceptions);
+	/* 64s accounts the mce in machine_check_early when in HVMODE */
+	if (!IS_ENABLED(CONFIG_PPC_BOOK3S_64) || !cpu_has_feature(CPU_FTR_HVMODE))
+		__this_cpu_inc(irq_stat.mce_exceptions);
 
 	add_taint(TAINT_MACHINE_CHECK, LOCKDEP_NOW_UNRELIABLE);
 

commit 15770a13bebc7fae2fbc06bc4cc708a3f724c586
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Thu Jun 29 23:19:19 2017 +0530

    powerpc/64s: Blacklist functions invoked on a trap
    
    Blacklist all functions involved while handling a trap. We:
    - convert some of the symbols into private symbols, and
    - blacklist most functions involved while handling a trap.
    
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d4e545d27ef9..bfcfd9ef09f2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -237,6 +237,7 @@ void die(const char *str, struct pt_regs *regs, long err)
 		err = 0;
 	oops_end(flags, regs, err);
 }
+NOKPROBE_SYMBOL(die);
 
 void user_single_step_siginfo(struct task_struct *tsk,
 				struct pt_regs *regs, siginfo_t *info)
@@ -1968,6 +1969,7 @@ void unrecoverable_exception(struct pt_regs *regs)
 	       regs->trap, regs->nip);
 	die("Unrecoverable exception", regs, SIGABRT);
 }
+NOKPROBE_SYMBOL(unrecoverable_exception);
 
 #if defined(CONFIG_BOOKE_WDT) || defined(CONFIG_40x)
 /*
@@ -1998,6 +2000,7 @@ void kernel_bad_stack(struct pt_regs *regs)
 	       regs->gpr[1], regs->nip);
 	die("Bad kernel stack pointer", regs, SIGABRT);
 }
+NOKPROBE_SYMBOL(kernel_bad_stack);
 
 void __init trap_init(void)
 {

commit d93b0ac01a9ce276ec39644be47001873d3d183c
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Tue Apr 18 22:08:17 2017 +0530

    powerpc/book3s/mce: Move add_taint() later in virtual mode
    
    machine_check_early() gets called in real mode. The very first time when
    add_taint() is called, it prints a warning which ends up calling opal
    call (that uses OPAL_CALL wrapper) for writing it to console. If we get a
    very first machine check while we are in opal we are doomed. OPAL_CALL
    overwrites the PACASAVEDMSR in r13 and in this case when we are done with
    MCE handling the original opal call will use this new MSR on it's way
    back to opal_return. This usually leads to unexpected behaviour or the
    kernel to panic. Instead move the add_taint() call later in the virtual
    mode where it is safe to call.
    
    This is broken with current FW level. We got lucky so far for not getting
    very first MCE hit while in OPAL. But easily reproducible on Mambo.
    
    Fixes: 27ea2c420cad ("powerpc: Set the correct kernel taint on machine check errors.")
    Cc: stable@vger.kernel.org # v4.2+
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6a81a451d767..d4e545d27ef9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -323,8 +323,6 @@ long machine_check_early(struct pt_regs *regs)
 
 	__this_cpu_inc(irq_stat.mce_exceptions);
 
-	add_taint(TAINT_MACHINE_CHECK, LOCKDEP_NOW_UNRELIABLE);
-
 	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
 		handled = cur_cpu_spec->machine_check_early(regs);
 	return handled;
@@ -758,6 +756,8 @@ void machine_check_exception(struct pt_regs *regs)
 
 	__this_cpu_inc(irq_stat.mce_exceptions);
 
+	add_taint(TAINT_MACHINE_CHECK, LOCKDEP_NOW_UNRELIABLE);
+
 	/* See if any machine dependent calls. In theory, we would want
 	 * to call the CPU first, and call the ppc_md. one if the CPU
 	 * one returns a positive number. However there is existing code

commit 2b4f3ac5642672595ef6f71d1572b32475e94863
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:07 2016 +1000

    powerpc: Mark system reset as an NMI with nmi_enter/exit()
    
    System reset is a non-maskable interrupt from Linux's point of view
    (occurs under local_irq_disable()), so it should use nmi_enter/exit.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2393d3c46236..6a81a451d767 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -279,6 +279,14 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 
 void system_reset_exception(struct pt_regs *regs)
 {
+	/*
+	 * Avoid crashes in case of nested NMI exceptions. Recoverability
+	 * is determined by RI and in_nmi
+	 */
+	bool nested = in_nmi();
+	if (!nested)
+		nmi_enter();
+
 	/* See if any machine dependent calls */
 	if (ppc_md.system_reset_exception) {
 		if (ppc_md.system_reset_exception(regs))
@@ -297,6 +305,9 @@ void system_reset_exception(struct pt_regs *regs)
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable System Reset");
 
+	if (!nested)
+		nmi_exit();
+
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
 

commit c4f3b52ce7b16824befb16ab3d045c891b08b7db
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:05 2016 +1000

    powerpc/64s: Disallow system reset vs system reset reentrancy
    
    In preparation for using a dedicated stack for system reset interrupts,
    prevent a nested system reset from recovering, in order to simplify
    code that is called in crash/debug path. This allows a system reset
    interrupt to just use the base stack pointer.
    
    Keep an in_nmi nesting counter similarly to the in_mce counter. Consider
    the interrrupt non-recoverable if it is taken inside another system
    reset.
    
    Interrupt nesting could be allowed similarly to MCE, but system reset
    is a special case that's not for normal operation, so simplicity wins
    until there is requirement for nested system reset interrupts.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 76f6045b021b..2393d3c46236 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -282,11 +282,17 @@ void system_reset_exception(struct pt_regs *regs)
 	/* See if any machine dependent calls */
 	if (ppc_md.system_reset_exception) {
 		if (ppc_md.system_reset_exception(regs))
-			return;
+			goto out;
 	}
 
 	die("System Reset", regs, SIGABRT);
 
+out:
+#ifdef CONFIG_PPC_BOOK3S_64
+	BUG_ON(get_paca()->in_nmi == 0);
+	if (get_paca()->in_nmi > 1)
+		panic("Unrecoverable nested System Reset");
+#endif
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable System Reset");

commit 9b7ff0c6586bc0541ebcd1ff6773b11a49f1a058
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Apr 7 11:27:44 2017 +1000

    powerpc/64s: Add SCV FSCR bit for ISA v3.0
    
    Add the bit definition and use it in facility_unavailable_exception() so we can
    intelligently report the cause if we take a fault for SCV. This doesn't actually
    enable SCV.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Drop whitespace changes to the existing entries, flush out change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 65bd13338722..76f6045b021b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1441,6 +1441,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		[FSCR_EBB_LG] = "EBB",
 		[FSCR_TAR_LG] = "TAR",
 		[FSCR_MSGP_LG] = "MSGP",
+		[FSCR_SCV_LG] = "SCV",
 	};
 	char *facility = "unknown";
 	u64 value;

commit 794464f4dea0b13dacad267c06a01fc9c24f713a
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Apr 7 11:27:43 2017 +1000

    powerpc/64s: Add msgp facility unavailable log string
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 354946236c61..65bd13338722 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1440,6 +1440,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		[FSCR_TM_LG] = "TM",
 		[FSCR_EBB_LG] = "EBB",
 		[FSCR_TAR_LG] = "TAR",
+		[FSCR_MSGP_LG] = "MSGP",
 	};
 	char *facility = "unknown";
 	u64 value;

commit 7644d5819cf8956d799a0a0e5dc75f5a29889bd5
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Feb 10 12:04:56 2017 +1100

    powerpc: Create asm/debugfs.h and move powerpc_debugfs_root there
    
    powerpc_debugfs_root is the dentry representing the root of the
    "powerpc" directory tree in debugfs.
    
    Currently it sits in asm/debug.h, a long with some other things that
    have "debug" in the name, but are otherwise unrelated.
    
    Pull it out into a separate header, which also includes linux/debugfs.h,
    and convert all the users to include debugfs.h instead of debug.h.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ff365f9de27a..354946236c61 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -35,13 +35,13 @@
 #include <linux/backlight.h>
 #include <linux/bug.h>
 #include <linux/kdebug.h>
-#include <linux/debugfs.h>
 #include <linux/ratelimit.h>
 #include <linux/context_tracking.h>
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
 #include <linux/uaccess.h>
+#include <asm/debugfs.h>
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/rtas.h>

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e6cc56b61d01..ff365f9de27a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -17,6 +17,7 @@
 
 #include <linux/errno.h>
 #include <linux/sched.h>
+#include <linux/sched/debug.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/stddef.h>

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4239aaf74886..e6cc56b61d01 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -40,7 +40,7 @@
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/rtas.h>

commit 93c2ec0f7019a155769d1ecfc08a7de83b47e03d
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Nov 30 17:45:09 2016 +1100

    powerpc Don't print misleading facility name in facility unavailable exception
    
    The current facility_strings[] are correct when the trap address is
    0xf80 (hypervisor facility unavailable). When the trap address is
    0xf60 (facility unavailable) IC (Interruption Cause) a.k.a status in the
    code is undefined for values 0 and 1.
    
    Add a check to prevent printing the (misleading) facility name for IC 0
    and 1 when we came in via 0xf60. In all cases, print the actual IC
    value, to avoid any confusion.
    
    This hasn't been seen on real hardware, on only qemu which was
    misreporting an exception.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Fix indentation, combine printks(), massage change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5faaed2f2144..4239aaf74886 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1519,7 +1519,8 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		return;
 	}
 
-	if ((status < ARRAY_SIZE(facility_strings)) &&
+	if ((hv || status >= 2) &&
+	    (status < ARRAY_SIZE(facility_strings)) &&
 	    facility_strings[status])
 		facility = facility_strings[status];
 
@@ -1527,9 +1528,8 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
-	pr_err_ratelimited(
-		"%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
-		hv ? "Hypervisor " : "", facility, regs->nip, regs->msr);
+	pr_err_ratelimited("%sFacility '%s' unavailable (%d), exception at 0x%lx, MSR=%lx\n",
+		hv ? "Hypervisor " : "", facility, status, regs->nip, regs->msr);
 
 out:
 	if (user_mode(regs)) {

commit da6658859b9c734fee36570f3a7d51764c6c3838
Author: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
Date:   Tue Nov 29 23:45:50 2016 +1100

    powerpc: Change places using CONFIG_KEXEC to use CONFIG_KEXEC_CORE instead.
    
    Commit 2965faa5e03d ("kexec: split kexec_load syscall from kexec core
    code") introduced CONFIG_KEXEC_CORE so that CONFIG_KEXEC means whether
    the kexec_load system call should be compiled-in and CONFIG_KEXEC_FILE
    means whether the kexec_file_load system call should be compiled-in.
    These options can be set independently from each other.
    
    Since until now powerpc only supported kexec_load, CONFIG_KEXEC and
    CONFIG_KEXEC_CORE were synonyms. That is not the case anymore, so we
    need to make a distinction. Almost all places where CONFIG_KEXEC was
    being used should be using CONFIG_KEXEC_CORE instead, since
    kexec_file_load also needs that code compiled in.
    
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b922c6f4a2fe..5faaed2f2144 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -66,7 +66,7 @@
 #include <sysdev/fsl_pci.h>
 #include <asm/kprobes.h>
 
-#if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
+#if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC_CORE)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_ipi)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_bpt)(struct pt_regs *regs) __read_mostly;

commit 6cc89bad60a673a24386f1ada83de8a068a78909
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Mon Nov 21 22:36:41 2016 +0530

    powerpc/kprobes: Invoke handlers directly
    
    Invoke the kprobe handlers directly rather than through notify_die(), to
    reduce path taken for handling kprobes. Similar to commit 6f6343f53d13
    ("kprobes/x86: Call exception handlers directly from do_int3/do_debug").
    
    While at it, rename post_kprobe_handler() to kprobe_post_handler() for
    more uniform naming.
    
    Reported-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 3eb20d16c67c..b922c6f4a2fe 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -64,6 +64,7 @@
 #include <asm/asm-prototypes.h>
 #include <asm/hmi.h>
 #include <sysdev/fsl_pci.h>
+#include <asm/kprobes.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -826,6 +827,9 @@ void single_step_exception(struct pt_regs *regs)
 
 	clear_single_step(regs);
 
+	if (kprobe_post_handler(regs))
+		return;
+
 	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
 		goto bail;
@@ -1179,6 +1183,9 @@ void program_check_exception(struct pt_regs *regs)
 		if (debugger_bpt(regs))
 			goto bail;
 
+		if (kprobe_handler(regs))
+			goto bail;
+
 		/* trap exception */
 		if (notify_die(DIE_BPT, "breakpoint", regs, 5, 5, SIGTRAP)
 				== NOTIFY_STOP)
@@ -1747,6 +1754,9 @@ void DebugException(struct pt_regs *regs, unsigned long debug_status)
 			return;
 		}
 
+		if (kprobe_post_handler(regs))
+			return;
+
 		if (notify_die(DIE_SSTEP, "block_step", regs, 5,
 			       5, SIGTRAP) == NOTIFY_STOP) {
 			return;
@@ -1761,6 +1771,9 @@ void DebugException(struct pt_regs *regs, unsigned long debug_status)
 		/* Clear the instruction completion event */
 		mtspr(SPRN_DBSR, DBSR_IC);
 
+		if (kprobe_post_handler(regs))
+			return;
+
 		if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 			       5, SIGTRAP) == NOTIFY_STOP) {
 			return;

commit 7458e8b2ce62e65051fec0bcb14cac35d4f1118d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Nov 8 23:14:45 2016 +1100

    powerpc: Fix second nested oops hang
    
    When ending an oops, don't clear die_owner unless the nest count
    went to zero. This prevents a second nested oops from hanging forever
    on the die_lock.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 13ca8b687e88..3eb20d16c67c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -147,14 +147,15 @@ static void oops_end(unsigned long flags, struct pt_regs *regs,
 			       int signr)
 {
 	bust_spinlocks(0);
-	die_owner = -1;
 	add_taint(TAINT_DIE, LOCKDEP_NOW_UNRELIABLE);
 	die_nest_count--;
 	oops_exit();
 	printk("\n");
-	if (!die_nest_count)
+	if (!die_nest_count) {
 		/* Nest count reaches zero, release the lock. */
+		die_owner = -1;
 		arch_spin_unlock(&die_lock);
+	}
 	raw_local_irq_restore(flags);
 
 	crash_fadump(regs, "die oops");

commit 6f44b20ee9b4130345c189c0c90ef6604bcd8005
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Nov 8 23:14:44 2016 +1100

    powerpc: Fix graceful debugger recovery
    
    When exiting xmon with 'x' (exit and recover), oops_begin bails
    out immediately, but die then calls __die() and oops_end(), which
    cause a lot of bad things to happen.
    
    If the debugger was attached then went to graceful recovery, exit
    from die() immediately.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 91d278c9ab28..13ca8b687e88 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -122,9 +122,6 @@ static unsigned long oops_begin(struct pt_regs *regs)
 	int cpu;
 	unsigned long flags;
 
-	if (debugger(regs))
-		return 1;
-
 	oops_enter();
 
 	/* racy, but better than risking deadlock. */
@@ -227,8 +224,12 @@ NOKPROBE_SYMBOL(__die);
 
 void die(const char *str, struct pt_regs *regs, long err)
 {
-	unsigned long flags = oops_begin(regs);
+	unsigned long flags;
+
+	if (debugger(regs))
+		return;
 
+	flags = oops_begin(regs);
 	if (__die(str, regs, err))
 		err = 0;
 	oops_end(flags, regs, err);

commit 29a969b764817c1dce819c2bc8c00a147529a5ef
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Oct 31 13:19:39 2016 +1100

    powerpc: Revert Load Monitor Register Support
    
    Load monitored is no longer supported on POWER9 so let's remove the
    code.
    
    This reverts commit bd3ea317fddf ("powerpc: Load Monitor Register
    Support").
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 32c468b8b548..91d278c9ab28 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1430,7 +1430,6 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		[FSCR_TM_LG] = "TM",
 		[FSCR_EBB_LG] = "EBB",
 		[FSCR_TAR_LG] = "TAR",
-		[FSCR_LM_LG] = "LM",
 	};
 	char *facility = "unknown";
 	u64 value;
@@ -1488,14 +1487,6 @@ void facility_unavailable_exception(struct pt_regs *regs)
 			emulate_single_step(regs);
 		}
 		return;
-	} else if ((status == FSCR_LM_LG) && cpu_has_feature(CPU_FTR_ARCH_300)) {
-		/*
-		 * This process has touched LM, so turn it on forever
-		 * for this process
-		 */
-		current->thread.fscr |= FSCR_LM;
-		mtspr(SPRN_FSCR, current->thread.fscr);
-		return;
 	}
 
 	if (status == FSCR_TM_LG) {

commit 61a92f703120daf7ed25e046275aa8a2d3085ad4
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Oct 14 16:47:31 2016 +1100

    powerpc: Add support for relative exception tables
    
    This halves the exception table size on 64-bit builds, and it allows
    build-time sorting of exception tables to work on relocated kernels.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Minor asm fixups and bits to keep the selftests working]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 023a462725b5..32c468b8b548 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -365,7 +365,7 @@ static inline int check_io_access(struct pt_regs *regs)
 			       (*nip & 0x100)? "OUT to": "IN from",
 			       regs->gpr[rb] - _IO_BASE, nip);
 			regs->msr |= MSR_RI;
-			regs->nip = entry->fixup;
+			regs->nip = extable_fixup(entry);
 			return 1;
 		}
 	}

commit 065397a969a0f80624598c5030c2551abbd986fd
Merge: 8321564a11bb e0b80f00bb96
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Oct 11 20:07:56 2016 +1100

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include qbman support (a prerequisite for datapath drivers
    such as ethernet), a PCI DMA fix+improvement, reset handler changes, more
    8xx optimizations, and some cleanups and fixes."

commit 5d176f751ee3c6eededd984ad409bff201f436a7
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Wed Sep 14 18:02:16 2016 +1000

    powerpc: tm: Enable transactional memory (TM) lazily for userspace
    
    Currently the MSR TM bit is always set if the hardware is TM capable.
    This adds extra overhead as it means the TM SPRS (TFHAR, TEXASR and
    TFAIR) must be swapped for each process regardless of if they use TM.
    
    For processes that don't use TM the TM MSR bit can be turned off
    allowing the kernel to avoid the expensive swap of the TM registers.
    
    A TM unavailable exception will occur if a thread does use TM and the
    kernel will enable MSR_TM and leave it so for some time afterwards.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2f5ef5a80353..a1f8f5641e9e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1392,6 +1392,15 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 #ifdef CONFIG_PPC64
 static void tm_unavailable(struct pt_regs *regs)
 {
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+	if (user_mode(regs)) {
+		current->thread.load_tm++;
+		regs->msr |= MSR_TM;
+		tm_enable();
+		tm_restore_sprs(&current->thread);
+		return;
+	}
+#endif
 	pr_emerg("Unrecoverable TM Unavailable Exception "
 			"%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable TM Unavailable Exception", regs, SIGABRT);

commit 172f7aaa75d0eaae167edde25c08aae9059e80fc
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Wed Sep 14 18:02:15 2016 +1000

    powerpc/tm: Add TM Unavailable Exception
    
    If the kernel disables transactional memory (TM) and userspace still
    tries TM related actions (TM instructions or TM SPR accesses) TM aware
    hardware will cause the kernel to take a facility unavailable
    exception.
    
    Add checks for the exception being caused by illegal TM access in
    userspace.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    [mpe: Rewrite comment entirely, bugs in it are mine]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 487e1b442473..2f5ef5a80353 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1390,6 +1390,13 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_PPC64
+static void tm_unavailable(struct pt_regs *regs)
+{
+	pr_emerg("Unrecoverable TM Unavailable Exception "
+			"%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable TM Unavailable Exception", regs, SIGABRT);
+}
+
 void facility_unavailable_exception(struct pt_regs *regs)
 {
 	static char *facility_strings[] = {
@@ -1469,6 +1476,27 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		return;
 	}
 
+	if (status == FSCR_TM_LG) {
+		/*
+		 * If we're here then the hardware is TM aware because it
+		 * generated an exception with FSRM_TM set.
+		 *
+		 * If cpu_has_feature(CPU_FTR_TM) is false, then either firmware
+		 * told us not to do TM, or the kernel is not built with TM
+		 * support.
+		 *
+		 * If both of those things are true, then userspace can spam the
+		 * console by triggering the printk() below just by continually
+		 * doing tbegin (or any TM instruction). So in that case just
+		 * send the process a SIGILL immediately.
+		 */
+		if (!cpu_has_feature(CPU_FTR_TM))
+			goto out;
+
+		tm_unavailable(regs);
+		return;
+	}
+
 	if ((status < ARRAY_SIZE(facility_strings)) &&
 	    facility_strings[status])
 		facility = facility_strings[status];
@@ -1481,6 +1509,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		"%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
 		hv ? "Hypervisor " : "", facility, regs->nip, regs->msr);
 
+out:
 	if (user_mode(regs)) {
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;

commit dc3106690b20305c3df06b42456fe386dd632ac9
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Fri Sep 23 16:18:24 2016 +1000

    powerpc: tm: Always use fp_state and vr_state to store live registers
    
    There is currently an inconsistency as to how the entire CPU register
    state is saved and restored when a thread uses transactional memory
    (TM).
    
    Using transactional memory results in the CPU having duplicated
    (almost) all of its register state. This duplication results in a set
    of registers which can be considered 'live', those being currently
    modified by the instructions being executed and another set that is
    frozen at a point in time.
    
    On context switch, both sets of state have to be saved and (later)
    restored. These two states are often called a variety of different
    things. Common terms for the state which only exists after the CPU has
    entered a transaction (performed a TBEGIN instruction) in hardware are
    'transactional' or 'speculative'.
    
    Between a TBEGIN and a TEND or TABORT (or an event that causes the
    hardware to abort), regardless of the use of TSUSPEND the
    transactional state can be referred to as the live state.
    
    The second state is often to referred to as the 'checkpointed' state
    and is a duplication of the live state when the TBEGIN instruction is
    executed. This state is kept in the hardware and will be rolled back
    to on transaction failure.
    
    Currently all the registers stored in pt_regs are ALWAYS the live
    registers, that is, when a thread has transactional registers their
    values are stored in pt_regs and the checkpointed state is in
    ckpt_regs. A strange opposite is true for fp_state/vr_state. When a
    thread is non transactional fp_state/vr_state holds the live
    registers. When a thread has initiated a transaction fp_state/vr_state
    holds the checkpointed state and transact_fp/transact_vr become the
    structure which holds the live state (at this point it is a
    transactional state).
    
    This method creates confusion as to where the live state is, in some
    circumstances it requires extra work to determine where to put the
    live state and prevents the use of common functions designed (probably
    before TM) to save the live state.
    
    With this patch pt_regs, fp_state and vr_state all represent the
    same thing and the other structures [pending rename] are for
    checkpointed state.
    
    Acked-by: Simon Guo <wei.guo.simon@gmail.com>
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6b108ed29c20..487e1b442473 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1522,7 +1522,8 @@ void fp_unavailable_tm(struct pt_regs *regs)
 
 	/* If VMX is in use, get the transactional values back */
 	if (regs->msr & MSR_VEC) {
-		do_load_up_transact_altivec(&current->thread);
+		msr_check_and_set(MSR_VEC);
+		load_vr_state(&current->thread.vr_state);
 		/* At this point all the VSX state is loaded, so enable it */
 		regs->msr |= MSR_VSX;
 	}
@@ -1543,7 +1544,8 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 	current->thread.used_vr = 1;
 
 	if (regs->msr & MSR_FP) {
-		do_load_up_transact_fpu(&current->thread);
+		msr_check_and_set(MSR_FP);
+		load_fp_state(&current->thread.fp_state);
 		regs->msr |= MSR_VSX;
 	}
 }
@@ -1582,10 +1584,12 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 	 */
 	tm_recheckpoint(&current->thread, regs->msr & ~orig_msr);
 
+	msr_check_and_set(orig_msr & (MSR_FP | MSR_VEC));
+
 	if (orig_msr & MSR_FP)
-		do_load_up_transact_fpu(&current->thread);
+		load_fp_state(&current->thread.fp_state);
 	if (orig_msr & MSR_VEC)
-		do_load_up_transact_altivec(&current->thread);
+		load_vr_state(&current->thread.vr_state);
 }
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 

commit e627f8dc9a6fb8c9fff371ab99cc36b4f4116433
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Sep 16 10:23:11 2016 +0200

    powerpc/8xx: add dedicated machine check handler
    
    During a machine check, the 8xx provides indication of
    whether the check is due to data or instruction access, so
    let's display it.
    
    Lets also move 8xx specific handling into the new handler.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 137b1371cce8..e493062937b0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -667,6 +667,31 @@ int machine_check_e200(struct pt_regs *regs)
 
 	return 0;
 }
+#elif defined(CONFIG_PPC_8xx)
+int machine_check_8xx(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+
+	pr_err("Machine check in kernel mode.\n");
+	pr_err("Caused by (from SRR1=%lx): ", reason);
+	if (reason & 0x40000000)
+		pr_err("Fetch error at address %lx\n", regs->nip);
+	else
+		pr_err("Data access error at address %lx\n", regs->dar);
+
+#ifdef CONFIG_PCI
+	/* the qspan pci read routines can cause machine checks -- Cort
+	 *
+	 * yuck !!! that totally needs to go away ! There are better ways
+	 * to deal with that than having a wart in the mcheck handler.
+	 * -- BenH
+	 */
+	bad_page_fault(regs, regs->dar, SIGBUS);
+	return 1;
+#else
+	return 0;
+#endif
+}
 #else
 int machine_check_generic(struct pt_regs *regs)
 {
@@ -726,17 +751,6 @@ void machine_check_exception(struct pt_regs *regs)
 	if (recover > 0)
 		goto bail;
 
-#if defined(CONFIG_8xx) && defined(CONFIG_PCI)
-	/* the qspan pci read routines can cause machine checks -- Cort
-	 *
-	 * yuck !!! that totally needs to go away ! There are better ways
-	 * to deal with that than having a wart in the mcheck handler.
-	 * -- BenH
-	 */
-	bad_page_fault(regs, regs->dar, SIGBUS);
-	goto bail;
-#endif
-
 	if (debugger_fault_handler(regs))
 		goto bail;
 

commit f307939fb260c83e6875476695ac58a669348b8f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Sep 5 08:42:31 2016 +0200

    powerpc/8xx: add system_reset_exception
    
    When the watchdog is in NMI mode, the system reset interrupt is
    generated when the watchdog counter expires.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 68f8b5b0d885..137b1371cce8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -273,7 +273,6 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	force_sig_info(signr, &info, current);
 }
 
-#ifdef CONFIG_PPC64
 void system_reset_exception(struct pt_regs *regs)
 {
 	/* See if any machine dependent calls */
@@ -291,6 +290,7 @@ void system_reset_exception(struct pt_regs *regs)
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
 
+#ifdef CONFIG_PPC64
 /*
  * This function is called in real mode. Strictly no printk's please.
  *

commit ddc6cd0d70a6f958b2c01758ee53279d36db2234
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue May 17 14:01:39 2016 +0200

    powerpc32: Use instruction symbolic names in check_io_access()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6b108ed29c20..68f8b5b0d885 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -352,12 +352,11 @@ static inline int check_io_access(struct pt_regs *regs)
 		 * For the debug message, we look at the preceding
 		 * load or store.
 		 */
-		if (*nip == 0x60000000)		/* nop */
+		if (*nip == PPC_INST_NOP)
 			nip -= 2;
-		else if (*nip == 0x4c00012c)	/* isync */
+		else if (*nip == PPC_INST_ISYNC)
 			--nip;
-		if (*nip == 0x7c0004ac || (*nip >> 26) == 3) {
-			/* sync or twi */
+		if (*nip == PPC_INST_SYNC || (*nip >> 26) == OP_TRAP) {
 			unsigned int rb;
 
 			--nip;

commit 03465f899bdac70d34f6ca447a74d8ae9e284ce5
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Sep 16 20:48:08 2016 +1000

    powerpc: Use kprobe blacklist for exception handlers
    
    Currently we mark the C implementations of some exception handlers as
    __kprobes. This has the effect of putting them in the ".kprobes.text"
    section, which separates them from the rest of the text.
    
    Instead we can use the blacklist macros to add the symbols to a
    blacklist which kprobes will check. This allows the linker to move
    exception handler functions close to callers and avoids trampolines in
    larger kernels.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Reword change log a bit]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0bab80e64ff9..6b108ed29c20 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -117,7 +117,7 @@ static int die_owner = -1;
 static unsigned int die_nest_count;
 static int die_counter;
 
-static unsigned __kprobes long oops_begin(struct pt_regs *regs)
+static unsigned long oops_begin(struct pt_regs *regs)
 {
 	int cpu;
 	unsigned long flags;
@@ -144,8 +144,9 @@ static unsigned __kprobes long oops_begin(struct pt_regs *regs)
 		pmac_backlight_unblank();
 	return flags;
 }
+NOKPROBE_SYMBOL(oops_begin);
 
-static void __kprobes oops_end(unsigned long flags, struct pt_regs *regs,
+static void oops_end(unsigned long flags, struct pt_regs *regs,
 			       int signr)
 {
 	bust_spinlocks(0);
@@ -196,8 +197,9 @@ static void __kprobes oops_end(unsigned long flags, struct pt_regs *regs,
 		panic("Fatal exception");
 	do_exit(signr);
 }
+NOKPROBE_SYMBOL(oops_end);
 
-static int __kprobes __die(const char *str, struct pt_regs *regs, long err)
+static int __die(const char *str, struct pt_regs *regs, long err)
 {
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT
@@ -221,6 +223,7 @@ static int __kprobes __die(const char *str, struct pt_regs *regs, long err)
 
 	return 0;
 }
+NOKPROBE_SYMBOL(__die);
 
 void die(const char *str, struct pt_regs *regs, long err)
 {
@@ -802,7 +805,7 @@ void RunModeException(struct pt_regs *regs)
 	_exception(SIGTRAP, regs, 0, 0);
 }
 
-void __kprobes single_step_exception(struct pt_regs *regs)
+void single_step_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
 
@@ -819,6 +822,7 @@ void __kprobes single_step_exception(struct pt_regs *regs)
 bail:
 	exception_exit(prev_state);
 }
+NOKPROBE_SYMBOL(single_step_exception);
 
 /*
  * After we have successfully emulated an instruction, we have to
@@ -1140,7 +1144,7 @@ static int emulate_math(struct pt_regs *regs)
 static inline int emulate_math(struct pt_regs *regs) { return -1; }
 #endif
 
-void __kprobes program_check_exception(struct pt_regs *regs)
+void program_check_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
 	unsigned int reason = get_reason(regs);
@@ -1260,16 +1264,18 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 bail:
 	exception_exit(prev_state);
 }
+NOKPROBE_SYMBOL(program_check_exception);
 
 /*
  * This occurs when running in hypervisor mode on POWER6 or later
  * and an illegal instruction is encountered.
  */
-void __kprobes emulation_assist_interrupt(struct pt_regs *regs)
+void emulation_assist_interrupt(struct pt_regs *regs)
 {
 	regs->msr |= REASON_ILLEGAL;
 	program_check_exception(regs);
 }
+NOKPROBE_SYMBOL(emulation_assist_interrupt);
 
 void alignment_exception(struct pt_regs *regs)
 {
@@ -1668,7 +1674,7 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 		mtspr(SPRN_DBCR0, current->thread.debug.dbcr0);
 }
 
-void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+void DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
 	current->thread.debug.dbsr = debug_status;
 
@@ -1729,6 +1735,7 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 	} else
 		handle_debug(regs, debug_status);
 }
+NOKPROBE_SYMBOL(DebugException);
 #endif /* CONFIG_PPC_ADV_DEBUG_REGS */
 
 #if !defined(CONFIG_TAU_INT)

commit f0f558b131db0e793fd90aac5d93f694362973d2
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Fri Sep 2 21:49:21 2016 +1000

    powerpc/mm: Preserve CFAR value on SLB miss caused by access to bogus address
    
    Currently, if userspace or the kernel accesses a completely bogus address,
    for example with any of bits 46-59 set, we first take an SLB miss interrupt,
    install a corresponding SLB entry with VSID 0, retry the instruction, then
    take a DSI/ISI interrupt because there is no HPT entry mapping the address.
    However, by the time of the second interrupt, the Come-From Address Register
    (CFAR) has been overwritten by the rfid instruction at the end of the SLB
    miss interrupt handler.  Since bogus accesses can often be caused by a
    function return after the stack has been overwritten, the CFAR value would
    be very useful as it could indicate which function it was whose return had
    led to the bogus address.
    
    This patch adds code to create a full exception frame in the SLB miss handler
    in the case of a bogus address, rather than inserting an SLB entry with a
    zero VSID field.  Then we call a new slb_miss_bad_addr() function in C code,
    which delivers a signal for a user access or creates an oops for a kernel
    access.  In the latter case the oops message will show the CFAR value at the
    time of the access.
    
    In the case of the radix MMU, a segment miss interrupt indicates an access
    outside the ranges mapped by the page tables.  Previously this was handled
    by the code for an unrecoverable SLB miss (one with MSR[RI] = 0), which is
    not really correct.  With this patch, we now handle these interrupts with
    slb_miss_bad_addr(), which is much more consistent.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 62859ebe0062..0bab80e64ff9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1310,6 +1310,18 @@ void alignment_exception(struct pt_regs *regs)
 	exception_exit(prev_state);
 }
 
+void slb_miss_bad_addr(struct pt_regs *regs)
+{
+	enum ctx_state prev_state = exception_enter();
+
+	if (user_mode(regs))
+		_exception(SIGSEGV, regs, SEGV_BNDERR, regs->dar);
+	else
+		bad_page_fault(regs, regs->dar, SIGSEGV);
+
+	exception_exit(prev_state);
+}
+
 void StackOverflow(struct pt_regs *regs)
 {
 	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",

commit 8a39b05f086904c3b2e04e4db3d81f30c0eae6ae
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Aug 16 10:57:34 2016 -0400

    powerpc: migrate exception table users off module.h and onto extable.h
    
    These files were only including module.h for exception table
    related functions.  We've now separated that content out into its
    own file "extable.h" so now move over to that and avoid all the
    extra header content in module.h that we don't really need to compile
    these files.
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2cb589264cb7..62859ebe0062 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -25,7 +25,8 @@
 #include <linux/user.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
-#include <linux/module.h>
+#include <linux/extable.h>
+#include <linux/module.h>	/* print_modules */
 #include <linux/prctl.h>
 #include <linux/delay.h>
 #include <linux/kprobes.h>

commit 221bb8a46e230b9824204ae86537183d9991ff2a
Merge: f7b32e4c021f 23528bb21ee2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 2 16:11:27 2016 -0400

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
    
     - ARM: GICv3 ITS emulation and various fixes.  Removal of the
       old VGIC implementation.
    
     - s390: support for trapping software breakpoints, nested
       virtualization (vSIE), the STHYI opcode, initial extensions
       for CPU model support.
    
     - MIPS: support for MIPS64 hosts (32-bit guests only) and lots
       of cleanups, preliminary to this and the upcoming support for
       hardware virtualization extensions.
    
     - x86: support for execute-only mappings in nested EPT; reduced
       vmexit latency for TSC deadline timer (by about 30%) on Intel
       hosts; support for more than 255 vCPUs.
    
     - PPC: bugfixes.
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (302 commits)
      KVM: PPC: Introduce KVM_CAP_PPC_HTM
      MIPS: Select HAVE_KVM for MIPS64_R{2,6}
      MIPS: KVM: Reset CP0_PageMask during host TLB flush
      MIPS: KVM: Fix ptr->int cast via KVM_GUEST_KSEGX()
      MIPS: KVM: Sign extend MFC0/RDHWR results
      MIPS: KVM: Fix 64-bit big endian dynamic translation
      MIPS: KVM: Fail if ebase doesn't fit in CP0_EBase
      MIPS: KVM: Use 64-bit CP0_EBase when appropriate
      MIPS: KVM: Set CP0_Status.KX on MIPS64
      MIPS: KVM: Make entry code MIPS64 friendly
      MIPS: KVM: Use kmap instead of CKSEG0ADDR()
      MIPS: KVM: Use virt_to_phys() to get commpage PFN
      MIPS: Fix definition of KSEGX() for 64-bit
      KVM: VMX: Add VMCS to CPU's loaded VMCSs before VMPTRLD
      kvm: x86: nVMX: maintain internal copy of current VMCS
      KVM: PPC: Book3S HV: Save/restore TM state in H_CEDE
      KVM: PPC: Book3S HV: Pull out TM state save/restore into separate procedures
      KVM: arm64: vgic-its: Simplify MAPI error handling
      KVM: arm64: vgic-its: Make vgic_its_cmd_handle_mapi similar to other handlers
      KVM: arm64: vgic-its: Turn device_id validation into generic ID validation
      ...

commit bd3ea317fddfd0f2044f94bed294b90c4bc8e69e
Author: Jack Miller <jack@codezen.org>
Date:   Thu Jun 9 12:31:09 2016 +1000

    powerpc: Load Monitor Register Support
    
    This enables new registers, LMRR and LMSER, that can trigger an EBB in
    userspace code when a monitored load (via the new ldmx instruction)
    loads memory from a monitored space. This facility is controlled by a
    new FSCR bit, LM.
    
    This patch disables the FSCR LM control bit on task init and enables
    that bit when a load monitor facility unavailable exception is taken
    for using it. On context switch, this bit is then used to determine
    whether the two relevant registers are saved and restored. This is
    done lazily for performance reasons.
    
    Signed-off-by: Jack Miller <jack@codezen.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d2518c3cbf04..f7e2f2e318bd 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1377,6 +1377,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		[FSCR_TM_LG] = "TM",
 		[FSCR_EBB_LG] = "EBB",
 		[FSCR_TAR_LG] = "TAR",
+		[FSCR_LM_LG] = "LM",
 	};
 	char *facility = "unknown";
 	u64 value;
@@ -1434,6 +1435,14 @@ void facility_unavailable_exception(struct pt_regs *regs)
 			emulate_single_step(regs);
 		}
 		return;
+	} else if ((status == FSCR_LM_LG) && cpu_has_feature(CPU_FTR_ARCH_300)) {
+		/*
+		 * This process has touched LM, so turn it on forever
+		 * for this process
+		 */
+		current->thread.fscr |= FSCR_LM;
+		mtspr(SPRN_FSCR, current->thread.fscr);
+		return;
 	}
 
 	if ((status < ARRAY_SIZE(facility_strings)) &&

commit b57bd2de8c6c9aa03f1b899edd6f5582cc8b5b08
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Jun 9 12:31:08 2016 +1000

    powerpc: Improve FSCR init and context switching
    
    This fixes a few issues with FSCR init and switching.
    
    In commit 152d523e6307 ("powerpc: Create context switch helpers
    save_sprs() and restore_sprs()") we moved the setting of the FSCR
    register from inside an CPU_FTR_ARCH_207S section to inside just a
    CPU_FTR_ARCH_DSCR section. Hence we are setting FSCR on POWER6/7 where
    the FSCR doesn't exist. This is harmless but we shouldn't do it.
    
    Also, we can simplify the FSCR context switch. We don't need to go
    through the calculation involving dscr_inherit. We can just restore
    what we saved last time.
    
    We also set an initial value in INIT_THREAD, so that pid 1 which is
    cloned from that gets a sane value.
    
    Based on patch by Jack Miller.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 11d15e7270e0..d2518c3cbf04 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1419,7 +1419,8 @@ void facility_unavailable_exception(struct pt_regs *regs)
 			rd = (instword >> 21) & 0x1f;
 			current->thread.dscr = regs->gpr[rd];
 			current->thread.dscr_inherit = 1;
-			mtspr(SPRN_FSCR, value | FSCR_DSCR);
+			current->thread.fscr |= FSCR_DSCR;
+			mtspr(SPRN_FSCR, current->thread.fscr);
 		}
 
 		/* Read from DSCR (mfspr RT, 0x03) */

commit fd7bacbca47a86a6f418440d8a5d7b7edbb2f8f9
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Sun May 15 09:44:26 2016 +0530

    KVM: PPC: Book3S HV: Fix TB corruption in guest exit path on HMI interrupt
    
    When a guest is assigned to a core it converts the host Timebase (TB)
    into guest TB by adding guest timebase offset before entering into
    guest. During guest exit it restores the guest TB to host TB. This means
    under certain conditions (Guest migration) host TB and guest TB can differ.
    
    When we get an HMI for TB related issues the opal HMI handler would
    try fixing errors and restore the correct host TB value. With no guest
    running, we don't have any issues. But with guest running on the core
    we run into TB corruption issues.
    
    If we get an HMI while in the guest, the current HMI handler invokes opal
    hmi handler before forcing guest to exit. The guest exit path subtracts
    the guest TB offset from the current TB value which may have already
    been restored with host value by opal hmi handler. This leads to incorrect
    host and guest TB values.
    
    With split-core, things become more complex. With split-core, TB also gets
    split and each subcore gets its own TB register. When a hmi handler fixes
    a TB error and restores the TB value, it affects all the TB values of
    sibling subcores on the same core. On TB errors all the thread in the core
    gets HMI. With existing code, the individual threads call opal hmi handle
    independently which can easily throw TB out of sync if we have guest
    running on subcores. Hence we will need to co-ordinate with all the
    threads before making opal hmi handler call followed by TB resync.
    
    This patch introduces a sibling subcore state structure (shared by all
    threads in the core) in paca which holds information about whether sibling
    subcores are in Guest mode or host mode. An array in_guest[] of size
    MAX_SUBCORE_PER_CORE=4 is used to maintain the state of each subcore.
    The subcore id is used as index into in_guest[] array. Only primary
    thread entering/exiting the guest is responsible to set/unset its
    designated array element.
    
    On TB error, we get HMI interrupt on every thread on the core. Upon HMI,
    this patch will now force guest to vacate the core/subcore. Primary
    thread from each subcore will then turn off its respective bit
    from the above bitmap during the guest exit path just after the
    guest->host partition switch is complete.
    
    All other threads that have just exited the guest OR were already in host
    will wait until all other subcores clears their respective bit.
    Once all the subcores turn off their respective bit, all threads will
    will make call to opal hmi handler.
    
    It is not necessary that opal hmi handler would resync the TB value for
    every HMI interrupts. It would do so only for the HMI caused due to
    TB errors. For rest, it would not touch TB value. Hence to make things
    simpler, primary thread would call TB resync explicitly once for each
    core immediately after opal hmi handler instead of subtracting guest
    offset from TB. TB resync call will restore the TB with host value.
    Thus we can be sure about the TB state.
    
    One of the primary threads exiting the guest will take up the
    responsibility of calling TB resync. It will use one of the top bits
    (bit 63) from subcore state flags bitmap to make the decision. The first
    primary thread (among the subcores) that is able to set the bit will
    have to call the TB resync. Rest all other threads will wait until TB
    resync is complete.  Once TB resync is complete all threads will then
    proceed.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9229ba63c370..9ec95daccad9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -60,6 +60,7 @@
 #include <asm/switch_to.h>
 #include <asm/tm.h>
 #include <asm/debug.h>
+#include <asm/hmi.h>
 #include <sysdev/fsl_pci.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
@@ -307,9 +308,13 @@ long hmi_exception_realmode(struct pt_regs *regs)
 {
 	__this_cpu_inc(irq_stat.hmi_exceptions);
 
+	wait_for_subcore_guest_exit();
+
 	if (ppc_md.hmi_exception_early)
 		ppc_md.hmi_exception_early(regs);
 
+	wait_for_tb_resync();
+
 	return 0;
 }
 

commit 42f5b4cacd783faf05e3ff8bf85e8be31f3dfa9d
Author: Daniel Axtens <dja@axtens.net>
Date:   Wed May 18 11:16:50 2016 +1000

    powerpc: Introduce asm-prototypes.h
    
    Sparse picked up a number of functions that are implemented in C and
    then only referred to in asm code.
    
    This introduces asm-prototypes.h, which provides a place for
    prototypes of these functions.
    
    This silences some sparse warnings.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    [mpe: Add include guards, clean up copyright & GPL text]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9229ba63c370..11d15e7270e0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -60,6 +60,7 @@
 #include <asm/switch_to.h>
 #include <asm/tm.h>
 #include <asm/debug.h>
+#include <asm/asm-prototypes.h>
 #include <sysdev/fsl_pci.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)

commit d5e2d00898bdfed9586472679760fc81a2ca2d02
Merge: 31e182363b39 6e669f085d59
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 19 15:38:41 2016 -0700

    Merge tag 'powerpc-4.6-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "This was delayed a day or two by some build-breakage on old toolchains
      which we've now fixed.
    
      There's two PCI commits both acked by Bjorn.
    
      There's one commit to mm/hugepage.c which is (co)authored by Kirill.
    
      Highlights:
       - Restructure Linux PTE on Book3S/64 to Radix format from Paul
         Mackerras
       - Book3s 64 MMU cleanup in preparation for Radix MMU from Aneesh
         Kumar K.V
       - Add POWER9 cputable entry from Michael Neuling
       - FPU/Altivec/VSX save/restore optimisations from Cyril Bur
       - Add support for new ftrace ABI on ppc64le from Torsten Duwe
    
      Various cleanups & minor fixes from:
       - Adam Buchbinder, Andrew Donnellan, Balbir Singh, Christophe Leroy,
         Cyril Bur, Luis Henriques, Madhavan Srinivasan, Pan Xinhui, Russell
         Currey, Sukadev Bhattiprolu, Suraj Jitindar Singh.
    
      General:
       - atomics: Allow architectures to define their own __atomic_op_*
         helpers from Boqun Feng
       - Implement atomic{, 64}_*_return_* variants and acquire/release/
         relaxed variants for (cmp)xchg from Boqun Feng
       - Add powernv_defconfig from Jeremy Kerr
       - Fix BUG_ON() reporting in real mode from Balbir Singh
       - Add xmon command to dump OPAL msglog from Andrew Donnellan
       - Add xmon command to dump process/task similar to ps(1) from Douglas
         Miller
       - Clean up memory hotplug failure paths from David Gibson
    
      pci/eeh:
       - Redesign SR-IOV on PowerNV to give absolute isolation between VFs
         from Wei Yang.
       - EEH Support for SRIOV VFs from Wei Yang and Gavin Shan.
       - PCI/IOV: Rename and export virtfn_{add, remove} from Wei Yang
       - PCI: Add pcibios_bus_add_device() weak function from Wei Yang
       - MAINTAINERS: Update EEH details and maintainership from Russell
         Currey
    
      cxl:
       - Support added to the CXL driver for running on both bare-metal and
         hypervisor systems, from Christophe Lombard and Frederic Barrat.
       - Ignore probes for virtual afu pci devices from Vaibhav Jain
    
      perf:
       - Export Power8 generic and cache events to sysfs from Sukadev
         Bhattiprolu
       - hv-24x7: Fix usage with chip events, display change in counter
         values, display domain indices in sysfs, eliminate domain suffix in
         event names, from Sukadev Bhattiprolu
    
      Freescale:
       - Updates from Scott: "Highlights include 8xx optimizations, 32-bit
         checksum optimizations, 86xx consolidation, e5500/e6500 cpu
         hotplug, more fman and other dt bits, and minor fixes/cleanup"
    
    * tag 'powerpc-4.6-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (179 commits)
      powerpc: Fix unrecoverable SLB miss during restore_math()
      powerpc/8xx: Fix do_mtspr_cpu6() build on older compilers
      powerpc/rcpm: Fix build break when SMP=n
      powerpc/book3e-64: Use hardcoded mttmr opcode
      powerpc/fsl/dts: Add "jedec,spi-nor" flash compatible
      powerpc/T104xRDB: add tdm riser card node to device tree
      powerpc32: PAGE_EXEC required for inittext
      powerpc/mpc85xx: Add pcsphy nodes to FManV3 device tree
      powerpc/mpc85xx: Add MDIO bus muxing support to the board device tree(s)
      powerpc/86xx: Introduce and use common dtsi
      powerpc/86xx: Update device tree
      powerpc/86xx: Move dts files to fsl directory
      powerpc/86xx: Switch to kconfig fragments approach
      powerpc/86xx: Update defconfigs
      powerpc/86xx: Consolidate common platform code
      powerpc32: Remove one insn in mulhdu
      powerpc32: small optimisation in flush_icache_range()
      powerpc: Simplify test in __dma_sync()
      powerpc32: move xxxxx_dcache_range() functions inline
      powerpc32: Remove clear_pages() and define clear_page() inline
      ...

commit e7df0d88c455c915376397b4bd72a83b9ed656f7
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Thu Mar 17 14:17:59 2016 -0700

    powerpc: query dynamic DEBUG_PAGEALLOC setting
    
    We can disable debug_pagealloc processing even if the code is compiled
    with CONFIG_DEBUG_PAGEALLOC.  This patch changes the code to query
    whether it is enabled or not in runtime.
    
    Signed-off-by: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christoph Lameter <cl@linux.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b6becc795bb5..33c47fcc455a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -203,9 +203,8 @@ static int __kprobes __die(const char *str, struct pt_regs *regs, long err)
 #ifdef CONFIG_SMP
 	printk("SMP NR_CPUS=%d ", NR_CPUS);
 #endif
-#ifdef CONFIG_DEBUG_PAGEALLOC
-	printk("DEBUG_PAGEALLOC ");
-#endif
+	if (debug_pagealloc_enabled())
+		printk("DEBUG_PAGEALLOC ");
 #ifdef CONFIG_NUMA
 	printk("NUMA ");
 #endif

commit 446957ba5127141ee007fc61509e24a9e60853d9
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Wed Feb 24 10:51:11 2016 -0800

    powerpc: Fix misspellings in comments.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4e5c11d4d19d..88414dde7e35 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1402,7 +1402,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		 * is a read DSCR attempt through a mfspr instruction, we
 		 * just emulate the instruction instead. This code path will
 		 * always emulate all the mfspr instructions till the user
-		 * has attempted atleast one mtspr instruction. This way it
+		 * has attempted at least one mtspr instruction. This way it
 		 * preserves the same behaviour when the user is accessing
 		 * the DSCR through privilege level only SPR number (0x11)
 		 * which is emulated through illegal instruction exception.

commit a4c3f909b4d9bb9430bf42ad583661df6dfa86c6
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Thu Feb 18 13:48:01 2016 +1100

    powerpc: Fix BUG_ON() reporting in real mode
    
    I ran into this issue while debugging an early boot problem. The system
    hit a BUG_ON() but report bug failed to print the line number and file
    name. The reason being that the system was running in real mode and
    report_bug() searches for addresses in the PAGE_OFFSET+ region.
    
    Suggested-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b6becc795bb5..4e5c11d4d19d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1148,6 +1148,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		goto bail;
 	}
 	if (reason & REASON_TRAP) {
+		unsigned long bugaddr;
 		/* Debugger is first in line to stop recursive faults in
 		 * rcu_lock, notify_die, or atomic_notifier_call_chain */
 		if (debugger_bpt(regs))
@@ -1158,8 +1159,15 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 				== NOTIFY_STOP)
 			goto bail;
 
+		bugaddr = regs->nip;
+		/*
+		 * Fixup bugaddr for BUG_ON() in real mode
+		 */
+		if (!is_kernel_addr(bugaddr) && !(regs->msr & MSR_IR))
+			bugaddr += PAGE_OFFSET;
+
 		if (!(regs->msr & MSR_PR) &&  /* not user-mode */
-		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
+		    report_bug(bugaddr, regs) == BUG_TRAP_TYPE_WARN) {
 			regs->nip += 4;
 			goto bail;
 		}

commit cdfc8ed6904d7b0c0ca23d619b387b32070703b1
Author: Rashmica Gupta <rashmicy@gmail.com>
Date:   Thu Nov 19 14:26:28 2015 +1100

    powerpc: Remove unused function trace_syscall()
    
    This function has been unused since commit 14cf11af6cf6 ("powerpc: Merge enough
    to start building in arch/powerpc."), so remove it.
    
    Signed-off-by: Rashmica Gupta <rashmicy@gmail.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Reviewed-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 37de90f8a845..b6becc795bb5 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1313,13 +1313,6 @@ void nonrecoverable_exception(struct pt_regs *regs)
 	die("nonrecoverable exception", regs, SIGKILL);
 }
 
-void trace_syscall(struct pt_regs *regs)
-{
-	printk("Task: %p(%d), PC: %08lX/%08lX, Syscall: %3ld, Result: %s%ld    %s\n",
-	       current, task_pid_nr(current), regs->nip, regs->link, regs->gpr[0],
-	       regs->ccr&0x10000000?"Error=":"", regs->gpr[3], print_tainted());
-}
-
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();

commit 27ea2c420cad57386c25668cb9a9f0f082635586
Author: Daniel Axtens <dja@axtens.net>
Date:   Mon Jun 15 13:25:19 2015 +1000

    powerpc: Set the correct kernel taint on machine check errors.
    
    This means the 'M' flag will work properly when the kernel prints a backtrace.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6530f1b8874d..37de90f8a845 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -297,6 +297,8 @@ long machine_check_early(struct pt_regs *regs)
 
 	__this_cpu_inc(irq_stat.mce_exceptions);
 
+	add_taint(TAINT_MACHINE_CHECK, LOCKDEP_NOW_UNRELIABLE);
+
 	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
 		handled = cur_cpu_spec->machine_check_early(regs);
 	return handled;

commit c952c1c48233b95f838c8743f09feace1f0e6cab
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Thu May 21 12:13:01 2015 +0530

    powerpc: Fix handling of DSCR related facility unavailable exception
    
    Currently DSCR (Data Stream Control Register) can be accessed with
    mfspr or mtspr instructions inside a thread via two different SPR
    numbers. One being the user accessible problem state SPR number 0x03
    and the other being the privilege state SPR number 0x11. All access
    through the privilege state SPR number get emulated through illegal
    instruction exception. Any access through the problem state SPR number
    raises one facility unavailable exception which sets the thread based
    dscr_inherit bit and enables DSCR facility through FSCR register thus
    allowing direct access to DSCR without going through this exception in
    the future. We set the thread.dscr_inherit bit whether the access was
    with mfspr or mtspr instruction which is neither correct nor does it
    match the behaviour through the instruction emulation code path driven
    from privilege state SPR number. User currently observes two different
    kind of behaviour when accessing the DSCR through these two SPR numbers.
    This problem can be observed through these two test cases by replacing
    the privilege state SPR number with the problem state SPR number.
    
            (1) http://ozlabs.org/~anton/junkcode/dscr_default_test.c
            (2) http://ozlabs.org/~anton/junkcode/dscr_explicit_test.c
    
    This patch fixes the problem by making sure that the behaviour visible
    to the user remains the same irrespective of which SPR number is being
    used. Inside facility unavailable exception, we check whether it was
    cuased by a mfspr or a mtspr isntrucction. In case of mfspr instruction,
    just emulate the instruction. In case of mtspr instruction, set the
    thread based dscr_inherit bit and also enable the facility through FSCR.
    All user SPR based mfspr instruction will be emulated till one user SPR
    based mtspr has been executed.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 19e4744b6eba..6530f1b8874d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1377,6 +1377,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	};
 	char *facility = "unknown";
 	u64 value;
+	u32 instword, rd;
 	u8 status;
 	bool hv;
 
@@ -1388,12 +1389,46 @@ void facility_unavailable_exception(struct pt_regs *regs)
 
 	status = value >> 56;
 	if (status == FSCR_DSCR_LG) {
-		/* User is acessing the DSCR.  Set the inherit bit and allow
-		 * the user to set it directly in future by setting via the
-		 * FSCR DSCR bit.  We always leave HFSCR DSCR set.
+		/*
+		 * User is accessing the DSCR register using the problem
+		 * state only SPR number (0x03) either through a mfspr or
+		 * a mtspr instruction. If it is a write attempt through
+		 * a mtspr, then we set the inherit bit. This also allows
+		 * the user to write or read the register directly in the
+		 * future by setting via the FSCR DSCR bit. But in case it
+		 * is a read DSCR attempt through a mfspr instruction, we
+		 * just emulate the instruction instead. This code path will
+		 * always emulate all the mfspr instructions till the user
+		 * has attempted atleast one mtspr instruction. This way it
+		 * preserves the same behaviour when the user is accessing
+		 * the DSCR through privilege level only SPR number (0x11)
+		 * which is emulated through illegal instruction exception.
+		 * We always leave HFSCR DSCR set.
 		 */
-		current->thread.dscr_inherit = 1;
-		mtspr(SPRN_FSCR, value | FSCR_DSCR);
+		if (get_user(instword, (u32 __user *)(regs->nip))) {
+			pr_err("Failed to fetch the user instruction\n");
+			return;
+		}
+
+		/* Write into DSCR (mtspr 0x03, RS) */
+		if ((instword & PPC_INST_MTSPR_DSCR_USER_MASK)
+				== PPC_INST_MTSPR_DSCR_USER) {
+			rd = (instword >> 21) & 0x1f;
+			current->thread.dscr = regs->gpr[rd];
+			current->thread.dscr_inherit = 1;
+			mtspr(SPRN_FSCR, value | FSCR_DSCR);
+		}
+
+		/* Read from DSCR (mfspr RT, 0x03) */
+		if ((instword & PPC_INST_MFSPR_DSCR_USER_MASK)
+				== PPC_INST_MFSPR_DSCR_USER) {
+			if (emulate_instruction(regs)) {
+				pr_err("DSCR based mfspr emulation failed\n");
+				return;
+			}
+			regs->nip += 4;
+			emulate_single_step(regs);
+		}
 		return;
 	}
 

commit 8aa989b8fba1428b50a1be771c01285f1de0227b
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Jan 27 16:48:03 2015 +1100

    powerpc: Remove some unused functions
    
    Remove slice_set_psize() which is not used.
    
    It was added in 3a8247cc2c85 "powerpc: Only demote individual slices
    rather than whole process" but was never used.
    
    Remove vsx_assist_exception() which is not used.
    
    It was added in ce48b2100785 "powerpc: Add VSX context save/restore,
    ptrace and signal support" but was never used.
    
    Remove generic_mach_cpu_die() which is not used.
    
    Its last caller was removed in 375f561a4131 "powerpc/powernv: Always go
    into nap mode when CPU is offline".
    
    Remove mpc7448_hpc2_power_off() and mpc7448_hpc2_halt() which are
    unused.
    
    These were introduced in c5d56332fd6c "[POWERPC] Add general support for
    mpc7448hpc2 (Taiga) platform" but were never used.
    
    This was partially found by using a static code analysis program called
    cppcheck.
    
    Signed-off-by: Rickard Strandqvist <rickard_strandqvist@spectrumdigital.se>
    [mpe: Update changelog with details on when/why they are unused]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e6595b72269b..19e4744b6eba 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1707,21 +1707,6 @@ void altivec_assist_exception(struct pt_regs *regs)
 }
 #endif /* CONFIG_ALTIVEC */
 
-#ifdef CONFIG_VSX
-void vsx_assist_exception(struct pt_regs *regs)
-{
-	if (!user_mode(regs)) {
-		printk(KERN_EMERG "VSX assist exception in kernel mode"
-		       " at %lx\n", regs->nip);
-		die("Kernel VSX assist exception", regs, SIGILL);
-	}
-
-	flush_vsx_to_thread(current);
-	printk(KERN_INFO "VSX assist not supported at %lx\n", regs->nip);
-	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-}
-#endif /* CONFIG_VSX */
-
 #ifdef CONFIG_FSL_BOOKE
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)

commit 69111bac42f5ceacdd22e30947837ceb2c4493ed
Author: Christoph Lameter <cl@linux.com>
Date:   Tue Oct 21 15:23:25 2014 -0500

    powerpc: Replace __get_cpu_var uses
    
    This still has not been merged and now powerpc is the only arch that does
    not have this change. Sorry about missing linuxppc-dev before.
    
    V2->V2
      - Fix up to work against 3.18-rc1
    
    __get_cpu_var() is used for multiple purposes in the kernel source. One of
    them is address calculation via the form &__get_cpu_var(x).  This calculates
    the address for the instance of the percpu variable of the current processor
    based on an offset.
    
    Other use cases are for storing and retrieving data from the current
    processors percpu area.  __get_cpu_var() can be used as an lvalue when
    writing data or on the right side of an assignment.
    
    __get_cpu_var() is defined as :
    
    __get_cpu_var() always only does an address determination. However, store
    and retrieve operations could use a segment prefix (or global register on
    other platforms) to avoid the address calculation.
    
    this_cpu_write() and this_cpu_read() can directly take an offset into a
    percpu area and use optimized assembly code to read and write per cpu
    variables.
    
    This patch converts __get_cpu_var into either an explicit address
    calculation using this_cpu_ptr() or into a use of this_cpu operations that
    use the offset.  Thereby address calculations are avoided and less registers
    are used when code is generated.
    
    At the end of the patch set all uses of __get_cpu_var have been removed so
    the macro is removed too.
    
    The patch set includes passes over all arches as well. Once these operations
    are used throughout then specialized macros can be defined in non -x86
    arches as well in order to optimize per cpu access by f.e.  using a global
    register that may be set to the per cpu base.
    
    Transformations done to __get_cpu_var()
    
    1. Determine the address of the percpu instance of the current processor.
    
            DEFINE_PER_CPU(int, y);
            int *x = &__get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(&y);
    
    2. Same as #1 but this time an array structure is involved.
    
            DEFINE_PER_CPU(int, y[20]);
            int *x = __get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(y);
    
    3. Retrieve the content of the current processors instance of a per cpu
    variable.
    
            DEFINE_PER_CPU(int, y);
            int x = __get_cpu_var(y)
    
       Converts to
    
            int x = __this_cpu_read(y);
    
    4. Retrieve the content of a percpu struct
    
            DEFINE_PER_CPU(struct mystruct, y);
            struct mystruct x = __get_cpu_var(y);
    
       Converts to
    
            memcpy(&x, this_cpu_ptr(&y), sizeof(x));
    
    5. Assignment to a per cpu variable
    
            DEFINE_PER_CPU(int, y)
            __get_cpu_var(y) = x;
    
       Converts to
    
            __this_cpu_write(y, x);
    
    6. Increment/Decrement etc of a per cpu variable
    
            DEFINE_PER_CPU(int, y);
            __get_cpu_var(y)++
    
       Converts to
    
            __this_cpu_inc(y)
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    [mpe: Fix build errors caused by set/or_softirq_pending(), and rework
          assignment in __set_breakpoint() to use memcpy().]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0dc43f9932cf..e6595b72269b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -295,7 +295,7 @@ long machine_check_early(struct pt_regs *regs)
 {
 	long handled = 0;
 
-	__get_cpu_var(irq_stat).mce_exceptions++;
+	__this_cpu_inc(irq_stat.mce_exceptions);
 
 	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
 		handled = cur_cpu_spec->machine_check_early(regs);
@@ -304,7 +304,7 @@ long machine_check_early(struct pt_regs *regs)
 
 long hmi_exception_realmode(struct pt_regs *regs)
 {
-	__get_cpu_var(irq_stat).hmi_exceptions++;
+	__this_cpu_inc(irq_stat.hmi_exceptions);
 
 	if (ppc_md.hmi_exception_early)
 		ppc_md.hmi_exception_early(regs);
@@ -700,7 +700,7 @@ void machine_check_exception(struct pt_regs *regs)
 	enum ctx_state prev_state = exception_enter();
 	int recover = 0;
 
-	__get_cpu_var(irq_stat).mce_exceptions++;
+	__this_cpu_inc(irq_stat.mce_exceptions);
 
 	/* See if any machine dependent calls. In theory, we would want
 	 * to call the CPU first, and call the ppc_md. one if the CPU
@@ -1519,7 +1519,7 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 
 void performance_monitor_exception(struct pt_regs *regs)
 {
-	__get_cpu_var(irq_stat).pmu_irqs++;
+	__this_cpu_inc(irq_stat.pmu_irqs);
 
 	perf_irq(regs);
 }

commit 0869b6fd209bda402576a9a559120ddd4f61198e
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Tue Jul 29 18:40:01 2014 +0530

    powerpc/book3s: Add basic infrastructure to handle HMI in Linux.
    
    Handle Hypervisor Maintenance Interrupt (HMI) in Linux. This patch implements
    basic infrastructure to handle HMI in Linux host. The design is to invoke
    opal handle hmi in real mode for recovery and set irq_pending when we hit HMI.
    During check_irq_replay pull opal hmi event and print hmi info on console.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index cb9cfe448ee8..0dc43f9932cf 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -302,6 +302,16 @@ long machine_check_early(struct pt_regs *regs)
 	return handled;
 }
 
+long hmi_exception_realmode(struct pt_regs *regs)
+{
+	__get_cpu_var(irq_stat).hmi_exceptions++;
+
+	if (ppc_md.hmi_exception_early)
+		ppc_md.hmi_exception_early(regs);
+
+	return 0;
+}
+
 #endif
 
 /*
@@ -738,6 +748,20 @@ void SMIException(struct pt_regs *regs)
 	die("System Management Interrupt", regs, SIGABRT);
 }
 
+void handle_hmi_exception(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs;
+
+	old_regs = set_irq_regs(regs);
+	irq_enter();
+
+	if (ppc_md.handle_hmi_exception)
+		ppc_md.handle_hmi_exception(regs);
+
+	irq_exit();
+	set_irq_regs(old_regs);
+}
+
 void unknown_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();

commit c152833949a07f3cde8fa1e34dec80614085a159
Author: Wladislav Wiebe <wladislav.kw@gmail.com>
Date:   Tue Jun 17 15:30:53 2014 +0200

    powerpc/traps/e500: fix misleading error output
    
    In machine_check_e500 exception handler is a wrong indication
    in case of MCSR_BUS_WBERR - so print "Write" instead of "Read".
    
    Signed-off-by: Wladislav Wiebe <wladislav.kw@gmail.com>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 239f1cde3fff..cb9cfe448ee8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -609,7 +609,7 @@ int machine_check_e500(struct pt_regs *regs)
 	if (reason & MCSR_BUS_RBERR)
 		printk("Bus - Read Data Bus Error\n");
 	if (reason & MCSR_BUS_WBERR)
-		printk("Bus - Read Data Bus Error\n");
+		printk("Bus - Write Data Bus Error\n");
 	if (reason & MCSR_BUS_IPERR)
 		printk("Bus - Instruction Parity Error\n");
 	if (reason & MCSR_BUS_RPERR)

commit e6654d5b4259317be82b06cf9218f82abec8c8e7
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Wed Jun 11 14:18:07 2014 +0530

    powerpc/book3s: Increment the mce counter during machine_check_early call.
    
    We don't see MCE counter getting increased in /proc/interrupts which gives
    false impression of no MCE occurred even when there were MCE events.
    The machine check early handling was added for PowerKVM and we missed to
    increment the MCE count in the early handler.
    
    We also increment mce counters in the machine_check_exception call, but
    in most cases where we handle the error hypervisor never reaches there
    unless its fatal and we want to crash. Only during fatal situation we may
    see double increment of mce count. We need to fix that. But for
    now it always good to have some count increased instead of zero.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1bd7ca298fa1..239f1cde3fff 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -295,6 +295,8 @@ long machine_check_early(struct pt_regs *regs)
 {
 	long handled = 0;
 
+	__get_cpu_var(irq_stat).mce_exceptions++;
+
 	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
 		handled = cur_cpu_spec->machine_check_early(regs);
 	return handled;

commit f83319d71002aec03bd87bc9aabce5f549680f0a
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Mar 28 17:01:23 2014 +1100

    powerpc: Add lq/stq emulation
    
    Recent CPUs support quad word load and store instructions. Add
    support to the alignment handler for them.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index df86f0ce2d36..1bd7ca298fa1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1868,6 +1868,7 @@ struct ppc_emulated ppc_emulated = {
 #ifdef CONFIG_PPC64
 	WARN_EMULATED_SETUP(mfdscr),
 	WARN_EMULATED_SETUP(mtdscr),
+	WARN_EMULATED_SETUP(lq_stq),
 #endif
 };
 

commit ee4ed6fa5af0009a1205498d1f754fecc7af7657
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Mar 14 17:03:58 2014 +1100

    powerpc: Rate-limit users spamming kernel log buffer
    
    The facility unavailable exception can be triggered from userspace by
    accessing PMU registers when EBB is not enabled.  This causes the
    included pr_err() to run, hence spamming the kernel log buffer.
    
    This avoids this by rate limiting these messages.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 33cd7a0b8e73..df86f0ce2d36 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1379,8 +1379,9 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
-	pr_err("%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
-	       hv ? "Hypervisor " : "", facility, regs->nip, regs->msr);
+	pr_err_ratelimited(
+		"%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
+		hv ? "Hypervisor " : "", facility, regs->nip, regs->msr);
 
 	if (user_mode(regs)) {
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);

commit 3ac8ff1c475bda7174fce63230c0932454287cd5
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Jan 13 15:56:30 2014 +1100

    powerpc: Fix transactional FP/VMX/VSX unavailable handlers
    
    Currently, if a process starts a transaction and then takes an
    exception because the FPU, VMX or VSX unit is unavailable to it,
    we end up corrupting any FP/VMX/VSX state that was valid before
    the interrupt.  For example, if the process starts a transaction
    with the FPU available to it but VMX unavailable, and then does
    a VMX instruction inside the transaction, the FP state gets
    corrupted.
    
    Loading up the desired state generally involves doing a reclaim
    and a recheckpoint.  To avoid corrupting already-valid state, we have
    to be careful not to reload that state from the thread_struct
    between the reclaim and the recheckpoint (since the thread_struct
    values are stale by now), and we have to reload that state from
    the transact_fp/vr arrays after the recheckpoint to get back the
    current transactional values saved there by the reclaim.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 26e1358ff0bc..33cd7a0b8e73 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1416,11 +1416,19 @@ void fp_unavailable_tm(struct pt_regs *regs)
 	/* This loads and recheckpoints the FP registers from
 	 * thread.fpr[].  They will remain in registers after the
 	 * checkpoint so we don't need to reload them after.
+	 * If VMX is in use, the VRs now hold checkpointed values,
+	 * so we don't want to load the VRs from the thread_struct.
 	 */
-	tm_recheckpoint(&current->thread, regs->msr);
+	tm_recheckpoint(&current->thread, MSR_FP);
+
+	/* If VMX is in use, get the transactional values back */
+	if (regs->msr & MSR_VEC) {
+		do_load_up_transact_altivec(&current->thread);
+		/* At this point all the VSX state is loaded, so enable it */
+		regs->msr |= MSR_VSX;
+	}
 }
 
-#ifdef CONFIG_ALTIVEC
 void altivec_unavailable_tm(struct pt_regs *regs)
 {
 	/* See the comments in fp_unavailable_tm().  This function operates
@@ -1432,14 +1440,19 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 		 regs->nip, regs->msr);
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 	regs->msr |= MSR_VEC;
-	tm_recheckpoint(&current->thread, regs->msr);
+	tm_recheckpoint(&current->thread, MSR_VEC);
 	current->thread.used_vr = 1;
+
+	if (regs->msr & MSR_FP) {
+		do_load_up_transact_fpu(&current->thread);
+		regs->msr |= MSR_VSX;
+	}
 }
-#endif
 
-#ifdef CONFIG_VSX
 void vsx_unavailable_tm(struct pt_regs *regs)
 {
+	unsigned long orig_msr = regs->msr;
+
 	/* See the comments in fp_unavailable_tm().  This works similarly,
 	 * though we're loading both FP and VEC registers in here.
 	 *
@@ -1451,16 +1464,30 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 		 "MSR=%lx\n",
 		 regs->nip, regs->msr);
 
+	current->thread.used_vsr = 1;
+
+	/* If FP and VMX are already loaded, we have all the state we need */
+	if ((orig_msr & (MSR_FP | MSR_VEC)) == (MSR_FP | MSR_VEC)) {
+		regs->msr |= MSR_VSX;
+		return;
+	}
+
 	/* This reclaims FP and/or VR regs if they're already enabled */
 	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 
 	regs->msr |= MSR_VEC | MSR_FP | current->thread.fpexc_mode |
 		MSR_VSX;
-	/* This loads & recheckpoints FP and VRs. */
-	tm_recheckpoint(&current->thread, regs->msr);
-	current->thread.used_vsr = 1;
+
+	/* This loads & recheckpoints FP and VRs; but we have
+	 * to be sure not to overwrite previously-valid state.
+	 */
+	tm_recheckpoint(&current->thread, regs->msr & ~orig_msr);
+
+	if (orig_msr & MSR_FP)
+		do_load_up_transact_fpu(&current->thread);
+	if (orig_msr & MSR_VEC)
+		do_load_up_transact_altivec(&current->thread);
 }
-#endif
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 
 void performance_monitor_exception(struct pt_regs *regs)

commit d31626f70b6103f4d9153b75d07e0e8795728cc9
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Jan 13 15:56:29 2014 +1100

    powerpc: Don't corrupt transactional state when using FP/VMX in kernel
    
    Currently, when we have a process using the transactional memory
    facilities on POWER8 (that is, the processor is in transactional
    or suspended state), and the process enters the kernel and the
    kernel then uses the floating-point or vector (VMX/Altivec) facility,
    we end up corrupting the user-visible FP/VMX/VSX state.  This
    happens, for example, if a page fault causes a copy-on-write
    operation, because the copy_page function will use VMX to do the
    copy on POWER8.  The test program below demonstrates the bug.
    
    The bug happens because when FP/VMX state for a transactional process
    is stored in the thread_struct, we store the checkpointed state in
    .fp_state/.vr_state and the transactional (current) state in
    .transact_fp/.transact_vr.  However, when the kernel wants to use
    FP/VMX, it calls enable_kernel_fp() or enable_kernel_altivec(),
    which saves the current state in .fp_state/.vr_state.  Furthermore,
    when we return to the user process we return with FP/VMX/VSX
    disabled.  The next time the process uses FP/VMX/VSX, we don't know
    which set of state (the current register values, .fp_state/.vr_state,
    or .transact_fp/.transact_vr) we should be using, since we have no
    way to tell if we are still in the same transaction, and if not,
    whether the previous transaction succeeded or failed.
    
    Thus it is necessary to strictly adhere to the rule that if FP has
    been enabled at any point in a transaction, we must keep FP enabled
    for the user process with the current transactional state in the
    FP registers, until we detect that it is no longer in a transaction.
    Similarly for VMX; once enabled it must stay enabled until the
    process is no longer transactional.
    
    In order to keep this rule, we add a new thread_info flag which we
    test when returning from the kernel to userspace, called TIF_RESTORE_TM.
    This flag indicates that there is FP/VMX/VSX state to be restored
    before entering userspace, and when it is set the .tm_orig_msr field
    in the thread_struct indicates what state needs to be restored.
    The restoration is done by restore_tm_state().  The TIF_RESTORE_TM
    bit is set by new giveup_fpu/altivec_maybe_transactional helpers,
    which are called from enable_kernel_fp/altivec, giveup_vsx, and
    flush_fp/altivec_to_thread instead of giveup_fpu/altivec.
    
    The other thing to be done is to get the transactional FP/VMX/VSX
    state from .fp_state/.vr_state when doing reclaim, if that state
    has been saved there by giveup_fpu/altivec_maybe_transactional.
    Having done this, we set the FP/VMX bit in the thread's MSR after
    reclaim to indicate that that part of the state is now valid
    (having been reclaimed from the processor's checkpointed state).
    
    Finally, in the signal handling code, we move the clearing of the
    transactional state bits in the thread's MSR a bit earlier, before
    calling flush_fp_to_thread(), so that we don't unnecessarily set
    the TIF_RESTORE_TM bit.
    
    This is the test program:
    
    /* Michael Neuling 4/12/2013
     *
     * See if the altivec state is leaked out of an aborted transaction due to
     * kernel vmx copy loops.
     *
     *   gcc -m64 htm_vmxcopy.c -o htm_vmxcopy
     *
     */
    
    /* We don't use all of these, but for reference: */
    
    int main(int argc, char *argv[])
    {
            long double vecin = 1.3;
            long double vecout;
            unsigned long pgsize = getpagesize();
            int i;
            int fd;
            int size = pgsize*16;
            char tmpfile[] = "/tmp/page_faultXXXXXX";
            char buf[pgsize];
            char *a;
            uint64_t aborted = 0;
    
            fd = mkstemp(tmpfile);
            assert(fd >= 0);
    
            memset(buf, 0, pgsize);
            for (i = 0; i < size; i += pgsize)
                    assert(write(fd, buf, pgsize) == pgsize);
    
            unlink(tmpfile);
    
            a = mmap(NULL, size, PROT_READ|PROT_WRITE, MAP_PRIVATE, fd, 0);
            assert(a != MAP_FAILED);
    
            asm __volatile__(
                    "lxvd2x 40,0,%[vecinptr] ; " // set 40 to initial value
                    TBEGIN
                    "beq    3f ;"
                    TSUSPEND
                    "xxlxor 40,40,40 ; " // set 40 to 0
                    "std    5, 0(%[map]) ;" // cause kernel vmx copy page
                    TABORT
                    TRESUME
                    TEND
                    "li     %[res], 0 ;"
                    "b      5f ;"
                    "3: ;" // Abort handler
                    "li     %[res], 1 ;"
                    "5: ;"
                    "stxvd2x 40,0,%[vecoutptr] ; "
                    : [res]"=r"(aborted)
                    : [vecinptr]"r"(&vecin),
                      [vecoutptr]"r"(&vecout),
                      [map]"r"(a)
                    : "memory", "r0", "r3", "r4", "r5", "r6", "r7");
    
            if (aborted && (vecin != vecout)){
                    printf("FAILED: vector state leaked on abort %f != %f\n",
                           (double)vecin, (double)vecout);
                    exit(1);
            }
    
            munmap(a, size);
    
            close(fd);
    
            printf("PASSED!\n");
            return 0;
    }
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 330841766b09..26e1358ff0bc 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1399,7 +1399,6 @@ void fp_unavailable_tm(struct pt_regs *regs)
 
 	TM_DEBUG("FP Unavailable trap whilst transactional at 0x%lx, MSR=%lx\n",
 		 regs->nip, regs->msr);
-	tm_enable();
 
         /* We can only have got here if the task started using FP after
          * beginning the transaction.  So, the transactional regs are just a
@@ -1408,8 +1407,7 @@ void fp_unavailable_tm(struct pt_regs *regs)
          * transaction, and probably retry but now with FP enabled.  So the
          * checkpointed FP registers need to be loaded.
 	 */
-	tm_reclaim(&current->thread, current->thread.regs->msr,
-		   TM_CAUSE_FAC_UNAV);
+	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 	/* Reclaim didn't save out any FPRs to transact_fprs. */
 
 	/* Enable FP for the task: */
@@ -1432,9 +1430,7 @@ void altivec_unavailable_tm(struct pt_regs *regs)
 	TM_DEBUG("Vector Unavailable trap whilst transactional at 0x%lx,"
 		 "MSR=%lx\n",
 		 regs->nip, regs->msr);
-	tm_enable();
-	tm_reclaim(&current->thread, current->thread.regs->msr,
-		   TM_CAUSE_FAC_UNAV);
+	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 	regs->msr |= MSR_VEC;
 	tm_recheckpoint(&current->thread, regs->msr);
 	current->thread.used_vr = 1;
@@ -1455,10 +1451,8 @@ void vsx_unavailable_tm(struct pt_regs *regs)
 		 "MSR=%lx\n",
 		 regs->nip, regs->msr);
 
-	tm_enable();
 	/* This reclaims FP and/or VR regs if they're already enabled */
-	tm_reclaim(&current->thread, current->thread.regs->msr,
-		   TM_CAUSE_FAC_UNAV);
+	tm_reclaim_current(TM_CAUSE_FAC_UNAV);
 
 	regs->msr |= MSR_VEC | MSR_FP | current->thread.fpexc_mode |
 		MSR_VSX;

commit 4c703416efc0a23f83a282b9240bb92fbd9e0be9
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Wed Oct 30 20:04:40 2013 +0530

    powerpc/book3s: Introduce a early machine check hook in cpu_spec.
    
    This patch adds the early machine check function pointer in cputable for
    CPU specific early machine check handling. The early machine handle routine
    will be called in real mode to handle SLB and TLB errors. We can not reuse
    the existing machine_check hook because it is always invoked in kernel
    virtual mode and we would already be in trouble if we get SLB or TLB errors.
    This patch just sets up a mechanism to invoke CPU specific handler. The
    subsequent patches will populate the function pointer.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 97a1ce72e130..330841766b09 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -293,8 +293,11 @@ void system_reset_exception(struct pt_regs *regs)
  */
 long machine_check_early(struct pt_regs *regs)
 {
-	/* TODO: handle/decode machine check reason */
-	return 0;
+	long handled = 0;
+
+	if (cur_cpu_spec && cur_cpu_spec->machine_check_early)
+		handled = cur_cpu_spec->machine_check_early(regs);
+	return handled;
 }
 
 #endif

commit 1e9b4507ed98457edb8a892934282b8f63e17246
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Wed Oct 30 20:04:08 2013 +0530

    powerpc/book3s: handle machine check in Linux host.
    
    Move machine check entry point into Linux. So far we were dependent on
    firmware to decode MCE error details and handover the high level info to OS.
    
    This patch introduces early machine check routine that saves the MCE
    information (srr1, srr0, dar and dsisr) to the emergency stack. We allocate
    stack frame on emergency stack and set the r1 accordingly. This allows us to be
    prepared to take another exception without loosing context. One thing to note
    here that, if we get another machine check while ME bit is off then we risk a
    checkstop. Hence we restrict ourselves to save only MCE information and
    register saved on PACA_EXMC save are before we turn the ME bit on. We use
    paca->in_mce flag to differentiate between first entry and nested machine check
    entry which helps proper use of emergency stack. We increment paca->in_mce
    every time we enter in early machine check handler and decrement it while
    leaving. When we enter machine check early handler first time (paca->in_mce ==
    0), we are sure nobody is using MC emergency stack and allocate a stack frame
    at the start of the emergency stack. During subsequent entry (paca->in_mce >
    0), we know that r1 points inside emergency stack and we allocate separate
    stack frame accordingly. This prevents us from clobbering MCE information
    during nested machine checks.
    
    The early machine check handler changes are placed under CPU_FTR_HVMODE
    section. This makes sure that the early machine check handler will get executed
    only in hypervisor kernel.
    
    This is the code flow:
    
                    Machine Check Interrupt
                            |
                            V
                       0x200 vector                           ME=0, IR=0, DR=0
                            |
                            V
            +-----------------------------------------------+
            |machine_check_pSeries_early:                   | ME=0, IR=0, DR=0
            |       Alloc frame on emergency stack          |
            |       Save srr1, srr0, dar and dsisr on stack |
            +-----------------------------------------------+
                            |
                    (ME=1, IR=0, DR=0, RFID)
                            |
                            V
                    machine_check_handle_early                ME=1, IR=0, DR=0
                            |
                            V
            +-----------------------------------------------+
            |       machine_check_early (r3=pt_regs)        | ME=1, IR=0, DR=0
            |       Things to do: (in next patches)         |
            |               Flush SLB for SLB errors        |
            |               Flush TLB for TLB errors        |
            |               Decode and save MCE info        |
            +-----------------------------------------------+
                            |
            (Fall through existing exception handler routine.)
                            |
                            V
                    machine_check_pSerie                      ME=1, IR=0, DR=0
                            |
                    (ME=1, IR=1, DR=1, RFID)
                            |
                            V
                    machine_check_common                      ME=1, IR=1, DR=1
                            .
                            .
                            .
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 907a472f9a9e..97a1ce72e130 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -285,6 +285,18 @@ void system_reset_exception(struct pt_regs *regs)
 
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
+
+/*
+ * This function is called in real mode. Strictly no printk's please.
+ *
+ * regs->nip and regs->msr contains srr0 and ssr1.
+ */
+long machine_check_early(struct pt_regs *regs)
+{
+	/* TODO: handle/decode machine check reason */
+	return 0;
+}
+
 #endif
 
 /*

commit f080480488028bcc25357f85e8ae54ccc3bb7173
Merge: eda670c626a4 e504c9098ed6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 15 13:51:36 2013 +0900

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM changes from Paolo Bonzini:
     "Here are the 3.13 KVM changes.  There was a lot of work on the PPC
      side: the HV and emulation flavors can now coexist in a single kernel
      is probably the most interesting change from a user point of view.
    
      On the x86 side there are nested virtualization improvements and a few
      bugfixes.
    
      ARM got transparent huge page support, improved overcommit, and
      support for big endian guests.
    
      Finally, there is a new interface to connect KVM with VFIO.  This
      helps with devices that use NoSnoop PCI transactions, letting the
      driver in the guest execute WBINVD instructions.  This includes some
      nVidia cards on Windows, that fail to start without these patches and
      the corresponding userspace changes"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (146 commits)
      kvm, vmx: Fix lazy FPU on nested guest
      arm/arm64: KVM: PSCI: propagate caller endianness to the incoming vcpu
      arm/arm64: KVM: MMIO support for BE guest
      kvm, cpuid: Fix sparse warning
      kvm: Delete prototype for non-existent function kvm_check_iopl
      kvm: Delete prototype for non-existent function complete_pio
      hung_task: add method to reset detector
      pvclock: detect watchdog reset at pvclock read
      kvm: optimize out smp_mb after srcu_read_unlock
      srcu: API for barrier after srcu read unlock
      KVM: remove vm mmap method
      KVM: IOMMU: hva align mapping page size
      KVM: x86: trace cpuid emulation when called from emulator
      KVM: emulator: cleanup decode_register_operand() a bit
      KVM: emulator: check rex prefix inside decode_register()
      KVM: x86: fix emulation of "movzbl %bpl, %eax"
      kvm_host: typo fix
      KVM: x86: emulate SAHF instruction
      MAINTAINERS: add tree for kvm.git
      Documentation/kvm: add a 00-INDEX file
      ...

commit a3821b2af185b64e3382c45fbdaa2cbc91ce14b8
Author: Scott Wood <scottwood@freescale.com>
Date:   Mon Oct 28 22:07:59 2013 -0500

    powerpc: Fix PPC_EMULATED_STATS build break with sync patch
    
    Commit 9863c28a2af90a56c088f5f6288d7f6d2c923c14 ("powerpc: Emulate sync
    instruction variants") introduced a build breakage with
    CONFIG_PPC_EMULATED_STATS enabled.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Cc: Kumar Gala <galak@kernel.org>
    Cc: James Yang <James.Yang@freescale.com>
    ---

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ad20dcfaedd0..62c3dd8c69f2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1820,6 +1820,7 @@ struct ppc_emulated ppc_emulated = {
 	WARN_EMULATED_SETUP(popcntb),
 	WARN_EMULATED_SETUP(spe),
 	WARN_EMULATED_SETUP(string),
+	WARN_EMULATED_SETUP(sync),
 	WARN_EMULATED_SETUP(unaligned),
 #ifdef CONFIG_MATH_EMULATION
 	WARN_EMULATED_SETUP(math),

commit 1eb2819d69c818784cab0d4a89a35e36bd753e57
Author: LEROY Christophe <christophe.leroy@c-s.fr>
Date:   Wed Aug 28 16:19:17 2013 +0200

    powerpc/mpc8xx: Clearer Oops message for Software Emulation Exception
    
    This patch modifies the Oops message in case of Software Emulation Exception.
    The existing message is quite confusing because it refers to FPU Emulation
    while most often the issue is due to either a non supported instruction
    (not necessarily FPU related) or a stale instruction due to HW issues.
    The new message tries to be more generic in order to make the user understand
    that the Oops is due to something wrong with an instruction, not necessarily
    due to an FPU instruction.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f686686ca0aa..ad20dcfaedd0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1468,7 +1468,8 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 	if (!user_mode(regs)) {
 		debugger(regs);
-		die("Kernel Mode Software FPU Emulation", regs, SIGFPE);
+		die("Kernel Mode Unimplemented Instruction or SW FPU Emulation",
+			regs, SIGFPE);
 	}
 
 	if (!emulate_math(regs))

commit 51ae8d4a2b9e4aa9a502061b9c39168e08829b94
Author: Bharat Bhushan <r65777@freescale.com>
Date:   Thu Jul 4 11:45:46 2013 +0530

    powerpc: move debug registers in a structure
    
    This way we can use same data type struct with KVM and
    also help in using other debug related function.
    
    Signed-off-by: Bharat Bhushan <bharat.bhushan@freescale.com>
    Acked-by: Michael Neuling <mikey@neuling.org>
    [scottwood@freescale.com: removed obvious debug_reg comment]
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 36a1f95a2a36..f686686ca0aa 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -351,8 +351,8 @@ static inline int check_io_access(struct pt_regs *regs)
 #define REASON_TRAP		ESR_PTR
 
 /* single-step stuff */
-#define single_stepping(regs)	(current->thread.dbcr0 & DBCR0_IC)
-#define clear_single_step(regs)	(current->thread.dbcr0 &= ~DBCR0_IC)
+#define single_stepping(regs)	(current->thread.debug.dbcr0 & DBCR0_IC)
+#define clear_single_step(regs)	(current->thread.debug.dbcr0 &= ~DBCR0_IC)
 
 #else
 /* On non-4xx, the reason for the machine check or program
@@ -1489,7 +1489,7 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 	if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
 		dbcr_dac(current) &= ~(DBCR_DAC1R | DBCR_DAC1W);
 #ifdef CONFIG_PPC_ADV_DEBUG_DAC_RANGE
-		current->thread.dbcr2 &= ~DBCR2_DAC12MODE;
+		current->thread.debug.dbcr2 &= ~DBCR2_DAC12MODE;
 #endif
 		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status, TRAP_HWBKPT,
 			     5);
@@ -1500,24 +1500,24 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 			     6);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC1) {
-		current->thread.dbcr0 &= ~DBCR0_IAC1;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC1;
 		dbcr_iac_range(current) &= ~DBCR_IAC12MODE;
 		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status, TRAP_HWBKPT,
 			     1);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC2) {
-		current->thread.dbcr0 &= ~DBCR0_IAC2;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC2;
 		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status, TRAP_HWBKPT,
 			     2);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC3) {
-		current->thread.dbcr0 &= ~DBCR0_IAC3;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC3;
 		dbcr_iac_range(current) &= ~DBCR_IAC34MODE;
 		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status, TRAP_HWBKPT,
 			     3);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC4) {
-		current->thread.dbcr0 &= ~DBCR0_IAC4;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC4;
 		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status, TRAP_HWBKPT,
 			     4);
 		changed |= 0x01;
@@ -1527,19 +1527,20 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 	 * Check all other debug flags and see if that bit needs to be turned
 	 * back on or not.
 	 */
-	if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0, current->thread.dbcr1))
+	if (DBCR_ACTIVE_EVENTS(current->thread.debug.dbcr0,
+	    current->thread.debug.dbcr1))
 		regs->msr |= MSR_DE;
 	else
 		/* Make sure the IDM flag is off */
-		current->thread.dbcr0 &= ~DBCR0_IDM;
+		current->thread.debug.dbcr0 &= ~DBCR0_IDM;
 
 	if (changed & 0x01)
-		mtspr(SPRN_DBCR0, current->thread.dbcr0);
+		mtspr(SPRN_DBCR0, current->thread.debug.dbcr0);
 }
 
 void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
-	current->thread.dbsr = debug_status;
+	current->thread.debug.dbsr = debug_status;
 
 	/* Hack alert: On BookE, Branch Taken stops on the branch itself, while
 	 * on server, it stops on the target of the branch. In order to simulate
@@ -1556,8 +1557,8 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 
 		/* Do the single step trick only when coming from userspace */
 		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~DBCR0_BT;
-			current->thread.dbcr0 |= DBCR0_IDM | DBCR0_IC;
+			current->thread.debug.dbcr0 &= ~DBCR0_BT;
+			current->thread.debug.dbcr0 |= DBCR0_IDM | DBCR0_IC;
 			regs->msr |= MSR_DE;
 			return;
 		}
@@ -1585,13 +1586,13 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 			return;
 
 		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~DBCR0_IC;
-			if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0,
-					       current->thread.dbcr1))
+			current->thread.debug.dbcr0 &= ~DBCR0_IC;
+			if (DBCR_ACTIVE_EVENTS(current->thread.debug.dbcr0,
+					       current->thread.debug.dbcr1))
 				regs->msr |= MSR_DE;
 			else
 				/* Make sure the IDM bit is off */
-				current->thread.dbcr0 &= ~DBCR0_IDM;
+				current->thread.debug.dbcr0 &= ~DBCR0_IDM;
 		}
 
 		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);

commit 95791988fec645d196e746fcc0e329e19f7b1347
Author: Bharat Bhushan <r65777@freescale.com>
Date:   Wed Jun 26 11:12:22 2013 +0530

    powerpc: move debug registers in a structure
    
    This way we can use same data type struct with KVM and
    also help in using other debug related function.
    
    Signed-off-by: Bharat Bhushan <bharat.bhushan@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f783c932faeb..4f5df4e7df12 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -351,8 +351,8 @@ static inline int check_io_access(struct pt_regs *regs)
 #define REASON_TRAP		ESR_PTR
 
 /* single-step stuff */
-#define single_stepping(regs)	(current->thread.dbcr0 & DBCR0_IC)
-#define clear_single_step(regs)	(current->thread.dbcr0 &= ~DBCR0_IC)
+#define single_stepping(regs)	(current->thread.debug.dbcr0 & DBCR0_IC)
+#define clear_single_step(regs)	(current->thread.debug.dbcr0 &= ~DBCR0_IC)
 
 #else
 /* On non-4xx, the reason for the machine check or program
@@ -1486,7 +1486,7 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 	if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
 		dbcr_dac(current) &= ~(DBCR_DAC1R | DBCR_DAC1W);
 #ifdef CONFIG_PPC_ADV_DEBUG_DAC_RANGE
-		current->thread.dbcr2 &= ~DBCR2_DAC12MODE;
+		current->thread.debug.dbcr2 &= ~DBCR2_DAC12MODE;
 #endif
 		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status, TRAP_HWBKPT,
 			     5);
@@ -1497,24 +1497,24 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 			     6);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC1) {
-		current->thread.dbcr0 &= ~DBCR0_IAC1;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC1;
 		dbcr_iac_range(current) &= ~DBCR_IAC12MODE;
 		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status, TRAP_HWBKPT,
 			     1);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC2) {
-		current->thread.dbcr0 &= ~DBCR0_IAC2;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC2;
 		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status, TRAP_HWBKPT,
 			     2);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC3) {
-		current->thread.dbcr0 &= ~DBCR0_IAC3;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC3;
 		dbcr_iac_range(current) &= ~DBCR_IAC34MODE;
 		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status, TRAP_HWBKPT,
 			     3);
 		changed |= 0x01;
 	}  else if (debug_status & DBSR_IAC4) {
-		current->thread.dbcr0 &= ~DBCR0_IAC4;
+		current->thread.debug.dbcr0 &= ~DBCR0_IAC4;
 		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status, TRAP_HWBKPT,
 			     4);
 		changed |= 0x01;
@@ -1524,19 +1524,20 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 	 * Check all other debug flags and see if that bit needs to be turned
 	 * back on or not.
 	 */
-	if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0, current->thread.dbcr1))
+	if (DBCR_ACTIVE_EVENTS(current->thread.debug.dbcr0,
+			       current->thread.debug.dbcr1))
 		regs->msr |= MSR_DE;
 	else
 		/* Make sure the IDM flag is off */
-		current->thread.dbcr0 &= ~DBCR0_IDM;
+		current->thread.debug.dbcr0 &= ~DBCR0_IDM;
 
 	if (changed & 0x01)
-		mtspr(SPRN_DBCR0, current->thread.dbcr0);
+		mtspr(SPRN_DBCR0, current->thread.debug.dbcr0);
 }
 
 void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
-	current->thread.dbsr = debug_status;
+	current->thread.debug.dbsr = debug_status;
 
 	/* Hack alert: On BookE, Branch Taken stops on the branch itself, while
 	 * on server, it stops on the target of the branch. In order to simulate
@@ -1553,8 +1554,8 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 
 		/* Do the single step trick only when coming from userspace */
 		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~DBCR0_BT;
-			current->thread.dbcr0 |= DBCR0_IDM | DBCR0_IC;
+			current->thread.debug.dbcr0 &= ~DBCR0_BT;
+			current->thread.debug.dbcr0 |= DBCR0_IDM | DBCR0_IC;
 			regs->msr |= MSR_DE;
 			return;
 		}
@@ -1582,13 +1583,13 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 			return;
 
 		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~DBCR0_IC;
-			if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0,
-					       current->thread.dbcr1))
+			current->thread.debug.dbcr0 &= ~DBCR0_IC;
+			if (DBCR_ACTIVE_EVENTS(current->thread.debug.dbcr0,
+					       current->thread.debug.dbcr1))
 				regs->msr |= MSR_DE;
 			else
 				/* Make sure the IDM bit is off */
-				current->thread.dbcr0 &= ~DBCR0_IDM;
+				current->thread.debug.dbcr0 &= ~DBCR0_IDM;
 		}
 
 		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);

commit 9863c28a2af90a56c088f5f6288d7f6d2c923c14
Author: James Yang <James.Yang@freescale.com>
Date:   Wed Jul 3 16:26:47 2013 -0500

    powerpc: Emulate sync instruction variants
    
    Reserved fields of the sync instruction have been used for other
    instructions (e.g. lwsync).  On processors that do not support variants
    of the sync instruction, emulate it by executing a sync to subsume the
    effect of the intended instruction.
    
    Signed-off-by: James Yang <James.Yang@freescale.com>
    [scottwood@freescale.com: whitespace and subject line fix]
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f0a6814007a5..36a1f95a2a36 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1018,6 +1018,13 @@ static int emulate_instruction(struct pt_regs *regs)
 		return emulate_isel(regs, instword);
 	}
 
+	/* Emulate sync instruction variants */
+	if ((instword & PPC_INST_SYNC_MASK) == PPC_INST_SYNC) {
+		PPC_WARN_EMULATED(sync, regs);
+		asm volatile("sync");
+		return 0;
+	}
+
 #ifdef CONFIG_PPC64
 	/* Emulate the mfspr rD, DSCR. */
 	if ((((instword & PPC_INST_MFSPR_DSCR_USER_MASK) ==

commit de79f7b9f6f92ec1bd6f61fa1f20de60728a5b5e
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Sep 10 20:20:42 2013 +1000

    powerpc: Put FP/VSX and VR state into structures
    
    This creates new 'thread_fp_state' and 'thread_vr_state' structures
    to store FP/VSX state (including FPSCR) and Altivec/VSX state
    (including VSCR), and uses them in the thread_struct.  In the
    thread_fp_state, the FPRs and VSRs are represented as u64 rather
    than double, since we rarely perform floating-point computations
    on the values, and this will enable the structures to be used
    in KVM code as well.  Similarly FPSCR is now a u64 rather than
    a structure of two 32-bit values.
    
    This takes the offsets out of the macros such as SAVE_32FPRS,
    REST_32FPRS, etc.  This enables the same macros to be used for normal
    and transactional state, enabling us to delete the transactional
    versions of the macros.   This also removes the unused do_load_up_fpu
    and do_load_up_altivec, which were in fact buggy since they didn't
    create large enough stack frames to account for the fact that
    load_up_fpu and load_up_altivec are not designed to be called from C
    and assume that their caller's stack frame is an interrupt frame.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f783c932faeb..f0a6814007a5 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -816,7 +816,7 @@ static void parse_fpe(struct pt_regs *regs)
 
 	flush_fp_to_thread(current);
 
-	code = __parse_fpscr(current->thread.fpscr.val);
+	code = __parse_fpscr(current->thread.fp_state.fpscr);
 
 	_exception(SIGFPE, regs, code, regs->nip);
 }
@@ -1069,7 +1069,7 @@ static int emulate_math(struct pt_regs *regs)
 		return 0;
 	case 1: {
 			int code = 0;
-			code = __parse_fpscr(current->thread.fpscr.val);
+			code = __parse_fpscr(current->thread.fp_state.fpscr);
 			_exception(SIGFPE, regs, code, regs->nip);
 			return 0;
 		}
@@ -1371,8 +1371,6 @@ void facility_unavailable_exception(struct pt_regs *regs)
 
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
 
-extern void do_load_up_fpu(struct pt_regs *regs);
-
 void fp_unavailable_tm(struct pt_regs *regs)
 {
 	/* Note:  This does not handle any kind of FP laziness. */
@@ -1403,8 +1401,6 @@ void fp_unavailable_tm(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_ALTIVEC
-extern void do_load_up_altivec(struct pt_regs *regs);
-
 void altivec_unavailable_tm(struct pt_regs *regs)
 {
 	/* See the comments in fp_unavailable_tm().  This function operates
@@ -1634,7 +1630,7 @@ void altivec_assist_exception(struct pt_regs *regs)
 		/* XXX quick hack for now: set the non-Java bit in the VSCR */
 		printk_ratelimited(KERN_ERR "Unrecognized altivec instruction "
 				   "in %s at %lx\n", current->comm, regs->nip);
-		current->thread.vscr.u[3] |= 0x10000;
+		current->thread.vr_state.vscr.u[3] |= 0x10000;
 	}
 }
 #endif /* CONFIG_ALTIVEC */

commit bc683a7e51c5c838bc74316125bebec92af74f12
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Aug 26 13:55:57 2013 +1000

    powerpc: Cleanup handling of the DSCR bit in the FSCR register
    
    As suggested by paulus we can simplify the Data Stream Control Register
    (DSCR) Facility Status and Control Register (FSCR) handling.
    
    Firstly, we simplify the asm by using a rldimi.
    
    Secondly, we now use the FSCR only to control the DSCR facility, rather
    than both the FSCR and HFSCR.  Users will see no functional change from
    this but will get a minor speedup as they will trap into the kernel only
    once (rather than twice) when they first touch the DSCR.  Also, this
    changes removes a bunch of ugly FTR_SECTION code.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 529a9329e8d9..f783c932faeb 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1342,13 +1342,10 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	if (status == FSCR_DSCR_LG) {
 		/* User is acessing the DSCR.  Set the inherit bit and allow
 		 * the user to set it directly in future by setting via the
-		 * H/FSCR DSCR bit.
+		 * FSCR DSCR bit.  We always leave HFSCR DSCR set.
 		 */
 		current->thread.dscr_inherit = 1;
-		if (hv)
-			mtspr(SPRN_HFSCR, value | HFSCR_DSCR);
-		else
-			mtspr(SPRN_FSCR,  value | FSCR_DSCR);
+		mtspr(SPRN_FSCR, value | FSCR_DSCR);
 		return;
 	}
 

commit 3f1f4311881b330a7b5429dd101e676df191b159
Merge: 5935ff4343a6 28e61cc466d8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Aug 27 15:03:30 2013 +1000

    Merge branch 'merge' into next
    
    Merge stuff that already went into Linus via "merge" which
    are pre-reqs for subsequent patches

commit b3f6a45925232d29519007f1ba6687e1e790fb5d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Aug 15 15:22:19 2013 +1000

    powerpc: Skip emulating & leave interrupts off for kernel program checks
    
    In the program check handler we handle some causes with interrupts off
    and others with interrupts on.
    
    We need to enable interrupts to handle the emulation cases, because they
    access userspace memory and might sleep.
    
    For faults in the kernel we don't want to do any emulation, and
    emulate_instruction() enforces that. do_mathemu() doesn't but probably
    should.
    
    The other disadvantage of enabling interrupts for kernel faults is that
    we may take another interrupt, and recurse. As seen below:
    
      --- Exception: e40 at c000000000004ee0 performance_monitor_relon_pSeries_1
      [link register   ] c00000000000f858 .arch_local_irq_restore+0x38/0x90
      [c000000fb185dc10] 0000000000000000 (unreliable)
      [c000000fb185dc80] c0000000007d8558 .program_check_exception+0x298/0x2d0
      [c000000fb185dd00] c000000000002f40 emulation_assist_common+0x140/0x180
      --- Exception: e40 at c000000000004ee0 performance_monitor_relon_pSeries_1
      [link register   ] c00000000000f858 .arch_local_irq_restore+0x38/0x90
      [c000000fb185dff0] 00000000008b9190 (unreliable)
      [c000000fb185e060] c0000000007d8558 .program_check_exception+0x298/0x2d0
    
    So avoid both problems by checking if the fault was in the kernel and
    skipping the enable of interrupts and the emulation. Go straight to
    delivering the SIGILL, which for kernel faults calls die() and so on,
    dropping us in the debugger etc.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bdf2dd141598..77a7581dcb1c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1151,6 +1151,16 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	}
 #endif
 
+	/*
+	 * If we took the program check in the kernel skip down to sending a
+	 * SIGILL. The subsequent cases all relate to emulating instructions
+	 * which we should only do for userspace. We also do not want to enable
+	 * interrupts for kernel faults because that might lead to further
+	 * faults, and loose the context of the original exception.
+	 */
+	if (!user_mode(regs))
+		goto sigill;
+
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
@@ -1179,6 +1189,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		}
 	}
 
+sigill:
 	if (reason & REASON_PRIVILEGED)
 		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
 	else

commit 4288e343fb63cd74b35bf68c5d83551f867dba56
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Aug 7 02:01:47 2013 +1000

    powerpc: Emulate instructions in little endian mode
    
    Alistair noticed we got a SIGILL on userspace mfpvr instructions.
    
    Remove the little endian check in the emulation code, it is
    probably there to protect against the old pseudo little endian
    implementations but doesn't make sense for real little endian.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e6fac2102b06..bdf2dd141598 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -967,7 +967,7 @@ static int emulate_instruction(struct pt_regs *regs)
 	u32 instword;
 	u32 rd;
 
-	if (!user_mode(regs) || (regs->msr & MSR_LE))
+	if (!user_mode(regs))
 		return -EINVAL;
 	CHECK_FULL_REGS(regs);
 

commit 3a3b5aa63fad4911e239055c2c0a89ce2dac62ce
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sun Jul 14 16:40:07 2013 +0800

    powerpc: Introduce function emulate_math()
    
    There are two invocations of do_mathemu() in traps.c. And the codes
    in these two places are almost the same. Introduce a locale function
    to eliminate the duplication. With this change we can also make sure
    that in program_check_exception() the PPC_WARN_EMULATED is invoked for
    the correctly emulated math instructions.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 82df498069bc..e6fac2102b06 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1055,11 +1055,41 @@ int is_valid_bugaddr(unsigned long addr)
 	return is_kernel_addr(addr);
 }
 
+#ifdef CONFIG_MATH_EMULATION
+static int emulate_math(struct pt_regs *regs)
+{
+	int ret;
+	extern int do_mathemu(struct pt_regs *regs);
+
+	ret = do_mathemu(regs);
+	if (ret >= 0)
+		PPC_WARN_EMULATED(math, regs);
+
+	switch (ret) {
+	case 0:
+		emulate_single_step(regs);
+		return 0;
+	case 1: {
+			int code = 0;
+			code = __parse_fpscr(current->thread.fpscr.val);
+			_exception(SIGFPE, regs, code, regs->nip);
+			return 0;
+		}
+	case -EFAULT:
+		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+		return 0;
+	}
+
+	return -1;
+}
+#else
+static inline int emulate_math(struct pt_regs *regs) { return -1; }
+#endif
+
 void __kprobes program_check_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
 	unsigned int reason = get_reason(regs);
-	extern int do_mathemu(struct pt_regs *regs);
 
 	/* We can now get here via a FP Unavailable exception if the core
 	 * has no FPU, in that case the reason flags will be 0 */
@@ -1125,7 +1155,6 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
-#ifdef CONFIG_MATH_EMULATION
 	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
 	 * but there seems to be a hardware bug on the 405GP (RevD)
 	 * that means ESR is sometimes set incorrectly - either to
@@ -1134,22 +1163,8 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	 * instruction or only on FP instructions, whether there is a
 	 * pattern to occurrences etc. -dgibson 31/Mar/2003
 	 */
-	switch (do_mathemu(regs)) {
-	case 0:
-		emulate_single_step(regs);
-		goto bail;
-	case 1: {
-			int code = 0;
-			code = __parse_fpscr(current->thread.fpscr.val);
-			_exception(SIGFPE, regs, code, regs->nip);
-			goto bail;
-		}
-	case -EFAULT:
-		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+	if (!emulate_math(regs))
 		goto bail;
-	}
-	/* fall through on any other errors */
-#endif /* CONFIG_MATH_EMULATION */
 
 	/* Try to emulate it if we should. */
 	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
@@ -1428,11 +1443,6 @@ void performance_monitor_exception(struct pt_regs *regs)
 #ifdef CONFIG_8xx
 void SoftwareEmulation(struct pt_regs *regs)
 {
-	extern int do_mathemu(struct pt_regs *);
-#if defined(CONFIG_MATH_EMULATION)
-	int errcode;
-#endif
-
 	CHECK_FULL_REGS(regs);
 
 	if (!user_mode(regs)) {
@@ -1440,31 +1450,10 @@ void SoftwareEmulation(struct pt_regs *regs)
 		die("Kernel Mode Software FPU Emulation", regs, SIGFPE);
 	}
 
-#ifdef CONFIG_MATH_EMULATION
-	errcode = do_mathemu(regs);
-	if (errcode >= 0)
-		PPC_WARN_EMULATED(math, regs);
-
-	switch (errcode) {
-	case 0:
-		emulate_single_step(regs);
-		return;
-	case 1: {
-			int code = 0;
-			code = __parse_fpscr(current->thread.fpscr.val);
-			_exception(SIGFPE, regs, code, regs->nip);
-			return;
-		}
-	case -EFAULT:
-		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+	if (!emulate_math(regs))
 		return;
-	default:
-		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-		return;
-	}
-#else
+
 	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-#endif
 }
 #endif /* CONFIG_8xx */
 

commit 6761ee3d7e139ec8728e1515bfc5fdcaf3be317e
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sun Jul 14 16:40:06 2013 +0800

    powerpc/math-emu: Move the flush FPU state function into do_mathemu
    
    By doing this we can make sure that the FPU state is only flushed to
    the thread struct when it is really needed.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f58eaf23e8f1..82df498069bc 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1134,15 +1134,6 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	 * instruction or only on FP instructions, whether there is a
 	 * pattern to occurrences etc. -dgibson 31/Mar/2003
 	 */
-
-	/*
-	 * If we support a HW FPU, we need to ensure the FP state
-	 * if flushed into the thread_struct before attempting
-	 * emulation
-	 */
-#ifdef CONFIG_PPC_FPU
-	flush_fp_to_thread(current);
-#endif
 	switch (do_mathemu(regs)) {
 	case 0:
 		emulate_single_step(regs);

commit 2517617e0de65f8f7cfe75cae745d06b1fa98586
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Aug 9 17:29:29 2013 +1000

    powerpc: Fix context switch DSCR on POWER8
    
    POWER8 allows the DSCR to be accessed directly from userspace via a new SPR
    number 0x3 (Rather than 0x11.  DSCR SPR number 0x11 is still used on POWER8 but
    like POWER7, is only accessible in HV and OS modes).  Currently, we allow this
    by setting H/FSCR DSCR bit on boot.
    
    Unfortunately this doesn't work, as the kernel needs to see the DSCR change so
    that it knows to no longer restore the system wide version of DSCR on context
    switch (ie. to set thread.dscr_inherit).
    
    This clears the H/FSCR DSCR bit initially.  If a process then accesses the DSCR
    (via SPR 0x3), it'll trap into the kernel where we set thread.dscr_inherit in
    facility_unavailable_exception().
    
    We also change _switch() so that we set or clear the H/FSCR DSCR bit based on
    the thread.dscr_inherit.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> [v3.10]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bf33c22e38a4..e435bc089ea3 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -44,9 +44,7 @@
 #include <asm/machdep.h>
 #include <asm/rtas.h>
 #include <asm/pmc.h>
-#ifdef CONFIG_PPC32
 #include <asm/reg.h>
-#endif
 #ifdef CONFIG_PMAC_BACKLIGHT
 #include <asm/backlight.h>
 #endif
@@ -1296,43 +1294,54 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VSX Unavailable Exception", regs, SIGABRT);
 }
 
+#ifdef CONFIG_PPC64
 void facility_unavailable_exception(struct pt_regs *regs)
 {
 	static char *facility_strings[] = {
-		"FPU",
-		"VMX/VSX",
-		"DSCR",
-		"PMU SPRs",
-		"BHRB",
-		"TM",
-		"AT",
-		"EBB",
-		"TAR",
+		[FSCR_FP_LG] = "FPU",
+		[FSCR_VECVSX_LG] = "VMX/VSX",
+		[FSCR_DSCR_LG] = "DSCR",
+		[FSCR_PM_LG] = "PMU SPRs",
+		[FSCR_BHRB_LG] = "BHRB",
+		[FSCR_TM_LG] = "TM",
+		[FSCR_EBB_LG] = "EBB",
+		[FSCR_TAR_LG] = "TAR",
 	};
-	char *facility, *prefix;
+	char *facility = "unknown";
 	u64 value;
+	u8 status;
+	bool hv;
 
-	if (regs->trap == 0xf60) {
-		value = mfspr(SPRN_FSCR);
-		prefix = "";
-	} else {
+	hv = (regs->trap == 0xf80);
+	if (hv)
 		value = mfspr(SPRN_HFSCR);
-		prefix = "Hypervisor ";
+	else
+		value = mfspr(SPRN_FSCR);
+
+	status = value >> 56;
+	if (status == FSCR_DSCR_LG) {
+		/* User is acessing the DSCR.  Set the inherit bit and allow
+		 * the user to set it directly in future by setting via the
+		 * H/FSCR DSCR bit.
+		 */
+		current->thread.dscr_inherit = 1;
+		if (hv)
+			mtspr(SPRN_HFSCR, value | HFSCR_DSCR);
+		else
+			mtspr(SPRN_FSCR,  value | FSCR_DSCR);
+		return;
 	}
 
-	value = value >> 56;
+	if ((status < ARRAY_SIZE(facility_strings)) &&
+	    facility_strings[status])
+		facility = facility_strings[status];
 
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
-	if (value < ARRAY_SIZE(facility_strings))
-		facility = facility_strings[value];
-	else
-		facility = "unknown";
-
 	pr_err("%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
-		prefix, facility, regs->nip, regs->msr);
+	       hv ? "Hypervisor " : "", facility, regs->nip, regs->msr);
 
 	if (user_mode(regs)) {
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
@@ -1341,6 +1350,7 @@ void facility_unavailable_exception(struct pt_regs *regs)
 
 	die("Unexpected facility unavailable exception", regs, SIGABRT);
 }
+#endif
 
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
 

commit 4e0e3435b50285eafe5898124ce02f7577f6803a
Author: Hongtao Jia <hongtao.jia@freescale.com>
Date:   Sun Apr 28 13:20:08 2013 +0800

    powerpc/85xx: Add machine check handler to fix PCIe erratum on mpc85xx
    
    A PCIe erratum of mpc85xx may causes a core hang when a link of PCIe
    goes down. when the link goes down, Non-posted transactions issued
    via the ATMU requiring completion result in an instruction stall.
    At the same time a machine-check exception is generated to the core
    to allow further processing by the handler. We implements the handler
    which skips the instruction caused the stall.
    
    This patch depends on patch:
    powerpc/85xx: Add platform_device declaration to fsl_pci.h
    
    Signed-off-by: Zhao Chenhui <b35336@freescale.com>
    Signed-off-by: Li Yang <leoli@freescale.com>
    Signed-off-by: Liu Shuo <soniccat.liu@gmail.com>
    Signed-off-by: Jia Hongtao <hongtao.jia@freescale.com>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bf33c22e38a4..f58eaf23e8f1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -62,6 +62,7 @@
 #include <asm/switch_to.h>
 #include <asm/tm.h>
 #include <asm/debug.h>
+#include <sysdev/fsl_pci.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -567,6 +568,8 @@ int machine_check_e500(struct pt_regs *regs)
 	if (reason & MCSR_BUS_RBERR) {
 		if (fsl_rio_mcheck_exception(regs))
 			return 1;
+		if (fsl_pci_mcheck_exception(regs))
+			return 1;
 	}
 
 	printk("Machine check in kernel mode.\n");

commit 24a72acac155576d630cf4304fa9cefb9b62ea1f
Merge: 6e0b8bc965d2 8bb495e3f024
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 1 17:57:25 2013 +1000

    Merge tag 'v3.10' into next
    
    Merge 3.10 in order to get some of the last minute powerpc
    changes, resolve conflicts and add additional fixes on top
    of them.

commit b14b6260efeee6eb8942c6e6420e31281892acb6
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Jun 25 17:47:57 2013 +1000

    powerpc: Wire up the HV facility unavailable exception
    
    Similar to the facility unavailble exception, except the facilities are
    controlled by HFSCR.
    
    Adapt the facility_unavailable_exception() so it can be called for
    either the regular or Hypervisor facility unavailable exceptions.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    CC: <stable@vger.kernel.org> [v3.10]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 11f448812dc1..4a87fcbe3ba9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1299,10 +1299,18 @@ void facility_unavailable_exception(struct pt_regs *regs)
 		"EBB",
 		"TAR",
 	};
-	char *facility;
+	char *facility, *prefix;
 	u64 value;
 
-	value = mfspr(SPRN_FSCR) >> 56;
+	if (regs->trap == 0xf60) {
+		value = mfspr(SPRN_FSCR);
+		prefix = "";
+	} else {
+		value = mfspr(SPRN_HFSCR);
+		prefix = "Hypervisor ";
+	}
+
+	value = value >> 56;
 
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))
@@ -1313,8 +1321,8 @@ void facility_unavailable_exception(struct pt_regs *regs)
 	else
 		facility = "unknown";
 
-	pr_err("Facility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
-		facility, regs->nip, regs->msr);
+	pr_err("%sFacility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
+		prefix, facility, regs->nip, regs->msr);
 
 	if (user_mode(regs)) {
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);

commit 021424a1fce335e05807fd770eb8e1da30a63eea
Author: Michael Ellerman <michaele@au1.ibm.com>
Date:   Tue Jun 25 17:47:56 2013 +1000

    powerpc: Rename and flesh out the facility unavailable exception handler
    
    The exception at 0xf60 is not the TM (Transactional Memory) unavailable
    exception, it is the "Facility Unavailable Exception", rename it as
    such.
    
    Flesh out the handler to acknowledge the fact that it can be called for
    many reasons, one of which is TM being unavailable.
    
    Use STD_EXCEPTION_COMMON() for the exception body, for some reason we
    had it open-coded, I've checked the generated code is identical.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    CC: <stable@vger.kernel.org> [v3.10]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 300daf3e7ab0..11f448812dc1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1286,25 +1286,42 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VSX Unavailable Exception", regs, SIGABRT);
 }
 
-void tm_unavailable_exception(struct pt_regs *regs)
+void facility_unavailable_exception(struct pt_regs *regs)
 {
+	static char *facility_strings[] = {
+		"FPU",
+		"VMX/VSX",
+		"DSCR",
+		"PMU SPRs",
+		"BHRB",
+		"TM",
+		"AT",
+		"EBB",
+		"TAR",
+	};
+	char *facility;
+	u64 value;
+
+	value = mfspr(SPRN_FSCR) >> 56;
+
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
-	/* Currently we never expect a TMU exception.  Catch
-	 * this and kill the process!
-	 */
-	printk(KERN_EMERG "Unexpected TM unavailable exception at %lx "
-	       "(msr %lx)\n",
-	       regs->nip, regs->msr);
+	if (value < ARRAY_SIZE(facility_strings))
+		facility = facility_strings[value];
+	else
+		facility = "unknown";
+
+	pr_err("Facility '%s' unavailable, exception at 0x%lx, MSR=%lx\n",
+		facility, regs->nip, regs->msr);
 
 	if (user_mode(regs)) {
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
 
-	die("Unexpected TM unavailable exception", regs, SIGABRT);
+	die("Unexpected facility unavailable exception", regs, SIGABRT);
 }
 
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM

commit 80aa0fb4940bf8ee52bcb574d74459a7aea45621
Author: James Yang <James.Yang@freescale.com>
Date:   Tue Jun 25 11:41:05 2013 -0500

    powerpc: Fix string instr. emulation for 32-bit processes on ppc64
    
    String instruction emulation would erroneously result in a segfault if
    the upper bits of the EA are set and is so high that it fails access
    check.  Truncate the EA to 32 bits if the process is 32-bit.
    
    Signed-off-by: James Yang <James.Yang@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 071f6e040eb2..300daf3e7ab0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -866,6 +866,10 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 		u8 val;
 		u32 shift = 8 * (3 - (pos & 0x3));
 
+		/* if process is 32-bit, clear upper 32 bits of EA */
+		if ((regs->msr & MSR_64BIT) == 0)
+			EA &= 0xFFFFFFFF;
+
 		switch ((instword & PPC_INST_STRING_MASK)) {
 			case PPC_INST_LSWX:
 			case PPC_INST_LSWI:

commit 968219fa334ce8fed3421dd12ea12e9f562c95cb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Sun Jun 9 17:04:58 2013 +1000

    powerpc/8xx: Remove 8xx specific "minimal FPU emulation"
    
    This is duplicated code from math-emu and implements such a small
    subset of the FPU (load/stores/fmr) that it's essentially pointless
    nowdays.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f4b5687b0c66..071f6e040eb2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1396,8 +1396,7 @@ void performance_monitor_exception(struct pt_regs *regs)
 void SoftwareEmulation(struct pt_regs *regs)
 {
 	extern int do_mathemu(struct pt_regs *);
-	extern int Soft_emulate_8xx(struct pt_regs *);
-#if defined(CONFIG_MATH_EMULATION) || defined(CONFIG_8XX_MINIMAL_FPEMU)
+#if defined(CONFIG_MATH_EMULATION)
 	int errcode;
 #endif
 
@@ -1430,23 +1429,6 @@ void SoftwareEmulation(struct pt_regs *regs)
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
-
-#elif defined(CONFIG_8XX_MINIMAL_FPEMU)
-	errcode = Soft_emulate_8xx(regs);
-	if (errcode >= 0)
-		PPC_WARN_EMULATED(8xx, regs);
-
-	switch (errcode) {
-	case 0:
-		emulate_single_step(regs);
-		return;
-	case 1:
-		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-		return;
-	case -EFAULT:
-		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
-		return;
-	}
 #else
 	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 #endif
@@ -1796,8 +1778,6 @@ struct ppc_emulated ppc_emulated = {
 	WARN_EMULATED_SETUP(unaligned),
 #ifdef CONFIG_MATH_EMULATION
 	WARN_EMULATED_SETUP(math),
-#elif defined(CONFIG_8XX_MINIMAL_FPEMU)
-	WARN_EMULATED_SETUP(8xx),
 #endif
 #ifdef CONFIG_VSX
 	WARN_EMULATED_SETUP(vsx),

commit 4e63f8edfe4d6f20b1af176efc022c2b2f5e7aeb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Sun Jun 9 17:01:24 2013 +1000

    powerpc/math-emu: Allow math-emu to be used for HW FPU
    
    (Including 64-bit ones)
    
    This allow SW emulation by the kernel of optional instructions
    such as fsqrt which aren't implemented on some processors, and
    thus fixes some Fedora 19 issues such as Anaconda since the
    compiler is set to generate those by default on 64-bit.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f18c79c324ef..f4b5687b0c66 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1125,7 +1125,17 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	 * ESR_DST (!?) or 0.  In the process of chasing this with the
 	 * hardware people - not sure if it can happen on any illegal
 	 * instruction or only on FP instructions, whether there is a
-	 * pattern to occurrences etc. -dgibson 31/Mar/2003 */
+	 * pattern to occurrences etc. -dgibson 31/Mar/2003
+	 */
+
+	/*
+	 * If we support a HW FPU, we need to ensure the FP state
+	 * if flushed into the thread_struct before attempting
+	 * emulation
+	 */
+#ifdef CONFIG_PPC_FPU
+	flush_fp_to_thread(current);
+#endif
 	switch (do_mathemu(regs)) {
 	case 0:
 		emulate_single_step(regs);

commit bf593907f7236e95698a76b7c7a2bbf8b1165327
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Jun 14 20:07:41 2013 +1000

    powerpc: Fix emulation of illegal instructions on PowerNV platform
    
    Normally, the kernel emulates a few instructions that are unimplemented
    on some processors (e.g. the old dcba instruction), or privileged (e.g.
    mfpvr).  The emulation of unimplemented instructions is currently not
    working on the PowerNV platform.  The reason is that on these machines,
    unimplemented and illegal instructions cause a hypervisor emulation
    assist interrupt, rather than a program interrupt as on older CPUs.
    Our vector for the emulation assist interrupt just calls
    program_check_exception() directly, without setting the bit in SRR1
    that indicates an illegal instruction interrupt.  This fixes it by
    making the emulation assist interrupt set that bit before calling
    program_check_interrupt().  With this, old programs that use no-longer
    implemented instructions such as dcba now work again.
    
    CC: <stable@vger.kernel.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f18c79c324ef..c0e5caf8ccc7 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1165,6 +1165,16 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	exception_exit(prev_state);
 }
 
+/*
+ * This occurs when running in hypervisor mode on POWER6 or later
+ * and an illegal instruction is encountered.
+ */
+void __kprobes emulation_assist_interrupt(struct pt_regs *regs)
+{
+	regs->msr |= REASON_ILLEGAL;
+	program_check_exception(regs);
+}
+
 void alignment_exception(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();

commit 6ce6c629fd8254b3177650de99699682ff7f6707
Author: Michael Neuling <mikey@neuling.org>
Date:   Sun May 26 18:09:39 2013 +0000

    powerpc/tm: Abort on emulation and alignment faults
    
    If we are emulating an instruction inside an active user transaction that
    touches memory, the kernel can't emulate it as it operates in transactional
    suspend context.  We need to abort these transactions and send them back to
    userspace for the hardware to rollback.
    
    We can service these if the user transaction is in suspend mode, since the
    kernel will operate in the same suspend context.
    
    This adds a check to all alignment faults and to specific instruction
    emulations (only string instructions for now).  If the user process is in an
    active (non-suspended) transaction, we abort the transaction go back to
    userspace allowing the HW to roll back the transaction and tell the user of the
    failure.  This also adds new tm abort cause codes to report the reason of the
    persistent error to the user.
    
    Crappy test case here http://neuling.org/devel/junkcode/aligntm.c
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> # v3.9
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a7a648f6b750..f18c79c324ef 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -53,6 +53,7 @@
 #ifdef CONFIG_PPC64
 #include <asm/firmware.h>
 #include <asm/processor.h>
+#include <asm/tm.h>
 #endif
 #include <asm/kexec.h>
 #include <asm/ppc-opcode.h>
@@ -932,6 +933,28 @@ static int emulate_isel(struct pt_regs *regs, u32 instword)
 	return 0;
 }
 
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+static inline bool tm_abort_check(struct pt_regs *regs, int cause)
+{
+        /* If we're emulating a load/store in an active transaction, we cannot
+         * emulate it as the kernel operates in transaction suspended context.
+         * We need to abort the transaction.  This creates a persistent TM
+         * abort so tell the user what caused it with a new code.
+	 */
+	if (MSR_TM_TRANSACTIONAL(regs->msr)) {
+		tm_enable();
+		tm_abort(cause);
+		return true;
+	}
+	return false;
+}
+#else
+static inline bool tm_abort_check(struct pt_regs *regs, int reason)
+{
+	return false;
+}
+#endif
+
 static int emulate_instruction(struct pt_regs *regs)
 {
 	u32 instword;
@@ -971,6 +994,9 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulate load/store string insn. */
 	if ((instword & PPC_INST_STRING_GEN_MASK) == PPC_INST_STRING) {
+		if (tm_abort_check(regs,
+				   TM_CAUSE_EMULATE | TM_CAUSE_PERSISTENT))
+			return -EINVAL;
 		PPC_WARN_EMULATED(string, regs);
 		return emulate_string_inst(regs, instword);
 	}
@@ -1148,6 +1174,9 @@ void alignment_exception(struct pt_regs *regs)
 	if (!arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
+	if (tm_abort_check(regs, TM_CAUSE_ALIGNMENT | TM_CAUSE_PERSISTENT))
+		goto bail;
+
 	/* we don't implement logging of alignment exceptions */
 	if (!(current->thread.align_ctl & PR_UNALIGN_SIGBUS))
 		fixed = fix_alignment(regs);

commit ba12eedee321eeb5baecaada285daeb3462c35f5
Author: Li Zhong <zhong@linux.vnet.ibm.com>
Date:   Mon May 13 16:16:41 2013 +0000

    powerpc: Exception hooks for context tracking subsystem
    
    This is the exception hooks for context tracking subsystem, including
    data access, program check, single step, instruction breakpoint, machine check,
    alignment, fp unavailable, altivec assist, unknown exception, whose handlers
    might use RCU.
    
    This patch corresponds to
    [PATCH] x86: Exception hooks for userspace RCU extended QS
      commit 6ba3c97a38803883c2eee489505796cb0a727122
    
    But after the exception handling moved to generic code, and some changes in
    following two commits:
    56dd9470d7c8734f055da2a6bac553caf4a468eb
      context_tracking: Move exception handling to generic code
    6c1e0256fad84a843d915414e4b5973b7443d48d
      context_tracking: Restore correct previous context state on exception exit
    
    it is able for exception hooks to use the generic code above instead of a
    redundant arch implementation.
    
    Signed-off-by: Li Zhong <zhong@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 83efa2f7d926..a7a648f6b750 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -35,6 +35,7 @@
 #include <linux/kdebug.h>
 #include <linux/debugfs.h>
 #include <linux/ratelimit.h>
+#include <linux/context_tracking.h>
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
@@ -667,6 +668,7 @@ int machine_check_generic(struct pt_regs *regs)
 
 void machine_check_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
 	int recover = 0;
 
 	__get_cpu_var(irq_stat).mce_exceptions++;
@@ -683,7 +685,7 @@ void machine_check_exception(struct pt_regs *regs)
 		recover = cur_cpu_spec->machine_check(regs);
 
 	if (recover > 0)
-		return;
+		goto bail;
 
 #if defined(CONFIG_8xx) && defined(CONFIG_PCI)
 	/* the qspan pci read routines can cause machine checks -- Cort
@@ -693,20 +695,23 @@ void machine_check_exception(struct pt_regs *regs)
 	 * -- BenH
 	 */
 	bad_page_fault(regs, regs->dar, SIGBUS);
-	return;
+	goto bail;
 #endif
 
 	if (debugger_fault_handler(regs))
-		return;
+		goto bail;
 
 	if (check_io_access(regs))
-		return;
+		goto bail;
 
 	die("Machine check", regs, SIGBUS);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable Machine check");
+
+bail:
+	exception_exit(prev_state);
 }
 
 void SMIException(struct pt_regs *regs)
@@ -716,20 +721,29 @@ void SMIException(struct pt_regs *regs)
 
 void unknown_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
+
 	printk("Bad trap at PC: %lx, SR: %lx, vector=%lx\n",
 	       regs->nip, regs->msr, regs->trap);
 
 	_exception(SIGTRAP, regs, 0, 0);
+
+	exception_exit(prev_state);
 }
 
 void instruction_breakpoint_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
+
 	if (notify_die(DIE_IABR_MATCH, "iabr_match", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
-		return;
+		goto bail;
 	if (debugger_iabr_match(regs))
-		return;
+		goto bail;
 	_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
+
+bail:
+	exception_exit(prev_state);
 }
 
 void RunModeException(struct pt_regs *regs)
@@ -739,15 +753,20 @@ void RunModeException(struct pt_regs *regs)
 
 void __kprobes single_step_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
+
 	clear_single_step(regs);
 
 	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
-		return;
+		goto bail;
 	if (debugger_sstep(regs))
-		return;
+		goto bail;
 
 	_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
+
+bail:
+	exception_exit(prev_state);
 }
 
 /*
@@ -1005,6 +1024,7 @@ int is_valid_bugaddr(unsigned long addr)
 
 void __kprobes program_check_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
 	unsigned int reason = get_reason(regs);
 	extern int do_mathemu(struct pt_regs *regs);
 
@@ -1014,26 +1034,26 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	if (reason & REASON_FP) {
 		/* IEEE FP exception */
 		parse_fpe(regs);
-		return;
+		goto bail;
 	}
 	if (reason & REASON_TRAP) {
 		/* Debugger is first in line to stop recursive faults in
 		 * rcu_lock, notify_die, or atomic_notifier_call_chain */
 		if (debugger_bpt(regs))
-			return;
+			goto bail;
 
 		/* trap exception */
 		if (notify_die(DIE_BPT, "breakpoint", regs, 5, 5, SIGTRAP)
 				== NOTIFY_STOP)
-			return;
+			goto bail;
 
 		if (!(regs->msr & MSR_PR) &&  /* not user-mode */
 		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
 			regs->nip += 4;
-			return;
+			goto bail;
 		}
 		_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
-		return;
+		goto bail;
 	}
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
 	if (reason & REASON_TM) {
@@ -1049,7 +1069,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		if (!user_mode(regs) &&
 		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
 			regs->nip += 4;
-			return;
+			goto bail;
 		}
 		/* If usermode caused this, it's done something illegal and
 		 * gets a SIGILL slap on the wrist.  We call it an illegal
@@ -1059,7 +1079,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		 */
 		if (user_mode(regs)) {
 			_exception(SIGILL, regs, ILL_ILLOPN, regs->nip);
-			return;
+			goto bail;
 		} else {
 			printk(KERN_EMERG "Unexpected TM Bad Thing exception "
 			       "at %lx (msr 0x%x)\n", regs->nip, reason);
@@ -1083,16 +1103,16 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	switch (do_mathemu(regs)) {
 	case 0:
 		emulate_single_step(regs);
-		return;
+		goto bail;
 	case 1: {
 			int code = 0;
 			code = __parse_fpscr(current->thread.fpscr.val);
 			_exception(SIGFPE, regs, code, regs->nip);
-			return;
+			goto bail;
 		}
 	case -EFAULT:
 		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
-		return;
+		goto bail;
 	}
 	/* fall through on any other errors */
 #endif /* CONFIG_MATH_EMULATION */
@@ -1103,10 +1123,10 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		case 0:
 			regs->nip += 4;
 			emulate_single_step(regs);
-			return;
+			goto bail;
 		case -EFAULT:
 			_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
-			return;
+			goto bail;
 		}
 	}
 
@@ -1114,10 +1134,14 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
 	else
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+
+bail:
+	exception_exit(prev_state);
 }
 
 void alignment_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
 	int sig, code, fixed = 0;
 
 	/* We restore the interrupt state now */
@@ -1131,7 +1155,7 @@ void alignment_exception(struct pt_regs *regs)
 	if (fixed == 1) {
 		regs->nip += 4;	/* skip over emulated instruction */
 		emulate_single_step(regs);
-		return;
+		goto bail;
 	}
 
 	/* Operand address was bad */
@@ -1146,6 +1170,9 @@ void alignment_exception(struct pt_regs *regs)
 		_exception(sig, regs, code, regs->dar);
 	else
 		bad_page_fault(regs, regs->dar, sig);
+
+bail:
+	exception_exit(prev_state);
 }
 
 void StackOverflow(struct pt_regs *regs)
@@ -1174,23 +1201,32 @@ void trace_syscall(struct pt_regs *regs)
 
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
+
 	printk(KERN_EMERG "Unrecoverable FP Unavailable Exception "
 			  "%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable FP Unavailable Exception", regs, SIGABRT);
+
+	exception_exit(prev_state);
 }
 
 void altivec_unavailable_exception(struct pt_regs *regs)
 {
+	enum ctx_state prev_state = exception_enter();
+
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-		return;
+		goto bail;
 	}
 
 	printk(KERN_EMERG "Unrecoverable VMX/Altivec Unavailable Exception "
 			"%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
+
+bail:
+	exception_exit(prev_state);
 }
 
 void vsx_unavailable_exception(struct pt_regs *regs)

commit 73d2fb758e678c93bc76d40876c2359f0729b0ef
Author: Anton Blanchard <anton@samba.org>
Date:   Wed May 1 20:06:33 2013 +0000

    powerpc: Emulate non privileged DSCR read and write
    
    POWER8 allows read and write of the DSCR in userspace. We added
    kernel emulation so applications could always use the instructions
    regardless of the CPU type.
    
    Unfortunately there are two SPRs for the DSCR and we only added
    emulation for the privileged one. Add code to match the non
    privileged one.
    
    A simple test was created to verify the fix:
    
    http://ozlabs.org/~anton/junkcode/user_dscr_test.c
    
    Without the patch we get a SIGILL and it passes with the patch.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 37cc40ef5043..83efa2f7d926 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -970,7 +970,10 @@ static int emulate_instruction(struct pt_regs *regs)
 
 #ifdef CONFIG_PPC64
 	/* Emulate the mfspr rD, DSCR. */
-	if (((instword & PPC_INST_MFSPR_DSCR_MASK) == PPC_INST_MFSPR_DSCR) &&
+	if ((((instword & PPC_INST_MFSPR_DSCR_USER_MASK) ==
+		PPC_INST_MFSPR_DSCR_USER) ||
+	     ((instword & PPC_INST_MFSPR_DSCR_MASK) ==
+		PPC_INST_MFSPR_DSCR)) &&
 			cpu_has_feature(CPU_FTR_DSCR)) {
 		PPC_WARN_EMULATED(mfdscr, regs);
 		rd = (instword >> 21) & 0x1f;
@@ -978,7 +981,10 @@ static int emulate_instruction(struct pt_regs *regs)
 		return 0;
 	}
 	/* Emulate the mtspr DSCR, rD. */
-	if (((instword & PPC_INST_MTSPR_DSCR_MASK) == PPC_INST_MTSPR_DSCR) &&
+	if ((((instword & PPC_INST_MTSPR_DSCR_USER_MASK) ==
+		PPC_INST_MTSPR_DSCR_USER) ||
+	     ((instword & PPC_INST_MTSPR_DSCR_MASK) ==
+		PPC_INST_MTSPR_DSCR)) &&
 			cpu_has_feature(CPU_FTR_DSCR)) {
 		PPC_WARN_EMULATED(mtdscr, regs);
 		rd = (instword >> 21) & 0x1f;

commit 9043a2650cd21f96f831a97f516c2c302e21fb70
Merge: ab7826595e9e d9d8d7ed498e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 25 15:41:43 2013 -0800

    Merge tag 'modules-next-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux
    
    Pull module update from Rusty Russell:
     "The sweeping change is to make add_taint() explicitly indicate whether
      to disable lockdep, but it's a mechanical change."
    
    * tag 'modules-next-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux:
      MODSIGN: Add option to not sign modules during modules_install
      MODSIGN: Add -s <signature> option to sign-file
      MODSIGN: Specify the hash algorithm on sign-file command line
      MODSIGN: Simplify Makefile with a Kconfig helper
      module: clean up load_module a little more.
      modpost: Ignore ARC specific non-alloc sections
      module: constify within_module_*
      taint: add explicit flag to show whether lock dep is still OK.
      module: printk message when module signature fail taints kernel.

commit bc2a9408fa65195288b41751016c36fd00a75a85
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:40 2013 +0000

    powerpc: Hook in new transactional memory code
    
    This hooks the new transactional memory code into context switching, FP/VMX/VMX
    unavailable and exception return.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5c304697fe84..f9b751b29558 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1029,6 +1029,38 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
 		return;
 	}
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+	if (reason & REASON_TM) {
+		/* This is a TM "Bad Thing Exception" program check.
+		 * This occurs when:
+		 * -  An rfid/hrfid/mtmsrd attempts to cause an illegal
+		 *    transition in TM states.
+		 * -  A trechkpt is attempted when transactional.
+		 * -  A treclaim is attempted when non transactional.
+		 * -  A tend is illegally attempted.
+		 * -  writing a TM SPR when transactional.
+		 */
+		if (!user_mode(regs) &&
+		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
+			regs->nip += 4;
+			return;
+		}
+		/* If usermode caused this, it's done something illegal and
+		 * gets a SIGILL slap on the wrist.  We call it an illegal
+		 * operand to distinguish from the instruction just being bad
+		 * (e.g. executing a 'tend' on a CPU without TM!); it's an
+		 * illegal /placement/ of a valid instruction.
+		 */
+		if (user_mode(regs)) {
+			_exception(SIGILL, regs, ILL_ILLOPN, regs->nip);
+			return;
+		} else {
+			printk(KERN_EMERG "Unexpected TM Bad Thing exception "
+			       "at %lx (msr 0x%x)\n", regs->nip, reason);
+			die("Unrecoverable exception", regs, SIGABRT);
+		}
+	}
+#endif
 
 	/* We restore the interrupt state now */
 	if (!arch_irq_disabled_regs(regs))

commit f54db641b9bbca91b071128e4d71f0f6af9a3c25
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:39 2013 +0000

    powerpc: Routines for FP/VSX/VMX unavailable during a transaction
    
    We do lazy FP but not lazy TM (ie. userspace starts with MSR TM=1 FP=0).  Hence
    if userspace does an FP instruction during a transaction, we'll take an
    fp unavailable exception.
    
    This adds functions needed to handle this case.  We have to inject the current
    FP state into the checkpoint so that the hardware can decide what to do with
    the transaction.  We can't inject only the FP so we have to do a full treclaim
    and recheckpoint to inject just the FP state.  This will cause the transaction
    to be marked as aborted by the hardware.
    
    This just add the routines needed to do this for FP, VMX and VSX.  It doesn't
    hook them into the rest of the code yet.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f829e05d8b1b..5c304697fe84 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -58,6 +58,7 @@
 #include <asm/rio.h>
 #include <asm/fadump.h>
 #include <asm/switch_to.h>
+#include <asm/tm.h>
 #include <asm/debug.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
@@ -1189,6 +1190,88 @@ void tm_unavailable_exception(struct pt_regs *regs)
 	die("Unexpected TM unavailable exception", regs, SIGABRT);
 }
 
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+
+extern void do_load_up_fpu(struct pt_regs *regs);
+
+void fp_unavailable_tm(struct pt_regs *regs)
+{
+	/* Note:  This does not handle any kind of FP laziness. */
+
+	TM_DEBUG("FP Unavailable trap whilst transactional at 0x%lx, MSR=%lx\n",
+		 regs->nip, regs->msr);
+	tm_enable();
+
+        /* We can only have got here if the task started using FP after
+         * beginning the transaction.  So, the transactional regs are just a
+         * copy of the checkpointed ones.  But, we still need to recheckpoint
+         * as we're enabling FP for the process; it will return, abort the
+         * transaction, and probably retry but now with FP enabled.  So the
+         * checkpointed FP registers need to be loaded.
+	 */
+	tm_reclaim(&current->thread, current->thread.regs->msr,
+		   TM_CAUSE_FAC_UNAV);
+	/* Reclaim didn't save out any FPRs to transact_fprs. */
+
+	/* Enable FP for the task: */
+	regs->msr |= (MSR_FP | current->thread.fpexc_mode);
+
+	/* This loads and recheckpoints the FP registers from
+	 * thread.fpr[].  They will remain in registers after the
+	 * checkpoint so we don't need to reload them after.
+	 */
+	tm_recheckpoint(&current->thread, regs->msr);
+}
+
+#ifdef CONFIG_ALTIVEC
+extern void do_load_up_altivec(struct pt_regs *regs);
+
+void altivec_unavailable_tm(struct pt_regs *regs)
+{
+	/* See the comments in fp_unavailable_tm().  This function operates
+	 * the same way.
+	 */
+
+	TM_DEBUG("Vector Unavailable trap whilst transactional at 0x%lx,"
+		 "MSR=%lx\n",
+		 regs->nip, regs->msr);
+	tm_enable();
+	tm_reclaim(&current->thread, current->thread.regs->msr,
+		   TM_CAUSE_FAC_UNAV);
+	regs->msr |= MSR_VEC;
+	tm_recheckpoint(&current->thread, regs->msr);
+	current->thread.used_vr = 1;
+}
+#endif
+
+#ifdef CONFIG_VSX
+void vsx_unavailable_tm(struct pt_regs *regs)
+{
+	/* See the comments in fp_unavailable_tm().  This works similarly,
+	 * though we're loading both FP and VEC registers in here.
+	 *
+	 * If FP isn't in use, load FP regs.  If VEC isn't in use, load VEC
+	 * regs.  Either way, set MSR_VSX.
+	 */
+
+	TM_DEBUG("VSX Unavailable trap whilst transactional at 0x%lx,"
+		 "MSR=%lx\n",
+		 regs->nip, regs->msr);
+
+	tm_enable();
+	/* This reclaims FP and/or VR regs if they're already enabled */
+	tm_reclaim(&current->thread, current->thread.regs->msr,
+		   TM_CAUSE_FAC_UNAV);
+
+	regs->msr |= MSR_VEC | MSR_FP | current->thread.fpexc_mode |
+		MSR_VSX;
+	/* This loads & recheckpoints FP and VRs. */
+	tm_recheckpoint(&current->thread, regs->msr);
+	current->thread.used_vsr = 1;
+}
+#endif
+#endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
+
 void performance_monitor_exception(struct pt_regs *regs)
 {
 	__get_cpu_var(irq_stat).pmu_irqs++;

commit d0c0c9a13f682157e8610565b6125a31d24434bc
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:38 2013 +0000

    powerpc: Add transactional memory unavaliable execption handler
    
    These should never happen since we always turn on MSR TM when in userspace. We
    don't do lazy TM.
    
    Hence if we hit this, we barf and kill the task as something's gone horribly
    wrong.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bd5de5deaf51..f829e05d8b1b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1168,6 +1168,27 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VSX Unavailable Exception", regs, SIGABRT);
 }
 
+void tm_unavailable_exception(struct pt_regs *regs)
+{
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
+	/* Currently we never expect a TMU exception.  Catch
+	 * this and kill the process!
+	 */
+	printk(KERN_EMERG "Unexpected TM unavailable exception at %lx "
+	       "(msr %lx)\n",
+	       regs->nip, regs->msr);
+
+	if (user_mode(regs)) {
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	}
+
+	die("Unexpected TM unavailable exception", regs, SIGABRT);
+}
+
 void performance_monitor_exception(struct pt_regs *regs)
 {
 	__get_cpu_var(irq_stat).pmu_irqs++;

commit 8b3c34cf0e0ab334a24aad7367cd06a5ba09a898
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:32 2013 +0000

    powerpc: New macros for transactional memory support
    
    This adds new macros for saving and restoring checkpointed architected state
    from and to the thread_struct.
    
    It also adds some debugging macros for when your brain explodes trying to debug
    your transactional memory enabled kernel.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a008cf5c0fce..bd5de5deaf51 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -78,6 +78,13 @@ EXPORT_SYMBOL(__debugger_break_match);
 EXPORT_SYMBOL(__debugger_fault_handler);
 #endif
 
+/* Transactional Memory trap debug */
+#ifdef TM_DEBUG_SW
+#define TM_DEBUG(x...) printk(KERN_INFO x)
+#else
+#define TM_DEBUG(x...) do { } while(0)
+#endif
+
 /*
  * Trap & Exception support
  */
@@ -350,6 +357,7 @@ static inline int check_io_access(struct pt_regs *regs)
    exception is in the MSR. */
 #define get_reason(regs)	((regs)->msr)
 #define get_mc_reason(regs)	((regs)->msr)
+#define REASON_TM		0x200000
 #define REASON_FP		0x100000
 #define REASON_ILLEGAL		0x80000
 #define REASON_PRIVILEGED	0x40000

commit 373d4d099761cb1f637bed488ab3871945882273
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Jan 21 17:17:39 2013 +1030

    taint: add explicit flag to show whether lock dep is still OK.
    
    Fix up all callers as they were before, with make one change: an
    unsigned module taints the kernel, but doesn't turn off lockdep.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 32518401af68..c579db859388 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -138,7 +138,7 @@ static void __kprobes oops_end(unsigned long flags, struct pt_regs *regs,
 {
 	bust_spinlocks(0);
 	die_owner = -1;
-	add_taint(TAINT_DIE);
+	add_taint(TAINT_DIE, LOCKDEP_NOW_UNRELIABLE);
 	die_nest_count--;
 	oops_exit();
 	printk("\n");

commit 9422de3e953d0e60eb95f5430a9dd803eec1c6d7
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Dec 20 14:06:44 2012 +0000

    powerpc: Hardware breakpoints rewrite to handle non DABR breakpoint registers
    
    This is a rewrite so that we don't assume we are using the DABR throughout the
    code.  We now use the arch_hw_breakpoint to store the breakpoint in a generic
    manner in the thread_struct, rather than storing the raw DABR value.
    
    The ptrace GET/SET_DEBUGREG interface currently passes the raw DABR in from
    userspace.  We keep this functionality, so that future changes (like the POWER8
    DAWR), will still fake the DABR to userspace.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 114ea241916f..a008cf5c0fce 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -66,7 +66,7 @@ int (*__debugger_ipi)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_bpt)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_sstep)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_iabr_match)(struct pt_regs *regs) __read_mostly;
-int (*__debugger_dabr_match)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_break_match)(struct pt_regs *regs) __read_mostly;
 int (*__debugger_fault_handler)(struct pt_regs *regs) __read_mostly;
 
 EXPORT_SYMBOL(__debugger);
@@ -74,7 +74,7 @@ EXPORT_SYMBOL(__debugger_ipi);
 EXPORT_SYMBOL(__debugger_bpt);
 EXPORT_SYMBOL(__debugger_sstep);
 EXPORT_SYMBOL(__debugger_iabr_match);
-EXPORT_SYMBOL(__debugger_dabr_match);
+EXPORT_SYMBOL(__debugger_break_match);
 EXPORT_SYMBOL(__debugger_fault_handler);
 #endif
 

commit 1e18c17adf32b86474fd903071b0181de9334bd4
Author: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
Date:   Fri Oct 5 08:07:15 2012 +0000

    powerpc: Enable the Watchdog vector for 405
    
    The watchdog and FIT code has been #if 0'd for ever, if the CPU takes
    an exception to either of those vectors it will jump into the middle
    of the PIT or Data TLB code and surely crash.
    
    At least some (all?) 405 cores have both the WDT and FIT
    vectors defined, so lets have proper entry points for them.
    
    Tested that the WDT vector works on a 405F6 core.
    
    Signed-off-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 32518401af68..114ea241916f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1515,7 +1515,7 @@ void unrecoverable_exception(struct pt_regs *regs)
 	die("Unrecoverable exception", regs, SIGABRT);
 }
 
-#ifdef CONFIG_BOOKE_WDT
+#if defined(CONFIG_BOOKE_WDT) || defined(CONFIG_40x)
 /*
  * Default handler for a Watchdog exception,
  * spins until a reboot occurs

commit fff34b3412b9401a76ba9d021db1bd91cb0e02b6
Merge: 28e1e58fb668 636802ef96ee
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Sep 7 09:48:59 2012 +1000

    Merge branch 'merge' into next
    
    Brings in various bug fixes from 3.6-rcX

commit 00ca0de02f80924dfff6b4f630e1dff3db005e35
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Sep 3 16:48:46 2012 +0000

    powerpc: Keep thread.dscr and thread.dscr_inherit in sync
    
    When we update the DSCR either via emulation of mtspr(DSCR) or via
    a change to dscr_default in sysfs we don't update thread.dscr.
    We will eventually update it at context switch time but there is
    a period where thread.dscr is incorrect.
    
    If we fork at this point we will copy the old value of thread.dscr
    into the child. To avoid this, always keep thread.dscr in sync with
    reality.
    
    This issue was found with the following testcase:
    
    http://ozlabs.org/~anton/junkcode/dscr_inherit_test.c
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Cc: <stable@kernel.org> # 3.0+
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 158972341a2d..ae0843fa7a61 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -972,8 +972,9 @@ static int emulate_instruction(struct pt_regs *regs)
 			cpu_has_feature(CPU_FTR_DSCR)) {
 		PPC_WARN_EMULATED(mtdscr, regs);
 		rd = (instword >> 21) & 0x1f;
-		mtspr(SPRN_DSCR, regs->gpr[rd]);
+		current->thread.dscr = regs->gpr[rd];
 		current->thread.dscr_inherit = 1;
+		mtspr(SPRN_DSCR, current->thread.dscr);
 		return 0;
 	}
 #endif

commit 41ab5266c3622354353433618edb92ab278025fa
Author: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
Date:   Thu Aug 23 21:27:09 2012 +0000

    powerpc: Add trap_nr to thread_struct
    
    Add thread_struct.trap_nr and use it to store the last exception
    the thread experienced. In this patch, we populate the field at
    various places where we force_sig_info() to the process.
    
    This is also used in uprobes to determine if the probed instruction
    caused an exception.
    
    Signed-off-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 158972341a2d..8831322962d3 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -251,6 +251,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	if (arch_irqs_disabled() && !arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
+	current->thread.trap_nr = code;
 	memset(&info, 0, sizeof(info));
 	info.si_signo = signr;
 	info.si_code = code;

commit a3512b2dd57cb653bb33645ca9c934436e547e3c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue May 8 13:38:50 2012 +1000

    powerpc/irq: Make alignment & program interrupt behave the same
    
    Alignment was the last user of the ENABLE_INTS macro, which we can
    now remove. All non-syscall exceptions now disable interrupts on
    entry, they get re-enabled conditionally from C code. Don't
    unconditionally re-enable in program check either, check the
    original context.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6aa0c663e247..158972341a2d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -248,7 +248,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 				   addr, regs->nip, regs->link, code);
 	}
 
-	if (!arch_irq_disabled_regs(regs))
+	if (arch_irqs_disabled() && !arch_irq_disabled_regs(regs))
 		local_irq_enable();
 
 	memset(&info, 0, sizeof(info));
@@ -1019,7 +1019,9 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		return;
 	}
 
-	local_irq_enable();
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
 
 #ifdef CONFIG_MATH_EMULATION
 	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
@@ -1069,6 +1071,10 @@ void alignment_exception(struct pt_regs *regs)
 {
 	int sig, code, fixed = 0;
 
+	/* We restore the interrupt state now */
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
 	/* we don't implement logging of alignment exceptions */
 	if (!(current->thread.align_ctl & PR_UNALIGN_SIGBUS))
 		fixed = fix_alignment(regs);

commit ae3a197e3d0bfe3f4bf1693723e82dc018c096f3
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for PowerPC
    
    Disintegrate asm/system.h for PowerPC.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    cc: linuxppc-dev@lists.ozlabs.org

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a750409ccc4e..6aa0c663e247 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -39,7 +39,6 @@
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
-#include <asm/system.h>
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/rtas.h>
@@ -58,6 +57,8 @@
 #include <asm/ppc-opcode.h>
 #include <asm/rio.h>
 #include <asm/fadump.h>
+#include <asm/switch_to.h>
+#include <asm/debug.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;

commit 9f2f79e3a3c19ae745d0439d6e0eed31df28de3c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Mar 1 15:47:44 2012 +1100

    powerpc: Disable interrupts in 64-bit kernel FP and vector faults
    
    If we get a floating point, altivec or vsx unavaible interrupt in
    kernel, we trigger a kernel error. There is no point preserving
    the interrupt state, in fact, that can even make debugging harder
    as the processor state might change (we may even preempt) between
    taking the exception and landing in a debugger.
    
    So just make those 3 disable interrupts unconditionally.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    ---
    
    v2: On BookE only disable when hitting the kernel unavailable
        path, otherwise it will fail to restore softe as
        fast_exception_return doesn't do it.

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5d40e592ffcb..a750409ccc4e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -247,6 +247,9 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 				   addr, regs->nip, regs->link, code);
 	}
 
+	if (!arch_irq_disabled_regs(regs))
+		local_irq_enable();
+
 	memset(&info, 0, sizeof(info));
 	info.si_signo = signr;
 	info.si_code = code;

commit ebaeb5ae24379b5b635dc1d1fa6df904bc95b4d9
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Thu Feb 16 01:14:45 2012 +0000

    fadump: Convert firmware-assisted cpu state dump data into elf notes.
    
    When registered for firmware assisted dump on powerpc, firmware preserves
    the registers for the active CPUs during a system crash. This patch reads
    the cpu register data stored in Firmware-assisted dump format (except for
    crashing cpu) and converts it into elf notes and updates the PT_NOTE program
    header accordingly. The exact register state for crashing cpu is saved to
    fadump crash info structure in scratch area during crash_fadump() and read
    during second kernel boot.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c091527efd89..5d40e592ffcb 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -57,6 +57,7 @@
 #include <asm/kexec.h>
 #include <asm/ppc-opcode.h>
 #include <asm/rio.h>
+#include <asm/fadump.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -145,6 +146,8 @@ static void __kprobes oops_end(unsigned long flags, struct pt_regs *regs,
 		arch_spin_unlock(&die_lock);
 	raw_local_irq_restore(flags);
 
+	crash_fadump(regs, "die oops");
+
 	/*
 	 * A system reset (0x100) is a request to dump, so we always send
 	 * it through the crashdump code.

commit 760ca4dc90e624eb8f7ff85a5925151e25577758
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 30 00:23:13 2011 +0000

    powerpc: Rework die()
    
    Our die() code was based off a very old x86 version. Update it to
    mirror the current x86 code.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 014f88f03d3f..c091527efd89 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -98,18 +98,14 @@ static void pmac_backlight_unblank(void)
 static inline void pmac_backlight_unblank(void) { }
 #endif
 
-int die(const char *str, struct pt_regs *regs, long err)
+static arch_spinlock_t die_lock = __ARCH_SPIN_LOCK_UNLOCKED;
+static int die_owner = -1;
+static unsigned int die_nest_count;
+static int die_counter;
+
+static unsigned __kprobes long oops_begin(struct pt_regs *regs)
 {
-	static struct {
-		raw_spinlock_t lock;
-		u32 lock_owner;
-		int lock_owner_depth;
-	} die = {
-		.lock =			__RAW_SPIN_LOCK_UNLOCKED(die.lock),
-		.lock_owner =		-1,
-		.lock_owner_depth =	0
-	};
-	static int die_counter;
+	int cpu;
 	unsigned long flags;
 
 	if (debugger(regs))
@@ -117,50 +113,37 @@ int die(const char *str, struct pt_regs *regs, long err)
 
 	oops_enter();
 
-	if (die.lock_owner != raw_smp_processor_id()) {
-		console_verbose();
-		raw_spin_lock_irqsave(&die.lock, flags);
-		die.lock_owner = smp_processor_id();
-		die.lock_owner_depth = 0;
-		bust_spinlocks(1);
-		if (machine_is(powermac))
-			pmac_backlight_unblank();
-	} else {
-		local_save_flags(flags);
-	}
-
-	if (++die.lock_owner_depth < 3) {
-		printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
-#ifdef CONFIG_PREEMPT
-		printk("PREEMPT ");
-#endif
-#ifdef CONFIG_SMP
-		printk("SMP NR_CPUS=%d ", NR_CPUS);
-#endif
-#ifdef CONFIG_DEBUG_PAGEALLOC
-		printk("DEBUG_PAGEALLOC ");
-#endif
-#ifdef CONFIG_NUMA
-		printk("NUMA ");
-#endif
-		printk("%s\n", ppc_md.name ? ppc_md.name : "");
-
-		if (notify_die(DIE_OOPS, str, regs, err, 255,
-			       SIGSEGV) == NOTIFY_STOP)
-			return 1;
-
-		print_modules();
-		show_regs(regs);
-	} else {
-		printk("Recursive die() failure, output suppressed\n");
+	/* racy, but better than risking deadlock. */
+	raw_local_irq_save(flags);
+	cpu = smp_processor_id();
+	if (!arch_spin_trylock(&die_lock)) {
+		if (cpu == die_owner)
+			/* nested oops. should stop eventually */;
+		else
+			arch_spin_lock(&die_lock);
 	}
+	die_nest_count++;
+	die_owner = cpu;
+	console_verbose();
+	bust_spinlocks(1);
+	if (machine_is(powermac))
+		pmac_backlight_unblank();
+	return flags;
+}
 
+static void __kprobes oops_end(unsigned long flags, struct pt_regs *regs,
+			       int signr)
+{
 	bust_spinlocks(0);
-	die.lock_owner = -1;
+	die_owner = -1;
 	add_taint(TAINT_DIE);
+	die_nest_count--;
 	oops_exit();
 	printk("\n");
-	raw_spin_unlock_irqrestore(&die.lock, flags);
+	if (!die_nest_count)
+		/* Nest count reaches zero, release the lock. */
+		arch_spin_unlock(&die_lock);
+	raw_local_irq_restore(flags);
 
 	/*
 	 * A system reset (0x100) is a request to dump, so we always send
@@ -177,6 +160,9 @@ int die(const char *str, struct pt_regs *regs, long err)
 		crash_kexec_secondary(regs);
 	}
 
+	if (!signr)
+		return;
+
 	/*
 	 * While our oops output is serialised by a spinlock, output
 	 * from panic() called below can race and corrupt it. If we
@@ -190,15 +176,46 @@ int die(const char *str, struct pt_regs *regs, long err)
 
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");
-
 	if (panic_on_oops)
 		panic("Fatal exception");
+	do_exit(signr);
+}
 
-	do_exit(err);
+static int __kprobes __die(const char *str, struct pt_regs *regs, long err)
+{
+	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
+#ifdef CONFIG_PREEMPT
+	printk("PREEMPT ");
+#endif
+#ifdef CONFIG_SMP
+	printk("SMP NR_CPUS=%d ", NR_CPUS);
+#endif
+#ifdef CONFIG_DEBUG_PAGEALLOC
+	printk("DEBUG_PAGEALLOC ");
+#endif
+#ifdef CONFIG_NUMA
+	printk("NUMA ");
+#endif
+	printk("%s\n", ppc_md.name ? ppc_md.name : "");
+
+	if (notify_die(DIE_OOPS, str, regs, err, 255, SIGSEGV) == NOTIFY_STOP)
+		return 1;
+
+	print_modules();
+	show_regs(regs);
 
 	return 0;
 }
 
+void die(const char *str, struct pt_regs *regs, long err)
+{
+	unsigned long flags = oops_begin(regs);
+
+	if (__die(str, regs, err))
+		err = 0;
+	oops_end(flags, regs, err);
+}
+
 void user_single_step_siginfo(struct task_struct *tsk,
 				struct pt_regs *regs, siginfo_t *info)
 {
@@ -217,10 +234,11 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 			"at %016lx nip %016lx lr %016lx code %x\n";
 
 	if (!user_mode(regs)) {
-		if (die("Exception in kernel mode", regs, signr))
-			return;
-	} else if (show_unhandled_signals &&
-		   unhandled_signal(current, signr)) {
+		die("Exception in kernel mode", regs, signr);
+		return;
+	}
+
+	if (show_unhandled_signals && unhandled_signal(current, signr)) {
 		printk_ratelimited(regs->msr & MSR_64BIT ? fmt64 : fmt32,
 				   current->comm, current->pid, signr,
 				   addr, regs->nip, regs->link, code);

commit 9b00ac06978c54788f13eefd34a07b77db48d567
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 30 00:23:10 2011 +0000

    powerpc: Remove broken and complicated kdump system reset code
    
    We have a lot of complicated logic that handles possible recursion between
    kdump and a system reset exception. We can solve this in a much simpler
    way using the same setjmp/longjmp tricks xmon does.
    
    As a first step, this patch removes the old system reset code.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 91377870b26a..014f88f03d3f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -162,10 +162,20 @@ int die(const char *str, struct pt_regs *regs, long err)
 	printk("\n");
 	raw_spin_unlock_irqrestore(&die.lock, flags);
 
-	if (kexec_should_crash(current) ||
-		kexec_sr_activated(smp_processor_id()))
+	/*
+	 * A system reset (0x100) is a request to dump, so we always send
+	 * it through the crashdump code.
+	 */
+	if (kexec_should_crash(current) || (TRAP(regs) == 0x100)) {
 		crash_kexec(regs);
-	crash_kexec_secondary(regs);
+
+		/*
+		 * We aren't the primary crash CPU. We need to send it
+		 * to a holding pattern to avoid it ending up in the panic
+		 * code.
+		 */
+		crash_kexec_secondary(regs);
+	}
 
 	/*
 	 * While our oops output is serialised by a spinlock, output
@@ -232,25 +242,8 @@ void system_reset_exception(struct pt_regs *regs)
 			return;
 	}
 
-#ifdef CONFIG_KEXEC
-	cpumask_set_cpu(smp_processor_id(), &cpus_in_sr);
-#endif
-
 	die("System Reset", regs, SIGABRT);
 
-	/*
-	 * Some CPUs when released from the debugger will execute this path.
-	 * These CPUs entered the debugger via a soft-reset. If the CPU was
-	 * hung before entering the debugger it will return to the hung
-	 * state when exiting this function.  This causes a problem in
-	 * kdump since the hung CPU(s) will not respond to the IPI sent
-	 * from kdump. To prevent the problem we call crash_kexec_secondary()
-	 * here. If a kdump had not been initiated or we exit the debugger
-	 * with the "exit and recover" command (x) crash_kexec_secondary()
-	 * will return after 5ms and the CPU returns to its previous state.
-	 */
-	crash_kexec_secondary(regs);
-
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable System Reset");

commit 58154c8ce71a7854d969d73468fd00e5eeeab708
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 30 00:23:09 2011 +0000

    powerpc: Give us time to get all oopses out before panicking
    
    I've been seeing truncated output when people send system reset info
    to me. We should see a backtrace for every CPU, but the panic() code
    takes the box down before they all make it out to the console. The
    panic code runs unlocked so we also see corrupted console output.
    
    If we are going to panic, then delay 1 second before calling into the
    panic code. Move oops_exit inside the die lock and put a newline
    between oopses for clarity.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5459d148a0f6..91377870b26a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -158,6 +158,8 @@ int die(const char *str, struct pt_regs *regs, long err)
 	bust_spinlocks(0);
 	die.lock_owner = -1;
 	add_taint(TAINT_DIE);
+	oops_exit();
+	printk("\n");
 	raw_spin_unlock_irqrestore(&die.lock, flags);
 
 	if (kexec_should_crash(current) ||
@@ -165,13 +167,23 @@ int die(const char *str, struct pt_regs *regs, long err)
 		crash_kexec(regs);
 	crash_kexec_secondary(regs);
 
+	/*
+	 * While our oops output is serialised by a spinlock, output
+	 * from panic() called below can race and corrupt it. If we
+	 * know we are going to panic, delay for 1 second so we have a
+	 * chance to get clean backtraces from all CPUs that are oopsing.
+	 */
+	if (in_interrupt() || panic_on_oops || !current->pid ||
+	    is_global_init(current)) {
+		mdelay(MSEC_PER_SEC);
+	}
+
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");
 
 	if (panic_on_oops)
 		panic("Fatal exception");
 
-	oops_exit();
 	do_exit(err);
 
 	return 0;

commit b95bc2191412f5ecf2781c966110a13fa82a80d3
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Oct 6 02:53:39 2011 +0000

    powerpc: Remove extraneous CONFIG_PPC_ADV_DEBUG_REGS define
    
    All of DebugException is already protected by CONFIG_PPC_ADV_DEBUG_REGS
    there is no need to have another such ifdef inside the function.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4e5908264d1a..5459d148a0f6 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1298,14 +1298,12 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 
 		if (user_mode(regs)) {
 			current->thread.dbcr0 &= ~DBCR0_IC;
-#ifdef CONFIG_PPC_ADV_DEBUG_REGS
 			if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0,
 					       current->thread.dbcr1))
 				regs->msr |= MSR_DE;
 			else
 				/* Make sure the IDM bit is off */
 				current->thread.dbcr0 &= ~DBCR0_IDM;
-#endif
 		}
 
 		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);

commit 37caf9f2a1b99d11ba71e17168d221da9ca13f24
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Sat Aug 27 06:14:23 2011 -0500

    powerpc/fsl-booke: Handle L1 D-cache parity error correctly on e500mc
    
    If the L1 D-Cache is in write shadow mode the HW will auto-recover the
    error.  However we might still log the error and cause a machine check
    (if L1CSR0[CPE] - Cache error checking enable).  We should only treat
    the non-write shadow case as non-recoverable.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f19d9777d3c1..4e5908264d1a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -457,7 +457,14 @@ int machine_check_e500mc(struct pt_regs *regs)
 
 	if (reason & MCSR_DCPERR_MC) {
 		printk("Data Cache Parity Error\n");
-		recoverable = 0;
+
+		/*
+		 * In write shadow mode we auto-recover from the error, but it
+		 * may still get logged and cause a machine check.  We should
+		 * only treat the non-write shadow case as non-recoverable.
+		 */
+		if (!(mfspr(SPRN_L1CSR2) & L1CSR2_DCWS))
+			recoverable = 0;
 	}
 
 	if (reason & MCSR_L2MMU_MHIT) {

commit 685659ee70db0bac47ffd619c726cf600e504fd7
Author: yu liu <yu.liu@freescale.com>
Date:   Tue Jun 14 18:34:25 2011 -0500

    powerpc/e500: Save SPEFCSR in flush_spe_to_thread()
    
    giveup_spe() saves the SPE state which is protected by MSR[SPE].
    However, modifying SPEFSCR does not trap when MSR[SPE]=0.
    And since SPEFSCR is already saved/restored in _switch(),
    not all the callers want to save SPEFSCR again.
    Thus, saving SPEFSCR should not belong to giveup_spe().
    
    This patch moves SPEFSCR saving to flush_spe_to_thread(),
    and cleans up the caller that needs to save SPEFSCR accordingly.
    
    Signed-off-by: Liu Yu <yu.liu@freescale.com>
    Acked-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1a0141426cda..f19d9777d3c1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1387,10 +1387,7 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	int code = 0;
 	int err;
 
-	preempt_disable();
-	if (regs->msr & MSR_SPE)
-		giveup_spe(current);
-	preempt_enable();
+	flush_spe_to_thread(current);
 
 	spefscr = current->thread.spefscr;
 	fpexc_mode = current->thread.fpexc_mode;

commit 76462232c21dc011462522387ddad0598a4f11e4
Author: Christian Dietrich <christian.dietrich@informatik.uni-erlangen.de>
Date:   Sat Jun 4 05:36:54 2011 +0000

    arch/powerpc: use printk_ratelimited instead of printk_ratelimit
    
    Since printk_ratelimit() shouldn't be used anymore (see comment in
    include/linux/printk.h), replace it with printk_ratelimited.
    
    Signed-off-by: Christian Dietrich <christian.dietrich@informatik.uni-erlangen.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6414a0d5ba65..1a0141426cda 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -34,6 +34,7 @@
 #include <linux/bug.h>
 #include <linux/kdebug.h>
 #include <linux/debugfs.h>
+#include <linux/ratelimit.h>
 
 #include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
@@ -197,12 +198,11 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 		if (die("Exception in kernel mode", regs, signr))
 			return;
 	} else if (show_unhandled_signals &&
-		    unhandled_signal(current, signr) &&
-		    printk_ratelimit()) {
-			printk(regs->msr & MSR_64BIT ? fmt64 : fmt32,
-				current->comm, current->pid, signr,
-				addr, regs->nip, regs->link, code);
-		}
+		   unhandled_signal(current, signr)) {
+		printk_ratelimited(regs->msr & MSR_64BIT ? fmt64 : fmt32,
+				   current->comm, current->pid, signr,
+				   addr, regs->nip, regs->link, code);
+	}
 
 	memset(&info, 0, sizeof(info));
 	info.si_signo = signr;
@@ -1342,9 +1342,8 @@ void altivec_assist_exception(struct pt_regs *regs)
 	} else {
 		/* didn't recognize the instruction */
 		/* XXX quick hack for now: set the non-Java bit in the VSCR */
-		if (printk_ratelimit())
-			printk(KERN_ERR "Unrecognized altivec instruction "
-			       "in %s at %lx\n", current->comm, regs->nip);
+		printk_ratelimited(KERN_ERR "Unrecognized altivec instruction "
+				   "in %s at %lx\n", current->comm, regs->nip);
 		current->thread.vscr.u[3] |= 0x10000;
 	}
 }
@@ -1548,9 +1547,8 @@ u32 ppc_warn_emulated;
 
 void ppc_warn_emulated_print(const char *type)
 {
-	if (printk_ratelimit())
-		pr_warning("%s used emulated %s instruction\n", current->comm,
-			   type);
+	pr_warn_ratelimited("%s used emulated %s instruction\n", current->comm,
+			    type);
 }
 
 static int __init ppc_warn_emulated_init(void)

commit 82a9a4809f4cb4ce3f17da99a8150df8455fa096
Author: Scott Wood <scottwood@freescale.com>
Date:   Thu Jun 16 14:09:17 2011 -0500

    powerpc/e500: fix breakage with fsl_rio_mcheck_exception
    
    The wrong MCSR bit was being used on e500mc.  MCSR_BUS_RBERR only exists
    on e500v1/v2.  Use MCSR_LD on e500mc, and remove all MCSR checking
    in fsl_rio_mcheck_exception as we now no longer call that function
    if the appropriate bit in MCSR is not set.
    
    If RIO support was enabled at compile-time, but was never probed, just
    return from fsl_rio_mcheck_exception rather than dereference a NULL
    pointer.
    
    TODO: There is still a remaining, though comparitively minor, issue in
    that this recovery mechanism will falsely engage if there's an unrelated
    MCSR_LD event at the same time as a RIO error.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0ff4ab98d50c..6414a0d5ba65 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -425,7 +425,7 @@ int machine_check_e500mc(struct pt_regs *regs)
 	unsigned long reason = mcsr;
 	int recoverable = 1;
 
-	if (reason & MCSR_BUS_RBERR) {
+	if (reason & MCSR_LD) {
 		recoverable = fsl_rio_mcheck_exception(regs);
 		if (recoverable == 1)
 			goto silent_out;

commit cce1f106c64dc1d19d5e9406320fde18dfc662df
Author: Shaohui Xie <b21989@freescale.com>
Date:   Thu Nov 18 14:57:32 2010 +0800

    powerpc/fsl_rio: move machine_check handler
    
    Add support for machine_check support into machine_check_e500 and
    machine_check_e500mc.
    
    Signed-off-by: Shaohui Xie <b21989@freescale.com>
    Cc: Li Yang <leoli@freescale.com>
    Cc: Roy Zang <tie-fei.zang@freescale.com>
    Cc: Alexandre Bounine <alexandre.bounine@idt.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b13306b0d925..0ff4ab98d50c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -55,6 +55,7 @@
 #endif
 #include <asm/kexec.h>
 #include <asm/ppc-opcode.h>
+#include <asm/rio.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -424,6 +425,12 @@ int machine_check_e500mc(struct pt_regs *regs)
 	unsigned long reason = mcsr;
 	int recoverable = 1;
 
+	if (reason & MCSR_BUS_RBERR) {
+		recoverable = fsl_rio_mcheck_exception(regs);
+		if (recoverable == 1)
+			goto silent_out;
+	}
+
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from MCSR=%lx): ", reason);
 
@@ -499,6 +506,7 @@ int machine_check_e500mc(struct pt_regs *regs)
 		       reason & MCSR_MEA ? "Effective" : "Physical", addr);
 	}
 
+silent_out:
 	mtspr(SPRN_MCSR, mcsr);
 	return mfspr(SPRN_MCSR) == 0 && recoverable;
 }
@@ -507,6 +515,11 @@ int machine_check_e500(struct pt_regs *regs)
 {
 	unsigned long reason = get_mc_reason(regs);
 
+	if (reason & MCSR_BUS_RBERR) {
+		if (fsl_rio_mcheck_exception(regs))
+			return 1;
+	}
+
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from MCSR=%lx): ", reason);
 

commit 880102e78547c1db158a17e36cf0cdd98e7ad710
Merge: 3d07f0e83d43 39ab05c8e0b5
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri May 20 15:36:52 2011 +1000

    Merge remote branch 'origin/master' into merge
    
    Manual merge of arch/powerpc/kernel/smp.c and add missing scheduler_ipi()
    call to arch/powerpc/platforms/cell/interrupt.c
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

commit 82a3242e11d9e63c8195be46c954efaefee35e22
Author: Greg Kroah-Hartman <gregkh@suse.de>
Date:   Thu May 12 16:01:02 2011 -0700

    sysfs: remove "last sysfs file:" line from the oops messages
    
    On some arches (x86, sh, arm, unicore, powerpc) the oops message would
    print out the last sysfs file accessed.
    
    This was very useful in finding a number of sysfs and driver core bugs
    in the 2.5 and early 2.6 development days, but it has been a number of
    years since this file has actually helped in debugging anything that
    couldn't also be trivially determined from the stack traceback.
    
    So it's time to delete the line.  This is good as we need all the space
    we can get for oops messages at times on consoles.
    
    Acked-by: Phil Carmody <ext-phil.2.carmody@nokia.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5ddb801bc154..d782cd71c07c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -143,7 +143,6 @@ int die(const char *str, struct pt_regs *regs, long err)
 #endif
 		printk("%s\n", ppc_md.name ? ppc_md.name : "");
 
-		sysfs_printk_last_file();
 		if (notify_die(DIE_OOPS, str, regs, err, 255,
 			       SIGSEGV) == NOTIFY_STOP)
 			return 1;

commit 104699c0ab473535793b5fea156adaf309afd29b
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Thu Apr 28 05:07:23 2011 +0000

    powerpc: Convert old cpumask API into new one
    
    Adapt new API.
    
    Almost change is trivial. Most important change is the below line
    because we plan to change task->cpus_allowed implementation.
    
    -       ctx->cpus_allowed = current->cpus_allowed;
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4a6a109b6816..06b9d457d0a7 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -221,7 +221,7 @@ void system_reset_exception(struct pt_regs *regs)
 	}
 
 #ifdef CONFIG_KEXEC
-	cpu_set(smp_processor_id(), cpus_in_sr);
+	cpumask_set_cpu(smp_processor_id(), &cpus_in_sr);
 #endif
 
 	die("System Reset", regs, SIGABRT);

commit 9f0b079320ad1cc71ad7ea4e0ed0b64cd72bbd6d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 7 21:56:03 2011 +0000

    powerpc: Use MSR_64BIT in places
    
    Use the new MSR_64BIT in a few places. Some of these are already ifdef'ed
    for BOOKE vs BOOKS, but it's still clearer, MSR_SF does not immediately
    parse as "MSR bit for 64bit".
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index cb71cf29edea..4a6a109b6816 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -199,7 +199,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	} else if (show_unhandled_signals &&
 		    unhandled_signal(current, signr) &&
 		    printk_ratelimit()) {
-			printk(regs->msr & MSR_SF ? fmt64 : fmt32,
+			printk(regs->msr & MSR_64BIT ? fmt64 : fmt32,
 				current->comm, current->pid, signr,
 				addr, regs->nip, regs->link, code);
 		}

commit efcac6589a277c10060e4be44b9455cf43838dc1
Author: Alexey Kardashevskiy <aik@au1.ibm.com>
Date:   Wed Mar 2 15:18:48 2011 +0000

    powerpc: Per process DSCR + some fixes (try#4)
    
    The DSCR (aka Data Stream Control Register) is supported on some
    server PowerPC chips and allow some control over the prefetch
    of data streams.
    
    This patch allows the value to be specified per thread by emulating
    the corresponding mfspr and mtspr instructions. Children of such
    threads inherit the value. Other threads use a default value that
    can be specified in sysfs - /sys/devices/system/cpu/dscr_default.
    
    If a thread starts with non default value in the sysfs entry,
    all children threads inherit this non default value even if
    the sysfs value is changed later.
    
    Signed-off-by: Alexey Kardashevskiy <aik@au1.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5ddb801bc154..cb71cf29edea 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -909,6 +909,26 @@ static int emulate_instruction(struct pt_regs *regs)
 		return emulate_isel(regs, instword);
 	}
 
+#ifdef CONFIG_PPC64
+	/* Emulate the mfspr rD, DSCR. */
+	if (((instword & PPC_INST_MFSPR_DSCR_MASK) == PPC_INST_MFSPR_DSCR) &&
+			cpu_has_feature(CPU_FTR_DSCR)) {
+		PPC_WARN_EMULATED(mfdscr, regs);
+		rd = (instword >> 21) & 0x1f;
+		regs->gpr[rd] = mfspr(SPRN_DSCR);
+		return 0;
+	}
+	/* Emulate the mtspr DSCR, rD. */
+	if (((instword & PPC_INST_MTSPR_DSCR_MASK) == PPC_INST_MTSPR_DSCR) &&
+			cpu_has_feature(CPU_FTR_DSCR)) {
+		PPC_WARN_EMULATED(mtdscr, regs);
+		rd = (instword >> 21) & 0x1f;
+		mtspr(SPRN_DSCR, regs->gpr[rd]);
+		current->thread.dscr_inherit = 1;
+		return 0;
+	}
+#endif
+
 	return -EINVAL;
 }
 
@@ -1506,6 +1526,10 @@ struct ppc_emulated ppc_emulated = {
 #ifdef CONFIG_VSX
 	WARN_EMULATED_SETUP(vsx),
 #endif
+#ifdef CONFIG_PPC64
+	WARN_EMULATED_SETUP(mfdscr),
+	WARN_EMULATED_SETUP(mtdscr),
+#endif
 };
 
 u32 ppc_warn_emulated;

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bd74fac169be..5ddb801bc154 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -959,7 +959,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	 * ESR_DST (!?) or 0.  In the process of chasing this with the
 	 * hardware people - not sure if it can happen on any illegal
 	 * instruction or only on FP instructions, whether there is a
-	 * pattern to occurences etc. -dgibson 31/Mar/2003 */
+	 * pattern to occurrences etc. -dgibson 31/Mar/2003 */
 	switch (do_mathemu(regs)) {
 	case 0:
 		emulate_single_step(regs);

commit e49b1fae0ba4d06b29bd753a961abb447566bf4a
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jan 11 19:48:14 2011 +0000

    powerpc: Don't silently handle machine checks from userspace
    
    If a machine check comes from userspace we send a SIGBUS to the task and
    fail to printk anything.
    
    If we are taking machine checks due to bad hardware we want to know about
    it right away. Furthermore if we don't complain loudly then it will look
    a lot like a bug in the userspace application, potentially causing a lot
    of confusion.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9e24224962d9..bd74fac169be 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -626,11 +626,6 @@ void machine_check_exception(struct pt_regs *regs)
 	if (recover > 0)
 		return;
 
-	if (user_mode(regs)) {
-		_exception(SIGBUS, regs, BUS_ADRERR, regs->nip);
-		return;
-	}
-
 #if defined(CONFIG_8xx) && defined(CONFIG_PCI)
 	/* the qspan pci read routines can cause machine checks -- Cort
 	 *

commit dfb5509f8f49ffd52922060c830978ed5a9b9731
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jan 11 19:47:20 2011 +0000

    powerpc: Remove duplicate debugger hook in machine_check_exception
    
    We are calling debugger_fault_handler twice in machine_check_exception.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6865002df6ce..9e24224962d9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -648,8 +648,6 @@ void machine_check_exception(struct pt_regs *regs)
 	if (check_io_access(regs))
 		return;
 
-	if (debugger_fault_handler(regs))
-		return;
 	die("Machine check", regs, SIGBUS);
 
 	/* Must die if the interrupt is not recoverable */

commit a443506b8598bbd784cfe403ad1db2c7083ff465
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jan 11 19:45:31 2011 +0000

    powerpc: Don't force MSR_RI in machine_check_exception
    
    We should never force MSR_RI on. If we take a machine check with MSR_RI off
    then we have no chance of recovering safely.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1b2cdc8eec90..6865002df6ce 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -627,7 +627,6 @@ void machine_check_exception(struct pt_regs *regs)
 		return;
 
 	if (user_mode(regs)) {
-		regs->msr |= MSR_RI;
 		_exception(SIGBUS, regs, BUS_ADRERR, regs->nip);
 		return;
 	}
@@ -643,10 +642,8 @@ void machine_check_exception(struct pt_regs *regs)
 	return;
 #endif
 
-	if (debugger_fault_handler(regs)) {
-		regs->msr |= MSR_RI;
+	if (debugger_fault_handler(regs))
 		return;
-	}
 
 	if (check_io_access(regs))
 		return;

commit 4490c06b581ad7d6392bb398960ef86dfd203a91
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Fri Oct 8 08:32:11 2010 -0500

    powerpc/fsl-booke: Add support for FSL 64-bit e5500 core
    
    The new e5500 core is similar to the e500mc core but adds 64-bit
    support.  We support running it in 32-bit mode as it is identical to the
    e500mc.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a45a63c3a0c7..1b2cdc8eec90 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -538,6 +538,11 @@ int machine_check_e500(struct pt_regs *regs)
 
 	return 0;
 }
+
+int machine_check_generic(struct pt_regs *regs)
+{
+	return 0;
+}
 #elif defined(CONFIG_E200)
 int machine_check_e200(struct pt_regs *regs)
 {

commit e3145b387a02d4bf8b8033b1354d413fc0864494
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:25:18 2010 +1000

    powerpc/book3e: Move doorbell_exception from traps.c to dbell.c
    
    ... where it belongs
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index e5fe5a8522a6..a45a63c3a0c7 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -55,9 +55,6 @@
 #endif
 #include <asm/kexec.h>
 #include <asm/ppc-opcode.h>
-#ifdef CONFIG_FSL_BOOKE
-#include <asm/dbell.h>
-#endif
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs) __read_mostly;
@@ -1342,24 +1339,6 @@ void vsx_assist_exception(struct pt_regs *regs)
 #endif /* CONFIG_VSX */
 
 #ifdef CONFIG_FSL_BOOKE
-
-void doorbell_exception(struct pt_regs *regs)
-{
-#ifdef CONFIG_SMP
-	int cpu = smp_processor_id();
-	int msg;
-
-	if (num_online_cpus() < 2)
-		return;
-
-	for (msg = 0; msg < 4; msg++)
-		if (test_and_clear_bit(msg, &dbell_smp_message[cpu]))
-			smp_message_recv(msg);
-#else
-	printk(KERN_WARNING "Received doorbell on non-smp system\n");
-#endif
-}
-
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)
 {

commit 2538c2d08f46141550a1e68819efa8fe31c6e3dc
Author: K.Prasad <prasad@linux.vnet.ibm.com>
Date:   Tue Jun 15 11:35:31 2010 +0530

    powerpc, hw_breakpoint: Handle concurrent alignment interrupts
    
    If an alignment interrupt occurs on an instruction that is being
    single-stepped, the alignment interrupt handler currently handles
    the single-step condition by unconditionally sending a SIGTRAP to
    the process.  Other synchronous interrupts that result in the
    instruction being emulated do likewise.
    
    With hw_breakpoint support, the hw_breakpoint code needs to be able
    to intercept these single-step events as well as those where the
    instruction executes normally and a trace interrupt happens.
    
    Fix this by making emulate_single_step() use the existing
    single_step_exception() function instead of calling _exception()
    directly.  We then make single_step_exception() use the abstracted
    clear_single_step() rather than clearing bits in the MSR image
    directly so that emulate_single_step() will continue to work
    correctly on Book 3E processors.
    
    Signed-off-by: K.Prasad <prasad@linux.vnet.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 25fc33984c2b..e5fe5a8522a6 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -688,7 +688,7 @@ void RunModeException(struct pt_regs *regs)
 
 void __kprobes single_step_exception(struct pt_regs *regs)
 {
-	regs->msr &= ~(MSR_SE | MSR_BE);  /* Turn off 'trace' bits */
+	clear_single_step(regs);
 
 	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
@@ -707,10 +707,8 @@ void __kprobes single_step_exception(struct pt_regs *regs)
  */
 static void emulate_single_step(struct pt_regs *regs)
 {
-	if (single_stepping(regs)) {
-		clear_single_step(regs);
-		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
-	}
+	if (single_stepping(regs))
+		single_step_exception(regs);
 }
 
 static inline int __parse_fpscr(unsigned long fpscr)

commit ecca1a34befbb13fc23d9a2cc0d6b725c7727fb2
Merge: 3d00d4ff1168 48936a08b855
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon May 31 10:01:50 2010 +1000

    Merge commit 'kumar/next' into next
    
    Conflicts:
            arch/powerpc/sysdev/fsl_msi.c

commit 79c4581262e225a7c96d88b632b05ab3b5e9a52c
Merge: 59534f7298c5 99ec28f183da
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 21 11:17:05 2010 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (92 commits)
      powerpc: Remove unused 'protect4gb' boot parameter
      powerpc: Build-in e1000e for pseries & ppc64_defconfig
      powerpc/pseries: Make request_ras_irqs() available to other pseries code
      powerpc/numa: Use ibm,architecture-vec-5 to detect form 1 affinity
      powerpc/numa: Set a smaller value for RECLAIM_DISTANCE to enable zone reclaim
      powerpc: Use smt_snooze_delay=-1 to always busy loop
      powerpc: Remove check of ibm,smt-snooze-delay OF property
      powerpc/kdump: Fix race in kdump shutdown
      powerpc/kexec: Fix race in kexec shutdown
      powerpc/kexec: Speedup kexec hash PTE tear down
      powerpc/pseries: Add hcall to read 4 ptes at a time in real mode
      powerpc: Use more accurate limit for first segment memory allocations
      powerpc/kdump: Use chip->shutdown to disable IRQs
      powerpc/kdump: CPUs assume the context of the oopsing CPU
      powerpc/crashdump: Do not fail on NULL pointer dereferencing
      powerpc/eeh: Fix oops when probing in early boot
      powerpc/pci: Check devices status property when scanning OF tree
      powerpc/vio: Switch VIO Bus PM to use generic helpers
      powerpc: Avoid bad relocations in iSeries code
      powerpc: Use common cpu_die (fixes SMP+SUSPEND build)
      ...

commit fe04b1121511a97982a1fcdd38e44d2029304a6d
Author: Scott Wood <scottwood@freescale.com>
Date:   Thu Apr 8 00:38:22 2010 -0500

    powerpc/e500mc: Implement machine check handler.
    
    Most of the MSCR bit assigments are different in e500mc versus
    e500, and they are now write-one-to-clear.
    
    Some e500mc machine check conditions are made recoverable (as long as
    they aren't stuck on), most notably L1 instruction cache parity errors.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ca7ce85ebc2e..5ed46758f4e9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1,5 +1,6 @@
 /*
  *  Copyright (C) 1995-1996  Gary Thomas (gdt@linuxppc.org)
+ *  Copyright 2007-2010 Freescale Semiconductor, Inc.
  *
  *  This program is free software; you can redistribute it and/or
  *  modify it under the terms of the GNU General Public License
@@ -305,7 +306,7 @@ static inline int check_io_access(struct pt_regs *regs)
 #ifndef CONFIG_FSL_BOOKE
 #define get_mc_reason(regs)	((regs)->dsisr)
 #else
-#define get_mc_reason(regs)	(mfspr(SPRN_MCSR) & MCSR_MASK)
+#define get_mc_reason(regs)	(mfspr(SPRN_MCSR))
 #endif
 #define REASON_FP		ESR_FP
 #define REASON_ILLEGAL		(ESR_PIL | ESR_PUO)
@@ -421,6 +422,91 @@ int machine_check_47x(struct pt_regs *regs)
 	return 0;
 }
 #elif defined(CONFIG_E500)
+int machine_check_e500mc(struct pt_regs *regs)
+{
+	unsigned long mcsr = mfspr(SPRN_MCSR);
+	unsigned long reason = mcsr;
+	int recoverable = 1;
+
+	printk("Machine check in kernel mode.\n");
+	printk("Caused by (from MCSR=%lx): ", reason);
+
+	if (reason & MCSR_MCP)
+		printk("Machine Check Signal\n");
+
+	if (reason & MCSR_ICPERR) {
+		printk("Instruction Cache Parity Error\n");
+
+		/*
+		 * This is recoverable by invalidating the i-cache.
+		 */
+		mtspr(SPRN_L1CSR1, mfspr(SPRN_L1CSR1) | L1CSR1_ICFI);
+		while (mfspr(SPRN_L1CSR1) & L1CSR1_ICFI)
+			;
+
+		/*
+		 * This will generally be accompanied by an instruction
+		 * fetch error report -- only treat MCSR_IF as fatal
+		 * if it wasn't due to an L1 parity error.
+		 */
+		reason &= ~MCSR_IF;
+	}
+
+	if (reason & MCSR_DCPERR_MC) {
+		printk("Data Cache Parity Error\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_L2MMU_MHIT) {
+		printk("Hit on multiple TLB entries\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_NMI)
+		printk("Non-maskable interrupt\n");
+
+	if (reason & MCSR_IF) {
+		printk("Instruction Fetch Error Report\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_LD) {
+		printk("Load Error Report\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_ST) {
+		printk("Store Error Report\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_LDG) {
+		printk("Guarded Load Error Report\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_TLBSYNC)
+		printk("Simultaneous tlbsync operations\n");
+
+	if (reason & MCSR_BSL2_ERR) {
+		printk("Level 2 Cache Error\n");
+		recoverable = 0;
+	}
+
+	if (reason & MCSR_MAV) {
+		u64 addr;
+
+		addr = mfspr(SPRN_MCAR);
+		addr |= (u64)mfspr(SPRN_MCARU) << 32;
+
+		printk("Machine Check %s Address: %#llx\n",
+		       reason & MCSR_MEA ? "Effective" : "Physical", addr);
+	}
+
+	mtspr(SPRN_MCSR, mcsr);
+	return mfspr(SPRN_MCSR) == 0 && recoverable;
+}
+
 int machine_check_e500(struct pt_regs *regs)
 {
 	unsigned long reason = get_mc_reason(regs);

commit ba797b28131b1f1367b662936ea370239d603cff
Author: Jason Wessel <jason.wessel@windriver.com>
Date:   Thu May 20 21:04:25 2010 -0500

    powerpc,kgdb: Introduce low level trap catching
    
    The only way the debugger can handle a trap in inside rcu_lock,
    notify_die, or atomic_notifier_call_chain without a recursive fault is
    to allow the kernel debugger to handle the exception first in
    program_check_exception().
    
    The other change here is to make sure that kgdb_handle_exception() is
    called with correct parameters when catching an oops, because kdb
    needs to know if the entry was an oops, single step, or breakpoint
    exception.
    
    [benh@kernel.crashing.org: move debugger_bpt instead of #ifdef]
    
    CC: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Jason Wessel <jason.wessel@windriver.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 29d128eb6c43..b6859aade9c2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -815,12 +815,15 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		return;
 	}
 	if (reason & REASON_TRAP) {
+		/* Debugger is first in line to stop recursive faults in
+		 * rcu_lock, notify_die, or atomic_notifier_call_chain */
+		if (debugger_bpt(regs))
+			return;
+
 		/* trap exception */
 		if (notify_die(DIE_BPT, "breakpoint", regs, 5, 5, SIGTRAP)
 				== NOTIFY_STOP)
 			return;
-		if (debugger_bpt(regs))
-			return;
 
 		if (!(regs->msr & MSR_PR) &&  /* not user-mode */
 		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {

commit fc5e709731429bc2db27897630e7c0089f297680
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Fri Mar 5 03:43:18 2010 +0000

    powerpc/476: add machine check handler for 47x core
    
    The 47x core's MCSR varies from 44x, so it needs it's own machine check
    handler.
    
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 29d128eb6c43..ca7ce85ebc2e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -380,6 +380,46 @@ int machine_check_440A(struct pt_regs *regs)
 	}
 	return 0;
 }
+
+int machine_check_47x(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+	u32 mcsr;
+
+	printk(KERN_ERR "Machine check in kernel mode.\n");
+	if (reason & ESR_IMCP) {
+		printk(KERN_ERR
+		       "Instruction Synchronous Machine Check exception\n");
+		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
+		return 0;
+	}
+	mcsr = mfspr(SPRN_MCSR);
+	if (mcsr & MCSR_IB)
+		printk(KERN_ERR "Instruction Read PLB Error\n");
+	if (mcsr & MCSR_DRB)
+		printk(KERN_ERR "Data Read PLB Error\n");
+	if (mcsr & MCSR_DWB)
+		printk(KERN_ERR "Data Write PLB Error\n");
+	if (mcsr & MCSR_TLBP)
+		printk(KERN_ERR "TLB Parity Error\n");
+	if (mcsr & MCSR_ICP) {
+		flush_instruction_cache();
+		printk(KERN_ERR "I-Cache Parity Error\n");
+	}
+	if (mcsr & MCSR_DCSP)
+		printk(KERN_ERR "D-Cache Search Parity Error\n");
+	if (mcsr & PPC47x_MCSR_GPR)
+		printk(KERN_ERR "GPR Parity Error\n");
+	if (mcsr & PPC47x_MCSR_FPR)
+		printk(KERN_ERR "FPR Parity Error\n");
+	if (mcsr & PPC47x_MCSR_IPR)
+		printk(KERN_ERR "Machine Check exception is imprecise\n");
+
+	/* Clear MCSR */
+	mtspr(SPRN_MCSR, mcsr);
+
+	return 0;
+}
 #elif defined(CONFIG_E500)
 int machine_check_e500(struct pt_regs *regs)
 {

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 696626a2e835..29d128eb6c43 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -21,7 +21,6 @@
 #include <linux/stddef.h>
 #include <linux/unistd.h>
 #include <linux/ptrace.h>
-#include <linux/slab.h>
 #include <linux/user.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>

commit b8f87782e82709d613c5d2a165d1443478e57c00
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 18 02:22:31 2010 +0000

    powerpc: Convert die.lock to raw_spinlock
    
    die.lock needs to be a real spinlock in RT. Convert it to
    raw_spinlock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 987437e04e61..696626a2e835 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -102,11 +102,11 @@ static inline void pmac_backlight_unblank(void) { }
 int die(const char *str, struct pt_regs *regs, long err)
 {
 	static struct {
-		spinlock_t lock;
+		raw_spinlock_t lock;
 		u32 lock_owner;
 		int lock_owner_depth;
 	} die = {
-		.lock =			__SPIN_LOCK_UNLOCKED(die.lock),
+		.lock =			__RAW_SPIN_LOCK_UNLOCKED(die.lock),
 		.lock_owner =		-1,
 		.lock_owner_depth =	0
 	};
@@ -120,7 +120,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 
 	if (die.lock_owner != raw_smp_processor_id()) {
 		console_verbose();
-		spin_lock_irqsave(&die.lock, flags);
+		raw_spin_lock_irqsave(&die.lock, flags);
 		die.lock_owner = smp_processor_id();
 		die.lock_owner_depth = 0;
 		bust_spinlocks(1);
@@ -160,7 +160,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	bust_spinlocks(0);
 	die.lock_owner = -1;
 	add_taint(TAINT_DIE);
-	spin_unlock_irqrestore(&die.lock, flags);
+	raw_spin_unlock_irqrestore(&die.lock, flags);
 
 	if (kexec_should_crash(current) ||
 		kexec_sr_activated(smp_processor_id()))

commit 3bffb6529cf10d48a97ac0d6d789986894c25c37
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Mon Feb 8 11:51:18 2010 +0000

    powerpc/booke: Add support for advanced debug registers
    
    powerpc/booke: Add support for advanced debug registers
    
    From: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    
    Based on patches originally written by Torez Smith.
    
    This patch defines context switch and trap related functionality
    for BookE specific Debug Registers. It adds support to ptrace()
    for setting and getting BookE related Debug Registers
    
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Cc: Torez Smith  <lnxtorez@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Gibson <dwg@au1.ibm.com>
    Cc: Josh Boyer <jwboyer@linux.vnet.ibm.com>
    Cc: Kumar Gala <galak@kernel.crashing.org>
    Cc: Sergio Durigan Junior <sergiodj@br.ibm.com>
    Cc: Thiago Jung Bauermann <bauerman@br.ibm.com>
    Cc: linuxppc-dev list <Linuxppc-dev@ozlabs.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4e293b75f951..987437e04e61 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1034,9 +1034,68 @@ void SoftwareEmulation(struct pt_regs *regs)
 #endif /* CONFIG_8xx */
 
 #ifdef CONFIG_PPC_ADV_DEBUG_REGS
+static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
+{
+	int changed = 0;
+	/*
+	 * Determine the cause of the debug event, clear the
+	 * event flags and send a trap to the handler. Torez
+	 */
+	if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
+		dbcr_dac(current) &= ~(DBCR_DAC1R | DBCR_DAC1W);
+#ifdef CONFIG_PPC_ADV_DEBUG_DAC_RANGE
+		current->thread.dbcr2 &= ~DBCR2_DAC12MODE;
+#endif
+		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status, TRAP_HWBKPT,
+			     5);
+		changed |= 0x01;
+	}  else if (debug_status & (DBSR_DAC2R | DBSR_DAC2W)) {
+		dbcr_dac(current) &= ~(DBCR_DAC2R | DBCR_DAC2W);
+		do_send_trap(regs, mfspr(SPRN_DAC2), debug_status, TRAP_HWBKPT,
+			     6);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC1) {
+		current->thread.dbcr0 &= ~DBCR0_IAC1;
+		dbcr_iac_range(current) &= ~DBCR_IAC12MODE;
+		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status, TRAP_HWBKPT,
+			     1);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC2) {
+		current->thread.dbcr0 &= ~DBCR0_IAC2;
+		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status, TRAP_HWBKPT,
+			     2);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC3) {
+		current->thread.dbcr0 &= ~DBCR0_IAC3;
+		dbcr_iac_range(current) &= ~DBCR_IAC34MODE;
+		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status, TRAP_HWBKPT,
+			     3);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC4) {
+		current->thread.dbcr0 &= ~DBCR0_IAC4;
+		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status, TRAP_HWBKPT,
+			     4);
+		changed |= 0x01;
+	}
+	/*
+	 * At the point this routine was called, the MSR(DE) was turned off.
+	 * Check all other debug flags and see if that bit needs to be turned
+	 * back on or not.
+	 */
+	if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0, current->thread.dbcr1))
+		regs->msr |= MSR_DE;
+	else
+		/* Make sure the IDM flag is off */
+		current->thread.dbcr0 &= ~DBCR0_IDM;
+
+	if (changed & 0x01)
+		mtspr(SPRN_DBCR0, current->thread.dbcr0);
+}
 
 void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
+	current->thread.dbsr = debug_status;
+
 	/* Hack alert: On BookE, Branch Taken stops on the branch itself, while
 	 * on server, it stops on the target of the branch. In order to simulate
 	 * the server behaviour, we thus restart right away with a single step
@@ -1080,27 +1139,21 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 		if (debugger_sstep(regs))
 			return;
 
-		if (user_mode(regs))
-			current->thread.dbcr0 &= ~(DBCR0_IC);
-
-		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
-	} else if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
-		regs->msr &= ~MSR_DE;
-
 		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~(DBSR_DAC1R | DBSR_DAC1W |
-								DBCR0_IDM);
-		} else {
-			/* Disable DAC interupts */
-			mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~(DBSR_DAC1R |
-						DBSR_DAC1W | DBCR0_IDM));
-
-			/* Clear the DAC event */
-			mtspr(SPRN_DBSR, (DBSR_DAC1R | DBSR_DAC1W));
+			current->thread.dbcr0 &= ~DBCR0_IC;
+#ifdef CONFIG_PPC_ADV_DEBUG_REGS
+			if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0,
+					       current->thread.dbcr1))
+				regs->msr |= MSR_DE;
+			else
+				/* Make sure the IDM bit is off */
+				current->thread.dbcr0 &= ~DBCR0_IDM;
+#endif
 		}
-		/* Setup and send the trap to the handler */
-		do_dabr(regs, mfspr(SPRN_DAC1), debug_status);
-	}
+
+		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
+	} else
+		handle_debug(regs, debug_status);
 }
 #endif /* CONFIG_PPC_ADV_DEBUG_REGS */
 

commit 172ae2e7f8ff9053905a36672453a6d2ff95b182
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Mon Feb 8 11:50:57 2010 +0000

    powerpc/booke: Introduce new CONFIG options for advanced debug registers
    
    powerpc/booke: Introduce new CONFIG options for advanced debug registers
    
    From: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    
    Introduce new config options to simplify the ifdefs pertaining to the
    advanced debug registers for booke and 40x processors:
    
    CONFIG_PPC_ADV_DEBUG_REGS - boolean: true for dac-based processors
    CONFIG_PPC_ADV_DEBUG_IACS - number of IAC registers
    CONFIG_PPC_ADV_DEBUG_DACS - number of DAC registers
    CONFIG_PPC_ADV_DEBUG_DVCS - number of DVC registers
    CONFIG_PPC_ADV_DEBUG_DAC_RANGE - DAC ranges supported
    
    Beginning conservatively, since I only have the facilities to test 440
    hardware.  I believe all 40x and booke platforms support at least 2 IAC
    and 2 DAC registers.  For 440, 4 IAC and 2 DVC registers are enabled, as
    well as the DAC ranges.
    
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Acked-by: David Gibson <dwg@au1.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 895da29e7db8..4e293b75f951 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -299,7 +299,7 @@ static inline int check_io_access(struct pt_regs *regs)
 	return 0;
 }
 
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#ifdef CONFIG_PPC_ADV_DEBUG_REGS
 /* On 4xx, the reason for the machine check or program exception
    is in the ESR. */
 #define get_reason(regs)	((regs)->dsisr)
@@ -1033,7 +1033,7 @@ void SoftwareEmulation(struct pt_regs *regs)
 }
 #endif /* CONFIG_8xx */
 
-#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+#ifdef CONFIG_PPC_ADV_DEBUG_REGS
 
 void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
@@ -1102,7 +1102,7 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 		do_dabr(regs, mfspr(SPRN_DAC1), debug_status);
 	}
 }
-#endif /* CONFIG_4xx || CONFIG_BOOKE */
+#endif /* CONFIG_PPC_ADV_DEBUG_REGS */
 
 #if !defined(CONFIG_TAU_INT)
 void TAUException(struct pt_regs *regs)

commit 89713ed10815401a1bfe12e3a076b64048381b56
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Jan 31 20:34:06 2010 +0000

    powerpc: Add timer, performance monitor and machine check counts to /proc/interrupts
    
    With NO_HZ it is useful to know how often the decrementer is going off. The
    patch below adds an entry for it and also adds it into the /proc/stat
    summaries.
    
    While here, I added performance monitoring and machine check exceptions.
    I found it useful to keep an eye on the PMU exception rate
    when using the perf tool. Since it's possible to take a completely
    handled machine check on a System p box it also sounds like a good idea to
    keep a machine check summary.
    
    The event naming matches x86 to keep gratuitous differences to a minimum.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0a320dbd950a..895da29e7db8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -483,6 +483,8 @@ void machine_check_exception(struct pt_regs *regs)
 {
 	int recover = 0;
 
+	__get_cpu_var(irq_stat).mce_exceptions++;
+
 	/* See if any machine dependent calls. In theory, we would want
 	 * to call the CPU first, and call the ppc_md. one if the CPU
 	 * one returns a positive number. However there is existing code
@@ -965,6 +967,8 @@ void vsx_unavailable_exception(struct pt_regs *regs)
 
 void performance_monitor_exception(struct pt_regs *regs)
 {
+	__get_cpu_var(irq_stat).pmu_irqs++;
+
 	perf_irq(regs);
 }
 

commit 66fcb1059deeae072c1bf1536a8e2613028bce3e
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Feb 7 14:44:16 2010 +0000

    powerpc: Add last sysfs file and dump of ftrace buffer to oops printout
    
    Add printout of last accessed sysfs file, added to x86 in
    ae87221d3ce49d9de1e43756da834fd0bf05a2ad (sysfs: crash debugging)
    
    Also add the notify_die hook that allows us to print out the ftrace
    buffer on oops. This is useful in conjunction with ftrace function_graph:
    
    Oops: Kernel access of bad area, sig: 11 [#1]
    SMP NR_CPUS=128 NUMA pSeries
    last sysfs file: /sys/class/net/tunl0/type
    Dumping ftrace buffer:
    
    ...
    
      0)               |                .sysrq_handle_crash() {
      0)   0.476 us    |                  .hash_page();
      0)   0.488 us    |                  .xmon_fault_handler();
      0)               |                  .bad_page_fault() {
      0)               |                    .search_exception_tables() {
      0)   0.590 us    |                      .search_module_extables();
      0)   2.546 us    |                    }
      0)               |                    .printk() {
      0)               |                      .vprintk() {
      0)   0.488 us    |                        ._raw_spin_lock();
      0)   0.572 us    |                        .emit_log_char();
    
    Showing the function graph of a sysrq-c crash.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4588d1eb18d2..0a320dbd950a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -146,6 +146,11 @@ int die(const char *str, struct pt_regs *regs, long err)
 #endif
 		printk("%s\n", ppc_md.name ? ppc_md.name : "");
 
+		sysfs_printk_last_file();
+		if (notify_die(DIE_OOPS, str, regs, err, 255,
+			       SIGSEGV) == NOTIFY_STOP)
+			return 1;
+
 		print_modules();
 		show_regs(regs);
 	} else {

commit 5be3492f972b73051ead7ecbac6fb9efd1e8e0ec
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jan 12 00:50:14 2010 +0000

    powerpc: Mark some variables in the page fault path __read_mostly
    
    Using perf to trace L1 dcache misses and dumping data addresses I found a few
    variables taking a lot of misses. Since they are almost never written, they
    should go into the __read_mostly section.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d069ff8a7e03..4588d1eb18d2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -60,13 +60,13 @@
 #endif
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
-int (*__debugger)(struct pt_regs *regs);
-int (*__debugger_ipi)(struct pt_regs *regs);
-int (*__debugger_bpt)(struct pt_regs *regs);
-int (*__debugger_sstep)(struct pt_regs *regs);
-int (*__debugger_iabr_match)(struct pt_regs *regs);
-int (*__debugger_dabr_match)(struct pt_regs *regs);
-int (*__debugger_fault_handler)(struct pt_regs *regs);
+int (*__debugger)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_ipi)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_bpt)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_sstep)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_iabr_match)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_dabr_match)(struct pt_regs *regs) __read_mostly;
+int (*__debugger_fault_handler)(struct pt_regs *regs) __read_mostly;
 
 EXPORT_SYMBOL(__debugger);
 EXPORT_SYMBOL(__debugger_ipi);

commit 25baa35befeebe6a4a8d8d12a4fc5b95918bda54
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:18 2009 -0800

    ptrace: powerpc: implement user_single_step_siginfo()
    
    Suggested by Roland.
    
    Implement user_single_step_siginfo() for powerpc.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 804f0f30f227..d069ff8a7e03 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -174,6 +174,15 @@ int die(const char *str, struct pt_regs *regs, long err)
 	return 0;
 }
 
+void user_single_step_siginfo(struct task_struct *tsk,
+				struct pt_regs *regs, siginfo_t *info)
+{
+	memset(info, 0, sizeof(*info));
+	info->si_signo = SIGTRAP;
+	info->si_code = TRAP_TRACE;
+	info->si_addr = (void __user *)regs->nip;
+}
+
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 {
 	siginfo_t info;

commit bcd6acd51f3d4d1ada201e9bc5c40a31d6d80c71
Merge: 11c34c7deaee 3ff6a468b45b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Dec 9 17:14:38 2009 +1100

    Merge commit 'origin/master' into next
    
    Conflicts:
            include/linux/kvm.h

commit a0592d42fe3e12966db02f5c41f1edae2e59c490
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Nov 10 15:13:15 2009 +0000

    powerpc: kill the obsolete code under is_global_init()
    
    The code under "if (is_global_init())" is bogus, and is_global_init()
    itself is not right in mt case.
    
    Contrary to what the comment says, nowadays force_sig_info() does kill
    init even if the handler is SIG_DFL. Note that force_sig_info() clears
    SIGNAL_UNKILLABLE exactly for this case.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6f0ae1a9bfae..a81c7438d341 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -198,28 +198,6 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	info.si_code = code;
 	info.si_addr = (void __user *) addr;
 	force_sig_info(signr, &info, current);
-
-	/*
-	 * Init gets no signals that it doesn't have a handler for.
-	 * That's all very well, but if it has caused a synchronous
-	 * exception and we ignore the resulting signal, it will just
-	 * generate the same exception over and over again and we get
-	 * nowhere.  Better to kill it and let the kernel panic.
-	 */
-	if (is_global_init(current)) {
-		__sighandler_t handler;
-
-		spin_lock_irq(&current->sighand->siglock);
-		handler = current->sighand->action[signr-1].sa.sa_handler;
-		spin_unlock_irq(&current->sighand->siglock);
-		if (handler == SIG_DFL) {
-			/* init has generated a synchronous exception
-			   and it doesn't have a handler for the signal */
-			printk(KERN_CRIT "init has generated signal %d "
-			       "but has no handler for it\n", signr);
-			do_exit(signr);
-		}
-	}
 }
 
 #ifdef CONFIG_PPC64

commit eecff81d1fcda22cd0029d11fe2a71dceed11dad
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Oct 27 18:46:55 2009 +0000

    powerpc: Create PPC_WARN_ALIGNMENT to match PPC_WARN_EMULATED
    
    perf_event wants a separate event for alignment and emulation faults,
    so create another emulation event.  This will make it easy to hook in
    perf_event at one spot.
    
    We pass in regs which will be required for these events.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6f0ae1a9bfae..9d1f9354d6ca 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -759,7 +759,7 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulate the mfspr rD, PVR. */
 	if ((instword & PPC_INST_MFSPR_PVR_MASK) == PPC_INST_MFSPR_PVR) {
-		PPC_WARN_EMULATED(mfpvr);
+		PPC_WARN_EMULATED(mfpvr, regs);
 		rd = (instword >> 21) & 0x1f;
 		regs->gpr[rd] = mfspr(SPRN_PVR);
 		return 0;
@@ -767,7 +767,7 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulating the dcba insn is just a no-op.  */
 	if ((instword & PPC_INST_DCBA_MASK) == PPC_INST_DCBA) {
-		PPC_WARN_EMULATED(dcba);
+		PPC_WARN_EMULATED(dcba, regs);
 		return 0;
 	}
 
@@ -776,7 +776,7 @@ static int emulate_instruction(struct pt_regs *regs)
 		int shift = (instword >> 21) & 0x1c;
 		unsigned long msk = 0xf0000000UL >> shift;
 
-		PPC_WARN_EMULATED(mcrxr);
+		PPC_WARN_EMULATED(mcrxr, regs);
 		regs->ccr = (regs->ccr & ~msk) | ((regs->xer >> shift) & msk);
 		regs->xer &= ~0xf0000000UL;
 		return 0;
@@ -784,19 +784,19 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulate load/store string insn. */
 	if ((instword & PPC_INST_STRING_GEN_MASK) == PPC_INST_STRING) {
-		PPC_WARN_EMULATED(string);
+		PPC_WARN_EMULATED(string, regs);
 		return emulate_string_inst(regs, instword);
 	}
 
 	/* Emulate the popcntb (Population Count Bytes) instruction. */
 	if ((instword & PPC_INST_POPCNTB_MASK) == PPC_INST_POPCNTB) {
-		PPC_WARN_EMULATED(popcntb);
+		PPC_WARN_EMULATED(popcntb, regs);
 		return emulate_popcntb_inst(regs, instword);
 	}
 
 	/* Emulate isel (Integer Select) instruction */
 	if ((instword & PPC_INST_ISEL_MASK) == PPC_INST_ISEL) {
-		PPC_WARN_EMULATED(isel);
+		PPC_WARN_EMULATED(isel, regs);
 		return emulate_isel(regs, instword);
 	}
 
@@ -995,7 +995,7 @@ void SoftwareEmulation(struct pt_regs *regs)
 #ifdef CONFIG_MATH_EMULATION
 	errcode = do_mathemu(regs);
 	if (errcode >= 0)
-		PPC_WARN_EMULATED(math);
+		PPC_WARN_EMULATED(math, regs);
 
 	switch (errcode) {
 	case 0:
@@ -1018,7 +1018,7 @@ void SoftwareEmulation(struct pt_regs *regs)
 #elif defined(CONFIG_8XX_MINIMAL_FPEMU)
 	errcode = Soft_emulate_8xx(regs);
 	if (errcode >= 0)
-		PPC_WARN_EMULATED(8xx);
+		PPC_WARN_EMULATED(8xx, regs);
 
 	switch (errcode) {
 	case 0:
@@ -1129,7 +1129,7 @@ void altivec_assist_exception(struct pt_regs *regs)
 
 	flush_altivec_to_thread(current);
 
-	PPC_WARN_EMULATED(altivec);
+	PPC_WARN_EMULATED(altivec, regs);
 	err = emulate_altivec(regs);
 	if (err == 0) {
 		regs->nip += 4;		/* skip emulated instruction */

commit ec097c84dff17511f2693e6ef6c3064dfbf0a3af
Author: Roland McGrath <roland@redhat.com>
Date:   Thu May 28 21:26:38 2009 +0000

    powerpc: Add PTRACE_SINGLEBLOCK support
    
    Reworked by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    
    This adds block-step support on powerpc, including a PTRACE_SINGLEBLOCK
    request for ptrace.
    
    The BookE implementation is tweaked to fire a single step after a
    block step in order to mimmic the server behaviour.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6a5b2b731f43..6f0ae1a9bfae 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1041,7 +1041,34 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
-	if (debug_status & DBSR_IC) {	/* instruction completion */
+	/* Hack alert: On BookE, Branch Taken stops on the branch itself, while
+	 * on server, it stops on the target of the branch. In order to simulate
+	 * the server behaviour, we thus restart right away with a single step
+	 * instead of stopping here when hitting a BT
+	 */
+	if (debug_status & DBSR_BT) {
+		regs->msr &= ~MSR_DE;
+
+		/* Disable BT */
+		mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~DBCR0_BT);
+		/* Clear the BT event */
+		mtspr(SPRN_DBSR, DBSR_BT);
+
+		/* Do the single step trick only when coming from userspace */
+		if (user_mode(regs)) {
+			current->thread.dbcr0 &= ~DBCR0_BT;
+			current->thread.dbcr0 |= DBCR0_IDM | DBCR0_IC;
+			regs->msr |= MSR_DE;
+			return;
+		}
+
+		if (notify_die(DIE_SSTEP, "block_step", regs, 5,
+			       5, SIGTRAP) == NOTIFY_STOP) {
+			return;
+		}
+		if (debugger_sstep(regs))
+			return;
+	} else if (debug_status & DBSR_IC) { 	/* Instruction complete */
 		regs->msr &= ~MSR_DE;
 
 		/* Disable instruction completion */
@@ -1057,9 +1084,8 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 		if (debugger_sstep(regs))
 			return;
 
-		if (user_mode(regs)) {
-			current->thread.dbcr0 &= ~DBCR0_IC;
-		}
+		if (user_mode(regs))
+			current->thread.dbcr0 &= ~(DBCR0_IC);
 
 		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
 	} else if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {

commit 80947e7c99c29ce3a78bdc1933b310468455a82f
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Mon May 18 02:10:05 2009 +0000

    powerpc: Keep track of emulated instructions
    
    If CONFIG_PPC_EMULATED_STATS is enabled, make available counters for the
    various classes of emulated instructions under
    /sys/kernel/debug/powerpc/emulated_instructions/ (assumed debugfs is mounted on
    /sys/kernel/debug).  Optionally (controlled by
    /sys/kernel/debug/powerpc/emulated_instructions/do_warn), rate-limited warnings
    can be printed to the console when instructions are emulated.
    
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 678fbff0d206..6a5b2b731f43 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -33,7 +33,9 @@
 #include <linux/backlight.h>
 #include <linux/bug.h>
 #include <linux/kdebug.h>
+#include <linux/debugfs.h>
 
+#include <asm/emulated_ops.h>
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -757,36 +759,44 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulate the mfspr rD, PVR. */
 	if ((instword & PPC_INST_MFSPR_PVR_MASK) == PPC_INST_MFSPR_PVR) {
+		PPC_WARN_EMULATED(mfpvr);
 		rd = (instword >> 21) & 0x1f;
 		regs->gpr[rd] = mfspr(SPRN_PVR);
 		return 0;
 	}
 
 	/* Emulating the dcba insn is just a no-op.  */
-	if ((instword & PPC_INST_DCBA_MASK) == PPC_INST_DCBA)
+	if ((instword & PPC_INST_DCBA_MASK) == PPC_INST_DCBA) {
+		PPC_WARN_EMULATED(dcba);
 		return 0;
+	}
 
 	/* Emulate the mcrxr insn.  */
 	if ((instword & PPC_INST_MCRXR_MASK) == PPC_INST_MCRXR) {
 		int shift = (instword >> 21) & 0x1c;
 		unsigned long msk = 0xf0000000UL >> shift;
 
+		PPC_WARN_EMULATED(mcrxr);
 		regs->ccr = (regs->ccr & ~msk) | ((regs->xer >> shift) & msk);
 		regs->xer &= ~0xf0000000UL;
 		return 0;
 	}
 
 	/* Emulate load/store string insn. */
-	if ((instword & PPC_INST_STRING_GEN_MASK) == PPC_INST_STRING)
+	if ((instword & PPC_INST_STRING_GEN_MASK) == PPC_INST_STRING) {
+		PPC_WARN_EMULATED(string);
 		return emulate_string_inst(regs, instword);
+	}
 
 	/* Emulate the popcntb (Population Count Bytes) instruction. */
 	if ((instword & PPC_INST_POPCNTB_MASK) == PPC_INST_POPCNTB) {
+		PPC_WARN_EMULATED(popcntb);
 		return emulate_popcntb_inst(regs, instword);
 	}
 
 	/* Emulate isel (Integer Select) instruction */
 	if ((instword & PPC_INST_ISEL_MASK) == PPC_INST_ISEL) {
+		PPC_WARN_EMULATED(isel);
 		return emulate_isel(regs, instword);
 	}
 
@@ -984,6 +994,8 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 #ifdef CONFIG_MATH_EMULATION
 	errcode = do_mathemu(regs);
+	if (errcode >= 0)
+		PPC_WARN_EMULATED(math);
 
 	switch (errcode) {
 	case 0:
@@ -1005,6 +1017,9 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 #elif defined(CONFIG_8XX_MINIMAL_FPEMU)
 	errcode = Soft_emulate_8xx(regs);
+	if (errcode >= 0)
+		PPC_WARN_EMULATED(8xx);
+
 	switch (errcode) {
 	case 0:
 		emulate_single_step(regs);
@@ -1088,6 +1103,7 @@ void altivec_assist_exception(struct pt_regs *regs)
 
 	flush_altivec_to_thread(current);
 
+	PPC_WARN_EMULATED(altivec);
 	err = emulate_altivec(regs);
 	if (err == 0) {
 		regs->nip += 4;		/* skip emulated instruction */
@@ -1286,3 +1302,79 @@ void kernel_bad_stack(struct pt_regs *regs)
 void __init trap_init(void)
 {
 }
+
+
+#ifdef CONFIG_PPC_EMULATED_STATS
+
+#define WARN_EMULATED_SETUP(type)	.type = { .name = #type }
+
+struct ppc_emulated ppc_emulated = {
+#ifdef CONFIG_ALTIVEC
+	WARN_EMULATED_SETUP(altivec),
+#endif
+	WARN_EMULATED_SETUP(dcba),
+	WARN_EMULATED_SETUP(dcbz),
+	WARN_EMULATED_SETUP(fp_pair),
+	WARN_EMULATED_SETUP(isel),
+	WARN_EMULATED_SETUP(mcrxr),
+	WARN_EMULATED_SETUP(mfpvr),
+	WARN_EMULATED_SETUP(multiple),
+	WARN_EMULATED_SETUP(popcntb),
+	WARN_EMULATED_SETUP(spe),
+	WARN_EMULATED_SETUP(string),
+	WARN_EMULATED_SETUP(unaligned),
+#ifdef CONFIG_MATH_EMULATION
+	WARN_EMULATED_SETUP(math),
+#elif defined(CONFIG_8XX_MINIMAL_FPEMU)
+	WARN_EMULATED_SETUP(8xx),
+#endif
+#ifdef CONFIG_VSX
+	WARN_EMULATED_SETUP(vsx),
+#endif
+};
+
+u32 ppc_warn_emulated;
+
+void ppc_warn_emulated_print(const char *type)
+{
+	if (printk_ratelimit())
+		pr_warning("%s used emulated %s instruction\n", current->comm,
+			   type);
+}
+
+static int __init ppc_warn_emulated_init(void)
+{
+	struct dentry *dir, *d;
+	unsigned int i;
+	struct ppc_emulated_entry *entries = (void *)&ppc_emulated;
+
+	if (!powerpc_debugfs_root)
+		return -ENODEV;
+
+	dir = debugfs_create_dir("emulated_instructions",
+				 powerpc_debugfs_root);
+	if (!dir)
+		return -ENOMEM;
+
+	d = debugfs_create_u32("do_warn", S_IRUGO | S_IWUSR, dir,
+			       &ppc_warn_emulated);
+	if (!d)
+		goto fail;
+
+	for (i = 0; i < sizeof(ppc_emulated)/sizeof(*entries); i++) {
+		d = debugfs_create_u32(entries[i].name, S_IRUGO | S_IWUSR, dir,
+				       (u32 *)&entries[i].val.counter);
+		if (!d)
+			goto fail;
+	}
+
+	return 0;
+
+fail:
+	debugfs_remove_recursive(dir);
+	return -ENOMEM;
+}
+
+device_initcall(ppc_warn_emulated_init);
+
+#endif /* CONFIG_PPC_EMULATED_STATS */

commit 620165f971753c2c451c880796bac7cd66f3534a
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Feb 12 13:54:53 2009 +0000

    powerpc: Add support for using doorbells for SMP IPI
    
    The e500mc supports the new msgsnd/doorbell mechanisms that were added in
    the Power ISA 2.05 architecture.  We use the normal level doorbell for
    doing SMP IPIs at this point.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 970d66ec4657..678fbff0d206 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -53,6 +53,9 @@
 #endif
 #include <asm/kexec.h>
 #include <asm/ppc-opcode.h>
+#ifdef CONFIG_FSL_BOOKE
+#include <asm/dbell.h>
+#endif
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs);
@@ -1122,6 +1125,24 @@ void vsx_assist_exception(struct pt_regs *regs)
 #endif /* CONFIG_VSX */
 
 #ifdef CONFIG_FSL_BOOKE
+
+void doorbell_exception(struct pt_regs *regs)
+{
+#ifdef CONFIG_SMP
+	int cpu = smp_processor_id();
+	int msg;
+
+	if (num_online_cpus() < 2)
+		return;
+
+	for (msg = 0; msg < 4; msg++)
+		if (test_and_clear_bit(msg, &dbell_smp_message[cpu]))
+			smp_message_recv(msg);
+#else
+	printk(KERN_WARNING "Received doorbell on non-smp system\n");
+#endif
+}
+
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)
 {

commit 16c57b3620d77e0bc981da5ef32beae730512684
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Tue Feb 10 20:10:44 2009 +0000

    powerpc: Unify opcode definitions and support
    
    Create a new header that becomes a single location for defining PowerPC
    opcodes used by code that is either generationg instructions
    at runtime (fixups, debug, etc.), emulating instructions, or just
    compiling instructions old assemblers don't know about.
    
    We currently don't handle the floating point emulation or alignment decode
    as both are better handled by the specific decode support they already
    have.
    
    Added support for the new dcbzl, dcbal, msgsnd, tlbilx, & wait instructions
    since older assemblers don't know about them.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5457e9575685..970d66ec4657 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -52,6 +52,7 @@
 #include <asm/processor.h>
 #endif
 #include <asm/kexec.h>
+#include <asm/ppc-opcode.h>
 
 #if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs);
@@ -637,29 +638,6 @@ static void parse_fpe(struct pt_regs *regs)
  * bits is faster and easier.
  *
  */
-#define INST_MFSPR_PVR		0x7c1f42a6
-#define INST_MFSPR_PVR_MASK	0xfc1fffff
-
-#define INST_DCBA		0x7c0005ec
-#define INST_DCBA_MASK		0xfc0007fe
-
-#define INST_MCRXR		0x7c000400
-#define INST_MCRXR_MASK		0xfc0007fe
-
-#define INST_STRING		0x7c00042a
-#define INST_STRING_MASK	0xfc0007fe
-#define INST_STRING_GEN_MASK	0xfc00067e
-#define INST_LSWI		0x7c0004aa
-#define INST_LSWX		0x7c00042a
-#define INST_STSWI		0x7c0005aa
-#define INST_STSWX		0x7c00052a
-
-#define INST_POPCNTB		0x7c0000f4
-#define INST_POPCNTB_MASK	0xfc0007fe
-
-#define INST_ISEL		0x7c00001e
-#define INST_ISEL_MASK		0xfc00003e
-
 static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 {
 	u8 rT = (instword >> 21) & 0x1f;
@@ -670,20 +648,20 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 	int pos = 0;
 
 	/* Early out if we are an invalid form of lswx */
-	if ((instword & INST_STRING_MASK) == INST_LSWX)
+	if ((instword & PPC_INST_STRING_MASK) == PPC_INST_LSWX)
 		if ((rT == rA) || (rT == NB_RB))
 			return -EINVAL;
 
 	EA = (rA == 0) ? 0 : regs->gpr[rA];
 
-	switch (instword & INST_STRING_MASK) {
-		case INST_LSWX:
-		case INST_STSWX:
+	switch (instword & PPC_INST_STRING_MASK) {
+		case PPC_INST_LSWX:
+		case PPC_INST_STSWX:
 			EA += NB_RB;
 			num_bytes = regs->xer & 0x7f;
 			break;
-		case INST_LSWI:
-		case INST_STSWI:
+		case PPC_INST_LSWI:
+		case PPC_INST_STSWI:
 			num_bytes = (NB_RB == 0) ? 32 : NB_RB;
 			break;
 		default:
@@ -695,9 +673,9 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 		u8 val;
 		u32 shift = 8 * (3 - (pos & 0x3));
 
-		switch ((instword & INST_STRING_MASK)) {
-			case INST_LSWX:
-			case INST_LSWI:
+		switch ((instword & PPC_INST_STRING_MASK)) {
+			case PPC_INST_LSWX:
+			case PPC_INST_LSWI:
 				if (get_user(val, (u8 __user *)EA))
 					return -EFAULT;
 				/* first time updating this reg,
@@ -706,8 +684,8 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 					regs->gpr[rT] = 0;
 				regs->gpr[rT] |= val << shift;
 				break;
-			case INST_STSWI:
-			case INST_STSWX:
+			case PPC_INST_STSWI:
+			case PPC_INST_STSWX:
 				val = regs->gpr[rT] >> shift;
 				if (put_user(val, (u8 __user *)EA))
 					return -EFAULT;
@@ -775,18 +753,18 @@ static int emulate_instruction(struct pt_regs *regs)
 		return -EFAULT;
 
 	/* Emulate the mfspr rD, PVR. */
-	if ((instword & INST_MFSPR_PVR_MASK) == INST_MFSPR_PVR) {
+	if ((instword & PPC_INST_MFSPR_PVR_MASK) == PPC_INST_MFSPR_PVR) {
 		rd = (instword >> 21) & 0x1f;
 		regs->gpr[rd] = mfspr(SPRN_PVR);
 		return 0;
 	}
 
 	/* Emulating the dcba insn is just a no-op.  */
-	if ((instword & INST_DCBA_MASK) == INST_DCBA)
+	if ((instword & PPC_INST_DCBA_MASK) == PPC_INST_DCBA)
 		return 0;
 
 	/* Emulate the mcrxr insn.  */
-	if ((instword & INST_MCRXR_MASK) == INST_MCRXR) {
+	if ((instword & PPC_INST_MCRXR_MASK) == PPC_INST_MCRXR) {
 		int shift = (instword >> 21) & 0x1c;
 		unsigned long msk = 0xf0000000UL >> shift;
 
@@ -796,16 +774,16 @@ static int emulate_instruction(struct pt_regs *regs)
 	}
 
 	/* Emulate load/store string insn. */
-	if ((instword & INST_STRING_GEN_MASK) == INST_STRING)
+	if ((instword & PPC_INST_STRING_GEN_MASK) == PPC_INST_STRING)
 		return emulate_string_inst(regs, instword);
 
 	/* Emulate the popcntb (Population Count Bytes) instruction. */
-	if ((instword & INST_POPCNTB_MASK) == INST_POPCNTB) {
+	if ((instword & PPC_INST_POPCNTB_MASK) == PPC_INST_POPCNTB) {
 		return emulate_popcntb_inst(regs, instword);
 	}
 
 	/* Emulate isel (Integer Select) instruction */
-	if ((instword & INST_ISEL_MASK) == INST_ISEL) {
+	if ((instword & PPC_INST_ISEL_MASK) == PPC_INST_ISEL) {
 		return emulate_isel(regs, instword);
 	}
 

commit 6a800f36acd5bf06b5fe2cb27c4d0524d60c3df5
Author: Liu Yu <yu.liu@freescale.com>
Date:   Tue Oct 28 11:50:21 2008 +0800

    powerpc: Add SPE/EFP math emulation for E500v1/v2 processors.
    
    This patch add the handlers of SPE/EFP exceptions.
    The code is used to emulate float point arithmetic,
    when MSR(SPE) is enabled and receive EFP data interrupt or EFP round interrupt.
    
    This patch has no conflict with or dependence on FP math-emu.
    
    The code has been tested by TestFloat.
    
    Now the code doesn't support SPE/EFP instructions emulation
    (it won't be called when receive program interrupt),
    but it could be easily added.
    
    Signed-off-by: Liu Yu <yu.liu@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f5def6cf5cd6..5457e9575685 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1160,37 +1160,85 @@ void CacheLockingException(struct pt_regs *regs, unsigned long address,
 #ifdef CONFIG_SPE
 void SPEFloatingPointException(struct pt_regs *regs)
 {
+	extern int do_spe_mathemu(struct pt_regs *regs);
 	unsigned long spefscr;
 	int fpexc_mode;
 	int code = 0;
+	int err;
+
+	preempt_disable();
+	if (regs->msr & MSR_SPE)
+		giveup_spe(current);
+	preempt_enable();
 
 	spefscr = current->thread.spefscr;
 	fpexc_mode = current->thread.fpexc_mode;
 
-	/* Hardware does not neccessarily set sticky
-	 * underflow/overflow/invalid flags */
 	if ((spefscr & SPEFSCR_FOVF) && (fpexc_mode & PR_FP_EXC_OVF)) {
 		code = FPE_FLTOVF;
-		spefscr |= SPEFSCR_FOVFS;
 	}
 	else if ((spefscr & SPEFSCR_FUNF) && (fpexc_mode & PR_FP_EXC_UND)) {
 		code = FPE_FLTUND;
-		spefscr |= SPEFSCR_FUNFS;
 	}
 	else if ((spefscr & SPEFSCR_FDBZ) && (fpexc_mode & PR_FP_EXC_DIV))
 		code = FPE_FLTDIV;
 	else if ((spefscr & SPEFSCR_FINV) && (fpexc_mode & PR_FP_EXC_INV)) {
 		code = FPE_FLTINV;
-		spefscr |= SPEFSCR_FINVS;
 	}
 	else if ((spefscr & (SPEFSCR_FG | SPEFSCR_FX)) && (fpexc_mode & PR_FP_EXC_RES))
 		code = FPE_FLTRES;
 
-	current->thread.spefscr = spefscr;
+	err = do_spe_mathemu(regs);
+	if (err == 0) {
+		regs->nip += 4;		/* skip emulated instruction */
+		emulate_single_step(regs);
+		return;
+	}
+
+	if (err == -EFAULT) {
+		/* got an error reading the instruction */
+		_exception(SIGSEGV, regs, SEGV_ACCERR, regs->nip);
+	} else if (err == -EINVAL) {
+		/* didn't recognize the instruction */
+		printk(KERN_ERR "unrecognized spe instruction "
+		       "in %s at %lx\n", current->comm, regs->nip);
+	} else {
+		_exception(SIGFPE, regs, code, regs->nip);
+	}
 
-	_exception(SIGFPE, regs, code, regs->nip);
 	return;
 }
+
+void SPEFloatingPointRoundException(struct pt_regs *regs)
+{
+	extern int speround_handler(struct pt_regs *regs);
+	int err;
+
+	preempt_disable();
+	if (regs->msr & MSR_SPE)
+		giveup_spe(current);
+	preempt_enable();
+
+	regs->nip -= 4;
+	err = speround_handler(regs);
+	if (err == 0) {
+		regs->nip += 4;		/* skip emulated instruction */
+		emulate_single_step(regs);
+		return;
+	}
+
+	if (err == -EFAULT) {
+		/* got an error reading the instruction */
+		_exception(SIGSEGV, regs, SEGV_ACCERR, regs->nip);
+	} else if (err == -EINVAL) {
+		/* didn't recognize the instruction */
+		printk(KERN_ERR "unrecognized spe instruction "
+		       "in %s at %lx\n", current->comm, regs->nip);
+	} else {
+		_exception(SIGFPE, regs, 0, regs->nip);
+		return;
+	}
+}
 #endif
 
 /*

commit 9d5a9e74655b9d04d0ec9c8e47801163b7b74211
Author: Adrian Bunk <bunk@kernel.org>
Date:   Sat Jun 28 00:12:52 2008 +0300

    Remove asm/a.out.h files for all architectures without a.out support.
    
    This patch also includes the required removal of (unused) inclusion of
    <asm/a.out.h> <linux/a.out.h>'s in the arch/ code for these
    architectures.
    
    [dwmw2: updated for 2.6.27-rc]
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 81ccb8dd1a54..f5def6cf5cd6 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -23,7 +23,6 @@
 #include <linux/ptrace.h>
 #include <linux/slab.h>
 #include <linux/user.h>
-#include <linux/a.out.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
 #include <linux/module.h>

commit d6a61bfc06d6f2248f3e75f208d64e794082013c
Author: Luis Machado <luisgpm@linux.vnet.ibm.com>
Date:   Thu Jul 24 02:10:41 2008 +1000

    powerpc: BookE hardware watchpoint support
    
    This patch implements support for HW based watchpoint via the
    DBSR_DAC (Data Address Compare) facility of the BookE processors.
    
    It does so by interfacing with the existing DABR breakpoint code
    and adding the necessary bits and pieces for the new bits to
    be properly set or cleared
    
    Signed-off-by: Luis Machado <luisgpm@br.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 878fbddb6ae1..81ccb8dd1a54 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1067,6 +1067,22 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 		}
 
 		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
+	} else if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
+		regs->msr &= ~MSR_DE;
+
+		if (user_mode(regs)) {
+			current->thread.dbcr0 &= ~(DBSR_DAC1R | DBSR_DAC1W |
+								DBCR0_IDM);
+		} else {
+			/* Disable DAC interupts */
+			mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~(DBSR_DAC1R |
+						DBSR_DAC1W | DBCR0_IDM));
+
+			/* Clear the DAC event */
+			mtspr(SPRN_DBSR, (DBSR_DAC1R | DBSR_DAC1W));
+		}
+		/* Setup and send the trap to the handler */
+		do_dabr(regs, mfspr(SPRN_DAC1), debug_status);
 	}
 }
 #endif /* CONFIG_4xx || CONFIG_BOOKE */

commit ce48b2100785e5ca629fb3aa8e3b50aca808f692
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Jun 25 14:07:18 2008 +1000

    powerpc: Add VSX context save/restore, ptrace and signal support
    
    This patch extends the floating point save and restore code to use the
    VSX load/stores when VSX is available.  This will make FP context
    save/restore marginally slower on FP only code, when VSX is available,
    as it has to load/store 128bits rather than just 64bits.
    
    Mixing FP, VMX and VSX code will get constant architected state.
    
    The signals interface is extended to enable access to VSR 0-31
    doubleword 1 after discussions with tool chain maintainers.  Backward
    compatibility is maintained.
    
    The ptrace interface is also extended to allow access to VSR 0-31 full
    registers.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index b463d48145a4..878fbddb6ae1 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -967,6 +967,20 @@ void altivec_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
 }
 
+void vsx_unavailable_exception(struct pt_regs *regs)
+{
+	if (user_mode(regs)) {
+		/* A user program has executed an vsx instruction,
+		   but this kernel doesn't support vsx. */
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	}
+
+	printk(KERN_EMERG "Unrecoverable VSX Unavailable Exception "
+			"%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable VSX Unavailable Exception", regs, SIGABRT);
+}
+
 void performance_monitor_exception(struct pt_regs *regs)
 {
 	perf_irq(regs);
@@ -1099,6 +1113,21 @@ void altivec_assist_exception(struct pt_regs *regs)
 }
 #endif /* CONFIG_ALTIVEC */
 
+#ifdef CONFIG_VSX
+void vsx_assist_exception(struct pt_regs *regs)
+{
+	if (!user_mode(regs)) {
+		printk(KERN_EMERG "VSX assist exception in kernel mode"
+		       " at %lx\n", regs->nip);
+		die("Kernel VSX assist exception", regs, SIGILL);
+	}
+
+	flush_vsx_to_thread(current);
+	printk(KERN_INFO "VSX assist not supported at %lx\n", regs->nip);
+	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+}
+#endif /* CONFIG_VSX */
+
 #ifdef CONFIG_FSL_BOOKE
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)

commit f82796214a95b1ec00c2f121c1080d10f2b099a1
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Jun 26 02:01:37 2008 -0500

    powerpc/booke: Add kprobes support for booke style processors
    
    This patch is based on work done by Madhvesh. R. Sulibhavi back in
    March 2007.
    
    We refactor some of the single step handling since it differs between
    "classic" and "booke" powerpc cores.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4b5b7ff4f78b..b463d48145a4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1030,21 +1030,29 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 #if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
 
-void DebugException(struct pt_regs *regs, unsigned long debug_status)
+void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
 	if (debug_status & DBSR_IC) {	/* instruction completion */
 		regs->msr &= ~MSR_DE;
+
+		/* Disable instruction completion */
+		mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~DBCR0_IC);
+		/* Clear the instruction completion event */
+		mtspr(SPRN_DBSR, DBSR_IC);
+
+		if (notify_die(DIE_SSTEP, "single_step", regs, 5,
+			       5, SIGTRAP) == NOTIFY_STOP) {
+			return;
+		}
+
+		if (debugger_sstep(regs))
+			return;
+
 		if (user_mode(regs)) {
 			current->thread.dbcr0 &= ~DBCR0_IC;
-		} else {
-			/* Disable instruction completion */
-			mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~DBCR0_IC);
-			/* Clear the instruction completion event */
-			mtspr(SPRN_DBSR, DBSR_IC);
-			if (debugger_sstep(regs))
-				return;
 		}
-		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
+
+		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
 	}
 }
 #endif /* CONFIG_4xx || CONFIG_BOOKE */

commit 7dbb922cea70897dd0e76c6cf8a300b061ca2531
Author: Olof Johansson <olof@lixom.net>
Date:   Thu Jan 31 14:34:47 2008 +1100

    [POWERPC] Fix compilation for CONFIG_DEBUGGER=n and CONFIG_KEXEC=y
    
    Looks like "[POWERPC] kdump shutdown hook support" broke builds when
    CONFIG_DEBUGGER=n and CONFIG_KEXEC=y, such as in g5_defconfig:
    
    arch/powerpc/kernel/crash.c: In function 'default_machine_crash_shutdown':
    arch/powerpc/kernel/crash.c:388: error: '__debugger_fault_handler' undeclared (first use in this function)
    arch/powerpc/kernel/crash.c:388: error: (Each undeclared identifier is reported only once
    arch/powerpc/kernel/crash.c:388: error: for each function it appears in.)
    
    Move the debugger hooks to under CONFIG_DEBUGGER || CONFIG_KEXEC, since
    that's when the crash code is enabled.
    
    (I should have caught this with my build-script pre-merge, my bad. :( )
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 848a20475db8..4b5b7ff4f78b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -54,7 +54,7 @@
 #endif
 #include <asm/kexec.h>
 
-#ifdef CONFIG_DEBUGGER
+#if defined(CONFIG_DEBUGGER) || defined(CONFIG_KEXEC)
 int (*__debugger)(struct pt_regs *regs);
 int (*__debugger_ipi)(struct pt_regs *regs);
 int (*__debugger_bpt)(struct pt_regs *regs);

commit 47c0bd1ae24c34e851cf0f2b02ef2a6847d7ae15
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Dec 21 15:39:21 2007 +1100

    [POWERPC] Reworking machine check handling and Fix 440/440A
    
    This adds a cputable function pointer for the CPU-side machine
    check handling. The semantic is still the same as the old one,
    the one in ppc_md. overrides the one in cputable, though
    ultimately we'll want to change that so the CPU gets first.
    
    This removes CONFIG_440A which was a problem for multiplatform
    kernels and instead fixes up the IVOR at runtime from a setup_cpu
    function. The "A" version of the machine check also tweaks the
    regs->trap value to differenciate the 2 versions at the C level.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index cad64840fce4..848a20475db8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -334,18 +334,25 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
-static int generic_machine_check_exception(struct pt_regs *regs)
+#if defined(CONFIG_4xx)
+int machine_check_4xx(struct pt_regs *regs)
 {
 	unsigned long reason = get_mc_reason(regs);
 
-#if defined(CONFIG_4xx) && !defined(CONFIG_440A)
 	if (reason & ESR_IMCP) {
 		printk("Instruction");
 		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
 	} else
 		printk("Data");
 	printk(" machine check in kernel mode.\n");
-#elif defined(CONFIG_440A)
+
+	return 0;
+}
+
+int machine_check_440A(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+
 	printk("Machine check in kernel mode.\n");
 	if (reason & ESR_IMCP){
 		printk("Instruction Synchronous Machine Check exception\n");
@@ -375,7 +382,13 @@ static int generic_machine_check_exception(struct pt_regs *regs)
 		/* Clear MCSR */
 		mtspr(SPRN_MCSR, mcsr);
 	}
-#elif defined (CONFIG_E500)
+	return 0;
+}
+#elif defined(CONFIG_E500)
+int machine_check_e500(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from MCSR=%lx): ", reason);
 
@@ -403,7 +416,14 @@ static int generic_machine_check_exception(struct pt_regs *regs)
 		printk("Bus - Instruction Parity Error\n");
 	if (reason & MCSR_BUS_RPERR)
 		printk("Bus - Read Parity Error\n");
-#elif defined (CONFIG_E200)
+
+	return 0;
+}
+#elif defined(CONFIG_E200)
+int machine_check_e200(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from MCSR=%lx): ", reason);
 
@@ -421,7 +441,14 @@ static int generic_machine_check_exception(struct pt_regs *regs)
 		printk("Bus - Read Bus Error on data load\n");
 	if (reason & MCSR_BUS_WRERR)
 		printk("Bus - Write Bus Error on buffered store or cache line push\n");
-#else /* !CONFIG_4xx && !CONFIG_E500 && !CONFIG_E200 */
+
+	return 0;
+}
+#else
+int machine_check_generic(struct pt_regs *regs)
+{
+	unsigned long reason = get_mc_reason(regs);
+
 	printk("Machine check in kernel mode.\n");
 	printk("Caused by (from SRR1=%lx): ", reason);
 	switch (reason & 0x601F0000) {
@@ -451,22 +478,26 @@ static int generic_machine_check_exception(struct pt_regs *regs)
 	default:
 		printk("Unknown values in msr\n");
 	}
-#endif /* CONFIG_4xx */
-
 	return 0;
 }
+#endif /* everything else */
 
 void machine_check_exception(struct pt_regs *regs)
 {
 	int recover = 0;
 
-	/* See if any machine dependent calls */
+	/* See if any machine dependent calls. In theory, we would want
+	 * to call the CPU first, and call the ppc_md. one if the CPU
+	 * one returns a positive number. However there is existing code
+	 * that assumes the board gets a first chance, so let's keep it
+	 * that way for now and fix things later. --BenH.
+	 */
 	if (ppc_md.machine_check_exception)
 		recover = ppc_md.machine_check_exception(regs);
-	else
-		recover = generic_machine_check_exception(regs);
+	else if (cur_cpu_spec->machine_check)
+		recover = cur_cpu_spec->machine_check(regs);
 
-	if (recover)
+	if (recover > 0)
 		return;
 
 	if (user_mode(regs)) {
@@ -476,7 +507,12 @@ void machine_check_exception(struct pt_regs *regs)
 	}
 
 #if defined(CONFIG_8xx) && defined(CONFIG_PCI)
-	/* the qspan pci read routines can cause machine checks -- Cort */
+	/* the qspan pci read routines can cause machine checks -- Cort
+	 *
+	 * yuck !!! that totally needs to go away ! There are better ways
+	 * to deal with that than having a wart in the mcheck handler.
+	 * -- BenH
+	 */
 	bad_page_fault(regs, regs->dar, SIGBUS);
 	return;
 #endif

commit c1469f13de275fc92b051328ea5764a32a5a43c9
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Mon Nov 19 21:35:29 2007 -0600

    [POWERPC] Emulate isel (Integer Select) instruction
    
    isel (Integer Select) is a new user space instruction in the
    PowerISA 2.04 spec.  Not all processors implement it so lets emulate
    to ensure code built with isel will run everywhere.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 59c464e26f38..cad64840fce4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -622,6 +622,9 @@ static void parse_fpe(struct pt_regs *regs)
 #define INST_POPCNTB		0x7c0000f4
 #define INST_POPCNTB_MASK	0xfc0007fe
 
+#define INST_ISEL		0x7c00001e
+#define INST_ISEL_MASK		0xfc00003e
+
 static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 {
 	u8 rT = (instword >> 21) & 0x1f;
@@ -707,6 +710,23 @@ static int emulate_popcntb_inst(struct pt_regs *regs, u32 instword)
 	return 0;
 }
 
+static int emulate_isel(struct pt_regs *regs, u32 instword)
+{
+	u8 rT = (instword >> 21) & 0x1f;
+	u8 rA = (instword >> 16) & 0x1f;
+	u8 rB = (instword >> 11) & 0x1f;
+	u8 BC = (instword >> 6) & 0x1f;
+	u8 bit;
+	unsigned long tmp;
+
+	tmp = (rA == 0) ? 0 : regs->gpr[rA];
+	bit = (regs->ccr >> (31 - BC)) & 0x1;
+
+	regs->gpr[rT] = bit ? tmp : regs->gpr[rB];
+
+	return 0;
+}
+
 static int emulate_instruction(struct pt_regs *regs)
 {
 	u32 instword;
@@ -749,6 +769,11 @@ static int emulate_instruction(struct pt_regs *regs)
 		return emulate_popcntb_inst(regs, instword);
 	}
 
+	/* Emulate isel (Integer Select) instruction */
+	if ((instword & INST_ISEL_MASK) == INST_ISEL) {
+		return emulate_isel(regs, instword);
+	}
+
 	return -EINVAL;
 }
 

commit 19c5870c0eefd27c6d09d867465e0571262e05d0
Author: Alexey Dobriyan <adobriyan@openvz.org>
Date:   Thu Oct 18 23:40:41 2007 -0700

    Use helpers to obtain task pid in printks (arch code)
    
    One of the easiest things to isolate is the pid printed in kernel log.
    There was a patch, that made this for arch-independent code, this one makes
    so for arch/xxx files.
    
    It took some time to cross-compile it, but hopefully these are all the
    printks in arch code.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9fb4a6849c5a..59c464e26f38 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -881,7 +881,7 @@ void nonrecoverable_exception(struct pt_regs *regs)
 void trace_syscall(struct pt_regs *regs)
 {
 	printk("Task: %p(%d), PC: %08lX/%08lX, Syscall: %3ld, Result: %s%ld    %s\n",
-	       current, current->pid, regs->nip, regs->link, regs->gpr[0],
+	       current, task_pid_nr(current), regs->nip, regs->link, regs->gpr[0],
 	       regs->ccr&0x10000000?"Error=":"", regs->gpr[3], print_tainted());
 }
 

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bf9e39c6e296..9fb4a6849c5a 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -201,7 +201,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	 * generate the same exception over and over again and we get
 	 * nowhere.  Better to kill it and let the kernel panic.
 	 */
-	if (is_init(current)) {
+	if (is_global_init(current)) {
 		__sighandler_t handler;
 
 		spin_lock_irq(&current->sighand->siglock);

commit d0c3d534a4388a465101b634a95f2ec586415254
Author: Olof Johansson <olof@lixom.net>
Date:   Fri Oct 12 10:20:07 2007 +1000

    [POWERPC] Implement logging of unhandled signals
    
    Implement show_unhandled_signals sysctl + support to print when a process
    is killed due to unhandled signals just as i386 and x86_64 does.
    
    Default to having it off, unlike x86 that defaults on.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2f1857c9819f..bf9e39c6e296 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -172,11 +172,21 @@ int die(const char *str, struct pt_regs *regs, long err)
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 {
 	siginfo_t info;
+	const char fmt32[] = KERN_INFO "%s[%d]: unhandled signal %d " \
+			"at %08lx nip %08lx lr %08lx code %x\n";
+	const char fmt64[] = KERN_INFO "%s[%d]: unhandled signal %d " \
+			"at %016lx nip %016lx lr %016lx code %x\n";
 
 	if (!user_mode(regs)) {
 		if (die("Exception in kernel mode", regs, signr))
 			return;
-	}
+	} else if (show_unhandled_signals &&
+		    unhandled_signal(current, signr) &&
+		    printk_ratelimit()) {
+			printk(regs->msr & MSR_SF ? fmt64 : fmt32,
+				current->comm, current->pid, signr,
+				addr, regs->nip, regs->link, code);
+		}
 
 	memset(&info, 0, sizeof(info));
 	info.si_signo = signr;

commit 5dd57a1308a7e40e04fb6ecbff170df7a0b92cd8
Author: Scott Wood <scottwood@freescale.com>
Date:   Tue Sep 18 15:29:35 2007 -0500

    [POWERPC] 8xx: Move softemu8xx.c from arch/ppc
    
    Previously, Soft_emulate_8xx was called with no implementation, resulting in
    build failures whenever building 8xx without math emulation.  The
    implementation is copied from arch/ppc to resolve this issue.
    
    However, this sort of minimal emulation is not a very good idea other than
    for compatibility with existing userspaces, as it's less efficient than
    soft-float and can mislead users into believing they have soft-float.  Thus,
    it is made a configurable option, off by default.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5a49eabd492e..2f1857c9819f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -906,7 +906,9 @@ void SoftwareEmulation(struct pt_regs *regs)
 {
 	extern int do_mathemu(struct pt_regs *);
 	extern int Soft_emulate_8xx(struct pt_regs *);
+#if defined(CONFIG_MATH_EMULATION) || defined(CONFIG_8XX_MINIMAL_FPEMU)
 	int errcode;
+#endif
 
 	CHECK_FULL_REGS(regs);
 
@@ -936,7 +938,7 @@ void SoftwareEmulation(struct pt_regs *regs)
 		return;
 	}
 
-#else
+#elif defined(CONFIG_8XX_MINIMAL_FPEMU)
 	errcode = Soft_emulate_8xx(regs);
 	switch (errcode) {
 	case 0:
@@ -949,6 +951,8 @@ void SoftwareEmulation(struct pt_regs *regs)
 		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
 		return;
 	}
+#else
+	_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 #endif
 }
 #endif /* CONFIG_8xx */

commit 75918a4b5998c93ee1ab131fbe64b97b5d0d2315
Author: Olof Johansson <olof@lixom.net>
Date:   Fri Sep 21 05:11:20 2007 +1000

    [POWERPC] Separate out legacy machine check exception parsers
    
    Move out the old-style exception parsers to a separate function, and
    don't call it on platforms that have a platform-specific handler.
    
    It would make sense to move out the generic versions into their platforms
    instead, but that can be done gradually down the road.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index ccfc99dad061..5a49eabd492e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -324,38 +324,10 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
-void machine_check_exception(struct pt_regs *regs)
+static int generic_machine_check_exception(struct pt_regs *regs)
 {
-	int recover = 0;
 	unsigned long reason = get_mc_reason(regs);
 
-	/* See if any machine dependent calls */
-	if (ppc_md.machine_check_exception)
-		recover = ppc_md.machine_check_exception(regs);
-
-	if (recover)
-		return;
-
-	if (user_mode(regs)) {
-		regs->msr |= MSR_RI;
-		_exception(SIGBUS, regs, BUS_ADRERR, regs->nip);
-		return;
-	}
-
-#if defined(CONFIG_8xx) && defined(CONFIG_PCI)
-	/* the qspan pci read routines can cause machine checks -- Cort */
-	bad_page_fault(regs, regs->dar, SIGBUS);
-	return;
-#endif
-
-	if (debugger_fault_handler(regs)) {
-		regs->msr |= MSR_RI;
-		return;
-	}
-
-	if (check_io_access(regs))
-		return;
-
 #if defined(CONFIG_4xx) && !defined(CONFIG_440A)
 	if (reason & ESR_IMCP) {
 		printk("Instruction");
@@ -471,6 +443,42 @@ void machine_check_exception(struct pt_regs *regs)
 	}
 #endif /* CONFIG_4xx */
 
+	return 0;
+}
+
+void machine_check_exception(struct pt_regs *regs)
+{
+	int recover = 0;
+
+	/* See if any machine dependent calls */
+	if (ppc_md.machine_check_exception)
+		recover = ppc_md.machine_check_exception(regs);
+	else
+		recover = generic_machine_check_exception(regs);
+
+	if (recover)
+		return;
+
+	if (user_mode(regs)) {
+		regs->msr |= MSR_RI;
+		_exception(SIGBUS, regs, BUS_ADRERR, regs->nip);
+		return;
+	}
+
+#if defined(CONFIG_8xx) && defined(CONFIG_PCI)
+	/* the qspan pci read routines can cause machine checks -- Cort */
+	bad_page_fault(regs, regs->dar, SIGBUS);
+	return;
+#endif
+
+	if (debugger_fault_handler(regs)) {
+		regs->msr |= MSR_RI;
+		return;
+	}
+
+	if (check_io_access(regs))
+		return;
+
 	if (debugger_fault_handler(regs))
 		return;
 	die("Machine check", regs, SIGBUS);

commit 01f1c735f57548e6b862e815cc845e452405643d
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Sep 5 12:41:09 2007 +1000

    [POWERPC] Remove unused platform_machine_check()
    
    Remove leftover cruft from ARCH=ppc.
    
    There are no users of platform_machine_check() in ARCH=powerpc, and none
    should be added (they should use ppc_md.machine_check_handler instead).
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d8502e377518..ccfc99dad061 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -324,15 +324,6 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
-/*
- * This is "fall-back" implementation for configurations
- * which don't provide platform-specific machine check info
- */
-void __attribute__ ((weak))
-platform_machine_check(struct pt_regs *regs)
-{
-}
-
 void machine_check_exception(struct pt_regs *regs)
 {
 	int recover = 0;
@@ -480,12 +471,6 @@ void machine_check_exception(struct pt_regs *regs)
 	}
 #endif /* CONFIG_4xx */
 
-	/*
-	 * Optional platform-provided routine to print out
-	 * additional info, e.g. bus error registers.
-	 */
-	platform_machine_check(regs);
-
 	if (debugger_fault_handler(regs))
 		return;
 	die("Machine check", regs, SIGBUS);

commit 86d7a9a9c4775f864e6bc5f5da66ef9ea3715734
Author: Becky Bruce <becky.bruce@freescale.com>
Date:   Thu Aug 2 15:37:15 2007 -0500

    [POWERPC] Fix FSL BookE machine check reporting
    
    Reserved MCSR bits on FSL BookE parts may have spurious values
    when mcheck occurs.  Mask these off when printing the MCSR to
    avoid confusion.  Also, get rid of the MCSR_GL_CI bit defined
    for e500 - this bit doesn't actually have any meaning.
    
    Signed-off-by: Becky Bruce <becky.bruce@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2bb1cb911783..d8502e377518 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -299,7 +299,7 @@ static inline int check_io_access(struct pt_regs *regs)
 #ifndef CONFIG_FSL_BOOKE
 #define get_mc_reason(regs)	((regs)->dsisr)
 #else
-#define get_mc_reason(regs)	(mfspr(SPRN_MCSR))
+#define get_mc_reason(regs)	(mfspr(SPRN_MCSR) & MCSR_MASK)
 #endif
 #define REASON_FP		ESR_FP
 #define REASON_ILLEGAL		(ESR_PIL | ESR_PUO)
@@ -414,8 +414,6 @@ void machine_check_exception(struct pt_regs *regs)
 		printk("Data Cache Push Parity Error\n");
 	if (reason & MCSR_DCPERR)
 		printk("Data Cache Parity Error\n");
-	if (reason & MCSR_GL_CI)
-		printk("Guarded Load or Cache-Inhibited stwcx.\n");
 	if (reason & MCSR_BUS_IAERR)
 		printk("Bus - Instruction Address Error\n");
 	if (reason & MCSR_BUS_RAERR)

commit bcdcd8e725b923ad7c0de809680d5d5658a7bf8c
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Tue Jul 17 04:03:42 2007 -0700

    Report that kernel is tainted if there was an OOPS
    
    If the kernel OOPSed or BUGed then it probably should be considered as
    tainted.  Thus, all subsequent OOPSes and SysRq dumps will report the
    tainted kernel.  This saves a lot of time explaining oddities in the
    calltraces.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Acked-by: Randy Dunlap <randy.dunlap@oracle.com>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    [ Added parisc patch from Matthew Wilson  -Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 3b8427e6283d..2bb1cb911783 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -149,6 +149,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 
 	bust_spinlocks(0);
 	die.lock_owner = -1;
+	add_taint(TAINT_DIE);
 	spin_unlock_irqrestore(&die.lock, flags);
 
 	if (kexec_should_crash(current) ||

commit 608e2619682e951f525b08e7a48669a3c0263b41
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Jul 15 23:41:39 2007 -0700

    generic bug: use show_regs() instead of dump_stack()
    
    The current generic bug implementation has a call to dump_stack() in case a
    WARN_ON(whatever) gets hit.  Since report_bug(), which calls dump_stack(),
    gets called from an exception handler we can do better: just pass the
    pt_regs structure to report_bug() and pass it to show_regs() in case of a
    warning.  This will give more debug informations like register contents,
    etc...  In addition this avoids some pointless lines that dump_stack()
    emits, since it includes a stack backtrace of the exception handler which
    is of no interest in case of a warning.  E.g.  on s390 the following lines
    are currently always present in a stack backtrace if dump_stack() gets
    called from report_bug():
    
     [<000000000001517a>] show_trace+0x92/0xe8)
     [<0000000000015270>] show_stack+0xa0/0xd0
     [<00000000000152ce>] dump_stack+0x2e/0x3c
     [<0000000000195450>] report_bug+0x98/0xf8
     [<0000000000016cc8>] illegal_op+0x1fc/0x21c
     [<00000000000227d6>] sysc_return+0x0/0x10
    
    Acked-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Acked-by: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: Kyle McMartin <kyle@parisc-linux.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bf6445ac9f1c..3b8427e6283d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -777,7 +777,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 			return;
 
 		if (!(regs->msr & MSR_PR) &&  /* not user-mode */
-		    report_bug(regs->nip) == BUG_TRAP_TYPE_WARN) {
+		    report_bug(regs->nip, regs) == BUG_TRAP_TYPE_WARN) {
 			regs->nip += 4;
 			return;
 		}

commit 1eeb66a1bb973534dc3d064920a5ca683823372e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 8 00:27:03 2007 -0700

    move die notifier handling to common code
    
    This patch moves the die notifier handling to common code.  Previous
    various architectures had exactly the same code for it.  Note that the new
    code is compiled unconditionally, this should be understood as an appel to
    the other architecture maintainer to implement support for it aswell (aka
    sprinkling a notify_die or two in the proper place)
    
    arm had a notifiy_die that did something totally different, I renamed it to
    arm_notify_die as part of the patch and made it static to the file it's
    declared and used at.  avr32 used to pass slightly less information through
    this interface and I brought it into line with the other architectures.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix vmalloc_sync_all bustage]
    [bryan.wu@analog.com: fix vmalloc_sync_all in nommu]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Bryan Wu <bryan.wu@analog.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f7862224fe85..bf6445ac9f1c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -33,8 +33,8 @@
 #include <linux/kexec.h>
 #include <linux/backlight.h>
 #include <linux/bug.h>
+#include <linux/kdebug.h>
 
-#include <asm/kdebug.h>
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -72,20 +72,6 @@ EXPORT_SYMBOL(__debugger_dabr_match);
 EXPORT_SYMBOL(__debugger_fault_handler);
 #endif
 
-ATOMIC_NOTIFIER_HEAD(powerpc_die_chain);
-
-int register_die_notifier(struct notifier_block *nb)
-{
-	return atomic_notifier_chain_register(&powerpc_die_chain, nb);
-}
-EXPORT_SYMBOL(register_die_notifier);
-
-int unregister_die_notifier(struct notifier_block *nb)
-{
-	return atomic_notifier_chain_unregister(&powerpc_die_chain, nb);
-}
-EXPORT_SYMBOL(unregister_die_notifier);
-
 /*
  * Trap & Exception support
  */

commit ae7f4463773dafac52d70c9803f283afe27ab1e3
Author: anton@samba.org <anton@samba.org>
Date:   Tue Mar 20 20:38:14 2007 -0500

    [POWERPC] Fix backwards ? : when printing machine type
    
    Looks like someone got this backwards, highlighting the perils of the
    ? : !!! :)
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 55d221ffcf1e..f7862224fe85 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -153,7 +153,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 #ifdef CONFIG_NUMA
 		printk("NUMA ");
 #endif
-		printk("%s\n", ppc_md.name ? "" : ppc_md.name);
+		printk("%s\n", ppc_md.name ? ppc_md.name : "");
 
 		print_modules();
 		show_regs(regs);

commit 34c2a14fc20e4ab878fbf87e5f7fe1cff6afb3d4
Author: anton@samba.org <anton@samba.org>
Date:   Tue Mar 20 20:38:13 2007 -0500

    [POWERPC] Handle recursive oopses
    
    Handle recursive oopses, like on x86. We had a few cases recently where
    we locked up in oops printing and didnt make it into crashdump.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6297da743db9..55d221ffcf1e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -108,42 +108,62 @@ static void pmac_backlight_unblank(void)
 static inline void pmac_backlight_unblank(void) { }
 #endif
 
-static DEFINE_SPINLOCK(die_lock);
-
 int die(const char *str, struct pt_regs *regs, long err)
 {
+	static struct {
+		spinlock_t lock;
+		u32 lock_owner;
+		int lock_owner_depth;
+	} die = {
+		.lock =			__SPIN_LOCK_UNLOCKED(die.lock),
+		.lock_owner =		-1,
+		.lock_owner_depth =	0
+	};
 	static int die_counter;
+	unsigned long flags;
 
 	if (debugger(regs))
 		return 1;
 
 	oops_enter();
 
-	console_verbose();
-	spin_lock_irq(&die_lock);
-	bust_spinlocks(1);
-	if (machine_is(powermac))
-		pmac_backlight_unblank();
+	if (die.lock_owner != raw_smp_processor_id()) {
+		console_verbose();
+		spin_lock_irqsave(&die.lock, flags);
+		die.lock_owner = smp_processor_id();
+		die.lock_owner_depth = 0;
+		bust_spinlocks(1);
+		if (machine_is(powermac))
+			pmac_backlight_unblank();
+	} else {
+		local_save_flags(flags);
+	}
 
-	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
+	if (++die.lock_owner_depth < 3) {
+		printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT
-	printk("PREEMPT ");
+		printk("PREEMPT ");
 #endif
 #ifdef CONFIG_SMP
-	printk("SMP NR_CPUS=%d ", NR_CPUS);
+		printk("SMP NR_CPUS=%d ", NR_CPUS);
 #endif
 #ifdef CONFIG_DEBUG_PAGEALLOC
-	printk("DEBUG_PAGEALLOC ");
+		printk("DEBUG_PAGEALLOC ");
 #endif
 #ifdef CONFIG_NUMA
-	printk("NUMA ");
+		printk("NUMA ");
 #endif
-	printk("%s\n", ppc_md.name ? "" : ppc_md.name);
+		printk("%s\n", ppc_md.name ? "" : ppc_md.name);
+
+		print_modules();
+		show_regs(regs);
+	} else {
+		printk("Recursive die() failure, output suppressed\n");
+	}
 
-	print_modules();
-	show_regs(regs);
 	bust_spinlocks(0);
-	spin_unlock_irq(&die_lock);
+	die.lock_owner = -1;
+	spin_unlock_irqrestore(&die.lock, flags);
 
 	if (kexec_should_crash(current) ||
 		kexec_sr_activated(smp_processor_id()))

commit 6031d9d9ad905b514bf45572bd1877fe6b5145ab
Author: anton@samba.org <anton@samba.org>
Date:   Tue Mar 20 20:38:12 2007 -0500

    [POWERPC] Clean up pmac_backlight_unblank in oops path
    
    Move pmac_backlight_unblank into its own function and only take the
    pmac_backlight_mutex when we are on a pmac for that added bit of
    paranoia.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 23f43b44bba6..6297da743db9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -90,6 +90,24 @@ EXPORT_SYMBOL(unregister_die_notifier);
  * Trap & Exception support
  */
 
+#ifdef CONFIG_PMAC_BACKLIGHT
+static void pmac_backlight_unblank(void)
+{
+	mutex_lock(&pmac_backlight_mutex);
+	if (pmac_backlight) {
+		struct backlight_properties *props;
+
+		props = &pmac_backlight->props;
+		props->brightness = props->max_brightness;
+		props->power = FB_BLANK_UNBLANK;
+		backlight_update_status(pmac_backlight);
+	}
+	mutex_unlock(&pmac_backlight_mutex);
+}
+#else
+static inline void pmac_backlight_unblank(void) { }
+#endif
+
 static DEFINE_SPINLOCK(die_lock);
 
 int die(const char *str, struct pt_regs *regs, long err)
@@ -104,18 +122,9 @@ int die(const char *str, struct pt_regs *regs, long err)
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
-#ifdef CONFIG_PMAC_BACKLIGHT
-	mutex_lock(&pmac_backlight_mutex);
-	if (machine_is(powermac) && pmac_backlight) {
-		struct backlight_properties *props;
+	if (machine_is(powermac))
+		pmac_backlight_unblank();
 
-		props = &pmac_backlight->props;
-		props->brightness = props->max_brightness;
-		props->power = FB_BLANK_UNBLANK;
-		backlight_update_status(pmac_backlight);
-	}
-	mutex_unlock(&pmac_backlight_mutex);
-#endif
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT
 	printk("PREEMPT ");

commit 293e4688fe2fec87fccf84a3b1100b27191424e9
Author: anton@samba.org <anton@samba.org>
Date:   Tue Mar 20 20:38:11 2007 -0500

    [POWERPC] Add missing oops_enter/oops_exit
    
    Add missing oops_enter/oops_exit, makes pause_on_oops boot parameter work.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 17724fb2067f..23f43b44bba6 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -99,6 +99,8 @@ int die(const char *str, struct pt_regs *regs, long err)
 	if (debugger(regs))
 		return 1;
 
+	oops_enter();
+
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
@@ -145,6 +147,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	if (panic_on_oops)
 		panic("Fatal exception");
 
+	oops_exit();
 	do_exit(err);
 
 	return 0;

commit 599a52d12629394236d785615808845823875868
Author: Richard Purdie <rpurdie@rpsys.net>
Date:   Sat Feb 10 23:07:48 2007 +0000

    backlight: Separate backlight properties from backlight ops pointers
    
    Per device data such as brightness belongs to the indivdual device
    and should therefore be separate from the the backlight operation
    function pointers. This patch splits the two types of data and
    allows simplifcation of some code.
    
    Signed-off-by: Richard Purdie <rpurdie@rpsys.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 35ce07b6a5bc..17724fb2067f 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -107,7 +107,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	if (machine_is(powermac) && pmac_backlight) {
 		struct backlight_properties *props;
 
-		props = pmac_backlight->props;
+		props = &pmac_backlight->props;
 		props->brightness = props->max_brightness;
 		props->power = FB_BLANK_UNBLANK;
 		backlight_update_status(pmac_backlight);

commit 28ee086d5b36aab2931f6740e409bb0fb6c65e5f
Author: Richard Purdie <rpurdie@rpsys.net>
Date:   Thu Feb 8 22:25:09 2007 +0000

    backlight: Fix external uses of backlight internal semaphore
    
    backlight_device->sem has a very specific use as documented in the
    header file. The external users of this are using it for a different
    reason, to serialise access to the update_status() method.
    
    backlight users were supposed to implement their own internal
    serialisation of update_status() if needed but everyone is doing
    things differently and incorrectly. Therefore add a global mutex to
    take care of serialisation for everyone, once and for all.
    
    Locking for get_brightness remains optional since most users don't
    need it.
    
    Also update the lcd class in a similar way.
    
    Signed-off-by: Richard Purdie <rpurdie@rpsys.net>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index dcc6f159fd94..35ce07b6a5bc 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -107,12 +107,10 @@ int die(const char *str, struct pt_regs *regs, long err)
 	if (machine_is(powermac) && pmac_backlight) {
 		struct backlight_properties *props;
 
-		down(&pmac_backlight->sem);
 		props = pmac_backlight->props;
 		props->brightness = props->max_brightness;
 		props->power = FB_BLANK_UNBLANK;
-		props->update_status(pmac_backlight);
-		up(&pmac_backlight->sem);
+		backlight_update_status(pmac_backlight);
 	}
 	mutex_unlock(&pmac_backlight_mutex);
 #endif

commit 5fad293bcbd48d9a2370020cf60e4b4a42559b12
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Feb 7 01:47:59 2007 -0600

    [POWERPC] Fixup error handling when emulating a floating point instruction
    
    When we do full FP emulation its possible that we need to post a SIGFPE based
    on the results of the emulation.  The previous code ignored this case completely.
    
    Additionally, the Soft_emulate_8xx case had two issues.  One, we should never
    generate a SIGFPE since the code only does data movement.  Second, we were
    interpreting the return codes incorrectly, it returns 0 on success, 1 on
    illop and -EFAULT on a data access error.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f038caa3c2b9..dcc6f159fd94 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -535,34 +535,40 @@ static void emulate_single_step(struct pt_regs *regs)
 	}
 }
 
-static void parse_fpe(struct pt_regs *regs)
+static inline int __parse_fpscr(unsigned long fpscr)
 {
-	int code = 0;
-	unsigned long fpscr;
-
-	flush_fp_to_thread(current);
-
-	fpscr = current->thread.fpscr.val;
+	int ret = 0;
 
 	/* Invalid operation */
 	if ((fpscr & FPSCR_VE) && (fpscr & FPSCR_VX))
-		code = FPE_FLTINV;
+		ret = FPE_FLTINV;
 
 	/* Overflow */
 	else if ((fpscr & FPSCR_OE) && (fpscr & FPSCR_OX))
-		code = FPE_FLTOVF;
+		ret = FPE_FLTOVF;
 
 	/* Underflow */
 	else if ((fpscr & FPSCR_UE) && (fpscr & FPSCR_UX))
-		code = FPE_FLTUND;
+		ret = FPE_FLTUND;
 
 	/* Divide by zero */
 	else if ((fpscr & FPSCR_ZE) && (fpscr & FPSCR_ZX))
-		code = FPE_FLTDIV;
+		ret = FPE_FLTDIV;
 
 	/* Inexact result */
 	else if ((fpscr & FPSCR_XE) && (fpscr & FPSCR_XX))
-		code = FPE_FLTRES;
+		ret = FPE_FLTRES;
+
+	return ret;
+}
+
+static void parse_fpe(struct pt_regs *regs)
+{
+	int code = 0;
+
+	flush_fp_to_thread(current);
+
+	code = __parse_fpscr(current->thread.fpscr.val);
 
 	_exception(SIGFPE, regs, code, regs->nip);
 }
@@ -773,10 +779,21 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	 * hardware people - not sure if it can happen on any illegal
 	 * instruction or only on FP instructions, whether there is a
 	 * pattern to occurences etc. -dgibson 31/Mar/2003 */
-	if (do_mathemu(regs) == 0) {
+	switch (do_mathemu(regs)) {
+	case 0:
 		emulate_single_step(regs);
 		return;
+	case 1: {
+			int code = 0;
+			code = __parse_fpscr(current->thread.fpscr.val);
+			_exception(SIGFPE, regs, code, regs->nip);
+			return;
+		}
+	case -EFAULT:
+		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+		return;
 	}
+	/* fall through on any other errors */
 #endif /* CONFIG_MATH_EMULATION */
 
 	/* Try to emulate it if we should. */
@@ -892,18 +909,39 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 #ifdef CONFIG_MATH_EMULATION
 	errcode = do_mathemu(regs);
+
+	switch (errcode) {
+	case 0:
+		emulate_single_step(regs);
+		return;
+	case 1: {
+			int code = 0;
+			code = __parse_fpscr(current->thread.fpscr.val);
+			_exception(SIGFPE, regs, code, regs->nip);
+			return;
+		}
+	case -EFAULT:
+		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+		return;
+	default:
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	}
+
 #else
 	errcode = Soft_emulate_8xx(regs);
-#endif
-	if (errcode) {
-		if (errcode > 0)
-			_exception(SIGFPE, regs, 0, 0);
-		else if (errcode == -EFAULT)
-			_exception(SIGSEGV, regs, 0, 0);
-		else
-			_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-	} else
+	switch (errcode) {
+	case 0:
 		emulate_single_step(regs);
+		return;
+	case 1:
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	case -EFAULT:
+		_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+		return;
+	}
+#endif
 }
 #endif /* CONFIG_8xx */
 

commit 04903a30a327513b97c1271fc6bc4dad6502d1b8
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Feb 7 01:13:32 2007 -0600

    [POWERPC] Enable interrupts if we are doing fp math emulation
    
    Anytime we are emulating an instruction we are going to be doing some form of
    get_user() to get the instruction image to decode.  Since get_user() might
    sleep we need to ensure we have interrupts enabled or we might see something
    like:
    
    Debug: sleeping function called from invalid context at arch/powerpc/kernel/traps.c:697
    in_atomic():0, irqs_disabled():1
    Call Trace:
    [D6023EB0] [C0007F84] show_stack+0x58/0x174 (unreliable)
    [D6023EE0] [C0022C34] __might_sleep+0xbc/0xd0
    [D6023EF0] [C000D158] program_check_exception+0x1d8/0x4fc
    [D6023F40] [C000E744] ret_from_except_full+0x0/0x4c
    --- Exception: 700 at 0x102a7100
        LR = 0xdb9ef04
    
    However, we want to ensure that interrupts are disabled when handling a trap
    exception that might be used for a kernel breakpoint.  This is why ProgramCheck
    is marked as EXC_XFER_STD instead of EXC_XFER_EE.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6915b91868b8..f038caa3c2b9 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -739,20 +739,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	extern int do_mathemu(struct pt_regs *regs);
 
 	/* We can now get here via a FP Unavailable exception if the core
-	 * has no FPU, in that case no reason flags will be set */
-#ifdef CONFIG_MATH_EMULATION
-	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
-	 * but there seems to be a hardware bug on the 405GP (RevD)
-	 * that means ESR is sometimes set incorrectly - either to
-	 * ESR_DST (!?) or 0.  In the process of chasing this with the
-	 * hardware people - not sure if it can happen on any illegal
-	 * instruction or only on FP instructions, whether there is a
-	 * pattern to occurences etc. -dgibson 31/Mar/2003 */
-	if (!(reason & REASON_TRAP) && do_mathemu(regs) == 0) {
-		emulate_single_step(regs);
-		return;
-	}
-#endif /* CONFIG_MATH_EMULATION */
+	 * has no FPU, in that case the reason flags will be 0 */
 
 	if (reason & REASON_FP) {
 		/* IEEE FP exception */
@@ -778,6 +765,20 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 
 	local_irq_enable();
 
+#ifdef CONFIG_MATH_EMULATION
+	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
+	 * but there seems to be a hardware bug on the 405GP (RevD)
+	 * that means ESR is sometimes set incorrectly - either to
+	 * ESR_DST (!?) or 0.  In the process of chasing this with the
+	 * hardware people - not sure if it can happen on any illegal
+	 * instruction or only on FP instructions, whether there is a
+	 * pattern to occurences etc. -dgibson 31/Mar/2003 */
+	if (do_mathemu(regs) == 0) {
+		emulate_single_step(regs);
+		return;
+	}
+#endif /* CONFIG_MATH_EMULATION */
+
 	/* Try to emulate it if we should. */
 	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
 		switch (emulate_instruction(regs)) {

commit 60bccbed6f53c953c62bdc2ac699395a13b6eecc
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Tue Dec 19 17:35:49 2006 +0900

    [POWERPC] Use is_init() instead of pid==1
    
    Use is_init() rather than hard coded pid comparison.
    
    Cc: Anton Blanchard <anton@samba.org>
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 535f50665647..6915b91868b8 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -174,7 +174,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	 * generate the same exception over and over again and we get
 	 * nowhere.  Better to kill it and let the kernel panic.
 	 */
-	if (current->pid == 1) {
+	if (is_init(current)) {
 		__sighandler_t handler;
 
 		spin_lock_irq(&current->sighand->siglock);

commit 73c9ceab40b1269d6195e556773167c078ac8311
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Dec 8 03:30:41 2006 -0800

    [POWERPC] Generic BUG for powerpc
    
    This makes powerpc use the generic BUG machinery.  The biggest reports the
    function name, since it is redundant with kallsyms, and not needed in general.
    
    There is an overall reduction of code, since module_32/64 duplicated several
    functions.
    
    Unfortunately there's no way to tell gcc that BUG won't return, so the BUG
    macro includes a goto loop.  This will generate a real jmp instruction, which
    is never used.
    
    [akpm@osdl.org: build fix]
    [paulus@samba.org: remove infinite loop in BUG_ON]
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Hugh Dickens <hugh@veritas.com>
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index fde820e52d03..535f50665647 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -32,6 +32,7 @@
 #include <linux/kprobes.h>
 #include <linux/kexec.h>
 #include <linux/backlight.h>
+#include <linux/bug.h>
 
 #include <asm/kdebug.h>
 #include <asm/pgtable.h>
@@ -727,54 +728,9 @@ static int emulate_instruction(struct pt_regs *regs)
 	return -EINVAL;
 }
 
-/*
- * Look through the list of trap instructions that are used for BUG(),
- * BUG_ON() and WARN_ON() and see if we hit one.  At this point we know
- * that the exception was caused by a trap instruction of some kind.
- * Returns 1 if we should continue (i.e. it was a WARN_ON) or 0
- * otherwise.
- */
-extern struct bug_entry __start___bug_table[], __stop___bug_table[];
-
-#ifndef CONFIG_MODULES
-#define module_find_bug(x)	NULL
-#endif
-
-struct bug_entry *find_bug(unsigned long bugaddr)
+int is_valid_bugaddr(unsigned long addr)
 {
-	struct bug_entry *bug;
-
-	for (bug = __start___bug_table; bug < __stop___bug_table; ++bug)
-		if (bugaddr == bug->bug_addr)
-			return bug;
-	return module_find_bug(bugaddr);
-}
-
-static int check_bug_trap(struct pt_regs *regs)
-{
-	struct bug_entry *bug;
-	unsigned long addr;
-
-	if (regs->msr & MSR_PR)
-		return 0;	/* not in kernel */
-	addr = regs->nip;	/* address of trap instruction */
-	if (addr < PAGE_OFFSET)
-		return 0;
-	bug = find_bug(regs->nip);
-	if (bug == NULL)
-		return 0;
-	if (bug->line & BUG_WARNING_TRAP) {
-		/* this is a WARN_ON rather than BUG/BUG_ON */
-		printk(KERN_ERR "Badness in %s at %s:%ld\n",
-		       bug->function, bug->file,
-		       bug->line & ~BUG_WARNING_TRAP);
-		dump_stack();
-		return 1;
-	}
-	printk(KERN_CRIT "kernel BUG in %s at %s:%ld!\n",
-	       bug->function, bug->file, bug->line);
-
-	return 0;
+	return is_kernel_addr(addr);
 }
 
 void __kprobes program_check_exception(struct pt_regs *regs)
@@ -810,7 +766,9 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 			return;
 		if (debugger_bpt(regs))
 			return;
-		if (check_bug_trap(regs)) {
+
+		if (!(regs->msr & MSR_PR) &&  /* not user-mode */
+		    report_bug(regs->nip) == BUG_TRAP_TYPE_WARN) {
 			regs->nip += 4;
 			return;
 		}

commit aa42c69c67f82e88f0726258efe7306708e1cf14
Author: Kim Phillips <kim.phillips@freescale.com>
Date:   Fri Dec 8 02:43:30 2006 -0600

    [POWERPC] Add support for FP emulation for the e300c2 core
    
    The e300c2 has no FPU.  Its MSR[FP] is grounded to zero.  If an attempt
    is made to execute a floating point instruction (including floating-point
    load, store, or move instructions), the e300c2 takes a floating-point
    unavailable interrupt.
    
    This patch adds support for FP emulation on the e300c2 by declaring a
    new CPU_FTR_FP_TAKES_FPUNAVAIL, where FP unavail interrupts are
    intercepted and redirected to the ProgramCheck exception path for
    correct emulation handling.
    
    (If we run out of CPU_FTR bits we could look to reclaim this bit by adding
    support to test the cpu_user_features for PPC_FEATURE_HAS_FPU instead)
    
    It adds a nop to the exception path for 32-bit processors with a FPU.
    
    Signed-off-by: Kim Phillips <kim.phillips@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0d4e203fa7a0..fde820e52d03 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -782,6 +782,8 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 	unsigned int reason = get_reason(regs);
 	extern int do_mathemu(struct pt_regs *regs);
 
+	/* We can now get here via a FP Unavailable exception if the core
+	 * has no FPU, in that case no reason flags will be set */
 #ifdef CONFIG_MATH_EMULATION
 	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
 	 * but there seems to be a hardware bug on the 405GP (RevD)

commit 68a64357d15ae4f596e92715719071952006e83c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Nov 13 09:27:39 2006 +1100

    [POWERPC] Merge 32 and 64 bits asm-powerpc/io.h
    
    powerpc: Merge 32 and 64 bits asm-powerpc/io.h
    
    The rework on io.h done for the new hookable accessors made it easier,
    so I just finished the work and merged 32 and 64 bits io.h for arch/powerpc.
    
    arch/ppc still uses the old version in asm-ppc, there is just too much gunk
    in there that I really can't be bothered trying to cleanup.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c66b4771ef44..0d4e203fa7a0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -53,10 +53,6 @@
 #endif
 #include <asm/kexec.h>
 
-#ifdef CONFIG_PPC64	/* XXX */
-#define _IO_BASE	pci_io_base
-#endif
-
 #ifdef CONFIG_DEBUGGER
 int (*__debugger)(struct pt_regs *regs);
 int (*__debugger_ipi)(struct pt_regs *regs);
@@ -241,7 +237,7 @@ void system_reset_exception(struct pt_regs *regs)
  */
 static inline int check_io_access(struct pt_regs *regs)
 {
-#if defined(CONFIG_PPC_PMAC) && defined(CONFIG_PPC32)
+#ifdef CONFIG_PPC32
 	unsigned long msr = regs->msr;
 	const struct exception_table_entry *entry;
 	unsigned int *nip = (unsigned int *)regs->nip;
@@ -274,7 +270,7 @@ static inline int check_io_access(struct pt_regs *regs)
 			return 1;
 		}
 	}
-#endif /* CONFIG_PPC_PMAC && CONFIG_PPC32 */
+#endif /* CONFIG_PPC32 */
 	return 0;
 }
 

commit 4393c4f6788cee65095dd838cfeca6edefbfeb52
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Nov 1 15:11:39 2006 +1100

    [POWERPC] Make alignment exception always check exception table
    
    The alignment exception used to only check the exception table for
    -EFAULT, not for other errors. That opens an oops window if we can
    coerce the kernel into getting an alignment exception for other reasons
    in what would normally be a user-protected accessor, which can be done
    via some of the futex ops. This fixes it by always checking the
    exception tables.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5ed4c2ceb5ca..c66b4771ef44 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -843,7 +843,7 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 
 void alignment_exception(struct pt_regs *regs)
 {
-	int fixed = 0;
+	int sig, code, fixed = 0;
 
 	/* we don't implement logging of alignment exceptions */
 	if (!(current->thread.align_ctl & PR_UNALIGN_SIGBUS))
@@ -857,14 +857,16 @@ void alignment_exception(struct pt_regs *regs)
 
 	/* Operand address was bad */
 	if (fixed == -EFAULT) {
-		if (user_mode(regs))
-			_exception(SIGSEGV, regs, SEGV_ACCERR, regs->dar);
-		else
-			/* Search exception table */
-			bad_page_fault(regs, regs->dar, SIGSEGV);
-		return;
+		sig = SIGSEGV;
+		code = SEGV_ACCERR;
+	} else {
+		sig = SIGBUS;
+		code = BUS_ADRALN;
 	}
-	_exception(SIGBUS, regs, BUS_ADRALN, regs->dar);
+	if (user_mode(regs))
+		_exception(sig, regs, code, regs->dar);
+	else
+		bad_page_fault(regs, regs->dar, sig);
 }
 
 void StackOverflow(struct pt_regs *regs)

commit 6c4841c2b6c32a134f9f36e5e08857138cc12b10
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Oct 13 11:41:00 2006 +1000

    [POWERPC] Never panic when taking altivec exceptions from userspace
    
    At the moment we rely on a cpu feature bit or a firmware property to
    detect altivec. If we dont have either of these and the cpu does in fact
    support altivec we can cause a panic from userspace.
    
    It seems safer to always send a signal if we manage to get an 0xf20
    exception from userspace.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index d9f10f2fc372..5ed4c2ceb5ca 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -900,14 +900,13 @@ void kernel_fp_unavailable_exception(struct pt_regs *regs)
 
 void altivec_unavailable_exception(struct pt_regs *regs)
 {
-#if !defined(CONFIG_ALTIVEC)
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
-#endif
+
 	printk(KERN_EMERG "Unrecoverable VMX/Altivec Unavailable Exception "
 			"%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);

commit c3412dcb75ff4d64b44bedc72761d5707d19edf7
Author: Will Schmidt <will_schmidt@vnet.ibm.com>
Date:   Wed Aug 30 13:11:38 2006 -0500

    [POWERPC] Emulate power5 popcntb instruction
    
    In an attempt to make it easier for a power5 optimized app to run on a
    power4 or a 970 or random earlier machine, this provides emulation of
    the popcntb instruction.
    
    Signed-off-by: Will Schmidt <will_schmidt@vnet.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 9b352bd0a460..d9f10f2fc372 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -598,6 +598,9 @@ static void parse_fpe(struct pt_regs *regs)
 #define INST_STSWI		0x7c0005aa
 #define INST_STSWX		0x7c00052a
 
+#define INST_POPCNTB		0x7c0000f4
+#define INST_POPCNTB_MASK	0xfc0007fe
+
 static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 {
 	u8 rT = (instword >> 21) & 0x1f;
@@ -666,6 +669,23 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 	return 0;
 }
 
+static int emulate_popcntb_inst(struct pt_regs *regs, u32 instword)
+{
+	u32 ra,rs;
+	unsigned long tmp;
+
+	ra = (instword >> 16) & 0x1f;
+	rs = (instword >> 21) & 0x1f;
+
+	tmp = regs->gpr[rs];
+	tmp = tmp - ((tmp >> 1) & 0x5555555555555555ULL);
+	tmp = (tmp & 0x3333333333333333ULL) + ((tmp >> 2) & 0x3333333333333333ULL);
+	tmp = (tmp + (tmp >> 4)) & 0x0f0f0f0f0f0f0f0fULL;
+	regs->gpr[ra] = tmp;
+
+	return 0;
+}
+
 static int emulate_instruction(struct pt_regs *regs)
 {
 	u32 instword;
@@ -703,6 +723,11 @@ static int emulate_instruction(struct pt_regs *regs)
 	if ((instword & INST_STRING_GEN_MASK) == INST_STRING)
 		return emulate_string_inst(regs, instword);
 
+	/* Emulate the popcntb (Population Count Bytes) instruction. */
+	if ((instword & INST_POPCNTB_MASK) == INST_POPCNTB) {
+		return emulate_popcntb_inst(regs, instword);
+	}
+
 	return -EINVAL;
 }
 

commit ccc712fe6b2acbafe9fc31f765a193e3249ca4a1
Merge: 9c637646dafd c9169f8747bb
Author: Greg Kroah-Hartman <gregkh@suse.de>
Date:   Wed Aug 23 21:08:12 2006 -0700

    Merge branch 'merge' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc

commit 87589f08beaec3e1f8a3af0c72406c845f706821
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Aug 23 16:58:39 2006 +1000

    [POWERPC] Correct masks used in emulating some instructions
    
    When we get an illegal instruction exception, we check to see whether
    the instruction is one that we emulate for the user program.  Some of
    the masks we use in checking whether the offending instruction is one
    we care about didn't have the top bit set, which is the MSB of the
    major opcode.  Thus some undefined opcodes could get emulated as other
    (defined but unimplemented) instructions.  This corrects the masks.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 125761aaa40b..4d0b4e74d579 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -585,14 +585,14 @@ static void parse_fpe(struct pt_regs *regs)
 #define INST_MFSPR_PVR_MASK	0xfc1fffff
 
 #define INST_DCBA		0x7c0005ec
-#define INST_DCBA_MASK		0x7c0007fe
+#define INST_DCBA_MASK		0xfc0007fe
 
 #define INST_MCRXR		0x7c000400
-#define INST_MCRXR_MASK		0x7c0007fe
+#define INST_MCRXR_MASK		0xfc0007fe
 
 #define INST_STRING		0x7c00042a
-#define INST_STRING_MASK	0x7c0007fe
-#define INST_STRING_GEN_MASK	0x7c00067e
+#define INST_STRING_MASK	0xfc0007fe
+#define INST_STRING_GEN_MASK	0xfc00067e
 #define INST_LSWI		0x7c0004aa
 #define INST_LSWX		0x7c00042a
 #define INST_STSWI		0x7c0005aa

commit ed0da6fc9d3096f54c4a76737eeae57ac81418cf
Merge: 774bd8613d01 9e8a9bc2d2c3
Author: Greg Kroah-Hartman <gregkh@suse.de>
Date:   Fri Aug 18 09:20:04 2006 -0700

    Merge branch 'merge' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc

commit b6f35b4966e0ae59cec45e5292b100698d12dc5f
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Jul 5 14:39:43 2006 +1000

    [POWERPC] Make crash.c work on 32-bit and 64-bit
    
    To compile kexec on 32-bit we need a few more bits and pieces. Rather
    than add empty definitions, we can make crash.c work on 32-bit, with
    only a couple of kludges.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5147175f921c..125761aaa40b 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -55,9 +55,6 @@
 
 #ifdef CONFIG_PPC64	/* XXX */
 #define _IO_BASE	pci_io_base
-#ifdef CONFIG_KEXEC
-cpumask_t cpus_in_sr = CPU_MASK_NONE;
-#endif
 #endif
 
 #ifdef CONFIG_DEBUGGER

commit eac8392f9591b359847b8a6abb75ca60967bcecd
Author: David Wilder <dwilder@us.ibm.com>
Date:   Thu Jun 29 15:17:30 2006 -0700

    [POWERPC] Make secondary CPUs call into kdump on reset exception
    
    In the case of a system hang, the user will invoke soft-reset to
    initiate the kdump boot.  If xmon is enabled, the CPU(s) enter into the
    xmon debugger.   Unfortunately, the secondary CPU(s) will return to the
    hung state when they exit from the debugger (returned from die() ->
    system_reset_exception()).  This causes a problem in kdump since the
    hung CPU(s) will not respond to the IPI sent from kdump.  This patch
    fixes the issue by calling crash_kexec_secondary() directly from
    system_reset_exception() without returning to the previous state.  These
    secondary CPUs wait 5ms until the kdump boot is started by the primary
    CPU.   In the case we exited from the debugger to "recover" (command 'x'
    in xmon) the primary and the secondary CPUs will all return from die()
    -> system_reset_exception() ->crash_kexec_secondary() wait 5ms, then
    return to the previous state.  A kdump boot is not started in this case.
    
    Signed-off-by: Haren Myneni <haren@us.ibm.com>
    Signed-off-by: David Wilder <dwilder@us.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2105767fcc57..5147175f921c 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -211,6 +211,19 @@ void system_reset_exception(struct pt_regs *regs)
 
 	die("System Reset", regs, SIGABRT);
 
+	/*
+	 * Some CPUs when released from the debugger will execute this path.
+	 * These CPUs entered the debugger via a soft-reset. If the CPU was
+	 * hung before entering the debugger it will return to the hung
+	 * state when exiting this function.  This causes a problem in
+	 * kdump since the hung CPU(s) will not respond to the IPI sent
+	 * from kdump. To prevent the problem we call crash_kexec_secondary()
+	 * here. If a kdump had not been initiated or we exit the debugger
+	 * with the "exit and recover" command (x) crash_kexec_secondary()
+	 * will return after 5ms and the CPU returns to its previous state.
+	 */
+	crash_kexec_secondary(regs);
+
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable System Reset");

commit 012c437d03cb299814e58ac8d574f7510f5989a5
Author: Horms <horms@verge.net.au>
Date:   Sun Aug 13 23:24:22 2006 -0700

    [PATCH] Change panic_on_oops message to "Fatal exception"
    
    Previously the message was "Fatal exception: panic_on_oops", as introduced
    in a recent patch whith removed a somewhat dangerous call to ssleep() in
    the panic_on_oops path.  However, Paul Mackerras suggested that this was
    somewhat confusing, leadind people to believe that it was panic_on_oops
    that was the root cause of the fatal exception.  On his suggestion, this
    patch changes the message to simply "Fatal exception".  A suitable oops
    message should already have been displayed.
    
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2105767fcc57..05682a24b210 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -151,7 +151,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 		panic("Fatal exception in interrupt");
 
 	if (panic_on_oops)
-		panic("Fatal exception: panic_on_oops");
+		panic("Fatal exception");
 
 	do_exit(err);
 

commit cea6a4ba8acfba6f59cc9ed71e0d05cb770b9d9c
Author: Horms <horms@verge.net.au>
Date:   Sun Jul 30 03:03:34 2006 -0700

    [PATCH] panic_on_oops: remove ssleep()
    
    This patch is part of an effort to unify the panic_on_oops behaviour across
    all architectures that implement it.
    
    It was pointed out to me by Andi Kleen that if an oops has occured in
    interrupt context, then calling sleep() in the oops path will only cause a
    panic, and that it would be really better for it not to be in the path at
    all.
    
    This patch removes the ssleep() call and reworks the console message
    accordinly.  I have a slght concern that the resulting console message is
    too long, feedback welcome.
    
    For powerpc it also unifies the 32bit and 64bit behaviour.
    
    Fror x86_64, this patch only updates the console message, as ssleep() is
    already not present.
    
    Signed-off-by: Horms <horms@verge.net.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Chris Zankel <chris@zankel.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 3c668078e524..2105767fcc57 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -150,13 +150,9 @@ int die(const char *str, struct pt_regs *regs, long err)
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");
 
-	if (panic_on_oops) {
-#ifdef CONFIG_PPC64
-		printk(KERN_EMERG "Fatal exception: panic in 5 seconds\n");
-		ssleep(5);
-#endif
-		panic("Fatal exception");
-	}
+	if (panic_on_oops)
+		panic("Fatal exception: panic_on_oops");
+
 	do_exit(err);
 
 	return 0;

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index fa6bd97b6b9d..3c668078e524 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -14,7 +14,6 @@
  * This file handles the architecture-dependent parts of hardware exceptions
  */
 
-#include <linux/config.h>
 #include <linux/errno.h>
 #include <linux/sched.h>
 #include <linux/kernel.h>

commit c0ce7d0886cf0c2579c604eac41a7e125bc0e96d
Author: David Wilder <dwilder@us.ibm.com>
Date:   Fri Jun 23 15:29:34 2006 -0700

    [POWERPC] Add the use of the firmware soft-reset-nmi to kdump.
    
    With this patch, kdump uses the firmware soft-reset NMI for two purposes:
    1) Initiate the kdump (take a crash dump) by issuing a soft-reset.
    2) Break a CPU out of a deadlock condition that is detected during kdump
    processing.
    
    When a soft-reset is initiated each CPU will enter
    system_reset_exception() and set its corresponding bit in the global
    bit-array cpus_in_sr then call die(). When die() finds the CPU's bit set
    in cpu_in_sr crash_kexec() is called to initiate a crash dump. The first
    CPU to enter crash_kexec() is called the "crashing CPU". All other CPUs
    are "secondary CPUs". The secondary CPU's pass through to
    crash_kexec_secondary() and sleep. The crashing CPU waits for all CPUs
    to enter via soft-reset then boots the kdump kernel (see
    crash_soft_reset_check())
    
    When the system crashes due to a panic or exception, crash_kexec() is
    called by panic() or die(). The crashing CPU sends an IPI to all other
    CPUs to notify them of the pending shutdown. If a CPU is in a deadlock
    or hung state with interrupts disabled, the IPI will not be delivered.
    The result being, that the kdump kernel is not booted. This problem is
    solved with the use of a firmware generated soft-reset. After the
    crashing_cpu has issued the IPI, it waits for 10 sec for all CPUs to
    enter crash_ipi_callback(). A CPU signifies its entry to
    crash_ipi_callback() by setting its corresponding bit in the
    cpus_in_crash bit array. After 10 sec, if one or more CPUs have not set
    their bit in cpus_in_crash we assume that the CPU(s) is deadlocked. The
    operator is then prompted to generate a soft-reset to break the
    deadlock. Each CPU enters the soft reset handler as described above.
    
    Two conditions must be handled at this point:
    1) The system crashed because the operator generated a soft-reset. See
    2) The system had crashed before the soft-reset was generated ( in the
    case of a Panic or oops).
    
    The first CPU to enter crash_kexec() uses the state of the kexec_lock to
    determine this state. If kexec_lock is already held then condition 2 is
    true and crash_kexec_secondary() is called, else; this CPU is flagged as
    the crashing CPU, the kexec_lock is acquired and crash_kexec() proceeds
    as described above.
    
    Each additional CPUs responding to the soft-reset will pass through
    crash_kexec() to kexec_secondary(). All secondary CPUs call
    crash_ipi_callback() readying them self's for the shutdown. When ready
    they clear their bit in cpus_in_sr. The crashing CPU waits in
    kexec_secondary() until all other CPUs have cleared their bits in
    cpus_in_sr. The kexec kernel boot is then started.
    
    Signed-off-by: Haren Myneni <haren@us.ibm.com>
    Signed-off-by: David Wilder <dwilder@us.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 52f5659534f4..fa6bd97b6b9d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -52,9 +52,13 @@
 #include <asm/firmware.h>
 #include <asm/processor.h>
 #endif
+#include <asm/kexec.h>
 
 #ifdef CONFIG_PPC64	/* XXX */
 #define _IO_BASE	pci_io_base
+#ifdef CONFIG_KEXEC
+cpumask_t cpus_in_sr = CPU_MASK_NONE;
+#endif
 #endif
 
 #ifdef CONFIG_DEBUGGER
@@ -97,7 +101,7 @@ static DEFINE_SPINLOCK(die_lock);
 
 int die(const char *str, struct pt_regs *regs, long err)
 {
-	static int die_counter, crash_dump_start = 0;
+	static int die_counter;
 
 	if (debugger(regs))
 		return 1;
@@ -137,21 +141,12 @@ int die(const char *str, struct pt_regs *regs, long err)
 	print_modules();
 	show_regs(regs);
 	bust_spinlocks(0);
+	spin_unlock_irq(&die_lock);
 
-	if (!crash_dump_start && kexec_should_crash(current)) {
-		crash_dump_start = 1;
-		spin_unlock_irq(&die_lock);
+	if (kexec_should_crash(current) ||
+		kexec_sr_activated(smp_processor_id()))
 		crash_kexec(regs);
-		/* NOTREACHED */
-	}
-	spin_unlock_irq(&die_lock);
-	if (crash_dump_start)
-		/*
-		 * Only for soft-reset: Other CPUs will be responded to an IPI
-		 * sent by first kexec CPU.
-		 */
-		for(;;)
-			;
+	crash_kexec_secondary(regs);
 
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");
@@ -215,6 +210,10 @@ void system_reset_exception(struct pt_regs *regs)
 			return;
 	}
 
+#ifdef CONFIG_KEXEC
+	cpu_set(smp_processor_id(), cpus_in_sr);
+#endif
+
 	die("System Reset", regs, SIGABRT);
 
 	/* Must die if the interrupt is not recoverable */

commit 5474c120aafe78ca54bf272f7a01107c42da2b21
Author: Michael Hanselmann <linux-kernel@hansmi.ch>
Date:   Sun Jun 25 05:47:08 2006 -0700

    [PATCH] Rewritten backlight infrastructure for portable Apple computers
    
    This patch contains a total rewrite of the backlight infrastructure for
    portable Apple computers.  Backward compatibility is retained.  A sysfs
    interface allows userland to control the brightness with more steps than
    before.  Userland is allowed to upload a brightness curve for different
    monitors, similar to Mac OS X.
    
    [akpm@osdl.org: add needed exports]
    Signed-off-by: Michael Hanselmann <linux-kernel@hansmi.ch>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Purdie <rpurdie@rpsys.net>
    Cc: "Antonino A. Daplas" <adaplas@pol.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 91a6e04d9741..52f5659534f4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -32,6 +32,7 @@
 #include <linux/delay.h>
 #include <linux/kprobes.h>
 #include <linux/kexec.h>
+#include <linux/backlight.h>
 
 #include <asm/kdebug.h>
 #include <asm/pgtable.h>
@@ -105,10 +106,18 @@ int die(const char *str, struct pt_regs *regs, long err)
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
 #ifdef CONFIG_PMAC_BACKLIGHT
-	if (machine_is(powermac)) {
-		set_backlight_enable(1);
-		set_backlight_level(BACKLIGHT_MAX);
+	mutex_lock(&pmac_backlight_mutex);
+	if (machine_is(powermac) && pmac_backlight) {
+		struct backlight_properties *props;
+
+		down(&pmac_backlight->sem);
+		props = pmac_backlight->props;
+		props->brightness = props->max_brightness;
+		props->power = FB_BLANK_UNBLANK;
+		props->update_status(pmac_backlight);
+		up(&pmac_backlight->sem);
 	}
+	mutex_unlock(&pmac_backlight_mutex);
 #endif
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT

commit e9370ae15dc2f8ba1e1889ce26f13cda565b6ecb
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 7 16:15:39 2006 +1000

    [PATCH] powerpc: Implement PR_[GS]ET_UNALIGN prctls for powerpc
    
    This gives the ability to control whether alignment exceptions get
    fixed up or reported to the process as a SIGBUS, using the existing
    PR_SET_UNALIGN and PR_GET_UNALIGN prctls.  We do not implement the
    option of logging a message on alignment exceptions.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 03def5715494..91a6e04d9741 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -805,9 +805,11 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 
 void alignment_exception(struct pt_regs *regs)
 {
-	int fixed;
+	int fixed = 0;
 
-	fixed = fix_alignment(regs);
+	/* we don't implement logging of alignment exceptions */
+	if (!(current->thread.align_ctl & PR_UNALIGN_SIGBUS))
+		fixed = fix_alignment(regs);
 
 	if (fixed == 1) {
 		regs->nip += 4;	/* skip over emulated instruction */

commit fab5db97e44f76461f76b24adfa8ccb14d4df498
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 7 16:14:40 2006 +1000

    [PATCH] powerpc: Implement support for setting little-endian mode via prctl
    
    This adds the PowerPC part of the code to allow processes to change
    their endian mode via prctl.
    
    This also extends the alignment exception handler to be able to fix up
    alignment exceptions that occur in little-endian mode, both for
    "PowerPC" little-endian and true little-endian.
    
    We always enter signal handlers in big-endian mode -- the support for
    little-endian mode does not amount to the creation of a little-endian
    user/kernel ABI.  If the signal handler returns, the endian mode is
    restored to what it was when the signal was delivered.
    
    We have two new kernel CPU feature bits, one for PPC little-endian and
    one for true little-endian.  Most of the classic 32-bit processors
    support PPC little-endian, and this is reflected in the CPU feature
    table.  There are two corresponding feature bits reported to userland
    in the AT_HWCAP aux vector entry.
    
    This is based on an earlier patch by Anton Blanchard.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 064a52564692..03def5715494 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -658,7 +658,7 @@ static int emulate_instruction(struct pt_regs *regs)
 	u32 instword;
 	u32 rd;
 
-	if (!user_mode(regs))
+	if (!user_mode(regs) || (regs->msr & MSR_LE))
 		return -EINVAL;
 	CHECK_FULL_REGS(regs);
 

commit 1a6a4ffef6a405f60b51856725074532c9696ac2
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Mar 30 21:11:15 2006 -0600

    powerpc: merge machine_check_exception between ppc32 & ppc64
    
    Make machine_check_exception handling code path the same on ppc32 & ppc64.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 4cbde211eb69..064a52564692 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -228,7 +228,7 @@ void system_reset_exception(struct pt_regs *regs)
  */
 static inline int check_io_access(struct pt_regs *regs)
 {
-#ifdef CONFIG_PPC_PMAC
+#if defined(CONFIG_PPC_PMAC) && defined(CONFIG_PPC32)
 	unsigned long msr = regs->msr;
 	const struct exception_table_entry *entry;
 	unsigned int *nip = (unsigned int *)regs->nip;
@@ -261,7 +261,7 @@ static inline int check_io_access(struct pt_regs *regs)
 			return 1;
 		}
 	}
-#endif /* CONFIG_PPC_PMAC */
+#endif /* CONFIG_PPC_PMAC && CONFIG_PPC32 */
 	return 0;
 }
 
@@ -308,8 +308,8 @@ platform_machine_check(struct pt_regs *regs)
 
 void machine_check_exception(struct pt_regs *regs)
 {
-#ifdef CONFIG_PPC64
 	int recover = 0;
+	unsigned long reason = get_mc_reason(regs);
 
 	/* See if any machine dependent calls */
 	if (ppc_md.machine_check_exception)
@@ -317,8 +317,6 @@ void machine_check_exception(struct pt_regs *regs)
 
 	if (recover)
 		return;
-#else
-	unsigned long reason = get_mc_reason(regs);
 
 	if (user_mode(regs)) {
 		regs->msr |= MSR_RI;
@@ -462,7 +460,6 @@ void machine_check_exception(struct pt_regs *regs)
 	 * additional info, e.g. bus error registers.
 	 */
 	platform_machine_check(regs);
-#endif /* CONFIG_PPC64 */
 
 	if (debugger_fault_handler(regs))
 		return;

commit bac30d1a78d0f11c613968fc8b351a91ed465386
Merge: e8222502ee61 ca9ba4471c12
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Mar 29 13:24:50 2006 +1100

    Merge ../linux-2.6

commit e8222502ee6157e2713da9e0792c21f4ad458d50
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Mar 28 23:15:54 2006 +1100

    [PATCH] powerpc: Kill _machine and hard-coded platform numbers
    
    This removes statically assigned platform numbers and reworks the
    powerpc platform probe code to use a better mechanism.  With this,
    board support files can simply declare a new machine type with a
    macro, and implement a probe() function that uses the flattened
    device-tree to detect if they apply for a given machine.
    
    We now have a machine_is() macro that replaces the comparisons of
    _machine with the various PLATFORM_* constants.  This commit also
    changes various drivers to use the new macro instead of looking at
    _machine.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 98660aedeeb7..27600c9432bc 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -97,7 +97,6 @@ static DEFINE_SPINLOCK(die_lock);
 int die(const char *str, struct pt_regs *regs, long err)
 {
 	static int die_counter, crash_dump_start = 0;
-	int nl = 0;
 
 	if (debugger(regs))
 		return 1;
@@ -106,7 +105,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
 #ifdef CONFIG_PMAC_BACKLIGHT
-	if (_machine == _MACH_Pmac) {
+	if (machine_is(powermac)) {
 		set_backlight_enable(1);
 		set_backlight_level(BACKLIGHT_MAX);
 	}
@@ -114,46 +113,18 @@ int die(const char *str, struct pt_regs *regs, long err)
 	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
 #ifdef CONFIG_PREEMPT
 	printk("PREEMPT ");
-	nl = 1;
 #endif
 #ifdef CONFIG_SMP
 	printk("SMP NR_CPUS=%d ", NR_CPUS);
-	nl = 1;
 #endif
 #ifdef CONFIG_DEBUG_PAGEALLOC
 	printk("DEBUG_PAGEALLOC ");
-	nl = 1;
 #endif
 #ifdef CONFIG_NUMA
 	printk("NUMA ");
-	nl = 1;
 #endif
-#ifdef CONFIG_PPC64
-	switch (_machine) {
-	case PLATFORM_PSERIES:
-		printk("PSERIES ");
-		nl = 1;
-		break;
-	case PLATFORM_PSERIES_LPAR:
-		printk("PSERIES LPAR ");
-		nl = 1;
-		break;
-	case PLATFORM_ISERIES_LPAR:
-		printk("ISERIES LPAR ");
-		nl = 1;
-		break;
-	case PLATFORM_POWERMAC:
-		printk("POWERMAC ");
-		nl = 1;
-		break;
-	case PLATFORM_CELL:
-		printk("CELL ");
-		nl = 1;
-		break;
-	}
-#endif
-	if (nl)
-		printk("\n");
+	printk("%s\n", ppc_md.name ? "" : ppc_md.name);
+
 	print_modules();
 	show_regs(regs);
 	bust_spinlocks(0);

commit e041c683412d5bf44dc2b109053e3b837b71742d
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon Mar 27 01:16:30 2006 -0800

    [PATCH] Notifier chain update: API changes
    
    The kernel's implementation of notifier chains is unsafe.  There is no
    protection against entries being added to or removed from a chain while the
    chain is in use.  The issues were discussed in this thread:
    
        http://marc.theaimsgroup.com/?l=linux-kernel&m=113018709002036&w=2
    
    We noticed that notifier chains in the kernel fall into two basic usage
    classes:
    
            "Blocking" chains are always called from a process context
            and the callout routines are allowed to sleep;
    
            "Atomic" chains can be called from an atomic context and
            the callout routines are not allowed to sleep.
    
    We decided to codify this distinction and make it part of the API.  Therefore
    this set of patches introduces three new, parallel APIs: one for blocking
    notifiers, one for atomic notifiers, and one for "raw" notifiers (which is
    really just the old API under a new name).  New kinds of data structures are
    used for the heads of the chains, and new routines are defined for
    registration, unregistration, and calling a chain.  The three APIs are
    explained in include/linux/notifier.h and their implementation is in
    kernel/sys.c.
    
    With atomic and blocking chains, the implementation guarantees that the chain
    links will not be corrupted and that chain callers will not get messed up by
    entries being added or removed.  For raw chains the implementation provides no
    guarantees at all; users of this API must provide their own protections.  (The
    idea was that situations may come up where the assumptions of the atomic and
    blocking APIs are not appropriate, so it should be possible for users to
    handle these things in their own way.)
    
    There are some limitations, which should not be too hard to live with.  For
    atomic/blocking chains, registration and unregistration must always be done in
    a process context since the chain is protected by a mutex/rwsem.  Also, a
    callout routine for a non-raw chain must not try to register or unregister
    entries on its own chain.  (This did happen in a couple of places and the code
    had to be changed to avoid it.)
    
    Since atomic chains may be called from within an NMI handler, they cannot use
    spinlocks for synchronization.  Instead we use RCU.  The overhead falls almost
    entirely in the unregister routine, which is okay since unregistration is much
    less frequent that calling a chain.
    
    Here is the list of chains that we adjusted and their classifications.  None
    of them use the raw API, so for the moment it is only a placeholder.
    
      ATOMIC CHAINS
      -------------
    arch/i386/kernel/traps.c:               i386die_chain
    arch/ia64/kernel/traps.c:               ia64die_chain
    arch/powerpc/kernel/traps.c:            powerpc_die_chain
    arch/sparc64/kernel/traps.c:            sparc64die_chain
    arch/x86_64/kernel/traps.c:             die_chain
    drivers/char/ipmi/ipmi_si_intf.c:       xaction_notifier_list
    kernel/panic.c:                         panic_notifier_list
    kernel/profile.c:                       task_free_notifier
    net/bluetooth/hci_core.c:               hci_notifier
    net/ipv4/netfilter/ip_conntrack_core.c: ip_conntrack_chain
    net/ipv4/netfilter/ip_conntrack_core.c: ip_conntrack_expect_chain
    net/ipv6/addrconf.c:                    inet6addr_chain
    net/netfilter/nf_conntrack_core.c:      nf_conntrack_chain
    net/netfilter/nf_conntrack_core.c:      nf_conntrack_expect_chain
    net/netlink/af_netlink.c:               netlink_chain
    
      BLOCKING CHAINS
      ---------------
    arch/powerpc/platforms/pseries/reconfig.c:      pSeries_reconfig_chain
    arch/s390/kernel/process.c:             idle_chain
    arch/x86_64/kernel/process.c            idle_notifier
    drivers/base/memory.c:                  memory_chain
    drivers/cpufreq/cpufreq.c               cpufreq_policy_notifier_list
    drivers/cpufreq/cpufreq.c               cpufreq_transition_notifier_list
    drivers/macintosh/adb.c:                adb_client_list
    drivers/macintosh/via-pmu.c             sleep_notifier_list
    drivers/macintosh/via-pmu68k.c          sleep_notifier_list
    drivers/macintosh/windfarm_core.c       wf_client_list
    drivers/usb/core/notify.c               usb_notifier_list
    drivers/video/fbmem.c                   fb_notifier_list
    kernel/cpu.c                            cpu_chain
    kernel/module.c                         module_notify_list
    kernel/profile.c                        munmap_notifier
    kernel/profile.c                        task_exit_notifier
    kernel/sys.c                            reboot_notifier_list
    net/core/dev.c                          netdev_chain
    net/decnet/dn_dev.c:                    dnaddr_chain
    net/ipv4/devinet.c:                     inetaddr_chain
    
    It's possible that some of these classifications are wrong.  If they are,
    please let us know or submit a patch to fix them.  Note that any chain that
    gets called very frequently should be atomic, because the rwsem read-locking
    used for blocking chains is very likely to incur cache misses on SMP systems.
    (However, if the chain's callout routines may sleep then the chain cannot be
    atomic.)
    
    The patch set was written by Alan Stern and Chandra Seetharaman, incorporating
    material written by Keith Owens and suggestions from Paul McKenney and Andrew
    Morton.
    
    [jes@sgi.com: restructure the notifier chain initialization macros]
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Chandra Seetharaman <sekharan@us.ibm.com>
    Signed-off-by: Jes Sorensen <jes@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 98660aedeeb7..9763faab6739 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -74,19 +74,19 @@ EXPORT_SYMBOL(__debugger_dabr_match);
 EXPORT_SYMBOL(__debugger_fault_handler);
 #endif
 
-struct notifier_block *powerpc_die_chain;
-static DEFINE_SPINLOCK(die_notifier_lock);
+ATOMIC_NOTIFIER_HEAD(powerpc_die_chain);
 
 int register_die_notifier(struct notifier_block *nb)
 {
-	int err = 0;
-	unsigned long flags;
+	return atomic_notifier_chain_register(&powerpc_die_chain, nb);
+}
+EXPORT_SYMBOL(register_die_notifier);
 
-	spin_lock_irqsave(&die_notifier_lock, flags);
-	err = notifier_chain_register(&powerpc_die_chain, nb);
-	spin_unlock_irqrestore(&die_notifier_lock, flags);
-	return err;
+int unregister_die_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_unregister(&powerpc_die_chain, nb);
 }
+EXPORT_SYMBOL(unregister_die_notifier);
 
 /*
  * Trap & Exception support

commit cd8a5673e9abb3fde0a1c25ee63a60fe1908c6f5
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Mar 3 17:11:40 2006 +1100

    powerpc: Fix might-sleep warning in program check exception handler
    
    On 32-bit, the exception prolog for the program check exception doesn't
    enable interrupts early on.  If it is an illegal instruction exception,
    we read the instruction in order to emulate certain instructions, and
    the get_user of the instruction triggers a WARN_ON since interrupts
    are still disabled.  This adds a local_irq_enable() to enable
    interrupts before reading the instruction.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 7509aa6474f2..98660aedeeb7 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -814,6 +814,8 @@ void __kprobes program_check_exception(struct pt_regs *regs)
 		return;
 	}
 
+	local_irq_enable();
+
 	/* Try to emulate it if we should. */
 	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
 		switch (emulate_instruction(regs)) {

commit c902be71dc6d5e8473bd021feafc8c3608e2b82a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Jan 4 19:55:53 2006 +0000

    [PATCH] cell: enable pause(0) in cpu_idle
    
    This patch enables support for pause(0) power management state
    for the Cell Broadband Processor, which is import for power efficient
    operation. The pervasive infrastructure will in the future enable
    us to introduce more functionality specific to the Cell's
    pervasive unit.
    
    From: Maximino Aguilar <maguilar@us.ibm.com>
    Signed-off-by: Arnd Bergmann <arndb@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6c793463d511..7509aa6474f2 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -230,8 +230,10 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 void system_reset_exception(struct pt_regs *regs)
 {
 	/* See if any machine dependent calls */
-	if (ppc_md.system_reset_exception)
-		ppc_md.system_reset_exception(regs);
+	if (ppc_md.system_reset_exception) {
+		if (ppc_md.system_reset_exception(regs))
+			return;
+	}
 
 	die("System Reset", regs, SIGABRT);
 

commit 555d97ac87aef08bb55dff6f05e68fe2987d6f6d
Author: Andy Fleming <afleming@freescale.com>
Date:   Thu Dec 15 20:02:04 2005 -0600

    [PATCH] powerpc: G4+ oprofile support
    
    This patch adds oprofile support for the 7450 and all its multitudinous
    derivatives.
    
    * Added 7450 (and derivatives) support for oprofile
    * Changed e500 cputable to have oprofile model and cpu_type fields
    * Added support for classic 32-bit performance monitor interrupt
    * Cleaned up common powerpc oprofile code to be as common as possible
    * Cleaned up oprofile_impl.h to reflect 32 bit classic code
    * Added 32-bit MMCRx bitfield definitions and SPR numbers
    
    Signed-off-by: Andy Fleming <afleming@freescale.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 76b579ca5230..6c793463d511 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -901,12 +901,10 @@ void altivec_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
 }
 
-#if defined(CONFIG_PPC64) || defined(CONFIG_E500)
 void performance_monitor_exception(struct pt_regs *regs)
 {
 	perf_irq(regs);
 }
-#endif
 
 #ifdef CONFIG_8xx
 void SoftwareEmulation(struct pt_regs *regs)

commit cc53291521701f9c7c7265bbb3c140563174d8b2
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Sun Dec 4 18:39:43 2005 +1100

    [PATCH] powerpc: Add arch dependent basic infrastructure for Kdump.
    
    Implementing the machine_crash_shutdown which will be called by
    crash_kexec (called in case of a panic, sysrq etc.). Disable the
    interrupts, shootdown cpus using debugger IPI and collect regs
    for all CPUs.
    
    elfcorehdr= specifies the location of elf core header stored by
    the crashed kernel. This command line option will be passed by
    the kexec-tools to capture kernel.
    
    savemaxmem= specifies the actual memory size that the first kernel
    has and this value will be used for dumping in the capture kernel.
    This command line option will be passed by the kexec-tools to
    capture kernel.
    
    Signed-off-by: Haren Myneni <haren@us.ibm.com>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 1511454c4690..76b579ca5230 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -31,6 +31,7 @@
 #include <linux/prctl.h>
 #include <linux/delay.h>
 #include <linux/kprobes.h>
+#include <linux/kexec.h>
 
 #include <asm/kdebug.h>
 #include <asm/pgtable.h>
@@ -95,7 +96,7 @@ static DEFINE_SPINLOCK(die_lock);
 
 int die(const char *str, struct pt_regs *regs, long err)
 {
-	static int die_counter;
+	static int die_counter, crash_dump_start = 0;
 	int nl = 0;
 
 	if (debugger(regs))
@@ -156,7 +157,21 @@ int die(const char *str, struct pt_regs *regs, long err)
 	print_modules();
 	show_regs(regs);
 	bust_spinlocks(0);
+
+	if (!crash_dump_start && kexec_should_crash(current)) {
+		crash_dump_start = 1;
+		spin_unlock_irq(&die_lock);
+		crash_kexec(regs);
+		/* NOTREACHED */
+	}
 	spin_unlock_irq(&die_lock);
+	if (crash_dump_start)
+		/*
+		 * Only for soft-reset: Other CPUs will be responded to an IPI
+		 * sent by first kexec CPU.
+		 */
+		for(;;)
+			;
 
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");

commit a7f290dad32ee34d931561b7943c858fe2aae503
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Nov 11 21:15:21 2005 +1100

    [PATCH] powerpc: Merge vdso's and add vdso support to 32 bits kernel
    
    This patch moves the vdso's to arch/powerpc, adds support for the 32
    bits vdso to the 32 bits kernel, rename systemcfg (finally !), and adds
    some new (still untested) routines to both vdso's: clock_gettime() with
    support for CLOCK_REALTIME and CLOCK_MONOTONIC, clock_getres() (same
    clocks) and get_tbfreq() for glibc to retreive the timebase frequency.
    
    Tom,Steve: The implementation of get_tbfreq() I've done for 32 bits
    returns a long long (r3, r4) not a long. This is such that if we ever
    add support for >4Ghz timebases on ppc32, the userland interface won't
    have to change.
    
    I have tested gettimeofday() using some glibc patches in both ppc32 and
    ppc64 kernels using 32 bits userland (I haven't had a chance to test a
    64 bits userland yet, but the implementation didn't change and was
    tested earlier). I haven't tested yet the new functions.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 2020bb7648fb..1511454c4690 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -49,7 +49,6 @@
 #ifdef CONFIG_PPC64
 #include <asm/firmware.h>
 #include <asm/processor.h>
-#include <asm/systemcfg.h>
 #endif
 
 #ifdef CONFIG_PPC64	/* XXX */

commit 799d6046d3fb557006e6d7c9767fdb96479b0e0a
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Nov 10 13:37:51 2005 +1100

    [PATCH] powerpc: merge code values for identifying platforms
    
    This patch merges platform codes.  systemcfg->platform is no longer used,
    systemcfg use in general is deprecated as much as possible (and renamed
    _systemcfg before it gets completely moved elsewhere in a future patch),
    _machine is now used on ppc64 along as ppc32.  Platform codes aren't gone
    yet but we are getting a step closer. A bunch of asm code in head[_64].S
    is also turned into C code.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 0578f8387603..2020bb7648fb 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -129,7 +129,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	nl = 1;
 #endif
 #ifdef CONFIG_PPC64
-	switch (systemcfg->platform) {
+	switch (_machine) {
 	case PLATFORM_PSERIES:
 		printk("PSERIES ");
 		nl = 1;

commit a31751e04ea738acc8042e5aa1a825901aa7b97f
Author: Matt Porter <mporter@kernel.crashing.org>
Date:   Tue Nov 8 21:34:38 2005 -0800

    [PATCH] ppc32: fix perf_irq extern on e500
    
    Fixes e500 build and cleans up traps.c by moving perf_irq extern to
    pmc.h.
    
    Signed-off-by: Matt Porter <mporter@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 32f215825e8d..0578f8387603 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -887,10 +887,6 @@ void altivec_unavailable_exception(struct pt_regs *regs)
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
 }
 
-#ifdef CONFIG_PPC64
-extern perf_irq_t perf_irq;
-#endif
-
 #if defined(CONFIG_PPC64) || defined(CONFIG_E500)
 void performance_monitor_exception(struct pt_regs *regs)
 {

commit 570142ca37248291c03df9852a5a0ce97f756464
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Nov 7 19:05:31 2005 +1100

    [PATCH] ppc64: remove some direct xmon calls
    
    Even though we can enable and disable xmon at runtime now, there are a
    few places in the merge tree that call xmon and xmon_printf directly.
    
    In the case below we call die() which will call xmon if it is enabled.
    
    Also remove an unnecessary include of xmon.h in smp.c.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 07e5ee40b870..32f215825e8d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -39,7 +39,6 @@
 #include <asm/io.h>
 #include <asm/machdep.h>
 #include <asm/rtas.h>
-#include <asm/xmon.h>
 #include <asm/pmc.h>
 #ifdef CONFIG_PPC32
 #include <asm/reg.h>
@@ -748,22 +747,12 @@ static int check_bug_trap(struct pt_regs *regs)
 		return 0;
 	if (bug->line & BUG_WARNING_TRAP) {
 		/* this is a WARN_ON rather than BUG/BUG_ON */
-#ifdef CONFIG_XMON
-		xmon_printf(KERN_ERR "Badness in %s at %s:%ld\n",
-		       bug->function, bug->file,
-		       bug->line & ~BUG_WARNING_TRAP);
-#endif /* CONFIG_XMON */		
 		printk(KERN_ERR "Badness in %s at %s:%ld\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
 		dump_stack();
 		return 1;
 	}
-#ifdef CONFIG_XMON
-	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%ld!\n",
-	       bug->function, bug->file, bug->line);
-	xmon(regs);
-#endif /* CONFIG_XMON */
 	printk(KERN_CRIT "kernel BUG in %s at %s:%ld!\n",
 	       bug->function, bug->file, bug->line);
 

commit 104dd65fef378773ec0510c788bd4b5ad6ea1121
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Nov 2 15:19:47 2005 +1100

    powerpc: clean up bug.h further
    
    This simplifies the macros which are different between 32-bit and
    64-bit.  It also fixes a couple of printks on the bug->line element,
    which is now a long.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index bb0d00284a7e..07e5ee40b870 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -749,22 +749,22 @@ static int check_bug_trap(struct pt_regs *regs)
 	if (bug->line & BUG_WARNING_TRAP) {
 		/* this is a WARN_ON rather than BUG/BUG_ON */
 #ifdef CONFIG_XMON
-		xmon_printf(KERN_ERR "Badness in %s at %s:%d\n",
+		xmon_printf(KERN_ERR "Badness in %s at %s:%ld\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
 #endif /* CONFIG_XMON */		
-		printk(KERN_ERR "Badness in %s at %s:%d\n",
+		printk(KERN_ERR "Badness in %s at %s:%ld\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
 		dump_stack();
 		return 1;
 	}
 #ifdef CONFIG_XMON
-	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
+	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%ld!\n",
 	       bug->function, bug->file, bug->line);
 	xmon(regs);
 #endif /* CONFIG_XMON */
-	printk(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
+	printk(KERN_CRIT "kernel BUG in %s at %s:%ld!\n",
 	       bug->function, bug->file, bug->line);
 
 	return 0;

commit f3f66f599db131ea57dc567ffd931d269dbc690e
Author: Arnd Bergmann <arndb@de.ibm.com>
Date:   Mon Oct 31 20:08:37 2005 -0500

    [PATCH] powerpc: Rename BPA to Cell
    
    The official name for BPA is now CBEA (Cell Broadband
    Engine Architecture). This patch renames all occurences
    of the term BPA to 'Cell' for easier recognition.
    
    Signed-off-by: Arnd Bergmann <arndb@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 5d638ecddbd0..bb0d00284a7e 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -147,8 +147,8 @@ int die(const char *str, struct pt_regs *regs, long err)
 		printk("POWERMAC ");
 		nl = 1;
 		break;
-	case PLATFORM_BPA:
-		printk("BPA ");
+	case PLATFORM_CELL:
+		printk("CELL ");
 		nl = 1;
 		break;
 	}

commit 25c8a78b1e00ac0cc640677eda78b462c2cd4c6e
Author: David Gibson <david@gibson.dropbear.id.au>
Date:   Thu Oct 27 16:27:25 2005 +1000

    [PATCH] powerpc: Fix handling of fpscr on 64-bit
    
    The recent merge of fpu.S broken the handling of fpscr for
    ARCH=powerpc and CONFIG_PPC64=y.  FP registers could be corrupted,
    leading to strange random application crashes.
    
    The confusion arises, because the thread_struct has (and requires) a
    64-bit area to save the fpscr, because we use load/store double
    instructions to get it in to/out of the FPU.  However, only the low
    32-bits are actually used, so we want to treat it as a 32-bit quantity
    when manipulating its bits to avoid extra load/stores on 32-bit.  This
    patch replaces the current definition with a structure of two 32-bit
    quantities (pad and val), to clarify things as much as is possible.
    The 'val' field is used when manipulating bits, the structure itself
    is used when obtaining the address for loading/unloading the value
    from the FPU.
    
    While we're at it, consolidate the 4 (!) almost identical versions of
    cvt_fd() and cvt_df() (arch/ppc/kernel/misc.S,
    arch/ppc64/kernel/misc.S, arch/powerpc/kernel/misc_32.S,
    arch/powerpc/kernel/misc_64.S) into a single version in fpu.S.  The
    new version takes a pointer to thread_struct and applies the correct
    offset itself, rather than a pointer to the fpscr field itself, again
    to avoid confusion as to which is the correct field to use.
    
    Finally, this patch makes ARCH=ppc64 also use the consolidated fpu.S
    code, which it previously did not.
    
    Built for G5 (ARCH=ppc64 and ARCH=powerpc), 32-bit powermac (ARCH=ppc
    and ARCH=powerpc) and Walnut (ARCH=ppc, CONFIG_MATH_EMULATION=y).
    Booted on G5 (ARCH=powerpc) and things which previously fell over no
    longer do.
    
    Signed-off-by: David Gibson <dwg@au1.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index f87580382da4..5d638ecddbd0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -549,7 +549,7 @@ static void parse_fpe(struct pt_regs *regs)
 
 	flush_fp_to_thread(current);
 
-	fpscr = current->thread.fpscr;
+	fpscr = current->thread.fpscr.val;
 
 	/* Invalid operation */
 	if ((fpscr & FPSCR_VE) && (fpscr & FPSCR_VX))

commit f7f6f4fea68d9981d65f99a589ad85f510924d99
Author: David Gibson <david@gibson.dropbear.id.au>
Date:   Wed Oct 19 14:53:32 2005 +1000

    [PATCH] powerpc: Merge ppc64 pmc.[ch] with ppc32 perfmon.[ch]
    
    This patches the ppc32 and ppc64 versions of the headers and .c files
    with helper functions for manipulating the performance counting
    hardware.  As a side effect, it removes use of the term "perfmon" from
    ppc32, thus avoiding confusion with the unrelated performance counter
    interface from HP Labs also called "perfmon".
    
    Built, but not booted, for g5, pSeries, iSeries, and 32-bit Powermac
    with both ARCH=powerpc and ARCH=ppc{,64} as appropriate.
    
    Signed-off-by: David Gibson <dwg@au1.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 6a881e3ea01d..f87580382da4 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -40,9 +40,9 @@
 #include <asm/machdep.h>
 #include <asm/rtas.h>
 #include <asm/xmon.h>
+#include <asm/pmc.h>
 #ifdef CONFIG_PPC32
 #include <asm/reg.h>
-#include <asm/perfmon.h>
 #endif
 #ifdef CONFIG_PMAC_BACKLIGHT
 #include <asm/backlight.h>
@@ -51,7 +51,6 @@
 #include <asm/firmware.h>
 #include <asm/processor.h>
 #include <asm/systemcfg.h>
-#include <asm/pmc.h>
 #endif
 
 #ifdef CONFIG_PPC64	/* XXX */

commit 8641778049e75c1da66e66441a6d8b7a2069f607
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Oct 10 22:37:57 2005 +1000

    powerpc: Reduce the 32/64-bit differences in traps.c
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index a2e4ad3f5a75..6a881e3ea01d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -31,29 +31,33 @@
 #include <linux/prctl.h>
 #include <linux/delay.h>
 #include <linux/kprobes.h>
-#include <asm/kdebug.h>
 
+#include <asm/kdebug.h>
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
 #include <asm/io.h>
+#include <asm/machdep.h>
+#include <asm/rtas.h>
+#include <asm/xmon.h>
 #ifdef CONFIG_PPC32
 #include <asm/reg.h>
-#include <asm/xmon.h>
+#include <asm/perfmon.h>
+#endif
 #ifdef CONFIG_PMAC_BACKLIGHT
 #include <asm/backlight.h>
 #endif
-#include <asm/perfmon.h>
-#endif
 #ifdef CONFIG_PPC64
+#include <asm/firmware.h>
 #include <asm/processor.h>
-#include <asm/ppcdebug.h>
-#include <asm/rtas.h>
 #include <asm/systemcfg.h>
-#include <asm/machdep.h>
 #include <asm/pmc.h>
 #endif
 
+#ifdef CONFIG_PPC64	/* XXX */
+#define _IO_BASE	pci_io_base
+#endif
+
 #ifdef CONFIG_DEBUGGER
 int (*__debugger)(struct pt_regs *regs);
 int (*__debugger_ipi)(struct pt_regs *regs);
@@ -277,7 +281,6 @@ static inline int check_io_access(struct pt_regs *regs)
 }
 
 #if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
-
 /* On 4xx, the reason for the machine check or program exception
    is in the ESR. */
 #define get_reason(regs)	((regs)->dsisr)
@@ -296,7 +299,6 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	(current->thread.dbcr0 &= ~DBCR0_IC)
 
 #else
-
 /* On non-4xx, the reason for the machine check or program
    exception is in the MSR. */
 #define get_reason(regs)	((regs)->msr)
@@ -475,7 +477,7 @@ void machine_check_exception(struct pt_regs *regs)
 	 * additional info, e.g. bus error registers.
 	 */
 	platform_machine_check(regs);
-#endif /* CONFIG_PPC32 */
+#endif /* CONFIG_PPC64 */
 
 	if (debugger_fault_handler(regs))
 		return;
@@ -486,12 +488,10 @@ void machine_check_exception(struct pt_regs *regs)
 		panic("Unrecoverable Machine check");
 }
 
-#ifdef CONFIG_PPC32
 void SMIException(struct pt_regs *regs)
 {
 	die("System Management Interrupt", regs, SIGABRT);
 }
-#endif
 
 void unknown_exception(struct pt_regs *regs)
 {
@@ -511,12 +511,10 @@ void instruction_breakpoint_exception(struct pt_regs *regs)
 	_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
 }
 
-#ifdef CONFIG_PPC32
 void RunModeException(struct pt_regs *regs)
 {
 	_exception(SIGTRAP, regs, 0, 0);
 }
-#endif
 
 void __kprobes single_step_exception(struct pt_regs *regs)
 {
@@ -542,7 +540,6 @@ static void emulate_single_step(struct pt_regs *regs)
 	if (single_stepping(regs)) {
 		clear_single_step(regs);
 		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
-		single_step_exception(regs);
 	}
 }
 
@@ -587,6 +584,7 @@ static void parse_fpe(struct pt_regs *regs)
  * There are a couple of ways to do this, either "decode" the instruction
  * or directly match lots of bits.  In this case, matching lots of
  * bits is faster and easier.
+ *
  */
 #define INST_MFSPR_PVR		0x7c1f42a6
 #define INST_MFSPR_PVR_MASK	0xfc1fffff
@@ -597,8 +595,6 @@ static void parse_fpe(struct pt_regs *regs)
 #define INST_MCRXR		0x7c000400
 #define INST_MCRXR_MASK		0x7c0007fe
 
-#ifdef CONFIG_PPC32
-
 #define INST_STRING		0x7c00042a
 #define INST_STRING_MASK	0x7c0007fe
 #define INST_STRING_GEN_MASK	0x7c00067e
@@ -674,7 +670,6 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 
 	return 0;
 }
-#endif /* CONFIG_PPC32 */
 
 static int emulate_instruction(struct pt_regs *regs)
 {
@@ -701,28 +696,17 @@ static int emulate_instruction(struct pt_regs *regs)
 
 	/* Emulate the mcrxr insn.  */
 	if ((instword & INST_MCRXR_MASK) == INST_MCRXR) {
-		unsigned int shift = (instword >> 21) & 0x1c;
+		int shift = (instword >> 21) & 0x1c;
 		unsigned long msk = 0xf0000000UL >> shift;
-#ifdef CONFIG_PPC64
-		static int warned;
 
-		if (!warned) {
-			printk(KERN_WARNING
-			       "process %d (%s) uses obsolete 'mcrxr' insn\n",
-			       current->pid, current->comm);
-			warned = 1;
-		}
-#endif
 		regs->ccr = (regs->ccr & ~msk) | ((regs->xer >> shift) & msk);
 		regs->xer &= ~0xf0000000UL;
 		return 0;
 	}
 
-#ifdef CONFIG_PPC32
 	/* Emulate load/store string insn. */
 	if ((instword & INST_STRING_GEN_MASK) == INST_STRING)
 		return emulate_string_inst(regs, instword);
-#endif
 
 	return -EINVAL;
 }
@@ -769,22 +753,18 @@ static int check_bug_trap(struct pt_regs *regs)
 		xmon_printf(KERN_ERR "Badness in %s at %s:%d\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
-#endif
+#endif /* CONFIG_XMON */		
 		printk(KERN_ERR "Badness in %s at %s:%d\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
-#ifdef CONFIG_PPC32
 		dump_stack();
-#else
-		show_stack(current, (void *)regs->gpr[1]);
-#endif
 		return 1;
 	}
-#if defined(CONFIG_PPC32) && defined(CONFIG_XMON)
+#ifdef CONFIG_XMON
 	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
 	       bug->function, bug->file, bug->line);
 	xmon(regs);
-#endif
+#endif /* CONFIG_XMON */
 	printk(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
 	       bug->function, bug->file, bug->line);
 
@@ -873,7 +853,6 @@ void alignment_exception(struct pt_regs *regs)
 	_exception(SIGBUS, regs, BUS_ADRALN, regs->dar);
 }
 
-#ifdef CONFIG_PPC32
 void StackOverflow(struct pt_regs *regs)
 {
 	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",
@@ -897,7 +876,6 @@ void trace_syscall(struct pt_regs *regs)
 	       current, current->pid, regs->nip, regs->link, regs->gpr[0],
 	       regs->ccr&0x10000000?"Error=":"", regs->gpr[3], print_tainted());
 }
-#endif /* CONFIG_PPC32 */
 
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
@@ -963,7 +941,6 @@ void SoftwareEmulation(struct pt_regs *regs)
 }
 #endif /* CONFIG_8xx */
 
-#ifdef CONFIG_PPC32
 #if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
 
 void DebugException(struct pt_regs *regs, unsigned long debug_status)
@@ -992,7 +969,6 @@ void TAUException(struct pt_regs *regs)
 	       regs->nip, regs->msr, regs->trap, print_tainted());
 }
 #endif /* CONFIG_INT_TAU */
-#endif /* CONFIG_PPC32*/
 
 #ifdef CONFIG_ALTIVEC
 void altivec_assist_exception(struct pt_regs *regs)

commit 8dad3f9257414f151cd821bfe01f54d7f52d2507
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Oct 6 13:27:05 2005 +1000

    powerpc: Merge traps.c a bit more
    
    This reduces the differences between ppc32 and ppc64 in
    arch/powerpc/kernel/traps.c a bit further.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 37b961f1e279..a2e4ad3f5a75 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -21,19 +21,17 @@
 #include <linux/mm.h>
 #include <linux/stddef.h>
 #include <linux/unistd.h>
+#include <linux/ptrace.h>
 #include <linux/slab.h>
 #include <linux/user.h>
 #include <linux/a.out.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
 #include <linux/module.h>
+#include <linux/prctl.h>
 #include <linux/delay.h>
 #include <linux/kprobes.h>
 #include <asm/kdebug.h>
-#ifdef CONFIG_PPC32
-#include <linux/ptrace.h>
-#include <linux/prctl.h>
-#endif
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
@@ -56,12 +54,6 @@
 #include <asm/pmc.h>
 #endif
 
-#ifdef CONFIG_PPC64
-#define __KPROBES	__kprobes
-#else
-#define __KPROBES
-#endif
-
 #ifdef CONFIG_DEBUGGER
 int (*__debugger)(struct pt_regs *regs);
 int (*__debugger_ipi)(struct pt_regs *regs);
@@ -111,7 +103,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
-#if defined(CONFIG_PPC32) && defined(CONFIG_PMAC_BACKLIGHT)
+#ifdef CONFIG_PMAC_BACKLIGHT
 	if (_machine == _MACH_Pmac) {
 		set_backlight_enable(1);
 		set_backlight_level(BACKLIGHT_MAX);
@@ -175,11 +167,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 #endif
 		panic("Fatal exception");
 	}
-#ifdef CONFIG_PPC32
 	do_exit(err);
-#else
-	do_exit(SIGSEGV);
-#endif
 
 	return 0;
 }
@@ -199,7 +187,6 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	info.si_addr = (void __user *) addr;
 	force_sig_info(signr, &info, current);
 
-#ifdef CONFIG_PPC32
 	/*
 	 * Init gets no signals that it doesn't have a handler for.
 	 * That's all very well, but if it has caused a synchronous
@@ -221,7 +208,6 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 			do_exit(signr);
 		}
 	}
-#endif
 }
 
 #ifdef CONFIG_PPC64
@@ -231,7 +217,7 @@ void system_reset_exception(struct pt_regs *regs)
 	if (ppc_md.system_reset_exception)
 		ppc_md.system_reset_exception(regs);
 
-	die("System Reset", regs, 0);
+	die("System Reset", regs, SIGABRT);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
@@ -241,7 +227,6 @@ void system_reset_exception(struct pt_regs *regs)
 }
 #endif
 
-#ifdef CONFIG_PPC32
 /*
  * I/O accesses can cause machine checks on powermacs.
  * Check if the NIP corresponds to the address of a sync
@@ -290,7 +275,6 @@ static inline int check_io_access(struct pt_regs *regs)
 #endif /* CONFIG_PPC_PMAC */
 	return 0;
 }
-#endif /* CONFIG_PPC32 */
 
 #if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
 
@@ -326,7 +310,6 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
-#ifdef CONFIG_PPC32
 /*
  * This is "fall-back" implementation for configurations
  * which don't provide platform-specific machine check info
@@ -335,7 +318,6 @@ void __attribute__ ((weak))
 platform_machine_check(struct pt_regs *regs)
 {
 }
-#endif
 
 void machine_check_exception(struct pt_regs *regs)
 {
@@ -497,13 +479,7 @@ void machine_check_exception(struct pt_regs *regs)
 
 	if (debugger_fault_handler(regs))
 		return;
-	die("Machine check", regs,
-#ifdef CONFIG_PPC32
-		SIGBUS
-#else
-		0
-#endif
-	);
+	die("Machine check", regs, SIGBUS);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
@@ -542,13 +518,9 @@ void RunModeException(struct pt_regs *regs)
 }
 #endif
 
-void __KPROBES single_step_exception(struct pt_regs *regs)
+void __kprobes single_step_exception(struct pt_regs *regs)
 {
-#ifdef CONFIG_PPC32
 	regs->msr &= ~(MSR_SE | MSR_BE);  /* Turn off 'trace' bits */
-#else
-	regs->msr &= ~MSR_SE;  /* Turn off 'trace' bit */
-#endif
 
 	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
@@ -565,15 +537,12 @@ void __KPROBES single_step_exception(struct pt_regs *regs)
  * pretend we got a single-step exception.  This was pointed out
  * by Kumar Gala.  -- paulus
  */
-static inline void emulate_single_step(struct pt_regs *regs)
+static void emulate_single_step(struct pt_regs *regs)
 {
 	if (single_stepping(regs)) {
-#ifdef CONFIG_PPC32
 		clear_single_step(regs);
 		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
-#else
 		single_step_exception(regs);
-#endif
 	}
 }
 
@@ -582,17 +551,7 @@ static void parse_fpe(struct pt_regs *regs)
 	int code = 0;
 	unsigned long fpscr;
 
-#ifdef CONFIG_PPC32
-	/* We must make sure the FP state is consistent with
-	 * our MSR_FP in regs
-	 */
-	preempt_disable();
-	if (regs->msr & MSR_FP)
-		giveup_fpu(current);
-	preempt_enable();
-#else
 	flush_fp_to_thread(current);
-#endif
 
 	fpscr = current->thread.fpscr;
 
@@ -737,19 +696,8 @@ static int emulate_instruction(struct pt_regs *regs)
 	}
 
 	/* Emulating the dcba insn is just a no-op.  */
-	if ((instword & INST_DCBA_MASK) == INST_DCBA) {
-#ifdef CONFIG_PPC64
-		static int warned;
-
-		if (!warned) {
-			printk(KERN_WARNING
-			       "process %d (%s) uses obsolete 'dcba' insn\n",
-			       current->pid, current->comm);
-			warned = 1;
-		}
-#endif /* CONFIG_PPC64 */
+	if ((instword & INST_DCBA_MASK) == INST_DCBA)
 		return 0;
-	}
 
 	/* Emulate the mcrxr insn.  */
 	if ((instword & INST_MCRXR_MASK) == INST_MCRXR) {
@@ -817,7 +765,7 @@ static int check_bug_trap(struct pt_regs *regs)
 		return 0;
 	if (bug->line & BUG_WARNING_TRAP) {
 		/* this is a WARN_ON rather than BUG/BUG_ON */
-#if defined(CONFIG_PPC32) && defined(CONFIG_XMON)
+#ifdef CONFIG_XMON
 		xmon_printf(KERN_ERR "Badness in %s at %s:%d\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
@@ -843,12 +791,12 @@ static int check_bug_trap(struct pt_regs *regs)
 	return 0;
 }
 
-void __KPROBES program_check_exception(struct pt_regs *regs)
+void __kprobes program_check_exception(struct pt_regs *regs)
 {
 	unsigned int reason = get_reason(regs);
-#if defined(CONFIG_PPC32) && defined(CONFIG_MATH_EMULATION)
 	extern int do_mathemu(struct pt_regs *regs);
 
+#ifdef CONFIG_MATH_EMULATION
 	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
 	 * but there seems to be a hardware bug on the 405GP (RevD)
 	 * that means ESR is sometimes set incorrectly - either to
@@ -860,58 +808,45 @@ void __KPROBES program_check_exception(struct pt_regs *regs)
 		emulate_single_step(regs);
 		return;
 	}
-#endif
-
-#ifdef CONFIG_PPC64
-	if (debugger_fault_handler(regs))
-		return;
-#endif
+#endif /* CONFIG_MATH_EMULATION */
 
 	if (reason & REASON_FP) {
 		/* IEEE FP exception */
 		parse_fpe(regs);
-	} else if (reason & REASON_TRAP) {
+		return;
+	}
+	if (reason & REASON_TRAP) {
 		/* trap exception */
-#ifdef CONFIG_PPC64
 		if (notify_die(DIE_BPT, "breakpoint", regs, 5, 5, SIGTRAP)
 				== NOTIFY_STOP)
 			return;
-#endif
 		if (debugger_bpt(regs))
 			return;
 		if (check_bug_trap(regs)) {
 			regs->nip += 4;
 			return;
 		}
-		_exception(SIGTRAP, regs, TRAP_BRKPT,
-#ifdef CONFIG_PPC32
-			0
-#else
-			regs->nip
-#endif
-		);
-	} else
-#ifdef CONFIG_PPC32
-	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED))
-#endif
-	{
-		/* Privileged or illegal instruction; try to emulate it. */
+		_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
+		return;
+	}
+
+	/* Try to emulate it if we should. */
+	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
 		switch (emulate_instruction(regs)) {
 		case 0:
 			regs->nip += 4;
 			emulate_single_step(regs);
-			break;
+			return;
 		case -EFAULT:
 			_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
-			break;
-		default:
-			if (reason & REASON_PRIVILEGED)
-				_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
-			else
-				_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-			break;
+			return;
 		}
 	}
+
+	if (reason & REASON_PRIVILEGED)
+		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
+	else
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 }
 
 void alignment_exception(struct pt_regs *regs)
@@ -929,25 +864,13 @@ void alignment_exception(struct pt_regs *regs)
 	/* Operand address was bad */
 	if (fixed == -EFAULT) {
 		if (user_mode(regs))
-			_exception(SIGSEGV, regs,
-#ifdef CONFIG_PPC32
-				SEGV_ACCERR,
-#else
-				SEGV_MAPERR,
-#endif
-			regs->dar);
+			_exception(SIGSEGV, regs, SEGV_ACCERR, regs->dar);
 		else
 			/* Search exception table */
 			bad_page_fault(regs, regs->dar, SIGSEGV);
 		return;
 	}
-	_exception(SIGBUS, regs, BUS_ADRALN,
-#ifdef CONFIG_PPC32
-		regs->dar
-#else
-		regs->nip
-#endif
-	);
+	_exception(SIGBUS, regs, BUS_ADRALN, regs->dar);
 }
 
 #ifdef CONFIG_PPC32
@@ -976,18 +899,16 @@ void trace_syscall(struct pt_regs *regs)
 }
 #endif /* CONFIG_PPC32 */
 
-#ifdef CONFIG_PPC64
 void kernel_fp_unavailable_exception(struct pt_regs *regs)
 {
 	printk(KERN_EMERG "Unrecoverable FP Unavailable Exception "
 			  "%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable FP Unavailable Exception", regs, SIGABRT);
 }
-#endif
 
 void altivec_unavailable_exception(struct pt_regs *regs)
 {
-#if !defined(CONFIG_ALTIVEC) || defined(CONFIG_PPC64)
+#if !defined(CONFIG_ALTIVEC)
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
@@ -995,22 +916,9 @@ void altivec_unavailable_exception(struct pt_regs *regs)
 		return;
 	}
 #endif
-#ifdef CONFIG_PPC32
-	{
-	static int kernel_altivec_count;
-
-	/* The kernel has executed an altivec instruction without
-	   first enabling altivec.  Whinge but let it do it. */
-	if (++kernel_altivec_count < 10)
-		printk(KERN_ERR "AltiVec used in kernel (task=%p, pc=%lx)\n",
-		       current, regs->nip);
-	regs->msr |= MSR_VEC;
-	}
-#else
 	printk(KERN_EMERG "Unrecoverable VMX/Altivec Unavailable Exception "
 			"%lx at %lx\n", regs->trap, regs->nip);
 	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
-#endif
 }
 
 #ifdef CONFIG_PPC64
@@ -1024,8 +932,7 @@ void performance_monitor_exception(struct pt_regs *regs)
 }
 #endif
 
-
-#if defined(CONFIG_PPC32) && defined(CONFIG_8xx)
+#ifdef CONFIG_8xx
 void SoftwareEmulation(struct pt_regs *regs)
 {
 	extern int do_mathemu(struct pt_regs *);
@@ -1054,7 +961,7 @@ void SoftwareEmulation(struct pt_regs *regs)
 	} else
 		emulate_single_step(regs);
 }
-#endif /* defined(CONFIG_PPC32) && defined(CONFIG_8xx) */
+#endif /* CONFIG_8xx */
 
 #ifdef CONFIG_PPC32
 #if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
@@ -1091,29 +998,14 @@ void TAUException(struct pt_regs *regs)
 void altivec_assist_exception(struct pt_regs *regs)
 {
 	int err;
-#ifdef CONFIG_PPC64
-	siginfo_t info;
-#endif
 
-#ifdef CONFIG_PPC32
-	preempt_disable();
-	if (regs->msr & MSR_VEC)
-		giveup_altivec(current);
-	preempt_enable();
-#endif
 	if (!user_mode(regs)) {
 		printk(KERN_EMERG "VMX/Altivec assist exception in kernel mode"
 		       " at %lx\n", regs->nip);
-		die("Kernel "
-#ifdef CONFIG_PPC64
-			"VMX/"
-#endif
-			"Altivec assist exception", regs, SIGILL);
+		die("Kernel VMX/Altivec assist exception", regs, SIGILL);
 	}
 
-#ifdef CONFIG_PPC64
 	flush_altivec_to_thread(current);
-#endif /* CONFIG_PPC64 */
 
 	err = emulate_altivec(regs);
 	if (err == 0) {
@@ -1124,15 +1016,7 @@ void altivec_assist_exception(struct pt_regs *regs)
 
 	if (err == -EFAULT) {
 		/* got an error reading the instruction */
-#ifdef CONFIG_PPC32
 		_exception(SIGSEGV, regs, SEGV_ACCERR, regs->nip);
-#else
-		info.si_signo = SIGSEGV;
-		info.si_errno = 0;
-		info.si_code = SEGV_MAPERR;
-		info.si_addr = (void __user *) regs->nip;
-		force_sig_info(SIGSEGV, &info, current);
-#endif
 	} else {
 		/* didn't recognize the instruction */
 		/* XXX quick hack for now: set the non-Java bit in the VSCR */
@@ -1144,7 +1028,6 @@ void altivec_assist_exception(struct pt_regs *regs)
 }
 #endif /* CONFIG_ALTIVEC */
 
-#ifdef CONFIG_PPC32
 #ifdef CONFIG_FSL_BOOKE
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)
@@ -1194,9 +1077,7 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	return;
 }
 #endif
-#endif /* CONFIG_PPC32 */
 
-#ifdef CONFIG_PPC64
 /*
  * We enter here if we get an unrecoverable exception, that is, one
  * that happened at a point where the RI (recoverable interrupt) bit
@@ -1209,9 +1090,7 @@ void unrecoverable_exception(struct pt_regs *regs)
 	       regs->trap, regs->nip);
 	die("Unrecoverable exception", regs, SIGABRT);
 }
-#endif /* CONFIG_PPC64 */
 
-#ifdef CONFIG_PPC32
 #ifdef CONFIG_BOOKE_WDT
 /*
  * Default handler for a Watchdog exception,
@@ -1230,9 +1109,7 @@ void WatchdogException(struct pt_regs *regs)
 	WatchdogHandler(regs);
 }
 #endif
-#endif /* CONFIG_PPC32 */
 
-#ifdef CONFIG_PPC64
 /*
  * We enter here if we discover during exception entry that we are
  * running in supervisor mode with a userspace value in the stack pointer.
@@ -1243,7 +1120,6 @@ void kernel_bad_stack(struct pt_regs *regs)
 	       regs->gpr[1], regs->nip);
 	die("Bad kernel stack pointer", regs, SIGABRT);
 }
-#endif
 
 void __init trap_init(void)
 {

commit dc1c1ca3dcd94c545c5e01d7c06b46824d43f4d0
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Sat Oct 1 18:43:42 2005 +1000

    powerpc: merge idle_power4.S and trapc.s
    
    Use idle_power4.S from ppc64 as we are not going to support
    32 bit power4 in the merged tree.
    
    Merge ppc64 traps.c into powerpc traps.c:
            use ppc64 versions of exception routine names
                    (as they don't have StudlyCaps)
            make all the versions if die() have the same
                    prototype
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index c7afbbba0f36..37b961f1e279 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -1,6 +1,4 @@
 /*
- *  arch/powerpc/kernel/traps.c
- *
  *  Copyright (C) 1995-1996  Gary Thomas (gdt@linuxppc.org)
  *
  *  This program is free software; you can redistribute it and/or
@@ -23,29 +21,46 @@
 #include <linux/mm.h>
 #include <linux/stddef.h>
 #include <linux/unistd.h>
-#include <linux/ptrace.h>
 #include <linux/slab.h>
 #include <linux/user.h>
 #include <linux/a.out.h>
 #include <linux/interrupt.h>
-#include <linux/config.h>
 #include <linux/init.h>
 #include <linux/module.h>
-#include <linux/prctl.h>
 #include <linux/delay.h>
 #include <linux/kprobes.h>
 #include <asm/kdebug.h>
+#ifdef CONFIG_PPC32
+#include <linux/ptrace.h>
+#include <linux/prctl.h>
+#endif
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
 #include <asm/io.h>
+#ifdef CONFIG_PPC32
 #include <asm/reg.h>
 #include <asm/xmon.h>
 #ifdef CONFIG_PMAC_BACKLIGHT
 #include <asm/backlight.h>
 #endif
 #include <asm/perfmon.h>
+#endif
+#ifdef CONFIG_PPC64
+#include <asm/processor.h>
+#include <asm/ppcdebug.h>
+#include <asm/rtas.h>
+#include <asm/systemcfg.h>
+#include <asm/machdep.h>
+#include <asm/pmc.h>
+#endif
+
+#ifdef CONFIG_PPC64
+#define __KPROBES	__kprobes
+#else
+#define __KPROBES
+#endif
 
 #ifdef CONFIG_DEBUGGER
 int (*__debugger)(struct pt_regs *regs);
@@ -96,7 +111,7 @@ int die(const char *str, struct pt_regs *regs, long err)
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
-#ifdef CONFIG_PMAC_BACKLIGHT
+#if defined(CONFIG_PPC32) && defined(CONFIG_PMAC_BACKLIGHT)
 	if (_machine == _MACH_Pmac) {
 		set_backlight_enable(1);
 		set_backlight_level(BACKLIGHT_MAX);
@@ -154,9 +169,17 @@ int die(const char *str, struct pt_regs *regs, long err)
 		panic("Fatal exception in interrupt");
 
 	if (panic_on_oops) {
+#ifdef CONFIG_PPC64
+		printk(KERN_EMERG "Fatal exception: panic in 5 seconds\n");
+		ssleep(5);
+#endif
 		panic("Fatal exception");
 	}
+#ifdef CONFIG_PPC32
 	do_exit(err);
+#else
+	do_exit(SIGSEGV);
+#endif
 
 	return 0;
 }
@@ -176,6 +199,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 	info.si_addr = (void __user *) addr;
 	force_sig_info(signr, &info, current);
 
+#ifdef CONFIG_PPC32
 	/*
 	 * Init gets no signals that it doesn't have a handler for.
 	 * That's all very well, but if it has caused a synchronous
@@ -197,6 +221,7 @@ void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
 			do_exit(signr);
 		}
 	}
+#endif
 }
 
 #ifdef CONFIG_PPC64
@@ -206,7 +231,7 @@ void system_reset_exception(struct pt_regs *regs)
 	if (ppc_md.system_reset_exception)
 		ppc_md.system_reset_exception(regs);
 
-	die("System Reset", regs, SIGABRT);
+	die("System Reset", regs, 0);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
@@ -216,6 +241,7 @@ void system_reset_exception(struct pt_regs *regs)
 }
 #endif
 
+#ifdef CONFIG_PPC32
 /*
  * I/O accesses can cause machine checks on powermacs.
  * Check if the NIP corresponds to the address of a sync
@@ -264,8 +290,10 @@ static inline int check_io_access(struct pt_regs *regs)
 #endif /* CONFIG_PPC_PMAC */
 	return 0;
 }
+#endif /* CONFIG_PPC32 */
 
 #if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+
 /* On 4xx, the reason for the machine check or program exception
    is in the ESR. */
 #define get_reason(regs)	((regs)->dsisr)
@@ -284,6 +312,7 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	(current->thread.dbcr0 &= ~DBCR0_IC)
 
 #else
+
 /* On non-4xx, the reason for the machine check or program
    exception is in the MSR. */
 #define get_reason(regs)	((regs)->msr)
@@ -297,6 +326,7 @@ static inline int check_io_access(struct pt_regs *regs)
 #define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
 #endif
 
+#ifdef CONFIG_PPC32
 /*
  * This is "fall-back" implementation for configurations
  * which don't provide platform-specific machine check info
@@ -305,8 +335,9 @@ void __attribute__ ((weak))
 platform_machine_check(struct pt_regs *regs)
 {
 }
+#endif
 
-void MachineCheckException(struct pt_regs *regs)
+void machine_check_exception(struct pt_regs *regs)
 {
 #ifdef CONFIG_PPC64
 	int recover = 0;
@@ -462,23 +493,31 @@ void MachineCheckException(struct pt_regs *regs)
 	 * additional info, e.g. bus error registers.
 	 */
 	platform_machine_check(regs);
-#endif /* CONFIG_PPC64 */
+#endif /* CONFIG_PPC32 */
 
 	if (debugger_fault_handler(regs))
 		return;
-	die("Machine check", regs, SIGBUS);
+	die("Machine check", regs,
+#ifdef CONFIG_PPC32
+		SIGBUS
+#else
+		0
+#endif
+	);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
 		panic("Unrecoverable Machine check");
 }
 
+#ifdef CONFIG_PPC32
 void SMIException(struct pt_regs *regs)
 {
 	die("System Management Interrupt", regs, SIGABRT);
 }
+#endif
 
-void UnknownException(struct pt_regs *regs)
+void unknown_exception(struct pt_regs *regs)
 {
 	printk("Bad trap at PC: %lx, SR: %lx, vector=%lx\n",
 	       regs->nip, regs->msr, regs->trap);
@@ -486,7 +525,7 @@ void UnknownException(struct pt_regs *regs)
 	_exception(SIGTRAP, regs, 0, 0);
 }
 
-void InstructionBreakpoint(struct pt_regs *regs)
+void instruction_breakpoint_exception(struct pt_regs *regs)
 {
 	if (notify_die(DIE_IABR_MATCH, "iabr_match", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
@@ -496,14 +535,20 @@ void InstructionBreakpoint(struct pt_regs *regs)
 	_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
 }
 
+#ifdef CONFIG_PPC32
 void RunModeException(struct pt_regs *regs)
 {
 	_exception(SIGTRAP, regs, 0, 0);
 }
+#endif
 
-void SingleStepException(struct pt_regs *regs)
+void __KPROBES single_step_exception(struct pt_regs *regs)
 {
+#ifdef CONFIG_PPC32
 	regs->msr &= ~(MSR_SE | MSR_BE);  /* Turn off 'trace' bits */
+#else
+	regs->msr &= ~MSR_SE;  /* Turn off 'trace' bit */
+#endif
 
 	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
 					5, SIGTRAP) == NOTIFY_STOP)
@@ -520,15 +565,62 @@ void SingleStepException(struct pt_regs *regs)
  * pretend we got a single-step exception.  This was pointed out
  * by Kumar Gala.  -- paulus
  */
-static void emulate_single_step(struct pt_regs *regs)
+static inline void emulate_single_step(struct pt_regs *regs)
 {
 	if (single_stepping(regs)) {
+#ifdef CONFIG_PPC32
 		clear_single_step(regs);
 		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
+#else
+		single_step_exception(regs);
+#endif
 	}
 }
 
-/* Illegal instruction emulation support.  Originally written to
+static void parse_fpe(struct pt_regs *regs)
+{
+	int code = 0;
+	unsigned long fpscr;
+
+#ifdef CONFIG_PPC32
+	/* We must make sure the FP state is consistent with
+	 * our MSR_FP in regs
+	 */
+	preempt_disable();
+	if (regs->msr & MSR_FP)
+		giveup_fpu(current);
+	preempt_enable();
+#else
+	flush_fp_to_thread(current);
+#endif
+
+	fpscr = current->thread.fpscr;
+
+	/* Invalid operation */
+	if ((fpscr & FPSCR_VE) && (fpscr & FPSCR_VX))
+		code = FPE_FLTINV;
+
+	/* Overflow */
+	else if ((fpscr & FPSCR_OE) && (fpscr & FPSCR_OX))
+		code = FPE_FLTOVF;
+
+	/* Underflow */
+	else if ((fpscr & FPSCR_UE) && (fpscr & FPSCR_UX))
+		code = FPE_FLTUND;
+
+	/* Divide by zero */
+	else if ((fpscr & FPSCR_ZE) && (fpscr & FPSCR_ZX))
+		code = FPE_FLTDIV;
+
+	/* Inexact result */
+	else if ((fpscr & FPSCR_XE) && (fpscr & FPSCR_XX))
+		code = FPE_FLTRES;
+
+	_exception(SIGFPE, regs, code, regs->nip);
+}
+
+/*
+ * Illegal instruction emulation support.  Originally written to
  * provide the PVR to user applications using the mfspr rd, PVR.
  * Return non-zero if we can't emulate, or -EFAULT if the associated
  * memory access caused an access fault.  Return zero on success.
@@ -536,7 +628,6 @@ static void emulate_single_step(struct pt_regs *regs)
  * There are a couple of ways to do this, either "decode" the instruction
  * or directly match lots of bits.  In this case, matching lots of
  * bits is faster and easier.
- *
  */
 #define INST_MFSPR_PVR		0x7c1f42a6
 #define INST_MFSPR_PVR_MASK	0xfc1fffff
@@ -547,6 +638,8 @@ static void emulate_single_step(struct pt_regs *regs)
 #define INST_MCRXR		0x7c000400
 #define INST_MCRXR_MASK		0x7c0007fe
 
+#ifdef CONFIG_PPC32
+
 #define INST_STRING		0x7c00042a
 #define INST_STRING_MASK	0x7c0007fe
 #define INST_STRING_GEN_MASK	0x7c00067e
@@ -622,6 +715,7 @@ static int emulate_string_inst(struct pt_regs *regs, u32 instword)
 
 	return 0;
 }
+#endif /* CONFIG_PPC32 */
 
 static int emulate_instruction(struct pt_regs *regs)
 {
@@ -643,22 +737,44 @@ static int emulate_instruction(struct pt_regs *regs)
 	}
 
 	/* Emulating the dcba insn is just a no-op.  */
-	if ((instword & INST_DCBA_MASK) == INST_DCBA)
+	if ((instword & INST_DCBA_MASK) == INST_DCBA) {
+#ifdef CONFIG_PPC64
+		static int warned;
+
+		if (!warned) {
+			printk(KERN_WARNING
+			       "process %d (%s) uses obsolete 'dcba' insn\n",
+			       current->pid, current->comm);
+			warned = 1;
+		}
+#endif /* CONFIG_PPC64 */
 		return 0;
+	}
 
 	/* Emulate the mcrxr insn.  */
 	if ((instword & INST_MCRXR_MASK) == INST_MCRXR) {
-		int shift = (instword >> 21) & 0x1c;
+		unsigned int shift = (instword >> 21) & 0x1c;
 		unsigned long msk = 0xf0000000UL >> shift;
+#ifdef CONFIG_PPC64
+		static int warned;
 
+		if (!warned) {
+			printk(KERN_WARNING
+			       "process %d (%s) uses obsolete 'mcrxr' insn\n",
+			       current->pid, current->comm);
+			warned = 1;
+		}
+#endif
 		regs->ccr = (regs->ccr & ~msk) | ((regs->xer >> shift) & msk);
 		regs->xer &= ~0xf0000000UL;
 		return 0;
 	}
 
+#ifdef CONFIG_PPC32
 	/* Emulate load/store string insn. */
 	if ((instword & INST_STRING_GEN_MASK) == INST_STRING)
 		return emulate_string_inst(regs, instword);
+#endif
 
 	return -EINVAL;
 }
@@ -686,7 +802,7 @@ struct bug_entry *find_bug(unsigned long bugaddr)
 	return module_find_bug(bugaddr);
 }
 
-int check_bug_trap(struct pt_regs *regs)
+static int check_bug_trap(struct pt_regs *regs)
 {
 	struct bug_entry *bug;
 	unsigned long addr;
@@ -701,34 +817,38 @@ int check_bug_trap(struct pt_regs *regs)
 		return 0;
 	if (bug->line & BUG_WARNING_TRAP) {
 		/* this is a WARN_ON rather than BUG/BUG_ON */
-#ifdef CONFIG_XMON
+#if defined(CONFIG_PPC32) && defined(CONFIG_XMON)
 		xmon_printf(KERN_ERR "Badness in %s at %s:%d\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
-#endif /* CONFIG_XMON */		
+#endif
 		printk(KERN_ERR "Badness in %s at %s:%d\n",
 		       bug->function, bug->file,
 		       bug->line & ~BUG_WARNING_TRAP);
+#ifdef CONFIG_PPC32
 		dump_stack();
+#else
+		show_stack(current, (void *)regs->gpr[1]);
+#endif
 		return 1;
 	}
-#ifdef CONFIG_XMON
+#if defined(CONFIG_PPC32) && defined(CONFIG_XMON)
 	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
 	       bug->function, bug->file, bug->line);
 	xmon(regs);
-#endif /* CONFIG_XMON */
+#endif
 	printk(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
 	       bug->function, bug->file, bug->line);
 
 	return 0;
 }
 
-void ProgramCheckException(struct pt_regs *regs)
+void __KPROBES program_check_exception(struct pt_regs *regs)
 {
 	unsigned int reason = get_reason(regs);
+#if defined(CONFIG_PPC32) && defined(CONFIG_MATH_EMULATION)
 	extern int do_mathemu(struct pt_regs *regs);
 
-#ifdef CONFIG_MATH_EMULATION
 	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
 	 * but there seems to be a hardware bug on the 405GP (RevD)
 	 * that means ESR is sometimes set incorrectly - either to
@@ -740,69 +860,61 @@ void ProgramCheckException(struct pt_regs *regs)
 		emulate_single_step(regs);
 		return;
 	}
-#endif /* CONFIG_MATH_EMULATION */
-
-	if (reason & REASON_FP) {
-		/* IEEE FP exception */
-		int code = 0;
-		u32 fpscr;
+#endif
 
-		/* We must make sure the FP state is consistent with
-		 * our MSR_FP in regs
-		 */
-		preempt_disable();
-		if (regs->msr & MSR_FP)
-			giveup_fpu(current);
-		preempt_enable();
-
-		fpscr = current->thread.fpscr;
-		fpscr &= fpscr << 22;	/* mask summary bits with enables */
-		if (fpscr & FPSCR_VX)
-			code = FPE_FLTINV;
-		else if (fpscr & FPSCR_OX)
-			code = FPE_FLTOVF;
-		else if (fpscr & FPSCR_UX)
-			code = FPE_FLTUND;
-		else if (fpscr & FPSCR_ZX)
-			code = FPE_FLTDIV;
-		else if (fpscr & FPSCR_XX)
-			code = FPE_FLTRES;
-		_exception(SIGFPE, regs, code, regs->nip);
+#ifdef CONFIG_PPC64
+	if (debugger_fault_handler(regs))
 		return;
-	}
+#endif
 
-	if (reason & REASON_TRAP) {
+	if (reason & REASON_FP) {
+		/* IEEE FP exception */
+		parse_fpe(regs);
+	} else if (reason & REASON_TRAP) {
 		/* trap exception */
+#ifdef CONFIG_PPC64
+		if (notify_die(DIE_BPT, "breakpoint", regs, 5, 5, SIGTRAP)
+				== NOTIFY_STOP)
+			return;
+#endif
 		if (debugger_bpt(regs))
 			return;
 		if (check_bug_trap(regs)) {
 			regs->nip += 4;
 			return;
 		}
-		_exception(SIGTRAP, regs, TRAP_BRKPT, 0);
-		return;
-	}
-
-	/* Try to emulate it if we should. */
-	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
+		_exception(SIGTRAP, regs, TRAP_BRKPT,
+#ifdef CONFIG_PPC32
+			0
+#else
+			regs->nip
+#endif
+		);
+	} else
+#ifdef CONFIG_PPC32
+	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED))
+#endif
+	{
+		/* Privileged or illegal instruction; try to emulate it. */
 		switch (emulate_instruction(regs)) {
 		case 0:
 			regs->nip += 4;
 			emulate_single_step(regs);
-			return;
+			break;
 		case -EFAULT:
 			_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
-			return;
+			break;
+		default:
+			if (reason & REASON_PRIVILEGED)
+				_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
+			else
+				_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+			break;
 		}
 	}
-
-	if (reason & REASON_PRIVILEGED)
-		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
-	else
-		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 }
 
-void AlignmentException(struct pt_regs *regs)
+void alignment_exception(struct pt_regs *regs)
 {
 	int fixed;
 
@@ -814,18 +926,31 @@ void AlignmentException(struct pt_regs *regs)
 		return;
 	}
 
-	/* Operand address was bad */	
+	/* Operand address was bad */
 	if (fixed == -EFAULT) {
 		if (user_mode(regs))
-			_exception(SIGSEGV, regs, SEGV_ACCERR, regs->dar);
+			_exception(SIGSEGV, regs,
+#ifdef CONFIG_PPC32
+				SEGV_ACCERR,
+#else
+				SEGV_MAPERR,
+#endif
+			regs->dar);
 		else
 			/* Search exception table */
 			bad_page_fault(regs, regs->dar, SIGSEGV);
 		return;
 	}
-	_exception(SIGBUS, regs, BUS_ADRALN, regs->dar);
+	_exception(SIGBUS, regs, BUS_ADRALN,
+#ifdef CONFIG_PPC32
+		regs->dar
+#else
+		regs->nip
+#endif
+	);
 }
 
+#ifdef CONFIG_PPC32
 void StackOverflow(struct pt_regs *regs)
 {
 	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",
@@ -849,8 +974,58 @@ void trace_syscall(struct pt_regs *regs)
 	       current, current->pid, regs->nip, regs->link, regs->gpr[0],
 	       regs->ccr&0x10000000?"Error=":"", regs->gpr[3], print_tainted());
 }
+#endif /* CONFIG_PPC32 */
+
+#ifdef CONFIG_PPC64
+void kernel_fp_unavailable_exception(struct pt_regs *regs)
+{
+	printk(KERN_EMERG "Unrecoverable FP Unavailable Exception "
+			  "%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable FP Unavailable Exception", regs, SIGABRT);
+}
+#endif
+
+void altivec_unavailable_exception(struct pt_regs *regs)
+{
+#if !defined(CONFIG_ALTIVEC) || defined(CONFIG_PPC64)
+	if (user_mode(regs)) {
+		/* A user program has executed an altivec instruction,
+		   but this kernel doesn't support altivec. */
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	}
+#endif
+#ifdef CONFIG_PPC32
+	{
+	static int kernel_altivec_count;
+
+	/* The kernel has executed an altivec instruction without
+	   first enabling altivec.  Whinge but let it do it. */
+	if (++kernel_altivec_count < 10)
+		printk(KERN_ERR "AltiVec used in kernel (task=%p, pc=%lx)\n",
+		       current, regs->nip);
+	regs->msr |= MSR_VEC;
+	}
+#else
+	printk(KERN_EMERG "Unrecoverable VMX/Altivec Unavailable Exception "
+			"%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
+#endif
+}
+
+#ifdef CONFIG_PPC64
+extern perf_irq_t perf_irq;
+#endif
+
+#if defined(CONFIG_PPC64) || defined(CONFIG_E500)
+void performance_monitor_exception(struct pt_regs *regs)
+{
+	perf_irq(regs);
+}
+#endif
+
 
-#ifdef CONFIG_8xx
+#if defined(CONFIG_PPC32) && defined(CONFIG_8xx)
 void SoftwareEmulation(struct pt_regs *regs)
 {
 	extern int do_mathemu(struct pt_regs *);
@@ -879,8 +1054,9 @@ void SoftwareEmulation(struct pt_regs *regs)
 	} else
 		emulate_single_step(regs);
 }
-#endif /* CONFIG_8xx */
+#endif /* defined(CONFIG_PPC32) && defined(CONFIG_8xx) */
 
+#ifdef CONFIG_PPC32
 #if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
 
 void DebugException(struct pt_regs *regs, unsigned long debug_status)
@@ -909,42 +1085,36 @@ void TAUException(struct pt_regs *regs)
 	       regs->nip, regs->msr, regs->trap, print_tainted());
 }
 #endif /* CONFIG_INT_TAU */
-
-void AltivecUnavailException(struct pt_regs *regs)
-{
-	static int kernel_altivec_count;
-
-#ifndef CONFIG_ALTIVEC
-	if (user_mode(regs)) {
-		/* A user program has executed an altivec instruction,
-		   but this kernel doesn't support altivec. */
-		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
-		return;
-	}
-#endif
-	/* The kernel has executed an altivec instruction without
-	   first enabling altivec.  Whinge but let it do it. */
-	if (++kernel_altivec_count < 10)
-		printk(KERN_ERR "AltiVec used in kernel (task=%p, pc=%lx)\n",
-		       current, regs->nip);
-	regs->msr |= MSR_VEC;
-}
+#endif /* CONFIG_PPC32*/
 
 #ifdef CONFIG_ALTIVEC
-void AltivecAssistException(struct pt_regs *regs)
+void altivec_assist_exception(struct pt_regs *regs)
 {
 	int err;
+#ifdef CONFIG_PPC64
+	siginfo_t info;
+#endif
 
+#ifdef CONFIG_PPC32
 	preempt_disable();
 	if (regs->msr & MSR_VEC)
 		giveup_altivec(current);
 	preempt_enable();
+#endif
 	if (!user_mode(regs)) {
 		printk(KERN_EMERG "VMX/Altivec assist exception in kernel mode"
 		       " at %lx\n", regs->nip);
-		die("Kernel Altivec assist exception", regs, SIGILL);
+		die("Kernel "
+#ifdef CONFIG_PPC64
+			"VMX/"
+#endif
+			"Altivec assist exception", regs, SIGILL);
 	}
 
+#ifdef CONFIG_PPC64
+	flush_altivec_to_thread(current);
+#endif /* CONFIG_PPC64 */
+
 	err = emulate_altivec(regs);
 	if (err == 0) {
 		regs->nip += 4;		/* skip emulated instruction */
@@ -954,7 +1124,15 @@ void AltivecAssistException(struct pt_regs *regs)
 
 	if (err == -EFAULT) {
 		/* got an error reading the instruction */
+#ifdef CONFIG_PPC32
 		_exception(SIGSEGV, regs, SEGV_ACCERR, regs->nip);
+#else
+		info.si_signo = SIGSEGV;
+		info.si_errno = 0;
+		info.si_code = SEGV_MAPERR;
+		info.si_addr = (void __user *) regs->nip;
+		force_sig_info(SIGSEGV, &info, current);
+#endif
 	} else {
 		/* didn't recognize the instruction */
 		/* XXX quick hack for now: set the non-Java bit in the VSCR */
@@ -966,13 +1144,7 @@ void AltivecAssistException(struct pt_regs *regs)
 }
 #endif /* CONFIG_ALTIVEC */
 
-#ifdef CONFIG_E500
-void PerformanceMonitorException(struct pt_regs *regs)
-{
-	perf_irq(regs);
-}
-#endif
-
+#ifdef CONFIG_PPC32
 #ifdef CONFIG_FSL_BOOKE
 void CacheLockingException(struct pt_regs *regs, unsigned long address,
 			   unsigned long error_code)
@@ -1022,7 +1194,24 @@ void SPEFloatingPointException(struct pt_regs *regs)
 	return;
 }
 #endif
+#endif /* CONFIG_PPC32 */
 
+#ifdef CONFIG_PPC64
+/*
+ * We enter here if we get an unrecoverable exception, that is, one
+ * that happened at a point where the RI (recoverable interrupt) bit
+ * in the MSR is 0.  This indicates that SRR0/1 are live, and that
+ * we therefore lost state by taking this exception.
+ */
+void unrecoverable_exception(struct pt_regs *regs)
+{
+	printk(KERN_EMERG "Unrecoverable exception %lx at %lx\n",
+	       regs->trap, regs->nip);
+	die("Unrecoverable exception", regs, SIGABRT);
+}
+#endif /* CONFIG_PPC64 */
+
+#ifdef CONFIG_PPC32
 #ifdef CONFIG_BOOKE_WDT
 /*
  * Default handler for a Watchdog exception,
@@ -1041,6 +1230,20 @@ void WatchdogException(struct pt_regs *regs)
 	WatchdogHandler(regs);
 }
 #endif
+#endif /* CONFIG_PPC32 */
+
+#ifdef CONFIG_PPC64
+/*
+ * We enter here if we discover during exception entry that we are
+ * running in supervisor mode with a userspace value in the stack pointer.
+ */
+void kernel_bad_stack(struct pt_regs *regs)
+{
+	printk(KERN_EMERG "Bad kernel stack pointer %lx at %lx\n",
+	       regs->gpr[1], regs->nip);
+	die("Bad kernel stack pointer", regs, SIGABRT);
+}
+#endif
 
 void __init trap_init(void)
 {

commit 14cf11af6cf608eb8c23e989ddb17a715ddce109
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Sep 26 16:04:21 2005 +1000

    powerpc: Merge enough to start building in arch/powerpc.
    
    This creates the directory structure under arch/powerpc and a bunch
    of Kconfig files.  It does a first-cut merge of arch/powerpc/mm,
    arch/powerpc/lib and arch/powerpc/platforms/powermac.  This is enough
    to build a 32-bit powermac kernel with ARCH=powerpc.
    
    For now we are getting some unmerged files from arch/ppc/kernel and
    arch/ppc/syslib, or arch/ppc64/kernel.  This makes some minor changes
    to files in those directories and files outside arch/powerpc.
    
    The boot directory is still not merged.  That's going to be interesting.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
new file mode 100644
index 000000000000..c7afbbba0f36
--- /dev/null
+++ b/arch/powerpc/kernel/traps.c
@@ -0,0 +1,1047 @@
+/*
+ *  arch/powerpc/kernel/traps.c
+ *
+ *  Copyright (C) 1995-1996  Gary Thomas (gdt@linuxppc.org)
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ *
+ *  Modified by Cort Dougan (cort@cs.nmt.edu)
+ *  and Paul Mackerras (paulus@samba.org)
+ */
+
+/*
+ * This file handles the architecture-dependent parts of hardware exceptions
+ */
+
+#include <linux/config.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/stddef.h>
+#include <linux/unistd.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/user.h>
+#include <linux/a.out.h>
+#include <linux/interrupt.h>
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/prctl.h>
+#include <linux/delay.h>
+#include <linux/kprobes.h>
+#include <asm/kdebug.h>
+
+#include <asm/pgtable.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/reg.h>
+#include <asm/xmon.h>
+#ifdef CONFIG_PMAC_BACKLIGHT
+#include <asm/backlight.h>
+#endif
+#include <asm/perfmon.h>
+
+#ifdef CONFIG_DEBUGGER
+int (*__debugger)(struct pt_regs *regs);
+int (*__debugger_ipi)(struct pt_regs *regs);
+int (*__debugger_bpt)(struct pt_regs *regs);
+int (*__debugger_sstep)(struct pt_regs *regs);
+int (*__debugger_iabr_match)(struct pt_regs *regs);
+int (*__debugger_dabr_match)(struct pt_regs *regs);
+int (*__debugger_fault_handler)(struct pt_regs *regs);
+
+EXPORT_SYMBOL(__debugger);
+EXPORT_SYMBOL(__debugger_ipi);
+EXPORT_SYMBOL(__debugger_bpt);
+EXPORT_SYMBOL(__debugger_sstep);
+EXPORT_SYMBOL(__debugger_iabr_match);
+EXPORT_SYMBOL(__debugger_dabr_match);
+EXPORT_SYMBOL(__debugger_fault_handler);
+#endif
+
+struct notifier_block *powerpc_die_chain;
+static DEFINE_SPINLOCK(die_notifier_lock);
+
+int register_die_notifier(struct notifier_block *nb)
+{
+	int err = 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&die_notifier_lock, flags);
+	err = notifier_chain_register(&powerpc_die_chain, nb);
+	spin_unlock_irqrestore(&die_notifier_lock, flags);
+	return err;
+}
+
+/*
+ * Trap & Exception support
+ */
+
+static DEFINE_SPINLOCK(die_lock);
+
+int die(const char *str, struct pt_regs *regs, long err)
+{
+	static int die_counter;
+	int nl = 0;
+
+	if (debugger(regs))
+		return 1;
+
+	console_verbose();
+	spin_lock_irq(&die_lock);
+	bust_spinlocks(1);
+#ifdef CONFIG_PMAC_BACKLIGHT
+	if (_machine == _MACH_Pmac) {
+		set_backlight_enable(1);
+		set_backlight_level(BACKLIGHT_MAX);
+	}
+#endif
+	printk("Oops: %s, sig: %ld [#%d]\n", str, err, ++die_counter);
+#ifdef CONFIG_PREEMPT
+	printk("PREEMPT ");
+	nl = 1;
+#endif
+#ifdef CONFIG_SMP
+	printk("SMP NR_CPUS=%d ", NR_CPUS);
+	nl = 1;
+#endif
+#ifdef CONFIG_DEBUG_PAGEALLOC
+	printk("DEBUG_PAGEALLOC ");
+	nl = 1;
+#endif
+#ifdef CONFIG_NUMA
+	printk("NUMA ");
+	nl = 1;
+#endif
+#ifdef CONFIG_PPC64
+	switch (systemcfg->platform) {
+	case PLATFORM_PSERIES:
+		printk("PSERIES ");
+		nl = 1;
+		break;
+	case PLATFORM_PSERIES_LPAR:
+		printk("PSERIES LPAR ");
+		nl = 1;
+		break;
+	case PLATFORM_ISERIES_LPAR:
+		printk("ISERIES LPAR ");
+		nl = 1;
+		break;
+	case PLATFORM_POWERMAC:
+		printk("POWERMAC ");
+		nl = 1;
+		break;
+	case PLATFORM_BPA:
+		printk("BPA ");
+		nl = 1;
+		break;
+	}
+#endif
+	if (nl)
+		printk("\n");
+	print_modules();
+	show_regs(regs);
+	bust_spinlocks(0);
+	spin_unlock_irq(&die_lock);
+
+	if (in_interrupt())
+		panic("Fatal exception in interrupt");
+
+	if (panic_on_oops) {
+		panic("Fatal exception");
+	}
+	do_exit(err);
+
+	return 0;
+}
+
+void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr)
+{
+	siginfo_t info;
+
+	if (!user_mode(regs)) {
+		if (die("Exception in kernel mode", regs, signr))
+			return;
+	}
+
+	memset(&info, 0, sizeof(info));
+	info.si_signo = signr;
+	info.si_code = code;
+	info.si_addr = (void __user *) addr;
+	force_sig_info(signr, &info, current);
+
+	/*
+	 * Init gets no signals that it doesn't have a handler for.
+	 * That's all very well, but if it has caused a synchronous
+	 * exception and we ignore the resulting signal, it will just
+	 * generate the same exception over and over again and we get
+	 * nowhere.  Better to kill it and let the kernel panic.
+	 */
+	if (current->pid == 1) {
+		__sighandler_t handler;
+
+		spin_lock_irq(&current->sighand->siglock);
+		handler = current->sighand->action[signr-1].sa.sa_handler;
+		spin_unlock_irq(&current->sighand->siglock);
+		if (handler == SIG_DFL) {
+			/* init has generated a synchronous exception
+			   and it doesn't have a handler for the signal */
+			printk(KERN_CRIT "init has generated signal %d "
+			       "but has no handler for it\n", signr);
+			do_exit(signr);
+		}
+	}
+}
+
+#ifdef CONFIG_PPC64
+void system_reset_exception(struct pt_regs *regs)
+{
+	/* See if any machine dependent calls */
+	if (ppc_md.system_reset_exception)
+		ppc_md.system_reset_exception(regs);
+
+	die("System Reset", regs, SIGABRT);
+
+	/* Must die if the interrupt is not recoverable */
+	if (!(regs->msr & MSR_RI))
+		panic("Unrecoverable System Reset");
+
+	/* What should we do here? We could issue a shutdown or hard reset. */
+}
+#endif
+
+/*
+ * I/O accesses can cause machine checks on powermacs.
+ * Check if the NIP corresponds to the address of a sync
+ * instruction for which there is an entry in the exception
+ * table.
+ * Note that the 601 only takes a machine check on TEA
+ * (transfer error ack) signal assertion, and does not
+ * set any of the top 16 bits of SRR1.
+ *  -- paulus.
+ */
+static inline int check_io_access(struct pt_regs *regs)
+{
+#ifdef CONFIG_PPC_PMAC
+	unsigned long msr = regs->msr;
+	const struct exception_table_entry *entry;
+	unsigned int *nip = (unsigned int *)regs->nip;
+
+	if (((msr & 0xffff0000) == 0 || (msr & (0x80000 | 0x40000)))
+	    && (entry = search_exception_tables(regs->nip)) != NULL) {
+		/*
+		 * Check that it's a sync instruction, or somewhere
+		 * in the twi; isync; nop sequence that inb/inw/inl uses.
+		 * As the address is in the exception table
+		 * we should be able to read the instr there.
+		 * For the debug message, we look at the preceding
+		 * load or store.
+		 */
+		if (*nip == 0x60000000)		/* nop */
+			nip -= 2;
+		else if (*nip == 0x4c00012c)	/* isync */
+			--nip;
+		if (*nip == 0x7c0004ac || (*nip >> 26) == 3) {
+			/* sync or twi */
+			unsigned int rb;
+
+			--nip;
+			rb = (*nip >> 11) & 0x1f;
+			printk(KERN_DEBUG "%s bad port %lx at %p\n",
+			       (*nip & 0x100)? "OUT to": "IN from",
+			       regs->gpr[rb] - _IO_BASE, nip);
+			regs->msr |= MSR_RI;
+			regs->nip = entry->fixup;
+			return 1;
+		}
+	}
+#endif /* CONFIG_PPC_PMAC */
+	return 0;
+}
+
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+/* On 4xx, the reason for the machine check or program exception
+   is in the ESR. */
+#define get_reason(regs)	((regs)->dsisr)
+#ifndef CONFIG_FSL_BOOKE
+#define get_mc_reason(regs)	((regs)->dsisr)
+#else
+#define get_mc_reason(regs)	(mfspr(SPRN_MCSR))
+#endif
+#define REASON_FP		ESR_FP
+#define REASON_ILLEGAL		(ESR_PIL | ESR_PUO)
+#define REASON_PRIVILEGED	ESR_PPR
+#define REASON_TRAP		ESR_PTR
+
+/* single-step stuff */
+#define single_stepping(regs)	(current->thread.dbcr0 & DBCR0_IC)
+#define clear_single_step(regs)	(current->thread.dbcr0 &= ~DBCR0_IC)
+
+#else
+/* On non-4xx, the reason for the machine check or program
+   exception is in the MSR. */
+#define get_reason(regs)	((regs)->msr)
+#define get_mc_reason(regs)	((regs)->msr)
+#define REASON_FP		0x100000
+#define REASON_ILLEGAL		0x80000
+#define REASON_PRIVILEGED	0x40000
+#define REASON_TRAP		0x20000
+
+#define single_stepping(regs)	((regs)->msr & MSR_SE)
+#define clear_single_step(regs)	((regs)->msr &= ~MSR_SE)
+#endif
+
+/*
+ * This is "fall-back" implementation for configurations
+ * which don't provide platform-specific machine check info
+ */
+void __attribute__ ((weak))
+platform_machine_check(struct pt_regs *regs)
+{
+}
+
+void MachineCheckException(struct pt_regs *regs)
+{
+#ifdef CONFIG_PPC64
+	int recover = 0;
+
+	/* See if any machine dependent calls */
+	if (ppc_md.machine_check_exception)
+		recover = ppc_md.machine_check_exception(regs);
+
+	if (recover)
+		return;
+#else
+	unsigned long reason = get_mc_reason(regs);
+
+	if (user_mode(regs)) {
+		regs->msr |= MSR_RI;
+		_exception(SIGBUS, regs, BUS_ADRERR, regs->nip);
+		return;
+	}
+
+#if defined(CONFIG_8xx) && defined(CONFIG_PCI)
+	/* the qspan pci read routines can cause machine checks -- Cort */
+	bad_page_fault(regs, regs->dar, SIGBUS);
+	return;
+#endif
+
+	if (debugger_fault_handler(regs)) {
+		regs->msr |= MSR_RI;
+		return;
+	}
+
+	if (check_io_access(regs))
+		return;
+
+#if defined(CONFIG_4xx) && !defined(CONFIG_440A)
+	if (reason & ESR_IMCP) {
+		printk("Instruction");
+		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
+	} else
+		printk("Data");
+	printk(" machine check in kernel mode.\n");
+#elif defined(CONFIG_440A)
+	printk("Machine check in kernel mode.\n");
+	if (reason & ESR_IMCP){
+		printk("Instruction Synchronous Machine Check exception\n");
+		mtspr(SPRN_ESR, reason & ~ESR_IMCP);
+	}
+	else {
+		u32 mcsr = mfspr(SPRN_MCSR);
+		if (mcsr & MCSR_IB)
+			printk("Instruction Read PLB Error\n");
+		if (mcsr & MCSR_DRB)
+			printk("Data Read PLB Error\n");
+		if (mcsr & MCSR_DWB)
+			printk("Data Write PLB Error\n");
+		if (mcsr & MCSR_TLBP)
+			printk("TLB Parity Error\n");
+		if (mcsr & MCSR_ICP){
+			flush_instruction_cache();
+			printk("I-Cache Parity Error\n");
+		}
+		if (mcsr & MCSR_DCSP)
+			printk("D-Cache Search Parity Error\n");
+		if (mcsr & MCSR_DCFP)
+			printk("D-Cache Flush Parity Error\n");
+		if (mcsr & MCSR_IMPE)
+			printk("Machine Check exception is imprecise\n");
+
+		/* Clear MCSR */
+		mtspr(SPRN_MCSR, mcsr);
+	}
+#elif defined (CONFIG_E500)
+	printk("Machine check in kernel mode.\n");
+	printk("Caused by (from MCSR=%lx): ", reason);
+
+	if (reason & MCSR_MCP)
+		printk("Machine Check Signal\n");
+	if (reason & MCSR_ICPERR)
+		printk("Instruction Cache Parity Error\n");
+	if (reason & MCSR_DCP_PERR)
+		printk("Data Cache Push Parity Error\n");
+	if (reason & MCSR_DCPERR)
+		printk("Data Cache Parity Error\n");
+	if (reason & MCSR_GL_CI)
+		printk("Guarded Load or Cache-Inhibited stwcx.\n");
+	if (reason & MCSR_BUS_IAERR)
+		printk("Bus - Instruction Address Error\n");
+	if (reason & MCSR_BUS_RAERR)
+		printk("Bus - Read Address Error\n");
+	if (reason & MCSR_BUS_WAERR)
+		printk("Bus - Write Address Error\n");
+	if (reason & MCSR_BUS_IBERR)
+		printk("Bus - Instruction Data Error\n");
+	if (reason & MCSR_BUS_RBERR)
+		printk("Bus - Read Data Bus Error\n");
+	if (reason & MCSR_BUS_WBERR)
+		printk("Bus - Read Data Bus Error\n");
+	if (reason & MCSR_BUS_IPERR)
+		printk("Bus - Instruction Parity Error\n");
+	if (reason & MCSR_BUS_RPERR)
+		printk("Bus - Read Parity Error\n");
+#elif defined (CONFIG_E200)
+	printk("Machine check in kernel mode.\n");
+	printk("Caused by (from MCSR=%lx): ", reason);
+
+	if (reason & MCSR_MCP)
+		printk("Machine Check Signal\n");
+	if (reason & MCSR_CP_PERR)
+		printk("Cache Push Parity Error\n");
+	if (reason & MCSR_CPERR)
+		printk("Cache Parity Error\n");
+	if (reason & MCSR_EXCP_ERR)
+		printk("ISI, ITLB, or Bus Error on first instruction fetch for an exception handler\n");
+	if (reason & MCSR_BUS_IRERR)
+		printk("Bus - Read Bus Error on instruction fetch\n");
+	if (reason & MCSR_BUS_DRERR)
+		printk("Bus - Read Bus Error on data load\n");
+	if (reason & MCSR_BUS_WRERR)
+		printk("Bus - Write Bus Error on buffered store or cache line push\n");
+#else /* !CONFIG_4xx && !CONFIG_E500 && !CONFIG_E200 */
+	printk("Machine check in kernel mode.\n");
+	printk("Caused by (from SRR1=%lx): ", reason);
+	switch (reason & 0x601F0000) {
+	case 0x80000:
+		printk("Machine check signal\n");
+		break;
+	case 0:		/* for 601 */
+	case 0x40000:
+	case 0x140000:	/* 7450 MSS error and TEA */
+		printk("Transfer error ack signal\n");
+		break;
+	case 0x20000:
+		printk("Data parity error signal\n");
+		break;
+	case 0x10000:
+		printk("Address parity error signal\n");
+		break;
+	case 0x20000000:
+		printk("L1 Data Cache error\n");
+		break;
+	case 0x40000000:
+		printk("L1 Instruction Cache error\n");
+		break;
+	case 0x00100000:
+		printk("L2 data cache parity error\n");
+		break;
+	default:
+		printk("Unknown values in msr\n");
+	}
+#endif /* CONFIG_4xx */
+
+	/*
+	 * Optional platform-provided routine to print out
+	 * additional info, e.g. bus error registers.
+	 */
+	platform_machine_check(regs);
+#endif /* CONFIG_PPC64 */
+
+	if (debugger_fault_handler(regs))
+		return;
+	die("Machine check", regs, SIGBUS);
+
+	/* Must die if the interrupt is not recoverable */
+	if (!(regs->msr & MSR_RI))
+		panic("Unrecoverable Machine check");
+}
+
+void SMIException(struct pt_regs *regs)
+{
+	die("System Management Interrupt", regs, SIGABRT);
+}
+
+void UnknownException(struct pt_regs *regs)
+{
+	printk("Bad trap at PC: %lx, SR: %lx, vector=%lx\n",
+	       regs->nip, regs->msr, regs->trap);
+
+	_exception(SIGTRAP, regs, 0, 0);
+}
+
+void InstructionBreakpoint(struct pt_regs *regs)
+{
+	if (notify_die(DIE_IABR_MATCH, "iabr_match", regs, 5,
+					5, SIGTRAP) == NOTIFY_STOP)
+		return;
+	if (debugger_iabr_match(regs))
+		return;
+	_exception(SIGTRAP, regs, TRAP_BRKPT, regs->nip);
+}
+
+void RunModeException(struct pt_regs *regs)
+{
+	_exception(SIGTRAP, regs, 0, 0);
+}
+
+void SingleStepException(struct pt_regs *regs)
+{
+	regs->msr &= ~(MSR_SE | MSR_BE);  /* Turn off 'trace' bits */
+
+	if (notify_die(DIE_SSTEP, "single_step", regs, 5,
+					5, SIGTRAP) == NOTIFY_STOP)
+		return;
+	if (debugger_sstep(regs))
+		return;
+
+	_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
+}
+
+/*
+ * After we have successfully emulated an instruction, we have to
+ * check if the instruction was being single-stepped, and if so,
+ * pretend we got a single-step exception.  This was pointed out
+ * by Kumar Gala.  -- paulus
+ */
+static void emulate_single_step(struct pt_regs *regs)
+{
+	if (single_stepping(regs)) {
+		clear_single_step(regs);
+		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
+	}
+}
+
+/* Illegal instruction emulation support.  Originally written to
+ * provide the PVR to user applications using the mfspr rd, PVR.
+ * Return non-zero if we can't emulate, or -EFAULT if the associated
+ * memory access caused an access fault.  Return zero on success.
+ *
+ * There are a couple of ways to do this, either "decode" the instruction
+ * or directly match lots of bits.  In this case, matching lots of
+ * bits is faster and easier.
+ *
+ */
+#define INST_MFSPR_PVR		0x7c1f42a6
+#define INST_MFSPR_PVR_MASK	0xfc1fffff
+
+#define INST_DCBA		0x7c0005ec
+#define INST_DCBA_MASK		0x7c0007fe
+
+#define INST_MCRXR		0x7c000400
+#define INST_MCRXR_MASK		0x7c0007fe
+
+#define INST_STRING		0x7c00042a
+#define INST_STRING_MASK	0x7c0007fe
+#define INST_STRING_GEN_MASK	0x7c00067e
+#define INST_LSWI		0x7c0004aa
+#define INST_LSWX		0x7c00042a
+#define INST_STSWI		0x7c0005aa
+#define INST_STSWX		0x7c00052a
+
+static int emulate_string_inst(struct pt_regs *regs, u32 instword)
+{
+	u8 rT = (instword >> 21) & 0x1f;
+	u8 rA = (instword >> 16) & 0x1f;
+	u8 NB_RB = (instword >> 11) & 0x1f;
+	u32 num_bytes;
+	unsigned long EA;
+	int pos = 0;
+
+	/* Early out if we are an invalid form of lswx */
+	if ((instword & INST_STRING_MASK) == INST_LSWX)
+		if ((rT == rA) || (rT == NB_RB))
+			return -EINVAL;
+
+	EA = (rA == 0) ? 0 : regs->gpr[rA];
+
+	switch (instword & INST_STRING_MASK) {
+		case INST_LSWX:
+		case INST_STSWX:
+			EA += NB_RB;
+			num_bytes = regs->xer & 0x7f;
+			break;
+		case INST_LSWI:
+		case INST_STSWI:
+			num_bytes = (NB_RB == 0) ? 32 : NB_RB;
+			break;
+		default:
+			return -EINVAL;
+	}
+
+	while (num_bytes != 0)
+	{
+		u8 val;
+		u32 shift = 8 * (3 - (pos & 0x3));
+
+		switch ((instword & INST_STRING_MASK)) {
+			case INST_LSWX:
+			case INST_LSWI:
+				if (get_user(val, (u8 __user *)EA))
+					return -EFAULT;
+				/* first time updating this reg,
+				 * zero it out */
+				if (pos == 0)
+					regs->gpr[rT] = 0;
+				regs->gpr[rT] |= val << shift;
+				break;
+			case INST_STSWI:
+			case INST_STSWX:
+				val = regs->gpr[rT] >> shift;
+				if (put_user(val, (u8 __user *)EA))
+					return -EFAULT;
+				break;
+		}
+		/* move EA to next address */
+		EA += 1;
+		num_bytes--;
+
+		/* manage our position within the register */
+		if (++pos == 4) {
+			pos = 0;
+			if (++rT == 32)
+				rT = 0;
+		}
+	}
+
+	return 0;
+}
+
+static int emulate_instruction(struct pt_regs *regs)
+{
+	u32 instword;
+	u32 rd;
+
+	if (!user_mode(regs))
+		return -EINVAL;
+	CHECK_FULL_REGS(regs);
+
+	if (get_user(instword, (u32 __user *)(regs->nip)))
+		return -EFAULT;
+
+	/* Emulate the mfspr rD, PVR. */
+	if ((instword & INST_MFSPR_PVR_MASK) == INST_MFSPR_PVR) {
+		rd = (instword >> 21) & 0x1f;
+		regs->gpr[rd] = mfspr(SPRN_PVR);
+		return 0;
+	}
+
+	/* Emulating the dcba insn is just a no-op.  */
+	if ((instword & INST_DCBA_MASK) == INST_DCBA)
+		return 0;
+
+	/* Emulate the mcrxr insn.  */
+	if ((instword & INST_MCRXR_MASK) == INST_MCRXR) {
+		int shift = (instword >> 21) & 0x1c;
+		unsigned long msk = 0xf0000000UL >> shift;
+
+		regs->ccr = (regs->ccr & ~msk) | ((regs->xer >> shift) & msk);
+		regs->xer &= ~0xf0000000UL;
+		return 0;
+	}
+
+	/* Emulate load/store string insn. */
+	if ((instword & INST_STRING_GEN_MASK) == INST_STRING)
+		return emulate_string_inst(regs, instword);
+
+	return -EINVAL;
+}
+
+/*
+ * Look through the list of trap instructions that are used for BUG(),
+ * BUG_ON() and WARN_ON() and see if we hit one.  At this point we know
+ * that the exception was caused by a trap instruction of some kind.
+ * Returns 1 if we should continue (i.e. it was a WARN_ON) or 0
+ * otherwise.
+ */
+extern struct bug_entry __start___bug_table[], __stop___bug_table[];
+
+#ifndef CONFIG_MODULES
+#define module_find_bug(x)	NULL
+#endif
+
+struct bug_entry *find_bug(unsigned long bugaddr)
+{
+	struct bug_entry *bug;
+
+	for (bug = __start___bug_table; bug < __stop___bug_table; ++bug)
+		if (bugaddr == bug->bug_addr)
+			return bug;
+	return module_find_bug(bugaddr);
+}
+
+int check_bug_trap(struct pt_regs *regs)
+{
+	struct bug_entry *bug;
+	unsigned long addr;
+
+	if (regs->msr & MSR_PR)
+		return 0;	/* not in kernel */
+	addr = regs->nip;	/* address of trap instruction */
+	if (addr < PAGE_OFFSET)
+		return 0;
+	bug = find_bug(regs->nip);
+	if (bug == NULL)
+		return 0;
+	if (bug->line & BUG_WARNING_TRAP) {
+		/* this is a WARN_ON rather than BUG/BUG_ON */
+#ifdef CONFIG_XMON
+		xmon_printf(KERN_ERR "Badness in %s at %s:%d\n",
+		       bug->function, bug->file,
+		       bug->line & ~BUG_WARNING_TRAP);
+#endif /* CONFIG_XMON */		
+		printk(KERN_ERR "Badness in %s at %s:%d\n",
+		       bug->function, bug->file,
+		       bug->line & ~BUG_WARNING_TRAP);
+		dump_stack();
+		return 1;
+	}
+#ifdef CONFIG_XMON
+	xmon_printf(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
+	       bug->function, bug->file, bug->line);
+	xmon(regs);
+#endif /* CONFIG_XMON */
+	printk(KERN_CRIT "kernel BUG in %s at %s:%d!\n",
+	       bug->function, bug->file, bug->line);
+
+	return 0;
+}
+
+void ProgramCheckException(struct pt_regs *regs)
+{
+	unsigned int reason = get_reason(regs);
+	extern int do_mathemu(struct pt_regs *regs);
+
+#ifdef CONFIG_MATH_EMULATION
+	/* (reason & REASON_ILLEGAL) would be the obvious thing here,
+	 * but there seems to be a hardware bug on the 405GP (RevD)
+	 * that means ESR is sometimes set incorrectly - either to
+	 * ESR_DST (!?) or 0.  In the process of chasing this with the
+	 * hardware people - not sure if it can happen on any illegal
+	 * instruction or only on FP instructions, whether there is a
+	 * pattern to occurences etc. -dgibson 31/Mar/2003 */
+	if (!(reason & REASON_TRAP) && do_mathemu(regs) == 0) {
+		emulate_single_step(regs);
+		return;
+	}
+#endif /* CONFIG_MATH_EMULATION */
+
+	if (reason & REASON_FP) {
+		/* IEEE FP exception */
+		int code = 0;
+		u32 fpscr;
+
+		/* We must make sure the FP state is consistent with
+		 * our MSR_FP in regs
+		 */
+		preempt_disable();
+		if (regs->msr & MSR_FP)
+			giveup_fpu(current);
+		preempt_enable();
+
+		fpscr = current->thread.fpscr;
+		fpscr &= fpscr << 22;	/* mask summary bits with enables */
+		if (fpscr & FPSCR_VX)
+			code = FPE_FLTINV;
+		else if (fpscr & FPSCR_OX)
+			code = FPE_FLTOVF;
+		else if (fpscr & FPSCR_UX)
+			code = FPE_FLTUND;
+		else if (fpscr & FPSCR_ZX)
+			code = FPE_FLTDIV;
+		else if (fpscr & FPSCR_XX)
+			code = FPE_FLTRES;
+		_exception(SIGFPE, regs, code, regs->nip);
+		return;
+	}
+
+	if (reason & REASON_TRAP) {
+		/* trap exception */
+		if (debugger_bpt(regs))
+			return;
+		if (check_bug_trap(regs)) {
+			regs->nip += 4;
+			return;
+		}
+		_exception(SIGTRAP, regs, TRAP_BRKPT, 0);
+		return;
+	}
+
+	/* Try to emulate it if we should. */
+	if (reason & (REASON_ILLEGAL | REASON_PRIVILEGED)) {
+		switch (emulate_instruction(regs)) {
+		case 0:
+			regs->nip += 4;
+			emulate_single_step(regs);
+			return;
+		case -EFAULT:
+			_exception(SIGSEGV, regs, SEGV_MAPERR, regs->nip);
+			return;
+		}
+	}
+
+	if (reason & REASON_PRIVILEGED)
+		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
+	else
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+}
+
+void AlignmentException(struct pt_regs *regs)
+{
+	int fixed;
+
+	fixed = fix_alignment(regs);
+
+	if (fixed == 1) {
+		regs->nip += 4;	/* skip over emulated instruction */
+		emulate_single_step(regs);
+		return;
+	}
+
+	/* Operand address was bad */	
+	if (fixed == -EFAULT) {
+		if (user_mode(regs))
+			_exception(SIGSEGV, regs, SEGV_ACCERR, regs->dar);
+		else
+			/* Search exception table */
+			bad_page_fault(regs, regs->dar, SIGSEGV);
+		return;
+	}
+	_exception(SIGBUS, regs, BUS_ADRALN, regs->dar);
+}
+
+void StackOverflow(struct pt_regs *regs)
+{
+	printk(KERN_CRIT "Kernel stack overflow in process %p, r1=%lx\n",
+	       current, regs->gpr[1]);
+	debugger(regs);
+	show_regs(regs);
+	panic("kernel stack overflow");
+}
+
+void nonrecoverable_exception(struct pt_regs *regs)
+{
+	printk(KERN_ERR "Non-recoverable exception at PC=%lx MSR=%lx\n",
+	       regs->nip, regs->msr);
+	debugger(regs);
+	die("nonrecoverable exception", regs, SIGKILL);
+}
+
+void trace_syscall(struct pt_regs *regs)
+{
+	printk("Task: %p(%d), PC: %08lX/%08lX, Syscall: %3ld, Result: %s%ld    %s\n",
+	       current, current->pid, regs->nip, regs->link, regs->gpr[0],
+	       regs->ccr&0x10000000?"Error=":"", regs->gpr[3], print_tainted());
+}
+
+#ifdef CONFIG_8xx
+void SoftwareEmulation(struct pt_regs *regs)
+{
+	extern int do_mathemu(struct pt_regs *);
+	extern int Soft_emulate_8xx(struct pt_regs *);
+	int errcode;
+
+	CHECK_FULL_REGS(regs);
+
+	if (!user_mode(regs)) {
+		debugger(regs);
+		die("Kernel Mode Software FPU Emulation", regs, SIGFPE);
+	}
+
+#ifdef CONFIG_MATH_EMULATION
+	errcode = do_mathemu(regs);
+#else
+	errcode = Soft_emulate_8xx(regs);
+#endif
+	if (errcode) {
+		if (errcode > 0)
+			_exception(SIGFPE, regs, 0, 0);
+		else if (errcode == -EFAULT)
+			_exception(SIGSEGV, regs, 0, 0);
+		else
+			_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+	} else
+		emulate_single_step(regs);
+}
+#endif /* CONFIG_8xx */
+
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+
+void DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	if (debug_status & DBSR_IC) {	/* instruction completion */
+		regs->msr &= ~MSR_DE;
+		if (user_mode(regs)) {
+			current->thread.dbcr0 &= ~DBCR0_IC;
+		} else {
+			/* Disable instruction completion */
+			mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) & ~DBCR0_IC);
+			/* Clear the instruction completion event */
+			mtspr(SPRN_DBSR, DBSR_IC);
+			if (debugger_sstep(regs))
+				return;
+		}
+		_exception(SIGTRAP, regs, TRAP_TRACE, 0);
+	}
+}
+#endif /* CONFIG_4xx || CONFIG_BOOKE */
+
+#if !defined(CONFIG_TAU_INT)
+void TAUException(struct pt_regs *regs)
+{
+	printk("TAU trap at PC: %lx, MSR: %lx, vector=%lx    %s\n",
+	       regs->nip, regs->msr, regs->trap, print_tainted());
+}
+#endif /* CONFIG_INT_TAU */
+
+void AltivecUnavailException(struct pt_regs *regs)
+{
+	static int kernel_altivec_count;
+
+#ifndef CONFIG_ALTIVEC
+	if (user_mode(regs)) {
+		/* A user program has executed an altivec instruction,
+		   but this kernel doesn't support altivec. */
+		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
+		return;
+	}
+#endif
+	/* The kernel has executed an altivec instruction without
+	   first enabling altivec.  Whinge but let it do it. */
+	if (++kernel_altivec_count < 10)
+		printk(KERN_ERR "AltiVec used in kernel (task=%p, pc=%lx)\n",
+		       current, regs->nip);
+	regs->msr |= MSR_VEC;
+}
+
+#ifdef CONFIG_ALTIVEC
+void AltivecAssistException(struct pt_regs *regs)
+{
+	int err;
+
+	preempt_disable();
+	if (regs->msr & MSR_VEC)
+		giveup_altivec(current);
+	preempt_enable();
+	if (!user_mode(regs)) {
+		printk(KERN_EMERG "VMX/Altivec assist exception in kernel mode"
+		       " at %lx\n", regs->nip);
+		die("Kernel Altivec assist exception", regs, SIGILL);
+	}
+
+	err = emulate_altivec(regs);
+	if (err == 0) {
+		regs->nip += 4;		/* skip emulated instruction */
+		emulate_single_step(regs);
+		return;
+	}
+
+	if (err == -EFAULT) {
+		/* got an error reading the instruction */
+		_exception(SIGSEGV, regs, SEGV_ACCERR, regs->nip);
+	} else {
+		/* didn't recognize the instruction */
+		/* XXX quick hack for now: set the non-Java bit in the VSCR */
+		if (printk_ratelimit())
+			printk(KERN_ERR "Unrecognized altivec instruction "
+			       "in %s at %lx\n", current->comm, regs->nip);
+		current->thread.vscr.u[3] |= 0x10000;
+	}
+}
+#endif /* CONFIG_ALTIVEC */
+
+#ifdef CONFIG_E500
+void PerformanceMonitorException(struct pt_regs *regs)
+{
+	perf_irq(regs);
+}
+#endif
+
+#ifdef CONFIG_FSL_BOOKE
+void CacheLockingException(struct pt_regs *regs, unsigned long address,
+			   unsigned long error_code)
+{
+	/* We treat cache locking instructions from the user
+	 * as priv ops, in the future we could try to do
+	 * something smarter
+	 */
+	if (error_code & (ESR_DLK|ESR_ILK))
+		_exception(SIGILL, regs, ILL_PRVOPC, regs->nip);
+	return;
+}
+#endif /* CONFIG_FSL_BOOKE */
+
+#ifdef CONFIG_SPE
+void SPEFloatingPointException(struct pt_regs *regs)
+{
+	unsigned long spefscr;
+	int fpexc_mode;
+	int code = 0;
+
+	spefscr = current->thread.spefscr;
+	fpexc_mode = current->thread.fpexc_mode;
+
+	/* Hardware does not neccessarily set sticky
+	 * underflow/overflow/invalid flags */
+	if ((spefscr & SPEFSCR_FOVF) && (fpexc_mode & PR_FP_EXC_OVF)) {
+		code = FPE_FLTOVF;
+		spefscr |= SPEFSCR_FOVFS;
+	}
+	else if ((spefscr & SPEFSCR_FUNF) && (fpexc_mode & PR_FP_EXC_UND)) {
+		code = FPE_FLTUND;
+		spefscr |= SPEFSCR_FUNFS;
+	}
+	else if ((spefscr & SPEFSCR_FDBZ) && (fpexc_mode & PR_FP_EXC_DIV))
+		code = FPE_FLTDIV;
+	else if ((spefscr & SPEFSCR_FINV) && (fpexc_mode & PR_FP_EXC_INV)) {
+		code = FPE_FLTINV;
+		spefscr |= SPEFSCR_FINVS;
+	}
+	else if ((spefscr & (SPEFSCR_FG | SPEFSCR_FX)) && (fpexc_mode & PR_FP_EXC_RES))
+		code = FPE_FLTRES;
+
+	current->thread.spefscr = spefscr;
+
+	_exception(SIGFPE, regs, code, regs->nip);
+	return;
+}
+#endif
+
+#ifdef CONFIG_BOOKE_WDT
+/*
+ * Default handler for a Watchdog exception,
+ * spins until a reboot occurs
+ */
+void __attribute__ ((weak)) WatchdogHandler(struct pt_regs *regs)
+{
+	/* Generic WatchdogHandler, implement your own */
+	mtspr(SPRN_TCR, mfspr(SPRN_TCR)&(~TCR_WIE));
+	return;
+}
+
+void WatchdogException(struct pt_regs *regs)
+{
+	printk (KERN_EMERG "PowerPC Book-E Watchdog Exception\n");
+	WatchdogHandler(regs);
+}
+#endif
+
+void __init trap_init(void)
+{
+}
