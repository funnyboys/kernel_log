commit 65fddcfca8ad14778f71a57672fd01e8112d30fa
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:42 2020 -0700

    mm: reorder includes after introduction of linux/pgtable.h
    
    The replacement of <asm/pgrable.h> with <linux/pgtable.h> made the include
    of the latter in the middle of asm includes.  Fix this up with the aid of
    the below script and manual adjustments here and there.
    
            import sys
            import re
    
            if len(sys.argv) is not 3:
                print "USAGE: %s <file> <header>" % (sys.argv[0])
                sys.exit(1)
    
            hdr_to_move="#include <linux/%s>" % sys.argv[2]
            moved = False
            in_hdrs = False
    
            with open(sys.argv[1], "r") as f:
                lines = f.readlines()
                for _line in lines:
                    line = _line.rstrip('
    ')
                    if line == hdr_to_move:
                        continue
                    if line.startswith("#include <linux/"):
                        in_hdrs = True
                    elif not moved and in_hdrs:
                        moved = True
                        print hdr_to_move
                    print line
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-4-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2c09bffdce2f..05b1cc0e009e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -51,10 +51,10 @@
 #include <linux/of.h>
 #include <linux/of_irq.h>
 #include <linux/vmalloc.h>
+#include <linux/pgtable.h>
 
 #include <linux/uaccess.h>
 #include <asm/io.h>
-#include <linux/pgtable.h>
 #include <asm/irq.h>
 #include <asm/cache.h>
 #include <asm/prom.h>

commit ca5999fde0a1761665a38e4c9a72dbcd7d190a81
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:38 2020 -0700

    mm: introduce include/linux/pgtable.h
    
    The include/linux/pgtable.h is going to be the home of generic page table
    manipulation functions.
    
    Start with moving asm-generic/pgtable.h to include/linux/pgtable.h and
    make the latter include asm/pgtable.h.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 112d150354b2..2c09bffdce2f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -54,7 +54,7 @@
 
 #include <linux/uaccess.h>
 #include <asm/io.h>
-#include <asm/pgtable.h>
+#include <linux/pgtable.h>
 #include <asm/irq.h>
 #include <asm/cache.h>
 #include <asm/prom.h>

commit cb0849a990b2928760bc38561e8d33b554196e25
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 1 21:52:10 2020 -0700

    powerpc: use __vmalloc_node in alloc_vm_stack
    
    alloc_vm_stack can use a slightly higher level vmalloc function.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Gao Xiang <xiang@kernel.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Michael Kelley <mikelley@microsoft.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Cc: Sakari Ailus <sakari.ailus@linux.intel.com>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Wei Liu <wei.liu@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mackerras <paulus@ozlabs.org>
    Cc: Vasily Gorbik <gor@linux.ibm.com>
    Cc: Will Deacon <will@kernel.org>
    Link: http://lkml.kernel.org/r/20200414131348.444715-29-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1f1169856dc8..112d150354b2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -748,9 +748,8 @@ void do_IRQ(struct pt_regs *regs)
 
 static void *__init alloc_vm_stack(void)
 {
-	return __vmalloc_node_range(THREAD_SIZE, THREAD_ALIGN, VMALLOC_START,
-				    VMALLOC_END, THREADINFO_GFP, PAGE_KERNEL,
-				     0, NUMA_NO_NODE, (void*)_RET_IP_);
+	return __vmalloc_node(THREAD_SIZE, THREAD_ALIGN, THREADINFO_GFP,
+			      NUMA_NO_NODE, (void *)_RET_IP_);
 }
 
 static void __init vmap_irqstack_init(void)

commit 0c89649a70bed679fd408c1eb82fa99dbe1354a0
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 2 22:12:12 2020 +1000

    powerpc/64s: Fix doorbell wakeup msgclr optimisation
    
    Commit 3282a3da25bd ("powerpc/64: Implement soft interrupt replay in C")
    broke the doorbell wakeup optimisation introduced by commit a9af97aa0a12
    ("powerpc/64s: msgclr when handling doorbell exceptions from system
    reset").
    
    This patch restores the msgclr, in C code. It's now done in the system
    reset wakeup path rather than doorbell interrupt replay where it used
    to be, because it is always the right thing to do in the wakeup case,
    but it may be rarely of use in other interrupt replay situations in
    which case it's wasted work - we would have to run measurements to see
    if that was a worthwhile optimisation, and I suspect it would not be.
    
    The results are similar to those in the original commit, test on POWER8
    of context_switch selftests benchmark with polling idle disabled (e.g.,
    always nap, giving cross-CPU IPIs) gives the following results:
    
                                      broken           patched
      Different threads, same core:   317k/s           375k/s    +18.7%
      Different cores:                280k/s           282k/s     +1.0%
    
    Fixes: 3282a3da25bd ("powerpc/64: Implement soft interrupt replay in C")
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200402121212.1118218-1-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a25ed47087ee..1f1169856dc8 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -527,6 +527,19 @@ void irq_set_pending_from_srr1(unsigned long srr1)
 		return;
 	}
 
+	if (reason == PACA_IRQ_DBELL) {
+		/*
+		 * When doorbell triggers a system reset wakeup, the message
+		 * is not cleared, so if the doorbell interrupt is replayed
+		 * and the IPI handled, the doorbell interrupt would still
+		 * fire when EE is enabled.
+		 *
+		 * To avoid taking the superfluous doorbell interrupt,
+		 * execute a msgclr here before the interrupt is replayed.
+		 */
+		ppc_msgclr(PPC_DBELL_MSGTYPE);
+	}
+
 	/*
 	 * The 0 index (SRR1[42:45]=b0000) must always evaluate to 0,
 	 * so this can be called unconditionally with the SRR1 wake

commit 6cc0c16d82f889f0083f3608237189afb55b67be
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 26 03:35:37 2020 +1000

    powerpc/64s: Implement interrupt exit logic in C
    
    Implement the bulk of interrupt return logic in C. The asm return code
    must handle a few cases: restoring full GPRs, and emulating stack
    store.
    
    The stack store emulation is significantly simplfied, rather than
    creating a new return frame and switching to that before performing
    the store, it uses the PACA to keep a scratch register around to
    perform the store.
    
    The asm return code is moved into 64e for now. The new logic has made
    allowance for 64e, but I don't have a full environment that works well
    to test it, and even booting in emulated qemu is not great for stress
    testing. 64e shouldn't be too far off working with this, given a bit
    more testing and auditing of the logic.
    
    This is slightly faster on a POWER9 (page fault speed increases about
    1.1%), probably due to reduced mtmsrd.
    
    mpe: Includes fixes from Nick for _TIF_EMULATE_STACK_STORE
    handling (including the fast_interrupt_return path), to remove
    trace_hardirqs_on(), and fixes the interrupt-return part of the
    MSR_VSX restore bug caught by tm-unavailable selftest.
    
    mpe: Incorporate fix from Nick:
    
    The return-to-kernel path has to replay any soft-pending interrupts if
    it is returning to a context that had interrupts soft-enabled. It has
    to do this carefully and avoid plain enabling interrupts if this is an
    irq context, which can cause multiple nesting of interrupts on the
    stack, and other unexpected issues.
    
    The code which avoided this case got the soft-mask state wrong, and
    marked interrupts as enabled before going around again to retry. This
    seems to be mostly harmless except when PREEMPT=y, this calls
    preempt_schedule_irq with irqs apparently enabled and runs into a BUG
    in kernel/sched/core.c
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200225173541.1549955-29-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2e5dca87b936..a25ed47087ee 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -110,6 +110,8 @@ static inline notrace int decrementer_check_overflow(void)
 	return now >= *next_tb;
 }
 
+#ifdef CONFIG_PPC_BOOK3E
+
 /* This is called whenever we are re-enabling interrupts
  * and returns either 0 (nothing to do) or 500/900/280/a00/e80 if
  * there's an EE, DEC or DBELL to generate.
@@ -169,41 +171,16 @@ notrace unsigned int __check_irq_replay(void)
 		}
 	}
 
-	/*
-	 * Force the delivery of pending soft-disabled interrupts on PS3.
-	 * Any HV call will have this side effect.
-	 */
-	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
-		u64 tmp, tmp2;
-		lv1_get_version_info(&tmp, &tmp2);
-	}
-
-	/*
-	 * Check if an hypervisor Maintenance interrupt happened.
-	 * This is a higher priority interrupt than the others, so
-	 * replay it first.
-	 */
-	if (happened & PACA_IRQ_HMI) {
-		local_paca->irq_happened &= ~PACA_IRQ_HMI;
-		return 0xe60;
-	}
-
 	if (happened & PACA_IRQ_DEC) {
 		local_paca->irq_happened &= ~PACA_IRQ_DEC;
 		return 0x900;
 	}
 
-	if (happened & PACA_IRQ_PMI) {
-		local_paca->irq_happened &= ~PACA_IRQ_PMI;
-		return 0xf00;
-	}
-
 	if (happened & PACA_IRQ_EE) {
 		local_paca->irq_happened &= ~PACA_IRQ_EE;
 		return 0x500;
 	}
 
-#ifdef CONFIG_PPC_BOOK3E
 	/*
 	 * Check if an EPR external interrupt happened this bit is typically
 	 * set if we need to handle another "edge" interrupt from within the
@@ -218,20 +195,15 @@ notrace unsigned int __check_irq_replay(void)
 		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
 		return 0x280;
 	}
-#else
-	if (happened & PACA_IRQ_DBELL) {
-		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
-		return 0xa00;
-	}
-#endif /* CONFIG_PPC_BOOK3E */
 
 	/* There should be nothing left ! */
 	BUG_ON(local_paca->irq_happened != 0);
 
 	return 0;
 }
+#endif /* CONFIG_PPC_BOOK3E */
 
-static void replay_soft_interrupts(void)
+void replay_soft_interrupts(void)
 {
 	/*
 	 * We use local_paca rather than get_paca() to avoid all

commit 3282a3da25bd63fdb7240bc35dbdefa4b1947005
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 26 03:35:36 2020 +1000

    powerpc/64: Implement soft interrupt replay in C
    
    When local_irq_enable() finds a pending soft-masked interrupt, it
    "replays" it by setting up registers like the initial interrupt entry,
    then calls into the low level handler to set up an interrupt stack
    frame and process the interrupt.
    
    This is not necessary, and uses more stack than needed. The high level
    interrupt handler can be called directly from C, with just pt_regs set
    up on stack. This should be faster and use less stack.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200225173541.1549955-28-npiggin@gmail.com

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1bed18b7229e..2e5dca87b936 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -70,6 +70,7 @@
 #include <asm/paca.h>
 #include <asm/firmware.h>
 #include <asm/lv1call.h>
+#include <asm/dbell.h>
 #endif
 #define CREATE_TRACE_POINTS
 #include <asm/trace.h>
@@ -230,10 +231,121 @@ notrace unsigned int __check_irq_replay(void)
 	return 0;
 }
 
+static void replay_soft_interrupts(void)
+{
+	/*
+	 * We use local_paca rather than get_paca() to avoid all
+	 * the debug_smp_processor_id() business in this low level
+	 * function
+	 */
+	unsigned char happened = local_paca->irq_happened;
+	struct pt_regs regs;
+
+	ppc_save_regs(&regs);
+	regs.softe = IRQS_ALL_DISABLED;
+
+again:
+	if (IS_ENABLED(CONFIG_PPC_IRQ_SOFT_MASK_DEBUG))
+		WARN_ON_ONCE(mfmsr() & MSR_EE);
+
+	if (happened & PACA_IRQ_HARD_DIS) {
+		/*
+		 * We may have missed a decrementer interrupt if hard disabled.
+		 * Check the decrementer register in case we had a rollover
+		 * while hard disabled.
+		 */
+		if (!(happened & PACA_IRQ_DEC)) {
+			if (decrementer_check_overflow())
+				happened |= PACA_IRQ_DEC;
+		}
+	}
+
+	/*
+	 * Force the delivery of pending soft-disabled interrupts on PS3.
+	 * Any HV call will have this side effect.
+	 */
+	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
+		u64 tmp, tmp2;
+		lv1_get_version_info(&tmp, &tmp2);
+	}
+
+	/*
+	 * Check if an hypervisor Maintenance interrupt happened.
+	 * This is a higher priority interrupt than the others, so
+	 * replay it first.
+	 */
+	if (IS_ENABLED(CONFIG_PPC_BOOK3S) && (happened & PACA_IRQ_HMI)) {
+		local_paca->irq_happened &= ~PACA_IRQ_HMI;
+		regs.trap = 0xe60;
+		handle_hmi_exception(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	if (happened & PACA_IRQ_DEC) {
+		local_paca->irq_happened &= ~PACA_IRQ_DEC;
+		regs.trap = 0x900;
+		timer_interrupt(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	if (happened & PACA_IRQ_EE) {
+		local_paca->irq_happened &= ~PACA_IRQ_EE;
+		regs.trap = 0x500;
+		do_IRQ(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	/*
+	 * Check if an EPR external interrupt happened this bit is typically
+	 * set if we need to handle another "edge" interrupt from within the
+	 * MPIC "EPR" handler.
+	 */
+	if (IS_ENABLED(CONFIG_PPC_BOOK3E) && (happened & PACA_IRQ_EE_EDGE)) {
+		local_paca->irq_happened &= ~PACA_IRQ_EE_EDGE;
+		regs.trap = 0x500;
+		do_IRQ(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	if (IS_ENABLED(CONFIG_PPC_DOORBELL) && (happened & PACA_IRQ_DBELL)) {
+		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
+		if (IS_ENABLED(CONFIG_PPC_BOOK3E))
+			regs.trap = 0x280;
+		else
+			regs.trap = 0xa00;
+		doorbell_exception(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	/* Book3E does not support soft-masking PMI interrupts */
+	if (IS_ENABLED(CONFIG_PPC_BOOK3S) && (happened & PACA_IRQ_PMI)) {
+		local_paca->irq_happened &= ~PACA_IRQ_PMI;
+		regs.trap = 0xf00;
+		performance_monitor_exception(&regs);
+		if (!(local_paca->irq_happened & PACA_IRQ_HARD_DIS))
+			hard_irq_disable();
+	}
+
+	happened = local_paca->irq_happened;
+	if (happened & ~PACA_IRQ_HARD_DIS) {
+		/*
+		 * We are responding to the next interrupt, so interrupt-off
+		 * latencies should be reset here.
+		 */
+		trace_hardirqs_on();
+		trace_hardirqs_off();
+		goto again;
+	}
+}
+
 notrace void arch_local_irq_restore(unsigned long mask)
 {
 	unsigned char irq_happened;
-	unsigned int replay;
 
 	/* Write the new soft-enabled value */
 	irq_soft_mask_set(mask);
@@ -255,24 +367,16 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 */
 	irq_happened = get_irq_happened();
 	if (!irq_happened) {
-#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		WARN_ON_ONCE(!(mfmsr() & MSR_EE));
-#endif
+		if (IS_ENABLED(CONFIG_PPC_IRQ_SOFT_MASK_DEBUG))
+			WARN_ON_ONCE(!(mfmsr() & MSR_EE));
 		return;
 	}
 
-	/*
-	 * We need to hard disable to get a trusted value from
-	 * __check_irq_replay(). We also need to soft-disable
-	 * again to avoid warnings in there due to the use of
-	 * per-cpu variables.
-	 */
+	/* We need to hard disable to replay. */
 	if (!(irq_happened & PACA_IRQ_HARD_DIS)) {
-#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		WARN_ON_ONCE(!(mfmsr() & MSR_EE));
-#endif
+		if (IS_ENABLED(CONFIG_PPC_IRQ_SOFT_MASK_DEBUG))
+			WARN_ON_ONCE(!(mfmsr() & MSR_EE));
 		__hard_irq_disable();
-#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
 	} else {
 		/*
 		 * We should already be hard disabled here. We had bugs
@@ -280,35 +384,26 @@ notrace void arch_local_irq_restore(unsigned long mask)
 		 * warn if we are wrong. Only do that when IRQ tracing
 		 * is enabled as mfmsr() can be costly.
 		 */
-		if (WARN_ON_ONCE(mfmsr() & MSR_EE))
-			__hard_irq_disable();
-#endif
+		if (IS_ENABLED(CONFIG_PPC_IRQ_SOFT_MASK_DEBUG)) {
+			if (WARN_ON_ONCE(mfmsr() & MSR_EE))
+				__hard_irq_disable();
+		}
+
+		if (irq_happened == PACA_IRQ_HARD_DIS) {
+			local_paca->irq_happened = 0;
+			__hard_irq_enable();
+			return;
+		}
 	}
 
 	irq_soft_mask_set(IRQS_ALL_DISABLED);
 	trace_hardirqs_off();
 
-	/*
-	 * Check if anything needs to be re-emitted. We haven't
-	 * soft-enabled yet to avoid warnings in decrementer_check_overflow
-	 * accessing per-cpu variables
-	 */
-	replay = __check_irq_replay();
+	replay_soft_interrupts();
+	local_paca->irq_happened = 0;
 
-	/* We can soft-enable now */
 	trace_hardirqs_on();
 	irq_soft_mask_set(IRQS_ENABLED);
-
-	/*
-	 * And replay if we have to. This will return with interrupts
-	 * hard-enabled.
-	 */
-	if (replay) {
-		__replay_interrupt(replay);
-		return;
-	}
-
-	/* Finally, let's ensure we are hard enabled */
 	__hard_irq_enable();
 }
 EXPORT_SYMBOL(arch_local_irq_restore);

commit 532d43a73cf191cf951d27e49d8d0a03e8cf2297
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 20 22:51:41 2020 +1100

    powerpc/irq: Use current_stack_pointer in do_IRQ()
    
    Until commit 7306e83ccf5c ("powerpc: Don't use CURRENT_THREAD_INFO to
    find the stack"), the current stack base address was obtained by
    calling current_thread_info(). That inline function was simply masking
    out the value of r1.
    
    In that commit, it was changed to using current_stack_pointer() (since
    renamed current_stack_frame()), which is a heavier function as it is
    an outline assembly function which cannot be inlined and which reads
    the content of the stack at 0(r1).
    
    Convert to using current_stack_pointer for geting r1 and masking out
    its value to obtain the base address of the stack pointer as before.
    
    Fixes: 7306e83ccf5c ("powerpc: Don't use CURRENT_THREAD_INFO to find the stack")
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200220115141.2707-5-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 46d5852fb00a..1bed18b7229e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -648,7 +648,7 @@ void do_IRQ(struct pt_regs *regs)
 	void *cursp, *irqsp, *sirqsp;
 
 	/* Switch to the irq stack to handle this */
-	cursp = (void *)(current_stack_frame() & ~(THREAD_SIZE - 1));
+	cursp = (void *)(current_stack_pointer & ~(THREAD_SIZE - 1));
 	irqsp = hardirq_ctx[raw_smp_processor_id()];
 	sirqsp = softirq_ctx[raw_smp_processor_id()];
 

commit 0dec6e1cca7eee6d5616f982efab2ff3b3ea1f9f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 20 22:51:40 2020 +1100

    powerpc/irq: use IS_ENABLED() in check_stack_overflow()
    
    Instead of #ifdef, use IS_ENABLED(CONFIG_DEBUG_STACKOVERFLOW).
    This enable GCC to check for code validity even when the option
    is not selected.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200220115141.2707-4-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c7d6f5cdffdb..46d5852fb00a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -599,9 +599,11 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 
 static inline void check_stack_overflow(void)
 {
-#ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
 
+	if (!IS_ENABLED(CONFIG_DEBUG_STACKOVERFLOW))
+		return;
+
 	sp = current_stack_pointer & (THREAD_SIZE - 1);
 
 	/* check for stack overflow: is there less than 2KB free? */
@@ -609,7 +611,6 @@ static inline void check_stack_overflow(void)
 		pr_err("do_IRQ: stack overflow: %ld\n", sp);
 		dump_stack();
 	}
-#endif
 }
 
 void __do_irq(struct pt_regs *regs)

commit 84ab14893054751a2b3adba725834183b872a17f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 20 22:51:39 2020 +1100

    powerpc/irq: Use current_stack_pointer in check_stack_overflow()
    
    The purpose of check_stack_overflow() is to verify that the stack has
    not overflowed.
    
    To really know whether the stack pointer is still within boundaries,
    the check must be done directly on the value of r1.
    
    So use current_stack_pointer, which returns the current value of r1,
    rather than current_stack_frame() which causes a frame to be created
    and then returns that value.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200220115141.2707-3-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 02118c18434d..c7d6f5cdffdb 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -602,7 +602,7 @@ static inline void check_stack_overflow(void)
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
 
-	sp = current_stack_frame() & (THREAD_SIZE-1);
+	sp = current_stack_pointer & (THREAD_SIZE - 1);
 
 	/* check for stack overflow: is there less than 2KB free? */
 	if (unlikely(sp < 2048)) {

commit 3d13e839e801e081bdece0127c2affa33d0f77cf
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Feb 20 22:51:37 2020 +1100

    powerpc: Rename current_stack_pointer() to current_stack_frame()
    
    current_stack_pointer(), which was called __get_SP(), used to just
    return the value in r1.
    
    But that caused problems in some cases, so it was turned into a
    function in commit bfe9a2cfe91a ("powerpc: Reimplement __get_SP() as a
    function not a define").
    
    Because it's a function in a separate compilation unit to all its
    callers, it has the effect of causing a stack frame to be created, and
    then returns the address of that frame. This is good in some cases
    like those described in the above commit, but in other cases it's
    overkill, we just need to know what stack page we're on.
    
    On some other arches current_stack_pointer is just a register global
    giving the stack pointer, and we'd like to do that too. So rename our
    current_stack_pointer() to current_stack_frame() to make that
    possible.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Link: https://lore.kernel.org/r/20200220115141.2707-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5c9b11878555..02118c18434d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -602,7 +602,7 @@ static inline void check_stack_overflow(void)
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
 
-	sp = current_stack_pointer() & (THREAD_SIZE-1);
+	sp = current_stack_frame() & (THREAD_SIZE-1);
 
 	/* check for stack overflow: is there less than 2KB free? */
 	if (unlikely(sp < 2048)) {
@@ -647,7 +647,7 @@ void do_IRQ(struct pt_regs *regs)
 	void *cursp, *irqsp, *sirqsp;
 
 	/* Switch to the irq stack to handle this */
-	cursp = (void *)(current_stack_pointer() & ~(THREAD_SIZE - 1));
+	cursp = (void *)(current_stack_frame() & ~(THREAD_SIZE - 1));
 	irqsp = hardirq_ctx[raw_smp_processor_id()];
 	sirqsp = softirq_ctx[raw_smp_processor_id()];
 

commit 547db12fd8a0ce753c6bafd130827f1755c93fe6
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Dec 21 08:32:30 2019 +0000

    powerpc/32: Use vmapped stacks for interrupts
    
    In order to also catch overflows on IRQ stacks, use vmapped stacks.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/d33ad1b36ddff4dcc19f96c592c12a61cf85d406.1576916812.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index add67498c126..5c9b11878555 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -50,6 +50,7 @@
 #include <linux/debugfs.h>
 #include <linux/of.h>
 #include <linux/of_irq.h>
+#include <linux/vmalloc.h>
 
 #include <linux/uaccess.h>
 #include <asm/io.h>
@@ -664,8 +665,29 @@ void do_IRQ(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
+static void *__init alloc_vm_stack(void)
+{
+	return __vmalloc_node_range(THREAD_SIZE, THREAD_ALIGN, VMALLOC_START,
+				    VMALLOC_END, THREADINFO_GFP, PAGE_KERNEL,
+				     0, NUMA_NO_NODE, (void*)_RET_IP_);
+}
+
+static void __init vmap_irqstack_init(void)
+{
+	int i;
+
+	for_each_possible_cpu(i) {
+		softirq_ctx[i] = alloc_vm_stack();
+		hardirq_ctx[i] = alloc_vm_stack();
+	}
+}
+
+
 void __init init_IRQ(void)
 {
+	if (IS_ENABLED(CONFIG_VMAP_STACK))
+		vmap_irqstack_init();
+
 	if (ppc_md.init_IRQ)
 		ppc_md.init_IRQ();
 }

commit 099bc4812f09155da77eeb960a983470249c9ce1
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Dec 9 06:19:08 2019 +0000

    powerpc/irq: fix stack overflow verification
    
    Before commit 0366a1c70b89 ("powerpc/irq: Run softirqs off the top of
    the irq stack"), check_stack_overflow() was called by do_IRQ(), before
    switching to the irq stack.
    In that commit, do_IRQ() was renamed __do_irq(), and is now executing
    on the irq stack, so check_stack_overflow() has just become almost
    useless.
    
    Move check_stack_overflow() call in do_IRQ() to do the check while
    still on the current stack.
    
    Fixes: 0366a1c70b89 ("powerpc/irq: Run softirqs off the top of the irq stack")
    Cc: stable@vger.kernel.org
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/e033aa8116ab12b7ca9a9c75189ad0741e3b9b5f.1575872340.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5645bc9cbc09..add67498c126 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -619,8 +619,6 @@ void __do_irq(struct pt_regs *regs)
 
 	trace_irq_entry(regs);
 
-	check_stack_overflow();
-
 	/*
 	 * Query the platform PIC for the interrupt & ack it.
 	 *
@@ -652,6 +650,8 @@ void do_IRQ(struct pt_regs *regs)
 	irqsp = hardirq_ctx[raw_smp_processor_id()];
 	sirqsp = softirq_ctx[raw_smp_processor_id()];
 
+	check_stack_overflow();
+
 	/* Already there ? */
 	if (unlikely(cursp == irqsp || cursp == sirqsp)) {
 		__do_irq(regs);

commit 192f0f8e9db7efe4ac98d47f5fa4334e43c1204d
Merge: ec9249752465 f5a9e488d623
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 13 16:08:36 2019 -0700

    Merge tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Removal of the NPU DMA code, used by the out-of-tree Nvidia driver,
         as well as some other functions only used by drivers that haven't
         (yet?) made it upstream.
    
       - A fix for a bug in our handling of hardware watchpoints (eg. perf
         record -e mem: ...) which could lead to register corruption and
         kernel crashes.
    
       - Enable HAVE_ARCH_HUGE_VMAP, which allows us to use large pages for
         vmalloc when using the Radix MMU.
    
       - A large but incremental rewrite of our exception handling code to
         use gas macros rather than multiple levels of nested CPP macros.
    
      And the usual small fixes, cleanups and improvements.
    
      Thanks to: Alastair D'Silva, Alexey Kardashevskiy, Andreas Schwab,
      Aneesh Kumar K.V, Anju T Sudhakar, Anton Blanchard, Arnd Bergmann,
      Athira Rajeev, CÃ©dric Le Goater, Christian Lamparter, Christophe
      Leroy, Christophe Lombard, Christoph Hellwig, Daniel Axtens, Denis
      Efremov, Enrico Weigelt, Frederic Barrat, Gautham R. Shenoy, Geert
      Uytterhoeven, Geliang Tang, Gen Zhang, Greg Kroah-Hartman, Greg Kurz,
      Gustavo Romero, Krzysztof Kozlowski, Madhavan Srinivasan, Masahiro
      Yamada, Mathieu Malaterre, Michael Neuling, Nathan Lynch, Naveen N.
      Rao, Nicholas Piggin, Nishad Kamdar, Oliver O'Halloran, Qian Cai, Ravi
      Bangoria, Sachin Sant, Sam Bobroff, Satheesh Rajendran, Segher
      Boessenkool, Shaokun Zhang, Shawn Anastasio, Stewart Smith, Suraj
      Jitindar Singh, Thiago Jung Bauermann, YueHaibing"
    
    * tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (163 commits)
      powerpc/powernv/idle: Fix restore of SPRN_LDBAR for POWER9 stop state.
      powerpc/eeh: Handle hugepages in ioremap space
      ocxl: Update for AFU descriptor template version 1.1
      powerpc/boot: pass CONFIG options in a simpler and more robust way
      powerpc/boot: add {get, put}_unaligned_be32 to xz_config.h
      powerpc/irq: Don't WARN continuously in arch_local_irq_restore()
      powerpc/module64: Use symbolic instructions names.
      powerpc/module32: Use symbolic instructions names.
      powerpc: Move PPC_HA() PPC_HI() and PPC_LO() to ppc-opcode.h
      powerpc/module64: Fix comment in R_PPC64_ENTRY handling
      powerpc/boot: Add lzo support for uImage
      powerpc/boot: Add lzma support for uImage
      powerpc/boot: don't force gzipped uImage
      powerpc/8xx: Add microcode patch to move SMC parameter RAM.
      powerpc/8xx: Use IO accessors in microcode programming.
      powerpc/8xx: replace #ifdefs by IS_ENABLED() in microcode.c
      powerpc/8xx: refactor programming of microcode CPM params.
      powerpc/8xx: refactor printing of microcode patch name.
      powerpc/8xx: Refactor microcode write
      powerpc/8xx: refactor writing of CPM microcode arrays
      ...

commit 0fc12c022ad25532b66bf6f6c818ee1c1d63e702
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Jul 8 16:02:19 2019 +1000

    powerpc/irq: Don't WARN continuously in arch_local_irq_restore()
    
    When CONFIG_PPC_IRQ_SOFT_MASK_DEBUG is enabled (uncommon), we have a
    series of WARN_ON's in arch_local_irq_restore().
    
    These are "should never happen" conditions, but if they do happen they
    can flood the console and render the system unusable. So switch them
    to WARN_ON_ONCE().
    
    Fixes: e2b36d591720 ("powerpc/64: Don't trace code that runs with the soft irq mask unreconciled")
    Fixes: 9b81c0211c24 ("powerpc/64s: make PACA_IRQ_HARD_DIS track MSR[EE] closely")
    Fixes: 7c0482e3d055 ("powerpc/irq: Fix another case of lazy IRQ state getting out of sync")
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190708061046.7075-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ada901af4950..c9a6eac3075c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -259,7 +259,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	irq_happened = get_irq_happened();
 	if (!irq_happened) {
 #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		WARN_ON(!(mfmsr() & MSR_EE));
+		WARN_ON_ONCE(!(mfmsr() & MSR_EE));
 #endif
 		return;
 	}
@@ -272,7 +272,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 */
 	if (!(irq_happened & PACA_IRQ_HARD_DIS)) {
 #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		WARN_ON(!(mfmsr() & MSR_EE));
+		WARN_ON_ONCE(!(mfmsr() & MSR_EE));
 #endif
 		__hard_irq_disable();
 #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
@@ -283,7 +283,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 		 * warn if we are wrong. Only do that when IRQ tracing
 		 * is enabled as mfmsr() can be costly.
 		 */
-		if (WARN_ON(mfmsr() & MSR_EE))
+		if (WARN_ON_ONCE(mfmsr() & MSR_EE))
 			__hard_irq_disable();
 #endif
 	}

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ada901af4950..bc68c53af67c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  *  Derived from arch/i386/kernel/irq.c
  *    Copyright (C) 1992 Linus Torvalds
@@ -8,11 +9,6 @@
  *  Adapted for Power Macintosh by Paul Mackerras
  *    Copyright (C) 1996 Paul Mackerras (paulus@cs.anu.edu.au)
  *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
- *
  * This file contains the code used by various IRQ handling routines:
  * asking for different IRQ's should be done through these routines
  * instead of just grabbing them. Thus setups with different IRQ numbers

commit e2b36d591720d81741f37e047a6f0047e8c89369
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu May 2 15:21:07 2019 +1000

    powerpc/64: Don't trace code that runs with the soft irq mask unreconciled
    
    "Reconciling" in terms of interrupt handling, is to bring the soft irq
    mask state in to synch with the hardware, after an interrupt causes
    MSR[EE] to be cleared (while the soft mask may be enabled, and hard
    irqs not marked disabled).
    
    General kernel code should not be called while unreconciled, because
    local_irq_disable, etc. manipulations can cause surprising irq traces,
    and it's fragile because the soft irq code does not really expect to
    be called in this situation.
    
    When exiting from an interrupt, MSR[EE] is cleared to prevent races,
    but soft irq state is enabled for the returned-to context, so this is
    now an unreconciled state. restore_math is called in this state, and
    that can be ftraced, and the ftrace subsystem disables local irqs.
    
    Mark restore_math and its callees as notrace. Restore a sanity check
    in the soft irq code that had to be disabled for this case, by commit
    4da1f79227ad4 ("powerpc/64: Disable irq restore warning for now").
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6672fec75e2a..ada901af4950 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -258,16 +258,9 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 */
 	irq_happened = get_irq_happened();
 	if (!irq_happened) {
-		/*
-		 * FIXME. Here we'd like to be able to do:
-		 *
-		 * #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		 *   WARN_ON(!(mfmsr() & MSR_EE));
-		 * #endif
-		 *
-		 * But currently it hits in a few paths, we should fix those and
-		 * enable the warning.
-		 */
+#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
+		WARN_ON(!(mfmsr() & MSR_EE));
+#endif
 		return;
 	}
 

commit 502523fd1d2ac559b41d8302dc9f826f578ec54d
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Mar 9 18:47:27 2019 +0100

    powerpc/irq: drop __irq_offset_value
    
    This patch drops__irq_offset_value which has not been used since
    commit 9c4cb8251513 ("powerpc: Remove use of CONFIG_PPC_MERGE")
    
    This removes a sparse warning.
    
    Fixes: 9c4cb8251513 ("powerpc: Remove use of CONFIG_PPC_MERGE")
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8a936723c791..6672fec75e2a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -81,10 +81,7 @@
 DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 EXPORT_PER_CPU_SYMBOL(irq_stat);
 
-int __irq_offset_value;
-
 #ifdef CONFIG_PPC32
-EXPORT_SYMBOL(__irq_offset_value);
 atomic_t ppc_n_lost_interrupts;
 
 #ifdef CONFIG_TAU_INT

commit d608898abc749424e26aa0e451d39e33cf3f4adc
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Jan 12 09:55:53 2019 +0000

    powerpc: clean stack pointers naming
    
    Some stack pointers used to also be thread_info pointers
    and were called tp. Now that they are only stack pointers,
    rename them sp.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 938944c6e2ee..8a936723c791 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -659,21 +659,21 @@ void __do_irq(struct pt_regs *regs)
 void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-	void *curtp, *irqtp, *sirqtp;
+	void *cursp, *irqsp, *sirqsp;
 
 	/* Switch to the irq stack to handle this */
-	curtp = (void *)(current_stack_pointer() & ~(THREAD_SIZE - 1));
-	irqtp = hardirq_ctx[raw_smp_processor_id()];
-	sirqtp = softirq_ctx[raw_smp_processor_id()];
+	cursp = (void *)(current_stack_pointer() & ~(THREAD_SIZE - 1));
+	irqsp = hardirq_ctx[raw_smp_processor_id()];
+	sirqsp = softirq_ctx[raw_smp_processor_id()];
 
 	/* Already there ? */
-	if (unlikely(curtp == irqtp || curtp == sirqtp)) {
+	if (unlikely(cursp == irqsp || cursp == sirqsp)) {
 		__do_irq(regs);
 		set_irq_regs(old_regs);
 		return;
 	}
 	/* Switch stack and call */
-	call_do_irq(regs, irqtp);
+	call_do_irq(regs, irqsp);
 
 	set_irq_regs(old_regs);
 }
@@ -695,10 +695,7 @@ void *hardirq_ctx[NR_CPUS] __read_mostly;
 
 void do_softirq_own_stack(void)
 {
-	void *irqtp;
-
-	irqtp = softirq_ctx[smp_processor_id()];
-	call_do_softirq(irqtp);
+	call_do_softirq(softirq_ctx[smp_processor_id()]);
 }
 
 irq_hw_number_t virq_to_hw(unsigned int virq)

commit a7916a1de526162d73e894b6d3ebd895d4302078
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 31 10:09:00 2019 +0000

    powerpc: regain entire stack space
    
    thread_info is not anymore in the stack, so the entire stack
    can now be used.
    
    There is also no risk anymore of corrupting task_cpu(p) with a
    stack overflow so the patch removes the test.
    
    When doing this, an explicit test for NULL stack pointer is
    needed in validate_sp() as it is not anymore implicitely covered
    by the sizeof(thread_info) gap.
    
    In the meantime, with the previous patch all pointers to the stacks
    are not anymore pointers to thread_info so this patch changes them
    to void*
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 85c48911938a..938944c6e2ee 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -618,9 +618,8 @@ static inline void check_stack_overflow(void)
 	sp = current_stack_pointer() & (THREAD_SIZE-1);
 
 	/* check for stack overflow: is there less than 2KB free? */
-	if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
-		pr_err("do_IRQ: stack overflow: %ld\n",
-			sp - sizeof(struct thread_info));
+	if (unlikely(sp < 2048)) {
+		pr_err("do_IRQ: stack overflow: %ld\n", sp);
 		dump_stack();
 	}
 #endif
@@ -660,7 +659,7 @@ void __do_irq(struct pt_regs *regs)
 void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-	struct thread_info *curtp, *irqtp, *sirqtp;
+	void *curtp, *irqtp, *sirqtp;
 
 	/* Switch to the irq stack to handle this */
 	curtp = (void *)(current_stack_pointer() & ~(THREAD_SIZE - 1));
@@ -686,17 +685,17 @@ void __init init_IRQ(void)
 }
 
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
-struct thread_info   *critirq_ctx[NR_CPUS] __read_mostly;
-struct thread_info    *dbgirq_ctx[NR_CPUS] __read_mostly;
-struct thread_info *mcheckirq_ctx[NR_CPUS] __read_mostly;
+void   *critirq_ctx[NR_CPUS] __read_mostly;
+void    *dbgirq_ctx[NR_CPUS] __read_mostly;
+void *mcheckirq_ctx[NR_CPUS] __read_mostly;
 #endif
 
-struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;
-struct thread_info *hardirq_ctx[NR_CPUS] __read_mostly;
+void *softirq_ctx[NR_CPUS] __read_mostly;
+void *hardirq_ctx[NR_CPUS] __read_mostly;
 
 void do_softirq_own_stack(void)
 {
-	struct thread_info *irqtp;
+	void *irqtp;
 
 	irqtp = softirq_ctx[smp_processor_id()];
 	call_do_softirq(irqtp);

commit ed1cd6deb013a11959d17a94e35ce159197632da
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 31 10:08:58 2019 +0000

    powerpc: Activate CONFIG_THREAD_INFO_IN_TASK
    
    This patch activates CONFIG_THREAD_INFO_IN_TASK which
    moves the thread_info into task_struct.
    
    Moving thread_info into task_struct has the following advantages:
      - It protects thread_info from corruption in the case of stack
        overflows.
      - Its address is harder to determine if stack addresses are leaked,
        making a number of attacks more difficult.
    
    This has the following consequences:
      - thread_info is now located at the beginning of task_struct.
      - The 'cpu' field is now in task_struct, and only exists when
        CONFIG_SMP is active.
      - thread_info doesn't have anymore the 'task' field.
    
    This patch:
      - Removes all recopy of thread_info struct when the stack changes.
      - Changes the CURRENT_THREAD_INFO() macro to point to current.
      - Selects CONFIG_THREAD_INFO_IN_TASK.
      - Modifies raw_smp_processor_id() to get ->cpu from current without
        including linux/sched.h to avoid circular inclusion and without
        including asm/asm-offsets.h to avoid symbol names duplication
        between ASM constants and C constants.
      - Modifies klp_init_thread_info() to take a task_struct pointer
        argument.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Add task_stack.h to livepatch.h to fix build fails]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 531e9ef153c0..85c48911938a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -673,24 +673,9 @@ void do_IRQ(struct pt_regs *regs)
 		set_irq_regs(old_regs);
 		return;
 	}
-
-	/* Prepare the thread_info in the irq stack */
-	irqtp->task = curtp->task;
-	irqtp->flags = 0;
-
-	/* Copy the preempt_count so that the [soft]irq checks work. */
-	irqtp->preempt_count = curtp->preempt_count;
-
 	/* Switch stack and call */
 	call_do_irq(regs, irqtp);
 
-	/* Restore stack limit */
-	irqtp->task = NULL;
-
-	/* Copy back updates to the thread_info */
-	if (irqtp->flags)
-		set_bits(irqtp->flags, &curtp->flags);
-
 	set_irq_regs(old_regs);
 }
 
@@ -698,85 +683,23 @@ void __init init_IRQ(void)
 {
 	if (ppc_md.init_IRQ)
 		ppc_md.init_IRQ();
-
-	exc_lvl_ctx_init();
-
-	irq_ctx_init();
 }
 
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
 struct thread_info   *critirq_ctx[NR_CPUS] __read_mostly;
 struct thread_info    *dbgirq_ctx[NR_CPUS] __read_mostly;
 struct thread_info *mcheckirq_ctx[NR_CPUS] __read_mostly;
-
-void exc_lvl_ctx_init(void)
-{
-	struct thread_info *tp;
-	int i, cpu_nr;
-
-	for_each_possible_cpu(i) {
-#ifdef CONFIG_PPC64
-		cpu_nr = i;
-#else
-#ifdef CONFIG_SMP
-		cpu_nr = get_hard_smp_processor_id(i);
-#else
-		cpu_nr = 0;
-#endif
-#endif
-
-		tp = critirq_ctx[cpu_nr];
-		tp->cpu = cpu_nr;
-		tp->preempt_count = 0;
-
-#ifdef CONFIG_BOOKE
-		tp = dbgirq_ctx[cpu_nr];
-		tp->cpu = cpu_nr;
-		tp->preempt_count = 0;
-
-		tp = mcheckirq_ctx[cpu_nr];
-		tp->cpu = cpu_nr;
-		tp->preempt_count = HARDIRQ_OFFSET;
-#endif
-	}
-}
 #endif
 
 struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;
 struct thread_info *hardirq_ctx[NR_CPUS] __read_mostly;
 
-void irq_ctx_init(void)
-{
-	struct thread_info *tp;
-	int i;
-
-	for_each_possible_cpu(i) {
-		tp = softirq_ctx[i];
-		tp->cpu = i;
-		klp_init_thread_info(tp);
-
-		tp = hardirq_ctx[i];
-		tp->cpu = i;
-		klp_init_thread_info(tp);
-	}
-}
-
 void do_softirq_own_stack(void)
 {
-	struct thread_info *curtp, *irqtp;
+	struct thread_info *irqtp;
 
-	curtp = current_thread_info();
 	irqtp = softirq_ctx[smp_processor_id()];
-	irqtp->task = curtp->task;
-	irqtp->flags = 0;
 	call_do_softirq(irqtp);
-	irqtp->task = NULL;
-
-	/* Set any flag that may have been set on the
-	 * alternate stack
-	 */
-	if (irqtp->flags)
-		set_bits(irqtp->flags, &curtp->flags);
 }
 
 irq_hw_number_t virq_to_hw(unsigned int virq)

commit 7306e83ccf5ce3a324546d274945ec1981d78f9a
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 17 23:23:57 2019 +1100

    powerpc: Don't use CURRENT_THREAD_INFO to find the stack
    
    A few places use CURRENT_THREAD_INFO, or the C version, to find the
    stack. This will no longer work with THREAD_INFO_IN_TASK so change
    them to find the stack in other ways.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4a5dd8800946..531e9ef153c0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -663,7 +663,7 @@ void do_IRQ(struct pt_regs *regs)
 	struct thread_info *curtp, *irqtp, *sirqtp;
 
 	/* Switch to the irq stack to handle this */
-	curtp = current_thread_info();
+	curtp = (void *)(current_stack_pointer() & ~(THREAD_SIZE - 1));
 	irqtp = hardirq_ctx[raw_smp_processor_id()];
 	sirqtp = softirq_ctx[raw_smp_processor_id()];
 

commit c8e409a33cf8df5060064a70df3e1350841371e1
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 31 10:08:44 2019 +0000

    powerpc/irq: use memblock functions returning virtual address
    
    Since only the virtual address of allocated blocks is used,
    lets use functions returning directly virtual address.
    
    Those functions have the advantage of also zeroing the block.
    
    Suggested-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Acked-by: Mike Rapoport <rppt@linux.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index bb299613a462..4a5dd8800946 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -725,18 +725,15 @@ void exc_lvl_ctx_init(void)
 #endif
 #endif
 
-		memset((void *)critirq_ctx[cpu_nr], 0, THREAD_SIZE);
 		tp = critirq_ctx[cpu_nr];
 		tp->cpu = cpu_nr;
 		tp->preempt_count = 0;
 
 #ifdef CONFIG_BOOKE
-		memset((void *)dbgirq_ctx[cpu_nr], 0, THREAD_SIZE);
 		tp = dbgirq_ctx[cpu_nr];
 		tp->cpu = cpu_nr;
 		tp->preempt_count = 0;
 
-		memset((void *)mcheckirq_ctx[cpu_nr], 0, THREAD_SIZE);
 		tp = mcheckirq_ctx[cpu_nr];
 		tp->cpu = cpu_nr;
 		tp->preempt_count = HARDIRQ_OFFSET;
@@ -754,12 +751,10 @@ void irq_ctx_init(void)
 	int i;
 
 	for_each_possible_cpu(i) {
-		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
 		tp = softirq_ctx[i];
 		tp->cpu = i;
 		klp_init_thread_info(tp);
 
-		memset((void *)hardirq_ctx[i], 0, THREAD_SIZE);
 		tp = hardirq_ctx[i];
 		tp->cpu = i;
 		klp_init_thread_info(tp);

commit 607ea5090b3fb61fea1d0bc5278e6c1d40ab5bd6
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Jan 8 11:37:19 2019 +0000

    powerpc/irq: drop arch_early_irq_init()
    
    arch_early_irq_init() does nothing different than the weak
    arch_early_irq_init() in kernel/softirq.c
    
    Fixes: 089fb442f301 ("powerpc: Use ARCH_IRQ_INIT_FLAGS")
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 916ddc4aac44..bb299613a462 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -827,11 +827,6 @@ int irq_choose_cpu(const struct cpumask *mask)
 }
 #endif
 
-int arch_early_irq_init(void)
-{
-	return 0;
-}
-
 #ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {

commit 4da1f79227ad42550e3e70e7b4812ec019be3b6e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Aug 6 20:30:49 2018 +1000

    powerpc/64: Disable irq restore warning for now
    
    We recently added a warning in arch_local_irq_restore() to check that
    the soft masking state matches reality.
    
    Unfortunately it trips in a few places, which are not entirely trivial
    to fix. The key problem is if we're doing function_graph tracing of
    restore_math(), the warning pops and then seems to recurse. It's not
    entirely clear because the system continuously oopses on all CPUs,
    with the output interleaved and unreadable.
    
    It's also been observed on a G5 coming out of idle.
    
    Until we can fix those cases disable the warning for now.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ca941f1e83a9..916ddc4aac44 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -261,9 +261,16 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 */
 	irq_happened = get_irq_happened();
 	if (!irq_happened) {
-#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-		WARN_ON(!(mfmsr() & MSR_EE));
-#endif
+		/*
+		 * FIXME. Here we'd like to be able to do:
+		 *
+		 * #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
+		 *   WARN_ON(!(mfmsr() & MSR_EE));
+		 * #endif
+		 *
+		 * But currently it hits in a few paths, we should fix those and
+		 * enable the warning.
+		 */
 		return;
 	}
 

commit 9b81c0211c249c1bc8caec2ddbc86e36c550ce0f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Jun 3 22:24:32 2018 +1000

    powerpc/64s: make PACA_IRQ_HARD_DIS track MSR[EE] closely
    
    When the masked interrupt handler clears MSR[EE] for an interrupt in
    the PACA_IRQ_MUST_HARD_MASK set, it does not set PACA_IRQ_HARD_DIS.
    This makes them get out of synch.
    
    With that taken into account, it's only low level irq manipulation
    (and interrupt entry before reconcile) where they can be out of synch.
    This makes the code less surprising.
    
    It also allows the IRQ replay code to rely on the IRQ_HARD_DIS value
    and not have to mtmsrd again in this case (e.g., for an external
    interrupt that has been masked). The bigger benefit might just be
    that there is not such an element of surprise in these two bits of
    state.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0682fef1f385..ca941f1e83a9 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -145,8 +145,20 @@ notrace unsigned int __check_irq_replay(void)
 	trace_hardirqs_on();
 	trace_hardirqs_off();
 
+	/*
+	 * We are always hard disabled here, but PACA_IRQ_HARD_DIS may
+	 * not be set, which means interrupts have only just been hard
+	 * disabled as part of the local_irq_restore or interrupt return
+	 * code. In that case, skip the decrementr check becaus it's
+	 * expensive to read the TB.
+	 *
+	 * HARD_DIS then gets cleared here, but it's reconciled later.
+	 * Either local_irq_disable will replay the interrupt and that
+	 * will reconcile state like other hard interrupts. Or interrupt
+	 * retur will replay the interrupt and in that case it sets
+	 * PACA_IRQ_HARD_DIS by hand (see comments in entry_64.S).
+	 */
 	if (happened & PACA_IRQ_HARD_DIS) {
-		/* Clear bit 0 which we wouldn't clear otherwise */
 		local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
 
 		/*
@@ -248,24 +260,26 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 * cannot have preempted.
 	 */
 	irq_happened = get_irq_happened();
-	if (!irq_happened)
+	if (!irq_happened) {
+#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
+		WARN_ON(!(mfmsr() & MSR_EE));
+#endif
 		return;
+	}
 
 	/*
 	 * We need to hard disable to get a trusted value from
 	 * __check_irq_replay(). We also need to soft-disable
 	 * again to avoid warnings in there due to the use of
 	 * per-cpu variables.
-	 *
-	 * We know that if the value in irq_happened is exactly 0x01
-	 * then we are already hard disabled (there are other less
-	 * common cases that we'll ignore for now), so we skip the
-	 * (expensive) mtmsrd.
 	 */
-	if (unlikely(irq_happened != PACA_IRQ_HARD_DIS))
+	if (!(irq_happened & PACA_IRQ_HARD_DIS)) {
+#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
+		WARN_ON(!(mfmsr() & MSR_EE));
+#endif
 		__hard_irq_disable();
 #ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
-	else {
+	} else {
 		/*
 		 * We should already be hard disabled here. We had bugs
 		 * where that wasn't the case so let's dbl check it and
@@ -274,8 +288,8 @@ notrace void arch_local_irq_restore(unsigned long mask)
 		 */
 		if (WARN_ON(mfmsr() & MSR_EE))
 			__hard_irq_disable();
-	}
 #endif
+	}
 
 	irq_soft_mask_set(IRQS_ALL_DISABLED);
 	trace_hardirqs_off();

commit e360cd37f0e9bac7b5f623132549e2d4b6417399
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat May 5 03:19:35 2018 +1000

    powerpc/time: account broadcast timer event interrupts separately
    
    These are not local timer interrupts but IPIs. It's good to be able
    to see how timer offloading is behaving, so split these out into
    their own category.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index bbf7ec582d60..0682fef1f385 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -508,6 +508,11 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs_event);
         seq_printf(p, "  Local timer interrupts for timer event device\n");
 
+	seq_printf(p, "%*s: ", prec, "BCT");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).broadcast_irqs_event);
+	seq_printf(p, "  Broadcast timer interrupts for timer event device\n");
+
 	seq_printf(p, "%*s: ", prec, "LOC");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs_others);
@@ -567,6 +572,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 {
 	u64 sum = per_cpu(irq_stat, cpu).timer_irqs_event;
 
+	sum += per_cpu(irq_stat, cpu).broadcast_irqs_event;
 	sum += per_cpu(irq_stat, cpu).pmu_irqs;
 	sum += per_cpu(irq_stat, cpu).mce_exceptions;
 	sum += per_cpu(irq_stat, cpu).spurious_irqs;

commit bd13ac95f954570e01fba5a6caf771da754ac0e3
Author: Mathieu Malaterre <malat@debian.org>
Date:   Wed Apr 4 22:10:28 2018 +0200

    powerpc/tau: Synchronize function prototypes and body
    
    Some function prototypes and body for Thermal Assist Units were not in
    sync. Update the function definition to match the existing function
    declaration found in `setup-common.c`, changing an `int` return type to a
    `u32` return type. Move the prototypes to a header file. Fix the following
    warnings, treated as error with W=1:
    
      arch/powerpc/kernel/tau_6xx.c:257:5: error: no previous prototype for âcpu_temp_bothâ [-Werror=missing-prototypes]
      arch/powerpc/kernel/tau_6xx.c:262:5: error: no previous prototype for âcpu_tempâ [-Werror=missing-prototypes]
      arch/powerpc/kernel/tau_6xx.c:267:5: error: no previous prototype for âtau_interruptsâ [-Werror=missing-prototypes]
    
    Compile tested with CONFIG_TAU_INT.
    
    Suggested-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 061aa0f47bb1..bbf7ec582d60 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -89,7 +89,7 @@ atomic_t ppc_n_lost_interrupts;
 
 #ifdef CONFIG_TAU_INT
 extern int tau_initialized;
-extern int tau_interrupts(int);
+u32 tau_interrupts(unsigned long cpu);
 #endif
 #endif /* CONFIG_PPC32 */
 

commit ff6781fd1bb404d8a551c02c35c70cec1da17ff1
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Mar 21 12:22:28 2018 +1000

    powerpc/64s: Fix lost pending interrupt due to race causing lost update to irq_happened
    
    force_external_irq_replay() can be called in the do_IRQ path with
    interrupts hard enabled and soft disabled if may_hard_irq_enable() set
    MSR[EE]=1. It updates local_paca->irq_happened with a load, modify,
    store sequence. If a maskable interrupt hits during this sequence, it
    will go to the masked handler to be marked pending in irq_happened.
    This update will be lost when the interrupt returns and the store
    instruction executes. This can result in unpredictable latencies,
    timeouts, lockups, etc.
    
    Fix this by ensuring hard interrupts are disabled before modifying
    irq_happened.
    
    This could cause any maskable asynchronous interrupt to get lost, but
    it was noticed on P9 SMP system doing RDMA NVMe target over 100GbE,
    so very high external interrupt rate and high IPI rate. The hang was
    bisected down to enabling doorbell interrupts for IPIs. These provided
    an interrupt type that could run at high rates in the do_IRQ path,
    stressing the race.
    
    Fixes: 1d607bb3bd60 ("powerpc/irq: Add mechanism to force a replay of interrupts")
    Cc: stable@vger.kernel.org # v4.8+
    Reported-by: Carol L. Soto <clsoto@us.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f88038847790..061aa0f47bb1 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -476,6 +476,14 @@ void force_external_irq_replay(void)
 	 */
 	WARN_ON(!arch_irqs_disabled());
 
+	/*
+	 * Interrupts must always be hard disabled before irq_happened is
+	 * modified (to prevent lost update in case of interrupt between
+	 * load and store).
+	 */
+	__hard_irq_disable();
+	local_paca->irq_happened |= PACA_IRQ_HARD_DIS;
+
 	/* Indicate in the PACA that we have an interrupt to replay */
 	local_paca->irq_happened |= PACA_IRQ_EE;
 }

commit 9aa88188ee87f4cc5c4e1bce15754bfcde8e900f
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:54 2017 +0530

    powerpc: Add new kconfig CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
    
    New Kconfig is added "CONFIG_PPC_IRQ_SOFT_MASK_DEBUG" to add WARN_ON
    to alert the invalid transitions. Also moved the code under the
    CONFIG_TRACE_IRQFLAGS in arch_local_irq_restore() to new Kconfig.
    
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    [mpe: Fix name of CONFIG option in change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1a41cceddfe2..f88038847790 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -264,7 +264,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	 */
 	if (unlikely(irq_happened != PACA_IRQ_HARD_DIS))
 		__hard_irq_disable();
-#ifdef CONFIG_TRACE_IRQFLAGS
+#ifdef CONFIG_PPC_IRQ_SOFT_MASK_DEBUG
 	else {
 		/*
 		 * We should already be hard disabled here. We had bugs
@@ -275,7 +275,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 		if (WARN_ON(mfmsr() & MSR_EE))
 			__hard_irq_disable();
 	}
-#endif /* CONFIG_TRACE_IRQFLAGS */
+#endif
 
 	irq_soft_mask_set(IRQS_ALL_DISABLED);
 	trace_hardirqs_off();

commit f442d004806e31fe5aab614ec48e53f7b38f7c2d
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:53 2017 +0530

    powerpc/64s: Add support to mask perf interrupts and replay them
    
    Two new bit mask field "IRQ_DISABLE_MASK_PMU" is introduced to support
    the masking of PMI and "IRQ_DISABLE_MASK_ALL" to aid interrupt masking
    checking.
    
    Couple of new irq #defs "PACA_IRQ_PMI" and "SOFTEN_VALUE_0xf0*" added
    to use in the exception code to check for PMI interrupts.
    
    In the masked_interrupt handler, for PMIs we reset the MSR[EE] and
    return. In the __check_irq_replay(), replay the PMI interrupt by
    calling performance_monitor_common handler.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index e137b98dc5f8..1a41cceddfe2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -186,6 +186,11 @@ notrace unsigned int __check_irq_replay(void)
 		return 0x900;
 	}
 
+	if (happened & PACA_IRQ_PMI) {
+		local_paca->irq_happened &= ~PACA_IRQ_PMI;
+		return 0xf00;
+	}
+
 	if (happened & PACA_IRQ_EE) {
 		local_paca->irq_happened &= ~PACA_IRQ_EE;
 		return 0x500;
@@ -272,7 +277,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	}
 #endif /* CONFIG_TRACE_IRQFLAGS */
 
-	irq_soft_mask_set(IRQS_DISABLED);
+	irq_soft_mask_set(IRQS_ALL_DISABLED);
 	trace_hardirqs_off();
 
 	/*

commit 4e26bc4a4ed683c42ba45f09050575a671c6f1f4
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:50 2017 +0530

    powerpc/64: Rename soft_enabled to irq_soft_mask
    
    Rename the paca->soft_enabled to paca->irq_soft_mask as it is no
    longer used as a flag for interrupt state, but a mask.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 406c4329b535..e137b98dc5f8 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -225,22 +225,9 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	unsigned int replay;
 
 	/* Write the new soft-enabled value */
-	soft_enabled_set(mask);
-	if (mask) {
-#ifdef CONFIG_TRACE_IRQFLAGS
-		/*
-		 * mask must always include LINUX bit if any
-		 * are set, and interrupts don't get replayed until
-		 * the Linux interrupt is unmasked. This could be
-		 * changed to replay partial unmasks in future,
-		 * which would allow Linux masks to nest inside
-		 * other masks, among other things. For now, be very
-		 * dumb and simple.
-		 */
-		WARN_ON(!(mask & IRQS_DISABLED));
-#endif
+	irq_soft_mask_set(mask);
+	if (mask)
 		return;
-	}
 
 	/*
 	 * From this point onward, we can take interrupts, preempt,
@@ -285,7 +272,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 	}
 #endif /* CONFIG_TRACE_IRQFLAGS */
 
-	soft_enabled_set(IRQS_DISABLED);
+	irq_soft_mask_set(IRQS_DISABLED);
 	trace_hardirqs_off();
 
 	/*
@@ -297,7 +284,7 @@ notrace void arch_local_irq_restore(unsigned long mask)
 
 	/* We can soft-enable now */
 	trace_hardirqs_on();
-	soft_enabled_set(IRQS_ENABLED);
+	irq_soft_mask_set(IRQS_ENABLED);
 
 	/*
 	 * And replay if we have to. This will return with interrupts
@@ -372,7 +359,7 @@ bool prep_irq_for_idle(void)
 	 * of entering the low power state.
 	 */
 	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
-	soft_enabled_set(IRQS_ENABLED);
+	irq_soft_mask_set(IRQS_ENABLED);
 
 	/* Tell the caller to enter the low power state */
 	return true;

commit 01417c6cc7dc9195f721f7f9e9ea066090ccc99d
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:49 2017 +0530

    powerpc/64: Change soft_enabled from flag to bitmask
    
    "paca->soft_enabled" is used as a flag to mask some of interrupts.
    Currently supported flags values and their details:
    
    soft_enabled    MSR[EE]
    
    0               0       Disabled (PMI and HMI not masked)
    1               1       Enabled
    
    "paca->soft_enabled" is initialized to 1 to make the interripts as
    enabled. arch_local_irq_disable() will toggle the value when
    interrupts needs to disbled. At this point, the interrupts are not
    actually disabled, instead, interrupt vector has code to check for the
    flag and mask it when it occurs. By "mask it", it update interrupt
    paca->irq_happened and return. arch_local_irq_restore() is called to
    re-enable interrupts, which checks and replays interrupts if any
    occured.
    
    Now, as mentioned, current logic doesnot mask "performance monitoring
    interrupts" and PMIs are implemented as NMI. But this patchset depends
    on local_irq_* for a successful local_* update. Meaning, mask all
    possible interrupts during local_* update and replay them after the
    update.
    
    So the idea here is to reserve the "paca->soft_enabled" logic. New
    values and details:
    
    soft_enabled    MSR[EE]
    
    1               0       Disabled  (PMI and HMI not masked)
    0               1       Enabled
    
    Reason for the this change is to create foundation for a third mask
    value "0x2" for "soft_enabled" to add support to mask PMIs. When
    ->soft_enabled is set to a value "3", PMI interrupts are mask and when
    set to a value of "1", PMI are not mask. With this patch also extends
    soft_enabled as interrupt disable mask.
    
    Current flags are renamed from IRQ_[EN?DIS}ABLED to
    IRQS_ENABLED and IRQS_DISABLED.
    
    Patch also fixes the ptrace call to force the user to see the softe
    value to be alway 1. Reason being, even though userspace has no
    business knowing about softe, it is part of pt_regs. Like-wise in
    signal context.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6c04e465caf5..406c4329b535 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -219,15 +219,29 @@ notrace unsigned int __check_irq_replay(void)
 	return 0;
 }
 
-notrace void arch_local_irq_restore(unsigned long en)
+notrace void arch_local_irq_restore(unsigned long mask)
 {
 	unsigned char irq_happened;
 	unsigned int replay;
 
 	/* Write the new soft-enabled value */
-	soft_enabled_set(en);
-	if (en == IRQS_DISABLED)
+	soft_enabled_set(mask);
+	if (mask) {
+#ifdef CONFIG_TRACE_IRQFLAGS
+		/*
+		 * mask must always include LINUX bit if any
+		 * are set, and interrupts don't get replayed until
+		 * the Linux interrupt is unmasked. This could be
+		 * changed to replay partial unmasks in future,
+		 * which would allow Linux masks to nest inside
+		 * other masks, among other things. For now, be very
+		 * dumb and simple.
+		 */
+		WARN_ON(!(mask & IRQS_DISABLED));
+#endif
 		return;
+	}
+
 	/*
 	 * From this point onward, we can take interrupts, preempt,
 	 * etc... unless we got hard-disabled. We check if an event

commit 0b63acf4a0eb8843f83954ea1bd29ccdfcbaa778
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:45 2017 +0530

    powerpc/64: Move set_soft_enabled() and rename
    
    Move set_soft_enabled() from powerpc/kernel/irq.c to asm/hw_irq.c, to
    encourage updates to paca->soft_enabled done via these access
    function. Add "memory" clobber to hint compiler since
    paca->soft_enabled memory is the target here.
    
    Renaming it as soft_enabled_set() will make namespaces works better as
    prefix than a postfix when new soft_enabled manipulation functions are
    introduced.
    
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 483a9206554f..6c04e465caf5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -107,12 +107,6 @@ static inline notrace unsigned long get_irq_happened(void)
 	return happened;
 }
 
-static inline notrace void set_soft_enabled(unsigned long enable)
-{
-	__asm__ __volatile__("stb %0,%1(13)"
-	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
-}
-
 static inline notrace int decrementer_check_overflow(void)
 {
  	u64 now = get_tb_or_rtc();
@@ -231,7 +225,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 	unsigned int replay;
 
 	/* Write the new soft-enabled value */
-	set_soft_enabled(en);
+	soft_enabled_set(en);
 	if (en == IRQS_DISABLED)
 		return;
 	/*
@@ -277,7 +271,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 	}
 #endif /* CONFIG_TRACE_IRQFLAGS */
 
-	set_soft_enabled(IRQS_DISABLED);
+	soft_enabled_set(IRQS_DISABLED);
 	trace_hardirqs_off();
 
 	/*
@@ -289,7 +283,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 
 	/* We can soft-enable now */
 	trace_hardirqs_on();
-	set_soft_enabled(IRQS_ENABLED);
+	soft_enabled_set(IRQS_ENABLED);
 
 	/*
 	 * And replay if we have to. This will return with interrupts
@@ -364,7 +358,7 @@ bool prep_irq_for_idle(void)
 	 * of entering the low power state.
 	 */
 	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
-	local_paca->soft_enabled = IRQS_ENABLED;
+	soft_enabled_set(IRQS_ENABLED);
 
 	/* Tell the caller to enter the low power state */
 	return true;

commit c2e480ba822718190e58849b79a76db13c3dac18
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:42 2017 +0530

    powerpc/64: Add #defines for paca->soft_enabled flags
    
    Two #defines IRQS_ENABLED and IRQS_DISABLED are added to be used when
    updating paca->soft_enabled. Replace the hardcoded values used when
    updating paca->soft_enabled with IRQ_(EN|DIS)ABLED #define. No logic
    change.
    
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b7a84522e652..483a9206554f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -67,6 +67,7 @@
 #include <asm/smp.h>
 #include <asm/livepatch.h>
 #include <asm/asm-prototypes.h>
+#include <asm/hw_irq.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
@@ -231,7 +232,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 
 	/* Write the new soft-enabled value */
 	set_soft_enabled(en);
-	if (!en)
+	if (en == IRQS_DISABLED)
 		return;
 	/*
 	 * From this point onward, we can take interrupts, preempt,
@@ -276,7 +277,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 	}
 #endif /* CONFIG_TRACE_IRQFLAGS */
 
-	set_soft_enabled(0);
+	set_soft_enabled(IRQS_DISABLED);
 	trace_hardirqs_off();
 
 	/*
@@ -288,7 +289,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 
 	/* We can soft-enable now */
 	trace_hardirqs_on();
-	set_soft_enabled(1);
+	set_soft_enabled(IRQS_ENABLED);
 
 	/*
 	 * And replay if we have to. This will return with interrupts
@@ -363,7 +364,7 @@ bool prep_irq_for_idle(void)
 	 * of entering the low power state.
 	 */
 	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
-	local_paca->soft_enabled = 1;
+	local_paca->soft_enabled = IRQS_ENABLED;
 
 	/* Tell the caller to enter the low power state */
 	return true;

commit ff967900c9d4740f6337c6456f111104267633cb
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Oct 21 17:56:06 2017 +1000

    powerpc/64: Fix latency tracing for lazy irq replay
    
    When returning from an exception to a soft-enabled context, pending
    IRQs are replayed but IRQ tracing is not reset, so a number of them
    can get chained together into the same IRQ-disabled trace.
    
    Fix this by having __check_irq_replay re-set IRQ trace. This is
    conceptually where we respond to the next interrupt, so it fits the
    semantics of the IRQ tracer.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6a6995173f51..b7a84522e652 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -143,6 +143,13 @@ notrace unsigned int __check_irq_replay(void)
 	 */
 	unsigned char happened = local_paca->irq_happened;
 
+	/*
+	 * We are responding to the next interrupt, so interrupt-off
+	 * latencies should be reset here.
+	 */
+	trace_hardirqs_on();
+	trace_hardirqs_off();
+
 	if (happened & PACA_IRQ_HARD_DIS) {
 		/* Clear bit 0 which we wouldn't clear otherwise */
 		local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
@@ -270,6 +277,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 #endif /* CONFIG_TRACE_IRQFLAGS */
 
 	set_soft_enabled(0);
+	trace_hardirqs_off();
 
 	/*
 	 * Check if anything needs to be re-emitted. We haven't
@@ -279,6 +287,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 	replay = __check_irq_replay();
 
 	/* We can soft-enable now */
+	trace_hardirqs_on();
 	set_soft_enabled(1);
 
 	/*

commit 6de6638b35daa0dfb7daefd78d55015655b4d8f3
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Nov 5 23:33:55 2017 +1100

    KVM: PPC: Book3S HV: Handle host system reset in guest mode
    
    If the host takes a system reset interrupt while a guest is running,
    the CPU must exit the guest before processing the host exception
    handler.
    
    After this patch, taking a sysrq+x with a CPU running in a guest
    gives a trace like this:
    
       cpu 0x27: Vector: 100 (System Reset) at [c000000fdf5776f0]
           pc: c008000010158b80: kvmppc_run_core+0x16b8/0x1ad0 [kvm_hv]
           lr: c008000010158b80: kvmppc_run_core+0x16b8/0x1ad0 [kvm_hv]
           sp: c000000fdf577850
          msr: 9000000002803033
         current = 0xc000000fdf4b1e00
         paca    = 0xc00000000fd4d680        softe: 3        irq_happened: 0x01
           pid   = 6608, comm = qemu-system-ppc
       Linux version 4.14.0-rc7-01489-g47e1893a404a-dirty #26 SMP
       [c000000fdf577a00] c008000010159dd4 kvmppc_vcpu_run_hv+0x3dc/0x12d0 [kvm_hv]
       [c000000fdf577b30] c0080000100a537c kvmppc_vcpu_run+0x44/0x60 [kvm]
       [c000000fdf577b60] c0080000100a1ae0 kvm_arch_vcpu_ioctl_run+0x118/0x310 [kvm]
       [c000000fdf577c00] c008000010093e98 kvm_vcpu_ioctl+0x530/0x7c0 [kvm]
       [c000000fdf577d50] c000000000357bf8 do_vfs_ioctl+0xd8/0x8c0
       [c000000fdf577df0] c000000000358448 SyS_ioctl+0x68/0x100
       [c000000fdf577e30] c00000000000b220 system_call+0x58/0x6c
       --- Exception: c01 (System Call) at 00007fff76868df0
       SP (7fff7069baf0) is in userspace
    
    Fixes: e36d0a2ed5 ("powerpc/powernv: Implement NMI IPI with OPAL_SIGNAL_SYSTEM_RESET")
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4813b83b22aa..6a6995173f51 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -415,7 +415,7 @@ static const u8 srr1_to_lazyirq[0x10] = {
 	PACA_IRQ_HMI,
 	0, 0, 0, 0, 0 };
 
-static noinline void replay_system_reset(void)
+void replay_system_reset(void)
 {
 	struct pt_regs regs;
 
@@ -425,6 +425,7 @@ static noinline void replay_system_reset(void)
 	system_reset_exception(&regs);
 	get_paca()->in_nmi = 0;
 }
+EXPORT_SYMBOL_GPL(replay_system_reset);
 
 void irq_set_pending_from_srr1(unsigned long srr1)
 {

commit 78adf6c214f04fef01c714d78441653dc838a3ba
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Sep 29 13:29:41 2017 +1000

    powerpc/64s: Implement system reset idle wakeup reason
    
    It is possible to wake from idle due to a system reset exception, in
    which case the CPU takes a system reset interrupt to wake from idle,
    with system reset as the wakeup reason.
    
    The regular (not idle wakeup) system reset interrupt handler must be
    invoked in this case, otherwise the system reset interrupt is lost.
    
    Handle the system reset interrupt immediately after CPU state has been
    restored.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4e65bf82f5e0..4813b83b22aa 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -394,11 +394,19 @@ bool prep_irq_for_idle_irqsoff(void)
 /*
  * Take the SRR1 wakeup reason, index into this table to find the
  * appropriate irq_happened bit.
+ *
+ * Sytem reset exceptions taken in idle state also come through here,
+ * but they are NMI interrupts so do not need to wait for IRQs to be
+ * restored, and should be taken as early as practical. These are marked
+ * with 0xff in the table. The Power ISA specifies 0100b as the system
+ * reset interrupt reason.
  */
+#define IRQ_SYSTEM_RESET	0xff
+
 static const u8 srr1_to_lazyirq[0x10] = {
 	0, 0, 0,
 	PACA_IRQ_DBELL,
-	0,
+	IRQ_SYSTEM_RESET,
 	PACA_IRQ_DBELL,
 	PACA_IRQ_DEC,
 	0,
@@ -407,15 +415,42 @@ static const u8 srr1_to_lazyirq[0x10] = {
 	PACA_IRQ_HMI,
 	0, 0, 0, 0, 0 };
 
+static noinline void replay_system_reset(void)
+{
+	struct pt_regs regs;
+
+	ppc_save_regs(&regs);
+	regs.trap = 0x100;
+	get_paca()->in_nmi = 1;
+	system_reset_exception(&regs);
+	get_paca()->in_nmi = 0;
+}
+
 void irq_set_pending_from_srr1(unsigned long srr1)
 {
 	unsigned int idx = (srr1 & SRR1_WAKEMASK_P8) >> 18;
+	u8 reason = srr1_to_lazyirq[idx];
+
+	/*
+	 * Take the system reset now, which is immediately after registers
+	 * are restored from idle. It's an NMI, so interrupts need not be
+	 * re-enabled before it is taken.
+	 */
+	if (unlikely(reason == IRQ_SYSTEM_RESET)) {
+		replay_system_reset();
+		return;
+	}
 
 	/*
 	 * The 0 index (SRR1[42:45]=b0000) must always evaluate to 0,
-	 * so this can be called unconditionally with srr1 wake reason.
+	 * so this can be called unconditionally with the SRR1 wake
+	 * reason as returned by the idle code, which uses 0 to mean no
+	 * interrupt.
+	 *
+	 * If a future CPU was to designate this as an interrupt reason,
+	 * then a new index for no interrupt must be assigned.
 	 */
-	local_paca->irq_happened |= srr1_to_lazyirq[idx];
+	local_paca->irq_happened |= reason;
 }
 #endif /* CONFIG_PPC_BOOK3S */
 

commit d6f73fc69bf5837ad0d028d2a40f912921ed839f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Aug 12 02:39:03 2017 +1000

    powerpc/64s: Merge HV and non-HV paths for doorbell IRQ replay
    
    This results in smaller code, and fewer branches. This relies on the
    fact that both the 0xe80 and 0xa00 handlers call the same upper level
    code, namely doorbell_exception().
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Mention we rely on the implementation of the 0xe80/0xa00 handlers]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b5d7c27186bd..4e65bf82f5e0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -207,8 +207,6 @@ notrace unsigned int __check_irq_replay(void)
 #else
 	if (happened & PACA_IRQ_DBELL) {
 		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
-		if (cpu_has_feature(CPU_FTR_HVMODE))
-			return 0xe80;
 		return 0xa00;
 	}
 #endif /* CONFIG_PPC_BOOK3E */

commit 6f881eaeb552ad27b7e8210919c19b7be3d88d9d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Aug 12 02:39:02 2017 +1000

    powerpc/64: Cleanup __check_irq_replay()
    
    Move the clearing of irq_happened bits into the condition where they
    were found to be set. This reduces instruction count slightly, and
    reduces stores into irq_happened.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index da6d22ab180e..b5d7c27186bd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -143,9 +143,10 @@ notrace unsigned int __check_irq_replay(void)
 	 */
 	unsigned char happened = local_paca->irq_happened;
 
-	/* Clear bit 0 which we wouldn't clear otherwise */
-	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
 	if (happened & PACA_IRQ_HARD_DIS) {
+		/* Clear bit 0 which we wouldn't clear otherwise */
+		local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
+
 		/*
 		 * We may have missed a decrementer interrupt if hard disabled.
 		 * Check the decrementer register in case we had a rollover
@@ -173,39 +174,39 @@ notrace unsigned int __check_irq_replay(void)
 	 * This is a higher priority interrupt than the others, so
 	 * replay it first.
 	 */
-	local_paca->irq_happened &= ~PACA_IRQ_HMI;
-	if (happened & PACA_IRQ_HMI)
+	if (happened & PACA_IRQ_HMI) {
+		local_paca->irq_happened &= ~PACA_IRQ_HMI;
 		return 0xe60;
+	}
 
-	/*
-	 * We may have missed a decrementer interrupt. We check the
-	 * decrementer itself rather than the paca irq_happened field
-	 * in case we also had a rollover while hard disabled
-	 */
-	local_paca->irq_happened &= ~PACA_IRQ_DEC;
-	if (happened & PACA_IRQ_DEC)
+	if (happened & PACA_IRQ_DEC) {
+		local_paca->irq_happened &= ~PACA_IRQ_DEC;
 		return 0x900;
+	}
 
-	/* Finally check if an external interrupt happened */
-	local_paca->irq_happened &= ~PACA_IRQ_EE;
-	if (happened & PACA_IRQ_EE)
+	if (happened & PACA_IRQ_EE) {
+		local_paca->irq_happened &= ~PACA_IRQ_EE;
 		return 0x500;
+	}
 
 #ifdef CONFIG_PPC_BOOK3E
-	/* Finally check if an EPR external interrupt happened
-	 * this bit is typically set if we need to handle another
-	 * "edge" interrupt from within the MPIC "EPR" handler
+	/*
+	 * Check if an EPR external interrupt happened this bit is typically
+	 * set if we need to handle another "edge" interrupt from within the
+	 * MPIC "EPR" handler.
 	 */
-	local_paca->irq_happened &= ~PACA_IRQ_EE_EDGE;
-	if (happened & PACA_IRQ_EE_EDGE)
+	if (happened & PACA_IRQ_EE_EDGE) {
+		local_paca->irq_happened &= ~PACA_IRQ_EE_EDGE;
 		return 0x500;
+	}
 
-	local_paca->irq_happened &= ~PACA_IRQ_DBELL;
-	if (happened & PACA_IRQ_DBELL)
+	if (happened & PACA_IRQ_DBELL) {
+		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
 		return 0x280;
+	}
 #else
-	local_paca->irq_happened &= ~PACA_IRQ_DBELL;
 	if (happened & PACA_IRQ_DBELL) {
+		local_paca->irq_happened &= ~PACA_IRQ_DBELL;
 		if (cpu_has_feature(CPU_FTR_HVMODE))
 			return 0xe80;
 		return 0xa00;

commit 15c659ff9d5b367c886166a9854a89b72c524a68
Merge: 516fa8d0e19d 1a92a80ad386
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Aug 23 22:20:10 2017 +1000

    Merge branch 'fixes' into next
    
    There's a non-trivial dependency between some commits we want to put in
    next and the KVM prefetch work around that went into fixes. So merge
    fixes into next.

commit 968159c0031ac1e07ab4426397e786c9c483f068
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 8 13:58:54 2017 +0200

    powerpc/8xx: Getting rid of remaining use of CONFIG_8xx
    
    Two config options exist to define powerpc MPC8xx:
    * CONFIG_PPC_8xx
    * CONFIG_8xx
    
    arch/powerpc/platforms/Kconfig.cputype has contained the following
    comment about CONFIG_8xx item for some years:
    "# this is temp to handle compat with arch=ppc"
    
    arch/powerpc is now the only place with remaining use of
    CONFIG_8xx: get rid of them.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 77a7f7514327..8b514e910bf1 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -24,7 +24,7 @@
  * mask register (of which only 16 are defined), hence the weird shifting
  * and complement of the cached_irq_mask.  I want to be able to stuff
  * this right into the SIU SMASK register.
- * Many of the prep/chrp functions are conditional compiled on CONFIG_8xx
+ * Many of the prep/chrp functions are conditional compiled on CONFIG_PPC_8xx
  * to reduce code space and undefined function references.
  */
 

commit 04019bf8ebb3c8cd66d75046054aeb264ba2db54
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Aug 1 22:00:54 2017 +1000

    powerpc: Add irq accounting for watchdog interrupts
    
    This adds an irq counter for the watchdog soft-NMI. This interrupt
    only fires when interrupts are soft-disabled, so it will not
    increment much even when the watchdog is running. However it's
    useful for debugging and sanity checking.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5c18335580b6..77a7f7514327 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -475,6 +475,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).sreset_irqs);
 	seq_printf(p, "  System Reset interrupts\n");
 
+#ifdef CONFIG_PPC_WATCHDOG
+	seq_printf(p, "%*s: ", prec, "WDG");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).soft_nmi_irqs);
+	seq_printf(p, "  Watchdog soft-NMI interrupts\n");
+#endif
+
 #ifdef CONFIG_PPC_DOORBELL
 	if (cpu_has_feature(CPU_FTR_DBELL)) {
 		seq_printf(p, "%*s: ", prec, "DBL");
@@ -500,6 +507,9 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += per_cpu(irq_stat, cpu).timer_irqs_others;
 	sum += per_cpu(irq_stat, cpu).hmi_exceptions;
 	sum += per_cpu(irq_stat, cpu).sreset_irqs;
+#ifdef CONFIG_PPC_WATCHDOG
+	sum += per_cpu(irq_stat, cpu).soft_nmi_irqs;
+#endif
 #ifdef CONFIG_PPC_DOORBELL
 	sum += per_cpu(irq_stat, cpu).doorbell_irqs;
 #endif

commit ca41ad4377072e3e51593a2a9593c6cdbf4a5c0d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Aug 1 22:00:53 2017 +1000

    powerpc: Add irq accounting for system reset interrupts
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0bcec745a672..5c18335580b6 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -470,6 +470,11 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "  Hypervisor Maintenance Interrupts\n");
 	}
 
+	seq_printf(p, "%*s: ", prec, "NMI");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).sreset_irqs);
+	seq_printf(p, "  System Reset interrupts\n");
+
 #ifdef CONFIG_PPC_DOORBELL
 	if (cpu_has_feature(CPU_FTR_DBELL)) {
 		seq_printf(p, "%*s: ", prec, "DBL");
@@ -494,6 +499,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += per_cpu(irq_stat, cpu).spurious_irqs;
 	sum += per_cpu(irq_stat, cpu).timer_irqs_others;
 	sum += per_cpu(irq_stat, cpu).hmi_exceptions;
+	sum += per_cpu(irq_stat, cpu).sreset_irqs;
 #ifdef CONFIG_PPC_DOORBELL
 	sum += per_cpu(irq_stat, cpu).doorbell_irqs;
 #endif

commit 3db40c312c2c1eb2187c5731102fa8ff380e6e40
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Aug 1 23:59:28 2017 +1000

    powerpc/64: Fix __check_irq_replay missing decrementer interrupt
    
    If the decrementer wraps again and de-asserts the decrementer
    exception while hard-disabled, __check_irq_replay() has a test to
    notice the wrap when interrupts are re-enabled.
    
    The decrementer check must be done when clearing the PACA_IRQ_HARD_DIS
    flag, not when the PACA_IRQ_DEC flag is tested. Previously this worked
    because the decrementer interrupt was always the first one checked
    after clearing the hard disable flag, but HMI check was moved ahead of
    that, which introduced this bug.
    
    This can cause a missed decrementer interrupt if we soft-disable
    interrupts then take an HMI which is recorded in irq_happened, then
    hard-disable interrupts for > 4s to wrap the decrementer.
    
    Fixes: e0e0d6b7390b ("powerpc/64: Replay hypervisor maintenance interrupt first")
    Cc: stable@vger.kernel.org # v4.9+
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0bcec745a672..f291f7826abc 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -145,6 +145,19 @@ notrace unsigned int __check_irq_replay(void)
 
 	/* Clear bit 0 which we wouldn't clear otherwise */
 	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
+	if (happened & PACA_IRQ_HARD_DIS) {
+		/*
+		 * We may have missed a decrementer interrupt if hard disabled.
+		 * Check the decrementer register in case we had a rollover
+		 * while hard disabled.
+		 */
+		if (!(happened & PACA_IRQ_DEC)) {
+			if (decrementer_check_overflow()) {
+				local_paca->irq_happened |= PACA_IRQ_DEC;
+				happened |= PACA_IRQ_DEC;
+			}
+		}
+	}
 
 	/*
 	 * Force the delivery of pending soft-disabled interrupts on PS3.
@@ -170,7 +183,7 @@ notrace unsigned int __check_irq_replay(void)
 	 * in case we also had a rollover while hard disabled
 	 */
 	local_paca->irq_happened &= ~PACA_IRQ_DEC;
-	if ((happened & PACA_IRQ_DEC) || decrementer_check_overflow())
+	if (happened & PACA_IRQ_DEC)
 		return 0x900;
 
 	/* Finally check if an external interrupt happened */

commit 771d4304d07f080b6ce751e12f3579cb012a1b22
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Jun 13 23:05:47 2017 +1000

    powerpc/64s/idle: Process interrupts from system reset wakeup
    
    When the CPU wakes from low power state, it begins at the system reset
    interrupt with the exception that caused the wakeup encoded in SRR1.
    
    Today, powernv idle wakeup ignores the wakeup reason (except a special
    case for HMI), and the regular interrupt corresponding to the
    exception will fire after the idle wakeup exits.
    
    Change this to replay the interrupt from the idle wakeup before
    interrupts are hard-enabled.
    
    Test on POWER8 of context_switch selftests benchmark with polling idle
    disabled (e.g., always nap, giving cross-CPU IPIs) gives the following
    results:
    
                                    original         wakeup direct
    Different threads, same core:   315k/s           264k/s
    Different cores:                235k/s           242k/s
    
    There is a slowdown for doorbell IPI (same core) case because system
    reset wakeup does not clear the message and the doorbell interrupt
    fires again needlessly.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 58dcac88bc79..0bcec745a672 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -348,6 +348,7 @@ bool prep_irq_for_idle(void)
 	return true;
 }
 
+#ifdef CONFIG_PPC_BOOK3S
 /*
  * This is for idle sequences that return with IRQs off, but the
  * idle state itself wakes on interrupt. Tell the irq tracer that
@@ -378,6 +379,34 @@ bool prep_irq_for_idle_irqsoff(void)
 	return true;
 }
 
+/*
+ * Take the SRR1 wakeup reason, index into this table to find the
+ * appropriate irq_happened bit.
+ */
+static const u8 srr1_to_lazyirq[0x10] = {
+	0, 0, 0,
+	PACA_IRQ_DBELL,
+	0,
+	PACA_IRQ_DBELL,
+	PACA_IRQ_DEC,
+	0,
+	PACA_IRQ_EE,
+	PACA_IRQ_EE,
+	PACA_IRQ_HMI,
+	0, 0, 0, 0, 0 };
+
+void irq_set_pending_from_srr1(unsigned long srr1)
+{
+	unsigned int idx = (srr1 & SRR1_WAKEMASK_P8) >> 18;
+
+	/*
+	 * The 0 index (SRR1[42:45]=b0000) must always evaluate to 0,
+	 * so this can be called unconditionally with srr1 wake reason.
+	 */
+	local_paca->irq_happened |= srr1_to_lazyirq[idx];
+}
+#endif /* CONFIG_PPC_BOOK3S */
+
 /*
  * Force a replay of the external interrupt handler on this CPU.
  */

commit 2201f994a5742c03e660623c385fd6897dd1fa2f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Jun 13 23:05:45 2017 +1000

    powerpc/64s/idle: Move soft interrupt mask logic into C code
    
    This simplifies the asm and fixes irq-off tracing over sleep
    instructions.
    
    Also move powersave_nap check for POWER8 into C code, and move
    PSSCR register value calculation for POWER9 into C.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5c291df30fe3..58dcac88bc79 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -322,7 +322,8 @@ bool prep_irq_for_idle(void)
 	 * First we need to hard disable to ensure no interrupt
 	 * occurs before we effectively enter the low power state
 	 */
-	hard_irq_disable();
+	__hard_irq_disable();
+	local_paca->irq_happened |= PACA_IRQ_HARD_DIS;
 
 	/*
 	 * If anything happened while we were soft-disabled,
@@ -347,6 +348,36 @@ bool prep_irq_for_idle(void)
 	return true;
 }
 
+/*
+ * This is for idle sequences that return with IRQs off, but the
+ * idle state itself wakes on interrupt. Tell the irq tracer that
+ * IRQs are enabled for the duration of idle so it does not get long
+ * off times. Must be paired with fini_irq_for_idle_irqsoff.
+ */
+bool prep_irq_for_idle_irqsoff(void)
+{
+	WARN_ON(!irqs_disabled());
+
+	/*
+	 * First we need to hard disable to ensure no interrupt
+	 * occurs before we effectively enter the low power state
+	 */
+	__hard_irq_disable();
+	local_paca->irq_happened |= PACA_IRQ_HARD_DIS;
+
+	/*
+	 * If anything happened while we were soft-disabled,
+	 * we return now and do not enter the low power state.
+	 */
+	if (lazy_irq_pending())
+		return false;
+
+	/* Tell lockdep we are about to re-enable */
+	trace_hardirqs_on();
+
+	return true;
+}
+
 /*
  * Force a replay of the external interrupt handler on this CPU.
  */

commit 0edc2ca9ccc9df99f7a94b6407ae2a0ff27d86b2
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jun 15 16:20:46 2017 +1000

    Revert "powerpc: Handle simultaneous interrupts at once"
    
    This reverts commit 45cb08f4791ce6a15c54598b4cb73db4b4b8294f.
    
    For some reason this is causing IRQ problems on Freescale Book3E
    machines, eg on my p5020ds:
    
      irq 25: nobody cared (try booting with the "irqpoll" option)
      CPU: 0 PID: 1 Comm: swapper/0 Not tainted 4.12.0-rc3-gcc-6.3.1-00037-g45cb08f4791c #624
      Call Trace:
      [c0000000fffdbb10] [c00000000049962c] .dump_stack+0xa8/0xe8 (unreliable)
      [c0000000fffdbba0] [c0000000000babf4] .__report_bad_irq+0x54/0x140
      [c0000000fffdbc40] [c0000000000bb11c] .note_interrupt+0x324/0x380
      [c0000000fffdbd00] [c0000000000b7110] .handle_irq_event_percpu+0x68/0x88
      [c0000000fffdbd90] [c0000000000b718c] .handle_irq_event+0x5c/0xa8
      [c0000000fffdbe10] [c0000000000bc01c] .handle_fasteoi_irq+0xe4/0x298
      [c0000000fffdbe90] [c0000000000b59c4] .generic_handle_irq+0x50/0x74
      [c0000000fffdbf10] [c0000000000075d8] .__do_irq+0x74/0x1f0
      [c0000000fffdbf90] [c0000000000189f8] .call_do_irq+0x14/0x24
      [c0000000f7173060] [c0000000000077e4] .do_IRQ+0x90/0x120
      [c0000000f7173100] [c00000000001d93c] exc_0x500_common+0xfc/0x100
      --- interrupt: 501 at .prepare_to_wait_event+0xc/0x14c
          LR = .fsl_elbc_run_command+0xc8/0x23c
      [c0000000f71734d0] [c00000000065f418] .nand_reset+0xb8/0x168
      [c0000000f7173560] [c00000000065fec4] .nand_scan_ident+0x2b0/0x1638
      [c0000000f7173650] [c000000000666cd8] .fsl_elbc_nand_probe+0x34c/0x5f0
      ata2: SATA link up 1.5 Gbps (SStatus 113 SControl 300)
      [c0000000f7173750] [c0000000005a3c60] .platform_drv_probe+0x64/0xb0
      [c0000000f71737d0] [c0000000005a12e0] .really_probe+0x290/0x334
      [c0000000f7173870] [c0000000005a14a0] .__driver_attach+0x11c/0x120
      [c0000000f7173900] [c00000000059e6a0] .bus_for_each_dev+0x98/0xfc
      [c0000000f71739a0] [c0000000005a0b3c] .driver_attach+0x34/0x4c
      [c0000000f7173a20] [c0000000005a04b0] .bus_add_driver+0x1ac/0x2e0
      [c0000000f7173ac0] [c0000000005a2170] .driver_register+0x94/0x160
      [c0000000f7173b40] [c0000000005a3be0] .__platform_driver_register+0x60/0x7c
      [c0000000f7173bc0] [c000000000d6aab4] .fsl_elbc_nand_driver_init+0x24/0x38
      [c0000000f7173c30] [c000000000001934] .do_one_initcall+0x68/0x1b8
      [c0000000f7173d00] [c000000000d210f8] .kernel_init_freeable+0x260/0x338
      [c0000000f7173db0] [c0000000000021b0] .kernel_init+0x20/0xe70
      [c0000000f7173e30] [c0000000000009bc] .ret_from_kernel_thread+0x58/0x9c
      handlers:
      [<c000000000ed85c8>] .fsl_lbc_ctrl_irq
      Disabling IRQ #25
    
    Ben also had concerns with the implementation being potentially slow on
    some PICs, so revert it for now.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ab2ed9afd3c2..5c291df30fe3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -481,11 +481,7 @@ void __do_irq(struct pt_regs *regs)
 	if (unlikely(!irq))
 		__this_cpu_inc(irq_stat.spurious_irqs);
 	else
-		do {
-			generic_handle_irq(irq);
-
-			irq = ppc_md.get_irq();
-		} while (irq);
+		generic_handle_irq(irq);
 
 	trace_irq_exit(regs);
 

commit 45cb08f4791ce6a15c54598b4cb73db4b4b8294f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Mar 16 09:55:45 2017 +0100

    powerpc: Handle simultaneous interrupts at once
    
    It often happens to have simultaneous interrupts, for instance
    when having double Ethernet attachment. With the current
    implementation, we suffer the cost of kernel entry/exit for each
    interrupt.
    
    This patch introduces a loop in __do_irq() to handle all interrupts
    at once before returning.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5c291df30fe3..ab2ed9afd3c2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -481,7 +481,11 @@ void __do_irq(struct pt_regs *regs)
 	if (unlikely(!irq))
 		__this_cpu_inc(irq_stat.spurious_irqs);
 	else
-		generic_handle_irq(irq);
+		do {
+			generic_handle_irq(irq);
+
+			irq = ppc_md.get_irq();
+		} while (irq);
 
 	trace_irq_exit(regs);
 

commit 3c19d5ada1bec8b97119215298df7669d3ffb3db
Merge: 17ed4c8f81da 08a1e650cc63
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Apr 12 22:25:02 2017 +1000

    Merge branch 'topic/xive' (early part) into next
    
    This merges the arch part of the XIVE support, leaving the final commit
    with the KVM specific pieces dangling on the branch for Paul to merge
    via the kvm-ppc tree.

commit 3ae05fb3ccb365894662d6073c851cb466dd2220
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Feb 10 12:12:44 2017 +1100

    powerpc: Remove unnecessary includes of asm/debug.h
    
    These files don't seem to have any need for asm/debug.h, now that all it
    includes are the debugger hooks and breakpoint definitions.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a018f5cae899..097f2f9ff85d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -65,7 +65,6 @@
 #include <asm/machdep.h>
 #include <asm/udbg.h>
 #include <asm/smp.h>
-#include <asm/debug.h>
 #include <asm/livepatch.h>
 #include <asm/asm-prototypes.h>
 

commit a978e13965a40ac07163643cc3fa0ddb0d354198
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:49 2017 +1000

    powerpc/smp: Remove migrate_irq() custom implementation
    
    Some powerpc platforms use this to move IRQs away from a CPU being
    unplugged. This function has several bugs such as not taking the right
    locks or failing to NULL check pointers.
    
    There's a new generic function doing exactly the same thing without all
    the bugs, so let's use it instead.
    
    mpe: The obvious place for the select of GENERIC_IRQ_MIGRATION is on
    HOTPLUG_CPU, but that doesn't work. On some configs PM_SLEEP_SMP will
    select HOTPLUG_CPU even though its dependencies are not met, which means
    the select of GENERIC_IRQ_MIGRATION doesn't happen. That leads to the
    build breaking. Fix it by moving the select of GENERIC_IRQ_MIGRATION to
    SMP.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a018f5cae899..8ee7b44450eb 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -442,46 +442,6 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	return sum;
 }
 
-#ifdef CONFIG_HOTPLUG_CPU
-void migrate_irqs(void)
-{
-	struct irq_desc *desc;
-	unsigned int irq;
-	static int warned;
-	cpumask_var_t mask;
-	const struct cpumask *map = cpu_online_mask;
-
-	alloc_cpumask_var(&mask, GFP_KERNEL);
-
-	for_each_irq_desc(irq, desc) {
-		struct irq_data *data;
-		struct irq_chip *chip;
-
-		data = irq_desc_get_irq_data(desc);
-		if (irqd_is_per_cpu(data))
-			continue;
-
-		chip = irq_data_get_irq_chip(data);
-
-		cpumask_and(mask, irq_data_get_affinity_mask(data), map);
-		if (cpumask_any(mask) >= nr_cpu_ids) {
-			pr_warn("Breaking affinity for irq %i\n", irq);
-			cpumask_copy(mask, map);
-		}
-		if (chip->irq_set_affinity)
-			chip->irq_set_affinity(data, mask, true);
-		else if (desc->action && !(warned++))
-			pr_err("Cannot set affinity for irq %i\n", irq);
-	}
-
-	free_cpumask_var(mask);
-
-	local_irq_enable();
-	mdelay(1);
-	local_irq_disable();
-}
-#endif
-
 static inline void check_stack_overflow(void)
 {
 #ifdef CONFIG_DEBUG_STACKOVERFLOW

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 3c05c311e35e..a018f5cae899 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -55,7 +55,7 @@
 #include <linux/of.h>
 #include <linux/of_irq.h>
 
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/io.h>
 #include <asm/pgtable.h>
 #include <asm/irq.h>

commit ef24ba7091517d2bbf9ba2cb4256c0dccd51d248
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Sep 6 21:53:24 2016 +1000

    powerpc: Remove all usages of NO_IRQ
    
    NO_IRQ has been == 0 on powerpc for just over ten years (since commit
    0ebfff1491ef ("[POWERPC] Add new interrupt mapping core and change
    platforms to use it")). It's also 0 on most other arches.
    
    Although it's fairly harmless, every now and then it causes confusion
    when a driver is built on powerpc and another arch which doesn't define
    NO_IRQ. There's at least 6 definitions of NO_IRQ in drivers/, at least
    some of which are to work around that problem.
    
    So we'd like to remove it. This is fairly trivial in the arch code, we
    just convert:
    
        if (irq == NO_IRQ)  to      if (!irq)
        if (irq != NO_IRQ)  to      if (irq)
        irq = NO_IRQ;       to      irq = 0;
        return NO_IRQ;      to      return 0;
    
    And a few other odd cases as well.
    
    At least for now we keep the #define NO_IRQ, because there is driver
    code that uses NO_IRQ and the fixes to remove those will go via other
    trees.
    
    Note we also change some occurrences in PPC sound drivers, drivers/ps3,
    and drivers/macintosh.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 471f65ad1b9b..3c05c311e35e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -519,7 +519,7 @@ void __do_irq(struct pt_regs *regs)
 	may_hard_irq_enable();
 
 	/* And finally process it */
-	if (unlikely(irq == NO_IRQ))
+	if (unlikely(!irq))
 		__this_cpu_inc(irq_stat.spurious_irqs);
 	else
 		generic_handle_irq(irq);

commit e0e0d6b7390b61feb06350ef4a9594bcf84ad204
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Sep 14 13:01:21 2016 +1000

    powerpc/64: Replay hypervisor maintenance interrupt first
    
    The HMI (Hypervisor Maintenance Interrupt) is defined by the
    architecture to be higher priority than other maskable interrupts, so
    replay it first, as a best-effort to replay according to hardware
    priorities.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9594ac8e7090..471f65ad1b9b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -156,6 +156,15 @@ notrace unsigned int __check_irq_replay(void)
 		lv1_get_version_info(&tmp, &tmp2);
 	}
 
+	/*
+	 * Check if an hypervisor Maintenance interrupt happened.
+	 * This is a higher priority interrupt than the others, so
+	 * replay it first.
+	 */
+	local_paca->irq_happened &= ~PACA_IRQ_HMI;
+	if (happened & PACA_IRQ_HMI)
+		return 0xe60;
+
 	/*
 	 * We may have missed a decrementer interrupt. We check the
 	 * decrementer itself rather than the paca irq_happened field
@@ -191,11 +200,6 @@ notrace unsigned int __check_irq_replay(void)
 	}
 #endif /* CONFIG_PPC_BOOK3E */
 
-	/* Check if an hypervisor Maintenance interrupt happened */
-	local_paca->irq_happened &= ~PACA_IRQ_HMI;
-	if (happened & PACA_IRQ_HMI)
-		return 0xe60;
-
 	/* There should be nothing left ! */
 	BUG_ON(local_paca->irq_happened != 0);
 

commit 0545d5436aefddff7ca417adc1a431c108403a35
Author: Daniel Axtens <dja@axtens.net>
Date:   Tue Sep 6 15:32:43 2016 +1000

    powerpc/sparse: Add more assembler prototypes
    
    Another set of things that are only called from assembler and so need
    prototypes to keep sparse happy.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 08887cf2b20e..9594ac8e7090 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -67,6 +67,7 @@
 #include <asm/smp.h>
 #include <asm/debug.h>
 #include <asm/livepatch.h>
+#include <asm/asm-prototypes.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>

commit b92a226e528423b8d249dd09bb450d53361fbfcb
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sat Jul 23 14:42:40 2016 +0530

    powerpc: Move cpu_has_feature() to a separate file
    
    We plan to use jump label for cpu_has_feature(). In order to implement
    this we need to include the linux/jump_label.h in asm/cputable.h.
    
    Unfortunately if we do that it leads to an include loop. The root of the
    problem seems to be that reg.h needs cputable.h (for CPU_FTRs), and then
    cputable.h via jump_label.h eventually pulls in hw_irq.h which needs
    reg.h (for MSR_EE).
    
    So move cpu_has_feature() to a separate file on its own.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    [mpe: Rename to cpu_has_feature.h and flesh out change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ac910d9982df..08887cf2b20e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -75,6 +75,7 @@
 #endif
 #define CREATE_TRACE_POINTS
 #include <asm/trace.h>
+#include <asm/cpu_has_feature.h>
 
 DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 EXPORT_PER_CPU_SYMBOL(irq_stat);

commit 1d607bb3bd60f404d1ceb0d6ebceadf261068422
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 8 16:37:07 2016 +1000

    powerpc/irq: Add mechanism to force a replay of interrupts
    
    Calling this function with interrupts soft-disabled will cause
    a replay of the external interrupt vector when they are re-enabled.
    
    This will be used by the OPAL XICS backend (and latter by the native
    XIVE code) to handle EOI signaling that there are more interrupts to
    fetch from the hardware since the hardware won't issue another HW
    interrupt in that case.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 58217aec30ea..ac910d9982df 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -342,6 +342,21 @@ bool prep_irq_for_idle(void)
 	return true;
 }
 
+/*
+ * Force a replay of the external interrupt handler on this CPU.
+ */
+void force_external_irq_replay(void)
+{
+	/*
+	 * This must only be called with interrupts soft-disabled,
+	 * the replay will happen when re-enabling.
+	 */
+	WARN_ON(!arch_irqs_disabled());
+
+	/* Indicate in the PACA that we have an interrupt to replay */
+	local_paca->irq_happened |= PACA_IRQ_EE;
+}
+
 #endif /* CONFIG_PPC64 */
 
 int arch_show_interrupts(struct seq_file *p, int prec)

commit fa2cff3f54cfec5c0b83afdb4f79975f5447a0b4
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Tue Jul 5 16:12:34 2016 +1000

    powerpc: Fix typo in comment reference to CONFIG_TRACE_IRQFLAGS
    
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 3cb46a3b1de7..58217aec30ea 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -250,7 +250,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 		if (WARN_ON(mfmsr() & MSR_EE))
 			__hard_irq_disable();
 	}
-#endif /* CONFIG_TRACE_IRQFLAG */
+#endif /* CONFIG_TRACE_IRQFLAGS */
 
 	set_soft_enabled(0);
 

commit 5d31a96e6c0187f2c5d7004e005fd094a1277e9e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 24 22:04:04 2016 +1100

    powerpc/livepatch: Add livepatch stack to struct thread_info
    
    In order to support live patching we need to maintain an alternate
    stack of TOC & LR values. We use the base of the stack for this, and
    store the "live patch stack pointer" in struct thread_info.
    
    Unlike the other fields of thread_info, we can not statically initialise
    that value, so it must be done at run time.
    
    This patch just adds the code to support that, it is not enabled until
    the next patch which actually adds live patch support.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Acked-by: Balbir Singh <bsingharora@gmail.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 290559df1e8b..3cb46a3b1de7 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -66,6 +66,7 @@
 #include <asm/udbg.h>
 #include <asm/smp.h>
 #include <asm/debug.h>
+#include <asm/livepatch.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
@@ -607,10 +608,12 @@ void irq_ctx_init(void)
 		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
 		tp = softirq_ctx[i];
 		tp->cpu = i;
+		klp_init_thread_info(tp);
 
 		memset((void *)hardirq_ctx[i], 0, THREAD_SIZE);
 		tp = hardirq_ctx[i];
 		tp->cpu = i;
+		klp_init_thread_info(tp);
 	}
 }
 

commit da92b4eb7e2ec9866f14a0c8f453788e8052dee7
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jun 1 16:05:33 2015 +0800

    powerpc, irq: Use access helper irq_data_get_affinity_mask()
    
    Use access helper irq_data_get_affinity_mask() so we can move the
    affinity mask to irq_common_data.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/1433145945-789-25-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 45096033d37b..290559df1e8b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -441,7 +441,7 @@ void migrate_irqs(void)
 
 		chip = irq_data_get_irq_chip(data);
 
-		cpumask_and(mask, data->affinity, map);
+		cpumask_and(mask, irq_data_get_affinity_mask(data), map);
 		if (cpumask_any(mask) >= nr_cpu_ids) {
 			pr_warn("Breaking affinity for irq %i\n", irq);
 			cpumask_copy(mask, map);

commit 68cf0d642f62267b960f947370539ff3582c4935
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Sep 17 22:15:35 2014 +1000

    powerpc: Remove superfluous bootmem includes
    
    Lots of places included bootmem.h even when not using bootmem.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Tested-by: Emil Medve <Emilian.Medve@Freescale.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8d87bb162ecd..45096033d37b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -50,7 +50,6 @@
 #include <linux/list.h>
 #include <linux/radix-tree.h>
 #include <linux/mutex.h>
-#include <linux/bootmem.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
 #include <linux/of.h>

commit 69111bac42f5ceacdd22e30947837ceb2c4493ed
Author: Christoph Lameter <cl@linux.com>
Date:   Tue Oct 21 15:23:25 2014 -0500

    powerpc: Replace __get_cpu_var uses
    
    This still has not been merged and now powerpc is the only arch that does
    not have this change. Sorry about missing linuxppc-dev before.
    
    V2->V2
      - Fix up to work against 3.18-rc1
    
    __get_cpu_var() is used for multiple purposes in the kernel source. One of
    them is address calculation via the form &__get_cpu_var(x).  This calculates
    the address for the instance of the percpu variable of the current processor
    based on an offset.
    
    Other use cases are for storing and retrieving data from the current
    processors percpu area.  __get_cpu_var() can be used as an lvalue when
    writing data or on the right side of an assignment.
    
    __get_cpu_var() is defined as :
    
    __get_cpu_var() always only does an address determination. However, store
    and retrieve operations could use a segment prefix (or global register on
    other platforms) to avoid the address calculation.
    
    this_cpu_write() and this_cpu_read() can directly take an offset into a
    percpu area and use optimized assembly code to read and write per cpu
    variables.
    
    This patch converts __get_cpu_var into either an explicit address
    calculation using this_cpu_ptr() or into a use of this_cpu operations that
    use the offset.  Thereby address calculations are avoided and less registers
    are used when code is generated.
    
    At the end of the patch set all uses of __get_cpu_var have been removed so
    the macro is removed too.
    
    The patch set includes passes over all arches as well. Once these operations
    are used throughout then specialized macros can be defined in non -x86
    arches as well in order to optimize per cpu access by f.e.  using a global
    register that may be set to the per cpu base.
    
    Transformations done to __get_cpu_var()
    
    1. Determine the address of the percpu instance of the current processor.
    
            DEFINE_PER_CPU(int, y);
            int *x = &__get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(&y);
    
    2. Same as #1 but this time an array structure is involved.
    
            DEFINE_PER_CPU(int, y[20]);
            int *x = __get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(y);
    
    3. Retrieve the content of the current processors instance of a per cpu
    variable.
    
            DEFINE_PER_CPU(int, y);
            int x = __get_cpu_var(y)
    
       Converts to
    
            int x = __this_cpu_read(y);
    
    4. Retrieve the content of a percpu struct
    
            DEFINE_PER_CPU(struct mystruct, y);
            struct mystruct x = __get_cpu_var(y);
    
       Converts to
    
            memcpy(&x, this_cpu_ptr(&y), sizeof(x));
    
    5. Assignment to a per cpu variable
    
            DEFINE_PER_CPU(int, y)
            __get_cpu_var(y) = x;
    
       Converts to
    
            __this_cpu_write(y, x);
    
    6. Increment/Decrement etc of a per cpu variable
    
            DEFINE_PER_CPU(int, y);
            __get_cpu_var(y)++
    
       Converts to
    
            __this_cpu_inc(y)
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    [mpe: Fix build errors caused by set/or_softirq_pending(), and rework
          assignment in __set_breakpoint() to use memcpy().]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c14383575fe8..8d87bb162ecd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -114,7 +114,7 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 static inline notrace int decrementer_check_overflow(void)
 {
  	u64 now = get_tb_or_rtc();
- 	u64 *next_tb = &__get_cpu_var(decrementers_next_tb);
+	u64 *next_tb = this_cpu_ptr(&decrementers_next_tb);
  
 	return now >= *next_tb;
 }
@@ -499,7 +499,7 @@ void __do_irq(struct pt_regs *regs)
 
 	/* And finally process it */
 	if (unlikely(irq == NO_IRQ))
-		__get_cpu_var(irq_stat).spurious_irqs++;
+		__this_cpu_inc(irq_stat.spurious_irqs);
 	else
 		generic_handle_irq(irq);
 

commit acf620ecf56cfc4edaffaf158250e128539cdd26
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Oct 13 19:41:39 2014 +1100

    powerpc: Rename __get_SP() to current_stack_pointer()
    
    Michael points out that __get_SP() is a pretty horrible
    function name. Let's give it a better name.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8eb857f216c1..c14383575fe8 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -466,7 +466,7 @@ static inline void check_stack_overflow(void)
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
 
-	sp = __get_SP() & (THREAD_SIZE-1);
+	sp = current_stack_pointer() & (THREAD_SIZE-1);
 
 	/* check for stack overflow: is there less than 2KB free? */
 	if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {

commit a7696b36c01316308f2b9f2009ce38cb01fd7a3f
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Sep 17 14:39:39 2014 +1000

    powerpc: Add printk levels to powerpc code
    
    Add printk levels to some places in the powerpc port.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4c5891de162e..8eb857f216c1 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -444,13 +444,13 @@ void migrate_irqs(void)
 
 		cpumask_and(mask, data->affinity, map);
 		if (cpumask_any(mask) >= nr_cpu_ids) {
-			printk("Breaking affinity for irq %i\n", irq);
+			pr_warn("Breaking affinity for irq %i\n", irq);
 			cpumask_copy(mask, map);
 		}
 		if (chip->irq_set_affinity)
 			chip->irq_set_affinity(data, mask, true);
 		else if (desc->action && !(warned++))
-			printk("Cannot set affinity for irq %i\n", irq);
+			pr_err("Cannot set affinity for irq %i\n", irq);
 	}
 
 	free_cpumask_var(mask);
@@ -470,7 +470,7 @@ static inline void check_stack_overflow(void)
 
 	/* check for stack overflow: is there less than 2KB free? */
 	if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
-		printk("do_IRQ: stack overflow: %ld\n",
+		pr_err("do_IRQ: stack overflow: %ld\n",
 			sp - sizeof(struct thread_info));
 		dump_stack();
 	}

commit 0869b6fd209bda402576a9a559120ddd4f61198e
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Tue Jul 29 18:40:01 2014 +0530

    powerpc/book3s: Add basic infrastructure to handle HMI in Linux.
    
    Handle Hypervisor Maintenance Interrupt (HMI) in Linux. This patch implements
    basic infrastructure to handle HMI in Linux host. The design is to invoke
    opal handle hmi in real mode for recovery and set irq_pending when we hit HMI.
    During check_irq_replay pull opal hmi event and print hmi info on console.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 248ee7e5bebd..4c5891de162e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -189,6 +189,11 @@ notrace unsigned int __check_irq_replay(void)
 	}
 #endif /* CONFIG_PPC_BOOK3E */
 
+	/* Check if an hypervisor Maintenance interrupt happened */
+	local_paca->irq_happened &= ~PACA_IRQ_HMI;
+	if (happened & PACA_IRQ_HMI)
+		return 0xe60;
+
 	/* There should be nothing left ! */
 	BUG_ON(local_paca->irq_happened != 0);
 
@@ -377,6 +382,14 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).mce_exceptions);
 	seq_printf(p, "  Machine check exceptions\n");
 
+	if (cpu_has_feature(CPU_FTR_HVMODE)) {
+		seq_printf(p, "%*s: ", prec, "HMI");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ",
+					per_cpu(irq_stat, j).hmi_exceptions);
+		seq_printf(p, "  Hypervisor Maintenance Interrupts\n");
+	}
+
 #ifdef CONFIG_PPC_DOORBELL
 	if (cpu_has_feature(CPU_FTR_DBELL)) {
 		seq_printf(p, "%*s: ", prec, "DBL");
@@ -400,6 +413,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += per_cpu(irq_stat, cpu).mce_exceptions;
 	sum += per_cpu(irq_stat, cpu).spurious_irqs;
 	sum += per_cpu(irq_stat, cpu).timer_irqs_others;
+	sum += per_cpu(irq_stat, cpu).hmi_exceptions;
 #ifdef CONFIG_PPC_DOORBELL
 	sum += per_cpu(irq_stat, cpu).doorbell_irqs;
 #endif

commit 0d2b7ea9287d39e87531d233ba885263e6160127
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Fri Jun 6 14:38:33 2014 -0700

    powerpc: update comments for generic idle conversion
    
    As of commit 799fef06123f ("powerpc: Use generic idle loop"), this
    applies to arch_cpu_idle() instead of cpu_idle().
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ca1cd7459c4a..248ee7e5bebd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -304,7 +304,7 @@ void notrace restore_interrupts(void)
  * being re-enabled and generally sanitized the lazy irq state,
  * and in the latter case it will leave with interrupts hard
  * disabled and marked as such, so the local_irq_enable() call
- * in cpu_idle() will properly re-enable everything.
+ * in arch_cpu_idle() will properly re-enable everything.
  */
 bool prep_irq_for_idle(void)
 {

commit a4e04c9f219d2c00764ffa7ba45500411815879d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 23 21:40:08 2014 +0000

    powerpc: Irq: Use generic_handle_irq
    
    No functional change
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: ppc <linuxppc-dev@lists.ozlabs.org>
    Link: http://lkml.kernel.org/r/20140223212736.333718121@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1d0848bba049..ca1cd7459c4a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -465,7 +465,6 @@ static inline void check_stack_overflow(void)
 
 void __do_irq(struct pt_regs *regs)
 {
-	struct irq_desc *desc;
 	unsigned int irq;
 
 	irq_enter();
@@ -487,11 +486,8 @@ void __do_irq(struct pt_regs *regs)
 	/* And finally process it */
 	if (unlikely(irq == NO_IRQ))
 		__get_cpu_var(irq_stat).spurious_irqs++;
-	else {
-		desc = irq_to_desc(irq);
-		if (likely(desc))
-			desc->handle_irq(irq, desc);
-	}
+	else
+		generic_handle_irq(irq);
 
 	trace_irq_exit(regs);
 

commit 04a341138da55daf47551308660a5fcc6b5b9077
Author: Kevin Hao <haokexin@gmail.com>
Date:   Wed Jan 29 18:24:54 2014 +0800

    powerpc/ppc32: Fix the bug in the init of non-base exception stack for UP
    
    We would allocate one specific exception stack for each kind of
    non-base exceptions for every CPU. For ppc32 the CPU hard ID is
    used as the subscript to get the specific exception stack for
    one CPU. But for an UP kernel, there is only one element in the
    each kind of exception stack array. We would get stuck if the
    CPU hard ID is not equal to '0'. So in this case we should use the
    subscript '0' no matter what the CPU hard ID is.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9729b23bfb0a..1d0848bba049 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -559,8 +559,13 @@ void exc_lvl_ctx_init(void)
 #ifdef CONFIG_PPC64
 		cpu_nr = i;
 #else
+#ifdef CONFIG_SMP
 		cpu_nr = get_hard_smp_processor_id(i);
+#else
+		cpu_nr = 0;
 #endif
+#endif
+
 		memset((void *)critirq_ctx[cpu_nr], 0, THREAD_SIZE);
 		tp = critirq_ctx[cpu_nr];
 		tp->cpu = cpu_nr;

commit c041cfa2af1ccb8d0346dc576144a1085e9b4d4b
Author: fan.du <fan.du@windriver.com>
Date:   Wed Jan 23 16:06:11 2013 +0800

    powerpc: Make irq_stat.timers_irqs counting more specific
    
    Current irq_stat.timers_irqs counting doesn't discriminate timer event handler
    and other timer interrupt(like arch_irq_work_raise). Sometimes we need to know
    exactly how much interrupts timer event handler fired, so let's be more specific
    on this.
    
    Signed-off-by: Fan Du <fan.du@windriver.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ba0165615215..9729b23bfb0a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -354,8 +354,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 
 	seq_printf(p, "%*s: ", prec, "LOC");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs);
-        seq_printf(p, "  Local timer interrupts\n");
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs_event);
+        seq_printf(p, "  Local timer interrupts for timer event device\n");
+
+	seq_printf(p, "%*s: ", prec, "LOC");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs_others);
+        seq_printf(p, "  Local timer interrupts for others\n");
 
 	seq_printf(p, "%*s: ", prec, "SPU");
 	for_each_online_cpu(j)
@@ -389,11 +394,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
  */
 u64 arch_irq_stat_cpu(unsigned int cpu)
 {
-	u64 sum = per_cpu(irq_stat, cpu).timer_irqs;
+	u64 sum = per_cpu(irq_stat, cpu).timer_irqs_event;
 
 	sum += per_cpu(irq_stat, cpu).pmu_irqs;
 	sum += per_cpu(irq_stat, cpu).mce_exceptions;
 	sum += per_cpu(irq_stat, cpu).spurious_irqs;
+	sum += per_cpu(irq_stat, cpu).timer_irqs_others;
 #ifdef CONFIG_PPC_DOORBELL
 	sum += per_cpu(irq_stat, cpu).doorbell_irqs;
 #endif

commit 1006fae359cc810c16354805c0cffbb6ffee602e
Merge: 70fdcb83db15 5702941eec32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 10:02:59 2013 +0900

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull IRQ changes from Ingo Molnar:
     "The biggest change this cycle are the softirq/hardirq stack
      interaction and nesting fixes, cleanups and reorganizations from
      Frederic.  This is the longer followup story to the softirq nesting
      fix that is already upstream (commit ded797547548: "irq: Force hardirq
      exit's softirq processing on its own stack")"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      irqchip: bcm2835: Convert to use IRQCHIP_DECLARE macro
      powerpc: Tell about irq stack coverage
      x86: Tell about irq stack coverage
      irq: Optimize softirq stack selection in irq exit
      irq: Justify the various softirq stack choices
      irq: Improve a bit softirq debugging
      irq: Optimize call to softirq on hardirq exit
      irq: Consolidate do_softirq() arch overriden implementations
      x86/irq: Correct comment about i8259 initialization

commit 8b5ede69d24db939f52b47effff2f6fe1e83e08b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Oct 8 08:08:24 2013 +1100

    powerpc/irq: Don't switch to irq stack from softirq stack
    
    irq_exit() is now called on the irq stack, which can trigger a switch to
    the softirq stack from the irq stack.  If an interrupt happens at that
    point, we will not properly detect the re-entrancy and clobber the
    original return context on the irq stack.
    
    This fixes it.  The side effect is to prevent all nesting from softirq
    stack to irq stack even in the "safe" case but it's simpler that way and
    matches what x86_64 does.
    
    Reported-by: CÃ©dric Le Goater <clg@fr.ibm.com>
    Tested-by: CÃ©dric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 57d286a78f86..c7cb8c232d2f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -495,14 +495,15 @@ void __do_irq(struct pt_regs *regs)
 void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-	struct thread_info *curtp, *irqtp;
+	struct thread_info *curtp, *irqtp, *sirqtp;
 
 	/* Switch to the irq stack to handle this */
 	curtp = current_thread_info();
 	irqtp = hardirq_ctx[raw_smp_processor_id()];
+	sirqtp = softirq_ctx[raw_smp_processor_id()];
 
 	/* Already there ? */
-	if (unlikely(curtp == irqtp)) {
+	if (unlikely(curtp == irqtp || curtp == sirqtp)) {
 		__do_irq(regs);
 		set_irq_regs(old_regs);
 		return;

commit 7d65f4a6553203da6a22097821d151fbbe7e4956
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Sep 5 15:49:45 2013 +0200

    irq: Consolidate do_softirq() arch overriden implementations
    
    All arch overriden implementations of do_softirq() share the following
    common code: disable irqs (to avoid races with the pending check),
    check if there are softirqs pending, then execute __do_softirq() on
    a specific stack.
    
    Consolidate the common parts such that archs only worry about the
    stack switch.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@au1.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Mackerras <paulus@au1.ibm.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Andrew Morton <akpm@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 57d286a78f86..5c4adfc6a6d0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -593,7 +593,7 @@ void irq_ctx_init(void)
 	}
 }
 
-static inline void do_softirq_onstack(void)
+void do_softirq_own_stack(void)
 {
 	struct thread_info *curtp, *irqtp;
 
@@ -611,21 +611,6 @@ static inline void do_softirq_onstack(void)
 		set_bits(irqtp->flags, &curtp->flags);
 }
 
-void do_softirq(void)
-{
-	unsigned long flags;
-
-	if (in_interrupt())
-		return;
-
-	local_irq_save(flags);
-
-	if (local_softirq_pending())
-		do_softirq_onstack();
-
-	local_irq_restore(flags);
-}
-
 irq_hw_number_t virq_to_hw(unsigned int virq)
 {
 	struct irq_data *irq_data = irq_get_irq_data(virq);

commit cbc9565ee82694dec31d8137dec975b83175183b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Sep 24 15:17:21 2013 +1000

    powerpc: Remove ksp_limit on ppc64
    
    We've been keeping that field in thread_struct for a while, it contains
    the "limit" of the current stack pointer and is meant to be used for
    detecting stack overflows.
    
    It has a few problems however:
    
     - First, it was never actually *used* on 64-bit. Set and updated but
    not actually exploited
    
     - When switching stack to/from irq and softirq stacks, it's update
    is racy unless we hard disable interrupts, which is costly. This
    is fine on 32-bit as we don't soft-disable there but not on 64-bit.
    
    Thus rather than fixing 2 in order to implement 1 in some hypothetical
    future, let's remove the code completely from 64-bit. In order to avoid
    a clutter of ifdef's, we remove the updates from C code completely
    during interrupt stack switching, and instead maintain it from the
    asm helper that is used to do the stack switching in the first place.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2234a1276a77..57d286a78f86 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -496,7 +496,6 @@ void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct thread_info *curtp, *irqtp;
-	unsigned long saved_sp_limit;
 
 	/* Switch to the irq stack to handle this */
 	curtp = current_thread_info();
@@ -509,12 +508,6 @@ void do_IRQ(struct pt_regs *regs)
 		return;
 	}
 
-	/* Adjust the stack limit */
-	saved_sp_limit = current->thread.ksp_limit;
-	current->thread.ksp_limit = (unsigned long)irqtp +
-		_ALIGN_UP(sizeof(struct thread_info), 16);
-
-
 	/* Prepare the thread_info in the irq stack */
 	irqtp->task = curtp->task;
 	irqtp->flags = 0;
@@ -526,7 +519,6 @@ void do_IRQ(struct pt_regs *regs)
 	call_do_irq(regs, irqtp);
 
 	/* Restore stack limit */
-	current->thread.ksp_limit = saved_sp_limit;
 	irqtp->task = NULL;
 
 	/* Copy back updates to the thread_info */
@@ -604,16 +596,12 @@ void irq_ctx_init(void)
 static inline void do_softirq_onstack(void)
 {
 	struct thread_info *curtp, *irqtp;
-	unsigned long saved_sp_limit = current->thread.ksp_limit;
 
 	curtp = current_thread_info();
 	irqtp = softirq_ctx[smp_processor_id()];
 	irqtp->task = curtp->task;
 	irqtp->flags = 0;
-	current->thread.ksp_limit = (unsigned long)irqtp +
-				    _ALIGN_UP(sizeof(struct thread_info), 16);
 	call_do_softirq(irqtp);
-	current->thread.ksp_limit = saved_sp_limit;
 	irqtp->task = NULL;
 
 	/* Set any flag that may have been set on the

commit 0366a1c70b89efed4f9d590216bb004a16effbed
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Sep 23 14:29:11 2013 +1000

    powerpc/irq: Run softirqs off the top of the irq stack
    
    Nowadays, irq_exit() calls __do_softirq() pretty much directly
    instead of calling do_softirq() which switches to the decicated
    softirq stack.
    
    This has lead to observed stack overflows on powerpc since we call
    irq_enter() and irq_exit() outside of the scope that switches to
    the irq stack.
    
    This fixes it by moving the stack switching up a level, making
    irq_enter() and irq_exit() run off the irq stack.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c69440cef7af..2234a1276a77 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -441,50 +441,6 @@ void migrate_irqs(void)
 }
 #endif
 
-static inline void handle_one_irq(unsigned int irq)
-{
-	struct thread_info *curtp, *irqtp;
-	unsigned long saved_sp_limit;
-	struct irq_desc *desc;
-
-	desc = irq_to_desc(irq);
-	if (!desc)
-		return;
-
-	/* Switch to the irq stack to handle this */
-	curtp = current_thread_info();
-	irqtp = hardirq_ctx[smp_processor_id()];
-
-	if (curtp == irqtp) {
-		/* We're already on the irq stack, just handle it */
-		desc->handle_irq(irq, desc);
-		return;
-	}
-
-	saved_sp_limit = current->thread.ksp_limit;
-
-	irqtp->task = curtp->task;
-	irqtp->flags = 0;
-
-	/* Copy the softirq bits in preempt_count so that the
-	 * softirq checks work in the hardirq context. */
-	irqtp->preempt_count = (irqtp->preempt_count & ~SOFTIRQ_MASK) |
-			       (curtp->preempt_count & SOFTIRQ_MASK);
-
-	current->thread.ksp_limit = (unsigned long)irqtp +
-		_ALIGN_UP(sizeof(struct thread_info), 16);
-
-	call_handle_irq(irq, desc, irqtp, desc->handle_irq);
-	current->thread.ksp_limit = saved_sp_limit;
-	irqtp->task = NULL;
-
-	/* Set any flag that may have been set on the
-	 * alternate stack
-	 */
-	if (irqtp->flags)
-		set_bits(irqtp->flags, &curtp->flags);
-}
-
 static inline void check_stack_overflow(void)
 {
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
@@ -501,9 +457,9 @@ static inline void check_stack_overflow(void)
 #endif
 }
 
-void do_IRQ(struct pt_regs *regs)
+void __do_irq(struct pt_regs *regs)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
+	struct irq_desc *desc;
 	unsigned int irq;
 
 	irq_enter();
@@ -519,18 +475,64 @@ void do_IRQ(struct pt_regs *regs)
 	 */
 	irq = ppc_md.get_irq();
 
-	/* We can hard enable interrupts now */
+	/* We can hard enable interrupts now to allow perf interrupts */
 	may_hard_irq_enable();
 
 	/* And finally process it */
-	if (irq != NO_IRQ)
-		handle_one_irq(irq);
-	else
+	if (unlikely(irq == NO_IRQ))
 		__get_cpu_var(irq_stat).spurious_irqs++;
+	else {
+		desc = irq_to_desc(irq);
+		if (likely(desc))
+			desc->handle_irq(irq, desc);
+	}
 
 	trace_irq_exit(regs);
 
 	irq_exit();
+}
+
+void do_IRQ(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+	struct thread_info *curtp, *irqtp;
+	unsigned long saved_sp_limit;
+
+	/* Switch to the irq stack to handle this */
+	curtp = current_thread_info();
+	irqtp = hardirq_ctx[raw_smp_processor_id()];
+
+	/* Already there ? */
+	if (unlikely(curtp == irqtp)) {
+		__do_irq(regs);
+		set_irq_regs(old_regs);
+		return;
+	}
+
+	/* Adjust the stack limit */
+	saved_sp_limit = current->thread.ksp_limit;
+	current->thread.ksp_limit = (unsigned long)irqtp +
+		_ALIGN_UP(sizeof(struct thread_info), 16);
+
+
+	/* Prepare the thread_info in the irq stack */
+	irqtp->task = curtp->task;
+	irqtp->flags = 0;
+
+	/* Copy the preempt_count so that the [soft]irq checks work. */
+	irqtp->preempt_count = curtp->preempt_count;
+
+	/* Switch stack and call */
+	call_do_irq(regs, irqtp);
+
+	/* Restore stack limit */
+	current->thread.ksp_limit = saved_sp_limit;
+	irqtp->task = NULL;
+
+	/* Copy back updates to the thread_info */
+	if (irqtp->flags)
+		set_bits(irqtp->flags, &curtp->flags);
+
 	set_irq_regs(old_regs);
 }
 
@@ -592,12 +594,10 @@ void irq_ctx_init(void)
 		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
 		tp = softirq_ctx[i];
 		tp->cpu = i;
-		tp->preempt_count = 0;
 
 		memset((void *)hardirq_ctx[i], 0, THREAD_SIZE);
 		tp = hardirq_ctx[i];
 		tp->cpu = i;
-		tp->preempt_count = HARDIRQ_OFFSET;
 	}
 }
 

commit e8e813ed268d90c1377f53460527c419eb52c67a
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Jun 4 14:21:17 2013 +1000

    powerpc: Rename PMU interrupts from CNT to PMI
    
    Back in commit 89713ed "Add timer, performance monitor and machine check
    counts to /proc/interrupts" we added a count of PMU interrupts to the
    output of /proc/interrupts.
    
    At the time we named them "CNT" to match x86.
    
    However in commit 89ccf46 "Rename 'performance counter interrupt'", the
    x86 guys renamed theirs from "CNT" to "PMI".
    
    Arguably changing the name could break someone's script, but I think the
    chance of that is minimal, and it's preferable to have a name that 1) is
    somewhat meaningful, and 2) matches x86.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2e51cde616d2..c69440cef7af 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -362,7 +362,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).spurious_irqs);
 	seq_printf(p, "  Spurious interrupts\n");
 
-	seq_printf(p, "%*s: ", prec, "CNT");
+	seq_printf(p, "%*s: ", prec, "PMI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).pmu_irqs);
 	seq_printf(p, "  Performance monitoring interrupts\n");

commit 24a72acac155576d630cf4304fa9cefb9b62ea1f
Merge: 6e0b8bc965d2 8bb495e3f024
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 1 17:57:25 2013 +1000

    Merge tag 'v3.10' into next
    
    Merge 3.10 in order to get some of the last minute powerpc
    changes, resolve conflicts and add additional fixes on top
    of them.

commit 3139b0a797d6826519ed98a13623a92f12269613
Author: Kevin Hao <haokexin@gmail.com>
Date:   Wed Apr 17 17:50:35 2013 +0800

    powerpc: Remove the unneeded trigger of decrementer interrupt in decrementer_check_overflow
    
    Previously in order to handle the edge sensitive decrementers,
    we choose to set the decrementer to 1 to trigger a decrementer
    interrupt when re-enabling interrupts. But with the rework of the
    lazy EE, we would replay the decrementer interrupt when re-enabling
    interrupts if a decrementer interrupt occurs with irq soft-disabled.
    So there is no need to trigger a decrementer interrupt in this case
    any more.
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5cbcf4d5a808..32fa52e8163f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -116,8 +116,6 @@ static inline notrace int decrementer_check_overflow(void)
  	u64 now = get_tb_or_rtc();
  	u64 *next_tb = &__get_cpu_var(decrementers_next_tb);
  
-	if (now >= *next_tb)
-		set_dec(1);
 	return now >= *next_tb;
 }
 

commit 230b3034793247f61e6a0b08c44cf415f6d92981
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Sat Jun 15 12:13:40 2013 +1000

    powerpc: Fix missing/delayed calls to irq_work
    
    When replaying interrupts (as a result of the interrupt occurring
    while soft-disabled), in the case of the decrementer, we are exclusively
    testing for a pending timer target. However we also use decrementer
    interrupts to trigger the new "irq_work", which in this case would
    be missed.
    
    This change the logic to force a replay in both cases of a timer
    boundary reached and a decrementer interrupt having actually occurred
    while disabled. The former test is still useful to catch cases where
    a CPU having been hard-disabled for a long time completely misses the
    interrupt due to a decrementer rollover.
    
    CC: <stable@vger.kernel.org> [v3.4+]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Tested-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5cbcf4d5a808..ea185e0b3cae 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -162,7 +162,7 @@ notrace unsigned int __check_irq_replay(void)
 	 * in case we also had a rollover while hard disabled
 	 */
 	local_paca->irq_happened &= ~PACA_IRQ_DEC;
-	if (decrementer_check_overflow())
+	if ((happened & PACA_IRQ_DEC) || decrementer_check_overflow())
 		return 0x900;
 
 	/* Finally check if an external interrupt happened */

commit a6a058e52a0ce62de84496c9d4b133f2afc61f27
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Mar 21 19:22:52 2013 +0000

    powerpc: Add accounting for Doorbell interrupts
    
    This patch adds a new line to /proc/interrupts to account for the
    doorbell interrupts that each hardware thread has received. The total
    interrupt count in /proc/stat will now also include doorbells.
    
     # cat /proc/interrupts
               CPU0       CPU1       CPU2       CPU3
     16:        551       1267        281        175      XICS Level     IPI
    LOC:       2037       1503       1688       1625   Local timer interrupts
    SPU:          0          0          0          0   Spurious interrupts
    CNT:          0          0          0          0   Performance monitoring interrupts
    MCE:          0          0          0          0   Machine check exceptions
    DBL:         42        550         20         91   Doorbell interrupts
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4f97fe345526..5cbcf4d5a808 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -374,6 +374,15 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).mce_exceptions);
 	seq_printf(p, "  Machine check exceptions\n");
 
+#ifdef CONFIG_PPC_DOORBELL
+	if (cpu_has_feature(CPU_FTR_DBELL)) {
+		seq_printf(p, "%*s: ", prec, "DBL");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", per_cpu(irq_stat, j).doorbell_irqs);
+		seq_printf(p, "  Doorbell interrupts\n");
+	}
+#endif
+
 	return 0;
 }
 
@@ -387,6 +396,9 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += per_cpu(irq_stat, cpu).pmu_irqs;
 	sum += per_cpu(irq_stat, cpu).mce_exceptions;
 	sum += per_cpu(irq_stat, cpu).spurious_irqs;
+#ifdef CONFIG_PPC_DOORBELL
+	sum += per_cpu(irq_stat, cpu).doorbell_irqs;
+#endif
 
 	return sum;
 }

commit fe9e1d54e3ea2e5134d7aaa233441f9229326ef6
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Nov 14 18:49:48 2012 +0000

    powerpc: Add code to handle soft-disabled doorbells on server
    
    This patch adds the logic to properly handle doorbells that come in when
    interrupts have been soft disabled and to replay them when interrupts
    are re-enabled:
    
    - masked_##_H##interrupt is modified to leave interrupts enabled when a
      doorbell has come in since doorbells are edge sensitive and as such
      won't be automatically re-raised.
    
    - __check_irq_replay now tests if a doorbell happened on book3s, and
      returns either 0xe80 or 0xa00 depending on whether we are the
      hypervisor or not.
    
    - restore_check_irq_replay now tests for the two possible server
      doorbell vector numbers to replay.
    
    - __replay_interrupt also adds tests for the two server doorbell vector
      numbers, and is modified to use a compare instruction rather than an
      andi. on the single bit difference between 0x500 and 0x900.
    
    The last two use a CPU feature section to avoid needlessly testing
    against the hypervisor vector if it is not the hypervisor, and vice
    versa.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 71413f41278f..4f97fe345526 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -122,8 +122,8 @@ static inline notrace int decrementer_check_overflow(void)
 }
 
 /* This is called whenever we are re-enabling interrupts
- * and returns either 0 (nothing to do) or 500/900 if there's
- * either an EE or a DEC to generate.
+ * and returns either 0 (nothing to do) or 500/900/280/a00/e80 if
+ * there's an EE, DEC or DBELL to generate.
  *
  * This is called in two contexts: From arch_local_irq_restore()
  * before soft-enabling interrupts, and from the exception exit
@@ -182,6 +182,13 @@ notrace unsigned int __check_irq_replay(void)
 	local_paca->irq_happened &= ~PACA_IRQ_DBELL;
 	if (happened & PACA_IRQ_DBELL)
 		return 0x280;
+#else
+	local_paca->irq_happened &= ~PACA_IRQ_DBELL;
+	if (happened & PACA_IRQ_DBELL) {
+		if (cpu_has_feature(CPU_FTR_HVMODE))
+			return 0xe80;
+		return 0xa00;
+	}
 #endif /* CONFIG_PPC_BOOK3E */
 
 	/* There should be nothing left ! */

commit e72bbbab278a2e6d506bd2cf380ba9bef68e8ec1
Author: Li Zhong <zhong@linux.vnet.ibm.com>
Date:   Mon Sep 10 15:37:43 2012 +0000

    powerpc/trace: Fix interrupt tracepoints vs. RCU
    
    There are a few tracepoints in the interrupt code path, which is before
    irq_enter(), or after irq_exit(), like
    trace_irq_entry()/trace_irq_exit() in do_IRQ(),
    trace_timer_interrupt_entry()/trace_timer_interrupt_exit() in
    timer_interrupt().
    
    If the interrupt is from idle(), and because tracepoint contains RCU
    read-side critical section, we could see following suspicious RCU usage
    reported:
    
    [  145.127743] ===============================
    [  145.127747] [ INFO: suspicious RCU usage. ]
    [  145.127752] 3.6.0-rc3+ #1 Not tainted
    [  145.127755] -------------------------------
    [  145.127759] /root/.workdir/linux/arch/powerpc/include/asm/trace.h:33
    suspicious rcu_dereference_check() usage!
    [  145.127765]
    [  145.127765] other info that might help us debug this:
    [  145.127765]
    [  145.127771]
    [  145.127771] RCU used illegally from idle CPU!
    [  145.127771] rcu_scheduler_active = 1, debug_locks = 0
    [  145.127777] RCU used illegally from extended quiescent state!
    [  145.127781] no locks held by swapper/0/0.
    [  145.127785]
    [  145.127785] stack backtrace:
    [  145.127789] Call Trace:
    [  145.127796] [c00000000108b530] [c000000000013c40] .show_stack
    +0x70/0x1c0 (unreliable)
    [  145.127806] [c00000000108b5e0]
    [c0000000000f59d8] .lockdep_rcu_suspicious+0x118/0x150
    [  145.127813] [c00000000108b680] [c00000000000fc58] .do_IRQ+0x498/0x500
    [  145.127820] [c00000000108b750] [c000000000003950]
    hardware_interrupt_common+0x150/0x180
    [  145.127828] --- Exception: 501 at .plpar_hcall_norets+0x84/0xd4
    [  145.127828]     LR = .check_and_cede_processor+0x38/0x70
    [  145.127836] [c00000000108bab0] [c0000000000665dc] .shared_cede_loop
    +0x5c/0x100
    [  145.127844] [c00000000108bb70] [c000000000588ab0] .cpuidle_enter
    +0x30/0x50
    [  145.127850] [c00000000108bbe0]
    [c000000000588b0c] .cpuidle_enter_state+0x3c/0xb0
    [  145.127857] [c00000000108bc60] [c000000000589730] .cpuidle_idle_call
    +0x150/0x6c0
    [  145.127863] [c00000000108bd30] [c000000000058440] .pSeries_idle
    +0x10/0x40
    [  145.127870] [c00000000108bda0] [c00000000001683c] .cpu_idle
    +0x18c/0x2d0
    [  145.127876] [c00000000108be60] [c00000000000b434] .rest_init
    +0x124/0x1b0
    [  145.127884] [c00000000108bef0] [c0000000009d0d28] .start_kernel
    +0x568/0x588
    [  145.127890] [c00000000108bf90] [c000000000009660] .start_here_common
    +0x20/0x40
    
    This is because the RCU usage in interrupt context should be used in
    area marked by rcu_irq_enter()/rcu_irq_exit(), called in
    irq_enter()/irq_exit() respectively.
    
    Move them into the irq_enter()/irq_exit() area to avoid the reporting.
    
    Signed-off-by: Li Zhong <zhong@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1f017bb7a7ce..71413f41278f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -489,10 +489,10 @@ void do_IRQ(struct pt_regs *regs)
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 
-	trace_irq_entry(regs);
-
 	irq_enter();
 
+	trace_irq_entry(regs);
+
 	check_stack_overflow();
 
 	/*
@@ -511,10 +511,10 @@ void do_IRQ(struct pt_regs *regs)
 	else
 		__get_cpu_var(irq_stat).spurious_irqs++;
 
+	trace_irq_exit(regs);
+
 	irq_exit();
 	set_irq_regs(old_regs);
-
-	trace_irq_exit(regs);
 }
 
 void __init init_IRQ(void)

commit 21b2de341270bd7bb7a811027ffe63276d9b3b75
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 10 18:37:56 2012 +1000

    powerpc: Fix build of some debug irq code
    
    There was a typo, checking for CONFIG_TRACE_IRQFLAG instead of
    CONFIG_TRACE_IRQFLAGS causing some useful debug code to not be
    built
    
    This in turns causes a build error on BookE 64-bit due to incorrect
    semicolons at the end of a couple of macros, so let's fix that too
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: stable@vger.kernel.org [v3.4]

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9270a399c9d6..1f017bb7a7ce 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -229,7 +229,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 */
 	if (unlikely(irq_happened != PACA_IRQ_HARD_DIS))
 		__hard_irq_disable();
-#ifdef CONFIG_TRACE_IRQFLAG
+#ifdef CONFIG_TRACE_IRQFLAGS
 	else {
 		/*
 		 * We should already be hard disabled here. We had bugs

commit be2cf20a5ad31ebb13562c1c866ecc626fbd721e
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 10 18:36:40 2012 +1000

    powerpc: More fixes for lazy IRQ vs. idle
    
    Looks like we still have issues with pSeries and Cell idle code
    vs. the lazy irq state. In fact, the reset fixes that went upstream
    are exposing the problem more by causing BUG_ON() to trigger (which
    this patch turns into a WARN_ON instead).
    
    We need to be careful when using a variant of low power state that
    has the side effect of turning interrupts back on, to properly set
    all the SW & lazy state to look as if everything is enabled before
    we enter the low power state with MSR:EE off as we will return with
    MSR:EE on. If not, we have a discrepancy of state which can cause
    things to go very wrong later on.
    
    This patch moves the logic into a helper and uses it from the
    pseries and cell idle code. The power4/970 idle code already got
    things right (in assembly even !) so I'm not touching it. The power7
    "bare metal" idle code is subtly different and correct. Remains PA6T
    and some hypervisor based Cell platforms which have questionable
    code in there, but they are mostly dead platforms so I'll fix them
    when I manage to get final answers from the respective maintainers
    about how the low power state actually works on them.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: stable@vger.kernel.org [v3.4]

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1b415027ec0e..9270a399c9d6 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -286,6 +286,52 @@ void notrace restore_interrupts(void)
 		__hard_irq_enable();
 }
 
+/*
+ * This is a helper to use when about to go into idle low-power
+ * when the latter has the side effect of re-enabling interrupts
+ * (such as calling H_CEDE under pHyp).
+ *
+ * You call this function with interrupts soft-disabled (this is
+ * already the case when ppc_md.power_save is called). The function
+ * will return whether to enter power save or just return.
+ *
+ * In the former case, it will have notified lockdep of interrupts
+ * being re-enabled and generally sanitized the lazy irq state,
+ * and in the latter case it will leave with interrupts hard
+ * disabled and marked as such, so the local_irq_enable() call
+ * in cpu_idle() will properly re-enable everything.
+ */
+bool prep_irq_for_idle(void)
+{
+	/*
+	 * First we need to hard disable to ensure no interrupt
+	 * occurs before we effectively enter the low power state
+	 */
+	hard_irq_disable();
+
+	/*
+	 * If anything happened while we were soft-disabled,
+	 * we return now and do not enter the low power state.
+	 */
+	if (lazy_irq_pending())
+		return false;
+
+	/* Tell lockdep we are about to re-enable */
+	trace_hardirqs_on();
+
+	/*
+	 * Mark interrupts as soft-enabled and clear the
+	 * PACA_IRQ_HARD_DIS from the pending mask since we
+	 * are about to hard enable as well as a side effect
+	 * of entering the low power state.
+	 */
+	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
+	local_paca->soft_enabled = 1;
+
+	/* Tell the caller to enter the low power state */
+	return true;
+}
+
 #endif /* CONFIG_PPC64 */
 
 int arch_show_interrupts(struct seq_file *p, int prec)

commit 2d773aa4810d4a612d1c879faacc38594cc3f841
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Mon Jun 4 16:27:54 2012 +0000

    powerpc/ftrace: Do not trace restore_interrupts()
    
    As I was adding code that affects all archs, I started testing function
    tracer against PPC64 and found that it currently locks up with 3.4
    kernel. I figured it was due to tracing a function that shouldn't be, so
    I went through the following process to bisect to find the culprit:
    
     cat /debug/tracing/available_filter_functions > t
     num=`wc -l t`
     sed -ne "1,${num}p" t > t1
     let num=num+1
     sed -ne "${num},$p" t > t2
     cat t1 > /debug/tracing/set_ftrace_filter
     echo function /debug/tracing/current_tracer
     <failed? bisect t1, if not bisect t2>
    
    It finally came down to this function: restore_interrupts()
    
    I'm not sure why this locks up the system. It just seems to prevent
    scheduling from occurring. Interrupts seem to still work, as I can ping
    the box. But all user processes freeze.
    
    When restore_interrupts() is not traced, function tracing works fine.
    
    Cc: stable@kernel.org
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 7835a5e1ea5f..1b415027ec0e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -277,7 +277,7 @@ EXPORT_SYMBOL(arch_local_irq_restore);
  * NOTE: This is called with interrupts hard disabled but not marked
  * as such in paca->irq_happened, so we need to resync this.
  */
-void restore_interrupts(void)
+void notrace restore_interrupts(void)
 {
 	if (irqs_disabled()) {
 		local_paca->irq_happened |= PACA_IRQ_HARD_DIS;

commit 2074b1d9d53ae696dd3f49482bad43254f40f01d
Author: Kim Phillips <kim.phillips@freescale.com>
Date:   Thu May 17 15:11:45 2012 +0000

    powerpc: Fix irq distribution
    
    setting CONFIG_IRQ_ALL_CPUS distributes IRQs to CPUs only when
    the number of online CPUs equals NR_CPUS.  See commit
    280ff97494e0fef4124bee5c52e39b23a18dd283 "sparc64: fix and
    optimize irq distribution" for more details.
    
    Using the online mask fixes IRQ-to-CPU distribution on systems
    that boot with less than NR_CPUS.
    
    Signed-off-by: Kim Phillips <kim.phillips@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 641da9e868ce..7835a5e1ea5f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -587,7 +587,7 @@ int irq_choose_cpu(const struct cpumask *mask)
 {
 	int cpuid;
 
-	if (cpumask_equal(mask, cpu_all_mask)) {
+	if (cpumask_equal(mask, cpu_online_mask)) {
 		static int irq_rover;
 		static DEFINE_RAW_SPINLOCK(irq_rover_lock);
 		unsigned long flags;

commit 7c0482e3d055e5de056d3c693b821e39205b99ae
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu May 10 16:12:38 2012 +0000

    powerpc/irq: Fix another case of lazy IRQ state getting out of sync
    
    So we have another case of paca->irq_happened getting out of
    sync with the HW irq state. This can happen when a perfmon
    interrupt occurs while soft disabled, as it will return to a
    soft disabled but hard enabled context while leaving a stale
    PACA_IRQ_HARD_DIS flag set.
    
    This patch fixes it, and also adds a test for the condition
    of those flags being out of sync in arch_local_irq_restore()
    when CONFIG_TRACE_IRQFLAGS is enabled.
    
    This helps catching those gremlins faster (and so far I
    can't seem see any anymore, so that's good news).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c6c6f3b7f8cd..641da9e868ce 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -229,6 +229,19 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 */
 	if (unlikely(irq_happened != PACA_IRQ_HARD_DIS))
 		__hard_irq_disable();
+#ifdef CONFIG_TRACE_IRQFLAG
+	else {
+		/*
+		 * We should already be hard disabled here. We had bugs
+		 * where that wasn't the case so let's dbl check it and
+		 * warn if we are wrong. Only do that when IRQ tracing
+		 * is enabled as mfmsr() can be costly.
+		 */
+		if (WARN_ON(mfmsr() & MSR_EE))
+			__hard_irq_disable();
+	}
+#endif /* CONFIG_TRACE_IRQFLAG */
+
 	set_soft_enabled(0);
 
 	/*

commit 56dfa7fa19e36db352a94be022243ed461710119
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue May 8 13:31:59 2012 +1000

    powerpc/irq: Fix bug with new lazy IRQ handling code
    
    We had a case where we could turn on hard interrupts while
    leaving the PACA_IRQ_HARD_DIS bit set in the PACA. This can
    in turn cause a BUG_ON() to hit in __check_irq_replay() due
    to interrupt state getting out of sync.
    
    The assembly code was also way too convoluted. Instead, we
    now leave it to the C code to do the right thing which ends
    up being smaller and more readable.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 43eb74fcedde..c6c6f3b7f8cd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -260,11 +260,17 @@ EXPORT_SYMBOL(arch_local_irq_restore);
  * if they are currently disabled. This is typically called before
  * schedule() or do_signal() when returning to userspace. We do it
  * in C to avoid the burden of dealing with lockdep etc...
+ *
+ * NOTE: This is called with interrupts hard disabled but not marked
+ * as such in paca->irq_happened, so we need to resync this.
  */
 void restore_interrupts(void)
 {
-	if (irqs_disabled())
+	if (irqs_disabled()) {
+		local_paca->irq_happened |= PACA_IRQ_HARD_DIS;
 		local_irq_enable();
+	} else
+		__hard_irq_enable();
 }
 
 #endif /* CONFIG_PPC64 */

commit 4013369f3782af9a488e37c2b603f1dcf008ea76
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Mon Apr 23 12:30:02 2012 +0000

    powerpc/irqdomain: Fix broken NR_IRQ references
    
    The switch from using irq_map to irq_alloc_desc*() for managing irq
    number allocations introduced new bugs in some of the powerpc
    interrupt code.  Several functions rely on the value of NR_IRQS to
    determine the maximum irq number that could get allocated.  However,
    with sparse_irq and using irq_alloc_desc*() the maximum possible irq
    number is now specified with 'nr_irqs' which may be a number larger
    than NR_IRQS.  This has caused breakage on powermac when
    CONFIG_NR_IRQS is set to 32.
    
    This patch removes most of the direct references to NR_IRQS in the
    powerpc code and replaces them with either a nr_irqs reference or by
    using the common for_each_irq_desc() macro.  The powerpc-specific
    for_each_irq() macro is removed at the same time.
    
    Also, the Cell axon_msi driver is refactored to remove the global
    build assumption on the size of NR_IRQS and instead add a limit to the
    maximum irq number when calling irq_domain_add_nomap().
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5ec1b2354ca6..43eb74fcedde 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -330,14 +330,10 @@ void migrate_irqs(void)
 
 	alloc_cpumask_var(&mask, GFP_KERNEL);
 
-	for_each_irq(irq) {
+	for_each_irq_desc(irq, desc) {
 		struct irq_data *data;
 		struct irq_chip *chip;
 
-		desc = irq_to_desc(irq);
-		if (!desc)
-			continue;
-
 		data = irq_desc_get_irq_data(desc);
 		if (irqd_is_per_cpu(data))
 			continue;

commit a699e4e49ec3fb62c4a44394357d14081df10bef
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Tue Apr 3 07:11:04 2012 -0600

    irq: Kill pointless irqd_to_hw export
    
    It makes no sense to export this trivial function.  Make it a static inline
    instead.
    
    This patch also drops virq_to_hw from arch/c6x since it is unused by that
    architecture.
    
    v2: Move irq_hw_number_t into types.h to fix ARM build failure
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 243dbabfe74d..5ec1b2354ca6 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -560,12 +560,6 @@ void do_softirq(void)
 	local_irq_restore(flags);
 }
 
-irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
-{
-	return d->hwirq;
-}
-EXPORT_SYMBOL_GPL(irqd_to_hwirq);
-
 irq_hw_number_t virq_to_hw(unsigned int virq)
 {
 	struct irq_data *irq_data = irq_get_irq_data(virq);

commit 0195c00244dc2e9f522475868fa278c473ba7339
Merge: f21ce8f8447c 141124c02059
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 28 15:58:21 2012 -0700

    Merge tag 'split-asm_system_h-for-linus-20120328' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-asm_system
    
    Pull "Disintegrate and delete asm/system.h" from David Howells:
     "Here are a bunch of patches to disintegrate asm/system.h into a set of
      separate bits to relieve the problem of circular inclusion
      dependencies.
    
      I've built all the working defconfigs from all the arches that I can
      and made sure that they don't break.
    
      The reason for these patches is that I recently encountered a circular
      dependency problem that came about when I produced some patches to
      optimise get_order() by rewriting it to use ilog2().
    
      This uses bitops - and on the SH arch asm/bitops.h drags in
      asm-generic/get_order.h by a circuituous route involving asm/system.h.
    
      The main difficulty seems to be asm/system.h.  It holds a number of
      low level bits with no/few dependencies that are commonly used (eg.
      memory barriers) and a number of bits with more dependencies that
      aren't used in many places (eg.  switch_to()).
    
      These patches break asm/system.h up into the following core pieces:
    
        (1) asm/barrier.h
    
            Move memory barriers here.  This already done for MIPS and Alpha.
    
        (2) asm/switch_to.h
    
            Move switch_to() and related stuff here.
    
        (3) asm/exec.h
    
            Move arch_align_stack() here.  Other process execution related bits
            could perhaps go here from asm/processor.h.
    
        (4) asm/cmpxchg.h
    
            Move xchg() and cmpxchg() here as they're full word atomic ops and
            frequently used by atomic_xchg() and atomic_cmpxchg().
    
        (5) asm/bug.h
    
            Move die() and related bits.
    
        (6) asm/auxvec.h
    
            Move AT_VECTOR_SIZE_ARCH here.
    
      Other arch headers are created as needed on a per-arch basis."
    
    Fixed up some conflicts from other header file cleanups and moving code
    around that has happened in the meantime, so David's testing is somewhat
    weakened by that.  We'll find out anything that got broken and fix it..
    
    * tag 'split-asm_system_h-for-linus-20120328' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-asm_system: (38 commits)
      Delete all instances of asm/system.h
      Remove all #inclusions of asm/system.h
      Add #includes needed to permit the removal of asm/system.h
      Move all declarations of free_initmem() to linux/mm.h
      Disintegrate asm/system.h for OpenRISC
      Split arch_align_stack() out from asm-generic/system.h
      Split the switch_to() wrapper out of asm-generic/system.h
      Move the asm-generic/system.h xchg() implementation to asm-generic/cmpxchg.h
      Create asm-generic/barrier.h
      Make asm-generic/cmpxchg.h #include asm-generic/cmpxchg-local.h
      Disintegrate asm/system.h for Xtensa
      Disintegrate asm/system.h for Unicore32 [based on ver #3, changed by gxt]
      Disintegrate asm/system.h for Tile
      Disintegrate asm/system.h for Sparc
      Disintegrate asm/system.h for SH
      Disintegrate asm/system.h for Score
      Disintegrate asm/system.h for S390
      Disintegrate asm/system.h for PowerPC
      Disintegrate asm/system.h for PA-RISC
      Disintegrate asm/system.h for MN10300
      ...

commit ae3a197e3d0bfe3f4bf1693723e82dc018c096f3
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for PowerPC
    
    Disintegrate asm/system.h for PowerPC.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    cc: linuxppc-dev@lists.ozlabs.org

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a3d128e94cff..2c5635dce05f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -57,7 +57,6 @@
 #include <linux/of_irq.h>
 
 #include <asm/uaccess.h>
-#include <asm/system.h>
 #include <asm/io.h>
 #include <asm/pgtable.h>
 #include <asm/irq.h>
@@ -67,6 +66,7 @@
 #include <asm/machdep.h>
 #include <asm/udbg.h>
 #include <asm/smp.h>
+#include <asm/debug.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>

commit 1d9a47315042606b4217691bcea36cfa6ccbde66
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Mar 21 18:23:27 2012 +0000

    powerpc: Random little legacy iSeries removal tidy ups
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 46ce5f733511..cea2d9f3ae4e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -208,8 +208,8 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 * we are checking the "new" CPU instead of the old one. This
 	 * is only a problem if an event happened on the "old" CPU.
 	 *
-	 * External interrupt events on non-iseries will have caused
-	 * interrupts to be hard-disabled, so there is no problem, we
+	 * External interrupt events will have caused interrupts to
+	 * be hard-disabled, so there is no problem, we
 	 * cannot have preempted.
 	 */
 	irq_happened = get_irq_happened();

commit 7ba3e4f5877466b0f81dcd3cb78db5d75b267645
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Mar 21 18:09:51 2012 +0000

    powerpc: Remove NO_IRQ_IGNORE
    
    Now that legacy iSeries is gone, this is no longer used.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a3d128e94cff..46ce5f733511 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -445,9 +445,9 @@ void do_IRQ(struct pt_regs *regs)
 	may_hard_irq_enable();
 
 	/* And finally process it */
-	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE)
+	if (irq != NO_IRQ)
 		handle_one_irq(irq);
-	else if (irq != NO_IRQ_IGNORE)
+	else
 		__get_cpu_var(irq_stat).spurious_irqs++;
 
 	irq_exit();

commit 5375871d432ae9fc581014ac117b96aaee3cd0c7
Merge: b57cb7231b2c dfbc2d75c1bd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 21 18:55:10 2012 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc merge from Benjamin Herrenschmidt:
     "Here's the powerpc batch for this merge window.  It is going to be a
      bit more nasty than usual as in touching things outside of
      arch/powerpc mostly due to the big iSeriesectomy :-) We finally got
      rid of the bugger (legacy iSeries support) which was a PITA to
      maintain and that nobody really used anymore.
    
      Here are some of the highlights:
    
       - Legacy iSeries is gone.  Thanks Stephen ! There's still some bits
         and pieces remaining if you do a grep -ir series arch/powerpc but
         they are harmless and will be removed in the next few weeks
         hopefully.
    
       - The 'fadump' functionality (Firmware Assisted Dump) replaces the
         previous (equivalent) "pHyp assisted dump"...  it's a rewrite of a
         mechanism to get the hypervisor to do crash dumps on pSeries, the
         new implementation hopefully being much more reliable.  Thanks
         Mahesh Salgaonkar.
    
       - The "EEH" code (pSeries PCI error handling & recovery) got a big
         spring cleaning, motivated by the need to be able to implement a
         new backend for it on top of some new different type of firwmare.
    
         The work isn't complete yet, but a good chunk of the cleanups is
         there.  Note that this adds a field to struct device_node which is
         not very nice and which Grant objects to.  I will have a patch soon
         that moves that to a powerpc private data structure (hopefully
         before rc1) and we'll improve things further later on (hopefully
         getting rid of the need for that pointer completely).  Thanks Gavin
         Shan.
    
       - I dug into our exception & interrupt handling code to improve the
         way we do lazy interrupt handling (and make it work properly with
         "edge" triggered interrupt sources), and while at it found & fixed
         a wagon of issues in those areas, including adding support for page
         fault retry & fatal signals on page faults.
    
       - Your usual random batch of small fixes & updates, including a bunch
         of new embedded boards, both Freescale and APM based ones, etc..."
    
    I fixed up some conflicts with the generalized irq-domain changes from
    Grant Likely, hopefully correctly.
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (141 commits)
      powerpc/ps3: Do not adjust the wrapper load address
      powerpc: Remove the rest of the legacy iSeries include files
      powerpc: Remove the remaining CONFIG_PPC_ISERIES pieces
      init: Remove CONFIG_PPC_ISERIES
      powerpc: Remove FW_FEATURE ISERIES from arch code
      tty/hvc_vio: FW_FEATURE_ISERIES is no longer selectable
      powerpc/spufs: Fix double unlocks
      powerpc/5200: convert mpc5200 to use of_platform_populate()
      powerpc/mpc5200: add options to mpc5200_defconfig
      powerpc/mpc52xx: add a4m072 board support
      powerpc/mpc5200: update mpc5200_defconfig to fit for charon board
      Documentation/powerpc/mpc52xx.txt: Checkpatch cleanup
      powerpc/44x: Add additional device support for APM821xx SoC and Bluestone board
      powerpc/44x: Add support PCI-E for APM821xx SoC and Bluestone board
      MAINTAINERS: Update PowerPC 4xx tree
      powerpc/44x: The bug fixed support for APM821xx SoC and Bluestone board
      powerpc: document the FSL MPIC message register binding
      powerpc: add support for MPIC message register API
      powerpc/fsl: Added aliased MSIIR register address to MSI node in dts
      powerpc/85xx: mpc8548cds - add 36-bit dts
      ...

commit c207f3a43194e108dda43dc9a1ce507335cff6b9
Merge: c7c66c0cb0c7 e7cc3aca0f6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 21 10:27:19 2012 -0700

    Merge tag 'irqdomain-for-linus' of git://git.secretlab.ca/git/linux-2.6
    
    Pull irq_domain support for all architectures from Grant Likely:
     "Generialize powerpc's irq_host as irq_domain
    
      This branch takes the PowerPC irq_host infrastructure (reverse mapping
      from Linux IRQ numbers to hardware irq numbering), generalizes it,
      renames it to irq_domain, and makes it available to all architectures.
    
      Originally the plan has been to create an all-new irq_domain
      implementation which addresses some of the powerpc shortcomings such
      as not handling 1:1 mappings well, but doing that proved to be far
      more difficult and invasive than generalizing the working code and
      refactoring it in-place.  So, this branch rips out the 'new'
      irq_domain and replaces it with the modified powerpc version (in a
      fully bisectable way of course).  It converts all users over to the
      new API and makes irq_domain selectable on any architecture.
    
      No architecture is forced to enable irq_domain, but the infrastructure
      is required for doing OpenFirmware style irq translations.  It will
      even work on SPARC even though SPARC has it's own mechanism for
      translating irqs at boot time.  MIPS, microblaze, embedded x86 and c6x
      are converted too.
    
      The resulting irq_domain code is probably still too verbose and can be
      optimized more, but that can be done incrementally and is a task for
      follow-on patches."
    
    * tag 'irqdomain-for-linus' of git://git.secretlab.ca/git/linux-2.6: (31 commits)
      dt: fix twl4030 for non-dt compile on x86
      mfd: twl-core: Add IRQ_DOMAIN dependency
      devicetree: Add empty of_platform_populate() for !CONFIG_OF_ADDRESS (sparc)
      irq_domain: Centralize definition of irq_dispose_mapping()
      irq_domain/mips: Allow irq_domain on MIPS
      irq_domain/x86: Convert x86 (embedded) to use common irq_domain
      ppc-6xx: fix build failure in flipper-pic.c and hlwd-pic.c
      irq_domain/microblaze: Convert microblaze to use irq_domains
      irq_domain/powerpc: Replace custom xlate functions with library functions
      irq_domain/powerpc: constify irq_domain_ops
      irq_domain/c6x: Use library of xlate functions
      irq_domain/c6x: constify irq_domain structures
      irq_domain/c6x: Convert c6x to use generic irq_domain support.
      irq_domain: constify irq_domain_ops
      irq_domain: Create common xlate functions that device drivers can use
      irq_domain: Remove irq_domain_add_simple()
      irq_domain: Remove 'new' irq_domain in favour of the ppc one
      mfd: twl-core.c: Fix the number of interrupts managed by twl4030
      of/address: add empty static inlines for !CONFIG_OF
      irq_domain: Add support for base irq and hwirq in legacy mappings
      ...

commit f5339277eb8d3aed37f12a27988366f68ab68930
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Mar 15 18:18:00 2012 +0000

    powerpc: Remove FW_FEATURE ISERIES from arch code
    
    This is no longer selectable, so just remove all the dependent code.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index eb804e15b29b..45b367c8d8b8 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -211,11 +211,6 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 * External interrupt events on non-iseries will have caused
 	 * interrupts to be hard-disabled, so there is no problem, we
 	 * cannot have preempted.
-	 *
-	 * That leaves us with EEs on iSeries or decrementer interrupts,
-	 * which I decided to safely ignore. The preemption would have
-	 * itself been the result of an interrupt, upon which return we
-	 * will have checked for pending events on the old CPU.
 	 */
 	irq_happened = get_irq_happened();
 	if (!irq_happened)
@@ -458,15 +453,6 @@ void do_IRQ(struct pt_regs *regs)
 	irq_exit();
 	set_irq_regs(old_regs);
 
-#ifdef CONFIG_PPC_ISERIES
-	if (firmware_has_feature(FW_FEATURE_ISERIES) &&
-			get_lppaca()->int_dword.fields.decr_int) {
-		get_lppaca()->int_dword.fields.decr_int = 0;
-		/* Signal a fake decrementer interrupt */
-		timer_interrupt(regs);
-	}
-#endif
-
 	trace_irq_exit(regs);
 }
 

commit 7230c5644188cd9e3fb380cc97dde00c464a3ba7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Mar 6 18:27:59 2012 +1100

    powerpc: Rework lazy-interrupt handling
    
    The current implementation of lazy interrupts handling has some
    issues that this tries to address.
    
    We don't do the various workarounds we need to do when re-enabling
    interrupts in some cases such as when returning from an interrupt
    and thus we may still lose or get delayed decrementer or doorbell
    interrupts.
    
    The current scheme also makes it much harder to handle the external
    "edge" interrupts provided by some BookE processors when using the
    EPR facility (External Proxy) and the Freescale Hypervisor.
    
    Additionally, we tend to keep interrupts hard disabled in a number
    of cases, such as decrementer interrupts, external interrupts, or
    when a masked decrementer interrupt is pending. This is sub-optimal.
    
    This is an attempt at fixing it all in one go by reworking the way
    we do the lazy interrupt disabling from the ground up.
    
    The base idea is to replace the "hard_enabled" field with a
    "irq_happened" field in which we store a bit mask of what interrupt
    occurred while soft-disabled.
    
    When re-enabling, either via arch_local_irq_restore() or when returning
    from an interrupt, we can now decide what to do by testing bits in that
    field.
    
    We then implement replaying of the missed interrupts either by
    re-using the existing exception frame (in exception exit case) or via
    the creation of a new one from an assembly trampoline (in the
    arch_local_irq_enable case).
    
    This removes the need to play with the decrementer to try to create
    fake interrupts, among others.
    
    In addition, this adds a few refinements:
    
     - We no longer  hard disable decrementer interrupts that occur
    while soft-disabled. We now simply bump the decrementer back to max
    (on BookS) or leave it stopped (on BookE) and continue with hard interrupts
    enabled, which means that we'll potentially get better sample quality from
    performance monitor interrupts.
    
     - Timer, decrementer and doorbell interrupts now hard-enable
    shortly after removing the source of the interrupt, which means
    they no longer run entirely hard disabled. Again, this will improve
    perf sample quality.
    
     - On Book3E 64-bit, we now make the performance monitor interrupt
    act as an NMI like Book3S (the necessary C code for that to work
    appear to already be present in the FSL perf code, notably calling
    nmi_enter instead of irq_enter). (This also fixes a bug where BookE
    perfmon interrupts could clobber r14 ... oops)
    
     - We could make "masked" decrementer interrupts act as NMIs when doing
    timer-based perf sampling to improve the sample quality.
    
    Signed-off-by-yet: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    ---
    
    v2:
    
    - Add hard-enable to decrementer, timer and doorbells
    - Fix CR clobber in masked irq handling on BookE
    - Make embedded perf interrupt act as an NMI
    - Add a PACA_HAPPENED_EE_EDGE for use by FSL if they want
      to retrigger an interrupt without preventing hard-enable
    
    v3:
    
     - Fix or vs. ori bug on Book3E
     - Fix enabling of interrupts for some exceptions on Book3E
    
    v4:
    
     - Fix resend of doorbells on return from interrupt on Book3E
    
    v5:
    
     - Rebased on top of my latest series, which involves some significant
    rework of some aspects of the patch.
    
    v6:
     - 32-bit compile fix
     - more compile fixes with various .config combos
     - factor out the asm code to soft-disable interrupts
     - remove the C wrapper around preempt_schedule_irq
    
    v7:
     - Fix a bug with hard irq state tracking on native power7

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9b6e80668cfb..eb804e15b29b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -95,14 +95,14 @@ extern int tau_interrupts(int);
 
 int distribute_irqs = 1;
 
-static inline notrace unsigned long get_hard_enabled(void)
+static inline notrace unsigned long get_irq_happened(void)
 {
-	unsigned long enabled;
+	unsigned long happened;
 
 	__asm__ __volatile__("lbz %0,%1(13)"
-	: "=r" (enabled) : "i" (offsetof(struct paca_struct, hard_enabled)));
+	: "=r" (happened) : "i" (offsetof(struct paca_struct, irq_happened)));
 
-	return enabled;
+	return happened;
 }
 
 static inline notrace void set_soft_enabled(unsigned long enable)
@@ -111,88 +111,167 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
-static inline notrace void decrementer_check_overflow(void)
+static inline notrace int decrementer_check_overflow(void)
 {
-	u64 now = get_tb_or_rtc();
-	u64 *next_tb;
-
-	preempt_disable();
-	next_tb = &__get_cpu_var(decrementers_next_tb);
-
+ 	u64 now = get_tb_or_rtc();
+ 	u64 *next_tb = &__get_cpu_var(decrementers_next_tb);
+ 
 	if (now >= *next_tb)
 		set_dec(1);
-	preempt_enable();
+	return now >= *next_tb;
 }
 
-notrace void arch_local_irq_restore(unsigned long en)
+/* This is called whenever we are re-enabling interrupts
+ * and returns either 0 (nothing to do) or 500/900 if there's
+ * either an EE or a DEC to generate.
+ *
+ * This is called in two contexts: From arch_local_irq_restore()
+ * before soft-enabling interrupts, and from the exception exit
+ * path when returning from an interrupt from a soft-disabled to
+ * a soft enabled context. In both case we have interrupts hard
+ * disabled.
+ *
+ * We take care of only clearing the bits we handled in the
+ * PACA irq_happened field since we can only re-emit one at a
+ * time and we don't want to "lose" one.
+ */
+notrace unsigned int __check_irq_replay(void)
 {
 	/*
-	 * get_paca()->soft_enabled = en;
-	 * Is it ever valid to use local_irq_restore(0) when soft_enabled is 1?
-	 * That was allowed before, and in such a case we do need to take care
-	 * that gcc will set soft_enabled directly via r13, not choose to use
-	 * an intermediate register, lest we're preempted to a different cpu.
+	 * We use local_paca rather than get_paca() to avoid all
+	 * the debug_smp_processor_id() business in this low level
+	 * function
 	 */
-	set_soft_enabled(en);
-	if (!en)
-		return;
+	unsigned char happened = local_paca->irq_happened;
 
-#ifdef CONFIG_PPC_STD_MMU_64
-	if (firmware_has_feature(FW_FEATURE_ISERIES)) {
-		/*
-		 * Do we need to disable preemption here?  Not really: in the
-		 * unlikely event that we're preempted to a different cpu in
-		 * between getting r13, loading its lppaca_ptr, and loading
-		 * its any_int, we might call iseries_handle_interrupts without
-		 * an interrupt pending on the new cpu, but that's no disaster,
-		 * is it?  And the business of preempting us off the old cpu
-		 * would itself involve a local_irq_restore which handles the
-		 * interrupt to that cpu.
-		 *
-		 * But use "local_paca->lppaca_ptr" instead of "get_lppaca()"
-		 * to avoid any preemption checking added into get_paca().
-		 */
-		if (local_paca->lppaca_ptr->int_dword.any_int)
-			iseries_handle_interrupts();
+	/* Clear bit 0 which we wouldn't clear otherwise */
+	local_paca->irq_happened &= ~PACA_IRQ_HARD_DIS;
+
+	/*
+	 * Force the delivery of pending soft-disabled interrupts on PS3.
+	 * Any HV call will have this side effect.
+	 */
+	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
+		u64 tmp, tmp2;
+		lv1_get_version_info(&tmp, &tmp2);
 	}
-#endif /* CONFIG_PPC_STD_MMU_64 */
 
 	/*
-	 * if (get_paca()->hard_enabled) return;
-	 * But again we need to take care that gcc gets hard_enabled directly
-	 * via r13, not choose to use an intermediate register, lest we're
-	 * preempted to a different cpu in between the two instructions.
+	 * We may have missed a decrementer interrupt. We check the
+	 * decrementer itself rather than the paca irq_happened field
+	 * in case we also had a rollover while hard disabled
+	 */
+	local_paca->irq_happened &= ~PACA_IRQ_DEC;
+	if (decrementer_check_overflow())
+		return 0x900;
+
+	/* Finally check if an external interrupt happened */
+	local_paca->irq_happened &= ~PACA_IRQ_EE;
+	if (happened & PACA_IRQ_EE)
+		return 0x500;
+
+#ifdef CONFIG_PPC_BOOK3E
+	/* Finally check if an EPR external interrupt happened
+	 * this bit is typically set if we need to handle another
+	 * "edge" interrupt from within the MPIC "EPR" handler
+	 */
+	local_paca->irq_happened &= ~PACA_IRQ_EE_EDGE;
+	if (happened & PACA_IRQ_EE_EDGE)
+		return 0x500;
+
+	local_paca->irq_happened &= ~PACA_IRQ_DBELL;
+	if (happened & PACA_IRQ_DBELL)
+		return 0x280;
+#endif /* CONFIG_PPC_BOOK3E */
+
+	/* There should be nothing left ! */
+	BUG_ON(local_paca->irq_happened != 0);
+
+	return 0;
+}
+
+notrace void arch_local_irq_restore(unsigned long en)
+{
+	unsigned char irq_happened;
+	unsigned int replay;
+
+	/* Write the new soft-enabled value */
+	set_soft_enabled(en);
+	if (!en)
+		return;
+	/*
+	 * From this point onward, we can take interrupts, preempt,
+	 * etc... unless we got hard-disabled. We check if an event
+	 * happened. If none happened, we know we can just return.
+	 *
+	 * We may have preempted before the check below, in which case
+	 * we are checking the "new" CPU instead of the old one. This
+	 * is only a problem if an event happened on the "old" CPU.
+	 *
+	 * External interrupt events on non-iseries will have caused
+	 * interrupts to be hard-disabled, so there is no problem, we
+	 * cannot have preempted.
+	 *
+	 * That leaves us with EEs on iSeries or decrementer interrupts,
+	 * which I decided to safely ignore. The preemption would have
+	 * itself been the result of an interrupt, upon which return we
+	 * will have checked for pending events on the old CPU.
 	 */
-	if (get_hard_enabled())
+	irq_happened = get_irq_happened();
+	if (!irq_happened)
 		return;
 
 	/*
-	 * Need to hard-enable interrupts here.  Since currently disabled,
-	 * no need to take further asm precautions against preemption; but
-	 * use local_paca instead of get_paca() to avoid preemption checking.
+	 * We need to hard disable to get a trusted value from
+	 * __check_irq_replay(). We also need to soft-disable
+	 * again to avoid warnings in there due to the use of
+	 * per-cpu variables.
+	 *
+	 * We know that if the value in irq_happened is exactly 0x01
+	 * then we are already hard disabled (there are other less
+	 * common cases that we'll ignore for now), so we skip the
+	 * (expensive) mtmsrd.
 	 */
-	local_paca->hard_enabled = en;
+	if (unlikely(irq_happened != PACA_IRQ_HARD_DIS))
+		__hard_irq_disable();
+	set_soft_enabled(0);
 
 	/*
-	 * Trigger the decrementer if we have a pending event. Some processors
-	 * only trigger on edge transitions of the sign bit. We might also
-	 * have disabled interrupts long enough that the decrementer wrapped
-	 * to positive.
+	 * Check if anything needs to be re-emitted. We haven't
+	 * soft-enabled yet to avoid warnings in decrementer_check_overflow
+	 * accessing per-cpu variables
 	 */
-	decrementer_check_overflow();
+	replay = __check_irq_replay();
+
+	/* We can soft-enable now */
+	set_soft_enabled(1);
 
 	/*
-	 * Force the delivery of pending soft-disabled interrupts on PS3.
-	 * Any HV call will have this side effect.
+	 * And replay if we have to. This will return with interrupts
+	 * hard-enabled.
 	 */
-	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
-		u64 tmp, tmp2;
-		lv1_get_version_info(&tmp, &tmp2);
+	if (replay) {
+		__replay_interrupt(replay);
+		return;
 	}
 
+	/* Finally, let's ensure we are hard enabled */
 	__hard_irq_enable();
 }
 EXPORT_SYMBOL(arch_local_irq_restore);
+
+/*
+ * This is specifically called by assembly code to re-enable interrupts
+ * if they are currently disabled. This is typically called before
+ * schedule() or do_signal() when returning to userspace. We do it
+ * in C to avoid the burden of dealing with lockdep etc...
+ */
+void restore_interrupts(void)
+{
+	if (irqs_disabled())
+		local_irq_enable();
+}
+
 #endif /* CONFIG_PPC64 */
 
 int arch_show_interrupts(struct seq_file *p, int prec)
@@ -360,8 +439,17 @@ void do_IRQ(struct pt_regs *regs)
 
 	check_stack_overflow();
 
+	/*
+	 * Query the platform PIC for the interrupt & ack it.
+	 *
+	 * This will typically lower the interrupt line to the CPU
+	 */
 	irq = ppc_md.get_irq();
 
+	/* We can hard enable interrupts now */
+	may_hard_irq_enable();
+
+	/* And finally process it */
 	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE)
 		handle_one_irq(irq);
 	else if (irq != NO_IRQ_IGNORE)

commit ad5b7f1350c263eef0c99c20f8659d0ed363cb32
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Mon Jan 30 08:02:19 2012 +0000

    powerpc: Make SPARSE_IRQ required
    
    All IRQs on powerpc are managed via irq_domain anyway, there isn't really
    any advantage to turning SPARSE_IRQ off, and it's the direction we want
    to take the kernel design anyway.  This patch makes powerpc always use
    SPARSE_IRQ.
    
    On pseries_defconfig, SPARSE_IRQ adds only about 0x300 bytes to the
    .text sections, and removes about 0x20000 from the data section for the
    static irq_desc table.
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Rob Herring <rob.herring@calxeda.com>
    Cc: Ben Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 01e2877e8e04..9b6e80668cfb 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -93,10 +93,6 @@ extern int tau_interrupts(int);
 
 #ifdef CONFIG_PPC64
 
-#ifndef CONFIG_SPARSE_IRQ
-EXPORT_SYMBOL(irq_desc);
-#endif
-
 int distribute_irqs = 1;
 
 static inline notrace unsigned long get_hard_enabled(void)

commit cc79ca691c292e9fd44f589c7940b9654e22f2f6
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Thu Feb 16 01:37:49 2012 -0700

    irq_domain: Move irq_domain code from powerpc to kernel/irq
    
    This patch only moves the code.  It doesn't make any changes, and the
    code is still only compiled for powerpc.  Follow-on patches will generalize
    the code for other architectures.
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Milton Miller <miltonm@bga.com>
    Tested-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 269fbd5ac62f..e3673ff6b7a0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -486,17 +486,6 @@ void do_softirq(void)
 	local_irq_restore(flags);
 }
 
-
-/*
- * IRQ controller and virtual interrupts
- */
-
-static LIST_HEAD(irq_domain_list);
-static DEFINE_MUTEX(irq_domain_mutex);
-static DEFINE_MUTEX(revmap_trees_mutex);
-static unsigned int irq_virq_count = NR_IRQS;
-static struct irq_domain *irq_default_host;
-
 irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
 {
 	return d->hwirq;
@@ -510,362 +499,6 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
-static int default_irq_host_match(struct irq_domain *h, struct device_node *np)
-{
-	return h->of_node != NULL && h->of_node == np;
-}
-
-struct irq_domain *irq_alloc_host(struct device_node *of_node,
-				unsigned int revmap_type,
-				unsigned int revmap_arg,
-				struct irq_domain_ops *ops,
-				irq_hw_number_t inval_irq)
-{
-	struct irq_domain *host, *h;
-	unsigned int size = sizeof(struct irq_domain);
-	unsigned int i;
-	unsigned int *rmap;
-
-	/* Allocate structure and revmap table if using linear mapping */
-	if (revmap_type == IRQ_DOMAIN_MAP_LINEAR)
-		size += revmap_arg * sizeof(unsigned int);
-	host = kzalloc(size, GFP_KERNEL);
-	if (host == NULL)
-		return NULL;
-
-	/* Fill structure */
-	host->revmap_type = revmap_type;
-	host->inval_irq = inval_irq;
-	host->ops = ops;
-	host->of_node = of_node_get(of_node);
-
-	if (host->ops->match == NULL)
-		host->ops->match = default_irq_host_match;
-
-	mutex_lock(&irq_domain_mutex);
-	/* Make sure only one legacy controller can be created */
-	if (revmap_type == IRQ_DOMAIN_MAP_LEGACY) {
-		list_for_each_entry(h, &irq_domain_list, link) {
-			if (WARN_ON(h->revmap_type == IRQ_DOMAIN_MAP_LEGACY)) {
-				mutex_unlock(&irq_domain_mutex);
-				of_node_put(host->of_node);
-				kfree(host);
-				return NULL;
-			}
-		}
-	}
-	list_add(&host->link, &irq_domain_list);
-	mutex_unlock(&irq_domain_mutex);
-
-	/* Additional setups per revmap type */
-	switch(revmap_type) {
-	case IRQ_DOMAIN_MAP_LEGACY:
-		/* 0 is always the invalid number for legacy */
-		host->inval_irq = 0;
-		/* setup us as the host for all legacy interrupts */
-		for (i = 1; i < NUM_ISA_INTERRUPTS; i++) {
-			struct irq_data *irq_data = irq_get_irq_data(i);
-			irq_data->hwirq = i;
-			irq_data->domain = host;
-
-			/* Legacy flags are left to default at this point,
-			 * one can then use irq_create_mapping() to
-			 * explicitly change them
-			 */
-			ops->map(host, i, i);
-
-			/* Clear norequest flags */
-			irq_clear_status_flags(i, IRQ_NOREQUEST);
-		}
-		break;
-	case IRQ_DOMAIN_MAP_LINEAR:
-		rmap = (unsigned int *)(host + 1);
-		for (i = 0; i < revmap_arg; i++)
-			rmap[i] = NO_IRQ;
-		host->revmap_data.linear.size = revmap_arg;
-		host->revmap_data.linear.revmap = rmap;
-		break;
-	case IRQ_DOMAIN_MAP_TREE:
-		INIT_RADIX_TREE(&host->revmap_data.tree, GFP_KERNEL);
-		break;
-	default:
-		break;
-	}
-
-	pr_debug("irq: Allocated host of type %d @0x%p\n", revmap_type, host);
-
-	return host;
-}
-
-struct irq_domain *irq_find_host(struct device_node *node)
-{
-	struct irq_domain *h, *found = NULL;
-
-	/* We might want to match the legacy controller last since
-	 * it might potentially be set to match all interrupts in
-	 * the absence of a device node. This isn't a problem so far
-	 * yet though...
-	 */
-	mutex_lock(&irq_domain_mutex);
-	list_for_each_entry(h, &irq_domain_list, link)
-		if (h->ops->match(h, node)) {
-			found = h;
-			break;
-		}
-	mutex_unlock(&irq_domain_mutex);
-	return found;
-}
-EXPORT_SYMBOL_GPL(irq_find_host);
-
-void irq_set_default_host(struct irq_domain *host)
-{
-	pr_debug("irq: Default host set to @0x%p\n", host);
-
-	irq_default_host = host;
-}
-
-void irq_set_virq_count(unsigned int count)
-{
-	pr_debug("irq: Trying to set virq count to %d\n", count);
-
-	BUG_ON(count < NUM_ISA_INTERRUPTS);
-	if (count < NR_IRQS)
-		irq_virq_count = count;
-}
-
-static int irq_setup_virq(struct irq_domain *host, unsigned int virq,
-			    irq_hw_number_t hwirq)
-{
-	struct irq_data *irq_data = irq_get_irq_data(virq);
-
-	irq_data->hwirq = hwirq;
-	irq_data->domain = host;
-	if (host->ops->map(host, virq, hwirq)) {
-		pr_debug("irq: -> mapping failed, freeing\n");
-		irq_data->domain = NULL;
-		irq_data->hwirq = 0;
-		return -1;
-	}
-
-	irq_clear_status_flags(virq, IRQ_NOREQUEST);
-
-	return 0;
-}
-
-unsigned int irq_create_direct_mapping(struct irq_domain *host)
-{
-	unsigned int virq;
-
-	if (host == NULL)
-		host = irq_default_host;
-
-	BUG_ON(host == NULL);
-	WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_NOMAP);
-
-	virq = irq_alloc_desc_from(1, 0);
-	if (virq == NO_IRQ) {
-		pr_debug("irq: create_direct virq allocation failed\n");
-		return NO_IRQ;
-	}
-	if (virq >= irq_virq_count) {
-		pr_err("ERROR: no free irqs available below %i maximum\n",
-			irq_virq_count);
-		irq_free_desc(virq);
-		return 0;
-	}
-
-	pr_debug("irq: create_direct obtained virq %d\n", virq);
-
-	if (irq_setup_virq(host, virq, virq)) {
-		irq_free_desc(virq);
-		return NO_IRQ;
-	}
-
-	return virq;
-}
-
-unsigned int irq_create_mapping(struct irq_domain *host,
-				irq_hw_number_t hwirq)
-{
-	unsigned int virq, hint;
-
-	pr_debug("irq: irq_create_mapping(0x%p, 0x%lx)\n", host, hwirq);
-
-	/* Look for default host if nececssary */
-	if (host == NULL)
-		host = irq_default_host;
-	if (host == NULL) {
-		printk(KERN_WARNING "irq_create_mapping called for"
-		       " NULL host, hwirq=%lx\n", hwirq);
-		WARN_ON(1);
-		return NO_IRQ;
-	}
-	pr_debug("irq: -> using host @%p\n", host);
-
-	/* Check if mapping already exists */
-	virq = irq_find_mapping(host, hwirq);
-	if (virq != NO_IRQ) {
-		pr_debug("irq: -> existing mapping on virq %d\n", virq);
-		return virq;
-	}
-
-	/* Get a virtual interrupt number */
-	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY) {
-		/* Handle legacy */
-		virq = (unsigned int)hwirq;
-		if (virq == 0 || virq >= NUM_ISA_INTERRUPTS)
-			return NO_IRQ;
-		return virq;
-	} else {
-		/* Allocate a virtual interrupt number */
-		hint = hwirq % irq_virq_count;
-		if (hint == 0)
-			hint = 1;
-		virq = irq_alloc_desc_from(hint, 0);
-		if (!virq)
-			virq = irq_alloc_desc_from(1, 0);
-		if (virq == NO_IRQ) {
-			pr_debug("irq: -> virq allocation failed\n");
-			return NO_IRQ;
-		}
-	}
-
-	if (irq_setup_virq(host, virq, hwirq)) {
-		if (host->revmap_type != IRQ_DOMAIN_MAP_LEGACY)
-			irq_free_desc(virq);
-		return NO_IRQ;
-	}
-
-	pr_debug("irq: irq %lu on host %s mapped to virtual irq %u\n",
-		hwirq, host->of_node ? host->of_node->full_name : "null", virq);
-
-	return virq;
-}
-EXPORT_SYMBOL_GPL(irq_create_mapping);
-
-unsigned int irq_create_of_mapping(struct device_node *controller,
-				   const u32 *intspec, unsigned int intsize)
-{
-	struct irq_domain *host;
-	irq_hw_number_t hwirq;
-	unsigned int type = IRQ_TYPE_NONE;
-	unsigned int virq;
-
-	if (controller == NULL)
-		host = irq_default_host;
-	else
-		host = irq_find_host(controller);
-	if (host == NULL) {
-		printk(KERN_WARNING "irq: no irq host found for %s !\n",
-		       controller->full_name);
-		return NO_IRQ;
-	}
-
-	/* If host has no translation, then we assume interrupt line */
-	if (host->ops->xlate == NULL)
-		hwirq = intspec[0];
-	else {
-		if (host->ops->xlate(host, controller, intspec, intsize,
-				     &hwirq, &type))
-			return NO_IRQ;
-	}
-
-	/* Create mapping */
-	virq = irq_create_mapping(host, hwirq);
-	if (virq == NO_IRQ)
-		return virq;
-
-	/* Set type if specified and different than the current one */
-	if (type != IRQ_TYPE_NONE &&
-	    type != (irqd_get_trigger_type(irq_get_irq_data(virq))))
-		irq_set_irq_type(virq, type);
-	return virq;
-}
-EXPORT_SYMBOL_GPL(irq_create_of_mapping);
-
-void irq_dispose_mapping(unsigned int virq)
-{
-	struct irq_data *irq_data = irq_get_irq_data(virq);
-	struct irq_domain *host;
-	irq_hw_number_t hwirq;
-
-	if (virq == NO_IRQ || !irq_data)
-		return;
-
-	host = irq_data->domain;
-	if (WARN_ON(host == NULL))
-		return;
-
-	/* Never unmap legacy interrupts */
-	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY)
-		return;
-
-	irq_set_status_flags(virq, IRQ_NOREQUEST);
-
-	/* remove chip and handler */
-	irq_set_chip_and_handler(virq, NULL, NULL);
-
-	/* Make sure it's completed */
-	synchronize_irq(virq);
-
-	/* Tell the PIC about it */
-	if (host->ops->unmap)
-		host->ops->unmap(host, virq);
-	smp_mb();
-
-	/* Clear reverse map */
-	hwirq = irq_data->hwirq;
-	switch(host->revmap_type) {
-	case IRQ_DOMAIN_MAP_LINEAR:
-		if (hwirq < host->revmap_data.linear.size)
-			host->revmap_data.linear.revmap[hwirq] = NO_IRQ;
-		break;
-	case IRQ_DOMAIN_MAP_TREE:
-		mutex_lock(&revmap_trees_mutex);
-		radix_tree_delete(&host->revmap_data.tree, hwirq);
-		mutex_unlock(&revmap_trees_mutex);
-		break;
-	}
-
-	/* Destroy map */
-	irq_data->hwirq = host->inval_irq;
-
-	irq_free_desc(virq);
-}
-EXPORT_SYMBOL_GPL(irq_dispose_mapping);
-
-unsigned int irq_find_mapping(struct irq_domain *host,
-			      irq_hw_number_t hwirq)
-{
-	unsigned int i;
-	unsigned int hint = hwirq % irq_virq_count;
-
-	/* Look for default host if nececssary */
-	if (host == NULL)
-		host = irq_default_host;
-	if (host == NULL)
-		return NO_IRQ;
-
-	/* legacy -> bail early */
-	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY)
-		return hwirq;
-
-	/* Slow path does a linear search of the map */
-	if (hint == 0)
-		hint = 1;
-	i = hint;
-	do {
-		struct irq_data *data = irq_get_irq_data(i);
-		if (data && (data->domain == host) && (data->hwirq == hwirq))
-			return i;
-		i++;
-		if (i >= irq_virq_count)
-			i = 1;
-	} while(i != hint);
-	return NO_IRQ;
-}
-EXPORT_SYMBOL_GPL(irq_find_mapping);
-
 #ifdef CONFIG_SMP
 int irq_choose_cpu(const struct cpumask *mask)
 {
@@ -902,146 +535,11 @@ int irq_choose_cpu(const struct cpumask *mask)
 }
 #endif
 
-unsigned int irq_radix_revmap_lookup(struct irq_domain *host,
-				     irq_hw_number_t hwirq)
-{
-	struct irq_data *irq_data;
-
-	if (WARN_ON_ONCE(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
-		return irq_find_mapping(host, hwirq);
-
-	/*
-	 * Freeing an irq can delete nodes along the path to
-	 * do the lookup via call_rcu.
-	 */
-	rcu_read_lock();
-	irq_data = radix_tree_lookup(&host->revmap_data.tree, hwirq);
-	rcu_read_unlock();
-
-	/*
-	 * If found in radix tree, then fine.
-	 * Else fallback to linear lookup - this should not happen in practice
-	 * as it means that we failed to insert the node in the radix tree.
-	 */
-	return irq_data ? irq_data->irq : irq_find_mapping(host, hwirq);
-}
-
-void irq_radix_revmap_insert(struct irq_domain *host, unsigned int virq,
-			     irq_hw_number_t hwirq)
-{
-	struct irq_data *irq_data = irq_get_irq_data(virq);
-
-	if (WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
-		return;
-
-	if (virq != NO_IRQ) {
-		mutex_lock(&revmap_trees_mutex);
-		radix_tree_insert(&host->revmap_data.tree, hwirq, irq_data);
-		mutex_unlock(&revmap_trees_mutex);
-	}
-}
-
-unsigned int irq_linear_revmap(struct irq_domain *host,
-			       irq_hw_number_t hwirq)
-{
-	unsigned int *revmap;
-
-	if (WARN_ON_ONCE(host->revmap_type != IRQ_DOMAIN_MAP_LINEAR))
-		return irq_find_mapping(host, hwirq);
-
-	/* Check revmap bounds */
-	if (unlikely(hwirq >= host->revmap_data.linear.size))
-		return irq_find_mapping(host, hwirq);
-
-	/* Check if revmap was allocated */
-	revmap = host->revmap_data.linear.revmap;
-	if (unlikely(revmap == NULL))
-		return irq_find_mapping(host, hwirq);
-
-	/* Fill up revmap with slow path if no mapping found */
-	if (unlikely(revmap[hwirq] == NO_IRQ))
-		revmap[hwirq] = irq_find_mapping(host, hwirq);
-
-	return revmap[hwirq];
-}
-
 int arch_early_irq_init(void)
 {
 	return 0;
 }
 
-#ifdef CONFIG_VIRQ_DEBUG
-static int virq_debug_show(struct seq_file *m, void *private)
-{
-	unsigned long flags;
-	struct irq_desc *desc;
-	const char *p;
-	static const char none[] = "none";
-	void *data;
-	int i;
-
-	seq_printf(m, "%-5s  %-7s  %-15s  %-18s  %s\n", "virq", "hwirq",
-		      "chip name", "chip data", "host name");
-
-	for (i = 1; i < nr_irqs; i++) {
-		desc = irq_to_desc(i);
-		if (!desc)
-			continue;
-
-		raw_spin_lock_irqsave(&desc->lock, flags);
-
-		if (desc->action && desc->action->handler) {
-			struct irq_chip *chip;
-
-			seq_printf(m, "%5d  ", i);
-			seq_printf(m, "0x%05lx  ", desc->irq_data.hwirq);
-
-			chip = irq_desc_get_chip(desc);
-			if (chip && chip->name)
-				p = chip->name;
-			else
-				p = none;
-			seq_printf(m, "%-15s  ", p);
-
-			data = irq_desc_get_chip_data(desc);
-			seq_printf(m, "0x%16p  ", data);
-
-			if (desc->irq_data.domain->of_node)
-				p = desc->irq_data.domain->of_node->full_name;
-			else
-				p = none;
-			seq_printf(m, "%s\n", p);
-		}
-
-		raw_spin_unlock_irqrestore(&desc->lock, flags);
-	}
-
-	return 0;
-}
-
-static int virq_debug_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, virq_debug_show, inode->i_private);
-}
-
-static const struct file_operations virq_debug_fops = {
-	.open = virq_debug_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-static int __init irq_debugfs_init(void)
-{
-	if (debugfs_create_file("virq_mapping", S_IRUGO, powerpc_debugfs_root,
-				 NULL, &virq_debug_fops) == NULL)
-		return -ENOMEM;
-
-	return 0;
-}
-__initcall(irq_debugfs_init);
-#endif /* CONFIG_VIRQ_DEBUG */
-
 #ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {

commit 6d9285b00f776eebe459a858ebf07b56c36c60d2
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Tue Feb 14 14:06:51 2012 -0700

    irq_domain/powerpc: Eliminate virq_is_host()
    
    There is only one user, and it is trivial to open-code.
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Milton Miller <miltonm@bga.com>
    Tested-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 03c95f03d792..269fbd5ac62f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -510,13 +510,6 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
-bool virq_is_host(unsigned int virq, struct irq_domain *host)
-{
-	struct irq_data *irq_data = irq_get_irq_data(virq);
-	return irq_data ? irq_data->domain == host : false;
-}
-EXPORT_SYMBOL_GPL(virq_is_host);
-
 static int default_irq_host_match(struct irq_domain *h, struct device_node *np)
 {
 	return h->of_node != NULL && h->of_node == np;

commit 4bbdd45afdae208a7c4ade89cf602f89a6397cff
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Tue Feb 14 14:06:51 2012 -0700

    irq_domain/powerpc: eliminate irq_map; use irq_alloc_desc() instead
    
    This patch drops the powerpc-specific irq_map table and replaces it with
    directly using the irq_alloc_desc()/irq_free_desc() interfaces for allocating
    and freeing irq_desc structures.
    
    This patch is a preparation step for generalizing the powerpc-specific virq
    infrastructure to become irq_domains.
    
    As part of this change, the irq_big_lock is changed to a mutex from a raw
    spinlock.  There is no longer any need to use a spin lock since the irq_desc
    allocation code is now responsible for the critical section of finding
    an unused range of irq numbers.
    
    The radix lookup table is also changed to store the irq_data pointer instead
    of the irq_map entry since the irq_map is removed.  This should end up being
    functionally equivalent since only allocated irq_descs are ever added to the
    radix tree.
    
    v5: - Really don't ever allocate virq 0.  The previous version could still
          do it if hint == 0
        - Respect irq_virq_count setting for NOMAP.  Some NOMAP domains cannot
          use virq values above irq_virq_count.
        - Use numa_node_id() when allocating irq_descs.  Ideally the API should
          obtain that value from the caller, but that touches a lot of call sites
          so will be deferred to a follow-on patch.
        - Fix irq_find_mapping() to include irq numbers lower than
          NUM_ISA_INTERRUPTS.  With the switch to irq_alloc_desc*(), the lowest
          possible allocated irq is now returned by arch_probe_nr_irqs().
    v4: - Fix incorrect access to irq_data structure in debugfs code
        - Don't ever allocate virq 0
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Milton Miller <miltonm@bga.com>
    Tested-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 7305f2f65534..03c95f03d792 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -491,38 +491,29 @@ void do_softirq(void)
  * IRQ controller and virtual interrupts
  */
 
-/* The main irq map itself is an array of NR_IRQ entries containing the
- * associate host and irq number. An entry with a host of NULL is free.
- * An entry can be allocated if it's free, the allocator always then sets
- * hwirq first to the host's invalid irq number and then fills ops.
- */
-struct irq_map_entry {
-	irq_hw_number_t	hwirq;
-	struct irq_domain	*host;
-};
-
 static LIST_HEAD(irq_domain_list);
-static DEFINE_RAW_SPINLOCK(irq_big_lock);
+static DEFINE_MUTEX(irq_domain_mutex);
 static DEFINE_MUTEX(revmap_trees_mutex);
-static struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_domain *irq_default_host;
 
 irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
 {
-	return irq_map[d->irq].hwirq;
+	return d->hwirq;
 }
 EXPORT_SYMBOL_GPL(irqd_to_hwirq);
 
 irq_hw_number_t virq_to_hw(unsigned int virq)
 {
-	return irq_map[virq].hwirq;
+	struct irq_data *irq_data = irq_get_irq_data(virq);
+	return WARN_ON(!irq_data) ? 0 : irq_data->hwirq;
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
 bool virq_is_host(unsigned int virq, struct irq_domain *host)
 {
-	return irq_map[virq].host == host;
+	struct irq_data *irq_data = irq_get_irq_data(virq);
+	return irq_data ? irq_data->domain == host : false;
 }
 EXPORT_SYMBOL_GPL(virq_is_host);
 
@@ -537,11 +528,10 @@ struct irq_domain *irq_alloc_host(struct device_node *of_node,
 				struct irq_domain_ops *ops,
 				irq_hw_number_t inval_irq)
 {
-	struct irq_domain *host;
+	struct irq_domain *host, *h;
 	unsigned int size = sizeof(struct irq_domain);
 	unsigned int i;
 	unsigned int *rmap;
-	unsigned long flags;
 
 	/* Allocate structure and revmap table if using linear mapping */
 	if (revmap_type == IRQ_DOMAIN_MAP_LINEAR)
@@ -559,23 +549,20 @@ struct irq_domain *irq_alloc_host(struct device_node *of_node,
 	if (host->ops->match == NULL)
 		host->ops->match = default_irq_host_match;
 
-	raw_spin_lock_irqsave(&irq_big_lock, flags);
-
-	/* If it's a legacy controller, check for duplicates and
-	 * mark it as allocated (we use irq 0 host pointer for that
-	 */
+	mutex_lock(&irq_domain_mutex);
+	/* Make sure only one legacy controller can be created */
 	if (revmap_type == IRQ_DOMAIN_MAP_LEGACY) {
-		if (irq_map[0].host != NULL) {
-			raw_spin_unlock_irqrestore(&irq_big_lock, flags);
-			of_node_put(host->of_node);
-			kfree(host);
-			return NULL;
+		list_for_each_entry(h, &irq_domain_list, link) {
+			if (WARN_ON(h->revmap_type == IRQ_DOMAIN_MAP_LEGACY)) {
+				mutex_unlock(&irq_domain_mutex);
+				of_node_put(host->of_node);
+				kfree(host);
+				return NULL;
+			}
 		}
-		irq_map[0].host = host;
 	}
-
 	list_add(&host->link, &irq_domain_list);
-	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
+	mutex_unlock(&irq_domain_mutex);
 
 	/* Additional setups per revmap type */
 	switch(revmap_type) {
@@ -584,10 +571,9 @@ struct irq_domain *irq_alloc_host(struct device_node *of_node,
 		host->inval_irq = 0;
 		/* setup us as the host for all legacy interrupts */
 		for (i = 1; i < NUM_ISA_INTERRUPTS; i++) {
-			irq_map[i].hwirq = i;
-			smp_wmb();
-			irq_map[i].host = host;
-			smp_wmb();
+			struct irq_data *irq_data = irq_get_irq_data(i);
+			irq_data->hwirq = i;
+			irq_data->domain = host;
 
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to
@@ -604,7 +590,6 @@ struct irq_domain *irq_alloc_host(struct device_node *of_node,
 		for (i = 0; i < revmap_arg; i++)
 			rmap[i] = NO_IRQ;
 		host->revmap_data.linear.size = revmap_arg;
-		smp_wmb();
 		host->revmap_data.linear.revmap = rmap;
 		break;
 	case IRQ_DOMAIN_MAP_TREE:
@@ -622,20 +607,19 @@ struct irq_domain *irq_alloc_host(struct device_node *of_node,
 struct irq_domain *irq_find_host(struct device_node *node)
 {
 	struct irq_domain *h, *found = NULL;
-	unsigned long flags;
 
 	/* We might want to match the legacy controller last since
 	 * it might potentially be set to match all interrupts in
 	 * the absence of a device node. This isn't a problem so far
 	 * yet though...
 	 */
-	raw_spin_lock_irqsave(&irq_big_lock, flags);
+	mutex_lock(&irq_domain_mutex);
 	list_for_each_entry(h, &irq_domain_list, link)
 		if (h->ops->match(h, node)) {
 			found = h;
 			break;
 		}
-	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
+	mutex_unlock(&irq_domain_mutex);
 	return found;
 }
 EXPORT_SYMBOL_GPL(irq_find_host);
@@ -659,33 +643,20 @@ void irq_set_virq_count(unsigned int count)
 static int irq_setup_virq(struct irq_domain *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
-	int res;
-
-	res = irq_alloc_desc_at(virq, 0);
-	if (res != virq) {
-		pr_debug("irq: -> allocating desc failed\n");
-		goto error;
-	}
-
-	/* map it */
-	smp_wmb();
-	irq_map[virq].hwirq = hwirq;
-	smp_mb();
+	struct irq_data *irq_data = irq_get_irq_data(virq);
 
+	irq_data->hwirq = hwirq;
+	irq_data->domain = host;
 	if (host->ops->map(host, virq, hwirq)) {
 		pr_debug("irq: -> mapping failed, freeing\n");
-		goto errdesc;
+		irq_data->domain = NULL;
+		irq_data->hwirq = 0;
+		return -1;
 	}
 
 	irq_clear_status_flags(virq, IRQ_NOREQUEST);
 
 	return 0;
-
-errdesc:
-	irq_free_descs(virq, 1);
-error:
-	irq_free_virt(virq, 1);
-	return -1;
 }
 
 unsigned int irq_create_direct_mapping(struct irq_domain *host)
@@ -698,16 +669,24 @@ unsigned int irq_create_direct_mapping(struct irq_domain *host)
 	BUG_ON(host == NULL);
 	WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_NOMAP);
 
-	virq = irq_alloc_virt(host, 1, 0);
+	virq = irq_alloc_desc_from(1, 0);
 	if (virq == NO_IRQ) {
 		pr_debug("irq: create_direct virq allocation failed\n");
 		return NO_IRQ;
 	}
+	if (virq >= irq_virq_count) {
+		pr_err("ERROR: no free irqs available below %i maximum\n",
+			irq_virq_count);
+		irq_free_desc(virq);
+		return 0;
+	}
 
 	pr_debug("irq: create_direct obtained virq %d\n", virq);
 
-	if (irq_setup_virq(host, virq, virq))
+	if (irq_setup_virq(host, virq, virq)) {
+		irq_free_desc(virq);
 		return NO_IRQ;
+	}
 
 	return virq;
 }
@@ -747,15 +726,22 @@ unsigned int irq_create_mapping(struct irq_domain *host,
 	} else {
 		/* Allocate a virtual interrupt number */
 		hint = hwirq % irq_virq_count;
-		virq = irq_alloc_virt(host, 1, hint);
+		if (hint == 0)
+			hint = 1;
+		virq = irq_alloc_desc_from(hint, 0);
+		if (!virq)
+			virq = irq_alloc_desc_from(1, 0);
 		if (virq == NO_IRQ) {
 			pr_debug("irq: -> virq allocation failed\n");
 			return NO_IRQ;
 		}
 	}
 
-	if (irq_setup_virq(host, virq, hwirq))
+	if (irq_setup_virq(host, virq, hwirq)) {
+		if (host->revmap_type != IRQ_DOMAIN_MAP_LEGACY)
+			irq_free_desc(virq);
 		return NO_IRQ;
+	}
 
 	pr_debug("irq: irq %lu on host %s mapped to virtual irq %u\n",
 		hwirq, host->of_node ? host->of_node->full_name : "null", virq);
@@ -806,13 +792,14 @@ EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
 void irq_dispose_mapping(unsigned int virq)
 {
+	struct irq_data *irq_data = irq_get_irq_data(virq);
 	struct irq_domain *host;
 	irq_hw_number_t hwirq;
 
-	if (virq == NO_IRQ)
+	if (virq == NO_IRQ || !irq_data)
 		return;
 
-	host = irq_map[virq].host;
+	host = irq_data->domain;
 	if (WARN_ON(host == NULL))
 		return;
 
@@ -834,7 +821,7 @@ void irq_dispose_mapping(unsigned int virq)
 	smp_mb();
 
 	/* Clear reverse map */
-	hwirq = irq_map[virq].hwirq;
+	hwirq = irq_data->hwirq;
 	switch(host->revmap_type) {
 	case IRQ_DOMAIN_MAP_LINEAR:
 		if (hwirq < host->revmap_data.linear.size)
@@ -848,12 +835,9 @@ void irq_dispose_mapping(unsigned int virq)
 	}
 
 	/* Destroy map */
-	smp_mb();
-	irq_map[virq].hwirq = host->inval_irq;
+	irq_data->hwirq = host->inval_irq;
 
-	irq_free_descs(virq, 1);
-	/* Free it */
-	irq_free_virt(virq, 1);
+	irq_free_desc(virq);
 }
 EXPORT_SYMBOL_GPL(irq_dispose_mapping);
 
@@ -874,16 +858,16 @@ unsigned int irq_find_mapping(struct irq_domain *host,
 		return hwirq;
 
 	/* Slow path does a linear search of the map */
-	if (hint < NUM_ISA_INTERRUPTS)
-		hint = NUM_ISA_INTERRUPTS;
+	if (hint == 0)
+		hint = 1;
 	i = hint;
-	do  {
-		if (irq_map[i].host == host &&
-		    irq_map[i].hwirq == hwirq)
+	do {
+		struct irq_data *data = irq_get_irq_data(i);
+		if (data && (data->domain == host) && (data->hwirq == hwirq))
 			return i;
 		i++;
 		if (i >= irq_virq_count)
-			i = NUM_ISA_INTERRUPTS;
+			i = 1;
 	} while(i != hint);
 	return NO_IRQ;
 }
@@ -928,19 +912,17 @@ int irq_choose_cpu(const struct cpumask *mask)
 unsigned int irq_radix_revmap_lookup(struct irq_domain *host,
 				     irq_hw_number_t hwirq)
 {
-	struct irq_map_entry *ptr;
-	unsigned int virq;
+	struct irq_data *irq_data;
 
 	if (WARN_ON_ONCE(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
 		return irq_find_mapping(host, hwirq);
 
 	/*
-	 * The ptr returned references the static global irq_map.
-	 * but freeing an irq can delete nodes along the path to
+	 * Freeing an irq can delete nodes along the path to
 	 * do the lookup via call_rcu.
 	 */
 	rcu_read_lock();
-	ptr = radix_tree_lookup(&host->revmap_data.tree, hwirq);
+	irq_data = radix_tree_lookup(&host->revmap_data.tree, hwirq);
 	rcu_read_unlock();
 
 	/*
@@ -948,24 +930,20 @@ unsigned int irq_radix_revmap_lookup(struct irq_domain *host,
 	 * Else fallback to linear lookup - this should not happen in practice
 	 * as it means that we failed to insert the node in the radix tree.
 	 */
-	if (ptr)
-		virq = ptr - irq_map;
-	else
-		virq = irq_find_mapping(host, hwirq);
-
-	return virq;
+	return irq_data ? irq_data->irq : irq_find_mapping(host, hwirq);
 }
 
 void irq_radix_revmap_insert(struct irq_domain *host, unsigned int virq,
 			     irq_hw_number_t hwirq)
 {
+	struct irq_data *irq_data = irq_get_irq_data(virq);
+
 	if (WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
 		return;
 
 	if (virq != NO_IRQ) {
 		mutex_lock(&revmap_trees_mutex);
-		radix_tree_insert(&host->revmap_data.tree, hwirq,
-				  &irq_map[virq]);
+		radix_tree_insert(&host->revmap_data.tree, hwirq, irq_data);
 		mutex_unlock(&revmap_trees_mutex);
 	}
 }
@@ -994,86 +972,6 @@ unsigned int irq_linear_revmap(struct irq_domain *host,
 	return revmap[hwirq];
 }
 
-unsigned int irq_alloc_virt(struct irq_domain *host,
-			    unsigned int count,
-			    unsigned int hint)
-{
-	unsigned long flags;
-	unsigned int i, j, found = NO_IRQ;
-
-	if (count == 0 || count > (irq_virq_count - NUM_ISA_INTERRUPTS))
-		return NO_IRQ;
-
-	raw_spin_lock_irqsave(&irq_big_lock, flags);
-
-	/* Use hint for 1 interrupt if any */
-	if (count == 1 && hint >= NUM_ISA_INTERRUPTS &&
-	    hint < irq_virq_count && irq_map[hint].host == NULL) {
-		found = hint;
-		goto hint_found;
-	}
-
-	/* Look for count consecutive numbers in the allocatable
-	 * (non-legacy) space
-	 */
-	for (i = NUM_ISA_INTERRUPTS, j = 0; i < irq_virq_count; i++) {
-		if (irq_map[i].host != NULL)
-			j = 0;
-		else
-			j++;
-
-		if (j == count) {
-			found = i - count + 1;
-			break;
-		}
-	}
-	if (found == NO_IRQ) {
-		raw_spin_unlock_irqrestore(&irq_big_lock, flags);
-		return NO_IRQ;
-	}
- hint_found:
-	for (i = found; i < (found + count); i++) {
-		irq_map[i].hwirq = host->inval_irq;
-		smp_wmb();
-		irq_map[i].host = host;
-	}
-	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
-	return found;
-}
-
-void irq_free_virt(unsigned int virq, unsigned int count)
-{
-	unsigned long flags;
-	unsigned int i;
-
-	WARN_ON (virq < NUM_ISA_INTERRUPTS);
-	WARN_ON (count == 0 || (virq + count) > irq_virq_count);
-
-	if (virq < NUM_ISA_INTERRUPTS) {
-		if (virq + count < NUM_ISA_INTERRUPTS)
-			return;
-		count  =- NUM_ISA_INTERRUPTS - virq;
-		virq = NUM_ISA_INTERRUPTS;
-	}
-
-	if (count > irq_virq_count || virq > irq_virq_count - count) {
-		if (virq > irq_virq_count)
-			return;
-		count = irq_virq_count - virq;
-	}
-
-	raw_spin_lock_irqsave(&irq_big_lock, flags);
-	for (i = virq; i < (virq + count); i++) {
-		struct irq_domain *host;
-
-		host = irq_map[i].host;
-		irq_map[i].hwirq = host->inval_irq;
-		smp_wmb();
-		irq_map[i].host = NULL;
-	}
-	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
-}
-
 int arch_early_irq_init(void)
 {
 	return 0;
@@ -1103,7 +1001,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			struct irq_chip *chip;
 
 			seq_printf(m, "%5d  ", i);
-			seq_printf(m, "0x%05lx  ", irq_map[i].hwirq);
+			seq_printf(m, "0x%05lx  ", desc->irq_data.hwirq);
 
 			chip = irq_desc_get_chip(desc);
 			if (chip && chip->name)
@@ -1115,8 +1013,8 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			data = irq_desc_get_chip_data(desc);
 			seq_printf(m, "0x%16p  ", data);
 
-			if (irq_map[i].host && irq_map[i].host->of_node)
-				p = irq_map[i].host->of_node->full_name;
+			if (desc->irq_data.domain->of_node)
+				p = desc->irq_data.domain->of_node->full_name;
 			else
 				p = none;
 			seq_printf(m, "%s\n", p);

commit bae1d8f19983fbfa25559aa3cb6a81a84aa82a18
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Tue Feb 14 14:06:50 2012 -0700

    irq_domain/powerpc: Use common irq_domain structure instead of irq_host
    
    This patch drops the powerpc-specific irq_host structures and uses the common
    irq_domain strucutres defined in linux/irqdomain.h.  It also fixes all
    the users to use the new structure names.
    
    Renaming irq_host to irq_domain has been discussed for a long time, and this
    patch is a step in the process of generalizing the powerpc virq code to be
    usable by all architecture.
    
    An astute reader will notice that this patch actually removes the irq_host
    structure instead of renaming it.  This is because the irq_domain structure
    already exists in include/linux/irqdomain.h and has the needed data members.
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Milton Miller <miltonm@bga.com>
    Tested-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 701d4aceb4f4..7305f2f65534 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -498,15 +498,15 @@ void do_softirq(void)
  */
 struct irq_map_entry {
 	irq_hw_number_t	hwirq;
-	struct irq_host	*host;
+	struct irq_domain	*host;
 };
 
-static LIST_HEAD(irq_hosts);
+static LIST_HEAD(irq_domain_list);
 static DEFINE_RAW_SPINLOCK(irq_big_lock);
 static DEFINE_MUTEX(revmap_trees_mutex);
 static struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
-static struct irq_host *irq_default_host;
+static struct irq_domain *irq_default_host;
 
 irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
 {
@@ -520,31 +520,31 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
-bool virq_is_host(unsigned int virq, struct irq_host *host)
+bool virq_is_host(unsigned int virq, struct irq_domain *host)
 {
 	return irq_map[virq].host == host;
 }
 EXPORT_SYMBOL_GPL(virq_is_host);
 
-static int default_irq_host_match(struct irq_host *h, struct device_node *np)
+static int default_irq_host_match(struct irq_domain *h, struct device_node *np)
 {
 	return h->of_node != NULL && h->of_node == np;
 }
 
-struct irq_host *irq_alloc_host(struct device_node *of_node,
+struct irq_domain *irq_alloc_host(struct device_node *of_node,
 				unsigned int revmap_type,
 				unsigned int revmap_arg,
-				struct irq_host_ops *ops,
+				struct irq_domain_ops *ops,
 				irq_hw_number_t inval_irq)
 {
-	struct irq_host *host;
-	unsigned int size = sizeof(struct irq_host);
+	struct irq_domain *host;
+	unsigned int size = sizeof(struct irq_domain);
 	unsigned int i;
 	unsigned int *rmap;
 	unsigned long flags;
 
 	/* Allocate structure and revmap table if using linear mapping */
-	if (revmap_type == IRQ_HOST_MAP_LINEAR)
+	if (revmap_type == IRQ_DOMAIN_MAP_LINEAR)
 		size += revmap_arg * sizeof(unsigned int);
 	host = kzalloc(size, GFP_KERNEL);
 	if (host == NULL)
@@ -564,7 +564,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	/* If it's a legacy controller, check for duplicates and
 	 * mark it as allocated (we use irq 0 host pointer for that
 	 */
-	if (revmap_type == IRQ_HOST_MAP_LEGACY) {
+	if (revmap_type == IRQ_DOMAIN_MAP_LEGACY) {
 		if (irq_map[0].host != NULL) {
 			raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 			of_node_put(host->of_node);
@@ -574,12 +574,12 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 		irq_map[0].host = host;
 	}
 
-	list_add(&host->link, &irq_hosts);
+	list_add(&host->link, &irq_domain_list);
 	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 
 	/* Additional setups per revmap type */
 	switch(revmap_type) {
-	case IRQ_HOST_MAP_LEGACY:
+	case IRQ_DOMAIN_MAP_LEGACY:
 		/* 0 is always the invalid number for legacy */
 		host->inval_irq = 0;
 		/* setup us as the host for all legacy interrupts */
@@ -599,7 +599,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 			irq_clear_status_flags(i, IRQ_NOREQUEST);
 		}
 		break;
-	case IRQ_HOST_MAP_LINEAR:
+	case IRQ_DOMAIN_MAP_LINEAR:
 		rmap = (unsigned int *)(host + 1);
 		for (i = 0; i < revmap_arg; i++)
 			rmap[i] = NO_IRQ;
@@ -607,7 +607,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 		smp_wmb();
 		host->revmap_data.linear.revmap = rmap;
 		break;
-	case IRQ_HOST_MAP_TREE:
+	case IRQ_DOMAIN_MAP_TREE:
 		INIT_RADIX_TREE(&host->revmap_data.tree, GFP_KERNEL);
 		break;
 	default:
@@ -619,9 +619,9 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	return host;
 }
 
-struct irq_host *irq_find_host(struct device_node *node)
+struct irq_domain *irq_find_host(struct device_node *node)
 {
-	struct irq_host *h, *found = NULL;
+	struct irq_domain *h, *found = NULL;
 	unsigned long flags;
 
 	/* We might want to match the legacy controller last since
@@ -630,7 +630,7 @@ struct irq_host *irq_find_host(struct device_node *node)
 	 * yet though...
 	 */
 	raw_spin_lock_irqsave(&irq_big_lock, flags);
-	list_for_each_entry(h, &irq_hosts, link)
+	list_for_each_entry(h, &irq_domain_list, link)
 		if (h->ops->match(h, node)) {
 			found = h;
 			break;
@@ -640,7 +640,7 @@ struct irq_host *irq_find_host(struct device_node *node)
 }
 EXPORT_SYMBOL_GPL(irq_find_host);
 
-void irq_set_default_host(struct irq_host *host)
+void irq_set_default_host(struct irq_domain *host)
 {
 	pr_debug("irq: Default host set to @0x%p\n", host);
 
@@ -656,7 +656,7 @@ void irq_set_virq_count(unsigned int count)
 		irq_virq_count = count;
 }
 
-static int irq_setup_virq(struct irq_host *host, unsigned int virq,
+static int irq_setup_virq(struct irq_domain *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
 	int res;
@@ -688,7 +688,7 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 	return -1;
 }
 
-unsigned int irq_create_direct_mapping(struct irq_host *host)
+unsigned int irq_create_direct_mapping(struct irq_domain *host)
 {
 	unsigned int virq;
 
@@ -696,7 +696,7 @@ unsigned int irq_create_direct_mapping(struct irq_host *host)
 		host = irq_default_host;
 
 	BUG_ON(host == NULL);
-	WARN_ON(host->revmap_type != IRQ_HOST_MAP_NOMAP);
+	WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_NOMAP);
 
 	virq = irq_alloc_virt(host, 1, 0);
 	if (virq == NO_IRQ) {
@@ -712,7 +712,7 @@ unsigned int irq_create_direct_mapping(struct irq_host *host)
 	return virq;
 }
 
-unsigned int irq_create_mapping(struct irq_host *host,
+unsigned int irq_create_mapping(struct irq_domain *host,
 				irq_hw_number_t hwirq)
 {
 	unsigned int virq, hint;
@@ -738,7 +738,7 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	}
 
 	/* Get a virtual interrupt number */
-	if (host->revmap_type == IRQ_HOST_MAP_LEGACY) {
+	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY) {
 		/* Handle legacy */
 		virq = (unsigned int)hwirq;
 		if (virq == 0 || virq >= NUM_ISA_INTERRUPTS)
@@ -767,7 +767,7 @@ EXPORT_SYMBOL_GPL(irq_create_mapping);
 unsigned int irq_create_of_mapping(struct device_node *controller,
 				   const u32 *intspec, unsigned int intsize)
 {
-	struct irq_host *host;
+	struct irq_domain *host;
 	irq_hw_number_t hwirq;
 	unsigned int type = IRQ_TYPE_NONE;
 	unsigned int virq;
@@ -806,7 +806,7 @@ EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
 void irq_dispose_mapping(unsigned int virq)
 {
-	struct irq_host *host;
+	struct irq_domain *host;
 	irq_hw_number_t hwirq;
 
 	if (virq == NO_IRQ)
@@ -817,7 +817,7 @@ void irq_dispose_mapping(unsigned int virq)
 		return;
 
 	/* Never unmap legacy interrupts */
-	if (host->revmap_type == IRQ_HOST_MAP_LEGACY)
+	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY)
 		return;
 
 	irq_set_status_flags(virq, IRQ_NOREQUEST);
@@ -836,11 +836,11 @@ void irq_dispose_mapping(unsigned int virq)
 	/* Clear reverse map */
 	hwirq = irq_map[virq].hwirq;
 	switch(host->revmap_type) {
-	case IRQ_HOST_MAP_LINEAR:
+	case IRQ_DOMAIN_MAP_LINEAR:
 		if (hwirq < host->revmap_data.linear.size)
 			host->revmap_data.linear.revmap[hwirq] = NO_IRQ;
 		break;
-	case IRQ_HOST_MAP_TREE:
+	case IRQ_DOMAIN_MAP_TREE:
 		mutex_lock(&revmap_trees_mutex);
 		radix_tree_delete(&host->revmap_data.tree, hwirq);
 		mutex_unlock(&revmap_trees_mutex);
@@ -857,7 +857,7 @@ void irq_dispose_mapping(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(irq_dispose_mapping);
 
-unsigned int irq_find_mapping(struct irq_host *host,
+unsigned int irq_find_mapping(struct irq_domain *host,
 			      irq_hw_number_t hwirq)
 {
 	unsigned int i;
@@ -870,7 +870,7 @@ unsigned int irq_find_mapping(struct irq_host *host,
 		return NO_IRQ;
 
 	/* legacy -> bail early */
-	if (host->revmap_type == IRQ_HOST_MAP_LEGACY)
+	if (host->revmap_type == IRQ_DOMAIN_MAP_LEGACY)
 		return hwirq;
 
 	/* Slow path does a linear search of the map */
@@ -925,13 +925,13 @@ int irq_choose_cpu(const struct cpumask *mask)
 }
 #endif
 
-unsigned int irq_radix_revmap_lookup(struct irq_host *host,
+unsigned int irq_radix_revmap_lookup(struct irq_domain *host,
 				     irq_hw_number_t hwirq)
 {
 	struct irq_map_entry *ptr;
 	unsigned int virq;
 
-	if (WARN_ON_ONCE(host->revmap_type != IRQ_HOST_MAP_TREE))
+	if (WARN_ON_ONCE(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
 		return irq_find_mapping(host, hwirq);
 
 	/*
@@ -956,10 +956,10 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 	return virq;
 }
 
-void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
+void irq_radix_revmap_insert(struct irq_domain *host, unsigned int virq,
 			     irq_hw_number_t hwirq)
 {
-	if (WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE))
+	if (WARN_ON(host->revmap_type != IRQ_DOMAIN_MAP_TREE))
 		return;
 
 	if (virq != NO_IRQ) {
@@ -970,12 +970,12 @@ void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
 	}
 }
 
-unsigned int irq_linear_revmap(struct irq_host *host,
+unsigned int irq_linear_revmap(struct irq_domain *host,
 			       irq_hw_number_t hwirq)
 {
 	unsigned int *revmap;
 
-	if (WARN_ON_ONCE(host->revmap_type != IRQ_HOST_MAP_LINEAR))
+	if (WARN_ON_ONCE(host->revmap_type != IRQ_DOMAIN_MAP_LINEAR))
 		return irq_find_mapping(host, hwirq);
 
 	/* Check revmap bounds */
@@ -994,7 +994,7 @@ unsigned int irq_linear_revmap(struct irq_host *host,
 	return revmap[hwirq];
 }
 
-unsigned int irq_alloc_virt(struct irq_host *host,
+unsigned int irq_alloc_virt(struct irq_domain *host,
 			    unsigned int count,
 			    unsigned int hint)
 {
@@ -1064,7 +1064,7 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 
 	raw_spin_lock_irqsave(&irq_big_lock, flags);
 	for (i = virq; i < (virq + count); i++) {
-		struct irq_host *host;
+		struct irq_domain *host;
 
 		host = irq_map[i].host;
 		irq_map[i].hwirq = host->inval_irq;

commit 6fe5f5f3ffade25aa94526010f219df3be521bf7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Feb 8 19:34:13 2012 +0000

    powerpc: Fix WARN_ON in decrementer_check_overflow
    
    We use __get_cpu_var() which triggers a false positive warning
    in smp_processor_id() thinking interrupts are enabled (at this
    point, they are soft-enabled but hard-disabled).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 701d4aceb4f4..01e2877e8e04 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -118,10 +118,14 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 static inline notrace void decrementer_check_overflow(void)
 {
 	u64 now = get_tb_or_rtc();
-	u64 *next_tb = &__get_cpu_var(decrementers_next_tb);
+	u64 *next_tb;
+
+	preempt_disable();
+	next_tb = &__get_cpu_var(decrementers_next_tb);
 
 	if (now >= *next_tb)
 		set_dec(1);
+	preempt_enable();
 }
 
 notrace void arch_local_irq_restore(unsigned long en)

commit 816cb49a4baf0e4b27730bcc31e5d35a1eadd283
Author: Geoff Levand <geoff@infradead.org>
Date:   Tue Nov 29 15:38:50 2011 +0000

    powerpc/ps3: Fix hcall lv1_get_version_info
    
    The lv1_get_version_info hcall takes 2, not 1 output
    arguments.  Adjust the lv1 hcall table and all calls.
    
    Usage:
    
      int lv1_get_version_info(u64 *version_number, u64 *vendor_id)
    
    Signed-off-by: Geoff Levand <geoff@infradead.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2ff4f5e59620..701d4aceb4f4 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -186,8 +186,8 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 * Any HV call will have this side effect.
 	 */
 	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
-		u64 tmp;
-		lv1_get_version_info(&tmp);
+		u64 tmp, tmp2;
+		lv1_get_version_info(&tmp, &tmp2);
 	}
 
 	__hard_irq_enable();

commit 7df1027542c9353bef4d027cb4ab8e99f69017b7
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 23 20:07:22 2011 +0000

    powerpc/time: Optimise decrementer_check_overflow
    
    decrementer_check_overflow is called from arch_local_irq_restore so
    we want to make it as light weight as possible. As such, turn
    decrementer_check_overflow into an inline function.
    
    To avoid a circular mess of includes, separate out the two components
    of struct decrementer_clock and keep the struct clock_event_device
    part local to time.c.
    
    The fast path improves from:
    
    arch_local_irq_restore
         0:       mflr    r0
         4:       std     r0,16(r1)
         8:       stdu    r1,-112(r1)
         c:       stb     r3,578(r13)
        10:       cmpdi   cr7,r3,0
        14:       beq-    cr7,24 <.arch_local_irq_restore+0x24>
    ...
        24:       addi    r1,r1,112
        28:       ld      r0,16(r1)
        2c:       mtlr    r0
        30:       blr
    
    to:
    
    arch_local_irq_restore
        0:       std     r30,-16(r1)
        4:       ld      r30,0(r2)
        8:       stb     r3,578(r13)
        c:       cmpdi   cr7,r3,0
       10:       beq-    cr7,6c <.arch_local_irq_restore+0x6c>
    ...
       6c:       ld      r30,-16(r1)
       70:       blr
    
    Unfortunately we still setup a local TOC (due to -mminimal-toc). Yet
    another sign we should be moving to -mcmodel=medium.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 745c1e7c10fd..2ff4f5e59620 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -115,6 +115,15 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
+static inline notrace void decrementer_check_overflow(void)
+{
+	u64 now = get_tb_or_rtc();
+	u64 *next_tb = &__get_cpu_var(decrementers_next_tb);
+
+	if (now >= *next_tb)
+		set_dec(1);
+}
+
 notrace void arch_local_irq_restore(unsigned long en)
 {
 	/*

commit 37fb9a0231ee43d42d069863bdfd567fca2b61af
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Nov 23 20:07:17 2011 +0000

    powerpc/time: Handle wrapping of decrementer
    
    When re-enabling interrupts we have code to handle edge sensitive
    decrementers by resetting the decrementer to 1 whenever it is negative.
    If interrupts were disabled long enough that the decrementer wrapped to
    positive we do nothing. This means interrupts can be delayed for a long
    time until it finally goes negative again.
    
    While we hope interrupts are never be disabled long enough for the
    decrementer to go positive, we have a very good test team that can
    drive any kernel into the ground. The softlockup data we get back
    from these fails could be seconds in the future, completely missing
    the cause of the lockup.
    
    We already keep track of the timebase of the next event so use that
    to work out if we should trigger a decrementer exception.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Cc: stable@kernel.org
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5c3c46948d94..745c1e7c10fd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -164,16 +164,13 @@ notrace void arch_local_irq_restore(unsigned long en)
 	 */
 	local_paca->hard_enabled = en;
 
-#ifndef CONFIG_BOOKE
-	/* On server, re-trigger the decrementer if it went negative since
-	 * some processors only trigger on edge transitions of the sign bit.
-	 *
-	 * BookE has a level sensitive decrementer (latches in TSR) so we
-	 * don't need that
+	/*
+	 * Trigger the decrementer if we have a pending event. Some processors
+	 * only trigger on edge transitions of the sign bit. We might also
+	 * have disabled interrupts long enough that the decrementer wrapped
+	 * to positive.
 	 */
-	if ((int)mfspr(SPRN_DEC) < 0)
-		mtspr(SPRN_DEC, 1);
-#endif /* CONFIG_BOOKE */
+	decrementer_check_overflow();
 
 	/*
 	 * Force the delivery of pending soft-disabled interrupts on PS3.

commit 4b16f8e2d6d64249f0ed3ca7fe2a319d0dde2719
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri Jul 22 18:24:23 2011 -0400

    powerpc: various straight conversions from module.h --> export.h
    
    All these files were including module.h just for the basic
    EXPORT_SYMBOL infrastructure.  We can shift them off to the
    export.h header which is a way smaller footprint and thus
    realize some compile time gains.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d281fb6f12f3..5c3c46948d94 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -30,7 +30,7 @@
 
 #undef DEBUG
 
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/threads.h>
 #include <linux/kernel_stat.h>
 #include <linux/signal.h>

commit 50d2a4223bb875d1e3a7ee97d40dd03bf31ce1b7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 18 17:17:22 2011 +0000

    powerpc: Copy back TIF flags on return from softirq stack
    
    We already did it for hard IRQs but it looks like we forgot
    to do it for softirqs. Without this, we would lose flags
    such as TIF_NEED_RESCHED set using current_thread_info()
    by something running of a softirq.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 346cc4a396fe..d281fb6f12f3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -451,11 +451,18 @@ static inline void do_softirq_onstack(void)
 	curtp = current_thread_info();
 	irqtp = softirq_ctx[smp_processor_id()];
 	irqtp->task = curtp->task;
+	irqtp->flags = 0;
 	current->thread.ksp_limit = (unsigned long)irqtp +
 				    _ALIGN_UP(sizeof(struct thread_info), 16);
 	call_do_softirq(irqtp);
 	current->thread.ksp_limit = saved_sp_limit;
 	irqtp->task = NULL;
+
+	/* Set any flag that may have been set on the
+	 * alternate stack
+	 */
+	if (irqtp->flags)
+		set_bits(irqtp->flags, &curtp->flags);
 }
 
 void do_softirq(void)

commit 88962934226c570717c346684ab5ed2f09c2b359
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Jul 7 20:35:38 2011 +0000

    powerpc/irq: Quieten irq mapping printks
    
    HFI creates interrupts each time a window is setup. This results in
    a lot of messages in the kernel log buffer:
    
        irq: irq 199007 on host null mapped to virtual irq 351
    
    This box has over 3500 of them, causing more important kernel
    messages to be overwritten. We can get at this information via
    debugfs now so we may as well turn it into a pr_debug.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 164fb6ca692e..346cc4a396fe 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -744,7 +744,7 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	if (irq_setup_virq(host, virq, hwirq))
 		return NO_IRQ;
 
-	printk(KERN_DEBUG "irq: irq %lu on host %s mapped to virtual irq %u\n",
+	pr_debug("irq: irq %lu on host %s mapped to virtual irq %u\n",
 		hwirq, host->of_node ? host->of_node->full_name : "null", virq);
 
 	return virq;

commit 3d97a619acbb2c8a7a9a7da08c2d3041dfdd241f
Author: Scott Wood <scottwood@freescale.com>
Date:   Wed Jun 22 11:19:49 2011 +0000

    powerpc/book3e-64: Reraise doorbell when masked by soft-irq-disable
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 38dd10e2841d..164fb6ca692e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -157,12 +157,6 @@ notrace void arch_local_irq_restore(unsigned long en)
 	if (get_hard_enabled())
 		return;
 
-#if defined(CONFIG_BOOKE) && defined(CONFIG_SMP)
-	/* Check for pending doorbell interrupts and resend to ourself */
-	if (cpu_has_feature(CPU_FTR_DBELL))
-		smp_muxed_ipi_resend();
-#endif
-
 	/*
 	 * Need to hard-enable interrupts here.  Since currently disabled,
 	 * no need to take further asm precautions against preemption; but

commit 6ec36b5848a8336d3a0010727b9365c3254d2d2e
Author: Stuart Yoder <stuart.yoder@freescale.com>
Date:   Thu May 19 08:54:26 2011 -0500

    powerpc: make irq_choose_cpu() available to all PIC drivers
    
    Move irq_choose_cpu() into arch/powerpc/kernel/irq.c so that it can be used
    by other PIC drivers.  The function is not MPIC-specific.
    
    Signed-off-by: Stuart Yoder <stuart.yoder@freescale.com>
    Signed-off-by: Timur Tabi <timur@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5b428e308666..38dd10e2841d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -882,6 +882,41 @@ unsigned int irq_find_mapping(struct irq_host *host,
 }
 EXPORT_SYMBOL_GPL(irq_find_mapping);
 
+#ifdef CONFIG_SMP
+int irq_choose_cpu(const struct cpumask *mask)
+{
+	int cpuid;
+
+	if (cpumask_equal(mask, cpu_all_mask)) {
+		static int irq_rover;
+		static DEFINE_RAW_SPINLOCK(irq_rover_lock);
+		unsigned long flags;
+
+		/* Round-robin distribution... */
+do_round_robin:
+		raw_spin_lock_irqsave(&irq_rover_lock, flags);
+
+		irq_rover = cpumask_next(irq_rover, cpu_online_mask);
+		if (irq_rover >= nr_cpu_ids)
+			irq_rover = cpumask_first(cpu_online_mask);
+
+		cpuid = irq_rover;
+
+		raw_spin_unlock_irqrestore(&irq_rover_lock, flags);
+	} else {
+		cpuid = cpumask_first_and(mask, cpu_online_mask);
+		if (cpuid >= nr_cpu_ids)
+			goto do_round_robin;
+	}
+
+	return get_hard_smp_processor_id(cpuid);
+}
+#else
+int irq_choose_cpu(const struct cpumask *mask)
+{
+	return hard_smp_processor_id();
+}
+#endif
 
 unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 				     irq_hw_number_t hwirq)

commit 4dd602900196bcc00505485e2a363caec4f3fd93
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:18 2011 +0000

    powerpc: Fix irq_free_virt by adjusting bounds before loop
    
    Instead of looping over each irq and checking against the irq array
    bounds, adjust the bounds before looping.
    
    The old code will not free any irq if the irq + count is above
    irq_virq_count because the test in the loop is testing irq + count
    instead of irq + i.
    
    This code checks the limits to avoid unsigned integer overflows.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6cb3fcd7fc37..5b428e308666 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1007,14 +1007,23 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 	WARN_ON (virq < NUM_ISA_INTERRUPTS);
 	WARN_ON (count == 0 || (virq + count) > irq_virq_count);
 
+	if (virq < NUM_ISA_INTERRUPTS) {
+		if (virq + count < NUM_ISA_INTERRUPTS)
+			return;
+		count  =- NUM_ISA_INTERRUPTS - virq;
+		virq = NUM_ISA_INTERRUPTS;
+	}
+
+	if (count > irq_virq_count || virq > irq_virq_count - count) {
+		if (virq > irq_virq_count)
+			return;
+		count = irq_virq_count - virq;
+	}
+
 	raw_spin_lock_irqsave(&irq_big_lock, flags);
 	for (i = virq; i < (virq + count); i++) {
 		struct irq_host *host;
 
-		if (i < NUM_ISA_INTERRUPTS ||
-		    (virq + count) > irq_virq_count)
-			continue;
-
 		host = irq_map[i].host;
 		irq_map[i].hwirq = host->inval_irq;
 		smp_wmb();

commit 9b7882515864117d0015a3484c0ba0eee6713de9
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:18 2011 +0000

    powerpc/irq: Protect irq_radix_revmap_lookup against irq_free_virt
    
    The radix-tree code uses call_rcu when freeing internal elements.
    We must protect against the elements being freed while we traverse
    the tree, even if the returned pointer will still be valid.
    
    While preparing a patch to expand the context in which
    irq_radix_revmap_lookup will be called, I realized that the
    radix tree was not locked.
    
    When asked
    
        For a normal call_rcu usage, is it allowed to read the structure in
        irq_enter / irq_exit, without additional rcu_read_lock?  Could an
        element freed with call_rcu advance with the cpu still between
        irq_enter/irq_exit (and irq_disabled())?
    
    Paul McKenney replied:
    
        Absolutely illegal to do so. OK for call_rcu_sched(), but a
        flaming bug for call_rcu().
    
        And thank you very much for finding this!!!
    
    Further analysis:
    
    In the current CONFIG_TREE_RCU implementation. CONFIG_TREE_PREEMPT_RCU
    (and CONFIG_TINY_PREEMPT_RCU) uses explicit counters.
    
    These counters are reflected from per-CPU to global in the
    scheduling-clock-interrupt handler, so disabling irq does prevent the
    grace period from completing. But there are real-time implementations
    (such as the one use by the Concurrent guys) where disabling irq
    does -not- prevent the grace period from completing.
    
    While an alternative fix would be to switch radix-tree to rcu_sched, I
    don't want to audit the other users of radix trees (nor put alternative
    freeing in the library).  The normal overhead for rcu_read_lock and
    unlock are a local counter increment and decrement.
    
    This does not show up in the rcu lockdep because in 2.6.34 commit
    2676a58c98 (radix-tree: Disable RCU lockdep checking in radix tree)
    deemed it too hard to pass the condition of the protecting lock
    to the library.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ac4d29119f3e..6cb3fcd7fc37 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -893,10 +893,13 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 		return irq_find_mapping(host, hwirq);
 
 	/*
-	 * No rcu_read_lock(ing) needed, the ptr returned can't go under us
-	 * as it's referencing an entry in the static irq_map table.
+	 * The ptr returned references the static global irq_map.
+	 * but freeing an irq can delete nodes along the path to
+	 * do the lookup via call_rcu.
 	 */
+	rcu_read_lock();
 	ptr = radix_tree_lookup(&host->revmap_data.tree, hwirq);
+	rcu_read_unlock();
 
 	/*
 	 * If found in radix tree, then fine.

commit 2e455257d143f54b44701e947a092d513889d01c
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:18 2011 +0000

    powerpc/irq: Check desc in handle_one_irq and expand generic_handle_irq
    
    Look up the descriptor and check that it is found in handle_one_irq
    before checking if we are on the irq stack, and call the handler
    directly using the descriptor if we are on the stack.
    
    We need check irq_to_desc finds the descriptor to avoid a NULL
    pointer dereference.  It could have failed because the number from
    ppc_md.get_irq was above NR_IRQS, or various exceptional conditions
    with sparse irqs (eg race conditions while freeing an irq if its was
    not shutdown in the controller).
    
    fe12bc2c99 (genirq: Uninline and sanity check generic_handle_irq())
    moved generic_handle_irq out of line to allow its use by interrupt
    controllers in modules.  However, handle_one_irq is core arch code.
    It already knows the details of struct irq_desc and handling irqs in
    the nested irq case.  This will avoid the extra stack frame to return
    the value we don't check.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0df255414836..ac4d29119f3e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -295,17 +295,20 @@ static inline void handle_one_irq(unsigned int irq)
 	unsigned long saved_sp_limit;
 	struct irq_desc *desc;
 
+	desc = irq_to_desc(irq);
+	if (!desc)
+		return;
+
 	/* Switch to the irq stack to handle this */
 	curtp = current_thread_info();
 	irqtp = hardirq_ctx[smp_processor_id()];
 
 	if (curtp == irqtp) {
 		/* We're already on the irq stack, just handle it */
-		generic_handle_irq(irq);
+		desc->handle_irq(irq, desc);
 		return;
 	}
 
-	desc = irq_to_desc(irq);
 	saved_sp_limit = current->thread.ksp_limit;
 
 	irqtp->task = curtp->task;

commit 3d1b5e206a4f0ce46f2aa138590738c5d8e118ac
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:17 2011 +0000

    powerpc/irq: Always free duplicate IRQ_LEGACY hosts
    
    Since kmem caches are allocated before init_IRQ as noted in 3af259d155
    (powerpc: Radix trees are available before init_IRQ), we now call
    kmalloc in all cases and can can always call kfree if we are asked
    to allocate a duplicate or conflicting IRQ_HOST_MAP_LEGACY host.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f2fd6539d8bf..0df255414836 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -557,15 +557,8 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	if (revmap_type == IRQ_HOST_MAP_LEGACY) {
 		if (irq_map[0].host != NULL) {
 			raw_spin_unlock_irqrestore(&irq_big_lock, flags);
-			/* If we are early boot, we can't free the structure,
-			 * too bad...
-			 * this will be fixed once slab is made available early
-			 * instead of the current cruft
-			 */
-			if (mem_init_done) {
-				of_node_put(host->of_node);
-				kfree(host);
-			}
+			of_node_put(host->of_node);
+			kfree(host);
 			return NULL;
 		}
 		irq_map[0].host = host;

commit 8142f032a90680ed2fb080ca694ffe9509276361
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:18 2011 +0000

    powerpc/irq: Remove stale and misleading comment
    
    The comment claims we will call host->ops->map() to update the flags if
    we find a previously established mapping, but we never did.  We used
    to call remap, but that call was removed in da05198002 (powerpc: Remove
    irq_host_ops->remap hook).
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a24d37d4cf51..f2fd6539d8bf 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -727,9 +727,7 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	}
 	pr_debug("irq: -> using host @%p\n", host);
 
-	/* Check if mapping already exist, if it does, call
-	 * host->ops->map() to update the flags
-	 */
+	/* Check if mapping already exists */
 	virq = irq_find_mapping(host, hwirq);
 	if (virq != NO_IRQ) {
 		pr_debug("irq: -> existing mapping on virq %d\n", virq);

commit 41fb5e62604c5ddd00a784ffb7672dd8df5d76f2
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:30:44 2011 +0000

    powerpc: Make IRQ_NOREQUEST last to clear, first to set
    
    When creating an irq, don't allow a concurent driver request until
    we have caled map, which will likley call set_chip_and_handler to
    change the irq_chip and its operations.
    
    Similarly, when tearing down an IRQ, make sure no new uses come
    along while we change the irq back to the nop chip and then reset
    the descriptor to freed status.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4368b5ed5604..a24d37d4cf51 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -586,14 +586,14 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 			irq_map[i].host = host;
 			smp_wmb();
 
-			/* Clear norequest flags */
-			irq_clear_status_flags(i, IRQ_NOREQUEST);
-
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to
 			 * explicitly change them
 			 */
 			ops->map(host, i, i);
+
+			/* Clear norequest flags */
+			irq_clear_status_flags(i, IRQ_NOREQUEST);
 		}
 		break;
 	case IRQ_HOST_MAP_LINEAR:
@@ -664,8 +664,6 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 		goto error;
 	}
 
-	irq_clear_status_flags(virq, IRQ_NOREQUEST);
-
 	/* map it */
 	smp_wmb();
 	irq_map[virq].hwirq = hwirq;
@@ -676,6 +674,8 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 		goto errdesc;
 	}
 
+	irq_clear_status_flags(virq, IRQ_NOREQUEST);
+
 	return 0;
 
 errdesc:
@@ -819,6 +819,8 @@ void irq_dispose_mapping(unsigned int virq)
 	if (host->revmap_type == IRQ_HOST_MAP_LEGACY)
 		return;
 
+	irq_set_status_flags(virq, IRQ_NOREQUEST);
+
 	/* remove chip and handler */
 	irq_set_chip_and_handler(virq, NULL, NULL);
 
@@ -848,8 +850,6 @@ void irq_dispose_mapping(unsigned int virq)
 	smp_mb();
 	irq_map[virq].hwirq = host->inval_irq;
 
-	irq_set_status_flags(virq, IRQ_NOREQUEST);
-
 	irq_free_descs(virq, 1);
 	/* Free it */
 	irq_free_virt(virq, 1);

commit 1e8c23013ed0d535e531b3b9cc30200e884f3ff0
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:30:40 2011 +0000

    powerpc: Remove virq_to_host
    
    The only references to the irq_map[].host field are internal to
    arch/powerpc/kernel/irq.c
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 73cf29078fef..4368b5ed5604 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -516,12 +516,6 @@ bool virq_is_host(unsigned int virq, struct irq_host *host)
 }
 EXPORT_SYMBOL_GPL(virq_is_host);
 
-struct irq_host *virq_to_host(unsigned int virq)
-{
-	return irq_map[virq].host;
-}
-EXPORT_SYMBOL_GPL(virq_to_host);
-
 static int default_irq_host_match(struct irq_host *h, struct device_node *np)
 {
 	return h->of_node != NULL && h->of_node == np;

commit 3ee62d365b519c0c18c774049efcde84fe51c60c
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:30:36 2011 +0000

    powerpc: Add virq_is_host to reduce virq_to_host usage
    
    Some irq_host implementations are using virq_to_host to check if
    they are the irq_host for a virtual irq.  To allow us to make space
    versus time tradeoffs, replace this usage with an assertive
    virq_is_host that confirms or denies the irq is associated with the
    given irq_host.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0715a09a4101..73cf29078fef 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -510,6 +510,12 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
+bool virq_is_host(unsigned int virq, struct irq_host *host)
+{
+	return irq_map[virq].host == host;
+}
+EXPORT_SYMBOL_GPL(virq_is_host);
+
 struct irq_host *virq_to_host(unsigned int virq)
 {
 	return irq_map[virq].host;

commit da0519800260a3c791b4fe3317a0c7560027a372
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:30:26 2011 +0000

    powerpc: Remove irq_host_ops->remap hook
    
    It was called from irq_create_mapping if that was called for a host
    and hwirq that was previously mapped, "to update the flags".  But the
    only implementation was in beat_interrupt and all it did was repeat a
    hypervisor call without error checking that was performed with error
    checking at the beginning of the map hook.  In addition, the comment on
    the beat remap hook says it will only called once for a given mapping,
    which would apply to map not remap.
    
    All flags should be known by the time the match hook is called, before
    we call the map hook.  Removing this mostly unused hook will simpify
    the requirements of irq_domain concept.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4a5aa8ca97a5..0715a09a4101 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -732,8 +732,6 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	 */
 	virq = irq_find_mapping(host, hwirq);
 	if (virq != NO_IRQ) {
-		if (host->ops->remap)
-			host->ops->remap(host, virq, hwirq);
 		pr_debug("irq: -> existing mapping on virq %d\n", virq);
 		return virq;
 	}

commit 2d441681a4df7822e6ef6fcc0320bb14d2a06dbb
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:57 2011 +0000

    powerpc: Return early if irq_host lookup type is wrong
    
    If for some reason the code incrorectly calls the wrong function to
    manage the revmap, not only should we warn, we should take action.
    However, in the paths we expect to be taken every delivered interrupt
    change to WARN_ON_ONCE.  Use the if (WARN_ON(x)) format to get the
    unlikely for free.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Reviewed-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f42e869ee3cc..4a5aa8ca97a5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -814,8 +814,7 @@ void irq_dispose_mapping(unsigned int virq)
 		return;
 
 	host = irq_map[virq].host;
-	WARN_ON (host == NULL);
-	if (host == NULL)
+	if (WARN_ON(host == NULL))
 		return;
 
 	/* Never unmap legacy interrupts */
@@ -898,7 +897,8 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 	struct irq_map_entry *ptr;
 	unsigned int virq;
 
-	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
+	if (WARN_ON_ONCE(host->revmap_type != IRQ_HOST_MAP_TREE))
+		return irq_find_mapping(host, hwirq);
 
 	/*
 	 * No rcu_read_lock(ing) needed, the ptr returned can't go under us
@@ -922,7 +922,8 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
 			     irq_hw_number_t hwirq)
 {
-	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
+	if (WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE))
+		return;
 
 	if (virq != NO_IRQ) {
 		mutex_lock(&revmap_trees_mutex);
@@ -937,7 +938,8 @@ unsigned int irq_linear_revmap(struct irq_host *host,
 {
 	unsigned int *revmap;
 
-	WARN_ON(host->revmap_type != IRQ_HOST_MAP_LINEAR);
+	if (WARN_ON_ONCE(host->revmap_type != IRQ_HOST_MAP_LINEAR))
+		return irq_find_mapping(host, hwirq);
 
 	/* Check revmap bounds */
 	if (unlikely(hwirq >= host->revmap_data.linear.size))

commit 3af259d1555a93b3b6f6545af13e0eb99b0d5d32
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:53 2011 +0000

    powerpc: Radix trees are available before init_IRQ
    
    Since the generic irq code uses a radix tree for sparse interrupts,
    the initcall ordering has been changed to initialize radix trees before
    irqs.   We no longer need to defer creating revmap radix trees to the
    arch_initcall irq_late_init.
    
    Also, the kmem caches are allocated so we don't need to use
    zalloc_maybe_bootmem.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Reviewed-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 826552cecebd..f42e869ee3cc 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -493,7 +493,6 @@ struct irq_map_entry {
 
 static LIST_HEAD(irq_hosts);
 static DEFINE_RAW_SPINLOCK(irq_big_lock);
-static unsigned int revmap_trees_allocated;
 static DEFINE_MUTEX(revmap_trees_mutex);
 static struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
@@ -537,7 +536,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	/* Allocate structure and revmap table if using linear mapping */
 	if (revmap_type == IRQ_HOST_MAP_LINEAR)
 		size += revmap_arg * sizeof(unsigned int);
-	host = zalloc_maybe_bootmem(size, GFP_KERNEL);
+	host = kzalloc(size, GFP_KERNEL);
 	if (host == NULL)
 		return NULL;
 
@@ -605,6 +604,9 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 		smp_wmb();
 		host->revmap_data.linear.revmap = rmap;
 		break;
+	case IRQ_HOST_MAP_TREE:
+		INIT_RADIX_TREE(&host->revmap_data.tree, GFP_KERNEL);
+		break;
 	default:
 		break;
 	}
@@ -839,13 +841,6 @@ void irq_dispose_mapping(unsigned int virq)
 			host->revmap_data.linear.revmap[hwirq] = NO_IRQ;
 		break;
 	case IRQ_HOST_MAP_TREE:
-		/*
-		 * Check if radix tree allocated yet, if not then nothing to
-		 * remove.
-		 */
-		smp_rmb();
-		if (revmap_trees_allocated < 1)
-			break;
 		mutex_lock(&revmap_trees_mutex);
 		radix_tree_delete(&host->revmap_data.tree, hwirq);
 		mutex_unlock(&revmap_trees_mutex);
@@ -905,14 +900,6 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 
 	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
 
-	/*
-	 * Check if the radix tree exists and has bee initialized.
-	 * If not, we fallback to slow mode
-	 */
-	if (revmap_trees_allocated < 2)
-		return irq_find_mapping(host, hwirq);
-
-	/* Now try to resolve */
 	/*
 	 * No rcu_read_lock(ing) needed, the ptr returned can't go under us
 	 * as it's referencing an entry in the static irq_map table.
@@ -935,18 +922,8 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
 			     irq_hw_number_t hwirq)
 {
-
 	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
 
-	/*
-	 * Check if the radix tree exists yet.
-	 * If not, then the irq will be inserted into the tree when it gets
-	 * initialized.
-	 */
-	smp_rmb();
-	if (revmap_trees_allocated < 1)
-		return;
-
 	if (virq != NO_IRQ) {
 		mutex_lock(&revmap_trees_mutex);
 		radix_tree_insert(&host->revmap_data.tree, hwirq,
@@ -1054,53 +1031,6 @@ int arch_early_irq_init(void)
 	return 0;
 }
 
-/* We need to create the radix trees late */
-static int irq_late_init(void)
-{
-	struct irq_host *h;
-	unsigned int i;
-
-	/*
-	 * No mutual exclusion with respect to accessors of the tree is needed
-	 * here as the synchronization is done via the state variable
-	 * revmap_trees_allocated.
-	 */
-	list_for_each_entry(h, &irq_hosts, link) {
-		if (h->revmap_type == IRQ_HOST_MAP_TREE)
-			INIT_RADIX_TREE(&h->revmap_data.tree, GFP_KERNEL);
-	}
-
-	/*
-	 * Make sure the radix trees inits are visible before setting
-	 * the flag
-	 */
-	smp_wmb();
-	revmap_trees_allocated = 1;
-
-	/*
-	 * Insert the reverse mapping for those interrupts already present
-	 * in irq_map[].
-	 */
-	mutex_lock(&revmap_trees_mutex);
-	for (i = 0; i < irq_virq_count; i++) {
-		if (irq_map[i].host &&
-		    (irq_map[i].host->revmap_type == IRQ_HOST_MAP_TREE))
-			radix_tree_insert(&irq_map[i].host->revmap_data.tree,
-					  irq_map[i].hwirq, &irq_map[i]);
-	}
-	mutex_unlock(&revmap_trees_mutex);
-
-	/*
-	 * Make sure the radix trees insertions are visible before setting
-	 * the flag
-	 */
-	smp_wmb();
-	revmap_trees_allocated = 2;
-
-	return 0;
-}
-arch_initcall(irq_late_init);
-
 #ifdef CONFIG_VIRQ_DEBUG
 static int virq_debug_show(struct seq_file *m, void *private)
 {

commit 23d72bfd8f9f24aa9efafed3586a99f5669c23d7
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:39 2011 +0000

    powerpc: Consolidate ipi message mux and demux
    
    Consolidate the mux and demux of ipi messages into smp.c and call
    a new smp_ops callback to actually trigger the ipi.
    
    The powerpc architecture code is optimised for having 4 distinct
    ipi triggers, which are mapped to 4 distinct messages (ipi many, ipi
    single, scheduler ipi, and enter debugger).  However, several interrupt
    controllers only provide a single software triggered interrupt that
    can be delivered to each cpu.  To resolve this limitation, each smp_ops
    implementation created a per-cpu variable that is manipulated with atomic
    bitops.  Since these lines will be contended they are optimialy marked as
    shared_aligned and take a full cache line for each cpu.  Distro kernels
    may have 2 or 3 of these in their config, each taking per-cpu space
    even though at most one will be in use.
    
    This consolidation removes smp_message_recv and replaces the single call
    actions cases with direct calls from the common message recognition loop.
    The complicated debugger ipi case with its muxed crash handling code is
    moved to debug_ipi_action which is now called from the demux code (instead
    of the multi-message action calling smp_message_recv).
    
    I put a call to reschedule_action to increase the likelyhood of correctly
    merging the anticipated scheduler_ipi() hook coming from the scheduler
    tree; that single required call can be inlined later.
    
    The actual message decode is a copy of the old pseries xics code with its
    memory barriers and cache line spacing, augmented with a per-cpu unsigned
    long based on the book-e doorbell code.  The optional data is set via a
    callback from the implementation and is passed to the new cause-ipi hook
    along with the logical cpu number.  While currently only the doorbell
    implemntation uses this data it should be almost zero cost to retrieve and
    pass it -- it adds a single register load for the argument from the same
    cache line to which we just completed a store and the register is dead
    on return from the call.  I extended the data element from unsigned int
    to unsigned long in case some other code wanted to associate a pointer.
    
    The doorbell check_self is replaced by a call to smp_muxed_ipi_resend,
    conditioned on the CPU_DBELL feature.  The ifdef guard could be relaxed
    to CONFIG_SMP but I left it with BOOKE for now.
    
    Also, the doorbell interrupt vector for book-e was not calling irq_enter
    and irq_exit, which throws off cpu accounting and causes code to not
    realize it is running in interrupt context.  Add the missing calls.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a81dd74414bf..826552cecebd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -66,7 +66,6 @@
 #include <asm/ptrace.h>
 #include <asm/machdep.h>
 #include <asm/udbg.h>
-#include <asm/dbell.h>
 #include <asm/smp.h>
 
 #ifdef CONFIG_PPC64
@@ -160,7 +159,8 @@ notrace void arch_local_irq_restore(unsigned long en)
 
 #if defined(CONFIG_BOOKE) && defined(CONFIG_SMP)
 	/* Check for pending doorbell interrupts and resend to ourself */
-	doorbell_check_self();
+	if (cpu_has_feature(CPU_FTR_DBELL))
+		smp_muxed_ipi_resend();
 #endif
 
 	/*

commit 476eb4912601a8c01e6702b9a029f476b4b131d2
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Wed May 4 15:02:15 2011 +1000

    powerpc/irq: Stop exporting irq_map
    
    First step in eliminating irq_map[] table entirely
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4f5d6e751a65..a81dd74414bf 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -481,20 +481,42 @@ void do_softirq(void)
  * IRQ controller and virtual interrupts
  */
 
+/* The main irq map itself is an array of NR_IRQ entries containing the
+ * associate host and irq number. An entry with a host of NULL is free.
+ * An entry can be allocated if it's free, the allocator always then sets
+ * hwirq first to the host's invalid irq number and then fills ops.
+ */
+struct irq_map_entry {
+	irq_hw_number_t	hwirq;
+	struct irq_host	*host;
+};
+
 static LIST_HEAD(irq_hosts);
 static DEFINE_RAW_SPINLOCK(irq_big_lock);
 static unsigned int revmap_trees_allocated;
 static DEFINE_MUTEX(revmap_trees_mutex);
-struct irq_map_entry irq_map[NR_IRQS];
+static struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_host *irq_default_host;
 
+irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
+{
+	return irq_map[d->irq].hwirq;
+}
+EXPORT_SYMBOL_GPL(irqd_to_hwirq);
+
 irq_hw_number_t virq_to_hw(unsigned int virq)
 {
 	return irq_map[virq].hwirq;
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
+struct irq_host *virq_to_host(unsigned int virq)
+{
+	return irq_map[virq].host;
+}
+EXPORT_SYMBOL_GPL(virq_to_host);
+
 static int default_irq_host_match(struct irq_host *h, struct device_node *np)
 {
 	return h->of_node != NULL && h->of_node == np;
@@ -1103,7 +1125,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			struct irq_chip *chip;
 
 			seq_printf(m, "%5d  ", i);
-			seq_printf(m, "0x%05lx  ", virq_to_hw(i));
+			seq_printf(m, "0x%05lx  ", irq_map[i].hwirq);
 
 			chip = irq_desc_get_chip(desc);
 			if (chip && chip->name)

commit 73706c3283d755d3725c6a48a18e677a15ced8be
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Sun Apr 10 20:26:15 2011 +0000

    powerpc/irq: Dump chip data pointer in virq_mapping
    
    This can be useful for differentiating interrupts on the same host
    but with different chip data.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ea09512a68c3..4f5d6e751a65 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1086,10 +1086,11 @@ static int virq_debug_show(struct seq_file *m, void *private)
 	struct irq_desc *desc;
 	const char *p;
 	static const char none[] = "none";
+	void *data;
 	int i;
 
-	seq_printf(m, "%-5s  %-7s  %-15s  %s\n", "virq", "hwirq",
-		      "chip name", "host name");
+	seq_printf(m, "%-5s  %-7s  %-15s  %-18s  %s\n", "virq", "hwirq",
+		      "chip name", "chip data", "host name");
 
 	for (i = 1; i < nr_irqs; i++) {
 		desc = irq_to_desc(i);
@@ -1111,6 +1112,9 @@ static int virq_debug_show(struct seq_file *m, void *private)
 				p = none;
 			seq_printf(m, "%-15s  ", p);
 
+			data = irq_desc_get_chip_data(desc);
+			seq_printf(m, "0x%16p  ", data);
+
 			if (irq_map[i].host && irq_map[i].host->of_node)
 				p = irq_map[i].host->of_node->full_name;
 			else

commit ca1769f7a372898f5e3dbb8e4ff53f53f0626ef4
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 14 22:32:04 2011 +0000

    powerpc: Index crit/dbg/mcheck stacks using cpu number on 64bit
    
    In exc_lvl_ctx_init() we index into the crit/dbg/mcheck stacks using
    the hard cpu id, but that assumes the hard cpu id is zero based and
    contiguous. That is not the case on A2.
    
    The root of the problem is that the 32bit code has no equivalent of the
    paca to allow it to do the hard->soft mapping in assembler. Until the
    32bit code is updated to handle that, index the stacks using the soft
    cpu ids on 64bit and hard on 32 bit.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f621b7d2d869..ea09512a68c3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -397,24 +397,28 @@ struct thread_info *mcheckirq_ctx[NR_CPUS] __read_mostly;
 void exc_lvl_ctx_init(void)
 {
 	struct thread_info *tp;
-	int i, hw_cpu;
+	int i, cpu_nr;
 
 	for_each_possible_cpu(i) {
-		hw_cpu = get_hard_smp_processor_id(i);
-		memset((void *)critirq_ctx[hw_cpu], 0, THREAD_SIZE);
-		tp = critirq_ctx[hw_cpu];
-		tp->cpu = i;
+#ifdef CONFIG_PPC64
+		cpu_nr = i;
+#else
+		cpu_nr = get_hard_smp_processor_id(i);
+#endif
+		memset((void *)critirq_ctx[cpu_nr], 0, THREAD_SIZE);
+		tp = critirq_ctx[cpu_nr];
+		tp->cpu = cpu_nr;
 		tp->preempt_count = 0;
 
 #ifdef CONFIG_BOOKE
-		memset((void *)dbgirq_ctx[hw_cpu], 0, THREAD_SIZE);
-		tp = dbgirq_ctx[hw_cpu];
-		tp->cpu = i;
+		memset((void *)dbgirq_ctx[cpu_nr], 0, THREAD_SIZE);
+		tp = dbgirq_ctx[cpu_nr];
+		tp->cpu = cpu_nr;
 		tp->preempt_count = 0;
 
-		memset((void *)mcheckirq_ctx[hw_cpu], 0, THREAD_SIZE);
-		tp = mcheckirq_ctx[hw_cpu];
-		tp->cpu = i;
+		memset((void *)mcheckirq_ctx[cpu_nr], 0, THREAD_SIZE);
+		tp = mcheckirq_ctx[cpu_nr];
+		tp->cpu = cpu_nr;
 		tp->preempt_count = HARDIRQ_OFFSET;
 #endif
 	}

commit 1c91cc570576dfd0f288d664c095d64d11aaace4
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Feb 11 13:05:17 2011 +1100

    powerpc/pmac/smp: Rename fixup_irqs() to migrate_irqs() and use it on ppc32
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 63625e0650b5..f621b7d2d869 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -246,12 +246,13 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
-void fixup_irqs(const struct cpumask *map)
+void migrate_irqs(void)
 {
 	struct irq_desc *desc;
 	unsigned int irq;
 	static int warned;
 	cpumask_var_t mask;
+	const struct cpumask *map = cpu_online_mask;
 
 	alloc_cpumask_var(&mask, GFP_KERNEL);
 

commit 433c9c67c53cc42b2824532d3abb7ac62970d3fb
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 25 17:04:59 2011 +0100

    powerpc: Use generic show_interrupts()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a155dfde9ac3..63625e0650b5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -195,7 +195,7 @@ notrace void arch_local_irq_restore(unsigned long en)
 EXPORT_SYMBOL(arch_local_irq_restore);
 #endif /* CONFIG_PPC64 */
 
-static int show_other_interrupts(struct seq_file *p, int prec)
+int arch_show_interrupts(struct seq_file *p, int prec)
 {
 	int j;
 
@@ -231,65 +231,6 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	return 0;
 }
 
-int show_interrupts(struct seq_file *p, void *v)
-{
-	unsigned long flags, any_count = 0;
-	int i = *(loff_t *) v, j, prec;
-	struct irqaction *action;
-	struct irq_desc *desc;
-	struct irq_chip *chip;
-
-	if (i > nr_irqs)
-		return 0;
-
-	for (prec = 3, j = 1000; prec < 10 && j <= nr_irqs; ++prec)
-		j *= 10;
-
-	if (i == nr_irqs)
-		return show_other_interrupts(p, prec);
-
-	/* print header */
-	if (i == 0) {
-		seq_printf(p, "%*s", prec + 8, "");
-		for_each_online_cpu(j)
-			seq_printf(p, "CPU%-8d", j);
-		seq_putc(p, '\n');
-	}
-
-	desc = irq_to_desc(i);
-	if (!desc)
-		return 0;
-
-	raw_spin_lock_irqsave(&desc->lock, flags);
-	for_each_online_cpu(j)
-		any_count |= kstat_irqs_cpu(i, j);
-	action = desc->action;
-	if (!action && !any_count)
-		goto out;
-
-	seq_printf(p, "%*d: ", prec, i);
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-
-	chip = get_irq_desc_chip(desc);
-	if (chip)
-		seq_printf(p, "  %-16s", chip->name);
-	else
-		seq_printf(p, "  %-16s", "None");
-	seq_printf(p, " %-8s", (irqd_is_level_type(&desc->irq_data) ? "Level" : "Edge");
-
-	if (action) {
-		seq_printf(p, "     %s", action->name);
-		while ((action = action->next) != NULL)
-			seq_printf(p, ", %s", action->name);
-	}
-
-	seq_putc(p, '\n');
-out:
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	return 0;
-}
-
 /*
  * /proc/stat helpers
  */

commit ec775d0e70eb6b7116406b3441cb8501c2849dd2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 25 16:45:20 2011 +0100

    powerpc: Convert to new irq_* function names
    
    Scripted with coccinelle.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 58d401265328..a155dfde9ac3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -830,7 +830,7 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 	/* Set type if specified and different than the current one */
 	if (type != IRQ_TYPE_NONE &&
 	    type != (irqd_get_trigger_type(irq_get_irq_data(virq))))
-		set_irq_type(virq, type);
+		irq_set_irq_type(virq, type);
 	return virq;
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
@@ -853,7 +853,7 @@ void irq_dispose_mapping(unsigned int virq)
 		return;
 
 	/* remove chip and handler */
-	set_irq_chip_and_handler(virq, NULL, NULL);
+	irq_set_chip_and_handler(virq, NULL, NULL);
 
 	/* Make sure it's completed */
 	synchronize_irq(virq);
@@ -1158,7 +1158,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			seq_printf(m, "%5d  ", i);
 			seq_printf(m, "0x%05lx  ", virq_to_hw(i));
 
-			chip = get_irq_desc_chip(desc);
+			chip = irq_desc_get_chip(desc);
 			if (chip && chip->name)
 				p = chip->name;
 			else

commit 7bfbc1f28311d680e45d7122ecd48dec57703750
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 25 16:36:35 2011 +0100

    powerpc: irq: Use irqdata based information
    
    We want to tighten the irq_desc access. So use the new accessors for
    the same information.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8f7da4402e9b..58d401265328 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -276,7 +276,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "  %-16s", chip->name);
 	else
 		seq_printf(p, "  %-16s", "None");
-	seq_printf(p, " %-8s", (desc->status & IRQ_LEVEL) ? "Level" : "Edge");
+	seq_printf(p, " %-8s", (irqd_is_level_type(&desc->irq_data) ? "Level" : "Edge");
 
 	if (action) {
 		seq_printf(p, "     %s", action->name);
@@ -315,24 +315,26 @@ void fixup_irqs(const struct cpumask *map)
 	alloc_cpumask_var(&mask, GFP_KERNEL);
 
 	for_each_irq(irq) {
+		struct irq_data *data;
 		struct irq_chip *chip;
 
 		desc = irq_to_desc(irq);
 		if (!desc)
 			continue;
 
-		if (desc->status & IRQ_PER_CPU)
+		data = irq_desc_get_irq_data(desc);
+		if (irqd_is_per_cpu(data))
 			continue;
 
-		chip = get_irq_desc_chip(desc);
+		chip = irq_data_get_irq_chip(data);
 
-		cpumask_and(mask, desc->irq_data.affinity, map);
+		cpumask_and(mask, data->affinity, map);
 		if (cpumask_any(mask) >= nr_cpu_ids) {
 			printk("Breaking affinity for irq %i\n", irq);
 			cpumask_copy(mask, map);
 		}
 		if (chip->irq_set_affinity)
-			chip->irq_set_affinity(&desc->irq_data, mask, true);
+			chip->irq_set_affinity(data, mask, true);
 		else if (desc->action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}
@@ -827,7 +829,7 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 
 	/* Set type if specified and different than the current one */
 	if (type != IRQ_TYPE_NONE &&
-	    type != (irq_to_desc(virq)->status & IRQF_TRIGGER_MASK))
+	    type != (irqd_get_trigger_type(irq_get_irq_data(virq))))
 		set_irq_type(virq, type);
 	return virq;
 }

commit 98488db9ff01849354bffb6a9675b1cc2ecf03fd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 25 15:43:57 2011 +0100

    powerpc: Use proper accessors for IRQ_* flags
    
    Use the proper accessors instead of open access to irq_desc.
    Converted with coccinelle.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0a5570338b96..8f7da4402e9b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -618,7 +618,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 			smp_wmb();
 
 			/* Clear norequest flags */
-			irq_to_desc(i)->status &= ~IRQ_NOREQUEST;
+			irq_clear_status_flags(i, IRQ_NOREQUEST);
 
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to

commit e11802872db82417e51e1bbe0751dbb21842d713
Author: Lennert Buytenhek <buytenh@wantstofly.org>
Date:   Mon Mar 7 14:00:20 2011 +0000

    powerpc: core irq_data conversion.
    
    Signed-off-by: Lennert Buytenhek <buytenh@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8a958ca26ac2..0a5570338b96 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -237,6 +237,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	int i = *(loff_t *) v, j, prec;
 	struct irqaction *action;
 	struct irq_desc *desc;
+	struct irq_chip *chip;
 
 	if (i > nr_irqs)
 		return 0;
@@ -270,8 +271,9 @@ int show_interrupts(struct seq_file *p, void *v)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
 
-	if (desc->chip)
-		seq_printf(p, "  %-16s", desc->chip->name);
+	chip = get_irq_desc_chip(desc);
+	if (chip)
+		seq_printf(p, "  %-16s", chip->name);
 	else
 		seq_printf(p, "  %-16s", "None");
 	seq_printf(p, " %-8s", (desc->status & IRQ_LEVEL) ? "Level" : "Edge");
@@ -313,6 +315,8 @@ void fixup_irqs(const struct cpumask *map)
 	alloc_cpumask_var(&mask, GFP_KERNEL);
 
 	for_each_irq(irq) {
+		struct irq_chip *chip;
+
 		desc = irq_to_desc(irq);
 		if (!desc)
 			continue;
@@ -320,13 +324,15 @@ void fixup_irqs(const struct cpumask *map)
 		if (desc->status & IRQ_PER_CPU)
 			continue;
 
-		cpumask_and(mask, desc->affinity, map);
+		chip = get_irq_desc_chip(desc);
+
+		cpumask_and(mask, desc->irq_data.affinity, map);
 		if (cpumask_any(mask) >= nr_cpu_ids) {
 			printk("Breaking affinity for irq %i\n", irq);
 			cpumask_copy(mask, map);
 		}
-		if (desc->chip->set_affinity)
-			desc->chip->set_affinity(irq, mask);
+		if (chip->irq_set_affinity)
+			chip->irq_set_affinity(&desc->irq_data, mask, true);
 		else if (desc->action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}
@@ -1145,11 +1151,14 @@ static int virq_debug_show(struct seq_file *m, void *private)
 		raw_spin_lock_irqsave(&desc->lock, flags);
 
 		if (desc->action && desc->action->handler) {
+			struct irq_chip *chip;
+
 			seq_printf(m, "%5d  ", i);
 			seq_printf(m, "0x%05lx  ", virq_to_hw(i));
 
-			if (desc->chip && desc->chip->name)
-				p = desc->chip->name;
+			chip = get_irq_desc_chip(desc);
+			if (chip && chip->name)
+				p = chip->name;
 			else
 				p = none;
 			seq_printf(m, "%-15s  ", p);

commit a9d8946b4af9e003c645ffb46489fdeb154e7ed9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jan 21 06:12:30 2011 +0000

    powerpc: Use new irq allocator
    
    Use the new functions and free the descriptor when the virq is
    destroyed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0531ccda8005..8a958ca26ac2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -678,16 +678,15 @@ void irq_set_virq_count(unsigned int count)
 static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
-	struct irq_desc *desc;
+	int res;
 
-	desc = irq_to_desc_alloc_node(virq, 0);
-	if (!desc) {
+	res = irq_alloc_desc_at(virq, 0);
+	if (res != virq) {
 		pr_debug("irq: -> allocating desc failed\n");
 		goto error;
 	}
 
-	/* Clear IRQ_NOREQUEST flag */
-	desc->status &= ~IRQ_NOREQUEST;
+	irq_clear_status_flags(virq, IRQ_NOREQUEST);
 
 	/* map it */
 	smp_wmb();
@@ -696,11 +695,13 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 
 	if (host->ops->map(host, virq, hwirq)) {
 		pr_debug("irq: -> mapping failed, freeing\n");
-		goto error;
+		goto errdesc;
 	}
 
 	return 0;
 
+errdesc:
+	irq_free_descs(virq, 1);
 error:
 	irq_free_virt(virq, 1);
 	return -1;
@@ -879,9 +880,9 @@ void irq_dispose_mapping(unsigned int virq)
 	smp_mb();
 	irq_map[virq].hwirq = host->inval_irq;
 
-	/* Set some flags */
-	irq_to_desc(virq)->status |= IRQ_NOREQUEST;
+	irq_set_status_flags(virq, IRQ_NOREQUEST);
 
+	irq_free_descs(virq, 1);
 	/* Free it */
 	irq_free_virt(virq, 1);
 }

commit 089fb442f3018a3ed094f8ac7a7cc2d3bd03b114
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jan 21 06:12:28 2011 +0000

    powerpc: Use ARCH_IRQ_INIT_FLAGS
    
    Define the ARCH_IRQ_INIT_FLAGS instead of fixing it up in a loop.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ce557f6f00fc..0531ccda8005 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1074,21 +1074,6 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 
 int arch_early_irq_init(void)
 {
-	struct irq_desc *desc;
-	int i;
-
-	for (i = 0; i < NR_IRQS; i++) {
-		desc = irq_to_desc(i);
-		if (desc)
-			desc->status |= IRQ_NOREQUEST;
-	}
-
-	return 0;
-}
-
-int arch_init_chip_data(struct irq_desc *desc, int node)
-{
-	desc->status |= IRQ_NOREQUEST;
 	return 0;
 }
 

commit d4429f608abde89e8bc1e24b43cd503feb95c496
Merge: e10117d36ef7 6a1c9dfe4186
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 21:19:54 2010 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (71 commits)
      powerpc/44x: Update ppc44x_defconfig
      powerpc/watchdog: Make default timeout for Book-E watchdog a Kconfig option
      fsl_rio: Add comments for sRIO registers.
      powerpc/fsl-booke: Add e55xx (64-bit) smp defconfig
      powerpc/fsl-booke: Add p5020 DS board support
      powerpc/fsl-booke64: Use TLB CAMs to cover linear mapping on FSL 64-bit chips
      powerpc/fsl-booke: Add support for FSL Arch v1.0 MMU in setup_page_sizes
      powerpc/fsl-booke: Add support for FSL 64-bit e5500 core
      powerpc/85xx: add cache-sram support
      powerpc/85xx: add ngPIXIS FPGA device tree node to the P1022DS board
      powerpc: Fix compile error with paca code on ppc64e
      powerpc/fsl-booke: Add p3041 DS board support
      oprofile/fsl emb: Don't set MSR[PMM] until after clearing the interrupt.
      powerpc/fsl-booke: Add PCI device ids for P2040/P3041/P5010/P5020 QoirQ chips
      powerpc/mpc8xxx_gpio: Add support for 'qoriq-gpio' controllers
      powerpc/fsl_booke: Add support to boot from core other than 0
      powerpc/p1022: Add probing for individual DMA channels
      powerpc/fsl_soc: Search all global-utilities nodes for rstccr
      powerpc: Fix invalid page flags in create TLB CAM path for PTE_64BIT
      powerpc/mpc83xx: Support for MPC8308 P1M board
      ...
    
    Fix up conflict with the generic irq_work changes in arch/powerpc/kernel/time.c

commit a655237fa2f9e4afe9949abe2c511432ab9537dd
Author: Julia Lawall <julia@diku.dk>
Date:   Sat Sep 4 00:12:44 2010 +0000

    powerpc/irq.c: Add of_node_put to avoid memory leak
    
    In this case, a device_node structure is stored in another structure that
    is then freed without first decrementing the reference count of the
    device_node structure.
    
    The semantic match that finds this problem is as follows:
    (http://coccinelle.lip6.fr/)
    
    // <smpl>
    @r exists@
    expression x;
    identifier f;
    position p1,p2;
    @@
    
    x@p1->f = \(of_find_node_by_path\|of_find_node_by_name\|of_find_node_by_phandle\|of_get_parent\|of_get_next_parent\|of_get_next_child\|of_find_compatible_node\|of_match_node\|of_find_node_by_type\|of_find_node_with_property\|of_find_matching_node\|of_parse_phandle\|of_node_get\)(...);
    ... when != of_node_put(x)
    kfree@p2(x)
    
    @script:python@
    p1 << r.p1;
    p2 << r.p2;
    @@
    cocci.print_main("call",p1)
    cocci.print_secs("free",p2)
    // </smpl>
    
    Signed-off-by: Julia Lawall <julia@diku.dk>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 47fbc56e9e1c..4002b48fd607 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -587,8 +587,10 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 			 * this will be fixed once slab is made available early
 			 * instead of the current cruft
 			 */
-			if (mem_init_done)
+			if (mem_init_done) {
+				of_node_put(host->of_node);
 				kfree(host);
+			}
 			return NULL;
 		}
 		irq_map[0].host = host;

commit 4e74fd7d0a6eda70f9356c113450182a844abcf1
Author: Joe Perches <joe@perches.com>
Date:   Mon Sep 13 09:47:40 2010 +0000

    powerpc: Use static const char arrays
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Reviewed-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4a65386995d7..47fbc56e9e1c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1143,7 +1143,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 	unsigned long flags;
 	struct irq_desc *desc;
 	const char *p;
-	char none[] = "none";
+	static const char none[] = "none";
 	int i;
 
 	seq_printf(m, "%-5s  %-7s  %-15s  %s\n", "virq", "hwirq",

commit df9ee29270c11dba7d0fe0b83ce47a4d8e8d2101
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 7 14:08:55 2010 +0100

    Fix IRQ flag handling naming
    
    Fix the IRQ flag handling naming.  In linux/irqflags.h under one configuration,
    it maps:
    
            local_irq_enable() -> raw_local_irq_enable()
            local_irq_disable() -> raw_local_irq_disable()
            local_irq_save() -> raw_local_irq_save()
            ...
    
    and under the other configuration, it maps:
    
            raw_local_irq_enable() -> local_irq_enable()
            raw_local_irq_disable() -> local_irq_disable()
            raw_local_irq_save() -> local_irq_save()
            ...
    
    This is quite confusing.  There should be one set of names expected of the
    arch, and this should be wrapped to give another set of names that are expected
    by users of this facility.
    
    Change this to have the arch provide:
    
            flags = arch_local_save_flags()
            flags = arch_local_irq_save()
            arch_local_irq_restore(flags)
            arch_local_irq_disable()
            arch_local_irq_enable()
            arch_irqs_disabled_flags(flags)
            arch_irqs_disabled()
            arch_safe_halt()
    
    Then linux/irqflags.h wraps these to provide:
    
            raw_local_save_flags(flags)
            raw_local_irq_save(flags)
            raw_local_irq_restore(flags)
            raw_local_irq_disable()
            raw_local_irq_enable()
            raw_irqs_disabled_flags(flags)
            raw_irqs_disabled()
            raw_safe_halt()
    
    with type checking on the flags 'arguments', and then wraps those to provide:
    
            local_save_flags(flags)
            local_irq_save(flags)
            local_irq_restore(flags)
            local_irq_disable()
            local_irq_enable()
            irqs_disabled_flags(flags)
            irqs_disabled()
            safe_halt()
    
    with tracing included if enabled.
    
    The arch functions can now all be inline functions rather than some of them
    having to be macros.
    
    Signed-off-by: David Howells <dhowells@redhat.com> [X86, FRV, MN10300]
    Signed-off-by: Chris Metcalf <cmetcalf@tilera.com> [Tile]
    Signed-off-by: Michal Simek <monstr@monstr.eu> [Microblaze]
    Tested-by: Catalin Marinas <catalin.marinas@arm.com> [ARM]
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Haavard Skinnemoen <haavard.skinnemoen@atmel.com> [AVR]
    Acked-by: Tony Luck <tony.luck@intel.com> [IA-64]
    Acked-by: Hirokazu Takata <takata@linux-m32r.org> [M32R]
    Acked-by: Greg Ungerer <gerg@uclinux.org> [M68K/M68KNOMMU]
    Acked-by: Ralf Baechle <ralf@linux-mips.org> [MIPS]
    Acked-by: Kyle McMartin <kyle@mcmartin.ca> [PA-RISC]
    Acked-by: Paul Mackerras <paulus@samba.org> [PowerPC]
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com> [S390]
    Acked-by: Chen Liqin <liqin.chen@sunplusct.com> [Score]
    Acked-by: Matt Fleming <matt@console-pimps.org> [SH]
    Acked-by: David S. Miller <davem@davemloft.net> [Sparc]
    Acked-by: Chris Zankel <chris@zankel.net> [Xtensa]
    Reviewed-by: Richard Henderson <rth@twiddle.net> [Alpha]
    Reviewed-by: Yoshinori Sato <ysato@users.sourceforge.jp> [H8300]
    Cc: starvik@axis.com [CRIS]
    Cc: jesper.nilsson@axis.com [CRIS]
    Cc: linux-cris-kernel@axis.com

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4a65386995d7..1903290f5469 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -116,7 +116,7 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
-notrace void raw_local_irq_restore(unsigned long en)
+notrace void arch_local_irq_restore(unsigned long en)
 {
 	/*
 	 * get_paca()->soft_enabled = en;
@@ -192,7 +192,7 @@ notrace void raw_local_irq_restore(unsigned long en)
 
 	__hard_irq_enable();
 }
-EXPORT_SYMBOL(raw_local_irq_restore);
+EXPORT_SYMBOL(arch_local_irq_restore);
 #endif /* CONFIG_PPC64 */
 
 static int show_other_interrupts(struct seq_file *p, int prec)

commit 3e7f45ad521ac3e38889d255ec7676037fa84ae2
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Wed Aug 18 06:44:25 2010 +0000

    powerpc/4xx: Index interrupt stacks by physical cpu
    
    The interrupt stacks need to be indexed by the physical cpu since the
    critical, debug and machine check handlers use the contents of SPRN_PIR to
    index the critirq_ctx, dbgirq_ctx, and mcheckirq_ctx arrays.
    
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d3ce67cf03be..4a65386995d7 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -67,6 +67,7 @@
 #include <asm/machdep.h>
 #include <asm/udbg.h>
 #include <asm/dbell.h>
+#include <asm/smp.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
@@ -446,22 +447,23 @@ struct thread_info *mcheckirq_ctx[NR_CPUS] __read_mostly;
 void exc_lvl_ctx_init(void)
 {
 	struct thread_info *tp;
-	int i;
+	int i, hw_cpu;
 
 	for_each_possible_cpu(i) {
-		memset((void *)critirq_ctx[i], 0, THREAD_SIZE);
-		tp = critirq_ctx[i];
+		hw_cpu = get_hard_smp_processor_id(i);
+		memset((void *)critirq_ctx[hw_cpu], 0, THREAD_SIZE);
+		tp = critirq_ctx[hw_cpu];
 		tp->cpu = i;
 		tp->preempt_count = 0;
 
 #ifdef CONFIG_BOOKE
-		memset((void *)dbgirq_ctx[i], 0, THREAD_SIZE);
-		tp = dbgirq_ctx[i];
+		memset((void *)dbgirq_ctx[hw_cpu], 0, THREAD_SIZE);
+		tp = dbgirq_ctx[hw_cpu];
 		tp->cpu = i;
 		tp->preempt_count = 0;
 
-		memset((void *)mcheckirq_ctx[i], 0, THREAD_SIZE);
-		tp = mcheckirq_ctx[i];
+		memset((void *)mcheckirq_ctx[hw_cpu], 0, THREAD_SIZE);
+		tp = mcheckirq_ctx[hw_cpu];
 		tp->cpu = i;
 		tp->preempt_count = HARDIRQ_OFFSET;
 #endif

commit 03c0c29aff7e56b722eb6c47eace222b140d0377
Merge: c60c6a96b7bb 7fb8f881c54b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 5 15:57:35 2010 -0700

    Merge branch 'next-devicetree' of git://git.secretlab.ca/git/linux-2.6
    
    * 'next-devicetree' of git://git.secretlab.ca/git/linux-2.6: (63 commits)
      of/platform: Register of_platform_drivers with an "of:" prefix
      of/address: Clean up function declarations
      of/spi: call of_register_spi_devices() from spi core code
      of: Provide default of_node_to_nid() implementation.
      of/device: Make of_device_make_bus_id() usable by other code.
      of/irq: Fix endian issues in parsing interrupt specifiers
      of: Fix phandle endian issues
      of/flattree: fix of_flat_dt_is_compatible() to match the full compatible string
      of: remove of_default_bus_ids
      of: make of_find_device_by_node generic
      microblaze: remove references to of_device and to_of_device
      sparc: remove references to of_device and to_of_device
      powerpc: remove references to of_device and to_of_device
      of/device: Replace of_device with platform_device in includes and core code
      of/device: Protect against binding of_platform_drivers to non-OF devices
      of: remove asm/of_device.h
      of: remove asm/of_platform.h
      of/platform: remove all of_bus_type and of_platform_bus_type references
      of: Merge of_platform_bus_type with platform_bus_type
      drivercore/of: Add OF style matching to platform bus
      ...
    
    Fix up trivial conflicts in arch/microblaze/kernel/Makefile due to just
    some obj-y removals by the devicetree branch, while the microblaze
    updates added a new file.

commit 4e4f62bf7396fca48efe61513640ee399a6046e3
Merge: 9e3288dc9a94 b37fa16e78d6
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Sat Jul 24 09:49:13 2010 -0600

    Merge commit 'v2.6.35-rc6' into devicetree/next
    
    Conflicts:
            arch/sparc/kernel/prom_64.c

commit 850f22d5688941ea51628f3f8f8dcf3baff409ff
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jul 9 15:34:00 2010 +1000

    powerpc/book3e: Resend doorbell exceptions to ourself
    
    If we are soft disabled and receive a doorbell exception we don't process
    it immediately. This means we need to check on the way out of irq restore
    if there are any doorbell exceptions to process.
    
    The problem is at that point we don't know what our regs are, and that
    in turn makes xmon unhappy. To workaround the problem, instead of checking
    for and processing doorbells, we check for any doorbells and if there were
    any we send ourselves another.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2f6dc7faf6de..8f96d3198905 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -156,8 +156,8 @@ notrace void raw_local_irq_restore(unsigned long en)
 		return;
 
 #if defined(CONFIG_BOOKE) && defined(CONFIG_SMP)
-	/* Check for pending doorbell interrupts on SMP */
-	doorbell_exception(NULL);
+	/* Check for pending doorbell interrupts and resend to ourself */
+	doorbell_check_self();
 #endif
 
 	/*

commit 89c81797d4a0779a957f4ea1f0c676cda203615b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:31:28 2010 +1000

    powerpc/book3e: Hookup doorbells exceptions on 64-bit Book3E
    
    Note that critical doorbells are an unimplemented stub just like
    other critical or machine check handlers, since we haven't done
    support for "levelled" exceptions yet.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index fa6f38525801..2f6dc7faf6de 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -64,6 +64,8 @@
 #include <asm/ptrace.h>
 #include <asm/machdep.h>
 #include <asm/udbg.h>
+#include <asm/dbell.h>
+
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 #include <asm/firmware.h>
@@ -153,6 +155,11 @@ notrace void raw_local_irq_restore(unsigned long en)
 	if (get_hard_enabled())
 		return;
 
+#if defined(CONFIG_BOOKE) && defined(CONFIG_SMP)
+	/* Check for pending doorbell interrupts on SMP */
+	doorbell_exception(NULL);
+#endif
+
 	/*
 	 * Need to hard-enable interrupts here.  Since currently disabled,
 	 * no need to take further asm precautions against preemption; but

commit e8775d4aa17d70d123814e68a6a51bbea50e5c16
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:30:22 2010 +1000

    powerpc/book3e: Don't re-trigger decrementer on lazy irq restore
    
    The decrementer on BookE acts as a level interrupt and doesn't
    need to be re-triggered when going negative. It doesn't go
    negative anyways (unless programmed to auto-reload with a
    negative value) as it stops when reaching 0.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 77be3d058a65..fa6f38525801 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -159,8 +159,17 @@ notrace void raw_local_irq_restore(unsigned long en)
 	 * use local_paca instead of get_paca() to avoid preemption checking.
 	 */
 	local_paca->hard_enabled = en;
+
+#ifndef CONFIG_BOOKE
+	/* On server, re-trigger the decrementer if it went negative since
+	 * some processors only trigger on edge transitions of the sign bit.
+	 *
+	 * BookE has a level sensitive decrementer (latches in TSR) so we
+	 * don't need that
+	 */
 	if ((int)mfspr(SPRN_DEC) < 0)
 		mtspr(SPRN_DEC, 1);
+#endif /* CONFIG_BOOKE */
 
 	/*
 	 * Force the delivery of pending soft-disabled interrupts on PS3.

commit 3cd8519248e9e17d982c6fab0f1a89bca6feb49a
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Wed Jun 16 00:09:35 2010 +0000

    powerpc: Fix logic error in fixup_irqs
    
    When SPARSE_IRQ is set, irq_to_desc() can
    return NULL. While the code here has a
    check for NULL, it's not really correct.
    Fix it by separating the check for it.
    
    This fixes CPU hot unplug for me.
    
    Reported-by: Alastair Bridgewater <alastair.bridgewater@gmail.com>
    Cc: stable@kernel.org [2.6.32+]
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 3333bbdd23ef..77be3d058a65 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -295,7 +295,10 @@ void fixup_irqs(const struct cpumask *map)
 
 	for_each_irq(irq) {
 		desc = irq_to_desc(irq);
-		if (desc && desc->status & IRQ_PER_CPU)
+		if (!desc)
+			continue;
+
+		if (desc->status & IRQ_PER_CPU)
 			continue;
 
 		cpumask_and(mask, desc->affinity, map);

commit e3873444990dd6f8a095d1f72b5ad45192f8c506
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Fri Jun 18 11:09:59 2010 -0600

    of/irq: Move irq_of_parse_and_map() to common code
    
    Merge common code between PowerPC and Microblaze.  SPARC implements
    irq_of_parse_and_map(), but the implementation is different, so it
    does not use this code.
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Jeremy Kerr <jeremy.kerr@canonical.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 30817d9b20cb..2676ef288bf5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -53,6 +53,8 @@
 #include <linux/bootmem.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -813,18 +815,6 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
-unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
-{
-	struct of_irq oirq;
-
-	if (of_irq_map_one(dev, index, &oirq))
-		return NO_IRQ;
-
-	return irq_create_of_mapping(oirq.controller, oirq.specifier,
-				     oirq.size);
-}
-EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
-
 void irq_dispose_mapping(unsigned int virq)
 {
 	struct irq_host *host;

commit f1ba9a5b2ab7d3f5a910d93371c4f22b636b7683
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 2 22:24:26 2010 +0000

    powerpc: Unconditionally enabled irq stacks
    
    Irq stacks provide an essential protection from stack overflows through
    external interrupts, at the cost of two additionals stacks per CPU.
    
    Enable them unconditionally to simplify the kernel build and prevent
    people from accidentally disabling them.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 30817d9b20cb..3333bbdd23ef 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -317,7 +317,6 @@ void fixup_irqs(const struct cpumask *map)
 }
 #endif
 
-#ifdef CONFIG_IRQSTACKS
 static inline void handle_one_irq(unsigned int irq)
 {
 	struct thread_info *curtp, *irqtp;
@@ -358,12 +357,6 @@ static inline void handle_one_irq(unsigned int irq)
 	if (irqtp->flags)
 		set_bits(irqtp->flags, &curtp->flags);
 }
-#else
-static inline void handle_one_irq(unsigned int irq)
-{
-	generic_handle_irq(irq);
-}
-#endif
 
 static inline void check_stack_overflow(void)
 {
@@ -455,7 +448,6 @@ void exc_lvl_ctx_init(void)
 }
 #endif
 
-#ifdef CONFIG_IRQSTACKS
 struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;
 struct thread_info *hardirq_ctx[NR_CPUS] __read_mostly;
 
@@ -492,10 +484,6 @@ static inline void do_softirq_onstack(void)
 	irqtp->task = NULL;
 }
 
-#else
-#define do_softirq_onstack()	__do_softirq()
-#endif /* CONFIG_IRQSTACKS */
-
 void do_softirq(void)
 {
 	unsigned long flags;

commit 79c4581262e225a7c96d88b632b05ab3b5e9a52c
Merge: 59534f7298c5 99ec28f183da
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 21 11:17:05 2010 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (92 commits)
      powerpc: Remove unused 'protect4gb' boot parameter
      powerpc: Build-in e1000e for pseries & ppc64_defconfig
      powerpc/pseries: Make request_ras_irqs() available to other pseries code
      powerpc/numa: Use ibm,architecture-vec-5 to detect form 1 affinity
      powerpc/numa: Set a smaller value for RECLAIM_DISTANCE to enable zone reclaim
      powerpc: Use smt_snooze_delay=-1 to always busy loop
      powerpc: Remove check of ibm,smt-snooze-delay OF property
      powerpc/kdump: Fix race in kdump shutdown
      powerpc/kexec: Fix race in kexec shutdown
      powerpc/kexec: Speedup kexec hash PTE tear down
      powerpc/pseries: Add hcall to read 4 ptes at a time in real mode
      powerpc: Use more accurate limit for first segment memory allocations
      powerpc/kdump: Use chip->shutdown to disable IRQs
      powerpc/kdump: CPUs assume the context of the oopsing CPU
      powerpc/crashdump: Do not fail on NULL pointer dereferencing
      powerpc/eeh: Fix oops when probing in early boot
      powerpc/pci: Check devices status property when scanning OF tree
      powerpc/vio: Switch VIO Bus PM to use generic helpers
      powerpc: Avoid bad relocations in iSeries code
      powerpc: Use common cpu_die (fixes SMP+SUSPEND build)
      ...

commit 0fe1ac48bef018bed896307cd12f6ca9b5e704ab
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Apr 13 20:46:04 2010 +0000

    powerpc/perf_event: Fix oops due to perf_event_do_pending call
    
    Anton Blanchard found that large POWER systems would occasionally
    crash in the exception exit path when profiling with perf_events.
    The symptom was that an interrupt would occur late in the exit path
    when the MSR[RI] (recoverable interrupt) bit was clear.  Interrupts
    should be hard-disabled at this point but they were enabled.  Because
    the interrupt was not recoverable the system panicked.
    
    The reason is that the exception exit path was calling
    perf_event_do_pending after hard-disabling interrupts, and
    perf_event_do_pending will re-enable interrupts.
    
    The simplest and cleanest fix for this is to use the same mechanism
    that 32-bit powerpc does, namely to cause a self-IPI by setting the
    decrementer to 1.  This means we can remove the tests in the exception
    exit path and raw_local_irq_restore.
    
    This also makes sure that the call to perf_event_do_pending from
    timer_interrupt() happens within irq_enter/irq_exit.  (Note that
    calling perf_event_do_pending from timer_interrupt does not mean that
    there is a possible 1/HZ latency; setting the decrementer to 1 ensures
    that the timer interrupt will happen immediately, i.e. within one
    timebase tick, which is a few nanoseconds or 10s of nanoseconds.)
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Cc: stable@kernel.org
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 64f6f2031c22..066bd31551d5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -53,7 +53,6 @@
 #include <linux/bootmem.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
-#include <linux/perf_event.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -145,11 +144,6 @@ notrace void raw_local_irq_restore(unsigned long en)
 	}
 #endif /* CONFIG_PPC_STD_MMU_64 */
 
-	if (test_perf_event_pending()) {
-		clear_perf_event_pending();
-		perf_event_do_pending();
-	}
-
 	/*
 	 * if (get_paca()->hard_enabled) return;
 	 * But again we need to take care that gcc gets hard_enabled directly

commit b6decb707952c678d110699abb5ed86d45ca6927
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Apr 26 15:32:35 2010 +0000

    powerpc/cpumask: Convert fixup_irqs to new cpumask API
    
    Use new cpumask_* functions, and dynamically allocate cpumask in fixup_irqs.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 64f6f2031c22..250ee2ebf288 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -290,30 +290,33 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
-void fixup_irqs(cpumask_t map)
+void fixup_irqs(const struct cpumask *map)
 {
 	struct irq_desc *desc;
 	unsigned int irq;
 	static int warned;
+	cpumask_var_t mask;
 
-	for_each_irq(irq) {
-		cpumask_t mask;
+	alloc_cpumask_var(&mask, GFP_KERNEL);
 
+	for_each_irq(irq) {
 		desc = irq_to_desc(irq);
 		if (desc && desc->status & IRQ_PER_CPU)
 			continue;
 
-		cpumask_and(&mask, desc->affinity, &map);
-		if (any_online_cpu(mask) == NR_CPUS) {
+		cpumask_and(mask, desc->affinity, map);
+		if (cpumask_any(mask) >= nr_cpu_ids) {
 			printk("Breaking affinity for irq %i\n", irq);
-			mask = map;
+			cpumask_copy(mask, map);
 		}
 		if (desc->chip->set_affinity)
-			desc->chip->set_affinity(irq, &mask);
+			desc->chip->set_affinity(irq, mask);
 		else if (desc->action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}
 
+	free_cpumask_var(mask);
+
 	local_irq_enable();
 	mdelay(1);
 	local_irq_disable();

commit f95e085b2531c86262b97a081eb0d1cf793606d3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 18 02:22:24 2010 +0000

    powerpc: Convert big_irq_lock to raw_spinlock
    
    big_irq_lock needs to be a real spinlock in RT. Convert it to
    raw_spinlock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9ae77e52f9d3..64f6f2031c22 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -520,7 +520,7 @@ void do_softirq(void)
  */
 
 static LIST_HEAD(irq_hosts);
-static DEFINE_SPINLOCK(irq_big_lock);
+static DEFINE_RAW_SPINLOCK(irq_big_lock);
 static unsigned int revmap_trees_allocated;
 static DEFINE_MUTEX(revmap_trees_mutex);
 struct irq_map_entry irq_map[NR_IRQS];
@@ -566,14 +566,14 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	if (host->ops->match == NULL)
 		host->ops->match = default_irq_host_match;
 
-	spin_lock_irqsave(&irq_big_lock, flags);
+	raw_spin_lock_irqsave(&irq_big_lock, flags);
 
 	/* If it's a legacy controller, check for duplicates and
 	 * mark it as allocated (we use irq 0 host pointer for that
 	 */
 	if (revmap_type == IRQ_HOST_MAP_LEGACY) {
 		if (irq_map[0].host != NULL) {
-			spin_unlock_irqrestore(&irq_big_lock, flags);
+			raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 			/* If we are early boot, we can't free the structure,
 			 * too bad...
 			 * this will be fixed once slab is made available early
@@ -587,7 +587,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	}
 
 	list_add(&host->link, &irq_hosts);
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 
 	/* Additional setups per revmap type */
 	switch(revmap_type) {
@@ -638,13 +638,13 @@ struct irq_host *irq_find_host(struct device_node *node)
 	 * the absence of a device node. This isn't a problem so far
 	 * yet though...
 	 */
-	spin_lock_irqsave(&irq_big_lock, flags);
+	raw_spin_lock_irqsave(&irq_big_lock, flags);
 	list_for_each_entry(h, &irq_hosts, link)
 		if (h->ops->match(h, node)) {
 			found = h;
 			break;
 		}
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 	return found;
 }
 EXPORT_SYMBOL_GPL(irq_find_host);
@@ -1013,7 +1013,7 @@ unsigned int irq_alloc_virt(struct irq_host *host,
 	if (count == 0 || count > (irq_virq_count - NUM_ISA_INTERRUPTS))
 		return NO_IRQ;
 
-	spin_lock_irqsave(&irq_big_lock, flags);
+	raw_spin_lock_irqsave(&irq_big_lock, flags);
 
 	/* Use hint for 1 interrupt if any */
 	if (count == 1 && hint >= NUM_ISA_INTERRUPTS &&
@@ -1037,7 +1037,7 @@ unsigned int irq_alloc_virt(struct irq_host *host,
 		}
 	}
 	if (found == NO_IRQ) {
-		spin_unlock_irqrestore(&irq_big_lock, flags);
+		raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 		return NO_IRQ;
 	}
  hint_found:
@@ -1046,7 +1046,7 @@ unsigned int irq_alloc_virt(struct irq_host *host,
 		smp_wmb();
 		irq_map[i].host = host;
 	}
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 	return found;
 }
 
@@ -1058,7 +1058,7 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 	WARN_ON (virq < NUM_ISA_INTERRUPTS);
 	WARN_ON (count == 0 || (virq + count) > irq_virq_count);
 
-	spin_lock_irqsave(&irq_big_lock, flags);
+	raw_spin_lock_irqsave(&irq_big_lock, flags);
 	for (i = virq; i < (virq + count); i++) {
 		struct irq_host *host;
 
@@ -1071,7 +1071,7 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 		smp_wmb();
 		irq_map[i].host = NULL;
 	}
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+	raw_spin_unlock_irqrestore(&irq_big_lock, flags);
 }
 
 int arch_early_irq_init(void)

commit 17081102a6e0fe32cf47cdbdf8f2e9ab55273b08
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Jan 31 20:34:36 2010 +0000

    powerpc: Convert global "BAD" interrupt to per cpu spurious
    
    I often get asked if BAD interrupts are really bad. On some boxes (eg
    IBM machines running a hypervisor) there are valid cases where are
    presented with an interrupt that is not for us. These cases are common
    enough to show up as thousands of BAD interrupts a day.
    
    Tone them down by calling them spurious. Since they can be a significant cause
    of OS jitter, we may as well log them per cpu so we know where they are
    occurring.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 710505240f2f..9ae77e52f9d3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -77,7 +77,6 @@ DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 EXPORT_PER_CPU_SYMBOL(irq_stat);
 
 int __irq_offset_value;
-static int ppc_spurious_interrupts;
 
 #ifdef CONFIG_PPC32
 EXPORT_SYMBOL(__irq_offset_value);
@@ -201,6 +200,11 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs);
         seq_printf(p, "  Local timer interrupts\n");
 
+	seq_printf(p, "%*s: ", prec, "SPU");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).spurious_irqs);
+	seq_printf(p, "  Spurious interrupts\n");
+
 	seq_printf(p, "%*s: ", prec, "CNT");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).pmu_irqs);
@@ -211,8 +215,6 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(irq_stat, j).mce_exceptions);
 	seq_printf(p, "  Machine check exceptions\n");
 
-	seq_printf(p, "%*s: %10u\n", prec, "BAD", ppc_spurious_interrupts);
-
 	return 0;
 }
 
@@ -282,13 +284,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 
 	sum += per_cpu(irq_stat, cpu).pmu_irqs;
 	sum += per_cpu(irq_stat, cpu).mce_exceptions;
-
-	return sum;
-}
-
-u64 arch_irq_stat(void)
-{
-	u64 sum = ppc_spurious_interrupts;
+	sum += per_cpu(irq_stat, cpu).spurious_irqs;
 
 	return sum;
 }
@@ -404,8 +400,7 @@ void do_IRQ(struct pt_regs *regs)
 	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE)
 		handle_one_irq(irq);
 	else if (irq != NO_IRQ_IGNORE)
-		/* That's not SMP safe ... but who cares ? */
-		ppc_spurious_interrupts++;
+		__get_cpu_var(irq_stat).spurious_irqs++;
 
 	irq_exit();
 	set_irq_regs(old_regs);

commit 89713ed10815401a1bfe12e3a076b64048381b56
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Jan 31 20:34:06 2010 +0000

    powerpc: Add timer, performance monitor and machine check counts to /proc/interrupts
    
    With NO_HZ it is useful to know how often the decrementer is going off. The
    patch below adds an entry for it and also adds it into the /proc/stat
    summaries.
    
    While here, I added performance monitoring and machine check exceptions.
    I found it useful to keep an eye on the PMU exception rate
    when using the perf tool. Since it's possible to take a completely
    handled machine check on a System p box it also sounds like a good idea to
    keep a machine check summary.
    
    The event naming matches x86 to keep gratuitous differences to a minimum.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b9cbb4570048..710505240f2f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -196,6 +196,21 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	}
 #endif /* CONFIG_PPC32 && CONFIG_TAU_INT */
 
+	seq_printf(p, "%*s: ", prec, "LOC");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).timer_irqs);
+        seq_printf(p, "  Local timer interrupts\n");
+
+	seq_printf(p, "%*s: ", prec, "CNT");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).pmu_irqs);
+	seq_printf(p, "  Performance monitoring interrupts\n");
+
+	seq_printf(p, "%*s: ", prec, "MCE");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(irq_stat, j).mce_exceptions);
+	seq_printf(p, "  Machine check exceptions\n");
+
 	seq_printf(p, "%*s: %10u\n", prec, "BAD", ppc_spurious_interrupts);
 
 	return 0;
@@ -258,6 +273,26 @@ int show_interrupts(struct seq_file *p, void *v)
 	return 0;
 }
 
+/*
+ * /proc/stat helpers
+ */
+u64 arch_irq_stat_cpu(unsigned int cpu)
+{
+	u64 sum = per_cpu(irq_stat, cpu).timer_irqs;
+
+	sum += per_cpu(irq_stat, cpu).pmu_irqs;
+	sum += per_cpu(irq_stat, cpu).mce_exceptions;
+
+	return sum;
+}
+
+u64 arch_irq_stat(void)
+{
+	u64 sum = ppc_spurious_interrupts;
+
+	return sum;
+}
+
 #ifdef CONFIG_HOTPLUG_CPU
 void fixup_irqs(cpumask_t map)
 {

commit c86845ede8b643ca025aec277dec1892d0ccac01
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Jan 31 20:33:18 2010 +0000

    powerpc: Rework /proc/interrupts
    
    On a large machine I noticed the columns of /proc/interrupts failed to line up
    with the header after CPU9. At sufficiently large numbers of CPUs it becomes
    impossible to line up the CPU number with the counts.
    
    While fixing this I noticed x86 has a number of updates that we may as well
    pull in. On PowerPC we currently omit an interrupt completely if there is no
    active handler, whereas on x86 it is printed if there is a non zero count.
    
    The x86 code also spaces the first column correctly based on nr_irqs.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c6ac5583672a..b9cbb4570048 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -183,30 +183,46 @@ notrace void raw_local_irq_restore(unsigned long en)
 EXPORT_SYMBOL(raw_local_irq_restore);
 #endif /* CONFIG_PPC64 */
 
+static int show_other_interrupts(struct seq_file *p, int prec)
+{
+	int j;
+
+#if defined(CONFIG_PPC32) && defined(CONFIG_TAU_INT)
+	if (tau_initialized) {
+		seq_printf(p, "%*s: ", prec, "TAU");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", tau_interrupts(j));
+		seq_puts(p, "  PowerPC             Thermal Assist (cpu temp)\n");
+	}
+#endif /* CONFIG_PPC32 && CONFIG_TAU_INT */
+
+	seq_printf(p, "%*s: %10u\n", prec, "BAD", ppc_spurious_interrupts);
+
+	return 0;
+}
+
 int show_interrupts(struct seq_file *p, void *v)
 {
-	int i = *(loff_t *)v, j;
+	unsigned long flags, any_count = 0;
+	int i = *(loff_t *) v, j, prec;
 	struct irqaction *action;
 	struct irq_desc *desc;
-	unsigned long flags;
 
+	if (i > nr_irqs)
+		return 0;
+
+	for (prec = 3, j = 1000; prec < 10 && j <= nr_irqs; ++prec)
+		j *= 10;
+
+	if (i == nr_irqs)
+		return show_other_interrupts(p, prec);
+
+	/* print header */
 	if (i == 0) {
-		seq_puts(p, "           ");
+		seq_printf(p, "%*s", prec + 8, "");
 		for_each_online_cpu(j)
-			seq_printf(p, "CPU%d       ", j);
+			seq_printf(p, "CPU%-8d", j);
 		seq_putc(p, '\n');
-	} else if (i == nr_irqs) {
-#if defined(CONFIG_PPC32) && defined(CONFIG_TAU_INT)
-		if (tau_initialized){
-			seq_puts(p, "TAU: ");
-			for_each_online_cpu(j)
-				seq_printf(p, "%10u ", tau_interrupts(j));
-			seq_puts(p, "  PowerPC             Thermal Assist (cpu temp)\n");
-		}
-#endif /* CONFIG_PPC32 && CONFIG_TAU_INT*/
-		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
-
-		return 0;
 	}
 
 	desc = irq_to_desc(i);
@@ -214,34 +230,31 @@ int show_interrupts(struct seq_file *p, void *v)
 		return 0;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-
+	for_each_online_cpu(j)
+		any_count |= kstat_irqs_cpu(i, j);
 	action = desc->action;
-	if (!action || !action->handler)
-		goto skip;
+	if (!action && !any_count)
+		goto out;
 
-	seq_printf(p, "%3d: ", i);
-#ifdef CONFIG_SMP
+	seq_printf(p, "%*d: ", prec, i);
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-#else
-	seq_printf(p, "%10u ", kstat_irqs(i));
-#endif /* CONFIG_SMP */
 
 	if (desc->chip)
-		seq_printf(p, " %s ", desc->chip->name);
+		seq_printf(p, "  %-16s", desc->chip->name);
 	else
-		seq_puts(p, "  None      ");
+		seq_printf(p, "  %-16s", "None");
+	seq_printf(p, " %-8s", (desc->status & IRQ_LEVEL) ? "Level" : "Edge");
 
-	seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
-	seq_printf(p, "    %s", action->name);
+	if (action) {
+		seq_printf(p, "     %s", action->name);
+		while ((action = action->next) != NULL)
+			seq_printf(p, ", %s", action->name);
+	}
 
-	for (action = action->next; action; action = action->next)
-		seq_printf(p, ", %s", action->name);
 	seq_putc(p, '\n');
-
-skip:
+out:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-
 	return 0;
 }
 

commit 8c007bfdf1bab536f824d91fccc76596c18aba78
Author: Anton Blanchard <anton@samba.org>
Date:   Sun Jan 31 20:30:23 2010 +0000

    powerpc: Reduce footprint of irq_stat
    
    PowerPC is currently using asm-generic/hardirq.h which statically allocates an
    NR_CPUS irq_stat array. Switch to an arch specific implementation which uses
    per cpu data:
    
    On a kernel with NR_CPUS=1024, this saves quite a lot of memory:
    
       text    data     bss      dec         hex    filename
    8767938 2944132 1636796 13348866         cbb002 vmlinux.baseline
    8767779 2944260 1505724 13217763         c9afe3 vmlinux.irq_cpustat
    
    A saving of around 128kB.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9040330b0530..c6ac5583672a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -73,6 +73,9 @@
 #define CREATE_TRACE_POINTS
 #include <asm/trace.h>
 
+DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
+EXPORT_PER_CPU_SYMBOL(irq_stat);
+
 int __irq_offset_value;
 static int ppc_spurious_interrupts;
 

commit 239007b8440abff689632f50cdf0f2b9e895b534
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 16:46:45 2009 +0100

    genirq: Convert irq_desc.lock to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f6dca4f4b295..9040330b0530 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -210,7 +210,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	if (!desc)
 		return 0;
 
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 
 	action = desc->action;
 	if (!action || !action->handler)
@@ -237,7 +237,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	seq_putc(p, '\n');
 
 skip:
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	return 0;
 }
@@ -1112,7 +1112,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 		if (!desc)
 			continue;
 
-		spin_lock_irqsave(&desc->lock, flags);
+		raw_spin_lock_irqsave(&desc->lock, flags);
 
 		if (desc->action && desc->action->handler) {
 			seq_printf(m, "%5d  ", i);
@@ -1131,7 +1131,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			seq_printf(m, "%s\n", p);
 		}
 
-		spin_unlock_irqrestore(&desc->lock, flags);
+		raw_spin_unlock_irqrestore(&desc->lock, flags);
 	}
 
 	return 0;

commit bcd6acd51f3d4d1ada201e9bc5c40a31d6d80c71
Merge: 11c34c7deaee 3ff6a468b45b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Dec 9 17:14:38 2009 +1100

    Merge commit 'origin/master' into next
    
    Conflicts:
            include/linux/kvm.h

commit 40d50cf7ca956183f3a573bc21082e1c7d04fa7b
Author: Roman Fietze <roman.fietze@telemotive.de>
Date:   Tue Dec 8 02:39:50 2009 +0000

    powerpc: Make "intspec" pointers in irq_host->xlate() const
    
    Writing a driver using SCLPC on the MPC5200B I detected, that the
    intspec arrays to map irqs to Linux virq cannot be const, because the
    mapping and xlate functions only take non const pointers. All those
    functions do not modify the intspec, so a const pointer could be used.
    
    Signed-off-by: Roman Fietze <roman.fietze@telemotive.de>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a31176ace02b..042a53009701 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -725,7 +725,7 @@ unsigned int irq_create_mapping(struct irq_host *host,
 EXPORT_SYMBOL_GPL(irq_create_mapping);
 
 unsigned int irq_create_of_mapping(struct device_node *controller,
-				   u32 *intspec, unsigned int intsize)
+				   const u32 *intspec, unsigned int intsize)
 {
 	struct irq_host *host;
 	irq_hw_number_t hwirq;

commit b27df67248d3ae61d7814f18e363954254935090
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Nov 18 23:44:21 2009 +0000

    powerpc: Fixup last users of irq_chip->typename
    
    The typename member of struct irq_chip was kept for migration purposes
    and is obsolete since more than 2 years. Fix up the leftovers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: linuxppc-dev@ozlabs.org
    Acked-by: Geoff Levand <geoffrey.levand@am.sony.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index eba53923630f..a31176ace02b 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -223,7 +223,7 @@ int show_interrupts(struct seq_file *p, void *v)
 #endif /* CONFIG_SMP */
 
 	if (desc->chip)
-		seq_printf(p, " %s ", desc->chip->typename);
+		seq_printf(p, " %s ", desc->chip->name);
 	else
 		seq_puts(p, "  None      ");
 
@@ -1112,8 +1112,8 @@ static int virq_debug_show(struct seq_file *m, void *private)
 			seq_printf(m, "%5d  ", i);
 			seq_printf(m, "0x%05lx  ", virq_to_hw(i));
 
-			if (desc->chip && desc->chip->typename)
-				p = desc->chip->typename;
+			if (desc->chip && desc->chip->name)
+				p = desc->chip->name;
 			else
 				p = none;
 			seq_printf(m, "%-15s  ", p);

commit cd015707176820b86d07b5dffdecfefdd539a497
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 13 19:45:03 2009 +0000

    powerpc: Enable sparse irq_descs on powerpc
    
    Defining CONFIG_SPARSE_IRQ enables generic code that gets rid of the
    static irq_desc array, and replaces it with an array of pointers to
    irq_descs.
    
    It also allows node local allocation of irq_descs, however we
    currently don't have the information available to do that, so we just
    allocate them on all on node 0.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 63e27d5c52de..eba53923630f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -85,7 +85,10 @@ extern int tau_interrupts(int);
 #endif /* CONFIG_PPC32 */
 
 #ifdef CONFIG_PPC64
+
+#ifndef CONFIG_SPARSE_IRQ
 EXPORT_SYMBOL(irq_desc);
+#endif
 
 int distribute_irqs = 1;
 
@@ -613,8 +616,16 @@ void irq_set_virq_count(unsigned int count)
 static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
+	struct irq_desc *desc;
+
+	desc = irq_to_desc_alloc_node(virq, 0);
+	if (!desc) {
+		pr_debug("irq: -> allocating desc failed\n");
+		goto error;
+	}
+
 	/* Clear IRQ_NOREQUEST flag */
-	irq_to_desc(virq)->status &= ~IRQ_NOREQUEST;
+	desc->status &= ~IRQ_NOREQUEST;
 
 	/* map it */
 	smp_wmb();
@@ -623,11 +634,14 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 
 	if (host->ops->map(host, virq, hwirq)) {
 		pr_debug("irq: -> mapping failed, freeing\n");
-		irq_free_virt(virq, 1);
-		return -1;
+		goto error;
 	}
 
 	return 0;
+
+error:
+	irq_free_virt(virq, 1);
+	return -1;
 }
 
 unsigned int irq_create_direct_mapping(struct irq_host *host)
@@ -1008,12 +1022,24 @@ void irq_free_virt(unsigned int virq, unsigned int count)
 	spin_unlock_irqrestore(&irq_big_lock, flags);
 }
 
-void irq_early_init(void)
+int arch_early_irq_init(void)
 {
-	unsigned int i;
+	struct irq_desc *desc;
+	int i;
 
-	for (i = 0; i < NR_IRQS; i++)
-		irq_to_desc(i)->status |= IRQ_NOREQUEST;
+	for (i = 0; i < NR_IRQS; i++) {
+		desc = irq_to_desc(i);
+		if (desc)
+			desc->status |= IRQ_NOREQUEST;
+	}
+
+	return 0;
+}
+
+int arch_init_chip_data(struct irq_desc *desc, int node)
+{
+	desc->status |= IRQ_NOREQUEST;
+	return 0;
 }
 
 /* We need to create the radix trees late */

commit 750ab112919220a1d14491ae210b689bcb7d6d66
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 13 19:45:00 2009 +0000

    powerpc: Rearrange and fix show_interrupts() for sparse irq_descs
    
    Move the default case out of the if, ie. when we're just displaying
    an irq. And consolidate all the odd cases at the top, ie. printing
    the header and footer.
    
    And in the process cope with sparse irq_descs.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index baa49eb93228..63e27d5c52de 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -187,33 +187,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		for_each_online_cpu(j)
 			seq_printf(p, "CPU%d       ", j);
 		seq_putc(p, '\n');
-	}
-
-	if (i < NR_IRQS) {
-		desc = irq_to_desc(i);
-		spin_lock_irqsave(&desc->lock, flags);
-		action = desc->action;
-		if (!action || !action->handler)
-			goto skip;
-		seq_printf(p, "%3d: ", i);
-#ifdef CONFIG_SMP
-		for_each_online_cpu(j)
-			seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-#else
-		seq_printf(p, "%10u ", kstat_irqs(i));
-#endif /* CONFIG_SMP */
-		if (desc->chip)
-			seq_printf(p, " %s ", desc->chip->typename);
-		else
-			seq_puts(p, "  None      ");
-		seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
-		seq_printf(p, "    %s", action->name);
-		for (action = action->next; action; action = action->next)
-			seq_printf(p, ", %s", action->name);
-		seq_putc(p, '\n');
-skip:
-		spin_unlock_irqrestore(&desc->lock, flags);
-	} else if (i == NR_IRQS) {
+	} else if (i == nr_irqs) {
 #if defined(CONFIG_PPC32) && defined(CONFIG_TAU_INT)
 		if (tau_initialized){
 			seq_puts(p, "TAU: ");
@@ -223,7 +197,43 @@ int show_interrupts(struct seq_file *p, void *v)
 		}
 #endif /* CONFIG_PPC32 && CONFIG_TAU_INT*/
 		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
+
+		return 0;
 	}
+
+	desc = irq_to_desc(i);
+	if (!desc)
+		return 0;
+
+	spin_lock_irqsave(&desc->lock, flags);
+
+	action = desc->action;
+	if (!action || !action->handler)
+		goto skip;
+
+	seq_printf(p, "%3d: ", i);
+#ifdef CONFIG_SMP
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
+#else
+	seq_printf(p, "%10u ", kstat_irqs(i));
+#endif /* CONFIG_SMP */
+
+	if (desc->chip)
+		seq_printf(p, " %s ", desc->chip->typename);
+	else
+		seq_puts(p, "  None      ");
+
+	seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
+	seq_printf(p, "    %s", action->name);
+
+	for (action = action->next; action; action = action->next)
+		seq_printf(p, ", %s", action->name);
+	seq_putc(p, '\n');
+
+skip:
+	spin_unlock_irqrestore(&desc->lock, flags);
+
 	return 0;
 }
 

commit 76f1d94f3ebdee0d14cab4d87bdeed1cf9badb17
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 13 19:44:56 2009 +0000

    powerpc: Make virq_debug_show() cope with sparse irq_descs
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 65632215f020..baa49eb93228 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1065,8 +1065,11 @@ static int virq_debug_show(struct seq_file *m, void *private)
 	seq_printf(m, "%-5s  %-7s  %-15s  %s\n", "virq", "hwirq",
 		      "chip name", "host name");
 
-	for (i = 1; i < NR_IRQS; i++) {
+	for (i = 1; i < nr_irqs; i++) {
 		desc = irq_to_desc(i);
+		if (!desc)
+			continue;
+
 		spin_lock_irqsave(&desc->lock, flags);
 
 		if (desc->action && desc->action->handler) {

commit 6cff46f4bc6cc4a8a4154b0b6a2e669db08e8fd2
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 13 19:44:51 2009 +0000

    powerpc: Remove get_irq_desc()
    
    get_irq_desc() is a powerpc-specific version of irq_to_desc(). That
    is reason enough to remove it, but it also doesn't know about sparse
    irq_desc support which irq_to_desc() does (when we enable it).
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index e5d121177984..65632215f020 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -190,7 +190,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	}
 
 	if (i < NR_IRQS) {
-		desc = get_irq_desc(i);
+		desc = irq_to_desc(i);
 		spin_lock_irqsave(&desc->lock, flags);
 		action = desc->action;
 		if (!action || !action->handler)
@@ -230,23 +230,25 @@ int show_interrupts(struct seq_file *p, void *v)
 #ifdef CONFIG_HOTPLUG_CPU
 void fixup_irqs(cpumask_t map)
 {
+	struct irq_desc *desc;
 	unsigned int irq;
 	static int warned;
 
 	for_each_irq(irq) {
 		cpumask_t mask;
 
-		if (irq_desc[irq].status & IRQ_PER_CPU)
+		desc = irq_to_desc(irq);
+		if (desc && desc->status & IRQ_PER_CPU)
 			continue;
 
-		cpumask_and(&mask, irq_desc[irq].affinity, &map);
+		cpumask_and(&mask, desc->affinity, &map);
 		if (any_online_cpu(mask) == NR_CPUS) {
 			printk("Breaking affinity for irq %i\n", irq);
 			mask = map;
 		}
-		if (irq_desc[irq].chip->set_affinity)
-			irq_desc[irq].chip->set_affinity(irq, &mask);
-		else if (irq_desc[irq].action && !(warned++))
+		if (desc->chip->set_affinity)
+			desc->chip->set_affinity(irq, &mask);
+		else if (desc->action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}
 
@@ -273,7 +275,7 @@ static inline void handle_one_irq(unsigned int irq)
 		return;
 	}
 
-	desc = irq_desc + irq;
+	desc = irq_to_desc(irq);
 	saved_sp_limit = current->thread.ksp_limit;
 
 	irqtp->task = curtp->task;
@@ -535,7 +537,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 			smp_wmb();
 
 			/* Clear norequest flags */
-			get_irq_desc(i)->status &= ~IRQ_NOREQUEST;
+			irq_to_desc(i)->status &= ~IRQ_NOREQUEST;
 
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to
@@ -602,7 +604,7 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
 	/* Clear IRQ_NOREQUEST flag */
-	get_irq_desc(virq)->status &= ~IRQ_NOREQUEST;
+	irq_to_desc(virq)->status &= ~IRQ_NOREQUEST;
 
 	/* map it */
 	smp_wmb();
@@ -732,7 +734,7 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 
 	/* Set type if specified and different than the current one */
 	if (type != IRQ_TYPE_NONE &&
-	    type != (get_irq_desc(virq)->status & IRQF_TRIGGER_MASK))
+	    type != (irq_to_desc(virq)->status & IRQF_TRIGGER_MASK))
 		set_irq_type(virq, type);
 	return virq;
 }
@@ -804,7 +806,7 @@ void irq_dispose_mapping(unsigned int virq)
 	irq_map[virq].hwirq = host->inval_irq;
 
 	/* Set some flags */
-	get_irq_desc(virq)->status |= IRQ_NOREQUEST;
+	irq_to_desc(virq)->status |= IRQ_NOREQUEST;
 
 	/* Free it */
 	irq_free_virt(virq, 1);
@@ -1001,7 +1003,7 @@ void irq_early_init(void)
 	unsigned int i;
 
 	for (i = 0; i < NR_IRQS; i++)
-		get_irq_desc(i)->status |= IRQ_NOREQUEST;
+		irq_to_desc(i)->status |= IRQ_NOREQUEST;
 }
 
 /* We need to create the radix trees late */
@@ -1064,7 +1066,7 @@ static int virq_debug_show(struct seq_file *m, void *private)
 		      "chip name", "host name");
 
 	for (i = 1; i < NR_IRQS; i++) {
-		desc = get_irq_desc(i);
+		desc = irq_to_desc(i);
 		spin_lock_irqsave(&desc->lock, flags);
 
 		if (desc->action && desc->action->handler) {

commit 1bf4af165050d90ea6659ffb2536ec8ca783aab5
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Oct 26 18:47:42 2009 +0000

    powerpc: tracing: Add powerpc tracepoints for interrupt entry and exit
    
    This adds powerpc-specific tracepoints for interrupt entry and exit.
    
    While we already have generic irq_handler_entry and irq_handler_exit
    tracepoints there are cases on our virtualised powerpc machines where an
    interrupt is presented to the OS, but subsequently handled by the hypervisor.
    This means no OS interrupt handler is invoked.
    
    Here is an example on a POWER6 machine with the patch below applied:
    
    <idle>-0     [006]  3243.949840744: irq_entry: pt_regs=c0000000ce31fb10
    <idle>-0     [006]  3243.949850520: irq_exit: pt_regs=c0000000ce31fb10
    
    <idle>-0     [007]  3243.950218208: irq_entry: pt_regs=c0000000ce323b10
    <idle>-0     [007]  3243.950224080: irq_exit: pt_regs=c0000000ce323b10
    
    <idle>-0     [000]  3244.021879320: irq_entry: pt_regs=c000000000a63aa0
    <idle>-0     [000]  3244.021883616: irq_handler_entry: irq=87 handler=eth0
    <idle>-0     [000]  3244.021887328: irq_handler_exit: irq=87 return=handled
    <idle>-0     [000]  3244.021897408: irq_exit: pt_regs=c000000000a63aa0
    
    Here we see two phantom interrupts (no handler was invoked), followed
    by a real interrupt for eth0. Without the tracepoints in this patch we
    would have missed the phantom interrupts.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index e5d121177984..02a334662cc0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -70,6 +70,8 @@
 #include <asm/firmware.h>
 #include <asm/lv1call.h>
 #endif
+#define CREATE_TRACE_POINTS
+#include <asm/trace.h>
 
 int __irq_offset_value;
 static int ppc_spurious_interrupts;
@@ -325,6 +327,8 @@ void do_IRQ(struct pt_regs *regs)
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 
+	trace_irq_entry(regs);
+
 	irq_enter();
 
 	check_stack_overflow();
@@ -348,6 +352,8 @@ void do_IRQ(struct pt_regs *regs)
 		timer_interrupt(regs);
 	}
 #endif
+
+	trace_irq_exit(regs);
 }
 
 void __init init_IRQ(void)

commit cdd6c482c9ff9c55475ee7392ec8f672eddb7be6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Sep 21 12:02:48 2009 +0200

    perf: Do the big rename: Performance Counters -> Performance Events
    
    Bye-bye Performance Counters, welcome Performance Events!
    
    In the past few months the perfcounters subsystem has grown out its
    initial role of counting hardware events, and has become (and is
    becoming) a much broader generic event enumeration, reporting, logging,
    monitoring, analysis facility.
    
    Naming its core object 'perf_counter' and naming the subsystem
    'perfcounters' has become more and more of a misnomer. With pending
    code like hw-breakpoints support the 'counter' name is less and
    less appropriate.
    
    All in one, we've decided to rename the subsystem to 'performance
    events' and to propagate this rename through all fields, variables
    and API names. (in an ABI compatible fashion)
    
    The word 'event' is also a bit shorter than 'counter' - which makes
    it slightly more convenient to write/handle as well.
    
    Thanks goes to Stephane Eranian who first observed this misnomer and
    suggested a rename.
    
    User-space tooling and ABI compatibility is not affected - this patch
    should be function-invariant. (Also, defconfigs were not touched to
    keep the size down.)
    
    This patch has been generated via the following script:
    
      FILES=$(find * -type f | grep -vE 'oprofile|[^K]config')
    
      sed -i \
        -e 's/PERF_EVENT_/PERF_RECORD_/g' \
        -e 's/PERF_COUNTER/PERF_EVENT/g' \
        -e 's/perf_counter/perf_event/g' \
        -e 's/nb_counters/nb_events/g' \
        -e 's/swcounter/swevent/g' \
        -e 's/tpcounter_event/tp_event/g' \
        $FILES
    
      for N in $(find . -name perf_counter.[ch]); do
        M=$(echo $N | sed 's/perf_counter/perf_event/g')
        mv $N $M
      done
    
      FILES=$(find . -name perf_event.*)
    
      sed -i \
        -e 's/COUNTER_MASK/REG_MASK/g' \
        -e 's/COUNTER/EVENT/g' \
        -e 's/\<event\>/event_id/g' \
        -e 's/counter/event/g' \
        -e 's/Counter/Event/g' \
        $FILES
    
    ... to keep it as correct as possible. This script can also be
    used by anyone who has pending perfcounters patches - it converts
    a Linux kernel tree over to the new naming. We tried to time this
    change to the point in time where the amount of pending patches
    is the smallest: the end of the merge window.
    
    Namespace clashes were fixed up in a preparatory patch - and some
    stylistic fallout will be fixed up in a subsequent patch.
    
    ( NOTE: 'counters' are still the proper terminology when we deal
      with hardware registers - and these sed scripts are a bit
      over-eager in renaming them. I've undone some of that, but
      in case there's something left where 'counter' would be
      better than 'event' we can undo that on an individual basis
      instead of touching an otherwise nicely automated patch. )
    
    Suggested-by: Stephane Eranian <eranian@google.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Reviewed-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: <linux-arch@vger.kernel.org>
    LKML-Reference: <new-submission>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index f7f376ea7b17..e5d121177984 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -53,7 +53,7 @@
 #include <linux/bootmem.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
-#include <linux/perf_counter.h>
+#include <linux/perf_event.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -138,9 +138,9 @@ notrace void raw_local_irq_restore(unsigned long en)
 	}
 #endif /* CONFIG_PPC_STD_MMU_64 */
 
-	if (test_perf_counter_pending()) {
-		clear_perf_counter_pending();
-		perf_counter_do_pending();
+	if (test_perf_event_pending()) {
+		clear_perf_event_pending();
+		perf_event_do_pending();
 	}
 
 	/*

commit bc47ab0241c7c86da4f5e5f82fbca7d45387c18d
Merge: 37f9ef553bed 8ebf975608aa
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jun 12 16:53:38 2009 +1000

    Merge commit 'origin/master' into next
    
    Manual merge of:
            arch/powerpc/kernel/asm-offsets.c

commit e14112d1bd5e193166b54be19119cf6440470560
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Jun 12 10:14:22 2009 +1000

    perfcounters: remove powerpc definitions of perf_counter_do_pending
    
    Commit 925d519ab82b6dd7aca9420d809ee83819c08db2 ("perf_counter:
    unify and fix delayed counter wakeup") added global definitions.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index feff792ed0f9..844d3f882a15 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -53,6 +53,7 @@
 #include <linux/bootmem.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
+#include <linux/perf_counter.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>

commit 944916858a430a0627e483657d4cfa2cd2dfb4f7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jun 2 21:17:45 2009 +0000

    powerpc: Shield code specific to 64-bit server processors
    
    This is a random collection of added ifdef's around portions of
    code that only mak sense on server processors. Using either
    CONFIG_PPC_STD_MMU_64 or CONFIG_PPC_BOOK3S as seems appropriate.
    
    This is meant to make the future merging of Book3E 64-bit support
    easier.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 7d46e5d5b207..8564a412e7a6 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -117,6 +117,7 @@ notrace void raw_local_irq_restore(unsigned long en)
 	if (!en)
 		return;
 
+#ifdef CONFIG_PPC_STD_MMU_64
 	if (firmware_has_feature(FW_FEATURE_ISERIES)) {
 		/*
 		 * Do we need to disable preemption here?  Not really: in the
@@ -134,6 +135,7 @@ notrace void raw_local_irq_restore(unsigned long en)
 		if (local_paca->lppaca_ptr->int_dword.any_int)
 			iseries_handle_interrupts();
 	}
+#endif /* CONFIG_PPC_STD_MMU_64 */
 
 	/*
 	 * if (get_paca()->hard_enabled) return;

commit 835363e67dc27ad0809de05b2b5a8b725c95d77f
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Apr 22 15:31:43 2009 +0000

    powerpc/irq: Remove fallback to __do_IRQ()
    
    We should no longer have any irq code that needs __do_IRQ(), so
    remove the fallback to __do_IRQ().
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a5fe12aa937d..7d46e5d5b207 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -254,7 +254,6 @@ static inline void handle_one_irq(unsigned int irq)
 	struct thread_info *curtp, *irqtp;
 	unsigned long saved_sp_limit;
 	struct irq_desc *desc;
-	void *handler;
 
 	/* Switch to the irq stack to handle this */
 	curtp = current_thread_info();
@@ -269,10 +268,6 @@ static inline void handle_one_irq(unsigned int irq)
 	desc = irq_desc + irq;
 	saved_sp_limit = current->thread.ksp_limit;
 
-	handler = desc->handle_irq;
-	if (handler == NULL)
-		handler = &__do_IRQ;
-
 	irqtp->task = curtp->task;
 	irqtp->flags = 0;
 
@@ -284,7 +279,7 @@ static inline void handle_one_irq(unsigned int irq)
 	current->thread.ksp_limit = (unsigned long)irqtp +
 		_ALIGN_UP(sizeof(struct thread_info), 16);
 
-	call_handle_irq(irq, desc, irqtp, handler);
+	call_handle_irq(irq, desc, irqtp, desc->handle_irq);
 	current->thread.ksp_limit = saved_sp_limit;
 	irqtp->task = NULL;
 

commit 9b647a30cbc228259555d6b0b6bc7d9ec798f907
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Apr 22 15:31:38 2009 +0000

    powerpc/irq: Move get_irq() comment into header
    
    The guts of do_IRQ() isn't really the right place to be documenting
    the ppc_md.get_irq() interface. So move the comment into machdep.h
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 463b6ab9d6b9..a5fe12aa937d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -326,13 +326,6 @@ void do_IRQ(struct pt_regs *regs)
 
 	check_stack_overflow();
 
-	/*
-	 * Every platform is required to implement ppc_md.get_irq.
-	 * This function will either return an irq number or NO_IRQ to
-	 * indicate there are no more pending.
-	 * The value NO_IRQ_IGNORE is for buggy hardware and means that this
-	 * IRQ has already been handled. -- Tom
-	 */
 	irq = ppc_md.get_irq();
 
 	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE)

commit d7cb10d6d23f451eec3d1f0f4e4e8862333fa152
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Apr 22 15:31:37 2009 +0000

    powerpc/irq: Move stack overflow check into a separate function
    
    Makes do_IRQ() shorter and clearer.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 3d3658d0b7b9..463b6ab9d6b9 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -301,6 +301,22 @@ static inline void handle_one_irq(unsigned int irq)
 }
 #endif
 
+static inline void check_stack_overflow(void)
+{
+#ifdef CONFIG_DEBUG_STACKOVERFLOW
+	long sp;
+
+	sp = __get_SP() & (THREAD_SIZE-1);
+
+	/* check for stack overflow: is there less than 2KB free? */
+	if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
+		printk("do_IRQ: stack overflow: %ld\n",
+			sp - sizeof(struct thread_info));
+		dump_stack();
+	}
+#endif
+}
+
 void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
@@ -308,20 +324,7 @@ void do_IRQ(struct pt_regs *regs)
 
 	irq_enter();
 
-#ifdef CONFIG_DEBUG_STACKOVERFLOW
-	/* Debugging check for stack overflow: is there less than 2KB free? */
-	{
-		long sp;
-
-		sp = __get_SP() & (THREAD_SIZE-1);
-
-		if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
-			printk("do_IRQ: stack overflow: %ld\n",
-				sp - sizeof(struct thread_info));
-			dump_stack();
-		}
-	}
-#endif
+	check_stack_overflow();
 
 	/*
 	 * Every platform is required to implement ppc_md.get_irq.

commit f2694ba56808a3a0fa45d9bb45289575f31e48d2
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Apr 28 01:57:43 2009 +0000

    powerpc/irq: Move #ifdef'ed body of do_IRQ() into a separate function
    
    Rather than a giant ifdef in the body of do_IRQ(), including a
    dangling else, move the irq stack logic into a separate routine and
    do the ifdef there.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8c1a4966867e..3d3658d0b7b9 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -248,13 +248,63 @@ void fixup_irqs(cpumask_t map)
 }
 #endif
 
+#ifdef CONFIG_IRQSTACKS
+static inline void handle_one_irq(unsigned int irq)
+{
+	struct thread_info *curtp, *irqtp;
+	unsigned long saved_sp_limit;
+	struct irq_desc *desc;
+	void *handler;
+
+	/* Switch to the irq stack to handle this */
+	curtp = current_thread_info();
+	irqtp = hardirq_ctx[smp_processor_id()];
+
+	if (curtp == irqtp) {
+		/* We're already on the irq stack, just handle it */
+		generic_handle_irq(irq);
+		return;
+	}
+
+	desc = irq_desc + irq;
+	saved_sp_limit = current->thread.ksp_limit;
+
+	handler = desc->handle_irq;
+	if (handler == NULL)
+		handler = &__do_IRQ;
+
+	irqtp->task = curtp->task;
+	irqtp->flags = 0;
+
+	/* Copy the softirq bits in preempt_count so that the
+	 * softirq checks work in the hardirq context. */
+	irqtp->preempt_count = (irqtp->preempt_count & ~SOFTIRQ_MASK) |
+			       (curtp->preempt_count & SOFTIRQ_MASK);
+
+	current->thread.ksp_limit = (unsigned long)irqtp +
+		_ALIGN_UP(sizeof(struct thread_info), 16);
+
+	call_handle_irq(irq, desc, irqtp, handler);
+	current->thread.ksp_limit = saved_sp_limit;
+	irqtp->task = NULL;
+
+	/* Set any flag that may have been set on the
+	 * alternate stack
+	 */
+	if (irqtp->flags)
+		set_bits(irqtp->flags, &curtp->flags);
+}
+#else
+static inline void handle_one_irq(unsigned int irq)
+{
+	generic_handle_irq(irq);
+}
+#endif
+
 void do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
-#ifdef CONFIG_IRQSTACKS
-	struct thread_info *curtp, *irqtp;
-#endif
 
 	irq_enter();
 
@@ -282,43 +332,9 @@ void do_IRQ(struct pt_regs *regs)
 	 */
 	irq = ppc_md.get_irq();
 
-	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE) {
-#ifdef CONFIG_IRQSTACKS
-		/* Switch to the irq stack to handle this */
-		curtp = current_thread_info();
-		irqtp = hardirq_ctx[smp_processor_id()];
-		if (curtp != irqtp) {
-			struct irq_desc *desc = irq_desc + irq;
-			void *handler = desc->handle_irq;
-			unsigned long saved_sp_limit = current->thread.ksp_limit;
-			if (handler == NULL)
-				handler = &__do_IRQ;
-			irqtp->task = curtp->task;
-			irqtp->flags = 0;
-
-			/* Copy the softirq bits in preempt_count so that the
-			 * softirq checks work in the hardirq context.
-			 */
-			irqtp->preempt_count =
-				(irqtp->preempt_count & ~SOFTIRQ_MASK) |
-				(curtp->preempt_count & SOFTIRQ_MASK);
-
-			current->thread.ksp_limit = (unsigned long)irqtp +
-				_ALIGN_UP(sizeof(struct thread_info), 16);
-			call_handle_irq(irq, desc, irqtp, handler);
-			current->thread.ksp_limit = saved_sp_limit;
-			irqtp->task = NULL;
-
-
-			/* Set any flag that may have been set on the
-			 * alternate stack
-			 */
-			if (irqtp->flags)
-				set_bits(irqtp->flags, &curtp->flags);
-		} else
-#endif
-			generic_handle_irq(irq);
-	} else if (irq != NO_IRQ_IGNORE)
+	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE)
+		handle_one_irq(irq);
+	else if (irq != NO_IRQ_IGNORE)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
 

commit 5ea472a77f8e4811ceee3f44a9deda6ad6e8b789
Merge: 6c009ecef8cc 577c9c456f0e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Apr 8 10:35:30 2009 +0200

    Merge commit 'v2.6.30-rc1' into perfcounters/core
    
    Conflicts:
            arch/powerpc/include/asm/systbl.h
            arch/powerpc/include/asm/unistd.h
            include/linux/init_task.h
    
    Merge reason: the conflicts are non-trivial: PowerPC placement
                  of sys_perf_counter_open has to be mixed with the
                  new preadv/pwrite syscalls.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit c7d07fdd5af084bbd0a7921f9b07037b9bc8829d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Sun Apr 5 16:05:02 2009 +0000

    powerpc: Print information about mapping hw irqs to virtual irqs
    
    The irq remapping layer seems to cause some confusion when people
    see a different irq number in /proc/interrupts vs the one they
    request in their driver or DTS.
    
    So have the irq remapping layer print out a message when we map an
    irq. The message is only printed the first time the irq is mapped,
    and it's KERN_DEBUG so most people won't see it.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Wolfram Sang <w.sang@pengutronix.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5576147e57b6..8c1a4966867e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -672,11 +672,13 @@ unsigned int irq_create_mapping(struct irq_host *host,
 			return NO_IRQ;
 		}
 	}
-	pr_debug("irq: -> obtained virq %d\n", virq);
 
 	if (irq_setup_virq(host, virq, hwirq))
 		return NO_IRQ;
 
+	printk(KERN_DEBUG "irq: irq %lu on host %s mapped to virtual irq %u\n",
+		hwirq, host->of_node ? host->of_node->full_name : "null", virq);
+
 	return virq;
 }
 EXPORT_SYMBOL_GPL(irq_create_mapping);

commit 925d519ab82b6dd7aca9420d809ee83819c08db2
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Mar 30 19:07:02 2009 +0200

    perf_counter: unify and fix delayed counter wakeup
    
    While going over the wakeup code I noticed delayed wakeups only work
    for hardware counters but basically all software counters rely on
    them.
    
    This patch unifies and generalizes the delayed wakeup to fix this
    issue.
    
    Since we're dealing with NMI context bits here, use a cmpxchg() based
    single link list implementation to track counters that have pending
    wakeups.
    
    [ This should really be generic code for delayed wakeups, but since we
      cannot use cmpxchg()/xchg() in generic code, I've let it live in the
      perf_counter code. -- Eric Dumazet could use it to aggregate the
      network wakeups. ]
    
    Furthermore, the x86 method of using TIF flags was flawed in that its
    quite possible to end up setting the bit on the idle task, loosing the
    wakeup.
    
    The powerpc method uses per-cpu storage and does appear to be
    sufficient.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Orig-LKML-Reference: <20090330171023.153932974@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 469e9635ff04..2cd471f92fe6 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -135,7 +135,7 @@ notrace void raw_local_irq_restore(unsigned long en)
 			iseries_handle_interrupts();
 	}
 
-	if (get_perf_counter_pending()) {
+	if (test_perf_counter_pending()) {
 		clear_perf_counter_pending();
 		perf_counter_do_pending();
 	}

commit b6c5a71da1477d261bc36254fe1f20d32b57598d
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Mar 16 21:00:00 2009 +1100

    perf_counter: abstract wakeup flag setting in core to fix powerpc build
    
    Impact: build fix for powerpc
    
    Commit bd753921015e7905 ("perf_counter: software counter event
    infrastructure") introduced a use of TIF_PERF_COUNTERS into the core
    perfcounter code.  This breaks the build on powerpc because we use
    a flag in a per-cpu area to signal wakeups on powerpc rather than
    a thread_info flag, because the thread_info flags have to be
    manipulated with atomic operations and are thus slower than per-cpu
    flags.
    
    This fixes the by changing the core to use an abstracted
    set_perf_counter_pending() function, which is defined on x86 to set
    the TIF_PERF_COUNTERS flag and on powerpc to set the per-cpu flag
    (paca->perf_counter_pending).  It changes the previous powerpc
    definition of set_perf_counter_pending to not take an argument and
    adds a clear_perf_counter_pending, so as to simplify the definition
    on x86.
    
    On x86, set_perf_counter_pending() is defined as a macro.  Defining
    it as a static inline in arch/x86/include/asm/perf_counters.h causes
    compile failures because <asm/perf_counters.h> gets included early in
    <linux/sched.h>, and the definitions of set_tsk_thread_flag etc. are
    therefore not available in <asm/perf_counters.h>.  (On powerpc this
    problem is avoided by defining set_perf_counter_pending etc. in
    <asm/hw_irq.h>.)
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0d2e37c57738..469e9635ff04 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -104,13 +104,6 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
-#ifdef CONFIG_PERF_COUNTERS
-notrace void __weak perf_counter_do_pending(void)
-{
-	set_perf_counter_pending(0);
-}
-#endif
-
 notrace void raw_local_irq_restore(unsigned long en)
 {
 	/*
@@ -142,8 +135,10 @@ notrace void raw_local_irq_restore(unsigned long en)
 			iseries_handle_interrupts();
 	}
 
-	if (get_perf_counter_pending())
+	if (get_perf_counter_pending()) {
+		clear_perf_counter_pending();
 		perf_counter_do_pending();
+	}
 
 	/*
 	 * if (get_paca()->hard_enabled) return;

commit f541ae326fa120fa5c57433e4d9a133df212ce41
Merge: e255357764f9 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 09:02:57 2009 +0200

    Merge branch 'linus' into perfcounters/core-v2
    
    Merge reason: we have gathered quite a few conflicts, need to merge upstream
    
    Conflicts:
            arch/powerpc/kernel/Makefile
            arch/x86/ia32/ia32entry.S
            arch/x86/include/asm/hardirq.h
            arch/x86/include/asm/unistd_32.h
            arch/x86/include/asm/unistd_64.h
            arch/x86/kernel/cpu/common.c
            arch/x86/kernel/irq.c
            arch/x86/kernel/syscall_table_32.S
            arch/x86/mm/iomap_32.c
            include/linux/sched.h
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9ff9a26b786c35ee8d2a66222924a807ec851a9f
Merge: 0a3108beea91 0d34fb8e93ce
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Mar 30 14:04:53 2009 +1100

    Merge commit 'origin/master' into next
    
    Manual merge of:
            arch/powerpc/include/asm/elf.h
            drivers/i2c/busses/i2c-mpc.c

commit 6e15cf04860074ad032e88c306bea656bbdd0f22
Merge: be0ea69674ed 60db56422043
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 26 21:39:17 2009 +0100

    Merge branch 'core/percpu' into percpu-cpumask-x86-for-linus-2
    
    Conflicts:
            arch/parisc/kernel/irq.c
            arch/x86/include/asm/fixmap_64.h
            arch/x86/include/asm/setup.h
            kernel/irq/handle.c
    
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 97f7d6bcc10687ff79632da338646a266dd590fc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 10 14:45:54 2009 +0000

    powerpc/irq: Convert obsolete irq_desc_t to struct irq_desc
    
    Impact: cleanup
    
    Convert the last remaining users.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    CC: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: linuxppc-dev@ozlabs.org
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 23b8b5e36f98..48ea2008b20d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -171,7 +171,7 @@ int show_interrupts(struct seq_file *p, void *v)
 {
 	int i = *(loff_t *)v, j;
 	struct irqaction *action;
-	irq_desc_t *desc;
+	struct irq_desc *desc;
 	unsigned long flags;
 
 	if (i == 0) {
@@ -1038,7 +1038,7 @@ arch_initcall(irq_late_init);
 static int virq_debug_show(struct seq_file *m, void *private)
 {
 	unsigned long flags;
-	irq_desc_t *desc;
+	struct irq_desc *desc;
 	const char *p;
 	char none[] = "none";
 	int i;

commit af37501c792107c2bde1524bdae38d9a247b841a
Merge: d859e29fe34c 99937d6455ce
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 18 18:15:49 2009 +0100

    Merge branch 'core/percpu' into perfcounters/core
    
    Conflicts:
            arch/x86/include/asm/pda.h
    
    We merge tip/core/percpu into tip/perfcounters/core because of a
    semantic and contextual conflict: the former eliminates the PDA,
    while the latter extends it with apic_perf_irqs field.
    
    Resolve the conflict by moving the new field to the irq_cpustat
    structure on 64-bit too.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit e65e49d0f3714f4a6a42f6f6a19926ba33fcda75
Author: Mike Travis <travis@sgi.com>
Date:   Mon Jan 12 15:27:13 2009 -0800

    irq: update all arches for new irq_desc
    
    Impact: cleanup, update to new cpumask API
    
    Irq_desc.affinity and irq_desc.pending_mask are now cpumask_var_t's
    so access to them should be using the new cpumask API.
    
    Signed-off-by: Mike Travis <travis@sgi.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 23b8b5e36f98..ad1e5ac721d8 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -231,7 +231,7 @@ void fixup_irqs(cpumask_t map)
 		if (irq_desc[irq].status & IRQ_PER_CPU)
 			continue;
 
-		cpus_and(mask, irq_desc[irq].affinity, map);
+		cpumask_and(&mask, irq_desc[irq].affinity, &map);
 		if (any_online_cpu(mask) == NR_CPUS) {
 			printk("Breaking affinity for irq %i\n", irq);
 			mask = map;

commit dee4102a9a5882b4f7d5cc165ba29e8cc63cf92e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sun Jan 11 00:29:15 2009 -0800

    sparseirq: use kstat_irqs_cpu instead
    
    Impact: build fix
    
    Ingo Molnar wrote:
    
    > tip/arch/blackfin/kernel/irqchip.c: In function 'show_interrupts':
    > tip/arch/blackfin/kernel/irqchip.c:85: error: 'struct kernel_stat' has no member named 'irqs'
    > make[2]: *** [arch/blackfin/kernel/irqchip.o] Error 1
    > make[2]: *** Waiting for unfinished jobs....
    >
    
    So could move kstat_irqs array to irq_desc struct.
    
    (s390, m68k, sparc) are not touched yet, because they don't support genirq
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 23b8b5e36f98..17efb7118db1 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -190,7 +190,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%3d: ", i);
 #ifdef CONFIG_SMP
 		for_each_online_cpu(j)
-			seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+			seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
 #else
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */

commit c0d362a832ee70435fc4555a64f820893b1da0bd
Merge: 506c10f26c48 f78628374a13
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 02:44:08 2009 +0100

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/perfcounters into perfcounters/core

commit 93a6d3ce6962044fe9badf528fed46b455d58292
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Jan 9 16:52:19 2009 +1100

    powerpc: Provide a way to defer perf counter work until interrupts are enabled
    
    Because 64-bit powerpc uses lazy (soft) interrupt disabling, it is
    possible for a performance monitor exception to come in when the
    kernel thinks interrupts are disabled (i.e. when they are
    soft-disabled but hard-enabled).  In such a situation the performance
    monitor exception handler might have some processing to do (such as
    process wakeups) which can't be done in what is effectively an NMI
    handler.
    
    This provides a way to defer that work until interrupts get enabled,
    either in raw_local_irq_restore() or by returning from an interrupt
    handler to code that had interrupts enabled.  We have a per-processor
    flag that indicates that there is work pending to do when interrupts
    subsequently get re-enabled.  This flag is checked in the interrupt
    return path and in raw_local_irq_restore(), and if it is set,
    perf_counter_do_pending() is called to do the pending work.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ac222d0ab12e..4efb886ea439 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -104,6 +104,13 @@ static inline notrace void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
+#ifdef CONFIG_PERF_COUNTERS
+notrace void __weak perf_counter_do_pending(void)
+{
+	set_perf_counter_pending(0);
+}
+#endif
+
 notrace void raw_local_irq_restore(unsigned long en)
 {
 	/*
@@ -135,6 +142,9 @@ notrace void raw_local_irq_restore(unsigned long en)
 			iseries_handle_interrupts();
 	}
 
+	if (get_perf_counter_pending())
+		perf_counter_do_pending();
+
 	/*
 	 * if (get_paca()->hard_enabled) return;
 	 * But again we need to take care that gcc gets hard_enabled directly

commit 0de26520c7cabf36e1de090ea8092f011a6106ce
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: make irq_set_affinity() take a const struct cpumask
    
    Impact: change existing irq_chip API
    
    Not much point with gentle transition here: the struct irq_chip's
    setaffinity method signature needs to change.
    
    Fortunately, not widely used code, but hits a few architectures.
    
    Note: In irq_select_affinity() I save a temporary in by mangling
    irq_desc[irq].affinity directly.  Ingo, does this break anything?
    
    (Folded in fix from KOSAKI Motohiro)
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: jeremy@xensource.com
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ac222d0ab12e..23b8b5e36f98 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -237,7 +237,7 @@ void fixup_irqs(cpumask_t map)
 			mask = map;
 		}
 		if (irq_desc[irq].chip->set_affinity)
-			irq_desc[irq].chip->set_affinity(irq, mask);
+			irq_desc[irq].chip->set_affinity(irq, &mask);
 		else if (irq_desc[irq].action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}

commit 150c6c8fecf6daaf68c2987ba2b6b259baefdff2
Author: Sebastien Dugue <sebastien.dugue@bull.net>
Date:   Thu Sep 4 22:37:08 2008 +1000

    powerpc: Make the irq reverse mapping radix tree lockless
    
    The radix trees used by interrupt controllers for their irq reverse
    mapping (currently only the XICS found on pSeries) have a complex
    locking scheme dating back to before the advent of the lockless radix
    tree.
    
    This takes advantage of the lockless radix tree and of the fact that
    the items of the tree are pointers to a static array (irq_map)
    elements which can never go under us to simplify the locking.
    
    Concurrency between readers and writers is handled by the intrinsic
    properties of the lockless radix tree.  Concurrency between writers is
    handled with a global mutex.
    
    Signed-off-by: Sebastien Dugue <sebastien.dugue@bull.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2656924415da..ac222d0ab12e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -439,9 +439,8 @@ void do_softirq(void)
 
 static LIST_HEAD(irq_hosts);
 static DEFINE_SPINLOCK(irq_big_lock);
-static DEFINE_PER_CPU(unsigned int, irq_radix_reader);
-static unsigned int irq_radix_writer;
 static unsigned int revmap_trees_allocated;
+static DEFINE_MUTEX(revmap_trees_mutex);
 struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_host *irq_default_host;
@@ -584,57 +583,6 @@ void irq_set_virq_count(unsigned int count)
 		irq_virq_count = count;
 }
 
-/* radix tree not lockless safe ! we use a brlock-type mecanism
- * for now, until we can use a lockless radix tree
- */
-static void irq_radix_wrlock(unsigned long *flags)
-{
-	unsigned int cpu, ok;
-
-	spin_lock_irqsave(&irq_big_lock, *flags);
-	irq_radix_writer = 1;
-	smp_mb();
-	do {
-		barrier();
-		ok = 1;
-		for_each_possible_cpu(cpu) {
-			if (per_cpu(irq_radix_reader, cpu)) {
-				ok = 0;
-				break;
-			}
-		}
-		if (!ok)
-			cpu_relax();
-	} while(!ok);
-}
-
-static void irq_radix_wrunlock(unsigned long flags)
-{
-	smp_wmb();
-	irq_radix_writer = 0;
-	spin_unlock_irqrestore(&irq_big_lock, flags);
-}
-
-static void irq_radix_rdlock(unsigned long *flags)
-{
-	local_irq_save(*flags);
-	__get_cpu_var(irq_radix_reader) = 1;
-	smp_mb();
-	if (likely(irq_radix_writer == 0))
-		return;
-	__get_cpu_var(irq_radix_reader) = 0;
-	smp_wmb();
-	spin_lock(&irq_big_lock);
-	__get_cpu_var(irq_radix_reader) = 1;
-	spin_unlock(&irq_big_lock);
-}
-
-static void irq_radix_rdunlock(unsigned long flags)
-{
-	__get_cpu_var(irq_radix_reader) = 0;
-	local_irq_restore(flags);
-}
-
 static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 			    irq_hw_number_t hwirq)
 {
@@ -789,7 +737,6 @@ void irq_dispose_mapping(unsigned int virq)
 {
 	struct irq_host *host;
 	irq_hw_number_t hwirq;
-	unsigned long flags;
 
 	if (virq == NO_IRQ)
 		return;
@@ -829,9 +776,9 @@ void irq_dispose_mapping(unsigned int virq)
 		smp_rmb();
 		if (revmap_trees_allocated < 1)
 			break;
-		irq_radix_wrlock(&flags);
+		mutex_lock(&revmap_trees_mutex);
 		radix_tree_delete(&host->revmap_data.tree, hwirq);
-		irq_radix_wrunlock(flags);
+		mutex_unlock(&revmap_trees_mutex);
 		break;
 	}
 
@@ -885,7 +832,6 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 {
 	struct irq_map_entry *ptr;
 	unsigned int virq;
-	unsigned long flags;
 
 	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
 
@@ -897,9 +843,11 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 		return irq_find_mapping(host, hwirq);
 
 	/* Now try to resolve */
-	irq_radix_rdlock(&flags);
+	/*
+	 * No rcu_read_lock(ing) needed, the ptr returned can't go under us
+	 * as it's referencing an entry in the static irq_map table.
+	 */
 	ptr = radix_tree_lookup(&host->revmap_data.tree, hwirq);
-	irq_radix_rdunlock(flags);
 
 	/*
 	 * If found in radix tree, then fine.
@@ -917,7 +865,6 @@ unsigned int irq_radix_revmap_lookup(struct irq_host *host,
 void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
 			     irq_hw_number_t hwirq)
 {
-	unsigned long flags;
 
 	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
 
@@ -931,10 +878,10 @@ void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
 		return;
 
 	if (virq != NO_IRQ) {
-		irq_radix_wrlock(&flags);
+		mutex_lock(&revmap_trees_mutex);
 		radix_tree_insert(&host->revmap_data.tree, hwirq,
 				  &irq_map[virq]);
-		irq_radix_wrunlock(flags);
+		mutex_unlock(&revmap_trees_mutex);
 	}
 }
 
@@ -1044,7 +991,6 @@ void irq_early_init(void)
 static int irq_late_init(void)
 {
 	struct irq_host *h;
-	unsigned long flags;
 	unsigned int i;
 
 	/*
@@ -1068,14 +1014,14 @@ static int irq_late_init(void)
 	 * Insert the reverse mapping for those interrupts already present
 	 * in irq_map[].
 	 */
-	irq_radix_wrlock(&flags);
+	mutex_lock(&revmap_trees_mutex);
 	for (i = 0; i < irq_virq_count; i++) {
 		if (irq_map[i].host &&
 		    (irq_map[i].host->revmap_type == IRQ_HOST_MAP_TREE))
 			radix_tree_insert(&irq_map[i].host->revmap_data.tree,
 					  irq_map[i].hwirq, &irq_map[i]);
 	}
-	irq_radix_wrunlock(flags);
+	mutex_unlock(&revmap_trees_mutex);
 
 	/*
 	 * Make sure the radix trees insertions are visible before setting

commit 967e012ef306e99cfddcd7423f37414e6b568361
Author: Sebastien Dugue <sebastien.dugue@bull.net>
Date:   Thu Sep 4 22:37:07 2008 +1000

    powerpc: Separate the irq radix tree insertion and lookup
    
    irq_radix_revmap() currently serves 2 purposes, irq mapping lookup
    and insertion which happen in interrupt and process context respectively.
    
    Separate the function into its 2 components, one for lookup only and one
    for insertion only.
    
    Fix the only user of the revmap tree (XICS) to use the new functions.
    
    Also, move the insertion into the radix tree of those irqs that were
    requested before it was initialized at said tree initialization.
    
    Mutual exclusion between the tree initialization and readers/writers is
    handled via a state variable (revmap_trees_allocated) set to 1 when the tree
    has been initialized and set to 2 after the already requested irqs have been
    inserted in the tree by the init path. This state is checked before any reader
    or writer access just like we used to check for tree.gfp_mask != 0 before.
    
    Finally, now that we're not any longer inserting nodes into the radix-tree
    in interrupt context, turn the GFP_ATOMIC allocations into GFP_KERNEL ones.
    
    Signed-off-by: Sebastien Dugue <sebastien.dugue@bull.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d972decf0324..2656924415da 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -441,6 +441,7 @@ static LIST_HEAD(irq_hosts);
 static DEFINE_SPINLOCK(irq_big_lock);
 static DEFINE_PER_CPU(unsigned int, irq_radix_reader);
 static unsigned int irq_radix_writer;
+static unsigned int revmap_trees_allocated;
 struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_host *irq_default_host;
@@ -821,8 +822,12 @@ void irq_dispose_mapping(unsigned int virq)
 			host->revmap_data.linear.revmap[hwirq] = NO_IRQ;
 		break;
 	case IRQ_HOST_MAP_TREE:
-		/* Check if radix tree allocated yet */
-		if (host->revmap_data.tree.gfp_mask == 0)
+		/*
+		 * Check if radix tree allocated yet, if not then nothing to
+		 * remove.
+		 */
+		smp_rmb();
+		if (revmap_trees_allocated < 1)
 			break;
 		irq_radix_wrlock(&flags);
 		radix_tree_delete(&host->revmap_data.tree, hwirq);
@@ -875,43 +880,62 @@ unsigned int irq_find_mapping(struct irq_host *host,
 EXPORT_SYMBOL_GPL(irq_find_mapping);
 
 
-unsigned int irq_radix_revmap(struct irq_host *host,
-			      irq_hw_number_t hwirq)
+unsigned int irq_radix_revmap_lookup(struct irq_host *host,
+				     irq_hw_number_t hwirq)
 {
-	struct radix_tree_root *tree;
 	struct irq_map_entry *ptr;
 	unsigned int virq;
 	unsigned long flags;
 
 	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
 
-	/* Check if the radix tree exist yet. We test the value of
-	 * the gfp_mask for that. Sneaky but saves another int in the
-	 * structure. If not, we fallback to slow mode
+	/*
+	 * Check if the radix tree exists and has bee initialized.
+	 * If not, we fallback to slow mode
 	 */
-	tree = &host->revmap_data.tree;
-	if (tree->gfp_mask == 0)
+	if (revmap_trees_allocated < 2)
 		return irq_find_mapping(host, hwirq);
 
 	/* Now try to resolve */
 	irq_radix_rdlock(&flags);
-	ptr = radix_tree_lookup(tree, hwirq);
+	ptr = radix_tree_lookup(&host->revmap_data.tree, hwirq);
 	irq_radix_rdunlock(flags);
 
-	/* Found it, return */
-	if (ptr) {
+	/*
+	 * If found in radix tree, then fine.
+	 * Else fallback to linear lookup - this should not happen in practice
+	 * as it means that we failed to insert the node in the radix tree.
+	 */
+	if (ptr)
 		virq = ptr - irq_map;
-		return virq;
-	}
+	else
+		virq = irq_find_mapping(host, hwirq);
+
+	return virq;
+}
+
+void irq_radix_revmap_insert(struct irq_host *host, unsigned int virq,
+			     irq_hw_number_t hwirq)
+{
+	unsigned long flags;
+
+	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
+
+	/*
+	 * Check if the radix tree exists yet.
+	 * If not, then the irq will be inserted into the tree when it gets
+	 * initialized.
+	 */
+	smp_rmb();
+	if (revmap_trees_allocated < 1)
+		return;
 
-	/* If not there, try to insert it */
-	virq = irq_find_mapping(host, hwirq);
 	if (virq != NO_IRQ) {
 		irq_radix_wrlock(&flags);
-		radix_tree_insert(tree, hwirq, &irq_map[virq]);
+		radix_tree_insert(&host->revmap_data.tree, hwirq,
+				  &irq_map[virq]);
 		irq_radix_wrunlock(flags);
 	}
-	return virq;
 }
 
 unsigned int irq_linear_revmap(struct irq_host *host,
@@ -1021,14 +1045,45 @@ static int irq_late_init(void)
 {
 	struct irq_host *h;
 	unsigned long flags;
+	unsigned int i;
 
-	irq_radix_wrlock(&flags);
+	/*
+	 * No mutual exclusion with respect to accessors of the tree is needed
+	 * here as the synchronization is done via the state variable
+	 * revmap_trees_allocated.
+	 */
 	list_for_each_entry(h, &irq_hosts, link) {
 		if (h->revmap_type == IRQ_HOST_MAP_TREE)
-			INIT_RADIX_TREE(&h->revmap_data.tree, GFP_ATOMIC);
+			INIT_RADIX_TREE(&h->revmap_data.tree, GFP_KERNEL);
+	}
+
+	/*
+	 * Make sure the radix trees inits are visible before setting
+	 * the flag
+	 */
+	smp_wmb();
+	revmap_trees_allocated = 1;
+
+	/*
+	 * Insert the reverse mapping for those interrupts already present
+	 * in irq_map[].
+	 */
+	irq_radix_wrlock(&flags);
+	for (i = 0; i < irq_virq_count; i++) {
+		if (irq_map[i].host &&
+		    (irq_map[i].host->revmap_type == IRQ_HOST_MAP_TREE))
+			radix_tree_insert(&irq_map[i].host->revmap_data.tree,
+					  irq_map[i].hwirq, &irq_map[i]);
 	}
 	irq_radix_wrunlock(flags);
 
+	/*
+	 * Make sure the radix trees insertions are visible before setting
+	 * the flag
+	 */
+	smp_wmb();
+	revmap_trees_allocated = 2;
+
 	return 0;
 }
 arch_initcall(irq_late_init);

commit 9c4cb82515130c62224e23fdf7c13c8f6c59c614
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Sat Aug 2 02:44:11 2008 +1000

    powerpc: Remove use of CONFIG_PPC_MERGE
    
    Now that arch/ppc is gone and CONFIG_PPC_MERGE is always set, remove
    the dead code associated with !CONFIG_PPC_MERGE from arch/powerpc
    and include/asm-powerpc.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6ac8612da3c3..d972decf0324 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -77,22 +77,12 @@ static int ppc_spurious_interrupts;
 EXPORT_SYMBOL(__irq_offset_value);
 atomic_t ppc_n_lost_interrupts;
 
-#ifndef CONFIG_PPC_MERGE
-#define NR_MASK_WORDS	((NR_IRQS + 31) / 32)
-unsigned long ppc_cached_irq_mask[NR_MASK_WORDS];
-#endif
-
 #ifdef CONFIG_TAU_INT
 extern int tau_initialized;
 extern int tau_interrupts(int);
 #endif
 #endif /* CONFIG_PPC32 */
 
-#if defined(CONFIG_SMP) && !defined(CONFIG_PPC_MERGE)
-extern atomic_t ipi_recv;
-extern atomic_t ipi_sent;
-#endif
-
 #ifdef CONFIG_PPC64
 EXPORT_SYMBOL(irq_desc);
 
@@ -216,21 +206,14 @@ int show_interrupts(struct seq_file *p, void *v)
 skip:
 		spin_unlock_irqrestore(&desc->lock, flags);
 	} else if (i == NR_IRQS) {
-#ifdef CONFIG_PPC32
-#ifdef CONFIG_TAU_INT
+#if defined(CONFIG_PPC32) && defined(CONFIG_TAU_INT)
 		if (tau_initialized){
 			seq_puts(p, "TAU: ");
 			for_each_online_cpu(j)
 				seq_printf(p, "%10u ", tau_interrupts(j));
 			seq_puts(p, "  PowerPC             Thermal Assist (cpu temp)\n");
 		}
-#endif
-#if defined(CONFIG_SMP) && !defined(CONFIG_PPC_MERGE)
-		/* should this be per processor send/receive? */
-		seq_printf(p, "IPI (recv/sent): %10u/%u\n",
-				atomic_read(&ipi_recv), atomic_read(&ipi_sent));
-#endif
-#endif /* CONFIG_PPC32 */
+#endif /* CONFIG_PPC32 && CONFIG_TAU_INT*/
 		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
 	}
 	return 0;
@@ -454,8 +437,6 @@ void do_softirq(void)
  * IRQ controller and virtual interrupts
  */
 
-#ifdef CONFIG_PPC_MERGE
-
 static LIST_HEAD(irq_hosts);
 static DEFINE_SPINLOCK(irq_big_lock);
 static DEFINE_PER_CPU(unsigned int, irq_radix_reader);
@@ -1114,8 +1095,6 @@ static int __init irq_debugfs_init(void)
 __initcall(irq_debugfs_init);
 #endif /* CONFIG_VIRQ_DEBUG */
 
-#endif /* CONFIG_PPC_MERGE */
-
 #ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {

commit 43d2548bb2ef7e6d753f91468a746784041e522d
Merge: 585583d95c56 85082fd7cbe3
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 15 15:44:51 2008 +1000

    Merge commit '85082fd7cbe3173198aac0eb5e85ab1edcc6352c' into test-build
    
    Manual fixup of:
    
            arch/powerpc/Kconfig

commit e9a4b6a3f6592862a67837e80aad3f50468857a6
Merge: 441dbb500b43 1702b52092e9
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Jun 30 10:16:50 2008 +1000

    Merge branch 'linux-2.6'

commit f34bfb1beef8a17ba3d46b60f8fa19ffedc1ed8d
Merge: ee4311adf105 481c5346d098
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jun 23 11:11:42 2008 +0200

    Merge branch 'linus' into tracing/ftrace

commit 476ff8a0e3b17fc23994255aa9fd917d599d2ec7
Author: Emil Medve <Emilian.Medve@Freescale.com>
Date:   Fri May 23 05:49:22 2008 +1000

    [POWERPC] Fix return value check logic in debugfs virq_mapping setup
    
    debugfs_create_file() returns a non-NULL (non-zero) value in case of
    success, not a NULL value.
    
    This fixes this non-critical boot-time debugging error message:
    
    [    1.316386] calling  irq_debugfs_init+0x0/0x50
    [    1.316399] initcall irq_debugfs_init+0x0/0x50 returned -12 after 0 msecs
    [    1.316411] initcall irq_debugfs_init+0x0/0x50 returned with error code -12
    
    Signed-off-by: Emil Medve <Emilian.Medve@Freescale.com>
    Acked-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2f73f705d564..bcc249d90c4d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1073,7 +1073,7 @@ static const struct file_operations virq_debug_fops = {
 static int __init irq_debugfs_init(void)
 {
 	if (debugfs_create_file("virq_mapping", S_IRUGO, powerpc_debugfs_root,
-				 NULL, &virq_debug_fops))
+				 NULL, &virq_debug_fops) == NULL)
 		return -ENOMEM;
 
 	return 0;

commit 19fc65b5251dfd90312ae0142cc8650cd273e6a6
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Mon May 26 12:12:32 2008 +1000

    powerpc: Fix irq_alloc_host() reference counting and callers
    
    When I changed irq_alloc_host() to take an of_node
    (52964f87c64e6c6ea671b5bf3030fb1494090a48: "Add an optional
    device_node pointer to the irq_host"), I botched the reference
    counting semantics.
    
    Stephen pointed out that it's irq_alloc_host()'s business if
    it needs to take an additional reference to the device_node,
    the caller shouldn't need to care.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b5199752ac60..e9238556ae50 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -498,7 +498,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 	host->revmap_type = revmap_type;
 	host->inval_irq = inval_irq;
 	host->ops = ops;
-	host->of_node = of_node;
+	host->of_node = of_node_get(of_node);
 
 	if (host->ops->match == NULL)
 		host->ops->match = default_irq_host_match;

commit bcf0b0880710409420a4e3b15dbf4b9a63542c0b
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Apr 30 03:49:55 2008 -0500

    [POWERPC] Move to runtime allocated exception stacks
    
    For the additonal exception levels (critical, debug, machine check) on
    40x/book-e we were using "static" allocations of the stack in the
    associated head.S.
    
    Move to a runtime allocation to make the code a bit easier to read as
    we mimic how we handle IRQ stacks.  Its also a bit easier to setup the
    stack with a "dummy" thread_info in C code.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Acked-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2f73f705d564..b5199752ac60 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -356,9 +356,42 @@ void __init init_IRQ(void)
 {
 	if (ppc_md.init_IRQ)
 		ppc_md.init_IRQ();
+
+	exc_lvl_ctx_init();
+
 	irq_ctx_init();
 }
 
+#if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
+struct thread_info   *critirq_ctx[NR_CPUS] __read_mostly;
+struct thread_info    *dbgirq_ctx[NR_CPUS] __read_mostly;
+struct thread_info *mcheckirq_ctx[NR_CPUS] __read_mostly;
+
+void exc_lvl_ctx_init(void)
+{
+	struct thread_info *tp;
+	int i;
+
+	for_each_possible_cpu(i) {
+		memset((void *)critirq_ctx[i], 0, THREAD_SIZE);
+		tp = critirq_ctx[i];
+		tp->cpu = i;
+		tp->preempt_count = 0;
+
+#ifdef CONFIG_BOOKE
+		memset((void *)dbgirq_ctx[i], 0, THREAD_SIZE);
+		tp = dbgirq_ctx[i];
+		tp->cpu = i;
+		tp->preempt_count = 0;
+
+		memset((void *)mcheckirq_ctx[i], 0, THREAD_SIZE);
+		tp = mcheckirq_ctx[i];
+		tp->cpu = i;
+		tp->preempt_count = HARDIRQ_OFFSET;
+#endif
+	}
+}
+#endif
 
 #ifdef CONFIG_IRQSTACKS
 struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;

commit 4e491d14f2506b218d678935c25a7027b79178b1
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed May 14 23:49:44 2008 -0400

    ftrace: support for PowerPC
    
    This patch adds full support for ftrace for PowerPC (both 64 and 32 bit).
    This includes dynamic tracing and function filtering.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2f73f705d564..6e01eb0a3315 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -98,7 +98,7 @@ EXPORT_SYMBOL(irq_desc);
 
 int distribute_irqs = 1;
 
-static inline unsigned long get_hard_enabled(void)
+static inline notrace unsigned long get_hard_enabled(void)
 {
 	unsigned long enabled;
 
@@ -108,13 +108,13 @@ static inline unsigned long get_hard_enabled(void)
 	return enabled;
 }
 
-static inline void set_soft_enabled(unsigned long enable)
+static inline notrace void set_soft_enabled(unsigned long enable)
 {
 	__asm__ __volatile__("stb %0,%1(13)"
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
-void raw_local_irq_restore(unsigned long en)
+notrace void raw_local_irq_restore(unsigned long en)
 {
 	/*
 	 * get_paca()->soft_enabled = en;

commit 85218827cc4ca900867807f19345418164ffc108
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Mon Apr 28 16:21:22 2008 +1000

    [POWERPC] Add IRQSTACKS support on ppc32
    
    This makes it possible to use separate stacks for hard and soft IRQs
    on 32-bit powerpc as well as on 64-bit.  The code for 32-bit is just
    the 32-bit analog of the 64-bit code.
    
    * Added allocation and initialization of the irq stacks.  We limit the
      stacks to be in lowmem for ppc32.
    * Implemented ppc32 versions of call_do_softirq() and call_handle_irq()
      to switch the stack pointers
    * Reworked how we do stack overflow detection.  We now keep around the
      limit of the stack in the thread_struct and compare against the limit
      to see if we've overflowed.  We can now use this on ppc64 if desired.
    
    [ paulus@samba.org: Fixed bug on 6xx where we need to reload r9 with the
      thread_info pointer. ]
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 425616f92d18..2f73f705d564 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -307,6 +307,7 @@ void do_IRQ(struct pt_regs *regs)
 		if (curtp != irqtp) {
 			struct irq_desc *desc = irq_desc + irq;
 			void *handler = desc->handle_irq;
+			unsigned long saved_sp_limit = current->thread.ksp_limit;
 			if (handler == NULL)
 				handler = &__do_IRQ;
 			irqtp->task = curtp->task;
@@ -319,7 +320,10 @@ void do_IRQ(struct pt_regs *regs)
 				(irqtp->preempt_count & ~SOFTIRQ_MASK) |
 				(curtp->preempt_count & SOFTIRQ_MASK);
 
+			current->thread.ksp_limit = (unsigned long)irqtp +
+				_ALIGN_UP(sizeof(struct thread_info), 16);
 			call_handle_irq(irq, desc, irqtp, handler);
+			current->thread.ksp_limit = saved_sp_limit;
 			irqtp->task = NULL;
 
 
@@ -352,9 +356,7 @@ void __init init_IRQ(void)
 {
 	if (ppc_md.init_IRQ)
 		ppc_md.init_IRQ();
-#ifdef CONFIG_PPC64
 	irq_ctx_init();
-#endif
 }
 
 
@@ -383,11 +385,15 @@ void irq_ctx_init(void)
 static inline void do_softirq_onstack(void)
 {
 	struct thread_info *curtp, *irqtp;
+	unsigned long saved_sp_limit = current->thread.ksp_limit;
 
 	curtp = current_thread_info();
 	irqtp = softirq_ctx[smp_processor_id()];
 	irqtp->task = curtp->task;
+	current->thread.ksp_limit = (unsigned long)irqtp +
+				    _ALIGN_UP(sizeof(struct thread_info), 16);
 	call_do_softirq(irqtp);
+	current->thread.ksp_limit = saved_sp_limit;
 	irqtp->task = NULL;
 }
 

commit 945feb174b14e7098cc7ecf0cf4768d35bc52f9c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Apr 17 14:35:01 2008 +1000

    [POWERPC] irqtrace support for 64-bit powerpc
    
    This adds the low level irq tracing hooks to the powerpc architecture
    needed to enable full lockdep functionality.
    
    This is partly based on Johannes Berg's initial version.  I removed
    the asm trampoline that isn't needed (thus improving performance) and
    modified all sorts of bits and pieces, reworking most of the assembly,
    etc...
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4617b65d464d..425616f92d18 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -114,7 +114,7 @@ static inline void set_soft_enabled(unsigned long enable)
 	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
 }
 
-void local_irq_restore(unsigned long en)
+void raw_local_irq_restore(unsigned long en)
 {
 	/*
 	 * get_paca()->soft_enabled = en;
@@ -174,6 +174,7 @@ void local_irq_restore(unsigned long en)
 
 	__hard_irq_enable();
 }
+EXPORT_SYMBOL(raw_local_irq_restore);
 #endif /* CONFIG_PPC64 */
 
 int show_interrupts(struct seq_file *p, void *v)

commit e6768a4f392d05bc11ed508d35938932c73aac5a
Author: Benjamin Herrenschmidt <benh@ozlabs.org>
Date:   Wed Apr 9 17:21:28 2008 +1000

    [POWERPC] Fixup softirq preempt count
    
    This fixes the handling of the preempt count when switching
    interrupt stacks so that HW interrupt properly get the softirq
    mask copied over from the previous stack.
    
    It also initializes the softirq stack preempt_count to 0 instead
    of SOFTIRQ_OFFSET, like x86, as __do_softirq() does the increment,
    and we hit some lockdep checks if we have it twice.
    
    That means we do run for a little while off the softirq stack
    with the preempt-count set to 0, which could be deadly if we
    try to take a softirq at that point, however we do so with
    interrupts disabled, so I think we are ok.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 292163f5b39a..4617b65d464d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -310,8 +310,21 @@ void do_IRQ(struct pt_regs *regs)
 				handler = &__do_IRQ;
 			irqtp->task = curtp->task;
 			irqtp->flags = 0;
+
+			/* Copy the softirq bits in preempt_count so that the
+			 * softirq checks work in the hardirq context.
+			 */
+			irqtp->preempt_count =
+				(irqtp->preempt_count & ~SOFTIRQ_MASK) |
+				(curtp->preempt_count & SOFTIRQ_MASK);
+
 			call_handle_irq(irq, desc, irqtp, handler);
 			irqtp->task = NULL;
+
+
+			/* Set any flag that may have been set on the
+			 * alternate stack
+			 */
 			if (irqtp->flags)
 				set_bits(irqtp->flags, &curtp->flags);
 		} else
@@ -357,7 +370,7 @@ void irq_ctx_init(void)
 		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
 		tp = softirq_ctx[i];
 		tp->cpu = i;
-		tp->preempt_count = SOFTIRQ_OFFSET;
+		tp->preempt_count = 0;
 
 		memset((void *)hardirq_ctx[i], 0, THREAD_SIZE);
 		tp = hardirq_ctx[i];

commit ff3da2e0938bae36d10d69c22bce0177b067a9e2
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 2 15:58:40 2008 +1100

    [POWERPC] Fix iSeries hard irq enabling regression
    
    A subtle bug sneaked into iSeries recently.  On this platform, we must
    not normally clear MSR:EE (the hardware external interrupt enable)
    except for short periods of time.  Taking an interrupt while
    soft-disabled doesn't cause us to clear it for example.
    
    The iSeries kernel expects to mostly run with MSR:EE enabled at all
    times except in a few exception entry/exit code paths.  Thus
    local_irq_enable() doesn't check if it needs to hard-enable as it
    expects this to be unnecessary on iSeries.
    
    However, hard_irq_disable() _does_ cause MSR:EE to be cleared,
    including on iSeries.  A call to it was recently added to the
    context switch code, thus causing interrupts to become disabled
    for a long periods of time, causing the iSeries watchdog to kick
    in under some circumstances and other nasty things.
    
    This patch fixes it by making local_irq_enable() properly re-enable
    MSR:EE on iSeries.  It basically removes a return statement here
    to make iSeries use the same code path as everybody else.  That does
    mean that we might occasionally get spurious decrementer interrupts
    but I don't think that matters.
    
    Another option would have been to make hard_irq_disable() a nop
    on iSeries but I didn't like it much, in case we have good reasons
    to hard-disable.
    
    Part of the patch is fixes to make sure the hard_enabled PACA field
    is properly set on iSeries as it used not to be before, since it
    was mostly unused.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b0e5deb4274f..292163f5b39a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -143,7 +143,6 @@ void local_irq_restore(unsigned long en)
 		 */
 		if (local_paca->lppaca_ptr->int_dword.any_int)
 			iseries_handle_interrupts();
-		return;
 	}
 
 	/*

commit c03983ac9b268d4bbb8c2600baba5798aefa9d5d
Author: Jean Delvare <khali@linux-fr.org>
Date:   Fri Oct 19 23:22:55 2007 +0200

    Spelling fix: explicitly
    
    From: Jean Delvare <khali@linux-fr.org>
    
    Signed-off-by: Jean Delvare <khali@linux-fr.org>
    Signed-off-by: Adrian Bunk <bunk@kernel.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2250f9e6c5ca..b0e5deb4274f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -491,7 +491,7 @@ struct irq_host *irq_alloc_host(struct device_node *of_node,
 
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to
-			 * explicitely change them
+			 * explicitly change them
 			 */
 			ops->map(host, i, i);
 		}

commit e86908614f2c7fec401827e5cefd7a6ea9407f85
Merge: 547307420931 9b4b8feb962f
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Thu Oct 11 21:55:47 2007 -0700

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc
    
    * 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc: (408 commits)
      [POWERPC] Add memchr() to the bootwrapper
      [POWERPC] Implement logging of unhandled signals
      [POWERPC] Add legacy serial support for OPB with flattened device tree
      [POWERPC] Use 1TB segments
      [POWERPC] XilinxFB: Allow fixed framebuffer base address
      [POWERPC] XilinxFB: Add support for custom screen resolution
      [POWERPC] XilinxFB: Use pdata to pass around framebuffer parameters
      [POWERPC] PCI: Add 64-bit physical address support to setup_indirect_pci
      [POWERPC] 4xx: Kilauea defconfig file
      [POWERPC] 4xx: Kilauea DTS
      [POWERPC] 4xx: Add AMCC Kilauea eval board support to platforms/40x
      [POWERPC] 4xx: Add AMCC 405EX support to cputable.c
      [POWERPC] Adjust TASK_SIZE on ppc32 systems to 3GB that are capable
      [POWERPC] Use PAGE_OFFSET to tell if an address is user/kernel in SW TLB handlers
      [POWERPC] 85xx: Enable FP emulation in MPC8560 ADS defconfig
      [POWERPC] 85xx: Killed <asm/mpc85xx.h>
      [POWERPC] 85xx: Add cpm nodes for 8541/8555 CDS
      [POWERPC] 85xx: Convert mpc8560ads to the new CPM binding.
      [POWERPC] mpc8272ads: Remove muram from the CPM reg property.
      [POWERPC] Make clockevents work on PPC601 processors
      ...
    
    Fixed up conflict in Documentation/powerpc/booting-without-of.txt manually.

commit c45248c70125cc374fdf264659643276c72801bf
Author: Robert Olsson <robert.olsson@its.uu.se>
Date:   Mon Sep 17 11:47:12 2007 -0700

    [SOFTIRQ]: Remove do_softirq() symbol export.
    
    As noted by Christoph Hellwig, pktgen was the only user so
    it can now be removed.
    
    [ Add missing cases caught by Adrian Bunk. -DaveM ]
    
    Signed-off-by: Robert Olsson <robert.olsson@its.uu.se>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 24bea97c736c..9bf63d5256db 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -395,7 +395,6 @@ void do_softirq(void)
 
 	local_irq_restore(flags);
 }
-EXPORT_SYMBOL(do_softirq);
 
 
 /*

commit 5669c3cf19fbadaa9120b59914beec8431277efe
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Oct 2 13:37:53 2007 +1000

    [POWERPC] Limit range of __init_ref_ok somewhat
    
    This patch introduces zalloc_maybe_bootmem and uses it so that we don't
    have to mark a whole (largish) routine as __init_ref_ok.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0e47c8cfc979..151b13119208 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -424,7 +424,7 @@ static int default_irq_host_match(struct irq_host *h, struct device_node *np)
 	return h->of_node != NULL && h->of_node == np;
 }
 
-__init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
+struct irq_host *irq_alloc_host(struct device_node *of_node,
 				unsigned int revmap_type,
 				unsigned int revmap_arg,
 				struct irq_host_ops *ops,
@@ -439,13 +439,7 @@ __init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
 	/* Allocate structure and revmap table if using linear mapping */
 	if (revmap_type == IRQ_HOST_MAP_LINEAR)
 		size += revmap_arg * sizeof(unsigned int);
-	if (mem_init_done)
-		host = kzalloc(size, GFP_KERNEL);
-	else {
-		host = alloc_bootmem(size);
-		if (host)
-			memset(host, 0, size);
-	}
+	host = zalloc_maybe_bootmem(size, GFP_KERNEL);
 	if (host == NULL)
 		return NULL;
 

commit 60b332e755da7dbf32f1660973ce4f97ebf05d05
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Aug 28 18:47:57 2007 +1000

    [POWERPC] Export virq mapping via debugfs
    
    This adds a debugfs file "powerpc/virq_mapping", which shows the virtual
    to real mapping of irq numbers.  Enable it with CONFIG_VIRQ_DEBUG.
    
    Signed-off-by: Zhang Wei <wei.zhang@freescale.com>
    Signed-off-by: Chen Gong <G.Chen@freescale.com>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 1339f32b44b5..0e47c8cfc979 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -52,6 +52,7 @@
 #include <linux/mutex.h>
 #include <linux/bootmem.h>
 #include <linux/pci.h>
+#include <linux/debugfs.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -1006,6 +1007,68 @@ static int irq_late_init(void)
 }
 arch_initcall(irq_late_init);
 
+#ifdef CONFIG_VIRQ_DEBUG
+static int virq_debug_show(struct seq_file *m, void *private)
+{
+	unsigned long flags;
+	irq_desc_t *desc;
+	const char *p;
+	char none[] = "none";
+	int i;
+
+	seq_printf(m, "%-5s  %-7s  %-15s  %s\n", "virq", "hwirq",
+		      "chip name", "host name");
+
+	for (i = 1; i < NR_IRQS; i++) {
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+
+		if (desc->action && desc->action->handler) {
+			seq_printf(m, "%5d  ", i);
+			seq_printf(m, "0x%05lx  ", virq_to_hw(i));
+
+			if (desc->chip && desc->chip->typename)
+				p = desc->chip->typename;
+			else
+				p = none;
+			seq_printf(m, "%-15s  ", p);
+
+			if (irq_map[i].host && irq_map[i].host->of_node)
+				p = irq_map[i].host->of_node->full_name;
+			else
+				p = none;
+			seq_printf(m, "%s\n", p);
+		}
+
+		spin_unlock_irqrestore(&desc->lock, flags);
+	}
+
+	return 0;
+}
+
+static int virq_debug_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, virq_debug_show, inode->i_private);
+}
+
+static const struct file_operations virq_debug_fops = {
+	.open = virq_debug_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+static int __init irq_debugfs_init(void)
+{
+	if (debugfs_create_file("virq_mapping", S_IRUGO, powerpc_debugfs_root,
+				 NULL, &virq_debug_fops))
+		return -ENOMEM;
+
+	return 0;
+}
+__initcall(irq_debugfs_init);
+#endif /* CONFIG_VIRQ_DEBUG */
+
 #endif /* CONFIG_PPC_MERGE */
 
 #ifdef CONFIG_PPC64

commit 7866291d4cabf5491d4ecb62787308f8b8958f59
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Aug 28 18:47:56 2007 +1000

    [POWERPC] Initialise hwirq for legacy irqs
    
    Although no one uses the hwirq value for legacy irqs at the moment, we
    should really setup the correct value in the irq_map.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d5c7e4cf2b39..1339f32b44b5 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -487,7 +487,7 @@ __init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
 		host->inval_irq = 0;
 		/* setup us as the host for all legacy interrupts */
 		for (i = 1; i < NUM_ISA_INTERRUPTS; i++) {
-			irq_map[i].hwirq = 0;
+			irq_map[i].hwirq = i;
 			smp_wmb();
 			irq_map[i].host = host;
 			smp_wmb();

commit 6815800601d3e46b976c868e4e85fb6de32b9133
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Aug 28 18:47:55 2007 +1000

    [POWERPC] Provide a default irq_host match, which matches on an exact of_node
    
    The most common match semantic is an exact match based on the device node.
    So provide a default implementation that does this, and hook it up if no
    match routine is specified.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 30fb8e2c5c9d..d5c7e4cf2b39 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -418,6 +418,11 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
+static int default_irq_host_match(struct irq_host *h, struct device_node *np)
+{
+	return h->of_node != NULL && h->of_node == np;
+}
+
 __init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
 				unsigned int revmap_type,
 				unsigned int revmap_arg,
@@ -449,6 +454,9 @@ __init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
 	host->ops = ops;
 	host->of_node = of_node;
 
+	if (host->ops->match == NULL)
+		host->ops->match = default_irq_host_match;
+
 	spin_lock_irqsave(&irq_big_lock, flags);
 
 	/* If it's a legacy controller, check for duplicates and
@@ -523,7 +531,7 @@ struct irq_host *irq_find_host(struct device_node *node)
 	 */
 	spin_lock_irqsave(&irq_big_lock, flags);
 	list_for_each_entry(h, &irq_hosts, link)
-		if (h->ops->match != NULL && h->ops->match(h, node)) {
+		if (h->ops->match(h, node)) {
 			found = h;
 			break;
 		}

commit 8528ab84ebe7a1eeed9b0acc808df86663d506c0
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Aug 28 18:47:55 2007 +1000

    [POWERPC] Invert null match behaviour for irq_hosts
    
    Currently if you don't specify a match callback for your irq_host it's
    assumed you match everything. This is a kind of opt-out approach, and
    turns out to be the exception rather than the rule.
    
    So change the semantics to be opt-in, ie. you don't match anything unless
    you provide a match callback.  This in itself isn't very useful, but will
    allow us to provide a default match implementation in a subsequent patch.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 79b451247b89..30fb8e2c5c9d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -523,7 +523,7 @@ struct irq_host *irq_find_host(struct device_node *node)
 	 */
 	spin_lock_irqsave(&irq_big_lock, flags);
 	list_for_each_entry(h, &irq_hosts, link)
-		if (h->ops->match == NULL || h->ops->match(h, node)) {
+		if (h->ops->match != NULL && h->ops->match(h, node)) {
 			found = h;
 			break;
 		}

commit 52964f87c64e6c6ea671b5bf3030fb1494090a48
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Aug 28 18:47:54 2007 +1000

    [POWERPC] Add an optional device_node pointer to the irq_host
    
    The majority of irq_host implementations (3 out of 4) are associated
    with a device_node, and need to stash it somewhere. Rather than having
    it somewhere different for each host, add an optional device_node pointer
    to the irq_host structure.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index dfad0e469eec..79b451247b89 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -418,10 +418,11 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
-__init_refok struct irq_host *irq_alloc_host(unsigned int revmap_type,
-						unsigned int revmap_arg,
-						struct irq_host_ops *ops,
-						irq_hw_number_t inval_irq)
+__init_refok struct irq_host *irq_alloc_host(struct device_node *of_node,
+				unsigned int revmap_type,
+				unsigned int revmap_arg,
+				struct irq_host_ops *ops,
+				irq_hw_number_t inval_irq)
 {
 	struct irq_host *host;
 	unsigned int size = sizeof(struct irq_host);
@@ -446,6 +447,7 @@ __init_refok struct irq_host *irq_alloc_host(unsigned int revmap_type,
 	host->revmap_type = revmap_type;
 	host->inval_irq = inval_irq;
 	host->ops = ops;
+	host->of_node = of_node;
 
 	spin_lock_irqsave(&irq_big_lock, flags);
 

commit 4b218e9bb2fbbc57b5a05de41d77c056a134528c
Author: Scott Wood <scottwood@freescale.com>
Date:   Tue Aug 21 02:36:19 2007 +1000

    [POWERPC] Whitespace cleanup in arch/powerpc
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 24bea97c736c..dfad0e469eec 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -272,7 +272,7 @@ void do_IRQ(struct pt_regs *regs)
 	struct thread_info *curtp, *irqtp;
 #endif
 
-        irq_enter();
+	irq_enter();
 
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	/* Debugging check for stack overflow: is there less than 2KB free? */
@@ -321,7 +321,7 @@ void do_IRQ(struct pt_regs *regs)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
 
-        irq_exit();
+	irq_exit();
 	set_irq_regs(old_regs);
 
 #ifdef CONFIG_PPC_ISERIES

commit 282045b45060d5a8be0ebd13c1506551c6a0a0b8
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Jul 26 00:16:05 2007 -0500

    [POWREPC] Fixup a number of modpost warnings on ppc32
    
    Fixed the following warnings:
    
    WARNING: vmlinux.o(.text+0x2934): Section mismatch: reference to .init.text:__alloc_bootmem (between 'irq_alloc_host' and 'irq_set_default_host')
    WARNING: vmlinux.o(.text+0xb2aa): Section mismatch: reference to .init.data:boot_command_line (between 'register_early_udbg_console' and 'udbg_printf')
    WARNING: vmlinux.o(.text+0xb2b2): Section mismatch: reference to .init.data:boot_command_line (between 'register_early_udbg_console' and 'udbg_printf')
    WARNING: vmlinux.o(.text+0xe354): Section mismatch: reference to .init.text:__alloc_bootmem (between 'pcibios_alloc_controller' and 'pci_domain_nr')
    WARNING: vmlinux.o(.text+0x12768): Section mismatch: reference to .init.text:update_bridge_resource (between 'quirk_fsl_pcie_transparent' and 'indirect_read_config')
    WARNING: vmlinux.o(.text+0x127a8): Section mismatch: reference to .init.text:update_bridge_resource (between 'quirk_fsl_pcie_transparent' and 'indirect_read_config')
    WARNING: vmlinux.o(.text+0x17566c): Section mismatch: reference to .init.text:pcibios_fixup_bus (between 'pci_scan_child_bus' and 'pci_scan_bus_parented')
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 2fc87862146c..24bea97c736c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -418,10 +418,10 @@ irq_hw_number_t virq_to_hw(unsigned int virq)
 }
 EXPORT_SYMBOL_GPL(virq_to_hw);
 
-struct irq_host *irq_alloc_host(unsigned int revmap_type,
-				unsigned int revmap_arg,
-				struct irq_host_ops *ops,
-				irq_hw_number_t inval_irq)
+__init_refok struct irq_host *irq_alloc_host(unsigned int revmap_type,
+						unsigned int revmap_arg,
+						struct irq_host_ops *ops,
+						irq_hw_number_t inval_irq)
 {
 	struct irq_host *host;
 	unsigned int size = sizeof(struct irq_host);

commit 70584578ab3e940ac9d7820f268f9adc9884e407
Author: Sonny Rao <sonny@burdell.org>
Date:   Tue Jul 10 03:31:44 2007 +1000

    [POWERPC] Check for NULL ppc_md.init_IRQ() before calling
    
    Check to make sure ppc_md.init_IRQ has been set before calling it.
    
    Signed-off-by: Sonny Rao <sonny@burdell.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a3351561d283..2fc87862146c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -336,7 +336,8 @@ void do_IRQ(struct pt_regs *regs)
 
 void __init init_IRQ(void)
 {
-	ppc_md.init_IRQ();
+	if (ppc_md.init_IRQ)
+		ppc_md.init_IRQ();
 #ifdef CONFIG_PPC64
 	irq_ctx_init();
 #endif

commit ee51de5645edee4124db6a479d2e135ebe436748
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Mon Jun 4 23:00:00 2007 +1000

    [POWERPC] Add irq_create_direct_mapping()
    
    This patch adds irq_create_direct_mapping().  This routine is
    an alternative to irq_create_mapping(), for irq controllers that
    can use linux virq numbers directly as hardware numbers.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d806b18d9ff9..a3351561d283 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -616,6 +616,30 @@ static int irq_setup_virq(struct irq_host *host, unsigned int virq,
 	return 0;
 }
 
+unsigned int irq_create_direct_mapping(struct irq_host *host)
+{
+	unsigned int virq;
+
+	if (host == NULL)
+		host = irq_default_host;
+
+	BUG_ON(host == NULL);
+	WARN_ON(host->revmap_type != IRQ_HOST_MAP_NOMAP);
+
+	virq = irq_alloc_virt(host, 1, 0);
+	if (virq == NO_IRQ) {
+		pr_debug("irq: create_direct virq allocation failed\n");
+		return NO_IRQ;
+	}
+
+	pr_debug("irq: create_direct obtained virq %d\n", virq);
+
+	if (irq_setup_virq(host, virq, virq))
+		return NO_IRQ;
+
+	return virq;
+}
+
 unsigned int irq_create_mapping(struct irq_host *host,
 				irq_hw_number_t hwirq)
 {

commit 6fde40f3f1a9641ea0a41471cea77f34c0cbb36f
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Mon Jun 4 22:59:59 2007 +1000

    [POWERPC] Split virq setup logic out into irq_setup_virq()
    
    A future patch will need the logic at the end of irq_create_mapping()
    which setups a virq and installs it in the irq_map. So split it out
    into a new function irq_setup_virq().
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0a769893c5c3..d806b18d9ff9 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -596,6 +596,25 @@ static void irq_radix_rdunlock(unsigned long flags)
 	local_irq_restore(flags);
 }
 
+static int irq_setup_virq(struct irq_host *host, unsigned int virq,
+			    irq_hw_number_t hwirq)
+{
+	/* Clear IRQ_NOREQUEST flag */
+	get_irq_desc(virq)->status &= ~IRQ_NOREQUEST;
+
+	/* map it */
+	smp_wmb();
+	irq_map[virq].hwirq = hwirq;
+	smp_mb();
+
+	if (host->ops->map(host, virq, hwirq)) {
+		pr_debug("irq: -> mapping failed, freeing\n");
+		irq_free_virt(virq, 1);
+		return -1;
+	}
+
+	return 0;
+}
 
 unsigned int irq_create_mapping(struct irq_host *host,
 				irq_hw_number_t hwirq)
@@ -644,18 +663,9 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	}
 	pr_debug("irq: -> obtained virq %d\n", virq);
 
-	/* Clear IRQ_NOREQUEST flag */
-	get_irq_desc(virq)->status &= ~IRQ_NOREQUEST;
-
-	/* map it */
-	smp_wmb();
-	irq_map[virq].hwirq = hwirq;
-	smp_mb();
-	if (host->ops->map(host, virq, hwirq)) {
-		pr_debug("irq: -> mapping failed, freeing\n");
-		irq_free_virt(virq, 1);
+	if (irq_setup_virq(host, virq, hwirq))
 		return NO_IRQ;
-	}
+
 	return virq;
 }
 EXPORT_SYMBOL_GPL(irq_create_mapping);

commit 35923f12e42a3baf4ac6da7c05cf5f7478e5a7c6
Author: Olof Johansson <olof@lixom.net>
Date:   Mon Jun 4 14:47:04 2007 +1000

    [POWERPC] Uninline and export virq_to_hw()
    
    Uninline virq_to_hw and export it so modules can use it.  The alternative
    would be to export the irq_map array instead, but it's an infrequently
    called function, and keeping the array unexported seems considerably
    cleaner.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b74b0fd764b2..0a769893c5c3 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -411,6 +411,12 @@ struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_host *irq_default_host;
 
+irq_hw_number_t virq_to_hw(unsigned int virq)
+{
+	return irq_map[virq].hwirq;
+}
+EXPORT_SYMBOL_GPL(virq_to_hw);
+
 struct irq_host *irq_alloc_host(unsigned int revmap_type,
 				unsigned int revmap_arg,
 				struct irq_host_ops *ops,

commit f21f49ea639ac3f24824177dac1268af75a2d373
Author: David Gibson <david@gibson.dropbear.id.au>
Date:   Wed Jun 13 14:52:54 2007 +1000

    [POWERPC] Remove the dregs of APUS support from arch/powerpc
    
    APUS (the Amiga Power-Up System) is not supported under arch/powerpc
    and it's unlikely it ever will be.  Therefore, this patch removes the
    fragments of APUS support code from arch/powerpc which have been
    copied from arch/ppc.
    
    A few APUS references are left in asm-powerpc in .h files which are
    still used from arch/ppc.
    
    Signed-off-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 42c8ed6ed528..b74b0fd764b2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -7,7 +7,6 @@
  *    Copyright (C) 1996-2001 Cort Dougan
  *  Adapted for Power Macintosh by Paul Mackerras
  *    Copyright (C) 1996 Paul Mackerras (paulus@cs.anu.edu.au)
- *  Amiga/APUS changes by Jesper Skov (jskov@cygnus.co.uk).
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License

commit f5921697cf5cae68dcbfa881d9e08f3cebef47eb
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jun 1 17:23:26 2007 +1000

    [POWERPC] Compare irq numbers with NO_IRQ not IRQ_NONE
    
    There is a thinko in the irq code, it uses IRQ_NONE to indicate no irq,
    whereas it should be using NO_IRQ.  IRQ_NONE is returned from irq
    handlers to say "not handled".
    
    As it happens they currently have the same value (0), so this is just for
    future proof-ness.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 068377a2a8dc..42c8ed6ed528 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -489,7 +489,7 @@ struct irq_host *irq_alloc_host(unsigned int revmap_type,
 	case IRQ_HOST_MAP_LINEAR:
 		rmap = (unsigned int *)(host + 1);
 		for (i = 0; i < revmap_arg; i++)
-			rmap[i] = IRQ_NONE;
+			rmap[i] = NO_IRQ;
 		host->revmap_data.linear.size = revmap_arg;
 		smp_wmb();
 		host->revmap_data.linear.revmap = rmap;
@@ -614,7 +614,7 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	 * host->ops->map() to update the flags
 	 */
 	virq = irq_find_mapping(host, hwirq);
-	if (virq != IRQ_NONE) {
+	if (virq != NO_IRQ) {
 		if (host->ops->remap)
 			host->ops->remap(host, virq, hwirq);
 		pr_debug("irq: -> existing mapping on virq %d\n", virq);
@@ -741,7 +741,7 @@ void irq_dispose_mapping(unsigned int virq)
 	switch(host->revmap_type) {
 	case IRQ_HOST_MAP_LINEAR:
 		if (hwirq < host->revmap_data.linear.size)
-			host->revmap_data.linear.revmap[hwirq] = IRQ_NONE;
+			host->revmap_data.linear.revmap[hwirq] = NO_IRQ;
 		break;
 	case IRQ_HOST_MAP_TREE:
 		/* Check if radix tree allocated yet */

commit e1fa2e136ff64a3814a98c03d46320b9e80d29c8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu May 10 22:22:45 2007 -0700

    powerpc: fixup hard_irq_disable semantics
    
    This patch renames the raw hard_irq_{enable,disable} into
    __hard_irq_{enable,disable} and introduces a higher level hard_irq_disable()
    function that can be used by any code to enforce that IRQs are fully disabled,
    not only lazy disabled.
    
    The difference with the __ versions is that it will update some per-processor
    fields so that the kernel keeps track and properly re-enables them in the next
    local_irq_disable();
    
    This prepares powerpc for my next patch that introduces hard_irq_disable()
    generically.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9ed4931af164..068377a2a8dc 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -173,7 +173,7 @@ void local_irq_restore(unsigned long en)
 		lv1_get_version_info(&tmp);
 	}
 
-	hard_irq_enable();
+	__hard_irq_enable();
 }
 #endif /* CONFIG_PPC64 */
 

commit f728b5c3a599d0410a079f447f921a10be7d59d6
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue May 8 12:58:33 2007 +1000

    [POWERPC] Rip out the existing powerpc msi stubs
    
    Rip out the existing powerpc msi stubs. These were the start of an
    implementation based on ppc_md calls, but were never used in mainline.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5719a530f2d1..9ed4931af164 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -958,33 +958,6 @@ arch_initcall(irq_late_init);
 
 #endif /* CONFIG_PPC_MERGE */
 
-#ifdef CONFIG_PCI_MSI
-int pci_enable_msi(struct pci_dev * pdev)
-{
-	if (ppc_md.enable_msi)
-		return ppc_md.enable_msi(pdev);
-	else
-		return -1;
-}
-EXPORT_SYMBOL(pci_enable_msi);
-
-void pci_disable_msi(struct pci_dev * pdev)
-{
-	if (ppc_md.disable_msi)
-		ppc_md.disable_msi(pdev);
-}
-EXPORT_SYMBOL(pci_disable_msi);
-
-void pci_scan_msi_device(struct pci_dev *dev) {}
-int pci_enable_msix(struct pci_dev* dev, struct msix_entry *entries, int nvec) {return -1;}
-void pci_disable_msix(struct pci_dev *dev) {}
-void msi_remove_pci_irq_vectors(struct pci_dev *dev) {}
-void pci_no_msi(void) {}
-EXPORT_SYMBOL(pci_enable_msix);
-EXPORT_SYMBOL(pci_disable_msix);
-
-#endif
-
 #ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {

commit 0874dd40bf3c1f291da14b2c554c5640c0b6bf1b
Author: Takao Shinohara <shin@sm.sony.co.jp>
Date:   Tue May 1 07:01:07 2007 +1000

    [POWERPC] PS3: Fix system slowdown
    
    The PS3 HV will deliver soft-disabled interrupts at the next HV call or
    interrupt.  Add an HV call to local_irq_restore() to force the timely
    delivery of any pending interrupts.
    
    This fixes the system slowdown bug reported here
    http://bugzilla.kernel.org/show_bug.cgi?id=8260
    
    Signed-off-by: Geoff Levand <geoffrey.levand@am.sony.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 6c83fe229e60..5719a530f2d1 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -67,6 +67,7 @@
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 #include <asm/firmware.h>
+#include <asm/lv1call.h>
 #endif
 
 int __irq_offset_value;
@@ -162,6 +163,16 @@ void local_irq_restore(unsigned long en)
 	local_paca->hard_enabled = en;
 	if ((int)mfspr(SPRN_DEC) < 0)
 		mtspr(SPRN_DEC, 1);
+
+	/*
+	 * Force the delivery of pending soft-disabled interrupts on PS3.
+	 * Any HV call will have this side effect.
+	 */
+	if (firmware_has_feature(FW_FEATURE_PS3_LV1)) {
+		u64 tmp;
+		lv1_get_version_info(&tmp);
+	}
+
 	hard_irq_enable();
 }
 #endif /* CONFIG_PPC64 */

commit 057b184a007376562e905aa39f1ba352fb8d78b1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Apr 29 16:10:39 2007 +0000

    [POWERPC] Spinlock initializer cleanup
    
    Use DEFINE_SPINLOCK instead of initializing spinlocks to
    SPIN_LOCK_UNLOCKED, since DEFINE_SPINLOCK is better for lockdep.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 100930826850..6c83fe229e60 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -394,7 +394,7 @@ EXPORT_SYMBOL(do_softirq);
 #ifdef CONFIG_PPC_MERGE
 
 static LIST_HEAD(irq_hosts);
-static spinlock_t irq_big_lock = SPIN_LOCK_UNLOCKED;
+static DEFINE_SPINLOCK(irq_big_lock);
 static DEFINE_PER_CPU(unsigned int, irq_radix_reader);
 static unsigned int irq_radix_writer;
 struct irq_map_entry irq_map[NR_IRQS];

commit f5f2b13129a6541debf8851bae843cbbf48298b7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Mar 5 00:30:07 2007 -0800

    [PATCH] msi: sanely support hardware level msi disabling
    
    In some cases when we are not using msi we need a way to ensure that the
    hardware does not have an msi capability enabled.  Currently the code has been
    calling disable_msi_mode to try and achieve that.  However disable_msi_mode
    has several other side effects and is only available when msi support is
    compiled in so it isn't really appropriate.
    
    Instead this patch implements pci_msi_off which disables all msi and msix
    capabilities unconditionally with no additional side effects.
    
    pci_disable_device was redundantly clearing the bus master enable flag and
    clearing the msi enable bit.  A device that is not allowed to perform bus
    mastering operations cannot generate intx or msi interrupt messages as those
    are essentially a special case of dma, and require bus mastering.  So the call
    in pci_disable_device to disable msi capabilities was redundant.
    
    quirk_pcie_pxh also called disable_msi_mode and is updated to use pci_msi_off.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Greg KH <greg@kroah.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 919fbf568495..100930826850 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -968,7 +968,6 @@ void pci_scan_msi_device(struct pci_dev *dev) {}
 int pci_enable_msix(struct pci_dev* dev, struct msix_entry *entries, int nvec) {return -1;}
 void pci_disable_msix(struct pci_dev *dev) {}
 void msi_remove_pci_irq_vectors(struct pci_dev *dev) {}
-void disable_msi_mode(struct pci_dev *dev, int pos, int type) {}
 void pci_no_msi(void) {}
 EXPORT_SYMBOL(pci_enable_msix);
 EXPORT_SYMBOL(pci_disable_msix);

commit 92d4dda3332577bc2228b8d436f3d2796c59a520
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Wed Dec 13 13:38:22 2006 +0100

    [POWERPC] Fix comment in kernel/irq.c
    
    kernel/irq.c contains a comment that speaks of -1 and -2 as interrupt
    numbers, but this is actually dependent on configuration options now.
    Replace by NO_IRQ and NO_IRQ_ENABLED.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 34dc37e0e369..919fbf568495 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -281,10 +281,10 @@ void do_IRQ(struct pt_regs *regs)
 
 	/*
 	 * Every platform is required to implement ppc_md.get_irq.
-	 * This function will either return an irq number or -1 to
+	 * This function will either return an irq number or NO_IRQ to
 	 * indicate there are no more pending.
-	 * The value -2 is for buggy hardware and means that this IRQ
-	 * has already been handled. -- Tom
+	 * The value NO_IRQ_IGNORE is for buggy hardware and means that this
+	 * IRQ has already been handled. -- Tom
 	 */
 	irq = ppc_md.get_irq();
 

commit acc900ef5b6400747e3bafe0017e725b2ba641b8
Author: Ishizaki Kou <kou.ishizaki@toshiba.co.jp>
Date:   Fri Jan 12 09:58:39 2007 +0900

    [POWERPC] Add IRQ remapping hook
    
    This patch adds irq remapping hook. On interrupt mechanism on Beat,
    when an irq outlet which has an id which is formerly used is created,
    remapping the irq is required.
    
    Signed-off-by: Kou Ishizaki <kou.ishizaki@toshiba.co.jp>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 0bd8c7665834..34dc37e0e369 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -604,6 +604,8 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	 */
 	virq = irq_find_mapping(host, hwirq);
 	if (virq != IRQ_NONE) {
+		if (host->ops->remap)
+			host->ops->remap(host, virq, hwirq);
 		pr_debug("irq: -> existing mapping on virq %d\n", virq);
 		return virq;
 	}

commit ef2b343e99e772e35f0f9d00f7db318b6629c16e
Author: Hugh Dickins <hugh@veritas.com>
Date:   Fri Nov 10 21:32:40 2006 +0000

    [POWERPC] Make soft_enabled irqs preempt safe
    
    Rewrite local_get_flags and local_irq_disable to use r13 explicitly,
    to avoid the risk that gcc will split get_paca()->soft_enabled into a
    sequence unsafe against preemption.  Similar care in local_irq_restore.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index e1936952017c..0bd8c7665834 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -97,22 +97,69 @@ EXPORT_SYMBOL(irq_desc);
 
 int distribute_irqs = 1;
 
+static inline unsigned long get_hard_enabled(void)
+{
+	unsigned long enabled;
+
+	__asm__ __volatile__("lbz %0,%1(13)"
+	: "=r" (enabled) : "i" (offsetof(struct paca_struct, hard_enabled)));
+
+	return enabled;
+}
+
+static inline void set_soft_enabled(unsigned long enable)
+{
+	__asm__ __volatile__("stb %0,%1(13)"
+	: : "r" (enable), "i" (offsetof(struct paca_struct, soft_enabled)));
+}
+
 void local_irq_restore(unsigned long en)
 {
-	get_paca()->soft_enabled = en;
+	/*
+	 * get_paca()->soft_enabled = en;
+	 * Is it ever valid to use local_irq_restore(0) when soft_enabled is 1?
+	 * That was allowed before, and in such a case we do need to take care
+	 * that gcc will set soft_enabled directly via r13, not choose to use
+	 * an intermediate register, lest we're preempted to a different cpu.
+	 */
+	set_soft_enabled(en);
 	if (!en)
 		return;
 
 	if (firmware_has_feature(FW_FEATURE_ISERIES)) {
-		if (get_paca()->lppaca_ptr->int_dword.any_int)
+		/*
+		 * Do we need to disable preemption here?  Not really: in the
+		 * unlikely event that we're preempted to a different cpu in
+		 * between getting r13, loading its lppaca_ptr, and loading
+		 * its any_int, we might call iseries_handle_interrupts without
+		 * an interrupt pending on the new cpu, but that's no disaster,
+		 * is it?  And the business of preempting us off the old cpu
+		 * would itself involve a local_irq_restore which handles the
+		 * interrupt to that cpu.
+		 *
+		 * But use "local_paca->lppaca_ptr" instead of "get_lppaca()"
+		 * to avoid any preemption checking added into get_paca().
+		 */
+		if (local_paca->lppaca_ptr->int_dword.any_int)
 			iseries_handle_interrupts();
 		return;
 	}
 
-	if (get_paca()->hard_enabled)
+	/*
+	 * if (get_paca()->hard_enabled) return;
+	 * But again we need to take care that gcc gets hard_enabled directly
+	 * via r13, not choose to use an intermediate register, lest we're
+	 * preempted to a different cpu in between the two instructions.
+	 */
+	if (get_hard_enabled())
 		return;
-	/* need to hard-enable interrupts here */
-	get_paca()->hard_enabled = en;
+
+	/*
+	 * Need to hard-enable interrupts here.  Since currently disabled,
+	 * no need to take further asm precautions against preemption; but
+	 * use local_paca instead of get_paca() to avoid preemption checking.
+	 */
+	local_paca->hard_enabled = en;
 	if ((int)mfspr(SPRN_DEC) < 0)
 		mtspr(SPRN_DEC, 1);
 	hard_irq_enable();

commit b06a318372ba95873abfe323076bd7e115d64b67
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Nov 21 14:16:13 2006 +1100

    [POWERPC] iSeries: fix irq.c for combined build
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index eb9fc621e057..e1936952017c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -268,7 +268,8 @@ void do_IRQ(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 
 #ifdef CONFIG_PPC_ISERIES
-	if (get_lppaca()->int_dword.fields.decr_int) {
+	if (firmware_has_feature(FW_FEATURE_ISERIES) &&
+			get_lppaca()->int_dword.fields.decr_int) {
 		get_lppaca()->int_dword.fields.decr_int = 0;
 		/* Signal a fake decrementer interrupt */
 		timer_interrupt(regs);

commit 5414c6be57dd02e089c3eba1f5134f441733d013
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 24 13:37:34 2006 +1000

    [POWERPC] Make irq_dispose_mapping(NO_IRQ) a nop
    
    It makes for a friendlier API if irq_dispose_mapping(NO_IRQ) is a
    nop, rather than triggering a WARN_ON.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 67b21a008f6e..eb9fc621e057 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -648,10 +648,14 @@ EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
 void irq_dispose_mapping(unsigned int virq)
 {
-	struct irq_host *host = irq_map[virq].host;
+	struct irq_host *host;
 	irq_hw_number_t hwirq;
 	unsigned long flags;
 
+	if (virq == NO_IRQ)
+		return;
+
+	host = irq_map[virq].host;
 	WARN_ON (host == NULL);
 	if (host == NULL)
 		return;

commit d04c56f73c30a5e593202ecfcf25ed43d42363a2
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Oct 4 16:47:49 2006 +1000

    [POWERPC] Lazy interrupt disabling for 64-bit machines
    
    This implements a lazy strategy for disabling interrupts.  This means
    that local_irq_disable() et al. just clear the 'interrupts are
    enabled' flag in the paca.  If an interrupt comes along, the interrupt
    entry code notices that interrupts are supposed to be disabled, and
    clears the EE bit in SRR1, clears the 'interrupts are hard-enabled'
    flag in the paca, and returns.  This means that interrupts only
    actually get disabled in the processor when an interrupt comes along.
    
    When interrupts are enabled by local_irq_enable() et al., the code
    sets the interrupts-enabled flag in the paca, and then checks whether
    interrupts got hard-disabled.  If so, it also sets the EE bit in the
    MSR to hard-enable the interrupts.
    
    This has the potential to improve performance, and also makes it
    easier to make a kernel that can boot on iSeries and on other 64-bit
    machines, since this lazy-disable strategy is very similar to the
    soft-disable strategy that iSeries already uses.
    
    This version renames paca->proc_enabled to paca->soft_enabled, and
    changes a couple of soft-disables in the kexec code to hard-disables,
    which should fix the crash that Michael Ellerman saw.  This doesn't
    yet use a reserved CR field for the soft_enabled and hard_enabled
    flags.  This applies on top of Stephen Rothwell's patches to make it
    possible to build a combined iSeries/other kernel.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5e37bf14ef2d..67b21a008f6e 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -64,8 +64,9 @@
 #include <asm/ptrace.h>
 #include <asm/machdep.h>
 #include <asm/udbg.h>
-#ifdef CONFIG_PPC_ISERIES
+#ifdef CONFIG_PPC64
 #include <asm/paca.h>
+#include <asm/firmware.h>
 #endif
 
 int __irq_offset_value;
@@ -95,6 +96,27 @@ extern atomic_t ipi_sent;
 EXPORT_SYMBOL(irq_desc);
 
 int distribute_irqs = 1;
+
+void local_irq_restore(unsigned long en)
+{
+	get_paca()->soft_enabled = en;
+	if (!en)
+		return;
+
+	if (firmware_has_feature(FW_FEATURE_ISERIES)) {
+		if (get_paca()->lppaca_ptr->int_dword.any_int)
+			iseries_handle_interrupts();
+		return;
+	}
+
+	if (get_paca()->hard_enabled)
+		return;
+	/* need to hard-enable interrupts here */
+	get_paca()->hard_enabled = en;
+	if ((int)mfspr(SPRN_DEC) < 0)
+		mtspr(SPRN_DEC, 1);
+	hard_irq_enable();
+}
 #endif /* CONFIG_PPC64 */
 
 int show_interrupts(struct seq_file *p, void *v)

commit f3d2ab41b5e2dfb2fc8679b786476327cea2f249
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Mon Oct 9 16:22:09 2006 +0100

    [PATCH] extern doesn't make sense on a definition of function...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 829ac18b566c..5e37bf14ef2d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -572,8 +572,8 @@ unsigned int irq_create_mapping(struct irq_host *host,
 }
 EXPORT_SYMBOL_GPL(irq_create_mapping);
 
-extern unsigned int irq_create_of_mapping(struct device_node *controller,
-					  u32 *intspec, unsigned int intsize)
+unsigned int irq_create_of_mapping(struct device_node *controller,
+				   u32 *intspec, unsigned int intsize)
 {
 	struct irq_host *host;
 	irq_hw_number_t hwirq;

commit 35a84c2f56e0f77ea2c5a4327b17104705f4c8c7
Author: Olaf Hering <olaf@aepfle.de>
Date:   Sat Oct 7 22:08:26 2006 +1000

    [POWERPC] Fix up after irq changes
    
    Remove struct pt_regs * from all handlers.
    Also remove the regs argument from get_irq() functions.
    Compile tested with arch/powerpc/config/* and
    arch/ppc/configs/prep_defconfig
    
    Signed-off-by: Olaf Hering <olaf@aepfle.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5deaab3090b4..829ac18b566c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -217,7 +217,7 @@ void do_IRQ(struct pt_regs *regs)
 	 * The value -2 is for buggy hardware and means that this IRQ
 	 * has already been handled. -- Tom
 	 */
-	irq = ppc_md.get_irq(regs);
+	irq = ppc_md.get_irq();
 
 	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE) {
 #ifdef CONFIG_IRQSTACKS

commit 7d12e780e003f93433d49ce78cfedf4b4c52adc5
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 5 14:55:46 2006 +0100

    IRQ: Maintain regs pointer globally rather than passing to IRQ handlers
    
    Maintain a per-CPU global "struct pt_regs *" variable which can be used instead
    of passing regs around manually through all ~1800 interrupt handlers in the
    Linux kernel.
    
    The regs pointer is used in few places, but it potentially costs both stack
    space and code to pass it around.  On the FRV arch, removing the regs parameter
    from all the genirq function results in a 20% speed up of the IRQ exit path
    (ie: from leaving timer_interrupt() to leaving do_IRQ()).
    
    Where appropriate, an arch may override the generic storage facility and do
    something different with the variable.  On FRV, for instance, the address is
    maintained in GR28 at all times inside the kernel as part of general exception
    handling.
    
    Having looked over the code, it appears that the parameter may be handed down
    through up to twenty or so layers of functions.  Consider a USB character
    device attached to a USB hub, attached to a USB controller that posts its
    interrupts through a cascaded auxiliary interrupt controller.  A character
    device driver may want to pass regs to the sysrq handler through the input
    layer which adds another few layers of parameter passing.
    
    I've build this code with allyesconfig for x86_64 and i386.  I've runtested the
    main part of the code on FRV and i386, though I can't test most of the drivers.
    I've also done partial conversion for powerpc and MIPS - these at least compile
    with minimal configurations.
    
    This will affect all archs.  Mostly the changes should be relatively easy.
    Take do_IRQ(), store the regs pointer at the beginning, saving the old one:
    
            struct pt_regs *old_regs = set_irq_regs(regs);
    
    And put the old one back at the end:
    
            set_irq_regs(old_regs);
    
    Don't pass regs through to generic_handle_irq() or __do_IRQ().
    
    In timer_interrupt(), this sort of change will be necessary:
    
            -       update_process_times(user_mode(regs));
            -       profile_tick(CPU_PROFILING, regs);
            +       update_process_times(user_mode(get_irq_regs()));
            +       profile_tick(CPU_PROFILING);
    
    I'd like to move update_process_times()'s use of get_irq_regs() into itself,
    except that i386, alone of the archs, uses something other than user_mode().
    
    Some notes on the interrupt handling in the drivers:
    
     (*) input_dev() is now gone entirely.  The regs pointer is no longer stored in
         the input_dev struct.
    
     (*) finish_unlinks() in drivers/usb/host/ohci-q.c needs checking.  It does
         something different depending on whether it's been supplied with a regs
         pointer or not.
    
     (*) Various IRQ handler function pointers have been moved to type
         irq_handler_t.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    (cherry picked from 1b16e7ac850969f38b375e511e3fa2f474a33867 commit)

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index c3f58f2f9f52..5deaab3090b4 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -187,6 +187,7 @@ void fixup_irqs(cpumask_t map)
 
 void do_IRQ(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 #ifdef CONFIG_IRQSTACKS
 	struct thread_info *curtp, *irqtp;
@@ -230,18 +231,19 @@ void do_IRQ(struct pt_regs *regs)
 				handler = &__do_IRQ;
 			irqtp->task = curtp->task;
 			irqtp->flags = 0;
-			call_handle_irq(irq, desc, regs, irqtp, handler);
+			call_handle_irq(irq, desc, irqtp, handler);
 			irqtp->task = NULL;
 			if (irqtp->flags)
 				set_bits(irqtp->flags, &curtp->flags);
 		} else
 #endif
-			generic_handle_irq(irq, regs);
+			generic_handle_irq(irq);
 	} else if (irq != NO_IRQ_IGNORE)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
 
         irq_exit();
+	set_irq_regs(old_regs);
 
 #ifdef CONFIG_PPC_ISERIES
 	if (get_lppaca()->int_dword.fields.decr_int) {

commit e12514650b167f48e952d50315fd492d01d42988
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Aug 2 10:48:50 2006 +1000

    [POWERPC] Fix loop logic in irq_alloc_virt()
    
    There's a bug in irq_alloc_virt() if it's asked for more than 1 interrupt,
    if it can't find a slot it might look past the end of the irq_map.
    To be clear: the bug is that the continue affects the inner for loop,
    not the outer one, so i becomes j + 1 and then we continue the inner
    loop without checking if i is still <= limit.
    
    This fixes it. No one in the kernel actually calls this with count >
    1, so it's not critical.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index b4432332341f..c3f58f2f9f52 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -777,7 +777,6 @@ unsigned int irq_alloc_virt(struct irq_host *host,
 {
 	unsigned long flags;
 	unsigned int i, j, found = NO_IRQ;
-	unsigned int limit = irq_virq_count - count;
 
 	if (count == 0 || count > (irq_virq_count - NUM_ISA_INTERRUPTS))
 		return NO_IRQ;
@@ -794,14 +793,16 @@ unsigned int irq_alloc_virt(struct irq_host *host,
 	/* Look for count consecutive numbers in the allocatable
 	 * (non-legacy) space
 	 */
-	for (i = NUM_ISA_INTERRUPTS; i <= limit; ) {
-		for (j = i; j < (i + count); j++)
-			if (irq_map[j].host != NULL) {
-				i = j + 1;
-				continue;
-			}
-		found = i;
-		break;
+	for (i = NUM_ISA_INTERRUPTS, j = 0; i < irq_virq_count; i++) {
+		if (irq_map[i].host != NULL)
+			j = 0;
+		else
+			j++;
+
+		if (j == count) {
+			found = i - count + 1;
+			break;
+		}
 	}
 	if (found == NO_IRQ) {
 		spin_unlock_irqrestore(&irq_big_lock, flags);

commit aa43f77939c97bf9d3580c6a5e71a5a40290e451
Merge: 2818c5dec5e2 4c15343167b5
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Aug 31 15:45:48 2006 +1000

    Merge branch 'merge'

commit 8ec8f2e85c6b88b4a1641eb3902275bcf2c6d60a
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Aug 28 11:17:37 2006 +1000

    [POWERPC] Fix performance regression in IRQ radix tree locking
    
    When reworking the powerpc irq code, I figured out that we were using
    the radix tree in a racy way. As a temporary fix, I put a spinlock in
    there. However, this can have a significant impact on performances. This
    patch reworks that to use a smarter technique based on the fact that
    what we need is in fact a rwlock with extremely rare writers (thus
    optimized for the read path).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 7ee685433319..12c5971d6565 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -322,7 +322,8 @@ EXPORT_SYMBOL(do_softirq);
 
 static LIST_HEAD(irq_hosts);
 static spinlock_t irq_big_lock = SPIN_LOCK_UNLOCKED;
-
+static DEFINE_PER_CPU(unsigned int, irq_radix_reader);
+static unsigned int irq_radix_writer;
 struct irq_map_entry irq_map[NR_IRQS];
 static unsigned int irq_virq_count = NR_IRQS;
 static struct irq_host *irq_default_host;
@@ -455,6 +456,58 @@ void irq_set_virq_count(unsigned int count)
 		irq_virq_count = count;
 }
 
+/* radix tree not lockless safe ! we use a brlock-type mecanism
+ * for now, until we can use a lockless radix tree
+ */
+static void irq_radix_wrlock(unsigned long *flags)
+{
+	unsigned int cpu, ok;
+
+	spin_lock_irqsave(&irq_big_lock, *flags);
+	irq_radix_writer = 1;
+	smp_mb();
+	do {
+		barrier();
+		ok = 1;
+		for_each_possible_cpu(cpu) {
+			if (per_cpu(irq_radix_reader, cpu)) {
+				ok = 0;
+				break;
+			}
+		}
+		if (!ok)
+			cpu_relax();
+	} while(!ok);
+}
+
+static void irq_radix_wrunlock(unsigned long flags)
+{
+	smp_wmb();
+	irq_radix_writer = 0;
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+}
+
+static void irq_radix_rdlock(unsigned long *flags)
+{
+	local_irq_save(*flags);
+	__get_cpu_var(irq_radix_reader) = 1;
+	smp_mb();
+	if (likely(irq_radix_writer == 0))
+		return;
+	__get_cpu_var(irq_radix_reader) = 0;
+	smp_wmb();
+	spin_lock(&irq_big_lock);
+	__get_cpu_var(irq_radix_reader) = 1;
+	spin_unlock(&irq_big_lock);
+}
+
+static void irq_radix_rdunlock(unsigned long flags)
+{
+	__get_cpu_var(irq_radix_reader) = 0;
+	local_irq_restore(flags);
+}
+
+
 unsigned int irq_create_mapping(struct irq_host *host,
 				irq_hw_number_t hwirq)
 {
@@ -604,13 +657,9 @@ void irq_dispose_mapping(unsigned int virq)
 		/* Check if radix tree allocated yet */
 		if (host->revmap_data.tree.gfp_mask == 0)
 			break;
-		/* XXX radix tree not safe ! remove lock whem it becomes safe
-		 * and use some RCU sync to make sure everything is ok before we
-		 * can re-use that map entry
-		 */
-		spin_lock_irqsave(&irq_big_lock, flags);
+		irq_radix_wrlock(&flags);
 		radix_tree_delete(&host->revmap_data.tree, hwirq);
-		spin_unlock_irqrestore(&irq_big_lock, flags);
+		irq_radix_wrunlock(flags);
 		break;
 	}
 
@@ -677,25 +726,24 @@ unsigned int irq_radix_revmap(struct irq_host *host,
 	if (tree->gfp_mask == 0)
 		return irq_find_mapping(host, hwirq);
 
-	/* XXX Current radix trees are NOT SMP safe !!! Remove that lock
-	 * when that is fixed (when Nick's patch gets in
-	 */
-	spin_lock_irqsave(&irq_big_lock, flags);
-
 	/* Now try to resolve */
+	irq_radix_rdlock(&flags);
 	ptr = radix_tree_lookup(tree, hwirq);
+	irq_radix_rdunlock(flags);
+
 	/* Found it, return */
 	if (ptr) {
 		virq = ptr - irq_map;
-		goto bail;
+		return virq;
 	}
 
 	/* If not there, try to insert it */
 	virq = irq_find_mapping(host, hwirq);
-	if (virq != NO_IRQ)
+	if (virq != NO_IRQ) {
+		irq_radix_wrlock(&flags);
 		radix_tree_insert(tree, hwirq, &irq_map[virq]);
- bail:
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+		irq_radix_wrunlock(flags);
+	}
 	return virq;
 }
 
@@ -806,12 +854,12 @@ static int irq_late_init(void)
 	struct irq_host *h;
 	unsigned long flags;
 
-	spin_lock_irqsave(&irq_big_lock, flags);
+	irq_radix_wrlock(&flags);
 	list_for_each_entry(h, &irq_hosts, link) {
 		if (h->revmap_type == IRQ_HOST_MAP_TREE)
 			INIT_RADIX_TREE(&h->revmap_data.tree, GFP_ATOMIC);
 	}
-	spin_unlock_irqrestore(&irq_big_lock, flags);
+	irq_radix_wrunlock(flags);
 
 	return 0;
 }

commit ea0763a7e62f60f3e166327268a80f16ad806718
Merge: 271c511db9d3 c85c41ad73c6
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Aug 25 14:56:07 2006 +1000

    Merge branch 'merge'

commit e5c14ce118ab6a96afb2af5c4ec9727b03ab1936
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Aug 17 03:59:27 2006 +0200

    [POWERPC] Fix irq radix tree remapping typo
    
    The code for using the radix tree for reverse mapping of interrupts has
    a typo that causes it to create incorrect mappings if the software and
    hardware numbers happen to be different. This would, among others, cause
    the IDE interrupt to fail on js20's. This fixes it.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 01bdae35cb55..7ee685433319 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -693,7 +693,7 @@ unsigned int irq_radix_revmap(struct irq_host *host,
 	/* If not there, try to insert it */
 	virq = irq_find_mapping(host, hwirq);
 	if (virq != NO_IRQ)
-		radix_tree_insert(tree, virq, &irq_map[virq]);
+		radix_tree_insert(tree, hwirq, &irq_map[virq]);
  bail:
 	spin_unlock_irqrestore(&irq_big_lock, flags);
 	return virq;

commit 45934c47237108903ec019f08e124e592ba0b6c2
Author: Jake Moilanen <moilanen@austin.ibm.com>
Date:   Thu Jul 27 13:17:25 2006 -0500

    [POWERPC] Export msi symbols
    
    Forgot to export symbols for MSI.
    
    Signed-off-by: Jake Moilanen <moilanen@austin.ibm.com>
    Acked-by: Segher Boessenkool <segher@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 01bdae35cb55..b2ded6460a86 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -52,6 +52,7 @@
 #include <linux/radix-tree.h>
 #include <linux/mutex.h>
 #include <linux/bootmem.h>
+#include <linux/pci.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -827,12 +828,14 @@ int pci_enable_msi(struct pci_dev * pdev)
 	else
 		return -1;
 }
+EXPORT_SYMBOL(pci_enable_msi);
 
 void pci_disable_msi(struct pci_dev * pdev)
 {
 	if (ppc_md.disable_msi)
 		ppc_md.disable_msi(pdev);
 }
+EXPORT_SYMBOL(pci_disable_msi);
 
 void pci_scan_msi_device(struct pci_dev *dev) {}
 int pci_enable_msix(struct pci_dev* dev, struct msix_entry *entries, int nvec) {return -1;}
@@ -840,6 +843,8 @@ void pci_disable_msix(struct pci_dev *dev) {}
 void msi_remove_pci_irq_vectors(struct pci_dev *dev) {}
 void disable_msi_mode(struct pci_dev *dev, int pos, int type) {}
 void pci_no_msi(void) {}
+EXPORT_SYMBOL(pci_enable_msix);
+EXPORT_SYMBOL(pci_disable_msix);
 
 #endif
 

commit 6e99e4582861578fb00d84d085f8f283569f51dd
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 10 04:44:42 2006 -0700

    [PATCH] powerpc: fix trigger handling in the new irq code
    
    This patch slightly reworks the new irq code to fix a small design error.  I
    removed the passing of the trigger to the map() calls entirely, it was not a
    good idea to have one call do two different things.  It also fixes a couple of
    corner cases.
    
    Mapping a linux virtual irq to a physical irq now does only that.  Setting the
    trigger is a different action which has a different call.
    
    The main changes are:
    
    - I no longer call host->ops->map() for an already mapped irq, I just return
      the virtual number that was already mapped.  It was called before to give an
      opportunity to change the trigger, but that was causing issues as that could
      happen while the interrupt was in use by a device, and because of the
      trigger change, map would potentially muck around with things in a racy way.
       That was causing much burden on a given's controller implementation of
      map() to get it right.  This is much simpler now.  map() is only called on
      the initial mapping of an irq, meaning that you know that this irq is _not_
      being used.  You can initialize the hardware if you want (though you don't
      have to).
    
    - Controllers that can handle different type of triggers (level/edge/etc...)
      now implement the standard irq_chip->set_type() call as defined by the
      generic code.  That means that you can use the standard set_irq_type() to
      configure an irq line manually if you wish or (though I don't like that
      interface), pass explicit trigger flags to request_irq() as defined by the
      generic kernel interfaces.  Also, using those interfaces guarantees that
      your controller set_type callback is called with the descriptor lock held,
      thus providing locking against activity on the same interrupt (including
      mask/unmask/etc...) automatically.  A result is that, for example, MPIC's
      own map() implementation calls irq_set_type(NONE) to configure the hardware
      to the default triggers.
    
    - To allow the above, the irq_map array entry for the new mapped interrupt
      is now set before map() callback is called for the controller.
    
    - The irq_create_of_mapping() (also used by irq_of_parse_and_map()) function
      for mapping interrupts from the device-tree now also call the separate
      set_irq_type(), and only does so if there is a change in the trigger type.
    
    - While I was at it, I changed pci_read_irq_line() (which is the helper I
      would expect most archs to use in their pcibios_fixup() to get the PCI
      interrupt routing from the device tree) to also handle a fallback when the
      DT mapping fails consisting of reading the PCI_INTERRUPT_PIN to know wether
      the device has an interrupt at all, and the the PCI_INTERRUPT_LINE to get an
      interrupt number from the device.  That number is then mapped using the
      default controller, and the trigger is set to level low.  That default
      behaviour works for several platforms that don't have a proper interrupt
      tree like Pegasos.  If it doesn't work for your platform, then either
      provide a proper interrupt tree from the firmware so that fallback isn't
      needed, or don't call pci_read_irq_line()
    
    - Add back a bit that got dropped by my main rework patch for properly
      clearing pending IPIs on pSeries when using a kexec
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8cf987809c66..01bdae35cb55 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -391,15 +391,14 @@ struct irq_host *irq_alloc_host(unsigned int revmap_type,
 			irq_map[i].host = host;
 			smp_wmb();
 
-			/* Clear some flags */
-			get_irq_desc(i)->status
-				&= ~(IRQ_NOREQUEST | IRQ_LEVEL);
+			/* Clear norequest flags */
+			get_irq_desc(i)->status &= ~IRQ_NOREQUEST;
 
 			/* Legacy flags are left to default at this point,
 			 * one can then use irq_create_mapping() to
 			 * explicitely change them
 			 */
-			ops->map(host, i, i, 0);
+			ops->map(host, i, i);
 		}
 		break;
 	case IRQ_HOST_MAP_LINEAR:
@@ -457,13 +456,11 @@ void irq_set_virq_count(unsigned int count)
 }
 
 unsigned int irq_create_mapping(struct irq_host *host,
-				irq_hw_number_t hwirq,
-				unsigned int flags)
+				irq_hw_number_t hwirq)
 {
 	unsigned int virq, hint;
 
-	pr_debug("irq: irq_create_mapping(0x%p, 0x%lx, 0x%x)\n",
-		 host, hwirq, flags);
+	pr_debug("irq: irq_create_mapping(0x%p, 0x%lx)\n", host, hwirq);
 
 	/* Look for default host if nececssary */
 	if (host == NULL)
@@ -482,7 +479,6 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	virq = irq_find_mapping(host, hwirq);
 	if (virq != IRQ_NONE) {
 		pr_debug("irq: -> existing mapping on virq %d\n", virq);
-		host->ops->map(host, virq, hwirq, flags);
 		return virq;
 	}
 
@@ -504,18 +500,18 @@ unsigned int irq_create_mapping(struct irq_host *host,
 	}
 	pr_debug("irq: -> obtained virq %d\n", virq);
 
-	/* Clear some flags */
-	get_irq_desc(virq)->status &= ~(IRQ_NOREQUEST | IRQ_LEVEL);
+	/* Clear IRQ_NOREQUEST flag */
+	get_irq_desc(virq)->status &= ~IRQ_NOREQUEST;
 
 	/* map it */
-	if (host->ops->map(host, virq, hwirq, flags)) {
+	smp_wmb();
+	irq_map[virq].hwirq = hwirq;
+	smp_mb();
+	if (host->ops->map(host, virq, hwirq)) {
 		pr_debug("irq: -> mapping failed, freeing\n");
 		irq_free_virt(virq, 1);
 		return NO_IRQ;
 	}
-	smp_wmb();
-	irq_map[virq].hwirq = hwirq;
-	smp_mb();
 	return virq;
 }
 EXPORT_SYMBOL_GPL(irq_create_mapping);
@@ -525,25 +521,38 @@ extern unsigned int irq_create_of_mapping(struct device_node *controller,
 {
 	struct irq_host *host;
 	irq_hw_number_t hwirq;
-	unsigned int flags = IRQ_TYPE_NONE;
+	unsigned int type = IRQ_TYPE_NONE;
+	unsigned int virq;
 
 	if (controller == NULL)
 		host = irq_default_host;
 	else
 		host = irq_find_host(controller);
-	if (host == NULL)
+	if (host == NULL) {
+		printk(KERN_WARNING "irq: no irq host found for %s !\n",
+		       controller->full_name);
 		return NO_IRQ;
+	}
 
 	/* If host has no translation, then we assume interrupt line */
 	if (host->ops->xlate == NULL)
 		hwirq = intspec[0];
 	else {
 		if (host->ops->xlate(host, controller, intspec, intsize,
-				     &hwirq, &flags))
+				     &hwirq, &type))
 			return NO_IRQ;
 	}
 
-	return irq_create_mapping(host, hwirq, flags);
+	/* Create mapping */
+	virq = irq_create_mapping(host, hwirq);
+	if (virq == NO_IRQ)
+		return virq;
+
+	/* Set type if specified and different than the current one */
+	if (type != IRQ_TYPE_NONE &&
+	    type != (get_irq_desc(virq)->status & IRQF_TRIGGER_MASK))
+		set_irq_type(virq, type);
+	return virq;
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 

commit 912b2539e1e062cec73e2e61448e507f7719bd08
Merge: 70b97a7f0b19 39ab9c212aac
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Mon Jul 3 15:28:34 2006 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc:
      powerpc: add defconfig for Freescale MPC8349E-mITX board
      powerpc: Add base support for the Freescale MPC8349E-mITX eval board
      Documentation: correct values in MPC8548E SEC example node
      [POWERPC] Actually copy over i8259.c to arch/ppc/syslib this time
      [POWERPC] Add new interrupt mapping core and change platforms to use it
      [POWERPC] Copy i8259 code back to arch/ppc
      [POWERPC] New device-tree interrupt parsing code
      [POWERPC] Use the genirq framework
      [PATCH] genirq: Allow fasteoi handler to retrigger disabled interrupts
      [POWERPC] Update the SWIM3 (powermac) floppy driver
      [POWERPC] Fix error handling in detecting legacy serial ports
      [POWERPC] Fix booting on Momentum "Apache" board (a Maple derivative)
      [POWERPC] Fix various offb and BootX-related issues
      [POWERPC] Add a default config for 32-bit CHRP machines
      [POWERPC] fix implicit declaration on cell.
      [POWERPC] change get_property to return void *

commit 829035fd709119d9def124a6d40b94d317573e6f
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Jul 3 00:25:40 2006 -0700

    [PATCH] lockdep: irqtrace subsystem, move account_system_vtime() calls into kernel/softirq.c
    
    At the moment, powerpc and s390 have their own versions of do_softirq which
    include local_bh_disable() and __local_bh_enable() calls.  They end up
    calling __do_softirq (in kernel/softirq.c) which also does
    local_bh_disable/enable.
    
    Apparently the two levels of disable/enable trigger a warning from some
    validation code that Ingo is working on, and he would like to see the outer
    level removed.  But to do that, we have to move the account_system_vtime
    calls that are currently in the arch do_softirq() implementations for
    powerpc and s390 into the generic __do_softirq() (this is a no-op for other
    archs because account_system_vtime is defined to be an empty inline
    function on all other archs).  This patch does that.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 027728b95429..e3774f6b57cc 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -424,13 +424,8 @@ void do_softirq(void)
 
 	local_irq_save(flags);
 
-	if (local_softirq_pending()) {
-		account_system_vtime(current);
-		local_bh_disable();
+	if (local_softirq_pending())
 		do_softirq_onstack();
-		account_system_vtime(current);
-		_local_bh_enable();
-	}
 
 	local_irq_restore(flags);
 }

commit de30a2b355ea85350ca2f58f3b9bf4e5bc007986
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 3 00:24:42 2006 -0700

    [PATCH] lockdep: irqtrace subsystem, core
    
    Accurate hard-IRQ-flags and softirq-flags state tracing.
    
    This allows us to attach extra functionality to IRQ flags on/off
    events (such as trace-on/off).
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 525baab45d2d..027728b95429 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -429,7 +429,7 @@ void do_softirq(void)
 		local_bh_disable();
 		do_softirq_onstack();
 		account_system_vtime(current);
-		__local_bh_enable();
+		_local_bh_enable();
 	}
 
 	local_irq_restore(flags);

commit 0ebfff1491ef85d41ddf9c633834838be144f69f
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 3 21:36:01 2006 +1000

    [POWERPC] Add new interrupt mapping core and change platforms to use it
    
    This adds the new irq remapper core and removes the old one.  Because
    there are some fundamental conflicts with the old code, like the value
    of NO_IRQ which I'm now setting to 0 (as per discussions with Linus),
    etc..., this commit also changes the relevant platform and driver code
    over to use the new remapper (so as not to cause difficulties later
    in bisecting).
    
    This patch removes the old pre-parsing of the open firmware interrupt
    tree along with all the bogus assumptions it made to try to renumber
    interrupts according to the platform. This is all to be handled by the
    new code now.
    
    For the pSeries XICS interrupt controller, a single remapper host is
    created for the whole machine regardless of how many interrupt
    presentation and source controllers are found, and it's set to match
    any device node that isn't a 8259.  That works fine on pSeries and
    avoids having to deal with some of the complexities of split source
    controllers vs. presentation controllers in the pSeries device trees.
    
    The powerpc i8259 PIC driver now always requests the legacy interrupt
    range. It also has the feature of being able to match any device node
    (including NULL) if passed no device node as an input. That will help
    porting over platforms with broken device-trees like Pegasos who don't
    have a proper interrupt tree.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 91248559099a..05a700940f67 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -29,6 +29,8 @@
  * to reduce code space and undefined function references.
  */
 
+#undef DEBUG
+
 #include <linux/module.h>
 #include <linux/threads.h>
 #include <linux/kernel_stat.h>
@@ -46,7 +48,10 @@
 #include <linux/cpumask.h>
 #include <linux/profile.h>
 #include <linux/bitops.h>
-#include <linux/pci.h>
+#include <linux/list.h>
+#include <linux/radix-tree.h>
+#include <linux/mutex.h>
+#include <linux/bootmem.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -57,6 +62,7 @@
 #include <asm/prom.h>
 #include <asm/ptrace.h>
 #include <asm/machdep.h>
+#include <asm/udbg.h>
 #ifdef CONFIG_PPC_ISERIES
 #include <asm/paca.h>
 #endif
@@ -88,7 +94,6 @@ extern atomic_t ipi_sent;
 EXPORT_SYMBOL(irq_desc);
 
 int distribute_irqs = 1;
-u64 ppc64_interrupt_controller;
 #endif /* CONFIG_PPC64 */
 
 int show_interrupts(struct seq_file *p, void *v)
@@ -181,7 +186,7 @@ void fixup_irqs(cpumask_t map)
 
 void do_IRQ(struct pt_regs *regs)
 {
-	int irq;
+	unsigned int irq;
 #ifdef CONFIG_IRQSTACKS
 	struct thread_info *curtp, *irqtp;
 #endif
@@ -212,7 +217,7 @@ void do_IRQ(struct pt_regs *regs)
 	 */
 	irq = ppc_md.get_irq(regs);
 
-	if (irq >= 0) {
+	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE) {
 #ifdef CONFIG_IRQSTACKS
 		/* Switch to the irq stack to handle this */
 		curtp = current_thread_info();
@@ -231,7 +236,7 @@ void do_IRQ(struct pt_regs *regs)
 		} else
 #endif
 			generic_handle_irq(irq, regs);
-	} else if (irq != -2)
+	} else if (irq != NO_IRQ_IGNORE)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
 
@@ -254,123 +259,6 @@ void __init init_IRQ(void)
 #endif
 }
 
-#ifdef CONFIG_PPC64
-/*
- * Virtual IRQ mapping code, used on systems with XICS interrupt controllers.
- */
-
-#define UNDEFINED_IRQ 0xffffffff
-unsigned int virt_irq_to_real_map[NR_IRQS];
-
-/*
- * Don't use virtual irqs 0, 1, 2 for devices.
- * The pcnet32 driver considers interrupt numbers < 2 to be invalid,
- * and 2 is the XICS IPI interrupt.
- * We limit virtual irqs to __irq_offet_value less than virt_irq_max so
- * that when we offset them we don't end up with an interrupt
- * number >= virt_irq_max.
- */
-#define MIN_VIRT_IRQ	3
-
-unsigned int virt_irq_max;
-static unsigned int max_virt_irq;
-static unsigned int nr_virt_irqs;
-
-void
-virt_irq_init(void)
-{
-	int i;
-
-	if ((virt_irq_max == 0) || (virt_irq_max > (NR_IRQS - 1)))
-		virt_irq_max = NR_IRQS - 1;
-	max_virt_irq = virt_irq_max - __irq_offset_value;
-	nr_virt_irqs = max_virt_irq - MIN_VIRT_IRQ + 1;
-
-	for (i = 0; i < NR_IRQS; i++)
-		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
-}
-
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-int virt_irq_create_mapping(unsigned int real_irq)
-{
-	unsigned int virq, first_virq;
-	static int warned;
-
-	if (ppc64_interrupt_controller == IC_OPEN_PIC)
-		return real_irq;	/* no mapping for openpic (for now) */
-
-	if (ppc64_interrupt_controller == IC_CELL_PIC)
-		return real_irq;	/* no mapping for iic either */
-
-	/* don't map interrupts < MIN_VIRT_IRQ */
-	if (real_irq < MIN_VIRT_IRQ) {
-		virt_irq_to_real_map[real_irq] = real_irq;
-		return real_irq;
-	}
-
-	/* map to a number between MIN_VIRT_IRQ and max_virt_irq */
-	virq = real_irq;
-	if (virq > max_virt_irq)
-		virq = (virq % nr_virt_irqs) + MIN_VIRT_IRQ;
-
-	/* search for this number or a free slot */
-	first_virq = virq;
-	while (virt_irq_to_real_map[virq] != UNDEFINED_IRQ) {
-		if (virt_irq_to_real_map[virq] == real_irq)
-			return virq;
-		if (++virq > max_virt_irq)
-			virq = MIN_VIRT_IRQ;
-		if (virq == first_virq)
-			goto nospace;	/* oops, no free slots */
-	}
-
-	virt_irq_to_real_map[virq] = real_irq;
-	return virq;
-
- nospace:
-	if (!warned) {
-		printk(KERN_CRIT "Interrupt table is full\n");
-		printk(KERN_CRIT "Increase virt_irq_max (currently %d) "
-		       "in your kernel sources and rebuild.\n", virt_irq_max);
-		warned = 1;
-	}
-	return NO_IRQ;
-}
-
-/*
- * In most cases will get a hit on the very first slot checked in the
- * virt_irq_to_real_map.  Only when there are a large number of
- * IRQs will this be expensive.
- */
-unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
-{
-	unsigned int virq;
-	unsigned int first_virq;
-
-	virq = real_irq;
-
-	if (virq > max_virt_irq)
-		virq = (virq % nr_virt_irqs) + MIN_VIRT_IRQ;
-
-	first_virq = virq;
-
-	do {
-		if (virt_irq_to_real_map[virq] == real_irq)
-			return virq;
-
-		virq++;
-
-		if (virq >= max_virt_irq)
-			virq = 0;
-
-	} while (first_virq != virq);
-
-	return NO_IRQ;
-
-}
-#endif /* CONFIG_PPC64 */
 
 #ifdef CONFIG_IRQSTACKS
 struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;
@@ -430,6 +318,503 @@ void do_softirq(void)
 }
 EXPORT_SYMBOL(do_softirq);
 
+
+/*
+ * IRQ controller and virtual interrupts
+ */
+
+#ifdef CONFIG_PPC_MERGE
+
+static LIST_HEAD(irq_hosts);
+static spinlock_t irq_big_lock = SPIN_LOCK_UNLOCKED;
+
+struct irq_map_entry irq_map[NR_IRQS];
+static unsigned int irq_virq_count = NR_IRQS;
+static struct irq_host *irq_default_host;
+
+struct irq_host *irq_alloc_host(unsigned int revmap_type,
+				unsigned int revmap_arg,
+				struct irq_host_ops *ops,
+				irq_hw_number_t inval_irq)
+{
+	struct irq_host *host;
+	unsigned int size = sizeof(struct irq_host);
+	unsigned int i;
+	unsigned int *rmap;
+	unsigned long flags;
+
+	/* Allocate structure and revmap table if using linear mapping */
+	if (revmap_type == IRQ_HOST_MAP_LINEAR)
+		size += revmap_arg * sizeof(unsigned int);
+	if (mem_init_done)
+		host = kzalloc(size, GFP_KERNEL);
+	else {
+		host = alloc_bootmem(size);
+		if (host)
+			memset(host, 0, size);
+	}
+	if (host == NULL)
+		return NULL;
+
+	/* Fill structure */
+	host->revmap_type = revmap_type;
+	host->inval_irq = inval_irq;
+	host->ops = ops;
+
+	spin_lock_irqsave(&irq_big_lock, flags);
+
+	/* If it's a legacy controller, check for duplicates and
+	 * mark it as allocated (we use irq 0 host pointer for that
+	 */
+	if (revmap_type == IRQ_HOST_MAP_LEGACY) {
+		if (irq_map[0].host != NULL) {
+			spin_unlock_irqrestore(&irq_big_lock, flags);
+			/* If we are early boot, we can't free the structure,
+			 * too bad...
+			 * this will be fixed once slab is made available early
+			 * instead of the current cruft
+			 */
+			if (mem_init_done)
+				kfree(host);
+			return NULL;
+		}
+		irq_map[0].host = host;
+	}
+
+	list_add(&host->link, &irq_hosts);
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+
+	/* Additional setups per revmap type */
+	switch(revmap_type) {
+	case IRQ_HOST_MAP_LEGACY:
+		/* 0 is always the invalid number for legacy */
+		host->inval_irq = 0;
+		/* setup us as the host for all legacy interrupts */
+		for (i = 1; i < NUM_ISA_INTERRUPTS; i++) {
+			irq_map[i].hwirq = 0;
+			smp_wmb();
+			irq_map[i].host = host;
+			smp_wmb();
+
+			/* Clear some flags */
+			get_irq_desc(i)->status
+				&= ~(IRQ_NOREQUEST | IRQ_LEVEL);
+
+			/* Legacy flags are left to default at this point,
+			 * one can then use irq_create_mapping() to
+			 * explicitely change them
+			 */
+			ops->map(host, i, i, 0);
+		}
+		break;
+	case IRQ_HOST_MAP_LINEAR:
+		rmap = (unsigned int *)(host + 1);
+		for (i = 0; i < revmap_arg; i++)
+			rmap[i] = IRQ_NONE;
+		host->revmap_data.linear.size = revmap_arg;
+		smp_wmb();
+		host->revmap_data.linear.revmap = rmap;
+		break;
+	default:
+		break;
+	}
+
+	pr_debug("irq: Allocated host of type %d @0x%p\n", revmap_type, host);
+
+	return host;
+}
+
+struct irq_host *irq_find_host(struct device_node *node)
+{
+	struct irq_host *h, *found = NULL;
+	unsigned long flags;
+
+	/* We might want to match the legacy controller last since
+	 * it might potentially be set to match all interrupts in
+	 * the absence of a device node. This isn't a problem so far
+	 * yet though...
+	 */
+	spin_lock_irqsave(&irq_big_lock, flags);
+	list_for_each_entry(h, &irq_hosts, link)
+		if (h->ops->match == NULL || h->ops->match(h, node)) {
+			found = h;
+			break;
+		}
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+	return found;
+}
+EXPORT_SYMBOL_GPL(irq_find_host);
+
+void irq_set_default_host(struct irq_host *host)
+{
+	pr_debug("irq: Default host set to @0x%p\n", host);
+
+	irq_default_host = host;
+}
+
+void irq_set_virq_count(unsigned int count)
+{
+	pr_debug("irq: Trying to set virq count to %d\n", count);
+
+	BUG_ON(count < NUM_ISA_INTERRUPTS);
+	if (count < NR_IRQS)
+		irq_virq_count = count;
+}
+
+unsigned int irq_create_mapping(struct irq_host *host,
+				irq_hw_number_t hwirq,
+				unsigned int flags)
+{
+	unsigned int virq, hint;
+
+	pr_debug("irq: irq_create_mapping(0x%p, 0x%lx, 0x%x)\n",
+		 host, hwirq, flags);
+
+	/* Look for default host if nececssary */
+	if (host == NULL)
+		host = irq_default_host;
+	if (host == NULL) {
+		printk(KERN_WARNING "irq_create_mapping called for"
+		       " NULL host, hwirq=%lx\n", hwirq);
+		WARN_ON(1);
+		return NO_IRQ;
+	}
+	pr_debug("irq: -> using host @%p\n", host);
+
+	/* Check if mapping already exist, if it does, call
+	 * host->ops->map() to update the flags
+	 */
+	virq = irq_find_mapping(host, hwirq);
+	if (virq != IRQ_NONE) {
+		pr_debug("irq: -> existing mapping on virq %d\n", virq);
+		host->ops->map(host, virq, hwirq, flags);
+		return virq;
+	}
+
+	/* Get a virtual interrupt number */
+	if (host->revmap_type == IRQ_HOST_MAP_LEGACY) {
+		/* Handle legacy */
+		virq = (unsigned int)hwirq;
+		if (virq == 0 || virq >= NUM_ISA_INTERRUPTS)
+			return NO_IRQ;
+		return virq;
+	} else {
+		/* Allocate a virtual interrupt number */
+		hint = hwirq % irq_virq_count;
+		virq = irq_alloc_virt(host, 1, hint);
+		if (virq == NO_IRQ) {
+			pr_debug("irq: -> virq allocation failed\n");
+			return NO_IRQ;
+		}
+	}
+	pr_debug("irq: -> obtained virq %d\n", virq);
+
+	/* Clear some flags */
+	get_irq_desc(virq)->status &= ~(IRQ_NOREQUEST | IRQ_LEVEL);
+
+	/* map it */
+	if (host->ops->map(host, virq, hwirq, flags)) {
+		pr_debug("irq: -> mapping failed, freeing\n");
+		irq_free_virt(virq, 1);
+		return NO_IRQ;
+	}
+	smp_wmb();
+	irq_map[virq].hwirq = hwirq;
+	smp_mb();
+	return virq;
+}
+EXPORT_SYMBOL_GPL(irq_create_mapping);
+
+extern unsigned int irq_create_of_mapping(struct device_node *controller,
+					  u32 *intspec, unsigned int intsize)
+{
+	struct irq_host *host;
+	irq_hw_number_t hwirq;
+	unsigned int flags = IRQ_TYPE_NONE;
+
+	if (controller == NULL)
+		host = irq_default_host;
+	else
+		host = irq_find_host(controller);
+	if (host == NULL)
+		return NO_IRQ;
+
+	/* If host has no translation, then we assume interrupt line */
+	if (host->ops->xlate == NULL)
+		hwirq = intspec[0];
+	else {
+		if (host->ops->xlate(host, controller, intspec, intsize,
+				     &hwirq, &flags))
+			return NO_IRQ;
+	}
+
+	return irq_create_mapping(host, hwirq, flags);
+}
+EXPORT_SYMBOL_GPL(irq_create_of_mapping);
+
+unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+{
+	struct of_irq oirq;
+
+	if (of_irq_map_one(dev, index, &oirq))
+		return NO_IRQ;
+
+	return irq_create_of_mapping(oirq.controller, oirq.specifier,
+				     oirq.size);
+}
+EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
+
+void irq_dispose_mapping(unsigned int virq)
+{
+	struct irq_host *host = irq_map[virq].host;
+	irq_hw_number_t hwirq;
+	unsigned long flags;
+
+	WARN_ON (host == NULL);
+	if (host == NULL)
+		return;
+
+	/* Never unmap legacy interrupts */
+	if (host->revmap_type == IRQ_HOST_MAP_LEGACY)
+		return;
+
+	/* remove chip and handler */
+	set_irq_chip_and_handler(virq, NULL, NULL);
+
+	/* Make sure it's completed */
+	synchronize_irq(virq);
+
+	/* Tell the PIC about it */
+	if (host->ops->unmap)
+		host->ops->unmap(host, virq);
+	smp_mb();
+
+	/* Clear reverse map */
+	hwirq = irq_map[virq].hwirq;
+	switch(host->revmap_type) {
+	case IRQ_HOST_MAP_LINEAR:
+		if (hwirq < host->revmap_data.linear.size)
+			host->revmap_data.linear.revmap[hwirq] = IRQ_NONE;
+		break;
+	case IRQ_HOST_MAP_TREE:
+		/* Check if radix tree allocated yet */
+		if (host->revmap_data.tree.gfp_mask == 0)
+			break;
+		/* XXX radix tree not safe ! remove lock whem it becomes safe
+		 * and use some RCU sync to make sure everything is ok before we
+		 * can re-use that map entry
+		 */
+		spin_lock_irqsave(&irq_big_lock, flags);
+		radix_tree_delete(&host->revmap_data.tree, hwirq);
+		spin_unlock_irqrestore(&irq_big_lock, flags);
+		break;
+	}
+
+	/* Destroy map */
+	smp_mb();
+	irq_map[virq].hwirq = host->inval_irq;
+
+	/* Set some flags */
+	get_irq_desc(virq)->status |= IRQ_NOREQUEST;
+
+	/* Free it */
+	irq_free_virt(virq, 1);
+}
+EXPORT_SYMBOL_GPL(irq_dispose_mapping);
+
+unsigned int irq_find_mapping(struct irq_host *host,
+			      irq_hw_number_t hwirq)
+{
+	unsigned int i;
+	unsigned int hint = hwirq % irq_virq_count;
+
+	/* Look for default host if nececssary */
+	if (host == NULL)
+		host = irq_default_host;
+	if (host == NULL)
+		return NO_IRQ;
+
+	/* legacy -> bail early */
+	if (host->revmap_type == IRQ_HOST_MAP_LEGACY)
+		return hwirq;
+
+	/* Slow path does a linear search of the map */
+	if (hint < NUM_ISA_INTERRUPTS)
+		hint = NUM_ISA_INTERRUPTS;
+	i = hint;
+	do  {
+		if (irq_map[i].host == host &&
+		    irq_map[i].hwirq == hwirq)
+			return i;
+		i++;
+		if (i >= irq_virq_count)
+			i = NUM_ISA_INTERRUPTS;
+	} while(i != hint);
+	return NO_IRQ;
+}
+EXPORT_SYMBOL_GPL(irq_find_mapping);
+
+
+unsigned int irq_radix_revmap(struct irq_host *host,
+			      irq_hw_number_t hwirq)
+{
+	struct radix_tree_root *tree;
+	struct irq_map_entry *ptr;
+	unsigned int virq;
+	unsigned long flags;
+
+	WARN_ON(host->revmap_type != IRQ_HOST_MAP_TREE);
+
+	/* Check if the radix tree exist yet. We test the value of
+	 * the gfp_mask for that. Sneaky but saves another int in the
+	 * structure. If not, we fallback to slow mode
+	 */
+	tree = &host->revmap_data.tree;
+	if (tree->gfp_mask == 0)
+		return irq_find_mapping(host, hwirq);
+
+	/* XXX Current radix trees are NOT SMP safe !!! Remove that lock
+	 * when that is fixed (when Nick's patch gets in
+	 */
+	spin_lock_irqsave(&irq_big_lock, flags);
+
+	/* Now try to resolve */
+	ptr = radix_tree_lookup(tree, hwirq);
+	/* Found it, return */
+	if (ptr) {
+		virq = ptr - irq_map;
+		goto bail;
+	}
+
+	/* If not there, try to insert it */
+	virq = irq_find_mapping(host, hwirq);
+	if (virq != NO_IRQ)
+		radix_tree_insert(tree, virq, &irq_map[virq]);
+ bail:
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+	return virq;
+}
+
+unsigned int irq_linear_revmap(struct irq_host *host,
+			       irq_hw_number_t hwirq)
+{
+	unsigned int *revmap;
+
+	WARN_ON(host->revmap_type != IRQ_HOST_MAP_LINEAR);
+
+	/* Check revmap bounds */
+	if (unlikely(hwirq >= host->revmap_data.linear.size))
+		return irq_find_mapping(host, hwirq);
+
+	/* Check if revmap was allocated */
+	revmap = host->revmap_data.linear.revmap;
+	if (unlikely(revmap == NULL))
+		return irq_find_mapping(host, hwirq);
+
+	/* Fill up revmap with slow path if no mapping found */
+	if (unlikely(revmap[hwirq] == NO_IRQ))
+		revmap[hwirq] = irq_find_mapping(host, hwirq);
+
+	return revmap[hwirq];
+}
+
+unsigned int irq_alloc_virt(struct irq_host *host,
+			    unsigned int count,
+			    unsigned int hint)
+{
+	unsigned long flags;
+	unsigned int i, j, found = NO_IRQ;
+	unsigned int limit = irq_virq_count - count;
+
+	if (count == 0 || count > (irq_virq_count - NUM_ISA_INTERRUPTS))
+		return NO_IRQ;
+
+	spin_lock_irqsave(&irq_big_lock, flags);
+
+	/* Use hint for 1 interrupt if any */
+	if (count == 1 && hint >= NUM_ISA_INTERRUPTS &&
+	    hint < irq_virq_count && irq_map[hint].host == NULL) {
+		found = hint;
+		goto hint_found;
+	}
+
+	/* Look for count consecutive numbers in the allocatable
+	 * (non-legacy) space
+	 */
+	for (i = NUM_ISA_INTERRUPTS; i <= limit; ) {
+		for (j = i; j < (i + count); j++)
+			if (irq_map[j].host != NULL) {
+				i = j + 1;
+				continue;
+			}
+		found = i;
+		break;
+	}
+	if (found == NO_IRQ) {
+		spin_unlock_irqrestore(&irq_big_lock, flags);
+		return NO_IRQ;
+	}
+ hint_found:
+	for (i = found; i < (found + count); i++) {
+		irq_map[i].hwirq = host->inval_irq;
+		smp_wmb();
+		irq_map[i].host = host;
+	}
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+	return found;
+}
+
+void irq_free_virt(unsigned int virq, unsigned int count)
+{
+	unsigned long flags;
+	unsigned int i;
+
+	WARN_ON (virq < NUM_ISA_INTERRUPTS);
+	WARN_ON (count == 0 || (virq + count) > irq_virq_count);
+
+	spin_lock_irqsave(&irq_big_lock, flags);
+	for (i = virq; i < (virq + count); i++) {
+		struct irq_host *host;
+
+		if (i < NUM_ISA_INTERRUPTS ||
+		    (virq + count) > irq_virq_count)
+			continue;
+
+		host = irq_map[i].host;
+		irq_map[i].hwirq = host->inval_irq;
+		smp_wmb();
+		irq_map[i].host = NULL;
+	}
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+}
+
+void irq_early_init(void)
+{
+	unsigned int i;
+
+	for (i = 0; i < NR_IRQS; i++)
+		get_irq_desc(i)->status |= IRQ_NOREQUEST;
+}
+
+/* We need to create the radix trees late */
+static int irq_late_init(void)
+{
+	struct irq_host *h;
+	unsigned long flags;
+
+	spin_lock_irqsave(&irq_big_lock, flags);
+	list_for_each_entry(h, &irq_hosts, link) {
+		if (h->revmap_type == IRQ_HOST_MAP_TREE)
+			INIT_RADIX_TREE(&h->revmap_data.tree, GFP_ATOMIC);
+	}
+	spin_unlock_irqrestore(&irq_big_lock, flags);
+
+	return 0;
+}
+arch_initcall(irq_late_init);
+
+#endif /* CONFIG_PPC_MERGE */
+
 #ifdef CONFIG_PCI_MSI
 int pci_enable_msi(struct pci_dev * pdev)
 {

commit b9e5b4e6a991a5a6d521f2e20a65835404b4169f
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jul 3 19:32:51 2006 +1000

    [POWERPC] Use the genirq framework
    
    This adapts the generic powerpc interrupt handling code, and all of
    the platforms except for the embedded 6xx machines, to use the new
    genirq framework.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 525baab45d2d..91248559099a 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -62,28 +62,27 @@
 #endif
 
 int __irq_offset_value;
-#ifdef CONFIG_PPC32
-EXPORT_SYMBOL(__irq_offset_value);
-#endif
-
 static int ppc_spurious_interrupts;
 
 #ifdef CONFIG_PPC32
-#define NR_MASK_WORDS	((NR_IRQS + 31) / 32)
+EXPORT_SYMBOL(__irq_offset_value);
+atomic_t ppc_n_lost_interrupts;
 
+#ifndef CONFIG_PPC_MERGE
+#define NR_MASK_WORDS	((NR_IRQS + 31) / 32)
 unsigned long ppc_cached_irq_mask[NR_MASK_WORDS];
-atomic_t ppc_n_lost_interrupts;
+#endif
 
 #ifdef CONFIG_TAU_INT
 extern int tau_initialized;
 extern int tau_interrupts(int);
 #endif
+#endif /* CONFIG_PPC32 */
 
 #if defined(CONFIG_SMP) && !defined(CONFIG_PPC_MERGE)
 extern atomic_t ipi_recv;
 extern atomic_t ipi_sent;
 #endif
-#endif /* CONFIG_PPC32 */
 
 #ifdef CONFIG_PPC64
 EXPORT_SYMBOL(irq_desc);
@@ -219,15 +218,19 @@ void do_IRQ(struct pt_regs *regs)
 		curtp = current_thread_info();
 		irqtp = hardirq_ctx[smp_processor_id()];
 		if (curtp != irqtp) {
+			struct irq_desc *desc = irq_desc + irq;
+			void *handler = desc->handle_irq;
+			if (handler == NULL)
+				handler = &__do_IRQ;
 			irqtp->task = curtp->task;
 			irqtp->flags = 0;
-			call___do_IRQ(irq, regs, irqtp);
+			call_handle_irq(irq, desc, regs, irqtp, handler);
 			irqtp->task = NULL;
 			if (irqtp->flags)
 				set_bits(irqtp->flags, &curtp->flags);
 		} else
 #endif
-			__do_IRQ(irq, regs);
+			generic_handle_irq(irq, regs);
 	} else if (irq != -2)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
@@ -245,15 +248,6 @@ void do_IRQ(struct pt_regs *regs)
 
 void __init init_IRQ(void)
 {
-#ifdef CONFIG_PPC64
-	static int once = 0;
-
-	if (once)
-		return;
-
-	once++;
-
-#endif
 	ppc_md.init_IRQ();
 #ifdef CONFIG_PPC64
 	irq_ctx_init();

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 24f6050aa4ab..525baab45d2d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -38,7 +38,6 @@
 #include <linux/ioport.h>
 #include <linux/interrupt.h>
 #include <linux/timex.h>
-#include <linux/config.h>
 #include <linux/init.h>
 #include <linux/slab.h>
 #include <linux/delay.h>

commit a53da52fd743fd637637572838c0a7af23a2d038
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:38 2006 -0700

    [PATCH] genirq: cleanup: merge irq_affinity[] into irq_desc[]
    
    Consolidation: remove the irq_affinity[NR_IRQS] array and move it into the
    irq_desc[NR_IRQS].affinity field.
    
    [akpm@osdl.org: sparc64 build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 8cfc779d882d..24f6050aa4ab 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -164,7 +164,7 @@ void fixup_irqs(cpumask_t map)
 		if (irq_desc[irq].status & IRQ_PER_CPU)
 			continue;
 
-		cpus_and(mask, irq_affinity[irq], map);
+		cpus_and(mask, irq_desc[irq].affinity, map);
 		if (any_online_cpu(mask) == NR_CPUS) {
 			printk("Breaking affinity for irq %i\n", irq);
 			mask = map;

commit d1bef4ed5faf7d9872337b33c4269e45ae1bf960
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:36 2006 -0700

    [PATCH] genirq: rename desc->handler to desc->chip
    
    This patch-queue improves the generic IRQ layer to be truly generic, by adding
    various abstractions and features to it, without impacting existing
    functionality.
    
    While the queue can be best described as "fix and improve everything in the
    generic IRQ layer that we could think of", and thus it consists of many
    smaller features and lots of cleanups, the one feature that stands out most is
    the new 'irq chip' abstraction.
    
    The irq-chip abstraction is about describing and coding and IRQ controller
    driver by mapping its raw hardware capabilities [and quirks, if needed] in a
    straightforward way, without having to think about "IRQ flow"
    (level/edge/etc.) type of details.
    
    This stands in contrast with the current 'irq-type' model of genirq
    architectures, which 'mixes' raw hardware capabilities with 'flow' details.
    The patchset supports both types of irq controller designs at once, and
    converts i386 and x86_64 to the new irq-chip design.
    
    As a bonus side-effect of the irq-chip approach, chained interrupt controllers
    (master/slave PIC constructs, etc.) are now supported by design as well.
    
    The end result of this patchset intends to be simpler architecture-level code
    and more consolidation between architectures.
    
    We reused many bits of code and many concepts from Russell King's ARM IRQ
    layer, the merging of which was one of the motivations for this patchset.
    
    This patch:
    
    rename desc->handler to desc->chip.
    
    Originally i did not want to do this, because it's a big patch.  But having
    both "desc->handler", "desc->handle_irq" and "action->handler" caused a
    large degree of confusion and made the code appear alot less clean than it
    truly is.
    
    I have also attempted a dual approach as well by introducing a
    desc->chip alias - but that just wasnt robust enough and broke
    frequently.
    
    So lets get over with this quickly.  The conversion was done automatically
    via scripts and converts all the code in the kernel.
    
    This renaming patch is the first one amongst the patches, so that the
    remaining patches can stay flexible and can be merged and split up
    without having some big monolithic patch act as a merge barrier.
    
    [akpm@osdl.org: build fix]
    [akpm@osdl.org: another build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 40d4c14fde8f..8cfc779d882d 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -120,8 +120,8 @@ int show_interrupts(struct seq_file *p, void *v)
 #else
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */
-		if (desc->handler)
-			seq_printf(p, " %s ", desc->handler->typename);
+		if (desc->chip)
+			seq_printf(p, " %s ", desc->chip->typename);
 		else
 			seq_puts(p, "  None      ");
 		seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
@@ -169,8 +169,8 @@ void fixup_irqs(cpumask_t map)
 			printk("Breaking affinity for irq %i\n", irq);
 			mask = map;
 		}
-		if (irq_desc[irq].handler->set_affinity)
-			irq_desc[irq].handler->set_affinity(irq, mask);
+		if (irq_desc[irq].chip->set_affinity)
+			irq_desc[irq].chip->set_affinity(irq, mask);
 		else if (irq_desc[irq].action && !(warned++))
 			printk("Cannot set affinity for irq %i\n", irq);
 	}

commit 22722051fb6bcbb95c895e68dad10d34a9db7e4d
Author: Andreas Mohr <andi@rhlx01.fht-esslingen.de>
Date:   Fri Jun 23 02:05:30 2006 -0700

    [PATCH] x86/powerpc make hardirq_ctx and softirq_ctx __read_mostly
    
    The hardirq_ctx and softirq_ctx variables are written to on init only,
    
    Signed-off-by: Andreas Mohr <andi@lisas.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index bfcec4cc70a7..40d4c14fde8f 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -380,8 +380,8 @@ unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
 #endif /* CONFIG_PPC64 */
 
 #ifdef CONFIG_IRQSTACKS
-struct thread_info *softirq_ctx[NR_CPUS];
-struct thread_info *hardirq_ctx[NR_CPUS];
+struct thread_info *softirq_ctx[NR_CPUS] __read_mostly;
+struct thread_info *hardirq_ctx[NR_CPUS] __read_mostly;
 
 void irq_ctx_init(void)
 {

commit 204face4fb3ba2ca09a4073e7debc595e14c2388
Author: Jake Moilanen <moilanen@austin.ibm.com>
Date:   Wed Jun 7 16:15:10 2006 -0500

    [POWERPC] MSI abstraction
    
    Instead of trying to make PPC64 MSI fit in a Intel-centric MSI layer, a
    simple short-term solution is to hook the pci_{en/dis}able_msi() calls
    and make a machdep call.
    
    The rest of the MSI functions are superfluous for what is needed at this
    time.  Many of which can have machdep calls added as needed.
    
    Ben and Michael Ellerman are looking into rewrite the MSI layer to be
    more generic.  However, in the meantime this works as a interim
    solution.
    
    Signed-off-by: Jake Moilanen <moilanen@austin.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 57d560c68897..bfcec4cc70a7 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -47,6 +47,7 @@
 #include <linux/cpumask.h>
 #include <linux/profile.h>
 #include <linux/bitops.h>
+#include <linux/pci.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -436,6 +437,30 @@ void do_softirq(void)
 }
 EXPORT_SYMBOL(do_softirq);
 
+#ifdef CONFIG_PCI_MSI
+int pci_enable_msi(struct pci_dev * pdev)
+{
+	if (ppc_md.enable_msi)
+		return ppc_md.enable_msi(pdev);
+	else
+		return -1;
+}
+
+void pci_disable_msi(struct pci_dev * pdev)
+{
+	if (ppc_md.disable_msi)
+		ppc_md.disable_msi(pdev);
+}
+
+void pci_scan_msi_device(struct pci_dev *dev) {}
+int pci_enable_msix(struct pci_dev* dev, struct msix_entry *entries, int nvec) {return -1;}
+void pci_disable_msix(struct pci_dev *dev) {}
+void msi_remove_pci_irq_vectors(struct pci_dev *dev) {}
+void disable_msi_mode(struct pci_dev *dev, int pos, int type) {}
+void pci_no_msi(void) {}
+
+#endif
+
 #ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {

commit 7d01c880856bae31502095bc68784c1518a680cb
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Apr 4 14:49:48 2006 +1000

    powerpc: iSeries has only 256 IRQs
    
    The iSeries Hypervisor only allows us to specify IRQ numbers up to 255 (it
    has a u8 field to pass it in).  This patch allows platforms to specify a
    maximum to the virtual IRQ numbers we will use and has iSeries set that
    to 255.  If not set, the maximum is NR_IRQS - 1 (as before).
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index bb5c9501234c..57d560c68897 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -272,18 +272,26 @@ unsigned int virt_irq_to_real_map[NR_IRQS];
  * Don't use virtual irqs 0, 1, 2 for devices.
  * The pcnet32 driver considers interrupt numbers < 2 to be invalid,
  * and 2 is the XICS IPI interrupt.
- * We limit virtual irqs to 17 less than NR_IRQS so that when we
- * offset them by 16 (to reserve the first 16 for ISA interrupts)
- * we don't end up with an interrupt number >= NR_IRQS.
+ * We limit virtual irqs to __irq_offet_value less than virt_irq_max so
+ * that when we offset them we don't end up with an interrupt
+ * number >= virt_irq_max.
  */
 #define MIN_VIRT_IRQ	3
-#define MAX_VIRT_IRQ	(NR_IRQS - NUM_ISA_INTERRUPTS - 1)
-#define NR_VIRT_IRQS	(MAX_VIRT_IRQ - MIN_VIRT_IRQ + 1)
+
+unsigned int virt_irq_max;
+static unsigned int max_virt_irq;
+static unsigned int nr_virt_irqs;
 
 void
 virt_irq_init(void)
 {
 	int i;
+
+	if ((virt_irq_max == 0) || (virt_irq_max > (NR_IRQS - 1)))
+		virt_irq_max = NR_IRQS - 1;
+	max_virt_irq = virt_irq_max - __irq_offset_value;
+	nr_virt_irqs = max_virt_irq - MIN_VIRT_IRQ + 1;
+
 	for (i = 0; i < NR_IRQS; i++)
 		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
 }
@@ -308,17 +316,17 @@ int virt_irq_create_mapping(unsigned int real_irq)
 		return real_irq;
 	}
 
-	/* map to a number between MIN_VIRT_IRQ and MAX_VIRT_IRQ */
+	/* map to a number between MIN_VIRT_IRQ and max_virt_irq */
 	virq = real_irq;
-	if (virq > MAX_VIRT_IRQ)
-		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+	if (virq > max_virt_irq)
+		virq = (virq % nr_virt_irqs) + MIN_VIRT_IRQ;
 
 	/* search for this number or a free slot */
 	first_virq = virq;
 	while (virt_irq_to_real_map[virq] != UNDEFINED_IRQ) {
 		if (virt_irq_to_real_map[virq] == real_irq)
 			return virq;
-		if (++virq > MAX_VIRT_IRQ)
+		if (++virq > max_virt_irq)
 			virq = MIN_VIRT_IRQ;
 		if (virq == first_virq)
 			goto nospace;	/* oops, no free slots */
@@ -330,8 +338,8 @@ int virt_irq_create_mapping(unsigned int real_irq)
  nospace:
 	if (!warned) {
 		printk(KERN_CRIT "Interrupt table is full\n");
-		printk(KERN_CRIT "Increase NR_IRQS (currently %d) "
-		       "in your kernel sources and rebuild.\n", NR_IRQS);
+		printk(KERN_CRIT "Increase virt_irq_max (currently %d) "
+		       "in your kernel sources and rebuild.\n", virt_irq_max);
 		warned = 1;
 	}
 	return NO_IRQ;
@@ -349,8 +357,8 @@ unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
 
 	virq = real_irq;
 
-	if (virq > MAX_VIRT_IRQ)
-		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+	if (virq > max_virt_irq)
+		virq = (virq % nr_virt_irqs) + MIN_VIRT_IRQ;
 
 	first_virq = virq;
 
@@ -360,7 +368,7 @@ unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
 
 		virq++;
 
-		if (virq >= MAX_VIRT_IRQ)
+		if (virq >= max_virt_irq)
 			virq = 0;
 
 	} while (first_virq != virq);

commit 0e5519548fdc8eadc3eacb49b1908d44d347fb2b
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Tue Mar 28 14:50:51 2006 -0800

    [PATCH] for_each_possible_cpu: powerpc
    
    for_each_cpu() actually iterates across all possible CPUs.  We've had mistakes
    in the past where people were using for_each_cpu() where they should have been
    iterating across only online or present CPUs.  This is inefficient and
    possibly buggy.
    
    We're renaming for_each_cpu() to for_each_possible_cpu() to avoid this in the
    future.
    
    This patch replaces for_each_cpu with for_each_possible_cpu.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 771a59cbd213..bb5c9501234c 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -379,7 +379,7 @@ void irq_ctx_init(void)
 	struct thread_info *tp;
 	int i;
 
-	for_each_cpu(i) {
+	for_each_possible_cpu(i) {
 		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
 		tp = softirq_ctx[i];
 		tp->cpu = i;

commit 394e3902c55e667945f6f1c2bdbc59842cce70f7
Author: Andrew Morton <akpm@osdl.org>
Date:   Thu Mar 23 03:01:05 2006 -0800

    [PATCH] more for_each_cpu() conversions
    
    When we stop allocating percpu memory for not-possible CPUs we must not touch
    the percpu data for not-possible CPUs at all.  The correct way of doing this
    is to test cpu_possible() or to use for_each_cpu().
    
    This patch is a kernel-wide sweep of all instances of NR_CPUS.  I found very
    few instances of this bug, if any.  But the patch converts lots of open-coded
    test to use the preferred helper macros.
    
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Acked-by: Kyle McMartin <kyle@parisc-linux.org>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Christian Zankel <chris@zankel.net>
    Cc: Philippe Elie <phil.el@wanadoo.fr>
    Cc: Nathan Scott <nathans@sgi.com>
    Cc: Jens Axboe <axboe@suse.de>
    Cc: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 24dc8117b822..771a59cbd213 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -135,9 +135,8 @@ int show_interrupts(struct seq_file *p, void *v)
 #ifdef CONFIG_TAU_INT
 		if (tau_initialized){
 			seq_puts(p, "TAU: ");
-			for (j = 0; j < NR_CPUS; j++)
-				if (cpu_online(j))
-					seq_printf(p, "%10u ", tau_interrupts(j));
+			for_each_online_cpu(j)
+				seq_printf(p, "%10u ", tau_interrupts(j));
 			seq_puts(p, "  PowerPC             Thermal Assist (cpu temp)\n");
 		}
 #endif

commit c6622f63db86fcbd41bf6fe05ddf2e00c1e51ced
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Feb 24 10:06:59 2006 +1100

    powerpc: Implement accurate task and CPU time accounting
    
    This implements accurate task and cpu time accounting for 64-bit
    powerpc kernels.  Instead of accounting a whole jiffy of time to a
    task on a timer interrupt because that task happened to be running at
    the time, we now account time in units of timebase ticks according to
    the actual time spent by the task in user mode and kernel mode.  We
    also count the time spent processing hardware and software interrupts
    accurately.  This is conditional on CONFIG_VIRT_CPU_ACCOUNTING.  If
    that is not set, we do tick-based approximate accounting as before.
    
    To get this accurate information, we read either the PURR (processor
    utilization of resources register) on POWER5 machines, or the timebase
    on other machines on
    
    * each entry to the kernel from usermode
    * each exit to usermode
    * transitions between process context, hard irq context and soft irq
      context in kernel mode
    * context switches.
    
    On POWER5 systems with shared-processor logical partitioning we also
    read both the PURR and the timebase at each timer interrupt and
    context switch in order to determine how much time has been taken by
    the hypervisor to run other partitions ("steal" time).  Unfortunately,
    since we need values of the PURR on both threads at the same time to
    accurately calculate the steal time, and since we can only calculate
    steal time on a per-core basis, the apportioning of the steal time
    between idle time (time which we ceded to the hypervisor in the idle
    loop) and actual stolen time is somewhat approximate at the moment.
    
    This is all based quite heavily on what s390 does, and it uses the
    generic interfaces that were added by the s390 developers,
    i.e. account_system_time(), account_user_time(), etc.
    
    This patch doesn't add any new interfaces between the kernel and
    userspace, and doesn't change the units in which time is reported to
    userspace by things such as /proc/stat, /proc/<pid>/stat, getrusage(),
    times(), etc.  Internally the various task and cpu times are stored in
    timebase units, but they are converted to USER_HZ units (1/100th of a
    second) when reported to userspace.  Some precision is therefore lost
    but there should not be any accumulating error, since the internal
    accumulation is at full precision.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index edb2b00edbd2..24dc8117b822 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -369,6 +369,7 @@ unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
 	return NO_IRQ;
 
 }
+#endif /* CONFIG_PPC64 */
 
 #ifdef CONFIG_IRQSTACKS
 struct thread_info *softirq_ctx[NR_CPUS];
@@ -392,10 +393,24 @@ void irq_ctx_init(void)
 	}
 }
 
+static inline void do_softirq_onstack(void)
+{
+	struct thread_info *curtp, *irqtp;
+
+	curtp = current_thread_info();
+	irqtp = softirq_ctx[smp_processor_id()];
+	irqtp->task = curtp->task;
+	call_do_softirq(irqtp);
+	irqtp->task = NULL;
+}
+
+#else
+#define do_softirq_onstack()	__do_softirq()
+#endif /* CONFIG_IRQSTACKS */
+
 void do_softirq(void)
 {
 	unsigned long flags;
-	struct thread_info *curtp, *irqtp;
 
 	if (in_interrupt())
 		return;
@@ -403,19 +418,18 @@ void do_softirq(void)
 	local_irq_save(flags);
 
 	if (local_softirq_pending()) {
-		curtp = current_thread_info();
-		irqtp = softirq_ctx[smp_processor_id()];
-		irqtp->task = curtp->task;
-		call_do_softirq(irqtp);
-		irqtp->task = NULL;
+		account_system_vtime(current);
+		local_bh_disable();
+		do_softirq_onstack();
+		account_system_vtime(current);
+		__local_bh_enable();
 	}
 
 	local_irq_restore(flags);
 }
 EXPORT_SYMBOL(do_softirq);
 
-#endif /* CONFIG_IRQSTACKS */
-
+#ifdef CONFIG_PPC64
 static int __init setup_noirqdistrib(char *str)
 {
 	distribute_irqs = 0;

commit 2ef9481e666b4654159ac9f847e6963809e3c470
Author: Jon Mason <jdmason@us.ibm.com>
Date:   Mon Jan 23 10:58:20 2006 -0600

    [PATCH] powerpc: trivial: modify comments to refer to new location of files
    
    This patch removes all self references and fixes references to files
    in the now defunct arch/ppc64 tree.  I think this accomplises
    everything wanted, though there might be a few references I missed.
    
    Signed-off-by: Jon Mason <jdmason@us.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index d1fffce86df9..edb2b00edbd2 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -1,6 +1,4 @@
 /*
- *  arch/ppc/kernel/irq.c
- *
  *  Derived from arch/i386/kernel/irq.c
  *    Copyright (C) 1992 Linus Torvalds
  *  Adapted from arch/i386 by Gary Thomas

commit 3356bb9f7ba378a6e2709f9df95f4ea52111f4df
Author: David Gibson <david@gibson.dropbear.id.au>
Date:   Fri Jan 13 10:26:42 2006 +1100

    [PATCH] powerpc: Remove lppaca structure from the PACA
    
    At present the lppaca - the structure shared with the iSeries
    hypervisor and phyp - is contained within the PACA, our own low-level
    per-cpu structure.  This doesn't have to be so, the patch below
    removes it, making a separate array of lppaca structures.
    
    This saves approximately 500*NR_CPUS bytes of image size and kernel
    memory, because we don't need aligning gap between the Linux and
    hypervisor portions of every PACA.  On the other hand it means an
    extra level of dereference in many accesses to the lppaca.
    
    The patch also gets rid of several places where we assign the paca
    address to a local variable for no particular reason.
    
    Signed-off-by: David Gibson <dwg@au1.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5651032d8706..d1fffce86df9 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -238,14 +238,10 @@ void do_IRQ(struct pt_regs *regs)
         irq_exit();
 
 #ifdef CONFIG_PPC_ISERIES
-	{
-		struct paca_struct *lpaca = get_paca();
-
-		if (lpaca->lppaca.int_dword.fields.decr_int) {
-			lpaca->lppaca.int_dword.fields.decr_int = 0;
-			/* Signal a fake decrementer interrupt */
-			timer_interrupt(regs);
-		}
+	if (get_lppaca()->int_dword.fields.decr_int) {
+		get_lppaca()->int_dword.fields.decr_int = 0;
+		/* Signal a fake decrementer interrupt */
+		timer_interrupt(regs);
 	}
 #endif
 }

commit a50b56d24c59db33792b421af4016a9c958a906f
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Nov 17 16:14:17 2005 +1100

    powerpc: reduce include in irq.c
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 9540c454ff02..5651032d8706 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -31,7 +31,6 @@
  * to reduce code space and undefined function references.
  */
 
-#include <linux/errno.h>
 #include <linux/module.h>
 #include <linux/threads.h>
 #include <linux/kernel_stat.h>
@@ -44,18 +43,12 @@
 #include <linux/config.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/pci.h>
 #include <linux/delay.h>
 #include <linux/irq.h>
-#include <linux/proc_fs.h>
-#include <linux/random.h>
 #include <linux/seq_file.h>
 #include <linux/cpumask.h>
 #include <linux/profile.h>
 #include <linux/bitops.h>
-#ifdef CONFIG_PPC64
-#include <linux/kallsyms.h>
-#endif
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -66,8 +59,7 @@
 #include <asm/prom.h>
 #include <asm/ptrace.h>
 #include <asm/machdep.h>
-#ifdef CONFIG_PPC64
-#include <asm/iseries/it_lp_queue.h>
+#ifdef CONFIG_PPC_ISERIES
 #include <asm/paca.h>
 #endif
 

commit e199500c6280aadf98c185db99fd24ab61ebe0c7
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Nov 16 18:53:29 2005 +1100

    powerpc: partly merge iseries do_IRQ
    
    Hide some of the iseries details in iSeries_get_irq.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5a71ed9612fe..9540c454ff02 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -78,10 +78,6 @@ EXPORT_SYMBOL(__irq_offset_value);
 
 static int ppc_spurious_interrupts;
 
-#if defined(CONFIG_PPC_ISERIES) && defined(CONFIG_SMP)
-extern void iSeries_smp_message_recv(struct pt_regs *);
-#endif
-
 #ifdef CONFIG_PPC32
 #define NR_MASK_WORDS	((NR_IRQS + 31) / 32)
 
@@ -195,49 +191,6 @@ void fixup_irqs(cpumask_t map)
 }
 #endif
 
-#ifdef CONFIG_PPC_ISERIES
-void do_IRQ(struct pt_regs *regs)
-{
-	struct paca_struct *lpaca;
-
-	irq_enter();
-
-#ifdef CONFIG_DEBUG_STACKOVERFLOW
-	/* Debugging check for stack overflow: is there less than 2KB free? */
-	{
-		long sp;
-
-		sp = __get_SP() & (THREAD_SIZE-1);
-
-		if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
-			printk("do_IRQ: stack overflow: %ld\n",
-				sp - sizeof(struct thread_info));
-			dump_stack();
-		}
-	}
-#endif
-
-	lpaca = get_paca();
-#ifdef CONFIG_SMP
-	if (lpaca->lppaca.int_dword.fields.ipi_cnt) {
-		lpaca->lppaca.int_dword.fields.ipi_cnt = 0;
-		iSeries_smp_message_recv(regs);
-	}
-#endif /* CONFIG_SMP */
-	if (hvlpevent_is_pending())
-		process_hvlpevents(regs);
-
-	irq_exit();
-
-	if (lpaca->lppaca.int_dword.fields.decr_int) {
-		lpaca->lppaca.int_dword.fields.decr_int = 0;
-		/* Signal a fake decrementer interrupt */
-		timer_interrupt(regs);
-	}
-}
-
-#else	/* CONFIG_PPC_ISERIES */
-
 void do_IRQ(struct pt_regs *regs)
 {
 	int irq;
@@ -286,16 +239,24 @@ void do_IRQ(struct pt_regs *regs)
 		} else
 #endif
 			__do_IRQ(irq, regs);
-	} else
-#ifdef CONFIG_PPC32
-		if (irq != -2)
-#endif
-			/* That's not SMP safe ... but who cares ? */
-			ppc_spurious_interrupts++;
+	} else if (irq != -2)
+		/* That's not SMP safe ... but who cares ? */
+		ppc_spurious_interrupts++;
+
         irq_exit();
-}
 
-#endif	/* CONFIG_PPC_ISERIES */
+#ifdef CONFIG_PPC_ISERIES
+	{
+		struct paca_struct *lpaca = get_paca();
+
+		if (lpaca->lppaca.int_dword.fields.decr_int) {
+			lpaca->lppaca.int_dword.fields.decr_int = 0;
+			/* Signal a fake decrementer interrupt */
+			timer_interrupt(regs);
+		}
+	}
+#endif
+}
 
 void __init init_IRQ(void)
 {

commit 868accb7b9126dffdebb6b45631e145991e3535d
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Nov 10 18:38:46 2005 +1100

    powerpc: have only one definition of __irq_offset_value
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 5e5ed4441c69..5a71ed9612fe 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -71,6 +71,11 @@
 #include <asm/paca.h>
 #endif
 
+int __irq_offset_value;
+#ifdef CONFIG_PPC32
+EXPORT_SYMBOL(__irq_offset_value);
+#endif
+
 static int ppc_spurious_interrupts;
 
 #if defined(CONFIG_PPC_ISERIES) && defined(CONFIG_SMP)
@@ -98,7 +103,6 @@ extern atomic_t ipi_sent;
 EXPORT_SYMBOL(irq_desc);
 
 int distribute_irqs = 1;
-int __irq_offset_value;
 u64 ppc64_interrupt_controller;
 #endif /* CONFIG_PPC64 */
 

commit d9ae2bad5c92cd116e3daedf16f79cf597e09ad7
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Nov 10 18:11:19 2005 +1100

    powerpc: make iSeries use generic virtual irq mapping
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index 4b7940693f3d..5e5ed4441c69 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -311,7 +311,6 @@ void __init init_IRQ(void)
 }
 
 #ifdef CONFIG_PPC64
-#ifndef CONFIG_PPC_ISERIES
 /*
  * Virtual IRQ mapping code, used on systems with XICS interrupt controllers.
  */
@@ -420,8 +419,6 @@ unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
 
 }
 
-#endif /* CONFIG_PPC_ISERIES */
-
 #ifdef CONFIG_IRQSTACKS
 struct thread_info *softirq_ctx[NR_CPUS];
 struct thread_info *hardirq_ctx[NR_CPUS];

commit 756e7104fefc82e3ebaa5f1da5ba6659c9c1cae5
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Nov 9 18:07:45 2005 +1100

    powerpc: merge irq.c
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
new file mode 100644
index 000000000000..4b7940693f3d
--- /dev/null
+++ b/arch/powerpc/kernel/irq.c
@@ -0,0 +1,478 @@
+/*
+ *  arch/ppc/kernel/irq.c
+ *
+ *  Derived from arch/i386/kernel/irq.c
+ *    Copyright (C) 1992 Linus Torvalds
+ *  Adapted from arch/i386 by Gary Thomas
+ *    Copyright (C) 1995-1996 Gary Thomas (gdt@linuxppc.org)
+ *  Updated and modified by Cort Dougan <cort@fsmlabs.com>
+ *    Copyright (C) 1996-2001 Cort Dougan
+ *  Adapted for Power Macintosh by Paul Mackerras
+ *    Copyright (C) 1996 Paul Mackerras (paulus@cs.anu.edu.au)
+ *  Amiga/APUS changes by Jesper Skov (jskov@cygnus.co.uk).
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ * This file contains the code used by various IRQ handling routines:
+ * asking for different IRQ's should be done through these routines
+ * instead of just grabbing them. Thus setups with different IRQ numbers
+ * shouldn't result in any weird surprises, and installing new handlers
+ * should be easier.
+ *
+ * The MPC8xx has an interrupt mask in the SIU.  If a bit is set, the
+ * interrupt is _enabled_.  As expected, IRQ0 is bit 0 in the 32-bit
+ * mask register (of which only 16 are defined), hence the weird shifting
+ * and complement of the cached_irq_mask.  I want to be able to stuff
+ * this right into the SIU SMASK register.
+ * Many of the prep/chrp functions are conditional compiled on CONFIG_8xx
+ * to reduce code space and undefined function references.
+ */
+
+#include <linux/errno.h>
+#include <linux/module.h>
+#include <linux/threads.h>
+#include <linux/kernel_stat.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/timex.h>
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <linux/irq.h>
+#include <linux/proc_fs.h>
+#include <linux/random.h>
+#include <linux/seq_file.h>
+#include <linux/cpumask.h>
+#include <linux/profile.h>
+#include <linux/bitops.h>
+#ifdef CONFIG_PPC64
+#include <linux/kallsyms.h>
+#endif
+
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/pgtable.h>
+#include <asm/irq.h>
+#include <asm/cache.h>
+#include <asm/prom.h>
+#include <asm/ptrace.h>
+#include <asm/machdep.h>
+#ifdef CONFIG_PPC64
+#include <asm/iseries/it_lp_queue.h>
+#include <asm/paca.h>
+#endif
+
+static int ppc_spurious_interrupts;
+
+#if defined(CONFIG_PPC_ISERIES) && defined(CONFIG_SMP)
+extern void iSeries_smp_message_recv(struct pt_regs *);
+#endif
+
+#ifdef CONFIG_PPC32
+#define NR_MASK_WORDS	((NR_IRQS + 31) / 32)
+
+unsigned long ppc_cached_irq_mask[NR_MASK_WORDS];
+atomic_t ppc_n_lost_interrupts;
+
+#ifdef CONFIG_TAU_INT
+extern int tau_initialized;
+extern int tau_interrupts(int);
+#endif
+
+#if defined(CONFIG_SMP) && !defined(CONFIG_PPC_MERGE)
+extern atomic_t ipi_recv;
+extern atomic_t ipi_sent;
+#endif
+#endif /* CONFIG_PPC32 */
+
+#ifdef CONFIG_PPC64
+EXPORT_SYMBOL(irq_desc);
+
+int distribute_irqs = 1;
+int __irq_offset_value;
+u64 ppc64_interrupt_controller;
+#endif /* CONFIG_PPC64 */
+
+int show_interrupts(struct seq_file *p, void *v)
+{
+	int i = *(loff_t *)v, j;
+	struct irqaction *action;
+	irq_desc_t *desc;
+	unsigned long flags;
+
+	if (i == 0) {
+		seq_puts(p, "           ");
+		for_each_online_cpu(j)
+			seq_printf(p, "CPU%d       ", j);
+		seq_putc(p, '\n');
+	}
+
+	if (i < NR_IRQS) {
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
+		if (!action || !action->handler)
+			goto skip;
+		seq_printf(p, "%3d: ", i);
+#ifdef CONFIG_SMP
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+#else
+		seq_printf(p, "%10u ", kstat_irqs(i));
+#endif /* CONFIG_SMP */
+		if (desc->handler)
+			seq_printf(p, " %s ", desc->handler->typename);
+		else
+			seq_puts(p, "  None      ");
+		seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
+		seq_printf(p, "    %s", action->name);
+		for (action = action->next; action; action = action->next)
+			seq_printf(p, ", %s", action->name);
+		seq_putc(p, '\n');
+skip:
+		spin_unlock_irqrestore(&desc->lock, flags);
+	} else if (i == NR_IRQS) {
+#ifdef CONFIG_PPC32
+#ifdef CONFIG_TAU_INT
+		if (tau_initialized){
+			seq_puts(p, "TAU: ");
+			for (j = 0; j < NR_CPUS; j++)
+				if (cpu_online(j))
+					seq_printf(p, "%10u ", tau_interrupts(j));
+			seq_puts(p, "  PowerPC             Thermal Assist (cpu temp)\n");
+		}
+#endif
+#if defined(CONFIG_SMP) && !defined(CONFIG_PPC_MERGE)
+		/* should this be per processor send/receive? */
+		seq_printf(p, "IPI (recv/sent): %10u/%u\n",
+				atomic_read(&ipi_recv), atomic_read(&ipi_sent));
+#endif
+#endif /* CONFIG_PPC32 */
+		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
+	}
+	return 0;
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+void fixup_irqs(cpumask_t map)
+{
+	unsigned int irq;
+	static int warned;
+
+	for_each_irq(irq) {
+		cpumask_t mask;
+
+		if (irq_desc[irq].status & IRQ_PER_CPU)
+			continue;
+
+		cpus_and(mask, irq_affinity[irq], map);
+		if (any_online_cpu(mask) == NR_CPUS) {
+			printk("Breaking affinity for irq %i\n", irq);
+			mask = map;
+		}
+		if (irq_desc[irq].handler->set_affinity)
+			irq_desc[irq].handler->set_affinity(irq, mask);
+		else if (irq_desc[irq].action && !(warned++))
+			printk("Cannot set affinity for irq %i\n", irq);
+	}
+
+	local_irq_enable();
+	mdelay(1);
+	local_irq_disable();
+}
+#endif
+
+#ifdef CONFIG_PPC_ISERIES
+void do_IRQ(struct pt_regs *regs)
+{
+	struct paca_struct *lpaca;
+
+	irq_enter();
+
+#ifdef CONFIG_DEBUG_STACKOVERFLOW
+	/* Debugging check for stack overflow: is there less than 2KB free? */
+	{
+		long sp;
+
+		sp = __get_SP() & (THREAD_SIZE-1);
+
+		if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
+			printk("do_IRQ: stack overflow: %ld\n",
+				sp - sizeof(struct thread_info));
+			dump_stack();
+		}
+	}
+#endif
+
+	lpaca = get_paca();
+#ifdef CONFIG_SMP
+	if (lpaca->lppaca.int_dword.fields.ipi_cnt) {
+		lpaca->lppaca.int_dword.fields.ipi_cnt = 0;
+		iSeries_smp_message_recv(regs);
+	}
+#endif /* CONFIG_SMP */
+	if (hvlpevent_is_pending())
+		process_hvlpevents(regs);
+
+	irq_exit();
+
+	if (lpaca->lppaca.int_dword.fields.decr_int) {
+		lpaca->lppaca.int_dword.fields.decr_int = 0;
+		/* Signal a fake decrementer interrupt */
+		timer_interrupt(regs);
+	}
+}
+
+#else	/* CONFIG_PPC_ISERIES */
+
+void do_IRQ(struct pt_regs *regs)
+{
+	int irq;
+#ifdef CONFIG_IRQSTACKS
+	struct thread_info *curtp, *irqtp;
+#endif
+
+        irq_enter();
+
+#ifdef CONFIG_DEBUG_STACKOVERFLOW
+	/* Debugging check for stack overflow: is there less than 2KB free? */
+	{
+		long sp;
+
+		sp = __get_SP() & (THREAD_SIZE-1);
+
+		if (unlikely(sp < (sizeof(struct thread_info) + 2048))) {
+			printk("do_IRQ: stack overflow: %ld\n",
+				sp - sizeof(struct thread_info));
+			dump_stack();
+		}
+	}
+#endif
+
+	/*
+	 * Every platform is required to implement ppc_md.get_irq.
+	 * This function will either return an irq number or -1 to
+	 * indicate there are no more pending.
+	 * The value -2 is for buggy hardware and means that this IRQ
+	 * has already been handled. -- Tom
+	 */
+	irq = ppc_md.get_irq(regs);
+
+	if (irq >= 0) {
+#ifdef CONFIG_IRQSTACKS
+		/* Switch to the irq stack to handle this */
+		curtp = current_thread_info();
+		irqtp = hardirq_ctx[smp_processor_id()];
+		if (curtp != irqtp) {
+			irqtp->task = curtp->task;
+			irqtp->flags = 0;
+			call___do_IRQ(irq, regs, irqtp);
+			irqtp->task = NULL;
+			if (irqtp->flags)
+				set_bits(irqtp->flags, &curtp->flags);
+		} else
+#endif
+			__do_IRQ(irq, regs);
+	} else
+#ifdef CONFIG_PPC32
+		if (irq != -2)
+#endif
+			/* That's not SMP safe ... but who cares ? */
+			ppc_spurious_interrupts++;
+        irq_exit();
+}
+
+#endif	/* CONFIG_PPC_ISERIES */
+
+void __init init_IRQ(void)
+{
+#ifdef CONFIG_PPC64
+	static int once = 0;
+
+	if (once)
+		return;
+
+	once++;
+
+#endif
+	ppc_md.init_IRQ();
+#ifdef CONFIG_PPC64
+	irq_ctx_init();
+#endif
+}
+
+#ifdef CONFIG_PPC64
+#ifndef CONFIG_PPC_ISERIES
+/*
+ * Virtual IRQ mapping code, used on systems with XICS interrupt controllers.
+ */
+
+#define UNDEFINED_IRQ 0xffffffff
+unsigned int virt_irq_to_real_map[NR_IRQS];
+
+/*
+ * Don't use virtual irqs 0, 1, 2 for devices.
+ * The pcnet32 driver considers interrupt numbers < 2 to be invalid,
+ * and 2 is the XICS IPI interrupt.
+ * We limit virtual irqs to 17 less than NR_IRQS so that when we
+ * offset them by 16 (to reserve the first 16 for ISA interrupts)
+ * we don't end up with an interrupt number >= NR_IRQS.
+ */
+#define MIN_VIRT_IRQ	3
+#define MAX_VIRT_IRQ	(NR_IRQS - NUM_ISA_INTERRUPTS - 1)
+#define NR_VIRT_IRQS	(MAX_VIRT_IRQ - MIN_VIRT_IRQ + 1)
+
+void
+virt_irq_init(void)
+{
+	int i;
+	for (i = 0; i < NR_IRQS; i++)
+		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
+}
+
+/* Create a mapping for a real_irq if it doesn't already exist.
+ * Return the virtual irq as a convenience.
+ */
+int virt_irq_create_mapping(unsigned int real_irq)
+{
+	unsigned int virq, first_virq;
+	static int warned;
+
+	if (ppc64_interrupt_controller == IC_OPEN_PIC)
+		return real_irq;	/* no mapping for openpic (for now) */
+
+	if (ppc64_interrupt_controller == IC_CELL_PIC)
+		return real_irq;	/* no mapping for iic either */
+
+	/* don't map interrupts < MIN_VIRT_IRQ */
+	if (real_irq < MIN_VIRT_IRQ) {
+		virt_irq_to_real_map[real_irq] = real_irq;
+		return real_irq;
+	}
+
+	/* map to a number between MIN_VIRT_IRQ and MAX_VIRT_IRQ */
+	virq = real_irq;
+	if (virq > MAX_VIRT_IRQ)
+		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+
+	/* search for this number or a free slot */
+	first_virq = virq;
+	while (virt_irq_to_real_map[virq] != UNDEFINED_IRQ) {
+		if (virt_irq_to_real_map[virq] == real_irq)
+			return virq;
+		if (++virq > MAX_VIRT_IRQ)
+			virq = MIN_VIRT_IRQ;
+		if (virq == first_virq)
+			goto nospace;	/* oops, no free slots */
+	}
+
+	virt_irq_to_real_map[virq] = real_irq;
+	return virq;
+
+ nospace:
+	if (!warned) {
+		printk(KERN_CRIT "Interrupt table is full\n");
+		printk(KERN_CRIT "Increase NR_IRQS (currently %d) "
+		       "in your kernel sources and rebuild.\n", NR_IRQS);
+		warned = 1;
+	}
+	return NO_IRQ;
+}
+
+/*
+ * In most cases will get a hit on the very first slot checked in the
+ * virt_irq_to_real_map.  Only when there are a large number of
+ * IRQs will this be expensive.
+ */
+unsigned int real_irq_to_virt_slowpath(unsigned int real_irq)
+{
+	unsigned int virq;
+	unsigned int first_virq;
+
+	virq = real_irq;
+
+	if (virq > MAX_VIRT_IRQ)
+		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+
+	first_virq = virq;
+
+	do {
+		if (virt_irq_to_real_map[virq] == real_irq)
+			return virq;
+
+		virq++;
+
+		if (virq >= MAX_VIRT_IRQ)
+			virq = 0;
+
+	} while (first_virq != virq);
+
+	return NO_IRQ;
+
+}
+
+#endif /* CONFIG_PPC_ISERIES */
+
+#ifdef CONFIG_IRQSTACKS
+struct thread_info *softirq_ctx[NR_CPUS];
+struct thread_info *hardirq_ctx[NR_CPUS];
+
+void irq_ctx_init(void)
+{
+	struct thread_info *tp;
+	int i;
+
+	for_each_cpu(i) {
+		memset((void *)softirq_ctx[i], 0, THREAD_SIZE);
+		tp = softirq_ctx[i];
+		tp->cpu = i;
+		tp->preempt_count = SOFTIRQ_OFFSET;
+
+		memset((void *)hardirq_ctx[i], 0, THREAD_SIZE);
+		tp = hardirq_ctx[i];
+		tp->cpu = i;
+		tp->preempt_count = HARDIRQ_OFFSET;
+	}
+}
+
+void do_softirq(void)
+{
+	unsigned long flags;
+	struct thread_info *curtp, *irqtp;
+
+	if (in_interrupt())
+		return;
+
+	local_irq_save(flags);
+
+	if (local_softirq_pending()) {
+		curtp = current_thread_info();
+		irqtp = softirq_ctx[smp_processor_id()];
+		irqtp->task = curtp->task;
+		call_do_softirq(irqtp);
+		irqtp->task = NULL;
+	}
+
+	local_irq_restore(flags);
+}
+EXPORT_SYMBOL(do_softirq);
+
+#endif /* CONFIG_IRQSTACKS */
+
+static int __init setup_noirqdistrib(char *str)
+{
+	distribute_irqs = 0;
+	return 1;
+}
+
+__setup("noirqdistrib", setup_noirqdistrib);
+#endif /* CONFIG_PPC64 */
