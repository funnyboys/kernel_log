commit 3a83f677a6eeff65751b29e3648d7c69c3be83f3
Author: Michael Roth <mdroth@linux.vnet.ibm.com>
Date:   Wed Sep 11 17:31:55 2019 -0500

    KVM: PPC: Book3S HV: use smp_mb() when setting/clearing host_ipi flag
    
    On a 2-socket Power9 system with 32 cores/128 threads (SMT4) and 1TB
    of memory running the following guest configs:
    
      guest A:
        - 224GB of memory
        - 56 VCPUs (sockets=1,cores=28,threads=2), where:
          VCPUs 0-1 are pinned to CPUs 0-3,
          VCPUs 2-3 are pinned to CPUs 4-7,
          ...
          VCPUs 54-55 are pinned to CPUs 108-111
    
      guest B:
        - 4GB of memory
        - 4 VCPUs (sockets=1,cores=4,threads=1)
    
    with the following workloads (with KSM and THP enabled in all):
    
      guest A:
        stress --cpu 40 --io 20 --vm 20 --vm-bytes 512M
    
      guest B:
        stress --cpu 4 --io 4 --vm 4 --vm-bytes 512M
    
      host:
        stress --cpu 4 --io 4 --vm 2 --vm-bytes 256M
    
    the below soft-lockup traces were observed after an hour or so and
    persisted until the host was reset (this was found to be reliably
    reproducible for this configuration, for kernels 4.15, 4.18, 5.0,
    and 5.3-rc5):
    
      [ 1253.183290] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1253.183319] rcu:     124-....: (5250 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=1941
      [ 1256.287426] watchdog: BUG: soft lockup - CPU#105 stuck for 23s! [CPU 52/KVM:19709]
      [ 1264.075773] watchdog: BUG: soft lockup - CPU#24 stuck for 23s! [worker:19913]
      [ 1264.079769] watchdog: BUG: soft lockup - CPU#31 stuck for 23s! [worker:20331]
      [ 1264.095770] watchdog: BUG: soft lockup - CPU#45 stuck for 23s! [worker:20338]
      [ 1264.131773] watchdog: BUG: soft lockup - CPU#64 stuck for 23s! [avocado:19525]
      [ 1280.408480] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1316.198012] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1316.198032] rcu:     124-....: (21003 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=8243
      [ 1340.411024] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1379.212609] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1379.212629] rcu:     124-....: (36756 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=14714
      [ 1404.413615] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1442.227095] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1442.227115] rcu:     124-....: (52509 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=21403
      [ 1455.111787] INFO: task worker:19907 blocked for more than 120 seconds.
      [ 1455.111822]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111833] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.111884] INFO: task worker:19908 blocked for more than 120 seconds.
      [ 1455.111905]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111925] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.111966] INFO: task worker:20328 blocked for more than 120 seconds.
      [ 1455.111986]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111998] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112048] INFO: task worker:20330 blocked for more than 120 seconds.
      [ 1455.112068]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112097] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112138] INFO: task worker:20332 blocked for more than 120 seconds.
      [ 1455.112159]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112179] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112210] INFO: task worker:20333 blocked for more than 120 seconds.
      [ 1455.112231]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112242] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112282] INFO: task worker:20335 blocked for more than 120 seconds.
      [ 1455.112303]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112332] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112372] INFO: task worker:20336 blocked for more than 120 seconds.
      [ 1455.112392]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
    
    CPUs 45, 24, and 124 are stuck on spin locks, likely held by
    CPUs 105 and 31.
    
    CPUs 105 and 31 are stuck in smp_call_function_many(), waiting on
    target CPU 42. For instance:
    
      # CPU 105 registers (via xmon)
      R00 = c00000000020b20c   R16 = 00007d1bcd800000
      R01 = c00000363eaa7970   R17 = 0000000000000001
      R02 = c0000000019b3a00   R18 = 000000000000006b
      R03 = 000000000000002a   R19 = 00007d537d7aecf0
      R04 = 000000000000002a   R20 = 60000000000000e0
      R05 = 000000000000002a   R21 = 0801000000000080
      R06 = c0002073fb0caa08   R22 = 0000000000000d60
      R07 = c0000000019ddd78   R23 = 0000000000000001
      R08 = 000000000000002a   R24 = c00000000147a700
      R09 = 0000000000000001   R25 = c0002073fb0ca908
      R10 = c000008ffeb4e660   R26 = 0000000000000000
      R11 = c0002073fb0ca900   R27 = c0000000019e2464
      R12 = c000000000050790   R28 = c0000000000812b0
      R13 = c000207fff623e00   R29 = c0002073fb0ca808
      R14 = 00007d1bbee00000   R30 = c0002073fb0ca800
      R15 = 00007d1bcd600000   R31 = 0000000000000800
      pc  = c00000000020b260 smp_call_function_many+0x3d0/0x460
      cfar= c00000000020b270 smp_call_function_many+0x3e0/0x460
      lr  = c00000000020b20c smp_call_function_many+0x37c/0x460
      msr = 900000010288b033   cr  = 44024824
      ctr = c000000000050790   xer = 0000000000000000   trap =  100
    
    CPU 42 is running normally, doing VCPU work:
    
      # CPU 42 stack trace (via xmon)
      [link register   ] c00800001be17188 kvmppc_book3s_radix_page_fault+0x90/0x2b0 [kvm_hv]
      [c000008ed3343820] c000008ed3343850 (unreliable)
      [c000008ed33438d0] c00800001be11b6c kvmppc_book3s_hv_page_fault+0x264/0xe30 [kvm_hv]
      [c000008ed33439d0] c00800001be0d7b4 kvmppc_vcpu_run_hv+0x8dc/0xb50 [kvm_hv]
      [c000008ed3343ae0] c00800001c10891c kvmppc_vcpu_run+0x34/0x48 [kvm]
      [c000008ed3343b00] c00800001c10475c kvm_arch_vcpu_ioctl_run+0x244/0x420 [kvm]
      [c000008ed3343b90] c00800001c0f5a78 kvm_vcpu_ioctl+0x470/0x7c8 [kvm]
      [c000008ed3343d00] c000000000475450 do_vfs_ioctl+0xe0/0xc70
      [c000008ed3343db0] c0000000004760e4 ksys_ioctl+0x104/0x120
      [c000008ed3343e00] c000000000476128 sys_ioctl+0x28/0x80
      [c000008ed3343e20] c00000000000b388 system_call+0x5c/0x70
      --- Exception: c00 (System Call) at 00007d545cfd7694
      SP (7d53ff7edf50) is in userspace
    
    It was subsequently found that ipi_message[PPC_MSG_CALL_FUNCTION]
    was set for CPU 42 by at least 1 of the CPUs waiting in
    smp_call_function_many(), but somehow the corresponding
    call_single_queue entries were never processed by CPU 42, causing the
    callers to spin in csd_lock_wait() indefinitely.
    
    Nick Piggin suggested something similar to the following sequence as
    a possible explanation (interleaving of CALL_FUNCTION/RESCHEDULE
    IPI messages seems to be most common, but any mix of CALL_FUNCTION and
    !CALL_FUNCTION messages could trigger it):
    
        CPU
          X: smp_muxed_ipi_set_message():
          X:   smp_mb()
          X:   message[RESCHEDULE] = 1
          X: doorbell_global_ipi(42):
          X:   kvmppc_set_host_ipi(42, 1)
          X:   ppc_msgsnd_sync()/smp_mb()
          X:   ppc_msgsnd() -> 42
         42: doorbell_exception(): // from CPU X
         42:   ppc_msgsync()
        105: smp_muxed_ipi_set_message():
        105:   smb_mb()
             // STORE DEFERRED DUE TO RE-ORDERING
      --105:   message[CALL_FUNCTION] = 1
      | 105: doorbell_global_ipi(42):
      | 105:   kvmppc_set_host_ipi(42, 1)
      |  42:   kvmppc_set_host_ipi(42, 0)
      |  42: smp_ipi_demux_relaxed()
      |  42: // returns to executing guest
      |      // RE-ORDERED STORE COMPLETES
      ->105:   message[CALL_FUNCTION] = 1
        105:   ppc_msgsnd_sync()/smp_mb()
        105:   ppc_msgsnd() -> 42
         42: local_paca->kvm_hstate.host_ipi == 0 // IPI ignored
        105: // hangs waiting on 42 to process messages/call_single_queue
    
    This can be prevented with an smp_mb() at the beginning of
    kvmppc_set_host_ipi(), such that stores to message[<type>] (or other
    state indicated by the host_ipi flag) are ordered vs. the store to
    to host_ipi.
    
    However, doing so might still allow for the following scenario (not
    yet observed):
    
        CPU
          X: smp_muxed_ipi_set_message():
          X:   smp_mb()
          X:   message[RESCHEDULE] = 1
          X: doorbell_global_ipi(42):
          X:   kvmppc_set_host_ipi(42, 1)
          X:   ppc_msgsnd_sync()/smp_mb()
          X:   ppc_msgsnd() -> 42
         42: doorbell_exception(): // from CPU X
         42:   ppc_msgsync()
             // STORE DEFERRED DUE TO RE-ORDERING
      -- 42:   kvmppc_set_host_ipi(42, 0)
      |  42: smp_ipi_demux_relaxed()
      | 105: smp_muxed_ipi_set_message():
      | 105:   smb_mb()
      | 105:   message[CALL_FUNCTION] = 1
      | 105: doorbell_global_ipi(42):
      | 105:   kvmppc_set_host_ipi(42, 1)
      |      // RE-ORDERED STORE COMPLETES
      -> 42:   kvmppc_set_host_ipi(42, 0)
         42: // returns to executing guest
        105:   ppc_msgsnd_sync()/smp_mb()
        105:   ppc_msgsnd() -> 42
         42: local_paca->kvm_hstate.host_ipi == 0 // IPI ignored
        105: // hangs waiting on 42 to process messages/call_single_queue
    
    Fixing this scenario would require an smp_mb() *after* clearing
    host_ipi flag in kvmppc_set_host_ipi() to order the store vs.
    subsequent processing of IPI messages.
    
    To handle both cases, this patch splits kvmppc_set_host_ipi() into
    separate set/clear functions, where we execute smp_mb() prior to
    setting host_ipi flag, and after clearing host_ipi flag. These
    functions pair with each other to synchronize the sender and receiver
    sides.
    
    With that change in place the above workload ran for 20 hours without
    triggering any lock-ups.
    
    Fixes: 755563bc79c7 ("powerpc/powernv: Fixes for hypervisor doorbell handling") # v4.0
    Signed-off-by: Michael Roth <mdroth@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190911223155.16045-1-mdroth@linux.vnet.ibm.com

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 804b1a6196fa..f17ff1200eaa 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -33,7 +33,7 @@ void doorbell_global_ipi(int cpu)
 {
 	u32 tag = get_hard_smp_processor_id(cpu);
 
-	kvmppc_set_host_ipi(cpu, 1);
+	kvmppc_set_host_ipi(cpu);
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
 	ppc_msgsnd_sync();
 	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
@@ -48,7 +48,7 @@ void doorbell_core_ipi(int cpu)
 {
 	u32 tag = cpu_thread_in_core(cpu);
 
-	kvmppc_set_host_ipi(cpu, 1);
+	kvmppc_set_host_ipi(cpu);
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
 	ppc_msgsnd_sync();
 	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
@@ -84,7 +84,7 @@ void doorbell_exception(struct pt_regs *regs)
 
 	may_hard_irq_enable();
 
-	kvmppc_set_host_ipi(smp_processor_id(), 0);
+	kvmppc_clear_host_ipi(smp_processor_id());
 	__this_cpu_inc(irq_stat.doorbell_irqs);
 
 	smp_ipi_demux_relaxed(); /* already performed the barrier */

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 5ec3b3835925..804b1a6196fa 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -1,12 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Author: Kumar Gala <galak@kernel.crashing.org>
  *
  * Copyright 2009 Freescale Semiconductor Inc.
- *
- * This program is free software; you can redistribute  it and/or modify it
- * under  the terms of  the GNU General  Public License as published by the
- * Free Software Foundation;  either version 2 of the  License, or (at your
- * option) any later version.
  */
 
 #include <linux/stddef.h>

commit 5b2a15296210d3b70e06d0f09a8e701ff74ccbe8
Author: Anton Blanchard <anton@ozlabs.org>
Date:   Thu Oct 4 16:23:37 2018 +1000

    powerpc: Add doorbell tracepoints
    
    When analysing sources of OS jitter, I noticed that doorbells cannot be
    traced.
    
    Signed-off-by: Anton Blanchard <anton@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index b6fe883b1016..5ec3b3835925 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -18,6 +18,7 @@
 #include <asm/dbell.h>
 #include <asm/irq_regs.h>
 #include <asm/kvm_ppc.h>
+#include <asm/trace.h>
 
 #ifdef CONFIG_SMP
 
@@ -81,6 +82,7 @@ void doorbell_exception(struct pt_regs *regs)
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	irq_enter();
+	trace_doorbell_entry(regs);
 
 	ppc_msgsync();
 
@@ -91,6 +93,7 @@ void doorbell_exception(struct pt_regs *regs)
 
 	smp_ipi_demux_relaxed(); /* already performed the barrier */
 
+	trace_doorbell_exit(regs);
 	irq_exit();
 	set_irq_regs(old_regs);
 }

commit b87ac0218355a83abb899a0022bb2e5252879fc0
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:22 2017 +1000

    powerpc: Introduce msgsnd/doorbell barrier primitives
    
    POWER9 changes requirements and adds new instructions for
    synchronization.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 5869c66adfd0..b6fe883b1016 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -38,7 +38,7 @@ void doorbell_global_ipi(int cpu)
 
 	kvmppc_set_host_ipi(cpu, 1);
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
-	mb();
+	ppc_msgsnd_sync();
 	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
 }
 
@@ -53,7 +53,7 @@ void doorbell_core_ipi(int cpu)
 
 	kvmppc_set_host_ipi(cpu, 1);
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
-	mb();
+	ppc_msgsnd_sync();
 	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
 }
 
@@ -82,12 +82,14 @@ void doorbell_exception(struct pt_regs *regs)
 
 	irq_enter();
 
+	ppc_msgsync();
+
 	may_hard_irq_enable();
 
 	kvmppc_set_host_ipi(smp_processor_id(), 0);
 	__this_cpu_inc(irq_stat.doorbell_irqs);
 
-	smp_ipi_demux();
+	smp_ipi_demux_relaxed(); /* already performed the barrier */
 
 	irq_exit();
 	set_irq_regs(old_regs);

commit b866cc2199d6a6cdcefe4acfe4cfca3ac3c6d38e
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:21 2017 +1000

    powerpc: Change the doorbell IPI calling convention
    
    Change the doorbell callers to know about their msgsnd addressing,
    rather than have them set a per-cpu target data tag at boot that gets
    sent to the cause_ipi functions. The data is only used for doorbell IPI
    functions, no other IPI types, so it makes sense to keep that detail
    local to doorbell.
    
    Have the platform code understand doorbell IPIs, rather than the
    interrupt controller code understand them. Platform code can look at
    capabilities it has available and decide which to use.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 2128f3a96c32..5869c66adfd0 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -20,18 +20,60 @@
 #include <asm/kvm_ppc.h>
 
 #ifdef CONFIG_SMP
-void doorbell_setup_this_cpu(void)
+
+/*
+ * Doorbells must only be used if CPU_FTR_DBELL is available.
+ * msgsnd is used in HV, and msgsndp is used in !HV.
+ *
+ * These should be used by platform code that is aware of restrictions.
+ * Other arch code should use ->cause_ipi.
+ *
+ * doorbell_global_ipi() sends a dbell to any target CPU.
+ * Must be used only by architectures that address msgsnd target
+ * by PIR/get_hard_smp_processor_id.
+ */
+void doorbell_global_ipi(int cpu)
 {
-	unsigned long tag = mfspr(SPRN_DOORBELL_CPUTAG) & PPC_DBELL_TAG_MASK;
+	u32 tag = get_hard_smp_processor_id(cpu);
 
-	smp_muxed_ipi_set_data(smp_processor_id(), tag);
+	kvmppc_set_host_ipi(cpu, 1);
+	/* Order previous accesses vs. msgsnd, which is treated as a store */
+	mb();
+	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
 }
 
-void doorbell_cause_ipi(int cpu, unsigned long data)
+/*
+ * doorbell_core_ipi() sends a dbell to a target CPU in the same core.
+ * Must be used only by architectures that address msgsnd target
+ * by TIR/cpu_thread_in_core.
+ */
+void doorbell_core_ipi(int cpu)
 {
+	u32 tag = cpu_thread_in_core(cpu);
+
+	kvmppc_set_host_ipi(cpu, 1);
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
 	mb();
-	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, data);
+	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, tag);
+}
+
+/*
+ * Attempt to cause a core doorbell if destination is on the same core.
+ * Returns 1 on success, 0 on failure.
+ */
+int doorbell_try_core_ipi(int cpu)
+{
+	int this_cpu = get_cpu();
+	int ret = 0;
+
+	if (cpumask_test_cpu(cpu, cpu_sibling_mask(this_cpu))) {
+		doorbell_core_ipi(cpu);
+		ret = 1;
+	}
+
+	put_cpu();
+
+	return ret;
 }
 
 void doorbell_exception(struct pt_regs *regs)

commit 755563bc79c764c90b9f44db5e4fe6c556d3440c
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Mar 19 19:29:01 2015 +1100

    powerpc/powernv: Fixes for hypervisor doorbell handling
    
    Since we can now use hypervisor doorbells for host IPIs, this makes
    sure we clear the host IPI flag when taking a doorbell interrupt, and
    clears any pending doorbell IPI in pnv_smp_cpu_kill_self() (as we
    already do for IPIs sent via the XICS interrupt controller).  Otherwise
    if there did happen to be a leftover pending doorbell interrupt for
    an offline CPU thread for any reason, it would prevent that thread from
    going into a power-saving mode; it would instead keep waking up because
    of the interrupt.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index f4217819cc31..2128f3a96c32 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -17,6 +17,7 @@
 
 #include <asm/dbell.h>
 #include <asm/irq_regs.h>
+#include <asm/kvm_ppc.h>
 
 #ifdef CONFIG_SMP
 void doorbell_setup_this_cpu(void)
@@ -41,6 +42,7 @@ void doorbell_exception(struct pt_regs *regs)
 
 	may_hard_irq_enable();
 
+	kvmppc_set_host_ipi(smp_processor_id(), 0);
 	__this_cpu_inc(irq_stat.doorbell_irqs);
 
 	smp_ipi_demux();

commit 69111bac42f5ceacdd22e30947837ceb2c4493ed
Author: Christoph Lameter <cl@linux.com>
Date:   Tue Oct 21 15:23:25 2014 -0500

    powerpc: Replace __get_cpu_var uses
    
    This still has not been merged and now powerpc is the only arch that does
    not have this change. Sorry about missing linuxppc-dev before.
    
    V2->V2
      - Fix up to work against 3.18-rc1
    
    __get_cpu_var() is used for multiple purposes in the kernel source. One of
    them is address calculation via the form &__get_cpu_var(x).  This calculates
    the address for the instance of the percpu variable of the current processor
    based on an offset.
    
    Other use cases are for storing and retrieving data from the current
    processors percpu area.  __get_cpu_var() can be used as an lvalue when
    writing data or on the right side of an assignment.
    
    __get_cpu_var() is defined as :
    
    __get_cpu_var() always only does an address determination. However, store
    and retrieve operations could use a segment prefix (or global register on
    other platforms) to avoid the address calculation.
    
    this_cpu_write() and this_cpu_read() can directly take an offset into a
    percpu area and use optimized assembly code to read and write per cpu
    variables.
    
    This patch converts __get_cpu_var into either an explicit address
    calculation using this_cpu_ptr() or into a use of this_cpu operations that
    use the offset.  Thereby address calculations are avoided and less registers
    are used when code is generated.
    
    At the end of the patch set all uses of __get_cpu_var have been removed so
    the macro is removed too.
    
    The patch set includes passes over all arches as well. Once these operations
    are used throughout then specialized macros can be defined in non -x86
    arches as well in order to optimize per cpu access by f.e.  using a global
    register that may be set to the per cpu base.
    
    Transformations done to __get_cpu_var()
    
    1. Determine the address of the percpu instance of the current processor.
    
            DEFINE_PER_CPU(int, y);
            int *x = &__get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(&y);
    
    2. Same as #1 but this time an array structure is involved.
    
            DEFINE_PER_CPU(int, y[20]);
            int *x = __get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(y);
    
    3. Retrieve the content of the current processors instance of a per cpu
    variable.
    
            DEFINE_PER_CPU(int, y);
            int x = __get_cpu_var(y)
    
       Converts to
    
            int x = __this_cpu_read(y);
    
    4. Retrieve the content of a percpu struct
    
            DEFINE_PER_CPU(struct mystruct, y);
            struct mystruct x = __get_cpu_var(y);
    
       Converts to
    
            memcpy(&x, this_cpu_ptr(&y), sizeof(x));
    
    5. Assignment to a per cpu variable
    
            DEFINE_PER_CPU(int, y)
            __get_cpu_var(y) = x;
    
       Converts to
    
            __this_cpu_write(y, x);
    
    6. Increment/Decrement etc of a per cpu variable
    
            DEFINE_PER_CPU(int, y);
            __get_cpu_var(y)++
    
       Converts to
    
            __this_cpu_inc(y)
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    [mpe: Fix build errors caused by set/or_softirq_pending(), and rework
          assignment in __set_breakpoint() to use memcpy().]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index d55c76c571f3..f4217819cc31 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -41,7 +41,7 @@ void doorbell_exception(struct pt_regs *regs)
 
 	may_hard_irq_enable();
 
-	__get_cpu_var(irq_stat).doorbell_irqs++;
+	__this_cpu_inc(irq_stat.doorbell_irqs);
 
 	smp_ipi_demux();
 

commit a6a058e52a0ce62de84496c9d4b133f2afc61f27
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Mar 21 19:22:52 2013 +0000

    powerpc: Add accounting for Doorbell interrupts
    
    This patch adds a new line to /proc/interrupts to account for the
    doorbell interrupts that each hardware thread has received. The total
    interrupt count in /proc/stat will now also include doorbells.
    
     # cat /proc/interrupts
               CPU0       CPU1       CPU2       CPU3
     16:        551       1267        281        175      XICS Level     IPI
    LOC:       2037       1503       1688       1625   Local timer interrupts
    SPU:          0          0          0          0   Spurious interrupts
    CNT:          0          0          0          0   Performance monitoring interrupts
    MCE:          0          0          0          0   Machine check exceptions
    DBL:         42        550         20         91   Doorbell interrupts
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 9ebbc24bb23c..d55c76c571f3 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -41,6 +41,8 @@ void doorbell_exception(struct pt_regs *regs)
 
 	may_hard_irq_enable();
 
+	__get_cpu_var(irq_stat).doorbell_irqs++;
+
 	smp_ipi_demux();
 
 	irq_exit();

commit 42d02b81f265b77be39262666c888d50cb488fc5
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Nov 14 18:49:44 2012 +0000

    powerpc: Define differences between doorbells on book3e and book3s
    
    There are a few key differences between doorbells on server compared
    with embedded that we care about on Linux, namely:
    
    - We have a new msgsndp instruction for directed privileged doorbells.
      msgsnd is used for directed hypervisor doorbells.
    - The tag we use in the instruction is the Thread Identification
      Register of the recipient thread (since server doorbells can only
      occur between threads within a single core), and is only 7 bits wide.
    - A new message type is introduced for server doorbells (none of the
      existing book3e message types are currently supported on book3s).
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Tested-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index a892680668d8..9ebbc24bb23c 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -21,7 +21,7 @@
 #ifdef CONFIG_SMP
 void doorbell_setup_this_cpu(void)
 {
-	unsigned long tag = mfspr(SPRN_PIR) & 0x3fff;
+	unsigned long tag = mfspr(SPRN_DOORBELL_CPUTAG) & PPC_DBELL_TAG_MASK;
 
 	smp_muxed_ipi_set_data(smp_processor_id(), tag);
 }
@@ -30,7 +30,7 @@ void doorbell_cause_ipi(int cpu, unsigned long data)
 {
 	/* Order previous accesses vs. msgsnd, which is treated as a store */
 	mb();
-	ppc_msgsnd(PPC_DBELL, 0, data);
+	ppc_msgsnd(PPC_DBELL_MSGTYPE, 0, data);
 }
 
 void doorbell_exception(struct pt_regs *regs)

commit 9fb1b36ca1234e64a5d1cc573175303395e3354d
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Sep 4 18:33:08 2012 +0000

    powerpc: Make sure IPI handlers see data written by IPI senders
    
    We have been observing hangs, both of KVM guest vcpu tasks and more
    generally, where a process that is woken doesn't properly wake up and
    continue to run, but instead sticks in TASK_WAKING state.  This
    happens because the update of rq->wake_list in ttwu_queue_remote()
    is not ordered with the update of ipi_message in
    smp_muxed_ipi_message_pass(), and the reading of rq->wake_list in
    scheduler_ipi() is not ordered with the reading of ipi_message in
    smp_ipi_demux().  Thus it is possible for the IPI receiver not to see
    the updated rq->wake_list and therefore conclude that there is nothing
    for it to do.
    
    In order to make sure that anything done before smp_send_reschedule()
    is ordered before anything done in the resulting call to scheduler_ipi(),
    this adds barriers in smp_muxed_message_pass() and smp_ipi_demux().
    The barrier in smp_muxed_message_pass() is a full barrier to ensure that
    there is a full ordering between the smp_send_reschedule() caller and
    scheduler_ipi().  In smp_ipi_demux(), we use xchg() rather than
    xchg_local() because xchg() includes release and acquire barriers.
    Using xchg() rather than xchg_local() makes sense given that
    ipi_message is not just accessed locally.
    
    This moves the barrier between setting the message and calling the
    cause_ipi() function into the individual cause_ipi implementations.
    Most of them -- those that used outb, out_8 or similar -- already had
    a full barrier because out_8 etc. include a sync before the MMIO
    store.  This adds an explicit barrier in the two remaining cases.
    
    These changes made no measurable difference to the speed of IPIs as
    measured using a simple ping-pong latency test across two CPUs on
    different cores of a POWER7 machine.
    
    The analysis of the reason why processes were not waking up properly
    is due to Milton Miller.
    
    Cc: stable@vger.kernel.org # v3.0+
    Reported-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 5b25c8060fd6..a892680668d8 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -28,6 +28,8 @@ void doorbell_setup_this_cpu(void)
 
 void doorbell_cause_ipi(int cpu, unsigned long data)
 {
+	/* Order previous accesses vs. msgsnd, which is treated as a store */
+	mb();
 	ppc_msgsnd(PPC_DBELL, 0, data);
 }
 

commit 7230c5644188cd9e3fb380cc97dde00c464a3ba7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Mar 6 18:27:59 2012 +1100

    powerpc: Rework lazy-interrupt handling
    
    The current implementation of lazy interrupts handling has some
    issues that this tries to address.
    
    We don't do the various workarounds we need to do when re-enabling
    interrupts in some cases such as when returning from an interrupt
    and thus we may still lose or get delayed decrementer or doorbell
    interrupts.
    
    The current scheme also makes it much harder to handle the external
    "edge" interrupts provided by some BookE processors when using the
    EPR facility (External Proxy) and the Freescale Hypervisor.
    
    Additionally, we tend to keep interrupts hard disabled in a number
    of cases, such as decrementer interrupts, external interrupts, or
    when a masked decrementer interrupt is pending. This is sub-optimal.
    
    This is an attempt at fixing it all in one go by reworking the way
    we do the lazy interrupt disabling from the ground up.
    
    The base idea is to replace the "hard_enabled" field with a
    "irq_happened" field in which we store a bit mask of what interrupt
    occurred while soft-disabled.
    
    When re-enabling, either via arch_local_irq_restore() or when returning
    from an interrupt, we can now decide what to do by testing bits in that
    field.
    
    We then implement replaying of the missed interrupts either by
    re-using the existing exception frame (in exception exit case) or via
    the creation of a new one from an assembly trampoline (in the
    arch_local_irq_enable case).
    
    This removes the need to play with the decrementer to try to create
    fake interrupts, among others.
    
    In addition, this adds a few refinements:
    
     - We no longer  hard disable decrementer interrupts that occur
    while soft-disabled. We now simply bump the decrementer back to max
    (on BookS) or leave it stopped (on BookE) and continue with hard interrupts
    enabled, which means that we'll potentially get better sample quality from
    performance monitor interrupts.
    
     - Timer, decrementer and doorbell interrupts now hard-enable
    shortly after removing the source of the interrupt, which means
    they no longer run entirely hard disabled. Again, this will improve
    perf sample quality.
    
     - On Book3E 64-bit, we now make the performance monitor interrupt
    act as an NMI like Book3S (the necessary C code for that to work
    appear to already be present in the FSL perf code, notably calling
    nmi_enter instead of irq_enter). (This also fixes a bug where BookE
    perfmon interrupts could clobber r14 ... oops)
    
     - We could make "masked" decrementer interrupts act as NMIs when doing
    timer-based perf sampling to improve the sample quality.
    
    Signed-off-by-yet: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    ---
    
    v2:
    
    - Add hard-enable to decrementer, timer and doorbells
    - Fix CR clobber in masked irq handling on BookE
    - Make embedded perf interrupt act as an NMI
    - Add a PACA_HAPPENED_EE_EDGE for use by FSL if they want
      to retrigger an interrupt without preventing hard-enable
    
    v3:
    
     - Fix or vs. ori bug on Book3E
     - Fix enabling of interrupts for some exceptions on Book3E
    
    v4:
    
     - Fix resend of doorbells on return from interrupt on Book3E
    
    v5:
    
     - Rebased on top of my latest series, which involves some significant
    rework of some aspects of the patch.
    
    v6:
     - 32-bit compile fix
     - more compile fixes with various .config combos
     - factor out the asm code to soft-disable interrupts
     - remove the C wrapper around preempt_schedule_irq
    
    v7:
     - Fix a bug with hard irq state tracking on native power7

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 2cc451aaaca7..5b25c8060fd6 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -37,6 +37,8 @@ void doorbell_exception(struct pt_regs *regs)
 
 	irq_enter();
 
+	may_hard_irq_enable();
+
 	smp_ipi_demux();
 
 	irq_exit();

commit 23d72bfd8f9f24aa9efafed3586a99f5669c23d7
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:39 2011 +0000

    powerpc: Consolidate ipi message mux and demux
    
    Consolidate the mux and demux of ipi messages into smp.c and call
    a new smp_ops callback to actually trigger the ipi.
    
    The powerpc architecture code is optimised for having 4 distinct
    ipi triggers, which are mapped to 4 distinct messages (ipi many, ipi
    single, scheduler ipi, and enter debugger).  However, several interrupt
    controllers only provide a single software triggered interrupt that
    can be delivered to each cpu.  To resolve this limitation, each smp_ops
    implementation created a per-cpu variable that is manipulated with atomic
    bitops.  Since these lines will be contended they are optimialy marked as
    shared_aligned and take a full cache line for each cpu.  Distro kernels
    may have 2 or 3 of these in their config, each taking per-cpu space
    even though at most one will be in use.
    
    This consolidation removes smp_message_recv and replaces the single call
    actions cases with direct calls from the common message recognition loop.
    The complicated debugger ipi case with its muxed crash handling code is
    moved to debug_ipi_action which is now called from the demux code (instead
    of the multi-message action calling smp_message_recv).
    
    I put a call to reschedule_action to increase the likelyhood of correctly
    merging the anticipated scheduler_ipi() hook coming from the scheduler
    tree; that single required call can be inlined later.
    
    The actual message decode is a copy of the old pseries xics code with its
    memory barriers and cache line spacing, augmented with a per-cpu unsigned
    long based on the book-e doorbell code.  The optional data is set via a
    callback from the implementation and is passed to the new cause-ipi hook
    along with the logical cpu number.  While currently only the doorbell
    implemntation uses this data it should be almost zero cost to retrieve and
    pass it -- it adds a single register load for the argument from the same
    cache line to which we just completed a store and the register is dead
    on return from the call.  I extended the data element from unsigned int
    to unsigned long in case some other code wanted to associate a pointer.
    
    The doorbell check_self is replaced by a call to smp_muxed_ipi_resend,
    conditioned on the CPU_DBELL feature.  The ifdef guard could be relaxed
    to CONFIG_SMP but I left it with BOOKE for now.
    
    Also, the doorbell interrupt vector for book-e was not calling irq_enter
    and irq_exit, which throws off cpu accounting and causes code to not
    realize it is running in interrupt context.  Add the missing calls.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index e49b24c84133..2cc451aaaca7 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -13,65 +13,35 @@
 #include <linux/kernel.h>
 #include <linux/smp.h>
 #include <linux/threads.h>
-#include <linux/percpu.h>
+#include <linux/hardirq.h>
 
 #include <asm/dbell.h>
 #include <asm/irq_regs.h>
 
 #ifdef CONFIG_SMP
-struct doorbell_cpu_info {
-	unsigned long	messages;	/* current messages bits */
-	unsigned int	tag;		/* tag value */
-};
-
-static DEFINE_PER_CPU(struct doorbell_cpu_info, doorbell_cpu_info);
-
 void doorbell_setup_this_cpu(void)
 {
-	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
+	unsigned long tag = mfspr(SPRN_PIR) & 0x3fff;
 
-	info->messages = 0;
-	info->tag = mfspr(SPRN_PIR) & 0x3fff;
+	smp_muxed_ipi_set_data(smp_processor_id(), tag);
 }
 
-void doorbell_message_pass(int cpu, int msg)
+void doorbell_cause_ipi(int cpu, unsigned long data)
 {
-	struct doorbell_cpu_info *info;
-
-	info = &per_cpu(doorbell_cpu_info, cpu);
-	set_bit(msg, &info->messages);
-	ppc_msgsnd(PPC_DBELL, 0, info->tag);
+	ppc_msgsnd(PPC_DBELL, 0, data);
 }
 
 void doorbell_exception(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
-	int msg;
 
-	/* Warning: regs can be NULL when called from irq enable */
+	irq_enter();
 
-	if (!info->messages || (num_online_cpus() < 2))
-		goto out;
+	smp_ipi_demux();
 
-	for (msg = 0; msg < 4; msg++)
-		if (test_and_clear_bit(msg, &info->messages))
-			smp_message_recv(msg);
-
-out:
+	irq_exit();
 	set_irq_regs(old_regs);
 }
-
-void doorbell_check_self(void)
-{
-	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
-
-	if (!info->messages)
-		return;
-
-	ppc_msgsnd(PPC_DBELL, 0, info->tag);
-}
-
 #else /* CONFIG_SMP */
 void doorbell_exception(struct pt_regs *regs)
 {

commit f1072939b6dd01d038d47db0bdc01b33e5f90f28
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:10 2011 +0000

    powerpc: Remove checks for MSG_ALL and MSG_ALL_BUT_SELF
    
    Now that smp_ops->smp_message_pass is always called with an (online) cpu
    number for the target remove the checks for MSG_ALL and MSG_ALL_BUT_SELF.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 3307a52d797f..e49b24c84133 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -34,32 +34,13 @@ void doorbell_setup_this_cpu(void)
 	info->tag = mfspr(SPRN_PIR) & 0x3fff;
 }
 
-void doorbell_message_pass(int target, int msg)
+void doorbell_message_pass(int cpu, int msg)
 {
 	struct doorbell_cpu_info *info;
-	int i;
-
-	if (target < NR_CPUS) {
-		info = &per_cpu(doorbell_cpu_info, target);
-		set_bit(msg, &info->messages);
-		ppc_msgsnd(PPC_DBELL, 0, info->tag);
-	}
-	else if (target == MSG_ALL_BUT_SELF) {
-		for_each_online_cpu(i) {
-			if (i == smp_processor_id())
-				continue;
-			info = &per_cpu(doorbell_cpu_info, i);
-			set_bit(msg, &info->messages);
-			ppc_msgsnd(PPC_DBELL, 0, info->tag);
-		}
-	}
-	else { /* target == MSG_ALL */
-		for_each_online_cpu(i) {
-			info = &per_cpu(doorbell_cpu_info, i);
-			set_bit(msg, &info->messages);
-		}
-		ppc_msgsnd(PPC_DBELL, PPC_DBELL_MSG_BRDCAST, 0);
-	}
+
+	info = &per_cpu(doorbell_cpu_info, cpu);
+	set_bit(msg, &info->messages);
+	ppc_msgsnd(PPC_DBELL, 0, info->tag);
 }
 
 void doorbell_exception(struct pt_regs *regs)

commit 850f22d5688941ea51628f3f8f8dcf3baff409ff
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jul 9 15:34:00 2010 +1000

    powerpc/book3e: Resend doorbell exceptions to ourself
    
    If we are soft disabled and receive a doorbell exception we don't process
    it immediately. This means we need to check on the way out of irq restore
    if there are any doorbell exceptions to process.
    
    The problem is at that point we don't know what our regs are, and that
    in turn makes xmon unhappy. To workaround the problem, instead of checking
    for and processing doorbells, we check for any doorbells and if there were
    any we send ourselves another.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index f7b518894c80..3307a52d797f 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -81,6 +81,16 @@ void doorbell_exception(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
+void doorbell_check_self(void)
+{
+	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
+
+	if (!info->messages)
+		return;
+
+	ppc_msgsnd(PPC_DBELL, 0, info->tag);
+}
+
 #else /* CONFIG_SMP */
 void doorbell_exception(struct pt_regs *regs)
 {

commit 0e37d25950f4fd5a7d74723e6ce608aaa972d24c
Author: David Gibson <david@gibson.dropbear.id.au>
Date:   Fri Jul 9 15:32:30 2010 +1000

    powerpc/book3e: Use set_irq_regs() in the msgsnd/msgrcv IPI path
    
    include/asm-generic/irq_regs.h declares per-cpu irq_regs variables and
    get_irq_regs() and set_irq_regs() helper functions to maintain them.
    These can be used to access the proper pt_regs structure related to the
    current interrupt entry (if any).
    
    In the powerpc arch code, this is used to maintain irq regs on
    decrementer and external interrupt exceptions.  However, for the
    doorbell exceptions used by the msgsnd/msgrcv IPI mechanism of newer
    BookE CPUs, the irq_regs are not kept up to date.
    
    In particular this means that xmon will not work properly on SMP,
    because the secondary xmon instances started by IPI will blow up when
    they cannot retrieve the irq regs.
    
    This patch fixes the problem by adding calls to maintain the irq regs
    across doorbell exceptions.
    
    Signed-off-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 1c7a94580c3f..f7b518894c80 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -16,6 +16,7 @@
 #include <linux/percpu.h>
 
 #include <asm/dbell.h>
+#include <asm/irq_regs.h>
 
 #ifdef CONFIG_SMP
 struct doorbell_cpu_info {
@@ -63,17 +64,21 @@ void doorbell_message_pass(int target, int msg)
 
 void doorbell_exception(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
 	int msg;
 
 	/* Warning: regs can be NULL when called from irq enable */
 
 	if (!info->messages || (num_online_cpus() < 2))
-		return;
+		goto out;
 
 	for (msg = 0; msg < 4; msg++)
 		if (test_and_clear_bit(msg, &info->messages))
 			smp_message_recv(msg);
+
+out:
+	set_irq_regs(old_regs);
 }
 
 #else /* CONFIG_SMP */

commit b9f1cd71dbf21a91fb7e2336a1d1ff18b97771e5
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:29:53 2010 +1000

    powerpc/book3e: More doorbell cleanups. Sample the PIR register
    
    The doorbells use the content of the PIR register to match messages
    from other CPUs. This may or may not be the same as our linux CPU
    number, so using that as the "target" is no right.
    
    Instead, we sample the PIR register at boot on every processor
    and use that value subsequently when sending IPIs.
    
    We also use a per-cpu message mask rather than a global array which
    should limit cache line contention.
    
    Note: We could use the CPU number in the device-tree instead of
    the PIR register, as they are supposed to be equivalent. This
    might prove useful if doorbells are to be used to kick CPUs out
    of FW at boot time, thus before we can sample the PIR. This is
    however not the case now and using the PIR just works.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index e3a717704fd6..1c7a94580c3f 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -13,45 +13,66 @@
 #include <linux/kernel.h>
 #include <linux/smp.h>
 #include <linux/threads.h>
+#include <linux/percpu.h>
 
 #include <asm/dbell.h>
 
 #ifdef CONFIG_SMP
-unsigned long dbell_smp_message[NR_CPUS];
+struct doorbell_cpu_info {
+	unsigned long	messages;	/* current messages bits */
+	unsigned int	tag;		/* tag value */
+};
 
-void smp_dbell_message_pass(int target, int msg)
+static DEFINE_PER_CPU(struct doorbell_cpu_info, doorbell_cpu_info);
+
+void doorbell_setup_this_cpu(void)
+{
+	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
+
+	info->messages = 0;
+	info->tag = mfspr(SPRN_PIR) & 0x3fff;
+}
+
+void doorbell_message_pass(int target, int msg)
 {
+	struct doorbell_cpu_info *info;
 	int i;
 
-	if(target < NR_CPUS) {
-		set_bit(msg, &dbell_smp_message[target]);
-		ppc_msgsnd(PPC_DBELL, 0, target);
+	if (target < NR_CPUS) {
+		info = &per_cpu(doorbell_cpu_info, target);
+		set_bit(msg, &info->messages);
+		ppc_msgsnd(PPC_DBELL, 0, info->tag);
 	}
-	else if(target == MSG_ALL_BUT_SELF) {
+	else if (target == MSG_ALL_BUT_SELF) {
 		for_each_online_cpu(i) {
 			if (i == smp_processor_id())
 				continue;
-			set_bit(msg, &dbell_smp_message[i]);
-			ppc_msgsnd(PPC_DBELL, 0, i);
+			info = &per_cpu(doorbell_cpu_info, i);
+			set_bit(msg, &info->messages);
+			ppc_msgsnd(PPC_DBELL, 0, info->tag);
 		}
 	}
 	else { /* target == MSG_ALL */
-		for_each_online_cpu(i)
-			set_bit(msg, &dbell_smp_message[i]);
+		for_each_online_cpu(i) {
+			info = &per_cpu(doorbell_cpu_info, i);
+			set_bit(msg, &info->messages);
+		}
 		ppc_msgsnd(PPC_DBELL, PPC_DBELL_MSG_BRDCAST, 0);
 	}
 }
 
 void doorbell_exception(struct pt_regs *regs)
 {
-	int cpu = smp_processor_id();
+	struct doorbell_cpu_info *info = &__get_cpu_var(doorbell_cpu_info);
 	int msg;
 
-	if (num_online_cpus() < 2)
+	/* Warning: regs can be NULL when called from irq enable */
+
+	if (!info->messages || (num_online_cpus() < 2))
 		return;
 
 	for (msg = 0; msg < 4; msg++)
-		if (test_and_clear_bit(msg, &dbell_smp_message[cpu]))
+		if (test_and_clear_bit(msg, &info->messages))
 			smp_message_recv(msg);
 }
 

commit e3145b387a02d4bf8b8033b1354d413fc0864494
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:25:18 2010 +1000

    powerpc/book3e: Move doorbell_exception from traps.c to dbell.c
    
    ... where it belongs
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
index 1493734cd871..e3a717704fd6 100644
--- a/arch/powerpc/kernel/dbell.c
+++ b/arch/powerpc/kernel/dbell.c
@@ -41,4 +41,24 @@ void smp_dbell_message_pass(int target, int msg)
 		ppc_msgsnd(PPC_DBELL, PPC_DBELL_MSG_BRDCAST, 0);
 	}
 }
-#endif
+
+void doorbell_exception(struct pt_regs *regs)
+{
+	int cpu = smp_processor_id();
+	int msg;
+
+	if (num_online_cpus() < 2)
+		return;
+
+	for (msg = 0; msg < 4; msg++)
+		if (test_and_clear_bit(msg, &dbell_smp_message[cpu]))
+			smp_message_recv(msg);
+}
+
+#else /* CONFIG_SMP */
+void doorbell_exception(struct pt_regs *regs)
+{
+	printk(KERN_WARNING "Received doorbell on non-smp system\n");
+}
+#endif /* CONFIG_SMP */
+

commit 620165f971753c2c451c880796bac7cd66f3534a
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Feb 12 13:54:53 2009 +0000

    powerpc: Add support for using doorbells for SMP IPI
    
    The e500mc supports the new msgsnd/doorbell mechanisms that were added in
    the Power ISA 2.05 architecture.  We use the normal level doorbell for
    doing SMP IPIs at this point.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/dbell.c b/arch/powerpc/kernel/dbell.c
new file mode 100644
index 000000000000..1493734cd871
--- /dev/null
+++ b/arch/powerpc/kernel/dbell.c
@@ -0,0 +1,44 @@
+/*
+ * Author: Kumar Gala <galak@kernel.crashing.org>
+ *
+ * Copyright 2009 Freescale Semiconductor Inc.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/stddef.h>
+#include <linux/kernel.h>
+#include <linux/smp.h>
+#include <linux/threads.h>
+
+#include <asm/dbell.h>
+
+#ifdef CONFIG_SMP
+unsigned long dbell_smp_message[NR_CPUS];
+
+void smp_dbell_message_pass(int target, int msg)
+{
+	int i;
+
+	if(target < NR_CPUS) {
+		set_bit(msg, &dbell_smp_message[target]);
+		ppc_msgsnd(PPC_DBELL, 0, target);
+	}
+	else if(target == MSG_ALL_BUT_SELF) {
+		for_each_online_cpu(i) {
+			if (i == smp_processor_id())
+				continue;
+			set_bit(msg, &dbell_smp_message[i]);
+			ppc_msgsnd(PPC_DBELL, 0, i);
+		}
+	}
+	else { /* target == MSG_ALL */
+		for_each_online_cpu(i)
+			set_bit(msg, &dbell_smp_message[i]);
+		ppc_msgsnd(PPC_DBELL, PPC_DBELL_MSG_BRDCAST, 0);
+	}
+}
+#endif
