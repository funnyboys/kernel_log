commit c5ff46d69c410f7fac173e4fde3eea484b4b4eda
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri May 22 23:33:18 2020 +1000

    powerpc: Add ppc_inst_next()
    
    In a few places we want to calculate the address of the next
    instruction. Previously that was simple, we just added 4 bytes, or if
    using a u32 * we incremented that pointer by 1.
    
    But prefixed instructions make it more complicated, we need to advance
    by either 4 or 8 bytes depending on the actual instruction. We also
    can't do pointer arithmetic using struct ppc_inst, because it is
    always 8 bytes in size on 64-bit, even though we might only need to
    advance by 4 bytes.
    
    So add a ppc_inst_next() helper which calculates the location of the
    next instruction, if the given instruction was located at the given
    address. Note the instruction doesn't need to actually be at the
    address in memory.
    
    Although it would seem natural for the value to be passed by value,
    that makes it too easy to write a loop that will read off the end of a
    page, eg:
    
            for (; src < end; src = ppc_inst_next(src, *src),
                              dest = ppc_inst_next(dest, *dest))
    
    As noticed by Christophe and Jordan, if end is the exact end of a
    page, and the next page is not mapped, this will fault, because *dest
    will read 8 bytes, 4 bytes into the next page.
    
    So value is passed by reference, so the helper can be careful to use
    ppc_inst_read() on it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Jordan Niethe <jniethe5@gmail.com>
    Link: https://lore.kernel.org/r/20200522133318.1681406-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 83e883e1a42d..d200e7df7167 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -112,7 +112,7 @@ int arch_uprobe_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	 * support doesn't exist and have to fix-up the next instruction
 	 * to be executed.
 	 */
-	regs->nip = utask->vaddr + ppc_inst_len(ppc_inst_read(&auprobe->insn));
+	regs->nip = (unsigned long)ppc_inst_next((void *)utask->vaddr, &auprobe->insn);
 
 	user_disable_single_step(current);
 	return 0;

commit 622cf6f436a12338bbcfbb3474629755547fd112
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:37 2020 +1000

    powerpc: Introduce a function for reporting instruction length
    
    Currently all instructions have the same length, but in preparation for
    prefixed instructions introduce a function for returning instruction
    length.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-18-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 6893d40a48c5..83e883e1a42d 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -112,7 +112,7 @@ int arch_uprobe_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	 * support doesn't exist and have to fix-up the next instruction
 	 * to be executed.
 	 */
-	regs->nip = utask->vaddr + MAX_UINSN_BYTES;
+	regs->nip = utask->vaddr + ppc_inst_len(ppc_inst_read(&auprobe->insn));
 
 	user_disable_single_step(current);
 	return 0;

commit f8faaffaa7d99028e457ef2d1dcb43a98f736938
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:32 2020 +1000

    powerpc: Use a function for reading instructions
    
    Prefixed instructions will mean there are instructions of different
    length. As a result dereferencing a pointer to an instruction will not
    necessarily give the desired result. Introduce a function for reading
    instructions from memory into the instruction data type.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-13-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 31c870287f2b..6893d40a48c5 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -174,7 +174,7 @@ bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	 * emulate_step() returns 1 if the insn was successfully emulated.
 	 * For all other cases, we need to single-step in hardware.
 	 */
-	ret = emulate_step(regs, auprobe->insn);
+	ret = emulate_step(regs, ppc_inst_read(&auprobe->insn));
 	if (ret > 0)
 		return true;
 

commit 753462512868674a788ecc77bb96752efb818785
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:26 2020 +1000

    powerpc: Use a macro for creating instructions from u32s
    
    In preparation for instructions having a more complex data type start
    using a macro, ppc_inst(), for making an instruction out of a u32.  A
    macro is used so that instructions can be used as initializer elements.
    Currently this does nothing, but it will allow for creating a data type
    that can represent prefixed instructions.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Change include guard to _ASM_POWERPC_INST_H]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-7-jniethe5@gmail.com

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 1cfef0e5fec5..31c870287f2b 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -14,6 +14,7 @@
 #include <linux/kdebug.h>
 
 #include <asm/sstep.h>
+#include <asm/inst.h>
 
 #define UPROBE_TRAP_NR	UINT_MAX
 

commit 1a59d1b8e05ea6ab45f7e18897de1ef0e6bc3da6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:05 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 156
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not write to the free software foundation inc
      59 temple place suite 330 boston ma 02111 1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1334 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.113240726@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 5d105b8eeece..1cfef0e5fec5 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -1,20 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * User-space Probes (UProbes) for powerpc
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
- *
  * Copyright IBM Corporation, 2007-2012
  *
  * Adapted from the x86 port by Ananth N Mavinakayanahalli <ananth@in.ibm.com>

commit 2dea1d9c38e481051fa0e62807e518c5768e62dd
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Jun 14 21:14:00 2017 +0530

    powerpc/uprobes: Implement arch_uretprobe_is_alive()
    
    This helper is used to detect if a uprobe'd function has returned
    through a setjmp/longjmp, rather than branching to the LR that was
    updated previously by us. This fixes a SIGSEGV that gets generated when
    programs use setjmp/longjmp with uretprobes.
    
    We use the arm64 model (arch/arm64/kernel/probes/uprobes.c:
    arch_uretprobe_is_alive()) for detecting when stack frames have been
    removed from under us.
    
    Reference:
    https://marc.info/?l=linux-kernel&m=143748610330073
    commit 7b868e4802a86 ("uprobes/x86: Reimplement arch_uretprobe_is_alive()")
    commit db087ef69a2b1 ("uprobes/x86: Make arch_uretprobe_is_alive(RP_CHECK_CALL) more
    clever")
    
    Tested with the test program from:
    https://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=testsuite/systemtap.base/bz5274.c;hb=HEAD
    
    And this script:
        $ cat test.sh
        #!/bin/bash
    
        perf probe -x ./bz5274 -a bz5274_main_return=main%return
        perf probe -x ./bz5274 -a bz5274_funca_return=funca%return
        perf probe -x ./bz5274 -a bz5274_funcb_return=funcb%return
        perf probe -x ./bz5274 -a bz5274_funcc_return=funcc%return
        perf probe -x ./bz5274 -a bz5274_funcd_return=funcd%return
    
        perf record -e 'probe_bz5274:*' -aR ./bz5274
    
    Reported-by: Gustavo Luiz Duarte <gduarte@redhat.com>
    Reported-by: zsun@redhat.com
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 003b20964ea0..5d105b8eeece 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -205,3 +205,12 @@ arch_uretprobe_hijack_return_addr(unsigned long trampoline_vaddr, struct pt_regs
 
 	return orig_ret_vaddr;
 }
+
+bool arch_uretprobe_is_alive(struct return_instance *ret, enum rp_check ctx,
+				struct pt_regs *regs)
+{
+	if (ctx == RP_CHECK_CHAIN_CALL)
+		return regs->gpr[1] <= ret->stack;
+	else
+		return regs->gpr[1] < ret->stack;
+}

commit 3d78e945b6249d4ef2308192343f8b203b1d7ea5
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Nov 9 18:44:19 2013 +0100

    uprobes/powerpc: Kill arch_uprobe->ainsn
    
    powerpc has both arch_uprobe->insn and arch_uprobe->ainsn to
    make the generic code happy. This is no longer needed after
    the previous change, powerpc can just use "u32 insn".
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Acked-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 59f419b935f2..003b20964ea0 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -186,7 +186,7 @@ bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	 * emulate_step() returns 1 if the insn was successfully emulated.
 	 * For all other cases, we need to single-step in hardware.
 	 */
-	ret = emulate_step(regs, auprobe->ainsn);
+	ret = emulate_step(regs, auprobe->insn);
 	if (ret > 0)
 		return true;
 

commit f15706b79d6f71e016cd06afa21ee31500029067
Author: Anton Arapov <anton@redhat.com>
Date:   Wed Apr 3 18:00:34 2013 +0200

    uretprobes/powerpc: Hijack return address
    
    Hijack the return address and replace it with a trampoline address.
    PowerPC implementation.
    
    Signed-off-by: Anton Arapov <anton@redhat.com>
    Acked-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index 2ecdbe304f46..59f419b935f2 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -192,3 +192,16 @@ bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 	return false;
 }
+
+unsigned long
+arch_uretprobe_hijack_return_addr(unsigned long trampoline_vaddr, struct pt_regs *regs)
+{
+	unsigned long orig_ret_vaddr;
+
+	orig_ret_vaddr = regs->link;
+
+	/* Replace the return addr with trampoline addr */
+	regs->link = trampoline_vaddr;
+
+	return orig_ret_vaddr;
+}

commit 3c9eb54f71fed86b761a6da4ad3eedc9566ceb8d
Author: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
Date:   Fri Mar 22 20:49:46 2013 +0530

    uprobes/powerpc: Remove additional trap instruction check
    
    prepare_uprobe() already checks if the underlying unstruction
    (on file) is a trap variant. We don't need to check this again.
    
    Signed-off-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index cb7f63da140c..2ecdbe304f46 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -53,12 +53,6 @@ int arch_uprobe_analyze_insn(struct arch_uprobe *auprobe,
 	if (addr & 0x03)
 		return -EINVAL;
 
-	/*
-	 * We currently don't support a uprobe on an already
-	 * existing breakpoint instruction underneath
-	 */
-	if (is_trap(auprobe->ainsn))
-		return -ENOTSUPP;
 	return 0;
 }
 

commit ab07e807be533d6317ea0971900bdf547962effd
Author: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
Date:   Fri Mar 22 20:48:38 2013 +0530

    uprobes/powerpc: Teach uprobes to ignore gdb breakpoints
    
    Powerpc has many trap variants that could be used by entities like gdb.
    Currently, running gdb on a program being traced by uprobes causes an
    endless loop since uprobes doesn't understand that the trap was inserted
    by some other entity and a SIGTRAP needs to be delivered.
    
    Teach uprobes to ignore breakpoints that do not belong to it.
    
    Signed-off-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index bc77834dbf43..cb7f63da140c 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -30,6 +30,16 @@
 
 #define UPROBE_TRAP_NR	UINT_MAX
 
+/**
+ * is_trap_insn - check if the instruction is a trap variant
+ * @insn: instruction to be checked.
+ * Returns true if @insn is a trap variant.
+ */
+bool is_trap_insn(uprobe_opcode_t *insn)
+{
+	return (is_trap(*insn));
+}
+
 /**
  * arch_uprobe_analyze_insn
  * @mm: the probed address space.

commit 65b2c8f0e53347583168423de0f32227d8baf01b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Oct 28 16:55:36 2012 +0100

    uprobes/powerpc: Do not use arch_uprobe_*_step() helpers
    
    No functional changes.
    
    powerpc is the only user of arch_uprobe_enable/disable_step() helpers,
    but they should die. They can not be used correctly, every arch needs
    its own implementation (like x86 does). And they do not really help
    even as initial-and-almost-working code, arch_uprobe_*_xol() hooks can
    easily use user_enable/disable_single_step() directly.
    
    Change arch_uprobe_*_step() to do nothing, and convert powerpc to use
    ptrace helpers. This is equally wrong, powerpc needs the arch-specific
    fixes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
index d2d46d1014f8..bc77834dbf43 100644
--- a/arch/powerpc/kernel/uprobes.c
+++ b/arch/powerpc/kernel/uprobes.c
@@ -64,6 +64,8 @@ int arch_uprobe_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	autask->saved_trap_nr = current->thread.trap_nr;
 	current->thread.trap_nr = UPROBE_TRAP_NR;
 	regs->nip = current->utask->xol_vaddr;
+
+	user_enable_single_step(current);
 	return 0;
 }
 
@@ -119,6 +121,8 @@ int arch_uprobe_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	 * to be executed.
 	 */
 	regs->nip = utask->vaddr + MAX_UINSN_BYTES;
+
+	user_disable_single_step(current);
 	return 0;
 }
 
@@ -162,6 +166,8 @@ void arch_uprobe_abort_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 	current->thread.trap_nr = utask->autask.saved_trap_nr;
 	instruction_pointer_set(regs, utask->vaddr);
+
+	user_disable_single_step(current);
 }
 
 /*

commit 8b7b80b9ebb46dd88fbb94e918297295cf312b59
Author: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
Date:   Thu Aug 23 21:31:32 2012 +0000

    powerpc: Uprobes port to powerpc
    
    This is the port of uprobes to powerpc. Usage is similar to x86.
    
    [root@xxxx ~]# ./bin/perf probe -x /lib64/libc.so.6 malloc
    Added new event:
      probe_libc:malloc    (on 0xb4860)
    
    You can now use it in all perf tools, such as:
    
            perf record -e probe_libc:malloc -aR sleep 1
    
    [root@xxxx ~]# ./bin/perf record -e probe_libc:malloc -aR sleep 20
    [ perf record: Woken up 22 times to write data ]
    [ perf record: Captured and wrote 5.843 MB perf.data (~255302 samples) ]
    [root@xxxx ~]# ./bin/perf report --stdio
    ...
    
        69.05%           tar  libc-2.12.so   [.] malloc
        28.57%            rm  libc-2.12.so   [.] malloc
         1.32%  avahi-daemon  libc-2.12.so   [.] malloc
         0.58%          bash  libc-2.12.so   [.] malloc
         0.28%          sshd  libc-2.12.so   [.] malloc
         0.08%    irqbalance  libc-2.12.so   [.] malloc
         0.05%         bzip2  libc-2.12.so   [.] malloc
         0.04%         sleep  libc-2.12.so   [.] malloc
         0.03%    multipathd  libc-2.12.so   [.] malloc
         0.01%      sendmail  libc-2.12.so   [.] malloc
         0.01%     automount  libc-2.12.so   [.] malloc
    
    The trap_nr addition patch is a prereq.
    
    Signed-off-by: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/uprobes.c b/arch/powerpc/kernel/uprobes.c
new file mode 100644
index 000000000000..d2d46d1014f8
--- /dev/null
+++ b/arch/powerpc/kernel/uprobes.c
@@ -0,0 +1,184 @@
+/*
+ * User-space Probes (UProbes) for powerpc
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ *
+ * Copyright IBM Corporation, 2007-2012
+ *
+ * Adapted from the x86 port by Ananth N Mavinakayanahalli <ananth@in.ibm.com>
+ */
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/ptrace.h>
+#include <linux/uprobes.h>
+#include <linux/uaccess.h>
+#include <linux/kdebug.h>
+
+#include <asm/sstep.h>
+
+#define UPROBE_TRAP_NR	UINT_MAX
+
+/**
+ * arch_uprobe_analyze_insn
+ * @mm: the probed address space.
+ * @arch_uprobe: the probepoint information.
+ * @addr: vaddr to probe.
+ * Return 0 on success or a -ve number on error.
+ */
+int arch_uprobe_analyze_insn(struct arch_uprobe *auprobe,
+		struct mm_struct *mm, unsigned long addr)
+{
+	if (addr & 0x03)
+		return -EINVAL;
+
+	/*
+	 * We currently don't support a uprobe on an already
+	 * existing breakpoint instruction underneath
+	 */
+	if (is_trap(auprobe->ainsn))
+		return -ENOTSUPP;
+	return 0;
+}
+
+/*
+ * arch_uprobe_pre_xol - prepare to execute out of line.
+ * @auprobe: the probepoint information.
+ * @regs: reflects the saved user state of current task.
+ */
+int arch_uprobe_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
+{
+	struct arch_uprobe_task *autask = &current->utask->autask;
+
+	autask->saved_trap_nr = current->thread.trap_nr;
+	current->thread.trap_nr = UPROBE_TRAP_NR;
+	regs->nip = current->utask->xol_vaddr;
+	return 0;
+}
+
+/**
+ * uprobe_get_swbp_addr - compute address of swbp given post-swbp regs
+ * @regs: Reflects the saved state of the task after it has hit a breakpoint
+ * instruction.
+ * Return the address of the breakpoint instruction.
+ */
+unsigned long uprobe_get_swbp_addr(struct pt_regs *regs)
+{
+	return instruction_pointer(regs);
+}
+
+/*
+ * If xol insn itself traps and generates a signal (SIGILL/SIGSEGV/etc),
+ * then detect the case where a singlestepped instruction jumps back to its
+ * own address. It is assumed that anything like do_page_fault/do_trap/etc
+ * sets thread.trap_nr != UINT_MAX.
+ *
+ * arch_uprobe_pre_xol/arch_uprobe_post_xol save/restore thread.trap_nr,
+ * arch_uprobe_xol_was_trapped() simply checks that ->trap_nr is not equal to
+ * UPROBE_TRAP_NR == UINT_MAX set by arch_uprobe_pre_xol().
+ */
+bool arch_uprobe_xol_was_trapped(struct task_struct *t)
+{
+	if (t->thread.trap_nr != UPROBE_TRAP_NR)
+		return true;
+
+	return false;
+}
+
+/*
+ * Called after single-stepping. To avoid the SMP problems that can
+ * occur when we temporarily put back the original opcode to
+ * single-step, we single-stepped a copy of the instruction.
+ *
+ * This function prepares to resume execution after the single-step.
+ */
+int arch_uprobe_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
+{
+	struct uprobe_task *utask = current->utask;
+
+	WARN_ON_ONCE(current->thread.trap_nr != UPROBE_TRAP_NR);
+
+	current->thread.trap_nr = utask->autask.saved_trap_nr;
+
+	/*
+	 * On powerpc, except for loads and stores, most instructions
+	 * including ones that alter code flow (branches, calls, returns)
+	 * are emulated in the kernel. We get here only if the emulation
+	 * support doesn't exist and have to fix-up the next instruction
+	 * to be executed.
+	 */
+	regs->nip = utask->vaddr + MAX_UINSN_BYTES;
+	return 0;
+}
+
+/* callback routine for handling exceptions. */
+int arch_uprobe_exception_notify(struct notifier_block *self,
+				unsigned long val, void *data)
+{
+	struct die_args *args = data;
+	struct pt_regs *regs = args->regs;
+
+	/* regs == NULL is a kernel bug */
+	if (WARN_ON(!regs))
+		return NOTIFY_DONE;
+
+	/* We are only interested in userspace traps */
+	if (!user_mode(regs))
+		return NOTIFY_DONE;
+
+	switch (val) {
+	case DIE_BPT:
+		if (uprobe_pre_sstep_notifier(regs))
+			return NOTIFY_STOP;
+		break;
+	case DIE_SSTEP:
+		if (uprobe_post_sstep_notifier(regs))
+			return NOTIFY_STOP;
+	default:
+		break;
+	}
+	return NOTIFY_DONE;
+}
+
+/*
+ * This function gets called when XOL instruction either gets trapped or
+ * the thread has a fatal signal, so reset the instruction pointer to its
+ * probed address.
+ */
+void arch_uprobe_abort_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
+{
+	struct uprobe_task *utask = current->utask;
+
+	current->thread.trap_nr = utask->autask.saved_trap_nr;
+	instruction_pointer_set(regs, utask->vaddr);
+}
+
+/*
+ * See if the instruction can be emulated.
+ * Returns true if instruction was emulated, false otherwise.
+ */
+bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
+{
+	int ret;
+
+	/*
+	 * emulate_step() returns 1 if the insn was successfully emulated.
+	 * For all other cases, we need to single-step in hardware.
+	 */
+	ret = emulate_step(regs, auprobe->ainsn);
+	if (ret > 0)
+		return true;
+
+	return false;
+}
