commit 7053f80d96967d8e72e9f2a724bbfc3906ce2b07
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Mar 20 14:21:16 2020 +1100

    powerpc/64: Prevent stack protection in early boot
    
    The previous commit reduced the amount of code that is run before we
    setup a paca. However there are still a few remaining functions that
    run with no paca, or worse, with an arbitrary value in r13 that will
    be used as a paca pointer.
    
    In particular the stack protector canary is stored in the paca, so if
    stack protector is activated for any of these functions we will read
    the stack canary from wherever r13 points. If r13 happens to point
    outside of memory we will get a machine check / checkstop.
    
    For example if we modify initialise_paca() to trigger stack
    protection, and then boot in the mambo simulator with r13 poisoned in
    skiboot before calling the kernel:
    
      DEBUG: 19952232: (19952232): INSTRUCTION: PC=0xC0000000191FC1E8: [0x3C4C006D]: addis   r2,r12,0x6D [fetch]
      DEBUG: 19952236: (19952236): INSTRUCTION: PC=0xC00000001807EAD8: [0x7D8802A6]: mflr    r12 [fetch]
      FATAL ERROR: 19952276: (19952276): Check Stop for 0:0: Machine Check with ME bit of MSR off
      DEBUG: 19952276: (19952276): INSTRUCTION: PC=0xC0000000191FCA7C: [0xE90D0CF8]: ld      r8,0xCF8(r13) [Instruction Failed]
      INFO: 19952276: (19952277): ** Execution stopped: Mambo Error, Machine Check Stop,  **
      systemsim % bt
      pc:                             0xC0000000191FCA7C      initialise_paca+0x54
      lr:                             0xC0000000191FC22C      early_setup+0x44
      stack:0x00000000198CBED0        0x0     +0x0
      stack:0x00000000198CBF00        0xC0000000191FC22C      early_setup+0x44
      stack:0x00000000198CBF90        0x1801C968      +0x1801C968
    
    So annotate the relevant functions to ensure stack protection is never
    enabled for them.
    
    Fixes: 06ec27aea9fc ("powerpc/64: add stack protector support")
    Cc: stable@vger.kernel.org # v4.20+
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200320032116.1024773-2-mpe@ellerman.id.au

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index 2dd0d9cb5a20..2ec835574cc9 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -8,6 +8,12 @@
 #ifndef __ARCH_POWERPC_KERNEL_SETUP_H
 #define __ARCH_POWERPC_KERNEL_SETUP_H
 
+#ifdef CONFIG_CC_IS_CLANG
+#define __nostackprotector
+#else
+#define __nostackprotector __attribute__((__optimize__("no-stack-protector")))
+#endif
+
 void initialize_cache_info(void);
 void irqstack_early_init(void);
 

commit 3978eb78517c1fc06dd75405d732af45c80f5bd2
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Dec 21 08:32:29 2019 +0000

    powerpc/32: Add early stack overflow detection with VMAP stack.
    
    To avoid recursive faults, stack overflow detection has to be
    performed before writing in the stack in exception prologs.
    
    Do it by checking the alignment. If the stack pointer alignment is
    wrong, it means it is pointing to the following or preceding page.
    
    Without VMAP stack, a stack overflow is catastrophic. With VMAP
    stack, a stack overflow isn't destructive, so don't panic. Kill
    the task with SIGSEGV instead.
    
    A dedicated overflow stack is set up for each CPU.
    
      lkdtm: Performing direct entry EXHAUST_STACK
      lkdtm: Calling function with 512 frame size to depth 32 ...
      lkdtm: loop 32/32 ...
      lkdtm: loop 31/32 ...
      lkdtm: loop 30/32 ...
      lkdtm: loop 29/32 ...
      lkdtm: loop 28/32 ...
      lkdtm: loop 27/32 ...
      lkdtm: loop 26/32 ...
      lkdtm: loop 25/32 ...
      lkdtm: loop 24/32 ...
      lkdtm: loop 23/32 ...
      lkdtm: loop 22/32 ...
      lkdtm: loop 21/32 ...
      lkdtm: loop 20/32 ...
      Kernel stack overflow in process test[359], r1=c900c008
      Oops: Kernel stack overflow, sig: 6 [#1]
      BE PAGE_SIZE=4K MMU=Hash PowerMac
      Modules linked in:
      CPU: 0 PID: 359 Comm: test Not tainted 5.3.0-rc7+ #2225
      NIP:  c0622060 LR: c0626710 CTR: 00000000
      REGS: c0895f48 TRAP: 0000   Not tainted  (5.3.0-rc7+)
      MSR:  00001032 <ME,IR,DR,RI>  CR: 28004224  XER: 00000000
      GPR00: c0626ca4 c900c008 c783c000 c07335cc c900c010 c07335cc c900c0f0 c07335cc
      GPR08: c900c0f0 00000001 00000000 00000000 28008222 00000000 00000000 00000000
      GPR16: 00000000 00000000 10010128 10010000 b799c245 10010158 c07335cc 00000025
      GPR24: c0690000 c08b91d4 c068f688 00000020 c900c0f0 c068f668 c08b95b4 c08b91d4
      NIP [c0622060] format_decode+0x0/0x4d4
      LR [c0626710] vsnprintf+0x80/0x5fc
      Call Trace:
      [c900c068] [c0626ca4] vscnprintf+0x18/0x48
      [c900c078] [c007b944] vprintk_store+0x40/0x214
      [c900c0b8] [c007bf50] vprintk_emit+0x90/0x1dc
      [c900c0e8] [c007c5cc] printk+0x50/0x60
      [c900c128] [c03da5b0] recursive_loop+0x44/0x6c
      [c900c338] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c548] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c758] [c03da5c4] recursive_loop+0x58/0x6c
      [c900c968] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cb78] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cd88] [c03da5c4] recursive_loop+0x58/0x6c
      [c900cf98] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d1a8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d3b8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d5c8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d7d8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900d9e8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900dbf8] [c03da5c4] recursive_loop+0x58/0x6c
      [c900de08] [c03da67c] lkdtm_EXHAUST_STACK+0x30/0x4c
      [c900de18] [c03da3e8] direct_entry+0xc8/0x140
      [c900de48] [c029fb40] full_proxy_write+0x64/0xcc
      [c900de68] [c01500f8] __vfs_write+0x30/0x1d0
      [c900dee8] [c0152cb8] vfs_write+0xb8/0x1d4
      [c900df08] [c0152f7c] ksys_write+0x58/0xe8
      [c900df38] [c0014208] ret_from_syscall+0x0/0x34
      --- interrupt: c01 at 0xf806664
          LR = 0x1000c868
      Instruction dump:
      4bffff91 80010014 7c832378 7c0803a6 38210010 4e800020 3d20c08a 3ca0c089
      8089a0cc 38a58f0c 38600001 4ba2d494 <9421ffe0> 7c0802a6 bfc10018 7c9f2378
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1b89c121b4070c7ee99e4f22cc178f15a736b07b.1576916812.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index c82577c4b15d..2dd0d9cb5a20 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -35,7 +35,7 @@ void exc_lvl_early_init(void);
 static inline void exc_lvl_early_init(void) { };
 #endif
 
-#ifdef CONFIG_PPC64
+#if defined(CONFIG_PPC64) || defined(CONFIG_VMAP_STACK)
 void emergency_stack_init(void);
 #else
 static inline void emergency_stack_init(void) { };

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index c6a592b67386..c82577c4b15d 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -1,12 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Prototypes for functions that are shared between setup_(32|64|common).c
  *
  * Copyright 2016 Michael Ellerman, IBM Corporation.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #ifndef __ARCH_POWERPC_KERNEL_SETUP_H

commit bd13ac95f954570e01fba5a6caf771da754ac0e3
Author: Mathieu Malaterre <malat@debian.org>
Date:   Wed Apr 4 22:10:28 2018 +0200

    powerpc/tau: Synchronize function prototypes and body
    
    Some function prototypes and body for Thermal Assist Units were not in
    sync. Update the function definition to match the existing function
    declaration found in `setup-common.c`, changing an `int` return type to a
    `u32` return type. Move the prototypes to a header file. Fix the following
    warnings, treated as error with W=1:
    
      arch/powerpc/kernel/tau_6xx.c:257:5: error: no previous prototype for ‘cpu_temp_both’ [-Werror=missing-prototypes]
      arch/powerpc/kernel/tau_6xx.c:262:5: error: no previous prototype for ‘cpu_temp’ [-Werror=missing-prototypes]
      arch/powerpc/kernel/tau_6xx.c:267:5: error: no previous prototype for ‘tau_interrupts’ [-Werror=missing-prototypes]
    
    Compile tested with CONFIG_TAU_INT.
    
    Suggested-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index d144df54ad40..c6a592b67386 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -62,4 +62,10 @@ void kvm_cma_reserve(void);
 static inline void kvm_cma_reserve(void) { };
 #endif
 
+#ifdef CONFIG_TAU
+u32 cpu_temp(unsigned long cpu);
+u32 cpu_temp_both(unsigned long cpu);
+u32 tau_interrupts(unsigned long cpu);
+#endif /* CONFIG_TAU */
+
 #endif /* __ARCH_POWERPC_KERNEL_SETUP_H */

commit c0abd0c745bdabe027a8f013a866f385fba717b1
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 14 01:08:17 2018 +1000

    powerpc/64: move default SPR recording
    
    Move this into the early setup code, and don't iterate over CPU masks.
    We don't want to call into sysfs so early from setup, and a future patch
    won't initialize CPU masks by the time this is called.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Fold in incremental fix from Nick for DSCR handling]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index 3fc11e30308f..d144df54ad40 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -45,14 +45,11 @@ void emergency_stack_init(void);
 static inline void emergency_stack_init(void) { };
 #endif
 
-#ifdef CONFIG_PPC64
-void record_spr_defaults(void);
-#else
-static inline void record_spr_defaults(void) { };
-#endif
-
 #ifdef CONFIG_PPC64
 u64 ppc64_bolted_size(void);
+
+/* Default SPR values from firmware/kexec */
+extern unsigned long spr_default_dscr;
 #endif
 
 /*

commit 1af19331a3a18296a918802dbe032a13328e264d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Dec 22 21:17:13 2017 +1000

    powerpc/64s: Relax PACA address limitations
    
    Book3S PACA memory allocation is restricted by the RMA limit and also
    must not take SLB faults when accessed in virtual mode. Currently a
    fixed 256MB limit is used for this, which is imprecise and sub-optimal.
    
    Update the paca allocation limits to use use the ppc64_rma_size for RMA
    limit, and share the safe_stack_limit() that is currently used for stack
    allocations that must not take virtual mode faults.
    
    The safe_stack_limit() name is changed to ppc64_bolted_size() to match
    ppc64_rma_size and some comments are updated. We also need to use
    early_mmu_has_feature() because we are now calling this function prior
    to the jump label patching that enables mmu_has_feature().
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Change mmu_has_feature() to early_mmu_has_feature()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index 21c18071d9d5..3fc11e30308f 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -51,6 +51,10 @@ void record_spr_defaults(void);
 static inline void record_spr_defaults(void) { };
 #endif
 
+#ifdef CONFIG_PPC64
+u64 ppc64_bolted_size(void);
+#endif
+
 /*
  * Having this in kvm_ppc.h makes include dependencies too
  * tricky to solve for setup-common.c so have it here.

commit 1696d0fb7fcd18160c9cc92a3f2b2d68e6923dd8
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Oct 24 21:44:44 2017 +1000

    powerpc/64: Set DSCR default initially from SPR
    
    Take the DSCR value set by firmware as the dscr_default value,
    rather than zero.
    
    POWER9 recommends DSCR default to a non-zero value.
    
    Signed-off-by: From: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make record_spr_defaults() __init]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index cfba134b3024..21c18071d9d5 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -45,6 +45,12 @@ void emergency_stack_init(void);
 static inline void emergency_stack_init(void) { };
 #endif
 
+#ifdef CONFIG_PPC64
+void record_spr_defaults(void);
+#else
+static inline void record_spr_defaults(void) { };
+#endif
+
 /*
  * Having this in kvm_ppc.h makes include dependencies too
  * tricky to solve for setup-common.c so have it here.

commit b1923caa6e641f3d0a93b5d045aef67ded5aef67
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 5 15:07:51 2016 +1000

    powerpc: Merge 32-bit and 64-bit setup_arch()
    
    There is little enough differences now.
    
    mpe: Add a/p/k/setup.h to contain the prototypes and empty versions of
    functions we need, rather than using weak functions. Add a few other
    empty versions to avoid as many #ifdefs as possible in the code.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
new file mode 100644
index 000000000000..cfba134b3024
--- /dev/null
+++ b/arch/powerpc/kernel/setup.h
@@ -0,0 +1,58 @@
+/*
+ * Prototypes for functions that are shared between setup_(32|64|common).c
+ *
+ * Copyright 2016 Michael Ellerman, IBM Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#ifndef __ARCH_POWERPC_KERNEL_SETUP_H
+#define __ARCH_POWERPC_KERNEL_SETUP_H
+
+void initialize_cache_info(void);
+void irqstack_early_init(void);
+
+#ifdef CONFIG_PPC32
+void setup_power_save(void);
+#else
+static inline void setup_power_save(void) { };
+#endif
+
+#if defined(CONFIG_PPC64) && defined(CONFIG_SMP)
+void check_smt_enabled(void);
+#else
+static inline void check_smt_enabled(void) { };
+#endif
+
+#if defined(CONFIG_PPC_BOOK3E) && defined(CONFIG_SMP)
+void setup_tlb_core_data(void);
+#else
+static inline void setup_tlb_core_data(void) { };
+#endif
+
+#if defined(CONFIG_PPC_BOOK3E) || defined(CONFIG_BOOKE) || defined(CONFIG_40x)
+void exc_lvl_early_init(void);
+#else
+static inline void exc_lvl_early_init(void) { };
+#endif
+
+#ifdef CONFIG_PPC64
+void emergency_stack_init(void);
+#else
+static inline void emergency_stack_init(void) { };
+#endif
+
+/*
+ * Having this in kvm_ppc.h makes include dependencies too
+ * tricky to solve for setup-common.c so have it here.
+ */
+#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+void kvm_cma_reserve(void);
+#else
+static inline void kvm_cma_reserve(void) { };
+#endif
+
+#endif /* __ARCH_POWERPC_KERNEL_SETUP_H */

commit b88c4767d9e2290aaa22b8b3702ad72af0ebd113
Author: Robert Jennings <rcj@linux.vnet.ibm.com>
Date:   Mon Oct 28 09:20:51 2013 -0500

    powerpc: Move local setup.h declarations to arch includes
    
    Move the few declarations from arch/powerpc/kernel/setup.h
    into arch/powerpc/include/asm/setup.h.  This resolves a
    sparse warning for arch/powerpc/mm/numa.c which defines
    do_init_bootmem() but can't include the setup.h header
    in the prior path.
    
    Resolves:
    arch/powerpc/mm/numa.c:998:13:
            warning: symbol 'do_init_bootmem' was not declared.
                     Should it be static?
    
    Signed-off-by: Robert C Jennings <rcj@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
deleted file mode 100644
index 4c67ad7fae08..000000000000
--- a/arch/powerpc/kernel/setup.h
+++ /dev/null
@@ -1,9 +0,0 @@
-#ifndef _POWERPC_KERNEL_SETUP_H
-#define _POWERPC_KERNEL_SETUP_H
-
-void check_for_initrd(void);
-void do_init_bootmem(void);
-void setup_panic(void);
-extern int do_early_xmon;
-
-#endif /* _POWERPC_KERNEL_SETUP_H */

commit 480f6f35a149802a94ad5c1a2673ed6ec8d2c158
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed May 17 18:00:41 2006 +1000

    [PATCH] powerpc: Make early xmon logic immune to location of early parsing
    
    Currently early_xmon() calls directly into debugger() if xmon=early is passed.
    This ties the invocation of early xmon to the location of parse_early_param(),
    which might change.
    
    Tested on P5 LPAR and F50.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index e67066c1933e..4c67ad7fae08 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -4,5 +4,6 @@
 void check_for_initrd(void);
 void do_init_bootmem(void);
 void setup_panic(void);
+extern int do_early_xmon;
 
 #endif /* _POWERPC_KERNEL_SETUP_H */

commit 7e990266c845d7f712c96013891aaf74baef198f
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Fri May 5 00:02:08 2006 -0500

    powerpc: provide ppc_md.panic() for both ppc32 & ppc64
    
    Allow boards to provide a panic callback on ppc32.  Moved the code to sets
    this up into setup-common.c so its shared between ppc32 & ppc64.  Also moved
    do_init_bootmem prototype into setup.h.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
index 2ebba755272e..e67066c1933e 100644
--- a/arch/powerpc/kernel/setup.h
+++ b/arch/powerpc/kernel/setup.h
@@ -2,5 +2,7 @@
 #define _POWERPC_KERNEL_SETUP_H
 
 void check_for_initrd(void);
+void do_init_bootmem(void);
+void setup_panic(void);
 
 #endif /* _POWERPC_KERNEL_SETUP_H */

commit 66ba135c5a398df5c3a4b43d84d9df80cbc87c61
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Nov 9 11:01:06 2005 +1100

    powerpc: create kernel/setup.h
    
    for functions defined by setup-common.c and used in setup_xx.c
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/powerpc/kernel/setup.h b/arch/powerpc/kernel/setup.h
new file mode 100644
index 000000000000..2ebba755272e
--- /dev/null
+++ b/arch/powerpc/kernel/setup.h
@@ -0,0 +1,6 @@
+#ifndef _POWERPC_KERNEL_SETUP_H
+#define _POWERPC_KERNEL_SETUP_H
+
+void check_for_initrd(void);
+
+#endif /* _POWERPC_KERNEL_SETUP_H */
