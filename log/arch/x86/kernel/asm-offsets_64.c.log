commit fd501d4f0399700011acde486576c7c1eb8e7a61
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri May 29 23:27:38 2020 +0200

    x86/entry: Remove DBn stacks
    
    Both #DB itself, as all other IST users (NMI, #MC) now clear DR7 on
    entry. Combined with not allowing breakpoints on entry/noinstr/NOKPROBE
    text and no single step (EFLAGS.TF) inside the #DB handler should guarantee
    no nested #DB.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20200529213321.303027161@infradead.org

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index c2a47016f243..828be792231e 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -57,9 +57,6 @@ int main(void)
 	BLANK();
 #undef ENTRY
 
-	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
-	DEFINE(DB_STACK_OFFSET, offsetof(struct cea_exception_stacks, DB_stack) -
-	       offsetof(struct cea_exception_stacks, DB1_stack));
 	BLANK();
 
 #ifdef CONFIG_STACKPROTECTOR

commit 0872098804b5f44bab91f80b6df55df32894fee3
Author: Brian Gerst <brgerst@gmail.com>
Date:   Fri Mar 13 15:51:34 2020 -0400

    x86/entry: Move max syscall number calculation to syscallhdr.sh
    
    Instead of using an array in asm-offsets to calculate the max syscall
    number, calculate it when writing out the syscall headers.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20200313195144.164260-9-brgerst@gmail.com

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 24d2fde30d00..c2a47016f243 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -5,30 +5,6 @@
 
 #include <asm/ia32.h>
 
-#define __SYSCALL_64(nr, sym, qual) [nr] = 1,
-#define __SYSCALL_X32(nr, sym, qual)
-static char syscalls_64[] = {
-#include <asm/syscalls_64.h>
-};
-#undef __SYSCALL_64
-#undef __SYSCALL_X32
-
-#ifdef CONFIG_X86_X32_ABI
-#define __SYSCALL_64(nr, sym, qual)
-#define __SYSCALL_X32(nr, sym, qual) [nr] = 1,
-static char syscalls_x32[] = {
-#include <asm/syscalls_64.h>
-};
-#undef __SYSCALL_64
-#undef __SYSCALL_X32
-#endif
-
-#define __SYSCALL_I386(nr, sym, qual) [nr] = 1,
-static char syscalls_ia32[] = {
-#include <asm/syscalls_32.h>
-};
-#undef __SYSCALL_I386
-
 #if defined(CONFIG_KVM_GUEST) && defined(CONFIG_PARAVIRT_SPINLOCKS)
 #include <asm/kvm_para.h>
 #endif
@@ -90,17 +66,5 @@ int main(void)
 	DEFINE(stack_canary_offset, offsetof(struct fixed_percpu_data, stack_canary));
 	BLANK();
 #endif
-
-	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
-	DEFINE(NR_syscalls, sizeof(syscalls_64));
-
-#ifdef CONFIG_X86_X32_ABI
-	DEFINE(__NR_syscall_x32_max, sizeof(syscalls_x32) - 1);
-	DEFINE(X32_NR_syscalls, sizeof(syscalls_x32));
-#endif
-
-	DEFINE(__NR_syscall_compat_max, sizeof(syscalls_ia32) - 1);
-	DEFINE(IA32_NR_syscalls, sizeof(syscalls_ia32));
-
 	return 0;
 }

commit c5f12fdb8bd873aa3ffdb79512e6bdac92b257b0
Merge: a572ba63298d 743dac494d61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 17 12:04:39 2019 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 apic updates from Thomas Gleixner:
    
     - Cleanup the apic IPI implementation by removing duplicated code and
       consolidating the functions into the APIC core.
    
     - Implement a safe variant of the IPI broadcast mode. Contrary to
       earlier attempts this uses the core tracking of which CPUs have been
       brought online at least once so that a broadcast does not end up in
       some dead end in BIOS/SMM code when the CPU is still waiting for
       init. Once all CPUs have been brought up once, IPI broadcasting is
       enabled. Before that regular one by one IPIs are issued.
    
     - Drop the paravirt CR8 related functions as they have no user anymore
    
     - Initialize the APIC TPR to block interrupt 16-31 as they are reserved
       for CPU exceptions and should never be raised by any well behaving
       device.
    
     - Emit a warning when vector space exhaustion breaks the admin set
       affinity of an interrupt.
    
     - Make sure to use the NMI fallback when shutdown via reboot vector IPI
       fails. The original code had conditions which prevent the code path
       to be reached.
    
     - Annotate various APIC config variables as RO after init.
    
    [ The ipi broadcase change came in earlier through the cpu hotplug
      branch, but I left the explanation in the commit message since it was
      shared between the two different branches    - Linus ]
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (28 commits)
      x86/apic/vector: Warn when vector space exhaustion breaks affinity
      x86/apic: Annotate global config variables as "read-only after init"
      x86/apic/x2apic: Implement IPI shorthands support
      x86/apic/flat64: Remove the IPI shorthand decision logic
      x86/apic: Share common IPI helpers
      x86/apic: Remove the shorthand decision logic
      x86/smp: Enhance native_send_call_func_ipi()
      x86/smp: Move smp_function_call implementations into IPI code
      x86/apic: Provide and use helper for send_IPI_allbutself()
      x86/apic: Add static key to Control IPI shorthands
      x86/apic: Move no_ipi_broadcast() out of 32bit
      x86/apic: Add NMI_VECTOR wait to IPI shorthand
      x86/apic: Remove dest argument from __default_send_IPI_shortcut()
      x86/hotplug: Silence APIC and NMI when CPU is dead
      x86/cpu: Move arch_smt_update() to a neutral place
      x86/apic/uv: Make x2apic_extra_bits static
      x86/apic: Consolidate the apic local headers
      x86/apic: Move apic_flat_64 header into apic directory
      x86/apic: Move ipi header into apic directory
      x86/apic: Cleanup the include maze
      ...

commit 6365b842aae4490ebfafadfc6bb27a6d3cc54757
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Jul 3 13:34:04 2019 -0700

    x86/syscalls: Split the x32 syscalls into their own table
    
    For unfortunate historical reasons, the x32 syscalls and the x86_64
    syscalls are not all numbered the same.  As an example, ioctl() is nr 16 on
    x86_64 but 514 on x32.
    
    This has potentially nasty consequences, since it means that there are two
    valid RAX values to do ioctl(2) and two invalid RAX values.  The valid
    values are 16 (i.e. ioctl(2) using the x86_64 ABI) and (514 | 0x40000000)
    (i.e. ioctl(2) using the x32 ABI).
    
    The invalid values are 514 and (16 | 0x40000000).  514 will enter the
    "COMPAT_SYSCALL_DEFINE3(ioctl, ...)" entry point with in_compat_syscall()
    and in_x32_syscall() returning false, whereas (16 | 0x40000000) will enter
    the native entry point with in_compat_syscall() and in_x32_syscall()
    returning true.  Both are bogus, and both will exercise code paths in the
    kernel and in any running seccomp filters that really ought to be
    unreachable.
    
    Splitting out the x32 syscalls into their own tables, allows both bogus
    invocations to return -ENOSYS.  I've checked glibc, musl, and Bionic, and
    all of them appear to call syscalls with their correct numbers, so this
    change should have no effect on them.
    
    There is an added benefit going forward: new syscalls that need special
    handling on x32 can share the same number on x32 and x86_64.  This means
    that the special syscall range 512-547 can be treated as a legacy wart
    instead of something that may need to be extended in the future.
    
    Also add a selftest to verify the new behavior.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/208024256b764312598f014ebfb0a42472c19354.1562185330.git.luto@kernel.org

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index d3d075226c0a..70e97727a26a 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -6,13 +6,28 @@
 #include <asm/ia32.h>
 
 #define __SYSCALL_64(nr, sym, qual) [nr] = 1,
+#define __SYSCALL_X32(nr, sym, qual)
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };
+#undef __SYSCALL_64
+#undef __SYSCALL_X32
+
+#ifdef CONFIG_X86_X32_ABI
+#define __SYSCALL_64(nr, sym, qual)
+#define __SYSCALL_X32(nr, sym, qual) [nr] = 1,
+static char syscalls_x32[] = {
+#include <asm/syscalls_64.h>
+};
+#undef __SYSCALL_64
+#undef __SYSCALL_X32
+#endif
+
 #define __SYSCALL_I386(nr, sym, qual) [nr] = 1,
 static char syscalls_ia32[] = {
 #include <asm/syscalls_32.h>
 };
+#undef __SYSCALL_I386
 
 #if defined(CONFIG_KVM_GUEST) && defined(CONFIG_PARAVIRT_SPINLOCKS)
 #include <asm/kvm_para.h>
@@ -80,6 +95,11 @@ int main(void)
 	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
 	DEFINE(NR_syscalls, sizeof(syscalls_64));
 
+#ifdef CONFIG_X86_X32_ABI
+	DEFINE(__NR_syscall_x32_max, sizeof(syscalls_x32) - 1);
+	DEFINE(X32_NR_syscalls, sizeof(syscalls_x32));
+#endif
+
 	DEFINE(__NR_syscall_compat_max, sizeof(syscalls_ia32) - 1);
 	DEFINE(IA32_NR_syscalls, sizeof(syscalls_ia32));
 

commit 83b584d9c6a1494170abd3a8b24f41939b23d625
Author: Andrew Cooper <andrew.cooper3@citrix.com>
Date:   Mon Jul 15 16:16:41 2019 +0100

    x86/paravirt: Drop {read,write}_cr8() hooks
    
    There is a lot of infrastructure for functionality which is used
    exclusively in __{save,restore}_processor_state() on the suspend/resume
    path.
    
    cr8 is an alias of APIC_TASKPRI, and APIC_TASKPRI is saved/restored by
    lapic_{suspend,resume}().  Saving and restoring cr8 independently of the
    rest of the Local APIC state isn't a clever thing to be doing.
    
    Delete the suspend/resume cr8 handling, which shrinks the size of struct
    saved_context, and allows for the removal of both PVOPS.
    
    Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Juergen Gross <jgross@suse.com>
    Link: https://lkml.kernel.org/r/20190715151641.29210-1-andrew.cooper3@citrix.com

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index d3d075226c0a..8b54d8e3a561 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -62,7 +62,6 @@ int main(void)
 	ENTRY(cr2);
 	ENTRY(cr3);
 	ENTRY(cr4);
-	ENTRY(cr8);
 	ENTRY(gdt_desc);
 	BLANK();
 #undef ENTRY

commit e6401c13093173aad709a5c6de00cf8d692ee786
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sun Apr 14 18:00:06 2019 +0200

    x86/irq/64: Split the IRQ stack into its own pages
    
    Currently, the IRQ stack is hardcoded as the first page of the percpu
    area, and the stack canary lives on the IRQ stack. The former gets in
    the way of adding an IRQ stack guard page, and the latter is a potential
    weakness in the stack canary mechanism.
    
    Split the IRQ stack into its own private percpu pages.
    
    [ tglx: Make 64 and 32 bit share struct irq_stack ]
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: "Chang S. Bae" <chang.seok.bae@intel.com>
    Cc: Dominik Brodowski <linux@dominikbrodowski.net>
    Cc: Feng Tang <feng.tang@intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jan Beulich <JBeulich@suse.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Jordan Borgner <mail@jordan-borgner.de>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Maran Wilson <maran.wilson@oracle.com>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Pu Wen <puwen@hygon.cn>
    Cc: "Rafael Ávila de Espíndola" <rafael@espindo.la>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: Stefano Stabellini <sstabellini@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: x86-ml <x86@kernel.org>
    Cc: xen-devel@lists.xenproject.org
    Link: https://lkml.kernel.org/r/20190414160146.267376656@linutronix.de

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index f5281567e28e..d3d075226c0a 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -73,7 +73,7 @@ int main(void)
 	BLANK();
 
 #ifdef CONFIG_STACKPROTECTOR
-	DEFINE(stack_canary_offset, offsetof(union irq_stack_union, stack_canary));
+	DEFINE(stack_canary_offset, offsetof(struct fixed_percpu_data, stack_canary));
 	BLANK();
 #endif
 

commit 2a594d4ccf3f10f80b77d71bd3dad10813ac0137
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Apr 14 17:59:57 2019 +0200

    x86/exceptions: Split debug IST stack
    
    The debug IST stack is actually two separate debug stacks to handle #DB
    recursion. This is required because the CPU starts always at top of stack
    on exception entry, which means on #DB recursion the second #DB would
    overwrite the stack of the first.
    
    The low level entry code therefore adjusts the top of stack on entry so a
    secondary #DB starts from a different stack page. But the stack pages are
    adjacent without a guard page between them.
    
    Split the debug stack into 3 stacks which are separated by guard pages. The
    3rd stack is never mapped into the cpu_entry_area and is only there to
    catch triple #DB nesting:
    
          --- top of DB_stack       <- Initial stack
          --- end of DB_stack
              guard page
    
          --- top of DB1_stack      <- Top of stack after entering first #DB
          --- end of DB1_stack
              guard page
    
          --- top of DB2_stack      <- Top of stack after entering second #DB
          --- end of DB2_stack
              guard page
    
    If DB2 would not act as the final guard hole, a second #DB would point the
    top of #DB stack to the stack below #DB1 which would be valid and not catch
    the not so desired triple nesting.
    
    The backing store does not allocate any memory for DB2 and its guard page
    as it is not going to be mapped into the cpu_entry_area.
    
     - Adjust the low level entry code so it adjusts top of #DB with the offset
       between the stacks instead of exception stack size.
    
     - Make the dumpstack code aware of the new stacks.
    
     - Adjust the in_debug_stack() implementation and move it into the NMI code
       where it belongs. As this is NMI hotpath code, it just checks the full
       area between top of DB_stack and bottom of DB1_stack without checking
       for the guard page. That's correct because the NMI cannot hit a
       stackpointer pointing to the guard page between DB and DB1 stack.  Even
       if it would, then the NMI operation still is unaffected, but the resume
       of the debug exception on the topmost DB stack will crash by touching
       the guard page.
    
      [ bp: Make exception_stack_names static const char * const ]
    
    Suggested-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: "Chang S. Bae" <chang.seok.bae@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dominik Brodowski <linux@dominikbrodowski.net>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: linux-doc@vger.kernel.org
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Qian Cai <cai@lca.pw>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20190414160145.439944544@linutronix.de

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index ddced33184b5..f5281567e28e 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -68,6 +68,8 @@ int main(void)
 #undef ENTRY
 
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
+	DEFINE(DB_STACK_OFFSET, offsetof(struct cea_exception_stacks, DB_stack) -
+	       offsetof(struct cea_exception_stacks, DB1_stack));
 	BLANK();
 
 #ifdef CONFIG_STACKPROTECTOR

commit 6da63eb241a05b0e676d68975e793c0521387141
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:24 2018 +0200

    x86/paravirt: Move the pv_irq_ops under the PARAVIRT_XXL umbrella
    
    All of the paravirt ops defined in pv_irq_ops are for Xen PV guests
    or VSMP only. Define them only if CONFIG_PARAVIRT_XXL is set.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-14-jgross@suse.com

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 2a15d420a84d..ddced33184b5 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -25,9 +25,9 @@ int main(void)
 	OFFSET(PV_CPU_usergs_sysret64, paravirt_patch_template,
 	       cpu.usergs_sysret64);
 	OFFSET(PV_CPU_swapgs, paravirt_patch_template, cpu.swapgs);
-#endif
 #ifdef CONFIG_DEBUG_ENTRY
 	OFFSET(PV_IRQ_save_fl, paravirt_patch_template, irq.save_fl);
+#endif
 #endif
 	BLANK();
 #endif

commit 9bad5658ea710f45e4ee68b88a01cfe1839d8b00
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:23 2018 +0200

    x86/paravirt: Move the Xen-only pv_cpu_ops under the PARAVIRT_XXL umbrella
    
    Most of the paravirt ops defined in pv_cpu_ops are for Xen PV guests
    only. Define them only if CONFIG_PARAVIRT_XXL is set.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-13-jgross@suse.com

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 3384b03e717f..2a15d420a84d 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -21,9 +21,11 @@ static char syscalls_ia32[] = {
 int main(void)
 {
 #ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_XXL
 	OFFSET(PV_CPU_usergs_sysret64, paravirt_patch_template,
 	       cpu.usergs_sysret64);
 	OFFSET(PV_CPU_swapgs, paravirt_patch_template, cpu.swapgs);
+#endif
 #ifdef CONFIG_DEBUG_ENTRY
 	OFFSET(PV_IRQ_save_fl, paravirt_patch_template, irq.save_fl);
 #endif

commit 5c83511bdb9832c86be20fb86b783356e2f58062
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:19 2018 +0200

    x86/paravirt: Use a single ops structure
    
    Instead of using six globally visible paravirt ops structures combine
    them in a single structure, keeping the original structures as
    sub-structures.
    
    This avoids the need to assemble struct paravirt_patch_template at
    runtime on the stack each time apply_paravirt() is being called (i.e.
    when loading a module).
    
    [ tglx: Made the struct and the initializer tabular for readability sake ]
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-9-jgross@suse.com

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 3b9405e7ba2b..3384b03e717f 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -21,10 +21,11 @@ static char syscalls_ia32[] = {
 int main(void)
 {
 #ifdef CONFIG_PARAVIRT
-	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
-	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
+	OFFSET(PV_CPU_usergs_sysret64, paravirt_patch_template,
+	       cpu.usergs_sysret64);
+	OFFSET(PV_CPU_swapgs, paravirt_patch_template, cpu.swapgs);
 #ifdef CONFIG_DEBUG_ENTRY
-	OFFSET(PV_IRQ_save_fl, pv_irq_ops, save_fl);
+	OFFSET(PV_IRQ_save_fl, paravirt_patch_template, irq.save_fl);
 #endif
 	BLANK();
 #endif

commit 9e97b73fdb235345a826519862a52a7398c89eb8
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Jul 18 11:40:38 2018 +0200

    x86/asm-offsets: Move TSS_sp0 and TSS_sp1 to asm-offsets.c
    
    These offsets will be used in 32 bit assembly code as well, so make them
    available for all of x86 code.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Pavel Machek <pavel@ucw.cz>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H . Peter Anvin" <hpa@zytor.com>
    Cc: linux-mm@kvack.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Waiman Long <llong@redhat.com>
    Cc: "David H . Gutteridge" <dhgutteridge@sympatico.ca>
    Cc: joro@8bytes.org
    Link: https://lkml.kernel.org/r/1531906876-13451-2-git-send-email-joro@8bytes.org

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index b2dcd161f514..3b9405e7ba2b 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -65,8 +65,6 @@ int main(void)
 #undef ENTRY
 
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
-	OFFSET(TSS_sp0, tss_struct, x86_tss.sp0);
-	OFFSET(TSS_sp1, tss_struct, x86_tss.sp1);
 	BLANK();
 
 #ifdef CONFIG_STACKPROTECTOR

commit 050e9baa9dc9fbd9ce2b27f0056990fc9e0a08a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 14 12:21:18 2018 +0900

    Kbuild: rename CC_STACKPROTECTOR[_STRONG] config variables
    
    The changes to automatically test for working stack protector compiler
    support in the Kconfig files removed the special STACKPROTECTOR_AUTO
    option that picked the strongest stack protector that the compiler
    supported.
    
    That was all a nice cleanup - it makes no sense to have the AUTO case
    now that the Kconfig phase can just determine the compiler support
    directly.
    
    HOWEVER.
    
    It also meant that doing "make oldconfig" would now _disable_ the strong
    stackprotector if you had AUTO enabled, because in a legacy config file,
    the sane stack protector configuration would look like
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      # CONFIG_CC_STACKPROTECTOR_NONE is not set
      # CONFIG_CC_STACKPROTECTOR_REGULAR is not set
      # CONFIG_CC_STACKPROTECTOR_STRONG is not set
      CONFIG_CC_STACKPROTECTOR_AUTO=y
    
    and when you ran this through "make oldconfig" with the Kbuild changes,
    it would ask you about the regular CONFIG_CC_STACKPROTECTOR (that had
    been renamed from CONFIG_CC_STACKPROTECTOR_REGULAR to just
    CONFIG_CC_STACKPROTECTOR), but it would think that the STRONG version
    used to be disabled (because it was really enabled by AUTO), and would
    disable it in the new config, resulting in:
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      CONFIG_CC_HAS_STACKPROTECTOR_NONE=y
      CONFIG_CC_STACKPROTECTOR=y
      # CONFIG_CC_STACKPROTECTOR_STRONG is not set
      CONFIG_CC_HAS_SANE_STACKPROTECTOR=y
    
    That's dangerously subtle - people could suddenly find themselves with
    the weaker stack protector setup without even realizing.
    
    The solution here is to just rename not just the old RECULAR stack
    protector option, but also the strong one.  This does that by just
    removing the CC_ prefix entirely for the user choices, because it really
    is not about the compiler support (the compiler support now instead
    automatially impacts _visibility_ of the options to users).
    
    This results in "make oldconfig" actually asking the user for their
    choice, so that we don't have any silent subtle security model changes.
    The end result would generally look like this:
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      CONFIG_CC_HAS_STACKPROTECTOR_NONE=y
      CONFIG_STACKPROTECTOR=y
      CONFIG_STACKPROTECTOR_STRONG=y
      CONFIG_CC_HAS_SANE_STACKPROTECTOR=y
    
    where the "CC_" versions really are about internal compiler
    infrastructure, not the user selections.
    
    Acked-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index bf51e51d808d..b2dcd161f514 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -69,7 +69,7 @@ int main(void)
 	OFFSET(TSS_sp1, tss_struct, x86_tss.sp1);
 	BLANK();
 
-#ifdef CONFIG_CC_STACKPROTECTOR
+#ifdef CONFIG_STACKPROTECTOR
 	DEFINE(stack_canary_offset, offsetof(union irq_stack_union, stack_canary));
 	BLANK();
 #endif

commit 9aaefe7b59ae00605256a7d6bd1c1456432495fc
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:21 2017 +0100

    x86/entry/64: Separate cpu_current_top_of_stack from TSS.sp0
    
    On 64-bit kernels, we used to assume that TSS.sp0 was the current
    top of stack.  With the addition of an entry trampoline, this will
    no longer be the case.  Store the current top of stack in TSS.sp1,
    which is otherwise unused but shares the same cacheline.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150606.050864668@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index e3a5175a444b..bf51e51d808d 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -66,6 +66,7 @@ int main(void)
 
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
 	OFFSET(TSS_sp0, tss_struct, x86_tss.sp0);
+	OFFSET(TSS_sp1, tss_struct, x86_tss.sp1);
 	BLANK();
 
 #ifdef CONFIG_CC_STACKPROTECTOR

commit e17f8234538d1ff708673f287a42457c4dee720d
Author: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Date:   Mon Dec 4 15:07:07 2017 +0100

    x86/entry/64/paravirt: Use paravirt-safe macro to access eflags
    
    Commit 1d3e53e8624a ("x86/entry/64: Refactor IRQ stacks and make them
    NMI-safe") added DEBUG_ENTRY_ASSERT_IRQS_OFF macro that acceses eflags
    using 'pushfq' instruction when testing for IF bit. On PV Xen guests
    looking at IF flag directly will always see it set, resulting in 'ud2'.
    
    Introduce SAVE_FLAGS() macro that will use appropriate save_fl pv op when
    running paravirt.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Juergen Gross <jgross@suse.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Cc: xen-devel@lists.xenproject.org
    Link: https://lkml.kernel.org/r/20171204150604.899457242@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 630212fa9b9d..e3a5175a444b 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -23,6 +23,9 @@ int main(void)
 #ifdef CONFIG_PARAVIRT
 	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
+#ifdef CONFIG_DEBUG_ENTRY
+	OFFSET(PV_IRQ_save_fl, pv_irq_ops, save_fl);
+#endif
 	BLANK();
 #endif
 

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index cf42206926af..630212fa9b9d 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #ifndef __LINUX_KBUILD_H
 # error "Please do not build this file directly, build asm-offsets.c instead"
 #endif

commit 5878d5d6fdef6447d73b0acc121ba445bef37f53
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Aug 31 19:42:49 2017 +0200

    x86/xen: Get rid of paravirt op adjust_exception_frame
    
    When running as Xen pv-guest the exception frame on the stack contains
    %r11 and %rcx additional to the other data pushed by the processor.
    
    Instead of having a paravirt op being called for each exception type
    prepend the Xen specific code to each exception entry. When running as
    Xen pv-guest just use the exception entry with prepended instructions,
    otherwise use the entry without the Xen specific code.
    
    [ tglx: Merged through tip to avoid ugly merge conflict ]
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: boris.ostrovsky@oracle.com
    Cc: luto@amacapital.net
    Link: http://lkml.kernel.org/r/20170831174249.26853-1-jg@pfupf.net

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 99332f550c48..cf42206926af 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -20,7 +20,6 @@ static char syscalls_ia32[] = {
 int main(void)
 {
 #ifdef CONFIG_PARAVIRT
-	OFFSET(PV_IRQ_adjust_exception_frame, pv_irq_ops, adjust_exception_frame);
 	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
 	BLANK();

commit dd0fd8bca1850ddadf5d33a9ed28f3707cd98ac7
Author: Waiman Long <longman@redhat.com>
Date:   Mon Feb 20 13:36:04 2017 -0500

    x86/kvm: Provide optimized version of vcpu_is_preempted() for x86-64
    
    It was found when running fio sequential write test with a XFS ramdisk
    on a KVM guest running on a 2-socket x86-64 system, the %CPU times
    as reported by perf were as follows:
    
     69.75%  0.59%  fio  [k] down_write
     69.15%  0.01%  fio  [k] call_rwsem_down_write_failed
     67.12%  1.12%  fio  [k] rwsem_down_write_failed
     63.48% 52.77%  fio  [k] osq_lock
      9.46%  7.88%  fio  [k] __raw_callee_save___kvm_vcpu_is_preempt
      3.93%  3.93%  fio  [k] __kvm_vcpu_is_preempted
    
    Making vcpu_is_preempted() a callee-save function has a relatively
    high cost on x86-64 primarily due to at least one more cacheline of
    data access from the saving and restoring of registers (8 of them)
    to and from stack as well as one more level of function call.
    
    To reduce this performance overhead, an optimized assembly version
    of the the __raw_callee_save___kvm_vcpu_is_preempt() function is
    provided for x86-64.
    
    With this patch applied on a KVM guest on a 2-socket 16-core 32-thread
    system with 16 parallel jobs (8 on each socket), the aggregrate
    bandwidth of the fio test on an XFS ramdisk were as follows:
    
       I/O Type      w/o patch    with patch
       --------      ---------    ----------
       random read   8141.2 MB/s  8497.1 MB/s
       seq read      8229.4 MB/s  8304.2 MB/s
       random write  1675.5 MB/s  1701.5 MB/s
       seq write     1681.3 MB/s  1699.9 MB/s
    
    There are some increases in the aggregated bandwidth because of
    the patch.
    
    The perf data now became:
    
     70.78%  0.58%  fio  [k] down_write
     70.20%  0.01%  fio  [k] call_rwsem_down_write_failed
     69.70%  1.17%  fio  [k] rwsem_down_write_failed
     59.91% 55.42%  fio  [k] osq_lock
     10.14% 10.14%  fio  [k] __kvm_vcpu_is_preempted
    
    The assembly code was verified by using a test kernel module to
    compare the output of C __kvm_vcpu_is_preempted() and that of assembly
    __raw_callee_save___kvm_vcpu_is_preempt() to verify that they matched.
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Waiman Long <longman@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 210927ee2e74..99332f550c48 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -13,6 +13,10 @@ static char syscalls_ia32[] = {
 #include <asm/syscalls_32.h>
 };
 
+#if defined(CONFIG_KVM_GUEST) && defined(CONFIG_PARAVIRT_SPINLOCKS)
+#include <asm/kvm_para.h>
+#endif
+
 int main(void)
 {
 #ifdef CONFIG_PARAVIRT
@@ -22,6 +26,11 @@ int main(void)
 	BLANK();
 #endif
 
+#if defined(CONFIG_KVM_GUEST) && defined(CONFIG_PARAVIRT_SPINLOCKS)
+	OFFSET(KVM_STEAL_TIME_preempted, kvm_steal_time, preempted);
+	BLANK();
+#endif
+
 #define ENTRY(entry) OFFSET(pt_regs_ ## entry, pt_regs, entry)
 	ENTRY(bx);
 	ENTRY(cx);

commit 0100301bfdf56a2a370c7157b5ab0fbf9313e1cd
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sat Aug 13 12:38:19 2016 -0400

    sched/x86: Rewrite the switch_to() code
    
    Move the low-level context switch code to an out-of-line asm stub instead of
    using complex inline asm.  This allows constructing a new stack frame for the
    child process to make it seamlessly flow to ret_from_fork without an extra
    test and branch in __switch_to().  It also improves code generation for
    __schedule() by using the C calling convention instead of clobbering all
    registers.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1471106302-10159-5-git-send-email-brgerst@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index d875f97d4e0b..210927ee2e74 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -56,6 +56,11 @@ int main(void)
 	OFFSET(TSS_sp0, tss_struct, x86_tss.sp0);
 	BLANK();
 
+#ifdef CONFIG_CC_STACKPROTECTOR
+	DEFINE(stack_canary_offset, offsetof(union irq_stack_union, stack_canary));
+	BLANK();
+#endif
+
 	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
 	DEFINE(NR_syscalls, sizeof(syscalls_64));
 

commit cfcbadb49dabb05efa23e1a0f95f3391c0a815bc
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jan 28 15:11:24 2016 -0800

    x86/syscalls: Add syscall entry qualifiers
    
    This will let us specify something like 'sys_xyz/foo' instead of
    'sys_xyz' in the syscall table, where the 'foo' qualifier conveys
    some extra information to the C code.
    
    The intent is to allow things like sys_execve/ptregs to indicate
    that sys_execve() touches pt_regs.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/2de06e33dce62556b3ec662006fcb295504e296e.1454022279.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 9677bf9a616f..d875f97d4e0b 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -4,11 +4,11 @@
 
 #include <asm/ia32.h>
 
-#define __SYSCALL_64(nr, sym) [nr] = 1,
+#define __SYSCALL_64(nr, sym, qual) [nr] = 1,
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };
-#define __SYSCALL_I386(nr, sym) [nr] = 1,
+#define __SYSCALL_I386(nr, sym, qual) [nr] = 1,
 static char syscalls_ia32[] = {
 #include <asm/syscalls_32.h>
 };

commit 3e65654e3db6df6aba9c5b895f8b8e6a8d8eb508
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jan 28 15:11:23 2016 -0800

    x86/syscalls: Move compat syscall entry handling into syscalltbl.sh
    
    Rather than duplicating the compat entry handling in all
    consumers of syscalls_BITS.h, handle it directly in
    syscalltbl.sh.  Now we generate entries in syscalls_32.h like:
    
    __SYSCALL_I386(5, sys_open)
    __SYSCALL_I386(5, compat_sys_open)
    
    and all of its consumers implicitly get the right entry point.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/b7c2b501dc0e6e43050e916b95807c3e2e16e9bb.1454022279.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 29db3b3f550c..9677bf9a616f 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -4,11 +4,11 @@
 
 #include <asm/ia32.h>
 
-#define __SYSCALL_64(nr, sym, compat) [nr] = 1,
+#define __SYSCALL_64(nr, sym) [nr] = 1,
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };
-#define __SYSCALL_I386(nr, sym, compat) [nr] = 1,
+#define __SYSCALL_I386(nr, sym) [nr] = 1,
 static char syscalls_ia32[] = {
 #include <asm/syscalls_32.h>
 };

commit 32324ce15ea8cb4c8acc28acb2fd36fabf73e9db
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jan 28 15:11:22 2016 -0800

    x86/syscalls: Remove __SYSCALL_COMMON and __SYSCALL_X32
    
    The common/64/x32 distinction has no effect other than
    determining which kernels actually support the syscall.  Move
    the logic into syscalltbl.sh.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/58d4a95f40e43b894f93288b4a3633963d0ee22e.1454022279.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index f2edafb5f24e..29db3b3f550c 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -5,12 +5,6 @@
 #include <asm/ia32.h>
 
 #define __SYSCALL_64(nr, sym, compat) [nr] = 1,
-#define __SYSCALL_COMMON(nr, sym, compat) [nr] = 1,
-#ifdef CONFIG_X86_X32_ABI
-# define __SYSCALL_X32(nr, sym, compat) [nr] = 1,
-#else
-# define __SYSCALL_X32(nr, sym, compat) /* nothing */
-#endif
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };

commit 75ef82190dceac3d84cdc209fdf82800a7cc6609
Author: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Date:   Thu Nov 19 16:55:47 2015 -0500

    x86/entry, x86/paravirt: Remove the unused usergs_sysret32 PV op
    
    As result of commit "x86/xen: Avoid fast syscall path for Xen PV
    guests", usergs_sysret32 pv op is not called by Xen PV guests
    anymore and since they were the only ones who used it we can
    safely remove it.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: david.vrabel@citrix.com
    Cc: konrad.wilk@oracle.com
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1447970147-1733-4-git-send-email-boris.ostrovsky@oracle.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index d8f42f902a0f..f2edafb5f24e 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -23,7 +23,6 @@ int main(void)
 {
 #ifdef CONFIG_PARAVIRT
 	OFFSET(PV_IRQ_adjust_exception_frame, pv_irq_ops, adjust_exception_frame);
-	OFFSET(PV_CPU_usergs_sysret32, pv_cpu_ops, usergs_sysret32);
 	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
 	BLANK();

commit bace7117d3fb59a6ed7ea1aa6c8994df6a28a72a
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Jun 8 21:20:26 2015 +0200

    x86/asm/entry: (Re-)rename __NR_entry_INT80_compat_max to __NR_syscall_compat_max
    
    Brian Gerst noticed that I did a weird rename in the following commit:
    
       b2502b418e63 ("x86/asm/entry: Untangle 'system_call' into two entry points: entry_SYSCALL_64 and entry_INT80_32")
    
    which renamed __NR_ia32_syscall_max to __NR_entry_INT80_compat_max.
    
    Now the original name was a misnomer, but the new one is a misnomer as well,
    as all the 32-bit compat syscall entry points (sysenter, syscall) share the
    system call table, not just the INT80 based one.
    
    Rename it to __NR_syscall_compat_max.
    
    Reported-by: Brian Gerst <brgerst@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 599afcf0005f..d8f42f902a0f 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -66,7 +66,7 @@ int main(void)
 	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
 	DEFINE(NR_syscalls, sizeof(syscalls_64));
 
-	DEFINE(__NR_entry_INT80_compat_max, sizeof(syscalls_ia32) - 1);
+	DEFINE(__NR_syscall_compat_max, sizeof(syscalls_ia32) - 1);
 	DEFINE(IA32_NR_syscalls, sizeof(syscalls_ia32));
 
 	return 0;

commit 2cd23553b488589f287457b7396470f5e3c40698
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Jun 8 08:28:07 2015 +0200

    x86/asm/entry: Rename compat syscall entry points
    
    Rename the following system call entry points:
    
            ia32_cstar_target       -> entry_SYSCALL_compat
            ia32_syscall            -> entry_INT80_compat
    
    The generic naming scheme for x86 system call entry points is:
    
            entry_MNEMONIC_qualifier
    
    where 'qualifier' is one of _32, _64 or _compat.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index dcaab87da629..599afcf0005f 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -66,7 +66,7 @@ int main(void)
 	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
 	DEFINE(NR_syscalls, sizeof(syscalls_64));
 
-	DEFINE(__NR_ia32_syscall_max, sizeof(syscalls_ia32) - 1);
+	DEFINE(__NR_entry_INT80_compat_max, sizeof(syscalls_ia32) - 1);
 	DEFINE(IA32_NR_syscalls, sizeof(syscalls_ia32));
 
 	return 0;

commit 4d178f94ebe123d462a51169b53854cb7f198888
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sun Apr 12 09:14:45 2015 -0400

    x86/asm: Merge common 32-bit values in asm-offsets.c
    
    Merge common values for 32-bit native and compat.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Link: http://lkml.kernel.org/r/1428844486-6638-1-git-send-email-brgerst@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 5ce6f2da8763..dcaab87da629 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -29,27 +29,6 @@ int main(void)
 	BLANK();
 #endif
 
-#ifdef CONFIG_IA32_EMULATION
-	OFFSET(TI_sysenter_return, thread_info, sysenter_return);
-	BLANK();
-
-#define ENTRY(entry) OFFSET(IA32_SIGCONTEXT_ ## entry, sigcontext_ia32, entry)
-	ENTRY(ax);
-	ENTRY(bx);
-	ENTRY(cx);
-	ENTRY(dx);
-	ENTRY(si);
-	ENTRY(di);
-	ENTRY(bp);
-	ENTRY(sp);
-	ENTRY(ip);
-	BLANK();
-#undef ENTRY
-
-	OFFSET(IA32_RT_SIGFRAME_sigcontext, rt_sigframe_ia32, uc.uc_mcontext);
-	BLANK();
-#endif
-
 #define ENTRY(entry) OFFSET(pt_regs_ ## entry, pt_regs, entry)
 	ENTRY(bx);
 	ENTRY(cx);

commit 9d0c914c60f4d3123debb653340dc1f7cf44939d
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Mar 5 19:19:04 2015 -0800

    x86/asm/entry/64/compat: Change the 32-bit sysenter code to use sp0
    
    The ia32 sysenter code loaded the top of the kernel stack into
    rsp by loading kernel_stack and then adjusting it.  It can be
    simplified to just read sp0 directly.
    
    This requires the addition of a new asm-offsets entry for sp0.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/88ff9006163d296a0665338585c36d9bfb85235d.1425611534.git.luto@amacapital.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index fdcbb4d27c9f..5ce6f2da8763 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -81,6 +81,7 @@ int main(void)
 #undef ENTRY
 
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
+	OFFSET(TSS_sp0, tss_struct, x86_tss.sp0);
 	BLANK();
 
 	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);

commit 536e89ee53e9cbdec00e49ae1888bffa262043d8
Merge: 9ea18f8cab5f 0e58af4e1d21
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Dec 14 11:51:50 2014 -0800

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fixes from Ingo Molnar:
     "Misc fixes (mainly Andy's TLS fixes), plus a cleanup"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/tls: Disallow unusual TLS segments
      x86/tls: Validate TLS entries to protect espfix
      MAINTAINERS: Add me as x86 VDSO submaintainer
      x86/asm: Unify segment selector defines
      x86/asm: Guard against building the 32/64-bit versions of the asm-offsets*.c file directly
      x86_64, switch_to(): Load TLS descriptors before switching DS and ES
      x86/mm: Use min() instead of min_t() in the e820 printout code
      x86/mm: Fix zone ranges boot printout
      x86/doc: Update documentation after file shuffling

commit 5de2b61a63f0982641eb00b9a6a9650f23487eaa
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Dec 9 16:45:17 2014 +0100

    x86/asm: Guard against building the 32/64-bit versions of the asm-offsets*.c file directly
    
    Sometimes it is helpful to build a kernel compilation unit
    directly, i.e.:
    
      make .../<filename>.i
    
    in order to look at compiler output.
    
    Since asm-offsets_{32,64}.c are included by asm-offsets.c and
    building them directly doesn't evaluate the macros used (thus
    making the preprocessor output not very useful), error out when
    an attempt is made to build them. Issue a hint for the user to
    build asm-offsets.c instead.
    
    Suggested-by: Michael Matz <matz@suse.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Michal Marek <mmarek@suse.cz>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1418139917-12722-1-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index e7c798b354fa..4c0c596dfb95 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -1,3 +1,7 @@
+#ifndef __LINUX_KBUILD_H
+# error "Please do not build this file directly, build asm-offsets.c instead"
+#endif
+
 #include <asm/ia32.h>
 
 #define __SYSCALL_64(nr, sym, compat) [nr] = 1,

commit a1a5831d295f34eceec3ba12c199c2c070e1aaed
Author: Nicholas Mc Guire <der.herr@hofr.at>
Date:   Mon Oct 27 18:28:05 2014 +0100

    x86/asm: Fix typo in arch/x86/kernel/asm_offset_64.c
    
    Drop double entry for pt_regs_bx.
    
    This seems to be a typo - resulting in a double entry in the
    generated include/generated/asm-offsets.h, which is not necessary.
    
    Build-tested and booted on x86 64 box to make sure it was not
    doing any strange magic.... after all it was in the kernel in
    this form for almost 10 years.
    
    Signed-off-by: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: Jan Beulich <JBeulich@suse.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20141027172805.GA19760@opentech.at
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index e7c798b354fa..4f9359f36bb7 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -47,7 +47,6 @@ int main(void)
 #endif
 
 #define ENTRY(entry) OFFSET(pt_regs_ ## entry, pt_regs, entry)
-	ENTRY(bx);
 	ENTRY(bx);
 	ENTRY(cx);
 	ENTRY(dx);

commit cc456c4e7cac3837a86aaa7ca3cb9f488d44d196
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed May 1 21:53:30 2013 -0400

    x86, gdt, hibernate: Store/load GDT for hibernate path.
    
    The git commite7a5cd063c7b4c58417f674821d63f5eb6747e37
    ("x86-64, gdt: Store/load GDT for ACPI S3 or hibernate/resume path
    is not needed.") assumes that for the hibernate path the booting
    kernel and the resuming kernel MUST be the same. That is certainly
    the case for a 32-bit kernel (see check_image_kernel and
    CONFIG_ARCH_HIBERNATION_HEADER config option).
    
    However for 64-bit kernels it is OK to have a different kernel
    version (and size of the image) of the booting and resuming kernels.
    Hence the above mentioned git commit introduces an regression.
    
    This patch fixes it by introducing a 'struct desc_ptr gdt_desc'
    back in the 'struct saved_context'. However instead of having in the
    'save_processor_state' and 'restore_processor_state' the
    store/load_gdt calls, we are only saving the GDT in the
    save_processor_state.
    
    For the restore path the lgdt operation is done in
    hibernate_asm_[32|64].S in the 'restore_registers' path.
    
    The apt reader of this description will recognize that only 64-bit
    kernels need this treatment, not 32-bit. This patch adds the logic
    in the 32-bit path to be more similar to 64-bit so that in the future
    the unification process can take advantage of this.
    
    [ hpa: this also reverts an inadvertent on-disk format change ]
    
    Suggested-by: "H. Peter Anvin" <hpa@zytor.com>
    Acked-by: "Rafael J. Wysocki" <rjw@sisk.pl>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Link: http://lkml.kernel.org/r/1367459610-9656-2-git-send-email-konrad.wilk@oracle.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 1b4754f82ba7..e7c798b354fa 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -73,6 +73,7 @@ int main(void)
 	ENTRY(cr3);
 	ENTRY(cr4);
 	ENTRY(cr8);
+	ENTRY(gdt_desc);
 	BLANK();
 #undef ENTRY
 

commit a06c9bc0647f66df0534fb887ddf6cddd35f426c
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Sun Feb 19 11:08:37 2012 -0800

    x32: If configured, add x32 system calls to system call tables
    
    If CONFIG_X86_X32_ABI is defined, add the x32 system calls to the
    system call tables.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index c3354f7b0a06..1b4754f82ba7 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -2,7 +2,11 @@
 
 #define __SYSCALL_64(nr, sym, compat) [nr] = 1,
 #define __SYSCALL_COMMON(nr, sym, compat) [nr] = 1,
-#define __SYSCALL_X32(nr, sym, compat) /* Not yet */
+#ifdef CONFIG_X86_X32_ABI
+# define __SYSCALL_X32(nr, sym, compat) [nr] = 1,
+#else
+# define __SYSCALL_X32(nr, sym, compat) /* nothing */
+#endif
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };

commit 6630f11ba54414b9870d87dfef2bee467bfa842a
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Tue Feb 14 14:18:50 2012 -0800

    x32: Add x32 system calls to syscall/syscall_64.tbl
    
    Split the 64-bit system calls into "64" (64-bit only) and "common"
    (64-bit or x32) and add the x32 system call numbers.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 834e897b1e25..c3354f7b0a06 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -1,6 +1,8 @@
 #include <asm/ia32.h>
 
 #define __SYSCALL_64(nr, sym, compat) [nr] = 1,
+#define __SYSCALL_COMMON(nr, sym, compat) [nr] = 1,
+#define __SYSCALL_X32(nr, sym, compat) /* Not yet */
 static char syscalls_64[] = {
 #include <asm/syscalls_64.h>
 };

commit 303395ac3bf3e2cb488435537d416bc840438fcb
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Nov 11 16:07:41 2011 -0800

    x86: Generate system call tables and unistd_*.h from tables
    
    Generate system call tables and unistd_*.h automatically from the
    tables in arch/x86/syscalls.  All other information, like NR_syscalls,
    is auto-generated, some of which is in asm-offsets_*.c.
    
    This allows us to keep all the system call information in one place,
    and allows for kernel space and user space to see different
    information; this is currently used for the ia32 system call numbers
    when building the 64-bit kernel, but will be used by the x32 ABI in
    the near future.
    
    This also removes some gratuitious differences between i386, x86-64
    and ia32; in particular, now all system call tables are generated with
    the same mechanism.
    
    Cc: H. J. Lu <hjl.tools@gmail.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Cc: Michal Marek <mmarek@suse.cz>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index e72a1194af22..834e897b1e25 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -1,11 +1,12 @@
 #include <asm/ia32.h>
 
-#define __NO_STUBS 1
-#undef __SYSCALL
-#undef _ASM_X86_UNISTD_64_H
-#define __SYSCALL(nr, sym) [nr] = 1,
-static char syscalls[] = {
-#include <asm/unistd.h>
+#define __SYSCALL_64(nr, sym, compat) [nr] = 1,
+static char syscalls_64[] = {
+#include <asm/syscalls_64.h>
+};
+#define __SYSCALL_I386(nr, sym, compat) [nr] = 1,
+static char syscalls_ia32[] = {
+#include <asm/syscalls_32.h>
 };
 
 int main(void)
@@ -72,7 +73,11 @@ int main(void)
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
 	BLANK();
 
-	DEFINE(__NR_syscall_max, sizeof(syscalls) - 1);
+	DEFINE(__NR_syscall_max, sizeof(syscalls_64) - 1);
+	DEFINE(NR_syscalls, sizeof(syscalls_64));
+
+	DEFINE(__NR_ia32_syscall_max, sizeof(syscalls_ia32) - 1);
+	DEFINE(IA32_NR_syscalls, sizeof(syscalls_ia32));
 
 	return 0;
 }

commit b82fef82d56789439e6be638a87a1a5bba1e6e75
Author: Jan Beulich <JBeulich@novell.com>
Date:   Wed Feb 9 08:24:34 2011 +0000

    x86: Partly unify asm-offsets_{32,64}.c
    
    Just consolidating the common parts. Full unification would seem
    straight forward, but it's not clear the necessary #ifdef-s would
    be acceptable.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <4D525D520200007800030EE9@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 4a6aeedcd965..e72a1194af22 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -1,27 +1,4 @@
-/*
- * Generate definitions needed by assembly language modules.
- * This code generates raw asm output which is post-processed to extract
- * and format the required data.
- */
-#define COMPILE_OFFSETS
-
-#include <linux/crypto.h>
-#include <linux/sched.h> 
-#include <linux/stddef.h>
-#include <linux/errno.h> 
-#include <linux/hardirq.h>
-#include <linux/suspend.h>
-#include <linux/kbuild.h>
-#include <asm/processor.h>
-#include <asm/segment.h>
-#include <asm/thread_info.h>
 #include <asm/ia32.h>
-#include <asm/bootparam.h>
-#include <asm/suspend.h>
-
-#include <xen/interface/xen.h>
-
-#include <asm/sigframe.h>
 
 #define __NO_STUBS 1
 #undef __SYSCALL
@@ -33,41 +10,19 @@ static char syscalls[] = {
 
 int main(void)
 {
-#define ENTRY(entry) DEFINE(tsk_ ## entry, offsetof(struct task_struct, entry))
-	ENTRY(state);
-	ENTRY(flags); 
-	ENTRY(pid);
-	BLANK();
-#undef ENTRY
-#define ENTRY(entry) DEFINE(TI_ ## entry, offsetof(struct thread_info, entry))
-	ENTRY(flags);
-	ENTRY(addr_limit);
-	ENTRY(preempt_count);
-	ENTRY(status);
-#ifdef CONFIG_IA32_EMULATION
-	ENTRY(sysenter_return);
-#endif
-	BLANK();
-#undef ENTRY
 #ifdef CONFIG_PARAVIRT
-	BLANK();
-	OFFSET(PARAVIRT_enabled, pv_info, paravirt_enabled);
-	OFFSET(PARAVIRT_PATCH_pv_cpu_ops, paravirt_patch_template, pv_cpu_ops);
-	OFFSET(PARAVIRT_PATCH_pv_irq_ops, paravirt_patch_template, pv_irq_ops);
-	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
-	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
 	OFFSET(PV_IRQ_adjust_exception_frame, pv_irq_ops, adjust_exception_frame);
-	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
 	OFFSET(PV_CPU_usergs_sysret32, pv_cpu_ops, usergs_sysret32);
 	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
-	OFFSET(PV_CPU_irq_enable_sysexit, pv_cpu_ops, irq_enable_sysexit);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
-	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
+	BLANK();
 #endif
 
-
 #ifdef CONFIG_IA32_EMULATION
-#define ENTRY(entry) DEFINE(IA32_SIGCONTEXT_ ## entry, offsetof(struct sigcontext_ia32, entry))
+	OFFSET(TI_sysenter_return, thread_info, sysenter_return);
+	BLANK();
+
+#define ENTRY(entry) OFFSET(IA32_SIGCONTEXT_ ## entry, sigcontext_ia32, entry)
 	ENTRY(ax);
 	ENTRY(bx);
 	ENTRY(cx);
@@ -79,15 +34,12 @@ int main(void)
 	ENTRY(ip);
 	BLANK();
 #undef ENTRY
-	DEFINE(IA32_RT_SIGFRAME_sigcontext,
-	       offsetof (struct rt_sigframe_ia32, uc.uc_mcontext));
+
+	OFFSET(IA32_RT_SIGFRAME_sigcontext, rt_sigframe_ia32, uc.uc_mcontext);
 	BLANK();
 #endif
-	DEFINE(pbe_address, offsetof(struct pbe, address));
-	DEFINE(pbe_orig_address, offsetof(struct pbe, orig_address));
-	DEFINE(pbe_next, offsetof(struct pbe, next));
-	BLANK();
-#define ENTRY(entry) DEFINE(pt_regs_ ## entry, offsetof(struct pt_regs, entry))
+
+#define ENTRY(entry) OFFSET(pt_regs_ ## entry, pt_regs, entry)
 	ENTRY(bx);
 	ENTRY(bx);
 	ENTRY(cx);
@@ -107,7 +59,8 @@ int main(void)
 	ENTRY(flags);
 	BLANK();
 #undef ENTRY
-#define ENTRY(entry) DEFINE(saved_context_ ## entry, offsetof(struct saved_context, entry))
+
+#define ENTRY(entry) OFFSET(saved_context_ ## entry, saved_context, entry)
 	ENTRY(cr0);
 	ENTRY(cr2);
 	ENTRY(cr3);
@@ -115,26 +68,11 @@ int main(void)
 	ENTRY(cr8);
 	BLANK();
 #undef ENTRY
-	DEFINE(TSS_ist, offsetof(struct tss_struct, x86_tss.ist));
-	BLANK();
-	DEFINE(crypto_tfm_ctx_offset, offsetof(struct crypto_tfm, __crt_ctx));
-	BLANK();
-	DEFINE(__NR_syscall_max, sizeof(syscalls) - 1);
 
+	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
 	BLANK();
-	OFFSET(BP_scratch, boot_params, scratch);
-	OFFSET(BP_loadflags, boot_params, hdr.loadflags);
-	OFFSET(BP_hardware_subarch, boot_params, hdr.hardware_subarch);
-	OFFSET(BP_version, boot_params, hdr.version);
-	OFFSET(BP_kernel_alignment, boot_params, hdr.kernel_alignment);
 
-	BLANK();
-	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);
-#ifdef CONFIG_XEN
-	BLANK();
-	OFFSET(XEN_vcpu_info_mask, vcpu_info, evtchn_upcall_mask);
-	OFFSET(XEN_vcpu_info_pending, vcpu_info, evtchn_upcall_pending);
-#undef ENTRY
-#endif
+	DEFINE(__NR_syscall_max, sizeof(syscalls) - 1);
+
 	return 0;
 }

commit a5a2f8e2acb991327952c45a13f5441fc09dffd6
Author: Jason Baron <jbaron@redhat.com>
Date:   Wed Aug 26 12:09:10 2009 -0400

    tracing: Define NR_syscalls for x86_64
    
    Express the available number of syscalls in a standard way by defining
    NR_syscalls.
    
    The common way to define it is to place its definition in asm/unistd.h
    However, the number of syscalls is defined using __NR_syscall_max in
    x86-64 after building a dynamic header file "asm-offsets.h"
    
    The source file that generates this header, asm-offsets-64.c includes
    unistd.h, then if we want to express NR_syscalls from __NR_syscall_max
    in unistd.h only after generating the dynamic header file, we need a
    watchguard.
    
    If unistd.h is included from asm-offsets-64.c, then we are generating
    asm-offset.h which defines __NR_syscall_max. At this time, we don't
    want to (we can't) define NR_syscalls, then we do nothing.
    Otherwise we define NR_syscalls because we know asm-offsets.h has
    been generated.
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Cc: Jiaying Zhang <jiayingz@google.com>
    Cc: Martin Bligh <mbligh@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Josh Stone <jistone@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: H. Peter Anwin <hpa@zytor.com>
    Cc: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    LKML-Reference: <20090826160910.GB2658@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 898ecc47e129..4a6aeedcd965 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -3,6 +3,7 @@
  * This code generates raw asm output which is post-processed to extract
  * and format the required data.
  */
+#define COMPILE_OFFSETS
 
 #include <linux/crypto.h>
 #include <linux/sched.h> 

commit 37ba7ab5e33cebc25c68fffe33e9f21e7c2014e8
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Mon May 11 15:56:08 2009 -0700

    x86, boot: make kernel_alignment adjustable; new bzImage fields
    
    Make the kernel_alignment field adjustable; this allows us to set it
    to a large value (intended to be 16 MB to avoid ZONE_DMA contention,
    memory holes and other weirdness) while a smart bootloader can still
    force a loading at a lesser alignment if absolutely necessary.
    
    Also export pref_address (preferred loading address, corresponding to
    the link-time address) and init_size, the total amount of linear
    memory the kernel will require during initialization.
    
    [ Impact: allows better kernel placement, gives bootloader more info ]
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index e72f062fb4b5..898ecc47e129 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -125,6 +125,7 @@ int main(void)
 	OFFSET(BP_loadflags, boot_params, hdr.loadflags);
 	OFFSET(BP_hardware_subarch, boot_params, hdr.hardware_subarch);
 	OFFSET(BP_version, boot_params, hdr.version);
+	OFFSET(BP_kernel_alignment, boot_params, hdr.kernel_alignment);
 
 	BLANK();
 	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);

commit a8af78982ff4c0b3731527b0217d286a343a3089
Author: Magnus Damm <damm@igel.co.jp>
Date:   Tue Mar 31 15:23:37 2009 -0700

    pm: rework includes, remove arch ifdefs
    
    Make the following header file changes:
    
     - remove arch ifdefs and asm/suspend.h from linux/suspend.h
     - add asm/suspend.h to disk.c (for arch_prepare_suspend())
     - add linux/io.h to swsusp.c (for ioremap())
     - x86 32/64 bit compile fixes
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Acked-by: "Rafael J. Wysocki" <rjw@sisk.pl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 8793ab33e2c1..e72f062fb4b5 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -16,6 +16,7 @@
 #include <asm/thread_info.h>
 #include <asm/ia32.h>
 #include <asm/bootparam.h>
+#include <asm/suspend.h>
 
 #include <xen/interface/xen.h>
 

commit 0d974d4592708f85044751817da4b7016e1b0602
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sun Jan 18 19:52:25 2009 -0500

    x86: remove pda.h
    
    Impact: cleanup
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 94f9c8b39d20..8793ab33e2c1 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -11,7 +11,6 @@
 #include <linux/hardirq.h>
 #include <linux/suspend.h>
 #include <linux/kbuild.h>
-#include <asm/pda.h>
 #include <asm/processor.h>
 #include <asm/segment.h>
 #include <asm/thread_info.h>

commit 947e76cdc34c782fc947313d4331380686eebbad
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 12:21:28 2009 +0900

    x86: move stack_canary into irq_stack
    
    Impact: x86_64 percpu area layout change, irq_stack now at the beginning
    
    Now that the PDA is empty except for the stack canary, it can be removed.
    The irqstack is moved to the start of the per-cpu section.  If the stack
    protector is enabled, the canary overlaps the bottom 48 bytes of the irqstack.
    
    tj: * updated subject
        * dropped asm relocation of irq_stack_ptr
        * updated comments a bit
        * rebased on top of stack canary changes
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 64c834a39aa8..94f9c8b39d20 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -48,10 +48,6 @@ int main(void)
 #endif
 	BLANK();
 #undef ENTRY
-#define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
-	DEFINE(pda_size, sizeof(struct x8664_pda));
-	BLANK();
-#undef ENTRY
 #ifdef CONFIG_PARAVIRT
 	BLANK();
 	OFFSET(PARAVIRT_enabled, pv_info, paravirt_enabled);

commit 5689553076c4a67b83426b076082c63085b7567a
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move irqcount from PDA to per-cpu.
    
    tj: s/irqcount/irq_count/
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index afda6deb8515..64c834a39aa8 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -49,7 +49,6 @@ int main(void)
 	BLANK();
 #undef ENTRY
 #define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
-	ENTRY(irqcount);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();
 #undef ENTRY

commit 3d1e42a7cf945e289d6ba26159aa0e2b0645401b
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move oldrsp from PDA to per-cpu.
    
    tj: * in asm-offsets_64.c, pda.h inclusion shouldn't be removed as pda
          is still referenced in the file
        * s/oldrsp/old_rsp/
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index cafff5f4a031..afda6deb8515 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -49,7 +49,6 @@ int main(void)
 	BLANK();
 #undef ENTRY
 #define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
-	ENTRY(oldrsp); 
 	ENTRY(irqcount);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();

commit 9af45651f1f7c89942e016a1a00a7ebddfa727f8
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move kernelstack from PDA to per-cpu.
    
    Also clean up PER_CPU_VAR usage in xen-asm_64.S
    
    tj: * remove now unused stack_thread_info()
        * s/kernelstack/kernel_stack/
        * added FIXME comment in xen-asm_64.S
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 4f7a210e1e58..cafff5f4a031 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -49,7 +49,6 @@ int main(void)
 	BLANK();
 #undef ENTRY
 #define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
-	ENTRY(kernelstack); 
 	ENTRY(oldrsp); 
 	ENTRY(irqcount);
 	DEFINE(pda_size, sizeof(struct x8664_pda));

commit c6f5e0acd5d12ee23f701f15889872e67b47caa6
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move current task from PDA to per-cpu and consolidate with 32-bit.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index cae6697c0991..4f7a210e1e58 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -51,7 +51,6 @@ int main(void)
 #define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
 	ENTRY(kernelstack); 
 	ENTRY(oldrsp); 
-	ENTRY(pcurrent); 
 	ENTRY(irqcount);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();

commit ea9279066de44053d0c20ea855bc9f4706652d84
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move cpu number from PDA to per-cpu and consolidate with 32-bit.
    
    tj: moved cpu_number definition out of CONFIG_HAVE_SETUP_PER_CPU_AREA
        for voyager.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 5b821fbdaf7b..cae6697c0991 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -53,7 +53,6 @@ int main(void)
 	ENTRY(oldrsp); 
 	ENTRY(pcurrent); 
 	ENTRY(irqcount);
-	ENTRY(cpunumber);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();
 #undef ENTRY

commit 26f80bd6a9ab17bc8a60b6092e7c0d05c5927ce5
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Convert irqstacks to per-cpu
    
    Move the irqstackptr variable from the PDA to per-cpu.  Make the
    stacks themselves per-cpu, removing some specific allocation code.
    Add a seperate flag (is_boot_cpu) to simplify the per-cpu boot
    adjustments.
    
    tj: * sprinkle some underbars around.
    
        * irq_stack_ptr is not used till traps_init(), no reason to
          initialize it early.  On SMP, just leaving it NULL till proper
          initialization in setup_per_cpu_areas() works.  Dropped
          is_boot_cpu and early irq_stack_ptr initialization.
    
        * do DECLARE/DEFINE_PER_CPU(char[IRQ_STACK_SIZE], irq_stack)
          instead of (char, irq_stack[IRQ_STACK_SIZE]).
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index f4cc81bfbf89..5b821fbdaf7b 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -54,7 +54,6 @@ int main(void)
 	ENTRY(pcurrent); 
 	ENTRY(irqcount);
 	ENTRY(cpunumber);
-	ENTRY(irqstackptr);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();
 #undef ENTRY

commit 9939ddaff52787b2a7c1adf1b2afc95421aa0884
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jan 13 20:41:35 2009 +0900

    x86: merge 64 and 32 SMP percpu handling
    
    Now that pda is allocated as part of percpu, percpu doesn't need to be
    accessed through pda.  Unify x86_64 SMP percpu access with x86_32 SMP
    one.  Other than the segment register, operand size and the base of
    percpu symbols, they behave identical now.
    
    This patch replaces now unnecessary pda->data_offset with a dummy
    field which is necessary to keep stack_canary at its place.  This
    patch also moves per_cpu_offset initialization out of init_gdt() into
    setup_per_cpu_areas().  Note that this change also necessitates
    explicit per_cpu_offset initializations in voyager_smp.c.
    
    With this change, x86_OP_percpu()'s are as efficient on x86_64 as on
    x86_32 and also x86_64 can use assembly PER_CPU macros.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index f8d1b047ef4f..f4cc81bfbf89 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -55,7 +55,6 @@ int main(void)
 	ENTRY(irqcount);
 	ENTRY(cpunumber);
 	ENTRY(irqstackptr);
-	ENTRY(data_offset);
 	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();
 #undef ENTRY

commit 1a51e3a0aed18767cf2762e95456ecfeb0bca5e6
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jan 13 20:41:35 2009 +0900

    x86: fold pda into percpu area on SMP
    
    [ Based on original patch from Christoph Lameter and Mike Travis. ]
    
    Currently pdas and percpu areas are allocated separately.  %gs points
    to local pda and percpu area can be reached using pda->data_offset.
    This patch folds pda into percpu area.
    
    Due to strange gcc requirement, pda needs to be at the beginning of
    the percpu area so that pda->stack_canary is at %gs:40.  To achieve
    this, a new percpu output section macro - PERCPU_VADDR_PREALLOC() - is
    added and used to reserve pda sized chunk at the start of the percpu
    area.
    
    After this change, for boot cpu, %gs first points to pda in the
    data.init area and later during setup_per_cpu_areas() gets updated to
    point to the actual pda.  This means that setup_per_cpu_areas() need
    to reload %gs for CPU0 while clearing pda area for other cpus as cpu0
    already has modified it when control reaches setup_per_cpu_areas().
    
    This patch also removes now unnecessary get_local_pda() and its call
    sites.
    
    A lot of this patch is taken from Mike Travis' "x86_64: Fold pda into
    per cpu area" patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 1d41d3f1edbc..f8d1b047ef4f 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -56,6 +56,7 @@ int main(void)
 	ENTRY(cpunumber);
 	ENTRY(irqstackptr);
 	ENTRY(data_offset);
+	DEFINE(pda_size, sizeof(struct x8664_pda));
 	BLANK();
 #undef ENTRY
 #ifdef CONFIG_PARAVIRT

commit 8869a2e5d3a66d5b63b948052d60cd13ede8b735
Author: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
Date:   Thu Dec 18 14:46:52 2008 -0800

    x86: asm-offset_64: use rt_sigframe_ia32
    
    Impact: cleanup
    
    Use rt_sigframe_ia32 instead of rt_sigframe32.
    
    Signed-off-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 7fcf63d22f8b..1d41d3f1edbc 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -20,6 +20,8 @@
 
 #include <xen/interface/xen.h>
 
+#include <asm/sigframe.h>
+
 #define __NO_STUBS 1
 #undef __SYSCALL
 #undef _ASM_X86_UNISTD_64_H
@@ -87,7 +89,7 @@ int main(void)
 	BLANK();
 #undef ENTRY
 	DEFINE(IA32_RT_SIGFRAME_sigcontext,
-	       offsetof (struct rt_sigframe32, uc.uc_mcontext));
+	       offsetof (struct rt_sigframe_ia32, uc.uc_mcontext));
 	BLANK();
 #endif
 	DEFINE(pbe_address, offsetof(struct pbe, address));

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 505543a75a56..7fcf63d22f8b 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -22,7 +22,7 @@
 
 #define __NO_STUBS 1
 #undef __SYSCALL
-#undef ASM_X86__UNISTD_64_H
+#undef _ASM_X86_UNISTD_64_H
 #define __SYSCALL(nr, sym) [nr] = 1,
 static char syscalls[] = {
 #include <asm/unistd.h>

commit a31863168660c6b6f6c7ffe05bb6a38e97803326
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Tue Jul 22 21:53:53 2008 +0200

    x86: consolidate header guards
    
    This patch consolidates the header guard names which are also used
    externally, i.e. in .c files.
    
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index aa89387006fe..505543a75a56 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -22,7 +22,7 @@
 
 #define __NO_STUBS 1
 #undef __SYSCALL
-#undef _ASM_X86_64_UNISTD_H_
+#undef ASM_X86__UNISTD_64_H
 #define __SYSCALL(nr, sym) [nr] = 1,
 static char syscalls[] = {
 #include <asm/unistd.h>

commit 555cf2b5805a213ba262a2830c4d22ad635a249e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Tue Jul 8 15:06:45 2008 -0700

    xen64: add asm-offsets
    
    Add Xen vcpu_info offsets to asm-offsets_64.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 0f7e1f09aa09..aa89387006fe 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -18,6 +18,8 @@
 #include <asm/ia32.h>
 #include <asm/bootparam.h>
 
+#include <xen/interface/xen.h>
+
 #define __NO_STUBS 1
 #undef __SYSCALL
 #undef _ASM_X86_64_UNISTD_H_
@@ -134,5 +136,11 @@ int main(void)
 
 	BLANK();
 	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);
+#ifdef CONFIG_XEN
+	BLANK();
+	OFFSET(XEN_vcpu_info_mask, vcpu_info, evtchn_upcall_mask);
+	OFFSET(XEN_vcpu_info_pending, vcpu_info, evtchn_upcall_pending);
+#undef ENTRY
+#endif
 	return 0;
 }

commit 8c5e5ac32fe08793246709fbb94c055ec76a7c0e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Tue Jul 8 15:06:44 2008 -0700

    xen64: add xen-head code to head_64.S
    
    Add the Xen entrypoint and ELF notes to head_64.S.  Adapts xen-head.S
    to compile either 32-bit or 64-bit.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index bacf5deeec2d..0f7e1f09aa09 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -131,5 +131,8 @@ int main(void)
 	OFFSET(BP_loadflags, boot_params, hdr.loadflags);
 	OFFSET(BP_hardware_subarch, boot_params, hdr.hardware_subarch);
 	OFFSET(BP_version, boot_params, hdr.version);
+
+	BLANK();
+	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);
 	return 0;
 }

commit 26ccb8a7183eed424ff9c874c83af20dafe7cdef
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Jun 24 11:19:35 2008 -0300

    x86: rename threadinfo to TI.
    
    This is for consistency with i386.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 3295e7c08fe7..bacf5deeec2d 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -34,7 +34,7 @@ int main(void)
 	ENTRY(pid);
 	BLANK();
 #undef ENTRY
-#define ENTRY(entry) DEFINE(threadinfo_ ## entry, offsetof(struct thread_info, entry))
+#define ENTRY(entry) DEFINE(TI_ ## entry, offsetof(struct thread_info, entry))
 	ENTRY(flags);
 	ENTRY(addr_limit);
 	ENTRY(preempt_count);

commit fab58420ac0007a452b540cfb07923225ea4f48d
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Jun 25 00:19:31 2008 -0400

    x86/paravirt, 64-bit: add adjust_exception_frame
    
    64-bit Xen pushes a couple of extra words onto an exception frame.
    Add a hook to deal with them.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: xen-devel <xen-devel@lists.xensource.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 06c451af979a..3295e7c08fe7 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -61,6 +61,7 @@ int main(void)
 	OFFSET(PARAVIRT_PATCH_pv_irq_ops, paravirt_patch_template, pv_irq_ops);
 	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
 	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
+	OFFSET(PV_IRQ_adjust_exception_frame, pv_irq_ops, adjust_exception_frame);
 	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
 	OFFSET(PV_CPU_usergs_sysret32, pv_cpu_ops, usergs_sysret32);
 	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);

commit 2be29982a08009c731307f4a39053b70ac4700da
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Jun 25 00:19:28 2008 -0400

    x86/paravirt: add sysret/sysexit pvops for returning to 32-bit compatibility userspace
    
    In a 64-bit system, we need separate sysret/sysexit operations to
    return to a 32-bit userspace.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citirx.com>
    Cc: xen-devel <xen-devel@lists.xensource.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index a19aba8c5bb3..06c451af979a 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -62,7 +62,9 @@ int main(void)
 	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
 	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
 	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
-	OFFSET(PV_CPU_usergs_sysret, pv_cpu_ops, usergs_sysret);
+	OFFSET(PV_CPU_usergs_sysret32, pv_cpu_ops, usergs_sysret32);
+	OFFSET(PV_CPU_usergs_sysret64, pv_cpu_ops, usergs_sysret64);
+	OFFSET(PV_CPU_irq_enable_sysexit, pv_cpu_ops, irq_enable_sysexit);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
 	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
 #endif

commit c7245da6ae7e5208504ff027c4e0eec69b788651
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Jun 25 00:19:27 2008 -0400

    x86/paravirt, 64-bit: don't restore user rsp within sysret
    
    There's no need to combine restoring the user rsp within the sysret
    pvop, so split it out.  This makes the pvop's semantics closer to the
    machine instruction.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citirx.com>
    Cc: xen-devel <xen-devel@lists.xensource.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 27ac2deca465..a19aba8c5bb3 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -62,7 +62,7 @@ int main(void)
 	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
 	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
 	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
-	OFFSET(PV_CPU_usersp_sysret, pv_cpu_ops, usersp_sysret);
+	OFFSET(PV_CPU_usergs_sysret, pv_cpu_ops, usergs_sysret);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
 	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
 #endif

commit d75cd22fdd5f7d203fb60014d426942df33dd9a6
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Jun 25 00:19:26 2008 -0400

    x86/paravirt: split sysret and sysexit
    
    Don't conflate sysret and sysexit; they're different instructions with
    different semantics, and may be in use at the same time (at least
    within the same kernel, depending on whether its an Intel or AMD
    system).
    
    sysexit - just return to userspace, does no register restoration of
        any kind; must explicitly atomically enable interrupts.
    
    sysret - reloads flags from r11, so no need to explicitly enable
        interrupts on 64-bit, responsible for restoring usermode %gs
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citirx.com>
    Cc: xen-devel <xen-devel@lists.xensource.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index f126c05d6170..27ac2deca465 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -62,7 +62,7 @@ int main(void)
 	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
 	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
 	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
-	OFFSET(PV_CPU_irq_enable_syscall_ret, pv_cpu_ops, irq_enable_syscall_ret);
+	OFFSET(PV_CPU_usersp_sysret, pv_cpu_ops, usersp_sysret);
 	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
 	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
 #endif

commit 66916cd2670e2033a468c492a0192a643ff0965e
Author: Christoph Lameter <clameter@sgi.com>
Date:   Tue Apr 29 01:03:54 2008 -0700

    x86: use kbuild.h
    
    Drop the macro definitions in asm-offsets_*.c and use kbuild.h
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 494e1e096ee6..f126c05d6170 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -10,6 +10,7 @@
 #include <linux/errno.h> 
 #include <linux/hardirq.h>
 #include <linux/suspend.h>
+#include <linux/kbuild.h>
 #include <asm/pda.h>
 #include <asm/processor.h>
 #include <asm/segment.h>
@@ -17,14 +18,6 @@
 #include <asm/ia32.h>
 #include <asm/bootparam.h>
 
-#define DEFINE(sym, val) \
-        asm volatile("\n->" #sym " %0 " #val : : "i" (val))
-
-#define BLANK() asm volatile("\n->" : : )
-
-#define OFFSET(sym, str, mem) \
-	DEFINE(sym, offsetof(struct str, mem))
-
 #define __NO_STUBS 1
 #undef __SYSCALL
 #undef _ASM_X86_64_UNISTD_H_

commit a59153dceb860f810b2ecd2504162309291edd4c
Author: Glauber de Oliveira Costa <gcosta@redhat.com>
Date:   Wed Jan 30 13:33:19 2008 +0100

    x86: add asm_offset PARAVIRT constants
    
    This patch adds the constant PARAVIRT needs in asm_offsets_64.c
    
    Signed-off-by: Glauber de Oliveira Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 2b32719a3fea..494e1e096ee6 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -61,6 +61,20 @@ int main(void)
 	ENTRY(data_offset);
 	BLANK();
 #undef ENTRY
+#ifdef CONFIG_PARAVIRT
+	BLANK();
+	OFFSET(PARAVIRT_enabled, pv_info, paravirt_enabled);
+	OFFSET(PARAVIRT_PATCH_pv_cpu_ops, paravirt_patch_template, pv_cpu_ops);
+	OFFSET(PARAVIRT_PATCH_pv_irq_ops, paravirt_patch_template, pv_irq_ops);
+	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
+	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
+	OFFSET(PV_CPU_iret, pv_cpu_ops, iret);
+	OFFSET(PV_CPU_irq_enable_syscall_ret, pv_cpu_ops, irq_enable_syscall_ret);
+	OFFSET(PV_CPU_swapgs, pv_cpu_ops, swapgs);
+	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
+#endif
+
+
 #ifdef CONFIG_IA32_EMULATION
 #define ENTRY(entry) DEFINE(IA32_SIGCONTEXT_ ## entry, offsetof(struct sigcontext_ia32, entry))
 	ENTRY(ax);

commit ca241c75037b32e0216a68e39ad2801d04fa1f87
Author: Glauber de Oliveira Costa <gcosta@redhat.com>
Date:   Wed Jan 30 13:31:31 2008 +0100

    x86: unify tss_struct
    
    Although slighly different, the tss_struct is very similar in x86_64 and
    i386. The really different part, which matchs the hardware vision of it, is
    now called x86_hw_tss, and each of the architectures provides yours.
    It's then used as a field in the outter tss_struct.
    
    Signed-off-by: Glauber de Oliveira Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index a05428764314..2b32719a3fea 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -110,7 +110,7 @@ int main(void)
 	ENTRY(cr8);
 	BLANK();
 #undef ENTRY
-	DEFINE(TSS_ist, offsetof(struct tss_struct, ist));
+	DEFINE(TSS_ist, offsetof(struct tss_struct, x86_tss.ist));
 	BLANK();
 	DEFINE(crypto_tfm_ctx_offset, offsetof(struct crypto_tfm, __crt_ctx));
 	BLANK();

commit 742fa54a62be6a263df14a553bf832724471dfbe
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Jan 30 13:30:56 2008 +0100

    x86: use generic register names in struct sigcontext
    
    Switch struct sigcontext (defined in <asm/sigcontext*.h>) to using
    register names withut e- or r-prefixes for both 32- and 64-bit x86.
    This is intended as a preliminary step in unifying this code between
    architectures.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 2e918ebf21d3..a05428764314 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -63,15 +63,15 @@ int main(void)
 #undef ENTRY
 #ifdef CONFIG_IA32_EMULATION
 #define ENTRY(entry) DEFINE(IA32_SIGCONTEXT_ ## entry, offsetof(struct sigcontext_ia32, entry))
-	ENTRY(eax);
-	ENTRY(ebx);
-	ENTRY(ecx);
-	ENTRY(edx);
-	ENTRY(esi);
-	ENTRY(edi);
-	ENTRY(ebp);
-	ENTRY(esp);
-	ENTRY(eip);
+	ENTRY(ax);
+	ENTRY(bx);
+	ENTRY(cx);
+	ENTRY(dx);
+	ENTRY(si);
+	ENTRY(di);
+	ENTRY(bp);
+	ENTRY(sp);
+	ENTRY(ip);
 	BLANK();
 #undef ENTRY
 	DEFINE(IA32_RT_SIGFRAME_sigcontext,

commit 65ea5b0349903585bfed9720fa06f5edb4f1cd25
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Jan 30 13:30:56 2008 +0100

    x86: rename the struct pt_regs members for 32/64-bit consistency
    
    We have a lot of code which differs only by the naming of specific
    members of structures that contain registers.  In order to enable
    additional unifications, this patch drops the e- or r- size prefix
    from the register names in struct pt_regs, and drops the x- prefixes
    for segment registers on the 32-bit side.
    
    This patch also performs the equivalent renames in some additional
    places that might be candidates for unification in the future.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index c27c646214f4..2e918ebf21d3 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -83,14 +83,14 @@ int main(void)
 	DEFINE(pbe_next, offsetof(struct pbe, next));
 	BLANK();
 #define ENTRY(entry) DEFINE(pt_regs_ ## entry, offsetof(struct pt_regs, entry))
-	ENTRY(rbx);
-	ENTRY(rbx);
-	ENTRY(rcx);
-	ENTRY(rdx);
-	ENTRY(rsp);
-	ENTRY(rbp);
-	ENTRY(rsi);
-	ENTRY(rdi);
+	ENTRY(bx);
+	ENTRY(bx);
+	ENTRY(cx);
+	ENTRY(dx);
+	ENTRY(sp);
+	ENTRY(bp);
+	ENTRY(si);
+	ENTRY(di);
 	ENTRY(r8);
 	ENTRY(r9);
 	ENTRY(r10);
@@ -99,7 +99,7 @@ int main(void)
 	ENTRY(r13);
 	ENTRY(r14);
 	ENTRY(r15);
-	ENTRY(eflags);
+	ENTRY(flags);
 	BLANK();
 #undef ENTRY
 #define ENTRY(entry) DEFINE(saved_context_ ## entry, offsetof(struct saved_context, entry))

commit 36197c92a20c142fc2a068e0366053d770fa0096
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Jan 30 13:30:43 2008 +0100

    x86 vDSO: ia32 sysenter_return
    
    This changes the 64-bit kernel's support for the 32-bit sysenter
    instruction to use stored fields rather than constants for the
    user-mode return address, as the 32-bit kernel does.  This adds a
    sysenter_return field to struct thread_info, as 32-bit has.  There
    is no observable effect from this yet.  It makes the assembly code
    independent of the 32-bit vDSO mapping address, paving the way for
    making the vDSO address vary as it does on the 32-bit kernel.
    
    [ akpm@linux-foundation.org: build fix on !CONFIG_IA32_EMULATION ]
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 40f41752c1df..c27c646214f4 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -46,6 +46,9 @@ int main(void)
 	ENTRY(addr_limit);
 	ENTRY(preempt_count);
 	ENTRY(status);
+#ifdef CONFIG_IA32_EMULATION
+	ENTRY(sysenter_return);
+#endif
 	BLANK();
 #undef ENTRY
 #define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))

commit 5cabbd97b10229159919ff17f746b69742cec84d
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed Jan 30 13:30:39 2008 +0100

    x86: remove unused tsk_thread from asm-offsets_64.c
    
    So this patch simply removes the "thread" from asm-offsets.c since I
    can't find an owner for it.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index d1b6ed98774e..40f41752c1df 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -38,7 +38,6 @@ int main(void)
 #define ENTRY(entry) DEFINE(tsk_ ## entry, offsetof(struct task_struct, entry))
 	ENTRY(state);
 	ENTRY(flags); 
-	ENTRY(thread); 
 	ENTRY(pid);
 	BLANK();
 #undef ENTRY

commit bd53147db8bdf5dd49025c198ff18ac23f560e0e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Oct 26 11:29:04 2007 -0600

    x86: Fix boot protocol KEEP_SEGMENTS check.
    
    The kernel only ever supports 1 version of the boot protocol
    so there is no need to check the boot protocol revision to
    see if a feature is supported.
    
    Both x86 and x86_64 support the same boot protocol so we need
    to implement the KEEP_SEGMENTS on x86_64 as well.  It isn't
    just paravirt bootloaders that could use this functionality.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Vivek Goyal <vgoyal@in.ibm.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Zachary Amsden <zach@vmware.com>
    Cc: Andi Kleen <ak@suse.de>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 7e50bda565b4..d1b6ed98774e 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -15,12 +15,16 @@
 #include <asm/segment.h>
 #include <asm/thread_info.h>
 #include <asm/ia32.h>
+#include <asm/bootparam.h>
 
 #define DEFINE(sym, val) \
         asm volatile("\n->" #sym " %0 " #val : : "i" (val))
 
 #define BLANK() asm volatile("\n->" : : )
 
+#define OFFSET(sym, str, mem) \
+	DEFINE(sym, offsetof(struct str, mem))
+
 #define __NO_STUBS 1
 #undef __SYSCALL
 #undef _ASM_X86_64_UNISTD_H_
@@ -109,5 +113,11 @@ int main(void)
 	DEFINE(crypto_tfm_ctx_offset, offsetof(struct crypto_tfm, __crt_ctx));
 	BLANK();
 	DEFINE(__NR_syscall_max, sizeof(syscalls) - 1);
+
+	BLANK();
+	OFFSET(BP_scratch, boot_params, scratch);
+	OFFSET(BP_loadflags, boot_params, hdr.loadflags);
+	OFFSET(BP_hardware_subarch, boot_params, hdr.hardware_subarch);
+	OFFSET(BP_version, boot_params, hdr.version);
 	return 0;
 }

commit 0de80bcc2baed116a569c38cbc38c5dcb945d14d
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Oct 23 22:37:24 2007 +0200

    x86: Save registers in saved_context during suspend and hibernation
    
    During hibernation and suspend on x86_64 save CPU registers in the saved_context
    structure rather than in a handful of separate variables.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 778953bc636c..7e50bda565b4 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -76,6 +76,34 @@ int main(void)
 	DEFINE(pbe_orig_address, offsetof(struct pbe, orig_address));
 	DEFINE(pbe_next, offsetof(struct pbe, next));
 	BLANK();
+#define ENTRY(entry) DEFINE(pt_regs_ ## entry, offsetof(struct pt_regs, entry))
+	ENTRY(rbx);
+	ENTRY(rbx);
+	ENTRY(rcx);
+	ENTRY(rdx);
+	ENTRY(rsp);
+	ENTRY(rbp);
+	ENTRY(rsi);
+	ENTRY(rdi);
+	ENTRY(r8);
+	ENTRY(r9);
+	ENTRY(r10);
+	ENTRY(r11);
+	ENTRY(r12);
+	ENTRY(r13);
+	ENTRY(r14);
+	ENTRY(r15);
+	ENTRY(eflags);
+	BLANK();
+#undef ENTRY
+#define ENTRY(entry) DEFINE(saved_context_ ## entry, offsetof(struct saved_context, entry))
+	ENTRY(cr0);
+	ENTRY(cr2);
+	ENTRY(cr3);
+	ENTRY(cr4);
+	ENTRY(cr8);
+	BLANK();
+#undef ENTRY
 	DEFINE(TSS_ist, offsetof(struct tss_struct, ist));
 	BLANK();
 	DEFINE(crypto_tfm_ctx_offset, offsetof(struct crypto_tfm, __crt_ctx));

commit 250c22777fe1ccd7ac588579a6c16db4c0161cc5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Oct 11 11:17:24 2007 +0200

    x86_64: move kernel
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
new file mode 100644
index 000000000000..778953bc636c
--- /dev/null
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -0,0 +1,85 @@
+/*
+ * Generate definitions needed by assembly language modules.
+ * This code generates raw asm output which is post-processed to extract
+ * and format the required data.
+ */
+
+#include <linux/crypto.h>
+#include <linux/sched.h> 
+#include <linux/stddef.h>
+#include <linux/errno.h> 
+#include <linux/hardirq.h>
+#include <linux/suspend.h>
+#include <asm/pda.h>
+#include <asm/processor.h>
+#include <asm/segment.h>
+#include <asm/thread_info.h>
+#include <asm/ia32.h>
+
+#define DEFINE(sym, val) \
+        asm volatile("\n->" #sym " %0 " #val : : "i" (val))
+
+#define BLANK() asm volatile("\n->" : : )
+
+#define __NO_STUBS 1
+#undef __SYSCALL
+#undef _ASM_X86_64_UNISTD_H_
+#define __SYSCALL(nr, sym) [nr] = 1,
+static char syscalls[] = {
+#include <asm/unistd.h>
+};
+
+int main(void)
+{
+#define ENTRY(entry) DEFINE(tsk_ ## entry, offsetof(struct task_struct, entry))
+	ENTRY(state);
+	ENTRY(flags); 
+	ENTRY(thread); 
+	ENTRY(pid);
+	BLANK();
+#undef ENTRY
+#define ENTRY(entry) DEFINE(threadinfo_ ## entry, offsetof(struct thread_info, entry))
+	ENTRY(flags);
+	ENTRY(addr_limit);
+	ENTRY(preempt_count);
+	ENTRY(status);
+	BLANK();
+#undef ENTRY
+#define ENTRY(entry) DEFINE(pda_ ## entry, offsetof(struct x8664_pda, entry))
+	ENTRY(kernelstack); 
+	ENTRY(oldrsp); 
+	ENTRY(pcurrent); 
+	ENTRY(irqcount);
+	ENTRY(cpunumber);
+	ENTRY(irqstackptr);
+	ENTRY(data_offset);
+	BLANK();
+#undef ENTRY
+#ifdef CONFIG_IA32_EMULATION
+#define ENTRY(entry) DEFINE(IA32_SIGCONTEXT_ ## entry, offsetof(struct sigcontext_ia32, entry))
+	ENTRY(eax);
+	ENTRY(ebx);
+	ENTRY(ecx);
+	ENTRY(edx);
+	ENTRY(esi);
+	ENTRY(edi);
+	ENTRY(ebp);
+	ENTRY(esp);
+	ENTRY(eip);
+	BLANK();
+#undef ENTRY
+	DEFINE(IA32_RT_SIGFRAME_sigcontext,
+	       offsetof (struct rt_sigframe32, uc.uc_mcontext));
+	BLANK();
+#endif
+	DEFINE(pbe_address, offsetof(struct pbe, address));
+	DEFINE(pbe_orig_address, offsetof(struct pbe, orig_address));
+	DEFINE(pbe_next, offsetof(struct pbe, next));
+	BLANK();
+	DEFINE(TSS_ist, offsetof(struct tss_struct, ist));
+	BLANK();
+	DEFINE(crypto_tfm_ctx_offset, offsetof(struct crypto_tfm, __crt_ctx));
+	BLANK();
+	DEFINE(__NR_syscall_max, sizeof(syscalls) - 1);
+	return 0;
+}
