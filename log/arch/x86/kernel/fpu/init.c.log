commit 8ab22804efefea9ecf3c68aa00f1fa69c70fcfad
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Tue May 12 07:54:36 2020 -0700

    x86/fpu/xstate: Define new macros for supervisor and user xstates
    
    XCNTXT_MASK is 'all supported xfeatures' before introducing supervisor
    xstates.  Rename it to XFEATURE_MASK_USER_SUPPORTED to make clear that
    these are user xstates.
    
    Replace XFEATURE_MASK_SUPERVISOR with the following:
    - XFEATURE_MASK_SUPERVISOR_SUPPORTED: Currently nothing.  ENQCMD and
      Control-flow Enforcement Technology (CET) will be introduced in separate
      series.
    - XFEATURE_MASK_SUPERVISOR_UNSUPPORTED: Currently only Processor Trace.
    - XFEATURE_MASK_SUPERVISOR_ALL: the combination of above.
    
    Co-developed-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Link: https://lkml.kernel.org/r/20200512145444.15483-3-yu-cheng.yu@intel.com

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6ce7e0a23268..61ddc3a5e5c2 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -224,7 +224,8 @@ static void __init fpu__init_system_xstate_size_legacy(void)
  */
 u64 __init fpu__get_supported_xfeatures_mask(void)
 {
-	return XCNTXT_MASK;
+	return XFEATURE_MASK_USER_SUPPORTED |
+	       XFEATURE_MASK_SUPERVISOR_SUPPORTED;
 }
 
 /* Legacy code to initialize eager fpu mode. */

commit 7891bc0ab739a31538b5f879a523232b8b07a0d3
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Thu Jul 4 08:07:43 2019 +0200

    x86/fpu: Inline fpu__xstate_clear_all_cpu_caps()
    
    All fpu__xstate_clear_all_cpu_caps() does is to invoke one simple
    function since commit
    
      73e3a7d2a7c3b ("x86/fpu: Remove the explicit clearing of XSAVE dependent features")
    
    so invoke that function directly and remove the wrapper.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190704060743.rvew4yrjd6n33uzx@linutronix.de

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 5baae74af4f9..6ce7e0a23268 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -259,7 +259,7 @@ static void __init fpu__init_parse_early_param(void)
 #endif
 
 	if (cmdline_find_option_bool(boot_command_line, "noxsave"))
-		fpu__xstate_clear_all_cpu_caps();
+		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 
 	if (cmdline_find_option_bool(boot_command_line, "noxsaveopt"))
 		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);

commit 9838e3bff0f92f23fcd50fe1ff1d4b3e91b8a448
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jul 3 10:32:47 2019 +0200

    x86/fpu: Make 'no387' and 'nofxsr' command line options useful
    
    The command line option `no387' is designed to disable the FPU
    entirely. This only 'works' with CONFIG_MATH_EMULATION enabled.
    
    But on 64bit this cannot work because user space expects SSE to work which
    required basic FPU support. MATH_EMULATION does not help because SSE is not
    emulated.
    
    The command line option `nofxsr' should also be limited to 32bit because
    FXSR is part of the required flags on 64bit so turning it off is not
    possible.
    
    Clearing X86_FEATURE_FPU without emulation enabled will not work anyway and
    hang in fpu__init_system_early_generic() before the console is enabled.
    
    Setting additioal dependencies, ensures that the CPU still boots on a
    modern CPU. Otherwise, dropping FPU will leave FXSR enabled causing the
    kernel to crash early in fpu__init_system_mxcsr().
    
    With XSAVE support it will crash in fpu__init_cpu_xstate(). The problem is
    that xsetbv() with XMM set and SSE cleared is not allowed.  That means
    XSAVE has to be disabled. The XSAVE support is disabled in
    fpu__init_system_xstate_size_legacy() but it is too late. It can be
    removed, it has been added in commit
    
      1f999ab5a1360 ("x86, xsave: Disable xsave in i387 emulation mode")
    
    to use `no387' on a CPU with XSAVE support.
    
    All this happens before console output.
    
    After hat, the next possible crash is in RAID6 detect code because MMX
    remained enabled. With a 3DNOW enabled config it will explode in memcpy()
    for instance due to kernel_fpu_begin() but this is unconditionally enabled.
    
    This is enough to boot a Debian Wheezy on a 32bit qemu "host" CPU which
    supports everything up to XSAVES, AVX2 without 3DNOW. Later, Debian
    increased the minimum requirements to i686 which means it does not boot
    userland atleast due to CMOV.
    
    After masking the additional features it still keeps SSE4A and 3DNOW*
    enabled (if present on the host) but those are unused in the kernel.
    
    Restrict `no387' and `nofxsr' otions to 32bit only. Add dependencies for
    FPU, FXSR to additionaly mask CMOV, MMX, XSAVE if FXSR or FPU is cleared.
    
    Reported-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190703083247.57kjrmlxkai3vpw3@linutronix.de

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index ef0030e3fe6b..5baae74af4f9 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -204,12 +204,6 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 	 */
 
 	if (!boot_cpu_has(X86_FEATURE_FPU)) {
-		/*
-		 * Disable xsave as we do not support it if i387
-		 * emulation is enabled.
-		 */
-		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
-		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
 		fpu_kernel_xstate_size = sizeof(struct swregs_state);
 	} else {
 		if (boot_cpu_has(X86_FEATURE_FXSR))
@@ -252,14 +246,17 @@ static void __init fpu__init_parse_early_param(void)
 	char *argptr = arg;
 	int bit;
 
+#ifdef CONFIG_X86_32
 	if (cmdline_find_option_bool(boot_command_line, "no387"))
+#ifdef CONFIG_MATH_EMULATION
 		setup_clear_cpu_cap(X86_FEATURE_FPU);
+#else
+		pr_err("Option 'no387' required CONFIG_MATH_EMULATION enabled.\n");
+#endif
 
-	if (cmdline_find_option_bool(boot_command_line, "nofxsr")) {
+	if (cmdline_find_option_bool(boot_command_line, "nofxsr"))
 		setup_clear_cpu_cap(X86_FEATURE_FXSR);
-		setup_clear_cpu_cap(X86_FEATURE_FXSR_OPT);
-		setup_clear_cpu_cap(X86_FEATURE_XMM);
-	}
+#endif
 
 	if (cmdline_find_option_bool(boot_command_line, "noxsave"))
 		fpu__xstate_clear_all_cpu_caps();

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 20d8fa7124c7..ef0030e3fe6b 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * x86 FPU boot time init code:
  */

commit 2722146eb78451b30e4717a267a3a2b44e4ad317
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Apr 3 18:41:36 2019 +0200

    x86/fpu: Remove fpu->initialized
    
    The struct fpu.initialized member is always set to one for user tasks
    and zero for kernel tasks. This avoids saving/restoring the FPU
    registers for kernel threads.
    
    The ->initialized = 0 case for user tasks has been removed in previous
    changes, for instance, by doing an explicit unconditional init at fork()
    time for FPU-less systems which was otherwise delayed until the emulated
    opcode.
    
    The context switch code (switch_fpu_prepare() + switch_fpu_finish())
    can't unconditionally save/restore registers for kernel threads. Not
    only would it slow down the switch but also load a zeroed xcomp_bv for
    XSAVES.
    
    For kernel_fpu_begin() (+end) the situation is similar: EFI with runtime
    services uses this before alternatives_patched is true. Which means that
    this function is used too early and it wasn't the case before.
    
    For those two cases, use current->mm to distinguish between user and
    kernel thread. For kernel_fpu_begin() skip save/restore of the FPU
    registers.
    
    During the context switch into a kernel thread don't do anything. There
    is no reason to save the FPU state of a kernel thread.
    
    The reordering in __switch_to() is important because the current()
    pointer needs to be valid before switch_fpu_finish() is invoked so ->mm
    is seen of the new task instead the old one.
    
    N.B.: fpu__save() doesn't need to check ->mm because it is called by
    user tasks only.
    
     [ bp: Massage. ]
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Aubrey Li <aubrey.li@intel.com>
    Cc: Babu Moger <Babu.Moger@amd.com>
    Cc: "Chang S. Bae" <chang.seok.bae@intel.com>
    Cc: Dmitry Safonov <dima@arista.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: kvm ML <kvm@vger.kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20190403164156.19645-8-bigeasy@linutronix.de

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6abd83572b01..20d8fa7124c7 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -239,8 +239,6 @@ static void __init fpu__init_system_ctx_switch(void)
 
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;
-
-	WARN_ON_FPU(current->thread.fpu.initialized);
 }
 
 /*

commit 0c2a3913d6f50503f7c59d83a6219e39508cc898
Author: Andi Kleen <ak@linux.intel.com>
Date:   Fri Oct 13 14:56:43 2017 -0700

    x86/fpu: Parse clearcpuid= as early XSAVE argument
    
    With a followon patch we want to make clearcpuid affect the XSAVE
    configuration. But xsave is currently initialized before arguments
    are parsed. Move the clearcpuid= parsing into the special
    early xsave argument parsing code.
    
    Since clearcpuid= contains a = we need to keep the old __setup
    around as a dummy, otherwise it would end up as a environment
    variable in init's environment.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20171013215645.23166-4-andi@firstfloor.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 7affb7e3d9a5..6abd83572b01 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -249,6 +249,10 @@ static void __init fpu__init_system_ctx_switch(void)
  */
 static void __init fpu__init_parse_early_param(void)
 {
+	char arg[32];
+	char *argptr = arg;
+	int bit;
+
 	if (cmdline_find_option_bool(boot_command_line, "no387"))
 		setup_clear_cpu_cap(X86_FEATURE_FPU);
 
@@ -266,6 +270,13 @@ static void __init fpu__init_parse_early_param(void)
 
 	if (cmdline_find_option_bool(boot_command_line, "noxsaves"))
 		setup_clear_cpu_cap(X86_FEATURE_XSAVES);
+
+	if (cmdline_find_option(boot_command_line, "clearcpuid", arg,
+				sizeof(arg)) &&
+	    get_option(&argptr, &bit) &&
+	    bit >= 0 &&
+	    bit < NCAPINTS * 32)
+		setup_clear_cpu_cap(bit);
 }
 
 /*

commit e4a81bfcaae1ebbdc6efe74e8ea563144d90e9a9
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Sep 26 09:43:36 2017 +0200

    x86/fpu: Rename fpu::fpstate_active to fpu::initialized
    
    The x86 FPU code used to have a complex state machine where both the FPU
    registers and the FPU state context could be 'active' (or inactive)
    independently of each other - which enabled features like lazy FPU restore.
    
    Much of this complexity is gone in the current code: now we basically can
    have FPU-less tasks (kernel threads) that don't use (and save/restore) FPU
    state at all, plus full FPU users that save/restore directly with no laziness
    whatsoever.
    
    But the fpu::fpstate_active still carries bits of the old complexity - meanwhile
    this flag has become a simple flag that shows whether the FPU context saving
    area in the thread struct is initialized and used, or not.
    
    Rename it to fpu::initialized to express this simplicity in the name as well.
    
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Eric Biggers <ebiggers3@gmail.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/20170923130016.21448-30-mingo@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index d5d44c452624..7affb7e3d9a5 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -240,7 +240,7 @@ static void __init fpu__init_system_ctx_switch(void)
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;
 
-	WARN_ON_FPU(current->thread.fpu.fpstate_active);
+	WARN_ON_FPU(current->thread.fpu.initialized);
 }
 
 /*

commit a575813bfe4bc15aba511a5e91e61d242bff8b9d
Author: Wanpeng Li <wanpeng.li@hotmail.com>
Date:   Thu May 11 02:58:55 2017 -0700

    KVM: x86: Fix load damaged SSEx MXCSR register
    
    Reported by syzkaller:
    
       BUG: unable to handle kernel paging request at ffffffffc07f6a2e
       IP: report_bug+0x94/0x120
       PGD 348e12067
       P4D 348e12067
       PUD 348e14067
       PMD 3cbd84067
       PTE 80000003f7e87161
    
       Oops: 0003 [#1] SMP
       CPU: 2 PID: 7091 Comm: kvm_load_guest_ Tainted: G           OE   4.11.0+ #8
       task: ffff92fdfb525400 task.stack: ffffbda6c3d04000
       RIP: 0010:report_bug+0x94/0x120
       RSP: 0018:ffffbda6c3d07b20 EFLAGS: 00010202
        do_trap+0x156/0x170
        do_error_trap+0xa3/0x170
        ? kvm_load_guest_fpu.part.175+0x12a/0x170 [kvm]
        ? mark_held_locks+0x79/0xa0
        ? retint_kernel+0x10/0x10
        ? trace_hardirqs_off_thunk+0x1a/0x1c
        do_invalid_op+0x20/0x30
        invalid_op+0x1e/0x30
       RIP: 0010:kvm_load_guest_fpu.part.175+0x12a/0x170 [kvm]
        ? kvm_load_guest_fpu.part.175+0x1c/0x170 [kvm]
        kvm_arch_vcpu_ioctl_run+0xed6/0x1b70 [kvm]
        kvm_vcpu_ioctl+0x384/0x780 [kvm]
        ? kvm_vcpu_ioctl+0x384/0x780 [kvm]
        ? sched_clock+0x13/0x20
        ? __do_page_fault+0x2a0/0x550
        do_vfs_ioctl+0xa4/0x700
        ? up_read+0x1f/0x40
        ? __do_page_fault+0x2a0/0x550
        SyS_ioctl+0x79/0x90
        entry_SYSCALL_64_fastpath+0x23/0xc2
    
    SDM mentioned that "The MXCSR has several reserved bits, and attempting to write
    a 1 to any of these bits will cause a general-protection exception(#GP) to be
    generated". The syzkaller forks' testcase overrides xsave area w/ random values
    and steps on the reserved bits of MXCSR register. The damaged MXCSR register
    values of guest will be restored to SSEx MXCSR register before vmentry. This
    patch fixes it by catching userspace override MXCSR register reserved bits w/
    random values and bails out immediately.
    
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Wanpeng Li <wanpeng.li@hotmail.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index c2f8dde3255c..d5d44c452624 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -90,6 +90,7 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
  * Boot time FPU feature detection code:
  */
 unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
+EXPORT_SYMBOL_GPL(mxcsr_feature_mask);
 
 static void __init fpu__init_system_mxcsr(void)
 {

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 19bdd1bf8160..c2f8dde3255c 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -7,6 +7,7 @@
 #include <asm/cmdline.h>
 
 #include <linux/sched.h>
+#include <linux/sched/task.h>
 #include <linux/init.h>
 
 /*

commit 9729017f844431ab2800519297d8d1b0ecbc420d
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Jan 18 11:15:42 2017 -0800

    x86/fpu: Fix the "Giving up, no FPU found" test
    
    We would never print "Giving up, no FPU found" because
    X86_FEATURE_FPU was in REQUIRED_MASK on non-FPU-emulating builds, so
    the boot_cpu_has() test didn't do anything.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthew Whitehead <tedheadster@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: One Thousand Gnomes <gnomes@lxorguk.ukuu.org.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/1499077fa76f0f84b8ea28e37d3fa70beca4e310.1484705016.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 8b526c5fc306..19bdd1bf8160 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -77,7 +77,7 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 	}
 
 #ifndef CONFIG_MATH_EMULATION
-	if (!boot_cpu_has(X86_FEATURE_FPU)) {
+	if (!test_cpu_cap(&boot_cpu_data, X86_FEATURE_FPU)) {
 		pr_emerg("x86/fpu: Giving up, no FPU found and no math emulation present\n");
 		for (;;)
 			asm volatile("hlt");

commit 37ac78b67b3384d1ced5424d5a13ee146041bda3
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Jan 18 11:15:41 2017 -0800

    x86/fpu: Fix CPUID-less FPU detection
    
    The old code didn't work at all because it adjusted the current caps
    instead of the forced caps.  Anything it did would be undone later
    during CPU identification.  Fix that and, while we're at it, improve
    the logging and don't bother running it if CPUID is available.
    
    Reported-by: Matthew Whitehead <tedheadster@gmail.com>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: One Thousand Gnomes <gnomes@lxorguk.ukuu.org.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/f1134e30cafa73c4e2e68119e9741793622cfd15.1484705016.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 60dece392b3a..8b526c5fc306 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -48,13 +48,7 @@ void fpu__init_cpu(void)
 	fpu__init_cpu_xstate();
 }
 
-/*
- * The earliest FPU detection code.
- *
- * Set the X86_FEATURE_FPU CPU-capability bit based on
- * trying to execute an actual sequence of FPU instructions:
- */
-static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
+static bool fpu__probe_without_cpuid(void)
 {
 	unsigned long cr0;
 	u16 fsw, fcw;
@@ -65,14 +59,21 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 	cr0 &= ~(X86_CR0_TS | X86_CR0_EM);
 	write_cr0(cr0);
 
-	if (!test_bit(X86_FEATURE_FPU, (unsigned long *)cpu_caps_cleared)) {
-		asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
-			     : "+m" (fsw), "+m" (fcw));
+	asm volatile("fninit ; fnstsw %0 ; fnstcw %1" : "+m" (fsw), "+m" (fcw));
+
+	pr_info("x86/fpu: Probing for FPU: FSW=0x%04hx FCW=0x%04hx\n", fsw, fcw);
 
-		if (fsw == 0 && (fcw & 0x103f) == 0x003f)
-			set_cpu_cap(c, X86_FEATURE_FPU);
+	return fsw == 0 && (fcw & 0x103f) == 0x003f;
+}
+
+static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
+{
+	if (!boot_cpu_has(X86_FEATURE_CPUID) &&
+	    !test_bit(X86_FEATURE_FPU, (unsigned long *)cpu_caps_cleared)) {
+		if (fpu__probe_without_cpuid())
+			setup_force_cpu_cap(X86_FEATURE_FPU);
 		else
-			clear_cpu_cap(c, X86_FEATURE_FPU);
+			setup_clear_cpu_cap(X86_FEATURE_FPU);
 	}
 
 #ifndef CONFIG_MATH_EMULATION

commit 36fd4f0249f8cb445835acb7c6937a0ffa2b5f14
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 31 15:18:42 2016 -0700

    x86/fpu: Get rid of two redundant clts() calls
    
    CR0.TS is cleared by a direct CR0 write in fpu__init_cpu_generic().
    We don't need to call clts() two more times right after that.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: kvm list <kvm@vger.kernel.org>
    Link: http://lkml.kernel.org/r/476d2d5066eda24838853426ea74c94140b50c85.1477951965.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 1a09d133c801..60dece392b3a 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -9,15 +9,6 @@
 #include <linux/sched.h>
 #include <linux/init.h>
 
-/*
- * Initialize the TS bit in CR0 according to the style of context-switches
- * we are using:
- */
-static void fpu__init_cpu_ctx_switch(void)
-{
-	clts();
-}
-
 /*
  * Initialize the registers found in all CPUs, CR0 and CR4:
  */
@@ -55,7 +46,6 @@ void fpu__init_cpu(void)
 {
 	fpu__init_cpu_generic();
 	fpu__init_cpu_xstate();
-	fpu__init_cpu_ctx_switch();
 }
 
 /*
@@ -290,14 +280,6 @@ void __init fpu__init_system(struct cpuinfo_x86 *c)
 	 */
 	fpu__init_cpu();
 
-	/*
-	 * But don't leave CR0::TS set yet, as some of the FPU setup
-	 * methods depend on being able to execute FPU instructions
-	 * that will fault on a set TS, such as the FXSAVE in
-	 * fpu__init_system_mxcsr().
-	 */
-	clts();
-
 	fpu__init_system_generic();
 	fpu__init_system_xstate_size_legacy();
 	fpu__init_system_xstate();

commit ca6938a1cd8a1c5e861a99b67f84ac166fc2b9e7
Author: Andy Lutomirski <luto@kernel.org>
Date:   Tue Oct 4 20:34:31 2016 -0400

    x86/fpu: Hard-disable lazy FPU mode
    
    Since commit:
    
      58122bf1d856 ("x86/fpu: Default eagerfpu=on on all CPUs")
    
    ... in Linux 4.6, eager FPU mode has been the default on all x86
    systems, and no one has reported any regressions.
    
    This patch removes the ability to enable lazy mode: use_eager_fpu()
    becomes "return true" and all of the FPU mode selection machinery is
    removed.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: pbonzini@redhat.com
    Link: http://lkml.kernel.org/r/1475627678-20788-3-git-send-email-riel@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 2f2b8c7ccb85..1a09d133c801 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -15,10 +15,7 @@
  */
 static void fpu__init_cpu_ctx_switch(void)
 {
-	if (!boot_cpu_has(X86_FEATURE_EAGER_FPU))
-		stts();
-	else
-		clts();
+	clts();
 }
 
 /*
@@ -232,42 +229,6 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 	fpu_user_xstate_size = fpu_kernel_xstate_size;
 }
 
-/*
- * FPU context switching strategies:
- *
- * Against popular belief, we don't do lazy FPU saves, due to the
- * task migration complications it brings on SMP - we only do
- * lazy FPU restores.
- *
- * 'lazy' is the traditional strategy, which is based on setting
- * CR0::TS to 1 during context-switch (instead of doing a full
- * restore of the FPU state), which causes the first FPU instruction
- * after the context switch (whenever it is executed) to fault - at
- * which point we lazily restore the FPU state into FPU registers.
- *
- * Tasks are of course under no obligation to execute FPU instructions,
- * so it can easily happen that another context-switch occurs without
- * a single FPU instruction being executed. If we eventually switch
- * back to the original task (that still owns the FPU) then we have
- * not only saved the restores along the way, but we also have the
- * FPU ready to be used for the original task.
- *
- * 'lazy' is deprecated because it's almost never a performance win
- * and it's much more complicated than 'eager'.
- *
- * 'eager' switching is by default on all CPUs, there we switch the FPU
- * state during every context switch, regardless of whether the task
- * has used FPU instructions in that time slice or not. This is done
- * because modern FPU context saving instructions are able to optimize
- * state saving and restoration in hardware: they can detect both
- * unused and untouched FPU state and optimize accordingly.
- *
- * [ Note that even in 'lazy' mode we might optimize context switches
- *   to use 'eager' restores, if we detect that a task is using the FPU
- *   frequently. See the fpu->counter logic in fpu/internal.h for that. ]
- */
-static enum { ENABLE, DISABLE } eagerfpu = ENABLE;
-
 /*
  * Find supported xfeatures based on cpu features and command-line input.
  * This must be called after fpu__init_parse_early_param() is called and
@@ -275,40 +236,10 @@ static enum { ENABLE, DISABLE } eagerfpu = ENABLE;
  */
 u64 __init fpu__get_supported_xfeatures_mask(void)
 {
-	/* Support all xfeatures known to us */
-	if (eagerfpu != DISABLE)
-		return XCNTXT_MASK;
-
-	/* Warning of xfeatures being disabled for no eagerfpu mode */
-	if (xfeatures_mask & XFEATURE_MASK_EAGER) {
-		pr_err("x86/fpu: eagerfpu switching disabled, disabling the following xstate features: 0x%llx.\n",
-			xfeatures_mask & XFEATURE_MASK_EAGER);
-	}
-
-	/* Return a mask that masks out all features requiring eagerfpu mode */
-	return ~XFEATURE_MASK_EAGER;
-}
-
-/*
- * Disable features dependent on eagerfpu.
- */
-static void __init fpu__clear_eager_fpu_features(void)
-{
-	setup_clear_cpu_cap(X86_FEATURE_MPX);
+	return XCNTXT_MASK;
 }
 
-/*
- * Pick the FPU context switching strategy:
- *
- * When eagerfpu is AUTO or ENABLE, we ensure it is ENABLE if either of
- * the following is true:
- *
- * (1) the cpu has xsaveopt, as it has the optimization and doing eager
- *     FPU switching has a relatively low cost compared to a plain xsave;
- * (2) the cpu has xsave features (e.g. MPX) that depend on eager FPU
- *     switching. Should the kernel boot with noxsaveopt, we support MPX
- *     with eager FPU switching at a higher cost.
- */
+/* Legacy code to initialize eager fpu mode. */
 static void __init fpu__init_system_ctx_switch(void)
 {
 	static bool on_boot_cpu __initdata = 1;
@@ -317,17 +248,6 @@ static void __init fpu__init_system_ctx_switch(void)
 	on_boot_cpu = 0;
 
 	WARN_ON_FPU(current->thread.fpu.fpstate_active);
-
-	if (boot_cpu_has(X86_FEATURE_XSAVEOPT) && eagerfpu != DISABLE)
-		eagerfpu = ENABLE;
-
-	if (xfeatures_mask & XFEATURE_MASK_EAGER)
-		eagerfpu = ENABLE;
-
-	if (eagerfpu == ENABLE)
-		setup_force_cpu_cap(X86_FEATURE_EAGER_FPU);
-
-	printk(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
 }
 
 /*
@@ -336,11 +256,6 @@ static void __init fpu__init_system_ctx_switch(void)
  */
 static void __init fpu__init_parse_early_param(void)
 {
-	if (cmdline_find_option_bool(boot_command_line, "eagerfpu=off")) {
-		eagerfpu = DISABLE;
-		fpu__clear_eager_fpu_features();
-	}
-
 	if (cmdline_find_option_bool(boot_command_line, "no387"))
 		setup_clear_cpu_cap(X86_FEATURE_FPU);
 

commit b9d989c7218ac922185d82ad46f3e58b27a4bea9
Author: Andy Lutomirski <luto@kernel.org>
Date:   Tue Sep 13 14:29:21 2016 -0700

    x86/asm: Move the thread_info::status field to thread_struct
    
    Because sched.h and thread_info.h are a tangled mess, I turned
    in_compat_syscall() into a macro.  If we had current_thread_struct()
    or similar and we could use it from thread_info.h, then this would
    be a bit cleaner.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jann Horn <jann@thejh.net>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/ccc8a1b2f41f9c264a41f771bb4a6539a642ad72.1473801993.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 93982aebb398..2f2b8c7ccb85 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -317,7 +317,6 @@ static void __init fpu__init_system_ctx_switch(void)
 	on_boot_cpu = 0;
 
 	WARN_ON_FPU(current->thread.fpu.fpstate_active);
-	current_thread_info()->status = 0;
 
 	if (boot_cpu_has(X86_FEATURE_XSAVEOPT) && eagerfpu != DISABLE)
 		eagerfpu = ENABLE;

commit b8be15d588060a03569ac85dc4a0247460988f5b
Author: Yu-cheng Yu <yu-cheng.yu@intel.com>
Date:   Mon Jul 11 09:18:57 2016 -0700

    x86/fpu/xstate: Re-enable XSAVES
    
    We did not handle XSAVES instructions correctly. There were issues in
    converting between standard and compacted format when interfacing with
    user-space. These issues have been corrected.
    
    Add a WARN_ONCE() to make it clear that XSAVES supervisor states are not
    yet implemented.
    
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Cc: H. Peter Anvin <h.peter.anvin@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi V Shankar <ravi.v.shankar@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1468253937-40008-5-git-send-email-fenghua.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 60f3839c5bfa..93982aebb398 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -230,21 +230,6 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 	}
 
 	fpu_user_xstate_size = fpu_kernel_xstate_size;
-
-	/*
-	 * Quirk: we don't yet handle the XSAVES* instructions
-	 * correctly, as we don't correctly convert between
-	 * standard and compacted format when interfacing
-	 * with user-space - so disable it for now.
-	 *
-	 * The difference is small: with recent CPUs the
-	 * compacted format is only marginally smaller than
-	 * the standard FPU state format.
-	 *
-	 * ( This is easy to backport while we are fixing
-	 *   XSAVES* support. )
-	 */
-	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
 }
 
 /*

commit bf15a8cf8d14879b785c548728415d36ccb6a33b
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri May 20 10:47:06 2016 -0700

    x86/fpu/xstate: Rename 'xstate_size' to 'fpu_kernel_xstate_size', to distinguish it from 'fpu_user_xstate_size'
    
    User space uses standard format xsave area. fpstate in signal frame
    should have standard format size.
    
    To explicitly distinguish between xstate size in kernel space and the
    one in user space, we rename 'xstate_size' to 'fpu_kernel_xstate_size'.
    
    Cleanup only, no change in functionality.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    [ Rebased the patch and cleaned up the naming. ]
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/2ecbae347a5152d94be52adf7d0f3b7305d90d99.1463760376.git.yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 5b1928c0aad4..60f3839c5bfa 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -145,8 +145,8 @@ static void __init fpu__init_system_generic(void)
  * This is inherent to the XSAVE architecture which puts all state
  * components into a single, continuous memory block:
  */
-unsigned int xstate_size;
-EXPORT_SYMBOL_GPL(xstate_size);
+unsigned int fpu_kernel_xstate_size;
+EXPORT_SYMBOL_GPL(fpu_kernel_xstate_size);
 
 /* Get alignment of the TYPE. */
 #define TYPE_ALIGN(TYPE) offsetof(struct { char x; TYPE test; }, test)
@@ -178,7 +178,7 @@ static void __init fpu__init_task_struct_size(void)
 	 * Add back the dynamically-calculated register state
 	 * size.
 	 */
-	task_size += xstate_size;
+	task_size += fpu_kernel_xstate_size;
 
 	/*
 	 * We dynamically size 'struct fpu', so we require that
@@ -195,7 +195,7 @@ static void __init fpu__init_task_struct_size(void)
 }
 
 /*
- * Set up the user and kernel xstate_size based on the legacy FPU context size.
+ * Set up the user and kernel xstate sizes based on the legacy FPU context size.
  *
  * We set this up first, and later it will be overwritten by
  * fpu__init_system_xstate() if the CPU knows about xstates.
@@ -208,7 +208,7 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 	on_boot_cpu = 0;
 
 	/*
-	 * Note that xstate_size might be overwriten later during
+	 * Note that xstate sizes might be overwritten later during
 	 * fpu__init_system_xstate().
 	 */
 
@@ -219,15 +219,17 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 		 */
 		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
-		xstate_size = sizeof(struct swregs_state);
+		fpu_kernel_xstate_size = sizeof(struct swregs_state);
 	} else {
 		if (boot_cpu_has(X86_FEATURE_FXSR))
-			xstate_size = sizeof(struct fxregs_state);
+			fpu_kernel_xstate_size =
+				sizeof(struct fxregs_state);
 		else
-			xstate_size = sizeof(struct fregs_state);
+			fpu_kernel_xstate_size =
+				sizeof(struct fregs_state);
 	}
 
-	fpu_user_xstate_size = xstate_size;
+	fpu_user_xstate_size = fpu_kernel_xstate_size;
 
 	/*
 	 * Quirk: we don't yet handle the XSAVES* instructions

commit a1141e0b5ca6ee3e5e35d5f1a310a5ecb9c96ce5
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri May 20 10:47:05 2016 -0700

    x86/fpu/xstate: Define and use 'fpu_user_xstate_size'
    
    The kernel xstate area can be in standard or compacted format;
    it is always in standard format for user mode. When XSAVES is
    enabled, the kernel uses the compacted format and it is necessary
    to use a separate fpu_user_xstate_size for signal/ptrace frames.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    [ Rebased the patch and cleaned up the naming. ]
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/8756ec34dabddfc727cda5743195eb81e8caf91c.1463760376.git.yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index aacfd7a82cec..5b1928c0aad4 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -195,7 +195,7 @@ static void __init fpu__init_task_struct_size(void)
 }
 
 /*
- * Set up the xstate_size based on the legacy FPU context size.
+ * Set up the user and kernel xstate_size based on the legacy FPU context size.
  *
  * We set this up first, and later it will be overwritten by
  * fpu__init_system_xstate() if the CPU knows about xstates.
@@ -226,6 +226,9 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 		else
 			xstate_size = sizeof(struct fregs_state);
 	}
+
+	fpu_user_xstate_size = xstate_size;
+
 	/*
 	 * Quirk: we don't yet handle the XSAVES* instructions
 	 * correctly, as we don't correctly convert between

commit 01f8fd7379149fb9a4046e76617958bf771f856f
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Apr 4 22:25:01 2016 +0200

    x86/cpufeature: Replace cpu_has_fxsr with boot_cpu_has() usage
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1459801503-15600-9-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 3a84275f012e..aacfd7a82cec 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -29,7 +29,7 @@ static void fpu__init_cpu_generic(void)
 	unsigned long cr0;
 	unsigned long cr4_mask = 0;
 
-	if (cpu_has_fxsr)
+	if (boot_cpu_has(X86_FEATURE_FXSR))
 		cr4_mask |= X86_CR4_OSFXSR;
 	if (boot_cpu_has(X86_FEATURE_XMM))
 		cr4_mask |= X86_CR4_OSXMMEXCPT;
@@ -106,7 +106,7 @@ static void __init fpu__init_system_mxcsr(void)
 {
 	unsigned int mask = 0;
 
-	if (cpu_has_fxsr) {
+	if (boot_cpu_has(X86_FEATURE_FXSR)) {
 		/* Static because GCC does not get 16-byte stack alignment right: */
 		static struct fxregs_state fxregs __initdata;
 
@@ -221,7 +221,7 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
 		xstate_size = sizeof(struct swregs_state);
 	} else {
-		if (cpu_has_fxsr)
+		if (boot_cpu_has(X86_FEATURE_FXSR))
 			xstate_size = sizeof(struct fxregs_state);
 		else
 			xstate_size = sizeof(struct fregs_state);

commit a402a8dffc9f838b413c5ee0317d2d3184968f5b
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Apr 4 22:24:58 2016 +0200

    x86/cpufeature: Replace cpu_has_fpu with boot_cpu_has() usage
    
    Use static_cpu_has() in the timing-sensitive paths in fpstate_init() and
    fpu__copy().
    
    While at it, simplify the use in init_cyrix() and get rid of the ternary
    operator.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1459801503-15600-6-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 9bbb332a71ff..3a84275f012e 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -38,13 +38,13 @@ static void fpu__init_cpu_generic(void)
 
 	cr0 = read_cr0();
 	cr0 &= ~(X86_CR0_TS|X86_CR0_EM); /* clear TS and EM */
-	if (!cpu_has_fpu)
+	if (!boot_cpu_has(X86_FEATURE_FPU))
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
 	/* Flush out any pending x87 state: */
 #ifdef CONFIG_MATH_EMULATION
-	if (!cpu_has_fpu)
+	if (!boot_cpu_has(X86_FEATURE_FPU))
 		fpstate_init_soft(&current->thread.fpu.state.soft);
 	else
 #endif
@@ -89,7 +89,7 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 	}
 
 #ifndef CONFIG_MATH_EMULATION
-	if (!cpu_has_fpu) {
+	if (!boot_cpu_has(X86_FEATURE_FPU)) {
 		pr_emerg("x86/fpu: Giving up, no FPU found and no math emulation present\n");
 		for (;;)
 			asm volatile("hlt");
@@ -212,7 +212,7 @@ static void __init fpu__init_system_xstate_size_legacy(void)
 	 * fpu__init_system_xstate().
 	 */
 
-	if (!cpu_has_fpu) {
+	if (!boot_cpu_has(X86_FEATURE_FPU)) {
 		/*
 		 * Disable xsave as we do not support it if i387
 		 * emulation is enabled.

commit dda9edf7c1fdc0d7a7ed7f46299a26282190fb6d
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Apr 4 22:24:57 2016 +0200

    x86/cpufeature: Replace cpu_has_xmm with boot_cpu_has() usage
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1459801503-15600-5-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 54c86fffbf9f..9bbb332a71ff 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -31,7 +31,7 @@ static void fpu__init_cpu_generic(void)
 
 	if (cpu_has_fxsr)
 		cr4_mask |= X86_CR4_OSFXSR;
-	if (cpu_has_xmm)
+	if (boot_cpu_has(X86_FEATURE_XMM))
 		cr4_mask |= X86_CR4_OSXMMEXCPT;
 	if (cr4_mask)
 		cr4_set_bits(cr4_mask);

commit ecc026bff6e8444c6b50dcde192e7acdaf42bf82
Merge: fa53c4893994 14ddde78c787
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 15 10:23:56 2016 -0700

    Merge branch 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fpu updates from Ingo Molnar:
     "The biggest change in terms of impact is the changing of the FPU
      context switch model to 'eagerfpu' for all CPU types, via: commit
      58122bf1d856: "x86/fpu: Default eagerfpu=on on all CPUs"
    
      This makes all FPU saves and restores synchronous and makes the FPU
      code a lot more obvious to read.  In the next cycle, if this change is
      problem free, we'll remove the old lazy FPU restore code altogether.
    
      This change flushed out some old bugs, which should all be fixed by
      now, BYMMV"
    
    * 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/fpu: Default eagerfpu=on on all CPUs
      x86/fpu: Speed up lazy FPU restores slightly
      x86/fpu: Fold fpu_copy() into fpu__copy()
      x86/fpu: Fix FNSAVE usage in eagerfpu mode
      x86/fpu: Fix math emulation in eager fpu mode

commit 6e6867093de35141f0a76b66ac13f9f2e2c8e77a
Author: Borislav Petkov <bp@alien8.de>
Date:   Fri Mar 11 12:32:06 2016 +0100

    x86/fpu: Fix eager-FPU handling on legacy FPU machines
    
    i486 derived cores like Intel Quark support only the very old,
    legacy x87 FPU (FSAVE/FRSTOR, CPUID bit FXSR is not set), and
    our FPU code wasn't handling the saving and restoring there
    properly in the 'eagerfpu' case.
    
    So after we made eagerfpu the default for all CPU types:
    
      58122bf1d856 x86/fpu: Default eagerfpu=on on all CPUs
    
    these old FPU designs broke. First, Andy Shevchenko reported a splat:
    
      WARNING: CPU: 0 PID: 823 at arch/x86/include/asm/fpu/internal.h:163 fpu__clear+0x8c/0x160
    
    which was us trying to execute FXRSTOR on those machines even though
    they don't support it.
    
    After taking care of that, Bryan O'Donoghue reported that a simple FPU
    test still failed because we weren't initializing the FPU state properly
    on those machines.
    
    Take care of all that.
    
    Reported-and-tested-by: Bryan O'Donoghue <pure.logic@nexus-software.ie>
    Reported-by: Andy Shevchenko <andy.shevchenko@gmail.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yu-cheng <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/20160311113206.GD4312@pd.tnic
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 9ee7e307b18f..bd08fb77073d 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -134,7 +134,7 @@ static void __init fpu__init_system_generic(void)
 	 * Set up the legacy init FPU context. (xstate init might overwrite this
 	 * with a more modern format, if the CPU supports it.)
 	 */
-	fpstate_init_fxstate(&init_fpstate.fxsave);
+	fpstate_init(&init_fpstate);
 
 	fpu__init_system_mxcsr();
 }

commit a65050c6f17e52442716138d48d0a47301a8344b
Author: Yu-cheng Yu <yu-cheng.yu@intel.com>
Date:   Wed Mar 9 16:28:54 2016 -0800

    x86/fpu: Revert ("x86/fpu: Disable AVX when eagerfpu is off")
    
    Leonid Shatz noticed that the SDM interpretation of the following
    recent commit:
    
      394db20ca240741 ("x86/fpu: Disable AVX when eagerfpu is off")
    
    ... is incorrect and that the original behavior of the FPU code was correct.
    
    Because AVX is not stated in CR0 TS bit description, it was mistakenly
    believed to be not supported for lazy context switch. This turns out
    to be false:
    
      Intel Software Developer's Manual Vol. 3A, Sec. 2.5 Control Registers:
    
       'TS Task Switched bit (bit 3 of CR0) -- Allows the saving of the x87 FPU/
        MMX/SSE/SSE2/SSE3/SSSE3/SSE4 context on a task switch to be delayed until
        an x87 FPU/MMX/SSE/SSE2/SSE3/SSSE3/SSE4 instruction is actually executed
        by the new task.'
    
      Intel Software Developer's Manual Vol. 2A, Sec. 2.4 Instruction Exception
      Specification:
    
       'AVX instructions refer to exceptions by classes that include #NM
        "Device Not Available" exception for lazy context switch.'
    
    So revert the commit.
    
    Reported-by: Leonid Shatz <leonid.shatz@ravellosystems.com>
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1457569734-3785-1-git-send-email-yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index d53ab3d3b8e8..9ee7e307b18f 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -302,12 +302,6 @@ u64 __init fpu__get_supported_xfeatures_mask(void)
 static void __init fpu__clear_eager_fpu_features(void)
 {
 	setup_clear_cpu_cap(X86_FEATURE_MPX);
-	setup_clear_cpu_cap(X86_FEATURE_AVX);
-	setup_clear_cpu_cap(X86_FEATURE_AVX2);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512F);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512PF);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512ER);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512CD);
 }
 
 /*

commit f363938c70a04e6bc99023a5e0c44ef7879b903f
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jan 21 15:24:31 2016 -0800

    x86/fpu: Fix 'no387' regression
    
    After fixing FPU option parsing, we now parse the 'no387' boot option
    too early: no387 clears X86_FEATURE_FPU before it's even probed, so
    the boot CPU promptly re-enables it.
    
    I suspect it gets even more confused on SMP.
    
    Fix the probing code to leave X86_FEATURE_FPU off if it's been
    disabled by setup_clear_cpu_cap().
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Fixes: 4f81cbafcce2 ("x86/fpu: Fix early FPU command-line parsing")
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6d9f0a7ef4c8..d53ab3d3b8e8 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -78,13 +78,15 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 	cr0 &= ~(X86_CR0_TS | X86_CR0_EM);
 	write_cr0(cr0);
 
-	asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
-		     : "+m" (fsw), "+m" (fcw));
+	if (!test_bit(X86_FEATURE_FPU, (unsigned long *)cpu_caps_cleared)) {
+		asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
+			     : "+m" (fsw), "+m" (fcw));
 
-	if (fsw == 0 && (fcw & 0x103f) == 0x003f)
-		set_cpu_cap(c, X86_FEATURE_FPU);
-	else
-		clear_cpu_cap(c, X86_FEATURE_FPU);
+		if (fsw == 0 && (fcw & 0x103f) == 0x003f)
+			set_cpu_cap(c, X86_FEATURE_FPU);
+		else
+			clear_cpu_cap(c, X86_FEATURE_FPU);
+	}
 
 #ifndef CONFIG_MATH_EMULATION
 	if (!cpu_has_fpu) {

commit 58122bf1d856a4ea9581d62a07c557d997d46a19
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sun Jan 24 14:38:10 2016 -0800

    x86/fpu: Default eagerfpu=on on all CPUs
    
    We have eager and lazy FPU modes, introduced in:
    
      304bceda6a18 ("x86, fpu: use non-lazy fpu restore for processors supporting xsave")
    
    The result is rather messy.  There are two code paths in almost all
    of the FPU code, and only one of them (the eager case) is tested
    frequently, since most kernel developers have new enough hardware
    that we use eagerfpu.
    
    It seems that, on any remotely recent hardware, eagerfpu is a win:
    glibc uses SSE2, so laziness is probably overoptimistic, and, in any
    case, manipulating TS is far slower that saving and restoring the
    full state.  (Stores to CR0.TS are serializing and are poorly
    optimized.)
    
    To try to shake out any latent issues on old hardware, this changes
    the default to eager on all CPUs.  If no performance or functionality
    problems show up, a subsequent patch could remove lazy mode entirely.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/ac290de61bf08d9cfc2664a4f5080257ffc1075a.1453675014.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6d9f0a7ef4c8..471fe277ff40 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -260,7 +260,10 @@ static void __init fpu__init_system_xstate_size_legacy(void)
  * not only saved the restores along the way, but we also have the
  * FPU ready to be used for the original task.
  *
- * 'eager' switching is used on modern CPUs, there we switch the FPU
+ * 'lazy' is deprecated because it's almost never a performance win
+ * and it's much more complicated than 'eager'.
+ *
+ * 'eager' switching is by default on all CPUs, there we switch the FPU
  * state during every context switch, regardless of whether the task
  * has used FPU instructions in that time slice or not. This is done
  * because modern FPU context saving instructions are able to optimize
@@ -271,7 +274,7 @@ static void __init fpu__init_system_xstate_size_legacy(void)
  *   to use 'eager' restores, if we detect that a task is using the FPU
  *   frequently. See the fpu->counter logic in fpu/internal.h for that. ]
  */
-static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
+static enum { ENABLE, DISABLE } eagerfpu = ENABLE;
 
 /*
  * Find supported xfeatures based on cpu features and command-line input.
@@ -348,15 +351,9 @@ static void __init fpu__init_system_ctx_switch(void)
  */
 static void __init fpu__init_parse_early_param(void)
 {
-	/*
-	 * No need to check "eagerfpu=auto" again, since it is the
-	 * initial default.
-	 */
 	if (cmdline_find_option_bool(boot_command_line, "eagerfpu=off")) {
 		eagerfpu = DISABLE;
 		fpu__clear_eager_fpu_features();
-	} else if (cmdline_find_option_bool(boot_command_line, "eagerfpu=on")) {
-		eagerfpu = ENABLE;
 	}
 
 	if (cmdline_find_option_bool(boot_command_line, "no387"))

commit 394db20ca240741a08d472173db13d6f6a6e5a28
Author: yu-cheng yu <yu-cheng.yu@intel.com>
Date:   Wed Jan 6 14:24:54 2016 -0800

    x86/fpu: Disable AVX when eagerfpu is off
    
    When "eagerfpu=off" is given as a command-line input, the kernel
    should disable AVX support.
    
    The Task Switched bit used for lazy context switching does not
    support AVX. If AVX is enabled without eagerfpu context
    switching, one task's AVX state could become corrupted or leak
    to other tasks. This is a bug and has bad security implications.
    
    This only affects systems that have AVX/AVX2/AVX512 and this
    issue will be found only when one actually uses AVX/AVX2/AVX512
    _AND_ does eagerfpu=off.
    
    Reference: Intel Software Developer's Manual Vol. 3A
    
    Sec. 2.5 Control Registers:
    TS Task Switched bit (bit 3 of CR0) -- Allows the saving of the
    x87 FPU/ MMX/SSE/SSE2/SSE3/SSSE3/SSE4 context on a task switch
    to be delayed until an x87 FPU/MMX/SSE/SSE2/SSE3/SSSE3/SSE4
    instruction is actually executed by the new task.
    
    Sec. 13.4.1 Using the TS Flag to Control the Saving of the X87
    FPU and SSE State
    When the TS flag is set, the processor monitors the instruction
    stream for x87 FPU, MMX, SSE instructions. When the processor
    detects one of these instructions, it raises a
    device-not-available exeception (#NM) prior to executing the
    instruction.
    
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/1452119094-7252-5-git-send-email-yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index f0ab36844a6d..6d9f0a7ef4c8 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -300,6 +300,12 @@ u64 __init fpu__get_supported_xfeatures_mask(void)
 static void __init fpu__clear_eager_fpu_features(void)
 {
 	setup_clear_cpu_cap(X86_FEATURE_MPX);
+	setup_clear_cpu_cap(X86_FEATURE_AVX);
+	setup_clear_cpu_cap(X86_FEATURE_AVX2);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512F);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512PF);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512ER);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512CD);
 }
 
 /*

commit a5fe93a549c54838063d2952dd9643b0b18aa67f
Author: yu-cheng yu <yu-cheng.yu@intel.com>
Date:   Wed Jan 6 14:24:53 2016 -0800

    x86/fpu: Disable MPX when eagerfpu is off
    
    This issue is a fallout from the command-line parsing move.
    
    When "eagerfpu=off" is given as a command-line input, the kernel
    should disable MPX support. The decision for turning off MPX was
    made in fpu__init_system_ctx_switch(), which is after the
    selection of the XSAVE format. This patch fixes it by getting
    that decision done earlier in fpu__init_system_xstate().
    
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/1452119094-7252-4-git-send-email-yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 3a45fcd0b924..f0ab36844a6d 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -273,8 +273,46 @@ static void __init fpu__init_system_xstate_size_legacy(void)
  */
 static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
 
+/*
+ * Find supported xfeatures based on cpu features and command-line input.
+ * This must be called after fpu__init_parse_early_param() is called and
+ * xfeatures_mask is enumerated.
+ */
+u64 __init fpu__get_supported_xfeatures_mask(void)
+{
+	/* Support all xfeatures known to us */
+	if (eagerfpu != DISABLE)
+		return XCNTXT_MASK;
+
+	/* Warning of xfeatures being disabled for no eagerfpu mode */
+	if (xfeatures_mask & XFEATURE_MASK_EAGER) {
+		pr_err("x86/fpu: eagerfpu switching disabled, disabling the following xstate features: 0x%llx.\n",
+			xfeatures_mask & XFEATURE_MASK_EAGER);
+	}
+
+	/* Return a mask that masks out all features requiring eagerfpu mode */
+	return ~XFEATURE_MASK_EAGER;
+}
+
+/*
+ * Disable features dependent on eagerfpu.
+ */
+static void __init fpu__clear_eager_fpu_features(void)
+{
+	setup_clear_cpu_cap(X86_FEATURE_MPX);
+}
+
 /*
  * Pick the FPU context switching strategy:
+ *
+ * When eagerfpu is AUTO or ENABLE, we ensure it is ENABLE if either of
+ * the following is true:
+ *
+ * (1) the cpu has xsaveopt, as it has the optimization and doing eager
+ *     FPU switching has a relatively low cost compared to a plain xsave;
+ * (2) the cpu has xsave features (e.g. MPX) that depend on eager FPU
+ *     switching. Should the kernel boot with noxsaveopt, we support MPX
+ *     with eager FPU switching at a higher cost.
  */
 static void __init fpu__init_system_ctx_switch(void)
 {
@@ -286,19 +324,11 @@ static void __init fpu__init_system_ctx_switch(void)
 	WARN_ON_FPU(current->thread.fpu.fpstate_active);
 	current_thread_info()->status = 0;
 
-	/* Auto enable eagerfpu for xsaveopt */
 	if (boot_cpu_has(X86_FEATURE_XSAVEOPT) && eagerfpu != DISABLE)
 		eagerfpu = ENABLE;
 
-	if (xfeatures_mask & XFEATURE_MASK_EAGER) {
-		if (eagerfpu == DISABLE) {
-			pr_err("x86/fpu: eagerfpu switching disabled, disabling the following xstate features: 0x%llx.\n",
-			       xfeatures_mask & XFEATURE_MASK_EAGER);
-			xfeatures_mask &= ~XFEATURE_MASK_EAGER;
-		} else {
-			eagerfpu = ENABLE;
-		}
-	}
+	if (xfeatures_mask & XFEATURE_MASK_EAGER)
+		eagerfpu = ENABLE;
 
 	if (eagerfpu == ENABLE)
 		setup_force_cpu_cap(X86_FEATURE_EAGER_FPU);
@@ -316,10 +346,12 @@ static void __init fpu__init_parse_early_param(void)
 	 * No need to check "eagerfpu=auto" again, since it is the
 	 * initial default.
 	 */
-	if (cmdline_find_option_bool(boot_command_line, "eagerfpu=off"))
+	if (cmdline_find_option_bool(boot_command_line, "eagerfpu=off")) {
 		eagerfpu = DISABLE;
-	else if (cmdline_find_option_bool(boot_command_line, "eagerfpu=on"))
+		fpu__clear_eager_fpu_features();
+	} else if (cmdline_find_option_bool(boot_command_line, "eagerfpu=on")) {
 		eagerfpu = ENABLE;
+	}
 
 	if (cmdline_find_option_bool(boot_command_line, "no387"))
 		setup_clear_cpu_cap(X86_FEATURE_FPU);

commit 4f81cbafcce2c603db7865e9d0e461f7947d77d4
Author: yu-cheng yu <yu-cheng.yu@intel.com>
Date:   Wed Jan 6 14:24:51 2016 -0800

    x86/fpu: Fix early FPU command-line parsing
    
    The function fpu__init_system() is executed before
    parse_early_param(). This causes wrong FPU configuration. This
    patch fixes this issue by parsing boot_command_line in the
    beginning of fpu__init_system().
    
    With all four patches in this series, each parameter disables
    features as the following:
    
    eagerfpu=off: eagerfpu, avx, avx2, avx512, mpx
    no387: fpu
    nofxsr: fxsr, fxsropt, xmm
    noxsave: xsave, xsaveopt, xsaves, xsavec, avx, avx2, avx512,
    mpx, xgetbv1 noxsaveopt: xsaveopt
    noxsaves: xsaves
    
    Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Ravi V. Shankar <ravi.v.shankar@intel.com>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/1452119094-7252-2-git-send-email-yu-cheng.yu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 7b2978ab30df..3a45fcd0b924 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -3,8 +3,11 @@
  */
 #include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
+#include <asm/setup.h>
+#include <asm/cmdline.h>
 
 #include <linux/sched.h>
+#include <linux/init.h>
 
 /*
  * Initialize the TS bit in CR0 according to the style of context-switches
@@ -270,18 +273,6 @@ static void __init fpu__init_system_xstate_size_legacy(void)
  */
 static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
 
-static int __init eager_fpu_setup(char *s)
-{
-	if (!strcmp(s, "on"))
-		eagerfpu = ENABLE;
-	else if (!strcmp(s, "off"))
-		eagerfpu = DISABLE;
-	else if (!strcmp(s, "auto"))
-		eagerfpu = AUTO;
-	return 1;
-}
-__setup("eagerfpu=", eager_fpu_setup);
-
 /*
  * Pick the FPU context switching strategy:
  */
@@ -315,12 +306,47 @@ static void __init fpu__init_system_ctx_switch(void)
 	printk(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
 }
 
+/*
+ * We parse fpu parameters early because fpu__init_system() is executed
+ * before parse_early_param().
+ */
+static void __init fpu__init_parse_early_param(void)
+{
+	/*
+	 * No need to check "eagerfpu=auto" again, since it is the
+	 * initial default.
+	 */
+	if (cmdline_find_option_bool(boot_command_line, "eagerfpu=off"))
+		eagerfpu = DISABLE;
+	else if (cmdline_find_option_bool(boot_command_line, "eagerfpu=on"))
+		eagerfpu = ENABLE;
+
+	if (cmdline_find_option_bool(boot_command_line, "no387"))
+		setup_clear_cpu_cap(X86_FEATURE_FPU);
+
+	if (cmdline_find_option_bool(boot_command_line, "nofxsr")) {
+		setup_clear_cpu_cap(X86_FEATURE_FXSR);
+		setup_clear_cpu_cap(X86_FEATURE_FXSR_OPT);
+		setup_clear_cpu_cap(X86_FEATURE_XMM);
+	}
+
+	if (cmdline_find_option_bool(boot_command_line, "noxsave"))
+		fpu__xstate_clear_all_cpu_caps();
+
+	if (cmdline_find_option_bool(boot_command_line, "noxsaveopt"))
+		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+
+	if (cmdline_find_option_bool(boot_command_line, "noxsaves"))
+		setup_clear_cpu_cap(X86_FEATURE_XSAVES);
+}
+
 /*
  * Called on the boot CPU once per system bootup, to set up the initial
  * FPU state that is later cloned into all processes:
  */
 void __init fpu__init_system(struct cpuinfo_x86 *c)
 {
+	fpu__init_parse_early_param();
 	fpu__init_system_early_generic(c);
 
 	/*
@@ -344,62 +370,3 @@ void __init fpu__init_system(struct cpuinfo_x86 *c)
 
 	fpu__init_system_ctx_switch();
 }
-
-/*
- * Boot parameter to turn off FPU support and fall back to math-emu:
- */
-static int __init no_387(char *s)
-{
-	setup_clear_cpu_cap(X86_FEATURE_FPU);
-	return 1;
-}
-__setup("no387", no_387);
-
-/*
- * Disable all xstate CPU features:
- */
-static int __init x86_noxsave_setup(char *s)
-{
-	if (strlen(s))
-		return 0;
-
-	fpu__xstate_clear_all_cpu_caps();
-
-	return 1;
-}
-__setup("noxsave", x86_noxsave_setup);
-
-/*
- * Disable the XSAVEOPT instruction specifically:
- */
-static int __init x86_noxsaveopt_setup(char *s)
-{
-	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
-
-	return 1;
-}
-__setup("noxsaveopt", x86_noxsaveopt_setup);
-
-/*
- * Disable the XSAVES instruction:
- */
-static int __init x86_noxsaves_setup(char *s)
-{
-	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
-
-	return 1;
-}
-__setup("noxsaves", x86_noxsaves_setup);
-
-/*
- * Disable FX save/restore and SSE support:
- */
-static int __init x86_nofxsr_setup(char *s)
-{
-	setup_clear_cpu_cap(X86_FEATURE_FXSR);
-	setup_clear_cpu_cap(X86_FEATURE_FXSR_OPT);
-	setup_clear_cpu_cap(X86_FEATURE_XMM);
-
-	return 1;
-}
-__setup("nofxsr", x86_nofxsr_setup);

commit 6896d9f7e7ee98d772224a539b7581a1e6dd6b2c
Merge: 671d5532aaad e49a449b869a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 11 16:56:38 2016 -0800

    Merge branch 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fpu updates from Ingo Molnar:
     "This cleans up the FPU fault handling methods to be more robust, and
      moves eligible variables to .init.data"
    
    * 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/fpu: Put a few variables in .init.data
      x86/fpu: Get rid of xstate_fault()
      x86/fpu: Add an XSTATE_OP() macro

commit 67c707e451e12f59e57bca6cf33b5803cb74b022
Merge: 463eb8ac337b 0105c8d8334f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 11 16:26:03 2016 -0800

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cleanups from Ingo Molnar:
     "The main changes in this cycle were:
    
       - code patching and cpu_has cleanups (Borislav Petkov)
    
       - paravirt cleanups (Juergen Gross)
    
       - TSC cleanup (Thomas Gleixner)
    
       - ptrace cleanup (Chen Gang)"
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      arch/x86/kernel/ptrace.c: Remove unused arg_offs_table
      x86/mm: Align macro defines
      x86/cpu: Provide a config option to disable static_cpu_has
      x86/cpufeature: Remove unused and seldomly used cpu_has_xx macros
      x86/cpufeature: Cleanup get_cpu_cap()
      x86/cpufeature: Move some of the scattered feature bits to x86_capability
      x86/paravirt: Remove paravirt ops pmd_update[_defer] and pte_update_defer
      x86/paravirt: Remove unused pv_apic_ops structure
      x86/tsc: Remove unused tsc_pre_init() hook
      x86: Remove unused function cpu_has_ht_siblings()
      x86/paravirt: Kill some unused patching functions

commit 25ec02f2c14466a4549c5dcc044b628c2cc46fde
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Dec 21 15:25:30 2015 +0100

    x86/fpu: Properly align size in CHECK_MEMBER_AT_END_OF() macro
    
    The CHECK_MEMBER_AT_END_OF(TYPE, MEMBER) checks whether MEMBER
    is last member of TYPE by evaluating:
    
      offsetof(TYPE::MEMBER) + sizeof(TYPE::MEMBER) == sizeof(TYPE)
    
    and ensuring TYPE::MEMBER is the last member of the TYPE.
    
    This condition breaks on structs that are padded to be
    aligned. This patch ensures the TYPE alignment is taken
    into account.
    
    This bug was revealed after adding cacheline alignment into
    struct sched_entity, which broke task_struct::thread check:
    
      CHECK_MEMBER_AT_END_OF(struct task_struct, thread);
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1450707930-3445-1-git-send-email-jolsa@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index be39b5fde4b9..8e839e7f5e2f 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -143,9 +143,18 @@ static void __init fpu__init_system_generic(void)
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
 
-/* Enforce that 'MEMBER' is the last field of 'TYPE': */
+/* Get alignment of the TYPE. */
+#define TYPE_ALIGN(TYPE) offsetof(struct { char x; TYPE test; }, test)
+
+/*
+ * Enforce that 'MEMBER' is the last field of 'TYPE'.
+ *
+ * Align the computed size with alignment of the TYPE,
+ * because that's how C aligns structs.
+ */
 #define CHECK_MEMBER_AT_END_OF(TYPE, MEMBER) \
-	BUILD_BUG_ON(sizeof(TYPE) != offsetofend(TYPE, MEMBER))
+	BUILD_BUG_ON(sizeof(TYPE) != ALIGN(offsetofend(TYPE, MEMBER), \
+					   TYPE_ALIGN(TYPE)))
 
 /*
  * We append the 'struct fpu' to the task_struct:

commit 362f924b64ba0f4be2ee0cb697690c33d40be721
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Dec 7 10:39:41 2015 +0100

    x86/cpufeature: Remove unused and seldomly used cpu_has_xx macros
    
    Those are stupid and code should use static_cpu_has_safe() or
    boot_cpu_has() instead. Kill the least used and unused ones.
    
    The remaining ones need more careful inspection before a conversion can
    happen. On the TODO.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: http://lkml.kernel.org/r/1449481182-27541-4-git-send-email-bp@alien8.de
    Cc: David Sterba <dsterba@suse.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Matt Mackall <mpm@selenic.com>
    Cc: Chris Mason <clm@fb.com>
    Cc: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index be39b5fde4b9..22abea04731e 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -12,7 +12,7 @@
  */
 static void fpu__init_cpu_ctx_switch(void)
 {
-	if (!cpu_has_eager_fpu)
+	if (!boot_cpu_has(X86_FEATURE_EAGER_FPU))
 		stts();
 	else
 		clts();
@@ -287,7 +287,7 @@ static void __init fpu__init_system_ctx_switch(void)
 	current_thread_info()->status = 0;
 
 	/* Auto enable eagerfpu for xsaveopt */
-	if (cpu_has_xsaveopt && eagerfpu != DISABLE)
+	if (boot_cpu_has(X86_FEATURE_XSAVEOPT) && eagerfpu != DISABLE)
 		eagerfpu = ENABLE;
 
 	if (xfeatures_mask & XFEATURE_MASK_EAGER) {

commit e49a449b869afb2b8bf282427c8355bc3a2fad56
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Fri Nov 13 15:18:31 2015 +0100

    x86/fpu: Put a few variables in .init.data
    
    These are clearly just used during init.
    
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1447424312-26400-1-git-send-email-linux@rasmusvillemoes.dk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index be39b5fde4b9..e1ed5194c02a 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -188,7 +188,7 @@ static void __init fpu__init_task_struct_size(void)
  */
 static void __init fpu__init_system_xstate_size_legacy(void)
 {
-	static int on_boot_cpu = 1;
+	static int on_boot_cpu __initdata = 1;
 
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;
@@ -278,7 +278,7 @@ __setup("eagerfpu=", eager_fpu_setup);
  */
 static void __init fpu__init_system_ctx_switch(void)
 {
-	static bool on_boot_cpu = 1;
+	static bool on_boot_cpu __initdata = 1;
 
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;

commit d91cab78133d33b1dfd3d3fa7167fcbf74fb5f99
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Wed Sep 2 16:31:26 2015 -0700

    x86/fpu: Rename XSAVE macros
    
    There are two concepts that have some confusing naming:
     1. Extended State Component numbers (currently called
        XFEATURE_BIT_*)
     2. Extended State Component masks (currently called XSTATE_*)
    
    The numbers are (currently) from 0-9.  State component 3 is the
    bounds registers for MPX, for instance.
    
    But when we want to enable "state component 3", we go set a bit
    in XCR0.  The bit we set is 1<<3.  We can check to see if a
    state component feature is enabled by looking at its bit.
    
    The current 'xfeature_bit's are at best xfeature bit _numbers_.
    Calling them bits is at best inconsistent with ending the enum
    list with 'XFEATURES_NR_MAX'.
    
    This patch renames the enum to be 'xfeature'.  These also
    happen to be what the Intel documentation calls a "state
    component".
    
    We also want to differentiate these from the "XSTATE_*" macros.
    The "XSTATE_*" macros are a mask, and we rename them to match.
    
    These macros are reasonably widely used so this patch is a
    wee bit big, but this really is just a rename.
    
    The only non-mechanical part of this is the
    
            s/XSTATE_EXTEND_MASK/XFEATURE_MASK_EXTEND/
    
    We need a better name for it, but that's another patch.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: dave@sr71.net
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20150902233126.38653250@viggo.jf.intel.com
    [ Ported to v4.3-rc1. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 0a250afc6cdf..be39b5fde4b9 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -290,11 +290,11 @@ static void __init fpu__init_system_ctx_switch(void)
 	if (cpu_has_xsaveopt && eagerfpu != DISABLE)
 		eagerfpu = ENABLE;
 
-	if (xfeatures_mask & XSTATE_EAGER) {
+	if (xfeatures_mask & XFEATURE_MASK_EAGER) {
 		if (eagerfpu == DISABLE) {
 			pr_err("x86/fpu: eagerfpu switching disabled, disabling the following xstate features: 0x%llx.\n",
-			       xfeatures_mask & XSTATE_EAGER);
-			xfeatures_mask &= ~XSTATE_EAGER;
+			       xfeatures_mask & XFEATURE_MASK_EAGER);
+			xfeatures_mask &= ~XFEATURE_MASK_EAGER;
 		} else {
 			eagerfpu = ENABLE;
 		}

commit 0a265375028b241a9173b7c569dd2368ba97fcd4
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Wed Sep 2 16:31:24 2015 -0700

    x86/fpu: Move XSAVE-disabling code to a helper
    
    When we want to _completely_ disable XSAVE support as far as
    the kernel is concerned, we have a big set of feature flags
    to clear.  We currently only do this in cases where the user
    asks for it to be disabled, but we are about to expand the
    places where we do it to handle errors too.
    
    Move the code in to xstate.c, and put it in the xstate.h
    header.  We will use it in the next patch too.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: dave@sr71.net
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20150902233124.EA9A70E5@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index d14e9ac3235a..0a250afc6cdf 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -354,17 +354,7 @@ static int __init x86_noxsave_setup(char *s)
 	if (strlen(s))
 		return 0;
 
-	setup_clear_cpu_cap(X86_FEATURE_XSAVE);
-	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
-	setup_clear_cpu_cap(X86_FEATURE_XSAVEC);
-	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
-	setup_clear_cpu_cap(X86_FEATURE_AVX);
-	setup_clear_cpu_cap(X86_FEATURE_AVX2);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512F);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512PF);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512ER);
-	setup_clear_cpu_cap(X86_FEATURE_AVX512CD);
-	setup_clear_cpu_cap(X86_FEATURE_MPX);
+	fpu__xstate_clear_all_cpu_caps();
 
 	return 1;
 }

commit 5fc960380ea44ba529c78b558b6cd4250e5e1958
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Aug 22 09:52:06 2015 +0200

    x86/fpu/math-emu: Fix math-emu boot crash
    
    On a math-emu bootup the following crash occurs:
    
            Initializing CPU#0
            ------------[ cut here ]------------
            kernel BUG at arch/x86/kernel/traps.c:779!
            invalid opcode: 0000 [#1] SMP
            [...]
            EIP is at do_device_not_available+0xe/0x70
            [...]
            Call Trace:
             [<c18238e6>] error_code+0x5a/0x60
             [<c1002bd0>] ? math_error+0x140/0x140
             [<c100bbd9>] ? fpu__init_cpu+0x59/0xa0
             [<c1012322>] cpu_init+0x202/0x330
             [<c104509f>] ? __native_set_fixmap+0x1f/0x30
             [<c1b56ab0>] trap_init+0x305/0x346
             [<c1b548af>] start_kernel+0x1a5/0x35d
             [<c1b542b4>] i386_start_kernel+0x82/0x86
    
    The reason is that in the following commit:
    
      b1276c48e91b ("x86/fpu: Initialize fpregs in fpu__init_cpu_generic()")
    
    I failed to consider math-emu's limitation that it cannot execute the
    FNINIT instruction in kernel mode.
    
    The long term fix might be to allow math-emu to execute (certain) kernel
    mode FPU instructions, but for now apply the safe (albeit somewhat ugly)
    fix: initialize the emulation state explicitly without trapping out to
    the FPU emulator.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 1e173f6285c7..d14e9ac3235a 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -40,7 +40,12 @@ static void fpu__init_cpu_generic(void)
 	write_cr0(cr0);
 
 	/* Flush out any pending x87 state: */
-	asm volatile ("fninit");
+#ifdef CONFIG_MATH_EMULATION
+	if (!cpu_has_fpu)
+		fpstate_init_soft(&current->thread.fpu.state.soft);
+	else
+#endif
+		asm volatile ("fninit");
 }
 
 /*

commit 5bc016f1abaa1c5ac0e3af23aa79faec4634a074
Author: Jan Beulich <JBeulich@suse.com>
Date:   Mon Jul 20 08:49:01 2015 +0100

    x86/fpu: Disable dependent CPU features on "noxsave"
    
    Complete the set of dependent features that need disabling at
    once: XSAVEC, AVX-512 and all currently known to the kernel
    extensions to it, as well as MPX need to be disabled too.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/55ACC40D0200007800092E6C@mail.emea.novell.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 0b39173dd971..1e173f6285c7 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -351,9 +351,15 @@ static int __init x86_noxsave_setup(char *s)
 
 	setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+	setup_clear_cpu_cap(X86_FEATURE_XSAVEC);
 	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
 	setup_clear_cpu_cap(X86_FEATURE_AVX);
 	setup_clear_cpu_cap(X86_FEATURE_AVX2);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512F);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512PF);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512ER);
+	setup_clear_cpu_cap(X86_FEATURE_AVX512CD);
+	setup_clear_cpu_cap(X86_FEATURE_MPX);
 
 	return 1;
 }

commit 5aaeb5c01c5b6c0be7b7aadbf3ace9f3a4458c3d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jul 17 12:28:12 2015 +0200

    x86/fpu, sched: Introduce CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT and use it on x86
    
    Don't burden architectures without dynamic task_struct sizing
    with the overhead of dynamic sizing.
    
    Also optimize the x86 code a bit by caching task_struct_size.
    
    Acked-and-Tested-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1437128892-9831-3-git-send-email-mingo@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index deacbfa6b33e..0b39173dd971 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -4,6 +4,8 @@
 #include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
 
+#include <linux/sched.h>
+
 /*
  * Initialize the TS bit in CR0 according to the style of context-switches
  * we are using:
@@ -136,16 +138,14 @@ static void __init fpu__init_system_generic(void)
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
 
-#define CHECK_MEMBER_AT_END_OF(TYPE, MEMBER)	\
-	BUILD_BUG_ON((sizeof(TYPE) -			\
-			offsetof(TYPE, MEMBER) -	\
-			sizeof(((TYPE *)0)->MEMBER)) > 	\
-			0)				\
+/* Enforce that 'MEMBER' is the last field of 'TYPE': */
+#define CHECK_MEMBER_AT_END_OF(TYPE, MEMBER) \
+	BUILD_BUG_ON(sizeof(TYPE) != offsetofend(TYPE, MEMBER))
 
 /*
- * We append the 'struct fpu' to the task_struct.
+ * We append the 'struct fpu' to the task_struct:
  */
-int __weak arch_task_struct_size(void)
+static void __init fpu__init_task_struct_size(void)
 {
 	int task_size = sizeof(struct task_struct);
 
@@ -172,7 +172,7 @@ int __weak arch_task_struct_size(void)
 	CHECK_MEMBER_AT_END_OF(struct thread_struct, fpu);
 	CHECK_MEMBER_AT_END_OF(struct task_struct, thread);
 
-	return task_size;
+	arch_task_struct_size = task_size;
 }
 
 /*
@@ -326,6 +326,7 @@ void __init fpu__init_system(struct cpuinfo_x86 *c)
 	fpu__init_system_generic();
 	fpu__init_system_xstate_size_legacy();
 	fpu__init_system_xstate();
+	fpu__init_task_struct_size();
 
 	fpu__init_system_ctx_switch();
 }

commit 0c8c0f03e3a292e031596484275c14cf39c0ab7a
Author: Dave Hansen <dave@sr71.net>
Date:   Fri Jul 17 12:28:11 2015 +0200

    x86/fpu, sched: Dynamically allocate 'struct fpu'
    
    The FPU rewrite removed the dynamic allocations of 'struct fpu'.
    But, this potentially wastes massive amounts of memory (2k per
    task on systems that do not have AVX-512 for instance).
    
    Instead of having a separate slab, this patch just appends the
    space that we need to the 'task_struct' which we dynamically
    allocate already.  This saves from doing an extra slab
    allocation at fork().
    
    The only real downside here is that we have to stick everything
    and the end of the task_struct.  But, I think the
    BUILD_BUG_ON()s I stuck in there should keep that from being too
    fragile.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1437128892-9831-2-git-send-email-mingo@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 32826791e675..deacbfa6b33e 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -136,6 +136,45 @@ static void __init fpu__init_system_generic(void)
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
 
+#define CHECK_MEMBER_AT_END_OF(TYPE, MEMBER)	\
+	BUILD_BUG_ON((sizeof(TYPE) -			\
+			offsetof(TYPE, MEMBER) -	\
+			sizeof(((TYPE *)0)->MEMBER)) > 	\
+			0)				\
+
+/*
+ * We append the 'struct fpu' to the task_struct.
+ */
+int __weak arch_task_struct_size(void)
+{
+	int task_size = sizeof(struct task_struct);
+
+	/*
+	 * Subtract off the static size of the register state.
+	 * It potentially has a bunch of padding.
+	 */
+	task_size -= sizeof(((struct task_struct *)0)->thread.fpu.state);
+
+	/*
+	 * Add back the dynamically-calculated register state
+	 * size.
+	 */
+	task_size += xstate_size;
+
+	/*
+	 * We dynamically size 'struct fpu', so we require that
+	 * it be at the end of 'thread_struct' and that
+	 * 'thread_struct' be at the end of 'task_struct'.  If
+	 * you hit a compile error here, check the structure to
+	 * see if something got added to the end.
+	 */
+	CHECK_MEMBER_AT_END_OF(struct fpu, state);
+	CHECK_MEMBER_AT_END_OF(struct thread_struct, fpu);
+	CHECK_MEMBER_AT_END_OF(struct task_struct, thread);
+
+	return task_size;
+}
+
 /*
  * Set up the xstate_size based on the legacy FPU context size.
  *

commit b96fecbfa8c88b057e2bbf10021521c232bb3650
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jul 4 09:58:19 2015 +0200

    x86/fpu: Fix boot crash in the early FPU code
    
    Jan Kara and Thomas Gleixner reported boot crashes in the FPU
    code:
    
      general protection fault: 0000 [#1] SMP
      RIP: 0010:[<ffffffff81048a6c>]  [<ffffffff81048a6c>] mxcsr_feature_mask_init+0x1c/0x40
    
      2b:*  0f ae 85 00 fe ff ff    fxsave -0x200(%rbp)
    
    and bisected it down to the following FPU commit:
    
       91a8c2a5b43f ("x86/fpu: Clean up and fix MXCSR handling")
    
    The reason is that the on-stack FPU registers state variable,
    used by the FXSAVE instruction, did not have the required
    minimum alignment of 16 bytes, causing the general protection
    fault.
    
    This is most likely a GCC bug in older GCC versions, but the
    offending commit also added a bogus extra 32-byte alignment
    (which GCC ignored too).
    
    So fix this bug by making the variable static again, but also
    mark it __initdata this time, because fpu__init_system_mxcsr()
    is now an __init function.
    
    Reported-and-bisected-by: Jan Kara <jack@suse.cz>
    Reported-bisected-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20150704075819.GA9201@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index fc878fee6a51..32826791e675 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -95,11 +95,12 @@ static void __init fpu__init_system_mxcsr(void)
 	unsigned int mask = 0;
 
 	if (cpu_has_fxsr) {
-		struct fxregs_state fx_tmp __aligned(32) = { };
+		/* Static because GCC does not get 16-byte stack alignment right: */
+		static struct fxregs_state fxregs __initdata;
 
-		asm volatile("fxsave %0" : "+m" (fx_tmp));
+		asm volatile("fxsave %0" : "+m" (fxregs));
 
-		mask = fx_tmp.mxcsr_mask;
+		mask = fxregs.mxcsr_mask;
 
 		/*
 		 * If zero then use the default features mask,

commit 6f56a8d024757e2f3bda8bf3bdf6aa1a21e6810b
Merge: 5856afed0c8c e88221c50cad
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed May 20 11:59:45 2015 +0200

    Merge branch 'x86/urgent' into x86/fpu, to resolve a conflict
    
    Conflicts:
            arch/x86/kernel/i387.c
    
    This commit is conflicting:
    
      e88221c50cad ("x86/fpu: Disable XSAVES* support for now")
    
    These functions changed a lot, move the quirk to arch/x86/kernel/fpu/init.c's
    fpu__init_system_xstate_size_legacy().
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 5856afed0c8c419286d9f0c8e57e83e2875eec4b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed May 20 11:39:35 2015 +0200

    x86/fpu/init: Clean up and comment the __setup() functions
    
    Explain the functions and also standardize their style
    and naming.
    
    No change in functionality.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index fe8cce7fc5ea..9da740e236d5 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -284,42 +284,57 @@ static int __init no_387(char *s)
 	setup_clear_cpu_cap(X86_FEATURE_FPU);
 	return 1;
 }
-
 __setup("no387", no_387);
 
-static int __init x86_xsave_setup(char *s)
+/*
+ * Disable all xstate CPU features:
+ */
+static int __init x86_noxsave_setup(char *s)
 {
 	if (strlen(s))
 		return 0;
+
 	setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
 	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
 	setup_clear_cpu_cap(X86_FEATURE_AVX);
 	setup_clear_cpu_cap(X86_FEATURE_AVX2);
+
 	return 1;
 }
-__setup("noxsave", x86_xsave_setup);
+__setup("noxsave", x86_noxsave_setup);
 
-static int __init x86_xsaveopt_setup(char *s)
+/*
+ * Disable the XSAVEOPT instruction specifically:
+ */
+static int __init x86_noxsaveopt_setup(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+
 	return 1;
 }
-__setup("noxsaveopt", x86_xsaveopt_setup);
+__setup("noxsaveopt", x86_noxsaveopt_setup);
 
-static int __init x86_xsaves_setup(char *s)
+/*
+ * Disable the XSAVES instruction:
+ */
+static int __init x86_noxsaves_setup(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
+
 	return 1;
 }
-__setup("noxsaves", x86_xsaves_setup);
+__setup("noxsaves", x86_noxsaves_setup);
 
-static int __init x86_fxsr_setup(char *s)
+/*
+ * Disable FX save/restore and SSE support:
+ */
+static int __init x86_nofxsr_setup(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_FXSR);
 	setup_clear_cpu_cap(X86_FEATURE_FXSR_OPT);
 	setup_clear_cpu_cap(X86_FEATURE_XMM);
+
 	return 1;
 }
-__setup("nofxsr", x86_fxsr_setup);
-
+__setup("nofxsr", x86_nofxsr_setup);

commit 7cf82d33b613780a79fda91babf7b9e6c5c82d75
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed May 20 11:35:02 2015 +0200

    x86/fpu/init: Move __setup() functions to fpu/init.c
    
    We had a number of FPU init related boot option handlers
    in arch/x86/kernel/cpu/common.c - move them over into
    arch/x86/kernel/fpu/init.c to have them all in a
    single place.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index e9f1d6e62146..fe8cce7fc5ea 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -286,3 +286,40 @@ static int __init no_387(char *s)
 }
 
 __setup("no387", no_387);
+
+static int __init x86_xsave_setup(char *s)
+{
+	if (strlen(s))
+		return 0;
+	setup_clear_cpu_cap(X86_FEATURE_XSAVE);
+	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
+	setup_clear_cpu_cap(X86_FEATURE_AVX);
+	setup_clear_cpu_cap(X86_FEATURE_AVX2);
+	return 1;
+}
+__setup("noxsave", x86_xsave_setup);
+
+static int __init x86_xsaveopt_setup(char *s)
+{
+	setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+	return 1;
+}
+__setup("noxsaveopt", x86_xsaveopt_setup);
+
+static int __init x86_xsaves_setup(char *s)
+{
+	setup_clear_cpu_cap(X86_FEATURE_XSAVES);
+	return 1;
+}
+__setup("noxsaves", x86_xsaves_setup);
+
+static int __init x86_fxsr_setup(char *s)
+{
+	setup_clear_cpu_cap(X86_FEATURE_FXSR);
+	setup_clear_cpu_cap(X86_FEATURE_FXSR_OPT);
+	setup_clear_cpu_cap(X86_FEATURE_XMM);
+	return 1;
+}
+__setup("nofxsr", x86_fxsr_setup);
+

commit e97131a8391e9fce5126ed54dc66c9d8965d3b4e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue May 5 11:34:49 2015 +0200

    x86/fpu: Add CONFIG_X86_DEBUG_FPU=y FPU debugging code
    
    There are various internal FPU state debugging checks that never
    trigger in practice, but which are useful for FPU code development.
    
    Separate these out into CONFIG_X86_DEBUG_FPU=y, and also add a
    couple of new ones.
    
    The size difference is about 0.5K of code on defconfig:
    
       text        data     bss          filename
       15028906    2578816  1638400      vmlinux
       15029430    2578816  1638400      vmlinux
    
    ( Keep this enabled by default until the new FPU code is debugged. )
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index a9e506a99a83..e9f1d6e62146 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -143,6 +143,11 @@ EXPORT_SYMBOL_GPL(xstate_size);
  */
 static void __init fpu__init_system_xstate_size_legacy(void)
 {
+	static int on_boot_cpu = 1;
+
+	WARN_ON_FPU(!on_boot_cpu);
+	on_boot_cpu = 0;
+
 	/*
 	 * Note that xstate_size might be overwriten later during
 	 * fpu__init_system_xstate().
@@ -214,7 +219,12 @@ __setup("eagerfpu=", eager_fpu_setup);
  */
 static void __init fpu__init_system_ctx_switch(void)
 {
-	WARN_ON(current->thread.fpu.fpstate_active);
+	static bool on_boot_cpu = 1;
+
+	WARN_ON_FPU(!on_boot_cpu);
+	on_boot_cpu = 0;
+
+	WARN_ON_FPU(current->thread.fpu.fpstate_active);
 	current_thread_info()->status = 0;
 
 	/* Auto enable eagerfpu for xsaveopt */

commit 32231879f66162352fc6f3041c5c2b1d965879b2
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 4 09:52:42 2015 +0200

    x86/fpu/init: Propagate __init annotations
    
    Now that all the FPU init function call dependencies are
    cleaned up we can propagate __init annotations deeper.
    
    This shrinks the runtime size of the kernel a bit, and
    also addresses a few section warnings.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 889025217407..a9e506a99a83 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -90,7 +90,7 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
  */
 unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
 
-static void fpu__init_system_mxcsr(void)
+static void __init fpu__init_system_mxcsr(void)
 {
 	unsigned int mask = 0;
 
@@ -115,7 +115,7 @@ static void fpu__init_system_mxcsr(void)
 /*
  * Once per bootup FPU initialization sequences that will run on most x86 CPUs:
  */
-static void fpu__init_system_generic(void)
+static void __init fpu__init_system_generic(void)
 {
 	/*
 	 * Set up the legacy init FPU context. (xstate init might overwrite this
@@ -141,7 +141,7 @@ EXPORT_SYMBOL_GPL(xstate_size);
  * We set this up first, and later it will be overwritten by
  * fpu__init_system_xstate() if the CPU knows about xstates.
  */
-static void fpu__init_system_xstate_size_legacy(void)
+static void __init fpu__init_system_xstate_size_legacy(void)
 {
 	/*
 	 * Note that xstate_size might be overwriten later during
@@ -212,7 +212,7 @@ __setup("eagerfpu=", eager_fpu_setup);
 /*
  * Pick the FPU context switching strategy:
  */
-static void fpu__init_system_ctx_switch(void)
+static void __init fpu__init_system_ctx_switch(void)
 {
 	WARN_ON(current->thread.fpu.fpstate_active);
 	current_thread_info()->status = 0;
@@ -234,14 +234,14 @@ static void fpu__init_system_ctx_switch(void)
 	if (eagerfpu == ENABLE)
 		setup_force_cpu_cap(X86_FEATURE_EAGER_FPU);
 
-	printk_once(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
+	printk(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
 }
 
 /*
  * Called on the boot CPU once per system bootup, to set up the initial
  * FPU state that is later cloned into all processes:
  */
-void fpu__init_system(struct cpuinfo_x86 *c)
+void __init fpu__init_system(struct cpuinfo_x86 *c)
 {
 	fpu__init_system_early_generic(c);
 

commit 5fd402dfa7fc97f8e8d74c92d24abadbdc4002ca
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 4 09:43:55 2015 +0200

    x86/fpu/xstate: Clean up setup_xstate_comp() call
    
    So call setup_xstate_comp() from the xstate init code, not
    from the generic fpu__init_system() code.
    
    This allows us to remove the protytype from xstate.h as well.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 504370662899..889025217407 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -262,7 +262,6 @@ void fpu__init_system(struct cpuinfo_x86 *c)
 	fpu__init_system_generic();
 	fpu__init_system_xstate_size_legacy();
 	fpu__init_system_xstate();
-	setup_xstate_comp();
 
 	fpu__init_system_ctx_switch();
 }

commit c47ada305de3803517ae64aa50686f644c5456fa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Apr 30 17:15:32 2015 +0200

    x86/fpu: Harmonize FPU register state types
    
    Use these consistent names:
    
        struct fregs_state           # was: i387_fsave_struct
        struct fxregs_state          # was: i387_fxsave_struct
        struct swregs_state          # was: i387_soft_struct
        struct xregs_state           # was: xsave_struct
        union  fpregs_state          # was: thread_xstate
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 93bc11a5812c..504370662899 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -95,7 +95,7 @@ static void fpu__init_system_mxcsr(void)
 	unsigned int mask = 0;
 
 	if (cpu_has_fxsr) {
-		struct i387_fxsave_struct fx_tmp __aligned(32) = { };
+		struct fxregs_state fx_tmp __aligned(32) = { };
 
 		asm volatile("fxsave %0" : "+m" (fx_tmp));
 
@@ -155,12 +155,12 @@ static void fpu__init_system_xstate_size_legacy(void)
 		 */
 		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
-		xstate_size = sizeof(struct i387_soft_struct);
+		xstate_size = sizeof(struct swregs_state);
 	} else {
 		if (cpu_has_fxsr)
-			xstate_size = sizeof(struct i387_fxsave_struct);
+			xstate_size = sizeof(struct fxregs_state);
 		else
-			xstate_size = sizeof(struct i387_fsave_struct);
+			xstate_size = sizeof(struct fregs_state);
 	}
 }
 

commit 6f57502310c85b60bdea78228e9b5bb3e82dc3b7
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Apr 30 11:07:06 2015 +0200

    x86/fpu: Generalize 'init_xstate_ctx'
    
    So the handling of init_xstate_ctx has a layering violation: both
    'struct xsave_struct' and 'union thread_xstate' have a
    'struct i387_fxsave_struct' member:
    
       xsave_struct::i387
       thread_xstate::fxsave
    
    The handling of init_xstate_ctx is generic, it is used on all
    CPUs, with or without XSAVE instruction. So it's confusing how
    the generic code passes around and handles an XSAVE specific
    format.
    
    What we really want is for init_xstate_ctx to be a proper
    fpstate and we use its ::fxsave and ::xsave members, as
    appropriate.
    
    Since the xsave_struct::i387 and thread_xstate::fxsave aliases
    each other this is not a functional problem.
    
    So implement this, and move init_xstate_ctx to the generic FPU
    code in the process.
    
    Also, since init_xstate_ctx is not XSAVE specific anymore,
    rename it to init_fpstate, and mark it __read_mostly,
    because it's only modified once during bootup, and used
    as a reference fpstate later on.
    
    There's no change in functionality.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 5a7e57078935..93bc11a5812c 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -121,7 +121,7 @@ static void fpu__init_system_generic(void)
 	 * Set up the legacy init FPU context. (xstate init might overwrite this
 	 * with a more modern format, if the CPU supports it.)
 	 */
-	fpstate_init_fxstate(&init_xstate_ctx.i387);
+	fpstate_init_fxstate(&init_fpstate.fxsave);
 
 	fpu__init_system_mxcsr();
 }

commit 0aba69789452faab6f6bd7cd293489bab66352bc
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Apr 30 10:08:36 2015 +0200

    x86/fpu: Harmonize the names of the fpstate_init() helper functions
    
    Harmonize the inconsistent naming of these related functions:
    
                              fpstate_init()
      finit_soft_fpu()   =>   fpstate_init_fsoft()
      fx_finit()         =>   fpstate_init_fxstate()
      fx_finit()         =>   fpstate_init_fstate()       # split out
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 7b6265df6082..5a7e57078935 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -121,7 +121,7 @@ static void fpu__init_system_generic(void)
 	 * Set up the legacy init FPU context. (xstate init might overwrite this
 	 * with a more modern format, if the CPU supports it.)
 	 */
-	fx_finit(&init_xstate_ctx.i387);
+	fpstate_init_fxstate(&init_xstate_ctx.i387);
 
 	fpu__init_system_mxcsr();
 }

commit acd58a3ad0ed5875fb88bbb078309a3d7ee147a0
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Apr 30 09:17:50 2015 +0200

    x86/fpu: Remove run-once init quirks
    
    Remove various boot quirks that came from the old code.
    
    The new code is cleanly split up into per-system and per-cpu
    init sequences, and system init functions are only called once.
    
    Remove the run-once quirks.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 72219ce2385a..7b6265df6082 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -143,12 +143,6 @@ EXPORT_SYMBOL_GPL(xstate_size);
  */
 static void fpu__init_system_xstate_size_legacy(void)
 {
-	static bool on_boot_cpu = 1;
-
-	if (!on_boot_cpu)
-		return;
-	on_boot_cpu = 0;
-
 	/*
 	 * Note that xstate_size might be overwriten later during
 	 * fpu__init_system_xstate().

commit b1276c48e91bee869454301d3678cc49d8f57ab4
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Apr 29 10:58:03 2015 +0200

    x86/fpu: Initialize fpregs in fpu__init_cpu_generic()
    
    FPU fpregs do not get initialized during bootup on secondary CPUs,
    on non-xsave capable CPUs.
    
    For example on one of my systems, the secondary CPU has this FPU
    state on bootup:
    
            x86: Booting SMP configuration:
            .... node  #0, CPUs:      #1
            x86/fpu ######################
            x86/fpu # FPU register dump on CPU#1:
            x86/fpu # ... CWD: ffff0040
            x86/fpu # ... SWD: ffff0000
            x86/fpu # ... TWD: ffff555a
            x86/fpu # ... FIP: 00000000
            x86/fpu # ... FCS: 00000000
            x86/fpu # ... FOO: 00000000
            x86/fpu # ... FOS: ffff0000
            x86/fpu # ... FP0: 02 57 00 00 00 00 00 00 ff ff
            x86/fpu # ... FP1: 1b e2 00 00 00 00 00 00 ff ff
            x86/fpu # ... FP2: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ... FP3: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ... FP4: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ... FP5: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ... FP6: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ... FP7: 00 00 00 00 00 00 00 00 00 00
            x86/fpu # ...  SW: dadadada
            x86/fpu ######################
    
    Note how CWD and TWD are off their usual init state (0x037f and 0xffff),
    and how FP0 and FP1 has non-zero content.
    
    This is normally not a problem, because any user-space FPU state
    is initalized properly - but it can complicate the use of FPU
    instructions in kernel code via kernel_fpu_begin()/end(): if
    the FPU using code does not initialize registers itself, it
    might generate spurious exceptions depending on which CPU it
    executes on.
    
    Fix this by initializing the x87 state via the FNINIT instruction.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 460e7e2c6186..72219ce2385a 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -36,6 +36,9 @@ static void fpu__init_cpu_generic(void)
 	if (!cpu_has_fpu)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
+
+	/* Flush out any pending x87 state: */
+	asm volatile ("fninit");
 }
 
 /*

commit c4d6ee6e2e52ec604cc1d76877791f8e8f5c79b5
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Apr 27 05:52:40 2015 +0200

    x86/fpu: Remove failure paths from fpstate-alloc low level functions
    
    Now that we always allocate the FPU context as part of task_struct there's
    no need for separate allocations - remove them and their primary failure
    handling code.
    
    ( Note that there's still secondary error codes that have become superfluous,
      those will be removed in separate patches. )
    
    Move the somewhat misplaced setup_xstate_comp() call to the core.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 7ae5a62918c7..460e7e2c6186 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -265,6 +265,7 @@ void fpu__init_system(struct cpuinfo_x86 *c)
 	fpu__init_system_generic();
 	fpu__init_system_xstate_size_legacy();
 	fpu__init_system_xstate();
+	setup_xstate_comp();
 
 	fpu__init_system_ctx_switch();
 }

commit ae02679c566fb1c2f76d3c6dffef977a9d69474a
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 15:36:46 2015 +0200

    x86/fpu: Add more comments to the FPU init code
    
    Extend the comments of the FPU init code, and fix old ones.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index dbff1335229c..7ae5a62918c7 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -1,9 +1,13 @@
 /*
- * x86 FPU boot time init code
+ * x86 FPU boot time init code:
  */
 #include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
 
+/*
+ * Initialize the TS bit in CR0 according to the style of context-switches
+ * we are using:
+ */
 static void fpu__init_cpu_ctx_switch(void)
 {
 	if (!cpu_has_eager_fpu)
@@ -35,7 +39,7 @@ static void fpu__init_cpu_generic(void)
 }
 
 /*
- * Enable all supported FPU features. Called when a CPU is brought online.
+ * Enable all supported FPU features. Called when a CPU is brought online:
  */
 void fpu__init_cpu(void)
 {
@@ -71,8 +75,7 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 
 #ifndef CONFIG_MATH_EMULATION
 	if (!cpu_has_fpu) {
-		pr_emerg("No FPU found and no math emulation present\n");
-		pr_emerg("Giving up\n");
+		pr_emerg("x86/fpu: Giving up, no FPU found and no math emulation present\n");
 		for (;;)
 			asm volatile("hlt");
 	}
@@ -120,6 +123,12 @@ static void fpu__init_system_generic(void)
 	fpu__init_system_mxcsr();
 }
 
+/*
+ * Size of the FPU context state. All tasks in the system use the
+ * same context size, regardless of what portion they use.
+ * This is inherent to the XSAVE architecture which puts all state
+ * components into a single, continuous memory block:
+ */
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
 
@@ -158,6 +167,37 @@ static void fpu__init_system_xstate_size_legacy(void)
 	}
 }
 
+/*
+ * FPU context switching strategies:
+ *
+ * Against popular belief, we don't do lazy FPU saves, due to the
+ * task migration complications it brings on SMP - we only do
+ * lazy FPU restores.
+ *
+ * 'lazy' is the traditional strategy, which is based on setting
+ * CR0::TS to 1 during context-switch (instead of doing a full
+ * restore of the FPU state), which causes the first FPU instruction
+ * after the context switch (whenever it is executed) to fault - at
+ * which point we lazily restore the FPU state into FPU registers.
+ *
+ * Tasks are of course under no obligation to execute FPU instructions,
+ * so it can easily happen that another context-switch occurs without
+ * a single FPU instruction being executed. If we eventually switch
+ * back to the original task (that still owns the FPU) then we have
+ * not only saved the restores along the way, but we also have the
+ * FPU ready to be used for the original task.
+ *
+ * 'eager' switching is used on modern CPUs, there we switch the FPU
+ * state during every context switch, regardless of whether the task
+ * has used FPU instructions in that time slice or not. This is done
+ * because modern FPU context saving instructions are able to optimize
+ * state saving and restoration in hardware: they can detect both
+ * unused and untouched FPU state and optimize accordingly.
+ *
+ * [ Note that even in 'lazy' mode we might optimize context switches
+ *   to use 'eager' restores, if we detect that a task is using the FPU
+ *   frequently. See the fpu->counter logic in fpu/internal.h for that. ]
+ */
 static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
 
 static int __init eager_fpu_setup(char *s)
@@ -173,8 +213,7 @@ static int __init eager_fpu_setup(char *s)
 __setup("eagerfpu=", eager_fpu_setup);
 
 /*
- * setup_init_fpu_buf() is __init and it is OK to call it here because
- * init_xstate_ctx will be unset only once during boot.
+ * Pick the FPU context switching strategy:
  */
 static void fpu__init_system_ctx_switch(void)
 {
@@ -202,20 +241,24 @@ static void fpu__init_system_ctx_switch(void)
 }
 
 /*
- * Called on the boot CPU once per system bootup, to set up the initial FPU state that
- * is later cloned into all processes.
+ * Called on the boot CPU once per system bootup, to set up the initial
+ * FPU state that is later cloned into all processes:
  */
 void fpu__init_system(struct cpuinfo_x86 *c)
 {
 	fpu__init_system_early_generic(c);
 
-	/* The FPU has to be operational for some of the later FPU init activities: */
+	/*
+	 * The FPU has to be operational for some of the
+	 * later FPU init activities:
+	 */
 	fpu__init_cpu();
 
 	/*
-	 * But don't leave CR0::TS set yet, as some of the FPU setup methods depend
-	 * on being able to execute FPU instructions that will fault on a set TS,
-	 * such as the FXSAVE in fpu__init_system_mxcsr().
+	 * But don't leave CR0::TS set yet, as some of the FPU setup
+	 * methods depend on being able to execute FPU instructions
+	 * that will fault on a set TS, such as the FXSAVE in
+	 * fpu__init_system_mxcsr().
 	 */
 	clts();
 
@@ -226,6 +269,9 @@ void fpu__init_system(struct cpuinfo_x86 *c)
 	fpu__init_system_ctx_switch();
 }
 
+/*
+ * Boot parameter to turn off FPU support and fall back to math-emu:
+ */
 static int __init no_387(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_FPU);

commit 41e78410d89cc0e60d90e6a62a060d5d4084accb
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 15:32:40 2015 +0200

    x86/fpu: Reorder init methods
    
    Reorder init methods in order of their relationship and usage, to
    form coherent blocks throughout the whole file.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index a7ce5bcbcbab..dbff1335229c 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -4,6 +4,46 @@
 #include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
 
+static void fpu__init_cpu_ctx_switch(void)
+{
+	if (!cpu_has_eager_fpu)
+		stts();
+	else
+		clts();
+}
+
+/*
+ * Initialize the registers found in all CPUs, CR0 and CR4:
+ */
+static void fpu__init_cpu_generic(void)
+{
+	unsigned long cr0;
+	unsigned long cr4_mask = 0;
+
+	if (cpu_has_fxsr)
+		cr4_mask |= X86_CR4_OSFXSR;
+	if (cpu_has_xmm)
+		cr4_mask |= X86_CR4_OSXMMEXCPT;
+	if (cr4_mask)
+		cr4_set_bits(cr4_mask);
+
+	cr0 = read_cr0();
+	cr0 &= ~(X86_CR0_TS|X86_CR0_EM); /* clear TS and EM */
+	if (!cpu_has_fpu)
+		cr0 |= X86_CR0_EM;
+	write_cr0(cr0);
+}
+
+/*
+ * Enable all supported FPU features. Called when a CPU is brought online.
+ */
+void fpu__init_cpu(void)
+{
+	fpu__init_cpu_generic();
+	fpu__init_cpu_xstate();
+	fpu__init_cpu_ctx_switch();
+}
+
 /*
  * The earliest FPU detection code.
  *
@@ -44,9 +84,6 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
  */
 unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
 
-unsigned int xstate_size;
-EXPORT_SYMBOL_GPL(xstate_size);
-
 static void fpu__init_system_mxcsr(void)
 {
 	unsigned int mask = 0;
@@ -83,6 +120,15 @@ static void fpu__init_system_generic(void)
 	fpu__init_system_mxcsr();
 }
 
+unsigned int xstate_size;
+EXPORT_SYMBOL_GPL(xstate_size);
+
+/*
+ * Set up the xstate_size based on the legacy FPU context size.
+ *
+ * We set this up first, and later it will be overwritten by
+ * fpu__init_system_xstate() if the CPU knows about xstates.
+ */
 static void fpu__init_system_xstate_size_legacy(void)
 {
 	static bool on_boot_cpu = 1;
@@ -112,50 +158,6 @@ static void fpu__init_system_xstate_size_legacy(void)
 	}
 }
 
-/*
- * Initialize the TS bit in CR0 according to the style of context-switches
- * we are using:
- */
-static void fpu__init_cpu_ctx_switch(void)
-{
-	if (!cpu_has_eager_fpu)
-		stts();
-	else
-		clts();
-}
-
-/*
- * Initialize the registers found in all CPUs, CR0 and CR4:
- */
-static void fpu__init_cpu_generic(void)
-{
-	unsigned long cr0;
-	unsigned long cr4_mask = 0;
-
-	if (cpu_has_fxsr)
-		cr4_mask |= X86_CR4_OSFXSR;
-	if (cpu_has_xmm)
-		cr4_mask |= X86_CR4_OSXMMEXCPT;
-	if (cr4_mask)
-		cr4_set_bits(cr4_mask);
-
-	cr0 = read_cr0();
-	cr0 &= ~(X86_CR0_TS|X86_CR0_EM); /* clear TS and EM */
-	if (!cpu_has_fpu)
-		cr0 |= X86_CR0_EM;
-	write_cr0(cr0);
-}
-
-/*
- * Enable all supported FPU features. Called when a CPU is brought online.
- */
-void fpu__init_cpu(void)
-{
-	fpu__init_cpu_generic();
-	fpu__init_cpu_xstate();
-	fpu__init_cpu_ctx_switch();
-}
-
 static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
 
 static int __init eager_fpu_setup(char *s)

commit 7638b74b56640d9c266b5b3622109128e30bdc1a
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 15:23:37 2015 +0200

    x86/fpu: Rename fpstate_xstate_init_size() to fpu__init_system_xstate_size_legacy()
    
    To bring it in line with the other init_system*() methods.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 77b5d403de22..a7ce5bcbcbab 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -83,7 +83,7 @@ static void fpu__init_system_generic(void)
 	fpu__init_system_mxcsr();
 }
 
-static void fpstate_xstate_init_size(void)
+static void fpu__init_system_xstate_size_legacy(void)
 {
 	static bool on_boot_cpu = 1;
 
@@ -218,7 +218,7 @@ void fpu__init_system(struct cpuinfo_x86 *c)
 	clts();
 
 	fpu__init_system_generic();
-	fpstate_xstate_init_size();
+	fpu__init_system_xstate_size_legacy();
 	fpu__init_system_xstate();
 
 	fpu__init_system_ctx_switch();

commit c66e3f28237199629358e9e5a76973c400a54041
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 15:12:44 2015 +0200

    x86/fpu: Remove the extra fpu__detect() layer
    
    Now that fpu__detect() has become an empty layer around
    fpu__init_system(), eliminate it and make fpu__init_system()
    the main system initialization routine.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 1155a98d8c1e..77b5d403de22 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -231,9 +231,3 @@ static int __init no_387(char *s)
 }
 
 __setup("no387", no_387);
-
-void fpu__detect(struct cpuinfo_x86 *c)
-{
-	fpu__init_system(c);
-	/* The final cr0 value is set later, in fpu_init() */
-}

commit dd863880acd24a23d71576e402f999375d0b4b80
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 15:07:18 2015 +0200

    x86/fpu: Move fpu__init_system_early_generic() out of fpu__detect()
    
    Move the fpu__init_system_early_generic() call into fpu__init_system(),
    which hosts all the system init calls.
    
    Expose fpu__init_system() to other modules - this will be our main and only
    system init function.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 63cd1703d25c..1155a98d8c1e 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -5,7 +5,10 @@
 #include <asm/tlbflush.h>
 
 /*
- * The earliest FPU detection code:
+ * The earliest FPU detection code.
+ *
+ * Set the X86_FEATURE_FPU CPU-capability bit based on
+ * trying to execute an actual sequence of FPU instructions:
  */
 static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 {
@@ -200,8 +203,10 @@ static void fpu__init_system_ctx_switch(void)
  * Called on the boot CPU once per system bootup, to set up the initial FPU state that
  * is later cloned into all processes.
  */
-void fpu__init_system(void)
+void fpu__init_system(struct cpuinfo_x86 *c)
 {
+	fpu__init_system_early_generic(c);
+
 	/* The FPU has to be operational for some of the later FPU init activities: */
 	fpu__init_cpu();
 
@@ -227,13 +232,8 @@ static int __init no_387(char *s)
 
 __setup("no387", no_387);
 
-/*
- * Set the X86_FEATURE_FPU CPU-capability bit based on
- * trying to execute an actual sequence of FPU instructions:
- */
 void fpu__detect(struct cpuinfo_x86 *c)
 {
-	fpu__init_system_early_generic(c);
-	fpu__init_system();
+	fpu__init_system(c);
 	/* The final cr0 value is set later, in fpu_init() */
 }

commit 0bf23f3d6cadb2f0961d0ea370371cf35480bcb5
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:48:08 2015 +0200

    x86/fpu: Factor out FPU bug checks into fpu/bugs.c
    
    Create separate fpu/bugs.c code so that if we read generic FPU code
    we don't have to wade through all the bugcheck related code first.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 69cdadd49ddf..63cd1703d25c 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -4,66 +4,6 @@
 #include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
 
-/*
- * Boot time CPU/FPU FDIV bug detection code:
- */
-
-static double __initdata x = 4195835.0;
-static double __initdata y = 3145727.0;
-
-/*
- * This used to check for exceptions..
- * However, it turns out that to support that,
- * the XMM trap handlers basically had to
- * be buggy. So let's have a correct XMM trap
- * handler, and forget about printing out
- * some status at boot.
- *
- * We should really only care about bugs here
- * anyway. Not features.
- */
-static void __init check_fpu(void)
-{
-	s32 fdiv_bug;
-
-	kernel_fpu_begin();
-
-	/*
-	 * trap_init() enabled FXSR and company _before_ testing for FP
-	 * problems here.
-	 *
-	 * Test for the divl bug: http://en.wikipedia.org/wiki/Fdiv_bug
-	 */
-	__asm__("fninit\n\t"
-		"fldl %1\n\t"
-		"fdivl %2\n\t"
-		"fmull %2\n\t"
-		"fldl %1\n\t"
-		"fsubp %%st,%%st(1)\n\t"
-		"fistpl %0\n\t"
-		"fwait\n\t"
-		"fninit"
-		: "=m" (*&fdiv_bug)
-		: "m" (*&x), "m" (*&y));
-
-	kernel_fpu_end();
-
-	if (fdiv_bug) {
-		set_cpu_bug(&boot_cpu_data, X86_BUG_FDIV);
-		pr_warn("Hmm, FPU with FDIV bug\n");
-	}
-}
-
-void fpu__init_check_bugs(void)
-{
-	/*
-	 * kernel_fpu_begin/end() in check_fpu() relies on the patched
-	 * alternative instructions.
-	 */
-	if (cpu_has_fpu)
-		check_fpu();
-}
-
 /*
  * The earliest FPU detection code:
  */

commit e83ab9ad97a702917cb018e6c5a7d1176ff95305
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:43:44 2015 +0200

    x86/fpu: Move !FPU check ingo fpu__init_system_early_generic()
    
    There's a !FPU related sanity check in fpu__init_cpu_generic(),
    which is executed on every CPU onlining - even though we should do
    this only once, and during system init.
    
    Move this check to fpu__init_system_early_generic().
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 3637c509956d..69cdadd49ddf 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -85,6 +85,15 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 		set_cpu_cap(c, X86_FEATURE_FPU);
 	else
 		clear_cpu_cap(c, X86_FEATURE_FPU);
+
+#ifndef CONFIG_MATH_EMULATION
+	if (!cpu_has_fpu) {
+		pr_emerg("No FPU found and no math emulation present\n");
+		pr_emerg("Giving up\n");
+		for (;;)
+			asm volatile("hlt");
+	}
+#endif
 }
 
 /*
@@ -180,14 +189,6 @@ static void fpu__init_cpu_generic(void)
 	unsigned long cr0;
 	unsigned long cr4_mask = 0;
 
-#ifndef CONFIG_MATH_EMULATION
-	if (!cpu_has_fpu) {
-		pr_emerg("No FPU found and no math emulation present\n");
-		pr_emerg("Giving up\n");
-		for (;;)
-			asm volatile("hlt");
-	}
-#endif
 	if (cpu_has_fxsr)
 		cr4_mask |= X86_CR4_OSFXSR;
 	if (cpu_has_xmm)

commit 2e2f3da7714f323a0db65baa19b2b8110cc23f95
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:40:54 2015 +0200

    x86/fpu: Factor out fpu__init_system_early_generic()
    
    Move the generic bits of fpu__detect() into fpu__init_system_early_generic().
    
    We'll move some other code here too in a followup patch.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index c3f3a89cbbf6..3637c509956d 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -64,6 +64,29 @@ void fpu__init_check_bugs(void)
 		check_fpu();
 }
 
+/*
+ * The earliest FPU detection code:
+ */
+static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
+{
+	unsigned long cr0;
+	u16 fsw, fcw;
+
+	fsw = fcw = 0xffff;
+
+	cr0 = read_cr0();
+	cr0 &= ~(X86_CR0_TS | X86_CR0_EM);
+	write_cr0(cr0);
+
+	asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
+		     : "+m" (fsw), "+m" (fcw));
+
+	if (fsw == 0 && (fcw & 0x103f) == 0x003f)
+		set_cpu_cap(c, X86_FEATURE_FPU);
+	else
+		clear_cpu_cap(c, X86_FEATURE_FPU);
+}
+
 /*
  * Boot time FPU feature detection code:
  */
@@ -269,23 +292,7 @@ __setup("no387", no_387);
  */
 void fpu__detect(struct cpuinfo_x86 *c)
 {
-	unsigned long cr0;
-	u16 fsw, fcw;
-
-	fsw = fcw = 0xffff;
-
-	cr0 = read_cr0();
-	cr0 &= ~(X86_CR0_TS | X86_CR0_EM);
-	write_cr0(cr0);
-
-	asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
-		     : "+m" (fsw), "+m" (fcw));
-
-	if (fsw == 0 && (fcw & 0x103f) == 0x003f)
-		set_cpu_cap(c, X86_FEATURE_FPU);
-	else
-		clear_cpu_cap(c, X86_FEATURE_FPU);
-
+	fpu__init_system_early_generic(c);
 	fpu__init_system();
 	/* The final cr0 value is set later, in fpu_init() */
 }

commit 7218e8b723dc9ceb71cf2fbd3d019e9e11b7d3cf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:35:54 2015 +0200

    x86/fpu: Factor out fpu__init_system_generic()
    
    Factor out the generic bits from fpu__init_system().
    
    Rename mxcsr_feature_mask_init() to fpu__init_system_mxcsr()
    to bring it in line with the rest of the nomenclature.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 37e8b139dc31..c3f3a89cbbf6 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -72,7 +72,7 @@ unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
 
-static void mxcsr_feature_mask_init(void)
+static void fpu__init_system_mxcsr(void)
 {
 	unsigned int mask = 0;
 
@@ -94,6 +94,20 @@ static void mxcsr_feature_mask_init(void)
 	mxcsr_feature_mask &= mask;
 }
 
+/*
+ * Once per bootup FPU initialization sequences that will run on most x86 CPUs:
+ */
+static void fpu__init_system_generic(void)
+{
+	/*
+	 * Set up the legacy init FPU context. (xstate init might overwrite this
+	 * with a more modern format, if the CPU supports it.)
+	 */
+	fx_finit(&init_xstate_ctx.i387);
+
+	fpu__init_system_mxcsr();
+}
+
 static void fpstate_xstate_init_size(void)
 {
 	static bool on_boot_cpu = 1;
@@ -230,18 +244,11 @@ void fpu__init_system(void)
 	/*
 	 * But don't leave CR0::TS set yet, as some of the FPU setup methods depend
 	 * on being able to execute FPU instructions that will fault on a set TS,
-	 * such as the FXSAVE in mxcsr_feature_mask_init().
+	 * such as the FXSAVE in fpu__init_system_mxcsr().
 	 */
 	clts();
 
-	/*
-	 * Set up the legacy init FPU context. (xstate init might overwrite this
-	 * with a more modern format, if the CPU supports it.)
-	 */
-	fx_finit(&init_xstate_ctx.i387);
-
-	mxcsr_feature_mask_init();
-
+	fpu__init_system_generic();
 	fpstate_xstate_init_size();
 	fpu__init_system_xstate();
 

commit b11316ed9ed9e453562d9f89a39d344331a3ec1d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:32:34 2015 +0200

    x86/fpu: Factor out fpu__init_cpu_generic()
    
    Factor out the generic bits from fpu__init_cpu(), to create
    a flat sequence of per CPU initialization function calls:
    
            fpu__init_cpu_generic();
            fpu__init_cpu_xstate();
            fpu__init_cpu_ctx_switch();
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index cf27bbed1ba1..37e8b139dc31 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -136,9 +136,9 @@ static void fpu__init_cpu_ctx_switch(void)
 }
 
 /*
- * Enable all supported FPU features. Called when a CPU is brought online.
+ * Initialize the registers found in all CPUs, CR0 and CR4:
  */
-void fpu__init_cpu(void)
+static void fpu__init_cpu_generic(void)
 {
 	unsigned long cr0;
 	unsigned long cr4_mask = 0;
@@ -163,7 +163,14 @@ void fpu__init_cpu(void)
 	if (!cpu_has_fpu)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
+}
 
+/*
+ * Enable all supported FPU features. Called when a CPU is brought online.
+ */
+void fpu__init_cpu(void)
+{
+	fpu__init_cpu_generic();
 	fpu__init_cpu_xstate();
 	fpu__init_cpu_ctx_switch();
 }

commit 21c4cd108a1b144ad645355bfee1f8be937f03a2
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 14:27:17 2015 +0200

    x86/fpu: Simplify fpu__cpu_init()
    
    After the latest round of cleanups, fpu__cpu_init() has become
    a simple call to fpu__init_cpu().
    
    Rename fpu__init_cpu() to fpu__cpu_init() and remove the
    extra layer.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 0c9c1069fba8..cf27bbed1ba1 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -241,11 +241,6 @@ void fpu__init_system(void)
 	fpu__init_system_ctx_switch();
 }
 
-void fpu__cpu_init(void)
-{
-	fpu__init_cpu();
-}
-
 static int __init no_387(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_FPU);

commit 7202ab46f7392265c1ecbf03f600393bf32a8bdf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Apr 24 12:17:57 2015 +0200

    x86/fpu: Remove fpu__init_cpu_ctx_switch() call from fpu__init_system()
    
    We are now doing the fpu__init_cpu_ctx_switch() call from fpu__init_cpu(),
    so there's no need to call it from fpu__init_system() anymore.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6e422cf1e197..0c9c1069fba8 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -239,7 +239,6 @@ void fpu__init_system(void)
 	fpu__init_system_xstate();
 
 	fpu__init_system_ctx_switch();
-	fpu__init_cpu_ctx_switch();
 }
 
 void fpu__cpu_init(void)

commit 067051ccd209623cb56152cf4cb06616ee2bcc5c
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:27:44 2015 +0200

    x86/fpu: Do system-wide setup from fpu__detect()
    
    fpu__cpu_init() is called on every CPU, so it is the wrong place
    to call fpu__init_system() from. Call it from fpu__detect():
    this is early CPU init code, but we already have CPU features detected,
    so we can call the system-wide FPU init code from here.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index b3ea4f86d643..6e422cf1e197 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -245,7 +245,6 @@ void fpu__init_system(void)
 void fpu__cpu_init(void)
 {
 	fpu__init_cpu();
-	fpu__init_system();
 }
 
 static int __init no_387(char *s)
@@ -279,5 +278,6 @@ void fpu__detect(struct cpuinfo_x86 *c)
 	else
 		clear_cpu_cap(c, X86_FEATURE_FPU);
 
+	fpu__init_system();
 	/* The final cr0 value is set later, in fpu_init() */
 }

commit 3960fccf2e22c3b3d61bd5a45b6172e66e660d8b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:27:44 2015 +0200

    x86/fpu: Call fpu__init_cpu_ctx_switch() from fpu__init_cpu()
    
    fpu__init_cpu() is currently called from fpu__init_system(),
    which is the wrong place for it: call it from the proper high level
    per CPU init function, fpu__init_cpu().
    
    Note, we still keep the old call site as well, because it depends
    on having proper CR0::TS setup. We'll fix this in the next patch.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index ca3468d8bc31..b3ea4f86d643 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -165,6 +165,7 @@ void fpu__init_cpu(void)
 	write_cr0(cr0);
 
 	fpu__init_cpu_xstate();
+	fpu__init_cpu_ctx_switch();
 }
 
 static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;

commit 997578b14c2730226a804d53ce681d3506f2f876
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 10:35:57 2015 +0200

    x86/fpu: Move the fpstate_xstate_init_size() call into fpu__init_system()
    
    The fpstate_xstate_init_size() function sets up a basic xstate_size, called
    during fpu__detect() currently.
    
    Its real dependency is to be called before fpu__init_system_xstate().
    
    So move the function call site into fpu__init_system(), to right before the
    fpu__init_system_xstate() call.
    
    Also add a once-per-boot flag to fpstate_xstate_init_size(), we'll remove
    this quirk later once we've cleaned up the init dependencies.
    
    This moves the two related functions closer to each other and makes them
    both part of the _init_system() functionality.
    
    Currently we do the fpstate_xstate_init_size()
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 567e7e6cdc6b..ca3468d8bc31 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -96,6 +96,12 @@ static void mxcsr_feature_mask_init(void)
 
 static void fpstate_xstate_init_size(void)
 {
+	static bool on_boot_cpu = 1;
+
+	if (!on_boot_cpu)
+		return;
+	on_boot_cpu = 0;
+
 	/*
 	 * Note that xstate_size might be overwriten later during
 	 * fpu__init_system_xstate().
@@ -227,7 +233,10 @@ void fpu__init_system(void)
 	fx_finit(&init_xstate_ctx.i387);
 
 	mxcsr_feature_mask_init();
+
+	fpstate_xstate_init_size();
 	fpu__init_system_xstate();
+
 	fpu__init_system_ctx_switch();
 	fpu__init_cpu_ctx_switch();
 }
@@ -270,6 +279,4 @@ void fpu__detect(struct cpuinfo_x86 *c)
 		clear_cpu_cap(c, X86_FEATURE_FPU);
 
 	/* The final cr0 value is set later, in fpu_init() */
-
-	fpstate_xstate_init_size();
 }

commit 530b37e43ce3f0bb9969308c0a64901b442f8e0a
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:27:44 2015 +0200

    x86/fpu: Do CLTS fpu__init_system()
    
    mxcsr_feature_mask_init() depends on TS being cleared, as it executes
    an FXSAVE instruction.
    
    After later changes we will move the TS setup into fpu__init_cpu(),
    which will interact with this - so clear the TS flag explicitly.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 2752b4bae854..567e7e6cdc6b 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -213,6 +213,13 @@ void fpu__init_system(void)
 	/* The FPU has to be operational for some of the later FPU init activities: */
 	fpu__init_cpu();
 
+	/*
+	 * But don't leave CR0::TS set yet, as some of the FPU setup methods depend
+	 * on being able to execute FPU instructions that will fault on a set TS,
+	 * such as the FXSAVE in mxcsr_feature_mask_init().
+	 */
+	clts();
+
 	/*
 	 * Set up the legacy init FPU context. (xstate init might overwrite this
 	 * with a more modern format, if the CPU supports it.)

commit 011545b570be22191047d07299515c1d711eeb38
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Apr 26 08:28:31 2015 +0200

    x86/fpu: Split fpu__ctx_switch_init() into _cpu() and _system() portions
    
    So fpu__ctx_switch_init() has two aspects: a once per bootup functionality
    that sets up a capability flag, and a per CPU functionality that sets CR0::TS.
    
    Split the function.
    
    Note that at this stage we still have duplicate calls into these methods, as
    both the _system() and the _cpu() methods are run on all CPUs, with lower
    level on_boot_cpu flags filtering out the duplicates where needed. So add
    TS flag clearing as well, to handle the aftermath of early CPU init sequences
    that might call in without having eager-fpu set - don't assume the TS flag
    is cleared.
    
    Calling each from its respective init level will happen later on.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index d6d582080c3b..2752b4bae854 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -117,6 +117,18 @@ static void fpstate_xstate_init_size(void)
 	}
 }
 
+/*
+ * Initialize the TS bit in CR0 according to the style of context-switches
+ * we are using:
+ */
+static void fpu__init_cpu_ctx_switch(void)
+{
+	if (!cpu_has_eager_fpu)
+		stts();
+	else
+		clts();
+}
+
 /*
  * Enable all supported FPU features. Called when a CPU is brought online.
  */
@@ -167,7 +179,7 @@ __setup("eagerfpu=", eager_fpu_setup);
  * setup_init_fpu_buf() is __init and it is OK to call it here because
  * init_xstate_ctx will be unset only once during boot.
  */
-static void fpu__ctx_switch_init(void)
+static void fpu__init_system_ctx_switch(void)
 {
 	WARN_ON(current->thread.fpu.fpstate_active);
 	current_thread_info()->status = 0;
@@ -190,9 +202,6 @@ static void fpu__ctx_switch_init(void)
 		setup_force_cpu_cap(X86_FEATURE_EAGER_FPU);
 
 	printk_once(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
-
-	if (!cpu_has_eager_fpu)
-		stts();
 }
 
 /*
@@ -212,7 +221,8 @@ void fpu__init_system(void)
 
 	mxcsr_feature_mask_init();
 	fpu__init_system_xstate();
-	fpu__ctx_switch_init();
+	fpu__init_system_ctx_switch();
+	fpu__init_cpu_ctx_switch();
 }
 
 void fpu__cpu_init(void)

commit 064e51e3c8aee6cfb03ab75e9f9551db3924eb07
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:48:54 2015 +0200

    x86/fpu: Clean up eager_fpu_init() and rename it to fpu__ctx_switch_init()
    
    It's not an xsave specific function anymore, so rename it accordingly
    and also clean it up a bit:
    
     - remove the obsolete __init_refok, as the code paths are not
       mixed anymore
    
     - rename it from eager_fpu_init() to fpu__ctx_switch_init()
    
     - remove stray 'return;'
    
     - make it static to its only user
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index fa9678f13630..d6d582080c3b 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -167,7 +167,7 @@ __setup("eagerfpu=", eager_fpu_setup);
  * setup_init_fpu_buf() is __init and it is OK to call it here because
  * init_xstate_ctx will be unset only once during boot.
  */
-void __init_refok eager_fpu_init(void)
+static void fpu__ctx_switch_init(void)
 {
 	WARN_ON(current->thread.fpu.fpstate_active);
 	current_thread_info()->status = 0;
@@ -191,10 +191,8 @@ void __init_refok eager_fpu_init(void)
 
 	printk_once(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
 
-	if (!cpu_has_eager_fpu) {
+	if (!cpu_has_eager_fpu)
 		stts();
-		return;
-	}
 }
 
 /*
@@ -214,7 +212,7 @@ void fpu__init_system(void)
 
 	mxcsr_feature_mask_init();
 	fpu__init_system_xstate();
-	eager_fpu_init();
+	fpu__ctx_switch_init();
 }
 
 void fpu__cpu_init(void)

commit 6f5d265afffb5968e25a8951a085c0467558c073
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 20:11:05 2015 +0200

    x86/fpu: Move eager_fpu_init() to fpu/init.c
    
    Move eager_fpu_init() and the 'eagerfpu' boot parameter handling function
    to the generic FPU init file: it's generic FPU functionality.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 30d2d5d03cb0..fa9678f13630 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -149,6 +149,54 @@ void fpu__init_cpu(void)
 	fpu__init_cpu_xstate();
 }
 
+static enum { AUTO, ENABLE, DISABLE } eagerfpu = AUTO;
+
+static int __init eager_fpu_setup(char *s)
+{
+	if (!strcmp(s, "on"))
+		eagerfpu = ENABLE;
+	else if (!strcmp(s, "off"))
+		eagerfpu = DISABLE;
+	else if (!strcmp(s, "auto"))
+		eagerfpu = AUTO;
+	return 1;
+}
+__setup("eagerfpu=", eager_fpu_setup);
+
+/*
+ * setup_init_fpu_buf() is __init and it is OK to call it here because
+ * init_xstate_ctx will be unset only once during boot.
+ */
+void __init_refok eager_fpu_init(void)
+{
+	WARN_ON(current->thread.fpu.fpstate_active);
+	current_thread_info()->status = 0;
+
+	/* Auto enable eagerfpu for xsaveopt */
+	if (cpu_has_xsaveopt && eagerfpu != DISABLE)
+		eagerfpu = ENABLE;
+
+	if (xfeatures_mask & XSTATE_EAGER) {
+		if (eagerfpu == DISABLE) {
+			pr_err("x86/fpu: eagerfpu switching disabled, disabling the following xstate features: 0x%llx.\n",
+			       xfeatures_mask & XSTATE_EAGER);
+			xfeatures_mask &= ~XSTATE_EAGER;
+		} else {
+			eagerfpu = ENABLE;
+		}
+	}
+
+	if (eagerfpu == ENABLE)
+		setup_force_cpu_cap(X86_FEATURE_EAGER_FPU);
+
+	printk_once(KERN_INFO "x86/fpu: Using '%s' FPU context switches.\n", eagerfpu == ENABLE ? "eager" : "lazy");
+
+	if (!cpu_has_eager_fpu) {
+		stts();
+		return;
+	}
+}
+
 /*
  * Called on the boot CPU once per system bootup, to set up the initial FPU state that
  * is later cloned into all processes.

commit 2507e1c03f577173d613d6728329eb220724c577
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:35:53 2015 +0200

    x86/fpu: Set up the legacy FPU init image from fpu__init_system()
    
    The legacy FPU init image is used on older CPUs who don't run xstate init.
    But the init code is called within setup_init_fpu_buf(), an xstate method.
    
    Move this legacy init out of the xstate code and put it into fpu/init.c.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index c1b2d1cfe745..30d2d5d03cb0 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -158,6 +158,12 @@ void fpu__init_system(void)
 	/* The FPU has to be operational for some of the later FPU init activities: */
 	fpu__init_cpu();
 
+	/*
+	 * Set up the legacy init FPU context. (xstate init might overwrite this
+	 * with a more modern format, if the CPU supports it.)
+	 */
+	fx_finit(&init_xstate_ctx.i387);
+
 	mxcsr_feature_mask_init();
 	fpu__init_system_xstate();
 	eager_fpu_init();

commit 429ced50a0e5f863f95b100749043451e1968c4c
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 08:21:08 2015 +0200

    x86/fpu: Do fpu__init_system_xstate only from fpu__init_system()
    
    Only call xstate system setup routines from fpu__init_system().
    
    Likewise, don't call fpu__init_cpu_xstate() from fpu__init_system().
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 77599fe8af56..c1b2d1cfe745 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -146,7 +146,6 @@ void fpu__init_cpu(void)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
-	fpu__init_system_xstate();
 	fpu__init_cpu_xstate();
 }
 
@@ -161,7 +160,6 @@ void fpu__init_system(void)
 
 	mxcsr_feature_mask_init();
 	fpu__init_system_xstate();
-	fpu__init_cpu_xstate();
 	eager_fpu_init();
 }
 

commit c42103b22652dae50e1aaacb5c2767145027ab3e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 06:52:53 2015 +0200

    x86/fpu: Remove xsave_init()
    
    Expand fpu__init_system_xstate() and fpu__init_cpu_xstate() calls
    into xsave_init() calls.
    
    (This will allow us to call the proper versions in higher level FPU init code
    later on.)
    
    No change in functionality.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index d6234adc8ba0..77599fe8af56 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -98,7 +98,7 @@ static void fpstate_xstate_init_size(void)
 {
 	/*
 	 * Note that xstate_size might be overwriten later during
-	 * xsave_init().
+	 * fpu__init_system_xstate().
 	 */
 
 	if (!cpu_has_fpu) {
@@ -146,7 +146,8 @@ void fpu__init_cpu(void)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
-	xsave_init();
+	fpu__init_system_xstate();
+	fpu__init_cpu_xstate();
 }
 
 /*
@@ -159,7 +160,8 @@ void fpu__init_system(void)
 	fpu__init_cpu();
 
 	mxcsr_feature_mask_init();
-	xsave_init();
+	fpu__init_system_xstate();
+	fpu__init_cpu_xstate();
 	eager_fpu_init();
 }
 

commit e35f6f14148c09ad534d122ed32722dd431ac184
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 04:34:48 2015 +0200

    x86/fpu: Split fpu__cpu_init() into early-boot and cpu-boot parts
    
    There are two kinds of FPU initialization sequences necessary to bring FPU
    functionality up: once per system bootup activities, such as detection,
    feature initialization, etc. of attributes that are shared by all CPUs
    in the system - and per cpu initialization sequences run when a CPU is
    brought online (either during bootup or during CPU hotplug onlining),
    such as CR0/CR4 register setting, etc.
    
    The FPU code is mixing these roles together, with no clear distinction.
    
    Start sorting this out by splitting the main FPU detection routine
    (fpu__cpu_init()) into two parts: fpu__init_system() for
    one per system init activities, and fpu__init_cpu() for the
    per CPU onlining init activities.
    
    Note that xstate_init() is called from both variants for the time being,
    because it has a dual nature as well. We'll fix that in upcoming patches.
    
    Just do the split and call it as we used to before, don't introduce any
    change in initialization behavior yet, beyond duplicate (and harmless)
    fpu__init_cpu() and xstate_init() calls - which we'll fix in later
    patches.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 3e0fee5bc2e7..d6234adc8ba0 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -118,13 +118,9 @@ static void fpstate_xstate_init_size(void)
 }
 
 /*
- * Called on the boot CPU at bootup to set up the initial FPU state that
- * is later cloned into all processes.
- *
- * Also called on secondary CPUs to set up the FPU state of their
- * idle threads.
+ * Enable all supported FPU features. Called when a CPU is brought online.
  */
-void fpu__cpu_init(void)
+void fpu__init_cpu(void)
 {
 	unsigned long cr0;
 	unsigned long cr4_mask = 0;
@@ -150,12 +146,29 @@ void fpu__cpu_init(void)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
+	xsave_init();
+}
+
+/*
+ * Called on the boot CPU once per system bootup, to set up the initial FPU state that
+ * is later cloned into all processes.
+ */
+void fpu__init_system(void)
+{
+	/* The FPU has to be operational for some of the later FPU init activities: */
+	fpu__init_cpu();
 
 	mxcsr_feature_mask_init();
 	xsave_init();
 	eager_fpu_init();
 }
 
+void fpu__cpu_init(void)
+{
+	fpu__init_cpu();
+	fpu__init_system();
+}
+
 static int __init no_387(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_FPU);

commit 6a133207587bce64efdd0fda9bea09ed994fa690
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 25 04:29:26 2015 +0200

    x86/fpu: Remove fpstate_xstate_init_size() boot quirk
    
    fpstate_xstate_init_size() is called in fpu__cpu_init(), which is
    run on every CPU, every time they are brought online.
    
    But we want to call fpstate_xstate_init_size() only once. Move it to
    fpu__detect(), which only runs once, on the boot CPU.
    
    Also clean up the flow of fpstate_xstate_init_size() a bit, by
    removing a 'return' from the middle of the function.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 0b16f61cb2a4..3e0fee5bc2e7 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -109,13 +109,12 @@ static void fpstate_xstate_init_size(void)
 		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
 		xstate_size = sizeof(struct i387_soft_struct);
-		return;
+	} else {
+		if (cpu_has_fxsr)
+			xstate_size = sizeof(struct i387_fxsave_struct);
+		else
+			xstate_size = sizeof(struct i387_fsave_struct);
 	}
-
-	if (cpu_has_fxsr)
-		xstate_size = sizeof(struct i387_fxsave_struct);
-	else
-		xstate_size = sizeof(struct i387_fsave_struct);
 }
 
 /*
@@ -151,12 +150,6 @@ void fpu__cpu_init(void)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
-	/*
-	 * fpstate_xstate_init_size() is only called once, to avoid overriding
-	 * 'xstate_size' during (secondary CPU) bootup or during CPU hotplug.
-	 */
-	if (xstate_size == 0)
-		fpstate_xstate_init_size();
 
 	mxcsr_feature_mask_init();
 	xsave_init();
@@ -194,5 +187,7 @@ void fpu__detect(struct cpuinfo_x86 *c)
 	else
 		clear_cpu_cap(c, X86_FEATURE_FPU);
 
-	/* The final cr0 value is set in fpu_init() */
+	/* The final cr0 value is set later, in fpu_init() */
+
+	fpstate_xstate_init_size();
 }

commit 91a8c2a5b43fc4be4adb4bda50cd331697e289e0
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Apr 24 10:49:11 2015 +0200

    x86/fpu: Clean up and fix MXCSR handling
    
    The code has the following problems:
    
     - it uses a single global 'fx_scratch' area that multiple CPUs could
       write into simultaneously, in theory.
    
     - it wastes 512 bytes of .data for something that is only rarely used.
    
    Fix this by moving the state buffer to the stack. Note that while
    this is 512 bytes, we don't ever call this function in very deep
    callchains, so its stack usage should not be a problem.
    
    Also add comments to explain the magic 0x0000ffbf default value.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 33df056b1624..0b16f61cb2a4 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -68,18 +68,26 @@ void fpu__init_check_bugs(void)
  * Boot time FPU feature detection code:
  */
 unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
+
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);
-static struct i387_fxsave_struct fx_scratch;
 
 static void mxcsr_feature_mask_init(void)
 {
-	unsigned long mask = 0;
+	unsigned int mask = 0;
 
 	if (cpu_has_fxsr) {
-		memset(&fx_scratch, 0, sizeof(struct i387_fxsave_struct));
-		asm volatile("fxsave %0" : "+m" (fx_scratch));
-		mask = fx_scratch.mxcsr_mask;
+		struct i387_fxsave_struct fx_tmp __aligned(32) = { };
+
+		asm volatile("fxsave %0" : "+m" (fx_tmp));
+
+		mask = fx_tmp.mxcsr_mask;
+
+		/*
+		 * If zero then use the default features mask,
+		 * which has all features set, except the
+		 * denormals-are-zero feature bit:
+		 */
 		if (mask == 0)
 			mask = 0x0000ffbf;
 	}

commit 78f7f1e54bac032b98956862a5bcf8c28ed22d07
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Apr 24 02:54:44 2015 +0200

    x86/fpu: Rename fpu-internal.h to fpu/internal.h
    
    This unifies all the FPU related header files under a unified, hiearchical
    naming scheme:
    
     - asm/fpu/types.h:      FPU related data types, needed for 'struct task_struct',
                             widely included in almost all kernel code, and hence kept
                             as small as possible.
    
     - asm/fpu/api.h:        FPU related 'public' methods exported to other subsystems.
    
     - asm/fpu/internal.h:   FPU subsystem internal methods
    
     - asm/fpu/xsave.h:      XSAVE support internal methods
    
    (Also standardize the header guard in asm/fpu/internal.h.)
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 4eabb426e910..33df056b1624 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -1,7 +1,7 @@
 /*
  * x86 FPU boot time init code
  */
-#include <asm/fpu-internal.h>
+#include <asm/fpu/internal.h>
 #include <asm/tlbflush.h>
 
 /*

commit 4d1640927bd54aa118f91c2bcfe6c2de0e2ba2a3
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Apr 22 13:44:25 2015 +0200

    x86/fpu: Factor out the FPU bug detection code into fpu__init_check_bugs()
    
    Move the boot-time FPU bug detection code to the other FPU boot time
    init code in fpu/init.c.
    
    No change in code size:
    
       text    data     bss     dec     hex filename
       13044568        1884440 1130496 16059504         f50c70 vmlinux.before
       13044568        1884440 1130496 16059504         f50c70 vmlinux.after
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 5e06aa6cc22e..4eabb426e910 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -4,6 +4,69 @@
 #include <asm/fpu-internal.h>
 #include <asm/tlbflush.h>
 
+/*
+ * Boot time CPU/FPU FDIV bug detection code:
+ */
+
+static double __initdata x = 4195835.0;
+static double __initdata y = 3145727.0;
+
+/*
+ * This used to check for exceptions..
+ * However, it turns out that to support that,
+ * the XMM trap handlers basically had to
+ * be buggy. So let's have a correct XMM trap
+ * handler, and forget about printing out
+ * some status at boot.
+ *
+ * We should really only care about bugs here
+ * anyway. Not features.
+ */
+static void __init check_fpu(void)
+{
+	s32 fdiv_bug;
+
+	kernel_fpu_begin();
+
+	/*
+	 * trap_init() enabled FXSR and company _before_ testing for FP
+	 * problems here.
+	 *
+	 * Test for the divl bug: http://en.wikipedia.org/wiki/Fdiv_bug
+	 */
+	__asm__("fninit\n\t"
+		"fldl %1\n\t"
+		"fdivl %2\n\t"
+		"fmull %2\n\t"
+		"fldl %1\n\t"
+		"fsubp %%st,%%st(1)\n\t"
+		"fistpl %0\n\t"
+		"fwait\n\t"
+		"fninit"
+		: "=m" (*&fdiv_bug)
+		: "m" (*&x), "m" (*&y));
+
+	kernel_fpu_end();
+
+	if (fdiv_bug) {
+		set_cpu_bug(&boot_cpu_data, X86_BUG_FDIV);
+		pr_warn("Hmm, FPU with FDIV bug\n");
+	}
+}
+
+void fpu__init_check_bugs(void)
+{
+	/*
+	 * kernel_fpu_begin/end() in check_fpu() relies on the patched
+	 * alternative instructions.
+	 */
+	if (cpu_has_fpu)
+		check_fpu();
+}
+
+/*
+ * Boot time FPU feature detection code:
+ */
 unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
 unsigned int xstate_size;
 EXPORT_SYMBOL_GPL(xstate_size);

commit 146ed598d12ac173bf5fed05ba7046812b8a8978
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Apr 22 11:36:14 2015 +0200

    x86/fpu: Move the no_387 handling and FPU detection code into init.c
    
    Both no_387() and fpu__detect() run at boot time, so they belong
    into init.c.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 0a666298abbd..5e06aa6cc22e 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -91,3 +91,37 @@ void fpu__cpu_init(void)
 	xsave_init();
 	eager_fpu_init();
 }
+
+static int __init no_387(char *s)
+{
+	setup_clear_cpu_cap(X86_FEATURE_FPU);
+	return 1;
+}
+
+__setup("no387", no_387);
+
+/*
+ * Set the X86_FEATURE_FPU CPU-capability bit based on
+ * trying to execute an actual sequence of FPU instructions:
+ */
+void fpu__detect(struct cpuinfo_x86 *c)
+{
+	unsigned long cr0;
+	u16 fsw, fcw;
+
+	fsw = fcw = 0xffff;
+
+	cr0 = read_cr0();
+	cr0 &= ~(X86_CR0_TS | X86_CR0_EM);
+	write_cr0(cr0);
+
+	asm volatile("fninit ; fnstsw %0 ; fnstcw %1"
+		     : "+m" (fsw), "+m" (fcw));
+
+	if (fsw == 0 && (fcw & 0x103f) == 0x003f)
+		set_cpu_cap(c, X86_FEATURE_FPU);
+	else
+		clear_cpu_cap(c, X86_FEATURE_FPU);
+
+	/* The final cr0 value is set in fpu_init() */
+}

commit 0c8675379048f36c76ad3a46519310ee2d626b2f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Apr 22 10:53:34 2015 +0200

    x86/fpu: Split out the boot time FPU init code into fpu/init.c
    
    Move boot time FPU initialization code into init.c, to better
    isolate it into its own domain.
    
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
new file mode 100644
index 000000000000..0a666298abbd
--- /dev/null
+++ b/arch/x86/kernel/fpu/init.c
@@ -0,0 +1,93 @@
+/*
+ * x86 FPU boot time init code
+ */
+#include <asm/fpu-internal.h>
+#include <asm/tlbflush.h>
+
+unsigned int mxcsr_feature_mask __read_mostly = 0xffffffffu;
+unsigned int xstate_size;
+EXPORT_SYMBOL_GPL(xstate_size);
+static struct i387_fxsave_struct fx_scratch;
+
+static void mxcsr_feature_mask_init(void)
+{
+	unsigned long mask = 0;
+
+	if (cpu_has_fxsr) {
+		memset(&fx_scratch, 0, sizeof(struct i387_fxsave_struct));
+		asm volatile("fxsave %0" : "+m" (fx_scratch));
+		mask = fx_scratch.mxcsr_mask;
+		if (mask == 0)
+			mask = 0x0000ffbf;
+	}
+	mxcsr_feature_mask &= mask;
+}
+
+static void fpstate_xstate_init_size(void)
+{
+	/*
+	 * Note that xstate_size might be overwriten later during
+	 * xsave_init().
+	 */
+
+	if (!cpu_has_fpu) {
+		/*
+		 * Disable xsave as we do not support it if i387
+		 * emulation is enabled.
+		 */
+		setup_clear_cpu_cap(X86_FEATURE_XSAVE);
+		setup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);
+		xstate_size = sizeof(struct i387_soft_struct);
+		return;
+	}
+
+	if (cpu_has_fxsr)
+		xstate_size = sizeof(struct i387_fxsave_struct);
+	else
+		xstate_size = sizeof(struct i387_fsave_struct);
+}
+
+/*
+ * Called on the boot CPU at bootup to set up the initial FPU state that
+ * is later cloned into all processes.
+ *
+ * Also called on secondary CPUs to set up the FPU state of their
+ * idle threads.
+ */
+void fpu__cpu_init(void)
+{
+	unsigned long cr0;
+	unsigned long cr4_mask = 0;
+
+#ifndef CONFIG_MATH_EMULATION
+	if (!cpu_has_fpu) {
+		pr_emerg("No FPU found and no math emulation present\n");
+		pr_emerg("Giving up\n");
+		for (;;)
+			asm volatile("hlt");
+	}
+#endif
+	if (cpu_has_fxsr)
+		cr4_mask |= X86_CR4_OSFXSR;
+	if (cpu_has_xmm)
+		cr4_mask |= X86_CR4_OSXMMEXCPT;
+	if (cr4_mask)
+		cr4_set_bits(cr4_mask);
+
+	cr0 = read_cr0();
+	cr0 &= ~(X86_CR0_TS|X86_CR0_EM); /* clear TS and EM */
+	if (!cpu_has_fpu)
+		cr0 |= X86_CR0_EM;
+	write_cr0(cr0);
+
+	/*
+	 * fpstate_xstate_init_size() is only called once, to avoid overriding
+	 * 'xstate_size' during (secondary CPU) bootup or during CPU hotplug.
+	 */
+	if (xstate_size == 0)
+		fpstate_xstate_init_size();
+
+	mxcsr_feature_mask_init();
+	xsave_init();
+	eager_fpu_init();
+}
