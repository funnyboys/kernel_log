commit 694cfd87b0c8a48af2f1afb225563571c0b975c4
Author: Ronald G. Minnich <rminnich@gmail.com>
Date:   Sat Apr 25 18:10:21 2020 -0700

    x86/setup: Add an initrdmem= option to specify initrd physical address
    
    Add the initrdmem option:
    
      initrdmem=ss[KMG],nn[KMG]
    
    which is used to specify the physical address of the initrd, almost
    always an address in FLASH. Also add code for x86 to use the existing
    phys_init_start and phys_init_size variables in the kernel.
    
    This is useful in cases where a kernel and an initrd is placed in FLASH,
    but there is no firmware file system structure in the FLASH.
    
    One such situation occurs when unused FLASH space on UEFI systems has
    been reclaimed by, e.g., taking it from the Management Engine. For
    example, on many systems, the ME is given half the FLASH part; not only
    is 2.75M of an 8M part unused; but 10.75M of a 16M part is unused. This
    space can be used to contain an initrd, but need to tell Linux where it
    is.
    
    This space is "raw": due to, e.g., UEFI limitations: it can not be added
    to UEFI firmware volumes without rebuilding UEFI from source or writing
    a UEFI device driver. It can be referenced only as a physical address
    and size.
    
    At the same time, if a kernel can be "netbooted" or loaded from GRUB or
    syslinux, the option of not using the physical address specification
    should be available.
    
    Then, it is easy to boot the kernel and provide an initrd; or boot the
    the kernel and let it use the initrd in FLASH. In practice, this has
    proven to be very helpful when integrating Linux into FLASH on x86.
    
    Hence, the most flexible and convenient path is to enable the initrdmem
    command line option in a way that it is the last choice tried.
    
    For example, on the DigitalLoggers Atomic Pi, an image into FLASH can be
    burnt in with a built-in command line which includes:
    
      initrdmem=0xff968000,0x200000
    
    which specifies a location and size.
    
     [ bp: Massage commit message, make it passive. ]
    
    [akpm@linux-foundation.org: coding style fixes]
    Signed-off-by: Ronald G. Minnich <rminnich@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: H. Peter Anvin (Intel) <hpa@zytor.com>
    Link: http://lkml.kernel.org/r/CAP6exYLK11rhreX=6QPyDQmW7wPHsKNEFtXE47pjx41xS6O7-A@mail.gmail.com
    Link: https://lkml.kernel.org/r/20200426011021.1cskg0AGd%akpm@linux-foundation.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4b3fa6cd3106..a3767e74c758 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -237,6 +237,9 @@ static u64 __init get_ramdisk_image(void)
 
 	ramdisk_image |= (u64)boot_params.ext_ramdisk_image << 32;
 
+	if (ramdisk_image == 0)
+		ramdisk_image = phys_initrd_start;
+
 	return ramdisk_image;
 }
 static u64 __init get_ramdisk_size(void)
@@ -245,6 +248,9 @@ static u64 __init get_ramdisk_size(void)
 
 	ramdisk_size |= (u64)boot_params.ext_ramdisk_size << 32;
 
+	if (ramdisk_size == 0)
+		ramdisk_size = phys_initrd_size;
+
 	return ramdisk_size;
 }
 

commit cf11e85fc08cc6a4fe3ac2ba2e610c962bf20bc3
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Apr 10 14:32:45 2020 -0700

    mm: hugetlb: optionally allocate gigantic hugepages using cma
    
    Commit 944d9fec8d7a ("hugetlb: add support for gigantic page allocation
    at runtime") has added the run-time allocation of gigantic pages.
    
    However it actually works only at early stages of the system loading,
    when the majority of memory is free.  After some time the memory gets
    fragmented by non-movable pages, so the chances to find a contiguous 1GB
    block are getting close to zero.  Even dropping caches manually doesn't
    help a lot.
    
    At large scale rebooting servers in order to allocate gigantic hugepages
    is quite expensive and complex.  At the same time keeping some constant
    percentage of memory in reserved hugepages even if the workload isn't
    using it is a big waste: not all workloads can benefit from using 1 GB
    pages.
    
    The following solution can solve the problem:
    1) On boot time a dedicated cma area* is reserved. The size is passed
       as a kernel argument.
    2) Run-time allocations of gigantic hugepages are performed using the
       cma allocator and the dedicated cma area
    
    In this case gigantic hugepages can be allocated successfully with a
    high probability, however the memory isn't completely wasted if nobody
    is using 1GB hugepages: it can be used for pagecache, anon memory, THPs,
    etc.
    
    * On a multi-node machine a per-node cma area is allocated on each node.
      Following gigantic hugetlb allocation are using the first available
      numa node if the mask isn't specified by a user.
    
    Usage:
    1) configure the kernel to allocate a cma area for hugetlb allocations:
       pass hugetlb_cma=10G as a kernel argument
    
    2) allocate hugetlb pages as usual, e.g.
       echo 10 > /sys/kernel/mm/hugepages/hugepages-1048576kB/nr_hugepages
    
    If the option isn't enabled or the allocation of the cma area failed,
    the current behavior of the system is preserved.
    
    x86 and arm-64 are covered by this patch, other architectures can be
    trivially added later.
    
    The patch contains clean-ups and fixes proposed and implemented by Aslan
    Bakirov and Randy Dunlap.  It also contains ideas and suggestions
    proposed by Rik van Riel, Michal Hocko and Mike Kravetz.  Thanks!
    
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Andreas Schaufler <andreas.schaufler@gmx.de>
    Acked-by: Mike Kravetz <mike.kravetz@oracle.com>
    Acked-by: Michal Hocko <mhocko@kernel.org>
    Cc: Aslan Bakirov <aslan@fb.com>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Link: http://lkml.kernel.org/r/20200407163840.92263-3-guro@fb.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e6b545047f38..4b3fa6cd3106 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -16,6 +16,7 @@
 #include <linux/pci.h>
 #include <linux/root_dev.h>
 #include <linux/sfi.h>
+#include <linux/hugetlb.h>
 #include <linux/tboot.h>
 #include <linux/usb/xhci-dbgp.h>
 
@@ -1157,6 +1158,9 @@ void __init setup_arch(char **cmdline_p)
 	initmem_init();
 	dma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);
 
+	if (boot_cpu_has(X86_FEATURE_GBPAGES))
+		hugetlb_cma_reserve(PUD_SHIFT - PAGE_SHIFT);
+
 	/*
 	 * Reserve memory for crash kernel after SRAT is parsed so that it
 	 * won't consume hotpluggable memory.

commit bac59d18c7018a2fd5e800a1e72a8271bf404977
Author: Guenter Roeck <linux@roeck-us.net>
Date:   Thu Jan 30 18:11:59 2020 -0800

    x86/setup: Fix static memory detection
    
    When booting x86 images in qemu, the following warning is seen randomly
    if DEBUG_LOCKDEP is enabled.
    
      WARNING: CPU: 0 PID: 1 at kernel/locking/lockdep.c:1119
              lockdep_register_key+0xc0/0x100
    
    static_obj() returns true if an address is between _stext and _end.
    
    On x86, this includes the brk memory space. Problem is that this memory
    block is not static on x86; its unused portions are released after init
    and can be allocated. This results in the observed warning if a lockdep
    object is allocated from this memory.
    
    Solve the problem by implementing arch_is_kernel_initmem_freed() for
    x86 and have it return true if an address is within the released memory
    range.
    
    The same problem was solved for s390 with commit
    
      7a5da02de8d6e ("locking/lockdep: check for freed initmem in static_obj()"),
    
    which introduced arch_is_kernel_initmem_freed().
    
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20200131021159.9178-1-linux@roeck-us.net

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a74262c71484..e6b545047f38 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -64,7 +64,6 @@ RESERVE_BRK(dmi_alloc, 65536);
  * at link time, with RESERVE_BRK*() facility reserving additional
  * chunks.
  */
-static __initdata
 unsigned long _brk_start = (unsigned long)__brk_base;
 unsigned long _brk_end   = (unsigned long)__brk_base;
 

commit ccaaaf6fe5a5e1fffca5cca0f3fc4ec84d7ae752
Merge: 35c222fd3236 45fc24e89b7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 16:11:50 2020 -0800

    Merge tag 'mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/daveh/x86-mpx
    
    Pull x86 MPX removal from Dave Hansen:
     "MPX requires recompiling applications, which requires compiler
      support. Unfortunately, GCC 9.1 is expected to be be released without
      support for MPX. This means that there was only a relatively small
      window where folks could have ever used MPX. It failed to gain wide
      adoption in the industry, and Linux was the only mainstream OS to ever
      support it widely.
    
      Support for the feature may also disappear on future processors.
    
      This set completes the process that we started during the 5.4 merge
      window when the MPX prctl()s were removed. XSAVE support is left in
      place, which allows MPX-using KVM guests to continue to function"
    
    * tag 'mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/daveh/x86-mpx:
      x86/mpx: remove MPX from arch/x86
      mm: remove arch_bprm_mm_init() hook
      x86/mpx: remove bounds exception code
      x86/mpx: remove build infrastructure
      x86/alternatives: add missing insn.h include

commit ca9b5b6283984f67434cee810f3b08e19630226d
Merge: aac96626713f 85f4c95172d6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 29 10:13:27 2020 -0800

    Merge tag 'tty-5.6-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty
    
    Pull tty/serial driver updates from Greg KH:
     "Here are the big set of tty and serial driver updates for 5.6-rc1
    
      Included in here are:
       - dummy_con cleanups (touches lots of arch code)
       - sysrq logic cleanups (touches lots of serial drivers)
       - samsung driver fixes (wasn't really being built)
       - conmakeshash move to tty subdir out of scripts
       - lots of small tty/serial driver updates
    
      All of these have been in linux-next for a while with no reported
      issues"
    
    * tag 'tty-5.6-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty: (140 commits)
      tty: n_hdlc: Use flexible-array member and struct_size() helper
      tty: baudrate: SPARC supports few more baud rates
      tty: baudrate: Synchronise baud_table[] and baud_bits[]
      tty: serial: meson_uart: Add support for kernel debugger
      serial: imx: fix a race condition in receive path
      serial: 8250_bcm2835aux: Document struct bcm2835aux_data
      serial: 8250_bcm2835aux: Use generic remapping code
      serial: 8250_bcm2835aux: Allocate uart_8250_port on stack
      serial: 8250_bcm2835aux: Suppress register_port error on -EPROBE_DEFER
      serial: 8250_bcm2835aux: Suppress clk_get error on -EPROBE_DEFER
      serial: 8250_bcm2835aux: Fix line mismatch on driver unbind
      serial_core: Remove unused member in uart_port
      vt: Correct comment documenting do_take_over_console()
      vt: Delete comment referencing non-existent unbind_con_driver()
      arch/xtensa/setup: Drop dummy_con initialization
      arch/x86/setup: Drop dummy_con initialization
      arch/unicore32/setup: Drop dummy_con initialization
      arch/sparc/setup: Drop dummy_con initialization
      arch/sh/setup: Drop dummy_con initialization
      arch/s390/setup: Drop dummy_con initialization
      ...

commit 634cd4b6afe15dca8df02bcba242b9b0c5e9b5a5
Merge: d99391ec2b42 ac6119e7f25b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 28 09:03:40 2020 -0800

    Merge branch 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull EFI updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - Cleanup of the GOP [graphics output] handling code in the EFI stub
    
       - Complete refactoring of the mixed mode handling in the x86 EFI stub
    
       - Overhaul of the x86 EFI boot/runtime code
    
       - Increase robustness for mixed mode code
    
       - Add the ability to disable DMA at the root port level in the EFI
         stub
    
       - Get rid of RWX mappings in the EFI memory map and page tables,
         where possible
    
       - Move the support code for the old EFI memory mapping style into its
         only user, the SGI UV1+ support code.
    
       - plus misc fixes, updates, smaller cleanups.
    
      ... and due to interactions with the RWX changes, another round of PAT
      cleanups make a guest appearance via the EFI tree - with no side
      effects intended"
    
    * 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (75 commits)
      efi/x86: Disable instrumentation in the EFI runtime handling code
      efi/libstub/x86: Fix EFI server boot failure
      efi/x86: Disallow efi=old_map in mixed mode
      x86/boot/compressed: Relax sed symbol type regex for LLVM ld.lld
      efi/x86: avoid KASAN false positives when accessing the 1: 1 mapping
      efi: Fix handling of multiple efi_fake_mem= entries
      efi: Fix efi_memmap_alloc() leaks
      efi: Add tracking for dynamically allocated memmaps
      efi: Add a flags parameter to efi_memory_map
      efi: Fix comment for efi_mem_type() wrt absent physical addresses
      efi/arm: Defer probe of PCIe backed efifb on DT systems
      efi/x86: Limit EFI old memory map to SGI UV machines
      efi/x86: Avoid RWX mappings for all of DRAM
      efi/x86: Don't map the entire kernel text RW for mixed mode
      x86/mm: Fix NX bit clearing issue in kernel_map_pages_in_pgd
      efi/libstub/x86: Fix unused-variable warning
      efi/libstub/x86: Use mandatory 16-byte stack alignment in mixed mode
      efi/libstub/x86: Use const attribute for efi_is_64bit()
      efi: Allow disabling PCI busmastering on bridges during boot
      efi/x86: Allow translating 64-bit arguments for mixed mode calls
      ...

commit 45fc24e89b7cc2e227b2f03d99dda0a2204bf383
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Thu Jan 23 10:41:20 2020 -0800

    x86/mpx: remove MPX from arch/x86
    
    From: Dave Hansen <dave.hansen@linux.intel.com>
    
    MPX is being removed from the kernel due to a lack of support
    in the toolchain going forward (gcc).
    
    This removes all the remaining (dead at this point) MPX handling
    code remaining in the tree.  The only remaining code is the XSAVE
    support for MPX state which is currently needd for KVM to handle
    VMs which might use MPX.
    
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: x86@kernel.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 77ea96b794bd..6cf206806be0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -947,8 +947,6 @@ void __init setup_arch(char **cmdline_p)
 	init_mm.end_data = (unsigned long) _edata;
 	init_mm.brk = _brk_end;
 
-	mpx_mm_init(&init_mm);
-
 	code_resource.start = __pa_symbol(_text);
 	code_resource.end = __pa_symbol(_etext)-1;
 	data_resource.start = __pa_symbol(_etext);

commit 2f1e1d8ba44458bdc673ac01d04ba7300d9f9534
Author: Arvind Sankar <nivedita@alum.mit.edu>
Date:   Wed Dec 18 16:45:05 2019 -0500

    arch/x86/setup: Drop dummy_con initialization
    
    con_init in tty/vt.c will now set conswitchp to dummy_con if it's unset.
    Drop it from arch setup code.
    
    Signed-off-by: Arvind Sankar <nivedita@alum.mit.edu>
    Link: https://lore.kernel.org/r/20191218214506.49252-24-nivedita@alum.mit.edu
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cedfe2077a69..8ad29fa05d00 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1295,8 +1295,6 @@ void __init setup_arch(char **cmdline_p)
 #if defined(CONFIG_VGA_CONSOLE)
 	if (!efi_enabled(EFI_BOOT) || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))
 		conswitchp = &vga_con;
-#elif defined(CONFIG_DUMMY_CONSOLE)
-	conswitchp = &dummy_con;
 #endif
 #endif
 	x86_init.oem.banner();

commit ca947b72e1dec3a000190733f7e0be38fe73eaae
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Nov 26 08:54:07 2019 -0800

    x86/boot: Explicitly include realmode.h to handle RM reservations
    
    Explicitly include asm/realmode.h, which provides reserve_real_mode(),
    instead of picking it up by an indirect include of asm/acpi.h.  acpi.h
    will soon stop including realmode.h so that changing realmode.h doesn't
    require a full kernel rebuild.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Link: https://lkml.kernel.org/r/20191126165417.22423-3-sean.j.christopherson@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b5ac9932bcf6..a58498364cac 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -35,6 +35,7 @@
 #include <asm/kaslr.h>
 #include <asm/mce.h>
 #include <asm/mtrr.h>
+#include <asm/realmode.h>
 #include <asm/olpc_ofw.h>
 #include <asm/pci-direct.h>
 #include <asm/prom.h>

commit 186525bd6b83efc592672e2d6185e4d7c810d2b4
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Nov 29 08:17:25 2019 +0100

    mm, x86/mm: Untangle address space layout definitions from basic pgtable type definitions
    
    - Untangle the somewhat incestous way of how VMALLOC_START is used all across the
      kernel, but is, on x86, defined deep inside one of the lowest level page table headers.
      It doesn't help that vmalloc.h only includes a single asm header:
    
         #include <asm/page.h>           /* pgprot_t */
    
      So there was no existing cross-arch way to decouple address layout
      definitions from page.h details. I used this:
    
       #ifndef VMALLOC_START
       # include <asm/vmalloc.h>
       #endif
    
      This way every architecture that wants to simplify page.h can do so.
    
    - Also on x86 we had a couple of LDT related inline functions that used
      the late-stage address space layout positions - but these could be
      uninlined without real trouble - the end result is cleaner this way as
      well.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b5ac9932bcf6..90296a04e5ad 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -41,6 +41,7 @@
 #include <asm/proto.h>
 #include <asm/unwind.h>
 #include <asm/vsyscall.h>
+#include <linux/vmalloc.h>
 
 /*
  * max_low_pfn_mapped: highest directly mapped pfn < 4 GB

commit 360db4ace3117ac1d9936d529f59c653e337b0f5
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Nov 18 16:03:39 2019 +0100

    x86/setup: Enhance the comments
    
    Update various comments, fix outright mistakes and meaningless descriptions.
    
    Also harmonize the style across the file, both in form and in language.
    
    Cc: linux-kernel@vger.kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7778ee065470..b5ac9932bcf6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -43,11 +43,11 @@
 #include <asm/vsyscall.h>
 
 /*
- * max_low_pfn_mapped: highest direct mapped pfn under 4GB
- * max_pfn_mapped:     highest direct mapped pfn over 4GB
+ * max_low_pfn_mapped: highest directly mapped pfn < 4 GB
+ * max_pfn_mapped:     highest directly mapped pfn > 4 GB
  *
  * The direct mapping only covers E820_TYPE_RAM regions, so the ranges and gaps are
- * represented by pfn_mapped
+ * represented by pfn_mapped[].
  */
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
@@ -57,14 +57,23 @@ RESERVE_BRK(dmi_alloc, 65536);
 #endif
 
 
-static __initdata unsigned long _brk_start = (unsigned long)__brk_base;
-unsigned long _brk_end = (unsigned long)__brk_base;
+/*
+ * Range of the BSS area. The size of the BSS area is determined
+ * at link time, with RESERVE_BRK*() facility reserving additional
+ * chunks.
+ */
+static __initdata
+unsigned long _brk_start = (unsigned long)__brk_base;
+unsigned long _brk_end   = (unsigned long)__brk_base;
 
 struct boot_params boot_params;
 
 /*
- * Machine setup..
+ * These are the four main kernel memory regions, we put them into
+ * the resource tree so that kdump tools and other debugging tools
+ * recover it:
  */
+
 static struct resource rodata_resource = {
 	.name	= "Kernel rodata",
 	.start	= 0,
@@ -95,16 +104,16 @@ static struct resource bss_resource = {
 
 
 #ifdef CONFIG_X86_32
-/* cpu data as detected by the assembly code in head_32.S */
+/* CPU data as detected by the assembly code in head_32.S */
 struct cpuinfo_x86 new_cpu_data;
 
-/* common cpu data for all cpus */
+/* Common CPU data for all CPUs */
 struct cpuinfo_x86 boot_cpu_data __read_mostly;
 EXPORT_SYMBOL(boot_cpu_data);
 
 unsigned int def_to_bigsmp;
 
-/* for MCA, but anyone else can use it if they want */
+/* For MCA, but anyone else can use it if they want */
 unsigned int machine_id;
 unsigned int machine_submodel_id;
 unsigned int BIOS_revision;
@@ -390,15 +399,15 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 /*
  * Keep the crash kernel below this limit.
  *
- * On 32 bits earlier kernels would limit the kernel to the low 512 MiB
+ * Earlier 32-bits kernels would limit the kernel to the low 512 MB range
  * due to mapping restrictions.
  *
- * On 64bit, kdump kernel need be restricted to be under 64TB, which is
+ * 64-bit kdump kernels need to be restricted to be under 64 TB, which is
  * the upper limit of system RAM in 4-level paging mode. Since the kdump
- * jumping could be from 5-level to 4-level, the jumping will fail if
- * kernel is put above 64TB, and there's no way to detect the paging mode
- * of the kernel which will be loaded for dumping during the 1st kernel
- * bootup.
+ * jump could be from 5-level paging to 4-level paging, the jump will fail if
+ * the kernel is put above 64 TB, and during the 1st kernel bootup there's
+ * no good way to detect the paging mode of the target kernel which will be
+ * loaded for dumping.
  */
 #ifdef CONFIG_X86_32
 # define CRASH_ADDR_LOW_MAX	SZ_512M
@@ -809,7 +818,7 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Note: Quark X1000 CPUs advertise PGE incorrectly and require
 	 * a cr3 based tlb flush, so the following __flush_tlb_all()
-	 * will not flush anything because the cpu quirk which clears
+	 * will not flush anything because the CPU quirk which clears
 	 * X86_FEATURE_PGE has not been invoked yet. Though due to the
 	 * load_cr3() above the TLB has been flushed already. The
 	 * quirk is invoked before subsequent calls to __flush_tlb_all()

commit 12609013c43acaa5e547062ffc2fcfc4dcddde2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Nov 18 15:49:22 2019 +0100

    x86/setup: Clean up the header portion of setup.c
    
    In 20 years we accumulated 89 #include lines in setup.c,
    but we only need 30 of them (!) ...
    
    Get rid of the excessive ones, and while at it, sort the
    remaining ones alphabetically.
    
    Also get rid of the incomplete changelogs at the header of the file,
    and explain better what this file does.
    
    Cc: linux-kernel@vger.kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cedfe2077a69..7778ee065470 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -2,123 +2,45 @@
 /*
  *  Copyright (C) 1995  Linus Torvalds
  *
- *  Support of BIGMEM added by Gerhard Wichert, Siemens AG, July 1999
- *
- *  Memory region support
- *	David Parsons <orc@pell.chi.il.us>, July-August 1999
- *
- *  Added E820 sanitization routine (removes overlapping memory regions);
- *  Brian Moyle <bmoyle@mvista.com>, February 2001
- *
- * Moved CPU detection code to cpu/${cpu}.c
- *    Patrick Mochel <mochel@osdl.org>, March 2002
- *
- *  Provisions for empty E820 memory regions (reported by certain BIOSes).
- *  Alex Achenbach <xela@slit.de>, December 2002.
- *
+ * This file contains the setup_arch() code, which handles the architecture-dependent
+ * parts of early kernel initialization.
  */
-
-/*
- * This file handles the architecture-dependent parts of initialization
- */
-
-#include <linux/sched.h>
-#include <linux/mm.h>
-#include <linux/mmzone.h>
-#include <linux/screen_info.h>
-#include <linux/ioport.h>
-#include <linux/acpi.h>
-#include <linux/sfi.h>
-#include <linux/apm_bios.h>
-#include <linux/initrd.h>
-#include <linux/memblock.h>
-#include <linux/seq_file.h>
 #include <linux/console.h>
-#include <linux/root_dev.h>
-#include <linux/highmem.h>
-#include <linux/export.h>
+#include <linux/crash_dump.h>
+#include <linux/dmi.h>
 #include <linux/efi.h>
-#include <linux/init.h>
-#include <linux/edd.h>
+#include <linux/init_ohci1394_dma.h>
+#include <linux/initrd.h>
 #include <linux/iscsi_ibft.h>
-#include <linux/nodemask.h>
-#include <linux/kexec.h>
-#include <linux/dmi.h>
-#include <linux/pfn.h>
+#include <linux/memblock.h>
 #include <linux/pci.h>
-#include <asm/pci-direct.h>
-#include <linux/init_ohci1394_dma.h>
-#include <linux/kvm_para.h>
-#include <linux/dma-contiguous.h>
-#include <xen/xen.h>
-#include <uapi/linux/mount.h>
-
-#include <linux/errno.h>
-#include <linux/kernel.h>
-#include <linux/stddef.h>
-#include <linux/unistd.h>
-#include <linux/ptrace.h>
-#include <linux/user.h>
-#include <linux/delay.h>
-
-#include <linux/kallsyms.h>
-#include <linux/cpufreq.h>
-#include <linux/dma-mapping.h>
-#include <linux/ctype.h>
-#include <linux/uaccess.h>
-
-#include <linux/percpu.h>
-#include <linux/crash_dump.h>
+#include <linux/root_dev.h>
+#include <linux/sfi.h>
 #include <linux/tboot.h>
-#include <linux/jiffies.h>
-#include <linux/mem_encrypt.h>
-#include <linux/sizes.h>
-
 #include <linux/usb/xhci-dbgp.h>
-#include <video/edid.h>
 
-#include <asm/mtrr.h>
+#include <uapi/linux/mount.h>
+
+#include <xen/xen.h>
+
 #include <asm/apic.h>
-#include <asm/realmode.h>
-#include <asm/e820/api.h>
-#include <asm/mpspec.h>
-#include <asm/setup.h>
-#include <asm/efi.h>
-#include <asm/timer.h>
-#include <asm/i8259.h>
-#include <asm/sections.h>
-#include <asm/io_apic.h>
-#include <asm/ist.h>
-#include <asm/setup_arch.h>
 #include <asm/bios_ebda.h>
-#include <asm/cacheflush.h>
-#include <asm/processor.h>
 #include <asm/bugs.h>
-#include <asm/kasan.h>
-
-#include <asm/vsyscall.h>
 #include <asm/cpu.h>
-#include <asm/desc.h>
-#include <asm/dma.h>
-#include <asm/iommu.h>
+#include <asm/efi.h>
 #include <asm/gart.h>
-#include <asm/mmu_context.h>
-#include <asm/proto.h>
-
-#include <asm/paravirt.h>
 #include <asm/hypervisor.h>
-#include <asm/olpc_ofw.h>
-
-#include <asm/percpu.h>
-#include <asm/topology.h>
-#include <asm/apicdef.h>
-#include <asm/amd_nb.h>
+#include <asm/io_apic.h>
+#include <asm/kasan.h>
+#include <asm/kaslr.h>
 #include <asm/mce.h>
-#include <asm/alternative.h>
+#include <asm/mtrr.h>
+#include <asm/olpc_ofw.h>
+#include <asm/pci-direct.h>
 #include <asm/prom.h>
-#include <asm/microcode.h>
-#include <asm/kaslr.h>
+#include <asm/proto.h>
 #include <asm/unwind.h>
+#include <asm/vsyscall.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB

commit 6e9f879684b46331f51d0c76ebee981c788417db
Merge: 9e7a03233e02 782b59711e15
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 26 19:25:25 2019 -0800

    Merge tag 'acpi-5.5-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI updates from Rafael Wysocki:
     "These update the ACPICA code in the kernel to upstream revision
      20191018, add support for EFI specific purpose memory, update the ACPI
      EC driver to make it work on systems with hardware-reduced ACPI,
      improve ACPI-based device enumeration for some platforms, rework the
      lid blacklist handling in the button driver and add more lid quirks to
      it, unify ACPI _HID/_UID matching, fix assorted issues and clean up
      the code and documentation.
    
      Specifics:
    
       - Update the ACPICA code in the kernel to upstream revision 20191018
         including:
          * Fixes for Clang warnings (Bob Moore)
          * Fix for possible overflow in get_tick_count() (Bob Moore)
          * Introduction of acpi_unload_table() (Bob Moore)
          * Debugger and utilities updates (Erik Schmauss)
          * Fix for unloading tables loaded via configfs (Nikolaus Voss)
    
       - Add support for EFI specific purpose memory to optionally allow
         either application-exclusive or core-kernel-mm managed access to
         differentiated memory (Dan Williams)
    
       - Fix and clean up processing of the HMAT table (Brice Goglin, Qian
         Cai, Tao Xu)
    
       - Update the ACPI EC driver to make it work on systems with
         hardware-reduced ACPI (Daniel Drake)
    
       - Always build in support for the Generic Event Device (GED) to allow
         one kernel binary to work both on systems with full hardware ACPI
         and hardware-reduced ACPI (Arjan van de Ven)
    
       - Fix the table unload mechanism to unregister platform devices
         created when the given table was loaded (Andy Shevchenko)
    
       - Rework the lid blacklist handling in the button driver and add more
         lid quirks to it (Hans de Goede)
    
       - Improve ACPI-based device enumeration for some platforms based on
         Intel BayTrail SoCs (Hans de Goede)
    
       - Add an OpRegion driver for the Cherry Trail Crystal Cove PMIC and
         prevent handlers from being registered for unhandled PMIC OpRegions
         (Hans de Goede)
    
       - Unify ACPI _HID/_UID matching (Andy Shevchenko)
    
       - Clean up documentation and comments (Cao jin, James Pack, Kacper
         Piwi≈Ñski)"
    
    * tag 'acpi-5.5-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (52 commits)
      ACPI: OSI: Shoot duplicate word
      ACPI: HMAT: use %u instead of %d to print u32 values
      ACPI: NUMA: HMAT: fix a section mismatch
      ACPI: HMAT: don't mix pxm and nid when setting memory target processor_pxm
      ACPI: NUMA: HMAT: Register "soft reserved" memory as an "hmem" device
      ACPI: NUMA: HMAT: Register HMAT at device_initcall level
      device-dax: Add a driver for "hmem" devices
      dax: Fix alloc_dax_region() compile warning
      lib: Uplevel the pmem "region" ida to a global allocator
      x86/efi: Add efi_fake_mem support for EFI_MEMORY_SP
      arm/efi: EFI soft reservation to memblock
      x86/efi: EFI soft reservation to E820 enumeration
      efi: Common enable/disable infrastructure for EFI soft reservation
      x86/efi: Push EFI_MEMMAP check into leaf routines
      efi: Enumerate EFI_MEMORY_SP
      ACPI: NUMA: Establish a new drivers/acpi/numa/ directory
      ACPICA: Update version to 20191018
      ACPICA: debugger: remove leading whitespaces when converting a string to a buffer
      ACPICA: acpiexec: initialize all simple types and field units from user input
      ACPICA: debugger: add field unit support for acpi_db_get_next_token
      ...

commit 1d87200446f1d10dfe9672ca8edb027a82612f8c
Merge: 5c4a1c090d86 f01ec4fca820
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 26 10:42:40 2019 -0800

    Merge branch 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 asm updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - Cross-arch changes to move the linker sections for NOTES and
         EXCEPTION_TABLE into the RO_DATA area, where they belong on most
         architectures. (Kees Cook)
    
       - Switch the x86 linker fill byte from x90 (NOP) to 0xcc (INT3), to
         trap jumps into the middle of those padding areas instead of
         sliding execution. (Kees Cook)
    
       - A thorough cleanup of symbol definitions within x86 assembler code.
         The rather randomly named macros got streamlined around a
         (hopefully) straightforward naming scheme:
    
            SYM_START(name, linkage, align...)
            SYM_END(name, sym_type)
    
            SYM_FUNC_START(name)
            SYM_FUNC_END(name)
    
            SYM_CODE_START(name)
            SYM_CODE_END(name)
    
            SYM_DATA_START(name)
            SYM_DATA_END(name)
    
         etc - with about three times of these basic primitives with some
         label, local symbol or attribute variant, expressed via postfixes.
    
         No change in functionality intended. (Jiri Slaby)
    
       - Misc other changes, cleanups and smaller fixes"
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (67 commits)
      x86/entry/64: Remove pointless jump in paranoid_exit
      x86/entry/32: Remove unused resume_userspace label
      x86/build/vdso: Remove meaningless CFLAGS_REMOVE_*.o
      m68k: Convert missed RODATA to RO_DATA
      x86/vmlinux: Use INT3 instead of NOP for linker fill bytes
      x86/mm: Report actual image regions in /proc/iomem
      x86/mm: Report which part of kernel image is freed
      x86/mm: Remove redundant address-of operators on addresses
      xtensa: Move EXCEPTION_TABLE to RO_DATA segment
      powerpc: Move EXCEPTION_TABLE to RO_DATA segment
      parisc: Move EXCEPTION_TABLE to RO_DATA segment
      microblaze: Move EXCEPTION_TABLE to RO_DATA segment
      ia64: Move EXCEPTION_TABLE to RO_DATA segment
      h8300: Move EXCEPTION_TABLE to RO_DATA segment
      c6x: Move EXCEPTION_TABLE to RO_DATA segment
      arm64: Move EXCEPTION_TABLE to RO_DATA segment
      alpha: Move EXCEPTION_TABLE to RO_DATA segment
      x86/vmlinux: Move EXCEPTION_TABLE to RO_DATA segment
      x86/vmlinux: Actually use _etext for the end of the text segment
      vmlinux.lds.h: Allow EXCEPTION_TABLE to live in RO_DATA
      ...

commit 85fbf15bc9ac458f014fe70b38fa5773ee6aca9d
Merge: fd2615908dfd b3c72fc9a78e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 26 08:40:20 2019 -0800

    Merge branch 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 boot updates from Ingo Molnar:
     "The main changes were:
    
       - Extend the boot protocol to allow future extensions without hitting
         the setup_header size limit.
    
       - Add quirk to devicetree systems to disable the RTC unless it's
         listed as a supported device.
    
       - Fix ld.lld linker pedantry"
    
    * 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/boot: Introduce setup_indirect
      x86/boot: Introduce kernel_info.setup_type_max
      x86/boot: Introduce kernel_info
      x86/init: Allow DT configured systems to disable RTC at boot time
      x86/realmode: Explicitly set entry point via ENTRY in linker script

commit 11a98f37a5c11fd3cec9c7a566dfa902bceb5bde
Author: Cao jin <caoj.fnst@cn.fujitsu.com>
Date:   Mon Nov 18 15:00:12 2019 +0800

    x86: Fix typos in comments
    
    BIOSen -> BIOSes; paing -> paging. Append to 640 its proper unit "Kb".
    encomapssing -> encompassing.
    
     [ bp: Merge into a single patch, fix one more typo, massage. ]
    
    Signed-off-by: Cao jin <caoj.fnst@cn.fujitsu.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Robert Richter <rrichter@marvell.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Lendacky <Thomas.Lendacky@amd.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20191118070012.27850-1-caoj.fnst@cn.fujitsu.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 77ea96b794bd..35b3f3a976dc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -459,7 +459,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
  * due to mapping restrictions.
  *
  * On 64bit, kdump kernel need be restricted to be under 64TB, which is
- * the upper limit of system RAM in 4-level paing mode. Since the kdump
+ * the upper limit of system RAM in 4-level paging mode. Since the kdump
  * jumping could be from 5-level to 4-level, the jumping will fail if
  * kernel is put above 64TB, and there's no way to detect the paging mode
  * of the kernel which will be loaded for dumping during the 1st kernel
@@ -743,8 +743,8 @@ static void __init trim_bios_range(void)
 	e820__range_update(0, PAGE_SIZE, E820_TYPE_RAM, E820_TYPE_RESERVED);
 
 	/*
-	 * special case: Some BIOSen report the PC BIOS
-	 * area (640->1Mb) as ram even though it is not.
+	 * special case: Some BIOSes report the PC BIOS
+	 * area (640Kb -> 1Mb) as RAM even though it is not.
 	 * take them out.
 	 */
 	e820__range_remove(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_TYPE_RAM, 1);

commit b3c72fc9a78e74161f9d05ef7191706060628f8c
Author: Daniel Kiper <daniel.kiper@oracle.com>
Date:   Tue Nov 12 14:46:40 2019 +0100

    x86/boot: Introduce setup_indirect
    
    The setup_data is a bit awkward to use for extremely large data objects,
    both because the setup_data header has to be adjacent to the data object
    and because it has a 32-bit length field. However, it is important that
    intermediate stages of the boot process have a way to identify which
    chunks of memory are occupied by kernel data. Thus introduce an uniform
    way to specify such indirect data as setup_indirect struct and
    SETUP_INDIRECT type.
    
    And finally bump setup_header version in arch/x86/boot/header.S.
    
    Suggested-by: H. Peter Anvin (Intel) <hpa@zytor.com>
    Signed-off-by: Daniel Kiper <daniel.kiper@oracle.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ross Philipson <ross.philipson@oracle.com>
    Reviewed-by: H. Peter Anvin (Intel) <hpa@zytor.com>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: ard.biesheuvel@linaro.org
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: dave.hansen@linux.intel.com
    Cc: eric.snowberg@oracle.com
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: kanth.ghatraju@oracle.com
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi <linux-efi@vger.kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: rdunlap@infradead.org
    Cc: ross.philipson@oracle.com
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Cc: xen-devel@lists.xenproject.org
    Link: https://lkml.kernel.org/r/20191112134640.16035-4-daniel.kiper@oracle.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 77ea96b794bd..8f48bb8f2ceb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -438,6 +438,12 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));
 		memblock_reserve(pa_data, sizeof(*data) + data->len);
+
+		if (data->type == SETUP_INDIRECT &&
+		    ((struct setup_indirect *)data->data)->type != SETUP_INDIRECT)
+			memblock_reserve(((struct setup_indirect *)data->data)->addr,
+					 ((struct setup_indirect *)data->data)->len);
+
 		pa_data = data->next;
 		early_memunmap(data, sizeof(*data));
 	}

commit 6950e31b35fdf4588cbbdec1813091bb02cf8871
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Nov 6 17:43:05 2019 -0800

    x86/efi: Push EFI_MEMMAP check into leaf routines
    
    In preparation for adding another EFI_MEMMAP dependent call that needs
    to occur before e820__memblock_setup() fixup the existing efi calls to
    check for EFI_MEMMAP internally. This ends up being cleaner than the
    alternative of checking EFI_MEMMAP multiple times in setup_arch().
    
    Reviewed-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 77ea96b794bd..1c4b866bc184 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1122,17 +1122,15 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_bios_regions();
 
-	if (efi_enabled(EFI_MEMMAP)) {
-		efi_fake_memmap();
-		efi_find_mirror();
-		efi_esrt_init();
+	efi_fake_memmap();
+	efi_find_mirror();
+	efi_esrt_init();
 
-		/*
-		 * The EFI specification says that boot service code won't be
-		 * called after ExitBootServices(). This is, in fact, a lie.
-		 */
-		efi_reserve_boot_services();
-	}
+	/*
+	 * The EFI specification says that boot service code won't be
+	 * called after ExitBootServices(). This is, in fact, a lie.
+	 */
+	efi_reserve_boot_services();
 
 	/* preallocate 4k for mptable mpc */
 	e820__memblock_alloc_reserved_mpc_new();

commit a329975491aafcb1fb6e2fad0de22cae5c16154f
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Oct 29 14:13:50 2019 -0700

    x86/mm: Report actual image regions in /proc/iomem
    
    The resource reservations in /proc/iomem made for the kernel image did
    not reflect the gaps between text, rodata, and data. Add the "rodata"
    resource and update the start/end calculations to match the respective
    calls to free_kernel_image_pages().
    
    Before (booted with "nokaslr" for easier comparison):
    
    00100000-bffd9fff : System RAM
      01000000-01e011d0 : Kernel code
      01e011d1-025619bf : Kernel data
      02a95000-035fffff : Kernel bss
    
    After:
    
    00100000-bffd9fff : System RAM
      01000000-01e011d0 : Kernel code
      02000000-023d4fff : Kernel rodata
      02400000-025619ff : Kernel data
      02a95000-035fffff : Kernel bss
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: linux-alpha@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-s390@vger.kernel.org
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Rick Edgecombe <rick.p.edgecombe@intel.com>
    Cc: Robert Richter <rrichter@marvell.com>
    Cc: Segher Boessenkool <segher@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Lendacky <Thomas.Lendacky@amd.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: x86-ml <x86@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: https://lkml.kernel.org/r/20191029211351.13243-29-keescook@chromium.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 77ea96b794bd..591e885a852e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -143,6 +143,13 @@ struct boot_params boot_params;
 /*
  * Machine setup..
  */
+static struct resource rodata_resource = {
+	.name	= "Kernel rodata",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
+};
+
 static struct resource data_resource = {
 	.name	= "Kernel data",
 	.start	= 0,
@@ -951,7 +958,9 @@ void __init setup_arch(char **cmdline_p)
 
 	code_resource.start = __pa_symbol(_text);
 	code_resource.end = __pa_symbol(_etext)-1;
-	data_resource.start = __pa_symbol(_etext);
+	rodata_resource.start = __pa_symbol(__start_rodata);
+	rodata_resource.end = __pa_symbol(__end_rodata)-1;
+	data_resource.start = __pa_symbol(_sdata);
 	data_resource.end = __pa_symbol(_edata)-1;
 	bss_resource.start = __pa_symbol(__bss_start);
 	bss_resource.end = __pa_symbol(__bss_stop)-1;
@@ -1040,6 +1049,7 @@ void __init setup_arch(char **cmdline_p)
 
 	/* after parse_early_param, so could debug it */
 	insert_resource(&iomem_resource, &code_resource);
+	insert_resource(&iomem_resource, &rodata_resource);
 	insert_resource(&iomem_resource, &data_resource);
 	insert_resource(&iomem_resource, &bss_resource);
 

commit 392e879a445008e8e96b872dabaaf5b1eca58729
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Wed Jun 19 17:19:55 2019 +0300

    dma-mapping: fix filename references
    
    After commit cf65a0f6f6ff ("dma-mapping: move all DMA mapping code to
    kernel/dma") some of the files are referring to outdated information,
    i.e. old file names of DMA mapping sources. Fix it here.
    
    Note, the lines with "Glue code for..." have been removed completely.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bbe35bf879f5..77ea96b794bd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -486,7 +486,7 @@ static int __init reserve_crashkernel_low(void)
 	ret = parse_crashkernel_low(boot_command_line, total_low_mem, &low_size, &base);
 	if (ret) {
 		/*
-		 * two parts from lib/swiotlb.c:
+		 * two parts from kernel/dma/swiotlb.c:
 		 * -swiotlb size: user-specified with swiotlb= or default.
 		 *
 		 * -swiotlb overflow buffer: now hardcoded to 32k. We round it

commit 565eb5f8c5d379b6a6a3134c76b2fcfecdd007d3
Merge: b7d5c9239855 4eb5fec31e61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 9 11:52:34 2019 -0700

    Merge branch 'x86-kdump-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x865 kdump updates from Thomas Gleixner:
     "Yet more kexec/kdump updates:
    
       - Properly support kexec when AMD's memory encryption (SME) is
         enabled
    
       - Pass reserved e820 ranges to the kexec kernel so both PCI and SME
         can work"
    
    * 'x86-kdump-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      fs/proc/vmcore: Enable dumping of encrypted memory when SEV was active
      x86/kexec: Set the C-bit in the identity map page table when SEV is active
      x86/kexec: Do not map kexec area as decrypted when SEV is active
      x86/crash: Add e820 reserved ranges to kdump kernel's e820 table
      x86/mm: Rework ioremap resource mapping determination
      x86/e820, ioport: Add a new I/O resource descriptor IORES_DESC_RESERVED
      x86/mm: Create a workarea in the kernel for SME early encryption
      x86/mm: Identify the end of the kernel area to be reserved

commit 8ff80fbe7e9870078b1cc3c2cdd8f3f223b333a9
Author: Baoquan He <bhe@redhat.com>
Date:   Fri May 24 15:38:10 2019 +0800

    x86/kdump/64: Restrict kdump kernel reservation to <64TB
    
    Restrict kdump to only reserve crashkernel below 64TB.
    
    The reaons is that the kdump may jump from a 5-level paging mode to a
    4-level paging mode kernel. If a 4-level paging mode kdump kernel is put
    above 64TB, then the kdump kernel cannot start.
    
    The 1st kernel reserves the kdump kernel region during bootup. At that
    point it is not known whether the kdump kernel has 5-level or 4-level
    paging support.
    
    To support both restrict the kdump kernel reservation to the lower 64TB
    address space to ensure that a 4-level paging mode kdump kernel can be
    loaded and successfully started.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Dave Young <dyoung@redhat.com>
    Cc: bp@alien8.de
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20190524073810.24298-4-bhe@redhat.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 08a5f4a131f5..dcbdf54fb5c1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -453,15 +453,24 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 #define CRASH_ALIGN		SZ_16M
 
 /*
- * Keep the crash kernel below this limit.  On 32 bits earlier kernels
- * would limit the kernel to the low 512 MiB due to mapping restrictions.
+ * Keep the crash kernel below this limit.
+ *
+ * On 32 bits earlier kernels would limit the kernel to the low 512 MiB
+ * due to mapping restrictions.
+ *
+ * On 64bit, kdump kernel need be restricted to be under 64TB, which is
+ * the upper limit of system RAM in 4-level paing mode. Since the kdump
+ * jumping could be from 5-level to 4-level, the jumping will fail if
+ * kernel is put above 64TB, and there's no way to detect the paging mode
+ * of the kernel which will be loaded for dumping during the 1st kernel
+ * bootup.
  */
 #ifdef CONFIG_X86_32
 # define CRASH_ADDR_LOW_MAX	SZ_512M
 # define CRASH_ADDR_HIGH_MAX	SZ_512M
 #else
 # define CRASH_ADDR_LOW_MAX	SZ_4G
-# define CRASH_ADDR_HIGH_MAX	MAXMEM
+# define CRASH_ADDR_HIGH_MAX	SZ_64T
 #endif
 
 static int __init reserve_crashkernel_low(void)

commit c603a309cc75f3dd018ddb20ee44c05047918cbf
Author: Thomas Lendacky <Thomas.Lendacky@amd.com>
Date:   Wed Jun 19 18:40:57 2019 +0000

    x86/mm: Identify the end of the kernel area to be reserved
    
    The memory occupied by the kernel is reserved using memblock_reserve()
    in setup_arch(). Currently, the area is from symbols _text to __bss_stop.
    Everything after __bss_stop must be specifically reserved otherwise it
    is discarded. This is not clearly documented.
    
    Add a new symbol, __end_of_kernel_reserve, that more readily identifies
    what is reserved, along with comments that indicate what is reserved,
    what is discarded and what needs to be done to prevent a section from
    being discarded.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Baoquan He <bhe@redhat.com>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Tested-by: Lianbo Jiang <lijiang@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Pavel Tatashin <pasha.tatashin@oracle.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Robert Richter <rrichter@marvell.com>
    Cc: Sami Tolvanen <samitolvanen@google.com>
    Cc: Sinan Kaya <okaya@codeaurora.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "x86@kernel.org" <x86@kernel.org>
    Link: https://lkml.kernel.org/r/7db7da45b435f8477f25e66f292631ff766a844c.1560969363.git.thomas.lendacky@amd.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 08a5f4a131f5..dac60ad37e5e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -827,8 +827,14 @@ dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 
 void __init setup_arch(char **cmdline_p)
 {
+	/*
+	 * Reserve the memory occupied by the kernel between _text and
+	 * __end_of_kernel_reserve symbols. Any kernel sections after the
+	 * __end_of_kernel_reserve symbol must be explicitly reserved with a
+	 * separate memblock_reserve() or they will be discarded.
+	 */
 	memblock_reserve(__pa_symbol(_text),
-			 (unsigned long)__bss_stop - (unsigned long)_text);
+			 (unsigned long)__end_of_kernel_reserve - (unsigned long)_text);
 
 	/*
 	 * Make sure page 0 is always reserved because on systems with

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 905dae880563..08a5f4a131f5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  Copyright (C) 1995  Linus Torvalds
  *

commit e913c4a4c21cd83317fafe63bfdc9d34d2910114
Merge: 8f147727030b b9ac3849af41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 6 16:11:45 2019 -0700

    Merge branch 'x86-kdump-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 kdump update from Ingo Molnar:
     "This includes two changes:
    
       - Raise the crash kernel reservation limit from from ~896MB to ~4GB.
    
         Only very old (and already known-broken) kexec-tools is supposed to
         be affected by this negatively.
    
       - Allow higher than 4GB crash kernel allocations when low allocations
         fail"
    
    * 'x86-kdump-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/kdump: Fall back to reserve high crashkernel memory
      x86/kdump: Have crashkernel=X reserve under 4G by default

commit b9ac3849af412fd3887d7652bdbabf29d2aecc16
Author: Dave Young <dyoung@redhat.com>
Date:   Mon Apr 22 11:19:05 2019 +0800

    x86/kdump: Fall back to reserve high crashkernel memory
    
    crashkernel=xM tries to reserve memory for the crash kernel under 4G,
    which is enough, usually. But this could fail sometimes, for example
    when one tries to reserve a big chunk like 2G, for example.
    
    So let the crashkernel=xM just fall back to use high memory in case it
    fails to find a suitable low range. Do not set the ,high as default
    because it allocates extra low memory for DMA buffers and swiotlb, and
    this is not always necessary for all machines.
    
    Typically, crashkernel=128M usually works with low reservation under 4G,
    so keep <4G as default.
    
     [ bp: Massage. ]
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Baoquan He <bhe@redhat.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: linux-doc@vger.kernel.org
    Cc: "Paul E. McKenney" <paulmck@linux.ibm.com>
    Cc: Petr Tesarik <ptesarik@suse.cz>
    Cc: piliu@redhat.com
    Cc: Ram Pai <linuxram@us.ibm.com>
    Cc: Sinan Kaya <okaya@codeaurora.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thymo van Beers <thymovanbeers@gmail.com>
    Cc: vgoyal@redhat.com
    Cc: x86-ml <x86@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Zhimin Gu <kookoo.gu@intel.com>
    Link: https://lkml.kernel.org/r/20190422031905.GA8387@dhcp-128-65.nay.redhat.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index daf7c5650c18..c15f362a2516 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -541,21 +541,27 @@ static void __init reserve_crashkernel(void)
 	}
 
 	/* 0 means: find the address automatically */
-	if (crash_base <= 0) {
+	if (!crash_base) {
 		/*
 		 * Set CRASH_ADDR_LOW_MAX upper bound for crash memory,
-		 * as old kexec-tools loads bzImage below that, unless
-		 * "crashkernel=size[KMG],high" is specified.
+		 * crashkernel=x,high reserves memory over 4G, also allocates
+		 * 256M extra low memory for DMA buffers and swiotlb.
+		 * But the extra memory is not required for all machines.
+		 * So try low memory first and fall back to high memory
+		 * unless "crashkernel=size[KMG],high" is specified.
 		 */
-		crash_base = memblock_find_in_range(CRASH_ALIGN,
-						    high ? CRASH_ADDR_HIGH_MAX
-							 : CRASH_ADDR_LOW_MAX,
-						    crash_size, CRASH_ALIGN);
+		if (!high)
+			crash_base = memblock_find_in_range(CRASH_ALIGN,
+						CRASH_ADDR_LOW_MAX,
+						crash_size, CRASH_ALIGN);
+		if (!crash_base)
+			crash_base = memblock_find_in_range(CRASH_ALIGN,
+						CRASH_ADDR_HIGH_MAX,
+						crash_size, CRASH_ALIGN);
 		if (!crash_base) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
 		}
-
 	} else {
 		unsigned long long start;
 

commit 9ca5c8e632ce8f144ec6d00da2dc5e16b41d593c
Author: Dave Young <dyoung@redhat.com>
Date:   Sun Apr 21 11:50:59 2019 +0800

    x86/kdump: Have crashkernel=X reserve under 4G by default
    
    The kdump crashkernel low reservation is limited to under 896M even for
    X86_64. This obscure and miserable limitation exists for compatibility
    with old kexec-tools but the reason is not documented anywhere.
    
    Some more tests/investigations about the background:
    
    a) Previously, old kexec-tools could only load purgatory to memory under
       2G. Eric removed that limitation in 2012 in kexec-tools:
    
         b4f9f8599679 ("kexec x86_64: Make purgatory relocatable anywhere
                       in the 64bit address space.")
    
    b) Back in 2013 Yinghai removed all the limitations in new kexec-tools,
       bzImage64 can be loaded anywhere:
    
         82c3dd2280d2 ("kexec, x86_64: Load bzImage64 above 4G")
    
    c) Test results with old kexec-tools with old and latest kernels:
    
      1. Old kexec-tools can not build with modern toolchain anymore,
         I built it in a RHEL6 vm.
    
      2. 2.0.0 kexec-tools does not work with the latest kernel even with
         memory under 896M and gives an error:
    
         "ELF core (kcore) parse failed"
    
         For that it needs below kexec-tools fix:
    
           ed15ba1b9977 ("build_mem_phdrs(): check if p_paddr is invalid")
    
      3. Even with patched kexec-tools which fixes 2),  it still needs some
         other fixes to work correctly for KASLR-enabled kernels.
    
    So the situation is:
    
    * Old kexec-tools is already broken with latest kernels.
    
    * We can not keep these limitations forever just for compatibility with very
      old kexec-tools.
    
    * If one must use old tools then he/she can choose crashkernel=X@Y.
    
    * People have reported bugs where crashkernel=384M failed because KASLR
      makes the 0-896M space sparse.
    
    * Crashkernel can reserve in low or high area, it is natural to understand
      low as memory under 4G.
    
    Hence drop the 896M limitation and change crashkernel low reservation to
    reserve under 4G by default.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Baoquan He <bhe@redhat.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Petr Tesarik <ptesarik@suse.cz>
    Cc: piliu@redhat.com
    Cc: Ram Pai <linuxram@us.ibm.com>
    Cc: Sinan Kaya <okaya@codeaurora.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: vgoyal@redhat.com
    Cc: x86-ml <x86@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Zhimin Gu <kookoo.gu@intel.com>
    Link: https://lkml.kernel.org/r/20190421035058.943630505@redhat.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3d872a527cd9..daf7c5650c18 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -71,6 +71,7 @@
 #include <linux/tboot.h>
 #include <linux/jiffies.h>
 #include <linux/mem_encrypt.h>
+#include <linux/sizes.h>
 
 #include <linux/usb/xhci-dbgp.h>
 #include <video/edid.h>
@@ -448,18 +449,17 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 #ifdef CONFIG_KEXEC_CORE
 
 /* 16M alignment for crash kernel regions */
-#define CRASH_ALIGN		(16 << 20)
+#define CRASH_ALIGN		SZ_16M
 
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels
  * would limit the kernel to the low 512 MiB due to mapping restrictions.
- * On 64bit, old kexec-tools need to under 896MiB.
  */
 #ifdef CONFIG_X86_32
-# define CRASH_ADDR_LOW_MAX	(512 << 20)
-# define CRASH_ADDR_HIGH_MAX	(512 << 20)
+# define CRASH_ADDR_LOW_MAX	SZ_512M
+# define CRASH_ADDR_HIGH_MAX	SZ_512M
 #else
-# define CRASH_ADDR_LOW_MAX	(896UL << 20)
+# define CRASH_ADDR_LOW_MAX	SZ_4G
 # define CRASH_ADDR_HIGH_MAX	MAXMEM
 #endif
 

commit 0fca08122eaf5c956a2cbe12775245d747f8b1ac
Author: Robert Richter <rrichter@marvell.com>
Date:   Thu Mar 28 20:34:28 2019 +0100

    efi: Unify DMI setup code over the arm/arm64, ia64 and x86 architectures
    
    All architectures (arm/arm64, ia64 and x86) do the same here, so unify
    the code.
    
    Note: We do not need to call dump_stack_set_arch_desc() in case of
    !dmi_available. Both strings, dmi_ids_string and dump_stack_arch_
    desc_str are initialized zero and thus nothing would change.
    
    Signed-off-by: Robert Richter <rrichter@marvell.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Jean Delvare <jdelvare@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20190328193429.21373-5-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3d872a527cd9..3773905cd2c1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1005,13 +1005,11 @@ void __init setup_arch(char **cmdline_p)
 	if (efi_enabled(EFI_BOOT))
 		efi_init();
 
-	dmi_scan_machine();
-	dmi_memdev_walk();
-	dmi_set_dump_stack_arch_desc();
+	dmi_setup();
 
 	/*
 	 * VMware detection requires dmi to be available, so this
-	 * needs to be done after dmi_scan_machine(), for the boot CPU.
+	 * needs to be done after dmi_setup(), for the boot CPU.
 	 */
 	init_hypervisor_platform();
 

commit 505b050fdf42097883b2d37b8e796e1f11dbef50
Merge: 9b286efeb5eb 718c43038f28
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 5 13:25:58 2019 -0800

    Merge branch 'mount.part1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs mount API prep from Al Viro:
     "Mount API prereqs.
    
      Mostly that's LSM mount options cleanups. There are several minor
      fixes in there, but nothing earth-shattering (leaks on failure exits,
      mostly)"
    
    * 'mount.part1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (27 commits)
      mount_fs: suppress MAC on MS_SUBMOUNT as well as MS_KERNMOUNT
      smack: rewrite smack_sb_eat_lsm_opts()
      smack: get rid of match_token()
      smack: take the guts of smack_parse_opts_str() into a new helper
      LSM: new method: ->sb_add_mnt_opt()
      selinux: rewrite selinux_sb_eat_lsm_opts()
      selinux: regularize Opt_... names a bit
      selinux: switch away from match_token()
      selinux: new helper - selinux_add_opt()
      LSM: bury struct security_mnt_opts
      smack: switch to private smack_mnt_opts
      selinux: switch to private struct selinux_mnt_opts
      LSM: hide struct security_mnt_opts from any generic code
      selinux: kill selinux_sb_get_mnt_opts()
      LSM: turn sb_eat_lsm_opts() into a method
      nfs_remount(): don't leak, don't ignore LSM options quietly
      btrfs: sanitize security_mnt_opts use
      selinux; don't open-code a loop in sb_finish_set_opts()
      LSM: split ->sb_set_mnt_opts() out of ->sb_kern_mount()
      new helper: security_sb_eat_lsm_opts()
      ...

commit e262e32d6bde0f77fb0c95d977482fc872c51996
Author: David Howells <dhowells@redhat.com>
Date:   Thu Nov 1 23:07:23 2018 +0000

    vfs: Suppress MS_* flag defs within the kernel unless explicitly enabled
    
    Only the mount namespace code that implements mount(2) should be using the
    MS_* flags.  Suppress them inside the kernel unless uapi/linux/mount.h is
    included.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Reviewed-by: David Howells <dhowells@redhat.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b74e7bfed6ab..25a9802fffec 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -50,6 +50,7 @@
 #include <linux/kvm_para.h>
 #include <linux/dma-contiguous.h>
 #include <xen/xen.h>
+#include <uapi/linux/mount.h>
 
 #include <linux/errno.h>
 #include <linux/kernel.h>

commit 3841840449817ba6cf3e636008bc4e1061a03388
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Nov 20 08:25:28 2018 +0100

    x86/boot: Mostly revert commit ae7e1238e68f2a ("Add ACPI RSDP address to setup_header")
    
    Peter Anvin pointed out that commit:
    
      ae7e1238e68f2a ("x86/boot: Add ACPI RSDP address to setup_header")
    
    should be reverted as setup_header should only contain items set by the
    legacy BIOS.
    
    So revert said commit. Instead of fully reverting the dependent commit
    of:
    
      e7b66d16fe4172 ("x86/acpi, x86/boot: Take RSDP address for boot params if available")
    
    just remove the setup_header reference in order to replace it by
    a boot_params in a followup patch.
    
    Suggested-by: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: boris.ostrovsky@oracle.com
    Cc: bp@alien8.de
    Cc: daniel.kiper@oracle.com
    Cc: sstabellini@kernel.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/20181120072529.5489-2-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b74e7bfed6ab..d494b9bfe618 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1280,23 +1280,6 @@ void __init setup_arch(char **cmdline_p)
 	unwind_init();
 }
 
-/*
- * From boot protocol 2.14 onwards we expect the bootloader to set the
- * version to "0x8000 | <used version>". In case we find a version >= 2.14
- * without the 0x8000 we assume the boot loader supports 2.13 only and
- * reset the version accordingly. The 0x8000 flag is removed in any case.
- */
-void __init x86_verify_bootdata_version(void)
-{
-	if (boot_params.hdr.version & VERSION_WRITTEN)
-		boot_params.hdr.version &= ~VERSION_WRITTEN;
-	else if (boot_params.hdr.version >= 0x020e)
-		boot_params.hdr.version = 0x020d;
-
-	if (boot_params.hdr.version < 0x020e)
-		boot_params.hdr.acpi_rsdp_addr = 0;
-}
-
 #ifdef CONFIG_X86_32
 
 static struct resource video_ram_resource = {

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7005f89bf3b2..b74e7bfed6ab 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -30,7 +30,6 @@
 #include <linux/sfi.h>
 #include <linux/apm_bios.h>
 #include <linux/initrd.h>
-#include <linux/bootmem.h>
 #include <linux/memblock.h>
 #include <linux/seq_file.h>
 #include <linux/console.h>

commit ac73e08eda885a6723593c45d634b59c63365986
Merge: fec98069fb72 e7b66d16fe41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 23 16:31:33 2018 +0100

    Merge branch 'x86-grub2-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 grub2 updates from Ingo Molnar:
     "This extends the x86 boot protocol to include an address for the RSDP
      table - utilized by Xen currently.
    
      Matching Grub2 patches are pending as well. (Juergen Gross)"
    
    * 'x86-grub2-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/acpi, x86/boot: Take RSDP address for boot params if available
      x86/boot: Add ACPI RSDP address to setup_header
      x86/xen: Fix boot loader version reported for PVH guests

commit ae7e1238e68f2a472a125673ab506d49158c1889
Author: Juergen Gross <jgross@suse.com>
Date:   Wed Oct 10 08:14:55 2018 +0200

    x86/boot: Add ACPI RSDP address to setup_header
    
    Xen PVH guests receive the address of the RSDP table from Xen. In order
    to support booting a Xen PVH guest via Grub2 using the standard x86
    boot entry we need a way for Grub2 to pass the RSDP address to the
    kernel.
    
    For this purpose expand the struct setup_header to hold the physical
    address of the RSDP address. Being zero means it isn't specified and
    has to be located the legacy way (searching through low memory or
    EBDA).
    
    While documenting the new setup_header layout and protocol version
    2.14 add the missing documentation of protocol version 2.13.
    
    There are Grub2 versions in several distros with a downstream patch
    violating the boot protocol by writing past the end of setup_header.
    This requires another update of the boot protocol to enable the kernel
    to distinguish between a specified RSDP address and one filled with
    garbage by such a broken Grub2.
    
    From protocol 2.14 on Grub2 will write the version it is supporting
    (but never a higher value than found to be supported by the kernel)
    ored with 0x8000 to the version field of setup_header. This enables
    the kernel to know up to which field Grub2 has written information
    to. All fields after that are supposed to be clobbered.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: boris.ostrovsky@oracle.com
    Cc: bp@alien8.de
    Cc: corbet@lwn.net
    Cc: linux-doc@vger.kernel.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/20181010061456.22238-3-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4866badb235..8e226b7a1753 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1281,6 +1281,23 @@ void __init setup_arch(char **cmdline_p)
 	unwind_init();
 }
 
+/*
+ * From boot protocol 2.14 onwards we expect the bootloader to set the
+ * version to "0x8000 | <used version>". In case we find a version >= 2.14
+ * without the 0x8000 we assume the boot loader supports 2.13 only and
+ * reset the version accordingly. The 0x8000 flag is removed in any case.
+ */
+void __init x86_verify_bootdata_version(void)
+{
+	if (boot_params.hdr.version & VERSION_WRITTEN)
+		boot_params.hdr.version &= ~VERSION_WRITTEN;
+	else if (boot_params.hdr.version >= 0x020e)
+		boot_params.hdr.version = 0x020d;
+
+	if (boot_params.hdr.version < 0x020e)
+		boot_params.hdr.acpi_rsdp_addr = 0;
+}
+
 #ifdef CONFIG_X86_32
 
 static struct resource video_ram_resource = {

commit cc55f7537db6af371e9c1c6a71161ee40f918824
Author: Zhimin Gu <kookoo.gu@intel.com>
Date:   Fri Sep 21 14:26:24 2018 +0800

    x86, hibernate: Fix nosave_regions setup for hibernation
    
    On 32bit systems, nosave_regions(non RAM areas) located between
    max_low_pfn and max_pfn are not excluded from hibernation snapshot
    currently, which may result in a machine check exception when
    trying to access these unsafe regions during hibernation:
    
    [  612.800453] Disabling lock debugging due to kernel taint
    [  612.805786] mce: [Hardware Error]: CPU 0: Machine Check Exception: 5 Bank 6: fe00000000801136
    [  612.814344] mce: [Hardware Error]: RIP !INEXACT! 60:<00000000d90be566> {swsusp_save+0x436/0x560}
    [  612.823167] mce: [Hardware Error]: TSC 1f5939fe276 ADDR dd000000 MISC 30e0000086
    [  612.830677] mce: [Hardware Error]: PROCESSOR 0:306c3 TIME 1529487426 SOCKET 0 APIC 0 microcode 24
    [  612.839581] mce: [Hardware Error]: Run the above through 'mcelog --ascii'
    [  612.846394] mce: [Hardware Error]: Machine check: Processor context corrupt
    [  612.853380] Kernel panic - not syncing: Fatal machine check
    [  612.858978] Kernel Offset: 0x18000000 from 0xc1000000 (relocation range: 0xc0000000-0xf7ffdfff)
    
    This is because on 32bit systems, pages above max_low_pfn are regarded
    as high memeory, and accessing unsafe pages might cause expected MCE.
    On the problematic 32bit system, there are reserved memory above low
    memory, which triggered the MCE:
    
    e820 memory mapping:
    [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009d7ff] usable
    [    0.000000] BIOS-e820: [mem 0x000000000009d800-0x000000000009ffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000fffff] reserved
    [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000d160cfff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000d160d000-0x00000000d1613fff] ACPI NVS
    [    0.000000] BIOS-e820: [mem 0x00000000d1614000-0x00000000d1a44fff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000d1a45000-0x00000000d1ecffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000d1ed0000-0x00000000d7eeafff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000d7eeb000-0x00000000d7ffffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000d8000000-0x00000000d875ffff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000d8760000-0x00000000d87fffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000d8800000-0x00000000d8fadfff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000d8fae000-0x00000000d8ffffff] ACPI data
    [    0.000000] BIOS-e820: [mem 0x00000000d9000000-0x00000000da71bfff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000da71c000-0x00000000da7fffff] ACPI NVS
    [    0.000000] BIOS-e820: [mem 0x00000000da800000-0x00000000dbb8bfff] usable
    [    0.000000] BIOS-e820: [mem 0x00000000dbb8c000-0x00000000dbffffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000dd000000-0x00000000df1fffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000f8000000-0x00000000fbffffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000fec00000-0x00000000fec00fff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000fed00000-0x00000000fed03fff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000fee00000-0x00000000fee00fff] reserved
    [    0.000000] BIOS-e820: [mem 0x00000000ff000000-0x00000000ffffffff] reserved
    [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000041edfffff] usable
    
    Fix this problem by changing pfn limit from max_low_pfn to max_pfn.
    This fix does not impact 64bit system because on 64bit max_low_pfn
    is the same as max_pfn.
    
    Signed-off-by: Zhimin Gu <kookoo.gu@intel.com>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Chen Yu <yu.c.chen@intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: All applicable <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4866badb235..90ecc108bc8a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1251,7 +1251,7 @@ void __init setup_arch(char **cmdline_p)
 	x86_init.hyper.guest_late_init();
 
 	e820__reserve_resources();
-	e820__register_nosave_regions(max_low_pfn);
+	e820__register_nosave_regions(max_pfn);
 
 	x86_init.resources.reserve_resources();
 

commit 4e31843f681c34f7185e7d169fe627c9d891ce2c
Merge: f91e654474d4 fa687fb9ced4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 16 09:21:54 2018 -0700

    Merge tag 'pci-v4.19-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci
    
    Pull pci updates from Bjorn Helgaas:
    
     - Decode AER errors with names similar to "lspci" (Tyler Baicar)
    
     - Expose AER statistics in sysfs (Rajat Jain)
    
     - Clear AER status bits selectively based on the type of recovery (Oza
       Pawandeep)
    
     - Honor "pcie_ports=native" even if HEST sets FIRMWARE_FIRST (Alexandru
       Gagniuc)
    
     - Don't clear AER status bits if we're using the "Firmware-First"
       strategy where firmware owns the registers (Alexandru Gagniuc)
    
     - Use sysfs_match_string() to simplify ASPM sysfs parsing (Andy
       Shevchenko)
    
     - Remove unnecessary includes of <linux/pci-aspm.h> (Bjorn Helgaas)
    
     - Defer DPC event handling to work queue (Keith Busch)
    
     - Use threaded IRQ for DPC bottom half (Keith Busch)
    
     - Print AER status while handling DPC events (Keith Busch)
    
     - Work around IDT switch ACS Source Validation erratum (James
       Puthukattukaran)
    
     - Emit diagnostics for all cases of PCIe Link downtraining (Links
       operating slower than they're capable of) (Alexandru Gagniuc)
    
     - Skip VFs when configuring Max Payload Size (Myron Stowe)
    
     - Reduce Root Port Max Payload Size if necessary when hot-adding a
       device below it (Myron Stowe)
    
     - Simplify SHPC existence/permission checks (Bjorn Helgaas)
    
     - Remove hotplug sample skeleton driver (Lukas Wunner)
    
     - Convert pciehp to threaded IRQ handling (Lukas Wunner)
    
     - Improve pciehp tolerance of missed events and initially unstable
       links (Lukas Wunner)
    
     - Clear spurious pciehp events on resume (Lukas Wunner)
    
     - Add pciehp runtime PM support, including for Thunderbolt controllers
       (Lukas Wunner)
    
     - Support interrupts from pciehp bridges in D3hot (Lukas Wunner)
    
     - Mark fall-through switch cases before enabling -Wimplicit-fallthrough
       (Gustavo A. R. Silva)
    
     - Move DMA-debug PCI init from arch code to PCI core (Christoph
       Hellwig)
    
     - Fix pci_request_irq() usage of IRQF_ONESHOT when no handler is
       supplied (Heiner Kallweit)
    
     - Unify PCI and DMA direction #defines (Shunyong Yang)
    
     - Add PCI_DEVICE_DATA() macro (Andy Shevchenko)
    
     - Check for VPD completion before checking for timeout (Bert Kenward)
    
     - Limit Netronome NFP5000 config space size to work around erratum
       (Jakub Kicinski)
    
     - Set IRQCHIP_ONESHOT_SAFE for PCI MSI irqchips (Heiner Kallweit)
    
     - Document ACPI description of PCI host bridges (Bjorn Helgaas)
    
     - Add "pci=disable_acs_redir=" parameter to disable ACS redirection for
       peer-to-peer DMA support (we don't have the peer-to-peer support yet;
       this is just one piece) (Logan Gunthorpe)
    
     - Clean up devm_of_pci_get_host_bridge_resources() resource allocation
       (Jan Kiszka)
    
     - Fixup resizable BARs after suspend/resume (Christian K√∂nig)
    
     - Make "pci=earlydump" generic (Sinan Kaya)
    
     - Fix ROM BAR access routines to stay in bounds and check for signature
       correctly (Rex Zhu)
    
     - Add DMA alias quirk for Microsemi Switchtec NTB (Doug Meyer)
    
     - Expand documentation for pci_add_dma_alias() (Logan Gunthorpe)
    
     - To avoid bus errors, enable PASID only if entire path supports
       End-End TLP prefixes (Sinan Kaya)
    
     - Unify slot and bus reset functions and remove hotplug knowledge from
       callers (Sinan Kaya)
    
     - Add Function-Level Reset quirks for Intel and Samsung NVMe devices to
       fix guest reboot issues (Alex Williamson)
    
     - Add function 1 DMA alias quirk for Marvell 88SS9183 PCIe SSD
       Controller (Bjorn Helgaas)
    
     - Remove Xilinx AXI-PCIe host bridge arch dependency (Palmer Dabbelt)
    
     - Remove Aardvark outbound window configuration (Evan Wang)
    
     - Fix Aardvark bridge window sizing issue (Zachary Zhang)
    
     - Convert Aardvark to use pci_host_probe() to reduce code duplication
       (Thomas Petazzoni)
    
     - Correct the Cadence cdns_pcie_writel() signature (Alan Douglas)
    
     - Add Cadence support for optional generic PHYs (Alan Douglas)
    
     - Add Cadence power management ops (Alan Douglas)
    
     - Remove redundant variable from Cadence driver (Colin Ian King)
    
     - Add Kirin MSI support (Xiaowei Song)
    
     - Drop unnecessary root_bus_nr setting from exynos, imx6, keystone,
       armada8k, artpec6, designware-plat, histb, qcom, spear13xx (Shawn
       Guo)
    
     - Move link notification settings from DesignWare core to individual
       drivers (Gustavo Pimentel)
    
     - Add endpoint library MSI-X interfaces (Gustavo Pimentel)
    
     - Correct signature of endpoint library IRQ interfaces (Gustavo
       Pimentel)
    
     - Add DesignWare endpoint library MSI-X callbacks (Gustavo Pimentel)
    
     - Add endpoint library MSI-X test support (Gustavo Pimentel)
    
     - Remove unnecessary GFP_ATOMIC from Hyper-V "new child" allocation
       (Jia-Ju Bai)
    
     - Add more devices to Broadcom PAXC quirk (Ray Jui)
    
     - Work around corrupted Broadcom PAXC config space to enable SMMU and
       GICv3 ITS (Ray Jui)
    
     - Disable MSI parsing to work around broken Broadcom PAXC logic in some
       devices (Ray Jui)
    
     - Hide unconfigured functions to work around a Broadcom PAXC defect
       (Ray Jui)
    
     - Lower iproc log level to reduce console output during boot (Ray Jui)
    
     - Fix mobiveil iomem/phys_addr_t type usage (Lorenzo Pieralisi)
    
     - Fix mobiveil missing include file (Lorenzo Pieralisi)
    
     - Add mobiveil Kconfig/Makefile support (Lorenzo Pieralisi)
    
     - Fix mvebu I/O space remapping issues (Thomas Petazzoni)
    
     - Use generic pci_host_bridge in mvebu instead of ARM-specific API
       (Thomas Petazzoni)
    
     - Whitelist VMD devices with fast interrupt handlers to avoid sharing
       vectors with slow handlers (Keith Busch)
    
    * tag 'pci-v4.19-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci: (153 commits)
      PCI/AER: Don't clear AER bits if error handling is Firmware-First
      PCI: Limit config space size for Netronome NFP5000
      PCI/MSI: Set IRQCHIP_ONESHOT_SAFE for PCI-MSI irqchips
      PCI/VPD: Check for VPD access completion before checking for timeout
      PCI: Add PCI_DEVICE_DATA() macro to fully describe device ID entry
      PCI: Match Root Port's MPS to endpoint's MPSS as necessary
      PCI: Skip MPS logic for Virtual Functions (VFs)
      PCI: Add function 1 DMA alias quirk for Marvell 88SS9183
      PCI: Check for PCIe Link downtraining
      PCI: Add ACS Redirect disable quirk for Intel Sunrise Point
      PCI: Add device-specific ACS Redirect disable infrastructure
      PCI: Convert device-specific ACS quirks from NULL termination to ARRAY_SIZE
      PCI: Add "pci=disable_acs_redir=" parameter for peer-to-peer support
      PCI: Allow specifying devices using a base bus and path of devfns
      PCI: Make specifying PCI devices in kernel parameters reusable
      PCI: Hide ACS quirk declarations inside PCI core
      PCI: Delay after FLR of Intel DC P3700 NVMe
      PCI: Disable Samsung SM961/PM961 NVMe before FLR
      PCI: Export pcie_has_flr()
      PCI: mvebu: Drop bogus comment above mvebu_pcie_map_registers()
      ...

commit 958f338e96f874a0d29442396d6adf9c1e17aa2d
Merge: 781fca5b1046 07d981ad4cf1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 14 09:46:06 2018 -0700

    Merge branch 'l1tf-final' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Merge L1 Terminal Fault fixes from Thomas Gleixner:
     "L1TF, aka L1 Terminal Fault, is yet another speculative hardware
      engineering trainwreck. It's a hardware vulnerability which allows
      unprivileged speculative access to data which is available in the
      Level 1 Data Cache when the page table entry controlling the virtual
      address, which is used for the access, has the Present bit cleared or
      other reserved bits set.
    
      If an instruction accesses a virtual address for which the relevant
      page table entry (PTE) has the Present bit cleared or other reserved
      bits set, then speculative execution ignores the invalid PTE and loads
      the referenced data if it is present in the Level 1 Data Cache, as if
      the page referenced by the address bits in the PTE was still present
      and accessible.
    
      While this is a purely speculative mechanism and the instruction will
      raise a page fault when it is retired eventually, the pure act of
      loading the data and making it available to other speculative
      instructions opens up the opportunity for side channel attacks to
      unprivileged malicious code, similar to the Meltdown attack.
    
      While Meltdown breaks the user space to kernel space protection, L1TF
      allows to attack any physical memory address in the system and the
      attack works across all protection domains. It allows an attack of SGX
      and also works from inside virtual machines because the speculation
      bypasses the extended page table (EPT) protection mechanism.
    
      The assoicated CVEs are: CVE-2018-3615, CVE-2018-3620, CVE-2018-3646
    
      The mitigations provided by this pull request include:
    
       - Host side protection by inverting the upper address bits of a non
         present page table entry so the entry points to uncacheable memory.
    
       - Hypervisor protection by flushing L1 Data Cache on VMENTER.
    
       - SMT (HyperThreading) control knobs, which allow to 'turn off' SMT
         by offlining the sibling CPU threads. The knobs are available on
         the kernel command line and at runtime via sysfs
    
       - Control knobs for the hypervisor mitigation, related to L1D flush
         and SMT control. The knobs are available on the kernel command line
         and at runtime via sysfs
    
       - Extensive documentation about L1TF including various degrees of
         mitigations.
    
      Thanks to all people who have contributed to this in various ways -
      patches, review, testing, backporting - and the fruitful, sometimes
      heated, but at the end constructive discussions.
    
      There is work in progress to provide other forms of mitigations, which
      might be less horrible performance wise for a particular kind of
      workloads, but this is not yet ready for consumption due to their
      complexity and limitations"
    
    * 'l1tf-final' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (75 commits)
      x86/microcode: Allow late microcode loading with SMT disabled
      tools headers: Synchronise x86 cpufeatures.h for L1TF additions
      x86/mm/kmmio: Make the tracer robust against L1TF
      x86/mm/pat: Make set_memory_np() L1TF safe
      x86/speculation/l1tf: Make pmd/pud_mknotpresent() invert
      x86/speculation/l1tf: Invert all not present mappings
      cpu/hotplug: Fix SMT supported evaluation
      KVM: VMX: Tell the nested hypervisor to skip L1D flush on vmentry
      x86/speculation: Use ARCH_CAPABILITIES to skip L1D flush on vmentry
      x86/speculation: Simplify sysfs report of VMX L1TF vulnerability
      Documentation/l1tf: Remove Yonah processors from not vulnerable list
      x86/KVM/VMX: Don't set l1tf_flush_l1d from vmx_handle_external_intr()
      x86/irq: Let interrupt handlers set kvm_cpu_l1tf_flush_l1d
      x86: Don't include linux/irq.h from asm/hardirq.h
      x86/KVM/VMX: Introduce per-host-cpu analogue of l1tf_flush_l1d
      x86/irq: Demote irq_cpustat_t::__softirq_pending to u16
      x86/KVM/VMX: Move the l1tf_flush_l1d test to vmx_l1d_flush()
      x86/KVM/VMX: Replace 'vmx_l1d_flush_always' with 'vmx_l1d_flush_cond'
      x86/KVM/VMX: Don't set l1tf_flush_l1d to true from vmx_l1d_flush()
      cpu/hotplug: detect SMT disabled by BIOS
      ...

commit cf7a63ef4e0203f6f33284c69e8188d91422de83
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Thu Jul 19 16:55:38 2018 -0400

    x86/tsc: Calibrate tsc only once
    
    During boot tsc is calibrated twice: once in tsc_early_delay_calibrate(),
    and the second time in tsc_init().
    
    Rename tsc_early_delay_calibrate() to tsc_early_init(), and rework it so
    the calibration is done only early, and make tsc_init() to use the values
    already determined in tsc_early_init().
    
    Sometimes it is not possible to determine tsc early, as the subsystem that
    is required is not yet initialized, in such case try again later in
    tsc_init().
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: steven.sistare@oracle.com
    Cc: daniel.m.jordan@oracle.com
    Cc: linux@armlinux.org.uk
    Cc: schwidefsky@de.ibm.com
    Cc: heiko.carstens@de.ibm.com
    Cc: john.stultz@linaro.org
    Cc: sboyd@codeaurora.org
    Cc: hpa@zytor.com
    Cc: douly.fnst@cn.fujitsu.com
    Cc: peterz@infradead.org
    Cc: prarit@redhat.com
    Cc: feng.tang@intel.com
    Cc: pmladek@suse.com
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: linux-s390@vger.kernel.org
    Cc: boris.ostrovsky@oracle.com
    Cc: jgross@suse.com
    Cc: pbonzini@redhat.com
    Link: https://lkml.kernel.org/r/20180719205545.16512-20-pasha.tatashin@oracle.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7490de925a81..5d32c55aeb8b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1014,6 +1014,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	init_hypervisor_platform();
 
+	tsc_early_init();
 	x86_init.resources.probe_roms();
 
 	/* after parse_early_param, so could debug it */
@@ -1199,7 +1200,6 @@ void __init setup_arch(char **cmdline_p)
 
 	memblock_find_dma_reserve();
 
-	tsc_early_delay_calibrate();
 	if (!early_xdbc_setup_hardware())
 		early_xdbc_register_console();
 

commit 8990cac6e5ea7fa57607736019fe8dca961b998f
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Thu Jul 19 16:55:28 2018 -0400

    x86/jump_label: Initialize static branching early
    
    Static branching is useful to runtime patch branches that are used in hot
    path, but are infrequently changed.
    
    The x86 clock framework is one example that uses static branches to setup
    the best clock during boot and never changes it again.
    
    It is desired to enable the TSC based sched clock early to allow fine
    grained boot time analysis early on. That requires the static branching
    functionality to be functional early as well.
    
    Static branching requires patching nop instructions, thus,
    arch_init_ideal_nops() must be called prior to jump_label_init().
    
    Do all the necessary steps to call arch_init_ideal_nops() right after
    early_cpu_init(), which also allows to insert a call to jump_label_init()
    right after that. jump_label_init() will be called again from the generic
    init code, but the code is protected against reinitialization already.
    
    [ tglx: Massaged changelog ]
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: steven.sistare@oracle.com
    Cc: daniel.m.jordan@oracle.com
    Cc: linux@armlinux.org.uk
    Cc: schwidefsky@de.ibm.com
    Cc: heiko.carstens@de.ibm.com
    Cc: john.stultz@linaro.org
    Cc: sboyd@codeaurora.org
    Cc: hpa@zytor.com
    Cc: douly.fnst@cn.fujitsu.com
    Cc: prarit@redhat.com
    Cc: feng.tang@intel.com
    Cc: pmladek@suse.com
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: linux-s390@vger.kernel.org
    Cc: boris.ostrovsky@oracle.com
    Cc: jgross@suse.com
    Cc: pbonzini@redhat.com
    Link: https://lkml.kernel.org/r/20180719205545.16512-10-pasha.tatashin@oracle.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index da1dbd99cb6e..7490de925a81 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -866,6 +866,8 @@ void __init setup_arch(char **cmdline_p)
 
 	idt_setup_early_traps();
 	early_cpu_init();
+	arch_init_ideal_nops();
+	jump_label_init();
 	early_ioremap_init();
 
 	setup_olpc_ofw_pgd();
@@ -1268,8 +1270,6 @@ void __init setup_arch(char **cmdline_p)
 
 	mcheck_init();
 
-	arch_init_ideal_nops();
-
 	register_refined_jiffies(CLOCK_TICK_RATE);
 
 #ifdef CONFIG_EFI

commit 368a540e0232ad446931f5a4e8a5e06f69f21343
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Thu Jul 19 16:55:20 2018 -0400

    x86/kvmclock: Remove memblock dependency
    
    KVM clock is initialized later compared to other hypervisor clocks because
    it has a dependency on the memblock allocator.
    
    Bring it in line with other hypervisors by using memory from the BSS
    instead of allocating it.
    
    The benefits:
    
      - Remove ifdef from common code
      - Earlier availability of the clock
      - Remove dependency on memblock, and reduce code
    
    The downside:
    
      - Static allocation of the per cpu data structures sized NR_CPUS * 64byte
        Will be addressed in follow up patches.
    
    [ tglx: Split out from larger series ]
    
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: steven.sistare@oracle.com
    Cc: daniel.m.jordan@oracle.com
    Cc: linux@armlinux.org.uk
    Cc: schwidefsky@de.ibm.com
    Cc: heiko.carstens@de.ibm.com
    Cc: john.stultz@linaro.org
    Cc: sboyd@codeaurora.org
    Cc: hpa@zytor.com
    Cc: douly.fnst@cn.fujitsu.com
    Cc: peterz@infradead.org
    Cc: prarit@redhat.com
    Cc: feng.tang@intel.com
    Cc: pmladek@suse.com
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: linux-s390@vger.kernel.org
    Cc: boris.ostrovsky@oracle.com
    Cc: jgross@suse.com
    Link: https://lkml.kernel.org/r/20180719205545.16512-2-pasha.tatashin@oracle.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2f86d883dd95..da1dbd99cb6e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1197,10 +1197,6 @@ void __init setup_arch(char **cmdline_p)
 
 	memblock_find_dma_reserve();
 
-#ifdef CONFIG_KVM_GUEST
-	kvmclock_init();
-#endif
-
 	tsc_early_delay_calibrate();
 	if (!early_xdbc_setup_hardware())
 		early_xdbc_register_console();

commit 11eb0e0e8dea8b97cff972b09cf6fb033b729dff
Author: Sinan Kaya <okaya@codeaurora.org>
Date:   Mon Jun 4 22:16:09 2018 -0400

    PCI: Make early dump functionality generic
    
    Move early dump functionality into common code so that it is available for
    all architectures.  No need to carry arch-specific reads around as the read
    hooks are already initialized by the time pci_setup_device() is getting
    called during scan.
    
    Tested-by: Andy Shevchenko <andy.shevchenko@gmail.com>
    Signed-off-by: Sinan Kaya <okaya@codeaurora.org>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Andy Shevchenko <andy.shevchenko@gmail.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2f86d883dd95..480f250b3c4f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -991,11 +991,6 @@ void __init setup_arch(char **cmdline_p)
 		setup_clear_cpu_cap(X86_FEATURE_APIC);
 	}
 
-#ifdef CONFIG_PCI
-	if (pci_early_dump_regs)
-		early_dump_pci_devices();
-#endif
-
 	e820__reserve_setup_data();
 	e820__finish_early_params();
 

commit 10a70416e1f067f6c4efda6ffd8ea96002ac4223
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Jun 13 15:48:25 2018 -0700

    x86/speculation/l1tf: Make sure the first page is always reserved
    
    The L1TF workaround doesn't make any attempt to mitigate speculate accesses
    to the first physical page for zeroed PTEs. Normally it only contains some
    data from the early real mode BIOS.
    
    It's not entirely clear that the first page is reserved in all
    configurations, so add an extra reservation call to make sure it is really
    reserved. In most configurations (e.g.  with the standard reservations)
    it's likely a nop.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Dave Hansen <dave.hansen@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2f86d883dd95..74b4472ba0a6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -823,6 +823,12 @@ void __init setup_arch(char **cmdline_p)
 	memblock_reserve(__pa_symbol(_text),
 			 (unsigned long)__bss_stop - (unsigned long)_text);
 
+	/*
+	 * Make sure page 0 is always reserved because on systems with
+	 * L1TF its contents can be leaked to user processes.
+	 */
+	memblock_reserve(0, PAGE_SIZE);
+
 	early_reserve_initrd();
 
 	/*

commit 27cca866e3fce0961e13b38b87e5322fe153e437
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Fri Apr 13 23:55:07 2018 +1000

    mm/pkeys, x86, powerpc: Display pkey in smaps if arch supports pkeys
    
    Currently the architecture specific code is expected to display the
    protection keys in smap for a given vma. This can lead to redundant
    code and possibly to divergent formats in which the key gets
    displayed.
    
    This patch changes the implementation. It displays the pkey only if
    the architecture support pkeys, i.e arch_pkeys_enabled() returns true.
    
    x86 arch_show_smap() function is not needed anymore, delete it.
    
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    [mpe: Split out from larger patch, rebased on header changes]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5c623dfe39d1..2f86d883dd95 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1312,11 +1312,3 @@ static int __init register_kernel_offset_dumper(void)
 	return 0;
 }
 __initcall(register_kernel_offset_dumper);
-
-void arch_show_smap(struct seq_file *m, struct vm_area_struct *vma)
-{
-	if (!boot_cpu_has(X86_FEATURE_OSPKE))
-		return;
-
-	seq_printf(m, "ProtectionKey:  %8u\n", vma_pkey(vma));
-}

commit 3db3eb285259ac129f7aec6b814b3e9f6c1b372b
Author: Petr Tesarik <ptesarik@suse.cz>
Date:   Wed Apr 25 12:08:35 2018 +0200

    x86/setup: Do not reserve a crash kernel region if booted on Xen PV
    
    Xen PV domains cannot shut down and start a crash kernel. Instead,
    the crashing kernel makes a SCHEDOP_shutdown hypercall with the
    reason code SHUTDOWN_crash, cf. xen_crash_shutdown() machine op in
    arch/x86/xen/enlighten_pv.c.
    
    A crash kernel reservation is merely a waste of RAM in this case. It
    may also confuse users of kexec_load(2) and/or kexec_file_load(2).
    When flags include KEXEC_ON_CRASH or KEXEC_FILE_ON_CRASH,
    respectively, these syscalls return success, which is technically
    correct, but the crash kexec image will never be actually used.
    
    Signed-off-by: Petr Tesarik <ptesarik@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Juergen Gross <jgross@suse.com>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Cc: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: xen-devel@lists.xenproject.org
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Jean Delvare <jdelvare@suse.de>
    Link: https://lkml.kernel.org/r/20180425120835.23cef60c@ezekiel.suse.cz

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6285697b6e56..5c623dfe39d1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -50,6 +50,7 @@
 #include <linux/init_ohci1394_dma.h>
 #include <linux/kvm_para.h>
 #include <linux/dma-contiguous.h>
+#include <xen/xen.h>
 
 #include <linux/errno.h>
 #include <linux/kernel.h>
@@ -534,6 +535,11 @@ static void __init reserve_crashkernel(void)
 		high = true;
 	}
 
+	if (xen_pv_domain()) {
+		pr_info("Ignoring crashkernel for a Xen PV domain\n");
+		return;
+	}
+
 	/* 0 means: find the address automatically */
 	if (crash_base <= 0) {
 		/*

commit 3c76db70eb70a0fbd40b3e0dec8f69ca344d1ff8
Merge: 194a9749c73d 7958b2246fad
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Mar 12 12:10:03 2018 +0100

    Merge branch 'x86/pti' into x86/mm, to pick up dependencies
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 945fd17ab6bab8a4d05da6c3170519fbcfe62ddb
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 28 21:14:26 2018 +0100

    x86/cpu_entry_area: Sync cpu_entry_area to initial_page_table
    
    The separation of the cpu_entry_area from the fixmap missed the fact that
    on 32bit non-PAE kernels the cpu_entry_area mapping might not be covered in
    initial_page_table by the previous synchronizations.
    
    This results in suspend/resume failures because 32bit utilizes initial page
    table for resume. The absence of the cpu_entry_area mapping results in a
    triple fault, aka. insta reboot.
    
    With PAE enabled this works by chance because the PGD entry which covers
    the fixmap and other parts incindentally provides the cpu_entry_area
    mapping as well.
    
    Synchronize the initial page table after setting up the cpu entry
    area. Instead of adding yet another copy of the same code, move it to a
    function and invoke it from the various places.
    
    It needs to be investigated if the existing calls in setup_arch() and
    setup_per_cpu_areas() can be replaced by the later invocation from
    setup_cpu_entry_areas(), but that's beyond the scope of this fix.
    
    Fixes: 92a0f81d8957 ("x86/cpu_entry_area: Move it out of the fixmap")
    Reported-by: Woody Suwalski <terraluna977@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Woody Suwalski <terraluna977@gmail.com>
    Cc: William Grant <william.grant@canonical.com>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1802282137290.1392@nanos.tec.linutronix.de

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1ae67e982af7..4c616be28506 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1204,20 +1204,13 @@ void __init setup_arch(char **cmdline_p)
 
 	kasan_init();
 
-#ifdef CONFIG_X86_32
-	/* sync back kernel address range */
-	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
-			KERNEL_PGD_PTRS);
-
 	/*
-	 * sync back low identity map too.  It is used for example
-	 * in the 32-bit EFI stub.
+	 * Sync back kernel address range.
+	 *
+	 * FIXME: Can the later sync in setup_cpu_entry_areas() replace
+	 * this call?
 	 */
-	clone_pgd_range(initial_page_table,
-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
-			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
-#endif
+	sync_initial_page_table();
 
 	tboot_probe();
 

commit 162434e7f58b21f0b6c9cc5fb02222cd7d9064cc
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Wed Feb 14 14:16:54 2018 +0300

    x86/mm: Make MAX_PHYSADDR_BITS and MAX_PHYSMEM_BITS dynamic
    
    For boot-time switching between paging modes, we need to be able to
    adjust size of physical address space at runtime.
    
    As part of making physical address space size variable, we have to make
    X86_5LEVEL dependent on SPARSEMEM_VMEMMAP. !SPARSEMEM_VMEMMAP
    configuration doesn't build with variable MAX_PHYSMEM_BITS.
    
    For !SPARSEMEM_VMEMMAP SECTIONS_WIDTH depends on MAX_PHYSMEM_BITS:
    
    SECTIONS_WIDTH
      SECTIONS_SHIFT
        MAX_PHYSMEM_BITS
    
    And SECTIONS_WIDTH is used on pre-processor stage, it doesn't work if it's
    dyncamic. See include/linux/page-flags-layout.h.
    
    Effect on kernel image size:
    
       text    data     bss     dec     hex filename
    8628393 4734340 1368064 14730797         e0c62d vmlinux.before
    8628892 4734340 1368064 14731296         e0c820 vmlinux.after
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20180214111656.88514-8-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1ae67e982af7..399d0f7fa8f1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -189,9 +189,7 @@ struct ist_info ist_info;
 #endif
 
 #else
-struct cpuinfo_x86 boot_cpu_data __read_mostly = {
-	.x86_phys_bits = MAX_PHYSMEM_BITS,
-};
+struct cpuinfo_x86 boot_cpu_data __read_mostly;
 EXPORT_SYMBOL(boot_cpu_data);
 #endif
 
@@ -851,6 +849,7 @@ void __init setup_arch(char **cmdline_p)
 	__flush_tlb_all();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
+	boot_cpu_data.x86_phys_bits = MAX_PHYSMEM_BITS;
 #endif
 
 	/*

commit 3ccabd6d9d9b0da5780e0386b4bf7c5f07669e37
Merge: 5289d3005a36 782bf20c2a17
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 30 13:01:09 2018 -0800

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cleanups from Ingo Molnar:
     "Misc cleanups"
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Remove unused IOMMU_STRESS Kconfig
      x86/extable: Mark exception handler functions visible
      x86/timer: Don't inline __const_udelay
      x86/headers: Remove duplicate #includes

commit 107cd2532181b96c549e8f224cdcca8631c3076b
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Wed Jan 10 13:26:34 2018 -0600

    x86/mm: Encrypt the initrd earlier for BSP microcode update
    
    Currently the BSP microcode update code examines the initrd very early
    in the boot process.  If SME is active, the initrd is treated as being
    encrypted but it has not been encrypted (in place) yet.  Update the
    early boot code that encrypts the kernel to also encrypt the initrd so
    that early BSP microcode updates work.
    
    Tested-by: Gabriel Craciunescu <nix.or.die@gmail.com>
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20180110192634.6026.10452.stgit@tlendack-t1.amdoffice.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 145810b0edf6..68d7ab81c62f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -364,16 +364,6 @@ static void __init reserve_initrd(void)
 	    !ramdisk_image || !ramdisk_size)
 		return;		/* No initrd provided by bootloader */
 
-	/*
-	 * If SME is active, this memory will be marked encrypted by the
-	 * kernel when it is accessed (including relocation). However, the
-	 * ramdisk image was loaded decrypted by the bootloader, so make
-	 * sure that it is encrypted before accessing it. For SEV the
-	 * ramdisk will already be encrypted, so only do this for SME.
-	 */
-	if (sme_active())
-		sme_early_encrypt(ramdisk_image, ramdisk_end - ramdisk_image);
-
 	initrd_start = 0;
 
 	mapped_size = memblock_mem_size(max_pfn_mapped);

commit 835bcec5fdf3f9e880111b482177e7e70e3596da
Author: Dave Young <dyoung@redhat.com>
Date:   Tue Jan 2 17:21:09 2018 +0000

    x86/efi: Fix kernel param add_efi_memmap regression
    
    'add_efi_memmap' is an early param, but do_add_efi_memmap() has no
    chance to run because the code path is before parse_early_param().
    I believe it worked when the param was introduced but probably later
    some other changes caused the wrong order and nobody noticed it.
    
    Move efi_memblock_x86_reserve_range() after parse_early_param()
    to fix it.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Bryan O'Donoghue <pure.logic@nexus-software.ie>
    Cc: Ge Song <ge.song@hxt-semitech.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180102172110.17018-2-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8af2e8d0c0a1..145810b0edf6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -906,9 +906,6 @@ void __init setup_arch(char **cmdline_p)
 		set_bit(EFI_BOOT, &efi.flags);
 		set_bit(EFI_64BIT, &efi.flags);
 	}
-
-	if (efi_enabled(EFI_BOOT))
-		efi_memblock_x86_reserve_range();
 #endif
 
 	x86_init.oem.arch_setup();
@@ -962,6 +959,8 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+	if (efi_enabled(EFI_BOOT))
+		efi_memblock_x86_reserve_range();
 #ifdef CONFIG_MEMORY_HOTPLUG
 	/*
 	 * Memory used by the kernel cannot be hot-removed because Linux

commit 81bf665d00baf1aef01118c6c9e51520e57c0757
Author: Pravin Shedge <pravin.shedge4linux@gmail.com>
Date:   Tue Dec 12 02:12:31 2017 +0530

    x86/headers: Remove duplicate #includes
    
    These duplicate includes have been found with scripts/checkincludes.pl but
    they have been removed manually to avoid removing false positives.
    
    Signed-off-by: Pravin Shedge <pravin.shedge4linux@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: ard.biesheuvel@linaro.org
    Cc: boris.ostrovsky@oracle.com
    Cc: geert@linux-m68k.org
    Cc: jgross@suse.com
    Cc: linux-efi@vger.kernel.org
    Cc: luto@kernel.org
    Cc: matt@codeblueprint.co.uk
    Cc: thomas.lendacky@amd.com
    Cc: tim.c.chen@linux.intel.com
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1513024951-9221-1-git-send-email-pravin.shedge4linux@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8af2e8d0c0a1..c8e04472a141 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -114,7 +114,6 @@
 #include <asm/alternative.h>
 #include <asm/prom.h>
 #include <asm/microcode.h>
-#include <asm/mmu_context.h>
 #include <asm/kaslr.h>
 #include <asm/unwind.h>
 

commit 99306dfc067e6098365d395168b6fd5db3095292
Merge: 3643b7e05b16 120fc3fbb778
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 19:07:38 2017 -0800

    Merge branch 'x86-timers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 timer updates from Thomas Gleixner:
     "These updates are related to TSC handling:
    
       - Support platforms which have synchronized TSCs but the boot CPU has
         a non zero TSC_ADJUST value, which is considered a firmware bug on
         normal systems.
    
         This applies to HPE/SGI UV platforms where the platform firmware
         uses TSC_ADJUST to ensure TSC synchronization across a huge number
         of sockets, but due to power on timings the boot CPU cannot be
         guaranteed to have a zero TSC_ADJUST register value.
    
       - Fix the ordering of udelay calibration and kvmclock_init()
    
       - Cleanup the udelay and calibration code"
    
    * 'x86-timers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/tsc: Mark cyc2ns_init() and detect_art() __init
      x86/platform/UV: Mark tsc_check_sync as an init function
      x86/tsc: Make CONFIG_X86_TSC=n build work again
      x86/platform/UV: Add check of TSC state set by UV BIOS
      x86/tsc: Provide a means to disable TSC ART
      x86/tsc: Drastically reduce the number of firmware bug warnings
      x86/tsc: Skip TSC test and error messages if already unstable
      x86/tsc: Add option that TSC on Socket 0 being non-zero is valid
      x86/timers: Move simple_udelay_calibration() past kvmclock_init()
      x86/timers: Make recalibrate_cpu_khz() void
      x86/timers: Move the simple udelay calibration to tsc.h

commit b18d62891aaff49d0ee8367d4b6bb9452469f807
Merge: 7d58e1c9059e 141d3b1daacd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 18:29:23 2017 -0800

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 APIC updates from Thomas Gleixner:
     "This update provides a major overhaul of the APIC initialization and
      vector allocation code:
    
       - Unification of the APIC and interrupt mode setup which was
         scattered all over the place and was hard to follow. This also
         distangles the timer setup from the APIC initialization which
         brings a clear separation of functionality.
    
         Great detective work from Dou Lyiang!
    
       - Refactoring of the x86 vector allocation mechanism. The existing
         code was based on nested loops and rather convoluted APIC callbacks
         which had a horrible worst case behaviour and tried to serve all
         different use cases in one go. This led to quite odd hacks when
         supporting the new managed interupt facility for multiqueue devices
         and made it more or less impossible to deal with the vector space
         exhaustion which was a major roadblock for server hibernation.
    
         Aside of that the code dealing with cpu hotplug and the system
         vectors was disconnected from the actual vector management and
         allocation code, which made it hard to follow and maintain.
    
         Utilizing the new bitmap matrix allocator core mechanism, the new
         allocator and management code consolidates the handling of system
         vectors, legacy vectors, cpu hotplug mechanisms and the actual
         allocation which needs to be aware of system and legacy vectors and
         hotplug constraints into a single consistent entity.
    
         This has one visible change: The support for multi CPU targets of
         interrupts, which is only available on a certain subset of
         CPUs/APIC variants has been removed in favour of single interrupt
         targets. A proper analysis of the multi CPU target feature revealed
         that there is no real advantage as the vast majority of interrupts
         end up on the CPU with the lowest APIC id in the set of target CPUs
         anyway. That change was agreed on by the relevant folks and allowed
         to simplify the implementation significantly and to replace rather
         fragile constructs like the vector cleanup IPI with straight
         forward and solid code.
    
         Furthermore this allowed to cleanly separate the allocation details
         for legacy, normal and managed interrupts:
    
          * Legacy interrupts are not longer wasting 16 vectors
            unconditionally
    
          * Managed interrupts have now a guaranteed vector reservation, but
            the actual vector assignment happens when the interrupt is
            requested. It's guaranteed not to fail.
    
          * Normal interrupts no longer allocate vectors unconditionally
            when the interrupt is set up (IO/APIC init or MSI(X) enable).
            The mechanism has been switched to a best effort reservation
            mode. The actual allocation happens when the interrupt is
            requested. Contrary to managed interrupts the request can fail
            due to vector space exhaustion, but drivers must handle a fail
            of request_irq() anyway. When the interrupt is freed, the vector
            is handed back as well.
    
            This solves a long standing problem with large unconditional
            vector allocations for a certain class of enterprise devices
            which prevented server hibernation due to vector space
            exhaustion when the unused allocated vectors had to be migrated
            to CPU0 while unplugging all non boot CPUs.
    
         The code has been equipped with trace points and detailed debugfs
         information to aid analysis of the vector space"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (60 commits)
      x86/vector/msi: Select CONFIG_GENERIC_IRQ_RESERVATION_MODE
      PCI/MSI: Set MSI_FLAG_MUST_REACTIVATE in core code
      genirq: Add config option for reservation mode
      x86/vector: Use correct per cpu variable in free_moved_vector()
      x86/apic/vector: Ignore set_affinity call for inactive interrupts
      x86/apic: Fix spelling mistake: "symmectic" -> "symmetric"
      x86/apic: Use dead_cpu instead of current CPU when cleaning up
      ACPI/init: Invoke early ACPI initialization earlier
      x86/vector: Respect affinity mask in irq descriptor
      x86/irq: Simplify hotplug vector accounting
      x86/vector: Switch IOAPIC to global reservation mode
      x86/vector/msi: Switch to global reservation mode
      x86/vector: Handle managed interrupts proper
      x86/io_apic: Reevaluate vector configuration on activate()
      iommu/amd: Reevaluate vector configuration on activate()
      iommu/vt-d: Reevaluate vector configuration on activate()
      x86/apic/msi: Force reactivation of interrupts at startup time
      x86/vector: Untangle internal state from irq_cfg
      x86/vector: Compile SMP only code conditionally
      x86/apic: Remove unused callbacks
      ...

commit 43ff2f4db9d0f76452b77cfa645f02b471143b24
Merge: 13e57da4a5ea 418492ba40b2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 17:04:36 2017 -0800

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 platform updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - a refactoring of the early virt init code by merging 'struct
         x86_hyper' into 'struct x86_platform' and 'struct x86_init', which
         allows simplifications and also the addition of a new
         ->guest_late_init() callback. (Juergen Gross)
    
       - timer_setup() conversion of the UV code (Kees Cook)"
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/virt/xen: Use guest_late_init to detect Xen PVH guest
      x86/virt, x86/platform: Add ->guest_late_init() callback to hypervisor_x86 structure
      x86/virt, x86/acpi: Add test for ACPI_FADT_NO_VGA
      x86/virt: Add enum for hypervisors to replace x86_hyper
      x86/virt, x86/platform: Merge 'struct x86_hyper' into 'struct x86_platform' and 'struct x86_init'
      x86/platform/UV: Convert timers to use timer_setup()

commit 6a9f70b0a5b3ca5db1dd5c7743ca555bfca2ae08
Merge: d6ec9d9a4def 6c3b56b19730
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 16:32:30 2017 -0800

    Merge branch 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 boot updates from Ingo Molnar:
     "Three smaller changes:
    
       - clang fix
    
       - boot message beautification
    
       - unnecessary header inclusion removal"
    
    * 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/boot: Disable Clang warnings about GNU extensions
      x86/boot: Remove unnecessary #include <generated/utsrelease.h>
      x86/boot: Spell out "boot CPU" for BP

commit f3614646005a1b59f836ff54351c9bd2224b6005
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Nov 9 14:27:38 2017 +0100

    x86/virt, x86/platform: Add ->guest_late_init() callback to hypervisor_x86 structure
    
    Add a new guest_late_init callback to the hypervisor_x86 structure. It
    will replace the current kvm_guest_init() call which is changed to
    make use of the new callback.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kvm@vger.kernel.org
    Cc: rkrcmar@redhat.com
    Link: http://lkml.kernel.org/r/20171109132739.23465-5-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0957dd73d127..372da5299334 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1294,7 +1294,7 @@ void __init setup_arch(char **cmdline_p)
 
 	io_apic_init_mappings();
 
-	kvm_guest_init();
+	x86_init.hyper.guest_late_init();
 
 	e820__reserve_resources();
 	e820__register_nosave_regions(max_low_pfn);

commit 682af54399b6111730aec0be63e5f6a3a3359a76
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Fri Oct 20 09:30:45 2017 -0500

    x86/mm: Don't attempt to encrypt initrd under SEV
    
    When SEV is active the initrd/initramfs will already have already been
    placed in memory encrypted so do not try to encrypt it.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Tested-by: Borislav Petkov <bp@suse.de>
    Cc: kvm@vger.kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20171020143059.3291-4-brijesh.singh@amd.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0957dd73d127..507100a72eb3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -380,9 +380,11 @@ static void __init reserve_initrd(void)
 	 * If SME is active, this memory will be marked encrypted by the
 	 * kernel when it is accessed (including relocation). However, the
 	 * ramdisk image was loaded decrypted by the bootloader, so make
-	 * sure that it is encrypted before accessing it.
+	 * sure that it is encrypted before accessing it. For SEV the
+	 * ramdisk will already be encrypted, so only do this for SME.
 	 */
-	sme_early_encrypt(ramdisk_image, ramdisk_end - ramdisk_image);
+	if (sme_active())
+		sme_early_encrypt(ramdisk_image, ramdisk_end - ramdisk_image);
 
 	initrd_start = 0;
 

commit a1652bb8a01c1a830cacbe958aec17f880cc1e47
Author: Jean Delvare <jdelvare@suse.de>
Date:   Tue Oct 3 11:47:27 2017 +0200

    x86/boot: Spell out "boot CPU" for BP
    
    It's not obvious to everybody that BP stands for boot processor. At
    least it was not for me. And BP is also a CPU register on x86, so it
    is ambiguous. Spell out "boot CPU" everywhere instead.
    
    Signed-off-by: Jean Delvare <jdelvare@suse.de>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0957dd73d127..cb71626d49da 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1045,7 +1045,7 @@ void __init setup_arch(char **cmdline_p)
 
 	/*
 	 * VMware detection requires dmi to be available, so this
-	 * needs to be done after dmi_scan_machine, for the BP.
+	 * needs to be done after dmi_scan_machine(), for the boot CPU.
 	 */
 	init_hypervisor_platform();
 

commit 64063505835663c67cf18524c46e1eb70d30fb54
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:21 2017 +0200

    x86/apic: Sanitize 32/64bit APIC callbacks
    
    The 32bit and the 64bit implementation of default_cpu_present_to_apicid()
    and default_check_phys_apicid_present() are exactly the same, but
    implemented and located differently.
    
    Move them to common apic code and get rid of the pointless difference.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213153.757329991@linutronix.de

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0957dd73d127..82559867e0a9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -136,18 +136,6 @@ RESERVE_BRK(dmi_alloc, 65536);
 static __initdata unsigned long _brk_start = (unsigned long)__brk_base;
 unsigned long _brk_end = (unsigned long)__brk_base;
 
-#ifdef CONFIG_X86_64
-int default_cpu_present_to_apicid(int mps_cpu)
-{
-	return __default_cpu_present_to_apicid(mps_cpu);
-}
-
-int default_check_phys_apicid_present(int phys_apicid)
-{
-	return __default_check_phys_apicid_present(phys_apicid);
-}
-#endif
-
 struct boot_params boot_params;
 
 /*

commit ccb64941f375a6eb21b1b20136730eb7d1716068
Author: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Date:   Mon Sep 11 14:51:11 2017 -0400

    x86/timers: Move simple_udelay_calibration() past kvmclock_init()
    
    simple_udelay_calibration() relies on x86_platform's calibration ops.
    For KVM these ops are set late in setup_arch() and so
    simple_udelay_calibration() ends up using native version.
    
    Besides being possibly incorrect, this significantly increases kernel
    boot time. For example, on my laptop executing start_kernel() by a guest
    takes ~10 times more than when KVM's ops are used.
    
    Since early_xdbc_setup_hardware() relies on calibration having been
    performed move it too.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: baolu.lu@linux.intel.com
    Link: https://lkml.kernel.org/r/20170911185111.20636-1-boris.ostrovsky@oracle.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c63d2b4dd5c8..b40311027c15 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1029,8 +1029,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	init_hypervisor_platform();
 
-	tsc_early_delay_calibrate();
-
 	x86_init.resources.probe_roms();
 
 	/* after parse_early_param, so could debug it */
@@ -1115,9 +1113,6 @@ void __init setup_arch(char **cmdline_p)
 	memblock_set_current_limit(ISA_END_ADDRESS);
 	e820__memblock_setup();
 
-	if (!early_xdbc_setup_hardware())
-		early_xdbc_register_console();
-
 	reserve_bios_regions();
 
 	if (efi_enabled(EFI_MEMMAP)) {
@@ -1223,6 +1218,10 @@ void __init setup_arch(char **cmdline_p)
 	kvmclock_init();
 #endif
 
+	tsc_early_delay_calibrate();
+	if (!early_xdbc_setup_hardware())
+		early_xdbc_register_console();
+
 	x86_init.paging.pagetable_init();
 
 	kasan_init();

commit eb496063c9904ce682253ee445b9acb9b6257581
Author: Dou Liyang <douly.fnst@cn.fujitsu.com>
Date:   Fri Jul 14 11:34:06 2017 +0800

    x86/timers: Move the simple udelay calibration to tsc.h
    
    Commit dd759d93f4dd ("x86/timers: Add simple udelay calibration") adds
    an static function in x86 boot-time initializations.
    
    But, this function is actually related to TSC, so it should be maintained
    in tsc.c, not in setup.c.
    
    Move simple_udelay_calibration() from setup.c to tsc.c and rename it to
    tsc_early_delay_calibrate for more readability.
    
    Signed-off-by: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/1500003247-17368-1-git-send-email-douly.fnst@cn.fujitsu.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0957dd73d127..c63d2b4dd5c8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -822,26 +822,6 @@ dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 	return 0;
 }
 
-static void __init simple_udelay_calibration(void)
-{
-	unsigned int tsc_khz, cpu_khz;
-	unsigned long lpj;
-
-	if (!boot_cpu_has(X86_FEATURE_TSC))
-		return;
-
-	cpu_khz = x86_platform.calibrate_cpu();
-	tsc_khz = x86_platform.calibrate_tsc();
-
-	tsc_khz = tsc_khz ? : cpu_khz;
-	if (!tsc_khz)
-		return;
-
-	lpj = tsc_khz * 1000;
-	do_div(lpj, HZ);
-	loops_per_jiffy = lpj;
-}
-
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -1049,7 +1029,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	init_hypervisor_platform();
 
-	simple_udelay_calibration();
+	tsc_early_delay_calibrate();
 
 	x86_init.resources.probe_roms();
 

commit c7ad5ad297e644601747d6dbee978bf85e14f7bc
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sun Sep 10 17:48:27 2017 -0700

    x86/mm/64: Initialize CR4.PCIDE early
    
    cpu_init() is weird: it's called rather late (after early
    identification and after most MMU state is initialized) on the boot
    CPU but is called extremely early (before identification) on secondary
    CPUs.  It's called just late enough on the boot CPU that its CR4 value
    isn't propagated to mmu_cr4_features.
    
    Even if we put CR4.PCIDE into mmu_cr4_features, we'd hit two
    problems.  First, we'd crash in the trampoline code.  That's
    fixable, and I tried that.  It turns out that mmu_cr4_features is
    totally ignored by secondary_start_64(), though, so even with the
    trampoline code fixed, it wouldn't help.
    
    This means that we don't currently have CR4.PCIDE reliably initialized
    before we start playing with cpu_tlbstate.  This is very fragile and
    tends to cause boot failures if I make even small changes to the TLB
    handling code.
    
    Make it more robust: initialize CR4.PCIDE earlier on the boot CPU
    and propagate it to secondary CPUs in start_secondary().
    
    ( Yes, this is ugly.  I think we should have improved mmu_cr4_features
      to actually control CR4 during secondary bootup, but that would be
      fairly intrusive at this stage. )
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reported-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Tested-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Fixes: 660da7c9228f ("x86/mm: Enable CR4.PCIDE on supported systems")
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d84afb0a322d..0957dd73d127 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1178,8 +1178,11 @@ void __init setup_arch(char **cmdline_p)
 	 * with the current CR4 value.  This may not be necessary, but
 	 * auditing all the early-boot CR4 manipulation would be needed to
 	 * rule it out.
+	 *
+	 * Mask off features that don't work outside long mode (just
+	 * PCIDE for now).
 	 */
-	mmu_cr4_features = __read_cr4();
+	mmu_cr4_features = __read_cr4() & ~X86_CR4_PCIDE;
 
 	memblock_set_current_limit(get_max_mapped());
 

commit 53ac64aac9af8cd0e5456c8a9bb68c47b571b0a9
Merge: 439644096c1a 298bd7fb26cb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 5 12:45:03 2017 -0700

    Merge tag 'acpi-4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI updates from Rafael Wysocki:
     "These include a usual ACPICA code update (this time to upstream
      revision 20170728), a fix for a boot crash on some systems with
      Thunderbolt devices connected at boot time, a rework of the handling
      of PCI bridges when setting up device wakeup, new support for Apple
      device properties, support for DMA configurations reported via ACPI on
      ARM64, APEI-related updates, ACPI EC driver updates and assorted minor
      modifications in several places.
    
      Specifics:
    
       - Update the ACPICA code in the kernel to upstream revision 20170728
         including:
          * Alias operator handling update (Bob Moore).
          * Deferred resolution of reference package elements (Bob Moore).
          * Support for the _DMA method in walk resources (Bob Moore).
          * Tables handling update and support for deferred table
            verification (Lv Zheng).
          * Update of SMMU models for IORT (Robin Murphy).
          * Compiler and disassembler updates (Alex James, Erik Schmauss,
            Ganapatrao Kulkarni, James Morse).
          * Tools updates (Erik Schmauss, Lv Zheng).
          * Assorted minor fixes and cleanups (Bob Moore, Kees Cook, Lv
            Zheng, Shao Ming).
    
       - Rework the initialization of non-wakeup GPEs with method handlers
         in order to address a boot crash on some systems with Thunderbolt
         devices connected at boot time where we miss an early hotplug event
         due to a delay in GPE enabling (Rafael Wysocki).
    
       - Rework the handling of PCI bridges when setting up ACPI-based
         device wakeup in order to avoid disabling wakeup for bridges
         prematurely (Rafael Wysocki).
    
       - Consolidate Apple DMI checks throughout the tree, add support for
         Apple device properties to the device properties framework and use
         these properties for the handling of I2C and SPI devices on Apple
         systems (Lukas Wunner).
    
       - Add support for _DMA to the ACPI-based device properties lookup
         code and make it possible to use the information from there to
         configure DMA regions on ARM64 systems (Lorenzo Pieralisi).
    
       - Fix several issues in the APEI code, add support for exporting the
         BERT error region over sysfs and update APEI MAINTAINERS entry with
         reviewers information (Borislav Petkov, Dongjiu Geng, Loc Ho, Punit
         Agrawal, Tony Luck, Yazen Ghannam).
    
       - Fix a potential initialization ordering issue in the ACPI EC driver
         and clean it up somewhat (Lv Zheng).
    
       - Update the ACPI SPCR driver to extend the existing XGENE 8250
         workaround in it to a new platform (m400) and to work around an
         Xgene UART clock issue (Graeme Gregory).
    
       - Add a new utility function to the ACPI core to support using ACPI
         OEM ID / OEM Table ID / Revision for system identification in
         blacklisting or similar and switch over the existing code already
         using this information to this new interface (Toshi Kani).
    
       - Fix an xpower PMIC issue related to GPADC reads that always return
         0 without extra pin manipulations (Hans de Goede).
    
       - Add statements to print debug messages in a couple of places in the
         ACPI core for easier diagnostics (Rafael Wysocki).
    
       - Clean up the ACPI processor driver slightly (Colin Ian King, Hanjun
         Guo).
    
       - Clean up the ACPI x86 boot code somewhat (Andy Shevchenko).
    
       - Add a quirk for Dell OptiPlex 9020M to the ACPI backlight driver
         (Alex Hung).
    
       - Assorted fixes, cleanups and updates related to ACPI (Amitoj Kaur
         Chawla, Bhumika Goyal, Frank Rowand, Jean Delvare, Punit Agrawal,
         Ronald Tschal√§r, Sumeet Pawnikar)"
    
    * tag 'acpi-4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (75 commits)
      ACPI / APEI: Suppress message if HEST not present
      intel_pstate: convert to use acpi_match_platform_list()
      ACPI / blacklist: add acpi_match_platform_list()
      ACPI, APEI, EINJ: Subtract any matching Register Region from Trigger resources
      ACPI: make device_attribute const
      ACPI / sysfs: Extend ACPI sysfs to provide access to boot error region
      ACPI: APEI: fix the wrong iteration of generic error status block
      ACPI / processor: make function acpi_processor_check_duplicates() static
      ACPI / EC: Clean up EC GPE mask flag
      ACPI: EC: Fix possible issues related to EC initialization order
      ACPI / PM: Add debug statements to acpi_pm_notify_handler()
      ACPI: Add debug statements to acpi_global_event_handler()
      ACPI / scan: Enable GPEs before scanning the namespace
      ACPICA: Make it possible to enable runtime GPEs earlier
      ACPICA: Dispatch active GPEs at init time
      ACPI: SPCR: work around clock issue on xgene UART
      ACPI: SPCR: extend XGENE 8250 workaround to m400
      ACPI / LPSS: Don't abort ACPI scan on missing mem resource
      mailbox: pcc: Drop uninformative output during boot
      ACPI/IORT: Add IORT named component memory address limits
      ...

commit 24e700e291d52bd200212487e2b654c0aa3f07a2
Merge: f57091767add c6ef89421e23
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 4 17:43:56 2017 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 apic updates from Thomas Gleixner:
     "This update provides:
    
       - Cleanup of the IDT management including the removal of the extra
         tracing IDT. A first step to cleanup the vector management code.
    
       - The removal of the paravirt op adjust_exception_frame. This is a
         XEN specific issue, but merged through this branch to avoid nasty
         merge collisions
    
       - Prevent dmesg spam about the TSC DEADLINE bug, when the CPU has
         disabled the TSC DEADLINE timer in CPUID.
    
       - Adjust a debug message in the ioapic code to print out the
         information correctly"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (51 commits)
      x86/idt: Fix the X86_TRAP_BP gate
      x86/xen: Get rid of paravirt op adjust_exception_frame
      x86/eisa: Add missing include
      x86/idt: Remove superfluous ALIGNment
      x86/apic: Silence "FW_BUG TSC_DEADLINE disabled due to Errata" on CPUs without the feature
      x86/idt: Remove the tracing IDT leftovers
      x86/idt: Hide set_intr_gate()
      x86/idt: Simplify alloc_intr_gate()
      x86/idt: Deinline setup functions
      x86/idt: Remove unused functions/inlines
      x86/idt: Move interrupt gate initialization to IDT code
      x86/idt: Move APIC gate initialization to tables
      x86/idt: Move regular trap init to tables
      x86/idt: Move IST stack based traps to table init
      x86/idt: Move debug stack init to table based
      x86/idt: Switch early trap init to IDT tables
      x86/idt: Prepare for table based init
      x86/idt: Move early IDT setup out of 32-bit asm
      x86/idt: Move early IDT handler setup to IDT code
      x86/idt: Consolidate IDT invalidation
      ...

commit b1b6f83ac938d176742c85757960dec2cf10e468
Merge: 5f82e71a001d 9e52fc2b50de
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 4 12:21:28 2017 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm changes from Ingo Molnar:
     "PCID support, 5-level paging support, Secure Memory Encryption support
    
      The main changes in this cycle are support for three new, complex
      hardware features of x86 CPUs:
    
       - Add 5-level paging support, which is a new hardware feature on
         upcoming Intel CPUs allowing up to 128 PB of virtual address space
         and 4 PB of physical RAM space - a 512-fold increase over the old
         limits. (Supercomputers of the future forecasting hurricanes on an
         ever warming planet can certainly make good use of more RAM.)
    
         Many of the necessary changes went upstream in previous cycles,
         v4.14 is the first kernel that can enable 5-level paging.
    
         This feature is activated via CONFIG_X86_5LEVEL=y - disabled by
         default.
    
         (By Kirill A. Shutemov)
    
       - Add 'encrypted memory' support, which is a new hardware feature on
         upcoming AMD CPUs ('Secure Memory Encryption', SME) allowing system
         RAM to be encrypted and decrypted (mostly) transparently by the
         CPU, with a little help from the kernel to transition to/from
         encrypted RAM. Such RAM should be more secure against various
         attacks like RAM access via the memory bus and should make the
         radio signature of memory bus traffic harder to intercept (and
         decrypt) as well.
    
         This feature is activated via CONFIG_AMD_MEM_ENCRYPT=y - disabled
         by default.
    
         (By Tom Lendacky)
    
       - Enable PCID optimized TLB flushing on newer Intel CPUs: PCID is a
         hardware feature that attaches an address space tag to TLB entries
         and thus allows to skip TLB flushing in many cases, even if we
         switch mm's.
    
         (By Andy Lutomirski)
    
      All three of these features were in the works for a long time, and
      it's coincidence of the three independent development paths that they
      are all enabled in v4.14 at once"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (65 commits)
      x86/mm: Enable RCU based page table freeing (CONFIG_HAVE_RCU_TABLE_FREE=y)
      x86/mm: Use pr_cont() in dump_pagetable()
      x86/mm: Fix SME encryption stack ptr handling
      kvm/x86: Avoid clearing the C-bit in rsvd_bits()
      x86/CPU: Align CR3 defines
      x86/mm, mm/hwpoison: Clear PRESENT bit for kernel 1:1 mappings of poison pages
      acpi, x86/mm: Remove encryption mask from ACPI page protection type
      x86/mm, kexec: Fix memory corruption with SME on successive kexecs
      x86/mm/pkeys: Fix typo in Documentation/x86/protection-keys.txt
      x86/mm/dump_pagetables: Speed up page tables dump for CONFIG_KASAN=y
      x86/mm: Implement PCID based optimization: try to preserve old TLB entries using PCID
      x86: Enable 5-level paging support via CONFIG_X86_5LEVEL=y
      x86/mm: Allow userspace have mappings above 47-bit
      x86/mm: Prepare to expose larger address space to userspace
      x86/mpx: Do not allow MPX if we have mappings above 47-bit
      x86/mm: Rename tasksize_32bit/64bit to task_size_32bit/64bit()
      x86/xen: Redefine XEN_ELFNOTE_INIT_P2M using PUD_SIZE * PTRS_PER_PUD
      x86/mm/dump_pagetables: Fix printout of p4d level
      x86/mm/dump_pagetables: Generalize address normalization
      x86/boot: Fix memremap() related build failure
      ...

commit 433f8924fa8e55a50ce57f3b8a33ed095c405644
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 28 08:47:50 2017 +0200

    x86/idt: Switch early trap init to IDT tables
    
    Add the initialization table for the early trap setup and replace the early
    trap init code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20170828064958.929139008@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ecab32282f0f..30dc84ee35b2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -891,7 +891,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	olpc_ofw_detect();
 
-	early_trap_init();
+	idt_setup_early_traps();
 	early_cpu_init();
 	early_ioremap_init();
 
@@ -1162,7 +1162,7 @@ void __init setup_arch(char **cmdline_p)
 
 	init_mem_mapping();
 
-	early_trap_pf_init();
+	idt_setup_early_pf();
 
 	/*
 	 * Update mmu_cr4_features (and, indirectly, trampoline_cr4_features)

commit 630b3aff8a51c90ef15b59c9560ac35e40e7ec09
Author: Lukas Wunner <lukas@wunner.de>
Date:   Tue Aug 1 14:10:41 2017 +0200

    treewide: Consolidate Apple DMI checks
    
    We're about to amend ACPI bus scan with DMI checks whether we're running
    on a Mac to support Apple device properties in AML.  The DMI checks are
    performed for every single device, adding overhead for everything x86
    that isn't Apple, which is the majority.  Rafael and Andy therefore
    request to perform the DMI match only once and cache the result.
    
    Outside of ACPI various other Apple DMI checks exist and it seems
    reasonable to use the cached value there as well.  Rafael, Andy and
    Darren suggest performing the DMI check in arch code and making it
    available with a header in include/linux/platform_data/x86/.
    
    To this end, add early_platform_quirks() to arch/x86/kernel/quirks.c
    to perform the DMI check and invoke it from setup_arch().  Switch over
    all existing Apple DMI checks, thereby fixing two deficiencies:
    
    * They are now #defined to false on non-x86 arches and can thus be
      optimized away if they're located in cross-arch code.
    
    * Some of them only match "Apple Inc." but not "Apple Computer, Inc.",
      which is used by BIOSes released between January 2006 (when the first
      x86 Macs started shipping) and January 2007 (when the company name
      changed upon introduction of the iPhone).
    
    Suggested-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Suggested-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Suggested-by: Darren Hart <dvhart@infradead.org>
    Signed-off-by: Lukas Wunner <lukas@wunner.de>
    Acked-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3486d0498800..77b3c3af7cba 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1206,6 +1206,8 @@ void __init setup_arch(char **cmdline_p)
 
 	io_delay_init();
 
+	early_platform_quirks();
+
 	/*
 	 * Parse the ACPI tables for possible boot-time SMP configuration.
 	 */

commit ee9f8fce99640811b2b8e79d0d1dbe8bab69ba67
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Mon Jul 24 18:36:57 2017 -0500

    x86/unwind: Add the ORC unwinder
    
    Add the new ORC unwinder which is enabled by CONFIG_ORC_UNWINDER=y.
    It plugs into the existing x86 unwinder framework.
    
    It relies on objtool to generate the needed .orc_unwind and
    .orc_unwind_ip sections.
    
    For more details on why ORC is used instead of DWARF, see
    Documentation/x86/orc-unwinder.txt - but the short version is
    that it's a simplified, fundamentally more robust debugninfo
    data structure, which also allows up to two orders of magnitude
    faster lookups than the DWARF unwinder - which matters to
    profiling workloads like perf.
    
    Thanks to Andy Lutomirski for the performance improvement ideas:
    splitting the ORC unwind table into two parallel arrays and creating a
    fast lookup table to search a subset of the unwind table.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: live-patching@vger.kernel.org
    Link: http://lkml.kernel.org/r/0a6cbfb40f8da99b7a45a1a8302dc6aef16ec812.1500938583.git.jpoimboe@redhat.com
    [ Extended the changelog. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3486d0498800..ecab32282f0f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -115,6 +115,7 @@
 #include <asm/microcode.h>
 #include <asm/mmu_context.h>
 #include <asm/kaslr.h>
+#include <asm/unwind.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
@@ -1310,6 +1311,8 @@ void __init setup_arch(char **cmdline_p)
 	if (efi_enabled(EFI_BOOT))
 		efi_apply_memmap_quirks();
 #endif
+
+	unwind_init();
 }
 
 #ifdef CONFIG_X86_32

commit b9d05200bc12444c7778a49c9694d8382ed06aa8
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:11 2017 -0500

    x86/mm: Insure that boot memory areas are mapped properly
    
    The boot data and command line data are present in memory in a decrypted
    state and are copied early in the boot process.  The early page fault
    support will map these areas as encrypted, so before attempting to copy
    them, add decrypted mappings so the data is accessed properly when copied.
    
    For the initrd, encrypt this data in place. Since the future mapping of
    the initrd area will be mapped as encrypted the data will be accessed
    properly.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krƒçm√°≈ô <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/bb0d430b41efefd45ee515aaf0979dcfda8b6a44.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3486d0498800..0bfe0c1628f6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -69,6 +69,7 @@
 #include <linux/crash_dump.h>
 #include <linux/tboot.h>
 #include <linux/jiffies.h>
+#include <linux/mem_encrypt.h>
 
 #include <linux/usb/xhci-dbgp.h>
 #include <video/edid.h>
@@ -374,6 +375,14 @@ static void __init reserve_initrd(void)
 	    !ramdisk_image || !ramdisk_size)
 		return;		/* No initrd provided by bootloader */
 
+	/*
+	 * If SME is active, this memory will be marked encrypted by the
+	 * kernel when it is accessed (including relocation). However, the
+	 * ramdisk image was loaded decrypted by the bootloader, so make
+	 * sure that it is encrypted before accessing it.
+	 */
+	sme_early_encrypt(ramdisk_image, ramdisk_end - ramdisk_image);
+
 	initrd_start = 0;
 
 	mapped_size = memblock_mem_size(max_pfn_mapped);

commit 99c13b8c8896d7bcb92753bf0c63a8de4326e78d
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Tue Jul 4 19:04:23 2017 -0400

    x86/mm/pat: Don't report PAT on CPUs that don't support it
    
    The pat_enabled() logic is broken on CPUs which do not support PAT and
    where the initialization code fails to call pat_init(). Due to that the
    enabled flag stays true and pat_enabled() returns true wrongfully.
    
    As a consequence the mappings, e.g. for Xorg, are set up with the wrong
    caching mode and the required MTRR setups are omitted.
    
    To cure this the following changes are required:
    
      1) Make pat_enabled() return true only if PAT initialization was
         invoked and successful.
    
      2) Invoke init_cache_modes() unconditionally in setup_arch() and
         remove the extra callsites in pat_disable() and the pat disabled
         code path in pat_init().
    
    Also rename __pat_enabled to pat_disabled to reflect the real purpose of
    this variable.
    
    Fixes: 9cd25aac1f44 ("x86/mm/pat: Emulate PAT when it is disabled")
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Bernhard Held <berny156@gmx.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: "Luis R. Rodriguez" <mcgrof@suse.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/alpine.LRH.2.02.1707041749300.3456@file01.intranet.prod.int.rdu2.redhat.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 65622f07e633..3486d0498800 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1075,6 +1075,13 @@ void __init setup_arch(char **cmdline_p)
 
 	max_possible_pfn = max_pfn;
 
+	/*
+	 * This call is required when the CPU does not support PAT. If
+	 * mtrr_bp_init() invoked it already via pat_init() the call has no
+	 * effect.
+	 */
+	init_cache_modes();
+
 	/*
 	 * Define random base addresses for memory sections after max_pfn is
 	 * defined and before each memory section base is used.

commit 25e09ca52459586eb6171209635bc8b436a56d79
Merge: 48b5259cf0a2 fe2d48b805d0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 13:40:38 2017 -0700

    Merge branch 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 boot updates from Ingo Molnar:
     "The main changes in this cycle were KASLR improvements for rare
      environments with special boot options, by Baoquan He. Also misc
      smaller changes/cleanups"
    
    * 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/debug: Extend the lower bound of crash kernel low reservations
      x86/boot: Remove unused copy_*_gs() functions
      x86/KASLR: Use the right memcpy() implementation
      Documentation/kernel-parameters.txt: Update 'memmap=' boot option description
      x86/KASLR: Handle the memory limit specified by the 'memmap=' and 'mem=' boot options
      x86/KASLR: Parse all 'memmap=' boot option entries

commit fe2d48b805d01e14ddb8144de01de43171eb516f
Author: Jiri Bohac <jbohac@suse.cz>
Date:   Fri Jun 16 18:16:02 2017 +0200

    x86/debug: Extend the lower bound of crash kernel low reservations
    
    The following change in 2013:
    
      0212f9159694 ("x86: Add Crash kernel low reservation")
    
    ... introduced reserve_crashkernel_low(). This function is used to
    reserve crash kernel memory either if crashkernel=size,low is given
    on the command line or if the region reserved by reserve_crashkernel
    is entirely above 4G.
    
    reserve_crashkernel_low() tries to find a block of 'low_size' bytes.
    But there seems to be no good reason to restrict the lower bound
    of the range to 'low_size'.
    
    Make memblock_find_in_range() search from the start of memory.
    
    Signed-off-by: Jiri Bohac <jbohac@suse.cz>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20170616161602.2r7birrf2y3ylv6v@dwarf.suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0b4d3c686b1e..848d0489ad00 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -503,7 +503,7 @@ static int __init reserve_crashkernel_low(void)
 			return 0;
 	}
 
-	low_base = memblock_find_in_range(low_size, 1ULL << 32, low_size, CRASH_ALIGN);
+	low_base = memblock_find_in_range(0, 1ULL << 32, low_size, CRASH_ALIGN);
 	if (!low_base) {
 		pr_err("Cannot reserve %ldMB crashkernel low memory, please try smaller size.\n",
 		       (unsigned long)(low_size >> 20));

commit 702644ec1cab10ffefcebb4060d4da46d4ef2c7f
Author: Jan Kiszka <jan.kiszka@siemens.com>
Date:   Wed May 24 20:04:41 2017 +0200

    x86/timers: Move simple_udelay_calibration past init_hypervisor_platform
    
    This ensures that adjustments to x86_platform done by the hypervisor
    setup is already respected by this simple calibration.
    
    The current user of this, introduced by 1b5aeebf3a92 ("x86/earlyprintk:
    Add support for earlyprintk via USB3 debug port"), comes much later
    into play.
    
    Fixes: dd759d93f4dd ("x86/timers: Add simple udelay calibration")
    Signed-off-by: Jan Kiszka <jan.kiszka@siemens.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: http://lkml.kernel.org/r/5e89fe60-aab3-2c1c-aba8-32f8ad376189@siemens.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0b4d3c686b1e..f81823695014 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -980,8 +980,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	x86_configure_nx();
 
-	simple_udelay_calibration();
-
 	parse_early_param();
 
 #ifdef CONFIG_MEMORY_HOTPLUG
@@ -1041,6 +1039,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	init_hypervisor_platform();
 
+	simple_udelay_calibration();
+
 	x86_init.resources.probe_roms();
 
 	/* after parse_early_param, so could debug it */

commit d2b6dc61a8dd3c429609b993778cb54e75a5c5f0
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon May 8 17:09:10 2017 -0700

    x86/boot/32: Fix UP boot on Quark and possibly other platforms
    
    This partially reverts commit:
    
      23b2a4ddebdd17f ("x86/boot/32: Defer resyncing initial_page_table until per-cpu is set up")
    
    That commit had one definite bug and one potential bug.  The
    definite bug is that setup_per_cpu_areas() uses a differnet generic
    implementation on UP kernels, so initial_page_table never got
    resynced.  This was fine for access to percpu data (it's in the
    identity map on UP), but it breaks other users of
    initial_page_table.  The potential bug is that helpers like
    efi_init() would be called before the tables were synced.
    
    Avoid both problems by just syncing the page tables in setup_arch()
    *and* setup_per_cpu_areas().
    
    Reported-by: Jan Kiszka <jan.kiszka@siemens.com>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Garnier <thgarnie@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 603a1669a2ec..0b4d3c686b1e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1225,6 +1225,21 @@ void __init setup_arch(char **cmdline_p)
 
 	kasan_init();
 
+#ifdef CONFIG_X86_32
+	/* sync back kernel address range */
+	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
+
+	/*
+	 * sync back low identity map too.  It is used for example
+	 * in the 32-bit EFI stub.
+	 */
+	clone_pgd_range(initial_page_table,
+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
+			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
+#endif
+
 	tboot_probe();
 
 	map_vsyscall();

commit d3b5d35290d729a2518af00feca867385a1b08fa
Merge: aa2a4b6569d5 71389703839e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 23:54:56 2017 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm updates from Ingo Molnar:
     "The main x86 MM changes in this cycle were:
    
       - continued native kernel PCID support preparation patches to the TLB
         flushing code (Andy Lutomirski)
    
       - various fixes related to 32-bit compat syscall returning address
         over 4Gb in applications, launched from 64-bit binaries - motivated
         by C/R frameworks such as Virtuozzo. (Dmitry Safonov)
    
       - continued Intel 5-level paging enablement: in particular the
         conversion of x86 GUP to the generic GUP code. (Kirill A. Shutemov)
    
       - x86/mpx ABI corner case fixes/enhancements (Joerg Roedel)
    
       - ... plus misc updates, fixes and cleanups"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (62 commits)
      mm, zone_device: Replace {get, put}_zone_device_page() with a single reference to fix pmem crash
      x86/mm: Fix flush_tlb_page() on Xen
      x86/mm: Make flush_tlb_mm_range() more predictable
      x86/mm: Remove flush_tlb() and flush_tlb_current_task()
      x86/vm86/32: Switch to flush_tlb_mm_range() in mark_screen_rdonly()
      x86/mm/64: Fix crash in remove_pagetable()
      Revert "x86/mm/gup: Switch GUP to the generic get_user_page_fast() implementation"
      x86/boot/e820: Remove a redundant self assignment
      x86/mm: Fix dump pagetables for 4 levels of page tables
      x86/mpx, selftests: Only check bounds-vs-shadow when we keep shadow
      x86/mpx: Correctly report do_mpx_bt_fault() failures to user-space
      Revert "x86/mm/numa: Remove numa_nodemask_from_meminfo()"
      x86/espfix: Add support for 5-level paging
      x86/kasan: Extend KASAN to support 5-level paging
      x86/mm: Add basic defines/helpers for CONFIG_X86_5LEVEL=y
      x86/paravirt: Add 5-level support to the paravirt code
      x86/mm: Define virtual memory map for 5-level paging
      x86/asm: Remove __VIRTUAL_MASK_SHIFT==47 assert
      x86/boot: Detect 5-level paging support
      x86/mm/numa: Remove numa_nodemask_from_meminfo()
      ...

commit 7d6a31c394722c914c61292b457e1999c8bef5ea
Merge: 2cc12e2e8cb6 1b326277798a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 23:00:21 2017 -0700

    Merge branch 'x86-debug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 debug updates from Ingo Molnar:
     "The biggest update is the addition of USB3 debug port based
      early-console.
    
      Greg was fine with the USB changes and with the routing of these
      patches:
    
        https://www.spinics.net/lists/linux-usb/msg155093.html"
    
    * 'x86-debug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      usb/doc: Add document for USB3 debug port usage
      usb/serial: Add DBC debug device support to usb_debug
      x86/earlyprintk: Add support for earlyprintk via USB3 debug port
      usb/early: Add driver for xhci debug capability
      x86/timers: Add simple udelay calibration

commit a52bbaf4a3b81e07430a91ee37ea76557c2c02ed
Merge: 16b76293c5c8 4797b7dfdfcf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 21:15:50 2017 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cpu updates from Ingo Molnar:
     "The biggest changes are an extension of the Intel RDT code to extend
      it with Intel Memory Bandwidth Allocation CPU support: MBA allows
      bandwidth allocation between cores, while CBM (already upstream)
      allows CPU cache partitioning.
    
      There's also misc smaller fixes and updates"
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      x86/intel_rdt: Return error for incorrect resource names in schemata
      x86/intel_rdt: Trim whitespace while parsing schemata input
      x86/intel_rdt: Fix padding when resource is enabled via mount
      x86/intel_rdt: Get rid of anon union
      x86/cpu: Keep model defines sorted by model number
      x86/intel_rdt/mba: Add schemata file support for MBA
      x86/intel_rdt: Make schemata file parsers resource specific
      x86/intel_rdt/mba: Add info directory files for Memory Bandwidth Allocation
      x86/intel_rdt: Make information files resource specific
      x86/intel_rdt/mba: Add primary support for Memory Bandwidth Allocation (MBA)
      x86/intel_rdt/mba: Memory bandwith allocation feature detect
      x86/intel_rdt: Add resource specific msr update function
      x86/intel_rdt: Move CBM specific data into a struct
      x86/intel_rdt: Cleanup namespace to support multiple resource types
      Documentation, x86: Intel Memory bandwidth allocation
      x86/intel_rdt: Organize code properly
      x86/intel_rdt: Init padding only if a device exists
      x86/intel_rdt: Add cpus_list rdtgroup file
      x86/intel_rdt: Cleanup kernel-doc
      x86/intel_rdt: Update schemata read to show data in tabular format
      ...

commit e5185a76a23b2d56fb2327ad8bd58fb1bcaa52b1
Merge: b678c91aefa7 4729277156cf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Apr 11 08:56:05 2017 +0200

    Merge branch 'x86/boot' into x86/mm, to avoid conflict
    
    There's a conflict between ongoing level-5 paging support and
    the E820 rewrite. Since the E820 rewrite is essentially ready,
    merge it into x86/mm to reduce tree conflicts.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 73fa1362a7f337d149f76d26b6c6845cb38c1af9
Merge: fdd3d8ce0ea6 6415813bae75
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Mar 30 09:07:54 2017 +0200

    Merge branch 'x86/cpu' into x86/mm, before applying dependent patch
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 23b2a4ddebdd17fad265b4bb77256c2e4ec37dee
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Mar 22 14:32:32 2017 -0700

    x86/boot/32: Defer resyncing initial_page_table until per-cpu is set up
    
    The x86 smpboot trampoline expects initial_page_table to have the
    GDT mapped.  If the GDT ends up in a virtually mapped per-cpu page,
    then it won't be in the page tables at all until perc-pu areas are
    set up.  The result will be a triple fault the first time that the
    CPU attempts to access the GDT after LGDT loads the perc-pu GDT.
    
    This appears to be an old bug, but somehow the GDT fixmap rework
    is triggering it.  This seems to have something to do with the
    memory layout.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Garnier <thgarnie@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/a553264a5972c6a86f9b5caac237470a0c74a720.1490218061.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4bf0c8926a1c..56b1177155db 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1226,21 +1226,6 @@ void __init setup_arch(char **cmdline_p)
 
 	kasan_init();
 
-#ifdef CONFIG_X86_32
-	/* sync back kernel address range */
-	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
-			KERNEL_PGD_PTRS);
-
-	/*
-	 * sync back low identity map too.  It is used for example
-	 * in the 32-bit EFI stub.
-	 */
-	clone_pgd_range(initial_page_table,
-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
-			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
-#endif
-
 	tboot_probe();
 
 	map_vsyscall();

commit 1b5aeebf3a92273b4d85aeff37a16037bc3c3abf
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Tue Mar 21 16:01:31 2017 +0800

    x86/earlyprintk: Add support for earlyprintk via USB3 debug port
    
    Add support for earlyprintk by writing debug messages to the
    USB3 debug port. Users can use this type of early printk by
    specifying the kernel parameter of "earlyprintk=xdbc". This
    gives users a chance of providing debugging output.
    
    The hardware for USB3 debug port requires DMA memory blocks.
    This requires to delay setting up debugging hardware and
    registering boot console until the memblocks are filled.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathias Nyman <mathias.nyman@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: linux-usb@vger.kernel.org
    Link: http://lkml.kernel.org/r/1490083293-3792-4-git-send-email-baolu.lu@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e70204e13e48..2600b1d0043b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -70,6 +70,7 @@
 #include <linux/tboot.h>
 #include <linux/jiffies.h>
 
+#include <linux/usb/xhci-dbgp.h>
 #include <video/edid.h>
 
 #include <asm/mtrr.h>
@@ -1144,6 +1145,9 @@ void __init setup_arch(char **cmdline_p)
 	memblock_set_current_limit(ISA_END_ADDRESS);
 	memblock_x86_fill();
 
+	if (!early_xdbc_setup_hardware())
+		early_xdbc_register_console();
+
 	reserve_bios_regions();
 
 	if (efi_enabled(EFI_MEMMAP)) {

commit dd759d93f4dd4fd2f345a78ad1223bb3edf3ee7b
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Tue Mar 21 16:01:29 2017 +0800

    x86/timers: Add simple udelay calibration
    
    Add a simple udelay calibration in x86 architecture-specific
    boot-time initializations. This will get a workable estimate
    for loops_per_jiffy. Hence, udelay() could be used after this
    initialization.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathias Nyman <mathias.nyman@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: linux-usb@vger.kernel.org
    Link: http://lkml.kernel.org/r/1490083293-3792-2-git-send-email-baolu.lu@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4bf0c8926a1c..e70204e13e48 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -837,6 +837,26 @@ dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 	return 0;
 }
 
+static void __init simple_udelay_calibration(void)
+{
+	unsigned int tsc_khz, cpu_khz;
+	unsigned long lpj;
+
+	if (!boot_cpu_has(X86_FEATURE_TSC))
+		return;
+
+	cpu_khz = x86_platform.calibrate_cpu();
+	tsc_khz = x86_platform.calibrate_tsc();
+
+	tsc_khz = tsc_khz ? : cpu_khz;
+	if (!tsc_khz)
+		return;
+
+	lpj = tsc_khz * 1000;
+	do_div(lpj, HZ);
+	loops_per_jiffy = lpj;
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -985,6 +1005,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	x86_configure_nx();
 
+	simple_udelay_calibration();
+
 	parse_early_param();
 
 #ifdef CONFIG_MEMORY_HOTPLUG

commit 6415813bae75feba10b8ca3ed6634a72c2a4d313
Author: Mathias Krause <minipli@googlemail.com>
Date:   Sun Feb 12 22:12:08 2017 +0100

    x86/cpu: Drop wp_works_ok member of struct cpuinfo_x86
    
    Remove the wp_works_ok member of struct cpuinfo_x86. It's an
    optimization back from Linux v0.99 times where we had no fixup support
    yet and did the CR0.WP test via special code in the page fault handler.
    The < 0 test was an optimization to not do the special casing for each
    NULL ptr access violation but just for the first one doing the WP test.
    Today it serves no real purpose as the test no longer needs special code
    in the page fault handler and the only call side -- mem_init() -- calls
    it just once, anyway. However, Xen pre-initializes it to 1, to skip the
    test.
    
    Doing the test again for Xen should be no issue at all, as even the
    commit introducing skipping the test (commit d560bc61575e ("x86, xen:
    Suppress WP test on Xen")) mentioned it being ban aid only. And, in
    fact, testing the patch on Xen showed nothing breaks.
    
    The pre-fixup times are long gone and with the removal of the fallback
    handling code in commit a5c2a893dbd4 ("x86, 386 removal: Remove
    CONFIG_X86_WP_WORKS_OK") the kernel requires a working CR0.WP anyway.
    So just get rid of the "optimization" and do the test unconditionally.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Acked-by: Borislav Petkov <bp@alien8.de>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Arnd Hannemann <hannemann@nets.rwth-aachen.de>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Link: http://lkml.kernel.org/r/1486933932-585-3-git-send-email-minipli@googlemail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4bf0c8926a1c..7cd7bbefd418 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -173,14 +173,11 @@ static struct resource bss_resource = {
 
 
 #ifdef CONFIG_X86_32
-/* cpu data as detected by the assembly code in head.S */
-struct cpuinfo_x86 new_cpu_data = {
-	.wp_works_ok = -1,
-};
+/* cpu data as detected by the assembly code in head_32.S */
+struct cpuinfo_x86 new_cpu_data;
+
 /* common cpu data for all cpus */
-struct cpuinfo_x86 boot_cpu_data __read_mostly = {
-	.wp_works_ok = -1,
-};
+struct cpuinfo_x86 boot_cpu_data __read_mostly;
 EXPORT_SYMBOL(boot_cpu_data);
 
 unsigned int def_to_bigsmp;

commit 0871d5a66da5c41151e0896a90298b163e42f2e0
Merge: e22af0be2cf6 2d6be4abf514
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Mar 1 09:02:26 2017 +0100

    Merge branch 'linus' into WIP.x86/boot, to fix up conflicts and to pick up updates
    
     Conflicts:
            arch/x86/xen/setup.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit f89db789de2157441d3b5e879a742437ed69cbbc
Merge: 65314ed08e9c 8312593a5594
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 28 11:46:00 2017 -0800

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fixes from Ingo Molnar:
     "Two documentation updates, plus a debugging annotation fix"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/crash: Update the stale comment in reserve_crashkernel()
      x86/irq, trace: Add __irq_entry annotation to x86's platform IRQ handlers
      Documentation, x86, resctrl: Recommend locking for resctrlfs

commit 9661b332041dab63ba2e5222b40a9f916c1368a9
Author: David Howells <dhowells@redhat.com>
Date:   Mon Feb 6 11:22:45 2017 +0000

    efi: Print the secure boot status in x86 setup_arch()
    
    Print the secure boot status in the x86 setup_arch() function, but otherwise do
    nothing more for now. More functionality will be added later, but this at
    least allows for testing.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    [ Use efi_enabled() instead of IS_ENABLED(CONFIG_EFI). ]
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1486380166-31868-7-git-send-email-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4cfba947d774..69780edf0dde 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1176,6 +1176,20 @@ void __init setup_arch(char **cmdline_p)
 	/* Allocate bigger log buffer */
 	setup_log_buf(1);
 
+	if (efi_enabled(EFI_BOOT)) {
+		switch (boot_params.secure_boot) {
+		case efi_secureboot_mode_disabled:
+			pr_info("Secure boot disabled\n");
+			break;
+		case efi_secureboot_mode_enabled:
+			pr_info("Secure boot enabled\n");
+			break;
+		default:
+			pr_info("Secure boot could not be determined\n");
+			break;
+		}
+	}
+
 	reserve_initrd();
 
 	acpi_table_upgrade();

commit 0c6fc11ac343c82d4a2f8348fa6f829e07c12554
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 22:52:16 2017 +0100

    x86/boot/e820: Rename the remaining E820 APIs to the e820__*() prefix
    
    Three more renames left:
    
       e820_end_of_ram_pfn()      =>  e820__end_of_ram_pfn()
       e820_end_of_low_ram_pfn()  =>  e820__end_of_low_ram_pfn()
       e820_reallocate_tables()   =>  e820__reallocate_tables()
    
    After this all E820 API calls are prefixed with "e820__", making
    it much easier to grep for E820 functionality in the kernel.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0e0b15b53c69..a1114ffff0f5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1044,12 +1044,12 @@ void __init setup_arch(char **cmdline_p)
 	 * partially used pages are not usable - thus
 	 * we are rounding upwards:
 	 */
-	max_pfn = e820_end_of_ram_pfn();
+	max_pfn = e820__end_of_ram_pfn();
 
 	/* update e820 for memory not covered by WB MTRRs */
 	mtrr_bp_init();
 	if (mtrr_trim_uncached_memory(max_pfn))
-		max_pfn = e820_end_of_ram_pfn();
+		max_pfn = e820__end_of_ram_pfn();
 
 	max_possible_pfn = max_pfn;
 
@@ -1068,7 +1068,7 @@ void __init setup_arch(char **cmdline_p)
 	/* How many end-of-memory variables you have, grandma! */
 	/* need this before calling reserve_initrd */
 	if (max_pfn > (1UL<<(32 - PAGE_SHIFT)))
-		max_low_pfn = e820_end_of_low_ram_pfn();
+		max_low_pfn = e820__end_of_low_ram_pfn();
 	else
 		max_low_pfn = max_pfn;
 

commit 090d717164eec7d7bf7c0db396a123e1f9157dbf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 22:44:12 2017 +0100

    x86/boot/e820: Rename e820_mark_nosave_regions() to e820__register_nosave_regions()
    
    This function is a minor misnomer: it is talking about 'marking' regions
    as nosave - while the hibernation API is called register_nosave_region()
    and the e820_mark_nosave_regions() is a wrapper around that functionality.
    
    So name it to be in line with the API it is derived from.
    
    ( Rename e820_mark_nvs_memory() to e820__register_nvs_regions(), for similar
      reasons. )
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 34b16fcef131..0e0b15b53c69 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1236,7 +1236,7 @@ void __init setup_arch(char **cmdline_p)
 	kvm_guest_init();
 
 	e820__reserve_resources();
-	e820_mark_nosave_regions(max_low_pfn);
+	e820__register_nosave_regions(max_low_pfn);
 
 	x86_init.resources.reserve_resources();
 

commit 1506c8dc947251bfd02f8186b5e81657a9635112
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 22:41:14 2017 +0100

    x86/boot/e820: Rename e820_reserve_resources*() to e820__reserve_resources*()
    
    Also do some minor cleanups.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4ac8ae8a7573..34b16fcef131 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1235,7 +1235,7 @@ void __init setup_arch(char **cmdline_p)
 
 	kvm_guest_init();
 
-	e820_reserve_resources();
+	e820__reserve_resources();
 	e820_mark_nosave_regions(max_low_pfn);
 
 	x86_init.resources.reserve_resources();

commit 1a1270349a0710162a160eef4f2e360845e0f47d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 22:27:28 2017 +0100

    x86/boot/e820: Document e820__reserve_setup_data()
    
    Also clean it up a bit.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index acb2db02ec81..4ac8ae8a7573 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1003,8 +1003,7 @@ void __init setup_arch(char **cmdline_p)
 		early_dump_pci_devices();
 #endif
 
-	/* update the e820_table_firmware too */
-	e820_reserve_setup_data();
+	e820__reserve_setup_data();
 	e820__finish_early_params();
 
 	if (efi_enabled(EFI_BOOT))

commit f9748fa045851041ba69a1d2899971746f29c9d5
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 18:00:35 2017 +0100

    x86/boot/e820: Simplify the e820__update_table() interface
    
    The e820__update_table() parameters are pretty complex:
    
      arch/x86/include/asm/e820/api.h:extern int  e820__update_table(struct e820_entry *biosmap, int max_nr_map, u32 *pnr_map);
    
    But 90% of the usage is trivial:
    
      arch/x86/kernel/e820.c:       if (e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries))
      arch/x86/kernel/e820.c:       e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/kernel/e820.c:       e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/kernel/e820.c:               if (e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries) < 0)
      arch/x86/kernel/e820.c:       e820__update_table(boot_params.e820_table, ARRAY_SIZE(boot_params.e820_table), &new_nr);
      arch/x86/kernel/early-quirks.c:       e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/kernel/setup.c:      e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/kernel/setup.c:              e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/platform/efi/efi.c:  e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/xen/setup.c: e820__update_table(xen_e820_table.entries, ARRAY_SIZE(xen_e820_table.entries),
      arch/x86/xen/setup.c: e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
      arch/x86/xen/setup.c: e820__update_table(xen_e820_table.entries, ARRAY_SIZE(xen_e820_table.entries),
    
    as it only uses an exiting struct e820_table's entries array, its size and
    its current number of entries as input and output arguments.
    
    Only one use is non-trivial:
    
      arch/x86/kernel/e820.c:       e820__update_table(boot_params.e820_table, ARRAY_SIZE(boot_params.e820_table), &new_nr);
    
    ... which call updates the E820 table in the zeropage in-situ, and the layout there does not
    match that of 'struct e820_table' (in particular nr_entries is at a different offset,
    hardcoded by the boot protocol).
    
    Simplify all this by introducing a low level __e820__update_table() API that
    the zeropage update call can use, and simplifying the main e820__update_table()
    call signature down to:
    
            int e820__update_table(struct e820_table *table);
    
    This visibly simplifies all the call sites:
    
      arch/x86/include/asm/e820/api.h:extern int  e820__update_table(struct e820_table *table);
      arch/x86/include/asm/e820/types.h: * call to e820__update_table() to remove duplicates.  The allowance
      arch/x86/kernel/e820.c: * The return value from e820__update_table() is zero if it
      arch/x86/kernel/e820.c:int __init e820__update_table(struct e820_table *table)
      arch/x86/kernel/e820.c:       if (e820__update_table(e820_table))
      arch/x86/kernel/e820.c:       e820__update_table(e820_table_firmware);
      arch/x86/kernel/e820.c:       e820__update_table(e820_table);
      arch/x86/kernel/e820.c:       e820__update_table(e820_table);
      arch/x86/kernel/e820.c:               if (e820__update_table(e820_table) < 0)
      arch/x86/kernel/early-quirks.c:       e820__update_table(e820_table);
      arch/x86/kernel/setup.c:      e820__update_table(e820_table);
      arch/x86/kernel/setup.c:              e820__update_table(e820_table);
      arch/x86/platform/efi/efi.c:  e820__update_table(e820_table);
      arch/x86/xen/setup.c: e820__update_table(&xen_e820_table);
      arch/x86/xen/setup.c: e820__update_table(e820_table);
      arch/x86/xen/setup.c: e820__update_table(&xen_e820_table);
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 074c86a0ee86..acb2db02ec81 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -740,7 +740,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820__range_remove(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_TYPE_RAM, 1);
 
-	e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
+	e820__update_table(e820_table);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1033,7 +1033,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820__range_update(0x70000000ULL, 0x40000ULL, E820_TYPE_RAM,
 				  E820_TYPE_RESERVED);
-		e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
+		e820__update_table(e820_table);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820__print_table("bad_ppro");
 	}

commit 09821ff1d50a1ecade182c2a68a90f835e257eef
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 17:09:33 2017 +0100

    x86/boot/e820: Prefix the E820_* type names with "E820_TYPE_"
    
    So there's a number of constants that start with "E820" but which
    are not types - these create a confusing mixture when seen together
    with 'enum e820_type' values:
    
            E820MAP
            E820NR
            E820_X_MAX
            E820MAX
    
    To better differentiate the 'enum e820_type' values prefix them
    with E820_TYPE_.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0e70a7bbeeef..074c86a0ee86 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -119,7 +119,7 @@
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
  * max_pfn_mapped:     highest direct mapped pfn over 4GB
  *
- * The direct mapping only covers E820_RAM regions, so the ranges and gaps are
+ * The direct mapping only covers E820_TYPE_RAM regions, so the ranges and gaps are
  * represented by pfn_mapped
  */
 unsigned long max_low_pfn_mapped;
@@ -731,14 +731,14 @@ static void __init trim_bios_range(void)
 	 * since some BIOSes are known to corrupt low memory.  See the
 	 * Kconfig help text for X86_RESERVE_LOW.
 	 */
-	e820__range_update(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
+	e820__range_update(0, PAGE_SIZE, E820_TYPE_RAM, E820_TYPE_RESERVED);
 
 	/*
 	 * special case: Some BIOSen report the PC BIOS
 	 * area (640->1Mb) as ram even though it is not.
 	 * take them out.
 	 */
-	e820__range_remove(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
+	e820__range_remove(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_TYPE_RAM, 1);
 
 	e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 }
@@ -750,18 +750,18 @@ static void __init e820_add_kernel_range(void)
 	u64 size = __pa_symbol(_end) - start;
 
 	/*
-	 * Complain if .text .data and .bss are not marked as E820_RAM and
+	 * Complain if .text .data and .bss are not marked as E820_TYPE_RAM and
 	 * attempt to fix it by adding the range. We may have a confused BIOS,
 	 * or the user may have used memmap=exactmap or memmap=xxM$yyM to
 	 * exclude kernel range. If we really are running on top non-RAM,
 	 * we will crash later anyways.
 	 */
-	if (e820__mapped_all(start, start + size, E820_RAM))
+	if (e820__mapped_all(start, start + size, E820_TYPE_RAM))
 		return;
 
-	pr_warn(".text .data .bss are not marked as E820_RAM!\n");
-	e820__range_remove(start, size, E820_RAM, 0);
-	e820__range_add(start, size, E820_RAM);
+	pr_warn(".text .data .bss are not marked as E820_TYPE_RAM!\n");
+	e820__range_remove(start, size, E820_TYPE_RAM, 0);
+	e820__range_add(start, size, E820_TYPE_RAM);
 }
 
 static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
@@ -1031,8 +1031,8 @@ void __init setup_arch(char **cmdline_p)
 	trim_bios_range();
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {
-		e820__range_update(0x70000000ULL, 0x40000ULL, E820_RAM,
-				  E820_RESERVED);
+		e820__range_update(0x70000000ULL, 0x40000ULL, E820_TYPE_RAM,
+				  E820_TYPE_RESERVED);
 		e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820__print_table("bad_ppro");

commit be0c3f0fcade7ad67f484fa5dc00310813de6d7d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 14:24:02 2017 +0100

    x86/boot/e820: Rename e820_print_map() to e820__print_table()
    
    All other table-level methods are already named 'table' in some way,
    to change this one over to the (now consistent) nomenclature.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2449df3c0044..0e70a7bbeeef 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1035,7 +1035,7 @@ void __init setup_arch(char **cmdline_p)
 				  E820_RESERVED);
 		e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 		printk(KERN_INFO "fixed physical RAM map:\n");
-		e820_print_map("bad_ppro");
+		e820__print_table("bad_ppro");
 	}
 #else
 	early_gart_iommu_check();

commit ab6bc04cfdbd5da00a85909c054770a606e7c804
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 14:19:36 2017 +0100

    x86/boot/e820: Create coherent API function names for E820 range operations
    
    We have these three related functions:
    
     extern void e820_add_region(u64 start, u64 size, int type);
     extern u64  e820_update_range(u64 start, u64 size, unsigned old_type, unsigned new_type);
     extern u64  e820_remove_range(u64 start, u64 size, unsigned old_type, int checktype);
    
    But it's not clear from the naming that they are 3 operations based around the
    same 'memory range' concept. Rename them to better signal this, and move
    the prototypes next to each other:
    
     extern void e820__range_add   (u64 start, u64 size, int type);
     extern u64  e820__range_update(u64 start, u64 size, unsigned old_type, unsigned new_type);
     extern u64  e820__range_remove(u64 start, u64 size, unsigned old_type, int checktype);
    
    Note that this improved organization of the functions shows another problem that was easy
    to miss before: sometimes the E820 entry type is 'int', sometimes 'unsigned int' - but this
    will be fixed in a separate patch.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fd7c0ef2716..2449df3c0044 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -731,14 +731,14 @@ static void __init trim_bios_range(void)
 	 * since some BIOSes are known to corrupt low memory.  See the
 	 * Kconfig help text for X86_RESERVE_LOW.
 	 */
-	e820_update_range(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
+	e820__range_update(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
 
 	/*
 	 * special case: Some BIOSen report the PC BIOS
 	 * area (640->1Mb) as ram even though it is not.
 	 * take them out.
 	 */
-	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
+	e820__range_remove(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
 	e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 }
@@ -760,8 +760,8 @@ static void __init e820_add_kernel_range(void)
 		return;
 
 	pr_warn(".text .data .bss are not marked as E820_RAM!\n");
-	e820_remove_range(start, size, E820_RAM, 0);
-	e820_add_region(start, size, E820_RAM);
+	e820__range_remove(start, size, E820_RAM, 0);
+	e820__range_add(start, size, E820_RAM);
 }
 
 static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
@@ -1031,7 +1031,7 @@ void __init setup_arch(char **cmdline_p)
 	trim_bios_range();
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {
-		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
+		e820__range_update(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
 		e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 		printk(KERN_INFO "fixed physical RAM map:\n");

commit 2df908baf52ccf8eaabe5576d1ecb2f972b1135f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 14:16:38 2017 +0100

    x86/boot/e820: Rename e820_setup_gap() to e820__setup_pci_gap()
    
    The e820_setup_gap() function name is unnecessarily silent about what
    kind of gap it sets up. Make it clear that it's about the PCI gap.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5ea90a2b3709..0fd7c0ef2716 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1241,7 +1241,7 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.resources.reserve_resources();
 
-	e820_setup_gap();
+	e820__setup_pci_gap();
 
 #ifdef CONFIG_VT
 #if defined(CONFIG_VGA_CONSOLE)

commit 3bce64f019a801f526cc38523c77ffda4e846155
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 14:14:25 2017 +0100

    x86/boot/e820: Rename e820_any_mapped()/e820_all_mapped() to e820__mapped_any()/e820__mapped_all()
    
    The 'any' and 'all' are modified to the 'mapped' concept, so move them last in the name.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e8ec0c693a77..5ea90a2b3709 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -756,7 +756,7 @@ static void __init e820_add_kernel_range(void)
 	 * exclude kernel range. If we really are running on top non-RAM,
 	 * we will crash later anyways.
 	 */
-	if (e820_all_mapped(start, start + size, E820_RAM))
+	if (e820__mapped_all(start, start + size, E820_RAM))
 		return;
 
 	pr_warn(".text .data .bss are not marked as E820_RAM!\n");

commit f52355a99fc06f609ca6a61098d78e476d56f526
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 14:09:20 2017 +0100

    x86/boot/e820: Rename sanitize_e820_table() to e820__update_table()
    
    sanitize_e820_table() is a minor misnomer in that it suggests that
    the E820 table requires sanitizing - which implies that it will only
    do anything if the E820 table is irregular (not sane).
    
    That is wrong, because sanitize_e820_table() also does a very regular
    sorting of the E820 table, which is a necessity in the basic
    append-only flow of E820 updates the kernel is allowed to perform to
    it.
    
    So rename it to e820__update_table() to include that purpose as well.
    
    This also lines up all the table-update functions into a coherent
    naming family:
    
      int  e820__update_table(struct e820_entry *biosmap, int max_nr_map, u32 *pnr_map);
    
      void e820__update_table_print(void);
      void e820__update_table_firmware(void);
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a31c5bc99635..e8ec0c693a77 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -740,7 +740,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
-	sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
+	e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1033,7 +1033,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
-		sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
+		e820__update_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820_print_map("bad_ppro");
 	}

commit 5da217ca967b9d7a0bbbd8edd06749c99a4fe501
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 13:46:28 2017 +0100

    x86/boot/e820: Rename early_reserve_e820() to e820__memblock_alloc() and document it
    
    early_reserve_e820() is an early hack for kexec that does a limited fixup of the
    mptable and passes it to the kexec kernel as if it was the real thing.
    
    For this it needs to allocate memory - but no memory allocator is available yet
    beyond the memblock allocator, so early_reserve_e820() is really a wrapper
    around memblock_alloc() plus a hack to update the e820_table_firmware entries.
    
    The name 'reserve' is really a bit of a misnomer, as 'reserved' memory typically
    means memory completely inaccessible to the kernel - while here what we want to do
    is a special RAM allocation for our own purposes and insert that as RAM_RESERVED.
    
    Rename the function to e820__memblock_alloc_reserved() to better signal this dual
    purpose, plus document it better, which was omitted when it was merged. The barely
    comprehensible and cryptic comment:
    
      /*
       * pre allocated 4k and reserved it in memblock and e820_table_firmware
       */
      u64 __init e820__memblock_alloc_reserved(u64 size, u64 align)
    
    ... does not count as documentation, replace it with:
    
      /*
       * Allocate the requested number of bytes with the requsted alignment
       * and return (the physical address) to the caller. Also register this
       * range in the 'firmware' E820 table.
       *
       * This allows kexec to fake a new mptable, as if it came from the real
       * system.
       */
      u64 __init e820__memblock_alloc_reserved(u64 size, u64 align)
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a121e01d8a4d..a31c5bc99635 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1112,7 +1112,7 @@ void __init setup_arch(char **cmdline_p)
 	}
 
 	/* preallocate 4k for mptable mpc */
-	early_reserve_e820_mpc_new();
+	e820__memblock_alloc_reserved_mpc_new();
 
 #ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
 	setup_bios_corruption_check();

commit 9641bdafd8571e2d86817935e4e7ffa6fa2c56b6
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 13:37:17 2017 +0100

    x86/boot/e820: Clarify the role of finish_e820_parsing() and rename it to e820__finish_early_params()
    
    finish_e820_parsing() is closely related to parse_early_params(), but the
    name does not tell us this clearly, so rename it to e820__finish_early_params().
    
    Also add a few comments to explain what the function does.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7954159f0d27..a121e01d8a4d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1005,7 +1005,7 @@ void __init setup_arch(char **cmdline_p)
 
 	/* update the e820_table_firmware too */
 	e820_reserve_setup_data();
-	finish_e820_parsing();
+	e820__finish_early_params();
 
 	if (efi_enabled(EFI_BOOT))
 		efi_init();

commit da92139bff5fb334981d56225d3d80e73125b51f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 13:25:45 2017 +0100

    x86/boot/e820: Move e820_reserve_setup_data() to e820.c
    
    The e820_reserve_setup_data() is local to arch/x86/kernel/setup.c,
    but it is E820 functionality - so move it to e820.c to better
    isolate E820 functionality.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4451c3a818db..7954159f0d27 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -441,29 +441,6 @@ static void __init parse_setup_data(void)
 	}
 }
 
-static void __init e820_reserve_setup_data(void)
-{
-	struct setup_data *data;
-	u64 pa_data;
-
-	pa_data = boot_params.hdr.setup_data;
-	if (!pa_data)
-		return;
-
-	while (pa_data) {
-		data = early_memremap(pa_data, sizeof(*data));
-		e820_update_range(pa_data, sizeof(*data)+data->len,
-			 E820_RAM, E820_RESERVED_KERN);
-		pa_data = data->next;
-		early_memunmap(data, sizeof(*data));
-	}
-
-	sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
-	memcpy(e820_table_firmware, e820_table, sizeof(struct e820_table));
-	printk(KERN_INFO "extended physical RAM map:\n");
-	e820_print_map("reserve setup_data");
-}
-
 static void __init memblock_x86_reserve_range_setup_data(void)
 {
 	struct setup_data *data;

commit 914053c08e95b2577d5834d51d5962c922ad0a72
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 13:18:40 2017 +0100

    x86/boot/e820: Rename parse_e820_ext() to e820__memory_setup_extended()
    
    parse_e820_ext() is very similar to e820__memory_setup_default(), both are
    taking bootloader provided data, add it to the E820 table and then
    pass it sanitize_e820_table().
    
    Rename it to e820__memory_setup_extended() to better signal their similar role.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 838e4b5707ae..4451c3a818db 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -426,7 +426,7 @@ static void __init parse_setup_data(void)
 
 		switch (data_type) {
 		case SETUP_E820_EXT:
-			parse_e820_ext(pa_data, data_len);
+			e820__memory_setup_extended(pa_data, data_len);
 			break;
 		case SETUP_DTB:
 			add_dtb(pa_data);

commit 4918e2286d0c023ee29c1f6d4e6d45e1aa420408
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 11:37:42 2017 +0100

    x86/boot/e820: Rename memblock_x86_fill() to e820__memblock_setup() and improve the explanations
    
    So memblock_x86_fill() is another E820 code misnomer:
    
     - nothing in its name tells us that it's part of the E820 subsystem ...
    
     - The 'fill' wording is ambiguous and doesn't tell us whether it's a single
       entry or some process - while the _real_ purpose of the function is hidden,
       which is to do a complete setup of the (platform independent) memblock regions.
    
    So rename it accordingly, to e820__memblock_setup().
    
    Also translate this incomprehensible and misleading comment:
    
            /*
             * EFI may have more than 128 entries
             * We are safe to enable resizing, beause memblock_x86_fill()
             * is rather later for x86
             */
            memblock_allow_resize();
    
    The worst aspect of this comment isn't even the sloppy typos, but that it
    casually mentions a '128' number with no explanation, which makes one lead
    to the assumption that this is related to the well-known limit of a maximum
    of 128 E820 entries passed via legacy bootloaders.
    
    But no, the _real_ meaning of 128 here is that of the memblock subsystem,
    which too happens to have a 128 entries limit for very early memblock
    regions (which is unrelated to E820), via INIT_MEMBLOCK_REGIONS ...
    
    So change the comment to a more comprehensible version:
    
            /*
             * The bootstrap memblock region count maximum is 128 entries
             * (INIT_MEMBLOCK_REGIONS), but EFI might pass us more E820 entries
             * than that - so allow memblock resizing.
             *
             * This is safe, because this call happens pretty late during x86 setup,
             * so we know about reserved memory regions already. (This is important
             * so that memblock resizing does no stomp over reserved areas.)
             */
            memblock_allow_resize();
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f905430d7b04..838e4b5707ae 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1109,7 +1109,7 @@ void __init setup_arch(char **cmdline_p)
 	early_alloc_pgt_buf();
 
 	/*
-	 * Need to conclude brk, before memblock_x86_fill()
+	 * Need to conclude brk, before e820__memblock_setup()
 	 *  it could use memblock_find_in_range, could overlap with
 	 *  brk area.
 	 */
@@ -1118,7 +1118,7 @@ void __init setup_arch(char **cmdline_p)
 	cleanup_highmap();
 
 	memblock_set_current_limit(ISA_END_ADDRESS);
-	memblock_x86_fill();
+	e820__memblock_setup();
 
 	reserve_bios_regions();
 

commit 544a0f47e7803443980496d6c9ae78b6c2b3dbcb
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 10:07:49 2017 +0100

    x86/boot/e820: Rename e820_table_saved to e820_table_firmware and improve the description
    
    So the 'e820_table_saved' is a bit of a misnomer that hides its real purpose.
    
    At first sight the name suggests that it's some sort save/restore mechanism,
    as this is how we typically name such facilities in the kernel.
    
    But that is not so, e820_table_saved is the original firmware version of the
    e820 table, not modified by the kernel. This table is displayed in the
    /sys/firmware/memmap file, and it's also used by the hibernation code to
    calculate a physical memory layout MD5 fingerprint checksum which is
    invariant of the kernel.
    
    So rename it to 'e820_table_firmware' and update all the comments to better
    describe the main e820 data strutures.
    
    Also rename:
    
      'initial_e820_table_saved'  =>  'e820_table_firmware_init'
      'e820_update_range_saved'   =>  'e820_update_range_firmware'
    
    ... to better match the new nomenclature.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a8d0e388b358..f905430d7b04 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -459,7 +459,7 @@ static void __init e820_reserve_setup_data(void)
 	}
 
 	sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
-	memcpy(e820_table_saved, e820_table, sizeof(struct e820_table));
+	memcpy(e820_table_firmware, e820_table, sizeof(struct e820_table));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }
@@ -1026,7 +1026,7 @@ void __init setup_arch(char **cmdline_p)
 		early_dump_pci_devices();
 #endif
 
-	/* update the e820_table_saved too */
+	/* update the e820_table_firmware too */
 	e820_reserve_setup_data();
 	finish_e820_parsing();
 

commit 103e206309639b615981e56008720806b4a102af
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jan 28 09:58:49 2017 +0100

    x86/boot/e820: Rename default_machine_specific_memory_setup() to e820__memory_setup_default()
    
    The default_machine_specific_memory_setup() is a mouthful and despite the
    many words it doesn't actually tell us clearly what it does.
    
    The function is the x86 legacy memory layout setup code, based on
    E820-formatted memory layout information passed by the bootloader
    via the boot_params.
    
    Rename it to e820__memory_setup_default() to better signal its purpose.
    
    Also rename the related higher level function to be consistent with
    this new naming:
    
        setup_memory_map() => e820__memory_setup()
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c2bb2d143d70..a8d0e388b358 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -937,7 +937,7 @@ void __init setup_arch(char **cmdline_p)
 	x86_init.oem.arch_setup();
 
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
-	setup_memory_map();
+	e820__memory_setup();
 	parse_setup_data();
 
 	copy_edd();

commit bf495573fae84451a8a26215fafb5b62e387ddaf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 14:06:21 2017 +0100

    x86/boot/e820: Harmonize the 'struct e820_table' fields
    
    So the e820_table->map and e820_table->nr_map names are a bit
    confusing, because it's not clear what a 'map' really means
    (it could be a bitmap, or some other data structure), nor is
    it clear what nr_map means (is it a current index, or some
    other count).
    
    Rename the fields from:
    
     e820_table->map        =>     e820_table->entries
     e820_table->nr_map     =>     e820_table->nr_entries
    
    which makes it abundantly clear that these are entries
    of the table, and that the size of the table is ->nr_entries.
    
    Propagate the changes to all affected files. Where necessary,
    adjust local variable names to better reflect the new field names.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a3c1d39116b7..c2bb2d143d70 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -458,7 +458,7 @@ static void __init e820_reserve_setup_data(void)
 		early_memunmap(data, sizeof(*data));
 	}
 
-	sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
+	sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 	memcpy(e820_table_saved, e820_table, sizeof(struct e820_table));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
@@ -763,7 +763,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
-	sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
+	sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1056,7 +1056,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
-		sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
+		sanitize_e820_table(e820_table->entries, ARRAY_SIZE(e820_table->entries), &e820_table->nr_entries);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820_print_map("bad_ppro");
 	}

commit 61a50101638254d38e3f4281265b44de0f2cba4e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 13:54:38 2017 +0100

    x86/boot/e820: Rename everything to e820_table
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a91db2edee9e..a3c1d39116b7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -458,8 +458,8 @@ static void __init e820_reserve_setup_data(void)
 		early_memunmap(data, sizeof(*data));
 	}
 
-	sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
-	memcpy(e820_array_saved, e820_array, sizeof(struct e820_array));
+	sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
+	memcpy(e820_table_saved, e820_table, sizeof(struct e820_table));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }
@@ -763,7 +763,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
-	sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
+	sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1026,7 +1026,7 @@ void __init setup_arch(char **cmdline_p)
 		early_dump_pci_devices();
 #endif
 
-	/* update the e820_array_saved too */
+	/* update the e820_table_saved too */
 	e820_reserve_setup_data();
 	finish_e820_parsing();
 
@@ -1056,7 +1056,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
-		sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
+		sanitize_e820_table(e820_table->map, ARRAY_SIZE(e820_table->map), &e820_table->nr_map);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820_print_map("bad_ppro");
 	}

commit acd4c048728814505fae8e224cf9074bd1ad291e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 13:20:53 2017 +0100

    x86/boot/e820: Rename 'e820_map' variables to 'e820_array'
    
    In line with the rename to 'struct e820_array', harmonize the naming of common e820
    table variable names as well:
    
     e820          =>  e820_array
     e820_saved    =>  e820_array_saved
     e820_map      =>  e820_array
     initial_e820  =>  e820_array_init
    
    This makes the variable names more consistent  and easier to grep for.
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d2bdda9c3d6f..a91db2edee9e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -458,8 +458,8 @@ static void __init e820_reserve_setup_data(void)
 		early_memunmap(data, sizeof(*data));
 	}
 
-	sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
-	memcpy(e820_saved, e820, sizeof(struct e820_array));
+	sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
+	memcpy(e820_array_saved, e820_array, sizeof(struct e820_array));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }
@@ -763,7 +763,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
-	sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
+	sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1026,7 +1026,7 @@ void __init setup_arch(char **cmdline_p)
 		early_dump_pci_devices();
 #endif
 
-	/* update the e820_saved too */
+	/* update the e820_array_saved too */
 	e820_reserve_setup_data();
 	finish_e820_parsing();
 
@@ -1056,7 +1056,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
-		sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
+		sanitize_e820_array(e820_array->map, ARRAY_SIZE(e820_array->map), &e820_array->nr_map);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820_print_map("bad_ppro");
 	}

commit 8ec67d97bff592cc5b5325d1ee3646ebd7d635fc
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 12:54:38 2017 +0100

    x86/boot/e820: Rename the basic e820 data types to 'struct e820_entry' and 'struct e820_array'
    
    The 'e820entry' and 'e820map' names have various annoyances:
    
     - the missing underscore departs from the usual kernel style
       and makes the code look weird,
    
     - in the past I kept confusing the 'map' with the 'entry', because
       a 'map' is ambiguous in that regard,
    
     - it's not really clear from the 'e820map' that this is a regular
       C array.
    
    Rename them to 'struct e820_entry' and 'struct e820_array' accordingly.
    
    ( Leave the legacy UAPI header alone but do the rename in the bootparam.h
      and e820/types.h file - outside tools relying on these defines should
      either adjust their code, or should use the legacy header, or should
      create their private copies for the definitions. )
    
    No change in functionality.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6e521831f6ba..d2bdda9c3d6f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -459,7 +459,7 @@ static void __init e820_reserve_setup_data(void)
 	}
 
 	sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
-	memcpy(e820_saved, e820, sizeof(struct e820map));
+	memcpy(e820_saved, e820, sizeof(struct e820_array));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }

commit 66441bd3cfdcc03816b7009a296c284d70f629e1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 10:27:10 2017 +0100

    x86/boot/e820: Move asm/e820.h to asm/e820/api.h
    
    In line with asm/e820/types.h, move the e820 API declarations to
    asm/e820/api.h and update all usage sites.
    
    This is just a mechanical, obviously correct move & replace patch,
    there will be subsequent changes to clean up the code and to make
    better use of the new header organization.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4cfba947d774..6e521831f6ba 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -75,7 +75,7 @@
 #include <asm/mtrr.h>
 #include <asm/apic.h>
 #include <asm/realmode.h>
-#include <asm/e820.h>
+#include <asm/e820/api.h>
 #include <asm/mpspec.h>
 #include <asm/setup.h>
 #include <asm/efi.h>

commit a8d4c8246b290ce97f88752d833804843041ac84
Author: Xunlei Pang <xlpang@redhat.com>
Date:   Mon Jan 23 14:48:23 2017 +0800

    x86/crash: Update the stale comment in reserve_crashkernel()
    
    CRASH_KERNEL_ADDR_MAX has been missing for a long time,
    update it with a more detailed explanation.
    
    Signed-off-by: Xunlei Pang <xlpang@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Robert LeBlanc <robert@leblancnet.us>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: kexec@lists.infradead.org
    Link: http://lkml.kernel.org/r/1485154103-18426-1-git-send-email-xlpang@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4cfba947d774..eb69b14dbfc8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -575,7 +575,9 @@ static void __init reserve_crashkernel(void)
 	/* 0 means: find the address automatically */
 	if (crash_base <= 0) {
 		/*
-		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
+		 * Set CRASH_ADDR_LOW_MAX upper bound for crash memory,
+		 * as old kexec-tools loads bzImage below that, unless
+		 * "crashkernel=size[KMG],high" is specified.
 		 */
 		crash_base = memblock_find_in_range(CRASH_ALIGN,
 						    high ? CRASH_ADDR_HIGH_MAX

commit 39fa104d5b87655c1c19d4b1990ea63d190c4817
Author: Reza Arbab <arbab@linux.vnet.ibm.com>
Date:   Mon Dec 12 16:42:55 2016 -0800

    mm: remove x86-only restriction of movable_node
    
    In commit c5320926e370 ("mem-hotplug: introduce movable_node boot
    option"), the memblock allocation direction is changed to bottom-up and
    then back to top-down like this:
    
    1. memblock_set_bottom_up(true), called by cmdline_parse_movable_node().
    2. memblock_set_bottom_up(false), called by x86's numa_init().
    
    Even though (1) occurs in generic mm code, it is wrapped by #ifdef
    CONFIG_MOVABLE_NODE, which depends on X86_64.
    
    This means that when we extend CONFIG_MOVABLE_NODE to non-x86 arches,
    things will be unbalanced.  (1) will happen for them, but (2) will not.
    
    This toggle was added in the first place because x86 has a delay between
    adding memblocks and marking them as hotpluggable.  Since other arches
    do this marking either immediately or not at all, they do not require
    the bottom-up toggle.
    
    So, resolve things by moving (1) from cmdline_parse_movable_node() to
    x86's setup_arch(), immediately after the movable_node parameter has
    been parsed.
    
    Link: http://lkml.kernel.org/r/1479160961-25840-3-git-send-email-arbab@linux.vnet.ibm.com
    Signed-off-by: Reza Arbab <arbab@linux.vnet.ibm.com>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Alistair Popple <apopple@au1.ibm.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Bharata B Rao <bharata@linux.vnet.ibm.com>
    Cc: Frank Rowand <frowand.list@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Stewart Smith <stewart@linux.vnet.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9c337b0e8ba7..4cfba947d774 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -985,6 +985,30 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+#ifdef CONFIG_MEMORY_HOTPLUG
+	/*
+	 * Memory used by the kernel cannot be hot-removed because Linux
+	 * cannot migrate the kernel pages. When memory hotplug is
+	 * enabled, we should prevent memblock from allocating memory
+	 * for the kernel.
+	 *
+	 * ACPI SRAT records all hotpluggable memory ranges. But before
+	 * SRAT is parsed, we don't know about it.
+	 *
+	 * The kernel image is loaded into memory at very early time. We
+	 * cannot prevent this anyway. So on NUMA system, we set any
+	 * node the kernel resides in as un-hotpluggable.
+	 *
+	 * Since on modern servers, one node could have double-digit
+	 * gigabytes memory, we can assume the memory around the kernel
+	 * image is also un-hotpluggable. So before SRAT is parsed, just
+	 * allocate memory near the kernel image to try the best to keep
+	 * the kernel away from hotpluggable memory.
+	 */
+	if (movable_node_is_enabled())
+		memblock_set_bottom_up(true);
+#endif
+
 	x86_report_nx();
 
 	/* after early param, so could get panic from serial */

commit 1e90a13d0c3dc94512af1ccb2b6563e8297838fa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Oct 29 13:42:42 2016 +0200

    x86/smpboot: Init apic mapping before usage
    
    The recent changes, which forced the registration of the boot cpu on UP
    systems, which do not have ACPI tables, have been fixed for systems w/o
    local APIC, but left a wreckage for systems which have neither ACPI nor
    mptables, but the CPU has an APIC, e.g. virtualbox.
    
    The boot process crashes in prefill_possible_map() as it wants to register
    the boot cpu, which needs to access the local apic, but the local APIC is
    not yet mapped.
    
    There is no reason why init_apic_mapping() can't be invoked before
    prefill_possible_map(). So instead of playing another silly early mapping
    game, as the ACPI/mptables code does, we just move init_apic_mapping()
    before the call to prefill_possible_map().
    
    In hindsight, I should have noticed that combination earlier.
    
    Sorry for the churn (also in stable)!
    
    Fixes: ff8560512b8d ("x86/boot/smp: Don't try to poke disabled/non-existent APIC")
    Reported-and-debugged-by: Michal Necasek <michal.necasek@oracle.com>
    Reported-and-tested-by: Wolfgang Bauer <wbauer@tmo.at>
    Cc: prarit@redhat.com
    Cc: ville.syrjala@linux.intel.com
    Cc: michael.thayer@oracle.com
    Cc: knut.osmundsen@oracle.com
    Cc: frank.mehnert@oracle.com
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/alpine.DEB.2.20.1610282114380.5053@nanos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bbfbca5fea0c..9c337b0e8ba7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1221,11 +1221,16 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	get_smp_config();
 
+	/*
+	 * Systems w/o ACPI and mptables might not have it mapped the local
+	 * APIC yet, but prefill_possible_map() might need to access it.
+	 */
+	init_apic_mappings();
+
 	prefill_possible_map();
 
 	init_cpu_to_node();
 
-	init_apic_mappings();
 	io_apic_init_mappings();
 
 	kvm_guest_init();

commit 3ef0a61a467639cf7def299309cd9ea524c3e1c1
Merge: 1a4a2bc46072 917db484dc6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 3 16:46:53 2016 -0700

    Merge branch 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 boot updates from Ingo Molnar:
     "The changes in this cycle were:
    
       - Save e820 table RAM footprint on larger kernel configurations.
         (Denys Vlasenko)
    
       - pmem related fixes (Dan Williams)
    
       - theoretical e820 boundary condition fix (Wei Yang)"
    
    * 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/boot: Fix kdump, cleanup aborted E820_PRAM max_pfn manipulation
      x86/e820: Use much less memory for e820/e820_saved, save up to 120k
      x86/e820: Prepare e280 code for switch to dynamic storage
      x86/e820: Mark some static functions __init
      x86/e820: Fix very large 'size' handling boundary condition

commit 1a4a2bc460721bc8f91e4c1294d39b38e5af132f
Merge: 110a9e42b687 1ef55be16ed6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 3 16:13:28 2016 -0700

    Merge branch 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull low-level x86 updates from Ingo Molnar:
     "In this cycle this topic tree has become one of those 'super topics'
      that accumulated a lot of changes:
    
       - Add CONFIG_VMAP_STACK=y support to the core kernel and enable it on
         x86 - preceded by an array of changes. v4.8 saw preparatory changes
         in this area already - this is the rest of the work. Includes the
         thread stack caching performance optimization. (Andy Lutomirski)
    
       - switch_to() cleanups and all around enhancements. (Brian Gerst)
    
       - A large number of dumpstack infrastructure enhancements and an
         unwinder abstraction. The secret long term plan is safe(r) live
         patching plus maybe another attempt at debuginfo based unwinding -
         but all these current bits are standalone enhancements in a frame
         pointer based debug environment as well. (Josh Poimboeuf)
    
       - More __ro_after_init and const annotations. (Kees Cook)
    
       - Enable KASLR for the vmemmap memory region. (Thomas Garnier)"
    
    [ The virtually mapped stack changes are pretty fundamental, and not
      x86-specific per se, even if they are only used on x86 right now. ]
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (70 commits)
      x86/asm: Get rid of __read_cr4_safe()
      thread_info: Use unsigned long for flags
      x86/alternatives: Add stack frame dependency to alternative_call_2()
      x86/dumpstack: Fix show_stack() task pointer regression
      x86/dumpstack: Remove dump_trace() and related callbacks
      x86/dumpstack: Convert show_trace_log_lvl() to use the new unwinder
      oprofile/x86: Convert x86_backtrace() to use the new unwinder
      x86/stacktrace: Convert save_stack_trace_*() to use the new unwinder
      perf/x86: Convert perf_callchain_kernel() to use the new unwinder
      x86/unwind: Add new unwind interface and implementations
      x86/dumpstack: Remove NULL task pointer convention
      fork: Optimize task creation by caching two thread stacks per CPU if CONFIG_VMAP_STACK=y
      sched/core: Free the stack early if CONFIG_THREAD_INFO_IN_TASK
      lib/syscall: Pin the task stack in collect_syscall()
      x86/process: Pin the target stack in get_wchan()
      x86/dumpstack: Pin the target stack when dumping it
      kthread: Pin the stack via try_get_task_stack()/put_task_stack() in to_live_kthread() function
      sched/core: Add try_get_task_stack() and put_task_stack()
      x86/entry/64: Fix a minor comment rebase error
      iommu/amd: Don't put completion-wait semaphore on stack
      ...

commit 110a9e42b68719f584879c5c5c727bbae90d15f9
Merge: af79ad2b1f33 eb6296dec19f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 3 15:36:06 2016 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 apic updates from Ingo Molnar:
     "The main changes are:
    
       - Persistent CPU/node numbering across CPU hotplug/unplug events.
         This is a pretty involved series of changes that first fetches all
         the information during bootup and then uses it for the various
         hotplug/unplug methods. (Gu Zheng, Dou Liyang)
    
       - IO-APIC hot-add/remove fixes and enhancements. (Rui Wang)
    
       - ... various fixes, cleanups and enhancements"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (22 commits)
      x86/apic: Fix silent & fatal merge conflict in __generic_processor_info()
      acpi: Fix broken error check in map_processor()
      acpi: Validate processor id when mapping the processor
      acpi: Provide mechanism to validate processors in the ACPI tables
      x86/acpi: Set persistent cpuid <-> nodeid mapping when booting
      x86/acpi: Enable MADT APIs to return disabled apicids
      x86/acpi: Introduce persistent storage for cpuid <-> apicid mapping
      x86/acpi: Enable acpi to register all possible cpus at boot time
      x86/numa: Online memory-less nodes at boot time
      x86/apic: Get rid of apic_version[] array
      x86/apic: Order irq_enter/exit() calls correctly vs. ack_APIC_irq()
      x86/ioapic: Ignore root bridges without a companion ACPI device
      x86/apic: Update comment about disabling processor focus
      x86/smpboot: Check APIC ID before setting up default routing
      x86/ioapic: Fix IOAPIC failing to request resource
      x86/ioapic: Fix lost IOAPIC resource after hot-removal and hotadd
      x86/ioapic: Fix setup_res() failing to get resource
      x86/ioapic: Support hot-removal of IOAPICs present during boot
      x86/ioapic: Change prototype of acpi_ioapic_add()
      x86/apic, ACPI: Fix incorrect assignment when handling apic/x2apic entries
      ...

commit de956b8f45b3338cfb66a725e22b4050109daf2a
Merge: d7a0dab82fef 2ab78a724b1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 3 11:33:18 2016 -0700

    Merge branch 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull EFI updates from Ingo Molnar:
     "Main changes in this cycle were:
    
       - Refactor the EFI memory map code into architecture neutral files
         and allow drivers to permanently reserve EFI boot services regions
         on x86, as well as ARM/arm64. (Matt Fleming)
    
       - Add ARM support for the EFI ESRT driver. (Ard Biesheuvel)
    
       - Make the EFI runtime services and efivar API interruptible by
         swapping spinlocks for semaphores. (Sylvain Chouleur)
    
       - Provide the EFI identity mapping for kexec which allows kexec to
         work on SGI/UV platforms with requiring the "noefi" kernel command
         line parameter. (Alex Thorlton)
    
       - Add debugfs node to dump EFI page tables on arm64. (Ard Biesheuvel)
    
       - Merge the EFI test driver being carried out of tree until now in
         the FWTS project. (Ivan Hu)
    
       - Expand the list of flags for classifying EFI regions as "RAM" on
         arm64 so we align with the UEFI spec. (Ard Biesheuvel)
    
       - Optimise out the EFI mixed mode if it's unsupported (CONFIG_X86_32)
         or disabled (CONFIG_EFI_MIXED=n) and switch the early EFI boot
         services function table for direct calls, alleviating us from
         having to maintain the custom function table. (Lukas Wunner)
    
       - Miscellaneous cleanups and fixes"
    
    * 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (30 commits)
      x86/efi: Round EFI memmap reservations to EFI_PAGE_SIZE
      x86/efi: Allow invocation of arbitrary boot services
      x86/efi: Optimize away setup_gop32/64 if unused
      x86/efi: Use kmalloc_array() in efi_call_phys_prolog()
      efi/arm64: Treat regions with WT/WC set but WB cleared as memory
      efi: Add efi_test driver for exporting UEFI runtime service interfaces
      x86/efi: Defer efi_esrt_init until after memblock_x86_fill
      efi/arm64: Add debugfs node to dump UEFI runtime page tables
      x86/efi: Remove unused find_bits() function
      fs/efivarfs: Fix double kfree() in error path
      x86/efi: Map in physical addresses in efi_map_region_fixed
      lib/ucs2_string: Speed up ucs2_utf8size()
      firmware-gsmi: Delete an unnecessary check before the function call "dma_pool_destroy"
      x86/efi: Initialize status to ensure garbage is not returned on small size
      efi: Replace runtime services spinlock with semaphore
      efi: Don't use spinlocks for efi vars
      efi: Use a file local lock for efivars
      efi/arm*: esrt: Add missing call to efi_esrt_init()
      efi/esrt: Use memremap not ioremap to access ESRT table in memory
      x86/efi-bgrt: Use efi_mem_reserve() to avoid copying image data
      ...

commit 1ef55be16ed69538f89e0a6508be5e62fdc9851c
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Sep 29 12:48:12 2016 -0700

    x86/asm: Get rid of __read_cr4_safe()
    
    We use __read_cr4() vs __read_cr4_safe() inconsistently.  On
    CR4-less CPUs, all CR4 bits are effectively clear, so we can make
    the code simpler and more robust by making __read_cr4() always fix
    up faults on 32-bit kernels.
    
    This may fix some bugs on old 486-like CPUs, but I don't have any
    easy way to test that.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: david@saggiorato.net
    Link: http://lkml.kernel.org/r/ea647033d357d9ce2ad2bbde5a631045f5052fb6.1475178370.git.luto@kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 87f2330cc805..3aabfdcbcb52 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1137,7 +1137,7 @@ void __init setup_arch(char **cmdline_p)
 	 * auditing all the early-boot CR4 manipulation would be needed to
 	 * rule it out.
 	 */
-	mmu_cr4_features = __read_cr4_safe();
+	mmu_cr4_features = __read_cr4();
 
 	memblock_set_current_limit(get_max_mapped());
 

commit d7e25c66c9bf882450060fd9464e784bd229d3ae
Merge: 907241dccb4c e4aad64597d7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Sep 30 12:38:28 2016 +0200

    Merge branch 'x86/urgent' into x86/asm
    
    Get the cr4 fixes so we can apply the final cleanup

commit 192d1dccbfc5b901b66527df9df80304693cf06e
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Sep 29 12:48:11 2016 -0700

    x86/boot: Fix another __read_cr4() case on 486
    
    The condition for reading CR4 was wrong: there are some CPUs with
    CPUID but not CR4.  Rather than trying to make the condition exact,
    use __read_cr4_safe().
    
    Fixes: 18bc7bd523e0 ("x86/boot: Synchronize trampoline_cr4_features and mmu_cr4_features directly")
    Reported-by: david@saggiorato.net
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Link: http://lkml.kernel.org/r/8c453a61c4f44ab6ff43c29780ba04835234d2e5.1475178369.git.luto@kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa60f5f5a16..98c9cd6f3b5d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1137,9 +1137,7 @@ void __init setup_arch(char **cmdline_p)
 	 * auditing all the early-boot CR4 manipulation would be needed to
 	 * rule it out.
 	 */
-	if (boot_cpu_data.cpuid_level >= 0)
-		/* A CPU has %cr4 if and only if it has CPUID. */
-		mmu_cr4_features = __read_cr4();
+	mmu_cr4_features = __read_cr4_safe();
 
 	memblock_set_current_limit(get_max_mapped());
 

commit 475339684ef19e46f4702e2d185a869a5c454688
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Sat Sep 17 23:39:26 2016 +0200

    x86/e820: Prepare e280 code for switch to dynamic storage
    
    This patch turns e820 and e820_saved into pointers to e820 tables,
    of the same size as before.
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20160917213927.1787-2-dvlasenk@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa60f5f5a16..cc43d660c990 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -458,8 +458,8 @@ static void __init e820_reserve_setup_data(void)
 		early_memunmap(data, sizeof(*data));
 	}
 
-	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
-	memcpy(&e820_saved, &e820, sizeof(struct e820map));
+	sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
+	memcpy(e820_saved, e820, sizeof(struct e820map));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }
@@ -763,7 +763,7 @@ static void __init trim_bios_range(void)
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
 
-	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+	sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
@@ -1032,7 +1032,7 @@ void __init setup_arch(char **cmdline_p)
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
 				  E820_RESERVED);
-		sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+		sanitize_e820_map(e820->map, ARRAY_SIZE(e820->map), &e820->nr_map);
 		printk(KERN_INFO "fixed physical RAM map:\n");
 		e820_print_map("bad_ppro");
 	}

commit 3dad6f7f6975387f53f1a772f29f54335563d93d
Author: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
Date:   Tue Aug 16 17:32:31 2016 -0700

    x86/efi: Defer efi_esrt_init until after memblock_x86_fill
    
    Commit 7b02d53e7852 ("efi: Allow drivers to reserve boot services forever")
    introduced a new efi_mem_reserve to reserve the boot services memory
    regions forever. This reservation involves allocating a new EFI memory
    range descriptor. However, allocation can only succeed if there is memory
    available for the allocation. Otherwise, error such as the following may
    occur:
    
    esrt: Reserving ESRT space from 0x000000003dd6a000 to 0x000000003dd6a010.
    Kernel panic - not syncing: ERROR: Failed to allocate 0x9f0 bytes below \
     0x0.
    CPU: 0 PID: 0 Comm: swapper Not tainted 4.7.0-rc5+ #503
     0000000000000000 ffffffff81e03ce0 ffffffff8131dae8 ffffffff81bb6c50
     ffffffff81e03d70 ffffffff81e03d60 ffffffff8111f4df 0000000000000018
     ffffffff81e03d70 ffffffff81e03d08 00000000000009f0 00000000000009f0
    Call Trace:
     [<ffffffff8131dae8>] dump_stack+0x4d/0x65
     [<ffffffff8111f4df>] panic+0xc5/0x206
     [<ffffffff81f7c6d3>] memblock_alloc_base+0x29/0x2e
     [<ffffffff81f7c6e3>] memblock_alloc+0xb/0xd
     [<ffffffff81f6c86d>] efi_arch_mem_reserve+0xbc/0x134
     [<ffffffff81fa3280>] efi_mem_reserve+0x2c/0x31
     [<ffffffff81fa3280>] ? efi_mem_reserve+0x2c/0x31
     [<ffffffff81fa40d3>] efi_esrt_init+0x19e/0x1b4
     [<ffffffff81f6d2dd>] efi_init+0x398/0x44a
     [<ffffffff81f5c782>] setup_arch+0x415/0xc30
     [<ffffffff81f55af1>] start_kernel+0x5b/0x3ef
     [<ffffffff81f55434>] x86_64_start_reservations+0x2f/0x31
     [<ffffffff81f55520>] x86_64_start_kernel+0xea/0xed
    ---[ end Kernel panic - not syncing: ERROR: Failed to allocate 0x9f0
         bytes below 0x0.
    
    An inspection of the memblock configuration reveals that there is no memory
    available for the allocation:
    
    MEMBLOCK configuration:
     memory size = 0x0 reserved size = 0x4f339c0
     memory.cnt  = 0x1
     memory[0x0]    [0x00000000000000-0xffffffffffffffff], 0x0 bytes on node 0\
                     flags: 0x0
     reserved.cnt  = 0x4
     reserved[0x0]  [0x0000000008c000-0x0000000008c9bf], 0x9c0 bytes flags: 0x0
     reserved[0x1]  [0x0000000009f000-0x000000000fffff], 0x61000 bytes\
                     flags: 0x0
     reserved[0x2]  [0x00000002800000-0x0000000394bfff], 0x114c000 bytes\
                     flags: 0x0
     reserved[0x3]  [0x000000304e4000-0x00000034269fff], 0x3d86000 bytes\
                     flags: 0x0
    
    This situation can be avoided if we call efi_esrt_init after memblock has
    memory regions for the allocation.
    
    Also, the EFI ESRT driver makes use of early_memremap'pings. Therfore, we
    do not want to defer efi_esrt_init for too long. We must call such function
    while calls to early_memremap are still valid.
    
    A good place to meet the two aforementioned conditions is right after
    memblock_x86_fill, grouped with other EFI-related functions.
    
    Reported-by: Scott Lawson <scott.lawson@intel.com>
    Signed-off-by: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Peter Jones <pjones@redhat.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4fd69e532c15..528b8eb24a04 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1101,6 +1101,7 @@ void __init setup_arch(char **cmdline_p)
 	if (efi_enabled(EFI_MEMMAP)) {
 		efi_fake_memmap();
 		efi_find_mirror();
+		efi_esrt_init();
 
 		/*
 		 * The EFI specification says that boot service code won't be

commit 4971531af319f8bdd9a81a87eecfb6b19f2f8c8e
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Tue Jun 21 23:11:38 2016 +0100

    x86/efi: Test for EFI_MEMMAP functionality when iterating EFI memmap
    
    Both efi_find_mirror() and efi_fake_memmap() really want to know
    whether the EFI memory map is available, not just whether the machine
    was booted using EFI. efi_fake_memmap() even has a check for
    EFI_MEMMAP at the start of the function.
    
    Since we've already got other code that has this dependency, merge
    everything under one if() conditional, and remove the now superfluous
    check from efi_fake_memmap().
    
    Tested-by: Dave Young <dyoung@redhat.com> [kexec/kdump]
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org> [arm]
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Taku Izumi <izumi.taku@jp.fujitsu.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Xishi Qiu <qiuxishi@huawei.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa60f5f5a16..4fd69e532c15 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1096,19 +1096,18 @@ void __init setup_arch(char **cmdline_p)
 	memblock_set_current_limit(ISA_END_ADDRESS);
 	memblock_x86_fill();
 
-	if (efi_enabled(EFI_BOOT)) {
+	reserve_bios_regions();
+
+	if (efi_enabled(EFI_MEMMAP)) {
 		efi_fake_memmap();
 		efi_find_mirror();
-	}
-
-	reserve_bios_regions();
 
-	/*
-	 * The EFI specification says that boot service code won't be called
-	 * after ExitBootServices(). This is, in fact, a lie.
-	 */
-	if (efi_enabled(EFI_MEMMAP))
+		/*
+		 * The EFI specification says that boot service code won't be
+		 * called after ExitBootServices(). This is, in fact, a lie.
+		 */
 		efi_reserve_boot_services();
+	}
 
 	/* preallocate 4k for mptable mpc */
 	early_reserve_e820_mpc_new();

commit 2b3061c77ce7e429b25a25560ba088e8e7193a67
Merge: 01175255fd8e 25dfe4785332
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Sep 8 08:41:52 2016 +0200

    Merge branch 'x86/mm' into x86/asm, to unify the two branches for simplicity
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit a91bf718dbc993ea582cd53c0cb711a0839b4603
Author: Baoquan He <bhe@redhat.com>
Date:   Fri Aug 12 14:57:12 2016 +0800

    x86/mm/numa: Open code function early_get_boot_cpu_id()
    
    Previously early_acpi_boot_init() was called in early_get_boot_cpu_id()
    to get the value for boot_cpu_physical_apicid. Now early_acpi_boot_init()
    has been taken out and moved to setup_arch(), the name of
    early_get_boot_cpu_id() doesn't match its implementation anymore, and
    only the getting boot-time SMP configuration code was left.
    
    So in this patch we open code it.
    
    Also move the smp_found_config check into default_get_smp_config to
    simplify code, because both early_get_smp_config() and get_smp_config()
    call x86_init.mpparse.get_smp_config().
    
    Also remove the redundent CONFIG_X86_MPPARSE #ifdef check when we call
    early_get_smp_config().
    
    Signed-off-by: Baoquan He <bhe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-acpi@vger.kernel.org
    Cc: rjw@rjwysocki.net
    Link: http://lkml.kernel.org/r/1470985033-22493-1-git-send-email-bhe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa60f5f5a16..cbf56344a0f6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1221,8 +1221,7 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * get boot-time SMP configuration:
 	 */
-	if (smp_found_config)
-		get_smp_config();
+	get_smp_config();
 
 	prefill_possible_map();
 

commit d0de0f685db7faf2ae4597a39a59996dd84e18c7
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Aug 10 02:29:15 2016 -0700

    x86/boot: Defer setup_real_mode() to early_initcall time
    
    There's no need to run setup_real_mode() as early as we run it.
    Defer it to the same early_initcall that sets up the page
    permissions for the real mode code.
    
    This should be a code size reduction.  More importantly, it give us
    a longer window in which we can allocate the real mode trampoline.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mario Limonciello <mario_limonciello@dell.com>
    Cc: Matt Fleming <mfleming@suse.de>
    Cc: Matthew Garrett <mjg59@srcf.ucam.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/fd62f0da4f79357695e9bf3e365623736b05f119.1470821230.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 95c8c9c7dd6d..0fa60f5f5a16 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1141,8 +1141,6 @@ void __init setup_arch(char **cmdline_p)
 		/* A CPU has %cr4 if and only if it has CPUID. */
 		mmu_cr4_features = __read_cr4();
 
-	setup_real_mode();
-
 	memblock_set_current_limit(get_max_mapped());
 
 	/*

commit 18bc7bd523e0fc5be8d76bf84bde733a97a8c375
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Aug 10 02:29:14 2016 -0700

    x86/boot: Synchronize trampoline_cr4_features and mmu_cr4_features directly
    
    The initialization process for trampoline_cr4_features and
    mmu_cr4_features was confusing.  The intent is for mmu_cr4_features
    and *trampoline_cr4_features to stay in sync, but
    trampoline_cr4_features is NULL until setup_real_mode() runs.  The
    old code synchronized *trampoline_cr4_features *twice*, once in
    setup_real_mode() and once in setup_arch().  It also initialized
    mmu_cr4_features in setup_real_mode(), which causes the actual value
    of mmu_cr4_features to potentially depend on when setup_real_mode()
    is called.
    
    With this patch, mmu_cr4_features is initialized directly in
    setup_arch(), and *trampoline_cr4_features is synchronized to
    mmu_cr4_features when the trampoline is set up.
    
    After this patch, it should be safe to defer setup_real_mode().
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mario Limonciello <mario_limonciello@dell.com>
    Cc: Matt Fleming <mfleming@suse.de>
    Cc: Matthew Garrett <mjg59@srcf.ucam.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/d48a263f9912389b957dd495a7127b009259ffe0.1470821230.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bf780e0f76ef..95c8c9c7dd6d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1131,6 +1131,16 @@ void __init setup_arch(char **cmdline_p)
 
 	early_trap_pf_init();
 
+	/*
+	 * Update mmu_cr4_features (and, indirectly, trampoline_cr4_features)
+	 * with the current CR4 value.  This may not be necessary, but
+	 * auditing all the early-boot CR4 manipulation would be needed to
+	 * rule it out.
+	 */
+	if (boot_cpu_data.cpuid_level >= 0)
+		/* A CPU has %cr4 if and only if it has CPUID. */
+		mmu_cr4_features = __read_cr4();
+
 	setup_real_mode();
 
 	memblock_set_current_limit(get_max_mapped());
@@ -1180,13 +1190,6 @@ void __init setup_arch(char **cmdline_p)
 
 	kasan_init();
 
-	if (boot_cpu_data.cpuid_level >= 0) {
-		/* A CPU has %cr4 if and only if it has CPUID */
-		mmu_cr4_features = __read_cr4();
-		if (trampoline_cr4_features)
-			*trampoline_cr4_features = mmu_cr4_features;
-	}
-
 #ifdef CONFIG_X86_32
 	/* sync back kernel address range */
 	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,

commit 007b756053386af079ba963a8f5817ac651c7c59
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Aug 10 02:29:13 2016 -0700

    x86/boot: Run reserve_bios_regions() after we initialize the memory map
    
    reserve_bios_regions() is a quirk that reserves memory that we might
    otherwise think is available.  There's no need to run it so early,
    and running it before we have the memory map initialized with its
    non-quirky inputs makes it hard to make reserve_bios_regions() more
    intelligent.
    
    Move it right after we populate the memblock state.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mario Limonciello <mario_limonciello@dell.com>
    Cc: Matt Fleming <mfleming@suse.de>
    Cc: Matthew Garrett <mjg59@srcf.ucam.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/59f58618911005c799c6c9979ce6ae4881d907c2.1470821230.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 95cf31c9f4ec..bf780e0f76ef 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1101,6 +1101,8 @@ void __init setup_arch(char **cmdline_p)
 		efi_find_mirror();
 	}
 
+	reserve_bios_regions();
+
 	/*
 	 * The EFI specification says that boot service code won't be called
 	 * after ExitBootServices(). This is, in fact, a lie.

commit 404f6aac9b3ef595735feca99979db084ea48315
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Aug 8 16:29:06 2016 -0700

    x86: Apply more __ro_after_init and const
    
    Guided by grsecurity's analogous __read_only markings in arch/x86,
    this applies several uses of __ro_after_init to structures that are
    only updated during __init, and const for some structures that are
    never updated.  Additionally extends __init markings to some functions
    that are only used during __init, and cleans up some missing C99 style
    static initializers.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: David Brown <david.brown@linaro.org>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathias Krause <minipli@googlemail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: kernel-hardening@lists.openwall.com
    Link: http://lkml.kernel.org/r/20160808232906.GA29731@www.outflux.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 95cf31c9f4ec..2d98798d395e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -210,9 +210,9 @@ EXPORT_SYMBOL(boot_cpu_data);
 
 
 #if !defined(CONFIG_X86_PAE) || defined(CONFIG_X86_64)
-__visible unsigned long mmu_cr4_features;
+__visible unsigned long mmu_cr4_features __ro_after_init;
 #else
-__visible unsigned long mmu_cr4_features = X86_CR4_PAE;
+__visible unsigned long mmu_cr4_features __ro_after_init = X86_CR4_PAE;
 #endif
 
 /* Boot loader ID and version as integers, for the benefit of proc_dointvec */

commit c7d2361f7524f365c1ae42f47880e3fa9efb2c2a
Author: Thomas Garnier <thgarnie@google.com>
Date:   Tue Aug 9 10:11:04 2016 -0700

    x86/mm/KASLR: Fix physical memory calculation on KASLR memory randomization
    
    Initialize KASLR memory randomization after max_pfn is initialized. Also
    ensure the size is rounded up. It could create problems on machines
    with more than 1Tb of memory on certain random addresses.
    
    Signed-off-by: Thomas Garnier <thgarnie@google.com>
    Cc: Aleksey Makarov <aleksey.makarov@linaro.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Fabian Frederick <fabf@skynet.be>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Lv Zheng <lv.zheng@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J . Wysocki <rafael.j.wysocki@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: kernel-hardening@lists.openwall.com
    Fixes: 021182e52fe0 ("Enable KASLR for physical mapping memory regions")
    Link: http://lkml.kernel.org/r/1470762665-88032-1-git-send-email-thgarnie@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 991b77986d57..95cf31c9f4ec 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -936,8 +936,6 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.oem.arch_setup();
 
-	kernel_randomize_memory();
-
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();
@@ -1055,6 +1053,12 @@ void __init setup_arch(char **cmdline_p)
 
 	max_possible_pfn = max_pfn;
 
+	/*
+	 * Define random base addresses for memory sections after max_pfn is
+	 * defined and before each memory section base is used.
+	 */
+	kernel_randomize_memory();
+
 #ifdef CONFIG_X86_32
 	/* max_low_pfn get updated here */
 	find_low_pfn_range();

commit aeb35d6b74174ed08daab84e232b456bbd89d1d9
Merge: 7a66ecfd319a a47177d360a2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 1 14:23:42 2016 -0400

    Merge branch 'x86-headers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 header cleanups from Ingo Molnar:
     "This tree is a cleanup of the x86 tree reducing spurious uses of
      module.h - which should improve build performance a bit"
    
    * 'x86-headers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, crypto: Restore MODULE_LICENSE() to glue_helper.c so it loads
      x86/apic: Remove duplicated include from probe_64.c
      x86/ce4100: Remove duplicated include from ce4100.c
      x86/headers: Include spinlock_types.h in x8664_ksyms_64.c for missing spinlock_t
      x86/platform: Delete extraneous MODULE_* tags fromm ts5500
      x86: Audit and remove any remaining unnecessary uses of module.h
      x86/kvm: Audit and remove any unnecessary uses of module.h
      x86/xen: Audit and remove any unnecessary uses of module.h
      x86/platform: Audit and remove any unnecessary uses of module.h
      x86/lib: Audit and remove any unnecessary uses of module.h
      x86/kernel: Audit and remove any unnecessary uses of module.h
      x86/mm: Audit and remove any unnecessary uses of module.h
      x86: Don't use module.h just for AUTHOR / LICENSE tags

commit e663107fa1edda4d8a0d5b8ce704d71f8e27de43
Merge: 6453dbdda304 54d0b14ad7cc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 17:56:45 2016 -0700

    Merge tag 'acpi-4.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI updates from Rafael Wysocki:
     "The new feaures here are the support for ACPI overlays (allowing ACPI
      tables to be loaded at any time from EFI variables or via configfs)
      and the LPI (Low-Power Idle) support.  Also notable is the ACPI-based
      NUMA support for ARM64.
    
      Apart from that we have two new drivers, for the DPTF (Dynamic Power
      and Thermal Framework) power participant device and for the Intel
      Broxton WhiskeyCove PMIC, some more PMIC-related changes, support for
      the Boot Error Record Table (BERT) in APEI and support for
      platform-initiated graceful shutdown.
    
      Plus two new pieces of documentation and usual assorted fixes and
      cleanups in quite a few places.
    
      Specifics:
    
       - Support for ACPI SSDT overlays allowing Secondary System
         Description Tables (SSDTs) to be loaded at any time from EFI
         variables or via configfs (Octavian Purdila, Mika Westerberg).
    
       - Support for the ACPI LPI (Low-Power Idle) feature introduced in
         ACPI 6.0 and allowing processor idle states to be represented in
         ACPI tables in a hierarchical way (with the help of Processor
         Container objects) and support for ACPI idle states management on
         ARM64, based on LPI (Sudeep Holla).
    
       - General improvements of ACPI support for NUMA and ARM64 support for
         ACPI-based NUMA (Hanjun Guo, David Daney, Robert Richter).
    
       - General improvements of the ACPI table upgrade mechanism and ARM64
         support for that feature (Aleksey Makarov, Jon Masters).
    
       - Support for the Boot Error Record Table (BERT) in APEI and
         improvements of kernel messages printed by the error injection code
         (Huang Ying, Borislav Petkov).
    
       - New driver for the Intel Broxton WhiskeyCove PMIC operation region
         and support for the REGS operation region on Broxton, PMIC code
         cleanups (Bin Gao, Felipe Balbi, Paul Gortmaker).
    
       - New driver for the power participant device which is part of the
         Dynamic Power and Thermal Framework (DPTF) and DPTF-related code
         reorganization (Srinivas Pandruvada).
    
       - Support for the platform-initiated graceful shutdown feature
         introduced in ACPI 6.1 (Prashanth Prakash).
    
       - ACPI button driver update related to lid input events generated
         automatically on initialization and system resume that have been
         problematic for some time (Lv Zheng).
    
       - ACPI EC driver cleanups (Lv Zheng).
    
       - Documentation of the ACPICA release automation process and the
         in-kernel ACPI AML debugger (Lv Zheng).
    
       - New blacklist entry and two fixes for the ACPI backlight driver
         (Alex Hung, Arvind Yadav, Ralf Gerbig).
    
       - Cleanups of the ACPI pci_slot driver (Joe Perches, Paul Gortmaker).
    
       - ACPI CPPC code changes to make it more robust against possible
         defects in ACPI tables and new symbol definitions for PCC (Hoan
         Tran).
    
       - System reboot code modification to execute the ACPI _PTS (Prepare
         To Sleep) method in addition to _TTS (Ocean He).
    
       - ACPICA-related change to carry out lock ordering checks in ACPICA
         if ACPICA debug is enabled in the kernel (Lv Zheng).
    
       - Assorted minor fixes and cleanups (Andy Shevchenko, Baoquan He,
         Bhaktipriya Shridhar, Paul Gortmaker, Rafael Wysocki)"
    
    * tag 'acpi-4.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (71 commits)
      ACPI: enable ACPI_PROCESSOR_IDLE on ARM64
      arm64: add support for ACPI Low Power Idle(LPI)
      drivers: firmware: psci: initialise idle states using ACPI LPI
      cpuidle: introduce CPU_PM_CPU_IDLE_ENTER macro for ARM{32, 64}
      arm64: cpuidle: drop __init section marker to arm_cpuidle_init
      ACPI / processor_idle: Add support for Low Power Idle(LPI) states
      ACPI / processor_idle: introduce ACPI_PROCESSOR_CSTATE
      ACPI / DPTF: move int340x_thermal.c to the DPTF folder
      ACPI / DPTF: Add DPTF power participant driver
      ACPI / lpat: make it explicitly non-modular
      ACPI / dock: make dock explicitly non-modular
      ACPI / PCI: make pci_slot explicitly non-modular
      ACPI / PMIC: remove modular references from non-modular code
      ACPICA: Linux: Enable ACPI_MUTEX_DEBUG for Linux kernel
      ACPI: Rename configfs.c to acpi_configfs.c to prevent link error
      ACPI / debugger: Add AML debugger documentation
      ACPI: Add documentation describing ACPICA release automation
      ACPI: add support for loading SSDTs via configfs
      ACPI: add support for configfs
      efi / ACPI: load SSTDs from EFI variables
      ...

commit 186f43608a5c827f8284fe4559225b4dccaa49ef
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Jul 13 20:18:56 2016 -0400

    x86/kernel: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.  The advantage
    in doing so is that module.h itself sources about 15 other headers;
    adding significantly to what we feed cpp, and it can obscure what
    headers we are effectively using.
    
    Since module.h was the source for init.h (for __init) and for
    export.h (for EXPORT_SYMBOL) we consider each obj-y/bool instance
    for the presence of either and replace as needed.  Build testing
    revealed some implicit header usage that was fixed up accordingly.
    
    Note that some bool/obj-y instances remain since module.h is
    the header for some exception table entry stuff, and for things
    like __init_or_module (code that is tossed when MODULES=n).
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20160714001901.31603-4-paul.gortmaker@windriver.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c4e7b3991b60..9203a6eac2a6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -36,7 +36,7 @@
 #include <linux/console.h>
 #include <linux/root_dev.h>
 #include <linux/highmem.h>
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/efi.h>
 #include <linux/init.h>
 #include <linux/edd.h>

commit 0483e1fa6e09d4948272680f691dccb1edb9677f
Author: Thomas Garnier <thgarnie@google.com>
Date:   Tue Jun 21 17:47:02 2016 -0700

    x86/mm: Implement ASLR for kernel memory regions
    
    Randomizes the virtual address space of kernel memory regions for
    x86_64. This first patch adds the infrastructure and does not randomize
    any region. The following patches will randomize the physical memory
    mapping, vmalloc and vmemmap regions.
    
    This security feature mitigates exploits relying on predictable kernel
    addresses. These addresses can be used to disclose the kernel modules
    base addresses or corrupt specific structures to elevate privileges
    bypassing the current implementation of KASLR. This feature can be
    enabled with the CONFIG_RANDOMIZE_MEMORY option.
    
    The order of each memory region is not changed. The feature looks at the
    available space for the regions based on different configuration options
    and randomizes the base and space between each. The size of the physical
    memory mapping is the available physical memory. No performance impact
    was detected while testing the feature.
    
    Entropy is generated using the KASLR early boot functions now shared in
    the lib directory (originally written by Kees Cook). Randomization is
    done on PGD & PUD page table levels to increase possible addresses. The
    physical memory mapping code was adapted to support PUD level virtual
    addresses. This implementation on the best configuration provides 30,000
    possible virtual addresses in average for each memory region.  An
    additional low memory page is used to ensure each CPU can start with a
    PGD aligned virtual address (for realmode).
    
    x86/dump_pagetable was updated to correctly display each region.
    
    Updated documentation on x86_64 memory layout accordingly.
    
    Performance data, after all patches in the series:
    
    Kernbench shows almost no difference (-+ less than 1%):
    
    Before:
    
    Average Optimal load -j 12 Run (std deviation): Elapsed Time 102.63 (1.2695)
    User Time 1034.89 (1.18115) System Time 87.056 (0.456416) Percent CPU 1092.9
    (13.892) Context Switches 199805 (3455.33) Sleeps 97907.8 (900.636)
    
    After:
    
    Average Optimal load -j 12 Run (std deviation): Elapsed Time 102.489 (1.10636)
    User Time 1034.86 (1.36053) System Time 87.764 (0.49345) Percent CPU 1095
    (12.7715) Context Switches 199036 (4298.1) Sleeps 97681.6 (1031.11)
    
    Hackbench shows 0% difference on average (hackbench 90 repeated 10 times):
    
    attemp,before,after 1,0.076,0.069 2,0.072,0.069 3,0.066,0.066 4,0.066,0.068
    5,0.066,0.067 6,0.066,0.069 7,0.067,0.066 8,0.063,0.067 9,0.067,0.065
    10,0.068,0.071 average,0.0677,0.0677
    
    Signed-off-by: Thomas Garnier <thgarnie@google.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Alexander Kuleshov <kuleshovmail@gmail.com>
    Cc: Alexander Popov <alpopov@ptsecurity.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jan Beulich <JBeulich@suse.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Lv Zheng <lv.zheng@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hpe.com>
    Cc: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: kernel-hardening@lists.openwall.com
    Cc: linux-doc@vger.kernel.org
    Link: http://lkml.kernel.org/r/1466556426-32664-6-git-send-email-keescook@chromium.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c4e7b3991b60..a2616584b6e9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -113,6 +113,7 @@
 #include <asm/prom.h>
 #include <asm/microcode.h>
 #include <asm/mmu_context.h>
+#include <asm/kaslr.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
@@ -942,6 +943,8 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.oem.arch_setup();
 
+	kernel_randomize_memory();
+
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();

commit da3d3f98d28bc071a2d566aefc8c461bd564be35
Author: Aleksey Makarov <aleksey.makarov@linaro.org>
Date:   Mon Jun 20 13:56:10 2016 +0300

    ACPI / tables: table upgrade: refactor function definitions
    
    Refer initrd_start, initrd_end directly from drivers/acpi/tables.c.
    This allows to use the table upgrade feature in architectures
    other than x86.  Also this simplifies header files.
    
    The patch renames acpi_table_initrd_init() to acpi_table_upgrade()
    (what reflects the purpose of the function) and removes the unneeded
    wraps early_acpi_table_init() and early_initrd_acpi_init().
    
    Signed-off-by: Aleksey Makarov <aleksey.makarov@linaro.org>
    Acked-by: Lv Zheng <lv.zheng@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c4e7b3991b60..aac91beabf05 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -399,10 +399,6 @@ static void __init reserve_initrd(void)
 	memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
 }
 
-static void __init early_initrd_acpi_init(void)
-{
-	early_acpi_table_init((void *)initrd_start, initrd_end - initrd_start);
-}
 #else
 static void __init early_reserve_initrd(void)
 {
@@ -410,9 +406,6 @@ static void __init early_reserve_initrd(void)
 static void __init reserve_initrd(void)
 {
 }
-static void __init early_initrd_acpi_init(void)
-{
-}
 #endif /* CONFIG_BLK_DEV_INITRD */
 
 static void __init parse_setup_data(void)
@@ -1146,7 +1139,7 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
-	early_initrd_acpi_init();
+	acpi_table_upgrade();
 
 	vsmp_init();
 

commit af06f8b7a102417e93dc57ee7affb9fedcf5d83f
Author: Lv Zheng <lv.zheng@intel.com>
Date:   Mon Apr 11 10:13:27 2016 +0800

    ACPI / x86: Cleanup initrd related code
    
    In arch/x86/kernel/setup.c, the #ifdef kept for CONFIG_ACPI actually is
    related to the accessibility of initrd_start/initrd_end, so the stub should
    be provided from this source file and should only be dependent on
    CONFIG_BLK_DEV_INITRD.
    
    Note that when ACPI=n and BLK_DEV_INITRD=y, early_initrd_acpi_init() is
    still a stub because of the stub prepared for early_acpi_table_init().
    
    Signed-off-by: Lv Zheng <lv.zheng@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 902a6f7b1c04..c4e7b3991b60 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -398,6 +398,11 @@ static void __init reserve_initrd(void)
 
 	memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
 }
+
+static void __init early_initrd_acpi_init(void)
+{
+	early_acpi_table_init((void *)initrd_start, initrd_end - initrd_start);
+}
 #else
 static void __init early_reserve_initrd(void)
 {
@@ -405,6 +410,9 @@ static void __init early_reserve_initrd(void)
 static void __init reserve_initrd(void)
 {
 }
+static void __init early_initrd_acpi_init(void)
+{
+}
 #endif /* CONFIG_BLK_DEV_INITRD */
 
 static void __init parse_setup_data(void)
@@ -1138,9 +1146,7 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
-#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)
-	early_acpi_table_init((void *)initrd_start, initrd_end - initrd_start);
-#endif
+	early_initrd_acpi_init();
 
 	vsmp_init();
 

commit 5ae74f2cc2f150c1a5cee54cabbd71dd0661285a
Author: Lv Zheng <lv.zheng@intel.com>
Date:   Mon Apr 11 10:13:18 2016 +0800

    ACPI / tables: Move table override mechanisms to tables.c
    
    This patch moves acpi_os_table_override() and
    acpi_os_physical_table_override() to tables.c.
    
    Along with the mechanisms, acpi_initrd_initialize_tables() is also moved to
    tables.c to form a static function. The following functions are renamed
    according to this change:
     1. acpi_initrd_override() -> renamed to early_acpi_table_init(), which
        invokes acpi_table_initrd_init()
     2. acpi_os_physical_table_override() -> which invokes
        acpi_table_initrd_override()
     3. acpi_initialize_initrd_tables() -> renamed to acpi_table_initrd_scan()
    
    Signed-off-by: Lv Zheng <lv.zheng@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2367ae07eb76..902a6f7b1c04 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1139,7 +1139,7 @@ void __init setup_arch(char **cmdline_p)
 	reserve_initrd();
 
 #if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)
-	acpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);
+	early_acpi_table_init((void *)initrd_start, initrd_end - initrd_start);
 #endif
 
 	vsmp_init();

commit 4046d6e81f33b7ef50d6668b78076d54c5e066b6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 14 11:18:57 2016 -0700

    Revert "x86: remove the kernel code/data/bss resources from /proc/iomem"
    
    This reverts commit c4004b02f8e5b9ce357a0bb1641756cc86962664.
    
    Sadly, my hope that nobody would actually use the special kernel entries
    in /proc/iomem were dashed by kexec.  Which reads /proc/iomem explicitly
    to find the kernel base address.  Nasty.
    
    Anyway, that means we can't do the sane and simple thing and just remove
    the entries, and we'll instead have to mask them out based on permissions.
    
    Reported-by: Zhengyu Zhang <zhezhang@redhat.com>
    Reported-by: Dave Young <dyoung@redhat.com>
    Reported-by: Freeman Zhang <freeman.zhang1992@gmail.com>
    Reported-by: Emrah Demir <ed@abdsec.com>
    Reported-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 319b08a5b6ed..2367ae07eb76 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -146,6 +146,31 @@ int default_check_phys_apicid_present(int phys_apicid)
 
 struct boot_params boot_params;
 
+/*
+ * Machine setup..
+ */
+static struct resource data_resource = {
+	.name	= "Kernel data",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
+};
+
+static struct resource code_resource = {
+	.name	= "Kernel code",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
+};
+
+static struct resource bss_resource = {
+	.name	= "Kernel bss",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
+};
+
+
 #ifdef CONFIG_X86_32
 /* cpu data as detected by the assembly code in head.S */
 struct cpuinfo_x86 new_cpu_data = {
@@ -924,6 +949,13 @@ void __init setup_arch(char **cmdline_p)
 
 	mpx_mm_init(&init_mm);
 
+	code_resource.start = __pa_symbol(_text);
+	code_resource.end = __pa_symbol(_etext)-1;
+	data_resource.start = __pa_symbol(_etext);
+	data_resource.end = __pa_symbol(_edata)-1;
+	bss_resource.start = __pa_symbol(__bss_start);
+	bss_resource.end = __pa_symbol(__bss_stop)-1;
+
 #ifdef CONFIG_CMDLINE_BOOL
 #ifdef CONFIG_CMDLINE_OVERRIDE
 	strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
@@ -987,6 +1019,11 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.resources.probe_roms();
 
+	/* after parse_early_param, so could debug it */
+	insert_resource(&iomem_resource, &code_resource);
+	insert_resource(&iomem_resource, &data_resource);
+	insert_resource(&iomem_resource, &bss_resource);
+
 	e820_add_kernel_range();
 	trim_bios_range();
 #ifdef CONFIG_X86_32

commit c4004b02f8e5b9ce357a0bb1641756cc86962664
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 6 13:45:07 2016 -0700

    x86: remove the kernel code/data/bss resources from /proc/iomem
    
    Let's see if anybody even notices.  I doubt anybody uses this, and it
    does expose addresses that should be randomized, so let's just remove
    the code.  It's old and traditional, and it used to be cute, but we
    should have removed this long ago.
    
    If it turns out anybody notices and this breaks something, we'll have to
    revert this, and maybe we'll end up using other approaches instead
    (using %pK or similar).  But removing unnecessary code is always the
    preferred option.
    
    Noted-by: Emrah Demir <ed@abdsec.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2367ae07eb76..319b08a5b6ed 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -146,31 +146,6 @@ int default_check_phys_apicid_present(int phys_apicid)
 
 struct boot_params boot_params;
 
-/*
- * Machine setup..
- */
-static struct resource data_resource = {
-	.name	= "Kernel data",
-	.start	= 0,
-	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
-};
-
-static struct resource code_resource = {
-	.name	= "Kernel code",
-	.start	= 0,
-	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
-};
-
-static struct resource bss_resource = {
-	.name	= "Kernel bss",
-	.start	= 0,
-	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
-};
-
-
 #ifdef CONFIG_X86_32
 /* cpu data as detected by the assembly code in head.S */
 struct cpuinfo_x86 new_cpu_data = {
@@ -949,13 +924,6 @@ void __init setup_arch(char **cmdline_p)
 
 	mpx_mm_init(&init_mm);
 
-	code_resource.start = __pa_symbol(_text);
-	code_resource.end = __pa_symbol(_etext)-1;
-	data_resource.start = __pa_symbol(_etext);
-	data_resource.end = __pa_symbol(_edata)-1;
-	bss_resource.start = __pa_symbol(__bss_start);
-	bss_resource.end = __pa_symbol(__bss_stop)-1;
-
 #ifdef CONFIG_CMDLINE_BOOL
 #ifdef CONFIG_CMDLINE_OVERRIDE
 	strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
@@ -1019,11 +987,6 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.resources.probe_roms();
 
-	/* after parse_early_param, so could debug it */
-	insert_resource(&iomem_resource, &code_resource);
-	insert_resource(&iomem_resource, &data_resource);
-	insert_resource(&iomem_resource, &bss_resource);
-
 	e820_add_kernel_range();
 	trim_bios_range();
 #ifdef CONFIG_X86_32

commit 643ad15d47410d37d43daf3ef1c8ac52c281efa5
Merge: 24b5e20f11a7 0d47638f80a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Mar 20 19:08:56 2016 -0700

    Merge branch 'mm-pkeys-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 protection key support from Ingo Molnar:
     "This tree adds support for a new memory protection hardware feature
      that is available in upcoming Intel CPUs: 'protection keys' (pkeys).
    
      There's a background article at LWN.net:
    
          https://lwn.net/Articles/643797/
    
      The gist is that protection keys allow the encoding of
      user-controllable permission masks in the pte.  So instead of having a
      fixed protection mask in the pte (which needs a system call to change
      and works on a per page basis), the user can map a (handful of)
      protection mask variants and can change the masks runtime relatively
      cheaply, without having to change every single page in the affected
      virtual memory range.
    
      This allows the dynamic switching of the protection bits of large
      amounts of virtual memory, via user-space instructions.  It also
      allows more precise control of MMU permission bits: for example the
      executable bit is separate from the read bit (see more about that
      below).
    
      This tree adds the MM infrastructure and low level x86 glue needed for
      that, plus it adds a high level API to make use of protection keys -
      if a user-space application calls:
    
            mmap(..., PROT_EXEC);
    
      or
    
            mprotect(ptr, sz, PROT_EXEC);
    
      (note PROT_EXEC-only, without PROT_READ/WRITE), the kernel will notice
      this special case, and will set a special protection key on this
      memory range.  It also sets the appropriate bits in the Protection
      Keys User Rights (PKRU) register so that the memory becomes unreadable
      and unwritable.
    
      So using protection keys the kernel is able to implement 'true'
      PROT_EXEC on x86 CPUs: without protection keys PROT_EXEC implies
      PROT_READ as well.  Unreadable executable mappings have security
      advantages: they cannot be read via information leaks to figure out
      ASLR details, nor can they be scanned for ROP gadgets - and they
      cannot be used by exploits for data purposes either.
    
      We know about no user-space code that relies on pure PROT_EXEC
      mappings today, but binary loaders could start making use of this new
      feature to map binaries and libraries in a more secure fashion.
    
      There is other pending pkeys work that offers more high level system
      call APIs to manage protection keys - but those are not part of this
      pull request.
    
      Right now there's a Kconfig that controls this feature
      (CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS) that is default enabled
      (like most x86 CPU feature enablement code that has no runtime
      overhead), but it's not user-configurable at the moment.  If there's
      any serious problem with this then we can make it configurable and/or
      flip the default"
    
    * 'mm-pkeys-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (38 commits)
      x86/mm/pkeys: Fix mismerge of protection keys CPUID bits
      mm/pkeys: Fix siginfo ABI breakage caused by new u64 field
      x86/mm/pkeys: Fix access_error() denial of writes to write-only VMA
      mm/core, x86/mm/pkeys: Add execute-only protection keys support
      x86/mm/pkeys: Create an x86 arch_calc_vm_prot_bits() for VMA flags
      x86/mm/pkeys: Allow kernel to modify user pkey rights register
      x86/fpu: Allow setting of XSAVE state
      x86/mm: Factor out LDT init from context init
      mm/core, x86/mm/pkeys: Add arch_validate_pkey()
      mm/core, arch, powerpc: Pass a protection key in to calc_vm_flag_bits()
      x86/mm/pkeys: Actually enable Memory Protection Keys in the CPU
      x86/mm/pkeys: Add Kconfig prompt to existing config option
      x86/mm/pkeys: Dump pkey from VMA in /proc/pid/smaps
      x86/mm/pkeys: Dump PKRU with other kernel registers
      mm/core, x86/mm/pkeys: Differentiate instruction fetches
      x86/mm/pkeys: Optimize fault handling in access_error()
      mm/core: Do not enforce PKEY permissions on remote mm access
      um, pkeys: Add UML arch_*_access_permitted() methods
      mm/gup, x86/mm/pkeys: Check VMAs and PTEs for protection keys
      x86/mm/gup: Simplify get_user_pages() PTE bit handling
      ...

commit c1192f8428414679c8126180e690f8daa1d4d98a
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:27 2016 -0800

    x86/mm/pkeys: Dump pkey from VMA in /proc/pid/smaps
    
    The protection key can now be just as important as read/write
    permissions on a VMA.  We need some debug mechanism to help
    figure out if it is in play.  smaps seems like a logical
    place to expose it.
    
    arch/x86/kernel/setup.c is a bit of a weirdo place to put
    this code, but it already had seq_file.h and there was not
    a much better existing place to put it.
    
    We also use no #ifdef.  If protection keys is .config'd out we
    will effectively get the same function as if we used the weak
    generic function.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Mark Williamson <mwilliamson@undo-software.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20160212210227.4F8EB3F8@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d3d80e6d42a2..7260f992cd11 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -112,6 +112,7 @@
 #include <asm/alternative.h>
 #include <asm/prom.h>
 #include <asm/microcode.h>
+#include <asm/mmu_context.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
@@ -1282,3 +1283,11 @@ static int __init register_kernel_offset_dumper(void)
 	return 0;
 }
 __initcall(register_kernel_offset_dumper);
+
+void arch_show_smap(struct seq_file *m, struct vm_area_struct *vma)
+{
+	if (!boot_cpu_has(X86_FEATURE_OSPKE))
+		return;
+
+	seq_printf(m, "ProtectionKey:  %8u\n", vma_pkey(vma));
+}

commit f33b14a4b96b185634848046f54fb0d5028566a9
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue Jan 26 21:57:20 2016 +0100

    x86/e820: Set System RAM type and descriptor
    
    Change e820_reserve_resources() to set 'flags' and 'desc' from
    e820 types.
    
    Set E820_RESERVED_KERN and E820_RAM's (System RAM) io resource
    type to IORESOURCE_SYSTEM_RAM.
    
    Do the same for "Kernel data", "Kernel code", and "Kernel bss",
    which are child nodes of System RAM.
    
    I/O resource descriptor is set to 'desc' for entries that are
    (and will be) target ranges of walk_iomem_res() and
    region_intersects().
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-mm <linux-mm@kvack.org>
    Link: http://lkml.kernel.org/r/1453841853-11383-5-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d3d80e6d42a2..aa52c1009475 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -152,21 +152,21 @@ static struct resource data_resource = {
 	.name	= "Kernel data",
 	.start	= 0,
 	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
 };
 
 static struct resource code_resource = {
 	.name	= "Kernel code",
 	.start	= 0,
 	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
 };
 
 static struct resource bss_resource = {
 	.name	= "Kernel bss",
 	.start	= 0,
 	.end	= 0,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+	.flags	= IORESOURCE_BUSY | IORESOURCE_SYSTEM_RAM
 };
 
 

commit 0ffedcda63f56eaca99a77392b9f057dfb738817
Merge: 6896d9f7e7ee 1f1a89ac05f6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 11 17:16:01 2016 -0800

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - make the debugfs 'kernel_page_tables' file read-only, as it only
         has read ops.  (Borislav Petkov)
    
       - micro-optimize clflush_cache_range() (Chris Wilson)
    
       - swiotlb enhancements, which fixes certain KVM emulated devices
         (Igor Mammedov)
    
       - fix an LDT related debug message (Jan Beulich)
    
       - modularize CONFIG_X86_PTDUMP (Kees Cook)
    
       - tone down an overly alarming warning (Laura Abbott)
    
       - Mark variable __initdata (Rasmus Villemoes)
    
       - PAT additions (Toshi Kani)"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/mm: Micro-optimise clflush_cache_range()
      x86/mm/pat: Change free_memtype() to support shrinking case
      x86/mm/pat: Add untrack_pfn_moved for mremap
      x86/mm: Drop WARN from multi-BAR check
      x86/LDT: Print the real LDT base address
      x86/mm/64: Enable SWIOTLB if system has SRAT memory regions above MAX_DMA32_PFN
      x86/mm: Introduce max_possible_pfn
      x86/mm/ptdump: Make (debugfs)/kernel_page_tables read-only
      x86/mm/mtrr: Mark the 'range_new' static variable in mtrr_calc_range_state() as __initdata
      x86/mm: Turn CONFIG_X86_PTDUMP into a module

commit 8dd3303001976aa8583bf20f6b93590c74114308
Author: Igor Mammedov <imammedo@redhat.com>
Date:   Fri Dec 4 14:07:05 2015 +0100

    x86/mm: Introduce max_possible_pfn
    
    max_possible_pfn will be used for tracking max possible
    PFN for memory that isn't present in E820 table and
    could be hotplugged later.
    
    By default max_possible_pfn is initialized with max_pfn,
    but later it could be updated with highest PFN of
    hotpluggable memory ranges declared in ACPI SRAT table
    if any present.
    
    Signed-off-by: Igor Mammedov <imammedo@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: akataria@vmware.com
    Cc: fujita.tomonori@lab.ntt.co.jp
    Cc: konrad.wilk@oracle.com
    Cc: pbonzini@redhat.com
    Cc: revers@redhat.com
    Cc: riel@redhat.com
    Link: http://lkml.kernel.org/r/1449234426-273049-2-git-send-email-imammedo@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 29db25f9a745..16a846548ece 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1048,6 +1048,8 @@ void __init setup_arch(char **cmdline_p)
 	if (mtrr_trim_uncached_memory(max_pfn))
 		max_pfn = e820_end_of_ram_pfn();
 
+	max_possible_pfn = max_pfn;
+
 #ifdef CONFIG_X86_32
 	/* max_low_pfn get updated here */
 	find_low_pfn_range();

commit 2d5be37d686c4dae8e60d20283d6f44ac2c44f65
Author: Borislav Petkov <bp@suse.de>
Date:   Fri Nov 20 12:24:00 2015 +0100

    x86/microcode: Initialize the driver late when facilities are up
    
    Running microcode_init() from setup_arch() is a bad idea because
    not even kmalloc() is ready at that point and the loader does
    all kinds of allocations and init/registration with various
    subsystems.
    
    Make it a late initcall when required facilities are initialized
    so that the microcode driver initialization can succeed too.
    
    Reported-and-tested-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20151120112400.GC4028@pd.tnic
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 29db25f9a745..d2bbe343fda7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1250,8 +1250,6 @@ void __init setup_arch(char **cmdline_p)
 	if (efi_enabled(EFI_BOOT))
 		efi_apply_memmap_quirks();
 #endif
-
-	microcode_init();
 }
 
 #ifdef CONFIG_X86_32

commit 68accac392d859d24adcf1be3a90e41f978bd54c
Author: Krzysztof Mazur <krzysiek@podlesie.net>
Date:   Fri Nov 6 14:18:36 2015 +0100

    x86/setup: Fix low identity map for >= 2GB kernel range
    
    The commit f5f3497cad8c extended the low identity mapping. However, if
    the kernel uses more than 2 GB (VMSPLIT_2G_OPT or VMSPLIT_1G memory
    split), the normal memory mapping is overwritten by the low identity
    mapping causing a crash. To avoid overwritting, limit the low identity
    map to cover only memory before kernel range (PAGE_OFFSET).
    
    Fixes: f5f3497cad8c "x86/setup: Extend low identity map to cover whole kernel range
    Signed-off-by: Krzysztof Mazur <krzysiek@podlesie.net>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Laszlo Ersek <lersek@redhat.com>
    Cc: Matt Fleming <matt.fleming@intel.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/1446815916-22105-1-git-send-email-krzysiek@podlesie.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a1e4da98c8f0..29db25f9a745 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1188,7 +1188,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	clone_pgd_range(initial_page_table,
 			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
-			KERNEL_PGD_PTRS);
+			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
 #endif
 
 	tboot_probe();

commit b831ef2cad979912850e34f82415c0c5d59de8cb
Merge: b02ac6b18cd4 dc34bdd2367f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 3 17:51:33 2015 -0800

    Merge branch 'ras-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RAS changes from Ingo Molnar:
     "The main system reliability related changes were from x86, but also
      some generic RAS changes:
    
       - AMD MCE error injection subsystem enhancements.  (Aravind
         Gopalakrishnan)
    
       - Fix MCE and CPU hotplug interaction bug.  (Ashok Raj)
    
       - kcrash bootup robustness fix.  (Baoquan He)
    
       - kcrash cleanups.  (Borislav Petkov)
    
       - x86 microcode driver rework: simplify it by unmodularizing it and
         other cleanups.  (Borislav Petkov)"
    
    * 'ras-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      x86/mce: Add a default case to the switch in __mcheck_cpu_ancient_init()
      x86/mce: Add a Scalable MCA vendor flags bit
      MAINTAINERS: Unify the microcode driver section
      x86/microcode/intel: Move #ifdef DEBUG inside the function
      x86/microcode/amd: Remove maintainers from comments
      x86/microcode: Remove modularization leftovers
      x86/microcode: Merge the early microcode loader
      x86/microcode: Unmodularize the microcode driver
      x86/mce: Fix thermal throttling reporting after kexec
      kexec/crash: Say which char is the unrecognized
      x86/setup/crash: Check memblock_reserve() retval
      x86/setup/crash: Cleanup some more
      x86/setup/crash: Remove alignment variable
      x86/setup: Cleanup crashkernel reservation functions
      x86/amd_nb, EDAC: Rename amd_get_node_id()
      x86/setup: Do not reserve crashkernel high memory if low reservation failed
      x86/microcode/amd: Do not overwrite final patch levels
      x86/microcode/amd: Extract current patch level read to a function
      x86/ras/mce_amd_inj: Inject bank 4 errors on the NBC
      x86/ras/mce_amd_inj: Trigger deferred and thresholding errors interrupts
      ...

commit f5a8160c1e055c0fd8d16a5b3ac97c638365b0db
Merge: 7eeef2abe87d 78b9bc947b18
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 3 15:05:52 2015 -0800

    Merge branch 'core-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull EFI changes from Ingo Molnar:
     "The main changes in this cycle were:
    
       - further EFI code generalization to make it more workable for ARM64
       - various extensions, such as 64-bit framebuffer address support,
         UEFI v2.5 EFI_PROPERTIES_TABLE support
       - code modularization simplifications and cleanups
       - new debugging parameters
       - various fixes and smaller additions"
    
    * 'core-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      efi: Fix warning of int-to-pointer-cast on x86 32-bit builds
      efi: Use correct type for struct efi_memory_map::phys_map
      x86/efi: Fix kernel panic when CONFIG_DEBUG_VIRTUAL is enabled
      efi: Add "efi_fake_mem" boot option
      x86/efi: Rename print_efi_memmap() to efi_print_memmap()
      efi: Auto-load the efi-pstore module
      efi: Introduce EFI_NX_PE_DATA bit and set it from properties table
      efi: Add support for UEFIv2.5 Properties table
      efi: Add EFI_MEMORY_MORE_RELIABLE support to efi_md_typeattr_format()
      efifb: Add support for 64-bit frame buffer addresses
      efi/arm64: Clean up efi_get_fdt_params() interface
      arm64: Use core efi=debug instead of uefi_debug command line parameter
      efi/x86: Move efi=debug option parsing to core
      drivers/firmware: Make efi/esrt.c driver explicitly non-modular
      efi: Use the generic efi.memmap instead of 'memmap'
      acpi/apei: Use appropriate pgprot_t to map GHES memory
      arm64, acpi/apei: Implement arch_apei_get_mem_attributes()
      arm64/mm: Add PROT_DEVICE_nGnRnE and PROT_NORMAL_WT
      acpi, x86: Implement arch_apei_get_mem_attributes()
      efi, x86: Rearrange efi_mem_attributes()
      ...

commit 9a2bc335f100a0f6ee6392b9f97ac4188d84db1d
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Oct 20 11:54:44 2015 +0200

    x86/microcode: Unmodularize the microcode driver
    
    Make CONFIG_MICROCODE a bool. It was practically a bool already anyway,
    since early loader was forcing it to =y.
    
    Regardless, there's no real reason to have something be a module which
    gets built-in on the majority of installations out there. And its not
    like there's noticeable change in functionality - we still can load late
    microcode - just the module glue disappears.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Jones <davej@codemonkey.org.uk>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Link: http://lkml.kernel.org/r/1445334889-300-2-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3f75297d5fd0..3a896109e1df 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -111,6 +111,7 @@
 #include <asm/mce.h>
 #include <asm/alternative.h>
 #include <asm/prom.h>
+#include <asm/microcode.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
@@ -1239,6 +1240,8 @@ void __init setup_arch(char **cmdline_p)
 	if (efi_enabled(EFI_BOOT))
 		efi_apply_memmap_quirks();
 #endif
+
+	microcode_init();
 }
 
 #ifdef CONFIG_X86_32

commit 6f3760570e26eefc214e641b6daeddb7106240bb
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Oct 19 11:17:46 2015 +0200

    x86/setup/crash: Check memblock_reserve() retval
    
    memblock_reserve() can fail but the crashkernel reservation code
    doesn't check that and this can lead the user into believing
    that the crashkernel region was actually reserved. Make sure we
    check that return value and we exit early with a failure message
    in the error case.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: Joerg Roedel <jroedel@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: jerry_hoemann@hp.com
    Link: http://lkml.kernel.org/r/1445246268-26285-7-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d4788719a1e2..3f75297d5fd0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -531,7 +531,11 @@ static int __init reserve_crashkernel_low(void)
 		return -ENOMEM;
 	}
 
-	memblock_reserve(low_base, low_size);
+	ret = memblock_reserve(low_base, low_size);
+	if (ret) {
+		pr_err("%s: Error reserving crashkernel low memblock.\n", __func__);
+		return ret;
+	}
 
 	pr_info("Reserving %ldMB of low memory at %ldMB for crashkernel (System low RAM: %ldMB)\n",
 		(unsigned long)(low_size >> 20),
@@ -589,7 +593,11 @@ static void __init reserve_crashkernel(void)
 			return;
 		}
 	}
-	memblock_reserve(crash_base, crash_size);
+	ret = memblock_reserve(crash_base, crash_size);
+	if (ret) {
+		pr_err("%s: Error reserving crashkernel memblock.\n", __func__);
+		return;
+	}
 
 	if (crash_base >= (1ULL << 32) && reserve_crashkernel_low()) {
 		memblock_free(crash_base, crash_size);

commit f56d55781c1ff5663874775d0672ba954fe5634c
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Oct 19 11:17:45 2015 +0200

    x86/setup/crash: Cleanup some more
    
    * Remove unused auto_set variable
    * Cleanup local function variable declarations
    * Reformat printk string and use pr_info()
    
    No functionality change.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: Joerg Roedel <jroedel@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: jerry_hoemann@hp.com
    Link: http://lkml.kernel.org/r/1445246268-26285-6-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ea086dd8e821..d4788719a1e2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -499,17 +499,15 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 static int __init reserve_crashkernel_low(void)
 {
 #ifdef CONFIG_X86_64
-	unsigned long long low_base = 0, low_size = 0;
+	unsigned long long base, low_base = 0, low_size = 0;
 	unsigned long total_low_mem;
-	unsigned long long base;
-	bool auto_set = false;
 	int ret;
 
 	total_low_mem = memblock_mem_size(1UL << (32 - PAGE_SHIFT));
 
 	/* crashkernel=Y,low */
 	ret = parse_crashkernel_low(boot_command_line, total_low_mem, &low_size, &base);
-	if (ret != 0) {
+	if (ret) {
 		/*
 		 * two parts from lib/swiotlb.c:
 		 * -swiotlb size: user-specified with swiotlb= or default.
@@ -520,7 +518,6 @@ static int __init reserve_crashkernel_low(void)
 		 * don't run out of DMA buffers for 32-bit devices.
 		 */
 		low_size = max(swiotlb_size_or_default() + (8UL << 20), 256UL << 20);
-		auto_set = true;
 	} else {
 		/* passed with crashkernel=0,low ? */
 		if (!low_size)
@@ -550,8 +547,7 @@ static int __init reserve_crashkernel_low(void)
 
 static void __init reserve_crashkernel(void)
 {
-	unsigned long long total_mem;
-	unsigned long long crash_size, crash_base;
+	unsigned long long crash_size, crash_base, total_mem;
 	bool high = false;
 	int ret;
 
@@ -600,11 +596,10 @@ static void __init reserve_crashkernel(void)
 		return;
 	}
 
-	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
-			"for crashkernel (System RAM: %ldMB)\n",
-			(unsigned long)(crash_size >> 20),
-			(unsigned long)(crash_base >> 20),
-			(unsigned long)(total_mem >> 20));
+	pr_info("Reserving %ldMB of memory at %ldMB for crashkernel (System RAM: %ldMB)\n",
+		(unsigned long)(crash_size >> 20),
+		(unsigned long)(crash_base >> 20),
+		(unsigned long)(total_mem >> 20));
 
 	crashk_res.start = crash_base;
 	crashk_res.end   = crash_base + crash_size - 1;

commit 606134f77ce22997fd2800d5937698d85c6990d9
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Oct 19 11:17:44 2015 +0200

    x86/setup/crash: Remove alignment variable
    
    Use a macro instead. No functionality change.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: Joerg Roedel <jroedel@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: jerry_hoemann@hp.com
    Link: http://lkml.kernel.org/r/1445246268-26285-5-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fd9e178aa890..ea086dd8e821 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -480,6 +480,9 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 
 #ifdef CONFIG_KEXEC_CORE
 
+/* 16M alignment for crash kernel regions */
+#define CRASH_ALIGN		(16 << 20)
+
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels
  * would limit the kernel to the low 512 MiB due to mapping restrictions.
@@ -496,7 +499,6 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 static int __init reserve_crashkernel_low(void)
 {
 #ifdef CONFIG_X86_64
-	const unsigned long long alignment = 16<<20;	/* 16M */
 	unsigned long long low_base = 0, low_size = 0;
 	unsigned long total_low_mem;
 	unsigned long long base;
@@ -525,7 +527,7 @@ static int __init reserve_crashkernel_low(void)
 			return 0;
 	}
 
-	low_base = memblock_find_in_range(low_size, 1ULL << 32, low_size, alignment);
+	low_base = memblock_find_in_range(low_size, 1ULL << 32, low_size, CRASH_ALIGN);
 	if (!low_base) {
 		pr_err("Cannot reserve %ldMB crashkernel low memory, please try smaller size.\n",
 		       (unsigned long)(low_size >> 20));
@@ -548,7 +550,6 @@ static int __init reserve_crashkernel_low(void)
 
 static void __init reserve_crashkernel(void)
 {
-	const unsigned long long alignment = 16<<20;	/* 16M */
 	unsigned long long total_mem;
 	unsigned long long crash_size, crash_base;
 	bool high = false;
@@ -572,10 +573,10 @@ static void __init reserve_crashkernel(void)
 		/*
 		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
 		 */
-		crash_base = memblock_find_in_range(alignment,
+		crash_base = memblock_find_in_range(CRASH_ALIGN,
 						    high ? CRASH_ADDR_HIGH_MAX
 							 : CRASH_ADDR_LOW_MAX,
-						    crash_size, alignment);
+						    crash_size, CRASH_ALIGN);
 		if (!crash_base) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;

commit 97eac21babe47e1a8ed4cac4f8874c5746cf6e36
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Oct 19 11:17:43 2015 +0200

    x86/setup: Cleanup crashkernel reservation functions
    
    * Shorten variable names
    * Realign code, space out for better readability
    
    No code changed:
    
      # arch/x86/kernel/setup.o:
    
       text    data     bss     dec     hex filename
       4543    3096   69904   77543   12ee7 setup.o.before
       4543    3096   69904   77543   12ee7 setup.o.after
    
    md5:
       8a1b7c6738a553ca207b56bd84a8f359  setup.o.before.asm
       8a1b7c6738a553ca207b56bd84a8f359  setup.o.after.asm
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: Joerg Roedel <jroedel@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: jerry_hoemann@hp.com
    Link: http://lkml.kernel.org/r/1445246268-26285-4-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1b36839e41eb..fd9e178aa890 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -486,11 +486,11 @@ static void __init memblock_x86_reserve_range_setup_data(void)
  * On 64bit, old kexec-tools need to under 896MiB.
  */
 #ifdef CONFIG_X86_32
-# define CRASH_KERNEL_ADDR_LOW_MAX	(512 << 20)
-# define CRASH_KERNEL_ADDR_HIGH_MAX	(512 << 20)
+# define CRASH_ADDR_LOW_MAX	(512 << 20)
+# define CRASH_ADDR_HIGH_MAX	(512 << 20)
 #else
-# define CRASH_KERNEL_ADDR_LOW_MAX	(896UL<<20)
-# define CRASH_KERNEL_ADDR_HIGH_MAX	MAXMEM
+# define CRASH_ADDR_LOW_MAX	(896UL << 20)
+# define CRASH_ADDR_HIGH_MAX	MAXMEM
 #endif
 
 static int __init reserve_crashkernel_low(void)
@@ -503,10 +503,10 @@ static int __init reserve_crashkernel_low(void)
 	bool auto_set = false;
 	int ret;
 
-	total_low_mem = memblock_mem_size(1UL<<(32-PAGE_SHIFT));
+	total_low_mem = memblock_mem_size(1UL << (32 - PAGE_SHIFT));
+
 	/* crashkernel=Y,low */
-	ret = parse_crashkernel_low(boot_command_line, total_low_mem,
-						&low_size, &base);
+	ret = parse_crashkernel_low(boot_command_line, total_low_mem, &low_size, &base);
 	if (ret != 0) {
 		/*
 		 * two parts from lib/swiotlb.c:
@@ -517,7 +517,7 @@ static int __init reserve_crashkernel_low(void)
 		 * make sure we allocate enough extra low memory so that we
 		 * don't run out of DMA buffers for 32-bit devices.
 		 */
-		low_size = max(swiotlb_size_or_default() + (8UL<<20), 256UL<<20);
+		low_size = max(swiotlb_size_or_default() + (8UL << 20), 256UL << 20);
 		auto_set = true;
 	} else {
 		/* passed with crashkernel=0,low ? */
@@ -525,9 +525,7 @@ static int __init reserve_crashkernel_low(void)
 			return 0;
 	}
 
-	low_base = memblock_find_in_range(low_size, (1ULL<<32),
-					low_size, alignment);
-
+	low_base = memblock_find_in_range(low_size, 1ULL << 32, low_size, alignment);
 	if (!low_base) {
 		pr_err("Cannot reserve %ldMB crashkernel low memory, please try smaller size.\n",
 		       (unsigned long)(low_size >> 20));
@@ -535,10 +533,12 @@ static int __init reserve_crashkernel_low(void)
 	}
 
 	memblock_reserve(low_base, low_size);
+
 	pr_info("Reserving %ldMB of low memory at %ldMB for crashkernel (System low RAM: %ldMB)\n",
-			(unsigned long)(low_size >> 20),
-			(unsigned long)(low_base >> 20),
-			(unsigned long)(total_low_mem >> 20));
+		(unsigned long)(low_size >> 20),
+		(unsigned long)(low_base >> 20),
+		(unsigned long)(total_low_mem >> 20));
+
 	crashk_low_res.start = low_base;
 	crashk_low_res.end   = low_base + low_size - 1;
 	insert_resource(&iomem_resource, &crashk_low_res);
@@ -557,12 +557,11 @@ static void __init reserve_crashkernel(void)
 	total_mem = memblock_phys_mem_size();
 
 	/* crashkernel=XM */
-	ret = parse_crashkernel(boot_command_line, total_mem,
-			&crash_size, &crash_base);
+	ret = parse_crashkernel(boot_command_line, total_mem, &crash_size, &crash_base);
 	if (ret != 0 || crash_size <= 0) {
 		/* crashkernel=X,high */
 		ret = parse_crashkernel_high(boot_command_line, total_mem,
-				&crash_size, &crash_base);
+					     &crash_size, &crash_base);
 		if (ret != 0 || crash_size <= 0)
 			return;
 		high = true;
@@ -574,10 +573,9 @@ static void __init reserve_crashkernel(void)
 		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
 		 */
 		crash_base = memblock_find_in_range(alignment,
-					high ? CRASH_KERNEL_ADDR_HIGH_MAX :
-					       CRASH_KERNEL_ADDR_LOW_MAX,
-					crash_size, alignment);
-
+						    high ? CRASH_ADDR_HIGH_MAX
+							 : CRASH_ADDR_LOW_MAX,
+						    crash_size, alignment);
 		if (!crash_base) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
@@ -587,7 +585,8 @@ static void __init reserve_crashkernel(void)
 		unsigned long long start;
 
 		start = memblock_find_in_range(crash_base,
-				 crash_base + crash_size, crash_size, 1<<20);
+					       crash_base + crash_size,
+					       crash_size, 1 << 20);
 		if (start != crash_base) {
 			pr_info("crashkernel reservation failed - memory is in use.\n");
 			return;

commit eb6db83d105914c246ac5875be76fd4b944833d5
Author: Baoquan He <bhe@redhat.com>
Date:   Mon Oct 19 11:17:41 2015 +0200

    x86/setup: Do not reserve crashkernel high memory if low reservation failed
    
    People reported that when allocating crashkernel memory using
    the ",high" and ",low" syntax, there were cases where the
    reservation of the high portion succeeds but the reservation of
    the low portion fails.
    
    Then kexec can load the kdump kernel successfully, but booting
    the kdump kernel fails as there's no low memory.
    
    The low memory allocation for the kdump kernel can fail on large
    systems for a couple of reasons. For example, the manually
    specified crashkernel low memory can be too large and thus no
    adequate memblock region would be found.
    
    Therefore, we try to reserve low memory for the crash kernel
    *after* the high memory portion has been allocated. If that
    fails, we free crashkernel high memory too and return. The user
    can then take measures accordingly.
    
    Tested-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Baoquan He <bhe@redhat.com>
    [ Massage text. ]
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Joerg Roedel <jroedel@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: WANG Chao <chaowang@redhat.com>
    Cc: jerry_hoemann@hp.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/1445246268-26285-2-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fdb7f2a2d328..1b36839e41eb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -493,7 +493,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 # define CRASH_KERNEL_ADDR_HIGH_MAX	MAXMEM
 #endif
 
-static void __init reserve_crashkernel_low(void)
+static int __init reserve_crashkernel_low(void)
 {
 #ifdef CONFIG_X86_64
 	const unsigned long long alignment = 16<<20;	/* 16M */
@@ -522,17 +522,16 @@ static void __init reserve_crashkernel_low(void)
 	} else {
 		/* passed with crashkernel=0,low ? */
 		if (!low_size)
-			return;
+			return 0;
 	}
 
 	low_base = memblock_find_in_range(low_size, (1ULL<<32),
 					low_size, alignment);
 
 	if (!low_base) {
-		if (!auto_set)
-			pr_info("crashkernel low reservation failed - No suitable area found.\n");
-
-		return;
+		pr_err("Cannot reserve %ldMB crashkernel low memory, please try smaller size.\n",
+		       (unsigned long)(low_size >> 20));
+		return -ENOMEM;
 	}
 
 	memblock_reserve(low_base, low_size);
@@ -544,6 +543,7 @@ static void __init reserve_crashkernel_low(void)
 	crashk_low_res.end   = low_base + low_size - 1;
 	insert_resource(&iomem_resource, &crashk_low_res);
 #endif
+	return 0;
 }
 
 static void __init reserve_crashkernel(void)
@@ -595,6 +595,11 @@ static void __init reserve_crashkernel(void)
 	}
 	memblock_reserve(crash_base, crash_size);
 
+	if (crash_base >= (1ULL << 32) && reserve_crashkernel_low()) {
+		memblock_free(crash_base, crash_size);
+		return;
+	}
+
 	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
 			"for crashkernel (System RAM: %ldMB)\n",
 			(unsigned long)(crash_size >> 20),
@@ -604,9 +609,6 @@ static void __init reserve_crashkernel(void)
 	crashk_res.start = crash_base;
 	crashk_res.end   = crash_base + crash_size - 1;
 	insert_resource(&iomem_resource, &crashk_res);
-
-	if (crash_base >= (1ULL<<32))
-		reserve_crashkernel_low();
 }
 #else
 static void __init reserve_crashkernel(void)

commit f5f3497cad8c8416a74b9aaceb127908755d020a
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed Oct 14 13:30:45 2015 +0200

    x86/setup: Extend low identity map to cover whole kernel range
    
    On 32-bit systems, the initial_page_table is reused by
    efi_call_phys_prolog as an identity map to call
    SetVirtualAddressMap.  efi_call_phys_prolog takes care of
    converting the current CPU's GDT to a physical address too.
    
    For PAE kernels the identity mapping is achieved by aliasing the
    first PDPE for the kernel memory mapping into the first PDPE
    of initial_page_table.  This makes the EFI stub's trick "just work".
    
    However, for non-PAE kernels there is no guarantee that the identity
    mapping in the initial_page_table extends as far as the GDT; in this
    case, accesses to the GDT will cause a page fault (which quickly becomes
    a triple fault).  Fix this by copying the kernel mappings from
    swapper_pg_dir to initial_page_table twice, both at PAGE_OFFSET and at
    identity mapping.
    
    For some reason, this is only reproducible with QEMU's dynamic translation
    mode, and not for example with KVM.  However, even under KVM one can clearly
    see that the page table is bogus:
    
        $ qemu-system-i386 -pflash OVMF.fd -M q35 vmlinuz0 -s -S -daemonize
        $ gdb
        (gdb) target remote localhost:1234
        (gdb) hb *0x02858f6f
        Hardware assisted breakpoint 1 at 0x2858f6f
        (gdb) c
        Continuing.
    
        Breakpoint 1, 0x02858f6f in ?? ()
        (gdb) monitor info registers
        ...
        GDT=     0724e000 000000ff
        IDT=     fffbb000 000007ff
        CR0=0005003b CR2=ff896000 CR3=032b7000 CR4=00000690
        ...
    
    The page directory is sane:
    
        (gdb) x/4wx 0x32b7000
        0x32b7000:  0x03398063      0x03399063      0x0339a063      0x0339b063
        (gdb) x/4wx 0x3398000
        0x3398000:  0x00000163      0x00001163      0x00002163      0x00003163
        (gdb) x/4wx 0x3399000
        0x3399000:  0x00400003      0x00401003      0x00402003      0x00403003
    
    but our particular page directory entry is empty:
    
        (gdb) x/1wx 0x32b7000 + (0x724e000 >> 22) * 4
        0x32b7070:  0x00000000
    
    [ It appears that you can skate past this issue if you don't receive
      any interrupts while the bogus GDT pointer is loaded, or if you avoid
      reloading the segment registers in general.
    
      Andy Lutomirski provides some additional insight:
    
       "AFAICT it's entirely permissible for the GDTR and/or LDT
        descriptor to point to unmapped memory.  Any attempt to use them
        (segment loads, interrupts, IRET, etc) will try to access that memory
        as if the access came from CPL 0 and, if the access fails, will
        generate a valid page fault with CR2 pointing into the GDT or
        LDT."
    
      Up until commit 23a0d4e8fa6d ("efi: Disable interrupts around EFI
      calls, not in the epilog/prolog calls") interrupts were disabled
      around the prolog and epilog calls, and the functional GDT was
      re-installed before interrupts were re-enabled.
    
      Which explains why no one has hit this issue until now. ]
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Reported-by: Laszlo Ersek <lersek@redhat.com>
    Cc: <stable@vger.kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    [ Updated changelog. ]

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fdb7f2a2d328..a3cccbfc5f77 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1173,6 +1173,14 @@ void __init setup_arch(char **cmdline_p)
 	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
 			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
 			KERNEL_PGD_PTRS);
+
+	/*
+	 * sync back low identity map too.  It is used for example
+	 * in the 32-bit EFI stub.
+	 */
+	clone_pgd_range(initial_page_table,
+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
 #endif
 
 	tboot_probe();

commit 790a2ee2427852cff50993c98f15ed88511e9af0
Merge: c7d77a7980e4 0f96a99dab36
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Oct 14 16:05:40 2015 +0200

    Merge tag 'efi-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mfleming/efi into core/efi
    
    Pull v4.4 EFI updates from Matt Fleming:
    
      - Make the EFI System Resource Table (ESRT) driver explicitly
        non-modular by ripping out the module_* code since Kconfig doesn't
        allow it to be built as a module anyway. (Paul Gortmaker)
    
      - Make the x86 efi=debug kernel parameter, which enables EFI debug
        code and output, generic and usable by arm64. (Leif Lindholm)
    
      - Add support to the x86 EFI boot stub for 64-bit Graphics Output
        Protocol frame buffer addresses. (Matt Fleming)
    
      - Detect when the UEFI v2.5 EFI_PROPERTIES_TABLE feature is enabled
        in the firmware and set an efi.flags bit so the kernel knows when
        it can apply more strict runtime mapping attributes - Ard Biesheuvel
    
      - Auto-load the efi-pstore module on EFI systems, just like we
        currently do for the efivars module. (Ben Hutchings)
    
      - Add "efi_fake_mem" kernel parameter which allows the system's EFI
        memory map to be updated with additional attributes for specific
        memory ranges. This is useful for testing the kernel code that handles
        the EFI_MEMORY_MORE_RELIABLE memmap bit even if your firmware
        doesn't include support. (Taku Izumi)
    
    Note: there is a semantic conflict between the following two commits:
    
      8a53554e12e9 ("x86/efi: Fix multiple GOP device support")
      ae2ee627dc87 ("efifb: Add support for 64-bit frame buffer addresses")
    
    I fixed up the interaction in the merge commit, changing the type of
    current_fb_base from u32 to u64.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 0f96a99dab366333439e110d6ad253bc7c557c09
Author: Taku Izumi <izumi.taku@jp.fujitsu.com>
Date:   Wed Sep 30 23:01:56 2015 +0900

    efi: Add "efi_fake_mem" boot option
    
    This patch introduces new boot option named "efi_fake_mem".
    By specifying this parameter, you can add arbitrary attribute
    to specific memory range.
    This is useful for debugging of Address Range Mirroring feature.
    
    For example, if "efi_fake_mem=2G@4G:0x10000,2G@0x10a0000000:0x10000"
    is specified, the original (firmware provided) EFI memmap will be
    updated so that the specified memory regions have
    EFI_MEMORY_MORE_RELIABLE attribute (0x10000):
    
     <original>
       efi: mem36: [Conventional Memory|  |  |  |  |  |   |WB|WT|WC|UC] range=[0x0000000100000000-0x00000020a0000000) (129536MB)
    
     <updated>
       efi: mem36: [Conventional Memory|  |MR|  |  |  |   |WB|WT|WC|UC] range=[0x0000000100000000-0x0000000180000000) (2048MB)
       efi: mem37: [Conventional Memory|  |  |  |  |  |   |WB|WT|WC|UC] range=[0x0000000180000000-0x00000010a0000000) (61952MB)
       efi: mem38: [Conventional Memory|  |MR|  |  |  |   |WB|WT|WC|UC] range=[0x00000010a0000000-0x0000001120000000) (2048MB)
       efi: mem39: [Conventional Memory|  |  |  |  |  |   |WB|WT|WC|UC] range=[0x0000001120000000-0x00000020a0000000) (63488MB)
    
    And you will find that the following message is output:
    
       efi: Memory: 4096M/131455M mirrored memory
    
    Signed-off-by: Taku Izumi <izumi.taku@jp.fujitsu.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Xishi Qiu <qiuxishi@huawei.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 80f874bf999e..e3ed628f7db4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1104,8 +1104,10 @@ void __init setup_arch(char **cmdline_p)
 	memblock_set_current_limit(ISA_END_ADDRESS);
 	memblock_x86_fill();
 
-	if (efi_enabled(EFI_BOOT))
+	if (efi_enabled(EFI_BOOT)) {
+		efi_fake_memmap();
 		efi_find_mirror();
+	}
 
 	/*
 	 * The EFI specification says that boot service code won't be called

commit 2965faa5e03d1e71e9ff9aa143fff39e0a77543a
Author: Dave Young <dyoung@redhat.com>
Date:   Wed Sep 9 15:38:55 2015 -0700

    kexec: split kexec_load syscall from kexec core code
    
    There are two kexec load syscalls, kexec_load another and kexec_file_load.
     kexec_file_load has been splited as kernel/kexec_file.c.  In this patch I
    split kexec_load syscall code to kernel/kexec.c.
    
    And add a new kconfig option KEXEC_CORE, so we can disable kexec_load and
    use kexec_file_load only, or vice verse.
    
    The original requirement is from Ted Ts'o, he want kexec kernel signature
    being checked with CONFIG_KEXEC_VERIFY_SIG enabled.  But kexec-tools use
    kexec_load syscall can bypass the checking.
    
    Vivek Goyal proposed to create a common kconfig option so user can compile
    in only one syscall for loading kexec kernel.  KEXEC/KEXEC_FILE selects
    KEXEC_CORE so that old config files still work.
    
    Because there's general code need CONFIG_KEXEC_CORE, so I updated all the
    architecture Kconfig with a new option KEXEC_CORE, and let KEXEC selects
    KEXEC_CORE in arch Kconfig.  Also updated general kernel code with to
    kexec_load syscall.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Petr Tesarik <ptesarik@suse.cz>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Josh Boyer <jwboyer@fedoraproject.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index baadbf90a7c5..fdb7f2a2d328 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -478,7 +478,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
  * --------- Crashkernel reservation ------------------------------
  */
 
-#ifdef CONFIG_KEXEC
+#ifdef CONFIG_KEXEC_CORE
 
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels

commit 5dd2c4bded8776ee93c8f38b739fea531095067f
Author: Mark Salter <msalter@redhat.com>
Date:   Tue Sep 8 15:03:07 2015 -0700

    x86: use generic early mem copy
    
    The early_ioremap library now has a generic copy_from_early_mem()
    function.  Use the generic copy function for x86 relocate_initrd().
    
    [akpm@linux-foundation.org: remove MAX_MAP_CHUNK define, per Yinghai Lu]
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b143c2d04420..baadbf90a7c5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -317,15 +317,12 @@ static u64 __init get_ramdisk_size(void)
 	return ramdisk_size;
 }
 
-#define MAX_MAP_CHUNK	(NR_FIX_BTMAPS << PAGE_SHIFT)
 static void __init relocate_initrd(void)
 {
 	/* Assume only end is not page aligned */
 	u64 ramdisk_image = get_ramdisk_image();
 	u64 ramdisk_size  = get_ramdisk_size();
 	u64 area_size     = PAGE_ALIGN(ramdisk_size);
-	unsigned long slop, clen, mapaddr;
-	char *p, *q;
 
 	/* We need to move the initrd down into directly mapped mem */
 	relocated_ramdisk = memblock_find_in_range(0, PFN_PHYS(max_pfn_mapped),
@@ -343,25 +340,8 @@ static void __init relocate_initrd(void)
 	printk(KERN_INFO "Allocated new RAMDISK: [mem %#010llx-%#010llx]\n",
 	       relocated_ramdisk, relocated_ramdisk + ramdisk_size - 1);
 
-	q = (char *)initrd_start;
-
-	/* Copy the initrd */
-	while (ramdisk_size) {
-		slop = ramdisk_image & ~PAGE_MASK;
-		clen = ramdisk_size;
-		if (clen > MAX_MAP_CHUNK-slop)
-			clen = MAX_MAP_CHUNK-slop;
-		mapaddr = ramdisk_image & PAGE_MASK;
-		p = early_memremap(mapaddr, clen+slop);
-		memcpy(q, p+slop, clen);
-		early_memunmap(p, clen+slop);
-		q += clen;
-		ramdisk_image += clen;
-		ramdisk_size  -= clen;
-	}
+	copy_from_early_mem((void *)initrd_start, ramdisk_image, ramdisk_size);
 
-	ramdisk_image = get_ramdisk_image();
-	ramdisk_size  = get_ramdisk_size();
 	printk(KERN_INFO "Move RAMDISK from [mem %#010llx-%#010llx] to"
 		" [mem %#010llx-%#010llx]\n",
 		ramdisk_image, ramdisk_image + ramdisk_size - 1,

commit 949163015ce6fdb76a5e846a3582d3c40c23c001
Author: Paolo Pisati <p.pisati@gmail.com>
Date:   Mon Jul 20 18:23:50 2015 +0200

    x86/boot: Obsolete the MCA sys_desc_table
    
    The kernel does not support the MCA bus anymroe, so mark sys_desc_table
    as obsolete: remove any reference from the code together with the remaining
    of MCA logic.
    
    bloat-o-meter output:
    
      add/remove: 0/0 grow/shrink: 0/2 up/down: 0/-55 (-55)
      function                                     old     new   delta
      i386_start_kernel                            128     119      -9
      setup_arch                                  1421    1375     -46
    
    Signed-off-by: Paolo Pisati <p.pisati@gmail.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1437409430-8491-1-git-send-email-p.pisati@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 80f874bf999e..b143c2d04420 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -916,11 +916,6 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_32
 	apm_info.bios = boot_params.apm_bios_info;
 	ist_info = boot_params.ist_info;
-	if (boot_params.sys_desc_table.length != 0) {
-		machine_id = boot_params.sys_desc_table.table[0];
-		machine_submodel_id = boot_params.sys_desc_table.table[1];
-		BIOS_revision = boot_params.sys_desc_table.table[2];
-	}
 #endif
 	saved_video_mode = boot_params.hdr.vid_mode;
 	bootloader_type = boot_params.hdr.type_of_loader;

commit b1be9ead135939136b87d73004891a6bac35bb43
Merge: 22a093b2fb52 b96fecbfa8c8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 4 08:58:50 2015 -0700

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fixes from Ingo Molnar:
     "Two FPU rewrite related fixes.  This addresses all known x86
      regressions at this stage.  Also some other misc fixes"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/fpu: Fix boot crash in the early FPU code
      x86/asm/entry/64: Update path names
      x86/fpu: Fix FPU related boot regression when CPUID masking BIOS feature is enabled
      x86/boot/setup: Clean up the e820_reserve_setup_data() code
      x86/kaslr: Fix typo in the KASLR_FLAG documentation

commit dc5fb575df9cdd34ac12bf7a814c9beae0a7ca9b
Merge: db52ef74b35d f2af7d25b4aa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Jun 30 07:57:04 2015 +0200

    Merge branch 'x86/boot' into x86/urgent
    
    Merge branch that got ready.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b05b9f5f9dcf593a0e9327676b78e6c17b4218e8
Author: Tony Luck <tony.luck@intel.com>
Date:   Wed Jun 24 16:58:15 2015 -0700

    x86, mirror: x86 enabling - find mirrored memory ranges
    
    UEFI GetMemoryMap() uses a new attribute bit to mark mirrored memory
    address ranges.  See UEFI 2.5 spec pages 157-158:
    
      http://www.uefi.org/sites/default/files/resources/UEFI%202_5.pdf
    
    On EFI enabled systems scan the memory map and tell memblock about any
    mirrored ranges.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Cc: Xishi Qiu <qiuxishi@huawei.com>
    Cc: Hanjun Guo <guohanjun@huawei.com>
    Cc: Xiexiuqi <xiexiuqi@huawei.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Naoya Horiguchi <nao.horiguchi@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 39ca113676fe..d3b95b89e9b2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1105,6 +1105,9 @@ void __init setup_arch(char **cmdline_p)
 	memblock_set_current_limit(ISA_END_ADDRESS);
 	memblock_x86_fill();
 
+	if (efi_enabled(EFI_BOOT))
+		efi_find_mirror();
+
 	/*
 	 * The EFI specification says that boot service code won't be called
 	 * after ExitBootServices(). This is, in fact, a lie.

commit 0faef837e431b4984652f4a14d2075bed108a04d
Merge: 67db8a8086e9 110c14664514
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 23 14:07:26 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching
    
    Pull livepatching fixes from Jiri Kosina:
    
     - symbol lookup locking fix, from Miroslav Benes
    
     - error handling improvements in case of failure of the module coming
       notifier, from Minfei Huang
    
     - we were too pessimistic when kASLR has been enabled on x86 and were
       dropping address hints on the floor unnecessarily in such case.  Fix
       from Jiri Kosina
    
     - a few other small fixes and cleanups
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching:
      livepatch: add module locking around kallsyms calls
      livepatch: annotate klp_init() with __init
      livepatch: introduce patch/func-walking helpers
      livepatch: make kobject in klp_object statically allocated
      livepatch: Prevent patch inconsistencies if the coming module notifier fails
      livepatch: match return value to function signature
      x86: kaslr: fix build due to missing ALIGN definition
      livepatch: x86: make kASLR logic more accurate
      x86: introduce kaslr_offset()

commit d70b3ef54ceaf1c7c92209f5a662a670d04cbed9
Merge: 650ec5a6bd5d 7ef3d7d58d9d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 22 17:59:09 2015 -0700

    Merge branch 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 core updates from Ingo Molnar:
     "There were so many changes in the x86/asm, x86/apic and x86/mm topics
      in this cycle that the topical separation of -tip broke down somewhat -
      so the result is a more traditional architecture pull request,
      collected into the 'x86/core' topic.
    
      The topics were still maintained separately as far as possible, so
      bisectability and conceptual separation should still be pretty good -
      but there were a handful of merge points to avoid excessive
      dependencies (and conflicts) that would have been poorly tested in the
      end.
    
      The next cycle will hopefully be much more quiet (or at least will
      have fewer dependencies).
    
      The main changes in this cycle were:
    
       * x86/apic changes, with related IRQ core changes: (Jiang Liu, Thomas
         Gleixner)
    
         - This is the second and most intrusive part of changes to the x86
           interrupt handling - full conversion to hierarchical interrupt
           domains:
    
              [IOAPIC domain]   -----
                                     |
              [MSI domain]      --------[Remapping domain] ----- [ Vector domain ]
                                     |   (optional)          |
              [HPET MSI domain] -----                        |
                                                             |
              [DMAR domain]     -----------------------------
                                                             |
              [Legacy domain]   -----------------------------
    
           This now reflects the actual hardware and allowed us to distangle
           the domain specific code from the underlying parent domain, which
           can be optional in the case of interrupt remapping.  It's a clear
           separation of functionality and removes quite some duct tape
           constructs which plugged the remap code between ioapic/msi/hpet
           and the vector management.
    
         - Intel IOMMU IRQ remapping enhancements, to allow direct interrupt
           injection into guests (Feng Wu)
    
       * x86/asm changes:
    
         - Tons of cleanups and small speedups, micro-optimizations.  This
           is in preparation to move a good chunk of the low level entry
           code from assembly to C code (Denys Vlasenko, Andy Lutomirski,
           Brian Gerst)
    
         - Moved all system entry related code to a new home under
           arch/x86/entry/ (Ingo Molnar)
    
         - Removal of the fragile and ugly CFI dwarf debuginfo annotations.
           Conversion to C will reintroduce many of them - but meanwhile
           they are only getting in the way, and the upstream kernel does
           not rely on them (Ingo Molnar)
    
         - NOP handling refinements. (Borislav Petkov)
    
       * x86/mm changes:
    
         - Big PAT and MTRR rework: making the code more robust and
           preparing to phase out exposing direct MTRR interfaces to drivers -
           in favor of using PAT driven interfaces (Toshi Kani, Luis R
           Rodriguez, Borislav Petkov)
    
         - New ioremap_wt()/set_memory_wt() interfaces to support
           Write-Through cached memory mappings.  This is especially
           important for good performance on NVDIMM hardware (Toshi Kani)
    
       * x86/ras changes:
    
         - Add support for deferred errors on AMD (Aravind Gopalakrishnan)
    
           This is an important RAS feature which adds hardware support for
           poisoned data.  That means roughly that the hardware marks data
           which it has detected as corrupted but wasn't able to correct, as
           poisoned data and raises an APIC interrupt to signal that in the
           form of a deferred error.  It is the OS's responsibility then to
           take proper recovery action and thus prolonge system lifetime as
           far as possible.
    
         - Add support for Intel "Local MCE"s: upcoming CPUs will support
           CPU-local MCE interrupts, as opposed to the traditional system-
           wide broadcasted MCE interrupts (Ashok Raj)
    
         - Misc cleanups (Borislav Petkov)
    
       * x86/platform changes:
    
         - Intel Atom SoC updates
    
      ... and lots of other cleanups, fixlets and other changes - see the
      shortlog and the Git log for details"
    
    * 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (222 commits)
      x86/hpet: Use proper hpet device number for MSI allocation
      x86/hpet: Check for irq==0 when allocating hpet MSI interrupts
      x86/mm/pat, drivers/infiniband/ipath: Use arch_phys_wc_add() and require PAT disabled
      x86/mm/pat, drivers/media/ivtv: Use arch_phys_wc_add() and require PAT disabled
      x86/platform/intel/baytrail: Add comments about why we disabled HPET on Baytrail
      genirq: Prevent crash in irq_move_irq()
      genirq: Enhance irq_data_to_desc() to support hierarchy irqdomain
      iommu, x86: Properly handle posted interrupts for IOMMU hotplug
      iommu, x86: Provide irq_remapping_cap() interface
      iommu, x86: Setup Posted-Interrupts capability for Intel iommu
      iommu, x86: Add cap_pi_support() to detect VT-d PI capability
      iommu, x86: Avoid migrating VT-d posted interrupts
      iommu, x86: Save the mode (posted or remapped) of an IRTE
      iommu, x86: Implement irq_set_vcpu_affinity for intel_ir_chip
      iommu: dmar: Provide helper to copy shared irte fields
      iommu: dmar: Extend struct irte for VT-d Posted-Interrupts
      iommu: Add new member capability to struct irq_remap_ops
      x86/asm/entry/64: Disentangle error_entry/exit gsbase/ebx/usermode code
      x86/asm/entry/32: Shorten __audit_syscall_entry() args preparation
      x86/asm/entry/32: Explain reloading of registers after __audit_syscall_entry()
      ...

commit 94fb9334182284e8e7e4bcb9125c25dc33af19d4
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Jun 10 17:49:42 2015 +0200

    x86/crash: Allocate enough low memory when crashkernel=high
    
    When the crash kernel is loaded above 4GiB in memory, the
    first kernel allocates only 72MiB of low-memory for the DMA
    requirements of the second kernel. On systems with many
    devices this is not enough and causes device driver
    initialization errors and failed crash dumps. Testing by
    SUSE and Redhat has shown that 256MiB is a good default
    value for now and the discussion has lead to this value as
    well. So set this default value to 256MiB to make sure there
    is enough memory available for DMA.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    [ Reflow comment. ]
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Baoquan He <bhe@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: J√∂rg R√∂del <joro@8bytes.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: kexec@lists.infradead.org
    Link: http://lkml.kernel.org/r/1433500202-25531-4-git-send-email-joro@8bytes.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d74ac33290ae..cba828892790 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -531,12 +531,14 @@ static void __init reserve_crashkernel_low(void)
 	if (ret != 0) {
 		/*
 		 * two parts from lib/swiotlb.c:
-		 *	swiotlb size: user specified with swiotlb= or default.
-		 *	swiotlb overflow buffer: now is hardcoded to 32k.
-		 *		We round it to 8M for other buffers that
-		 *		may need to stay low too.
+		 * -swiotlb size: user-specified with swiotlb= or default.
+		 *
+		 * -swiotlb overflow buffer: now hardcoded to 32k. We round it
+		 * to 8M for other buffers that may need to stay low too. Also
+		 * make sure we allocate enough extra low memory so that we
+		 * don't run out of DMA buffers for 32-bit devices.
 		 */
-		low_size = swiotlb_size_or_default() + (8UL<<20);
+		low_size = max(swiotlb_size_or_default() + (8UL<<20), 256UL<<20);
 		auto_set = true;
 	} else {
 		/* passed with crashkernel=0,low ? */

commit f2af7d25b4aa5b01203cc76e7530ea7fd18864a0
Author: Wei Yang <weiyang@linux.vnet.ibm.com>
Date:   Thu Jun 4 14:18:49 2015 +0800

    x86/boot/setup: Clean up the e820_reserve_setup_data() code
    
    Deobfuscate the 'found' logic, it can be replaced with a simple:
    
            if (!pa_data)
                    return;
    
    and 'found' can be eliminated.
    
    Signed-off-by: Wei Yang <weiyang@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1433398729-8314-1-git-send-email-weiyang@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d74ac33290ae..c3992c3a4378 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -461,19 +461,18 @@ static void __init e820_reserve_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
-	int found = 0;
 
 	pa_data = boot_params.hdr.setup_data;
+	if (!pa_data)
+		return;
+
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));
 		e820_update_range(pa_data, sizeof(*data)+data->len,
 			 E820_RAM, E820_RESERVED_KERN);
-		found = 1;
 		pa_data = data->next;
 		early_memunmap(data, sizeof(*data));
 	}
-	if (!found)
-		return;
 
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 	memcpy(&e820_saved, &e820, sizeof(struct e820map));

commit 4545c89880138b30a868159bc1b209867b8a5f32
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Mon Apr 27 13:17:19 2015 +0200

    x86: introduce kaslr_offset()
    
    Offset that has been chosen for kaslr during kernel decompression can be
    easily computed as a difference between _text and __START_KERNEL. We are
    already making use of this in dump_kernel_offset() notifier and in
    arch_crash_save_vmcoreinfo().
    
    Introduce kaslr_offset() that makes this computation instead of hard-coding
    it, so that other kernel code (such as live patching) can make use of it.
    Also convert existing users to make use of it.
    
    This patch is equivalent transofrmation without any effects on the resulting
    code:
    
            $ diff -u vmlinux.old.asm vmlinux.new.asm
            --- vmlinux.old.asm     2015-04-28 17:55:19.520983368 +0200
            +++ vmlinux.new.asm     2015-04-28 17:55:24.141206072 +0200
            @@ -1,5 +1,5 @@
    
            -vmlinux.old:     file format elf64-x86-64
            +vmlinux.new:     file format elf64-x86-64
    
            Disassembly of section .text:
            $
    
    Acked-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d74ac33290ae..5056d3cfe266 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -834,7 +834,7 @@ dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
 	if (kaslr_enabled()) {
 		pr_emerg("Kernel Offset: 0x%lx from 0x%lx (relocation range: 0x%lx-0x%lx)\n",
-			 (unsigned long)&_text - __START_KERNEL,
+			 kaslr_offset(),
 			 __START_KERNEL,
 			 __START_KERNEL_map,
 			 MODULES_VADDR-1);

commit ca1b88622e9c16df7b1e0a57e9c6c2300321bed4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 24 13:57:48 2015 +0200

    x86: Remove more unmodified io_apic_ops
    
    io_apic_ops.init() is either NULL, if IO-APIC support is disabled at
    compile time or native_io_apic_init_mappings(). No point to have that
    as we can achieve the same thing with an empty inline.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d74ac33290ae..8d04a7594a03 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1222,8 +1222,7 @@ void __init setup_arch(char **cmdline_p)
 	init_cpu_to_node();
 
 	init_apic_mappings();
-	if (x86_io_apic_ops.init)
-		x86_io_apic_ops.init();
+	io_apic_init_mappings();
 
 	kvm_guest_init();
 

commit 6cf78d4b3766bcd25348d72377796f9566ac8e1a
Merge: 0ad5c6b3c2d1 4e26d11f5268
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 13 12:31:32 2015 -0800

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm changes from Ingo Molnar:
     "The main changes in this cycle were:
    
       - reduce the x86/32 PAE per task PGD allocation overhead from 4K to
         0.032k (Fenghua Yu)
    
       - early_ioremap/memunmap() usage cleanups (Juergen Gross)
    
       - gbpages support cleanups (Luis R Rodriguez)
    
       - improve AMD Bulldozer (family 0x15) ASLR I$ aliasing workaround to
         increase randomization by 3 bits (per bootup) (Hector
         Marco-Gisbert)
    
       - misc fixlets"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/mm: Improve AMD Bulldozer ASLR workaround
      x86/mm/pat: Initialize __cachemode2pte_tbl[] and __pte2cachemode_tbl[] in a bit more readable fashion
      init.h: Clean up the __setup()/early_param() macros
      x86/mm: Simplify probe_page_size_mask()
      x86/mm: Further simplify 1 GB kernel linear mappings handling
      x86/mm: Use early_param_on_off() for direct_gbpages
      init.h: Add early_param_on_off()
      x86/mm: Simplify enabling direct_gbpages
      x86/mm: Use IS_ENABLED() for direct_gbpages
      x86/mm: Unexport set_memory_ro() and set_memory_rw()
      x86/mm, efi: Use early_ioremap() in arch/x86/platform/efi/efi-bgrt.c
      x86/mm: Use early_memunmap() instead of early_iounmap()
      x86/mm/pat: Ensure different messages in STRICT_DEVMEM and PAT cases
      x86/mm: Reduce PAE-mode per task pgd allocation overhead from 4K to 32 bytes

commit 78cac48c0434c82e860fade3cd0420a7a4adbb08
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Apr 1 12:49:52 2015 +0200

    x86/mm/KASLR: Propagate KASLR status to kernel proper
    
    Commit:
    
      e2b32e678513 ("x86, kaslr: randomize module base load address")
    
    made module base address randomization unconditional and didn't regard
    disabled KKASLR due to CONFIG_HIBERNATION and command line option
    "nokaslr". For more info see (now reverted) commit:
    
      f47233c2d34f ("x86/mm/ASLR: Propagate base load address calculation")
    
    In order to propagate KASLR status to kernel proper, we need a single bit
    in boot_params.hdr.loadflags and we've chosen bit 1 thus leaving the
    top-down allocated bits for bits supposed to be used by the bootloader.
    
    Originally-From: Jiri Kosina <jkosina@suse.cz>
    Suggested-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0a2421cca01f..014466b152b5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -832,10 +832,15 @@ static void __init trim_low_memory_range(void)
 static int
 dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
-	pr_emerg("Kernel Offset: 0x%lx from 0x%lx "
-		 "(relocation range: 0x%lx-0x%lx)\n",
-		 (unsigned long)&_text - __START_KERNEL, __START_KERNEL,
-		 __START_KERNEL_map, MODULES_VADDR-1);
+	if (kaslr_enabled()) {
+		pr_emerg("Kernel Offset: 0x%lx from 0x%lx (relocation range: 0x%lx-0x%lx)\n",
+			 (unsigned long)&_text - __START_KERNEL,
+			 __START_KERNEL,
+			 __START_KERNEL_map,
+			 MODULES_VADDR-1);
+	} else {
+		pr_emerg("Kernel Offset: disabled\n");
+	}
 
 	return 0;
 }

commit 69797dafe35541bfff1989c0b37c66ed785faf0e
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Mar 16 11:06:28 2015 +0100

    Revert "x86/mm/ASLR: Propagate base load address calculation"
    
    This reverts commit:
    
      f47233c2d34f ("x86/mm/ASLR: Propagate base load address calculation")
    
    The main reason for the revert is that the new boot flag does not work
    at all currently, and in order to make this work, we need non-trivial
    changes to the x86 boot code which we didn't manage to get done in
    time for merging.
    
    And even if we did, they would've been too risky so instead of
    rushing things and break booting 4.1 on boxes left and right, we
    will be very strict and conservative and will take our time with
    this to fix and test it properly.
    
    Reported-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: H. Peter Anvin <hpa@linux.intel.com
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Junjie Mao <eternal.n08@gmail.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt.fleming@intel.com>
    Link: http://lkml.kernel.org/r/20150316100628.GD22995@pd.tnic
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 98dc9317286e..0a2421cca01f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -122,8 +122,6 @@
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
 
-bool __read_mostly kaslr_enabled = false;
-
 #ifdef CONFIG_DMI
 RESERVE_BRK(dmi_alloc, 65536);
 #endif
@@ -427,11 +425,6 @@ static void __init reserve_initrd(void)
 }
 #endif /* CONFIG_BLK_DEV_INITRD */
 
-static void __init parse_kaslr_setup(u64 pa_data, u32 data_len)
-{
-	kaslr_enabled = (bool)(pa_data + sizeof(struct setup_data));
-}
-
 static void __init parse_setup_data(void)
 {
 	struct setup_data *data;
@@ -457,9 +450,6 @@ static void __init parse_setup_data(void)
 		case SETUP_EFI:
 			parse_efi_setup(pa_data, data_len);
 			break;
-		case SETUP_KASLR:
-			parse_kaslr_setup(pa_data, data_len);
-			break;
 		default:
 			break;
 		}
@@ -842,14 +832,10 @@ static void __init trim_low_memory_range(void)
 static int
 dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
-	if (kaslr_enabled)
-		pr_emerg("Kernel Offset: 0x%lx from 0x%lx (relocation range: 0x%lx-0x%lx)\n",
-			 (unsigned long)&_text - __START_KERNEL,
-			 __START_KERNEL,
-			 __START_KERNEL_map,
-			 MODULES_VADDR-1);
-	else
-		pr_emerg("Kernel Offset: disabled\n");
+	pr_emerg("Kernel Offset: 0x%lx from 0x%lx "
+		 "(relocation range: 0x%lx-0x%lx)\n",
+		 (unsigned long)&_text - __START_KERNEL, __START_KERNEL,
+		 __START_KERNEL_map, MODULES_VADDR-1);
 
 	return 0;
 }

commit 8d4a40bc0651ea51c196a3d3016d041c41ec19a2
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Feb 24 10:13:28 2015 +0100

    x86/mm: Use early_memunmap() instead of early_iounmap()
    
    Memory mapped via early_memremap() should be unmapped with
    early_memunmap() instead of early_iounmap().
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Cc: matt.fleming@intel.com
    Link: http://lkml.kernel.org/r/1424769211-11378-2-git-send-email-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 98dc9317286e..733864a653ab 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -356,7 +356,7 @@ static void __init relocate_initrd(void)
 		mapaddr = ramdisk_image & PAGE_MASK;
 		p = early_memremap(mapaddr, clen+slop);
 		memcpy(q, p+slop, clen);
-		early_iounmap(p, clen+slop);
+		early_memunmap(p, clen+slop);
 		q += clen;
 		ramdisk_image += clen;
 		ramdisk_size  -= clen;
@@ -445,7 +445,7 @@ static void __init parse_setup_data(void)
 		data_len = data->len + sizeof(struct setup_data);
 		data_type = data->type;
 		pa_next = data->next;
-		early_iounmap(data, sizeof(*data));
+		early_memunmap(data, sizeof(*data));
 
 		switch (data_type) {
 		case SETUP_E820_EXT:
@@ -480,7 +480,7 @@ static void __init e820_reserve_setup_data(void)
 			 E820_RAM, E820_RESERVED_KERN);
 		found = 1;
 		pa_data = data->next;
-		early_iounmap(data, sizeof(*data));
+		early_memunmap(data, sizeof(*data));
 	}
 	if (!found)
 		return;
@@ -501,7 +501,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 		data = early_memremap(pa_data, sizeof(*data));
 		memblock_reserve(pa_data, sizeof(*data) + data->len);
 		pa_data = data->next;
-		early_iounmap(data, sizeof(*data));
+		early_memunmap(data, sizeof(*data));
 	}
 }
 

commit 5fbe4c224ce3e2e62bd487158dfd1e89f9ae3e11
Merge: e2defd02717e 570e1aa84c37
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 21 10:41:29 2015 -0800

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull misc x86 fixes from Ingo Molnar:
     "This contains:
    
       - EFI fixes
       - a boot printout fix
       - ASLR/kASLR fixes
       - intel microcode driver fixes
       - other misc fixes
    
      Most of the linecount comes from an EFI revert"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/mm/ASLR: Avoid PAGE_SIZE redefinition for UML subarch
      x86/microcode/intel: Handle truncated microcode images more robustly
      x86/microcode/intel: Guard against stack overflow in the loader
      x86, mm/ASLR: Fix stack randomization on 64-bit systems
      x86/mm/init: Fix incorrect page size in init_memory_mapping() printks
      x86/mm/ASLR: Propagate base load address calculation
      Documentation/x86: Fix path in zero-page.txt
      x86/apic: Fix the devicetree build in certain configs
      Revert "efi/libstub: Call get_memory_map() to obtain map and desc sizes"
      x86/efi: Avoid triple faults during EFI mixed mode calls

commit a267b0a349bb021c010e36a2a13e1e16657b1b0f
Merge: ee408b4207c8 4e7c22d447bb
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 19 12:06:04 2015 +0100

    Merge branch 'tip-x86-kaslr' of git://git.kernel.org/pub/scm/linux/kernel/git/bp/bp into x86/urgent
    
    Pull ASLR and kASLR fixes from Borislav Petkov:
    
      - Add a global flag announcing KASLR state so that relevant code can do
        informed decisions based on its setting. (Jiri Kosina)
    
      - Fix a stack randomization entropy decrease bug. (Hector Marco-Gisbert)
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit f47233c2d34f243ecdaac179c3408a39ff9216a7
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Fri Feb 13 16:04:55 2015 +0100

    x86/mm/ASLR: Propagate base load address calculation
    
    Commit:
    
      e2b32e678513 ("x86, kaslr: randomize module base load address")
    
    makes the base address for module to be unconditionally randomized in
    case when CONFIG_RANDOMIZE_BASE is defined and "nokaslr" option isn't
    present on the commandline.
    
    This is not consistent with how choose_kernel_location() decides whether
    it will randomize kernel load base.
    
    Namely, CONFIG_HIBERNATION disables kASLR (unless "kaslr" option is
    explicitly specified on kernel commandline), which makes the state space
    larger than what module loader is looking at. IOW CONFIG_HIBERNATION &&
    CONFIG_RANDOMIZE_BASE is a valid config option, kASLR wouldn't be applied
    by default in that case, but module loader is not aware of that.
    
    Instead of fixing the logic in module.c, this patch takes more generic
    aproach. It introduces a new bootparam setup data_type SETUP_KASLR and
    uses that to pass the information whether kaslr has been applied during
    kernel decompression, and sets a global 'kaslr_enabled' variable
    accordingly, so that any kernel code (module loading, livepatching, ...)
    can make decisions based on its value.
    
    x86 module loader is converted to make use of this flag.
    
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: "H. Peter Anvin" <hpa@linux.intel.com>
    Link: https://lkml.kernel.org/r/alpine.LNX.2.00.1502101411280.10719@pobox.suse.cz
    [ Always dump correct kaslr status when panicking ]
    Signed-off-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ab4734e5411d..16b6043cb073 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -121,6 +121,8 @@
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
 
+bool __read_mostly kaslr_enabled = false;
+
 #ifdef CONFIG_DMI
 RESERVE_BRK(dmi_alloc, 65536);
 #endif
@@ -424,6 +426,11 @@ static void __init reserve_initrd(void)
 }
 #endif /* CONFIG_BLK_DEV_INITRD */
 
+static void __init parse_kaslr_setup(u64 pa_data, u32 data_len)
+{
+	kaslr_enabled = (bool)(pa_data + sizeof(struct setup_data));
+}
+
 static void __init parse_setup_data(void)
 {
 	struct setup_data *data;
@@ -451,6 +458,9 @@ static void __init parse_setup_data(void)
 		case SETUP_EFI:
 			parse_efi_setup(pa_data, data_len);
 			break;
+		case SETUP_KASLR:
+			parse_kaslr_setup(pa_data, data_len);
+			break;
 		default:
 			break;
 		}
@@ -833,10 +843,14 @@ static void __init trim_low_memory_range(void)
 static int
 dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
-	pr_emerg("Kernel Offset: 0x%lx from 0x%lx "
-		 "(relocation range: 0x%lx-0x%lx)\n",
-		 (unsigned long)&_text - __START_KERNEL, __START_KERNEL,
-		 __START_KERNEL_map, MODULES_VADDR-1);
+	if (kaslr_enabled)
+		pr_emerg("Kernel Offset: 0x%lx from 0x%lx (relocation range: 0x%lx-0x%lx)\n",
+			 (unsigned long)&_text - __START_KERNEL,
+			 __START_KERNEL,
+			 __START_KERNEL_map,
+			 MODULES_VADDR-1);
+	else
+		pr_emerg("Kernel Offset: disabled\n");
 
 	return 0;
 }

commit 37507717de51a8332a34ee07fd88700be88df5bf
Merge: a68fb48380bb a66734297f78
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 16 14:58:12 2015 -0800

    Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 perf updates from Ingo Molnar:
     "This series tightens up RDPMC permissions: currently even highly
      sandboxed x86 execution environments (such as seccomp) have permission
      to execute RDPMC, which may leak various perf events / PMU state such
      as timing information and other CPU execution details.
    
      This 'all is allowed' RDPMC mode is still preserved as the
      (non-default) /sys/devices/cpu/rdpmc=2 setting.  The new default is
      that RDPMC access is only allowed if a perf event is mmap-ed (which is
      needed to correctly interpret RDPMC counter values in any case).
    
      As a side effect of these changes CR4 handling is cleaned up in the
      x86 code and a shadow copy of the CR4 value is added.
    
      The extra CR4 manipulation adds ~ <50ns to the context switch cost
      between rdpmc-capable and rdpmc-non-capable mms"
    
    * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      perf/x86: Add /sys/devices/cpu/rdpmc=2 to allow rdpmc for all tasks
      perf/x86: Only allow rdpmc if a perf_event is mapped
      perf: Pass the event to arch_perf_update_userpage()
      perf: Add pmu callbacks to track event mapping and unmapping
      x86: Add a comment clarifying LDT context switching
      x86: Store a per-cpu shadow copy of CR4
      x86: Clean up cr4 manipulation

commit ef7f0d6a6ca8c9e4b27d78895af86c2fbfaeedb2
Author: Andrey Ryabinin <a.ryabinin@samsung.com>
Date:   Fri Feb 13 14:39:25 2015 -0800

    x86_64: add KASan support
    
    This patch adds arch specific code for kernel address sanitizer.
    
    16TB of virtual addressed used for shadow memory.  It's located in range
    [ffffec0000000000 - fffffc0000000000] between vmemmap and %esp fixup
    stacks.
    
    At early stage we map whole shadow region with zero page.  Latter, after
    pages mapped to direct mapping address range we unmap zero pages from
    corresponding shadow (see kasan_map_shadow()) and allocate and map a real
    shadow memory reusing vmemmap_populate() function.
    
    Also replace __pa with __pa_nodebug before shadow initialized.  __pa with
    CONFIG_DEBUG_VIRTUAL=y make external function call (__phys_addr)
    __phys_addr is instrumented, so __asan_load could be called before shadow
    area initialized.
    
    Signed-off-by: Andrey Ryabinin <a.ryabinin@samsung.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Konstantin Serebryany <kcc@google.com>
    Cc: Dmitry Chernenkov <dmitryc@google.com>
    Signed-off-by: Andrey Konovalov <adech.fo@gmail.com>
    Cc: Yuri Gribov <tetra2005@gmail.com>
    Cc: Konstantin Khlebnikov <koct9i@gmail.com>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Jim Davis <jim.epost@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c4648adadd7d..27d200929864 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -89,6 +89,7 @@
 #include <asm/cacheflush.h>
 #include <asm/processor.h>
 #include <asm/bugs.h>
+#include <asm/kasan.h>
 
 #include <asm/vsyscall.h>
 #include <asm/cpu.h>
@@ -1174,6 +1175,8 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.paging.pagetable_init();
 
+	kasan_init();
+
 	if (boot_cpu_data.cpuid_level >= 0) {
 		/* A CPU has %cr4 if and only if it has CPUID */
 		mmu_cr4_features = read_cr4();

commit 1e02ce4cccdcb9688386e5b8d2c9fa4660b45389
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Fri Oct 24 15:58:08 2014 -0700

    x86: Store a per-cpu shadow copy of CR4
    
    Context switches and TLB flushes can change individual bits of CR4.
    CR4 reads take several cycles, so store a shadow copy of CR4 in a
    per-cpu variable.
    
    To avoid wasting a cache line, I added the CR4 shadow to
    cpu_tlbstate, which is already touched in switch_mm.  The heaviest
    users of the cr4 shadow will be switch_mm and __switch_to_xtra, and
    __switch_to_xtra is called shortly after switch_mm during context
    switch, so the cacheline is likely to be hot.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Vince Weaver <vince@deater.net>
    Cc: "hillf.zj" <hillf.zj@alibaba-inc.com>
    Cc: Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/3a54dd3353fffbf84804398e00dfdc5b7c1afd7d.1414190806.git.luto@amacapital.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ab4734e5411d..04e6c62f1a93 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1178,7 +1178,7 @@ void __init setup_arch(char **cmdline_p)
 
 	if (boot_cpu_data.cpuid_level >= 0) {
 		/* A CPU has %cr4 if and only if it has CPUID */
-		mmu_cr4_features = read_cr4();
+		mmu_cr4_features = __read_cr4();
 		if (trampoline_cr4_features)
 			*trampoline_cr4_features = mmu_cr4_features;
 	}

commit 7389882c81474d635a208726edb22938645ff9ad
Author: WANG Chao <chaowang@redhat.com>
Date:   Wed Jan 7 18:55:48 2015 +0800

    x86, setup: Let early_memremap() handle page alignment
    
    early_memremap() takes care of page alignment and map size, so we can
    just remap the required data size and get rid of the adjustments in
    the setup code.
    
    [tglx: Massaged changelog ]
    
    Signed-off-by: WANG Chao <chaowang@redhat.com>
    Cc: Matt Fleming <matt.fleming@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Bryan O'Donoghue <pure.logic@nexus-software.ie>
    Link: http://lkml.kernel.org/r/1420628150-16872-1-git-send-email-chaowang@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ab4734e5411d..c4648adadd7d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -431,15 +431,13 @@ static void __init parse_setup_data(void)
 
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		u32 data_len, map_len, data_type;
+		u32 data_len, data_type;
 
-		map_len = max(PAGE_SIZE - (pa_data & ~PAGE_MASK),
-			      (u64)sizeof(struct setup_data));
-		data = early_memremap(pa_data, map_len);
+		data = early_memremap(pa_data, sizeof(*data));
 		data_len = data->len + sizeof(struct setup_data);
 		data_type = data->type;
 		pa_next = data->next;
-		early_iounmap(data, map_len);
+		early_iounmap(data, sizeof(*data));
 
 		switch (data_type) {
 		case SETUP_E820_EXT:

commit 3100e448e7d74489a96cb7b45d88fe6962774eaa
Merge: c9f861c77269 26893107aa71
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 10 14:24:20 2014 -0800

    Merge branch 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 vdso updates from Ingo Molnar:
     "Various vDSO updates from Andy Lutomirski, mostly cleanups and
      reorganization to improve maintainability, but also some
      micro-optimizations and robustization changes"
    
    * 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86_64/vsyscall: Restore orig_ax after vsyscall seccomp
      x86_64: Add a comment explaining the TASK_SIZE_MAX guard page
      x86_64,vsyscall: Make vsyscall emulation configurable
      x86_64, vsyscall: Rewrite comment and clean up headers in vsyscall code
      x86_64, vsyscall: Turn vsyscalls all the way off when vsyscall==none
      x86,vdso: Use LSL unconditionally for vgetcpu
      x86: vdso: Fix build with older gcc
      x86_64/vdso: Clean up vgetcpu init and merge the vdso initcalls
      x86_64/vdso: Remove jiffies from the vvar page
      x86/vdso: Make the PER_CPU segment 32 bits
      x86/vdso: Make the PER_CPU segment start out accessed
      x86/vdso: Change the PER_CPU segment to use struct desc_struct
      x86_64/vdso: Move getcpu code from vsyscall_64.c to vdso/vma.c
      x86_64/vsyscall: Move all of the gate_area code to vsyscall_64.c

commit fe3d197f84319d3bce379a9c0dc17b1f48ad358c
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Nov 14 07:18:29 2014 -0800

    x86, mpx: On-demand kernel allocation of bounds tables
    
    This is really the meat of the MPX patch set.  If there is one patch to
    review in the entire series, this is the one.  There is a new ABI here
    and this kernel code also interacts with userspace memory in a
    relatively unusual manner.  (small FAQ below).
    
    Long Description:
    
    This patch adds two prctl() commands to provide enable or disable the
    management of bounds tables in kernel, including on-demand kernel
    allocation (See the patch "on-demand kernel allocation of bounds tables")
    and cleanup (See the patch "cleanup unused bound tables"). Applications
    do not strictly need the kernel to manage bounds tables and we expect
    some applications to use MPX without taking advantage of this kernel
    support. This means the kernel can not simply infer whether an application
    needs bounds table management from the MPX registers.  The prctl() is an
    explicit signal from userspace.
    
    PR_MPX_ENABLE_MANAGEMENT is meant to be a signal from userspace to
    require kernel's help in managing bounds tables.
    
    PR_MPX_DISABLE_MANAGEMENT is the opposite, meaning that userspace don't
    want kernel's help any more. With PR_MPX_DISABLE_MANAGEMENT, the kernel
    won't allocate and free bounds tables even if the CPU supports MPX.
    
    PR_MPX_ENABLE_MANAGEMENT will fetch the base address of the bounds
    directory out of a userspace register (bndcfgu) and then cache it into
    a new field (->bd_addr) in  the 'mm_struct'.  PR_MPX_DISABLE_MANAGEMENT
    will set "bd_addr" to an invalid address.  Using this scheme, we can
    use "bd_addr" to determine whether the management of bounds tables in
    kernel is enabled.
    
    Also, the only way to access that bndcfgu register is via an xsaves,
    which can be expensive.  Caching "bd_addr" like this also helps reduce
    the cost of those xsaves when doing table cleanup at munmap() time.
    Unfortunately, we can not apply this optimization to #BR fault time
    because we need an xsave to get the value of BNDSTATUS.
    
    ==== Why does the hardware even have these Bounds Tables? ====
    
    MPX only has 4 hardware registers for storing bounds information.
    If MPX-enabled code needs more than these 4 registers, it needs to
    spill them somewhere. It has two special instructions for this
    which allow the bounds to be moved between the bounds registers
    and some new "bounds tables".
    
    They are similar conceptually to a page fault and will be raised by
    the MPX hardware during both bounds violations or when the tables
    are not present. This patch handles those #BR exceptions for
    not-present tables by carving the space out of the normal processes
    address space (essentially calling the new mmap() interface indroduced
    earlier in this patch set.) and then pointing the bounds-directory
    over to it.
    
    The tables *need* to be accessed and controlled by userspace because
    the instructions for moving bounds in and out of them are extremely
    frequent. They potentially happen every time a register pointing to
    memory is dereferenced. Any direct kernel involvement (like a syscall)
    to access the tables would obviously destroy performance.
    
    ==== Why not do this in userspace? ====
    
    This patch is obviously doing this allocation in the kernel.
    However, MPX does not strictly *require* anything in the kernel.
    It can theoretically be done completely from userspace. Here are
    a few ways this *could* be done. I don't think any of them are
    practical in the real-world, but here they are.
    
    Q: Can virtual space simply be reserved for the bounds tables so
       that we never have to allocate them?
    A: As noted earlier, these tables are *HUGE*. An X-GB virtual
       area needs 4*X GB of virtual space, plus 2GB for the bounds
       directory. If we were to preallocate them for the 128TB of
       user virtual address space, we would need to reserve 512TB+2GB,
       which is larger than the entire virtual address space today.
       This means they can not be reserved ahead of time. Also, a
       single process's pre-popualated bounds directory consumes 2GB
       of virtual *AND* physical memory. IOW, it's completely
       infeasible to prepopulate bounds directories.
    
    Q: Can we preallocate bounds table space at the same time memory
       is allocated which might contain pointers that might eventually
       need bounds tables?
    A: This would work if we could hook the site of each and every
       memory allocation syscall. This can be done for small,
       constrained applications. But, it isn't practical at a larger
       scale since a given app has no way of controlling how all the
       parts of the app might allocate memory (think libraries). The
       kernel is really the only place to intercept these calls.
    
    Q: Could a bounds fault be handed to userspace and the tables
       allocated there in a signal handler instead of in the kernel?
    A: (thanks to tglx) mmap() is not on the list of safe async
       handler functions and even if mmap() would work it still
       requires locking or nasty tricks to keep track of the
       allocation state there.
    
    Having ruled out all of the userspace-only approaches for managing
    bounds tables that we could think of, we create them on demand in
    the kernel.
    
    Based-on-patch-by: Qiaowei Ren <qiaowei.ren@intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: linux-mm@kvack.org
    Cc: linux-mips@linux-mips.org
    Cc: Dave Hansen <dave@sr71.net>
    Link: http://lkml.kernel.org/r/20141114151829.AD4310DE@viggo.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ab08aa2276fb..214245d6b996 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -960,6 +960,8 @@ void __init setup_arch(char **cmdline_p)
 	init_mm.end_data = (unsigned long) _edata;
 	init_mm.brk = _brk_end;
 
+	mpx_mm_init(&init_mm);
+
 	code_resource.start = __pa_symbol(_text);
 	code_resource.end = __pa_symbol(_etext)-1;
 	data_resource.start = __pa_symbol(_etext);

commit 1ad83c858c7d4ea210429142c99a1548e6715a35
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Wed Oct 29 14:33:47 2014 -0700

    x86_64,vsyscall: Make vsyscall emulation configurable
    
    This adds CONFIG_X86_VSYSCALL_EMULATION, guarded by CONFIG_EXPERT.
    Turning it off completely disables vsyscall emulation, saving ~3.5k
    for vsyscall_64.c, 4k for vsyscall_emu_64.S (the fake vsyscall
    page), some tiny amount of core mm code that supports a gate area,
    and possibly 4k for a wasted pagetable.  The latter is because the
    vsyscall addresses are misaligned and fit poorly in the fixmap.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Link: http://lkml.kernel.org/r/406db88b8dd5f0cbbf38216d11be34bbb43c7eae.1414618407.git.luto@amacapital.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 235cfd39e0d7..59a6f884fdad 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1190,9 +1190,7 @@ void __init setup_arch(char **cmdline_p)
 
 	tboot_probe();
 
-#ifdef CONFIG_X86_64
 	map_vsyscall();
-#endif
 
 	generic_apic_probe();
 

commit 3c325f8233c35fb35dec3744ba01634aab4ea36a
Author: Weijie Yang <weijie.yang@samsung.com>
Date:   Fri Oct 24 17:00:34 2014 +0800

    x86, cma: Reserve DMA contiguous area after initmem_init()
    
    Fengguang Wu reported a boot crash on the x86 platform
    via the 0-day Linux Kernel Performance Test:
    
      cma: dma_contiguous_reserve: reserving 31 MiB for global area
      BUG: Int 6: CR2   (null)
      [<41850786>] dump_stack+0x16/0x18
      [<41d2b1db>] early_idt_handler+0x6b/0x6b
      [<41072227>] ? __phys_addr+0x2e/0xca
      [<41d4ee4d>] cma_declare_contiguous+0x3c/0x2d7
      [<41d6d359>] dma_contiguous_reserve_area+0x27/0x47
      [<41d6d4d1>] dma_contiguous_reserve+0x158/0x163
      [<41d33e0f>] setup_arch+0x79b/0xc68
      [<41d2b7cf>] start_kernel+0x9c/0x456
      [<41d2b2ca>] i386_start_kernel+0x79/0x7d
    
    (See details at: https://lkml.org/lkml/2014/10/8/708)
    
    It is because dma_contiguous_reserve() is called before
    initmem_init() in x86, the variable high_memory is not
    initialized but accessed by __pa(high_memory) in
    dma_contiguous_reserve().
    
    This patch moves dma_contiguous_reserve() after initmem_init()
    so that high_memory is initialized before accessed.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Weijie Yang <weijie.yang@samsung.com>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Michal Nazarewicz <mina86@mina86.com>
    Cc: iamjoonsoo.kim@lge.com
    Cc: 'Linux-MM' <linux-mm@kvack.org>
    Cc: 'Weijie Yang' <weijie.yang.kh@gmail.com>
    Link: http://lkml.kernel.org/r/000101cfef69%2431e528a0%2495af79e0%24%25yang@samsung.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 235cfd39e0d7..ab08aa2276fb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1128,7 +1128,6 @@ void __init setup_arch(char **cmdline_p)
 	setup_real_mode();
 
 	memblock_set_current_limit(get_max_mapped());
-	dma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);
 
 	/*
 	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.
@@ -1159,6 +1158,7 @@ void __init setup_arch(char **cmdline_p)
 	early_acpi_boot_init();
 
 	initmem_init();
+	dma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);
 
 	/*
 	 * Reserve memory for crash kernel after SRAT is parsed so that it

commit 2075244f9b871f18a007935c73d2ab49d4fb43e0
Author: Bryan O'Donoghue <pure.logic@nexus-software.ie>
Date:   Tue Oct 7 01:19:48 2014 +0100

    x86: Quark: Comment setup_arch() to document TLB/PGE bug
    
    Quark SoC X1000 advertises Page Global Enable for it's
    Translation Lookaside Buffer via cpuid. The silicon does not
    in fact support PGE and hence will not flush the TLB when CR4.PGE
    is rewritten. The Quark documentation makes clear the necessity to
    instead rewrite CR3 in order to flush any TLB entries, irrespective
    of the state of CR4.PGE or an individual PTE.PGE
    
    See Intel Quark Core DevMan_001.pdf section 6.4.11
    
    In setup.c setup_arch() the code will load_cr3() and then do a
    __flush_tlb_all().
    
    On Quark the entire TLB will be flushed at the load_cr3().
    The __flush_tlb_all() have no effect and can be safely ignored.
    
    Later on in the boot process we switch off the flag for cpu_has_pge()
    which means that subsequent calls to __flush_tlb_all() will
    call __flush_tlb() not __flush_tlb_global() flushing the TLB in the
    correct way via load_cr3() not CR4.PGE rewrite
    
    This patch documents the behaviour of flushing the TLB for Quark in
    setup_arch()
    
    Comment text suggested by Thomas Gleixner
    
    Signed-off-by: Bryan O'Donoghue <pure.logic@nexus-software.ie>
    Cc: davej@redhat.com
    Cc: hmh@hmh.eng.br
    Link: http://lkml.kernel.org/r/1412641189-12415-2-git-send-email-pure.logic@nexus-software.ie
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 41ead8d3bc0b..235cfd39e0d7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -879,6 +879,15 @@ void __init setup_arch(char **cmdline_p)
 			KERNEL_PGD_PTRS);
 
 	load_cr3(swapper_pg_dir);
+	/*
+	 * Note: Quark X1000 CPUs advertise PGE incorrectly and require
+	 * a cr3 based tlb flush, so the following __flush_tlb_all()
+	 * will not flush anything because the cpu quirk which clears
+	 * X86_FEATURE_PGE has not been invoked yet. Though due to the
+	 * load_cr3() above the TLB has been flushed already. The
+	 * quirk is invoked before subsequent calls to __flush_tlb_all()
+	 * so proper operation is guaranteed.
+	 */
 	__flush_tlb_all();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);

commit 9402973d49d9a4bc463bba4f609bf8d8247f79e2
Author: Daniel Kiper <daniel.kiper@oracle.com>
Date:   Mon Jun 30 19:53:03 2014 +0200

    arch/x86: Replace plain strings with constants
    
    We've got constants, so let's use them instead of hard-coded values.
    
    Signed-off-by: Daniel Kiper <daniel.kiper@oracle.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 78a0e6298922..41ead8d3bc0b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -924,10 +924,10 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
-		     "EL32", 4)) {
+		     EFI32_LOADER_SIGNATURE, 4)) {
 		set_bit(EFI_BOOT, &efi.flags);
 	} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
-		     "EL64", 4)) {
+		     EFI64_LOADER_SIGNATURE, 4)) {
 		set_bit(EFI_BOOT, &efi.flags);
 		set_bit(EFI_64BIT, &efi.flags);
 	}

commit 5ea3b1b2f8ad9162684431ce6188102ca4c64b7a
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Jun 4 16:06:54 2014 -0700

    cma: add placement specifier for "cma=" kernel parameter
    
    Currently, "cma=" kernel parameter is used to specify the size of CMA,
    but we can't specify where it is located.  We want to locate CMA below
    4GB for devices only supporting 32-bit addressing on 64-bit systems
    without iommu.
    
    This enables to specify the placement of CMA by extending "cma=" kernel
    parameter.
    
    Examples:
     1. locate 64MB CMA below 4GB by "cma=64M@0-4G"
     2. locate 64MB CMA exact at 512MB by "cma=64M@512M"
    
    Note that the DMA contiguous memory allocator on x86 assumes that
    page_address() works for the pages to allocate.  So this change requires
    to limit end address of contiguous memory area upto max_pfn_mapped to
    prevent from locating it on highmem area by the argument of
    dma_contiguous_reserve().
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Don Dutile <ddutile@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 09c76d265550..78a0e6298922 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1119,7 +1119,7 @@ void __init setup_arch(char **cmdline_p)
 	setup_real_mode();
 
 	memblock_set_current_limit(get_max_mapped());
-	dma_contiguous_reserve(0);
+	dma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);
 
 	/*
 	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.

commit 467cbd207abdbfe29514b5804a22661ab6e80dc6
Merge: 7125764c5d1a b5660ba76b41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 2 13:15:58 2014 -0700

    Merge branch 'x86-nuke-platforms-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 old platform removal from Peter Anvin:
     "This patchset removes support for several completely obsolete
      platforms, where the maintainers either have completely vanished or
      acked the removal.  For some of them it is questionable if there even
      exists functional specimens of the hardware"
    
    Geert Uytterhoeven apparently thought this was a April Fool's pull request ;)
    
    * 'x86-nuke-platforms-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, platforms: Remove NUMAQ
      x86, platforms: Remove SGI Visual Workstation
      x86, apic: Remove support for IBM Summit/EXA chipset
      x86, apic: Remove support for ia32-based Unisys ES7000

commit 4fd69331ad227a4d8de26592d017b73e00caca9f
Merge: 69e608411473 0ac09f9f8cd1
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Wed Mar 5 17:22:57 2014 +0000

    Merge remote-tracking branch 'tip/x86/urgent' into efi-for-mingo
    
    Conflicts:
            arch/x86/include/asm/efi.h

commit a5d90c923bcfb9632d998ed06e9569216ad695f3
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Mar 4 17:02:17 2014 +0100

    x86/efi: Quirk out SGI UV
    
    Alex reported hitting the following BUG after the EFI 1:1 virtual
    mapping work was merged,
    
     kernel BUG at arch/x86/mm/init_64.c:351!
     invalid opcode: 0000 [#1] SMP
     Call Trace:
      [<ffffffff818aa71d>] init_extra_mapping_uc+0x13/0x15
      [<ffffffff818a5e20>] uv_system_init+0x22b/0x124b
      [<ffffffff8108b886>] ? clockevents_register_device+0x138/0x13d
      [<ffffffff81028dbb>] ? setup_APIC_timer+0xc5/0xc7
      [<ffffffff8108b620>] ? clockevent_delta2ns+0xb/0xd
      [<ffffffff818a3a92>] ? setup_boot_APIC_clock+0x4a8/0x4b7
      [<ffffffff8153d955>] ? printk+0x72/0x74
      [<ffffffff818a1757>] native_smp_prepare_cpus+0x389/0x3d6
      [<ffffffff818957bc>] kernel_init_freeable+0xb7/0x1fb
      [<ffffffff81535530>] ? rest_init+0x74/0x74
      [<ffffffff81535539>] kernel_init+0x9/0xff
      [<ffffffff81541dfc>] ret_from_fork+0x7c/0xb0
      [<ffffffff81535530>] ? rest_init+0x74/0x74
    
    Getting this thing to work with the new mapping scheme would need more
    work, so automatically switch to the old memmap layout for SGI UV.
    
    Acked-by: Russ Anderson <rja@sgi.com>
    Cc: Alex Thorlton <athorlton@sgi.com
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 06853e670354..ce72964b2f46 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1239,14 +1239,8 @@ void __init setup_arch(char **cmdline_p)
 	register_refined_jiffies(CLOCK_TICK_RATE);
 
 #ifdef CONFIG_EFI
-	/* Once setup is done above, unmap the EFI memory map on
-	 * mismatched firmware/kernel archtectures since there is no
-	 * support for runtime services.
-	 */
-	if (efi_enabled(EFI_BOOT) && !efi_is_native()) {
-		pr_info("efi: Setup done, disabling due to 32/64-bit mismatch\n");
-		efi_unmap_memmap();
-	}
+	if (efi_enabled(EFI_BOOT))
+		efi_apply_memmap_quirks();
 #endif
 }
 

commit 3e909599215456928e6b42a04f11c2517881570b
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Wed Jan 15 13:21:22 2014 +0000

    efi: Move facility flags to struct efi
    
    As we grow support for more EFI architectures they're going to want the
    ability to query which EFI features are available on the running system.
    Instead of storing this information in an architecture-specific place,
    stick it in the global 'struct efi', which is already the central
    location for EFI state.
    
    While we're at it, let's change the return value of efi_enabled() to be
    bool and replace all references to 'facility' with 'feature', which is
    the usual word used to describe the attributes of the running system.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 06853e670354..3b5d278b7d5b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -926,11 +926,11 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     "EL32", 4)) {
-		set_bit(EFI_BOOT, &x86_efi_facility);
+		set_bit(EFI_BOOT, &efi.flags);
 	} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     "EL64", 4)) {
-		set_bit(EFI_BOOT, &x86_efi_facility);
-		set_bit(EFI_64BIT, &x86_efi_facility);
+		set_bit(EFI_BOOT, &efi.flags);
+		set_bit(EFI_64BIT, &efi.flags);
 	}
 
 	if (efi_enabled(EFI_BOOT))

commit c5f9ee3d665a7660b296aa1e91949ae3376f0d07
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Tue Feb 25 12:05:34 2014 -0800

    x86, platforms: Remove SGI Visual Workstation
    
    The SGI Visual Workstation seems to be dead; remove support so we
    don't have to continue maintaining it.
    
    Cc: Andrey Panin <pazke@donpac.ru>
    Cc: Michael Reed <mdr@sgi.com>
    Link: http://lkml.kernel.org/r/530CFD6C.7040705@zytor.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 06853e670354..12907ab8f33e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -869,7 +869,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
-	visws_early_detect();
 
 	/*
 	 * copy kernel address range established so far and switch

commit 4ce7a8697cb795fda6bdf082c14743b4bcd551c3
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Jan 27 17:06:50 2014 -0800

    x86: revert wrong memblock current limit setting
    
    Dave reported big numa system booting is broken.
    
    It turns out that commit 5b6e529521d3 ("x86: memblock: set current limit
    to max low memory address") sets the limit to low wrongly.
    
    max_low_pfn_mapped is different from max_pfn_mapped.
    max_low_pfn_mapped is always under 4G.
    
    That will memblock_alloc_nid all go under 4G.
    
    Revert 5b6e529521d3 to fix a no-boot regression which was triggered by
    457ff1de2d24 ("lib/swiotlb.c: use memblock apis for early memory
    allocations").
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Reported-by: Dave Hansen <dave.hansen@intel.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c9675594d7ca..06853e670354 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1119,7 +1119,7 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_real_mode();
 
-	memblock_set_current_limit(get_max_low_mapped());
+	memblock_set_current_limit(get_max_mapped());
 	dma_contiguous_reserve(0);
 
 	/*

commit 5b6e529521d35e1bcaa0fe43456d1bbb335cae5d
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Tue Jan 21 15:50:03 2014 -0800

    x86: memblock: set current limit to max low memory address
    
    The memblock current limit value is used to limit early boot memory
    allocations below max low memory address by default, as the kernel can
    access only to the low memory.
    
    Hence, set memblock current limit value to the max mapped low memory
    address instead of max mapped memory address.
    
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Paul Walmsley <paul@pwsan.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 06853e670354..c9675594d7ca 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1119,7 +1119,7 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_real_mode();
 
-	memblock_set_current_limit(get_max_mapped());
+	memblock_set_current_limit(get_max_low_mapped());
 	dma_contiguous_reserve(0);
 
 	/*

commit f4bcd8ccddb02833340652e9f46f5127828eb79d
Merge: 7fe67a1180db da2b6fb990cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 20 14:45:50 2014 -0800

    Merge branch 'x86-kaslr-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 kernel address space randomization support from Peter Anvin:
     "This enables kernel address space randomization for x86"
    
    * 'x86-kaslr-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, kaslr: Clarify RANDOMIZE_BASE_MAX_OFFSET
      x86, kaslr: Remove unused including <linux/version.h>
      x86, kaslr: Use char array to gain sizeof sanity
      x86, kaslr: Add a circular multiply for better bit diffusion
      x86, kaslr: Mix entropy sources together as needed
      x86/relocs: Add percpu fixup for GNU ld 2.23
      x86, boot: Rename get_flags() and check_flags() to *_cpuflags()
      x86, kaslr: Raise the maximum virtual address to -1 GiB on x86_64
      x86, kaslr: Report kernel offset on panic
      x86, kaslr: Select random position from e820 maps
      x86, kaslr: Provide randomness functions
      x86, kaslr: Return location from decompress_kernel
      x86, boot: Move CPU flags out of cpucheck
      x86, relocs: Add more per-cpu gold special cases

commit 2bb2c5e235e8459de5761f89bc2bcb2efd2b6b45
Merge: 4500cf60dbe4 9c079129d7bf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 20 12:07:54 2014 -0800

    Merge branch 'x86-microcode-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 microcode loader updates from Ingo Molnar:
     "There are two main changes in this tree:
    
       - AMD microcode early loading fixes
       - some microcode loader source files reorganization"
    
    * 'x86-microcode-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, microcode: Move to a proper location
      x86, microcode, AMD: Fix early ucode loading
      x86, microcode: Share native MSR accessing variants
      x86, ramdisk: Export relocated ramdisk VA

commit 5aa3d718f259007121b9366d36315fb8a2983d3d
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Dec 4 20:50:42 2013 +0100

    x86, ramdisk: Export relocated ramdisk VA
    
    The ramdisk can possibly get relocated if the whole image is not mapped.
    And since we're going over it in the microcode loader and fishing out
    the relevant microcode patches, we want access it at its new location.
    Thus, export it.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Tested-by: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cb233bc9dee3..baefc6dc553c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -295,6 +295,8 @@ static void __init reserve_brk(void)
 	_brk_start = 0;
 }
 
+u64 relocated_ramdisk;
+
 #ifdef CONFIG_BLK_DEV_INITRD
 
 static u64 __init get_ramdisk_image(void)
@@ -321,25 +323,24 @@ static void __init relocate_initrd(void)
 	u64 ramdisk_image = get_ramdisk_image();
 	u64 ramdisk_size  = get_ramdisk_size();
 	u64 area_size     = PAGE_ALIGN(ramdisk_size);
-	u64 ramdisk_here;
 	unsigned long slop, clen, mapaddr;
 	char *p, *q;
 
 	/* We need to move the initrd down into directly mapped mem */
-	ramdisk_here = memblock_find_in_range(0, PFN_PHYS(max_pfn_mapped),
-						 area_size, PAGE_SIZE);
+	relocated_ramdisk = memblock_find_in_range(0, PFN_PHYS(max_pfn_mapped),
+						   area_size, PAGE_SIZE);
 
-	if (!ramdisk_here)
+	if (!relocated_ramdisk)
 		panic("Cannot find place for new RAMDISK of size %lld\n",
-			 ramdisk_size);
+		      ramdisk_size);
 
 	/* Note: this includes all the mem currently occupied by
 	   the initrd, we rely on that fact to keep the data intact. */
-	memblock_reserve(ramdisk_here, area_size);
-	initrd_start = ramdisk_here + PAGE_OFFSET;
+	memblock_reserve(relocated_ramdisk, area_size);
+	initrd_start = relocated_ramdisk + PAGE_OFFSET;
 	initrd_end   = initrd_start + ramdisk_size;
 	printk(KERN_INFO "Allocated new RAMDISK: [mem %#010llx-%#010llx]\n",
-			 ramdisk_here, ramdisk_here + ramdisk_size - 1);
+	       relocated_ramdisk, relocated_ramdisk + ramdisk_size - 1);
 
 	q = (char *)initrd_start;
 
@@ -363,7 +364,7 @@ static void __init relocate_initrd(void)
 	printk(KERN_INFO "Move RAMDISK from [mem %#010llx-%#010llx] to"
 		" [mem %#010llx-%#010llx]\n",
 		ramdisk_image, ramdisk_image + ramdisk_size - 1,
-		ramdisk_here, ramdisk_here + ramdisk_size - 1);
+		relocated_ramdisk, relocated_ramdisk + ramdisk_size - 1);
 }
 
 static void __init early_reserve_initrd(void)

commit 77ea8c948953a90401e436e7c05973b2d5529804
Author: Dave Young <dyoung@redhat.com>
Date:   Fri Dec 20 18:02:22 2013 +0800

    x86: Reserve setup_data ranges late after parsing memmap cmdline
    
    Currently e820_reserve_setup_data() is called before parsing early
    params, it works in normal case. But for memmap=exactmap, the final
    memory ranges are created after parsing memmap= cmdline params, so the
    previous e820_reserve_setup_data() has no effect. For example,
    setup_data ranges will still be marked as normal system ram, thus when
    later sysfs driver ioremap them kernel will warn about mapping normal
    ram.
    
    This patch fix it by moving the e820_reserve_setup_data() callback after
    parsing early params so they can be set as reserved ranges and later
    ioremap will be fine with it.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 24536f7a0ae6..be4b456e444b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -927,8 +927,6 @@ void __init setup_arch(char **cmdline_p)
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();
-	/* update the e820_saved too */
-	e820_reserve_setup_data();
 
 	copy_edd();
 
@@ -990,6 +988,8 @@ void __init setup_arch(char **cmdline_p)
 		early_dump_pci_devices();
 #endif
 
+	/* update the e820_saved too */
+	e820_reserve_setup_data();
 	finish_e820_parsing();
 
 	if (efi_enabled(EFI_BOOT))

commit 1fec0533693cd74f2d1a46edd29449cfee429df0
Author: Dave Young <dyoung@redhat.com>
Date:   Fri Dec 20 18:02:19 2013 +0800

    x86/efi: Pass necessary EFI data for kexec via setup_data
    
    Add a new setup_data type SETUP_EFI for kexec use.  Passing the saved
    fw_vendor, runtime, config tables and EFI runtime mappings.
    
    When entering virtual mode, directly mapping the EFI runtime regions
    which we passed in previously. And skip the step to call
    SetVirtualAddressMap().
    
    Specially for HP z420 workstation we need save the smbios physical
    address.  The kernel boot sequence proceeds in the following order.
    Step 2 requires efi.smbios to be the physical address.  However, I found
    that on HP z420 EFI system table has a virtual address of SMBIOS in step
    1.  Hence, we need set it back to the physical address with the smbios
    in efi_setup_data.  (When it is still the physical address, it simply
    sets the same value.)
    
    1. efi_init() - Set efi.smbios from EFI system table
    2. dmi_scan_machine() - Temporary map efi.smbios to access SMBIOS table
    3. efi_enter_virtual_mode() - Map EFI ranges
    
    Tested on ovmf+qemu, lenovo thinkpad, a dell laptop and an
    HP z420 workstation.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cb233bc9dee3..24536f7a0ae6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -447,6 +447,9 @@ static void __init parse_setup_data(void)
 		case SETUP_DTB:
 			add_dtb(pa_data);
 			break;
+		case SETUP_EFI:
+			parse_efi_setup(pa_data, data_len);
+			break;
 		default:
 			break;
 		}

commit fa591c4ae76ecbd4d26d7e8f65429d6d454554a6
Author: Tang Chen <tangchen@cn.fujitsu.com>
Date:   Tue Nov 12 15:08:07 2013 -0800

    x86, acpi, crash, kdump: do reserve_crashkernel() after SRAT is parsed.
    
    Memory reserved for crashkernel could be large.  So we should not allocate
    this memory bottom up from the end of kernel image.
    
    When SRAT is parsed, we will be able to know which memory is hotpluggable,
    and we can avoid allocating this memory for the kernel.  So reorder
    reserve_crashkernel() after SRAT is parsed.
    
    Signed-off-by: Tang Chen <tangchen@cn.fujitsu.com>
    Signed-off-by: Zhang Yanfei <zhangyanfei@cn.fujitsu.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: Toshi Kani <toshi.kani@hp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Thomas Renninger <trenn@suse.de>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Taku Izumi <izumi.taku@jp.fujitsu.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michal Nazarewicz <mina86@mina86.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 918d489fa53d..cb233bc9dee3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1121,8 +1121,6 @@ void __init setup_arch(char **cmdline_p)
 	acpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);
 #endif
 
-	reserve_crashkernel();
-
 	vsmp_init();
 
 	io_delay_init();
@@ -1135,6 +1133,13 @@ void __init setup_arch(char **cmdline_p)
 	early_acpi_boot_init();
 
 	initmem_init();
+
+	/*
+	 * Reserve memory for crash kernel after SRAT is parsed so that it
+	 * won't consume hotpluggable memory.
+	 */
+	reserve_crashkernel();
+
 	memblock_find_dma_reserve();
 
 #ifdef CONFIG_KVM_GUEST

commit dd6dad4288cb93e79bd7abfa6c6a338c47454d1a
Author: Chen, Gong <gong.chen@linux.intel.com>
Date:   Fri Oct 18 14:29:25 2013 -0700

    DMI: Parse memory device (type 17) in SMBIOS
    
    This patch adds a new interface to decode memory device (type 17)
    to help error reporting on DIMMs.
    
    Original-author: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Chen, Gong <gong.chen@linux.intel.com>
    Acked-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Mauro Carvalho Chehab <m.chehab@samsung.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f0de6294b955..918d489fa53d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -993,6 +993,7 @@ void __init setup_arch(char **cmdline_p)
 		efi_init();
 
 	dmi_scan_machine();
+	dmi_memdev_walk();
 	dmi_set_dump_stack_arch_desc();
 
 	/*

commit f32360ef6608434a032dc7ad262d45e9693c27f3
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Oct 10 17:18:17 2013 -0700

    x86, kaslr: Report kernel offset on panic
    
    When the system panics, include the kernel offset in the report to assist
    in debugging.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Link: http://lkml.kernel.org/r/1381450698-28710-6-git-send-email-keescook@chromium.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f0de6294b955..1708862fc40d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -823,6 +823,20 @@ static void __init trim_low_memory_range(void)
 	memblock_reserve(0, ALIGN(reserve_low, PAGE_SIZE));
 }
 	
+/*
+ * Dump out kernel offset information on panic.
+ */
+static int
+dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
+{
+	pr_emerg("Kernel Offset: 0x%lx from 0x%lx "
+		 "(relocation range: 0x%lx-0x%lx)\n",
+		 (unsigned long)&_text - __START_KERNEL, __START_KERNEL,
+		 __START_KERNEL_map, MODULES_VADDR-1);
+
+	return 0;
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -1242,3 +1256,15 @@ void __init i386_reserve_resources(void)
 }
 
 #endif /* CONFIG_X86_32 */
+
+static struct notifier_block kernel_offset_notifier = {
+	.notifier_call = dump_kernel_offset
+};
+
+static int __init register_kernel_offset_dumper(void)
+{
+	atomic_notifier_chain_register(&panic_notifier_list,
+					&kernel_offset_notifier);
+	return 0;
+}
+__initcall(register_kernel_offset_dumper);

commit cb3e4330e697dffaf3d9cefebc9c7e7d39c89f2e
Merge: aafcd5d75797 30e46b574a1d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 4 09:39:26 2013 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm changes from Ingo Molnar:
     "Misc smaller fixes:
    
       - a parse_setup_data() boot crash fix
    
       - a memblock and an __early_ioremap cleanup
    
       - turn the always-on CONFIG_ARCH_MEMORY_PROBE=y into a configurable
         option and turn it off - it's an unrobust debug facility, it
         shouldn't be enabled by default"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: avoid remapping data in parse_setup_data()
      x86: Use memblock_set_current_limit() to set limit for memblock.
      mm: Remove unused variable idx0 in __early_ioremap()
      mm/hotplug, x86: Disable ARCH_MEMORY_PROBE by default

commit 30e46b574a1db7d14404e52dca8e1aa5f5155fd2
Author: Linn Crosetto <linn@hp.com>
Date:   Tue Aug 13 15:46:41 2013 -0600

    x86: avoid remapping data in parse_setup_data()
    
    Type SETUP_PCI, added by setup_efi_pci(), may advertise a ROM size
    larger than early_memremap() is able to handle, which is currently
    limited to 256kB. If this occurs it leads to a NULL dereference in
    parse_setup_data().
    
    To avoid this, remap the setup_data header and allow parsing functions
    for individual types to handle their own data remapping.
    
    Signed-off-by: Linn Crosetto <linn@hp.com>
    Link: http://lkml.kernel.org/r/1376430401-67445-1-git-send-email-linn@hp.com
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index de337983f679..b6b45e4d6d3e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -426,25 +426,23 @@ static void __init reserve_initrd(void)
 static void __init parse_setup_data(void)
 {
 	struct setup_data *data;
-	u64 pa_data;
+	u64 pa_data, pa_next;
 
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		u32 data_len, map_len;
+		u32 data_len, map_len, data_type;
 
 		map_len = max(PAGE_SIZE - (pa_data & ~PAGE_MASK),
 			      (u64)sizeof(struct setup_data));
 		data = early_memremap(pa_data, map_len);
 		data_len = data->len + sizeof(struct setup_data);
-		if (data_len > map_len) {
-			early_iounmap(data, map_len);
-			data = early_memremap(pa_data, data_len);
-			map_len = data_len;
-		}
+		data_type = data->type;
+		pa_next = data->next;
+		early_iounmap(data, map_len);
 
-		switch (data->type) {
+		switch (data_type) {
 		case SETUP_E820_EXT:
-			parse_e820_ext(data);
+			parse_e820_ext(pa_data, data_len);
 			break;
 		case SETUP_DTB:
 			add_dtb(pa_data);
@@ -452,8 +450,7 @@ static void __init parse_setup_data(void)
 		default:
 			break;
 		}
-		pa_data = data->next;
-		early_iounmap(data, map_len);
+		pa_data = pa_next;
 	}
 }
 

commit 2449f343e4adc778de1c3d45b5aa14fe788663f5
Author: Tang Chen <tangchen@cn.fujitsu.com>
Date:   Wed Aug 14 11:44:04 2013 +0800

    x86: Use memblock_set_current_limit() to set limit for memblock.
    
    In setup_arch() of x86, it set memblock.current_limit directly.
    We should use memblock_set_current_limit(). If the implementation
    is changed, it is easy to maintain.
    
    Signed-off-by: Tang Chen <tangchen@cn.fujitsu.com>
    Link: http://lkml.kernel.org/r/1376451844-15682-1-git-send-email-tangchen@cn.fujitsu.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f8ec57815c05..de337983f679 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1070,7 +1070,7 @@ void __init setup_arch(char **cmdline_p)
 
 	cleanup_highmap();
 
-	memblock.current_limit = ISA_END_ADDRESS;
+	memblock_set_current_limit(ISA_END_ADDRESS);
 	memblock_x86_fill();
 
 	/*
@@ -1103,7 +1103,7 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_real_mode();
 
-	memblock.current_limit = get_max_mapped();
+	memblock_set_current_limit(get_max_mapped());
 	dma_contiguous_reserve(0);
 
 	/*

commit 277d5b40b7bf495d2d4193746181b17dd98441b2
Author: Andi Kleen <ak@linux.intel.com>
Date:   Mon Aug 5 15:02:43 2013 -0700

    x86, asmlinkage: Make several variables used from assembler/linker script visible
    
    Plus one function, load_gs_index().
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1375740170-7446-10-git-send-email-andi@firstfloor.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f8ec57815c05..dfa55afccf5e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -206,9 +206,9 @@ EXPORT_SYMBOL(boot_cpu_data);
 
 
 #if !defined(CONFIG_X86_PAE) || defined(CONFIG_X86_64)
-unsigned long mmu_cr4_features;
+__visible unsigned long mmu_cr4_features;
 #else
-unsigned long mmu_cr4_features = X86_CR4_PAE;
+__visible unsigned long mmu_cr4_features = X86_CR4_PAE;
 #endif
 
 /* Boot loader ID and version as integers, for the benefit of proc_dointvec */

commit 148f9bb87745ed45f7a11b2cbd3bc0f017d5d257
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Jun 18 18:23:59 2013 -0400

    x86: delete __cpuinit usage from all x86 files
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    are flagged as __cpuinit  -- so if we remove the __cpuinit from
    arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    content into no-ops as early as possible, since that will get rid
    of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the arch/x86 uses of the __cpuinit macros from
    all C files.  x86 only had the one __CPUINIT used in assembly files,
    and it wasn't paired off with a .previous or a __FINIT, so we can
    delete it directly w/o any corresponding additional change there.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e68709da8251..f8ec57815c05 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -170,7 +170,7 @@ static struct resource bss_resource = {
 
 #ifdef CONFIG_X86_32
 /* cpu data as detected by the assembly code in head.S */
-struct cpuinfo_x86 new_cpu_data __cpuinitdata = {
+struct cpuinfo_x86 new_cpu_data = {
 	.wp_works_ok = -1,
 };
 /* common cpu data for all cpus */

commit 46a841329a6cd6298e131afd82e7d58130b19025
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:04:19 2013 -0700

    mm/x86: prepare for removing num_physpages and simplify mem_init()
    
    Prepare for removing num_physpages and simplify mem_init().
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andreas Herrmann <andreas.herrmann3@amd.com>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 56f7fcfe7fa2..e68709da8251 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1040,8 +1040,6 @@ void __init setup_arch(char **cmdline_p)
 	/* max_low_pfn get updated here */
 	find_low_pfn_range();
 #else
-	num_physpages = max_pfn;
-
 	check_x2apic();
 
 	/* How many end-of-memory variables you have, grandma! */

commit 98e5e1bf722c4f976a860aed06dd365a56a34ee0
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Apr 30 15:27:15 2013 -0700

    dump_stack: implement arch-specific hardware description in task dumps
    
    x86 and ia64 can acquire extra hardware identification information
    from DMI and print it along with task dumps; however, the usage isn't
    consistent.
    
    * x86 show_regs() collects vendor, product and board strings and print
      them out with PID, comm and utsname.  Some of the information is
      printed again later in the same dump.
    
    * warn_slowpath_common() explicitly accesses the DMI board and prints
      it out with "Hardware name:" label.  This applies to both x86 and
      ia64 but is irrelevant on all other archs.
    
    * ia64 doesn't show DMI information on other non-WARN dumps.
    
    This patch introduces arch-specific hardware description used by
    dump_stack().  It can be set by calling dump_stack_set_arch_desc()
    during boot and, if exists, printed out in a separate line with
    "Hardware name:" label.
    
    dmi_set_dump_stack_arch_desc() is added which sets arch-specific
    description from DMI data.  It uses dmi_ids_string[] which is set from
    dmi_present() used for DMI debug message.  It is superset of the
    information x86 show_regs() is using.  The function is called from x86
    and ia64 boot code right after dmi_scan_machine().
    
    This makes the explicit DMI handling in warn_slowpath_common()
    unnecessary.  Removed.
    
    show_regs() isn't yet converted to use generic debug information
    printing and this patch doesn't remove the duplicate DMI handling in
    x86 show_regs().  The next patch will unify show_regs() handling and
    remove the duplication.
    
    An example WARN dump follows.
    
     WARNING: at kernel/workqueue.c:4841 init_workqueues+0x35/0x505()
     Modules linked in:
     CPU: 0 PID: 1 Comm: swapper/0 Not tainted 3.9.0-rc1-work+ #3
     Hardware name: empty empty/S3992, BIOS 080011  10/26/2007
      0000000000000009 ffff88007c861e08 ffffffff81c614dc ffff88007c861e48
      ffffffff8108f500 ffffffff82228240 0000000000000040 ffffffff8234a08e
      0000000000000000 0000000000000000 0000000000000000 ffff88007c861e58
     Call Trace:
      [<ffffffff81c614dc>] dump_stack+0x19/0x1b
      [<ffffffff8108f500>] warn_slowpath_common+0x70/0xa0
      [<ffffffff8108f54a>] warn_slowpath_null+0x1a/0x20
      [<ffffffff8234a0c3>] init_workqueues+0x35/0x505
      ...
    
    v2: Use the same string as the debug message from dmi_present() which
        also contains BIOS information.  Move hardware name into its own
        line as warn_slowpath_common() did.  This change was suggested by
        Bjorn Helgaas.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4689855c2f8a..56f7fcfe7fa2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -996,6 +996,7 @@ void __init setup_arch(char **cmdline_p)
 		efi_init();
 
 	dmi_scan_machine();
+	dmi_set_dump_stack_arch_desc();
 
 	/*
 	 * VMware detection requires dmi to be available, so this

commit 74c7d2f5200a340ae6655e9adcf990381e387937
Merge: 1e2f5b598aa5 06d219dc22da
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 30 08:42:11 2013 -0700

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 platform changes from Ingo Molnar:
     "Small fixes and cleanups all over the map"
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/setup: Drop unneeded include <asm/dmi.h>
      x86/olpc/xo1/sci: Don't call input_free_device() after input_unregister_device()
      x86/platform/intel/mrst: Remove cast for kmalloc() return value
      x86/platform/uv: Replace kmalloc() & memset with kzalloc()

commit df8edfa9af5b2160549ed1a79b72e3ed13b6c7e2
Merge: 874f6d1be769 1077c932db63
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 30 08:34:38 2013 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cpuid changes from Ingo Molnar:
     "The biggest change is x86 CPU bug handling refactoring and cleanups,
      by Borislav Petkov"
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, CPU, AMD: Drop useless label
      x86, AMD: Correct {rd,wr}msr_amd_safe warnings
      x86: Fold-in trivial check_config function
      x86, cpu: Convert AMD Erratum 400
      x86, cpu: Convert AMD Erratum 383
      x86, cpu: Convert Cyrix coma bug detection
      x86, cpu: Convert FDIV bug detection
      x86, cpu: Convert F00F bug detection
      x86, cpu: Expand cpufeature facility to include cpu bugs

commit 06d219dc22daa26b79ec8e611caa68801607f15d
Author: Jean Delvare <jdelvare@suse.de>
Date:   Thu Apr 25 11:24:05 2013 +0200

    x86/setup: Drop unneeded include <asm/dmi.h>
    
    arch/x86/kernel/setup.c includes <asm/dmi.h> but it doesn't look
    like it needs it, <linux/dmi.h> is sufficient.
    
    Signed-off-by: Jean Delvare <jdelvare@suse.de>
    Link: http://lkml.kernel.org/r/1366881845.4186.65.camel@chaos.site
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 90d8cc930f5e..a60b245951e1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -82,7 +82,6 @@
 #include <asm/timer.h>
 #include <asm/i8259.h>
 #include <asm/sections.h>
-#include <asm/dmi.h>
 #include <asm/io_apic.h>
 #include <asm/ist.h>
 #include <asm/setup_arch.h>

commit adbc742bf78695bb98c79d18c558b61571748b99
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 15 22:23:48 2013 -0700

    x86, kdump: Change crashkernel_high/low= to crashkernel=,high/low
    
    Per hpa, use crashkernel=X,high crashkernel=Y,low instead of
    crashkernel_hign=X crashkernel_low=Y. As that could be extensible.
    
    -v2: according to Vivek, change delimiter to ;
    -v3: let hign and low only handle simple form and it conforms to
            description in kernel-parameters.txt
         still keep crashkernel=X override any crashkernel=X,high
            crashkernel=Y,low
    -v4: update get_last_crashkernel returning and add more strict
         checking in parse_crashkernel_simple() found by HATAYAMA.
    -v5: Change delimiter back to , according to HPA.
         also separate parse_suffix from parse_simper according to vivek.
            so we can avoid @pos in that path.
    -v6: Tight the checking about crashkernel=X,highblahblah,high
         found by HTYAYAMA.
    
    Cc: HATAYAMA Daisuke <d.hatayama@jp.fujitsu.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1366089828-19692-5-git-send-email-yinghai@kernel.org
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a85a144f2052..fae9134a2de9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -528,7 +528,7 @@ static void __init reserve_crashkernel_low(void)
 	int ret;
 
 	total_low_mem = memblock_mem_size(1UL<<(32-PAGE_SHIFT));
-	/* crashkernel_low=YM */
+	/* crashkernel=Y,low */
 	ret = parse_crashkernel_low(boot_command_line, total_low_mem,
 						&low_size, &base);
 	if (ret != 0) {
@@ -542,7 +542,7 @@ static void __init reserve_crashkernel_low(void)
 		low_size = swiotlb_size_or_default() + (8UL<<20);
 		auto_set = true;
 	} else {
-		/* passed with crashkernel_low=0 ? */
+		/* passed with crashkernel=0,low ? */
 		if (!low_size)
 			return;
 	}
@@ -582,7 +582,7 @@ static void __init reserve_crashkernel(void)
 	ret = parse_crashkernel(boot_command_line, total_mem,
 			&crash_size, &crash_base);
 	if (ret != 0 || crash_size <= 0) {
-		/* crashkernel_high=XM */
+		/* crashkernel=X,high */
 		ret = parse_crashkernel_high(boot_command_line, total_mem,
 				&crash_size, &crash_base);
 		if (ret != 0 || crash_size <= 0)

commit 55a20ee7804ab64ac90bcdd4e2868a42829e2784
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 15 22:23:47 2013 -0700

    x86, kdump: Retore crashkernel= to allocate under 896M
    
    Vivek found old kexec-tools does not work new kernel anymore.
    
    So change back crashkernel= back to old behavoir, and add crashkernel_high=
    to let user decide if buffer could be above 4G, and also new kexec-tools will
    be needed.
    
    -v2: let crashkernel=X override crashkernel_high=
        update description about _high will be ignored by crashkernel=X
    -v3: update description about kernel-parameters.txt according to Vivek.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1366089828-19692-4-git-send-email-yinghai@kernel.org
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 12349202cae7..a85a144f2052 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -507,11 +507,14 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels
  * would limit the kernel to the low 512 MiB due to mapping restrictions.
+ * On 64bit, old kexec-tools need to under 896MiB.
  */
 #ifdef CONFIG_X86_32
-# define CRASH_KERNEL_ADDR_MAX	(512 << 20)
+# define CRASH_KERNEL_ADDR_LOW_MAX	(512 << 20)
+# define CRASH_KERNEL_ADDR_HIGH_MAX	(512 << 20)
 #else
-# define CRASH_KERNEL_ADDR_MAX	MAXMEM
+# define CRASH_KERNEL_ADDR_LOW_MAX	(896UL<<20)
+# define CRASH_KERNEL_ADDR_HIGH_MAX	MAXMEM
 #endif
 
 static void __init reserve_crashkernel_low(void)
@@ -525,6 +528,7 @@ static void __init reserve_crashkernel_low(void)
 	int ret;
 
 	total_low_mem = memblock_mem_size(1UL<<(32-PAGE_SHIFT));
+	/* crashkernel_low=YM */
 	ret = parse_crashkernel_low(boot_command_line, total_low_mem,
 						&low_size, &base);
 	if (ret != 0) {
@@ -569,14 +573,22 @@ static void __init reserve_crashkernel(void)
 	const unsigned long long alignment = 16<<20;	/* 16M */
 	unsigned long long total_mem;
 	unsigned long long crash_size, crash_base;
+	bool high = false;
 	int ret;
 
 	total_mem = memblock_phys_mem_size();
 
+	/* crashkernel=XM */
 	ret = parse_crashkernel(boot_command_line, total_mem,
 			&crash_size, &crash_base);
-	if (ret != 0 || crash_size <= 0)
-		return;
+	if (ret != 0 || crash_size <= 0) {
+		/* crashkernel_high=XM */
+		ret = parse_crashkernel_high(boot_command_line, total_mem,
+				&crash_size, &crash_base);
+		if (ret != 0 || crash_size <= 0)
+			return;
+		high = true;
+	}
 
 	/* 0 means: find the address automatically */
 	if (crash_base <= 0) {
@@ -584,7 +596,9 @@ static void __init reserve_crashkernel(void)
 		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
 		 */
 		crash_base = memblock_find_in_range(alignment,
-			       CRASH_KERNEL_ADDR_MAX, crash_size, alignment);
+					high ? CRASH_KERNEL_ADDR_HIGH_MAX :
+					       CRASH_KERNEL_ADDR_LOW_MAX,
+					crash_size, alignment);
 
 		if (!crash_base) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");

commit c729de8fcea37a1c444e81857eace12494c804a9
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 15 22:23:45 2013 -0700

    x86, kdump: Set crashkernel_low automatically
    
    Chao said that kdump does does work well on his system on 3.8
    without extra parameter, even iommu does not work with kdump.
    And now have to append crashkernel_low=Y in first kernel to make
    kdump work.
    
    We have now modified crashkernel=X to allocate memory beyong 4G (if
    available) and do not allocate low range for crashkernel if the user
    does not specify that with crashkernel_low=Y.  This causes regression
    if iommu is not enabled.  Without iommu, swiotlb needs to be setup in
    first 4G and there is no low memory available to second kernel.
    
    Set crashkernel_low automatically if the user does not specify that.
    
    For system that does support IOMMU with kdump properly, user could
    specify crashkernel_low=0 to save that 72M low ram.
    
    -v3: add swiotlb_size() according to Konrad.
    -v4: add comments what 8M is for according to hpa.
         also update more crashkernel_low= in kernel-parameters.txt
    -v5: update changelog according to Vivek.
    -v6: Change description about swiotlb referring according to HATAYAMA.
    
    Reported-by: WANG Chao <chaowang@redhat.com>
    Tested-by: WANG Chao <chaowang@redhat.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1366089828-19692-2-git-send-email-yinghai@kernel.org
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 90d8cc930f5e..12349202cae7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -521,19 +521,34 @@ static void __init reserve_crashkernel_low(void)
 	unsigned long long low_base = 0, low_size = 0;
 	unsigned long total_low_mem;
 	unsigned long long base;
+	bool auto_set = false;
 	int ret;
 
 	total_low_mem = memblock_mem_size(1UL<<(32-PAGE_SHIFT));
 	ret = parse_crashkernel_low(boot_command_line, total_low_mem,
 						&low_size, &base);
-	if (ret != 0 || low_size <= 0)
-		return;
+	if (ret != 0) {
+		/*
+		 * two parts from lib/swiotlb.c:
+		 *	swiotlb size: user specified with swiotlb= or default.
+		 *	swiotlb overflow buffer: now is hardcoded to 32k.
+		 *		We round it to 8M for other buffers that
+		 *		may need to stay low too.
+		 */
+		low_size = swiotlb_size_or_default() + (8UL<<20);
+		auto_set = true;
+	} else {
+		/* passed with crashkernel_low=0 ? */
+		if (!low_size)
+			return;
+	}
 
 	low_base = memblock_find_in_range(low_size, (1ULL<<32),
 					low_size, alignment);
 
 	if (!low_base) {
-		pr_info("crashkernel low reservation failed - No suitable area found.\n");
+		if (!auto_set)
+			pr_info("crashkernel low reservation failed - No suitable area found.\n");
 
 		return;
 	}

commit 93a829e8e2c292f1d30155f64803101ca1cb7d3d
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Mar 20 15:07:25 2013 +0100

    x86, cpu: Convert FDIV bug detection
    
    ... to the new facility. Add a reference to the wikipedia article
    explaining the FDIV test we're doing here.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: http://lkml.kernel.org/r/1363788448-31325-4-git-send-email-bp@alien8.de
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 90d8cc930f5e..29258c75a2f3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -173,12 +173,10 @@ static struct resource bss_resource = {
 /* cpu data as detected by the assembly code in head.S */
 struct cpuinfo_x86 new_cpu_data __cpuinitdata = {
 	.wp_works_ok = -1,
-	.fdiv_bug = -1,
 };
 /* common cpu data for all cpus */
 struct cpuinfo_x86 boot_cpu_data __read_mostly = {
 	.wp_works_ok = -1,
-	.fdiv_bug = -1,
 };
 EXPORT_SYMBOL(boot_cpu_data);
 

commit 015221fefbc93689dd47508a66326556adf2abcd
Author: Krzysztof Mazur <krzysiek@podlesie.net>
Date:   Sun Mar 3 00:14:42 2013 +0100

    x86: Fix 32-bit *_cpu_data initializers
    
    The commit 27be457000211a6903968dfce06d5f73f051a217
    ('x86 idle: remove 32-bit-only "no-hlt" parameter, hlt_works_ok
    flag') removed the hlt_works_ok flag from struct cpuinfo_x86, but
    boot_cpu_data and new_cpu_data initializers were not changed
    causing setting f00f_bug flag, instead of fdiv_bug.
    
    If CONFIG_X86_F00F_BUG is not set the f00f_bug flag is never
    cleared.
    
    To avoid such problems in future C99-style initialization is now
    used.
    
    Signed-off-by: Krzysztof Mazur <krzysiek@podlesie.net>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: len.brown@intel.com
    Link: http://lkml.kernel.org/r/1362266082-2227-1-git-send-email-krzysiek@podlesie.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 84d32855f65c..90d8cc930f5e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -171,9 +171,15 @@ static struct resource bss_resource = {
 
 #ifdef CONFIG_X86_32
 /* cpu data as detected by the assembly code in head.S */
-struct cpuinfo_x86 new_cpu_data __cpuinitdata = {0, 0, 0, 0, -1, 1, 0, 0, -1};
+struct cpuinfo_x86 new_cpu_data __cpuinitdata = {
+	.wp_works_ok = -1,
+	.fdiv_bug = -1,
+};
 /* common cpu data for all cpus */
-struct cpuinfo_x86 boot_cpu_data __read_mostly = {0, 0, 0, 0, -1, 1, 0, 0, -1};
+struct cpuinfo_x86 boot_cpu_data __read_mostly = {
+	.wp_works_ok = -1,
+	.fdiv_bug = -1,
+};
 EXPORT_SYMBOL(boot_cpu_data);
 
 unsigned int def_to_bigsmp;

commit 20e6926dcbafa1b361f1c29d967688be14b6ca4b
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Mar 1 14:51:27 2013 -0800

    x86, ACPI, mm: Revert movablemem_map support
    
    Tim found:
    
      WARNING: at arch/x86/kernel/smpboot.c:324 topology_sane.isra.2+0x6f/0x80()
      Hardware name: S2600CP
      sched: CPU #1's llc-sibling CPU #0 is not on the same node! [node: 1 != 0]. Ignoring dependency.
      smpboot: Booting Node   1, Processors  #1
      Modules linked in:
      Pid: 0, comm: swapper/1 Not tainted 3.9.0-0-generic #1
      Call Trace:
        set_cpu_sibling_map+0x279/0x449
        start_secondary+0x11d/0x1e5
    
    Don Morris reproduced on a HP z620 workstation, and bisected it to
    commit e8d195525809 ("acpi, memory-hotplug: parse SRAT before memblock
    is ready")
    
    It turns out movable_map has some problems, and it breaks several things
    
    1. numa_init is called several times, NOT just for srat. so those
            nodes_clear(numa_nodes_parsed)
            memset(&numa_meminfo, 0, sizeof(numa_meminfo))
       can not be just removed.  Need to consider sequence is: numaq, srat, amd, dummy.
       and make fall back path working.
    
    2. simply split acpi_numa_init to early_parse_srat.
       a. that early_parse_srat is NOT called for ia64, so you break ia64.
       b.  for (i = 0; i < MAX_LOCAL_APIC; i++)
                 set_apicid_to_node(i, NUMA_NO_NODE)
         still left in numa_init. So it will just clear result from early_parse_srat.
         it should be moved before that....
       c.  it breaks ACPI_TABLE_OVERIDE...as the acpi table scan is moved
           early before override from INITRD is settled.
    
    3. that patch TITLE is total misleading, there is NO x86 in the title,
       but it changes critical x86 code. It caused x86 guys did not
       pay attention to find the problem early. Those patches really should
       be routed via tip/x86/mm.
    
    4. after that commit, following range can not use movable ram:
      a. real_mode code.... well..funny, legacy Node0 [0,1M) could be hot-removed?
      b. initrd... it will be freed after booting, so it could be on movable...
      c. crashkernel for kdump...: looks like we can not put kdump kernel above 4G
            anymore.
      d. init_mem_mapping: can not put page table high anymore.
      e. initmem_init: vmemmap can not be high local node anymore. That is
         not good.
    
    If node is hotplugable, the mem related range like page table and
    vmemmap could be on the that node without problem and should be on that
    node.
    
    We have workaround patch that could fix some problems, but some can not
    be fixed.
    
    So just remove that offending commit and related ones including:
    
     f7210e6c4ac7 ("mm/memblock.c: use CONFIG_HAVE_MEMBLOCK_NODE_MAP to
        protect movablecore_map in memblock_overlaps_region().")
    
     01a178a94e8e ("acpi, memory-hotplug: support getting hotplug info from
        SRAT")
    
     27168d38fa20 ("acpi, memory-hotplug: extend movablemem_map ranges to
        the end of node")
    
     e8d195525809 ("acpi, memory-hotplug: parse SRAT before memblock is
        ready")
    
     fb06bc8e5f42 ("page_alloc: bootmem limit with movablecore_map")
    
     42f47e27e761 ("page_alloc: make movablemem_map have higher priority")
    
     6981ec31146c ("page_alloc: introduce zone_movable_limit[] to keep
        movable limit for nodes")
    
     34b71f1e04fc ("page_alloc: add movable_memmap kernel parameter")
    
     4d59a75125d5 ("x86: get pg_data_t's memory from other node")
    
    Later we should have patches that will make sure kernel put page table
    and vmemmap on local node ram instead of push them down to node0.  Also
    need to find way to put other kernel used ram to local node ram.
    
    Reported-by: Tim Gardner <tim.gardner@canonical.com>
    Reported-by: Don Morris <don.morris@hp.com>
    Bisected-by: Don Morris <don.morris@hp.com>
    Tested-by: Don Morris <don.morris@hp.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Thomas Renninger <trenn@suse.de>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e89acdf6b77b..84d32855f65c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1056,15 +1056,6 @@ void __init setup_arch(char **cmdline_p)
 	setup_bios_corruption_check();
 #endif
 
-	/*
-	 * In the memory hotplug case, the kernel needs info from SRAT to
-	 * determine which memory is hotpluggable before allocating memory
-	 * using memblock.
-	 */
-	acpi_boot_table_init();
-	early_acpi_boot_init();
-	early_parse_srat();
-
 #ifdef CONFIG_X86_32
 	printk(KERN_DEBUG "initial memory mapped: [mem 0x00000000-%#010lx]\n",
 			(max_pfn_mapped<<PAGE_SHIFT) - 1);
@@ -1110,6 +1101,10 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Parse the ACPI tables for possible boot-time SMP configuration.
 	 */
+	acpi_boot_table_init();
+
+	early_acpi_boot_init();
+
 	initmem_init();
 	memblock_find_dma_reserve();
 

commit e3c4877de8b9d93bd47b6ee88eb594b1c1e10da5
Merge: 18a44a7ff107 6b59e366e074
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 27 16:17:42 2013 -0800

    Merge branch 'x86-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86/EFI changes from Peter Anvin:
    
     - Improve the initrd handling in the EFI boot stub by allowing forward
       slashes in the pathname - from Chun-Yi Lee.
    
     - Cleanup code duplication in the EFI mixed kernel/firmware code - from
       Satoru Takeuchi.
    
     - efivarfs bug fixes for more strict filename validation, with lots of
       input from Al Viro.
    
    * 'x86-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, efi: remove duplicate code in setup_arch() by using, efi_is_native()
      efivarfs: guid part of filenames are case-insensitive
      efivarfs: Validate filenames much more aggressively
      efivarfs: Use sizeof() instead of magic number
      x86, efi: Allow slash in file path of initrd

commit e8d1955258091e4c92d5a975ebd7fd8a98f5d30f
Author: Tang Chen <tangchen@cn.fujitsu.com>
Date:   Fri Feb 22 16:33:44 2013 -0800

    acpi, memory-hotplug: parse SRAT before memblock is ready
    
    On linux, the pages used by kernel could not be migrated.  As a result,
    if a memory range is used by kernel, it cannot be hot-removed.  So if we
    want to hot-remove memory, we should prevent kernel from using it.
    
    The way now used to prevent this is specify a memory range by
    movablemem_map boot option and set it as ZONE_MOVABLE.
    
    But when the system is booting, memblock will allocate memory, and
    reserve the memory for kernel.  And before we parse SRAT, and know the
    node memory ranges, memblock is working.  And it may allocate memory in
    ranges to be set as ZONE_MOVABLE.  This memory can be used by kernel,
    and never be freed.
    
    So, let's parse SRAT before memblock is called first.  And it is early
    enough.
    
    The first call of memblock_find_in_range_node() is in:
    
      setup_arch()
        |-->setup_real_mode()
    
    so, this patch add a function early_parse_srat() to parse SRAT, and call
    it before setup_real_mode() is called.
    
    NOTE:
    
    1) early_parse_srat() is called before numa_init(), and has initialized
       numa_meminfo.  So DO NOT clear numa_nodes_parsed in numa_init() and DO
       NOT zero numa_meminfo in numa_init(), otherwise we will lose memory
       numa info.
    
    2) I don't know why using count of memory affinities parsed from SRAT
       as a return value in original acpi_numa_init().  So I add a static
       variable srat_mem_cnt to remember this count and use it as the return
       value of the new acpi_numa_init()
    
    [mhocko@suse.cz: parse SRAT before memblock is ready fix]
    Signed-off-by: Tang Chen <tangchen@cn.fujitsu.com>
    Reviewed-by: Wen Congyang <wency@cn.fujitsu.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Wu Jianguo <wujianguo@huawei.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: "Brown, Len" <len.brown@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 915f5efefcf5..9c857f05cef0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1056,6 +1056,15 @@ void __init setup_arch(char **cmdline_p)
 	setup_bios_corruption_check();
 #endif
 
+	/*
+	 * In the memory hotplug case, the kernel needs info from SRAT to
+	 * determine which memory is hotpluggable before allocating memory
+	 * using memblock.
+	 */
+	acpi_boot_table_init();
+	early_acpi_boot_init();
+	early_parse_srat();
+
 #ifdef CONFIG_X86_32
 	printk(KERN_DEBUG "initial memory mapped: [mem 0x00000000-%#010lx]\n",
 			(max_pfn_mapped<<PAGE_SHIFT) - 1);
@@ -1101,10 +1110,6 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Parse the ACPI tables for possible boot-time SMP configuration.
 	 */
-	acpi_boot_table_init();
-
-	early_acpi_boot_init();
-
 	initmem_init();
 	memblock_find_dma_reserve();
 

commit 2ef14f465b9e096531343f5b734cffc5f759f4a6
Merge: cb715a836642 0da3e7f526fd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 21 18:06:55 2013 -0800

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm changes from Peter Anvin:
     "This is a huge set of several partly interrelated (and concurrently
      developed) changes, which is why the branch history is messier than
      one would like.
    
      The *really* big items are two humonguous patchsets mostly developed
      by Yinghai Lu at my request, which completely revamps the way we
      create initial page tables.  In particular, rather than estimating how
      much memory we will need for page tables and then build them into that
      memory -- a calculation that has shown to be incredibly fragile -- we
      now build them (on 64 bits) with the aid of a "pseudo-linear mode" --
      a #PF handler which creates temporary page tables on demand.
    
      This has several advantages:
    
      1. It makes it much easier to support things that need access to data
         very early (a followon patchset uses this to load microcode way
         early in the kernel startup).
    
      2. It allows the kernel and all the kernel data objects to be invoked
         from above the 4 GB limit.  This allows kdump to work on very large
         systems.
    
      3. It greatly reduces the difference between Xen and native (Xen's
         equivalent of the #PF handler are the temporary page tables created
         by the domain builder), eliminating a bunch of fragile hooks.
    
      The patch series also gets us a bit closer to W^X.
    
      Additional work in this pull is the 64-bit get_user() work which you
      were also involved with, and a bunch of cleanups/speedups to
      __phys_addr()/__pa()."
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (105 commits)
      x86, mm: Move reserving low memory later in initialization
      x86, doc: Clarify the use of asm("%edx") in uaccess.h
      x86, mm: Redesign get_user with a __builtin_choose_expr hack
      x86: Be consistent with data size in getuser.S
      x86, mm: Use a bitfield to mask nuisance get_user() warnings
      x86/kvm: Fix compile warning in kvm_register_steal_time()
      x86-32: Add support for 64bit get_user()
      x86-32, mm: Remove reference to alloc_remap()
      x86-32, mm: Remove reference to resume_map_numa_kva()
      x86-32, mm: Rip out x86_32 NUMA remapping code
      x86/numa: Use __pa_nodebug() instead
      x86: Don't panic if can not alloc buffer for swiotlb
      mm: Add alloc_bootmem_low_pages_nopanic()
      x86, 64bit, mm: hibernate use generic mapping_init
      x86, 64bit, mm: Mark data/bss/brk to nx
      x86: Merge early kernel reserve for 32bit and 64bit
      x86: Add Crash kernel low reservation
      x86, kdump: Remove crashkernel range find limit for 64bit
      memblock: Add memblock_mem_size()
      x86, boot: Not need to check setup_header version for setup_data
      ...

commit 0da3e7f526fde7a6522a3038b7ce609fc50f6707
Merge: 95c9608478d6 68d00bbebb5a
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Feb 15 09:25:08 2013 -0800

    Merge branch 'x86/mm2' into x86/mm
    
    x86/mm2 is testing out fine, but has developed conflicts with x86/mm
    due to patches in adjacent code.  Merge them so we can drop x86/mm2
    and have a unified branch.
    
    Resolved Conflicts:
            arch/x86/kernel/setup.c

commit 95c9608478d639dcffc14ea47b31bff021a99ed1
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Thu Feb 14 14:02:52 2013 -0800

    x86, mm: Move reserving low memory later in initialization
    
    Move the reservation of low memory, except for the 4K which actually
    does belong to the BIOS, later in the initialization; in particular,
    after we have already reserved the trampoline.
    
    The current code locates the trampoline as high as possible, so by
    deferring the allocation we will still be able to reserve as much
    memory as is possible.  This allows us to run with reservelow=640k
    without getting a crash on system startup.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Link: http://lkml.kernel.org/n/tip-0y9dqmmsousf69wutxwl3kkf@git.kernel.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8354399b3aae..0aebd776018e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -608,8 +608,6 @@ static __init void reserve_ibft_region(void)
 		memblock_reserve(addr, size);
 }
 
-static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
-
 static bool __init snb_gfx_workaround_needed(void)
 {
 #ifdef CONFIG_PCI
@@ -698,8 +696,7 @@ static void __init trim_bios_range(void)
 	 * since some BIOSes are known to corrupt low memory.  See the
 	 * Kconfig help text for X86_RESERVE_LOW.
 	 */
-	e820_update_range(0, ALIGN(reserve_low, PAGE_SIZE),
-			  E820_RAM, E820_RESERVED);
+	e820_update_range(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
 
 	/*
 	 * special case: Some BIOSen report the PC BIOS
@@ -711,6 +708,8 @@ static void __init trim_bios_range(void)
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
 
+static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
+
 static int __init parse_reservelow(char *p)
 {
 	unsigned long long size;
@@ -733,6 +732,11 @@ static int __init parse_reservelow(char *p)
 
 early_param("reservelow", parse_reservelow);
 
+static void __init trim_low_memory_range(void)
+{
+	memblock_reserve(0, ALIGN(reserve_low, PAGE_SIZE));
+}
+	
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -987,6 +991,7 @@ void __init setup_arch(char **cmdline_p)
 	setup_real_mode();
 
 	trim_platform_memory_ranges();
+	trim_low_memory_range();
 
 	init_gbpages();
 

commit 6b59e366e074d3962e04f01efb8acc10a33c0e1e
Author: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
Date:   Thu Feb 14 09:07:35 2013 +0900

    x86, efi: remove duplicate code in setup_arch() by using, efi_is_native()
    
    The check, "IS_ENABLED(CONFIG_X86_64) != efi_enabled(EFI_64BIT)",
    in setup_arch() can be replaced by efi_is_enabled(). This change
    remove duplicate code and improve readability.
    
    Signed-off-by: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Olof Johansson <olof@lixom.net>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8b24289cc10c..1abb7969173a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1135,8 +1135,7 @@ void __init setup_arch(char **cmdline_p)
 	 * mismatched firmware/kernel archtectures since there is no
 	 * support for runtime services.
 	 */
-	if (efi_enabled(EFI_BOOT) &&
-	    IS_ENABLED(CONFIG_X86_64) != efi_enabled(EFI_64BIT)) {
+	if (efi_enabled(EFI_BOOT) && !efi_is_native()) {
 		pr_info("efi: Setup done, disabling due to 32/64-bit mismatch\n");
 		efi_unmap_memmap();
 	}

commit 68d00bbebb5a48b7a9056a8c03476a71ecbc30a6
Merge: ac2cbab21f31 07f4207a305c
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Feb 1 02:25:06 2013 -0800

    Merge remote-tracking branch 'origin/x86/mm' into x86/mm2
    
    Explicitly merging these two branches due to nontrivial conflicts and
    to allow further work.
    
    Resolved Conflicts:
            arch/x86/kernel/head32.c
            arch/x86/kernel/head64.c
            arch/x86/mm/init_64.c
            arch/x86/realmode/init.c
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit 83e68189745ad931c2afd45d8ee3303929233e7f
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Wed Nov 14 09:42:35 2012 +0000

    efi: Make 'efi_enabled' a function to query EFI facilities
    
    Originally 'efi_enabled' indicated whether a kernel was booted from
    EFI firmware. Over time its semantics have changed, and it now
    indicates whether or not we are booted on an EFI machine with
    bit-native firmware, e.g. 64-bit kernel with 64-bit firmware.
    
    The immediate motivation for this patch is the bug report at,
    
        https://bugs.launchpad.net/ubuntu-cdimage/+bug/1040557
    
    which details how running a platform driver on an EFI machine that is
    designed to run under BIOS can cause the machine to become
    bricked. Also, the following report,
    
        https://bugzilla.kernel.org/show_bug.cgi?id=47121
    
    details how running said driver can also cause Machine Check
    Exceptions. Drivers need a new means of detecting whether they're
    running on an EFI machine, as sadly the expression,
    
        if (!efi_enabled)
    
    hasn't been a sufficient condition for quite some time.
    
    Users actually want to query 'efi_enabled' for different reasons -
    what they really want access to is the list of available EFI
    facilities.
    
    For instance, the x86 reboot code needs to know whether it can invoke
    the ResetSystem() function provided by the EFI runtime services, while
    the ACPI OSL code wants to know whether the EFI config tables were
    mapped successfully. There are also checks in some of the platform
    driver code to simply see if they're running on an EFI machine (which
    would make it a bad idea to do BIOS-y things).
    
    This patch is a prereq for the samsung-laptop fix patch.
    
    Cc: David Airlie <airlied@linux.ie>
    Cc: Corentin Chary <corentincj@iksaif.net>
    Cc: Matthew Garrett <mjg59@srcf.ucam.org>
    Cc: Dave Jiang <dave.jiang@intel.com>
    Cc: Olof Johansson <olof@lixom.net>
    Cc: Peter Jones <pjones@redhat.com>
    Cc: Colin Ian King <colin.king@canonical.com>
    Cc: Steve Langasek <steve.langasek@canonical.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad@kernel.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 00f6c1472b85..8b24289cc10c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -807,15 +807,15 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     "EL32", 4)) {
-		efi_enabled = 1;
-		efi_64bit = false;
+		set_bit(EFI_BOOT, &x86_efi_facility);
 	} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     "EL64", 4)) {
-		efi_enabled = 1;
-		efi_64bit = true;
+		set_bit(EFI_BOOT, &x86_efi_facility);
+		set_bit(EFI_64BIT, &x86_efi_facility);
 	}
-	if (efi_enabled && efi_memblock_x86_reserve_range())
-		efi_enabled = 0;
+
+	if (efi_enabled(EFI_BOOT))
+		efi_memblock_x86_reserve_range();
 #endif
 
 	x86_init.oem.arch_setup();
@@ -888,7 +888,7 @@ void __init setup_arch(char **cmdline_p)
 
 	finish_e820_parsing();
 
-	if (efi_enabled)
+	if (efi_enabled(EFI_BOOT))
 		efi_init();
 
 	dmi_scan_machine();
@@ -971,7 +971,7 @@ void __init setup_arch(char **cmdline_p)
 	 * The EFI specification says that boot service code won't be called
 	 * after ExitBootServices(). This is, in fact, a lie.
 	 */
-	if (efi_enabled)
+	if (efi_enabled(EFI_MEMMAP))
 		efi_reserve_boot_services();
 
 	/* preallocate 4k for mptable mpc */
@@ -1114,7 +1114,7 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_VT
 #if defined(CONFIG_VGA_CONSOLE)
-	if (!efi_enabled || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))
+	if (!efi_enabled(EFI_BOOT) || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))
 		conswitchp = &vga_con;
 #elif defined(CONFIG_DUMMY_CONSOLE)
 	conswitchp = &dummy_con;
@@ -1131,14 +1131,14 @@ void __init setup_arch(char **cmdline_p)
 	register_refined_jiffies(CLOCK_TICK_RATE);
 
 #ifdef CONFIG_EFI
-	/* Once setup is done above, disable efi_enabled on mismatched
-	 * firmware/kernel archtectures since there is no support for
-	 * runtime services.
+	/* Once setup is done above, unmap the EFI memory map on
+	 * mismatched firmware/kernel archtectures since there is no
+	 * support for runtime services.
 	 */
-	if (efi_enabled && IS_ENABLED(CONFIG_X86_64) != efi_64bit) {
+	if (efi_enabled(EFI_BOOT) &&
+	    IS_ENABLED(CONFIG_X86_64) != efi_enabled(EFI_64BIT)) {
 		pr_info("efi: Setup done, disabling due to 32/64-bit mismatch\n");
 		efi_unmap_memmap();
-		efi_enabled = 0;
 	}
 #endif
 }

commit 6c902b656c4a808d9c6f40a387b166455efecd62
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:20:12 2013 -0800

    x86: Merge early kernel reserve for 32bit and 64bit
    
    They are the same, and we could move them out from head32/64.c to setup.c.
    
    We are using memblock, and it could handle overlapping properly, so
    we don't need to reserve some at first to hold the location, and just
    need to make sure we reserve them before we are using memblock to find
    free mem to use.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-32-git-send-email-yinghai@kernel.org
    Cc: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5dc47c3e537b..a74701af74e3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -805,8 +805,17 @@ early_param("reservelow", parse_reservelow);
 
 void __init setup_arch(char **cmdline_p)
 {
+	memblock_reserve(__pa_symbol(_text),
+			 (unsigned long)__bss_stop - (unsigned long)_text);
+
 	early_reserve_initrd();
 
+	/*
+	 * At this point everything still needed from the boot loader
+	 * or BIOS or kernel text should be early reserved or marked not
+	 * RAM in e820. All other memory is free game.
+	 */
+
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();

commit 0212f9159694be61c6bc52e925fa76643e0c1abf
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:20:11 2013 -0800

    x86: Add Crash kernel low reservation
    
    During kdump kernel's booting stage, it need to find low ram for
    swiotlb buffer when system does not support intel iommu/dmar remapping.
    
    kexed-tools is appending memmap=exactmap and range from /proc/iomem
    with "Crash kernel", and that range is above 4G for 64bit after boot
    protocol 2.12.
    
    We need to add another range in /proc/iomem like "Crash kernel low",
    so kexec-tools could find that info and append to kdump kernel
    command line.
    
    Try to reserve some under 4G if the normal "Crash kernel" is above 4G.
    
    User could specify the size with crashkernel_low=XX[KMG].
    
    -v2: fix warning that is found by Fengguang's test robot.
    -v3: move out get_mem_size change to another patch, to solve compiling
         warning that is found by Borislav Petkov <bp@alien8.de>
    -v4: user must specify crashkernel_low if system does not support
         intel or amd iommu.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-31-git-send-email-yinghai@kernel.org
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Rob Landley <rob@landley.net>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4778ddeedc8a..5dc47c3e537b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -508,8 +508,44 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 # define CRASH_KERNEL_ADDR_MAX	MAXMEM
 #endif
 
+static void __init reserve_crashkernel_low(void)
+{
+#ifdef CONFIG_X86_64
+	const unsigned long long alignment = 16<<20;	/* 16M */
+	unsigned long long low_base = 0, low_size = 0;
+	unsigned long total_low_mem;
+	unsigned long long base;
+	int ret;
+
+	total_low_mem = memblock_mem_size(1UL<<(32-PAGE_SHIFT));
+	ret = parse_crashkernel_low(boot_command_line, total_low_mem,
+						&low_size, &base);
+	if (ret != 0 || low_size <= 0)
+		return;
+
+	low_base = memblock_find_in_range(low_size, (1ULL<<32),
+					low_size, alignment);
+
+	if (!low_base) {
+		pr_info("crashkernel low reservation failed - No suitable area found.\n");
+
+		return;
+	}
+
+	memblock_reserve(low_base, low_size);
+	pr_info("Reserving %ldMB of low memory at %ldMB for crashkernel (System low RAM: %ldMB)\n",
+			(unsigned long)(low_size >> 20),
+			(unsigned long)(low_base >> 20),
+			(unsigned long)(total_low_mem >> 20));
+	crashk_low_res.start = low_base;
+	crashk_low_res.end   = low_base + low_size - 1;
+	insert_resource(&iomem_resource, &crashk_low_res);
+#endif
+}
+
 static void __init reserve_crashkernel(void)
 {
+	const unsigned long long alignment = 16<<20;	/* 16M */
 	unsigned long long total_mem;
 	unsigned long long crash_size, crash_base;
 	int ret;
@@ -523,8 +559,6 @@ static void __init reserve_crashkernel(void)
 
 	/* 0 means: find the address automatically */
 	if (crash_base <= 0) {
-		const unsigned long long alignment = 16<<20;	/* 16M */
-
 		/*
 		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
 		 */
@@ -535,6 +569,7 @@ static void __init reserve_crashkernel(void)
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
 		}
+
 	} else {
 		unsigned long long start;
 
@@ -556,6 +591,9 @@ static void __init reserve_crashkernel(void)
 	crashk_res.start = crash_base;
 	crashk_res.end   = crash_base + crash_size - 1;
 	insert_resource(&iomem_resource, &crashk_res);
+
+	if (crash_base >= (1ULL<<32))
+		reserve_crashkernel_low();
 }
 #else
 static void __init reserve_crashkernel(void)

commit 7d41a8a4a2b2438621a9159477bff36a11d79a42
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:20:10 2013 -0800

    x86, kdump: Remove crashkernel range find limit for 64bit
    
    Now kexeced kernel/ramdisk could be above 4g, so remove 896 limit for
    64bit.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-30-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bbe8cdf7515e..4778ddeedc8a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -501,13 +501,11 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels
  * would limit the kernel to the low 512 MiB due to mapping restrictions.
- * On 64 bits, kexec-tools currently limits us to 896 MiB; increase this
- * limit once kexec-tools are fixed.
  */
 #ifdef CONFIG_X86_32
 # define CRASH_KERNEL_ADDR_MAX	(512 << 20)
 #else
-# define CRASH_KERNEL_ADDR_MAX	(896 << 20)
+# define CRASH_KERNEL_ADDR_MAX	MAXMEM
 #endif
 
 static void __init reserve_crashkernel(void)

commit 595ad9af8584908ea5fb698b836169d05b99f186
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:20:09 2013 -0800

    memblock: Add memblock_mem_size()
    
    Use it to get mem size under the limit_pfn.
    to replace local version in x86 reserved_initrd.
    
    -v2: remove not needed cast that is pointed out by HPA.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-29-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b80bee10982f..bbe8cdf7515e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -363,20 +363,6 @@ static void __init relocate_initrd(void)
 		ramdisk_here, ramdisk_here + ramdisk_size - 1);
 }
 
-static u64 __init get_mem_size(unsigned long limit_pfn)
-{
-	int i;
-	u64 mapped_pages = 0;
-	unsigned long start_pfn, end_pfn;
-
-	for_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, NULL) {
-		start_pfn = min_t(unsigned long, start_pfn, limit_pfn);
-		end_pfn = min_t(unsigned long, end_pfn, limit_pfn);
-		mapped_pages += end_pfn - start_pfn;
-	}
-
-	return mapped_pages << PAGE_SHIFT;
-}
 static void __init early_reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
@@ -404,7 +390,7 @@ static void __init reserve_initrd(void)
 
 	initrd_start = 0;
 
-	mapped_size = get_mem_size(max_pfn_mapped);
+	mapped_size = memblock_mem_size(max_pfn_mapped);
 	if (ramdisk_size >= (mapped_size>>1))
 		panic("initrd too large to handle, "
 		       "disabling initrd (%lld needed, %lld available)\n",

commit d1af6d045fba6b070fa81f54dfe9227214be99ea
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:20:08 2013 -0800

    x86, boot: Not need to check setup_header version for setup_data
    
    That is for bootloaders.
    
    setup_data is in setup_header, and bootloader is copying that from bzImage.
    So for old bootloader should keep that as 0 already.
    
    old kexec-tools till now for elf image set setup_data to 0, so it is ok.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-28-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 519f2bc4950a..b80bee10982f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -439,8 +439,6 @@ static void __init parse_setup_data(void)
 	struct setup_data *data;
 	u64 pa_data;
 
-	if (boot_params.hdr.version < 0x0209)
-		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
 		u32 data_len, map_len;
@@ -476,8 +474,6 @@ static void __init e820_reserve_setup_data(void)
 	u64 pa_data;
 	int found = 0;
 
-	if (boot_params.hdr.version < 0x0209)
-		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));
@@ -501,8 +497,6 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 	struct setup_data *data;
 	u64 pa_data;
 
-	if (boot_params.hdr.version < 0x0209)
-		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));

commit ee92d815027a76ef92f3ec7b155b0c8aa345f239
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Jan 28 20:16:44 2013 -0800

    x86, boot: Support loading bzImage, boot_params and ramdisk above 4G
    
    xloadflags bit 1 indicates that we can load the kernel and all data
    structures above 4G; it is set if kernel is relocatable and 64bit.
    
    bootloader will check if xloadflags bit 1 is set to decide if
    it could load ramdisk and kernel high above 4G.
    
    bootloader will fill value to ext_ramdisk_image/size for high 32bits
    when it load ramdisk above 4G.
    kernel use get_ramdisk_image/size to use ext_ramdisk_image/size to get
    right positon for ramdisk.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Rob Landley <rob@landley.net>
    Cc: Matt Fleming <matt.fleming@intel.com>
    Cc: Gokul Caushik <caushik1@gmail.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Joe Millenbach <jmillenbach@gmail.com>
    Link: http://lkml.kernel.org/r/1359058816-7615-26-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 83b38617ff59..519f2bc4950a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -298,12 +298,16 @@ static u64 __init get_ramdisk_image(void)
 {
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 
+	ramdisk_image |= (u64)boot_params.ext_ramdisk_image << 32;
+
 	return ramdisk_image;
 }
 static u64 __init get_ramdisk_size(void)
 {
 	u64 ramdisk_size = boot_params.hdr.ramdisk_size;
 
+	ramdisk_size |= (u64)boot_params.ext_ramdisk_size << 32;
+
 	return ramdisk_size;
 }
 

commit a8a51a88d5152aa40e5e07dcdd939c7fafc42224
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:19:56 2013 -0800

    x86: Add get_ramdisk_image/size()
    
    There are several places to find ramdisk information early for reserving
    and relocating.
    
    Use accessor functions to make code more readable and consistent.
    
    Later will add ext_ramdisk_image/size in those functions to support
    loading ramdisk above 4g.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-16-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8e356923cbd0..83b38617ff59 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -294,12 +294,25 @@ static void __init reserve_brk(void)
 
 #ifdef CONFIG_BLK_DEV_INITRD
 
+static u64 __init get_ramdisk_image(void)
+{
+	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
+
+	return ramdisk_image;
+}
+static u64 __init get_ramdisk_size(void)
+{
+	u64 ramdisk_size = boot_params.hdr.ramdisk_size;
+
+	return ramdisk_size;
+}
+
 #define MAX_MAP_CHUNK	(NR_FIX_BTMAPS << PAGE_SHIFT)
 static void __init relocate_initrd(void)
 {
 	/* Assume only end is not page aligned */
-	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
-	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 ramdisk_image = get_ramdisk_image();
+	u64 ramdisk_size  = get_ramdisk_size();
 	u64 area_size     = PAGE_ALIGN(ramdisk_size);
 	u64 ramdisk_here;
 	unsigned long slop, clen, mapaddr;
@@ -338,8 +351,8 @@ static void __init relocate_initrd(void)
 		ramdisk_size  -= clen;
 	}
 
-	ramdisk_image = boot_params.hdr.ramdisk_image;
-	ramdisk_size  = boot_params.hdr.ramdisk_size;
+	ramdisk_image = get_ramdisk_image();
+	ramdisk_size  = get_ramdisk_size();
 	printk(KERN_INFO "Move RAMDISK from [mem %#010llx-%#010llx] to"
 		" [mem %#010llx-%#010llx]\n",
 		ramdisk_image, ramdisk_image + ramdisk_size - 1,
@@ -363,8 +376,8 @@ static u64 __init get_mem_size(unsigned long limit_pfn)
 static void __init early_reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
-	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
-	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 ramdisk_image = get_ramdisk_image();
+	u64 ramdisk_size  = get_ramdisk_size();
 	u64 ramdisk_end   = PAGE_ALIGN(ramdisk_image + ramdisk_size);
 
 	if (!boot_params.hdr.type_of_loader ||
@@ -376,8 +389,8 @@ static void __init early_reserve_initrd(void)
 static void __init reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
-	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
-	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 ramdisk_image = get_ramdisk_image();
+	u64 ramdisk_size  = get_ramdisk_size();
 	u64 ramdisk_end   = PAGE_ALIGN(ramdisk_image + ramdisk_size);
 	u64 mapped_size;
 

commit 1b8c78be01203e1c95ec5dfef6db307796fe0bc7
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:19:55 2013 -0800

    x86: Merge early_reserve_initrd for 32bit and 64bit
    
    They are the same, could move them out from head32/64.c to setup.c.
    
    We are using memblock, and it could handle overlapping properly, so
    we don't need to reserve some at first to hold the location, and just
    need to make sure we reserve them before we are using memblock to find
    free mem to use.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-15-git-send-email-yinghai@kernel.org
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d58083a2e158..8e356923cbd0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -360,6 +360,19 @@ static u64 __init get_mem_size(unsigned long limit_pfn)
 
 	return mapped_pages << PAGE_SHIFT;
 }
+static void __init early_reserve_initrd(void)
+{
+	/* Assume only end is not page aligned */
+	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
+	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 ramdisk_end   = PAGE_ALIGN(ramdisk_image + ramdisk_size);
+
+	if (!boot_params.hdr.type_of_loader ||
+	    !ramdisk_image || !ramdisk_size)
+		return;		/* No initrd provided by bootloader */
+
+	memblock_reserve(ramdisk_image, ramdisk_end - ramdisk_image);
+}
 static void __init reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
@@ -386,10 +399,6 @@ static void __init reserve_initrd(void)
 	if (pfn_range_is_mapped(PFN_DOWN(ramdisk_image),
 				PFN_DOWN(ramdisk_end))) {
 		/* All are mapped, easy case */
-		/*
-		 * don't need to reserve again, already reserved early
-		 * in i386_start_kernel
-		 */
 		initrd_start = ramdisk_image + PAGE_OFFSET;
 		initrd_end = initrd_start + ramdisk_size;
 		return;
@@ -400,6 +409,9 @@ static void __init reserve_initrd(void)
 	memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
 }
 #else
+static void __init early_reserve_initrd(void)
+{
+}
 static void __init reserve_initrd(void)
 {
 }
@@ -760,6 +772,8 @@ early_param("reservelow", parse_reservelow);
 
 void __init setup_arch(char **cmdline_p)
 {
+	early_reserve_initrd();
+
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();

commit 100542306f644fc580857a8ca4896fb12b794d41
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:19:54 2013 -0800

    x86, 64bit: Don't set max_pfn_mapped wrong value early on native path
    
    We are not having max_pfn_mapped set correctly until init_memory_mapping.
    So don't print its initial value for 64bit
    
    Also need to use KERNEL_IMAGE_SIZE directly for highmap cleanup.
    
    -v2: update comments about max_pfn_mapped according to Stefano Stabellini.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-14-git-send-email-yinghai@kernel.org
    Acked-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index db9c41dae8d7..d58083a2e158 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -996,8 +996,10 @@ void __init setup_arch(char **cmdline_p)
 	setup_bios_corruption_check();
 #endif
 
+#ifdef CONFIG_X86_32
 	printk(KERN_DEBUG "initial memory mapped: [mem 0x00000000-%#010lx]\n",
 			(max_pfn_mapped<<PAGE_SHIFT) - 1);
+#endif
 
 	reserve_real_mode();
 

commit 8170e6bed465b4b0c7687f93e9948aca4358a33b
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Thu Jan 24 12:19:52 2013 -0800

    x86, 64bit: Use a #PF handler to materialize early mappings on demand
    
    Linear mode (CR0.PG = 0) is mutually exclusive with 64-bit mode; all
    64-bit code has to use page tables.  This makes it awkward before we
    have first set up properly all-covering page tables to access objects
    that are outside the static kernel range.
    
    So far we have dealt with that simply by mapping a fixed amount of
    low memory, but that fails in at least two upcoming use cases:
    
    1. We will support load and run kernel, struct boot_params, ramdisk,
       command line, etc. above the 4 GiB mark.
    2. need to access ramdisk early to get microcode to update that as
       early possible.
    
    We could use early_iomap to access them too, but it will make code to
    messy and hard to be unified with 32 bit.
    
    Hence, set up a #PF table and use a fixed number of buffers to set up
    page tables on demand.  If the buffers fill up then we simply flush
    them and start over.  These buffers are all in __initdata, so it does
    not increase RAM usage at runtime.
    
    Thus, with the help of the #PF handler, we can set the final kernel
    mapping from blank, and switch to init_level4_pgt later.
    
    During the switchover in head_64.S, before #PF handler is available,
    we use three pages to handle kernel crossing 1G, 512G boundaries with
    sharing page by playing games with page aliasing: the same page is
    mapped twice in the higher-level tables with appropriate wraparound.
    The kernel region itself will be properly mapped; other mappings may
    be spurious.
    
    early_make_pgtable is using kernel high mapping address to access pages
    to set page table.
    
    -v4: Add phys_base offset to make kexec happy, and add
            init_mapping_kernel()   - Yinghai
    -v5: fix compiling with xen, and add back ident level3 and level2 for xen
         also move back init_level4_pgt from BSS to DATA again.
         because we have to clear it anyway.  - Yinghai
    -v6: switch to init_level4_pgt in init_mem_mapping. - Yinghai
    -v7: remove not needed clear_page for init_level4_page
         it is with fill 512,8,0 already in head_64.S  - Yinghai
    -v8: we need to keep that handler alive until init_mem_mapping and don't
         let early_trap_init to trash that early #PF handler.
         So split early_trap_pf_init out and move it down. - Yinghai
    -v9: switchover only cover kernel space instead of 1G so could avoid
         touch possible mem holes. - Yinghai
    -v11: change far jmp back to far return to initial_code, that is needed
         to fix failure that is reported by Konrad on AMD systems.  - Yinghai
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-12-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 85a8290801df..db9c41dae8d7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1005,6 +1005,8 @@ void __init setup_arch(char **cmdline_p)
 
 	init_mem_mapping();
 
+	early_trap_pf_init();
+
 	setup_real_mode();
 
 	memblock.current_limit = get_max_mapped();

commit 4f7b92263ad68cdc72b11808320d9c881bfa857e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:19:51 2013 -0800

    x86, realmode: Separate real_mode reserve and setup
    
    After we switch to use #PF handler help to set page table, init_level4_pgt
    will only have entries set after init_mem_mapping().
    We need to move copying init_level4_pgt to trampoline_pgd after that.
    
    So split reserve and setup, and move the setup after init_mem_mapping()
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-11-git-send-email-yinghai@kernel.org
    Cc: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
    Acked-by: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5552d04b0cc1..85a8290801df 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -999,12 +999,14 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_DEBUG "initial memory mapped: [mem 0x00000000-%#010lx]\n",
 			(max_pfn_mapped<<PAGE_SHIFT) - 1);
 
-	setup_real_mode();
+	reserve_real_mode();
 
 	trim_platform_memory_ranges();
 
 	init_mem_mapping();
 
+	setup_real_mode();
+
 	memblock.current_limit = get_max_mapped();
 	dma_contiguous_reserve(0);
 

commit b422a3091748c38b68052e8ba021652590b1f25c
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 24 12:19:45 2013 -0800

    x86: Factor out e820_add_kernel_range()
    
    Separate out the reservation of the kernel static memory areas into a
    separate function.
    
    Also add support for case when memmap=xxM$yyM is used without exactmap.
    Need to remove reserved range at first before we add E820_RAM
    range, otherwise added E820_RAM range will be ignored.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1359058816-7615-5-git-send-email-yinghai@kernel.org
    Cc: Jacob Shin <jacob.shin@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 268193746cd8..5552d04b0cc1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -702,6 +702,27 @@ static void __init trim_bios_range(void)
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
 
+/* called before trim_bios_range() to spare extra sanitize */
+static void __init e820_add_kernel_range(void)
+{
+	u64 start = __pa_symbol(_text);
+	u64 size = __pa_symbol(_end) - start;
+
+	/*
+	 * Complain if .text .data and .bss are not marked as E820_RAM and
+	 * attempt to fix it by adding the range. We may have a confused BIOS,
+	 * or the user may have used memmap=exactmap or memmap=xxM$yyM to
+	 * exclude kernel range. If we really are running on top non-RAM,
+	 * we will crash later anyways.
+	 */
+	if (e820_all_mapped(start, start + size, E820_RAM))
+		return;
+
+	pr_warn(".text .data .bss are not marked as E820_RAM!\n");
+	e820_remove_range(start, size, E820_RAM, 0);
+	e820_add_region(start, size, E820_RAM);
+}
+
 static int __init parse_reservelow(char *p)
 {
 	unsigned long long size;
@@ -897,20 +918,7 @@ void __init setup_arch(char **cmdline_p)
 	insert_resource(&iomem_resource, &data_resource);
 	insert_resource(&iomem_resource, &bss_resource);
 
-	/*
-	 * Complain if .text .data and .bss are not marked as E820_RAM and
-	 * attempt to fix it by adding the range. We may have a confused BIOS,
-	 * or the user may have incorrectly supplied it via memmap=exactmap. If
-	 * we really are running on top non-RAM, we will crash later anyways.
-	 */
-	if (!e820_all_mapped(code_resource.start, __pa(__brk_limit), E820_RAM)) {
-		pr_warn(".text .data .bss are not marked as E820_RAM!\n");
-
-		e820_add_region(code_resource.start,
-				__pa(__brk_limit) - code_resource.start + 1,
-				E820_RAM);
-	}
-
+	e820_add_kernel_range();
 	trim_bios_range();
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {

commit de65d816aa44f9ddd79861ae21d75010cc1fd003
Merge: 9710f581bb4c 5dcd14ecd41e
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Tue Jan 29 14:59:09 2013 -0800

    Merge remote-tracking branch 'origin/x86/boot' into x86/mm2
    
    Coming patches to x86/mm2 require the changes and advanced baseline in
    x86/boot.
    
    Resolved Conflicts:
            arch/x86/kernel/setup.c
            mm/nobootmem.c
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit 7b5c4a65cc27f017c170b025f8d6d75dabb11c6f
Merge: 3596f5bb0a6a 949db153b646
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Jan 25 16:31:21 2013 -0800

    Merge tag 'v3.8-rc5' into x86/mm
    
    The __pa() fixup series that follows touches KVM code that is not
    present in the existing branch based on v3.7-rc5, so merge in the
    current upstream from Linus.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit e43b3cec711a61edf047adf6204d542f3a659ef8
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Sun Jan 13 20:56:41 2013 -0800

    x86/Sandy Bridge: Sandy Bridge workaround depends on CONFIG_PCI
    
    early_pci_allowed() and read_pci_config_16() are only available if
    CONFIG_PCI is defined.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 18182d19b71b..00f6c1472b85 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -612,6 +612,7 @@ static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
 
 static bool __init snb_gfx_workaround_needed(void)
 {
+#ifdef CONFIG_PCI
 	int i;
 	u16 vendor, devid;
 	static const __initconst u16 snb_ids[] = {
@@ -636,6 +637,7 @@ static bool __init snb_gfx_workaround_needed(void)
 	for (i = 0; i < ARRAY_SIZE(snb_ids); i++)
 		if (devid == snb_ids[i])
 			return true;
+#endif
 
 	return false;
 }

commit ab3cd8670e0b3fcde7f029e1503ed3c5138e9571
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Sun Jan 13 20:36:39 2013 -0800

    x86/Sandy Bridge: mark arrays in __init functions as __initconst
    
    Mark static arrays as __initconst so they get removed when the init
    sections are flushed.
    
    Reported-by: Mathias Krause <minipli@googlemail.com>
    Link: http://lkml.kernel.org/r/75F4BEE6-CB0E-4426-B40B-697451677738@googlemail.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9dcb32545032..18182d19b71b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -614,7 +614,7 @@ static bool __init snb_gfx_workaround_needed(void)
 {
 	int i;
 	u16 vendor, devid;
-	static const u16 snb_ids[] = {
+	static const __initconst u16 snb_ids[] = {
 		0x0102,
 		0x0112,
 		0x0122,
@@ -646,7 +646,7 @@ static bool __init snb_gfx_workaround_needed(void)
  */
 static void __init trim_snb_memory(void)
 {
-	static const unsigned long bad_pages[] = {
+	static const __initconst unsigned long bad_pages[] = {
 		0x20050000,
 		0x20110000,
 		0x20130000,

commit a9acc5365dbda29f7be2884efb63771dc24bd815
Author: Jesse Barnes <jbarnes@virtuousgeek.org>
Date:   Wed Nov 14 20:43:31 2012 +0000

    x86/Sandy Bridge: reserve pages when integrated graphics is present
    
    SNB graphics devices have a bug that prevent them from accessing certain
    memory ranges, namely anything below 1M and in the pages listed in the
    table.  So reserve those at boot if set detect a SNB gfx device on the
    CPU to avoid GPU hangs.
    
    Stephane Marchesin had a similar patch to the page allocator awhile
    back, but rather than reserving pages up front, it leaked them at
    allocation time.
    
    [ hpa: made a number of stylistic changes, marked arrays as static
      const, and made less verbose; use "memblock=debug" for full
      verbosity. ]
    
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 23ddd558fbd5..9dcb32545032 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -610,6 +610,81 @@ static __init void reserve_ibft_region(void)
 
 static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
 
+static bool __init snb_gfx_workaround_needed(void)
+{
+	int i;
+	u16 vendor, devid;
+	static const u16 snb_ids[] = {
+		0x0102,
+		0x0112,
+		0x0122,
+		0x0106,
+		0x0116,
+		0x0126,
+		0x010a,
+	};
+
+	/* Assume no if something weird is going on with PCI */
+	if (!early_pci_allowed())
+		return false;
+
+	vendor = read_pci_config_16(0, 2, 0, PCI_VENDOR_ID);
+	if (vendor != 0x8086)
+		return false;
+
+	devid = read_pci_config_16(0, 2, 0, PCI_DEVICE_ID);
+	for (i = 0; i < ARRAY_SIZE(snb_ids); i++)
+		if (devid == snb_ids[i])
+			return true;
+
+	return false;
+}
+
+/*
+ * Sandy Bridge graphics has trouble with certain ranges, exclude
+ * them from allocation.
+ */
+static void __init trim_snb_memory(void)
+{
+	static const unsigned long bad_pages[] = {
+		0x20050000,
+		0x20110000,
+		0x20130000,
+		0x20138000,
+		0x40004000,
+	};
+	int i;
+
+	if (!snb_gfx_workaround_needed())
+		return;
+
+	printk(KERN_DEBUG "reserving inaccessible SNB gfx pages\n");
+
+	/*
+	 * Reserve all memory below the 1 MB mark that has not
+	 * already been reserved.
+	 */
+	memblock_reserve(0, 1<<20);
+	
+	for (i = 0; i < ARRAY_SIZE(bad_pages); i++) {
+		if (memblock_reserve(bad_pages[i], PAGE_SIZE))
+			printk(KERN_WARNING "failed to reserve 0x%08lx\n",
+			       bad_pages[i]);
+	}
+}
+
+/*
+ * Here we put platform-specific memory range workarounds, i.e.
+ * memory known to be corrupt or otherwise in need to be reserved on
+ * specific platforms.
+ *
+ * If this gets used more widely it could use a real dispatch mechanism.
+ */
+static void __init trim_platform_memory_ranges(void)
+{
+	trim_snb_memory();
+}
+
 static void __init trim_bios_range(void)
 {
 	/*
@@ -630,6 +705,7 @@ static void __init trim_bios_range(void)
 	 * take them out.
 	 */
 	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
+
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
 
@@ -908,6 +984,8 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_real_mode();
 
+	trim_platform_memory_ranges();
+
 	init_gbpages();
 
 	/* max_pfn_mapped is updated here */

commit 18dd0bf22b6f0c1bd5e4e813a42245ed86ec57b6
Merge: 2d9c8b5d6a5f 385ddeac7ed9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 14 10:03:23 2012 -0800

    Merge branch 'x86-acpi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 ACPI update from Peter Anvin:
     "This is a patchset which didn't make the last merge window.  It adds a
      debugging capability to feed ACPI tables via the initramfs.
    
      On a grander scope, it formalizes using the initramfs protocol for
      feeding arbitrary blobs which need to be accessed early to the kernel:
      they are fed first in the initramfs blob (lots of bootloaders can
      concatenate this at boot time, others can use a single file) in an
      uncompressed cpio archive using filenames starting with "kernel/".
    
      The ACPI maintainers requested that this patchset be fed via the x86
      tree rather than the ACPI tree as the footprint in the general x86
      code is much bigger than in the ACPI code proper."
    
    * 'x86-acpi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      X86 ACPI: Use #ifdef not #if for CONFIG_X86 check
      ACPI: Fix build when disabled
      ACPI: Document ACPI table overriding via initrd
      ACPI: Create acpi_table_taint() function to avoid code duplication
      ACPI: Implement physical address table override
      ACPI: Store valid ACPI tables passed via early initrd in reserved memblock areas
      x86, acpi: Introduce x86 arch specific arch_reserve_mem_area() for e820 handling
      lib: Add early cpio decoder

commit f9a37be0f02a943d63e3346b19f9c9d8d91826cb
Author: Matthew Garrett <mjg@redhat.com>
Date:   Wed Dec 5 14:33:27 2012 -0700

    x86: Use PCI setup data
    
    EFI can provide PCI ROMs out of band via boot services, which may not be
    available after boot. Add support for using the data handed off to us by
    the boot stub or bootloader.
    
    [bhelgaas: added Seth's boot_params section mismatch fix]
    [bhelgaas: drop "boot_params.hdr.version < 0x0209" test]
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Tested-by: Seth Forshee <seth.forshee@canonical.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ca45696f30fb..c228322ca180 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -143,11 +143,7 @@ int default_check_phys_apicid_present(int phys_apicid)
 }
 #endif
 
-#ifndef CONFIG_DEBUG_BOOT_PARAMS
-struct boot_params __initdata boot_params;
-#else
 struct boot_params boot_params;
-#endif
 
 /*
  * Machine setup..

commit c074eaac2ab264c94520efff7e896b771de885ae
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:39:20 2012 -0800

    x86, mm: kill numa_64.h
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-44-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 85b62f1c8071..6d29d1fcf068 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -108,9 +108,6 @@
 #include <asm/topology.h>
 #include <asm/apicdef.h>
 #include <asm/amd_nb.h>
-#ifdef CONFIG_X86_64
-#include <asm/numa_64.h>
-#endif
 #include <asm/mce.h>
 #include <asm/alternative.h>
 #include <asm/prom.h>

commit 148b20989e0b83cb301e1fcd9e987c7abde05333
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:39:08 2012 -0800

    x86, mm: Move init_gbpages() out of setup.c
    
    Put it in mm/init.c, and call it from probe_page_mask().
    init_mem_mapping is calling probe_page_mask at first.
    So calling sequence is not changed.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-32-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 20151941cce8..85b62f1c8071 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -282,18 +282,7 @@ void * __init extend_brk(size_t size, size_t align)
 	return ret;
 }
 
-#ifdef CONFIG_X86_64
-static void __init init_gbpages(void)
-{
-	if (direct_gbpages && cpu_has_gbpages)
-		printk(KERN_INFO "Using GB pages for direct mapping\n");
-	else
-		direct_gbpages = 0;
-}
-#else
-static inline void init_gbpages(void)
-{
-}
+#ifdef CONFIG_X86_32
 static void __init cleanup_highmap(void)
 {
 }
@@ -933,8 +922,6 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_real_mode();
 
-	init_gbpages();
-
 	init_mem_mapping();
 
 	memblock.current_limit = get_max_mapped();

commit 9985b4c6fa7d660f685918a58282275e9e35d8e0
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:39:02 2012 -0800

    x86, mm: Move min_pfn_mapped back to mm/init.c
    
    Also change it to static.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-26-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f7634092931b..20151941cce8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -124,7 +124,6 @@
  */
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
-unsigned long min_pfn_mapped;
 
 #ifdef CONFIG_DMI
 RESERVE_BRK(dmi_alloc, 65536);

commit 8d57470d8f859635deffe3919d7d4867b488b85a
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:58 2012 -0800

    x86, mm: setup page table in top-down
    
    Get pgt_buf early from BRK, and use it to map PMD_SIZE from top at first.
    Then use mapped pages to map more ranges below, and keep looping until
    all pages get mapped.
    
    alloc_low_page will use page from BRK at first, after that buffer is used
    up, will use memblock to find and reserve pages for page table usage.
    
    Introduce min_pfn_mapped to make sure find new pages from mapped ranges,
    that will be updated when lower pages get mapped.
    
    Also add step_size to make sure that don't try to map too big range with
    limited mapped pages initially, and increase the step_size when we have
    more mapped pages on hand.
    
    We don't need to call pagetable_reserve anymore, reserve work is done
    in alloc_low_page() directly.
    
    At last we can get rid of calculation and find early pgt related code.
    
    -v2: update to after fix_xen change,
         also use MACRO for initial pgt_buf size and add comments with it.
    -v3: skip big reserved range in memblock.reserved near end.
    -v4: don't need fix_xen change now.
    -v5: add changelog about moving about reserving pagetable to alloc_low_page.
    
    Suggested-by: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-22-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 94f922a73c54..f7634092931b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -124,6 +124,7 @@
  */
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
+unsigned long min_pfn_mapped;
 
 #ifdef CONFIG_DMI
 RESERVE_BRK(dmi_alloc, 65536);
@@ -900,6 +901,8 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_ibft_region();
 
+	early_alloc_pgt_buf();
+
 	/*
 	 * Need to conclude brk, before memblock_x86_fill()
 	 *  it could use memblock_find_in_range, could overlap with

commit 74f27655dda84604d8bab47872020dcce5c88731
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:53 2012 -0800

    x86, mm: relocate initrd under all mem for 64bit
    
    instead of under 4g.
    
    For 64bit, we can use any mapped mem instead of low mem.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-17-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 68dffeceb193..94f922a73c54 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -324,7 +324,7 @@ static void __init relocate_initrd(void)
 	char *p, *q;
 
 	/* We need to move the initrd down into directly mapped mem */
-	ramdisk_here = memblock_find_in_range(0, PFN_PHYS(max_low_pfn_mapped),
+	ramdisk_here = memblock_find_in_range(0, PFN_PHYS(max_pfn_mapped),
 						 area_size, PAGE_SIZE);
 
 	if (!ramdisk_here)
@@ -392,7 +392,7 @@ static void __init reserve_initrd(void)
 
 	initrd_start = 0;
 
-	mapped_size = get_mem_size(max_low_pfn_mapped);
+	mapped_size = get_mem_size(max_pfn_mapped);
 	if (ramdisk_size >= (mapped_size>>1))
 		panic("initrd too large to handle, "
 		       "disabling initrd (%lld needed, %lld available)\n",
@@ -401,8 +401,7 @@ static void __init reserve_initrd(void)
 	printk(KERN_INFO "RAMDISK: [mem %#010llx-%#010llx]\n", ramdisk_image,
 			ramdisk_end - 1);
 
-	if (ramdisk_end <= (max_low_pfn_mapped<<PAGE_SHIFT) &&
-	    pfn_range_is_mapped(PFN_DOWN(ramdisk_image),
+	if (pfn_range_is_mapped(PFN_DOWN(ramdisk_image),
 				PFN_DOWN(ramdisk_end))) {
 		/* All are mapped, easy case */
 		/*

commit 66520ebc2df3fe52eb4792f8101fac573b766baf
Author: Jacob Shin <jacob.shin@amd.com>
Date:   Fri Nov 16 19:38:52 2012 -0800

    x86, mm: Only direct map addresses that are marked as E820_RAM
    
    Currently direct mappings are created for [ 0 to max_low_pfn<<PAGE_SHIFT )
    and [ 4GB to max_pfn<<PAGE_SHIFT ), which may include regions that are not
    backed by actual DRAM. This is fine for holes under 4GB which are covered
    by fixed and variable range MTRRs to be UC. However, we run into trouble
    on higher memory addresses which cannot be covered by MTRRs.
    
    Our system with 1TB of RAM has an e820 that looks like this:
    
     BIOS-e820: [mem 0x0000000000000000-0x00000000000983ff] usable
     BIOS-e820: [mem 0x0000000000098400-0x000000000009ffff] reserved
     BIOS-e820: [mem 0x00000000000d0000-0x00000000000fffff] reserved
     BIOS-e820: [mem 0x0000000000100000-0x00000000c7ebffff] usable
     BIOS-e820: [mem 0x00000000c7ec0000-0x00000000c7ed7fff] ACPI data
     BIOS-e820: [mem 0x00000000c7ed8000-0x00000000c7ed9fff] ACPI NVS
     BIOS-e820: [mem 0x00000000c7eda000-0x00000000c7ffffff] reserved
     BIOS-e820: [mem 0x00000000fec00000-0x00000000fec0ffff] reserved
     BIOS-e820: [mem 0x00000000fee00000-0x00000000fee00fff] reserved
     BIOS-e820: [mem 0x00000000fff00000-0x00000000ffffffff] reserved
     BIOS-e820: [mem 0x0000000100000000-0x000000e037ffffff] usable
     BIOS-e820: [mem 0x000000e038000000-0x000000fcffffffff] reserved
     BIOS-e820: [mem 0x0000010000000000-0x0000011ffeffffff] usable
    
    and so direct mappings are created for huge memory hole between
    0x000000e038000000 to 0x0000010000000000. Even though the kernel never
    generates memory accesses in that region, since the page tables mark
    them incorrectly as being WB, our (AMD) processor ends up causing a MCE
    while doing some memory bookkeeping/optimizations around that area.
    
    This patch iterates through e820 and only direct maps ranges that are
    marked as E820_RAM, and keeps track of those pfn ranges. Depending on
    the alignment of E820 ranges, this may possibly result in using smaller
    size (i.e. 4K instead of 2M or 1G) page tables.
    
    -v2: move changes from setup.c to mm/init.c, also use for_each_mem_pfn_range
            instead.  - Yinghai Lu
    -v3: add calculate_all_table_space_size() to get correct needed page table
            size. - Yinghai Lu
    -v4: fix add_pfn_range_mapped() to get correct max_low_pfn_mapped when
         mem map does have hole under 4g that is found by Konard on xen
         domU with 8g ram. - Yinghai
    
    Signed-off-by: Jacob Shin <jacob.shin@amd.com>
    Link: http://lkml.kernel.org/r/1353123563-3103-16-git-send-email-yinghai@kernel.org
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bd52f9da17cc..68dffeceb193 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -116,9 +116,11 @@
 #include <asm/prom.h>
 
 /*
- * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
- * The direct mapping extends to max_pfn_mapped, so that we can directly access
- * apertures, ACPI and other tables without having to play with fixmaps.
+ * max_low_pfn_mapped: highest direct mapped pfn under 4GB
+ * max_pfn_mapped:     highest direct mapped pfn over 4GB
+ *
+ * The direct mapping only covers E820_RAM regions, so the ranges and gaps are
+ * represented by pfn_mapped
  */
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;

commit e8c57d40519d7226acb8e662f3ab496202ebc7a6
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:51 2012 -0800

    x86, mm: use pfn_range_is_mapped() with reserve_initrd
    
    We are going to map ram only, so under max_low_pfn_mapped,
    between 4g and max_pfn_mapped does not mean mapped at all.
    
    Use pfn_range_is_mapped() to find out if range is mapped for initrd.
    
    That could happen bootloader put initrd in range but user could
    use memmap to carve some of range out.
    
    Also during copying need to use early_memmap to map original initrd
    for accessing.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-15-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d85cbd96525d..bd52f9da17cc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -317,20 +317,19 @@ static void __init relocate_initrd(void)
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
 	u64 area_size     = PAGE_ALIGN(ramdisk_size);
-	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
 	u64 ramdisk_here;
 	unsigned long slop, clen, mapaddr;
 	char *p, *q;
 
-	/* We need to move the initrd down into lowmem */
-	ramdisk_here = memblock_find_in_range(0, end_of_lowmem, area_size,
-					 PAGE_SIZE);
+	/* We need to move the initrd down into directly mapped mem */
+	ramdisk_here = memblock_find_in_range(0, PFN_PHYS(max_low_pfn_mapped),
+						 area_size, PAGE_SIZE);
 
 	if (!ramdisk_here)
 		panic("Cannot find place for new RAMDISK of size %lld\n",
 			 ramdisk_size);
 
-	/* Note: this includes all the lowmem currently occupied by
+	/* Note: this includes all the mem currently occupied by
 	   the initrd, we rely on that fact to keep the data intact. */
 	memblock_reserve(ramdisk_here, area_size);
 	initrd_start = ramdisk_here + PAGE_OFFSET;
@@ -340,17 +339,7 @@ static void __init relocate_initrd(void)
 
 	q = (char *)initrd_start;
 
-	/* Copy any lowmem portion of the initrd */
-	if (ramdisk_image < end_of_lowmem) {
-		clen = end_of_lowmem - ramdisk_image;
-		p = (char *)__va(ramdisk_image);
-		memcpy(q, p, clen);
-		q += clen;
-		ramdisk_image += clen;
-		ramdisk_size  -= clen;
-	}
-
-	/* Copy the highmem portion of the initrd */
+	/* Copy the initrd */
 	while (ramdisk_size) {
 		slop = ramdisk_image & ~PAGE_MASK;
 		clen = ramdisk_size;
@@ -364,7 +353,7 @@ static void __init relocate_initrd(void)
 		ramdisk_image += clen;
 		ramdisk_size  -= clen;
 	}
-	/* high pages is not converted by early_res_to_bootmem */
+
 	ramdisk_image = boot_params.hdr.ramdisk_image;
 	ramdisk_size  = boot_params.hdr.ramdisk_size;
 	printk(KERN_INFO "Move RAMDISK from [mem %#010llx-%#010llx] to"
@@ -373,13 +362,27 @@ static void __init relocate_initrd(void)
 		ramdisk_here, ramdisk_here + ramdisk_size - 1);
 }
 
+static u64 __init get_mem_size(unsigned long limit_pfn)
+{
+	int i;
+	u64 mapped_pages = 0;
+	unsigned long start_pfn, end_pfn;
+
+	for_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, NULL) {
+		start_pfn = min_t(unsigned long, start_pfn, limit_pfn);
+		end_pfn = min_t(unsigned long, end_pfn, limit_pfn);
+		mapped_pages += end_pfn - start_pfn;
+	}
+
+	return mapped_pages << PAGE_SHIFT;
+}
 static void __init reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
 	u64 ramdisk_end   = PAGE_ALIGN(ramdisk_image + ramdisk_size);
-	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
+	u64 mapped_size;
 
 	if (!boot_params.hdr.type_of_loader ||
 	    !ramdisk_image || !ramdisk_size)
@@ -387,18 +390,19 @@ static void __init reserve_initrd(void)
 
 	initrd_start = 0;
 
-	if (ramdisk_size >= (end_of_lowmem>>1)) {
+	mapped_size = get_mem_size(max_low_pfn_mapped);
+	if (ramdisk_size >= (mapped_size>>1))
 		panic("initrd too large to handle, "
 		       "disabling initrd (%lld needed, %lld available)\n",
-		       ramdisk_size, end_of_lowmem>>1);
-	}
+		       ramdisk_size, mapped_size>>1);
 
 	printk(KERN_INFO "RAMDISK: [mem %#010llx-%#010llx]\n", ramdisk_image,
 			ramdisk_end - 1);
 
-
-	if (ramdisk_end <= end_of_lowmem) {
-		/* All in lowmem, easy case */
+	if (ramdisk_end <= (max_low_pfn_mapped<<PAGE_SHIFT) &&
+	    pfn_range_is_mapped(PFN_DOWN(ramdisk_image),
+				PFN_DOWN(ramdisk_end))) {
+		/* All are mapped, easy case */
 		/*
 		 * don't need to reserve again, already reserved early
 		 * in i386_start_kernel

commit 4eea6aa581abfeb2695ebe9f9d4672597e1bdd4b
Author: Jacob Shin <jacob.shin@amd.com>
Date:   Fri Nov 16 19:38:47 2012 -0800

    x86, mm: if kernel .text .data .bss are not marked as E820_RAM, complain and fix
    
    There could be cases where user supplied memmap=exactmap memory
    mappings do not mark the region where the kernel .text .data and
    .bss reside as E820_RAM, as reported here:
    
    https://lkml.org/lkml/2012/8/14/86
    
    Handle it by complaining, and adding the range back into the e820.
    
    Signed-off-by: Jacob Shin <jacob.shin@amd.com>
    Link: http://lkml.kernel.org/r/1353123563-3103-11-git-send-email-yinghai@kernel.org
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4bd89218cbc3..d85cbd96525d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -832,6 +832,20 @@ void __init setup_arch(char **cmdline_p)
 	insert_resource(&iomem_resource, &data_resource);
 	insert_resource(&iomem_resource, &bss_resource);
 
+	/*
+	 * Complain if .text .data and .bss are not marked as E820_RAM and
+	 * attempt to fix it by adding the range. We may have a confused BIOS,
+	 * or the user may have incorrectly supplied it via memmap=exactmap. If
+	 * we really are running on top non-RAM, we will crash later anyways.
+	 */
+	if (!e820_all_mapped(code_resource.start, __pa(__brk_limit), E820_RAM)) {
+		pr_warn(".text .data .bss are not marked as E820_RAM!\n");
+
+		e820_add_region(code_resource.start,
+				__pa(__brk_limit) - code_resource.start + 1,
+				E820_RAM);
+	}
+
 	trim_bios_range();
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {

commit dd7dfad7fb297b1746bcdbebbdc970d723a635bd
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:46 2012 -0800

    x86, mm: Set memblock initial limit to 1M
    
    memblock_x86_fill() could double memory array.
    If we set memblock.current_limit to 512M, so memory array could be around 512M.
    So kdump will not get big range (like 512M) under 1024M.
    
    Try to put it down under 1M, it would use about 4k or so, and that is limited.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-10-git-send-email-yinghai@kernel.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 23b079fb93fc..4bd89218cbc3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -890,7 +890,7 @@ void __init setup_arch(char **cmdline_p)
 
 	cleanup_highmap();
 
-	memblock.current_limit = get_max_mapped();
+	memblock.current_limit = ISA_END_ADDRESS;
 	memblock_x86_fill();
 
 	/*

commit 22ddfcaa0dbae992332381d41b8a1fbc72269a13
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:41 2012 -0800

    x86, mm: Move init_memory_mapping calling out of setup.c
    
    Now init_memory_mapping is called two times, later will be called for every
    ram ranges.
    
    Could put all related init_mem calling together and out of setup.c.
    
    Actually, it reverts commit 1bbbbe7
        x86: Exclude E820_RESERVED regions and memory holes above 4 GB from direct mapping.
    will address that later with complete solution include handling hole under 4g.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-5-git-send-email-yinghai@kernel.org
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 01fb5f9baf90..23b079fb93fc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -913,34 +913,9 @@ void __init setup_arch(char **cmdline_p)
 	setup_real_mode();
 
 	init_gbpages();
-	probe_page_size_mask();
 
-	/* max_pfn_mapped is updated here */
-	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
-	max_pfn_mapped = max_low_pfn_mapped;
+	init_mem_mapping();
 
-#ifdef CONFIG_X86_64
-	if (max_pfn > max_low_pfn) {
-		int i;
-		unsigned long start, end;
-		unsigned long start_pfn, end_pfn;
-
-		for_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn,
-							 NULL) {
-
-			end = PFN_PHYS(end_pfn);
-			if (end <= (1UL<<32))
-				continue;
-
-			start = PFN_PHYS(start_pfn);
-			max_pfn_mapped = init_memory_mapping(
-						max((1UL<<32), start), end);
-		}
-
-		/* can we preseve max_low_pfn ?*/
-		max_low_pfn = max_pfn;
-	}
-#endif
 	memblock.current_limit = get_max_mapped();
 	dma_contiguous_reserve(0);
 

commit fa62aafea9e415cd1efd8c4054106112fe809f19
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Nov 16 19:38:38 2012 -0800

    x86, mm: Add global page_size_mask and probe one time only
    
    Now we pass around use_gbpages and use_pse for calculating page table size,
    Later we will need to call init_memory_mapping for every ram range one by one,
    that mean those calculation will be done several times.
    
    Those information are the same for all ram range and could be stored in
    page_size_mask and could be probed it one time only.
    
    Move that probing code out of init_memory_mapping into separated function
    probe_page_size_mask(), and call it before all init_memory_mapping.
    
    Suggested-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/1353123563-3103-2-git-send-email-yinghai@kernel.org
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ca45696f30fb..01fb5f9baf90 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -913,6 +913,7 @@ void __init setup_arch(char **cmdline_p)
 	setup_real_mode();
 
 	init_gbpages();
+	probe_page_size_mask();
 
 	/* max_pfn_mapped is updated here */
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);

commit fc8d782677f163dee76427fdd8a92bebd2b50b23
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Nov 16 13:57:13 2012 -0800

    x86: Use __pa_symbol instead of __pa on C visible symbols
    
    When I made an attempt at separating __pa_symbol and __pa I found that there
    were a number of cases where __pa was used on an obvious symbol.
    
    I also caught one non-obvious case as _brk_start and _brk_end are based on the
    address of __brk_base which is a C visible symbol.
    
    In mark_rodata_ro I was able to reduce the overhead of kernel symbol to
    virtual memory translation by using a combination of __va(__pa_symbol())
    instead of page_address(virt_to_page()).
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Link: http://lkml.kernel.org/r/20121116215640.8521.80483.stgit@ahduyck-cp1.jf.intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ca45696f30fb..2702c5d4acd2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -300,8 +300,8 @@ static void __init cleanup_highmap(void)
 static void __init reserve_brk(void)
 {
 	if (_brk_end > _brk_start)
-		memblock_reserve(__pa(_brk_start),
-				 __pa(_brk_end) - __pa(_brk_start));
+		memblock_reserve(__pa_symbol(_brk_start),
+				 _brk_end - _brk_start);
 
 	/* Mark brk area as locked down and no longer taking any
 	   new allocations */
@@ -761,12 +761,12 @@ void __init setup_arch(char **cmdline_p)
 	init_mm.end_data = (unsigned long) _edata;
 	init_mm.brk = _brk_end;
 
-	code_resource.start = virt_to_phys(_text);
-	code_resource.end = virt_to_phys(_etext)-1;
-	data_resource.start = virt_to_phys(_etext);
-	data_resource.end = virt_to_phys(_edata)-1;
-	bss_resource.start = virt_to_phys(&__bss_start);
-	bss_resource.end = virt_to_phys(&__bss_stop)-1;
+	code_resource.start = __pa_symbol(_text);
+	code_resource.end = __pa_symbol(_etext)-1;
+	data_resource.start = __pa_symbol(_etext);
+	data_resource.end = __pa_symbol(_edata)-1;
+	bss_resource.start = __pa_symbol(__bss_start);
+	bss_resource.end = __pa_symbol(__bss_stop)-1;
 
 #ifdef CONFIG_CMDLINE_BOOL
 #ifdef CONFIG_CMDLINE_OVERRIDE

commit 8b724e2a12d553cad8ad412846511c783a92d25e
Merge: f82f64dd9f48 5189c2a7c776
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Oct 26 10:17:38 2012 +0200

    Merge tag 'efi-for-3.7' of git://git.kernel.org/pub/scm/linux/kernel/git/mfleming/efi into x86/urgent
    
    Pull EFI fixes from Matt Fleming:
    
     "Fix oops with EFI variables on mixed 32/64-bit firmware/kernels and
      document EFI git repository location on kernel.org."
    
    Conflicts:
            arch/x86/include/asm/efi.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 5189c2a7c7769ee9d037d76c1a7b8550ccf3481c
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Oct 24 10:00:44 2012 -0700

    x86: efi: Turn off efi_enabled after setup on mixed fw/kernel
    
    When 32-bit EFI is used with 64-bit kernel (or vice versa), turn off
    efi_enabled once setup is done. Beyond setup, it is normally used to
    determine if runtime services are available and we will have none.
    
    This will resolve issues stemming from efivars modprobe panicking on a
    32/64-bit setup, as well as some reboot issues on similar setups.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=45991
    
    Reported-by: Marko Kohtala <marko.kohtala@gmail.com>
    Reported-by: Maxim Kammerer <mk@dee.su>
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Acked-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Cc: stable@kernel.org # 3.4 - 3.6
    Cc: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a2bb18e02839..6fd7752cee96 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1035,6 +1035,18 @@ void __init setup_arch(char **cmdline_p)
 	arch_init_ideal_nops();
 
 	register_refined_jiffies(CLOCK_TICK_RATE);
+
+#ifdef CONFIG_EFI
+	/* Once setup is done above, disable efi_enabled on mismatched
+	 * firmware/kernel archtectures since there is no support for
+	 * runtime services.
+	 */
+	if (efi_enabled && IS_ENABLED(CONFIG_X86_64) != efi_64bit) {
+		pr_info("efi: Setup done, disabling due to 32/64-bit mismatch\n");
+		efi_unmap_memmap();
+		efi_enabled = 0;
+	}
+#endif
 }
 
 #ifdef CONFIG_X86_32

commit 1f2ff682ac951ed82cc043cf140d2851084512df
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Oct 22 16:35:18 2012 -0700

    x86, mm: Use memblock memory loop instead of e820_RAM
    
    We need to handle E820_RAM and E820_RESERVED_KERNEL at the same time.
    
    Also memblock has page aligned range for ram, so we could avoid mapping
    partial pages.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/CAE9FiQVZirvaBMFYRfXMmWEcHbKSicQEHz4VAwUv0xFCk51ZNw@mail.gmail.com
    Acked-by: Jacob Shin <jacob.shin@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: <stable@vger.kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 468e98dfd44e..5d888af8682a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -921,18 +921,19 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_64
 	if (max_pfn > max_low_pfn) {
 		int i;
-		for (i = 0; i < e820.nr_map; i++) {
-			struct e820entry *ei = &e820.map[i];
+		unsigned long start, end;
+		unsigned long start_pfn, end_pfn;
 
-			if (ei->addr + ei->size <= 1UL << 32)
-				continue;
+		for_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn,
+							 NULL) {
 
-			if (ei->type == E820_RESERVED)
+			end = PFN_PHYS(end_pfn);
+			if (end <= (1UL<<32))
 				continue;
 
+			start = PFN_PHYS(start_pfn);
 			max_pfn_mapped = init_memory_mapping(
-				ei->addr < 1UL << 32 ? 1UL << 32 : ei->addr,
-				ei->addr + ei->size);
+						max((1UL<<32), start), end);
 		}
 
 		/* can we preseve max_low_pfn ?*/

commit 4533d86270d7986e00594495dde9a109d6be27ae
Merge: 21c5e50e15b1 5bc66170dc48
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Oct 19 07:54:24 2012 -0700

    Merge commit '5bc66170dc486556a1e36fd384463536573f4b82' into x86/urgent
    
    From Borislav Petkov <bp@amd64.org>:
    
    Below is a RAS fix which reverts the addition of a sysfs attribute
    which we agreed is not needed, post-factum. And this should go in now
    because that sysfs attribute is going to end up in 3.7 otherwise and
    thus exposed to userspace; removing it then would be a lot harder.
    
    This is done as a merge rather than a simple patch/cherry-pick since
    the baseline for this patch was not in the previous x86/urgent.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit 1bbbbe779aabe1f0768c2bf8f8c0a5583679b54a
Author: Jacob Shin <jacob.shin@amd.com>
Date:   Thu Oct 20 16:15:26 2011 -0500

    x86: Exclude E820_RESERVED regions and memory holes above 4 GB from direct mapping.
    
    On systems with very large memory (1 TB in our case), BIOS may report a
    reserved region or a hole in the E820 map, even above the 4 GB range. Exclude
    these from the direct mapping.
    
    [ hpa: this should be done not just for > 4 GB but for everything above the legacy
      region (1 MB), at the very least.  That, however, turns out to require significant
      restructuring.  That work is well underway, but is not suitable for rc/stable. ]
    
    Cc: stable@kernel.org   # > 2.6.32
    Signed-off-by: Jacob Shin <jacob.shin@amd.com>
    Link: http://lkml.kernel.org/r/1319145326-13902-1-git-send-email-jacob.shin@amd.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f4b9b80e1b95..198e774498ec 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -919,8 +919,21 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_64
 	if (max_pfn > max_low_pfn) {
-		max_pfn_mapped = init_memory_mapping(1UL<<32,
-						     max_pfn<<PAGE_SHIFT);
+		int i;
+		for (i = 0; i < e820.nr_map; i++) {
+			struct e820entry *ei = &e820.map[i];
+
+			if (ei->addr + ei->size <= 1UL << 32)
+				continue;
+
+			if (ei->type == E820_RESERVED)
+				continue;
+
+			max_pfn_mapped = init_memory_mapping(
+				ei->addr < 1UL << 32 ? 1UL << 32 : ei->addr,
+				ei->addr + ei->size);
+		}
+
 		/* can we preseve max_low_pfn ?*/
 		max_low_pfn = max_pfn;
 	}

commit 03d3602a833715f83ea53b9feb078b9c4c5f6c1a
Merge: 0588f1f93479 5b3900cd4094
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 12 22:17:48 2012 +0900

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer core update from Thomas Gleixner:
     - Bug fixes (one for a longstanding dead loop issue)
     - Rework of time related vsyscalls
     - Alarm timer updates
     - Jiffies updates to remove compile time dependencies
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      timekeeping: Cast raw_interval to u64 to avoid shift overflow
      timers: Fix endless looping between cascade() and internal_add_timer()
      time/jiffies: bring back unconditional LATCH definition
      time: Convert x86_64 to using new update_vsyscall
      time: Only do nanosecond rounding on GENERIC_TIME_VSYSCALL_OLD systems
      time: Introduce new GENERIC_TIME_VSYSCALL
      time: Convert CONFIG_GENERIC_TIME_VSYSCALL to CONFIG_GENERIC_TIME_VSYSCALL_OLD
      time: Move update_vsyscall definitions to timekeeper_internal.h
      time: Move timekeeper structure to timekeeper_internal.h for vsyscall changes
      jiffies: Remove compile time assumptions about CLOCK_TICK_RATE
      jiffies: Kill unused TICK_USEC_TO_NSEC
      alarmtimer: Rename alarmtimer_remove to alarmtimer_dequeue
      alarmtimer: Remove unused helpers & defines
      alarmtimer: Use hrtimer per-alarm instead of per-base
      alarmtimer: Implement minimum alarm interval for allowing suspend

commit ecefbd94b834fa32559d854646d777c56749ef1c
Merge: ce57e981f2b9 3d11df7abbff
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 4 09:30:33 2012 -0700

    Merge tag 'kvm-3.7-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Avi Kivity:
     "Highlights of the changes for this release include support for vfio
      level triggered interrupts, improved big real mode support on older
      Intels, a streamlines guest page table walker, guest APIC speedups,
      PIO optimizations, better overcommit handling, and read-only memory."
    
    * tag 'kvm-3.7-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (138 commits)
      KVM: s390: Fix vcpu_load handling in interrupt code
      KVM: x86: Fix guest debug across vcpu INIT reset
      KVM: Add resampling irqfds for level triggered interrupts
      KVM: optimize apic interrupt delivery
      KVM: MMU: Eliminate pointless temporary 'ac'
      KVM: MMU: Avoid access/dirty update loop if all is well
      KVM: MMU: Eliminate eperm temporary
      KVM: MMU: Optimize is_last_gpte()
      KVM: MMU: Simplify walk_addr_generic() loop
      KVM: MMU: Optimize pte permission checks
      KVM: MMU: Update accessed and dirty bits after guest pagetable walk
      KVM: MMU: Move gpte_access() out of paging_tmpl.h
      KVM: MMU: Optimize gpte_access() slightly
      KVM: MMU: Push clean gpte write protection out of gpte_access()
      KVM: clarify kvmclock documentation
      KVM: make processes waiting on vcpu mutex killable
      KVM: SVM: Make use of asm.h
      KVM: VMX: Make use of asm.h
      KVM: VMX: Make lto-friendly
      KVM: x86: lapic: Clean up find_highest_vector() and count_vectors()
      ...
    
    Conflicts:
            arch/s390/include/asm/processor.h
            arch/x86/kvm/i8259.c

commit 3dfd8235002727dbd759bb0f80f8ac862f392071
Author: David Rientjes <rientjes@google.com>
Date:   Mon Oct 1 20:38:47 2012 -0700

    ACPI: Fix build when disabled
    
    "ACPI: Store valid ACPI tables passed via early initrd in reserved
    memblock areas" breaks the build if either CONFIG_ACPI or
    CONFIG_BLK_DEV_INITRD is disabled:
    
    arch/x86/kernel/setup.c: In function 'setup_arch':
    arch/x86/kernel/setup.c:944: error: implicit declaration of function 'acpi_initrd_override'
    
    or
    
    arch/x86/built-in.o: In function `setup_arch':
    (.init.text+0x1397): undefined reference to `initrd_start'
    arch/x86/built-in.o: In function `setup_arch':
    (.init.text+0x139e): undefined reference to `initrd_end'
    
    The dummy acpi_initrd_override() function in acpi.h isn't defined without
    CONFIG_ACPI and initrd_{start,end} are declared but not defined without
    CONFIG_BLK_DEV_INITRD.
    
    [ hpa: applying this as a fix, but this really should be done cleaner ]
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.00.1210012032470.31644@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Thomas Renninger <trenn@suse.de>
    Cc: Len Brown <lenb@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 764e543b2297..bf82c1e05464 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -941,7 +941,9 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
+#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)
 	acpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);
+#endif
 
 	reserve_crashkernel();
 

commit 53aac44c904abbad9f474f652f099de13b5c3563
Author: Thomas Renninger <trenn@suse.de>
Date:   Mon Oct 1 00:23:54 2012 +0200

    ACPI: Store valid ACPI tables passed via early initrd in reserved memblock areas
    
    A later patch will compare them with ACPI tables that get loaded at boot or
    runtime and if criteria match, a stored one is loaded.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Link: http://lkml.kernel.org/r/1349043837-22659-4-git-send-email-trenn@suse.de
    Cc: Len Brown <lenb@kernel.org>
    Cc: Robert Moore <robert.moore@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Eric Piel <eric.piel@tremplin-utc.net>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f4b9b80e1b95..764e543b2297 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -941,6 +941,8 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
+	acpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);
+
 	reserve_crashkernel();
 
 	vsmp_init();

commit b3c869d35b9b014f63ac0beacd31c57372084d01
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 12:42:27 2012 -0400

    jiffies: Remove compile time assumptions about CLOCK_TICK_RATE
    
    CLOCK_TICK_RATE is used to accurately caclulate exactly how
    a tick will be at a given HZ.
    
    This is useful, because while we'd expect NSEC_PER_SEC/HZ,
    the underlying hardware will have some granularity limit,
    so we won't be able to have exactly HZ ticks per second.
    
    This slight error can cause timekeeping quality problems
    when using the jiffies or other jiffies driven clocksources.
    Thus we currently use compile time CLOCK_TICK_RATE value to
    generate SHIFTED_HZ and NSEC_PER_JIFFIES, which we then use
    to adjust the jiffies clocksource to correct this error.
    
    Unfortunately though, since CLOCK_TICK_RATE is a compile
    time value, and the jiffies clocksource is registered very
    early during boot, there are a number of cases where there
    are different possible hardware timers that have different
    tick rates. This causes problems in cases like ARM where
    there are numerous different types of hardware, each having
    their own compile-time CLOCK_TICK_RATE, making it hard to
    accurately support different hardware with a single kernel.
    
    For the most part, this doesn't matter all that much, as not
    too many systems actually utilize the jiffies or jiffies driven
    clocksource. Usually there are other highres clocksources
    who's granularity error is negligable.
    
    Even so, we have some complicated calcualtions that we do
    everywhere to handle these edge cases.
    
    This patch removes the compile time SHIFTED_HZ value, and
    introduces a register_refined_jiffies() function. This results
    in the default jiffies clock as being assumed a perfect HZ
    freq, and allows archtectures that care about jiffies accuracy
    to call register_refined_jiffies() with the tick rate, specified
    dynamically at boot.
    
    This allows us, where necessary, to not have a compile time
    CLOCK_TICK_RATE constant, simplifies the jiffies code, and
    still provides a way to have an accurate jiffies clock.
    
    NOTE: Since this patch does not add register_refinied_jiffies()
    calls for every arch, it may cause time quality regressions
    in some cases. Its likely these will not be noticable, but
    if they are an issue, adding the following to the end of
    setup_arch() should resolve the regression:
            register_refinied_jiffies(CLOCK_TICK_RATE)
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f4b9b80e1b95..4062f15bfbdd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -68,6 +68,7 @@
 #include <linux/percpu.h>
 #include <linux/crash_dump.h>
 #include <linux/tboot.h>
+#include <linux/jiffies.h>
 
 #include <video/edid.h>
 
@@ -1034,6 +1035,8 @@ void __init setup_arch(char **cmdline_p)
 	mcheck_init();
 
 	arch_init_ideal_nops();
+
+	register_refined_jiffies(CLOCK_TICK_RATE);
 }
 
 #ifdef CONFIG_X86_32

commit c711288727a62f74d48032e56e51333dd104bf58
Author: Attilio Rao <attilio.rao@citrix.com>
Date:   Tue Aug 21 21:22:40 2012 +0100

    x86: xen: Cleanup and remove x86_init.paging.pagetable_setup_done()
    
    At this stage x86_init.paging.pagetable_setup_done is only used in the
    XEN case. Move its content in the x86_init.paging.pagetable_init setup
    function and remove the now unused x86_init.paging.pagetable_setup_done
    remaining infrastructure.
    
    Signed-off-by: Attilio Rao <attilio.rao@citrix.com>
    Acked-by: <konrad.wilk@oracle.com>
    Cc: <Ian.Campbell@citrix.com>
    Cc: <Stefano.Stabellini@eu.citrix.com>
    Cc: <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/1345580561-8506-5-git-send-email-attilio.rao@citrix.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 315fd24131ed..4f165479c453 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -962,7 +962,6 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	x86_init.paging.pagetable_init();
-	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
 	if (boot_cpu_data.cpuid_level >= 0) {
 		/* A CPU has %cr4 if and only if it has CPUID */

commit 843b8ed2ec598aae5e3516b21957ede62a070e36
Author: Attilio Rao <attilio.rao@citrix.com>
Date:   Tue Aug 21 21:22:39 2012 +0100

    x86: Move paging_init() call to x86_init.paging.pagetable_init()
    
    Move the paging_init() call to the platform specific pagetable_init()
    function, so we can get rid of the extra pagetable_setup_done()
    function pointer.
    
    Signed-off-by: Attilio Rao <attilio.rao@citrix.com>
    Acked-by: <konrad.wilk@oracle.com>
    Cc: <Ian.Campbell@citrix.com>
    Cc: <Stefano.Stabellini@eu.citrix.com>
    Cc: <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/1345580561-8506-4-git-send-email-attilio.rao@citrix.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 61b7d9827afb..315fd24131ed 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -962,7 +962,6 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	x86_init.paging.pagetable_init();
-	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
 	if (boot_cpu_data.cpuid_level >= 0) {

commit 7737b215ad0f94d20a87d98315da9f6cadaf35c9
Author: Attilio Rao <attilio.rao@citrix.com>
Date:   Tue Aug 21 21:22:38 2012 +0100

    x86: Rename pagetable_setup_start() to pagetable_init()
    
    In preparation for unifying the pagetable_setup_start() and
    pagetable_setup_done() setup functions, rename appropriately all the
    infrastructure related to pagetable_setup_start().
    
    Signed-off-by: Attilio Rao <attilio.rao@citrix.com>
    Ackedd-by: <konrad.wilk@oracle.com>
    Cc: <Ian.Campbell@citrix.com>
    Cc: <Stefano.Stabellini@eu.citrix.com>
    Cc: <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/1345580561-8506-3-git-send-email-attilio.rao@citrix.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 90cbbe00adca..61b7d9827afb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -961,7 +961,7 @@ void __init setup_arch(char **cmdline_p)
 	kvmclock_init();
 #endif
 
-	x86_init.paging.pagetable_setup_start();
+	x86_init.paging.pagetable_init();
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 

commit 73090f8993a40a2f67fed1ab866a928c68cd3765
Author: Attilio Rao <attilio.rao@citrix.com>
Date:   Tue Aug 21 21:22:37 2012 +0100

    x86: Remove base argument from x86_init.paging.pagetable_setup_start
    
    We either use swapper_pg_dir or the argument is unused. Preparatory
    patch to simplify platform pagetable setup further.
    
    Signed-off-by: Attilio Rao <attilio.rao@citrix.com>
    Ackedb-by: <konrad.wilk@oracle.com>
    Cc: <Ian.Campbell@citrix.com>
    Cc: <Stefano.Stabellini@eu.citrix.com>
    Cc: <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/1345580561-8506-2-git-send-email-attilio.rao@citrix.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f4b9b80e1b95..90cbbe00adca 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -961,7 +961,7 @@ void __init setup_arch(char **cmdline_p)
 	kvmclock_init();
 #endif
 
-	x86_init.paging.pagetable_setup_start(swapper_pg_dir);
+	x86_init.paging.pagetable_setup_start();
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 

commit 90993cdd1800dc6ef9587431a0c625b978584e81
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Thu Aug 16 17:00:19 2012 -0300

    x86: KVM guest: merge CONFIG_KVM_CLOCK into CONFIG_KVM_GUEST
    
    The distinction between CONFIG_KVM_CLOCK and CONFIG_KVM_GUEST is
    not so clear anymore, as demonstrated by recent bugs caused by poor
    handling of on/off combinations of these options.
    
    Merge CONFIG_KVM_CLOCK into CONFIG_KVM_GUEST.
    
    Reported-By: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f4b9b80e1b95..b3386ae3438b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -957,7 +957,7 @@ void __init setup_arch(char **cmdline_p)
 	initmem_init();
 	memblock_find_dma_reserve();
 
-#ifdef CONFIG_KVM_CLOCK
+#ifdef CONFIG_KVM_GUEST
 	kvmclock_init();
 #endif
 

commit 879060d5745250c6f38304fd548d42b76f9df093
Merge: 5a0a2a308113 fbd24153c48b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jun 15 14:16:54 2012 +0200

    Merge branch 'x86/cleanups' into x86/apic
    
    Merge in the cleanups because a followup x86/apic change relies on them.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 731a7378b81c2f5fa88ca1ae20b83d548d5613dc
Merge: 87a5af24e548 61f544616904
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 29 20:14:53 2012 -0700

    Merge branch 'x86-trampoline-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 trampoline rework from H. Peter Anvin:
     "This code reworks all the "trampoline"/"realmode" code (various bits
      that need to live in the first megabyte of memory, most but not all of
      which runs in real mode at some point) in the kernel into a single
      object.  The main reason for doing this is that it eliminates the last
      place in the kernel where we needed pages to be mapped RWX.  This code
      separates all that code into proper R/RW/RX pages."
    
    Fix up conflicts in arch/x86/kernel/Makefile (mca removed next to reboot
    code), and arch/x86/kernel/reboot.c (reboot code moved around in one
    branch, modified in this one), and arch/x86/tools/relocs.c (mostly same
    code came in earlier due to working around the ld bugs just before the
    3.4 release).
    
    Also remove stale x86-relocs entry from scripts/.gitignore as per Peter
    Anvin.
    
    * commit '61f5446169046c217a5479517edac3a890c3bee7': (36 commits)
      x86, realmode: Move end signature into header.S
      x86, relocs: When printing an error, say relative or absolute
      x86, relocs: More relocations which may end up as absolute
      x86, relocs: Workaround for binutils 2.22.52.0.1 section bug
      xen-acpi-processor: Add missing #include <xen/xen.h>
      acpi, bgrd: Add missing <linux/io.h> to drivers/acpi/bgrt.c
      x86, realmode: Change EFER to a single u64 field
      x86, realmode: Move kernel/realmode.c to realmode/init.c
      x86, realmode: Move not-common bits out of trampoline_common.S
      x86, realmode: Mask out EFER.LMA when saving trampoline EFER
      x86, realmode: Fix no cache bits test in reboot_32.S
      x86, realmode: Make sure all generated files are listed in targets
      x86, realmode: build fix: remove duplicate build
      x86, realmode: read cr4 and EFER from kernel for 64-bit trampoline
      x86, realmode: fixes compilation issue in tboot.c
      x86, realmode: move relocs from scripts/ to arch/x86/tools
      x86, realmode: header for trampoline code
      x86, realmode: flattened rm hierachy
      x86, realmode: don't copy real_mode_header
      x86, realmode: fix 64-bit wakeup sequence
      ...

commit 365811d6f9bd98543bedc02b72d94f0f0faf3670
Author: Bjorn Helgaas <bhelgaas@google.com>
Date:   Tue May 29 15:06:29 2012 -0700

    x86: print physical addresses consistently with other parts of kernel
    
    Print physical address info in a style consistent with the %pR style used
    elsewhere in the kernel.  For example:
    
        -found SMP MP-table at [ffff8800000fce90] fce90
        +found SMP MP-table at [mem 0x000fce90-0x000fce9f] mapped at [ffff8800000fce90]
        -initial memory mapped : 0 - 20000000
        +initial memory mapped: [mem 0x00000000-0x1fffffff]
        -Base memory trampoline at [ffff88000009c000] 9c000 size 8192
        +Base memory trampoline [mem 0x0009c000-0x0009dfff] mapped at [ffff88000009c000]
        -SRAT: Node 0 PXM 0 0-80000000
        +SRAT: Node 0 PXM 0 [mem 0x00000000-0x7fffffff]
    
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f2afee6a19c1..982e44f960db 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -334,8 +334,8 @@ static void __init relocate_initrd(void)
 	memblock_reserve(ramdisk_here, area_size);
 	initrd_start = ramdisk_here + PAGE_OFFSET;
 	initrd_end   = initrd_start + ramdisk_size;
-	printk(KERN_INFO "Allocated new RAMDISK: %08llx - %08llx\n",
-			 ramdisk_here, ramdisk_here + ramdisk_size);
+	printk(KERN_INFO "Allocated new RAMDISK: [mem %#010llx-%#010llx]\n",
+			 ramdisk_here, ramdisk_here + ramdisk_size - 1);
 
 	q = (char *)initrd_start;
 
@@ -366,8 +366,8 @@ static void __init relocate_initrd(void)
 	/* high pages is not converted by early_res_to_bootmem */
 	ramdisk_image = boot_params.hdr.ramdisk_image;
 	ramdisk_size  = boot_params.hdr.ramdisk_size;
-	printk(KERN_INFO "Move RAMDISK from %016llx - %016llx to"
-		" %08llx - %08llx\n",
+	printk(KERN_INFO "Move RAMDISK from [mem %#010llx-%#010llx] to"
+		" [mem %#010llx-%#010llx]\n",
 		ramdisk_image, ramdisk_image + ramdisk_size - 1,
 		ramdisk_here, ramdisk_here + ramdisk_size - 1);
 }
@@ -392,8 +392,8 @@ static void __init reserve_initrd(void)
 		       ramdisk_size, end_of_lowmem>>1);
 	}
 
-	printk(KERN_INFO "RAMDISK: %08llx - %08llx\n", ramdisk_image,
-			ramdisk_end);
+	printk(KERN_INFO "RAMDISK: [mem %#010llx-%#010llx]\n", ramdisk_image,
+			ramdisk_end - 1);
 
 
 	if (ramdisk_end <= end_of_lowmem) {
@@ -906,8 +906,8 @@ void __init setup_arch(char **cmdline_p)
 	setup_bios_corruption_check();
 #endif
 
-	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
-			max_pfn_mapped<<PAGE_SHIFT);
+	printk(KERN_DEBUG "initial memory mapped: [mem 0x00000000-%#010lx]\n",
+			(max_pfn_mapped<<PAGE_SHIFT) - 1);
 
 	setup_trampolines();
 

commit d484864dd96e1830e7689510597707c1df8cd681
Merge: be87cfb47c5c 0f51596bd39a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 25 09:18:59 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping
    
    Pull CMA and ARM DMA-mapping updates from Marek Szyprowski:
     "These patches contain two major updates for DMA mapping subsystem
      (mainly for ARM architecture).  First one is Contiguous Memory
      Allocator (CMA) which makes it possible for device drivers to allocate
      big contiguous chunks of memory after the system has booted.
    
      The main difference from the similar frameworks is the fact that CMA
      allows to transparently reuse the memory region reserved for the big
      chunk allocation as a system memory, so no memory is wasted when no
      big chunk is allocated.  Once the alloc request is issued, the
      framework migrates system pages to create space for the required big
      chunk of physically contiguous memory.
    
      For more information one can refer to nice LWN articles:
    
       - 'A reworked contiguous memory allocator':
                    http://lwn.net/Articles/447405/
    
       - 'CMA and ARM':
                    http://lwn.net/Articles/450286/
    
       - 'A deep dive into CMA':
                    http://lwn.net/Articles/486301/
    
       - and the following thread with the patches and links to all previous
         versions:
                    https://lkml.org/lkml/2012/4/3/204
    
      The main client for this new framework is ARM DMA-mapping subsystem.
    
      The second part provides a complete redesign in ARM DMA-mapping
      subsystem.  The core implementation has been changed to use common
      struct dma_map_ops based infrastructure with the recent updates for
      new dma attributes merged in v3.4-rc2.  This allows to use more than
      one implementation of dma-mapping calls and change/select them on the
      struct device basis.  The first client of this new infractructure is
      dmabounce implementation which has been completely cut out of the
      core, common code.
    
      The last patch of this redesign update introduces a new, experimental
      implementation of dma-mapping calls on top of generic IOMMU framework.
      This lets ARM sub-platform to transparently use IOMMU for DMA-mapping
      calls if one provides required IOMMU hardware.
    
      For more information please refer to the following thread:
                    http://www.spinics.net/lists/arm-kernel/msg175729.html
    
      The last patch merges changes from both updates and provides a
      resolution for the conflicts which cannot be avoided when patches have
      been applied on the same files (mainly arch/arm/mm/dma-mapping.c)."
    
    Acked by Andrew Morton <akpm@linux-foundation.org>:
     "Yup, this one please.  It's had much work, plenty of review and I
      think even Russell is happy with it."
    
    * 'for-linus' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping: (28 commits)
      ARM: dma-mapping: use PMD size for section unmap
      cma: fix migration mode
      ARM: integrate CMA with DMA-mapping subsystem
      X86: integrate CMA with DMA-mapping subsystem
      drivers: add Contiguous Memory Allocator
      mm: trigger page reclaim in alloc_contig_range() to stabilise watermarks
      mm: extract reclaim code from __alloc_pages_direct_reclaim()
      mm: Serialize access to min_free_kbytes
      mm: page_isolation: MIGRATE_CMA isolation functions added
      mm: mmzone: MIGRATE_CMA migration type added
      mm: page_alloc: change fallbacks array handling
      mm: page_alloc: introduce alloc_contig_range()
      mm: compaction: export some of the functions
      mm: compaction: introduce isolate_freepages_range()
      mm: compaction: introduce map_pages()
      mm: compaction: introduce isolate_migratepages_range()
      mm: page_alloc: remove trailing whitespace
      ARM: dma-mapping: add support for IOMMU mapper
      ARM: dma-mapping: use alloc, mmap, free from dma_ops
      ARM: dma-mapping: remove redundant code and do the cleanup
      ...
    
    Conflicts:
            arch/x86/include/asm/dma-mapping.h

commit 151766fce8bee0e3e6076c8b829f9fcc0a2412ae
Author: Feng Tang <feng.tang@intel.com>
Date:   Sat Apr 28 14:30:40 2012 +0800

    Revert "x86/platform: Add a wallclock_init func to x86_platforms ops"
    
    This reverts commit cf8ff6b6ab0e99dd3058852f4ec76a6140abadec.
    
    Just found this commit is a function duplicatation of commit 6b617e22
    "x86/platform: Add a wallclock_init func to x86_init.timers ops".
    Let's revert it and sorry for the noise.
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Alan Cox <alan@linux.intel.com>
    Cc: Dirk Brandewie <dirk.brandewie@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 366c688d619e..58a07b10812c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1027,8 +1027,6 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.timers.wallclock_init();
 
-	x86_platform.wallclock_init();
-
 	mcheck_init();
 
 	arch_init_ideal_nops();

commit d5b4bb4d103cd601d8009f2d3a7e44586c9ae7cc
Merge: c80ddb526331 bb8187d35f82
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 17:12:06 2012 -0700

    Merge branch 'delete-mca' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    Pull the MCA deletion branch from Paul Gortmaker:
     "It was good that we could support MCA machines back in the day, but
      realistically, nobody is using them anymore.  They were mostly limited
      to 386-sx 16MHz CPU and some 486 class machines and never more than
      64MB of RAM.  Even the enthusiast hobbyist community seems to have
      dried up close to ten years ago, based on what you can find searching
      various websites dedicated to the relatively short lived hardware.
    
      So lets remove the support relating to CONFIG_MCA.  There is no point
      carrying this forward, wasting cycles doing routine maintenance on it;
      wasting allyesconfig build time on validating it, wasting I/O on git
      grep'ping over it, and so on."
    
    Let's see if anybody screams.  It generally has compiled, and James
    Bottomley pointed out that there was a MCA extension from NCR that
    allowed for up to 4GB of memory and PPro-class machines.  So in *theory*
    there may be users out there.
    
    But even James (technically listed as a maintainer) doesn't actually
    have a system, and while Alan Cox claims to have a machine in his cellar
    that he offered to anybody who wants to take it off his hands, he didn't
    argue for keeping MCA support either.
    
    So we could bring it back.  But somebody had better speak up and talk
    about how they have actually been using said MCA hardware with modern
    kernels for us to do that.  And David already took the patch to delete
    all the networking driver code (commit a5e371f61ad3: "drivers/net:
    delete all code/drivers depending on CONFIG_MCA").
    
    * 'delete-mca' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux:
      MCA: delete all remaining traces of microchannel bus support.
      scsi: delete the MCA specific drivers and driver code
      serial: delete the MCA specific 8250 support.
      arm: remove ability to select CONFIG_MCA

commit 19bec32d7f26f263dba13f2797d9c3245de2020b
Merge: 514b1923e154 fba60c620a6a 74bc49179542 ddc5681ed33a 57da8b960b9a e826abd52391
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 10:09:50 2012 -0700

    Merge branches 'x86-asm-for-linus', 'x86-cleanups-for-linus', 'x86-cpu-for-linus', 'x86-debug-for-linus' and 'x86-microcode-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull initial trivial x86 stuff from Ingo Molnar.
    
    Various random cleanups and trivial fixes.
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86-64: Eliminate dead ia32 syscall handlers
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/pci-calgary_64.c: Remove obsoleted simple_strtoul() usage
      x86: Don't continue booting if we can't load the specified initrd
      x86: kernel/dumpstack.c simple_strtoul cleanup
      x86: kernel/check.c simple_strtoul cleanup
      debug: Add CONFIG_READABLE_ASM
      x86: spinlock.h: Remove REG_PTR_MODE
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/cache_info: Fix setup of l2/l3 ids
    
    * 'x86-debug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Avoid double stack traces with show_regs()
    
    * 'x86-microcode-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, microcode: microcode_core.c simple_strtoul cleanup

commit 0a2b9a6ea93650b8a00f9fd5ee8fdd25671e2df6
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Thu Dec 29 13:09:51 2011 +0100

    X86: integrate CMA with DMA-mapping subsystem
    
    This patch adds support for CMA to dma-mapping subsystem for x86
    architecture that uses common pci-dma/pci-nommu implementation. This
    allows to test CMA on KVM/QEMU and a lot of common x86 boxes.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    CC: Michal Nazarewicz <mina86@mina86.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1a2901562059..d6c956e674cc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -50,6 +50,7 @@
 #include <asm/pci-direct.h>
 #include <linux/init_ohci1394_dma.h>
 #include <linux/kvm_para.h>
+#include <linux/dma-contiguous.h>
 
 #include <linux/errno.h>
 #include <linux/kernel.h>
@@ -934,6 +935,7 @@ void __init setup_arch(char **cmdline_p)
 	}
 #endif
 	memblock.current_limit = get_max_mapped();
+	dma_contiguous_reserve(0);
 
 	/*
 	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.

commit bb8187d35f820671d6dd76700d77a6b55f95e2c5
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu May 17 19:06:13 2012 -0400

    MCA: delete all remaining traces of microchannel bus support.
    
    Hardware with MCA bus is limited to 386 and 486 class machines
    that are now 20+ years old and typically with less than 32MB
    of memory.  A quick search on the internet, and you see that
    even the MCA hobbyist/enthusiast community has lost interest
    in the early 2000 era and never really even moved ahead from
    the 2.4 kernels to the 2.6 series.
    
    This deletes anything remaining related to CONFIG_MCA from core
    kernel code and from the x86 architecture.  There is no point in
    carrying this any further into the future.
    
    One complication to watch for is inadvertently scooping up
    stuff relating to machine check, since there is overlap in
    the TLA name space (e.g. arch/x86/boot/mca.c).
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: James Bottomley <JBottomley@Parallels.com>
    Cc: x86@kernel.org
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1a2901562059..879166402bf9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -34,7 +34,6 @@
 #include <linux/memblock.h>
 #include <linux/seq_file.h>
 #include <linux/console.h>
-#include <linux/mca.h>
 #include <linux/root_dev.h>
 #include <linux/highmem.h>
 #include <linux/module.h>
@@ -179,12 +178,6 @@ struct cpuinfo_x86 new_cpu_data __cpuinitdata = {0, 0, 0, 0, -1, 1, 0, 0, -1};
 /* common cpu data for all cpus */
 struct cpuinfo_x86 boot_cpu_data __read_mostly = {0, 0, 0, 0, -1, 1, 0, 0, -1};
 EXPORT_SYMBOL(boot_cpu_data);
-static void set_mca_bus(int x)
-{
-#ifdef CONFIG_MCA
-	MCA_bus = x;
-#endif
-}
 
 unsigned int def_to_bigsmp;
 
@@ -717,7 +710,6 @@ void __init setup_arch(char **cmdline_p)
 	apm_info.bios = boot_params.apm_bios_info;
 	ist_info = boot_params.ist_info;
 	if (boot_params.sys_desc_table.length != 0) {
-		set_mca_bus(boot_params.sys_desc_table.table[3] & 0x2);
 		machine_id = boot_params.sys_desc_table.table[0];
 		machine_submodel_id = boot_params.sys_desc_table.table[1];
 		BIOS_revision = boot_params.sys_desc_table.table[2];

commit ab7b64e9ee1e930ffe9d7f5b5eebe618a3b3a03b
Author: Peter Jones <pjones@redhat.com>
Date:   Wed May 16 13:43:26 2012 -0400

    x86: Don't continue booting if we can't load the specified initrd
    
    If we've determined we can't do what the user asked, trying to do
    something else isn't going to make the user's life better.
    
    Without this the screen scrolls a bit and then you get a panic
    anyway, and it's nice not to have so much scroll after the real
    problem in bug reports.
    
    Link: http://lkml.kernel.org/r/1337190206-12121-1-git-send-email-pjones@redhat.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1a2901562059..37ef1169ffde 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -393,10 +393,9 @@ static void __init reserve_initrd(void)
 	initrd_start = 0;
 
 	if (ramdisk_size >= (end_of_lowmem>>1)) {
-		memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
-		printk(KERN_ERR "initrd too large to handle, "
-		       "disabling initrd\n");
-		return;
+		panic("initrd too large to handle, "
+		       "disabling initrd (%lld needed, %lld available)\n",
+		       ramdisk_size, end_of_lowmem>>1);
 	}
 
 	printk(KERN_INFO "RAMDISK: %08llx - %08llx\n", ramdisk_image,

commit cda846f101fb1396b6924f1d9b68ac3d42de5403
Author: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
Date:   Tue May 8 21:22:46 2012 +0300

    x86, realmode: read cr4 and EFER from kernel for 64-bit trampoline
    
    This patch changes 64-bit trampoline so that CR4 and
    EFER are provided by the kernel instead of using fixed
    values.
    
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
    Link: http://lkml.kernel.org/r/1336501366-28617-24-git-send-email-jarkko.sakkinen@intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7a14fece9cfc..efcf305210a4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -975,6 +975,8 @@ void __init setup_arch(char **cmdline_p)
 	if (boot_cpu_data.cpuid_level >= 0) {
 		/* A CPU has %cr4 if and only if it has CPUID */
 		mmu_cr4_features = read_cr4();
+		if (trampoline_cr4_features)
+			*trampoline_cr4_features = mmu_cr4_features;
 	}
 
 #ifdef CONFIG_X86_32

commit c9b77ccb52a5c77233b0e557b7d4417b00ef4012
Author: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
Date:   Tue May 8 21:22:29 2012 +0300

    x86, realmode: Move ACPI wakeup to unified realmode code
    
    Migrated ACPI wakeup code to the real-mode blob.
    Code existing in .x86_trampoline  can be completely
    removed. Static descriptor table in wakeup_asm.S is
    courtesy of H. Peter Anvin.
    
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
    Link: http://lkml.kernel.org/r/1336501366-28617-7-git-send-email-jarkko.sakkinen@intel.com
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Len Brown <len.brown@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 56e41242a6b8..7a14fece9cfc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -73,7 +73,6 @@
 
 #include <asm/mtrr.h>
 #include <asm/apic.h>
-#include <asm/trampoline.h>
 #include <asm/realmode.h>
 #include <asm/e820.h>
 #include <asm/mpspec.h>
@@ -918,7 +917,6 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
 			max_pfn_mapped<<PAGE_SHIFT);
 
-	setup_trampolines();
 	setup_real_mode();
 
 	init_gbpages();

commit 084ee1c641a068bfd1194d545f7dc9ab2043eb35
Author: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
Date:   Tue May 8 21:22:26 2012 +0300

    x86, realmode: Relocator for realmode code
    
    Implements relocator for real mode code that is called
    as part of setup_arch(). Processes segment relocations
    and linear relocations. Real-mode code is relocated to
    a free hole below 1 MB.
    
    Signed-off-by: Jarkko Sakkinen <jarkko.sakkinen@intel.com>
    Link: http://lkml.kernel.org/r/1336501366-28617-4-git-send-email-jarkko.sakkinen@intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1a2901562059..56e41242a6b8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -74,6 +74,7 @@
 #include <asm/mtrr.h>
 #include <asm/apic.h>
 #include <asm/trampoline.h>
+#include <asm/realmode.h>
 #include <asm/e820.h>
 #include <asm/mpspec.h>
 #include <asm/setup.h>
@@ -918,6 +919,7 @@ void __init setup_arch(char **cmdline_p)
 			max_pfn_mapped<<PAGE_SHIFT);
 
 	setup_trampolines();
+	setup_real_mode();
 
 	init_gbpages();
 

commit 9438ef7f4ea73d5430a330fc206f97826eb9fb16
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 7 19:19:56 2012 +0200

    x86/apic: Fix UP boot crash
    
    Commit 31b3c9d72340 ("xen/x86: Implement x86_apic_ops") implemented
    this:
    
    ... without considering that on UP the function pointer might be NULL.
    
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Link: http://lkml.kernel.org/n/tip-3pfty0ml4yp62phbkchichh0@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8526317c5f0b..7e67c5a71061 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1012,7 +1012,8 @@ void __init setup_arch(char **cmdline_p)
 	init_cpu_to_node();
 
 	init_apic_mappings();
-	x86_io_apic_ops.init();
+	if (x86_io_apic_ops.init)
+		x86_io_apic_ops.init();
 
 	kvm_guest_init();
 

commit 4a8e2a3115e7aa4bd2deb4c6483d47c743e0fbb3
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed Mar 28 12:37:36 2012 -0400

    x86/apic: Replace io_apic_ops with x86_io_apic_ops.
    
    Which makes the code fit within the rest of the x86_ops functions.
    
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    [v1: Changed x86_apic -> x86_ioapic per Yinghai Lu <yinghai@kernel.org> suggestion]
    [v2: Rebased on tip/x86/urgent and redid to match Ingo's syntax style]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1a2901562059..8526317c5f0b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1012,7 +1012,7 @@ void __init setup_arch(char **cmdline_p)
 	init_cpu_to_node();
 
 	init_apic_mappings();
-	ioapic_and_gsi_init();
+	x86_io_apic_ops.init();
 
 	kvm_guest_init();
 

commit 532bfc851a7475fb6a36c1e953aa395798a7cca7
Merge: 0195c00244dc 8da00edc1069
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 28 17:19:27 2012 -0700

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge third batch of patches from Andrew Morton:
     - Some MM stragglers
     - core SMP library cleanups (on_each_cpu_mask)
     - Some IPI optimisations
     - kexec
     - kdump
     - IPMI
     - the radix-tree iterator work
     - various other misc bits.
    
     "That'll do for -rc1.  I still have ~10 patches for 3.4, will send
      those along when they've baked a little more."
    
    * emailed from Andrew Morton <akpm@linux-foundation.org>: (35 commits)
      backlight: fix typo in tosa_lcd.c
      crc32: add help text for the algorithm select option
      mm: move hugepage test examples to tools/testing/selftests/vm
      mm: move slabinfo.c to tools/vm
      mm: move page-types.c from Documentation to tools/vm
      selftests/Makefile: make `run_tests' depend on `all'
      selftests: launch individual selftests from the main Makefile
      radix-tree: use iterators in find_get_pages* functions
      radix-tree: rewrite gang lookup using iterator
      radix-tree: introduce bit-optimized iterator
      fs/proc/namespaces.c: prevent crash when ns_entries[] is empty
      nbd: rename the nbd_device variable from lo to nbd
      pidns: add reboot_pid_ns() to handle the reboot syscall
      sysctl: use bitmap library functions
      ipmi: use locks on watchdog timeout set on reboot
      ipmi: simplify locking
      ipmi: fix message handling during panics
      ipmi: use a tasklet for handling received messages
      ipmi: increase KCS timeouts
      ipmi: decrease the IPMI message transaction time in interrupt mode
      ...

commit 09c71bfd8384278c42f56380365940508194cec0
Author: Dave Young <dyoung@redhat.com>
Date:   Wed Mar 28 14:42:47 2012 -0700

    kdump x86: fix total mem size calculation for reservation
    
    crashkernel reservation need know the total memory size.  Current
    get_total_mem simply use max_pfn - min_low_pfn.  It is wrong because it
    will including memory holes in the middle.
    
    Especially for kvm guest with memory > 0xe0000000, there's below in qemu
    code: qemu split memory as below:
    
        if (ram_size >= 0xe0000000 ) {
            above_4g_mem_size = ram_size - 0xe0000000;
            below_4g_mem_size = 0xe0000000;
        } else {
            below_4g_mem_size = ram_size;
        }
    
    So for 4G mem guest, seabios will insert a 512M usable region beyond of
    4G.  Thus in above case max_pfn - min_low_pfn will be more than original
    memsize.
    
    Fixing this issue by using memblock_phys_mem_size() to get the total
    memsize.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: WANG Cong <xiyou.wangcong@gmail.com>
    Reviewed-by: Simon Horman <horms@verge.net.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 88638883176a..ab77aae4ad9b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -509,15 +509,6 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 
 #ifdef CONFIG_KEXEC
 
-static inline unsigned long long get_total_mem(void)
-{
-	unsigned long long total;
-
-	total = max_pfn - min_low_pfn;
-
-	return total << PAGE_SHIFT;
-}
-
 /*
  * Keep the crash kernel below this limit.  On 32 bits earlier kernels
  * would limit the kernel to the low 512 MiB due to mapping restrictions.
@@ -536,7 +527,7 @@ static void __init reserve_crashkernel(void)
 	unsigned long long crash_size, crash_base;
 	int ret;
 
-	total_mem = get_total_mem();
+	total_mem = memblock_phys_mem_size();
 
 	ret = parse_crashkernel(boot_command_line, total_mem,
 			&crash_size, &crash_base);

commit f05e798ad4c09255f590f5b2c00a7ca6c172f983
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:11:12 2012 +0100

    Disintegrate asm/system.h for X86
    
    Disintegrate asm/system.h for X86.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    cc: x86@kernel.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 88638883176a..8cbeb7209c3e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -90,7 +90,6 @@
 #include <asm/processor.h>
 #include <asm/bugs.h>
 
-#include <asm/system.h>
 #include <asm/vsyscall.h>
 #include <asm/cpu.h>
 #include <asm/desc.h>

commit 1adbfa3511ee1c1118e16a9a0246870f12fef4e6
Author: Olof Johansson <olof@lixom.net>
Date:   Sun Feb 12 13:24:29 2012 -0800

    x86, efi: Allow basic init with mixed 32/64-bit efi/kernel
    
    Traditionally the kernel has refused to setup EFI at all if there's been
    a mismatch in 32/64-bit mode between EFI and the kernel.
    
    On some platforms that boot natively through EFI (Chrome OS being one),
    we still need to get at least some of the static data such as memory
    configuration out of EFI. Runtime services aren't as critical, and
    it's a significant amount of work to implement switching between the
    operating modes to call between kernel and firmware for thise cases. So
    I'm ignoring it for now.
    
    v5:
    * Fixed some printk strings based on feedback
    * Renamed 32/64-bit specific types to not have _ prefix
    * Fixed bug in printout of efi runtime disablement
    
    v4:
    * Some of the earlier cleanup was accidentally reverted by this patch, fixed.
    * Reworded some messages to not have to line wrap printk strings
    
    v3:
    * Reorganized to a series of patches to make it easier to review, and
      do some of the cleanups I had left out before.
    
    v2:
    * Added graceful error handling for 32-bit kernel that gets passed
      EFI data above 4GB.
    * Removed some warnings that were missed in first version.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Link: http://lkml.kernel.org/r/1329081869-20779-6-git-send-email-olof@lixom.net
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d7d5099fe874..88638883176a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -749,10 +749,16 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
-		     EFI_LOADER_SIGNATURE, 4)) {
+		     "EL32", 4)) {
 		efi_enabled = 1;
-		efi_memblock_x86_reserve_range();
+		efi_64bit = false;
+	} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
+		     "EL64", 4)) {
+		efi_enabled = 1;
+		efi_64bit = true;
 	}
+	if (efi_enabled && efi_memblock_x86_reserve_range())
+		efi_enabled = 0;
 #endif
 
 	x86_init.oem.arch_setup();

commit bcede2f64a3b5cb50c0bdec1553ab480fd75d659
Merge: d0b9706c20eb 2d2da60fb40a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 11 19:12:33 2012 -0800

    Merge branch 'x86-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'x86-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, efi: Break up large initrd reads
      x86, efi: EFI boot stub support
      efi: Add EFI file I/O data types
      efi.h: Add boottime->locate_handle search types
      efi.h: Add graphics protocol guids
      efi.h: Add allocation types for boottime->allocate_pages()
      efi.h: Add efi_image_loaded_t
      efi.h: Add struct definition for boot time services
      x86: Don't use magic strings for EFI loader signature
      x86: Add missing bzImage fields to struct setup_header

commit f7d7d01be53cb47e0ae212c4e968aa28b82d2138
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Tue Nov 15 12:56:14 2011 +0000

    x86: Don't use magic strings for EFI loader signature
    
    Introduce a symbol, EFI_LOADER_SIGNATURE instead of using the magic
    strings, which also helps to reduce the amount of ifdeffery.
    
    Cc: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Link: http://lkml.kernel.org/r/1318848017-12301-1-git-send-email-matt@console-pimps.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9a9e40fb091c..4d5243c31ac4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -752,12 +752,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
-#ifdef CONFIG_X86_32
-		     "EL32",
-#else
-		     "EL64",
-#endif
-	 4)) {
+		     EFI_LOADER_SIGNATURE, 4)) {
 		efi_enabled = 1;
 		efi_memblock_x86_reserve_range();
 	}

commit e8c7106280a305e1ff2a3a8a4dfce141469fb039
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Nov 18 13:09:11 2011 +0000

    x86, efi: Calling __pa() with an ioremap()ed address is invalid
    
    If we encounter an efi_memory_desc_t without EFI_MEMORY_WB set
    in ->attribute we currently call set_memory_uc(), which in turn
    calls __pa() on a potentially ioremap'd address.
    
    On CONFIG_X86_32 this is invalid, resulting in the following
    oops on some machines:
    
      BUG: unable to handle kernel paging request at f7f22280
      IP: [<c10257b9>] reserve_ram_pages_type+0x89/0x210
      [...]
    
      Call Trace:
       [<c104f8ca>] ? page_is_ram+0x1a/0x40
       [<c1025aff>] reserve_memtype+0xdf/0x2f0
       [<c1024dc9>] set_memory_uc+0x49/0xa0
       [<c19334d0>] efi_enter_virtual_mode+0x1c2/0x3aa
       [<c19216d4>] start_kernel+0x291/0x2f2
       [<c19211c7>] ? loglevel+0x1b/0x1b
       [<c19210bf>] i386_start_kernel+0xbf/0xc8
    
    A better approach to this problem is to map the memory region
    with the correct attributes from the start, instead of modifying
    it after the fact. The uncached case can be handled by
    ioremap_nocache() and the cached by ioremap_cache().
    
    Despite first impressions, it's not possible to use
    ioremap_cache() to map all cached memory regions on
    CONFIG_X86_64 because EFI_RUNTIME_SERVICES_DATA regions really
    don't like being mapped into the vmalloc space, as detailed in
    the following bug report,
    
            https://bugzilla.redhat.com/show_bug.cgi?id=748516
    
    Therefore, we need to ensure that any EFI_RUNTIME_SERVICES_DATA
    regions are covered by the direct kernel mapping table on
    CONFIG_X86_64. To accomplish this we now map E820_RESERVED_EFI
    regions via the direct kernel mapping with the initial call to
    init_memory_mapping() in setup_arch(), whereas previously these
    regions wouldn't be mapped if they were after the last E820_RAM
    region until efi_ioremap() was called. Doing it this way allows
    us to delete efi_ioremap() completely.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Matthew Garrett <mjg@redhat.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Huang Ying <huang.ying.caritas@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1321621751-3650-1-git-send-email-matt@console-pimps.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cf0ef986cb6d..9a9e40fb091c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -691,6 +691,8 @@ early_param("reservelow", parse_reservelow);
 
 void __init setup_arch(char **cmdline_p)
 {
+	unsigned long end_pfn;
+
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
@@ -932,7 +934,24 @@ void __init setup_arch(char **cmdline_p)
 	init_gbpages();
 
 	/* max_pfn_mapped is updated here */
-	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
+	end_pfn = max_low_pfn;
+
+#ifdef CONFIG_X86_64
+	/*
+	 * There may be regions after the last E820_RAM region that we
+	 * want to include in the kernel direct mapping, such as
+	 * EFI_RUNTIME_SERVICES_DATA.
+	 */
+	if (efi_enabled) {
+		unsigned long efi_end;
+
+		efi_end = e820_end_pfn(MAXMEM>>PAGE_SHIFT, E820_RESERVED_EFI);
+		if (efi_end > max_low_pfn)
+			end_pfn = efi_end;
+	}
+#endif
+
+	max_low_pfn_mapped = init_memory_mapping(0, end_pfn << PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;
 
 #ifdef CONFIG_X86_64

commit d4bbf7e7759afc172e2bfbc5c416324590049cdd
Merge: a150439c4a97 401d0069cb34
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 28 09:46:22 2011 -0800

    Merge branch 'master' into x86/memblock
    
    Conflicts & resolutions:
    
    * arch/x86/xen/setup.c
    
            dc91c728fd "xen: allow extra memory to be in multiple regions"
            24aa07882b "memblock, x86: Replace memblock_x86_reserve/free..."
    
            conflicted on xen_add_extra_mem() updates.  The resolution is
            trivial as the latter just want to replace
            memblock_x86_reserve_range() with memblock_reserve().
    
    * drivers/pci/intel-iommu.c
    
            166e9278a3f "x86/ia64: intel-iommu: move to drivers/iommu/"
            5dfe8660a3d "bootmem: Replace work_with_active_regions() with..."
    
            conflicted as the former moved the file under drivers/iommu/.
            Resolved by applying the chnages from the latter on the moved
            file.
    
    * mm/Kconfig
    
            6661672053a "memblock: add NO_BOOTMEM config symbol"
            c378ddd53f9 "memblock, x86: Make ARCH_DISCARD_MEMBLOCK a config option"
    
            conflicted trivially.  Both added config options.  Just
            letting both add their own options resolves the conflict.
    
    * mm/memblock.c
    
            d1f0ece6cdc "mm/memblock.c: small function definition fixes"
            ed7b56a799c "memblock: Remove memblock_memory_can_coalesce()"
    
            confliected.  The former updates function removed by the
            latter.  Resolution is trivial.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit cf8ff6b6ab0e99dd3058852f4ec76a6140abadec
Author: Feng Tang <feng.tang@intel.com>
Date:   Thu Nov 10 13:42:02 2011 +0000

    x86/platform: Add a wallclock_init func to x86_platforms ops
    
    Some wall clock devices use MMIO based HW register, this new
    function will give them a chance to do some initialization work
    before their get/set_time service get called.
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    Signed-off-by: Dirk Brandewie <dirk.brandewie@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index afaf38447ef5..cf0ef986cb6d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1045,6 +1045,8 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.timers.wallclock_init();
 
+	x86_platform.wallclock_init();
+
 	mcheck_init();
 
 	arch_init_ideal_nops();

commit 24aa07882b672fff2da2f5c955759f0bd13d32d5
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 12 11:16:06 2011 +0200

    memblock, x86: Replace memblock_x86_reserve/free_range() with generic ones
    
    Other than sanity check and debug message, the x86 specific version of
    memblock reserve/free functions are simple wrappers around the generic
    versions - memblock_reserve/free().
    
    This patch adds debug messages with caller identification to the
    generic versions and replaces x86 specific ones and kills them.
    arch/x86/include/asm/memblock.h and arch/x86/mm/memblock.c are empty
    after this change and removed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/1310462166-31469-14-git-send-email-tj@kernel.org
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 31ffe20d5d27..97d227ec995d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -306,7 +306,8 @@ static void __init cleanup_highmap(void)
 static void __init reserve_brk(void)
 {
 	if (_brk_end > _brk_start)
-		memblock_x86_reserve_range(__pa(_brk_start), __pa(_brk_end), "BRK");
+		memblock_reserve(__pa(_brk_start),
+				 __pa(_brk_end) - __pa(_brk_start));
 
 	/* Mark brk area as locked down and no longer taking any
 	   new allocations */
@@ -337,7 +338,7 @@ static void __init relocate_initrd(void)
 
 	/* Note: this includes all the lowmem currently occupied by
 	   the initrd, we rely on that fact to keep the data intact. */
-	memblock_x86_reserve_range(ramdisk_here, ramdisk_here + area_size, "NEW RAMDISK");
+	memblock_reserve(ramdisk_here, area_size);
 	initrd_start = ramdisk_here + PAGE_OFFSET;
 	initrd_end   = initrd_start + ramdisk_size;
 	printk(KERN_INFO "Allocated new RAMDISK: %08llx - %08llx\n",
@@ -393,7 +394,7 @@ static void __init reserve_initrd(void)
 	initrd_start = 0;
 
 	if (ramdisk_size >= (end_of_lowmem>>1)) {
-		memblock_x86_free_range(ramdisk_image, ramdisk_end);
+		memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
 		printk(KERN_ERR "initrd too large to handle, "
 		       "disabling initrd\n");
 		return;
@@ -416,7 +417,7 @@ static void __init reserve_initrd(void)
 
 	relocate_initrd();
 
-	memblock_x86_free_range(ramdisk_image, ramdisk_end);
+	memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
 }
 #else
 static void __init reserve_initrd(void)
@@ -490,15 +491,13 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
-	char buf[32];
 
 	if (boot_params.hdr.version < 0x0209)
 		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));
-		sprintf(buf, "setup data %x", data->type);
-		memblock_x86_reserve_range(pa_data, pa_data+sizeof(*data)+data->len, buf);
+		memblock_reserve(pa_data, sizeof(*data) + data->len);
 		pa_data = data->next;
 		early_iounmap(data, sizeof(*data));
 	}
@@ -568,7 +567,7 @@ static void __init reserve_crashkernel(void)
 			return;
 		}
 	}
-	memblock_x86_reserve_range(crash_base, crash_base + crash_size, "CRASH KERNEL");
+	memblock_reserve(crash_base, crash_size);
 
 	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
 			"for crashkernel (System RAM: %ldMB)\n",
@@ -626,7 +625,7 @@ static __init void reserve_ibft_region(void)
 	addr = find_ibft_region(&size);
 
 	if (size)
-		memblock_x86_reserve_range(addr, addr + size, "* ibft");
+		memblock_reserve(addr, size);
 }
 
 static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;

commit 1f5026a7e21e409c2b9dd54f6dfb9446511fb7c5
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 12 09:58:09 2011 +0200

    memblock: Kill MEMBLOCK_ERROR
    
    25818f0f28 (memblock: Make MEMBLOCK_ERROR be 0) thankfully made
    MEMBLOCK_ERROR 0 and there already are codes which expect error return
    to be 0.  There's no point in keeping MEMBLOCK_ERROR around.  End its
    misery.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/1310457490-3356-6-git-send-email-tj@kernel.org
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index afaf38447ef5..31ffe20d5d27 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -331,7 +331,7 @@ static void __init relocate_initrd(void)
 	ramdisk_here = memblock_find_in_range(0, end_of_lowmem, area_size,
 					 PAGE_SIZE);
 
-	if (ramdisk_here == MEMBLOCK_ERROR)
+	if (!ramdisk_here)
 		panic("Cannot find place for new RAMDISK of size %lld\n",
 			 ramdisk_size);
 
@@ -554,7 +554,7 @@ static void __init reserve_crashkernel(void)
 		crash_base = memblock_find_in_range(alignment,
 			       CRASH_KERNEL_ADDR_MAX, crash_size, alignment);
 
-		if (crash_base == MEMBLOCK_ERROR) {
+		if (!crash_base) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
 		}

commit de66ee979d0ea45171cc2501750e9f9f22f5a690
Merge: 916f676f8dc0 4db70f73e569
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu May 26 13:51:31 2011 +0200

    Merge branch 'linus' into x86/urgent
    
    Merge reason: we want to queue up a dependent patch.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 916f676f8dc016103f983c7ec54c18ecdbb6e349
Author: Matthew Garrett <mjg@redhat.com>
Date:   Wed May 25 09:53:13 2011 -0400

    x86, efi: Retain boot service code until after switching to virtual mode
    
    UEFI stands for "Unified Extensible Firmware Interface", where "Firmware"
    is an ancient African word meaning "Why do something right when you can
    do it so wrong that children will weep and brave adults will cower before
    you", and "UEI" is Celtic for "We missed DOS so we burned it into your
    ROMs". The UEFI specification provides for runtime services (ie, another
    way for the operating system to be forced to depend on the firmware) and
    we rely on these for certain trivial tasks such as setting up the
    bootloader. But some hardware fails to work if we attempt to use these
    runtime services from physical mode, and so we have to switch into virtual
    mode. So far so dreadful.
    
    The specification makes it clear that the operating system is free to do
    whatever it wants with boot services code after ExitBootServices() has been
    called. SetVirtualAddressMap() can't be called until ExitBootServices() has
    been. So, obviously, a whole bunch of EFI implementations call into boot
    services code when we do that. Since we've been charmingly naive and
    trusted that the specification may be somehow relevant to the real world,
    we've already stuffed a picture of a penguin or something in that address
    space. And just to make things more entertaining, we've also marked it
    non-executable.
    
    This patch allocates the boot services regions during EFI init and makes
    sure that they're executable. Then, after SetVirtualAddressMap(), it
    discards them and everyone lives happily ever after. Except for the ones
    who have to work on EFI, who live sad lives haunted by the knowledge that
    someone's eventually going to write yet another firmware specification.
    
    [ hpa: adding this to urgent with a stable tag since it fixes currently-broken
      hardware.  However, I do not know what the dependencies are and so I do
      not know which -stable versions this may be a candidate for. ]
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Link: http://lkml.kernel.org/r/1306331593-28715-1-git-send-email-mjg@redhat.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: <stable@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 605e5ae19c7f..b9ca498f5602 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -910,6 +910,13 @@ void __init setup_arch(char **cmdline_p)
 	memblock.current_limit = get_max_mapped();
 	memblock_x86_fill();
 
+	/*
+	 * The EFI specification says that boot service code won't be called
+	 * after ExitBootServices(). This is, in fact, a lie.
+	 */
+	if (efi_enabled)
+		efi_reserve_boot_services();
+
 	/* preallocate 4k for mptable mpc */
 	early_reserve_e820_mpc_new();
 

commit 162a7e7500f9664636e649ba59defe541b7c2c60
Author: Mike Travis <travis@sgi.com>
Date:   Tue May 24 17:13:20 2011 -0700

    printk: allocate kernel log buffer earlier
    
    On larger systems, because of the numerous ACPI, Bootmem and EFI messages,
    the static log buffer overflows before the larger one specified by the
    log_buf_len param is allocated.  Minimize the overflow by allocating the
    new log buffer as soon as possible.
    
    On kernels without memblock, a later call to setup_log_buf from
    kernel/init.c is the fallback.
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix CONFIG_PRINTK=n build]
    Signed-off-by: Mike Travis <travis@sgi.com>
    Cc: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Jack Steiner <steiner@sgi.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 605e5ae19c7f..a3e5948670c2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -946,6 +946,8 @@ void __init setup_arch(char **cmdline_p)
 	if (init_ohci1394_dma_early)
 		init_ohci1394_dma_on_all_controllers();
 #endif
+	/* Allocate bigger log buffer */
+	setup_log_buf(1);
 
 	reserve_initrd();
 

commit 5e152b4c9e0fce6149c74406346a7ae7e7a17727
Merge: a77febbef105 9251bac97d47
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 23 15:39:34 2011 -0700

    Merge branch 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6
    
    * 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6: (27 commits)
      PCI: Don't use dmi_name_in_vendors in quirk
      PCI: remove unused AER functions
      PCI/sysfs: move bus cpuaffinity to class dev_attrs
      PCI: add rescan to /sys/.../pci_bus/.../
      PCI: update bridge resources to get more big ranges when allocating space (again)
      KVM: Use pci_store/load_saved_state() around VM device usage
      PCI: Add interfaces to store and load the device saved state
      PCI: Track the size of each saved capability data area
      PCI/e1000e: Add and use pci_disable_link_state_locked()
      x86/PCI: derive pcibios_last_bus from ACPI MCFG
      PCI: add latency tolerance reporting enable/disable support
      PCI: add OBFF enable/disable support
      PCI: add ID-based ordering enable/disable support
      PCI hotplug: acpiphp: assume device is in state D0 after powering on a slot.
      PCI: Set PCIE maxpayload for card during hotplug insertion
      PCI/ACPI: Report _OSC control mask returned on failure to get control
      x86/PCI: irq and pci_ids patch for Intel Panther Point DeviceIDs
      PCI: handle positive error codes
      PCI: check pci_vpd_pci22_wait() return
      PCI: Use ICH6_GPIO_EN in ich6_lpc_acpi_gpio
      ...
    
    Fix up trivial conflicts in include/linux/pci_ids.h: commit a6e5e2be4461
    moved the intel SMBUS ID definitons to the i2c-i801.c driver.

commit 016281880439a8665ecf37514865742da58131d4
Merge: 17b141803c6c 865be7a81071
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 19 17:55:12 2011 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, cpu: Fix detection of Celeron Covington stepping A1 and B0
      Documentation, ABI: Update L3 cache index disable text
      x86, AMD, cacheinfo: Fix L3 cache index disable checks
      x86, AMD, cacheinfo: Fix fallout caused by max3 conversion
      x86, cpu: Change NOP selection for certain Intel CPUs
      x86, cpu: Clean up and unify the NOP selection infrastructure
      x86, percpu: Use ASM_NOP4 instead of hardcoding P6_NOP4
      x86, cpu: Move AMD Elan Kconfig under "Processor family"
    
    Fix up trivial conflicts in alternative handling (commit dc326fca2b64
    "x86, cpu: Clean up and unify the NOP selection infrastructure" removed
    some hacky 5-byte instruction stuff, while commit d430d3d7e646 "jump
    label: Introduce static_branch() interface" renamed HAVE_JUMP_LABEL to
    CONFIG_JUMP_LABEL in the code that went away)

commit 5491ff511d31ed06e9572f1e84e3494be66b6e8c
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Apr 12 10:20:48 2011 -0700

    x86/PCI: Remove dma32_reserve_bootmem
    
    This workaround holds a dma32 buffer at early boot to prevent later
    bootmem allocations from stealing it in the case of large RAM configs.
    
    Now that x86 is using memblock, and the nobootmem wrapper does top-down
    allocation, it's no longer necessary, so remove it.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4be9b398470e..cab4f24e2177 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -966,7 +966,6 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init();
 	memblock_find_dma_reserve();
-	dma32_reserve_bootmem();
 
 #ifdef CONFIG_KVM_CLOCK
 	kvmclock_init();

commit dc326fca2b640fc41aed7c015d0f456935a66255
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Mon Apr 18 15:19:51 2011 -0700

    x86, cpu: Clean up and unify the NOP selection infrastructure
    
    Clean up and unify the NOP selection infrastructure:
    
    - Make the atomic 5-byte NOP a part of the selection system.
    - Pick NOPs once during early boot and then be done with it.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jason Baron <jbaron@redhat.com>
    Link: http://lkml.kernel.org/r/1303166160-10315-3-git-send-email-hpa@linux.intel.com

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5a0484a95ad6..390a663894d8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -691,8 +691,6 @@ early_param("reservelow", parse_reservelow);
 
 void __init setup_arch(char **cmdline_p)
 {
-	unsigned long flags;
-
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
@@ -1036,9 +1034,7 @@ void __init setup_arch(char **cmdline_p)
 
 	mcheck_init();
 
-	local_irq_save(flags);
-	arch_init_ideal_nop5();
-	local_irq_restore(flags);
+	arch_init_ideal_nops();
 }
 
 #ifdef CONFIG_X86_32

commit 4da9484bdece39ab0b098fa711e095e3e9fc8684
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Apr 6 13:10:02 2011 -0700

    x86, hibernate: Initialize mmu_cr4_features during boot
    
    Restore the initialization of mmu_cr4_features during boot, which was
    removed without comment in checkin e5f15b45ddf3afa2bbbb10c7ea34fb32b6de0a0e
    
    x86: Cleanup highmap after brk is concluded
    
    thereby breaking resume from hibernate.  This restores previous
    functionality in approximately the same place, and corrects the
    reading of %cr4 on pre-CPUID hardware (%cr4 exists if and only if
    CPUID is supported.)
    
    However, part of the problem is that the hibernate suspend/resume
    sequence should manage the save/restore of %cr4 explicitly.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <201104020154.57136.rjw@sisk.pl>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5a0484a95ad6..4be9b398470e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -976,6 +976,11 @@ void __init setup_arch(char **cmdline_p)
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
+	if (boot_cpu_data.cpuid_level >= 0) {
+		/* A CPU has %cr4 if and only if it has CPUID */
+		mmu_cr4_features = read_cr4();
+	}
+
 #ifdef CONFIG_X86_32
 	/* sync back kernel address range */
 	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,

commit 93a72052be81823fa1584b9be037d51924f9efa4
Author: Olaf Hering <olaf@aepfle.de>
Date:   Wed Mar 23 16:43:29 2011 -0700

    crash_dump: export is_kdump_kernel to modules, consolidate elfcorehdr_addr, setup_elfcorehdr and saved_max_pfn
    
    The Xen PV drivers in a crashed HVM guest can not connect to the dom0
    backend drivers because both frontend and backend drivers are still in
    connected state.  To run the connection reset function only in case of a
    crashdump, the is_kdump_kernel() function needs to be available for the PV
    driver modules.
    
    Consolidate elfcorehdr_addr, setup_elfcorehdr and saved_max_pfn into
    kernel/crash_dump.c Also export elfcorehdr_addr to make is_kdump_kernel()
    usable for modules.
    
    Leave 'elfcorehdr' as early_param().  This changes powerpc from __setup()
    to early_param().  It adds an address range check from x86 also on ia64
    and powerpc.
    
    [akpm@linux-foundation.org: additional #includes]
    [akpm@linux-foundation.org: remove elfcorehdr_addr export]
    [akpm@linux-foundation.org: fix for Tejun's mm/nobootmem.c changes]
    Signed-off-by: Olaf Hering <olaf@aepfle.de>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 32bd87cbf982..5a0484a95ad6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -619,28 +619,6 @@ void __init reserve_standard_io_resources(void)
 
 }
 
-/*
- * Note: elfcorehdr_addr is not just limited to vmcore. It is also used by
- * is_kdump_kernel() to determine if we are booting after a panic. Hence
- * ifdef it under CONFIG_CRASH_DUMP and not CONFIG_PROC_VMCORE.
- */
-
-#ifdef CONFIG_CRASH_DUMP
-/* elfcorehdr= specifies the location of elf core header
- * stored by the crashed kernel. This option will be passed
- * by kexec loader to the capture kernel.
- */
-static int __init setup_elfcorehdr(char *arg)
-{
-	char *end;
-	if (!arg)
-		return -EINVAL;
-	elfcorehdr_addr = memparse(arg, &end);
-	return end > arg ? 0 : -EINVAL;
-}
-early_param("elfcorehdr", setup_elfcorehdr);
-#endif
-
 static __init void reserve_ibft_region(void)
 {
 	unsigned long addr, size = 0;

commit 73d5a8675f32b8e22e11773b314324316f920192
Merge: e77277dfe28b d8aa5ec3382e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 22 10:41:36 2011 -0700

    Merge branch 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      xen: update mask_rw_pte after kernel page tables init changes
      xen: set max_pfn_mapped to the last pfn mapped
      x86: Cleanup highmap after brk is concluded
    
    Fix up trivial onflict (added header file includes) in
    arch/x86/mm/init_64.c

commit e5f15b45ddf3afa2bbbb10c7ea34fb32b6de0a0e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Feb 18 11:30:30 2011 +0000

    x86: Cleanup highmap after brk is concluded
    
    Now cleanup_highmap actually is in two steps: one is early in head64.c
    and only clears above _end; a second one is in init_memory_mapping() and
    tries to clean from _brk_end to _end.
    It should check if those boundaries are PMD_SIZE aligned but currently
    does not.
    Also init_memory_mapping() is called several times for numa or memory
    hotplug, so we really should not handle initial kernel mappings there.
    
    This patch moves cleanup_highmap() down after _brk_end is settled so
    we can do everything in one step.
    Also we honor max_pfn_mapped in the implementation of cleanup_highmap.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    LKML-Reference: <alpine.DEB.2.00.1103171739050.3382@kaball-desktop>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b176f2b1f45d..4a52a5f9afcb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -294,30 +294,11 @@ static void __init init_gbpages(void)
 	else
 		direct_gbpages = 0;
 }
-
-static void __init cleanup_highmap_brk_end(void)
-{
-	pud_t *pud;
-	pmd_t *pmd;
-
-	mmu_cr4_features = read_cr4();
-
-	/*
-	 * _brk_end cannot change anymore, but it and _end may be
-	 * located on different 2M pages. cleanup_highmap(), however,
-	 * can only consider _end when it runs, so destroy any
-	 * mappings beyond _brk_end here.
-	 */
-	pud = pud_offset(pgd_offset_k(_brk_end), _brk_end);
-	pmd = pmd_offset(pud, _brk_end - 1);
-	while (++pmd <= pmd_offset(pud, (unsigned long)_end - 1))
-		pmd_clear(pmd);
-}
 #else
 static inline void init_gbpages(void)
 {
 }
-static inline void cleanup_highmap_brk_end(void)
+static void __init cleanup_highmap(void)
 {
 }
 #endif
@@ -330,8 +311,6 @@ static void __init reserve_brk(void)
 	/* Mark brk area as locked down and no longer taking any
 	   new allocations */
 	_brk_start = 0;
-
-	cleanup_highmap_brk_end();
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -950,6 +929,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	reserve_brk();
 
+	cleanup_highmap();
+
 	memblock.current_limit = get_max_mapped();
 	memblock_x86_fill();
 

commit e7fd3b4669f5b835c8afce28425d9f698a558115
Merge: fc82e1d59a24 2ae9d293b14d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 16 10:10:02 2011 -0700

    Merge branch 'x86-trampoline-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-trampoline-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Fix binutils-2.21 symbol related build failures
      x86-64, trampoline: Remove unused variable
      x86, reboot: Fix the use of passed arguments in 32-bit BIOS reboot
      x86, reboot: Move the real-mode reboot code to an assembly file
      x86: Make the GDT_ENTRY() macro in <asm/segment.h> safe for assembly
      x86, trampoline: Use the unified trampoline setup for ACPI wakeup
      x86, trampoline: Common infrastructure for low memory trampolines
    
    Fix up trivial conflicts in arch/x86/kernel/Makefile

commit d10902812c9cd5583130a4ebb9ad19c60b68149d
Merge: 181f977d134a 25874a299ef8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 15 20:01:36 2011 -0700

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (27 commits)
      x86: Clean up apic.c and apic.h
      x86: Remove superflous goal definition of tsc_sync
      x86: dt: Correct local apic documentation in device tree bindings
      x86: dt: Cleanup local apic setup
      x86: dt: Fix OLPC=y/INTEL_CE=n build
      rtc: cmos: Add OF bindings
      x86: ce4100: Use OF to setup devices
      x86: ioapic: Add OF bindings for IO_APIC
      x86: dtb: Add generic bus probe
      x86: dtb: Add support for PCI devices backed by dtb nodes
      x86: dtb: Add device tree support for HPET
      x86: dtb: Add early parsing of IO_APIC
      x86: dtb: Add irq domain abstraction
      x86: dtb: Add a device tree for CE4100
      x86: Add device tree support
      x86: e820: Remove conditional early mapping in parse_e820_ext
      x86: OLPC: Make OLPC=n build again
      x86: OLPC: Remove extra OLPC_OPENFIRMWARE_DT indirection
      x86: OLPC: Cleanup config maze completely
      x86: OLPC: Hide OLPC_OPENFIRMWARE config switch
      ...
    
    Fix up conflicts in arch/x86/platform/ce4100/ce4100.c

commit f89112502805c1f6a6955f90ad158e538edb319d
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Mar 4 10:26:36 2011 +0100

    x86-64, NUMA: Revert NUMA affine page table allocation
    
    This patch reverts NUMA affine page table allocation added by commit
    1411e0ec31 (x86-64, numa: Put pgtable to local node memory).
    
    The commit made an undocumented change where the kernel linear mapping
    strictly follows intersection of e820 memory map and NUMA
    configuration.  If the physical memory configuration has holes or NUMA
    nodes are not properly aligned, this leads to using unnecessarily
    smaller mapping size which leads to increased TLB pressure.  For
    details,
    
      http://thread.gmane.org/gmane.linux.kernel/1104672
    
    Patches to fix the problem have been proposed but the underlying code
    needs more cleanup and the approach itself seems a bit heavy handed
    and it has been determined to revert the feature for now and come back
    to it in the next developement cycle.
    
      http://thread.gmane.org/gmane.linux.kernel/1105959
    
    As init_memory_mapping_high() callsites have been consolidated since
    the commit, reverting is done manually.  Also, the RED-PEN comment in
    arch/x86/mm/init.c is not restored as the problem no longer exists
    with memblock based top-down early memory allocation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 46e684f85b36..c3a606c41ce0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -963,6 +963,14 @@ void __init setup_arch(char **cmdline_p)
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;
 
+#ifdef CONFIG_X86_64
+	if (max_pfn > max_low_pfn) {
+		max_pfn_mapped = init_memory_mapping(1UL<<32,
+						     max_pfn<<PAGE_SHIFT);
+		/* can we preseve max_low_pfn ?*/
+		max_low_pfn = max_pfn;
+	}
+#endif
 	memblock.current_limit = get_max_mapped();
 
 	/*

commit a906fdaacca49917d83e5032dfc31f694249ad10
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 25 16:09:31 2011 +0100

    x86: dt: Cleanup local apic setup
    
    Up to now we force enable the local apic in the devicetree setup
    uncoditionally and set smp_found_config unconditionally to 1 when a
    devicetree blob is available. This breaks, when local apic is disabled
    in the Kconfig.
    
    Make it consistent by initializing device tree explicitely before
    smp_get_config() so a non lapic configuration could be used as well.
    To be functional that would require to implement PIT as an interrupt
    host, but the only user of this code until now is ce4100 which
    requires apics to be available. So we leave this up to those who need
    it.
    
    Tested-by: Sebastian Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 33dcbce1ab0f..b3143bc74e6c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1044,8 +1044,8 @@ void __init setup_arch(char **cmdline_p)
 	 * Read APIC and some other early information from ACPI tables.
 	 */
 	acpi_boot_init();
-
 	sfi_init();
+	x86_dtb_init();
 
 	/*
 	 * get boot-time SMP configuration:

commit da6b737b9ab768dd06bb4b0395131d10e524cf83
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Feb 22 21:07:37 2011 +0100

    x86: Add device tree support
    
    This patch adds minimal support for device tree on x86. The device
    tree blob is passed to the kernel via setup_data which requires at
    least boot protocol 2.09.
    
    Memory size, restricted memory regions, boot arguments are gathered
    the traditional way so things like cmd_line are just here to let the
    code compile.
    
    The current plan is use the device tree as an extension and to gather
    information which can not be enumerated and would have to be hardcoded
    otherwise. This includes things like
       - which devices are on this I2C/SPI bus?
       - how are the interrupts wired to IO APIC?
       - where could my hpet be?
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Dirk Brandewie <dirk.brandewie@gmail.com>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: sodaville@linutronix.de
    Cc: devicetree-discuss@lists.ozlabs.org
    LKML-Reference: <1298405266-1624-3-git-send-email-bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9521483ce58c..33dcbce1ab0f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -113,6 +113,7 @@
 #endif
 #include <asm/mce.h>
 #include <asm/alternative.h>
+#include <asm/prom.h>
 
 /*
  * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
@@ -445,6 +446,9 @@ static void __init parse_setup_data(void)
 		case SETUP_E820_EXT:
 			parse_e820_ext(data);
 			break;
+		case SETUP_DTB:
+			add_dtb(pa_data);
+			break;
 		default:
 			break;
 		}

commit f1c2b357148ec27fcc6ce0992211209a0ea20d8f
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Feb 22 21:07:36 2011 +0100

    x86: e820: Remove conditional early mapping in parse_e820_ext
    
    This patch ensures that the memory passed from parse_setup_data() is
    large enough to cover the complete data structure. That means that the
    conditional mapping in parse_e820_ext() can go.
    
    While here, I also attempt not to map two pages if the address is not
    aligned to a page boundary.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Dirk Brandewie <dirk.brandewie@gmail.com>
    Cc: sodaville@linutronix.de
    Cc: devicetree-discuss@lists.ozlabs.org
    LKML-Reference: <1298405266-1624-2-git-send-email-bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ca2f10622a79..9521483ce58c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -429,16 +429,27 @@ static void __init parse_setup_data(void)
 		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		data = early_memremap(pa_data, PAGE_SIZE);
+		u32 data_len, map_len;
+
+		map_len = max(PAGE_SIZE - (pa_data & ~PAGE_MASK),
+			      (u64)sizeof(struct setup_data));
+		data = early_memremap(pa_data, map_len);
+		data_len = data->len + sizeof(struct setup_data);
+		if (data_len > map_len) {
+			early_iounmap(data, map_len);
+			data = early_memremap(pa_data, data_len);
+			map_len = data_len;
+		}
+
 		switch (data->type) {
 		case SETUP_E820_EXT:
-			parse_e820_ext(data, pa_data);
+			parse_e820_ext(data);
 			break;
 		default:
 			break;
 		}
 		pa_data = data->next;
-		early_iounmap(data, PAGE_SIZE);
+		early_iounmap(data, map_len);
 	}
 }
 

commit 695884fb8acd9857e0e7120ccb2150e30f4b8fef
Merge: 5df91509d324 04bea68b2f0e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 22 18:24:26 2011 +0100

    Merge branch 'devicetree/for-x86' of git://git.secretlab.ca/git/linux-2.6 into x86/platform
    
    Reason: x86 devicetree support for ce4100 depends on those device tree
            changes scheduled for .39.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit d1ee433539ea5963a8f946f3428b335d1c5fdb20
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Mon Feb 14 15:42:46 2011 -0800

    x86, trampoline: Use the unified trampoline setup for ACPI wakeup
    
    Use the unified trampoline allocation setup to allocate and install
    the ACPI wakeup code in low memory.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    LKML-Reference: <4D5DFBE4.7090104@intel.com>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Matthieu Castet <castet.matthieu@free.fr>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 994ea20e177c..a089fc19ffae 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -937,13 +937,6 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_trampolines();
 
-#ifdef CONFIG_ACPI_SLEEP
-	/*
-	 * Reserve low memory region for sleep support.
-	 * even before init_memory_mapping
-	 */
-	acpi_reserve_wakeup_memory();
-#endif
 	init_gbpages();
 
 	/* max_pfn_mapped is updated here */

commit 4822b7fc6d4870685a9feadfc348d48f5e47460a
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Mon Feb 14 15:34:57 2011 -0800

    x86, trampoline: Common infrastructure for low memory trampolines
    
    Common infrastructure for low memory trampolines.  This code installs
    the trampolines permanently in low memory very early.  It also permits
    multiple pieces of code to be used for this purpose.
    
    This code also introduces a standard infrastructure for computing
    symbol addresses in the trampoline code.
    
    The only change to the actual SMP trampolines themselves is that the
    64-bit trampoline has been made reusable -- the previous version would
    overwrite the code with a status variable; this moves the status
    variable to a separate location.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    LKML-Reference: <4D5DFBE4.7090104@intel.com>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Matthieu Castet <castet.matthieu@free.fr>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d3cfe26c0252..994ea20e177c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -935,7 +935,7 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
 			max_pfn_mapped<<PAGE_SHIFT);
 
-	reserve_trampoline_memory();
+	setup_trampolines();
 
 #ifdef CONFIG_ACPI_SLEEP
 	/*

commit d8fc3afc49bb226c20e37f48a4ddd493cd092837
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 16 12:13:06 2011 +0100

    x86, NUMA: Move *_numa_init() invocations into initmem_init()
    
    There's no reason for these to live in setup_arch().  Move them inside
    initmem_init().
    
    - v2: x86-32 initmem_init() weren't updated breaking 32bit builds.
      Fixed.  Found by Ankita.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Ankita Garg <ankita@in.ibm.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Shaohui Zheng <shaohui.zheng@intel.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c9a139c3056b..46e684f85b36 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -719,8 +719,6 @@ early_param("reservelow", parse_reservelow);
 
 void __init setup_arch(char **cmdline_p)
 {
-	int acpi = 0;
-	int amd = 0;
 	unsigned long flags;
 
 #ifdef CONFIG_X86_32
@@ -991,19 +989,7 @@ void __init setup_arch(char **cmdline_p)
 
 	early_acpi_boot_init();
 
-#ifdef CONFIG_ACPI_NUMA
-	/*
-	 * Parse SRAT to discover nodes.
-	 */
-	acpi = !x86_acpi_numa_init();
-#endif
-
-#ifdef CONFIG_AMD_NUMA
-	if (!acpi)
-		amd = !amd_numa_init();
-#endif
-
-	initmem_init(acpi, amd);
+	initmem_init();
 	memblock_find_dma_reserve();
 	dma32_reserve_bootmem();
 

commit a9aec56afac238e4ed3980bd10b22121b83866dd
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 16 12:13:06 2011 +0100

    x86-64, NUMA: Wrap acpi_numa_init() so that failure can be indicated by return value
    
    Because of the way ACPI tables are parsed, the generic
    acpi_numa_init() couldn't return failure when error was detected by
    arch hooks.  Instead, the failure state was recorded and later arch
    dependent init hook - acpi_scan_nodes() - would fail.
    
    Wrap acpi_numa_init() with x86_acpi_numa_init() so that failure can be
    indicated as return value immediately.  This is in preparation for
    further NUMA init cleanups.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Shaohui Zheng <shaohui.zheng@intel.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 96810a3c6003..c9a139c3056b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -995,7 +995,7 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Parse SRAT to discover nodes.
 	 */
-	acpi = !acpi_numa_init();
+	acpi = !x86_acpi_numa_init();
 #endif
 
 #ifdef CONFIG_AMD_NUMA

commit 940fed2e79a15cf0d006c860d7811adbe5c19882
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 16 12:13:06 2011 +0100

    x86-64, NUMA: Unify {acpi|amd}_{numa_init|scan_nodes}() arguments and return values
    
    The functions used during NUMA initialization - *_numa_init() and
    *_scan_nodes() - have different arguments and return values.  Unify
    them such that they all take no argument and return 0 on success and
    -errno on failure.  This is in preparation for further NUMA init
    cleanups.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Shaohui Zheng <shaohui.zheng@intel.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 756d640723f9..96810a3c6003 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -995,12 +995,12 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Parse SRAT to discover nodes.
 	 */
-	acpi = acpi_numa_init();
+	acpi = !acpi_numa_init();
 #endif
 
 #ifdef CONFIG_AMD_NUMA
 	if (!acpi)
-		amd = !amd_numa_init(0, max_pfn);
+		amd = !amd_numa_init();
 #endif
 
 	initmem_init(acpi, amd);

commit 86ef4dbf1f736bb1a4d567e043e3dd81b8b7860c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 16 12:13:06 2011 +0100

    x86, NUMA: Drop @start/last_pfn from initmem_init()
    
    initmem_init() extensively accesses and modifies global data
    structures and the parameters aren't even followed depending on which
    path is being used.  Drop @start/last_pfn and let it deal with
    @max_pfn directly.  This is in preparation for further NUMA init
    cleanups.
    
    - v2: x86-32 initmem_init() weren't updated breaking 32bit builds.
      Fixed.  Found by Yinghai.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Shaohui Zheng <shaohui.zheng@intel.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ac909ba297b9..756d640723f9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1003,7 +1003,7 @@ void __init setup_arch(char **cmdline_p)
 		amd = !amd_numa_init(0, max_pfn);
 #endif
 
-	initmem_init(0, max_pfn, acpi, amd);
+	initmem_init(acpi, amd);
 	memblock_find_dma_reserve();
 	dma32_reserve_bootmem();
 

commit 52b8b8d7251f8f7b8ed4a6c623618106d83e18b5
Merge: 02ac81a812fe 14392fd329ec
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Feb 16 09:44:04 2011 +0100

    Merge branch 'x86/numa' into x86/mm
    
    Merge reason: consolidate it into the more generic x86/mm tree to prevent conflicts.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 6b617e224dfac0b64ed70dacdac50be6eb78a6a1
Author: Feng Tang <feng.tang@intel.com>
Date:   Tue Feb 15 00:13:31 2011 +0800

    x86/platform: Add a wallclock_init func to x86_init.timers ops
    
    Some wall clock devices use MMIO based HW register, this new
    function will give them a chance to do some initialization work
    before their get/set_time service get called, which is usually
    in early kernel boot phase.
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 21c6746338af..68d535a77df0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1059,6 +1059,8 @@ void __init setup_arch(char **cmdline_p)
 #endif
 	x86_init.oem.banner();
 
+	x86_init.timers.wallclock_init();
+
 	mcheck_init();
 
 	local_irq_save(flags);

commit d2137d5af4259f50c19addb8246a186c9ffac325
Merge: f005fe12b90c 795abaf1e4e1
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 14 11:55:18 2011 +0100

    Merge branch 'linus' into x86/bootmem
    
    Conflicts:
            arch/x86/mm/numa_64.c
    
    Merge reason: fix the conflict, update to latest -rc and pick up this
                  dependent fix from Yinghai:
    
      e6d2e2b2b1e1: memblock: don't adjust size in memblock_find_base()
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 8db78cc4b4048e3add40bca1bc3e55057c319256
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Jan 23 14:37:42 2011 +0100

    x86: Unify NUMA initialization between 32 and 64bit
    
    Now that everything else is unified, NUMA initialization can be
    unified too.
    
    * numa_init_array() and init_cpu_to_node() are moved from
      numa_64 to numa.
    
    * numa_32::initmem_init() is updated to call numa_init_array()
      and setup_arch() to call init_cpu_to_node() on 32bit too.
    
    * x86_cpu_to_node_map is now initialized to NUMA_NO_NODE on
      32bit too. This is safe now as numa_init_array() will initialize
      it early during boot.
    
    This makes NUMA mapping fully initialized before
    setup_per_cpu_areas() on 32bit too and thus makes the first
    percpu chunk which contains all the static variables and some of
    dynamic area allocated with NUMA affinity correctly considered.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: yinghai@kernel.org
    Cc: brgerst@gmail.com
    Cc: gorcunov@gmail.com
    Cc: shaohui.zheng@intel.com
    Cc: rientjes@google.com
    LKML-Reference: <1295789862-25482-17-git-send-email-tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Reported-by: Eric Dumazet <eric.dumazet@gmail.com>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d3cfe26c0252..12023412fdf7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1040,9 +1040,7 @@ void __init setup_arch(char **cmdline_p)
 
 	prefill_possible_map();
 
-#ifdef CONFIG_X86_64
 	init_cpu_to_node();
-#endif
 
 	init_apic_mappings();
 	ioapic_and_gsi_init();

commit 017892c341033b3e961e695bc0bf1a815efcf92e
Merge: 42cbd8efb074 cb2ded37fd2e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 6 10:51:36 2011 -0800

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Fix APIC ID sizing bug on larger systems, clean up MAX_APICS confusion
      x86, acpi: Parse all SRAT cpu entries even above the cpu number limitation
      x86, acpi: Add MAX_LOCAL_APIC for 32bit
      x86: io_apic: Split setup_ioapic_ids_from_mpc()
      x86: io_apic: Fix CONFIG_X86_IO_APIC=n breakage
      x86: apic: Move probe_nr_irqs_gsi() into ioapic_init_mappings()
      x86: Allow platforms to force enable apic

commit 42cbd8efb0746b55112de45173219f76c54390da
Merge: dda5f0a37287 f658bcfb2607
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 6 10:50:28 2011 -0800

    Merge branch 'x86-amd-nb-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-amd-nb-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, cacheinfo: Cleanup L3 cache index disable support
      x86, amd-nb: Cleanup AMD northbridge caching code
      x86, amd-nb: Complete the rename of AMD NB and related code

commit f005fe12b90c5b9fe180a09209a893e09affa8aa
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Dec 27 16:48:32 2010 -0800

    x86-64: Move out cleanup higmap [_brk_end, _end) out of init_memory_mapping()
    
    It is not related to init_memory_mapping(),  and init_memory_mapping() is
    getting more bigger.
    
    So make it as seperated function and call it from reserve_brk() and that is
    point when _brk_end is concluded.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4D1933E0.7090305@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fc0fe743f3a1..635185ba4435 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -293,10 +293,32 @@ static void __init init_gbpages(void)
 	else
 		direct_gbpages = 0;
 }
+
+static void __init cleanup_highmap_brk_end(void)
+{
+	pud_t *pud;
+	pmd_t *pmd;
+
+	mmu_cr4_features = read_cr4();
+
+	/*
+	 * _brk_end cannot change anymore, but it and _end may be
+	 * located on different 2M pages. cleanup_highmap(), however,
+	 * can only consider _end when it runs, so destroy any
+	 * mappings beyond _brk_end here.
+	 */
+	pud = pud_offset(pgd_offset_k(_brk_end), _brk_end);
+	pmd = pmd_offset(pud, _brk_end - 1);
+	while (++pmd <= pmd_offset(pud, (unsigned long)_end - 1))
+		pmd_clear(pmd);
+}
 #else
 static inline void init_gbpages(void)
 {
 }
+static inline void cleanup_highmap_brk_end(void)
+{
+}
 #endif
 
 static void __init reserve_brk(void)
@@ -307,6 +329,8 @@ static void __init reserve_brk(void)
 	/* Mark brk area as locked down and no longer taking any
 	   new allocations */
 	_brk_start = 0;
+
+	cleanup_highmap_brk_end();
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD

commit bc030d6cb9532877c1c5a3f5e7123344fa24a285
Merge: d3bd058826aa 387c31c7e5c9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 4 09:43:42 2011 +0100

    Merge commit 'v2.6.37-rc8' into x86/apic
    
    Conflicts:
            arch/x86/include/asm/io_apic.h
    
    Merge reason: move to a fresh -rc, resolve the conflict.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 1411e0ec3123ae4c4ead6bfc9fe3ee5a3ae5c327
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Dec 27 16:48:17 2010 -0800

    x86-64, numa: Put pgtable to local node memory
    
    Introduce init_memory_mapping_high(), and use it with 64bit.
    
    It will go with every memory segment above 4g to create page table to the
    memory range itself.
    
    before this patch all page tables was on one node.
    
    with this patch, one RED-PEN is killed
    
    debug out for 8 sockets system after patch
    [    0.000000] initial memory mapped : 0 - 20000000
    [    0.000000] init_memory_mapping: [0x00000000000000-0x0000007f74ffff]
    [    0.000000]  0000000000 - 007f600000 page 2M
    [    0.000000]  007f600000 - 007f750000 page 4k
    [    0.000000] kernel direct mapping tables up to 7f750000 @ [0x7f74c000-0x7f74ffff]
    [    0.000000] RAMDISK: 7bc84000 - 7f745000
    ....
    [    0.000000] Adding active range (0, 0x10, 0x95) 0 entries of 3200 used
    [    0.000000] Adding active range (0, 0x100, 0x7f750) 1 entries of 3200 used
    [    0.000000] Adding active range (0, 0x100000, 0x1080000) 2 entries of 3200 used
    [    0.000000] Adding active range (1, 0x1080000, 0x2080000) 3 entries of 3200 used
    [    0.000000] Adding active range (2, 0x2080000, 0x3080000) 4 entries of 3200 used
    [    0.000000] Adding active range (3, 0x3080000, 0x4080000) 5 entries of 3200 used
    [    0.000000] Adding active range (4, 0x4080000, 0x5080000) 6 entries of 3200 used
    [    0.000000] Adding active range (5, 0x5080000, 0x6080000) 7 entries of 3200 used
    [    0.000000] Adding active range (6, 0x6080000, 0x7080000) 8 entries of 3200 used
    [    0.000000] Adding active range (7, 0x7080000, 0x8080000) 9 entries of 3200 used
    [    0.000000] init_memory_mapping: [0x00000100000000-0x0000107fffffff]
    [    0.000000]  0100000000 - 1080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 1080000000 @ [0x107ffbd000-0x107fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x107ffc2000-0x107fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00001080000000-0x0000207fffffff]
    [    0.000000]  1080000000 - 2080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 2080000000 @ [0x207ff7d000-0x207fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x207ffc0000-0x207fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00002080000000-0x0000307fffffff]
    [    0.000000]  2080000000 - 3080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 3080000000 @ [0x307ff3d000-0x307fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x307ffc0000-0x307fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00003080000000-0x0000407fffffff]
    [    0.000000]  3080000000 - 4080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 4080000000 @ [0x407fefd000-0x407fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x407ffc0000-0x407fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00004080000000-0x0000507fffffff]
    [    0.000000]  4080000000 - 5080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 5080000000 @ [0x507febd000-0x507fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x507ffc0000-0x507fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00005080000000-0x0000607fffffff]
    [    0.000000]  5080000000 - 6080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 6080000000 @ [0x607fe7d000-0x607fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x607ffc0000-0x607fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00006080000000-0x0000707fffffff]
    [    0.000000]  6080000000 - 7080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 7080000000 @ [0x707fe3d000-0x707fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x707ffc0000-0x707fffffff]          PGTABLE
    [    0.000000] init_memory_mapping: [0x00007080000000-0x0000807fffffff]
    [    0.000000]  7080000000 - 8080000000 page 2M
    [    0.000000] kernel direct mapping tables up to 8080000000 @ [0x807fdfc000-0x807fffffff]
    [    0.000000]     memblock_x86_reserve_range: [0x807ffbf000-0x807fffffff]          PGTABLE
    [    0.000000] Initmem setup node 0 [0000000000000000-000000107fffffff]
    [    0.000000]   NODE_DATA [0x0000107ffbd000-0x0000107ffc1fff]
    [    0.000000] Initmem setup node 1 [0000001080000000-000000207fffffff]
    [    0.000000]   NODE_DATA [0x0000207ffbb000-0x0000207ffbffff]
    [    0.000000] Initmem setup node 2 [0000002080000000-000000307fffffff]
    [    0.000000]   NODE_DATA [0x0000307ffbb000-0x0000307ffbffff]
    [    0.000000] Initmem setup node 3 [0000003080000000-000000407fffffff]
    [    0.000000]   NODE_DATA [0x0000407ffbb000-0x0000407ffbffff]
    [    0.000000] Initmem setup node 4 [0000004080000000-000000507fffffff]
    [    0.000000]   NODE_DATA [0x0000507ffbb000-0x0000507ffbffff]
    [    0.000000] Initmem setup node 5 [0000005080000000-000000607fffffff]
    [    0.000000]   NODE_DATA [0x0000607ffbb000-0x0000607ffbffff]
    [    0.000000] Initmem setup node 6 [0000006080000000-000000707fffffff]
    [    0.000000]   NODE_DATA [0x0000707ffbb000-0x0000707ffbffff]
    [    0.000000] Initmem setup node 7 [0000007080000000-000000807fffffff]
    [    0.000000]   NODE_DATA [0x0000807ffba000-0x0000807ffbefff]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4D1933D1.9020609@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3def8c9a5dc9..fc0fe743f3a1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -931,14 +931,6 @@ void __init setup_arch(char **cmdline_p)
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;
 
-#ifdef CONFIG_X86_64
-	if (max_pfn > max_low_pfn) {
-		max_pfn_mapped = init_memory_mapping(1UL<<32,
-						     max_pfn<<PAGE_SHIFT);
-		/* can we preseve max_low_pfn ?*/
-		max_low_pfn = max_pfn;
-	}
-#endif
 	memblock.current_limit = get_max_mapped();
 
 	/*

commit 45635ab5e41bcde94a82f9a05d660ef77fe38c1b
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Dec 27 16:47:54 2010 -0800

    x86: Change get_max_mapped() to inline
    
    Move it into head file. to prepare use it in other files.
    
    [ hpa: added missing <linux/types.h> and changed type to phys_addr_t. ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4D1933BA.8000508@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index df172c1e8238..3def8c9a5dc9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -669,15 +669,6 @@ static int __init parse_reservelow(char *p)
 
 early_param("reservelow", parse_reservelow);
 
-static u64 __init get_max_mapped(void)
-{
-	u64 end = max_pfn_mapped;
-
-	end <<= PAGE_SHIFT;
-
-	return end;
-}
-
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit 79534f237f05cac7f728cc957efdcc17603e38cd
Merge: 3fc5e98d8cf8 2ce494a3dac3 7f8595bfacef
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 23 15:39:40 2010 -0800

    Merge branches 'perf-fixes-for-linus' and 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'perf-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      perf probe: Fix to support libdwfl older than 0.148
      perf tools: Fix lazy wildcard matching
      perf buildid-list: Fix error return for success
      perf buildid-cache: Fix symbolic link handling
      perf symbols: Stop using vmlinux files with no symbols
      perf probe: Fix use of kernel image path given by 'k' option
    
    * 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, kexec: Limit the crashkernel address appropriately

commit 7f8595bfacef279f06c82ec98d420ef54f2537e0
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Thu Dec 16 19:20:41 2010 -0800

    x86, kexec: Limit the crashkernel address appropriately
    
    Keep the crash kernel address below 512 MiB for 32 bits and 896 MiB
    for 64 bits.  For 32 bits, this retains compatibility with earlier
    kernel releases, and makes it work even if the vmalloc= setting is
    adjusted.
    
    For 64 bits, we should be able to increase this substantially once a
    hard-coded limit in kexec-tools is fixed.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <20101217195035.GE14502@redhat.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 21c6746338af..c9089a13bad9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -501,7 +501,18 @@ static inline unsigned long long get_total_mem(void)
 	return total << PAGE_SHIFT;
 }
 
-#define DEFAULT_BZIMAGE_ADDR_MAX 0x37FFFFFF
+/*
+ * Keep the crash kernel below this limit.  On 32 bits earlier kernels
+ * would limit the kernel to the low 512 MiB due to mapping restrictions.
+ * On 64 bits, kexec-tools currently limits us to 896 MiB; increase this
+ * limit once kexec-tools are fixed.
+ */
+#ifdef CONFIG_X86_32
+# define CRASH_KERNEL_ADDR_MAX	(512 << 20)
+#else
+# define CRASH_KERNEL_ADDR_MAX	(896 << 20)
+#endif
+
 static void __init reserve_crashkernel(void)
 {
 	unsigned long long total_mem;
@@ -520,10 +531,10 @@ static void __init reserve_crashkernel(void)
 		const unsigned long long alignment = 16<<20;	/* 16M */
 
 		/*
-		 *  kexec want bzImage is below DEFAULT_BZIMAGE_ADDR_MAX
+		 *  kexec want bzImage is below CRASH_KERNEL_ADDR_MAX
 		 */
 		crash_base = memblock_find_in_range(alignment,
-			       DEFAULT_BZIMAGE_ADDR_MAX, crash_size, alignment);
+			       CRASH_KERNEL_ADDR_MAX, crash_size, alignment);
 
 		if (crash_base == MEMBLOCK_ERROR) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");

commit 5e52f1c5e85fdc3831eeae8b546577e94a586f81
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Thu Dec 16 10:38:25 2010 -0700

    Revert "x86: allocate space within a region top-down"
    
    This reverts commit 1af3c2e45e7a641e774bbb84fa428f2f0bf2d9c9.
    
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 21c6746338af..85268f8eadf6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -769,7 +769,6 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.oem.arch_setup();
 
-	resource_alloc_from_bottom = 0;
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();

commit eec1d4fa00c6552ae2fdf71d59f1eded7c88dd89
Author: Hans Rosenfeld <hans.rosenfeld@amd.com>
Date:   Fri Oct 29 17:14:30 2010 +0200

    x86, amd-nb: Complete the rename of AMD NB and related code
    
    Not only the naming of the files was confusing, it was even more so for
    the function and variable names.
    
    Renamed the K8 NB and NUMA stuff that is also used on other AMD
    platforms. This also renames the CONFIG_K8_NUMA option to
    CONFIG_AMD_NUMA and the related file k8topology_64.c to
    amdtopology_64.c. No functional changes intended.
    
    Signed-off-by: Hans Rosenfeld <hans.rosenfeld@amd.com>
    Signed-off-by: Borislav Petkov <borislav.petkov@amd.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 21c6746338af..df172c1e8238 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -694,7 +694,7 @@ static u64 __init get_max_mapped(void)
 void __init setup_arch(char **cmdline_p)
 {
 	int acpi = 0;
-	int k8 = 0;
+	int amd = 0;
 	unsigned long flags;
 
 #ifdef CONFIG_X86_32
@@ -981,12 +981,12 @@ void __init setup_arch(char **cmdline_p)
 	acpi = acpi_numa_init();
 #endif
 
-#ifdef CONFIG_K8_NUMA
+#ifdef CONFIG_AMD_NUMA
 	if (!acpi)
-		k8 = !k8_numa_init(0, max_pfn);
+		amd = !amd_numa_init(0, max_pfn);
 #endif
 
-	initmem_init(0, max_pfn, acpi, k8);
+	initmem_init(0, max_pfn, acpi, amd);
 	memblock_find_dma_reserve();
 	dma32_reserve_bootmem();
 

commit e9f29c9a56ca06d0effa557823a737cbe7ec09f7
Merge: 800416f799e0 1af3c2e45e7a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 28 11:59:52 2010 -0700

    Merge branch 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6
    
    * 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6: (27 commits)
      x86: allocate space within a region top-down
      x86: update iomem_resource end based on CPU physical address capabilities
      x86/PCI: allocate space from the end of a region, not the beginning
      PCI: allocate bus resources from the top down
      resources: support allocating space within a region from the top down
      resources: handle overflow when aligning start of available area
      resources: ensure callback doesn't allocate outside available space
      resources: factor out resource_clip() to simplify find_resource()
      resources: add a default alignf to simplify find_resource()
      x86/PCI: MMCONFIG: fix region end calculation
      PCI: Add support for polling PME state on suspended legacy PCI devices
      PCI: Export some PCI PM functionality
      PCI: fix message typo
      PCI: log vendor/device ID always
      PCI: update Intel chipset names and defines
      PCI: use new ccflags variable in Makefile
      PCI: add PCI_MSIX_TABLE/PBA defines
      PCI: add PCI vendor id for STmicroelectronics
      x86/PCI: irq and pci_ids patch for Intel Patsburg DeviceIDs
      PCI: OLPC: Only enable PCI configuration type override on XO-1
      ...

commit 1af3c2e45e7a641e774bbb84fa428f2f0bf2d9c9
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Tue Oct 26 15:41:54 2010 -0600

    x86: allocate space within a region top-down
    
    Request that allocate_resource() use available space from high addresses
    first, rather than the default of using low addresses first.
    
    The most common place this makes a difference is when we move or assign
    new PCI device resources.  Low addresses are generally scarce, so it's
    better to use high addresses when possible.  This follows Windows practice
    for PCI allocation.
    
    Reference: https://bugzilla.kernel.org/show_bug.cgi?id=16228#c42
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 922b5a1f978b..0fe76df866db 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -788,6 +788,7 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.oem.arch_setup();
 
+	resource_alloc_from_bottom = 0;
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();

commit 419afdf53cca794a190014593b4778e2e9d64cf3
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Tue Oct 26 15:41:49 2010 -0600

    x86: update iomem_resource end based on CPU physical address capabilities
    
    The iomem_resource map reflects the available physical address space.
    We statically initialize the end to -1, i.e., 0xffffffff_ffffffff, but
    of course we can only use as much as the CPU can address.
    
    This patch updates the end based on the CPU capabilities, so we don't
    mistakenly allocate space that isn't usable, as we're likely to do when
    allocating from the top-down.
    
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c3a4fbb2b996..922b5a1f978b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -788,6 +788,7 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_init.oem.arch_setup();
 
+	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
 	setup_memory_map();
 	parse_setup_data();
 	/* update the e820_saved too */

commit 23f9b267159b4c7ff59d2e6c8ed31693eff841e3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 15 15:38:50 2010 -0700

    x86: apic: Move probe_nr_irqs_gsi() into ioapic_init_mappings()
    
    probe_br_irqs_gsi() is called right after ioapic_init_mappings() and
    there are no other users. Move it into ioapic_init_mappings() so the
    declaration can disappear and the function can become static.
    
    Rename ioapic_init_mappings() to ioapic_and_gsi_init() to reflect that
    change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <1287510389-8388-2-git-send-email-dirk.brandewie@gmail.com>
    Signed-off-by: Dirk Brandewie <dirk.j.brandewie@intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 420e64197850..b8982e0fc0c2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1017,10 +1017,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	init_apic_mappings();
-	ioapic_init_mappings();
-
-	/* need to wait for io_apic is mapped */
-	probe_nr_irqs_gsi();
+	ioapic_and_gsi_init();
 
 	kvm_guest_init();
 

commit 10f2a2b0f68abf39c06cf519cbc1740fa50f900b
Merge: 8814011679d1 b40827fa7268
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 22 20:37:50 2010 -0700

    Merge branch 'x86-trampoline-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-trampoline-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86-32, mm: Add an initial page table for core bootstrapping

commit 3044100e58c84e133791c8b60a2f5bef69d732e4
Merge: b5153163ed58 67e87f0a1c5c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 18:52:11 2010 -0700

    Merge branch 'core-memblock-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-memblock-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (74 commits)
      x86-64: Only set max_pfn_mapped to 512 MiB if we enter via head_64.S
      xen: Cope with unmapped pages when initializing kernel pagetable
      memblock, bootmem: Round pfn properly for memory and reserved regions
      memblock: Annotate memblock functions with __init_memblock
      memblock: Allow memblock_init to be called early
      memblock/arm: Fix memblock_region_is_memory() typo
      x86, memblock: Remove __memblock_x86_find_in_range_size()
      memblock: Fix wraparound in find_region()
      x86-32, memblock: Make add_highpages honor early reserved ranges
      x86, memblock: Fix crashkernel allocation
      arm, memblock: Fix the sparsemem build
      memblock: Fix section mismatch warnings
      powerpc, memblock: Fix memblock API change fallout
      memblock, microblaze: Fix memblock API change fallout
      x86: Remove old bootmem code
      x86, memblock: Use memblock_memory_size()/memblock_free_memory_size() to get correct dma_reserve
      x86: Remove not used early_res code
      x86, memblock: Replace e820_/_early string with memblock_
      x86: Use memblock to replace early_res
      x86, memblock: Use memblock_debug to control debug message print out
      ...
    
    Fix up trivial conflicts in arch/x86/kernel/setup.c and kernel/Makefile

commit 709d9f54cc1847a2d24224ffedec7fd4d0f3c714
Merge: cca8209ed962 b0f4c062fb6d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 13:53:24 2010 -0700

    Merge branch 'x86-vmware-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-vmware-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, paravirt: Remove alloc_pmd_clone hook, only used by VMI
      x86, vmware: Remove deprecated VMI kernel support
    
    Fix up trivial #include conflict in arch/x86/kernel/smpboot.c

commit d60a2793ba562c6ea9bbf62112da3e6342adcf83
Merge: 781c5a67f152 40ffa9379198
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 13:18:06 2010 -0700

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Remove stale pmtimer_64.c
      x86, cleanups: Use clear_page/copy_page rather than memset/memcpy
      x86: Remove unnecessary #ifdef ACPI/X86_IO_ACPI
      x86, cleanup: Remove obsolete boot_cpu_id variable

commit 781c5a67f152c17c3e4a9ed9647f8c0be6ea5ae9
Merge: e990c77d06db 9ea77bdb39b6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 13:06:49 2010 -0700

    Merge branch 'x86-bios-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-bios-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, bios: Make the x86 early memory reservation a kernel option
      x86, bios: By default, reserve the low 64K for all BIOSes

commit 2f0384e5fc4766ad909597547d0e2b716c036755
Merge: bc4016f48161 5c80cc78de46
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 13:01:08 2010 -0700

    Merge branch 'x86-amd-nb-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-amd-nb-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, amd_nb: Enable GART support for AMD family 0x15 CPUs
      x86, amd: Use compute unit information to determine thread siblings
      x86, amd: Extract compute unit information for AMD CPUs
      x86, amd: Add support for CPUID topology extension of AMD CPUs
      x86, nmi: Support NMI watchdog on newer AMD CPU families
      x86, mtrr: Assume SYS_CFG[Tom2ForceMemTypeWB] exists on all future AMD CPUs
      x86, k8: Rename k8.[ch] to amd_nb.[ch] and CONFIG_K8_NB to CONFIG_AMD_NB
      x86, k8-gart: Decouple handling of garts and northbridges
      x86, cacheinfo: Fix dependency of AMD L3 CID
      x86, kvm: add new AMD SVM feature bits
      x86, cpu: Fix allowed CPUID bits for KVM guests
      x86, cpu: Update AMD CPUID feature bits
      x86, cpu: Fix renamed, not-yet-shipping AMD CPUID feature bit
      x86, AMD: Remove needless CPU family check (for L3 cache info)
      x86, tsc: Remove CPU frequency calibration on AMD

commit b40827fa7268fda8a62490728a61c2856f33830b
Author: Borislav Petkov <bp@alien8.de>
Date:   Sat Aug 28 15:58:33 2010 +0200

    x86-32, mm: Add an initial page table for core bootstrapping
    
    This patch adds an initial page table with low mappings used exclusively
    for booting APs/resuming after ACPI suspend/machine restart. After this,
    there's no need to add low mappings to swapper_pg_dir and zap them later
    or create own swsusp PGD page solely for ACPI sleep needs - we have
    initial_page_table for that.
    
    Signed-off-by: Borislav Petkov <bp@alien8.de>
    LKML-Reference: <20101020070526.GA9588@liondog.tnic>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 322b24fbeafd..af6cf2bfceee 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -728,6 +728,17 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
+
+	/*
+	 * copy kernel address range established so far and switch
+	 * to the proper swapper page table
+	 */
+	clone_pgd_range(swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
+			initial_page_table + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
+
+	load_cr3(swapper_pg_dir);
+	__flush_tlb_all();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
@@ -1009,7 +1020,12 @@ void __init setup_arch(char **cmdline_p)
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
-	setup_trampoline_page_table();
+#ifdef CONFIG_X86_32
+	/* sync back kernel address range */
+	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
+#endif
 
 	tboot_probe();
 

commit d25e6b0b326278a1096e8334584c3e64517057a3
Merge: e44dea35ccb7 40ffa9379198
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Oct 20 14:22:45 2010 -0700

    Merge branch 'x86/cleanups' into x86/trampoline

commit 67e87f0a1c5cbc750f81ebf6a128e8ff6f4376cc
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Oct 13 16:34:15 2010 -0700

    x86-64: Only set max_pfn_mapped to 512 MiB if we enter via head_64.S
    
    head_64.S maps up to 512 MiB, but that is not necessarity true for
    other entry paths, such as Xen.
    
    Thus, co-locate the setting of max_pfn_mapped with the code to
    actually set up the page tables in head_64.S.  The 32-bit code is
    already so co-located.  (The Xen code already sets max_pfn_mapped
    correctly for its own use case.)
    
    -v2:
    
     Yinghai fixed the following bug in this patch:
    
     |
     | max_pfn_mapped is in .bss section, so we need to set that
     | after bss get cleared. Without that we crash on bootup.
     |
     | That is safe because Xen does not call x86_64_start_kernel().
     |
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Fixed-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    LKML-Reference: <4CB6AB24.9020504@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b11a238b2e35..c3cebfe7bfc9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -932,7 +932,6 @@ void __init setup_arch(char **cmdline_p)
 		max_low_pfn = max_pfn;
 
 	high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
-	max_pfn_mapped = KERNEL_IMAGE_SIZE >> PAGE_SHIFT;
 #endif
 
 	/*

commit 9f4c13964b58608fbce05540743281ea3146c0e8
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Oct 5 16:05:14 2010 -0700

    x86, memblock: Fix crashkernel allocation
    
    Cai Qian found crashkernel is broken with the x86 memblock changes.
    
    1. crashkernel=128M@32M always reported that range is used, even if
       the first kernel is small and does not usethat range
    
    2. we always got following report when using "kexec -p"
            Could not find a free area of memory of a000 bytes...
            locate_hole failed
    
    The root cause is that generic memblock_find_in_range() will try to
    allocate from the top of the range, whereas the kexec code was written
    assuming that allocation was always near the bottom and that it could
    blindly extend memory upward.  Unfortunately the kexec code doesn't
    have a system for requesting the range that it really needs, so this
    is subject to probabilistic failures.
    
    This patch hacks around the problem by limiting the target range
    heuristically to below the traditional bzImage max range.  This number
    is arbitrary and not always correct, and a much better result would be
    obtained by having kexec communicate this number based on the kernel
    header information and any appropriate command line options.
    
    Reported-and-Bisected-by: CAI Qian <caiqian@redhat.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4CABAF2A.5090501@kernel.org>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bf89e0a59b88..b11a238b2e35 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -502,6 +502,7 @@ static inline unsigned long long get_total_mem(void)
 	return total << PAGE_SHIFT;
 }
 
+#define DEFAULT_BZIMAGE_ADDR_MAX 0x37FFFFFF
 static void __init reserve_crashkernel(void)
 {
 	unsigned long long total_mem;
@@ -519,8 +520,12 @@ static void __init reserve_crashkernel(void)
 	if (crash_base <= 0) {
 		const unsigned long long alignment = 16<<20;	/* 16M */
 
-		crash_base = memblock_find_in_range(alignment, ULONG_MAX, crash_size,
-				 alignment);
+		/*
+		 *  kexec want bzImage is below DEFAULT_BZIMAGE_ADDR_MAX
+		 */
+		crash_base = memblock_find_in_range(alignment,
+			       DEFAULT_BZIMAGE_ADDR_MAX, crash_size, alignment);
+
 		if (crash_base == MEMBLOCK_ERROR) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
@@ -528,8 +533,8 @@ static void __init reserve_crashkernel(void)
 	} else {
 		unsigned long long start;
 
-		start = memblock_find_in_range(crash_base, ULONG_MAX, crash_size,
-				 1<<20);
+		start = memblock_find_in_range(crash_base,
+				 crash_base + crash_size, crash_size, 1<<20);
 		if (start != crash_base) {
 			pr_info("crashkernel reservation failed - memory is in use.\n");
 			return;

commit f49aa448561fe9215f43405cac6f31eb86317792
Author: Jason Baron <jbaron@redhat.com>
Date:   Fri Sep 17 11:08:51 2010 -0400

    jump label: Make dynamic no-op selection available outside of ftrace
    
    Move Steve's code for finding the best 5-byte no-op from ftrace.c to
    alternative.c. The idea is that other consumers (in this case jump label)
    want to make use of that code.
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    LKML-Reference: <96259ae74172dcac99c0020c249743c523a92e18.1284733808.git.jbaron@redhat.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c3a4fbb2b996..00e167870f71 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -112,6 +112,7 @@
 #include <asm/numa_64.h>
 #endif
 #include <asm/mce.h>
+#include <asm/alternative.h>
 
 /*
  * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
@@ -726,6 +727,7 @@ void __init setup_arch(char **cmdline_p)
 {
 	int acpi = 0;
 	int k8 = 0;
+	unsigned long flags;
 
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
@@ -1071,6 +1073,10 @@ void __init setup_arch(char **cmdline_p)
 	x86_init.oem.banner();
 
 	mcheck_init();
+
+	local_irq_save(flags);
+	arch_init_ideal_nop5();
+	local_irq_restore(flags);
 }
 
 #ifdef CONFIG_X86_32

commit 23ac4ae827e6264e21b898f2cd3f601450aa02a6
Author: Andreas Herrmann <andreas.herrmann3@amd.com>
Date:   Fri Sep 17 18:03:43 2010 +0200

    x86, k8: Rename k8.[ch] to amd_nb.[ch] and CONFIG_K8_NB to CONFIG_AMD_NB
    
    The file names are somehow misleading as the code is not specific to
    AMD K8 CPUs anymore. The files accomodate code for other AMD CPU
    northbridges as well.
    
    Same is true for the config option which is valid for AMD CPU
    northbridges in general and not specific to K8.
    
    Signed-off-by: Andreas Herrmann <andreas.herrmann3@amd.com>
    LKML-Reference: <20100917160343.GD4958@loge.amd.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c3a4fbb2b996..77eea0362a49 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -107,7 +107,7 @@
 #include <asm/percpu.h>
 #include <asm/topology.h>
 #include <asm/apicdef.h>
-#include <asm/k8.h>
+#include <asm/amd_nb.h>
 #ifdef CONFIG_X86_64
 #include <asm/numa_64.h>
 #endif

commit daab7fc734a53fdeaf844b7c03053118ad1769da
Merge: 774ea0bcb27f 2bfc96a127bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Aug 31 09:45:21 2010 +0200

    Merge commit 'v2.6.36-rc3' into x86/memblock
    
    Conflicts:
            arch/x86/kernel/trampoline.c
            mm/memblock.c
    
    Merge reason: Resolve the conflicts, update to latest upstream.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 774ea0bcb27f57b6fd521b3b6c43237782fed4b9
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Aug 25 13:39:18 2010 -0700

    x86: Remove old bootmem code
    
    Requested by Ingo, Thomas and HPA.
    
    The old bootmem code is no longer necessary, and the transition is
    complete.  Remove it.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 924c8f78e98e..1d114ff6a078 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1014,10 +1014,6 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init(0, max_pfn, acpi, k8);
 	memblock_find_dma_reserve();
-#ifndef CONFIG_NO_BOOTMEM
-	memblock_x86_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
-#endif
-
 	dma32_reserve_bootmem();
 
 #ifdef CONFIG_KVM_CLOCK

commit 6f2a75369e7561e800d86927ecd83c970996b21f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Aug 25 13:39:18 2010 -0700

    x86, memblock: Use memblock_memory_size()/memblock_free_memory_size() to get correct dma_reserve
    
    memblock_memory_size() will return memory size in memblock.memory.region.
    memblock_free_memory_size() will return free memory size in memblock.memory.region.
    
    So We can get exact reseved size in specified range.
    
    Set the size right after initmem_init(), because later bootmem API will
    get area above 16M. (except some fallback).
    
    Later after we remove the bootmem, We could call that just before paging_init().
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a4f01733e879..924c8f78e98e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1013,6 +1013,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	initmem_init(0, max_pfn, acpi, k8);
+	memblock_find_dma_reserve();
 #ifndef CONFIG_NO_BOOTMEM
 	memblock_x86_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
 #endif

commit a9ce6bc15100023b411f8117e53a016d61889800
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Aug 25 13:39:17 2010 -0700

    x86, memblock: Replace e820_/_early string with memblock_
    
    1.include linux/memblock.h directly. so later could reduce e820.h reference.
    2 this patch is done by sed scripts mainly
    
    -v2: use MEMBLOCK_ERROR instead of -1ULL or -1UL
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bbe0aaf77494..a4f01733e879 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -302,7 +302,7 @@ static inline void init_gbpages(void)
 static void __init reserve_brk(void)
 {
 	if (_brk_end > _brk_start)
-		reserve_early(__pa(_brk_start), __pa(_brk_end), "BRK");
+		memblock_x86_reserve_range(__pa(_brk_start), __pa(_brk_end), "BRK");
 
 	/* Mark brk area as locked down and no longer taking any
 	   new allocations */
@@ -324,17 +324,16 @@ static void __init relocate_initrd(void)
 	char *p, *q;
 
 	/* We need to move the initrd down into lowmem */
-	ramdisk_here = find_e820_area(0, end_of_lowmem, area_size,
+	ramdisk_here = memblock_find_in_range(0, end_of_lowmem, area_size,
 					 PAGE_SIZE);
 
-	if (ramdisk_here == -1ULL)
+	if (ramdisk_here == MEMBLOCK_ERROR)
 		panic("Cannot find place for new RAMDISK of size %lld\n",
 			 ramdisk_size);
 
 	/* Note: this includes all the lowmem currently occupied by
 	   the initrd, we rely on that fact to keep the data intact. */
-	reserve_early(ramdisk_here, ramdisk_here + area_size,
-			 "NEW RAMDISK");
+	memblock_x86_reserve_range(ramdisk_here, ramdisk_here + area_size, "NEW RAMDISK");
 	initrd_start = ramdisk_here + PAGE_OFFSET;
 	initrd_end   = initrd_start + ramdisk_size;
 	printk(KERN_INFO "Allocated new RAMDISK: %08llx - %08llx\n",
@@ -390,7 +389,7 @@ static void __init reserve_initrd(void)
 	initrd_start = 0;
 
 	if (ramdisk_size >= (end_of_lowmem>>1)) {
-		free_early(ramdisk_image, ramdisk_end);
+		memblock_x86_free_range(ramdisk_image, ramdisk_end);
 		printk(KERN_ERR "initrd too large to handle, "
 		       "disabling initrd\n");
 		return;
@@ -413,7 +412,7 @@ static void __init reserve_initrd(void)
 
 	relocate_initrd();
 
-	free_early(ramdisk_image, ramdisk_end);
+	memblock_x86_free_range(ramdisk_image, ramdisk_end);
 }
 #else
 static void __init reserve_initrd(void)
@@ -469,7 +468,7 @@ static void __init e820_reserve_setup_data(void)
 	e820_print_map("reserve setup_data");
 }
 
-static void __init reserve_early_setup_data(void)
+static void __init memblock_x86_reserve_range_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
@@ -481,7 +480,7 @@ static void __init reserve_early_setup_data(void)
 	while (pa_data) {
 		data = early_memremap(pa_data, sizeof(*data));
 		sprintf(buf, "setup data %x", data->type);
-		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
+		memblock_x86_reserve_range(pa_data, pa_data+sizeof(*data)+data->len, buf);
 		pa_data = data->next;
 		early_iounmap(data, sizeof(*data));
 	}
@@ -519,23 +518,23 @@ static void __init reserve_crashkernel(void)
 	if (crash_base <= 0) {
 		const unsigned long long alignment = 16<<20;	/* 16M */
 
-		crash_base = find_e820_area(alignment, ULONG_MAX, crash_size,
+		crash_base = memblock_find_in_range(alignment, ULONG_MAX, crash_size,
 				 alignment);
-		if (crash_base == -1ULL) {
+		if (crash_base == MEMBLOCK_ERROR) {
 			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
 		}
 	} else {
 		unsigned long long start;
 
-		start = find_e820_area(crash_base, ULONG_MAX, crash_size,
+		start = memblock_find_in_range(crash_base, ULONG_MAX, crash_size,
 				 1<<20);
 		if (start != crash_base) {
 			pr_info("crashkernel reservation failed - memory is in use.\n");
 			return;
 		}
 	}
-	reserve_early(crash_base, crash_base + crash_size, "CRASH KERNEL");
+	memblock_x86_reserve_range(crash_base, crash_base + crash_size, "CRASH KERNEL");
 
 	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
 			"for crashkernel (System RAM: %ldMB)\n",
@@ -786,7 +785,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 	 4)) {
 		efi_enabled = 1;
-		efi_reserve_early();
+		efi_memblock_x86_reserve_range();
 	}
 #endif
 
@@ -846,7 +845,7 @@ void __init setup_arch(char **cmdline_p)
 	vmi_activate();
 
 	/* after early param, so could get panic from serial */
-	reserve_early_setup_data();
+	memblock_x86_reserve_range_setup_data();
 
 	if (acpi_mps_check()) {
 #ifdef CONFIG_X86_LOCAL_APIC

commit 72d7c3b33c980843e756681fb4867dc1efd62a76
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Aug 25 13:39:17 2010 -0700

    x86: Use memblock to replace early_res
    
    1. replace find_e820_area with memblock_find_in_range
    2. replace reserve_early with memblock_x86_reserve_range
    3. replace free_early with memblock_x86_free_range.
    4. NO_BOOTMEM will switch to use memblock too.
    5. use _e820, _early wrap in the patch, in following patch, will
       replace them all
    6. because memblock_x86_free_range support partial free, we can remove some special care
    7. Need to make sure that memblock_find_in_range() is called after memblock_x86_fill()
       so adjust some calling later in setup.c::setup_arch()
       -- corruption_check and mptable_update
    
    -v2: Move reserve_brk() early
        Before fill_memblock_area, to avoid overlap between brk and memblock_find_in_range()
        that could happen We have more then 128 RAM entry in E820 tables, and
        memblock_x86_fill() could use memblock_find_in_range() to find a new place for
        memblock.memory.region array.
        and We don't need to use extend_brk() after fill_memblock_area()
        So move reserve_brk() early before fill_memblock_area().
    -v3: Move find_smp_config early
        To make sure memblock_find_in_range not find wrong place, if BIOS doesn't put mptable
        in right place.
    -v4: Treat RESERVED_KERN as RAM in memblock.memory. and they are already in
        memblock.reserved already..
        use __NOT_KEEP_MEMBLOCK to make sure memblock related code could be freed later.
    -v5: Generic version __memblock_find_in_range() is going from high to low, and for 32bit
        active_region for 32bit does include high pages
        need to replace the limit with memblock.default_alloc_limit, aka get_max_mapped()
    -v6: Use current_limit instead
    -v7: check with MEMBLOCK_ERROR instead of -1ULL or -1L
    -v8: Set memblock_can_resize early to handle EFI with more RAM entries
    -v9: update after kmemleak changes in mainline
    
    Suggested-by: David S. Miller <davem@davemloft.net>
    Suggested-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4ae4acbd031..bbe0aaf77494 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -31,6 +31,7 @@
 #include <linux/apm_bios.h>
 #include <linux/initrd.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/seq_file.h>
 #include <linux/console.h>
 #include <linux/mca.h>
@@ -614,7 +615,7 @@ static __init void reserve_ibft_region(void)
 	addr = find_ibft_region(&size);
 
 	if (size)
-		reserve_early_overlap_ok(addr, addr + size, "ibft");
+		memblock_x86_reserve_range(addr, addr + size, "* ibft");
 }
 
 #ifdef CONFIG_X86_RESERVE_LOW_64K
@@ -708,6 +709,15 @@ static void __init trim_bios_range(void)
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
 
+static u64 __init get_max_mapped(void)
+{
+	u64 end = max_pfn_mapped;
+
+	end <<= PAGE_SHIFT;
+
+	return end;
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -891,8 +901,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	max_pfn = e820_end_of_ram_pfn();
 
-	/* preallocate 4k for mptable mpc */
-	early_reserve_e820_mpc_new();
 	/* update e820 for memory not covered by WB MTRRs */
 	mtrr_bp_init();
 	if (mtrr_trim_uncached_memory(max_pfn))
@@ -917,15 +925,6 @@ void __init setup_arch(char **cmdline_p)
 	max_pfn_mapped = KERNEL_IMAGE_SIZE >> PAGE_SHIFT;
 #endif
 
-#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
-	setup_bios_corruption_check();
-#endif
-
-	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
-			max_pfn_mapped<<PAGE_SHIFT);
-
-	reserve_brk();
-
 	/*
 	 * Find and reserve possible boot-time SMP configuration:
 	 */
@@ -933,6 +932,26 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_ibft_region();
 
+	/*
+	 * Need to conclude brk, before memblock_x86_fill()
+	 *  it could use memblock_find_in_range, could overlap with
+	 *  brk area.
+	 */
+	reserve_brk();
+
+	memblock.current_limit = get_max_mapped();
+	memblock_x86_fill();
+
+	/* preallocate 4k for mptable mpc */
+	early_reserve_e820_mpc_new();
+
+#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
+	setup_bios_corruption_check();
+#endif
+
+	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
+			max_pfn_mapped<<PAGE_SHIFT);
+
 	reserve_trampoline_memory();
 
 #ifdef CONFIG_ACPI_SLEEP
@@ -956,6 +975,7 @@ void __init setup_arch(char **cmdline_p)
 		max_low_pfn = max_pfn;
 	}
 #endif
+	memblock.current_limit = get_max_mapped();
 
 	/*
 	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.
@@ -995,7 +1015,7 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init(0, max_pfn, acpi, k8);
 #ifndef CONFIG_NO_BOOTMEM
-	early_res_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
+	memblock_x86_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
 #endif
 
 	dma32_reserve_bootmem();

commit 9ea77bdb39b62c9bf9fd3cdd1c25a9420bccd380
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Aug 25 16:38:20 2010 -0700

    x86, bios: Make the x86 early memory reservation a kernel option
    
    Add a kernel command-line option so the x86 early memory reservation
    size can be adjusted at runtime instead of only at compile time.
    
    Suggested-by: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <tip-d0cd7425fab774a480cce17c2f649984312d0b55@git.kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index eb87f1c83f91..af277e369def 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -618,6 +618,8 @@ static __init void reserve_ibft_region(void)
 		reserve_early_overlap_ok(addr, addr + size, "ibft");
 }
 
+static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
+
 static void __init trim_bios_range(void)
 {
 	/*
@@ -627,9 +629,9 @@ static void __init trim_bios_range(void)
 	 *
 	 * This typically reserves additional memory (64KiB by default)
 	 * since some BIOSes are known to corrupt low memory.  See the
-	 * Kconfig help text for X86_LOW_RESERVE.
+	 * Kconfig help text for X86_RESERVE_LOW.
 	 */
-	e820_update_range(0, ALIGN(CONFIG_X86_LOW_RESERVE << 10, PAGE_SIZE),
+	e820_update_range(0, ALIGN(reserve_low, PAGE_SIZE),
 			  E820_RAM, E820_RESERVED);
 
 	/*
@@ -641,6 +643,28 @@ static void __init trim_bios_range(void)
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
 
+static int __init parse_reservelow(char *p)
+{
+	unsigned long long size;
+
+	if (!p)
+		return -EINVAL;
+
+	size = memparse(p, &p);
+
+	if (size < 4096)
+		size = 4096;
+
+	if (size > 640*1024)
+		size = 640*1024;
+
+	reserve_low = size;
+
+	return 0;
+}
+
+early_param("reservelow", parse_reservelow);
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit d0cd7425fab774a480cce17c2f649984312d0b55
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Tue Aug 24 17:32:04 2010 -0700

    x86, bios: By default, reserve the low 64K for all BIOSes
    
    The laundry list of BIOSes that need the low 64K reserved is getting
    very long, so make it the default across all BIOSes.  This also allows
    the code to be simplified and unified with the reservation code for
    the first 4K.
    
    This resolves kernel bugzilla 16661 and who knows what else...
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    LKML-Reference: <tip-*@git.kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c3a4fbb2b996..eb87f1c83f91 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -618,88 +618,20 @@ static __init void reserve_ibft_region(void)
 		reserve_early_overlap_ok(addr, addr + size, "ibft");
 }
 
-#ifdef CONFIG_X86_RESERVE_LOW_64K
-static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
-{
-	printk(KERN_NOTICE
-		"%s detected: BIOS may corrupt low RAM, working around it.\n",
-		d->ident);
-
-	e820_update_range(0, 0x10000, E820_RAM, E820_RESERVED);
-	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
-
-	return 0;
-}
-#endif
-
-/* List of systems that have known low memory corruption BIOS problems */
-static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
-#ifdef CONFIG_X86_RESERVE_LOW_64K
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "AMI BIOS",
-		.matches = {
-			DMI_MATCH(DMI_BIOS_VENDOR, "American Megatrends Inc."),
-		},
-	},
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "Phoenix BIOS",
-		.matches = {
-			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies"),
-		},
-	},
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "Phoenix/MSC BIOS",
-		.matches = {
-			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix/MSC"),
-		},
-	},
-	/*
-	 * AMI BIOS with low memory corruption was found on Intel DG45ID and
-	 * DG45FC boards.
-	 * It has a different DMI_BIOS_VENDOR = "Intel Corp.", for now we will
-	 * match only DMI_BOARD_NAME and see if there is more bad products
-	 * with this vendor.
-	 */
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "AMI BIOS",
-		.matches = {
-			DMI_MATCH(DMI_BOARD_NAME, "DG45ID"),
-		},
-	},
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "AMI BIOS",
-		.matches = {
-			DMI_MATCH(DMI_BOARD_NAME, "DG45FC"),
-		},
-	},
-	/*
-	 * The Dell Inspiron Mini 1012 has DMI_BIOS_VENDOR = "Dell Inc.", so
-	 * match on the product name.
-	 */
-	{
-		.callback = dmi_low_memory_corruption,
-		.ident = "Phoenix BIOS",
-		.matches = {
-			DMI_MATCH(DMI_PRODUCT_NAME, "Inspiron 1012"),
-		},
-	},
-#endif
-	{}
-};
-
 static void __init trim_bios_range(void)
 {
 	/*
 	 * A special case is the first 4Kb of memory;
 	 * This is a BIOS owned area, not kernel ram, but generally
 	 * not listed as such in the E820 table.
+	 *
+	 * This typically reserves additional memory (64KiB by default)
+	 * since some BIOSes are known to corrupt low memory.  See the
+	 * Kconfig help text for X86_LOW_RESERVE.
 	 */
-	e820_update_range(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
+	e820_update_range(0, ALIGN(CONFIG_X86_LOW_RESERVE << 10, PAGE_SIZE),
+			  E820_RAM, E820_RESERVED);
+
 	/*
 	 * special case: Some BIOSen report the PC BIOS
 	 * area (640->1Mb) as ram even though it is not.
@@ -863,8 +795,6 @@ void __init setup_arch(char **cmdline_p)
 
 	dmi_scan_machine();
 
-	dmi_check_system(bad_bios_dmi_table);
-
 	/*
 	 * VMware detection requires dmi to be available, so this
 	 * needs to be done after dmi_scan_machine, for the BP.

commit 9863c90f682fba34cdc26c3437e8c00da6c83fa4
Author: Alok Kataria <akataria@vmware.com>
Date:   Mon Aug 23 14:49:11 2010 -0700

    x86, vmware: Remove deprecated VMI kernel support
    
    With the recent innovations in CPU hardware acceleration technologies
    from Intel and AMD, VMware ran a few experiments to compare these
    techniques to guest paravirtualization technique on VMware's platform.
    These hardware assisted virtualization techniques have outperformed the
    performance benefits provided by VMI in most of the workloads. VMware
    expects that these hardware features will be ubiquitous in a couple of
    years, as a result, VMware has started a phased retirement of this
    feature from the hypervisor.
    
    Please note that VMI has always been an optimization and non-VMI kernels
    still work fine on VMware's platform.
    Latest versions of VMware's product which support VMI are,
    Workstation 7.0 and VSphere 4.0 on ESX side, future maintainence
    releases for these products will continue supporting VMI.
    
    For more details about VMI retirement take a look at this,
    http://blogs.vmware.com/guestosguide/2009/09/vmi-retirement.html
    
    This feature removal was scheduled for 2.6.37 back in September 2009.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    LKML-Reference: <1282600151.19396.22.camel@ank32.eng.vmware.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c3a4fbb2b996..feb4c21e499a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -83,7 +83,6 @@
 #include <asm/dmi.h>
 #include <asm/io_apic.h>
 #include <asm/ist.h>
-#include <asm/vmi.h>
 #include <asm/setup_arch.h>
 #include <asm/bios_ebda.h>
 #include <asm/cacheflush.h>
@@ -734,10 +733,10 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
-	/* VMI may relocate the fixmap; do this before touching ioremap area */
-	vmi_init();
-
-	/* OFW also may relocate the fixmap */
+	/*
+	 * If we have OLPC OFW, we might end up relocating the fixmap due to
+	 * reserve_top(), so do this before touching the ioremap area.
+	 */
 	olpc_ofw_detect();
 
 	early_trap_init();
@@ -838,9 +837,6 @@ void __init setup_arch(char **cmdline_p)
 
 	x86_report_nx();
 
-	/* Must be before kernel pagetables are setup */
-	vmi_activate();
-
 	/* after early param, so could get panic from serial */
 	reserve_early_setup_data();
 

commit fd89a137924e0710078c3ae855e7cec1c43cb845
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon Aug 16 14:38:33 2010 +0200

    x86-32: Separate 1:1 pagetables from swapper_pg_dir
    
    This patch fixes machine crashes which occur when heavily exercising the
    CPU hotplug codepaths on a 32-bit kernel. These crashes are caused by
    AMD Erratum 383 and result in a fatal machine check exception. Here's
    the scenario:
    
    1. On 32-bit, the swapper_pg_dir page table is used as the initial page
    table for booting a secondary CPU.
    
    2. To make this work, swapper_pg_dir needs a direct mapping of physical
    memory in it (the low mappings). By adding those low, large page (2M)
    mappings (PAE kernel), we create the necessary conditions for Erratum
    383 to occur.
    
    3. Other CPUs which do not participate in the off- and onlining game may
    use swapper_pg_dir while the low mappings are present (when leave_mm is
    called). For all steps below, the CPU referred to is a CPU that is using
    swapper_pg_dir, and not the CPU which is being onlined.
    
    4. The presence of the low mappings in swapper_pg_dir can result
    in TLB entries for addresses below __PAGE_OFFSET to be established
    speculatively. These TLB entries are marked global and large.
    
    5. When the CPU with such TLB entry switches to another page table, this
    TLB entry remains because it is global.
    
    6. The process then generates an access to an address covered by the
    above TLB entry but there is a permission mismatch - the TLB entry
    covers a large global page not accessible to userspace.
    
    7. Due to this permission mismatch a new 4kb, user TLB entry gets
    established. Further, Erratum 383 provides for a small window of time
    where both TLB entries are present. This results in an uncorrectable
    machine check exception signalling a TLB multimatch which panics the
    machine.
    
    There are two ways to fix this issue:
    
            1. Always do a global TLB flush when a new cr3 is loaded and the
            old page table was swapper_pg_dir. I consider this a hack hard
            to understand and with performance implications
    
            2. Do not use swapper_pg_dir to boot secondary CPUs like 64-bit
            does.
    
    This patch implements solution 2. It introduces a trampoline_pg_dir
    which has the same layout as swapper_pg_dir with low_mappings. This page
    table is used as the initial page table of the booting CPU. Later in the
    bringup process, it switches to swapper_pg_dir and does a global TLB
    flush. This fixes the crashes in our test cases.
    
    -v2: switch to swapper_pg_dir right after entering start_secondary() so
    that we are able to access percpu data which might not be mapped in the
    trampoline page table.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    LKML-Reference: <20100816123833.GB28147@aftab>
    Signed-off-by: Borislav Petkov <borislav.petkov@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b008e7883207..c3a4fbb2b996 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1014,6 +1014,8 @@ void __init setup_arch(char **cmdline_p)
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
+	setup_trampoline_page_table();
+
 	tboot_probe();
 
 #ifdef CONFIG_X86_64

commit f6e9456c9272bb570df6e217cdbe007e270b1c4e
Author: Robert Richter <robert.richter@amd.com>
Date:   Wed Jul 21 19:03:58 2010 +0200

    x86, cleanup: Remove obsolete boot_cpu_id variable
    
    boot_cpu_id is there for historical reasons and was renamed to
    boot_cpu_physical_apicid in patch:
    
     c70dcb7 x86: change boot_cpu_id to boot_cpu_physical_apicid
    
    However, there are some remaining occurrences of boot_cpu_id that are
    never touched in the kernel and thus its value is always 0.
    
    This patch removes boot_cpu_id completely.
    
    Signed-off-by: Robert Richter <robert.richter@amd.com>
    LKML-Reference: <1279731838-1522-8-git-send-email-robert.richter@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b008e7883207..dede5c4bae4b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -125,7 +125,6 @@ unsigned long max_pfn_mapped;
 RESERVE_BRK(dmi_alloc, 65536);
 #endif
 
-unsigned int boot_cpu_id __read_mostly;
 
 static __initdata unsigned long _brk_start = (unsigned long)__brk_base;
 unsigned long _brk_end = (unsigned long)__brk_base;

commit fd699c76552bbfa66631f019be415a87dbb08237
Author: Andres Salomon <dilinger@queued.net>
Date:   Fri Jun 18 17:46:53 2010 -0400

    x86, olpc: Add support for calling into OpenFirmware
    
    Add support for saving OFW's cif, and later calling into it to run OFW
    commands.  OFW remains resident in memory, living within virtual range
    0xff800000 - 0xffc00000.  A single page directory entry points to the
    pgdir that OFW actually uses, so rather than saving the entire page
    table, we grab and install that one entry permanently in the kernel's
    page table.
    
    This is currently only used by the OLPC XO.  Note that this particular
    calling convention breaks PAE and PAT, and so cannot be used on newer
    x86 hardware.
    
    Signed-off-by: Andres Salomon <dilinger@queued.net>
    LKML-Reference: <20100618174653.7755a39a@dev.queued.net>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4ae4acbd031..b008e7883207 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -102,6 +102,7 @@
 
 #include <asm/paravirt.h>
 #include <asm/hypervisor.h>
+#include <asm/olpc_ofw.h>
 
 #include <asm/percpu.h>
 #include <asm/topology.h>
@@ -736,10 +737,15 @@ void __init setup_arch(char **cmdline_p)
 	/* VMI may relocate the fixmap; do this before touching ioremap area */
 	vmi_init();
 
+	/* OFW also may relocate the fixmap */
+	olpc_ofw_detect();
+
 	early_trap_init();
 	early_cpu_init();
 	early_ioremap_init();
 
+	setup_olpc_ofw_pgd();
+
 	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
 	screen_info = boot_params.screen_info;
 	edid_info = boot_params.edid_info;

commit 3d6e77a3ddb8e4156b89f4273ff8c7d37abaf781
Author: Gabor Gombas <gombasg@digikabel.hu>
Date:   Mon May 24 12:13:18 2010 -0700

    x86, setup: Phoenix BIOS fixup is needed on Dell Inspiron Mini 1012
    
    The low-memory corruption checker triggers during suspend/resume, so we
    need to reserve the low 64k.  Don't be fooled that the BIOS identifies
    itself as "Dell Inc.", it's still Phoenix BIOS.
    
    [ hpa: I think we blacklist almost every BIOS in existence.  We should
    either change this to a whitelist or just make it unconditional. ]
    
    Signed-off-by: Gabor Gombas <gombasg@digikabel.hu>
    LKML-Reference: <201005241913.o4OJDIMM010877@imap1.linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: <stable@kernel.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e8029896309a..b4ae4acbd031 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -676,6 +676,17 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BOARD_NAME, "DG45FC"),
 		},
 	},
+	/*
+	 * The Dell Inspiron Mini 1012 has DMI_BIOS_VENDOR = "Dell Inc.", so
+	 * match on the product name.
+	 */
+	{
+		.callback = dmi_low_memory_corruption,
+		.ident = "Phoenix BIOS",
+		.matches = {
+			DMI_MATCH(DMI_PRODUCT_NAME, "Inspiron 1012"),
+		},
+	},
 #endif
 	{}
 };

commit 29c843912a0baa7fa63033fe28e1ca7e796686a5
Author: Jan Kiszka <jan.kiszka@web.de>
Date:   Thu May 20 21:04:29 2010 -0500

    x86, kgdb: early trap init for early debug
    
    Allow the x86 arch to have early exception processing for the purpose
    of debugging via the kgdb.
    
    Signed-off-by: Jan Kiszka <jan.kiszka@web.de>
    Signed-off-by: Jason Wessel <jason.wessel@windriver.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c4851eff57b3..e8029896309a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -725,6 +725,7 @@ void __init setup_arch(char **cmdline_p)
 	/* VMI may relocate the fixmap; do this before touching ioremap area */
 	vmi_init();
 
+	early_trap_init();
 	early_cpu_init();
 	early_ioremap_init();
 

commit fb1ae635772d679eb312fa447290fc02cd0e4cf1
Merge: addb2d6c1399 472a474c6630
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 7 11:02:23 2010 -0700

    Merge branch 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/x86/linux-2.6-tip
    
    * 'x86-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/x86/linux-2.6-tip:
      x86: Fix double enable_IR_x2apic() call on SMP kernel on !SMP boards
      x86: Increase CONFIG_NODES_SHIFT max to 10
      ibft, x86: Change reserve_ibft_region() to find_ibft_region()
      x86, hpet: Fix bug in RTC emulation
      x86, hpet: Erratum workaround for read after write of HPET comparator
      bootmem, x86: Fix 32bit numa system without RAM on node 0
      nobootmem, x86: Fix 32bit numa system without RAM on node 0
      x86: Handle overlapping mptables
      x86: Make e820_remove_range to handle all covered case
      x86-32, resume: do a global tlb flush in S4 resume

commit 336f5899d287f06d8329e208fc14ce50f7ec9698
Merge: a4ab2773205e db217dece300
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Apr 5 11:37:28 2010 +0900

    Merge branch 'master' into export-slabh

commit 042be38e6106ed70b42d096ab4a1ed4187e510e6
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Apr 1 14:32:43 2010 -0700

    ibft, x86: Change reserve_ibft_region() to find_ibft_region()
    
    This allows arch code could decide the way to reserve the ibft.
    
    And we should reserve ibft as early as possible, instead of BOOTMEM
    stage, in case the table is in RAM range and is not reserved by BIOS
    (this will often be the case.)
    
    Move to just after find_smp_config().
    
    Also when CONFIG_NO_BOOTMEM=y, We will not have reserve_bootmem() anymore.
    
    -v2: fix typo about ibft pointed by Konrad Rzeszutek Wilk <konrad@darnok.org>
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4BB510FB.80601@kernel.org>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Peter Jones <pjones@redhat.com>
    Cc: Konrad Rzeszutek Wilk <konrad@kernel.org>
    CC: Jan Beulich <jbeulich@novell.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d76e18570c60..580e6b3dbdb8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -608,6 +608,16 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
+static __init void reserve_ibft_region(void)
+{
+	unsigned long addr, size = 0;
+
+	addr = find_ibft_region(&size);
+
+	if (size)
+		reserve_early_overlap_ok(addr, addr + size, "ibft");
+}
+
 #ifdef CONFIG_X86_RESERVE_LOW_64K
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
@@ -910,6 +920,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	find_smp_config();
 
+	reserve_ibft_region();
+
 	reserve_trampoline_memory();
 
 #ifdef CONFIG_ACPI_SLEEP
@@ -977,8 +989,6 @@ void __init setup_arch(char **cmdline_p)
 
 	dma32_reserve_bootmem();
 
-	reserve_ibft_region();
-
 #ifdef CONFIG_KVM_CLOCK
 	kvmclock_init();
 #endif

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5d7ba1a449bd..c08d1e3261a8 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -55,7 +55,6 @@
 #include <linux/stddef.h>
 #include <linux/unistd.h>
 #include <linux/ptrace.h>
-#include <linux/slab.h>
 #include <linux/user.h>
 #include <linux/delay.h>
 

commit c967da6a0ba837f762042e931d4afcf72045547c
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sun Mar 28 19:42:55 2010 -0700

    x86: Make sure free_init_pages() frees pages on page boundary
    
    When CONFIG_NO_BOOTMEM=y, it could use memory more effiently, or
    in a more compact fashion.
    
    Example:
    
     Allocated new RAMDISK: 00ec2000 - 0248ce57
     Move RAMDISK from 000000002ea04000 - 000000002ffcee56 to 00ec2000 - 0248ce56
    
    The new RAMDISK's end is not page aligned.
    Last page could be shared with other users.
    
    When free_init_pages are called for initrd or .init, the page
    could be freed and we could corrupt other data.
    
    code segment in free_init_pages():
    
     |        for (; addr < end; addr += PAGE_SIZE) {
     |                ClearPageReserved(virt_to_page(addr));
     |                init_page_count(virt_to_page(addr));
     |                memset((void *)(addr & ~(PAGE_SIZE-1)),
     |                        POISON_FREE_INITMEM, PAGE_SIZE);
     |                free_page(addr);
     |                totalram_pages++;
     |        }
    
    last half page could be used as one whole free page.
    
    So page align the boundaries.
    
    -v2: make the original initramdisk to be aligned, according to
         Johannes, otherwise we have the chance to lose one page.
         we still need to keep initrd_end not aligned, otherwise it could
         confuse decompressor.
    -v3: change to WARN_ON instead, suggested by Johannes.
    -v4: use PAGE_ALIGN, suggested by Johannes.
         We may fix that macro name later to PAGE_ALIGN_UP, and PAGE_ALIGN_DOWN
         Add comments about assuming ramdisk start is aligned
         in relocate_initrd(), change to re get ramdisk_image instead of save it
         to make diff smaller. Add warning for wrong range, suggested by Johannes.
    -v6: remove one WARN()
         We need to align beginning in free_init_pages()
         do not copy more than ramdisk_size, noticed by Johannes
    
    Reported-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Tested-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    LKML-Reference: <1269830604-26214-3-git-send-email-yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5d7ba1a449bd..d76e18570c60 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -314,16 +314,17 @@ static void __init reserve_brk(void)
 #define MAX_MAP_CHUNK	(NR_FIX_BTMAPS << PAGE_SHIFT)
 static void __init relocate_initrd(void)
 {
-
+	/* Assume only end is not page aligned */
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 area_size     = PAGE_ALIGN(ramdisk_size);
 	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
 	u64 ramdisk_here;
 	unsigned long slop, clen, mapaddr;
 	char *p, *q;
 
 	/* We need to move the initrd down into lowmem */
-	ramdisk_here = find_e820_area(0, end_of_lowmem, ramdisk_size,
+	ramdisk_here = find_e820_area(0, end_of_lowmem, area_size,
 					 PAGE_SIZE);
 
 	if (ramdisk_here == -1ULL)
@@ -332,7 +333,7 @@ static void __init relocate_initrd(void)
 
 	/* Note: this includes all the lowmem currently occupied by
 	   the initrd, we rely on that fact to keep the data intact. */
-	reserve_early(ramdisk_here, ramdisk_here + ramdisk_size,
+	reserve_early(ramdisk_here, ramdisk_here + area_size,
 			 "NEW RAMDISK");
 	initrd_start = ramdisk_here + PAGE_OFFSET;
 	initrd_end   = initrd_start + ramdisk_size;
@@ -376,9 +377,10 @@ static void __init relocate_initrd(void)
 
 static void __init reserve_initrd(void)
 {
+	/* Assume only end is not page aligned */
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
-	u64 ramdisk_end   = ramdisk_image + ramdisk_size;
+	u64 ramdisk_end   = PAGE_ALIGN(ramdisk_image + ramdisk_size);
 	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
 
 	if (!boot_params.hdr.type_of_loader ||

commit a626b46e17d0762d664ce471d40bc506b6e721ab
Merge: c1dcb4bb1e3e dce46a04d55d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 3 08:15:05 2010 -0800

    Merge branch 'x86-bootmem-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-bootmem-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (30 commits)
      early_res: Need to save the allocation name in drop_range_partial()
      sparsemem: Fix compilation on PowerPC
      early_res: Add free_early_partial()
      x86: Fix non-bootmem compilation on PowerPC
      core: Move early_res from arch/x86 to kernel/
      x86: Add find_fw_memmap_area
      Move round_up/down to kernel.h
      x86: Make 32bit support NO_BOOTMEM
      early_res: Enhance check_and_double_early_res
      x86: Move back find_e820_area to e820.c
      x86: Add find_early_area_size
      x86: Separate early_res related code from e820.c
      x86: Move bios page reserve early to head32/64.c
      sparsemem: Put mem map for one node together.
      sparsemem: Put usemap for one node together
      x86: Make 64 bit use early_res instead of bootmem before slab
      x86: Only call dma32_reserve_bootmem 64bit !CONFIG_NUMA
      x86: Make early_node_mem get mem > 4 GB if possible
      x86: Dynamically increase early_res array size
      x86: Introduce max_early_res and early_res_count
      ...

commit e808bae2407a087bfd40200a27587898e5a9909d
Author: Thadeu Lima de Souza Cascardo <cascardo@holoscopio.com>
Date:   Tue Feb 9 21:38:45 2010 -0200

    x86: Do not reserve brk for DMI if it's not going to be used
    
    This will save 64K bytes from memory when loading linux if DMI is
    disabled, which is good for embedded systems.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@holoscopio.com>
    LKML-Reference: <1265758732-19320-1-git-send-email-cascardo@holoscopio.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3499b4fabc94..cb42109a55b4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -121,7 +121,9 @@
 unsigned long max_low_pfn_mapped;
 unsigned long max_pfn_mapped;
 
+#ifdef CONFIG_DMI
 RESERVE_BRK(dmi_alloc, 65536);
+#endif
 
 unsigned int boot_cpu_id __read_mostly;
 

commit b7e56edba4b02f2079042c326a8cd72a44635817
Merge: 13ca0fcaa33f b0483e78e5c4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 17 18:27:37 2010 +0100

    Merge branch 'linus' into x86/mm
    
    x86/mm is on 32-rc4 and missing the spinlock namespace changes which
    are needed for further commits into this topic.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 08677214e318297f228237be0042aac754f48f1d
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 10 01:20:20 2010 -0800

    x86: Make 64 bit use early_res instead of bootmem before slab
    
    Finally we can use early_res to replace bootmem for x86_64 now.
    
    Still can use CONFIG_NO_BOOTMEM to enable it or not.
    
    -v2: fix 32bit compiling about MAX_DMA32_PFN
    -v3: folded bug fix from LKML message below
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4B747239.4070907@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ea4141b48518..d49e168bda8c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -967,7 +967,9 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	initmem_init(0, max_pfn, acpi, k8);
+#ifndef CONFIG_NO_BOOTMEM
 	early_res_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
+#endif
 
 	dma32_reserve_bootmem();
 

commit c252a5bb1f57afb1e336d68085217727ca7b2134
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 10 01:20:19 2010 -0800

    x86: Only call dma32_reserve_bootmem 64bit !CONFIG_NUMA
    
    64bit NUMA already make enough space under 4G with new early_node_mem.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <1265793639-15071-16-git-send-email-yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 48cadbb1d28b..ea4141b48518 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -969,14 +969,7 @@ void __init setup_arch(char **cmdline_p)
 	initmem_init(0, max_pfn, acpi, k8);
 	early_res_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
 
-#ifdef CONFIG_X86_64
-	/*
-	 * dma32_reserve_bootmem() allocates bootmem which may conflict
-	 * with the crashkernel command line, so do that after
-	 * reserve_crashkernel()
-	 */
 	dma32_reserve_bootmem();
-#endif
 
 	reserve_ibft_region();
 

commit 1842f90cc98625d4d9bf8f8b927f17705ceb4e9c
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 10 01:20:15 2010 -0800

    x86: Call early_res_to_bootmem one time
    
    Simplify setup_node_mem: don't use bootmem from other node, instead
    just find_e820_area in early_node_mem.
    
    This keeps the boundary between early_res and boot mem more clear, and
    lets us only call early_res_to_bootmem() one time instead of for all
    nodes.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <1265793639-15071-12-git-send-email-yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3499b4fabc94..48cadbb1d28b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -967,6 +967,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	initmem_init(0, max_pfn, acpi, k8);
+	early_res_to_bootmem(0, max_low_pfn<<PAGE_SHIFT);
 
 #ifdef CONFIG_X86_64
 	/*

commit 84abd88a70090cf00f9e45c3a81680874f17626e
Merge: 13ca0fcaa33f e28cab42f384
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Feb 10 16:55:28 2010 -0800

    Merge remote branch 'linus/master' into x86/bootmem

commit 1b5576e69a5fe168c08a159685ac366316ac9bbc
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Jan 22 11:21:04 2010 +0800

    x86: Remove BIOS data range from e820
    
    In preparation for moving to the generic page_is_ram(), make explicit
    what we expect to be reserved and not reserved.
    
    Tested-by: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <20100122033004.335813103@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cdb6a8a506dd..f9b1f4e5ab74 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -650,6 +650,23 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 	{}
 };
 
+static void __init trim_bios_range(void)
+{
+	/*
+	 * A special case is the first 4Kb of memory;
+	 * This is a BIOS owned area, not kernel ram, but generally
+	 * not listed as such in the E820 table.
+	 */
+	e820_update_range(0, PAGE_SIZE, E820_RAM, E820_RESERVED);
+	/*
+	 * special case: Some BIOSen report the PC BIOS
+	 * area (640->1Mb) as ram even though it is not.
+	 * take them out.
+	 */
+	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
+	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -813,7 +830,7 @@ void __init setup_arch(char **cmdline_p)
 	insert_resource(&iomem_resource, &data_resource);
 	insert_resource(&iomem_resource, &bss_resource);
 
-
+	trim_bios_range();
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {
 		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,

commit 7c099ce1575126395f186ecf58b51a60d5c3be7d
Author: David H√§rdeman <david@hardeman.nu>
Date:   Thu Jan 28 21:02:54 2010 +0100

    x86: Add quirk for Intel DG45FC board to avoid low memory corruption
    
    Commit 6aa542a694dc9ea4344a8a590d2628c33d1b9431 added a quirk for the
    Intel DG45ID board due to low memory corruption. The Intel DG45FC
    shares the same BIOS (and the same bug) as noted in:
    
      http://bugzilla.kernel.org/show_bug.cgi?id=13736
    
    Signed-off-by: David H√§rdeman <david@hardeman.nu>
    LKML-Reference: <20100128200254.GA9134@hardeman.nu>
    Cc: <stable@kernel.org>
    Cc: Alexey Fisher <bug-track@fisher-privat.net>
    Cc: ykzhao <yakui.zhao@intel.com>
    Cc: Tony Bones <aabonesml@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f7b8b9894b22..5d9e40c58628 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -642,19 +642,27 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix/MSC"),
 		},
 	},
-	{
 	/*
-	 * AMI BIOS with low memory corruption was found on Intel DG45ID board.
-	 * It hase different DMI_BIOS_VENDOR = "Intel Corp.", for now we will
+	 * AMI BIOS with low memory corruption was found on Intel DG45ID and
+	 * DG45FC boards.
+	 * It has a different DMI_BIOS_VENDOR = "Intel Corp.", for now we will
 	 * match only DMI_BOARD_NAME and see if there is more bad products
 	 * with this vendor.
 	 */
+	{
 		.callback = dmi_low_memory_corruption,
 		.ident = "AMI BIOS",
 		.matches = {
 			DMI_MATCH(DMI_BOARD_NAME, "DG45ID"),
 		},
 	},
+	{
+		.callback = dmi_low_memory_corruption,
+		.ident = "AMI BIOS",
+		.matches = {
+			DMI_MATCH(DMI_BOARD_NAME, "DG45FC"),
+		},
+	},
 #endif
 	{}
 };

commit 893f38d144a4d96d2483cd7c3801d26e1b2c23e9
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Dec 10 13:07:22 2009 -0800

    x86: Use find_e820() instead of hard coded trampoline address
    
    Jens found the following crash/regression:
    
    [    0.000000] found SMP MP-table at [ffff8800000fdd80] fdd80
    [    0.000000] Kernel panic - not syncing: Overlapping early reservations 12-f011 MP-table mpc to 0-fff BIOS data page
    
    and
    
    [    0.000000] Kernel panic - not syncing: Overlapping early reservations 12-f011 MP-table mpc to 6000-7fff TRAMPOLINE
    
    and bisected it to b24c2a9 ("x86: Move find_smp_config()
    earlier and avoid bootmem usage").
    
    It turns out the BIOS is using the first 64k for mptable,
    without reserving it.
    
    So try to find good range for the real-mode trampoline instead of
    hard coding it, in case some bios tries to use that range for sth.
    
    Reported-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Tested-by: Jens Axboe <jens.axboe@oracle.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    LKML-Reference: <4B21630A.6000308@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 946a311a25c9..f7b8b9894b22 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -73,6 +73,7 @@
 
 #include <asm/mtrr.h>
 #include <asm/apic.h>
+#include <asm/trampoline.h>
 #include <asm/e820.h>
 #include <asm/mpspec.h>
 #include <asm/setup.h>
@@ -875,6 +876,13 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_brk();
 
+	/*
+	 * Find and reserve possible boot-time SMP configuration:
+	 */
+	find_smp_config();
+
+	reserve_trampoline_memory();
+
 #ifdef CONFIG_ACPI_SLEEP
 	/*
 	 * Reserve low memory region for sleep support.
@@ -921,11 +929,6 @@ void __init setup_arch(char **cmdline_p)
 
 	early_acpi_boot_init();
 
-	/*
-	 * Find and reserve possible boot-time SMP configuration:
-	 */
-	find_smp_config();
-
 #ifdef CONFIG_ACPI_NUMA
 	/*
 	 * Parse SRAT to discover nodes.

commit e33c01972239fee4696679ae5f7d1f340f424999
Merge: 343036cea285 ccef086454d4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 8 13:27:33 2009 -0800

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (36 commits)
      x86, mm: Correct the implementation of is_untracked_pat_range()
      x86/pat: Trivial: don't create debugfs for memtype if pat is disabled
      x86, mtrr: Fix sorting of mtrr after subtracting
      x86: Move find_smp_config() earlier and avoid bootmem usage
      x86, platform: Change is_untracked_pat_range() to bool; cleanup init
      x86: Change is_ISA_range() into an inline function
      x86, mm: is_untracked_pat_range() takes a normal semiclosed range
      x86, mm: Call is_untracked_pat_range() rather than is_ISA_range()
      x86: UV SGI: Don't track GRU space in PAT
      x86: SGI UV: Fix BAU initialization
      x86, numa: Use near(er) online node instead of roundrobin for NUMA
      x86, numa, bootmem: Only free bootmem on NUMA failure path
      x86: Change crash kernel to reserve via reserve_early()
      x86: Eliminate redundant/contradicting cache line size config options
      x86: When cleaning MTRRs, do not fold WP into UC
      x86: remove "extern" from function prototypes in <asm/proto.h>
      x86, mm: Report state of NX protections during boot
      x86, mm: Clean up and simplify NX enablement
      x86, pageattr: Make set_memory_(x|nx) aware of NX support
      x86, sleep: Always save the value of EFER
      ...
    
    Fix up conflicts (added both iommu_shutdown and is_untracked_pat_range)
    to 'struct x86_platform_ops') in
            arch/x86/include/asm/x86_init.h
            arch/x86/kernel/x86_init.c

commit c2ed69cdc9da49a8d2d7b4212fd225abf902ceaa
Merge: ef26b1691d11 9eaa192d8988
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 5 15:32:18 2009 -0800

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Fix a section mismatch in arch/x86/kernel/setup.c
      x86: Fixup last users of irq_chip->typename
      x86: Remove BKL from apm_32
      x86: Remove BKL from microcode
      x86: use kernel_stack_pointer() in kprobes.c
      x86: use kernel_stack_pointer() in kgdb.c
      x86: use kernel_stack_pointer() in dumpstack.c
      x86: use kernel_stack_pointer() in process_32.c

commit 26fb20d008d841268545c25bb183f21ed16db891
Merge: 23ba90e328fd 767df1bdd8cb
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Dec 3 20:10:59 2009 +0100

    Merge branch 'perf/mce' into perf/core
    
    Merge reason: It's ready for v2.6.33.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9eaa192d8988d621217a9e6071cd403fd6010496
Author: Helight.Xu <helight.xu@gmail.com>
Date:   Mon Nov 30 18:33:51 2009 +0800

    x86: Fix a section mismatch in arch/x86/kernel/setup.c
    
    copy_edd() should be __init.
    warning msg:
    WARNING: vmlinux.o(.text+0x7759): Section mismatch in reference from the
    function copy_edd() to the variable .init.data:boot_params
    The function copy_edd() references
    the variable __initdata boot_params.
    This is often because copy_edd lacks a __initdata
    annotation or the annotation of boot_params is wrong.
    
    Signed-off-by: ZhenwenXu <helight.xu@gmail.com>
    LKML-Reference: <4B139F8F.4000907@gmail.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e09f0e2c14b5..e020b2d03b4f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -247,7 +247,7 @@ EXPORT_SYMBOL(edd);
  *              from boot_params into a safe place.
  *
  */
-static inline void copy_edd(void)
+static inline void __init copy_edd(void)
 {
      memcpy(edd.mbr_signature, boot_params.edd_mbr_sig_buffer,
 	    sizeof(edd.mbr_signature));
@@ -256,7 +256,7 @@ static inline void copy_edd(void)
      edd.edd_info_nr = boot_params.eddbuf_entries;
 }
 #else
-static inline void copy_edd(void)
+static inline void __init copy_edd(void)
 {
 }
 #endif

commit b24c2a925a9837cccf54d50aeac22ba0cbc15455
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Nov 24 02:48:18 2009 -0800

    x86: Move find_smp_config() earlier and avoid bootmem usage
    
    Move the find_smp_config() call to before bootmem is initialized.
    Use reserve_early() instead of reserve_bootmem() in it.
    
    This simplifies the code, we only need to call find_smp_config()
    once and can remove the now unneeded reserve parameter from
    x86_init_mpparse::find_smp_config.
    
    We thus also reduce x86's dependency on bootmem allocations.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4B0BB9F2.70907@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e3eae5965e4a..cdb6a8a506dd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -913,6 +913,11 @@ void __init setup_arch(char **cmdline_p)
 
 	early_acpi_boot_init();
 
+	/*
+	 * Find and reserve possible boot-time SMP configuration:
+	 */
+	find_smp_config();
+
 #ifdef CONFIG_ACPI_NUMA
 	/*
 	 * Parse SRAT to discover nodes.
@@ -927,11 +932,6 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init(0, max_pfn, acpi, k8);
 
-	/*
-	 * Find and reserve possible boot-time SMP configuration:
-	 */
-	find_smp_config();
-
 #ifdef CONFIG_X86_64
 	/*
 	 * dma32_reserve_bootmem() allocates bootmem which may conflict

commit 44280733e71ad15377735b42d8538c109c94d7e3
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sun Nov 22 17:18:49 2009 -0800

    x86: Change crash kernel to reserve via reserve_early()
    
    use find_e820_area()/reserve_early() instead.
    
    -v2: address Eric's request, to restore original semantics.
         will fail, if the provided address can not be used.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Eric W. Biederman <ebiederm@xmission.com>
    LKML-Reference: <4B09E2F9.7040403@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d2043a00abc1..e3eae5965e4a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -487,42 +487,11 @@ static void __init reserve_early_setup_data(void)
 
 #ifdef CONFIG_KEXEC
 
-/**
- * Reserve @size bytes of crashkernel memory at any suitable offset.
- *
- * @size: Size of the crashkernel memory to reserve.
- * Returns the base address on success, and -1ULL on failure.
- */
-static
-unsigned long long __init find_and_reserve_crashkernel(unsigned long long size)
-{
-	const unsigned long long alignment = 16<<20; 	/* 16M */
-	unsigned long long start = 0LL;
-
-	while (1) {
-		int ret;
-
-		start = find_e820_area(start, ULONG_MAX, size, alignment);
-		if (start == -1ULL)
-			return start;
-
-		/* try to reserve it */
-		ret = reserve_bootmem_generic(start, size, BOOTMEM_EXCLUSIVE);
-		if (ret >= 0)
-			return start;
-
-		start += alignment;
-	}
-}
-
 static inline unsigned long long get_total_mem(void)
 {
 	unsigned long long total;
 
-	total = max_low_pfn - min_low_pfn;
-#ifdef CONFIG_HIGHMEM
-	total += highend_pfn - highstart_pfn;
-#endif
+	total = max_pfn - min_low_pfn;
 
 	return total << PAGE_SHIFT;
 }
@@ -542,21 +511,25 @@ static void __init reserve_crashkernel(void)
 
 	/* 0 means: find the address automatically */
 	if (crash_base <= 0) {
-		crash_base = find_and_reserve_crashkernel(crash_size);
+		const unsigned long long alignment = 16<<20;	/* 16M */
+
+		crash_base = find_e820_area(alignment, ULONG_MAX, crash_size,
+				 alignment);
 		if (crash_base == -1ULL) {
-			pr_info("crashkernel reservation failed. "
-				"No suitable area found.\n");
+			pr_info("crashkernel reservation failed - No suitable area found.\n");
 			return;
 		}
 	} else {
-		ret = reserve_bootmem_generic(crash_base, crash_size,
-					BOOTMEM_EXCLUSIVE);
-		if (ret < 0) {
-			pr_info("crashkernel reservation failed - "
-				"memory is in use\n");
+		unsigned long long start;
+
+		start = find_e820_area(crash_base, ULONG_MAX, crash_size,
+				 1<<20);
+		if (start != crash_base) {
+			pr_info("crashkernel reservation failed - memory is in use.\n");
 			return;
 		}
 	}
+	reserve_early(crash_base, crash_base + crash_size, "CRASH KERNEL");
 
 	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
 			"for crashkernel (System RAM: %ldMB)\n",
@@ -927,6 +900,8 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
+	reserve_crashkernel();
+
 	vsmp_init();
 
 	io_delay_init();
@@ -957,8 +932,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	find_smp_config();
 
-	reserve_crashkernel();
-
 #ifdef CONFIG_X86_64
 	/*
 	 * dma32_reserve_bootmem() allocates bootmem which may conflict

commit 4b0f3b81eb33ef18283aa71440cccfede1753ae0
Author: Kees Cook <kees.cook@canonical.com>
Date:   Fri Nov 13 15:28:17 2009 -0800

    x86, mm: Report state of NX protections during boot
    
    It is possible for x86_64 systems to lack the NX bit either due to the
    hardware lacking support or the BIOS having turned off the CPU capability,
    so NX status should be reported.  Additionally, anyone booting NX-capable
    CPUs in 32bit mode without PAE will lack NX functionality, so this change
    provides feedback for that case as well.
    
    Signed-off-by: Kees Cook <kees.cook@canonical.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    LKML-Reference: <1258154897-6770-6-git-send-email-hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 23b7f46bf843..d2043a00abc1 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -788,16 +788,17 @@ void __init setup_arch(char **cmdline_p)
 	*cmdline_p = command_line;
 
 	/*
-	 * Must call this twice: Once just to detect whether hardware doesn't
-	 * support NX (so that the early EHCI debug console setup can safely
-	 * call set_fixmap(), and then again after parsing early parameters to
-	 * honor the respective command line option.
+	 * x86_configure_nx() is called before parse_early_param() to detect
+	 * whether hardware doesn't support NX (so that the early EHCI debug
+	 * console setup can safely call set_fixmap()). It may then be called
+	 * again from within noexec_setup() during parsing early parameters
+	 * to honor the respective command line option.
 	 */
 	x86_configure_nx();
 
 	parse_early_param();
 
-	x86_configure_nx();
+	x86_report_nx();
 
 	/* Must be before kernel pagetables are setup */
 	vmi_activate();

commit 4763ed4d45522b876c97e1f7f4b659d211f75571
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Fri Nov 13 15:28:16 2009 -0800

    x86, mm: Clean up and simplify NX enablement
    
    The 32- and 64-bit code used very different mechanisms for enabling
    NX, but even the 32-bit code was enabling NX in head_32.S if it is
    available.  Furthermore, we had a bewildering collection of tests for
    the available of NX.
    
    This patch:
    
    a) merges the 32-bit set_nx() and the 64-bit check_efer() function
       into a single x86_configure_nx() function.  EFER control is left
       to the head code.
    
    b) eliminates the nx_enabled variable entirely.  Things that need to
       test for NX enablement can verify __supported_pte_mask directly,
       and cpu_has_nx gives the supported status of NX.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Cc: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Chris Wright <chrisw@sous-sol.org>
    LKML-Reference: <1258154897-6770-5-git-send-email-hpa@zytor.com>
    Acked-by: Kees Cook <kees.cook@canonical.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0a6e94ab8339..23b7f46bf843 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -787,21 +787,17 @@ void __init setup_arch(char **cmdline_p)
 	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
 	*cmdline_p = command_line;
 
-#ifdef CONFIG_X86_64
 	/*
 	 * Must call this twice: Once just to detect whether hardware doesn't
 	 * support NX (so that the early EHCI debug console setup can safely
 	 * call set_fixmap(), and then again after parsing early parameters to
 	 * honor the respective command line option.
 	 */
-	check_efer();
-#endif
+	x86_configure_nx();
 
 	parse_early_param();
 
-#ifdef CONFIG_X86_64
-	check_efer();
-#endif
+	x86_configure_nx();
 
 	/* Must be before kernel pagetables are setup */
 	vmi_activate();

commit 196cf0d67acad70ebb2572da489d5cc7066cdd05
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Nov 10 18:27:23 2009 -0800

    x86: Make sure wakeup trampoline code is below 1MB
    
    Instead of using bootmem, try find_e820_area()/reserve_early(),
    and call acpi_reserve_memory() early, to allocate the wakeup
    trampoline code area below 1M.
    
    This is more reliable, and it also removes a dependency on
    bootmem.
    
    -v2: change function name to acpi_reserve_wakeup_memory(),
         as suggested by Rafael.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: pm list <linux-pm@lists.linux-foundation.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    LKML-Reference: <4AFA210B.3020207@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f89141982702..0a6e94ab8339 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -897,6 +897,13 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_brk();
 
+#ifdef CONFIG_ACPI_SLEEP
+	/*
+	 * Reserve low memory region for sleep support.
+	 * even before init_memory_mapping
+	 */
+	acpi_reserve_wakeup_memory();
+#endif
 	init_gbpages();
 
 	/* max_pfn_mapped is updated here */
@@ -948,12 +955,6 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init(0, max_pfn, acpi, k8);
 
-#ifdef CONFIG_ACPI_SLEEP
-	/*
-	 * Reserve low memory region for sleep support.
-	 */
-	acpi_reserve_bootmem();
-#endif
 	/*
 	 * Find and reserve possible boot-time SMP configuration:
 	 */

commit a2202aa29289db64ca7988b12343158b67b27f10
Author: Yong Wang <yong.y.wang@linux.intel.com>
Date:   Tue Nov 10 09:38:24 2009 +0800

    x86: Under BIOS control, restore AP's APIC_LVTTHMR to the BSP value
    
    On platforms where the BIOS handles the thermal monitor interrupt,
    APIC_LVTTHMR on each logical CPU is programmed to generate a SMI
    and OS must not touch it.
    
    Unfortunately AP bringup sequence using INIT-SIPI-SIPI clears all
    the LVT entries except the mask bit. Essentially this results in
    all LVT entries including the thermal monitoring interrupt set
    to masked (clearing the bios programmed value for APIC_LVTTHMR).
    
    And this leads to kernel take over the thermal monitoring
    interrupt on AP's but not on BSP (leaving the bios programmed
    value only on BSP).
    
    As a result of this, we have seen system hangs when the thermal
    monitoring interrupt is generated.
    
    Fix this by reading the initial value of thermal LVT entry on
    BSP and if bios has taken over the control, then program the
    same value on all AP's and leave the thermal monitoring
    interrupt control on all the logical cpu's to the bios.
    
    Signed-off-by: Yong Wang <yong.y.wang@intel.com>
    Reviewed-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    LKML-Reference: <20091110013824.GA24940@ywang-moblin2.bj.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: stable@kernel.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e09f0e2c14b5..179c1f2aa457 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -109,6 +109,7 @@
 #ifdef CONFIG_X86_64
 #include <asm/numa_64.h>
 #endif
+#include <asm/mce.h>
 
 /*
  * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
@@ -1024,6 +1025,8 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #endif
 	x86_init.oem.banner();
+
+	mcheck_init();
 }
 
 #ifdef CONFIG_X86_32

commit f1b291d4c47440cbfc1a478e88800e2742d60a80
Author: Simon Kagstrom <simon.kagstrom@netinsight.net>
Date:   Fri Nov 6 15:44:04 2009 +0100

    x86: Add Phoenix/MSC BIOSes to lowmem corruption list
    
    We have a board with a Phoenix/MSC BIOS which also corrupts the low
    64KB of RAM, so add an entry to the table.
    
    Signed-off-by: Simon Kagstrom <simon.kagstrom@netinsight.net>
    LKML-Reference: <20091106154404.002648d9@marrow.netinsight.se>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e09f0e2c14b5..2a34f9c5be21 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -659,6 +659,13 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies"),
 		},
 	},
+	{
+		.callback = dmi_low_memory_corruption,
+		.ident = "Phoenix/MSC BIOS",
+		.matches = {
+			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix/MSC"),
+		},
+	},
 	{
 	/*
 	 * AMI BIOS with low memory corruption was found on Intel DG45ID board.

commit 8716273caef7f55f39fe4fc6c69c5f9f197f41f1
Author: David Rientjes <rientjes@google.com>
Date:   Fri Sep 25 15:20:04 2009 -0700

    x86: Export srat physical topology
    
    This is the counterpart to "x86: export k8 physical topology" for
    SRAT. It is not as invasive because the acpi code already seperates
    node setup into detection and registration steps, with the
    exception of registering e820 active regions in
    acpi_numa_memory_affinity_init().  This is now moved to
    acpi_scan_nodes() if NUMA emulation is disabled or deferred.
    
    acpi_numa_init() now returns a value which specifies whether an
    underlying SRAT was located.  If so, that topology can be used by
    the emulation code to interleave emulated nodes over physical nodes
    or to register the nodes for ACPI.
    
    acpi_get_nodes() may now be used to export the srat physical
    topology of the machine for NUMA emulation.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Cc: Andreas Herrmann <andreas.herrmann3@amd.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Ankita Garg <ankita@in.ibm.com>
    Cc: Len Brown <len.brown@intel.com>
    LKML-Reference: <alpine.DEB.1.00.0909251518580.14754@chino.kir.corp.google.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fda0032c25c6..f89141982702 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -938,11 +938,12 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Parse SRAT to discover nodes.
 	 */
-	acpi_numa_init();
+	acpi = acpi_numa_init();
 #endif
 
 #ifdef CONFIG_K8_NUMA
-	k8 = !k8_numa_init(0, max_pfn);
+	if (!acpi)
+		k8 = !k8_numa_init(0, max_pfn);
 #endif
 
 	initmem_init(0, max_pfn, acpi, k8);

commit 8ee2debce32412118cf8c239e0026ace56ea1425
Author: David Rientjes <rientjes@google.com>
Date:   Fri Sep 25 15:20:00 2009 -0700

    x86: Export k8 physical topology
    
    To eventually interleave emulated nodes over physical nodes, we
    need to know the physical topology of the machine without actually
    registering it.  This does the k8 node setup in two parts:
    detection and registration.  NUMA emulation can then used the
    physical topology detected to setup the address ranges of emulated
    nodes accordingly.  If emulation isn't used, the k8 nodes are
    registered as normal.
    
    Two formals are added to the x86 NUMA setup functions: `acpi' and
    `k8'. These represent whether ACPI or K8 NUMA has been detected;
    both cannot be true at the same time.  This specifies to the NUMA
    emulation code whether an underlying physical NUMA topology exists
    and which interface to use.
    
    This patch deals solely with separating the k8 setup path into
    Northbridge detection and registration steps and leaves the ACPI
    changes for a subsequent patch.  The `acpi' formal is added here,
    however, to avoid touching all the header files again in the next
    patch.
    
    This approach also ensures emulated nodes will not span physical
    nodes so the true memory latency is not misrepresented.
    
    k8_get_nodes() may now be used to export the k8 physical topology
    of the machine for NUMA emulation.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Cc: Andreas Herrmann <andreas.herrmann3@amd.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
    Cc: Ankita Garg <ankita@in.ibm.com>
    Cc: Len Brown <len.brown@intel.com>
    LKML-Reference: <alpine.DEB.1.00.0909251518400.14754@chino.kir.corp.google.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e09f0e2c14b5..fda0032c25c6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -106,6 +106,7 @@
 #include <asm/percpu.h>
 #include <asm/topology.h>
 #include <asm/apicdef.h>
+#include <asm/k8.h>
 #ifdef CONFIG_X86_64
 #include <asm/numa_64.h>
 #endif
@@ -691,6 +692,9 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 
 void __init setup_arch(char **cmdline_p)
 {
+	int acpi = 0;
+	int k8 = 0;
+
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
@@ -937,7 +941,11 @@ void __init setup_arch(char **cmdline_p)
 	acpi_numa_init();
 #endif
 
-	initmem_init(0, max_pfn);
+#ifdef CONFIG_K8_NUMA
+	k8 = !k8_numa_init(0, max_pfn);
+#endif
+
+	initmem_init(0, max_pfn, acpi, k8);
 
 #ifdef CONFIG_ACPI_SLEEP
 	/*

commit 746942d06acdb4dd78d16baa5f3728a48a033bdd
Merge: c11f6c82581e c602c65b2f81
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 23 09:34:07 2009 -0700

    Merge branch 'sfi-release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-sfi-2.6
    
    * 'sfi-release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-sfi-2.6:
      SFI: remove unneeded includes
      sfi: Remove unused code
      SFI: Hook PCI MMCONFIG
      x86: add arch-specific SFI support
      SFI: add capability to parse ACPI tables
      SFI: add platform-independent core support
      SFI: create linux/sfi.h
      SFI: Simple Firmware Interface - MAINTAINERS, Kconfig

commit bfefb7a0c6e08736f2d5917c468467f134bf28bb
Merge: 8d0cc631f6dd 78f28b7c5553
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Sep 20 20:24:58 2009 +0200

    Merge branch 'linus' into x86/urgent
    
    Merge reason: Bring in changes that the next patch will depend on.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit eda6da9286ad5b35b1eb70f6368958a8ee41a9dd
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sat Sep 19 11:07:57 2009 -0700

    Revert 'x86: Fix system crash when loading with "reservetop" parameter'
    
    After close looking, commit 8126dec3 will break:
    
     1. some cpu feature  in early stage too, like cpu_has_x2apic
     2. will break built-in-command line
     3. will break other memmap= and mem=
     4. early_dbgp and early_console that will use early_ioremap to access mmio (?)
    
    So revert it.
    
    Reported-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>,
    Cc: Linus Torvalds <torvalds@linux-foundation.org>,
    Cc: Andrew Morton <akpm@linux-foundation.org>,
    LKML-Reference: <4AB51DFD.2000904@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 19f15c4076fb..f5baa2ae0c87 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -712,21 +712,6 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
-	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
-	*cmdline_p = command_line;
-
-#ifdef CONFIG_X86_64
-	/*
-	 * Must call this twice: Once just to detect whether hardware doesn't
-	 * support NX (so that the early EHCI debug console setup can safely
-	 * call set_fixmap(), and then again after parsing early parameters to
-	 * honor the respective command line option.
-	 */
-	check_efer();
-#endif
-
-	parse_early_param();
-
 	/* VMI may relocate the fixmap; do this before touching ioremap area */
 	vmi_init();
 
@@ -809,6 +794,21 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #endif
 
+	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
+	*cmdline_p = command_line;
+
+#ifdef CONFIG_X86_64
+	/*
+	 * Must call this twice: Once just to detect whether hardware doesn't
+	 * support NX (so that the early EHCI debug console setup can safely
+	 * call set_fixmap(), and then again after parsing early parameters to
+	 * honor the respective command line option.
+	 */
+	check_efer();
+#endif
+
+	parse_early_param();
+
 #ifdef CONFIG_X86_64
 	check_efer();
 #endif

commit c602c65b2f81d14456771d1e3f15d1381f4b7efa
Merge: 3834f47291df 78f28b7c5553
Author: Len Brown <len.brown@intel.com>
Date:   Sat Sep 19 00:11:26 2009 -0400

    Merge branch 'linus' into sfi-release
    
    Conflicts:
            arch/x86/kernel/setup.c
            drivers/acpi/power.c
            init/main.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 78f28b7c555359c67c2a0d23f7436e915329421e
Merge: 3240a77b515f 7bd867dfb4e0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 18 14:05:47 2009 -0700

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (38 commits)
      x86: Move get/set_wallclock to x86_platform_ops
      x86: platform: Fix section annotations
      x86: apic namespace cleanup
      x86: Distangle ioapic and i8259
      x86: Add Moorestown early detection
      x86: Add hardware_subarch ID for Moorestown
      x86: Add early platform detection
      x86: Move tsc_init to late_time_init
      x86: Move tsc_calibration to x86_init_ops
      x86: Replace the now identical time_32/64.c by time.c
      x86: time_32/64.c unify profile_pc
      x86: Move calibrate_cpu to tsc.c
      x86: Make timer setup and global variables the same in time_32/64.c
      x86: Remove mca bus ifdef from timer interrupt
      x86: Simplify timer_ack magic in time_32.c
      x86: Prepare unification of time_32/64.c
      x86: Remove do_timer hook
      x86: Add timer_init to x86_init_ops
      x86: Move percpu clockevents setup to x86_init_ops
      x86: Move xen_post_allocator_init into xen_pagetable_setup_done
      ...
    
    Fix up conflicts in arch/x86/include/asm/io_apic.h

commit 227423904c709a8e60245c97081bbeb4fb500655
Merge: 1aaf2e59135f fa526d0d641b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 15 09:19:38 2009 -0700

    Merge branch 'x86-pat-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-pat-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, pat: Fix cacheflush address in change_page_attr_set_clr()
      mm: remove !NUMA condition from PAGEFLAGS_EXTENDED condition set
      x86: Fix earlyprintk=dbgp for machines without NX
      x86, pat: Sanity check remap_pfn_range for RAM region
      x86, pat: Lookup the protection from memtype list on vm_insert_pfn()
      x86, pat: Add lookup_memtype to get the current memtype of a paddr
      x86, pat: Use page flags to track memtypes of RAM pages
      x86, pat: Generalize the use of page flag PG_uncached
      x86, pat: Add rbtree to do quick lookup in memtype tracking
      x86, pat: Add PAT reserve free to io_mapping* APIs
      x86, pat: New i/f for driver to request memtype for IO regions
      x86, pat: ioremap to follow same PAT restrictions as other PAT users
      x86, pat: Keep identity maps consistent with mmaps even when pat_disabled
      x86, mtrr: make mtrr_aps_delayed_init static bool
      x86, pat/mtrr: Rendezvous all the cpus for MTRR/PAT init
      generic-ipi: Allow cpus not yet online to call smp_call_function with irqs disabled
      x86: Fix an incorrect argument of reserve_bootmem()
      x86: Fix system crash when loading with "reservetop" parameter

commit 936e894a976dd3b0f07f1f6f43c17b77b7e6146d
Merge: 69575d388603 326ba5010a54
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Sep 2 08:17:56 2009 +0200

    Merge commit 'v2.6.31-rc8' into x86/txt
    
    Conflicts:
            arch/x86/kernel/reboot.c
            security/Kconfig
    
    Merge reason: resolve the conflicts, bump up from rc3 to rc8.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 69575d388603365f2afbf4166df93152df59b165
Author: Shane Wang <shane.wang@intel.com>
Date:   Tue Sep 1 18:25:07 2009 -0700

    x86, intel_txt: clean up the impact on generic code, unbreak non-x86
    
    Move tboot.h from asm to linux to fix the build errors of intel_txt
    patch on non-X86 platforms. Remove the tboot code from generic code
    init/main.c and kernel/cpu.c.
    
    Signed-off-by: Shane Wang <shane.wang@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 80d6e9e32483..6ce0d6f38f7f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -66,6 +66,7 @@
 
 #include <linux/percpu.h>
 #include <linux/crash_dump.h>
+#include <linux/tboot.h>
 
 #include <video/edid.h>
 
@@ -145,8 +146,6 @@ struct boot_params __initdata boot_params;
 struct boot_params boot_params;
 #endif
 
-#include <asm/tboot.h>
-
 /*
  * Machine setup..
  */

commit e11dadabf443dc3101f28b74d8b9d56870a87db4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 31 15:18:40 2009 +0200

    x86: apic namespace cleanup
    
    boot_cpu_physical_apicid is a global variable and used as function
    argument as well. Rename the function arguments to avoid confusion.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2d93026af7cd..fda22ec1a935 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -129,9 +129,9 @@ int default_cpu_present_to_apicid(int mps_cpu)
 	return __default_cpu_present_to_apicid(mps_cpu);
 }
 
-int default_check_phys_apicid_present(int boot_cpu_physical_apicid)
+int default_check_phys_apicid_present(int phys_apicid)
 {
-	return __default_check_phys_apicid_present(boot_cpu_physical_apicid);
+	return __default_check_phys_apicid_present(phys_apicid);
 }
 #endif
 

commit 2d826404f0bdcac2a4dd7e3c446b70d6a3b63b78
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 17:06:25 2009 +0200

    x86: Move tsc_calibration to x86_init_ops
    
    TSC calibration is modified by the vmware hypervisor and paravirt by
    separate means. Moorestown wants to add its own calibration routine as
    well. So make calibrate_tsc a proper x86_init_ops function and
    override it by paravirt or by the early setup of the vmware
    hypervisor.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bb207a47c631..2d93026af7cd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -818,7 +818,7 @@ void __init setup_arch(char **cmdline_p)
 	 * VMware detection requires dmi to be available, so this
 	 * needs to be done after dmi_scan_machine, for the BP.
 	 */
-	init_hypervisor(&boot_cpu_data);
+	init_hypervisor_platform();
 
 	x86_init.resources.probe_roms();
 

commit 845b3944bbdf9e9247849bf037f27ff3a3f26d87
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Aug 19 15:37:03 2009 +0200

    x86: Add timer_init to x86_init_ops
    
    The timer init code is convoluted with several quirks and the paravirt
    timer chooser. Figuring out which code path is actually taken is not
    for the faint hearted.
    
    Move the numaq TSC quirk to tsc_pre_init x86_init_ops function and
    replace the paravirt time chooser and the remaining x86 quirk with a
    simple x86_init_ops function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 43ec6aa175bd..bb207a47c631 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -626,10 +626,6 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
-static struct x86_quirks default_x86_quirks __initdata;
-
-struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
-
 #ifdef CONFIG_X86_RESERVE_LOW_64K
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
@@ -1016,45 +1012,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 
-static struct irqaction irq0  = {
-	.handler = timer_interrupt,
-	.flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER,
-	.name = "timer"
-};
-
-/**
- * x86_quirk_pre_time_init - do any specific initialisations before.
- *
- **/
-void __init x86_quirk_pre_time_init(void)
-{
-	if (x86_quirks->arch_pre_time_init)
-		x86_quirks->arch_pre_time_init();
-}
-
-/**
- * x86_quirk_time_init - do any specific initialisations for the system timer.
- *
- * Description:
- *	Must plug the system timer interrupt source at HZ into the IRQ listed
- *	in irq_vectors.h:TIMER_IRQ
- **/
-void __init x86_quirk_time_init(void)
-{
-	if (x86_quirks->arch_time_init) {
-		/*
-		 * A nonzero return code does not mean failure, it means
-		 * that the architecture quirk does not want any
-		 * generic (timer) setup to be performed after this:
-		 */
-		if (x86_quirks->arch_time_init())
-			return;
-	}
-
-	irq0.mask = cpumask_of_cpu(0);
-	setup_irq(0, &irq0);
-}
-
 static struct resource video_ram_resource = {
 	.name	= "Video RAM area",
 	.start	= 0xa0000,

commit f1d7062a235d057e5d85ed2860bef609e0160cde
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 13:13:52 2009 +0200

    x86: Move xen_post_allocator_init into xen_pagetable_setup_done
    
    We really do not need two paravirt/x86_init_ops functions which are
    called in two consecutive source lines. Move the only user of
    post_allocator_init into the already existing pagetable_setup_done
    function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4952d63dd67a..43ec6aa175bd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -962,7 +962,6 @@ void __init setup_arch(char **cmdline_p)
 	x86_init.paging.pagetable_setup_start(swapper_pg_dir);
 	paging_init();
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
-	paravirt_post_allocator_init();
 
 #ifdef CONFIG_X86_64
 	map_vsyscall();

commit 030cb6c00d242c20e92a3327d0cac17ce02d0cc3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 14:30:02 2009 +0200

    x86: Move paravirt pagetable_setup to x86_init_ops
    
    Replace more paravirt hackery by proper x86_init_ops.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bc5f0e561cfd..4952d63dd67a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -959,9 +959,9 @@ void __init setup_arch(char **cmdline_p)
 	kvmclock_init();
 #endif
 
-	paravirt_pagetable_setup_start(swapper_pg_dir);
+	x86_init.paging.pagetable_setup_start(swapper_pg_dir);
 	paging_init();
-	paravirt_pagetable_setup_done(swapper_pg_dir);
+	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 	paravirt_post_allocator_init();
 
 #ifdef CONFIG_X86_64

commit 6f30c1ac3fcf11e08f00670f293546a112cdf4e3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 13:19:57 2009 +0200

    x86: Move paravirt banner printout to x86_init_ops
    
    Replace another obscure paravirt magic and move it to
    x86_init_ops. Such a hook is also useful for embedded and special
    hardware.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d12aa82c9c32..bc5f0e561cfd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1012,6 +1012,7 @@ void __init setup_arch(char **cmdline_p)
 	conswitchp = &dummy_con;
 #endif
 #endif
+	x86_init.oem.banner();
 }
 
 #ifdef CONFIG_X86_32

commit 42bbdb43b16d233b2dacb4cd76e28f61c2a86dc6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 13:04:10 2009 +0200

    x86: Replace ARCH_SETUP by a proper x86_init_ops
    
    ARCH_SETUP is a horrible leftover from the old arch/i386 mach support
    code. It still has a lonely user in xen. Move it to x86_init_ops.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bf3b87f1f7db..d12aa82c9c32 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -108,10 +108,6 @@
 #include <asm/numa_64.h>
 #endif
 
-#ifndef ARCH_SETUP
-#define ARCH_SETUP
-#endif
-
 /*
  * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
  * The direct mapping extends to max_pfn_mapped, so that we can directly access
@@ -750,7 +746,7 @@ void __init setup_arch(char **cmdline_p)
 	}
 #endif
 
-	ARCH_SETUP
+	x86_init.oem.arch_setup();
 
 	setup_memory_map();
 	parse_setup_data();

commit 428cf9025b15573e16e658032f2b963283e34ae0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 10:35:46 2009 +0200

    x86: Move traps_init to x86_init_ops
    
    Replace the quirks by a simple x86_init_ops function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d3da0f7333f7..bf3b87f1f7db 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1020,21 +1020,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 
-/**
- * x86_quirk_trap_init - initialise system specific traps
- *
- * Description:
- *	Called as the final act of trap_init().  Used in VISWS to initialise
- *	the various board specific APIC traps.
- **/
-void __init x86_quirk_trap_init(void)
-{
-	if (x86_quirks->arch_trap_init) {
-		if (x86_quirks->arch_trap_init())
-			return;
-	}
-}
-
 static struct irqaction irq0  = {
 	.handler = timer_interrupt,
 	.flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER,

commit 66bcaf0bde100a4b54b82fc6fea6ceee2212ffb4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 09:59:09 2009 +0200

    x86: Move irq_init to x86_init_ops
    
    irq_init is overridden by x86_quirks and by paravirts. Unify the whole
    mess and make it an unconditional x86_init_ops function which defaults
    to the standard function and can be overridden by the early platform
    code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 54043cb7ba68..d3da0f7333f7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1020,23 +1020,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 
-/**
- * x86_quirk_intr_init - post gate setup interrupt initialisation
- *
- * Description:
- *	Fill in any interrupts that may have been left out by the general
- *	init_IRQ() routine.  interrupts having to do with the machine rather
- *	than the devices on the I/O bus (like APIC interrupts in intel MP
- *	systems) are started here.
- **/
-void __init x86_quirk_intr_init(void)
-{
-	if (x86_quirks->arch_intr_init) {
-		if (x86_quirks->arch_intr_init())
-			return;
-	}
-}
-
 /**
  * x86_quirk_trap_init - initialise system specific traps
  *

commit b3f1b617f49447df6c3f5fac9c225aaea8b724ea
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 11:11:52 2009 +0200

    x86: Move get/find_smp_config to x86_init_ops
    
    Replace the quirk machinery by a x86_init_ops function which defaults
    to the standard implementation.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c2a8090e8312..54043cb7ba68 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -981,13 +981,11 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_init();
 
-#if defined(CONFIG_X86_MPPARSE) || defined(CONFIG_X86_VISWS)
 	/*
 	 * get boot-time SMP configuration:
 	 */
 	if (smp_found_config)
 		get_smp_config();
-#endif
 
 	prefill_possible_map();
 

commit 47d25003cbd9e9030a95f7ccc4e70fec6aa7b844
Author: Jan Beulich <JBeulich@novell.com>
Date:   Fri Aug 28 14:11:57 2009 +0100

    x86: Fix earlyprintk=dbgp for machines without NX
    
    Since parse_early_param() may (e.g. for earlyprintk=dbgp)
    involve calls to page table manipulation functions (here
    set_fixmap_nocache()), NX hardware support must be determined
    before calling that function (so that __supported_pte_mask gets
    properly set up).
    
    But the call after parse_early_param() can also not go away, as
    that will honor eventual command line specified disabling of
    the NX functionality.
    
    ( This will then just result in whatever mappings got
      established during parse_early_param() having the NX bit set
      despite it being disabled on the command line, but I think
      that's tolerable).
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Yinghai Lu <yhlu.kernel@gmail.com>
    LKML-Reference: <4A97F3BD02000078000121B9@vpn.id2.novell.com>
    [ merged to x86/pat to resolve a conflict. ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 02643cc3bf26..eb1f1e6e52b0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -714,6 +714,16 @@ void __init setup_arch(char **cmdline_p)
 	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
 	*cmdline_p = command_line;
 
+#ifdef CONFIG_X86_64
+	/*
+	 * Must call this twice: Once just to detect whether hardware doesn't
+	 * support NX (so that the early EHCI debug console setup can safely
+	 * call set_fixmap(), and then again after parsing early parameters to
+	 * honor the respective command line option.
+	 */
+	check_efer();
+#endif
+
 	parse_early_param();
 
 	/* VMI may relocate the fixmap; do this before touching ioremap area */

commit efafc8b213e67ed148a5b53ade29ee7b48af907d
Author: Feng Tang <feng.tang@intel.com>
Date:   Fri Aug 14 15:23:29 2009 -0400

    x86: add arch-specific SFI support
    
    arch/x86/kernel/sfi.c serves the dual-purpose of supporting the
    SFI core with arch specific code, as well as a home for the
    arch-specific code that uses SFI.
    
    analogous to ACPI, drivers/sfi/Kconfig is pulled in by arch/x86/Kconfig
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Cc: x86@kernel.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 63f32d220ef2..d784ea207606 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -27,6 +27,7 @@
 #include <linux/screen_info.h>
 #include <linux/ioport.h>
 #include <linux/acpi.h>
+#include <linux/sfi.h>
 #include <linux/apm_bios.h>
 #include <linux/initrd.h>
 #include <linux/bootmem.h>
@@ -990,6 +991,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_init();
 
+	sfi_init();
+
 #if defined(CONFIG_X86_MPPARSE) || defined(CONFIG_X86_VISWS)
 	/*
 	 * get boot-time SMP configuration:

commit 8fee697d990c54976c8dc167270633299e2515d2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Aug 19 14:55:50 2009 +0200

    x86: Add request_standard_resources to x86_init
    
    The 32bit and the 64bit code are slighty different in the reservation
    of standard resources. Also the upcoming Moorestown support needs its
    own version of that.
    
    Add it to x86_init_ops and initialize it with the 64bit default. 32bit
    overrides it in early boot. Now moorestown can add it's own override
    w/o sprinkling the code with more #ifdefs
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5796eb158d49..c2a8090e8312 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -171,13 +171,6 @@ static struct resource bss_resource = {
 
 
 #ifdef CONFIG_X86_32
-static struct resource video_ram_resource = {
-	.name	= "Video RAM area",
-	.start	= 0xa0000,
-	.end	= 0xbffff,
-	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
-};
-
 /* cpu data as detected by the assembly code in head.S */
 struct cpuinfo_x86 new_cpu_data __cpuinitdata = {0, 0, 0, 0, -1, 1, 0, 0, -1};
 /* common cpu data for all cpus */
@@ -605,7 +598,7 @@ static struct resource standard_io_resources[] = {
 		.flags = IORESOURCE_BUSY | IORESOURCE_IO }
 };
 
-static void __init reserve_standard_io_resources(void)
+void __init reserve_standard_io_resources(void)
 {
 	int i;
 
@@ -1013,10 +1006,7 @@ void __init setup_arch(char **cmdline_p)
 	e820_reserve_resources();
 	e820_mark_nosave_regions(max_low_pfn);
 
-#ifdef CONFIG_X86_32
-	request_resource(&iomem_resource, &video_ram_resource);
-#endif
-	reserve_standard_io_resources();
+	x86_init.resources.reserve_resources();
 
 	e820_setup_gap();
 
@@ -1102,4 +1092,18 @@ void __init x86_quirk_time_init(void)
 	irq0.mask = cpumask_of_cpu(0);
 	setup_irq(0, &irq0);
 }
+
+static struct resource video_ram_resource = {
+	.name	= "Video RAM area",
+	.start	= 0xa0000,
+	.end	= 0xbffff,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+};
+
+void __init i386_reserve_resources(void)
+{
+	request_resource(&iomem_resource, &video_ram_resource);
+	reserve_standard_io_resources();
+}
+
 #endif /* CONFIG_X86_32 */

commit f7cf5a5b8c0e59eac8d30b62271cb0fa52e53ebc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Aug 19 14:43:56 2009 +0200

    x86: Add probe_roms to x86_init
    
    probe_roms is only used on 32bit. Add it to the x86_init ops and
    remove the #ifdefs.
    
    Default initializer is x86_init_noop() which is overridden in
    the 32bit boot code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 63f32d220ef2..5796eb158d49 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -835,9 +835,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	init_hypervisor(&boot_cpu_data);
 
-#ifdef CONFIG_X86_32
-	probe_roms();
-#endif
+	x86_init.resources.probe_roms();
 
 	/* after parse_early_param, so could debug it */
 	insert_resource(&iomem_resource, &code_resource);

commit 8126dec32738421afa362114337331337b4be17f
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Thu Aug 20 20:23:11 2009 +0800

    x86: Fix system crash when loading with "reservetop" parameter
    
    The system will die if the kernel is booted with "reservetop"
    parameter, in present code, parse "reservetop" parameter after
    early_ioremap_init(), and some function still use
    early_ioremap() after it.
    
    The problem is, "reservetop" parameter can modify
    'FIXADDR_TOP', then the virtual address got by early_ioremap()
    is base on old 'FIXADDR_TOP', but the page mapping is base on
    new 'FIXADDR_TOP', it will occur page fault, and the IDT is not
    prepare yet, so, the system is dead.
    
    So, put parse_early_param() in the front of
    early_ioremap_init() in this patch.
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Cc: yinghai@kernel.org
    Cc: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <4A8D402F.4080805@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 63f32d220ef2..02643cc3bf26 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -711,6 +711,11 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
+	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
+	*cmdline_p = command_line;
+
+	parse_early_param();
+
 	/* VMI may relocate the fixmap; do this before touching ioremap area */
 	vmi_init();
 
@@ -793,11 +798,6 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #endif
 
-	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
-	*cmdline_p = command_line;
-
-	parse_early_param();
-
 #ifdef CONFIG_X86_64
 	check_efer();
 #endif

commit 3162534069597e34dd0ac9eb711be8dc23835ae7
Author: Joseph Cihula <joseph.cihula@intel.com>
Date:   Tue Jun 30 19:30:59 2009 -0700

    x86, intel_txt: Intel TXT boot support
    
    This patch adds kernel configuration and boot support for Intel Trusted
    Execution Technology (Intel TXT).
    
    Intel's technology for safer computing, Intel Trusted Execution
    Technology (Intel TXT), defines platform-level enhancements that
    provide the building blocks for creating trusted platforms.
    
    Intel TXT was formerly known by the code name LaGrande Technology (LT).
    
    Intel TXT in Brief:
    o  Provides dynamic root of trust for measurement (DRTM)
    o  Data protection in case of improper shutdown
    o  Measurement and verification of launched environment
    
    Intel TXT is part of the vPro(TM) brand and is also available some
    non-vPro systems.  It is currently available on desktop systems based on
    the Q35, X38, Q45, and Q43 Express chipsets (e.g. Dell Optiplex 755, HP
    dc7800, etc.) and mobile systems based on the GM45, PM45, and GS45
    Express chipsets.
    
    For more information, see http://www.intel.com/technology/security/.
    This site also has a link to the Intel TXT MLE Developers Manual, which
    has been updated for the new released platforms.
    
    A much more complete description of how these patches support TXT, how to
    configure a system for it, etc. is in the Documentation/intel_txt.txt file
    in this patch.
    
    This patch provides the TXT support routines for complete functionality,
    documentation for TXT support and for the changes to the boot_params structure,
    and boot detection of a TXT launch.  Attempts to shutdown (reboot, Sx) the system
    will result in platform resets; subsequent patches will support these shutdown modes
    properly.
    
     Documentation/intel_txt.txt      |  210 +++++++++++++++++++++
     Documentation/x86/zero-page.txt  |    1
     arch/x86/include/asm/bootparam.h |    3
     arch/x86/include/asm/fixmap.h    |    3
     arch/x86/include/asm/tboot.h     |  197 ++++++++++++++++++++
     arch/x86/kernel/Makefile         |    1
     arch/x86/kernel/setup.c          |    4
     arch/x86/kernel/tboot.c          |  379 +++++++++++++++++++++++++++++++++++++++
     security/Kconfig                 |   30 +++
     9 files changed, 827 insertions(+), 1 deletion(-)
    
    Signed-off-by: Joseph Cihula <joseph.cihula@intel.com>
    Signed-off-by: Shane Wang <shane.wang@intel.com>
    Signed-off-by: Gang Wei <gang.wei@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index de2cab132844..80d6e9e32483 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -145,6 +145,8 @@ struct boot_params __initdata boot_params;
 struct boot_params boot_params;
 #endif
 
+#include <asm/tboot.h>
+
 /*
  * Machine setup..
  */
@@ -964,6 +966,8 @@ void __init setup_arch(char **cmdline_p)
 	paravirt_pagetable_setup_done(swapper_pg_dir);
 	paravirt_post_allocator_init();
 
+	tboot_probe();
+
 #ifdef CONFIG_X86_64
 	map_vsyscall();
 #endif

commit 6aa542a694dc9ea4344a8a590d2628c33d1b9431
Author: Alexey Fisher <bug-track@fisher-privat.net>
Date:   Wed Jul 15 14:16:09 2009 +0200

    x86: Add quirk for Intel DG45ID board to avoid low memory corruption
    
    AMI BIOS with low memory corruption was found on Intel DG45ID
    board (Bug 13710). Add this board to the blacklist - in the
    (somewhat optimistic) hope of future boards/BIOSes from Intel
    not having this bug.
    
    Also see:
    
      http://bugzilla.kernel.org/show_bug.cgi?id=13736
    
    Signed-off-by: Alexey Fisher <bug-track@fisher-privat.net>
    Cc: ykzhao <yakui.zhao@intel.com>
    Cc: alan@lxorguk.ukuu.org.uk
    Cc: <stable@kernel.org>
    LKML-Reference: <1247660169-4503-1-git-send-email-bug-track@fisher-privat.net>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index de2cab132844..63f32d220ef2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -672,6 +672,19 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies"),
 		},
 	},
+	{
+	/*
+	 * AMI BIOS with low memory corruption was found on Intel DG45ID board.
+	 * It hase different DMI_BIOS_VENDOR = "Intel Corp.", for now we will
+	 * match only DMI_BOARD_NAME and see if there is more bad products
+	 * with this vendor.
+	 */
+		.callback = dmi_low_memory_corruption,
+		.ident = "AMI BIOS",
+		.matches = {
+			DMI_MATCH(DMI_BOARD_NAME, "DG45ID"),
+		},
+	},
 #endif
 	{}
 };

commit 854c879f5abf309ebd378bea1ee41acf4ddf7194
Author: Pekka J Enberg <penberg@cs.helsinki.fi>
Date:   Mon Jun 22 17:39:41 2009 +0300

    x86: Move init_gbpages() to setup_arch()
    
    The init_gbpages() function is conditionally called from
    init_memory_mapping() function. There are two call-sites where
    this 'after_bootmem' condition can be true: setup_arch() and
    mem_init() via pci_iommu_alloc().
    
    Therefore, it's safe to move the call to init_gbpages() to
    setup_arch() as it's always called before mem_init().
    
    This removes an after_bootmem use - paving the way to remove
    all uses of that state variable.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <Pine.LNX.4.64.0906221731210.19474@melkki.cs.Helsinki.FI>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index be5ae80f897f..de2cab132844 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -289,6 +289,20 @@ void * __init extend_brk(size_t size, size_t align)
 	return ret;
 }
 
+#ifdef CONFIG_X86_64
+static void __init init_gbpages(void)
+{
+	if (direct_gbpages && cpu_has_gbpages)
+		printk(KERN_INFO "Using GB pages for direct mapping\n");
+	else
+		direct_gbpages = 0;
+}
+#else
+static inline void init_gbpages(void)
+{
+}
+#endif
+
 static void __init reserve_brk(void)
 {
 	if (_brk_end > _brk_start)
@@ -871,6 +885,8 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_brk();
 
+	init_gbpages();
+
 	/* max_pfn_mapped is updated here */
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;

commit 8c5dd8f43367f4f266dd616f11658005bc2d20ef
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jun 4 19:14:22 2009 -0700

    x86: handle initrd that extends into unusable memory
    
    On a system where system memory (according e820) is not covered by
    mtrr, mtrr_trim_memory converts a portion of memory to reserved, but
    bootloader has already put the initrd in that range.
    
    Thus, we need to have 64bit to use relocate_initrd too.
    
    [ Impact: fix using initrd when mtrr_trim_memory happen ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: stable@kernel.org

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d1c636bf31a7..be5ae80f897f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -301,15 +301,13 @@ static void __init reserve_brk(void)
 
 #ifdef CONFIG_BLK_DEV_INITRD
 
-#ifdef CONFIG_X86_32
-
 #define MAX_MAP_CHUNK	(NR_FIX_BTMAPS << PAGE_SHIFT)
 static void __init relocate_initrd(void)
 {
 
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
-	u64 end_of_lowmem = max_low_pfn << PAGE_SHIFT;
+	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
 	u64 ramdisk_here;
 	unsigned long slop, clen, mapaddr;
 	char *p, *q;
@@ -365,14 +363,13 @@ static void __init relocate_initrd(void)
 		ramdisk_image, ramdisk_image + ramdisk_size - 1,
 		ramdisk_here, ramdisk_here + ramdisk_size - 1);
 }
-#endif
 
 static void __init reserve_initrd(void)
 {
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
 	u64 ramdisk_end   = ramdisk_image + ramdisk_size;
-	u64 end_of_lowmem = max_low_pfn << PAGE_SHIFT;
+	u64 end_of_lowmem = max_low_pfn_mapped << PAGE_SHIFT;
 
 	if (!boot_params.hdr.type_of_loader ||
 	    !ramdisk_image || !ramdisk_size)
@@ -402,14 +399,8 @@ static void __init reserve_initrd(void)
 		return;
 	}
 
-#ifdef CONFIG_X86_32
 	relocate_initrd();
-#else
-	printk(KERN_ERR "initrd extends beyond end of memory "
-	       "(0x%08llx > 0x%08llx)\ndisabling initrd\n",
-	       ramdisk_end, end_of_lowmem);
-	initrd_start = 0;
-#endif
+
 	free_early(ramdisk_image, ramdisk_end);
 }
 #else

commit bb7762961d3ce745688e9050e914c1d3f980268d
Merge: 48c72d1ab4ec 35d5a9a61490
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 10 16:13:20 2009 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (22 commits)
      x86: fix system without memory on node0
      x86, mm: Fix node_possible_map logic
      mm, x86: remove MEMORY_HOTPLUG_RESERVE related code
      x86: make sparse mem work in non-NUMA mode
      x86: process.c, remove useless headers
      x86: merge process.c a bit
      x86: use sparse_memory_present_with_active_regions() on UMA
      x86: unify 64-bit UMA and NUMA paging_init()
      x86: Allow 1MB of slack between the e820 map and SRAT, not 4GB
      x86: Sanity check the e820 against the SRAT table using e820 map only
      x86: clean up and and print out initial max_pfn_mapped
      x86/pci: remove rounding quirk from e820_setup_gap()
      x86, e820, pci: reserve extra free space near end of RAM
      x86: fix typo in address space documentation
      x86: 46 bit physical address support on 64 bits
      x86, mm: fault.c, use printk_once() in is_errata93()
      x86: move per-cpu mmu_gathers to mm/init.c
      x86: move max_pfn_mapped and max_low_pfn_mapped to setup.c
      x86: unify noexec handling
      x86: remove (null) in /sys kernel_page_tables
      ...

commit 82782ca77d1bfb32b0334cce40a25b91bd8ec016
Merge: f0d5e12bd42b 6799687a53a2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 10 15:30:41 2009 -0700

    Merge branch 'x86-kbuild-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-kbuild-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (46 commits)
      x86, boot: add new generated files to the appropriate .gitignore files
      x86, boot: correct the calculation of ZO_INIT_SIZE
      x86-64: align __PHYSICAL_START, remove __KERNEL_ALIGN
      x86, boot: correct sanity checks in boot/compressed/misc.c
      x86: add extension fields for bootloader type and version
      x86, defconfig: update kernel position parameters
      x86, defconfig: update to current, no material changes
      x86: make CONFIG_RELOCATABLE the default
      x86: default CONFIG_PHYSICAL_START and CONFIG_PHYSICAL_ALIGN to 16 MB
      x86: document new bzImage fields
      x86, boot: make kernel_alignment adjustable; new bzImage fields
      x86, boot: remove dead code from boot/compressed/head_*.S
      x86, boot: use LOAD_PHYSICAL_ADDR on 64 bits
      x86, boot: make symbols from the main vmlinux available
      x86, boot: determine compressed code offset at compile time
      x86, boot: use appropriate rep string for move and clear
      x86, boot: zero EFLAGS on 32 bits
      x86, boot: set up the decompression stack as early as possible
      x86, boot: straighten out ranges to copy/zero in compressed/head*.S
      x86, boot: stylistic cleanups for boot/compressed/head_64.S
      ...
    
    Fixed trivial conflict in arch/x86/configs/x86_64_defconfig manually

commit 5031296c57024a78ddad4edfc993367dbf4abb98
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Thu May 7 16:54:11 2009 -0700

    x86: add extension fields for bootloader type and version
    
    A long ago, in days of yore, it all began with a god named Thor.
    There were vikings and boats and some plans for a Linux kernel
    header.  Unfortunately, a single 8-bit field was used for bootloader
    type and version.  This has generally worked without *too* much pain,
    but we're getting close to flat running out of ID fields.
    
    Add extension fields for both type and version.  The type will be
    extended if it the old field is 0xE; the version is a simple MSB
    extension.
    
    Keep /proc/sys/kernel/bootloader_type containing
    (type << 4) + (ver & 0xf) for backwards compatiblity, but also add
    /proc/sys/kernel/bootloader_version which contains the full version
    number.
    
    [ Impact: new feature to support more bootloaders ]
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4158439bf63..2b093451aec9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -214,8 +214,8 @@ unsigned long mmu_cr4_features;
 unsigned long mmu_cr4_features = X86_CR4_PAE;
 #endif
 
-/* Boot loader ID as an integer, for the benefit of proc_dointvec */
-int bootloader_type;
+/* Boot loader ID and version as integers, for the benefit of proc_dointvec */
+int bootloader_type, bootloader_version;
 
 /*
  * Setup options
@@ -706,6 +706,12 @@ void __init setup_arch(char **cmdline_p)
 #endif
 	saved_video_mode = boot_params.hdr.vid_mode;
 	bootloader_type = boot_params.hdr.type_of_loader;
+	if ((bootloader_type >> 4) == 0xe) {
+		bootloader_type &= 0xf;
+		bootloader_type |= (boot_params.hdr.ext_loader_type+0x10) << 4;
+	}
+	bootloader_version  = bootloader_type & 0xf;
+	bootloader_version |= boot_params.hdr.ext_loader_ver << 4;
 
 #ifdef CONFIG_BLK_DEV_RAM
 	rd_image_start = boot_params.hdr.ram_size & RAMDISK_IMAGE_START_MASK;

commit 80989ce0643c1034822f3e339ed8d790b649abe1
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sat May 9 23:47:42 2009 -0700

    x86: clean up and and print out initial max_pfn_mapped
    
    Do this so we can check the range that is mapped before
    init_memory_mapping().
    
    To be able to print out meaningful info, we first have to fix
    64-bit to have max_pfn_mapped assigned before that call. This
    also unifies the code-path a bit.
    
    [ Impact: print more debug info, cleanup ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <49BF0978.40605@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0d77e56e821b..4031d6cb3ff9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -862,12 +862,16 @@ void __init setup_arch(char **cmdline_p)
 		max_low_pfn = max_pfn;
 
 	high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
+	max_pfn_mapped = KERNEL_IMAGE_SIZE >> PAGE_SHIFT;
 #endif
 
 #ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
 	setup_bios_corruption_check();
 #endif
 
+	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
+			max_pfn_mapped<<PAGE_SHIFT);
+
 	reserve_brk();
 
 	/* max_pfn_mapped is updated here */

commit 2b72394e4089643f11669d9610907a1442fe044a
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Tue Apr 28 16:00:49 2009 +0300

    x86: move max_pfn_mapped and max_low_pfn_mapped to setup.c
    
    This patch moves the max_pfn_mapped and max_low_pfn_mapped global
    variables to kernel/setup.c where they're initialized.
    
    [ Impact: cleanup ]
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    LKML-Reference: <1240923649.1982.21.camel@penberg-laptop>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4158439bf63..0d77e56e821b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -112,6 +112,14 @@
 #define ARCH_SETUP
 #endif
 
+/*
+ * end_pfn only includes RAM, while max_pfn_mapped includes all e820 entries.
+ * The direct mapping extends to max_pfn_mapped, so that we can directly access
+ * apertures, ACPI and other tables without having to play with fixmaps.
+ */
+unsigned long max_low_pfn_mapped;
+unsigned long max_pfn_mapped;
+
 RESERVE_BRK(dmi_alloc, 65536);
 
 unsigned int boot_cpu_id __read_mostly;

commit f465145235313c451164bdfa9037ac254bf00c9a
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Thu Apr 9 11:52:18 2009 +0300

    x86: move x86_quirk_pre_intr_init() to irqinit_32.c
    
    Impact: cleanup
    
    In preparation for unifying irqinit_{32,64}.c, make
    x86_quirk_pre_intr_init() local to irqinit_32.c.
    
    Reviewed-by Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4158439bf63..523bb697120d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -996,24 +996,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 
-/**
- * x86_quirk_pre_intr_init - initialisation prior to setting up interrupt vectors
- *
- * Description:
- *	Perform any necessary interrupt initialisation prior to setting up
- *	the "ordinary" interrupt call gates.  For legacy reasons, the ISA
- *	interrupts should be initialised here if the machine emulates a PC
- *	in any way.
- **/
-void __init x86_quirk_pre_intr_init(void)
-{
-	if (x86_quirks->arch_pre_intr_init) {
-		if (x86_quirks->arch_pre_intr_init())
-			return;
-	}
-	init_ISA_irqs();
-}
-
 /**
  * x86_quirk_intr_init - post gate setup interrupt initialisation
  *

commit d17abcd5417d84cfa8a225160481203a37dc81d4
Merge: db6f20401938 bb75efddeaca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 30 18:00:26 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-cpumask
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-cpumask:
      oprofile: Thou shalt not call __exit functions from __init functions
      cpumask: remove the now-obsoleted pcibus_to_cpumask(): generic
      cpumask: remove cpumask_t from core
      cpumask: convert rcutorture.c
      cpumask: use new cpumask_ functions in core code.
      cpumask: remove references to struct irqaction's mask field.
      cpumask: use mm_cpumask() wrapper: kernel/fork.c
      cpumask: use set_cpu_active in init/main.c
      cpumask: remove node_to_first_cpu
      cpumask: fix seq_bitmap_*() functions.
      cpumask: remove dangerous CPU_MASK_ALL_PTR, &CPU_MASK_ALL

commit 1a8a51004a18b627ea81444201f7867875212f46
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Mar 30 22:05:13 2009 -0600

    cpumask: remove references to struct irqaction's mask field.
    
    Impact: cleanup
    
    It's unused, since about 1995.  So remove all initialization of it in
    preparation for actually removing the field.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b746deb9ebc6..900dad7fe38d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1027,7 +1027,6 @@ void __init x86_quirk_trap_init(void)
 static struct irqaction irq0  = {
 	.handler = timer_interrupt,
 	.flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER,
-	.mask = CPU_MASK_NONE,
 	.name = "timer"
 };
 

commit 6e15cf04860074ad032e88c306bea656bbdd0f22
Merge: be0ea69674ed 60db56422043
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 26 21:39:17 2009 +0100

    Merge branch 'core/percpu' into percpu-cpumask-x86-for-linus-2
    
    Conflicts:
            arch/parisc/kernel/irq.c
            arch/x86/include/asm/fixmap_64.h
            arch/x86/include/asm/setup.h
            kernel/irq/handle.c
    
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 796216a57fe45c04adc35bda1f0782efec78a713
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Thu Mar 12 16:09:49 2009 -0700

    x86: allow extend_brk users to reserve brk space
    
    Impact: new interface; remove hard-coded limit
    
    Add RESERVE_BRK(name, size) macro to reserve space in the brk
    area.  This should be a conservative (ie, larger) estimate of
    how much space might possibly be required from the brk area.
    Any unused space will be freed, so there's no real downside
    on making the reservation too large (within limits).
    
    The name should be unique within a given file, and somewhat
    descriptive.
    
    The C definition of RESERVE_BRK() ends up being more complex than
    one would expect to work around a cluster of gcc infelicities:
    
      The first attempt was to simply try putting __section(.brk_reservation)
      on a variable.  This doesn't work because it ends up making it a
      @progbits section, which gets actual space allocated in the vmlinux
      executable.
    
      The second attempt was to emit the space into a section using asm,
      but gcc doesn't allow arguments to be passed to file-level asm()
      statements, making it hard to pass in the size.
    
      The final attempt is to wrap the asm() in a function to allow
      it to have arguments, and put the function itself into the
      .discard section, which vmlinux*.lds drops entirely from the
      emitted vmlinux.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e894f36335f2..a0d26237d7cf 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -112,6 +112,8 @@
 #define ARCH_SETUP
 #endif
 
+RESERVE_BRK(dmi_alloc, 65536);
+
 unsigned int boot_cpu_id __read_mostly;
 
 static __initdata unsigned long _brk_start = (unsigned long)__brk_base;

commit 6de6cb442e76bbaf2e685150be8ddac0f237a59c
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Fri Feb 27 13:35:45 2009 -0800

    x86: use brk allocation for DMI
    
    Impact: use new interface instead of previous ad hoc implementation
    
    Use extend_brk() to allocate memory for DMI rather than having an
    ad-hoc allocator.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3ac2aa7b9eaf..e894f36335f2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -215,12 +215,6 @@ unsigned long mmu_cr4_features = X86_CR4_PAE;
 /* Boot loader ID as an integer, for the benefit of proc_dointvec */
 int bootloader_type;
 
-/*
- * Early DMI memory
- */
-int dmi_alloc_index;
-char dmi_alloc_data[DMI_MAX_DATA];
-
 /*
  * Setup options
  */

commit ccf3fe02e35f4abca2589f99022cc25084bbd8ae
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Fri Feb 27 13:27:38 2009 -0800

    x86-32: use brk segment for allocating initial kernel pagetable
    
    Impact: use new interface instead of previous ad hoc implementation
    
    Rather than having special purpose init_pg_table_start/end variables
    to delimit the kernel pagetable built by head_32.S, just use the brk
    mechanism to extend the bss for the new pagetable.
    
    This patch removes init_pg_table_start/end and pg0, defines __brk_base
    (which is page-aligned and immediately follows _end), initializes
    the brk region to start there, and uses it for the 32-bit pagetable.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b8329029c150..3ac2aa7b9eaf 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -161,12 +161,6 @@ static struct resource bss_resource = {
 
 
 #ifdef CONFIG_X86_32
-/* This value is set up by the early boot code to point to the value
-   immediately after the boot time page tables.  It contains a *physical*
-   address, and must not be in the .bss segment! */
-unsigned long init_pg_tables_start __initdata = ~0UL;
-unsigned long init_pg_tables_end __initdata = ~0UL;
-
 static struct resource video_ram_resource = {
 	.name	= "Video RAM area",
 	.start	= 0xa0000,

commit 5368a2be34b96fda9c05d79424fa63a73ead04ed
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Sat Mar 14 17:19:51 2009 -0700

    x86: move brk initialization out of #ifdef CONFIG_BLK_DEV_INITRD
    
    Impact: build fix
    
    The brk initialization functions were incorrectly located inside
    an #ifdef CONFIG_VLK_DEV_INITRD block, causing the obvious build failure in
    minimal configurations.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e6b742d2a3f5..b8329029c150 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -272,6 +272,35 @@ static inline void copy_edd(void)
 }
 #endif
 
+void * __init extend_brk(size_t size, size_t align)
+{
+	size_t mask = align - 1;
+	void *ret;
+
+	BUG_ON(_brk_start == 0);
+	BUG_ON(align & mask);
+
+	_brk_end = (_brk_end + mask) & ~mask;
+	BUG_ON((char *)(_brk_end + size) > __brk_limit);
+
+	ret = (void *)_brk_end;
+	_brk_end += size;
+
+	memset(ret, 0, size);
+
+	return ret;
+}
+
+static void __init reserve_brk(void)
+{
+	if (_brk_end > _brk_start)
+		reserve_early(__pa(_brk_start), __pa(_brk_end), "BRK");
+
+	/* Mark brk area as locked down and no longer taking any
+	   new allocations */
+	_brk_start = 0;
+}
+
 #ifdef CONFIG_BLK_DEV_INITRD
 
 #ifdef CONFIG_X86_32
@@ -340,34 +369,6 @@ static void __init relocate_initrd(void)
 }
 #endif
 
-void * __init extend_brk(size_t size, size_t align)
-{
-	size_t mask = align - 1;
-	void *ret;
-
-	BUG_ON(_brk_start == 0);
-	BUG_ON(align & mask);
-
-	_brk_end = (_brk_end + mask) & ~mask;
-	BUG_ON((char *)(_brk_end + size) > __brk_limit);
-
-	ret = (void *)_brk_end;
-	_brk_end += size;
-
-	memset(ret, 0, size);
-
-	return ret;
-}
-
-static void __init reserve_brk(void)
-{
-	if (_brk_end > _brk_start)
-		reserve_early(__pa(_brk_start), __pa(_brk_end), "BRK");
-
-	/* Mark brk area as locked down and no longer taking any new allocations */
-	_brk_start = 0;
-}
-
 static void __init reserve_initrd(void)
 {
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;

commit 93dbda7cbcd70a0bd1a99f39f44a9ccde8ab9040
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Thu Feb 26 17:35:44 2009 -0800

    x86: add brk allocation for very, very early allocations
    
    Impact: new interface
    
    Add a brk()-like allocator which effectively extends the bss in order
    to allow very early code to do dynamic allocations.  This is better than
    using statically allocated arrays for data in subsystems which may never
    get used.
    
    The space for brk allocations is in the bss ELF segment, so that the
    space is mapped properly by the code which maps the kernel, and so
    that bootloaders keep the space free rather than putting a ramdisk or
    something into it.
    
    The bss itself, delimited by __bss_stop, ends before the brk area
    (__brk_base to __brk_limit).  The kernel text, data and bss is reserved
    up to __bss_stop.
    
    Any brk-allocated data is reserved separately just before the kernel
    pagetable is built, as that code allocates from unreserved spaces
    in the e820 map, potentially allocating from any unused brk memory.
    Ultimately any unused memory in the brk area is used in the general
    kernel memory pool.
    
    Initially the brk space is set to 1MB, which is probably much larger
    than any user needs (the largest current user is i386 head_32.S's code
    to build the pagetables to map the kernel, which can get fairly large
    with a big kernel image and no PSE support).  So long as the system
    has sufficient memory for the bootloader to reserve the kernel+1MB brk,
    there are no bad effects resulting from an over-large brk.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f28c56e6bf94..e6b742d2a3f5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -114,6 +114,9 @@
 
 unsigned int boot_cpu_id __read_mostly;
 
+static __initdata unsigned long _brk_start = (unsigned long)__brk_base;
+unsigned long _brk_end = (unsigned long)__brk_base;
+
 #ifdef CONFIG_X86_64
 int default_cpu_present_to_apicid(int mps_cpu)
 {
@@ -337,6 +340,34 @@ static void __init relocate_initrd(void)
 }
 #endif
 
+void * __init extend_brk(size_t size, size_t align)
+{
+	size_t mask = align - 1;
+	void *ret;
+
+	BUG_ON(_brk_start == 0);
+	BUG_ON(align & mask);
+
+	_brk_end = (_brk_end + mask) & ~mask;
+	BUG_ON((char *)(_brk_end + size) > __brk_limit);
+
+	ret = (void *)_brk_end;
+	_brk_end += size;
+
+	memset(ret, 0, size);
+
+	return ret;
+}
+
+static void __init reserve_brk(void)
+{
+	if (_brk_end > _brk_start)
+		reserve_early(__pa(_brk_start), __pa(_brk_end), "BRK");
+
+	/* Mark brk area as locked down and no longer taking any new allocations */
+	_brk_start = 0;
+}
+
 static void __init reserve_initrd(void)
 {
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
@@ -717,11 +748,7 @@ void __init setup_arch(char **cmdline_p)
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code = (unsigned long) _etext;
 	init_mm.end_data = (unsigned long) _edata;
-#ifdef CONFIG_X86_32
-	init_mm.brk = init_pg_tables_end + PAGE_OFFSET;
-#else
-	init_mm.brk = (unsigned long) &_end;
-#endif
+	init_mm.brk = _brk_end;
 
 	code_resource.start = virt_to_phys(_text);
 	code_resource.end = virt_to_phys(_etext)-1;
@@ -842,6 +869,8 @@ void __init setup_arch(char **cmdline_p)
 	setup_bios_corruption_check();
 #endif
 
+	reserve_brk();
+
 	/* max_pfn_mapped is updated here */
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;

commit ed26dbe5ae045e5bf95c6dc27497397a3fde52e1
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Wed Mar 4 16:16:51 2009 -0800

    x86: pre-initialize boot_cpu_data.x86_phys_bits to avoid system_state tests
    
    Impact: cleanup, micro-optimization
    
    Pre-initialize boot_cpu_data.x86_phys_bits to a reasonable default
    to remove the use of system_state tests in __virt_addr_valid()
    and __phys_addr().
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b746deb9ebc6..f28c56e6bf94 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -202,7 +202,9 @@ struct ist_info ist_info;
 #endif
 
 #else
-struct cpuinfo_x86 boot_cpu_data __read_mostly;
+struct cpuinfo_x86 boot_cpu_data __read_mostly = {
+	.x86_phys_bits = MAX_PHYSMEM_BITS,
+};
 EXPORT_SYMBOL(boot_cpu_data);
 #endif
 

commit 6d2e91bf80e4410207f01edb0962aec9213f3533
Merge: 6298e719cf38 dd39ecf522ba
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Mar 4 20:20:10 2009 +0100

    Merge branch 'x86/urgent' into x86/mm
    
    Conflicts:
            arch/x86/include/asm/fixmap_64.h
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit ff0c0874905fb312ca1491bbdac2653b0b48c20b
Author: Brian Maly <bmaly@redhat.com>
Date:   Tue Mar 3 21:55:31 2009 -0500

    x86: fix DMI on EFI
    
    Impact: reactivate DMI quirks on EFI hardware
    
    DMI tables are loaded by EFI, so the dmi calls must happen after
    efi_init() and not before.
    
    Currently Apple hardware uses DMI to determine the framebuffer mappings
    for efifb. Without DMI working you also have no video on MacBook Pro.
    
    This patch resolves the DMI issue for EFI hardware (DMI is now properly
    detected at boot), and additionally efifb now loads on Apple hardware
    (i.e. video works).
    
    Signed-off-by: Brian Maly <bmaly@redhat>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Cc: ying.huang@intel.com
    LKML-Reference: <49ADEDA3.1030406@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    
     arch/x86/kernel/setup.c |    5 +++--
     1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c461f6d69074..6a8811a69324 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -770,6 +770,9 @@ void __init setup_arch(char **cmdline_p)
 
 	finish_e820_parsing();
 
+	if (efi_enabled)
+		efi_init();
+
 	dmi_scan_machine();
 
 	dmi_check_system(bad_bios_dmi_table);
@@ -789,8 +792,6 @@ void __init setup_arch(char **cmdline_p)
 	insert_resource(&iomem_resource, &data_resource);
 	insert_resource(&iomem_resource, &bss_resource);
 
-	if (efi_enabled)
-		efi_init();
 
 #ifdef CONFIG_X86_32
 	if (ppro_with_ram_bug()) {

commit 129d8bc828e011bda0b7110a097bf3a0167f966e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 25 21:20:50 2009 -0800

    x86: don't compile vsmp_64 for 32bit
    
    Impact: cleanup
    
    that is only needed when CONFIG_X86_VSMP is defined with 64bit
    also remove dead code about PCI, because CONFIG_X86_VSMP depends on PCI
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Ravikiran Thirumalai <kiran@scalex86.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2280d93c5b90..4c54bc0d8ff3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -863,9 +863,7 @@ void __init setup_arch(char **cmdline_p)
 
 	reserve_initrd();
 
-#ifdef CONFIG_X86_64
 	vsmp_init();
-#endif
 
 	io_delay_init();
 

commit 2b6163bf5772644068694583816fa41e8474239f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 25 20:50:49 2009 -0800

    x86: remove update_apic from x86_quirks
    
    Impact: cleanup
    
    x86_quirks->update_apic() calling looks crazy. so try to remove it:
    
     1. every apic take wakeup_cpu member directly
     2. separate es7000_apic to es7000_apic_cluster
     3. use uv_wakeup_cpu directly
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5b85759e7972..2280d93c5b90 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -600,19 +600,7 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
-static int __init default_update_apic(void)
-{
-#ifdef CONFIG_SMP
-	if (!apic->wakeup_cpu)
-		apic->wakeup_cpu = wakeup_secondary_cpu_via_init;
-#endif
-
-	return 0;
-}
-
-static struct x86_quirks default_x86_quirks __initdata = {
-	.update_apic         = default_update_apic,
-};
+static struct x86_quirks default_x86_quirks __initdata;
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 

commit 8e6dafd6c741cd4679b4de3c5d9698851e4fa59c
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 23 00:34:39 2009 +0100

    x86: refactor x86_quirks support
    
    Impact: cleanup
    
    Make x86_quirks support more transparent. The highlevel
    methods are now named:
    
      extern void x86_quirk_pre_intr_init(void);
      extern void x86_quirk_intr_init(void);
    
      extern void x86_quirk_trap_init(void);
    
      extern void x86_quirk_pre_time_init(void);
      extern void x86_quirk_time_init(void);
    
    This makes it clear that if some platform extension has to
    do something here that it is considered ... weird, and is
    discouraged.
    
    Also remove arch_hooks.h and move it into setup.h (and other
    header files where appropriate).
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d4de1e4c2045..5b85759e7972 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -74,8 +74,9 @@
 #include <asm/e820.h>
 #include <asm/mpspec.h>
 #include <asm/setup.h>
-#include <asm/arch_hooks.h>
 #include <asm/efi.h>
+#include <asm/timer.h>
+#include <asm/i8259.h>
 #include <asm/sections.h>
 #include <asm/dmi.h>
 #include <asm/io_apic.h>
@@ -987,7 +988,7 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_32
 
 /**
- * pre_intr_init_hook - initialisation prior to setting up interrupt vectors
+ * x86_quirk_pre_intr_init - initialisation prior to setting up interrupt vectors
  *
  * Description:
  *	Perform any necessary interrupt initialisation prior to setting up
@@ -995,7 +996,7 @@ void __init setup_arch(char **cmdline_p)
  *	interrupts should be initialised here if the machine emulates a PC
  *	in any way.
  **/
-void __init pre_intr_init_hook(void)
+void __init x86_quirk_pre_intr_init(void)
 {
 	if (x86_quirks->arch_pre_intr_init) {
 		if (x86_quirks->arch_pre_intr_init())
@@ -1005,7 +1006,7 @@ void __init pre_intr_init_hook(void)
 }
 
 /**
- * intr_init_hook - post gate setup interrupt initialisation
+ * x86_quirk_intr_init - post gate setup interrupt initialisation
  *
  * Description:
  *	Fill in any interrupts that may have been left out by the general
@@ -1013,7 +1014,7 @@ void __init pre_intr_init_hook(void)
  *	than the devices on the I/O bus (like APIC interrupts in intel MP
  *	systems) are started here.
  **/
-void __init intr_init_hook(void)
+void __init x86_quirk_intr_init(void)
 {
 	if (x86_quirks->arch_intr_init) {
 		if (x86_quirks->arch_intr_init())
@@ -1022,13 +1023,13 @@ void __init intr_init_hook(void)
 }
 
 /**
- * trap_init_hook - initialise system specific traps
+ * x86_quirk_trap_init - initialise system specific traps
  *
  * Description:
  *	Called as the final act of trap_init().  Used in VISWS to initialise
  *	the various board specific APIC traps.
  **/
-void __init trap_init_hook(void)
+void __init x86_quirk_trap_init(void)
 {
 	if (x86_quirks->arch_trap_init) {
 		if (x86_quirks->arch_trap_init())
@@ -1044,23 +1045,23 @@ static struct irqaction irq0  = {
 };
 
 /**
- * pre_time_init_hook - do any specific initialisations before.
+ * x86_quirk_pre_time_init - do any specific initialisations before.
  *
  **/
-void __init pre_time_init_hook(void)
+void __init x86_quirk_pre_time_init(void)
 {
 	if (x86_quirks->arch_pre_time_init)
 		x86_quirks->arch_pre_time_init();
 }
 
 /**
- * time_init_hook - do any specific initialisations for the system timer.
+ * x86_quirk_time_init - do any specific initialisations for the system timer.
  *
  * Description:
  *	Must plug the system timer interrupt source at HZ into the IRQ listed
  *	in irq_vectors.h:TIMER_IRQ
  **/
-void __init time_init_hook(void)
+void __init x86_quirk_time_init(void)
 {
 	if (x86_quirks->arch_time_init) {
 		/*

commit d85a881d780cc7aaebe1b7aefcddbcb939acbe2d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 23 00:29:45 2009 +0100

    x86: remove various unused subarch hooks
    
    Impact: remove dead code
    
    Remove:
    
     - pre_setup_arch_hook()
     - mca_nmi_hook()
    
    If needed they can be added back via an x86_quirk handler.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d699811b3f7c..d4de1e4c2045 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -668,7 +668,6 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
-	pre_setup_arch_hook();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
@@ -1022,18 +1021,6 @@ void __init intr_init_hook(void)
 	}
 }
 
-/**
- * pre_setup_arch_hook - hook called prior to any setup_arch() execution
- *
- * Description:
- *	generally used to activate any machine specific identification
- *	routines that may be needed before setup_arch() runs.  On Voyager
- *	this is used to get the board revision and type.
- **/
-void __init pre_setup_arch_hook(void)
-{
-}
-
 /**
  * trap_init_hook - initialise system specific traps
  *
@@ -1088,25 +1075,4 @@ void __init time_init_hook(void)
 	irq0.mask = cpumask_of_cpu(0);
 	setup_irq(0, &irq0);
 }
-
-#ifdef CONFIG_MCA
-/**
- * mca_nmi_hook - hook into MCA specific NMI chain
- *
- * Description:
- *	The MCA (Microchannel Architecture) has an NMI chain for NMI sources
- *	along the MCA bus.  Use this to hook into that chain if you will need
- *	it.
- **/
-void mca_nmi_hook(void)
-{
-	/*
-	 * If I recall correctly, there's a whole bunch of other things that
-	 * we can do to check for NMI problems, but that's all I know about
-	 * at the moment.
-	 */
-	pr_warning("NMI generated from unknown source!\n");
-}
-#endif /* CONFIG_MCA */
-
 #endif /* CONFIG_X86_32 */

commit fc6fc7f1b1095b92d4834e69b385b91e412a7ce5
Merge: ef1f87aa7ba6 770824bdc421
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Feb 22 20:05:19 2009 +0100

    Merge branch 'linus' into x86/apic
    
    Conflicts:
            arch/x86/mach-default/setup.c
    
    Semantic conflict resolution:
            arch/x86/kernel/setup.c
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9be1b56a3e718aa998772019c57c398dbb19e258
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 23:12:48 2009 +0100

    x86, apic: separate 32-bit setup functionality out of apic_32.c
    
    Impact: build fix, cleanup
    
    A couple of arch setup callbacks were mistakenly in apic_32.c, breaking
    the build.
    
    Also simplify the code a bit.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6b588d6b3889..ebef80055795 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -985,4 +985,128 @@ void __init setup_arch(char **cmdline_p)
 #endif
 }
 
+#ifdef CONFIG_X86_32
+
+/**
+ * pre_intr_init_hook - initialisation prior to setting up interrupt vectors
+ *
+ * Description:
+ *	Perform any necessary interrupt initialisation prior to setting up
+ *	the "ordinary" interrupt call gates.  For legacy reasons, the ISA
+ *	interrupts should be initialised here if the machine emulates a PC
+ *	in any way.
+ **/
+void __init pre_intr_init_hook(void)
+{
+	if (x86_quirks->arch_pre_intr_init) {
+		if (x86_quirks->arch_pre_intr_init())
+			return;
+	}
+	init_ISA_irqs();
+}
+
+/**
+ * intr_init_hook - post gate setup interrupt initialisation
+ *
+ * Description:
+ *	Fill in any interrupts that may have been left out by the general
+ *	init_IRQ() routine.  interrupts having to do with the machine rather
+ *	than the devices on the I/O bus (like APIC interrupts in intel MP
+ *	systems) are started here.
+ **/
+void __init intr_init_hook(void)
+{
+	if (x86_quirks->arch_intr_init) {
+		if (x86_quirks->arch_intr_init())
+			return;
+	}
+}
+
+/**
+ * pre_setup_arch_hook - hook called prior to any setup_arch() execution
+ *
+ * Description:
+ *	generally used to activate any machine specific identification
+ *	routines that may be needed before setup_arch() runs.  On Voyager
+ *	this is used to get the board revision and type.
+ **/
+void __init pre_setup_arch_hook(void)
+{
+}
+
+/**
+ * trap_init_hook - initialise system specific traps
+ *
+ * Description:
+ *	Called as the final act of trap_init().  Used in VISWS to initialise
+ *	the various board specific APIC traps.
+ **/
+void __init trap_init_hook(void)
+{
+	if (x86_quirks->arch_trap_init) {
+		if (x86_quirks->arch_trap_init())
+			return;
+	}
+}
+
+static struct irqaction irq0  = {
+	.handler = timer_interrupt,
+	.flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL,
+	.mask = CPU_MASK_NONE,
+	.name = "timer"
+};
+
+/**
+ * pre_time_init_hook - do any specific initialisations before.
+ *
+ **/
+void __init pre_time_init_hook(void)
+{
+	if (x86_quirks->arch_pre_time_init)
+		x86_quirks->arch_pre_time_init();
+}
+
+/**
+ * time_init_hook - do any specific initialisations for the system timer.
+ *
+ * Description:
+ *	Must plug the system timer interrupt source at HZ into the IRQ listed
+ *	in irq_vectors.h:TIMER_IRQ
+ **/
+void __init time_init_hook(void)
+{
+	if (x86_quirks->arch_time_init) {
+		/*
+		 * A nonzero return code does not mean failure, it means
+		 * that the architecture quirk does not want any
+		 * generic (timer) setup to be performed after this:
+		 */
+		if (x86_quirks->arch_time_init())
+			return;
+	}
+
+	irq0.mask = cpumask_of_cpu(0);
+	setup_irq(0, &irq0);
+}
+
+#ifdef CONFIG_MCA
+/**
+ * mca_nmi_hook - hook into MCA specific NMI chain
+ *
+ * Description:
+ *	The MCA (Microchannel Architecture) has an NMI chain for NMI sources
+ *	along the MCA bus.  Use this to hook into that chain if you will need
+ *	it.
+ **/
+void mca_nmi_hook(void)
+{
+	/*
+	 * If I recall correctly, there's a whole bunch of other things that
+	 * we can do to check for NMI problems, but that's all I know about
+	 * at the moment.
+	 */
+	pr_warning("NMI generated from unknown source!\n");
+}
+#endif /* CONFIG_MCA */
 
+#endif /* CONFIG_X86_32 */

commit be163a159b223e94b3180afdd47a8d468eb9a492
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 16:28:46 2009 +0100

    x86, apic: rename 'genapic' to 'apic'
    
    Impact: cleanup
    
    Now that all APIC code is consolidated there's nothing 'gen' about
    apics anymore - so rename 'struct genapic' to 'struct apic'.
    
    This shortens the code and is nicer to read as well.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b2da0b1d15e7..6b588d6b3889 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -599,7 +599,7 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
-static int __init default_update_genapic(void)
+static int __init default_update_apic(void)
 {
 #ifdef CONFIG_SMP
 	if (!apic->wakeup_cpu)
@@ -610,7 +610,7 @@ static int __init default_update_genapic(void)
 }
 
 static struct x86_quirks default_x86_quirks __initdata = {
-	.update_genapic         = default_update_genapic,
+	.update_apic         = default_update_apic,
 };
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;

commit e641f5f525acb163ba71d92de79c9c7366deae03
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 14:02:01 2009 +0100

    x86, apic: remove duplicate asm/apic.h inclusions
    
    Impact: cleanup
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index deaafd2693ee..b2da0b1d15e7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -97,7 +97,6 @@
 #include <asm/mmu_context.h>
 #include <asm/proto.h>
 
-#include <asm/apic.h>
 #include <asm/paravirt.h>
 #include <asm/hypervisor.h>
 

commit 7b6aa335ca1a845c2262ec7a595b4521bca0f79d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 13:58:15 2009 +0100

    x86, apic: remove genapic.h
    
    Impact: cleanup
    
    Remove genapic.h and remove all references to it.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 43d964411c0d..deaafd2693ee 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -97,7 +97,7 @@
 #include <asm/mmu_context.h>
 #include <asm/proto.h>
 
-#include <asm/genapic.h>
+#include <asm/apic.h>
 #include <asm/paravirt.h>
 #include <asm/hypervisor.h>
 

commit 06cd9a7dc8a58186060a91b6ddc031057435fd34
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Feb 16 17:29:58 2009 -0800

    x86: add x2apic config
    
    Impact: cleanup
    
    so could deselect x2apic
    and INTR_REMAP will select x2apic
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8fce6c714514..43d964411c0d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -836,8 +836,7 @@ void __init setup_arch(char **cmdline_p)
 #else
 	num_physpages = max_pfn;
 
- 	if (cpu_has_x2apic)
- 		check_x2apic();
+	check_x2apic();
 
 	/* How many end-of-memory variables you have, grandma! */
 	/* need this before calling reserve_initrd */

commit 160d8dac12932ad6eb4a359b66521e2e3282ea7d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Feb 11 11:27:39 2009 +0100

    x86, apic: make generic_apic_probe() generally available
    
    Impact: build fix
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 150e6d0a3b47..8fce6c714514 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -936,9 +936,7 @@ void __init setup_arch(char **cmdline_p)
 	map_vsyscall();
 #endif
 
-#ifdef CONFIG_X86_32
 	generic_apic_probe();
-#endif
 
 	early_quirks();
 

commit 0e81cb59c7120191c0243c686b591797bc79e5c6
Author: Alok Kataria <akataria@vmware.com>
Date:   Tue Feb 10 16:45:37 2009 -0800

    x86, apic: fix initialization of wakeup_cpu
    
    With refactoring of wake_cpu macros the 32bit code in tip doesn't
    execute generic_apic_probe if CONFIG_X86_32_NON_STANDARD is not set.
    
    Even on a x86 STANDARD cpu we need to execute the generic_apic_probe
    function, as we rely on this function to execute the update_genapic
    quirk which initilizes apic->wakeup_cpu.
    
    Failing to do so results in we making a call to a null function in do_boot_cpu.
    
    The stack trace without the patch goes like this.
    
    Booting processor 1 APIC 0x1 ip 0x6000
    BUG: unable to handle kernel NULL pointer dereference at (null)
    IP: [<(null)>] (null)
    *pdpt = 0000000000839001 *pde = 0000000000c97067 *pte = 0000000000000163
    Oops: 0000 [#1] SMP
    last sysfs file:
    Modules linked in:
    
    Pid: 1, comm: swapper Not tainted (2.6.29-rc4-tip #18) VMware Virtual Platform
    EIP: 0062:[<00000000>] EFLAGS: 00010293 CPU: 0
    EIP is at 0x0
    EAX: 00000001 EBX: 00006000 ECX: c077ed00 EDX: 00006000
    ESI: 00000001 EDI: 00000001 EBP: ef04cf40 ESP: ef04cf1c
     DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: 006a
    Process swapper (pid: 1, ti=ef04c000 task=ef050000 task.ti=ef04c000)
    Stack:
     c0644e52 00000000 ef04cf24 ef04cf24 c064468d c0886dc0 00000000 c0702aea
     ef055480 00000001 00000101 dead4ead ffffffff ffffffff c08af530 00000000
     c0709715 ef04cf60 ef04cf60 00000001 00000000 00000000 dead4ead ffffffff
    Call Trace:
     [<c0644e52>] ? native_cpu_up+0x2de/0x45b
     [<c064468d>] ? do_fork_idle+0x0/0x19
     [<c0645c5e>] ? _cpu_up+0x88/0xe8
     [<c0645d20>] ? cpu_up+0x42/0x4e
     [<c07e7462>] ? kernel_init+0x99/0x14b
     [<c07e73c9>] ? kernel_init+0x0/0x14b
     [<c040375f>] ? kernel_thread_helper+0x7/0x10
    Code:  Bad EIP value.
    EIP: [<00000000>] 0x0 SS:ESP 006a:ef04cf1c
    
    I think we should call generic_apic_probe unconditionally for 32 bit now.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8d8fa992c9a0..150e6d0a3b47 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -936,7 +936,7 @@ void __init setup_arch(char **cmdline_p)
 	map_vsyscall();
 #endif
 
-#if defined(CONFIG_X86_32_NON_STANDARD) || defined(CONFIG_X86_BIGSMP)
+#ifdef CONFIG_X86_32
 	generic_apic_probe();
 #endif
 

commit 9d45cf9e36bf9bcf16df6e1cbf049807c8402823
Merge: a146649bc19d 0cd5c3c80a0e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Jan 31 17:32:31 2009 +0100

    Merge branch 'x86/urgent' into x86/apic
    
    Conflicts:
            arch/x86/mach-default/setup.c
    
    Semantic merge:
            arch/x86/kernel/irqinit_32.c
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 4560839939f4b4a96e21e80584f87308ac93c1da
Author: Alex Chiang <achiang@hp.com>
Date:   Wed Feb 4 16:44:01 2009 -0700

    x86: fix grammar in user-visible BIOS warning
    
    Fix user-visible grammo.
    
    Signed-off-by: Alex Chiang <achiang@hp.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ae0d8042cf69..c461f6d69074 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -607,7 +607,7 @@ struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
 	printk(KERN_NOTICE
-		"%s detected: BIOS may corrupt low RAM, working it around.\n",
+		"%s detected: BIOS may corrupt low RAM, working around it.\n",
 		d->ident);
 
 	e820_update_range(0, 0x10000, E820_RAM, E820_RESERVED);

commit 26f7ef14a76b0e590a3797fd7b2f3cee868d9664
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Jan 29 14:19:22 2009 -0800

    x86: don't treat bigsmp as non-standard
    
    just like 64 bit switch from flat logical APIC messages to
    flat physical mode automatically.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f64e1a487c9e..df64afff5806 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -936,7 +936,7 @@ void __init setup_arch(char **cmdline_p)
 	map_vsyscall();
 #endif
 
-#ifdef CONFIG_X86_32_NON_STANDARD
+#if defined(CONFIG_X86_32_NON_STANDARD) || defined(CONFIG_X86_BIGSMP)
 	generic_apic_probe();
 #endif
 

commit e0c7ae376a13fd79a4dad8becab51040d13dfa90
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 27 18:43:09 2009 +0100

    x86: rename X86_GENERICARCH to X86_32_NON_STANDARD
    
    X86_GENERICARCH is a misnomer - it contains non-PC 32-bit architectures
    that are not included in the default build.
    
    Rename it to X86_32_NON_STANDARD.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6abce6703c53..f64e1a487c9e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -936,7 +936,7 @@ void __init setup_arch(char **cmdline_p)
 	map_vsyscall();
 #endif
 
-#ifdef CONFIG_X86_GENERICARCH
+#ifdef CONFIG_X86_32_NON_STANDARD
 	generic_apic_probe();
 #endif
 

commit 550fe4f198558c147c6b8273a709568222a1668a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 27 17:28:08 2009 +0100

    x86/Voyager: remove X86_FIND_SMP_CONFIG Kconfig quirk
    
    x86/Voyager had this Kconfig quirk:
    
     config X86_FIND_SMP_CONFIG
            def_bool y
            depends on X86_MPPARSE || X86_VOYAGER
    
    Which splits off the find_smp_config() callback into a build-time quirk.
    
    Voyager should use the existing x86_quirks.mach_find_smp_config() callback
    to introduce SMP-config quirks. NUMAQ-32 and VISWS already use this.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 609e5af60282..6abce6703c53 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -905,12 +905,11 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_reserve_bootmem();
 #endif
-#ifdef CONFIG_X86_FIND_SMP_CONFIG
 	/*
 	 * Find and reserve possible boot-time SMP configuration:
 	 */
 	find_smp_config();
-#endif
+
 	reserve_crashkernel();
 
 #ifdef CONFIG_X86_64

commit c0b5842a457d44c8788b3fd0c64969be7ef673cd
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 27 17:13:05 2009 +0100

    x86: generalize boot_cpu_id
    
    x86/Voyager can boot on non-zero processors. While that can probably
    be fixed by properly remapping the physical CPU IDs, keep boot_cpu_id
    for now for easier transition - and expand it to all of x86.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index eeb180b1d7aa..609e5af60282 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -112,6 +112,20 @@
 #define ARCH_SETUP
 #endif
 
+unsigned int boot_cpu_id __read_mostly;
+
+#ifdef CONFIG_X86_64
+int default_cpu_present_to_apicid(int mps_cpu)
+{
+	return __default_cpu_present_to_apicid(mps_cpu);
+}
+
+int default_check_phys_apicid_present(int boot_cpu_physical_apicid)
+{
+	return __default_check_phys_apicid_present(boot_cpu_physical_apicid);
+}
+#endif
+
 #ifndef CONFIG_DEBUG_BOOT_PARAMS
 struct boot_params __initdata boot_params;
 #else

commit 3e5095d15276efd14a45393666b1bb7536bf179f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 27 17:07:08 2009 +0100

    x86: replace CONFIG_X86_SMP with CONFIG_SMP
    
    The x86/Voyager subarch used to have this distinction between
     'x86 SMP support' and 'Voyager SMP support':
    
     config X86_SMP
            bool
            depends on SMP && ((X86_32 && !X86_VOYAGER) || X86_64)
    
    This is a pointless distinction - Voyager can (and already does) use
    smp_ops to implement various SMP quirks it has - and it can be extended
    more to cover all the specialities of Voyager.
    
    So remove this complication in the Kconfig space.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e645d4793e4d..eeb180b1d7aa 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -588,7 +588,7 @@ early_param("elfcorehdr", setup_elfcorehdr);
 
 static int __init default_update_genapic(void)
 {
-#ifdef CONFIG_X86_SMP
+#ifdef CONFIG_SMP
 	if (!apic->wakeup_cpu)
 		apic->wakeup_cpu = wakeup_secondary_cpu_via_init;
 #endif

commit 1164dd0099c0d79146a55319670f57ab7ad1d352
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 19:34:09 2009 +0100

    x86: move mach-default/*.h files to asm/
    
    We are getting rid of subarchitecture support - move the hook files
    to asm/. (These are now stale and should be replaced with more explicit
    runtime mechanisms - but the transition is simpler this way.)
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 92e42939fb08..e645d4793e4d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -81,7 +81,7 @@
 #include <asm/io_apic.h>
 #include <asm/ist.h>
 #include <asm/vmi.h>
-#include <setup_arch.h>
+#include <asm/setup_arch.h>
 #include <asm/bios_ebda.h>
 #include <asm/cacheflush.h>
 #include <asm/processor.h>

commit 1dcdd3d15ecea0c22a09d4d001a39d425fceff2c
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 17:55:37 2009 +0100

    x86: remove mach_apic.h
    
    Spread mach_apic.h definitions into genapic.h. (with some knock-on effects
    on smp.h and apic.h.)
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6b27f6dc7bf7..92e42939fb08 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -97,7 +97,7 @@
 #include <asm/mmu_context.h>
 #include <asm/proto.h>
 
-#include <mach_apic.h>
+#include <asm/genapic.h>
 #include <asm/paravirt.h>
 #include <asm/hypervisor.h>
 

commit 328386d7ab600aa0993a1226f5817ac30a735724
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 17:50:18 2009 +0100

    x86, smp: refactor ->wake_cpu
    
    - remove macro wrappers
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a58e9f5e6030..6b27f6dc7bf7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -589,9 +589,8 @@ early_param("elfcorehdr", setup_elfcorehdr);
 static int __init default_update_genapic(void)
 {
 #ifdef CONFIG_X86_SMP
-# if defined(CONFIG_X86_GENERICARCH) || defined(CONFIG_X86_64)
-	apic->wakeup_cpu = wakeup_secondary_cpu_via_init;
-# endif
+	if (!apic->wakeup_cpu)
+		apic->wakeup_cpu = wakeup_secondary_cpu_via_init;
 #endif
 
 	return 0;

commit c8d46cf06dc2e3a8f57a350eb9f9b19fd7f2ffe5
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 00:14:11 2009 +0100

    x86: rename 'genapic' to 'apic'
    
    Rename genapic-> to apic-> references because in a future chagne we'll
    open-code all the indirect calls (instead of obscuring them via macros),
    so we want this reference to be as short as possible.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f41c4486c270..a58e9f5e6030 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -590,7 +590,7 @@ static int __init default_update_genapic(void)
 {
 #ifdef CONFIG_X86_SMP
 # if defined(CONFIG_X86_GENERICARCH) || defined(CONFIG_X86_64)
-	genapic->wakeup_cpu = wakeup_secondary_cpu_via_init;
+	apic->wakeup_cpu = wakeup_secondary_cpu_via_init;
 # endif
 #endif
 

commit 6e5385d44b2df05e50a8d07ba0e14d3e32685237
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 18:11:35 2009 +0530

    x86: smp.h move prefill_possible_map declartion to cpu.h
    
    Impact: cleanup, moving NON-SMP stuff from smp.h
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ae0d8042cf69..f41c4486c270 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -89,7 +89,7 @@
 
 #include <asm/system.h>
 #include <asm/vsyscall.h>
-#include <asm/smp.h>
+#include <asm/cpu.h>
 #include <asm/desc.h>
 #include <asm/dma.h>
 #include <asm/iommu.h>

commit 179475a3b46f86e2d06f83e2312218ac3f0cf3a7
Merge: bb758e9637e5 860cf8894b32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 16:20:19 2008 -0800

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, sparseirq: clean up Kconfig entry
      x86: turn CONFIG_SPARSE_IRQ off by default
      sparseirq: fix numa_migrate_irq_desc dependency and comments
      sparseirq: add kernel-doc notation for new member in irq_desc, -v2
      locking, irq: enclose irq_desc_lock_class in CONFIG_LOCKDEP
      sparseirq, xen: make sure irq_desc is allocated for interrupts
      sparseirq: fix !SMP building, #2
      x86, sparseirq: move irq_desc according to smp_affinity, v7
      proc: enclose desc variable of show_stat() in CONFIG_SPARSE_IRQ
      sparse irqs: add irqnr.h to the user headers list
      sparse irqs: handle !GENIRQ platforms
      sparseirq: fix !SMP && !PCI_MSI && !HT_IRQ build
      sparseirq: fix Alpha build failure
      sparseirq: fix typo in !CONFIG_IO_APIC case
      x86, MSI: pass irq_cfg and irq_desc
      x86: MSI start irq numbering from nr_irqs_gsi
      x86: use NR_IRQS_LEGACY
      sparse irq_desc[] array: core kernel and x86 changes
      genirq: record IRQ_LEVEL in irq_desc[]
      irq.h: remove padding from irq_desc on 64bits

commit 860cf8894b326e4b89720f520540604834337b72
Merge: e262a7ba31f0 973656fe1afb f2b662da8d6b 4a6908a3a050
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Dec 25 16:27:54 2008 +0100

    Merge branches 'irq/sparseirq', 'irq/genirq' and 'irq/urgent'; commit 'v2.6.28' into irq/core

commit 3e5621edb3392b28efb260ac99b2d26fb8b44e73
Merge: be9a1d3c2e55 181de82ee3ff
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Dec 23 16:30:27 2008 +0100

    Merge branch 'x86/iommu' into x86/core

commit fa623d1b0222adbe8f822e53c08003b9679a410c
Merge: 3d44cc3e01ee 1ccedb7cdba6 34945ede3107 d43779740621 c415b3dce30d beeb4195cbc8 f269b07e862c 4e42ebd57b2e e1286f2c686f 878719e831d9 fd28a5b58ddd adf77bac052b 8f2466f45f75 93093d099e5d bb5574608a83 f34a10bd9f8c b6fd6f26733e 30604bb410b5 5b9a0e14eb4b 67bac792cd0c 7a9787e1eba9 f4166c54bfe0 69b88afa8d11 8daa19051e1c 3e1e9002aa8b 8403295e0fa4 4db646b1af8f 205516c12dbb c8182f0016fb ecbf29cdb399
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Dec 23 16:27:23 2008 +0100

    Merge branches 'x86/apic', 'x86/cleanups', 'x86/cpufeature', 'x86/crashdump', 'x86/debug', 'x86/defconfig', 'x86/detect-hyper', 'x86/doc', 'x86/dumpstack', 'x86/early-printk', 'x86/fpu', 'x86/idle', 'x86/io', 'x86/memory-corruption-check', 'x86/microcode', 'x86/mm', 'x86/mtrr', 'x86/nmi-watchdog', 'x86/pat2', 'x86/pci-ioapic-boot-irq-quirks', 'x86/ptrace', 'x86/quirks', 'x86/reboot', 'x86/setup-memory', 'x86/signal', 'x86/sparse-fixes', 'x86/time', 'x86/uv' and 'x86/xen' into x86/core

commit a9b43c7d9890066709609df849959009645c1a19
Author: Jaswinder Singh <jaswinder@infradead.org>
Date:   Mon Dec 15 23:11:10 2008 +0530

    x86: setup.c find_and_reserve_crashkernel should be static
    
    Impact: cleanup, reduce kernel size a bit
    
    Signed-off-by: Jaswinder Singh <jaswinder@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9d5674f7b6cc..81f5d22747ae 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -448,6 +448,7 @@ static void __init reserve_early_setup_data(void)
  * @size: Size of the crashkernel memory to reserve.
  * Returns the base address on success, and -1ULL on failure.
  */
+static
 unsigned long long __init find_and_reserve_crashkernel(unsigned long long size)
 {
 	const unsigned long long alignment = 16<<20; 	/* 16M */

commit ae8d04e2ecbb233926860e9ce145eac19c7835dc
Author: Zachary Amsden <zach@vmware.com>
Date:   Sat Dec 13 12:36:58 2008 -0800

    x86 Fix VMI crash on boot in 2.6.28-rc8
    
    VMI initialiation can relocate the fixmap, causing early_ioremap to
    malfunction if it is initialized before the relocation.  To fix this,
    VMI activation is split into two phases; the detection, which must
    happen before setting up ioremap, and the activation, which must happen
    after parsing early boot parameters.
    
    This fixes a crash on boot when VMI is enabled under VMware.
    
    Signed-off-by: Zachary Amsden <zach@vmware.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9d5674f7b6cc..bdec76e55594 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -794,6 +794,9 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
+	/* VMI may relocate the fixmap; do this before touching ioremap area */
+	vmi_init();
+
 	early_cpu_init();
 	early_ioremap_init();
 
@@ -880,13 +883,8 @@ void __init setup_arch(char **cmdline_p)
 	check_efer();
 #endif
 
-#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
-	/*
-	 * Must be before kernel pagetables are setup
-	 * or fixmap area is touched.
-	 */
-	vmi_init();
-#endif
+	/* Must be before kernel pagetables are setup */
+	vmi_activate();
 
 	/* after early param, so could get panic from serial */
 	reserve_early_setup_data();

commit aa9c9b8c584a42a094202b7e0f63497e888f86a7
Merge: 87f7606591ae 218d11a8b071
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Dec 8 15:07:49 2008 +0100

    Merge branch 'linus' into x86/quirks

commit be5d5350a937cd8513b258739f1099420129e96f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Dec 5 18:58:33 2008 -0800

    x86: MSI start irq numbering from nr_irqs_gsi
    
    Impact: sanitize MSI irq number ordering from top-down to bottom-up
    
    Increase new MSI IRQs starting from nr_irqs_gsi (which is somewhere below
    256), instead of decreasing from NR_IRQS. (The latter method can result
    in confusingly high IRQ numbers - if NR_CPUS is set to a high value and
    NR_IRQS scales up to a high value.)
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 9d5674f7b6cc..a3834f123206 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1082,7 +1082,7 @@ void __init setup_arch(char **cmdline_p)
 	ioapic_init_mappings();
 
 	/* need to wait for io_apic is mapped */
-	nr_irqs = probe_nr_irqs();
+	probe_nr_irqs_gsi();
 
 	kvm_guest_init();
 

commit f6d2e6f57bba66272b28dd20c949b14ce39cb804
Merge: 8caac56305ce 7b1dedca42ac
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Dec 1 20:36:13 2008 +0100

    Merge branch 'x86/urgent' into x86/iommu

commit 1d9b16d1690fe5edb1c907fe4746681cf026cdf3
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Nov 27 18:39:15 2008 +0100

    x86: move GART specific stuff from iommu.h to gart.h
    
    Impact: cleanup
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa6790c1dd3..67d5979e654e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -93,6 +93,7 @@
 #include <asm/desc.h>
 #include <asm/dma.h>
 #include <asm/iommu.h>
+#include <asm/gart.h>
 #include <asm/mmu_context.h>
 #include <asm/proto.h>
 

commit bb5574608a8375026510b4f983ffbb06ece33fe2
Author: Richard A. Holden III <aciddeath@gmail.com>
Date:   Wed Nov 19 16:05:15 2008 -0700

    x86: fix arch/x86/kernel/setup.c build warning when !CONFIG_X86_RESERVE_LOW_64K
    
    Impact: cleanup
    
    Fix:
    
      arch/x86/kernel/setup.c:592: warning: 'dmi_low_memory_corruption' defined but not used
    
    this is only used if CONFIG_X86_RESERVE_LOW_64K is defined.
    
    Signed-off-by: Richard A. Holden III <aciddeath@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index e6c51433247d..13a5f592ac28 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -587,6 +587,7 @@ static struct x86_quirks default_x86_quirks __initdata;
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 
+#ifdef CONFIG_X86_RESERVE_LOW_64K
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
 	printk(KERN_NOTICE
@@ -598,6 +599,7 @@ static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 
 	return 0;
 }
+#endif
 
 /* List of systems that have known low memory corruption BIOS problems */
 static struct dmi_system_id __initdata bad_bios_dmi_table[] = {

commit 90accd6fabf9b2fa2705945a4c601877a75d43bf
Merge: b43d196c4d3f ee2f6cc7f9ea
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Nov 20 09:03:38 2008 +0100

    Merge branch 'linus' into x86/memory-corruption-check

commit f632ddcc0786149c0e4bef9b6b44c96a75c0d074
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Nov 18 17:32:26 2008 +0100

    x86: fix wakeup_cpu with numaq/es7000, v2, fix #2
    
    Impact: fix boot crash
    
    fix default_update_genapic().
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c366e891e10b..31328909456e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -585,8 +585,10 @@ early_param("elfcorehdr", setup_elfcorehdr);
 
 static int __init default_update_genapic(void)
 {
-#if defined(CONFIG_X86_GENERICARCH) || defined(CONFIG_X86_64)
-	genapic->wakeup_cpu = wakeup_secondary_cpu_via_nmi;
+#ifdef CONFIG_X86_SMP
+# if defined(CONFIG_X86_GENERICARCH) || defined(CONFIG_X86_64)
+	genapic->wakeup_cpu = wakeup_secondary_cpu_via_init;
+# endif
 #endif
 
 	return 0;

commit 0af40a4b1050c050e62eb1dc30b82d5ab22bf221
Author: Philipp Kohlbecher <xt28@gmx.de>
Date:   Sun Nov 16 12:11:01 2008 +0100

    x86: more general identifier for Phoenix BIOS
    
    Impact: widen the reach of the low-memory-protect DMI quirk
    
    Phoenix BIOSes variously identify their vendor as "Phoenix Technologies,
    LTD" or "Phoenix Technologies LTD" (without the comma.)
    
    This patch makes the identification string in the bad_bios_dmi_table
    more general (following a suggestion by Ingo Molnar), so that both
    versions are handled.
    
    Again, the patched file compiles cleanly and the patch has been tested
    successfully on my machine.
    
    Signed-off-by: Philipp Kohlbecher <xt28@gmx.de>
    Cc: <stable@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa6790c1dd3..9d5674f7b6cc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -764,7 +764,7 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 		.callback = dmi_low_memory_corruption,
 		.ident = "Phoenix BIOS",
 		.matches = {
-			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies, LTD"),
+			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies"),
 		},
 	},
 #endif

commit 54ac14a8e982ae6c7ac71ee2b0d0173b974509e2
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Nov 17 15:19:53 2008 -0800

    x86: fix wakeup_cpu with numaq/es7000, v2, fix
    
    Impact: fix wakeup_secondary_cpu with hotplug
    
    We can not put that into x86_quirks, because that is __initdata.
    So try to move that to genapic, and add update_genapic in x86_quirks.
    
    later we even could use that stub to:
    
     1. autodetect CONFIG_ES7000_CLUSTERED_APIC
     2. more correct inquire_remote_apic with apic_verbosity setting.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa6790c1dd3..c366e891e10b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -583,7 +583,18 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
-static struct x86_quirks default_x86_quirks __initdata;
+static int __init default_update_genapic(void)
+{
+#if defined(CONFIG_X86_GENERICARCH) || defined(CONFIG_X86_64)
+	genapic->wakeup_cpu = wakeup_secondary_cpu_via_nmi;
+#endif
+
+	return 0;
+}
+
+static struct x86_quirks default_x86_quirks __initdata = {
+	.update_genapic         = default_update_genapic,
+};
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 

commit 88b094fb8d4fe43b7025ea8d487059e8813e02cd
Author: Alok Kataria <akataria@vmware.com>
Date:   Mon Oct 27 10:41:46 2008 -0700

    x86: Hypervisor detection and get tsc_freq from hypervisor
    
    Impact: Changes timebase calibration on Vmware.
    
    v3->v2 : Abstract the hypervisor detection and feature (tsc_freq) request
             behind a hypervisor.c file
    v2->v1 : Add a x86_hyper_vendor field to the cpuinfo_x86 structure.
             This avoids multiple calls to the hypervisor detection function.
    
    This patch adds function to detect if we are running under VMware.
    The current way to check if we are on VMware is following,
    #  check if "hypervisor present bit" is set, if so read the 0x40000000
       cpuid leaf and check for "VMwareVMware" signature.
    #  if the above fails, check the DMI vendors name for "VMware" string
       if we find one we query the VMware hypervisor port to check if we are
       under VMware.
    
    The DMI + "VMware hypervisor port check" is needed for older VMware products,
    which don't implement the hypervisor signature cpuid leaf.
    Also note that since we are checking for the DMI signature the hypervisor
    port should never be accessed on native hardware.
    
    This patch also adds a hypervisor_get_tsc_freq function, instead of
    calibrating the frequency which can be error prone in virtualized
    environment, we ask the hypervisor for it. We get the frequency from
    the hypervisor by accessing the hypervisor port if we are running on VMware.
    Other hypervisors too can add code to the generic routine to get frequency on
    their platform.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    Signed-off-by: Dan Hecht <dhecht@vmware.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa6790c1dd3..f44dadfb32cf 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -98,6 +98,7 @@
 
 #include <mach_apic.h>
 #include <asm/paravirt.h>
+#include <asm/hypervisor.h>
 
 #include <asm/percpu.h>
 #include <asm/topology.h>
@@ -909,6 +910,12 @@ void __init setup_arch(char **cmdline_p)
 
 	dmi_check_system(bad_bios_dmi_table);
 
+	/*
+	 * VMware detection requires dmi to be available, so this
+	 * needs to be done after dmi_scan_machine, for the BP.
+	 */
+	init_hypervisor(&boot_cpu_data);
+
 #ifdef CONFIG_X86_32
 	probe_roms();
 #endif

commit 6784f7d0a5016a397d38be1134e63fc784c1ca8e
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Sun Oct 5 11:33:42 2008 -0700

    x86: corruption check: move the corruption checks into their own file
    
    Impact: cleanup
    
    The corruption check code is rather sizable and it's likely to grow over
    time when we add checks for more types of corruptions (there's a few
    candidates in kerneloops.org that I want to add checks for)... so lets move
    it to its own file
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4f38e0305b07..af690aa593a9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -587,158 +587,6 @@ static struct x86_quirks default_x86_quirks __initdata;
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 
-/*
- * Some BIOSes seem to corrupt the low 64k of memory during events
- * like suspend/resume and unplugging an HDMI cable.  Reserve all
- * remaining free memory in that area and fill it with a distinct
- * pattern.
- */
-#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
-#define MAX_SCAN_AREAS	8
-
-static int __read_mostly memory_corruption_check = -1;
-
-static unsigned __read_mostly corruption_check_size = 64*1024;
-static unsigned __read_mostly corruption_check_period = 60; /* seconds */
-
-static struct e820entry scan_areas[MAX_SCAN_AREAS];
-static int num_scan_areas;
-
-
-static int set_corruption_check(char *arg)
-{
-	char *end;
-
-	memory_corruption_check = simple_strtol(arg, &end, 10);
-
-	return (*end == 0) ? 0 : -EINVAL;
-}
-early_param("memory_corruption_check", set_corruption_check);
-
-static int set_corruption_check_period(char *arg)
-{
-	char *end;
-
-	corruption_check_period = simple_strtoul(arg, &end, 10);
-
-	return (*end == 0) ? 0 : -EINVAL;
-}
-early_param("memory_corruption_check_period", set_corruption_check_period);
-
-static int set_corruption_check_size(char *arg)
-{
-	char *end;
-	unsigned size;
-
-	size = memparse(arg, &end);
-
-	if (*end == '\0')
-		corruption_check_size = size;
-
-	return (size == corruption_check_size) ? 0 : -EINVAL;
-}
-early_param("memory_corruption_check_size", set_corruption_check_size);
-
-
-static void __init setup_bios_corruption_check(void)
-{
-	u64 addr = PAGE_SIZE;	/* assume first page is reserved anyway */
-
-	if (memory_corruption_check == -1) {
-		memory_corruption_check =
-#ifdef CONFIG_X86_BOOTPARAM_MEMORY_CORRUPTION_CHECK
-			1
-#else
-			0
-#endif
-			;
-	}
-
-	if (corruption_check_size == 0)
-		memory_corruption_check = 0;
-
-	if (!memory_corruption_check)
-		return;
-
-	corruption_check_size = round_up(corruption_check_size, PAGE_SIZE);
-
-	while (addr < corruption_check_size && num_scan_areas < MAX_SCAN_AREAS) {
-		u64 size;
-		addr = find_e820_area_size(addr, &size, PAGE_SIZE);
-
-		if (addr == 0)
-			break;
-
-		if ((addr + size) > corruption_check_size)
-			size = corruption_check_size - addr;
-
-		if (size == 0)
-			break;
-
-		e820_update_range(addr, size, E820_RAM, E820_RESERVED);
-		scan_areas[num_scan_areas].addr = addr;
-		scan_areas[num_scan_areas].size = size;
-		num_scan_areas++;
-
-		/* Assume we've already mapped this early memory */
-		memset(__va(addr), 0, size);
-
-		addr += size;
-	}
-
-	printk(KERN_INFO "Scanning %d areas for low memory corruption\n",
-	       num_scan_areas);
-	update_e820();
-}
-
-static struct timer_list periodic_check_timer;
-
-void check_for_bios_corruption(void)
-{
-	int i;
-	int corruption = 0;
-
-	if (!memory_corruption_check)
-		return;
-
-	for (i = 0; i < num_scan_areas; i++) {
-		unsigned long *addr = __va(scan_areas[i].addr);
-		unsigned long size = scan_areas[i].size;
-
-		for (; size; addr++, size -= sizeof(unsigned long)) {
-			if (!*addr)
-				continue;
-			printk(KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n",
-			       addr, __pa(addr), *addr);
-			corruption = 1;
-			*addr = 0;
-		}
-	}
-
-	WARN(corruption, KERN_ERR "Memory corruption detected in low memory\n");
-}
-
-static void periodic_check_for_corruption(unsigned long data)
-{
-	check_for_bios_corruption();
-	mod_timer(&periodic_check_timer,
-		round_jiffies(jiffies + corruption_check_period*HZ));
-}
-
-void start_periodic_check_for_corruption(void)
-{
-	if (!memory_corruption_check || corruption_check_period == 0)
-		return;
-
-	printk(KERN_INFO "Scanning for low memory corruption every %d seconds\n",
-	       corruption_check_period);
-
-	init_timer(&periodic_check_timer);
-	periodic_check_timer.function = &periodic_check_for_corruption;
-	periodic_check_for_corruption(0);
-}
-#endif
-
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
 	printk(KERN_NOTICE

commit 04d2aac33eb54fd3084140f2db130530d71e97c6
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Sun Oct 5 11:08:10 2008 -0700

    x86: corruption-check: fix some style issues
    
    Impact: cleanup
    
    Before moving the code to it's own file, fix some style issues
    in the corruption check code.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0fa6790c1dd3..4f38e0305b07 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -662,7 +662,7 @@ static void __init setup_bios_corruption_check(void)
 
 	corruption_check_size = round_up(corruption_check_size, PAGE_SIZE);
 
-	while(addr < corruption_check_size && num_scan_areas < MAX_SCAN_AREAS) {
+	while (addr < corruption_check_size && num_scan_areas < MAX_SCAN_AREAS) {
 		u64 size;
 		addr = find_e820_area_size(addr, &size, PAGE_SIZE);
 
@@ -701,11 +701,11 @@ void check_for_bios_corruption(void)
 	if (!memory_corruption_check)
 		return;
 
-	for(i = 0; i < num_scan_areas; i++) {
+	for (i = 0; i < num_scan_areas; i++) {
 		unsigned long *addr = __va(scan_areas[i].addr);
 		unsigned long size = scan_areas[i].size;
 
-		for(; size; addr++, size -= sizeof(unsigned long)) {
+		for (; size; addr++, size -= sizeof(unsigned long)) {
 			if (!*addr)
 				continue;
 			printk(KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n",
@@ -721,7 +721,8 @@ void check_for_bios_corruption(void)
 static void periodic_check_for_corruption(unsigned long data)
 {
 	check_for_bios_corruption();
-	mod_timer(&periodic_check_timer, round_jiffies(jiffies + corruption_check_period*HZ));
+	mod_timer(&periodic_check_timer,
+		round_jiffies(jiffies + corruption_check_period*HZ));
 }
 
 void start_periodic_check_for_corruption(void)

commit 9301975ec251bab1ad7cfcb84a688b26187e4e4a
Merge: 7110879cf2af dd3a1db900f2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 20 13:22:50 2008 -0700

    Merge branch 'genirq-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    This merges branches irq/genirq, irq/sparseirq-v4, timers/hpet-percpu
    and x86/uv.
    
    The sparseirq branch is just preliminary groundwork: no sparse IRQs are
    actually implemented by this tree anymore - just the new APIs are added
    while keeping the old way intact as well (the new APIs map 1:1 to
    irq_desc[]).  The 'real' sparse IRQ support will then be a relatively
    small patch ontop of this - with a v2.6.29 merge target.
    
    * 'genirq-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (178 commits)
      genirq: improve include files
      intr_remapping: fix typo
      io_apic: make irq_mis_count available on 64-bit too
      genirq: fix name space collisions of nr_irqs in arch/*
      genirq: fix name space collision of nr_irqs in autoprobe.c
      genirq: use iterators for irq_desc loops
      proc: fixup irq iterator
      genirq: add reverse iterator for irq_desc
      x86: move ack_bad_irq() to irq.c
      x86: unify show_interrupts() and proc helpers
      x86: cleanup show_interrupts
      genirq: cleanup the sparseirq modifications
      genirq: remove artifacts from sparseirq removal
      genirq: revert dynarray
      genirq: remove irq_to_desc_alloc
      genirq: remove sparse irq code
      genirq: use inline function for irq_to_desc
      genirq: consolidate nr_irqs and for_each_irq_desc()
      x86: remove sparse irq from Kconfig
      genirq: define nr_irqs for architectures with GENERIC_HARDIRQS=n
      ...

commit 57cac4d1880527e0baf6c2fda529d2ad1d815aec
Author: Vivek Goyal <vgoyal@redhat.com>
Date:   Sat Oct 18 20:28:25 2008 -0700

    kdump: make elfcorehdr_addr independent of CONFIG_PROC_VMCORE
    
    o elfcorehdr_addr is used by not only the code under CONFIG_PROC_VMCORE
      but also by the code which is not inside CONFIG_PROC_VMCORE.  For
      example, is_kdump_kernel() is used by powerpc code to determine if
      kernel is booting after a panic then use previous kernel's TCE table.
      So even if CONFIG_PROC_VMCORE is not set in second kernel, one should be
      able to correctly determine that we are booting after a panic and setup
      calgary iommu accordingly.
    
    o So remove the assumption that elfcorehdr_addr is under
      CONFIG_PROC_VMCORE.
    
    o Move definition of elfcorehdr_addr to arch dependent crash files.
      (Unfortunately crash dump does not have an arch independent file
      otherwise that would have been the best place).
    
    o kexec.c is not the right place as one can Have CRASH_DUMP enabled in
      second kernel without KEXEC being enabled.
    
    o I don't see sh setup code parsing the command line for
      elfcorehdr_addr.  I am wondering how does vmcore interface work on sh.
      Anyway, I am atleast defining elfcoredhr_addr so that compilation is not
      broken on sh.
    
    Signed-off-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Simon Horman <horms@verge.net.au>
    Acked-by: Paul Mundt <lethal@linux-sh.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2255782e8d4b..b2c97874ec0f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -561,7 +561,13 @@ static void __init reserve_standard_io_resources(void)
 
 }
 
-#ifdef CONFIG_PROC_VMCORE
+/*
+ * Note: elfcorehdr_addr is not just limited to vmcore. It is also used by
+ * is_kdump_kernel() to determine if we are booting after a panic. Hence
+ * ifdef it under CONFIG_CRASH_DUMP and not CONFIG_PROC_VMCORE.
+ */
+
+#ifdef CONFIG_CRASH_DUMP
 /* elfcorehdr= specifies the location of elf core header
  * stored by the crashed kernel. This option will be passed
  * by kexec loader to the capture kernel.

commit 9d6a4d0823b3b8e29156f5e698b5a68687afad32
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:52 2008 -0700

    x86: probe nr_irqs even only mptable is used
    
    for !CONFIG_HAVE_SPARSE_IRQ
    
    fix:
    
     In file included from arch/x86/kernel/early-quirks.c:18:
     include/asm/io_apic.h: In function 'probe_nr_irqs':
     include/asm/io_apic.h:209: error: 'NR_IRQS' undeclared (first use in this function)
     include/asm/io_apic.h:209: error: (Each undeclared identifier is reported only once
     include/asm/io_apic.h:209: error: for each function it appears in.)
    
    v2: fix by Ingo
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d90c659b70e9..61335306696a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1069,15 +1069,15 @@ void __init setup_arch(char **cmdline_p)
 	prefill_possible_map();
 
 #ifdef CONFIG_X86_64
-	/* need to wait for nr_cpu_ids settle down */
-	if (nr_irqs == NR_IRQS)
-		nr_irqs = 32 * nr_cpu_ids + 224;
 	init_cpu_to_node();
 #endif
 
 	init_apic_mappings();
 	ioapic_init_mappings();
 
+	/* need to wait for io_apic is mapped */
+	nr_irqs = probe_nr_irqs();
+
 	kvm_guest_init();
 
 	e820_reserve_resources();

commit 29ccbbf232c035b8c7ff0c5060fbe30a66ed9b99
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:49 2008 -0700

    x86: remove first_free_entry/pin_map_size
    
    no user now
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 02e3a6697977..d90c659b70e9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1074,10 +1074,6 @@ void __init setup_arch(char **cmdline_p)
 		nr_irqs = 32 * nr_cpu_ids + 224;
 	init_cpu_to_node();
 #endif
-#ifdef CONFIG_X86_IO_APIC
-	pin_map_size = nr_irqs * 2;
-	first_free_entry = nr_irqs;
-#endif
 
 	init_apic_mappings();
 	ioapic_init_mappings();

commit a84488c213a8cfc29200344a6fb6357d48c8ed85
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Aug 19 20:50:31 2008 -0700

    irq: sparse irqs, fix #3
    
    fix non-APIC UP build:
    
     arch/x86/kernel/built-in.o: In function `setup_arch':
     : undefined reference to `pin_map_size'
     arch/x86/kernel/built-in.o: In function `setup_arch':
     : undefined reference to `first_free_entry'
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 558ec26b08e2..02e3a6697977 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1074,8 +1074,10 @@ void __init setup_arch(char **cmdline_p)
 		nr_irqs = 32 * nr_cpu_ids + 224;
 	init_cpu_to_node();
 #endif
+#ifdef CONFIG_X86_IO_APIC
 	pin_map_size = nr_irqs * 2;
 	first_free_entry = nr_irqs;
+#endif
 
 	init_apic_mappings();
 	ioapic_init_mappings();

commit 301e619020dd67bde7e7e64bb9ffb7f30d26c979
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:02 2008 -0700

    x86: use dyn_array in io_apic_xx.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2255782e8d4b..558ec26b08e2 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1067,9 +1067,15 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	prefill_possible_map();
+
 #ifdef CONFIG_X86_64
+	/* need to wait for nr_cpu_ids settle down */
+	if (nr_irqs == NR_IRQS)
+		nr_irqs = 32 * nr_cpu_ids + 224;
 	init_cpu_to_node();
 #endif
+	pin_map_size = nr_irqs * 2;
+	first_free_entry = nr_irqs;
 
 	init_apic_mappings();
 	ioapic_init_mappings();

commit 2e42060c19cb79adacc48beb5e9ec5361df976a2
Author: Jack Steiner <steiner@sgi.com>
Date:   Tue Sep 23 15:37:13 2008 -0500

    x86, uv: add early detection of UV system types
    
    Portions of the ACPI code needs to know if a system is a UV system prior
    to genapic initialization. This patch adds a call early_acpi_boot_init()
    so that the apic type is discovered earlier.
    
    V2 of the patch adding fixes from Yinghai Lu.
    Much cleaner and smaller.
    
    Signed-off-by: Jack Steiner <steiner@sgi.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index de6a9d6d599f..2255782e8d4b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -998,6 +998,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_table_init();
 
+	early_acpi_boot_init();
+
 #ifdef CONFIG_ACPI_NUMA
 	/*
 	 * Parse SRAT to discover nodes.

commit 88b4c146961f4178f38a8c3e6e54709fa39a3f36
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Sun Sep 7 15:21:16 2008 -0700

    x86: use early_memremap() in setup.c
    
    The remappings in setup.c are all just ordinary memory, so use
    early_memremap() rather than early_ioremap().
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 21b8e0a59780..de6a9d6d599f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -302,7 +302,7 @@ static void __init relocate_initrd(void)
 		if (clen > MAX_MAP_CHUNK-slop)
 			clen = MAX_MAP_CHUNK-slop;
 		mapaddr = ramdisk_image & PAGE_MASK;
-		p = early_ioremap(mapaddr, clen+slop);
+		p = early_memremap(mapaddr, clen+slop);
 		memcpy(q, p+slop, clen);
 		early_iounmap(p, clen+slop);
 		q += clen;
@@ -379,7 +379,7 @@ static void __init parse_setup_data(void)
 		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		data = early_ioremap(pa_data, PAGE_SIZE);
+		data = early_memremap(pa_data, PAGE_SIZE);
 		switch (data->type) {
 		case SETUP_E820_EXT:
 			parse_e820_ext(data, pa_data);
@@ -402,7 +402,7 @@ static void __init e820_reserve_setup_data(void)
 		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		data = early_ioremap(pa_data, sizeof(*data));
+		data = early_memremap(pa_data, sizeof(*data));
 		e820_update_range(pa_data, sizeof(*data)+data->len,
 			 E820_RAM, E820_RESERVED_KERN);
 		found = 1;
@@ -428,7 +428,7 @@ static void __init reserve_early_setup_data(void)
 		return;
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
-		data = early_ioremap(pa_data, sizeof(*data));
+		data = early_memremap(pa_data, sizeof(*data));
 		sprintf(buf, "setup data %x", data->type);
 		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
 		pa_data = data->next;

commit a9b9e81c915e4a57ac3b21d1a7fa7ff184639780
Merge: a8b71a281038 fd0480883066
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Oct 12 15:05:39 2008 +0200

    Merge branch 'linus' into x86/memory-corruption-check

commit d84705969f898f294bc3fc32eca33580f14105bd
Merge: 725c25819e4a 11494547b175
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Oct 10 19:50:00 2008 +0200

    Merge branch 'x86/apic' into x86-v28-for-linus-phase4-B
    
    Conflicts:
            arch/x86/kernel/apic_32.c
            arch/x86/kernel/apic_64.c
            arch/x86/kernel/setup.c
            drivers/pci/intel-iommu.c
            include/asm-x86/cpufeature.h
            include/asm-x86/dma-mapping.h

commit e496e3d645c93206faf61ff6005995ebd08cc39c
Merge: b159d7a989e5 5bbd4c372400 175e438f7a2d 516cbf3730c4 af2d237bf574 9b1568458a3e 5b7e41ff3726 1befdefcf476 a03352d2c1dc 7b22ff5344fd 2c7e9fd4c6cb 91030ca1e739 dd5523552c28 b3e15bdef689 20211e4d3447 efd327a2d412 c7ffa6c26277 e51a1ac2dfca 5df455155124 d99e90164e6c e621bd18958e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Oct 6 18:17:07 2008 +0200

    Merge branches 'x86/alternatives', 'x86/cleanups', 'x86/commandline', 'x86/crashdump', 'x86/debug', 'x86/defconfig', 'x86/doc', 'x86/exports', 'x86/fpu', 'x86/gart', 'x86/idle', 'x86/mm', 'x86/mtrr', 'x86/nmi-watchdog', 'x86/oprofile', 'x86/paravirt', 'x86/reboot', 'x86/sparse-fixes', 'x86/tsc', 'x86/urgent' and 'x86/vmalloc' into x86-v28-for-linus-phase1

commit a8b71a2810386a5ac8f43d2095fe3355f0d8db37
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Sep 23 00:35:33 2008 -0700

    x86: fix macro with bad_bios_dmi_table
    
    DMI tables need a blank NULL tail.
    
    fixes the crash on Ingo's test box.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d29951c11be0..3ce3edfcc3cd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -758,8 +758,8 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies, LTD"),
 		},
 	},
-	{}
 #endif
+	{}
 };
 
 /*

commit 2216d199b1430d1c0affb1498a9ebdbd9c0de439
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Mon Sep 22 02:52:26 2008 -0700

    x86: fix CONFIG_X86_RESERVE_LOW_64K=y
    
    The bad_bios_dmi_table() quirk never triggered because we do DMI setup
    too late. Move it a bit earlier.
    
    Also change the CONFIG_X86_RESERVE_LOW_64K quirk to operate on the e820
    table directly instead of messing with early reservations - this handles
    overlaps (which do occur in this low range of RAM) more gracefully.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 161f1b33ecec..d29951c11be0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -735,7 +735,8 @@ static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 		"%s detected: BIOS may corrupt low RAM, working it around.\n",
 		d->ident);
 
-	reserve_early_overlap_ok(0x0, 0x10000, "BIOS quirk");
+	e820_update_range(0, 0x10000, E820_RAM, E820_RESERVED);
+	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 
 	return 0;
 }
@@ -784,8 +785,6 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
-	dmi_check_system(bad_bios_dmi_table);
-
 	early_cpu_init();
 	early_ioremap_init();
 
@@ -880,6 +879,10 @@ void __init setup_arch(char **cmdline_p)
 
 	finish_e820_parsing();
 
+	dmi_scan_machine();
+
+	dmi_check_system(bad_bios_dmi_table);
+
 #ifdef CONFIG_X86_32
 	probe_roms();
 #endif
@@ -967,8 +970,6 @@ void __init setup_arch(char **cmdline_p)
 	vsmp_init();
 #endif
 
-	dmi_scan_machine();
-
 	io_delay_init();
 
 	/*

commit 5871c6b0a52bb052c3891a787655043b90ae18e3
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Sat Sep 20 20:35:44 2008 -0700

    x86: use round_jiffies() for the corruption check timer
    
    the exact timing of the corruption check isn't too important (it's once a
    minute timer), use round_jiffies() to align it and avoid extra wakeups.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 786c1886ae53..161f1b33ecec 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -712,7 +712,7 @@ void check_for_bios_corruption(void)
 static void periodic_check_for_corruption(unsigned long data)
 {
 	check_for_bios_corruption();
-	mod_timer(&periodic_check_timer, jiffies + corruption_check_period*HZ);
+	mod_timer(&periodic_check_timer, round_jiffies(jiffies + corruption_check_period*HZ));
 }
 
 void start_periodic_check_for_corruption(void)

commit fc38151947477596aa27df6c4306ad6008dc6711
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Sep 16 10:07:34 2008 +0200

    x86: add X86_RESERVE_LOW_64K
    
    This bugzilla:
    
      http://bugzilla.kernel.org/show_bug.cgi?id=11237
    
    Documents a wide range of systems where the BIOS utilizes the first
    64K of physical memory during suspend/resume and other hardware events.
    
    Currently we reserve this memory on all AMI and Phoenix BIOS systems.
    Life is too short to hunt subtle memory corruption problems like this,
    so we try to be robust by default.
    
    Still, allow this to be overriden: allow users who want that first 64K
    of memory to be available to the kernel disable the quirk, via
    CONFIG_X86_RESERVE_LOW_64K=n.
    
    Also, allow the early reservation to overlap with other
    early reservations.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 33719544a224..786c1886ae53 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -735,13 +735,14 @@ static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 		"%s detected: BIOS may corrupt low RAM, working it around.\n",
 		d->ident);
 
-	reserve_early(0x0, 0x10000, "BIOS quirk");
+	reserve_early_overlap_ok(0x0, 0x10000, "BIOS quirk");
 
 	return 0;
 }
 
 /* List of systems that have known low memory corruption BIOS problems */
 static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
+#ifdef CONFIG_X86_RESERVE_LOW_64K
 	{
 		.callback = dmi_low_memory_corruption,
 		.ident = "AMI BIOS",
@@ -757,6 +758,7 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 		},
 	},
 	{}
+#endif
 };
 
 /*

commit 1e22436eba84edfec9c25e5a25d09062c4f91ca9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Sep 16 09:58:02 2008 +0200

    x86: reserve low 64K on AMI and Phoenix BIOS boxen
    
    there's multiple reports about suspend/resume related low memory
    corruption in this bugzilla:
    
      http://bugzilla.kernel.org/show_bug.cgi?id=11237
    
    the common pattern is that the corruption is caused by the BIOS,
    and that it affects some portion of the first 64K of physical RAM.
    
    So add a DMI quirk
    
    This will waste 64K RAM on 'good' systems too, but without knowing
    the exact nature of this BIOS memory corruption this is the safest
    approach.
    
    This might as well solve a wide range of suspend/resume breakages
    under Linux.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3109ca37a67c..33719544a224 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -732,10 +732,10 @@ void start_periodic_check_for_corruption(void)
 static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
 {
 	printk(KERN_NOTICE
-		"%s detected: BIOS corrupts 0xc000, working it around.\n",
+		"%s detected: BIOS may corrupt low RAM, working it around.\n",
 		d->ident);
 
-	reserve_early(0xc000, 0xc400, "BIOS quirk");
+	reserve_early(0x0, 0x10000, "BIOS quirk");
 
 	return 0;
 }
@@ -749,6 +749,13 @@ static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
 			DMI_MATCH(DMI_BIOS_VENDOR, "American Megatrends Inc."),
 		},
 	},
+	{
+		.callback = dmi_low_memory_corruption,
+		.ident = "Phoenix BIOS",
+		.matches = {
+			DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies, LTD"),
+		},
+	},
 	{}
 };
 

commit 5649b7c30316a51792808422ac03ee825d26aa5e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Sep 16 09:29:09 2008 +0200

    x86: add DMI quirk for AMI BIOS which corrupts address 0xc000 during resume
    
    Alan Jenkins and Andy Wettstein reported a suspend/resume memory
    corruption bug and extensively documented it here:
    
       http://bugzilla.kernel.org/show_bug.cgi?id=11237
    
    The bug is that the BIOS overwrites 1K of memory at 0xc000 physical,
    without registering it in e820 as reserved or giving the kernel any
    idea about this.
    
    Detect AMI BIOSen and reserve that 1K.
    
    We paint this bug around with a very broad brush (reserving that 1K on all
    AMI BIOS systems), as the bug was extremely hard to find and needed several
    weeks and lots of debugging and patching.
    
    The bug was found via the CONFIG_X86_CHECK_BIOS_CORRUPTION=y debug feature,
    if similar bugs are suspected then this feature can be enabled on other
    systems as well to scan low memory for corrupted memory.
    
    Reported-by: Alan Jenkins <alan-jenkins@tuffmail.co.uk>
    Reported-by: Andy Wettstein <ajw1980@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ec7e56c1b984..3109ca37a67c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -729,6 +729,29 @@ void start_periodic_check_for_corruption(void)
 }
 #endif
 
+static int __init dmi_low_memory_corruption(const struct dmi_system_id *d)
+{
+	printk(KERN_NOTICE
+		"%s detected: BIOS corrupts 0xc000, working it around.\n",
+		d->ident);
+
+	reserve_early(0xc000, 0xc400, "BIOS quirk");
+
+	return 0;
+}
+
+/* List of systems that have known low memory corruption BIOS problems */
+static struct dmi_system_id __initdata bad_bios_dmi_table[] = {
+	{
+		.callback = dmi_low_memory_corruption,
+		.ident = "AMI BIOS",
+		.matches = {
+			DMI_MATCH(DMI_BIOS_VENDOR, "American Megatrends Inc."),
+		},
+	},
+	{}
+};
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -752,6 +775,8 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
+	dmi_check_system(bad_bios_dmi_table);
+
 	early_cpu_init();
 	early_ioremap_init();
 
@@ -1037,3 +1062,5 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #endif
 }
+
+

commit 0ad5bce7409d681a5655c66e64bb0eb740b89c1f
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Thu Sep 11 16:42:00 2008 -0700

    x86: fix possible x86_64 and EFI regression
    
    Russ Anderson reported a boot crash with EFI and latest mainline:
    
     BIOS-e820: 00000000fffa0000 - 00000000fffac000 (reserved)
    Pid: 0, comm: swapper Not tainted 2.6.27-rc5-00100-gec0c15a-dirty #5
    
    Call Trace:
     [<ffffffff80849195>] early_idt_handler+0x55/0x69
     [<ffffffff80313e52>] __memcpy+0x12/0xa4
     [<ffffffff80859015>] efi_init+0xce/0x932
     [<ffffffff80869c83>] setup_early_serial8250_console+0x2d/0x36a
     [<ffffffff80238688>] __insert_resource+0x18/0xc8
     [<ffffffff8084f6de>] setup_arch+0x3a7/0x632
     [<ffffffff808499ed>] start_kernel+0x91/0x367
     [<ffffffff80849393>] x86_64_start_kernel+0xe3/0xe7
     [<ffffffff808492b0>] x86_64_start_kernel+0x0/0xe7
    
     RIP 0x10
    
    Such a crash is possible if the CPU in this system is a 64-bit
    processor which doesn't support NX (ie, old Intel P4 -based64-bit
    processors).
    
    Certainly, if we support such processors, then we should start with
    _PAGE_NX initially clear in __supported_pte_flags, and then set it once
    we've established that the processor does indeed support NX.  That will
    prevent early_ioremap - or anything else - from trying to set it.
    
    The simple fix is to simply call check_efer() earlier.
    
    Reported-by: Russ Anderson <rja@sgi.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 362d4e7f2d38..9838f2539dfc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -670,6 +670,10 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+#ifdef CONFIG_X86_64
+	check_efer();
+#endif
+
 #if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
 	/*
 	 * Must be before kernel pagetables are setup
@@ -738,7 +742,6 @@ void __init setup_arch(char **cmdline_p)
 #else
 	num_physpages = max_pfn;
 
-	check_efer();
 
 	/* How many end-of-memory variables you have, grandma! */
 	/* need this before calling reserve_initrd */

commit c885df50f571faf9fd9f395361cfff1b3a16e06e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Sun Sep 7 02:37:32 2008 -0700

    x86: default corruption check to off, but put parameter default in Kconfig
    
    Default the low memory corruption check to off, but make the default setting of
    the memory_corruption_check kernel parameter a config parameter.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 27ae91288855..ec7e56c1b984 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -587,7 +587,8 @@ struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 #ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
 #define MAX_SCAN_AREAS	8
 
-static int __read_mostly memory_corruption_check = 0;
+static int __read_mostly memory_corruption_check = -1;
+
 static unsigned __read_mostly corruption_check_size = 64*1024;
 static unsigned __read_mostly corruption_check_period = 60; /* seconds */
 
@@ -634,6 +635,16 @@ static void __init setup_bios_corruption_check(void)
 {
 	u64 addr = PAGE_SIZE;	/* assume first page is reserved anyway */
 
+	if (memory_corruption_check == -1) {
+		memory_corruption_check =
+#ifdef CONFIG_X86_BOOTPARAM_MEMORY_CORRUPTION_CHECK
+			1
+#else
+			0
+#endif
+			;
+	}
+
 	if (corruption_check_size == 0)
 		memory_corruption_check = 0;
 

commit 9f077871ce7237e2387fc76542b3b4033cb05e49
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Sun Sep 7 01:51:34 2008 -0700

    x86: clean up memory corruption check and add more kernel parameters
    
    The corruption check is enabled in Kconfig by default, but disabled at runtime.
    
    This patch adds several kernel parameters to control the corruption
    check's behaviour; these are documented in kernel-parameters.txt.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c239b3780973..27ae91288855 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -586,22 +586,71 @@ struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
  */
 #ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
 #define MAX_SCAN_AREAS	8
+
+static int __read_mostly memory_corruption_check = 0;
+static unsigned __read_mostly corruption_check_size = 64*1024;
+static unsigned __read_mostly corruption_check_period = 60; /* seconds */
+
 static struct e820entry scan_areas[MAX_SCAN_AREAS];
 static int num_scan_areas;
 
+
+static int set_corruption_check(char *arg)
+{
+	char *end;
+
+	memory_corruption_check = simple_strtol(arg, &end, 10);
+
+	return (*end == 0) ? 0 : -EINVAL;
+}
+early_param("memory_corruption_check", set_corruption_check);
+
+static int set_corruption_check_period(char *arg)
+{
+	char *end;
+
+	corruption_check_period = simple_strtoul(arg, &end, 10);
+
+	return (*end == 0) ? 0 : -EINVAL;
+}
+early_param("memory_corruption_check_period", set_corruption_check_period);
+
+static int set_corruption_check_size(char *arg)
+{
+	char *end;
+	unsigned size;
+
+	size = memparse(arg, &end);
+
+	if (*end == '\0')
+		corruption_check_size = size;
+
+	return (size == corruption_check_size) ? 0 : -EINVAL;
+}
+early_param("memory_corruption_check_size", set_corruption_check_size);
+
+
 static void __init setup_bios_corruption_check(void)
 {
 	u64 addr = PAGE_SIZE;	/* assume first page is reserved anyway */
 
-	while(addr < 0x10000 && num_scan_areas < MAX_SCAN_AREAS) {
+	if (corruption_check_size == 0)
+		memory_corruption_check = 0;
+
+	if (!memory_corruption_check)
+		return;
+
+	corruption_check_size = round_up(corruption_check_size, PAGE_SIZE);
+
+	while(addr < corruption_check_size && num_scan_areas < MAX_SCAN_AREAS) {
 		u64 size;
 		addr = find_e820_area_size(addr, &size, PAGE_SIZE);
 
 		if (addr == 0)
 			break;
 
-		if ((addr + size) > 0x10000)
-			size = 0x10000 - addr;
+		if ((addr + size) > corruption_check_size)
+			size = corruption_check_size - addr;
 
 		if (size == 0)
 			break;
@@ -617,12 +666,11 @@ static void __init setup_bios_corruption_check(void)
 		addr += size;
 	}
 
-	printk(KERN_INFO "scanning %d areas for BIOS corruption\n",
+	printk(KERN_INFO "Scanning %d areas for low memory corruption\n",
 	       num_scan_areas);
 	update_e820();
 }
 
-static int __read_mostly bios_corruption_check = 1;
 static struct timer_list periodic_check_timer;
 
 void check_for_bios_corruption(void)
@@ -630,7 +678,7 @@ void check_for_bios_corruption(void)
 	int i;
 	int corruption = 0;
 
-	if (!bios_corruption_check)
+	if (!memory_corruption_check)
 		return;
 
 	for(i = 0; i < num_scan_areas; i++) {
@@ -647,35 +695,27 @@ void check_for_bios_corruption(void)
 		}
 	}
 
-	if (corruption)
-		dump_stack();
+	WARN(corruption, KERN_ERR "Memory corruption detected in low memory\n");
 }
 
 static void periodic_check_for_corruption(unsigned long data)
 {
 	check_for_bios_corruption();
-	mod_timer(&periodic_check_timer, jiffies + 60*HZ);
+	mod_timer(&periodic_check_timer, jiffies + corruption_check_period*HZ);
 }
 
 void start_periodic_check_for_corruption(void)
 {
-	if (!bios_corruption_check)
+	if (!memory_corruption_check || corruption_check_period == 0)
 		return;
 
+	printk(KERN_INFO "Scanning for low memory corruption every %d seconds\n",
+	       corruption_check_period);
+
 	init_timer(&periodic_check_timer);
 	periodic_check_timer.function = &periodic_check_for_corruption;
 	periodic_check_for_corruption(0);
 }
-
-static int set_bios_corruption_check(char *arg)
-{
-	char *end;
-
-	bios_corruption_check = simple_strtol(arg, &end, 10);
-
-	return (*end == 0) ? 0 : -EINVAL;
-}
-early_param("bios_corruption_check", set_bios_corruption_check);
 #endif
 
 /*

commit bb577f980ef35e2b0d00aeed566724e5032aa5eb
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sun Sep 7 01:51:33 2008 -0700

    x86: add periodic corruption check
    
    Perodically check for corruption in low phusical memory.  Don't bother
    checking at fault time, since it won't show anything useful.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ee89ebc5aabc..c239b3780973 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -623,6 +623,7 @@ static void __init setup_bios_corruption_check(void)
 }
 
 static int __read_mostly bios_corruption_check = 1;
+static struct timer_list periodic_check_timer;
 
 void check_for_bios_corruption(void)
 {
@@ -650,6 +651,22 @@ void check_for_bios_corruption(void)
 		dump_stack();
 }
 
+static void periodic_check_for_corruption(unsigned long data)
+{
+	check_for_bios_corruption();
+	mod_timer(&periodic_check_timer, jiffies + 60*HZ);
+}
+
+void start_periodic_check_for_corruption(void)
+{
+	if (!bios_corruption_check)
+		return;
+
+	init_timer(&periodic_check_timer);
+	periodic_check_timer.function = &periodic_check_for_corruption;
+	periodic_check_for_corruption(0);
+}
+
 static int set_bios_corruption_check(char *arg)
 {
 	char *end;

commit 5394f80f92642c61fc2a95385be85f2fdcfb5adb
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Sun Sep 7 01:51:32 2008 -0700

    x86: check for and defend against BIOS memory corruption
    
    Some BIOSes have been observed to corrupt memory in the low 64k.  This
    change:
     - Reserves all memory which does not have to be in that area, to
       prevent it from being used as general memory by the kernel.  Things
       like the SMP trampoline are still in the memory, however.
     - Clears the reserved memory so we can observe changes to it.
     - Adds a function check_for_bios_corruption() which checks and reports on
       memory becoming unexpectedly non-zero.  Currently it's called in the
       x86 fault handler, and the powermanagement debug output.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 362d4e7f2d38..ee89ebc5aabc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -578,6 +578,89 @@ static struct x86_quirks default_x86_quirks __initdata;
 
 struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
 
+/*
+ * Some BIOSes seem to corrupt the low 64k of memory during events
+ * like suspend/resume and unplugging an HDMI cable.  Reserve all
+ * remaining free memory in that area and fill it with a distinct
+ * pattern.
+ */
+#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
+#define MAX_SCAN_AREAS	8
+static struct e820entry scan_areas[MAX_SCAN_AREAS];
+static int num_scan_areas;
+
+static void __init setup_bios_corruption_check(void)
+{
+	u64 addr = PAGE_SIZE;	/* assume first page is reserved anyway */
+
+	while(addr < 0x10000 && num_scan_areas < MAX_SCAN_AREAS) {
+		u64 size;
+		addr = find_e820_area_size(addr, &size, PAGE_SIZE);
+
+		if (addr == 0)
+			break;
+
+		if ((addr + size) > 0x10000)
+			size = 0x10000 - addr;
+
+		if (size == 0)
+			break;
+
+		e820_update_range(addr, size, E820_RAM, E820_RESERVED);
+		scan_areas[num_scan_areas].addr = addr;
+		scan_areas[num_scan_areas].size = size;
+		num_scan_areas++;
+
+		/* Assume we've already mapped this early memory */
+		memset(__va(addr), 0, size);
+
+		addr += size;
+	}
+
+	printk(KERN_INFO "scanning %d areas for BIOS corruption\n",
+	       num_scan_areas);
+	update_e820();
+}
+
+static int __read_mostly bios_corruption_check = 1;
+
+void check_for_bios_corruption(void)
+{
+	int i;
+	int corruption = 0;
+
+	if (!bios_corruption_check)
+		return;
+
+	for(i = 0; i < num_scan_areas; i++) {
+		unsigned long *addr = __va(scan_areas[i].addr);
+		unsigned long size = scan_areas[i].size;
+
+		for(; size; addr++, size -= sizeof(unsigned long)) {
+			if (!*addr)
+				continue;
+			printk(KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n",
+			       addr, __pa(addr), *addr);
+			corruption = 1;
+			*addr = 0;
+		}
+	}
+
+	if (corruption)
+		dump_stack();
+}
+
+static int set_bios_corruption_check(char *arg)
+{
+	char *end;
+
+	bios_corruption_check = simple_strtol(arg, &end, 10);
+
+	return (*end == 0) ? 0 : -EINVAL;
+}
+early_param("bios_corruption_check", set_bios_corruption_check);
+#endif
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -750,6 +833,10 @@ void __init setup_arch(char **cmdline_p)
 	high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
 #endif
 
+#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION
+	setup_bios_corruption_check();
+#endif
+
 	/* max_pfn_mapped is updated here */
 	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
 	max_pfn_mapped = max_low_pfn_mapped;

commit 3a6ddd5f18405ca92e004416af8ed44b9c9783d7
Author: Alok Kataria <akataria@vmware.com>
Date:   Thu Aug 21 11:32:26 2008 -0700

    x86: fix VMI for early params
    
    while fixing a different bug i moved the call to vmi_init before
    early params could be parsed.
    
    This broke the vmi specific commandline parameters.
    Fix that, by moving vmi initialization after kernel has got a chance to
    parse early parameters.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a4656adab53b..362d4e7f2d38 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -604,14 +604,6 @@ void __init setup_arch(char **cmdline_p)
 	early_cpu_init();
 	early_ioremap_init();
 
-#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
-	/*
-	 * Must be before kernel pagetables are setup
-	 * or fixmap area is touched.
-	 */
-	vmi_init();
-#endif
-
 	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
 	screen_info = boot_params.screen_info;
 	edid_info = boot_params.edid_info;
@@ -678,6 +670,14 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
+	/*
+	 * Must be before kernel pagetables are setup
+	 * or fixmap area is touched.
+	 */
+	vmi_init();
+#endif
+
 	/* after early param, so could get panic from serial */
 	reserve_early_setup_data();
 

commit 516cbf3730c49739629d66313b20bdc50c98aa2c
Author: Tim Bird <tim.bird@am.sony.com>
Date:   Tue Aug 12 12:52:36 2008 -0700

    x86, bootup: add built-in kernel command line for x86 (v2)
    
    Allow x86 to support a built-in kernel command line.  The built-in
    command line can override the one provided by the boot loader, for
    those cases where the boot loader is broken or it is difficult
    to change the command line in the the boot loader.
    
    H. Peter Anvin wrote:
    > Ingo Molnar wrote:
    >> Best would be to make it really apparent in the code that nothing
    >> changes if this config option is not set. Preferably there should be
    >> no extra code at all in that case.
    >>
    >
    > I would like to see this:
    [...Nested ifdefs...]
    
    OK. This version changes absolutely nothing if CONFIG_CMDLINE_BOOL is not
    set (the default).  Also, no space is appended even when CONFIG_CMDLINE_BOOL
    is set, but the builtin string is empty.  This is less sloppy all the way
    around, IMHO.
    
    Note that I use the same option names as on other arches for
    this feature.
    
    [ mingo@elte.hu: build fix ]
    
    Signed-off-by: Tim Bird <tim.bird@am.sony.com>
    Cc: Matt Mackall <mpm@selenic.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 68b48e3fbcbd..2f31cddd27b7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -223,6 +223,9 @@ unsigned long saved_video_mode;
 #define RAMDISK_LOAD_FLAG		0x4000
 
 static char __initdata command_line[COMMAND_LINE_SIZE];
+#ifdef CONFIG_CMDLINE_BOOL
+static char __initdata builtin_cmdline[COMMAND_LINE_SIZE] = CONFIG_CMDLINE;
+#endif
 
 #if defined(CONFIG_EDD) || defined(CONFIG_EDD_MODULE)
 struct edd edd;
@@ -673,6 +676,19 @@ void __init setup_arch(char **cmdline_p)
 	bss_resource.start = virt_to_phys(&__bss_start);
 	bss_resource.end = virt_to_phys(&__bss_stop)-1;
 
+#ifdef CONFIG_CMDLINE_BOOL
+#ifdef CONFIG_CMDLINE_OVERRIDE
+	strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
+#else
+	if (builtin_cmdline[0]) {
+		/* append boot loader cmdline to builtin */
+		strlcat(builtin_cmdline, " ", COMMAND_LINE_SIZE);
+		strlcat(builtin_cmdline, boot_command_line, COMMAND_LINE_SIZE);
+		strlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);
+	}
+#endif
+#endif
+
 	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
 	*cmdline_p = command_line;
 

commit 51ca3c679194e7435c25b8e77b0a73c597e41ae9
Merge: b55793f7528c b635acec48bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Aug 14 14:58:01 2008 +0200

    Merge branch 'linus' into x86/core
    
    Conflicts:
            arch/x86/kernel/genapic_64.c
            include/asm-x86/kvm_host.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 6b3560229d3b6be7443fa9f9c6502e660bcfef5f
Author: Marcin Slusarz <marcin.slusarz@gmail.com>
Date:   Tue Aug 12 23:23:05 2008 +0200

    x86: fix 2 section mismatch warnings - find_and_reserve_crashkernel
    
    WARNING: vmlinux.o(.text+0xcd1f): Section mismatch in reference from the function find_and_reserve_crashkernel() to the function .init.text:find_e820_area()
    The function find_and_reserve_crashkernel() references
    the function __init find_e820_area().
    This is often because find_and_reserve_crashkernel lacks a __init
    annotation or the annotation of find_e820_area is wrong.
    
    WARNING: vmlinux.o(.text+0xcd38): Section mismatch in reference from the function find_and_reserve_crashkernel() to the function .init.text:reserve_bootmem_generic()
    The function find_and_reserve_crashkernel() references
    the function __init reserve_bootmem_generic().
    This is often because find_and_reserve_crashkernel lacks a __init
    annotation or the annotation of reserve_bootmem_generic is wrong.
    
    find_and_reserve_crashkernel is called from __init function (reserve_crashkernel)
    and calls 2 __init functions (find_e820_area, reserve_bootmem_generic),
    so mark it __init
    
    Signed-off-by: Marcin Slusarz <marcin.slusarz@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 68b48e3fbcbd..a4656adab53b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -445,7 +445,7 @@ static void __init reserve_early_setup_data(void)
  * @size: Size of the crashkernel memory to reserve.
  * Returns the base address on success, and -1ULL on failure.
  */
-unsigned long long find_and_reserve_crashkernel(unsigned long long size)
+unsigned long long __init find_and_reserve_crashkernel(unsigned long long size)
 {
 	const unsigned long long alignment = 16<<20; 	/* 16M */
 	unsigned long long start = 0LL;

commit b74548e76a0eab1f29546e7c5a589429c069a680
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Mon Aug 11 13:36:04 2008 -0700

    x86: fix 2.6.27rc1 cannot boot more than 8CPUs
    
    Jeff Chua reported that booting a !bigsmp kernel on a 16-way box
    hangs silently.
    
    this is a long-standing issue, smp start AP cpu could check the
    apic id >=8 etc before trying to start it.
    
    achieve this by moving the def_to_bigsmp check later and skip the
    apicid id > 8
    
    [ mingo@elte.hu: clean up the message that is printed. ]
    
    Reported-by: "Jeff Chua" <jeff.chua.linux@gmail.com>
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    
     arch/x86/kernel/setup.c   |    6 ------
     arch/x86/kernel/smpboot.c |   10 ++++++++++
     2 files changed, 10 insertions(+), 6 deletions(-)

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6e5823b9e765..68b48e3fbcbd 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -861,12 +861,6 @@ void __init setup_arch(char **cmdline_p)
 	init_apic_mappings();
 	ioapic_init_mappings();
 
-#if defined(CONFIG_SMP) && defined(CONFIG_X86_PC) && defined(CONFIG_X86_32)
-	if (def_to_bigsmp)
-		printk(KERN_WARNING "More than 8 CPUs detected and "
-			"CONFIG_X86_PC cannot handle it.\nUse "
-			"CONFIG_X86_GENERICARCH or CONFIG_X86_BIGSMP.\n");
-#endif
 	kvm_guest_init();
 
 	e820_reserve_resources();

commit 31343d8a5079cda57ffd539fcf4f00cea344fe98
Author: Alok Kataria <akataria@vmware.com>
Date:   Fri Aug 8 12:15:57 2008 -0700

    x86: Fix broken VMI in 2.6.27-rc..
    
    The lowmem mapping table created by VMI need not depend on max_low_pfn
    at all.  Instead we now create an extra large mapping which covers all
    possible lowmem instead of the physical ram that is actually available.
    
    This allows the vmi initialization to be done before max_low_pfn could
    be computed. We also move the vmi_init code very early in the boot process
    so that nobody accidentally breaks the fixmap dependancy.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    Acked-by: Zachary Amsden <zach@vmware.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2d888586385d..6e5823b9e765 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -604,6 +604,14 @@ void __init setup_arch(char **cmdline_p)
 	early_cpu_init();
 	early_ioremap_init();
 
+#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
+	/*
+	 * Must be before kernel pagetables are setup
+	 * or fixmap area is touched.
+	 */
+	vmi_init();
+#endif
+
 	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
 	screen_info = boot_params.screen_info;
 	edid_info = boot_params.edid_info;
@@ -817,14 +825,6 @@ void __init setup_arch(char **cmdline_p)
 	kvmclock_init();
 #endif
 
-#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
-	/*
-	 * Must be after max_low_pfn is determined, and before kernel
-	 * pagetables are setup.
-	 */
-	vmi_init();
-#endif
-
 	paravirt_pagetable_setup_start(swapper_pg_dir);
 	paging_init();
 	paravirt_pagetable_setup_done(swapper_pg_dir);

commit 6ce37a58e334ef773f88283939afc9f4965c7697
Merge: d7ba11d01cfe 91467bdf6e53
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 28 17:19:02 2008 +0200

    Merge branch 'x86/crashdump' into x86/urgent

commit 10a010f6953b5a14ba2f0be40a4fce1bea220875
Merge: 510b37258dfd fb2e405fc1fc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 25 13:08:16 2008 +0200

    Merge branch 'linus' into x86/x2apic
    
    Conflicts:
    
            drivers/pci/dmar.c
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9e882c9282512cc622752f29ec7c29ce338fc1eb
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Mon Jul 21 16:49:54 2008 -0700

    x86: call early_cpu_init at the same point
    
    Call early_cpu_init() at the same (early) point in setup_arch().
    The x86_64 code was calling it relatively late, after when other arch
    code need to do cpu-related setup which depends on it.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4aacb9f52e3..b520dae02bf4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -597,11 +597,11 @@ void __init setup_arch(char **cmdline_p)
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
 	pre_setup_arch_hook();
-	early_cpu_init();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
+	early_cpu_init();
 	early_ioremap_init();
 
 	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
@@ -665,9 +665,6 @@ void __init setup_arch(char **cmdline_p)
 	bss_resource.start = virt_to_phys(&__bss_start);
 	bss_resource.end = virt_to_phys(&__bss_stop)-1;
 
-#ifdef CONFIG_X86_64
-	early_cpu_init();
-#endif
 	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
 	*cmdline_p = command_line;
 

commit 76c3bb15d6786a0b8da0ad0090e0c9c3672fc08b
Merge: 7be42004065c 93ded9b8fd42
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 22 09:06:21 2008 +0200

    Merge branch 'linus' into x86/x2apic

commit 988781dc3e1d9209192b04458d279815923f5e76
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Mon Jul 21 11:21:43 2008 -0700

    x86: use setup_clear_cpu_cap with disable_apic, fix
    
    beauty fix: /proc/cpuinfo will still show apic feature even if
    we booted up with it disabled.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ec952aa5394a..b4aacb9f52e3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -680,7 +680,7 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_X86_LOCAL_APIC
 		disable_apic = 1;
 #endif
-		clear_cpu_cap(&boot_cpu_data, X86_FEATURE_APIC);
+		setup_clear_cpu_cap(X86_FEATURE_APIC);
 	}
 
 #ifdef CONFIG_PCI

commit acee709cab689ec7703770e8b8cb5cc3a4abcb31
Merge: 33a37eb411d1 5ff4789d045c 35b680557f95 c4dc59ae7af8 7edf8891ad7a 9781f39fd209 48fe4a76e27d be54f9d1c8df 77e442461c74 caadbdce240c 5e5a29bf2624 e3a61b0a8c0e fec0962e0bed fab3b58d3b24 f2ba93929fdb 48ae74443403 3cabf37f6167 7019cc2dd6fa 2ddf9b7b3e66 e66d90fb4abd
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 21 16:37:17 2008 +0200

    Merge branches 'x86/urgent', 'x86/amd-iommu', 'x86/apic', 'x86/cleanups', 'x86/core', 'x86/cpu', 'x86/fixmap', 'x86/gart', 'x86/kprobes', 'x86/memtest', 'x86/modules', 'x86/nmi', 'x86/pat', 'x86/reboot', 'x86/setup', 'x86/step', 'x86/unify-pci', 'x86/uv', 'x86/xen' and 'xen-64bit' into x86/for-linus

commit 63b5d7af2556a7de6bf72c5dd0b85a32fb4c3767
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sat Jul 19 18:02:26 2008 -0700

    x86: add ->pre_time_init to x86_quirks
    
    so NUMAQ can use that to call numaq_pre_time_init()
    
    This allows us to remove a NUMAQ special from arch/x86/kernel/setup.c.
    
    (and paves the way to remove the NUMAQ subarch)
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bbcc13d0b569..4064616cfa85 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -853,14 +853,6 @@ void __init setup_arch(char **cmdline_p)
 	init_cpu_to_node();
 #endif
 
-#ifdef CONFIG_X86_NUMAQ
-	/*
-	 * need to check online nodes num, call it
-	 * here before time_init/tsc_init
-	 */
-	numaq_tsc_disable();
-#endif
-
 	init_apic_mappings();
 	ioapic_init_mappings();
 

commit 3c9cb6de1e5ad37d1558fdb0d9d2bed5a7bac0d9
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sat Jul 19 02:07:25 2008 -0700

    x86: introduce x86_quirks
    
    introduce x86_quirks array of boot-time quirk methods.
    
    No change in functionality intended.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4a2b8acc1d95..bbcc13d0b569 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -574,6 +574,10 @@ static int __init setup_elfcorehdr(char *arg)
 early_param("elfcorehdr", setup_elfcorehdr);
 #endif
 
+static struct x86_quirks default_x86_quirks __initdata;
+
+struct x86_quirks *x86_quirks __initdata = &default_x86_quirks;
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit 91467bdf6e53058af13fd255375d6634ba0c70e0
Author: Bernhard Walle <bwalle@suse.de>
Date:   Fri Jul 18 19:07:53 2008 +0200

    x86: move dma32_reserve_bootmem() after reserve_crashkernel()
    
    On a x86-64 machine (nothing special I could encounter) I had the problem that
    crashkernel reservation with the usual "64M@16M" failed. While debugging that,
    I encountered that dma32_reserve_bootmem() reserves a memory region which is in
    that area.
    
    Because dma32_reserve_bootmem() does not rely on a specific offset but
    crashkernel does, it makes sense to move the dma32_reserve_bootmem()
    reservation down a bit. I tested that patch and it works without problems. I
    don't see any negative effects of that move, but maybe I oversaw something ...
    
    While we strictly don't need that patch in 2.6.27 because we have the
    automatic, dynamic offset detection, it makes sense to also include it here
    because:
    
      - it's easier to get it in -stable then,
      - many people are still used to the 'crashkernel=...@16M' syntax,
      - not everybody may be using a reloatable kernel.
    
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: kexec@lists.infradead.org
    Cc: vgoyal@redhat.com
    Cc: akpm@linux-foundation.org
    Cc: Bernhard Walle <bwalle@suse.de>
    Cc: yhlu.kernel@gmail.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 531b55b8e81a..74d110ef2690 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -792,10 +792,6 @@ void __init setup_arch(char **cmdline_p)
 
 	initmem_init(0, max_pfn);
 
-#ifdef CONFIG_X86_64
-	dma32_reserve_bootmem();
-#endif
-
 #ifdef CONFIG_ACPI_SLEEP
 	/*
 	 * Reserve low memory region for sleep support.
@@ -810,6 +806,15 @@ void __init setup_arch(char **cmdline_p)
 #endif
 	reserve_crashkernel();
 
+#ifdef CONFIG_X86_64
+	/*
+	 * dma32_reserve_bootmem() allocates bootmem which may conflict
+	 * with the crashkernel command line, so do that after
+	 * reserve_crashkernel()
+	 */
+	dma32_reserve_bootmem();
+#endif
+
 	reserve_ibft_region();
 
 #ifdef CONFIG_KVM_CLOCK

commit a208f37a465e222218974ab20a31b42b7b4893b2
Merge: 511d9d341836 5b664cb235e9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 18 22:50:34 2008 +0200

    Merge branch 'linus' into x86/x2apic

commit 47129654226b5bd418afe533ce4e11d6a0b6d6e4
Author: Alexander Beregalov <a.beregalov@gmail.com>
Date:   Sun Jul 6 20:13:49 2008 +0400

    x86 setup.c: cleanup includes
    
    x86: remove double includes in setup.c
    
    Signed-off-by: Alexander Beregalov <a.beregalov@gmail.com>
    Cc: yhlu.kernel@gmail.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 531b55b8e81a..4a2b8acc1d95 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -57,12 +57,8 @@
 #include <linux/slab.h>
 #include <linux/user.h>
 #include <linux/delay.h>
-#include <linux/highmem.h>
 
 #include <linux/kallsyms.h>
-#include <linux/edd.h>
-#include <linux/iscsi_ibft.h>
-#include <linux/kexec.h>
 #include <linux/cpufreq.h>
 #include <linux/dma-mapping.h>
 #include <linux/ctype.h>
@@ -104,7 +100,6 @@
 #include <asm/paravirt.h>
 
 #include <asm/percpu.h>
-#include <asm/sections.h>
 #include <asm/topology.h>
 #include <asm/apicdef.h>
 #ifdef CONFIG_X86_64

commit 393d81aa026e19b6ede6f5f11955c97ee62e5df5
Merge: 93a0886e2368 5b664cb235e9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jul 17 23:57:20 2008 +0200

    Merge branch 'linus' into xen-64bit

commit dc7c65db2845a8d17432d89252c4227a9a7cb15f
Merge: 8a0ca91e1db5 58b6e5538460
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 16 17:25:46 2008 -0700

    Merge branch 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6
    
    * 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6: (72 commits)
      Revert "x86/PCI: ACPI based PCI gap calculation"
      PCI: remove unnecessary volatile in PCIe hotplug struct controller
      x86/PCI: ACPI based PCI gap calculation
      PCI: include linux/pm_wakeup.h for device_set_wakeup_capable
      PCI PM: Fix pci_prepare_to_sleep
      x86/PCI: Fix PCI config space for domains > 0
      Fix acpi_pm_device_sleep_wake() by providing a stub for CONFIG_PM_SLEEP=n
      PCI: Simplify PCI device PM code
      PCI PM: Introduce pci_prepare_to_sleep and pci_back_from_sleep
      PCI ACPI: Rework PCI handling of wake-up
      ACPI: Introduce new device wakeup flag 'prepared'
      ACPI: Introduce acpi_device_sleep_wake function
      PCI: rework pci_set_power_state function to call platform first
      PCI: Introduce platform_pci_power_manageable function
      ACPI: Introduce acpi_bus_power_manageable function
      PCI: make pci_name use dev_name
      PCI: handle pci_name() being const
      PCI: add stub for pci_set_consistent_dma_mask()
      PCI: remove unused arch pcibios_update_resource() functions
      PCI: fix pci_setup_device()'s sprinting into a const buffer
      ...
    
    Fixed up conflicts in various files (arch/x86/kernel/setup_64.c,
    arch/x86/pci/irq.c, arch/x86/pci/pci.h, drivers/acpi/sleep/main.c,
    drivers/pci/pci.c, drivers/pci/pci.h, include/acpi/acpi_bus.h) from x86
    and ACPI updates manually.

commit c1f2f09ef66d5dadd5fe42ea909e708470c9636d
Author: Eduardo Habkost <ehabkost@redhat.com>
Date:   Tue Jul 8 15:06:24 2008 -0700

    pvops-64: call paravirt_post_allocator_init() on setup_arch()
    
    Signed-off-by: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 8ce6a91ce108..2ed504b97d47 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -822,6 +822,7 @@ void __init setup_arch(char **cmdline_p)
 	paravirt_pagetable_setup_start(swapper_pg_dir);
 	paging_init();
 	paravirt_pagetable_setup_done(swapper_pg_dir);
+	paravirt_post_allocator_init();
 
 #ifdef CONFIG_X86_64
 	map_vsyscall();

commit a312b37b2a212fd2e227d1d6321f903b91b65ec7
Author: Eduardo Habkost <ehabkost@redhat.com>
Date:   Tue Jul 8 15:06:23 2008 -0700

    x86/paravirt: call paravirt_pagetable_setup_{start, done}
    
    Call paravirt_pagetable_setup_{start,done}
    
    These paravirt_ops functions were not being called on x86_64.
    
    Signed-off-by: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 36c540d4ac4b..8ce6a91ce108 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -819,7 +819,9 @@ void __init setup_arch(char **cmdline_p)
 	vmi_init();
 #endif
 
+	paravirt_pagetable_setup_start(swapper_pg_dir);
 	paging_init();
+	paravirt_pagetable_setup_done(swapper_pg_dir);
 
 #ifdef CONFIG_X86_64
 	map_vsyscall();

commit 3d88cca7085cffce077f808f36551e9050eb9e3a
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sat Jul 12 22:52:55 2008 -0700

    x86: fix numaq_tsc_disable calling
    
    got this on a test-system:
    
     calling  numaq_tsc_disable+0x0/0x39
     NUMAQ: disabling TSC
     initcall numaq_tsc_disable+0x0/0x39 returned 0 after 0 msecs
    
    that's because we should not be using arch_initcall to call numaq_tsc_disable.
    
    need to call it in setup_arch before time_init()/tsc_init()
    and call it in init_intel() to make the cpu feature bits right.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 987b6fde3a99..36c540d4ac4b 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -849,6 +849,14 @@ void __init setup_arch(char **cmdline_p)
 	init_cpu_to_node();
 #endif
 
+#ifdef CONFIG_X86_NUMAQ
+	/*
+	 * need to check online nodes num, call it
+	 * here before time_init/tsc_init
+	 */
+	numaq_tsc_disable();
+#endif
+
 	init_apic_mappings();
 	ioapic_init_mappings();
 

commit 6e1cb38a2aef7680975e71f23de187859ee8b158
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu Jul 10 11:16:58 2008 -0700

    x64, x2apic/intr-remap: add x2apic support, including enabling interrupt-remapping
    
    x2apic support.  Interrupt-remapping must be enabled before enabling x2apic,
    this is needed to ensure that IO interrupts continue to work properly after the
    cpu mode is changed to x2apic(which uses 32bit extended physical/cluster
    apic id).
    
    On systems where apicid's are > 255, BIOS can handover the control to OS in
    x2apic mode. Or if the OS handover was in legacy xapic mode, check
    if it is capable of x2apic mode. And if we succeed in enabling
    Interrupt-remapping, then we can enable x2apic mode in the CPU.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: akpm@linux-foundation.org
    Cc: arjan@linux.intel.com
    Cc: andi@firstfloor.org
    Cc: ebiederm@xmission.com
    Cc: jbarnes@virtuousgeek.org
    Cc: steiner@sgi.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 987b6fde3a99..2e78a143dec3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -730,6 +730,8 @@ void __init setup_arch(char **cmdline_p)
 	num_physpages = max_pfn;
 
 	check_efer();
+ 	if (cpu_has_x2apic)
+ 		check_x2apic();
 
 	/* How many end-of-memory variables you have, grandma! */
 	/* need this before calling reserve_initrd */

commit 6c82a000a29b93541b5b7db597a083c069755cc9
Merge: 5b4d2386c23e 39415a440ecc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 11 21:22:18 2008 +0200

    Merge branch 'x86/generalize-visws' into x86/core

commit 46a7fa270afbe5fddc6042a598cfe22977b0e989
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 11 10:23:42 2008 +0900

    x86: make only GART code include gart.h
    
    gart.h has only GART-specific stuff. Only GART code needs it. Other
    IOMMU stuff should include iommu.h instead of gart.h.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 86fc2d624270..e5d208934bfc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -96,7 +96,7 @@
 #include <asm/smp.h>
 #include <asm/desc.h>
 #include <asm/dma.h>
-#include <asm/gart.h>
+#include <asm/iommu.h>
 #include <asm/mmu_context.h>
 #include <asm/proto.h>
 

commit f361a450bf1ad14e2b003217dbf3958638631265
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Thu Jul 10 20:38:26 2008 -0700

    x86: introduce max_low_pfn_mapped for 64-bit
    
    when more than 4g memory is installed, don't map the big hole below 4g.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a7c3471ea17c..86fc2d624270 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -713,14 +713,14 @@ void __init setup_arch(char **cmdline_p)
 	 * partially used pages are not usable - thus
 	 * we are rounding upwards:
 	 */
-	max_pfn = e820_end();
+	max_pfn = e820_end_of_ram_pfn();
 
 	/* preallocate 4k for mptable mpc */
 	early_reserve_e820_mpc_new();
 	/* update e820 for memory not covered by WB MTRRs */
 	mtrr_bp_init();
 	if (mtrr_trim_uncached_memory(max_pfn))
-		max_pfn = e820_end();
+		max_pfn = e820_end_of_ram_pfn();
 
 #ifdef CONFIG_X86_32
 	/* max_low_pfn get updated here */
@@ -732,12 +732,26 @@ void __init setup_arch(char **cmdline_p)
 
 	/* How many end-of-memory variables you have, grandma! */
 	/* need this before calling reserve_initrd */
-	max_low_pfn = max_pfn;
+	if (max_pfn > (1UL<<(32 - PAGE_SHIFT)))
+		max_low_pfn = e820_end_of_low_ram_pfn();
+	else
+		max_low_pfn = max_pfn;
+
 	high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
 #endif
 
 	/* max_pfn_mapped is updated here */
-	max_pfn_mapped = init_memory_mapping(0, (max_low_pfn << PAGE_SHIFT));
+	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
+	max_pfn_mapped = max_low_pfn_mapped;
+
+#ifdef CONFIG_X86_64
+	if (max_pfn > max_low_pfn) {
+		max_pfn_mapped = init_memory_mapping(1UL<<32,
+						     max_pfn<<PAGE_SHIFT);
+		/* can we preseve max_low_pfn ?*/
+		max_low_pfn = max_pfn;
+	}
+#endif
 
 	/*
 	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.

commit 3b33553badcde952adcf3b3ba5faae38d7d85071
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jul 10 17:30:40 2008 +0200

    x86: add early quirk support
    
    Add early quirks support.
    
    In preparation of enabling the generic architecture to boot on a VISWS.
    
    This will allow us to remove the VISWS subarch and all its complications.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index a7c3471ea17c..cb3db406247c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -596,6 +596,7 @@ void __init setup_arch(char **cmdline_p)
 {
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
+	visws_early_detect();
 	pre_setup_arch_hook();
 	early_cpu_init();
 #else

commit 2dc807b37b7b8c7df445513ad2b415df4ebcaf6d
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Jul 8 18:56:38 2008 -0700

    x86: make max_pfn cover acpi table below 4g
    
    When system have 4g less ram installed, and acpi table sit
    near end of ram, make max_pfn cover them too,
    so 64bit kernel don't need to mess up fixmap.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: "Suresh Siddha" <suresh.b.siddha@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bea8ae77d059..a7c3471ea17c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -709,22 +709,18 @@ void __init setup_arch(char **cmdline_p)
 	early_gart_iommu_check();
 #endif
 
-	e820_register_active_regions(0, 0, -1UL);
 	/*
 	 * partially used pages are not usable - thus
 	 * we are rounding upwards:
 	 */
-	max_pfn = e820_end_of_ram();
+	max_pfn = e820_end();
 
 	/* preallocate 4k for mptable mpc */
 	early_reserve_e820_mpc_new();
 	/* update e820 for memory not covered by WB MTRRs */
 	mtrr_bp_init();
-	if (mtrr_trim_uncached_memory(max_pfn)) {
-		remove_all_active_ranges();
-		e820_register_active_regions(0, 0, -1UL);
-		max_pfn = e820_end_of_ram();
-	}
+	if (mtrr_trim_uncached_memory(max_pfn))
+		max_pfn = e820_end();
 
 #ifdef CONFIG_X86_32
 	/* max_low_pfn get updated here */
@@ -767,9 +763,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_table_init();
 
-	/* Remove active ranges so rediscovery with NUMA-awareness happens */
-	remove_all_active_ranges();
-
 #ifdef CONFIG_ACPI_NUMA
 	/*
 	 * Parse SRAT to discover nodes.

commit a0a0becd2da0ba0d7f0204a61d1905926cdb163d
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Thu Jul 3 11:37:13 2008 -0700

    x86: make e820_saved have update from setup_data
    
    seperate reserve_setup_data into e820_reserved_setup_data,
    and reserve_early_setup_data.
    
    So could use e820_reserved_setup_data to backup e820 with setup_data.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: Bernhard Walle <bwalle@suse.de>
    Cc: Ying Huang <ying.huang@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cfcfbefee0b9..bea8ae77d059 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -394,11 +394,10 @@ static void __init parse_setup_data(void)
 	}
 }
 
-static void __init reserve_setup_data(void)
+static void __init e820_reserve_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
-	char buf[32];
 	int found = 0;
 
 	if (boot_params.hdr.version < 0x0209)
@@ -406,8 +405,6 @@ static void __init reserve_setup_data(void)
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
 		data = early_ioremap(pa_data, sizeof(*data));
-		sprintf(buf, "setup data %x", data->type);
-		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
 		e820_update_range(pa_data, sizeof(*data)+data->len,
 			 E820_RAM, E820_RESERVED_KERN);
 		found = 1;
@@ -418,10 +415,29 @@ static void __init reserve_setup_data(void)
 		return;
 
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+	memcpy(&e820_saved, &e820, sizeof(struct e820map));
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");
 }
 
+static void __init reserve_early_setup_data(void)
+{
+	struct setup_data *data;
+	u64 pa_data;
+	char buf[32];
+
+	if (boot_params.hdr.version < 0x0209)
+		return;
+	pa_data = boot_params.hdr.setup_data;
+	while (pa_data) {
+		data = early_ioremap(pa_data, sizeof(*data));
+		sprintf(buf, "setup data %x", data->type);
+		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
+		pa_data = data->next;
+		early_iounmap(data, sizeof(*data));
+	}
+}
+
 /*
  * --------- Crashkernel reservation ------------------------------
  */
@@ -626,6 +642,8 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_memory_map();
 	parse_setup_data();
+	/* update the e820_saved too */
+	e820_reserve_setup_data();
 
 	copy_edd();
 
@@ -656,7 +674,7 @@ void __init setup_arch(char **cmdline_p)
 	parse_early_param();
 
 	/* after early param, so could get panic from serial */
-	reserve_setup_data();
+	reserve_early_setup_data();
 
 	if (acpi_mps_check()) {
 #ifdef CONFIG_X86_LOCAL_APIC

commit 329513a35d1a2b6b28d54f5c2c0dde4face8200b
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jul 2 18:54:40 2008 -0700

    x86: move prefill_possible_map calling early
    
    call it right after we are done with MADT/mptable handling, instead of
    doing that in setup_per_cpu_areas() later on...
    
    this way for_possible_cpu() can be used early.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f52a6fb90238..cfcfbefee0b9 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -818,6 +818,7 @@ void __init setup_arch(char **cmdline_p)
 		get_smp_config();
 #endif
 
+	prefill_possible_map();
 #ifdef CONFIG_X86_64
 	init_cpu_to_node();
 #endif

commit 5f4765f96eebee6a0adc4009758b597ba48a0a3a
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jul 2 18:53:44 2008 -0700

    x86: move init_cpu_to_node after get_smp_config
    
    when acpi=off, cpu_to_apicid is ready after get_smp_config
    so need to move init_cpu_to_node after it.
    
    otherwise, we will get wrong cpu->node mapping, and it will rely on
    amd_detect_cmp() to correct it - but that is too late as
    setup_per_cpu_data is already called before that so  we will get
    per_cpu_data on the wrong node.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index d5de157b02ae..f52a6fb90238 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -810,10 +810,6 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_init();
 
-#ifdef CONFIG_X86_64
-	init_cpu_to_node();
-#endif
-
 #if defined(CONFIG_X86_MPPARSE) || defined(CONFIG_X86_VISWS)
 	/*
 	 * get boot-time SMP configuration:
@@ -822,6 +818,10 @@ void __init setup_arch(char **cmdline_p)
 		get_smp_config();
 #endif
 
+#ifdef CONFIG_X86_64
+	init_cpu_to_node();
+#endif
+
 	init_apic_mappings();
 	ioapic_init_mappings();
 

commit cb95a13a8ace8612ecab042a838e5aab2ec14ef0
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jul 2 00:31:02 2008 -0700

    x86: merge zones_sizes_init for numa and non numa on 32-bit
    
    move out e820_register_active_regions from non numa zones_sizes_init()
    and remove numa version zones_sizes_init().
    
    and let 32 bit call remove_all_active_ranges() in setup_arch() directly
    like 64-bit
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4ac01d0ce624..d5de157b02ae 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -749,10 +749,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_table_init();
 
-#ifdef CONFIG_X86_64
 	/* Remove active ranges so rediscovery with NUMA-awareness happens */
 	remove_all_active_ranges();
-#endif
 
 #ifdef CONFIG_ACPI_NUMA
 	/*

commit d9a81b4411d53196c4535c3a1258cb03d945c718
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Jul 1 20:04:10 2008 -0700

    x86: do not printout if we do not find setup_data
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b3469898717e..4ac01d0ce624 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -399,6 +399,7 @@ static void __init reserve_setup_data(void)
 	struct setup_data *data;
 	u64 pa_data;
 	char buf[32];
+	int found = 0;
 
 	if (boot_params.hdr.version < 0x0209)
 		return;
@@ -409,9 +410,13 @@ static void __init reserve_setup_data(void)
 		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
 		e820_update_range(pa_data, sizeof(*data)+data->len,
 			 E820_RAM, E820_RESERVED_KERN);
+		found = 1;
 		pa_data = data->next;
 		early_iounmap(data, sizeof(*data));
 	}
+	if (!found)
+		return;
+
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 	printk(KERN_INFO "extended physical RAM map:\n");
 	e820_print_map("reserve setup_data");

commit 32105f7fd8faa7bc3d101dcc3eabc0ae1ac375a7
Author: Bernhard Walle <bwalle@suse.de>
Date:   Thu Jun 26 21:54:08 2008 +0200

    x86: find offset for crashkernel reservation automatically
    
    This patch removes the need of the crashkernel=...@offset parameter to define
    a fixed offset for crashkernel reservation. That feature can be used together
    with a relocatable kernel where the kexec-tools relocate the kernel and
    get the actual offset from /proc/iomem.
    
    The use case is a kernel where the .text+.data+.bss is after 16M physical
    memory (debug kernel with lockdep on x86_64 can cause that) which caused a
    major pain in autoconfiguration in our distribution.
    
    Also, that patch unifies crashdump architectures a bit since IA64 has
    that semantics from the very beginning of the kdump port.
    
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: vgoyal@redhat.com
    Cc: Bernhard Walle <bwalle@suse.de>
    Cc: kexec@lists.infradead.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 2ca12d4c88fb..b3469898717e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -422,6 +422,34 @@ static void __init reserve_setup_data(void)
  */
 
 #ifdef CONFIG_KEXEC
+
+/**
+ * Reserve @size bytes of crashkernel memory at any suitable offset.
+ *
+ * @size: Size of the crashkernel memory to reserve.
+ * Returns the base address on success, and -1ULL on failure.
+ */
+unsigned long long find_and_reserve_crashkernel(unsigned long long size)
+{
+	const unsigned long long alignment = 16<<20; 	/* 16M */
+	unsigned long long start = 0LL;
+
+	while (1) {
+		int ret;
+
+		start = find_e820_area(start, ULONG_MAX, size, alignment);
+		if (start == -1ULL)
+			return start;
+
+		/* try to reserve it */
+		ret = reserve_bootmem_generic(start, size, BOOTMEM_EXCLUSIVE);
+		if (ret >= 0)
+			return start;
+
+		start += alignment;
+	}
+}
+
 static inline unsigned long long get_total_mem(void)
 {
 	unsigned long long total;
@@ -444,30 +472,36 @@ static void __init reserve_crashkernel(void)
 
 	ret = parse_crashkernel(boot_command_line, total_mem,
 			&crash_size, &crash_base);
-	if (ret == 0 && crash_size > 0) {
-		if (crash_base <= 0) {
-			printk(KERN_INFO "crashkernel reservation failed - "
-					"you have to specify a base address\n");
+	if (ret != 0 || crash_size <= 0)
+		return;
+
+	/* 0 means: find the address automatically */
+	if (crash_base <= 0) {
+		crash_base = find_and_reserve_crashkernel(crash_size);
+		if (crash_base == -1ULL) {
+			pr_info("crashkernel reservation failed. "
+				"No suitable area found.\n");
 			return;
 		}
-
-		if (reserve_bootmem_generic(crash_base, crash_size,
-					BOOTMEM_EXCLUSIVE) < 0) {
-			printk(KERN_INFO "crashkernel reservation failed - "
-					"memory is in use\n");
+	} else {
+		ret = reserve_bootmem_generic(crash_base, crash_size,
+					BOOTMEM_EXCLUSIVE);
+		if (ret < 0) {
+			pr_info("crashkernel reservation failed - "
+				"memory is in use\n");
 			return;
 		}
+	}
 
-		printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
-				"for crashkernel (System RAM: %ldMB)\n",
-				(unsigned long)(crash_size >> 20),
-				(unsigned long)(crash_base >> 20),
-				(unsigned long)(total_mem >> 20));
+	printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
+			"for crashkernel (System RAM: %ldMB)\n",
+			(unsigned long)(crash_size >> 20),
+			(unsigned long)(crash_base >> 20),
+			(unsigned long)(total_mem >> 20));
 
-		crashk_res.start = crash_base;
-		crashk_res.end   = crash_base + crash_size - 1;
-		insert_resource(&iomem_resource, &crashk_res);
-	}
+	crashk_res.start = crash_base;
+	crashk_res.end   = crash_base + crash_size - 1;
+	insert_resource(&iomem_resource, &crashk_res);
 }
 #else
 static void __init reserve_crashkernel(void)

commit 28bb22379513ca3cac9d13766064a219c5fc21a9
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Mon Jun 30 16:20:54 2008 -0700

    x86: move reserve_setup_data to setup.c
    
    Ying Huang would like setup_data to be reserved, but not included in the
    no save range.
    
    Here we try to modify the e820 table to reserve that range early.
    also add that in early_res in case bootloader messes up with the ramdisk.
    
    other solution would be
    1. add early_res_to_highmem...
    2. early_res_to_e820...
    but they could reserve another type memory wrongly, if early_res has some
    resource reserved early, and not needed later, but it is not removed from
    early_res in time. Like the RAMDISK (already handled).
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: andi@firstfloor.org
    Tested-by: Huang, Ying <ying.huang@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index caec79fb83a3..2ca12d4c88fb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -389,14 +389,34 @@ static void __init parse_setup_data(void)
 		default:
 			break;
 		}
-#ifndef CONFIG_DEBUG_BOOT_PARAMS
-		free_early(pa_data, pa_data+sizeof(*data)+data->len);
-#endif
 		pa_data = data->next;
 		early_iounmap(data, PAGE_SIZE);
 	}
 }
 
+static void __init reserve_setup_data(void)
+{
+	struct setup_data *data;
+	u64 pa_data;
+	char buf[32];
+
+	if (boot_params.hdr.version < 0x0209)
+		return;
+	pa_data = boot_params.hdr.setup_data;
+	while (pa_data) {
+		data = early_ioremap(pa_data, sizeof(*data));
+		sprintf(buf, "setup data %x", data->type);
+		reserve_early(pa_data, pa_data+sizeof(*data)+data->len, buf);
+		e820_update_range(pa_data, sizeof(*data)+data->len,
+			 E820_RAM, E820_RESERVED_KERN);
+		pa_data = data->next;
+		early_iounmap(data, sizeof(*data));
+	}
+	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+	printk(KERN_INFO "extended physical RAM map:\n");
+	e820_print_map("reserve setup_data");
+}
+
 /*
  * --------- Crashkernel reservation ------------------------------
  */
@@ -523,7 +543,6 @@ void __init setup_arch(char **cmdline_p)
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	pre_setup_arch_hook();
 	early_cpu_init();
-	reserve_setup_data();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
@@ -567,6 +586,8 @@ void __init setup_arch(char **cmdline_p)
 	ARCH_SETUP
 
 	setup_memory_map();
+	parse_setup_data();
+
 	copy_edd();
 
 	if (!boot_params.hdr.root_flags)
@@ -593,10 +614,11 @@ void __init setup_arch(char **cmdline_p)
 	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
 	*cmdline_p = command_line;
 
-	parse_setup_data();
-
 	parse_early_param();
 
+	/* after early param, so could get panic from serial */
+	reserve_setup_data();
+
 	if (acpi_mps_check()) {
 #ifdef CONFIG_X86_LOCAL_APIC
 		disable_apic = 1;

commit 1a98fd14f44cfade4af3e6ed96ba55065fa17ee4
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Sun Jun 29 20:02:44 2008 -0700

    x86: setup_arch() && early_ioremap_init()
    
    Looks like the setup.c unification missed the early_ioremap init from
    the early_ioremap unification.  Unconditionally call early_ioremap_init().
    
    needed for "x86/paravirt: groundwork for 64-bit Xen support".
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Nick Piggin <npiggin@suse.de>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Cc: xen-devel <xen-devel@lists.xensource.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Vegard Nossum <vegard.nossum@gmail.com>
    Cc: Stephen Tweedie <sct@redhat.com>
    Cc: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index fb318edd8bc6..caec79fb83a3 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -523,12 +523,13 @@ void __init setup_arch(char **cmdline_p)
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	pre_setup_arch_hook();
 	early_cpu_init();
-	early_ioremap_init();
 	reserve_setup_data();
 #else
 	printk(KERN_INFO "Command line: %s\n", boot_command_line);
 #endif
 
+	early_ioremap_init();
+
 	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
 	screen_info = boot_params.screen_info;
 	edid_info = boot_params.edid_info;

commit 914bebfad42c417b84bda8920a3073d236007fde
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sun Jun 29 00:06:37 2008 -0700

    x86: use disable_apic in 32bit
    
    change the enable_local_apic to static force_enable_local_apic for 32bit
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4716460607b4..fb318edd8bc6 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -598,11 +598,7 @@ void __init setup_arch(char **cmdline_p)
 
 	if (acpi_mps_check()) {
 #ifdef CONFIG_X86_LOCAL_APIC
-#ifdef CONFIG_X86_32
-		enable_local_apic = -1;
-#else
 		disable_apic = 1;
-#endif
 #endif
 		clear_cpu_cap(&boot_cpu_data, X86_FEATURE_APIC);
 	}

commit f3294a33e765d8308c3e17b951a13e0db9cf5f00
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Fri Jun 27 01:41:56 2008 -0700

    x86: let setup_arch call init_apic_mappings for 32bit
    
    instead of calling it from trap_init()
    
    also move init ioapic mapping out of apic_32.c
    
    so 32 bit do same as 64 bit
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index bf528b23750a..4716460607b4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -766,16 +766,14 @@ void __init setup_arch(char **cmdline_p)
 		get_smp_config();
 #endif
 
-#ifdef CONFIG_X86_64
 	init_apic_mappings();
 	ioapic_init_mappings();
-#else
-# if defined(CONFIG_SMP) && defined(CONFIG_X86_PC)
+
+#if defined(CONFIG_SMP) && defined(CONFIG_X86_PC) && defined(CONFIG_X86_32)
 	if (def_to_bigsmp)
 		printk(KERN_WARNING "More than 8 CPUs detected and "
 			"CONFIG_X86_PC cannot handle it.\nUse "
 			"CONFIG_X86_GENERICARCH or CONFIG_X86_BIGSMP.\n");
-# endif
 #endif
 	kvm_guest_init();
 

commit e7b3789524eecc96213dd69d6686efd429235051
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 21:51:28 2008 -0700

    x86: move fix mapping page table range early
    
    do that in init_memory_mapping
    
    also remove one init_ohci1394_dma_on_all_controllers
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 161609c6925e..bf528b23750a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -611,11 +611,6 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_X86_32
 	probe_roms();
-#else
-# ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
-	if (init_ohci1394_dma_early)
-		init_ohci1394_dma_on_all_controllers();
-# endif
 #endif
 
 	/* after parse_early_param, so could debug it */
@@ -672,6 +667,15 @@ void __init setup_arch(char **cmdline_p)
 	/* max_pfn_mapped is updated here */
 	max_pfn_mapped = init_memory_mapping(0, (max_low_pfn << PAGE_SHIFT));
 
+	/*
+	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.
+	 */
+
+#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
+	if (init_ohci1394_dma_early)
+		init_ohci1394_dma_on_all_controllers();
+#endif
+
 	reserve_initrd();
 
 #ifdef CONFIG_X86_64
@@ -739,15 +743,6 @@ void __init setup_arch(char **cmdline_p)
 	map_vsyscall();
 #endif
 
-	/*
-	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.
-	 */
-
-#if defined(CONFIG_PROVIDE_OHCI1394_DMA_INIT) && defined(CONFIG_X86_32)
-	if (init_ohci1394_dma_early)
-		init_ohci1394_dma_on_all_controllers();
-#endif
-
 #ifdef CONFIG_X86_GENERICARCH
 	generic_apic_probe();
 #endif

commit 042623bbabae168246ad8a37693f0ecb6c450aea
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 19:52:15 2008 -0700

    x86: clean up ARCH_SETUP
    
    asm-x86/paravirt.h already have protection with CONFIG_PARAVIRT inside
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 63dbb5e8f7ee..161609c6925e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -101,11 +101,7 @@
 #include <asm/proto.h>
 
 #include <mach_apic.h>
-#ifdef CONFIG_PARAVIRT
 #include <asm/paravirt.h>
-#else
-#define ARCH_SETUP
-#endif
 
 #include <asm/percpu.h>
 #include <asm/sections.h>
@@ -115,6 +111,10 @@
 #include <asm/numa_64.h>
 #endif
 
+#ifndef ARCH_SETUP
+#define ARCH_SETUP
+#endif
+
 #ifndef CONFIG_DEBUG_BOOT_PARAMS
 struct boot_params __initdata boot_params;
 #else

commit 330ddd20894f99a2b956ad59cf0cfdba188bde63
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 26 12:40:35 2008 +0200

    x86: build fix
    
    fix:
    
    In file included from arch/x86/kernel/setup.c:118:
    include/asm/highmem.h:64: error: expected identifier or ‚Äò(' before ‚Äòdo'
    include/asm/highmem.h:64: error: expected identifier or ‚Äò(' before ‚Äòwhile'
    include/asm/highmem.h:67: error: expected identifier or ‚Äò(' before ‚Äòdo'
    include/asm/highmem.h:67: error: expected identifier or ‚Äò(' before ‚Äòwhile'
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 172a83e57ee7..63dbb5e8f7ee 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -114,9 +114,6 @@
 #ifdef CONFIG_X86_64
 #include <asm/numa_64.h>
 #endif
-#ifdef CONFIG_X86_32
-#include <asm/highmem.h>
-#endif
 
 #ifndef CONFIG_DEBUG_BOOT_PARAMS
 struct boot_params __initdata boot_params;

commit 3442682a54a9f44047efe526869aa52bd74fe16e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 26 12:29:29 2008 +0200

    x86: remove extra newline from setup.c
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f2e314b5b5fa..172a83e57ee7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -806,4 +806,3 @@ void __init setup_arch(char **cmdline_p)
 #endif
 #endif
 }
-

commit 5092301c7250d7459b79fe40dae43eca3b518e92
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 18:02:06 2008 -0700

    x86: we only have init_pg_tables_end for 32bit
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 35022dc10428..f2e314b5b5fa 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -124,12 +124,6 @@ struct boot_params __initdata boot_params;
 struct boot_params boot_params;
 #endif
 
-/* This value is set up by the early boot code to point to the value
-   immediately after the boot time page tables.  It contains a *physical*
-   address, and must not be in the .bss segment! */
-unsigned long init_pg_tables_start __initdata = ~0UL;
-unsigned long init_pg_tables_end __initdata = ~0UL;
-
 /*
  * Machine setup..
  */
@@ -156,6 +150,12 @@ static struct resource bss_resource = {
 
 
 #ifdef CONFIG_X86_32
+/* This value is set up by the early boot code to point to the value
+   immediately after the boot time page tables.  It contains a *physical*
+   address, and must not be in the .bss segment! */
+unsigned long init_pg_tables_start __initdata = ~0UL;
+unsigned long init_pg_tables_end __initdata = ~0UL;
+
 static struct resource video_ram_resource = {
 	.name	= "Video RAM area",
 	.start	= 0xa0000,

commit 29f784e369a914b5926e01a0b0caae0b47f6452a
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 18:00:22 2008 -0700

    x86: change some functions in setup.c to static
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 7690547ac285..35022dc10428 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -375,7 +375,7 @@ static void __init reserve_initrd(void)
 }
 #endif /* CONFIG_BLK_DEV_INITRD */
 
-void __init parse_setup_data(void)
+static void __init parse_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
@@ -417,7 +417,7 @@ static inline unsigned long long get_total_mem(void)
 	return total << PAGE_SHIFT;
 }
 
-void __init reserve_crashkernel(void)
+static void __init reserve_crashkernel(void)
 {
 	unsigned long long total_mem;
 	unsigned long long crash_size, crash_base;
@@ -453,7 +453,7 @@ void __init reserve_crashkernel(void)
 	}
 }
 #else
-void __init reserve_crashkernel(void)
+static void __init reserve_crashkernel(void)
 {
 }
 #endif
@@ -481,7 +481,7 @@ static struct resource standard_io_resources[] = {
 		.flags = IORESOURCE_BUSY | IORESOURCE_IO }
 };
 
-void __init reserve_standard_io_resources(void)
+static void __init reserve_standard_io_resources(void)
 {
 	int i;
 

commit d1b20afec356085a202d7832d47bfb89303ea901
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:59:41 2008 -0700

    x86: make x86_find_smp_config depends on 64 bit too
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 08efab538a24..7690547ac285 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -714,8 +714,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_reserve_bootmem();
 #endif
-#if defined(CONFIG_X86_FIND_SMP_CONFIG) && defined(CONFIG_X86_32) || \
-    defined(CONFIG_X86_MPPARSE) && defined(CONFIG_X86_64)
+#ifdef CONFIG_X86_FIND_SMP_CONFIG
 	/*
 	 * Find and reserve possible boot-time SMP configuration:
 	 */

commit 0196bcbb150786d54a50e3074013020570a59d31
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:58:55 2008 -0700

    x86: move parse elfvorehdr back to setup.c
    
    Signed-off-by: Yinghai <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 62647b04fab5..08efab538a24 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -491,6 +491,22 @@ void __init reserve_standard_io_resources(void)
 
 }
 
+#ifdef CONFIG_PROC_VMCORE
+/* elfcorehdr= specifies the location of elf core header
+ * stored by the crashed kernel. This option will be passed
+ * by kexec loader to the capture kernel.
+ */
+static int __init setup_elfcorehdr(char *arg)
+{
+	char *end;
+	if (!arg)
+		return -EINVAL;
+	elfcorehdr_addr = memparse(arg, &end);
+	return end > arg ? 0 : -EINVAL;
+}
+early_param("elfcorehdr", setup_elfcorehdr);
+#endif
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit bdba0e700c86fa2f152b1fe37b001c9e9c65d2b7
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:58:02 2008 -0700

    x86: move reserve_standard_io_resources back to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 75d35401a8c7..62647b04fab5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -458,6 +458,39 @@ void __init reserve_crashkernel(void)
 }
 #endif
 
+static struct resource standard_io_resources[] = {
+	{ .name = "dma1", .start = 0x00, .end = 0x1f,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "pic1", .start = 0x20, .end = 0x21,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "timer0", .start = 0x40, .end = 0x43,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "timer1", .start = 0x50, .end = 0x53,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "keyboard", .start = 0x60, .end = 0x60,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "keyboard", .start = 0x64, .end = 0x64,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "dma page reg", .start = 0x80, .end = 0x8f,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "pic2", .start = 0xa0, .end = 0xa1,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "dma2", .start = 0xc0, .end = 0xdf,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "fpu", .start = 0xf0, .end = 0xff,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO }
+};
+
+void __init reserve_standard_io_resources(void)
+{
+	int i;
+
+	/* request I/O space for devices used on all i[345]86 PCs */
+	for (i = 0; i < ARRAY_SIZE(standard_io_resources); i++)
+		request_resource(&ioport_resource, &standard_io_resources[i]);
+
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit ccb4defa71744f086822950d8fa64a17c4e6eb04
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:57:13 2008 -0700

    x86: move back crashkernel back to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 4b00c8347bb7..75d35401a8c7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -400,6 +400,64 @@ void __init parse_setup_data(void)
 	}
 }
 
+/*
+ * --------- Crashkernel reservation ------------------------------
+ */
+
+#ifdef CONFIG_KEXEC
+static inline unsigned long long get_total_mem(void)
+{
+	unsigned long long total;
+
+	total = max_low_pfn - min_low_pfn;
+#ifdef CONFIG_HIGHMEM
+	total += highend_pfn - highstart_pfn;
+#endif
+
+	return total << PAGE_SHIFT;
+}
+
+void __init reserve_crashkernel(void)
+{
+	unsigned long long total_mem;
+	unsigned long long crash_size, crash_base;
+	int ret;
+
+	total_mem = get_total_mem();
+
+	ret = parse_crashkernel(boot_command_line, total_mem,
+			&crash_size, &crash_base);
+	if (ret == 0 && crash_size > 0) {
+		if (crash_base <= 0) {
+			printk(KERN_INFO "crashkernel reservation failed - "
+					"you have to specify a base address\n");
+			return;
+		}
+
+		if (reserve_bootmem_generic(crash_base, crash_size,
+					BOOTMEM_EXCLUSIVE) < 0) {
+			printk(KERN_INFO "crashkernel reservation failed - "
+					"memory is in use\n");
+			return;
+		}
+
+		printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
+				"for crashkernel (System RAM: %ldMB)\n",
+				(unsigned long)(crash_size >> 20),
+				(unsigned long)(crash_base >> 20),
+				(unsigned long)(total_mem >> 20));
+
+		crashk_res.start = crash_base;
+		crashk_res.end   = crash_base + crash_size - 1;
+		insert_resource(&iomem_resource, &crashk_res);
+	}
+}
+#else
+void __init reserve_crashkernel(void)
+{
+}
+#endif
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit 257b0fde99df0160db03e529dbfb3a4e46c07a88
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:56:22 2008 -0700

    x86: move parse_setup_data back to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index f24a8fe8a7e4..4b00c8347bb7 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -375,6 +375,31 @@ static void __init reserve_initrd(void)
 }
 #endif /* CONFIG_BLK_DEV_INITRD */
 
+void __init parse_setup_data(void)
+{
+	struct setup_data *data;
+	u64 pa_data;
+
+	if (boot_params.hdr.version < 0x0209)
+		return;
+	pa_data = boot_params.hdr.setup_data;
+	while (pa_data) {
+		data = early_ioremap(pa_data, PAGE_SIZE);
+		switch (data->type) {
+		case SETUP_E820_EXT:
+			parse_e820_ext(data, pa_data);
+			break;
+		default:
+			break;
+		}
+#ifndef CONFIG_DEBUG_BOOT_PARAMS
+		free_early(pa_data, pa_data+sizeof(*data)+data->len);
+#endif
+		pa_data = data->next;
+		early_iounmap(data, PAGE_SIZE);
+	}
+}
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures

commit 217b8ce89088dd47e7176686ff34573f75a624e9
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:55:20 2008 -0700

    x86: move boot_params back to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 222d7038f2fd..f24a8fe8a7e4 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -118,6 +118,12 @@
 #include <asm/highmem.h>
 #endif
 
+#ifndef CONFIG_DEBUG_BOOT_PARAMS
+struct boot_params __initdata boot_params;
+#else
+struct boot_params boot_params;
+#endif
+
 /* This value is set up by the early boot code to point to the value
    immediately after the boot time page tables.  It contains a *physical*
    address, and must not be in the .bss segment! */

commit 55f262391a2365d657a00ed68edd1a51bca66af5
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:54:23 2008 -0700

    x86: rename setup_32.c to setup.c
    
    and let 64 bit use that instead of setup_64.c
    
    [ mingo@elte.hu ]
    
    x86: build fix
    
    fix:
    
    arch/x86/kernel/setup.c: In function ‚Äòsetup_arch':
    arch/x86/kernel/setup.c:561: error: implicit declaration of function ‚Äòefi_reserve_early'
    
    and:
    
    arch/x86/kernel/setup.c:766: error: implicit declaration of function 'init_cpu_to_node'
    
    and:
    
    arch/x86/kernel/setup.c:676: warning: operation on 'max_pfn_mapped' may be undefined
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
new file mode 100644
index 000000000000..222d7038f2fd
--- /dev/null
+++ b/arch/x86/kernel/setup.c
@@ -0,0 +1,672 @@
+/*
+ *  Copyright (C) 1995  Linus Torvalds
+ *
+ *  Support of BIGMEM added by Gerhard Wichert, Siemens AG, July 1999
+ *
+ *  Memory region support
+ *	David Parsons <orc@pell.chi.il.us>, July-August 1999
+ *
+ *  Added E820 sanitization routine (removes overlapping memory regions);
+ *  Brian Moyle <bmoyle@mvista.com>, February 2001
+ *
+ * Moved CPU detection code to cpu/${cpu}.c
+ *    Patrick Mochel <mochel@osdl.org>, March 2002
+ *
+ *  Provisions for empty E820 memory regions (reported by certain BIOSes).
+ *  Alex Achenbach <xela@slit.de>, December 2002.
+ *
+ */
+
+/*
+ * This file handles the architecture-dependent parts of initialization
+ */
+
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/mmzone.h>
+#include <linux/screen_info.h>
+#include <linux/ioport.h>
+#include <linux/acpi.h>
+#include <linux/apm_bios.h>
+#include <linux/initrd.h>
+#include <linux/bootmem.h>
+#include <linux/seq_file.h>
+#include <linux/console.h>
+#include <linux/mca.h>
+#include <linux/root_dev.h>
+#include <linux/highmem.h>
+#include <linux/module.h>
+#include <linux/efi.h>
+#include <linux/init.h>
+#include <linux/edd.h>
+#include <linux/iscsi_ibft.h>
+#include <linux/nodemask.h>
+#include <linux/kexec.h>
+#include <linux/dmi.h>
+#include <linux/pfn.h>
+#include <linux/pci.h>
+#include <asm/pci-direct.h>
+#include <linux/init_ohci1394_dma.h>
+#include <linux/kvm_para.h>
+
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/stddef.h>
+#include <linux/unistd.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/user.h>
+#include <linux/delay.h>
+#include <linux/highmem.h>
+
+#include <linux/kallsyms.h>
+#include <linux/edd.h>
+#include <linux/iscsi_ibft.h>
+#include <linux/kexec.h>
+#include <linux/cpufreq.h>
+#include <linux/dma-mapping.h>
+#include <linux/ctype.h>
+#include <linux/uaccess.h>
+
+#include <linux/percpu.h>
+#include <linux/crash_dump.h>
+
+#include <video/edid.h>
+
+#include <asm/mtrr.h>
+#include <asm/apic.h>
+#include <asm/e820.h>
+#include <asm/mpspec.h>
+#include <asm/setup.h>
+#include <asm/arch_hooks.h>
+#include <asm/efi.h>
+#include <asm/sections.h>
+#include <asm/dmi.h>
+#include <asm/io_apic.h>
+#include <asm/ist.h>
+#include <asm/vmi.h>
+#include <setup_arch.h>
+#include <asm/bios_ebda.h>
+#include <asm/cacheflush.h>
+#include <asm/processor.h>
+#include <asm/bugs.h>
+
+#include <asm/system.h>
+#include <asm/vsyscall.h>
+#include <asm/smp.h>
+#include <asm/desc.h>
+#include <asm/dma.h>
+#include <asm/gart.h>
+#include <asm/mmu_context.h>
+#include <asm/proto.h>
+
+#include <mach_apic.h>
+#ifdef CONFIG_PARAVIRT
+#include <asm/paravirt.h>
+#else
+#define ARCH_SETUP
+#endif
+
+#include <asm/percpu.h>
+#include <asm/sections.h>
+#include <asm/topology.h>
+#include <asm/apicdef.h>
+#ifdef CONFIG_X86_64
+#include <asm/numa_64.h>
+#endif
+#ifdef CONFIG_X86_32
+#include <asm/highmem.h>
+#endif
+
+/* This value is set up by the early boot code to point to the value
+   immediately after the boot time page tables.  It contains a *physical*
+   address, and must not be in the .bss segment! */
+unsigned long init_pg_tables_start __initdata = ~0UL;
+unsigned long init_pg_tables_end __initdata = ~0UL;
+
+/*
+ * Machine setup..
+ */
+static struct resource data_resource = {
+	.name	= "Kernel data",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+};
+
+static struct resource code_resource = {
+	.name	= "Kernel code",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+};
+
+static struct resource bss_resource = {
+	.name	= "Kernel bss",
+	.start	= 0,
+	.end	= 0,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+};
+
+
+#ifdef CONFIG_X86_32
+static struct resource video_ram_resource = {
+	.name	= "Video RAM area",
+	.start	= 0xa0000,
+	.end	= 0xbffff,
+	.flags	= IORESOURCE_BUSY | IORESOURCE_MEM
+};
+
+/* cpu data as detected by the assembly code in head.S */
+struct cpuinfo_x86 new_cpu_data __cpuinitdata = {0, 0, 0, 0, -1, 1, 0, 0, -1};
+/* common cpu data for all cpus */
+struct cpuinfo_x86 boot_cpu_data __read_mostly = {0, 0, 0, 0, -1, 1, 0, 0, -1};
+EXPORT_SYMBOL(boot_cpu_data);
+static void set_mca_bus(int x)
+{
+#ifdef CONFIG_MCA
+	MCA_bus = x;
+#endif
+}
+
+unsigned int def_to_bigsmp;
+
+/* for MCA, but anyone else can use it if they want */
+unsigned int machine_id;
+unsigned int machine_submodel_id;
+unsigned int BIOS_revision;
+
+struct apm_info apm_info;
+EXPORT_SYMBOL(apm_info);
+
+#if defined(CONFIG_X86_SPEEDSTEP_SMI) || \
+	defined(CONFIG_X86_SPEEDSTEP_SMI_MODULE)
+struct ist_info ist_info;
+EXPORT_SYMBOL(ist_info);
+#else
+struct ist_info ist_info;
+#endif
+
+#else
+struct cpuinfo_x86 boot_cpu_data __read_mostly;
+EXPORT_SYMBOL(boot_cpu_data);
+#endif
+
+
+#if !defined(CONFIG_X86_PAE) || defined(CONFIG_X86_64)
+unsigned long mmu_cr4_features;
+#else
+unsigned long mmu_cr4_features = X86_CR4_PAE;
+#endif
+
+/* Boot loader ID as an integer, for the benefit of proc_dointvec */
+int bootloader_type;
+
+/*
+ * Early DMI memory
+ */
+int dmi_alloc_index;
+char dmi_alloc_data[DMI_MAX_DATA];
+
+/*
+ * Setup options
+ */
+struct screen_info screen_info;
+EXPORT_SYMBOL(screen_info);
+struct edid_info edid_info;
+EXPORT_SYMBOL_GPL(edid_info);
+
+extern int root_mountflags;
+
+unsigned long saved_video_mode;
+
+#define RAMDISK_IMAGE_START_MASK	0x07FF
+#define RAMDISK_PROMPT_FLAG		0x8000
+#define RAMDISK_LOAD_FLAG		0x4000
+
+static char __initdata command_line[COMMAND_LINE_SIZE];
+
+#if defined(CONFIG_EDD) || defined(CONFIG_EDD_MODULE)
+struct edd edd;
+#ifdef CONFIG_EDD_MODULE
+EXPORT_SYMBOL(edd);
+#endif
+/**
+ * copy_edd() - Copy the BIOS EDD information
+ *              from boot_params into a safe place.
+ *
+ */
+static inline void copy_edd(void)
+{
+     memcpy(edd.mbr_signature, boot_params.edd_mbr_sig_buffer,
+	    sizeof(edd.mbr_signature));
+     memcpy(edd.edd_info, boot_params.eddbuf, sizeof(edd.edd_info));
+     edd.mbr_signature_nr = boot_params.edd_mbr_sig_buf_entries;
+     edd.edd_info_nr = boot_params.eddbuf_entries;
+}
+#else
+static inline void copy_edd(void)
+{
+}
+#endif
+
+#ifdef CONFIG_BLK_DEV_INITRD
+
+#ifdef CONFIG_X86_32
+
+#define MAX_MAP_CHUNK	(NR_FIX_BTMAPS << PAGE_SHIFT)
+static void __init relocate_initrd(void)
+{
+
+	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
+	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 end_of_lowmem = max_low_pfn << PAGE_SHIFT;
+	u64 ramdisk_here;
+	unsigned long slop, clen, mapaddr;
+	char *p, *q;
+
+	/* We need to move the initrd down into lowmem */
+	ramdisk_here = find_e820_area(0, end_of_lowmem, ramdisk_size,
+					 PAGE_SIZE);
+
+	if (ramdisk_here == -1ULL)
+		panic("Cannot find place for new RAMDISK of size %lld\n",
+			 ramdisk_size);
+
+	/* Note: this includes all the lowmem currently occupied by
+	   the initrd, we rely on that fact to keep the data intact. */
+	reserve_early(ramdisk_here, ramdisk_here + ramdisk_size,
+			 "NEW RAMDISK");
+	initrd_start = ramdisk_here + PAGE_OFFSET;
+	initrd_end   = initrd_start + ramdisk_size;
+	printk(KERN_INFO "Allocated new RAMDISK: %08llx - %08llx\n",
+			 ramdisk_here, ramdisk_here + ramdisk_size);
+
+	q = (char *)initrd_start;
+
+	/* Copy any lowmem portion of the initrd */
+	if (ramdisk_image < end_of_lowmem) {
+		clen = end_of_lowmem - ramdisk_image;
+		p = (char *)__va(ramdisk_image);
+		memcpy(q, p, clen);
+		q += clen;
+		ramdisk_image += clen;
+		ramdisk_size  -= clen;
+	}
+
+	/* Copy the highmem portion of the initrd */
+	while (ramdisk_size) {
+		slop = ramdisk_image & ~PAGE_MASK;
+		clen = ramdisk_size;
+		if (clen > MAX_MAP_CHUNK-slop)
+			clen = MAX_MAP_CHUNK-slop;
+		mapaddr = ramdisk_image & PAGE_MASK;
+		p = early_ioremap(mapaddr, clen+slop);
+		memcpy(q, p+slop, clen);
+		early_iounmap(p, clen+slop);
+		q += clen;
+		ramdisk_image += clen;
+		ramdisk_size  -= clen;
+	}
+	/* high pages is not converted by early_res_to_bootmem */
+	ramdisk_image = boot_params.hdr.ramdisk_image;
+	ramdisk_size  = boot_params.hdr.ramdisk_size;
+	printk(KERN_INFO "Move RAMDISK from %016llx - %016llx to"
+		" %08llx - %08llx\n",
+		ramdisk_image, ramdisk_image + ramdisk_size - 1,
+		ramdisk_here, ramdisk_here + ramdisk_size - 1);
+}
+#endif
+
+static void __init reserve_initrd(void)
+{
+	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
+	u64 ramdisk_size  = boot_params.hdr.ramdisk_size;
+	u64 ramdisk_end   = ramdisk_image + ramdisk_size;
+	u64 end_of_lowmem = max_low_pfn << PAGE_SHIFT;
+
+	if (!boot_params.hdr.type_of_loader ||
+	    !ramdisk_image || !ramdisk_size)
+		return;		/* No initrd provided by bootloader */
+
+	initrd_start = 0;
+
+	if (ramdisk_size >= (end_of_lowmem>>1)) {
+		free_early(ramdisk_image, ramdisk_end);
+		printk(KERN_ERR "initrd too large to handle, "
+		       "disabling initrd\n");
+		return;
+	}
+
+	printk(KERN_INFO "RAMDISK: %08llx - %08llx\n", ramdisk_image,
+			ramdisk_end);
+
+
+	if (ramdisk_end <= end_of_lowmem) {
+		/* All in lowmem, easy case */
+		/*
+		 * don't need to reserve again, already reserved early
+		 * in i386_start_kernel
+		 */
+		initrd_start = ramdisk_image + PAGE_OFFSET;
+		initrd_end = initrd_start + ramdisk_size;
+		return;
+	}
+
+#ifdef CONFIG_X86_32
+	relocate_initrd();
+#else
+	printk(KERN_ERR "initrd extends beyond end of memory "
+	       "(0x%08llx > 0x%08llx)\ndisabling initrd\n",
+	       ramdisk_end, end_of_lowmem);
+	initrd_start = 0;
+#endif
+	free_early(ramdisk_image, ramdisk_end);
+}
+#else
+static void __init reserve_initrd(void)
+{
+}
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+/*
+ * Determine if we were loaded by an EFI loader.  If so, then we have also been
+ * passed the efi memmap, systab, etc., so we should use these data structures
+ * for initialization.  Note, the efi init code path is determined by the
+ * global efi_enabled. This allows the same kernel image to be used on existing
+ * systems (with a traditional BIOS) as well as on EFI systems.
+ */
+/*
+ * setup_arch - architecture-specific boot-time initializations
+ *
+ * Note: On x86_64, fixmaps are ready for use even before this is called.
+ */
+
+void __init setup_arch(char **cmdline_p)
+{
+#ifdef CONFIG_X86_32
+	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
+	pre_setup_arch_hook();
+	early_cpu_init();
+	early_ioremap_init();
+	reserve_setup_data();
+#else
+	printk(KERN_INFO "Command line: %s\n", boot_command_line);
+#endif
+
+	ROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);
+	screen_info = boot_params.screen_info;
+	edid_info = boot_params.edid_info;
+#ifdef CONFIG_X86_32
+	apm_info.bios = boot_params.apm_bios_info;
+	ist_info = boot_params.ist_info;
+	if (boot_params.sys_desc_table.length != 0) {
+		set_mca_bus(boot_params.sys_desc_table.table[3] & 0x2);
+		machine_id = boot_params.sys_desc_table.table[0];
+		machine_submodel_id = boot_params.sys_desc_table.table[1];
+		BIOS_revision = boot_params.sys_desc_table.table[2];
+	}
+#endif
+	saved_video_mode = boot_params.hdr.vid_mode;
+	bootloader_type = boot_params.hdr.type_of_loader;
+
+#ifdef CONFIG_BLK_DEV_RAM
+	rd_image_start = boot_params.hdr.ram_size & RAMDISK_IMAGE_START_MASK;
+	rd_prompt = ((boot_params.hdr.ram_size & RAMDISK_PROMPT_FLAG) != 0);
+	rd_doload = ((boot_params.hdr.ram_size & RAMDISK_LOAD_FLAG) != 0);
+#endif
+#ifdef CONFIG_EFI
+	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
+#ifdef CONFIG_X86_32
+		     "EL32",
+#else
+		     "EL64",
+#endif
+	 4)) {
+		efi_enabled = 1;
+		efi_reserve_early();
+	}
+#endif
+
+	ARCH_SETUP
+
+	setup_memory_map();
+	copy_edd();
+
+	if (!boot_params.hdr.root_flags)
+		root_mountflags &= ~MS_RDONLY;
+	init_mm.start_code = (unsigned long) _text;
+	init_mm.end_code = (unsigned long) _etext;
+	init_mm.end_data = (unsigned long) _edata;
+#ifdef CONFIG_X86_32
+	init_mm.brk = init_pg_tables_end + PAGE_OFFSET;
+#else
+	init_mm.brk = (unsigned long) &_end;
+#endif
+
+	code_resource.start = virt_to_phys(_text);
+	code_resource.end = virt_to_phys(_etext)-1;
+	data_resource.start = virt_to_phys(_etext);
+	data_resource.end = virt_to_phys(_edata)-1;
+	bss_resource.start = virt_to_phys(&__bss_start);
+	bss_resource.end = virt_to_phys(&__bss_stop)-1;
+
+#ifdef CONFIG_X86_64
+	early_cpu_init();
+#endif
+	strlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);
+	*cmdline_p = command_line;
+
+	parse_setup_data();
+
+	parse_early_param();
+
+	if (acpi_mps_check()) {
+#ifdef CONFIG_X86_LOCAL_APIC
+#ifdef CONFIG_X86_32
+		enable_local_apic = -1;
+#else
+		disable_apic = 1;
+#endif
+#endif
+		clear_cpu_cap(&boot_cpu_data, X86_FEATURE_APIC);
+	}
+
+	finish_e820_parsing();
+
+#ifdef CONFIG_X86_32
+	probe_roms();
+#else
+# ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
+	if (init_ohci1394_dma_early)
+		init_ohci1394_dma_on_all_controllers();
+# endif
+#endif
+
+	/* after parse_early_param, so could debug it */
+	insert_resource(&iomem_resource, &code_resource);
+	insert_resource(&iomem_resource, &data_resource);
+	insert_resource(&iomem_resource, &bss_resource);
+
+	if (efi_enabled)
+		efi_init();
+
+#ifdef CONFIG_X86_32
+	if (ppro_with_ram_bug()) {
+		e820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,
+				  E820_RESERVED);
+		sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
+		printk(KERN_INFO "fixed physical RAM map:\n");
+		e820_print_map("bad_ppro");
+	}
+#else
+	early_gart_iommu_check();
+#endif
+
+	e820_register_active_regions(0, 0, -1UL);
+	/*
+	 * partially used pages are not usable - thus
+	 * we are rounding upwards:
+	 */
+	max_pfn = e820_end_of_ram();
+
+	/* preallocate 4k for mptable mpc */
+	early_reserve_e820_mpc_new();
+	/* update e820 for memory not covered by WB MTRRs */
+	mtrr_bp_init();
+	if (mtrr_trim_uncached_memory(max_pfn)) {
+		remove_all_active_ranges();
+		e820_register_active_regions(0, 0, -1UL);
+		max_pfn = e820_end_of_ram();
+	}
+
+#ifdef CONFIG_X86_32
+	/* max_low_pfn get updated here */
+	find_low_pfn_range();
+#else
+	num_physpages = max_pfn;
+
+	check_efer();
+
+	/* How many end-of-memory variables you have, grandma! */
+	/* need this before calling reserve_initrd */
+	max_low_pfn = max_pfn;
+	high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
+#endif
+
+	/* max_pfn_mapped is updated here */
+	max_pfn_mapped = init_memory_mapping(0, (max_low_pfn << PAGE_SHIFT));
+
+	reserve_initrd();
+
+#ifdef CONFIG_X86_64
+	vsmp_init();
+#endif
+
+	dmi_scan_machine();
+
+	io_delay_init();
+
+	/*
+	 * Parse the ACPI tables for possible boot-time SMP configuration.
+	 */
+	acpi_boot_table_init();
+
+#ifdef CONFIG_X86_64
+	/* Remove active ranges so rediscovery with NUMA-awareness happens */
+	remove_all_active_ranges();
+#endif
+
+#ifdef CONFIG_ACPI_NUMA
+	/*
+	 * Parse SRAT to discover nodes.
+	 */
+	acpi_numa_init();
+#endif
+
+	initmem_init(0, max_pfn);
+
+#ifdef CONFIG_X86_64
+	dma32_reserve_bootmem();
+#endif
+
+#ifdef CONFIG_ACPI_SLEEP
+	/*
+	 * Reserve low memory region for sleep support.
+	 */
+	acpi_reserve_bootmem();
+#endif
+#if defined(CONFIG_X86_FIND_SMP_CONFIG) && defined(CONFIG_X86_32) || \
+    defined(CONFIG_X86_MPPARSE) && defined(CONFIG_X86_64)
+	/*
+	 * Find and reserve possible boot-time SMP configuration:
+	 */
+	find_smp_config();
+#endif
+	reserve_crashkernel();
+
+	reserve_ibft_region();
+
+#ifdef CONFIG_KVM_CLOCK
+	kvmclock_init();
+#endif
+
+#if defined(CONFIG_VMI) && defined(CONFIG_X86_32)
+	/*
+	 * Must be after max_low_pfn is determined, and before kernel
+	 * pagetables are setup.
+	 */
+	vmi_init();
+#endif
+
+	paging_init();
+
+#ifdef CONFIG_X86_64
+	map_vsyscall();
+#endif
+
+	/*
+	 * NOTE: On x86-32, only from this point on, fixmaps are ready for use.
+	 */
+
+#if defined(CONFIG_PROVIDE_OHCI1394_DMA_INIT) && defined(CONFIG_X86_32)
+	if (init_ohci1394_dma_early)
+		init_ohci1394_dma_on_all_controllers();
+#endif
+
+#ifdef CONFIG_X86_GENERICARCH
+	generic_apic_probe();
+#endif
+
+	early_quirks();
+
+	/*
+	 * Read APIC and some other early information from ACPI tables.
+	 */
+	acpi_boot_init();
+
+#ifdef CONFIG_X86_64
+	init_cpu_to_node();
+#endif
+
+#if defined(CONFIG_X86_MPPARSE) || defined(CONFIG_X86_VISWS)
+	/*
+	 * get boot-time SMP configuration:
+	 */
+	if (smp_found_config)
+		get_smp_config();
+#endif
+
+#ifdef CONFIG_X86_64
+	init_apic_mappings();
+	ioapic_init_mappings();
+#else
+# if defined(CONFIG_SMP) && defined(CONFIG_X86_PC)
+	if (def_to_bigsmp)
+		printk(KERN_WARNING "More than 8 CPUs detected and "
+			"CONFIG_X86_PC cannot handle it.\nUse "
+			"CONFIG_X86_GENERICARCH or CONFIG_X86_BIGSMP.\n");
+# endif
+#endif
+	kvm_guest_init();
+
+	e820_reserve_resources();
+	e820_mark_nosave_regions(max_low_pfn);
+
+#ifdef CONFIG_X86_32
+	request_resource(&iomem_resource, &video_ram_resource);
+#endif
+	reserve_standard_io_resources();
+
+	e820_setup_gap();
+
+#ifdef CONFIG_VT
+#if defined(CONFIG_VGA_CONSOLE)
+	if (!efi_enabled || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))
+		conswitchp = &vga_con;
+#elif defined(CONFIG_DUMMY_CONSOLE)
+	conswitchp = &dummy_con;
+#endif
+#endif
+}
+

commit 378b39a4f91ab0846eb6e13d47ea812bc82b44d9
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Wed Jun 25 17:48:14 2008 -0700

    x86: rename setup.c to setup_percpu.c
    
    some functions need to be moved to setup_numa.c
    after we merge setup32/64.c, some funcs need to be moved back to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
deleted file mode 100644
index 5c0c4bb5727d..000000000000
--- a/arch/x86/kernel/setup.c
+++ /dev/null
@@ -1,528 +0,0 @@
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/bootmem.h>
-#include <linux/percpu.h>
-#include <linux/kexec.h>
-#include <linux/crash_dump.h>
-#include <asm/smp.h>
-#include <asm/percpu.h>
-#include <asm/sections.h>
-#include <asm/processor.h>
-#include <asm/setup.h>
-#include <asm/topology.h>
-#include <asm/mpspec.h>
-#include <asm/apicdef.h>
-#include <asm/highmem.h>
-
-#ifndef CONFIG_DEBUG_BOOT_PARAMS
-struct boot_params __initdata boot_params;
-#else
-struct boot_params boot_params;
-#endif
-
-#ifdef CONFIG_X86_LOCAL_APIC
-unsigned int num_processors;
-unsigned disabled_cpus __cpuinitdata;
-/* Processor that is doing the boot up */
-unsigned int boot_cpu_physical_apicid = -1U;
-unsigned int max_physical_apicid;
-EXPORT_SYMBOL(boot_cpu_physical_apicid);
-
-/* Bitmask of physically existing CPUs */
-physid_mask_t phys_cpu_present_map;
-#endif
-
-/* map cpu index to physical APIC ID */
-DEFINE_EARLY_PER_CPU(u16, x86_cpu_to_apicid, BAD_APICID);
-DEFINE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid, BAD_APICID);
-EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_apicid);
-EXPORT_EARLY_PER_CPU_SYMBOL(x86_bios_cpu_apicid);
-
-#if defined(CONFIG_NUMA) && defined(CONFIG_X86_64)
-#define	X86_64_NUMA	1
-
-/* map cpu index to node index */
-DEFINE_EARLY_PER_CPU(int, x86_cpu_to_node_map, NUMA_NO_NODE);
-EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_node_map);
-
-/* which logical CPUs are on which nodes */
-cpumask_t *node_to_cpumask_map;
-EXPORT_SYMBOL(node_to_cpumask_map);
-
-/* setup node_to_cpumask_map */
-static void __init setup_node_to_cpumask_map(void);
-
-#else
-static inline void setup_node_to_cpumask_map(void) { }
-#endif
-
-#if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_X86_SMP)
-/*
- * Copy data used in early init routines from the initial arrays to the
- * per cpu data areas.  These arrays then become expendable and the
- * *_early_ptr's are zeroed indicating that the static arrays are gone.
- */
-static void __init setup_per_cpu_maps(void)
-{
-	int cpu;
-
-	for_each_possible_cpu(cpu) {
-		per_cpu(x86_cpu_to_apicid, cpu) =
-				early_per_cpu_map(x86_cpu_to_apicid, cpu);
-		per_cpu(x86_bios_cpu_apicid, cpu) =
-				early_per_cpu_map(x86_bios_cpu_apicid, cpu);
-#ifdef X86_64_NUMA
-		per_cpu(x86_cpu_to_node_map, cpu) =
-				early_per_cpu_map(x86_cpu_to_node_map, cpu);
-#endif
-	}
-
-	/* indicate the early static arrays will soon be gone */
-	early_per_cpu_ptr(x86_cpu_to_apicid) = NULL;
-	early_per_cpu_ptr(x86_bios_cpu_apicid) = NULL;
-#ifdef X86_64_NUMA
-	early_per_cpu_ptr(x86_cpu_to_node_map) = NULL;
-#endif
-}
-
-#ifdef CONFIG_HAVE_CPUMASK_OF_CPU_MAP
-cpumask_t *cpumask_of_cpu_map __read_mostly;
-EXPORT_SYMBOL(cpumask_of_cpu_map);
-
-/* requires nr_cpu_ids to be initialized */
-static void __init setup_cpumask_of_cpu(void)
-{
-	int i;
-
-	/* alloc_bootmem zeroes memory */
-	cpumask_of_cpu_map = alloc_bootmem_low(sizeof(cpumask_t) * nr_cpu_ids);
-	for (i = 0; i < nr_cpu_ids; i++)
-		cpu_set(i, cpumask_of_cpu_map[i]);
-}
-#else
-static inline void setup_cpumask_of_cpu(void) { }
-#endif
-
-#ifdef CONFIG_X86_32
-/*
- * Great future not-so-futuristic plan: make i386 and x86_64 do it
- * the same way
- */
-unsigned long __per_cpu_offset[NR_CPUS] __read_mostly;
-EXPORT_SYMBOL(__per_cpu_offset);
-static inline void setup_cpu_pda_map(void) { }
-
-#elif !defined(CONFIG_SMP)
-static inline void setup_cpu_pda_map(void) { }
-
-#else /* CONFIG_SMP && CONFIG_X86_64 */
-
-/*
- * Allocate cpu_pda pointer table and array via alloc_bootmem.
- */
-static void __init setup_cpu_pda_map(void)
-{
-	char *pda;
-	struct x8664_pda **new_cpu_pda;
-	unsigned long size;
-	int cpu;
-
-	size = roundup(sizeof(struct x8664_pda), cache_line_size());
-
-	/* allocate cpu_pda array and pointer table */
-	{
-		unsigned long tsize = nr_cpu_ids * sizeof(void *);
-		unsigned long asize = size * (nr_cpu_ids - 1);
-
-		tsize = roundup(tsize, cache_line_size());
-		new_cpu_pda = alloc_bootmem(tsize + asize);
-		pda = (char *)new_cpu_pda + tsize;
-	}
-
-	/* initialize pointer table to static pda's */
-	for_each_possible_cpu(cpu) {
-		if (cpu == 0) {
-			/* leave boot cpu pda in place */
-			new_cpu_pda[0] = cpu_pda(0);
-			continue;
-		}
-		new_cpu_pda[cpu] = (struct x8664_pda *)pda;
-		new_cpu_pda[cpu]->in_bootmem = 1;
-		pda += size;
-	}
-
-	/* point to new pointer table */
-	_cpu_pda = new_cpu_pda;
-}
-#endif
-
-/*
- * Great future plan:
- * Declare PDA itself and support (irqstack,tss,pgd) as per cpu data.
- * Always point %gs to its beginning
- */
-void __init setup_per_cpu_areas(void)
-{
-	ssize_t size = PERCPU_ENOUGH_ROOM;
-	char *ptr;
-	int cpu;
-
-	/* no processor from mptable or madt */
-	if (!num_processors)
-		num_processors = 1;
-
-#ifdef CONFIG_HOTPLUG_CPU
-	prefill_possible_map();
-#else
-	nr_cpu_ids = num_processors;
-#endif
-
-	/* Setup cpu_pda map */
-	setup_cpu_pda_map();
-
-	/* Copy section for each CPU (we discard the original) */
-	size = PERCPU_ENOUGH_ROOM;
-	printk(KERN_INFO "PERCPU: Allocating %zd bytes of per cpu data\n",
-			  size);
-
-	for_each_possible_cpu(cpu) {
-#ifndef CONFIG_NEED_MULTIPLE_NODES
-		ptr = alloc_bootmem_pages(size);
-#else
-		int node = early_cpu_to_node(cpu);
-		if (!node_online(node) || !NODE_DATA(node)) {
-			ptr = alloc_bootmem_pages(size);
-			printk(KERN_INFO
-			       "cpu %d has no node %d or node-local memory\n",
-				cpu, node);
-		}
-		else
-			ptr = alloc_bootmem_pages_node(NODE_DATA(node), size);
-#endif
-		per_cpu_offset(cpu) = ptr - __per_cpu_start;
-		memcpy(ptr, __per_cpu_start, __per_cpu_end - __per_cpu_start);
-
-	}
-
-	printk(KERN_DEBUG "NR_CPUS: %d, nr_cpu_ids: %d, nr_node_ids %d\n",
-		NR_CPUS, nr_cpu_ids, nr_node_ids);
-
-	/* Setup percpu data maps */
-	setup_per_cpu_maps();
-
-	/* Setup node to cpumask map */
-	setup_node_to_cpumask_map();
-
-	/* Setup cpumask_of_cpu map */
-	setup_cpumask_of_cpu();
-}
-
-#endif
-
-void __init parse_setup_data(void)
-{
-	struct setup_data *data;
-	u64 pa_data;
-
-	if (boot_params.hdr.version < 0x0209)
-		return;
-	pa_data = boot_params.hdr.setup_data;
-	while (pa_data) {
-		data = early_ioremap(pa_data, PAGE_SIZE);
-		switch (data->type) {
-		case SETUP_E820_EXT:
-			parse_e820_ext(data, pa_data);
-			break;
-		default:
-			break;
-		}
-#ifndef CONFIG_DEBUG_BOOT_PARAMS
-		free_early(pa_data, pa_data+sizeof(*data)+data->len);
-#endif
-		pa_data = data->next;
-		early_iounmap(data, PAGE_SIZE);
-	}
-}
-
-#ifdef X86_64_NUMA
-
-/*
- * Allocate node_to_cpumask_map based on number of available nodes
- * Requires node_possible_map to be valid.
- *
- * Note: node_to_cpumask() is not valid until after this is done.
- */
-static void __init setup_node_to_cpumask_map(void)
-{
-	unsigned int node, num = 0;
-	cpumask_t *map;
-
-	/* setup nr_node_ids if not done yet */
-	if (nr_node_ids == MAX_NUMNODES) {
-		for_each_node_mask(node, node_possible_map)
-			num = node;
-		nr_node_ids = num + 1;
-	}
-
-	/* allocate the map */
-	map = alloc_bootmem_low(nr_node_ids * sizeof(cpumask_t));
-
-	Dprintk(KERN_DEBUG "Node to cpumask map at %p for %d nodes\n",
-		map, nr_node_ids);
-
-	/* node_to_cpumask() will now work */
-	node_to_cpumask_map = map;
-}
-
-void __cpuinit numa_set_node(int cpu, int node)
-{
-	int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
-
-	if (cpu_pda(cpu) && node != NUMA_NO_NODE)
-		cpu_pda(cpu)->nodenumber = node;
-
-	if (cpu_to_node_map)
-		cpu_to_node_map[cpu] = node;
-
-	else if (per_cpu_offset(cpu))
-		per_cpu(x86_cpu_to_node_map, cpu) = node;
-
-	else
-		Dprintk(KERN_INFO "Setting node for non-present cpu %d\n", cpu);
-}
-
-void __cpuinit numa_clear_node(int cpu)
-{
-	numa_set_node(cpu, NUMA_NO_NODE);
-}
-
-#ifndef CONFIG_DEBUG_PER_CPU_MAPS
-
-void __cpuinit numa_add_cpu(int cpu)
-{
-	cpu_set(cpu, node_to_cpumask_map[early_cpu_to_node(cpu)]);
-}
-
-void __cpuinit numa_remove_cpu(int cpu)
-{
-	cpu_clear(cpu, node_to_cpumask_map[cpu_to_node(cpu)]);
-}
-
-#else /* CONFIG_DEBUG_PER_CPU_MAPS */
-
-/*
- * --------- debug versions of the numa functions ---------
- */
-static void __cpuinit numa_set_cpumask(int cpu, int enable)
-{
-	int node = cpu_to_node(cpu);
-	cpumask_t *mask;
-	char buf[64];
-
-	if (node_to_cpumask_map == NULL) {
-		printk(KERN_ERR "node_to_cpumask_map NULL\n");
-		dump_stack();
-		return;
-	}
-
-	mask = &node_to_cpumask_map[node];
-	if (enable)
-		cpu_set(cpu, *mask);
-	else
-		cpu_clear(cpu, *mask);
-
-	cpulist_scnprintf(buf, sizeof(buf), *mask);
-	printk(KERN_DEBUG "%s cpu %d node %d: mask now %s\n",
-		enable? "numa_add_cpu":"numa_remove_cpu", cpu, node, buf);
- }
-
-void __cpuinit numa_add_cpu(int cpu)
-{
-	numa_set_cpumask(cpu, 1);
-}
-
-void __cpuinit numa_remove_cpu(int cpu)
-{
-	numa_set_cpumask(cpu, 0);
-}
-
-int cpu_to_node(int cpu)
-{
-	if (early_per_cpu_ptr(x86_cpu_to_node_map)) {
-		printk(KERN_WARNING
-			"cpu_to_node(%d): usage too early!\n", cpu);
-		dump_stack();
-		return early_per_cpu_ptr(x86_cpu_to_node_map)[cpu];
-	}
-	return per_cpu(x86_cpu_to_node_map, cpu);
-}
-EXPORT_SYMBOL(cpu_to_node);
-
-/*
- * Same function as cpu_to_node() but used if called before the
- * per_cpu areas are setup.
- */
-int early_cpu_to_node(int cpu)
-{
-	if (early_per_cpu_ptr(x86_cpu_to_node_map))
-		return early_per_cpu_ptr(x86_cpu_to_node_map)[cpu];
-
-	if (!per_cpu_offset(cpu)) {
-		printk(KERN_WARNING
-			"early_cpu_to_node(%d): no per_cpu area!\n", cpu);
-		dump_stack();
-		return NUMA_NO_NODE;
-	}
-	return per_cpu(x86_cpu_to_node_map, cpu);
-}
-
-/*
- * Returns a pointer to the bitmask of CPUs on Node 'node'.
- */
-cpumask_t *_node_to_cpumask_ptr(int node)
-{
-	if (node_to_cpumask_map == NULL) {
-		printk(KERN_WARNING
-			"_node_to_cpumask_ptr(%d): no node_to_cpumask_map!\n",
-			node);
-		dump_stack();
-		return &cpu_online_map;
-	}
-	BUG_ON(node >= nr_node_ids);
-	return &node_to_cpumask_map[node];
-}
-EXPORT_SYMBOL(_node_to_cpumask_ptr);
-
-/*
- * Returns a bitmask of CPUs on Node 'node'.
- */
-cpumask_t node_to_cpumask(int node)
-{
-	if (node_to_cpumask_map == NULL) {
-		printk(KERN_WARNING
-			"node_to_cpumask(%d): no node_to_cpumask_map!\n", node);
-		dump_stack();
-		return cpu_online_map;
-	}
-	BUG_ON(node >= nr_node_ids);
-	return node_to_cpumask_map[node];
-}
-EXPORT_SYMBOL(node_to_cpumask);
-
-/*
- * --------- end of debug versions of the numa functions ---------
- */
-
-#endif /* CONFIG_DEBUG_PER_CPU_MAPS */
-
-#endif /* X86_64_NUMA */
-
-
-/*
- * --------- Crashkernel reservation ------------------------------
- */
-
-static inline unsigned long long get_total_mem(void)
-{
-	unsigned long long total;
-
-	total = max_low_pfn - min_low_pfn;
-#ifdef CONFIG_HIGHMEM
-	total += highend_pfn - highstart_pfn;
-#endif
-
-	return total << PAGE_SHIFT;
-}
-
-#ifdef CONFIG_KEXEC
-void __init reserve_crashkernel(void)
-{
-	unsigned long long total_mem;
-	unsigned long long crash_size, crash_base;
-	int ret;
-
-	total_mem = get_total_mem();
-
-	ret = parse_crashkernel(boot_command_line, total_mem,
-			&crash_size, &crash_base);
-	if (ret == 0 && crash_size > 0) {
-		if (crash_base <= 0) {
-			printk(KERN_INFO "crashkernel reservation failed - "
-					"you have to specify a base address\n");
-			return;
-		}
-
-		if (reserve_bootmem_generic(crash_base, crash_size,
-					BOOTMEM_EXCLUSIVE) < 0) {
-			printk(KERN_INFO "crashkernel reservation failed - "
-					"memory is in use\n");
-			return;
-		}
-
-		printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
-				"for crashkernel (System RAM: %ldMB)\n",
-				(unsigned long)(crash_size >> 20),
-				(unsigned long)(crash_base >> 20),
-				(unsigned long)(total_mem >> 20));
-
-		crashk_res.start = crash_base;
-		crashk_res.end   = crash_base + crash_size - 1;
-		insert_resource(&iomem_resource, &crashk_res);
-	}
-}
-#else
-void __init reserve_crashkernel(void)
-{}
-#endif
-static struct resource standard_io_resources[] = {
-	{ .name = "dma1", .start = 0x00, .end = 0x1f,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "pic1", .start = 0x20, .end = 0x21,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "timer0", .start = 0x40, .end = 0x43,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "timer1", .start = 0x50, .end = 0x53,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "keyboard", .start = 0x60, .end = 0x60,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "keyboard", .start = 0x64, .end = 0x64,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "dma page reg", .start = 0x80, .end = 0x8f,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "pic2", .start = 0xa0, .end = 0xa1,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "dma2", .start = 0xc0, .end = 0xdf,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
-	{ .name = "fpu", .start = 0xf0, .end = 0xff,
-		.flags = IORESOURCE_BUSY | IORESOURCE_IO }
-};
-
-void __init reserve_standard_io_resources(void)
-{
-	int i;
-
-	/* request I/O space for devices used on all i[345]86 PCs */
-	for (i = 0; i < ARRAY_SIZE(standard_io_resources); i++)
-		request_resource(&ioport_resource, &standard_io_resources[i]);
-
-}
-
-#ifdef CONFIG_PROC_VMCORE
-/* elfcorehdr= specifies the location of elf core header
- * stored by the crashed kernel. This option will be passed
- * by kexec loader to the capture kernel.
- */
-static int __init setup_elfcorehdr(char *arg)
-{
-	char *end;
-	if (!arg)
-		return -EINVAL;
-	elfcorehdr_addr = memparse(arg, &end);
-	return end > arg ? 0 : -EINVAL;
-}
-early_param("elfcorehdr", setup_elfcorehdr);
-#endif
-
-
-

commit 7f0be02c5ed1deb04c54c6a17f412e04f417df11
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sun Jun 22 17:37:54 2008 -0700

    x86: move boot_params declaring to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 5497fb9b00a0..5c0c4bb5727d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -15,6 +15,12 @@
 #include <asm/apicdef.h>
 #include <asm/highmem.h>
 
+#ifndef CONFIG_DEBUG_BOOT_PARAMS
+struct boot_params __initdata boot_params;
+#else
+struct boot_params boot_params;
+#endif
+
 #ifdef CONFIG_X86_LOCAL_APIC
 unsigned int num_processors;
 unsigned disabled_cpus __cpuinitdata;

commit 17b4cceb1feb2a8865ce47064dd3bd446063a5d5
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sat Jun 21 21:02:20 2008 -0700

    x86: move elfcorehdr parsing to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3b9ec81ba4fb..5497fb9b00a0 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -4,6 +4,7 @@
 #include <linux/bootmem.h>
 #include <linux/percpu.h>
 #include <linux/kexec.h>
+#include <linux/crash_dump.h>
 #include <asm/smp.h>
 #include <asm/percpu.h>
 #include <asm/sections.h>
@@ -501,3 +502,21 @@ void __init reserve_standard_io_resources(void)
 
 }
 
+#ifdef CONFIG_PROC_VMCORE
+/* elfcorehdr= specifies the location of elf core header
+ * stored by the crashed kernel. This option will be passed
+ * by kexec loader to the capture kernel.
+ */
+static int __init setup_elfcorehdr(char *arg)
+{
+	char *end;
+	if (!arg)
+		return -EINVAL;
+	elfcorehdr_addr = memparse(arg, &end);
+	return end > arg ? 0 : -EINVAL;
+}
+early_param("elfcorehdr", setup_elfcorehdr);
+#endif
+
+
+

commit ce97c40e28223c148e142bda7af48fd0f27c81f9
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sat Jun 21 20:22:09 2008 -0700

    x86: move reserve_standard_io_resource to setup.c
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 56aee55cf8dc..3b9ec81ba4fb 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -468,4 +468,36 @@ void __init reserve_crashkernel(void)
 void __init reserve_crashkernel(void)
 {}
 #endif
+static struct resource standard_io_resources[] = {
+	{ .name = "dma1", .start = 0x00, .end = 0x1f,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "pic1", .start = 0x20, .end = 0x21,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "timer0", .start = 0x40, .end = 0x43,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "timer1", .start = 0x50, .end = 0x53,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "keyboard", .start = 0x60, .end = 0x60,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "keyboard", .start = 0x64, .end = 0x64,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "dma page reg", .start = 0x80, .end = 0x8f,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "pic2", .start = 0xa0, .end = 0xa1,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "dma2", .start = 0xc0, .end = 0xdf,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO },
+	{ .name = "fpu", .start = 0xf0, .end = 0xff,
+		.flags = IORESOURCE_BUSY | IORESOURCE_IO }
+};
+
+void __init reserve_standard_io_resources(void)
+{
+	int i;
+
+	/* request I/O space for devices used on all i[345]86 PCs */
+	for (i = 0; i < ARRAY_SIZE(standard_io_resources); i++)
+		request_resource(&ioport_resource, &standard_io_resources[i]);
+
+}
 

commit 3c999f142665265afd0fe9190204dd051f17e505
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Fri Jun 20 16:11:20 2008 -0700

    x86: check command line when CONFIG_X86_MPPARSE is not set, v2
    
    if acpi=off, acpi=noirq and pci=noacpi, we need to disable apic.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: "Maciej W. Rozycki" <macro@linux-mips.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c5330f601b68..56aee55cf8dc 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -161,6 +161,10 @@ void __init setup_per_cpu_areas(void)
 	char *ptr;
 	int cpu;
 
+	/* no processor from mptable or madt */
+	if (!num_processors)
+		num_processors = 1;
+
 #ifdef CONFIG_HOTPLUG_CPU
 	prefill_possible_map();
 #else

commit 1ecd27657b735128a728ebf0c31fce5e1456718a
Author: Bernhard Walle <bwalle@suse.de>
Date:   Fri Jun 20 15:38:22 2008 +0200

    x86: unify crashkernel reservation for 32 and 64 bit
    
    This patch moves the reserve_crashkernel() to setup.c and removes the
    architecture-specific version. Both versions were more or less the same.
    
    I tested it on both x86-64 and i386, with CONFIG_KEXEC on and off (so
    that it compiles).
    
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: yhlu.kernel@gmail.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ebb0a2bcdc08..c5330f601b68 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -3,6 +3,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/percpu.h>
+#include <linux/kexec.h>
 #include <asm/smp.h>
 #include <asm/percpu.h>
 #include <asm/sections.h>
@@ -11,6 +12,7 @@
 #include <asm/topology.h>
 #include <asm/mpspec.h>
 #include <asm/apicdef.h>
+#include <asm/highmem.h>
 
 #ifdef CONFIG_X86_LOCAL_APIC
 unsigned int num_processors;
@@ -404,3 +406,62 @@ EXPORT_SYMBOL(node_to_cpumask);
 #endif /* CONFIG_DEBUG_PER_CPU_MAPS */
 
 #endif /* X86_64_NUMA */
+
+
+/*
+ * --------- Crashkernel reservation ------------------------------
+ */
+
+static inline unsigned long long get_total_mem(void)
+{
+	unsigned long long total;
+
+	total = max_low_pfn - min_low_pfn;
+#ifdef CONFIG_HIGHMEM
+	total += highend_pfn - highstart_pfn;
+#endif
+
+	return total << PAGE_SHIFT;
+}
+
+#ifdef CONFIG_KEXEC
+void __init reserve_crashkernel(void)
+{
+	unsigned long long total_mem;
+	unsigned long long crash_size, crash_base;
+	int ret;
+
+	total_mem = get_total_mem();
+
+	ret = parse_crashkernel(boot_command_line, total_mem,
+			&crash_size, &crash_base);
+	if (ret == 0 && crash_size > 0) {
+		if (crash_base <= 0) {
+			printk(KERN_INFO "crashkernel reservation failed - "
+					"you have to specify a base address\n");
+			return;
+		}
+
+		if (reserve_bootmem_generic(crash_base, crash_size,
+					BOOTMEM_EXCLUSIVE) < 0) {
+			printk(KERN_INFO "crashkernel reservation failed - "
+					"memory is in use\n");
+			return;
+		}
+
+		printk(KERN_INFO "Reserving %ldMB of memory at %ldMB "
+				"for crashkernel (System RAM: %ldMB)\n",
+				(unsigned long)(crash_size >> 20),
+				(unsigned long)(crash_base >> 20),
+				(unsigned long)(total_mem >> 20));
+
+		crashk_res.start = crash_base;
+		crashk_res.end   = crash_base + crash_size - 1;
+		insert_resource(&iomem_resource, &crashk_res);
+	}
+}
+#else
+void __init reserve_crashkernel(void)
+{}
+#endif
+

commit 2b4fa851b2f06fdb04cac808b57324f5e51e1578
Merge: 3de352bbd86f 46f68e1c6b04
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 8 11:59:23 2008 +0200

    Merge branch 'x86/numa' into x86/devel
    
    Conflicts:
    
            arch/x86/Kconfig
            arch/x86/kernel/e820.c
            arch/x86/kernel/efi_64.c
            arch/x86/kernel/mpparse.c
            arch/x86/kernel/setup.c
            arch/x86/kernel/setup_32.c
            arch/x86/mm/init_64.c
            include/asm-x86/proto.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 053713f5745b8b08fb598adb65230bc168cb9d8d
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Thu Jun 5 11:10:59 2008 -0700

    x86: fix setup.c printk format warning
    
    Fix setup.c printk format warning:
    
    linux-next-20080605/arch/x86/kernel/setup.c: In function 'setup_per_cpu_areas':
    linux-next-20080605/arch/x86/kernel/setup.c:173: warning: format '%lu' expects type 'long unsigned int', but argument 2 has type 'ssize_t'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index df49ce87a300..d4eaa4eb481d 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -169,7 +169,7 @@ void __init setup_per_cpu_areas(void)
 
 	/* Copy section for each CPU (we discard the original) */
 	size = PERCPU_ENOUGH_ROOM;
-	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
+	printk(KERN_INFO "PERCPU: Allocating %zd bytes of per cpu data\n",
 			  size);
 
 	for_each_possible_cpu(cpu) {

commit 03db1f74a7d823e3de3767f36b1e08829f6fb3a1
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Fri Jun 6 16:33:25 2008 +0200

    x86: don't return invalid pointers from node_to_cpumask()
    
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index dd12c1c84a8f..df49ce87a300 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -350,6 +350,7 @@ cpumask_t *_node_to_cpumask_ptr(int node)
 		dump_stack();
 		return &cpu_online_map;
 	}
+	BUG_ON(node >= nr_node_ids);
 	return &node_to_cpumask_map[node];
 }
 EXPORT_SYMBOL(_node_to_cpumask_ptr);
@@ -365,6 +366,7 @@ cpumask_t node_to_cpumask(int node)
 		dump_stack();
 		return cpu_online_map;
 	}
+	BUG_ON(node >= nr_node_ids);
 	return node_to_cpumask_map[node];
 }
 EXPORT_SYMBOL(node_to_cpumask);

commit 3461b0af025251bbc6b3d56c821c6ac2de6f7209
Author: Mike Travis <travis@sgi.com>
Date:   Mon May 12 21:21:13 2008 +0200

    x86: remove static boot_cpu_pda array v2
    
      * Remove the boot_cpu_pda array and pointer table from the data section.
        Allocate the pointer table and array during init.  do_boot_cpu()
        will reallocate the pda in node local memory and if the cpu is being
        brought up before the bootmem array is released (after_bootmem = 0),
        then it will free the initial pda.  This will happen for all cpus
        present at system startup.
    
        This removes 512k + 32k bytes from the data section.
    
    For inclusion into sched-devel/latest tree.
    
    Based on:
            git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git
        +   sched-devel/latest  .../mingo/linux-2.6-sched-devel.git
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 913af838c3c5..dd12c1c84a8f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -101,6 +101,50 @@ static inline void setup_cpumask_of_cpu(void) { }
  */
 unsigned long __per_cpu_offset[NR_CPUS] __read_mostly;
 EXPORT_SYMBOL(__per_cpu_offset);
+static inline void setup_cpu_pda_map(void) { }
+
+#elif !defined(CONFIG_SMP)
+static inline void setup_cpu_pda_map(void) { }
+
+#else /* CONFIG_SMP && CONFIG_X86_64 */
+
+/*
+ * Allocate cpu_pda pointer table and array via alloc_bootmem.
+ */
+static void __init setup_cpu_pda_map(void)
+{
+	char *pda;
+	struct x8664_pda **new_cpu_pda;
+	unsigned long size;
+	int cpu;
+
+	size = roundup(sizeof(struct x8664_pda), cache_line_size());
+
+	/* allocate cpu_pda array and pointer table */
+	{
+		unsigned long tsize = nr_cpu_ids * sizeof(void *);
+		unsigned long asize = size * (nr_cpu_ids - 1);
+
+		tsize = roundup(tsize, cache_line_size());
+		new_cpu_pda = alloc_bootmem(tsize + asize);
+		pda = (char *)new_cpu_pda + tsize;
+	}
+
+	/* initialize pointer table to static pda's */
+	for_each_possible_cpu(cpu) {
+		if (cpu == 0) {
+			/* leave boot cpu pda in place */
+			new_cpu_pda[0] = cpu_pda(0);
+			continue;
+		}
+		new_cpu_pda[cpu] = (struct x8664_pda *)pda;
+		new_cpu_pda[cpu]->in_bootmem = 1;
+		pda += size;
+	}
+
+	/* point to new pointer table */
+	_cpu_pda = new_cpu_pda;
+}
 #endif
 
 /*
@@ -110,46 +154,43 @@ EXPORT_SYMBOL(__per_cpu_offset);
  */
 void __init setup_per_cpu_areas(void)
 {
-	int i, highest_cpu = 0;
-	unsigned long size;
+	ssize_t size = PERCPU_ENOUGH_ROOM;
+	char *ptr;
+	int cpu;
 
 #ifdef CONFIG_HOTPLUG_CPU
 	prefill_possible_map();
+#else
+	nr_cpu_ids = num_processors;
 #endif
 
+	/* Setup cpu_pda map */
+	setup_cpu_pda_map();
+
 	/* Copy section for each CPU (we discard the original) */
 	size = PERCPU_ENOUGH_ROOM;
 	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
 			  size);
 
-	for_each_possible_cpu(i) {
-		char *ptr;
+	for_each_possible_cpu(cpu) {
 #ifndef CONFIG_NEED_MULTIPLE_NODES
 		ptr = alloc_bootmem_pages(size);
 #else
-		int node = early_cpu_to_node(i);
+		int node = early_cpu_to_node(cpu);
 		if (!node_online(node) || !NODE_DATA(node)) {
 			ptr = alloc_bootmem_pages(size);
 			printk(KERN_INFO
 			       "cpu %d has no node %d or node-local memory\n",
-				i, node);
+				cpu, node);
 		}
 		else
 			ptr = alloc_bootmem_pages_node(NODE_DATA(node), size);
 #endif
-		if (!ptr)
-			panic("Cannot allocate cpu data for CPU %d\n", i);
-#ifdef CONFIG_X86_64
-		cpu_pda(i)->data_offset = ptr - __per_cpu_start;
-#else
-		__per_cpu_offset[i] = ptr - __per_cpu_start;
-#endif
+		per_cpu_offset(cpu) = ptr - __per_cpu_start;
 		memcpy(ptr, __per_cpu_start, __per_cpu_end - __per_cpu_start);
 
-		highest_cpu = i;
 	}
 
-	nr_cpu_ids = highest_cpu + 1;
 	printk(KERN_DEBUG "NR_CPUS: %d, nr_cpu_ids: %d, nr_node_ids %d\n",
 		NR_CPUS, nr_cpu_ids, nr_node_ids);
 
@@ -199,7 +240,7 @@ void __cpuinit numa_set_node(int cpu, int node)
 {
 	int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
 
-	if (node != NUMA_NO_NODE)
+	if (cpu_pda(cpu) && node != NUMA_NO_NODE)
 		cpu_pda(cpu)->nodenumber = node;
 
 	if (cpu_to_node_map)

commit 9f248bde9d47cc177011198c9a15fb339b9f3215
Author: Mike Travis <travis@sgi.com>
Date:   Mon May 12 21:21:12 2008 +0200

    x86: remove the static 256k node_to_cpumask_map
    
      * Consolidate node_to_cpumask operations and remove the 256k
        byte node_to_cpumask_map.  This is done by allocating the
        node_to_cpumask_map array after the number of possible nodes
        (nr_node_ids) is known.
    
      * Debug printouts when CONFIG_DEBUG_PER_CPU_MAPS is active have
        been increased.  It now shows faults when calling node_to_cpumask()
        and node_to_cpumask_ptr().
    
    For inclusion into sched-devel/latest tree.
    
    Based on:
            git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git
        +   sched-devel/latest  .../mingo/linux-2.6-sched-devel.git
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0dff17ee3d73..913af838c3c5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -35,6 +35,16 @@ EXPORT_EARLY_PER_CPU_SYMBOL(x86_bios_cpu_apicid);
 /* map cpu index to node index */
 DEFINE_EARLY_PER_CPU(int, x86_cpu_to_node_map, NUMA_NO_NODE);
 EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_node_map);
+
+/* which logical CPUs are on which nodes */
+cpumask_t *node_to_cpumask_map;
+EXPORT_SYMBOL(node_to_cpumask_map);
+
+/* setup node_to_cpumask_map */
+static void __init setup_node_to_cpumask_map(void);
+
+#else
+static inline void setup_node_to_cpumask_map(void) { }
 #endif
 
 #if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_X86_SMP)
@@ -140,11 +150,15 @@ void __init setup_per_cpu_areas(void)
 	}
 
 	nr_cpu_ids = highest_cpu + 1;
-	printk(KERN_DEBUG "NR_CPUS: %d, nr_cpu_ids: %d\n", NR_CPUS, nr_cpu_ids);
+	printk(KERN_DEBUG "NR_CPUS: %d, nr_cpu_ids: %d, nr_node_ids %d\n",
+		NR_CPUS, nr_cpu_ids, nr_node_ids);
 
 	/* Setup percpu data maps */
 	setup_per_cpu_maps();
 
+	/* Setup node to cpumask map */
+	setup_node_to_cpumask_map();
+
 	/* Setup cpumask_of_cpu map */
 	setup_cpumask_of_cpu();
 }
@@ -152,6 +166,35 @@ void __init setup_per_cpu_areas(void)
 #endif
 
 #ifdef X86_64_NUMA
+
+/*
+ * Allocate node_to_cpumask_map based on number of available nodes
+ * Requires node_possible_map to be valid.
+ *
+ * Note: node_to_cpumask() is not valid until after this is done.
+ */
+static void __init setup_node_to_cpumask_map(void)
+{
+	unsigned int node, num = 0;
+	cpumask_t *map;
+
+	/* setup nr_node_ids if not done yet */
+	if (nr_node_ids == MAX_NUMNODES) {
+		for_each_node_mask(node, node_possible_map)
+			num = node;
+		nr_node_ids = num + 1;
+	}
+
+	/* allocate the map */
+	map = alloc_bootmem_low(nr_node_ids * sizeof(cpumask_t));
+
+	Dprintk(KERN_DEBUG "Node to cpumask map at %p for %d nodes\n",
+		map, nr_node_ids);
+
+	/* node_to_cpumask() will now work */
+	node_to_cpumask_map = map;
+}
+
 void __cpuinit numa_set_node(int cpu, int node)
 {
 	int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
@@ -174,6 +217,8 @@ void __cpuinit numa_clear_node(int cpu)
 	numa_set_node(cpu, NUMA_NO_NODE);
 }
 
+#ifndef CONFIG_DEBUG_PER_CPU_MAPS
+
 void __cpuinit numa_add_cpu(int cpu)
 {
 	cpu_set(cpu, node_to_cpumask_map[early_cpu_to_node(cpu)]);
@@ -183,9 +228,44 @@ void __cpuinit numa_remove_cpu(int cpu)
 {
 	cpu_clear(cpu, node_to_cpumask_map[cpu_to_node(cpu)]);
 }
-#endif /* CONFIG_NUMA */
 
-#if defined(CONFIG_DEBUG_PER_CPU_MAPS) && defined(CONFIG_X86_64)
+#else /* CONFIG_DEBUG_PER_CPU_MAPS */
+
+/*
+ * --------- debug versions of the numa functions ---------
+ */
+static void __cpuinit numa_set_cpumask(int cpu, int enable)
+{
+	int node = cpu_to_node(cpu);
+	cpumask_t *mask;
+	char buf[64];
+
+	if (node_to_cpumask_map == NULL) {
+		printk(KERN_ERR "node_to_cpumask_map NULL\n");
+		dump_stack();
+		return;
+	}
+
+	mask = &node_to_cpumask_map[node];
+	if (enable)
+		cpu_set(cpu, *mask);
+	else
+		cpu_clear(cpu, *mask);
+
+	cpulist_scnprintf(buf, sizeof(buf), *mask);
+	printk(KERN_DEBUG "%s cpu %d node %d: mask now %s\n",
+		enable? "numa_add_cpu":"numa_remove_cpu", cpu, node, buf);
+ }
+
+void __cpuinit numa_add_cpu(int cpu)
+{
+	numa_set_cpumask(cpu, 1);
+}
+
+void __cpuinit numa_remove_cpu(int cpu)
+{
+	numa_set_cpumask(cpu, 0);
+}
 
 int cpu_to_node(int cpu)
 {
@@ -199,6 +279,10 @@ int cpu_to_node(int cpu)
 }
 EXPORT_SYMBOL(cpu_to_node);
 
+/*
+ * Same function as cpu_to_node() but used if called before the
+ * per_cpu areas are setup.
+ */
 int early_cpu_to_node(int cpu)
 {
 	if (early_per_cpu_ptr(x86_cpu_to_node_map))
@@ -207,9 +291,47 @@ int early_cpu_to_node(int cpu)
 	if (!per_cpu_offset(cpu)) {
 		printk(KERN_WARNING
 			"early_cpu_to_node(%d): no per_cpu area!\n", cpu);
-			dump_stack();
+		dump_stack();
 		return NUMA_NO_NODE;
 	}
 	return per_cpu(x86_cpu_to_node_map, cpu);
 }
-#endif
+
+/*
+ * Returns a pointer to the bitmask of CPUs on Node 'node'.
+ */
+cpumask_t *_node_to_cpumask_ptr(int node)
+{
+	if (node_to_cpumask_map == NULL) {
+		printk(KERN_WARNING
+			"_node_to_cpumask_ptr(%d): no node_to_cpumask_map!\n",
+			node);
+		dump_stack();
+		return &cpu_online_map;
+	}
+	return &node_to_cpumask_map[node];
+}
+EXPORT_SYMBOL(_node_to_cpumask_ptr);
+
+/*
+ * Returns a bitmask of CPUs on Node 'node'.
+ */
+cpumask_t node_to_cpumask(int node)
+{
+	if (node_to_cpumask_map == NULL) {
+		printk(KERN_WARNING
+			"node_to_cpumask(%d): no node_to_cpumask_map!\n", node);
+		dump_stack();
+		return cpu_online_map;
+	}
+	return node_to_cpumask_map[node];
+}
+EXPORT_SYMBOL(node_to_cpumask);
+
+/*
+ * --------- end of debug versions of the numa functions ---------
+ */
+
+#endif /* CONFIG_DEBUG_PER_CPU_MAPS */
+
+#endif /* X86_64_NUMA */

commit 7891a24e1ee50c96896c0cf7da216a8e7b573ca5
Author: Mike Travis <travis@sgi.com>
Date:   Mon May 12 21:21:12 2008 +0200

    x86: restore pda nodenumber field
    
      * Restore the nodenumber field in the x86_64 pda.  This field is slightly
        different than the x86_cpu_to_node_map mainly because it's a static
        indication of which node the cpu is on while the cpu to node map is a
        dyanamic mapping that may get reset if the cpu goes offline.  This also
        simplifies the numa_node_id() macro.
    
    For inclusion into sched-devel/latest tree.
    
    Based on:
            git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git
        +   sched-devel/latest  .../mingo/linux-2.6-sched-devel.git
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 03caa8e4351f..0dff17ee3d73 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -32,6 +32,7 @@ EXPORT_EARLY_PER_CPU_SYMBOL(x86_bios_cpu_apicid);
 #if defined(CONFIG_NUMA) && defined(CONFIG_X86_64)
 #define	X86_64_NUMA	1
 
+/* map cpu index to node index */
 DEFINE_EARLY_PER_CPU(int, x86_cpu_to_node_map, NUMA_NO_NODE);
 EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_node_map);
 #endif
@@ -155,6 +156,9 @@ void __cpuinit numa_set_node(int cpu, int node)
 {
 	int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
 
+	if (node != NUMA_NO_NODE)
+		cpu_pda(cpu)->nodenumber = node;
+
 	if (cpu_to_node_map)
 		cpu_to_node_map[cpu] = node;
 

commit 23ca4bba3e20c6c3cb11c1bb0ab4770b724d39ac
Author: Mike Travis <travis@sgi.com>
Date:   Mon May 12 21:21:12 2008 +0200

    x86: cleanup early per cpu variables/accesses v4
    
      * Introduce a new PER_CPU macro called "EARLY_PER_CPU".  This is
        used by some per_cpu variables that are initialized and accessed
        before there are per_cpu areas allocated.
    
        ["Early" in respect to per_cpu variables is "earlier than the per_cpu
        areas have been setup".]
    
        This patchset adds these new macros:
    
            DEFINE_EARLY_PER_CPU(_type, _name, _initvalue)
            EXPORT_EARLY_PER_CPU_SYMBOL(_name)
            DECLARE_EARLY_PER_CPU(_type, _name)
    
            early_per_cpu_ptr(_name)
            early_per_cpu_map(_name, _idx)
            early_per_cpu(_name, _cpu)
    
        The DEFINE macro defines the per_cpu variable as well as the early
        map and pointer.  It also initializes the per_cpu variable and map
        elements to "_initvalue".  The early_* macros provide access to
        the initial map (usually setup during system init) and the early
        pointer.  This pointer is initialized to point to the early map
        but is then NULL'ed when the actual per_cpu areas are setup.  After
        that the per_cpu variable is the correct access to the variable.
    
        The early_per_cpu() macro is not very efficient but does show how to
        access the variable if you have a function that can be called both
        "early" and "late".  It tests the early ptr to be NULL, and if not
        then it's still valid.  Otherwise, the per_cpu variable is used
        instead:
    
            #define early_per_cpu(_name, _cpu)                      \
                    (early_per_cpu_ptr(_name) ?                     \
                            early_per_cpu_ptr(_name)[_cpu] :        \
                            per_cpu(_name, _cpu))
    
        A better method is to actually check the pointer manually.  In the
        case below, numa_set_node can be called both "early" and "late":
    
            void __cpuinit numa_set_node(int cpu, int node)
            {
                int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
    
                if (cpu_to_node_map)
                        cpu_to_node_map[cpu] = node;
                else
                        per_cpu(x86_cpu_to_node_map, cpu) = node;
            }
    
      * Add a flag "arch_provides_topology_pointers" that indicates pointers
        to topology cpumask_t maps are available.  Otherwise, use the function
        returning the cpumask_t value.  This is useful if cpumask_t set size
        is very large to avoid copying data on to/off of the stack.
    
      * The coverage of CONFIG_DEBUG_PER_CPU_MAPS has been increased while
        the non-debug case has been optimized a bit.
    
      * Remove an unreferenced compiler warning in drivers/base/topology.c
    
      * Clean up #ifdef in setup.c
    
    For inclusion into sched-devel/latest tree.
    
    Based on:
            git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git
        +   sched-devel/latest  .../mingo/linux-2.6-sched-devel.git
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6f80b852a196..03caa8e4351f 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -19,13 +19,23 @@ unsigned disabled_cpus __cpuinitdata;
 unsigned int boot_cpu_physical_apicid = -1U;
 EXPORT_SYMBOL(boot_cpu_physical_apicid);
 
-DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;
-EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
-
 /* Bitmask of physically existing CPUs */
 physid_mask_t phys_cpu_present_map;
 #endif
 
+/* map cpu index to physical APIC ID */
+DEFINE_EARLY_PER_CPU(u16, x86_cpu_to_apicid, BAD_APICID);
+DEFINE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid, BAD_APICID);
+EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_apicid);
+EXPORT_EARLY_PER_CPU_SYMBOL(x86_bios_cpu_apicid);
+
+#if defined(CONFIG_NUMA) && defined(CONFIG_X86_64)
+#define	X86_64_NUMA	1
+
+DEFINE_EARLY_PER_CPU(int, x86_cpu_to_node_map, NUMA_NO_NODE);
+EXPORT_EARLY_PER_CPU_SYMBOL(x86_cpu_to_node_map);
+#endif
+
 #if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_X86_SMP)
 /*
  * Copy data used in early init routines from the initial arrays to the
@@ -37,20 +47,21 @@ static void __init setup_per_cpu_maps(void)
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-		per_cpu(x86_cpu_to_apicid, cpu) = x86_cpu_to_apicid_init[cpu];
+		per_cpu(x86_cpu_to_apicid, cpu) =
+				early_per_cpu_map(x86_cpu_to_apicid, cpu);
 		per_cpu(x86_bios_cpu_apicid, cpu) =
-						x86_bios_cpu_apicid_init[cpu];
-#ifdef CONFIG_NUMA
+				early_per_cpu_map(x86_bios_cpu_apicid, cpu);
+#ifdef X86_64_NUMA
 		per_cpu(x86_cpu_to_node_map, cpu) =
-						x86_cpu_to_node_map_init[cpu];
+				early_per_cpu_map(x86_cpu_to_node_map, cpu);
 #endif
 	}
 
 	/* indicate the early static arrays will soon be gone */
-	x86_cpu_to_apicid_early_ptr = NULL;
-	x86_bios_cpu_apicid_early_ptr = NULL;
-#ifdef CONFIG_NUMA
-	x86_cpu_to_node_map_early_ptr = NULL;
+	early_per_cpu_ptr(x86_cpu_to_apicid) = NULL;
+	early_per_cpu_ptr(x86_bios_cpu_apicid) = NULL;
+#ifdef X86_64_NUMA
+	early_per_cpu_ptr(x86_cpu_to_node_map) = NULL;
 #endif
 }
 
@@ -109,7 +120,8 @@ void __init setup_per_cpu_areas(void)
 		if (!node_online(node) || !NODE_DATA(node)) {
 			ptr = alloc_bootmem_pages(size);
 			printk(KERN_INFO
-			       "cpu %d has no node or node-local memory\n", i);
+			       "cpu %d has no node %d or node-local memory\n",
+				i, node);
 		}
 		else
 			ptr = alloc_bootmem_pages_node(NODE_DATA(node), size);
@@ -137,3 +149,63 @@ void __init setup_per_cpu_areas(void)
 }
 
 #endif
+
+#ifdef X86_64_NUMA
+void __cpuinit numa_set_node(int cpu, int node)
+{
+	int *cpu_to_node_map = early_per_cpu_ptr(x86_cpu_to_node_map);
+
+	if (cpu_to_node_map)
+		cpu_to_node_map[cpu] = node;
+
+	else if (per_cpu_offset(cpu))
+		per_cpu(x86_cpu_to_node_map, cpu) = node;
+
+	else
+		Dprintk(KERN_INFO "Setting node for non-present cpu %d\n", cpu);
+}
+
+void __cpuinit numa_clear_node(int cpu)
+{
+	numa_set_node(cpu, NUMA_NO_NODE);
+}
+
+void __cpuinit numa_add_cpu(int cpu)
+{
+	cpu_set(cpu, node_to_cpumask_map[early_cpu_to_node(cpu)]);
+}
+
+void __cpuinit numa_remove_cpu(int cpu)
+{
+	cpu_clear(cpu, node_to_cpumask_map[cpu_to_node(cpu)]);
+}
+#endif /* CONFIG_NUMA */
+
+#if defined(CONFIG_DEBUG_PER_CPU_MAPS) && defined(CONFIG_X86_64)
+
+int cpu_to_node(int cpu)
+{
+	if (early_per_cpu_ptr(x86_cpu_to_node_map)) {
+		printk(KERN_WARNING
+			"cpu_to_node(%d): usage too early!\n", cpu);
+		dump_stack();
+		return early_per_cpu_ptr(x86_cpu_to_node_map)[cpu];
+	}
+	return per_cpu(x86_cpu_to_node_map, cpu);
+}
+EXPORT_SYMBOL(cpu_to_node);
+
+int early_cpu_to_node(int cpu)
+{
+	if (early_per_cpu_ptr(x86_cpu_to_node_map))
+		return early_per_cpu_ptr(x86_cpu_to_node_map)[cpu];
+
+	if (!per_cpu_offset(cpu)) {
+		printk(KERN_WARNING
+			"early_cpu_to_node(%d): no per_cpu area!\n", cpu);
+			dump_stack();
+		return NUMA_NO_NODE;
+	}
+	return per_cpu(x86_cpu_to_node_map, cpu);
+}
+#endif

commit 8c5beb50d3ec915d15c4d38aa37282309a65f14e
Author: Huang, Ying <ying.huang@intel.com>
Date:   Wed Jun 11 11:33:39 2008 +0800

    x86 boot: pass E820 memory map entries more than 128 via linked list of setup data
    
    Because of the size limits of struct boot_params (zero page), the
    maximum number of E820 memory map entries can be passed to kernel is
    128. As pointed by Paul Jackson, there is some machine produced by SGI
    with so many nodes that the number of E820 memory map entries is more
    than 128. To enabling Linux kernel on these system, a new setup data
    type named SETUP_E820_EXT is defined to pass additional memory map
    entries to Linux kernel.
    
    This patch is based on x86/auto-latest branch of git-x86 tree and has
    been tested on x86_64 and i386 platform.
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 45a5e247d450..5b0de38cde48 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -150,6 +150,9 @@ void __init parse_setup_data(void)
 	while (pa_data) {
 		data = early_ioremap(pa_data, PAGE_SIZE);
 		switch (data->type) {
+		case SETUP_E820_EXT:
+			parse_e820_ext(data, pa_data);
+			break;
 		default:
 			break;
 		}

commit e0da33646826b66ef933d47ea2fb7a693fd849bf
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Sun Jun 8 18:29:22 2008 -0700

    x86: introduce max_physical_apicid for bigsmp switching
    
    a multi-socket test-system with 3 or 4 ioapics, when 4 dualcore cpus or
    2 quadcore cpus installed, needs to switch to bigsmp or physflat.
    
    CPU apic id is [4,11] instead of [0,7], and we need to check max apic
    id instead of cpu numbers.
    
    also add check for 32 bit when acpi is not compiled in or acpi=off.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0a281f2c7157..45a5e247d450 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -17,6 +17,7 @@ unsigned int num_processors;
 unsigned disabled_cpus __cpuinitdata;
 /* Processor that is doing the boot up */
 unsigned int boot_cpu_physical_apicid = -1U;
+unsigned int max_physical_apicid;
 EXPORT_SYMBOL(boot_cpu_physical_apicid);
 
 DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;

commit c45a707dbe35cb9aa6490223e5b1129fa3583948
Author: Huang, Ying <ying.huang@intel.com>
Date:   Mon Jun 2 14:26:25 2008 +0800

    x86: linked list of setup_data for i386
    
    This patch adds linked list of struct setup_data supported for i386.
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Cc: andi@firstfloor.org
    Cc: mingo@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 6f80b852a196..0a281f2c7157 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -137,3 +137,25 @@ void __init setup_per_cpu_areas(void)
 }
 
 #endif
+
+void __init parse_setup_data(void)
+{
+	struct setup_data *data;
+	u64 pa_data;
+
+	if (boot_params.hdr.version < 0x0209)
+		return;
+	pa_data = boot_params.hdr.setup_data;
+	while (pa_data) {
+		data = early_ioremap(pa_data, PAGE_SIZE);
+		switch (data->type) {
+		default:
+			break;
+		}
+#ifndef CONFIG_DEBUG_BOOT_PARAMS
+		free_early(pa_data, pa_data+sizeof(*data)+data->len);
+#endif
+		pa_data = data->next;
+		early_iounmap(data, PAGE_SIZE);
+	}
+}

commit f8955ebe3ea85a9d3ff2685ee64386fd34434cf3
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Sat May 10 09:01:48 2008 -0500

    x86: [VOYAGER] fix duplicate phys_cpu_present_map symbol
    
    The phys_cpu_present_map is an expected symbol in the SMP harness.
    Unfortunately, x86 recently moved this and a few others to
    kernel/setup.c where it doesn't quite work because voyager has to
    define its own.  Use CONFIG_X86_LOCAL_APIC to isolate these
    definitions and fix up another area in setup.c where CONFIG_X86_SMP
    should be used instead of CONFIG_SMP.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: toralf.foerster@gmx.de
    Cc: Mike Travis <travis@sgi.com>
    Cc: Alexey Starikovskiy <astarikovskiy@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c0c68c18a788..6f80b852a196 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -12,6 +12,7 @@
 #include <asm/mpspec.h>
 #include <asm/apicdef.h>
 
+#ifdef CONFIG_X86_LOCAL_APIC
 unsigned int num_processors;
 unsigned disabled_cpus __cpuinitdata;
 /* Processor that is doing the boot up */
@@ -23,8 +24,9 @@ EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
 
 /* Bitmask of physically existing CPUs */
 physid_mask_t phys_cpu_present_map;
+#endif
 
-#if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_SMP)
+#if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_X86_SMP)
 /*
  * Copy data used in early init routines from the initial arrays to the
  * per cpu data areas.  These arrays then become expendable and the

commit 5ecddcebfb7c737fe36494c77bd99ad045eab5ae
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 8 16:38:11 2008 +0200

    x86: revert printk format warning change which is for linux-next
    
    commit 62179849b40aded9e727cca5006627a1c4d6446e
        x86: fix setup printk format warning
    
    is for linux-next and not for .26
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cc6f5eb20b24..c0c68c18a788 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -95,7 +95,7 @@ void __init setup_per_cpu_areas(void)
 
 	/* Copy section for each CPU (we discard the original) */
 	size = PERCPU_ENOUGH_ROOM;
-	printk(KERN_INFO "PERCPU: Allocating %zd bytes of per cpu data\n",
+	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
 			  size);
 
 	for_each_possible_cpu(i) {

commit 62179849b40aded9e727cca5006627a1c4d6446e
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Fri May 2 13:32:35 2008 -0700

    x86: fix setup printk format warning
    
    Fix x86 setup printk format warming:
    
    next-20080430/arch/x86/kernel/setup.c:172: warning: format '%lu' expects type 'long unsigned int', but argument 2 has type 'ssize_t'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: mingo@elte.hu
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c0c68c18a788..cc6f5eb20b24 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -95,7 +95,7 @@ void __init setup_per_cpu_areas(void)
 
 	/* Copy section for each CPU (we discard the original) */
 	size = PERCPU_ENOUGH_ROOM;
-	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
+	printk(KERN_INFO "PERCPU: Allocating %zd bytes of per cpu data\n",
 			  size);
 
 	for_each_possible_cpu(i) {

commit 4d33bdb7688de7a61859dafc783eb9b6bca279fc
Author: Alexey Starikovskiy <astarikovskiy@suse.de>
Date:   Mon Apr 21 13:31:55 2008 +0400

    x86: Drop duplicate from setup.c
    
    Signed-off-by: Alexey Starikovskiy <astarikovskiy@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 0d1f44ae6eea..c0c68c18a788 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -18,8 +18,6 @@ unsigned disabled_cpus __cpuinitdata;
 unsigned int boot_cpu_physical_apicid = -1U;
 EXPORT_SYMBOL(boot_cpu_physical_apicid);
 
-physid_mask_t phys_cpu_present_map;
-
 DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;
 EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
 

commit 9f0e8d0400d925c3acd5f4e01dbeb736e4011882
Author: Mike Travis <travis@sgi.com>
Date:   Fri Apr 4 18:11:01 2008 -0700

    x86: convert cpumask_of_cpu macro to allocated array
    
      * Here is a simple patch to use an allocated array of cpumasks to
        represent cpumask_of_cpu() instead of constructing one on the stack.
        It's based on the Kconfig option "HAVE_CPUMASK_OF_CPU_MAP" which is
        currently only set for x86_64 SMP.  Otherwise the the existing
        cpumask_of_cpu() is used but has been changed to produce an lvalue
        so a pointer to it can be used.
    
    Cc: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index ed157c90412e..0d1f44ae6eea 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -54,6 +54,24 @@ static void __init setup_per_cpu_maps(void)
 #endif
 }
 
+#ifdef CONFIG_HAVE_CPUMASK_OF_CPU_MAP
+cpumask_t *cpumask_of_cpu_map __read_mostly;
+EXPORT_SYMBOL(cpumask_of_cpu_map);
+
+/* requires nr_cpu_ids to be initialized */
+static void __init setup_cpumask_of_cpu(void)
+{
+	int i;
+
+	/* alloc_bootmem zeroes memory */
+	cpumask_of_cpu_map = alloc_bootmem_low(sizeof(cpumask_t) * nr_cpu_ids);
+	for (i = 0; i < nr_cpu_ids; i++)
+		cpu_set(i, cpumask_of_cpu_map[i]);
+}
+#else
+static inline void setup_cpumask_of_cpu(void) { }
+#endif
+
 #ifdef CONFIG_X86_32
 /*
  * Great future not-so-futuristic plan: make i386 and x86_64 do it
@@ -70,7 +88,7 @@ EXPORT_SYMBOL(__per_cpu_offset);
  */
 void __init setup_per_cpu_areas(void)
 {
-	int i;
+	int i, highest_cpu = 0;
 	unsigned long size;
 
 #ifdef CONFIG_HOTPLUG_CPU
@@ -104,10 +122,18 @@ void __init setup_per_cpu_areas(void)
 		__per_cpu_offset[i] = ptr - __per_cpu_start;
 #endif
 		memcpy(ptr, __per_cpu_start, __per_cpu_end - __per_cpu_start);
+
+		highest_cpu = i;
 	}
 
+	nr_cpu_ids = highest_cpu + 1;
+	printk(KERN_DEBUG "NR_CPUS: %d, nr_cpu_ids: %d\n", NR_CPUS, nr_cpu_ids);
+
 	/* Setup percpu data maps */
 	setup_per_cpu_maps();
+
+	/* Setup cpumask_of_cpu map */
+	setup_cpumask_of_cpu();
 }
 
 #endif

commit 2fe60147570231cde0d1f14711d2e34ccdf54b65
Author: Alexey Starikovskiy <astarikovskiy@suse.de>
Date:   Fri Apr 4 23:41:44 2008 +0400

    x86: move up & smp variables to setup.c
    
    Signed-off-by: Alexey Starikovskiy <astarikovskiy@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 011fcdd213ff..ed157c90412e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -12,6 +12,14 @@
 #include <asm/mpspec.h>
 #include <asm/apicdef.h>
 
+unsigned int num_processors;
+unsigned disabled_cpus __cpuinitdata;
+/* Processor that is doing the boot up */
+unsigned int boot_cpu_physical_apicid = -1U;
+EXPORT_SYMBOL(boot_cpu_physical_apicid);
+
+physid_mask_t phys_cpu_present_map;
+
 DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;
 EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
 

commit 0fc0906e59df1427d194b78376d15ca48079f6bf
Author: Alexey Starikovskiy <astarikovskiy@suse.de>
Date:   Fri Apr 4 23:40:48 2008 +0400

    x86: move phys_cpu_present_map to setup.c
    
    Signed-off-by: Alexey Starikovskiy <astarikovskiy@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 01119d9b013e..011fcdd213ff 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -9,11 +9,15 @@
 #include <asm/processor.h>
 #include <asm/setup.h>
 #include <asm/topology.h>
+#include <asm/mpspec.h>
 #include <asm/apicdef.h>
 
 DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;
 EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
 
+/* Bitmask of physically existing CPUs */
+physid_mask_t phys_cpu_present_map;
+
 #if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_SMP)
 /*
  * Copy data used in early init routines from the initial arrays to the

commit 76eb41319d6ab98d17c81a8001a6d7ed9f8359ee
Author: Alexey Starikovskiy <astarikovskiy@suse.de>
Date:   Fri Apr 4 23:40:41 2008 +0400

    x86: move x86_cpu_to_apicid to setup.c
    
    Signed-off-by: Alexey Starikovskiy <astarikovskiy@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index dc7940955b7a..01119d9b013e 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -9,6 +9,10 @@
 #include <asm/processor.h>
 #include <asm/setup.h>
 #include <asm/topology.h>
+#include <asm/apicdef.h>
+
+DEFINE_PER_CPU(u16, x86_cpu_to_apicid) = BAD_APICID;
+EXPORT_PER_CPU_SYMBOL(x86_cpu_to_apicid);
 
 #if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_SMP)
 /*

commit b447a468fcd130aa8951672b6115c673c274e888
Author: Mike Travis <travis@sgi.com>
Date:   Tue Mar 25 15:06:51 2008 -0700

    x86: clean up non-smp usage of cpu maps
    
    Cleanup references to the early cpu maps for the non-SMP configuration
    and remove some functions called for SMP configurations only.
    
    Cc: Andi Kleen <ak@suse.de>
    Cc: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 1179aa06cdbf..dc7940955b7a 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -10,7 +10,7 @@
 #include <asm/setup.h>
 #include <asm/topology.h>
 
-#ifdef CONFIG_HAVE_SETUP_PER_CPU_AREA
+#if defined(CONFIG_HAVE_SETUP_PER_CPU_AREA) && defined(CONFIG_SMP)
 /*
  * Copy data used in early init routines from the initial arrays to the
  * per cpu data areas.  These arrays then become expendable and the
@@ -21,21 +21,12 @@ static void __init setup_per_cpu_maps(void)
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-#ifdef CONFIG_SMP
-		if (per_cpu_offset(cpu)) {
-#endif
-			per_cpu(x86_cpu_to_apicid, cpu) =
-						x86_cpu_to_apicid_init[cpu];
-			per_cpu(x86_bios_cpu_apicid, cpu) =
+		per_cpu(x86_cpu_to_apicid, cpu) = x86_cpu_to_apicid_init[cpu];
+		per_cpu(x86_bios_cpu_apicid, cpu) =
 						x86_bios_cpu_apicid_init[cpu];
 #ifdef CONFIG_NUMA
-			per_cpu(x86_cpu_to_node_map, cpu) =
+		per_cpu(x86_cpu_to_node_map, cpu) =
 						x86_cpu_to_node_map_init[cpu];
-#endif
-#ifdef CONFIG_SMP
-		} else
-			printk(KERN_NOTICE "per_cpu_offset zero for cpu %d\n",
-									cpu);
 #endif
 	}
 
@@ -72,17 +63,20 @@ void __init setup_per_cpu_areas(void)
 
 	/* Copy section for each CPU (we discard the original) */
 	size = PERCPU_ENOUGH_ROOM;
-
 	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
 			  size);
-	for_each_cpu_mask(i, cpu_possible_map) {
+
+	for_each_possible_cpu(i) {
 		char *ptr;
 #ifndef CONFIG_NEED_MULTIPLE_NODES
 		ptr = alloc_bootmem_pages(size);
 #else
 		int node = early_cpu_to_node(i);
-		if (!node_online(node) || !NODE_DATA(node))
+		if (!node_online(node) || !NODE_DATA(node)) {
 			ptr = alloc_bootmem_pages(size);
+			printk(KERN_INFO
+			       "cpu %d has no node or node-local memory\n", i);
+		}
 		else
 			ptr = alloc_bootmem_pages_node(NODE_DATA(node), size);
 #endif
@@ -96,7 +90,7 @@ void __init setup_per_cpu_areas(void)
 		memcpy(ptr, __per_cpu_start, __per_cpu_end - __per_cpu_start);
 	}
 
-	/* setup percpu data maps early */
+	/* Setup percpu data maps */
 	setup_per_cpu_maps();
 }
 

commit 4fe29a85642544503cf81e9cf251ef0f4e65b162
Author: Glauber de Oliveira Costa <gcosta@redhat.com>
Date:   Wed Mar 19 14:25:23 2008 -0300

    x86: use specialized routine for setup per-cpu area
    
    We use the same routing as x86_64, moved now to setup.c.
    Just with a few ifdefs inside.
    Note that this routing uses prefill_possible_map().
    It has the very nice side effect of allowing hotplugging of
    cpus that are marked as present but disabled by acpi bios.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
new file mode 100644
index 000000000000..1179aa06cdbf
--- /dev/null
+++ b/arch/x86/kernel/setup.c
@@ -0,0 +1,103 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <linux/percpu.h>
+#include <asm/smp.h>
+#include <asm/percpu.h>
+#include <asm/sections.h>
+#include <asm/processor.h>
+#include <asm/setup.h>
+#include <asm/topology.h>
+
+#ifdef CONFIG_HAVE_SETUP_PER_CPU_AREA
+/*
+ * Copy data used in early init routines from the initial arrays to the
+ * per cpu data areas.  These arrays then become expendable and the
+ * *_early_ptr's are zeroed indicating that the static arrays are gone.
+ */
+static void __init setup_per_cpu_maps(void)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+#ifdef CONFIG_SMP
+		if (per_cpu_offset(cpu)) {
+#endif
+			per_cpu(x86_cpu_to_apicid, cpu) =
+						x86_cpu_to_apicid_init[cpu];
+			per_cpu(x86_bios_cpu_apicid, cpu) =
+						x86_bios_cpu_apicid_init[cpu];
+#ifdef CONFIG_NUMA
+			per_cpu(x86_cpu_to_node_map, cpu) =
+						x86_cpu_to_node_map_init[cpu];
+#endif
+#ifdef CONFIG_SMP
+		} else
+			printk(KERN_NOTICE "per_cpu_offset zero for cpu %d\n",
+									cpu);
+#endif
+	}
+
+	/* indicate the early static arrays will soon be gone */
+	x86_cpu_to_apicid_early_ptr = NULL;
+	x86_bios_cpu_apicid_early_ptr = NULL;
+#ifdef CONFIG_NUMA
+	x86_cpu_to_node_map_early_ptr = NULL;
+#endif
+}
+
+#ifdef CONFIG_X86_32
+/*
+ * Great future not-so-futuristic plan: make i386 and x86_64 do it
+ * the same way
+ */
+unsigned long __per_cpu_offset[NR_CPUS] __read_mostly;
+EXPORT_SYMBOL(__per_cpu_offset);
+#endif
+
+/*
+ * Great future plan:
+ * Declare PDA itself and support (irqstack,tss,pgd) as per cpu data.
+ * Always point %gs to its beginning
+ */
+void __init setup_per_cpu_areas(void)
+{
+	int i;
+	unsigned long size;
+
+#ifdef CONFIG_HOTPLUG_CPU
+	prefill_possible_map();
+#endif
+
+	/* Copy section for each CPU (we discard the original) */
+	size = PERCPU_ENOUGH_ROOM;
+
+	printk(KERN_INFO "PERCPU: Allocating %lu bytes of per cpu data\n",
+			  size);
+	for_each_cpu_mask(i, cpu_possible_map) {
+		char *ptr;
+#ifndef CONFIG_NEED_MULTIPLE_NODES
+		ptr = alloc_bootmem_pages(size);
+#else
+		int node = early_cpu_to_node(i);
+		if (!node_online(node) || !NODE_DATA(node))
+			ptr = alloc_bootmem_pages(size);
+		else
+			ptr = alloc_bootmem_pages_node(NODE_DATA(node), size);
+#endif
+		if (!ptr)
+			panic("Cannot allocate cpu data for CPU %d\n", i);
+#ifdef CONFIG_X86_64
+		cpu_pda(i)->data_offset = ptr - __per_cpu_start;
+#else
+		__per_cpu_offset[i] = ptr - __per_cpu_start;
+#endif
+		memcpy(ptr, __per_cpu_start, __per_cpu_end - __per_cpu_start);
+	}
+
+	/* setup percpu data maps early */
+	setup_per_cpu_maps();
+}
+
+#endif
