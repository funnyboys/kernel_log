commit 9c3b1f4975c46fc2932fd6d53e63c14f0ddf985f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:42 2020 +0200

    x86/entry: Convert KVM vectors to IDTENTRY_SYSVEC*
    
    Convert KVM specific system vectors to IDTENTRY_SYSVEC*:
    
    The two empty stub handlers which only increment the stats counter do no
    need to run on the interrupt stack. Use IDTENTRY_SYSVEC_SIMPLE for them.
    
    The wakeup handler does more work and runs on the interrupt stack.
    
    None of these handlers need to save and restore the irq_regs pointer.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202119.555715519@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 7e3005274f83..181060247e3c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -298,41 +298,29 @@ EXPORT_SYMBOL_GPL(kvm_set_posted_intr_wakeup_handler);
 /*
  * Handler for POSTED_INTERRUPT_VECTOR.
  */
-__visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
+DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_kvm_posted_intr_ipi)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
-
-	entering_ack_irq();
+	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_ipis);
-	exiting_irq();
-	set_irq_regs(old_regs);
 }
 
 /*
  * Handler for POSTED_INTERRUPT_WAKEUP_VECTOR.
  */
-__visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
+DEFINE_IDTENTRY_SYSVEC(sysvec_kvm_posted_intr_wakeup_ipi)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
-
-	entering_ack_irq();
+	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_wakeup_ipis);
 	kvm_posted_intr_wakeup_handler();
-	exiting_irq();
-	set_irq_regs(old_regs);
 }
 
 /*
  * Handler for POSTED_INTERRUPT_NESTED_VECTOR.
  */
-__visible void smp_kvm_posted_intr_nested_ipi(struct pt_regs *regs)
+DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_kvm_posted_intr_nested_ipi)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
-
-	entering_ack_irq();
+	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_nested_ipis);
-	exiting_irq();
-	set_irq_regs(old_regs);
 }
 #endif
 

commit db0338eec5836eea3bd1b274212234d04bac2034
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:39 2020 +0200

    x86/entry: Convert APIC interrupts to IDTENTRY_SYSVEC
    
    Convert APIC interrupts to IDTENTRY_SYSVEC:
    
      - Implement the C entry point with DEFINE_IDTENTRY_SYSVEC
      - Emit the ASM stub with DECLARE_IDTENTRY_SYSVEC
      - Remove the ASM idtentries in 64-bit
      - Remove the BUILD_INTERRUPT entries in 32-bit
      - Remove the old prototypes
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202119.280728850@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c449b8434036..7e3005274f83 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -268,17 +268,16 @@ void (*x86_platform_ipi_callback)(void) = NULL;
 /*
  * Handler for X86_PLATFORM_IPI_VECTOR.
  */
-__visible void __irq_entry smp_x86_platform_ipi(struct pt_regs *regs)
+DEFINE_IDTENTRY_SYSVEC(sysvec_x86_platform_ipi)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	entering_ack_irq();
+	ack_APIC_irq();
 	trace_x86_platform_ipi_entry(X86_PLATFORM_IPI_VECTOR);
 	inc_irq_stat(x86_platform_ipis);
 	if (x86_platform_ipi_callback)
 		x86_platform_ipi_callback();
 	trace_x86_platform_ipi_exit(X86_PLATFORM_IPI_VECTOR);
-	exiting_irq();
 	set_irq_regs(old_regs);
 }
 #endif

commit fa5e5c409213265da8a188b4a5e4e641b1382eb4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:37 2020 +0200

    x86/entry: Use idtentry for interrupts
    
    Replace the extra interrupt handling code and reuse the existing idtentry
    machinery. This moves the irq stack switching on 64-bit from ASM to C code;
    32-bit already does the stack switching in C.
    
    This requires to remove HAVE_IRQ_EXIT_ON_IRQ_STACK as the stack switch is
    not longer in the low level entry code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202119.078690991@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 5495ea4debba..c449b8434036 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -20,6 +20,7 @@
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
 #include <asm/desc.h>
+#include <asm/traps.h>
 
 #define CREATE_TRACE_POINTS
 #include <asm/trace/irq_vectors.h>
@@ -232,37 +233,25 @@ static __always_inline void handle_irq(struct irq_desc *desc,
 }
 
 /*
- * do_IRQ handles all normal device IRQ's (the special
- * SMP cross-CPU interrupts have their own specific
- * handlers).
+ * common_interrupt() handles all normal device IRQ's (the special SMP
+ * cross-CPU interrupts have their own entry points).
  */
-__visible void __irq_entry do_IRQ(struct pt_regs *regs, unsigned long vector)
+DEFINE_IDTENTRY_IRQ(common_interrupt)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct irq_desc *desc;
 
-	entering_irq();
-	/*
-	 * The push in the entry ASM code which stores the vector number on
-	 * the stack in the error code slot is sign expanding. Just use the
-	 * lower 8 bits.
-	 */
-	vector &= 0xFF;
-
-	/* entering_irq() tells RCU that we're not quiescent.  Check it. */
+	/* entry code tells RCU that we're not quiescent.  Check it. */
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "IRQ failed to wake up RCU");
 
 	desc = __this_cpu_read(vector_irq[vector]);
 	if (likely(!IS_ERR_OR_NULL(desc))) {
-		if (IS_ENABLED(CONFIG_X86_32))
-			__handle_irq(desc, regs);
-		else
-			generic_handle_irq_desc(desc);
+		handle_irq(desc, regs);
 	} else {
 		ack_APIC_irq();
 
 		if (desc == VECTOR_UNUSED) {
-			pr_emerg_ratelimited("%s: %d.%lu No irq handler for vector\n",
+			pr_emerg_ratelimited("%s: %d.%u No irq handler for vector\n",
 					     __func__, smp_processor_id(),
 					     vector);
 		} else {
@@ -270,8 +259,6 @@ __visible void __irq_entry do_IRQ(struct pt_regs *regs, unsigned long vector)
 		}
 	}
 
-	exiting_irq();
-
 	set_irq_regs(old_regs);
 }
 

commit 7c2a57364cae0f2e070a27d728f1df6844ffff56
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:35 2020 +0200

    x86/irq: Rework handle_irq() for 64-bit
    
    To consolidate the interrupt entry/exit code vs. the other exceptions
    make handle_irq() an inline and handle both 64-bit and 32-bit mode.
    
    Preparatory change to move irq stack switching for 64-bit to C which allows
    to consolidate the entry exit handling by reusing the idtentry machinery
    both in ASM and C.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202118.889972748@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c7669363251a..5495ea4debba 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -13,6 +13,7 @@
 #include <linux/export.h>
 #include <linux/irq.h>
 
+#include <asm/irq_stack.h>
 #include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/irq.h>
@@ -221,6 +222,14 @@ u64 arch_irq_stat(void)
 	return sum;
 }
 
+static __always_inline void handle_irq(struct irq_desc *desc,
+				       struct pt_regs *regs)
+{
+	if (IS_ENABLED(CONFIG_X86_64))
+		run_on_irqstack_cond(desc->handle_irq, desc, regs);
+	else
+		__handle_irq(desc, regs);
+}
 
 /*
  * do_IRQ handles all normal device IRQ's (the special
@@ -246,7 +255,7 @@ __visible void __irq_entry do_IRQ(struct pt_regs *regs, unsigned long vector)
 	desc = __this_cpu_read(vector_irq[vector]);
 	if (likely(!IS_ERR_OR_NULL(desc))) {
 		if (IS_ENABLED(CONFIG_X86_32))
-			handle_irq(desc, regs);
+			__handle_irq(desc, regs);
 		else
 			generic_handle_irq_desc(desc);
 	} else {

commit 633260fa143bbed05e65dc557a492667dfdc45bb
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:34 2020 +0200

    x86/irq: Convey vector as argument and not in ptregs
    
    Device interrupts which go through do_IRQ() or the spurious interrupt
    handler have their separate entry code on 64 bit for no good reason.
    
    Both 32 and 64 bit transport the vector number through ORIG_[RE]AX in
    pt_regs. Further the vector number is forced to fit into an u8 and is
    complemented and offset by 0x80 so it's in the signed character
    range. Otherwise GAS would expand the pushq to a 5 byte instruction for any
    vector > 0x7F.
    
    Treat the vector number like an error code and hand it to the C function as
    argument. This allows to get rid of the extra entry code in a later step.
    
    Simplify the error code push magic by implementing the pushq imm8 via a
    '.byte 0x6a, vector' sequence so GAS is not able to screw it up. As the
    pushq imm8 is sign extending the resulting error code needs to be truncated
    to 8 bits in C code.
    
    Originally-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202118.796915981@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 252065d32ab5..c7669363251a 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -227,14 +227,18 @@ u64 arch_irq_stat(void)
  * SMP cross-CPU interrupts have their own specific
  * handlers).
  */
-__visible void __irq_entry do_IRQ(struct pt_regs *regs)
+__visible void __irq_entry do_IRQ(struct pt_regs *regs, unsigned long vector)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-	struct irq_desc * desc;
-	/* high bit used in ret_from_ code  */
-	unsigned vector = ~regs->orig_ax;
+	struct irq_desc *desc;
 
 	entering_irq();
+	/*
+	 * The push in the entry ASM code which stores the vector number on
+	 * the stack in the error code slot is sign expanding. Just use the
+	 * lower 8 bits.
+	 */
+	vector &= 0xFF;
 
 	/* entering_irq() tells RCU that we're not quiescent.  Check it. */
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "IRQ failed to wake up RCU");
@@ -249,7 +253,7 @@ __visible void __irq_entry do_IRQ(struct pt_regs *regs)
 		ack_APIC_irq();
 
 		if (desc == VECTOR_UNUSED) {
-			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector\n",
+			pr_emerg_ratelimited("%s: %d.%lu No irq handler for vector\n",
 					     __func__, smp_processor_id(),
 					     vector);
 		} else {

commit 79b9c183021ef3f5ca2d5168cd3fd442580eca09
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:33 2020 +0200

    x86/irq: Use generic irq_regs implementation
    
    The only difference is the name of the per-CPU variable: irq_regs
    vs. __irq_regs, but the accessor functions are identical.
    
    Remove the pointless copy and use the generic variant.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202118.704169051@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c7965ff429c5..252065d32ab5 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -26,9 +26,6 @@
 DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 EXPORT_PER_CPU_SYMBOL(irq_stat);
 
-DEFINE_PER_CPU(struct pt_regs *, irq_regs);
-EXPORT_PER_CPU_SYMBOL(irq_regs);
-
 atomic_t irq_err_count;
 
 /*

commit 17dbedb5da184b501c5c51fc78d1071005139e48
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 25 22:36:43 2020 +0100

    x86/irq: Remove useless return value from do_IRQ()
    
    Nothing is using it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexandre Chartre <alexandre.chartre@oracle.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20200225220216.826870369@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 21efee32e2b1..c7965ff429c5 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -230,7 +230,7 @@ u64 arch_irq_stat(void)
  * SMP cross-CPU interrupts have their own specific
  * handlers).
  */
-__visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
+__visible void __irq_entry do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct irq_desc * desc;
@@ -263,7 +263,6 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	exiting_irq();
 
 	set_irq_regs(old_regs);
-	return 1;
 }
 
 #ifdef CONFIG_X86_LOCAL_APIC

commit 8725fcd99a3084a7a15a6e70882bfa3fe7925f52
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Mon Aug 19 21:36:39 2019 +0200

    x86/irq: Check for VECTOR_UNUSED directly
    
    It's simpler and more intuitive to directly check for VECTOR_UNUSED than
    checking whether the other error codes are not set.
    
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/caeaca93-5ee1-cea1-8894-3aa0d5b19241@gmail.com

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3eae01202332..21efee32e2b1 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -251,7 +251,7 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	} else {
 		ack_APIC_irq();
 
-		if (desc != VECTOR_RETRIGGERED && desc != VECTOR_SHUTDOWN) {
+		if (desc == VECTOR_UNUSED) {
 			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector\n",
 					     __func__, smp_processor_id(),
 					     vector);

commit d6f83427ff422b3a65e4a6bd84c010f78d4a30a5
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Mon Aug 19 21:36:09 2019 +0200

    x86/irq: Move IS_ERR_OR_NULL() check into common do_IRQ() code
    
    Both the 64bit and the 32bit handle_irq() implementation check the irq
    descriptor pointer with IS_ERR_OR_NULL() and return failure. That can be
    done simpler in the common do_IRQ() code.
    
    This reduces the 64bit handle_irq() function to a wrapper around
    generic_handle_irq_desc(). Invoke it directly from do_IRQ() to spare the
    extra function call.
    
    [ tglx: Got rid of the #ifdef and massaged changelog ]
    
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/2ec758c7-9aaa-73ab-f083-cc44c86aa741@gmail.com

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4215653f8a8e..3eae01202332 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -243,8 +243,12 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "IRQ failed to wake up RCU");
 
 	desc = __this_cpu_read(vector_irq[vector]);
-
-	if (!handle_irq(desc, regs)) {
+	if (likely(!IS_ERR_OR_NULL(desc))) {
+		if (IS_ENABLED(CONFIG_X86_32))
+			handle_irq(desc, regs);
+		else
+			generic_handle_irq_desc(desc);
+	} else {
 		ack_APIC_irq();
 
 		if (desc != VECTOR_RETRIGGERED && desc != VECTOR_SHUTDOWN) {

commit 8faef7125d02c0bbd7a1ceb4e3b599a9b8c42e58
Merge: da1770238597 d97ee99bf225
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 17:49:45 2019 -0700

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 platform updayes from Ingo Molnar:
     "Most of the commits add ACRN hypervisor guest support, plus two
      cleanups"
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/jailhouse: Mark jailhouse_x2apic_available() as __init
      x86/platform/geode: Drop <linux/gpio.h> includes
      x86/acrn: Use HYPERVISOR_CALLBACK_VECTOR for ACRN guest upcall vector
      x86: Add support for Linux guests on an ACRN hypervisor
      x86/Kconfig: Add new X86_HV_CALLBACK_VECTOR config symbol

commit 0902d5011cfaabd6a09326299ef77e1c8735fb89
Merge: 927ba67a63c7 f8a8fe61fec8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 11:22:57 2019 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x96 apic updates from Thomas Gleixner:
     "Updates for the x86 APIC interrupt handling and APIC timer:
    
       - Fix a long standing issue with spurious interrupts which was caused
         by the big vector management rework a few years ago. Robert Hodaszi
         provided finally enough debug data and an excellent initial failure
         analysis which allowed to understand the underlying issues.
    
         This contains a change to the core interrupt management code which
         is required to handle this correctly for the APIC/IO_APIC. The core
         changes are NOOPs for most architectures except ARM64. ARM64 is not
         impacted by the change as confirmed by Marc Zyngier.
    
       - Newer systems allow to disable the PIT clock for power saving
         causing panic in the timer interrupt delivery check of the IO/APIC
         when the HPET timer is not enabled either. While the clock could be
         turned on this would cause an endless whack a mole game to chase
         the proper register in each affected chipset.
    
         These systems provide the relevant frequencies for TSC, CPU and the
         local APIC timer via CPUID and/or MSRs, which allows to avoid the
         PIT/HPET based calibration. As the calibration code is the only
         usage of the legacy timers on modern systems and is skipped anyway
         when the frequencies are known already, there is no point in
         setting up the PIT and actually checking for the interrupt delivery
         via IO/APIC.
    
         To achieve this on a wide variety of platforms, the CPUID/MSR based
         frequency readout has been made more robust, which also allowed to
         remove quite some workarounds which turned out to be not longer
         required. Thanks to Daniel Drake for analysis, patches and
         verification"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/irq: Seperate unused system vectors from spurious entry again
      x86/irq: Handle spurious interrupt after shutdown gracefully
      x86/ioapic: Implement irq_get_irqchip_state() callback
      genirq: Add optional hardware synchronization for shutdown
      genirq: Fix misleading synchronize_irq() documentation
      genirq: Delay deactivation in free_irq()
      x86/timer: Skip PIT initialization on modern chipsets
      x86/apic: Use non-atomic operations when possible
      x86/apic: Make apic_bsp_setup() static
      x86/tsc: Set LAPIC timer period to crystal clock frequency
      x86/apic: Rename 'lapic_timer_frequency' to 'lapic_timer_period'
      x86/tsc: Use CPUID.0x16 to calculate missing crystal frequency

commit b7107a67f0d125459fe41f86e8079afd1a5e0b15
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 28 13:11:53 2019 +0200

    x86/irq: Handle spurious interrupt after shutdown gracefully
    
    Since the rework of the vector management, warnings about spurious
    interrupts have been reported. Robert provided some more information and
    did an initial analysis. The following situation leads to these warnings:
    
       CPU 0                  CPU 1               IO_APIC
    
                                                  interrupt is raised
                                                  sent to CPU1
                              Unable to handle
                              immediately
                              (interrupts off,
                               deep idle delay)
       mask()
       ...
       free()
         shutdown()
         synchronize_irq()
         clear_vector()
                              do_IRQ()
                                -> vector is clear
    
    Before the rework the vector entries of legacy interrupts were statically
    assigned and occupied precious vector space while most of them were
    unused. Due to that the above situation was handled silently because the
    vector was handled and the core handler of the assigned interrupt
    descriptor noticed that it is shut down and returned.
    
    While this has been usually observed with legacy interrupts, this situation
    is not limited to them. Any other interrupt source, e.g. MSI, can cause the
    same issue.
    
    After adding proper synchronization for level triggered interrupts, this
    can only happen for edge triggered interrupts where the IO-APIC obviously
    cannot provide information about interrupts in flight.
    
    While the spurious warning is actually harmless in this case it worries
    users and driver developers.
    
    Handle it gracefully by marking the vector entry as VECTOR_SHUTDOWN instead
    of VECTOR_UNUSED when the vector is freed up.
    
    If that above late handling happens the spurious detector will not complain
    and switch the entry to VECTOR_UNUSED. Any subsequent spurious interrupt on
    that line will trigger the spurious warning as before.
    
    Fixes: 464d12309e1b ("x86/vector: Switch IOAPIC to global reservation mode")
    Reported-by: Robert Hodaszi <Robert.Hodaszi@digi.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>-
    Tested-by: Robert Hodaszi <Robert.Hodaszi@digi.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Link: https://lkml.kernel.org/r/20190628111440.459647741@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 59b5f2ea7c2f..a975246074b5 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -246,7 +246,7 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	if (!handle_irq(desc, regs)) {
 		ack_APIC_irq();
 
-		if (desc != VECTOR_RETRIGGERED) {
+		if (desc != VECTOR_RETRIGGERED && desc != VECTOR_SHUTDOWN) {
 			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector\n",
 					     __func__, smp_processor_id(),
 					     vector);

commit ecca25029473bee6e98ce062e76b7310904bbdd1
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Apr 30 11:45:23 2019 +0800

    x86/Kconfig: Add new X86_HV_CALLBACK_VECTOR config symbol
    
    Add a special Kconfig symbol X86_HV_CALLBACK_VECTOR so that the guests
    using the hypervisor interrupt callback counter can select and thus
    enable that counter. Select it when xen or hyperv support is enabled. No
    functional changes.
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Frederic Weisbecker <frederic@kernel.org>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: linux-hyperv@vger.kernel.org
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sasha Levin <sashal@kernel.org>
    Cc: Stefano Stabellini <sstabellini@kernel.org>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Cc: xen-devel@lists.xenproject.org
    Link: https://lkml.kernel.org/r/1559108037-18813-2-git-send-email-yakui.zhao@intel.com

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 9b68b5b00ac9..4e8f193ad81f 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -135,7 +135,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
 	seq_puts(p, "  Machine check polls\n");
 #endif
-#if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
+#ifdef CONFIG_X86_HV_CALLBACK_VECTOR
 	if (test_bit(HYPERVISOR_CALLBACK_VECTOR, system_vectors)) {
 		seq_printf(p, "%*s: ", prec, "HYP");
 		for_each_online_cpu(j)

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 59b5f2ea7c2f..9b68b5b00ac9 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Common interrupt code for 32 and 64 bit
  */

commit 447ae316670230d7d29430e2cbf1f5db4f49d14c
Author: Nicolai Stange <nstange@suse.de>
Date:   Sun Jul 29 12:15:33 2018 +0200

    x86: Don't include linux/irq.h from asm/hardirq.h
    
    The next patch in this series will have to make the definition of
    irq_cpustat_t available to entering_irq().
    
    Inclusion of asm/hardirq.h into asm/apic.h would cause circular header
    dependencies like
    
      asm/smp.h
        asm/apic.h
          asm/hardirq.h
            linux/irq.h
              linux/topology.h
                linux/smp.h
                  asm/smp.h
    
    or
    
      linux/gfp.h
        linux/mmzone.h
          asm/mmzone.h
            asm/mmzone_64.h
              asm/smp.h
                asm/apic.h
                  asm/hardirq.h
                    linux/irq.h
                      linux/irqdesc.h
                        linux/kobject.h
                          linux/sysfs.h
                            linux/kernfs.h
                              linux/idr.h
                                linux/gfp.h
    
    and others.
    
    This causes compilation errors because of the header guards becoming
    effective in the second inclusion: symbols/macros that had been defined
    before wouldn't be available to intermediate headers in the #include chain
    anymore.
    
    A possible workaround would be to move the definition of irq_cpustat_t
    into its own header and include that from both, asm/hardirq.h and
    asm/apic.h.
    
    However, this wouldn't solve the real problem, namely asm/harirq.h
    unnecessarily pulling in all the linux/irq.h cruft: nothing in
    asm/hardirq.h itself requires it. Also, note that there are some other
    archs, like e.g. arm64, which don't have that #include in their
    asm/hardirq.h.
    
    Remove the linux/irq.h #include from x86' asm/hardirq.h.
    
    Fix resulting compilation errors by adding appropriate #includes to *.c
    files as needed.
    
    Note that some of these *.c files could be cleaned up a bit wrt. to their
    set of #includes, but that should better be done from separate patches, if
    at all.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 328d027d829d..59b5f2ea7c2f 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -10,6 +10,7 @@
 #include <linux/ftrace.h>
 #include <linux/delay.h>
 #include <linux/export.h>
+#include <linux/irq.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>

commit 248e742a396e7f00b283f1c56e14b1bef6e3ec56
Author: Michael Kelley <mhkelley@outlook.com>
Date:   Sun Mar 4 22:17:18 2018 -0700

    Drivers: hv: vmbus: Implement Direct Mode for stimer0
    
    The 2016 version of Hyper-V offers the option to operate the guest VM
    per-vcpu stimer's in Direct Mode, which means the timer interupts on its
    own vector rather than queueing a VMbus message. Direct Mode reduces
    timer processing overhead in both the hypervisor and the guest, and
    avoids having timer interrupts pollute the VMbus interrupt stream for
    the synthetic NIC and storage.  This patch enables Direct Mode by
    default on stimer0 when running on a version of Hyper-V that supports
    it.
    
    In prep for coming support of Hyper-V on ARM64, the arch independent
    portion of the code contains calls to routines that will be populated
    on ARM64 but are not needed and do nothing on x86.
    
    Signed-off-by: Michael Kelley <mikelley@microsoft.com>
    Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 45fb4d2565f8..328d027d829d 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -150,6 +150,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 				   irq_stats(j)->irq_hv_reenlightenment_count);
 		seq_puts(p, "  Hyper-V reenlightenment interrupts\n");
 	}
+	if (test_bit(HYPERV_STIMER0_VECTOR, system_vectors)) {
+		seq_printf(p, "%*s: ", prec, "HVS");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ",
+				   irq_stats(j)->hyperv_stimer0_count);
+		seq_puts(p, "  Hyper-V stimer0 interrupts\n");
+	}
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 51d4e5daa32808df4d50db511d167fde19fa114e
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Wed Jan 24 14:23:35 2018 +0100

    x86/irq: Count Hyper-V reenlightenment interrupts
    
    Hyper-V reenlightenment interrupts arrive when the VM is migrated, While
    they are not interesting in general it's important when L2 nested guests
    are running.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: "Michael Kelley (EOSG)" <Michael.H.Kelley@microsoft.com>
    Cc: Roman Kagan <rkagan@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: devel@linuxdriverproject.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Cathy Avery <cavery@redhat.com>
    Cc: Mohammed Gamal <mmorsy@redhat.com>
    Link: https://lkml.kernel.org/r/20180124132337.30138-6-vkuznets@redhat.com

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 68e1867cca80..45fb4d2565f8 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -141,6 +141,15 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 				   irq_stats(j)->irq_hv_callback_count);
 		seq_puts(p, "  Hypervisor callback interrupts\n");
 	}
+#endif
+#if IS_ENABLED(CONFIG_HYPERV)
+	if (test_bit(HYPERV_REENLIGHTENMENT_VECTOR, system_vectors)) {
+		seq_printf(p, "%*s: ", prec, "HRE");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ",
+				   irq_stats(j)->irq_hv_reenlightenment_count);
+		seq_puts(p, "  Hyper-V reenlightenment interrupts\n");
+	}
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 64a48099b3b31568ac45716b7fafcb74a0c2fcfe
Merge: 1291a0d5049d 6cbd2171e89b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 18 08:59:15 2017 -0800

    Merge branch 'WIP.x86-pti.entry-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 syscall entry code changes for PTI from Ingo Molnar:
     "The main changes here are Andy Lutomirski's changes to switch the
      x86-64 entry code to use the 'per CPU entry trampoline stack'. This,
      besides helping fix KASLR leaks (the pending Page Table Isolation
      (PTI) work), also robustifies the x86 entry code"
    
    * 'WIP.x86-pti.entry-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (26 commits)
      x86/cpufeatures: Make CPU bugs sticky
      x86/paravirt: Provide a way to check for hypervisors
      x86/paravirt: Dont patch flush_tlb_single
      x86/entry/64: Make cpu_entry_area.tss read-only
      x86/entry: Clean up the SYSENTER_stack code
      x86/entry/64: Remove the SYSENTER stack canary
      x86/entry/64: Move the IST stacks into struct cpu_entry_area
      x86/entry/64: Create a per-CPU SYSCALL entry trampoline
      x86/entry/64: Return to userspace from the trampoline stack
      x86/entry/64: Use a per-CPU trampoline stack for IDT entries
      x86/espfix/64: Stop assuming that pt_regs is on the entry stack
      x86/entry/64: Separate cpu_current_top_of_stack from TSS.sp0
      x86/entry: Remap the TSS into the CPU entry area
      x86/entry: Move SYSENTER_stack to the beginning of struct tss_struct
      x86/dumpstack: Handle stack overflow on all stacks
      x86/entry: Fix assumptions that the HW TSS is at the beginning of cpu_tss
      x86/kasan/64: Teach KASAN about the cpu_entry_area
      x86/mm/fixmap: Generalize the GDT fixmap mechanism, introduce struct cpu_entry_area
      x86/entry/gdt: Put per-CPU GDT remaps in ascending order
      x86/dumpstack: Add get_stack_info() support for the SYSENTER stack
      ...

commit 6669a692605547892a026445e460bf233958bd7f
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:10 2017 +0100

    x86/irq: Remove an old outdated comment about context tracking races
    
    That race has been fixed and code cleaned up for a while now.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150605.150551639@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 52089c043160..aa9d51eea9d0 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -219,18 +219,6 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	/* high bit used in ret_from_ code  */
 	unsigned vector = ~regs->orig_ax;
 
-	/*
-	 * NB: Unlike exception entries, IRQ entries do not reliably
-	 * handle context tracking in the low-level entry code.  This is
-	 * because syscall entries execute briefly with IRQs on before
-	 * updating context tracking state, so we can take an IRQ from
-	 * kernel mode with CONTEXT_USER.  The low-level entry code only
-	 * updates the context if we came from user mode, so we won't
-	 * switch to CONTEXT_KERNEL.  We'll fix that once the syscall
-	 * code is cleaned up enough that we can cleanly defer enabling
-	 * IRQs.
-	 */
-
 	entering_irq();
 
 	/* entering_irq() tells RCU that we're not quiescent.  Check it. */

commit 2cffad7bad83157f89332872015f4305d2ac09ac
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:53 2017 +0200

    x86/irq: Simplify hotplug vector accounting
    
    Before a CPU is taken offline the number of active interrupt vectors on the
    outgoing CPU and the number of vectors which are available on the other
    online CPUs are counted and compared. If the active vectors are more than
    the available vectors on the other CPUs then the CPU hot-unplug operation
    is aborted. This again uses loop based search and is inaccurate.
    
    The bitmap matrix allocator has accurate accounting information and can
    tell exactly whether the vector space is sufficient or not.
    
    Emit a message when the number of globaly reserved (unallocated) vectors is
    larger than the number of available vectors after offlining a CPU because
    after that point request_irq() might fail.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213156.351193962@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 188990c3a514..49cfd9fe7589 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -333,105 +333,6 @@ __visible void smp_kvm_posted_intr_nested_ipi(struct pt_regs *regs)
 
 
 #ifdef CONFIG_HOTPLUG_CPU
-
-/* These two declarations are only used in check_irq_vectors_for_cpu_disable()
- * below, which is protected by stop_machine().  Putting them on the stack
- * results in a stack frame overflow.  Dynamically allocating could result in a
- * failure so declare these two cpumasks as global.
- */
-static struct cpumask affinity_new, online_new;
-
-/*
- * This cpu is going to be removed and its vectors migrated to the remaining
- * online cpus.  Check to see if there are enough vectors in the remaining cpus.
- * This function is protected by stop_machine().
- */
-int check_irq_vectors_for_cpu_disable(void)
-{
-	unsigned int this_cpu, vector, this_count, count;
-	struct irq_desc *desc;
-	struct irq_data *data;
-	int cpu;
-
-	this_cpu = smp_processor_id();
-	cpumask_copy(&online_new, cpu_online_mask);
-	cpumask_clear_cpu(this_cpu, &online_new);
-
-	this_count = 0;
-	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
-		desc = __this_cpu_read(vector_irq[vector]);
-		if (IS_ERR_OR_NULL(desc))
-			continue;
-		/*
-		 * Protect against concurrent action removal, affinity
-		 * changes etc.
-		 */
-		raw_spin_lock(&desc->lock);
-		data = irq_desc_get_irq_data(desc);
-		cpumask_copy(&affinity_new,
-			     irq_data_get_affinity_mask(data));
-		cpumask_clear_cpu(this_cpu, &affinity_new);
-
-		/* Do not count inactive or per-cpu irqs. */
-		if (!irq_desc_has_action(desc) || irqd_is_per_cpu(data)) {
-			raw_spin_unlock(&desc->lock);
-			continue;
-		}
-
-		raw_spin_unlock(&desc->lock);
-		/*
-		 * A single irq may be mapped to multiple cpu's
-		 * vector_irq[] (for example IOAPIC cluster mode).  In
-		 * this case we have two possibilities:
-		 *
-		 * 1) the resulting affinity mask is empty; that is
-		 * this the down'd cpu is the last cpu in the irq's
-		 * affinity mask, or
-		 *
-		 * 2) the resulting affinity mask is no longer a
-		 * subset of the online cpus but the affinity mask is
-		 * not zero; that is the down'd cpu is the last online
-		 * cpu in a user set affinity mask.
-		 */
-		if (cpumask_empty(&affinity_new) ||
-		    !cpumask_subset(&affinity_new, &online_new))
-			this_count++;
-	}
-	/* No need to check any further. */
-	if (!this_count)
-		return 0;
-
-	count = 0;
-	for_each_online_cpu(cpu) {
-		if (cpu == this_cpu)
-			continue;
-		/*
-		 * We scan from FIRST_EXTERNAL_VECTOR to first system
-		 * vector. If the vector is marked in the used vectors
-		 * bitmap or an irq is assigned to it, we don't count
-		 * it as available.
-		 *
-		 * As this is an inaccurate snapshot anyway, we can do
-		 * this w/o holding vector_lock.
-		 */
-		for (vector = FIRST_EXTERNAL_VECTOR;
-		     vector < FIRST_SYSTEM_VECTOR; vector++) {
-			if (!test_bit(vector, system_vectors) &&
-			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector])) {
-				if (++count == this_count)
-					return 0;
-			}
-		}
-	}
-
-	if (count < this_count) {
-		pr_warn("CPU %d disable failed: CPU has %u vectors assigned and there are only %u available.\n",
-			this_cpu, this_count, count);
-		return -ERANGE;
-	}
-	return 0;
-}
-
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)
 {

commit 7854f82293e99f6bb3df793a2f579db4670ba71b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:26 2017 +0200

    x86/vector: Rename used_vectors to system_vectors
    
    used_vectors is a nisnomer as it only has the system vectors which are
    excluded from the regular vector allocation marked. It's not what the name
    suggests storage for the actually used vectors.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213154.150209009@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 52089c043160..188990c3a514 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -134,7 +134,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_puts(p, "  Machine check polls\n");
 #endif
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
-	if (test_bit(HYPERVISOR_CALLBACK_VECTOR, used_vectors)) {
+	if (test_bit(HYPERVISOR_CALLBACK_VECTOR, system_vectors)) {
 		seq_printf(p, "%*s: ", prec, "HYP");
 		for_each_online_cpu(j)
 			seq_printf(p, "%10u ",
@@ -416,7 +416,7 @@ int check_irq_vectors_for_cpu_disable(void)
 		 */
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < FIRST_SYSTEM_VECTOR; vector++) {
-			if (!test_bit(vector, used_vectors) &&
+			if (!test_bit(vector, system_vectors) &&
 			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector])) {
 				if (++count == this_count)
 					return 0;

commit 0428e01a2f13a6b7dae8289fb10030dbea336dee
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 28 08:47:34 2017 +0200

    x86/ipi: Make platform IPI depend on APIC
    
    The platform IPI vector is only installed when the local APIC is enabled. All
    users of it depend on the local APIC anyway.
    
    Make the related code conditional on CONFIG_X86_LOCAL_APIC=y.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20170828064957.615286163@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index befdd4a54ecc..52089c043160 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -29,9 +29,6 @@ EXPORT_PER_CPU_SYMBOL(irq_regs);
 
 atomic_t irq_err_count;
 
-/* Function pointer for generic interrupt vector handling */
-void (*x86_platform_ipi_callback)(void) = NULL;
-
 /*
  * 'what should we do if we get a hw irq event on an illegal vector'.
  * each architecture has to answer this themselves.
@@ -87,13 +84,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->icr_read_retry_count);
 	seq_puts(p, "  APIC ICR read retries\n");
-#endif
 	if (x86_platform_ipi_callback) {
 		seq_printf(p, "%*s: ", prec, "PLT");
 		for_each_online_cpu(j)
 			seq_printf(p, "%10u ", irq_stats(j)->x86_platform_ipis);
 		seq_puts(p, "  Platform interrupts\n");
 	}
+#endif
 #ifdef CONFIG_SMP
 	seq_printf(p, "%*s: ", prec, "RES");
 	for_each_online_cpu(j)
@@ -183,9 +180,9 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->apic_perf_irqs;
 	sum += irq_stats(cpu)->apic_irq_work_irqs;
 	sum += irq_stats(cpu)->icr_read_retry_count;
-#endif
 	if (x86_platform_ipi_callback)
 		sum += irq_stats(cpu)->x86_platform_ipis;
+#endif
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;
 	sum += irq_stats(cpu)->irq_call_count;
@@ -259,6 +256,9 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	return 1;
 }
 
+#ifdef CONFIG_X86_LOCAL_APIC
+/* Function pointer for generic interrupt vector handling */
+void (*x86_platform_ipi_callback)(void) = NULL;
 /*
  * Handler for X86_PLATFORM_IPI_VECTOR.
  */
@@ -275,6 +275,7 @@ __visible void __irq_entry smp_x86_platform_ipi(struct pt_regs *regs)
 	exiting_irq();
 	set_irq_regs(old_regs);
 }
+#endif
 
 #ifdef CONFIG_HAVE_KVM
 static void dummy_handler(void) {}

commit 8a17116b1fddc1f414cd4dd5e86fa239fcdb5208
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 28 08:47:25 2017 +0200

    x86/irq: Get rid of duplicated trace_x86_platform_ipi() code
    
    Two NOP5s are really a good tradeoff vs. the unholy IDT switching mess,
    which duplicates code all over the place.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20170828064956.907209383@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 019d0ac8ed3a..befdd4a54ecc 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -262,20 +262,16 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 /*
  * Handler for X86_PLATFORM_IPI_VECTOR.
  */
-void __smp_x86_platform_ipi(void)
-{
-	inc_irq_stat(x86_platform_ipis);
-
-	if (x86_platform_ipi_callback)
-		x86_platform_ipi_callback();
-}
-
 __visible void __irq_entry smp_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_ack_irq();
-	__smp_x86_platform_ipi();
+	trace_x86_platform_ipi_entry(X86_PLATFORM_IPI_VECTOR);
+	inc_irq_stat(x86_platform_ipis);
+	if (x86_platform_ipi_callback)
+		x86_platform_ipi_callback();
+	trace_x86_platform_ipi_exit(X86_PLATFORM_IPI_VECTOR);
 	exiting_irq();
 	set_irq_regs(old_regs);
 }
@@ -334,17 +330,6 @@ __visible void smp_kvm_posted_intr_nested_ipi(struct pt_regs *regs)
 }
 #endif
 
-__visible void __irq_entry smp_trace_x86_platform_ipi(struct pt_regs *regs)
-{
-	struct pt_regs *old_regs = set_irq_regs(regs);
-
-	entering_ack_irq();
-	trace_x86_platform_ipi_entry(X86_PLATFORM_IPI_VECTOR);
-	__smp_x86_platform_ipi();
-	trace_x86_platform_ipi_exit(X86_PLATFORM_IPI_VECTOR);
-	exiting_irq();
-	set_irq_regs(old_regs);
-}
 
 #ifdef CONFIG_HOTPLUG_CPU
 

commit 05161b9cbe553c41cf775ac41bb5120d94347e5c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 28 08:47:18 2017 +0200

    x86/irq: Get rid of the 'first_system_vector' indirection bogosity
    
    This variable is beyond pointless. Nothing allocates a vector via
    alloc_gate() below FIRST_SYSTEM_VECTOR. So nothing can change
    first_system_vector.
    
    If there is a need for a gate below FIRST_SYSTEM_VECTOR then it can be
    added to the vector defines and FIRST_SYSTEM_VECTOR can be adjusted
    accordingly.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20170828064956.357109735@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e6073a0ce77e..019d0ac8ed3a 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -429,7 +429,7 @@ int check_irq_vectors_for_cpu_disable(void)
 		 * this w/o holding vector_lock.
 		 */
 		for (vector = FIRST_EXTERNAL_VECTOR;
-		     vector < first_system_vector; vector++) {
+		     vector < FIRST_SYSTEM_VECTOR; vector++) {
 			if (!test_bit(vector, used_vectors) &&
 			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector])) {
 				if (++count == this_count)

commit 69de72ec6db950c436e36b94cf05eeb9e11ee144
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 28 08:47:16 2017 +0200

    x86/irq: Remove vector_used_by_percpu_irq()
    
    Last user (lguest) is gone. Remove it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20170828064956.201432430@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4ed0aba8dbc8..e6073a0ce77e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -346,8 +346,6 @@ __visible void __irq_entry smp_trace_x86_platform_ipi(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
-EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
-
 #ifdef CONFIG_HOTPLUG_CPU
 
 /* These two declarations are only used in check_irq_vectors_for_cpu_disable()

commit 210f84b0ca7743f3b2a9acfae81df668dbbb6a12
Author: Wincy Van <fanwenyi0529@gmail.com>
Date:   Fri Apr 28 13:13:58 2017 +0800

    x86: irq: Define a global vector for nested posted interrupts
    
    We are using the same vector for nested/non-nested posted
    interrupts delivery, this may cause interrupts latency in
    L1 since we can't kick the L2 vcpu out of vmx-nonroot mode.
    
    This patch introduces a new vector which is only for nested
    posted interrupts to solve the problems above.
    
    Signed-off-by: Wincy Van <fanwenyi0529@gmail.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4aa03c5a14c9..4ed0aba8dbc8 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -155,6 +155,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->kvm_posted_intr_ipis);
 	seq_puts(p, "  Posted-interrupt notification event\n");
 
+	seq_printf(p, "%*s: ", prec, "NPI");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ",
+			   irq_stats(j)->kvm_posted_intr_nested_ipis);
+	seq_puts(p, "  Nested posted-interrupt event\n");
+
 	seq_printf(p, "%*s: ", prec, "PIW");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ",
@@ -313,6 +319,19 @@ __visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
 	exiting_irq();
 	set_irq_regs(old_regs);
 }
+
+/*
+ * Handler for POSTED_INTERRUPT_NESTED_VECTOR.
+ */
+__visible void smp_kvm_posted_intr_nested_ipi(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	entering_ack_irq();
+	inc_irq_stat(kvm_posted_intr_nested_ipis);
+	exiting_irq();
+	set_irq_regs(old_regs);
+}
 #endif
 
 __visible void __irq_entry smp_trace_x86_platform_ipi(struct pt_regs *regs)

commit ad7a929fa4bb1143357aa83043a149d5c27c68fd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:33 2017 +0200

    x86/irq: Use irq_migrate_all_off_this_cpu()
    
    The generic migration code supports all the required features
    already. Remove the x86 specific implementation and use the generic one.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235445.851311033@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 78bd2b84eac6..4aa03c5a14c9 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -432,95 +432,12 @@ int check_irq_vectors_for_cpu_disable(void)
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)
 {
-	unsigned int irq, vector;
+	unsigned int irr, vector;
 	struct irq_desc *desc;
 	struct irq_data *data;
 	struct irq_chip *chip;
-	int ret;
 
-	for_each_irq_desc(irq, desc) {
-		const struct cpumask *affinity;
-		bool break_affinity = false;
-
-		if (!desc)
-			continue;
-
-		/* interrupt's are disabled at this point */
-		raw_spin_lock(&desc->lock);
-
-		data = irq_desc_get_irq_data(desc);
-		chip = irq_data_get_irq_chip(data);
-		/*
-		 * The interrupt descriptor might have been cleaned up
-		 * already, but it is not yet removed from the radix
-		 * tree. If the chip does not have an affinity setter,
-		 * nothing to do here.
-		 */
-		if (!chip && !chip->irq_set_affinity) {
-			raw_spin_unlock(&desc->lock);
-			continue;
-		}
-
-		affinity = irq_data_get_affinity_mask(data);
-
-		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
-		    cpumask_subset(affinity, cpu_online_mask)) {
-			irq_fixup_move_pending(desc, false);
-			raw_spin_unlock(&desc->lock);
-			continue;
-		}
-
-		/*
-		 * Complete an eventually pending irq move cleanup. If this
-		 * interrupt was moved in hard irq context, then the
-		 * vectors need to be cleaned up. It can't wait until this
-		 * interrupt actually happens and this CPU was involved.
-		 */
-		irq_force_complete_move(desc);
-
-		/*
-		 * If there is a setaffinity pending, then try to reuse the
-		 * pending mask, so the last change of the affinity does
-		 * not get lost. If there is no move pending or the pending
-		 * mask does not contain any online CPU, use the current
-		 * affinity mask.
-		 */
-		if (irq_fixup_move_pending(desc, true))
-			affinity = desc->pending_mask;
-
-		/*
-		 * If the mask does not contain an offline CPU, break
-		 * affinity and use cpu_online_mask as fall back.
-		 */
-		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
-			broke_affinity = true;
-			affinity = cpu_online_mask;
-		}
-
-		if (!irqd_can_move_in_process_context(data) && chip->irq_mask)
-			chip->irq_mask(data);
-
-		ret = chip->irq_set_affinity(data, affinity, true);
-		if (ret) {
-			pr_crit("IRQ %u: Force affinity failed (%d)\n",
-				d->irq, ret);
-			broke_affinity = false;
-		}
-
-		/*
-		 * We unmask if the irq was not marked masked by the
-		 * core code. That respects the lazy irq disable
-		 * behaviour.
-		 */
-		if (!irqd_can_move_in_process_context(data) &&
-		    !irqd_irq_masked(data) && chip->irq_unmask)
-			chip->irq_unmask(data);
-
-		raw_spin_unlock(&desc->lock);
-
-		if (broke_affinity)
-			pr_notice("Broke affinity for irq %i\n", irq);
-	}
+	irq_migrate_all_off_this_cpu();
 
 	/*
 	 * We can remove mdelay() and then send spuriuous interrupts to
@@ -539,8 +456,6 @@ void fixup_irqs(void)
 	 * nothing else will touch it.
 	 */
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
-		unsigned int irr;
-
 		if (IS_ERR_OR_NULL(__this_cpu_read(vector_irq[vector])))
 			continue;
 

commit 654abd0a7baf144998147787121da0f9422dafc8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:32 2017 +0200

    x86/irq: Restructure fixup_irqs()
    
    Reorder fixup_irqs() so it matches the flow in the generic migration code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235445.774272454@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 9696007df67b..78bd2b84eac6 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -433,7 +433,6 @@ int check_irq_vectors_for_cpu_disable(void)
 void fixup_irqs(void)
 {
 	unsigned int irq, vector;
-	static int warned;
 	struct irq_desc *desc;
 	struct irq_data *data;
 	struct irq_chip *chip;
@@ -441,18 +440,27 @@ void fixup_irqs(void)
 
 	for_each_irq_desc(irq, desc) {
 		const struct cpumask *affinity;
-		int break_affinity = 0;
-		int set_affinity = 1;
+		bool break_affinity = false;
 
 		if (!desc)
 			continue;
-		if (irq == 2)
-			continue;
 
 		/* interrupt's are disabled at this point */
 		raw_spin_lock(&desc->lock);
 
 		data = irq_desc_get_irq_data(desc);
+		chip = irq_data_get_irq_chip(data);
+		/*
+		 * The interrupt descriptor might have been cleaned up
+		 * already, but it is not yet removed from the radix
+		 * tree. If the chip does not have an affinity setter,
+		 * nothing to do here.
+		 */
+		if (!chip && !chip->irq_set_affinity) {
+			raw_spin_unlock(&desc->lock);
+			continue;
+		}
+
 		affinity = irq_data_get_affinity_mask(data);
 
 		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
@@ -485,30 +493,18 @@ void fixup_irqs(void)
 		 * affinity and use cpu_online_mask as fall back.
 		 */
 		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
-			break_affinity = 1;
+			broke_affinity = true;
 			affinity = cpu_online_mask;
 		}
 
-		chip = irq_data_get_irq_chip(data);
-		/*
-		 * The interrupt descriptor might have been cleaned up
-		 * already, but it is not yet removed from the radix tree
-		 */
-		if (!chip) {
-			raw_spin_unlock(&desc->lock);
-			continue;
-		}
-
 		if (!irqd_can_move_in_process_context(data) && chip->irq_mask)
 			chip->irq_mask(data);
 
-		if (chip->irq_set_affinity) {
-			ret = chip->irq_set_affinity(data, affinity, true);
-			if (ret == -ENOSPC)
-				pr_crit("IRQ %d set affinity failed because there are no available vectors.  The device assigned to this IRQ is unstable.\n", irq);
-		} else {
-			if (!(warned++))
-				set_affinity = 0;
+		ret = chip->irq_set_affinity(data, affinity, true);
+		if (ret) {
+			pr_crit("IRQ %u: Force affinity failed (%d)\n",
+				d->irq, ret);
+			broke_affinity = false;
 		}
 
 		/*
@@ -522,10 +518,8 @@ void fixup_irqs(void)
 
 		raw_spin_unlock(&desc->lock);
 
-		if (break_affinity && set_affinity)
+		if (broke_affinity)
 			pr_notice("Broke affinity for irq %i\n", irq);
-		else if (!set_affinity)
-			pr_notice("Cannot set affinity for irq %i\n", irq);
 	}
 
 	/*

commit 8e7b632237df8b17526411d1d98f838580bb6aa3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:20 2017 +0200

    x86/irq: Cleanup pending irq move in fixup_irqs()
    
    If an CPU goes offline, the interrupts are migrated away, but a eventually
    pending interrupt move, which has not yet been made effective is kept
    pending even if the outgoing CPU is the sole target of the pending affinity
    mask. What's worse is, that the pending affinity mask is discarded even if
    it would contain a valid subset of the online CPUs.
    
    Use the newly introduced helper to:
    
     - Discard a pending move when the outgoing CPU is the only target in the
       pending mask.
    
     - Use the pending mask instead of the affinity mask to find a valid target
       for the CPU if the pending mask intersects with the online CPUs.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235444.774068557@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index f34fe7444836..9696007df67b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -440,9 +440,9 @@ void fixup_irqs(void)
 	int ret;
 
 	for_each_irq_desc(irq, desc) {
+		const struct cpumask *affinity;
 		int break_affinity = 0;
 		int set_affinity = 1;
-		const struct cpumask *affinity;
 
 		if (!desc)
 			continue;
@@ -454,19 +454,36 @@ void fixup_irqs(void)
 
 		data = irq_desc_get_irq_data(desc);
 		affinity = irq_data_get_affinity_mask(data);
+
 		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
 		    cpumask_subset(affinity, cpu_online_mask)) {
+			irq_fixup_move_pending(desc, false);
 			raw_spin_unlock(&desc->lock);
 			continue;
 		}
 
 		/*
-		 * Complete the irq move. This cpu is going down and for
-		 * non intr-remapping case, we can't wait till this interrupt
-		 * arrives at this cpu before completing the irq move.
+		 * Complete an eventually pending irq move cleanup. If this
+		 * interrupt was moved in hard irq context, then the
+		 * vectors need to be cleaned up. It can't wait until this
+		 * interrupt actually happens and this CPU was involved.
 		 */
 		irq_force_complete_move(desc);
 
+		/*
+		 * If there is a setaffinity pending, then try to reuse the
+		 * pending mask, so the last change of the affinity does
+		 * not get lost. If there is no move pending or the pending
+		 * mask does not contain any online CPU, use the current
+		 * affinity mask.
+		 */
+		if (irq_fixup_move_pending(desc, true))
+			affinity = desc->pending_mask;
+
+		/*
+		 * If the mask does not contain an offline CPU, break
+		 * affinity and use cpu_online_mask as fall back.
+		 */
 		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
 			break_affinity = 1;
 			affinity = cpu_online_mask;

commit c0edbd4a1693600d6eb9e2faad452638c35391f7
Author: Chen Yu <yu.c.chen@intel.com>
Date:   Sun Apr 16 23:43:30 2017 +0800

    x86/irq: Optimize free vector check in the CPU offline path
    
    Before offlining a CPU its required to check whether there are enough free
    irq vectors available so interrupts can be migrated away from the CPU.
    
    This check is executed whether its required or not and neither stops
    searching when the number of required free vectors are reached.
    
    Bypass the free vector check if the current CPU has no irq to migrate and
    leave the for_each_online_cpu() loop when the free vector count reaches the
    number of required vectors.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Chen Yu <yu.c.chen@intel.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Len Brown <lenb@kernel.orq>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Link: http://lkml.kernel.org/r/1492357410-510-1-git-send-email-yu.c.chen@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4d8183b5f113..f34fe7444836 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -394,6 +394,9 @@ int check_irq_vectors_for_cpu_disable(void)
 		    !cpumask_subset(&affinity_new, &online_new))
 			this_count++;
 	}
+	/* No need to check any further. */
+	if (!this_count)
+		return 0;
 
 	count = 0;
 	for_each_online_cpu(cpu) {
@@ -411,8 +414,10 @@ int check_irq_vectors_for_cpu_disable(void)
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < first_system_vector; vector++) {
 			if (!test_bit(vector, used_vectors) &&
-			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector]))
-			    count++;
+			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector])) {
+				if (++count == this_count)
+					return 0;
+			}
 		}
 	}
 

commit c4158ff536439619fa342810cc575ae2c809f03f
Author: Daniel Bristot de Oliveira <bristot@redhat.com>
Date:   Wed Jan 4 12:20:33 2017 +0100

    x86/irq, trace: Add __irq_entry annotation to x86's platform IRQ handlers
    
    This patch adds the __irq_entry annotation to the default x86
    platform IRQ handlers. ftrace's function_graph tracer uses the
    __irq_entry annotation to notify the entry and return of IRQ
    handlers.
    
    For example, before the patch:
      354549.667252 |   3)  d..1              |  default_idle_call() {
      354549.667252 |   3)  d..1              |    arch_cpu_idle() {
      354549.667253 |   3)  d..1              |      default_idle() {
      354549.696886 |   3)  d..1              |        smp_trace_reschedule_interrupt() {
      354549.696886 |   3)  d..1              |          irq_enter() {
      354549.696886 |   3)  d..1              |            rcu_irq_enter() {
    
    After the patch:
      366416.254476 |   3)  d..1              |    arch_cpu_idle() {
      366416.254476 |   3)  d..1              |      default_idle() {
      366416.261566 |   3)  d..1  ==========> |
      366416.261566 |   3)  d..1              |        smp_trace_reschedule_interrupt() {
      366416.261566 |   3)  d..1              |          irq_enter() {
      366416.261566 |   3)  d..1              |            rcu_irq_enter() {
    
    KASAN also uses this annotation. The smp_apic_timer_interrupt()
    was already annotated.
    
    Signed-off-by: Daniel Bristot de Oliveira <bristot@redhat.com>
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Cc: Aaron Lu <aaron.lu@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Claudio Fontana <claudio.fontana@huawei.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Cc: Gu Zheng <guz.fnst@cn.fujitsu.com>
    Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Nicolai Stange <nicstange@gmail.com>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Cc: linux-edac@vger.kernel.org
    Link: http://lkml.kernel.org/r/059fdf437c2f0c09b13c18c8fe4e69999d3ffe69.1483528431.git.bristot@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 7c6e9ffe4424..4d8183b5f113 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -264,7 +264,7 @@ void __smp_x86_platform_ipi(void)
 		x86_platform_ipi_callback();
 }
 
-__visible void smp_x86_platform_ipi(struct pt_regs *regs)
+__visible void __irq_entry smp_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
@@ -315,7 +315,7 @@ __visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
 }
 #endif
 
-__visible void smp_trace_x86_platform_ipi(struct pt_regs *regs)
+__visible void __irq_entry smp_trace_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 

commit 34bc3560c657d3d4fb17367ed9bfda803166dce0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Dec 9 19:29:12 2016 +0100

    x86: Remove empty idle.h header
    
    One include less is always a good thing(tm). Good riddance.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/20161209182912.2726-6-bp@alien8.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 9f669fdd2010..7c6e9ffe4424 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -14,7 +14,6 @@
 #include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/irq.h>
-#include <asm/idle.h>
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
 #include <asm/desc.h>

commit 82ba4faca1bffad429f15c90c980ffd010366c25
Author: Aaron Lu <aaron.lu@intel.com>
Date:   Thu Aug 11 15:44:30 2016 +0800

    x86/irq: Do not substract irq_tlb_count from irq_call_count
    
    Since commit:
    
      52aec3308db8 ("x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR")
    
    the TLB remote shootdown is done through call function vector. That
    commit didn't take care of irq_tlb_count, which a later commit:
    
      fd0f5869724f ("x86: Distinguish TLB shootdown interrupts from other functions call interrupts")
    
    ... tried to fix.
    
    The fix assumes every increase of irq_tlb_count has a corresponding
    increase of irq_call_count. So the irq_call_count is always bigger than
    irq_tlb_count and we could substract irq_tlb_count from irq_call_count.
    
    Unfortunately this is not true for the smp_call_function_single() case.
    The IPI is only sent if the target CPU's call_single_queue is empty when
    adding a csd into it in generic_exec_single. That means if two threads
    are both adding flush tlb csds to the same CPU's call_single_queue, only
    one IPI is sent. In other words, the irq_call_count is incremented by 1
    but irq_tlb_count is incremented by 2. Over time, irq_tlb_count will be
    bigger than irq_call_count and the substract will produce a very large
    irq_call_count value due to overflow.
    
    Considering that:
    
      1) it's not worth to send more IPIs for the sake of accurate counting of
         irq_call_count in generic_exec_single();
    
      2) it's not easy to tell if the call function interrupt is for TLB
         shootdown in __smp_call_function_single_interrupt().
    
    Not to exclude TLB shootdown from call function count seems to be the
    simplest fix and this patch just does that.
    
    This bug was found by LKP's cyclic performance regression tracking recently
    with the vm-scalability test suite. I have bisected to commit:
    
      3dec0ba0be6a ("mm/rmap: share the i_mmap_rwsem")
    
    This commit didn't do anything wrong but revealed the irq_call_count
    problem. IIUC, the commit makes rwc->remap_one in rmap_walk_file
    concurrent with multiple threads.  When remap_one is try_to_unmap_one(),
    then multiple threads could queue flush TLB to the same CPU but only
    one IPI will be sent.
    
    Since the commit was added in Linux v3.19, the counting problem only
    shows up from v3.19 onwards.
    
    Signed-off-by: Aaron Lu <aaron.lu@intel.com>
    Cc: Alex Shi <alex.shi@linaro.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
    Link: http://lkml.kernel.org/r/20160811074430.GA18163@aaronlu.sh.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 61521dc19c10..9f669fdd2010 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -102,8 +102,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_puts(p, "  Rescheduling interrupts\n");
 	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count -
-					irq_stats(j)->irq_tlb_count);
+		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
 	seq_puts(p, "  Function call interrupts\n");
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)

commit 90a2282e23f0522e4b3f797ad447c5e91bf7fe32
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 31 16:30:53 2015 +0000

    x86/irq: Call irq_force_move_complete with irq descriptor
    
    First of all there is no point in looking up the irq descriptor again, but we
    also need the descriptor for the final cleanup race fix in the next
    patch. Make that change seperate. No functional difference.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Borislav Petkov <bp@alien8.de>
    Tested-by: Joe Lawrence <joe.lawrence@stratus.com>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Jeremiah Mahler <jmmahler@gmail.com>
    Cc: andy.shevchenko@gmail.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: stable@vger.kernel.org #4.3+
    Link: http://lkml.kernel.org/r/20151231160107.125211743@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c0b58dd1ca04..61521dc19c10 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -462,7 +462,7 @@ void fixup_irqs(void)
 		 * non intr-remapping case, we can't wait till this interrupt
 		 * arrives at this cpu before completing the irq move.
 		 */
-		irq_force_complete_move(irq);
+		irq_force_complete_move(desc);
 
 		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
 			break_affinity = 1;

commit 36f34c8c63da3e272fd66f91089228c22d2b6e8b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 31 16:30:45 2015 +0000

    x86/irq: Validate that irq descriptor is still active
    
    In fixup_irqs() we unconditionally dereference the irq chip of an irq
    descriptor. The descriptor might still be valid, but already cleaned up,
    i.e. the chip removed. Add a check for this condition.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Joe Lawrence <joe.lawrence@stratus.com>
    Cc: Jeremiah Mahler <jmmahler@gmail.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: andy.shevchenko@gmail.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: stable@vger.kernel.org #4.3+
    Link: http://lkml.kernel.org/r/20151231160106.236423282@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index f8062aaf5df9..c0b58dd1ca04 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -470,6 +470,15 @@ void fixup_irqs(void)
 		}
 
 		chip = irq_data_get_irq_chip(data);
+		/*
+		 * The interrupt descriptor might have been cleaned up
+		 * already, but it is not yet removed from the radix tree
+		 */
+		if (!chip) {
+			raw_spin_unlock(&desc->lock);
+			continue;
+		}
+
 		if (!irqd_can_move_in_process_context(data) && chip->irq_mask)
 			chip->irq_mask(data);
 

commit 43af9872f52abfed5523b8346d98a5e283b38163
Merge: 17e6b00ac422 a47d4576cd1c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 15:20:51 2015 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 apic updates from Thomas Gleixner:
     "This udpate contains:
    
       - rework the irq vector array to store a pointer to the irq
         descriptor instead of the irq number to avoid a lookup of the irq
         descriptor in the irq entry path
    
       - lguest interrupt handling cleanups
    
       - conversion of the local apic timer to the new clockevent callbacks
    
       - preparatory changes for the irq argument removal of interrupt flow
         handlers"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/irq: Do not dereference irq descriptor before checking it
      tools/lguest: Clean up include dir
      tools/lguest: Fix redefinition of struct virtio_pci_cfg_cap
      x86/irq: Store irq descriptor in vector array
      genirq: Provide irq_desc_has_action
      x86/irq: Get rid of an indentation level
      x86/irq: Rename VECTOR_UNDEFINED to VECTOR_UNUSED
      x86/irq: Replace numeric constant
      x86/irq: Protect smp_cleanup_move
      x86/lguest: Do not setup unused irq vectors
      x86/lguest: Clean up lguest_setup_irq
      x86/apic: Drop local_irq_save/restore in timer callbacks
      x86/apic: Migrate apic timer to new set_state interface
      x86/irq: Use access helper irq_data_get_affinity_mask()
      x86/irq: Use accessor irq_data_get_irq_handler_data()
      x86/irq: Use accessor irq_data_get_node()

commit 2962156d5cc0e7f959353d3f5275da7cc3765f06
Merge: 6b2282aa3726 9d87cd61a6b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 10:05:44 2015 -0700

    Merge branch 'x86-irq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 irq fixlet from Ingo Molnar:
     "A single change that hides the 'HYP:' line in /proc/interrupts when
      it's unused"
    
    * 'x86-irq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/irq: Hide 'HYP:' line in /proc/interrupts when not on Xen/Hyper-V

commit 5778077d03cb25aac9b6a428e18970642fc019e3
Merge: 65a99597f044 7e01ebffffed
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 08:40:25 2015 -0700

    Merge branch 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 asm changes from Ingo Molnar:
     "The biggest changes in this cycle were:
    
       - Revamp, simplify (and in some cases fix) Time Stamp Counter (TSC)
         primitives.  (Andy Lutomirski)
    
       - Add new, comprehensible entry and exit handlers written in C.
         (Andy Lutomirski)
    
       - vm86 mode cleanups and fixes.  (Brian Gerst)
    
       - 32-bit compat code cleanups.  (Brian Gerst)
    
      The amount of simplification in low level assembly code is already
      palpable:
    
         arch/x86/entry/entry_32.S                          | 130 +----
         arch/x86/entry/entry_64.S                          | 197 ++-----
    
      but more simplifications are planned.
    
      There's also the usual laudry mix of low level changes - see the
      changelog for details"
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (83 commits)
      x86/asm: Drop repeated macro of X86_EFLAGS_AC definition
      x86/asm/msr: Make wrmsrl() a function
      x86/asm/delay: Introduce an MWAITX-based delay with a configurable timer
      x86/asm: Add MONITORX/MWAITX instruction support
      x86/traps: Weaken context tracking entry assertions
      x86/asm/tsc: Add rdtscll() merge helper
      selftests/x86: Add syscall_nt selftest
      selftests/x86: Disable sigreturn_64
      x86/vdso: Emit a GNU hash
      x86/entry: Remove do_notify_resume(), syscall_trace_leave(), and their TIF masks
      x86/entry/32: Migrate to C exit path
      x86/entry/32: Remove 32-bit syscall audit optimizations
      x86/vm86: Rename vm86->v86flags and v86mask
      x86/vm86: Rename vm86->vm86_info to user_vm86
      x86/vm86: Clean up vm86.h includes
      x86/vm86: Move the vm86 IRQ definitions to vm86.h
      x86/vm86: Use the normal pt_regs area for vm86
      x86/vm86: Eliminate 'struct kernel_vm86_struct'
      x86/vm86: Move fields from 'struct kernel_vm86_struct' to 'struct vm86'
      x86/vm86: Move vm86 fields out of 'thread_struct'
      ...

commit a782a7e46bb50822fabfeb7271605762a59c86df
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Aug 2 20:38:27 2015 +0000

    x86/irq: Store irq descriptor in vector array
    
    We can spare the irq_desc lookup in the interrupt entry code if we
    store the descriptor pointer in the vector array instead the interrupt
    number.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/20150802203609.717724106@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 140950fb9902..e010847583d7 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -211,22 +211,21 @@ u64 arch_irq_stat(void)
 __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
-
+	struct irq_desc * desc;
 	/* high bit used in ret_from_ code  */
 	unsigned vector = ~regs->orig_ax;
-	unsigned irq;
 
 	entering_irq();
 
-	irq = __this_cpu_read(vector_irq[vector]);
+	desc = __this_cpu_read(vector_irq[vector]);
 
-	if (!handle_irq(irq, regs)) {
+	if (!handle_irq(desc, regs)) {
 		ack_APIC_irq();
 
-		if (irq != VECTOR_RETRIGGERED) {
-			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector (irq %d)\n",
+		if (desc != VECTOR_RETRIGGERED) {
+			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector\n",
 					     __func__, smp_processor_id(),
-					     vector, irq);
+					     vector);
 		} else {
 			__this_cpu_write(vector_irq[vector], VECTOR_UNUSED);
 		}
@@ -330,10 +329,10 @@ static struct cpumask affinity_new, online_new;
  */
 int check_irq_vectors_for_cpu_disable(void)
 {
-	int irq, cpu;
 	unsigned int this_cpu, vector, this_count, count;
 	struct irq_desc *desc;
 	struct irq_data *data;
+	int cpu;
 
 	this_cpu = smp_processor_id();
 	cpumask_copy(&online_new, cpu_online_mask);
@@ -341,24 +340,21 @@ int check_irq_vectors_for_cpu_disable(void)
 
 	this_count = 0;
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
-		irq = __this_cpu_read(vector_irq[vector]);
-		if (irq < 0)
-			continue;
-		desc = irq_to_desc(irq);
-		if (!desc)
+		desc = __this_cpu_read(vector_irq[vector]);
+		if (IS_ERR_OR_NULL(desc))
 			continue;
-
 		/*
 		 * Protect against concurrent action removal, affinity
 		 * changes etc.
 		 */
 		raw_spin_lock(&desc->lock);
 		data = irq_desc_get_irq_data(desc);
-		cpumask_copy(&affinity_new, irq_data_get_affinity_mask(data));
+		cpumask_copy(&affinity_new,
+			     irq_data_get_affinity_mask(data));
 		cpumask_clear_cpu(this_cpu, &affinity_new);
 
 		/* Do not count inactive or per-cpu irqs. */
-		if (!irq_has_action(irq) || irqd_is_per_cpu(data)) {
+		if (!irq_desc_has_action(desc) || irqd_is_per_cpu(data)) {
 			raw_spin_unlock(&desc->lock);
 			continue;
 		}
@@ -399,8 +395,8 @@ int check_irq_vectors_for_cpu_disable(void)
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < first_system_vector; vector++) {
 			if (!test_bit(vector, used_vectors) &&
-			    per_cpu(vector_irq, cpu)[vector] <= VECTOR_UNUSED)
-				count++;
+			    IS_ERR_OR_NULL(per_cpu(vector_irq, cpu)[vector]))
+			    count++;
 		}
 	}
 
@@ -504,14 +500,13 @@ void fixup_irqs(void)
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		unsigned int irr;
 
-		if (__this_cpu_read(vector_irq[vector]) <= VECTOR_UNUSED)
+		if (IS_ERR_OR_NULL(__this_cpu_read(vector_irq[vector])))
 			continue;
 
 		irr = apic_read(APIC_IRR + (vector / 32 * 0x10));
 		if (irr  & (1 << (vector % 32))) {
-			irq = __this_cpu_read(vector_irq[vector]);
+			desc = __this_cpu_read(vector_irq[vector]);
 
-			desc = irq_to_desc(irq);
 			raw_spin_lock(&desc->lock);
 			data = irq_desc_get_irq_data(desc);
 			chip = irq_data_get_irq_chip(data);

commit 44825757a3ee37c030165a94d6b4dd79c564f661
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Aug 2 20:38:25 2015 +0000

    x86/irq: Get rid of an indentation level
    
    Make the code simpler to read.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/20150802203609.555253675@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 931bdd2f9759..140950fb9902 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -342,47 +342,45 @@ int check_irq_vectors_for_cpu_disable(void)
 	this_count = 0;
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		irq = __this_cpu_read(vector_irq[vector]);
-		if (irq >= 0) {
-			desc = irq_to_desc(irq);
-			if (!desc)
-				continue;
+		if (irq < 0)
+			continue;
+		desc = irq_to_desc(irq);
+		if (!desc)
+			continue;
 
-			/*
-			 * Protect against concurrent action removal,
-			 * affinity changes etc.
-			 */
-			raw_spin_lock(&desc->lock);
-			data = irq_desc_get_irq_data(desc);
-			cpumask_copy(&affinity_new,
-				     irq_data_get_affinity_mask(data));
-			cpumask_clear_cpu(this_cpu, &affinity_new);
-
-			/* Do not count inactive or per-cpu irqs. */
-			if (!irq_has_action(irq) || irqd_is_per_cpu(data)) {
-				raw_spin_unlock(&desc->lock);
-				continue;
-			}
+		/*
+		 * Protect against concurrent action removal, affinity
+		 * changes etc.
+		 */
+		raw_spin_lock(&desc->lock);
+		data = irq_desc_get_irq_data(desc);
+		cpumask_copy(&affinity_new, irq_data_get_affinity_mask(data));
+		cpumask_clear_cpu(this_cpu, &affinity_new);
 
+		/* Do not count inactive or per-cpu irqs. */
+		if (!irq_has_action(irq) || irqd_is_per_cpu(data)) {
 			raw_spin_unlock(&desc->lock);
-			/*
-			 * A single irq may be mapped to multiple
-			 * cpu's vector_irq[] (for example IOAPIC cluster
-			 * mode).  In this case we have two
-			 * possibilities:
-			 *
-			 * 1) the resulting affinity mask is empty; that is
-			 * this the down'd cpu is the last cpu in the irq's
-			 * affinity mask, or
-			 *
-			 * 2) the resulting affinity mask is no longer
-			 * a subset of the online cpus but the affinity
-			 * mask is not zero; that is the down'd cpu is the
-			 * last online cpu in a user set affinity mask.
-			 */
-			if (cpumask_empty(&affinity_new) ||
-			    !cpumask_subset(&affinity_new, &online_new))
-				this_count++;
+			continue;
 		}
+
+		raw_spin_unlock(&desc->lock);
+		/*
+		 * A single irq may be mapped to multiple cpu's
+		 * vector_irq[] (for example IOAPIC cluster mode).  In
+		 * this case we have two possibilities:
+		 *
+		 * 1) the resulting affinity mask is empty; that is
+		 * this the down'd cpu is the last cpu in the irq's
+		 * affinity mask, or
+		 *
+		 * 2) the resulting affinity mask is no longer a
+		 * subset of the online cpus but the affinity mask is
+		 * not zero; that is the down'd cpu is the last online
+		 * cpu in a user set affinity mask.
+		 */
+		if (cpumask_empty(&affinity_new) ||
+		    !cpumask_subset(&affinity_new, &online_new))
+			this_count++;
 	}
 
 	count = 0;

commit 7276c6a2cb5f7ae46fd0c9539af02dbcb7c4f3f5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Aug 2 20:38:25 2015 +0000

    x86/irq: Rename VECTOR_UNDEFINED to VECTOR_UNUSED
    
    VECTOR_UNDEFINED is a misnomer. The vector is defined, but unused.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/20150802203609.477282494@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 35d4cb287771..931bdd2f9759 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -228,7 +228,7 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 					     __func__, smp_processor_id(),
 					     vector, irq);
 		} else {
-			__this_cpu_write(vector_irq[vector], VECTOR_UNDEFINED);
+			__this_cpu_write(vector_irq[vector], VECTOR_UNUSED);
 		}
 	}
 
@@ -401,7 +401,7 @@ int check_irq_vectors_for_cpu_disable(void)
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < first_system_vector; vector++) {
 			if (!test_bit(vector, used_vectors) &&
-			    per_cpu(vector_irq, cpu)[vector] <= VECTOR_UNDEFINED)
+			    per_cpu(vector_irq, cpu)[vector] <= VECTOR_UNUSED)
 				count++;
 		}
 	}
@@ -506,7 +506,7 @@ void fixup_irqs(void)
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		unsigned int irr;
 
-		if (__this_cpu_read(vector_irq[vector]) <= VECTOR_UNDEFINED)
+		if (__this_cpu_read(vector_irq[vector]) <= VECTOR_UNUSED)
 			continue;
 
 		irr = apic_read(APIC_IRR + (vector / 32 * 0x10));
@@ -524,7 +524,7 @@ void fixup_irqs(void)
 			raw_spin_unlock(&desc->lock);
 		}
 		if (__this_cpu_read(vector_irq[vector]) != VECTOR_RETRIGGERED)
-			__this_cpu_write(vector_irq[vector], VECTOR_UNDEFINED);
+			__this_cpu_write(vector_irq[vector], VECTOR_UNUSED);
 	}
 }
 #endif

commit 24c70e07a0311a98dbb5e7a7472fa96a22b789d3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Aug 2 20:38:24 2015 +0000

    x86/irq: Replace numeric constant
    
    Use the proper define instead of 0.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/20150802203609.385495420@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index bc28496fd196..35d4cb287771 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -401,8 +401,8 @@ int check_irq_vectors_for_cpu_disable(void)
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < first_system_vector; vector++) {
 			if (!test_bit(vector, used_vectors) &&
-			    per_cpu(vector_irq, cpu)[vector] < 0)
-					count++;
+			    per_cpu(vector_irq, cpu)[vector] <= VECTOR_UNDEFINED)
+				count++;
 		}
 	}
 

commit b7edaca4e825fd5d7a6ddce3548cc1f7a7337cf8
Merge: c948c26048ec cbfe8fa6cd67
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Aug 5 23:55:52 2015 +0200

    Merge branch 'linus' into x86/apic
    
    Pull in upstream changes to avoid conflicts

commit 5b929bd11df23922daf1be5d52731cc3900c1d79
Merge: b2c51106c758 37868fe113ff
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jul 31 10:23:35 2015 +0200

    Merge branch 'x86/urgent' into x86/asm, before applying dependent patches
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit c149e4cd08ba01f4d2d0104f469d5f5419294e06
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Wed Jun 3 11:46:22 2015 +0800

    x86/irq: Use access helper irq_data_get_affinity_mask()
    
    This is a preparatory patch for moving irq_data struct members.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 88b366487b0e..7ed9cba27637 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -348,7 +348,8 @@ int check_irq_vectors_for_cpu_disable(void)
 				continue;
 
 			data = irq_desc_get_irq_data(desc);
-			cpumask_copy(&affinity_new, data->affinity);
+			cpumask_copy(&affinity_new,
+				     irq_data_get_affinity_mask(data));
 			cpumask_clear_cpu(this_cpu, &affinity_new);
 
 			/* Do not count inactive or per-cpu irqs. */
@@ -426,7 +427,7 @@ void fixup_irqs(void)
 		raw_spin_lock(&desc->lock);
 
 		data = irq_desc_get_irq_data(desc);
-		affinity = data->affinity;
+		affinity = irq_data_get_affinity_mask(data);
 		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
 		    cpumask_subset(affinity, cpu_online_mask)) {
 			raw_spin_unlock(&desc->lock);

commit 9d87cd61a6b71ee00b7576a3ebc10208becdbea1
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Tue Jul 7 18:26:13 2015 +0200

    x86/irq: Hide 'HYP:' line in /proc/interrupts when not on Xen/Hyper-V
    
    Hypervisor callback interrupts are only accounted on
    Xen/Hyper-V. There is no point in having always-zero HYP: line
    on other hypervisors or bare metal. Print the line only if
    HYPERVISOR_CALLBACK_VECTOR was allocated.
    
    Reported-by: Radim Krčmář <rkrcmar@redhat.com>
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: Andrew Jones <drjones@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1436286373-11908-1-git-send-email-vkuznets@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 88b366487b0e..5b537479de83 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -139,10 +139,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_puts(p, "  Machine check polls\n");
 #endif
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
-	seq_printf(p, "%*s: ", prec, "HYP");
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_hv_callback_count);
-	seq_puts(p, "  Hypervisor callback interrupts\n");
+	if (test_bit(HYPERVISOR_CALLBACK_VECTOR, used_vectors)) {
+		seq_printf(p, "%*s: ", prec, "HYP");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ",
+				   irq_stats(j)->irq_hv_callback_count);
+		seq_puts(p, "  Hypervisor callback interrupts\n");
+	}
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 09cf92b784fae6109450c5d64f9908066d605249
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 5 17:12:35 2015 +0000

    x86/irq: Retrieve irq data after locking irq_desc
    
    irq_data is protected by irq_desc->lock, so retrieving the irq chip
    from irq_data outside the lock is racy vs. an concurrent update. Move
    it into the lock held region.
    
    While at it add a comment why the vector walk does not require
    vector_lock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: xiao jin <jin.xiao@intel.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Link: http://lkml.kernel.org/r/20150705171102.331320612@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 85ca76e6241c..c7dfe1be784e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -497,6 +497,11 @@ void fixup_irqs(void)
 	 */
 	mdelay(1);
 
+	/*
+	 * We can walk the vector array of this cpu without holding
+	 * vector_lock because the cpu is already marked !online, so
+	 * nothing else will touch it.
+	 */
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		unsigned int irr;
 
@@ -508,9 +513,9 @@ void fixup_irqs(void)
 			irq = __this_cpu_read(vector_irq[vector]);
 
 			desc = irq_to_desc(irq);
+			raw_spin_lock(&desc->lock);
 			data = irq_desc_get_irq_data(desc);
 			chip = irq_data_get_irq_chip(data);
-			raw_spin_lock(&desc->lock);
 			if (chip->irq_retrigger) {
 				chip->irq_retrigger(data);
 				__this_cpu_write(vector_irq[vector], VECTOR_RETRIGGERED);

commit cbb24dc761d95fe39a7a122bb1b298e9604cae15
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 5 17:12:33 2015 +0000

    x86/irq: Use proper locking in check_irq_vectors_for_cpu_disable()
    
    It's unsafe to examine fields in the irq descriptor w/o holding the
    descriptor lock. Add proper locking.
    
    While at it add a comment why the vector check can run lock less
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: xiao jin <jin.xiao@intel.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Link: http://lkml.kernel.org/r/20150705171102.236544164@linutronix.de

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 88b366487b0e..85ca76e6241c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -347,14 +347,22 @@ int check_irq_vectors_for_cpu_disable(void)
 			if (!desc)
 				continue;
 
+			/*
+			 * Protect against concurrent action removal,
+			 * affinity changes etc.
+			 */
+			raw_spin_lock(&desc->lock);
 			data = irq_desc_get_irq_data(desc);
 			cpumask_copy(&affinity_new, data->affinity);
 			cpumask_clear_cpu(this_cpu, &affinity_new);
 
 			/* Do not count inactive or per-cpu irqs. */
-			if (!irq_has_action(irq) || irqd_is_per_cpu(data))
+			if (!irq_has_action(irq) || irqd_is_per_cpu(data)) {
+				raw_spin_unlock(&desc->lock);
 				continue;
+			}
 
+			raw_spin_unlock(&desc->lock);
 			/*
 			 * A single irq may be mapped to multiple
 			 * cpu's vector_irq[] (for example IOAPIC cluster
@@ -385,6 +393,9 @@ int check_irq_vectors_for_cpu_disable(void)
 		 * vector. If the vector is marked in the used vectors
 		 * bitmap or an irq is assigned to it, we don't count
 		 * it as available.
+		 *
+		 * As this is an inaccurate snapshot anyway, we can do
+		 * this w/o holding vector_lock.
 		 */
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector < first_system_vector; vector++) {

commit 0333a209cbf600e980fc55c24878a56f25f48b65
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jul 3 12:44:34 2015 -0700

    x86/irq, context_tracking: Document how IRQ context tracking works and add an RCU assertion
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Denys Vlasenko <vda.linux@googlemail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: paulmck@linux.vnet.ibm.com
    Link: http://lkml.kernel.org/r/e8bdc4ed0193fb2fd130f3d6b7b8023e2ec1ab62.1435952415.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 88b366487b0e..6233de046c08 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -216,8 +216,23 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	unsigned vector = ~regs->orig_ax;
 	unsigned irq;
 
+	/*
+	 * NB: Unlike exception entries, IRQ entries do not reliably
+	 * handle context tracking in the low-level entry code.  This is
+	 * because syscall entries execute briefly with IRQs on before
+	 * updating context tracking state, so we can take an IRQ from
+	 * kernel mode with CONTEXT_USER.  The low-level entry code only
+	 * updates the context if we came from user mode, so we won't
+	 * switch to CONTEXT_KERNEL.  We'll fix that once the syscall
+	 * code is cleaned up enough that we can cleanly defer enabling
+	 * IRQs.
+	 */
+
 	entering_irq();
 
+	/* entering_irq() tells RCU that we're not quiescent.  Check it. */
+	rcu_lockdep_assert(rcu_is_watching(), "IRQ failed to wake up RCU");
+
 	irq = __this_cpu_read(vector_irq[vector]);
 
 	if (!handle_irq(irq, regs)) {

commit c2f9b0af8bb4b2a5c020ae88efc9a624f59a7080
Merge: c8e56d20f2d1 243d657eaf54
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Jun 7 15:35:27 2015 +0200

    Merge branch 'x86/ras' into x86/core, to fix conflicts
    
    Conflicts:
            arch/x86/include/asm/irq_vectors.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 501b32653ebf49114cccb9afbf9150cf18fd8700
Author: Feng Wu <feng.wu@intel.com>
Date:   Tue May 19 17:07:17 2015 +0800

    x86/irq: Show statistics information for posted-interrupts
    
    Show the statistics information for notification event
    and wakeup event for posted-interrupt in /proc/interrupts.
    
    [ tglx: Named the short identifiers PIN and PIW to match the long
            identifiers ]
    
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Cc: jiang.liu@linux.intel.com
    Link: http://lkml.kernel.org/r/1432026437-16560-5-git-send-email-feng.wu@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 90b2f7052f5b..7e10c8b4b318 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -141,6 +141,18 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)
 	seq_printf(p, "%*s: %10u\n", prec, "MIS", atomic_read(&irq_mis_count));
+#endif
+#ifdef CONFIG_HAVE_KVM
+	seq_printf(p, "%*s: ", prec, "PIN");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->kvm_posted_intr_ipis);
+	seq_puts(p, "  Posted-interrupt notification event\n");
+
+	seq_printf(p, "%*s: ", prec, "PIW");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ",
+			   irq_stats(j)->kvm_posted_intr_wakeup_ipis);
+	seq_puts(p, "  Posted-interrupt wakeup event\n");
 #endif
 	return 0;
 }

commit f6b3c72c23661e5534cd2eede16e9bac7ebb761c
Author: Feng Wu <feng.wu@intel.com>
Date:   Tue May 19 17:07:16 2015 +0800

    x86/irq: Define a global vector for VT-d Posted-Interrupts
    
    Currently, we use a global vector as the Posted-Interrupts
    Notification Event for all the vCPUs in the system. We need
    to introduce another global vector for VT-d Posted-Interrtups,
    which will be used to wakeup the sleep vCPU when an external
    interrupt from a direct-assigned device happens for that vCPU.
    
    [ tglx: Removed a gazillion of extra newlines ]
    
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Cc: jiang.liu@linux.intel.com
    Link: http://lkml.kernel.org/r/1432026437-16560-4-git-send-email-feng.wu@intel.com
    Suggested-by: Yang Zhang <yang.z.zhang@intel.com>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index be3894512820..90b2f7052f5b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -242,6 +242,18 @@ __visible void smp_x86_platform_ipi(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_HAVE_KVM
+static void dummy_handler(void) {}
+static void (*kvm_posted_intr_wakeup_handler)(void) = dummy_handler;
+
+void kvm_set_posted_intr_wakeup_handler(void (*handler)(void))
+{
+	if (handler)
+		kvm_posted_intr_wakeup_handler = handler;
+	else
+		kvm_posted_intr_wakeup_handler = dummy_handler;
+}
+EXPORT_SYMBOL_GPL(kvm_set_posted_intr_wakeup_handler);
+
 /*
  * Handler for POSTED_INTERRUPT_VECTOR.
  */
@@ -254,6 +266,20 @@ __visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 	exiting_irq();
 	set_irq_regs(old_regs);
 }
+
+/*
+ * Handler for POSTED_INTERRUPT_WAKEUP_VECTOR.
+ */
+__visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	entering_ack_irq();
+	inc_irq_stat(kvm_posted_intr_wakeup_ipis);
+	kvm_posted_intr_wakeup_handler();
+	exiting_irq();
+	set_irq_regs(old_regs);
+}
 #endif
 
 __visible void smp_trace_x86_platform_ipi(struct pt_regs *regs)

commit 6af7faf6076697a39438cf38e21b4035e2ebdac9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri May 15 15:48:25 2015 +0200

    x86: Use entering[_ack]_irq() instead of open coding it
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index fe2ed8bb507b..be3894512820 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -198,8 +198,7 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	unsigned vector = ~regs->orig_ax;
 	unsigned irq;
 
-	irq_enter();
-	exit_idle();
+	entering_irq();
 
 	irq = __this_cpu_read(vector_irq[vector]);
 
@@ -215,7 +214,7 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 		}
 	}
 
-	irq_exit();
+	exiting_irq();
 
 	set_irq_regs(old_regs);
 	return 1;
@@ -250,16 +249,9 @@ __visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	ack_APIC_irq();
-
-	irq_enter();
-
-	exit_idle();
-
+	entering_ack_irq();
 	inc_irq_stat(kvm_posted_intr_ipis);
-
-	irq_exit();
-
+	exiting_irq();
 	set_irq_regs(old_regs);
 }
 #endif

commit c5bde906d2916d214d78cd8b67d665bf09867033
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sat May 9 11:36:50 2015 -0400

    x86/irq: Merge irq_regs & irq_stat
    
    Move irq_regs and irq_stat definitions to irq.c.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1431185813-15413-2-git-send-email-brgerst@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e5952c225532..fe2ed8bb507b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -22,6 +22,12 @@
 #define CREATE_TRACE_POINTS
 #include <asm/trace/irq_vectors.h>
 
+DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
+EXPORT_PER_CPU_SYMBOL(irq_stat);
+
+DEFINE_PER_CPU(struct pt_regs *, irq_regs);
+EXPORT_PER_CPU_SYMBOL(irq_regs);
+
 atomic_t irq_err_count;
 
 /* Function pointer for generic interrupt vector handling */

commit 24fd78a81f6d3fe7f7a440c8629f9c52cd5f830e
Author: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
Date:   Wed May 6 06:58:56 2015 -0500

    x86/mce/amd: Introduce deferred error interrupt handler
    
    Deferred errors indicate error conditions that were not corrected, but
    require no action from S/W (or action is optional).These errors provide
    info about a latent UC MCE that can occur when a poisoned data is
    consumed by the processor.
    
    Processors that report these errors can be configured to generate APIC
    interrupts to notify OS about the error.
    
    Provide an interrupt handler in this patch so that OS can catch these
    errors as and when they happen. Currently, we simply log the errors and
    exit the handler as S/W action is not mandated.
    
    Signed-off-by: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: x86-ml <x86@kernel.org>
    Cc: linux-edac <linux-edac@vger.kernel.org>
    Link: http://lkml.kernel.org/r/1430913538-1415-5-git-send-email-Aravind.Gopalakrishnan@amd.com
    Signed-off-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e5952c225532..590ed6c1bf51 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -116,6 +116,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_puts(p, "  Threshold APIC interrupts\n");
 #endif
+#ifdef CONFIG_X86_MCE_AMD
+	seq_printf(p, "%*s: ", prec, "DFR");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_deferred_error_count);
+	seq_puts(p, "  Deferred Error APIC interrupts\n");
+#endif
 #ifdef CONFIG_X86_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
 	for_each_online_cpu(j)

commit 020b37ac66c5fcec70b6fa51113b84bdfff6a4bc
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Mar 2 22:05:49 2015 +1030

    x86: Fix up obsolete __cpu_set() function usage
    
    Thanks to spatch, plus manual removal of "&*".
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425296150-4722-8-git-send-email-rusty@rustcorp.com.au
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 67b1cbe0093a..e5952c225532 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -295,7 +295,7 @@ int check_irq_vectors_for_cpu_disable(void)
 
 	this_cpu = smp_processor_id();
 	cpumask_copy(&online_new, cpu_online_mask);
-	cpu_clear(this_cpu, online_new);
+	cpumask_clear_cpu(this_cpu, &online_new);
 
 	this_count = 0;
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
@@ -307,7 +307,7 @@ int check_irq_vectors_for_cpu_disable(void)
 
 			data = irq_desc_get_irq_data(desc);
 			cpumask_copy(&affinity_new, data->affinity);
-			cpu_clear(this_cpu, affinity_new);
+			cpumask_clear_cpu(this_cpu, &affinity_new);
 
 			/* Do not count inactive or per-cpu irqs. */
 			if (!irq_has_action(irq) || irqd_is_per_cpu(data))

commit d97eb8966c91f2c9d05f0a22eb89ed5b76d966d1
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 4 13:33:33 2015 +0100

    x86/irq: Check for valid irq descriptor in check_irq_vectors_for_cpu_disable()
    
    When an interrupt is migrated away from a cpu it will stay
    in its vector_irq array until smp_irq_move_cleanup_interrupt
    succeeded. The cfg->move_in_progress flag is cleared already
    when the IPI was sent.
    
    When the interrupt is destroyed after migration its 'struct
    irq_desc' is freed and the vector_irq arrays are cleaned up.
    But since cfg->move_in_progress is already 0 the references
    at cpus before the last migration will not be cleared. So
    this would leave a reference to an already destroyed irq
    alive.
    
    When the cpu is taken down at this point, the
    check_irq_vectors_for_cpu_disable() function finds a valid irq
    number in the vector_irq array, but gets NULL for its
    descriptor and dereferences it, causing a kernel panic.
    
    This has been observed on real systems at shutdown. Add a
    check to check_irq_vectors_for_cpu_disable() for a valid
    'struct irq_desc' to prevent this issue.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jan Beulich <JBeulich@suse.com>
    Cc: K. Y. Srinivasan <kys@microsoft.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: alnovak@suse.com
    Cc: joro@8bytes.org
    Link: http://lkml.kernel.org/r/20150204132754.GA10078@suse.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 705ef8d48e2d..67b1cbe0093a 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -302,6 +302,9 @@ int check_irq_vectors_for_cpu_disable(void)
 		irq = __this_cpu_read(vector_irq[vector]);
 		if (irq >= 0) {
 			desc = irq_to_desc(irq);
+			if (!desc)
+				continue;
+
 			data = irq_desc_get_irq_data(desc);
 			cpumask_copy(&affinity_new, data->affinity);
 			cpu_clear(this_cpu, affinity_new);

commit 4a0d3107d6b19125f21172c2b7d95f9c30ecaf6f
Author: Jan Beulich <JBeulich@suse.com>
Date:   Fri Jan 16 15:47:07 2015 +0000

    x86, irq: Properly tag virtualization entry in /proc/interrupts
    
    The mis-naming likely was a copy-and-paste effect.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/54B9408B0200007800055E8B@mail.emea.novell.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 6307a0f0cf17..705ef8d48e2d 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -127,7 +127,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_puts(p, "  Machine check polls\n");
 #endif
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
-	seq_printf(p, "%*s: ", prec, "THR");
+	seq_printf(p, "%*s: ", prec, "HYP");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_hv_callback_count);
 	seq_puts(p, "  Hypervisor callback interrupts\n");

commit 3736708f034ae1e8c62789ed737e8b90d5b40210
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Fri Nov 28 22:03:41 2014 +0100

    x86: Replace seq_printf() with seq_puts()
    
    seq_puts is a lot cheaper than seq_printf, so use that to print
    literal strings.
    
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Link: http://lkml.kernel.org/r/1417208622-12264-1-git-send-email-linux@rasmusvillemoes.dk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 922d28581024..6307a0f0cf17 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -59,78 +59,78 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "%*s: ", prec, "NMI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->__nmi_count);
-	seq_printf(p, "  Non-maskable interrupts\n");
+	seq_puts(p, "  Non-maskable interrupts\n");
 #ifdef CONFIG_X86_LOCAL_APIC
 	seq_printf(p, "%*s: ", prec, "LOC");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
-	seq_printf(p, "  Local timer interrupts\n");
+	seq_puts(p, "  Local timer interrupts\n");
 
 	seq_printf(p, "%*s: ", prec, "SPU");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
-	seq_printf(p, "  Spurious interrupts\n");
+	seq_puts(p, "  Spurious interrupts\n");
 	seq_printf(p, "%*s: ", prec, "PMI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
-	seq_printf(p, "  Performance monitoring interrupts\n");
+	seq_puts(p, "  Performance monitoring interrupts\n");
 	seq_printf(p, "%*s: ", prec, "IWI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_irq_work_irqs);
-	seq_printf(p, "  IRQ work interrupts\n");
+	seq_puts(p, "  IRQ work interrupts\n");
 	seq_printf(p, "%*s: ", prec, "RTR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->icr_read_retry_count);
-	seq_printf(p, "  APIC ICR read retries\n");
+	seq_puts(p, "  APIC ICR read retries\n");
 #endif
 	if (x86_platform_ipi_callback) {
 		seq_printf(p, "%*s: ", prec, "PLT");
 		for_each_online_cpu(j)
 			seq_printf(p, "%10u ", irq_stats(j)->x86_platform_ipis);
-		seq_printf(p, "  Platform interrupts\n");
+		seq_puts(p, "  Platform interrupts\n");
 	}
 #ifdef CONFIG_SMP
 	seq_printf(p, "%*s: ", prec, "RES");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
-	seq_printf(p, "  Rescheduling interrupts\n");
+	seq_puts(p, "  Rescheduling interrupts\n");
 	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count -
 					irq_stats(j)->irq_tlb_count);
-	seq_printf(p, "  Function call interrupts\n");
+	seq_puts(p, "  Function call interrupts\n");
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
-	seq_printf(p, "  TLB shootdowns\n");
+	seq_puts(p, "  TLB shootdowns\n");
 #endif
 #ifdef CONFIG_X86_THERMAL_VECTOR
 	seq_printf(p, "%*s: ", prec, "TRM");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_thermal_count);
-	seq_printf(p, "  Thermal event interrupts\n");
+	seq_puts(p, "  Thermal event interrupts\n");
 #endif
 #ifdef CONFIG_X86_MCE_THRESHOLD
 	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
-	seq_printf(p, "  Threshold APIC interrupts\n");
+	seq_puts(p, "  Threshold APIC interrupts\n");
 #endif
 #ifdef CONFIG_X86_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_exception_count, j));
-	seq_printf(p, "  Machine check exceptions\n");
+	seq_puts(p, "  Machine check exceptions\n");
 	seq_printf(p, "%*s: ", prec, "MCP");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
-	seq_printf(p, "  Machine check polls\n");
+	seq_puts(p, "  Machine check polls\n");
 #endif
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
 	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_hv_callback_count);
-	seq_printf(p, "  Hypervisor callback interrupts\n");
+	seq_puts(p, "  Hypervisor callback interrupts\n");
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 71998d1be4ae70e7d320cdd21595c1a02a29c61e
Merge: b2e09f633a39 fb24da805729
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 20:03:47 2014 -0700

    Merge branch 'x86-irq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 irq fixes from Ingo Molnar:
     "Two changes: a cpu-hotplug/irq race fix, plus a HyperV related fix"
    
    * 'x86-irq-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/irq: Fix fixup_irqs() error handling
      x86, irq, pic: Probe for legacy PIC and set legacy_pic appropriately

commit ac2a55395eddccd6e3e39532df9869d61e97b2ee
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue May 13 11:39:34 2014 -0400

    x86: irq: Get correct available vectors for cpu disable
    
    check_irq_vectors_for_cpu_disable() can overestimate the number of
    available interrupt vectors, so the check for cpu down succeeds, but
    the actual cpu removal fails.
    
    It iterates from FIRST_EXTERNAL_VECTOR to NR_VECTORS, which is wrong
    because the systems vectors are not taken into account.
    
    Limit the search to first_system_vector instead of NR_VECTORS.
    
    The second indicator for vector availability the used_vectors bitmap
    is not taken into account at all. So system vectors,
    e.g. IA32_SYSCALL_VECTOR (0x80) and IRQ_MOVE_CLEANUP_VECTOR (0x20),
    are accounted as available.
    
    Add a check for the used_vectors bitmap and do not account vectors
    which are marked there.
    
    [ tglx: Simplified code. Rewrote changelog and code comments. ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Prarit Bhargava <prarit@redhat.com>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: K. Y. Srinivasan <kys@microsoft.com>
    Cc: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Elliott, Robert (Server Storage)" <Elliott@hp.com>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1400160305-17774-2-git-send-email-prarit@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 283a76a9cc40..11ccfb0a63e7 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -17,6 +17,7 @@
 #include <asm/idle.h>
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
+#include <asm/desc.h>
 
 #define CREATE_TRACE_POINTS
 #include <asm/trace/irq_vectors.h>
@@ -334,10 +335,17 @@ int check_irq_vectors_for_cpu_disable(void)
 	for_each_online_cpu(cpu) {
 		if (cpu == this_cpu)
 			continue;
-		for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS;
-		     vector++) {
-			if (per_cpu(vector_irq, cpu)[vector] < 0)
-				count++;
+		/*
+		 * We scan from FIRST_EXTERNAL_VECTOR to first system
+		 * vector. If the vector is marked in the used vectors
+		 * bitmap or an irq is assigned to it, we don't count
+		 * it as available.
+		 */
+		for (vector = FIRST_EXTERNAL_VECTOR;
+		     vector < first_system_vector; vector++) {
+			if (!test_bit(vector, used_vectors) &&
+			    per_cpu(vector_irq, cpu)[vector] < 0)
+					count++;
 		}
 	}
 

commit fb24da805729ee4a83efa34015948f7d64da4b28
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Wed Apr 2 08:11:13 2014 -0400

    x86/irq: Fix fixup_irqs() error handling
    
    Several patches to fix cpu hotplug and the down'd cpu's irq
    relocations have been submitted in the past month or so.  The
    patches should resolve the problems with cpu hotplug and irq
    relocation, however, there is always a possibility that a bug
    still exists.  The big problem with debugging these irq
    reassignments is that the cpu down completes and then we get
    random stack traces from drivers for which irqs have not been
    properly assigned to a new cpu.  The stack traces are a mix of
    storage, network, and other kernel subsystem (I once saw the
    serial port stop working ...) warnings and failures.
    
    The problem with these failures is that they are difficult to
    diagnose. There is no warning in the cpu hotplug down path to
    indicate that an IRQ has failed to be assigned to a new cpu, and
    all we are left with is a stack trace from a driver, or a
    non-functional device.  If we had some information on the
    console debugging these situations would be much easier; after
    all we can map an IRQ to a device by simply using lspci or
    /proc/interrupts.
    
    The current code, fixup_irqs(), which migrates IRQs from the
    down'd cpu and is called close to the end of the cpu down path,
    calls chip->set_irq_affinity which eventually calls
    __assign_irq_vector(). Errors are not propogated back from this
    function call and this results in silent irq relocation
    failures.
    
    This patch fixes this issue by returning the error codes up the
    call stack and prints out a warning if there is a relocation
    failure.
    
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Rui Wang <rui.y.wang@intel.com>
    Cc: Liu Ping Fan <kernelfans@gmail.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Yoshihiro YUNOMAE <yoshihiro.yunomae.ez@hitachi.com>
    Cc: Lv Zheng <lv.zheng@intel.com>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Yang Zhang <yang.z.zhang@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
    Cc: Li Fei <fei.li@intel.com>
    Cc: gong.chen@linux.intel.com
    Link: http://lkml.kernel.org/r/1396440673-18286-1-git-send-email-prarit@redhat.com
    [ Made small cleanliness tweaks. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 283a76a9cc40..49bbb57da7f5 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -357,6 +357,7 @@ void fixup_irqs(void)
 	struct irq_desc *desc;
 	struct irq_data *data;
 	struct irq_chip *chip;
+	int ret;
 
 	for_each_irq_desc(irq, desc) {
 		int break_affinity = 0;
@@ -395,10 +396,14 @@ void fixup_irqs(void)
 		if (!irqd_can_move_in_process_context(data) && chip->irq_mask)
 			chip->irq_mask(data);
 
-		if (chip->irq_set_affinity)
-			chip->irq_set_affinity(data, affinity, true);
-		else if (!(warned++))
-			set_affinity = 0;
+		if (chip->irq_set_affinity) {
+			ret = chip->irq_set_affinity(data, affinity, true);
+			if (ret == -ENOSPC)
+				pr_crit("IRQ %d set affinity failed because there are no available vectors.  The device assigned to this IRQ is unstable.\n", irq);
+		} else {
+			if (!(warned++))
+				set_affinity = 0;
+		}
 
 		/*
 		 * We unmask if the irq was not marked masked by the

commit f704a7d7f1d815621cb4c47f7a94787e1bd7c27c
Author: K. Y. Srinivasan <kys@microsoft.com>
Date:   Tue Apr 1 23:51:42 2014 -0700

    x86/platform/hyperv: Handle VMBUS driver being a module
    
    Hyper-V VMBUS driver can be a module; handle this case
    correctly. Please apply.
    
    Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
    Cc: olaf@aepfle.de
    Cc: apw@canonical.com
    Cc: jasowang@redhat.com
    Link: http://lkml.kernel.org/r/1396421502-23222-1-git-send-email-kys@microsoft.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 42805fac0092..283a76a9cc40 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -125,7 +125,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
 	seq_printf(p, "  Machine check polls\n");
 #endif
-#if defined(CONFIG_HYPERV) || defined(CONFIG_XEN)
+#if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
 	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_hv_callback_count);

commit 929320e4b4c10708d3477d7e395f0ce7b0cc8744
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 23 21:40:20 2014 +0000

    x86: Add proper vector accounting for HYPERVISOR_CALLBACK_VECTOR
    
    HyperV abuses a device interrupt to account for the
    HYPERVISOR_CALLBACK_VECTOR.
    
    Provide proper accounting as we have for the other vectors as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: K. Y. Srinivasan <kys@microsoft.com>
    Cc: x86 <x86@kernel.org>
    Link: http://lkml.kernel.org/r/20140223212738.681855582@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index d99f31d9a750..42805fac0092 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -124,6 +124,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
 	seq_printf(p, "  Machine check polls\n");
+#endif
+#if defined(CONFIG_HYPERV) || defined(CONFIG_XEN)
+	seq_printf(p, "%*s: ", prec, "THR");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_hv_callback_count);
+	seq_printf(p, "  Hypervisor callback interrupts\n");
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 39424e89d64661faa0a2e00c5ad1e6dbeebfa972
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Tue Jan 28 08:22:11 2014 -0500

    x86, cpu hotplug: Fix stack frame warning in check_irq_vectors_for_cpu_disable()
    
    Further discussion here: http://marc.info/?l=linux-kernel&m=139073901101034&w=2
    
    kbuild, 0day kernel build service, outputs the warning:
    
    arch/x86/kernel/irq.c:333:1: warning: the frame size of 2056 bytes
    is larger than 2048 bytes [-Wframe-larger-than=]
    
    because check_irq_vectors_for_cpu_disable() allocates two cpumasks on the
    stack.   Fix this by moving the two cpumasks to a global file context.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Tested-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Link: http://lkml.kernel.org/r/1390915331-27375-1-git-send-email-prarit@redhat.com
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Yang Zhang <yang.z.zhang@Intel.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Janet Morgan <janet.morgan@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Ruiv Wang <ruiv.wang@gmail.com>
    Cc: Gong Chen <gong.chen@linux.intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index dbb60878b744..d99f31d9a750 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -266,6 +266,14 @@ __visible void smp_trace_x86_platform_ipi(struct pt_regs *regs)
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
 #ifdef CONFIG_HOTPLUG_CPU
+
+/* These two declarations are only used in check_irq_vectors_for_cpu_disable()
+ * below, which is protected by stop_machine().  Putting them on the stack
+ * results in a stack frame overflow.  Dynamically allocating could result in a
+ * failure so declare these two cpumasks as global.
+ */
+static struct cpumask affinity_new, online_new;
+
 /*
  * This cpu is going to be removed and its vectors migrated to the remaining
  * online cpus.  Check to see if there are enough vectors in the remaining cpus.
@@ -277,7 +285,6 @@ int check_irq_vectors_for_cpu_disable(void)
 	unsigned int this_cpu, vector, this_count, count;
 	struct irq_desc *desc;
 	struct irq_data *data;
-	struct cpumask affinity_new, online_new;
 
 	this_cpu = smp_processor_id();
 	cpumask_copy(&online_new, cpu_online_mask);

commit 7fe67a1180db49d41a3f764c379a08f8e31580ec
Merge: fab5669d5562 da6139e49c7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 20 12:11:41 2014 -0800

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull leftover x86 fixes from Ingo Molnar:
     "Two leftover fixes that did not make it into v3.13"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Add check for number of available vectors before CPU down
      x86, cpu, amd: Add workaround for family 16h, erratum 793

commit da6139e49c7cb0f4251265cb5243b8d220adb48d
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Mon Jan 13 06:51:01 2014 -0500

    x86: Add check for number of available vectors before CPU down
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=64791
    
    When a cpu is downed on a system, the irqs on the cpu are assigned to
    other cpus.  It is possible, however, that when a cpu is downed there
    aren't enough free vectors on the remaining cpus to account for the
    vectors from the cpu that is being downed.
    
    This results in an interesting "overflow" condition where irqs are
    "assigned" to a CPU but are not handled.
    
    For example, when downing cpus on a 1-64 logical processor system:
    
    <snip>
    [  232.021745] smpboot: CPU 61 is now offline
    [  238.480275] smpboot: CPU 62 is now offline
    [  245.991080] ------------[ cut here ]------------
    [  245.996270] WARNING: CPU: 0 PID: 0 at net/sched/sch_generic.c:264 dev_watchdog+0x246/0x250()
    [  246.005688] NETDEV WATCHDOG: p786p1 (ixgbe): transmit queue 0 timed out
    [  246.013070] Modules linked in: lockd sunrpc iTCO_wdt iTCO_vendor_support sb_edac ixgbe microcode e1000e pcspkr joydev edac_core lpc_ich ioatdma ptp mdio mfd_core i2c_i801 dca pps_core i2c_core wmi acpi_cpufreq isci libsas scsi_transport_sas
    [  246.037633] CPU: 0 PID: 0 Comm: swapper/0 Not tainted 3.12.0+ #14
    [  246.044451] Hardware name: Intel Corporation S4600LH ........../SVRBD-ROW_T, BIOS SE5C600.86B.01.08.0003.022620131521 02/26/2013
    [  246.057371]  0000000000000009 ffff88081fa03d40 ffffffff8164fbf6 ffff88081fa0ee48
    [  246.065728]  ffff88081fa03d90 ffff88081fa03d80 ffffffff81054ecc ffff88081fa13040
    [  246.074073]  0000000000000000 ffff88200cce0000 0000000000000040 0000000000000000
    [  246.082430] Call Trace:
    [  246.085174]  <IRQ>  [<ffffffff8164fbf6>] dump_stack+0x46/0x58
    [  246.091633]  [<ffffffff81054ecc>] warn_slowpath_common+0x8c/0xc0
    [  246.098352]  [<ffffffff81054fb6>] warn_slowpath_fmt+0x46/0x50
    [  246.104786]  [<ffffffff815710d6>] dev_watchdog+0x246/0x250
    [  246.110923]  [<ffffffff81570e90>] ? dev_deactivate_queue.constprop.31+0x80/0x80
    [  246.119097]  [<ffffffff8106092a>] call_timer_fn+0x3a/0x110
    [  246.125224]  [<ffffffff8106280f>] ? update_process_times+0x6f/0x80
    [  246.132137]  [<ffffffff81570e90>] ? dev_deactivate_queue.constprop.31+0x80/0x80
    [  246.140308]  [<ffffffff81061db0>] run_timer_softirq+0x1f0/0x2a0
    [  246.146933]  [<ffffffff81059a80>] __do_softirq+0xe0/0x220
    [  246.152976]  [<ffffffff8165fedc>] call_softirq+0x1c/0x30
    [  246.158920]  [<ffffffff810045f5>] do_softirq+0x55/0x90
    [  246.164670]  [<ffffffff81059d35>] irq_exit+0xa5/0xb0
    [  246.170227]  [<ffffffff8166062a>] smp_apic_timer_interrupt+0x4a/0x60
    [  246.177324]  [<ffffffff8165f40a>] apic_timer_interrupt+0x6a/0x70
    [  246.184041]  <EOI>  [<ffffffff81505a1b>] ? cpuidle_enter_state+0x5b/0xe0
    [  246.191559]  [<ffffffff81505a17>] ? cpuidle_enter_state+0x57/0xe0
    [  246.198374]  [<ffffffff81505b5d>] cpuidle_idle_call+0xbd/0x200
    [  246.204900]  [<ffffffff8100b7ae>] arch_cpu_idle+0xe/0x30
    [  246.210846]  [<ffffffff810a47b0>] cpu_startup_entry+0xd0/0x250
    [  246.217371]  [<ffffffff81646b47>] rest_init+0x77/0x80
    [  246.223028]  [<ffffffff81d09e8e>] start_kernel+0x3ee/0x3fb
    [  246.229165]  [<ffffffff81d0989f>] ? repair_env_string+0x5e/0x5e
    [  246.235787]  [<ffffffff81d095a5>] x86_64_start_reservations+0x2a/0x2c
    [  246.242990]  [<ffffffff81d0969f>] x86_64_start_kernel+0xf8/0xfc
    [  246.249610] ---[ end trace fb74fdef54d79039 ]---
    [  246.254807] ixgbe 0000:c2:00.0 p786p1: initiating reset due to tx timeout
    [  246.262489] ixgbe 0000:c2:00.0 p786p1: Reset adapter
    Last login: Mon Nov 11 08:35:14 from 10.18.17.119
    [root@(none) ~]# [  246.792676] ixgbe 0000:c2:00.0 p786p1: detected SFP+: 5
    [  249.231598] ixgbe 0000:c2:00.0 p786p1: NIC Link is Up 10 Gbps, Flow Control: RX/TX
    [  246.792676] ixgbe 0000:c2:00.0 p786p1: detected SFP+: 5
    [  249.231598] ixgbe 0000:c2:00.0 p786p1: NIC Link is Up 10 Gbps, Flow Control: RX/TX
    
    (last lines keep repeating.  ixgbe driver is dead until module reload.)
    
    If the downed cpu has more vectors than are free on the remaining cpus on the
    system, it is possible that some vectors are "orphaned" even though they are
    assigned to a cpu.  In this case, since the ixgbe driver had a watchdog, the
    watchdog fired and notified that something was wrong.
    
    This patch adds a function, check_vectors(), to compare the number of vectors
    on the CPU going down and compares it to the number of vectors available on
    the system.  If there aren't enough vectors for the CPU to go down, an
    error is returned and propogated back to userspace.
    
    v2: Do not need to look at percpu irqs
    v3: Need to check affinity to prevent counting of MSIs in IOAPIC Lowest
        Priority Mode
    v4: Additional changes suggested by Gong Chen.
    v5/v6/v7/v8: Updated comment text
    
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Link: http://lkml.kernel.org/r/1389613861-3853-1-git-send-email-prarit@redhat.com
    Reviewed-by: Gong Chen <gong.chen@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Yang Zhang <yang.z.zhang@Intel.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Janet Morgan <janet.morgan@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Ruiv Wang <ruiv.wang@gmail.com>
    Cc: Gong Chen <gong.chen@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: <stable@vger.kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 22d0687e7fda..4207e8d1a094 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -262,6 +262,76 @@ __visible void smp_trace_x86_platform_ipi(struct pt_regs *regs)
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
 #ifdef CONFIG_HOTPLUG_CPU
+/*
+ * This cpu is going to be removed and its vectors migrated to the remaining
+ * online cpus.  Check to see if there are enough vectors in the remaining cpus.
+ * This function is protected by stop_machine().
+ */
+int check_irq_vectors_for_cpu_disable(void)
+{
+	int irq, cpu;
+	unsigned int this_cpu, vector, this_count, count;
+	struct irq_desc *desc;
+	struct irq_data *data;
+	struct cpumask affinity_new, online_new;
+
+	this_cpu = smp_processor_id();
+	cpumask_copy(&online_new, cpu_online_mask);
+	cpu_clear(this_cpu, online_new);
+
+	this_count = 0;
+	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
+		irq = __this_cpu_read(vector_irq[vector]);
+		if (irq >= 0) {
+			desc = irq_to_desc(irq);
+			data = irq_desc_get_irq_data(desc);
+			cpumask_copy(&affinity_new, data->affinity);
+			cpu_clear(this_cpu, affinity_new);
+
+			/* Do not count inactive or per-cpu irqs. */
+			if (!irq_has_action(irq) || irqd_is_per_cpu(data))
+				continue;
+
+			/*
+			 * A single irq may be mapped to multiple
+			 * cpu's vector_irq[] (for example IOAPIC cluster
+			 * mode).  In this case we have two
+			 * possibilities:
+			 *
+			 * 1) the resulting affinity mask is empty; that is
+			 * this the down'd cpu is the last cpu in the irq's
+			 * affinity mask, or
+			 *
+			 * 2) the resulting affinity mask is no longer
+			 * a subset of the online cpus but the affinity
+			 * mask is not zero; that is the down'd cpu is the
+			 * last online cpu in a user set affinity mask.
+			 */
+			if (cpumask_empty(&affinity_new) ||
+			    !cpumask_subset(&affinity_new, &online_new))
+				this_count++;
+		}
+	}
+
+	count = 0;
+	for_each_online_cpu(cpu) {
+		if (cpu == this_cpu)
+			continue;
+		for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS;
+		     vector++) {
+			if (per_cpu(vector_irq, cpu)[vector] < 0)
+				count++;
+		}
+	}
+
+	if (count < this_count) {
+		pr_warn("CPU %d disable failed: CPU has %u vectors assigned and there are only %u available.\n",
+			this_cpu, this_count, count);
+		return -ERANGE;
+	}
+	return 0;
+}
+
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)
 {

commit 9345005f4eed805308193658d12e4e7e9c261e74
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Sun Jan 5 11:10:52 2014 -0500

    x86/irq: Fix do_IRQ() interrupt warning for cpu hotplug retriggered irqs
    
    During heavy CPU-hotplug operations the following spurious kernel warnings
    can trigger:
    
      do_IRQ: No ... irq handler for vector (irq -1)
    
      [ See: https://bugzilla.kernel.org/show_bug.cgi?id=64831 ]
    
    When downing a cpu it is possible that there are unhandled irqs
    left in the APIC IRR register.  The following code path shows
    how the problem can occur:
    
     1. CPU 5 is to go down.
    
     2. cpu_disable() on CPU 5 executes with interrupt flag cleared
        by local_irq_save() via stop_machine().
    
     3. IRQ 12 asserts on CPU 5, setting IRR but not ISR because
        interrupt flag is cleared (CPU unabled to handle the irq)
    
     4. IRQs are migrated off of CPU 5, and the vectors' irqs are set
        to -1. 5. stop_machine() finishes cpu_disable()
    
     6. cpu_die() for CPU 5 executes in normal context.
    
     7. CPU 5 attempts to handle IRQ 12 because the IRR is set for
        IRQ 12.  The code attempts to find the vector's IRQ and cannot
        because it has been set to -1. 8. do_IRQ() warning displays
        warning about CPU 5 IRQ 12.
    
    I added a debug printk to output which CPU & vector was
    retriggered and discovered that that we are getting bogus
    events.  I see a 100% correlation between this debug printk in
    fixup_irqs() and the do_IRQ() warning.
    
    This patchset resolves this by adding definitions for
    VECTOR_UNDEFINED(-1) and VECTOR_RETRIGGERED(-2) and modifying
    the code to use them.
    
    Fixes: https://bugzilla.kernel.org/show_bug.cgi?id=64831
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Reviewed-by: Rui Wang <rui.y.wang@intel.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Yang Zhang <yang.z.zhang@Intel.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: janet.morgan@Intel.com
    Cc: tony.luck@Intel.com
    Cc: ruiv.wang@gmail.com
    Link: http://lkml.kernel.org/r/1388938252-16627-1-git-send-email-prarit@redhat.com
    [ Cleaned up the code a bit. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 22d0687e7fda..884d875c1434 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -193,9 +193,13 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	if (!handle_irq(irq, regs)) {
 		ack_APIC_irq();
 
-		if (printk_ratelimit())
-			pr_emerg("%s: %d.%d No irq handler for vector (irq %d)\n",
-				__func__, smp_processor_id(), vector, irq);
+		if (irq != VECTOR_RETRIGGERED) {
+			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector (irq %d)\n",
+					     __func__, smp_processor_id(),
+					     vector, irq);
+		} else {
+			__this_cpu_write(vector_irq[vector], VECTOR_UNDEFINED);
+		}
 	}
 
 	irq_exit();
@@ -344,7 +348,7 @@ void fixup_irqs(void)
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		unsigned int irr;
 
-		if (__this_cpu_read(vector_irq[vector]) < 0)
+		if (__this_cpu_read(vector_irq[vector]) <= VECTOR_UNDEFINED)
 			continue;
 
 		irr = apic_read(APIC_IRR + (vector / 32 * 0x10));
@@ -355,11 +359,14 @@ void fixup_irqs(void)
 			data = irq_desc_get_irq_data(desc);
 			chip = irq_data_get_irq_chip(data);
 			raw_spin_lock(&desc->lock);
-			if (chip->irq_retrigger)
+			if (chip->irq_retrigger) {
 				chip->irq_retrigger(data);
+				__this_cpu_write(vector_irq[vector], VECTOR_RETRIGGERED);
+			}
 			raw_spin_unlock(&desc->lock);
 		}
-		__this_cpu_write(vector_irq[vector], -1);
+		if (__this_cpu_read(vector_irq[vector]) != VECTOR_RETRIGGERED)
+			__this_cpu_write(vector_irq[vector], VECTOR_UNDEFINED);
 	}
 }
 #endif

commit 1d9090e2fb32c84277cef6e72a21be7f78c929f4
Author: Andi Kleen <ak@linux.intel.com>
Date:   Mon Aug 5 15:02:37 2013 -0700

    x86, asmlinkage: Make all interrupt handlers asmlinkage / __visible
    
    These handlers are all referenced from assembler stubs, so need
    to be visible.
    
    The handlers without arguments become asmlinkage, the others __visible
    to not force regparms(0) on x86-32.
    
    I put it all into a single patch, please let me know if you want
    it it split up.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1375740170-7446-4-git-send-email-andi@firstfloor.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3a8185c042a2..22d0687e7fda 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -177,7 +177,7 @@ u64 arch_irq_stat(void)
  * SMP cross-CPU interrupts have their own specific
  * handlers).
  */
-unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
+__visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
@@ -215,7 +215,7 @@ void __smp_x86_platform_ipi(void)
 		x86_platform_ipi_callback();
 }
 
-void smp_x86_platform_ipi(struct pt_regs *regs)
+__visible void smp_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
@@ -229,7 +229,7 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 /*
  * Handler for POSTED_INTERRUPT_VECTOR.
  */
-void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
+__visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
@@ -247,7 +247,7 @@ void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 }
 #endif
 
-void smp_trace_x86_platform_ipi(struct pt_regs *regs)
+__visible void smp_trace_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 

commit 83ab85140bc1492f92de263a1c30ea04a0f465f7
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Fri Jun 21 10:29:05 2013 -0400

    trace,x86: Move creation of irq tracepoints from apic.c to irq.c
    
    Compiling without CONFIG_X86_LOCAL_APIC set, apic.c will not be
    compiled, and the irq tracepoints will not be created via the
    CREATE_TRACE_POINTS macro. When CONFIG_X86_LOCAL_APIC is not set,
    we get the following build error:
    
      LD      init/built-in.o
    arch/x86/built-in.o: In function `trace_x86_platform_ipi_entry':
    linux-test.git/arch/x86/include/asm/trace/irq_vectors.h:66: undefined reference to `__tracepoint_x86_platform_ipi_entry'
    arch/x86/built-in.o: In function `trace_x86_platform_ipi_exit':
    linux-test.git/arch/x86/include/asm/trace/irq_vectors.h:66: undefined reference to `__tracepoint_x86_platform_ipi_exit'
    arch/x86/built-in.o: In function `trace_irq_work_entry':
    linux-test.git/arch/x86/include/asm/trace/irq_vectors.h:72: undefined reference to `__tracepoint_irq_work_entry'
    arch/x86/built-in.o: In function `trace_irq_work_exit':
    linux-test.git/arch/x86/include/asm/trace/irq_vectors.h:72: undefined reference to `__tracepoint_irq_work_exit'
    arch/x86/built-in.o:(__jump_table+0x8): undefined reference to `__tracepoint_x86_platform_ipi_entry'
    arch/x86/built-in.o:(__jump_table+0x14): undefined reference to `__tracepoint_x86_platform_ipi_exit'
    arch/x86/built-in.o:(__jump_table+0x20): undefined reference to `__tracepoint_irq_work_entry'
    arch/x86/built-in.o:(__jump_table+0x2c): undefined reference to `__tracepoint_irq_work_exit'
    make[1]: *** [vmlinux] Error 1
    make: *** [sub-make] Error 2
    
    As irq.c is always compiled for x86, it is a more appropriate location
    to create the irq tracepoints.
    
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 06af119743a6..3a8185c042a2 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -17,6 +17,8 @@
 #include <asm/idle.h>
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
+
+#define CREATE_TRACE_POINTS
 #include <asm/trace/irq_vectors.h>
 
 atomic_t irq_err_count;

commit cf910e83ae23692fdeefc7e506e504c4c468d38a
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Thu Jun 20 11:46:53 2013 -0400

    x86, trace: Add irq vector tracepoints
    
    [Purpose of this patch]
    
    As Vaibhav explained in the thread below, tracepoints for irq vectors
    are useful.
    
    http://www.spinics.net/lists/mm-commits/msg85707.html
    
    <snip>
    The current interrupt traces from irq_handler_entry and irq_handler_exit
    provide when an interrupt is handled.  They provide good data about when
    the system has switched to kernel space and how it affects the currently
    running processes.
    
    There are some IRQ vectors which trigger the system into kernel space,
    which are not handled in generic IRQ handlers.  Tracing such events gives
    us the information about IRQ interaction with other system events.
    
    The trace also tells where the system is spending its time.  We want to
    know which cores are handling interrupts and how they are affecting other
    processes in the system.  Also, the trace provides information about when
    the cores are idle and which interrupts are changing that state.
    <snip>
    
    On the other hand, my usecase is tracing just local timer event and
    getting a value of instruction pointer.
    
    I suggested to add an argument local timer event to get instruction pointer before.
    But there is another way to get it with external module like systemtap.
    So, I don't need to add any argument to irq vector tracepoints now.
    
    [Patch Description]
    
    Vaibhav's patch shared a trace point ,irq_vector_entry/irq_vector_exit, in all events.
    But there is an above use case to trace specific irq_vector rather than tracing all events.
    In this case, we are concerned about overhead due to unwanted events.
    
    So, add following tracepoints instead of introducing irq_vector_entry/exit.
    so that we can enable them independently.
       - local_timer_vector
       - reschedule_vector
       - call_function_vector
       - call_function_single_vector
       - irq_work_entry_vector
       - error_apic_vector
       - thermal_apic_vector
       - threshold_apic_vector
       - spurious_apic_vector
       - x86_platform_ipi_vector
    
    Also, introduce a logic switching IDT at enabling/disabling time so that a time penalty
    makes a zero when tracepoints are disabled. Detailed explanations are as follows.
     - Create trace irq handlers with entering_irq()/exiting_irq().
     - Create a new IDT, trace_idt_table, at boot time by adding a logic to
       _set_gate(). It is just a copy of original idt table.
     - Register the new handlers for tracpoints to the new IDT by introducing
       macros to alloc_intr_gate() called at registering time of irq_vector handlers.
     - Add checking, whether irq vector tracing is on/off, into load_current_idt().
       This has to be done below debug checking for these reasons.
       - Switching to debug IDT may be kicked while tracing is enabled.
       - On the other hands, switching to trace IDT is kicked only when debugging
         is disabled.
    
    In addition, the new IDT is created only when CONFIG_TRACING is enabled to avoid being
    used for other purposes.
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Link: http://lkml.kernel.org/r/51C323ED.5050708@hds.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e3b8df1754cc..06af119743a6 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -17,6 +17,7 @@
 #include <asm/idle.h>
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
+#include <asm/trace/irq_vectors.h>
 
 atomic_t irq_err_count;
 
@@ -244,6 +245,18 @@ void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 }
 #endif
 
+void smp_trace_x86_platform_ipi(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	entering_ack_irq();
+	trace_x86_platform_ipi_entry(X86_PLATFORM_IPI_VECTOR);
+	__smp_x86_platform_ipi();
+	trace_x86_platform_ipi_exit(X86_PLATFORM_IPI_VECTOR);
+	exiting_irq();
+	set_irq_regs(old_regs);
+}
+
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
 #ifdef CONFIG_HOTPLUG_CPU

commit eddc0e922a3530e0f22cef170229bcae3a7d5e31
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Thu Jun 20 11:45:17 2013 -0400

    x86, trace: Introduce entering/exiting_irq()
    
    When implementing tracepoints in interrupt handers, if the tracepoints are
    simply added in the performance sensitive path of interrupt handers,
    it may cause potential performance problem due to the time penalty.
    
    To solve the problem, an idea is to prepare non-trace/trace irq handers and
    switch their IDTs at the enabling/disabling time.
    
    So, let's introduce entering_irq()/exiting_irq() for pre/post-
    processing of each irq handler.
    
    A way to use them is as follows.
    
    Non-trace irq handler:
    smp_irq_handler()
    {
            entering_irq();         /* pre-processing of this handler */
            __smp_irq_handler();    /*
                                     * common logic between non-trace and trace handlers
                                     * in a vector.
                                     */
            exiting_irq();          /* post-processing of this handler */
    
    }
    
    Trace irq_handler:
    smp_trace_irq_handler()
    {
            entering_irq();         /* pre-processing of this handler */
            trace_irq_entry();      /* tracepoint for irq entry */
            __smp_irq_handler();    /*
                                     * common logic between non-trace and trace handlers
                                     * in a vector.
                                     */
            trace_irq_exit();       /* tracepoint for irq exit */
            exiting_irq();          /* post-processing of this handler */
    
    }
    
    If tracepoints can place outside entering_irq()/exiting_irq() as follows,
    it looks cleaner.
    
    smp_trace_irq_handler()
    {
            trace_irq_entry();
            smp_irq_handler();
            trace_irq_exit();
    }
    
    But it doesn't work.
    The problem is with irq_enter/exit() being called. They must be called before
    trace_irq_enter/exit(),  because of the rcu_irq_enter() must be called before
    any tracepoints are used, as tracepoints use  rcu to synchronize.
    
    As a possible alternative, we may be able to call irq_enter() first as follows
    if irq_enter() can nest.
    
    smp_trace_irq_hander()
    {
            irq_entry();
            trace_irq_entry();
            smp_irq_handler();
            trace_irq_exit();
            irq_exit();
    }
    
    But it doesn't work, either.
    If irq_enter() is nested, it may have a time penalty because it has to check if it
    was already called or not. The time penalty is not desired in performance sensitive
    paths even if it is tiny.
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Link: http://lkml.kernel.org/r/51C3238D.9040706@hds.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index ac0631d8996f..e3b8df1754cc 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -204,23 +204,21 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 /*
  * Handler for X86_PLATFORM_IPI_VECTOR.
  */
-void smp_x86_platform_ipi(struct pt_regs *regs)
+void __smp_x86_platform_ipi(void)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
-
-	ack_APIC_irq();
-
-	irq_enter();
-
-	exit_idle();
-
 	inc_irq_stat(x86_platform_ipis);
 
 	if (x86_platform_ipi_callback)
 		x86_platform_ipi_callback();
+}
 
-	irq_exit();
+void smp_x86_platform_ipi(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
 
+	entering_ack_irq();
+	__smp_x86_platform_ipi();
+	exiting_irq();
 	set_irq_regs(old_regs);
 }
 

commit 01227a889ed56ae53aeebb9f93be9d54dd8b2de8
Merge: 9e6879460c8e db6ae6158186
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun May 5 14:47:31 2013 -0700

    Merge tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Gleb Natapov:
     "Highlights of the updates are:
    
      general:
       - new emulated device API
       - legacy device assignment is now optional
       - irqfd interface is more generic and can be shared between arches
    
      x86:
       - VMCS shadow support and other nested VMX improvements
       - APIC virtualization and Posted Interrupt hardware support
       - Optimize mmio spte zapping
    
      ppc:
        - BookE: in-kernel MPIC emulation with irqfd support
        - Book3S: in-kernel XICS emulation (incomplete)
        - Book3S: HV: migration fixes
        - BookE: more debug support preparation
        - BookE: e6500 support
    
      ARM:
       - reworking of Hyp idmaps
    
      s390:
       - ioeventfd for virtio-ccw
    
      And many other bug fixes, cleanups and improvements"
    
    * tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (204 commits)
      kvm: Add compat_ioctl for device control API
      KVM: x86: Account for failing enable_irq_window for NMI window request
      KVM: PPC: Book3S: Add API for in-kernel XICS emulation
      kvm/ppc/mpic: fix missing unlock in set_base_addr()
      kvm/ppc: Hold srcu lock when calling kvm_io_bus_read/write
      kvm/ppc/mpic: remove users
      kvm/ppc/mpic: fix mmio region lists when multiple guests used
      kvm/ppc/mpic: remove default routes from documentation
      kvm: KVM_CAP_IOMMU only available with device assignment
      ARM: KVM: iterate over all CPUs for CPU compatibility check
      KVM: ARM: Fix spelling in error message
      ARM: KVM: define KVM_ARM_MAX_VCPUS unconditionally
      KVM: ARM: Fix API documentation for ONE_REG encoding
      ARM: KVM: promote vfp_host pointer to generic host cpu context
      ARM: KVM: add architecture specific hook for capabilities
      ARM: KVM: perform HYP initilization for hotplugged CPUs
      ARM: KVM: switch to a dual-step HYP init code
      ARM: KVM: rework HYP page table freeing
      ARM: KVM: enforce maximum size for identity mapped code
      ARM: KVM: move to a KVM provided HYP idmap
      ...

commit f7b0e1055574ce06ab53391263b4e205bf38daf3
Author: Li Fei <fei.li@intel.com>
Date:   Fri Apr 26 20:50:11 2013 +0800

    x86: Eliminate irq_mis_count counted in arch_irq_stat
    
    With the current implementation, kstat_cpu(cpu).irqs_sum is also
    increased in case of irq_mis_count increment.
    
    So there is no need to count irq_mis_count in arch_irq_stat,
    otherwise irq_mis_count will be counted twice in the sum of
    /proc/stat.
    
    Reported-by: Liu Chuansheng <chuansheng.liu@intel.com>
    Signed-off-by: Li Fei <fei.li@intel.com>
    Acked-by: Liu Chuansheng <chuansheng.liu@intel.com>
    Cc: tomoki.sekiyama.qu@hitachi.com
    Cc: joe@perches.com
    Link: http://lkml.kernel.org/r/1366980611.32469.7.camel@fli24-HP-Compaq-8100-Elite-CMT-PC
    Cc: <stable@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e4595f105910..84b778962c66 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -165,10 +165,6 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 u64 arch_irq_stat(void)
 {
 	u64 sum = atomic_read(&irq_err_count);
-
-#ifdef CONFIG_X86_IO_APIC
-	sum += atomic_read(&irq_mis_count);
-#endif
 	return sum;
 }
 

commit d78f2664832f8d70e36422af9a10e44276dced48
Author: Yang Zhang <yang.z.zhang@Intel.com>
Date:   Thu Apr 11 19:25:11 2013 +0800

    KVM: VMX: Register a new IPI for posted interrupt
    
    Posted Interrupt feature requires a special IPI to deliver posted interrupt
    to guest. And it should has a high priority so the interrupt will not be
    blocked by others.
    Normally, the posted interrupt will be consumed by vcpu if target vcpu is
    running and transparent to OS. But in some cases, the interrupt will arrive
    when target vcpu is scheduled out. And host will see it. So we need to
    register a dump handler to handle it.
    
    Signed-off-by: Yang Zhang <yang.z.zhang@Intel.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Gleb Natapov <gleb@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index e4595f105910..6ae6ea1d27d9 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -228,6 +228,28 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
+#ifdef CONFIG_HAVE_KVM
+/*
+ * Handler for POSTED_INTERRUPT_VECTOR.
+ */
+void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	ack_APIC_irq();
+
+	irq_enter();
+
+	exit_idle();
+
+	inc_irq_stat(kvm_posted_intr_ipis);
+
+	irq_exit();
+
+	set_irq_regs(old_regs);
+}
+#endif
+
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
 #ifdef CONFIG_HOTPLUG_CPU

commit 229993001282e128a49a59ec43d255614775703a
Merge: 7687b80a4f5a fd0f5869724f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 1 11:13:33 2012 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86/mm changes from Ingo Molnar:
     "The biggest change is new TLB partial flushing code for AMD CPUs.
      (The v3.6 kernel had the Intel CPU side code, see commits
      e0ba94f14f74..effee4b9b3b.)
    
      There's also various other refinements around the TLB flush code"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Distinguish TLB shootdown interrupts from other functions call interrupts
      x86/mm: Fix range check in tlbflush debugfs interface
      x86, cpu: Preset default tlb_flushall_shift on AMD
      x86, cpu: Add AMD TLB size detection
      x86, cpu: Push TLB detection CPUID check down
      x86, cpu: Fixup tlb_flushall_shift formatting

commit fd0f5869724ff6195c6e7f12f8287c66a132e0ba
Author: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
Date:   Wed Sep 26 11:11:28 2012 +0900

    x86: Distinguish TLB shootdown interrupts from other functions call interrupts
    
    As TLB shootdown requests to other CPU cores are now using function call
    interrupts, TLB shootdowns entry in /proc/interrupts is always shown as 0.
    
    This behavior change was introduced by commit 52aec3308db8 ("x86/tlb:
    replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR").
    
    This patch reverts TLB shootdowns entry in /proc/interrupts to count TLB
    shootdowns separately from the other function call interrupts.
    
    Signed-off-by: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
    Link: http://lkml.kernel.org/r/20120926021128.22212.20440.stgit@hpxw
    Acked-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 1f5f1d5d2a02..355b13f6de8d 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -92,7 +92,8 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  Rescheduling interrupts\n");
 	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
+		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count -
+					irq_stats(j)->irq_tlb_count);
 	seq_printf(p, "  Function call interrupts\n");
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
@@ -147,7 +148,6 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;
 	sum += irq_stats(cpu)->irq_call_count;
-	sum += irq_stats(cpu)->irq_tlb_count;
 #endif
 #ifdef CONFIG_X86_THERMAL_VECTOR
 	sum += irq_stats(cpu)->irq_thermal_count;

commit 2530cd4f448935c74eeb49f29559589928e4b2f0
Author: Liu, Chuansheng <chuansheng.liu@intel.com>
Date:   Tue Aug 14 06:55:01 2012 +0000

    x86/fixup_irq: Use cpu_online_mask instead of cpu_all_mask
    
    When one CPU is going down and this CPU is the last one in irq
    affinity, current code is setting cpu_all_mask as the new
    affinity for that irq.
    
    But for some systems (such as in Medfield Android mobile) the
    firmware sends the interrupt to each CPU in the irq affinity
    mask, averaged, and cpu_all_mask includes all potential CPUs,
    i.e. offline ones as well.
    
    So replace cpu_all_mask with cpu_online_mask.
    
    Signed-off-by: liu chuansheng <chuansheng.liu@intel.com>
    Acked-by: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/27240C0AC20F114CBF8149A2696CBE4A137286@SHSMSX101.ccr.corp.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 7ad683d78645..d44f7829968e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -270,7 +270,7 @@ void fixup_irqs(void)
 
 		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
 			break_affinity = 1;
-			affinity = cpu_all_mask;
+			affinity = cpu_online_mask;
 		}
 
 		chip = irq_data_get_irq_chip(data);

commit 1d44b30f35a9873a65b320dd5300088fa995fd94
Author: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
Date:   Thu Jul 26 19:47:32 2012 +0900

    x86/ioapic: Fix NULL pointer dereference on CPU hotplug after disabling irqs
    
    In the current kernel, percpu variable `vector_irq' is not always
    cleared when a CPU is offlined. If the CPU that has the disabled
    irqs in vector_irq is hotplugged again, __setup_vector_irq()
    hits invalid irq vector and may crash.
    
    This bug can be reproduced as following;
    
     # echo 0 > /sys/devices/system/cpu/cpu7/online
     # modprobe -r some_driver_using_interrupts     # vector_irq@cpu7 uncleared
     # echo 1 > /sys/devices/system/cpu/cpu7/online # kernel may crash
    
    To fix this problem, this patch clears vector_irq in
    __fixup_irqs() when the CPU is offlined.
    
    This also reverts commit f6175f5bfb4c, which partially fixes
    this bug by clearing vector in __clear_irq_vector(). But in
    environments with IOMMU IRQ remapper, it could fail because
    cfg->domain doesn't contain offlined CPUs. With this patch, the
    fix in __clear_irq_vector() can be reverted because every
    vector_irq is already cleared in __fixup_irqs() on offlined CPUs.
    
    Signed-off-by: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: yrl.pp-manager.tt@hitachi.com
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Alexander Gordeev <agordeev@redhat.com>
    Link: http://lkml.kernel.org/r/20120726104732.2889.19144.stgit@kvmdev
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 1f5f1d5d2a02..7ad683d78645 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -328,6 +328,7 @@ void fixup_irqs(void)
 				chip->irq_retrigger(data);
 			raw_spin_unlock(&desc->lock);
 		}
+		__this_cpu_write(vector_irq[vector], -1);
 	}
 }
 #endif

commit c767a54ba0657e52e6edaa97cbe0b0a8bf1c1655
Author: Joe Perches <joe@perches.com>
Date:   Mon May 21 19:50:07 2012 -0700

    x86/debug: Add KERN_<LEVEL> to bare printks, convert printks to pr_<level>
    
    Use a more current logging style:
    
     - Bare printks should have a KERN_<LEVEL> for consistency's sake
     - Add pr_fmt where appropriate
     - Neaten some macro definitions
     - Convert some Ok output to OK
     - Use "%s: ", __func__ in pr_fmt for summit
     - Convert some printks to pr_<level>
    
    Message output is not identical in all cases.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: levinsasha928@gmail.com
    Link: http://lkml.kernel.org/r/1337655007.24226.10.camel@joe2Laptop
    [ merged two similar patches, tidied up the changelog ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3dafc6003b7c..1f5f1d5d2a02 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -294,9 +294,9 @@ void fixup_irqs(void)
 		raw_spin_unlock(&desc->lock);
 
 		if (break_affinity && set_affinity)
-			printk("Broke affinity for irq %i\n", irq);
+			pr_notice("Broke affinity for irq %i\n", irq);
 		else if (!set_affinity)
-			printk("Cannot set affinity for irq %i\n", irq);
+			pr_notice("Cannot set affinity for irq %i\n", irq);
 	}
 
 	/*

commit 99dd5497e5be4fe4194cad181d45fd6569a930db
Author: Liu, Chuansheng <chuansheng.liu@intel.com>
Date:   Mon Mar 26 07:11:50 2012 +0000

    x86: Preserve lazy irq disable semantics in fixup_irqs()
    
    The default irq_disable() sematics are to mark the interrupt disabled,
    but keep it unmasked. If the interrupt is delivered while marked
    disabled, the low level interrupt handler masks it and marks it
    pending. This is important for detecting wakeup interrupts during
    suspend and for edge type interrupts to avoid losing interrupts.
    
    fixup_irqs() moves the interrupts away from an offlined cpu. For
    certain interrupt types it needs to mask the interrupt line before
    changing the affinity. After affinity has changed the interrupt line
    is unmasked again, but only if it is not marked disabled.
    
    This breaks the lazy irq disable semantics and causes problems in
    suspend as the interrupt can be lost or wakeup functionality is
    broken.
    
    Check irqd_irq_masked() instead of irqd_irq_disabled() because
    irqd_irq_masked() is only set, when the core code actually masked the
    interrupt line. If it's not set, we unmask the interrupt and let the
    lazy irq disable logic deal with an eventually incoming interrupt.
    
    [ tglx: Massaged changelog and added a comment ]
    
    Signed-off-by: liu chuansheng <chuansheng.liu@intel.com>
    Cc: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Link: http://lkml.kernel.org/r/27240C0AC20F114CBF8149A2696CBE4A05DFB3@SHSMSX101.ccr.corp.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 7943e0c21bde..3dafc6003b7c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -282,8 +282,13 @@ void fixup_irqs(void)
 		else if (!(warned++))
 			set_affinity = 0;
 
+		/*
+		 * We unmask if the irq was not marked masked by the
+		 * core code. That respects the lazy irq disable
+		 * behaviour.
+		 */
 		if (!irqd_can_move_in_process_context(data) &&
-		    !irqd_irq_disabled(data) && chip->irq_unmask)
+		    !irqd_irq_masked(data) && chip->irq_unmask)
 			chip->irq_unmask(data);
 
 		raw_spin_unlock(&desc->lock);

commit 67b0243131150391125d8d0beb5359d7aec78b55
Merge: 376613e81ddc c284b42abadb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 6 13:58:21 2012 -0800

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Skip cpus with apic-ids >= 255 in !x2apic_mode
      x86, x2apic: Allow "nox2apic" to disable x2apic mode setup by BIOS
      x86, x2apic: Fallback to xapic when BIOS doesn't setup interrupt-remapping
      x86, acpi: Skip acpi x2apic entries if the x2apic feature is not present
      x86, apic: Add probe() for apic_flat
      x86: Simplify code by removing a !SMP #ifdefs from 'struct cpuinfo_x86'
      x86: Convert per-cpu counter icr_read_retry_count into a member of irq_stat
      x86: Add per-cpu stat counter for APIC ICR read tries
      pci, x86/io-apic: Allow PCI_IOAPIC to be user configurable on x86
      x86: Fix the !CONFIG_NUMA build of the new CPU ID fixup code support
      x86: Add NumaChip support
      x86: Add x86_init platform override to fix up NUMA core numbering
      x86: Make flat_init_apic_ldr() available

commit b49d7d877ff96428c8cd2076b33ba72bf85ceaba
Author: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
Date:   Thu Dec 15 11:32:24 2011 +0900

    x86: Convert per-cpu counter icr_read_retry_count into a member of irq_stat
    
    LAPIC related statistics are grouped inside the per-cpu
    structure irq_stat, so there is no need for icr_read_retry_count
    to be a standalone per-cpu variable.
    
    This patch moves icr_read_retry_count to where it belongs.
    
    Suggested-y: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
    Cc: Jörn Engel <joern@logfs.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4bbf1627905b..ef54ed4e307d 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -76,7 +76,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  IRQ work interrupts\n");
 	seq_printf(p, "%*s: ", prec, "RTR");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", per_cpu(icr_read_retry_count, j));
+		seq_printf(p, "%10u ", irq_stats(j)->icr_read_retry_count);
 	seq_printf(p, "  APIC ICR read retries\n");
 #endif
 	if (x86_platform_ipi_callback) {
@@ -140,7 +140,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->irq_spurious_count;
 	sum += irq_stats(cpu)->apic_perf_irqs;
 	sum += irq_stats(cpu)->apic_irq_work_irqs;
-	sum += per_cpu(icr_read_retry_count, cpu);
+	sum += irq_stats(cpu)->icr_read_retry_count;
 #endif
 	if (x86_platform_ipi_callback)
 		sum += irq_stats(cpu)->x86_platform_ipis;

commit 346b46be5f10e4d247160ea94ac34450be60ce1e
Author: Fernando Luis Vázquez Cao <fernando@oss.ntt.co.jp>
Date:   Tue Dec 13 11:51:53 2011 +0900

    x86: Add per-cpu stat counter for APIC ICR read tries
    
    In the IPI delivery slow path (NMI delivery) we retry the ICR
    read to check for delivery completion a limited number of times.
    
    [ The reason for the limited retries is that some of the places
      where it is used (cpu boot, kdump, etc) IPI delivery might not
      succeed (due to a firmware bug or system crash, for example)
      and in such a case it is better to give up and resume
      execution of other code. ]
    
    This patch adds a new entry to /proc/interrupts, RTR, which
    tells user space the number of times we retried the ICR read in
    the IPI delivery slow path.
    
    This should give some insight into how well the APIC
    message delivery hardware is working - if the counts are way
    too large then we are hitting a (very-) slow path way too
    often.
    
    Signed-off-by: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
    Cc: Jörn Engel <joern@logfs.org>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/n/tip-vzsp20lo2xdzh5f70g0eis2s@git.kernel.org
    [ extended the changelog ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 429e0c92924e..4bbf1627905b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -74,6 +74,10 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_irq_work_irqs);
 	seq_printf(p, "  IRQ work interrupts\n");
+	seq_printf(p, "%*s: ", prec, "RTR");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(icr_read_retry_count, j));
+	seq_printf(p, "  APIC ICR read retries\n");
 #endif
 	if (x86_platform_ipi_callback) {
 		seq_printf(p, "%*s: ", prec, "PLT");
@@ -136,6 +140,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->irq_spurious_count;
 	sum += irq_stats(cpu)->apic_perf_irqs;
 	sum += irq_stats(cpu)->apic_irq_work_irqs;
+	sum += per_cpu(icr_read_retry_count, cpu);
 #endif
 	if (x86_platform_ipi_callback)
 		sum += irq_stats(cpu)->x86_platform_ipis;

commit 98ad1cc14a5c4fd658f9d72c6ba5c86dfd3ce0d5
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 7 18:22:09 2011 +0200

    x86: Call idle notifier after irq_enter()
    
    Interrupts notify the idle exit state before calling irq_enter().
    But the notifier code calls rcu_read_lock() and this is not
    allowed while rcu is in an extended quiescent state. We need
    to wait for irq_enter() -> rcu_idle_exit() to be called before
    doing so otherwise this results in a grumpy RCU:
    
    [    0.099991] WARNING: at include/linux/rcupdate.h:194 __atomic_notifier_call_chain+0xd2/0x110()
    [    0.099991] Hardware name: AMD690VM-FMH
    [    0.099991] Modules linked in:
    [    0.099991] Pid: 0, comm: swapper Not tainted 3.0.0-rc6+ #255
    [    0.099991] Call Trace:
    [    0.099991]  <IRQ>  [<ffffffff81051c8a>] warn_slowpath_common+0x7a/0xb0
    [    0.099991]  [<ffffffff81051cd5>] warn_slowpath_null+0x15/0x20
    [    0.099991]  [<ffffffff817d6fa2>] __atomic_notifier_call_chain+0xd2/0x110
    [    0.099991]  [<ffffffff817d6ff1>] atomic_notifier_call_chain+0x11/0x20
    [    0.099991]  [<ffffffff81001873>] exit_idle+0x43/0x50
    [    0.099991]  [<ffffffff81020439>] smp_apic_timer_interrupt+0x39/0xa0
    [    0.099991]  [<ffffffff817da253>] apic_timer_interrupt+0x13/0x20
    [    0.099991]  <EOI>  [<ffffffff8100ae67>] ? default_idle+0xa7/0x350
    [    0.099991]  [<ffffffff8100ae65>] ? default_idle+0xa5/0x350
    [    0.099991]  [<ffffffff8100b19b>] amd_e400_idle+0x8b/0x110
    [    0.099991]  [<ffffffff810cb01f>] ? rcu_enter_nohz+0x8f/0x160
    [    0.099991]  [<ffffffff810019a0>] cpu_idle+0xb0/0x110
    [    0.099991]  [<ffffffff817a7505>] rest_init+0xe5/0x140
    [    0.099991]  [<ffffffff817a7468>] ? rest_init+0x48/0x140
    [    0.099991]  [<ffffffff81cc5ca3>] start_kernel+0x3d1/0x3dc
    [    0.099991]  [<ffffffff81cc5321>] x86_64_start_reservations+0x131/0x135
    [    0.099991]  [<ffffffff81cc5412>] x86_64_start_kernel+0xed/0xf4
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Andy Henroid <andrew.d.henroid@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 429e0c92924e..5d31e5bdbf85 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -181,8 +181,8 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	unsigned vector = ~regs->orig_ax;
 	unsigned irq;
 
-	exit_idle();
 	irq_enter();
+	exit_idle();
 
 	irq = __this_cpu_read(vector_irq[vector]);
 
@@ -209,10 +209,10 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 
 	ack_APIC_irq();
 
-	exit_idle();
-
 	irq_enter();
 
+	exit_idle();
+
 	inc_irq_stat(x86_platform_ipis);
 
 	if (x86_platform_ipi_callback)

commit 69c60c88eeb364ebf58432f9bc38033522d58767
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu May 26 12:22:53 2011 -0400

    x86: Fix files explicitly requiring export.h for EXPORT_SYMBOL/THIS_MODULE
    
    These files were implicitly getting EXPORT_SYMBOL via device.h
    which was including module.h, but that will be fixed up shortly.
    
    By fixing these now, we can avoid seeing things like:
    
    arch/x86/kernel/rtc.c:29: warning: type defaults to ‘int’ in declaration of ‘EXPORT_SYMBOL’
    arch/x86/kernel/pci-dma.c:20: warning: type defaults to ‘int’ in declaration of ‘EXPORT_SYMBOL’
    arch/x86/kernel/e820.c:69: warning: type defaults to ‘int’ in declaration of ‘EXPORT_SYMBOL_GPL’
    
    [ with input from Randy Dunlap <rdunlap@xenotime.net> and also
      from Stephen Rothwell <sfr@canb.auug.org.au> ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 6c0802eb2f7f..429e0c92924e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -9,6 +9,7 @@
 #include <linux/smp.h>
 #include <linux/ftrace.h>
 #include <linux/delay.h>
+#include <linux/export.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>

commit 983bbf1af0664b78689612b247acb514300f62c7
Author: Tian, Kevin <kevin.tian@intel.com>
Date:   Fri May 6 14:43:56 2011 +0800

    x86: Don't unmask disabled irqs when migrating them
    
    It doesn't make sense to unconditionally unmask a disabled irq when
    migrating it from offlined cpu to another. If the irq triggers then it
    will be disabled in the interrupt handler anyway. So we can just avoid
    unmasking it.
    
    [ tglx: Made masking unconditional again and fixed the changelog ]
    
    Signed-off-by: Fengzhe Zhang <fengzhe.zhang@intel.com>
    Signed-off-by: Kevin Tian <kevin.tian@intel.com>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: "xen-devel@lists.xensource.com" <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/%3C625BA99ED14B2D499DC4E29D8138F1505C8ED7F7E3%40shsmsx502.ccr.corp.intel.com%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 544efe2741be..6c0802eb2f7f 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -276,7 +276,8 @@ void fixup_irqs(void)
 		else if (!(warned++))
 			set_affinity = 0;
 
-		if (!irqd_can_move_in_process_context(data) && chip->irq_unmask)
+		if (!irqd_can_move_in_process_context(data) &&
+		    !irqd_irq_disabled(data) && chip->irq_unmask)
 			chip->irq_unmask(data);
 
 		raw_spin_unlock(&desc->lock);

commit b87ba87ca26e226b2277a2d5613ed596f408e96d
Author: Tian, Kevin <kevin.tian@intel.com>
Date:   Fri May 6 14:43:36 2011 +0800

    x86: Skip migrating IRQF_PER_CPU irqs in fixup_irqs()
    
    IRQF_PER_CPU means that the irq cannot be moved away from a given
    cpu. So it must not be migrated when the cpu goes offline.
    
    [ tglx: massaged changelog ]
    
    Signed-off-by: Fengzhe Zhang <fengzhe.zhang@intel.com>
    Signed-off-by: Kevin Tian <kevin.tian@intel.com>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: "xen-devel@lists.xensource.com" <xen-devel@lists.xensource.com>
    Link: http://lkml.kernel.org/r/%3C625BA99ED14B2D499DC4E29D8138F1505C8ED7F7E2%40shsmsx502.ccr.corp.intel.com%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 1cb0b9fc78dc..544efe2741be 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -249,7 +249,7 @@ void fixup_irqs(void)
 
 		data = irq_desc_get_irq_data(desc);
 		affinity = data->affinity;
-		if (!irq_has_action(irq) ||
+		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
 		    cpumask_subset(affinity, cpu_online_mask)) {
 			raw_spin_unlock(&desc->lock);
 			continue;

commit ca444564a947034557a85357b3911d067cac4b8f
Author: Jean Delvare <khali@linux-fr.org>
Date:   Fri Mar 25 15:20:14 2011 +0100

    x86: Stop including <linux/delay.h> in two asm header files
    
    Stop including <linux/delay.h> in x86 header files which don't
    need it. This will let the compiler complain when this header is
    not included by source files when it should, so that
    contributors can fix the problem before building on other
    architectures starts to fail.
    
    Credits go to Geert for the idea.
    
    Signed-off-by: Jean Delvare <khali@linux-fr.org>
    Cc: James E.J. Bottomley <James.Bottomley@suse.de>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    LKML-Reference: <20110325152014.297890ec@endymion.delvare>
    [ this also fixes an upstream build bug in drivers/media/rc/ite-cir.c ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 948a31eae75f..1cb0b9fc78dc 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -8,6 +8,7 @@
 #include <linux/seq_file.h>
 #include <linux/smp.h>
 #include <linux/ftrace.h>
+#include <linux/delay.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>

commit d10902812c9cd5583130a4ebb9ad19c60b68149d
Merge: 181f977d134a 25874a299ef8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 15 20:01:36 2011 -0700

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (27 commits)
      x86: Clean up apic.c and apic.h
      x86: Remove superflous goal definition of tsc_sync
      x86: dt: Correct local apic documentation in device tree bindings
      x86: dt: Cleanup local apic setup
      x86: dt: Fix OLPC=y/INTEL_CE=n build
      rtc: cmos: Add OF bindings
      x86: ce4100: Use OF to setup devices
      x86: ioapic: Add OF bindings for IO_APIC
      x86: dtb: Add generic bus probe
      x86: dtb: Add support for PCI devices backed by dtb nodes
      x86: dtb: Add device tree support for HPET
      x86: dtb: Add early parsing of IO_APIC
      x86: dtb: Add irq domain abstraction
      x86: dtb: Add a device tree for CE4100
      x86: Add device tree support
      x86: e820: Remove conditional early mapping in parse_e820_ext
      x86: OLPC: Make OLPC=n build again
      x86: OLPC: Remove extra OLPC_OPENFIRMWARE_DT indirection
      x86: OLPC: Cleanup config maze completely
      x86: OLPC: Hide OLPC_OPENFIRMWARE config switch
      ...
    
    Fix up conflicts in arch/x86/platform/ce4100/ce4100.c

commit 517e49815677b43b26d3167aadca83919ef36a45
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 16 17:59:57 2010 +0100

    x86: Use generic show_interrupts
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 00bf99df583c..5ee693faa111 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -44,9 +44,9 @@ void ack_bad_irq(unsigned int irq)
 
 #define irq_stats(x)		(&per_cpu(irq_stat, x))
 /*
- * /proc/interrupts printing:
+ * /proc/interrupts printing for arch specific interrupts
  */
-static int show_other_interrupts(struct seq_file *p, int prec)
+int arch_show_interrupts(struct seq_file *p, int prec)
 {
 	int j;
 
@@ -122,59 +122,6 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	return 0;
 }
 
-int show_interrupts(struct seq_file *p, void *v)
-{
-	unsigned long flags, any_count = 0;
-	int i = *(loff_t *) v, j, prec;
-	struct irqaction *action;
-	struct irq_desc *desc;
-
-	if (i > nr_irqs)
-		return 0;
-
-	for (prec = 3, j = 1000; prec < 10 && j <= nr_irqs; ++prec)
-		j *= 10;
-
-	if (i == nr_irqs)
-		return show_other_interrupts(p, prec);
-
-	/* print header */
-	if (i == 0) {
-		seq_printf(p, "%*s", prec + 8, "");
-		for_each_online_cpu(j)
-			seq_printf(p, "CPU%-8d", j);
-		seq_putc(p, '\n');
-	}
-
-	desc = irq_to_desc(i);
-	if (!desc)
-		return 0;
-
-	raw_spin_lock_irqsave(&desc->lock, flags);
-	for_each_online_cpu(j)
-		any_count |= kstat_irqs_cpu(i, j);
-	action = desc->action;
-	if (!action && !any_count)
-		goto out;
-
-	seq_printf(p, "%*d: ", prec, i);
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-	seq_printf(p, " %8s", desc->irq_data.chip->name);
-	seq_printf(p, "-%-8s", desc->name);
-
-	if (action) {
-		seq_printf(p, "  %s", action->name);
-		while ((action = action->next) != NULL)
-			seq_printf(p, ", %s", action->name);
-	}
-
-	seq_putc(p, '\n');
-out:
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	return 0;
-}
-
 /*
  * /proc/stat helpers
  */

commit 51c43ac6e4540786a6d79ea318b30f7bfa615ec7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 21:40:36 2011 +0100

    x86: Use the proper accessors in fixup_irqs()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 78793efd3180..00bf99df583c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -293,6 +293,7 @@ void fixup_irqs(void)
 	static int warned;
 	struct irq_desc *desc;
 	struct irq_data *data;
+	struct irq_chip *chip;
 
 	for_each_irq_desc(irq, desc) {
 		int break_affinity = 0;
@@ -307,7 +308,7 @@ void fixup_irqs(void)
 		/* interrupt's are disabled at this point */
 		raw_spin_lock(&desc->lock);
 
-		data = &desc->irq_data;
+		data = irq_desc_get_irq_data(desc);
 		affinity = data->affinity;
 		if (!irq_has_action(irq) ||
 		    cpumask_subset(affinity, cpu_online_mask)) {
@@ -327,16 +328,17 @@ void fixup_irqs(void)
 			affinity = cpu_all_mask;
 		}
 
-		if (!(desc->status & IRQ_MOVE_PCNTXT) && data->chip->irq_mask)
-			data->chip->irq_mask(data);
+		chip = irq_data_get_irq_chip(data);
+		if (!irqd_can_move_in_process_context(data) && chip->irq_mask)
+			chip->irq_mask(data);
 
-		if (data->chip->irq_set_affinity)
-			data->chip->irq_set_affinity(data, affinity, true);
+		if (chip->irq_set_affinity)
+			chip->irq_set_affinity(data, affinity, true);
 		else if (!(warned++))
 			set_affinity = 0;
 
-		if (!(desc->status & IRQ_MOVE_PCNTXT) && data->chip->irq_unmask)
-			data->chip->irq_unmask(data);
+		if (!irqd_can_move_in_process_context(data) && chip->irq_unmask)
+			chip->irq_unmask(data);
 
 		raw_spin_unlock(&desc->lock);
 
@@ -368,10 +370,11 @@ void fixup_irqs(void)
 			irq = __this_cpu_read(vector_irq[vector]);
 
 			desc = irq_to_desc(irq);
-			data = &desc->irq_data;
+			data = irq_desc_get_irq_data(desc);
+			chip = irq_data_get_irq_chip(data);
 			raw_spin_lock(&desc->lock);
-			if (data->chip->irq_retrigger)
-				data->chip->irq_retrigger(data);
+			if (chip->irq_retrigger)
+				chip->irq_retrigger(data);
 			raw_spin_unlock(&desc->lock);
 		}
 	}

commit da6b737b9ab768dd06bb4b0395131d10e524cf83
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Feb 22 21:07:37 2011 +0100

    x86: Add device tree support
    
    This patch adds minimal support for device tree on x86. The device
    tree blob is passed to the kernel via setup_data which requires at
    least boot protocol 2.09.
    
    Memory size, restricted memory regions, boot arguments are gathered
    the traditional way so things like cmd_line are just here to let the
    code compile.
    
    The current plan is use the device tree as an extension and to gather
    information which can not be enumerated and would have to be hardcoded
    otherwise. This includes things like
       - which devices are on this I2C/SPI bus?
       - how are the interrupts wired to IO APIC?
       - where could my hpet be?
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Dirk Brandewie <dirk.brandewie@gmail.com>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: sodaville@linutronix.de
    Cc: devicetree-discuss@lists.ozlabs.org
    LKML-Reference: <1298405266-1624-3-git-send-email-bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 387b6a0c9e81..753136003af1 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -276,15 +276,6 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
-#ifdef CONFIG_OF
-unsigned int irq_create_of_mapping(struct device_node *controller,
-		const u32 *intspec, unsigned int intsize)
-{
-	return intspec[0];
-}
-EXPORT_SYMBOL_GPL(irq_create_of_mapping);
-#endif
-
 #ifdef CONFIG_HOTPLUG_CPU
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)

commit 58bff947e2d164c7e5cbf7f485e4b3d4884befeb
Author: Jan Beulich <JBeulich@novell.com>
Date:   Thu Feb 17 15:54:26 2011 +0000

    x86: Eliminate pointless adjustment attempts in fixup_irqs()
    
    Not only when an IRQ's affinity equals cpu_online_mask is there
    no need to actually try to adjust the affinity, but also when
    it's a subset thereof. This particularly avoids adjustment
    attempts during system shutdown to any IRQs bound to CPU#0.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Gary Hade <garyhade@us.ibm.com>
    LKML-Reference: <4D5D52C2020000780003272C@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 387b6a0c9e81..78793efd3180 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -310,7 +310,7 @@ void fixup_irqs(void)
 		data = &desc->irq_data;
 		affinity = data->affinity;
 		if (!irq_has_action(irq) ||
-		    cpumask_equal(affinity, cpu_online_mask)) {
+		    cpumask_subset(affinity, cpu_online_mask)) {
 			raw_spin_unlock(&desc->lock);
 			continue;
 		}

commit 5117348dea5e3ecbb785cfa1271386fb49332b41
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 12 11:51:03 2011 +0100

    x86: Readd missing irq_to_desc() in fixup_irq()
    
    commit a3c08e5d(x86: Convert irq_chip access to new functions)
    accidentally zapped desc = irq_to_desc(irq); in the vector loop.
    So we lock some random irq descriptor.
    
    Add it back.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: <stable@kernel.org> # .37

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 52945da52a94..387b6a0c9e81 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -367,7 +367,8 @@ void fixup_irqs(void)
 		if (irr  & (1 << (vector % 32))) {
 			irq = __this_cpu_read(vector_irq[vector]);
 
-			data = irq_get_irq_data(irq);
+			desc = irq_to_desc(irq);
+			data = &desc->irq_data;
 			raw_spin_lock(&desc->lock);
 			if (data->chip->irq_retrigger)
 				data->chip->irq_retrigger(data);

commit e691d24e9c5007486bef59c589c2a2d784e0c30b
Merge: 55065bc52795 b5318d302f8a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 13 10:15:12 2011 -0800

    Merge branch 'x86-olpc-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-olpc-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, olpc: Speed up device tree creation during boot
      x86, olpc: Add OLPC device-tree support
      x86, of: Define irq functions to allow drivers/of/* to build on x86

commit 0a3aee0da4402aa19b66e458038533c896fb80c6
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Dec 18 16:28:55 2010 +0100

    x86: Use this_cpu_ops to optimize code
    
    Go through x86 code and replace __get_cpu_var and get_cpu_var
    instances that refer to a scalar and are not used for address
    determinations.
    
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 83ec0175f986..3a43caa3beb7 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -234,7 +234,7 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	exit_idle();
 	irq_enter();
 
-	irq = __get_cpu_var(vector_irq)[vector];
+	irq = __this_cpu_read(vector_irq[vector]);
 
 	if (!handle_irq(irq, regs)) {
 		ack_APIC_irq();
@@ -350,12 +350,12 @@ void fixup_irqs(void)
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		unsigned int irr;
 
-		if (__get_cpu_var(vector_irq)[vector] < 0)
+		if (__this_cpu_read(vector_irq[vector]) < 0)
 			continue;
 
 		irr = apic_read(APIC_IRR + (vector / 32 * 0x10));
 		if (irr  & (1 << (vector % 32))) {
-			irq = __get_cpu_var(vector_irq)[vector];
+			irq = __this_cpu_read(vector_irq[vector]);
 
 			data = irq_get_irq_data(irq);
 			raw_spin_lock(&desc->lock);

commit 4722d194e648fb5755faecee895b96b26f9732f3
Author: Andres Salomon <dilinger@queued.net>
Date:   Fri Nov 12 05:45:26 2010 +0000

    x86, of: Define irq functions to allow drivers/of/* to build on x86
    
    - Define a stub irq_create_of_mapping for x86 as a stop-gap solution until
       drivers/of/irq is further along.
     - Define irq_dispose_mapping for x86 to appease of_i2c.c
    
    These are needed to allow stuff in drivers/of/ to build on x86.  This stuff
    will eventually get replaced; quoting Grant,
    
    "The long term plan is to have the drivers/of/ code handling the mapping
    intelligently like powerpc currently does."  But for now, just provide
    these functions.
    
    Signed-off-by: Andres Salomon <dilinger@queued.net>
    LKML-Reference: <20101111214526.5de7121b@queued.net>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 83ec0175f986..d833d1b962a5 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -4,6 +4,7 @@
 #include <linux/cpu.h>
 #include <linux/interrupt.h>
 #include <linux/kernel_stat.h>
+#include <linux/of.h>
 #include <linux/seq_file.h>
 #include <linux/smp.h>
 #include <linux/ftrace.h>
@@ -275,6 +276,15 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 
+#ifdef CONFIG_OF
+unsigned int irq_create_of_mapping(struct device_node *controller,
+		const u32 *intspec, unsigned int intsize)
+{
+	return intspec[0];
+}
+EXPORT_SYMBOL_GPL(irq_create_of_mapping);
+#endif
+
 #ifdef CONFIG_HOTPLUG_CPU
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)

commit 4a60cfa9457749f7987fd4f3c956dbba5a281129
Merge: 62bea97f54d8 27afdf2008da
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 14:11:46 2010 -0700

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (96 commits)
      apic, x86: Use BIOS settings for IBS and MCE threshold interrupt LVT offsets
      apic, x86: Check if EILVT APIC registers are available (AMD only)
      x86: ioapic: Call free_irte only if interrupt remapping enabled
      arm: Use ARCH_IRQ_INIT_FLAGS
      genirq, ARM: Fix boot on ARM platforms
      genirq: Fix CONFIG_GENIRQ_NO_DEPRECATED=y build
      x86: Switch sparse_irq allocations to GFP_KERNEL
      genirq: Switch sparse_irq allocator to GFP_KERNEL
      genirq: Make sparse_lock a mutex
      x86: lguest: Use new irq allocator
      genirq: Remove the now unused sparse irq leftovers
      genirq: Sanitize dynamic irq handling
      genirq: Remove arch_init_chip_data()
      x86: xen: Sanitise sparse_irq handling
      x86: Use sane enumeration
      x86: uv: Clean up the direct access to irq_desc
      x86: Make io_apic.c local functions static
      genirq: Remove irq_2_iommu
      x86: Speed up the irq_remapped check in hot pathes
      intr_remap: Simplify the code further
      ...
    
    Fix up trivial conflicts in arch/x86/Kconfig

commit e360adbe29241a0194e10e20595360dd7b98a2b3
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Oct 14 14:01:34 2010 +0800

    irq_work: Add generic hardirq context callbacks
    
    Provide a mechanism that allows running code in IRQ context. It is
    most useful for NMI code that needs to interact with the rest of the
    system -- like wakeup a task to drain buffers.
    
    Perf currently has such a mechanism, so extract that and provide it as
    a generic feature, independent of perf so that others may also
    benefit.
    
    The IRQ context callback is generated through self-IPIs where
    possible, or on architectures like powerpc the decrementer (the
    built-in timer facility) is set to generate an interrupt immediately.
    
    Architectures that don't have anything like this get to do with a
    callback from the timer tick. These architectures can call
    irq_work_run() at the tail of any IRQ handlers that might enqueue such
    work (like the perf IRQ handler) to avoid undue latencies in
    processing the work.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    [ various fixes ]
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    LKML-Reference: <1287036094.7768.291.camel@yhuang-dev>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 91fd0c70a18a..44edb03fc9ec 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -67,10 +67,10 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
 	seq_printf(p, "  Performance monitoring interrupts\n");
-	seq_printf(p, "%*s: ", prec, "PND");
+	seq_printf(p, "%*s: ", prec, "IWI");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->apic_pending_irqs);
-	seq_printf(p, "  Performance pending work\n");
+		seq_printf(p, "%10u ", irq_stats(j)->apic_irq_work_irqs);
+	seq_printf(p, "  IRQ work interrupts\n");
 #endif
 	if (x86_platform_ipi_callback) {
 		seq_printf(p, "%*s: ", prec, "PLT");
@@ -185,7 +185,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->apic_timer_irqs;
 	sum += irq_stats(cpu)->irq_spurious_count;
 	sum += irq_stats(cpu)->apic_perf_irqs;
-	sum += irq_stats(cpu)->apic_pending_irqs;
+	sum += irq_stats(cpu)->apic_irq_work_irqs;
 #endif
 	if (x86_platform_ipi_callback)
 		sum += irq_stats(cpu)->x86_platform_ipis;

commit a3c08e5d80c54e32423efbba113b02942c91f726
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 8 20:24:58 2010 +0200

    x86: Convert irq_chip access to new functions
    
    Before moving the irq chips to the new functions, fixup direct callers.
    
    The cpu offline irq fixup code needs to become generic and archs need
    to honour the "force" flag as an indicator, but that's for later.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 91fd0c70a18a..d765bdc48074 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -159,7 +159,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	seq_printf(p, "%*d: ", prec, i);
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-	seq_printf(p, " %8s", desc->chip->name);
+	seq_printf(p, " %8s", desc->irq_data.chip->name);
 	seq_printf(p, "-%-8s", desc->name);
 
 	if (action) {
@@ -282,6 +282,7 @@ void fixup_irqs(void)
 	unsigned int irq, vector;
 	static int warned;
 	struct irq_desc *desc;
+	struct irq_data *data;
 
 	for_each_irq_desc(irq, desc) {
 		int break_affinity = 0;
@@ -296,7 +297,8 @@ void fixup_irqs(void)
 		/* interrupt's are disabled at this point */
 		raw_spin_lock(&desc->lock);
 
-		affinity = desc->affinity;
+		data = &desc->irq_data;
+		affinity = data->affinity;
 		if (!irq_has_action(irq) ||
 		    cpumask_equal(affinity, cpu_online_mask)) {
 			raw_spin_unlock(&desc->lock);
@@ -315,16 +317,16 @@ void fixup_irqs(void)
 			affinity = cpu_all_mask;
 		}
 
-		if (!(desc->status & IRQ_MOVE_PCNTXT) && desc->chip->mask)
-			desc->chip->mask(irq);
+		if (!(desc->status & IRQ_MOVE_PCNTXT) && data->chip->irq_mask)
+			data->chip->irq_mask(data);
 
-		if (desc->chip->set_affinity)
-			desc->chip->set_affinity(irq, affinity);
+		if (data->chip->irq_set_affinity)
+			data->chip->irq_set_affinity(data, affinity, true);
 		else if (!(warned++))
 			set_affinity = 0;
 
-		if (!(desc->status & IRQ_MOVE_PCNTXT) && desc->chip->unmask)
-			desc->chip->unmask(irq);
+		if (!(desc->status & IRQ_MOVE_PCNTXT) && data->chip->irq_unmask)
+			data->chip->irq_unmask(data);
 
 		raw_spin_unlock(&desc->lock);
 
@@ -355,10 +357,10 @@ void fixup_irqs(void)
 		if (irr  & (1 << (vector % 32))) {
 			irq = __get_cpu_var(vector_irq)[vector];
 
-			desc = irq_to_desc(irq);
+			data = irq_get_irq_data(irq);
 			raw_spin_lock(&desc->lock);
-			if (desc->chip->retrigger)
-				desc->chip->retrigger(irq);
+			if (data->chip->irq_retrigger)
+				data->chip->irq_retrigger(data);
 			raw_spin_unlock(&desc->lock);
 		}
 	}

commit 239007b8440abff689632f50cdf0f2b9e895b534
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 16:46:45 2009 +0100

    genirq: Convert irq_desc.lock to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 664bcb7384ac..91fd0c70a18a 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -149,7 +149,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	if (!desc)
 		return 0;
 
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	for_each_online_cpu(j)
 		any_count |= kstat_irqs_cpu(i, j);
 	action = desc->action;
@@ -170,7 +170,7 @@ int show_interrupts(struct seq_file *p, void *v)
 
 	seq_putc(p, '\n');
 out:
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
 }
 
@@ -294,12 +294,12 @@ void fixup_irqs(void)
 			continue;
 
 		/* interrupt's are disabled at this point */
-		spin_lock(&desc->lock);
+		raw_spin_lock(&desc->lock);
 
 		affinity = desc->affinity;
 		if (!irq_has_action(irq) ||
 		    cpumask_equal(affinity, cpu_online_mask)) {
-			spin_unlock(&desc->lock);
+			raw_spin_unlock(&desc->lock);
 			continue;
 		}
 
@@ -326,7 +326,7 @@ void fixup_irqs(void)
 		if (!(desc->status & IRQ_MOVE_PCNTXT) && desc->chip->unmask)
 			desc->chip->unmask(irq);
 
-		spin_unlock(&desc->lock);
+		raw_spin_unlock(&desc->lock);
 
 		if (break_affinity && set_affinity)
 			printk("Broke affinity for irq %i\n", irq);
@@ -356,10 +356,10 @@ void fixup_irqs(void)
 			irq = __get_cpu_var(vector_irq)[vector];
 
 			desc = irq_to_desc(irq);
-			spin_lock(&desc->lock);
+			raw_spin_lock(&desc->lock);
 			if (desc->chip->retrigger)
 				desc->chip->retrigger(irq);
-			spin_unlock(&desc->lock);
+			raw_spin_unlock(&desc->lock);
 		}
 	}
 }

commit 4646575daf21f544fc2f7e8d90d8c488948fcc7c
Merge: 86ed4aa457f9 581f202bcd60
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 8 13:38:21 2009 -0800

    Merge branch 'x86-uv-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-uv-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: UV RTC: Always enable RTC clocksource
      x86: UV RTC: Rename generic_interrupt to x86_platform_ipi
      x86: UV RTC: Clean up error handling
      x86: UV RTC: Add clocksource only boot option
      x86: UV RTC: Fix early expiry handling

commit a77d2e081bbbccb38f42da45500dd089756efdfb
Merge: 897e81bea1fc 7d1849aff668
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 5 15:31:25 2009 -0800

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (30 commits)
      x86, apic: Enable lapic nmi watchdog on AMD Family 11h
      x86: Remove unnecessary mdelay() from cpu_disable_common()
      x86, ioapic: Document another case when level irq is seen as an edge
      x86, ioapic: Fix the EOI register detection mechanism
      x86, io-apic: Move the effort of clearing remoteIRR explicitly before migrating the irq
      x86: SGI UV: Map low MMR ranges
      x86: apic: Print out SRAT table APIC id in hex
      x86: Re-get cfg_new in case reuse/move irq_desc
      x86: apic: Remove not needed #ifdef
      x86: io-apic: IO-APIC MMIO should not fail on resource insertion
      x86: Remove asm/apicnum.h
      x86: apic: Do not use stacked physid_mask_t
      x86, apic: Get rid of apicid_to_cpu_present assign on 64-bit
      x86, ioapic: Use snrpintf while set names for IO-APIC resourses
      x86, apic: Use PAGE_SIZE instead of numbers
      x86: Remove local_irq_enable()/local_irq_disable() in fixup_irqs()
      x86: Use EOI register in io-apic on intel platforms
      x86: Force irq complete move during cpu offline
      x86: Remove move_cleanup_count from irq_cfg
      x86, intr-remap: Avoid irq_chip mask/unmask in fixup_irqs() for intr-remapping
      ...

commit 0444c9bd0cf4e0eb946a7fcaf34765accfa9404a
Author: Jan Beulich <JBeulich@novell.com>
Date:   Fri Nov 20 14:03:05 2009 +0000

    x86: Tighten conditionals on MCE related statistics
    
    irq_thermal_count is only being maintained when
    X86_THERMAL_VECTOR, and both X86_THERMAL_VECTOR and
    X86_MCE_THRESHOLD don't need extra wrapping in X86_MCE
    conditionals.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Yong Wang <yong.y.wang@intel.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    LKML-Reference: <4B06AFA902000078000211F8@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 04bbd5278568..19212cb01558 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -92,17 +92,17 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
 	seq_printf(p, "  TLB shootdowns\n");
 #endif
-#ifdef CONFIG_X86_MCE
+#ifdef CONFIG_X86_THERMAL_VECTOR
 	seq_printf(p, "%*s: ", prec, "TRM");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_thermal_count);
 	seq_printf(p, "  Thermal event interrupts\n");
-# ifdef CONFIG_X86_MCE_THRESHOLD
+#endif
+#ifdef CONFIG_X86_MCE_THRESHOLD
 	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_printf(p, "  Threshold APIC interrupts\n");
-# endif
 #endif
 #ifdef CONFIG_X86_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
@@ -194,11 +194,11 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->irq_call_count;
 	sum += irq_stats(cpu)->irq_tlb_count;
 #endif
-#ifdef CONFIG_X86_MCE
+#ifdef CONFIG_X86_THERMAL_VECTOR
 	sum += irq_stats(cpu)->irq_thermal_count;
-# ifdef CONFIG_X86_MCE_THRESHOLD
+#endif
+#ifdef CONFIG_X86_MCE_THRESHOLD
 	sum += irq_stats(cpu)->irq_threshold_count;
-# endif
 #endif
 #ifdef CONFIG_X86_MCE
 	sum += per_cpu(mce_exception_count, cpu);

commit 5231a68614b94f60e8f6c56bc6e3d75955b9e75e
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Oct 26 14:24:36 2009 -0800

    x86: Remove local_irq_enable()/local_irq_disable() in fixup_irqs()
    
    To ensure that we handle all the pending interrupts (destined
    for this cpu that is going down) in the interrupt subsystem
    before the cpu goes offline, fixup_irqs() does:
    
            local_irq_enable();
            mdelay(1);
            local_irq_disable();
    
    Enabling interrupts is not a good thing as this cpu is already
    offline. So this patch replaces that logic with,
    
            mdelay(1);
            check APIC_IRR bits
            Retrigger the irq at the new destination if any interrupt has arrived
            via IPI.
    
    For IO-APIC level triggered interrupts, this retrigger IPI will
    appear as an edge interrupt. ack_apic_level() will detect this
    condition and IO-APIC RTE's remoteIRR is cleared using directed
    EOI(using IO-APIC EOI register) on Intel platforms and for
    others it uses the existing mask+edge logic followed by
    unmask+level.
    
    We can also remove mdelay() and then send spuriuous interrupts
    to new cpu targets for all the irqs that were handled previously
    by this cpu that is going offline. While it works, I have seen
    spurious interrupt messages (nothing wrong but still annoying
    messages during cpu offline, which can be seen during
    suspend/resume etc)
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Gary Hade <garyhade@us.ibm.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    LKML-Reference: <20091026230002.043281924@sbs-t61.sc.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index b10a5e1da06c..8a82728d47c1 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -281,7 +281,7 @@ EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
 /* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
 void fixup_irqs(void)
 {
-	unsigned int irq;
+	unsigned int irq, vector;
 	static int warned;
 	struct irq_desc *desc;
 
@@ -336,9 +336,33 @@ void fixup_irqs(void)
 			printk("Cannot set affinity for irq %i\n", irq);
 	}
 
-	/* That doesn't seem sufficient.  Give it 1ms. */
-	local_irq_enable();
+	/*
+	 * We can remove mdelay() and then send spuriuous interrupts to
+	 * new cpu targets for all the irqs that were handled previously by
+	 * this cpu. While it works, I have seen spurious interrupt messages
+	 * (nothing wrong but still...).
+	 *
+	 * So for now, retain mdelay(1) and check the IRR and then send those
+	 * interrupts to new targets as this cpu is already offlined...
+	 */
 	mdelay(1);
-	local_irq_disable();
+
+	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
+		unsigned int irr;
+
+		if (__get_cpu_var(vector_irq)[vector] < 0)
+			continue;
+
+		irr = apic_read(APIC_IRR + (vector / 32 * 0x10));
+		if (irr  & (1 << (vector % 32))) {
+			irq = __get_cpu_var(vector_irq)[vector];
+
+			desc = irq_to_desc(irq);
+			spin_lock(&desc->lock);
+			if (desc->chip->retrigger)
+				desc->chip->retrigger(irq);
+			spin_unlock(&desc->lock);
+		}
+	}
 }
 #endif

commit a5e74b841930bec78a4684ab9f208b2ddfe7c736
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Oct 26 14:24:34 2009 -0800

    x86: Force irq complete move during cpu offline
    
    When a cpu goes offline, fixup_irqs() try to move irq's
    currently destined to the offline cpu to a new cpu. But this
    attempt will fail if the irq is recently moved to this cpu and
    the irq still hasn't arrived at this cpu (for non intr-remapping
    platforms this is when we free the vector allocation at the
    previous destination) that is about to go offline.
    
    This will endup with the interrupt subsystem still pointing the
    irq to the offline cpu, causing that irq to not work any more.
    
    Fix this by forcing the irq to complete its move (its been a
    long time we moved the irq to this cpu which we are offlining
    now) and then move this irq to a new cpu before this cpu goes
    offline.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Gary Hade <garyhade@us.ibm.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    LKML-Reference: <20091026230001.848830905@sbs-t61.sc.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 342bcbca19b4..b10a5e1da06c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -305,6 +305,13 @@ void fixup_irqs(void)
 			continue;
 		}
 
+		/*
+		 * Complete the irq move. This cpu is going down and for
+		 * non intr-remapping case, we can't wait till this interrupt
+		 * arrives at this cpu before completing the irq move.
+		 */
+		irq_force_complete_move(irq);
+
 		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
 			break_affinity = 1;
 			affinity = cpu_all_mask;

commit 84e21493a3b28c9fefe99fe827fc0c0c101a813d
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Oct 26 14:24:32 2009 -0800

    x86, intr-remap: Avoid irq_chip mask/unmask in fixup_irqs() for intr-remapping
    
    In the presence of interrupt-remapping, irqs will be migrated in
    the process context and we don't do (and there is no need to)
    irq_chip mask/unmask while migrating the interrupt.
    
    Similarly fix the fixup_irqs() that get called during cpu
    offline and avoid calling irq_chip mask/unmask for irqs that are
    ok to be migrated in the process context.
    
    While we didn't observe any race condition with the existing
    code, this change takes complete advantage of
    interrupt-remapping in the newer generation platforms and avoids
    any potential HW lockup's (that often worry Eric :)
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: garyhade@us.ibm.com
    LKML-Reference: <20091026230001.661423939@sbs-t61.sc.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3ea66556e5e1..342bcbca19b4 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -310,7 +310,7 @@ void fixup_irqs(void)
 			affinity = cpu_all_mask;
 		}
 
-		if (desc->chip->mask)
+		if (!(desc->status & IRQ_MOVE_PCNTXT) && desc->chip->mask)
 			desc->chip->mask(irq);
 
 		if (desc->chip->set_affinity)
@@ -318,7 +318,7 @@ void fixup_irqs(void)
 		else if (!(warned++))
 			set_affinity = 0;
 
-		if (desc->chip->unmask)
+		if (!(desc->status & IRQ_MOVE_PCNTXT) && desc->chip->unmask)
 			desc->chip->unmask(irq);
 
 		spin_unlock(&desc->lock);

commit 7a7732bc0f7c46f217dbec723f25366b6285cc42
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Oct 26 14:24:31 2009 -0800

    x86: Unify fixup_irqs() for 32-bit and 64-bit kernels
    
    There is no reason to have different fixup_irqs() for 32-bit and
    64-bit kernels. Unify by using the superior 64-bit version for
    both the kernels.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Gary Hade <garyhade@us.ibm.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    LKML-Reference: <20091026230001.562512739@sbs-t61.sc.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 391206199515..3ea66556e5e1 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -276,3 +276,62 @@ void smp_generic_interrupt(struct pt_regs *regs)
 }
 
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);
+
+#ifdef CONFIG_HOTPLUG_CPU
+/* A cpu has been removed from cpu_online_mask.  Reset irq affinities. */
+void fixup_irqs(void)
+{
+	unsigned int irq;
+	static int warned;
+	struct irq_desc *desc;
+
+	for_each_irq_desc(irq, desc) {
+		int break_affinity = 0;
+		int set_affinity = 1;
+		const struct cpumask *affinity;
+
+		if (!desc)
+			continue;
+		if (irq == 2)
+			continue;
+
+		/* interrupt's are disabled at this point */
+		spin_lock(&desc->lock);
+
+		affinity = desc->affinity;
+		if (!irq_has_action(irq) ||
+		    cpumask_equal(affinity, cpu_online_mask)) {
+			spin_unlock(&desc->lock);
+			continue;
+		}
+
+		if (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {
+			break_affinity = 1;
+			affinity = cpu_all_mask;
+		}
+
+		if (desc->chip->mask)
+			desc->chip->mask(irq);
+
+		if (desc->chip->set_affinity)
+			desc->chip->set_affinity(irq, affinity);
+		else if (!(warned++))
+			set_affinity = 0;
+
+		if (desc->chip->unmask)
+			desc->chip->unmask(irq);
+
+		spin_unlock(&desc->lock);
+
+		if (break_affinity && set_affinity)
+			printk("Broke affinity for irq %i\n", irq);
+		else if (!set_affinity)
+			printk("Cannot set affinity for irq %i\n", irq);
+	}
+
+	/* That doesn't seem sufficient.  Give it 1ms. */
+	local_irq_enable();
+	mdelay(1);
+	local_irq_disable();
+}
+#endif

commit a0738a688d1105cbf8d71868a1e020c6cdf42d4c
Merge: 89ccf465abe6 a3ccf63ee643
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Oct 15 08:07:26 2009 +0200

    Merge branch 'linus' into x86/urgent
    
    Merge reason: pull in latest, to be able to revert a patch there.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 4a4de9c7d7111ce4caf422b856756125d8304f9d
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Wed Oct 14 09:22:57 2009 -0500

    x86: UV RTC: Rename generic_interrupt to x86_platform_ipi
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    LKML-Reference: <20091014142257.GE11048@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 391206199515..9375dce39f5f 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -18,7 +18,7 @@
 atomic_t irq_err_count;
 
 /* Function pointer for generic interrupt vector handling */
-void (*generic_interrupt_extension)(void) = NULL;
+void (*x86_platform_ipi_callback)(void) = NULL;
 
 /*
  * 'what should we do if we get a hw irq event on an illegal vector'.
@@ -72,10 +72,10 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_pending_irqs);
 	seq_printf(p, "  Performance pending work\n");
 #endif
-	if (generic_interrupt_extension) {
+	if (x86_platform_ipi_callback) {
 		seq_printf(p, "%*s: ", prec, "PLT");
 		for_each_online_cpu(j)
-			seq_printf(p, "%10u ", irq_stats(j)->generic_irqs);
+			seq_printf(p, "%10u ", irq_stats(j)->x86_platform_ipis);
 		seq_printf(p, "  Platform interrupts\n");
 	}
 #ifdef CONFIG_SMP
@@ -187,8 +187,8 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->apic_perf_irqs;
 	sum += irq_stats(cpu)->apic_pending_irqs;
 #endif
-	if (generic_interrupt_extension)
-		sum += irq_stats(cpu)->generic_irqs;
+	if (x86_platform_ipi_callback)
+		sum += irq_stats(cpu)->x86_platform_ipis;
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;
 	sum += irq_stats(cpu)->irq_call_count;
@@ -252,9 +252,9 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 }
 
 /*
- * Handler for GENERIC_INTERRUPT_VECTOR.
+ * Handler for X86_PLATFORM_IPI_VECTOR.
  */
-void smp_generic_interrupt(struct pt_regs *regs)
+void smp_x86_platform_ipi(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
@@ -264,10 +264,10 @@ void smp_generic_interrupt(struct pt_regs *regs)
 
 	irq_enter();
 
-	inc_irq_stat(generic_irqs);
+	inc_irq_stat(x86_platform_ipis);
 
-	if (generic_interrupt_extension)
-		generic_interrupt_extension();
+	if (x86_platform_ipi_callback)
+		x86_platform_ipi_callback();
 
 	run_local_timers();
 	irq_exit();

commit 89ccf465abe6b20d804a63ae20307970c441369d
Author: Li Hong <lihong.hi@gmail.com>
Date:   Wed Oct 14 18:50:39 2009 +0800

    x86, perf_event: Rename 'performance counter interrupt'
    
    In 'cdd6c482c9ff9c55475ee7392ec8f672eddb7be6', we renamed
    Performance Counters -> Performance Events.
    
    The name showed up in /proc/interrupts also needs a change. I use
    PMI (Performance monitoring interrupt) here, since it is the
    official name used in Intel's documents.
    
    Signed-off-by: Li Hong <lihong.hi@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <20091014105039.GA22670@uhli>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 391206199515..86fb2c8e065a 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -63,10 +63,10 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
 	seq_printf(p, "  Spurious interrupts\n");
-	seq_printf(p, "%*s: ", prec, "CNT");
+	seq_printf(p, "%*s: ", prec, "PMI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
-	seq_printf(p, "  Performance counter interrupts\n");
+	seq_printf(p, "  Performance monitoring interrupts\n");
 	seq_printf(p, "%*s: ", prec, "PND");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_pending_irqs);

commit e7ab0f7b50bc4688fb5cf65de5d42e3b882fb8d1
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Oct 9 15:58:20 2009 +0200

    Revert "x86, timers: Check for pending timers after (device) interrupts"
    
    This reverts commit 9bcbdd9c58617f1301dd4f17c738bb9bc73aca70.
    
    The real bug producing LatencyTop latencies has been fixed in:
    
      f5dc375: sched: Update the clock of runqueue select_task_rq() selected
    
    And the commit being reverted here triggers local timer processing
    from every device IRQ. If device IRQs come in at a high frequency,
    this could cause a performance regression.
    
    The commit being reverted here purely 'fixed' the reported latency
    as a side effect, because CPUs were being moved out of idle more
    often.
    
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Frans Pop <elendil@planet.nl>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <20091008064041.67219b13@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 391206199515..74656d1d4e30 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -244,7 +244,6 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 				__func__, smp_processor_id(), vector, irq);
 	}
 
-	run_local_timers();
 	irq_exit();
 
 	set_irq_regs(old_regs);
@@ -269,7 +268,6 @@ void smp_generic_interrupt(struct pt_regs *regs)
 	if (generic_interrupt_extension)
 		generic_interrupt_extension();
 
-	run_local_timers();
 	irq_exit();
 
 	set_irq_regs(old_regs);

commit 9bcbdd9c58617f1301dd4f17c738bb9bc73aca70
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Thu Oct 8 06:40:41 2009 -0700

    x86, timers: Check for pending timers after (device) interrupts
    
    Now that range timers and deferred timers are common, I found a
    problem with these using the "perf timechart" tool. Frans Pop also
    reported high scheduler latencies via LatencyTop, when using
    iwlagn.
    
    It turns out that on x86, these two 'opportunistic' timers only get
    checked when another "real" timer happens. These opportunistic
    timers have the objective to save power by hitchhiking on other
    wakeups, as to avoid CPU wakeups by themselves as much as possible.
    
    The change in this patch runs this check not only at timer
    interrupts, but at all (device) interrupts. The effect is that:
    
     1) the deferred timers/range timers get delayed less
    
     2) the range timers cause less wakeups by themselves because
        the percentage of hitchhiking on existing wakeup events goes up.
    
    I've verified the working of the patch using "perf timechart", the
    original exposed bug is gone with this patch. Frans also reported
    success - the latencies are now down in the expected ~10 msec
    range.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Tested-by: Frans Pop <elendil@planet.nl>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Mike Galbraith <efault@gmx.de>
    LKML-Reference: <20091008064041.67219b13@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 74656d1d4e30..391206199515 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -244,6 +244,7 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 				__func__, smp_processor_id(), vector, irq);
 	}
 
+	run_local_timers();
 	irq_exit();
 
 	set_irq_regs(old_regs);
@@ -268,6 +269,7 @@ void smp_generic_interrupt(struct pt_regs *regs)
 	if (generic_interrupt_extension)
 		generic_interrupt_extension();
 
+	run_local_timers();
 	irq_exit();
 
 	set_irq_regs(old_regs);

commit c1ebf835617035b1f08f734247dcb981e17aac6b
Author: Andi Kleen <andi@firstfloor.org>
Date:   Thu Jul 9 00:31:41 2009 +0200

    x86: mce: Rename CONFIG_X86_NEW_MCE to CONFIG_X86_MCE
    
    Drop the CONFIG_X86_NEW_MCE symbol and change all
    references to it to check for CONFIG_X86_MCE directly.
    
    No code changes
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index b0cdde6932f5..74656d1d4e30 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -104,7 +104,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  Threshold APIC interrupts\n");
 # endif
 #endif
-#ifdef CONFIG_X86_NEW_MCE
+#ifdef CONFIG_X86_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_exception_count, j));
@@ -200,7 +200,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->irq_threshold_count;
 # endif
 #endif
-#ifdef CONFIG_X86_NEW_MCE
+#ifdef CONFIG_X86_MCE
 	sum += per_cpu(mce_exception_count, cpu);
 	sum += per_cpu(mce_poll_count, cpu);
 #endif

commit 0d5959723e1db3fd7323c198a50c16cecf96c7a9
Merge: 62fdac5913f7 512626a04e72
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 11 23:31:52 2009 +0200

    Merge branch 'linus' into x86/mce3
    
    Conflicts:
            arch/x86/kernel/cpu/mcheck/mce_64.c
            arch/x86/kernel/irq.c
    
    Merge reason: Resolve the conflicts above.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 940010c5a314a7bd9b498593bc6ba1718ac5aec5
Merge: 8dc8e5e8bc0c 991ec02cdca3
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 11 17:55:42 2009 +0200

    Merge branch 'linus' into perfcounters/core
    
    Conflicts:
            arch/x86/kernel/irqinit.c
            arch/x86/kernel/irqinit_64.c
            arch/x86/kernel/traps.c
            arch/x86/mm/fault.c
            include/linux/sched.h
            kernel/exit.c

commit 7dc3ca39cb1e22eedbf1207ff9ac7bf682fc0f6d
Merge: aa98936e4f42 a4046f8d299e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 10 15:49:36 2009 -0700

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, nmi: Use predefined numbers instead of hardcoded one
      x86: asm/processor.h: remove double declaration
      x86, mtrr: replace MTRRdefType_MSR with msr-index's MSR_MTRRdefType
      x86, mtrr: replace MTRRfix4K_C0000_MSR with msr-index's MSR_MTRRfix4K_C0000
      x86, mtrr: remove mtrr MSRs double declaration
      x86, mtrr: replace MTRRfix16K_80000_MSR with msr-index's MSR_MTRRfix16K_80000
      x86, mtrr: replace MTRRfix64K_00000_MSR with msr-index's MSR_MTRRfix64K_00000
      x86, mtrr: replace MTRRcap_MSR with msr-index's MSR_MTRRcap
      x86: mce: remove duplicated #include
      x86: msr-index.h remove duplicate MSR C001_0015 declaration
      x86: clean up arch/x86/kernel/tsc_sync.c a bit
      x86: use symbolic name for VM86_SIGNAL when used as vm86 default return
      x86: added 'ifndef _ASM_X86_IOMAP_H' to iomap.h
      x86: avoid multiple declaration of kstack_depth_to_print
      x86: vdso/vma.c declare vdso_enabled and arch_setup_additional_pages before they get used
      x86: clean up declarations and variables
      x86: apic/x2apic_cluster.c x86_cpu_to_logical_apicid should be static
      x86 early quirks: eliminate unused function

commit 8051dbd2dfd1427cc102888d7d96bf39de0be150
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Tue Jun 2 16:53:23 2009 +0900

    x86, mce: fix for mce counters
    
    Make the MCE counters work on 32bit and add poll count in
    arch_irq_stat_cpu.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index eff46b5de62f..9773395aa758 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -95,7 +95,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  Threshold APIC interrupts\n");
 # endif
 #endif
-#if defined(CONFIG_X86_MCE) && defined(CONFIG_X86_64)
+#ifdef CONFIG_X86_NEW_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_exception_count, j));
@@ -172,9 +172,6 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 {
 	u64 sum = irq_stats(cpu)->__nmi_count;
 
-#if defined(CONFIG_X86_MCE) && defined(CONFIG_X86_64)
-	sum += per_cpu(mce_exception_count, cpu);
-#endif
 #ifdef CONFIG_X86_LOCAL_APIC
 	sum += irq_stats(cpu)->apic_timer_irqs;
 	sum += irq_stats(cpu)->irq_spurious_count;
@@ -191,6 +188,10 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 # ifdef CONFIG_X86_MCE_THRESHOLD
 	sum += irq_stats(cpu)->irq_threshold_count;
 # endif
+#endif
+#ifdef CONFIG_X86_NEW_MCE
+	sum += per_cpu(mce_exception_count, cpu);
+	sum += per_cpu(mce_poll_count, cpu);
 #endif
 	return sum;
 }

commit ca84f69697da0f004135e45b63ca560b6bd3554e
Author: Andi Kleen <andi@firstfloor.org>
Date:   Wed May 27 21:56:57 2009 +0200

    x86, mce: add MCE poll count to /proc/interrupts
    
    Keep a count of the machine check polls (or CMCI events) in
    /proc/interrupts.
    
    Andi needs this for debugging, but it's also useful in general
    to see what's going in by the kernel.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 05fc635c28c0..eff46b5de62f 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -100,6 +100,10 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", per_cpu(mce_exception_count, j));
 	seq_printf(p, "  Machine check exceptions\n");
+	seq_printf(p, "%*s: ", prec, "MCP");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
+	seq_printf(p, "  Machine check polls\n");
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)

commit 01ca79f1411eae2a45352709c838b946b1af9fbd
Author: Andi Kleen <andi@firstfloor.org>
Date:   Wed May 27 21:56:52 2009 +0200

    x86, mce: add machine check exception count in /proc/interrupts
    
    Useful for debugging, but it's also good general policy
    to have a counter for all special interrupts there. This makes it easier
    to diagnose where a CPU is spending its time.
    
    [ Impact: feature, debugging tool ]
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index a05660bf0299..05fc635c28c0 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -12,6 +12,7 @@
 #include <asm/io_apic.h>
 #include <asm/irq.h>
 #include <asm/idle.h>
+#include <asm/mce.h>
 
 atomic_t irq_err_count;
 
@@ -93,6 +94,12 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_printf(p, "  Threshold APIC interrupts\n");
 # endif
+#endif
+#if defined(CONFIG_X86_MCE) && defined(CONFIG_X86_64)
+	seq_printf(p, "%*s: ", prec, "MCE");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", per_cpu(mce_exception_count, j));
+	seq_printf(p, "  Machine check exceptions\n");
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)
@@ -161,6 +168,9 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 {
 	u64 sum = irq_stats(cpu)->__nmi_count;
 
+#if defined(CONFIG_X86_MCE) && defined(CONFIG_X86_64)
+	sum += per_cpu(mce_exception_count, cpu);
+#endif
 #ifdef CONFIG_X86_LOCAL_APIC
 	sum += irq_stats(cpu)->apic_timer_irqs;
 	sum += irq_stats(cpu)->irq_spurious_count;

commit 48b1fddbb100a64f3983ca9768b8ea629a09aa20
Merge: 38736072d454 ee4c24a5c9b5
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Mon Jun 1 15:13:02 2009 -0700

    Merge branch 'irq/numa' into x86/mce3
    
    Merge reason: arch/x86/kernel/irqinit_{32,64}.c unified in irq/numa
    and modified in x86/mce3; this merge resolves the conflict.
    
    Conflicts:
            arch/x86/kernel/irqinit.c
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

commit 4efc0670baf4b14bc95502e54a83ccf639146125
Author: Andi Kleen <ak@linux.intel.com>
Date:   Tue Apr 28 19:07:31 2009 +0200

    x86, mce: use 64bit machine check code on 32bit
    
    The 64bit machine check code is in many ways much better than
    the 32bit machine check code: it is more specification compliant,
    is cleaner, only has a single code base versus one per CPU,
    has better infrastructure for recovery, has a cleaner way to communicate
    with user space etc. etc.
    
    Use the 64bit code for 32bit too.
    
    This is the second attempt to do this. There was one a couple of years
    ago to unify this code for 32bit and 64bit.  Back then this ran into some
    trouble with K7s and was reverted.
    
    I believe this time the K7 problems (and some others) are addressed.
    I went over the old handlers and was very careful to retain
    all quirks.
    
    But of course this needs a lot of testing on old systems. On newer
    64bit capable systems I don't expect much problems because they have been
    already tested with the 64bit kernel.
    
    I made this a CONFIG for now that still allows to select the old
    machine check code. This is mostly to make testing easier,
    if someone runs into a problem we can ask them to try
    with the CONFIG switched.
    
    The new code is default y for more coverage.
    
    Once there is confidence the 64bit code works well on older hardware
    too the CONFIG_X86_OLD_MCE and the associated code can be easily
    removed.
    
    This causes a behaviour change for 32bit installations. They now
    have to install the mcelog package to be able to log
    corrected machine checks.
    
    The 64bit machine check code only handles CPUs which support the
    standard Intel machine check architecture described in the IA32 SDM.
    The 32bit code has special support for some older CPUs which
    have non standard machine check architectures, in particular
    WinChip C3 and Intel P5.  I made those a separate CONFIG option
    and kept them for now. The WinChip variant could be probably
    removed without too much pain, it doesn't really do anything
    interesting. P5 is also disabled by default (like it
    was before) because many motherboards have it miswired, but
    according to Alan Cox a few embedded setups use that one.
    
    Forward ported/heavily changed version of old patch, original patch
    included review/fixes from Thomas Gleixner, Bert Wesarg.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c3fe010d74c8..35eddc9ec99e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -89,7 +89,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_thermal_count);
 	seq_printf(p, "  Thermal event interrupts\n");
-# ifdef CONFIG_X86_64
+# ifdef CONFIG_X86_MCE_THRESHOLD
 	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
@@ -176,7 +176,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 #endif
 #ifdef CONFIG_X86_MCE
 	sum += irq_stats(cpu)->irq_thermal_count;
-# ifdef CONFIG_X86_64
+# ifdef CONFIG_X86_MCE_THRESHOLD
 	sum += irq_stats(cpu)->irq_threshold_count;
 #endif
 #endif

commit e7fd5d4b3d240f42c30a9e3d20a4689c4d3a795a
Merge: 1130b0296184 56a50adda49b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Apr 29 14:46:59 2009 +0200

    Merge branch 'linus' into perfcounters/core
    
    Merge reason: This brach was on -rc1, refresh it to almost-rc4 to pick up
                  the latest upstream fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 5043124e660fcc3ddefe4239ddfa017bf13f5081
Merge: 77857dc07247 9f76208c3398
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Apr 17 16:18:22 2009 +0200

    Merge branch 'linus' into x86/apic
    
    Merge reason: new intr-remap patches depend on the s2ram iommu fixes from upstream
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 0f3fd87ce43727d6b8573191ce89e874533b1429
Author: Luis Henriques <henrix@sapo.pt>
Date:   Mon Apr 13 20:24:50 2009 +0100

    perf_counter: fix alignment in /proc/interrupts
    
    Trivial fix on columns alignment in /proc/interrupts file.
    
    Signed-off-by: Luis Henriques <henrix@sapo.pt>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <20090413192449.GA3920@hades.domain.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index dccaaa855789..849cfabb1fdc 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -67,7 +67,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
 	seq_printf(p, "  Performance counter interrupts\n");
-	seq_printf(p, "PND: ");
+	seq_printf(p, "%*s: ", prec, "PND");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_pending_irqs);
 	seq_printf(p, "  Performance pending work\n");

commit 08306ce61d6848e6fbf74fa4cc693c3fb29e943f
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Sun Apr 12 20:47:41 2009 +0400

    x86: apic - introduce dummy apic operations
    
    Impact: refactor, speed up and robustize code
    
    In case if apic was disabled by kernel option
    or by hardware limits we can use dummy operations
    in apic->write to simplify the ack_APIC_irq() code.
    
    At the lame time the patch fixes the missed EOI in
    do_IRQ function (which has place if kernel is compiled
    as X86-32 and interrupt without handler happens where
    apic was not asked to be disabled via kernel option).
    
    Note that native_apic_write_dummy() consists of
    WARN_ON_ONCE to catch any buggy writes on enabled
    APICs. Could be removed after some time of testing.
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    LKML-Reference: <20090412165058.724788431@openvz.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 6603492e8b71..fd57bf35d0fc 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -27,7 +27,6 @@ void ack_bad_irq(unsigned int irq)
 	if (printk_ratelimit())
 		pr_err("unexpected IRQ trap at vector %02x\n", irq);
 
-#ifdef CONFIG_X86_LOCAL_APIC
 	/*
 	 * Currently unexpected vectors happen only on SMP and APIC.
 	 * We _must_ ack these because every local APIC has only N
@@ -37,9 +36,7 @@ void ack_bad_irq(unsigned int irq)
 	 * completely.
 	 * But only ack when the APIC is enabled -AK
 	 */
-	if (cpu_has_apic)
-		ack_APIC_irq();
-#endif
+	ack_APIC_irq();
 }
 
 #define irq_stats(x)		(&per_cpu(irq_stat, x))
@@ -214,10 +211,7 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	irq = __get_cpu_var(vector_irq)[vector];
 
 	if (!handle_irq(irq, regs)) {
-#ifdef CONFIG_X86_64
-		if (!disable_apic)
-			ack_APIC_irq();
-#endif
+		ack_APIC_irq();
 
 		if (printk_ratelimit())
 			pr_emerg("%s: %d.%d No irq handler for vector (irq %d)\n",

commit edea7148a87c099e5d5d4838285cc27e459588b7
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Sun Apr 12 20:47:39 2009 +0400

    x86: irq.c - tiny cleanup
    
    Impact: cleanup, robustization
    
     1) guard ack_bad_irq with printk_ratelimit since there is no
        guarantee we will not be flooded one day
    
     2) use pr_emerg() helper
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    LKML-Reference: <20090412165058.277579847@openvz.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3aaf7b9e3a8b..6603492e8b71 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -24,7 +24,8 @@ void (*generic_interrupt_extension)(void) = NULL;
  */
 void ack_bad_irq(unsigned int irq)
 {
-	printk(KERN_ERR "unexpected IRQ trap at vector %02x\n", irq);
+	if (printk_ratelimit())
+		pr_err("unexpected IRQ trap at vector %02x\n", irq);
 
 #ifdef CONFIG_X86_LOCAL_APIC
 	/*
@@ -178,7 +179,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->irq_thermal_count;
 # ifdef CONFIG_X86_64
 	sum += irq_stats(cpu)->irq_threshold_count;
-#endif
+# endif
 #endif
 	return sum;
 }
@@ -219,8 +220,8 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 #endif
 
 		if (printk_ratelimit())
-			printk(KERN_EMERG "%s: %d.%d No irq handler for vector (irq %d)\n",
-			       __func__, smp_processor_id(), vector, irq);
+			pr_emerg("%s: %d.%d No irq handler for vector (irq %d)\n",
+				__func__, smp_processor_id(), vector, irq);
 	}
 
 	irq_exit();

commit 2c1b284e4fa260fd922b9a65c99169e2630c6862
Author: Jaswinder Singh Rajput <jaswinder@kernel.org>
Date:   Sat Apr 11 00:03:10 2009 +0530

    x86: clean up declarations and variables
    
    Impact: cleanup, no code changed
    
     - syscalls.h       update declarations due to unifications
     - irq.c            declare smp_generic_interrupt() before it gets used
     - process.c        declare sys_fork() and sys_vfork() before they get used
     - tsc.c            rename tsc_khz shadowed variable
     - apic/probe_32.c  declare apic_default before it gets used
     - apic/nmi.c       prev_nmi_count should be unsigned
     - apic/io_apic.c   declare smp_irq_move_cleanup_interrupt() before it gets used
     - mm/init.c        declare direct_gbpages and free_initrd_mem before they get used
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinder@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3aaf7b9e3a8b..2188267f523b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -12,6 +12,7 @@
 #include <asm/io_apic.h>
 #include <asm/irq.h>
 #include <asm/idle.h>
+#include <asm/hw_irq.h>
 
 atomic_t irq_err_count;
 

commit 59d138120d18930ba9a5466662d45a2bd2223455
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Wed Mar 25 10:50:34 2009 +0900

    x86: smarten /proc/interrupts output for new counters
    
    Now /proc/interrupts of tip tree has new counters:
    
      PLT: Platform interrupts
    
    Format change of output, as like that by commit:
    
      commit 7a81d9a7da03d2f27840d659f97ef140d032f609
      x86: smarten /proc/interrupts output
    
    should be applied to these new counters too.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <49C98DEA.8060208@jp.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3aaf7b9e3a8b..c3fe010d74c8 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -65,7 +65,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  Spurious interrupts\n");
 #endif
 	if (generic_interrupt_extension) {
-		seq_printf(p, "PLT: ");
+		seq_printf(p, "%*s: ", prec, "PLT");
 		for_each_online_cpu(j)
 			seq_printf(p, "%10u ", irq_stats(j)->generic_irqs);
 		seq_printf(p, "  Platform interrupts\n");

commit 7333a8003cdc0470e8c0ae8b949cbc44f3165ff3
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Wed Mar 25 10:50:34 2009 +0900

    x86: smarten /proc/interrupts output for new counters
    
    Now /proc/interrupts of tip tree has new counters:
    
      CNT: Performance counter interrupts
    
    Format change of output, as like that by commit:
    
      commit 7a81d9a7da03d2f27840d659f97ef140d032f609
      x86: smarten /proc/interrupts output
    
    should be applied to these new counters too.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <49C98DEA.8060208@jp.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index d465487da587..dccaaa855789 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -63,7 +63,7 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
 	seq_printf(p, "  Spurious interrupts\n");
-	seq_printf(p, "CNT: ");
+	seq_printf(p, "%*s: ", prec, "CNT");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
 	seq_printf(p, "  Performance counter interrupts\n");

commit b6276f353bf490add62dcf7db0ebd75baa3e1a37
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Apr 6 11:45:03 2009 +0200

    perf_counter: x86: self-IPI for pending work
    
    Implement set_perf_counter_pending() with a self-IPI so that it will
    run ASAP in a usable context.
    
    For now use a second IRQ vector, because the primary vector pokes
    the apic in funny ways that seem to confuse things.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    LKML-Reference: <20090406094517.724626696@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 9c2754302ecc..d465487da587 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -67,6 +67,10 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
 	seq_printf(p, "  Performance counter interrupts\n");
+	seq_printf(p, "PND: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->apic_pending_irqs);
+	seq_printf(p, "  Performance pending work\n");
 #endif
 	if (generic_interrupt_extension) {
 		seq_printf(p, "PLT: ");
@@ -171,6 +175,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->apic_timer_irqs;
 	sum += irq_stats(cpu)->irq_spurious_count;
 	sum += irq_stats(cpu)->apic_perf_irqs;
+	sum += irq_stats(cpu)->apic_pending_irqs;
 #endif
 	if (generic_interrupt_extension)
 		sum += irq_stats(cpu)->generic_irqs;

commit f541ae326fa120fa5c57433e4d9a133df212ce41
Merge: e255357764f9 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 09:02:57 2009 +0200

    Merge branch 'linus' into perfcounters/core-v2
    
    Merge reason: we have gathered quite a few conflicts, need to merge upstream
    
    Conflicts:
            arch/powerpc/kernel/Makefile
            arch/x86/ia32/ia32entry.S
            arch/x86/include/asm/hardirq.h
            arch/x86/include/asm/unistd_32.h
            arch/x86/include/asm/unistd_64.h
            arch/x86/kernel/cpu/common.c
            arch/x86/kernel/irq.c
            arch/x86/kernel/syscall_table_32.S
            arch/x86/mm/iomap_32.c
            include/linux/sched.h
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 474e56b82c06cdbed468aea957805e0eb19d3510
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Mon Mar 23 02:08:34 2009 +0530

    x86: irq.c keep CONFIG_X86_LOCAL_APIC interrupts together
    
    Impact: cleanup
    
    keep CONFIG_X86_LOCAL_APIC interrupts together to avoid extra ifdef
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 5e7c3e6f8f27..3aaf7b9e3a8b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -58,6 +58,11 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
 	seq_printf(p, "  Local timer interrupts\n");
+
+	seq_printf(p, "%*s: ", prec, "SPU");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
+	seq_printf(p, "  Spurious interrupts\n");
 #endif
 	if (generic_interrupt_extension) {
 		seq_printf(p, "PLT: ");
@@ -90,12 +95,6 @@ static int show_other_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_printf(p, "  Threshold APIC interrupts\n");
 # endif
-#endif
-#ifdef CONFIG_X86_LOCAL_APIC
-	seq_printf(p, "%*s: ", prec, "SPU");
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
-	seq_printf(p, "  Spurious interrupts\n");
 #endif
 	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)
@@ -166,6 +165,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 
 #ifdef CONFIG_X86_LOCAL_APIC
 	sum += irq_stats(cpu)->apic_timer_irqs;
+	sum += irq_stats(cpu)->irq_spurious_count;
 #endif
 	if (generic_interrupt_extension)
 		sum += irq_stats(cpu)->generic_irqs;
@@ -179,9 +179,6 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 # ifdef CONFIG_X86_64
 	sum += irq_stats(cpu)->irq_threshold_count;
 #endif
-#endif
-#ifdef CONFIG_X86_LOCAL_APIC
-	sum += irq_stats(cpu)->irq_spurious_count;
 #endif
 	return sum;
 }

commit ce2d8bfd44c01fc9b22d64617b7e520e99095f33
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Mon Mar 23 02:08:00 2009 +0530

    x86: irq.c use same path for show_interrupts
    
    Impact: cleanup
    
    SMP and !SMP will use same path for show_interrupts
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index b8ac3b6cf776..5e7c3e6f8f27 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -133,23 +133,15 @@ int show_interrupts(struct seq_file *p, void *v)
 		return 0;
 
 	spin_lock_irqsave(&desc->lock, flags);
-#ifndef CONFIG_SMP
-	any_count = kstat_irqs(i);
-#else
 	for_each_online_cpu(j)
 		any_count |= kstat_irqs_cpu(i, j);
-#endif
 	action = desc->action;
 	if (!action && !any_count)
 		goto out;
 
 	seq_printf(p, "%*d: ", prec, i);
-#ifndef CONFIG_SMP
-	seq_printf(p, "%10u ", kstat_irqs(i));
-#else
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
-#endif
 	seq_printf(p, " %8s", desc->chip->name);
 	seq_printf(p, "-%-8s", desc->name);
 

commit 7a81d9a7da03d2f27840d659f97ef140d032f609
Author: Jan Beulich <jbeulich@novell.com>
Date:   Thu Mar 12 12:45:15 2009 +0000

    x86: smarten /proc/interrupts output
    
    Impact: change /proc/interrupts output ABI
    
    With the number of interrupts on large systems growing, assumptions on
    the width an interrupt number requires when converted to a decimal
    string turn invalid. Therefore, calculate the maximum number of digits
    dynamically.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <49B911EB.76E4.0078.0@novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index b864341dcc45..b8ac3b6cf776 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -45,16 +45,16 @@ void ack_bad_irq(unsigned int irq)
 /*
  * /proc/interrupts printing:
  */
-static int show_other_interrupts(struct seq_file *p)
+static int show_other_interrupts(struct seq_file *p, int prec)
 {
 	int j;
 
-	seq_printf(p, "NMI: ");
+	seq_printf(p, "%*s: ", prec, "NMI");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->__nmi_count);
 	seq_printf(p, "  Non-maskable interrupts\n");
 #ifdef CONFIG_X86_LOCAL_APIC
-	seq_printf(p, "LOC: ");
+	seq_printf(p, "%*s: ", prec, "LOC");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
 	seq_printf(p, "  Local timer interrupts\n");
@@ -66,40 +66,40 @@ static int show_other_interrupts(struct seq_file *p)
 		seq_printf(p, "  Platform interrupts\n");
 	}
 #ifdef CONFIG_SMP
-	seq_printf(p, "RES: ");
+	seq_printf(p, "%*s: ", prec, "RES");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
 	seq_printf(p, "  Rescheduling interrupts\n");
-	seq_printf(p, "CAL: ");
+	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
 	seq_printf(p, "  Function call interrupts\n");
-	seq_printf(p, "TLB: ");
+	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
 	seq_printf(p, "  TLB shootdowns\n");
 #endif
 #ifdef CONFIG_X86_MCE
-	seq_printf(p, "TRM: ");
+	seq_printf(p, "%*s: ", prec, "TRM");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_thermal_count);
 	seq_printf(p, "  Thermal event interrupts\n");
 # ifdef CONFIG_X86_64
-	seq_printf(p, "THR: ");
+	seq_printf(p, "%*s: ", prec, "THR");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_printf(p, "  Threshold APIC interrupts\n");
 # endif
 #endif
 #ifdef CONFIG_X86_LOCAL_APIC
-	seq_printf(p, "SPU: ");
+	seq_printf(p, "%*s: ", prec, "SPU");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
 	seq_printf(p, "  Spurious interrupts\n");
 #endif
-	seq_printf(p, "ERR: %10u\n", atomic_read(&irq_err_count));
+	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)
-	seq_printf(p, "MIS: %10u\n", atomic_read(&irq_mis_count));
+	seq_printf(p, "%*s: %10u\n", prec, "MIS", atomic_read(&irq_mis_count));
 #endif
 	return 0;
 }
@@ -107,19 +107,22 @@ static int show_other_interrupts(struct seq_file *p)
 int show_interrupts(struct seq_file *p, void *v)
 {
 	unsigned long flags, any_count = 0;
-	int i = *(loff_t *) v, j;
+	int i = *(loff_t *) v, j, prec;
 	struct irqaction *action;
 	struct irq_desc *desc;
 
 	if (i > nr_irqs)
 		return 0;
 
+	for (prec = 3, j = 1000; prec < 10 && j <= nr_irqs; ++prec)
+		j *= 10;
+
 	if (i == nr_irqs)
-		return show_other_interrupts(p);
+		return show_other_interrupts(p, prec);
 
 	/* print header */
 	if (i == 0) {
-		seq_printf(p, "           ");
+		seq_printf(p, "%*s", prec + 8, "");
 		for_each_online_cpu(j)
 			seq_printf(p, "CPU%-8d", j);
 		seq_putc(p, '\n');
@@ -140,7 +143,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	if (!action && !any_count)
 		goto out;
 
-	seq_printf(p, "%3d: ", i);
+	seq_printf(p, "%*d: ", prec, i);
 #ifndef CONFIG_SMP
 	seq_printf(p, "%10u ", kstat_irqs(i));
 #else

commit acaabe795a62bba089c185917af86b44654313dc
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Wed Mar 4 12:56:05 2009 -0600

    x86: UV, SGI RTC: add generic system vector
    
    This patch allocates a system interrupt vector for various platform
    specific uses.
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: john stultz <johnstul@us.ibm.com>
    LKML-Reference: <20090304185605.GA24419@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index f13ca1650aaf..b864341dcc45 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -15,6 +15,9 @@
 
 atomic_t irq_err_count;
 
+/* Function pointer for generic interrupt vector handling */
+void (*generic_interrupt_extension)(void) = NULL;
+
 /*
  * 'what should we do if we get a hw irq event on an illegal vector'.
  * each architecture has to answer this themselves.
@@ -56,6 +59,12 @@ static int show_other_interrupts(struct seq_file *p)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
 	seq_printf(p, "  Local timer interrupts\n");
 #endif
+	if (generic_interrupt_extension) {
+		seq_printf(p, "PLT: ");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", irq_stats(j)->generic_irqs);
+		seq_printf(p, "  Platform interrupts\n");
+	}
 #ifdef CONFIG_SMP
 	seq_printf(p, "RES: ");
 	for_each_online_cpu(j)
@@ -163,6 +172,8 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 #ifdef CONFIG_X86_LOCAL_APIC
 	sum += irq_stats(cpu)->apic_timer_irqs;
 #endif
+	if (generic_interrupt_extension)
+		sum += irq_stats(cpu)->generic_irqs;
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;
 	sum += irq_stats(cpu)->irq_call_count;
@@ -226,4 +237,27 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	return 1;
 }
 
+/*
+ * Handler for GENERIC_INTERRUPT_VECTOR.
+ */
+void smp_generic_interrupt(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	ack_APIC_irq();
+
+	exit_idle();
+
+	irq_enter();
+
+	inc_irq_stat(generic_irqs);
+
+	if (generic_interrupt_extension)
+		generic_interrupt_extension();
+
+	irq_exit();
+
+	set_irq_regs(old_regs);
+}
+
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);

commit 7b6aa335ca1a845c2262ec7a595b4521bca0f79d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 13:58:15 2009 +0100

    x86, apic: remove genapic.h
    
    Impact: cleanup
    
    Remove genapic.h and remove all references to it.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3957776b1930..f13ca1650aaf 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -8,7 +8,7 @@
 #include <linux/smp.h>
 #include <linux/ftrace.h>
 
-#include <asm/genapic.h>
+#include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/irq.h>
 #include <asm/idle.h>

commit c1eeb2de41d7015678bdd412b48a5f071b84e29a
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Feb 16 23:02:14 2009 -0800

    x86: fold apic_ops into genapic
    
    Impact: cleanup
    
    make it simpler, don't need have one extra struct.
    
    v2: fix the sgi_uv build
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index f13ca1650aaf..3957776b1930 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -8,7 +8,7 @@
 #include <linux/smp.h>
 #include <linux/ftrace.h>
 
-#include <asm/apic.h>
+#include <asm/genapic.h>
 #include <asm/io_apic.h>
 #include <asm/irq.h>
 #include <asm/idle.h>

commit b1864e9a1afef41709886072c6e6248def0386f4
Merge: e9c4ffb11f0b 7032e8696726
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Feb 13 09:49:38 2009 +0100

    Merge branch 'x86/core' into perfcounters/core
    
    Conflicts:
            arch/x86/Kconfig
            arch/x86/kernel/apic.c
            arch/x86/kernel/setup_percpu.c

commit 7c1d7cdcef1b54f4a78892b6b99d19f12c4f398e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Feb 6 14:09:41 2009 -0800

    x86: unify do_IRQ()
    
    With the differences in interrupt handling hoisted into handle_irq(),
    do_IRQ is more or less identical between 32 and 64 bit, so unify it.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 8b30d0c2512c..f13ca1650aaf 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -6,10 +6,12 @@
 #include <linux/kernel_stat.h>
 #include <linux/seq_file.h>
 #include <linux/smp.h>
+#include <linux/ftrace.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/irq.h>
+#include <asm/idle.h>
 
 atomic_t irq_err_count;
 
@@ -188,4 +190,40 @@ u64 arch_irq_stat(void)
 	return sum;
 }
 
+
+/*
+ * do_IRQ handles all normal device IRQ's (the special
+ * SMP cross-CPU interrupts have their own specific
+ * handlers).
+ */
+unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	/* high bit used in ret_from_ code  */
+	unsigned vector = ~regs->orig_ax;
+	unsigned irq;
+
+	exit_idle();
+	irq_enter();
+
+	irq = __get_cpu_var(vector_irq)[vector];
+
+	if (!handle_irq(irq, regs)) {
+#ifdef CONFIG_X86_64
+		if (!disable_apic)
+			ack_APIC_irq();
+#endif
+
+		if (printk_ratelimit())
+			printk(KERN_EMERG "%s: %d.%d No irq handler for vector (irq %d)\n",
+			       __func__, smp_processor_id(), vector, irq);
+	}
+
+	irq_exit();
+
+	set_irq_regs(old_regs);
+	return 1;
+}
+
 EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);

commit af37501c792107c2bde1524bdae38d9a247b841a
Merge: d859e29fe34c 99937d6455ce
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 18 18:15:49 2009 +0100

    Merge branch 'core/percpu' into perfcounters/core
    
    Conflicts:
            arch/x86/include/asm/pda.h
    
    We merge tip/core/percpu into tip/perfcounters/core because of a
    semantic and contextual conflict: the former eliminates the PDA,
    while the latter extends it with apic_perf_irqs field.
    
    Resolve the conflict by moving the new field to the irq_cpustat
    structure on 64-bit too.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 1b437c8c73a36daa471dd54a63c426d72af5723d
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:57 2009 +0900

    x86-64: Move irq stats from PDA to per-cpu and consolidate with 32-bit.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3973e2df7f87..8b30d0c2512c 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -36,11 +36,7 @@ void ack_bad_irq(unsigned int irq)
 #endif
 }
 
-#ifdef CONFIG_X86_32
-# define irq_stats(x)		(&per_cpu(irq_stat, x))
-#else
-# define irq_stats(x)		cpu_pda(x)
-#endif
+#define irq_stats(x)		(&per_cpu(irq_stat, x))
 /*
  * /proc/interrupts printing:
  */

commit 506c10f26c481b7f8ef27c1c79290f68989b2e9e
Merge: e1df957670ae c59765042f53
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 02:42:53 2009 +0100

    Merge commit 'v2.6.29-rc1' into perfcounters/core
    
    Conflicts:
            include/linux/kernel_stat.h

commit 6a02e71099a87d13f2aa49cb491b5bfb5e662fae
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Sun Jan 4 16:22:17 2009 +0530

    x86: irq.c fix style problems
    
    Impact: cleanup
    
    Fix:
    
     WARNING: Use #include <linux/smp.h> instead of <asm/smp.h>
    
     total: 0 errors, 1 warnings
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index bce53e1352a0..3973e2df7f87 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -5,10 +5,10 @@
 #include <linux/interrupt.h>
 #include <linux/kernel_stat.h>
 #include <linux/seq_file.h>
+#include <linux/smp.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>
-#include <asm/smp.h>
 #include <asm/irq.h>
 
 atomic_t irq_err_count;

commit c3d80000e3a812fe5a200d6bde755fbd7fa65481
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Dec 23 15:15:17 2008 +0100

    x86: export vector_used_by_percpu_irq
    
    Impact: build fix
    
    lguest can be built as a module and makes use of this new symbol:
    
    ERROR: "vector_used_by_percpu_irq" [drivers/lguest/lg.ko] undefined!
    
    export it.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3f1d9d18df67..bce53e1352a0 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -9,6 +9,7 @@
 #include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/smp.h>
+#include <asm/irq.h>
 
 atomic_t irq_err_count;
 
@@ -190,3 +191,5 @@ u64 arch_irq_stat(void)
 #endif
 	return sum;
 }
+
+EXPORT_SYMBOL_GPL(vector_used_by_percpu_irq);

commit 241771ef016b5c0c83cd7a4372a74321c973c1e6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Dec 3 10:39:53 2008 +0100

    performance counters: x86 support
    
    Implement performance counters for x86 Intel CPUs.
    
    It's simplified right now: the PERFMON CPU feature is assumed,
    which is available in Core2 and later Intel CPUs.
    
    The design is flexible to be extended to more CPU types as well.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index d1d4dc52f649..d92bc71e41a7 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -56,6 +56,10 @@ static int show_other_interrupts(struct seq_file *p)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
 	seq_printf(p, "  Local timer interrupts\n");
+	seq_printf(p, "CNT: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->apic_perf_irqs);
+	seq_printf(p, "  Performance counter interrupts\n");
 #endif
 #ifdef CONFIG_SMP
 	seq_printf(p, "RES: ");
@@ -160,6 +164,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 
 #ifdef CONFIG_X86_LOCAL_APIC
 	sum += irq_stats(cpu)->apic_timer_irqs;
+	sum += irq_stats(cpu)->apic_perf_irqs;
 #endif
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;

commit 0b8f1efad30bd58f89961b82dfe68b9edf8fd2ac
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Dec 5 18:58:31 2008 -0800

    sparse irq_desc[] array: core kernel and x86 changes
    
    Impact: new feature
    
    Problem on distro kernels: irq_desc[NR_IRQS] takes megabytes of RAM with
    NR_CPUS set to large values. The goal is to be able to scale up to much
    larger NR_IRQS value without impacting the (important) common case.
    
    To solve this, we generalize irq_desc[NR_IRQS] to an (optional) array of
    irq_desc pointers.
    
    When CONFIG_SPARSE_IRQ=y is used, we use kzalloc_node to get irq_desc,
    this also makes the IRQ descriptors NUMA-local (to the site that calls
    request_irq()).
    
    This gets rid of the irq_cfg[] static array on x86 as well: irq_cfg now
    uses desc->chip_data for x86 to store irq_cfg.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index d1d4dc52f649..3f1d9d18df67 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -118,6 +118,9 @@ int show_interrupts(struct seq_file *p, void *v)
 	}
 
 	desc = irq_to_desc(i);
+	if (!desc)
+		return 0;
+
 	spin_lock_irqsave(&desc->lock, flags);
 #ifndef CONFIG_SMP
 	any_count = kstat_irqs(i);

commit e9f95e637320efe1936b647308ddf4ec5b8e0311
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Oct 21 15:49:59 2008 +0200

    genirq: fix off by one and coding style
    
    Fix off-by-one in for_each_irq_desc_reverse().
    
    Impact is near zero in practice, because nothing substantial wants to
    iterate down to IRQ#0 - but fix it nevertheless.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index ccf6c503fc3b..d1d4dc52f649 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -36,7 +36,7 @@ void ack_bad_irq(unsigned int irq)
 }
 
 #ifdef CONFIG_X86_32
-# define irq_stats(x)		(&per_cpu(irq_stat,x))
+# define irq_stats(x)		(&per_cpu(irq_stat, x))
 #else
 # define irq_stats(x)		cpu_pda(x)
 #endif
@@ -113,7 +113,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	if (i == 0) {
 		seq_printf(p, "           ");
 		for_each_online_cpu(j)
-			seq_printf(p, "CPU%-8d",j);
+			seq_printf(p, "CPU%-8d", j);
 		seq_putc(p, '\n');
 	}
 

commit 249f6d9eab372790579ada8991bba3384c204e06
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Oct 16 12:18:50 2008 +0200

    x86: move ack_bad_irq() to irq.c
    
    Share more duplicated code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3b9128498976..ccf6c503fc3b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -12,6 +12,29 @@
 
 atomic_t irq_err_count;
 
+/*
+ * 'what should we do if we get a hw irq event on an illegal vector'.
+ * each architecture has to answer this themselves.
+ */
+void ack_bad_irq(unsigned int irq)
+{
+	printk(KERN_ERR "unexpected IRQ trap at vector %02x\n", irq);
+
+#ifdef CONFIG_X86_LOCAL_APIC
+	/*
+	 * Currently unexpected vectors happen only on SMP and APIC.
+	 * We _must_ ack these because every local APIC has only N
+	 * irq slots per priority level, and a 'hanging, unacked' IRQ
+	 * holds up an irq slot - in excessive cases (when multiple
+	 * unexpected vectors occur) that might lock up the APIC
+	 * completely.
+	 * But only ack when the APIC is enabled -AK
+	 */
+	if (cpu_has_apic)
+		ack_APIC_irq();
+#endif
+}
+
 #ifdef CONFIG_X86_32
 # define irq_stats(x)		(&per_cpu(irq_stat,x))
 #else

commit 6b39ba771e3c78d00e0abcebad270bd4212b28bc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Oct 16 11:32:24 2008 +0200

    x86: unify show_interrupts() and proc helpers
    
    show_interrupts() and proc helpers are basically the same for
    32 and 64 bit. Move them to a shared source file.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
new file mode 100644
index 000000000000..3b9128498976
--- /dev/null
+++ b/arch/x86/kernel/irq.c
@@ -0,0 +1,166 @@
+/*
+ * Common interrupt code for 32 and 64 bit
+ */
+#include <linux/cpu.h>
+#include <linux/interrupt.h>
+#include <linux/kernel_stat.h>
+#include <linux/seq_file.h>
+
+#include <asm/apic.h>
+#include <asm/io_apic.h>
+#include <asm/smp.h>
+
+atomic_t irq_err_count;
+
+#ifdef CONFIG_X86_32
+# define irq_stats(x)		(&per_cpu(irq_stat,x))
+#else
+# define irq_stats(x)		cpu_pda(x)
+#endif
+/*
+ * /proc/interrupts printing:
+ */
+static int show_other_interrupts(struct seq_file *p)
+{
+	int j;
+
+	seq_printf(p, "NMI: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->__nmi_count);
+	seq_printf(p, "  Non-maskable interrupts\n");
+#ifdef CONFIG_X86_LOCAL_APIC
+	seq_printf(p, "LOC: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->apic_timer_irqs);
+	seq_printf(p, "  Local timer interrupts\n");
+#endif
+#ifdef CONFIG_SMP
+	seq_printf(p, "RES: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
+	seq_printf(p, "  Rescheduling interrupts\n");
+	seq_printf(p, "CAL: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
+	seq_printf(p, "  Function call interrupts\n");
+	seq_printf(p, "TLB: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
+	seq_printf(p, "  TLB shootdowns\n");
+#endif
+#ifdef CONFIG_X86_MCE
+	seq_printf(p, "TRM: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_thermal_count);
+	seq_printf(p, "  Thermal event interrupts\n");
+# ifdef CONFIG_X86_64
+	seq_printf(p, "THR: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
+	seq_printf(p, "  Threshold APIC interrupts\n");
+# endif
+#endif
+#ifdef CONFIG_X86_LOCAL_APIC
+	seq_printf(p, "SPU: ");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_spurious_count);
+	seq_printf(p, "  Spurious interrupts\n");
+#endif
+	seq_printf(p, "ERR: %10u\n", atomic_read(&irq_err_count));
+#if defined(CONFIG_X86_IO_APIC)
+	seq_printf(p, "MIS: %10u\n", atomic_read(&irq_mis_count));
+#endif
+	return 0;
+}
+
+int show_interrupts(struct seq_file *p, void *v)
+{
+	unsigned long flags, any_count = 0;
+	int i = *(loff_t *) v, j;
+	struct irqaction *action;
+	struct irq_desc *desc;
+
+	if (i > nr_irqs)
+		return 0;
+
+	if (i == nr_irqs)
+		return show_other_interrupts(p);
+
+	/* print header */
+	if (i == 0) {
+		seq_printf(p, "           ");
+		for_each_online_cpu(j)
+			seq_printf(p, "CPU%-8d",j);
+		seq_putc(p, '\n');
+	}
+
+	desc = irq_to_desc(i);
+	spin_lock_irqsave(&desc->lock, flags);
+#ifndef CONFIG_SMP
+	any_count = kstat_irqs(i);
+#else
+	for_each_online_cpu(j)
+		any_count |= kstat_irqs_cpu(i, j);
+#endif
+	action = desc->action;
+	if (!action && !any_count)
+		goto out;
+
+	seq_printf(p, "%3d: ", i);
+#ifndef CONFIG_SMP
+	seq_printf(p, "%10u ", kstat_irqs(i));
+#else
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
+#endif
+	seq_printf(p, " %8s", desc->chip->name);
+	seq_printf(p, "-%-8s", desc->name);
+
+	if (action) {
+		seq_printf(p, "  %s", action->name);
+		while ((action = action->next) != NULL)
+			seq_printf(p, ", %s", action->name);
+	}
+
+	seq_putc(p, '\n');
+out:
+	spin_unlock_irqrestore(&desc->lock, flags);
+	return 0;
+}
+
+/*
+ * /proc/stat helpers
+ */
+u64 arch_irq_stat_cpu(unsigned int cpu)
+{
+	u64 sum = irq_stats(cpu)->__nmi_count;
+
+#ifdef CONFIG_X86_LOCAL_APIC
+	sum += irq_stats(cpu)->apic_timer_irqs;
+#endif
+#ifdef CONFIG_SMP
+	sum += irq_stats(cpu)->irq_resched_count;
+	sum += irq_stats(cpu)->irq_call_count;
+	sum += irq_stats(cpu)->irq_tlb_count;
+#endif
+#ifdef CONFIG_X86_MCE
+	sum += irq_stats(cpu)->irq_thermal_count;
+# ifdef CONFIG_X86_64
+	sum += irq_stats(cpu)->irq_threshold_count;
+#endif
+#endif
+#ifdef CONFIG_X86_LOCAL_APIC
+	sum += irq_stats(cpu)->irq_spurious_count;
+#endif
+	return sum;
+}
+
+u64 arch_irq_stat(void)
+{
+	u64 sum = atomic_read(&irq_err_count);
+
+#ifdef CONFIG_X86_IO_APIC
+	sum += atomic_read(&irq_mis_count);
+#endif
+	return sum;
+}
