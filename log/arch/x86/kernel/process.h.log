commit 6184488a19be96d89cb6c36fb4bc277198309484
Author: Nishad Kamdar <nishadkamdar@gmail.com>
Date:   Tue Apr 16 21:16:14 2019 +0530

    x86: Use the correct SPDX License Identifier in headers
    
    Correct the SPDX License Identifier format in a couple of headers.
    
    Suggested-by: Joe Perches <joe@perches.com>
    Signed-off-by: Nishad Kamdar <nishadkamdar@gmail.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Uwe Kleine-KÃ¶nig <u.kleine-koenig@pengutronix.de>
    Cc: Waiman Long <longman@redhat.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/697848ff866ade29e78e872525d7a3067642fd37.1555427420.git.nishadkamdar@gmail.com

diff --git a/arch/x86/kernel/process.h b/arch/x86/kernel/process.h
index 320ab978fb1f..1d0797b2338a 100644
--- a/arch/x86/kernel/process.h
+++ b/arch/x86/kernel/process.h
@@ -1,4 +1,4 @@
-// SPDX-License-Identifier: GPL-2.0
+/* SPDX-License-Identifier: GPL-2.0 */
 //
 // Code shared between 32 and 64 bit
 

commit aa77bfb354c495fc4361199e63fc5765b9e1e783
Author: Waiman Long <longman@redhat.com>
Date:   Wed Dec 5 14:49:27 2018 -0500

    x86/speculation: Change misspelled STIPB to STIBP
    
    STIBP stands for Single Thread Indirect Branch Predictors. The acronym,
    however, can be easily mis-spelled as STIPB. It is perhaps due to the
    presence of another related term - IBPB (Indirect Branch Predictor
    Barrier).
    
    Fix the mis-spelling in the code.
    
    Signed-off-by: Waiman Long <longman@redhat.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: KarimAllah Ahmed <karahmed@amazon.de>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/1544039368-9009-1-git-send-email-longman@redhat.com

diff --git a/arch/x86/kernel/process.h b/arch/x86/kernel/process.h
index 898e97cf6629..320ab978fb1f 100644
--- a/arch/x86/kernel/process.h
+++ b/arch/x86/kernel/process.h
@@ -19,7 +19,7 @@ static inline void switch_to_extra(struct task_struct *prev,
 	if (IS_ENABLED(CONFIG_SMP)) {
 		/*
 		 * Avoid __switch_to_xtra() invocation when conditional
-		 * STIPB is disabled and the only different bit is
+		 * STIBP is disabled and the only different bit is
 		 * TIF_SPEC_IB. For CONFIG_SMP=n TIF_SPEC_IB is not
 		 * in the TIF_WORK_CTXSW masks.
 		 */

commit 5635d99953f04b550738f6f4c1c532667c3fd872
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Nov 25 19:33:48 2018 +0100

    x86/speculation: Avoid __switch_to_xtra() calls
    
    The TIF_SPEC_IB bit does not need to be evaluated in the decision to invoke
    __switch_to_xtra() when:
    
     - CONFIG_SMP is disabled
    
     - The conditional STIPB mode is disabled
    
    The TIF_SPEC_IB bit still controls IBPB in both cases so the TIF work mask
    checks might invoke __switch_to_xtra() for nothing if TIF_SPEC_IB is the
    only set bit in the work masks.
    
    Optimize it out by masking the bit at compile time for CONFIG_SMP=n and at
    run time when the static key controlling the conditional STIBP mode is
    disabled.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Casey Schaufler <casey.schaufler@intel.com>
    Cc: Asit Mallick <asit.k.mallick@intel.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jon Masters <jcm@redhat.com>
    Cc: Waiman Long <longman9394@gmail.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Dave Stewart <david.c.stewart@intel.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20181125185005.374062201@linutronix.de

diff --git a/arch/x86/kernel/process.h b/arch/x86/kernel/process.h
index 020fbfac3a27..898e97cf6629 100644
--- a/arch/x86/kernel/process.h
+++ b/arch/x86/kernel/process.h
@@ -2,6 +2,8 @@
 //
 // Code shared between 32 and 64 bit
 
+#include <asm/spec-ctrl.h>
+
 void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p);
 
 /*
@@ -14,6 +16,19 @@ static inline void switch_to_extra(struct task_struct *prev,
 	unsigned long next_tif = task_thread_info(next)->flags;
 	unsigned long prev_tif = task_thread_info(prev)->flags;
 
+	if (IS_ENABLED(CONFIG_SMP)) {
+		/*
+		 * Avoid __switch_to_xtra() invocation when conditional
+		 * STIPB is disabled and the only different bit is
+		 * TIF_SPEC_IB. For CONFIG_SMP=n TIF_SPEC_IB is not
+		 * in the TIF_WORK_CTXSW masks.
+		 */
+		if (!static_branch_likely(&switch_to_cond_stibp)) {
+			prev_tif &= ~_TIF_SPEC_IB;
+			next_tif &= ~_TIF_SPEC_IB;
+		}
+	}
+
 	/*
 	 * __switch_to_xtra() handles debug registers, i/o bitmaps,
 	 * speculation mitigations etc.

commit ff16701a29cba3aafa0bd1656d766813b2d0a811
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Nov 25 19:33:47 2018 +0100

    x86/process: Consolidate and simplify switch_to_xtra() code
    
    Move the conditional invocation of __switch_to_xtra() into an inline
    function so the logic can be shared between 32 and 64 bit.
    
    Remove the handthrough of the TSS pointer and retrieve the pointer directly
    in the bitmap handling function. Use this_cpu_ptr() instead of the
    per_cpu() indirection.
    
    This is a preparatory change so integration of conditional indirect branch
    speculation optimization happens only in one place.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Casey Schaufler <casey.schaufler@intel.com>
    Cc: Asit Mallick <asit.k.mallick@intel.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jon Masters <jcm@redhat.com>
    Cc: Waiman Long <longman9394@gmail.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Dave Stewart <david.c.stewart@intel.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20181125185005.280855518@linutronix.de

diff --git a/arch/x86/kernel/process.h b/arch/x86/kernel/process.h
new file mode 100644
index 000000000000..020fbfac3a27
--- /dev/null
+++ b/arch/x86/kernel/process.h
@@ -0,0 +1,24 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Code shared between 32 and 64 bit
+
+void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p);
+
+/*
+ * This needs to be inline to optimize for the common case where no extra
+ * work needs to be done.
+ */
+static inline void switch_to_extra(struct task_struct *prev,
+				   struct task_struct *next)
+{
+	unsigned long next_tif = task_thread_info(next)->flags;
+	unsigned long prev_tif = task_thread_info(prev)->flags;
+
+	/*
+	 * __switch_to_xtra() handles debug registers, i/o bitmaps,
+	 * speculation mitigations etc.
+	 */
+	if (unlikely(next_tif & _TIF_WORK_CTXSW_NEXT ||
+		     prev_tif & _TIF_WORK_CTXSW_PREV))
+		__switch_to_xtra(prev, next);
+}
