commit 81b6b96475ac7a4ebfceae9f16fb3758327adbfe
Merge: a308a7102215 a7ba70f1787f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 28 11:16:43 2019 -0800

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux; tag 'dma-mapping-5.5' of git://git.infradead.org/users/hch/dma-mapping
    
    Pull dma-mapping updates from Christoph Hellwig:
    
     - improve dma-debug scalability (Eric Dumazet)
    
     - tiny dma-debug cleanup (Dan Carpenter)
    
     - check for vmap memory in dma_map_single (Kees Cook)
    
     - check for dma_addr_t overflows in dma-direct when using DMA offsets
       (Nicolas Saenz Julienne)
    
     - switch the x86 sta2x11 SOC to use more generic DMA code (Nicolas
       Saenz Julienne)
    
     - fix arm-nommu dma-ranges handling (Vladimir Murzin)
    
     - use __initdata in CMA (Shyam Saini)
    
     - replace the bus dma mask with a limit (Nicolas Saenz Julienne)
    
     - merge the remapping helpers into the main dma-direct flow (me)
    
     - switch xtensa to the generic dma remap handling (me)
    
     - various cleanups around dma_capable (me)
    
     - remove unused dev arguments to various dma-noncoherent helpers (me)
    
    * 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux:
    
    * tag 'dma-mapping-5.5' of git://git.infradead.org/users/hch/dma-mapping: (22 commits)
      dma-mapping: treat dev->bus_dma_mask as a DMA limit
      dma-direct: exclude dma_direct_map_resource from the min_low_pfn check
      dma-direct: don't check swiotlb=force in dma_direct_map_resource
      dma-debug: clean up put_hash_bucket()
      powerpc: remove support for NULL dev in __phys_to_dma / __dma_to_phys
      dma-direct: avoid a forward declaration for phys_to_dma
      dma-direct: unify the dma_capable definitions
      dma-mapping: drop the dev argument to arch_sync_dma_for_*
      x86/PCI: sta2x11: use default DMA address translation
      dma-direct: check for overflows on 32 bit DMA addresses
      dma-debug: increase HASH_SIZE
      dma-debug: reorder struct dma_debug_entry fields
      xtensa: use the generic uncached segment support
      dma-mapping: merge the generic remapping helpers into dma-direct
      dma-direct: provide mmap and get_sgtable method overrides
      dma-direct: remove the dma_handle argument to __dma_direct_alloc_pages
      dma-direct: remove __dma_direct_free_pages
      usb: core: Remove redundant vmap checks
      kernel: dma-contiguous: mark CMA parameters __initdata/__initconst
      dma-debug: add a schedule point in debug_dma_dump_mappings()
      ...

commit a7ba70f1787f977f970cd116076c6fce4b9e01cc
Author: Nicolas Saenz Julienne <nsaenzjulienne@suse.de>
Date:   Thu Nov 21 10:26:44 2019 +0100

    dma-mapping: treat dev->bus_dma_mask as a DMA limit
    
    Using a mask to represent bus DMA constraints has a set of limitations.
    The biggest one being it can only hold a power of two (minus one). The
    DMA mapping code is already aware of this and treats dev->bus_dma_mask
    as a limit. This quirk is already used by some architectures although
    still rare.
    
    With the introduction of the Raspberry Pi 4 we've found a new contender
    for the use of bus DMA limits, as its PCIe bus can only address the
    lower 3GB of memory (of a total of 4GB). This is impossible to represent
    with a mask. To make things worse the device-tree code rounds non power
    of two bus DMA limits to the next power of two, which is unacceptable in
    this case.
    
    In the light of this, rename dev->bus_dma_mask to dev->bus_dma_limit all
    over the tree and treat it as such. Note that dev->bus_dma_limit should
    contain the higher accessible DMA address.
    
    Signed-off-by: Nicolas Saenz Julienne <nsaenzjulienne@suse.de>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index fa4352dce491..3a75d665d43c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -146,7 +146,7 @@ rootfs_initcall(pci_iommu_init);
 
 static int via_no_dac_cb(struct pci_dev *pdev, void *data)
 {
-	pdev->dev.bus_dma_mask = DMA_BIT_MASK(32);
+	pdev->dev.bus_dma_limit = DMA_BIT_MASK(32);
 	return 0;
 }
 

commit 90dc392fc445ee2fc17c2617e306774b269386ac
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 13 08:18:34 2019 +0100

    x86: Remove the calgary IOMMU driver
    
    The calgary IOMMU was only used on high-end IBM systems in the early
    x86_64 age and has no known users left.  Remove it to avoid having to
    touch it for pending changes to the DMA API.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20191113071836.21041-2-hch@lst.de

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index fa4352dce491..57de2ebff7e2 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -12,7 +12,6 @@
 #include <asm/dma.h>
 #include <asm/iommu.h>
 #include <asm/gart.h>
-#include <asm/calgary.h>
 #include <asm/x86_init.h>
 #include <asm/iommu_table.h>
 
@@ -112,11 +111,6 @@ static __init int iommu_setup(char *p)
 
 		gart_parse_options(p);
 
-#ifdef CONFIG_CALGARY_IOMMU
-		if (!strncmp(p, "calgary", 7))
-			use_calgary = 1;
-#endif /* CONFIG_CALGARY_IOMMU */
-
 		p += strcspn(p, ",");
 		if (*p == ',')
 			++p;

commit c53c47aac4ff9509e7e1a32666baefbd9793c5a0
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:51 2019 +0200

    x86/dma: Get rid of iommu_pass_through
    
    This variable has no users anymore. Remove it and tell the
    IOMMU code via its new functions about requested DMA modes.
    
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f62b498b18fb..fa4352dce491 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,6 +1,7 @@
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/dma-direct.h>
 #include <linux/dma-debug.h>
+#include <linux/iommu.h>
 #include <linux/dmar.h>
 #include <linux/export.h>
 #include <linux/memblock.h>
@@ -34,21 +35,6 @@ int no_iommu __read_mostly;
 /* Set this to 1 if there is a HW IOMMU in the system */
 int iommu_detected __read_mostly = 0;
 
-/*
- * This variable becomes 1 if iommu=pt is passed on the kernel command line.
- * If this variable is 1, IOMMU implementations do no DMA translation for
- * devices and allow every device to access to whole physical memory. This is
- * useful if a user wants to use an IOMMU only for KVM device assignment to
- * guests and not for driver dma translation.
- * It is also possible to disable by default in kernel config, and enable with
- * iommu=nopt at boot time.
- */
-#ifdef CONFIG_IOMMU_DEFAULT_PASSTHROUGH
-int iommu_pass_through __read_mostly = 1;
-#else
-int iommu_pass_through __read_mostly;
-#endif
-
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
 void __init pci_iommu_alloc(void)
@@ -120,9 +106,9 @@ static __init int iommu_setup(char *p)
 			swiotlb = 1;
 #endif
 		if (!strncmp(p, "pt", 2))
-			iommu_pass_through = 1;
+			iommu_set_default_passthrough(true);
 		if (!strncmp(p, "nopt", 4))
-			iommu_pass_through = 0;
+			iommu_set_default_translated(true);
 
 		gart_parse_options(p);
 

commit cb1aaebea8d79860181559d7b5d482aea63db113
Author: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
Date:   Fri Jun 7 15:54:32 2019 -0300

    docs: fix broken documentation links
    
    Mostly due to x86 and acpi conversion, several documentation
    links are still pointing to the old file. Fix them.
    
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
    Reviewed-by: Wolfram Sang <wsa@the-dreams.de>
    Reviewed-by: Sven Van Asbroeck <TheSven73@gmail.com>
    Reviewed-by: Bhupesh Sharma <bhsharma@redhat.com>
    Acked-by: Mark Brown <broonie@kernel.org>
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index dcd272dbd0a9..f62b498b18fb 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -70,7 +70,7 @@ void __init pci_iommu_alloc(void)
 }
 
 /*
- * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
+ * See <Documentation/x86/x86_64/boot-options.rst> for the iommu kernel
  * parameter documentation.
  */
 static __init int iommu_setup(char *p)

commit e43e2657fe77a37b13643e2469670ecdb0ba5e10
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Dec 21 14:32:02 2018 +0100

    x86/dma: Remove the x86_dma_fallback_dev hack
    
    Now that we removed support for the NULL device argument in the DMA API,
    there is no need to cater for that in the x86 code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index d460998ae828..dcd272dbd0a9 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -51,14 +51,6 @@ int iommu_pass_through __read_mostly;
 
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
-/* Dummy device used for NULL arguments (normally ISA). */
-struct device x86_dma_fallback_dev = {
-	.init_name = "fallback device",
-	.coherent_dma_mask = ISA_DMA_BIT_MASK,
-	.dma_mask = &x86_dma_fallback_dev.coherent_dma_mask,
-};
-EXPORT_SYMBOL(x86_dma_fallback_dev);
-
 void __init pci_iommu_alloc(void)
 {
 	struct iommu_table_entry *p;
@@ -77,18 +69,6 @@ void __init pci_iommu_alloc(void)
 	}
 }
 
-bool arch_dma_alloc_attrs(struct device **dev)
-{
-	if (!*dev)
-		*dev = &x86_dma_fallback_dev;
-
-	if (!is_device_dma_capable(*dev))
-		return false;
-	return true;
-
-}
-EXPORT_SYMBOL(arch_dma_alloc_attrs);
-
 /*
  * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
  * parameter documentation.

commit 356da6d0cde3323236977fce54c1f9612a742036
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 6 13:39:32 2018 -0800

    dma-mapping: bypass indirect calls for dma-direct
    
    Avoid expensive indirect calls in the fast path DMA mapping
    operations by directly calling the dma_direct_* ops if we are using
    the directly mapped DMA operations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Tested-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Tested-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f4562fcec681..d460998ae828 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -17,7 +17,7 @@
 
 static bool disable_dac_quirk __read_mostly;
 
-const struct dma_map_ops *dma_ops = &dma_direct_ops;
+const struct dma_map_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
 #ifdef CONFIG_IOMMU_DEBUG

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 7ba73fe0d917..f4562fcec681 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -3,7 +3,7 @@
 #include <linux/dma-debug.h>
 #include <linux/dmar.h>
 #include <linux/export.h>
-#include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/gfp.h>
 #include <linux/pci.h>
 

commit 18b8bfdfbae5821a7df691bc1e542bbab6c31e9c
Merge: d972604f6f87 6488a7f35eea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 24 13:10:38 2018 -0700

    Merge tag 'iommu-updates-v4.19' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull IOMMU updates from Joerg Roedel:
    
     - PASID table handling updates for the Intel VT-d driver. It implements
       a global PASID space now so that applications usings multiple devices
       will just have one PASID.
    
     - A new config option to make iommu passthroug mode the default.
    
     - New sysfs attribute for iommu groups to export the type of the
       default domain.
    
     - A debugfs interface (for debug only) usable by IOMMU drivers to
       export internals to user-space.
    
     - R-Car Gen3 SoCs support for the ipmmu-vmsa driver
    
     - The ARM-SMMU now aborts transactions from unknown devices and devices
       not attached to any domain.
    
     - Various cleanups and smaller fixes all over the place.
    
    * tag 'iommu-updates-v4.19' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu: (42 commits)
      iommu/omap: Fix cache flushes on L2 table entries
      iommu: Remove the ->map_sg indirection
      iommu/arm-smmu-v3: Abort all transactions if SMMU is enabled in kdump kernel
      iommu/arm-smmu-v3: Prevent any devices access to memory without registration
      iommu/ipmmu-vmsa: Don't register as BUS IOMMU if machine doesn't have IPMMU-VMSA
      iommu/ipmmu-vmsa: Clarify supported platforms
      iommu/ipmmu-vmsa: Fix allocation in atomic context
      iommu: Add config option to set passthrough as default
      iommu: Add sysfs attribyte for domain type
      iommu/arm-smmu-v3: sync the OVACKFLG to PRIQ consumer register
      iommu/arm-smmu: Error out only if not enough context interrupts
      iommu/io-pgtable-arm-v7s: Abort allocation when table address overflows the PTE
      iommu/io-pgtable-arm: Fix pgtable allocation in selftest
      iommu/vt-d: Remove the obsolete per iommu pasid tables
      iommu/vt-d: Apply per pci device pasid table in SVA
      iommu/vt-d: Allocate and free pasid table
      iommu/vt-d: Per PCI device pasid table interfaces
      iommu/vt-d: Add for_each_device_domain() helper
      iommu/vt-d: Move device_domain_info to header
      iommu/vt-d: Apply global PASID in SVA
      ...

commit 4e31843f681c34f7185e7d169fe627c9d891ce2c
Merge: f91e654474d4 fa687fb9ced4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 16 09:21:54 2018 -0700

    Merge tag 'pci-v4.19-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci
    
    Pull pci updates from Bjorn Helgaas:
    
     - Decode AER errors with names similar to "lspci" (Tyler Baicar)
    
     - Expose AER statistics in sysfs (Rajat Jain)
    
     - Clear AER status bits selectively based on the type of recovery (Oza
       Pawandeep)
    
     - Honor "pcie_ports=native" even if HEST sets FIRMWARE_FIRST (Alexandru
       Gagniuc)
    
     - Don't clear AER status bits if we're using the "Firmware-First"
       strategy where firmware owns the registers (Alexandru Gagniuc)
    
     - Use sysfs_match_string() to simplify ASPM sysfs parsing (Andy
       Shevchenko)
    
     - Remove unnecessary includes of <linux/pci-aspm.h> (Bjorn Helgaas)
    
     - Defer DPC event handling to work queue (Keith Busch)
    
     - Use threaded IRQ for DPC bottom half (Keith Busch)
    
     - Print AER status while handling DPC events (Keith Busch)
    
     - Work around IDT switch ACS Source Validation erratum (James
       Puthukattukaran)
    
     - Emit diagnostics for all cases of PCIe Link downtraining (Links
       operating slower than they're capable of) (Alexandru Gagniuc)
    
     - Skip VFs when configuring Max Payload Size (Myron Stowe)
    
     - Reduce Root Port Max Payload Size if necessary when hot-adding a
       device below it (Myron Stowe)
    
     - Simplify SHPC existence/permission checks (Bjorn Helgaas)
    
     - Remove hotplug sample skeleton driver (Lukas Wunner)
    
     - Convert pciehp to threaded IRQ handling (Lukas Wunner)
    
     - Improve pciehp tolerance of missed events and initially unstable
       links (Lukas Wunner)
    
     - Clear spurious pciehp events on resume (Lukas Wunner)
    
     - Add pciehp runtime PM support, including for Thunderbolt controllers
       (Lukas Wunner)
    
     - Support interrupts from pciehp bridges in D3hot (Lukas Wunner)
    
     - Mark fall-through switch cases before enabling -Wimplicit-fallthrough
       (Gustavo A. R. Silva)
    
     - Move DMA-debug PCI init from arch code to PCI core (Christoph
       Hellwig)
    
     - Fix pci_request_irq() usage of IRQF_ONESHOT when no handler is
       supplied (Heiner Kallweit)
    
     - Unify PCI and DMA direction #defines (Shunyong Yang)
    
     - Add PCI_DEVICE_DATA() macro (Andy Shevchenko)
    
     - Check for VPD completion before checking for timeout (Bert Kenward)
    
     - Limit Netronome NFP5000 config space size to work around erratum
       (Jakub Kicinski)
    
     - Set IRQCHIP_ONESHOT_SAFE for PCI MSI irqchips (Heiner Kallweit)
    
     - Document ACPI description of PCI host bridges (Bjorn Helgaas)
    
     - Add "pci=disable_acs_redir=" parameter to disable ACS redirection for
       peer-to-peer DMA support (we don't have the peer-to-peer support yet;
       this is just one piece) (Logan Gunthorpe)
    
     - Clean up devm_of_pci_get_host_bridge_resources() resource allocation
       (Jan Kiszka)
    
     - Fixup resizable BARs after suspend/resume (Christian KÃ¶nig)
    
     - Make "pci=earlydump" generic (Sinan Kaya)
    
     - Fix ROM BAR access routines to stay in bounds and check for signature
       correctly (Rex Zhu)
    
     - Add DMA alias quirk for Microsemi Switchtec NTB (Doug Meyer)
    
     - Expand documentation for pci_add_dma_alias() (Logan Gunthorpe)
    
     - To avoid bus errors, enable PASID only if entire path supports
       End-End TLP prefixes (Sinan Kaya)
    
     - Unify slot and bus reset functions and remove hotplug knowledge from
       callers (Sinan Kaya)
    
     - Add Function-Level Reset quirks for Intel and Samsung NVMe devices to
       fix guest reboot issues (Alex Williamson)
    
     - Add function 1 DMA alias quirk for Marvell 88SS9183 PCIe SSD
       Controller (Bjorn Helgaas)
    
     - Remove Xilinx AXI-PCIe host bridge arch dependency (Palmer Dabbelt)
    
     - Remove Aardvark outbound window configuration (Evan Wang)
    
     - Fix Aardvark bridge window sizing issue (Zachary Zhang)
    
     - Convert Aardvark to use pci_host_probe() to reduce code duplication
       (Thomas Petazzoni)
    
     - Correct the Cadence cdns_pcie_writel() signature (Alan Douglas)
    
     - Add Cadence support for optional generic PHYs (Alan Douglas)
    
     - Add Cadence power management ops (Alan Douglas)
    
     - Remove redundant variable from Cadence driver (Colin Ian King)
    
     - Add Kirin MSI support (Xiaowei Song)
    
     - Drop unnecessary root_bus_nr setting from exynos, imx6, keystone,
       armada8k, artpec6, designware-plat, histb, qcom, spear13xx (Shawn
       Guo)
    
     - Move link notification settings from DesignWare core to individual
       drivers (Gustavo Pimentel)
    
     - Add endpoint library MSI-X interfaces (Gustavo Pimentel)
    
     - Correct signature of endpoint library IRQ interfaces (Gustavo
       Pimentel)
    
     - Add DesignWare endpoint library MSI-X callbacks (Gustavo Pimentel)
    
     - Add endpoint library MSI-X test support (Gustavo Pimentel)
    
     - Remove unnecessary GFP_ATOMIC from Hyper-V "new child" allocation
       (Jia-Ju Bai)
    
     - Add more devices to Broadcom PAXC quirk (Ray Jui)
    
     - Work around corrupted Broadcom PAXC config space to enable SMMU and
       GICv3 ITS (Ray Jui)
    
     - Disable MSI parsing to work around broken Broadcom PAXC logic in some
       devices (Ray Jui)
    
     - Hide unconfigured functions to work around a Broadcom PAXC defect
       (Ray Jui)
    
     - Lower iproc log level to reduce console output during boot (Ray Jui)
    
     - Fix mobiveil iomem/phys_addr_t type usage (Lorenzo Pieralisi)
    
     - Fix mobiveil missing include file (Lorenzo Pieralisi)
    
     - Add mobiveil Kconfig/Makefile support (Lorenzo Pieralisi)
    
     - Fix mvebu I/O space remapping issues (Thomas Petazzoni)
    
     - Use generic pci_host_bridge in mvebu instead of ARM-specific API
       (Thomas Petazzoni)
    
     - Whitelist VMD devices with fast interrupt handlers to avoid sharing
       vectors with slow handlers (Keith Busch)
    
    * tag 'pci-v4.19-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci: (153 commits)
      PCI/AER: Don't clear AER bits if error handling is Firmware-First
      PCI: Limit config space size for Netronome NFP5000
      PCI/MSI: Set IRQCHIP_ONESHOT_SAFE for PCI-MSI irqchips
      PCI/VPD: Check for VPD access completion before checking for timeout
      PCI: Add PCI_DEVICE_DATA() macro to fully describe device ID entry
      PCI: Match Root Port's MPS to endpoint's MPSS as necessary
      PCI: Skip MPS logic for Virtual Functions (VFs)
      PCI: Add function 1 DMA alias quirk for Marvell 88SS9183
      PCI: Check for PCIe Link downtraining
      PCI: Add ACS Redirect disable quirk for Intel Sunrise Point
      PCI: Add device-specific ACS Redirect disable infrastructure
      PCI: Convert device-specific ACS quirks from NULL termination to ARRAY_SIZE
      PCI: Add "pci=disable_acs_redir=" parameter for peer-to-peer support
      PCI: Allow specifying devices using a base bus and path of devfns
      PCI: Make specifying PCI devices in kernel parameters reusable
      PCI: Hide ACS quirk declarations inside PCI core
      PCI: Delay after FLR of Intel DC P3700 NVMe
      PCI: Disable Samsung SM961/PM961 NVMe before FLR
      PCI: Export pcie_has_flr()
      PCI: mvebu: Drop bogus comment above mvebu_pcie_map_registers()
      ...

commit a8651194f9f61406cb8926feeeb7829258295b2a
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 30 09:38:42 2018 +0200

    PCI: Call dma_debug_add_bus() for pci_bus_type from PCI core
    
    There is nothing arch-specific about PCI or dma-debug, so call
    dma_debug_add_bus() from the PCI core just after registering the bus type.
    
    Most of dma-debug is already generic; this just adds reporting of pending
    dma-allocations on driver unload for arches other than powerpc, sh, and
    x86.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ab5d9dd668d2..43f58632f123 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -155,9 +155,6 @@ static int __init pci_iommu_init(void)
 {
 	struct iommu_table_entry *p;
 
-#ifdef CONFIG_PCI
-	dma_debug_add_bus(&pci_bus_type);
-#endif
 	x86_init.iommu.iommu_init();
 
 	for (p = __iommu_table; p < __iommu_table_end; p++) {

commit f07d141fe9430cdf9f8a65a87c4136bd83b8ab2e
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Mon Jul 23 23:16:07 2018 +0100

    dma-mapping: Generalise dma_32bit_limit flag
    
    Whilst the notion of an upstream DMA restriction is most commonly seen
    in PCI host bridges saddled with a 32-bit native interface, a more
    general version of the same issue can exist on complex SoCs where a bus
    or point-to-point interconnect link from a device's DMA master interface
    to another component along the path to memory (often an IOMMU) may carry
    fewer address bits than the interfaces at both ends nominally support.
    In order to properly deal with this, the first step is to expand the
    dma_32bit_limit flag into an arbitrary mask.
    
    To minimise the impact on existing code, we'll make sure to only
    consider this new mask valid if set. That makes sense anyway, since a
    mask of zero would represent DMA not being wired up at all, and that
    would be better handled by not providing valid ops in the first place.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ab5d9dd668d2..80f9fe8d27d0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -175,7 +175,7 @@ rootfs_initcall(pci_iommu_init);
 
 static int via_no_dac_cb(struct pci_dev *pdev, void *data)
 {
-	pdev->dev.dma_32bit_limit = true;
+	pdev->dev.bus_dma_mask = DMA_BIT_MASK(32);
 	return 0;
 }
 

commit 58d1131777a4b7c228267b809bd88f7be66edcfb
Author: Olof Johansson <olof@lixom.net>
Date:   Fri Jul 20 11:02:23 2018 -0700

    iommu: Add config option to set passthrough as default
    
    This allows the default behavior to be controlled by a kernel config
    option instead of changing the commandline for the kernel to include
    "iommu.passthrough=on" or "iommu=pt" on machines where this is desired.
    
    Likewise, for machines where this config option is enabled, it can be
    disabled at boot time with "iommu.passthrough=off" or "iommu=nopt".
    
    Also corrected iommu=pt documentation for IA-64, since it has no code that
    parses iommu= at all.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ab5d9dd668d2..0acb135de7fb 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -40,8 +40,14 @@ int iommu_detected __read_mostly = 0;
  * devices and allow every device to access to whole physical memory. This is
  * useful if a user wants to use an IOMMU only for KVM device assignment to
  * guests and not for driver dma translation.
+ * It is also possible to disable by default in kernel config, and enable with
+ * iommu=nopt at boot time.
  */
+#ifdef CONFIG_IOMMU_DEFAULT_PASSTHROUGH
+int iommu_pass_through __read_mostly = 1;
+#else
 int iommu_pass_through __read_mostly;
+#endif
 
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
@@ -135,6 +141,8 @@ static __init int iommu_setup(char *p)
 #endif
 		if (!strncmp(p, "pt", 2))
 			iommu_pass_through = 1;
+		if (!strncmp(p, "nopt", 4))
+			iommu_pass_through = 0;
 
 		gart_parse_options(p);
 

commit 0ead51c3fbd15a4bc91e984f1b18b5c9422fbb02
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 28 12:47:57 2018 +0200

    x86/pci-dma: switch the VIA 32-bit DMA quirk to use the struct device flag
    
    Instead of globally disabling > 32bit DMA using the arch_dma_supported
    hook walk the PCI bus under the actually affected bridge and mark every
    device with the dma_32bit_limit flag.  This also gets rid of the
    arch_dma_supported hook entirely.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b523414bc323..ab5d9dd668d2 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -15,7 +15,7 @@
 #include <asm/x86_init.h>
 #include <asm/iommu_table.h>
 
-static int forbid_dac __read_mostly;
+static bool disable_dac_quirk __read_mostly;
 
 const struct dma_map_ops *dma_ops = &dma_direct_ops;
 EXPORT_SYMBOL(dma_ops);
@@ -126,7 +126,7 @@ static __init int iommu_setup(char *p)
 		if (!strncmp(p, "nodac", 5))
 			pr_warn("nodac option ignored.\n");
 		if (!strncmp(p, "usedac", 6)) {
-			forbid_dac = -1;
+			disable_dac_quirk = true;
 			return 1;
 		}
 #ifdef CONFIG_SWIOTLB
@@ -151,19 +151,6 @@ static __init int iommu_setup(char *p)
 }
 early_param("iommu", iommu_setup);
 
-int arch_dma_supported(struct device *dev, u64 mask)
-{
-#ifdef CONFIG_PCI
-	if (mask > 0xffffffff && forbid_dac > 0) {
-		dev_info(dev, "PCI: Disallowing DAC for device\n");
-		return 0;
-	}
-#endif
-
-	return 1;
-}
-EXPORT_SYMBOL(arch_dma_supported);
-
 static int __init pci_iommu_init(void)
 {
 	struct iommu_table_entry *p;
@@ -186,11 +173,17 @@ rootfs_initcall(pci_iommu_init);
 #ifdef CONFIG_PCI
 /* Many VIA bridges seem to corrupt data for DAC. Disable it here */
 
+static int via_no_dac_cb(struct pci_dev *pdev, void *data)
+{
+	pdev->dev.dma_32bit_limit = true;
+	return 0;
+}
+
 static void via_no_dac(struct pci_dev *dev)
 {
-	if (forbid_dac == 0) {
+	if (!disable_dac_quirk) {
 		dev_info(&dev->dev, "disabling DAC on VIA PCI bridge\n");
-		forbid_dac = 1;
+		pci_walk_bus(dev->subordinate, via_no_dac_cb, NULL);
 	}
 }
 DECLARE_PCI_FIXUP_CLASS_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID,

commit 098afd981744061d37eb4d40bc3f755438570afb
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 27 09:31:47 2018 +0200

    x86/pci-dma: remove the explicit nodac and allowdac option
    
    This is something drivers should decide (modulo chipset quirks like
    for VIA), which as far as I can tell is how things have been handled
    for the last 15 years.
    
    Note that we keep the usedac option for now, as it is used in the wild
    to override the too generic VIA quirk.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b65b0d7072f1..b523414bc323 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -122,9 +122,9 @@ static __init int iommu_setup(char *p)
 		if (!strncmp(p, "forcesac", 8))
 			pr_warn("forcesac option ignored.\n");
 		if (!strncmp(p, "allowdac", 8))
-			forbid_dac = 0;
+			pr_warn("allowdac option ignored.\n");
 		if (!strncmp(p, "nodac", 5))
-			forbid_dac = 1;
+			pr_warn("nodac option ignored.\n");
 		if (!strncmp(p, "usedac", 6)) {
 			forbid_dac = -1;
 			return 1;

commit 06e9552f5f12564dc1c3483f0934d96cc4f72f18
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 27 09:13:24 2018 +0200

    x86/pci-dma: remove the experimental forcesac boot option
    
    Limiting the dma mask to avoid PCI (pre-PCIe) DAC cycles while paying
    the huge overhead of an IOMMU is rather pointless, and this seriously
    gets in the way of dma mapping work.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index c7113fd18e32..b65b0d7072f1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -20,8 +20,6 @@ static int forbid_dac __read_mostly;
 const struct dma_map_ops *dma_ops = &dma_direct_ops;
 EXPORT_SYMBOL(dma_ops);
 
-static int iommu_sac_force __read_mostly;
-
 #ifdef CONFIG_IOMMU_DEBUG
 int panic_on_overflow __read_mostly = 1;
 int force_iommu __read_mostly = 1;
@@ -122,7 +120,7 @@ static __init int iommu_setup(char *p)
 		if (!strncmp(p, "nomerge", 7))
 			iommu_merge = 0;
 		if (!strncmp(p, "forcesac", 8))
-			iommu_sac_force = 1;
+			pr_warn("forcesac option ignored.\n");
 		if (!strncmp(p, "allowdac", 8))
 			forbid_dac = 0;
 		if (!strncmp(p, "nodac", 5))
@@ -162,23 +160,6 @@ int arch_dma_supported(struct device *dev, u64 mask)
 	}
 #endif
 
-	/* Tell the device to use SAC when IOMMU force is on.  This
-	   allows the driver to use cheaper accesses in some cases.
-
-	   Problem with this is that if we overflow the IOMMU area and
-	   return DAC as fallback address the device may not handle it
-	   correctly.
-
-	   As a special case some controllers have a 39bit address
-	   mode that is as efficient as 32bit (aic79xx). Don't force
-	   SAC for these.  Assume all masks <= 40 bits are of this
-	   type. Normally this doesn't make any difference, but gives
-	   more gentle handling of IOMMU overflow. */
-	if (iommu_sac_force && (mask >= DMA_BIT_MASK(40))) {
-		dev_info(dev, "Force SAC with mask %Lx\n", mask);
-		return 0;
-	}
-
 	return 1;
 }
 EXPORT_SYMBOL(arch_dma_supported);

commit 884571f0de7b02bb784be3a5c870eabce62cdaeb
Author: Huaisheng Ye <yehs1@lenovo.com>
Date:   Fri May 25 13:00:00 2018 +0800

    dma-mapping: remove unused gfp_t parameter to arch_dma_alloc_attrs
    
    Signed-off-by: Huaisheng Ye <yehs1@lenovo.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index bcbaa2e8031e..c7113fd18e32 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -73,7 +73,7 @@ void __init pci_iommu_alloc(void)
 	}
 }
 
-bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
+bool arch_dma_alloc_attrs(struct device **dev)
 {
 	if (!*dev)
 		*dev = &x86_dma_fallback_dev;

commit 15b28bbcd567a9199481ecfef39702b258f9baff
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 16 17:22:28 2018 +0200

    dma-debug: move initialization to common code
    
    Most mainstream architectures are using 65536 entries, so lets stick to
    that.  If someone is really desperate to override it that can still be
    done through <asm/dma-mapping.h>, but I'd rather see a really good
    rationale for that.
    
    dma_debug_init is now called as a core_initcall, which for many
    architectures means much earlier, and provides dma-debug functionality
    earlier in the boot process.  This should be safe as it only relies
    on the memory allocator already being available.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 77625b60a510..bcbaa2e8031e 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -55,9 +55,6 @@ struct device x86_dma_fallback_dev = {
 };
 EXPORT_SYMBOL(x86_dma_fallback_dev);
 
-/* Number of entries preallocated for DMA-API debugging */
-#define PREALLOC_DMA_DEBUG_ENTRIES       65536
-
 void __init pci_iommu_alloc(void)
 {
 	struct iommu_table_entry *p;
@@ -189,7 +186,6 @@ EXPORT_SYMBOL(arch_dma_supported);
 static int __init pci_iommu_init(void)
 {
 	struct iommu_table_entry *p;
-	dma_debug_init(PREALLOC_DMA_DEBUG_ENTRIES);
 
 #ifdef CONFIG_PCI
 	dma_debug_add_bus(&pci_bus_type);

commit 514c60324960137e74457fdc233a339b985fa8a8
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Thu Apr 5 16:25:34 2018 -0700

    headers: untangle kmemleak.h from mm.h
    
    Currently <linux/slab.h> #includes <linux/kmemleak.h> for no obvious
    reason.  It looks like it's only a convenience, so remove kmemleak.h
    from slab.h and add <linux/kmemleak.h> to any users of kmemleak_* that
    don't already #include it.  Also remove <linux/kmemleak.h> from source
    files that do not use it.
    
    This is tested on i386 allmodconfig and x86_64 allmodconfig.  It would
    be good to run it through the 0day bot for other $ARCHes.  I have
    neither the horsepower nor the storage space for the other $ARCHes.
    
    Update: This patch has been extensively build-tested by both the 0day
    bot & kisskb/ozlabs build farms.  Both of them reported 2 build failures
    for which patches are included here (in v2).
    
    [ slab.h is the second most used header file after module.h; kernel.h is
      right there with slab.h. There could be some minor error in the
      counting due to some #includes having comments after them and I didn't
      combine all of those. ]
    
    [akpm@linux-foundation.org: security/keys/big_key.c needs vmalloc.h, per sfr]
    Link: http://lkml.kernel.org/r/e4309f98-3749-93e1-4bb7-d9501a39d015@infradead.org
    Link: http://kisskb.ellerman.id.au/kisskb/head/13396/
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Reported-by: Michael Ellerman <mpe@ellerman.id.au>      [2 build failures]
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>      [2 build failures]
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Wei Yongjun <weiyongjun1@huawei.com>
    Cc: Luis R. Rodriguez <mcgrof@kernel.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Cc: John Johansen <john.johansen@canonical.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 14437116ffea..77625b60a510 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -6,7 +6,6 @@
 #include <linux/bootmem.h>
 #include <linux/gfp.h>
 #include <linux/pci.h>
-#include <linux/kmemleak.h>
 
 #include <asm/proto.h>
 #include <asm/dma.h>

commit 178c5682447ac0e315f0f3e27664fd4e0d2721cc
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Mar 19 11:38:21 2018 +0100

    x86/dma: Remove dma_alloc_coherent_gfp_flags()
    
    All dma_ops implementations used on x86 now take care of setting their own
    required GFP_ masks for the allocation.  And given that the common code
    now clears harmful flags itself that means we can stop the flags in all
    the IOMMU implementations as well.
    
    Tested-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Jon Mason <jdmason@kudzu.us>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Muli Ben-Yehuda <mulix@mulix.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: iommu@lists.linux-foundation.org
    Link: http://lkml.kernel.org/r/20180319103826.12853-10-hch@lst.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index db0b88ea8d1b..14437116ffea 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -82,8 +82,6 @@ bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 	if (!*dev)
 		*dev = &x86_dma_fallback_dev;
 
-	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
-
 	if (!is_device_dma_capable(*dev))
 		return false;
 	return true;

commit fec777c385b6376048fc4b08f039366545b335cd
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Mar 19 11:38:15 2018 +0100

    x86/dma: Use DMA-direct (CONFIG_DMA_DIRECT_OPS=y)
    
    The generic DMA-direct (CONFIG_DMA_DIRECT_OPS=y) implementation is now
    functionally equivalent to the x86 nommu dma_map implementation, so
    switch over to using it.
    
    That includes switching from using x86_dma_supported in various IOMMU
    drivers to use dma_direct_supported instead, which provides the same
    functionality.
    
    Tested-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Jon Mason <jdmason@kudzu.us>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Muli Ben-Yehuda <mulix@mulix.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: iommu@lists.linux-foundation.org
    Link: http://lkml.kernel.org/r/20180319103826.12853-4-hch@lst.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b59820872ec7..db0b88ea8d1b 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -18,7 +18,7 @@
 
 static int forbid_dac __read_mostly;
 
-const struct dma_map_ops *dma_ops = &nommu_dma_ops;
+const struct dma_map_ops *dma_ops = &dma_direct_ops;
 EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
@@ -76,60 +76,6 @@ void __init pci_iommu_alloc(void)
 		}
 	}
 }
-void *dma_generic_alloc_coherent(struct device *dev, size_t size,
-				 dma_addr_t *dma_addr, gfp_t flag,
-				 unsigned long attrs)
-{
-	struct page *page;
-	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
-	dma_addr_t addr;
-
-again:
-	page = NULL;
-	/* CMA can be used only in the context which permits sleeping */
-	if (gfpflags_allow_blocking(flag)) {
-		page = dma_alloc_from_contiguous(dev, count, get_order(size),
-						 flag);
-		if (page) {
-			addr = phys_to_dma(dev, page_to_phys(page));
-			if (addr + size > dev->coherent_dma_mask) {
-				dma_release_from_contiguous(dev, page, count);
-				page = NULL;
-			}
-		}
-	}
-	/* fallback */
-	if (!page)
-		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
-	if (!page)
-		return NULL;
-
-	addr = phys_to_dma(dev, page_to_phys(page));
-	if (addr + size > dev->coherent_dma_mask) {
-		__free_pages(page, get_order(size));
-
-		if (dev->coherent_dma_mask < DMA_BIT_MASK(32) &&
-		    !(flag & GFP_DMA)) {
-			flag = (flag & ~GFP_DMA32) | GFP_DMA;
-			goto again;
-		}
-
-		return NULL;
-	}
-	memset(page_address(page), 0, size);
-	*dma_addr = addr;
-	return page_address(page);
-}
-
-void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
-			       dma_addr_t dma_addr, unsigned long attrs)
-{
-	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
-	struct page *page = virt_to_page(vaddr);
-
-	if (!dma_release_from_contiguous(dev, page, count))
-		free_pages((unsigned long)vaddr, get_order(size));
-}
 
 bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 {
@@ -243,16 +189,6 @@ int arch_dma_supported(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(arch_dma_supported);
 
-int x86_dma_supported(struct device *dev, u64 mask)
-{
-	/* Copied from i386. Doesn't make much sense, because it will
-	   only work for pci_alloc_coherent.
-	   The caller just has to use GFP_DMA in this case. */
-	if (mask < DMA_BIT_MASK(24))
-		return 0;
-	return 1;
-}
-
 static int __init pci_iommu_init(void)
 {
 	struct iommu_table_entry *p;

commit 038d07a283d62336b32cc23b62aecdf9418cfc11
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Mar 19 11:38:14 2018 +0100

    x86/dma: Remove dma_alloc_coherent_mask()
    
    These days all devices (including the ISA fallback device) have a coherent
    DMA mask set, so remove the workaround.
    
    Tested-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Jon Mason <jdmason@kudzu.us>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Muli Ben-Yehuda <mulix@mulix.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: iommu@lists.linux-foundation.org
    Link: http://lkml.kernel.org/r/20180319103826.12853-3-hch@lst.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index df7ab02f959f..b59820872ec7 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -80,13 +80,10 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 dma_addr_t *dma_addr, gfp_t flag,
 				 unsigned long attrs)
 {
-	unsigned long dma_mask;
 	struct page *page;
 	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
 	dma_addr_t addr;
 
-	dma_mask = dma_alloc_coherent_mask(dev, flag);
-
 again:
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
@@ -95,7 +92,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 						 flag);
 		if (page) {
 			addr = phys_to_dma(dev, page_to_phys(page));
-			if (addr + size > dma_mask) {
+			if (addr + size > dev->coherent_dma_mask) {
 				dma_release_from_contiguous(dev, page, count);
 				page = NULL;
 			}
@@ -108,10 +105,11 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 		return NULL;
 
 	addr = phys_to_dma(dev, page_to_phys(page));
-	if (addr + size > dma_mask) {
+	if (addr + size > dev->coherent_dma_mask) {
 		__free_pages(page, get_order(size));
 
-		if (dma_mask < DMA_BIT_MASK(32) && !(flag & GFP_DMA)) {
+		if (dev->coherent_dma_mask < DMA_BIT_MASK(32) &&
+		    !(flag & GFP_DMA)) {
 			flag = (flag & ~GFP_DMA32) | GFP_DMA;
 			goto again;
 		}

commit cea9d03c822cf1b8e90cc4fc51be6d248fb5d776
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Dec 23 11:01:41 2017 +0100

    dma-mapping: add an arch_dma_supported hook
    
    To implement the x86 forbid_dac and iommu_sac_force we want an arch hook
    so that it can apply the global options across all dma_map_ops
    implementations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 61a8f1cb3829..df7ab02f959f 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -215,7 +215,7 @@ static __init int iommu_setup(char *p)
 }
 early_param("iommu", iommu_setup);
 
-int x86_dma_supported(struct device *dev, u64 mask)
+int arch_dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {
@@ -224,12 +224,6 @@ int x86_dma_supported(struct device *dev, u64 mask)
 	}
 #endif
 
-	/* Copied from i386. Doesn't make much sense, because it will
-	   only work for pci_alloc_coherent.
-	   The caller just has to use GFP_DMA in this case. */
-	if (mask < DMA_BIT_MASK(24))
-		return 0;
-
 	/* Tell the device to use SAC when IOMMU force is on.  This
 	   allows the driver to use cheaper accesses in some cases.
 
@@ -249,6 +243,17 @@ int x86_dma_supported(struct device *dev, u64 mask)
 
 	return 1;
 }
+EXPORT_SYMBOL(arch_dma_supported);
+
+int x86_dma_supported(struct device *dev, u64 mask)
+{
+	/* Copied from i386. Doesn't make much sense, because it will
+	   only work for pci_alloc_coherent.
+	   The caller just has to use GFP_DMA in this case. */
+	if (mask < DMA_BIT_MASK(24))
+		return 0;
+	return 1;
+}
 
 static int __init pci_iommu_init(void)
 {

commit 57bf5a8963f80fb3828c46c3e3a5b2dd790e09a7
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Dec 22 16:05:15 2017 +0100

    dma-mapping: clear harmful GFP_* flags in common code
    
    Lift the code from x86 so that we behave consistently.  In the future we
    should probably warn if any of these is set.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org> [m68k]

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 8439e6de6156..61a8f1cb3829 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -87,7 +87,6 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 
 	dma_mask = dma_alloc_coherent_mask(dev, flag);
 
-	flag &= ~__GFP_ZERO;
 again:
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
@@ -139,7 +138,6 @@ bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 	if (!*dev)
 		*dev = &x86_dma_fallback_dev;
 
-	*gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
 	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
 
 	if (!is_device_dma_capable(*dev))

commit ea8c64ace86647260ec4255f483e5844d62af2df
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 10 16:21:13 2018 +0100

    dma-mapping: move swiotlb arch helpers to a new header
    
    phys_to_dma, dma_to_phys and dma_capable are helpers published by
    architecture code for use of swiotlb and xen-swiotlb only.  Drivers are
    not supposed to use these directly, but use the DMA API instead.
    
    Move these to a new asm/dma-direct.h helper, included by a
    linux/dma-direct.h wrapper that provides the default linear mapping
    unless the architecture wants to override it.
    
    In the MIPS case the existing dma-coherent.h is reused for now as
    untangling it will take a bit of work.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Robin Murphy <robin.murphy@arm.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 599d7462eccc..8439e6de6156 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-#include <linux/dma-mapping.h>
+#include <linux/dma-direct.h>
 #include <linux/dma-debug.h>
 #include <linux/dmar.h>
 #include <linux/export.h>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0accc2404b92..599d7462eccc 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #include <linux/dma-mapping.h>
 #include <linux/dma-debug.h>
 #include <linux/dmar.h>

commit c7753208a94c73d5beb1e4bd843081d6dc7d4678
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:21 2017 -0500

    x86, swiotlb: Add memory encryption support
    
    Since DMA addresses will effectively look like 48-bit addresses when the
    memory encryption mask is set, SWIOTLB is needed if the DMA mask of the
    device performing the DMA does not support 48-bits. SWIOTLB will be
    initialized to create decrypted bounce buffers for use by these devices.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim KrÄmÃ¡Å <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/aa2d29b78ae7d508db8881e46a3215231b9327a7.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 5e16d3f29594..0accc2404b92 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -93,9 +93,12 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	if (gfpflags_allow_blocking(flag)) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size),
 						 flag);
-		if (page && page_to_phys(page) + size > dma_mask) {
-			dma_release_from_contiguous(dev, page, count);
-			page = NULL;
+		if (page) {
+			addr = phys_to_dma(dev, page_to_phys(page));
+			if (addr + size > dma_mask) {
+				dma_release_from_contiguous(dev, page, count);
+				page = NULL;
+			}
 		}
 	}
 	/* fallback */
@@ -104,7 +107,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	if (!page)
 		return NULL;
 
-	addr = page_to_phys(page);
+	addr = phys_to_dma(dev, page_to_phys(page));
 	if (addr + size > dma_mask) {
 		__free_pages(page, get_order(size));
 

commit 5860acc1a905b05c14e9ed9e22c20aad1a72554a
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 22 11:38:27 2017 +0200

    x86: remove arch specific dma_supported implementation
    
    And instead wire it up as method for all the dma_map_ops instances.
    
    Note that this also means the arch specific check will be fully instead
    of partially applied in the AMD iommu driver.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 3a216ec869cd..5e16d3f29594 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -213,10 +213,8 @@ static __init int iommu_setup(char *p)
 }
 early_param("iommu", iommu_setup);
 
-int dma_supported(struct device *dev, u64 mask)
+int x86_dma_supported(struct device *dev, u64 mask)
 {
-	const struct dma_map_ops *ops = get_dma_ops(dev);
-
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {
 		dev_info(dev, "PCI: Disallowing DAC for device\n");
@@ -224,9 +222,6 @@ int dma_supported(struct device *dev, u64 mask)
 	}
 #endif
 
-	if (ops->dma_supported)
-		return ops->dma_supported(dev, mask);
-
 	/* Copied from i386. Doesn't make much sense, because it will
 	   only work for pci_alloc_coherent.
 	   The caller just has to use GFP_DMA in this case. */
@@ -252,7 +247,6 @@ int dma_supported(struct device *dev, u64 mask)
 
 	return 1;
 }
-EXPORT_SYMBOL(dma_supported);
 
 static int __init pci_iommu_init(void)
 {

commit ac1820fb286b552b6885d40ab34f1e59b815f1f1
Merge: edccb5942965 0bbb3b7496ea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 25 13:45:43 2017 -0800

    Merge tag 'for-next-dma_ops' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma DMA mapping updates from Doug Ledford:
     "Drop IB DMA mapping code and use core DMA code instead.
    
      Bart Van Assche noted that the ib DMA mapping code was significantly
      similar enough to the core DMA mapping code that with a few changes it
      was possible to remove the IB DMA mapping code entirely and switch the
      RDMA stack to use the core DMA mapping code.
    
      This resulted in a nice set of cleanups, but touched the entire tree
      and has been kept separate for that reason."
    
    * tag 'for-next-dma_ops' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (37 commits)
      IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it
      IB/core: Remove ib_device.dma_device
      nvme-rdma: Switch from dma_device to dev.parent
      RDS: net: Switch from dma_device to dev.parent
      IB/srpt: Modify a debug statement
      IB/srp: Switch from dma_device to dev.parent
      IB/iser: Switch from dma_device to dev.parent
      IB/IPoIB: Switch from dma_device to dev.parent
      IB/rxe: Switch from dma_device to dev.parent
      IB/vmw_pvrdma: Switch from dma_device to dev.parent
      IB/usnic: Switch from dma_device to dev.parent
      IB/qib: Switch from dma_device to dev.parent
      IB/qedr: Switch from dma_device to dev.parent
      IB/ocrdma: Switch from dma_device to dev.parent
      IB/nes: Remove a superfluous assignment statement
      IB/mthca: Switch from dma_device to dev.parent
      IB/mlx5: Switch from dma_device to dev.parent
      IB/mlx4: Switch from dma_device to dev.parent
      IB/i40iw: Remove a superfluous assignment statement
      IB/hns: Switch from dma_device to dev.parent
      ...

commit 712c604dcdf8186295e2af694adf52c6842ad100
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Fri Feb 24 14:58:44 2017 -0800

    mm: wire up GFP flag passing in dma_alloc_from_contiguous
    
    The callers of the DMA alloc functions already provide the proper
    context GFP flags.  Make sure to pass them through to the CMA allocator,
    to make the CMA compaction context aware.
    
    Link: http://lkml.kernel.org/r/20170127172328.18574-3-l.stach@pengutronix.de
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Radim Krcmar <rkrcmar@redhat.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Alexander Graf <agraf@suse.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index d30c37750765..d5c223c9cf11 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -91,7 +91,8 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
 	if (gfpflags_allow_blocking(flag)) {
-		page = dma_alloc_from_contiguous(dev, count, get_order(size));
+		page = dma_alloc_from_contiguous(dev, count, get_order(size),
+						 flag);
 		if (page && page_to_phys(page) + size > dma_mask) {
 			dma_release_from_contiguous(dev, page, count);
 			page = NULL;

commit 5299709d0a87342dadc1fc9850484fadeb488bf8
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jan 20 13:04:01 2017 -0800

    treewide: Constify most dma_map_ops structures
    
    Most dma_map_ops structures are never modified. Constify these
    structures such that these can be write-protected. This patch
    has been generated as follows:
    
    git grep -l 'struct dma_map_ops' |
      xargs -d\\n sed -i \
        -e 's/struct dma_map_ops/const struct dma_map_ops/g' \
        -e 's/const struct dma_map_ops {/struct dma_map_ops {/g' \
        -e 's/^const struct dma_map_ops;$/struct dma_map_ops;/' \
        -e 's/const const struct dma_map_ops /const struct dma_map_ops /g';
    sed -i -e 's/const \(struct dma_map_ops intel_dma_ops\)/\1/' \
      $(git grep -l 'struct dma_map_ops intel_dma_ops');
    sed -i -e 's/const \(struct dma_map_ops dma_iommu_ops\)/\1/' \
      $(git grep -l 'struct dma_map_ops' | grep ^arch/powerpc);
    sed -i -e '/^struct vmd_dev {$/,/^};$/ s/const \(struct dma_map_ops[[:blank:]]dma_ops;\)/\1/' \
           -e '/^static void vmd_setup_dma_ops/,/^}$/ s/const \(struct dma_map_ops \*dest\)/\1/' \
           -e 's/const \(struct dma_map_ops \*dest = \&vmd->dma_ops\)/\1/' \
        drivers/pci/host/*.c
    sed -i -e '/^void __init pci_iommu_alloc(void)$/,/^}$/ s/dma_ops->/intel_dma_ops./' arch/ia64/kernel/pci-dma.c
    sed -i -e 's/static const struct dma_map_ops sn_dma_ops/static struct dma_map_ops sn_dma_ops/' arch/ia64/sn/pci/pci_dma.c
    sed -i -e 's/(const struct dma_map_ops \*)//' drivers/misc/mic/bus/vop_bus.c
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: x86@kernel.org
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index d30c37750765..76f4c039baae 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -17,7 +17,7 @@
 
 static int forbid_dac __read_mostly;
 
-struct dma_map_ops *dma_ops = &nommu_dma_ops;
+const struct dma_map_ops *dma_ops = &nommu_dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
@@ -214,7 +214,7 @@ early_param("iommu", iommu_setup);
 
 int dma_supported(struct device *dev, u64 mask)
 {
-	struct dma_map_ops *ops = get_dma_ops(dev);
+	const struct dma_map_ops *ops = get_dma_ops(dev);
 
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {

commit 00085f1efa387a8ce100e3734920f7639c80caa3
Author: Krzysztof Kozlowski <k.kozlowski@samsung.com>
Date:   Wed Aug 3 13:46:00 2016 -0700

    dma-mapping: use unsigned long for dma_attrs
    
    The dma-mapping core and the implementations do not change the DMA
    attributes passed by pointer.  Thus the pointer can point to const data.
    However the attributes do not have to be a bitfield.  Instead unsigned
    long will do fine:
    
    1. This is just simpler.  Both in terms of reading the code and setting
       attributes.  Instead of initializing local attributes on the stack
       and passing pointer to it to dma_set_attr(), just set the bits.
    
    2. It brings safeness and checking for const correctness because the
       attributes are passed by value.
    
    Semantic patches for this change (at least most of them):
    
        virtual patch
        virtual context
    
        @r@
        identifier f, attrs;
    
        @@
        f(...,
        - struct dma_attrs *attrs
        + unsigned long attrs
        , ...)
        {
        ...
        }
    
        @@
        identifier r.f;
        @@
        f(...,
        - NULL
        + 0
         )
    
    and
    
        // Options: --all-includes
        virtual patch
        virtual context
    
        @r@
        identifier f, attrs;
        type t;
    
        @@
        t f(..., struct dma_attrs *attrs);
    
        @@
        identifier r.f;
        @@
        f(...,
        - NULL
        + 0
         )
    
    Link: http://lkml.kernel.org/r/1468399300-5399-2-git-send-email-k.kozlowski@samsung.com
    Signed-off-by: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Acked-by: Robin Murphy <robin.murphy@arm.com>
    Acked-by: Hans-Christian Noren Egtvedt <egtvedt@samfundet.no>
    Acked-by: Mark Salter <msalter@redhat.com> [c6x]
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com> [cris]
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch> [drm]
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Acked-by: Joerg Roedel <jroedel@suse.de> [iommu]
    Acked-by: Fabien Dessenne <fabien.dessenne@st.com> [bdisp]
    Reviewed-by: Marek Szyprowski <m.szyprowski@samsung.com> [vb2-core]
    Acked-by: David Vrabel <david.vrabel@citrix.com> [xen]
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com> [xen swiotlb]
    Acked-by: Joerg Roedel <jroedel@suse.de> [iommu]
    Acked-by: Richard Kuo <rkuo@codeaurora.org> [hexagon]
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org> [m68k]
    Acked-by: Gerald Schaefer <gerald.schaefer@de.ibm.com> [s390]
    Acked-by: Bjorn Andersson <bjorn.andersson@linaro.org>
    Acked-by: Hans-Christian Noren Egtvedt <egtvedt@samfundet.no> [avr32]
    Acked-by: Vineet Gupta <vgupta@synopsys.com> [arc]
    Acked-by: Robin Murphy <robin.murphy@arm.com> [arm64 and dma-iommu]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 6ba014c61d62..d30c37750765 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -77,7 +77,7 @@ void __init pci_iommu_alloc(void)
 }
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 dma_addr_t *dma_addr, gfp_t flag,
-				 struct dma_attrs *attrs)
+				 unsigned long attrs)
 {
 	unsigned long dma_mask;
 	struct page *page;
@@ -120,7 +120,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 }
 
 void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
-			       dma_addr_t dma_addr, struct dma_attrs *attrs)
+			       dma_addr_t dma_addr, unsigned long attrs)
 {
 	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
 	struct page *page = virt_to_page(vaddr);

commit d0164adc89f6bb374d304ffcc375c6d2652fe67d
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 6 16:28:21 2015 -0800

    mm, page_alloc: distinguish between being unable to sleep, unwilling to sleep and avoiding waking kswapd
    
    __GFP_WAIT has been used to identify atomic context in callers that hold
    spinlocks or are in interrupts.  They are expected to be high priority and
    have access one of two watermarks lower than "min" which can be referred
    to as the "atomic reserve".  __GFP_HIGH users get access to the first
    lower watermark and can be called the "high priority reserve".
    
    Over time, callers had a requirement to not block when fallback options
    were available.  Some have abused __GFP_WAIT leading to a situation where
    an optimisitic allocation with a fallback option can access atomic
    reserves.
    
    This patch uses __GFP_ATOMIC to identify callers that are truely atomic,
    cannot sleep and have no alternative.  High priority users continue to use
    __GFP_HIGH.  __GFP_DIRECT_RECLAIM identifies callers that can sleep and
    are willing to enter direct reclaim.  __GFP_KSWAPD_RECLAIM to identify
    callers that want to wake kswapd for background reclaim.  __GFP_WAIT is
    redefined as a caller that is willing to enter direct reclaim and wake
    kswapd for background reclaim.
    
    This patch then converts a number of sites
    
    o __GFP_ATOMIC is used by callers that are high priority and have memory
      pools for those requests. GFP_ATOMIC uses this flag.
    
    o Callers that have a limited mempool to guarantee forward progress clear
      __GFP_DIRECT_RECLAIM but keep __GFP_KSWAPD_RECLAIM. bio allocations fall
      into this category where kswapd will still be woken but atomic reserves
      are not used as there is a one-entry mempool to guarantee progress.
    
    o Callers that are checking if they are non-blocking should use the
      helper gfpflags_allow_blocking() where possible. This is because
      checking for __GFP_WAIT as was done historically now can trigger false
      positives. Some exceptions like dm-crypt.c exist where the code intent
      is clearer if __GFP_DIRECT_RECLAIM is used instead of the helper due to
      flag manipulations.
    
    o Callers that built their own GFP flags instead of starting with GFP_KERNEL
      and friends now also need to specify __GFP_KSWAPD_RECLAIM.
    
    The first key hazard to watch out for is callers that removed __GFP_WAIT
    and was depending on access to atomic reserves for inconspicuous reasons.
    In some cases it may be appropriate for them to use __GFP_HIGH.
    
    The second key hazard is callers that assembled their own combination of
    GFP flags instead of starting with something like GFP_KERNEL.  They may
    now wish to specify __GFP_KSWAPD_RECLAIM.  It's almost certainly harmless
    if it's missed in most cases as other activity will wake kswapd.
    
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Vitaly Wool <vitalywool@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index cd99433b8ba1..6ba014c61d62 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -90,7 +90,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 again:
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
-	if (flag & __GFP_WAIT) {
+	if (gfpflags_allow_blocking(flag)) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
 		if (page && page_to_phys(page) + size > dma_mask) {
 			dma_release_from_contiguous(dev, page, count);

commit 298a96c12b2d8fd845ae0c2c21c0a1c0b470f99e
Author: Ville SyrjÃ¤lÃ¤ <ville.syrjala@linux.intel.com>
Date:   Sun Oct 25 23:11:43 2015 +0200

    x86/dma-mapping: Fix arch_dma_alloc_attrs() oops with NULL dev
    
    Commit 6894258eda2f broke drivers that pass NULL as the device pointer
    to dma_alloc. The reason is that arch_dma_alloc_attrs() now calls
    dma_alloc_coherent_gfp_flags() which in turn calls
    dma_alloc_coherent_mask(), where the device pointer is dereferenced
    unconditionally.
    
    Fix things by moving the ISA DMA fallback device assignment before the
    call to dma_alloc_coherent_gfp_flags().
    
    Fixes: 6894258eda2f ("dma-mapping: consolidate dma_{alloc,free}_{attrs,coherent}")
    Reported-and-tested-by: Meelis Roos <mroos@linux.ee>
    Signed-off-by: Ville SyrjÃ¤lÃ¤ <ville.syrjala@linux.intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/1445807503-8920-1-git-send-email-ville.syrjala@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1b55de1267cf..cd99433b8ba1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -131,11 +131,12 @@ void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
 
 bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 {
+	if (!*dev)
+		*dev = &x86_dma_fallback_dev;
+
 	*gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
 	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
 
-	if (!*dev)
-		*dev = &x86_dma_fallback_dev;
 	if (!is_device_dma_capable(*dev))
 		return false;
 	return true;

commit 590f07874e8e3c83729b919312c65aea2533c8cf
Author: Junichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Mon Sep 14 07:38:36 2015 +0000

    x86/pci/dma: Fix gfp flags for coherent DMA memory allocation
    
    Commit 6894258eda2f reversed the order of gfp_flags adjustment in
    dma_alloc_attrs() for x86 [arch/x86/kernel/pci-dma.c] As a result,
    relevant flags set by dma_alloc_coherent_gfp_flags() are just
    discarded and cause coherent DMA memory allocation failure on some
    devices.
    
    Fixes: 6894258eda2f ("dma-mapping: consolidate dma_{alloc,free}_{attrs,coherent}")
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20150914073834.GA13077@xzibit.linux.bs1.fc.nec.co.jp
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 84b8ef82a159..1b55de1267cf 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -131,8 +131,8 @@ void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
 
 bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 {
-	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
 	*gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
+	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
 
 	if (!*dev)
 		*dev = &x86_dma_fallback_dev;

commit 452e06af1f0149b01201f94264d452cd7a95db7a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Sep 9 15:39:53 2015 -0700

    dma-mapping: consolidate dma_set_mask
    
    Almost everyone implements dma_set_mask the same way, although some time
    that's hidden in ->set_dma_mask methods.
    
    This patch consolidates those into a common implementation that either
    calls ->set_dma_mask if present or otherwise uses the default
    implementation.  Some architectures used to only call ->set_dma_mask
    after the initial checks, and those instance have been fixed to do the
    full work.  h8300 implemented dma_set_mask bogusly as a no-ops and has
    been fixed.
    
    Unfortunately some architectures overload unrelated semantics like changing
    the dma_ops into it so we still need to allow for an architecture override
    for now.
    
    [jcmvbkbc@gmail.com: fix xtensa]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
    Signed-off-by: Max Filippov <jcmvbkbc@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index bd23971e8f1d..84b8ef82a159 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -58,17 +58,6 @@ EXPORT_SYMBOL(x86_dma_fallback_dev);
 /* Number of entries preallocated for DMA-API debugging */
 #define PREALLOC_DMA_DEBUG_ENTRIES       65536
 
-int dma_set_mask(struct device *dev, u64 mask)
-{
-	if (!dev->dma_mask || !dma_supported(dev, mask))
-		return -EIO;
-
-	*dev->dma_mask = mask;
-
-	return 0;
-}
-EXPORT_SYMBOL(dma_set_mask);
-
 void __init pci_iommu_alloc(void)
 {
 	struct iommu_table_entry *p;

commit 6894258eda2f9badc28c878086c0e54bd5b7fb30
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Sep 9 15:39:39 2015 -0700

    dma-mapping: consolidate dma_{alloc,free}_{attrs,coherent}
    
    Since 2009 we have a nice asm-generic header implementing lots of DMA API
    functions for architectures using struct dma_map_ops, but unfortunately
    it's still missing a lot of APIs that all architectures still have to
    duplicate.
    
    This series consolidates the remaining functions, although we still need
    arch opt outs for two of them as a few architectures have very
    non-standard implementations.
    
    This patch (of 5):
    
    The coherent DMA allocator works the same over all architectures supporting
    dma_map operations.
    
    This patch consolidates them and converges the minor differences:
    
     - the debug_dma helpers are now called from all architectures, including
       those that were previously missing them
     - dma_alloc_from_coherent and dma_release_from_coherent are now always
       called from the generic alloc/free routines instead of the ops
       dma-mapping-common.h always includes dma-coherent.h to get the defintions
       for them, or the stubs if the architecture doesn't support this feature
     - checks for ->alloc / ->free presence are removed.  There is only one
       magic instead of dma_map_ops without them (mic_dma_ops) and that one
       is x86 only anyway.
    
    Besides that only x86 needs special treatment to replace a default devices
    if none is passed and tweak the gfp_flags.  An optional arch hook is provided
    for that.
    
    [linux@roeck-us.net: fix build]
    [jcmvbkbc@gmail.com: fix xtensa]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Max Filippov <jcmvbkbc@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 353972c1946c..bd23971e8f1d 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -140,50 +140,19 @@ void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
 		free_pages((unsigned long)vaddr, get_order(size));
 }
 
-void *dma_alloc_attrs(struct device *dev, size_t size, dma_addr_t *dma_handle,
-		      gfp_t gfp, struct dma_attrs *attrs)
+bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 {
-	struct dma_map_ops *ops = get_dma_ops(dev);
-	void *memory;
-
-	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
-
-	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
-		return memory;
-
-	if (!dev)
-		dev = &x86_dma_fallback_dev;
-
-	if (!is_device_dma_capable(dev))
-		return NULL;
-
-	if (!ops->alloc)
-		return NULL;
-
-	memory = ops->alloc(dev, size, dma_handle,
-			    dma_alloc_coherent_gfp_flags(dev, gfp), attrs);
-	debug_dma_alloc_coherent(dev, size, *dma_handle, memory);
-
-	return memory;
-}
-EXPORT_SYMBOL(dma_alloc_attrs);
-
-void dma_free_attrs(struct device *dev, size_t size,
-		    void *vaddr, dma_addr_t bus,
-		    struct dma_attrs *attrs)
-{
-	struct dma_map_ops *ops = get_dma_ops(dev);
-
-	WARN_ON(irqs_disabled());       /* for portability */
+	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
+	*gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
 
-	if (dma_release_from_coherent(dev, get_order(size), vaddr))
-		return;
+	if (!*dev)
+		*dev = &x86_dma_fallback_dev;
+	if (!is_device_dma_capable(*dev))
+		return false;
+	return true;
 
-	debug_dma_free_coherent(dev, size, vaddr, bus);
-	if (ops->free)
-		ops->free(dev, size, vaddr, bus, attrs);
 }
-EXPORT_SYMBOL(dma_free_attrs);
+EXPORT_SYMBOL(arch_dma_alloc_attrs);
 
 /*
  * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel

commit f1dc154f82595386cddcc7b980d8760474c3dd2d
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Mon Apr 13 13:54:33 2015 +0200

    x86: Deinline dma_free_attrs()
    
    Reduces kernel size by 76720 bytes on allyesconfig build:
    
        text     data      bss       dec     hex filename
    82594029 22255352 20627456 125476837 77a9fe5 vmlinux1
    82517277 22255384 20627456 125400117 7797435 vmlinux2
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Don Dutile <ddutile@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1428926075-28796-3-git-send-email-dvlasenk@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f9f7656e1d41..353972c1946c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -168,6 +168,23 @@ void *dma_alloc_attrs(struct device *dev, size_t size, dma_addr_t *dma_handle,
 }
 EXPORT_SYMBOL(dma_alloc_attrs);
 
+void dma_free_attrs(struct device *dev, size_t size,
+		    void *vaddr, dma_addr_t bus,
+		    struct dma_attrs *attrs)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+
+	WARN_ON(irqs_disabled());       /* for portability */
+
+	if (dma_release_from_coherent(dev, get_order(size), vaddr))
+		return;
+
+	debug_dma_free_coherent(dev, size, vaddr, bus);
+	if (ops->free)
+		ops->free(dev, size, vaddr, bus, attrs);
+}
+EXPORT_SYMBOL(dma_free_attrs);
+
 /*
  * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
  * parameter documentation.

commit 0c7965ff22472f60d5cf07308cb59f3a118feb8a
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Mon Apr 13 13:54:32 2015 +0200

    x86: Deinline dma_alloc_attrs()
    
    Reduces kernel size by 68739 bytes on allyesconfig build:
    
        text     data      bss       dec     hex filename
    82662736 22255384 20627456 125545576 77bac68 vmlinux0
    82594029 22255352 20627456 125476837 77a9fe5 vmlinux1
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Don Dutile <ddutile@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1428926075-28796-2-git-send-email-dvlasenk@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index a25e202bb319..f9f7656e1d41 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -140,6 +140,34 @@ void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
 		free_pages((unsigned long)vaddr, get_order(size));
 }
 
+void *dma_alloc_attrs(struct device *dev, size_t size, dma_addr_t *dma_handle,
+		      gfp_t gfp, struct dma_attrs *attrs)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+	void *memory;
+
+	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
+
+	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
+		return memory;
+
+	if (!dev)
+		dev = &x86_dma_fallback_dev;
+
+	if (!is_device_dma_capable(dev))
+		return NULL;
+
+	if (!ops->alloc)
+		return NULL;
+
+	memory = ops->alloc(dev, size, dma_handle,
+			    dma_alloc_coherent_gfp_flags(dev, gfp), attrs);
+	debug_dma_alloc_coherent(dev, size, *dma_handle, memory);
+
+	return memory;
+}
+EXPORT_SYMBOL(dma_alloc_attrs);
+
 /*
  * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
  * parameter documentation.

commit 38f7ea5a082bbde9e64b7ece389f20e71a9806f4
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Jun 4 16:06:56 2014 -0700

    arch/x86/kernel/pci-dma.c: fix dma_generic_alloc_coherent() when CONFIG_DMA_CMA is enabled
    
    dma_generic_alloc_coherent() firstly attempts to allocate by
    dma_alloc_from_contiguous() if CONFIG_DMA_CMA is enabled.  But the
    memory region allocated by it may not fit within the device's DMA mask.
    This change makes it fall back to usual alloc_pages_node() allocation
    for such cases.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Don Dutile <ddutile@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index e5f4e9629e61..a25e202bb319 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -101,8 +101,13 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 again:
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
-	if (flag & __GFP_WAIT)
+	if (flag & __GFP_WAIT) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
+		if (page && page_to_phys(page) + size > dma_mask) {
+			dma_release_from_contiguous(dev, page, count);
+			page = NULL;
+		}
+	}
 	/* fallback */
 	if (!page)
 		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));

commit d92ef66c4f8fdf7a24736b1ab6c48d32de9bfc07
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Wed Jun 4 16:06:48 2014 -0700

    x86: make dma_alloc_coherent() return zeroed memory if CMA is enabled
    
    This patchset enhances the DMA Contiguous Memory Allocator on x86.
    
    Currently the DMA CMA is only supported with pci-nommu dma_map_ops and
    furthermore it can't be enabled on x86_64.  But I would like to allocate
    big contiguous memory with dma_alloc_coherent() and tell it to the device
    that requires it, regardless of which dma mapping implementation is
    actually used in the system.
    
    So this makes it work with swiotlb and intel-iommu dma_map_ops, too.  And
    this also extends "cma=" kernel parameter to specify placement constraint
    by the physical address range of memory allocations.  For example, CMA
    allocates memory below 4GB by "cma=64M@0-4G", it is required for the
    devices only supporting 32-bit addressing on 64-bit systems without iommu.
    
    This patch (of 5):
    
    Calling dma_alloc_coherent() with __GFP_ZERO must return zeroed memory.
    
    But when the contiguous memory allocator (CMA) is enabled on x86 and the
    memory region is allocated by dma_alloc_from_contiguous(), it doesn't
    return zeroed memory.  Because dma_generic_alloc_coherent() forgot to fill
    the memory region with zero if it was allocated by
    dma_alloc_from_contiguous()
    
    Most implementations of dma_alloc_coherent() return zeroed memory
    regardless of whether __GFP_ZERO is specified.  So this fixes it by
    unconditionally zeroing the allocated memory region.
    
    Alternatively, we could fix dma_alloc_from_contiguous() to return zeroed
    out memory and remove memset() from all caller of it.  But we can't simply
    remove the memset on arm because __dma_clear_buffer() is used there for
    ensuring cache flushing and it is used in many places.  Of course we can
    do redundant memset in dma_alloc_from_contiguous(), but I think this patch
    is less impact for fixing this problem.
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Don Dutile <ddutile@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f7d0672481fd..e5f4e9629e61 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -97,7 +97,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 
 	dma_mask = dma_alloc_coherent_mask(dev, flag);
 
-	flag |= __GFP_ZERO;
+	flag &= ~__GFP_ZERO;
 again:
 	page = NULL;
 	/* CMA can be used only in the context which permits sleeping */
@@ -120,7 +120,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 
 		return NULL;
 	}
-
+	memset(page_address(page), 0, size);
 	*dma_addr = addr;
 	return page_address(page);
 }

commit c091c71ad2218fc50a07b3d1dab85783f3b77efd
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Fri Jan 24 14:49:58 2014 +0100

    x86: dma-mapping: fix GFP_ATOMIC macro usage
    
    GFP_ATOMIC is not a single gfp flag, but a macro which expands to the other
    flags, where meaningful is the LACK of __GFP_WAIT flag. To check if caller
    wants to perform an atomic allocation, the code must test for a lack of the
    __GFP_WAIT flag. This patch fixes the issue introduced in v3.5-rc1.
    
    CC: stable@vger.kernel.org
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 872079a67e4d..f7d0672481fd 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -100,8 +100,10 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	flag |= __GFP_ZERO;
 again:
 	page = NULL;
-	if (!(flag & GFP_ATOMIC))
+	/* CMA can be used only in the context which permits sleeping */
+	if (flag & __GFP_WAIT)
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
+	/* fallback */
 	if (!page)
 		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
 	if (!page)

commit 73b664ceb5f815c38def1c68912b83f83455e9eb
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Fri Nov 16 11:17:14 2012 +0100

    x86/dma-debug: Bump PREALLOC_DMA_DEBUG_ENTRIES
    
    I ran out of free entries when I had CONFIG_DMA_API_DEBUG
    enabled. Some other archs seem to default to 65536, so increase
    this limit for x86 too.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/50A612AA.7040206@canonical.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    ----

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0f5dec5c80e0..872079a67e4d 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -56,7 +56,7 @@ struct device x86_dma_fallback_dev = {
 EXPORT_SYMBOL(x86_dma_fallback_dev);
 
 /* Number of entries preallocated for DMA-API debugging */
-#define PREALLOC_DMA_DEBUG_ENTRIES       32768
+#define PREALLOC_DMA_DEBUG_ENTRIES       65536
 
 int dma_set_mask(struct device *dev, u64 mask)
 {

commit a18e3690a52790a034d6540d54e8e1f1cd125da2
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Dec 21 14:02:53 2012 -0800

    X86: drivers: remove __dev* attributes.
    
    CONFIG_HOTPLUG is going away as an option.  As a result, the __dev*
    markings need to be removed.
    
    This change removes the use of __devinit, __devexit_p, __devinitconst,
    and __devexit from these drivers.
    
    Based on patches originally written by Bill Pemberton, but redone by me
    in order to handle some of the coding style issues better, by hand.
    
    Cc: Bill Pemberton <wfp5p@virginia.edu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Drake <dsd@laptop.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index de2b7ad70273..0f5dec5c80e0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -265,7 +265,7 @@ rootfs_initcall(pci_iommu_init);
 #ifdef CONFIG_PCI
 /* Many VIA bridges seem to corrupt data for DAC. Disable it here */
 
-static __devinit void via_no_dac(struct pci_dev *dev)
+static void via_no_dac(struct pci_dev *dev)
 {
 	if (forbid_dac == 0) {
 		dev_info(&dev->dev, "disabling DAC on VIA PCI bridge\n");

commit 7d43c2e42cb1e436f97c1763150e4e1122ae0d57
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed May 30 14:19:55 2012 -0600

    iommu: Remove group_mf
    
    The iommu=group_mf is really no longer needed with the addition of ACS
    support in IOMMU drivers creating groups.  Most multifunction devices
    will now be grouped already.  If a device has gone to the trouble of
    exposing ACS, trust that it works.  We can use the device specific ACS
    function for fixing devices we trust individually.  This largely
    reverts bcb71abe.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index c0f420f76cd3..de2b7ad70273 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -45,15 +45,6 @@ int iommu_detected __read_mostly = 0;
  */
 int iommu_pass_through __read_mostly;
 
-/*
- * Group multi-function PCI devices into a single device-group for the
- * iommu_device_group interface.  This tells the iommu driver to pretend
- * it cannot distinguish between functions of a device, exposing only one
- * group for the device.  Useful for disallowing use of individual PCI
- * functions from userspace drivers.
- */
-int iommu_group_mf __read_mostly;
-
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
 /* Dummy device used for NULL arguments (normally ISA). */
@@ -194,8 +185,6 @@ static __init int iommu_setup(char *p)
 #endif
 		if (!strncmp(p, "pt", 2))
 			iommu_pass_through = 1;
-		if (!strncmp(p, "group_mf", 8))
-			iommu_group_mf = 1;
 
 		gart_parse_options(p);
 

commit c080e26edc3a2a3cdfa4c430c663ee1c3bbd8fae
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Thu Jun 14 14:01:30 2012 +0200

    x86: dma-mapping: fix broken allocation when dma_mask has been provided
    
    Commit 0a2b9a6ea93 ("X86: integrate CMA with DMA-mapping subsystem")
    broke memory allocation with dma_mask. This patch fixes possible kernel
    ops caused by lack of resetting page variable when jumping to 'again' label.
    
    Reported-by: Konrad Rzeszutek Wilk <konrad@darnok.org>
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Michal Nazarewicz <mina86@mina86.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 62c9457ccd2f..c0f420f76cd3 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -100,7 +100,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 struct dma_attrs *attrs)
 {
 	unsigned long dma_mask;
-	struct page *page = NULL;
+	struct page *page;
 	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
 	dma_addr_t addr;
 
@@ -108,6 +108,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 
 	flag |= __GFP_ZERO;
 again:
+	page = NULL;
 	if (!(flag & GFP_ATOMIC))
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
 	if (!page)

commit 0a2b9a6ea93650b8a00f9fd5ee8fdd25671e2df6
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Thu Dec 29 13:09:51 2011 +0100

    X86: integrate CMA with DMA-mapping subsystem
    
    This patch adds support for CMA to dma-mapping subsystem for x86
    architecture that uses common pci-dma/pci-nommu implementation. This
    allows to test CMA on KVM/QEMU and a lot of common x86 boxes.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    CC: Michal Nazarewicz <mina86@mina86.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 3003250ac51d..62c9457ccd2f 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -100,14 +100,18 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 struct dma_attrs *attrs)
 {
 	unsigned long dma_mask;
-	struct page *page;
+	struct page *page = NULL;
+	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
 	dma_addr_t addr;
 
 	dma_mask = dma_alloc_coherent_mask(dev, flag);
 
 	flag |= __GFP_ZERO;
 again:
-	page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
+	if (!(flag & GFP_ATOMIC))
+		page = dma_alloc_from_contiguous(dev, count, get_order(size));
+	if (!page)
+		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
 	if (!page)
 		return NULL;
 
@@ -127,6 +131,16 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	return page_address(page);
 }
 
+void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
+			       dma_addr_t dma_addr, struct dma_attrs *attrs)
+{
+	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
+	struct page *page = virt_to_page(vaddr);
+
+	if (!dma_release_from_contiguous(dev, page, count))
+		free_pages((unsigned long)vaddr, get_order(size));
+}
+
 /*
  * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
  * parameter documentation.

commit 58bca4a8fa90fcf9069379653b396b2cec642f7f
Merge: 64ebe9873118 64d70fe5d364
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 4 17:13:43 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping
    
    Pull DMA mapping branch from Marek Szyprowski:
     "Short summary for the whole series:
    
      A few limitations have been identified in the current dma-mapping
      design and its implementations for various architectures.  There exist
      more than one function for allocating and freeing the buffers:
      currently these 3 are used dma_{alloc, free}_coherent,
      dma_{alloc,free}_writecombine, dma_{alloc,free}_noncoherent.
    
      For most of the systems these calls are almost equivalent and can be
      interchanged.  For others, especially the truly non-coherent ones
      (like ARM), the difference can be easily noticed in overall driver
      performance.  Sadly not all architectures provide implementations for
      all of them, so the drivers might need to be adapted and cannot be
      easily shared between different architectures.  The provided patches
      unify all these functions and hide the differences under the already
      existing dma attributes concept.  The thread with more references is
      available here:
    
        http://www.spinics.net/lists/linux-sh/msg09777.html
    
      These patches are also a prerequisite for unifying DMA-mapping
      implementation on ARM architecture with the common one provided by
      dma_map_ops structure and extending it with IOMMU support.  More
      information is available in the following thread:
    
        http://thread.gmane.org/gmane.linux.kernel.cross-arch/12819
    
      More works on dma-mapping framework are planned, especially in the
      area of buffer sharing and managing the shared mappings (together with
      the recently introduced dma_buf interface: commit d15bd7ee445d
      "dma-buf: Introduce dma buffer sharing mechanism").
    
      The patches in the current set introduce a new alloc/free methods
      (with support for memory attributes) in dma_map_ops structure, which
      will later replace dma_alloc_coherent and dma_alloc_writecombine
      functions."
    
    People finally started piping up with support for merging this, so I'm
    merging it as the last of the pending stuff from the merge window.
    Looks like pohmelfs is going to wait for 3.5 and more external support
    for merging.
    
    * 'for-linus' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping:
      common: DMA-mapping: add NON-CONSISTENT attribute
      common: DMA-mapping: add WRITE_COMBINE attribute
      common: dma-mapping: introduce mmap method
      common: dma-mapping: remove old alloc_coherent and free_coherent methods
      Hexagon: adapt for dma_map_ops changes
      Unicore32: adapt for dma_map_ops changes
      Microblaze: adapt for dma_map_ops changes
      SH: adapt for dma_map_ops changes
      Alpha: adapt for dma_map_ops changes
      SPARC: adapt for dma_map_ops changes
      PowerPC: adapt for dma_map_ops changes
      MIPS: adapt for dma_map_ops changes
      X86 & IA64: adapt for dma_map_ops changes
      common: dma-mapping: introduce generic alloc() and free() methods

commit baa676fcf8d555269bd0a5a2496782beee55824d
Author: Andrzej Pietrasiewicz <andrzej.p@samsung.com>
Date:   Tue Mar 27 14:28:18 2012 +0200

    X86 & IA64: adapt for dma_map_ops changes
    
    Adapt core x86 and IA64 architecture code for dma_map_ops changes: replace
    alloc/free_coherent with generic alloc/free methods.
    
    Signed-off-by: Andrzej Pietrasiewicz <andrzej.p@samsung.com>
    Acked-by: Kyungmin Park <kyungmin.park@samsung.com>
    [removed swiotlb related changes and replaced it with wrappers,
     merged with IA64 patch to avoid inter-patch dependences in intel-iommu code]
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1c4d769e21ea..75e1cc19e630 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -96,7 +96,8 @@ void __init pci_iommu_alloc(void)
 	}
 }
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,
-				 dma_addr_t *dma_addr, gfp_t flag)
+				 dma_addr_t *dma_addr, gfp_t flag,
+				 struct dma_attrs *attrs)
 {
 	unsigned long dma_mask;
 	struct page *page;

commit c484b2418b0b5bb7b16f01343330650faee60df2
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Feb 23 23:46:50 2012 -0800

    PCI: Use class for quirk for via_no_dac
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1c4d769e21ea..28e5e06fcba4 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -262,10 +262,11 @@ rootfs_initcall(pci_iommu_init);
 
 static __devinit void via_no_dac(struct pci_dev *dev)
 {
-	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
+	if (forbid_dac == 0) {
 		dev_info(&dev->dev, "disabling DAC on VIA PCI bridge\n");
 		forbid_dac = 1;
 	}
 }
-DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID, via_no_dac);
+DECLARE_PCI_FIXUP_CLASS_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID,
+				PCI_CLASS_BRIDGE_PCI, 8, via_no_dac);
 #endif

commit bcb71abe7d4c5a0d0368c67da0a7def4fc73497a
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Oct 21 15:56:24 2011 -0400

    iommu: Add option to group multi-function devices
    
    The option iommu=group_mf indicates the that the iommu driver should
    expose all functions of a multi-function PCI device as the same
    iommu_device_group.  This is useful for disallowing individual functions
    being exposed as independent devices to userspace as there are often
    hidden dependencies.  Virtual functions are not affected by this option.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 80dc793b3f63..1c4d769e21ea 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -45,6 +45,15 @@ int iommu_detected __read_mostly = 0;
  */
 int iommu_pass_through __read_mostly;
 
+/*
+ * Group multi-function PCI devices into a single device-group for the
+ * iommu_device_group interface.  This tells the iommu driver to pretend
+ * it cannot distinguish between functions of a device, exposing only one
+ * group for the device.  Useful for disallowing use of individual PCI
+ * functions from userspace drivers.
+ */
+int iommu_group_mf __read_mostly;
+
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
 /* Dummy device used for NULL arguments (normally ISA). */
@@ -169,6 +178,8 @@ static __init int iommu_setup(char *p)
 #endif
 		if (!strncmp(p, "pt", 2))
 			iommu_pass_through = 1;
+		if (!strncmp(p, "group_mf", 8))
+			iommu_group_mf = 1;
 
 		gart_parse_options(p);
 

commit 69c60c88eeb364ebf58432f9bc38033522d58767
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu May 26 12:22:53 2011 -0400

    x86: Fix files explicitly requiring export.h for EXPORT_SYMBOL/THIS_MODULE
    
    These files were implicitly getting EXPORT_SYMBOL via device.h
    which was including module.h, but that will be fixed up shortly.
    
    By fixing these now, we can avoid seeing things like:
    
    arch/x86/kernel/rtc.c:29: warning: type defaults to âintâ in declaration of âEXPORT_SYMBOLâ
    arch/x86/kernel/pci-dma.c:20: warning: type defaults to âintâ in declaration of âEXPORT_SYMBOLâ
    arch/x86/kernel/e820.c:69: warning: type defaults to âintâ in declaration of âEXPORT_SYMBOL_GPLâ
    
    [ with input from Randy Dunlap <rdunlap@xenotime.net> and also
      from Stephen Rothwell <sfr@canb.auug.org.au> ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 622872054fbe..80dc793b3f63 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,6 +1,7 @@
 #include <linux/dma-mapping.h>
 #include <linux/dma-debug.h>
 #include <linux/dmar.h>
+#include <linux/export.h>
 #include <linux/bootmem.h>
 #include <linux/gfp.h>
 #include <linux/pci.h>

commit 395cf9691d72173d8cdaa613c5f0255f993af94b
Author: Paul Bolle <pebolle@tiscali.nl>
Date:   Mon Aug 15 02:02:26 2011 +0200

    doc: fix broken references
    
    There are numerous broken references to Documentation files (in other
    Documentation files, in comments, etc.). These broken references are
    caused by typo's in the references, and by renames or removals of the
    Documentation files. Some broken references are simply odd.
    
    Fix these broken references, sometimes by dropping the irrelevant text
    they were part of.
    
    Signed-off-by: Paul Bolle <pebolle@tiscali.nl>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b49d00da2aed..622872054fbe 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -117,8 +117,8 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 }
 
 /*
- * See <Documentation/x86_64/boot-options.txt> for the iommu kernel parameter
- * documentation.
+ * See <Documentation/x86/x86_64/boot-options.txt> for the iommu kernel
+ * parameter documentation.
  */
 static __init int iommu_setup(char *p)
 {

commit 5491ff511d31ed06e9572f1e84e3494be66b6e8c
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Apr 12 10:20:48 2011 -0700

    x86/PCI: Remove dma32_reserve_bootmem
    
    This workaround holds a dma32 buffer at early boot to prevent later
    bootmem allocations from stealing it in the case of large RAM configs.
    
    Now that x86 is using memblock, and the nobootmem wrapper does top-down
    allocation, it's no longer necessary, so remove it.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 9ea999a4dcc1..b49d00da2aed 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -68,74 +68,10 @@ int dma_set_mask(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_set_mask);
 
-#if defined(CONFIG_X86_64) && !defined(CONFIG_NUMA)
-static __initdata void *dma32_bootmem_ptr;
-static unsigned long dma32_bootmem_size __initdata = (128ULL<<20);
-
-static int __init parse_dma32_size_opt(char *p)
-{
-	if (!p)
-		return -EINVAL;
-	dma32_bootmem_size = memparse(p, &p);
-	return 0;
-}
-early_param("dma32_size", parse_dma32_size_opt);
-
-void __init dma32_reserve_bootmem(void)
-{
-	unsigned long size, align;
-	if (max_pfn <= MAX_DMA32_PFN)
-		return;
-
-	/*
-	 * check aperture_64.c allocate_aperture() for reason about
-	 * using 512M as goal
-	 */
-	align = 64ULL<<20;
-	size = roundup(dma32_bootmem_size, align);
-	dma32_bootmem_ptr = __alloc_bootmem_nopanic(size, align,
-				 512ULL<<20);
-	/*
-	 * Kmemleak should not scan this block as it may not be mapped via the
-	 * kernel direct mapping.
-	 */
-	kmemleak_ignore(dma32_bootmem_ptr);
-	if (dma32_bootmem_ptr)
-		dma32_bootmem_size = size;
-	else
-		dma32_bootmem_size = 0;
-}
-static void __init dma32_free_bootmem(void)
-{
-
-	if (max_pfn <= MAX_DMA32_PFN)
-		return;
-
-	if (!dma32_bootmem_ptr)
-		return;
-
-	free_bootmem(__pa(dma32_bootmem_ptr), dma32_bootmem_size);
-
-	dma32_bootmem_ptr = NULL;
-	dma32_bootmem_size = 0;
-}
-#else
-void __init dma32_reserve_bootmem(void)
-{
-}
-static void __init dma32_free_bootmem(void)
-{
-}
-
-#endif
-
 void __init pci_iommu_alloc(void)
 {
 	struct iommu_table_entry *p;
 
-	/* free the range so iommu could get some range less than 4G */
-	dma32_free_bootmem();
-
 	sort_iommu_table(__iommu_table, __iommu_table_end);
 	check_iommu_entries(__iommu_table, __iommu_table_end);
 

commit ee1f284f38c8dfcbc7b656915a039dde016de7d3
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Thu Aug 26 13:58:05 2010 -0400

    x86, iommu: Utilize the IOMMU_INIT macros functionality.
    
    We remove all of the sub-platform detection/init routines and instead
    use on the .iommu_table array of structs to call the .early_init if
    .detect returned a positive value. Also we can stop detecting other
    IOMMUs if the IOMMU used the _FINISH type macro. During the
    'pci_iommu_init' stage, we call .init for the second-stage
    initialization if it was defined. Currently only SWIOTLB has this
    defined and it used to de-allocate the SWIOTLB if the other detected
    IOMMUs have deemed it unnecessary to use SWIOTLB.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    LKML-Reference: <1282845485-8991-11-git-send-email-konrad.wilk@oracle.com>
    CC: Fujita Tomonori <fujita.tomonori@lab.ntt.co.jp>
    CC: Thomas Gleixner <tglx@linutronix.de>
    CC: Ingo Molnar <mingo@redhat.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1b3beb5075e6..9ea999a4dcc1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -11,9 +11,8 @@
 #include <asm/iommu.h>
 #include <asm/gart.h>
 #include <asm/calgary.h>
-#include <asm/amd_iommu.h>
 #include <asm/x86_init.h>
-#include <asm/xen/swiotlb-xen.h>
+#include <asm/iommu_table.h>
 
 static int forbid_dac __read_mostly;
 
@@ -45,6 +44,8 @@ int iommu_detected __read_mostly = 0;
  */
 int iommu_pass_through __read_mostly;
 
+extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
+
 /* Dummy device used for NULL arguments (normally ISA). */
 struct device x86_dma_fallback_dev = {
 	.init_name = "fallback device",
@@ -130,28 +131,24 @@ static void __init dma32_free_bootmem(void)
 
 void __init pci_iommu_alloc(void)
 {
+	struct iommu_table_entry *p;
+
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 
-	if (pci_xen_swiotlb_detect() || pci_swiotlb_detect_override())
-		goto out;
-
-	pci_swiotlb_detect_4gb();
-
-	gart_iommu_hole_init();
-
-	detect_calgary();
-
-	detect_intel_iommu();
+	sort_iommu_table(__iommu_table, __iommu_table_end);
+	check_iommu_entries(__iommu_table, __iommu_table_end);
 
-	/* needs to be called after gart_iommu_hole_init */
-	amd_iommu_detect();
-out:
-	pci_xen_swiotlb_init();
-
-	pci_swiotlb_init();
+	for (p = __iommu_table; p < __iommu_table_end; p++) {
+		if (p && p->detect && p->detect() > 0) {
+			p->flags |= IOMMU_DETECTED;
+			if (p->early_init)
+				p->early_init();
+			if (p->flags & IOMMU_FINISH_IF_DETECTED)
+				break;
+		}
+	}
 }
-
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 dma_addr_t *dma_addr, gfp_t flag)
 {
@@ -294,6 +291,7 @@ EXPORT_SYMBOL(dma_supported);
 
 static int __init pci_iommu_init(void)
 {
+	struct iommu_table_entry *p;
 	dma_debug_init(PREALLOC_DMA_DEBUG_ENTRIES);
 
 #ifdef CONFIG_PCI
@@ -301,12 +299,10 @@ static int __init pci_iommu_init(void)
 #endif
 	x86_init.iommu.iommu_init();
 
-	if (swiotlb || xen_swiotlb) {
-		printk(KERN_INFO "PCI-DMA: "
-		       "Using software bounce buffering for IO (SWIOTLB)\n");
-		swiotlb_print_info();
-	} else
-		swiotlb_free();
+	for (p = __iommu_table; p < __iommu_table_end; p++) {
+		if (p && (p->flags & IOMMU_DETECTED) && p->late_init)
+			p->late_init();
+	}
 
 	return 0;
 }

commit efa631c26d3bb1162b8f95008801db602217f52b
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Thu Aug 26 13:57:59 2010 -0400

    x86, swiotlb: Simplify SWIOTLB pci_swiotlb_detect routine.
    
    In 'pci_swiotlb_detect' we used to do two different things:
     a). If user provided 'iommu=soft' or 'swiotlb=force' we
         would set swiotlb=1 and return 1 (and forcing pci-dma.c
         to call pci_swiotlb_init() immediately).
     b). If 4GB or more would be detected and if user did not specify
         iommu=off, we would set 'swiotlb=1' and return whatever 'a)'
         figured out.
    
    We simplify this by splitting a) and b) in two different routines.
    
    CC: Fujita Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    LKML-Reference: <1282845485-8991-5-git-send-email-konrad.wilk@oracle.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 9f07cfcbd3a5..1b3beb5075e6 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -133,9 +133,11 @@ void __init pci_iommu_alloc(void)
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 
-	if (pci_xen_swiotlb_detect() || pci_swiotlb_detect())
+	if (pci_xen_swiotlb_detect() || pci_swiotlb_detect_override())
 		goto out;
 
+	pci_swiotlb_detect_4gb();
+
 	gart_iommu_hole_init();
 
 	detect_calgary();

commit fe96eb404e33b59bb39f7050205f7c56c1c7d686
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Thu Mar 18 13:53:24 2010 -0400

    x86: Detect whether we should use Xen SWIOTLB.
    
    It is paramount that we call pci_xen_swiotlb_detect before
    pci_swiotlb_detect as both implementations use the 'swiotlb'
    and 'swiotlb_force' flags. The pci-xen_swiotlb_detect inhibits
    the swiotlb_force and swiotlb flag so that the native SWIOTLB
    implementation is not enabled when running under Xen.
    
    [since v1 changed two Cc's to Acked-by]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Acked-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
        [http://lkml.org/lkml/2010/7/27/374]
    Cc: Albert Herranz <albert_herranz@yahoo.es>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
        [conditional http://lkml.org/lkml/2010/8/2/324]
    Cc: x86@kernel.org
    Cc: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 4b7e3d8b01dd..9f07cfcbd3a5 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -13,6 +13,7 @@
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 #include <asm/x86_init.h>
+#include <asm/xen/swiotlb-xen.h>
 
 static int forbid_dac __read_mostly;
 
@@ -132,7 +133,7 @@ void __init pci_iommu_alloc(void)
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 
-	if (pci_swiotlb_detect())
+	if (pci_xen_swiotlb_detect() || pci_swiotlb_detect())
 		goto out;
 
 	gart_iommu_hole_init();
@@ -144,6 +145,8 @@ void __init pci_iommu_alloc(void)
 	/* needs to be called after gart_iommu_hole_init */
 	amd_iommu_detect();
 out:
+	pci_xen_swiotlb_init();
+
 	pci_swiotlb_init();
 }
 
@@ -296,7 +299,7 @@ static int __init pci_iommu_init(void)
 #endif
 	x86_init.iommu.iommu_init();
 
-	if (swiotlb) {
+	if (swiotlb || xen_swiotlb) {
 		printk(KERN_INFO "PCI-DMA: "
 		       "Using software bounce buffering for IO (SWIOTLB)\n");
 		swiotlb_print_info();

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index a4ac764a6880..4b7e3d8b01dd 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -2,6 +2,7 @@
 #include <linux/dma-debug.h>
 #include <linux/dmar.h>
 #include <linux/bootmem.h>
+#include <linux/gfp.h>
 #include <linux/pci.h>
 #include <linux/kmemleak.h>
 

commit 318ae2edc3b29216abd8a2510f3f80b764f06858
Merge: 25cf84cf377c 3e58974027b0
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Mon Mar 8 16:55:37 2010 +0100

    Merge branch 'for-next' into for-linus
    
    Conflicts:
            Documentation/filesystems/proc.txt
            arch/arm/mach-u300/include/mach/debug-macro.S
            drivers/net/qlge/qlge_ethtool.c
            drivers/net/qlge/qlge_main.c
            drivers/net/typhoon.c

commit c252a5bb1f57afb1e336d68085217727ca7b2134
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 10 01:20:19 2010 -0800

    x86: Only call dma32_reserve_bootmem 64bit !CONFIG_NUMA
    
    64bit NUMA already make enough space under 4G with new early_node_mem.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <1265793639-15071-16-git-send-email-yinghai@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 75e14e21f61a..1aa966c565f9 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -65,7 +65,7 @@ int dma_set_mask(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_set_mask);
 
-#ifdef CONFIG_X86_64
+#if defined(CONFIG_X86_64) && !defined(CONFIG_NUMA)
 static __initdata void *dma32_bootmem_ptr;
 static unsigned long dma32_bootmem_size __initdata = (128ULL<<20);
 
@@ -116,14 +116,21 @@ static void __init dma32_free_bootmem(void)
 	dma32_bootmem_ptr = NULL;
 	dma32_bootmem_size = 0;
 }
+#else
+void __init dma32_reserve_bootmem(void)
+{
+}
+static void __init dma32_free_bootmem(void)
+{
+}
+
 #endif
 
 void __init pci_iommu_alloc(void)
 {
-#ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
-#endif
+
 	if (pci_swiotlb_detect())
 		goto out;
 

commit fb637f3cd31783db2b654842ea32ffec15c4bd62
Author: Justin P. Mattock <justinmattock@gmail.com>
Date:   Thu Jan 14 22:16:16 2010 -0800

    fix comment typo in pci-dma.c
    
    Signed-off-by: Justin P. Mattock <justinmattock@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 75e14e21f61a..eec33a7d96a0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -38,7 +38,7 @@ int iommu_detected __read_mostly = 0;
  * This variable becomes 1 if iommu=pt is passed on the kernel command line.
  * If this variable is 1, IOMMU implementations do no DMA translation for
  * devices and allow every device to access to whole physical memory. This is
- * useful if a user want to use an IOMMU only for KVM device assignment to
+ * useful if a user wants to use an IOMMU only for KVM device assignment to
  * guests and not for driver dma translation.
  */
 int iommu_pass_through __read_mostly;

commit 186a25026c44d1bfa97671110ff14dcd0c99678e
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Dec 15 20:47:56 2009 +0900

    x86: Split swiotlb initialization into two stages
    
    The commit f4780ca005404166cc40af77ef0e86132ab98a81 moves
    swiotlb initialization before dma32_free_bootmem(). It's
    supposed to fix a bug that the commit
    75f1cdf1dda92cae037ec848ae63690d91913eac introduced, we
    initialize SWIOTLB right after dma32_free_bootmem so we wrongly
    steal memory area allocated for GART with broken BIOS earlier.
    
    However, the above commit introduced another problem, which
    likely breaks machines with huge amount of memory. Such a box
    use the majority of DMA32_ZONE so there is no memory for
    swiotlb.
    
    With this patch, the x86 IOMMU initialization sequence are:
    
    1. We set swiotlb to 1 in the case of (max_pfn > MAX_DMA32_PFN
       && !no_iommu). If swiotlb usage is forced by the boot option,
       we go to the step 3 and finish (we don't try to detect IOMMUs).
    
    2. We call the detection functions of all the IOMMUs. The
       detection function sets x86_init.iommu.iommu_init to the IOMMU
       initialization function (so we can avoid calling the
       initialization functions of all the IOMMUs needlessly).
    
    3. We initialize swiotlb (and set dma_ops to swiotlb_dma_ops) if
       swiotlb is set to 1.
    
    4. If the IOMMU initialization function doesn't need swiotlb
       (e.g. the initialization is sucessful) then sets swiotlb to zero.
    
    5. If we find that swiotlb is set to zero, we free swiotlb
       resource.
    
    Reported-by: Yinghai Lu <yinghai@kernel.org>
    Reported-by: Roland Dreier <rdreier@cisco.com>
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    LKML-Reference: <20091215204729A.fujita.tomonori@lab.ntt.co.jp>
    Tested-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index fcc2f2bfa39c..75e14e21f61a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -120,15 +120,12 @@ static void __init dma32_free_bootmem(void)
 
 void __init pci_iommu_alloc(void)
 {
-	int use_swiotlb;
-
-	use_swiotlb = pci_swiotlb_init();
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 #endif
-	if (use_swiotlb)
-		return;
+	if (pci_swiotlb_detect())
+		goto out;
 
 	gart_iommu_hole_init();
 
@@ -138,6 +135,8 @@ void __init pci_iommu_alloc(void)
 
 	/* needs to be called after gart_iommu_hole_init */
 	amd_iommu_detect();
+out:
+	pci_swiotlb_init();
 }
 
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,

commit f4780ca005404166cc40af77ef0e86132ab98a81
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Mon Dec 14 11:52:14 2009 +0900

    x86: Move swiotlb initialization before dma32_free_bootmem
    
    The commit 75f1cdf1dda92cae037ec848ae63690d91913eac introduced a
    bug that we initialize SWIOTLB right after dma32_free_bootmem so
    we wrongly steal memory area allocated for GART with broken BIOS
    earlier.
    
    This moves swiotlb initialization before dma32_free_bootmem().
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: yinghai@kernel.org
    LKML-Reference: <1260759135-6450-2-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index afcc58b69c7c..fcc2f2bfa39c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -120,11 +120,14 @@ static void __init dma32_free_bootmem(void)
 
 void __init pci_iommu_alloc(void)
 {
+	int use_swiotlb;
+
+	use_swiotlb = pci_swiotlb_init();
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 #endif
-	if (pci_swiotlb_init())
+	if (use_swiotlb)
 		return;
 
 	gart_iommu_hole_init();

commit 8fd524b355daef0945692227e726fb444cebcd4f
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Sun Nov 15 21:19:53 2009 +0900

    x86: Kill bad_dma_address variable
    
    This kills bad_dma_address variable, the old mechanism to enable
    IOMMU drivers to make dma_mapping_error() work in IOMMU's
    specific way.
    
    bad_dma_address variable was introduced to enable IOMMU drivers
    to make dma_mapping_error() work in IOMMU's specific way.
    However, it can't handle systems that use both swiotlb and HW
    IOMMU. SO we introduced dma_map_ops->mapping_error to solve that
    case.
    
    Intel VT-d, GART, and swiotlb already use
    dma_map_ops->mapping_error. Calgary, AMD IOMMU, and nommu use
    zero for an error dma address. This adds DMA_ERROR_CODE and
    converts them to use it (as SPARC and POWER does).
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Jesse Barnes <jbarnes@virtuousgeek.org>
    Cc: muli@il.ibm.com
    Cc: joerg.roedel@amd.com
    LKML-Reference: <1258287594-8777-3-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index bf621b9ee26e..afcc58b69c7c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -43,9 +43,6 @@ int iommu_detected __read_mostly = 0;
  */
 int iommu_pass_through __read_mostly;
 
-dma_addr_t bad_dma_address __read_mostly = 0;
-EXPORT_SYMBOL(bad_dma_address);
-
 /* Dummy device used for NULL arguments (normally ISA). */
 struct device x86_dma_fallback_dev = {
 	.init_name = "fallback device",

commit 99f4c9de2b707795acb215e2e94df7ea266042b5
Merge: 62ad33f67003 156171c71a0d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Nov 17 07:51:02 2009 +0100

    Merge commit 'v2.6.32-rc7' into core/iommu
    
    Merge reason: Add fixes we'll depend on.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit a3b28ee1090072092e2be043c24df94230e725b2
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Sat Nov 14 20:46:36 2009 +0900

    x86: Set dma_ops to nommu_dma_ops by default
    
    We set dma_ops to nommu_dma_ops at two different places for
    x86_32 and x86_64. This unifies them by setting dma_ops to
    nommu_dma_ops by default.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    LKML-Reference: <1258199198-16657-2-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0b11bf18f540..f170b5364b41 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -15,7 +15,7 @@
 
 static int forbid_dac __read_mostly;
 
-struct dma_map_ops *dma_ops;
+struct dma_map_ops *dma_ops = &nommu_dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
@@ -128,8 +128,6 @@ void __init pci_iommu_alloc(void)
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
-#else
-	dma_ops = &nommu_dma_ops;
 #endif
 	if (pci_swiotlb_init())
 		return;

commit b18485e7acfe1a634615d1c628ef644c0d58d472
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Thu Nov 12 00:03:28 2009 +0900

    swiotlb: Remove the swiotlb variable usage
    
    POWERPC doesn't expect it to be used.
    
    This fixes the linux-next build failure reported by
    Stephen Rothwell:
    
      lib/swiotlb.c: In function 'setup_io_tlb_npages':
      lib/swiotlb.c:114: error: 'swiotlb' undeclared (first use in this function)
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: peterz@infradead.org
    LKML-Reference: <20091112000258F.fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f79870e89266..0b11bf18f540 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -125,16 +125,13 @@ static void __init dma32_free_bootmem(void)
 
 void __init pci_iommu_alloc(void)
 {
-	/* swiotlb is forced by the boot option */
-	int use_swiotlb = swiotlb;
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 #else
 	dma_ops = &nommu_dma_ops;
 #endif
-	pci_swiotlb_init();
-	if (use_swiotlb)
+	if (pci_swiotlb_init())
 		return;
 
 	gart_iommu_hole_init();

commit b4941a9a606f0131559cc040b64e8437ac7b32c5
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Nov 10 14:37:58 2009 +0100

    x86: Add iommu_init to x86_init_ops, fix build
    
    Most of the time x86_init.h is included in pci-dma.c - but not always,
    leading to this rare build failure:
    
    arch/x86/kernel/pci-dma.c:296: error: 'x86_init' undeclared (first use in this function)
    
    So include asm/x86_init.h explicitly.
    
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-2-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 63eebee80e75..f79870e89266 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -11,6 +11,7 @@
 #include <asm/gart.h>
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
+#include <asm/x86_init.h>
 
 static int forbid_dac __read_mostly;
 

commit 72d03802b8b5c841ab1da82bff0652628cbadf60
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 21:35:17 2009 +0900

    x86, 32-bit: Fix swiotlb boot crash
    
    Ingo Molnar reported this boot crash:
    
    [    8.655620] pata_amd 0000:00:06.0: version 0.4.1
    [    8.660286] BUG: unable to handle kernel NULL pointer dereference at 00000034
    [    8.663572] IP: [<c100617b>] dma_supported+0x3b/0xa4
    [    8.663572] *pde = 00000000
    
    Initialize dma_ops properly in the 32-bit case.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index a234e63c2656..63eebee80e75 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -129,6 +129,8 @@ void __init pci_iommu_alloc(void)
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
+#else
+	dma_ops = &nommu_dma_ops;
 #endif
 	pci_swiotlb_init();
 	if (use_swiotlb)

commit 75f1cdf1dda92cae037ec848ae63690d91913eac
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:20 2009 +0900

    x86: Handle HW IOMMU initialization failure gracefully
    
    If HW IOMMU initialization fails (Intel VT-d often does this,
    typically due to BIOS bugs), we fall back to nommu. It doesn't
    work for the majority since nowadays we have more than 4GB
    memory so we must use swiotlb instead of nommu.
    
    The problem is that it's too late to initialize swiotlb when HW
    IOMMU initialization fails. We need to allocate swiotlb memory
    earlier from bootmem allocator. Chris explained the issue in
    detail:
    
      http://marc.info/?l=linux-kernel&m=125657444317079&w=2
    
    The current x86 IOMMU initialization sequence is too complicated
    and handling the above issue makes it more hacky.
    
    This patch changes x86 IOMMU initialization sequence to handle
    the above issue cleanly.
    
    The new x86 IOMMU initialization sequence are:
    
    1. we initialize the swiotlb (and setting swiotlb to 1) in the case
       of (max_pfn > MAX_DMA32_PFN && !no_iommu). dma_ops is set to
       swiotlb_dma_ops or nommu_dma_ops. if swiotlb usage is forced by
       the boot option, we finish here.
    
    2. we call the detection functions of all the IOMMUs
    
    3. the detection function sets x86_init.iommu.iommu_init to the
       IOMMU initialization function (so we can avoid calling the
       initialization functions of all the IOMMUs needlessly).
    
    4. if the IOMMU initialization function doesn't need to swiotlb
       then sets swiotlb to zero (e.g. the initialization is
       sucessful).
    
    5. if we find that swiotlb is set to zero, we free swiotlb
       resource.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-10-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index bed05e2e5890..a234e63c2656 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -124,24 +124,24 @@ static void __init dma32_free_bootmem(void)
 
 void __init pci_iommu_alloc(void)
 {
+	/* swiotlb is forced by the boot option */
+	int use_swiotlb = swiotlb;
 #ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
 #endif
+	pci_swiotlb_init();
+	if (use_swiotlb)
+		return;
 
-	/*
-	 * The order of these functions is important for
-	 * fall-back/fail-over reasons
-	 */
 	gart_iommu_hole_init();
 
 	detect_calgary();
 
 	detect_intel_iommu();
 
+	/* needs to be called after gart_iommu_hole_init */
 	amd_iommu_detect();
-
-	pci_swiotlb_init();
 }
 
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,
@@ -291,10 +291,15 @@ static int __init pci_iommu_init(void)
 #ifdef CONFIG_PCI
 	dma_debug_add_bus(&pci_bus_type);
 #endif
-
 	x86_init.iommu.iommu_init();
 
-	no_iommu_init();
+	if (swiotlb) {
+		printk(KERN_INFO "PCI-DMA: "
+		       "Using software bounce buffering for IO (SWIOTLB)\n");
+		swiotlb_print_info();
+	} else
+		swiotlb_free();
+
 	return 0;
 }
 /* Must execute after PCI subsystem */

commit 9d5ce73a64be2be8112147a3e0b551ad9cd1247b
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:16 2009 +0900

    x86: intel-iommu: Convert detect_intel_iommu to use iommu_init hook
    
    This changes detect_intel_iommu() to set intel_iommu_init() to
    iommu_init hook if detect_intel_iommu() finds the IOMMU.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-6-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    [ -v2: build fix for the !CONFIG_DMAR case ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 5ca44a9301a0..bed05e2e5890 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -294,8 +294,6 @@ static int __init pci_iommu_init(void)
 
 	x86_init.iommu.iommu_init();
 
-	intel_iommu_init();
-
 	no_iommu_init();
 	return 0;
 }

commit ea1b0d3945c7374849235b6ecaea1191ee1d9d50
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:15 2009 +0900

    x86: amd_iommu: Convert amd_iommu_detect() to use iommu_init hook
    
    This changes amd_iommu_detect() to set amd_iommu_init to
    iommu_init hook if amd_iommu_detect() finds the AMD IOMMU.
    
    We can kill the code to check if we found the IOMMU in
    amd_iommu_init() since amd_iommu_detect() sets amd_iommu_init()
    only when it found the IOMMU.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-5-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ecde8543537f..5ca44a9301a0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -296,8 +296,6 @@ static int __init pci_iommu_init(void)
 
 	intel_iommu_init();
 
-	amd_iommu_init();
-
 	no_iommu_init();
 	return 0;
 }

commit de957628ce7c84764ff41331111036b3ae5bad0f
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:14 2009 +0900

    x86: GART: Convert gart_iommu_hole_init() to use iommu_init hook
    
    This changes gart_iommu_hole_init() to set gart_iommu_init() to
    iommu_init hook if gart_iommu_hole_init() finds the GART IOMMU.
    
    We can kill the code to check if we found the IOMMU in
    gart_iommu_init() since gart_iommu_hole_init() sets
    gart_iommu_init() only when it found the IOMMU.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-4-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0224da88256a..ecde8543537f 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -298,8 +298,6 @@ static int __init pci_iommu_init(void)
 
 	amd_iommu_init();
 
-	gart_iommu_init();
-
 	no_iommu_init();
 	return 0;
 }

commit d7b9f7be216b04ff9d108f856bc03d96e7b3439c
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:13 2009 +0900

    x86: Calgary: Convert detect_calgary() to use iommu_init hook
    
    This changes detect_calgary() to set init_calgary() to
    iommu_init hook if detect_calgary() finds the Calgary IOMMU.
    
    We can kill the code to check if we found the IOMMU in
    init_calgary() since detect_calgary() sets init_calgary() only
    when it found the IOMMU.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    LKML-Reference: <1257849980-22640-3-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index a13478da533c..0224da88256a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -294,8 +294,6 @@ static int __init pci_iommu_init(void)
 
 	x86_init.iommu.iommu_init();
 
-	calgary_iommu_init();
-
 	intel_iommu_init();
 
 	amd_iommu_init();

commit d07c1be0693e0902d743160b8b638585b808f8ac
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Nov 10 19:46:12 2009 +0900

    x86: Add iommu_init to x86_init_ops
    
    We call the detections functions of all the IOMMUs then all
    their initialization functions. The latter is pointless since we
    don't detect multiple different IOMMUs. What we need to do is
    calling the initialization function of the detected IOMMU.
    
    This adds iommu_init hook to x86_init_ops so if an IOMMU
    detection function can set its initialization function to the
    hook.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: chrisw@sous-sol.org
    Cc: dwmw2@infradead.org
    Cc: joerg.roedel@amd.com
    Cc: muli@il.ibm.com
    LKML-Reference: <1257849980-22640-2-git-send-email-fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 839d49a669bc..a13478da533c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -292,6 +292,8 @@ static int __init pci_iommu_init(void)
 	dma_debug_add_bus(&pci_bus_type);
 #endif
 
+	x86_init.iommu.iommu_init();
+
 	calgary_iommu_init();
 
 	intel_iommu_init();

commit eb647138acefc897c0eb6eddd5d3650966dfe627
Author: Jan Beulich <JBeulich@novell.com>
Date:   Sun Nov 8 12:12:14 2009 +0100

    x86/PCI: Adjust GFP mask handling for coherent allocations
    
    Rather than forcing GFP flags and DMA mask to be inconsistent,
    GFP flags should be determined even for the fallback device
    through dma_alloc_coherent_mask()/dma_alloc_coherent_gfp_flags().
    
    This restores 64-bit behavior as it was prior to commits
    8965eb19386fdf5ccd0ef8b02593eb8560aa3416 and
    4a367f3a9dbf2e7ffcee4702203479809236ee6e (not sure why there are
    two of them), where GFP_DMA was forced on for 32-bit, but not
    for 64-bit, with the slight adjustment that afaict even 32-bit
    doesn't need this without CONFIG_ISA.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Acked-by: Takashi Iwai <tiwai@suse.de>
    LKML-Reference: <4AF18187020000780001D8AA@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b2a71dca5642..a6e804d16c35 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -45,12 +45,10 @@ int iommu_pass_through __read_mostly;
 dma_addr_t bad_dma_address __read_mostly = 0;
 EXPORT_SYMBOL(bad_dma_address);
 
-/* Dummy device used for NULL arguments (normally ISA). Better would
-   be probably a smaller DMA mask, but this is bug-to-bug compatible
-   to older i386. */
+/* Dummy device used for NULL arguments (normally ISA). */
 struct device x86_dma_fallback_dev = {
 	.init_name = "fallback device",
-	.coherent_dma_mask = DMA_BIT_MASK(32),
+	.coherent_dma_mask = ISA_DMA_BIT_MASK,
 	.dma_mask = &x86_dma_fallback_dev.coherent_dma_mask,
 };
 EXPORT_SYMBOL(x86_dma_fallback_dev);

commit 2ae8bb75db1f3de422eb5898f2a063c46c36dba8
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Oct 26 15:41:46 2009 +0100

    x86: Fix iommu=nodac parameter handling
    
    iommu=nodac should forbid dac instead of enabling it. Fix it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: Matteo Frigo <athena@fftw.org>
    Cc: <stable@kernel.org> # .32.x and older
    LKML-Reference: <4AE5B52A.4050408@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ce2fb91bbed1..839d49a669bc 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -216,7 +216,7 @@ static __init int iommu_setup(char *p)
 		if (!strncmp(p, "allowdac", 8))
 			forbid_dac = 0;
 		if (!strncmp(p, "nodac", 5))
-			forbid_dac = -1;
+			forbid_dac = 1;
 		if (!strncmp(p, "usedac", 6)) {
 			forbid_dac = -1;
 			return 1;

commit 338bac527ed0e35b4cb50390972f15d3cbce92ca
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Oct 27 16:34:44 2009 +0900

    x86: Use x86_platform for iommu_shutdown
    
    This patch cleans up pci_iommu_shutdown() a bit to use
    x86_platform (similar to how IA64 initializes an IOMMU driver).
    
    This adds iommu_shutdown() to x86_platform to avoid calling
    every IOMMUs' shutdown functions in pci_iommu_shutdown() in
    order. The IOMMU shutdown functions are platform specific (we
    don't have multiple different IOMMU hardware) so the current way
    is pointless.
    
    An IOMMU driver sets x86_platform.iommu_shutdown to the shutdown
    function if necessary.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: joerg.roedel@amd.com
    LKML-Reference: <20091027163358F.fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b2a71dca5642..ce2fb91bbed1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -303,13 +303,6 @@ static int __init pci_iommu_init(void)
 	no_iommu_init();
 	return 0;
 }
-
-void pci_iommu_shutdown(void)
-{
-	gart_iommu_shutdown();
-
-	amd_iommu_shutdown();
-}
 /* Must execute after PCI subsystem */
 rootfs_initcall(pci_iommu_init);
 

commit 80fa680d22c11912a0be84b8139422eba1327322
Merge: 2caa731819a6 9a821b231644
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 13 10:04:40 2009 -0700

    Merge git://git.infradead.org/~dwmw2/iommu-2.6.32
    
    * git://git.infradead.org/~dwmw2/iommu-2.6.32:
      x86: Move pci_iommu_init to rootfs_initcall()
      Run pci_apply_final_quirks() sooner.
      Mark pci_apply_final_quirks() __init rather than __devinit
      Rename pci_init() to pci_apply_final_quirks(), move it to quirks.c
      intel-iommu: Yet another BIOS workaround: Isoch DMAR unit with no TLB space
      intel-iommu: Decode (and ignore) RHSA entries
      intel-iommu: Make "Unknown DMAR structure" message more informative

commit 9a821b231644028f8e2a853eb33d1184e925b183
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Mon Oct 12 12:59:29 2009 +0100

    x86: Move pci_iommu_init to rootfs_initcall()
    
    We want this to happen after the PCI quirks, which are now running at
    the very end of the fs_initcalls.
    
    This works around the BIOS problems which were originally addressed by
    commit db8be50c4307dac2b37305fc59c8dc0f978d09ea ('USB: Work around BIOS
    bugs by quiescing USB controllers earlier'), which was reverted in
    commit d93a8f829fe1d2f3002f2c6ddb553d12db420412.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 64b838eac18c..e0d9199d0eb9 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -311,7 +311,7 @@ void pci_iommu_shutdown(void)
 	amd_iommu_shutdown();
 }
 /* Must execute after PCI subsystem */
-fs_initcall(pci_iommu_init);
+rootfs_initcall(pci_iommu_init);
 
 #ifdef CONFIG_PCI
 /* Many VIA bridges seem to corrupt data for DAC. Disable it here */

commit e3be785fb59f92c0df685037062d041619653b7a
Author: Marin Mitov <mitov@issp.bas.bg>
Date:   Sat Oct 3 20:45:02 2009 +0300

    x86, pci: Correct spelling in a comment
    
    Signed-off-by: Marin Mitov <mitov@issp.bas.bg>
    Cc: Joerg Roedel <joerg.roedel@amd.com>
    Cc: Jesse Brandeburg <jesse.brandeburg@intel.com>
    LKML-Reference: <200910032045.02523.mitov@issp.bas.bg>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    ======================================================

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 64b838eac18c..d20009b4e6ef 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -35,7 +35,7 @@ int iommu_detected __read_mostly = 0;
 
 /*
  * This variable becomes 1 if iommu=pt is passed on the kernel command line.
- * If this variable is 1, IOMMU implementations do no DMA ranslation for
+ * If this variable is 1, IOMMU implementations do no DMA translation for
  * devices and allow every device to access to whole physical memory. This is
  * useful if a user want to use an IOMMU only for KVM device assignment to
  * guests and not for driver dma translation.

commit 4406c56d0a4da7a37b9180abeaece6cd00bcc874
Merge: 6b7b352f2102 5e3573db2bd5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 16 07:49:54 2009 -0700

    Merge branch 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6
    
    * 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6: (75 commits)
      PCI hotplug: clean up acpi_run_hpp()
      PCI hotplug: acpiphp: use generic pci_configure_slot()
      PCI hotplug: shpchp: use generic pci_configure_slot()
      PCI hotplug: pciehp: use generic pci_configure_slot()
      PCI hotplug: add pci_configure_slot()
      PCI hotplug: clean up acpi_get_hp_params_from_firmware() interface
      PCI hotplug: acpiphp: don't cache hotplug_params in acpiphp_bridge
      PCI hotplug: acpiphp: remove superfluous _HPP/_HPX evaluation
      PCI: Clear saved_state after the state has been restored
      PCI PM: Return error codes from pci_pm_resume()
      PCI: use dev_printk in quirk messages
      PCI / PCIe portdrv: Fix pcie_portdrv_slot_reset()
      PCI Hotplug: convert acpi_pci_detect_ejectable() to take an acpi_handle
      PCI Hotplug: acpiphp: find bridges the easy way
      PCI: pcie portdrv: remove unused variable
      PCI / ACPI PM: Propagate wake-up enable for devices w/o ACPI support
      ACPI PM: Replace wakeup.prepared with reference counter
      PCI PM: Introduce device flag wakeup_prepared
      PCI / ACPI PM: Rework some debug messages
      PCI PM: Simplify PCI wake-up code
      ...
    
    Fixed up conflict in arch/powerpc/kernel/pci_64.c due to OF device tree
    scanning having been moved and merged for the 32- and 64-bit cases.  The
    'needs_freset' initialization added in 6e19314cc ("PCI/powerpc: support
    PCIe fundamental reset") is now in arch/powerpc/kernel/pci_of_scan.c.

commit a66a50054e46ec2a03244bc14c48b9125fcd75a7
Merge: 7193bea53f9d 695a461296e5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 11 13:16:37 2009 -0700

    Merge branch 'core-iommu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-iommu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (59 commits)
      x86/gart: Do not select AGP for GART_IOMMU
      x86/amd-iommu: Initialize passthrough mode when requested
      x86/amd-iommu: Don't detach device from pt domain on driver unbind
      x86/amd-iommu: Make sure a device is assigned in passthrough mode
      x86/amd-iommu: Align locking between attach_device and detach_device
      x86/amd-iommu: Fix device table write order
      x86/amd-iommu: Add passthrough mode initialization functions
      x86/amd-iommu: Add core functions for pd allocation/freeing
      x86/dma: Mark iommu_pass_through as __read_mostly
      x86/amd-iommu: Change iommu_map_page to support multiple page sizes
      x86/amd-iommu: Support higher level PTEs in iommu_page_unmap
      x86/amd-iommu: Remove old page table handling macros
      x86/amd-iommu: Use 2-level page tables for dma_ops domains
      x86/amd-iommu: Remove bus_addr check in iommu_map_page
      x86/amd-iommu: Remove last usages of IOMMU_PTE_L0_INDEX
      x86/amd-iommu: Change alloc_pte to support 64 bit address space
      x86/amd-iommu: Introduce increase_address_space function
      x86/amd-iommu: Flush domains if address space size was increased
      x86/amd-iommu: Introduce set_dte_entry function
      x86/amd-iommu: Add a gneric version of amd_iommu_flush_all_devices
      ...

commit 80286879c209034245f0a28a2171d2ec23b7481c
Author: Alex Williamson <alex.williamson@hp.com>
Date:   Thu Jul 30 16:15:18 2009 -0600

    PCI iommu: iommu=pt is a valid early param
    
    This avoids a "Malformed early option 'iommu'" on boot when trying
    to use pass-through mode.
    
    Signed-off-by: Alex Williamson <alex.williamson@hp.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1a041bcf506b..ae13e34f7248 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -212,10 +212,8 @@ static __init int iommu_setup(char *p)
 		if (!strncmp(p, "soft", 4))
 			swiotlb = 1;
 #endif
-		if (!strncmp(p, "pt", 2)) {
+		if (!strncmp(p, "pt", 2))
 			iommu_pass_through = 1;
-			return 1;
-		}
 
 		gart_parse_options(p);
 

commit 695a461296e5df148c99ac087b9e1cb380f4db15
Merge: c7084b35eb1a 2b681fafcc50
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Sep 4 14:44:16 2009 +0200

    Merge branch 'amd-iommu/2.6.32' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/linux-2.6-iommu into core/iommu

commit ac0101d396fee24994632f71b55b9f7f9ee16eff
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 1 16:00:35 2009 +0200

    x86/dma: Mark iommu_pass_through as __read_mostly
    
    This variable is read most of the time. This patch marks it
    as such. It also documents the meaning the this variable
    while at it.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1a041bcf506b..873aa079d166 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -32,7 +32,14 @@ int no_iommu __read_mostly;
 /* Set this to 1 if there is a HW IOMMU in the system */
 int iommu_detected __read_mostly = 0;
 
-int iommu_pass_through;
+/*
+ * This variable becomes 1 if iommu=pt is passed on the kernel command line.
+ * If this variable is 1, IOMMU implementations do no DMA ranslation for
+ * devices and allow every device to access to whole physical memory. This is
+ * useful if a user want to use an IOMMU only for KVM device assignment to
+ * guests and not for driver dma translation.
+ */
+int iommu_pass_through __read_mostly;
 
 dma_addr_t bad_dma_address __read_mostly = 0;
 EXPORT_SYMBOL(bad_dma_address);

commit acde31dc467797ccae3a55b791a77af446cce018
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Aug 27 14:29:20 2009 +0100

    kmemleak: Ignore the aperture memory hole on x86_64
    
    This block is allocated with alloc_bootmem() and scanned by kmemleak but
    the kernel direct mapping may no longer exist. This patch tells kmemleak
    to ignore this memory hole. The dma32_bootmem_ptr in
    dma32_reserve_bootmem() is also ignored.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1a041bcf506b..fa80f60e9607 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -3,6 +3,7 @@
 #include <linux/dmar.h>
 #include <linux/bootmem.h>
 #include <linux/pci.h>
+#include <linux/kmemleak.h>
 
 #include <asm/proto.h>
 #include <asm/dma.h>
@@ -88,6 +89,11 @@ void __init dma32_reserve_bootmem(void)
 	size = roundup(dma32_bootmem_size, align);
 	dma32_bootmem_ptr = __alloc_bootmem_nopanic(size, align,
 				 512ULL<<20);
+	/*
+	 * Kmemleak should not scan this block as it may not be mapped via the
+	 * kernel direct mapping.
+	 */
+	kmemleak_ignore(dma32_bootmem_ptr);
 	if (dma32_bootmem_ptr)
 		dma32_bootmem_size = size;
 	else

commit a4c2baa6e148adfb27beaf16b6fb6d465b5b3acb
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 10 10:04:55 2009 +0900

    x86: replace is_buffer_dma_capable() with dma_capable
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1a041bcf506b..3c945c0b3501 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -147,7 +147,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 		return NULL;
 
 	addr = page_to_phys(page);
-	if (!is_buffer_dma_capable(dma_mask, addr, size)) {
+	if (addr + size > dma_mask) {
 		__free_pages(page, get_order(size));
 
 		if (dma_mask < DMA_BIT_MASK(32) && !(flag & GFP_DMA)) {

commit 3238c0c4d68d9a9022b411a11a4b933fbdb53a14
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Jul 1 18:56:16 2009 +0100

    intel-iommu: Make iommu=pt work on i386 too
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 47630479b067..1a041bcf506b 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -211,11 +211,11 @@ static __init int iommu_setup(char *p)
 #ifdef CONFIG_SWIOTLB
 		if (!strncmp(p, "soft", 4))
 			swiotlb = 1;
+#endif
 		if (!strncmp(p, "pt", 2)) {
 			iommu_pass_through = 1;
 			return 1;
 		}
-#endif
 
 		gart_parse_options(p);
 

commit 687d680985b1438360a9ba470ece8b57cd205c3b
Merge: 1053414068ba 008fe148cb0f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 22 21:38:22 2009 -0700

    Merge git://git.infradead.org/~dwmw2/iommu-2.6.31
    
    * git://git.infradead.org/~dwmw2/iommu-2.6.31:
      intel-iommu: Fix one last ia64 build problem in Pass Through Support
      VT-d: support the device IOTLB
      VT-d: cleanup iommu_flush_iotlb_psi and flush_unmaps
      VT-d: add device IOTLB invalidation support
      VT-d: parse ATSR in DMA Remapping Reporting Structure
      PCI: handle Virtual Function ATS enabling
      PCI: support the ATS capability
      intel-iommu: dmar_set_interrupt return error value
      intel-iommu: Tidy up iommu->gcmd handling
      intel-iommu: Fix tiny theoretical race in write-buffer flush.
      intel-iommu: Clean up handling of "caching mode" vs. IOTLB flushing.
      intel-iommu: Clean up handling of "caching mode" vs. context flushing.
      VT-d: fix invalid domain id for KVM context flush
      Fix !CONFIG_DMAR build failure introduced by Intel IOMMU Pass Through Support
      Intel IOMMU Pass Through Support
    
    Fix up trivial conflicts in drivers/pci/{intel-iommu.c,intr_remapping.c}

commit 0975904276552c8e201dad0ad31152ba8a21505a
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Jun 9 17:52:27 2009 +0200

    amd-iommu: disable IOMMU hardware on shutdown
    
    When the IOMMU stays enabled the BIOS may not be able to finish the
    machine shutdown properly. So disable the hardware on shutdown.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 745579bc8256..328592fb6044 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -290,6 +290,8 @@ static int __init pci_iommu_init(void)
 void pci_iommu_shutdown(void)
 {
 	gart_iommu_shutdown();
+
+	amd_iommu_shutdown();
 }
 /* Must execute after PCI subsystem */
 fs_initcall(pci_iommu_init);

commit aed5d5f4c5ea5da01a774e42cff08c4b4fa59072
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Thu Apr 30 17:57:11 2009 -0700

    Fix !CONFIG_DMAR build failure introduced by Intel IOMMU Pass Through Support
    
    This updated patch should fix the compiling errors and remove the extern
    iommu_pass_through from drivers/pci/intel-iommu.c file.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 8cad0d854242..049005e82178 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -32,6 +32,8 @@ int no_iommu __read_mostly;
 /* Set this to 1 if there is a HW IOMMU in the system */
 int iommu_detected __read_mostly = 0;
 
+int iommu_pass_through;
+
 dma_addr_t bad_dma_address __read_mostly = 0;
 EXPORT_SYMBOL(bad_dma_address);
 
@@ -160,8 +162,6 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	return page_address(page);
 }
 
-extern int iommu_pass_through;
-
 /*
  * See <Documentation/x86_64/boot-options.txt> for the iommu kernel parameter
  * documentation.

commit 4ed0d3e6c64cfd9ba4ceb2099b10d1cf8ece4320
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri Apr 24 17:30:20 2009 -0700

    Intel IOMMU Pass Through Support
    
    The patch adds kernel parameter intel_iommu=pt to set up pass through
    mode in context mapping entry. This disables DMAR in linux kernel; but
    KVM still runs on VT-d and interrupt remapping still works.
    
    In this mode, kernel uses swiotlb for DMA API functions but other VT-d
    functionalities are enabled for KVM. KVM always uses multi level
    translation page table in VT-d. By default, pass though mode is disabled
    in kernel.
    
    This is useful when people don't want to enable VT-d DMAR in kernel but
    still want to use KVM and interrupt remapping for reasons like DMAR
    performance concern or debug purpose.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Acked-by: Weidong Han <weidong@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 745579bc8256..8cad0d854242 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -160,6 +160,8 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	return page_address(page);
 }
 
+extern int iommu_pass_through;
+
 /*
  * See <Documentation/x86_64/boot-options.txt> for the iommu kernel parameter
  * documentation.
@@ -209,6 +211,10 @@ static __init int iommu_setup(char *p)
 #ifdef CONFIG_SWIOTLB
 		if (!strncmp(p, "soft", 4))
 			swiotlb = 1;
+		if (!strncmp(p, "pt", 2)) {
+			iommu_pass_through = 1;
+			return 1;
+		}
 #endif
 
 		gart_parse_options(p);

commit 2f4f27d42a301ed147e50c2edbcd27bb8990bc8e
Author: Yang Hongyang <yanghy@cn.fujitsu.com>
Date:   Mon Apr 6 19:01:18 2009 -0700

    dma-mapping: replace all DMA_24BIT_MASK macro with DMA_BIT_MASK(24)
    
    Replace all DMA_24BIT_MASK macro with DMA_BIT_MASK(24)
    
    Signed-off-by: Yang Hongyang<yanghy@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 136a01d52db0..745579bc8256 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -243,7 +243,7 @@ int dma_supported(struct device *dev, u64 mask)
 	/* Copied from i386. Doesn't make much sense, because it will
 	   only work for pci_alloc_coherent.
 	   The caller just has to use GFP_DMA in this case. */
-	if (mask < DMA_24BIT_MASK)
+	if (mask < DMA_BIT_MASK(24))
 		return 0;
 
 	/* Tell the device to use SAC when IOMMU force is on.  This

commit 284901a90a9e0b812ca3f5f852cbbfb60d10249d
Author: Yang Hongyang <yanghy@cn.fujitsu.com>
Date:   Mon Apr 6 19:01:15 2009 -0700

    dma-mapping: replace all DMA_32BIT_MASK macro with DMA_BIT_MASK(32)
    
    Replace all DMA_32BIT_MASK macro with DMA_BIT_MASK(32)
    
    Signed-off-by: Yang Hongyang<yanghy@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0cf2d900422b..136a01d52db0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -40,7 +40,7 @@ EXPORT_SYMBOL(bad_dma_address);
    to older i386. */
 struct device x86_dma_fallback_dev = {
 	.init_name = "fallback device",
-	.coherent_dma_mask = DMA_32BIT_MASK,
+	.coherent_dma_mask = DMA_BIT_MASK(32),
 	.dma_mask = &x86_dma_fallback_dev.coherent_dma_mask,
 };
 EXPORT_SYMBOL(x86_dma_fallback_dev);
@@ -148,7 +148,7 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	if (!is_buffer_dma_capable(dma_mask, addr, size)) {
 		__free_pages(page, get_order(size));
 
-		if (dma_mask < DMA_32BIT_MASK && !(flag & GFP_DMA)) {
+		if (dma_mask < DMA_BIT_MASK(32) && !(flag & GFP_DMA)) {
 			flag = (flag & ~GFP_DMA32) | GFP_DMA;
 			goto again;
 		}

commit 50cf156af7dc68a44409bef636585ef88ebbab34
Author: Yang Hongyang <yanghy@cn.fujitsu.com>
Date:   Mon Apr 6 19:01:14 2009 -0700

    dma-mapping: replace all DMA_40BIT_MASK macro with DMA_BIT_MASK(40)
    
    Replace all DMA_40BIT_MASK macro with DMA_BIT_MASK(40)
    
    Signed-off-by: Yang Hongyang<yanghy@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 90f5b9ef5def..0cf2d900422b 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -258,7 +258,7 @@ int dma_supported(struct device *dev, u64 mask)
 	   SAC for these.  Assume all masks <= 40 bits are of this
 	   type. Normally this doesn't make any difference, but gives
 	   more gentle handling of IOMMU overflow. */
-	if (iommu_sac_force && (mask >= DMA_40BIT_MASK)) {
+	if (iommu_sac_force && (mask >= DMA_BIT_MASK(40))) {
 		dev_info(dev, "Force SAC with mask %Lx\n", mask);
 		return 0;
 	}

commit e76e5b2c663ac74ae6a542ac20795c625e36a5cd
Merge: 32527bc0e4b4 eeafda70bf28
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 1 09:47:12 2009 -0700

    Merge branch 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6
    
    * 'linux-next' of git://git.kernel.org/pub/scm/linux/kernel/git/jbarnes/pci-2.6: (88 commits)
      PCI: fix HT MSI mapping fix
      PCI: don't enable too much HT MSI mapping
      x86/PCI: make pci=lastbus=255 work when acpi is on
      PCI: save and restore PCIe 2.0 registers
      PCI: update fakephp for bus_id removal
      PCI: fix kernel oops on bridge removal
      PCI: fix conflict between SR-IOV and config space sizing
      powerpc/PCI: include pci.h in powerpc MSI implementation
      PCI Hotplug: schedule fakephp for feature removal
      PCI Hotplug: rename legacy_fakephp to fakephp
      PCI Hotplug: restore fakephp interface with complete reimplementation
      PCI: Introduce /sys/bus/pci/devices/.../rescan
      PCI: Introduce /sys/bus/pci/devices/.../remove
      PCI: Introduce /sys/bus/pci/rescan
      PCI: Introduce pci_rescan_bus()
      PCI: do not enable bridges more than once
      PCI: do not initialize bridges more than once
      PCI: always scan child buses
      PCI: pci_scan_slot() returns newly found devices
      PCI: don't scan existing devices
      ...
    
    Fix trivial append-only conflict in Documentation/feature-removal-schedule.txt

commit 13bf75766966e1bcc71fae536988caec312eef8f
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Tue Feb 24 10:38:22 2009 -0700

    x86: use dev_printk in quirk message
    
    This patch changes a VIA PCI quirk to use dev_info() rather than printk().
    
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b25428533141..022833bb9ff1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -290,8 +290,7 @@ fs_initcall(pci_iommu_init);
 static __devinit void via_no_dac(struct pci_dev *dev)
 {
 	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
-		printk(KERN_INFO
-			"PCI: VIA PCI bridge detected. Disabling DAC.\n");
+		dev_info(&dev->dev, "disabling DAC on VIA PCI bridge\n");
 		forbid_dac = 1;
 	}
 }

commit 86f319529372953e353dc998bc6a761949614903
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon Mar 16 17:50:28 2009 +0100

    dma-debug/x86: register pci bus for dma-debug leak detection
    
    Impact: detect dma memory leaks for pci devices
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index ebf7d454f210..c7c4776ff630 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -271,6 +271,10 @@ static int __init pci_iommu_init(void)
 {
 	dma_debug_init(PREALLOC_DMA_DEBUG_ENTRIES);
 
+#ifdef CONFIG_PCI
+	dma_debug_add_bus(&pci_bus_type);
+#endif
+
 	calgary_iommu_init();
 
 	intel_iommu_init();

commit 2118d0c548e8a2205e1a29eb5b89e5f2e9ae2c8b
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Jan 9 15:13:15 2009 +0100

    dma-debug: x86 architecture bindings
    
    Impact: make use of DMA-API debugging code in x86
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f293a8df6828..ebf7d454f210 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,4 +1,5 @@
 #include <linux/dma-mapping.h>
+#include <linux/dma-debug.h>
 #include <linux/dmar.h>
 #include <linux/bootmem.h>
 #include <linux/pci.h>
@@ -44,6 +45,9 @@ struct device x86_dma_fallback_dev = {
 };
 EXPORT_SYMBOL(x86_dma_fallback_dev);
 
+/* Number of entries preallocated for DMA-API debugging */
+#define PREALLOC_DMA_DEBUG_ENTRIES       32768
+
 int dma_set_mask(struct device *dev, u64 mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, mask))
@@ -265,6 +269,8 @@ EXPORT_SYMBOL(dma_supported);
 
 static int __init pci_iommu_init(void)
 {
+	dma_debug_init(PREALLOC_DMA_DEBUG_ENTRIES);
+
 	calgary_iommu_init();
 
 	intel_iommu_init();

commit 0811a433c61e85f895018239c4466a36311cd5de
Merge: c29903076529 3d14bdad4031
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 00:51:06 2009 +0100

    Merge branch 'linus' into core/iommu

commit 1a9271331ab663f3c7cda78d86b884f2ea86d4d7
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Thu Oct 30 02:17:49 2008 +0100

    PCI: struct device - replace bus_id with dev_name(), dev_set_name()
    
    This patch is part of a larger patch series which will remove
    the "char bus_id[20]" name string from struct device. The device
    name is managed in the kobject anyway, and without any size
    limitation, and just needlessly copied into "struct device".
    
    To set and read the device name dev_name(dev) and dev_set_name(dev)
    must be used. If your code uses static kobjects, which it shouldn't
    do, "const char *init_name" can be used to statically provide the
    name the registered device should have. At registration time, the
    init_name field is cleared, to enforce the use of dev_name(dev) to
    access the device name at a later time.
    
    We need to get rid of all occurrences of bus_id in the entire tree
    to be able to enable the new interface. Please apply this patch,
    and possibly convert any remaining remaining occurrences of bus_id.
    
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
    Signed-Off-By: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 19a1044a0cd9..b25428533141 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -38,7 +38,7 @@ EXPORT_SYMBOL(bad_dma_address);
    be probably a smaller DMA mask, but this is bug-to-bug compatible
    to older i386. */
 struct device x86_dma_fallback_dev = {
-	.bus_id = "fallback device",
+	.init_name = "fallback device",
 	.coherent_dma_mask = DMA_32BIT_MASK,
 	.dma_mask = &x86_dma_fallback_dev.coherent_dma_mask,
 };

commit 160c1d8e40866edfeae7d68816b7005d70acf391
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Mon Jan 5 23:59:02 2009 +0900

    x86, ia64: convert to use generic dma_map_ops struct
    
    This converts X86 and IA64 to use include/linux/dma-mapping.h.
    
    It's a bit large but pretty boring. The major change for X86 is
    converting 'int dir' to 'enum dma_data_direction dir' in DMA mapping
    operations. The major changes for IA64 is using map_page and
    unmap_page instead of map_single and unmap_single.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 19a1044a0cd9..0d75c129b18a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -12,7 +12,7 @@
 
 static int forbid_dac __read_mostly;
 
-struct dma_mapping_ops *dma_ops;
+struct dma_map_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
@@ -224,7 +224,7 @@ early_param("iommu", iommu_setup);
 
 int dma_supported(struct device *dev, u64 mask)
 {
-	struct dma_mapping_ops *ops = get_dma_ops(dev);
+	struct dma_map_ops *ops = get_dma_ops(dev);
 
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {

commit 5f34fe1cfc1bdd8b4711bbe37421fba4ed0d1ed4
Merge: eca1bf5b4fab 6638101c1124
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 16:10:19 2008 -0800

    Merge branch 'core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (63 commits)
      stacktrace: provide save_stack_trace_tsk() weak alias
      rcu: provide RCU options on non-preempt architectures too
      printk: fix discarding message when recursion_bug
      futex: clean up futex_(un)lock_pi fault handling
      "Tree RCU": scalable classic RCU implementation
      futex: rename field in futex_q to clarify single waiter semantics
      x86/swiotlb: add default swiotlb_arch_range_needs_mapping
      x86/swiotlb: add default phys<->bus conversion
      x86: unify pci iommu setup and allow swiotlb to compile for 32 bit
      x86: add swiotlb allocation functions
      swiotlb: consolidate swiotlb info message printing
      swiotlb: support bouncing of HighMem pages
      swiotlb: factor out copy to/from device
      swiotlb: add arch hook to force mapping
      swiotlb: allow architectures to override phys<->bus<->phys conversions
      swiotlb: add comment where we handle the overflow of a dma mask on 32 bit
      rcu: fix rcutorture behavior during reboot
      resources: skip sanity check of busy resources
      swiotlb: move some definitions to header
      swiotlb: allow architectures to override swiotlb pool allocation
      ...
    
    Fix up trivial conflicts in
      arch/x86/kernel/Makefile
      arch/x86/mm/init_32.c
      include/linux/hardirq.h
    as per Ingo's suggestions.

commit 3e5621edb3392b28efb260ac99b2d26fb8b44e73
Merge: be9a1d3c2e55 181de82ee3ff
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Dec 23 16:30:27 2008 +0100

    Merge branch 'x86/iommu' into x86/core

commit cfb80c9eae8c7ed8f2ee81090062d15ead51cbe8
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Tue Dec 16 12:17:36 2008 -0800

    x86: unify pci iommu setup and allow swiotlb to compile for 32 bit
    
    swiotlb on 32 bit will be used by Xen domain 0 support.
    
    Signed-off-by: Ian Campbell <ian.campbell@citrix.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index e150ad4f0ccc..00e07447a5bd 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -105,11 +105,15 @@ static void __init dma32_free_bootmem(void)
 	dma32_bootmem_ptr = NULL;
 	dma32_bootmem_size = 0;
 }
+#endif
 
 void __init pci_iommu_alloc(void)
 {
+#ifdef CONFIG_X86_64
 	/* free the range so iommu could get some range less than 4G */
 	dma32_free_bootmem();
+#endif
+
 	/*
 	 * The order of these functions is important for
 	 * fall-back/fail-over reasons
@@ -125,8 +129,6 @@ void __init pci_iommu_alloc(void)
 	pci_swiotlb_init();
 }
 
-#endif
-
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 				 dma_addr_t *dma_addr, gfp_t flag)
 {

commit a79b7a2a758c39315344f0d86b5adb21d90d786e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Tue Dec 16 12:17:25 2008 -0800

    x86: remove unused iommu_nr_pages
    
    Impact: cleanup, remove dead code
    
    The last usage was removed by the patch set culminating in
    
    | commit e3c449f526cebb8d287241c7e82faafd9709668b
    | Author: Joerg Roedel <joerg.roedel@amd.com>
    | Date:   Wed Oct 15 22:02:11 2008 -0700
    |
    |     x86, AMD IOMMU: convert driver to generic iommu_num_pages function
    
    Signed-off-by: Ian Campbell <ian.campbell@citrix.com>
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 192624820217..e150ad4f0ccc 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -125,13 +125,6 @@ void __init pci_iommu_alloc(void)
 	pci_swiotlb_init();
 }
 
-unsigned long iommu_nr_pages(unsigned long addr, unsigned long len)
-{
-	unsigned long size = roundup((addr & ~PAGE_MASK) + len, PAGE_SIZE);
-
-	return size >> PAGE_SHIFT;
-}
-EXPORT_SYMBOL(iommu_nr_pages);
 #endif
 
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,

commit a0286c94f07636380082608196d41dd725a83229
Author: Michael Tokarev <mjt@tls.msk.ru>
Date:   Fri Dec 5 15:47:29 2008 +0300

    x86: fix missing space in printk, #2
    
    Impact: clean up printk
    
    Signed-off-by: Michael Tokarev <mjt@tls.msk.ru>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 192624820217..dc572994703d 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -300,8 +300,8 @@ fs_initcall(pci_iommu_init);
 static __devinit void via_no_dac(struct pci_dev *dev)
 {
 	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
-		printk(KERN_INFO "PCI: VIA PCI bridge detected."
-				 "Disabling DAC.\n");
+		printk(KERN_INFO
+			"PCI: VIA PCI bridge detected. Disabling DAC.\n");
 		forbid_dac = 1;
 	}
 }

commit 181de82ee3ffda1175f89d50c991dae31b79280c
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Wed Dec 3 14:53:04 2008 +0900

    x86: remove dead BIO_VMERGE_BOUNDARY definition
    
    Impact: cleanup, remove dead code
    
    The block layer dropped the virtual merge feature
    (b8b3e16cfe6435d961f6aaebcfd52a1ff2a988c5).
    
    BIO_VMERGE_BOUNDARY definition is meaningless now.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 12eeb4bfcdeb..da93c65f8f0b 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -31,11 +31,6 @@ int no_iommu __read_mostly;
 /* Set this to 1 if there is a HW IOMMU in the system */
 int iommu_detected __read_mostly = 0;
 
-/* This tells the BIO block layer to assume merging. Default to off
-   because we cannot guarantee merging later. */
-int iommu_bio_merge __read_mostly = 0;
-EXPORT_SYMBOL(iommu_bio_merge);
-
 dma_addr_t bad_dma_address __read_mostly = 0;
 EXPORT_SYMBOL(bad_dma_address);
 
@@ -189,7 +184,6 @@ static __init int iommu_setup(char *p)
 		}
 
 		if (!strncmp(p, "biomerge", 8)) {
-			iommu_bio_merge = 4096;
 			iommu_merge = 1;
 			force_iommu = 1;
 		}

commit 1d9b16d1690fe5edb1c907fe4746681cf026cdf3
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Nov 27 18:39:15 2008 +0100

    x86: move GART specific stuff from iommu.h to gart.h
    
    Impact: cleanup
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 192624820217..12eeb4bfcdeb 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -6,6 +6,7 @@
 #include <asm/proto.h>
 #include <asm/dma.h>
 #include <asm/iommu.h>
+#include <asm/gart.h>
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 

commit 3b15e581981b3ad35809f56d8131d5c19b6da1bd
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Thu Oct 23 16:51:00 2008 -0700

    x86/PCI: build failure at x86/kernel/pci-dma.c with !CONFIG_PCI
    
    On Thu, Oct 23, 2008 at 04:09:52PM -0700, Alexander Beregalov wrote:
    > arch/x86/kernel/built-in.o: In function `iommu_setup':
    > pci-dma.c:(.init.text+0x36ad): undefined reference to `forbid_dac'
    > pci-dma.c:(.init.text+0x36cc): undefined reference to `forbid_dac'
    > pci-dma.c:(.init.text+0x3711): undefined reference to `forbid_dac
    
    This patch partially reverts a patch to add IOMMU support to ia64.  The
    forbid_dac variable was incorrectly moved to quirks.c, which isn't built
    when PCI is disabled.
    
    Tested-by: "Alexander Beregalov" <a.beregalov@gmail.com>
    Acked-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1972266e8ba5..192624820217 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -9,6 +9,8 @@
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 
+static int forbid_dac __read_mostly;
+
 struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
@@ -291,3 +293,17 @@ void pci_iommu_shutdown(void)
 }
 /* Must execute after PCI subsystem */
 fs_initcall(pci_iommu_init);
+
+#ifdef CONFIG_PCI
+/* Many VIA bridges seem to corrupt data for DAC. Disable it here */
+
+static __devinit void via_no_dac(struct pci_dev *dev)
+{
+	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
+		printk(KERN_INFO "PCI: VIA PCI bridge detected."
+				 "Disabling DAC.\n");
+		forbid_dac = 1;
+	}
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID, via_no_dac);
+#endif

commit 5b6985ce8ec7127b4d60ad450b64ca8b82748a3b
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Thu Oct 16 18:02:32 2008 -0700

    intel-iommu: IA64 support
    
    The current Intel IOMMU code assumes that both host page size and Intel
    IOMMU page size are 4KiB. The first patch supports variable page size.
    This provides support for IA64 which has multiple page sizes.
    
    This patch also adds some other code hooks for IA64 platform including
    DMAR_OPERATION_TIMEOUT definition.
    
    [dwmw2: some cleanup]
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 192624820217..1972266e8ba5 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -9,8 +9,6 @@
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 
-static int forbid_dac __read_mostly;
-
 struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
@@ -293,17 +291,3 @@ void pci_iommu_shutdown(void)
 }
 /* Must execute after PCI subsystem */
 fs_initcall(pci_iommu_init);
-
-#ifdef CONFIG_PCI
-/* Many VIA bridges seem to corrupt data for DAC. Disable it here */
-
-static __devinit void via_no_dac(struct pci_dev *dev)
-{
-	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
-		printk(KERN_INFO "PCI: VIA PCI bridge detected."
-				 "Disabling DAC.\n");
-		forbid_dac = 1;
-	}
-}
-DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID, via_no_dac);
-#endif

commit bdab0ba3d9ad8de257ee6236daf314723748fde6
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed Oct 15 22:02:07 2008 -0700

    x86: rename iommu_num_pages function to iommu_nr_pages
    
    This series of patches re-introduces the iommu_num_pages function so that
    it can be used by each architecture specific IOMMU implementations.  The
    series also changes IOMMU implementations for X86, Alpha, PowerPC and
    UltraSparc.  The other implementations are not yet changed because the
    modifications required are not obvious and I can't test them on real
    hardware.
    
    This patch:
    
    This is a preparation patch for introducing a generic iommu_num_pages function.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: Muli Ben-Yehuda <muli@il.ibm.com>
    Cc: Dave Airlie <airlied@linux.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0a3824e837b4..192624820217 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -125,13 +125,13 @@ void __init pci_iommu_alloc(void)
 	pci_swiotlb_init();
 }
 
-unsigned long iommu_num_pages(unsigned long addr, unsigned long len)
+unsigned long iommu_nr_pages(unsigned long addr, unsigned long len)
 {
 	unsigned long size = roundup((addr & ~PAGE_MASK) + len, PAGE_SIZE);
 
 	return size >> PAGE_SHIFT;
 }
-EXPORT_SYMBOL(iommu_num_pages);
+EXPORT_SYMBOL(iommu_nr_pages);
 #endif
 
 void *dma_generic_alloc_coherent(struct device *dev, size_t size,

commit 725c25819e4a0dafdcf42a5f31bc569341919c7c
Merge: 3dd392a407d1 72d31053f62c 129d6aba444d 1e19b16a30c3
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Oct 10 19:47:12 2008 +0200

    Merge branches 'core/iommu', 'x86/amd-iommu' and 'x86/iommu' into x86-v28-for-linus-phase3-B
    
    Conflicts:
            arch/x86/kernel/pci-gart_64.c
            include/asm-x86/dma-mapping.h

commit 9f6ac57729724b58df81ca5dc005326759a806fe
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Wed Sep 24 20:48:35 2008 +0900

    x86: export pci-nommu's alloc_coherent
    
    This patch exports nommu_alloc_coherent (renamed
    dma_generic_alloc_coherent). GART needs this function.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0a1408abcc62..4e612d20170a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -134,6 +134,37 @@ unsigned long iommu_num_pages(unsigned long addr, unsigned long len)
 EXPORT_SYMBOL(iommu_num_pages);
 #endif
 
+void *dma_generic_alloc_coherent(struct device *dev, size_t size,
+				 dma_addr_t *dma_addr, gfp_t flag)
+{
+	unsigned long dma_mask;
+	struct page *page;
+	dma_addr_t addr;
+
+	dma_mask = dma_alloc_coherent_mask(dev, flag);
+
+	flag |= __GFP_ZERO;
+again:
+	page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
+	if (!page)
+		return NULL;
+
+	addr = page_to_phys(page);
+	if (!is_buffer_dma_capable(dma_mask, addr, size)) {
+		__free_pages(page, get_order(size));
+
+		if (dma_mask < DMA_32BIT_MASK && !(flag & GFP_DMA)) {
+			flag = (flag & ~GFP_DMA32) | GFP_DMA;
+			goto again;
+		}
+
+		return NULL;
+	}
+
+	*dma_addr = addr;
+	return page_address(page);
+}
+
 /*
  * See <Documentation/x86_64/boot-options.txt> for the iommu kernel parameter
  * documentation.

commit afa9fdc2f5f8e4d98f3e77bfa204412cbc181346
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Sat Sep 20 01:23:30 2008 +0900

    iommu: remove fullflush and nofullflush in IOMMU generic option
    
    This patch against tip/x86/iommu virtually reverts
    2842e5bf3115193f05dc9dac20f940e7abf44c1a. But just reverting the
    commit breaks AMD IOMMU so this patch also includes some fixes.
    
    The above commit adds new two options to x86 IOMMU generic kernel boot
    options, fullflush and nofullflush. But such change that affects all
    the IOMMUs needs more discussion (all IOMMU parties need the chance to
    discuss it):
    
    http://lkml.org/lkml/2008/9/19/106
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index d2f2c0158dc1..0a1408abcc62 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -16,15 +16,6 @@ EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
 
-/*
- * If this is disabled the IOMMU will use an optimized flushing strategy
- * of only flushing when an mapping is reused. With it true the GART is
- * flushed for every mapping. Problem is that doing the lazy flush seems
- * to trigger bugs with some popular PCI cards, in particular 3ware (but
- * has been also also seen with Qlogic at least).
- */
-int iommu_fullflush;
-
 #ifdef CONFIG_IOMMU_DEBUG
 int panic_on_overflow __read_mostly = 1;
 int force_iommu __read_mostly = 1;
@@ -180,10 +171,6 @@ static __init int iommu_setup(char *p)
 		}
 		if (!strncmp(p, "nomerge", 7))
 			iommu_merge = 0;
-		if (!strncmp(p, "fullflush", 8))
-			iommu_fullflush = 1;
-		if (!strncmp(p, "nofullflush", 11))
-			iommu_fullflush = 0;
 		if (!strncmp(p, "forcesac", 8))
 			iommu_sac_force = 1;
 		if (!strncmp(p, "allowdac", 8))

commit 2842e5bf3115193f05dc9dac20f940e7abf44c1a
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Sep 18 15:23:43 2008 +0200

    x86: move GART TLB flushing options to generic code
    
    The GART currently implements the iommu=[no]fullflush command line
    parameters which influence its IO/TLB flushing strategy. This patch
    makes these parameters generic so that they can be used by the AMD IOMMU
    too.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0a1408abcc62..d2f2c0158dc1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -16,6 +16,15 @@ EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
 
+/*
+ * If this is disabled the IOMMU will use an optimized flushing strategy
+ * of only flushing when an mapping is reused. With it true the GART is
+ * flushed for every mapping. Problem is that doing the lazy flush seems
+ * to trigger bugs with some popular PCI cards, in particular 3ware (but
+ * has been also also seen with Qlogic at least).
+ */
+int iommu_fullflush;
+
 #ifdef CONFIG_IOMMU_DEBUG
 int panic_on_overflow __read_mostly = 1;
 int force_iommu __read_mostly = 1;
@@ -171,6 +180,10 @@ static __init int iommu_setup(char *p)
 		}
 		if (!strncmp(p, "nomerge", 7))
 			iommu_merge = 0;
+		if (!strncmp(p, "fullflush", 8))
+			iommu_fullflush = 1;
+		if (!strncmp(p, "nofullflush", 11))
+			iommu_fullflush = 0;
 		if (!strncmp(p, "forcesac", 8))
 			iommu_sac_force = 1;
 		if (!strncmp(p, "allowdac", 8))

commit 6c505ce3930c6a6b455cda53fab3e88ae44f8221
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Aug 19 16:32:45 2008 +0200

    x86: move dma_*_coherent functions to include file
    
    All the x86 DMA-API functions are defined in asm/dma-mapping.h. This patch
    moves the dma_*_coherent functions also to this header file because they are
    now small enough to do so.
    This is done as a separate patch because it also includes some renaming and
    restructuring of the dma-mapping.h file.
    
    Signed-off-by: Joerg Roedel <joerg.roede@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 613332b26e31..0a1408abcc62 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -41,11 +41,12 @@ EXPORT_SYMBOL(bad_dma_address);
 /* Dummy device used for NULL arguments (normally ISA). Better would
    be probably a smaller DMA mask, but this is bug-to-bug compatible
    to older i386. */
-struct device fallback_dev = {
+struct device x86_dma_fallback_dev = {
 	.bus_id = "fallback device",
 	.coherent_dma_mask = DMA_32BIT_MASK,
-	.dma_mask = &fallback_dev.coherent_dma_mask,
+	.dma_mask = &x86_dma_fallback_dev.coherent_dma_mask,
 };
+EXPORT_SYMBOL(x86_dma_fallback_dev);
 
 int dma_set_mask(struct device *dev, u64 mask)
 {
@@ -241,50 +242,6 @@ int dma_supported(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_supported);
 
-/*
- * Allocate memory for a coherent mapping.
- */
-	void *
-dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
-		   gfp_t gfp)
-{
-	struct dma_mapping_ops *ops = get_dma_ops(dev);
-	void *memory;
-
-	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
-		return memory;
-
-	if (!dev) {
-		dev = &fallback_dev;
-		gfp |= GFP_DMA;
-	}
-
-	if (ops->alloc_coherent)
-		return ops->alloc_coherent(dev, size,
-				dma_handle, gfp);
-	return NULL;
-}
-EXPORT_SYMBOL(dma_alloc_coherent);
-
-/*
- * Unmap coherent memory.
- * The caller must ensure that the device has finished accessing the mapping.
- */
-void dma_free_coherent(struct device *dev, size_t size,
-		       void *vaddr, dma_addr_t bus)
-{
-	struct dma_mapping_ops *ops = get_dma_ops(dev);
-
-	WARN_ON(irqs_disabled());       /* for portability */
-
-	if (dma_release_from_coherent(dev, get_order(size), vaddr))
-		return;
-
-	if (ops->free_coherent)
-		ops->free_coherent(dev, size, vaddr, bus);
-}
-EXPORT_SYMBOL(dma_free_coherent);
-
 static int __init pci_iommu_init(void)
 {
 	calgary_iommu_init();

commit c647c3bb2d16246a87f49035985ddb7c1eb030df
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Aug 19 16:32:44 2008 +0200

    x86: cleanup dma_*_coherent functions
    
    All dma_ops implementations support the alloc_coherent and free_coherent
    callbacks now. This allows a big simplification of the dma_alloc_coherent
    function which is done with this patch. The dma_free_coherent functions is also
    cleaned up and calls now the free_coherent callback of the dma_ops
    implementation.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 87d4d6964ec2..613332b26e31 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -241,33 +241,15 @@ int dma_supported(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_supported);
 
-/* Allocate DMA memory on node near device */
-static noinline struct page *
-dma_alloc_pages(struct device *dev, gfp_t gfp, unsigned order)
-{
-	int node;
-
-	node = dev_to_node(dev);
-
-	return alloc_pages_node(node, gfp, order);
-}
-
 /*
  * Allocate memory for a coherent mapping.
  */
-void *
+	void *
 dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		   gfp_t gfp)
 {
 	struct dma_mapping_ops *ops = get_dma_ops(dev);
-	void *memory = NULL;
-	struct page *page;
-	unsigned long dma_mask = 0;
-	dma_addr_t bus;
-	int noretry = 0;
-
-	/* ignore region specifiers */
-	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
+	void *memory;
 
 	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
 		return memory;
@@ -276,89 +258,10 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		dev = &fallback_dev;
 		gfp |= GFP_DMA;
 	}
-	dma_mask = dev->coherent_dma_mask;
-	if (dma_mask == 0)
-		dma_mask = (gfp & GFP_DMA) ? DMA_24BIT_MASK : DMA_32BIT_MASK;
-
-	/* Device not DMA able */
-	if (dev->dma_mask == NULL)
-		return NULL;
-
-	/* Don't invoke OOM killer or retry in lower 16MB DMA zone */
-	if (gfp & __GFP_DMA)
-		noretry = 1;
-
-#ifdef CONFIG_X86_64
-	/* Why <=? Even when the mask is smaller than 4GB it is often
-	   larger than 16MB and in this case we have a chance of
-	   finding fitting memory in the next higher zone first. If
-	   not retry with true GFP_DMA. -AK */
-	if (dma_mask <= DMA_32BIT_MASK && !(gfp & GFP_DMA)) {
-		gfp |= GFP_DMA32;
-		if (dma_mask < DMA_32BIT_MASK)
-			noretry = 1;
-	}
-#endif
 
- again:
-	page = dma_alloc_pages(dev,
-		noretry ? gfp | __GFP_NORETRY : gfp, get_order(size));
-	if (page == NULL)
-		return NULL;
-
-	{
-		int high, mmu;
-		bus = page_to_phys(page);
-		memory = page_address(page);
-		high = (bus + size) >= dma_mask;
-		mmu = high;
-		if (force_iommu && !(gfp & GFP_DMA))
-			mmu = 1;
-		else if (high) {
-			free_pages((unsigned long)memory,
-				   get_order(size));
-
-			/* Don't use the 16MB ZONE_DMA unless absolutely
-			   needed. It's better to use remapping first. */
-			if (dma_mask < DMA_32BIT_MASK && !(gfp & GFP_DMA)) {
-				gfp = (gfp & ~GFP_DMA32) | GFP_DMA;
-				goto again;
-			}
-
-			/* Let low level make its own zone decisions */
-			gfp &= ~(GFP_DMA32|GFP_DMA);
-
-			if (ops->alloc_coherent)
-				return ops->alloc_coherent(dev, size,
-							   dma_handle, gfp);
-			return NULL;
-		}
-
-		memset(memory, 0, size);
-		if (!mmu) {
-			*dma_handle = bus;
-			return memory;
-		}
-	}
-
-	if (ops->alloc_coherent) {
-		free_pages((unsigned long)memory, get_order(size));
-		gfp &= ~(GFP_DMA|GFP_DMA32);
-		return ops->alloc_coherent(dev, size, dma_handle, gfp);
-	}
-
-	if (ops->map_simple) {
-		*dma_handle = ops->map_simple(dev, virt_to_phys(memory),
-					      size,
-					      PCI_DMA_BIDIRECTIONAL);
-		if (*dma_handle != bad_dma_address)
-			return memory;
-	}
-
-	if (panic_on_overflow)
-		panic("dma_alloc_coherent: IOMMU overflow by %lu bytes\n",
-		      (unsigned long)size);
-	free_pages((unsigned long)memory, get_order(size));
+	if (ops->alloc_coherent)
+		return ops->alloc_coherent(dev, size,
+				dma_handle, gfp);
 	return NULL;
 }
 EXPORT_SYMBOL(dma_alloc_coherent);
@@ -368,17 +271,17 @@ EXPORT_SYMBOL(dma_alloc_coherent);
  * The caller must ensure that the device has finished accessing the mapping.
  */
 void dma_free_coherent(struct device *dev, size_t size,
-			 void *vaddr, dma_addr_t bus)
+		       void *vaddr, dma_addr_t bus)
 {
 	struct dma_mapping_ops *ops = get_dma_ops(dev);
 
-	int order = get_order(size);
-	WARN_ON(irqs_disabled());	/* for portability */
-	if (dma_release_from_coherent(dev, order, vaddr))
+	WARN_ON(irqs_disabled());       /* for portability */
+
+	if (dma_release_from_coherent(dev, get_order(size), vaddr))
 		return;
-	if (ops->unmap_single)
-		ops->unmap_single(dev, bus, size, 0);
-	free_pages((unsigned long)vaddr, order);
+
+	if (ops->free_coherent)
+		ops->free_coherent(dev, size, vaddr, bus);
 }
 EXPORT_SYMBOL(dma_free_coherent);
 

commit 6de9c70882ecdee63a652d493bf2353963bd4c22
Merge: d406d21d90dc 796aadeb1b2d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Aug 11 12:57:01 2008 +0200

    Merge branch 'linus' into x86/cleanups

commit 8978b74253280d59e97cf49a3ec2c0cbccd5b801
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Jul 29 13:38:53 2008 +0900

    generic, x86: fix add iommu_num_pages helper function
    
    This IOMMU helper function doesn't work for some architectures:
    
      http://marc.info/?l=linux-kernel&m=121699304403202&w=2
    
    It also breaks POWER and SPARC builds:
    
      http://marc.info/?l=linux-kernel&m=121730388001890&w=2
    
    Currently, only x86 IOMMUs use this so let's move it to x86 for
    now.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 8dbffb846de9..87d4d6964ec2 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -123,6 +123,14 @@ void __init pci_iommu_alloc(void)
 
 	pci_swiotlb_init();
 }
+
+unsigned long iommu_num_pages(unsigned long addr, unsigned long len)
+{
+	unsigned long size = roundup((addr & ~PAGE_MASK) + len, PAGE_SIZE);
+
+	return size >> PAGE_SHIFT;
+}
+EXPORT_SYMBOL(iommu_num_pages);
 #endif
 
 /*

commit cb28a1bbdb4790378e7366d6c9ee1d2340b84f92
Merge: b6d4f7e3ef25 f934fb19ef34
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 29 00:07:55 2008 +0200

    Merge branch 'linus' into core/generic-dma-coherent
    
    Conflicts:
    
            arch/x86/Kconfig
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 8d8bb39b9eba32dd70e87fd5ad5c5dd4ba118e06
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 25 19:44:49 2008 -0700

    dma-mapping: add the device argument to dma_mapping_error()
    
    Add per-device dma_mapping_ops support for CONFIG_X86_64 as POWER
    architecture does:
    
    This enables us to cleanly fix the Calgary IOMMU issue that some devices
    are not behind the IOMMU (http://lkml.org/lkml/2008/5/8/423).
    
    I think that per-device dma_mapping_ops support would be also helpful for
    KVM people to support PCI passthrough but Andi thinks that this makes it
    difficult to support the PCI passthrough (see the above thread).  So I
    CC'ed this to KVM camp.  Comments are appreciated.
    
    A pointer to dma_mapping_ops to struct dev_archdata is added.  If the
    pointer is non NULL, DMA operations in asm/dma-mapping.h use it.  If it's
    NULL, the system-wide dma_ops pointer is used as before.
    
    If it's useful for KVM people, I plan to implement a mechanism to register
    a hook called when a new pci (or dma capable) device is created (it works
    with hot plugging).  It enables IOMMUs to set up an appropriate
    dma_mapping_ops per device.
    
    The major obstacle is that dma_mapping_error doesn't take a pointer to the
    device unlike other DMA operations.  So x86 can't have dma_mapping_ops per
    device.  Note all the POWER IOMMUs use the same dma_mapping_error function
    so this is not a problem for POWER but x86 IOMMUs use different
    dma_mapping_error functions.
    
    The first patch adds the device argument to dma_mapping_error.  The patch
    is trivial but large since it touches lots of drivers and dma-mapping.h in
    all the architecture.
    
    This patch:
    
    dma_mapping_error() doesn't take a pointer to the device unlike other DMA
    operations.  So we can't have dma_mapping_ops per device.
    
    Note that POWER already has dma_mapping_ops per device but all the POWER
    IOMMUs use the same dma_mapping_error function.  x86 IOMMUs use device
    argument.
    
    [akpm@linux-foundation.org: fix sge]
    [akpm@linux-foundation.org: fix svc_rdma]
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix bnx2x]
    [akpm@linux-foundation.org: fix s2io]
    [akpm@linux-foundation.org: fix pasemi_mac]
    [akpm@linux-foundation.org: fix sdhci]
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix sparc]
    [akpm@linux-foundation.org: fix ibmvscsi]
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: Muli Ben-Yehuda <muli@il.ibm.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Avi Kivity <avi@qumranet.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index cbecb05551bb..37544123896d 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -11,7 +11,7 @@
 
 static int forbid_dac __read_mostly;
 
-const struct dma_mapping_ops *dma_ops;
+struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
 static int iommu_sac_force __read_mostly;
@@ -312,6 +312,8 @@ static int dma_release_coherent(struct device *dev, int order, void *vaddr)
 
 int dma_supported(struct device *dev, u64 mask)
 {
+	struct dma_mapping_ops *ops = get_dma_ops(dev);
+
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {
 		dev_info(dev, "PCI: Disallowing DAC for device\n");
@@ -319,8 +321,8 @@ int dma_supported(struct device *dev, u64 mask)
 	}
 #endif
 
-	if (dma_ops->dma_supported)
-		return dma_ops->dma_supported(dev, mask);
+	if (ops->dma_supported)
+		return ops->dma_supported(dev, mask);
 
 	/* Copied from i386. Doesn't make much sense, because it will
 	   only work for pci_alloc_coherent.
@@ -367,6 +369,7 @@ void *
 dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		   gfp_t gfp)
 {
+	struct dma_mapping_ops *ops = get_dma_ops(dev);
 	void *memory = NULL;
 	struct page *page;
 	unsigned long dma_mask = 0;
@@ -435,8 +438,8 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 			/* Let low level make its own zone decisions */
 			gfp &= ~(GFP_DMA32|GFP_DMA);
 
-			if (dma_ops->alloc_coherent)
-				return dma_ops->alloc_coherent(dev, size,
+			if (ops->alloc_coherent)
+				return ops->alloc_coherent(dev, size,
 							   dma_handle, gfp);
 			return NULL;
 		}
@@ -448,14 +451,14 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 		}
 	}
 
-	if (dma_ops->alloc_coherent) {
+	if (ops->alloc_coherent) {
 		free_pages((unsigned long)memory, get_order(size));
 		gfp &= ~(GFP_DMA|GFP_DMA32);
-		return dma_ops->alloc_coherent(dev, size, dma_handle, gfp);
+		return ops->alloc_coherent(dev, size, dma_handle, gfp);
 	}
 
-	if (dma_ops->map_simple) {
-		*dma_handle = dma_ops->map_simple(dev, virt_to_phys(memory),
+	if (ops->map_simple) {
+		*dma_handle = ops->map_simple(dev, virt_to_phys(memory),
 					      size,
 					      PCI_DMA_BIDIRECTIONAL);
 		if (*dma_handle != bad_dma_address)
@@ -477,12 +480,14 @@ EXPORT_SYMBOL(dma_alloc_coherent);
 void dma_free_coherent(struct device *dev, size_t size,
 			 void *vaddr, dma_addr_t bus)
 {
+	struct dma_mapping_ops *ops = get_dma_ops(dev);
+
 	int order = get_order(size);
 	WARN_ON(irqs_disabled());	/* for portability */
 	if (dma_release_coherent(dev, order, vaddr))
 		return;
-	if (dma_ops->unmap_single)
-		dma_ops->unmap_single(dev, bus, size, 0);
+	if (ops->unmap_single)
+		ops->unmap_single(dev, bus, size, 0);
 	free_pages((unsigned long)vaddr, order);
 }
 EXPORT_SYMBOL(dma_free_coherent);

commit 1ddb5518052e4e28ab489237443f7443b3fd69ca
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Jul 25 16:48:55 2008 +0200

    x86: convert pci-dma.c from round_up to roundup
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index cbecb05551bb..88ddd04cfa98 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -82,7 +82,7 @@ void __init dma32_reserve_bootmem(void)
 	 * using 512M as goal
 	 */
 	align = 64ULL<<20;
-	size = round_up(dma32_bootmem_size, align);
+	size = roundup(dma32_bootmem_size, align);
 	dma32_bootmem_ptr = __alloc_bootmem_nopanic(size, align,
 				 512ULL<<20);
 	if (dma32_bootmem_ptr)

commit fc3a8828b139c24aade3f9d608775e36c248f8f5
Author: Greg Kroah-Hartman <gregkh@suse.de>
Date:   Fri May 2 06:02:41 2008 +0200

    driver core: fix a lot of printk usages of bus_id
    
    We have the dev_printk() variants for this kind of thing, use them
    instead of directly trying to access the bus_id field of struct device.
    
    This is done in order to remove bus_id entirely.
    
    Cc: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index a4213c00dffc..cbecb05551bb 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -314,8 +314,7 @@ int dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {
-		printk(KERN_INFO "PCI: Disallowing DAC for device %s\n",
-				 dev->bus_id);
+		dev_info(dev, "PCI: Disallowing DAC for device\n");
 		return 0;
 	}
 #endif
@@ -342,8 +341,7 @@ int dma_supported(struct device *dev, u64 mask)
 	   type. Normally this doesn't make any difference, but gives
 	   more gentle handling of IOMMU overflow. */
 	if (iommu_sac_force && (mask >= DMA_40BIT_MASK)) {
-		printk(KERN_INFO "%s: Force SAC with mask %Lx\n",
-				 dev->bus_id, mask);
+		dev_info(dev, "Force SAC with mask %Lx\n", mask);
 		return 0;
 	}
 

commit acee709cab689ec7703770e8b8cb5cc3a4abcb31
Merge: 33a37eb411d1 5ff4789d045c 35b680557f95 c4dc59ae7af8 7edf8891ad7a 9781f39fd209 48fe4a76e27d be54f9d1c8df 77e442461c74 caadbdce240c 5e5a29bf2624 e3a61b0a8c0e fec0962e0bed fab3b58d3b24 f2ba93929fdb 48ae74443403 3cabf37f6167 7019cc2dd6fa 2ddf9b7b3e66 e66d90fb4abd
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 21 16:37:17 2008 +0200

    Merge branches 'x86/urgent', 'x86/amd-iommu', 'x86/apic', 'x86/cleanups', 'x86/core', 'x86/cpu', 'x86/fixmap', 'x86/gart', 'x86/kprobes', 'x86/memtest', 'x86/modules', 'x86/nmi', 'x86/pat', 'x86/reboot', 'x86/setup', 'x86/step', 'x86/unify-pci', 'x86/uv', 'x86/xen' and 'xen-64bit' into x86/for-linus

commit 08e1a13e7d14ba5d6a22bf4b8c6e11128d3bcdfe
Author: Jan Beulich <jbeulich@novell.com>
Date:   Fri Jul 18 13:44:16 2008 +0100

    x86: reduce forbid_dac's visibility
    
    It's not used anywhere outside its declaring file.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 8467ec2320f1..702714bd1511 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -9,8 +9,7 @@
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 
-int forbid_dac __read_mostly;
-EXPORT_SYMBOL(forbid_dac);
+static int forbid_dac __read_mostly;
 
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);

commit f6dc8ccaab6d8f63cbae1e6c73fe972b26f5376c
Merge: 323ec001c6bb 5b664cb235e9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 18 21:13:20 2008 +0200

    Merge branch 'linus' into core/generic-dma-coherent
    
    Conflicts:
    
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit be54f9d1c8df93c4998e134a306652caaa58f67f
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 11 10:23:45 2008 +0900

    x86: remove ifdef CONFIG_SWIOTLB in pci-dma.c
    
    As other IOMMUs do, this puts dummy pci_swiotlb_init() in swiotlb.h
    and remove ifdef CONFIG_SWIOTLB in pci-dma.c.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f16cbbe424a1..d12945de0565 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -122,9 +122,7 @@ void __init pci_iommu_alloc(void)
 
 	amd_iommu_detect();
 
-#ifdef CONFIG_SWIOTLB
 	pci_swiotlb_init();
-#endif
 }
 #endif
 

commit b8b48326f312026af12799917383c54c25d05482
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 11 10:23:44 2008 +0900

    x86: remove ifdef CONFIG_CALGARY_IOMMU in pci-dma.c
    
    asm-x86/calgary.h has dummy calgary_iommu_init() and detect_calgary()
    in !CONFIG_CALGARY_IOMMU case. So we don't need ifdef
    CONFIG_CALGARY_IOMMU in pci-dma.c.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Cc: Alexis Bruemmer <alexisb@us.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index dd57c5bbe2da..f16cbbe424a1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -116,9 +116,7 @@ void __init pci_iommu_alloc(void)
 	 */
 	gart_iommu_hole_init();
 
-#ifdef CONFIG_CALGARY_IOMMU
 	detect_calgary();
-#endif
 
 	detect_intel_iommu();
 
@@ -496,9 +494,7 @@ EXPORT_SYMBOL(dma_free_coherent);
 
 static int __init pci_iommu_init(void)
 {
-#ifdef CONFIG_CALGARY_IOMMU
 	calgary_iommu_init();
-#endif
 
 	intel_iommu_init();
 

commit ac7ded2adb2e43152fe7385ddd53bf45f5c92285
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 11 10:23:43 2008 +0900

    x86: remove ifdef CONFIG_GART_IOMMU in pci-dma.c
    
    Our way to handle gart_* functions for CONFIG_GART_IOMMU and
    !CONFIG_GART_IOMMU cases is inconsistent.
    
    We have some dummy gart_* functions in !CONFIG_GART_IOMMU case and
    also use ifdef CONFIG_GART_IOMMU tricks in pci-dma.c to call some
    gart_* functions in only CONFIG_GART_IOMMU case.
    
    This patch removes ifdef CONFIG_GART_IOMMU in pci-dma.c and always use
    dummy gart_* functions in iommu.h.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f581a4b63b43..dd57c5bbe2da 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -114,9 +114,7 @@ void __init pci_iommu_alloc(void)
 	 * The order of these functions is important for
 	 * fall-back/fail-over reasons
 	 */
-#ifdef CONFIG_GART_IOMMU
 	gart_iommu_hole_init();
-#endif
 
 #ifdef CONFIG_CALGARY_IOMMU
 	detect_calgary();
@@ -184,9 +182,7 @@ static __init int iommu_setup(char *p)
 			swiotlb = 1;
 #endif
 
-#ifdef CONFIG_GART_IOMMU
 		gart_parse_options(p);
-#endif
 
 #ifdef CONFIG_CALGARY_IOMMU
 		if (!strncmp(p, "calgary", 7))
@@ -508,9 +504,7 @@ static int __init pci_iommu_init(void)
 
 	amd_iommu_init();
 
-#ifdef CONFIG_GART_IOMMU
 	gart_iommu_init();
-#endif
 
 	no_iommu_init();
 	return 0;

commit 46a7fa270afbe5fddc6042a598cfe22977b0e989
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Fri Jul 11 10:23:42 2008 +0900

    x86: make only GART code include gart.h
    
    gart.h has only GART-specific stuff. Only GART code needs it. Other
    IOMMU stuff should include iommu.h instead of gart.h.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Muli Ben-Yehuda <muli@il.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 8467ec2320f1..f581a4b63b43 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -5,7 +5,7 @@
 
 #include <asm/proto.h>
 #include <asm/dma.h>
-#include <asm/gart.h>
+#include <asm/iommu.h>
 #include <asm/calgary.h>
 #include <asm/amd_iommu.h>
 

commit c987d12f8455b19b3b057d63bac3de161bd809fc
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Jun 24 22:14:09 2008 -0700

    x86: remove end_pfn in 64bit
    
    and use max_pfn directly.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index cb0bdf440715..8467ec2320f1 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -75,7 +75,7 @@ early_param("dma32_size", parse_dma32_size_opt);
 void __init dma32_reserve_bootmem(void)
 {
 	unsigned long size, align;
-	if (end_pfn <= MAX_DMA32_PFN)
+	if (max_pfn <= MAX_DMA32_PFN)
 		return;
 
 	/*
@@ -94,7 +94,7 @@ void __init dma32_reserve_bootmem(void)
 static void __init dma32_free_bootmem(void)
 {
 
-	if (end_pfn <= MAX_DMA32_PFN)
+	if (max_pfn <= MAX_DMA32_PFN)
 		return;
 
 	if (!dma32_bootmem_ptr)

commit 58cf35228fec541418cc3bd781d6c069d904815e
Merge: 3c1ca43fafea c1f64a58003f 28f73e51d0f6 b664d6bbeedd f294a8ce211b 45fdc3a7624a 8b7fd21511f9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 8 09:46:15 2008 +0200

    Merge branches 'x86/mmio', 'x86/delay', 'x86/idle', 'x86/oprofile', 'x86/debug', 'x86/ptrace' and 'x86/amd-iommu' into x86/devel

commit 6924d1ab8b7bbe5ab416713f5701b3316b2df85b
Merge: 4e78c91abe1a 25556c1699ad b764a15f6799 437a0a54eea7 41b3eae669fb 84e65b0a84a2 684eb0163a98 93022136fff9 5cb04df8d3f0 44974c8fc1d7 48cf937f48f6 205f93288093 c54f9da1c8ce 0ed368c71aa6 b478458aeebf 2d144e63098b 607baf1f4ef9 33af9039cbf6 3557b18fcbe0 63687a528c39 009b9fc98ddd f6477cc76c73 e6b0edef3453 400d34944c4a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 8 09:16:56 2008 +0200

    Merge branches 'x86/numa-fixes', 'x86/apic', 'x86/apm', 'x86/bitops', 'x86/build', 'x86/cleanups', 'x86/cpa', 'x86/cpu', 'x86/defconfig', 'x86/gart', 'x86/i8259', 'x86/intel', 'x86/irqstats', 'x86/kconfig', 'x86/ldt', 'x86/mce', 'x86/memtest', 'x86/pat', 'x86/ptemask', 'x86/resumetrace', 'x86/threadinfo', 'x86/timers', 'x86/vdso' and 'x86/xen' into x86/devel

commit 323ec001c6bb98eeabb5abbdbb8c8055d9496554
Author: Dmitry Baryshkov <dbaryshkov@gmail.com>
Date:   Sun Jun 29 14:19:31 2008 +0400

    x86: use generic per-device dma coherent allocator
    
    Signed-off-by: Dmitry Baryshkov <dbaryshkov@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index dc00a1331ace..b75c81a8d3e6 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -197,124 +197,6 @@ static __init int iommu_setup(char *p)
 }
 early_param("iommu", iommu_setup);
 
-#ifdef CONFIG_X86_32
-int dma_declare_coherent_memory(struct device *dev, dma_addr_t bus_addr,
-				dma_addr_t device_addr, size_t size, int flags)
-{
-	void __iomem *mem_base = NULL;
-	int pages = size >> PAGE_SHIFT;
-	int bitmap_size = BITS_TO_LONGS(pages) * sizeof(long);
-
-	if ((flags & (DMA_MEMORY_MAP | DMA_MEMORY_IO)) == 0)
-		goto out;
-	if (!size)
-		goto out;
-	if (dev->dma_mem)
-		goto out;
-
-	/* FIXME: this routine just ignores DMA_MEMORY_INCLUDES_CHILDREN */
-
-	mem_base = ioremap(bus_addr, size);
-	if (!mem_base)
-		goto out;
-
-	dev->dma_mem = kzalloc(sizeof(struct dma_coherent_mem), GFP_KERNEL);
-	if (!dev->dma_mem)
-		goto out;
-	dev->dma_mem->bitmap = kzalloc(bitmap_size, GFP_KERNEL);
-	if (!dev->dma_mem->bitmap)
-		goto free1_out;
-
-	dev->dma_mem->virt_base = mem_base;
-	dev->dma_mem->device_base = device_addr;
-	dev->dma_mem->size = pages;
-	dev->dma_mem->flags = flags;
-
-	if (flags & DMA_MEMORY_MAP)
-		return DMA_MEMORY_MAP;
-
-	return DMA_MEMORY_IO;
-
- free1_out:
-	kfree(dev->dma_mem);
- out:
-	if (mem_base)
-		iounmap(mem_base);
-	return 0;
-}
-EXPORT_SYMBOL(dma_declare_coherent_memory);
-
-void dma_release_declared_memory(struct device *dev)
-{
-	struct dma_coherent_mem *mem = dev->dma_mem;
-
-	if (!mem)
-		return;
-	dev->dma_mem = NULL;
-	iounmap(mem->virt_base);
-	kfree(mem->bitmap);
-	kfree(mem);
-}
-EXPORT_SYMBOL(dma_release_declared_memory);
-
-void *dma_mark_declared_memory_occupied(struct device *dev,
-					dma_addr_t device_addr, size_t size)
-{
-	struct dma_coherent_mem *mem = dev->dma_mem;
-	int pos, err;
-	int pages = (size + (device_addr & ~PAGE_MASK) + PAGE_SIZE - 1);
-
-	pages >>= PAGE_SHIFT;
-
-	if (!mem)
-		return ERR_PTR(-EINVAL);
-
-	pos = (device_addr - mem->device_base) >> PAGE_SHIFT;
-	err = bitmap_allocate_region(mem->bitmap, pos, get_order(pages));
-	if (err != 0)
-		return ERR_PTR(err);
-	return mem->virt_base + (pos << PAGE_SHIFT);
-}
-EXPORT_SYMBOL(dma_mark_declared_memory_occupied);
-
-static int dma_alloc_from_coherent_mem(struct device *dev, ssize_t size,
-				       dma_addr_t *dma_handle, void **ret)
-{
-	struct dma_coherent_mem *mem = dev ? dev->dma_mem : NULL;
-	int order = get_order(size);
-
-	if (mem) {
-		int page = bitmap_find_free_region(mem->bitmap, mem->size,
-						     order);
-		if (page >= 0) {
-			*dma_handle = mem->device_base + (page << PAGE_SHIFT);
-			*ret = mem->virt_base + (page << PAGE_SHIFT);
-			memset(*ret, 0, size);
-		}
-		if (mem->flags & DMA_MEMORY_EXCLUSIVE)
-			*ret = NULL;
-	}
-	return (mem != NULL);
-}
-
-static int dma_release_coherent(struct device *dev, int order, void *vaddr)
-{
-	struct dma_coherent_mem *mem = dev ? dev->dma_mem : NULL;
-
-	if (mem && vaddr >= mem->virt_base && vaddr <
-		   (mem->virt_base + (mem->size << PAGE_SHIFT))) {
-		int page = (vaddr - mem->virt_base) >> PAGE_SHIFT;
-
-		bitmap_release_region(mem->bitmap, page, order);
-		return 1;
-	}
-	return 0;
-}
-#else
-#define dma_alloc_from_coherent_mem(dev, size, handle, ret) (0)
-#define dma_release_coherent(dev, order, vaddr) (0)
-#endif /* CONFIG_X86_32 */
-
 int dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI
@@ -383,7 +265,7 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	/* ignore region specifiers */
 	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
 
-	if (dma_alloc_from_coherent_mem(dev, size, dma_handle, &memory))
+	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
 		return memory;
 
 	if (!dev) {
@@ -486,7 +368,7 @@ void dma_free_coherent(struct device *dev, size_t size,
 {
 	int order = get_order(size);
 	WARN_ON(irqs_disabled());	/* for portability */
-	if (dma_release_coherent(dev, order, vaddr))
+	if (dma_release_from_coherent(dev, order, vaddr))
 		return;
 	if (dma_ops->unmap_single)
 		dma_ops->unmap_single(dev, bus, size, 0);

commit a69ca3401821b7312cb7ec939a8814240fd7b9b3
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Jun 26 21:28:08 2008 +0200

    AMD_IOMMU: call detect and initialization functions from dma code
    
    This patch adds the function calls to initialize the AMD IOMMU hardware and
    dma_ops to the generic DMA code for the x86 architecture.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: bhavna.sarathy@amd.com
    Cc: Sebastian.Biemueller@amd.com
    Cc: robert.richter@amd.com
    Cc: joro@8bytes.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index dc00a1331ace..dea01672f1f4 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -7,6 +7,7 @@
 #include <asm/dma.h>
 #include <asm/gart.h>
 #include <asm/calgary.h>
+#include <asm/amd_iommu.h>
 
 int forbid_dac __read_mostly;
 EXPORT_SYMBOL(forbid_dac);
@@ -122,6 +123,8 @@ void __init pci_iommu_alloc(void)
 
 	detect_intel_iommu();
 
+	amd_iommu_detect();
+
 #ifdef CONFIG_SWIOTLB
 	pci_swiotlb_init();
 #endif
@@ -502,6 +505,8 @@ static int __init pci_iommu_init(void)
 
 	intel_iommu_init();
 
+	amd_iommu_init();
+
 #ifdef CONFIG_GART_IOMMU
 	gart_iommu_init();
 #endif

commit 33ee375b2ea5dd11581a57d67bedd0ca39b19a5e
Merge: 6703f6d10dcd 066519068ad2
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jun 16 11:27:18 2008 +0200

    Merge branch 'linus' into x86/gart

commit 1791a78c0b10fe548bf08a2ed7f84a4ea1385430
Merge: bf07dc864902 066519068ad2
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jun 16 11:17:50 2008 +0200

    Merge branch 'linus' into x86/cleanups

commit b7f09ae583c49d28b2796d2fa5893dcf822e3a10
Author: Miquel van Smoorenburg <mikevs@xs4all.net>
Date:   Thu Jun 5 18:14:44 2008 +0200

    x86, pci-dma.c: don't always add __GFP_NORETRY to gfp
    
    Currently arch/x86/kernel/pci-dma.c always adds __GFP_NORETRY
    to the allocation flags, because it wants to be reasonably
    sure not to deadlock when calling alloc_pages().
    
    But really that should only be done in two cases:
    - when allocating memory in the lower 16 MB DMA zone.
      If there's no free memory there, waiting or OOM killing is of no use
    - when optimistically trying an allocation in the DMA32 zone
      when dma_mask < DMA_32BIT_MASK hoping that the allocation
      happens to fall within the limits of the dma_mask
    
    Also blindly adding __GFP_NORETRY to the the gfp variable might
    not be a good idea since we then also use it when calling
    dma_ops->alloc_coherent(). Clearing it might also not be a
    good idea, dma_alloc_coherent()'s caller might have set it
    on purpose. The gfp variable should not be clobbered.
    
    [ mingo@elte.hu: converted to delta patch ontop of previous version. ]
    
    Signed-off-by: Miquel van Smoorenburg <miquels@cistron.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 069e843f0b93..dc00a1331ace 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -378,6 +378,7 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	struct page *page;
 	unsigned long dma_mask = 0;
 	dma_addr_t bus;
+	int noretry = 0;
 
 	/* ignore region specifiers */
 	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
@@ -397,19 +398,25 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	if (dev->dma_mask == NULL)
 		return NULL;
 
+	/* Don't invoke OOM killer or retry in lower 16MB DMA zone */
+	if (gfp & __GFP_DMA)
+		noretry = 1;
+
 #ifdef CONFIG_X86_64
 	/* Why <=? Even when the mask is smaller than 4GB it is often
 	   larger than 16MB and in this case we have a chance of
 	   finding fitting memory in the next higher zone first. If
 	   not retry with true GFP_DMA. -AK */
-	if (dma_mask <= DMA_32BIT_MASK && !(gfp & GFP_DMA))
+	if (dma_mask <= DMA_32BIT_MASK && !(gfp & GFP_DMA)) {
 		gfp |= GFP_DMA32;
+		if (dma_mask < DMA_32BIT_MASK)
+			noretry = 1;
+	}
 #endif
 
  again:
-	/* Don't invoke OOM killer or retry in lower 16MB DMA zone */
 	page = dma_alloc_pages(dev,
-		(gfp & GFP_DMA) ? gfp | __GFP_NORETRY : gfp, get_order(size));
+		noretry ? gfp | __GFP_NORETRY : gfp, get_order(size));
 	if (page == NULL)
 		return NULL;
 

commit db9f600b96c16bb3c7f094e294fbdd370226ad86
Author: Miquel van Smoorenburg <mikevs@xs4all.net>
Date:   Wed May 28 10:31:25 2008 +0200

    x86: pci-dma.c: use __GFP_NO_OOM instead of __GFP_NORETRY
    
    On Wed, 2008-05-28 at 04:47 +0200, Andi Kleen wrote:
    > > So...  why not just remove the setting of __GFP_NORETRY?  Why is it
    > > wrong to oom-kill things in this case?
    >
    > When the 16MB zone overflows (which can be common in some workloads)
    > calling the OOM killer is pretty useless because it has barely any
    > real user data [only exception would be the "only 16MB" case Alan
    > mentioned]. Killing random processes in this case is bad.
    >
    > I think for 16MB __GFP_NORETRY is ok because there should be
    > nothing freeable in there so looping is useless. Only exception would be the
    > "only 16MB total" case again but I'm not sure 2.6 supports that at all
    > on x86.
    >
    > On the other hand d_a_c() does more allocations than just 16MB, especially
    > on 64bit and the other zones need different strategies.
    
    Okay, so how about this then ?
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index c5ef1af8e79d..069e843f0b93 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -397,9 +397,6 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	if (dev->dma_mask == NULL)
 		return NULL;
 
-	/* Don't invoke OOM killer */
-	gfp |= __GFP_NORETRY;
-
 #ifdef CONFIG_X86_64
 	/* Why <=? Even when the mask is smaller than 4GB it is often
 	   larger than 16MB and in this case we have a chance of
@@ -410,7 +407,9 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 #endif
 
  again:
-	page = dma_alloc_pages(dev, gfp, get_order(size));
+	/* Don't invoke OOM killer or retry in lower 16MB DMA zone */
+	page = dma_alloc_pages(dev,
+		(gfp & GFP_DMA) ? gfp | __GFP_NORETRY : gfp, get_order(size));
 	if (page == NULL)
 		return NULL;
 

commit 311f83494830fec17f086401a5b43984bb447cd2
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon May 12 15:43:37 2008 +0200

    x86: kernel/pci-dma.c cleanups
    
    This patch contains the following cleanups:
    - make the following needlessly global code static:
      - dma_alloc_pages()
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index c5ef1af8e79d..5bc29ca4196e 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -357,7 +357,7 @@ int dma_supported(struct device *dev, u64 mask)
 EXPORT_SYMBOL(dma_supported);
 
 /* Allocate DMA memory on node near device */
-noinline struct page *
+static noinline struct page *
 dma_alloc_pages(struct device *dev, gfp_t gfp, unsigned order)
 {
 	int node;

commit 538f0fd0f210c2ce5c585799f18d0e5c7cf6155e
Merge: 3bb6fbf9969a f26a39889179
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat May 17 17:12:24 2008 +0200

    Merge branch 'linus' into x86/gart

commit 4a367f3a9dbf2e7ffcee4702203479809236ee6e
Author: Takashi Iwai <tiwai@suse.de>
Date:   Fri May 9 08:06:55 2008 +0200

    x86/PCI: fix broken ISA DMA
    
    Rene Herman reported:
    
    > commit 8779f2fc3b84ebb6c5181fb13d702e9944c16069
    >
    > "x86: don't try to allocate from DMA zone at first"
    >
    > breaks all of ISA DMA. Or all of ALSA ISA DMA at least. All
    > ISA soundcards are silent following that commit -- no error
    > messages, everything appears fine, just silence.
    
    That patch is buggy. We had an implicit assumption that
    dev = NULL for ISA devices that require 24bit DMA.
    
    The recent work on x86 dma_alloc_coherent() breaks the ISA DMA buffer
    allocation, which is represented by "dev = NULL" and requires 24bit
    DMA implicitly.
    
    Bisected-by: Rene Herman <rene.herman@keyaccess.nl>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0c37f16b6950..c5ef1af8e79d 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -385,11 +385,13 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	if (dma_alloc_from_coherent_mem(dev, size, dma_handle, &memory))
 		return memory;
 
-	if (!dev)
+	if (!dev) {
 		dev = &fallback_dev;
+		gfp |= GFP_DMA;
+	}
 	dma_mask = dev->coherent_dma_mask;
 	if (dma_mask == 0)
-		dma_mask = DMA_32BIT_MASK;
+		dma_mask = (gfp & GFP_DMA) ? DMA_24BIT_MASK : DMA_32BIT_MASK;
 
 	/* Device not DMA able */
 	if (dev->dma_mask == NULL)
@@ -403,7 +405,7 @@ dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
 	   larger than 16MB and in this case we have a chance of
 	   finding fitting memory in the next higher zone first. If
 	   not retry with true GFP_DMA. -AK */
-	if (dma_mask <= DMA_32BIT_MASK)
+	if (dma_mask <= DMA_32BIT_MASK && !(gfp & GFP_DMA))
 		gfp |= GFP_DMA32;
 #endif
 

commit 330fce23dab6e6a3d1979e55f27aba4c0c301331
Author: Yinghai Lu <yhlu.kernel.send@gmail.com>
Date:   Sat Apr 19 01:31:45 2008 -0700

    x86: reserve dma32 early for gart fix
    
    we can use free_bootmem() directly.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1a017f00e867..81862d0c7a9a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -92,7 +92,6 @@ void __init dma32_reserve_bootmem(void)
 }
 static void __init dma32_free_bootmem(void)
 {
-	int node;
 
 	if (end_pfn <= MAX_DMA32_PFN)
 		return;
@@ -100,9 +99,7 @@ static void __init dma32_free_bootmem(void)
 	if (!dma32_bootmem_ptr)
 		return;
 
-	for_each_online_node(node)
-		free_bootmem_node(NODE_DATA(node), __pa(dma32_bootmem_ptr),
-				  dma32_bootmem_size);
+	free_bootmem(__pa(dma32_bootmem_ptr), dma32_bootmem_size);
 
 	dma32_bootmem_ptr = NULL;
 	dma32_bootmem_size = 0;

commit 7677b2ef6c0c4fddc84f6473f3863f40eb71821b
Author: Yinghai Lu <yhlu.kernel.send@gmail.com>
Date:   Mon Apr 14 20:40:37 2008 -0700

    x86_64: allocate gart aperture from 512M
    
    because we try to reserve dma32 early, so we have chance to get aperture
    from 64M.
    
    with some sequence aperture allocated from RAM, could become E820_RESERVED.
    
    and then if doing a kexec with a big kernel that uncompressed size is above
    64M we could have a range conflict with still using gart.
    
    So allocate gart aperture from 512M instead.
    
    Also change the fallback_aper_order to 5, because we don't have chance to get
    2G or 4G aperture.
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 0c37f16b6950..1a017f00e867 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -77,10 +77,14 @@ void __init dma32_reserve_bootmem(void)
 	if (end_pfn <= MAX_DMA32_PFN)
 		return;
 
+	/*
+	 * check aperture_64.c allocate_aperture() for reason about
+	 * using 512M as goal
+	 */
 	align = 64ULL<<20;
 	size = round_up(dma32_bootmem_size, align);
 	dma32_bootmem_ptr = __alloc_bootmem_nopanic(size, align,
-				 __pa(MAX_DMA_ADDRESS));
+				 512ULL<<20);
 	if (dma32_bootmem_ptr)
 		dma32_bootmem_size = size;
 	else

commit b4cdc4300de6ff7b8b366f23bed17c7d59c8117c
Author: Dmitri Vorobiev <dmitri.vorobiev@gmail.com>
Date:   Mon Apr 28 03:15:58 2008 +0400

    x86: iommu_sac_force can become static
    
    The iommu_sac_force variable is needlessly defined global,
    and this patch makes it static. Additionally, this variable
    needs not be explicitly initialized.
    
    Signed-off-by: Dmitri Vorobiev <dmitri.vorobiev@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 388b113a7d88..0c37f16b6950 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -14,7 +14,7 @@ EXPORT_SYMBOL(forbid_dac);
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
-int iommu_sac_force __read_mostly = 0;
+static int iommu_sac_force __read_mostly;
 
 #ifdef CONFIG_IOMMU_DEBUG
 int panic_on_overflow __read_mostly = 1;

commit 098cb7f27ed69276e4db560a444b94b982e4bb8f
Author: Glauber Costa <gcosta@redhat.com>
Date:   Wed Apr 9 13:18:10 2008 -0300

    x86: integrate pci-dma.c
    
    The code in pci-dma_{32,64}.c are now sufficiently
    close to each other. We merge them in pci-dma.c.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 00527e74e49c..388b113a7d88 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -38,6 +38,15 @@ EXPORT_SYMBOL(iommu_bio_merge);
 dma_addr_t bad_dma_address __read_mostly = 0;
 EXPORT_SYMBOL(bad_dma_address);
 
+/* Dummy device used for NULL arguments (normally ISA). Better would
+   be probably a smaller DMA mask, but this is bug-to-bug compatible
+   to older i386. */
+struct device fallback_dev = {
+	.bus_id = "fallback device",
+	.coherent_dma_mask = DMA_32BIT_MASK,
+	.dma_mask = &fallback_dev.coherent_dma_mask,
+};
+
 int dma_set_mask(struct device *dev, u64 mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, mask))
@@ -267,6 +276,43 @@ void *dma_mark_declared_memory_occupied(struct device *dev,
 	return mem->virt_base + (pos << PAGE_SHIFT);
 }
 EXPORT_SYMBOL(dma_mark_declared_memory_occupied);
+
+static int dma_alloc_from_coherent_mem(struct device *dev, ssize_t size,
+				       dma_addr_t *dma_handle, void **ret)
+{
+	struct dma_coherent_mem *mem = dev ? dev->dma_mem : NULL;
+	int order = get_order(size);
+
+	if (mem) {
+		int page = bitmap_find_free_region(mem->bitmap, mem->size,
+						     order);
+		if (page >= 0) {
+			*dma_handle = mem->device_base + (page << PAGE_SHIFT);
+			*ret = mem->virt_base + (page << PAGE_SHIFT);
+			memset(*ret, 0, size);
+		}
+		if (mem->flags & DMA_MEMORY_EXCLUSIVE)
+			*ret = NULL;
+	}
+	return (mem != NULL);
+}
+
+static int dma_release_coherent(struct device *dev, int order, void *vaddr)
+{
+	struct dma_coherent_mem *mem = dev ? dev->dma_mem : NULL;
+
+	if (mem && vaddr >= mem->virt_base && vaddr <
+		   (mem->virt_base + (mem->size << PAGE_SHIFT))) {
+		int page = (vaddr - mem->virt_base) >> PAGE_SHIFT;
+
+		bitmap_release_region(mem->bitmap, page, order);
+		return 1;
+	}
+	return 0;
+}
+#else
+#define dma_alloc_from_coherent_mem(dev, size, handle, ret) (0)
+#define dma_release_coherent(dev, order, vaddr) (0)
 #endif /* CONFIG_X86_32 */
 
 int dma_supported(struct device *dev, u64 mask)
@@ -310,6 +356,135 @@ int dma_supported(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_supported);
 
+/* Allocate DMA memory on node near device */
+noinline struct page *
+dma_alloc_pages(struct device *dev, gfp_t gfp, unsigned order)
+{
+	int node;
+
+	node = dev_to_node(dev);
+
+	return alloc_pages_node(node, gfp, order);
+}
+
+/*
+ * Allocate memory for a coherent mapping.
+ */
+void *
+dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle,
+		   gfp_t gfp)
+{
+	void *memory = NULL;
+	struct page *page;
+	unsigned long dma_mask = 0;
+	dma_addr_t bus;
+
+	/* ignore region specifiers */
+	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
+
+	if (dma_alloc_from_coherent_mem(dev, size, dma_handle, &memory))
+		return memory;
+
+	if (!dev)
+		dev = &fallback_dev;
+	dma_mask = dev->coherent_dma_mask;
+	if (dma_mask == 0)
+		dma_mask = DMA_32BIT_MASK;
+
+	/* Device not DMA able */
+	if (dev->dma_mask == NULL)
+		return NULL;
+
+	/* Don't invoke OOM killer */
+	gfp |= __GFP_NORETRY;
+
+#ifdef CONFIG_X86_64
+	/* Why <=? Even when the mask is smaller than 4GB it is often
+	   larger than 16MB and in this case we have a chance of
+	   finding fitting memory in the next higher zone first. If
+	   not retry with true GFP_DMA. -AK */
+	if (dma_mask <= DMA_32BIT_MASK)
+		gfp |= GFP_DMA32;
+#endif
+
+ again:
+	page = dma_alloc_pages(dev, gfp, get_order(size));
+	if (page == NULL)
+		return NULL;
+
+	{
+		int high, mmu;
+		bus = page_to_phys(page);
+		memory = page_address(page);
+		high = (bus + size) >= dma_mask;
+		mmu = high;
+		if (force_iommu && !(gfp & GFP_DMA))
+			mmu = 1;
+		else if (high) {
+			free_pages((unsigned long)memory,
+				   get_order(size));
+
+			/* Don't use the 16MB ZONE_DMA unless absolutely
+			   needed. It's better to use remapping first. */
+			if (dma_mask < DMA_32BIT_MASK && !(gfp & GFP_DMA)) {
+				gfp = (gfp & ~GFP_DMA32) | GFP_DMA;
+				goto again;
+			}
+
+			/* Let low level make its own zone decisions */
+			gfp &= ~(GFP_DMA32|GFP_DMA);
+
+			if (dma_ops->alloc_coherent)
+				return dma_ops->alloc_coherent(dev, size,
+							   dma_handle, gfp);
+			return NULL;
+		}
+
+		memset(memory, 0, size);
+		if (!mmu) {
+			*dma_handle = bus;
+			return memory;
+		}
+	}
+
+	if (dma_ops->alloc_coherent) {
+		free_pages((unsigned long)memory, get_order(size));
+		gfp &= ~(GFP_DMA|GFP_DMA32);
+		return dma_ops->alloc_coherent(dev, size, dma_handle, gfp);
+	}
+
+	if (dma_ops->map_simple) {
+		*dma_handle = dma_ops->map_simple(dev, virt_to_phys(memory),
+					      size,
+					      PCI_DMA_BIDIRECTIONAL);
+		if (*dma_handle != bad_dma_address)
+			return memory;
+	}
+
+	if (panic_on_overflow)
+		panic("dma_alloc_coherent: IOMMU overflow by %lu bytes\n",
+		      (unsigned long)size);
+	free_pages((unsigned long)memory, get_order(size));
+	return NULL;
+}
+EXPORT_SYMBOL(dma_alloc_coherent);
+
+/*
+ * Unmap coherent memory.
+ * The caller must ensure that the device has finished accessing the mapping.
+ */
+void dma_free_coherent(struct device *dev, size_t size,
+			 void *vaddr, dma_addr_t bus)
+{
+	int order = get_order(size);
+	WARN_ON(irqs_disabled());	/* for portability */
+	if (dma_release_coherent(dev, order, vaddr))
+		return;
+	if (dma_ops->unmap_single)
+		dma_ops->unmap_single(dev, bus, size, 0);
+	free_pages((unsigned long)vaddr, order);
+}
+EXPORT_SYMBOL(dma_free_coherent);
 
 static int __init pci_iommu_init(void)
 {

commit cac67877d268f21da74d879a355247e4e25b5b5f
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:21:00 2008 -0300

    x86: move bad_dma_address
    
    It goes to pci-dma.c, and is removed from the arch-specific files.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 967dfcfa2ad2..00527e74e49c 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -35,6 +35,8 @@ int iommu_detected __read_mostly = 0;
 int iommu_bio_merge __read_mostly = 0;
 EXPORT_SYMBOL(iommu_bio_merge);
 
+dma_addr_t bad_dma_address __read_mostly = 0;
+EXPORT_SYMBOL(bad_dma_address);
 
 int dma_set_mask(struct device *dev, u64 mask)
 {

commit 8e8edc6401205da3000cc3dfa76f3fd28a21d73c
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:57 2008 -0300

    x86: move dma_coherent functions to pci-dma.c
    
    They are placed in an ifdef, since they are i386 specific
    the structure definition goes to dma-mapping.h.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 48ab52d052b6..967dfcfa2ad2 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -186,6 +186,87 @@ static __init int iommu_setup(char *p)
 }
 early_param("iommu", iommu_setup);
 
+#ifdef CONFIG_X86_32
+int dma_declare_coherent_memory(struct device *dev, dma_addr_t bus_addr,
+				dma_addr_t device_addr, size_t size, int flags)
+{
+	void __iomem *mem_base = NULL;
+	int pages = size >> PAGE_SHIFT;
+	int bitmap_size = BITS_TO_LONGS(pages) * sizeof(long);
+
+	if ((flags & (DMA_MEMORY_MAP | DMA_MEMORY_IO)) == 0)
+		goto out;
+	if (!size)
+		goto out;
+	if (dev->dma_mem)
+		goto out;
+
+	/* FIXME: this routine just ignores DMA_MEMORY_INCLUDES_CHILDREN */
+
+	mem_base = ioremap(bus_addr, size);
+	if (!mem_base)
+		goto out;
+
+	dev->dma_mem = kzalloc(sizeof(struct dma_coherent_mem), GFP_KERNEL);
+	if (!dev->dma_mem)
+		goto out;
+	dev->dma_mem->bitmap = kzalloc(bitmap_size, GFP_KERNEL);
+	if (!dev->dma_mem->bitmap)
+		goto free1_out;
+
+	dev->dma_mem->virt_base = mem_base;
+	dev->dma_mem->device_base = device_addr;
+	dev->dma_mem->size = pages;
+	dev->dma_mem->flags = flags;
+
+	if (flags & DMA_MEMORY_MAP)
+		return DMA_MEMORY_MAP;
+
+	return DMA_MEMORY_IO;
+
+ free1_out:
+	kfree(dev->dma_mem);
+ out:
+	if (mem_base)
+		iounmap(mem_base);
+	return 0;
+}
+EXPORT_SYMBOL(dma_declare_coherent_memory);
+
+void dma_release_declared_memory(struct device *dev)
+{
+	struct dma_coherent_mem *mem = dev->dma_mem;
+
+	if (!mem)
+		return;
+	dev->dma_mem = NULL;
+	iounmap(mem->virt_base);
+	kfree(mem->bitmap);
+	kfree(mem);
+}
+EXPORT_SYMBOL(dma_release_declared_memory);
+
+void *dma_mark_declared_memory_occupied(struct device *dev,
+					dma_addr_t device_addr, size_t size)
+{
+	struct dma_coherent_mem *mem = dev->dma_mem;
+	int pos, err;
+	int pages = (size + (device_addr & ~PAGE_MASK) + PAGE_SIZE - 1);
+
+	pages >>= PAGE_SHIFT;
+
+	if (!mem)
+		return ERR_PTR(-EINVAL);
+
+	pos = (device_addr - mem->device_base) >> PAGE_SHIFT;
+	err = bitmap_allocate_region(mem->bitmap, pos, get_order(pages));
+	if (err != 0)
+		return ERR_PTR(err);
+	return mem->virt_base + (pos << PAGE_SHIFT);
+}
+EXPORT_SYMBOL(dma_mark_declared_memory_occupied);
+#endif /* CONFIG_X86_32 */
+
 int dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI

commit fae9a0d8ca68a14da8d2351ad3e0bf42f3b29899
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:56 2008 -0300

    x86: merge iommu initialization parameters
    
    we merge the iommu initialization parameters in pci-dma.c
    Nice thing, that both architectures at least recognize the same
    parameters.
    
    usedac i386 parameter is marked for deprecation
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 7d3bd652c36f..48ab52d052b6 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -24,6 +24,18 @@ int panic_on_overflow __read_mostly = 0;
 int force_iommu __read_mostly = 0;
 #endif
 
+int iommu_merge __read_mostly = 0;
+
+int no_iommu __read_mostly;
+/* Set this to 1 if there is a HW IOMMU in the system */
+int iommu_detected __read_mostly = 0;
+
+/* This tells the BIO block layer to assume merging. Default to off
+   because we cannot guarantee merging later. */
+int iommu_bio_merge __read_mostly = 0;
+EXPORT_SYMBOL(iommu_bio_merge);
+
+
 int dma_set_mask(struct device *dev, u64 mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, mask))
@@ -105,6 +117,75 @@ void __init pci_iommu_alloc(void)
 }
 #endif
 
+/*
+ * See <Documentation/x86_64/boot-options.txt> for the iommu kernel parameter
+ * documentation.
+ */
+static __init int iommu_setup(char *p)
+{
+	iommu_merge = 1;
+
+	if (!p)
+		return -EINVAL;
+
+	while (*p) {
+		if (!strncmp(p, "off", 3))
+			no_iommu = 1;
+		/* gart_parse_options has more force support */
+		if (!strncmp(p, "force", 5))
+			force_iommu = 1;
+		if (!strncmp(p, "noforce", 7)) {
+			iommu_merge = 0;
+			force_iommu = 0;
+		}
+
+		if (!strncmp(p, "biomerge", 8)) {
+			iommu_bio_merge = 4096;
+			iommu_merge = 1;
+			force_iommu = 1;
+		}
+		if (!strncmp(p, "panic", 5))
+			panic_on_overflow = 1;
+		if (!strncmp(p, "nopanic", 7))
+			panic_on_overflow = 0;
+		if (!strncmp(p, "merge", 5)) {
+			iommu_merge = 1;
+			force_iommu = 1;
+		}
+		if (!strncmp(p, "nomerge", 7))
+			iommu_merge = 0;
+		if (!strncmp(p, "forcesac", 8))
+			iommu_sac_force = 1;
+		if (!strncmp(p, "allowdac", 8))
+			forbid_dac = 0;
+		if (!strncmp(p, "nodac", 5))
+			forbid_dac = -1;
+		if (!strncmp(p, "usedac", 6)) {
+			forbid_dac = -1;
+			return 1;
+		}
+#ifdef CONFIG_SWIOTLB
+		if (!strncmp(p, "soft", 4))
+			swiotlb = 1;
+#endif
+
+#ifdef CONFIG_GART_IOMMU
+		gart_parse_options(p);
+#endif
+
+#ifdef CONFIG_CALGARY_IOMMU
+		if (!strncmp(p, "calgary", 7))
+			use_calgary = 1;
+#endif /* CONFIG_CALGARY_IOMMU */
+
+		p += strcspn(p, ",");
+		if (*p == ',')
+			++p;
+	}
+	return 0;
+}
+early_param("iommu", iommu_setup);
+
 int dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI

commit 8e0c379718ef32967deea55937895bfc9b493dd8
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:55 2008 -0300

    x86: merge dma_supported
    
    The code for both arches are very similar, so this patch merge them.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 48cccbe51aa5..7d3bd652c36f 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -14,6 +14,8 @@ EXPORT_SYMBOL(forbid_dac);
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
+int iommu_sac_force __read_mostly = 0;
+
 #ifdef CONFIG_IOMMU_DEBUG
 int panic_on_overflow __read_mostly = 1;
 int force_iommu __read_mostly = 1;
@@ -103,6 +105,48 @@ void __init pci_iommu_alloc(void)
 }
 #endif
 
+int dma_supported(struct device *dev, u64 mask)
+{
+#ifdef CONFIG_PCI
+	if (mask > 0xffffffff && forbid_dac > 0) {
+		printk(KERN_INFO "PCI: Disallowing DAC for device %s\n",
+				 dev->bus_id);
+		return 0;
+	}
+#endif
+
+	if (dma_ops->dma_supported)
+		return dma_ops->dma_supported(dev, mask);
+
+	/* Copied from i386. Doesn't make much sense, because it will
+	   only work for pci_alloc_coherent.
+	   The caller just has to use GFP_DMA in this case. */
+	if (mask < DMA_24BIT_MASK)
+		return 0;
+
+	/* Tell the device to use SAC when IOMMU force is on.  This
+	   allows the driver to use cheaper accesses in some cases.
+
+	   Problem with this is that if we overflow the IOMMU area and
+	   return DAC as fallback address the device may not handle it
+	   correctly.
+
+	   As a special case some controllers have a 39bit address
+	   mode that is as efficient as 32bit (aic79xx). Don't force
+	   SAC for these.  Assume all masks <= 40 bits are of this
+	   type. Normally this doesn't make any difference, but gives
+	   more gentle handling of IOMMU overflow. */
+	if (iommu_sac_force && (mask >= DMA_40BIT_MASK)) {
+		printk(KERN_INFO "%s: Force SAC with mask %Lx\n",
+				 dev->bus_id, mask);
+		return 0;
+	}
+
+	return 1;
+}
+EXPORT_SYMBOL(dma_supported);
+
+
 static int __init pci_iommu_init(void)
 {
 #ifdef CONFIG_CALGARY_IOMMU

commit bca5c09663030bdd18ab1b3ccb6671f663c3345a
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:53 2008 -0300

    x86: move pci fixup to pci-dma.c
    
    via_no_dac provides a fixup that is the same for both
    architectures. Move it to pci-dma.c.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 91443361cb67..48cccbe51aa5 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,12 +1,16 @@
 #include <linux/dma-mapping.h>
 #include <linux/dmar.h>
 #include <linux/bootmem.h>
+#include <linux/pci.h>
 
 #include <asm/proto.h>
 #include <asm/dma.h>
 #include <asm/gart.h>
 #include <asm/calgary.h>
 
+int forbid_dac __read_mostly;
+EXPORT_SYMBOL(forbid_dac);
+
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
@@ -121,3 +125,17 @@ void pci_iommu_shutdown(void)
 }
 /* Must execute after PCI subsystem */
 fs_initcall(pci_iommu_init);
+
+#ifdef CONFIG_PCI
+/* Many VIA bridges seem to corrupt data for DAC. Disable it here */
+
+static __devinit void via_no_dac(struct pci_dev *dev)
+{
+	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI && forbid_dac == 0) {
+		printk(KERN_INFO "PCI: VIA PCI bridge detected."
+				 "Disabling DAC.\n");
+		forbid_dac = 1;
+	}
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_ANY_ID, via_no_dac);
+#endif

commit 116890d556af38d539597655c564a73e6eef3d9e
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:54 2008 -0300

    x86: move x86_64-specific to common code.
    
    This patch moves the bootmem functions, that are largely
    x86_64-specific into pci-dma.c. The code goes inside an ifdef.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 6b77fd872a7a..91443361cb67 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,6 +1,9 @@
 #include <linux/dma-mapping.h>
 #include <linux/dmar.h>
+#include <linux/bootmem.h>
 
+#include <asm/proto.h>
+#include <asm/dma.h>
 #include <asm/gart.h>
 #include <asm/calgary.h>
 
@@ -26,6 +29,76 @@ int dma_set_mask(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_set_mask);
 
+#ifdef CONFIG_X86_64
+static __initdata void *dma32_bootmem_ptr;
+static unsigned long dma32_bootmem_size __initdata = (128ULL<<20);
+
+static int __init parse_dma32_size_opt(char *p)
+{
+	if (!p)
+		return -EINVAL;
+	dma32_bootmem_size = memparse(p, &p);
+	return 0;
+}
+early_param("dma32_size", parse_dma32_size_opt);
+
+void __init dma32_reserve_bootmem(void)
+{
+	unsigned long size, align;
+	if (end_pfn <= MAX_DMA32_PFN)
+		return;
+
+	align = 64ULL<<20;
+	size = round_up(dma32_bootmem_size, align);
+	dma32_bootmem_ptr = __alloc_bootmem_nopanic(size, align,
+				 __pa(MAX_DMA_ADDRESS));
+	if (dma32_bootmem_ptr)
+		dma32_bootmem_size = size;
+	else
+		dma32_bootmem_size = 0;
+}
+static void __init dma32_free_bootmem(void)
+{
+	int node;
+
+	if (end_pfn <= MAX_DMA32_PFN)
+		return;
+
+	if (!dma32_bootmem_ptr)
+		return;
+
+	for_each_online_node(node)
+		free_bootmem_node(NODE_DATA(node), __pa(dma32_bootmem_ptr),
+				  dma32_bootmem_size);
+
+	dma32_bootmem_ptr = NULL;
+	dma32_bootmem_size = 0;
+}
+
+void __init pci_iommu_alloc(void)
+{
+	/* free the range so iommu could get some range less than 4G */
+	dma32_free_bootmem();
+	/*
+	 * The order of these functions is important for
+	 * fall-back/fail-over reasons
+	 */
+#ifdef CONFIG_GART_IOMMU
+	gart_iommu_hole_init();
+#endif
+
+#ifdef CONFIG_CALGARY_IOMMU
+	detect_calgary();
+#endif
+
+	detect_intel_iommu();
+
+#ifdef CONFIG_SWIOTLB
+	pci_swiotlb_init();
+#endif
+}
+#endif
+
 static int __init pci_iommu_init(void)
 {
 #ifdef CONFIG_CALGARY_IOMMU

commit cb5867a5d8ca20e16ddc3397c36ee9c2e4cba219
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:51 2008 -0300

    x86: move initialization functions to pci-dma.c
    
    initcalls that triggers the various possibiities for
    dma subsys are moved to pci-dma.c.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 37a558a96153..6b77fd872a7a 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,4 +1,8 @@
 #include <linux/dma-mapping.h>
+#include <linux/dmar.h>
+
+#include <asm/gart.h>
+#include <asm/calgary.h>
 
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
@@ -22,4 +26,25 @@ int dma_set_mask(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_set_mask);
 
+static int __init pci_iommu_init(void)
+{
+#ifdef CONFIG_CALGARY_IOMMU
+	calgary_iommu_init();
+#endif
+
+	intel_iommu_init();
+
+#ifdef CONFIG_GART_IOMMU
+	gart_iommu_init();
+#endif
 
+	no_iommu_init();
+	return 0;
+}
+
+void pci_iommu_shutdown(void)
+{
+	gart_iommu_shutdown();
+}
+/* Must execute after PCI subsystem */
+fs_initcall(pci_iommu_init);

commit f9c258de3494a5249a61fe110ece2082e5927468
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:52 2008 -0300

    x86: unify pci-nommu
    
    merge pci-base_32.c and pci-nommu_64.c into pci-nommu.c
    Their code were made the same, so now they can be merged.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 1323cd80387b..37a558a96153 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -3,6 +3,14 @@
 const struct dma_mapping_ops *dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
+#ifdef CONFIG_IOMMU_DEBUG
+int panic_on_overflow __read_mostly = 1;
+int force_iommu __read_mostly = 1;
+#else
+int panic_on_overflow __read_mostly = 0;
+int force_iommu __read_mostly = 0;
+#endif
+
 int dma_set_mask(struct device *dev, u64 mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, mask))

commit 85c246ee16fe00bf7bf9e7ff09a5d17d9a83cf71
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:50 2008 -0300

    x86: move definition to pci-dma.c
    
    Move dma_ops structure definition to pci-dma.c, where it
    belongs.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index f1c24d8e7942..1323cd80387b 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,5 +1,8 @@
 #include <linux/dma-mapping.h>
 
+const struct dma_mapping_ops *dma_ops;
+EXPORT_SYMBOL(dma_ops);
+
 int dma_set_mask(struct device *dev, u64 mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, mask))

commit 459121c9ec1e6c5d701f6520f4170719ac008951
Author: Glauber Costa <gcosta@redhat.com>
Date:   Tue Apr 8 13:20:43 2008 -0300

    x86: introduce pci-dma.c
    
    This patch introduces pci-dma.c, a common file for pci dma
    between i386 and x86_64. As a start, dma_set_mask() is the same
    between architectures, and is placed there.
    
    Signed-off-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
new file mode 100644
index 000000000000..f1c24d8e7942
--- /dev/null
+++ b/arch/x86/kernel/pci-dma.c
@@ -0,0 +1,14 @@
+#include <linux/dma-mapping.h>
+
+int dma_set_mask(struct device *dev, u64 mask)
+{
+	if (!dev->dma_mask || !dma_supported(dev, mask))
+		return -EIO;
+
+	*dev->dma_mask = mask;
+
+	return 0;
+}
+EXPORT_SYMBOL(dma_set_mask);
+
+
