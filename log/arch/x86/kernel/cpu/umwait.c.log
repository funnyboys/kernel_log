commit bf09fb6cba4f7099620cc9ed32d94c27c4af992e
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Jun 22 17:51:35 2020 -0700

    KVM: VMX: Stop context switching MSR_IA32_UMWAIT_CONTROL
    
    Remove support for context switching between the guest's and host's
    desired UMWAIT_CONTROL.  Propagating the guest's value to hardware isn't
    required for correct functionality, e.g. KVM intercepts reads and writes
    to the MSR, and the latency effects of the settings controlled by the
    MSR are not architecturally visible.
    
    As a general rule, KVM should not allow the guest to control power
    management settings unless explicitly enabled by userspace, e.g. see
    KVM_CAP_X86_DISABLE_EXITS.  E.g. Intel's SDM explicitly states that C0.2
    can improve the performance of SMT siblings.  A devious guest could
    disable C0.2 so as to improve the performance of their workloads at the
    detriment to workloads running in the host or on other VMs.
    
    Wholesale removal of UMWAIT_CONTROL context switching also fixes a race
    condition where updates from the host may cause KVM to enter the guest
    with the incorrect value.  Because updates are are propagated to all
    CPUs via IPI (SMP function callback), the value in hardware may be
    stale with respect to the cached value and KVM could enter the guest
    with the wrong value in hardware.  As above, the guest can't observe the
    bad value, but it's a weird and confusing wart in the implementation.
    
    Removal also fixes the unnecessary usage of VMX's atomic load/store MSR
    lists.  Using the lists is only necessary for MSRs that are required for
    correct functionality immediately upon VM-Enter/VM-Exit, e.g. EFER on
    old hardware, or for MSRs that need to-the-uop precision, e.g. perf
    related MSRs.  For UMWAIT_CONTROL, the effects are only visible in the
    kernel via TPAUSE/delay(), and KVM doesn't do any form of delay in
    vcpu_vmx_run().  Using the atomic lists is undesirable as they are more
    expensive than direct RDMSR/WRMSR.
    
    Furthermore, even if giving the guest control of the MSR is legitimate,
    e.g. in pass-through scenarios, it's not clear that the benefits would
    outweigh the overhead.  E.g. saving and restoring an MSR across a VMX
    roundtrip costs ~250 cycles, and if the guest diverged from the host
    that cost would be paid on every run of the guest.  In other words, if
    there is a legitimate use case then it should be enabled by a new
    per-VM capability.
    
    Note, KVM still needs to emulate MSR_IA32_UMWAIT_CONTROL so that it can
    correctly expose other WAITPKG features to the guest, e.g. TPAUSE,
    UMWAIT and UMONITOR.
    
    Fixes: 6e3ba4abcea56 ("KVM: vmx: Emulate MSR IA32_UMWAIT_CONTROL")
    Cc: stable@vger.kernel.org
    Cc: Jingqi Liu <jingqi.liu@intel.com>
    Cc: Tao Xu <tao3.xu@intel.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Message-Id: <20200623005135.10414-1-sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index 300e3fd5ade3..ec8064c0ae03 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -18,12 +18,6 @@
  */
 static u32 umwait_control_cached = UMWAIT_CTRL_VAL(100000, UMWAIT_C02_ENABLE);
 
-u32 get_umwait_control_msr(void)
-{
-	return umwait_control_cached;
-}
-EXPORT_SYMBOL_GPL(get_umwait_control_msr);
-
 /*
  * Cache the original IA32_UMWAIT_CONTROL MSR value which is configured by
  * hardware or BIOS before kernel boot.

commit b10c307f6f314c068814d0e23c86f06d5d57004b
Author: Benjamin Thiel <b.thiel@posteo.de>
Date:   Thu Jan 23 18:29:45 2020 +0100

    x86/cpu: Move prototype for get_umwait_control_msr() to a global location
    
    .. in order to fix a -Wmissing-prototypes warning.
    
    No functional change.
    
    Signed-off-by: Benjamin Thiel <b.thiel@posteo.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: kvm@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200123172945.7235-1-b.thiel@posteo.de

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index c222f283b456..300e3fd5ade3 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -4,6 +4,7 @@
 #include <linux/cpu.h>
 
 #include <asm/msr.h>
+#include <asm/mwait.h>
 
 #define UMWAIT_C02_ENABLE	0
 

commit 6e3ba4abcea5681eebbfc10f1b56c9fbe80b6685
Author: Tao Xu <tao3.xu@intel.com>
Date:   Tue Jul 16 14:55:50 2019 +0800

    KVM: vmx: Emulate MSR IA32_UMWAIT_CONTROL
    
    UMWAIT and TPAUSE instructions use 32bit IA32_UMWAIT_CONTROL at MSR index
    E1H to determines the maximum time in TSC-quanta that the processor can
    reside in either C0.1 or C0.2.
    
    This patch emulates MSR IA32_UMWAIT_CONTROL in guest and differentiate
    IA32_UMWAIT_CONTROL between host and guest. The variable
    mwait_control_cached in arch/x86/kernel/cpu/umwait.c caches the MSR value,
    so this patch uses it to avoid frequently rdmsr of IA32_UMWAIT_CONTROL.
    
    Co-developed-by: Jingqi Liu <jingqi.liu@intel.com>
    Signed-off-by: Jingqi Liu <jingqi.liu@intel.com>
    Signed-off-by: Tao Xu <tao3.xu@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index 32b4dc9030aa..c222f283b456 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -17,6 +17,12 @@
  */
 static u32 umwait_control_cached = UMWAIT_CTRL_VAL(100000, UMWAIT_C02_ENABLE);
 
+u32 get_umwait_control_msr(void)
+{
+	return umwait_control_cached;
+}
+EXPORT_SYMBOL_GPL(get_umwait_control_msr);
+
 /*
  * Cache the original IA32_UMWAIT_CONTROL MSR value which is configured by
  * hardware or BIOS before kernel boot.

commit e7409258845a0f64967f8377e99294d438137537
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Fri Aug 9 18:40:37 2019 -0700

    x86/umwait: Fix error handling in umwait_init()
    
    Currently, failure of cpuhp_setup_state() is ignored and the syscore ops
    and the control interfaces can still be added even after the failure. But,
    this error handling will cause a few issues:
    
    1. The CPUs may have different values in the IA32_UMWAIT_CONTROL
       MSR because there is no way to roll back the control MSR on
       the CPUs which already set the MSR before the failure.
    
    2. If the sysfs interface is added successfully, there will be a mismatch
       between the global control value and the control MSR:
       - The interface shows the default global control value. But,
         the control MSR is not set to the value because the CPU online
         function, which is supposed to set the MSR to the value,
         is not installed.
       - If the sysadmin changes the global control value through
         the interface, the control MSR on all current online CPUs is
         set to the new value. But, the control MSR on newly onlined CPUs
         after the value change will not be set to the new value due to
         lack of the CPU online function.
    
    3. On resume from suspend/hibernation, the boot CPU restores the control
       MSR to the global control value through the syscore ops. But, the
       control MSR on all APs is not set due to lake of the CPU online
       function.
    
    To solve the issues and enforce consistent behavior on the failure
    of the CPU hotplug setup, make the following changes:
    
    1. Cache the original control MSR value which is configured by
       hardware or BIOS before kernel boot. This value is likely to
       be 0. But it could be a different number as well. Cache the
       control MSR only once before the MSR is changed.
    2. Add the CPU offline function so that the MSR is restored to the
       original control value on all CPUs on the failure.
    3. On the failure, exit from cpumait_init() so that the syscore ops
       and the control interfaces are not added.
    
    Reported-by: Valdis Kletnieks <valdis.kletnieks@vt.edu>
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/1565401237-60936-1-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index 6a204e7336c1..32b4dc9030aa 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -17,6 +17,12 @@
  */
 static u32 umwait_control_cached = UMWAIT_CTRL_VAL(100000, UMWAIT_C02_ENABLE);
 
+/*
+ * Cache the original IA32_UMWAIT_CONTROL MSR value which is configured by
+ * hardware or BIOS before kernel boot.
+ */
+static u32 orig_umwait_control_cached __ro_after_init;
+
 /*
  * Serialize access to umwait_control_cached and IA32_UMWAIT_CONTROL MSR in
  * the sysfs write functions.
@@ -52,6 +58,23 @@ static int umwait_cpu_online(unsigned int cpu)
 	return 0;
 }
 
+/*
+ * The CPU hotplug callback sets the control MSR to the original control
+ * value.
+ */
+static int umwait_cpu_offline(unsigned int cpu)
+{
+	/*
+	 * This code is protected by the CPU hotplug already and
+	 * orig_umwait_control_cached is never changed after it caches
+	 * the original control MSR value in umwait_init(). So there
+	 * is no race condition here.
+	 */
+	wrmsr(MSR_IA32_UMWAIT_CONTROL, orig_umwait_control_cached, 0);
+
+	return 0;
+}
+
 /*
  * On resume, restore IA32_UMWAIT_CONTROL MSR on the boot processor which
  * is the only active CPU at this time. The MSR is set up on the APs via the
@@ -185,8 +208,22 @@ static int __init umwait_init(void)
 	if (!boot_cpu_has(X86_FEATURE_WAITPKG))
 		return -ENODEV;
 
+	/*
+	 * Cache the original control MSR value before the control MSR is
+	 * changed. This is the only place where orig_umwait_control_cached
+	 * is modified.
+	 */
+	rdmsrl(MSR_IA32_UMWAIT_CONTROL, orig_umwait_control_cached);
+
 	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "umwait:online",
-				umwait_cpu_online, NULL);
+				umwait_cpu_online, umwait_cpu_offline);
+	if (ret < 0) {
+		/*
+		 * On failure, the control MSR on all CPUs has the
+		 * original control value.
+		 */
+		return ret;
+	}
 
 	register_syscore_ops(&umwait_syscore_ops);
 

commit bd9a0c97e53c3d7a56b2751179903ddc5da42683
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Wed Jun 19 18:33:57 2019 -0700

    x86/umwait: Add sysfs interface to control umwait maximum time
    
    IA32_UMWAIT_CONTROL[31:2] determines the maximum time in TSC-quanta
    that processor can stay in C0.1 or C0.2. A zero value means no maximum
    time.
    
    Each instruction sets its own deadline in the instruction's implicit
    input EDX:EAX value. The instruction wakes up if the time-stamp counter
    reaches or exceeds the specified deadline, or the umwait maximum time
    expires, or a store happens in the monitored address range in umwait.
    
    The administrator can write an unsigned 32-bit number to
    /sys/devices/system/cpu/umwait_control/max_time to change the default
    value. Note that a value of zero means there is no limit. The lower two
    bits of the value must be zero.
    
    [ tglx: Simplify the write function. Massage changelog ]
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Cc: "Borislav Petkov" <bp@alien8.de>
    Cc: "H Peter Anvin" <hpa@zytor.com>
    Cc: "Andy Lutomirski" <luto@kernel.org>
    Cc: "Peter Zijlstra" <peterz@infradead.org>
    Cc: "Ravi V Shankar" <ravi.v.shankar@intel.com>
    Link: https://lkml.kernel.org/r/1560994438-235698-5-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index 56149d630e35..6a204e7336c1 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -131,8 +131,44 @@ static ssize_t enable_c02_store(struct device *dev,
 }
 static DEVICE_ATTR_RW(enable_c02);
 
+static ssize_t
+max_time_show(struct device *kobj, struct device_attribute *attr, char *buf)
+{
+	u32 ctrl = READ_ONCE(umwait_control_cached);
+
+	return sprintf(buf, "%u\n", umwait_ctrl_max_time(ctrl));
+}
+
+static ssize_t max_time_store(struct device *kobj,
+			      struct device_attribute *attr,
+			      const char *buf, size_t count)
+{
+	u32 max_time, ctrl;
+	int ret;
+
+	ret = kstrtou32(buf, 0, &max_time);
+	if (ret)
+		return ret;
+
+	/* bits[1:0] must be zero */
+	if (max_time & ~MSR_IA32_UMWAIT_CONTROL_TIME_MASK)
+		return -EINVAL;
+
+	mutex_lock(&umwait_lock);
+
+	ctrl = READ_ONCE(umwait_control_cached);
+	if (max_time != umwait_ctrl_max_time(ctrl))
+		umwait_update_control(max_time, umwait_ctrl_c02_enabled(ctrl));
+
+	mutex_unlock(&umwait_lock);
+
+	return count;
+}
+static DEVICE_ATTR_RW(max_time);
+
 static struct attribute *umwait_attrs[] = {
 	&dev_attr_enable_c02.attr,
+	&dev_attr_max_time.attr,
 	NULL
 };
 

commit ff4b353f2ef9dc8e396d7cb9572801e34a8c7374
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Wed Jun 19 18:33:56 2019 -0700

    x86/umwait: Add sysfs interface to control umwait C0.2 state
    
    C0.2 state in umwait and tpause instructions can be enabled or disabled
    on a processor through IA32_UMWAIT_CONTROL MSR register.
    
    By default, C0.2 is enabled and the user wait instructions results in
    lower power consumption with slower wakeup time.
    
    But in real time systems which require faster wakeup time although power
    savings could be smaller, the administrator needs to disable C0.2 and all
    umwait invocations from user applications use C0.1.
    
    Create a sysfs interface which allows the administrator to control C0.2
    state during run time.
    
    Andy Lutomirski suggested to turn off local irqs before writing the MSR to
    ensure the cached control value is not changed by a concurrent sysfs write
    from a different CPU via IPI.
    
    [ tglx: Simplified the update logic in the write function and got rid of
            all the convoluted type casts. Added a shared update function and
            made the namespace consistent. Moved the sysfs create invocation.
            Massaged changelog ]
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Cc: "Borislav Petkov" <bp@alien8.de>
    Cc: "H Peter Anvin" <hpa@zytor.com>
    Cc: "Andy Lutomirski" <luto@kernel.org>
    Cc: "Peter Zijlstra" <peterz@infradead.org>
    Cc: "Ravi V Shankar" <ravi.v.shankar@intel.com>
    Link: https://lkml.kernel.org/r/1560994438-235698-4-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
index 0a113c731df3..56149d630e35 100644
--- a/arch/x86/kernel/cpu/umwait.c
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -7,8 +7,8 @@
 
 #define UMWAIT_C02_ENABLE	0
 
-#define UMWAIT_CTRL_VAL(maxtime, c02_disable)				\
-	(((maxtime) & MSR_IA32_UMWAIT_CONTROL_TIME_MASK) |		\
+#define UMWAIT_CTRL_VAL(max_time, c02_disable)				\
+	(((max_time) & MSR_IA32_UMWAIT_CONTROL_TIME_MASK) |		\
 	((c02_disable) & MSR_IA32_UMWAIT_CONTROL_C02_DISABLE))
 
 /*
@@ -17,10 +17,38 @@
  */
 static u32 umwait_control_cached = UMWAIT_CTRL_VAL(100000, UMWAIT_C02_ENABLE);
 
-/* Set IA32_UMWAIT_CONTROL MSR on this CPU to the current global setting. */
+/*
+ * Serialize access to umwait_control_cached and IA32_UMWAIT_CONTROL MSR in
+ * the sysfs write functions.
+ */
+static DEFINE_MUTEX(umwait_lock);
+
+static void umwait_update_control_msr(void * unused)
+{
+	lockdep_assert_irqs_disabled();
+	wrmsr(MSR_IA32_UMWAIT_CONTROL, READ_ONCE(umwait_control_cached), 0);
+}
+
+/*
+ * The CPU hotplug callback sets the control MSR to the global control
+ * value.
+ *
+ * Disable interrupts so the read of umwait_control_cached and the WRMSR
+ * are protected against a concurrent sysfs write. Otherwise the sysfs
+ * write could update the cached value after it had been read on this CPU
+ * and issue the IPI before the old value had been written. The IPI would
+ * interrupt, write the new value and after return from IPI the previous
+ * value would be written by this CPU.
+ *
+ * With interrupts disabled the upcoming CPU either sees the new control
+ * value or the IPI is updating this CPU to the new control value after
+ * interrupts have been reenabled.
+ */
 static int umwait_cpu_online(unsigned int cpu)
 {
-	wrmsr(MSR_IA32_UMWAIT_CONTROL, umwait_control_cached, 0);
+	local_irq_disable();
+	umwait_update_control_msr(NULL);
+	local_irq_enable();
 	return 0;
 }
 
@@ -36,15 +64,86 @@ static int umwait_cpu_online(unsigned int cpu)
  */
 static void umwait_syscore_resume(void)
 {
-	wrmsr(MSR_IA32_UMWAIT_CONTROL, umwait_control_cached, 0);
+	umwait_update_control_msr(NULL);
 }
 
 static struct syscore_ops umwait_syscore_ops = {
 	.resume	= umwait_syscore_resume,
 };
 
+/* sysfs interface */
+
+/*
+ * When bit 0 in IA32_UMWAIT_CONTROL MSR is 1, C0.2 is disabled.
+ * Otherwise, C0.2 is enabled.
+ */
+static inline bool umwait_ctrl_c02_enabled(u32 ctrl)
+{
+	return !(ctrl & MSR_IA32_UMWAIT_CONTROL_C02_DISABLE);
+}
+
+static inline u32 umwait_ctrl_max_time(u32 ctrl)
+{
+	return ctrl & MSR_IA32_UMWAIT_CONTROL_TIME_MASK;
+}
+
+static inline void umwait_update_control(u32 maxtime, bool c02_enable)
+{
+	u32 ctrl = maxtime & MSR_IA32_UMWAIT_CONTROL_TIME_MASK;
+
+	if (!c02_enable)
+		ctrl |= MSR_IA32_UMWAIT_CONTROL_C02_DISABLE;
+
+	WRITE_ONCE(umwait_control_cached, ctrl);
+	/* Propagate to all CPUs */
+	on_each_cpu(umwait_update_control_msr, NULL, 1);
+}
+
+static ssize_t
+enable_c02_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	u32 ctrl = READ_ONCE(umwait_control_cached);
+
+	return sprintf(buf, "%d\n", umwait_ctrl_c02_enabled(ctrl));
+}
+
+static ssize_t enable_c02_store(struct device *dev,
+				struct device_attribute *attr,
+				const char *buf, size_t count)
+{
+	bool c02_enable;
+	u32 ctrl;
+	int ret;
+
+	ret = kstrtobool(buf, &c02_enable);
+	if (ret)
+		return ret;
+
+	mutex_lock(&umwait_lock);
+
+	ctrl = READ_ONCE(umwait_control_cached);
+	if (c02_enable != umwait_ctrl_c02_enabled(ctrl))
+		umwait_update_control(ctrl, c02_enable);
+
+	mutex_unlock(&umwait_lock);
+
+	return count;
+}
+static DEVICE_ATTR_RW(enable_c02);
+
+static struct attribute *umwait_attrs[] = {
+	&dev_attr_enable_c02.attr,
+	NULL
+};
+
+static struct attribute_group umwait_attr_group = {
+	.attrs = umwait_attrs,
+	.name = "umwait_control",
+};
+
 static int __init umwait_init(void)
 {
+	struct device *dev;
 	int ret;
 
 	if (!boot_cpu_has(X86_FEATURE_WAITPKG))
@@ -52,11 +151,14 @@ static int __init umwait_init(void)
 
 	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "umwait:online",
 				umwait_cpu_online, NULL);
-	if (ret < 0)
-		return ret;
 
 	register_syscore_ops(&umwait_syscore_ops);
 
-	return 0;
+	/*
+	 * Add umwait control interface. Ignore failure, so at least the
+	 * default values are set up in case the machine manages to boot.
+	 */
+	dev = cpu_subsys.dev_root;
+	return sysfs_create_group(&dev->kobj, &umwait_attr_group);
 }
 device_initcall(umwait_init);

commit bd688c69b7e6693de3bd78f38fd63f7850c2711e
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Wed Jun 19 18:33:55 2019 -0700

    x86/umwait: Initialize umwait control values
    
    umwait or tpause allows the processor to enter a light-weight
    power/performance optimized state (C0.1 state) or an improved
    power/performance optimized state (C0.2 state) for a period specified by
    the instruction or until the system time limit or until a store to the
    monitored address range in umwait.
    
    IA32_UMWAIT_CONTROL MSR register allows the OS to enable/disable C0.2 on
    the processor and to set the maximum time the processor can reside in C0.1
    or C0.2.
    
    By default C0.2 is enabled so the user wait instructions can enter the
    C0.2 state to save more power with slower wakeup time.
    
    Andy Lutomirski proposed to set the maximum umwait time to 100000 cycles by
    default. A quote from Andy:
    
      "What I want to avoid is the case where it works dramatically differently
       on NO_HZ_FULL systems as compared to everything else. Also, UMWAIT may
       behave a bit differently if the max timeout is hit, and I'd like that
       path to get exercised widely by making it happen even on default
       configs."
    
    A sysfs interface to adjust the time and the C0.2 enablement is provided in
    a follow up change.
    
    [ tglx: Renamed MSR_IA32_UMWAIT_CONTROL_MAX_TIME to
            MSR_IA32_UMWAIT_CONTROL_TIME_MASK because the constant is used as
            mask throughout the code.
            Massaged comments and changelog ]
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Cc: "Borislav Petkov" <bp@alien8.de>
    Cc: "H Peter Anvin" <hpa@zytor.com>
    Cc: "Peter Zijlstra" <peterz@infradead.org>
    Cc: "Tony Luck" <tony.luck@intel.com>
    Cc: "Ravi V Shankar" <ravi.v.shankar@intel.com>
    Link: https://lkml.kernel.org/r/1560994438-235698-3-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/kernel/cpu/umwait.c b/arch/x86/kernel/cpu/umwait.c
new file mode 100644
index 000000000000..0a113c731df3
--- /dev/null
+++ b/arch/x86/kernel/cpu/umwait.c
@@ -0,0 +1,62 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <linux/syscore_ops.h>
+#include <linux/suspend.h>
+#include <linux/cpu.h>
+
+#include <asm/msr.h>
+
+#define UMWAIT_C02_ENABLE	0
+
+#define UMWAIT_CTRL_VAL(maxtime, c02_disable)				\
+	(((maxtime) & MSR_IA32_UMWAIT_CONTROL_TIME_MASK) |		\
+	((c02_disable) & MSR_IA32_UMWAIT_CONTROL_C02_DISABLE))
+
+/*
+ * Cache IA32_UMWAIT_CONTROL MSR. This is a systemwide control. By default,
+ * umwait max time is 100000 in TSC-quanta and C0.2 is enabled
+ */
+static u32 umwait_control_cached = UMWAIT_CTRL_VAL(100000, UMWAIT_C02_ENABLE);
+
+/* Set IA32_UMWAIT_CONTROL MSR on this CPU to the current global setting. */
+static int umwait_cpu_online(unsigned int cpu)
+{
+	wrmsr(MSR_IA32_UMWAIT_CONTROL, umwait_control_cached, 0);
+	return 0;
+}
+
+/*
+ * On resume, restore IA32_UMWAIT_CONTROL MSR on the boot processor which
+ * is the only active CPU at this time. The MSR is set up on the APs via the
+ * CPU hotplug callback.
+ *
+ * This function is invoked on resume from suspend and hibernation. On
+ * resume from suspend the restore should be not required, but we neither
+ * trust the firmware nor does it matter if the same value is written
+ * again.
+ */
+static void umwait_syscore_resume(void)
+{
+	wrmsr(MSR_IA32_UMWAIT_CONTROL, umwait_control_cached, 0);
+}
+
+static struct syscore_ops umwait_syscore_ops = {
+	.resume	= umwait_syscore_resume,
+};
+
+static int __init umwait_init(void)
+{
+	int ret;
+
+	if (!boot_cpu_has(X86_FEATURE_WAITPKG))
+		return -ENODEV;
+
+	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "umwait:online",
+				umwait_cpu_online, NULL);
+	if (ret < 0)
+		return ret;
+
+	register_syscore_ops(&umwait_syscore_ops);
+
+	return 0;
+}
+device_initcall(umwait_init);
