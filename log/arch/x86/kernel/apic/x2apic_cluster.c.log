commit 7a22e03b0c02988e91003c505b34d752a51de344
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Oct 1 13:50:19 2019 -0700

    x86/apic/x2apic: Fix a NULL pointer deref when handling a dying cpu
    
    Check that the per-cpu cluster mask pointer has been set prior to
    clearing a dying cpu's bit.  The per-cpu pointer is not set until the
    target cpu reaches smp_callin() during CPUHP_BRINGUP_CPU, whereas the
    teardown function, x2apic_dead_cpu(), is associated with the earlier
    CPUHP_X2APIC_PREPARE.  If an error occurs before the cpu is awakened,
    e.g. if do_boot_cpu() itself fails, x2apic_dead_cpu() will dereference
    the NULL pointer and cause a panic.
    
      smpboot: do_boot_cpu failed(-22) to wakeup CPU#1
      BUG: kernel NULL pointer dereference, address: 0000000000000008
      RIP: 0010:x2apic_dead_cpu+0x1a/0x30
      Call Trace:
       cpuhp_invoke_callback+0x9a/0x580
       _cpu_up+0x10d/0x140
       do_cpu_up+0x69/0xb0
       smp_init+0x63/0xa9
       kernel_init_freeable+0xd7/0x229
       ? rest_init+0xa0/0xa0
       kernel_init+0xa/0x100
       ret_from_fork+0x35/0x40
    
    Fixes: 023a611748fd5 ("x86/apic/x2apic: Simplify cluster management")
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20191001205019.5789-1-sean.j.christopherson@intel.com

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 45e92cba92f5..b0889c48a2ac 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -156,7 +156,8 @@ static int x2apic_dead_cpu(unsigned int dead_cpu)
 {
 	struct cluster_mask *cmsk = per_cpu(cluster_masks, dead_cpu);
 
-	cpumask_clear_cpu(dead_cpu, &cmsk->mask);
+	if (cmsk)
+		cpumask_clear_cpu(dead_cpu, &cmsk->mask);
 	free_cpumask_var(per_cpu(ipi_mask, dead_cpu));
 	return 0;
 }

commit 43931d350f30c6cd8c2f498d54ef7d65750abc92
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 22 20:47:30 2019 +0200

    x86/apic/x2apic: Implement IPI shorthands support
    
    All callers of apic->send_IPI_all() and apic->send_IPI_allbutself() contain
    the decision logic for shorthand invocation already and invoke
    send_IPI_mask() if the prereqisites are not satisfied.
    
    Implement shorthand support for x2apic.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20190722105221.134696837@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d0a13c88f777..45e92cba92f5 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -82,12 +82,12 @@ x2apic_send_IPI_mask_allbutself(const struct cpumask *mask, int vector)
 
 static void x2apic_send_IPI_allbutself(int vector)
 {
-	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLBUT);
+	__x2apic_send_IPI_shorthand(vector, APIC_DEST_ALLBUT);
 }
 
 static void x2apic_send_IPI_all(int vector)
 {
-	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
+	__x2apic_send_IPI_shorthand(vector, APIC_DEST_ALLINC);
 }
 
 static u32 x2apic_calc_apicid(unsigned int cpu)

commit c94f0718fb1c171d6dfdd69cb6001fa0d8206710
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 22 20:47:14 2019 +0200

    x86/apic: Consolidate the apic local headers
    
    Now there are three small local headers. Some contain functions which are
    only used in one source file.
    
    Move all the inlines and declarations into a single local header and the
    inlines which are only used in one source file into that.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20190722105219.618612624@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index ebde731dc4cf..d0a13c88f777 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -7,7 +7,7 @@
 
 #include <asm/apic.h>
 
-#include "x2apic.h"
+#include "local.h"
 
 struct cluster_mask {
 	unsigned int	clusterid;

commit 521b82fee98c1e334ba3a2459ba3739d459e9e4e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 22 20:47:11 2019 +0200

    x86/apic: Cleanup the include maze
    
    All of these APIC files include the world and some more. Remove the
    unneeded cruft.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20190722105219.342631201@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 609e499387a1..ebde731dc4cf 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -1,14 +1,12 @@
 // SPDX-License-Identifier: GPL-2.0
-#include <linux/threads.h>
+
+#include <linux/cpuhotplug.h>
 #include <linux/cpumask.h>
-#include <linux/string.h>
-#include <linux/kernel.h>
-#include <linux/ctype.h>
-#include <linux/dmar.h>
-#include <linux/irq.h>
-#include <linux/cpu.h>
-
-#include <asm/smp.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+
+#include <asm/apic.h>
+
 #include "x2apic.h"
 
 struct cluster_mask {

commit dde3626f815e38bbf96fddd5185038c4b4d395a8
Author: Nadav Amit <namit@vmware.com>
Date:   Wed Jun 12 23:48:13 2019 -0700

    x86/apic: Use non-atomic operations when possible
    
    Using __clear_bit() and __cpumask_clear_cpu() is more efficient than using
    their atomic counterparts.
    
    Use them when atomicity is not needed, such as when manipulating bitmasks
    that are on the stack.
    
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Link: https://lkml.kernel.org/r/20190613064813.8102-10-namit@vmware.com

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 7685444a106b..609e499387a1 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -50,7 +50,7 @@ __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 	cpumask_copy(tmpmsk, mask);
 	/* If IPI should not be sent to self, clear current CPU */
 	if (apic_dest != APIC_DEST_ALLINC)
-		cpumask_clear_cpu(smp_processor_id(), tmpmsk);
+		__cpumask_clear_cpu(smp_processor_id(), tmpmsk);
 
 	/* Collapse cpus in a cluster so a single IPI per cluster is sent */
 	for_each_cpu(cpu, tmpmsk) {

commit fed71f7d98795ed0fa1d431910787f0f4a68324f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 17 14:36:39 2018 +0200

    x86/apic/x2apic: Initialize cluster ID properly
    
    Rick bisected a regression on large systems which use the x2apic cluster
    mode for interrupt delivery to the commit wich reworked the cluster
    management.
    
    The problem is caused by a missing initialization of the clusterid field
    in the shared cluster data structures. So all structures end up with
    cluster ID 0 which only allows sharing between all CPUs which belong to
    cluster 0. All other CPUs with a cluster ID > 0 cannot share the data
    structure because they cannot find existing data with their cluster
    ID. This causes malfunction with IPIs because IPIs are sent to the wrong
    cluster and the caller waits for ever that the target CPU handles the IPI.
    
    Add the missing initialization when a upcoming CPU is the first in a
    cluster so that the later booting CPUs can find the data and share it for
    proper operation.
    
    Fixes: 023a611748fd ("x86/apic/x2apic: Simplify cluster management")
    Reported-by: Rick Warner <rick@microway.com>
    Bisected-by: Rick Warner <rick@microway.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Rick Warner <rick@microway.com>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1805171418210.1947@nanos.tec.linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 8b04234e010b..7685444a106b 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -116,6 +116,7 @@ static void init_x2apic_ldr(void)
 			goto update;
 	}
 	cmsk = cluster_hotplug_mask;
+	cmsk->clusterid = cluster;
 	cluster_hotplug_mask = NULL;
 update:
 	this_cpu_write(cluster_masks, cmsk);

commit a31e58e129f73ab5b04016330b13ed51fde7a961
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 28 11:33:33 2017 +0100

    x86/apic: Switch all APICs to Fixed delivery mode
    
    Some of the APIC incarnations are operating in lowest priority delivery
    mode. This worked as long as the vector management code allocated the same
    vector on all possible CPUs for each interrupt.
    
    Lowest priority delivery mode does not necessarily respect the affinity
    setting and may redirect to some other online CPU. This was documented
    somewhere in the old code and the conversion to single target delivery
    missed to update the delivery mode of the affected APIC drivers which
    results in spurious interrupts on some of the affected CPU/Chipset
    combinations.
    
    Switch the APIC drivers over to Fixed delivery mode and remove all
    leftovers of lowest priority delivery mode.
    
    Switching to Fixed delivery mode is not a problem on these CPUs because the
    kernel already uses Fixed delivery mode for IPIs. The reason for this is
    that th SDM explicitely forbids lowest prio mode for IPIs. The reason is
    obvious: If the irq routing does not honor destination targets in lowest
    prio mode then an IPI targeted at CPU1 might end up on CPU0, which would be
    a fatal problem in many cases.
    
    As a consequence of this change, the apic::irq_delivery_mode field is now
    pointless, but this needs to be cleaned up in a separate patch.
    
    Fixes: fdba46ffb4c2 ("x86/apic: Get rid of multi CPU affinity")
    Reported-by: vcaputo@pengaru.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: vcaputo@pengaru.com
    Cc: Pavel Machek <pavel@ucw.cz>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.20.1712281140440.1688@nanos

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 622f13ca8a94..8b04234e010b 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -184,7 +184,7 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.apic_id_valid			= x2apic_apic_id_valid,
 	.apic_id_registered		= x2apic_apic_id_registered,
 
-	.irq_delivery_mode		= dest_LowestPrio,
+	.irq_delivery_mode		= dest_Fixed,
 	.irq_dest_mode			= 1, /* logical */
 
 	.disable_esr			= 0,

commit 141d3b1daacd11bdbd6fa74c2b163093e10d17ee
Merge: c201c91799d6 e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:51:10 2017 +0100

    Merge branch 'linus' into x86/apic, to resolve conflicts
    
    Conflicts:
            arch/x86/include/asm/x2apic.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 481237cb1544..e216cf3d64d2 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #include <linux/threads.h>
 #include <linux/cpumask.h>
 #include <linux/string.h>

commit 1e66e2b86293ff1ded32104ac0ad26a7f08ec439
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Sep 26 19:08:45 2017 +0200

    x86/apic: Use dead_cpu instead of current CPU when cleaning up
    
    x2apic_dead_cpu() cleans up the leftovers of a CPU which got unplugged, but
    instead of clearing the dead cpu bit in the cluster mask it clears the
    current (alive) cpu bit. Noticed because smp_processor_id() is called in
    preemptible code and triggers a debug warning.
    
    [ tglx: Rewrote changelog ]
    
    Fixes: 023a611748fd ("x86/apic/x2apic: Simplify cluster management")
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20170926170845.13955-1-bp@alien8.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 3da94277140f..6050c5364bdc 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -156,7 +156,7 @@ static int x2apic_dead_cpu(unsigned int dead_cpu)
 {
 	struct cluster_mask *cmsk = per_cpu(cluster_masks, dead_cpu);
 
-	cpumask_clear_cpu(smp_processor_id(), &cmsk->mask);
+	cpumask_clear_cpu(dead_cpu, &cmsk->mask);
 	free_cpumask_var(per_cpu(ipi_mask, dead_cpu));
 	return 0;
 }

commit baab1e84b1124bfd3e40ef6c8e05b2a15136e3d5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:43 2017 +0200

    x86/apic: Remove unused callbacks
    
    Now that the old allocator is gone, these apic functions are unused. Remove
    them.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213155.524662349@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 17bf63f580d7..3da94277140f 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -91,29 +91,6 @@ static void x2apic_send_IPI_all(int vector)
 	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
 }
 
-static int
-x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
-			  unsigned int *apicid)
-{
-	struct cpumask *effmsk = irq_data_get_effective_affinity_mask(irqdata);
-	struct cluster_mask *cmsk;
-	unsigned int cpu;
-	u32 dest = 0;
-
-	cpu = cpumask_first(mask);
-	if (cpu >= nr_cpu_ids)
-		return -EINVAL;
-
-	cmsk = per_cpu(cluster_masks, cpu);
-	cpumask_clear(effmsk);
-	for_each_cpu_and(cpu, &cmsk->mask, mask) {
-		dest |= per_cpu(x86_cpu_to_logical_apicid, cpu);
-		cpumask_set_cpu(cpu, effmsk);
-	}
-	*apicid = dest;
-	return 0;
-}
-
 static u32 x2apic_calc_apicid(unsigned int cpu)
 {
 	return per_cpu(x86_cpu_to_logical_apicid, cpu);
@@ -198,29 +175,6 @@ static int x2apic_cluster_probe(void)
 	return 1;
 }
 
-/*
- * Each x2apic cluster is an allocation domain.
- */
-static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
-					     const struct cpumask *mask)
-{
-	struct cluster_mask *cmsk = per_cpu(cluster_masks, cpu);
-
-	/*
-	 * To minimize vector pressure, default case of boot, device bringup
-	 * etc will use a single cpu for the interrupt destination.
-	 *
-	 * On explicit migration requests coming from irqbalance etc,
-	 * interrupts will be routed to the x2apic cluster (cluster-id
-	 * derived from the first cpu in the mask) members specified
-	 * in the mask.
-	 */
-	if (cpumask_equal(mask, cpu_online_mask))
-		cpumask_copy(retmask, cpumask_of(cpu));
-	else
-		cpumask_and(retmask, mask, &cmsk->mask);
-}
-
 static struct apic apic_x2apic_cluster __ro_after_init = {
 
 	.name				= "cluster x2apic",
@@ -236,7 +190,6 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.dest_logical			= APIC_DEST_LOGICAL,
 	.check_apicid_used		= NULL,
 
-	.vector_allocation_domain	= cluster_vector_allocation_domain,
 	.init_apic_ldr			= init_x2apic_ldr,
 
 	.ioapic_phys_id_map		= NULL,
@@ -249,7 +202,6 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.get_apic_id			= x2apic_get_apic_id,
 	.set_apic_id			= x2apic_set_apic_id,
 
-	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,
 	.calc_dest_apicid		= x2apic_calc_apicid,
 
 	.send_IPI			= x2apic_send_IPI,

commit 9f9e3bb1cf2ecba7697bfb5e350ad2648e69dbdf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:37 2017 +0200

    x86/apic: Add replacement for cpu_mask_to_apicid()
    
    As preparation for replacing the vector allocator, provide a new function
    which takes a cpu number instead of a cpu mask to calculate/lookup the
    resulting APIC destination id.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index c1684f27226e..17bf63f580d7 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -114,6 +114,11 @@ x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
 	return 0;
 }
 
+static u32 x2apic_calc_apicid(unsigned int cpu)
+{
+	return per_cpu(x86_cpu_to_logical_apicid, cpu);
+}
+
 static void init_x2apic_ldr(void)
 {
 	struct cluster_mask *cmsk = this_cpu_read(cluster_masks);
@@ -245,6 +250,7 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.set_apic_id			= x2apic_set_apic_id,
 
 	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,
+	.calc_dest_apicid		= x2apic_calc_apicid,
 
 	.send_IPI			= x2apic_send_IPI,
 	.send_IPI_mask			= x2apic_send_IPI_mask,

commit c1d1ee9ac1793d939ba1a1322767cc5f77a5b8fe
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:25 2017 +0200

    x86/apic: Get rid of apic->target_cpus
    
    The target_cpus() callback of the apic struct is not really useful. Some
    APICs return cpu_online_mask and others cpus_all_mask. The latter is bogus
    as it does not take holes in the cpus_possible_mask into account.
    
    Replace it with cpus_online_mask which makes the most sense and remove the
    callback.
    
    The usage sites will be removed in a later step anyway, so get rid of it
    now to have incremental changes.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213154.070850916@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 729c0a512b72..c1684f27226e 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -193,11 +193,6 @@ static int x2apic_cluster_probe(void)
 	return 1;
 }
 
-static const struct cpumask *x2apic_cluster_target_cpus(void)
-{
-	return cpu_all_mask;
-}
-
 /*
  * Each x2apic cluster is an allocation domain.
  */
@@ -215,7 +210,7 @@ static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
 	 * derived from the first cpu in the mask) members specified
 	 * in the mask.
 	 */
-	if (mask == x2apic_cluster_target_cpus())
+	if (cpumask_equal(mask, cpu_online_mask))
 		cpumask_copy(retmask, cpumask_of(cpu));
 	else
 		cpumask_and(retmask, mask, &cmsk->mask);
@@ -232,7 +227,6 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.irq_delivery_mode		= dest_LowestPrio,
 	.irq_dest_mode			= 1, /* logical */
 
-	.target_cpus			= x2apic_cluster_target_cpus,
 	.disable_esr			= 0,
 	.dest_logical			= APIC_DEST_LOGICAL,
 	.check_apicid_used		= NULL,

commit 023a611748fd58d46c8aa049cf4f22ebada983f5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:24 2017 +0200

    x86/apic/x2apic: Simplify cluster management
    
    The cluster management code creates a cluster mask per cpu, which requires
    that on cpu on/offline all cluster masks have to be iterated and
    updated. Other information about the cluster is in different per cpu
    variables.
    
    Create a data structure which holds all information about a cluster and
    fill it in when the first CPU of a cluster comes online. If another CPU of
    a cluster comes online it just finds the pointer to the existing cluster
    structure and reuses it.
    
    That simplifies all usage sites and gets rid of quite some pointless
    iterations over the online cpus to find the cpus which belong to the
    cluster.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213153.992629420@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d7f5132ba5ca..729c0a512b72 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -10,20 +10,22 @@
 #include <asm/smp.h>
 #include "x2apic.h"
 
+struct cluster_mask {
+	unsigned int	clusterid;
+	int		node;
+	struct cpumask	mask;
+};
+
 static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
-static DEFINE_PER_CPU(cpumask_var_t, cpus_in_cluster);
 static DEFINE_PER_CPU(cpumask_var_t, ipi_mask);
+static DEFINE_PER_CPU(struct cluster_mask *, cluster_masks);
+static struct cluster_mask *cluster_hotplug_mask;
 
 static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 {
 	return x2apic_enabled();
 }
 
-static inline u32 x2apic_cluster(int cpu)
-{
-	return per_cpu(x86_cpu_to_logical_apicid, cpu) >> 16;
-}
-
 static void x2apic_send_IPI(int cpu, int vector)
 {
 	u32 dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
@@ -35,49 +37,34 @@ static void x2apic_send_IPI(int cpu, int vector)
 static void
 __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 {
-	struct cpumask *cpus_in_cluster_ptr;
-	struct cpumask *ipi_mask_ptr;
-	unsigned int cpu, this_cpu;
+	unsigned int cpu, clustercpu;
+	struct cpumask *tmpmsk;
 	unsigned long flags;
 	u32 dest;
 
 	x2apic_wrmsr_fence();
-
 	local_irq_save(flags);
 
-	this_cpu = smp_processor_id();
+	tmpmsk = this_cpu_cpumask_var_ptr(ipi_mask);
+	cpumask_copy(tmpmsk, mask);
+	/* If IPI should not be sent to self, clear current CPU */
+	if (apic_dest != APIC_DEST_ALLINC)
+		cpumask_clear_cpu(smp_processor_id(), tmpmsk);
 
-	/*
-	 * We are to modify mask, so we need an own copy
-	 * and be sure it's manipulated with irq off.
-	 */
-	ipi_mask_ptr = this_cpu_cpumask_var_ptr(ipi_mask);
-	cpumask_copy(ipi_mask_ptr, mask);
+	/* Collapse cpus in a cluster so a single IPI per cluster is sent */
+	for_each_cpu(cpu, tmpmsk) {
+		struct cluster_mask *cmsk = per_cpu(cluster_masks, cpu);
 
-	/*
-	 * The idea is to send one IPI per cluster.
-	 */
-	for_each_cpu(cpu, ipi_mask_ptr) {
-		unsigned long i;
-
-		cpus_in_cluster_ptr = per_cpu(cpus_in_cluster, cpu);
 		dest = 0;
-
-		/* Collect cpus in cluster. */
-		for_each_cpu_and(i, ipi_mask_ptr, cpus_in_cluster_ptr) {
-			if (apic_dest == APIC_DEST_ALLINC || i != this_cpu)
-				dest |= per_cpu(x86_cpu_to_logical_apicid, i);
-		}
+		for_each_cpu_and(clustercpu, tmpmsk, &cmsk->mask)
+			dest |= per_cpu(x86_cpu_to_logical_apicid, clustercpu);
 
 		if (!dest)
 			continue;
 
 		__x2apic_send_IPI_dest(dest, vector, apic->dest_logical);
-		/*
-		 * Cluster sibling cpus should be discared now so
-		 * we would not send IPI them second time.
-		 */
-		cpumask_andnot(ipi_mask_ptr, ipi_mask_ptr, cpus_in_cluster_ptr);
+		/* Remove cluster CPUs from tmpmask */
+		cpumask_andnot(tmpmsk, tmpmsk, &cmsk->mask);
 	}
 
 	local_irq_restore(flags);
@@ -109,91 +96,100 @@ x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
 			  unsigned int *apicid)
 {
 	struct cpumask *effmsk = irq_data_get_effective_affinity_mask(irqdata);
+	struct cluster_mask *cmsk;
 	unsigned int cpu;
 	u32 dest = 0;
-	u16 cluster;
 
 	cpu = cpumask_first(mask);
 	if (cpu >= nr_cpu_ids)
 		return -EINVAL;
 
-	dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
-	cluster = x2apic_cluster(cpu);
-
+	cmsk = per_cpu(cluster_masks, cpu);
 	cpumask_clear(effmsk);
-	for_each_cpu(cpu, mask) {
-		if (cluster != x2apic_cluster(cpu))
-			continue;
+	for_each_cpu_and(cpu, &cmsk->mask, mask) {
 		dest |= per_cpu(x86_cpu_to_logical_apicid, cpu);
 		cpumask_set_cpu(cpu, effmsk);
 	}
-
 	*apicid = dest;
 	return 0;
 }
 
 static void init_x2apic_ldr(void)
 {
-	unsigned int this_cpu = smp_processor_id();
+	struct cluster_mask *cmsk = this_cpu_read(cluster_masks);
+	u32 cluster, apicid = apic_read(APIC_LDR);
 	unsigned int cpu;
 
-	per_cpu(x86_cpu_to_logical_apicid, this_cpu) = apic_read(APIC_LDR);
+	this_cpu_write(x86_cpu_to_logical_apicid, apicid);
 
-	cpumask_set_cpu(this_cpu, per_cpu(cpus_in_cluster, this_cpu));
+	if (cmsk)
+		goto update;
+
+	cluster = apicid >> 16;
 	for_each_online_cpu(cpu) {
-		if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
-			continue;
-		cpumask_set_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
-		cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
+		cmsk = per_cpu(cluster_masks, cpu);
+		/* Matching cluster found. Link and update it. */
+		if (cmsk && cmsk->clusterid == cluster)
+			goto update;
 	}
+	cmsk = cluster_hotplug_mask;
+	cluster_hotplug_mask = NULL;
+update:
+	this_cpu_write(cluster_masks, cmsk);
+	cpumask_set_cpu(smp_processor_id(), &cmsk->mask);
 }
 
-/*
- * At CPU state changes, update the x2apic cluster sibling info.
- */
-static int x2apic_prepare_cpu(unsigned int cpu)
+static int alloc_clustermask(unsigned int cpu, int node)
 {
-	if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL))
-		return -ENOMEM;
+	if (per_cpu(cluster_masks, cpu))
+		return 0;
+	/*
+	 * If a hotplug spare mask exists, check whether it's on the right
+	 * node. If not, free it and allocate a new one.
+	 */
+	if (cluster_hotplug_mask) {
+		if (cluster_hotplug_mask->node == node)
+			return 0;
+		kfree(cluster_hotplug_mask);
+	}
 
-	if (!zalloc_cpumask_var(&per_cpu(ipi_mask, cpu), GFP_KERNEL)) {
-		free_cpumask_var(per_cpu(cpus_in_cluster, cpu));
+	cluster_hotplug_mask = kzalloc_node(sizeof(*cluster_hotplug_mask),
+					    GFP_KERNEL, node);
+	if (!cluster_hotplug_mask)
 		return -ENOMEM;
-	}
+	cluster_hotplug_mask->node = node;
+	return 0;
+}
 
+static int x2apic_prepare_cpu(unsigned int cpu)
+{
+	if (alloc_clustermask(cpu, cpu_to_node(cpu)) < 0)
+		return -ENOMEM;
+	if (!zalloc_cpumask_var(&per_cpu(ipi_mask, cpu), GFP_KERNEL))
+		return -ENOMEM;
 	return 0;
 }
 
-static int x2apic_dead_cpu(unsigned int this_cpu)
+static int x2apic_dead_cpu(unsigned int dead_cpu)
 {
-	int cpu;
+	struct cluster_mask *cmsk = per_cpu(cluster_masks, dead_cpu);
 
-	for_each_online_cpu(cpu) {
-		if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
-			continue;
-		cpumask_clear_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
-		cpumask_clear_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
-	}
-	free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
-	free_cpumask_var(per_cpu(ipi_mask, this_cpu));
+	cpumask_clear_cpu(smp_processor_id(), &cmsk->mask);
+	free_cpumask_var(per_cpu(ipi_mask, dead_cpu));
 	return 0;
 }
 
 static int x2apic_cluster_probe(void)
 {
-	int cpu = smp_processor_id();
-	int ret;
-
 	if (!x2apic_mode)
 		return 0;
 
-	ret = cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "x86/x2apic:prepare",
-				x2apic_prepare_cpu, x2apic_dead_cpu);
-	if (ret < 0) {
+	if (cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "x86/x2apic:prepare",
+			      x2apic_prepare_cpu, x2apic_dead_cpu) < 0) {
 		pr_err("Failed to register X2APIC_PREPARE\n");
 		return 0;
 	}
-	cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, cpu));
+	init_x2apic_ldr();
 	return 1;
 }
 
@@ -208,6 +204,8 @@ static const struct cpumask *x2apic_cluster_target_cpus(void)
 static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
 					     const struct cpumask *mask)
 {
+	struct cluster_mask *cmsk = per_cpu(cluster_masks, cpu);
+
 	/*
 	 * To minimize vector pressure, default case of boot, device bringup
 	 * etc will use a single cpu for the interrupt destination.
@@ -220,7 +218,7 @@ static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
 	if (mask == x2apic_cluster_target_cpus())
 		cpumask_copy(retmask, cpumask_of(cpu));
 	else
-		cpumask_and(retmask, mask, per_cpu(cpus_in_cluster, cpu));
+		cpumask_and(retmask, mask, &cmsk->mask);
 }
 
 static struct apic apic_x2apic_cluster __ro_after_init = {

commit 981c2eac1cb97c7db64acf567950e7e81019dd33
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:16 2017 +0200

    x86/apic: Deinline x2apic functions
    
    These inline functions are used in both the cluster and the physical x2apic
    code to fill in the function pointers of the apic structure. That means the
    code is generated twice for no reason.
    
    Move it to a C code and reuse it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213153.358954066@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 481237cb1544..d7f5132ba5ca 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -8,7 +8,7 @@
 #include <linux/cpu.h>
 
 #include <asm/smp.h>
-#include <asm/x2apic.h>
+#include "x2apic.h"
 
 static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
 static DEFINE_PER_CPU(cpumask_var_t, cpus_in_cluster);

commit c7d6c9dd871f42c4e0ce5563d2f684e78ea673cf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:46 2017 +0200

    x86/apic: Implement effective irq mask update
    
    Add the effective irq mask update to the apic implementations and enable
    effective irq masks for x86.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235446.878370703@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 305031e0a228..481237cb1544 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -4,6 +4,7 @@
 #include <linux/kernel.h>
 #include <linux/ctype.h>
 #include <linux/dmar.h>
+#include <linux/irq.h>
 #include <linux/cpu.h>
 
 #include <asm/smp.h>
@@ -107,6 +108,7 @@ static int
 x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
 			  unsigned int *apicid)
 {
+	struct cpumask *effmsk = irq_data_get_effective_affinity_mask(irqdata);
 	unsigned int cpu;
 	u32 dest = 0;
 	u16 cluster;
@@ -118,10 +120,12 @@ x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
 	dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
 	cluster = x2apic_cluster(cpu);
 
+	cpumask_clear(effmsk);
 	for_each_cpu(cpu, mask) {
 		if (cluster != x2apic_cluster(cpu))
 			continue;
 		dest |= per_cpu(x86_cpu_to_logical_apicid, cpu);
+		cpumask_set_cpu(cpu, effmsk);
 	}
 
 	*apicid = dest;

commit 0e24f7c9f67e218546ad44160d2a12d9d8be0171
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:44 2017 +0200

    x86/apic: Add irq_data argument to apic->cpu_mask_to_apicid()
    
    The decision to which CPUs an interrupt is effectively routed happens in
    the various apic->cpu_mask_to_apicid() implementations
    
    To support effective affinity masks this information needs to be updated in
    irq_data. Add a pointer to irq_data to the callbacks and feed it through
    the call chain.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235446.720739075@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 61474259bf3f..305031e0a228 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -104,7 +104,8 @@ static void x2apic_send_IPI_all(int vector)
 }
 
 static int
-x2apic_cpu_mask_to_apicid(const struct cpumask *mask, unsigned int *apicid)
+x2apic_cpu_mask_to_apicid(const struct cpumask *mask, struct irq_data *irqdata,
+			  unsigned int *apicid)
 {
 	unsigned int cpu;
 	u32 dest = 0;

commit 91cd9cb7ee1c081304d0e61f09e9faccb33d3df7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:43 2017 +0200

    x86/apic: Move cpumask and to core code
    
    All implementations of apic->cpu_mask_to_apicid_and() and the two incoming
    cpumasks to search for the target.
    
    Move that operation to the call site and rename it to cpu_mask_to_apicid()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235446.641575516@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d73baa8c1a17..61474259bf3f 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -104,22 +104,20 @@ static void x2apic_send_IPI_all(int vector)
 }
 
 static int
-x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
-			      const struct cpumask *andmask,
-			      unsigned int *apicid)
+x2apic_cpu_mask_to_apicid(const struct cpumask *mask, unsigned int *apicid)
 {
 	unsigned int cpu;
 	u32 dest = 0;
 	u16 cluster;
 
-	cpu = cpumask_first_and(cpumask, andmask);
+	cpu = cpumask_first(mask);
 	if (cpu >= nr_cpu_ids)
 		return -EINVAL;
 
 	dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
 	cluster = x2apic_cluster(cpu);
 
-	for_each_cpu_and(cpu, cpumask, andmask) {
+	for_each_cpu(cpu, mask) {
 		if (cluster != x2apic_cluster(cpu))
 			continue;
 		dest |= per_cpu(x86_cpu_to_logical_apicid, cpu);
@@ -249,7 +247,7 @@ static struct apic apic_x2apic_cluster __ro_after_init = {
 	.get_apic_id			= x2apic_get_apic_id,
 	.set_apic_id			= x2apic_set_apic_id,
 
-	.cpu_mask_to_apicid_and		= x2apic_cpu_mask_to_apicid_and,
+	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,
 
 	.send_IPI			= x2apic_send_IPI,
 	.send_IPI_mask			= x2apic_send_IPI_mask,

commit 52b166af40faec9813cd5ac26d6ba9adec2e3a9d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:42 2017 +0200

    x86/apic: Move online masking to core code
    
    All implementations of apic->cpu_mask_to_apicid_and() mask out the offline
    cpus. The callsite already has a mask available, which has the offline CPUs
    removed. Use that and remove the extra bits.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235446.560868224@linutronix.de

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 5a35f208ed95..d73baa8c1a17 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -108,31 +108,24 @@ x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 			      const struct cpumask *andmask,
 			      unsigned int *apicid)
 {
+	unsigned int cpu;
 	u32 dest = 0;
 	u16 cluster;
-	int i;
-
-	for_each_cpu_and(i, cpumask, andmask) {
-		if (!cpumask_test_cpu(i, cpu_online_mask))
-			continue;
-		dest = per_cpu(x86_cpu_to_logical_apicid, i);
-		cluster = x2apic_cluster(i);
-		break;
-	}
 
-	if (!dest)
+	cpu = cpumask_first_and(cpumask, andmask);
+	if (cpu >= nr_cpu_ids)
 		return -EINVAL;
 
-	for_each_cpu_and(i, cpumask, andmask) {
-		if (!cpumask_test_cpu(i, cpu_online_mask))
-			continue;
-		if (cluster != x2apic_cluster(i))
+	dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
+	cluster = x2apic_cluster(cpu);
+
+	for_each_cpu_and(cpu, cpumask, andmask) {
+		if (cluster != x2apic_cluster(cpu))
 			continue;
-		dest |= per_cpu(x86_cpu_to_logical_apicid, i);
+		dest |= per_cpu(x86_cpu_to_logical_apicid, cpu);
 	}
 
 	*apicid = dest;
-
 	return 0;
 }
 

commit 73c1b41e63f040e92669e61a02c7893933bfe743
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 21 20:19:54 2016 +0100

    cpu/hotplug: Cleanup state names
    
    When the state names got added a script was used to add the extra argument
    to the calls. The script basically converted the state constant to a
    string, but the cleanup to convert these strings into meaningful ones did
    not happen.
    
    Replace all the useless strings with 'subsys/xxx/yyy:state' strings which
    are used in all the other places already.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sebastian Siewior <bigeasy@linutronix.de>
    Link: http://lkml.kernel.org/r/20161221192112.085444152@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 200af5ae9662..5a35f208ed95 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -191,7 +191,7 @@ static int x2apic_cluster_probe(void)
 	if (!x2apic_mode)
 		return 0;
 
-	ret = cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "X2APIC_PREPARE",
+	ret = cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "x86/x2apic:prepare",
 				x2apic_prepare_cpu, x2apic_dead_cpu);
 	if (ret < 0) {
 		pr_err("Failed to register X2APIC_PREPARE\n");

commit 2b3061c77ce7e429b25a25560ba088e8e7193a67
Merge: 01175255fd8e 25dfe4785332
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Sep 8 08:41:52 2016 +0200

    Merge branch 'x86/mm' into x86/asm, to unify the two branches for simplicity
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit d52c0569bab4edc888832df44dc7ac28517134f6
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Thu Aug 11 16:08:35 2016 +0200

    x86/apic/x2apic, smp/hotplug: Don't use before alloc in x2apic_cluster_probe()
    
    I made a mistake while converting the driver to the hotplug state
    machine and as a result x2apic_cluster_probe() was accessing
    cpus_in_cluster before allocating it.
    
    This patch fixes it by setting the cpumask after the allocation the
    memory succeeded.
    
    While at it, I marked two functions static which are only used within
    this file.
    
    Reported-by: Laura Abbott <labbott@redhat.com>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 6b2c28471de5 ("x86/x2apic: Convert to CPU hotplug state machine")
    Link: http://lkml.kernel.org/r/1470924515-9444-1-git-send-email-bigeasy@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 6368fa69d2af..54f35d988025 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -155,7 +155,7 @@ static void init_x2apic_ldr(void)
 /*
  * At CPU state changes, update the x2apic cluster sibling info.
  */
-int x2apic_prepare_cpu(unsigned int cpu)
+static int x2apic_prepare_cpu(unsigned int cpu)
 {
 	if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL))
 		return -ENOMEM;
@@ -168,7 +168,7 @@ int x2apic_prepare_cpu(unsigned int cpu)
 	return 0;
 }
 
-int x2apic_dead_cpu(unsigned int this_cpu)
+static int x2apic_dead_cpu(unsigned int this_cpu)
 {
 	int cpu;
 
@@ -186,13 +186,18 @@ int x2apic_dead_cpu(unsigned int this_cpu)
 static int x2apic_cluster_probe(void)
 {
 	int cpu = smp_processor_id();
+	int ret;
 
 	if (!x2apic_mode)
 		return 0;
 
+	ret = cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "X2APIC_PREPARE",
+				x2apic_prepare_cpu, x2apic_dead_cpu);
+	if (ret < 0) {
+		pr_err("Failed to register X2APIC_PREPARE\n");
+		return 0;
+	}
 	cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, cpu));
-	cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "X2APIC_PREPARE",
-			  x2apic_prepare_cpu, x2apic_dead_cpu);
 	return 1;
 }
 

commit 404f6aac9b3ef595735feca99979db084ea48315
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Aug 8 16:29:06 2016 -0700

    x86: Apply more __ro_after_init and const
    
    Guided by grsecurity's analogous __read_only markings in arch/x86,
    this applies several uses of __ro_after_init to structures that are
    only updated during __init, and const for some structures that are
    never updated.  Additionally extends __init markings to some functions
    that are only used during __init, and cleans up some missing C99 style
    static initializers.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: David Brown <david.brown@linaro.org>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathias Krause <minipli@googlemail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: kernel-hardening@lists.openwall.com
    Link: http://lkml.kernel.org/r/20160808232906.GA29731@www.outflux.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 6368fa69d2af..766bdef1e1d7 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -222,7 +222,7 @@ static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
 		cpumask_and(retmask, mask, per_cpu(cpus_in_cluster, cpu));
 }
 
-static struct apic apic_x2apic_cluster = {
+static struct apic apic_x2apic_cluster __ro_after_init = {
 
 	.name				= "cluster x2apic",
 	.probe				= x2apic_cluster_probe,

commit a6408f6cb63ac0958fee7dbce7861ffb540d8a49
Merge: 1a81a8f2a591 4fae16dffb81
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 29 13:55:30 2016 -0700

    Merge branch 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull smp hotplug updates from Thomas Gleixner:
     "This is the next part of the hotplug rework.
    
       - Convert all notifiers with a priority assigned
    
       - Convert all CPU_STARTING/DYING notifiers
    
         The final removal of the STARTING/DYING infrastructure will happen
         when the merge window closes.
    
      Another 700 hundred line of unpenetrable maze gone :)"
    
    * 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (70 commits)
      timers/core: Correct callback order during CPU hot plug
      leds/trigger/cpu: Move from CPU_STARTING to ONLINE level
      powerpc/numa: Convert to hotplug state machine
      arm/perf: Fix hotplug state machine conversion
      irqchip/armada: Avoid unused function warnings
      ARC/time: Convert to hotplug state machine
      clocksource/atlas7: Convert to hotplug state machine
      clocksource/armada-370-xp: Convert to hotplug state machine
      clocksource/exynos_mct: Convert to hotplug state machine
      clocksource/arm_global_timer: Convert to hotplug state machine
      rcu: Convert rcutree to hotplug state machine
      KVM/arm/arm64/vgic-new: Convert to hotplug state machine
      smp/cfd: Convert core to hotplug state machine
      x86/x2apic: Convert to CPU hotplug state machine
      profile: Convert to hotplug state machine
      timers/core: Convert to hotplug state machine
      hrtimer: Convert to hotplug state machine
      x86/tboot: Convert to hotplug state machine
      arm64/armv8 deprecated: Convert to hotplug state machine
      hwtracing/coresight-etm4x: Convert to hotplug state machine
      ...

commit 6b2c28471de550308784560206c3365e5179d42f
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jul 13 17:17:00 2016 +0000

    x86/x2apic: Convert to CPU hotplug state machine
    
    Install the callbacks via the state machine and let the core invoke
    the callbacks on the already online CPUs.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathias Krause <minipli@googlemail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: rt@linutronix.de
    Link: http://lkml.kernel.org/r/20160713153337.736898691@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index aca8b75c1552..b5da5a8e5e45 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -152,68 +152,48 @@ static void init_x2apic_ldr(void)
 	}
 }
 
- /*
-  * At CPU state changes, update the x2apic cluster sibling info.
-  */
-static int
-update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
+/*
+ * At CPU state changes, update the x2apic cluster sibling info.
+ */
+int x2apic_prepare_cpu(unsigned int cpu)
 {
-	unsigned int this_cpu = (unsigned long)hcpu;
-	unsigned int cpu;
-	int err = 0;
-
-	switch (action) {
-	case CPU_UP_PREPARE:
-		if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, this_cpu),
-					GFP_KERNEL)) {
-			err = -ENOMEM;
-		} else if (!zalloc_cpumask_var(&per_cpu(ipi_mask, this_cpu),
-					       GFP_KERNEL)) {
-			free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
-			err = -ENOMEM;
-		}
-		break;
-	case CPU_UP_CANCELED:
-	case CPU_UP_CANCELED_FROZEN:
-	case CPU_DEAD:
-		for_each_online_cpu(cpu) {
-			if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
-				continue;
-			cpumask_clear_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
-			cpumask_clear_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
-		}
-		free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
-		free_cpumask_var(per_cpu(ipi_mask, this_cpu));
-		break;
+	if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL))
+		return -ENOMEM;
+
+	if (!zalloc_cpumask_var(&per_cpu(ipi_mask, cpu), GFP_KERNEL)) {
+		free_cpumask_var(per_cpu(cpus_in_cluster, cpu));
+		return -ENOMEM;
 	}
 
-	return notifier_from_errno(err);
+	return 0;
 }
 
-static struct notifier_block x2apic_cpu_notifier = {
-	.notifier_call = update_clusterinfo,
-};
-
-static int x2apic_init_cpu_notifier(void)
+int x2apic_dead_cpu(unsigned int this_cpu)
 {
-	int cpu = smp_processor_id();
-
-	zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL);
-	zalloc_cpumask_var(&per_cpu(ipi_mask, cpu), GFP_KERNEL);
+	int cpu;
 
-	BUG_ON(!per_cpu(cpus_in_cluster, cpu) || !per_cpu(ipi_mask, cpu));
-
-	cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, cpu));
-	register_hotcpu_notifier(&x2apic_cpu_notifier);
-	return 1;
+	for_each_online_cpu(cpu) {
+		if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
+			continue;
+		cpumask_clear_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
+		cpumask_clear_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
+	}
+	free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
+	free_cpumask_var(per_cpu(ipi_mask, this_cpu));
+	return 0;
 }
 
 static int x2apic_cluster_probe(void)
 {
-	if (x2apic_mode)
-		return x2apic_init_cpu_notifier();
-	else
+	int cpu = smp_processor_id();
+
+	if (!x2apic_mode)
 		return 0;
+
+	cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, cpu));
+	cpuhp_setup_state(CPUHP_X2APIC_PREPARE, "X2APIC_PREPARE",
+			  x2apic_prepare_cpu, x2apic_dead_cpu);
+	return 1;
 }
 
 static const struct cpumask *x2apic_cluster_target_cpus(void)

commit 102bb9fef68a21f357dc813d4792666c8295bc35
Author: Wei Jiangang <weijg.fnst@cn.fujitsu.com>
Date:   Thu Jul 14 10:24:06 2016 +0800

    x86/apic: Remove the unused struct apic::apic_id_mask field
    
    The only user verify_local_APIC() had been removed by commit:
    
      4399c03c6780 ("x86/apic: Remove verify_local_APIC()")
    
    ... so there is no need to keep it.
    
    Signed-off-by: Wei Jiangang <weijg.fnst@cn.fujitsu.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: boris.ostrovsky@oracle.com
    Cc: bsd@redhat.com
    Cc: david.vrabel@citrix.com
    Cc: jgross@suse.com
    Cc: konrad.wilk@oracle.com
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1468463046-20849-1-git-send-email-weijg.fnst@cn.fujitsu.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index aca8b75c1552..24170d0809ba 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -270,7 +270,6 @@ static struct apic apic_x2apic_cluster = {
 
 	.get_apic_id			= x2apic_get_apic_id,
 	.set_apic_id			= x2apic_set_apic_id,
-	.apic_id_mask			= 0xFFFFFFFFu,
 
 	.cpu_mask_to_apicid_and		= x2apic_cpu_mask_to_apicid_and,
 

commit 7b6ce46cb3d096831dea3accacee4717c66abac8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 4 22:57:00 2015 +0000

    x86/apic: Implement single target IPI function for x2apic_cluster
    
    [ tglx: Split it out from the patch which provides the new callback ]
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Mike Travis <travis@sgi.com>
    Cc: Daniel J Blueman <daniel@numascale.com>
    Link: http://lkml.kernel.org/r/20151104220848.817975597@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index cc8311c4d298..aca8b75c1552 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -23,6 +23,14 @@ static inline u32 x2apic_cluster(int cpu)
 	return per_cpu(x86_cpu_to_logical_apicid, cpu) >> 16;
 }
 
+static void x2apic_send_IPI(int cpu, int vector)
+{
+	u32 dest = per_cpu(x86_cpu_to_logical_apicid, cpu);
+
+	x2apic_wrmsr_fence();
+	__x2apic_send_IPI_dest(dest, vector, APIC_DEST_LOGICAL);
+}
+
 static void
 __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 {
@@ -266,6 +274,7 @@ static struct apic apic_x2apic_cluster = {
 
 	.cpu_mask_to_apicid_and		= x2apic_cpu_mask_to_apicid_and,
 
+	.send_IPI			= x2apic_send_IPI,
 	.send_IPI_mask			= x2apic_send_IPI_mask,
 	.send_IPI_mask_allbutself	= x2apic_send_IPI_mask_allbutself,
 	.send_IPI_allbutself		= x2apic_send_IPI_allbutself,

commit 0c0fee018d14b585461b146bdeda8bab9a61c211
Merge: a0c0d985ded5 4daa832d9987
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 09:33:26 2015 -0700

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 init code fixlet from Ingo Molnar:
     "A single change: fix obsolete init code annotations"
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Drop bogus __ref / __refdata annotations

commit 656bba306827a44ed73b3f93f75bb3147de17fae
Author: Len Brown <len.brown@intel.com>
Date:   Sun Aug 16 11:45:48 2015 -0400

    x86/smpboot: Remove APIC.wait_for_init_deassert and atomic init_deasserted
    
    Both the per-APIC flag ".wait_for_init_deassert",
    and the global atomic_t "init_deasserted"
    are dead code -- remove them.
    
    For all APIC types, "wait_for_master()"
    prevents an AP from proceeding until the BSP has set
    cpu_callout_mask, making "init_deasserted" {unnecessary}:
    
            BSP: <de-assert INIT>
            ...
            BSP: {set init_deasserted}
            AP: wait_for_master()
                    set cpu_initialized_mask
                    wait for cpu_callout_mask
            BSP: test cpu_initialized_mask
            BSP: set cpu_callout_mask
            AP: test cpu_callout_mask
            AP: {wait for init_deasserted}
            ...
            AP: <touch APIC>
    
    Deleting the {dead code} above is necessary to enable
    some parallelism in a future patch.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Igor Mammedov <imammedo@redhat.com>
    Cc: Jan H. Schönherr <jschoenh@amazon.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Zhu Guihua <zhugh.fnst@cn.fujitsu.com>
    Link: http://lkml.kernel.org/r/de4b3a9bab894735e285870b5296da25ee6a8a5a.1439739165.git.len.brown@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index ab3219b3fbda..1b6c1a4526a5 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -272,7 +272,6 @@ static struct apic apic_x2apic_cluster = {
 	.send_IPI_all			= x2apic_send_IPI_all,
 	.send_IPI_self			= x2apic_send_IPI_self,
 
-	.wait_for_init_deassert		= false,
 	.inquire_remote_apic		= NULL,
 
 	.read				= native_apic_msr_read,

commit 4daa832d99871356f5fdc52372c975e40f73a15e
Author: Mathias Krause <minipli@googlemail.com>
Date:   Mon Jul 20 18:32:53 2015 +0200

    x86: Drop bogus __ref / __refdata annotations
    
    The __ref / __refdata annotations used to be needed because of
    referencing functions / variables annotated __cpuinit /
    __cpuinitdata.
    
    But those annotations vanished during the development of v3.11.
    
    Therefore most of the __ref / __refdata annotations are not needed
    anymore. As they may hide legitimate sections mismatches, we
    better get rid of them.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1437409973-8927-1-git-send-email-minipli@googlemail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index ab3219b3fbda..e709bc276feb 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -182,7 +182,7 @@ update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __refdata x2apic_cpu_notifier = {
+static struct notifier_block x2apic_cpu_notifier = {
 	.notifier_call = update_clusterinfo,
 };
 

commit fdaf3a6539d6b9b6a7240c3b00bd81c813b2760d
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Tue Mar 10 12:43:45 2015 +1030

    x86: fix more deprecated cpu function usage.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d9d0bd2faaf4..ab3219b3fbda 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -171,8 +171,8 @@ update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
 		for_each_online_cpu(cpu) {
 			if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
 				continue;
-			__cpu_clear(this_cpu, per_cpu(cpus_in_cluster, cpu));
-			__cpu_clear(cpu, per_cpu(cpus_in_cluster, this_cpu));
+			cpumask_clear_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
+			cpumask_clear_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
 		}
 		free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
 		free_cpumask_var(per_cpu(ipi_mask, this_cpu));

commit d089f8e97d371a662dd233491e03bda377c9d46d
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Mar 5 10:49:17 2015 +1030

    x86: fix up obsolete cpu function usage.
    
    Thanks to spatch, plus manual removal of "&*".
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: x86@kernel.org

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index e658f21681c8..d9d0bd2faaf4 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -135,12 +135,12 @@ static void init_x2apic_ldr(void)
 
 	per_cpu(x86_cpu_to_logical_apicid, this_cpu) = apic_read(APIC_LDR);
 
-	__cpu_set(this_cpu, per_cpu(cpus_in_cluster, this_cpu));
+	cpumask_set_cpu(this_cpu, per_cpu(cpus_in_cluster, this_cpu));
 	for_each_online_cpu(cpu) {
 		if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
 			continue;
-		__cpu_set(this_cpu, per_cpu(cpus_in_cluster, cpu));
-		__cpu_set(cpu, per_cpu(cpus_in_cluster, this_cpu));
+		cpumask_set_cpu(this_cpu, per_cpu(cpus_in_cluster, cpu));
+		cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, this_cpu));
 	}
 }
 
@@ -195,7 +195,7 @@ static int x2apic_init_cpu_notifier(void)
 
 	BUG_ON(!per_cpu(cpus_in_cluster, cpu) || !per_cpu(ipi_mask, cpu));
 
-	__cpu_set(cpu, per_cpu(cpus_in_cluster, cpu));
+	cpumask_set_cpu(cpu, per_cpu(cpus_in_cluster, cpu));
 	register_hotcpu_notifier(&x2apic_cpu_notifier);
 	return 1;
 }

commit 59f6e2073c72d36c814a4417320bfa4874faa228
Author: Mel Gorman <mgorman@suse.de>
Date:   Mon Sep 8 23:06:54 2014 +0100

    percpu: Resolve ambiguities in __get_cpu_var/cpumask_var_t -fix
    
    A commit in linux-next was causing boot to fail and bisection
    identified the patch 4ba2968420fa ("percpu: Resolve ambiguities in
    __get_cpu_var/cpumask_var_").  One of the changes in that patch looks
    very suspicious.  Reverting the full patch fixes boot as does this
    fixlet.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Christoph Lameter <cl@linux.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 1f5d5f2ffae6..e658f21681c8 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -43,6 +43,7 @@ __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 	 * and be sure it's manipulated with irq off.
 	 */
 	ipi_mask_ptr = this_cpu_cpumask_var_ptr(ipi_mask);
+	cpumask_copy(ipi_mask_ptr, mask);
 
 	/*
 	 * The idea is to send one IPI per cluster.

commit 4ba2968420fa9d0604b6a6a5c61bfa8d0fa84ae0
Author: Christoph Lameter <cl@linux.com>
Date:   Tue Aug 26 19:12:21 2014 -0500

    percpu: Resolve ambiguities in __get_cpu_var/cpumask_var_t
    
    __get_cpu_var can paper over differences in the definitions of
    cpumask_var_t and either use the address of the cpumask variable
    directly or perform a fetch of the address of the struct cpumask
    allocated elsewhere. This is important particularly when using per cpu
    cpumask_var_t declarations because in one case we have an offset into
    a per cpu area to handle and in the other case we need to fetch a
    pointer from the offset.
    
    This patch introduces a new macro
    
    this_cpu_cpumask_var_ptr()
    
    that is defined where cpumask_var_t is defined and performs the proper
    actions. All use cases where __get_cpu_var is used with cpumask_var_t
    are converted to the use of this_cpu_cpumask_var_ptr().
    
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 6ce600f9bc78..1f5d5f2ffae6 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -42,8 +42,7 @@ __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 	 * We are to modify mask, so we need an own copy
 	 * and be sure it's manipulated with irq off.
 	 */
-	ipi_mask_ptr = __raw_get_cpu_var(ipi_mask);
-	cpumask_copy(ipi_mask_ptr, mask);
+	ipi_mask_ptr = this_cpu_cpumask_var_ptr(ipi_mask);
 
 	/*
 	 * The idea is to send one IPI per cluster.

commit 2f078b9cb8798cdabb7c2ff24b0b683eea546f96
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:51 2014 -0700

    x86, apic: Remove enable_apic_mode callback
    
    The enable_apic_mode() apic callback is never called, so remove it.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302352320.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index ac70128aa9e9..6ce600f9bc78 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -258,7 +258,6 @@ static struct apic apic_x2apic_cluster = {
 	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
 	.apicid_to_cpu_present		= NULL,
 	.check_phys_apicid_present	= default_check_phys_apicid_present,
-	.enable_apic_mode		= NULL,
 	.phys_pkg_id			= x2apic_phys_pkg_id,
 
 	.get_apic_id			= x2apic_get_apic_id,

commit 11a8318ef5a69cdb9be61f726d6e078d70af6129
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:47 2014 -0700

    x86, apic: Remove setup_portio_remap callback
    
    Since commit b5660ba76b41 ("x86, platforms: Remove NUMAQ") removed NUMAQ,
    the setup_portio_remap() apic callback has been obsolete.  Remove it.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302351480.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 88eeaa90c91c..ac70128aa9e9 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -257,7 +257,6 @@ static struct apic apic_x2apic_cluster = {
 	.setup_apic_routing		= NULL,
 	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
 	.apicid_to_cpu_present		= NULL,
-	.setup_portio_remap		= NULL,
 	.check_phys_apicid_present	= default_check_phys_apicid_present,
 	.enable_apic_mode		= NULL,
 	.phys_pkg_id			= x2apic_phys_pkg_id,

commit e76661ba09353efd04e3435ac15bb9444f5cf1fa
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:43 2014 -0700

    x86, apic: Remove multi_timer_check callback
    
    Since commit b5660ba76b41 ("x86, platforms: Remove NUMAQ") removed NUMAQ,
    the multi_timer_check() apic callback has been obsolete.  Remove it.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302351120.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d7bbe89b18da..88eeaa90c91c 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -255,7 +255,6 @@ static struct apic apic_x2apic_cluster = {
 
 	.ioapic_phys_id_map		= NULL,
 	.setup_apic_routing		= NULL,
-	.multi_timer_check		= NULL,
 	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
 	.apicid_to_cpu_present		= NULL,
 	.setup_portio_remap		= NULL,

commit 658ffd7e6f5ce62e15df99df5f9e181d76ffda8e
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:37 2014 -0700

    x86, apic: Remove check_apicid_present callback
    
    The check_apicid_present() apic callback is never called, so remove it
    and functions that implement it.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302350160.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 7e4ac5587af0..d7bbe89b18da 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -249,7 +249,6 @@ static struct apic apic_x2apic_cluster = {
 	.disable_esr			= 0,
 	.dest_logical			= APIC_DEST_LOGICAL,
 	.check_apicid_used		= NULL,
-	.check_apicid_present		= NULL,
 
 	.vector_allocation_domain	= cluster_vector_allocation_domain,
 	.init_apic_ldr			= init_x2apic_ldr,

commit c460b5d34018d71fdeb8540620690883db3f959b
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:34 2014 -0700

    x86, apic: Remove mps_oem_check callback
    
    Since commit b5660ba76b41 ("x86, platforms: Remove NUMAQ") removed NUMAQ,
    the mps_oem_check() apic callback has been obsolete.  Remove it.
    
    This allows generic_mps_oem_check() to be removed as well.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302349390.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index d96cab15f6f4..7e4ac5587af0 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -263,7 +263,6 @@ static struct apic apic_x2apic_cluster = {
 	.check_phys_apicid_present	= default_check_phys_apicid_present,
 	.enable_apic_mode		= NULL,
 	.phys_pkg_id			= x2apic_phys_pkg_id,
-	.mps_oem_check			= NULL,
 
 	.get_apic_id			= x2apic_get_apic_id,
 	.set_apic_id			= x2apic_set_apic_id,

commit 300eddf967920d35affa75db77c50c0fa493446a
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:30 2014 -0700

    x86, apic: Remove smp_callin_clear_local_apic callback
    
    Since commit b5660ba76b41 ("x86, platforms: Remove NUMAQ") removed NUMAQ,
    the smp_callin_clear_local_apic() apic callback has been obsolete.
    Remove it.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302349040.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 8b3200cc57e3..d96cab15f6f4 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -278,7 +278,6 @@ static struct apic apic_x2apic_cluster = {
 	.send_IPI_self			= x2apic_send_IPI_self,
 
 	.wait_for_init_deassert		= false,
-	.smp_callin_clear_local_apic	= NULL,
 	.inquire_remote_apic		= NULL,
 
 	.read				= native_apic_msr_read,

commit 6ab1b27c849106647c42b3ea0681a039552e24fa
Author: David Rientjes <rientjes@google.com>
Date:   Wed Jul 30 23:53:27 2014 -0700

    x86, apic: Replace trampoline physical addresses with defaults
    
    The trampoline_phys_{high,low} members of struct apic are always
    initialized to DEFAULT_TRAMPOLINE_PHYS_HIGH and TRAMPOLINE_PHYS_LOW,
    respectively.  Hardwire the constants and remove the unneeded members.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1407302348330.17503@chino.kir.corp.google.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index e66766bf1641..8b3200cc57e3 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -277,8 +277,6 @@ static struct apic apic_x2apic_cluster = {
 	.send_IPI_all			= x2apic_send_IPI_all,
 	.send_IPI_self			= x2apic_send_IPI_self,
 
-	.trampoline_phys_low		= DEFAULT_TRAMPOLINE_PHYS_LOW,
-	.trampoline_phys_high		= DEFAULT_TRAMPOLINE_PHYS_HIGH,
 	.wait_for_init_deassert		= false,
 	.smp_callin_clear_local_apic	= NULL,
 	.inquire_remote_apic		= NULL,

commit 465822cfc8cb850ba76046965cc7b6fd1f8c3d73
Author: David Rientjes <rientjes@google.com>
Date:   Tue Feb 4 23:55:01 2014 -0800

    x86/apic: Switch wait_for_init_deassert() to a bool flag
    
    Now that there is only a single wait_for_init_deassert()
    function, just convert the member of struct apic to a bool to
    determine whether we need to wait for init_deassert to become
    non-zero.
    
    There are no more callers of default_wait_for_init_deassert(),
    so fold it into the caller.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1402042354010.7839@chino.kir.corp.google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index cac85ee6913f..e66766bf1641 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -279,7 +279,7 @@ static struct apic apic_x2apic_cluster = {
 
 	.trampoline_phys_low		= DEFAULT_TRAMPOLINE_PHYS_LOW,
 	.trampoline_phys_high		= DEFAULT_TRAMPOLINE_PHYS_HIGH,
-	.wait_for_init_deassert		= NULL,
+	.wait_for_init_deassert		= false,
 	.smp_callin_clear_local_apic	= NULL,
 	.inquire_remote_apic		= NULL,
 

commit 663b55b9b39fa9c848cca273ca4e12bf29b32c71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jan 6 19:20:26 2014 -0500

    x86: Delete non-required instances of include <linux/init.h>
    
    None of these files are actually using any __init type directives
    and hence don't need to include <linux/init.h>.  Most are just a
    left over from __devinit and __cpuinit removal, or simply due to
    code getting copied from one driver to the next.
    
    [ hpa: undid incorrect removal from arch/x86/kernel/head_32.S ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Link: http://lkml.kernel.org/r/1389054026-12947-1-git-send-email-paul.gortmaker@windriver.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 140e29db478d..cac85ee6913f 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -3,7 +3,6 @@
 #include <linux/string.h>
 #include <linux/kernel.h>
 #include <linux/ctype.h>
-#include <linux/init.h>
 #include <linux/dmar.h>
 #include <linux/cpu.h>
 

commit 148f9bb87745ed45f7a11b2cbd3bc0f017d5d257
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Jun 18 18:23:59 2013 -0400

    x86: delete __cpuinit usage from all x86 files
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    are flagged as __cpuinit  -- so if we remove the __cpuinit from
    arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    content into no-ops as early as possible, since that will get rid
    of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the arch/x86 uses of the __cpuinit macros from
    all C files.  x86 only had the one __CPUINIT used in assembly files,
    and it wasn't paired off with a .previous or a __FINIT, so we can
    delete it directly w/o any corresponding additional change there.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index c88baa4ff0e5..140e29db478d 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -148,7 +148,7 @@ static void init_x2apic_ldr(void)
  /*
   * At CPU state changes, update the x2apic cluster sibling info.
   */
-static int __cpuinit
+static int
 update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
 {
 	unsigned int this_cpu = (unsigned long)hcpu;

commit d872818dbbeed1bccf58c7f8c7db432154c802f9
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Jun 25 13:38:29 2012 -0700

    x86/apic/x2apic: Use multiple cluster members for the irq destination only with the explicit affinity
    
    During boot or driver load etc, interrupt destination is setup
    using default target cpu's. Later the user (irqbalance etc) or
    the driver (irq_set_affinity/ irq_set_affinity_hint) can request
    the interrupt to be migrated to some specific set of cpu's.
    
    In the x2apic cluster routing, for the default scenario use
    single cpu as the interrupt destination and when there is an
    explicit interrupt affinity request, route the interrupt to
    multiple members of a x2apic cluster specified in the cpumask of
    the migration request.
    
    This will minmize the vector pressure when there are lot of
    interrupt sources and relatively few x2apic clusters (for
    example a single socket server). This will allow the performance
    critical interrupts to be routed to multiple cpu's in the x2apic
    cluster (irqbalance for example uses the cache siblings etc
    while specifying the interrupt destination) and allow
    non-critical interrupts to be serviced by a single logical cpu.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Alexander Gordeev <agordeev@redhat.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Link: http://lkml.kernel.org/r/1340656709-11423-4-git-send-email-suresh.b.siddha@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index bde78d0098a4..c88baa4ff0e5 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -209,13 +209,30 @@ static int x2apic_cluster_probe(void)
 		return 0;
 }
 
+static const struct cpumask *x2apic_cluster_target_cpus(void)
+{
+	return cpu_all_mask;
+}
+
 /*
  * Each x2apic cluster is an allocation domain.
  */
 static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
 					     const struct cpumask *mask)
 {
-	cpumask_and(retmask, mask, per_cpu(cpus_in_cluster, cpu));
+	/*
+	 * To minimize vector pressure, default case of boot, device bringup
+	 * etc will use a single cpu for the interrupt destination.
+	 *
+	 * On explicit migration requests coming from irqbalance etc,
+	 * interrupts will be routed to the x2apic cluster (cluster-id
+	 * derived from the first cpu in the mask) members specified
+	 * in the mask.
+	 */
+	if (mask == x2apic_cluster_target_cpus())
+		cpumask_copy(retmask, cpumask_of(cpu));
+	else
+		cpumask_and(retmask, mask, per_cpu(cpus_in_cluster, cpu));
 }
 
 static struct apic apic_x2apic_cluster = {
@@ -229,7 +246,7 @@ static struct apic apic_x2apic_cluster = {
 	.irq_delivery_mode		= dest_LowestPrio,
 	.irq_dest_mode			= 1, /* logical */
 
-	.target_cpus			= online_target_cpus,
+	.target_cpus			= x2apic_cluster_target_cpus,
 	.disable_esr			= 0,
 	.dest_logical			= APIC_DEST_LOGICAL,
 	.check_apicid_used		= NULL,

commit 1ac322d0b169c95ce34d55b3ed6d40ce1a5f3a02
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Jun 25 13:38:28 2012 -0700

    x86/apic/x2apic: Limit the vector reservation to the user specified mask
    
    For the x2apic cluster mode, vector for an interrupt is
    currently reserved on all the cpu's that are part of the x2apic
    cluster. But the interrupts will be routed only to the cluster
    (derived from the first cpu in the mask) members specified in
    the mask. So there is no need to reserve the vector in the
    unused cluster members.
    
    Modify __assign_irq_vector() to reserve the vectors based on the
    user specified irq destination mask. If the new mask is a proper
    subset of the currently used mask, cleanup the vector allocation
    on the unused cpu members.
    
    Also, allow the apic driver to tune the vector domain based on
    the affinity mask (which in most cases is the user-specified
    mask).
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Alexander Gordeev <agordeev@redhat.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Link: http://lkml.kernel.org/r/1340656709-11423-3-git-send-email-suresh.b.siddha@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index b5d889b5659a..bde78d0098a4 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -212,10 +212,10 @@ static int x2apic_cluster_probe(void)
 /*
  * Each x2apic cluster is an allocation domain.
  */
-static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
+static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask,
+					     const struct cpumask *mask)
 {
-	cpumask_clear(retmask);
-	cpumask_copy(retmask, per_cpu(cpus_in_cluster, cpu));
+	cpumask_and(retmask, mask, per_cpu(cpus_in_cluster, cpu));
 }
 
 static struct apic apic_x2apic_cluster = {

commit b39f25a849d7677a7dbf183f2483fd41c201a5ce
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Jun 25 13:38:27 2012 -0700

    x86/apic: Optimize cpu traversal in __assign_irq_vector() using domain membership
    
    Currently __assign_irq_vector() goes through each cpu in the
    specified mask until it finds a free vector in all the cpu's
    that are part of the same interrupt domain. We visit all the
    interrupt domain sibling cpus to reserve the free vector. So,
    when we fail to find a free vector in an interrupt domain, it is
    safe to continue our search with a cpu belonging to a new
    interrupt domain. No need to go through each cpu, if the domain
    containing that cpu is already visited.
    
    Use the irq_cfg's old_domain to track the visited domains and
    optimize the cpu traversal while finding a free vector in the
    given cpumask.
    
    NOTE: We can also optimize the search by using for_each_cpu() and
    skip the current cpu, if it is not the first cpu in the mask
    returned by the vector_allocation_domain(). But re-using the
    cfg->old_domain to track the visited domains will be slightly
    faster.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Alexander Gordeev <agordeev@redhat.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Link: http://lkml.kernel.org/r/1340656709-11423-2-git-send-email-suresh.b.siddha@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 943d03fc6fc4..b5d889b5659a 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -212,11 +212,10 @@ static int x2apic_cluster_probe(void)
 /*
  * Each x2apic cluster is an allocation domain.
  */
-static bool cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
+static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
 {
 	cpumask_clear(retmask);
 	cpumask_copy(retmask, per_cpu(cpus_in_cluster, cpu));
-	return true;
 }
 
 static struct apic apic_x2apic_cluster = {

commit a5a391561bc25898ba1a702a0c4b028aa5b11ce9
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Thu Jun 14 09:49:35 2012 +0200

    x86/apic: Eliminate cpu_mask_to_apicid() operation
    
    Since there are only two locations where cpu_mask_to_apicid() is
    called from, remove the operation and use only
    cpu_mask_to_apicid_and() instead.
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Suggested-and-acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120614074935.GE3383@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 1885a73b7f33..943d03fc6fc4 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -96,22 +96,6 @@ static void x2apic_send_IPI_all(int vector)
 	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
 }
 
-static int
-x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask, unsigned int *apicid)
-{
-	int cpu = cpumask_first_and(cpumask, cpu_online_mask);
-	int i;
-
-	if (cpu >= nr_cpu_ids)
-		return -EINVAL;
-
-	*apicid = 0;
-	for_each_cpu_and(i, cpumask, per_cpu(cpus_in_cluster, cpu))
-		*apicid |= per_cpu(x86_cpu_to_logical_apicid, i);
-
-	return 0;
-}
-
 static int
 x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 			      const struct cpumask *andmask,
@@ -270,7 +254,6 @@ static struct apic apic_x2apic_cluster = {
 	.set_apic_id			= x2apic_set_apic_id,
 	.apic_id_mask			= 0xFFFFFFFFu,
 
-	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,
 	.cpu_mask_to_apicid_and		= x2apic_cpu_mask_to_apicid_and,
 
 	.send_IPI_mask			= x2apic_send_IPI_mask,

commit cac4afbc3da58d9e5701b34bd4c1f11ea13328d4
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Thu Jun 14 12:39:34 2012 +0200

    x86/x2apic/cluster: Vector_allocation_domain() should return a value
    
    Since commit 8637e38 ("x86/apic: Avoid useless scanning thru a
    cpumask in assign_irq_vector()") vector_allocation_domain()
    operation indicates if a cpumask is dynamic or static. This
    update fixes the oversight and makes the operation to return a
    value.
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120614103933.GJ3383@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 23a46cf5b6fd..1885a73b7f33 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -228,10 +228,11 @@ static int x2apic_cluster_probe(void)
 /*
  * Each x2apic cluster is an allocation domain.
  */
-static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
+static bool cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
 {
 	cpumask_clear(retmask);
 	cpumask_copy(retmask, per_cpu(cpus_in_cluster, cpu));
+	return true;
 }
 
 static struct apic apic_x2apic_cluster = {

commit 4988a40c3981212fa8c64da68722affc1cb6697a
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Thu Jun 7 15:16:25 2012 +0200

    x86/apic: Make cpu_mask_to_apicid() operations check cpu_online_mask
    
    Currently cpu_mask_to_apicid() should not get a offline CPU with
    the cpumask. Otherwise some apic drivers might try to access
    non-existent per-cpu variables (i.e. x2apic). In that regard
    cpu_mask_to_apicid() and cpu_mask_to_apicid_and() operations are
    inconsistent.
    
    This fix makes the two operations do not rely on calling
    functions and always return the apicid for only online CPUs. As
    result, the meaning and implementations of cpu_mask_to_apicid()
    and cpu_mask_to_apicid_and() operations become straight.
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120607131624.GG4759@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 5f86f79335f4..23a46cf5b6fd 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -99,7 +99,7 @@ static void x2apic_send_IPI_all(int vector)
 static int
 x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask, unsigned int *apicid)
 {
-	int cpu = cpumask_first(cpumask);
+	int cpu = cpumask_first_and(cpumask, cpu_online_mask);
 	int i;
 
 	if (cpu >= nr_cpu_ids)

commit ff164324123c0fe181d8de7dadcc7b3fbe25f2cf
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Thu Jun 7 15:15:59 2012 +0200

    x86/apic: Make cpu_mask_to_apicid() operations return error code
    
    Current cpu_mask_to_apicid() and cpu_mask_to_apicid_and()
    implementations have few shortcomings:
    
    1. A value returned by cpu_mask_to_apicid() is written to
    hardware registers unconditionally. Should BAD_APICID get ever
    returned it will be written to a hardware too. But the value of
    BAD_APICID is not universal across all hardware in all modes and
    might cause unexpected results, i.e. interrupts might get routed
    to CPUs that are not configured to receive it.
    
    2. Because the value of BAD_APICID is not universal it is
    counter- intuitive to return it for a hardware where it does not
    make sense (i.e. x2apic).
    
    3. cpu_mask_to_apicid_and() operation is thought as an
    complement to cpu_mask_to_apicid() that only applies a AND mask
    on top of a cpumask being passed. Yet, as consequence of 18374d8
    commit the two operations are inconsistent in that of:
      cpu_mask_to_apicid() should not get a offline CPU with the cpumask
      cpu_mask_to_apicid_and() should not fail and return BAD_APICID
    These limitations are impossible to realize just from looking at
    the operations prototypes.
    
    Most of these shortcomings are resolved by returning a error
    code instead of BAD_APICID. As the result, faults are reported
    back early rather than possibilities to cause a unexpected
    behaviour exist (in case of [1]).
    
    The only exception is setup_timer_IRQ0_pin() routine. Although
    obviously controversial to this fix, its existing behaviour is
    preserved to not break the fragile check_timer() and would
    better addressed in a separate fix.
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120607131559.GF4759@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 612622c47dfb..5f86f79335f4 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -96,24 +96,26 @@ static void x2apic_send_IPI_all(int vector)
 	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
 }
 
-static unsigned int x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask)
+static int
+x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask, unsigned int *apicid)
 {
 	int cpu = cpumask_first(cpumask);
-	u32 dest = 0;
 	int i;
 
-	if (cpu > nr_cpu_ids)
-		return BAD_APICID;
+	if (cpu >= nr_cpu_ids)
+		return -EINVAL;
 
+	*apicid = 0;
 	for_each_cpu_and(i, cpumask, per_cpu(cpus_in_cluster, cpu))
-		dest |= per_cpu(x86_cpu_to_logical_apicid, i);
+		*apicid |= per_cpu(x86_cpu_to_logical_apicid, i);
 
-	return dest;
+	return 0;
 }
 
-static unsigned int
+static int
 x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
-			      const struct cpumask *andmask)
+			      const struct cpumask *andmask,
+			      unsigned int *apicid)
 {
 	u32 dest = 0;
 	u16 cluster;
@@ -128,7 +130,7 @@ x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 	}
 
 	if (!dest)
-		return BAD_APICID;
+		return -EINVAL;
 
 	for_each_cpu_and(i, cpumask, andmask) {
 		if (!cpumask_test_cpu(i, cpu_online_mask))
@@ -138,7 +140,9 @@ x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 		dest |= per_cpu(x86_cpu_to_logical_apicid, i);
 	}
 
-	return dest;
+	*apicid = dest;
+
+	return 0;
 }
 
 static void init_x2apic_ldr(void)

commit bf721d3a3bc7a731add45c8078b142b494ab413e
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Tue Jun 5 13:23:29 2012 +0200

    x86/apic: Factor out default target_cpus() operation
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120605112324.GA11449@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 2919e45d30c3..612622c47dfb 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -241,7 +241,7 @@ static struct apic apic_x2apic_cluster = {
 	.irq_delivery_mode		= dest_LowestPrio,
 	.irq_dest_mode			= 1, /* logical */
 
-	.target_cpus			= x2apic_target_cpus,
+	.target_cpus			= online_target_cpus,
 	.disable_esr			= 0,
 	.dest_logical			= APIC_DEST_LOGICAL,
 	.check_apicid_used		= NULL,

commit 49d0c7a0a425a89190b7c3b1445faba9eb227bec
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Tue Jun 5 13:23:15 2012 +0200

    x86/apic: Trivial whitespace fixes
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Link: http://lkml.kernel.org/r/20120605112310.GA11443@dhcp-26-207.brq.redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 90d999c7f2ea..2919e45d30c3 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -81,7 +81,7 @@ static void x2apic_send_IPI_mask(const struct cpumask *mask, int vector)
 }
 
 static void
- x2apic_send_IPI_mask_allbutself(const struct cpumask *mask, int vector)
+x2apic_send_IPI_mask_allbutself(const struct cpumask *mask, int vector)
 {
 	__x2apic_send_IPI_mask(mask, vector, APIC_DEST_ALLBUT);
 }

commit 0b8255e660a0c229ebfe8f9fde12a8d4d34c50e0
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon May 21 16:58:02 2012 -0700

    x86/x2apic/cluster: Use all the members of one cluster specified in the smp_affinity mask for the interrupt destination
    
    If the HW implements round-robin interrupt delivery, this
    enables multiple cpu's (which are part of the user specified
    interrupt smp_affinity mask and belong to the same x2apic
    cluster) to service the interrupt.
    
    Also if the platform supports Power Aware Interrupt Routing,
    then this enables the interrupt to be routed to an idle cpu or a
    busy cpu depending on the perf/power bias tunable.
    
    We are now grouping all the cpu's in a cluster to one vector
    domain. So that will limit the total number of interrupt sources
    handled by Linux. Previously we support "cpu-count *
    available-vectors-per-cpu" interrupt sources but this will now
    reduce to "cpu-count/16 * available-vectors-per-cpu".
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: yinghai@kernel.org
    Cc: gorcunov@openvz.org
    Cc: agordeev@redhat.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1337644682-19854-2-git-send-email-suresh.b.siddha@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index ff35cff0e1a7..90d999c7f2ea 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -98,34 +98,47 @@ static void x2apic_send_IPI_all(int vector)
 
 static unsigned int x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask)
 {
-	/*
-	 * We're using fixed IRQ delivery, can only return one logical APIC ID.
-	 * May as well be the first.
-	 */
 	int cpu = cpumask_first(cpumask);
+	u32 dest = 0;
+	int i;
 
-	if ((unsigned)cpu < nr_cpu_ids)
-		return per_cpu(x86_cpu_to_logical_apicid, cpu);
-	else
+	if (cpu > nr_cpu_ids)
 		return BAD_APICID;
+
+	for_each_cpu_and(i, cpumask, per_cpu(cpus_in_cluster, cpu))
+		dest |= per_cpu(x86_cpu_to_logical_apicid, i);
+
+	return dest;
 }
 
 static unsigned int
 x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 			      const struct cpumask *andmask)
 {
-	int cpu;
+	u32 dest = 0;
+	u16 cluster;
+	int i;
 
-	/*
-	 * We're using fixed IRQ delivery, can only return one logical APIC ID.
-	 * May as well be the first.
-	 */
-	for_each_cpu_and(cpu, cpumask, andmask) {
-		if (cpumask_test_cpu(cpu, cpu_online_mask))
-			break;
+	for_each_cpu_and(i, cpumask, andmask) {
+		if (!cpumask_test_cpu(i, cpu_online_mask))
+			continue;
+		dest = per_cpu(x86_cpu_to_logical_apicid, i);
+		cluster = x2apic_cluster(i);
+		break;
 	}
 
-	return per_cpu(x86_cpu_to_logical_apicid, cpu);
+	if (!dest)
+		return BAD_APICID;
+
+	for_each_cpu_and(i, cpumask, andmask) {
+		if (!cpumask_test_cpu(i, cpu_online_mask))
+			continue;
+		if (cluster != x2apic_cluster(i))
+			continue;
+		dest |= per_cpu(x86_cpu_to_logical_apicid, i);
+	}
+
+	return dest;
 }
 
 static void init_x2apic_ldr(void)
@@ -208,6 +221,15 @@ static int x2apic_cluster_probe(void)
 		return 0;
 }
 
+/*
+ * Each x2apic cluster is an allocation domain.
+ */
+static void cluster_vector_allocation_domain(int cpu, struct cpumask *retmask)
+{
+	cpumask_clear(retmask);
+	cpumask_copy(retmask, per_cpu(cpus_in_cluster, cpu));
+}
+
 static struct apic apic_x2apic_cluster = {
 
 	.name				= "cluster x2apic",
@@ -225,7 +247,7 @@ static struct apic apic_x2apic_cluster = {
 	.check_apicid_used		= NULL,
 	.check_apicid_present		= NULL,
 
-	.vector_allocation_domain	= x2apic_vector_allocation_domain,
+	.vector_allocation_domain	= cluster_vector_allocation_domain,
 	.init_apic_ldr			= init_x2apic_ldr,
 
 	.ioapic_phys_id_map		= NULL,

commit 0ab711ae6ab0db7696b43c74f9ba9de4d7fc1deb
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Wed May 16 19:03:58 2012 +0300

    x86/apic: Implement EIO micro-optimization
    
    We know both register and value for eoi beforehand,
    so there's no need to check it and no need to do math
    to calculate the msr. Saves instructions/branches
    on each EOI when using x2apic.
    
    I looked at the objdump output to verify that the
    generated code looks right and actually is shorter.
    
    The real improvemements will be on the KVM guest side
    though, those come in a later patch.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: gleb@redhat.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/e019d1a125316f10d3e3a4b2f6bda41473f4fb72.1337184153.git.mst@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index a5baa785a251..ff35cff0e1a7 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -260,7 +260,7 @@ static struct apic apic_x2apic_cluster = {
 
 	.read				= native_apic_msr_read,
 	.write				= native_apic_msr_write,
-	.eoi_write			= native_apic_msr_write,
+	.eoi_write			= native_apic_msr_eoi_write,
 	.icr_read			= native_x2apic_icr_read,
 	.icr_write			= native_x2apic_icr_write,
 	.wait_icr_idle			= native_x2apic_wait_icr_idle,

commit 2a43195d831997551da93e6b3c22c965e93fe9cc
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Wed May 16 19:03:52 2012 +0300

    x86/apic: Add apic->eoi_write() callback
    
    Add eoi_write callback so that kvm can override
    eoi accesses without touching the rest of the apic.
    As a side-effect, this will enable a micro-optimization
    for apics using msr.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: gleb@redhat.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/0df425d746c49ac2ecc405174df87752869629d2.1337184153.git.mst@redhat.com
    [ tidied it up a bit ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 48f3103b3c93..a5baa785a251 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -260,6 +260,7 @@ static struct apic apic_x2apic_cluster = {
 
 	.read				= native_apic_msr_read,
 	.write				= native_apic_msr_write,
+	.eoi_write			= native_apic_msr_write,
 	.icr_read			= native_x2apic_icr_read,
 	.icr_write			= native_x2apic_icr_write,
 	.wait_icr_idle			= native_x2apic_wait_icr_idle,

commit b7157acf429e6aef690646ba964b9ebd25049ec2
Author: Steffen Persvold <sp@numascale.com>
Date:   Fri Mar 16 20:25:35 2012 +0100

    x86/apic: Add separate apic_id_valid() functions for selected apic drivers
    
    As suggested by Suresh Siddha and Yinghai Lu:
    
    For x2apic pre-enabled systems, apic driver is set already early
    through early_acpi_boot_init()/early_acpi_process_madt()/
    acpi_parse_madt()/default_acpi_madt_oem_check() path so that
    apic_id_valid() checking will be sufficient during MADT and SRAT
    parsing.
    
    For non-x2apic pre-enabled systems, all apic ids should be less
    than 255.
    
    This allows us to substitute the checks in
    arch/x86/kernel/acpi/boot.c::acpi_parse_x2apic() and
    arch/x86/mm/srat.c::acpi_numa_x2apic_affinity_init() with
    apic->apic_id_valid().
    
    In addition we can avoid feigning the x2apic cpu feature in the
    NumaChip apic code.
    
    The following apic drivers have separate apic_id_valid()
    functions which will accept x2apic type IDs :
    
     x2apic_phys
     x2apic_cluster
     x2apic_uv_x
     apic_numachip
    
    Signed-off-by: Steffen Persvold <sp@numascale.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Daniel J Blueman <daniel@numascale-asia.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Jack Steiner <steiner@sgi.com>
    Link: http://lkml.kernel.org/r/1331925935-13372-1-git-send-email-sp@numascale.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 9193713060a9..48f3103b3c93 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -213,7 +213,7 @@ static struct apic apic_x2apic_cluster = {
 	.name				= "cluster x2apic",
 	.probe				= x2apic_cluster_probe,
 	.acpi_madt_oem_check		= x2apic_acpi_madt_oem_check,
-	.apic_id_valid			= default_apic_id_valid,
+	.apic_id_valid			= x2apic_apic_id_valid,
 	.apic_id_registered		= x2apic_apic_id_registered,
 
 	.irq_delivery_mode		= dest_LowestPrio,

commit fa63030e9c79e37b4d4e63b39ffb09cfb7aa0fe4
Author: Daniel J Blueman <daniel@numascale-asia.com>
Date:   Wed Mar 14 15:17:34 2012 +0800

    x86/platform: Move APIC ID validity check into platform APIC code
    
    Move APIC ID validity check into platform APIC code, so it can
    be overridden when needed. For NumaChip systems, always trust
    MADT, as it's constructed with high APIC IDs.
    
    Behaviour verifies on standard x86 systems and on NumaChip
    systems with this, and compile-tested with allyesconfig.
    
    Signed-off-by: Daniel J Blueman <daniel@numascale-asia.com>
    Reviewed-by: Steffen Persvold <sp@numascale.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/1331709454-27966-1-git-send-email-daniel@numascale-asia.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 500795875827..9193713060a9 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -213,6 +213,7 @@ static struct apic apic_x2apic_cluster = {
 	.name				= "cluster x2apic",
 	.probe				= x2apic_cluster_probe,
 	.acpi_madt_oem_check		= x2apic_acpi_madt_oem_check,
+	.apic_id_valid			= default_apic_id_valid,
 	.apic_id_registered		= x2apic_apic_id_registered,
 
 	.irq_delivery_mode		= dest_LowestPrio,

commit 1a8880a14270814dae0d226a2ad065d30587e60a
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Fri May 20 17:51:20 2011 -0700

    x86, apic: Make apic drivers static
    
    Apic probe now looks at the apic drivers listed in the
    .apicdrivers section. Remove apic_probe[] and make each apic
    driver static.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Tested-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: steiner@sgi.com
    Cc: gorcunov@openvz.org
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110521005526.341718626@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 7595c5775a54..500795875827 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -208,7 +208,7 @@ static int x2apic_cluster_probe(void)
 		return 0;
 }
 
-struct apic apic_x2apic_cluster = {
+static struct apic apic_x2apic_cluster = {
 
 	.name				= "cluster x2apic",
 	.probe				= x2apic_cluster_probe,

commit 107e0e0cd85beeee05af7ea374fda14d037ee500
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Fri May 20 17:51:17 2011 -0700

    x86, apic: Introduce .apicdrivers section to find the list of apic drivers
    
    This will pave the way for each apic driver to be self-contained
    and eliminate the need for apic_probe[].
    
    Order in which apic drivers are listed in the .apicdrivers
    section is important, as this determines the apic probe order.
    And this is enforced by the ordering of apic driver files in the
    Makefile and the macros apic_driver()/apic_drivers().
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Tested-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: steiner@sgi.com
    Cc: gorcunov@openvz.org
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110521005526.068775085@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index f7875d9a18c2..7595c5775a54 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -264,3 +264,5 @@ struct apic apic_x2apic_cluster = {
 	.wait_icr_idle			= native_x2apic_wait_icr_idle,
 	.safe_wait_icr_idle		= native_safe_x2apic_wait_icr_idle,
 };
+
+apic_driver(apic_x2apic_cluster);

commit 79deb8e511bd6fc8e40add4da75b19df085d9453
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Thu May 19 16:45:50 2011 -0700

    x86, x2apic: Move the common bits to x2apic.h
    
    To eliminate code duplication.
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: steiner@sgi.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110519234637.591426753@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 4dfe9363ff4e..f7875d9a18c2 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -8,8 +8,7 @@
 #include <linux/cpu.h>
 
 #include <asm/smp.h>
-#include <asm/apic.h>
-#include <asm/ipi.h>
+#include <asm/x2apic.h>
 
 static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
 static DEFINE_PER_CPU(cpumask_var_t, cpus_in_cluster);
@@ -20,37 +19,6 @@ static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 	return x2apic_enabled();
 }
 
-/*
- * need to use more than cpu 0, because we need more vectors when
- * MSI-X are used.
- */
-static const struct cpumask *x2apic_target_cpus(void)
-{
-	return cpu_online_mask;
-}
-
-/*
- * for now each logical cpu is in its own vector allocation domain.
- */
-static void x2apic_vector_allocation_domain(int cpu, struct cpumask *retmask)
-{
-	cpumask_clear(retmask);
-	cpumask_set_cpu(cpu, retmask);
-}
-
-static void
- __x2apic_send_IPI_dest(unsigned int apicid, int vector, unsigned int dest)
-{
-	unsigned long cfg;
-
-	cfg = __prepare_ICR(0, vector, dest);
-
-	/*
-	 * send the IPI.
-	 */
-	native_x2apic_icr_write(cfg, apicid);
-}
-
 static inline u32 x2apic_cluster(int cpu)
 {
 	return per_cpu(x86_cpu_to_logical_apicid, cpu) >> 16;
@@ -128,11 +96,6 @@ static void x2apic_send_IPI_all(int vector)
 	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
 }
 
-static int x2apic_apic_id_registered(void)
-{
-	return 1;
-}
-
 static unsigned int x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask)
 {
 	/*
@@ -165,32 +128,6 @@ x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 	return per_cpu(x86_cpu_to_logical_apicid, cpu);
 }
 
-static unsigned int x2apic_cluster_phys_get_apic_id(unsigned long x)
-{
-	unsigned int id;
-
-	id = x;
-	return id;
-}
-
-static unsigned long set_apic_id(unsigned int id)
-{
-	unsigned long x;
-
-	x = id;
-	return x;
-}
-
-static int x2apic_cluster_phys_pkg_id(int initial_apicid, int index_msb)
-{
-	return initial_apicid >> index_msb;
-}
-
-static void x2apic_send_IPI_self(int vector)
-{
-	apic_write(APIC_SELF_IPI, vector);
-}
-
 static void init_x2apic_ldr(void)
 {
 	unsigned int this_cpu = smp_processor_id();
@@ -298,11 +235,11 @@ struct apic apic_x2apic_cluster = {
 	.setup_portio_remap		= NULL,
 	.check_phys_apicid_present	= default_check_phys_apicid_present,
 	.enable_apic_mode		= NULL,
-	.phys_pkg_id			= x2apic_cluster_phys_pkg_id,
+	.phys_pkg_id			= x2apic_phys_pkg_id,
 	.mps_oem_check			= NULL,
 
-	.get_apic_id			= x2apic_cluster_phys_get_apic_id,
-	.set_apic_id			= set_apic_id,
+	.get_apic_id			= x2apic_get_apic_id,
+	.set_apic_id			= x2apic_set_apic_id,
 	.apic_id_mask			= 0xFFFFFFFFu,
 
 	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,

commit 9d0fa6c5f43f2d9c6966dcab7af96a717682fdec
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Thu May 19 16:45:49 2011 -0700

    x86, x2apic: Minimize IPI register writes using cluster groups
    
    In the case of x2apic cluster mode we can group IPI register
    writes based on the cluster group instead of individual per-cpu
    destination messages.
    
    This reduces the apic register writes and reduces the amount of
    IPI messages (in the best case we can reduce it by a factor of
    16).
    
    With this change, the cost of flush_tlb_others(), with the flush
    tlb IPI being sent from a cpu in the socket-1 to all the logical
    cpus in socket-2 (on a Westmere-EX system that has 20 logical
    cpus in a socket) is 3x times better now (compared to the former
    'send one-by-one' algorithm).
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: steiner@sgi.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110519234637.512271057@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 4b2bb1381ffa..4dfe9363ff4e 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -5,6 +5,7 @@
 #include <linux/ctype.h>
 #include <linux/init.h>
 #include <linux/dmar.h>
+#include <linux/cpu.h>
 
 #include <asm/smp.h>
 #include <asm/apic.h>
@@ -12,6 +13,7 @@
 
 static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
 static DEFINE_PER_CPU(cpumask_var_t, cpus_in_cluster);
+static DEFINE_PER_CPU(cpumask_var_t, ipi_mask);
 
 static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 {
@@ -54,30 +56,52 @@ static inline u32 x2apic_cluster(int cpu)
 	return per_cpu(x86_cpu_to_logical_apicid, cpu) >> 16;
 }
 
-/*
- * for now, we send the IPI's one by one in the cpumask.
- * TBD: Based on the cpu mask, we can send the IPI's to the cluster group
- * at once. We have 16 cpu's in a cluster. This will minimize IPI register
- * writes.
- */
 static void
 __x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 {
-	unsigned long query_cpu;
-	unsigned long this_cpu;
+	struct cpumask *cpus_in_cluster_ptr;
+	struct cpumask *ipi_mask_ptr;
+	unsigned int cpu, this_cpu;
 	unsigned long flags;
+	u32 dest;
 
 	x2apic_wrmsr_fence();
 
 	local_irq_save(flags);
 
 	this_cpu = smp_processor_id();
-	for_each_cpu(query_cpu, mask) {
-		if (apic_dest == APIC_DEST_ALLBUT && query_cpu == this_cpu)
+
+	/*
+	 * We are to modify mask, so we need an own copy
+	 * and be sure it's manipulated with irq off.
+	 */
+	ipi_mask_ptr = __raw_get_cpu_var(ipi_mask);
+	cpumask_copy(ipi_mask_ptr, mask);
+
+	/*
+	 * The idea is to send one IPI per cluster.
+	 */
+	for_each_cpu(cpu, ipi_mask_ptr) {
+		unsigned long i;
+
+		cpus_in_cluster_ptr = per_cpu(cpus_in_cluster, cpu);
+		dest = 0;
+
+		/* Collect cpus in cluster. */
+		for_each_cpu_and(i, ipi_mask_ptr, cpus_in_cluster_ptr) {
+			if (apic_dest == APIC_DEST_ALLINC || i != this_cpu)
+				dest |= per_cpu(x86_cpu_to_logical_apicid, i);
+		}
+
+		if (!dest)
 			continue;
-		__x2apic_send_IPI_dest(
-			per_cpu(x86_cpu_to_logical_apicid, query_cpu),
-			vector, apic->dest_logical);
+
+		__x2apic_send_IPI_dest(dest, vector, apic->dest_logical);
+		/*
+		 * Cluster sibling cpus should be discared now so
+		 * we would not send IPI them second time.
+		 */
+		cpumask_andnot(ipi_mask_ptr, ipi_mask_ptr, cpus_in_cluster_ptr);
 	}
 
 	local_irq_restore(flags);
@@ -198,6 +222,10 @@ update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
 		if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, this_cpu),
 					GFP_KERNEL)) {
 			err = -ENOMEM;
+		} else if (!zalloc_cpumask_var(&per_cpu(ipi_mask, this_cpu),
+					       GFP_KERNEL)) {
+			free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
+			err = -ENOMEM;
 		}
 		break;
 	case CPU_UP_CANCELED:
@@ -210,6 +238,7 @@ update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
 			__cpu_clear(cpu, per_cpu(cpus_in_cluster, this_cpu));
 		}
 		free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
+		free_cpumask_var(per_cpu(ipi_mask, this_cpu));
 		break;
 	}
 
@@ -225,8 +254,9 @@ static int x2apic_init_cpu_notifier(void)
 	int cpu = smp_processor_id();
 
 	zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL);
+	zalloc_cpumask_var(&per_cpu(ipi_mask, cpu), GFP_KERNEL);
 
-	BUG_ON(!per_cpu(cpus_in_cluster, cpu));
+	BUG_ON(!per_cpu(cpus_in_cluster, cpu) || !per_cpu(ipi_mask, cpu));
 
 	__cpu_set(cpu, per_cpu(cpus_in_cluster, cpu));
 	register_hotcpu_notifier(&x2apic_cpu_notifier);

commit a39d1f3f67f6a3d72b24f0d8bf9a295a27ea448e
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Thu May 19 16:45:48 2011 -0700

    x86, x2apic: Track the x2apic cluster sibling map
    
    In the case of x2apic cluster mode, we can group IPI register
    writes based on the cluster group instead of individual per-cpu
    destination messages.
    
    For this purpose, track the cpu's that belong to the same x2apic
    cluster.
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: steiner@sgi.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110519234637.421800999@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index b2617993de19..4b2bb1381ffa 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -11,6 +11,7 @@
 #include <asm/ipi.h>
 
 static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
+static DEFINE_PER_CPU(cpumask_var_t, cpus_in_cluster);
 
 static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 {
@@ -48,6 +49,11 @@ static void
 	native_x2apic_icr_write(cfg, apicid);
 }
 
+static inline u32 x2apic_cluster(int cpu)
+{
+	return per_cpu(x86_cpu_to_logical_apicid, cpu) >> 16;
+}
+
 /*
  * for now, we send the IPI's one by one in the cpumask.
  * TBD: Based on the cpu mask, we can send the IPI's to the cluster group
@@ -162,15 +168,77 @@ static void x2apic_send_IPI_self(int vector)
 }
 
 static void init_x2apic_ldr(void)
+{
+	unsigned int this_cpu = smp_processor_id();
+	unsigned int cpu;
+
+	per_cpu(x86_cpu_to_logical_apicid, this_cpu) = apic_read(APIC_LDR);
+
+	__cpu_set(this_cpu, per_cpu(cpus_in_cluster, this_cpu));
+	for_each_online_cpu(cpu) {
+		if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
+			continue;
+		__cpu_set(this_cpu, per_cpu(cpus_in_cluster, cpu));
+		__cpu_set(cpu, per_cpu(cpus_in_cluster, this_cpu));
+	}
+}
+
+ /*
+  * At CPU state changes, update the x2apic cluster sibling info.
+  */
+static int __cpuinit
+update_clusterinfo(struct notifier_block *nfb, unsigned long action, void *hcpu)
+{
+	unsigned int this_cpu = (unsigned long)hcpu;
+	unsigned int cpu;
+	int err = 0;
+
+	switch (action) {
+	case CPU_UP_PREPARE:
+		if (!zalloc_cpumask_var(&per_cpu(cpus_in_cluster, this_cpu),
+					GFP_KERNEL)) {
+			err = -ENOMEM;
+		}
+		break;
+	case CPU_UP_CANCELED:
+	case CPU_UP_CANCELED_FROZEN:
+	case CPU_DEAD:
+		for_each_online_cpu(cpu) {
+			if (x2apic_cluster(this_cpu) != x2apic_cluster(cpu))
+				continue;
+			__cpu_clear(this_cpu, per_cpu(cpus_in_cluster, cpu));
+			__cpu_clear(cpu, per_cpu(cpus_in_cluster, this_cpu));
+		}
+		free_cpumask_var(per_cpu(cpus_in_cluster, this_cpu));
+		break;
+	}
+
+	return notifier_from_errno(err);
+}
+
+static struct notifier_block __refdata x2apic_cpu_notifier = {
+	.notifier_call = update_clusterinfo,
+};
+
+static int x2apic_init_cpu_notifier(void)
 {
 	int cpu = smp_processor_id();
 
-	per_cpu(x86_cpu_to_logical_apicid, cpu) = apic_read(APIC_LDR);
+	zalloc_cpumask_var(&per_cpu(cpus_in_cluster, cpu), GFP_KERNEL);
+
+	BUG_ON(!per_cpu(cpus_in_cluster, cpu));
+
+	__cpu_set(cpu, per_cpu(cpus_in_cluster, cpu));
+	register_hotcpu_notifier(&x2apic_cpu_notifier);
+	return 1;
 }
 
 static int x2apic_cluster_probe(void)
 {
-	return x2apic_mode;
+	if (x2apic_mode)
+		return x2apic_init_cpu_notifier();
+	else
+		return 0;
 }
 
 struct apic apic_x2apic_cluster = {

commit a27d0b5e7d913b38880678ac05690f1dc737c4fd
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu May 19 16:45:47 2011 -0700

    x86, x2apic: Remove duplicate code for IPI mask routines
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: steiner@sgi.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110519234637.337024125@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 2967bab775e5..b2617993de19 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -54,64 +54,48 @@ static void
  * at once. We have 16 cpu's in a cluster. This will minimize IPI register
  * writes.
  */
-static void x2apic_send_IPI_mask(const struct cpumask *mask, int vector)
+static void
+__x2apic_send_IPI_mask(const struct cpumask *mask, int vector, int apic_dest)
 {
 	unsigned long query_cpu;
+	unsigned long this_cpu;
 	unsigned long flags;
 
 	x2apic_wrmsr_fence();
 
 	local_irq_save(flags);
+
+	this_cpu = smp_processor_id();
 	for_each_cpu(query_cpu, mask) {
+		if (apic_dest == APIC_DEST_ALLBUT && query_cpu == this_cpu)
+			continue;
 		__x2apic_send_IPI_dest(
 			per_cpu(x86_cpu_to_logical_apicid, query_cpu),
 			vector, apic->dest_logical);
 	}
+
 	local_irq_restore(flags);
 }
 
+static void x2apic_send_IPI_mask(const struct cpumask *mask, int vector)
+{
+	__x2apic_send_IPI_mask(mask, vector, APIC_DEST_ALLINC);
+}
+
 static void
  x2apic_send_IPI_mask_allbutself(const struct cpumask *mask, int vector)
 {
-	unsigned long this_cpu = smp_processor_id();
-	unsigned long query_cpu;
-	unsigned long flags;
-
-	x2apic_wrmsr_fence();
-
-	local_irq_save(flags);
-	for_each_cpu(query_cpu, mask) {
-		if (query_cpu == this_cpu)
-			continue;
-		__x2apic_send_IPI_dest(
-				per_cpu(x86_cpu_to_logical_apicid, query_cpu),
-				vector, apic->dest_logical);
-	}
-	local_irq_restore(flags);
+	__x2apic_send_IPI_mask(mask, vector, APIC_DEST_ALLBUT);
 }
 
 static void x2apic_send_IPI_allbutself(int vector)
 {
-	unsigned long this_cpu = smp_processor_id();
-	unsigned long query_cpu;
-	unsigned long flags;
-
-	x2apic_wrmsr_fence();
-
-	local_irq_save(flags);
-	for_each_online_cpu(query_cpu) {
-		if (query_cpu == this_cpu)
-			continue;
-		__x2apic_send_IPI_dest(
-				per_cpu(x86_cpu_to_logical_apicid, query_cpu),
-				vector, apic->dest_logical);
-	}
-	local_irq_restore(flags);
+	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLBUT);
 }
 
 static void x2apic_send_IPI_all(int vector)
 {
-	x2apic_send_IPI_mask(cpu_online_mask, vector);
+	__x2apic_send_IPI_mask(cpu_online_mask, vector, APIC_DEST_ALLINC);
 }
 
 static int x2apic_apic_id_registered(void)

commit 9ebd680bd029a9fc47399ca61c950f8b6730ac40
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu May 19 16:45:46 2011 -0700

    x86, apic: Use probe routines to simplify apic selection
    
    Use the unused probe routine in the apic driver to finalize the
    apic model selection. This cleans up the
    default_setup_apic_routing() and this probe routine in future
    can also be used for doing any apic model specific
    initialisation.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: steiner@sgi.com
    Cc: yinghai@kernel.org
    Link: http://lkml.kernel.org/r/20110519234637.247458931@sbsiddha-MOBL3.sc.intel.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 90949bbd566d..2967bab775e5 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -184,10 +184,15 @@ static void init_x2apic_ldr(void)
 	per_cpu(x86_cpu_to_logical_apicid, cpu) = apic_read(APIC_LDR);
 }
 
+static int x2apic_cluster_probe(void)
+{
+	return x2apic_mode;
+}
+
 struct apic apic_x2apic_cluster = {
 
 	.name				= "cluster x2apic",
-	.probe				= NULL,
+	.probe				= x2apic_cluster_probe,
 	.acpi_madt_oem_check		= x2apic_acpi_madt_oem_check,
 	.apic_id_registered		= x2apic_apic_id_registered,
 

commit 89e5dc218e084e13a3996db6693b01478912f4ee
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Jan 23 14:37:38 2011 +0100

    x86: Replace apic->apicid_to_node() with ->x86_32_numa_cpu_node()
    
    apic->apicid_to_node() is 32bit specific apic operation which
    determines NUMA node for a CPU.  Depending on the APIC
    implementation, it can be easier to determine NUMA node from
    either physical or logical apicid.  Currently,
    ->apicid_to_node() takes @logical_apicid and calls
    hard_smp_processor_id() if the physical apicid is needed.
    
    This prevents NUMA mapping from being queried from a different
    CPU, which in turn makes it impossible to initialize NUMA
    mapping before SMP bringup.
    
    This patch replaces apic->apicid_to_node() with
    ->x86_32_numa_cpu_node() which takes @cpu, from which both
    logical and physical apicids can easily be determined.  While at
    it, drop duplicate implementations from bigsmp_32 and summit_32,
    and use the default one.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Pekka Enberg <penberg@kernel.org>
    Cc: eric.dumazet@gmail.com
    Cc: yinghai@kernel.org
    Cc: brgerst@gmail.com
    Cc: gorcunov@gmail.com
    Cc: shaohui.zheng@intel.com
    Cc: rientjes@google.com
    LKML-Reference: <1295789862-25482-13-git-send-email-tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index badc1fdbea27..90949bbd566d 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -206,7 +206,6 @@ struct apic apic_x2apic_cluster = {
 	.ioapic_phys_id_map		= NULL,
 	.setup_apic_routing		= NULL,
 	.multi_timer_check		= NULL,
-	.apicid_to_node			= NULL,
 	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
 	.apicid_to_cpu_present		= NULL,
 	.setup_portio_remap		= NULL,

commit 7632611f534340182c832d2b139cb19676f24e1a
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Jan 23 14:37:32 2011 +0100

    x86: Kill apic->cpu_to_logical_apicid()
    
    After the previous patch, apic->cpu_to_logical_apicid() is no
    longer used.  Kill it.
    
    For apic types with custom cpu_to_logical_apicid() which is also
    used for other purposes, remove the function and modify its
    users to do the mapping directly.
    
    #ifdef's on CONFIG_SMP in es7000_32 and summit_32 are ignored
    during conversion as they are not used for UP kernels.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: eric.dumazet@gmail.com
    Cc: yinghai@kernel.org
    Cc: brgerst@gmail.com
    Cc: gorcunov@gmail.com
    Cc: penberg@kernel.org
    Cc: shaohui.zheng@intel.com
    Cc: rientjes@google.com
    LKML-Reference: <1295789862-25482-7-git-send-email-tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index cf69c59f4910..badc1fdbea27 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -207,7 +207,6 @@ struct apic apic_x2apic_cluster = {
 	.setup_apic_routing		= NULL,
 	.multi_timer_check		= NULL,
 	.apicid_to_node			= NULL,
-	.cpu_to_logical_apicid		= NULL,
 	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
 	.apicid_to_cpu_present		= NULL,
 	.setup_portio_remap		= NULL,

commit 18374d89e5fe96772102f44f535efb1198d9be08
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu Dec 17 18:29:46 2009 -0800

    x86, irq: Allow 0xff for /proc/irq/[n]/smp_affinity on an 8-cpu system
    
    John Blackwood reported:
    > on an older Dell PowerEdge 6650 system with 8 cpus (4 are hyper-threaded),
    > and  32 bit (x86) kernel, once you change the irq smp_affinity of an irq
    > to be less than all cpus in the system, you can never change really the
    > irq smp_affinity back to be all cpus in the system (0xff) again,
    > even though no error status is returned on the "/bin/echo ff >
    > /proc/irq/[n]/smp_affinity" operation.
    >
    > This is due to that fact that BAD_APICID has the same value as
    > all cpus (0xff) on 32bit kernels, and thus the value returned from
    > set_desc_affinity() via the cpu_mask_to_apicid_and() function is treated
    > as a failure in set_ioapic_affinity_irq_desc(), and no affinity changes
    > are made.
    
    set_desc_affinity() is already checking if the incoming cpu mask
    intersects with the cpu online mask or not. So there is no need
    for the apic op cpu_mask_to_apicid_and() to check again
    and return BAD_APICID.
    
    Remove the BAD_APICID return value from cpu_mask_to_apicid_and()
    and also fix set_desc_affinity() to return -1 instead of using BAD_APICID
    to represent error conditions (as cpu_mask_to_apicid_and() can return
    logical or physical apicid values and BAD_APICID is really to represent
    bad physical apic id).
    
    Reported-by: John Blackwood <john.blackwood@ccur.com>
    Root-caused-by: John Blackwood <john.blackwood@ccur.com>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    LKML-Reference: <1261103386.2535.409.camel@sbs-t61>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index a5371ec36776..cf69c59f4910 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -148,10 +148,7 @@ x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
 			break;
 	}
 
-	if (cpu < nr_cpu_ids)
-		return per_cpu(x86_cpu_to_logical_apicid, cpu);
-
-	return BAD_APICID;
+	return per_cpu(x86_cpu_to_logical_apicid, cpu);
 }
 
 static unsigned int x2apic_cluster_phys_get_apic_id(unsigned long x)

commit 087d7e56deffb611a098e7e257388a41edbeef1f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Aug 4 08:59:59 2009 -0700

    x86: Fix MSI-X initialization by using online_mask for x2apic target_cpus
    
    found a system where x2apic reports an MSI-X irq initialization
    failure:
    
    [  302.859446] igbvf 0000:81:10.4: enabling device (0000 -> 0002)
    [  302.874369] igbvf 0000:81:10.4: using 64bit DMA mask
    [  302.879023] igbvf 0000:81:10.4: using 64bit consistent DMA mask
    [  302.894386] igbvf 0000:81:10.4: enabling bus mastering
    [  302.898171] igbvf 0000:81:10.4: setting latency timer to 64
    [  302.914050] reserve_memtype added 0xefb08000-0xefb0c000, track uncached-minus, req uncached-minus, ret uncached-minus
    [  302.933839] reserve_memtype added 0xefb28000-0xefb29000, track uncached-minus, req uncached-minus, ret uncached-minus
    [  302.940367]   alloc irq_desc for 265 on node 4
    [  302.956874]   alloc kstat_irqs on node 4
    [  302.959452] alloc irq_2_iommu on node 0
    [  302.974328] igbvf 0000:81:10.4: irq 265 for MSI/MSI-X
    [  302.977778]   alloc irq_desc for 266 on node 4
    [  302.980347]   alloc kstat_irqs on node 4
    [  302.995312] free_memtype request 0xefb28000-0xefb29000
    [  302.998816] igbvf 0000:81:10.4: Failed to initialize MSI-X interrupts.
    
    ... it turns out that when trying to enable MSI-X,
    __assign_irq_vector(new, cfg_new, apic->target_cpus()) can not
    get vector because for x2apic target-cpus returns cpumask_of(0)
    
    Update that to online_mask like xapic.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    LKML-Reference: <4A785AFF.3050902@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 2ed4e2bb3b32..a5371ec36776 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -17,11 +17,13 @@ static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 	return x2apic_enabled();
 }
 
-/* Start with all IRQs pointing to boot CPU.  IRQ balancing will shift them. */
-
+/*
+ * need to use more than cpu 0, because we need more vectors when
+ * MSI-X are used.
+ */
 static const struct cpumask *x2apic_target_cpus(void)
 {
-	return cpumask_of(0);
+	return cpu_online_mask;
 }
 
 /*

commit d8c7eb34c2db6268909ae8c3958be63bde254292
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sat Jul 25 03:23:09 2009 -0700

    x86: Don't use current_cpu_data in x2apic phys_pkg_id
    
    One system has socket 1 come up as BSP.
    
    kexeced kernel reports BSP as:
    
    [    1.524550] Initializing cgroup subsys cpuacct
    [    1.536064] initial_apicid:20
    [    1.537135] ht_mask_width:1
    [    1.538128] core_select_mask:f
    [    1.539126] core_plus_mask_width:5
    [    1.558479] CPU: Physical Processor ID: 0
    [    1.559501] CPU: Processor Core ID: 0
    [    1.560539] CPU: L1 I cache: 32K, L1 D cache: 32K
    [    1.579098] CPU: L2 cache: 256K
    [    1.580085] CPU: L3 cache: 24576K
    [    1.581108] CPU 0/0x20 -> Node 0
    [    1.596193] CPU 0 microcode level: 0xffff0008
    
    It doesn't have correct physical processor id and will get an
    error:
    
    [   38.840859] CPU0 attaching sched-domain:
    [   38.848287]  domain 0: span 0,8,72 level SIBLING
    [   38.851151]   groups: 0 8 72
    [   38.858137]   domain 1: span 0,8-15,72-79 level MC
    [   38.868944]    groups: 0,8,72 9,73 10,74 11,75 12,76 13,77 14,78 15,79
    [   38.881383] ERROR: parent span is not a superset of domain->span
    [   38.890724]    domain 2: span 0-7,64-71 level CPU
    [   38.899237] ERROR: domain->groups does not contain CPU0
    [   38.909229]     groups: 8-15,72-79
    [   38.912547] ERROR: groups don't span domain->span
    [   38.919665]     domain 3: span 0-127 level NODE
    [   38.930739]      groups: 0-7,64-71 8-15,72-79 16-23,80-87 24-31,88-95 32-39,96-103 40-47,104-111 48-55,112-119 56-63,120-127
    
    it turns out: we can not use current_cpu_data in phys_pgd_id
    for x2apic.
    
    identify_boot_cpu() is called by check_bugs() before
    smp_prepare_cpus() and till smp_prepare_cpus() current_cpu_data
    for bsp is assigned with boot_cpu_data.
    
    Just make phys_pkg_id for x2apic is aligned to xapic.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <4A6ADD0D.10002@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 8e4cbb255c38..2ed4e2bb3b32 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -170,7 +170,7 @@ static unsigned long set_apic_id(unsigned int id)
 
 static int x2apic_cluster_phys_pkg_id(int initial_apicid, int index_msb)
 {
-	return current_cpu_data.initial_apicid >> index_msb;
+	return initial_apicid >> index_msb;
 }
 
 static void x2apic_send_IPI_self(int vector)

commit 2de1f33e99cec5fd79542a1d0e26efb9c36a98bb
Author: Jaswinder Singh Rajput <jaswinder@kernel.org>
Date:   Sat Apr 11 12:55:26 2009 +0530

    x86: apic/x2apic_cluster.c x86_cpu_to_logical_apicid should be static
    
    Impact: reduce kernel size a bit, address sparse warning
    
    Addresses the problem pointed out by this sparse warning:
      arch/x86/kernel/apic/x2apic_cluster.c:13:1: warning: symbol 'per_cpu__x86_cpu_to_logical_apicid' was not declared. Should it be static?
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    LKML-Reference: <1239434726.4418.24.camel@localhost.localdomain>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 4a903e2f0d17..8e4cbb255c38 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -10,7 +10,7 @@
 #include <asm/apic.h>
 #include <asm/ipi.h>
 
-DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
+static DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
 
 static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 {

commit ce4e240c279a31096f74afa6584a62d64a1ba8c8
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Tue Mar 17 10:16:54 2009 -0800

    x86: add x2apic_wrmsr_fence() to x2apic flush tlb paths
    
    Impact: optimize APIC IPI related barriers
    
    Uncached MMIO accesses for xapic are inherently serializing and hence
    we don't need explicit barriers for xapic IPI paths.
    
    x2apic MSR writes/reads don't have serializing semantics and hence need
    a serializing instruction or mfence, to make all the previous memory
    stores globally visisble before the x2apic msr write for IPI.
    
    Add x2apic_wrmsr_fence() in flush tlb path to x2apic specific paths.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: "steiner@sgi.com" <steiner@sgi.com>
    Cc: Nick Piggin <npiggin@suse.de>
    LKML-Reference: <1237313814.27006.203.camel@localhost.localdomain>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 8fb87b6dd633..4a903e2f0d17 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -57,6 +57,8 @@ static void x2apic_send_IPI_mask(const struct cpumask *mask, int vector)
 	unsigned long query_cpu;
 	unsigned long flags;
 
+	x2apic_wrmsr_fence();
+
 	local_irq_save(flags);
 	for_each_cpu(query_cpu, mask) {
 		__x2apic_send_IPI_dest(
@@ -73,6 +75,8 @@ static void
 	unsigned long query_cpu;
 	unsigned long flags;
 
+	x2apic_wrmsr_fence();
+
 	local_irq_save(flags);
 	for_each_cpu(query_cpu, mask) {
 		if (query_cpu == this_cpu)
@@ -90,6 +94,8 @@ static void x2apic_send_IPI_allbutself(int vector)
 	unsigned long query_cpu;
 	unsigned long flags;
 
+	x2apic_wrmsr_fence();
+
 	local_irq_save(flags);
 	for_each_online_cpu(query_cpu) {
 		if (query_cpu == this_cpu)

commit 1f5bcabf1b997d6b76a09114b5a79423495a1263
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Feb 26 13:51:40 2009 +0100

    x86: apic: simplify secondary CPU wakeup methods
    
    Impact: cleanup
    
    - rename apic->wakeup_cpu  to apic->wakeup_secondary_cpu, to
      make it apparent that this is an SMP-only method
    
    - handle NULL ->wakeup_secondary_cpus to mean the default INIT
      wakeup sequence - this allows simplification of the APIC
      driver templates.
    
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 561a6b1042ae..8fb87b6dd633 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -224,7 +224,6 @@ struct apic apic_x2apic_cluster = {
 	.send_IPI_all			= x2apic_send_IPI_all,
 	.send_IPI_self			= x2apic_send_IPI_self,
 
-	.wakeup_cpu			= wakeup_secondary_cpu_via_init,
 	.trampoline_phys_low		= DEFAULT_TRAMPOLINE_PHYS_LOW,
 	.trampoline_phys_high		= DEFAULT_TRAMPOLINE_PHYS_HIGH,
 	.wait_for_init_deassert		= NULL,

commit 2b6163bf5772644068694583816fa41e8474239f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Wed Feb 25 20:50:49 2009 -0800

    x86: remove update_apic from x86_quirks
    
    Impact: cleanup
    
    x86_quirks->update_apic() calling looks crazy. so try to remove it:
    
     1. every apic take wakeup_cpu member directly
     2. separate es7000_apic to es7000_apic_cluster
     3. use uv_wakeup_cpu directly
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 354b9c45601d..561a6b1042ae 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -224,7 +224,7 @@ struct apic apic_x2apic_cluster = {
 	.send_IPI_all			= x2apic_send_IPI_all,
 	.send_IPI_self			= x2apic_send_IPI_self,
 
-	.wakeup_cpu			= NULL,
+	.wakeup_cpu			= wakeup_secondary_cpu_via_init,
 	.trampoline_phys_low		= DEFAULT_TRAMPOLINE_PHYS_LOW,
 	.trampoline_phys_high		= DEFAULT_TRAMPOLINE_PHYS_HIGH,
 	.wait_for_init_deassert		= NULL,

commit ef1f87aa7ba6224bef1b750b3272ba281d8f43ed
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Sat Feb 21 14:23:21 2009 -0800

    x86: select x2apic ops in early apic probe only if x2apic mode is enabled
    
    If BIOS hands over the control to OS in legacy xapic mode, select
    legacy xapic related ops in the early apic probe and shift to x2apic
    ops later in the boot sequence, only after enabling x2apic mode.
    
    If BIOS hands over the control in x2apic mode, select x2apic related
    ops in the early apic probe.
    
    This fixes the early boot panic, where we were selecting x2apic ops,
    while the cpu is still in legacy xapic mode.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index 4e39d9ad4d52..354b9c45601d 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -14,10 +14,7 @@ DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
 
 static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 {
-	if (cpu_has_x2apic)
-		return 1;
-
-	return 0;
+	return x2apic_enabled();
 }
 
 /* Start with all IRQs pointing to boot CPU.  IRQ balancing will shift them. */

commit f62bae5009c1ba596cd475cafbc83e0570a36e26
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 18:09:24 2009 +0100

    x86, apic: move APIC drivers to arch/x86/kernel/apic/*
    
    arch/x86/kernel/ is getting a bit crowded, and the APIC
    drivers are scattered into various different files.
    
    Move them to arch/x86/kernel/apic/*, and also remove
    the 'gen' prefix from those which had it.
    
    Also move APIC related functionality: the IO-APIC driver,
    the NMI and the IPI code.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
new file mode 100644
index 000000000000..4e39d9ad4d52
--- /dev/null
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -0,0 +1,243 @@
+#include <linux/threads.h>
+#include <linux/cpumask.h>
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/ctype.h>
+#include <linux/init.h>
+#include <linux/dmar.h>
+
+#include <asm/smp.h>
+#include <asm/apic.h>
+#include <asm/ipi.h>
+
+DEFINE_PER_CPU(u32, x86_cpu_to_logical_apicid);
+
+static int x2apic_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
+{
+	if (cpu_has_x2apic)
+		return 1;
+
+	return 0;
+}
+
+/* Start with all IRQs pointing to boot CPU.  IRQ balancing will shift them. */
+
+static const struct cpumask *x2apic_target_cpus(void)
+{
+	return cpumask_of(0);
+}
+
+/*
+ * for now each logical cpu is in its own vector allocation domain.
+ */
+static void x2apic_vector_allocation_domain(int cpu, struct cpumask *retmask)
+{
+	cpumask_clear(retmask);
+	cpumask_set_cpu(cpu, retmask);
+}
+
+static void
+ __x2apic_send_IPI_dest(unsigned int apicid, int vector, unsigned int dest)
+{
+	unsigned long cfg;
+
+	cfg = __prepare_ICR(0, vector, dest);
+
+	/*
+	 * send the IPI.
+	 */
+	native_x2apic_icr_write(cfg, apicid);
+}
+
+/*
+ * for now, we send the IPI's one by one in the cpumask.
+ * TBD: Based on the cpu mask, we can send the IPI's to the cluster group
+ * at once. We have 16 cpu's in a cluster. This will minimize IPI register
+ * writes.
+ */
+static void x2apic_send_IPI_mask(const struct cpumask *mask, int vector)
+{
+	unsigned long query_cpu;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	for_each_cpu(query_cpu, mask) {
+		__x2apic_send_IPI_dest(
+			per_cpu(x86_cpu_to_logical_apicid, query_cpu),
+			vector, apic->dest_logical);
+	}
+	local_irq_restore(flags);
+}
+
+static void
+ x2apic_send_IPI_mask_allbutself(const struct cpumask *mask, int vector)
+{
+	unsigned long this_cpu = smp_processor_id();
+	unsigned long query_cpu;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	for_each_cpu(query_cpu, mask) {
+		if (query_cpu == this_cpu)
+			continue;
+		__x2apic_send_IPI_dest(
+				per_cpu(x86_cpu_to_logical_apicid, query_cpu),
+				vector, apic->dest_logical);
+	}
+	local_irq_restore(flags);
+}
+
+static void x2apic_send_IPI_allbutself(int vector)
+{
+	unsigned long this_cpu = smp_processor_id();
+	unsigned long query_cpu;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	for_each_online_cpu(query_cpu) {
+		if (query_cpu == this_cpu)
+			continue;
+		__x2apic_send_IPI_dest(
+				per_cpu(x86_cpu_to_logical_apicid, query_cpu),
+				vector, apic->dest_logical);
+	}
+	local_irq_restore(flags);
+}
+
+static void x2apic_send_IPI_all(int vector)
+{
+	x2apic_send_IPI_mask(cpu_online_mask, vector);
+}
+
+static int x2apic_apic_id_registered(void)
+{
+	return 1;
+}
+
+static unsigned int x2apic_cpu_mask_to_apicid(const struct cpumask *cpumask)
+{
+	/*
+	 * We're using fixed IRQ delivery, can only return one logical APIC ID.
+	 * May as well be the first.
+	 */
+	int cpu = cpumask_first(cpumask);
+
+	if ((unsigned)cpu < nr_cpu_ids)
+		return per_cpu(x86_cpu_to_logical_apicid, cpu);
+	else
+		return BAD_APICID;
+}
+
+static unsigned int
+x2apic_cpu_mask_to_apicid_and(const struct cpumask *cpumask,
+			      const struct cpumask *andmask)
+{
+	int cpu;
+
+	/*
+	 * We're using fixed IRQ delivery, can only return one logical APIC ID.
+	 * May as well be the first.
+	 */
+	for_each_cpu_and(cpu, cpumask, andmask) {
+		if (cpumask_test_cpu(cpu, cpu_online_mask))
+			break;
+	}
+
+	if (cpu < nr_cpu_ids)
+		return per_cpu(x86_cpu_to_logical_apicid, cpu);
+
+	return BAD_APICID;
+}
+
+static unsigned int x2apic_cluster_phys_get_apic_id(unsigned long x)
+{
+	unsigned int id;
+
+	id = x;
+	return id;
+}
+
+static unsigned long set_apic_id(unsigned int id)
+{
+	unsigned long x;
+
+	x = id;
+	return x;
+}
+
+static int x2apic_cluster_phys_pkg_id(int initial_apicid, int index_msb)
+{
+	return current_cpu_data.initial_apicid >> index_msb;
+}
+
+static void x2apic_send_IPI_self(int vector)
+{
+	apic_write(APIC_SELF_IPI, vector);
+}
+
+static void init_x2apic_ldr(void)
+{
+	int cpu = smp_processor_id();
+
+	per_cpu(x86_cpu_to_logical_apicid, cpu) = apic_read(APIC_LDR);
+}
+
+struct apic apic_x2apic_cluster = {
+
+	.name				= "cluster x2apic",
+	.probe				= NULL,
+	.acpi_madt_oem_check		= x2apic_acpi_madt_oem_check,
+	.apic_id_registered		= x2apic_apic_id_registered,
+
+	.irq_delivery_mode		= dest_LowestPrio,
+	.irq_dest_mode			= 1, /* logical */
+
+	.target_cpus			= x2apic_target_cpus,
+	.disable_esr			= 0,
+	.dest_logical			= APIC_DEST_LOGICAL,
+	.check_apicid_used		= NULL,
+	.check_apicid_present		= NULL,
+
+	.vector_allocation_domain	= x2apic_vector_allocation_domain,
+	.init_apic_ldr			= init_x2apic_ldr,
+
+	.ioapic_phys_id_map		= NULL,
+	.setup_apic_routing		= NULL,
+	.multi_timer_check		= NULL,
+	.apicid_to_node			= NULL,
+	.cpu_to_logical_apicid		= NULL,
+	.cpu_present_to_apicid		= default_cpu_present_to_apicid,
+	.apicid_to_cpu_present		= NULL,
+	.setup_portio_remap		= NULL,
+	.check_phys_apicid_present	= default_check_phys_apicid_present,
+	.enable_apic_mode		= NULL,
+	.phys_pkg_id			= x2apic_cluster_phys_pkg_id,
+	.mps_oem_check			= NULL,
+
+	.get_apic_id			= x2apic_cluster_phys_get_apic_id,
+	.set_apic_id			= set_apic_id,
+	.apic_id_mask			= 0xFFFFFFFFu,
+
+	.cpu_mask_to_apicid		= x2apic_cpu_mask_to_apicid,
+	.cpu_mask_to_apicid_and		= x2apic_cpu_mask_to_apicid_and,
+
+	.send_IPI_mask			= x2apic_send_IPI_mask,
+	.send_IPI_mask_allbutself	= x2apic_send_IPI_mask_allbutself,
+	.send_IPI_allbutself		= x2apic_send_IPI_allbutself,
+	.send_IPI_all			= x2apic_send_IPI_all,
+	.send_IPI_self			= x2apic_send_IPI_self,
+
+	.wakeup_cpu			= NULL,
+	.trampoline_phys_low		= DEFAULT_TRAMPOLINE_PHYS_LOW,
+	.trampoline_phys_high		= DEFAULT_TRAMPOLINE_PHYS_HIGH,
+	.wait_for_init_deassert		= NULL,
+	.smp_callin_clear_local_apic	= NULL,
+	.inquire_remote_apic		= NULL,
+
+	.read				= native_apic_msr_read,
+	.write				= native_apic_msr_write,
+	.icr_read			= native_x2apic_icr_read,
+	.icr_write			= native_x2apic_icr_write,
+	.wait_icr_idle			= native_x2apic_wait_icr_idle,
+	.safe_wait_icr_idle		= native_safe_x2apic_wait_icr_idle,
+};
