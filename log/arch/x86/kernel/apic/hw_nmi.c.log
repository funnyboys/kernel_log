commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index d6f387780849..d1fc62a67320 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *  HW NMI watchdog support
  *

commit 05a4a95279311c3a4633b4277a5d21cfd616c6c7
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jul 12 14:35:46 2017 -0700

    kernel/watchdog: split up config options
    
    Split SOFTLOCKUP_DETECTOR from LOCKUP_DETECTOR, and split
    HARDLOCKUP_DETECTOR_PERF from HARDLOCKUP_DETECTOR.
    
    LOCKUP_DETECTOR implies the general boot, sysctl, and programming
    interfaces for the lockup detectors.
    
    An architecture that wants to use a hard lockup detector must define
    HAVE_HARDLOCKUP_DETECTOR_PERF or HAVE_HARDLOCKUP_DETECTOR_ARCH.
    
    Alternatively an arch can define HAVE_NMI_WATCHDOG, which provides the
    minimum arch_touch_nmi_watchdog, and it otherwise does its own thing and
    does not implement the LOCKUP_DETECTOR interfaces.
    
    sparc is unusual in that it has started to implement some of the
    interfaces, but not fully yet.  It should probably be converted to a full
    HAVE_HARDLOCKUP_DETECTOR_ARCH.
    
    [npiggin@gmail.com: fix]
      Link: http://lkml.kernel.org/r/20170617223522.66c0ad88@roar.ozlabs.ibm.com
    Link: http://lkml.kernel.org/r/20170616065715.18390-4-npiggin@gmail.com
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Don Zickus <dzickus@redhat.com>
    Reviewed-by: Babu Moger <babu.moger@oracle.com>
    Tested-by: Babu Moger <babu.moger@oracle.com>   [sparc]
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c73c9fb281e1..d6f387780849 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -19,7 +19,7 @@
 #include <linux/init.h>
 #include <linux/delay.h>
 
-#ifdef CONFIG_HARDLOCKUP_DETECTOR
+#ifdef CONFIG_HARDLOCKUP_DETECTOR_PERF
 u64 hw_nmi_get_sample_period(int watchdog_thresh)
 {
 	return (u64)(cpu_khz) * 1000 * watchdog_thresh;

commit 9a01c3ed5cdb35d9004eb92510ee6ea11b4a5f16
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Fri Oct 7 17:02:45 2016 -0700

    nmi_backtrace: add more trigger_*_cpu_backtrace() methods
    
    Patch series "improvements to the nmi_backtrace code" v9.
    
    This patch series modifies the trigger_xxx_backtrace() NMI-based remote
    backtracing code to make it more flexible, and makes a few small
    improvements along the way.
    
    The motivation comes from the task isolation code, where there are
    scenarios where we want to be able to diagnose a case where some cpu is
    about to interrupt a task-isolated cpu.  It can be helpful to see both
    where the interrupting cpu is, and also an approximation of where the
    cpu that is being interrupted is.  The nmi_backtrace framework allows us
    to discover the stack of the interrupted cpu.
    
    I've tested that the change works as desired on tile, and build-tested
    x86, arm, mips, and sparc64.  For x86 I confirmed that the generic
    cpuidle stuff as well as the architecture-specific routines are in the
    new cpuidle section.  For arm, mips, and sparc I just build-tested it
    and made sure the generic cpuidle routines were in the new cpuidle
    section, but I didn't attempt to figure out which the platform-specific
    idle routines might be.  That might be more usefully done by someone
    with platform experience in follow-up patches.
    
    This patch (of 4):
    
    Currently you can only request a backtrace of either all cpus, or all
    cpus but yourself.  It can also be helpful to request a remote backtrace
    of a single cpu, and since we want that, the logical extension is to
    support a cpumask as the underlying primitive.
    
    This change modifies the existing lib/nmi_backtrace.c code to take a
    cpumask as its basic primitive, and modifies the linux/nmi.h code to use
    the new "cpumask" method instead.
    
    The existing clients of nmi_backtrace (arm and x86) are converted to
    using the new cpumask approach in this change.
    
    The other users of the backtracing API (sparc64 and mips) are converted
    to use the cpumask approach rather than the all/allbutself approach.
    The mips code ignored the "include_self" boolean but with this change it
    will now also dump a local backtrace if requested.
    
    Link: http://lkml.kernel.org/r/1472487169-14923-2-git-send-email-cmetcalf@mellanox.com
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Tested-by: Daniel Thompson <daniel.thompson@linaro.org> [arm]
    Reviewed-by: Aaron Tomlin <atomlin@redhat.com>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index f29501e1a5c1..c73c9fb281e1 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -26,32 +26,32 @@ u64 hw_nmi_get_sample_period(int watchdog_thresh)
 }
 #endif
 
-#ifdef arch_trigger_all_cpu_backtrace
+#ifdef arch_trigger_cpumask_backtrace
 static void nmi_raise_cpu_backtrace(cpumask_t *mask)
 {
 	apic->send_IPI_mask(mask, NMI_VECTOR);
 }
 
-void arch_trigger_all_cpu_backtrace(bool include_self)
+void arch_trigger_cpumask_backtrace(const cpumask_t *mask, bool exclude_self)
 {
-	nmi_trigger_all_cpu_backtrace(include_self, nmi_raise_cpu_backtrace);
+	nmi_trigger_cpumask_backtrace(mask, exclude_self,
+				      nmi_raise_cpu_backtrace);
 }
 
-static int
-arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
+static int nmi_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
 	if (nmi_cpu_backtrace(regs))
 		return NMI_HANDLED;
 
 	return NMI_DONE;
 }
-NOKPROBE_SYMBOL(arch_trigger_all_cpu_backtrace_handler);
+NOKPROBE_SYMBOL(nmi_cpu_backtrace_handler);
 
-static int __init register_trigger_all_cpu_backtrace(void)
+static int __init register_nmi_cpu_backtrace_handler(void)
 {
-	register_nmi_handler(NMI_LOCAL, arch_trigger_all_cpu_backtrace_handler,
+	register_nmi_handler(NMI_LOCAL, nmi_cpu_backtrace_handler,
 				0, "arch_bt");
 	return 0;
 }
-early_initcall(register_trigger_all_cpu_backtrace);
+early_initcall(register_nmi_cpu_backtrace_handler);
 #endif

commit 186f43608a5c827f8284fe4559225b4dccaa49ef
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Jul 13 20:18:56 2016 -0400

    x86/kernel: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.  The advantage
    in doing so is that module.h itself sources about 15 other headers;
    adding significantly to what we feed cpp, and it can obscure what
    headers we are effectively using.
    
    Since module.h was the source for init.h (for __init) and for
    export.h (for EXPORT_SYMBOL) we consider each obj-y/bool instance
    for the presence of either and replace as needed.  Build testing
    revealed some implicit header usage that was fixed up accordingly.
    
    Note that some bool/obj-y instances remain since module.h is
    the header for some exception table entry stuff, and for things
    like __init_or_module (code that is tossed when MODULES=n).
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20160714001901.31603-4-paul.gortmaker@windriver.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 7788ce643bf4..f29501e1a5c1 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -16,7 +16,7 @@
 #include <linux/notifier.h>
 #include <linux/kprobes.h>
 #include <linux/nmi.h>
-#include <linux/module.h>
+#include <linux/init.h>
 #include <linux/delay.h>
 
 #ifdef CONFIG_HARDLOCKUP_DETECTOR

commit 42a0bb3f71383b457a7db362f1c69e7afb96732b
Author: Petr Mladek <pmladek@suse.com>
Date:   Fri May 20 17:00:33 2016 -0700

    printk/nmi: generic solution for safe printk in NMI
    
    printk() takes some locks and could not be used a safe way in NMI
    context.
    
    The chance of a deadlock is real especially when printing stacks from
    all CPUs.  This particular problem has been addressed on x86 by the
    commit a9edc8809328 ("x86/nmi: Perform a safe NMI stack trace on all
    CPUs").
    
    The patchset brings two big advantages.  First, it makes the NMI
    backtraces safe on all architectures for free.  Second, it makes all NMI
    messages almost safe on all architectures (the temporary buffer is
    limited.  We still should keep the number of messages in NMI context at
    minimum).
    
    Note that there already are several messages printed in NMI context:
    WARN_ON(in_nmi()), BUG_ON(in_nmi()), anything being printed out from MCE
    handlers.  These are not easy to avoid.
    
    This patch reuses most of the code and makes it generic.  It is useful
    for all messages and architectures that support NMI.
    
    The alternative printk_func is set when entering and is reseted when
    leaving NMI context.  It queues IRQ work to copy the messages into the
    main ring buffer in a safe context.
    
    __printk_nmi_flush() copies all available messages and reset the buffer.
    Then we could use a simple cmpxchg operations to get synchronized with
    writers.  There is also used a spinlock to get synchronized with other
    flushers.
    
    We do not longer use seq_buf because it depends on external lock.  It
    would be hard to make all supported operations safe for a lockless use.
    It would be confusing and error prone to make only some operations safe.
    
    The code is put into separate printk/nmi.c as suggested by Steven
    Rostedt.  It needs a per-CPU buffer and is compiled only on
    architectures that call nmi_enter().  This is achieved by the new
    HAVE_NMI Kconfig flag.
    
    The are MN10300 and Xtensa architectures.  We need to clean up NMI
    handling there first.  Let's do it separately.
    
    The patch is heavily based on the draft from Peter Zijlstra, see
    
      https://lkml.org/lkml/2015/6/10/327
    
    [arnd@arndb.de: printk-nmi: use %zu format string for size_t]
    [akpm@linux-foundation.org: min_t->min - all types are size_t here]
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Suggested-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Jan Kara <jack@suse.cz>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>    [arm part]
    Cc: Daniel Thompson <daniel.thompson@linaro.org>
    Cc: Jiri Kosina <jkosina@suse.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: David Miller <davem@davemloft.net>
    Cc: Daniel Thompson <daniel.thompson@linaro.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 045e424fb368..7788ce643bf4 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -18,7 +18,6 @@
 #include <linux/nmi.h>
 #include <linux/module.h>
 #include <linux/delay.h>
-#include <linux/seq_buf.h>
 
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(int watchdog_thresh)

commit 4d7489ffba0aef4d2c708b6ff1428efd6ccf41df
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 10 21:47:36 2015 +0100

    nmi: x86: convert to generic nmi handler
    
    Convert x86 to use the generic nmi handler code which can be shared
    between architectures.
    
    Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 6873ab925d00..045e424fb368 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -28,146 +28,21 @@ u64 hw_nmi_get_sample_period(int watchdog_thresh)
 #endif
 
 #ifdef arch_trigger_all_cpu_backtrace
-/* For reliability, we're prepared to waste bits here. */
-static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
-static cpumask_t printtrace_mask;
-
-#define NMI_BUF_SIZE		4096
-
-struct nmi_seq_buf {
-	unsigned char		buffer[NMI_BUF_SIZE];
-	struct seq_buf		seq;
-};
-
-/* Safe printing in NMI context */
-static DEFINE_PER_CPU(struct nmi_seq_buf, nmi_print_seq);
-
-/* "in progress" flag of arch_trigger_all_cpu_backtrace */
-static unsigned long backtrace_flag;
-
-static void print_seq_line(struct nmi_seq_buf *s, int start, int end)
+static void nmi_raise_cpu_backtrace(cpumask_t *mask)
 {
-	const char *buf = s->buffer + start;
-
-	printk("%.*s", (end - start) + 1, buf);
+	apic->send_IPI_mask(mask, NMI_VECTOR);
 }
 
 void arch_trigger_all_cpu_backtrace(bool include_self)
 {
-	struct nmi_seq_buf *s;
-	int len;
-	int cpu;
-	int i;
-	int this_cpu = get_cpu();
-
-	if (test_and_set_bit(0, &backtrace_flag)) {
-		/*
-		 * If there is already a trigger_all_cpu_backtrace() in progress
-		 * (backtrace_flag == 1), don't output double cpu dump infos.
-		 */
-		put_cpu();
-		return;
-	}
-
-	cpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);
-	if (!include_self)
-		cpumask_clear_cpu(this_cpu, to_cpumask(backtrace_mask));
-
-	cpumask_copy(&printtrace_mask, to_cpumask(backtrace_mask));
-	/*
-	 * Set up per_cpu seq_buf buffers that the NMIs running on the other
-	 * CPUs will write to.
-	 */
-	for_each_cpu(cpu, to_cpumask(backtrace_mask)) {
-		s = &per_cpu(nmi_print_seq, cpu);
-		seq_buf_init(&s->seq, s->buffer, NMI_BUF_SIZE);
-	}
-
-	if (!cpumask_empty(to_cpumask(backtrace_mask))) {
-		pr_info("sending NMI to %s CPUs:\n",
-			(include_self ? "all" : "other"));
-		apic->send_IPI_mask(to_cpumask(backtrace_mask), NMI_VECTOR);
-	}
-
-	/* Wait for up to 10 seconds for all CPUs to do the backtrace */
-	for (i = 0; i < 10 * 1000; i++) {
-		if (cpumask_empty(to_cpumask(backtrace_mask)))
-			break;
-		mdelay(1);
-		touch_softlockup_watchdog();
-	}
-
-	/*
-	 * Now that all the NMIs have triggered, we can dump out their
-	 * back traces safely to the console.
-	 */
-	for_each_cpu(cpu, &printtrace_mask) {
-		int last_i = 0;
-
-		s = &per_cpu(nmi_print_seq, cpu);
-		len = seq_buf_used(&s->seq);
-		if (!len)
-			continue;
-
-		/* Print line by line. */
-		for (i = 0; i < len; i++) {
-			if (s->buffer[i] == '\n') {
-				print_seq_line(s, last_i, i);
-				last_i = i + 1;
-			}
-		}
-		/* Check if there was a partial line. */
-		if (last_i < len) {
-			print_seq_line(s, last_i, len - 1);
-			pr_cont("\n");
-		}
-	}
-
-	clear_bit(0, &backtrace_flag);
-	smp_mb__after_atomic();
-	put_cpu();
-}
-
-/*
- * It is not safe to call printk() directly from NMI handlers.
- * It may be fine if the NMI detected a lock up and we have no choice
- * but to do so, but doing a NMI on all other CPUs to get a back trace
- * can be done with a sysrq-l. We don't want that to lock up, which
- * can happen if the NMI interrupts a printk in progress.
- *
- * Instead, we redirect the vprintk() to this nmi_vprintk() that writes
- * the content into a per cpu seq_buf buffer. Then when the NMIs are
- * all done, we can safely dump the contents of the seq_buf to a printk()
- * from a non NMI context.
- */
-static int nmi_vprintk(const char *fmt, va_list args)
-{
-	struct nmi_seq_buf *s = this_cpu_ptr(&nmi_print_seq);
-	unsigned int len = seq_buf_used(&s->seq);
-
-	seq_buf_vprintf(&s->seq, fmt, args);
-	return seq_buf_used(&s->seq) - len;
+	nmi_trigger_all_cpu_backtrace(include_self, nmi_raise_cpu_backtrace);
 }
 
 static int
 arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
-	int cpu;
-
-	cpu = smp_processor_id();
-
-	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
-		printk_func_t printk_func_save = this_cpu_read(printk_func);
-
-		/* Replace printk to write into the NMI seq */
-		this_cpu_write(printk_func, nmi_vprintk);
-		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
-		show_regs(regs);
-		this_cpu_write(printk_func, printk_func_save);
-
-		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
+	if (nmi_cpu_backtrace(regs))
 		return NMI_HANDLED;
-	}
 
 	return NMI_DONE;
 }

commit db0865543739b3edb2ee9bf340380cf4986b58ff
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Tue Nov 25 11:06:00 2014 -0500

    x86/nmi: Fix use of unallocated cpumask_var_t
    
    Commit "x86/nmi: Perform a safe NMI stack trace on all CPUs" has introduced
    a cpumask_var_t variable:
    
            +static cpumask_var_t printtrace_mask;
    
    But never allocated it before using it, which caused a NULL ptr deref when
    trying to print the stack trace:
    
    [ 1110.296154] BUG: unable to handle kernel NULL pointer dereference at           (null)
    [ 1110.296169] IP: __memcpy (arch/x86/lib/memcpy_64.S:151)
    [ 1110.296178] PGD 4c34b3067 PUD 4c351b067 PMD 0
    [ 1110.296186] Oops: 0002 [#1] PREEMPT SMP KASAN
    [ 1110.296234] Dumping ftrace buffer:
    [ 1110.296330]    (ftrace buffer empty)
    [ 1110.296339] Modules linked in:
    [ 1110.296345] CPU: 1 PID: 10538 Comm: trinity-c99 Not tainted 3.18.0-rc5-next-20141124-sasha-00058-ge2a8c09-dirty #1499
    [ 1110.296348] task: ffff880152650000 ti: ffff8804c3560000 task.ti: ffff8804c3560000
    [ 1110.296357] RIP: __memcpy (arch/x86/lib/memcpy_64.S:151)
    [ 1110.296360] RSP: 0000:ffff8804c3563870  EFLAGS: 00010246
    [ 1110.296363] RAX: 0000000000000000 RBX: ffffe8fff3c4a809 RCX: 0000000000000000
    [ 1110.296366] RDX: 0000000000000008 RSI: ffffffff9e254040 RDI: 0000000000000000
    [ 1110.296369] RBP: ffff8804c3563908 R08: 0000000000ffffff R09: 0000000000ffffff
    [ 1110.296371] R10: 0000000000000000 R11: 0000000000000006 R12: 0000000000000000
    [ 1110.296375] R13: 0000000000000000 R14: ffffffff9e254040 R15: ffffe8fff3c4a809
    [ 1110.296379] FS:  00007f9e43b0b700(0000) GS:ffff880107e00000(0000) knlGS:0000000000000000
    [ 1110.296382] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1110.296385] CR2: 0000000000000000 CR3: 00000004e4334000 CR4: 00000000000006a0
    [ 1110.296400] Stack:
    [ 1110.296406]  ffffffff81b1e46c 0000000000000000 ffff880107e03fb8 000000000000000b
    [ 1110.296413]  ffff880107dfffc0 ffff880107e03fc0 0000000000000008 ffffffff93f2e9c8
    [ 1110.296419]  0000000000000000 ffffda0020fc07f7 0000000000000008 ffff8804c3563901
    [ 1110.296420] Call Trace:
    [ 1110.296429] ? memcpy (mm/kasan/kasan.c:275)
    [ 1110.296437] ? arch_trigger_all_cpu_backtrace (include/linux/bitmap.h:215 include/linux/cpumask.h:506 arch/x86/kernel/apic/hw_nmi.c:76)
    [ 1110.296444] arch_trigger_all_cpu_backtrace (include/linux/bitmap.h:215 include/linux/cpumask.h:506 arch/x86/kernel/apic/hw_nmi.c:76)
    [ 1110.296451] ? dump_stack (./arch/x86/include/asm/preempt.h:95 lib/dump_stack.c:55)
    [ 1110.296458] do_raw_spin_lock (./arch/x86/include/asm/spinlock.h:86 kernel/locking/spinlock_debug.c:130 kernel/locking/spinlock_debug.c:137)
    [ 1110.296468] _raw_spin_lock (include/linux/spinlock_api_smp.h:143 kernel/locking/spinlock.c:151)
    [ 1110.296474] ? __page_check_address (include/linux/spinlock.h:309 mm/rmap.c:630)
    [ 1110.296481] __page_check_address (include/linux/spinlock.h:309 mm/rmap.c:630)
    [ 1110.296487] ? preempt_count_sub (kernel/sched/core.c:2615)
    [ 1110.296493] try_to_unmap_one (include/linux/rmap.h:202 mm/rmap.c:1146)
    [ 1110.296504] ? anon_vma_interval_tree_iter_next (mm/interval_tree.c:72 mm/interval_tree.c:103)
    [ 1110.296514] rmap_walk (mm/rmap.c:1653 mm/rmap.c:1725)
    [ 1110.296521] ? page_get_anon_vma (include/linux/rcupdate.h:423 include/linux/rcupdate.h:935 mm/rmap.c:435)
    [ 1110.296530] try_to_unmap (mm/rmap.c:1545)
    [ 1110.296536] ? page_get_anon_vma (mm/rmap.c:437)
    [ 1110.296545] ? try_to_unmap_nonlinear (mm/rmap.c:1138)
    [ 1110.296551] ? SyS_msync (mm/rmap.c:1501)
    [ 1110.296558] ? page_remove_rmap (mm/rmap.c:1409)
    [ 1110.296565] ? page_get_anon_vma (mm/rmap.c:448)
    [ 1110.296571] ? anon_vma_ctor (mm/rmap.c:1496)
    [ 1110.296579] migrate_pages (mm/migrate.c:913 mm/migrate.c:956 mm/migrate.c:1136)
    [ 1110.296586] ? _raw_spin_unlock_irq (./arch/x86/include/asm/preempt.h:95 include/linux/spinlock_api_smp.h:169 kernel/locking/spinlock.c:199)
    [ 1110.296593] ? buffer_migrate_lock_buffers (mm/migrate.c:1584)
    [ 1110.296601] ? handle_mm_fault (mm/memory.c:3163 mm/memory.c:3223 mm/memory.c:3336 mm/memory.c:3365)
    [ 1110.296607] migrate_misplaced_page (mm/migrate.c:1738)
    [ 1110.296614] handle_mm_fault (mm/memory.c:3170 mm/memory.c:3223 mm/memory.c:3336 mm/memory.c:3365)
    [ 1110.296623] __do_page_fault (arch/x86/mm/fault.c:1246)
    [ 1110.296630] ? vtime_account_user (kernel/sched/cputime.c:701)
    [ 1110.296638] ? get_parent_ip (kernel/sched/core.c:2559)
    [ 1110.296646] ? context_tracking_user_exit (kernel/context_tracking.c:144)
    [ 1110.296656] trace_do_page_fault (arch/x86/mm/fault.c:1329 include/linux/jump_label.h:114 include/linux/context_tracking_state.h:27 include/linux/context_tracking.h:45 arch/x86/mm/fault.c:1330)
    [ 1110.296664] do_async_page_fault (arch/x86/kernel/kvm.c:280)
    [ 1110.296670] async_page_fault (arch/x86/kernel/entry_64.S:1285)
    [ 1110.296755] Code: 08 4c 8b 54 16 f0 4c 8b 5c 16 f8 4c 89 07 4c 89 4f 08 4c 89 54 17 f0 4c 89 5c 17 f8 c3 90 83 fa 08 72 1b 4c 8b 06 4c 8b 4c 16 f8 <4c> 89 07 4c 89 4c 17 f8 c3 66 2e 0f 1f 84 00 00 00 00 00 83 fa
    All code
    ========
       0:   08 4c 8b 54             or     %cl,0x54(%rbx,%rcx,4)
       4:   16                      (bad)
       5:   f0 4c 8b 5c 16 f8       lock mov -0x8(%rsi,%rdx,1),%r11
       b:   4c 89 07                mov    %r8,(%rdi)
       e:   4c 89 4f 08             mov    %r9,0x8(%rdi)
      12:   4c 89 54 17 f0          mov    %r10,-0x10(%rdi,%rdx,1)
      17:   4c 89 5c 17 f8          mov    %r11,-0x8(%rdi,%rdx,1)
      1c:   c3                      retq
      1d:   90                      nop
      1e:   83 fa 08                cmp    $0x8,%edx
      21:   72 1b                   jb     0x3e
      23:   4c 8b 06                mov    (%rsi),%r8
      26:   4c 8b 4c 16 f8          mov    -0x8(%rsi,%rdx,1),%r9
      2b:*  4c 89 07                mov    %r8,(%rdi)               <-- trapping instruction
      2e:   4c 89 4c 17 f8          mov    %r9,-0x8(%rdi,%rdx,1)
      33:   c3                      retq
      34:   66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)
      3b:   00 00 00
      3e:   83 fa 00                cmp    $0x0,%edx
    
    Code starting with the faulting instruction
    ===========================================
       0:   4c 89 07                mov    %r8,(%rdi)
       3:   4c 89 4c 17 f8          mov    %r9,-0x8(%rdi,%rdx,1)
       8:   c3                      retq
       9:   66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)
      10:   00 00 00
      13:   83 fa 00                cmp    $0x0,%edx
    [ 1110.296760] RIP __memcpy (arch/x86/lib/memcpy_64.S:151)
    [ 1110.296763]  RSP <ffff8804c3563870>
    [ 1110.296765] CR2: 0000000000000000
    
    Link: http://lkml.kernel.org/r/1416931560-10603-1-git-send-email-sasha.levin@oracle.com
    
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c95c3e9ce196..6873ab925d00 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -30,7 +30,7 @@ u64 hw_nmi_get_sample_period(int watchdog_thresh)
 #ifdef arch_trigger_all_cpu_backtrace
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
-static cpumask_var_t printtrace_mask;
+static cpumask_t printtrace_mask;
 
 #define NMI_BUF_SIZE		4096
 
@@ -73,7 +73,7 @@ void arch_trigger_all_cpu_backtrace(bool include_self)
 	if (!include_self)
 		cpumask_clear_cpu(this_cpu, to_cpumask(backtrace_mask));
 
-	cpumask_copy(printtrace_mask, to_cpumask(backtrace_mask));
+	cpumask_copy(&printtrace_mask, to_cpumask(backtrace_mask));
 	/*
 	 * Set up per_cpu seq_buf buffers that the NMIs running on the other
 	 * CPUs will write to.
@@ -101,7 +101,7 @@ void arch_trigger_all_cpu_backtrace(bool include_self)
 	 * Now that all the NMIs have triggered, we can dump out their
 	 * back traces safely to the console.
 	 */
-	for_each_cpu(cpu, printtrace_mask) {
+	for_each_cpu(cpu, &printtrace_mask) {
 		int last_i = 0;
 
 		s = &per_cpu(nmi_print_seq, cpu);

commit a9edc88093287183ac934be44f295f183b2c62dd
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Thu Jun 19 17:33:32 2014 -0400

    x86/nmi: Perform a safe NMI stack trace on all CPUs
    
    When trigger_all_cpu_backtrace() is called on x86, it will trigger an
    NMI on each CPU and call show_regs(). But this can lead to a hard lock
    up if the NMI comes in on another printk().
    
    In order to avoid this, when the NMI triggers, it switches the printk
    routine for that CPU to call a NMI safe printk function that records the
    printk in a per_cpu seq_buf descriptor. After all NMIs have finished
    recording its data, the seq_bufs are printed in a safe context.
    
    Link: http://lkml.kernel.org/p/20140619213952.360076309@goodmis.org
    Link: http://lkml.kernel.org/r/20141115050605.055232587@goodmis.org
    
    Tested-by: Jiri Kosina <jkosina@suse.cz>
    Acked-by: Jiri Kosina <jkosina@suse.cz>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Petr Mladek <pmladek@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 6a1e71bde323..c95c3e9ce196 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -18,6 +18,7 @@
 #include <linux/nmi.h>
 #include <linux/module.h>
 #include <linux/delay.h>
+#include <linux/seq_buf.h>
 
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(int watchdog_thresh)
@@ -29,14 +30,35 @@ u64 hw_nmi_get_sample_period(int watchdog_thresh)
 #ifdef arch_trigger_all_cpu_backtrace
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
+static cpumask_var_t printtrace_mask;
+
+#define NMI_BUF_SIZE		4096
+
+struct nmi_seq_buf {
+	unsigned char		buffer[NMI_BUF_SIZE];
+	struct seq_buf		seq;
+};
+
+/* Safe printing in NMI context */
+static DEFINE_PER_CPU(struct nmi_seq_buf, nmi_print_seq);
 
 /* "in progress" flag of arch_trigger_all_cpu_backtrace */
 static unsigned long backtrace_flag;
 
+static void print_seq_line(struct nmi_seq_buf *s, int start, int end)
+{
+	const char *buf = s->buffer + start;
+
+	printk("%.*s", (end - start) + 1, buf);
+}
+
 void arch_trigger_all_cpu_backtrace(bool include_self)
 {
+	struct nmi_seq_buf *s;
+	int len;
+	int cpu;
 	int i;
-	int cpu = get_cpu();
+	int this_cpu = get_cpu();
 
 	if (test_and_set_bit(0, &backtrace_flag)) {
 		/*
@@ -49,7 +71,17 @@ void arch_trigger_all_cpu_backtrace(bool include_self)
 
 	cpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);
 	if (!include_self)
-		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
+		cpumask_clear_cpu(this_cpu, to_cpumask(backtrace_mask));
+
+	cpumask_copy(printtrace_mask, to_cpumask(backtrace_mask));
+	/*
+	 * Set up per_cpu seq_buf buffers that the NMIs running on the other
+	 * CPUs will write to.
+	 */
+	for_each_cpu(cpu, to_cpumask(backtrace_mask)) {
+		s = &per_cpu(nmi_print_seq, cpu);
+		seq_buf_init(&s->seq, s->buffer, NMI_BUF_SIZE);
+	}
 
 	if (!cpumask_empty(to_cpumask(backtrace_mask))) {
 		pr_info("sending NMI to %s CPUs:\n",
@@ -65,11 +97,58 @@ void arch_trigger_all_cpu_backtrace(bool include_self)
 		touch_softlockup_watchdog();
 	}
 
+	/*
+	 * Now that all the NMIs have triggered, we can dump out their
+	 * back traces safely to the console.
+	 */
+	for_each_cpu(cpu, printtrace_mask) {
+		int last_i = 0;
+
+		s = &per_cpu(nmi_print_seq, cpu);
+		len = seq_buf_used(&s->seq);
+		if (!len)
+			continue;
+
+		/* Print line by line. */
+		for (i = 0; i < len; i++) {
+			if (s->buffer[i] == '\n') {
+				print_seq_line(s, last_i, i);
+				last_i = i + 1;
+			}
+		}
+		/* Check if there was a partial line. */
+		if (last_i < len) {
+			print_seq_line(s, last_i, len - 1);
+			pr_cont("\n");
+		}
+	}
+
 	clear_bit(0, &backtrace_flag);
 	smp_mb__after_atomic();
 	put_cpu();
 }
 
+/*
+ * It is not safe to call printk() directly from NMI handlers.
+ * It may be fine if the NMI detected a lock up and we have no choice
+ * but to do so, but doing a NMI on all other CPUs to get a back trace
+ * can be done with a sysrq-l. We don't want that to lock up, which
+ * can happen if the NMI interrupts a printk in progress.
+ *
+ * Instead, we redirect the vprintk() to this nmi_vprintk() that writes
+ * the content into a per cpu seq_buf buffer. Then when the NMIs are
+ * all done, we can safely dump the contents of the seq_buf to a printk()
+ * from a non NMI context.
+ */
+static int nmi_vprintk(const char *fmt, va_list args)
+{
+	struct nmi_seq_buf *s = this_cpu_ptr(&nmi_print_seq);
+	unsigned int len = seq_buf_used(&s->seq);
+
+	seq_buf_vprintf(&s->seq, fmt, args);
+	return seq_buf_used(&s->seq) - len;
+}
+
 static int
 arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
@@ -78,12 +157,14 @@ arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 	cpu = smp_processor_id();
 
 	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
-		static arch_spinlock_t lock = __ARCH_SPIN_LOCK_UNLOCKED;
+		printk_func_t printk_func_save = this_cpu_read(printk_func);
 
-		arch_spin_lock(&lock);
+		/* Replace printk to write into the NMI seq */
+		this_cpu_write(printk_func, nmi_vprintk);
 		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
 		show_regs(regs);
-		arch_spin_unlock(&lock);
+		this_cpu_write(printk_func, printk_func_save);
+
 		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
 		return NMI_HANDLED;
 	}

commit f3aca3d09525f87731ba6b892c9b010570bc54b4
Author: Aaron Tomlin <atomlin@redhat.com>
Date:   Mon Jun 23 13:22:05 2014 -0700

    nmi: provide the option to issue an NMI back trace to every cpu but current
    
    Sometimes it is preferred not to use the trigger_all_cpu_backtrace()
    routine when one wants to avoid capturing a back trace for current.  For
    instance if one was previously captured recently.
    
    This patch provides a new routine namely
    trigger_allbutself_cpu_backtrace() which offers the flexibility to issue
    an NMI to every cpu but current and capture a back trace accordingly.
    
    Patch x86 and sparc to support new routine.
    
    [dzickus@redhat.com: add stub in #else clause]
    [dzickus@redhat.com: don't print message in single processor case, wrap with get/put_cpu based on Oleg's suggestion]
    [sfr@canb.auug.org.au: undo C99ism]
    Signed-off-by: Aaron Tomlin <atomlin@redhat.com>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Cc: Mateusz Guzik <mguzik@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c3fcb5de5083..6a1e71bde323 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -33,31 +33,41 @@ static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 /* "in progress" flag of arch_trigger_all_cpu_backtrace */
 static unsigned long backtrace_flag;
 
-void arch_trigger_all_cpu_backtrace(void)
+void arch_trigger_all_cpu_backtrace(bool include_self)
 {
 	int i;
+	int cpu = get_cpu();
 
-	if (test_and_set_bit(0, &backtrace_flag))
+	if (test_and_set_bit(0, &backtrace_flag)) {
 		/*
 		 * If there is already a trigger_all_cpu_backtrace() in progress
 		 * (backtrace_flag == 1), don't output double cpu dump infos.
 		 */
+		put_cpu();
 		return;
+	}
 
 	cpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);
+	if (!include_self)
+		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
 
-	printk(KERN_INFO "sending NMI to all CPUs:\n");
-	apic->send_IPI_all(NMI_VECTOR);
+	if (!cpumask_empty(to_cpumask(backtrace_mask))) {
+		pr_info("sending NMI to %s CPUs:\n",
+			(include_self ? "all" : "other"));
+		apic->send_IPI_mask(to_cpumask(backtrace_mask), NMI_VECTOR);
+	}
 
 	/* Wait for up to 10 seconds for all CPUs to do the backtrace */
 	for (i = 0; i < 10 * 1000; i++) {
 		if (cpumask_empty(to_cpumask(backtrace_mask)))
 			break;
 		mdelay(1);
+		touch_softlockup_watchdog();
 	}
 
 	clear_bit(0, &backtrace_flag);
 	smp_mb__after_atomic();
+	put_cpu();
 }
 
 static int

commit 3737a12761636ebde0f09ef49daebb8eed18cc8a
Merge: c29deef32e36 82b897782d10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 19:18:49 2014 -0700

    Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull more perf updates from Ingo Molnar:
     "A second round of perf updates:
    
       - wide reaching kprobes sanitization and robustization, with the hope
         of fixing all 'probe this function crashes the kernel' bugs, by
         Masami Hiramatsu.
    
       - uprobes updates from Oleg Nesterov: tmpfs support, corner case
         fixes and robustization work.
    
       - perf tooling updates and fixes from Jiri Olsa, Namhyung Ki, Arnaldo
         et al:
            * Add support to accumulate hist periods (Namhyung Kim)
            * various fixes, refactorings and enhancements"
    
    * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (101 commits)
      perf: Differentiate exec() and non-exec() comm events
      perf: Fix perf_event_comm() vs. exec() assumption
      uprobes/x86: Rename arch_uprobe->def to ->defparam, minor comment updates
      perf/documentation: Add description for conditional branch filter
      perf/x86: Add conditional branch filtering support
      perf/tool: Add conditional branch filter 'cond' to perf record
      perf: Add new conditional branch filter 'PERF_SAMPLE_BRANCH_COND'
      uprobes: Teach copy_insn() to support tmpfs
      uprobes: Shift ->readpage check from __copy_insn() to uprobe_register()
      perf/x86: Use common PMU interrupt disabled code
      perf/ARM: Use common PMU interrupt disabled code
      perf: Disable sampled events if no PMU interrupt
      perf: Fix use after free in perf_remove_from_context()
      perf tools: Fix 'make help' message error
      perf record: Fix poll return value propagation
      perf tools: Move elide bool into perf_hpp_fmt struct
      perf tools: Remove elide setup for SORT_MODE__MEMORY mode
      perf tools: Fix "==" into "=" in ui_browser__warning assignment
      perf tools: Allow overriding sysfs and proc finding with env var
      perf tools: Consider header files outside perf directory in tags target
      ...

commit 9326638cbee2d36b051ed2a69f3e4e107e5f86bd
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Thu Apr 17 17:18:14 2014 +0900

    kprobes, x86: Use NOKPROBE_SYMBOL() instead of __kprobes annotation
    
    Use NOKPROBE_SYMBOL macro for protecting functions
    from kprobes instead of __kprobes annotation under
    arch/x86.
    
    This applies nokprobe_inline annotation for some cases,
    because NOKPROBE_SYMBOL() will inhibit inlining by
    referring the symbol address.
    
    This just folds a bunch of previous NOKPROBE_SYMBOL()
    cleanup patches for x86 to one patch.
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Link: http://lkml.kernel.org/r/20140417081814.26341.51656.stgit@ltc230.yrl.intra.hitachi.co.jp
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fernando Luis VÃ¡zquez Cao <fernando_b1@lab.ntt.co.jp>
    Cc: Gleb Natapov <gleb@redhat.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Jonathan Lebon <jlebon@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Matt Fleming <matt.fleming@intel.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Seiji Aguchi <seiji.aguchi@hds.com>
    Cc: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index a698d7165c96..73eb5b336f63 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -60,7 +60,7 @@ void arch_trigger_all_cpu_backtrace(void)
 	smp_mb__after_clear_bit();
 }
 
-static int __kprobes
+static int
 arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
 	int cpu;
@@ -80,6 +80,7 @@ arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 
 	return NMI_DONE;
 }
+NOKPROBE_SYMBOL(arch_trigger_all_cpu_backtrace_handler);
 
 static int __init register_trigger_all_cpu_backtrace(void)
 {

commit d00a569284b1340c16fe2c148099e077ea09ebc9
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 13 19:00:35 2014 +0100

    arch,x86: Convert smp_mb__*()
    
    x86 is strongly ordered and all its atomic ops imply a full barrier.
    
    Implement the two new primitives as the old ones were.
    
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/n/tip-knswsr5mldkr0w1lrdxvc81w@git.kernel.org
    Cc: Dave Jones <davej@redhat.com>
    Cc: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index a698d7165c96..eab67047dec3 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -57,7 +57,7 @@ void arch_trigger_all_cpu_backtrace(void)
 	}
 
 	clear_bit(0, &backtrace_flag);
-	smp_mb__after_clear_bit();
+	smp_mb__after_atomic();
 }
 
 static int __kprobes

commit b52e0a7c4e4100f8683af508664e60e1603070f9
Author: Michel Lespinasse <walken@google.com>
Date:   Thu Jun 6 04:41:15 2013 -0700

    x86: Fix trigger_all_cpu_backtrace() implementation
    
    The following change fixes the x86 implementation of
    trigger_all_cpu_backtrace(), which was previously (accidentally,
    as far as I can tell) disabled to always return false as on
    architectures that do not implement this function.
    
    trigger_all_cpu_backtrace(), as defined in include/linux/nmi.h,
    should call arch_trigger_all_cpu_backtrace() if available, or
    return false if the underlying arch doesn't implement this
    function.
    
    x86 did provide a suitable arch_trigger_all_cpu_backtrace()
    implementation, but it wasn't actually being used because it was
    declared in asm/nmi.h, which linux/nmi.h doesn't include. Also,
    linux/nmi.h couldn't easily be fixed by including asm/nmi.h,
    because that file is not available on all architectures.
    
    I am proposing to fix this by moving the x86 definition of
    arch_trigger_all_cpu_backtrace() to asm/irq.h.
    
    Tested via: echo l > /proc/sysrq-trigger
    
    Before the change, this uses a fallback implementation which
    shows backtraces on active CPUs (using
    smp_call_function_interrupt() )
    
    After the change, this shows NMI backtraces on all CPUs
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1370518875-1346-1-git-send-email-walken@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 31cb9ae992b7..a698d7165c96 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -9,6 +9,7 @@
  *
  */
 #include <asm/apic.h>
+#include <asm/nmi.h>
 
 #include <linux/cpumask.h>
 #include <linux/kdebug.h>

commit 9c48f1c629ecfa114850c03f875c6691003214de
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri Sep 30 15:06:21 2011 -0400

    x86, nmi: Wire up NMI handlers to new routines
    
    Just convert all the files that have an nmi handler to the new routines.
    Most of it is straight forward conversion.  A couple of places needed some
    tweaking like kgdb which separates the debug notifier from the nmi handler
    and mce removes a call to notify_die.
    
    [Thanks to Ying for finding out the history behind that mce call
    
    https://lkml.org/lkml/2010/5/27/114
    
    And Boris responding that he would like to remove that call because of it
    
    https://lkml.org/lkml/2011/9/21/163]
    
    The things that get converted are the registeration/unregistration routines
    and the nmi handler itself has its args changed along with code removal
    to check which list it is on (most are on one NMI list except for kgdb
    which has both an NMI routine and an NMI Unknown routine).
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Corey Minyard <minyard@acm.org>
    Cc: Jason Wessel <jason.wessel@windriver.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Corey Minyard <minyard@acm.org>
    Cc: Jack Steiner <steiner@sgi.com>
    Link: http://lkml.kernel.org/r/1317409584-23662-4-git-send-email-dzickus@redhat.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index d5e57db0f7be..31cb9ae992b7 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -60,22 +60,10 @@ void arch_trigger_all_cpu_backtrace(void)
 }
 
 static int __kprobes
-arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
-			 unsigned long cmd, void *__args)
+arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
-	struct die_args *args = __args;
-	struct pt_regs *regs;
 	int cpu;
 
-	switch (cmd) {
-	case DIE_NMI:
-		break;
-
-	default:
-		return NOTIFY_DONE;
-	}
-
-	regs = args->regs;
 	cpu = smp_processor_id();
 
 	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
@@ -86,21 +74,16 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 		show_regs(regs);
 		arch_spin_unlock(&lock);
 		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
-		return NOTIFY_STOP;
+		return NMI_HANDLED;
 	}
 
-	return NOTIFY_DONE;
+	return NMI_DONE;
 }
 
-static __read_mostly struct notifier_block backtrace_notifier = {
-	.notifier_call          = arch_trigger_all_cpu_backtrace_handler,
-	.next                   = NULL,
-	.priority               = NMI_LOCAL_LOW_PRIOR,
-};
-
 static int __init register_trigger_all_cpu_backtrace(void)
 {
-	register_die_notifier(&backtrace_notifier);
+	register_nmi_handler(NMI_LOCAL, arch_trigger_all_cpu_backtrace_handler,
+				0, "arch_bt");
 	return 0;
 }
 early_initcall(register_trigger_all_cpu_backtrace);

commit 4eec42f392043063d0f019640b4ccc2a45570002
Author: Mandeep Singh Baines <msb@chromium.org>
Date:   Sun May 22 22:10:23 2011 -0700

    watchdog: Change the default timeout and configure nmi watchdog period based on watchdog_thresh
    
    Before the conversion of the NMI watchdog to perf event, the
    watchdog timeout was 5 seconds. Now it is 60 seconds. For my
    particular application, netbooks, 5 seconds was a better
    timeout. With a short timeout, we catch faults earlier and are
    able to send back a panic. With a 60 second timeout, the user is
    unlikely to wait and will instead hit the power button, causing
    us to lose the panic info.
    
    This change configures the NMI period to watchdog_thresh and
    sets the softlockup_thresh to watchdog_thresh * 2. In addition,
    watchdog_thresh was reduced to 10 seconds as suggested by Ingo
    Molnar.
    
    Signed-off-by: Mandeep Singh Baines <msb@chromium.org>
    Cc: Marcin Slusarz <marcin.slusarz@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Link: http://lkml.kernel.org/r/1306127423-3347-4-git-send-email-msb@chromium.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    LKML-Reference: <20110517071642.GF22305@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 5260fe91bcb6..d5e57db0f7be 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -19,9 +19,9 @@
 #include <linux/delay.h>
 
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
-u64 hw_nmi_get_sample_period(void)
+u64 hw_nmi_get_sample_period(int watchdog_thresh)
 {
-	return (u64)(cpu_khz) * 1000 * 60;
+	return (u64)(cpu_khz) * 1000 * watchdog_thresh;
 }
 #endif
 

commit ca444564a947034557a85357b3911d067cac4b8f
Author: Jean Delvare <khali@linux-fr.org>
Date:   Fri Mar 25 15:20:14 2011 +0100

    x86: Stop including <linux/delay.h> in two asm header files
    
    Stop including <linux/delay.h> in x86 header files which don't
    need it. This will let the compiler complain when this header is
    not included by source files when it should, so that
    contributors can fix the problem before building on other
    architectures starts to fail.
    
    Credits go to Geert for the idea.
    
    Signed-off-by: Jean Delvare <khali@linux-fr.org>
    Cc: James E.J. Bottomley <James.Bottomley@suse.de>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    LKML-Reference: <20110325152014.297890ec@endymion.delvare>
    [ this also fixes an upstream build bug in drivers/media/rc/ite-cir.c ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c4e557a1ebb6..5260fe91bcb6 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -16,6 +16,7 @@
 #include <linux/kprobes.h>
 #include <linux/nmi.h>
 #include <linux/module.h>
+#include <linux/delay.h>
 
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(void)

commit bb3e6251a69e67d7620373ee18e35b404964273e
Author: Jan Beulich <JBeulich@novell.com>
Date:   Thu Feb 17 15:47:37 2011 +0000

    x86: Don't call dump_stack() from arch_trigger_all_cpu_backtrace_handler()
    
    show_regs() already prints two(!) stack traces, no need for a third one.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <4D5D512902000078000326EE@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 79fd43ca6f96..c4e557a1ebb6 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -83,7 +83,6 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 		arch_spin_lock(&lock);
 		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
 		show_regs(regs);
-		dump_stack();
 		arch_spin_unlock(&lock);
 		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
 		return NOTIFY_STOP;

commit c410b8307702c1e1f35be3fd868ad18e4ba0410f
Author: Don Zickus <dzickus@redhat.com>
Date:   Thu Jan 6 16:18:50 2011 -0500

    x86, NMI: Remove DIE_NMI_IPI
    
    With priorities in place and no one really understanding the difference between
    DIE_NMI and DIE_NMI_IPI, just remove DIE_NMI_IPI and convert everyone to DIE_NMI.
    
    This also simplifies default_do_nmi() a little bit.  Instead of calling the
    die_notifier in both the if and else part, just pull it out and call it before
    the if-statement.  This has the side benefit of avoiding a call to the ioport
    to see if there is an external NMI sitting around until after the (more frequent)
    internal NMIs are dealt with.
    
    Patch-Inspired-by: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1294348732-15030-5-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 8bc49f1ac7bc..79fd43ca6f96 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -68,7 +68,6 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 
 	switch (cmd) {
 	case DIE_NMI:
-	case DIE_NMI_IPI:
 		break;
 
 	default:

commit 166d751479c6d4e5b17dfc1f204a9c4397c9b3f1
Author: Don Zickus <dzickus@redhat.com>
Date:   Thu Jan 6 16:18:49 2011 -0500

    x86, NMI: Add priorities to handlers
    
    In order to consolidate the NMI die_chain events, we need to setup the priorities
    for the die notifiers.
    
    I started by defining a bunch of common priorities that can be used by the
    notifier blocks.  Then I modified the notifier blocks to use the newly created
    priorities.
    
    Now that the priorities are straightened out, it should be easier to remove the
    event DIE_NMI_IPI.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1294348732-15030-4-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 72ec29e1ae06..8bc49f1ac7bc 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -96,7 +96,7 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 static __read_mostly struct notifier_block backtrace_notifier = {
 	.notifier_call          = arch_trigger_all_cpu_backtrace_handler,
 	.next                   = NULL,
-	.priority               = 1
+	.priority               = NMI_LOCAL_LOW_PRIOR,
 };
 
 static int __init register_trigger_all_cpu_backtrace(void)

commit 554ec063982752e9a569ab9189eeffa3d96731b2
Author: Dongdong Deng <dongdong.deng@windriver.com>
Date:   Tue Jan 4 22:38:08 2011 -0500

    x86: Avoid calling arch_trigger_all_cpu_backtrace() at the same time
    
    The spin_lock_debug/rcu_cpu_stall detector uses
    trigger_all_cpu_backtrace() to dump cpu backtrace.
    Therefore it is possible that trigger_all_cpu_backtrace()
    could be called at the same time on different CPUs, which
    triggers and 'unknown reason NMI' warning. The following case
    illustrates the problem:
    
          CPU1                    CPU2                     ...   CPU N
                           trigger_all_cpu_backtrace()
                           set "backtrace_mask" to cpu mask
                                   |
    generate NMI interrupts  generate NMI interrupts       ...
        \                          |                               /
         \                         |                              /
    
    The "backtrace_mask" will be cleaned by the first NMI interrupt
    at nmi_watchdog_tick(), then the following NMI interrupts
    generated by other cpus's arch_trigger_all_cpu_backtrace() will
    be taken as unknown reason NMI interrupts.
    
    This patch uses a test_and_set to avoid the problem, and stop
    the arch_trigger_all_cpu_backtrace() from calling to avoid
    dumping a double cpu backtrace info when there is already a
    trigger_all_cpu_backtrace() in progress.
    
    Signed-off-by: Dongdong Deng <dongdong.deng@windriver.com>
    Reviewed-by: Bruce Ashfield <bruce.ashfield@windriver.com>
    Cc: fweisbec@gmail.com
    LKML-Reference: <1294198689-15447-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Don Zickus <dzickus@redhat.com>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 2b40a6045da2..72ec29e1ae06 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -28,10 +28,20 @@ u64 hw_nmi_get_sample_period(void)
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 
+/* "in progress" flag of arch_trigger_all_cpu_backtrace */
+static unsigned long backtrace_flag;
+
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;
 
+	if (test_and_set_bit(0, &backtrace_flag))
+		/*
+		 * If there is already a trigger_all_cpu_backtrace() in progress
+		 * (backtrace_flag == 1), don't output double cpu dump infos.
+		 */
+		return;
+
 	cpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);
 
 	printk(KERN_INFO "sending NMI to all CPUs:\n");
@@ -43,6 +53,9 @@ void arch_trigger_all_cpu_backtrace(void)
 			break;
 		mdelay(1);
 	}
+
+	clear_bit(0, &backtrace_flag);
+	smp_mb__after_clear_bit();
 }
 
 static int __kprobes

commit 9ab181fa9ff73a38fccd0a4f1c40a38dfe62b535
Author: Don Zickus <dzickus@redhat.com>
Date:   Tue Jan 4 22:38:07 2011 -0500

    x86: Only call smp_processor_id in non-preempt cases
    
    There are some paths that walk the die_chain with preemption on.
    Make sure we are in an NMI call before we start doing anything.
    
    This was triggered by do_general_protection calling notify_die
    with DIE_GPF.
    
    Reported-by: Jan Kiszka <jan.kiszka@web.de>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    LKML-Reference: <1294198689-15447-1-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c57d0b599448..2b40a6045da2 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -51,7 +51,7 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 {
 	struct die_args *args = __args;
 	struct pt_regs *regs;
-	int cpu = smp_processor_id();
+	int cpu;
 
 	switch (cmd) {
 	case DIE_NMI:
@@ -63,6 +63,7 @@ arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
 	}
 
 	regs = args->regs;
+	cpu = smp_processor_id();
 
 	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
 		static arch_spinlock_t lock = __ARCH_SPIN_LOCK_UNLOCKED;

commit 4a7863cc2eb5f9804f1c4e9156619a801cd7f14f
Author: Don Zickus <dzickus@redhat.com>
Date:   Wed Dec 22 14:00:03 2010 -0500

    x86, nmi_watchdog: Remove ARCH_HAS_NMI_WATCHDOG and rely on CONFIG_HARDLOCKUP_DETECTOR
    
    The x86 arch has shifted its use of the nmi_watchdog from a
    local implementation to the global one provide by
    kernel/watchdog.c.  This shift has caused a whole bunch of
    compile problems under different config options.  I attempt to
    simplify things with the patch below.
    
    In order to simplify things, I had to come to terms with the
    meaning of two terms ARCH_HAS_NMI_WATCHDOG and
    CONFIG_HARDLOCKUP_DETECTOR.  Basically they mean the same thing,
    the former on a local level and the latter on a global level.
    
    With the old x86 nmi watchdog gone, there is no need to rely on
    defining the ARCH_HAS_NMI_WATCHDOG variable because it doesn't
    make sense any more.  x86 will now use the global
    implementation.
    
    The changes below do a few things.  First it changes the few
    places that relied on ARCH_HAS_NMI_WATCHDOG to use
    CONFIG_X86_LOCAL_APIC (the former was an alias for the latter
    anyway, so nothing unusual here).  Those pieces of code were
    relying more on local apic functionality the nmi watchdog
    functionality, so the change should make sense.
    
    Second, I removed the x86 implementation of
    touch_nmi_watchdog().  It isn't need now, instead x86 will rely
    on kernel/watchdog.c's implementation.
    
    Third, I removed the #define ARCH_HAS_NMI_WATCHDOG itself from
    x86.  And tweaked the include/linux/nmi.h file to tell users to
    look for an externally defined touch_nmi_watchdog in the case of
    ARCH_HAS_NMI_WATCHDOG _or_ CONFIG_HARDLOCKUP_DETECTOR. This
    changes removes some of the ugliness in that file.
    
    Finally, I added a Kconfig dependency for
    CONFIG_HARDLOCKUP_DETECTOR that said you can't have
    ARCH_HAS_NMI_WATCHDOG _and_ CONFIG_HARDLOCKUP_DETECTOR.  You can
    only have one nmi_watchdog.
    
    Tested with
    ARCH=i386: allnoconfig, defconfig, allyesconfig, (various broken
    configs) ARCH=x86_64: allnoconfig, defconfig, allyesconfig,
    (various broken configs)
    
    Hopefully, after this patch I won't get any more compile broken
    emails. :-)
    
    v3:
      changed a couple of 'linux/nmi.h' -> 'asm/nmi.h' to pick-up correct function
      prototypes when CONFIG_HARDLOCKUP_DETECTOR is not set.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: fweisbec@gmail.com
    LKML-Reference: <1293044403-14117-1-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 93da91df5b38..c57d0b599448 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -17,7 +17,6 @@
 #include <linux/nmi.h>
 #include <linux/module.h>
 
-#ifdef ARCH_HAS_NMI_WATCHDOG
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(void)
 {
@@ -25,15 +24,6 @@ u64 hw_nmi_get_sample_period(void)
 }
 #endif
 
-#ifndef CONFIG_HARDLOCKUP_DETECTOR
-void touch_nmi_watchdog(void)
-{
-	touch_softlockup_watchdog();
-}
-EXPORT_SYMBOL(touch_nmi_watchdog);
-#endif
-#endif
-
 #ifdef arch_trigger_all_cpu_backtrace
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;

commit 5f29805a4f4627e766f862ff9f10c14f5f314359
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon Dec 13 10:31:58 2010 -0500

    x86, watchdog: Compile fix when CONFIG_LOCAL_APIC not enabled
    
    When adjusting the code to handle removing the old nmi watchdog,
    I forgot to consider the compile case when the local apic is not
    enabled.
    
    This change fixes the following build error:
    
      arch/x86/kernel/apic/hw_nmi.c:28:6: error: redefinition of âtouch_nmi_watchdogâ
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Acked-by: Randy Dunlap <randy.dunlap@oracle.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Rakib Mullick <rakib.mullick@gmail.com>
    LKML-Reference: <20101213153719.GD18577@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index c558e1101edf..93da91df5b38 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -17,6 +17,7 @@
 #include <linux/nmi.h>
 #include <linux/module.h>
 
+#ifdef ARCH_HAS_NMI_WATCHDOG
 #ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(void)
 {
@@ -31,6 +32,8 @@ void touch_nmi_watchdog(void)
 }
 EXPORT_SYMBOL(touch_nmi_watchdog);
 #endif
+#endif
+
 #ifdef arch_trigger_all_cpu_backtrace
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;

commit 5dc3055879b8f659f62abb7c3d1eaa4d02e36d65
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon Nov 29 17:07:17 2010 -0500

    x86, NMI: Add back unknown_nmi_panic and nmi_watchdog sysctls
    
    Originally adapted from Huang Ying's patch which moved the
    unknown_nmi_panic to the traps.c file.  Because the old nmi
    watchdog was deleted before this change happened, the
    unknown_nmi_panic sysctl was lost.  This re-adds it.
    
    Also, the nmi_watchdog sysctl was re-implemented and its
    documentation updated accordingly.
    
    Patch-inspired-by: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Reviewed-by: Cyrill Gorcunov <gorcunov@gmail.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Cc: fweisbec@gmail.com
    LKML-Reference: <1291068437-5331-3-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 2e94eb493591..c558e1101edf 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -99,6 +99,3 @@ static int __init register_trigger_all_cpu_backtrace(void)
 }
 early_initcall(register_trigger_all_cpu_backtrace);
 #endif
-
-/* STUB calls to mimic old nmi_watchdog behaviour */
-int unknown_nmi_panic;

commit 96a84c20d635fb1e98ab92f9fc517c4441f5c424
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon Nov 29 17:07:16 2010 -0500

    lockup detector: Compile fixes from removing the old x86 nmi watchdog
    
    My patch that removed the old x86 nmi watchdog broke other
    arches.  This change reverts a piece of that patch and puts the
    change in the correct spot.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Reviewed-by: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: fweisbec@gmail.com
    Cc: yinghai@kernel.org
    LKML-Reference: <1291068437-5331-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 057f1ebebe0c..2e94eb493591 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -24,8 +24,14 @@ u64 hw_nmi_get_sample_period(void)
 }
 #endif
 
+#ifndef CONFIG_HARDLOCKUP_DETECTOR
+void touch_nmi_watchdog(void)
+{
+	touch_softlockup_watchdog();
+}
+EXPORT_SYMBOL(touch_nmi_watchdog);
+#endif
 #ifdef arch_trigger_all_cpu_backtrace
-
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 

commit 2c6cb1053ad8b61ab9fb50b578d0ffea959f7583
Author: Rakib Mullick <rakib.mullick@gmail.com>
Date:   Thu Dec 9 14:47:34 2010 +0600

    x86: Address 'unused' warning in hw_nmi.c again
    
    arch/x86/kernel/apic/hw_nmi.c:29: warning: backtrace_mask defined but not used
    
    commit 0e2af2a9(x86, hw_nmi: Move backtrace_mask declaration under
    ARCH_HAS_NMI_WATCHDOG) addressed this warning, but it was reintroduced
    by commit 5f2b0ba4(x86, nmi_watchdog: Remove the old nmi_watchdog).
    
    Move backtrace_mask into the #ifdef arch_trigger_all_cpu_backtrace
    section again.
    
    Signed-off-by: Rakib Mullick <rakib.mullick@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    LKML-Reference: <AANLkTi=rcc38QzoKa6LFy4m++-p_9=Zt4_kDQE=GeKxf@mail.gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index a0e71cb4fa9c..057f1ebebe0c 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -24,11 +24,11 @@ u64 hw_nmi_get_sample_period(void)
 }
 #endif
 
+#ifdef arch_trigger_all_cpu_backtrace
 
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 
-#ifdef arch_trigger_all_cpu_backtrace
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;

commit 6c869e772c72d509d0db243a56c205ef48a29baf
Merge: e4e91ac41035 ee6dcfa40a50
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Nov 26 15:07:02 2010 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Conflicts:
            arch/x86/kernel/apic/hw_nmi.c
    
    Merge reason: Resolve conflict, queue up dependent patch.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 0e2af2a9abf94b408ff70679b692a8644fed4aab
Author: Rakib Mullick <rakib.mullick@gmail.com>
Date:   Fri Nov 12 09:50:54 2010 -0500

    x86, hw_nmi: Move backtrace_mask declaration under ARCH_HAS_NMI_WATCHDOG
    
    backtrace_mask has been used under the code context of
    ARCH_HAS_NMI_WATCHDOG. So put it into that context.
    We were warned by the following warning:
    
      arch/x86/kernel/apic/hw_nmi.c:21: warning: âbacktrace_maskâ defined but not used
    
    Signed-off-by: Rakib Mullick <rakib.mullick@gmail.com>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    LKML-Reference: <1289573455-3410-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index cefd6942f0e9..62f6e1e55b90 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -17,15 +17,16 @@
 #include <linux/nmi.h>
 #include <linux/module.h>
 
-/* For reliability, we're prepared to waste bits here. */
-static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
-
 u64 hw_nmi_get_sample_period(void)
 {
 	return (u64)(cpu_khz) * 1000 * 60;
 }
 
 #ifdef ARCH_HAS_NMI_WATCHDOG
+
+/* For reliability, we're prepared to waste bits here. */
+static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
+
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;

commit 072b198a4ad48bd722ec6d203d65422a4698eae7
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri Nov 12 11:22:24 2010 -0500

    x86, nmi_watchdog: Remove all stub function calls from old nmi_watchdog
    
    Now that the bulk of the old nmi_watchdog is gone, remove all
    the stub variables and hooks associated with it.
    
    This touches lots of files mainly because of how the io_apic
    nmi_watchdog was implemented.  Now that the io_apic nmi_watchdog
    is forever gone, remove all its fingers.
    
    Most of this code was not being exercised by virtue of
    nmi_watchdog != NMI_IO_APIC, so there shouldn't be anything to
    risky here.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: fweisbec@gmail.com
    Cc: gorcunov@openvz.org
    LKML-Reference: <1289578944-28564-3-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index b68b17460016..3e25afe9a62a 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -94,14 +94,4 @@ early_initcall(register_trigger_all_cpu_backtrace);
 #endif
 
 /* STUB calls to mimic old nmi_watchdog behaviour */
-#if defined(CONFIG_X86_LOCAL_APIC)
-unsigned int nmi_watchdog = NMI_NONE;
-EXPORT_SYMBOL(nmi_watchdog);
-#endif
-atomic_t nmi_active = ATOMIC_INIT(0);           /* oprofile uses this */
-EXPORT_SYMBOL(nmi_active);
 int unknown_nmi_panic;
-void cpu_nmi_set_wd_enabled(void) { return; }
-void stop_apic_nmi_watchdog(void *unused) { return; }
-void setup_apic_nmi_watchdog(void *unused) { return; }
-int __init check_nmi_watchdog(void) { return 0; }

commit 5f2b0ba4d94b3ac23cbc4b7f675d98eb677a760a
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri Nov 12 11:22:23 2010 -0500

    x86, nmi_watchdog: Remove the old nmi_watchdog
    
    Now that we have a new nmi_watchdog that is more generic and
    sits on top of the perf subsystem, we really do not need the old
    nmi_watchdog any more.
    
    In addition, the old nmi_watchdog doesn't really work if you are
    using the default clocksource, hpet.  The old nmi_watchdog code
    relied on local apic interrupts to determine if the cpu is still
    alive.  With hpet as the clocksource, these interrupts don't
    increment any more and the old nmi_watchdog triggers false
    postives.
    
    This piece removes the old nmi_watchdog code and stubs out any
    variables and functions calls.  The stubs are the same ones used
    by the new nmi_watchdog code, so it should be well tested.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: fweisbec@gmail.com
    Cc: gorcunov@openvz.org
    LKML-Reference: <1289578944-28564-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index cefd6942f0e9..b68b17460016 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -20,12 +20,14 @@
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 
+#ifdef CONFIG_HARDLOCKUP_DETECTOR
 u64 hw_nmi_get_sample_period(void)
 {
 	return (u64)(cpu_khz) * 1000 * 60;
 }
+#endif
 
-#ifdef ARCH_HAS_NMI_WATCHDOG
+#ifdef arch_trigger_all_cpu_backtrace
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;
@@ -95,8 +97,6 @@ early_initcall(register_trigger_all_cpu_backtrace);
 #if defined(CONFIG_X86_LOCAL_APIC)
 unsigned int nmi_watchdog = NMI_NONE;
 EXPORT_SYMBOL(nmi_watchdog);
-void acpi_nmi_enable(void) { return; }
-void acpi_nmi_disable(void) { return; }
 #endif
 atomic_t nmi_active = ATOMIC_INIT(0);           /* oprofile uses this */
 EXPORT_SYMBOL(nmi_active);

commit 5e85391b3badd3f0e50ebdd0cafe0202a979f73a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu May 13 09:12:39 2010 +0200

    x86, watchdog: Fix build error in hw_nmi.c
    
    On some configs the following build error triggers:
    
     arch/x86/kernel/apic/hw_nmi.c:35: error: 'apic' undeclared (first use in this function)
     arch/x86/kernel/apic/hw_nmi.c:35: error: (Each undeclared identifier is reported only once
     arch/x86/kernel/apic/hw_nmi.c:35: error: for each function it appears in.)
    
    Because asm/apic.h was only included implicitly. Include it explicitly.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    LKML-Reference: <1273713674-8434-1-git-send-regression-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 3b40082f0371..cefd6942f0e9 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -8,6 +8,7 @@
  *  Bits copied from original nmi.c file
  *
  */
+#include <asm/apic.h>
 
 #include <linux/cpumask.h>
 #include <linux/kdebug.h>

commit 10f9014912a2b1cb59c39cdea777e6d9afa8f17e
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri May 7 17:11:49 2010 -0400

    x86: Cleanup hw_nmi.c cruft
    
    The design of the hardlockup watchdog has changed and cruft was left
    behind in the hw_nmi.c file.  Just remove the code that isn't used
    anymore.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    LKML-Reference: <1273266711-18706-7-git-send-email-dzickus@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 8c3edfb89c2b..3b40082f0371 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -9,74 +9,16 @@
  *
  */
 
-#include <asm/apic.h>
-#include <linux/smp.h>
 #include <linux/cpumask.h>
-#include <linux/sched.h>
-#include <linux/percpu.h>
-#include <linux/cpumask.h>
-#include <linux/kernel_stat.h>
-#include <asm/mce.h>
 #include <linux/kdebug.h>
 #include <linux/notifier.h>
 #include <linux/kprobes.h>
-
-
 #include <linux/nmi.h>
 #include <linux/module.h>
 
 /* For reliability, we're prepared to waste bits here. */
 static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
 
-static DEFINE_PER_CPU(unsigned, last_irq_sum);
-
-/*
- * Take the local apic timer and PIT/HPET into account. We don't
- * know which one is active, when we have highres/dyntick on
- */
-static inline unsigned int get_timer_irqs(int cpu)
-{
-	unsigned int irqs = per_cpu(irq_stat, cpu).irq0_irqs;
-
-#if defined(CONFIG_X86_LOCAL_APIC)
-	irqs += per_cpu(irq_stat, cpu).apic_timer_irqs;
-#endif
-
-	return irqs;
-}
-
-static inline int mce_in_progress(void)
-{
-#if defined(CONFIG_X86_MCE)
-	return atomic_read(&mce_entry) > 0;
-#endif
-	return 0;
-}
-
-int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
-{
-	unsigned int sum;
-	int cpu = smp_processor_id();
-
-	/* if we are doing an mce, just assume the cpu is not stuck */
-	/* Could check oops_in_progress here too, but it's safer not to */
-	if (mce_in_progress())
-		return 0;
-
-	/* We determine if the cpu is stuck by checking whether any
-	 * interrupts have happened since we last checked.  Of course
-	 * an nmi storm could create false positives, but the higher
-	 * level logic should account for that
-	 */
-	sum = get_timer_irqs(cpu);
-	if (__get_cpu_var(last_irq_sum) == sum) {
-		return 1;
-	} else {
-		__get_cpu_var(last_irq_sum) = sum;
-		return 0;
-	}
-}
-
 u64 hw_nmi_get_sample_period(void)
 {
 	return (u64)(cpu_khz) * 1000 * 60;

commit 7cbb7e7fa46f6e5229438ac9e4a5c72ec0d53e0b
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri May 7 17:11:48 2010 -0400

    x86: Move trigger_all_cpu_backtrace to its own die_notifier
    
    As part of the transition of the nmi watchdog to something more
    generic, the trigger_all_cpu_backtrace code is getting left behind.
    Put it in its own die_notifier so it can still be used.
    
    V2:
    - use arch_spin_locks
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    LKML-Reference: <1273266711-18706-6-git-send-email-dzickus@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 79425f96fcee..8c3edfb89c2b 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -17,6 +17,10 @@
 #include <linux/cpumask.h>
 #include <linux/kernel_stat.h>
 #include <asm/mce.h>
+#include <linux/kdebug.h>
+#include <linux/notifier.h>
+#include <linux/kprobes.h>
+
 
 #include <linux/nmi.h>
 #include <linux/module.h>
@@ -54,20 +58,6 @@ int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
 	unsigned int sum;
 	int cpu = smp_processor_id();
 
-	/* FIXME: cheap hack for this check, probably should get its own
-	 * die_notifier handler
-	 */
-	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
-		static DEFINE_SPINLOCK(lock);	/* Serialise the printks */
-
-		spin_lock(&lock);
-		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
-		show_regs(regs);
-		dump_stack();
-		spin_unlock(&lock);
-		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
-	}
-
 	/* if we are doing an mce, just assume the cpu is not stuck */
 	/* Could check oops_in_progress here too, but it's safer not to */
 	if (mce_in_progress())
@@ -109,6 +99,53 @@ void arch_trigger_all_cpu_backtrace(void)
 		mdelay(1);
 	}
 }
+
+static int __kprobes
+arch_trigger_all_cpu_backtrace_handler(struct notifier_block *self,
+			 unsigned long cmd, void *__args)
+{
+	struct die_args *args = __args;
+	struct pt_regs *regs;
+	int cpu = smp_processor_id();
+
+	switch (cmd) {
+	case DIE_NMI:
+	case DIE_NMI_IPI:
+		break;
+
+	default:
+		return NOTIFY_DONE;
+	}
+
+	regs = args->regs;
+
+	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
+		static arch_spinlock_t lock = __ARCH_SPIN_LOCK_UNLOCKED;
+
+		arch_spin_lock(&lock);
+		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
+		show_regs(regs);
+		dump_stack();
+		arch_spin_unlock(&lock);
+		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
+		return NOTIFY_STOP;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static __read_mostly struct notifier_block backtrace_notifier = {
+	.notifier_call          = arch_trigger_all_cpu_backtrace_handler,
+	.next                   = NULL,
+	.priority               = 1
+};
+
+static int __init register_trigger_all_cpu_backtrace(void)
+{
+	register_die_notifier(&backtrace_notifier);
+	return 0;
+}
+early_initcall(register_trigger_all_cpu_backtrace);
 #endif
 
 /* STUB calls to mimic old nmi_watchdog behaviour */

commit 58687acba59266735adb8ccd9b5b9aa2c7cd205b
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri May 7 17:11:44 2010 -0400

    lockup_detector: Combine nmi_watchdog and softlockup detector
    
    The new nmi_watchdog (which uses the perf event subsystem) is very
    similar in structure to the softlockup detector.  Using Ingo's
    suggestion, I combined the two functionalities into one file:
    kernel/watchdog.c.
    
    Now both the nmi_watchdog (or hardlockup detector) and softlockup
    detector sit on top of the perf event subsystem, which is run every
    60 seconds or so to see if there are any lockups.
    
    To detect hardlockups, cpus not responding to interrupts, I
    implemented an hrtimer that runs 5 times for every perf event
    overflow event.  If that stops counting on a cpu, then the cpu is
    most likely in trouble.
    
    To detect softlockups, tasks not yielding to the scheduler, I used the
    previous kthread idea that now gets kicked every time the hrtimer fires.
    If the kthread isn't being scheduled neither is anyone else and the
    warning is printed to the console.
    
    I tested this on x86_64 and both the softlockup and hardlockup paths
    work.
    
    V2:
    - cleaned up the Kconfig and softlockup combination
    - surrounded hardlockup cases with #ifdef CONFIG_PERF_EVENTS_NMI
    - seperated out the softlockup case from perf event subsystem
    - re-arranged the enabling/disabling nmi watchdog from proc space
    - added cpumasks for hardlockup failure cases
    - removed fallback to soft events if no PMU exists for hard events
    
    V3:
    - comment cleanups
    - drop support for older softlockup code
    - per_cpu cleanups
    - completely remove software clock base hardlockup detector
    - use per_cpu masking on hard/soft lockup detection
    - #ifdef cleanups
    - rename config option NMI_WATCHDOG to LOCKUP_DETECTOR
    - documentation additions
    
    V4:
    - documentation fixes
    - convert per_cpu to __get_cpu_var
    - powerpc compile fixes
    
    V5:
    - split apart warn flags for hard and soft lockups
    
    TODO:
    - figure out how to make an arch-agnostic clock2cycles call
      (if possible) to feed into perf events as a sample period
    
    [fweisbec: merged conflict patch]
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: Randy Dunlap <randy.dunlap@oracle.com>
    LKML-Reference: <1273266711-18706-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index e8b78a0be5de..79425f96fcee 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -89,7 +89,7 @@ int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
 
 u64 hw_nmi_get_sample_period(void)
 {
-	return cpu_khz * 1000;
+	return (u64)(cpu_khz) * 1000 * 60;
 }
 
 #ifdef ARCH_HAS_NMI_WATCHDOG

commit 47195d57636604ff6048b0d7aa3e4ed9643f6073
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon Feb 22 18:09:03 2010 -0500

    nmi_watchdog: Clean up various small details
    
    Mostly copy/paste whitespace damage with a couple of nitpicks by
    the checkpatch script. Fix the struct definition as requested by Ingo too.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: peterz@infradead.org
    Cc: gorcunov@gmail.com
    Cc: aris@redhat.com
    LKML-Reference: <1266880143-24943-1-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    --
     arch/x86/kernel/apic/hw_nmi.c |   14 +++++------
     arch/x86/kernel/traps.c       |    6 ++--
     include/linux/nmi.h           |    2 -
     kernel/nmi_watchdog.c         |   51 ++++++++++++++++++++----------------------
     4 files changed, 36 insertions(+), 37 deletions(-)

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 0b4d205a6b8e..e8b78a0be5de 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -38,15 +38,15 @@ static inline unsigned int get_timer_irqs(int cpu)
 	irqs += per_cpu(irq_stat, cpu).apic_timer_irqs;
 #endif
 
-        return irqs;
+	return irqs;
 }
 
 static inline int mce_in_progress(void)
 {
 #if defined(CONFIG_X86_MCE)
-        return atomic_read(&mce_entry) > 0;
+	return atomic_read(&mce_entry) > 0;
 #endif
-        return 0;
+	return 0;
 }
 
 int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
@@ -69,9 +69,9 @@ int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
 	}
 
 	/* if we are doing an mce, just assume the cpu is not stuck */
-        /* Could check oops_in_progress here too, but it's safer not to */
-        if (mce_in_progress())
-                return 0;
+	/* Could check oops_in_progress here too, but it's safer not to */
+	if (mce_in_progress())
+		return 0;
 
 	/* We determine if the cpu is stuck by checking whether any
 	 * interrupts have happened since we last checked.  Of course
@@ -89,7 +89,7 @@ int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
 
 u64 hw_nmi_get_sample_period(void)
 {
-        return cpu_khz * 1000;
+	return cpu_khz * 1000;
 }
 
 #ifdef ARCH_HAS_NMI_WATCHDOG

commit 2cc4452bc31fc1cde6f0b64a4eb13269f982787d
Author: Don Zickus <dzickus@redhat.com>
Date:   Thu Feb 18 21:56:52 2010 -0500

    nmi_watchdog: Fix undefined 'apic' build bug
    
    Ingo provided me a config that fails to compile with:
    
      arch/x86/built-in.o: In function
      `arch_trigger_all_cpu_backtrace': (.text+0x17e78): undefined
      reference to `apic' make: *** [.tmp_vmlinux1] Error 1
    
    I realized I changed the compile behaviour of the nmi code by
    not wrapping it with CONFIG_LOCAL_APIC.  To fix this I add a
    compile check for ARCH_HAS_NMI_WATCHDOG around
    arch_trigger_all_cpu_backtrace.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: a.p.zijlstra@chello.nl
    Cc: gorcunov@gmail.com
    Cc: aris@redhat.com
    LKML-Reference: <1266548212-24243-1-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 312d772c5c35..0b4d205a6b8e 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -92,6 +92,7 @@ u64 hw_nmi_get_sample_period(void)
         return cpu_khz * 1000;
 }
 
+#ifdef ARCH_HAS_NMI_WATCHDOG
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;
@@ -108,6 +109,7 @@ void arch_trigger_all_cpu_backtrace(void)
 		mdelay(1);
 	}
 }
+#endif
 
 /* STUB calls to mimic old nmi_watchdog behaviour */
 #if defined(CONFIG_X86_LOCAL_APIC)

commit 504d7cf10ee42bb76b9556859f23d4121dee0a77
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri Feb 12 17:19:19 2010 -0500

    nmi_watchdog: Compile and portability fixes
    
    The original patch was x86_64 centric.  Changed the code to make
    it less so.
    
    ested by building and running on a powerpc.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: peterz@infradead.org
    Cc: gorcunov@gmail.com
    Cc: aris@redhat.com
    LKML-Reference: <1266013161-31197-2-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index 8c0e6a410d05..312d772c5c35 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -32,8 +32,13 @@ static DEFINE_PER_CPU(unsigned, last_irq_sum);
  */
 static inline unsigned int get_timer_irqs(int cpu)
 {
-        return per_cpu(irq_stat, cpu).apic_timer_irqs +
-                per_cpu(irq_stat, cpu).irq0_irqs;
+	unsigned int irqs = per_cpu(irq_stat, cpu).irq0_irqs;
+
+#if defined(CONFIG_X86_LOCAL_APIC)
+	irqs += per_cpu(irq_stat, cpu).apic_timer_irqs;
+#endif
+
+        return irqs;
 }
 
 static inline int mce_in_progress(void)
@@ -82,6 +87,11 @@ int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
 	}
 }
 
+u64 hw_nmi_get_sample_period(void)
+{
+        return cpu_khz * 1000;
+}
+
 void arch_trigger_all_cpu_backtrace(void)
 {
 	int i;
@@ -100,15 +110,16 @@ void arch_trigger_all_cpu_backtrace(void)
 }
 
 /* STUB calls to mimic old nmi_watchdog behaviour */
+#if defined(CONFIG_X86_LOCAL_APIC)
 unsigned int nmi_watchdog = NMI_NONE;
 EXPORT_SYMBOL(nmi_watchdog);
+void acpi_nmi_enable(void) { return; }
+void acpi_nmi_disable(void) { return; }
+#endif
 atomic_t nmi_active = ATOMIC_INIT(0);           /* oprofile uses this */
 EXPORT_SYMBOL(nmi_active);
-int nmi_watchdog_enabled;
 int unknown_nmi_panic;
 void cpu_nmi_set_wd_enabled(void) { return; }
-void acpi_nmi_enable(void) { return; }
-void acpi_nmi_disable(void) { return; }
 void stop_apic_nmi_watchdog(void *unused) { return; }
 void setup_apic_nmi_watchdog(void *unused) { return; }
 int __init check_nmi_watchdog(void) { return 0; }

commit 1fb9d6ad2766a1dd70d167552988375049a97f21
Author: Don Zickus <dzickus@redhat.com>
Date:   Fri Feb 5 21:47:04 2010 -0500

    nmi_watchdog: Add new, generic implementation, using perf events
    
    This is a new generic nmi_watchdog implementation using the perf
    events infrastructure as suggested by Ingo.
    
    The implementation is simple, just create an in-kernel perf
    event and register an overflow handler to check for cpu lockups.
    
    I created a generic implementation that lives in kernel/ and
    the hardware specific part that for now lives in arch/x86.
    
    This approach has a number of advantages:
    
     - It simplifies the x86 PMU implementation in the long run,
       in that it removes the hardcoded low-level PMU implementation
       that was the NMI watchdog before.
    
     - It allows new NMI watchdog features to be added in a central
       place.
    
     - It allows other architectures to enable the NMI watchdog,
       as long as they have perf events (that provide NMIs)
       implemented.
    
     - It also allows for more graceful co-existence of existing
       perf events apps and the NMI watchdog - before these changes
       the relationship was exclusive. (The NMI watchdog will 'spend'
       a perf event when enabled. In later iterations we might be
       able to piggyback from an existing NMI event without having
       to allocate a hardware event for the NMI watchdog - turning
       this into a no-hardware-cost feature.)
    
    As for compatibility, we'll keep the old NMI watchdog code as
    well until the new one can 100% replace it on all CPUs, old and
    new alike.  That might take some time as the NMI watchdog has
    been ported to many CPU models.
    
    I have done light testing to make sure the framework works
    correctly and it does.
    
     v2: Set the correct timeout values based on the old nmi
         watchdog
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: gorcunov@gmail.com
    Cc: aris@redhat.com
    Cc: peterz@infradead.org
    LKML-Reference: <1265424425-31562-3-git-send-email-dzickus@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
new file mode 100644
index 000000000000..8c0e6a410d05
--- /dev/null
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -0,0 +1,114 @@
+/*
+ *  HW NMI watchdog support
+ *
+ *  started by Don Zickus, Copyright (C) 2010 Red Hat, Inc.
+ *
+ *  Arch specific calls to support NMI watchdog
+ *
+ *  Bits copied from original nmi.c file
+ *
+ */
+
+#include <asm/apic.h>
+#include <linux/smp.h>
+#include <linux/cpumask.h>
+#include <linux/sched.h>
+#include <linux/percpu.h>
+#include <linux/cpumask.h>
+#include <linux/kernel_stat.h>
+#include <asm/mce.h>
+
+#include <linux/nmi.h>
+#include <linux/module.h>
+
+/* For reliability, we're prepared to waste bits here. */
+static DECLARE_BITMAP(backtrace_mask, NR_CPUS) __read_mostly;
+
+static DEFINE_PER_CPU(unsigned, last_irq_sum);
+
+/*
+ * Take the local apic timer and PIT/HPET into account. We don't
+ * know which one is active, when we have highres/dyntick on
+ */
+static inline unsigned int get_timer_irqs(int cpu)
+{
+        return per_cpu(irq_stat, cpu).apic_timer_irqs +
+                per_cpu(irq_stat, cpu).irq0_irqs;
+}
+
+static inline int mce_in_progress(void)
+{
+#if defined(CONFIG_X86_MCE)
+        return atomic_read(&mce_entry) > 0;
+#endif
+        return 0;
+}
+
+int hw_nmi_is_cpu_stuck(struct pt_regs *regs)
+{
+	unsigned int sum;
+	int cpu = smp_processor_id();
+
+	/* FIXME: cheap hack for this check, probably should get its own
+	 * die_notifier handler
+	 */
+	if (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {
+		static DEFINE_SPINLOCK(lock);	/* Serialise the printks */
+
+		spin_lock(&lock);
+		printk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
+		show_regs(regs);
+		dump_stack();
+		spin_unlock(&lock);
+		cpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));
+	}
+
+	/* if we are doing an mce, just assume the cpu is not stuck */
+        /* Could check oops_in_progress here too, but it's safer not to */
+        if (mce_in_progress())
+                return 0;
+
+	/* We determine if the cpu is stuck by checking whether any
+	 * interrupts have happened since we last checked.  Of course
+	 * an nmi storm could create false positives, but the higher
+	 * level logic should account for that
+	 */
+	sum = get_timer_irqs(cpu);
+	if (__get_cpu_var(last_irq_sum) == sum) {
+		return 1;
+	} else {
+		__get_cpu_var(last_irq_sum) = sum;
+		return 0;
+	}
+}
+
+void arch_trigger_all_cpu_backtrace(void)
+{
+	int i;
+
+	cpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);
+
+	printk(KERN_INFO "sending NMI to all CPUs:\n");
+	apic->send_IPI_all(NMI_VECTOR);
+
+	/* Wait for up to 10 seconds for all CPUs to do the backtrace */
+	for (i = 0; i < 10 * 1000; i++) {
+		if (cpumask_empty(to_cpumask(backtrace_mask)))
+			break;
+		mdelay(1);
+	}
+}
+
+/* STUB calls to mimic old nmi_watchdog behaviour */
+unsigned int nmi_watchdog = NMI_NONE;
+EXPORT_SYMBOL(nmi_watchdog);
+atomic_t nmi_active = ATOMIC_INIT(0);           /* oprofile uses this */
+EXPORT_SYMBOL(nmi_active);
+int nmi_watchdog_enabled;
+int unknown_nmi_panic;
+void cpu_nmi_set_wd_enabled(void) { return; }
+void acpi_nmi_enable(void) { return; }
+void acpi_nmi_disable(void) { return; }
+void stop_apic_nmi_watchdog(void *unused) { return; }
+void setup_apic_nmi_watchdog(void *unused) { return; }
+int __init check_nmi_watchdog(void) { return 0; }
