commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c5e393f8bb3f..8e364c4c6768 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -39,7 +39,6 @@
 #include <asm/setup.h>
 #include <asm/page.h>
 #include <asm/e820/api.h>
-#include <asm/pgtable.h>
 #include <asm/tlbflush.h>
 #include <asm/proto.h>
 #include <asm/efi.h>

commit f6103162008dfd37567f240b50e5e1ea7cf2e00c
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Thu Apr 9 15:04:34 2020 +0200

    efi/x86: Don't remap text<->rodata gap read-only for mixed mode
    
    Commit
    
      d9e3d2c4f10320 ("efi/x86: Don't map the entire kernel text RW for mixed mode")
    
    updated the code that creates the 1:1 memory mapping to use read-only
    attributes for the 1:1 alias of the kernel's text and rodata sections, to
    protect it from inadvertent modification. However, it failed to take into
    account that the unused gap between text and rodata is given to the page
    allocator for general use.
    
    If the vmap'ed stack happens to be allocated from this region, any by-ref
    output arguments passed to EFI runtime services that are allocated on the
    stack (such as the 'datasize' argument taken by GetVariable() when invoked
    from efivar_entry_size()) will be referenced via a read-only mapping,
    resulting in a page fault if the EFI code tries to write to it:
    
      BUG: unable to handle page fault for address: 00000000386aae88
      #PF: supervisor write access in kernel mode
      #PF: error_code(0x0003) - permissions violation
      PGD fd61063 P4D fd61063 PUD fd62063 PMD 386000e1
      Oops: 0003 [#1] SMP PTI
      CPU: 2 PID: 255 Comm: systemd-sysv-ge Not tainted 5.6.0-rc4-default+ #22
      Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015
      RIP: 0008:0x3eaeed95
      Code: ...  <89> 03 be 05 00 00 80 a1 74 63 b1 3e 83 c0 48 e8 44 d2 ff ff eb 05
      RSP: 0018:000000000fd73fa0 EFLAGS: 00010002
      RAX: 0000000000000001 RBX: 00000000386aae88 RCX: 000000003e9f1120
      RDX: 0000000000000001 RSI: 0000000000000000 RDI: 0000000000000001
      RBP: 000000000fd73fd8 R08: 00000000386aae88 R09: 0000000000000000
      R10: 0000000000000002 R11: 0000000000000000 R12: 0000000000000000
      R13: ffffc0f040220000 R14: 0000000000000000 R15: 0000000000000000
      FS:  00007f21160ac940(0000) GS:ffff9cf23d500000(0000) knlGS:0000000000000000
      CS:  0008 DS: 0018 ES: 0018 CR0: 0000000080050033
      CR2: 00000000386aae88 CR3: 000000000fd6c004 CR4: 00000000003606e0
      DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      Call Trace:
      Modules linked in:
      CR2: 00000000386aae88
      ---[ end trace a8bfbd202e712834 ]---
    
    Let's fix this by remapping text and rodata individually, and leave the
    gaps mapped read-write.
    
    Fixes: d9e3d2c4f10320 ("efi/x86: Don't map the entire kernel text RW for mixed mode")
    Reported-by: Jiri Slaby <jslaby@suse.cz>
    Tested-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200409130434.6736-10-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e0e2e8136cf5..c5e393f8bb3f 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -202,7 +202,7 @@ virt_to_phys_or_null_size(void *va, unsigned long size)
 
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
-	unsigned long pfn, text, pf;
+	unsigned long pfn, text, pf, rodata;
 	struct page *page;
 	unsigned npages;
 	pgd_t *pgd = efi_mm.pgd;
@@ -256,7 +256,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 	efi_scratch.phys_stack = page_to_phys(page + 1); /* stack grows down */
 
-	npages = (__end_rodata_aligned - _text) >> PAGE_SHIFT;
+	npages = (_etext - _text) >> PAGE_SHIFT;
 	text = __pa(_text);
 	pfn = text >> PAGE_SHIFT;
 
@@ -266,6 +266,14 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 		return 1;
 	}
 
+	npages = (__end_rodata - __start_rodata) >> PAGE_SHIFT;
+	rodata = __pa(__start_rodata);
+	pfn = rodata >> PAGE_SHIFT;
+	if (kernel_map_pages_in_pgd(pgd, pfn, rodata, npages, pf)) {
+		pr_err("Failed to map kernel rodata 1:1\n");
+		return 1;
+	}
+
 	return 0;
 }
 

commit a4b81ccfd4caba017d2b84720b6de4edd16911a0
Author: Gary Lin <glin@suse.com>
Date:   Thu Apr 9 15:04:33 2020 +0200

    efi/x86: Fix the deletion of variables in mixed mode
    
    efi_thunk_set_variable() treated the NULL "data" pointer as an invalid
    parameter, and this broke the deletion of variables in mixed mode.
    This commit fixes the check of data so that the userspace program can
    delete a variable in mixed mode.
    
    Fixes: 8319e9d5ad98ffcc ("efi/x86: Handle by-ref arguments covering multiple pages in mixed mode")
    Signed-off-by: Gary Lin <glin@suse.com>
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200408081606.1504-1-glin@suse.com
    Link: https://lore.kernel.org/r/20200409130434.6736-9-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 211bb9358b73..e0e2e8136cf5 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -638,7 +638,7 @@ efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
-	if (!phys_name || !phys_data)
+	if (!phys_name || (data && !phys_data))
 		status = EFI_INVALID_PARAMETER;
 	else
 		status = efi_thunk(set_variable, phys_name, phys_vendor,
@@ -669,7 +669,7 @@ efi_thunk_set_variable_nonblocking(efi_char16_t *name, efi_guid_t *vendor,
 	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
-	if (!phys_name || !phys_data)
+	if (!phys_name || (data && !phys_data))
 		status = EFI_INVALID_PARAMETER;
 	else
 		status = efi_thunk(set_variable, phys_name, phys_vendor,

commit 6120681bdf1a1c648e8c555704b71e04abe2e899
Merge: 3be5f0d286dc d6c066fda90d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Mar 8 09:57:58 2020 +0100

    Merge branch 'efi/urgent' into efi/core, to pick up fixes
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 8319e9d5ad98ffccd19f35664382c73cea216193
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Feb 21 09:48:48 2020 +0100

    efi/x86: Handle by-ref arguments covering multiple pages in mixed mode
    
    The mixed mode runtime wrappers are fragile when it comes to how the
    memory referred to by its pointer arguments are laid out in memory, due
    to the fact that it translates these addresses to physical addresses that
    the runtime services can dereference when running in 1:1 mode. Since
    vmalloc'ed pages (including the vmap'ed stack) are not contiguous in the
    physical address space, this scheme only works if the referenced memory
    objects do not cross page boundaries.
    
    Currently, the mixed mode runtime service wrappers require that all by-ref
    arguments that live in the vmalloc space have a size that is a power of 2,
    and are aligned to that same value. While this is a sensible way to
    construct an object that is guaranteed not to cross a page boundary, it is
    overly strict when it comes to checking whether a given object violates
    this requirement, as we can simply take the physical address of the first
    and the last byte, and verify that they point into the same physical page.
    
    When this check fails, we emit a WARN(), but then simply proceed with the
    call, which could cause data corruption if the next physical page belongs
    to a mapping that is entirely unrelated.
    
    Given that with vmap'ed stacks, this condition is much more likely to
    trigger, let's relax the condition a bit, but fail the runtime service
    call if it does trigger.
    
    Fixes: f6697df36bdf0bf7 ("x86/efi: Prevent mixed mode boot corruption with CONFIG_VMAP_STACK=y")
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: linux-efi@vger.kernel.org
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200221084849.26878-4-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ae398587f264..d19a2edd63cb 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -180,7 +180,7 @@ void efi_sync_low_kernel_mappings(void)
 static inline phys_addr_t
 virt_to_phys_or_null_size(void *va, unsigned long size)
 {
-	bool bad_size;
+	phys_addr_t pa;
 
 	if (!va)
 		return 0;
@@ -188,16 +188,13 @@ virt_to_phys_or_null_size(void *va, unsigned long size)
 	if (virt_addr_valid(va))
 		return virt_to_phys(va);
 
-	/*
-	 * A fully aligned variable on the stack is guaranteed not to
-	 * cross a page bounary. Try to catch strings on the stack by
-	 * checking that 'size' is a power of two.
-	 */
-	bad_size = size > PAGE_SIZE || !is_power_of_2(size);
+	pa = slow_virt_to_phys(va);
 
-	WARN_ON(!IS_ALIGNED((unsigned long)va, size) || bad_size);
+	/* check if the object crosses a page boundary */
+	if (WARN_ON((pa ^ (pa + size - 1)) & PAGE_MASK))
+		return 0;
 
-	return slow_virt_to_phys(va);
+	return pa;
 }
 
 #define virt_to_phys_or_null(addr)				\
@@ -615,8 +612,11 @@ efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 	phys_attr = virt_to_phys_or_null(attr);
 	phys_data = virt_to_phys_or_null_size(data, *data_size);
 
-	status = efi_thunk(get_variable, phys_name, phys_vendor,
-			   phys_attr, phys_data_size, phys_data);
+	if (!phys_name || (data && !phys_data))
+		status = EFI_INVALID_PARAMETER;
+	else
+		status = efi_thunk(get_variable, phys_name, phys_vendor,
+				   phys_attr, phys_data_size, phys_data);
 
 	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 
@@ -641,9 +641,11 @@ efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
-	/* If data_size is > sizeof(u32) we've got problems */
-	status = efi_thunk(set_variable, phys_name, phys_vendor,
-			   attr, data_size, phys_data);
+	if (!phys_name || !phys_data)
+		status = EFI_INVALID_PARAMETER;
+	else
+		status = efi_thunk(set_variable, phys_name, phys_vendor,
+				   attr, data_size, phys_data);
 
 	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 
@@ -670,9 +672,11 @@ efi_thunk_set_variable_nonblocking(efi_char16_t *name, efi_guid_t *vendor,
 	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
-	/* If data_size is > sizeof(u32) we've got problems */
-	status = efi_thunk(set_variable, phys_name, phys_vendor,
-			   attr, data_size, phys_data);
+	if (!phys_name || !phys_data)
+		status = EFI_INVALID_PARAMETER;
+	else
+		status = efi_thunk(set_variable, phys_name, phys_vendor,
+				   attr, data_size, phys_data);
 
 	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 
@@ -698,8 +702,11 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_name = virt_to_phys_or_null_size(name, *name_size);
 
-	status = efi_thunk(get_next_variable, phys_name_size,
-			   phys_name, phys_vendor);
+	if (!phys_name)
+		status = EFI_INVALID_PARAMETER;
+	else
+		status = efi_thunk(get_next_variable, phys_name_size,
+				   phys_name, phys_vendor);
 
 	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 

commit f80c9f6476db6c0802545aaa44eb9a38e751786a
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Feb 21 09:48:47 2020 +0100

    efi/x86: Remove support for EFI time and counter services in mixed mode
    
    Mixed mode calls at runtime are rather tricky with vmap'ed stacks,
    as we can no longer assume that data passed in by the callers of the
    EFI runtime wrapper routines is contiguous in physical memory.
    
    We need to fix this, but before we do, let's drop the implementations
    of routines that we know are never used on x86, i.e., the RTC related
    ones. Given that UEFI rev2.8 permits any runtime service to return
    EFI_UNSUPPORTED at runtime, let's return that instead.
    
    As get_next_high_mono_count() is never used at all, even on other
    architectures, let's make that return EFI_UNSUPPORTED too.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: linux-efi@vger.kernel.org
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200221084849.26878-3-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 543edfdcd1b9..ae398587f264 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -568,85 +568,25 @@ efi_thunk_set_virtual_address_map(unsigned long memory_map_size,
 
 static efi_status_t efi_thunk_get_time(efi_time_t *tm, efi_time_cap_t *tc)
 {
-	efi_status_t status;
-	u32 phys_tm, phys_tc;
-	unsigned long flags;
-
-	spin_lock(&rtc_lock);
-	spin_lock_irqsave(&efi_runtime_lock, flags);
-
-	phys_tm = virt_to_phys_or_null(tm);
-	phys_tc = virt_to_phys_or_null(tc);
-
-	status = efi_thunk(get_time, phys_tm, phys_tc);
-
-	spin_unlock_irqrestore(&efi_runtime_lock, flags);
-	spin_unlock(&rtc_lock);
-
-	return status;
+	return EFI_UNSUPPORTED;
 }
 
 static efi_status_t efi_thunk_set_time(efi_time_t *tm)
 {
-	efi_status_t status;
-	u32 phys_tm;
-	unsigned long flags;
-
-	spin_lock(&rtc_lock);
-	spin_lock_irqsave(&efi_runtime_lock, flags);
-
-	phys_tm = virt_to_phys_or_null(tm);
-
-	status = efi_thunk(set_time, phys_tm);
-
-	spin_unlock_irqrestore(&efi_runtime_lock, flags);
-	spin_unlock(&rtc_lock);
-
-	return status;
+	return EFI_UNSUPPORTED;
 }
 
 static efi_status_t
 efi_thunk_get_wakeup_time(efi_bool_t *enabled, efi_bool_t *pending,
 			  efi_time_t *tm)
 {
-	efi_status_t status;
-	u32 phys_enabled, phys_pending, phys_tm;
-	unsigned long flags;
-
-	spin_lock(&rtc_lock);
-	spin_lock_irqsave(&efi_runtime_lock, flags);
-
-	phys_enabled = virt_to_phys_or_null(enabled);
-	phys_pending = virt_to_phys_or_null(pending);
-	phys_tm = virt_to_phys_or_null(tm);
-
-	status = efi_thunk(get_wakeup_time, phys_enabled,
-			     phys_pending, phys_tm);
-
-	spin_unlock_irqrestore(&efi_runtime_lock, flags);
-	spin_unlock(&rtc_lock);
-
-	return status;
+	return EFI_UNSUPPORTED;
 }
 
 static efi_status_t
 efi_thunk_set_wakeup_time(efi_bool_t enabled, efi_time_t *tm)
 {
-	efi_status_t status;
-	u32 phys_tm;
-	unsigned long flags;
-
-	spin_lock(&rtc_lock);
-	spin_lock_irqsave(&efi_runtime_lock, flags);
-
-	phys_tm = virt_to_phys_or_null(tm);
-
-	status = efi_thunk(set_wakeup_time, enabled, phys_tm);
-
-	spin_unlock_irqrestore(&efi_runtime_lock, flags);
-	spin_unlock(&rtc_lock);
-
-	return status;
+	return EFI_UNSUPPORTED;
 }
 
 static unsigned long efi_name_size(efi_char16_t *name)
@@ -770,18 +710,7 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 static efi_status_t
 efi_thunk_get_next_high_mono_count(u32 *count)
 {
-	efi_status_t status;
-	u32 phys_count;
-	unsigned long flags;
-
-	spin_lock_irqsave(&efi_runtime_lock, flags);
-
-	phys_count = virt_to_phys_or_null(count);
-	status = efi_thunk(get_next_high_mono_count, phys_count);
-
-	spin_unlock_irqrestore(&efi_runtime_lock, flags);
-
-	return status;
+	return EFI_UNSUPPORTED;
 }
 
 static void

commit 63056e8b5ebf41d52170e9f5ba1fc83d1855278c
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Feb 21 09:48:46 2020 +0100

    efi/x86: Align GUIDs to their size in the mixed mode runtime wrapper
    
    Hans reports that his mixed mode systems running v5.6-rc1 kernels hit
    the WARN_ON() in virt_to_phys_or_null_size(), caused by the fact that
    efi_guid_t objects on the vmap'ed stack happen to be misaligned with
    respect to their sizes. As a quick (i.e., backportable) fix, copy GUID
    pointer arguments to the local stack into a buffer that is naturally
    aligned to its size, so that it is guaranteed to cover only one
    physical page.
    
    Note that on x86, we cannot rely on the stack pointer being aligned
    the way the compiler expects, so we need to allocate an 8-byte aligned
    buffer of sufficient size, and copy the GUID into that buffer at an
    offset that is aligned to 16 bytes.
    
    Fixes: f6697df36bdf0bf7 ("x86/efi: Prevent mixed mode boot corruption with CONFIG_VMAP_STACK=y")
    Reported-by: Hans de Goede <hdegoede@redhat.com>
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Tested-by: Hans de Goede <hdegoede@redhat.com>
    Cc: linux-efi@vger.kernel.org
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200221084849.26878-2-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index fa8506e76bbe..543edfdcd1b9 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -658,6 +658,8 @@ static efi_status_t
 efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 		       u32 *attr, unsigned long *data_size, void *data)
 {
+	u8 buf[24] __aligned(8);
+	efi_guid_t *vnd = PTR_ALIGN((efi_guid_t *)buf, sizeof(*vnd));
 	efi_status_t status;
 	u32 phys_name, phys_vendor, phys_attr;
 	u32 phys_data_size, phys_data;
@@ -665,8 +667,10 @@ efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 
 	spin_lock_irqsave(&efi_runtime_lock, flags);
 
+	*vnd = *vendor;
+
 	phys_data_size = virt_to_phys_or_null(data_size);
-	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
 	phys_attr = virt_to_phys_or_null(attr);
 	phys_data = virt_to_phys_or_null_size(data, *data_size);
@@ -683,14 +687,18 @@ static efi_status_t
 efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 		       u32 attr, unsigned long data_size, void *data)
 {
+	u8 buf[24] __aligned(8);
+	efi_guid_t *vnd = PTR_ALIGN((efi_guid_t *)buf, sizeof(*vnd));
 	u32 phys_name, phys_vendor, phys_data;
 	efi_status_t status;
 	unsigned long flags;
 
 	spin_lock_irqsave(&efi_runtime_lock, flags);
 
+	*vnd = *vendor;
+
 	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
-	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
 	/* If data_size is > sizeof(u32) we've got problems */
@@ -707,6 +715,8 @@ efi_thunk_set_variable_nonblocking(efi_char16_t *name, efi_guid_t *vendor,
 				   u32 attr, unsigned long data_size,
 				   void *data)
 {
+	u8 buf[24] __aligned(8);
+	efi_guid_t *vnd = PTR_ALIGN((efi_guid_t *)buf, sizeof(*vnd));
 	u32 phys_name, phys_vendor, phys_data;
 	efi_status_t status;
 	unsigned long flags;
@@ -714,8 +724,10 @@ efi_thunk_set_variable_nonblocking(efi_char16_t *name, efi_guid_t *vendor,
 	if (!spin_trylock_irqsave(&efi_runtime_lock, flags))
 		return EFI_NOT_READY;
 
+	*vnd = *vendor;
+
 	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
-	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
 	/* If data_size is > sizeof(u32) we've got problems */
@@ -732,14 +744,18 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 			    efi_char16_t *name,
 			    efi_guid_t *vendor)
 {
+	u8 buf[24] __aligned(8);
+	efi_guid_t *vnd = PTR_ALIGN((efi_guid_t *)buf, sizeof(*vnd));
 	efi_status_t status;
 	u32 phys_name_size, phys_name, phys_vendor;
 	unsigned long flags;
 
 	spin_lock_irqsave(&efi_runtime_lock, flags);
 
+	*vnd = *vendor;
+
 	phys_name_size = virt_to_phys_or_null(name_size);
-	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_vendor = virt_to_phys_or_null(vnd);
 	phys_name = virt_to_phys_or_null_size(name, *name_size);
 
 	status = efi_thunk(get_next_variable, phys_name_size,
@@ -747,6 +763,7 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 
 	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 
+	*vendor = *vnd;
 	return status;
 }
 

commit 59f2a619a2db86111e8bb30f349aebff6eb75baa
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Tue Jan 21 09:44:43 2020 +0100

    efi: Add 'runtime' pointer to struct efi
    
    Instead of going through the EFI system table each time, just copy the
    runtime services table pointer into struct efi directly. This is the
    last use of the system table pointer in struct efi, allowing us to
    drop it in a future patch, along with a fair amount of quirky handling
    of the translated address.
    
    Note that usually, the runtime services pointer changes value during
    the call to SetVirtualAddressMap(), so grab the updated value as soon
    as that call returns. (Mixed mode uses a 1:1 mapping, and kexec boot
    enters with the updated address in the system table, so in those cases,
    we don't need to do anything here)
    
    Tested-by: Tony Luck <tony.luck@intel.com> # arch/ia64
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index fa8506e76bbe..f78f7da666fb 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -500,12 +500,9 @@ static DEFINE_SPINLOCK(efi_runtime_lock);
  */
 #define __efi_thunk(func, ...)						\
 ({									\
-	efi_runtime_services_32_t *__rt;				\
 	unsigned short __ds, __es;					\
 	efi_status_t ____s;						\
 									\
-	__rt = (void *)(unsigned long)efi.systab->mixed_mode.runtime;	\
-									\
 	savesegment(ds, __ds);						\
 	savesegment(es, __es);						\
 									\
@@ -513,7 +510,7 @@ static DEFINE_SPINLOCK(efi_runtime_lock);
 	loadsegment(ds, __KERNEL_DS);					\
 	loadsegment(es, __KERNEL_DS);					\
 									\
-	____s = efi64_thunk(__rt->func, __VA_ARGS__);			\
+	____s = efi64_thunk(efi.runtime->mixed_mode.func, __VA_ARGS__);	\
 									\
 	loadsegment(ds, __ds);						\
 	loadsegment(es, __es);						\
@@ -886,8 +883,10 @@ efi_status_t __init __no_sanitize_address
 efi_set_virtual_address_map(unsigned long memory_map_size,
 			    unsigned long descriptor_size,
 			    u32 descriptor_version,
-			    efi_memory_desc_t *virtual_map)
+			    efi_memory_desc_t *virtual_map,
+			    unsigned long systab_phys)
 {
+	const efi_system_table_t *systab = (efi_system_table_t *)systab_phys;
 	efi_status_t status;
 	unsigned long flags;
 	pgd_t *save_pgd = NULL;
@@ -910,13 +909,16 @@ efi_set_virtual_address_map(unsigned long memory_map_size,
 
 	/* Disable interrupts around EFI calls: */
 	local_irq_save(flags);
-	status = efi_call(efi.systab->runtime->set_virtual_address_map,
+	status = efi_call(efi.runtime->set_virtual_address_map,
 			  memory_map_size, descriptor_size,
 			  descriptor_version, virtual_map);
 	local_irq_restore(flags);
 
 	kernel_fpu_end();
 
+	/* grab the virtually remapped EFI runtime services table pointer */
+	efi.runtime = READ_ONCE(systab->runtime);
+
 	if (save_pgd)
 		efi_uv1_memmap_phys_epilog(save_pgd);
 	else

commit e455248d5ee9c8a12469d21cfa92c8432be4a4fd
Author: Steven Price <steven.price@arm.com>
Date:   Mon Feb 3 17:36:11 2020 -0800

    x86: mm+efi: convert ptdump_walk_pgd_level() to take a mm_struct
    
    To enable x86 to use the generic walk_page_range() function, the callers
    of ptdump_walk_pgd_level() need to pass an mm_struct rather than the raw
    pgd_t pointer.  Luckily since commit 7e904a91bf60 ("efi: Use efi_mm in x86
    as well as ARM") we now have an mm_struct for EFI on x86.
    
    Link: http://lkml.kernel.org/r/20191218162402.45610-18-steven.price@arm.com
    Signed-off-by: Steven Price <steven.price@arm.com>
    Cc: Albert Ou <aou@eecs.berkeley.edu>
    Cc: Alexandre Ghiti <alex@ghiti.fr>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: James Morse <james.morse@arm.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: "Liang, Kan" <kan.liang@linux.intel.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vasily Gorbik <gor@linux.ibm.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Zong Li <zong.li@sifive.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e2accfe636bd..fa8506e76bbe 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -471,9 +471,9 @@ void __init efi_dump_pagetable(void)
 {
 #ifdef CONFIG_EFI_PGT_DUMP
 	if (efi_have_uv1_memmap())
-		ptdump_walk_pgd_level(NULL, swapper_pg_dir);
+		ptdump_walk_pgd_level(NULL, &init_mm);
 	else
-		ptdump_walk_pgd_level(NULL, efi_mm.pgd);
+		ptdump_walk_pgd_level(NULL, &efi_mm);
 #endif
 }
 

commit 3cc028619e284188cdde652631e1c3c5a83692b9
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Sat Jan 18 17:57:03 2020 +0100

    efi/x86: avoid KASAN false positives when accessing the 1: 1 mapping
    
    When installing the EFI virtual address map during early boot, we
    access the EFI system table to retrieve the 1:1 mapped address of
    the SetVirtualAddressMap() EFI runtime service. This memory is not
    known to KASAN, so on KASAN enabled builds, this may result in a
    splat like
    
      ==================================================================
      BUG: KASAN: user-memory-access in efi_set_virtual_address_map+0x141/0x354
      Read of size 4 at addr 000000003fbeef38 by task swapper/0/0
    
      CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.5.0-rc5+ #758
      Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015
      Call Trace:
       dump_stack+0x8b/0xbb
       ? efi_set_virtual_address_map+0x141/0x354
       ? efi_set_virtual_address_map+0x141/0x354
       __kasan_report+0x176/0x192
       ? efi_set_virtual_address_map+0x141/0x354
       kasan_report+0xe/0x20
       efi_set_virtual_address_map+0x141/0x354
       ? efi_thunk_runtime_setup+0x148/0x148
       ? __inc_numa_state+0x19/0x90
       ? memcpy+0x34/0x50
       efi_enter_virtual_mode+0x5fd/0x67d
       start_kernel+0x5cd/0x682
       ? mem_encrypt_init+0x6/0x6
       ? x86_family+0x5/0x20
       ? load_ucode_bsp+0x46/0x154
       secondary_startup_64+0xa4/0xb0
      ==================================================================
    
    Since this code runs only a single time during early boot, let's annotate
    it as __no_sanitize_address so KASAN disregards it entirely.
    
    Fixes: 698294704573 ("efi/x86: Split SetVirtualAddresMap() wrappers into ...")
    Reported-by: Qian Cai <cai@lca.pw>
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 8d1869ff1033..e2accfe636bd 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -543,7 +543,7 @@ static DEFINE_SPINLOCK(efi_runtime_lock);
 	__s;								\
 })
 
-static efi_status_t __init
+static efi_status_t __init __no_sanitize_address
 efi_thunk_set_virtual_address_map(unsigned long memory_map_size,
 				  unsigned long descriptor_size,
 				  u32 descriptor_version,
@@ -882,10 +882,11 @@ void __init efi_thunk_runtime_setup(void)
 	efi.query_capsule_caps = efi_thunk_query_capsule_caps;
 }
 
-efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
-						unsigned long descriptor_size,
-						u32 descriptor_version,
-						efi_memory_desc_t *virtual_map)
+efi_status_t __init __no_sanitize_address
+efi_set_virtual_address_map(unsigned long memory_map_size,
+			    unsigned long descriptor_size,
+			    u32 descriptor_version,
+			    efi_memory_desc_t *virtual_map)
 {
 	efi_status_t status;
 	unsigned long flags;

commit 1f299fad1e312947c974c6a1d8a3a484f27a6111
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Mon Jan 13 18:22:39 2020 +0100

    efi/x86: Limit EFI old memory map to SGI UV machines
    
    We carry a quirk in the x86 EFI code to switch back to an older
    method of mapping the EFI runtime services memory regions, because
    it was deemed risky at the time to implement a new method without
    providing a fallback to the old method in case problems arose.
    
    Such problems did arise, but they appear to be limited to SGI UV1
    machines, and so these are the only ones for which the fallback gets
    enabled automatically (via a DMI quirk). The fallback can be enabled
    manually as well, by passing efi=old_map, but there is very little
    evidence that suggests that this is something that is being relied
    upon in the field.
    
    Given that UV1 support is not enabled by default by the distros
    (Ubuntu, Fedora), there is no point in carrying this fallback code
    all the time if there are no other users. So let's move it into the
    UV support code, and document that efi=old_map now requires this
    support code to be enabled.
    
    Note that efi=old_map has been used in the past on other SGI UV
    machines to work around kernel regressions in production, so we
    keep the option to enable it by hand, but only if the kernel was
    built with UV support.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200113172245.27925-8-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 3eb23966e30a..8d1869ff1033 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -57,134 +57,6 @@ static u64 efi_va = EFI_VA_START;
 
 struct efi_scratch efi_scratch;
 
-static void __init early_code_mapping_set_exec(int executable)
-{
-	efi_memory_desc_t *md;
-
-	if (!(__supported_pte_mask & _PAGE_NX))
-		return;
-
-	/* Make EFI service code area executable */
-	for_each_efi_memory_desc(md) {
-		if (md->type == EFI_RUNTIME_SERVICES_CODE ||
-		    md->type == EFI_BOOT_SERVICES_CODE)
-			efi_set_executable(md, executable);
-	}
-}
-
-static void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd);
-
-static pgd_t * __init efi_old_memmap_phys_prolog(void)
-{
-	unsigned long vaddr, addr_pgd, addr_p4d, addr_pud;
-	pgd_t *save_pgd, *pgd_k, *pgd_efi;
-	p4d_t *p4d, *p4d_k, *p4d_efi;
-	pud_t *pud;
-
-	int pgd;
-	int n_pgds, i, j;
-
-	early_code_mapping_set_exec(1);
-
-	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
-	save_pgd = kmalloc_array(n_pgds, sizeof(*save_pgd), GFP_KERNEL);
-	if (!save_pgd)
-		return NULL;
-
-	/*
-	 * Build 1:1 identity mapping for efi=old_map usage. Note that
-	 * PAGE_OFFSET is PGDIR_SIZE aligned when KASLR is disabled, while
-	 * it is PUD_SIZE ALIGNED with KASLR enabled. So for a given physical
-	 * address X, the pud_index(X) != pud_index(__va(X)), we can only copy
-	 * PUD entry of __va(X) to fill in pud entry of X to build 1:1 mapping.
-	 * This means here we can only reuse the PMD tables of the direct mapping.
-	 */
-	for (pgd = 0; pgd < n_pgds; pgd++) {
-		addr_pgd = (unsigned long)(pgd * PGDIR_SIZE);
-		vaddr = (unsigned long)__va(pgd * PGDIR_SIZE);
-		pgd_efi = pgd_offset_k(addr_pgd);
-		save_pgd[pgd] = *pgd_efi;
-
-		p4d = p4d_alloc(&init_mm, pgd_efi, addr_pgd);
-		if (!p4d) {
-			pr_err("Failed to allocate p4d table!\n");
-			goto out;
-		}
-
-		for (i = 0; i < PTRS_PER_P4D; i++) {
-			addr_p4d = addr_pgd + i * P4D_SIZE;
-			p4d_efi = p4d + p4d_index(addr_p4d);
-
-			pud = pud_alloc(&init_mm, p4d_efi, addr_p4d);
-			if (!pud) {
-				pr_err("Failed to allocate pud table!\n");
-				goto out;
-			}
-
-			for (j = 0; j < PTRS_PER_PUD; j++) {
-				addr_pud = addr_p4d + j * PUD_SIZE;
-
-				if (addr_pud > (max_pfn << PAGE_SHIFT))
-					break;
-
-				vaddr = (unsigned long)__va(addr_pud);
-
-				pgd_k = pgd_offset_k(vaddr);
-				p4d_k = p4d_offset(pgd_k, vaddr);
-				pud[j] = *pud_offset(p4d_k, vaddr);
-			}
-		}
-		pgd_offset_k(pgd * PGDIR_SIZE)->pgd &= ~_PAGE_NX;
-	}
-
-	__flush_tlb_all();
-	return save_pgd;
-out:
-	efi_old_memmap_phys_epilog(save_pgd);
-	return NULL;
-}
-
-static void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd)
-{
-	/*
-	 * After the lock is released, the original page table is restored.
-	 */
-	int pgd_idx, i;
-	int nr_pgds;
-	pgd_t *pgd;
-	p4d_t *p4d;
-	pud_t *pud;
-
-	nr_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
-
-	for (pgd_idx = 0; pgd_idx < nr_pgds; pgd_idx++) {
-		pgd = pgd_offset_k(pgd_idx * PGDIR_SIZE);
-		set_pgd(pgd_offset_k(pgd_idx * PGDIR_SIZE), save_pgd[pgd_idx]);
-
-		if (!pgd_present(*pgd))
-			continue;
-
-		for (i = 0; i < PTRS_PER_P4D; i++) {
-			p4d = p4d_offset(pgd,
-					 pgd_idx * PGDIR_SIZE + i * P4D_SIZE);
-
-			if (!p4d_present(*p4d))
-				continue;
-
-			pud = (pud_t *)p4d_page_vaddr(*p4d);
-			pud_free(&init_mm, pud);
-		}
-
-		p4d = (p4d_t *)pgd_page_vaddr(*pgd);
-		p4d_free(&init_mm, p4d);
-	}
-
-	kfree(save_pgd);
-
-	__flush_tlb_all();
-	early_code_mapping_set_exec(0);
-}
-
 EXPORT_SYMBOL_GPL(efi_mm);
 
 /*
@@ -203,7 +75,7 @@ int __init efi_alloc_page_tables(void)
 	pud_t *pud;
 	gfp_t gfp_mask;
 
-	if (efi_enabled(EFI_OLD_MEMMAP))
+	if (efi_have_uv1_memmap())
 		return 0;
 
 	gfp_mask = GFP_KERNEL | __GFP_ZERO;
@@ -244,7 +116,7 @@ void efi_sync_low_kernel_mappings(void)
 	pud_t *pud_k, *pud_efi;
 	pgd_t *efi_pgd = efi_mm.pgd;
 
-	if (efi_enabled(EFI_OLD_MEMMAP))
+	if (efi_have_uv1_memmap())
 		return;
 
 	/*
@@ -338,7 +210,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	unsigned npages;
 	pgd_t *pgd = efi_mm.pgd;
 
-	if (efi_enabled(EFI_OLD_MEMMAP))
+	if (efi_have_uv1_memmap())
 		return 0;
 
 	/*
@@ -439,7 +311,7 @@ void __init efi_map_region(efi_memory_desc_t *md)
 	unsigned long size = md->num_pages << PAGE_SHIFT;
 	u64 pa = md->phys_addr;
 
-	if (efi_enabled(EFI_OLD_MEMMAP))
+	if (efi_have_uv1_memmap())
 		return old_map_region(md);
 
 	/*
@@ -496,26 +368,6 @@ void __init efi_map_region_fixed(efi_memory_desc_t *md)
 	__map_region(md, md->virt_addr);
 }
 
-void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
-				 u32 type, u64 attribute)
-{
-	unsigned long last_map_pfn;
-
-	if (type == EFI_MEMORY_MAPPED_IO)
-		return ioremap(phys_addr, size);
-
-	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
-	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {
-		unsigned long top = last_map_pfn << PAGE_SHIFT;
-		efi_ioremap(top, size - (top - phys_addr), type, attribute);
-	}
-
-	if (!(attribute & EFI_MEMORY_WB))
-		efi_memory_uc((u64)(unsigned long)__va(phys_addr), size);
-
-	return (void __iomem *)__va(phys_addr);
-}
-
 void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 {
 	efi_setup = phys_addr + sizeof(struct setup_data);
@@ -564,7 +416,7 @@ void __init efi_runtime_update_mappings(void)
 {
 	efi_memory_desc_t *md;
 
-	if (efi_enabled(EFI_OLD_MEMMAP)) {
+	if (efi_have_uv1_memmap()) {
 		if (__supported_pte_mask & _PAGE_NX)
 			runtime_code_page_mkexec();
 		return;
@@ -618,7 +470,7 @@ void __init efi_runtime_update_mappings(void)
 void __init efi_dump_pagetable(void)
 {
 #ifdef CONFIG_EFI_PGT_DUMP
-	if (efi_enabled(EFI_OLD_MEMMAP))
+	if (efi_have_uv1_memmap())
 		ptdump_walk_pgd_level(NULL, swapper_pg_dir);
 	else
 		ptdump_walk_pgd_level(NULL, efi_mm.pgd);
@@ -1045,8 +897,8 @@ efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 							 descriptor_version,
 							 virtual_map);
 
-	if (efi_enabled(EFI_OLD_MEMMAP)) {
-		save_pgd = efi_old_memmap_phys_prolog();
+	if (efi_have_uv1_memmap()) {
+		save_pgd = efi_uv1_memmap_phys_prolog();
 		if (!save_pgd)
 			return EFI_ABORTED;
 	} else {
@@ -1065,7 +917,7 @@ efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 	kernel_fpu_end();
 
 	if (save_pgd)
-		efi_old_memmap_phys_epilog(save_pgd);
+		efi_uv1_memmap_phys_epilog(save_pgd);
 	else
 		efi_switch_mm(efi_scratch.prev_mm);
 

commit 97bb9cdc32108036170d9d0d208257168f80d9e9
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Mon Jan 13 18:22:38 2020 +0100

    efi/x86: Avoid RWX mappings for all of DRAM
    
    The EFI code creates RWX mappings for all memory regions that are
    occupied after the stub completes, and in the mixed mode case, it
    even creates RWX mappings for all of the remaining DRAM as well.
    
    Let's try to avoid this, by setting the NX bit for all memory
    regions except the ones that are marked as EFI runtime services
    code [which means text+rodata+data in practice, so we cannot mark
    them read-only right away]. For cases of buggy firmware where boot
    services code is called during SetVirtualAddressMap(), map those
    regions with exec permissions as well - they will be unmapped in
    efi_free_boot_services().
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200113172245.27925-7-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 6ec58ff60b56..3eb23966e30a 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -365,10 +365,6 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * as trim_bios_range() will reserve the first page and isolate it away
 	 * from memory allocators anyway.
 	 */
-	pf = _PAGE_RW;
-	if (sev_active())
-		pf |= _PAGE_ENC;
-
 	if (kernel_map_pages_in_pgd(pgd, 0x0, 0x0, 1, pf)) {
 		pr_err("Failed to create 1:1 mapping for the first page!\n");
 		return 1;
@@ -410,6 +406,22 @@ static void __init __map_region(efi_memory_desc_t *md, u64 va)
 	unsigned long pfn;
 	pgd_t *pgd = efi_mm.pgd;
 
+	/*
+	 * EFI_RUNTIME_SERVICES_CODE regions typically cover PE/COFF
+	 * executable images in memory that consist of both R-X and
+	 * RW- sections, so we cannot apply read-only or non-exec
+	 * permissions just yet. However, modern EFI systems provide
+	 * a memory attributes table that describes those sections
+	 * with the appropriate restricted permissions, which are
+	 * applied in efi_runtime_update_mappings() below. All other
+	 * regions can be mapped non-executable at this point, with
+	 * the exception of boot services code regions, but those will
+	 * be unmapped again entirely in efi_free_boot_services().
+	 */
+	if (md->type != EFI_BOOT_SERVICES_CODE &&
+	    md->type != EFI_RUNTIME_SERVICES_CODE)
+		flags |= _PAGE_NX;
+
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
 

commit d9e3d2c4f103200d87f2c243a84c1fd3b3bfea8c
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Mon Jan 13 18:22:37 2020 +0100

    efi/x86: Don't map the entire kernel text RW for mixed mode
    
    The mixed mode thunking routine requires a part of it to be
    mapped 1:1, and for this reason, we currently map the entire
    kernel .text read/write in the EFI page tables, which is bad.
    
    In fact, the kernel_map_pages_in_pgd() invocation that installs
    this mapping is entirely redundant, since all of DRAM is already
    1:1 mapped read/write in the EFI page tables when we reach this
    point, which means that .rodata is mapped read-write as well.
    
    So let's remap both .text and .rodata read-only in the EFI
    page tables.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200113172245.27925-6-ardb@kernel.org

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c13fa2150976..6ec58ff60b56 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -391,11 +391,11 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 	efi_scratch.phys_stack = page_to_phys(page + 1); /* stack grows down */
 
-	npages = (_etext - _text) >> PAGE_SHIFT;
+	npages = (__end_rodata_aligned - _text) >> PAGE_SHIFT;
 	text = __pa(_text);
 	pfn = text >> PAGE_SHIFT;
 
-	pf = _PAGE_RW | _PAGE_ENC;
+	pf = _PAGE_ENC;
 	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, pf)) {
 		pr_err("Failed to map kernel text 1:1\n");
 		return 1;

commit e2d68a955e49d61fd0384f23e92058dc9b79be5e
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Jan 3 12:39:46 2020 +0100

    efi/x86: Don't panic or BUG() on non-critical error conditions
    
    The logic in __efi_enter_virtual_mode() does a number of steps in
    sequence, all of which may fail in one way or the other. In most
    cases, we simply print an error and disable EFI runtime services
    support, but in some cases, we BUG() or panic() and bring down the
    system when encountering conditions that we could easily handle in
    the same way.
    
    While at it, replace a pointless page-to-virt-phys conversion with
    one that goes straight from struct page to physical.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Matthew Garrett <mjg59@google.com>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200103113953.9571-14-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 910e9ec03b09..c13fa2150976 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -384,11 +384,12 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 		return 0;
 
 	page = alloc_page(GFP_KERNEL|__GFP_DMA32);
-	if (!page)
-		panic("Unable to allocate EFI runtime stack < 4GB\n");
+	if (!page) {
+		pr_err("Unable to allocate EFI runtime stack < 4GB\n");
+		return 1;
+	}
 
-	efi_scratch.phys_stack = virt_to_phys(page_address(page));
-	efi_scratch.phys_stack += PAGE_SIZE; /* stack grows down */
+	efi_scratch.phys_stack = page_to_phys(page + 1); /* stack grows down */
 
 	npages = (_etext - _text) >> PAGE_SHIFT;
 	text = __pa(_text);

commit ea5e1919b44f09fce72d919fbb87f9611fc700a6
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Jan 3 12:39:43 2020 +0100

    efi/x86: Simplify mixed mode call wrapper
    
    Calling 32-bit EFI runtime services from a 64-bit OS involves
    switching back to the flat mapping with a stack carved out of
    memory that is 32-bit addressable.
    
    There is no need to actually execute the 64-bit part of this
    routine from the flat mapping as well, as long as the entry
    and return address fit in 32 bits. There is also no need to
    preserve part of the calling context in global variables: we
    can simply push the old stack pointer value to the new stack,
    and keep the return address from the code32 section in EBX.
    
    While at it, move the conditional check whether to invoke
    the mixed mode version of SetVirtualAddressMap() into the
    64-bit implementation of the wrapper routine.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Matthew Garrett <mjg59@google.com>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200103113953.9571-11-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 03565dad0c4b..910e9ec03b09 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -626,61 +626,74 @@ void efi_switch_mm(struct mm_struct *mm)
 	switch_mm(efi_scratch.prev_mm, mm, NULL);
 }
 
-#ifdef CONFIG_EFI_MIXED
 static DEFINE_SPINLOCK(efi_runtime_lock);
 
-#define runtime_service32(func)						 \
-({									 \
-	u32 table = (u32)(unsigned long)efi.systab;			 \
-	u32 *rt, *___f;							 \
-									 \
-	rt = (u32 *)(table + offsetof(efi_system_table_32_t, runtime));	 \
-	___f = (u32 *)(*rt + offsetof(efi_runtime_services_32_t, func)); \
-	*___f;								 \
+/*
+ * DS and ES contain user values.  We need to save them.
+ * The 32-bit EFI code needs a valid DS, ES, and SS.  There's no
+ * need to save the old SS: __KERNEL_DS is always acceptable.
+ */
+#define __efi_thunk(func, ...)						\
+({									\
+	efi_runtime_services_32_t *__rt;				\
+	unsigned short __ds, __es;					\
+	efi_status_t ____s;						\
+									\
+	__rt = (void *)(unsigned long)efi.systab->mixed_mode.runtime;	\
+									\
+	savesegment(ds, __ds);						\
+	savesegment(es, __es);						\
+									\
+	loadsegment(ss, __KERNEL_DS);					\
+	loadsegment(ds, __KERNEL_DS);					\
+	loadsegment(es, __KERNEL_DS);					\
+									\
+	____s = efi64_thunk(__rt->func, __VA_ARGS__);			\
+									\
+	loadsegment(ds, __ds);						\
+	loadsegment(es, __es);						\
+									\
+	____s ^= (____s & BIT(31)) | (____s & BIT_ULL(31)) << 32;	\
+	____s;								\
 })
 
 /*
  * Switch to the EFI page tables early so that we can access the 1:1
  * runtime services mappings which are not mapped in any other page
- * tables. This function must be called before runtime_service32().
+ * tables.
  *
  * Also, disable interrupts because the IDT points to 64-bit handlers,
  * which aren't going to function correctly when we switch to 32-bit.
  */
-#define efi_thunk(f, ...)						\
+#define efi_thunk(func...)						\
 ({									\
 	efi_status_t __s;						\
-	u32 __func;							\
 									\
 	arch_efi_call_virt_setup();					\
 									\
-	__func = runtime_service32(f);					\
-	__s = efi64_thunk(__func, __VA_ARGS__);				\
+	__s = __efi_thunk(func);					\
 									\
 	arch_efi_call_virt_teardown();					\
 									\
 	__s;								\
 })
 
-efi_status_t efi_thunk_set_virtual_address_map(
-	void *phys_set_virtual_address_map,
-	unsigned long memory_map_size,
-	unsigned long descriptor_size,
-	u32 descriptor_version,
-	efi_memory_desc_t *virtual_map)
+static efi_status_t __init
+efi_thunk_set_virtual_address_map(unsigned long memory_map_size,
+				  unsigned long descriptor_size,
+				  u32 descriptor_version,
+				  efi_memory_desc_t *virtual_map)
 {
 	efi_status_t status;
 	unsigned long flags;
-	u32 func;
 
 	efi_sync_low_kernel_mappings();
 	local_irq_save(flags);
 
 	efi_switch_mm(&efi_mm);
 
-	func = (u32)(unsigned long)phys_set_virtual_address_map;
-	status = efi64_thunk(func, memory_map_size, descriptor_size,
-			     descriptor_version, virtual_map);
+	status = __efi_thunk(set_virtual_address_map, memory_map_size,
+			     descriptor_size, descriptor_version, virtual_map);
 
 	efi_switch_mm(efi_scratch.prev_mm);
 	local_irq_restore(flags);
@@ -983,8 +996,11 @@ efi_thunk_query_capsule_caps(efi_capsule_header_t **capsules,
 	return EFI_UNSUPPORTED;
 }
 
-void efi_thunk_runtime_setup(void)
+void __init efi_thunk_runtime_setup(void)
 {
+	if (!IS_ENABLED(CONFIG_EFI_MIXED))
+		return;
+
 	efi.get_time = efi_thunk_get_time;
 	efi.set_time = efi_thunk_set_time;
 	efi.get_wakeup_time = efi_thunk_get_wakeup_time;
@@ -1000,7 +1016,6 @@ void efi_thunk_runtime_setup(void)
 	efi.update_capsule = efi_thunk_update_capsule;
 	efi.query_capsule_caps = efi_thunk_query_capsule_caps;
 }
-#endif /* CONFIG_EFI_MIXED */
 
 efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 						unsigned long descriptor_size,
@@ -1011,6 +1026,12 @@ efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 	unsigned long flags;
 	pgd_t *save_pgd = NULL;
 
+	if (efi_is_mixed())
+		return efi_thunk_set_virtual_address_map(memory_map_size,
+							 descriptor_size,
+							 descriptor_version,
+							 virtual_map);
+
 	if (efi_enabled(EFI_OLD_MEMMAP)) {
 		save_pgd = efi_old_memmap_phys_prolog();
 		if (!save_pgd)

commit e5f930fe8dafd2055220c95958926af16ee20713
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Jan 3 12:39:42 2020 +0100

    efi/x86: Simplify 64-bit EFI firmware call wrapper
    
    The efi_call() wrapper used to invoke EFI runtime services serves
    a number of purposes:
    - realign the stack to 16 bytes
    - preserve FP and CR0 register state
    - translate from SysV to MS calling convention.
    
    Preserving CR0.TS is no longer necessary in Linux, and preserving the
    FP register state is also redundant in most cases, since efi_call() is
    almost always used from within the scope of a pair of kernel_fpu_begin()/
    kernel_fpu_end() calls, with the exception of the early call to
    SetVirtualAddressMap() and the SGI UV support code.
    
    So let's add a pair of kernel_fpu_begin()/_end() calls there as well,
    and remove the unnecessary code from the assembly implementation of
    efi_call(), and only keep the pieces that deal with the stack
    alignment and the ABI translation.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Matthew Garrett <mjg59@google.com>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200103113953.9571-10-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a7f11d1ff7c4..03565dad0c4b 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -1019,6 +1019,8 @@ efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 		efi_switch_mm(&efi_mm);
 	}
 
+	kernel_fpu_begin();
+
 	/* Disable interrupts around EFI calls: */
 	local_irq_save(flags);
 	status = efi_call(efi.systab->runtime->set_virtual_address_map,
@@ -1026,6 +1028,7 @@ efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
 			  descriptor_version, virtual_map);
 	local_irq_restore(flags);
 
+	kernel_fpu_end();
 
 	if (save_pgd)
 		efi_old_memmap_phys_epilog(save_pgd);

commit 6982947045734480b8b57521e8068073fe36bd14
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Jan 3 12:39:40 2020 +0100

    efi/x86: Split SetVirtualAddresMap() wrappers into 32 and 64 bit versions
    
    Split the phys_efi_set_virtual_address_map() routine into 32 and 64 bit
    versions, so we can simplify them individually in subsequent patches.
    
    There is very little overlap between the logic anyway, and this has
    already been factored out in prolog/epilog routines which are completely
    different between 32 bit and 64 bit. So let's take it one step further,
    and get rid of the overlap completely.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Matthew Garrett <mjg59@google.com>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200103113953.9571-8-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a72bbabbc595..a7f11d1ff7c4 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -72,9 +72,9 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
-void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd);
+static void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd);
 
-pgd_t * __init efi_old_memmap_phys_prolog(void)
+static pgd_t * __init efi_old_memmap_phys_prolog(void)
 {
 	unsigned long vaddr, addr_pgd, addr_p4d, addr_pud;
 	pgd_t *save_pgd, *pgd_k, *pgd_efi;
@@ -144,7 +144,7 @@ pgd_t * __init efi_old_memmap_phys_prolog(void)
 	return NULL;
 }
 
-void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd)
+static void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd)
 {
 	/*
 	 * After the lock is released, the original page table is restored.
@@ -185,23 +185,6 @@ void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd)
 	early_code_mapping_set_exec(0);
 }
 
-pgd_t * __init efi_call_phys_prolog(void)
-{
-	if (efi_enabled(EFI_OLD_MEMMAP))
-		return efi_old_memmap_phys_prolog();
-
-	efi_switch_mm(&efi_mm);
-	return efi_mm.pgd;
-}
-
-void __init efi_call_phys_epilog(pgd_t *save_pgd)
-{
-	if (efi_enabled(EFI_OLD_MEMMAP))
-		efi_old_memmap_phys_epilog(save_pgd);
-	else
-		efi_switch_mm(efi_scratch.prev_mm);
-}
-
 EXPORT_SYMBOL_GPL(efi_mm);
 
 /*
@@ -1018,3 +1001,36 @@ void efi_thunk_runtime_setup(void)
 	efi.query_capsule_caps = efi_thunk_query_capsule_caps;
 }
 #endif /* CONFIG_EFI_MIXED */
+
+efi_status_t __init efi_set_virtual_address_map(unsigned long memory_map_size,
+						unsigned long descriptor_size,
+						u32 descriptor_version,
+						efi_memory_desc_t *virtual_map)
+{
+	efi_status_t status;
+	unsigned long flags;
+	pgd_t *save_pgd = NULL;
+
+	if (efi_enabled(EFI_OLD_MEMMAP)) {
+		save_pgd = efi_old_memmap_phys_prolog();
+		if (!save_pgd)
+			return EFI_ABORTED;
+	} else {
+		efi_switch_mm(&efi_mm);
+	}
+
+	/* Disable interrupts around EFI calls: */
+	local_irq_save(flags);
+	status = efi_call(efi.systab->runtime->set_virtual_address_map,
+			  memory_map_size, descriptor_size,
+			  descriptor_version, virtual_map);
+	local_irq_restore(flags);
+
+
+	if (save_pgd)
+		efi_old_memmap_phys_epilog(save_pgd);
+	else
+		efi_switch_mm(efi_scratch.prev_mm);
+
+	return status;
+}

commit 98dd0e3a0ceebd594942777e4aca9791177e3f2b
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Fri Jan 3 12:39:39 2020 +0100

    efi/x86: Split off some old memmap handling into separate routines
    
    In a subsequent patch, we will fold the prolog/epilog routines that are
    part of the support code to call SetVirtualAddressMap() with a 1:1
    mapping into the callers. However, the 64-bit version mostly consists
    of ugly mapping code that is only used when efi=old_map is in effect,
    which is extremely rare. So let's move this code out of the way so it
    does not clutter the common code.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Matthew Garrett <mjg59@google.com>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20200103113953.9571-7-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 03c2ed3c645c..a72bbabbc595 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -72,7 +72,9 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
-pgd_t * __init efi_call_phys_prolog(void)
+void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd);
+
+pgd_t * __init efi_old_memmap_phys_prolog(void)
 {
 	unsigned long vaddr, addr_pgd, addr_p4d, addr_pud;
 	pgd_t *save_pgd, *pgd_k, *pgd_efi;
@@ -82,11 +84,6 @@ pgd_t * __init efi_call_phys_prolog(void)
 	int pgd;
 	int n_pgds, i, j;
 
-	if (!efi_enabled(EFI_OLD_MEMMAP)) {
-		efi_switch_mm(&efi_mm);
-		return efi_mm.pgd;
-	}
-
 	early_code_mapping_set_exec(1);
 
 	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
@@ -143,11 +140,11 @@ pgd_t * __init efi_call_phys_prolog(void)
 	__flush_tlb_all();
 	return save_pgd;
 out:
-	efi_call_phys_epilog(save_pgd);
+	efi_old_memmap_phys_epilog(save_pgd);
 	return NULL;
 }
 
-void __init efi_call_phys_epilog(pgd_t *save_pgd)
+void __init efi_old_memmap_phys_epilog(pgd_t *save_pgd)
 {
 	/*
 	 * After the lock is released, the original page table is restored.
@@ -158,11 +155,6 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	p4d_t *p4d;
 	pud_t *pud;
 
-	if (!efi_enabled(EFI_OLD_MEMMAP)) {
-		efi_switch_mm(efi_scratch.prev_mm);
-		return;
-	}
-
 	nr_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
 
 	for (pgd_idx = 0; pgd_idx < nr_pgds; pgd_idx++) {
@@ -193,6 +185,23 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	early_code_mapping_set_exec(0);
 }
 
+pgd_t * __init efi_call_phys_prolog(void)
+{
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return efi_old_memmap_phys_prolog();
+
+	efi_switch_mm(&efi_mm);
+	return efi_mm.pgd;
+}
+
+void __init efi_call_phys_epilog(pgd_t *save_pgd)
+{
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		efi_old_memmap_phys_epilog(save_pgd);
+	else
+		efi_switch_mm(efi_scratch.prev_mm);
+}
+
 EXPORT_SYMBOL_GPL(efi_mm);
 
 /*

commit afc4cc71cf78a8d691023da8ebcc31c3394a1674
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Tue Dec 24 16:10:13 2019 +0100

    efi/libstub/x86: Avoid thunking for native firmware calls
    
    We use special wrapper routines to invoke firmware services in the
    native case as well as the mixed mode case. For mixed mode, the need
    is obvious, but for the native cases, we can simply rely on the
    compiler to generate the indirect call, given that GCC now has
    support for the MS calling convention (and has had it for quite some
    time now). Note that on i386, the decompressor and the EFI stub are not
    built with -mregparm=3 like the rest of the i386 kernel, so we can
    safely allow the compiler to emit the indirect calls here as well.
    
    So drop all the wrappers and indirection, and switch to either native
    calls, or direct calls into the thunk routine for mixed mode.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: James Morse <james.morse@arm.com>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20191224151025.32482-14-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 885e50a707a6..03c2ed3c645c 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -635,8 +635,6 @@ void efi_switch_mm(struct mm_struct *mm)
 }
 
 #ifdef CONFIG_EFI_MIXED
-extern efi_status_t efi64_thunk(u32, ...);
-
 static DEFINE_SPINLOCK(efi_runtime_lock);
 
 #define runtime_service32(func)						 \

commit a8147dba75b188bff87d4ad072db84a0b70d716d
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Tue Dec 24 16:10:06 2019 +0100

    efi/x86: Rename efi_is_native() to efi_is_mixed()
    
    The ARM architecture does not permit combining 32-bit and 64-bit code
    at the same privilege level, and so EFI mixed mode is strictly a x86
    concept.
    
    In preparation of turning the 32/64 bit distinction in shared stub
    code to a native vs mixed one, refactor x86's current use of the
    helper function efi_is_native() into efi_is_mixed().
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: James Morse <james.morse@arm.com>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: https://lkml.kernel.org/r/20191224151025.32482-7-ardb@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 08ce8177c3af..885e50a707a6 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -388,7 +388,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * text and allocate a new stack because we can't rely on the
 	 * stack pointer being < 4GB.
 	 */
-	if (!IS_ENABLED(CONFIG_EFI_MIXED) || efi_is_native())
+	if (!efi_is_mixed())
 		return 0;
 
 	page = alloc_page(GFP_KERNEL|__GFP_DMA32);
@@ -449,7 +449,7 @@ void __init efi_map_region(efi_memory_desc_t *md)
 	 * booting in EFI mixed mode, because even though we may be
 	 * running a 64-bit kernel, the firmware may only be 32-bit.
 	 */
-	if (!efi_is_native () && IS_ENABLED(CONFIG_EFI_MIXED)) {
+	if (efi_is_mixed()) {
 		md->virt_addr = md->phys_addr;
 		return;
 	}

commit 4e78921ba4dd0aca1cc89168f45039add4183f8e
Author: Gen Zhang <blackgod016574@gmail.com>
Date:   Sat May 25 13:25:58 2019 +0200

    efi/x86/Add missing error handling to old_memmap 1:1 mapping code
    
    The old_memmap flow in efi_call_phys_prolog() performs numerous memory
    allocations, and either does not check for failure at all, or it does
    but fails to propagate it back to the caller, which may end up calling
    into the firmware with an incomplete 1:1 mapping.
    
    So let's fix this by returning NULL from efi_call_phys_prolog() on
    memory allocation failures only, and by handling this condition in the
    caller. Also, clean up any half baked sets of page tables that we may
    have created before returning with a NULL return value.
    
    Note that any failure at this level will trigger a panic() two levels
    up, so none of this makes a huge difference, but it is a nice cleanup
    nonetheless.
    
    [ardb: update commit log, add efi_call_phys_epilog() call on error path]
    
    Signed-off-by: Gen Zhang <blackgod016574@gmail.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rob Bradford <robert.bradford@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20190525112559.7917-2-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index cf0347f61b21..08ce8177c3af 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -84,13 +84,15 @@ pgd_t * __init efi_call_phys_prolog(void)
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
 		efi_switch_mm(&efi_mm);
-		return NULL;
+		return efi_mm.pgd;
 	}
 
 	early_code_mapping_set_exec(1);
 
 	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
 	save_pgd = kmalloc_array(n_pgds, sizeof(*save_pgd), GFP_KERNEL);
+	if (!save_pgd)
+		return NULL;
 
 	/*
 	 * Build 1:1 identity mapping for efi=old_map usage. Note that
@@ -138,10 +140,11 @@ pgd_t * __init efi_call_phys_prolog(void)
 		pgd_offset_k(pgd * PGDIR_SIZE)->pgd &= ~_PAGE_NX;
 	}
 
-out:
 	__flush_tlb_all();
-
 	return save_pgd;
+out:
+	efi_call_phys_epilog(save_pgd);
+	return NULL;
 }
 
 void __init efi_call_phys_epilog(pgd_t *save_pgd)

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e8da7f492970..cf0347f61b21 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -23,7 +23,7 @@
 #include <linux/mm.h>
 #include <linux/types.h>
 #include <linux/spinlock.h>
-#include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/ioport.h>
 #include <linux/mc146818rtc.h>
 #include <linux/efi.h>

commit 4eda11175fd9241908efb523b7f6e8a7c15afdb7
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Jul 24 21:28:55 2018 +0200

    efi/x86: drop task_lock() from efi_switch_mm()
    
    efi_switch_mm() is a wrapper around switch_mm() which saves current's
    ->active_mm, sets the requests mm as ->active_mm and invokes
    switch_mm().
    I don't think that task_lock() is required during that procedure. It
    protects ->mm which isn't changed here.
    
    It needs to be mentioned that during the whole procedure (switch to
    EFI's mm and back) the preemption needs to be disabled. A context switch
    at this point would reset the cr3 value based on current->mm. Also, this
    function may not be invoked at the same time on a different CPU because
    it would overwrite the efi_scratch.prev_mm information.
    
    Remove task_lock() and also update the comment to reflect it.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ee5d08f25ce4..e8da7f492970 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -619,18 +619,16 @@ void __init efi_dump_pagetable(void)
 
 /*
  * Makes the calling thread switch to/from efi_mm context. Can be used
- * for SetVirtualAddressMap() i.e. current->active_mm == init_mm as well
- * as during efi runtime calls i.e current->active_mm == current_mm.
- * We are not mm_dropping()/mm_grabbing() any mm, because we are not
- * losing/creating any references.
+ * in a kernel thread and user context. Preemption needs to remain disabled
+ * while the EFI-mm is borrowed. mmgrab()/mmdrop() is not used because the mm
+ * can not change under us.
+ * It should be ensured that there are no concurent calls to this function.
  */
 void efi_switch_mm(struct mm_struct *mm)
 {
-	task_lock(current);
 	efi_scratch.prev_mm = current->active_mm;
 	current->active_mm = mm;
 	switch_mm(efi_scratch.prev_mm, mm, NULL);
-	task_unlock(current);
 }
 
 #ifdef CONFIG_EFI_MIXED

commit 400439275d9543286f9d3f2925c3156f888e6b18
Merge: 0ad6b38ab2cc c4326563d9ab
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 13 10:25:08 2018 -0700

    Merge branch 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull EFI updates from Thomas Gleixner:
     "The EFI pile:
    
       - Make mixed mode UEFI runtime service invocations mutually
         exclusive, as mandated by the UEFI spec
    
       - Perform UEFI runtime services calls from a work queue so the calls
         into the firmware occur from a kernel thread
    
       - Honor the UEFI memory map attributes for live memory regions
         configured by UEFI as a framebuffer. This works around a coherency
         problem with KVM guests running on ARM.
    
       - Cleanups, improvements and fixes all over the place"
    
    * 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      efivars: Call guid_parse() against guid_t type of variable
      efi/cper: Use consistent types for UUIDs
      efi/x86: Replace references to efi_early->is64 with efi_is_64bit()
      efi: Deduplicate efi_open_volume()
      efi/x86: Add missing NULL initialization in UGA draw protocol discovery
      efi/x86: Merge 32-bit and 64-bit UGA draw protocol setup routines
      efi/x86: Align efi_uga_draw_protocol typedef names to convention
      efi/x86: Merge the setup_efi_pci32() and setup_efi_pci64() routines
      efi/x86: Prevent reentrant firmware calls in mixed mode
      efi/esrt: Only call efi_mem_reserve() for boot services memory
      fbdev/efifb: Honour UEFI memory map attributes when mapping the FB
      efi: Drop type and attribute checks in efi_mem_desc_lookup()
      efi/libstub/arm: Add opt-in Kconfig option for the DTB loader
      efi: Remove the declaration of efi_late_init() as the function is unused
      efi/cper: Avoid using get_seconds()
      efi: Use a work queue to invoke EFI Runtime Services
      efi/x86: Use non-blocking SetVariable() for efi_delete_dummy_variable()
      efi/x86: Clean up the eboot code

commit 83a0a2ea0b991927e42984be220329e776ce7137
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Jul 20 10:47:18 2018 +0900

    efi/x86: Prevent reentrant firmware calls in mixed mode
    
    The UEFI spec does not permit runtime services to be called
    reentrantly, and so it is up to the OS to provide proper locking
    around such calls.
    
    For the native case, this was fixed a long time ago, but for the
    mixed mode case, no locking is done whatsoever. Note that the calls
    are made with preemption and interrupts disabled, so only SMP
    configurations are affected by this issue.
    
    So add a spinlock and grab it when invoking a UEFI runtime service
    in mixed mode. We will also need to provide non-blocking versions
    of SetVariable() and QueryVariableInfo(), so add those as well.
    
    Tested-by: Hans de Goede <hdegoede@redhat.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Lukas Wunner <lukas@wunner.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180720014726.24031-2-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 77873ce700ae..448267f1c073 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -636,6 +636,8 @@ void efi_switch_mm(struct mm_struct *mm)
 #ifdef CONFIG_EFI_MIXED
 extern efi_status_t efi64_thunk(u32, ...);
 
+static DEFINE_SPINLOCK(efi_runtime_lock);
+
 #define runtime_service32(func)						 \
 ({									 \
 	u32 table = (u32)(unsigned long)efi.systab;			 \
@@ -657,17 +659,14 @@ extern efi_status_t efi64_thunk(u32, ...);
 #define efi_thunk(f, ...)						\
 ({									\
 	efi_status_t __s;						\
-	unsigned long __flags;						\
 	u32 __func;							\
 									\
-	local_irq_save(__flags);					\
 	arch_efi_call_virt_setup();					\
 									\
 	__func = runtime_service32(f);					\
 	__s = efi64_thunk(__func, __VA_ARGS__);				\
 									\
 	arch_efi_call_virt_teardown();					\
-	local_irq_restore(__flags);					\
 									\
 	__s;								\
 })
@@ -702,14 +701,17 @@ static efi_status_t efi_thunk_get_time(efi_time_t *tm, efi_time_cap_t *tc)
 {
 	efi_status_t status;
 	u32 phys_tm, phys_tc;
+	unsigned long flags;
 
 	spin_lock(&rtc_lock);
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_tm = virt_to_phys_or_null(tm);
 	phys_tc = virt_to_phys_or_null(tc);
 
 	status = efi_thunk(get_time, phys_tm, phys_tc);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 	spin_unlock(&rtc_lock);
 
 	return status;
@@ -719,13 +721,16 @@ static efi_status_t efi_thunk_set_time(efi_time_t *tm)
 {
 	efi_status_t status;
 	u32 phys_tm;
+	unsigned long flags;
 
 	spin_lock(&rtc_lock);
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_tm = virt_to_phys_or_null(tm);
 
 	status = efi_thunk(set_time, phys_tm);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 	spin_unlock(&rtc_lock);
 
 	return status;
@@ -737,8 +742,10 @@ efi_thunk_get_wakeup_time(efi_bool_t *enabled, efi_bool_t *pending,
 {
 	efi_status_t status;
 	u32 phys_enabled, phys_pending, phys_tm;
+	unsigned long flags;
 
 	spin_lock(&rtc_lock);
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_enabled = virt_to_phys_or_null(enabled);
 	phys_pending = virt_to_phys_or_null(pending);
@@ -747,6 +754,7 @@ efi_thunk_get_wakeup_time(efi_bool_t *enabled, efi_bool_t *pending,
 	status = efi_thunk(get_wakeup_time, phys_enabled,
 			     phys_pending, phys_tm);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 	spin_unlock(&rtc_lock);
 
 	return status;
@@ -757,13 +765,16 @@ efi_thunk_set_wakeup_time(efi_bool_t enabled, efi_time_t *tm)
 {
 	efi_status_t status;
 	u32 phys_tm;
+	unsigned long flags;
 
 	spin_lock(&rtc_lock);
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_tm = virt_to_phys_or_null(tm);
 
 	status = efi_thunk(set_wakeup_time, enabled, phys_tm);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 	spin_unlock(&rtc_lock);
 
 	return status;
@@ -781,6 +792,9 @@ efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 	efi_status_t status;
 	u32 phys_name, phys_vendor, phys_attr;
 	u32 phys_data_size, phys_data;
+	unsigned long flags;
+
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_data_size = virt_to_phys_or_null(data_size);
 	phys_vendor = virt_to_phys_or_null(vendor);
@@ -791,6 +805,8 @@ efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 	status = efi_thunk(get_variable, phys_name, phys_vendor,
 			   phys_attr, phys_data_size, phys_data);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
 	return status;
 }
 
@@ -800,6 +816,34 @@ efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 {
 	u32 phys_name, phys_vendor, phys_data;
 	efi_status_t status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&efi_runtime_lock, flags);
+
+	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
+	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_data = virt_to_phys_or_null_size(data, data_size);
+
+	/* If data_size is > sizeof(u32) we've got problems */
+	status = efi_thunk(set_variable, phys_name, phys_vendor,
+			   attr, data_size, phys_data);
+
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_set_variable_nonblocking(efi_char16_t *name, efi_guid_t *vendor,
+				   u32 attr, unsigned long data_size,
+				   void *data)
+{
+	u32 phys_name, phys_vendor, phys_data;
+	efi_status_t status;
+	unsigned long flags;
+
+	if (!spin_trylock_irqsave(&efi_runtime_lock, flags))
+		return EFI_NOT_READY;
 
 	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
 	phys_vendor = virt_to_phys_or_null(vendor);
@@ -809,6 +853,8 @@ efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 	status = efi_thunk(set_variable, phys_name, phys_vendor,
 			   attr, data_size, phys_data);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
 	return status;
 }
 
@@ -819,6 +865,9 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 {
 	efi_status_t status;
 	u32 phys_name_size, phys_name, phys_vendor;
+	unsigned long flags;
+
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_name_size = virt_to_phys_or_null(name_size);
 	phys_vendor = virt_to_phys_or_null(vendor);
@@ -827,6 +876,8 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 	status = efi_thunk(get_next_variable, phys_name_size,
 			   phys_name, phys_vendor);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
 	return status;
 }
 
@@ -835,10 +886,15 @@ efi_thunk_get_next_high_mono_count(u32 *count)
 {
 	efi_status_t status;
 	u32 phys_count;
+	unsigned long flags;
+
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_count = virt_to_phys_or_null(count);
 	status = efi_thunk(get_next_high_mono_count, phys_count);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
 	return status;
 }
 
@@ -847,10 +903,15 @@ efi_thunk_reset_system(int reset_type, efi_status_t status,
 		       unsigned long data_size, efi_char16_t *data)
 {
 	u32 phys_data;
+	unsigned long flags;
+
+	spin_lock_irqsave(&efi_runtime_lock, flags);
 
 	phys_data = virt_to_phys_or_null_size(data, data_size);
 
 	efi_thunk(reset_system, reset_type, status, data_size, phys_data);
+
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
 }
 
 static efi_status_t
@@ -872,10 +933,13 @@ efi_thunk_query_variable_info(u32 attr, u64 *storage_space,
 {
 	efi_status_t status;
 	u32 phys_storage, phys_remaining, phys_max;
+	unsigned long flags;
 
 	if (efi.runtime_version < EFI_2_00_SYSTEM_TABLE_REVISION)
 		return EFI_UNSUPPORTED;
 
+	spin_lock_irqsave(&efi_runtime_lock, flags);
+
 	phys_storage = virt_to_phys_or_null(storage_space);
 	phys_remaining = virt_to_phys_or_null(remaining_space);
 	phys_max = virt_to_phys_or_null(max_variable_size);
@@ -883,6 +947,35 @@ efi_thunk_query_variable_info(u32 attr, u64 *storage_space,
 	status = efi_thunk(query_variable_info, attr, phys_storage,
 			   phys_remaining, phys_max);
 
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_query_variable_info_nonblocking(u32 attr, u64 *storage_space,
+					  u64 *remaining_space,
+					  u64 *max_variable_size)
+{
+	efi_status_t status;
+	u32 phys_storage, phys_remaining, phys_max;
+	unsigned long flags;
+
+	if (efi.runtime_version < EFI_2_00_SYSTEM_TABLE_REVISION)
+		return EFI_UNSUPPORTED;
+
+	if (!spin_trylock_irqsave(&efi_runtime_lock, flags))
+		return EFI_NOT_READY;
+
+	phys_storage = virt_to_phys_or_null(storage_space);
+	phys_remaining = virt_to_phys_or_null(remaining_space);
+	phys_max = virt_to_phys_or_null(max_variable_size);
+
+	status = efi_thunk(query_variable_info, attr, phys_storage,
+			   phys_remaining, phys_max);
+
+	spin_unlock_irqrestore(&efi_runtime_lock, flags);
+
 	return status;
 }
 
@@ -908,9 +1001,11 @@ void efi_thunk_runtime_setup(void)
 	efi.get_variable = efi_thunk_get_variable;
 	efi.get_next_variable = efi_thunk_get_next_variable;
 	efi.set_variable = efi_thunk_set_variable;
+	efi.set_variable_nonblocking = efi_thunk_set_variable_nonblocking;
 	efi.get_next_high_mono_count = efi_thunk_get_next_high_mono_count;
 	efi.reset_system = efi_thunk_reset_system;
 	efi.query_variable_info = efi_thunk_query_variable_info;
+	efi.query_variable_info_nonblocking = efi_thunk_query_variable_info_nonblocking;
 	efi.update_capsule = efi_thunk_update_capsule;
 	efi.query_capsule_caps = efi_thunk_query_capsule_caps;
 }

commit 9b788f32bee6b0b293a4bdfca4ad4bb0206407fb
Author: Brijesh Singh <brijesh.singh@amd.com>
Date:   Fri Jul 20 10:28:46 2018 +0900

    x86/efi: Access EFI MMIO data as unencrypted when SEV is active
    
    SEV guest fails to update the UEFI runtime variables stored in the
    flash.
    
    The following commit:
    
      1379edd59673 ("x86/efi: Access EFI data as encrypted when SEV is active")
    
    unconditionally maps all the UEFI runtime data as 'encrypted' (C=1).
    
    When SEV is active the UEFI runtime data marked as EFI_MEMORY_MAPPED_IO
    should be mapped as 'unencrypted' so that both guest and hypervisor can
    access the data.
    
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: <stable@vger.kernel.org> # 4.15.x
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Fixes: 1379edd59673 ("x86/efi: Access EFI data as encrypted ...")
    Link: http://lkml.kernel.org/r/20180720012846.23560-2-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 77873ce700ae..5f2eb3231607 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -417,7 +417,7 @@ static void __init __map_region(efi_memory_desc_t *md, u64 va)
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
 
-	if (sev_active())
+	if (sev_active() && md->type != EFI_MEMORY_MAPPED_IO)
 		flags |= _PAGE_ENC;
 
 	pfn = md->phys_addr >> PAGE_SHIFT;

commit cfe19577047e74cdac5826adbdc2337d8437f8fb
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Mon Jun 25 15:08:52 2018 +0300

    x86/efi: Fix efi_call_phys_epilog() with CONFIG_X86_5LEVEL=y
    
    Open-coded page table entry checks don't work correctly when we fold the
    page table level at runtime.
    
    pgd_present() on 4-level paging machine always returns true, but
    open-coded version of the check may return false-negative result and
    we silently skip the rest of the loop body in efi_call_phys_epilog().
    
    Replace open-coded checks with proper helpers.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org # v4.12+
    Fixes: 94133e46a0f5 ("x86/efi: Correct EFI identity mapping under 'efi=old_map' when KASLR is enabled")
    Link: http://lkml.kernel.org/r/20180625120852.18300-1-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e01f7ceb9e7a..77873ce700ae 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -166,14 +166,14 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 		pgd = pgd_offset_k(pgd_idx * PGDIR_SIZE);
 		set_pgd(pgd_offset_k(pgd_idx * PGDIR_SIZE), save_pgd[pgd_idx]);
 
-		if (!(pgd_val(*pgd) & _PAGE_PRESENT))
+		if (!pgd_present(*pgd))
 			continue;
 
 		for (i = 0; i < PTRS_PER_P4D; i++) {
 			p4d = p4d_offset(pgd,
 					 pgd_idx * PGDIR_SIZE + i * P4D_SIZE);
 
-			if (!(p4d_val(*p4d) & _PAGE_PRESENT))
+			if (!p4d_present(*p4d))
 				continue;
 
 			pud = (pud_t *)p4d_page_vaddr(*p4d);

commit ed7588d5dc6f5e7202fb9bbeb14d94706ba225d7
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri May 18 13:35:24 2018 +0300

    x86/mm: Stop pretending pgtable_l5_enabled is a variable
    
    pgtable_l5_enabled is defined using cpu_feature_enabled() but we refer
    to it as a variable. This is misleading.
    
    Make pgtable_l5_enabled() a function.
    
    We cannot literally define it as a function due to circular dependencies
    between header files. Function-alike macros is close enough.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180518103528.59260-4-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index bed7e7f4e44c..e01f7ceb9e7a 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -225,7 +225,7 @@ int __init efi_alloc_page_tables(void)
 
 	pud = pud_alloc(&init_mm, p4d, EFI_VA_END);
 	if (!pud) {
-		if (pgtable_l5_enabled)
+		if (pgtable_l5_enabled())
 			free_page((unsigned long) pgd_page_vaddr(*pgd));
 		free_pages((unsigned long)efi_pgd, PGD_ALLOCATION_ORDER);
 		return -ENOMEM;

commit bc16d4052f1ae99996f3475b5a73d29c86e7ba81
Merge: 2fcd2b306aa8 03781e40890c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 2 17:46:37 2018 -0700

    Merge branch 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull EFI updates from Ingo Molnar:
     "The main EFI changes in this cycle were:
    
       - Fix the apple-properties code (Andy Shevchenko)
    
       - Add WARN() on arm64 if UEFI Runtime Services corrupt the reserved
         x18 register (Ard Biesheuvel)
    
       - Use efi_switch_mm() on x86 instead of manipulating %cr3 directly
         (Sai Praneeth)
    
       - Fix early memremap leak in ESRT code (Ard Biesheuvel)
    
       - Switch to L"xxx" notation for wide string literals (Ard Biesheuvel)
    
       - ... plus misc other cleanups and bugfixes"
    
    * 'efi-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/efi: Use efi_switch_mm() rather than manually twiddling with %cr3
      x86/efi: Replace efi_pgd with efi_mm.pgd
      efi: Use string literals for efi_char16_t variable initializers
      efi/esrt: Fix handling of early ESRT table mapping
      efi: Use efi_mm in x86 as well as ARM
      efi: Make const array 'apple' static
      efi/apple-properties: Use memremap() instead of ioremap()
      efi: Reorder pr_notice() with add_device_randomness() call
      x86/efi: Replace GFP_ATOMIC with GFP_KERNEL in efi_query_variable_store()
      efi/arm64: Check whether x18 is preserved by runtime services calls
      efi/arm*: Stop printing addresses of virtual mappings
      efi/apple-properties: Remove redundant attribute initialization from unmarshal_key_value_pairs()
      efi/arm*: Only register page tables when they exist

commit 0bc91d4ba77156ae9217d25ed7c434540f950d05
Merge: 565977a3d929 3eb2ce825ea1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Mar 27 08:43:39 2018 +0200

    Merge tag 'v4.16-rc7' into x86/mm, to fix up conflict
    
     Conflicts:
            arch/x86/mm/init_64.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 06ace26f4e6fcf747e890a39193be811777a048a
Author: Waiman Long <longman@redhat.com>
Date:   Thu Mar 22 15:18:53 2018 -0400

    x86/efi: Free efi_pgd with free_pages()
    
    The efi_pgd is allocated as PGD_ALLOCATION_ORDER pages and therefore must
    also be freed as PGD_ALLOCATION_ORDER pages with free_pages().
    
    Fixes: d9e9a6418065 ("x86/mm/pti: Allocate a separate user PGD")
    Signed-off-by: Waiman Long <longman@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/1521746333-19593-1-git-send-email-longman@redhat.com

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c310a8284358..f9cfbc0d1f33 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -227,7 +227,7 @@ int __init efi_alloc_page_tables(void)
 	if (!pud) {
 		if (CONFIG_PGTABLE_LEVELS > 4)
 			free_page((unsigned long) pgd_page_vaddr(*pgd));
-		free_page((unsigned long)efi_pgd);
+		free_pages((unsigned long)efi_pgd, PGD_ALLOCATION_ORDER);
 		return -ENOMEM;
 	}
 

commit 03781e40890c18bdea40092355b61431d0073c1d
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Mon Mar 12 09:43:55 2018 +0000

    x86/efi: Use efi_switch_mm() rather than manually twiddling with %cr3
    
    Use helper function efi_switch_mm() to switch to/from efi_mm when
    invoking any UEFI runtime services.
    
    Likewise, we need to switch back to previous mm (mm context stolen
    by efi_mm) after the above calls return successfully. We can use
    efi_switch_mm() helper function only with x86_64 kernel and
    "efi=old_map" disabled because, x86_32 and efi=old_map do not use
    efi_pgd, rather they use swapper_pg_dir.
    
    Tested-by: Bhupesh Sharma <bhsharma@redhat.com>
    [ardb: add #include of sched/task.h for task_lock/_unlock]
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: linux-efi@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 29b267b8cb63..4f8a9c963fbb 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -34,6 +34,7 @@
 #include <linux/slab.h>
 #include <linux/ucs2_string.h>
 #include <linux/mem_encrypt.h>
+#include <linux/sched/task.h>
 
 #include <asm/setup.h>
 #include <asm/page.h>
@@ -82,9 +83,8 @@ pgd_t * __init efi_call_phys_prolog(void)
 	int n_pgds, i, j;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
-		save_pgd = (pgd_t *)__read_cr3();
-		write_cr3((unsigned long)efi_scratch.efi_pgt);
-		goto out;
+		efi_switch_mm(&efi_mm);
+		return NULL;
 	}
 
 	early_code_mapping_set_exec(1);
@@ -156,8 +156,7 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	pud_t *pud;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
-		write_cr3((unsigned long)save_pgd);
-		__flush_tlb_all();
+		efi_switch_mm(efi_scratch.prev_mm);
 		return;
 	}
 
@@ -347,13 +346,6 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
-	/*
-	 * Since the PGD is encrypted, set the encryption mask so that when
-	 * this value is loaded into cr3 the PGD will be decrypted during
-	 * the pagetable walk.
-	 */
-	efi_scratch.efi_pgt = (pgd_t *)__sme_pa(pgd);
-
 	/*
 	 * It can happen that the physical address of new_memmap lands in memory
 	 * which is not mapped in the EFI page table. Therefore we need to go
@@ -367,8 +359,6 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 		return 1;
 	}
 
-	efi_scratch.use_pgd = true;
-
 	/*
 	 * Certain firmware versions are way too sentimential and still believe
 	 * they are exclusive and unquestionable owners of the first physical page,
@@ -627,6 +617,22 @@ void __init efi_dump_pagetable(void)
 #endif
 }
 
+/*
+ * Makes the calling thread switch to/from efi_mm context. Can be used
+ * for SetVirtualAddressMap() i.e. current->active_mm == init_mm as well
+ * as during efi runtime calls i.e current->active_mm == current_mm.
+ * We are not mm_dropping()/mm_grabbing() any mm, because we are not
+ * losing/creating any references.
+ */
+void efi_switch_mm(struct mm_struct *mm)
+{
+	task_lock(current);
+	efi_scratch.prev_mm = current->active_mm;
+	current->active_mm = mm;
+	switch_mm(efi_scratch.prev_mm, mm, NULL);
+	task_unlock(current);
+}
+
 #ifdef CONFIG_EFI_MIXED
 extern efi_status_t efi64_thunk(u32, ...);
 
@@ -680,16 +686,13 @@ efi_status_t efi_thunk_set_virtual_address_map(
 	efi_sync_low_kernel_mappings();
 	local_irq_save(flags);
 
-	efi_scratch.prev_cr3 = __read_cr3();
-	write_cr3((unsigned long)efi_scratch.efi_pgt);
-	__flush_tlb_all();
+	efi_switch_mm(&efi_mm);
 
 	func = (u32)(unsigned long)phys_set_virtual_address_map;
 	status = efi64_thunk(func, memory_map_size, descriptor_size,
 			     descriptor_version, virtual_map);
 
-	write_cr3(efi_scratch.prev_cr3);
-	__flush_tlb_all();
+	efi_switch_mm(efi_scratch.prev_mm);
 	local_irq_restore(flags);
 
 	return status;

commit 3ede3417f8d59fff5c07339b310b343468c81b07
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Mon Mar 12 09:43:54 2018 +0000

    x86/efi: Replace efi_pgd with efi_mm.pgd
    
    Since the previous patch added support for efi_mm, let's handle efi_pgd
    through efi_mm and remove global variable efi_pgd.
    
    Tested-by: Bhupesh Sharma <bhsharma@redhat.com>
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: linux-efi@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 29425b6c98a7..29b267b8cb63 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -191,8 +191,7 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	early_code_mapping_set_exec(0);
 }
 
-pgd_t *efi_pgd;
-EXPORT_SYMBOL_GPL(efi_pgd);
+EXPORT_SYMBOL_GPL(efi_mm);
 
 /*
  * We need our own copy of the higher levels of the page tables
@@ -205,7 +204,7 @@ EXPORT_SYMBOL_GPL(efi_pgd);
  */
 int __init efi_alloc_page_tables(void)
 {
-	pgd_t *pgd;
+	pgd_t *pgd, *efi_pgd;
 	p4d_t *p4d;
 	pud_t *pud;
 	gfp_t gfp_mask;
@@ -233,6 +232,7 @@ int __init efi_alloc_page_tables(void)
 		return -ENOMEM;
 	}
 
+	efi_mm.pgd = efi_pgd;
 	mm_init_cpumask(&efi_mm);
 	init_new_context(NULL, &efi_mm);
 
@@ -248,6 +248,7 @@ void efi_sync_low_kernel_mappings(void)
 	pgd_t *pgd_k, *pgd_efi;
 	p4d_t *p4d_k, *p4d_efi;
 	pud_t *pud_k, *pud_efi;
+	pgd_t *efi_pgd = efi_mm.pgd;
 
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return;
@@ -341,7 +342,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	unsigned long pfn, text, pf;
 	struct page *page;
 	unsigned npages;
-	pgd_t *pgd;
+	pgd_t *pgd = efi_mm.pgd;
 
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
@@ -351,8 +352,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * this value is loaded into cr3 the PGD will be decrypted during
 	 * the pagetable walk.
 	 */
-	efi_scratch.efi_pgt = (pgd_t *)__sme_pa(efi_pgd);
-	pgd = efi_pgd;
+	efi_scratch.efi_pgt = (pgd_t *)__sme_pa(pgd);
 
 	/*
 	 * It can happen that the physical address of new_memmap lands in memory
@@ -422,7 +422,7 @@ static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
 	unsigned long flags = _PAGE_RW;
 	unsigned long pfn;
-	pgd_t *pgd = efi_pgd;
+	pgd_t *pgd = efi_mm.pgd;
 
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
@@ -526,7 +526,7 @@ void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 static int __init efi_update_mappings(efi_memory_desc_t *md, unsigned long pf)
 {
 	unsigned long pfn;
-	pgd_t *pgd = efi_pgd;
+	pgd_t *pgd = efi_mm.pgd;
 	int err1, err2;
 
 	/* Update the 1:1 mapping */
@@ -623,7 +623,7 @@ void __init efi_dump_pagetable(void)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		ptdump_walk_pgd_level(NULL, swapper_pg_dir);
 	else
-		ptdump_walk_pgd_level(NULL, efi_pgd);
+		ptdump_walk_pgd_level(NULL, efi_mm.pgd);
 #endif
 }
 

commit 7e904a91bf6049071ef9d605a52f863ae774081d
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Mon Mar 12 08:44:56 2018 +0000

    efi: Use efi_mm in x86 as well as ARM
    
    Presently, only ARM uses mm_struct to manage EFI page tables and EFI
    runtime region mappings. As this is the preferred approach, let's make
    this data structure common across architectures. Specially, for x86,
    using this data structure improves code maintainability and readability.
    
    Tested-by: Bhupesh Sharma <bhsharma@redhat.com>
    [ardb: don't #include the world to get a declaration of struct mm_struct]
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180312084500.10764-2-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 780460aa5ea5..29425b6c98a7 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -233,6 +233,9 @@ int __init efi_alloc_page_tables(void)
 		return -ENOMEM;
 	}
 
+	mm_init_cpumask(&efi_mm);
+	init_new_context(NULL, &efi_mm);
+
 	return 0;
 }
 

commit 91f606a8fa68264224cbc76888fa8649cdbe9990
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Wed Feb 14 21:25:41 2018 +0300

    x86/mm: Replace compile-time checks for 5-level paging with runtime-time checks
    
    This patch converts the of CONFIG_X86_5LEVEL check to runtime checks for
    p4d folding.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20180214182542.69302-9-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index d52aaa7dc088..4845871a2006 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -227,7 +227,7 @@ int __init efi_alloc_page_tables(void)
 
 	pud = pud_alloc(&init_mm, p4d, EFI_VA_END);
 	if (!pud) {
-		if (CONFIG_PGTABLE_LEVELS > 4)
+		if (pgtable_l5_enabled)
 			free_page((unsigned long) pgd_page_vaddr(*pgd));
 		free_page((unsigned long)efi_pgd);
 		return -ENOMEM;

commit c65e774fb3f6af212641538694b9778ff9ab4300
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Wed Feb 14 14:16:53 2018 +0300

    x86/mm: Make PGDIR_SHIFT and PTRS_PER_P4D variable
    
    For boot-time switching between 4- and 5-level paging we need to be able
    to fold p4d page table level at runtime. It requires variable
    PGDIR_SHIFT and PTRS_PER_P4D.
    
    The change doesn't affect the kernel image size much:
    
       text    data     bss     dec     hex filename
    8628091 4734304 1368064 14730459         e0c4db vmlinux.before
    8628393 4734340 1368064 14730797         e0c62d vmlinux.after
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20180214111656.88514-7-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 780460aa5ea5..d52aaa7dc088 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -257,8 +257,8 @@ void efi_sync_low_kernel_mappings(void)
 	 * only span a single PGD entry and that the entry also maps
 	 * other important kernel regions.
 	 */
-	BUILD_BUG_ON(pgd_index(EFI_VA_END) != pgd_index(MODULES_END));
-	BUILD_BUG_ON((EFI_VA_START & PGDIR_MASK) !=
+	MAYBE_BUILD_BUG_ON(pgd_index(EFI_VA_END) != pgd_index(MODULES_END));
+	MAYBE_BUILD_BUG_ON((EFI_VA_START & PGDIR_MASK) !=
 			(EFI_VA_END & PGDIR_MASK));
 
 	pgd_efi = efi_pgd + pgd_index(PAGE_OFFSET);

commit 116fef6408599dd6ff6996235c50aa692e9b5631
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Jan 31 07:56:22 2018 -0800

    x86/mm/dump_pagetables: Add the EFI pagetable to the debugfs 'page_tables' directory
    
    EFI is complicated enough that being able to view its pagetables is
    quite helpful.  Rather than requiring users to fish it out of dmesg
    on an appropriately configured kernel, let users view it in debugfs
    as well.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/ba158a93f3250e6fca752cff2cfb1fcdd9f2b50c.1517414050.git.luto@kernel.org
    [ Fixed trivial whitespace damage and fixed missing export. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c310a8284358..780460aa5ea5 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -27,6 +27,7 @@
 #include <linux/ioport.h>
 #include <linux/mc146818rtc.h>
 #include <linux/efi.h>
+#include <linux/export.h>
 #include <linux/uaccess.h>
 #include <linux/io.h>
 #include <linux/reboot.h>
@@ -190,7 +191,8 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	early_code_mapping_set_exec(0);
 }
 
-static pgd_t *efi_pgd;
+pgd_t *efi_pgd;
+EXPORT_SYMBOL_GPL(efi_pgd);
 
 /*
  * We need our own copy of the higher levels of the page tables

commit 3ccabd6d9d9b0da5780e0386b4bf7c5f07669e37
Merge: 5289d3005a36 782bf20c2a17
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 30 13:01:09 2018 -0800

    Merge branch 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cleanups from Ingo Molnar:
     "Misc cleanups"
    
    * 'x86-cleanups-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Remove unused IOMMU_STRESS Kconfig
      x86/extable: Mark exception handler functions visible
      x86/timer: Don't inline __const_udelay
      x86/headers: Remove duplicate #includes

commit 40548c6b6c134275c750eb372dc2cf8ee1bbc3d4
Merge: 2c1cfa499018 99a9dc98ba52
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 14 09:51:25 2018 -0800

    Merge branch 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 pti updates from Thomas Gleixner:
     "This contains:
    
       - a PTI bugfix to avoid setting reserved CR3 bits when PCID is
         disabled. This seems to cause issues on a virtual machine at least
         and is incorrect according to the AMD manual.
    
       - a PTI bugfix which disables the perf BTS facility if PTI is
         enabled. The BTS AUX buffer is not globally visible and causes the
         CPU to fault when the mapping disappears on switching CR3 to user
         space. A full fix which restores BTS on PTI is non trivial and will
         be worked on.
    
       - PTI bugfixes for EFI and trusted boot which make sure that the user
         space visible page table entries have the NX bit cleared
    
       - removal of dead code in the PTI pagetable setup functions
    
       - add PTI documentation
    
       - add a selftest for vsyscall to verify that the kernel actually
         implements what it advertises.
    
       - a sysfs interface to expose vulnerability and mitigation
         information so there is a coherent way for users to retrieve the
         status.
    
       - the initial spectre_v2 mitigations, aka retpoline:
    
          + The necessary ASM thunk and compiler support
    
          + The ASM variants of retpoline and the conversion of affected ASM
            code
    
          + Make LFENCE serializing on AMD so it can be used as speculation
            trap
    
          + The RSB fill after vmexit
    
       - initial objtool support for retpoline
    
      As I said in the status mail this is the most of the set of patches
      which should go into 4.15 except two straight forward patches still on
      hold:
    
       - the retpoline add on of LFENCE which waits for ACKs
    
       - the RSB fill after context switch
    
      Both should be ready to go early next week and with that we'll have
      covered the major holes of spectre_v2 and go back to normality"
    
    * 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (28 commits)
      x86,perf: Disable intel_bts when PTI
      security/Kconfig: Correct the Documentation reference for PTI
      x86/pti: Fix !PCID and sanitize defines
      selftests/x86: Add test_vsyscall
      x86/retpoline: Fill return stack buffer on vmexit
      x86/retpoline/irq32: Convert assembler indirect jumps
      x86/retpoline/checksum32: Convert assembler indirect jumps
      x86/retpoline/xen: Convert Xen hypercall indirect jumps
      x86/retpoline/hyperv: Convert assembler indirect jumps
      x86/retpoline/ftrace: Convert ftrace assembler indirect jumps
      x86/retpoline/entry: Convert entry assembler indirect jumps
      x86/retpoline/crypto: Convert crypto assembler indirect jumps
      x86/spectre: Add boot time option to select Spectre v2 mitigation
      x86/retpoline: Add initial retpoline support
      objtool: Allow alternatives to be ignored
      objtool: Detect jumps to retpoline thunks
      x86/pti: Make unpoison of pgd for trusted boot work for real
      x86/alternatives: Fix optimize_nops() checking
      sysfs/cpu: Fix typos in vulnerability documentation
      x86/cpu/AMD: Use LFENCE_RDTSC in preference to MFENCE_RDTSC
      ...

commit de53c3786a3ce162a1c815d0c04c766c23ec9c0a
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Fri Jan 5 22:35:41 2018 +0100

    x86/pti: Unbreak EFI old_memmap
    
    EFI_OLD_MEMMAP's efi_call_phys_prolog() calls set_pgd() with swapper PGD that
    has PAGE_USER set, which makes PTI set NX on it, and therefore EFI can't
    execute it's code.
    
    Fix that by forcefully clearing _PAGE_NX from the PGD (this can't be done
    by the pgprot API).
    
    _PAGE_NX will be automatically reintroduced in efi_call_phys_epilog(), as
    _set_pgd() will again notice that this is _PAGE_USER, and set _PAGE_NX on
    it.
    
    Tested-by: Dimitri Sivanich <sivanich@hpe.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/nycvar.YFH.7.76.1801052215460.11852@cbobk.fhfr.pm

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 39c4b35ac7a4..61975b6bcb1a 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -134,7 +134,9 @@ pgd_t * __init efi_call_phys_prolog(void)
 				pud[j] = *pud_offset(p4d_k, vaddr);
 			}
 		}
+		pgd_offset_k(pgd * PGDIR_SIZE)->pgd &= ~_PAGE_NX;
 	}
+
 out:
 	__flush_tlb_all();
 

commit 5aa90a84589282b87666f92b6c3c917c8080a9bf
Merge: 61233580f1f3 9f5cb6b32d9e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 29 17:02:49 2017 -0800

    Merge branch 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 page table isolation updates from Thomas Gleixner:
     "This is the final set of enabling page table isolation on x86:
    
       - Infrastructure patches for handling the extra page tables.
    
       - Patches which map the various bits and pieces which are required to
         get in and out of user space into the user space visible page
         tables.
    
       - The required changes to have CR3 switching in the entry/exit code.
    
       - Optimizations for the CR3 switching along with documentation how
         the ASID/PCID mechanism works.
    
       - Updates to dump pagetables to cover the user space page tables for
         W+X scans and extra debugfs files to analyze both the kernel and
         the user space visible page tables
    
      The whole functionality is compile time controlled via a config switch
      and can be turned on/off on the command line as well"
    
    * 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (32 commits)
      x86/ldt: Make the LDT mapping RO
      x86/mm/dump_pagetables: Allow dumping current pagetables
      x86/mm/dump_pagetables: Check user space page table for WX pages
      x86/mm/dump_pagetables: Add page table directory to the debugfs VFS hierarchy
      x86/mm/pti: Add Kconfig
      x86/dumpstack: Indicate in Oops whether PTI is configured and enabled
      x86/mm: Clarify the whole ASID/kernel PCID/user PCID naming
      x86/mm: Use INVPCID for __native_flush_tlb_single()
      x86/mm: Optimize RESTORE_CR3
      x86/mm: Use/Fix PCID to optimize user/kernel switches
      x86/mm: Abstract switching CR3
      x86/mm: Allow flushing for future ASID switches
      x86/pti: Map the vsyscall page if needed
      x86/pti: Put the LDT in its own PGD if PTI is on
      x86/mm/64: Make a full PGD-entry size hole in the memory map
      x86/events/intel/ds: Map debug buffers in cpu_entry_area
      x86/cpu_entry_area: Add debugstore entries to cpu_entry_area
      x86/mm/pti: Map ESPFIX into user space
      x86/mm/pti: Share entry text PMD
      x86/entry: Align entry text section to PMD boundary
      ...

commit d9e9a6418065bb376e5de8d93ce346939b9a37a6
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Mon Dec 4 15:07:39 2017 +0100

    x86/mm/pti: Allocate a separate user PGD
    
    Kernel page table isolation requires to have two PGDs. One for the kernel,
    which contains the full kernel mapping plus the user space mapping and one
    for user space which contains the user space mappings and the minimal set
    of kernel mappings which are required by the architecture to be able to
    transition from and to user space.
    
    Add the necessary preliminaries.
    
    [ tglx: Split out from the big kaiser dump. EFI fixup from Kirill ]
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 20fb31579b69..39c4b35ac7a4 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -195,6 +195,9 @@ static pgd_t *efi_pgd;
  * because we want to avoid inserting EFI region mappings (EFI_VA_END
  * to EFI_VA_START) into the standard kernel page tables. Everything
  * else can be shared, see efi_sync_low_kernel_mappings().
+ *
+ * We don't want the pgd on the pgd_list and cannot use pgd_alloc() for the
+ * allocation.
  */
 int __init efi_alloc_page_tables(void)
 {
@@ -207,7 +210,7 @@ int __init efi_alloc_page_tables(void)
 		return 0;
 
 	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;
-	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);
+	efi_pgd = (pgd_t *)__get_free_pages(gfp_mask, PGD_ALLOCATION_ORDER);
 	if (!efi_pgd)
 		return -ENOMEM;
 

commit 81bf665d00baf1aef01118c6c9e51520e57c0757
Author: Pravin Shedge <pravin.shedge4linux@gmail.com>
Date:   Tue Dec 12 02:12:31 2017 +0530

    x86/headers: Remove duplicate #includes
    
    These duplicate includes have been found with scripts/checkincludes.pl but
    they have been removed manually to avoid removing false positives.
    
    Signed-off-by: Pravin Shedge <pravin.shedge4linux@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: ard.biesheuvel@linaro.org
    Cc: boris.ostrovsky@oracle.com
    Cc: geert@linux-m68k.org
    Cc: jgross@suse.com
    Cc: linux-efi@vger.kernel.org
    Cc: luto@kernel.org
    Cc: matt@codeblueprint.co.uk
    Cc: thomas.lendacky@amd.com
    Cc: tim.c.chen@linux.intel.com
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1513024951-9221-1-git-send-email-pravin.shedge4linux@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 6a151ce70e86..1e5184d7ce7a 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -25,7 +25,6 @@
 #include <linux/spinlock.h>
 #include <linux/bootmem.h>
 #include <linux/ioport.h>
-#include <linux/init.h>
 #include <linux/mc146818rtc.h>
 #include <linux/efi.h>
 #include <linux/uaccess.h>

commit 75f296d93bcebcfe375884ddac79e30263a31766
Author: Levin, Alexander (Sasha Levin) <alexander.levin@verizon.com>
Date:   Wed Nov 15 17:35:54 2017 -0800

    kmemcheck: stop using GFP_NOTRACK and SLAB_NOTRACK
    
    Convert all allocations that used a NOTRACK flag to stop using it.
    
    Link: http://lkml.kernel.org/r/20171007030159.22241-3-alexander.levin@verizon.com
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tim Hansen <devtimhansen@gmail.com>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 9e4ee5b04b2d..6a151ce70e86 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -207,7 +207,7 @@ int __init efi_alloc_page_tables(void)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
-	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;
+	gfp_mask = GFP_KERNEL | __GFP_ZERO;
 	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);
 	if (!efi_pgd)
 		return -ENOMEM;

commit 1379edd5967346a1fa79b8dc3e9ca261576c6bc9
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Fri Oct 20 09:30:49 2017 -0500

    x86/efi: Access EFI data as encrypted when SEV is active
    
    EFI data is encrypted when the kernel is run under SEV. Update the
    page table references to be sure the EFI memory areas are accessed
    encrypted.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Tested-by: Borislav Petkov <bp@suse.de>
    Cc: linux-efi@vger.kernel.org
    Cc: kvm@vger.kernel.org
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20171020143059.3291-8-brijesh.singh@amd.com

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 20fb31579b69..9e4ee5b04b2d 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -33,6 +33,7 @@
 #include <linux/reboot.h>
 #include <linux/slab.h>
 #include <linux/ucs2_string.h>
+#include <linux/mem_encrypt.h>
 
 #include <asm/setup.h>
 #include <asm/page.h>
@@ -370,7 +371,11 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * as trim_bios_range() will reserve the first page and isolate it away
 	 * from memory allocators anyway.
 	 */
-	if (kernel_map_pages_in_pgd(pgd, 0x0, 0x0, 1, _PAGE_RW)) {
+	pf = _PAGE_RW;
+	if (sev_active())
+		pf |= _PAGE_ENC;
+
+	if (kernel_map_pages_in_pgd(pgd, 0x0, 0x0, 1, pf)) {
 		pr_err("Failed to create 1:1 mapping for the first page!\n");
 		return 1;
 	}
@@ -413,6 +418,9 @@ static void __init __map_region(efi_memory_desc_t *md, u64 va)
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
 
+	if (sev_active())
+		flags |= _PAGE_ENC;
+
 	pfn = md->phys_addr >> PAGE_SHIFT;
 	if (kernel_map_pages_in_pgd(pgd, pfn, va, md->num_pages, flags))
 		pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
@@ -539,6 +547,9 @@ static int __init efi_update_mem_attr(struct mm_struct *mm, efi_memory_desc_t *m
 	if (!(md->attribute & EFI_MEMORY_RO))
 		pf |= _PAGE_RW;
 
+	if (sev_active())
+		pf |= _PAGE_ENC;
+
 	return efi_update_mappings(md, pf);
 }
 
@@ -590,6 +601,9 @@ void __init efi_runtime_update_mappings(void)
 			(md->type != EFI_RUNTIME_SERVICES_CODE))
 			pf |= _PAGE_RW;
 
+		if (sev_active())
+			pf |= _PAGE_ENC;
+
 		efi_update_mappings(md, pf);
 	}
 }

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 12e83888e5b9..20fb31579b69 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * x86_64 specific EFI support functions
  * Based on Extensible Firmware Interface Specification version 1.0

commit 38eecccdf488e38ee93690cfe9ec1914b73f512f
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:15 2017 -0500

    x86/efi: Update EFI pagetable creation to work with SME
    
    When SME is active, pagetable entries created for EFI need to have the
    encryption mask set as necessary.
    
    When the new pagetable pages are allocated they are mapped encrypted. So,
    update the efi_pgt value that will be used in CR3 to include the encryption
    mask so that the PGD table can be read successfully. The pagetable mapping
    as well as the kernel are also added to the pagetable mapping as encrypted.
    All other EFI mappings are mapped decrypted (tables, etc.).
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/9a8f4c502db4a84b09e2f0a1555bb75aa8b69785.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 9bf72f5bfedb..12e83888e5b9 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -327,7 +327,7 @@ virt_to_phys_or_null_size(void *va, unsigned long size)
 
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
-	unsigned long pfn, text;
+	unsigned long pfn, text, pf;
 	struct page *page;
 	unsigned npages;
 	pgd_t *pgd;
@@ -335,7 +335,12 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
-	efi_scratch.efi_pgt = (pgd_t *)__pa(efi_pgd);
+	/*
+	 * Since the PGD is encrypted, set the encryption mask so that when
+	 * this value is loaded into cr3 the PGD will be decrypted during
+	 * the pagetable walk.
+	 */
+	efi_scratch.efi_pgt = (pgd_t *)__sme_pa(efi_pgd);
 	pgd = efi_pgd;
 
 	/*
@@ -345,7 +350,8 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * phys_efi_set_virtual_address_map().
 	 */
 	pfn = pa_memmap >> PAGE_SHIFT;
-	if (kernel_map_pages_in_pgd(pgd, pfn, pa_memmap, num_pages, _PAGE_NX | _PAGE_RW)) {
+	pf = _PAGE_NX | _PAGE_RW | _PAGE_ENC;
+	if (kernel_map_pages_in_pgd(pgd, pfn, pa_memmap, num_pages, pf)) {
 		pr_err("Error ident-mapping new memmap (0x%lx)!\n", pa_memmap);
 		return 1;
 	}
@@ -388,7 +394,8 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	text = __pa(_text);
 	pfn = text >> PAGE_SHIFT;
 
-	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, _PAGE_RW)) {
+	pf = _PAGE_RW | _PAGE_ENC;
+	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, pf)) {
 		pr_err("Failed to map kernel text 1:1\n");
 		return 1;
 	}

commit 7a69f9c60b49699579f5bfb71f928cceba0afe1a
Merge: 9bc088ab66be 8781fb7e9749
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 14:45:09 2017 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - Continued work to add support for 5-level paging provided by future
         Intel CPUs. In particular we switch the x86 GUP code to the generic
         implementation. (Kirill A. Shutemov)
    
       - Continued work to add PCID CPU support to native kernels as well.
         In this round most of the focus is on reworking/refreshing the TLB
         flush infrastructure for the upcoming PCID changes. (Andy
         Lutomirski)"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (34 commits)
      x86/mm: Delete a big outdated comment about TLB flushing
      x86/mm: Don't reenter flush_tlb_func_common()
      x86/KASLR: Fix detection 32/64 bit bootloaders for 5-level paging
      x86/ftrace: Exclude functions in head64.c from function-tracing
      x86/mmap, ASLR: Do not treat unlimited-stack tasks as legacy mmap
      x86/mm: Remove reset_lazy_tlbstate()
      x86/ldt: Simplify the LDT switching logic
      x86/boot/64: Put __startup_64() into .head.text
      x86/mm: Add support for 5-level paging for KASLR
      x86/mm: Make kernel_physical_mapping_init() support 5-level paging
      x86/mm: Add sync_global_pgds() for configuration with 5-level paging
      x86/boot/64: Add support of additional page table level during early boot
      x86/boot/64: Rename init_level4_pgt and early_level4_pgt
      x86/boot/64: Rewrite startup_64() in C
      x86/boot/compressed: Enable 5-level paging during decompression stage
      x86/boot/efi: Define __KERNEL32_CS GDT on 64-bit configurations
      x86/boot/efi: Fix __KERNEL_CS definition of GDT entry on 64-bit configurations
      x86/boot/efi: Cleanup initialization of GDT entries
      x86/asm: Fix comment in return_from_SYSCALL_64()
      x86/mm/gup: Switch GUP to the generic get_user_page_fast() implementation
      ...

commit 6c690ee1039b251e583fc65b28da30e97d6a7385
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Jun 12 10:26:14 2017 -0700

    x86/mm: Split read_cr3() into read_cr3_pa() and __read_cr3()
    
    The kernel has several code paths that read CR3.  Most of them assume that
    CR3 contains the PGD's physical address, whereas some of them awkwardly
    use PHYSICAL_PAGE_MASK to mask off low bits.
    
    Add explicit mask macros for CR3 and convert all of the CR3 readers.
    This will keep them from breaking when PCID is enabled.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: xen-devel <xen-devel@lists.xen.org>
    Link: http://lkml.kernel.org/r/883f8fb121f4616c1c1427ad87350bb2f5ffeca1.1497288170.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index eb8dff15a7f6..f40bf6230480 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -80,7 +80,7 @@ pgd_t * __init efi_call_phys_prolog(void)
 	int n_pgds, i, j;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
-		save_pgd = (pgd_t *)read_cr3();
+		save_pgd = (pgd_t *)__read_cr3();
 		write_cr3((unsigned long)efi_scratch.efi_pgt);
 		goto out;
 	}
@@ -646,7 +646,7 @@ efi_status_t efi_thunk_set_virtual_address_map(
 	efi_sync_low_kernel_mappings();
 	local_irq_save(flags);
 
-	efi_scratch.prev_cr3 = read_cr3();
+	efi_scratch.prev_cr3 = __read_cr3();
 	write_cr3((unsigned long)efi_scratch.efi_pgt);
 	__flush_tlb_all();
 

commit ac81d3de03f7d8593a94240d057c8e2e8e869897
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Fri Jun 2 13:52:06 2017 +0000

    x86/efi: Extend CONFIG_EFI_PGT_DUMP support to x86_32 and kexec as well
    
    CONFIG_EFI_PGT_DUMP=y, as the name suggests, dumps EFI page tables to the
    kernel log during kernel boot.
    
    This feature is very useful while debugging page faults/null pointer
    dereferences to EFI related addresses.
    
    Presently, this feature is limited only to x86_64, so let's extend it to
    other EFI configurations like kexec kernel, efi=old_map and to x86_32 as well.
    
    This doesn't effect normal boot path because this config option should
    be used only for debug purposes.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170602135207.21708-13-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index eb8dff15a7f6..8ff1f95627f9 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -589,7 +589,10 @@ void __init efi_runtime_update_mappings(void)
 void __init efi_dump_pagetable(void)
 {
 #ifdef CONFIG_EFI_PGT_DUMP
-	ptdump_walk_pgd_level(NULL, efi_pgd);
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		ptdump_walk_pgd_level(NULL, swapper_pg_dir);
+	else
+		ptdump_walk_pgd_level(NULL, efi_pgd);
 #endif
 }
 

commit 94133e46a0f5ca3f138479806104ab4a8cb0455e
Author: Baoquan He <bhe@redhat.com>
Date:   Fri May 26 12:36:50 2017 +0100

    x86/efi: Correct EFI identity mapping under 'efi=old_map' when KASLR is enabled
    
    For EFI with the 'efi=old_map' kernel option specified, the kernel will panic
    when KASLR is enabled:
    
      BUG: unable to handle kernel paging request at 000000007febd57e
      IP: 0x7febd57e
      PGD 1025a067
      PUD 0
    
      Oops: 0010 [#1] SMP
      Call Trace:
       efi_enter_virtual_mode()
       start_kernel()
       x86_64_start_reservations()
       x86_64_start_kernel()
       start_cpu()
    
    The root cause is that the identity mapping is not built correctly
    in the 'efi=old_map' case.
    
    On 'nokaslr' kernels, PAGE_OFFSET is 0xffff880000000000 which is PGDIR_SIZE
    aligned. We can borrow the PUD table from the direct mappings safely. Given a
    physical address X, we have pud_index(X) == pud_index(__va(X)).
    
    However, on KASLR kernels, PAGE_OFFSET is PUD_SIZE aligned. For a given physical
    address X, pud_index(X) != pud_index(__va(X)). We can't just copy the PGD entry
    from direct mapping to build identity mapping, instead we need to copy the
    PUD entries one by one from the direct mapping.
    
    Fix it.
    
    Signed-off-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Bhupesh Sharma <bhsharma@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Frank Ramsay <frank.ramsay@hpe.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russ Anderson <rja@sgi.com>
    Cc: Thomas Garnier <thgarnie@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170526113652.21339-5-matt@codeblueprint.co.uk
    [ Fixed and reworded the changelog and code comments to be more readable. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c488625c9712..eb8dff15a7f6 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -71,11 +71,13 @@ static void __init early_code_mapping_set_exec(int executable)
 
 pgd_t * __init efi_call_phys_prolog(void)
 {
-	unsigned long vaddress;
-	pgd_t *save_pgd;
+	unsigned long vaddr, addr_pgd, addr_p4d, addr_pud;
+	pgd_t *save_pgd, *pgd_k, *pgd_efi;
+	p4d_t *p4d, *p4d_k, *p4d_efi;
+	pud_t *pud;
 
 	int pgd;
-	int n_pgds;
+	int n_pgds, i, j;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
 		save_pgd = (pgd_t *)read_cr3();
@@ -88,10 +90,49 @@ pgd_t * __init efi_call_phys_prolog(void)
 	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
 	save_pgd = kmalloc_array(n_pgds, sizeof(*save_pgd), GFP_KERNEL);
 
+	/*
+	 * Build 1:1 identity mapping for efi=old_map usage. Note that
+	 * PAGE_OFFSET is PGDIR_SIZE aligned when KASLR is disabled, while
+	 * it is PUD_SIZE ALIGNED with KASLR enabled. So for a given physical
+	 * address X, the pud_index(X) != pud_index(__va(X)), we can only copy
+	 * PUD entry of __va(X) to fill in pud entry of X to build 1:1 mapping.
+	 * This means here we can only reuse the PMD tables of the direct mapping.
+	 */
 	for (pgd = 0; pgd < n_pgds; pgd++) {
-		save_pgd[pgd] = *pgd_offset_k(pgd * PGDIR_SIZE);
-		vaddress = (unsigned long)__va(pgd * PGDIR_SIZE);
-		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));
+		addr_pgd = (unsigned long)(pgd * PGDIR_SIZE);
+		vaddr = (unsigned long)__va(pgd * PGDIR_SIZE);
+		pgd_efi = pgd_offset_k(addr_pgd);
+		save_pgd[pgd] = *pgd_efi;
+
+		p4d = p4d_alloc(&init_mm, pgd_efi, addr_pgd);
+		if (!p4d) {
+			pr_err("Failed to allocate p4d table!\n");
+			goto out;
+		}
+
+		for (i = 0; i < PTRS_PER_P4D; i++) {
+			addr_p4d = addr_pgd + i * P4D_SIZE;
+			p4d_efi = p4d + p4d_index(addr_p4d);
+
+			pud = pud_alloc(&init_mm, p4d_efi, addr_p4d);
+			if (!pud) {
+				pr_err("Failed to allocate pud table!\n");
+				goto out;
+			}
+
+			for (j = 0; j < PTRS_PER_PUD; j++) {
+				addr_pud = addr_p4d + j * PUD_SIZE;
+
+				if (addr_pud > (max_pfn << PAGE_SHIFT))
+					break;
+
+				vaddr = (unsigned long)__va(addr_pud);
+
+				pgd_k = pgd_offset_k(vaddr);
+				p4d_k = p4d_offset(pgd_k, vaddr);
+				pud[j] = *pud_offset(p4d_k, vaddr);
+			}
+		}
 	}
 out:
 	__flush_tlb_all();
@@ -104,8 +145,11 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	/*
 	 * After the lock is released, the original page table is restored.
 	 */
-	int pgd_idx;
+	int pgd_idx, i;
 	int nr_pgds;
+	pgd_t *pgd;
+	p4d_t *p4d;
+	pud_t *pud;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP)) {
 		write_cr3((unsigned long)save_pgd);
@@ -115,9 +159,28 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 
 	nr_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
 
-	for (pgd_idx = 0; pgd_idx < nr_pgds; pgd_idx++)
+	for (pgd_idx = 0; pgd_idx < nr_pgds; pgd_idx++) {
+		pgd = pgd_offset_k(pgd_idx * PGDIR_SIZE);
 		set_pgd(pgd_offset_k(pgd_idx * PGDIR_SIZE), save_pgd[pgd_idx]);
 
+		if (!(pgd_val(*pgd) & _PAGE_PRESENT))
+			continue;
+
+		for (i = 0; i < PTRS_PER_P4D; i++) {
+			p4d = p4d_offset(pgd,
+					 pgd_idx * PGDIR_SIZE + i * P4D_SIZE);
+
+			if (!(p4d_val(*p4d) & _PAGE_PRESENT))
+				continue;
+
+			pud = (pud_t *)p4d_page_vaddr(*p4d);
+			pud_free(&init_mm, pud);
+		}
+
+		p4d = (p4d_t *)pgd_page_vaddr(*pgd);
+		p4d_free(&init_mm, p4d);
+	}
+
 	kfree(save_pgd);
 
 	__flush_tlb_all();

commit d3b5d35290d729a2518af00feca867385a1b08fa
Merge: aa2a4b6569d5 71389703839e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 23:54:56 2017 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm updates from Ingo Molnar:
     "The main x86 MM changes in this cycle were:
    
       - continued native kernel PCID support preparation patches to the TLB
         flushing code (Andy Lutomirski)
    
       - various fixes related to 32-bit compat syscall returning address
         over 4Gb in applications, launched from 64-bit binaries - motivated
         by C/R frameworks such as Virtuozzo. (Dmitry Safonov)
    
       - continued Intel 5-level paging enablement: in particular the
         conversion of x86 GUP to the generic GUP code. (Kirill A. Shutemov)
    
       - x86/mpx ABI corner case fixes/enhancements (Joerg Roedel)
    
       - ... plus misc updates, fixes and cleanups"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (62 commits)
      mm, zone_device: Replace {get, put}_zone_device_page() with a single reference to fix pmem crash
      x86/mm: Fix flush_tlb_page() on Xen
      x86/mm: Make flush_tlb_mm_range() more predictable
      x86/mm: Remove flush_tlb() and flush_tlb_current_task()
      x86/vm86/32: Switch to flush_tlb_mm_range() in mark_screen_rdonly()
      x86/mm/64: Fix crash in remove_pagetable()
      Revert "x86/mm/gup: Switch GUP to the generic get_user_page_fast() implementation"
      x86/boot/e820: Remove a redundant self assignment
      x86/mm: Fix dump pagetables for 4 levels of page tables
      x86/mpx, selftests: Only check bounds-vs-shadow when we keep shadow
      x86/mpx: Correctly report do_mpx_bt_fault() failures to user-space
      Revert "x86/mm/numa: Remove numa_nodemask_from_meminfo()"
      x86/espfix: Add support for 5-level paging
      x86/kasan: Extend KASAN to support 5-level paging
      x86/mm: Add basic defines/helpers for CONFIG_X86_5LEVEL=y
      x86/paravirt: Add 5-level support to the paravirt code
      x86/mm: Define virtual memory map for 5-level paging
      x86/asm: Remove __VIRTUAL_MASK_SHIFT==47 assert
      x86/boot: Detect 5-level paging support
      x86/mm/numa: Remove numa_nodemask_from_meminfo()
      ...

commit 16b76293c5c81e6345323d7aef41b26e8390f62d
Merge: 3dee9fb2a4ce da63b6b20077
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 20:51:12 2017 -0700

    Merge branch 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 boot updates from Ingo Molnar:
     "The biggest changes in this cycle were:
    
       - reworking of the e820 code: separate in-kernel and boot-ABI data
         structures and apply a whole range of cleanups to the kernel side.
    
         No change in functionality.
    
       - enable KASLR by default: it's used by all major distros and it's
         out of the experimental stage as well.
    
       - ... misc fixes and cleanups"
    
    * 'x86-boot-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (63 commits)
      x86/KASLR: Fix kexec kernel boot crash when KASLR randomization fails
      x86/reboot: Turn off KVM when halting a CPU
      x86/boot: Fix BSS corruption/overwrite bug in early x86 kernel startup
      x86: Enable KASLR by default
      boot/param: Move next_arg() function to lib/cmdline.c for later reuse
      x86/boot: Fix Sparse warning by including required header file
      x86/boot/64: Rename start_cpu()
      x86/xen: Update e820 table handling to the new core x86 E820 code
      x86/boot: Fix pr_debug() API braindamage
      xen, x86/headers: Add <linux/device.h> dependency to <asm/xen/page.h>
      x86/boot/e820: Simplify e820__update_table()
      x86/boot/e820: Separate the E820 ABI structures from the in-kernel structures
      x86/boot/e820: Fix and clean up e820_type switch() statements
      x86/boot/e820: Rename the remaining E820 APIs to the e820__*() prefix
      x86/boot/e820: Remove unnecessary #include's
      x86/boot/e820: Rename e820_mark_nosave_regions() to e820__register_nosave_regions()
      x86/boot/e820: Rename e820_reserve_resources*() to e820__reserve_resources*()
      x86/boot/e820: Use bool in query APIs
      x86/boot/e820: Document e820__reserve_setup_data()
      x86/boot/e820: Clean up __e820__update_table() et al
      ...

commit e5185a76a23b2d56fb2327ad8bd58fb1bcaa52b1
Merge: b678c91aefa7 4729277156cf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Apr 11 08:56:05 2017 +0200

    Merge branch 'x86/boot' into x86/mm, to avoid conflict
    
    There's a conflict between ongoing level-5 paging support and
    the E820 rewrite. Since the E820 rewrite is essentially ready,
    merge it into x86/mm to reduce tree conflicts.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b1d1776139698d7522dfd46aa81a056f030ddaf7
Author: Baoquan He <bhe@redhat.com>
Date:   Tue Apr 4 17:02:43 2017 +0100

    x86/efi: Clean up a minor mistake in comment
    
    EFI allocates runtime services regions from EFI_VA_START, -4G, down
    to -68G, EFI_VA_END - 64G altogether, top-down.
    
    The mechanism was introduced in commit:
    
      d2f7cbe7b26a7 ("x86/efi: Runtime services virtual mapping")
    
    Fix the comment that still says bottom-up.
    
    Signed-off-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170404160245.27812-10-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a4695da42d77..6cbf9e036aa8 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -47,7 +47,7 @@
 #include <asm/pgalloc.h>
 
 /*
- * We allocate runtime services regions bottom-up, starting from -4G, i.e.
+ * We allocate runtime services regions top-down, starting from -4G, i.e.
  * 0xffff_ffff_0000_0000 and limit EFI VA mapping space to 64G.
  */
 static u64 efi_va = EFI_VA_START;

commit e981316f560482c001dede7f5b29259bde0b8afb
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Mar 17 21:55:11 2017 +0300

    x86/efi: Add 5-level paging support
    
    Allocate additional page table level and ajdust efi_sync_low_kernel_mappings()
    to work with additional page table level.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20170317185515.8636-3-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 8544dae3d1b4..eb64e5b33e37 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -135,6 +135,7 @@ static pgd_t *efi_pgd;
 int __init efi_alloc_page_tables(void)
 {
 	pgd_t *pgd;
+	p4d_t *p4d;
 	pud_t *pud;
 	gfp_t gfp_mask;
 
@@ -147,15 +148,20 @@ int __init efi_alloc_page_tables(void)
 		return -ENOMEM;
 
 	pgd = efi_pgd + pgd_index(EFI_VA_END);
+	p4d = p4d_alloc(&init_mm, pgd, EFI_VA_END);
+	if (!p4d) {
+		free_page((unsigned long)efi_pgd);
+		return -ENOMEM;
+	}
 
-	pud = pud_alloc_one(NULL, 0);
+	pud = pud_alloc(&init_mm, p4d, EFI_VA_END);
 	if (!pud) {
+		if (CONFIG_PGTABLE_LEVELS > 4)
+			free_page((unsigned long) pgd_page_vaddr(*pgd));
 		free_page((unsigned long)efi_pgd);
 		return -ENOMEM;
 	}
 
-	pgd_populate(NULL, pgd, pud);
-
 	return 0;
 }
 
@@ -190,6 +196,21 @@ void efi_sync_low_kernel_mappings(void)
 	num_entries = pgd_index(EFI_VA_END) - pgd_index(PAGE_OFFSET);
 	memcpy(pgd_efi, pgd_k, sizeof(pgd_t) * num_entries);
 
+	/*
+	 * As with PGDs, we share all P4D entries apart from the one entry
+	 * that covers the EFI runtime mapping space.
+	 */
+	BUILD_BUG_ON(p4d_index(EFI_VA_END) != p4d_index(MODULES_END));
+	BUILD_BUG_ON((EFI_VA_START & P4D_MASK) != (EFI_VA_END & P4D_MASK));
+
+	pgd_efi = efi_pgd + pgd_index(EFI_VA_END);
+	pgd_k = pgd_offset_k(EFI_VA_END);
+	p4d_efi = p4d_offset(pgd_efi, 0);
+	p4d_k = p4d_offset(pgd_k, 0);
+
+	num_entries = p4d_index(EFI_VA_END);
+	memcpy(p4d_efi, p4d_k, sizeof(p4d_t) * num_entries);
+
 	/*
 	 * We share all the PUD entries apart from those that map the
 	 * EFI regions. Copy around them.
@@ -197,20 +218,15 @@ void efi_sync_low_kernel_mappings(void)
 	BUILD_BUG_ON((EFI_VA_START & ~PUD_MASK) != 0);
 	BUILD_BUG_ON((EFI_VA_END & ~PUD_MASK) != 0);
 
-	pgd_efi = efi_pgd + pgd_index(EFI_VA_END);
-	p4d_efi = p4d_offset(pgd_efi, 0);
+	p4d_efi = p4d_offset(pgd_efi, EFI_VA_END);
+	p4d_k = p4d_offset(pgd_k, EFI_VA_END);
 	pud_efi = pud_offset(p4d_efi, 0);
-
-	pgd_k = pgd_offset_k(EFI_VA_END);
-	p4d_k = p4d_offset(pgd_k, 0);
 	pud_k = pud_offset(p4d_k, 0);
 
 	num_entries = pud_index(EFI_VA_END);
 	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);
 
-	p4d_efi = p4d_offset(pgd_efi, EFI_VA_START);
 	pud_efi = pud_offset(p4d_efi, EFI_VA_START);
-	p4d_k = p4d_offset(pgd_k, EFI_VA_START);
 	pud_k = pud_offset(p4d_k, EFI_VA_START);
 
 	num_entries = PTRS_PER_PUD - pud_index(EFI_VA_START);

commit e0c4f6750e130541cca7390739d25feb522acfff
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Mon Mar 13 17:33:05 2017 +0300

    x86/mm: Convert trivial cases of page table walk to 5-level paging
    
    This patch only covers simple cases. Less trivial cases will be
    converted with separate patches.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20170313143309.16020-3-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a4695da42d77..8544dae3d1b4 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -166,6 +166,7 @@ void efi_sync_low_kernel_mappings(void)
 {
 	unsigned num_entries;
 	pgd_t *pgd_k, *pgd_efi;
+	p4d_t *p4d_k, *p4d_efi;
 	pud_t *pud_k, *pud_efi;
 
 	if (efi_enabled(EFI_OLD_MEMMAP))
@@ -197,16 +198,20 @@ void efi_sync_low_kernel_mappings(void)
 	BUILD_BUG_ON((EFI_VA_END & ~PUD_MASK) != 0);
 
 	pgd_efi = efi_pgd + pgd_index(EFI_VA_END);
-	pud_efi = pud_offset(pgd_efi, 0);
+	p4d_efi = p4d_offset(pgd_efi, 0);
+	pud_efi = pud_offset(p4d_efi, 0);
 
 	pgd_k = pgd_offset_k(EFI_VA_END);
-	pud_k = pud_offset(pgd_k, 0);
+	p4d_k = p4d_offset(pgd_k, 0);
+	pud_k = pud_offset(p4d_k, 0);
 
 	num_entries = pud_index(EFI_VA_END);
 	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);
 
-	pud_efi = pud_offset(pgd_efi, EFI_VA_START);
-	pud_k = pud_offset(pgd_k, EFI_VA_START);
+	p4d_efi = p4d_offset(pgd_efi, EFI_VA_START);
+	pud_efi = pud_offset(p4d_efi, EFI_VA_START);
+	p4d_k = p4d_offset(pgd_k, EFI_VA_START);
+	pud_k = pud_offset(p4d_k, EFI_VA_START);
 
 	num_entries = PTRS_PER_PUD - pud_index(EFI_VA_START);
 	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);

commit 0871d5a66da5c41151e0896a90298b163e42f2e0
Merge: e22af0be2cf6 2d6be4abf514
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Mar 1 09:02:26 2017 +0100

    Merge branch 'linus' into WIP.x86/boot, to fix up conflicts and to pick up updates
    
     Conflicts:
            arch/x86/xen/setup.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 18141e89a76c58101860486fd9cc0999da2eed43
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Tue Jan 31 13:21:37 2017 +0000

    x86/efi: Add support for EFI_MEMORY_ATTRIBUTES_TABLE
    
    UEFI v2.6 introduces EFI_MEMORY_ATTRIBUTES_TABLE which describes memory
    protections that may be applied to the EFI Runtime code and data regions by
    the kernel. This enables the kernel to map these regions more strictly thereby
    increasing security.
    
    Presently, the only valid bits for the attribute field of a memory descriptor
    are EFI_MEMORY_RO and EFI_MEMORY_XP, hence use these bits to update the
    mappings in efi_pgd.
    
    The UEFI specification recommends to use this feature instead of
    EFI_PROPERTIES_TABLE and hence while updating EFI mappings we first
    check for EFI_MEMORY_ATTRIBUTES_TABLE and if it's present we update
    the mappings according to this table and hence disregarding
    EFI_PROPERTIES_TABLE even if it's published by the firmware. We consider
    EFI_PROPERTIES_TABLE only when EFI_MEMORY_ATTRIBUTES_TABLE is absent.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1485868902-20401-6-git-send-email-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 2f25a363068c..a4695da42d77 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -414,10 +414,44 @@ void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 	efi_setup = phys_addr + sizeof(struct setup_data);
 }
 
-void __init efi_runtime_update_mappings(void)
+static int __init efi_update_mappings(efi_memory_desc_t *md, unsigned long pf)
 {
 	unsigned long pfn;
 	pgd_t *pgd = efi_pgd;
+	int err1, err2;
+
+	/* Update the 1:1 mapping */
+	pfn = md->phys_addr >> PAGE_SHIFT;
+	err1 = kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, md->num_pages, pf);
+	if (err1) {
+		pr_err("Error while updating 1:1 mapping PA 0x%llx -> VA 0x%llx!\n",
+			   md->phys_addr, md->virt_addr);
+	}
+
+	err2 = kernel_map_pages_in_pgd(pgd, pfn, md->virt_addr, md->num_pages, pf);
+	if (err2) {
+		pr_err("Error while updating VA mapping PA 0x%llx -> VA 0x%llx!\n",
+			   md->phys_addr, md->virt_addr);
+	}
+
+	return err1 || err2;
+}
+
+static int __init efi_update_mem_attr(struct mm_struct *mm, efi_memory_desc_t *md)
+{
+	unsigned long pf = 0;
+
+	if (md->attribute & EFI_MEMORY_XP)
+		pf |= _PAGE_NX;
+
+	if (!(md->attribute & EFI_MEMORY_RO))
+		pf |= _PAGE_RW;
+
+	return efi_update_mappings(md, pf);
+}
+
+void __init efi_runtime_update_mappings(void)
+{
 	efi_memory_desc_t *md;
 
 	if (efi_enabled(EFI_OLD_MEMMAP)) {
@@ -426,6 +460,24 @@ void __init efi_runtime_update_mappings(void)
 		return;
 	}
 
+	/*
+	 * Use the EFI Memory Attribute Table for mapping permissions if it
+	 * exists, since it is intended to supersede EFI_PROPERTIES_TABLE.
+	 */
+	if (efi_enabled(EFI_MEM_ATTR)) {
+		efi_memattr_apply_permissions(NULL, efi_update_mem_attr);
+		return;
+	}
+
+	/*
+	 * EFI_MEMORY_ATTRIBUTES_TABLE is intended to replace
+	 * EFI_PROPERTIES_TABLE. So, use EFI_PROPERTIES_TABLE to update
+	 * permissions only if EFI_MEMORY_ATTRIBUTES_TABLE is not
+	 * published by the firmware. Even if we find a buggy implementation of
+	 * EFI_MEMORY_ATTRIBUTES_TABLE, don't fall back to
+	 * EFI_PROPERTIES_TABLE, because of the same reason.
+	 */
+
 	if (!efi_enabled(EFI_NX_PE_DATA))
 		return;
 
@@ -446,15 +498,7 @@ void __init efi_runtime_update_mappings(void)
 			(md->type != EFI_RUNTIME_SERVICES_CODE))
 			pf |= _PAGE_RW;
 
-		/* Update the 1:1 mapping */
-		pfn = md->phys_addr >> PAGE_SHIFT;
-		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, md->num_pages, pf))
-			pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
-				   md->phys_addr, md->virt_addr);
-
-		if (kernel_map_pages_in_pgd(pgd, pfn, md->virt_addr, md->num_pages, pf))
-			pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
-				   md->phys_addr, md->virt_addr);
+		efi_update_mappings(md, pf);
 	}
 }
 

commit 66441bd3cfdcc03816b7009a296c284d70f629e1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jan 27 10:27:10 2017 +0100

    x86/boot/e820: Move asm/e820.h to asm/e820/api.h
    
    In line with asm/e820/types.h, move the e820 API declarations to
    asm/e820/api.h and update all usage sites.
    
    This is just a mechanical, obviously correct move & replace patch,
    there will be subsequent changes to clean up the code and to make
    better use of the new header organization.
    
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Jackson <pj@sgi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wei Yang <richard.weiyang@gmail.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 319148bd4b05..2cc992be0070 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -35,7 +35,7 @@
 
 #include <asm/setup.h>
 #include <asm/page.h>
-#include <asm/e820.h>
+#include <asm/e820/api.h>
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>
 #include <asm/proto.h>

commit bf29bddf0417a4783da3b24e8c9e017ac649326f
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Fri Jan 27 22:25:52 2017 +0000

    x86/efi: Always map the first physical page into the EFI pagetables
    
    Commit:
    
      129766708 ("x86/efi: Only map RAM into EFI page tables if in mixed-mode")
    
    stopped creating 1:1 mappings for all RAM, when running in native 64-bit mode.
    
    It turns out though that there are 64-bit EFI implementations in the wild
    (this particular problem has been reported on a Lenovo Yoga 710-11IKB),
    which still make use of the first physical page for their own private use,
    even though they explicitly mark it EFI_CONVENTIONAL_MEMORY in the memory
    map.
    
    In case there is no mapping for this particular frame in the EFI pagetables,
    as soon as firmware tries to make use of it, a triple fault occurs and the
    system reboots (in case of the Yoga 710-11IKB this is very early during bootup).
    
    Fix that by always mapping the first page of physical memory into the EFI
    pagetables. We're free to hand this page to the BIOS, as trim_bios_range()
    will reserve the first page and isolate it away from memory allocators anyway.
    
    Note that just reverting 129766708 alone is not enough on v4.9-rc1+ to fix the
    regression on affected hardware, as this commit:
    
       ab72a27da ("x86/efi: Consolidate region mapping logic")
    
    later made the first physical frame not to be mapped anyway.
    
    Reported-by: Hanka Pavlikova <hanka@ucw.cz>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vojtech Pavlik <vojtech@ucw.cz>
    Cc: Waiman Long <waiman.long@hpe.com>
    Cc: linux-efi@vger.kernel.org
    Cc: stable@kernel.org # v4.8+
    Fixes: 129766708 ("x86/efi: Only map RAM into EFI page tables if in mixed-mode")
    Link: http://lkml.kernel.org/r/20170127222552.22336-1-matt@codeblueprint.co.uk
    [ Tidied up the changelog and the comment. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 319148bd4b05..2f25a363068c 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -268,6 +268,22 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 	efi_scratch.use_pgd = true;
 
+	/*
+	 * Certain firmware versions are way too sentimential and still believe
+	 * they are exclusive and unquestionable owners of the first physical page,
+	 * even though they explicitly mark it as EFI_CONVENTIONAL_MEMORY
+	 * (but then write-access it later during SetVirtualAddressMap()).
+	 *
+	 * Create a 1:1 mapping for this page, to avoid triple faults during early
+	 * boot with such firmware. We are free to hand this page to the BIOS,
+	 * as trim_bios_range() will reserve the first page and isolate it away
+	 * from memory allocators anyway.
+	 */
+	if (kernel_map_pages_in_pgd(pgd, 0x0, 0x0, 1, _PAGE_RW)) {
+		pr_err("Failed to create 1:1 mapping for the first page!\n");
+		return 1;
+	}
+
 	/*
 	 * When making calls to the firmware everything needs to be 1:1
 	 * mapped and addressable with 32-bit pointers. Map the kernel

commit f6697df36bdf0bf7fce984605c2918d4a7b4269f
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Sat Nov 12 21:04:24 2016 +0000

    x86/efi: Prevent mixed mode boot corruption with CONFIG_VMAP_STACK=y
    
    Booting an EFI mixed mode kernel has been crashing since commit:
    
      e37e43a497d5 ("x86/mm/64: Enable vmapped stacks (CONFIG_HAVE_ARCH_VMAP_STACK=y)")
    
    The user-visible effect in my test setup was the kernel being unable
    to find the root file system ramdisk. This was likely caused by silent
    memory or page table corruption.
    
    Enabling CONFIG_DEBUG_VIRTUAL=y immediately flagged the thunking code as
    abusing virt_to_phys() because it was passing addresses that were not
    part of the kernel direct mapping.
    
    Use the slow version instead, which correctly handles all memory
    regions by performing a page table walk.
    
    Suggested-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20161112210424.5157-3-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 58b0f801f66f..319148bd4b05 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -31,6 +31,7 @@
 #include <linux/io.h>
 #include <linux/reboot.h>
 #include <linux/slab.h>
+#include <linux/ucs2_string.h>
 
 #include <asm/setup.h>
 #include <asm/page.h>
@@ -211,6 +212,35 @@ void efi_sync_low_kernel_mappings(void)
 	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);
 }
 
+/*
+ * Wrapper for slow_virt_to_phys() that handles NULL addresses.
+ */
+static inline phys_addr_t
+virt_to_phys_or_null_size(void *va, unsigned long size)
+{
+	bool bad_size;
+
+	if (!va)
+		return 0;
+
+	if (virt_addr_valid(va))
+		return virt_to_phys(va);
+
+	/*
+	 * A fully aligned variable on the stack is guaranteed not to
+	 * cross a page bounary. Try to catch strings on the stack by
+	 * checking that 'size' is a power of two.
+	 */
+	bad_size = size > PAGE_SIZE || !is_power_of_2(size);
+
+	WARN_ON(!IS_ALIGNED((unsigned long)va, size) || bad_size);
+
+	return slow_virt_to_phys(va);
+}
+
+#define virt_to_phys_or_null(addr)				\
+	virt_to_phys_or_null_size((addr), sizeof(*(addr)))
+
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
 	unsigned long pfn, text;
@@ -494,8 +524,8 @@ static efi_status_t efi_thunk_get_time(efi_time_t *tm, efi_time_cap_t *tc)
 
 	spin_lock(&rtc_lock);
 
-	phys_tm = virt_to_phys(tm);
-	phys_tc = virt_to_phys(tc);
+	phys_tm = virt_to_phys_or_null(tm);
+	phys_tc = virt_to_phys_or_null(tc);
 
 	status = efi_thunk(get_time, phys_tm, phys_tc);
 
@@ -511,7 +541,7 @@ static efi_status_t efi_thunk_set_time(efi_time_t *tm)
 
 	spin_lock(&rtc_lock);
 
-	phys_tm = virt_to_phys(tm);
+	phys_tm = virt_to_phys_or_null(tm);
 
 	status = efi_thunk(set_time, phys_tm);
 
@@ -529,9 +559,9 @@ efi_thunk_get_wakeup_time(efi_bool_t *enabled, efi_bool_t *pending,
 
 	spin_lock(&rtc_lock);
 
-	phys_enabled = virt_to_phys(enabled);
-	phys_pending = virt_to_phys(pending);
-	phys_tm = virt_to_phys(tm);
+	phys_enabled = virt_to_phys_or_null(enabled);
+	phys_pending = virt_to_phys_or_null(pending);
+	phys_tm = virt_to_phys_or_null(tm);
 
 	status = efi_thunk(get_wakeup_time, phys_enabled,
 			     phys_pending, phys_tm);
@@ -549,7 +579,7 @@ efi_thunk_set_wakeup_time(efi_bool_t enabled, efi_time_t *tm)
 
 	spin_lock(&rtc_lock);
 
-	phys_tm = virt_to_phys(tm);
+	phys_tm = virt_to_phys_or_null(tm);
 
 	status = efi_thunk(set_wakeup_time, enabled, phys_tm);
 
@@ -558,6 +588,10 @@ efi_thunk_set_wakeup_time(efi_bool_t enabled, efi_time_t *tm)
 	return status;
 }
 
+static unsigned long efi_name_size(efi_char16_t *name)
+{
+	return ucs2_strsize(name, EFI_VAR_NAME_LEN) + 1;
+}
 
 static efi_status_t
 efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
@@ -567,11 +601,11 @@ efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
 	u32 phys_name, phys_vendor, phys_attr;
 	u32 phys_data_size, phys_data;
 
-	phys_data_size = virt_to_phys(data_size);
-	phys_vendor = virt_to_phys(vendor);
-	phys_name = virt_to_phys(name);
-	phys_attr = virt_to_phys(attr);
-	phys_data = virt_to_phys(data);
+	phys_data_size = virt_to_phys_or_null(data_size);
+	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
+	phys_attr = virt_to_phys_or_null(attr);
+	phys_data = virt_to_phys_or_null_size(data, *data_size);
 
 	status = efi_thunk(get_variable, phys_name, phys_vendor,
 			   phys_attr, phys_data_size, phys_data);
@@ -586,9 +620,9 @@ efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
 	u32 phys_name, phys_vendor, phys_data;
 	efi_status_t status;
 
-	phys_name = virt_to_phys(name);
-	phys_vendor = virt_to_phys(vendor);
-	phys_data = virt_to_phys(data);
+	phys_name = virt_to_phys_or_null_size(name, efi_name_size(name));
+	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_data = virt_to_phys_or_null_size(data, data_size);
 
 	/* If data_size is > sizeof(u32) we've got problems */
 	status = efi_thunk(set_variable, phys_name, phys_vendor,
@@ -605,9 +639,9 @@ efi_thunk_get_next_variable(unsigned long *name_size,
 	efi_status_t status;
 	u32 phys_name_size, phys_name, phys_vendor;
 
-	phys_name_size = virt_to_phys(name_size);
-	phys_vendor = virt_to_phys(vendor);
-	phys_name = virt_to_phys(name);
+	phys_name_size = virt_to_phys_or_null(name_size);
+	phys_vendor = virt_to_phys_or_null(vendor);
+	phys_name = virt_to_phys_or_null_size(name, *name_size);
 
 	status = efi_thunk(get_next_variable, phys_name_size,
 			   phys_name, phys_vendor);
@@ -621,7 +655,7 @@ efi_thunk_get_next_high_mono_count(u32 *count)
 	efi_status_t status;
 	u32 phys_count;
 
-	phys_count = virt_to_phys(count);
+	phys_count = virt_to_phys_or_null(count);
 	status = efi_thunk(get_next_high_mono_count, phys_count);
 
 	return status;
@@ -633,7 +667,7 @@ efi_thunk_reset_system(int reset_type, efi_status_t status,
 {
 	u32 phys_data;
 
-	phys_data = virt_to_phys(data);
+	phys_data = virt_to_phys_or_null_size(data, data_size);
 
 	efi_thunk(reset_system, reset_type, status, data_size, phys_data);
 }
@@ -661,9 +695,9 @@ efi_thunk_query_variable_info(u32 attr, u64 *storage_space,
 	if (efi.runtime_version < EFI_2_00_SYSTEM_TABLE_REVISION)
 		return EFI_UNSUPPORTED;
 
-	phys_storage = virt_to_phys(storage_space);
-	phys_remaining = virt_to_phys(remaining_space);
-	phys_max = virt_to_phys(max_variable_size);
+	phys_storage = virt_to_phys_or_null(storage_space);
+	phys_remaining = virt_to_phys_or_null(remaining_space);
+	phys_max = virt_to_phys_or_null(max_variable_size);
 
 	status = efi_thunk(query_variable_info, attr, phys_storage,
 			   phys_remaining, phys_max);

commit 41a66072c32978ff3914fd6be88f7592ef64bef7
Merge: 5465fe0fc331 7597cdc06631
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Sep 20 16:58:59 2016 +0200

    Merge branch 'efi/urgent' into efi/core, to pick up fixes
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 1297667083d5442aafe3e337b9413bf02b114edb
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Mon Sep 19 13:09:09 2016 +0100

    x86/efi: Only map RAM into EFI page tables if in mixed-mode
    
    Waiman reported that booting with CONFIG_EFI_MIXED enabled on his
    multi-terabyte HP machine results in boot crashes, because the EFI
    region mapping functions loop forever while trying to map those
    regions describing RAM.
    
    While this patch doesn't fix the underlying hang, there's really no
    reason to map EFI_CONVENTIONAL_MEMORY regions into the EFI page tables
    when mixed-mode is not in use at runtime.
    
    Reported-by: Waiman Long <waiman.long@hpe.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    CC: Theodore Ts'o <tytso@mit.edu>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Scott J Norton <scott.norton@hpe.com>
    Cc: Douglas Hatch <doug.hatch@hpe.com>
    Cc: <stable@vger.kernel.org> # v4.6+
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 677e29e29473..8dd3784eb075 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -245,7 +245,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * text and allocate a new stack because we can't rely on the
 	 * stack pointer being < 4GB.
 	 */
-	if (!IS_ENABLED(CONFIG_EFI_MIXED))
+	if (!IS_ENABLED(CONFIG_EFI_MIXED) || efi_is_native())
 		return 0;
 
 	/*

commit 20ebc15e6c8f9772804fa10110bf074a7b1d25fa
Author: Markus Elfring <elfring@users.sourceforge.net>
Date:   Thu Aug 25 11:34:03 2016 +0200

    x86/efi: Use kmalloc_array() in efi_call_phys_prolog()
    
    * A multiplication for the size determination of a memory allocation
      indicated that an array data structure should be processed.
      Thus reuse the corresponding function "kmalloc_array".
    
      This issue was detected by using the Coccinelle software.
    
    * Replace the specification of a data type by a pointer dereference
      to make the corresponding size determination a bit safer according to
      the Linux coding style convention.
    
    Signed-off-by: Markus Elfring <elfring@users.sourceforge.net>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Julia Lawall <julia.lawall@lip6.fr>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e1ca71259468..d65cdadaa6b6 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -85,7 +85,7 @@ pgd_t * __init efi_call_phys_prolog(void)
 	early_code_mapping_set_exec(1);
 
 	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
-	save_pgd = kmalloc(n_pgds * sizeof(pgd_t), GFP_KERNEL);
+	save_pgd = kmalloc_array(n_pgds, sizeof(*save_pgd), GFP_KERNEL);
 
 	for (pgd = 0; pgd < n_pgds; pgd++) {
 		save_pgd[pgd] = *pgd_offset_k(pgd * PGDIR_SIZE);

commit 0513fe1d28e45deb39159dbeedf0660c3f0effd2
Author: Alex Thorlton <athorlton@sgi.com>
Date:   Fri Aug 5 18:59:35 2016 -0500

    x86/efi: Map in physical addresses in efi_map_region_fixed
    
    This is a simple change to add in the physical mappings as well as the
    virtual mappings in efi_map_region_fixed.  The motivation here is to
    get access to EFI runtime code that is only available via the 1:1
    mappings on a kexec'd kernel.
    
    The added call is essentially the kexec analog of the first __map_region
    that Boris put in efi_map_region in commit d2f7cbe7b26a ("x86/efi:
    Runtime services virtual mapping").
    
    Signed-off-by: Alex Thorlton <athorlton@sgi.com>
    Cc: Russ Anderson <rja@sgi.com>
    Cc: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Mike Travis <travis@sgi.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 45434ea345e9..e1ca71259468 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -339,6 +339,7 @@ void __init efi_map_region(efi_memory_desc_t *md)
  */
 void __init efi_map_region_fixed(efi_memory_desc_t *md)
 {
+	__map_region(md, md->phys_addr);
 	__map_region(md, md->virt_addr);
 }
 

commit ab72a27da4c6c19b0e3d6d7556fdd4afb581c8ac
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Mon Jun 20 14:36:51 2016 +0100

    x86/efi: Consolidate region mapping logic
    
    EFI regions are currently mapped in two separate places. The bulk of
    the work is done in efi_map_regions() but when CONFIG_EFI_MIXED is
    enabled the additional regions that are required when operating in
    mixed mode are mapping in efi_setup_page_tables().
    
    Pull everything into efi_map_regions() and refactor the test for
    which regions should be mapped into a should_map_region() function.
    Generously sprinkle comments to clarify the different cases.
    
    Acked-by: Borislav Petkov <bp@suse.de>
    Tested-by: Dave Young <dyoung@redhat.com> [kexec/kdump]
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org> [arm]
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 677e29e29473..45434ea345e9 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -214,7 +214,6 @@ void efi_sync_low_kernel_mappings(void)
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
 	unsigned long pfn, text;
-	efi_memory_desc_t *md;
 	struct page *page;
 	unsigned npages;
 	pgd_t *pgd;
@@ -248,25 +247,6 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	if (!IS_ENABLED(CONFIG_EFI_MIXED))
 		return 0;
 
-	/*
-	 * Map all of RAM so that we can access arguments in the 1:1
-	 * mapping when making EFI runtime calls.
-	 */
-	for_each_efi_memory_desc(md) {
-		if (md->type != EFI_CONVENTIONAL_MEMORY &&
-		    md->type != EFI_LOADER_DATA &&
-		    md->type != EFI_LOADER_CODE)
-			continue;
-
-		pfn = md->phys_addr >> PAGE_SHIFT;
-		npages = md->num_pages;
-
-		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, npages, _PAGE_RW)) {
-			pr_err("Failed to map 1:1 memory\n");
-			return 1;
-		}
-	}
-
 	page = alloc_page(GFP_KERNEL|__GFP_DMA32);
 	if (!page)
 		panic("Unable to allocate EFI runtime stack < 4GB\n");

commit 6c84239d595dc6ffe39f0f03dae2f64ed200db95
Merge: d4c06c708123 6f367788d633
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 5 09:48:22 2016 -0400

    Merge tag 'rtc-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux
    
    Pull RTC updates from Alexandre Belloni:
     "RTC for 4.8
    
      Cleanups:
       - huge cleanup of rtc-generic and char/genrtc this allowed to cleanup
         rtc-cmos, rtc-sh, rtc-m68k, rtc-powerpc and rtc-parisc
       - move mn10300 to rtc-cmos
    
      Subsystem:
       - fix wakealarms after hibernate
       - multiples fixes for rctest
       - simplify implementations of .read_alarm
    
      New drivers:
       - Maxim MAX6916
    
      Drivers:
       - ds1307: fix weekday
       - m41t80: add wakeup support
       - pcf85063: add support for PCF85063A variant
       - rv8803: extend i2c fix and other fixes
       - s35390a: fix alarm reading, this fixes instant reboot after
         shutdown for QNAP TS-41x
       - s3c: clock fixes"
    
    * tag 'rtc-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux: (65 commits)
      rtc: rv8803: Clear V1F when setting the time
      rtc: rv8803: Stop the clock while setting the time
      rtc: rv8803: Always apply the I²C workaround
      rtc: rv8803: Fix read day of week
      rtc: rv8803: Remove the check for valid time
      rtc: rv8803: Kconfig: Indicate rx8900 support
      rtc: asm9260: remove .owner field for driver
      rtc: at91sam9: Fix missing spin_lock_init()
      rtc: m41t80: add suspend handlers for alarm IRQ
      rtc: m41t80: make it a real error message
      rtc: pcf85063: Add support for the PCF85063A device
      rtc: pcf85063: fix year range
      rtc: hym8563: in .read_alarm set .tm_sec to 0 to signal minute accuracy
      rtc: explicitly set tm_sec = 0 for drivers with minute accurancy
      rtc: s3c: Add s3c_rtc_{enable/disable}_clk in s3c_rtc_setfreq()
      rtc: s3c: Remove unnecessary call to disable already disabled clock
      rtc: abx80x: use devm_add_action_or_reset()
      rtc: m41t80: use devm_add_action_or_reset()
      rtc: fix a typo and reduce three empty lines to one
      rtc: s35390a: improve two comments in .set_alarm
      ...

commit aeb35d6b74174ed08daab84e232b456bbd89d1d9
Merge: 7a66ecfd319a a47177d360a2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 1 14:23:42 2016 -0400

    Merge branch 'x86-headers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 header cleanups from Ingo Molnar:
     "This tree is a cleanup of the x86 tree reducing spurious uses of
      module.h - which should improve build performance a bit"
    
    * 'x86-headers-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, crypto: Restore MODULE_LICENSE() to glue_helper.c so it loads
      x86/apic: Remove duplicated include from probe_64.c
      x86/ce4100: Remove duplicated include from ce4100.c
      x86/headers: Include spinlock_types.h in x8664_ksyms_64.c for missing spinlock_t
      x86/platform: Delete extraneous MODULE_* tags fromm ts5500
      x86: Audit and remove any remaining unnecessary uses of module.h
      x86/kvm: Audit and remove any unnecessary uses of module.h
      x86/xen: Audit and remove any unnecessary uses of module.h
      x86/platform: Audit and remove any unnecessary uses of module.h
      x86/lib: Audit and remove any unnecessary uses of module.h
      x86/kernel: Audit and remove any unnecessary uses of module.h
      x86/mm: Audit and remove any unnecessary uses of module.h
      x86: Don't use module.h just for AUTHOR / LICENSE tags

commit 0f657262d5f99ad86b9a63fb5dcd29036c2ed916
Merge: 425dbc6db34d 55920d31f1e3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 25 15:34:18 2016 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm updates from Ingo Molnar:
     "Various x86 low level modifications:
    
       - preparatory work to support virtually mapped kernel stacks (Andy
         Lutomirski)
    
       - support for 64-bit __get_user() on 32-bit kernels (Benjamin
         LaHaise)
    
       - (involved) workaround for Knights Landing CPU erratum (Dave Hansen)
    
       - MPX enhancements (Dave Hansen)
    
       - mremap() extension to allow remapping of the special VDSO vma, for
         purposes of user level context save/restore (Dmitry Safonov)
    
       - hweight and entry code cleanups (Borislav Petkov)
    
       - bitops code generation optimizations and cleanups with modern GCC
         (H. Peter Anvin)
    
       - syscall entry code optimizations (Paolo Bonzini)"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (43 commits)
      x86/mm/cpa: Add missing comment in populate_pdg()
      x86/mm/cpa: Fix populate_pgd(): Stop trying to deallocate failed PUDs
      x86/syscalls: Add compat_sys_preadv64v2/compat_sys_pwritev64v2
      x86/smp: Remove unnecessary initialization of thread_info::cpu
      x86/smp: Remove stack_smp_processor_id()
      x86/uaccess: Move thread_info::addr_limit to thread_struct
      x86/dumpstack: Rename thread_struct::sig_on_uaccess_error to sig_on_uaccess_err
      x86/uaccess: Move thread_info::uaccess_err and thread_info::sig_on_uaccess_err to thread_struct
      x86/dumpstack: When OOPSing, rewind the stack before do_exit()
      x86/mm/64: In vmalloc_fault(), use CR3 instead of current->active_mm
      x86/dumpstack/64: Handle faults when printing the "Stack: " part of an OOPS
      x86/dumpstack: Try harder to get a call trace on stack overflow
      x86/mm: Remove kernel_unmap_pages_in_pgd() and efi_cleanup_page_tables()
      x86/mm/cpa: In populate_pgd(), don't set the PGD entry until it's populated
      x86/mm/hotplug: Don't remove PGD entries in remove_pagetable()
      x86/mm: Use pte_none() to test for empty PTE
      x86/mm: Disallow running with 32-bit PTEs to work around erratum
      x86/mm: Ignore A/D bits in pte/pmd/pud_none()
      x86/mm: Move swap offset/type up in PTE to work around erratum
      x86/entry: Inline enter_from_user_mode()
      ...

commit d92fc69ccac4c0a20679fdbdc81b2010685a6f33
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jul 14 13:22:51 2016 -0700

    x86/mm: Remove kernel_unmap_pages_in_pgd() and efi_cleanup_page_tables()
    
    kernel_unmap_pages_in_pgd() is dangerous: if a PGD entry in
    init_mm.pgd were to be cleared, callers would need to ensure that
    the pgd entry hadn't been propagated to any other pgd.
    
    Its only caller was efi_cleanup_page_tables(), and that, in turn,
    was unused, so just delete both functions.  This leaves a couple of
    other helpers unused, so delete them, too.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/77ff20fdde3b75cd393be5559ad8218870520248.1468527351.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b226b3f497f1..d288dcea1ffe 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -285,11 +285,6 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	return 0;
 }
 
-void __init efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
-{
-	kernel_unmap_pages_in_pgd(efi_pgd, pa_memmap, num_pages);
-}
-
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
 	unsigned long flags = _PAGE_RW;

commit cc3ae7b0af27118994c1e491382b253be3b762bf
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Jul 13 20:18:58 2016 -0400

    x86/platform: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.  The advantage
    in doing so is that module.h itself sources about 15 other headers;
    adding significantly to what we feed cpp, and it can obscure what
    headers we are effectively using.
    
    Since module.h was the source for init.h (for __init) and for
    export.h (for EXPORT_SYMBOL) we consider each obj-y/bool instance
    for the presence of either and replace as needed.
    
    One module.h was converted to moduleparam.h since the file had
    multiple module_param() in it, and another file had an instance of
    MODULE_DEVICE_TABLE deleted, since that is a no-op when builtin.
    
    Finally, the 32 bit build coverage of olpc_ofw revealed a couple
    implicit includes, which were pretty self evident to fix based on
    what gcc was complaining about.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20160714001901.31603-6-paul.gortmaker@windriver.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b226b3f497f1..2f984457b9e2 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -24,7 +24,7 @@
 #include <linux/spinlock.h>
 #include <linux/bootmem.h>
 #include <linux/ioport.h>
-#include <linux/module.h>
+#include <linux/init.h>
 #include <linux/efi.h>
 #include <linux/uaccess.h>
 #include <linux/io.h>

commit 21f866257c7027f8f49bfde83f559f9e58f9ee93
Author: Alex Thorlton <athorlton@sgi.com>
Date:   Sat Jun 25 08:20:29 2016 +0100

    x86/efi: Update efi_thunk() to use the the arch_efi_call_virt*() macros
    
    Currently, the efi_thunk macro has some semi-duplicated code in it that
    can be replaced with the arch_efi_call_virt_setup/teardown macros. This
    commit simply replaces the duplicated code with those macros.
    
    Suggested-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Alex Thorlton <athorlton@sgi.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roy Franz <roy.franz@linaro.org>
    Cc: Russ Anderson <rja@sgi.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1466839230-12781-7-git-send-email-matt@codeblueprint.co.uk
    [ Renamed variables to the standard __ prefix. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b226b3f497f1..5cb4301c4dcf 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -466,22 +466,17 @@ extern efi_status_t efi64_thunk(u32, ...);
 #define efi_thunk(f, ...)						\
 ({									\
 	efi_status_t __s;						\
-	unsigned long flags;						\
-	u32 func;							\
+	unsigned long __flags;						\
+	u32 __func;							\
 									\
-	efi_sync_low_kernel_mappings();					\
-	local_irq_save(flags);						\
+	local_irq_save(__flags);					\
+	arch_efi_call_virt_setup();					\
 									\
-	efi_scratch.prev_cr3 = read_cr3();				\
-	write_cr3((unsigned long)efi_scratch.efi_pgt);			\
-	__flush_tlb_all();						\
+	__func = runtime_service32(f);					\
+	__s = efi64_thunk(__func, __VA_ARGS__);				\
 									\
-	func = runtime_service32(f);					\
-	__s = efi64_thunk(func, __VA_ARGS__);			\
-									\
-	write_cr3(efi_scratch.prev_cr3);				\
-	__flush_tlb_all();						\
-	local_irq_restore(flags);					\
+	arch_efi_call_virt_teardown();					\
+	local_irq_restore(__flags);					\
 									\
 	__s;								\
 })

commit f58f230a832ba8220a64f44aaafcce4b7358d826
Author: Michal Hocko <mhocko@suse.com>
Date:   Fri Jun 24 14:48:53 2016 -0700

    x86/efi: get rid of superfluous __GFP_REPEAT
    
    __GFP_REPEAT has a rather weak semantic but since it has been introduced
    around 2.6.12 it has been ignored for low order allocations.
    
    efi_alloc_page_tables uses __GFP_REPEAT but it allocates an order-0
    page.  This means that this flag has never been actually useful here
    because it has always been used only for PAGE_ALLOC_COSTLY requests.
    
    Link: http://lkml.kernel.org/r/1464599699-30131-4-git-send-email-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 6e7242be1c87..b226b3f497f1 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -139,7 +139,7 @@ int __init efi_alloc_page_tables(void)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
-	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_REPEAT | __GFP_ZERO;
+	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;
 	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);
 	if (!efi_pgd)
 		return -ENOMEM;

commit 5ab788d7383289bfc141ab357767bc6c11bbf77f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon May 30 20:57:50 2016 +0200

    rtc: cmos: move mc146818rtc code out of asm-generic/rtc.h
    
    Drivers should not really include stuff from asm-generic directly,
    and the PC-style cmos rtc driver does this in order to reuse the
    mc146818 implementation of get_rtc_time/set_rtc_time rather than
    the architecture specific one for the architecture it gets built for.
    
    To make it more obvious what is going on, this moves and renames the
    two functions into include/linux/mc146818rtc.h, which holds the
    other mc146818 specific code. Ideally it would be in a .c file,
    but that would require extra infrastructure as the functions are
    called by multiple drivers with conflicting dependencies.
    
    With this change, the asm-generic/rtc.h header also becomes much
    more generic, so it can be reused more easily across any architecture
    that still relies on the genrtc driver.
    
    The only caller of the internal __get_rtc_time/__set_rtc_time
    functions is in arch/alpha/kernel/rtc.c, and we just change those
    over to the new naming.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Alexandre Belloni <alexandre.belloni@free-electrons.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 6e7242be1c87..663c282801f3 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -25,6 +25,7 @@
 #include <linux/bootmem.h>
 #include <linux/ioport.h>
 #include <linux/module.h>
+#include <linux/mc146818rtc.h>
 #include <linux/efi.h>
 #include <linux/uaccess.h>
 #include <linux/io.h>

commit 78ce248faa3c46e24e9bd42db3ab3650659f16dd
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Mon Apr 25 21:06:38 2016 +0100

    efi: Iterate over efi.memmap in for_each_efi_memory_desc()
    
    Most of the users of for_each_efi_memory_desc() are equally happy
    iterating over the EFI memory map in efi.memmap instead of 'memmap',
    since the former is usually a pointer to the latter.
    
    For those users that want to specify an EFI memory map other than
    efi.memmap, that can be done using for_each_efi_memory_desc_in_map().
    One such example is in the libstub code where the firmware is queried
    directly for the memory map, it gets iterated over, and then freed.
    
    This change goes part of the way toward deleting the global 'memmap'
    variable, which is not universally available on all architectures
    (notably IA64) and is rather poorly named.
    
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Leif Lindholm <leif.lindholm@linaro.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1461614832-17633-7-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 49e4dd4a1f58..6e7242be1c87 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -55,14 +55,12 @@ struct efi_scratch efi_scratch;
 static void __init early_code_mapping_set_exec(int executable)
 {
 	efi_memory_desc_t *md;
-	void *p;
 
 	if (!(__supported_pte_mask & _PAGE_NX))
 		return;
 
 	/* Make EFI service code area executable */
-	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
-		md = p;
+	for_each_efi_memory_desc(md) {
 		if (md->type == EFI_RUNTIME_SERVICES_CODE ||
 		    md->type == EFI_BOOT_SERVICES_CODE)
 			efi_set_executable(md, executable);
@@ -253,7 +251,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * Map all of RAM so that we can access arguments in the 1:1
 	 * mapping when making EFI runtime calls.
 	 */
-	for_each_efi_memory_desc(&memmap, md) {
+	for_each_efi_memory_desc(md) {
 		if (md->type != EFI_CONVENTIONAL_MEMORY &&
 		    md->type != EFI_LOADER_DATA &&
 		    md->type != EFI_LOADER_CODE)
@@ -398,7 +396,6 @@ void __init efi_runtime_update_mappings(void)
 	unsigned long pfn;
 	pgd_t *pgd = efi_pgd;
 	efi_memory_desc_t *md;
-	void *p;
 
 	if (efi_enabled(EFI_OLD_MEMMAP)) {
 		if (__supported_pte_mask & _PAGE_NX)
@@ -409,9 +406,8 @@ void __init efi_runtime_update_mappings(void)
 	if (!efi_enabled(EFI_NX_PE_DATA))
 		return;
 
-	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
+	for_each_efi_memory_desc(md) {
 		unsigned long pf = 0;
-		md = p;
 
 		if (!(md->attribute & EFI_MEMORY_RUNTIME))
 			continue;

commit 2ad510dc372c2caac9aada9ff6dd10e787616e1d
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Wed Feb 17 12:36:06 2016 +0000

    x86/efi: Only map kernel text for EFI mixed mode
    
    The correct symbol to use when figuring out the size of the kernel
    text is '_etext', not '_end' which is the symbol for the entire kernel
    image includes data and debug sections.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1455712566-16727-14-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 40d2f447a9dd..49e4dd4a1f58 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -275,7 +275,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	efi_scratch.phys_stack = virt_to_phys(page_address(page));
 	efi_scratch.phys_stack += PAGE_SIZE; /* stack grows down */
 
-	npages = (_end - _text) >> PAGE_SHIFT;
+	npages = (_etext - _text) >> PAGE_SHIFT;
 	text = __pa(_text);
 	pfn = text >> PAGE_SHIFT;
 

commit 6d0cc887d571e96f928be83f094322451fd4bf6f
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Wed Feb 17 12:36:05 2016 +0000

    x86/efi: Map EFI_MEMORY_{XP,RO} memory region bits to EFI page tables
    
    Now that we have EFI memory region bits that indicate which regions do
    not need execute permission or read/write permission in the page tables,
    let's use them.
    
    We also check for EFI_NX_PE_DATA and only enforce the restrictive
    mappings if it's present (to allow us to ignore buggy firmware that sets
    bits it didn't mean to and to preserve backwards compatibility).
    
    Instead of assuming that firmware would set appropriate attributes in
    memory descriptor like EFI_MEMORY_RO for code and EFI_MEMORY_XP for
    data, we can expect some firmware out there which might only set *type*
    in memory descriptor to be EFI_RUNTIME_SERVICES_CODE or
    EFI_RUNTIME_SERVICES_DATA leaving away attribute. This will lead to
    improper mappings of EFI runtime regions. In order to avoid it, we check
    attribute and type of memory descriptor to update mappings and moreover
    Windows works this way.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1455712566-16727-13-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b0965b27e47f..40d2f447a9dd 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -393,13 +393,50 @@ void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 	efi_setup = phys_addr + sizeof(struct setup_data);
 }
 
-void __init efi_runtime_mkexec(void)
+void __init efi_runtime_update_mappings(void)
 {
-	if (!efi_enabled(EFI_OLD_MEMMAP))
+	unsigned long pfn;
+	pgd_t *pgd = efi_pgd;
+	efi_memory_desc_t *md;
+	void *p;
+
+	if (efi_enabled(EFI_OLD_MEMMAP)) {
+		if (__supported_pte_mask & _PAGE_NX)
+			runtime_code_page_mkexec();
+		return;
+	}
+
+	if (!efi_enabled(EFI_NX_PE_DATA))
 		return;
 
-	if (__supported_pte_mask & _PAGE_NX)
-		runtime_code_page_mkexec();
+	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
+		unsigned long pf = 0;
+		md = p;
+
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+
+		if (!(md->attribute & EFI_MEMORY_WB))
+			pf |= _PAGE_PCD;
+
+		if ((md->attribute & EFI_MEMORY_XP) ||
+			(md->type == EFI_RUNTIME_SERVICES_DATA))
+			pf |= _PAGE_NX;
+
+		if (!(md->attribute & EFI_MEMORY_RO) &&
+			(md->type != EFI_RUNTIME_SERVICES_CODE))
+			pf |= _PAGE_RW;
+
+		/* Update the 1:1 mapping */
+		pfn = md->phys_addr >> PAGE_SHIFT;
+		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, md->num_pages, pf))
+			pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
+				   md->phys_addr, md->virt_addr);
+
+		if (kernel_map_pages_in_pgd(pgd, pfn, md->virt_addr, md->num_pages, pf))
+			pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
+				   md->phys_addr, md->virt_addr);
+	}
 }
 
 void __init efi_dump_pagetable(void)

commit 15f003d20782a4079e078d16df57081ebd1fc150
Author: Sai Praneeth <sai.praneeth.prakhya@intel.com>
Date:   Wed Feb 17 12:36:04 2016 +0000

    x86/mm/pat: Don't implicitly allow _PAGE_RW in kernel_map_pages_in_pgd()
    
    As part of the preparation for the EFI_MEMORY_RO flag added in the UEFI
    2.5 specification, we need the ability to map pages in kernel page
    tables without _PAGE_RW being set.
    
    Modify kernel_map_pages_in_pgd() to require its callers to pass _PAGE_RW
    if the pages need to be mapped read/write. Otherwise, we'll map the
    pages as read-only.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Lee, Chun-Yi <jlee@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Shankar <ravi.v.shankar@intel.com>
    Cc: Ricardo Neri <ricardo.neri@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1455712566-16727-12-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b492521503fe..b0965b27e47f 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -233,7 +233,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * phys_efi_set_virtual_address_map().
 	 */
 	pfn = pa_memmap >> PAGE_SHIFT;
-	if (kernel_map_pages_in_pgd(pgd, pfn, pa_memmap, num_pages, _PAGE_NX)) {
+	if (kernel_map_pages_in_pgd(pgd, pfn, pa_memmap, num_pages, _PAGE_NX | _PAGE_RW)) {
 		pr_err("Error ident-mapping new memmap (0x%lx)!\n", pa_memmap);
 		return 1;
 	}
@@ -262,7 +262,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 		pfn = md->phys_addr >> PAGE_SHIFT;
 		npages = md->num_pages;
 
-		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, npages, 0)) {
+		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, npages, _PAGE_RW)) {
 			pr_err("Failed to map 1:1 memory\n");
 			return 1;
 		}
@@ -279,7 +279,7 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	text = __pa(_text);
 	pfn = text >> PAGE_SHIFT;
 
-	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, 0)) {
+	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, _PAGE_RW)) {
 		pr_err("Failed to map kernel text 1:1\n");
 		return 1;
 	}
@@ -294,7 +294,7 @@ void __init efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
-	unsigned long flags = 0;
+	unsigned long flags = _PAGE_RW;
 	unsigned long pfn;
 	pgd_t *pgd = efi_pgd;
 

commit 98f91276900fa07d6f1c4ae4f120d69962f6433c
Merge: ff3d0a12fb2d 50a0cb565246
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Dec 19 21:24:52 2015 +0100

    Merge tag 'efi-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mfleming/efi into x86/efi
    
    Pull efi changes from Matt Fleming:
    
     * We don't need to carry our own formatting code in the esrt driver
       because the kobject API can do that for us - Rasmus Villemoes
    
     * Update the arm64 file paths in Documentation/efi-stub.txt to match
       the current tree - Alan Ott
    
     * Consistently preface all print statements with "efi" arch/x86 so
       that it's more obvious to users reporting problems which statements
       in the kernel log are relevant for EFI - Matt Fleming
    
     * Fix a boot crash in the ACPI BGRT driver and delete
       efi_lookup_mapped_addr() since it's useless now that the EFI
       mappings *only* exist in the 'efi_pgd' page table. Instead we
       always early_memremap() the BGRT memory - Sai Praneeth Prakhya

commit 26d7f65fbd22168c33d2350f3e7e3021f5761256
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Sun Oct 25 10:26:35 2015 +0000

    x86/efi: Preface all print statements with efi* tag
    
    The pr_*() calls in the x86 EFI code may or may not include a
    subsystem tag, which makes it difficult to grep the kernel log for all
    relevant EFI messages and leads users to miss important information.
    
    Recently, a bug reporter provided all the EFI print messages from the
    kernel log when trying to diagnose an issue but missed the following
    statement because it wasn't prefixed with anything indicating it was
    related to EFI,
    
      pr_err("Error ident-mapping new memmap (0x%lx)!\n", pa_memmap);
    
    Cc: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a0ac0f9c307f..d347e854a5e4 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -15,6 +15,8 @@
  *
  */
 
+#define pr_fmt(fmt) "efi: " fmt
+
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/mm.h>

commit 67a9108ed4313b85a9c53406d80dc1ae3f8c3e36
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Fri Nov 27 21:09:34 2015 +0000

    x86/efi: Build our own page table structures
    
    With commit e1a58320a38d ("x86/mm: Warn on W^X mappings") all
    users booting on 64-bit UEFI machines see the following warning,
    
      ------------[ cut here ]------------
      WARNING: CPU: 7 PID: 1 at arch/x86/mm/dump_pagetables.c:225 note_page+0x5dc/0x780()
      x86/mm: Found insecure W+X mapping at address ffff88000005f000/0xffff88000005f000
      ...
      x86/mm: Checked W+X mappings: FAILED, 165660 W+X pages found.
      ...
    
    This is caused by mapping EFI regions with RWX permissions.
    There isn't much we can do to restrict the permissions for these
    regions due to the way the firmware toolchains mix code and
    data, but we can at least isolate these mappings so that they do
    not appear in the regular kernel page tables.
    
    In commit d2f7cbe7b26a ("x86/efi: Runtime services virtual
    mapping") we started using 'trampoline_pgd' to map the EFI
    regions because there was an existing identity mapping there
    which we use during the SetVirtualAddressMap() call and for
    broken firmware that accesses those addresses.
    
    But 'trampoline_pgd' shares some PGD entries with
    'swapper_pg_dir' and does not provide the isolation we require.
    Notably the virtual address for __START_KERNEL_map and
    MODULES_START are mapped by the same PGD entry so we need to be
    more careful when copying changes over in
    efi_sync_low_kernel_mappings().
    
    This patch doesn't go the full mile, we still want to share some
    PGD entries with 'swapper_pg_dir'. Having completely separate
    page tables brings its own issues such as synchronising new
    mappings after memory hotplug and module loading. Sharing also
    keeps memory usage down.
    
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Jones <davej@codemonkey.org.uk>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1448658575-17029-6-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index b19cdac959b2..4897f518760f 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -40,6 +40,7 @@
 #include <asm/fixmap.h>
 #include <asm/realmode.h>
 #include <asm/time.h>
+#include <asm/pgalloc.h>
 
 /*
  * We allocate runtime services regions bottom-up, starting from -4G, i.e.
@@ -121,22 +122,92 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	early_code_mapping_set_exec(0);
 }
 
+static pgd_t *efi_pgd;
+
+/*
+ * We need our own copy of the higher levels of the page tables
+ * because we want to avoid inserting EFI region mappings (EFI_VA_END
+ * to EFI_VA_START) into the standard kernel page tables. Everything
+ * else can be shared, see efi_sync_low_kernel_mappings().
+ */
+int __init efi_alloc_page_tables(void)
+{
+	pgd_t *pgd;
+	pud_t *pud;
+	gfp_t gfp_mask;
+
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return 0;
+
+	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_REPEAT | __GFP_ZERO;
+	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);
+	if (!efi_pgd)
+		return -ENOMEM;
+
+	pgd = efi_pgd + pgd_index(EFI_VA_END);
+
+	pud = pud_alloc_one(NULL, 0);
+	if (!pud) {
+		free_page((unsigned long)efi_pgd);
+		return -ENOMEM;
+	}
+
+	pgd_populate(NULL, pgd, pud);
+
+	return 0;
+}
+
 /*
  * Add low kernel mappings for passing arguments to EFI functions.
  */
 void efi_sync_low_kernel_mappings(void)
 {
-	unsigned num_pgds;
-	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
+	unsigned num_entries;
+	pgd_t *pgd_k, *pgd_efi;
+	pud_t *pud_k, *pud_efi;
 
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return;
 
-	num_pgds = pgd_index(MODULES_END - 1) - pgd_index(PAGE_OFFSET);
+	/*
+	 * We can share all PGD entries apart from the one entry that
+	 * covers the EFI runtime mapping space.
+	 *
+	 * Make sure the EFI runtime region mappings are guaranteed to
+	 * only span a single PGD entry and that the entry also maps
+	 * other important kernel regions.
+	 */
+	BUILD_BUG_ON(pgd_index(EFI_VA_END) != pgd_index(MODULES_END));
+	BUILD_BUG_ON((EFI_VA_START & PGDIR_MASK) !=
+			(EFI_VA_END & PGDIR_MASK));
+
+	pgd_efi = efi_pgd + pgd_index(PAGE_OFFSET);
+	pgd_k = pgd_offset_k(PAGE_OFFSET);
+
+	num_entries = pgd_index(EFI_VA_END) - pgd_index(PAGE_OFFSET);
+	memcpy(pgd_efi, pgd_k, sizeof(pgd_t) * num_entries);
 
-	memcpy(pgd + pgd_index(PAGE_OFFSET),
-		init_mm.pgd + pgd_index(PAGE_OFFSET),
-		sizeof(pgd_t) * num_pgds);
+	/*
+	 * We share all the PUD entries apart from those that map the
+	 * EFI regions. Copy around them.
+	 */
+	BUILD_BUG_ON((EFI_VA_START & ~PUD_MASK) != 0);
+	BUILD_BUG_ON((EFI_VA_END & ~PUD_MASK) != 0);
+
+	pgd_efi = efi_pgd + pgd_index(EFI_VA_END);
+	pud_efi = pud_offset(pgd_efi, 0);
+
+	pgd_k = pgd_offset_k(EFI_VA_END);
+	pud_k = pud_offset(pgd_k, 0);
+
+	num_entries = pud_index(EFI_VA_END);
+	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);
+
+	pud_efi = pud_offset(pgd_efi, EFI_VA_START);
+	pud_k = pud_offset(pgd_k, EFI_VA_START);
+
+	num_entries = PTRS_PER_PUD - pud_index(EFI_VA_START);
+	memcpy(pud_efi, pud_k, sizeof(pud_t) * num_entries);
 }
 
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
@@ -150,8 +221,8 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
-	efi_scratch.efi_pgt = (pgd_t *)(unsigned long)real_mode_header->trampoline_pgd;
-	pgd = __va(efi_scratch.efi_pgt);
+	efi_scratch.efi_pgt = (pgd_t *)__pa(efi_pgd);
+	pgd = efi_pgd;
 
 	/*
 	 * It can happen that the physical address of new_memmap lands in memory
@@ -216,16 +287,14 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 void __init efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
-	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
-
-	kernel_unmap_pages_in_pgd(pgd, pa_memmap, num_pages);
+	kernel_unmap_pages_in_pgd(efi_pgd, pa_memmap, num_pages);
 }
 
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
-	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
 	unsigned long flags = 0;
 	unsigned long pfn;
+	pgd_t *pgd = efi_pgd;
 
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
@@ -334,9 +403,7 @@ void __init efi_runtime_mkexec(void)
 void __init efi_dump_pagetable(void)
 {
 #ifdef CONFIG_EFI_PGT_DUMP
-	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
-
-	ptdump_walk_pgd_level(NULL, pgd);
+	ptdump_walk_pgd_level(NULL, efi_pgd);
 #endif
 }
 

commit c9f2a9a65e4855b74d92cdad688f6ee4a1a323ff
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Fri Nov 27 21:09:33 2015 +0000

    x86/efi: Hoist page table switching code into efi_call_virt()
    
    This change is a prerequisite for pending patches that switch to
    a dedicated EFI page table, instead of using 'trampoline_pgd'
    which shares PGD entries with 'swapper_pg_dir'. The pending
    patches make it impossible to dereference the runtime service
    function pointer without first switching %cr3.
    
    It's true that we now have duplicated switching code in
    efi_call_virt() and efi_call_phys_{prolog,epilog}() but we are
    sacrificing code duplication for a little more clarity and the
    ease of writing the page table switching code in C instead of
    asm.
    
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Jones <davej@codemonkey.org.uk>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1448658575-17029-5-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 102976dda8c4..b19cdac959b2 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -47,16 +47,7 @@
  */
 static u64 efi_va = EFI_VA_START;
 
-/*
- * Scratch space used for switching the pagetable in the EFI stub
- */
-struct efi_scratch {
-	u64 r15;
-	u64 prev_cr3;
-	pgd_t *efi_pgt;
-	bool use_pgd;
-	u64 phys_stack;
-} __packed;
+struct efi_scratch efi_scratch;
 
 static void __init early_code_mapping_set_exec(int executable)
 {
@@ -83,8 +74,11 @@ pgd_t * __init efi_call_phys_prolog(void)
 	int pgd;
 	int n_pgds;
 
-	if (!efi_enabled(EFI_OLD_MEMMAP))
-		return NULL;
+	if (!efi_enabled(EFI_OLD_MEMMAP)) {
+		save_pgd = (pgd_t *)read_cr3();
+		write_cr3((unsigned long)efi_scratch.efi_pgt);
+		goto out;
+	}
 
 	early_code_mapping_set_exec(1);
 
@@ -96,6 +90,7 @@ pgd_t * __init efi_call_phys_prolog(void)
 		vaddress = (unsigned long)__va(pgd * PGDIR_SIZE);
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));
 	}
+out:
 	__flush_tlb_all();
 
 	return save_pgd;
@@ -109,8 +104,11 @@ void __init efi_call_phys_epilog(pgd_t *save_pgd)
 	int pgd_idx;
 	int nr_pgds;
 
-	if (!save_pgd)
+	if (!efi_enabled(EFI_OLD_MEMMAP)) {
+		write_cr3((unsigned long)save_pgd);
+		__flush_tlb_all();
 		return;
+	}
 
 	nr_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
 

commit b61a76f8850d2979550abc42d7e09154ebb8d785
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Fri Nov 27 21:09:32 2015 +0000

    x86/efi: Map RAM into the identity page table for mixed mode
    
    We are relying on the pre-existing mappings in 'trampoline_pgd'
    when accessing function arguments in the EFI mixed mode thunking
    code.
    
    Instead let's map memory explicitly so that things will continue
    to work when we move to a separate page table in the future.
    
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1448658575-17029-4-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 5aa186db59e3..102976dda8c4 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -144,6 +144,7 @@ void efi_sync_low_kernel_mappings(void)
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
 	unsigned long pfn, text;
+	efi_memory_desc_t *md;
 	struct page *page;
 	unsigned npages;
 	pgd_t *pgd;
@@ -177,6 +178,25 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	if (!IS_ENABLED(CONFIG_EFI_MIXED))
 		return 0;
 
+	/*
+	 * Map all of RAM so that we can access arguments in the 1:1
+	 * mapping when making EFI runtime calls.
+	 */
+	for_each_efi_memory_desc(&memmap, md) {
+		if (md->type != EFI_CONVENTIONAL_MEMORY &&
+		    md->type != EFI_LOADER_DATA &&
+		    md->type != EFI_LOADER_CODE)
+			continue;
+
+		pfn = md->phys_addr >> PAGE_SHIFT;
+		npages = md->num_pages;
+
+		if (kernel_map_pages_in_pgd(pgd, pfn, md->phys_addr, npages, 0)) {
+			pr_err("Failed to map 1:1 memory\n");
+			return 1;
+		}
+	}
+
 	page = alloc_page(GFP_KERNEL|__GFP_DMA32);
 	if (!page)
 		panic("Unable to allocate EFI runtime stack < 4GB\n");

commit edc3b9129cecd0f0857112136f5b8b1bc1d45918
Author: Matt Fleming <matt@codeblueprint.co.uk>
Date:   Fri Nov 27 21:09:31 2015 +0000

    x86/mm/pat: Ensure cpa->pfn only contains page frame numbers
    
    The x86 pageattr code is confused about the data that is stored
    in cpa->pfn, sometimes it's treated as a page frame number,
    sometimes it's treated as an unshifted physical address, and in
    one place it's treated as a pte.
    
    The result of this is that the mapping functions do not map the
    intended physical address.
    
    This isn't a problem in practice because most of the addresses
    we're mapping in the EFI code paths are already mapped in
    'trampoline_pgd' and so the pageattr mapping functions don't
    actually do anything in this case. But when we move to using a
    separate page table for the EFI runtime this will be an issue.
    
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1448658575-17029-3-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index a0ac0f9c307f..5aa186db59e3 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -143,7 +143,7 @@ void efi_sync_low_kernel_mappings(void)
 
 int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
-	unsigned long text;
+	unsigned long pfn, text;
 	struct page *page;
 	unsigned npages;
 	pgd_t *pgd;
@@ -160,7 +160,8 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	 * and ident-map those pages containing the map before calling
 	 * phys_efi_set_virtual_address_map().
 	 */
-	if (kernel_map_pages_in_pgd(pgd, pa_memmap, pa_memmap, num_pages, _PAGE_NX)) {
+	pfn = pa_memmap >> PAGE_SHIFT;
+	if (kernel_map_pages_in_pgd(pgd, pfn, pa_memmap, num_pages, _PAGE_NX)) {
 		pr_err("Error ident-mapping new memmap (0x%lx)!\n", pa_memmap);
 		return 1;
 	}
@@ -185,8 +186,9 @@ int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 
 	npages = (_end - _text) >> PAGE_SHIFT;
 	text = __pa(_text);
+	pfn = text >> PAGE_SHIFT;
 
-	if (kernel_map_pages_in_pgd(pgd, text >> PAGE_SHIFT, text, npages, 0)) {
+	if (kernel_map_pages_in_pgd(pgd, pfn, text, npages, 0)) {
 		pr_err("Failed to map kernel text 1:1\n");
 		return 1;
 	}
@@ -204,12 +206,14 @@ void __init efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
 	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
-	unsigned long pf = 0;
+	unsigned long flags = 0;
+	unsigned long pfn;
 
 	if (!(md->attribute & EFI_MEMORY_WB))
-		pf |= _PAGE_PCD;
+		flags |= _PAGE_PCD;
 
-	if (kernel_map_pages_in_pgd(pgd, md->phys_addr, va, md->num_pages, pf))
+	pfn = md->phys_addr >> PAGE_SHIFT;
+	if (kernel_map_pages_in_pgd(pgd, pfn, va, md->num_pages, flags))
 		pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
 			   md->phys_addr, va);
 }

commit 744937b0b12a669f298949c4a810794c59fead98
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Mar 3 07:48:50 2015 +0100

    efi: Clean up the efi_call_phys_[prolog|epilog]() save/restore interaction
    
    Currently x86-64 efi_call_phys_prolog() saves into a global variable (save_pgd),
    and efi_call_phys_epilog() restores the kernel pagetables from that global
    variable.
    
    Change this to a cleaner save/restore pattern where the saving function returns
    the saved object and the restore function restores that.
    
    Apply the same concept to the 32-bit code as well.
    
    Plus this approach, as an added bonus, allows us to express the
    !efi_enabled(EFI_OLD_MEMMAP) situation in a clean fashion as well,
    via a 'NULL' return value.
    
    Cc: Tapasweni Pathak <tapaswenipathak@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 427eb3540e5f..a0ac0f9c307f 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -41,8 +41,6 @@
 #include <asm/realmode.h>
 #include <asm/time.h>
 
-static pgd_t *save_pgd __initdata;
-
 /*
  * We allocate runtime services regions bottom-up, starting from -4G, i.e.
  * 0xffff_ffff_0000_0000 and limit EFI VA mapping space to 64G.
@@ -77,14 +75,16 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
-void __init efi_call_phys_prolog(void)
+pgd_t * __init efi_call_phys_prolog(void)
 {
 	unsigned long vaddress;
+	pgd_t *save_pgd;
+
 	int pgd;
 	int n_pgds;
 
 	if (!efi_enabled(EFI_OLD_MEMMAP))
-		return;
+		return NULL;
 
 	early_code_mapping_set_exec(1);
 
@@ -97,22 +97,28 @@ void __init efi_call_phys_prolog(void)
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));
 	}
 	__flush_tlb_all();
+
+	return save_pgd;
 }
 
-void __init efi_call_phys_epilog(void)
+void __init efi_call_phys_epilog(pgd_t *save_pgd)
 {
 	/*
 	 * After the lock is released, the original page table is restored.
 	 */
-	int pgd;
-	int n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
+	int pgd_idx;
+	int nr_pgds;
 
-	if (!efi_enabled(EFI_OLD_MEMMAP))
+	if (!save_pgd)
 		return;
 
-	for (pgd = 0; pgd < n_pgds; pgd++)
-		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);
+	nr_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
+
+	for (pgd_idx = 0; pgd_idx < nr_pgds; pgd_idx++)
+		set_pgd(pgd_offset_k(pgd_idx * PGDIR_SIZE), save_pgd[pgd_idx]);
+
 	kfree(save_pgd);
+
 	__flush_tlb_all();
 	early_code_mapping_set_exec(0);
 }

commit 23a0d4e8fa6d3a1d7fb819f79bcc0a3739c30ba9
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Mar 3 07:34:33 2015 +0100

    efi: Disable interrupts around EFI calls, not in the epilog/prolog calls
    
    Tapasweni Pathak reported that we do a kmalloc() in efi_call_phys_prolog()
    on x86-64 while having interrupts disabled, which is a big no-no, as
    kmalloc() can sleep.
    
    Solve this by removing the irq disabling from the prolog/epilog calls
    around EFI calls: it's unnecessary, as in this stage we are single
    threaded in the boot thread, and we don't ever execute this from
    interrupt contexts.
    
    Reported-by: Tapasweni Pathak <tapaswenipathak@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 17e80d829df0..427eb3540e5f 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -42,7 +42,6 @@
 #include <asm/time.h>
 
 static pgd_t *save_pgd __initdata;
-static unsigned long efi_flags __initdata;
 
 /*
  * We allocate runtime services regions bottom-up, starting from -4G, i.e.
@@ -88,7 +87,6 @@ void __init efi_call_phys_prolog(void)
 		return;
 
 	early_code_mapping_set_exec(1);
-	local_irq_save(efi_flags);
 
 	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
 	save_pgd = kmalloc(n_pgds * sizeof(pgd_t), GFP_KERNEL);
@@ -116,7 +114,6 @@ void __init efi_call_phys_epilog(void)
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);
 	kfree(save_pgd);
 	__flush_tlb_all();
-	local_irq_restore(efi_flags);
 	early_code_mapping_set_exec(0);
 }
 

commit 8266e31ed0fedb7ee16ebc86e80468f7cc1bbb4e
Author: Mathias Krause <minipli@googlemail.com>
Date:   Sun Sep 21 17:26:54 2014 +0200

    x86, ptdump: Add section for EFI runtime services
    
    In commit 3891a04aafd6 ("x86-64, espfix: Don't leak bits 31:16 of %esp
    returning..") the "ESPFix Area" was added to the page table dump special
    sections. That area, though, has a limited amount of entries printed.
    
    The EFI runtime services are, unfortunately, located in-between the
    espfix area and the high kernel memory mapping. Due to the enforced
    limitation for the espfix area, the EFI mappings won't be printed in the
    page table dump.
    
    To make the ESP runtime service mappings visible again, provide them a
    dedicated entry.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 35aecb6042fb..17e80d829df0 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -48,8 +48,7 @@ static unsigned long efi_flags __initdata;
  * We allocate runtime services regions bottom-up, starting from -4G, i.e.
  * 0xffff_ffff_0000_0000 and limit EFI VA mapping space to 64G.
  */
-static u64 efi_va	= -4 * (1UL << 30);
-#define EFI_VA_END	(-68 * (1UL << 30))
+static u64 efi_va = EFI_VA_START;
 
 /*
  * Scratch space used for switching the pagetable in the EFI stub

commit 4e78eb056136b002ecdfbbf61436fedfb8a3c76b
Author: Mathias Krause <minipli@googlemail.com>
Date:   Sun Sep 7 19:42:17 2014 +0200

    x86/efi: Mark initialization code as such
    
    The 32 bit and 64 bit implementations differ in their __init annotations
    for some functions referenced from the common EFI code. Namely, the 32
    bit variant is missing some of the __init annotations the 64 bit variant
    has.
    
    To solve the colliding annotations, mark the corresponding functions in
    efi_32.c as initialization code, too -- as it is such.
    
    Actually, quite a few more functions are only used during initialization
    and therefore can be marked __init. They are therefore annotated, too.
    Also add the __init annotation to the prototypes in the efi.h header so
    users of those functions will see it's meant as initialization code
    only.
    
    This patch also fixes the "prelog" typo. ("prologue" / "epilogue" might
    be more appropriate but this is C code after all, not an opera! :D)
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 290d397e1dd9..35aecb6042fb 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -79,7 +79,7 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
-void __init efi_call_phys_prelog(void)
+void __init efi_call_phys_prolog(void)
 {
 	unsigned long vaddress;
 	int pgd;
@@ -139,7 +139,7 @@ void efi_sync_low_kernel_mappings(void)
 		sizeof(pgd_t) * num_pgds);
 }
 
-int efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
+int __init efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
 	unsigned long text;
 	struct page *page;
@@ -192,7 +192,7 @@ int efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 	return 0;
 }
 
-void efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
+void __init efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
 	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
 

commit 9a11040ff962304c1838aa9a9f33be78784eae47
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Sun Mar 16 17:46:46 2014 +0000

    x86/efi: Restore 'attr' argument to query_variable_info()
    
    In the thunk patches the 'attr' argument was dropped to
    query_variable_info(). Restore it otherwise the firmware will return
    EFI_INVALID_PARAMETER.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 7e7f195aa5cf..290d397e1dd9 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -567,7 +567,7 @@ efi_thunk_query_variable_info(u32 attr, u64 *storage_space,
 	phys_remaining = virt_to_phys(remaining_space);
 	phys_max = virt_to_phys(max_variable_size);
 
-	status = efi_thunk(query_variable_info, phys_storage,
+	status = efi_thunk(query_variable_info, attr, phys_storage,
 			   phys_remaining, phys_max);
 
 	return status;

commit 994448f1afa6689bafbebaf7412b23b541b41ef5
Merge: 4fd69331ad22 18c46461d9e4
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Wed Mar 5 18:15:37 2014 +0000

    Merge remote-tracking branch 'tip/x86/efi-mixed' into efi-for-mingo
    
    Conflicts:
            arch/x86/kernel/setup.c
            arch/x86/platform/efi/efi.c
            arch/x86/platform/efi/efi_64.c

commit 4f9dbcfc40299ddaa780fe8c1cd74998c1be3af5
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Jan 10 18:48:30 2014 +0000

    x86/efi: Add mixed runtime services support
    
    Setup the runtime services based on whether we're booting in EFI native
    mode or not. For non-native mode we need to thunk from 64-bit into
    32-bit mode before invoking the EFI runtime services.
    
    Using the runtime services after SetVirtualAddressMap() is slightly more
    complicated because we need to ensure that all the addresses we pass to
    the firmware are below the 4GB boundary so that they can be addressed
    with 32-bit pointers, see efi_setup_page_tables().
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 0c2a234fef1e..12112ab4fd40 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -39,6 +39,7 @@
 #include <asm/cacheflush.h>
 #include <asm/fixmap.h>
 #include <asm/realmode.h>
+#include <asm/time.h>
 
 static pgd_t *save_pgd __initdata;
 static unsigned long efi_flags __initdata;
@@ -58,7 +59,8 @@ struct efi_scratch {
 	u64 prev_cr3;
 	pgd_t *efi_pgt;
 	bool use_pgd;
-};
+	u64 phys_stack;
+} __packed;
 
 static void __init early_code_mapping_set_exec(int executable)
 {
@@ -139,10 +141,40 @@ void efi_sync_low_kernel_mappings(void)
 
 void efi_setup_page_tables(void)
 {
+	unsigned long text;
+	unsigned npages;
+	struct page *page;
+
 	efi_scratch.efi_pgt = (pgd_t *)(unsigned long)real_mode_header->trampoline_pgd;
 
-	if (!efi_enabled(EFI_OLD_MEMMAP))
-		efi_scratch.use_pgd = true;
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return;
+
+	efi_scratch.use_pgd = true;
+
+	/*
+	 * When making calls to the firmware everything needs to be 1:1
+	 * mapped and addressable with 32-bit pointers. Map the kernel
+	 * text and allocate a new stack because we can't rely on the
+	 * stack pointer being < 4GB.
+	 */
+	if (!IS_ENABLED(CONFIG_EFI_MIXED))
+		return;
+
+	page = alloc_page(GFP_KERNEL|__GFP_DMA32);
+	if (!page)
+		panic("Unable to allocate EFI runtime stack < 4GB\n");
+
+	efi_scratch.phys_stack = virt_to_phys(page_address(page));
+	efi_scratch.phys_stack += PAGE_SIZE; /* stack grows down */
+
+	npages = (_end - _text) >> PAGE_SHIFT;
+	text = __pa(_text);
+
+	if (kernel_map_pages_in_pgd(__va(efi_scratch.efi_pgt),
+				    text >> PAGE_SHIFT, text, npages, 0)) {
+		pr_err("Failed to map kernel text 1:1\n");
+	}
 }
 
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
@@ -173,6 +205,16 @@ void __init efi_map_region(efi_memory_desc_t *md)
 	 */
 	__map_region(md, md->phys_addr);
 
+	/*
+	 * Enforce the 1:1 mapping as the default virtual address when
+	 * booting in EFI mixed mode, because even though we may be
+	 * running a 64-bit kernel, the firmware may only be 32-bit.
+	 */
+	if (!efi_is_native () && IS_ENABLED(CONFIG_EFI_MIXED)) {
+		md->virt_addr = md->phys_addr;
+		return;
+	}
+
 	efi_va -= size;
 
 	/* Is PA 2M-aligned? */
@@ -242,3 +284,290 @@ void __init efi_runtime_mkexec(void)
 	if (__supported_pte_mask & _PAGE_NX)
 		runtime_code_page_mkexec();
 }
+
+#ifdef CONFIG_EFI_MIXED
+extern efi_status_t efi64_thunk(u32, ...);
+
+#define runtime_service32(func)						 \
+({									 \
+	u32 table = (u32)(unsigned long)efi.systab;			 \
+	u32 *rt, *___f;							 \
+									 \
+	rt = (u32 *)(table + offsetof(efi_system_table_32_t, runtime));	 \
+	___f = (u32 *)(*rt + offsetof(efi_runtime_services_32_t, func)); \
+	*___f;								 \
+})
+
+/*
+ * Switch to the EFI page tables early so that we can access the 1:1
+ * runtime services mappings which are not mapped in any other page
+ * tables. This function must be called before runtime_service32().
+ *
+ * Also, disable interrupts because the IDT points to 64-bit handlers,
+ * which aren't going to function correctly when we switch to 32-bit.
+ */
+#define efi_thunk(f, ...)						\
+({									\
+	efi_status_t __s;						\
+	unsigned long flags;						\
+	u32 func;							\
+									\
+	efi_sync_low_kernel_mappings();					\
+	local_irq_save(flags);						\
+									\
+	efi_scratch.prev_cr3 = read_cr3();				\
+	write_cr3((unsigned long)efi_scratch.efi_pgt);			\
+	__flush_tlb_all();						\
+									\
+	func = runtime_service32(f);					\
+	__s = efi64_thunk(func, __VA_ARGS__);			\
+									\
+	write_cr3(efi_scratch.prev_cr3);				\
+	__flush_tlb_all();						\
+	local_irq_restore(flags);					\
+									\
+	__s;								\
+})
+
+efi_status_t efi_thunk_set_virtual_address_map(
+	void *phys_set_virtual_address_map,
+	unsigned long memory_map_size,
+	unsigned long descriptor_size,
+	u32 descriptor_version,
+	efi_memory_desc_t *virtual_map)
+{
+	efi_status_t status;
+	unsigned long flags;
+	u32 func;
+
+	efi_sync_low_kernel_mappings();
+	local_irq_save(flags);
+
+	efi_scratch.prev_cr3 = read_cr3();
+	write_cr3((unsigned long)efi_scratch.efi_pgt);
+	__flush_tlb_all();
+
+	func = (u32)(unsigned long)phys_set_virtual_address_map;
+	status = efi64_thunk(func, memory_map_size, descriptor_size,
+			     descriptor_version, virtual_map);
+
+	write_cr3(efi_scratch.prev_cr3);
+	__flush_tlb_all();
+	local_irq_restore(flags);
+
+	return status;
+}
+
+static efi_status_t efi_thunk_get_time(efi_time_t *tm, efi_time_cap_t *tc)
+{
+	efi_status_t status;
+	u32 phys_tm, phys_tc;
+
+	spin_lock(&rtc_lock);
+
+	phys_tm = virt_to_phys(tm);
+	phys_tc = virt_to_phys(tc);
+
+	status = efi_thunk(get_time, phys_tm, phys_tc);
+
+	spin_unlock(&rtc_lock);
+
+	return status;
+}
+
+static efi_status_t efi_thunk_set_time(efi_time_t *tm)
+{
+	efi_status_t status;
+	u32 phys_tm;
+
+	spin_lock(&rtc_lock);
+
+	phys_tm = virt_to_phys(tm);
+
+	status = efi_thunk(set_time, phys_tm);
+
+	spin_unlock(&rtc_lock);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_get_wakeup_time(efi_bool_t *enabled, efi_bool_t *pending,
+			  efi_time_t *tm)
+{
+	efi_status_t status;
+	u32 phys_enabled, phys_pending, phys_tm;
+
+	spin_lock(&rtc_lock);
+
+	phys_enabled = virt_to_phys(enabled);
+	phys_pending = virt_to_phys(pending);
+	phys_tm = virt_to_phys(tm);
+
+	status = efi_thunk(get_wakeup_time, phys_enabled,
+			     phys_pending, phys_tm);
+
+	spin_unlock(&rtc_lock);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_set_wakeup_time(efi_bool_t enabled, efi_time_t *tm)
+{
+	efi_status_t status;
+	u32 phys_tm;
+
+	spin_lock(&rtc_lock);
+
+	phys_tm = virt_to_phys(tm);
+
+	status = efi_thunk(set_wakeup_time, enabled, phys_tm);
+
+	spin_unlock(&rtc_lock);
+
+	return status;
+}
+
+
+static efi_status_t
+efi_thunk_get_variable(efi_char16_t *name, efi_guid_t *vendor,
+		       u32 *attr, unsigned long *data_size, void *data)
+{
+	efi_status_t status;
+	u32 phys_name, phys_vendor, phys_attr;
+	u32 phys_data_size, phys_data;
+
+	phys_data_size = virt_to_phys(data_size);
+	phys_vendor = virt_to_phys(vendor);
+	phys_name = virt_to_phys(name);
+	phys_attr = virt_to_phys(attr);
+	phys_data = virt_to_phys(data);
+
+	status = efi_thunk(get_variable, phys_name, phys_vendor,
+			   phys_attr, phys_data_size, phys_data);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_set_variable(efi_char16_t *name, efi_guid_t *vendor,
+		       u32 attr, unsigned long data_size, void *data)
+{
+	u32 phys_name, phys_vendor, phys_data;
+	efi_status_t status;
+
+	phys_name = virt_to_phys(name);
+	phys_vendor = virt_to_phys(vendor);
+	phys_data = virt_to_phys(data);
+
+	/* If data_size is > sizeof(u32) we've got problems */
+	status = efi_thunk(set_variable, phys_name, phys_vendor,
+			   attr, data_size, phys_data);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_get_next_variable(unsigned long *name_size,
+			    efi_char16_t *name,
+			    efi_guid_t *vendor)
+{
+	efi_status_t status;
+	u32 phys_name_size, phys_name, phys_vendor;
+
+	phys_name_size = virt_to_phys(name_size);
+	phys_vendor = virt_to_phys(vendor);
+	phys_name = virt_to_phys(name);
+
+	status = efi_thunk(get_next_variable, phys_name_size,
+			   phys_name, phys_vendor);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_get_next_high_mono_count(u32 *count)
+{
+	efi_status_t status;
+	u32 phys_count;
+
+	phys_count = virt_to_phys(count);
+	status = efi_thunk(get_next_high_mono_count, phys_count);
+
+	return status;
+}
+
+static void
+efi_thunk_reset_system(int reset_type, efi_status_t status,
+		       unsigned long data_size, efi_char16_t *data)
+{
+	u32 phys_data;
+
+	phys_data = virt_to_phys(data);
+
+	efi_thunk(reset_system, reset_type, status, data_size, phys_data);
+}
+
+static efi_status_t
+efi_thunk_update_capsule(efi_capsule_header_t **capsules,
+			 unsigned long count, unsigned long sg_list)
+{
+	/*
+	 * To properly support this function we would need to repackage
+	 * 'capsules' because the firmware doesn't understand 64-bit
+	 * pointers.
+	 */
+	return EFI_UNSUPPORTED;
+}
+
+static efi_status_t
+efi_thunk_query_variable_info(u32 attr, u64 *storage_space,
+			      u64 *remaining_space,
+			      u64 *max_variable_size)
+{
+	efi_status_t status;
+	u32 phys_storage, phys_remaining, phys_max;
+
+	if (efi.runtime_version < EFI_2_00_SYSTEM_TABLE_REVISION)
+		return EFI_UNSUPPORTED;
+
+	phys_storage = virt_to_phys(storage_space);
+	phys_remaining = virt_to_phys(remaining_space);
+	phys_max = virt_to_phys(max_variable_size);
+
+	status = efi_thunk(query_variable_info, phys_storage,
+			   phys_remaining, phys_max);
+
+	return status;
+}
+
+static efi_status_t
+efi_thunk_query_capsule_caps(efi_capsule_header_t **capsules,
+			     unsigned long count, u64 *max_size,
+			     int *reset_type)
+{
+	/*
+	 * To properly support this function we would need to repackage
+	 * 'capsules' because the firmware doesn't understand 64-bit
+	 * pointers.
+	 */
+	return EFI_UNSUPPORTED;
+}
+
+void efi_thunk_runtime_setup(void)
+{
+	efi.get_time = efi_thunk_get_time;
+	efi.set_time = efi_thunk_set_time;
+	efi.get_wakeup_time = efi_thunk_get_wakeup_time;
+	efi.set_wakeup_time = efi_thunk_set_wakeup_time;
+	efi.get_variable = efi_thunk_get_variable;
+	efi.get_next_variable = efi_thunk_get_next_variable;
+	efi.set_variable = efi_thunk_set_variable;
+	efi.get_next_high_mono_count = efi_thunk_get_next_high_mono_count;
+	efi.reset_system = efi_thunk_reset_system;
+	efi.query_variable_info = efi_thunk_query_variable_info;
+	efi.update_capsule = efi_thunk_update_capsule;
+	efi.query_capsule_caps = efi_thunk_query_capsule_caps;
+}
+#endif /* CONFIG_EFI_MIXED */

commit b7b898ae0c0a82489511a1ce1b35f26215e6beb5
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jan 18 12:48:17 2014 +0100

    x86/efi: Make efi virtual runtime map passing more robust
    
    Currently, running SetVirtualAddressMap() and passing the physical
    address of the virtual map array was working only by a lucky coincidence
    because the memory was present in the EFI page table too. Until Toshi
    went and booted this on a big HP box - the krealloc() manner of resizing
    the memmap we're doing did allocate from such physical addresses which
    were not mapped anymore and boom:
    
    http://lkml.kernel.org/r/1386806463.1791.295.camel@misato.fc.hp.com
    
    One way to take care of that issue is to reimplement the krealloc thing
    but with pages. We start with contiguous pages of order 1, i.e. 2 pages,
    and when we deplete that memory (shouldn't happen all that often but you
    know firmware) we realloc the next power-of-two pages.
    
    Having the pages, it is much more handy and easy to map them into the
    EFI page table with the already existing mapping code which we're using
    for building the virtual mappings.
    
    Thanks to Toshi Kani and Matt for the great debugging help.
    
    Reported-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index e05c69b46f05..19280900ec25 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -137,12 +137,38 @@ void efi_sync_low_kernel_mappings(void)
 		sizeof(pgd_t) * num_pgds);
 }
 
-void efi_setup_page_tables(void)
+int efi_setup_page_tables(unsigned long pa_memmap, unsigned num_pages)
 {
+	pgd_t *pgd;
+
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return 0;
+
 	efi_scratch.efi_pgt = (pgd_t *)(unsigned long)real_mode_header->trampoline_pgd;
+	pgd = __va(efi_scratch.efi_pgt);
 
-	if (!efi_enabled(EFI_OLD_MEMMAP))
-		efi_scratch.use_pgd = true;
+	/*
+	 * It can happen that the physical address of new_memmap lands in memory
+	 * which is not mapped in the EFI page table. Therefore we need to go
+	 * and ident-map those pages containing the map before calling
+	 * phys_efi_set_virtual_address_map().
+	 */
+	if (kernel_map_pages_in_pgd(pgd, pa_memmap, pa_memmap, num_pages, _PAGE_NX)) {
+		pr_err("Error ident-mapping new memmap (0x%lx)!\n", pa_memmap);
+		return 1;
+	}
+
+	efi_scratch.use_pgd = true;
+
+
+	return 0;
+}
+
+void efi_cleanup_page_tables(unsigned long pa_memmap, unsigned num_pages)
+{
+	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
+
+	kernel_unmap_pages_in_pgd(pgd, pa_memmap, num_pages);
 }
 
 static void __init __map_region(efi_memory_desc_t *md, u64 va)

commit 11cc851254b4bc3bd4430be8db2a41469303a427
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jan 18 12:48:15 2014 +0100

    x86/efi: Dump the EFI page table
    
    This is very useful for debugging issues with the recently added
    pagetable switching code for EFI virtual mode.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 0c2a234fef1e..e05c69b46f05 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -242,3 +242,12 @@ void __init efi_runtime_mkexec(void)
 	if (__supported_pte_mask & _PAGE_NX)
 		runtime_code_page_mkexec();
 }
+
+void __init efi_dump_pagetable(void)
+{
+#ifdef CONFIG_EFI_PGT_DUMP
+	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
+
+	ptdump_walk_pgd_level(NULL, pgd);
+#endif
+}

commit c55d016f7a930dd1c995336017123b469a8c8f5a
Author: Borislav Petkov <bp@suse.de>
Date:   Fri Feb 14 08:24:24 2014 +0100

    x86/efi: Fix 32-bit fallout
    
    We do not enable the new efi memmap on 32-bit and thus we need to run
    runtime_code_page_mkexec() unconditionally there. Fix that.
    
    Reported-and-tested-by: Lejun Zhu <lejun.zhu@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 6284f158a47d..0c2a234fef1e 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -233,3 +233,12 @@ void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 {
 	efi_setup = phys_addr + sizeof(struct setup_data);
 }
+
+void __init efi_runtime_mkexec(void)
+{
+	if (!efi_enabled(EFI_OLD_MEMMAP))
+		return;
+
+	if (__supported_pte_mask & _PAGE_NX)
+		runtime_code_page_mkexec();
+}

commit 518548abd61808ea1e31614ccbdae34d3c32dfa4
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Sat Dec 21 16:09:46 2013 +0000

    x86/efi: Delete superfluous global variables
    
    There's no need to save the runtime map details in global variables, the
    values are only required to pass to efi_runtime_map_setup().
    
    And because 'nr_efi_runtime_map' isn't needed, get_nr_runtime_map() can
    be deleted along with 'efi_data_len'.
    
    Cc: Dave Young <dyoung@redhat.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 324b65103851..6284f158a47d 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -232,5 +232,4 @@ void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 void __init parse_efi_setup(u64 phys_addr, u32 data_len)
 {
 	efi_setup = phys_addr + sizeof(struct setup_data);
-	efi_data_len = data_len - sizeof(struct setup_data);
 }

commit 1fec0533693cd74f2d1a46edd29449cfee429df0
Author: Dave Young <dyoung@redhat.com>
Date:   Fri Dec 20 18:02:19 2013 +0800

    x86/efi: Pass necessary EFI data for kexec via setup_data
    
    Add a new setup_data type SETUP_EFI for kexec use.  Passing the saved
    fw_vendor, runtime, config tables and EFI runtime mappings.
    
    When entering virtual mode, directly mapping the EFI runtime regions
    which we passed in previously. And skip the step to call
    SetVirtualAddressMap().
    
    Specially for HP z420 workstation we need save the smbios physical
    address.  The kernel boot sequence proceeds in the following order.
    Step 2 requires efi.smbios to be the physical address.  However, I found
    that on HP z420 EFI system table has a virtual address of SMBIOS in step
    1.  Hence, we need set it back to the physical address with the smbios
    in efi_setup_data.  (When it is still the physical address, it simply
    sets the same value.)
    
    1. efi_init() - Set efi.smbios from EFI system table
    2. dmi_scan_machine() - Temporary map efi.smbios to access SMBIOS table
    3. efi_enter_virtual_mode() - Map EFI ranges
    
    Tested on ovmf+qemu, lenovo thinkpad, a dell laptop and an
    HP z420 workstation.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ff08cb19630b..324b65103851 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -228,3 +228,9 @@ void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 
 	return (void __iomem *)__va(phys_addr);
 }
+
+void __init parse_efi_setup(u64 phys_addr, u32 data_len)
+{
+	efi_setup = phys_addr + sizeof(struct setup_data);
+	efi_data_len = data_len - sizeof(struct setup_data);
+}

commit 3b2664964bc886ae9d5127c8d3708b1acc0626d2
Author: Dave Young <dyoung@redhat.com>
Date:   Fri Dec 20 18:02:14 2013 +0800

    x86/efi: Add a wrapper function efi_map_region_fixed()
    
    Kexec kernel will use saved runtime virtual mapping, so add a new
    function efi_map_region_fixed() for directly mapping a md to md->virt.
    
    The md is passed in from 1st kernel, the virtual addr is saved in
    md->virt_addr.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index c5a6491d95da..ff08cb19630b 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -199,6 +199,16 @@ void __init efi_map_region(efi_memory_desc_t *md)
 	md->virt_addr = efi_va;
 }
 
+/*
+ * kexec kernel will use efi_map_region_fixed to map efi runtime memory ranges.
+ * md->virt_addr is the original virtual address which had been mapped in kexec
+ * 1st kernel.
+ */
+void __init efi_map_region_fixed(efi_memory_desc_t *md)
+{
+	__map_region(md, md->virt_addr);
+}
+
 void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 				 u32 type, u64 attribute)
 {

commit 2da6e57cce14a1c3b0692d6f877b72e185110e2e
Author: Dave Young <dyoung@redhat.com>
Date:   Fri Dec 20 18:02:13 2013 +0800

    x86/efi: Remove unused variables in __map_region()
    
    variables size and end is useless in this function, thus remove them.
    
    Reported-by: Toshi Kani <toshi.kani@hp.com>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index bf286c386d33..c5a6491d95da 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -148,15 +148,11 @@ void efi_setup_page_tables(void)
 static void __init __map_region(efi_memory_desc_t *md, u64 va)
 {
 	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
-	unsigned long pf = 0, size;
-	u64 end;
+	unsigned long pf = 0;
 
 	if (!(md->attribute & EFI_MEMORY_WB))
 		pf |= _PAGE_PCD;
 
-	size = md->num_pages << PAGE_SHIFT;
-	end  = va + size;
-
 	if (kernel_map_pages_in_pgd(pgd, md->phys_addr, va, md->num_pages, pf))
 		pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
 			   md->phys_addr, va);

commit d2f7cbe7b26a74dbbbf8f325b2a6fd01bc34032c
Author: Borislav Petkov <bp@suse.de>
Date:   Thu Oct 31 17:25:08 2013 +0100

    x86/efi: Runtime services virtual mapping
    
    We map the EFI regions needed for runtime services non-contiguously,
    with preserved alignment on virtual addresses starting from -4G down
    for a total max space of 64G. This way, we provide for stable runtime
    services addresses across kernels so that a kexec'd kernel can still use
    them.
    
    Thus, they're mapped in a separate pagetable so that we don't pollute
    the kernel namespace.
    
    Add an efi= kernel command line parameter for passing miscellaneous
    options and chicken bits from the command line.
    
    While at it, add a chicken bit called "efi=old_map" which can be used as
    a fallback to the old runtime services mapping method in case there's
    some b0rkage with a particular EFI implementation (haha, it is hard to
    hold up the sarcasm here...).
    
    Also, add the UEFI RT VA space to Documentation/x86/x86_64/mm.txt.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 39a0e7f1f0a3..bf286c386d33 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -38,10 +38,28 @@
 #include <asm/efi.h>
 #include <asm/cacheflush.h>
 #include <asm/fixmap.h>
+#include <asm/realmode.h>
 
 static pgd_t *save_pgd __initdata;
 static unsigned long efi_flags __initdata;
 
+/*
+ * We allocate runtime services regions bottom-up, starting from -4G, i.e.
+ * 0xffff_ffff_0000_0000 and limit EFI VA mapping space to 64G.
+ */
+static u64 efi_va	= -4 * (1UL << 30);
+#define EFI_VA_END	(-68 * (1UL << 30))
+
+/*
+ * Scratch space used for switching the pagetable in the EFI stub
+ */
+struct efi_scratch {
+	u64 r15;
+	u64 prev_cr3;
+	pgd_t *efi_pgt;
+	bool use_pgd;
+};
+
 static void __init early_code_mapping_set_exec(int executable)
 {
 	efi_memory_desc_t *md;
@@ -65,6 +83,9 @@ void __init efi_call_phys_prelog(void)
 	int pgd;
 	int n_pgds;
 
+	if (!efi_enabled(EFI_OLD_MEMMAP))
+		return;
+
 	early_code_mapping_set_exec(1);
 	local_irq_save(efi_flags);
 
@@ -86,6 +107,10 @@ void __init efi_call_phys_epilog(void)
 	 */
 	int pgd;
 	int n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
+
+	if (!efi_enabled(EFI_OLD_MEMMAP))
+		return;
+
 	for (pgd = 0; pgd < n_pgds; pgd++)
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);
 	kfree(save_pgd);
@@ -94,6 +119,90 @@ void __init efi_call_phys_epilog(void)
 	early_code_mapping_set_exec(0);
 }
 
+/*
+ * Add low kernel mappings for passing arguments to EFI functions.
+ */
+void efi_sync_low_kernel_mappings(void)
+{
+	unsigned num_pgds;
+	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
+
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return;
+
+	num_pgds = pgd_index(MODULES_END - 1) - pgd_index(PAGE_OFFSET);
+
+	memcpy(pgd + pgd_index(PAGE_OFFSET),
+		init_mm.pgd + pgd_index(PAGE_OFFSET),
+		sizeof(pgd_t) * num_pgds);
+}
+
+void efi_setup_page_tables(void)
+{
+	efi_scratch.efi_pgt = (pgd_t *)(unsigned long)real_mode_header->trampoline_pgd;
+
+	if (!efi_enabled(EFI_OLD_MEMMAP))
+		efi_scratch.use_pgd = true;
+}
+
+static void __init __map_region(efi_memory_desc_t *md, u64 va)
+{
+	pgd_t *pgd = (pgd_t *)__va(real_mode_header->trampoline_pgd);
+	unsigned long pf = 0, size;
+	u64 end;
+
+	if (!(md->attribute & EFI_MEMORY_WB))
+		pf |= _PAGE_PCD;
+
+	size = md->num_pages << PAGE_SHIFT;
+	end  = va + size;
+
+	if (kernel_map_pages_in_pgd(pgd, md->phys_addr, va, md->num_pages, pf))
+		pr_warn("Error mapping PA 0x%llx -> VA 0x%llx!\n",
+			   md->phys_addr, va);
+}
+
+void __init efi_map_region(efi_memory_desc_t *md)
+{
+	unsigned long size = md->num_pages << PAGE_SHIFT;
+	u64 pa = md->phys_addr;
+
+	if (efi_enabled(EFI_OLD_MEMMAP))
+		return old_map_region(md);
+
+	/*
+	 * Make sure the 1:1 mappings are present as a catch-all for b0rked
+	 * firmware which doesn't update all internal pointers after switching
+	 * to virtual mode and would otherwise crap on us.
+	 */
+	__map_region(md, md->phys_addr);
+
+	efi_va -= size;
+
+	/* Is PA 2M-aligned? */
+	if (!(pa & (PMD_SIZE - 1))) {
+		efi_va &= PMD_MASK;
+	} else {
+		u64 pa_offset = pa & (PMD_SIZE - 1);
+		u64 prev_va = efi_va;
+
+		/* get us the same offset within this 2M page */
+		efi_va = (efi_va & PMD_MASK) + pa_offset;
+
+		if (efi_va > prev_va)
+			efi_va -= PMD_SIZE;
+	}
+
+	if (efi_va < EFI_VA_END) {
+		pr_warn(FW_WARN "VA address range overflow!\n");
+		return;
+	}
+
+	/* Do the VA map */
+	__map_region(md, efi_va);
+	md->virt_addr = efi_va;
+}
+
 void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 				 u32 type, u64 attribute)
 {

commit 0d01ff2583086fd532181d2ee16112f5342eb78d
Author: David Howells <dhowells@redhat.com>
Date:   Thu Apr 11 23:51:01 2013 +0100

    Include missing linux/slab.h inclusions
    
    Include missing linux/slab.h inclusions where the source file is currently
    expecting to get kmalloc() and co. through linux/proc_fs.h.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    cc: linux-s390@vger.kernel.org
    cc: sparclinux@vger.kernel.org
    cc: linux-efi@vger.kernel.org
    cc: linux-mtd@lists.infradead.org
    cc: devel@driverdev.osuosl.org
    cc: x86@kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 2b2003860615..39a0e7f1f0a3 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -27,6 +27,7 @@
 #include <linux/uaccess.h>
 #include <linux/io.h>
 #include <linux/reboot.h>
+#include <linux/slab.h>
 
 #include <asm/setup.h>
 #include <asm/page.h>

commit b8f2c21db390273c3eaf0e5308faeaeb1e233840
Author: Nathan Zimmer <nzimmer@sgi.com>
Date:   Tue Jan 8 09:02:43 2013 -0600

    efi, x86: Pass a proper identity mapping in efi_call_phys_prelog
    
    Update efi_call_phys_prelog to install an identity mapping of all available
    memory.  This corrects a bug on very large systems with more then 512 GB in
    which bios would not be able to access addresses above not in the mapping.
    
    The result is a crash that looks much like this.
    
    BUG: unable to handle kernel paging request at 000000effd870020
    IP: [<0000000078bce331>] 0x78bce330
    PGD 0
    Oops: 0000 [#1] SMP
    Modules linked in:
    CPU 0
    Pid: 0, comm: swapper/0 Tainted: G        W    3.8.0-rc1-next-20121224-medusa_ntz+ #2 Intel Corp. Stoutland Platform
    RIP: 0010:[<0000000078bce331>]  [<0000000078bce331>] 0x78bce330
    RSP: 0000:ffffffff81601d28  EFLAGS: 00010006
    RAX: 0000000078b80e18 RBX: 0000000000000004 RCX: 0000000000000004
    RDX: 0000000078bcf958 RSI: 0000000000002400 RDI: 8000000000000000
    RBP: 0000000078bcf760 R08: 000000effd870000 R09: 0000000000000000
    R10: 0000000000000000 R11: 00000000000000c3 R12: 0000000000000030
    R13: 000000effd870000 R14: 0000000000000000 R15: ffff88effd870000
    FS:  0000000000000000(0000) GS:ffff88effe400000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 000000effd870020 CR3: 000000000160c000 CR4: 00000000000006b0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process swapper/0 (pid: 0, threadinfo ffffffff81600000, task ffffffff81614400)
    Stack:
     0000000078b80d18 0000000000000004 0000000078bced7b ffff880078b81fff
     0000000000000000 0000000000000082 0000000078bce3a8 0000000000002400
     0000000060000202 0000000078b80da0 0000000078bce45d ffffffff8107cb5a
    Call Trace:
     [<ffffffff8107cb5a>] ? on_each_cpu+0x77/0x83
     [<ffffffff8102f4eb>] ? change_page_attr_set_clr+0x32f/0x3ed
     [<ffffffff81035946>] ? efi_call4+0x46/0x80
     [<ffffffff816c5abb>] ? efi_enter_virtual_mode+0x1f5/0x305
     [<ffffffff816aeb24>] ? start_kernel+0x34a/0x3d2
     [<ffffffff816ae5ed>] ? repair_env_string+0x60/0x60
     [<ffffffff816ae2be>] ? x86_64_start_reservations+0xba/0xc1
     [<ffffffff816ae120>] ? early_idt_handlers+0x120/0x120
     [<ffffffff816ae419>] ? x86_64_start_kernel+0x154/0x163
    Code:  Bad RIP value.
    RIP  [<0000000078bce331>] 0x78bce330
     RSP <ffffffff81601d28>
    CR2: 000000effd870020
    ---[ end trace ead828934fef5eab ]---
    
    Cc: stable@vger.kernel.org
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Nathan Zimmer <nzimmer@sgi.com>
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 95fd505dfeb6..2b2003860615 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -38,7 +38,7 @@
 #include <asm/cacheflush.h>
 #include <asm/fixmap.h>
 
-static pgd_t save_pgd __initdata;
+static pgd_t *save_pgd __initdata;
 static unsigned long efi_flags __initdata;
 
 static void __init early_code_mapping_set_exec(int executable)
@@ -61,12 +61,20 @@ static void __init early_code_mapping_set_exec(int executable)
 void __init efi_call_phys_prelog(void)
 {
 	unsigned long vaddress;
+	int pgd;
+	int n_pgds;
 
 	early_code_mapping_set_exec(1);
 	local_irq_save(efi_flags);
-	vaddress = (unsigned long)__va(0x0UL);
-	save_pgd = *pgd_offset_k(0x0UL);
-	set_pgd(pgd_offset_k(0x0UL), *pgd_offset_k(vaddress));
+
+	n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);
+	save_pgd = kmalloc(n_pgds * sizeof(pgd_t), GFP_KERNEL);
+
+	for (pgd = 0; pgd < n_pgds; pgd++) {
+		save_pgd[pgd] = *pgd_offset_k(pgd * PGDIR_SIZE);
+		vaddress = (unsigned long)__va(pgd * PGDIR_SIZE);
+		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));
+	}
 	__flush_tlb_all();
 }
 
@@ -75,7 +83,11 @@ void __init efi_call_phys_epilog(void)
 	/*
 	 * After the lock is released, the original page table is restored.
 	 */
-	set_pgd(pgd_offset_k(0x0UL), save_pgd);
+	int pgd;
+	int n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);
+	for (pgd = 0; pgd < n_pgds; pgd++)
+		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);
+	kfree(save_pgd);
 	__flush_tlb_all();
 	local_irq_restore(efi_flags);
 	early_code_mapping_set_exec(0);

commit 11520e5e7c1855fc3bf202bb3be35a39d9efa034
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 15 15:15:24 2012 -0800

    Revert "x86-64/efi: Use EFI to deal with platform wall clock (again)"
    
    This reverts commit bd52276fa1d4 ("x86-64/efi: Use EFI to deal with
    platform wall clock (again)"), and the two supporting commits:
    
      da5a108d05b4: "x86/kernel: remove tboot 1:1 page table creation code"
    
      185034e72d59: "x86, efi: 1:1 pagetable mapping for virtual EFI calls")
    
    as they all depend semantically on commit 53b87cf088e2 ("x86, mm:
    Include the entire kernel memory map in trampoline_pgd") that got
    reverted earlier due to the problems it caused.
    
    This was pointed out by Yinghai Lu, and verified by me on my Macbook Air
    that uses EFI.
    
    Pointed-out-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 06c8b2e662ab..95fd505dfeb6 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -58,21 +58,6 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
-unsigned long efi_call_virt_prelog(void)
-{
-	unsigned long saved;
-
-	saved = read_cr3();
-	write_cr3(real_mode_header->trampoline_pgd);
-
-	return saved;
-}
-
-void efi_call_virt_epilog(unsigned long saved)
-{
-	write_cr3(saved);
-}
-
 void __init efi_call_phys_prelog(void)
 {
 	unsigned long vaddress;

commit d42b3a2906a10b732ea7d7f849d49be79d242ef0
Merge: 18dd0bf22b6f e83af1f18c78
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 14 10:08:40 2012 -0800

    Merge branch 'core-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 EFI update from Peter Anvin:
     "EFI tree, from Matt Fleming.  Most of the patches are the new efivarfs
      filesystem by Matt Garrett & co.  The balance are support for EFI
      wallclock in the absence of a hardware-specific driver, and various
      fixes and cleanups."
    
    * 'core-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (24 commits)
      efivarfs: Make efivarfs_fill_super() static
      x86, efi: Check table header length in efi_bgrt_init()
      efivarfs: Use query_variable_info() to limit kmalloc()
      efivarfs: Fix return value of efivarfs_file_write()
      efivarfs: Return a consistent error when efivarfs_get_inode() fails
      efivarfs: Make 'datasize' unsigned long
      efivarfs: Add unique magic number
      efivarfs: Replace magic number with sizeof(attributes)
      efivarfs: Return an error if we fail to read a variable
      efi: Clarify GUID length calculations
      efivarfs: Implement exclusive access for {get,set}_variable
      efivarfs: efivarfs_fill_super() ensure we clean up correctly on error
      efivarfs: efivarfs_fill_super() ensure we free our temporary name
      efivarfs: efivarfs_fill_super() fix inode reference counts
      efivarfs: efivarfs_create() ensure we drop our reference on inode on error
      efivarfs: efivarfs_file_read ensure we free data in error paths
      x86-64/efi: Use EFI to deal with platform wall clock (again)
      x86/kernel: remove tboot 1:1 page table creation code
      x86, efi: 1:1 pagetable mapping for virtual EFI calls
      x86, mm: Include the entire kernel memory map in trampoline_pgd
      ...

commit 185034e72d591f9465e5e18f937ed642e7ea0070
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Sep 7 18:28:04 2012 +0100

    x86, efi: 1:1 pagetable mapping for virtual EFI calls
    
    Some firmware still needs a 1:1 (virt->phys) mapping even after we've
    called SetVirtualAddressMap(). So install the mapping alongside our
    existing kernel mapping whenever we make EFI calls in virtual mode.
    
    This bug was discovered on ASUS machines where the firmware
    implementation of GetTime() accesses the RTC device via physical
    addresses, even though that's bogus per the UEFI spec since we've
    informed the firmware via SetVirtualAddressMap() that the boottime
    memory map is no longer valid.
    
    This bug seems to be present in a lot of consumer devices, so there's
    not a lot we can do about this spec violation apart from workaround
    it.
    
    Cc: JérômeCarretero <cJ-ko@zougloub.eu>
    Cc: Vasco Dias <rafa.vasco@gmail.com>
    Acked-by: Jan Beulich <jbeulich@suse.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ac3aa54e2654..ddb0174cf093 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -58,6 +58,21 @@ static void __init early_code_mapping_set_exec(int executable)
 	}
 }
 
+unsigned long efi_call_virt_prelog(void)
+{
+	unsigned long saved;
+
+	saved = read_cr3();
+	write_cr3(real_mode_header->trampoline_pgd);
+
+	return saved;
+}
+
+void efi_call_virt_epilog(unsigned long saved)
+{
+	write_cr3(saved);
+}
+
 void __init efi_call_phys_prelog(void)
 {
 	unsigned long vaddress;

commit 3e8fa263a97079c74880675c451587bb6899e661
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Oct 19 13:25:46 2012 +0100

    x86/efi: Fix oops caused by incorrect set_memory_uc() usage
    
    Calling __pa() with an ioremap'd address is invalid. If we
    encounter an efi_memory_desc_t without EFI_MEMORY_WB set in
    ->attribute we currently call set_memory_uc(), which in turn
    calls __pa() on a potentially ioremap'd address.
    
    On CONFIG_X86_32 this results in the following oops:
    
      BUG: unable to handle kernel paging request at f7f22280
      IP: [<c10257b9>] reserve_ram_pages_type+0x89/0x210
      *pdpt = 0000000001978001 *pde = 0000000001ffb067 *pte = 0000000000000000
      Oops: 0000 [#1] PREEMPT SMP
      Modules linked in:
    
      Pid: 0, comm: swapper Not tainted 3.0.0-acpi-efi-0805 #3
       EIP: 0060:[<c10257b9>] EFLAGS: 00010202 CPU: 0
       EIP is at reserve_ram_pages_type+0x89/0x210
       EAX: 0070e280 EBX: 38714000 ECX: f7814000 EDX: 00000000
       ESI: 00000000 EDI: 38715000 EBP: c189fef0 ESP: c189fea8
       DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: 0068
      Process swapper (pid: 0, ti=c189e000 task=c18bbe60 task.ti=c189e000)
      Stack:
       80000200 ff108000 00000000 c189ff00 00038714 00000000 00000000 c189fed0
       c104f8ca 00038714 00000000 00038715 00000000 00000000 00038715 00000000
       00000010 38715000 c189ff48 c1025aff 38715000 00000000 00000010 00000000
      Call Trace:
       [<c104f8ca>] ? page_is_ram+0x1a/0x40
       [<c1025aff>] reserve_memtype+0xdf/0x2f0
       [<c1024dc9>] set_memory_uc+0x49/0xa0
       [<c19334d0>] efi_enter_virtual_mode+0x1c2/0x3aa
       [<c19216d4>] start_kernel+0x291/0x2f2
       [<c19211c7>] ? loglevel+0x1b/0x1b
       [<c19210bf>] i386_start_kernel+0xbf/0xc8
    
    The only time we can call set_memory_uc() for a memory region is
    when it is part of the direct kernel mapping. For the case where
    we ioremap a memory region we must leave it alone.
    
    This patch reimplements the fix from e8c7106280a3 ("x86, efi:
    Calling __pa() with an ioremap()ed address is invalid") which
    was reverted in e1ad783b12ec because it caused a regression on
    some MacBooks (they hung at boot). The regression was caused
    because the commit only marked EFI_RUNTIME_SERVICES_DATA as
    E820_RESERVED_EFI, when it should have marked all regions that
    have the EFI_MEMORY_RUNTIME attribute.
    
    Despite first impressions, it's not possible to use
    ioremap_cache() to map all cached memory regions on
    CONFIG_X86_64 because of the way that the memory map might be
    configured as detailed in the following bug report,
    
            https://bugzilla.redhat.com/show_bug.cgi?id=748516
    
    e.g. some of the EFI memory regions *need* to be mapped as part
    of the direct kernel mapping.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Cc: Matthew Garrett <mjg@redhat.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Huang Ying <huang.ying.caritas@gmail.com>
    Cc: Keith Packard <keithp@keithp.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1350649546-23541-1-git-send-email-matt@console-pimps.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ac3aa54e2654..95fd505dfeb6 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -82,7 +82,7 @@ void __init efi_call_phys_epilog(void)
 }
 
 void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
-				 u32 type)
+				 u32 type, u64 attribute)
 {
 	unsigned long last_map_pfn;
 
@@ -92,8 +92,11 @@ void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
 	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {
 		unsigned long top = last_map_pfn << PAGE_SHIFT;
-		efi_ioremap(top, size - (top - phys_addr), type);
+		efi_ioremap(top, size - (top - phys_addr), type, attribute);
 	}
 
+	if (!(attribute & EFI_MEMORY_WB))
+		efi_memory_uc((u64)(unsigned long)__va(phys_addr), size);
+
 	return (void __iomem *)__va(phys_addr);
 }

commit e1ad783b12ec8b69da83479c5d21a0d8180bc519
Author: Keith Packard <keithp@keithp.com>
Date:   Sun Dec 11 16:12:42 2011 -0800

    Revert "x86, efi: Calling __pa() with an ioremap()ed address is invalid"
    
    This hangs my MacBook Air at boot time; I get no console
    messages at all. I reverted this on top of -rc5 and my machine
    boots again.
    
    This reverts commit e8c7106280a305e1ff2a3a8a4dfce141469fb039.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Signed-off-by: Keith Packard <keithp@keithp.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Matthew Garrett <mjg@redhat.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Huang Ying <huang.ying.caritas@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1321621751-3650-1-git-send-email-matt@console
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 312250c6b2de..ac3aa54e2654 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -80,3 +80,20 @@ void __init efi_call_phys_epilog(void)
 	local_irq_restore(efi_flags);
 	early_code_mapping_set_exec(0);
 }
+
+void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
+				 u32 type)
+{
+	unsigned long last_map_pfn;
+
+	if (type == EFI_MEMORY_MAPPED_IO)
+		return ioremap(phys_addr, size);
+
+	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
+	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {
+		unsigned long top = last_map_pfn << PAGE_SHIFT;
+		efi_ioremap(top, size - (top - phys_addr), type);
+	}
+
+	return (void __iomem *)__va(phys_addr);
+}

commit e8c7106280a305e1ff2a3a8a4dfce141469fb039
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Nov 18 13:09:11 2011 +0000

    x86, efi: Calling __pa() with an ioremap()ed address is invalid
    
    If we encounter an efi_memory_desc_t without EFI_MEMORY_WB set
    in ->attribute we currently call set_memory_uc(), which in turn
    calls __pa() on a potentially ioremap'd address.
    
    On CONFIG_X86_32 this is invalid, resulting in the following
    oops on some machines:
    
      BUG: unable to handle kernel paging request at f7f22280
      IP: [<c10257b9>] reserve_ram_pages_type+0x89/0x210
      [...]
    
      Call Trace:
       [<c104f8ca>] ? page_is_ram+0x1a/0x40
       [<c1025aff>] reserve_memtype+0xdf/0x2f0
       [<c1024dc9>] set_memory_uc+0x49/0xa0
       [<c19334d0>] efi_enter_virtual_mode+0x1c2/0x3aa
       [<c19216d4>] start_kernel+0x291/0x2f2
       [<c19211c7>] ? loglevel+0x1b/0x1b
       [<c19210bf>] i386_start_kernel+0xbf/0xc8
    
    A better approach to this problem is to map the memory region
    with the correct attributes from the start, instead of modifying
    it after the fact. The uncached case can be handled by
    ioremap_nocache() and the cached by ioremap_cache().
    
    Despite first impressions, it's not possible to use
    ioremap_cache() to map all cached memory regions on
    CONFIG_X86_64 because EFI_RUNTIME_SERVICES_DATA regions really
    don't like being mapped into the vmalloc space, as detailed in
    the following bug report,
    
            https://bugzilla.redhat.com/show_bug.cgi?id=748516
    
    Therefore, we need to ensure that any EFI_RUNTIME_SERVICES_DATA
    regions are covered by the direct kernel mapping table on
    CONFIG_X86_64. To accomplish this we now map E820_RESERVED_EFI
    regions via the direct kernel mapping with the initial call to
    init_memory_mapping() in setup_arch(), whereas previously these
    regions wouldn't be mapped if they were after the last E820_RAM
    region until efi_ioremap() was called. Doing it this way allows
    us to delete efi_ioremap() completely.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Matthew Garrett <mjg@redhat.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Huang Ying <huang.ying.caritas@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1321621751-3650-1-git-send-email-matt@console-pimps.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ac3aa54e2654..312250c6b2de 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -80,20 +80,3 @@ void __init efi_call_phys_epilog(void)
 	local_irq_restore(efi_flags);
 	early_code_mapping_set_exec(0);
 }
-
-void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
-				 u32 type)
-{
-	unsigned long last_map_pfn;
-
-	if (type == EFI_MEMORY_MAPPED_IO)
-		return ioremap(phys_addr, size);
-
-	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
-	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {
-		unsigned long top = last_map_pfn << PAGE_SHIFT;
-		efi_ioremap(top, size - (top - phys_addr), type);
-	}
-
-	return (void __iomem *)__va(phys_addr);
-}

commit 916f676f8dc016103f983c7ec54c18ecdbb6e349
Author: Matthew Garrett <mjg@redhat.com>
Date:   Wed May 25 09:53:13 2011 -0400

    x86, efi: Retain boot service code until after switching to virtual mode
    
    UEFI stands for "Unified Extensible Firmware Interface", where "Firmware"
    is an ancient African word meaning "Why do something right when you can
    do it so wrong that children will weep and brave adults will cower before
    you", and "UEI" is Celtic for "We missed DOS so we burned it into your
    ROMs". The UEFI specification provides for runtime services (ie, another
    way for the operating system to be forced to depend on the firmware) and
    we rely on these for certain trivial tasks such as setting up the
    bootloader. But some hardware fails to work if we attempt to use these
    runtime services from physical mode, and so we have to switch into virtual
    mode. So far so dreadful.
    
    The specification makes it clear that the operating system is free to do
    whatever it wants with boot services code after ExitBootServices() has been
    called. SetVirtualAddressMap() can't be called until ExitBootServices() has
    been. So, obviously, a whole bunch of EFI implementations call into boot
    services code when we do that. Since we've been charmingly naive and
    trusted that the specification may be somehow relevant to the real world,
    we've already stuffed a picture of a penguin or something in that address
    space. And just to make things more entertaining, we've also marked it
    non-executable.
    
    This patch allocates the boot services regions during EFI init and makes
    sure that they're executable. Then, after SetVirtualAddressMap(), it
    discards them and everyone lives happily ever after. Except for the ones
    who have to work on EFI, who live sad lives haunted by the knowledge that
    someone's eventually going to write yet another firmware specification.
    
    [ hpa: adding this to urgent with a stable tag since it fixes currently-broken
      hardware.  However, I do not know what the dependencies are and so I do
      not know which -stable versions this may be a candidate for. ]
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Link: http://lkml.kernel.org/r/1306331593-28715-1-git-send-email-mjg@redhat.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: <stable@kernel.org>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 2649426a7905..ac3aa54e2654 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -49,10 +49,11 @@ static void __init early_code_mapping_set_exec(int executable)
 	if (!(__supported_pte_mask & _PAGE_NX))
 		return;
 
-	/* Make EFI runtime service code area executable */
+	/* Make EFI service code area executable */
 	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
 		md = p;
-		if (md->type == EFI_RUNTIME_SERVICES_CODE)
+		if (md->type == EFI_RUNTIME_SERVICES_CODE ||
+		    md->type == EFI_BOOT_SERVICES_CODE)
 			efi_set_executable(md, executable);
 	}
 }

commit 935a638241b0658b9749edd060f972575f9d4a78
Author: Matthew Garrett <mjg@redhat.com>
Date:   Thu May 5 15:19:46 2011 -0400

    x86, efi: Ensure that the entirity of a region is mapped
    
    It's possible for init_memory_mapping() to fail to map the entire region
    if it crosses a boundary, so ensure that we complete the mapping.
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Link: http://lkml.kernel.org/r/1304623186-18261-5-git-send-email-mjg@redhat.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 94d6b394b654..2649426a7905 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -89,8 +89,10 @@ void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
 		return ioremap(phys_addr, size);
 
 	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
-	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size)
-		return NULL;
+	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {
+		unsigned long top = last_map_pfn << PAGE_SHIFT;
+		efi_ioremap(top, size - (top - phys_addr), type);
+	}
 
 	return (void __iomem *)__va(phys_addr);
 }

commit 9cd2b07c197e3ff594fc04f5fb3d86efbeab6ad8
Author: Matthew Garrett <mjg@redhat.com>
Date:   Thu May 5 15:19:43 2011 -0400

    x86, efi: Consolidate EFI nx control
    
    The core EFI code and 64-bit EFI code currently have independent
    implementations of code for setting memory regions as executable or not.
    Let's consolidate them.
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Link: http://lkml.kernel.org/r/1304623186-18261-2-git-send-email-mjg@redhat.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index ac0621a7ac3d..94d6b394b654 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -41,22 +41,7 @@
 static pgd_t save_pgd __initdata;
 static unsigned long efi_flags __initdata;
 
-static void __init early_mapping_set_exec(unsigned long start,
-					  unsigned long end,
-					  int executable)
-{
-	unsigned long num_pages;
-
-	start &= PMD_MASK;
-	end = (end + PMD_SIZE - 1) & PMD_MASK;
-	num_pages = (end - start) >> PAGE_SHIFT;
-	if (executable)
-		set_memory_x((unsigned long)__va(start), num_pages);
-	else
-		set_memory_nx((unsigned long)__va(start), num_pages);
-}
-
-static void __init early_runtime_code_mapping_set_exec(int executable)
+static void __init early_code_mapping_set_exec(int executable)
 {
 	efi_memory_desc_t *md;
 	void *p;
@@ -67,11 +52,8 @@ static void __init early_runtime_code_mapping_set_exec(int executable)
 	/* Make EFI runtime service code area executable */
 	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
 		md = p;
-		if (md->type == EFI_RUNTIME_SERVICES_CODE) {
-			unsigned long end;
-			end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
-			early_mapping_set_exec(md->phys_addr, end, executable);
-		}
+		if (md->type == EFI_RUNTIME_SERVICES_CODE)
+			efi_set_executable(md, executable);
 	}
 }
 
@@ -79,7 +61,7 @@ void __init efi_call_phys_prelog(void)
 {
 	unsigned long vaddress;
 
-	early_runtime_code_mapping_set_exec(1);
+	early_code_mapping_set_exec(1);
 	local_irq_save(efi_flags);
 	vaddress = (unsigned long)__va(0x0UL);
 	save_pgd = *pgd_offset_k(0x0UL);
@@ -95,7 +77,7 @@ void __init efi_call_phys_epilog(void)
 	set_pgd(pgd_offset_k(0x0UL), save_pgd);
 	__flush_tlb_all();
 	local_irq_restore(efi_flags);
-	early_runtime_code_mapping_set_exec(0);
+	early_code_mapping_set_exec(0);
 }
 
 void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,

commit b17ed48040d9e8b6ae35bc492015bf0fe1c8bae4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Oct 16 10:19:54 2010 +0200

    x86: Move efi to platform
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Huang Ying <ying.huang@intel.com>

diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
new file mode 100644
index 000000000000..ac0621a7ac3d
--- /dev/null
+++ b/arch/x86/platform/efi/efi_64.c
@@ -0,0 +1,114 @@
+/*
+ * x86_64 specific EFI support functions
+ * Based on Extensible Firmware Interface Specification version 1.0
+ *
+ * Copyright (C) 2005-2008 Intel Co.
+ *	Fenghua Yu <fenghua.yu@intel.com>
+ *	Bibo Mao <bibo.mao@intel.com>
+ *	Chandramouli Narayanan <mouli@linux.intel.com>
+ *	Huang Ying <ying.huang@intel.com>
+ *
+ * Code to convert EFI to E820 map has been implemented in elilo bootloader
+ * based on a EFI patch by Edgar Hucek. Based on the E820 map, the page table
+ * is setup appropriately for EFI runtime code.
+ * - mouli 06/14/2007.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/types.h>
+#include <linux/spinlock.h>
+#include <linux/bootmem.h>
+#include <linux/ioport.h>
+#include <linux/module.h>
+#include <linux/efi.h>
+#include <linux/uaccess.h>
+#include <linux/io.h>
+#include <linux/reboot.h>
+
+#include <asm/setup.h>
+#include <asm/page.h>
+#include <asm/e820.h>
+#include <asm/pgtable.h>
+#include <asm/tlbflush.h>
+#include <asm/proto.h>
+#include <asm/efi.h>
+#include <asm/cacheflush.h>
+#include <asm/fixmap.h>
+
+static pgd_t save_pgd __initdata;
+static unsigned long efi_flags __initdata;
+
+static void __init early_mapping_set_exec(unsigned long start,
+					  unsigned long end,
+					  int executable)
+{
+	unsigned long num_pages;
+
+	start &= PMD_MASK;
+	end = (end + PMD_SIZE - 1) & PMD_MASK;
+	num_pages = (end - start) >> PAGE_SHIFT;
+	if (executable)
+		set_memory_x((unsigned long)__va(start), num_pages);
+	else
+		set_memory_nx((unsigned long)__va(start), num_pages);
+}
+
+static void __init early_runtime_code_mapping_set_exec(int executable)
+{
+	efi_memory_desc_t *md;
+	void *p;
+
+	if (!(__supported_pte_mask & _PAGE_NX))
+		return;
+
+	/* Make EFI runtime service code area executable */
+	for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
+		md = p;
+		if (md->type == EFI_RUNTIME_SERVICES_CODE) {
+			unsigned long end;
+			end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
+			early_mapping_set_exec(md->phys_addr, end, executable);
+		}
+	}
+}
+
+void __init efi_call_phys_prelog(void)
+{
+	unsigned long vaddress;
+
+	early_runtime_code_mapping_set_exec(1);
+	local_irq_save(efi_flags);
+	vaddress = (unsigned long)__va(0x0UL);
+	save_pgd = *pgd_offset_k(0x0UL);
+	set_pgd(pgd_offset_k(0x0UL), *pgd_offset_k(vaddress));
+	__flush_tlb_all();
+}
+
+void __init efi_call_phys_epilog(void)
+{
+	/*
+	 * After the lock is released, the original page table is restored.
+	 */
+	set_pgd(pgd_offset_k(0x0UL), save_pgd);
+	__flush_tlb_all();
+	local_irq_restore(efi_flags);
+	early_runtime_code_mapping_set_exec(0);
+}
+
+void __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,
+				 u32 type)
+{
+	unsigned long last_map_pfn;
+
+	if (type == EFI_MEMORY_MAPPED_IO)
+		return ioremap(phys_addr, size);
+
+	last_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);
+	if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size)
+		return NULL;
+
+	return (void __iomem *)__va(phys_addr);
+}
