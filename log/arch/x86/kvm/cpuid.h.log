commit cc440cdad5b7a4c1de12dace725209eb3e0cf663
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed May 13 13:36:32 2020 -0400

    KVM: nSVM: implement KVM_GET_NESTED_STATE and KVM_SET_NESTED_STATE
    
    Similar to VMX, the state that is captured through the currently available
    IOCTLs is a mix of L1 and L2 state, dependent on whether the L2 guest was
    running at the moment when the process was interrupted to save its state.
    
    In particular, the SVM-specific state for nested virtualization includes
    the L1 saved state (including the interrupt flag), the cached L2 controls,
    and the GIF.
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 63a70f6a3df3..05434cd9342f 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -303,4 +303,9 @@ static __always_inline void kvm_cpu_cap_check_and_set(unsigned int x86_feature)
 		kvm_cpu_cap_set(x86_feature);
 }
 
+static inline bool page_address_valid(struct kvm_vcpu *vcpu, gpa_t gpa)
+{
+	return PAGE_ALIGNED(gpa) && !(gpa >> cpuid_maxphyaddr(vcpu));
+}
+
 #endif

commit 855c7e9b9c2c39fb8d108ac70d0eed530f80a2aa
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Wed Mar 25 12:12:59 2020 -0700

    KVM: x86: Fix BUILD_BUG() in __cpuid_entry_get_reg() w/ CONFIG_UBSAN=y
    
    Take the target reg in __cpuid_entry_get_reg() instead of a pointer to a
    struct cpuid_reg.  When building with -fsanitize=alignment (enabled by
    CONFIG_UBSAN=y), some versions of gcc get tripped up on the pointer and
    trigger the BUILD_BUG().
    
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Fixes: d8577a4c238f8 ("KVM: x86: Do host CPUID at load time to mask KVM cpu caps")
    Fixes: 4c61534aaae2a ("KVM: x86: Introduce cpuid_entry_{get,has}() accessors")
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Message-Id: <20200325191259.23559-1-sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 23b4cd1ad986..63a70f6a3df3 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -99,9 +99,9 @@ static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned int x86_featu
 }
 
 static __always_inline u32 *__cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
-						  const struct cpuid_reg *cpuid)
+						  u32 reg)
 {
-	switch (cpuid->reg) {
+	switch (reg) {
 	case CPUID_EAX:
 		return &entry->eax;
 	case CPUID_EBX:
@@ -121,7 +121,7 @@ static __always_inline u32 *cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
 {
 	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
 
-	return __cpuid_entry_get_reg(entry, &cpuid);
+	return __cpuid_entry_get_reg(entry, cpuid.reg);
 }
 
 static __always_inline u32 cpuid_entry_get(struct kvm_cpuid_entry2 *entry,
@@ -189,7 +189,7 @@ static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
 	if (!entry)
 		return NULL;
 
-	return __cpuid_entry_get_reg(entry, &cpuid);
+	return __cpuid_entry_get_reg(entry, cpuid.reg);
 }
 
 static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu,

commit f91af5176cce77bb0d3292e46665c30af0792dcd
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Wed Mar 4 17:34:37 2020 -0800

    KVM: x86: Refactor kvm_cpuid() param that controls out-of-range logic
    
    Invert and rename the kvm_cpuid() param that controls out-of-range logic
    to better reflect the semantics of the affected callers, i.e. callers
    that bypass the out-of-range logic do so because they are looking up an
    exact guest CPUID entry, e.g. to query the maxphyaddr.
    
    Similarly, rename kvm_cpuid()'s internal "found" to "exact" to clarify
    that it tracks whether or not the exact requested leaf was found, as
    opposed to any usable leaf being found.
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a0988609f620..23b4cd1ad986 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -25,7 +25,7 @@ int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,
 			      struct kvm_cpuid2 *cpuid,
 			      struct kvm_cpuid_entry2 __user *entries);
 bool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,
-	       u32 *ecx, u32 *edx, bool check_limit);
+	       u32 *ecx, u32 *edx, bool exact_only);
 
 int cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu);
 

commit 23493d0a1731205a4bccaa0e283da642ca6f6e29
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Wed Mar 4 17:34:33 2020 -0800

    KVM x86: Extend AMD specific guest behavior to Hygon virtual CPUs
    
    Extend guest_cpuid_is_amd() to cover Hygon virtual CPUs and rename it
    accordingly.  Hygon CPUs use an AMD-based core and so have the same
    basic behavior as AMD CPUs.
    
    Fixes: b8f4abb652146 ("x86/kvm: Add Hygon Dhyana support to KVM")
    Cc: Pu Wen <puwen@hygon.cn>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index cccfd854aacf..a0988609f620 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -214,12 +214,14 @@ static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu,
 		*reg &= ~__feature_bit(x86_feature);
 }
 
-static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
+static inline bool guest_cpuid_is_amd_or_hygon(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;
 
 	best = kvm_find_cpuid_entry(vcpu, 0, 0);
-	return best && is_guest_vendor_amd(best->ebx, best->ecx, best->edx);
+	return best &&
+	       (is_guest_vendor_amd(best->ebx, best->ecx, best->edx) ||
+		is_guest_vendor_hygon(best->ebx, best->ecx, best->edx));
 }
 
 static inline int guest_cpuid_family(struct kvm_vcpu *vcpu)

commit 15608ed03f10a1414188612b0ee9653e3c78bbd9
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Wed Mar 4 17:34:32 2020 -0800

    KVM: x86: Add helpers to perform CPUID-based guest vendor check
    
    Add helpers to provide CPUID-based guest vendor checks, i.e. to do the
    ugly register comparisons.  Use the new helpers to check for an AMD
    guest vendor in guest_cpuid_is_amd() as well as in the existing emulator
    flows.
    
    Using the new helpers fixes a _very_ theoretical bug where
    guest_cpuid_is_amd() would get a false positive on a non-AMD virtual CPU
    with a vendor string beginning with "Auth" due to the previous logic
    only checking EBX.  It also fixes a marginally less theoretically bug
    where guest_cpuid_is_amd() would incorrectly return false for a guest
    CPU with "AMDisbetter!" as its vendor string.
    
    Fixes: a0c0feb57992c ("KVM: x86: reserve bit 8 of non-leaf PDPEs and PML4Es in 64-bit mode on AMD")
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index e9a3277ce256..cccfd854aacf 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -219,7 +219,7 @@ static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
 	struct kvm_cpuid_entry2 *best;
 
 	best = kvm_find_cpuid_entry(vcpu, 0, 0);
-	return best && best->ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx;
+	return best && is_guest_vendor_amd(best->ebx, best->ecx, best->edx);
 }
 
 static inline int guest_cpuid_family(struct kvm_vcpu *vcpu)

commit bd79199990477bf0c316b32bfcbd9862dc0f08ec
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:53 2020 -0800

    KVM: x86: Override host CPUID results with kvm_cpu_caps
    
    Override CPUID entries with kvm_cpu_caps during KVM_GET_SUPPORTED_CPUID
    instead of masking the host CPUID result, which is redundant now that
    the host CPUID is incorporated into kvm_cpu_caps at runtime.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index e3dc0f02ad5c..e9a3277ce256 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -170,13 +170,13 @@ static __always_inline void cpuid_entry_change(struct kvm_cpuid_entry2 *entry,
 		*reg &= ~__feature_bit(x86_feature);
 }
 
-static __always_inline void cpuid_entry_mask(struct kvm_cpuid_entry2 *entry,
-					     enum cpuid_leafs leaf)
+static __always_inline void cpuid_entry_override(struct kvm_cpuid_entry2 *entry,
+						 enum cpuid_leafs leaf)
 {
 	u32 *reg = cpuid_entry_get_reg(entry, leaf * 32);
 
 	BUILD_BUG_ON(leaf >= ARRAY_SIZE(kvm_cpu_caps));
-	*reg &= kvm_cpu_caps[leaf];
+	*reg = kvm_cpu_caps[leaf];
 }
 
 static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,

commit c10398b6d0ddb9c8234890828ab83341e11f9840
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:46 2020 -0800

    KVM: x86: Use KVM cpu caps to mark CR4.LA57 as not-reserved
    
    Add accessor(s) for KVM cpu caps and use said accessor to detect
    hardware support for LA57 instead of manually querying CPUID.
    
    Note, the explicit conversion to bool via '!!' in kvm_cpu_cap_has() is
    technically unnecessary, but it gives people a warm fuzzy feeling.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index fd29b646916a..e3dc0f02ad5c 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -282,6 +282,19 @@ static __always_inline void kvm_cpu_cap_set(unsigned int x86_feature)
 	kvm_cpu_caps[x86_leaf] |= __feature_bit(x86_feature);
 }
 
+static __always_inline u32 kvm_cpu_cap_get(unsigned int x86_feature)
+{
+	unsigned int x86_leaf = x86_feature / 32;
+
+	reverse_cpuid_check(x86_leaf);
+	return kvm_cpu_caps[x86_leaf] & __feature_bit(x86_feature);
+}
+
+static __always_inline bool kvm_cpu_cap_has(unsigned int x86_feature)
+{
+	return !!kvm_cpu_cap_get(x86_feature);
+}
+
 static __always_inline void kvm_cpu_cap_check_and_set(unsigned int x86_feature)
 {
 	if (boot_cpu_has(x86_feature))

commit 8721f5b061eb18c4bb3b77be3ec1c2811ca574ba
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:45 2020 -0800

    KVM: x86: Add a helper to check kernel support when setting cpu cap
    
    Add a helper, kvm_cpu_cap_check_and_set(), to query boot_cpu_has() as
    part of setting a KVM cpu capability.  VMX in particular has a number of
    features that are dependent on both a VMCS capability and kernel
    support.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 13374f885c81..fd29b646916a 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -282,4 +282,10 @@ static __always_inline void kvm_cpu_cap_set(unsigned int x86_feature)
 	kvm_cpu_caps[x86_leaf] |= __feature_bit(x86_feature);
 }
 
+static __always_inline void kvm_cpu_cap_check_and_set(unsigned int x86_feature)
+{
+	if (boot_cpu_has(x86_feature))
+		kvm_cpu_cap_set(x86_feature);
+}
+
 #endif

commit 66a6950f99950c77e2898e48d668eca1dac10a1e
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:41 2020 -0800

    KVM: x86: Introduce kvm_cpu_caps to replace runtime CPUID masking
    
    Calculate the CPUID masks for KVM_GET_SUPPORTED_CPUID at load time using
    what is effectively a KVM-adjusted copy of boot_cpu_data, or more
    precisely, the x86_capability array in boot_cpu_data.
    
    In terms of KVM support, the vast majority of CPUID feature bits are
    constant, and *all* feature support is known at KVM load time.  Rather
    than apply boot_cpu_data, which is effectively read-only after init,
    at runtime, copy it into a KVM-specific array and use *that* to mask
    CPUID registers.
    
    In additional to consolidating the masking, kvm_cpu_caps can be adjusted
    by SVM/VMX at load time and thus eliminate all feature bit manipulation
    in ->set_supported_cpuid().
    
    Opportunistically clean up a few warts:
    
      - Replace bare "unsigned" with "unsigned int" when a feature flag is
        captured in a local variable, e.g. f_nx.
    
      - Sort the CPUID masks by function, index and register (alphabetically
        for registers, i.e. EBX comes before ECX/EDX).
    
      - Remove the superfluous /* cpuid 7.0.ecx */ comments.
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    [Call kvm_set_cpu_caps from kvm_x86_ops->hardware_setup due to fixed
     GBPAGES patch. - Paolo]
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 407dc26c0633..13374f885c81 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -6,6 +6,9 @@
 #include <asm/cpu.h>
 #include <asm/processor.h>
 
+extern u32 kvm_cpu_caps[NCAPINTS] __read_mostly;
+void kvm_set_cpu_caps(void);
+
 int kvm_update_cpuid(struct kvm_vcpu *vcpu);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
 					      u32 function, u32 index);
@@ -172,7 +175,8 @@ static __always_inline void cpuid_entry_mask(struct kvm_cpuid_entry2 *entry,
 {
 	u32 *reg = cpuid_entry_get_reg(entry, leaf * 32);
 
-	*reg &= boot_cpu_data.x86_capability[leaf];
+	BUILD_BUG_ON(leaf >= ARRAY_SIZE(kvm_cpu_caps));
+	*reg &= kvm_cpu_caps[leaf];
 }
 
 static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
@@ -262,4 +266,20 @@ static inline bool cpuid_fault_enabled(struct kvm_vcpu *vcpu)
 		  MSR_MISC_FEATURES_ENABLES_CPUID_FAULT;
 }
 
+static __always_inline void kvm_cpu_cap_clear(unsigned int x86_feature)
+{
+	unsigned int x86_leaf = x86_feature / 32;
+
+	reverse_cpuid_check(x86_leaf);
+	kvm_cpu_caps[x86_leaf] &= ~__feature_bit(x86_feature);
+}
+
+static __always_inline void kvm_cpu_cap_set(unsigned int x86_feature)
+{
+	unsigned int x86_leaf = x86_feature / 32;
+
+	reverse_cpuid_check(x86_leaf);
+	kvm_cpu_caps[x86_leaf] |= __feature_bit(x86_feature);
+}
+
 #endif

commit e745e37d49771b8a06955f18c7a435830c0a4a5c
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:32 2020 -0800

    KVM: x86: Refactor cpuid_mask() to auto-retrieve the register
    
    Use the recently introduced cpuid_entry_get_reg() to automatically get
    the appropriate register when masking a CPUID entry.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index de3c6c365a5a..407dc26c0633 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -167,6 +167,14 @@ static __always_inline void cpuid_entry_change(struct kvm_cpuid_entry2 *entry,
 		*reg &= ~__feature_bit(x86_feature);
 }
 
+static __always_inline void cpuid_entry_mask(struct kvm_cpuid_entry2 *entry,
+					     enum cpuid_leafs leaf)
+{
+	u32 *reg = cpuid_entry_get_reg(entry, leaf * 32);
+
+	*reg &= boot_cpu_data.x86_capability[leaf];
+}
+
 static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
 						     unsigned int x86_feature)
 {

commit b32666b13a72a1fd9f5078d8142bd7325022520f
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:31 2020 -0800

    KVM: x86: Introduce cpuid_entry_{change,set,clear}() mutators
    
    Introduce mutators to modify feature bits in CPUID entries and use the
    new mutators where applicable.  Using the mutators eliminates the need
    to manually specify the register to modify query at no extra cost and
    will allow adding runtime consistency checks on the function/index in a
    future patch.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index bf95428ddf4e..de3c6c365a5a 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -135,6 +135,38 @@ static __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,
 	return cpuid_entry_get(entry, x86_feature);
 }
 
+static __always_inline void cpuid_entry_clear(struct kvm_cpuid_entry2 *entry,
+					      unsigned int x86_feature)
+{
+	u32 *reg = cpuid_entry_get_reg(entry, x86_feature);
+
+	*reg &= ~__feature_bit(x86_feature);
+}
+
+static __always_inline void cpuid_entry_set(struct kvm_cpuid_entry2 *entry,
+					    unsigned int x86_feature)
+{
+	u32 *reg = cpuid_entry_get_reg(entry, x86_feature);
+
+	*reg |= __feature_bit(x86_feature);
+}
+
+static __always_inline void cpuid_entry_change(struct kvm_cpuid_entry2 *entry,
+					       unsigned int x86_feature,
+					       bool set)
+{
+	u32 *reg = cpuid_entry_get_reg(entry, x86_feature);
+
+	/*
+	 * Open coded instead of using cpuid_entry_{clear,set}() to coerce the
+	 * compiler into using CMOV instead of Jcc when possible.
+	 */
+	if (set)
+		*reg |= __feature_bit(x86_feature);
+	else
+		*reg &= ~__feature_bit(x86_feature);
+}
+
 static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
 						     unsigned int x86_feature)
 {

commit 4c61534aaae2a170bf0abd72676624fd3fabc655
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:30 2020 -0800

    KVM: x86: Introduce cpuid_entry_{get,has}() accessors
    
    Introduce accessors to retrieve feature bits from CPUID entries and use
    the new accessors where applicable.  Using the accessors eliminates the
    need to manually specify the register to be queried at no extra cost
    (binary output is identical) and will allow adding runtime consistency
    checks on the function and index in a future patch.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 46b4b61b6cf8..bf95428ddf4e 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -95,17 +95,10 @@ static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned int x86_featu
 	return reverse_cpuid[x86_leaf];
 }
 
-static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
-						     unsigned int x86_feature)
+static __always_inline u32 *__cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
+						  const struct cpuid_reg *cpuid)
 {
-	struct kvm_cpuid_entry2 *entry;
-	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
-
-	entry = kvm_find_cpuid_entry(vcpu, cpuid.function, cpuid.index);
-	if (!entry)
-		return NULL;
-
-	switch (cpuid.reg) {
+	switch (cpuid->reg) {
 	case CPUID_EAX:
 		return &entry->eax;
 	case CPUID_EBX:
@@ -120,6 +113,41 @@ static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
 	}
 }
 
+static __always_inline u32 *cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
+						unsigned int x86_feature)
+{
+	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
+
+	return __cpuid_entry_get_reg(entry, &cpuid);
+}
+
+static __always_inline u32 cpuid_entry_get(struct kvm_cpuid_entry2 *entry,
+					   unsigned int x86_feature)
+{
+	u32 *reg = cpuid_entry_get_reg(entry, x86_feature);
+
+	return *reg & __feature_bit(x86_feature);
+}
+
+static __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,
+					    unsigned int x86_feature)
+{
+	return cpuid_entry_get(entry, x86_feature);
+}
+
+static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
+						     unsigned int x86_feature)
+{
+	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
+	struct kvm_cpuid_entry2 *entry;
+
+	entry = kvm_find_cpuid_entry(vcpu, cpuid.function, cpuid.index);
+	if (!entry)
+		return NULL;
+
+	return __cpuid_entry_get_reg(entry, &cpuid);
+}
+
 static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu,
 					    unsigned int x86_feature)
 {

commit 5e12b2bb34e9fb81d6942f9d300e6d259cc15431
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:29 2020 -0800

    KVM: x86: Replace bare "unsigned" with "unsigned int" in cpuid helpers
    
    Replace "unsigned" with "unsigned int" to make checkpatch and people
    everywhere a little bit happier, and to avoid propagating the filth when
    future patches add more cpuid helpers that work with unsigned (ints).
    
    No functional change intended.
    
    Suggested-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 72a79bdfed6b..46b4b61b6cf8 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -63,7 +63,7 @@ static const struct cpuid_reg reverse_cpuid[] = {
  * and can't be used by KVM to query/control guest capabilities.  And obviously
  * the leaf being queried must have an entry in the lookup table.
  */
-static __always_inline void reverse_cpuid_check(unsigned x86_leaf)
+static __always_inline void reverse_cpuid_check(unsigned int x86_leaf)
 {
 	BUILD_BUG_ON(x86_leaf == CPUID_LNX_1);
 	BUILD_BUG_ON(x86_leaf == CPUID_LNX_2);
@@ -87,15 +87,16 @@ static __always_inline u32 __feature_bit(int x86_feature)
 
 #define feature_bit(name)  __feature_bit(X86_FEATURE_##name)
 
-static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
+static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned int x86_feature)
 {
-	unsigned x86_leaf = x86_feature / 32;
+	unsigned int x86_leaf = x86_feature / 32;
 
 	reverse_cpuid_check(x86_leaf);
 	return reverse_cpuid[x86_leaf];
 }
 
-static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsigned x86_feature)
+static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
+						     unsigned int x86_feature)
 {
 	struct kvm_cpuid_entry2 *entry;
 	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
@@ -119,7 +120,8 @@ static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsi
 	}
 }
 
-static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_feature)
+static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu,
+					    unsigned int x86_feature)
 {
 	u32 *reg;
 
@@ -130,7 +132,8 @@ static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_
 	return *reg & __feature_bit(x86_feature);
 }
 
-static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu, unsigned x86_feature)
+static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu,
+					      unsigned int x86_feature)
 {
 	u32 *reg;
 

commit 3be5a60b454a19979963a246a6286255ce965fcf
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:28 2020 -0800

    KVM: x86: Use u32 for holding CPUID register value in helpers
    
    Change the intermediate CPUID output register values from "int" to "u32"
    to match both hardware and the storage type in struct cpuid_reg.
    
    No functional change intended.
    
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index c1ac0995843d..72a79bdfed6b 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -95,7 +95,7 @@ static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 	return reverse_cpuid[x86_leaf];
 }
 
-static __always_inline int *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsigned x86_feature)
+static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsigned x86_feature)
 {
 	struct kvm_cpuid_entry2 *entry;
 	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
@@ -121,7 +121,7 @@ static __always_inline int *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsi
 
 static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_feature)
 {
-	int *reg;
+	u32 *reg;
 
 	reg = guest_cpuid_get_register(vcpu, x86_feature);
 	if (!reg)
@@ -132,7 +132,7 @@ static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_
 
 static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu, unsigned x86_feature)
 {
-	int *reg;
+	u32 *reg;
 
 	reg = guest_cpuid_get_register(vcpu, x86_feature);
 	if (reg)

commit 615a4ae1c74c2997f19189412fae0326baaf1bff
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Mon Mar 2 15:56:25 2020 -0800

    KVM: x86: Make kvm_mpx_supported() an inline function
    
    Expose kvm_mpx_supported() as a static inline so that it can be inlined
    in kvm_intel.ko.
    
    No functional change intended.
    
    Reviewed-by: Xiaoyao Li <xiaoyao.li@intel.com>
    Reviewed-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 7366c618aa04..c1ac0995843d 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -7,7 +7,6 @@
 #include <asm/processor.h>
 
 int kvm_update_cpuid(struct kvm_vcpu *vcpu);
-bool kvm_mpx_supported(void);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
 					      u32 function, u32 index);
 int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,

commit 87382003e3555926017228452dae7e7064b0f915
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Dec 17 13:32:42 2019 -0800

    KVM: x86: Refactor and rename bit() to feature_bit() macro
    
    Rename bit() to __feature_bit() to give it a more descriptive name, and
    add a macro, feature_bit(), to stuff the X68_FEATURE_ prefix to keep
    line lengths manageable for code that hardcodes the bit to be retrieved.
    
    No functional change intended.
    
    Cc: Jim Mattson <jmattson@google.com>
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index fb3c44b019ec..7366c618aa04 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -80,12 +80,14 @@ static __always_inline void reverse_cpuid_check(unsigned x86_leaf)
  * "word" (stored in bits 31:5).  The word is used to index into arrays of
  * bit masks that hold the per-cpu feature capabilities, e.g. this_cpu_has().
  */
-static __always_inline u32 bit(int x86_feature)
+static __always_inline u32 __feature_bit(int x86_feature)
 {
 	reverse_cpuid_check(x86_feature / 32);
 	return 1 << (x86_feature & 31);
 }
 
+#define feature_bit(name)  __feature_bit(X86_FEATURE_##name)
+
 static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 {
 	unsigned x86_leaf = x86_feature / 32;
@@ -126,7 +128,7 @@ static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_
 	if (!reg)
 		return false;
 
-	return *reg & bit(x86_feature);
+	return *reg & __feature_bit(x86_feature);
 }
 
 static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu, unsigned x86_feature)
@@ -135,7 +137,7 @@ static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu, unsigned x8
 
 	reg = guest_cpuid_get_register(vcpu, x86_feature);
 	if (reg)
-		*reg &= ~bit(x86_feature);
+		*reg &= ~__feature_bit(x86_feature);
 }
 
 static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)

commit a7c48c3f56db8d18d15ee6d8c2c5e2da447c77cc
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Dec 17 13:32:41 2019 -0800

    KVM: x86: Expand build-time assertion on reverse CPUID usage
    
    Add build-time checks to ensure KVM isn't trying to do a reverse CPUID
    lookup on Linux-defined feature bits, along with comments to explain
    the gory details of X86_FEATUREs and bit().
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 5fc424d2e1fa..fb3c44b019ec 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -56,18 +56,41 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_7_1_EAX]       = {         7, 1, CPUID_EAX},
 };
 
-static inline u32 bit(int bitno)
+/*
+ * Reverse CPUID and its derivatives can only be used for hardware-defined
+ * feature words, i.e. words whose bits directly correspond to a CPUID leaf.
+ * Retrieving a feature bit or masking guest CPUID from a Linux-defined word
+ * is nonsensical as the bit number/mask is an arbitrary software-defined value
+ * and can't be used by KVM to query/control guest capabilities.  And obviously
+ * the leaf being queried must have an entry in the lookup table.
+ */
+static __always_inline void reverse_cpuid_check(unsigned x86_leaf)
 {
-	return BIT(bitno & 31);
+	BUILD_BUG_ON(x86_leaf == CPUID_LNX_1);
+	BUILD_BUG_ON(x86_leaf == CPUID_LNX_2);
+	BUILD_BUG_ON(x86_leaf == CPUID_LNX_3);
+	BUILD_BUG_ON(x86_leaf == CPUID_LNX_4);
+	BUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));
+	BUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);
+}
+
+/*
+ * Retrieve the bit mask from an X86_FEATURE_* definition.  Features contain
+ * the hardware defined bit number (stored in bits 4:0) and a software defined
+ * "word" (stored in bits 31:5).  The word is used to index into arrays of
+ * bit masks that hold the per-cpu feature capabilities, e.g. this_cpu_has().
+ */
+static __always_inline u32 bit(int x86_feature)
+{
+	reverse_cpuid_check(x86_feature / 32);
+	return 1 << (x86_feature & 31);
 }
 
 static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 {
 	unsigned x86_leaf = x86_feature / 32;
 
-	BUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));
-	BUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);
-
+	reverse_cpuid_check(x86_leaf);
 	return reverse_cpuid[x86_leaf];
 }
 

commit daa0d8c3a48732e5f64c69cca4c597cab1dfd455
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Dec 17 13:32:40 2019 -0800

    KVM: x86: Add CPUID_7_1_EAX to the reverse CPUID table
    
    Add an entry for CPUID_7_1_EAX in the reserve_cpuid array in preparation
    for incorporating the array in bit() build-time assertions, specifically
    to avoid an assertion on F(AVX512_BF16) in do_cpuid_7_mask().
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index f908f76216bf..5fc424d2e1fa 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -53,6 +53,7 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_7_ECX]         = {         7, 0, CPUID_ECX},
 	[CPUID_8000_0007_EBX] = {0x80000007, 0, CPUID_EBX},
 	[CPUID_7_EDX]         = {         7, 0, CPUID_EDX},
+	[CPUID_7_1_EAX]       = {         7, 1, CPUID_EAX},
 };
 
 static inline u32 bit(int bitno)

commit a0a2260c12d8658e522f21ed8ece72bbdede58fd
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Dec 17 13:32:39 2019 -0800

    KVM: x86: Move bit() helper to cpuid.h
    
    Move bit() to cpuid.h in preparation for incorporating the reverse_cpuid
    array in bit() build-time assertions.  Opportunistically use the BIT()
    macro instead of open-coding the shift.
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index b82ae4d3dc71..f908f76216bf 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -55,6 +55,11 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_7_EDX]         = {         7, 0, CPUID_EDX},
 };
 
+static inline u32 bit(int bitno)
+{
+	return BIT(bitno & 31);
+}
+
 static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 {
 	unsigned x86_leaf = x86_feature / 32;

commit 96be4e069c938e4a5fc7125de7e1cc7089b1adef
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Tue Dec 10 14:44:15 2019 -0800

    KVM: x86: Drop special XSAVE handling from guest_cpuid_has()
    
    Now that KVM prevents setting host-reserved CR4 bits, drop the dedicated
    XSAVE check in guest_cpuid_has() in favor of open coding similar checks
    in the SVM/VMX XSAVES enabling flows.
    
    Note, checking boot_cpu_has(X86_FEATURE_XSAVE) in the XSAVES flows is
    technically redundant with respect to the CR4 reserved bit checks, e.g.
    XSAVES #UDs if CR4.OSXSAVE=0 and arch.xsaves_enabled is consumed if and
    only if CR4.OXSAVE=1 in guest.  Keep (add?) the explicit boot_cpu_has()
    checks to help document KVM's usage of arch.xsaves_enabled.
    
    No functional change intended.
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index d78a61408243..b82ae4d3dc71 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -93,10 +93,6 @@ static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_
 {
 	int *reg;
 
-	if (x86_feature == X86_FEATURE_XSAVE &&
-			!static_cpu_has(X86_FEATURE_XSAVE))
-		return false;
-
 	reg = guest_cpuid_get_register(vcpu, x86_feature);
 	if (!reg)
 		return false;

commit acec0ce081de0c36459eea91647faf99296445a3
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Wed Jun 19 18:51:09 2019 +0200

    x86/cpufeatures: Combine word 11 and 12 into a new scattered features word
    
    It's a waste for the four X86_FEATURE_CQM_* feature bits to occupy two
    whole feature bits words. To better utilize feature words, re-define
    word 11 to host scattered features and move the four X86_FEATURE_CQM_*
    features into Linux defined word 11. More scattered features can be
    added in word 11 in the future.
    
    Rename leaf 11 in cpuid_leafs to CPUID_LNX_4 to reflect it's a
    Linux-defined leaf.
    
    Rename leaf 12 as CPUID_DUMMY which will be replaced by a meaningful
    name in the next patch when CPUID.7.1:EAX occupies world 12.
    
    Maximum number of RMID and cache occupancy scale are retrieved from
    CPUID.0xf.1 after scattered CQM features are enumerated. Carve out the
    code into a separate function.
    
    KVM doesn't support resctrl now. So it's safe to move the
    X86_FEATURE_CQM_* features to scattered features word 11 for KVM.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Aaron Lewis <aaronlewis@google.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Babu Moger <babu.moger@amd.com>
    Cc: "Chang S. Bae" <chang.seok.bae@intel.com>
    Cc: "Sean J Christopherson" <sean.j.christopherson@intel.com>
    Cc: Frederic Weisbecker <frederic@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: kvm ML <kvm@vger.kernel.org>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Nadav Amit <namit@vmware.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Pavel Tatashin <pasha.tatashin@oracle.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: "Peter Zijlstra (Intel)" <peterz@infradead.org>
    Cc: "Radim Krčmář" <rkrcmar@redhat.com>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Ravi V Shankar <ravi.v.shankar@intel.com>
    Cc: Sherry Hurwitz <sherry.hurwitz@amd.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Lendacky <Thomas.Lendacky@amd.com>
    Cc: x86 <x86@kernel.org>
    Link: https://lkml.kernel.org/r/1560794416-217638-2-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 9a327d5b6d1f..d78a61408243 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -47,8 +47,6 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_8000_0001_ECX] = {0x80000001, 0, CPUID_ECX},
 	[CPUID_7_0_EBX]       = {         7, 0, CPUID_EBX},
 	[CPUID_D_1_EAX]       = {       0xd, 1, CPUID_EAX},
-	[CPUID_F_0_EDX]       = {       0xf, 0, CPUID_EDX},
-	[CPUID_F_1_EDX]       = {       0xf, 1, CPUID_EDX},
 	[CPUID_8000_0008_EBX] = {0x80000008, 0, CPUID_EBX},
 	[CPUID_6_EAX]         = {         6, 0, CPUID_EAX},
 	[CPUID_8000_000A_EDX] = {0x8000000a, 0, CPUID_EDX},

commit b7b27aa011a1df42728d1768fc181d9ce69e6911
Author: KarimAllah Ahmed <karahmed@amazon.de>
Date:   Thu Feb 1 22:59:42 2018 +0100

    KVM/x86: Update the reverse_cpuid list to include CPUID_7_EDX
    
    [dwmw2: Stop using KF() for bits in it, too]
    Signed-off-by: KarimAllah Ahmed <karahmed@amazon.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Reviewed-by: Jim Mattson <jmattson@google.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Link: https://lkml.kernel.org/r/1517522386-18410-2-git-send-email-karahmed@amazon.de

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index c2cea6651279..9a327d5b6d1f 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -54,6 +54,7 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_8000_000A_EDX] = {0x8000000a, 0, CPUID_EDX},
 	[CPUID_7_ECX]         = {         7, 0, CPUID_ECX},
 	[CPUID_8000_0007_EBX] = {0x80000007, 0, CPUID_EBX},
+	[CPUID_7_EDX]         = {         7, 0, CPUID_EDX},
 };
 
 static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)

commit 50a671d4d15b859f447fa527191073019b6ce9cb
Author: Janakarajan Natarajan <Janakarajan.Natarajan@amd.com>
Date:   Mon Nov 6 11:44:23 2017 -0600

    KVM: x86: Fix CPUID function for word 6 (80000001_ECX)
    
    The function for CPUID 80000001 ECX is set to 0xc0000001. Set it to
    0x80000001.
    
    Signed-off-by: Janakarajan Natarajan <Janakarajan.Natarajan@amd.com>
    Reviewed-by: Jim Mattson <jmattson@google.com>
    Reviewed-by: Krish Sadhukhan <krish.sadhukhan@oracle.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Fixes: d6321d493319 ("KVM: x86: generalize guest_cpuid_has_ helpers")
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index cdc70a3a6583..c2cea6651279 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -44,7 +44,7 @@ static const struct cpuid_reg reverse_cpuid[] = {
 	[CPUID_8086_0001_EDX] = {0x80860001, 0, CPUID_EDX},
 	[CPUID_1_ECX]         = {         1, 0, CPUID_ECX},
 	[CPUID_C000_0001_EDX] = {0xc0000001, 0, CPUID_EDX},
-	[CPUID_8000_0001_ECX] = {0xc0000001, 0, CPUID_ECX},
+	[CPUID_8000_0001_ECX] = {0x80000001, 0, CPUID_ECX},
 	[CPUID_7_0_EBX]       = {         7, 0, CPUID_EBX},
 	[CPUID_D_1_EAX]       = {       0xd, 1, CPUID_EAX},
 	[CPUID_F_0_EDX]       = {       0xf, 0, CPUID_EDX},

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 0bc5c1315708..cdc70a3a6583 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef ARCH_X86_KVM_CPUID_H
 #define ARCH_X86_KVM_CPUID_H
 

commit 5153723388c8691b886eb9ad28dde92c01f9b191
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Wed Sep 13 15:13:46 2017 +0200

    KVM: x86: fix clang build
    
    Clang resolves __builtin_constant_p() to false even if the expression is
    constant in the end.  The only purpose of that expression was to
    differentiate a case where the following expression couldn't be checked
    at compile-time, so we can just remove the check.
    
    Clang handles the following two correctly.  Turn it into BUG_ON if there
    are any more problems with this.
    
    Fixes: d6321d493319 ("KVM: x86: generalize guest_cpuid_has_ helpers")
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 1ea3c0e1e3a9..0bc5c1315708 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -59,7 +59,6 @@ static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 {
 	unsigned x86_leaf = x86_feature / 32;
 
-	BUILD_BUG_ON(!__builtin_constant_p(x86_leaf));
 	BUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));
 	BUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);
 

commit e911eb3b3414e62cbd9853e0a91c124f4a545c0f
Author: Yu Zhang <yu.c.zhang@linux.intel.com>
Date:   Thu Aug 24 20:27:52 2017 +0800

    KVM: x86: Add return value to kvm_cpuid().
    
    Return false in kvm_cpuid() when it fails to find the cpuid
    entry. Also, this routine(and its caller) is optimized with
    a new argument - check_limit, so that the check_cpuid_limit()
    fall back can be avoided.
    
    Signed-off-by: Yu Zhang <yu.c.zhang@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index ac15193e5e52..1ea3c0e1e3a9 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -21,7 +21,8 @@ int kvm_vcpu_ioctl_set_cpuid2(struct kvm_vcpu *vcpu,
 int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,
 			      struct kvm_cpuid2 *cpuid,
 			      struct kvm_cpuid_entry2 __user *entries);
-void kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx, u32 *ecx, u32 *edx);
+bool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,
+	       u32 *ecx, u32 *edx, bool check_limit);
 
 int cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu);
 

commit 1b4d56b86a370a3785a33eba23e2e3009f5a03af
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Sat Aug 5 00:12:50 2017 +0200

    KVM: x86: use general helpers for some cpuid manipulation
    
    Add guest_cpuid_clear() and use it instead of kvm_find_cpuid_entry().
    Also replace some uses of kvm_find_cpuid_entry() with guest_cpuid_has().
    
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 4e9ac93b4f3a..ac15193e5e52 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -104,6 +104,15 @@ static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_
 	return *reg & bit(x86_feature);
 }
 
+static __always_inline void guest_cpuid_clear(struct kvm_vcpu *vcpu, unsigned x86_feature)
+{
+	int *reg;
+
+	reg = guest_cpuid_get_register(vcpu, x86_feature);
+	if (reg)
+		*reg &= ~bit(x86_feature);
+}
+
 static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit d6321d493319bfd406c484e8359c6101cbda39d3
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Sat Aug 5 00:12:49 2017 +0200

    KVM: x86: generalize guest_cpuid_has_ helpers
    
    This patch turns guest_cpuid_has_XYZ(cpuid) into guest_cpuid_has(cpuid,
    X86_FEATURE_XYZ), which gets rid of many very similar helpers.
    
    When seeing a X86_FEATURE_*, we can know which cpuid it belongs to, but
    this information isn't in common code, so we recreate it for KVM.
    
    Add some BUILD_BUG_ONs to make sure that it runs nicely.
    
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index c723d64657d0..4e9ac93b4f3a 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -3,6 +3,7 @@
 
 #include "x86.h"
 #include <asm/cpu.h>
+#include <asm/processor.h>
 
 int kvm_update_cpuid(struct kvm_vcpu *vcpu);
 bool kvm_mpx_supported(void);
@@ -29,95 +30,78 @@ static inline int cpuid_maxphyaddr(struct kvm_vcpu *vcpu)
 	return vcpu->arch.maxphyaddr;
 }
 
-static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
+struct cpuid_reg {
+	u32 function;
+	u32 index;
+	int reg;
+};
 
-	if (!static_cpu_has(X86_FEATURE_XSAVE))
-		return false;
-
-	best = kvm_find_cpuid_entry(vcpu, 1, 0);
-	return best && (best->ecx & bit(X86_FEATURE_XSAVE));
-}
+static const struct cpuid_reg reverse_cpuid[] = {
+	[CPUID_1_EDX]         = {         1, 0, CPUID_EDX},
+	[CPUID_8000_0001_EDX] = {0x80000001, 0, CPUID_EDX},
+	[CPUID_8086_0001_EDX] = {0x80860001, 0, CPUID_EDX},
+	[CPUID_1_ECX]         = {         1, 0, CPUID_ECX},
+	[CPUID_C000_0001_EDX] = {0xc0000001, 0, CPUID_EDX},
+	[CPUID_8000_0001_ECX] = {0xc0000001, 0, CPUID_ECX},
+	[CPUID_7_0_EBX]       = {         7, 0, CPUID_EBX},
+	[CPUID_D_1_EAX]       = {       0xd, 1, CPUID_EAX},
+	[CPUID_F_0_EDX]       = {       0xf, 0, CPUID_EDX},
+	[CPUID_F_1_EDX]       = {       0xf, 1, CPUID_EDX},
+	[CPUID_8000_0008_EBX] = {0x80000008, 0, CPUID_EBX},
+	[CPUID_6_EAX]         = {         6, 0, CPUID_EAX},
+	[CPUID_8000_000A_EDX] = {0x8000000a, 0, CPUID_EDX},
+	[CPUID_7_ECX]         = {         7, 0, CPUID_ECX},
+	[CPUID_8000_0007_EBX] = {0x80000007, 0, CPUID_EBX},
+};
 
-static inline bool guest_cpuid_has_mtrr(struct kvm_vcpu *vcpu)
+static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned x86_feature)
 {
-	struct kvm_cpuid_entry2 *best;
+	unsigned x86_leaf = x86_feature / 32;
 
-	best = kvm_find_cpuid_entry(vcpu, 1, 0);
-	return best && (best->edx & bit(X86_FEATURE_MTRR));
-}
+	BUILD_BUG_ON(!__builtin_constant_p(x86_leaf));
+	BUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));
+	BUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);
 
-static inline bool guest_cpuid_has_tsc_adjust(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_TSC_ADJUST));
-}
-
-static inline bool guest_cpuid_has_smep(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_SMEP));
+	return reverse_cpuid[x86_leaf];
 }
 
-static inline bool guest_cpuid_has_smap(struct kvm_vcpu *vcpu)
+static __always_inline int *guest_cpuid_get_register(struct kvm_vcpu *vcpu, unsigned x86_feature)
 {
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_SMAP));
-}
-
-static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_FSGSBASE));
-}
-
-static inline bool guest_cpuid_has_pku(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ecx & bit(X86_FEATURE_PKU));
-}
-
-static inline bool guest_cpuid_has_longmode(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
-	return best && (best->edx & bit(X86_FEATURE_LM));
-}
+	struct kvm_cpuid_entry2 *entry;
+	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
 
-static inline bool guest_cpuid_has_osvw(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
+	entry = kvm_find_cpuid_entry(vcpu, cpuid.function, cpuid.index);
+	if (!entry)
+		return NULL;
 
-	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
-	return best && (best->ecx & bit(X86_FEATURE_OSVW));
+	switch (cpuid.reg) {
+	case CPUID_EAX:
+		return &entry->eax;
+	case CPUID_EBX:
+		return &entry->ebx;
+	case CPUID_ECX:
+		return &entry->ecx;
+	case CPUID_EDX:
+		return &entry->edx;
+	default:
+		BUILD_BUG();
+		return NULL;
+	}
 }
 
-static inline bool guest_cpuid_has_pcid(struct kvm_vcpu *vcpu)
+static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu, unsigned x86_feature)
 {
-	struct kvm_cpuid_entry2 *best;
+	int *reg;
 
-	best = kvm_find_cpuid_entry(vcpu, 1, 0);
-	return best && (best->ecx & bit(X86_FEATURE_PCID));
-}
+	if (x86_feature == X86_FEATURE_XSAVE &&
+			!static_cpu_has(X86_FEATURE_XSAVE))
+		return false;
 
-static inline bool guest_cpuid_has_x2apic(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
+	reg = guest_cpuid_get_register(vcpu, x86_feature);
+	if (!reg)
+		return false;
 
-	best = kvm_find_cpuid_entry(vcpu, 1, 0);
-	return best && (best->ecx & bit(X86_FEATURE_X2APIC));
+	return *reg & bit(x86_feature);
 }
 
 static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
@@ -128,46 +112,6 @@ static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
 	return best && best->ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx;
 }
 
-static inline bool guest_cpuid_has_gbpages(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
-	return best && (best->edx & bit(X86_FEATURE_GBPAGES));
-}
-
-static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_RTM));
-}
-
-static inline bool guest_cpuid_has_mpx(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_MPX));
-}
-
-static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
-	return best && (best->edx & bit(X86_FEATURE_RDTSCP));
-}
-
-static inline bool guest_cpuid_has_nrips(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 0x8000000a, 0);
-	return best && (best->edx & bit(X86_FEATURE_NRIPS));
-}
-
 static inline int guest_cpuid_family(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit c6bd18011ff8ea23473a1f4c6d934f761879081d
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Sat Aug 5 00:12:48 2017 +0200

    KVM: x86: X86_FEATURE_NRIPS is not scattered anymore
    
    bit(X86_FEATURE_NRIPS) is 3 since 2ccd71f1b278 ("x86/cpufeature: Move
    some of the scattered feature bits to x86_capability"), so we can
    simplify the code.
    
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index da6728383052..c723d64657d0 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -160,25 +160,13 @@ static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
 	return best && (best->edx & bit(X86_FEATURE_RDTSCP));
 }
 
-/*
- * NRIPS is provided through cpuidfn 0x8000000a.edx bit 3
- */
-#define BIT_NRIPS	3
-
 static inline bool guest_cpuid_has_nrips(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;
 
 	best = kvm_find_cpuid_entry(vcpu, 0x8000000a, 0);
-
-	/*
-	 * NRIPS is a scattered cpuid feature, so we can't use
-	 * X86_FEATURE_NRIPS here (X86_FEATURE_NRIPS would be bit
-	 * position 8, not 3).
-	 */
-	return best && (best->edx & bit(BIT_NRIPS));
+	return best && (best->edx & bit(X86_FEATURE_NRIPS));
 }
-#undef BIT_NRIPS
 
 static inline int guest_cpuid_family(struct kvm_vcpu *vcpu)
 {

commit 4439af9f911ae0243ffe4e2dfc12bace49605d8b
Author: Jim Mattson <jmattson@google.com>
Date:   Wed May 24 10:49:25 2017 -0700

    kvm: x86: Guest BNDCFGS requires guest MPX support
    
    The BNDCFGS MSR should only be exposed to the guest if the guest
    supports MPX. (cf. the TSC_AUX MSR and RDTSCP.)
    
    Fixes: 0dd376e709975779 ("KVM: x86: add MSR_IA32_BNDCFGS to msrs_to_save")
    Change-Id: I3ad7c01bda616715137ceac878f3fa7e66b6b387
    Signed-off-by: Jim Mattson <jmattson@google.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a6fd40aade7c..da6728383052 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -144,6 +144,14 @@ static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_RTM));
 }
 
+static inline bool guest_cpuid_has_mpx(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_MPX));
+}
+
 static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit db2336a80489e7c3c7728cefd9be58fac5ecfb39
Author: Kyle Huey <me@kylehuey.com>
Date:   Mon Mar 20 01:16:28 2017 -0700

    KVM: x86: virtualize cpuid faulting
    
    Hardware support for faulting on the cpuid instruction is not required to
    emulate it, because cpuid triggers a VM exit anyways. KVM handles the relevant
    MSRs (MSR_PLATFORM_INFO and MSR_MISC_FEATURES_ENABLE) and upon a
    cpuid-induced VM exit checks the cpuid faulting state and the CPL.
    kvm_require_cpl is even kind enough to inject the GP fault for us.
    
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    [Return "1" from kvm_emulate_cpuid, it's not void. - Paolo]
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 35058c2c0eea..a6fd40aade7c 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -205,4 +205,15 @@ static inline int guest_cpuid_stepping(struct kvm_vcpu *vcpu)
 	return x86_stepping(best->eax);
 }
 
+static inline bool supports_cpuid_fault(struct kvm_vcpu *vcpu)
+{
+	return vcpu->arch.msr_platform_info & MSR_PLATFORM_INFO_CPUID_FAULT;
+}
+
+static inline bool cpuid_fault_enabled(struct kvm_vcpu *vcpu)
+{
+	return vcpu->arch.msr_misc_features_enables &
+		  MSR_MISC_FEATURES_ENABLES_CPUID_FAULT;
+}
+
 #endif

commit dfa169bbee00671288df25f8ef8a2f6e13fe2581
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 2 11:17:24 2016 -0700

    Revert "KVM: x86: add pcommit support"
    
    This reverts commit 8b3e34e46aca9b6d349b331cd9cf71ccbdc91b2e.
    
    Given the deprecation of the pcommit instruction, the relevant VMX
    features and CPUID bits are not going to be rolled into the SDM.  Remove
    their usage from KVM.
    
    Cc: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index e17a74b1d852..35058c2c0eea 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -144,14 +144,6 @@ static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_RTM));
 }
 
-static inline bool guest_cpuid_has_pcommit(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_PCOMMIT));
-}
-
 static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit b9baba861489041b37b54fc7ee0b0006b5327151
Author: Huaitong Han <huaitong.han@intel.com>
Date:   Tue Mar 22 16:51:21 2016 +0800

    KVM, pkeys: expose CPUID/CR4 to guest
    
    X86_FEATURE_PKU is referred to as "PKU" in the hardware documentation:
    CPUID.7.0.ECX[3]:PKU. X86_FEATURE_OSPKE is software support for pkeys,
    enumerated with CPUID.7.0.ECX[4]:OSPKE, and it reflects the setting of
    CR4.PKE(bit 22).
    
    This patch disables CPUID:PKU without ept, because pkeys is not yet
    implemented for shadow paging.
    
    Signed-off-by: Huaitong Han <huaitong.han@intel.com>
    Reviewed-by: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 66a6581724ad..e17a74b1d852 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -80,6 +80,14 @@ static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_FSGSBASE));
 }
 
+static inline bool guest_cpuid_has_pku(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ecx & bit(X86_FEATURE_PKU));
+}
+
 static inline bool guest_cpuid_has_longmode(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit a87036add09283e6c4f4103a15c596c67b86ab86
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue Mar 8 09:52:13 2016 +0100

    KVM: x86: disable MPX if host did not enable MPX XSAVE features
    
    When eager FPU is disabled, KVM will still see the MPX bit in CPUID and
    presumably the MPX vmentry and vmexit controls.  However, it will not
    be able to expose the MPX XSAVE features to the guest, because the guest's
    accessible XSAVE features are always a subset of host_xcr0.
    
    In this case, we should disable the MPX CPUID bit, the BNDCFGS MSR,
    and the MPX vmentry and vmexit controls for nested virtualization.
    It is then unnecessary to enable guest eager FPU if the guest has the
    MPX CPUID bit set.
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index c8eda1498121..66a6581724ad 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -5,6 +5,7 @@
 #include <asm/cpu.h>
 
 int kvm_update_cpuid(struct kvm_vcpu *vcpu);
+bool kvm_mpx_supported(void);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
 					      u32 function, u32 index);
 int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,
@@ -135,14 +136,6 @@ static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_RTM));
 }
 
-static inline bool guest_cpuid_has_mpx(struct kvm_vcpu *vcpu)
-{
-	struct kvm_cpuid_entry2 *best;
-
-	best = kvm_find_cpuid_entry(vcpu, 7, 0);
-	return best && (best->ebx & bit(X86_FEATURE_MPX));
-}
-
 static inline bool guest_cpuid_has_pcommit(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit 671d5532aaad777782b66eff71bc4dfad25f942d
Merge: 67c707e451e1 0007bccc3cfd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 11 16:46:20 2016 -0800

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cpu updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - Improved CPU ID handling code and related enhancements (Borislav
         Petkov)
    
       - RDRAND fix (Len Brown)"
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86: Replace RDRAND forced-reseed with simple sanity check
      x86/MSR: Chop off lower 32-bit value
      x86/cpu: Fix MSR value truncation issue
      x86/cpu/amd, kvm: Satisfy guest kernel reads of IC_CFG MSR
      kvm: Add accessors for guest CPU's family, model, stepping
      x86/cpu: Unify CPU family, model, stepping calculation

commit e24dea2afc6a0852983dc741072d8e96155e13f5
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue Dec 22 15:20:00 2015 +0100

    KVM: MTRR: treat memory as writeback if MTRR is disabled in guest CPUID
    
    Virtual machines can be run with CPUID such that there are no MTRRs.
    In that case, the firmware will never enable MTRRs and it is obviously
    undesirable to run the guest entirely with UC memory.  Check out guest
    CPUID, and use WB memory if MTRR do not exist.
    
    Cc: qemu-stable@nongnu.org
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=107561
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 06332cb7e7d1..3f5c48ddba45 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -38,6 +38,14 @@ static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_XSAVE));
 }
 
+static inline bool guest_cpuid_has_mtrr(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 1, 0);
+	return best && (best->edx & bit(X86_FEATURE_MTRR));
+}
+
 static inline bool guest_cpuid_has_tsc_adjust(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit 91713faf386be6d7e6556b656436813f8c4ee552
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Nov 23 11:12:22 2015 +0100

    kvm: Add accessors for guest CPU's family, model, stepping
    
    Those give the family, model and stepping of the guest vcpu.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1448273546-2567-3-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 06332cb7e7d1..5d47e0d95ef1 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -2,6 +2,7 @@
 #define ARCH_X86_KVM_CPUID_H
 
 #include "x86.h"
+#include <asm/cpu.h>
 
 int kvm_update_cpuid(struct kvm_vcpu *vcpu);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
@@ -170,4 +171,37 @@ static inline bool guest_cpuid_has_nrips(struct kvm_vcpu *vcpu)
 }
 #undef BIT_NRIPS
 
+static inline int guest_cpuid_family(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x1, 0);
+	if (!best)
+		return -1;
+
+	return x86_family(best->eax);
+}
+
+static inline int guest_cpuid_model(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x1, 0);
+	if (!best)
+		return -1;
+
+	return x86_model(best->eax);
+}
+
+static inline int guest_cpuid_stepping(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x1, 0);
+	if (!best)
+		return -1;
+
+	return x86_stepping(best->eax);
+}
+
 #endif

commit 6092d3d3e6db983048469d424a8f2221915a8dd3
Author: Joerg Roedel <joro@8bytes.org>
Date:   Wed Oct 14 15:10:54 2015 +0200

    kvm: svm: Only propagate next_rip when guest supports it
    
    Currently we always write the next_rip of the shadow vmcb to
    the guests vmcb when we emulate a vmexit. This could confuse
    the guest when its cpuid indicated no support for the
    next_rip feature.
    
    Fix this by only propagating next_rip if the guest actually
    supports it.
    
    Cc: Bandan Das <bsd@redhat.com>
    Cc: Dirk Mueller <dmueller@suse.com>
    Tested-By: Dirk Mueller <dmueller@suse.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index d434ee952b00..06332cb7e7d1 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -149,4 +149,25 @@ static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
 	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
 	return best && (best->edx & bit(X86_FEATURE_RDTSCP));
 }
+
+/*
+ * NRIPS is provided through cpuidfn 0x8000000a.edx bit 3
+ */
+#define BIT_NRIPS	3
+
+static inline bool guest_cpuid_has_nrips(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x8000000a, 0);
+
+	/*
+	 * NRIPS is a scattered cpuid feature, so we can't use
+	 * X86_FEATURE_NRIPS here (X86_FEATURE_NRIPS would be bit
+	 * position 8, not 3).
+	 */
+	return best && (best->edx & bit(BIT_NRIPS));
+}
+#undef BIT_NRIPS
+
 #endif

commit 1cea0ce68ed76490ffa64a9e2a7a40104efe9352
Author: Xiao Guangrong <guangrong.xiao@linux.intel.com>
Date:   Wed Sep 9 14:05:57 2015 +0800

    KVM: VMX: drop rdtscp_enabled field
    
    Check cpuid bit instead of it
    
    Signed-off-by: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index aed7bfeeaf0d..d434ee952b00 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -141,4 +141,12 @@ static inline bool guest_cpuid_has_pcommit(struct kvm_vcpu *vcpu)
 	best = kvm_find_cpuid_entry(vcpu, 7, 0);
 	return best && (best->ebx & bit(X86_FEATURE_PCOMMIT));
 }
+
+static inline bool guest_cpuid_has_rdtscp(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
+	return best && (best->edx & bit(X86_FEATURE_RDTSCP));
+}
 #endif

commit 8b3e34e46aca9b6d349b331cd9cf71ccbdc91b2e
Author: Xiao Guangrong <guangrong.xiao@linux.intel.com>
Date:   Wed Sep 9 14:05:51 2015 +0800

    KVM: x86: add pcommit support
    
    Pass PCOMMIT CPU feature to guest to enable PCOMMIT instruction
    
    Currently we do not catch pcommit instruction for L1 guest and
    allow L1 to catch this instruction for L2 if, as required by the spec,
    L1 can enumerate the PCOMMIT instruction via CPUID:
    | IA32_VMX_PROCBASED_CTLS2[53] (which enumerates support for the
    | 1-setting of PCOMMIT exiting) is always the same as
    | CPUID.07H:EBX.PCOMMIT[bit 22]. Thus, software can set PCOMMIT exiting
    | to 1 if and only if the PCOMMIT instruction is enumerated via CPUID
    
    The spec can be found at
    https://software.intel.com/sites/default/files/managed/0d/53/319433-022.pdf
    
    Signed-off-by: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index dd05b9cef6ae..aed7bfeeaf0d 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -133,4 +133,12 @@ static inline bool guest_cpuid_has_mpx(struct kvm_vcpu *vcpu)
 	best = kvm_find_cpuid_entry(vcpu, 7, 0);
 	return best && (best->ebx & bit(X86_FEATURE_MPX));
 }
+
+static inline bool guest_cpuid_has_pcommit(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_PCOMMIT));
+}
 #endif

commit 660a5d517aaab9187f93854425c4c63f4a09195c
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue May 5 11:50:23 2015 +0200

    KVM: x86: save/load state on SMM switch
    
    The big ugly one.  This patch adds support for switching in and out of
    system management mode, respectively upon receiving KVM_REQ_SMI and upon
    executing a RSM instruction.  Both 32- and 64-bit formats are supported
    for the SMM state save area.
    
    Reviewed-by: Radim Krčmář <rkrcmar@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 496b3695d3d3..dd05b9cef6ae 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -70,6 +70,14 @@ static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_FSGSBASE));
 }
 
+static inline bool guest_cpuid_has_longmode(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
+	return best && (best->edx & bit(X86_FEATURE_LM));
+}
+
 static inline bool guest_cpuid_has_osvw(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit c447e76b4cabb49ddae8e49c5758f031f35d55fb
Author: Liang Li <liang.z.li@intel.com>
Date:   Thu May 21 04:41:25 2015 +0800

    kvm/fpu: Enable eager restore kvm FPU for MPX
    
    The MPX feature requires eager KVM FPU restore support. We have verified
    that MPX cannot work correctly with the current lazy KVM FPU restore
    mechanism. Eager KVM FPU restore should be enabled if the MPX feature is
    exposed to VM.
    
    Signed-off-by: Yang Zhang <yang.z.zhang@intel.com>
    Signed-off-by: Liang Li <liang.z.li@intel.com>
    [Also activate the FPU on AMD processors. - Paolo]
    Cc: stable@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index c3b1ad9fca81..496b3695d3d3 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -117,4 +117,12 @@ static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
 	best = kvm_find_cpuid_entry(vcpu, 7, 0);
 	return best && (best->ebx & bit(X86_FEATURE_RTM));
 }
+
+static inline bool guest_cpuid_has_mpx(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_MPX));
+}
 #endif

commit 5a4f55cde81f1633cb7ae9f0963b722e47acdc36
Author: Eugene Korenevsky <ekorenevsky@gmail.com>
Date:   Sun Mar 29 23:56:12 2015 +0300

    KVM: x86: cache maxphyaddr CPUID leaf in struct kvm_vcpu
    
    cpuid_maxphyaddr(), which performs lot of memory accesses is called
    extensively across KVM, especially in nVMX code.
    
    This patch adds a cached value of maxphyaddr to vcpu.arch to reduce the
    pressure onto CPU cache and simplify the code of cpuid_maxphyaddr()
    callers. The cached value is initialized in kvm_arch_vcpu_init() and
    reloaded every time CPUID is updated by usermode. It is obvious that
    these reloads occur infrequently.
    
    Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
    Message-Id: <20150329205612.GA1223@gnote>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 26228466f3f8..c3b1ad9fca81 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -20,6 +20,12 @@ int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,
 			      struct kvm_cpuid_entry2 __user *entries);
 void kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx, u32 *ecx, u32 *edx);
 
+int cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu);
+
+static inline int cpuid_maxphyaddr(struct kvm_vcpu *vcpu)
+{
+	return vcpu->arch.maxphyaddr;
+}
 
 static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
 {

commit 1d804d079a92138d011900785193b6b00b44bc00
Author: Joe Perches <joe@perches.com>
Date:   Mon Mar 30 16:46:09 2015 -0700

    x86: Use bool function return values of true/false not 1/0
    
    Use the normal return values for bool functions
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Message-Id: <9f593eb2f43b456851cd73f7ed09654ca58fb570.1427759009.git.joe@perches.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 4452eedfaedd..26228466f3f8 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -26,7 +26,7 @@ static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
 	struct kvm_cpuid_entry2 *best;
 
 	if (!static_cpu_has(X86_FEATURE_XSAVE))
-		return 0;
+		return false;
 
 	best = kvm_find_cpuid_entry(vcpu, 1, 0);
 	return best && (best->ecx & bit(X86_FEATURE_XSAVE));

commit dd598091de4aabbc8bd7290a04f364e443c03455
Author: Nadav Amit <namit@cs.technion.ac.il>
Date:   Tue Sep 16 15:10:03 2014 +0300

    KVM: x86: Warn if guest virtual address space is not 48-bits
    
    The KVM emulator code assumes that the guest virtual address space (in 64-bit)
    is 48-bits wide.  Fail the KVM_SET_CPUID and KVM_SET_CPUID2 ioctl if
    userspace tries to create a guest that does not obey this restriction.
    
    Signed-off-by: Nadav Amit <namit@cs.technion.ac.il>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 43b33e301e68..4452eedfaedd 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -3,7 +3,7 @@
 
 #include "x86.h"
 
-void kvm_update_cpuid(struct kvm_vcpu *vcpu);
+int kvm_update_cpuid(struct kvm_vcpu *vcpu);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
 					      u32 function, u32 index);
 int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,

commit a0c0feb57992c5caed170feab8a68c51306eb7c3
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue Sep 2 13:24:12 2014 +0200

    KVM: x86: reserve bit 8 of non-leaf PDPEs and PML4Es in 64-bit mode on AMD
    
    Bit 8 would be the "global" bit, which does not quite make sense for non-leaf
    page table entries.  Intel ignores it; AMD ignores it in PDEs, but reserves it
    in PDPEs and PML4Es.  The SVM test is relying on this behavior, so enforce it.
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a5380590ab0e..43b33e301e68 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -88,6 +88,14 @@ static inline bool guest_cpuid_has_x2apic(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_X2APIC));
 }
 
+static inline bool guest_cpuid_is_amd(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0, 0);
+	return best && best->ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx;
+}
+
 static inline bool guest_cpuid_has_gbpages(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit 6f43ed01e87c8a8dbd8c826eaf0f714c1342c039
Author: Nadav Amit <namit@cs.technion.ac.il>
Date:   Tue Jul 15 17:37:46 2014 +0300

    KVM: x86: DR6/7.RTM cannot be written
    
    Haswell and newer Intel CPUs have support for RTM, and in that case DR6.RTM is
    not fixed to 1 and DR7.RTM is not fixed to zero. That is not the case in the
    current KVM implementation. This bug is apparent only if the MOV-DR instruction
    is emulated or the host also debugs the guest.
    
    This patch is a partial fix which enables DR6.RTM and DR7.RTM to be cleared and
    set respectively. It also sets DR6.RTM upon every debug exception. Obviously,
    it is not a complete fix, as debugging of RTM is still unsupported.
    
    Signed-off-by: Nadav Amit <namit@cs.technion.ac.il>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index f9087315e0cd..a5380590ab0e 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -95,4 +95,12 @@ static inline bool guest_cpuid_has_gbpages(struct kvm_vcpu *vcpu)
 	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
 	return best && (best->edx & bit(X86_FEATURE_GBPAGES));
 }
+
+static inline bool guest_cpuid_has_rtm(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_RTM));
+}
 #endif

commit 5f7dde7bbb3c628766676cbd63c0a1834035d6fa
Author: Nadav Amit <namit@cs.technion.ac.il>
Date:   Wed May 7 15:32:50 2014 +0300

    KVM: x86: Mark bit 7 in long-mode PDPTE according to 1GB pages support
    
    In long-mode, bit 7 in the PDPTE is not reserved only if 1GB pages are
    supported by the CPU. Currently the bit is considered by KVM as always
    reserved.
    
    Signed-off-by: Nadav Amit <namit@cs.technion.ac.il>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index eeecbed26ac7..f9087315e0cd 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -88,4 +88,11 @@ static inline bool guest_cpuid_has_x2apic(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_X2APIC));
 }
 
+static inline bool guest_cpuid_has_gbpages(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
+	return best && (best->edx & bit(X86_FEATURE_GBPAGES));
+}
 #endif

commit 97ec8c067d322d32effdc1701760d3babbc5595f
Author: Feng Wu <feng.wu@intel.com>
Date:   Tue Apr 1 17:46:34 2014 +0800

    KVM: Add SMAP support when setting CR4
    
    This patch adds SMAP handling logic when setting CR4 for guests
    
    Thanks a lot to Paolo Bonzini for his suggestion to use the branchless
    way to detect SMAP violation.
    
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a2a1bb7ed8c1..eeecbed26ac7 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -48,6 +48,14 @@ static inline bool guest_cpuid_has_smep(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_SMEP));
 }
 
+static inline bool guest_cpuid_has_smap(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_SMAP));
+}
+
 static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit 58cb628dbe24ce21b884729aebe15acb903dbfb5
Author: Jan Kiszka <jan.kiszka@siemens.com>
Date:   Fri Jan 24 16:48:44 2014 +0100

    KVM: x86: Validate guest writes to MSR_IA32_APICBASE
    
    Check for invalid state transitions on guest-initiated updates of
    MSR_IA32_APICBASE. This address both enabling of the x2APIC when it is
    not supported and all invalid transitions as described in SDM section
    10.12.5. It also checks that no reserved bit is set in APICBASE by the
    guest.
    
    Signed-off-by: Jan Kiszka <jan.kiszka@siemens.com>
    [Use cpuid_maxphyaddr instead of guest_cpuid_get_phys_bits. - Paolo]
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index f1e4895174b2..a2a1bb7ed8c1 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -72,4 +72,12 @@ static inline bool guest_cpuid_has_pcid(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_PCID));
 }
 
+static inline bool guest_cpuid_has_x2apic(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 1, 0);
+	return best && (best->ecx & bit(X86_FEATURE_X2APIC));
+}
+
 #endif

commit 9c15bb1d0a8411f9bb3395d21d5309bde7da0c1c
Author: Borislav Petkov <bp@suse.de>
Date:   Sun Sep 22 16:44:50 2013 +0200

    kvm: Add KVM_GET_EMULATED_CPUID
    
    Add a kvm ioctl which states which system functionality kvm emulates.
    The format used is that of CPUID and we return the corresponding CPUID
    bits set for which we do emulate functionality.
    
    Make sure ->padding is being passed on clean from userspace so that we
    can use it for something in the future, after the ioctl gets cast in
    stone.
    
    s/kvm_dev_ioctl_get_supported_cpuid/kvm_dev_ioctl_get_cpuid/ while at
    it.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index b7fd07984888..f1e4895174b2 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -6,8 +6,9 @@
 void kvm_update_cpuid(struct kvm_vcpu *vcpu);
 struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
 					      u32 function, u32 index);
-int kvm_dev_ioctl_get_supported_cpuid(struct kvm_cpuid2 *cpuid,
-				      struct kvm_cpuid_entry2 __user *entries);
+int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,
+			    struct kvm_cpuid_entry2 __user *entries,
+			    unsigned int type);
 int kvm_vcpu_ioctl_set_cpuid(struct kvm_vcpu *vcpu,
 			     struct kvm_cpuid *cpuid,
 			     struct kvm_cpuid_entry __user *entries);

commit 66cdd0ceaf65a18996f561b770eedde1d123b019
Merge: 896ea17d3da5 58b7825bc324
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 13 15:31:08 2012 -0800

    Merge tag 'kvm-3.8-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Marcelo Tosatti:
     "Considerable KVM/PPC work, x86 kvmclock vsyscall support,
      IA32_TSC_ADJUST MSR emulation, amongst others."
    
    Fix up trivial conflict in kernel/sched/core.c due to cross-cpu
    migration notifier added next to rq migration call-back.
    
    * tag 'kvm-3.8-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (156 commits)
      KVM: emulator: fix real mode segment checks in address linearization
      VMX: remove unneeded enable_unrestricted_guest check
      KVM: VMX: fix DPL during entry to protected mode
      x86/kexec: crash_vmclear_local_vmcss needs __rcu
      kvm: Fix irqfd resampler list walk
      KVM: VMX: provide the vmclear function and a bitmap to support VMCLEAR in kdump
      x86/kexec: VMCLEAR VMCSs loaded on all cpus if necessary
      KVM: MMU: optimize for set_spte
      KVM: PPC: booke: Get/set guest EPCR register using ONE_REG interface
      KVM: PPC: bookehv: Add EPCR support in mtspr/mfspr emulation
      KVM: PPC: bookehv: Add guest computation mode for irq delivery
      KVM: PPC: Make EPCR a valid field for booke64 and bookehv
      KVM: PPC: booke: Extend MAS2 EPN mask for 64-bit
      KVM: PPC: e500: Mask MAS2 EPN high 32-bits in 32/64 tlbwe emulation
      KVM: PPC: Mask ea's high 32-bits in 32/64 instr emulation
      KVM: PPC: e500: Add emulation helper for getting instruction ea
      KVM: PPC: bookehv64: Add support for interrupt handling
      KVM: PPC: bookehv: Remove GET_VCPU macro from exception handler
      KVM: PPC: booke: Fix get_tb() compile error on 64-bit
      KVM: PPC: e500: Silence bogus GCC warning in tlb code
      ...

commit ba904635d498fea43fc3610983f9dc430ac324e4
Author: Will Auld <will.auld.intel@gmail.com>
Date:   Thu Nov 29 12:42:50 2012 -0800

    KVM: x86: Emulate IA32_TSC_ADJUST MSR
    
    CPUID.7.0.EBX[1]=1 indicates IA32_TSC_ADJUST MSR 0x3b is supported
    
    Basic design is to emulate the MSR by allowing reads and writes to a guest
    vcpu specific location to store the value of the emulated MSR while adding
    the value to the vmcs tsc_offset. In this way the IA32_TSC_ADJUST value will
    be included in all reads to the TSC MSR whether through rdmsr or rdtsc. This
    is of course as long as the "use TSC counter offsetting" VM-execution control
    is enabled as well as the IA32_TSC_ADJUST control.
    
    However, because hardware will only return the TSC + IA32_TSC_ADJUST +
    vmsc tsc_offset for a guest process when it does and rdtsc (with the correct
    settings) the value of our virtualized IA32_TSC_ADJUST must be stored in one
    of these three locations. The argument against storing it in the actual MSR
    is performance. This is likely to be seldom used while the save/restore is
    required on every transition. IA32_TSC_ADJUST was created as a way to solve
    some issues with writing TSC itself so that is not an option either.
    
    The remaining option, defined above as our solution has the problem of
    returning incorrect vmcs tsc_offset values (unless we intercept and fix, not
    done here) as mentioned above. However, more problematic is that storing the
    data in vmcs tsc_offset will have a different semantic effect on the system
    than does using the actual MSR. This is illustrated in the following example:
    
    The hypervisor set the IA32_TSC_ADJUST, then the guest sets it and a guest
    process performs a rdtsc. In this case the guest process will get
    TSC + IA32_TSC_ADJUST_hyperviser + vmsc tsc_offset including
    IA32_TSC_ADJUST_guest. While the total system semantics changed the semantics
    as seen by the guest do not and hence this will not cause a problem.
    
    Signed-off-by: Will Auld <will.auld@intel.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a10e46016851..3a8b50474477 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -28,6 +28,14 @@ static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_XSAVE));
 }
 
+static inline bool guest_cpuid_has_tsc_adjust(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_TSC_ADJUST));
+}
+
 static inline bool guest_cpuid_has_smep(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;

commit 6d1068b3a98519247d8ba4ec85cd40ac136dbdf9
Author: Petr Matousek <pmatouse@redhat.com>
Date:   Tue Nov 6 19:24:07 2012 +0100

    KVM: x86: invalid opcode oops on SET_SREGS with OSXSAVE bit set (CVE-2012-4461)
    
    On hosts without the XSAVE support unprivileged local user can trigger
    oops similar to the one below by setting X86_CR4_OSXSAVE bit in guest
    cr4 register using KVM_SET_SREGS ioctl and later issuing KVM_RUN
    ioctl.
    
    invalid opcode: 0000 [#2] SMP
    Modules linked in: tun ip6table_filter ip6_tables ebtable_nat ebtables
    ...
    Pid: 24935, comm: zoog_kvm_monito Tainted: G      D      3.2.0-3-686-pae
    EIP: 0060:[<f8b9550c>] EFLAGS: 00210246 CPU: 0
    EIP is at kvm_arch_vcpu_ioctl_run+0x92a/0xd13 [kvm]
    EAX: 00000001 EBX: 000f387e ECX: 00000000 EDX: 00000000
    ESI: 00000000 EDI: 00000000 EBP: ef5a0060 ESP: d7c63e70
     DS: 007b ES: 007b FS: 00d8 GS: 00e0 SS: 0068
    Process zoog_kvm_monito (pid: 24935, ti=d7c62000 task=ed84a0c0
    task.ti=d7c62000)
    Stack:
     00000001 f70a1200 f8b940a9 ef5a0060 00000000 00200202 f8769009 00000000
     ef5a0060 000f387e eda5c020 8722f9c8 00015bae 00000000 ed84a0c0 ed84a0c0
     c12bf02d 0000ae80 ef7f8740 fffffffb f359b740 ef5a0060 f8b85dc1 0000ae80
    Call Trace:
     [<f8b940a9>] ? kvm_arch_vcpu_ioctl_set_sregs+0x2fe/0x308 [kvm]
    ...
     [<c12bfb44>] ? syscall_call+0x7/0xb
    Code: 89 e8 e8 14 ee ff ff ba 00 00 04 00 89 e8 e8 98 48 ff ff 85 c0 74
    1e 83 7d 48 00 75 18 8b 85 08 07 00 00 31 c9 8b 95 0c 07 00 00 <0f> 01
    d1 c7 45 48 01 00 00 00 c7 45 1c 01 00 00 00 0f ae f0 89
    EIP: [<f8b9550c>] kvm_arch_vcpu_ioctl_run+0x92a/0xd13 [kvm] SS:ESP
    0068:d7c63e70
    
    QEMU first retrieves the supported features via KVM_GET_SUPPORTED_CPUID
    and then sets them later. So guest's X86_FEATURE_XSAVE should be masked
    out on hosts without X86_FEATURE_XSAVE, making kvm_set_cr4 with
    X86_CR4_OSXSAVE fail. Userspaces that allow specifying guest cpuid with
    X86_FEATURE_XSAVE even on hosts that do not support it, might be
    susceptible to this attack from inside the guest as well.
    
    Allow setting X86_CR4_OSXSAVE bit only if host has XSAVE support.
    
    Signed-off-by: Petr Matousek <pmatouse@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a10e46016851..58fc51488828 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -24,6 +24,9 @@ static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
 {
 	struct kvm_cpuid_entry2 *best;
 
+	if (!static_cpu_has(X86_FEATURE_XSAVE))
+		return 0;
+
 	best = kvm_find_cpuid_entry(vcpu, 1, 0);
 	return best && (best->ecx & bit(X86_FEATURE_XSAVE));
 }

commit ad756a1603c5fac207758faaac7f01c34c9d0b7b
Author: Mao, Junjie <junjie.mao@intel.com>
Date:   Mon Jul 2 01:18:48 2012 +0000

    KVM: VMX: Implement PCID/INVPCID for guests with EPT
    
    This patch handles PCID/INVPCID for guests.
    
    Process-context identifiers (PCIDs) are a facility by which a logical processor
    may cache information for multiple linear-address spaces so that the processor
    may retain cached information when software switches to a different linear
    address space. Refer to section 4.10.1 in IA32 Intel Software Developer's Manual
    Volume 3A for details.
    
    For guests with EPT, the PCID feature is enabled and INVPCID behaves as running
    natively.
    For guests without EPT, the PCID feature is disabled and INVPCID triggers #UD.
    
    Signed-off-by: Junjie Mao <junjie.mao@intel.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index f449edc35e24..a10e46016851 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -52,4 +52,12 @@ static inline bool guest_cpuid_has_osvw(struct kvm_vcpu *vcpu)
 	return best && (best->ecx & bit(X86_FEATURE_OSVW));
 }
 
+static inline bool guest_cpuid_has_pcid(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 1, 0);
+	return best && (best->ecx & bit(X86_FEATURE_PCID));
+}
+
 #endif

commit 62046e5a867cbff35e0beff42718dda41ff5d74b
Author: Avi Kivity <avi@redhat.com>
Date:   Thu Jun 7 14:07:48 2012 +0300

    KVM: Split cpuid register access from computation
    
    Introduce kvm_cpuid() to perform the leaf limit check and calculate
    register values, and let kvm_emulate_cpuid() just handle reading and
    writing the registers from/to the vcpu.  This allows us to reuse
    kvm_cpuid() in a context where directly reading and writing registers
    is not desired.
    
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 26d1fb437eb5..f449edc35e24 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -17,6 +17,7 @@ int kvm_vcpu_ioctl_set_cpuid2(struct kvm_vcpu *vcpu,
 int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,
 			      struct kvm_cpuid2 *cpuid,
 			      struct kvm_cpuid_entry2 __user *entries);
+void kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx, u32 *ecx, u32 *edx);
 
 
 static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)

commit 2b036c6b861dc5da295c6fe19a3edcff7093fdeb
Author: Boris Ostrovsky <boris.ostrovsky@amd.com>
Date:   Mon Jan 9 14:00:35 2012 -0500

    KVM: SVM: Add support for AMD's OSVW feature in guests
    
    In some cases guests should not provide workarounds for errata even when the
    physical processor is affected. For example, because of erratum 400 on family
    10h processors a Linux guest will read an MSR (resulting in VMEXIT) before
    going to idle in order to avoid getting stuck in a non-C0 state. This is not
    necessary: HLT and IO instructions are intercepted and therefore there is no
    reason for erratum 400 workaround in the guest.
    
    This patch allows us to present a guest with certain errata as fixed,
    regardless of the state of actual hardware.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@amd.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 5b97e1797a6d..26d1fb437eb5 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -43,4 +43,12 @@ static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
 	return best && (best->ebx & bit(X86_FEATURE_FSGSBASE));
 }
 
+static inline bool guest_cpuid_has_osvw(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 0x80000001, 0);
+	return best && (best->ecx & bit(X86_FEATURE_OSVW));
+}
+
 #endif

commit 00b27a3efb116062ca5a276ad5cb01ea1b80b5f6
Author: Avi Kivity <avi@redhat.com>
Date:   Wed Nov 23 16:30:32 2011 +0200

    KVM: Move cpuid code to new file
    
    The cpuid code has grown; put it into a separate file.
    
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
new file mode 100644
index 000000000000..5b97e1797a6d
--- /dev/null
+++ b/arch/x86/kvm/cpuid.h
@@ -0,0 +1,46 @@
+#ifndef ARCH_X86_KVM_CPUID_H
+#define ARCH_X86_KVM_CPUID_H
+
+#include "x86.h"
+
+void kvm_update_cpuid(struct kvm_vcpu *vcpu);
+struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,
+					      u32 function, u32 index);
+int kvm_dev_ioctl_get_supported_cpuid(struct kvm_cpuid2 *cpuid,
+				      struct kvm_cpuid_entry2 __user *entries);
+int kvm_vcpu_ioctl_set_cpuid(struct kvm_vcpu *vcpu,
+			     struct kvm_cpuid *cpuid,
+			     struct kvm_cpuid_entry __user *entries);
+int kvm_vcpu_ioctl_set_cpuid2(struct kvm_vcpu *vcpu,
+			      struct kvm_cpuid2 *cpuid,
+			      struct kvm_cpuid_entry2 __user *entries);
+int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,
+			      struct kvm_cpuid2 *cpuid,
+			      struct kvm_cpuid_entry2 __user *entries);
+
+
+static inline bool guest_cpuid_has_xsave(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 1, 0);
+	return best && (best->ecx & bit(X86_FEATURE_XSAVE));
+}
+
+static inline bool guest_cpuid_has_smep(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_SMEP));
+}
+
+static inline bool guest_cpuid_has_fsgsbase(struct kvm_vcpu *vcpu)
+{
+	struct kvm_cpuid_entry2 *best;
+
+	best = kvm_find_cpuid_entry(vcpu, 7, 0);
+	return best && (best->ebx & bit(X86_FEATURE_FSGSBASE));
+}
+
+#endif
