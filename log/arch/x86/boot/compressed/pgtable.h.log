commit b677dfae5aa197afc5191755a76a8727ffca538a
Author: Wei Huang <wei@redhat.com>
Date:   Thu Jan 3 23:44:11 2019 -0600

    x86/boot/compressed/64: Set EFER.LME=1 in 32-bit trampoline before returning to long mode
    
    In some old AMD KVM implementation, guest's EFER.LME bit is cleared by KVM
    when the hypervsior detects that the guest sets CR0.PG to 0. This causes
    the guest OS to reboot when it tries to return from 32-bit trampoline code
    because the CPU is in incorrect state: CR4.PAE=1, CR0.PG=1, CS.L=1, but
    EFER.LME=0.  As a precaution, set EFER.LME=1 as part of long mode
    activation procedure. This extra step won't cause any harm when Linux is
    booted on a bare-metal machine.
    
    Signed-off-by: Wei Huang <wei@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: bp@alien8.de
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20190104054411.12489-1-wei@redhat.com

diff --git a/arch/x86/boot/compressed/pgtable.h b/arch/x86/boot/compressed/pgtable.h
index 91f75638f6e6..6ff7e81b5628 100644
--- a/arch/x86/boot/compressed/pgtable.h
+++ b/arch/x86/boot/compressed/pgtable.h
@@ -6,7 +6,7 @@
 #define TRAMPOLINE_32BIT_PGTABLE_OFFSET	0
 
 #define TRAMPOLINE_32BIT_CODE_OFFSET	PAGE_SIZE
-#define TRAMPOLINE_32BIT_CODE_SIZE	0x60
+#define TRAMPOLINE_32BIT_CODE_SIZE	0x70
 
 #define TRAMPOLINE_32BIT_STACK_END	TRAMPOLINE_32BIT_SIZE
 

commit 32fcefa2bfc8961987e91d1daeb00624b4176d2e
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Mon Feb 26 21:04:50 2018 +0300

    x86/boot/compressed/64: Set up trampoline memory
    
    This patch clears up trampoline memory and copies trampoline code in
    place. It's not yet used though.
    
    Tested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20180226180451.86788-5-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/boot/compressed/pgtable.h b/arch/x86/boot/compressed/pgtable.h
index 57722a2fe2a0..91f75638f6e6 100644
--- a/arch/x86/boot/compressed/pgtable.h
+++ b/arch/x86/boot/compressed/pgtable.h
@@ -3,9 +3,18 @@
 
 #define TRAMPOLINE_32BIT_SIZE		(2 * PAGE_SIZE)
 
+#define TRAMPOLINE_32BIT_PGTABLE_OFFSET	0
+
+#define TRAMPOLINE_32BIT_CODE_OFFSET	PAGE_SIZE
+#define TRAMPOLINE_32BIT_CODE_SIZE	0x60
+
+#define TRAMPOLINE_32BIT_STACK_END	TRAMPOLINE_32BIT_SIZE
+
 #ifndef __ASSEMBLER__
 
 extern unsigned long *trampoline_32bit;
 
+extern void trampoline_32bit_src(void *return_ptr);
+
 #endif /* __ASSEMBLER__ */
 #endif /* BOOT_COMPRESSED_PAGETABLE_H */

commit 3548e131ec6a82208f36e68d31947b0fe244c7a7
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Mon Feb 26 21:04:48 2018 +0300

    x86/boot/compressed/64: Find a place for 32-bit trampoline
    
    If a bootloader enables 64-bit mode with 4-level paging, we might need to
    switch over to 5-level paging. The switching requires the disabling of
    paging, which works fine if kernel itself is loaded below 4G.
    
    But if the bootloader puts the kernel above 4G (not sure if anybody does
    this), we would lose control as soon as paging is disabled, because the
    code becomes unreachable to the CPU.
    
    To handle the situation, we need a trampoline in lower memory that would
    take care of switching on 5-level paging.
    
    This patch finds a spot in low memory for a trampoline.
    
    The heuristic is based on code in reserve_bios_regions().
    
    We find the end of low memory based on BIOS and EBDA start addresses.
    The trampoline is put just before end of low memory. It's mimic approach
    taken to allocate memory for realtime trampoline.
    
    Tested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20180226180451.86788-3-kirill.shutemov@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/boot/compressed/pgtable.h b/arch/x86/boot/compressed/pgtable.h
new file mode 100644
index 000000000000..57722a2fe2a0
--- /dev/null
+++ b/arch/x86/boot/compressed/pgtable.h
@@ -0,0 +1,11 @@
+#ifndef BOOT_COMPRESSED_PAGETABLE_H
+#define BOOT_COMPRESSED_PAGETABLE_H
+
+#define TRAMPOLINE_32BIT_SIZE		(2 * PAGE_SIZE)
+
+#ifndef __ASSEMBLER__
+
+extern unsigned long *trampoline_32bit;
+
+#endif /* __ASSEMBLER__ */
+#endif /* BOOT_COMPRESSED_PAGETABLE_H */
