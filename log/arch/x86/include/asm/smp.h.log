commit d0a7166bc7ac4feac5c482ebe8b2417aa3302ef4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 22 20:47:25 2019 +0200

    x86/smp: Move smp_function_call implementations into IPI code
    
    Move it where it belongs. That allows to keep all the shorthand logic in
    one place.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20190722105220.677835995@linutronix.de

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index e1356a3b8223..e15f364efbcc 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -143,6 +143,7 @@ void play_dead_common(void);
 void wbinvd_on_cpu(int cpu);
 int wbinvd_on_all_cpus(void);
 
+void native_smp_send_reschedule(int cpu);
 void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
 void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);

commit 222a21d29521d144f3dd7a0bc4d4020e448f0126
Merge: 8faef7125d02 eb876fbc248e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 18:28:44 2019 -0700

    Merge branch 'x86-topology-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 topology updates from Ingo Molnar:
     "Implement multi-die topology support on Intel CPUs and expose the die
      topology to user-space tooling, by Len Brown, Kan Liang and Zhang Rui.
    
      These changes should have no effect on the kernel's existing
      understanding of topologies, i.e. there should be no behavioral impact
      on cache, NUMA, scheduler, perf and other topologies and overall
      system performance"
    
    * 'x86-topology-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      perf/x86/intel/rapl: Cosmetic rename internal variables in response to multi-die/pkg support
      perf/x86/intel/uncore: Cosmetic renames in response to multi-die/pkg support
      hwmon/coretemp: Cosmetic: Rename internal variables to zones from packages
      thermal/x86_pkg_temp_thermal: Cosmetic: Rename internal variables to zones from packages
      perf/x86/intel/cstate: Support multi-die/package
      perf/x86/intel/rapl: Support multi-die/package
      perf/x86/intel/uncore: Support multi-die/package
      topology: Create core_cpus and die_cpus sysfs attributes
      topology: Create package_cpus sysfs attribute
      hwmon/coretemp: Support multi-die/package
      powercap/intel_rapl: Update RAPL domain name and debug messages
      thermal/x86_pkg_temp_thermal: Support multi-die/package
      powercap/intel_rapl: Support multi-die/package
      powercap/intel_rapl: Simplify rapl_find_package()
      x86/topology: Define topology_logical_die_id()
      x86/topology: Define topology_die_id()
      cpu/topology: Export die_id
      x86/topology: Create topology_max_die_per_package()
      x86/topology: Add CPUID.1F multi-die/package support

commit 9ed7d75b2f09d836e71d597cd5879abb1a44e7a9
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Feb 27 09:48:51 2019 +0100

    x86/percpu: Relax smp_processor_id()
    
    Nadav reported that since this_cpu_read() became asm-volatile, many
    smp_processor_id() users generated worse code due to the extra
    constraints.
    
    However since smp_processor_id() is reading a stable value, we can use
    __this_cpu_read().
    
    While this does reduce text size somewhat, this mostly results in code
    movement to .text.unlikely as a result of more/larger .cold.
    subfunctions. Less text on the hotpath is good for I$.
    
      $ ./compare.sh defconfig-build1 defconfig-build2 vmlinux.o
      setup_APIC_ibs                                             90         98   -12,+20
      force_ibs_eilvt_setup                                     400        413   -57,+70
      pci_serr_error                                            109        104   -54,+49
      pci_serr_error                                            109        104   -54,+49
      unknown_nmi_error                                         125        120   -76,+71
      unknown_nmi_error                                         125        120   -76,+71
      io_check_error                                            125        132   -97,+104
      intel_thermal_interrupt                                   730        822   +92,+0
      intel_init_thermal                                        951        945   -6,+0
      generic_get_mtrr                                          301        294   -7,+0
      generic_get_mtrr                                          301        294   -7,+0
      generic_set_all                                           749        754   -44,+49
      get_fixed_ranges                                          352        360   -41,+49
      x86_acpi_suspend_lowlevel                                 369        363   -6,+0
      check_tsc_sync_source                                     412        412   -71,+71
      irq_migrate_all_off_this_cpu                              662        674   -14,+26
      clocksource_watchdog                                      748        748   -113,+113
      __perf_event_account_interrupt                            204        197   -7,+0
      attempt_merge                                            1748       1741   -7,+0
      intel_guc_send_ct                                        1424       1409   -15,+0
      __fini_doorbell                                           235        231   -4,+0
      bdw_set_cdclk                                             928        923   -5,+0
      gen11_dsi_disable                                        1571       1556   -15,+0
      gmbus_wait                                                493        488   -5,+0
      md_make_request                                           376        369   -7,+0
      __split_and_process_bio                                   543        536   -7,+0
      delay_tsc                                                  96         89   -7,+0
      hsw_disable_pc8                                           696        691   -5,+0
      tsc_verify_tsc_adjust                                     215        228   -22,+35
      cpuidle_driver_unref                                       56         49   -7,+0
      blk_account_io_completion                                 159        148   -11,+0
      mtrr_wrmsr                                                 95         99   -29,+33
      __intel_wait_for_register_fw                              401        419   +18,+0
      cpuidle_driver_ref                                         43         36   -7,+0
      cpuidle_get_driver                                         15          8   -7,+0
      blk_account_io_done                                       535        528   -7,+0
      irq_migrate_all_off_this_cpu                              662        674   -14,+26
      check_tsc_sync_source                                     412        412   -71,+71
      irq_wait_for_poll                                         170        163   -7,+0
      generic_end_io_acct                                       329        322   -7,+0
      x86_acpi_suspend_lowlevel                                 369        363   -6,+0
      nohz_balance_enter_idle                                   198        191   -7,+0
      generic_start_io_acct                                     254        247   -7,+0
      blk_account_io_start                                      341        334   -7,+0
      perf_event_task_tick                                      682        675   -7,+0
      intel_init_thermal                                        951        945   -6,+0
      amd_e400_c1e_apic_setup                                    47         51   -28,+32
      setup_APIC_eilvt                                          350        328   -22,+0
      hsw_enable_pc8                                           1611       1605   -6,+0
                                                   total   12985947   12985892   -994,+939
    
    Reported-by: Nadav Amit <nadav.amit@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index da545df207b2..0d3fe060a44f 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -162,7 +162,8 @@ __visible void smp_call_function_single_interrupt(struct pt_regs *r);
  * from the initial startup. We map APIC_BASE very early in page_setup(),
  * so this is correct in the x86 case.
  */
-#define raw_smp_processor_id() (this_cpu_read(cpu_number))
+#define raw_smp_processor_id()  this_cpu_read(cpu_number)
+#define __smp_processor_id() __this_cpu_read(cpu_number)
 
 #ifdef CONFIG_X86_32
 extern int safe_smp_processor_id(void);

commit 2e4c54dac7b360c3820399bdf06cde9134a4495b
Author: Len Brown <len.brown@intel.com>
Date:   Mon May 13 13:58:56 2019 -0400

    topology: Create core_cpus and die_cpus sysfs attributes
    
    Create CPU topology sysfs attributes: "core_cpus" and "core_cpus_list"
    
    These attributes represent all of the logical CPUs that share the
    same core.
    
    These attriutes is synonymous with the existing "thread_siblings" and
    "thread_siblings_list" attribute, which will be deprecated.
    
    Create CPU topology sysfs attributes: "die_cpus" and "die_cpus_list".
    These attributes represent all of the logical CPUs that share the
    same die.
    
    Suggested-by: Brice Goglin <Brice.Goglin@inria.fr>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/071c23a298cd27ede6ed0b6460cae190d193364f.1557769318.git.len.brown@intel.com

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index da545df207b2..b673a226ad6c 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -23,6 +23,7 @@ extern unsigned int num_processors;
 
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
+DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_die_map);
 /* cpus sharing the last level cache: */
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_llc_shared_map);
 DECLARE_PER_CPU_READ_MOSTLY(u16, cpu_llc_id);

commit 66c7ceb47f628c8bd4f84a6d01c2725ded6a342d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Apr 14 18:00:04 2019 +0200

    x86/irq/32: Handle irq stack allocation failure proper
    
    irq_ctx_init() crashes hard on page allocation failures. While that's ok
    during early boot, it's just wrong in the CPU hotplug bringup code.
    
    Check the page allocation failure and return -ENOMEM and handle it at the
    call sites. On early boot the only way out is to BUG(), but on CPU hotplug
    there is no reason to crash, so just abort the operation.
    
    Rename the function to something more sensible while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Alison Schofield <alison.schofield@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Anshuman Khandual <anshuman.khandual@arm.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: Pu Wen <puwen@hygon.cn>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: Shaokun Zhang <zhangshaokun@hisilicon.com>
    Cc: Stefano Stabellini <sstabellini@kernel.org>
    Cc: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Cc: x86-ml <x86@kernel.org>
    Cc: xen-devel@lists.xenproject.org
    Cc: Yazen Ghannam <yazen.ghannam@amd.com>
    Cc: Yi Wang <wang.yi59@zte.com.cn>
    Cc: Zhenzhong Duan <zhenzhong.duan@oracle.com>
    Link: https://lkml.kernel.org/r/20190414160146.089060584@linutronix.de

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 2e95b6c1bca3..da545df207b2 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -131,7 +131,7 @@ void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
 void calculate_max_logical_packages(void);
 void native_smp_cpus_done(unsigned int max_cpus);
-void common_cpu_up(unsigned int cpunum, struct task_struct *tidle);
+int common_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_disable(void);
 int common_cpu_die(unsigned int cpu);

commit 89f579ce99f7e028e81885d3965f973c0f787611
Author: Yi Wang <wang.yi59@zte.com.cn>
Date:   Thu Nov 22 10:04:09 2018 +0800

    x86/headers: Fix -Wmissing-prototypes warning
    
    When building the kernel with W=1 we get a lot of -Wmissing-prototypes
    warnings, which are trivial in nature and easy to fix - and which may
    mask some real future bugs if the prototypes get out of sync with
    the function definition.
    
    This patch fixes most of -Wmissing-prototypes warnings which
    are in the root directory of arch/x86/kernel, not including
    the subdirectories.
    
    These are the warnings fixed in this patch:
    
      arch/x86/kernel/signal.c:865:17: warning: no previous prototype for ‘sys32_x32_rt_sigreturn’ [-Wmissing-prototypes]
      arch/x86/kernel/signal_compat.c:164:6: warning: no previous prototype for ‘sigaction_compat_abi’ [-Wmissing-prototypes]
      arch/x86/kernel/traps.c:625:46: warning: no previous prototype for ‘sync_regs’ [-Wmissing-prototypes]
      arch/x86/kernel/traps.c:640:24: warning: no previous prototype for ‘fixup_bad_iret’ [-Wmissing-prototypes]
      arch/x86/kernel/traps.c:929:13: warning: no previous prototype for ‘trap_init’ [-Wmissing-prototypes]
      arch/x86/kernel/irq.c:270:28: warning: no previous prototype for ‘smp_x86_platform_ipi’ [-Wmissing-prototypes]
      arch/x86/kernel/irq.c:301:16: warning: no previous prototype for ‘smp_kvm_posted_intr_ipi’ [-Wmissing-prototypes]
      arch/x86/kernel/irq.c:314:16: warning: no previous prototype for ‘smp_kvm_posted_intr_wakeup_ipi’ [-Wmissing-prototypes]
      arch/x86/kernel/irq.c:328:16: warning: no previous prototype for ‘smp_kvm_posted_intr_nested_ipi’ [-Wmissing-prototypes]
      arch/x86/kernel/irq_work.c:16:28: warning: no previous prototype for ‘smp_irq_work_interrupt’ [-Wmissing-prototypes]
      arch/x86/kernel/irqinit.c:79:13: warning: no previous prototype for ‘init_IRQ’ [-Wmissing-prototypes]
      arch/x86/kernel/quirks.c:672:13: warning: no previous prototype for ‘early_platform_quirks’ [-Wmissing-prototypes]
      arch/x86/kernel/tsc.c:1499:15: warning: no previous prototype for ‘calibrate_delay_is_known’ [-Wmissing-prototypes]
      arch/x86/kernel/process.c:653:13: warning: no previous prototype for ‘arch_post_acpi_subsys_init’ [-Wmissing-prototypes]
      arch/x86/kernel/process.c:717:15: warning: no previous prototype for ‘arch_randomize_brk’ [-Wmissing-prototypes]
      arch/x86/kernel/process.c:784:6: warning: no previous prototype for ‘do_arch_prctl_common’ [-Wmissing-prototypes]
      arch/x86/kernel/reboot.c:869:6: warning: no previous prototype for ‘nmi_panic_self_stop’ [-Wmissing-prototypes]
      arch/x86/kernel/smp.c:176:27: warning: no previous prototype for ‘smp_reboot_interrupt’ [-Wmissing-prototypes]
      arch/x86/kernel/smp.c:260:28: warning: no previous prototype for ‘smp_reschedule_interrupt’ [-Wmissing-prototypes]
      arch/x86/kernel/smp.c:281:28: warning: no previous prototype for ‘smp_call_function_interrupt’ [-Wmissing-prototypes]
      arch/x86/kernel/smp.c:291:28: warning: no previous prototype for ‘smp_call_function_single_interrupt’ [-Wmissing-prototypes]
      arch/x86/kernel/ftrace.c:840:6: warning: no previous prototype for ‘arch_ftrace_update_trampoline’ [-Wmissing-prototypes]
      arch/x86/kernel/ftrace.c:934:7: warning: no previous prototype for ‘arch_ftrace_trampoline_func’ [-Wmissing-prototypes]
      arch/x86/kernel/ftrace.c:946:6: warning: no previous prototype for ‘arch_ftrace_trampoline_free’ [-Wmissing-prototypes]
      arch/x86/kernel/crash.c:114:6: warning: no previous prototype for ‘crash_smp_send_stop’ [-Wmissing-prototypes]
      arch/x86/kernel/crash.c:351:5: warning: no previous prototype for ‘crash_setup_memmap_entries’ [-Wmissing-prototypes]
      arch/x86/kernel/crash.c:424:5: warning: no previous prototype for ‘crash_load_segments’ [-Wmissing-prototypes]
      arch/x86/kernel/machine_kexec_64.c:372:7: warning: no previous prototype for ‘arch_kexec_kernel_image_load’ [-Wmissing-prototypes]
      arch/x86/kernel/paravirt-spinlocks.c:12:16: warning: no previous prototype for ‘__native_queued_spin_unlock’ [-Wmissing-prototypes]
      arch/x86/kernel/paravirt-spinlocks.c:18:6: warning: no previous prototype for ‘pv_is_native_spin_unlock’ [-Wmissing-prototypes]
      arch/x86/kernel/paravirt-spinlocks.c:24:16: warning: no previous prototype for ‘__native_vcpu_is_preempted’ [-Wmissing-prototypes]
      arch/x86/kernel/paravirt-spinlocks.c:30:6: warning: no previous prototype for ‘pv_is_native_vcpu_is_preempted’ [-Wmissing-prototypes]
      arch/x86/kernel/kvm.c:258:1: warning: no previous prototype for ‘do_async_page_fault’ [-Wmissing-prototypes]
      arch/x86/kernel/jailhouse.c:200:6: warning: no previous prototype for ‘jailhouse_paravirt’ [-Wmissing-prototypes]
      arch/x86/kernel/check.c:91:13: warning: no previous prototype for ‘setup_bios_corruption_check’ [-Wmissing-prototypes]
      arch/x86/kernel/check.c:139:6: warning: no previous prototype for ‘check_for_bios_corruption’ [-Wmissing-prototypes]
      arch/x86/kernel/devicetree.c:32:13: warning: no previous prototype for ‘early_init_dt_scan_chosen_arch’ [-Wmissing-prototypes]
      arch/x86/kernel/devicetree.c:42:13: warning: no previous prototype for ‘add_dtb’ [-Wmissing-prototypes]
      arch/x86/kernel/devicetree.c:108:6: warning: no previous prototype for ‘x86_of_pci_init’ [-Wmissing-prototypes]
      arch/x86/kernel/devicetree.c:314:13: warning: no previous prototype for ‘x86_dtb_init’ [-Wmissing-prototypes]
      arch/x86/kernel/tracepoint.c:16:5: warning: no previous prototype for ‘trace_pagefault_reg’ [-Wmissing-prototypes]
      arch/x86/kernel/tracepoint.c:22:6: warning: no previous prototype for ‘trace_pagefault_unreg’ [-Wmissing-prototypes]
      arch/x86/kernel/head64.c:113:22: warning: no previous prototype for ‘__startup_64’ [-Wmissing-prototypes]
      arch/x86/kernel/head64.c:262:15: warning: no previous prototype for ‘__startup_secondary_64’ [-Wmissing-prototypes]
      arch/x86/kernel/head64.c:350:12: warning: no previous prototype for ‘early_make_pgtable’ [-Wmissing-prototypes]
    
    [ mingo: rewrote the changelog, fixed build errors. ]
    
    Signed-off-by: Yi Wang <wang.yi59@zte.com.cn>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: akataria@vmware.com
    Cc: akpm@linux-foundation.org
    Cc: andy.shevchenko@gmail.com
    Cc: anton@enomsg.org
    Cc: ard.biesheuvel@linaro.org
    Cc: bhe@redhat.com
    Cc: bhelgaas@google.com
    Cc: bp@alien8.de
    Cc: ccross@android.com
    Cc: devicetree@vger.kernel.org
    Cc: douly.fnst@cn.fujitsu.com
    Cc: dwmw@amazon.co.uk
    Cc: dyoung@redhat.com
    Cc: ebiederm@xmission.com
    Cc: frank.rowand@sony.com
    Cc: frowand.list@gmail.com
    Cc: ivan.gorinov@intel.com
    Cc: jailhouse-dev@googlegroups.com
    Cc: jan.kiszka@siemens.com
    Cc: jgross@suse.com
    Cc: jroedel@suse.de
    Cc: keescook@chromium.org
    Cc: kexec@lists.infradead.org
    Cc: konrad.wilk@oracle.com
    Cc: kvm@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-pci@vger.kernel.org
    Cc: luto@kernel.org
    Cc: m.mizuma@jp.fujitsu.com
    Cc: namit@vmware.com
    Cc: oleg@redhat.com
    Cc: pasha.tatashin@oracle.com
    Cc: pbonzini@redhat.com
    Cc: prarit@redhat.com
    Cc: pravin.shedge4linux@gmail.com
    Cc: rajvi.jingar@intel.com
    Cc: rkrcmar@redhat.com
    Cc: robh+dt@kernel.org
    Cc: robh@kernel.org
    Cc: rostedt@goodmis.org
    Cc: takahiro.akashi@linaro.org
    Cc: thomas.lendacky@amd.com
    Cc: tony.luck@intel.com
    Cc: up2wing@gmail.com
    Cc: virtualization@lists.linux-foundation.org
    Cc: zhe.he@windriver.com
    Cc: zhong.weidong@zte.com.cn
    Link: http://lkml.kernel.org/r/1542852249-19820-1-git-send-email-wang.yi59@zte.com.cn
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 547c4fe50711..2e95b6c1bca3 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -148,6 +148,12 @@ void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);
 
 void smp_store_boot_cpu_info(void);
 void smp_store_cpu_info(int id);
+
+asmlinkage __visible void smp_reboot_interrupt(void);
+__visible void smp_reschedule_interrupt(struct pt_regs *regs);
+__visible void smp_call_function_interrupt(struct pt_regs *regs);
+__visible void smp_call_function_single_interrupt(struct pt_regs *r);
+
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
 #define cpu_acpi_id(cpu)	per_cpu(x86_cpu_to_acpiid, cpu)
 

commit f8b64d08dde2714c62751d18ba77f4aeceb161d3
Author: Borislav Petkov <bpetkov@suse.de>
Date:   Fri Apr 27 16:34:34 2018 -0500

    x86/CPU/AMD: Have smp_num_siblings and cpu_llc_id always be present
    
    Move smp_num_siblings and cpu_llc_id to cpu/common.c so that they're
    always present as symbols and not only in the CONFIG_SMP case. Then,
    other code using them doesn't need ugly ifdeffery anymore. Get rid of
    some ifdeffery.
    
    Signed-off-by: Borislav Petkov <bpetkov@suse.de>
    Signed-off-by: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1524864877-111962-2-git-send-email-suravee.suthikulpanit@amd.com

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index f75bff8f9d82..547c4fe50711 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -171,7 +171,6 @@ static inline int wbinvd_on_all_cpus(void)
 	wbinvd();
 	return 0;
 }
-#define smp_num_siblings	1
 #endif /* CONFIG_SMP */
 
 extern unsigned disabled_cpus;

commit 2451d1e59d5a154a42bcf02e0bfeebb01d8df1e0
Merge: 67dbfc142310 e25283bf83bd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 2 13:38:43 2018 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 apic updates from Ingo Molnar:
     "The main x86 APIC/IOAPIC changes in this cycle were:
    
       - Robustify kexec support to more carefully restore IRQ hardware
         state before calling into kexec/kdump kernels. (Baoquan He)
    
       - Clean up the local APIC code a bit (Dou Liyang)
    
       - Remove unused callbacks (David Rientjes)"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/apic: Finish removing unused callbacks
      x86/apic: Drop logical_smp_processor_id() inline
      x86/apic: Modernize the pending interrupt code
      x86/apic: Move pending interrupt check code into it's own function
      x86/apic: Set up through-local-APIC mode on the boot CPU if 'noapic' specified
      x86/apic: Rename variables and functions related to x86_io_apic_ops
      x86/apic: Remove the (now) unused disable_IO_APIC() function
      x86/apic: Fix restoring boot IRQ mode in reboot and kexec/kdump
      x86/apic: Split disable_IO_APIC() into two functions to fix CONFIG_KEXEC_JUMP=y
      x86/apic: Split out restore_boot_irq_mode() from disable_IO_APIC()
      x86/apic: Make setup_local_APIC() static
      x86/apic: Simplify init_bsp_APIC() usage
      x86/x2apic: Mark set_x2apic_phys_mode() as __init

commit 8f1561680f42a5491b371b513f1ab8197f31fd62
Author: Dou Liyang <douly.fnst@cn.fujitsu.com>
Date:   Thu Mar 1 13:59:30 2018 +0800

    x86/apic: Drop logical_smp_processor_id() inline
    
    The logical_smp_processor_id() inline which is only called in
    setup_local_APIC() on x86_32 systems has no real value.
    
    Drop it and directly use GET_APIC_LOGICAL_ID() at the call site and use a
    more suitable variable name for readability
    
    Signed-off-by: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: andy.shevchenko@gmail.com
    Cc: bhe@redhat.com
    Cc: ebiederm@xmission.com
    Link: https://lkml.kernel.org/r/20180301055930.2396-4-douly.fnst@cn.fujitsu.com

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 461f53d27708..e2057780d67f 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -176,16 +176,6 @@ static inline int wbinvd_on_all_cpus(void)
 extern unsigned disabled_cpus;
 
 #ifdef CONFIG_X86_LOCAL_APIC
-
-#ifndef CONFIG_X86_64
-static inline int logical_smp_processor_id(void)
-{
-	/* we don't want to mark this access volatile - bad code generation */
-	return GET_APIC_LOGICAL_ID(apic_read(APIC_LDR));
-}
-
-#endif
-
 extern int hard_smp_processor_id(void);
 
 #else /* CONFIG_X86_LOCAL_APIC */

commit 63e708f826bb21470155d37b103a75d8a9e25b18
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Wed Feb 7 18:49:23 2018 -0500

    x86/xen: Calculate __max_logical_packages on PV domains
    
    The kernel panics on PV domains because native_smp_cpus_done() is
    only called for HVM domains.
    
    Calculate __max_logical_packages for PV domains.
    
    Fixes: b4c0a7326f5d ("x86/smpboot: Fix __max_logical_packages estimate")
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Tested-and-reported-by: Simon Gaiser <simon@invisiblethingslab.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: xen-devel@lists.xenproject.org
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 461f53d27708..a4189762b266 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -129,6 +129,7 @@ static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 void cpu_disable_common(void);
 void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
+void calculate_max_logical_packages(void);
 void native_smp_cpus_done(unsigned int max_cpus);
 void common_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 47103eca3775..461f53d27708 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_SMP_H
 #define _ASM_X86_SMP_H
 #ifndef __ASSEMBLY__

commit 7b6e106276fcc803e397f9b1bd4c272055c7cf5a
Author: Dou Liyang <douly.fnst@cn.fujitsu.com>
Date:   Sun Apr 9 18:46:46 2017 +0800

    x86/smp: Remove the redundant #ifdef CONFIG_SMP directive
    
    The !CONFIG_X86_LOCAL_APIC section in smp.h wraps the define of
    hard_smp_processor_id() into #ifndef CONFIG_SMP. But Kconfig has:
    
      config X86_LOCAL_APIC
        def_bool y
        depends on X86_64 || SMP || X86_32_NON_STANDARD ...
    
    Therefore SMP can't be 'y' when X86_LOCAL_APIC == 'n'.
    
    Remove the redundant #ifndef CONFIG_SMP.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Cc: jaswinder@infradead.org
    Link: http://lkml.kernel.org/r/1491734806-15413-2-git-send-email-douly.fnst@cn.fujitsu.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index f64aaa72a301..47103eca3775 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -188,11 +188,7 @@ static inline int logical_smp_processor_id(void)
 extern int hard_smp_processor_id(void);
 
 #else /* CONFIG_X86_LOCAL_APIC */
-
-# ifndef CONFIG_SMP
-#  define hard_smp_processor_id()	0
-# endif
-
+#define hard_smp_processor_id()	0
 #endif /* CONFIG_X86_LOCAL_APIC */
 
 #ifdef CONFIG_DEBUG_NMI_SELFTEST

commit 0f08c3b22996c91cff62c96cf4b3db88902e12a9
Author: Dou Liyang <douly.fnst@cn.fujitsu.com>
Date:   Sun Apr 9 18:46:45 2017 +0800

    x86/smp: Reduce code duplication
    
    The CONFIG_X86_32_SMP and CONFIG_X86_64_SMP sections in smp.h contain
    duplicate defines.
    
    Merge them and only put the difference into an #ifdeff'ed section.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Cc: jaswinder@infradead.org
    Link: http://lkml.kernel.org/r/1491734806-15413-1-git-send-email-douly.fnst@cn.fujitsu.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 026ea82ecc60..f64aaa72a301 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -149,6 +149,19 @@ void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
 #define cpu_acpi_id(cpu)	per_cpu(x86_cpu_to_acpiid, cpu)
 
+/*
+ * This function is needed by all SMP systems. It must _always_ be valid
+ * from the initial startup. We map APIC_BASE very early in page_setup(),
+ * so this is correct in the x86 case.
+ */
+#define raw_smp_processor_id() (this_cpu_read(cpu_number))
+
+#ifdef CONFIG_X86_32
+extern int safe_smp_processor_id(void);
+#else
+# define safe_smp_processor_id()	smp_processor_id()
+#endif
+
 #else /* !CONFIG_SMP */
 #define wbinvd_on_cpu(cpu)     wbinvd()
 static inline int wbinvd_on_all_cpus(void)
@@ -161,22 +174,6 @@ static inline int wbinvd_on_all_cpus(void)
 
 extern unsigned disabled_cpus;
 
-#ifdef CONFIG_X86_32_SMP
-/*
- * This function is needed by all SMP systems. It must _always_ be valid
- * from the initial startup. We map APIC_BASE very early in page_setup(),
- * so this is correct in the x86 case.
- */
-#define raw_smp_processor_id() (this_cpu_read(cpu_number))
-extern int safe_smp_processor_id(void);
-
-#elif defined(CONFIG_X86_64_SMP)
-#define raw_smp_processor_id() (this_cpu_read(cpu_number))
-
-#define safe_smp_processor_id()		smp_processor_id()
-
-#endif
-
 #ifdef CONFIG_X86_LOCAL_APIC
 
 #ifndef CONFIG_X86_64

commit 0ee59413c967c35a6dd2dbdab605b4cd42025ee5
Author: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
Date:   Tue Oct 11 13:54:23 2016 -0700

    x86/panic: replace smp_send_stop() with kdump friendly version in panic path
    
    Daniel Walker reported problems which happens when
    crash_kexec_post_notifiers kernel option is enabled
    (https://lkml.org/lkml/2015/6/24/44).
    
    In that case, smp_send_stop() is called before entering kdump routines
    which assume other CPUs are still online.  As the result, for x86, kdump
    routines fail to save other CPUs' registers and disable virtualization
    extensions.
    
    To fix this problem, call a new kdump friendly function,
    crash_smp_send_stop(), instead of the smp_send_stop() when
    crash_kexec_post_notifiers is enabled.  crash_smp_send_stop() is a weak
    function, and it just call smp_send_stop().  Architecture codes should
    override it so that kdump can work appropriately.  This patch only
    provides x86-specific version.
    
    For Xen's PV kernel, just keep the current behavior.
    
    NOTES:
    
    - Right solution would be to place crash_smp_send_stop() before
      __crash_kexec() invocation in all cases and remove smp_send_stop(), but
      we can't do that until all architectures implement own
      crash_smp_send_stop()
    
    - crash_smp_send_stop()-like work is still needed by
      machine_crash_shutdown() because crash_kexec() can be called without
      entering panic()
    
    Fixes: f06e5153f4ae (kernel/panic.c: add "crash_kexec_post_notifiers" option)
    Link: http://lkml.kernel.org/r/20160810080948.11028.15344.stgit@sysi4-13.yrl.intra.hitachi.co.jp
    Signed-off-by: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Reported-by: Daniel Walker <dwalker@fifo99.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Daniel Walker <dwalker@fifo99.com>
    Cc: Xunlei Pang <xpang@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: Toshi Kani <toshi.kani@hpe.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Aaro Koskinen <aaro.koskinen@iki.fi>
    Cc: "Steven J. Hill" <steven.hill@cavium.com>
    Cc: Corey Minyard <cminyard@mvista.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 19980b36f394..026ea82ecc60 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -47,6 +47,7 @@ struct smp_ops {
 	void (*smp_cpus_done)(unsigned max_cpus);
 
 	void (*stop_other_cpus)(int wait);
+	void (*crash_stop_other_cpus)(void);
 	void (*smp_send_reschedule)(int cpu);
 
 	int (*cpu_up)(unsigned cpu, struct task_struct *tidle);

commit b32f96c75d0dcbb9bf9cc7994e8022c8ce20a668
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Thu Aug 18 10:59:03 2016 -0500

    x86/asm/head: Rename 'stack_start' -> 'initial_stack'
    
    The 'stack_start' variable is similar in usage to 'initial_code' and
    'initial_gs': they're all stored in head_64.S and they're all updated by
    SMP and ACPI suspend before starting a CPU.
    
    Rename it to 'initial_stack' to be consistent with the others.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Byungchul Park <byungchul.park@lge.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Nilay Vaish <nilayvaish@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/87063d773a3212051b77e17b0ee427f6582a5050.1471535549.git.jpoimboe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index ebd0c164cd4e..19980b36f394 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -39,9 +39,6 @@ DECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_bios_cpu_apicid);
 DECLARE_EARLY_PER_CPU_READ_MOSTLY(int, x86_cpu_to_logical_apicid);
 #endif
 
-/* Static state in head.S used to set up a CPU */
-extern unsigned long stack_start; /* Initial stack pointer address */
-
 struct task_struct;
 
 struct smp_ops {

commit 08fd8c17686c6b09fa410a26d516548dd80ff147
Merge: e831101a73fb d34c30cc1fa8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 11:35:37 2016 -0700

    Merge tag 'for-linus-4.8-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip
    
    Pull xen updates from David Vrabel:
     "Features and fixes for 4.8-rc0:
    
       - ACPI support for guests on ARM platforms.
       - Generic steal time support for arm and x86.
       - Support cases where kernel cpu is not Xen VCPU number (e.g., if
         in-guest kexec is used).
       - Use the system workqueue instead of a custom workqueue in various
         places"
    
    * tag 'for-linus-4.8-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip: (47 commits)
      xen: add static initialization of steal_clock op to xen_time_ops
      xen/pvhvm: run xen_vcpu_setup() for the boot CPU
      xen/evtchn: use xen_vcpu_id mapping
      xen/events: fifo: use xen_vcpu_id mapping
      xen/events: use xen_vcpu_id mapping in events_base
      x86/xen: use xen_vcpu_id mapping when pointing vcpu_info to shared_info
      x86/xen: use xen_vcpu_id mapping for HYPERVISOR_vcpu_op
      xen: introduce xen_vcpu_id mapping
      x86/acpi: store ACPI ids from MADT for future usage
      x86/xen: update cpuid.h from Xen-4.7
      xen/evtchn: add IOCTL_EVTCHN_RESTRICT
      xen-blkback: really don't leak mode property
      xen-blkback: constify instance of "struct attribute_group"
      xen-blkfront: prefer xenbus_scanf() over xenbus_gather()
      xen-blkback: prefer xenbus_scanf() over xenbus_gather()
      xen: support runqueue steal time on xen
      arm/xen: add support for vm_assist hypercall
      xen: update xen headers
      xen-pciback: drop superfluous variables
      xen-pciback: short-circuit read path used for merging write values
      ...

commit 6453dbdda30428a3c56568c96fe70ea3612f07e2
Merge: 27b79027bc11 bc841e260c95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 26 17:29:07 2016 -0700

    Merge tag 'pm-4.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael  Wysocki:
     "Again, the majority of changes go into the cpufreq subsystem, but
      there are no big features this time.  The cpufreq changes that stand
      out somewhat are the governor interface rework and improvements
      related to the handling of frequency tables.  Apart from those, there
      are fixes and new device/CPU IDs in drivers, cleanups and an
      improvement of the new schedutil governor.
    
      Next, there are some changes in the hibernation core, including a fix
      for a nasty problem related to the MONITOR/MWAIT usage by CPU offline
      during resume from hibernation, a few core improvements related to
      memory management during resume, a couple of additional debug features
      and cleanups.
    
      Finally, we have some fixes and cleanups in the devfreq subsystem,
      generic power domains framework improvements related to system
      suspend/resume, support for some new chips in intel_idle and in the
      power capping RAPL driver, a new version of the AnalyzeSuspend utility
      and some assorted fixes and cleanups.
    
      Specifics:
    
       - Rework the cpufreq governor interface to make it more
         straightforward and modify the conservative governor to avoid using
         transition notifications (Rafael Wysocki).
    
       - Rework the handling of frequency tables by the cpufreq core to make
         it more efficient (Viresh Kumar).
    
       - Modify the schedutil governor to reduce the number of wakeups it
         causes to occur in cases when the CPU frequency doesn't need to be
         changed (Steve Muckle, Viresh Kumar).
    
       - Fix some minor issues and clean up code in the cpufreq core and
         governors (Rafael Wysocki, Viresh Kumar).
    
       - Add Intel Broxton support to the intel_pstate driver (Srinivas
         Pandruvada).
    
       - Fix problems related to the config TDP feature and to the validity
         of the MSR_HWP_INTERRUPT register in intel_pstate (Jan Kiszka,
         Srinivas Pandruvada).
    
       - Make intel_pstate update the cpu_frequency tracepoint even if the
         frequency doesn't change to avoid confusing powertop (Rafael
         Wysocki).
    
       - Clean up the usage of __init/__initdata in intel_pstate, mark some
         of its internal variables as __read_mostly and drop an unused
         structure element from it (Jisheng Zhang, Carsten Emde).
    
       - Clean up the usage of some duplicate MSR symbols in intel_pstate
         and turbostat (Srinivas Pandruvada).
    
       - Update/fix the powernv, s3c24xx and mvebu cpufreq drivers (Akshay
         Adiga, Viresh Kumar, Ben Dooks).
    
       - Fix a regression (introduced during the 4.5 cycle) in the
         pcc-cpufreq driver by reverting the problematic commit (Andreas
         Herrmann).
    
       - Add support for Intel Denverton to intel_idle, clean up Broxton
         support in it and make it explicitly non-modular (Jacob Pan, Jan
         Beulich, Paul Gortmaker).
    
       - Add support for Denverton and Ivy Bridge server to the Intel RAPL
         power capping driver and make it more careful about the handing of
         MSRs that may not be present (Jacob Pan, Xiaolong Wang).
    
       - Fix resume from hibernation on x86-64 by making the CPU offline
         during resume avoid using MONITOR/MWAIT in the "play dead" loop
         which may lead to an inadvertent "revival" of a "dead" CPU and a
         page fault leading to a kernel crash from it (Rafael Wysocki).
    
       - Make memory management during resume from hibernation more
         straightforward (Rafael Wysocki).
    
       - Add debug features that should help to detect problems related to
         hibernation and resume from it (Rafael Wysocki, Chen Yu).
    
       - Clean up hibernation core somewhat (Rafael Wysocki).
    
       - Prevent KASAN from instrumenting the hibernation core which leads
         to large numbers of false-positives from it (James Morse).
    
       - Prevent PM (hibernate and suspend) notifiers from being called
         during the cleanup phase if they have not been called during the
         corresponding preparation phase which is possible if one of the
         other notifiers returns an error at that time (Lianwei Wang).
    
       - Improve suspend-related debug printout in the tasks freezer and
         clean up suspend-related console handling (Roger Lu, Borislav
         Petkov).
    
       - Update the AnalyzeSuspend script in the kernel sources to version
         4.2 (Todd Brandt).
    
       - Modify the generic power domains framework to make it handle system
         suspend/resume better (Ulf Hansson).
    
       - Make the runtime PM framework avoid resuming devices synchronously
         when user space changes the runtime PM settings for them and
         improve its error reporting (Rafael Wysocki, Linus Walleij).
    
       - Fix error paths in devfreq drivers (exynos, exynos-ppmu,
         exynos-bus) and in the core, make some devfreq code explicitly
         non-modular and change some of it into tristate (Bartlomiej
         Zolnierkiewicz, Peter Chen, Paul Gortmaker).
    
       - Add DT support to the generic PM clocks management code and make it
         export some more symbols (Jon Hunter, Paul Gortmaker).
    
       - Make the PCI PM core code slightly more robust against possible
         driver errors (Andy Shevchenko).
    
       - Make it possible to change DESTDIR and PREFIX in turbostat (Andy
         Shevchenko)"
    
    * tag 'pm-4.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (89 commits)
      Revert "cpufreq: pcc-cpufreq: update default value of cpuinfo_transition_latency"
      PM / hibernate: Introduce test_resume mode for hibernation
      cpufreq: export cpufreq_driver_resolve_freq()
      cpufreq: Disallow ->resolve_freq() for drivers providing ->target_index()
      PCI / PM: check all fields in pci_set_platform_pm()
      cpufreq: acpi-cpufreq: use cached frequency mapping when possible
      cpufreq: schedutil: map raw required frequency to driver frequency
      cpufreq: add cpufreq_driver_resolve_freq()
      cpufreq: intel_pstate: Check cpuid for MSR_HWP_INTERRUPT
      intel_pstate: Update cpu_frequency tracepoint every time
      cpufreq: intel_pstate: clean remnant struct element
      PM / tools: scripts: AnalyzeSuspend v4.2
      x86 / hibernate: Use hlt_play_dead() when resuming from hibernation
      cpufreq: powernv: Replacing pstate_id with frequency table index
      intel_pstate: Fix MSR_CONFIG_TDP_x addressing in core_get_max_pstate()
      PM / hibernate: Image data protection during restoration
      PM / hibernate: Add missing braces in __register_nosave_region()
      PM / hibernate: Clean up comments in snapshot.c
      PM / hibernate: Clean up function headers in snapshot.c
      PM / hibernate: Add missing braces in hibernate_setup()
      ...

commit 3e9e57fad3d8530aa30787f861c710f598ddc4e7
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Thu Jun 30 17:56:36 2016 +0200

    x86/acpi: store ACPI ids from MADT for future usage
    
    Currently we don't save ACPI ids (unlike LAPIC ids which go to
    x86_cpu_to_apicid) from MADT and we may need this information later.
    Particularly, ACPI ids is the only existent way for a PVHVM Xen guest
    to figure out Xen's idea of its vCPUs ids before these CPUs boot and
    in some cases these ids diverge from Linux's cpu ids.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 66b057306f40..c47b42b0d283 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -33,6 +33,7 @@ static inline struct cpumask *cpu_llc_shared_mask(int cpu)
 }
 
 DECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_cpu_to_apicid);
+DECLARE_EARLY_PER_CPU_READ_MOSTLY(u32, x86_cpu_to_acpiid);
 DECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_bios_cpu_apicid);
 #if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_X86_32)
 DECLARE_EARLY_PER_CPU_READ_MOSTLY(int, x86_cpu_to_logical_apicid);
@@ -147,6 +148,7 @@ void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);
 void smp_store_boot_cpu_info(void);
 void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
+#define cpu_acpi_id(cpu)	per_cpu(x86_cpu_to_acpiid, cpu)
 
 #else /* !CONFIG_SMP */
 #define wbinvd_on_cpu(cpu)     wbinvd()

commit 406f992e4a372dafbe3c2cff7efbb2002a5c8ebd
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Jul 14 03:55:23 2016 +0200

    x86 / hibernate: Use hlt_play_dead() when resuming from hibernation
    
    On Intel hardware, native_play_dead() uses mwait_play_dead() by
    default and only falls back to the other methods if that fails.
    That also happens during resume from hibernation, when the restore
    (boot) kernel runs disable_nonboot_cpus() to take all of the CPUs
    except for the boot one offline.
    
    However, that is problematic, because the address passed to
    __monitor() in mwait_play_dead() is likely to be written to in the
    last phase of hibernate image restoration and that causes the "dead"
    CPU to start executing instructions again.  Unfortunately, the page
    containing the address in that CPU's instruction pointer may not be
    valid any more at that point.
    
    First, that page may have been overwritten with image kernel memory
    contents already, so the instructions the CPU attempts to execute may
    simply be invalid.  Second, the page tables previously used by that
    CPU may have been overwritten by image kernel memory contents, so the
    address in its instruction pointer is impossible to resolve then.
    
    A report from Varun Koyyalagunta and investigation carried out by
    Chen Yu show that the latter sometimes happens in practice.
    
    To prevent it from happening, temporarily change the smp_ops.play_dead
    pointer during resume from hibernation so that it points to a special
    "play dead" routine which uses hlt_play_dead() and avoids the
    inadvertent "revivals" of "dead" CPUs this way.
    
    A slightly unpleasant consequence of this change is that if the
    system is hibernated with one or more CPUs offline, it will generally
    draw more power after resume than it did before hibernation, because
    the physical state entered by CPUs via hlt_play_dead() is higher-power
    than the mwait_play_dead() one in the majority of cases.  It is
    possible to work around this, but it is unclear how much of a problem
    that's going to be in practice, so the workaround will be implemented
    later if it turns out to be necessary.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=106371
    Reported-by: Varun Koyyalagunta <cpudebug@centtech.com>
    Original-by: Chen Yu <yu.c.chen@intel.com>
    Tested-by: Chen Yu <yu.c.chen@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 66b057306f40..7427ca895a27 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -135,6 +135,7 @@ int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_disable(void);
 int common_cpu_die(unsigned int cpu);
 void native_cpu_die(unsigned int cpu);
+void hlt_play_dead(void);
 void native_play_dead(void);
 void play_dead_common(void);
 void wbinvd_on_cpu(int cpu);

commit fb59831b496a5bb7d0a06c7e702d88d1757edfca
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jul 14 13:22:58 2016 -0700

    x86/smp: Remove stack_smp_processor_id()
    
    It serves no purpose -- raw_smp_processor_id() works fine.  This
    change will be needed to move thread_info off the stack.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/a2bf4f07fbc30fb32f9f7f3f8f94ad3580823847.1468527351.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 66b057306f40..0576b6157f3a 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -172,12 +172,6 @@ extern int safe_smp_processor_id(void);
 #elif defined(CONFIG_X86_64_SMP)
 #define raw_smp_processor_id() (this_cpu_read(cpu_number))
 
-#define stack_smp_processor_id()					\
-({								\
-	struct thread_info *ti;						\
-	__asm__("andq %%rsp,%0; ":"=r" (ti) : "0" (CURRENT_MASK));	\
-	ti->cpu;							\
-})
 #define safe_smp_processor_id()		smp_processor_id()
 
 #endif

commit ee6825c80e870fff1a370c718ec77022ade0889b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 25 15:52:34 2016 +0100

    x86/topology: Fix AMD core count
    
    It turns out AMD gets x86_max_cores wrong when there are compute
    units.
    
    The issue is that Linux assumes:
    
            nr_logical_cpus = nr_cores * nr_siblings
    
    But AMD reports its CU unit as 2 cores, but then sets num_smp_siblings
    to 2 as well.
    
    Boris: fixup ras/mce_amd_inj.c too, to compute the Node Base Core
    properly, according to the new nomenclature.
    
    Fixes: 1f12e32f4cd5 ("x86/topology: Create logical package id")
    Reported-by: Xiong Zhou <jencce.kernel@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andreas Herrmann <aherrmann@suse.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: http://lkml.kernel.org/r/20160317095220.GO6344@twins.programming.kicks-ass.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 20a3de5cb3b0..66b057306f40 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -155,6 +155,7 @@ static inline int wbinvd_on_all_cpus(void)
 	wbinvd();
 	return 0;
 }
+#define smp_num_siblings	1
 #endif /* CONFIG_SMP */
 
 extern unsigned disabled_cpus;

commit cd4d09ec6f6c12a2cc3db5b7d8876a325a53545b
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Jan 26 22:12:04 2016 +0100

    x86/cpufeature: Carve out X86_FEATURE_*
    
    Move them to a separate header and have the following
    dependency:
    
      x86/cpufeatures.h <- x86/processor.h <- x86/cpufeature.h
    
    This makes it easier to use the header in asm code and not
    include the whole cpufeature.h and add guards for asm.
    
    Suggested-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1453842730-28463-5-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index dfcf0727623b..20a3de5cb3b0 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -16,7 +16,6 @@
 #endif
 #include <asm/thread_info.h>
 #include <asm/cpumask.h>
-#include <asm/cpufeature.h>
 
 extern int smp_num_siblings;
 extern unsigned int num_processors;

commit 460958659270b7d750d4ccfe052171cb6f655cbb
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Nov 17 14:44:32 2015 +0100

    x86/paravirt: Remove unused pv_apic_ops structure
    
    The only member of that structure is startup_ipi_hook which is always
    set to paravirt_nop.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: David Vrabel <david.vrabel@citrix.com>
    Cc: jeremy@goop.org
    Cc: chrisw@sous-sol.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xen.org
    Cc: konrad.wilk@oracle.com
    Cc: boris.ostrovsky@oracle.com
    Link: http://lkml.kernel.org/r/1447767872-16730-1-git-send-email-jgross@suse.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index a438c5598a90..dfcf0727623b 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -65,9 +65,6 @@ struct smp_ops {
 extern void set_cpu_sibling_map(int cpu);
 
 #ifdef CONFIG_SMP
-#ifndef CONFIG_PARAVIRT
-#define startup_ipi_hook(phys_apicid, start_eip, start_esp) do { } while (0)
-#endif
 extern struct smp_ops smp_ops;
 
 static inline void smp_send_stop(void)

commit ed29210cd6a67425026e78aa298fa434e11a74e3
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Nov 17 13:05:43 2015 +0100

    x86: Remove unused function cpu_has_ht_siblings()
    
    It is used nowhere.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Link: http://lkml.kernel.org/r/1447761943-770-1-git-send-email-jgross@suse.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 222a6a3ca2b5..a438c5598a90 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -21,15 +21,6 @@
 extern int smp_num_siblings;
 extern unsigned int num_processors;
 
-static inline bool cpu_has_ht_siblings(void)
-{
-	bool has_siblings = false;
-#ifdef CONFIG_SMP
-	has_siblings = cpu_has_ht && smp_num_siblings > 1;
-#endif
-	return has_siblings;
-}
-
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
 /* cpus sharing the last level cache: */

commit 960d447b94b22ceba286917056871d1dac8da697
Author: Bartosz Golaszewski <bgolaszewski@baylibre.com>
Date:   Tue May 26 15:11:36 2015 +0200

    x86: Remove cpu_sibling_mask() and cpu_core_mask()
    
    These functions are arch-specific and duplicate the
    functionality of macros defined in linux/include/topology.h.
    
    Remove them as all the callers in x86 have now switched to using
    the topology_**_cpumask() family.
    
    Signed-off-by: Bartosz Golaszewski <bgolaszewski@baylibre.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benoit Cousson <bcousson@baylibre.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: Jean Delvare <jdelvare@suse.de>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Drokin <oleg.drokin@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Viresh Kumar <viresh.kumar@linaro.org>
    Link: http://lkml.kernel.org/r/1432645896-12588-10-git-send-email-bgolaszewski@baylibre.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 17a8dced12da..222a6a3ca2b5 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -37,16 +37,6 @@ DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_llc_shared_map);
 DECLARE_PER_CPU_READ_MOSTLY(u16, cpu_llc_id);
 DECLARE_PER_CPU_READ_MOSTLY(int, cpu_number);
 
-static inline struct cpumask *cpu_sibling_mask(int cpu)
-{
-	return per_cpu(cpu_sibling_map, cpu);
-}
-
-static inline struct cpumask *cpu_core_mask(int cpu)
-{
-	return per_cpu(cpu_core_map, cpu);
-}
-
 static inline struct cpumask *cpu_llc_shared_mask(int cpu)
 {
 	return per_cpu(cpu_llc_shared_map, cpu);

commit 078838d56574694d0a4815d9c1b7f28e8844638b
Merge: eeee78cf77df 590ee7dbd569
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 14 13:36:04 2015 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU changes from Ingo Molnar:
     "The main changes in this cycle were:
    
       - changes permitting use of call_rcu() and friends very early in
         boot, for example, before rcu_init() is invoked.
    
       - add in-kernel API to enable and disable expediting of normal RCU
         grace periods.
    
       - improve RCU's handling of (hotplug-) outgoing CPUs.
    
       - NO_HZ_FULL_SYSIDLE fixes.
    
       - tiny-RCU updates to make it more tiny.
    
       - documentation updates.
    
       - miscellaneous fixes"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (58 commits)
      cpu: Provide smpboot_thread_init() on !CONFIG_SMP kernels as well
      cpu: Defer smpboot kthread unparking until CPU known to scheduler
      rcu: Associate quiescent-state reports with grace period
      rcu: Yet another fix for preemption and CPU hotplug
      rcu: Add diagnostics to grace-period cleanup
      rcutorture: Default to grace-period-initialization delays
      rcu: Handle outgoing CPUs on exit from idle loop
      cpu: Make CPU-offline idle-loop transition point more precise
      rcu: Eliminate ->onoff_mutex from rcu_node structure
      rcu: Process offlining and onlining only at grace-period start
      rcu: Move rcu_report_unblock_qs_rnp() to common code
      rcu: Rework preemptible expedited bitmask handling
      rcu: Remove event tracing from rcu_cpu_notify(), used by offline CPUs
      rcutorture: Enable slow grace-period initializations
      rcu: Provide diagnostic option to slow down grace-period initialization
      rcu: Detect stalls caused by failure to propagate up rcu_node tree
      rcu: Eliminate empty HOTPLUG_CPU ifdef
      rcu: Simplify sync_rcu_preempt_exp_init()
      rcu: Put all orphan-callback-related code under same comment
      rcu: Consolidate offline-CPU callback initialization
      ...

commit 3f85483bd80ef1de8cbbf0361be59f6a069b59d4
Author: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Date:   Wed Apr 1 10:12:14 2015 -0400

    x86/cpu: Factor out common CPU initialization code, fix 32-bit Xen PV guests
    
    Some of x86 bare-metal and Xen CPU initialization code is common
    between the two and therefore can be factored out to avoid code
    duplication.
    
    As a side effect, doing so will also extend the fix provided by
    commit a7fcf28d431e ("x86/asm/entry: Replace this_cpu_sp0() with
    current_top_of_stack() to x86_32") to 32-bit Xen PV guests.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Reviewed-by: David Vrabel <david.vrabel@citrix.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: konrad.wilk@oracle.com
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1427897534-5086-1-git-send-email-boris.ostrovsky@oracle.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 8cd1cc3bc835..81d02fc7dafa 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -154,6 +154,7 @@ void cpu_die_common(unsigned int cpu);
 void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
 void native_smp_cpus_done(unsigned int max_cpus);
+void common_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_disable(void);
 void native_cpu_die(unsigned int cpu);

commit 2a442c9c6453d3d043dfd89f2e03a1deff8a6f06
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Feb 25 11:42:15 2015 -0800

    x86: Use common outgoing-CPU-notification code
    
    This commit removes the open-coded CPU-offline notification with new
    common code.  Among other things, this change avoids calling scheduler
    code using RCU from an offline CPU that RCU is ignoring.  It also allows
    Xen to notice at online time that the CPU did not go offline correctly.
    Note that Xen has the surviving CPU carry out some cleanup operations,
    so if the surviving CPU times out, these cleanup operations might have
    been carried out while the outgoing CPU was still running.  It might
    therefore be unwise to bring this CPU back online, and this commit
    avoids doing so.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: <x86@kernel.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: <xen-devel@lists.xenproject.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 8cd1cc3bc835..a5cb4f6e9492 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -150,12 +150,12 @@ static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 }
 
 void cpu_disable_common(void);
-void cpu_die_common(unsigned int cpu);
 void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
 void native_smp_cpus_done(unsigned int max_cpus);
 int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_disable(void);
+int common_cpu_die(unsigned int cpu);
 void native_cpu_die(unsigned int cpu);
 void native_play_dead(void);
 void play_dead_common(void);

commit 54279552bd260532d90e7a59fbc931924bbb0f7b
Author: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Date:   Fri Oct 31 11:49:32 2014 -0400

    x86/core, x86/xen/smp: Use 'die_complete' completion when taking CPU down
    
    Commit 2ed53c0d6cc9 ("x86/smpboot: Speed up suspend/resume by
    avoiding 100ms sleep for CPU offline during S3") introduced
    completions to CPU offlining process. These completions are not
    initialized on Xen kernels causing a panic in
    play_dead_common().
    
    Move handling of die_complete into common routines to make them
    available to Xen guests.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Reviewed-by: David Vrabel <david.vrabel@citrix.com>
    Cc: tianyu.lan@intel.com
    Cc: konrad.wilk@oracle.com
    Cc: xen-devel@lists.xenproject.org
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1414770572-7950-1-git-send-email-boris.ostrovsky@oracle.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 8cd27e08e23c..8cd1cc3bc835 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -150,6 +150,7 @@ static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 }
 
 void cpu_disable_common(void);
+void cpu_die_common(unsigned int cpu);
 void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
 void native_smp_cpus_done(unsigned int max_cpus);

commit 663b55b9b39fa9c848cca273ca4e12bf29b32c71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jan 6 19:20:26 2014 -0500

    x86: Delete non-required instances of include <linux/init.h>
    
    None of these files are actually using any __init type directives
    and hence don't need to include <linux/init.h>.  Most are just a
    left over from __devinit and __cpuinit removal, or simply due to
    code getting copied from one driver to the next.
    
    [ hpa: undid incorrect removal from arch/x86/kernel/head_32.S ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Link: http://lkml.kernel.org/r/1389054026-12947-1-git-send-email-paul.gortmaker@windriver.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4137890e88e3..8cd27e08e23c 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -2,7 +2,6 @@
 #define _ASM_X86_SMP_H
 #ifndef __ASSEMBLY__
 #include <linux/cpumask.h>
-#include <linux/init.h>
 #include <asm/percpu.h>
 
 /*

commit 148f9bb87745ed45f7a11b2cbd3bc0f017d5d257
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Jun 18 18:23:59 2013 -0400

    x86: delete __cpuinit usage from all x86 files
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    are flagged as __cpuinit  -- so if we remove the __cpuinit from
    arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    content into no-ops as early as possible, since that will get rid
    of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the arch/x86 uses of the __cpuinit macros from
    all C files.  x86 only had the one __CPUINIT used in assembly files,
    and it wasn't paired off with a .previous or a __FINIT, so we can
    delete it directly w/o any corresponding additional change there.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index b073aaea747c..4137890e88e3 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -179,7 +179,7 @@ static inline int wbinvd_on_all_cpus(void)
 }
 #endif /* CONFIG_SMP */
 
-extern unsigned disabled_cpus __cpuinitdata;
+extern unsigned disabled_cpus;
 
 #ifdef CONFIG_X86_32_SMP
 /*

commit 30106c174311b8cfaaa3186c7f6f9c36c62d17da
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Tue Nov 13 11:32:41 2012 -0800

    x86, hotplug: Support functions for CPU0 online/offline
    
    Add smp_store_boot_cpu_info() to store cpu info for BSP during boot time.
    
    Now smp_store_cpu_info() stores cpu info for bringing up BSP or AP after
    it's offline.
    
    Continue to online CPU0 in native_cpu_up().
    
    Continue to offline CPU0 in native_cpu_disable().
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Link: http://lkml.kernel.org/r/1352835171-3958-5-git-send-email-fenghua.yu@intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4f19a1526037..b073aaea747c 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -166,6 +166,7 @@ void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
 void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);
 
+void smp_store_boot_cpu_info(void);
 void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
 

commit 4cb38750d49010ae72e718d46605ac9ba5a851b4
Merge: 0a2fe19ccc4b 7efa1c87963d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 26 13:17:17 2012 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86/mm changes from Peter Anvin:
     "The big change here is the patchset by Alex Shi to use INVLPG to flush
      only the affected pages when we only need to flush a small page range.
    
      It also removes the special INVALIDATE_TLB_VECTOR interrupts (32
      vectors!) and replace it with an ordinary IPI function call."
    
    Fix up trivial conflicts in arch/x86/include/asm/apic.h (added code next
    to changed line)
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/tlb: Fix build warning and crash when building for !SMP
      x86/tlb: do flush_tlb_kernel_range by 'invlpg'
      x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR
      x86/tlb: enable tlb flush range support for x86
      mm/mmu_gather: enable tlb flush range in generic mmu_gather
      x86/tlb: add tlb_flushall_shift knob into debugfs
      x86/tlb: add tlb_flushall_shift for specific CPU
      x86/tlb: fall back to flush all when meet a THP large page
      x86/flush_tlb: try flush_tlb_single one by one in flush_tlb_range
      x86/tlb_info: get last level TLB entry number of CPU
      x86: Add read_mostly declaration/definition to variables from smp.h
      x86: Define early read-mostly per-cpu macros

commit 0816b0f0365539c8f6280634d2c1778d0108d8f5
Author: Vlad Zolotarov <vlad@scalemp.com>
Date:   Mon Jun 11 12:56:52 2012 +0300

    x86: Add read_mostly declaration/definition to variables from smp.h
    
    Add "read-mostly" qualifier to the following variables in
    smp.h:
    
     - cpu_sibling_map
     - cpu_core_map
     - cpu_llc_shared_map
     - cpu_llc_id
     - cpu_number
     - x86_cpu_to_apicid
     - x86_bios_cpu_apicid
     - x86_cpu_to_logical_apicid
    
    As long as all the variables above are only written during the
    initialization, this change is meant to prevent the false
    sharing. More specifically, on vSMP Foundation platform
    x86_cpu_to_apicid shared the same internode_cache_line with
    frequently written lapic_events.
    
    From the analysis of the first 33 per_cpu variables out of 219
    (memories they describe, to be more specific) the 8 have read_mostly
    nature (tlb_vector_offset, cpu_loops_per_jiffy, xen_debug_irq, etc.)
    and 25 are frequently written (irq_stack_union, gdt_page,
    exception_stacks, idt_desc, etc.).
    
    Assuming that the spread of the rest of the per_cpu variables is
    similar, identifying the read mostly memories will make more sense
    in terms of long-term code maintenance comparing to identifying
    frequently written memories.
    
    Signed-off-by: Vlad Zolotarov <vlad@scalemp.com>
    Acked-by: Shai Fultheim <shai@scalemp.com>
    Cc: Shai Fultheim (Shai@ScaleMP.com) <Shai@scalemp.com>
    Cc: ido@wizery.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1719258.EYKzE4Zbq5@vlad
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index f48394513c37..cc1df2b5cc65 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -31,12 +31,12 @@ static inline bool cpu_has_ht_siblings(void)
 	return has_siblings;
 }
 
-DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
-DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
+DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
+DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
 /* cpus sharing the last level cache: */
-DECLARE_PER_CPU(cpumask_var_t, cpu_llc_shared_map);
-DECLARE_PER_CPU(u16, cpu_llc_id);
-DECLARE_PER_CPU(int, cpu_number);
+DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_llc_shared_map);
+DECLARE_PER_CPU_READ_MOSTLY(u16, cpu_llc_id);
+DECLARE_PER_CPU_READ_MOSTLY(int, cpu_number);
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
 {
@@ -53,10 +53,10 @@ static inline struct cpumask *cpu_llc_shared_mask(int cpu)
 	return per_cpu(cpu_llc_shared_map, cpu);
 }
 
-DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
-DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
+DECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_cpu_to_apicid);
+DECLARE_EARLY_PER_CPU_READ_MOSTLY(u16, x86_bios_cpu_apicid);
 #if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_X86_32)
-DECLARE_EARLY_PER_CPU(int, x86_cpu_to_logical_apicid);
+DECLARE_EARLY_PER_CPU_READ_MOSTLY(int, x86_cpu_to_logical_apicid);
 #endif
 
 /* Static state in head.S used to set up a CPU */

commit 43cc7e86f3200b094e2960b732623aeec00b482d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 15 17:26:16 2012 +0200

    smp: Remove num_booting_cpus()
    
    No users.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index f48394513c37..2ffa95dc2333 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -169,11 +169,6 @@ void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);
 void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
 
-/* We don't mark CPUs online until __cpu_up(), so we need another measure */
-static inline int num_booting_cpus(void)
-{
-	return cpumask_weight(cpu_callout_mask);
-}
 #else /* !CONFIG_SMP */
 #define wbinvd_on_cpu(cpu)     wbinvd()
 static inline int wbinvd_on_all_cpus(void)

commit f5c101892fbd3d2f6d2729bc7eb7b3f6c31dbddd
Merge: c54894cd4672 641b695c2f11
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 22 17:37:47 2012 -0700

    Merge branch 'for-3.5' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu
    
    Pull percpu updates from Tejun Heo:
     "Contains Alex Shi's three patches to remove percpu_xxx() which overlap
      with this_cpu_xxx().  There shouldn't be any functional change."
    
    * 'for-3.5' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu:
      percpu: remove percpu_xxx() functions
      x86: replace percpu_xxx funcs with this_cpu_xxx
      net: replace percpu_xxx funcs with this_cpu_xxx or __this_cpu_xxx

commit c6ae41e7d469f00d9c92a2b2887c7235d121c009
Author: Alex Shi <alex.shi@intel.com>
Date:   Fri May 11 15:35:27 2012 +0800

    x86: replace percpu_xxx funcs with this_cpu_xxx
    
    Since percpu_xxx() serial functions are duplicated with this_cpu_xxx().
    Removing percpu_xxx() definition and replacing them by this_cpu_xxx()
    in code. There is no function change in this patch, just preparation for
    later percpu_xxx serial function removing.
    
    On x86 machine the this_cpu_xxx() serial functions are same as
    __this_cpu_xxx() without no unnecessary premmpt enable/disable.
    
    Thanks for Stephen Rothwell, he found and fixed a i386 build error in
    the patch.
    
    Also thanks for Andrew Morton, he kept updating the patchset in Linus'
    tree.
    
    Signed-off-by: Alex Shi <alex.shi@intel.com>
    Acked-by: Christoph Lameter <cl@gentwo.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 0434c400287c..e276f6bb6524 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -188,11 +188,11 @@ extern unsigned disabled_cpus __cpuinitdata;
  * from the initial startup. We map APIC_BASE very early in page_setup(),
  * so this is correct in the x86 case.
  */
-#define raw_smp_processor_id() (percpu_read(cpu_number))
+#define raw_smp_processor_id() (this_cpu_read(cpu_number))
 extern int safe_smp_processor_id(void);
 
 #elif defined(CONFIG_X86_64_SMP)
-#define raw_smp_processor_id() (percpu_read(cpu_number))
+#define raw_smp_processor_id() (this_cpu_read(cpu_number))
 
 #define stack_smp_processor_id()					\
 ({								\

commit 7eb43a6d232bfa46464b501cd1987ec2d705d8cf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:48 2012 +0000

    x86: Use generic idle thread allocation
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20120420124557.246929343@linutronix.de

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index f3ed33811c23..f8cbc6f20e31 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -164,6 +164,7 @@ int wbinvd_on_all_cpus(void);
 
 void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
+void x86_idle_thread_init(unsigned int cpu, struct task_struct *idle);
 
 void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)

commit 5cdaf1834f43b0edc4a3aa683aa4ec98f6bfe8a7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:47 2012 +0000

    x86: Add task_struct argument to smp_ops.cpu_up
    
    Preparatory patch to use the generic idle thread allocation.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20120420124557.176604405@linutronix.de

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4eb3a74bc4b0..f3ed33811c23 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -72,7 +72,7 @@ struct smp_ops {
 	void (*stop_other_cpus)(int wait);
 	void (*smp_send_reschedule)(int cpu);
 
-	int (*cpu_up)(unsigned cpu);
+	int (*cpu_up)(unsigned cpu, struct task_struct *tidle);
 	int (*cpu_disable)(void);
 	void (*cpu_die)(unsigned int cpu);
 	void (*play_dead)(void);
@@ -117,7 +117,7 @@ static inline void smp_cpus_done(unsigned int max_cpus)
 
 static inline int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
-	return smp_ops.cpu_up(cpu);
+	return smp_ops.cpu_up(cpu, tidle);
 }
 
 static inline int __cpu_disable(void)
@@ -154,7 +154,7 @@ void cpu_disable_common(void);
 void native_smp_prepare_boot_cpu(void);
 void native_smp_prepare_cpus(unsigned int max_cpus);
 void native_smp_cpus_done(unsigned int max_cpus);
-int native_cpu_up(unsigned int cpunum);
+int native_cpu_up(unsigned int cpunum, struct task_struct *tidle);
 int native_cpu_disable(void);
 void native_cpu_die(unsigned int cpu);
 void native_play_dead(void);

commit 8239c25f47d2b318156993b15f33900a86ea5e17
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:42 2012 +0000

    smp: Add task_struct argument to __cpu_up()
    
    Preparatory patch to make the idle thread allocation for secondary
    cpus generic.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20120420124556.964170564@linutronix.de

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 0434c400287c..4eb3a74bc4b0 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -62,6 +62,8 @@ DECLARE_EARLY_PER_CPU(int, x86_cpu_to_logical_apicid);
 /* Static state in head.S used to set up a CPU */
 extern unsigned long stack_start; /* Initial stack pointer address */
 
+struct task_struct;
+
 struct smp_ops {
 	void (*smp_prepare_boot_cpu)(void);
 	void (*smp_prepare_cpus)(unsigned max_cpus);
@@ -113,7 +115,7 @@ static inline void smp_cpus_done(unsigned int max_cpus)
 	smp_ops.smp_cpus_done(max_cpus);
 }
 
-static inline int __cpu_up(unsigned int cpu)
+static inline int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	return smp_ops.cpu_up(cpu);
 }

commit 99e8b9ca90d688c3ac7d3a141b701c9694a93925
Author: Don Zickus <dzickus@redhat.com>
Date:   Thu Oct 13 15:14:26 2011 -0400

    x86, NMI: Add NMI IPI selftest
    
    The previous patch modified the stop cpus path to use NMI
    instead of IRQ as the way to communicate to the other cpus to
    shutdown.  There were some concerns that various machines may
    have problems with using an NMI IPI.
    
    This patch creates a selftest to check if NMI is working at
    boot. The idea is to help catch any issues before the machine
    panics and we learn the hard way.
    
    Loosely based on the locking-selftest.c file, this separate file
    runs a couple of simple tests and reports the results.  The
    output looks like:
    
    ...
    Brought up 4 CPUs
    ----------------
    | NMI testsuite:
    --------------------
      remote IPI:  ok  |
       local IPI:  ok  |
    --------------------
    Good, all   2 testcases passed! |
    ---------------------------------
    Total of 4 processors activated (21330.61 BogoMIPS).
    ...
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: seiji.aguchi@hds.com
    Cc: vgoyal@redhat.com
    Cc: mjg@redhat.com
    Cc: tony.luck@intel.com
    Cc: gong.chen@intel.com
    Cc: satoru.moriya@hds.com
    Cc: avi@redhat.com
    Cc: Andi Kleen <andi@firstfloor.org>
    Link: http://lkml.kernel.org/r/1318533267-18880-3-git-send-email-dzickus@redhat.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 73b11bc0ae6f..0434c400287c 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -225,5 +225,11 @@ extern int hard_smp_processor_id(void);
 
 #endif /* CONFIG_X86_LOCAL_APIC */
 
+#ifdef CONFIG_DEBUG_NMI_SELFTEST
+extern void nmi_selftest(void);
+#else
+#define nmi_selftest() do { } while (0)
+#endif
+
 #endif /* __ASSEMBLY__ */
 #endif /* _ASM_X86_SMP_H */

commit 181f977d134a9f8e3f8839f42af655b045fc059e
Merge: d5d42399bd7b 25542c646afb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 15 19:49:10 2011 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (93 commits)
      x86, tlb, UV: Do small micro-optimization for native_flush_tlb_others()
      x86-64, NUMA: Don't call numa_set_distanc() for all possible node combinations during emulation
      x86-64, NUMA: Don't assume phys node 0 is always online in numa_emulation()
      x86-64, NUMA: Clean up initmem_init()
      x86-64, NUMA: Fix numa_emulation code with node0 without RAM
      x86-64, NUMA: Revert NUMA affine page table allocation
      x86: Work around old gas bug
      x86-64, NUMA: Better explain numa_distance handling
      x86-64, NUMA: Fix distance table handling
      mm: Move early_node_map[] reverse scan helpers under HAVE_MEMBLOCK
      x86-64, NUMA: Fix size of numa_distance array
      x86: Rename e820_table_* to pgt_buf_*
      bootmem: Move __alloc_memory_core_early() to nobootmem.c
      bootmem: Move contig_page_data definition to bootmem.c/nobootmem.c
      bootmem: Separate out CONFIG_NO_BOOTMEM code into nobootmem.c
      x86-64, NUMA: Seperate out numa_alloc_distance() from numa_set_distance()
      x86-64, NUMA: Add proper function comments to global functions
      x86-64, NUMA: Move NUMA emulation into numa_emulation.c
      x86-64, NUMA: Prepare numa_emulation() for moving NUMA emulation into a separate file
      x86-64, NUMA: Do not scan two times for setup_node_bootmem()
      ...
    
    Fix up conflicts in arch/x86/kernel/smpboot.c

commit 502f4d4f74219749a9758b9bbc27fb665b2e83ab
Merge: da849abeb86d e5fea868e6c0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 15 19:00:53 2011 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Fix and clean up generic_processor_info()
      x86: Don't copy per_cpu cpuinfo for BSP two times
      x86: Move llc_shared_map out of cpu_info

commit 6909262429b70a162e9e7053672cfd8024c9275d
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Thu Mar 3 10:34:50 2011 +0800

    perf: Avoid the percore allocations if the CPU is not HT capable
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1299119690-13991-5-git-send-email-ming.m.lin@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 1f4695136776..c1bbfa89a0e2 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -17,10 +17,20 @@
 #endif
 #include <asm/thread_info.h>
 #include <asm/cpumask.h>
+#include <asm/cpufeature.h>
 
 extern int smp_num_siblings;
 extern unsigned int num_processors;
 
+static inline bool cpu_has_ht_siblings(void)
+{
+	bool has_siblings = false;
+#ifdef CONFIG_SMP
+	has_siblings = cpu_has_ht && smp_num_siblings > 1;
+#endif
+	return has_siblings;
+}
+
 DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
 DECLARE_PER_CPU(u16, cpu_llc_id);

commit b366801c95bdbeda811ac9668a3943051a18c188
Merge: eff9073790e1 100b33c8bd8a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 14 13:28:29 2011 +0100

    Merge commit 'v2.6.38-rc4' into x86/numa
    
    Merge reason: Merge latest fixes before applying new patch.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 91e04ec05838a5b2c790decf2a91af98cb1666e8
Merge: 792363d2bece 100b33c8bd8a
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Feb 14 13:18:51 2011 +0100

    Merge commit 'v2.6.38-rc4' into x86/cpu
    
    Merge reason: pick up the latest fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 11d4c3f9b671720e80353dd7e433ff2bf65e9500
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Feb 4 16:14:11 2011 -0800

    x86-32: Make sure the stack is set up before we use it
    
    Since checkin ebba638ae723d8a8fc2f7abce5ec18b688b791d7 we call
    verify_cpu even in 32-bit mode.  Unfortunately, calling a function
    means using the stack, and the stack pointer was not initialized in
    the 32-bit setup code!  This code initializes the stack pointer, and
    simplifies the interface slightly since it is easier to rely on just a
    pointer value rather than a descriptor; we need to have different
    values for the segment register anyway.
    
    This retains start_stack as a virtual address, even though a physical
    address would be more convenient for 32 bits; the 64-bit code wants
    the other way around...
    
    Reported-by: Matthieu Castet <castet.matthieu@free.fr>
    LKML-Reference: <4D41E86D.8060205@free.fr>
    Tested-by: Kees Cook <kees.cook@canonical.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4c2f63c7fc1b..1f4695136776 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -40,10 +40,7 @@ DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
 DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
 
 /* Static state in head.S used to set up a CPU */
-extern struct {
-	void *sp;
-	unsigned short ss;
-} stack_start;
+extern unsigned long stack_start; /* Initial stack pointer address */
 
 struct smp_ops {
 	void (*smp_prepare_boot_cpu)(void);

commit 4e62445b90ac4ef708bd11c7ae052b1d5ef765b5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 28 17:22:48 2011 +0100

    x86: Fix build failure on X86_UP_APIC
    
    Commit 4c321ff8 (x86: Replace cpu_2_logical_apicid[] with early
    percpu variable) and following changes introduced and used
    x86_cpu_to_logical_apicid percpu variable.  It was declared and
    defined inside CONFIG_SMP && CONFIG_X86_32 but if
    CONFIG_X86_UP_APIC is set UP configuration makes use of it and
    build fails.
    
    Fix it by declaring and defining it inside CONFIG_X86_LOCAL_APIC
    && CONFIG_X86_32.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Ingo Molnar <mingo@elte.hu>
    Cc: eric.dumazet@gmail.com
    Cc: yinghai@kernel.org
    Cc: brgerst@gmail.com
    Cc: gorcunov@gmail.com
    Cc: penberg@kernel.org
    Cc: shaohui.zheng@intel.com
    Cc: rientjes@google.com
    LKML-Reference: <20110128162248.GA25746@htj.dyndns.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index dc7c46a89db7..75927822c5c8 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -38,7 +38,7 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 
 DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
 DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
-#if defined(CONFIG_SMP) && defined(CONFIG_X86_32)
+#if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_X86_32)
 DECLARE_EARLY_PER_CPU(int, x86_cpu_to_logical_apicid);
 #endif
 

commit 4c321ff8a01a95badf5d5403d80ca4e0ab07fce7
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Jan 23 14:37:30 2011 +0100

    x86: Replace cpu_2_logical_apicid[] with early percpu variable
    
    Unlike x86_64, on x86_32, the mapping from cpu to logical apicid
    may vary depending on apic in use.  cpu_2_logical_apicid[] array
    is used for this mapping.  Replace it with early percpu variable
    x86_cpu_to_logical_apicid to make it better aligned with other
    mappings.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: eric.dumazet@gmail.com
    Cc: yinghai@kernel.org
    Cc: brgerst@gmail.com
    Cc: gorcunov@gmail.com
    Cc: penberg@kernel.org
    Cc: shaohui.zheng@intel.com
    Cc: rientjes@google.com
    LKML-Reference: <1295789862-25482-5-git-send-email-tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4c2f63c7fc1b..dc7c46a89db7 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -38,6 +38,9 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 
 DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
 DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
+#if defined(CONFIG_SMP) && defined(CONFIG_X86_32)
+DECLARE_EARLY_PER_CPU(int, x86_cpu_to_logical_apicid);
+#endif
 
 /* Static state in head.S used to set up a CPU */
 extern struct {

commit b3d7336db553d318e7ec042eb50a70d307013339
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Fri Jan 21 15:29:44 2011 -0800

    x86: Move llc_shared_map out of cpu_info
    
    cpu_info is already with per_cpu, We can take llc_shared_map out
    of cpu_info, and declare it as per_cpu variable directly.
    
    So later referencing could be simple and directly instead of
    diving to find cpu_info at first.
    
    Also could make smp_store_cpu_info() much simple to avoid to do
    save and restore trick.
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Hans Rosenfeld <hans.rosenfeld@amd.com>
    Cc: Alok N Kataria <akataria@vmware.com>
    Cc: Stephen Hemminger <shemminger@vyatta.com>
    Cc: Hans J. Koch <hjk@linutronix.de>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Andreas Herrmann <andreas.herrmann3@amd.com>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    LKML-Reference: <4D3A16E8.5020608@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4c2f63c7fc1b..3597825a3112 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -23,6 +23,8 @@ extern unsigned int num_processors;
 
 DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
+/* cpus sharing the last level cache: */
+DECLARE_PER_CPU(cpumask_var_t, cpu_llc_shared_map);
 DECLARE_PER_CPU(u16, cpu_llc_id);
 DECLARE_PER_CPU(int, cpu_number);
 
@@ -36,6 +38,11 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 	return per_cpu(cpu_core_map, cpu);
 }
 
+static inline struct cpumask *cpu_llc_shared_mask(int cpu)
+{
+	return per_cpu(cpu_llc_shared_map, cpu);
+}
+
 DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
 DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
 

commit 76fac077db6b34e2c6383a7b4f3f4f7b7d06d8ce
Author: Alok Kataria <akataria@vmware.com>
Date:   Mon Oct 11 14:37:08 2010 -0700

    x86, kexec: Make sure to stop all CPUs before exiting the kernel
    
    x86 smp_ops now has a new op, stop_other_cpus which takes a parameter
    "wait" this allows the caller to specify if it wants to stop until all
    the cpus have processed the stop IPI.  This is required specifically
    for the kexec case where we should wait for all the cpus to be stopped
    before starting the new kernel.  We now wait for the cpus to stop in
    all cases except for panic/kdump where we expect things to be broken
    and we are doing our best to make things work anyway.
    
    This patch fixes a legitimate regression, which was introduced during
    2.6.30, by commit id 4ef702c10b5df18ab04921fc252c26421d4d6c75.
    
    Signed-off-by: Alok N Kataria <akataria@vmware.com>
    LKML-Reference: <1286833028.1372.20.camel@ank32.eng.vmware.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: <stable@kernel.org> v2.6.30-36
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 4cfc90824068..4c2f63c7fc1b 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -50,7 +50,7 @@ struct smp_ops {
 	void (*smp_prepare_cpus)(unsigned max_cpus);
 	void (*smp_cpus_done)(unsigned max_cpus);
 
-	void (*smp_send_stop)(void);
+	void (*stop_other_cpus)(int wait);
 	void (*smp_send_reschedule)(int cpu);
 
 	int (*cpu_up)(unsigned cpu);
@@ -73,7 +73,12 @@ extern struct smp_ops smp_ops;
 
 static inline void smp_send_stop(void)
 {
-	smp_ops.smp_send_stop();
+	smp_ops.stop_other_cpus(0);
+}
+
+static inline void stop_other_cpus(void)
+{
+	smp_ops.stop_other_cpus(1);
 }
 
 static inline void smp_prepare_boot_cpu(void)

commit a7b480e7f30b3813353ec009f10f2ac7a6669f3b
Author: Borislav Petkov <borislav.petkov@amd.com>
Date:   Fri Jan 22 16:01:03 2010 +0100

    x86, lib: Add wbinvd smp helpers
    
    Add wbinvd_on_cpu and wbinvd_on_all_cpus stubs for executing wbinvd on a
    particular CPU.
    
    [ hpa: renamed lib/smp.c to lib/cache-smp.c ]
    [ hpa: wbinvd_on_all_cpus() returns int, but wbinvd() returns
      void.  Thus, the former cannot be a macro for the latter,
      replace with an inline function. ]
    
    Signed-off-by: Borislav Petkov <borislav.petkov@amd.com>
    LKML-Reference: <1264172467-25155-2-git-send-email-bp@amd64.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 1e796782cd7b..4cfc90824068 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -135,6 +135,8 @@ int native_cpu_disable(void);
 void native_cpu_die(unsigned int cpu);
 void native_play_dead(void);
 void play_dead_common(void);
+void wbinvd_on_cpu(int cpu);
+int wbinvd_on_all_cpus(void);
 
 void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
@@ -147,6 +149,13 @@ static inline int num_booting_cpus(void)
 {
 	return cpumask_weight(cpu_callout_mask);
 }
+#else /* !CONFIG_SMP */
+#define wbinvd_on_cpu(cpu)     wbinvd()
+static inline int wbinvd_on_all_cpus(void)
+{
+	wbinvd();
+	return 0;
+}
 #endif /* CONFIG_SMP */
 
 extern unsigned disabled_cpus __cpuinitdata;

commit 0748bd01773395003208996c4c0b3f80caf80976
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Sep 24 09:34:46 2009 -0600

    cpumask: remove arch_send_call_function_ipi
    
    Now everyone is converted to arch_send_call_function_ipi_mask, remove
    the shim and the #defines.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 6a84ed166aec..1e796782cd7b 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -121,7 +121,6 @@ static inline void arch_send_call_function_single_ipi(int cpu)
 	smp_ops.send_call_func_single_ipi(cpu);
 }
 
-#define arch_send_call_function_ipi_mask arch_send_call_function_ipi_mask
 static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
 	smp_ops.send_call_func_ipi(mask);

commit 4797f6b021a3fa399942245d07a1feb30df81bb8
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sat May 2 10:40:57 2009 -0700

    x86: read apic ID in the !acpi_lapic case
    
    Ed found that on 32-bit, boot_cpu_physical_apicid is not read right,
    when the mptable is broken.
    
    Interestingly, actually three paths use/set it:
    
     1. acpi: at that time that is already read from reg
     2. mptable: only read from mptable
     3. no madt, and no mptable, that use default apic id 0 for 64-bit, -1 for 32-bit
    
    so we could read the apic id for the 2/3 path. We trust the hardware
    register more than we trust a BIOS data structure (the mptable).
    
    We can also avoid the double set_fixmap() when acpi_lapic
    is used, and also need to move cpu_has_apic earlier and
    call apic_disable().
    
    Also when need to update the apic id, we'd better read and
    set the apic version as well - so that quirks are applied precisely.
    
    v2: make path 3 with 64bit, use -1 as apic id, so could read it later.
    v3: fix whitespace problem pointed out by Ed Swierk
    v5: fix boot crash
    
    [ Impact: get correct apic id for bsp other than acpi path ]
    
    Reported-by: Ed Swierk <eswierk@aristanetworks.com>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    LKML-Reference: <49FC85A9.2070702@kernel.org>
    [ v4: sanity-check in the ACPI case too ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 19e0d88b966d..6a84ed166aec 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -180,7 +180,7 @@ extern int safe_smp_processor_id(void);
 static inline int logical_smp_processor_id(void)
 {
 	/* we don't want to mark this access volatile - bad code generation */
-	return GET_APIC_LOGICAL_ID(*(u32 *)(APIC_BASE + APIC_LDR));
+	return GET_APIC_LOGICAL_ID(apic_read(APIC_LDR));
 }
 
 #endif

commit b643decad6c80b6886a01a8c2229be6b7951ff7b
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Fri Mar 13 14:49:51 2009 +1030

    x86: arch_send_call_function_ipi_mask
    
    Impact: implement new API
    
    We define arch_send_call_function_ipi_mask and generic kernel/smp.c
    code creates arch_send_call_function_ipi() as a wrapper.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index cfb10f1667fe..19e0d88b966d 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -121,9 +121,10 @@ static inline void arch_send_call_function_single_ipi(int cpu)
 	smp_ops.send_call_func_single_ipi(cpu);
 }
 
-static inline void arch_send_call_function_ipi(cpumask_t mask)
+#define arch_send_call_function_ipi_mask arch_send_call_function_ipi_mask
+static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
-	smp_ops.send_call_func_ipi(&mask);
+	smp_ops.send_call_func_ipi(mask);
 }
 
 void cpu_disable_common(void);

commit 7ad728f98162cb1af06a85b2a5fc422dddd4fb78
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Fri Mar 13 14:49:50 2009 +1030

    cpumask: x86: convert cpu_sibling_map/cpu_core_map to cpumask_var_t
    
    Impact: reduce per-cpu size for CONFIG_CPUMASK_OFFSTACK=y
    
    In most places it's cleaner to use the accessors cpu_sibling_mask()
    and cpu_core_mask() wrappers which already exist.
    
    I couldn't avoid cleaning up the access in oprofile, either.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 47d0e21f2b9e..cfb10f1667fe 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -21,19 +21,19 @@
 extern int smp_num_siblings;
 extern unsigned int num_processors;
 
-DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
-DECLARE_PER_CPU(cpumask_t, cpu_core_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
 DECLARE_PER_CPU(u16, cpu_llc_id);
 DECLARE_PER_CPU(int, cpu_number);
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
 {
-	return &per_cpu(cpu_sibling_map, cpu);
+	return per_cpu(cpu_sibling_map, cpu);
 }
 
 static inline struct cpumask *cpu_core_mask(int cpu)
 {
-	return &per_cpu(cpu_core_map, cpu);
+	return per_cpu(cpu_core_map, cpu);
 }
 
 DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);

commit 1dcdd3d15ecea0c22a09d4d001a39d425fceff2c
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 17:55:37 2009 +0100

    x86: remove mach_apic.h
    
    Spread mach_apic.h definitions into genapic.h. (with some knock-on effects
    on smp.h and apic.h.)
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index d4ac4de4bcec..47d0e21f2b9e 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -173,8 +173,6 @@ extern int safe_smp_processor_id(void);
 
 #endif
 
-#include <asm/genapic.h>
-
 #ifdef CONFIG_X86_LOCAL_APIC
 
 #ifndef CONFIG_X86_64
@@ -184,26 +182,9 @@ static inline int logical_smp_processor_id(void)
 	return GET_APIC_LOGICAL_ID(*(u32 *)(APIC_BASE + APIC_LDR));
 }
 
-static inline unsigned int read_apic_id(void)
-{
-	unsigned int reg;
-
-	reg = *(u32 *)(APIC_BASE + APIC_ID);
-
-	return apic->get_apic_id(reg);
-}
 #endif
 
-
-# if defined(APIC_DEFINITION) || defined(CONFIG_X86_64)
 extern int hard_smp_processor_id(void);
-# else
-static inline int hard_smp_processor_id(void)
-{
-	/* we don't want to mark this access volatile - bad code generation */
-	return read_apic_id();
-}
-# endif /* APIC_DEFINITION */
 
 #else /* CONFIG_X86_LOCAL_APIC */
 

commit 1f75ed0c1311a50ed393bcac258de65680d360e5
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 17:36:56 2009 +0100

    x86: remove mach_apicdef.h
    
    Move its definitions into apic.h.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c63d480802af..d4ac4de4bcec 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -173,6 +173,8 @@ extern int safe_smp_processor_id(void);
 
 #endif
 
+#include <asm/genapic.h>
+
 #ifdef CONFIG_X86_LOCAL_APIC
 
 #ifndef CONFIG_X86_64
@@ -182,7 +184,6 @@ static inline int logical_smp_processor_id(void)
 	return GET_APIC_LOGICAL_ID(*(u32 *)(APIC_BASE + APIC_LDR));
 }
 
-#include <mach_apicdef.h>
 static inline unsigned int read_apic_id(void)
 {
 	unsigned int reg;
@@ -197,7 +198,6 @@ static inline unsigned int read_apic_id(void)
 # if defined(APIC_DEFINITION) || defined(CONFIG_X86_64)
 extern int hard_smp_processor_id(void);
 # else
-#include <mach_apicdef.h>
 static inline int hard_smp_processor_id(void)
 {
 	/* we don't want to mark this access volatile - bad code generation */

commit ca6c8ed4646f8ccaa4f7db618bf69b8b8fb49767
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 14:08:38 2009 +0100

    x86, apic: refactor ->get_apic_id() & GET_APIC_ID()
    
    - spread out the namespace on a per driver basis
    
     - get rid of macro wrappers
    
     - small cleanups
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 45ef8a1b9d7c..c63d480802af 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -189,7 +189,7 @@ static inline unsigned int read_apic_id(void)
 
 	reg = *(u32 *)(APIC_BASE + APIC_ID);
 
-	return GET_APIC_ID(reg);
+	return apic->get_apic_id(reg);
 }
 #endif
 

commit 0d974d4592708f85044751817da4b7016e1b0602
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sun Jan 18 19:52:25 2009 -0500

    x86: remove pda.h
    
    Impact: cleanup
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 68636e767a91..45ef8a1b9d7c 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -15,7 +15,6 @@
 #  include <asm/io_apic.h>
 # endif
 #endif
-#include <asm/pda.h>
 #include <asm/thread_info.h>
 #include <asm/cpumask.h>
 

commit ea9279066de44053d0c20ea855bc9f4706652d84
Author: Brian Gerst <brgerst@gmail.com>
Date:   Mon Jan 19 00:38:58 2009 +0900

    x86-64: Move cpu number from PDA to per-cpu and consolidate with 32-bit.
    
    tj: moved cpu_number definition out of CONFIG_HAVE_SETUP_PER_CPU_AREA
        for voyager.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c7bbbbe65d3f..68636e767a91 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -25,9 +25,7 @@ extern unsigned int num_processors;
 DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
 DECLARE_PER_CPU(cpumask_t, cpu_core_map);
 DECLARE_PER_CPU(u16, cpu_llc_id);
-#ifdef CONFIG_X86_32
 DECLARE_PER_CPU(int, cpu_number);
-#endif
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
 {
@@ -164,7 +162,7 @@ extern unsigned disabled_cpus __cpuinitdata;
 extern int safe_smp_processor_id(void);
 
 #elif defined(CONFIG_X86_64_SMP)
-#define raw_smp_processor_id()	read_pda(cpunumber)
+#define raw_smp_processor_id() (percpu_read(cpu_number))
 
 #define stack_smp_processor_id()					\
 ({								\

commit 6dbde3530850d4d8bfc1b6bd4006d92786a2787f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jan 15 22:15:53 2009 +0900

    percpu: add optimized generic percpu accessors
    
    It is an optimization and a cleanup, and adds the following new
    generic percpu methods:
    
      percpu_read()
      percpu_write()
      percpu_add()
      percpu_sub()
      percpu_and()
      percpu_or()
      percpu_xor()
    
    and implements support for them on x86. (other architectures will fall
    back to a default implementation)
    
    The advantage is that for example to read a local percpu variable,
    instead of this sequence:
    
     return __get_cpu_var(var);
    
     ffffffff8102ca2b:      48 8b 14 fd 80 09 74    mov    -0x7e8bf680(,%rdi,8),%rdx
     ffffffff8102ca32:      81
     ffffffff8102ca33:      48 c7 c0 d8 59 00 00    mov    $0x59d8,%rax
     ffffffff8102ca3a:      48 8b 04 10             mov    (%rax,%rdx,1),%rax
    
    We can get a single instruction by using the optimized variants:
    
     return percpu_read(var);
    
     ffffffff8102ca3f:      65 48 8b 05 91 8f fd    mov    %gs:0x7efd8f91(%rip),%rax
    
    I also cleaned up the x86-specific APIs and made the x86 code use
    these new generic percpu primitives.
    
    tj: * fixed generic percpu_sub() definition as Roel Kluin pointed out
        * added percpu_and() for completeness's sake
        * made generic percpu ops atomic against preemption
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 127415402ea1..c7bbbbe65d3f 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -160,7 +160,7 @@ extern unsigned disabled_cpus __cpuinitdata;
  * from the initial startup. We map APIC_BASE very early in page_setup(),
  * so this is correct in the x86 case.
  */
-#define raw_smp_processor_id() (x86_read_percpu(cpu_number))
+#define raw_smp_processor_id() (percpu_read(cpu_number))
 extern int safe_smp_processor_id(void);
 
 #elif defined(CONFIG_X86_64_SMP)

commit 1a51e3a0aed18767cf2762e95456ecfeb0bca5e6
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jan 13 20:41:35 2009 +0900

    x86: fold pda into percpu area on SMP
    
    [ Based on original patch from Christoph Lameter and Mike Travis. ]
    
    Currently pdas and percpu areas are allocated separately.  %gs points
    to local pda and percpu area can be reached using pda->data_offset.
    This patch folds pda into percpu area.
    
    Due to strange gcc requirement, pda needs to be at the beginning of
    the percpu area so that pda->stack_canary is at %gs:40.  To achieve
    this, a new percpu output section macro - PERCPU_VADDR_PREALLOC() - is
    added and used to reserve pda sized chunk at the start of the percpu
    area.
    
    After this change, for boot cpu, %gs first points to pda in the
    data.init area and later during setup_per_cpu_areas() gets updated to
    point to the actual pda.  This means that setup_per_cpu_areas() need
    to reload %gs for CPU0 while clearing pda area for other cpus as cpu0
    already has modified it when control reaches setup_per_cpu_areas().
    
    This patch also removes now unnecessary get_local_pda() and its call
    sites.
    
    A lot of this patch is taken from Mike Travis' "x86_64: Fold pda into
    per cpu area" patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index a8cea7b09434..127415402ea1 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -19,8 +19,6 @@
 #include <asm/thread_info.h>
 #include <asm/cpumask.h>
 
-extern int __cpuinit get_local_pda(int cpu);
-
 extern int smp_num_siblings;
 extern unsigned int num_processors;
 

commit 52811d8c9beb67da6bc4b770de3c4134376788a1
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Sat Jan 10 12:58:50 2009 +0530

    x86: smp.h move cpu_sibling_setup_mask and cpu_sibling_setup_map declartion to cpumask.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 7d2a80319e82..a8cea7b09434 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -19,18 +19,6 @@
 #include <asm/thread_info.h>
 #include <asm/cpumask.h>
 
-#ifdef CONFIG_X86_64
-
-extern cpumask_var_t cpu_sibling_setup_mask;
-
-#else /* CONFIG_X86_32 */
-
-extern cpumask_t cpu_sibling_setup_map;
-
-#define cpu_sibling_setup_mask	((struct cpumask *)&cpu_sibling_setup_map)
-
-#endif /* CONFIG_X86_32 */
-
 extern int __cpuinit get_local_pda(int cpu);
 
 extern int smp_num_siblings;

commit 493f6ca54e1ea59732dd334e35c5fe2d8e440b06
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Sat Jan 10 12:48:22 2009 +0530

    x86: smp.h move cpu_initialized_mask and cpu_initialized declartion to cpumask.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index a3afec5cad0b..7d2a80319e82 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -21,15 +21,12 @@
 
 #ifdef CONFIG_X86_64
 
-extern cpumask_var_t cpu_initialized_mask;
 extern cpumask_var_t cpu_sibling_setup_mask;
 
 #else /* CONFIG_X86_32 */
 
-extern cpumask_t cpu_initialized;
 extern cpumask_t cpu_sibling_setup_map;
 
-#define cpu_initialized_mask	((struct cpumask *)&cpu_initialized)
 #define cpu_sibling_setup_mask	((struct cpumask *)&cpu_sibling_setup_map)
 
 #endif /* CONFIG_X86_32 */

commit fb8fd077fbf0de6662acfd240e8e6b25cf3202ca
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Sat Jan 10 12:20:24 2009 +0530

    x86: smp.h move cpu_callout_mask and cpu_callout_map declartion to cpumask.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c35aa5c0dd11..a3afec5cad0b 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -17,20 +17,18 @@
 #endif
 #include <asm/pda.h>
 #include <asm/thread_info.h>
+#include <asm/cpumask.h>
 
 #ifdef CONFIG_X86_64
 
-extern cpumask_var_t cpu_callout_mask;
 extern cpumask_var_t cpu_initialized_mask;
 extern cpumask_var_t cpu_sibling_setup_mask;
 
 #else /* CONFIG_X86_32 */
 
-extern cpumask_t cpu_callout_map;
 extern cpumask_t cpu_initialized;
 extern cpumask_t cpu_sibling_setup_map;
 
-#define cpu_callout_mask	((struct cpumask *)&cpu_callout_map)
 #define cpu_initialized_mask	((struct cpumask *)&cpu_initialized)
 #define cpu_sibling_setup_mask	((struct cpumask *)&cpu_sibling_setup_map)
 

commit 068790334cececc3d2d945617ccc585477da2e38
Author: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
Date:   Sat Jan 10 12:17:37 2009 +0530

    x86: smp.h move cpu_callin_mask and cpu_callin_map declartion to cpumask.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 1963e27673c9..c35aa5c0dd11 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -20,19 +20,16 @@
 
 #ifdef CONFIG_X86_64
 
-extern cpumask_var_t cpu_callin_mask;
 extern cpumask_var_t cpu_callout_mask;
 extern cpumask_var_t cpu_initialized_mask;
 extern cpumask_var_t cpu_sibling_setup_mask;
 
 #else /* CONFIG_X86_32 */
 
-extern cpumask_t cpu_callin_map;
 extern cpumask_t cpu_callout_map;
 extern cpumask_t cpu_initialized;
 extern cpumask_t cpu_sibling_setup_map;
 
-#define cpu_callin_mask		((struct cpumask *)&cpu_callin_map)
 #define cpu_callout_mask	((struct cpumask *)&cpu_callout_map)
 #define cpu_initialized_mask	((struct cpumask *)&cpu_initialized)
 #define cpu_sibling_setup_mask	((struct cpumask *)&cpu_sibling_setup_map)

commit 1de8cd3cb9f61e854e743c7210df43db517d4832
Merge: 1eb1b3b65dc3 3d14bdad4031
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Jan 10 23:56:42 2009 +0100

    Merge branch 'linus' into x86/cleanups

commit 6d652ea1d056390a0c33db92b44ed219284b71af
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 21:38:59 2009 +0530

    x86: smp.h move boot_cpu_id declartion to cpu.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c975b6f83c68..74ad9ef6ae02 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -212,11 +212,5 @@ static inline int hard_smp_processor_id(void)
 
 #endif /* CONFIG_X86_LOCAL_APIC */
 
-#ifdef CONFIG_X86_HAS_BOOT_CPU_ID
-extern unsigned char boot_cpu_id;
-#else
-#define boot_cpu_id	0
-#endif
-
 #endif /* __ASSEMBLY__ */
 #endif /* _ASM_X86_SMP_H */

commit af8968abf09fe5984bdd206e54e0eeb1dc1fa29c
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 21:37:33 2009 +0530

    x86: smp.h move cpu_physical_id declartion to cpu.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c92b93594ab3..c975b6f83c68 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -170,8 +170,6 @@ extern int safe_smp_processor_id(void);
 })
 #define safe_smp_processor_id()		smp_processor_id()
 
-#else /* !CONFIG_X86_32_SMP && !CONFIG_X86_64_SMP */
-#define cpu_physical_id(cpu)		boot_cpu_physical_apicid
 #endif
 
 #ifdef CONFIG_X86_LOCAL_APIC

commit 96b89dc6598a50e3aac8e2c6d826ae3795b7d030
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 21:35:48 2009 +0530

    x86: smp.h move safe_smp_processor_id declartion to cpu.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index ed4af9a89cfd..c92b93594ab3 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -172,7 +172,6 @@ extern int safe_smp_processor_id(void);
 
 #else /* !CONFIG_X86_32_SMP && !CONFIG_X86_64_SMP */
 #define cpu_physical_id(cpu)		boot_cpu_physical_apicid
-#define safe_smp_processor_id()		0
 #endif
 
 #ifdef CONFIG_X86_LOCAL_APIC

commit f472cdba849cc3d838f3788469316e8572463a8c
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 21:34:25 2009 +0530

    x86: smp.h move stack_processor_id declartion to cpu.h
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 62bd3f68269a..ed4af9a89cfd 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -173,7 +173,6 @@ extern int safe_smp_processor_id(void);
 #else /* !CONFIG_X86_32_SMP && !CONFIG_X86_64_SMP */
 #define cpu_physical_id(cpu)		boot_cpu_physical_apicid
 #define safe_smp_processor_id()		0
-#define stack_smp_processor_id() 	0
 #endif
 
 #ifdef CONFIG_X86_LOCAL_APIC

commit 6e5385d44b2df05e50a8d07ba0e14d3e32685237
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 18:11:35 2009 +0530

    x86: smp.h move prefill_possible_map declartion to cpu.h
    
    Impact: cleanup, moving NON-SMP stuff from smp.h
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 64c9e848f137..62bd3f68269a 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -138,8 +138,6 @@ void play_dead_common(void);
 void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
 
-extern void prefill_possible_map(void);
-
 void smp_store_cpu_info(int id);
 #define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
 
@@ -148,10 +146,6 @@ static inline int num_booting_cpus(void)
 {
 	return cpus_weight(cpu_callout_map);
 }
-#else
-static inline void prefill_possible_map(void)
-{
-}
 #endif /* CONFIG_SMP */
 
 extern unsigned disabled_cpus __cpuinitdata;

commit dacf7333571d770366bff74d10b56aa545434605
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 17:26:35 2009 +0530

    x86: smp.h move zap_low_mappings declartion to tlbflush.h
    
    Impact: cleanup, moving NON-SMP stuff from smp.h
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 83a4cc074315..64c9e848f137 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -22,8 +22,6 @@ extern cpumask_t cpu_callout_map;
 extern cpumask_t cpu_initialized;
 extern cpumask_t cpu_callin_map;
 
-extern void zap_low_mappings(void);
-
 extern int __cpuinit get_local_pda(int cpu);
 
 extern int smp_num_siblings;

commit 7760ec77ab2a9e48bdd0d13341446a8a51f0b9f1
Author: Jaswinder Singh Rajput <jaswinder@infradead.org>
Date:   Wed Jan 7 18:10:13 2009 +0530

    x86: smp.h remove obsolete function declaration
    
    Impact: cleanup
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 830b9fcb6427..83a4cc074315 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -22,7 +22,6 @@ extern cpumask_t cpu_callout_map;
 extern cpumask_t cpu_initialized;
 extern cpumask_t cpu_callin_map;
 
-extern void (*mtrr_hook)(void);
 extern void zap_low_mappings(void);
 
 extern int __cpuinit get_local_pda(int cpu);

commit c2d1cec1c77f7714672c1efeae075424c929e0d5
Author: Mike Travis <travis@sgi.com>
Date:   Sun Jan 4 05:18:03 2009 -0800

    x86: cleanup remaining cpumask_t ops in smpboot code
    
    Impact: use new cpumask API to reduce memory and stack usage
    
    Allocate the following local cpumasks based on the number of cpus that
    are present.  References will use new cpumask API.  (Currently only
    modified for x86_64, x86_32 continues to use the *_map variants.)
    
        cpu_callin_mask
        cpu_callout_mask
        cpu_initialized_mask
        cpu_sibling_setup_mask
    
    Provide the following accessor functions:
    
        struct cpumask *cpu_sibling_mask(int cpu)
        struct cpumask *cpu_core_mask(int cpu)
    
    Other changes are when setting or clearing the cpu online, possible
    or present maps, use the accessor functions.
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 830b9fcb6427..19953df61c52 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -18,9 +18,26 @@
 #include <asm/pda.h>
 #include <asm/thread_info.h>
 
+#ifdef CONFIG_X86_64
+
+extern cpumask_var_t cpu_callin_mask;
+extern cpumask_var_t cpu_callout_mask;
+extern cpumask_var_t cpu_initialized_mask;
+extern cpumask_var_t cpu_sibling_setup_mask;
+
+#else /* CONFIG_X86_32 */
+
+extern cpumask_t cpu_callin_map;
 extern cpumask_t cpu_callout_map;
 extern cpumask_t cpu_initialized;
-extern cpumask_t cpu_callin_map;
+extern cpumask_t cpu_sibling_setup_map;
+
+#define cpu_callin_mask		((struct cpumask *)&cpu_callin_map)
+#define cpu_callout_mask	((struct cpumask *)&cpu_callout_map)
+#define cpu_initialized_mask	((struct cpumask *)&cpu_initialized)
+#define cpu_sibling_setup_mask	((struct cpumask *)&cpu_sibling_setup_map)
+
+#endif /* CONFIG_X86_32 */
 
 extern void (*mtrr_hook)(void);
 extern void zap_low_mappings(void);
@@ -29,7 +46,6 @@ extern int __cpuinit get_local_pda(int cpu);
 
 extern int smp_num_siblings;
 extern unsigned int num_processors;
-extern cpumask_t cpu_initialized;
 
 DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
 DECLARE_PER_CPU(cpumask_t, cpu_core_map);
@@ -38,6 +54,16 @@ DECLARE_PER_CPU(u16, cpu_llc_id);
 DECLARE_PER_CPU(int, cpu_number);
 #endif
 
+static inline struct cpumask *cpu_sibling_mask(int cpu)
+{
+	return &per_cpu(cpu_sibling_map, cpu);
+}
+
+static inline struct cpumask *cpu_core_mask(int cpu)
+{
+	return &per_cpu(cpu_core_map, cpu);
+}
+
 DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
 DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
 
@@ -149,7 +175,7 @@ void smp_store_cpu_info(int id);
 /* We don't mark CPUs online until __cpu_up(), so we need another measure */
 static inline int num_booting_cpus(void)
 {
-	return cpus_weight(cpu_callout_map);
+	return cpumask_weight(cpu_callout_mask);
 }
 #else
 static inline void prefill_possible_map(void)

commit bcda016eddd7a8b374bb371473c821a91ff1d8cc
Author: Mike Travis <travis@sgi.com>
Date:   Tue Dec 16 17:33:59 2008 -0800

    x86: cosmetic changes apic-related files.
    
    This patch simply changes cpumask_t to struct cpumask and similar
    trivial modernizations.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index c4a9aa52df6e..830b9fcb6427 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -60,7 +60,7 @@ struct smp_ops {
 	void (*cpu_die)(unsigned int cpu);
 	void (*play_dead)(void);
 
-	void (*send_call_func_ipi)(const cpumask_t *mask);
+	void (*send_call_func_ipi)(const struct cpumask *mask);
 	void (*send_call_func_single_ipi)(int cpu);
 };
 
@@ -138,7 +138,7 @@ void native_cpu_die(unsigned int cpu);
 void native_play_dead(void);
 void play_dead_common(void);
 
-void native_send_call_func_ipi(const cpumask_t *mask);
+void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
 
 extern void prefill_possible_map(void);

commit e7986739a76cde5079da08809d8bbc6878387ae0
Author: Mike Travis <travis@sgi.com>
Date:   Tue Dec 16 17:33:52 2008 -0800

    x86 smp: modify send_IPI_mask interface to accept cpumask_t pointers
    
    Impact: cleanup, change parameter passing
    
      * Change genapic interfaces to accept cpumask_t pointers where possible.
    
      * Modify external callers to use cpumask_t pointers in function calls.
    
      * Create new send_IPI_mask_allbutself which is the same as the
        send_IPI_mask functions but removes smp_processor_id() from list.
        This removes another common need for a temporary cpumask_t variable.
    
      * Functions that used a temp cpumask_t variable for:
    
            cpumask_t allbutme = cpu_online_map;
    
            cpu_clear(smp_processor_id(), allbutme);
            if (!cpus_empty(allbutme))
                    ...
    
        become:
    
            if (!cpus_equal(cpu_online_map, cpumask_of_cpu(cpu)))
                    ...
    
      * Other minor code optimizations (like using cpus_clear instead of
        CPU_MASK_NONE, etc.)
    
    Applies to linux-2.6.tip/master.
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index d12811ce51d9..c4a9aa52df6e 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -60,7 +60,7 @@ struct smp_ops {
 	void (*cpu_die)(unsigned int cpu);
 	void (*play_dead)(void);
 
-	void (*send_call_func_ipi)(cpumask_t mask);
+	void (*send_call_func_ipi)(const cpumask_t *mask);
 	void (*send_call_func_single_ipi)(int cpu);
 };
 
@@ -125,7 +125,7 @@ static inline void arch_send_call_function_single_ipi(int cpu)
 
 static inline void arch_send_call_function_ipi(cpumask_t mask)
 {
-	smp_ops.send_call_func_ipi(mask);
+	smp_ops.send_call_func_ipi(&mask);
 }
 
 void cpu_disable_common(void);
@@ -138,7 +138,7 @@ void native_cpu_die(unsigned int cpu);
 void native_play_dead(void);
 void play_dead_common(void);
 
-void native_send_call_func_ipi(cpumask_t mask);
+void native_send_call_func_ipi(const cpumask_t *mask);
 void native_send_call_func_single_ipi(int cpu);
 
 extern void prefill_possible_map(void);

commit b3572e361b6b2ac5e724bc4bb932b7774b720b95
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Thu Oct 30 16:00:59 2008 -0500

    x86/voyager: fix compile breakage caused by dc1e35c6e95e8923cf1d3510438b63c600fee1e2
    
    Impact: build fix on x86/Voyager
    
    Given commits like this:
    
    | Author: Suresh Siddha <suresh.b.siddha@intel.com>
    | Date:   Tue Jul 29 10:29:19 2008 -0700
    |
    |     x86, xsave: enable xsave/xrstor on cpus with xsave support
    
    Which deliberately expose boot cpu dependence to pieces of the system,
    I think it's time to explicitly have a variable for it to prevent this
    continual misassumption that the boot CPU is zero.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 2766021aef80..d12811ce51d9 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -225,5 +225,11 @@ static inline int hard_smp_processor_id(void)
 
 #endif /* CONFIG_X86_LOCAL_APIC */
 
+#ifdef CONFIG_X86_HAS_BOOT_CPU_ID
+extern unsigned char boot_cpu_id;
+#else
+#define boot_cpu_id	0
+#endif
+
 #endif /* __ASSEMBLY__ */
 #endif /* _ASM_X86_SMP_H */

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index a6afc29f2dd9..2766021aef80 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__SMP_H
-#define ASM_X86__SMP_H
+#ifndef _ASM_X86_SMP_H
+#define _ASM_X86_SMP_H
 #ifndef __ASSEMBLY__
 #include <linux/cpumask.h>
 #include <linux/init.h>
@@ -226,4 +226,4 @@ static inline int hard_smp_processor_id(void)
 #endif /* CONFIG_X86_LOCAL_APIC */
 
 #endif /* __ASSEMBLY__ */
-#endif /* ASM_X86__SMP_H */
+#endif /* _ASM_X86_SMP_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
new file mode 100644
index 000000000000..a6afc29f2dd9
--- /dev/null
+++ b/arch/x86/include/asm/smp.h
@@ -0,0 +1,229 @@
+#ifndef ASM_X86__SMP_H
+#define ASM_X86__SMP_H
+#ifndef __ASSEMBLY__
+#include <linux/cpumask.h>
+#include <linux/init.h>
+#include <asm/percpu.h>
+
+/*
+ * We need the APIC definitions automatically as part of 'smp.h'
+ */
+#ifdef CONFIG_X86_LOCAL_APIC
+# include <asm/mpspec.h>
+# include <asm/apic.h>
+# ifdef CONFIG_X86_IO_APIC
+#  include <asm/io_apic.h>
+# endif
+#endif
+#include <asm/pda.h>
+#include <asm/thread_info.h>
+
+extern cpumask_t cpu_callout_map;
+extern cpumask_t cpu_initialized;
+extern cpumask_t cpu_callin_map;
+
+extern void (*mtrr_hook)(void);
+extern void zap_low_mappings(void);
+
+extern int __cpuinit get_local_pda(int cpu);
+
+extern int smp_num_siblings;
+extern unsigned int num_processors;
+extern cpumask_t cpu_initialized;
+
+DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_t, cpu_core_map);
+DECLARE_PER_CPU(u16, cpu_llc_id);
+#ifdef CONFIG_X86_32
+DECLARE_PER_CPU(int, cpu_number);
+#endif
+
+DECLARE_EARLY_PER_CPU(u16, x86_cpu_to_apicid);
+DECLARE_EARLY_PER_CPU(u16, x86_bios_cpu_apicid);
+
+/* Static state in head.S used to set up a CPU */
+extern struct {
+	void *sp;
+	unsigned short ss;
+} stack_start;
+
+struct smp_ops {
+	void (*smp_prepare_boot_cpu)(void);
+	void (*smp_prepare_cpus)(unsigned max_cpus);
+	void (*smp_cpus_done)(unsigned max_cpus);
+
+	void (*smp_send_stop)(void);
+	void (*smp_send_reschedule)(int cpu);
+
+	int (*cpu_up)(unsigned cpu);
+	int (*cpu_disable)(void);
+	void (*cpu_die)(unsigned int cpu);
+	void (*play_dead)(void);
+
+	void (*send_call_func_ipi)(cpumask_t mask);
+	void (*send_call_func_single_ipi)(int cpu);
+};
+
+/* Globals due to paravirt */
+extern void set_cpu_sibling_map(int cpu);
+
+#ifdef CONFIG_SMP
+#ifndef CONFIG_PARAVIRT
+#define startup_ipi_hook(phys_apicid, start_eip, start_esp) do { } while (0)
+#endif
+extern struct smp_ops smp_ops;
+
+static inline void smp_send_stop(void)
+{
+	smp_ops.smp_send_stop();
+}
+
+static inline void smp_prepare_boot_cpu(void)
+{
+	smp_ops.smp_prepare_boot_cpu();
+}
+
+static inline void smp_prepare_cpus(unsigned int max_cpus)
+{
+	smp_ops.smp_prepare_cpus(max_cpus);
+}
+
+static inline void smp_cpus_done(unsigned int max_cpus)
+{
+	smp_ops.smp_cpus_done(max_cpus);
+}
+
+static inline int __cpu_up(unsigned int cpu)
+{
+	return smp_ops.cpu_up(cpu);
+}
+
+static inline int __cpu_disable(void)
+{
+	return smp_ops.cpu_disable();
+}
+
+static inline void __cpu_die(unsigned int cpu)
+{
+	smp_ops.cpu_die(cpu);
+}
+
+static inline void play_dead(void)
+{
+	smp_ops.play_dead();
+}
+
+static inline void smp_send_reschedule(int cpu)
+{
+	smp_ops.smp_send_reschedule(cpu);
+}
+
+static inline void arch_send_call_function_single_ipi(int cpu)
+{
+	smp_ops.send_call_func_single_ipi(cpu);
+}
+
+static inline void arch_send_call_function_ipi(cpumask_t mask)
+{
+	smp_ops.send_call_func_ipi(mask);
+}
+
+void cpu_disable_common(void);
+void native_smp_prepare_boot_cpu(void);
+void native_smp_prepare_cpus(unsigned int max_cpus);
+void native_smp_cpus_done(unsigned int max_cpus);
+int native_cpu_up(unsigned int cpunum);
+int native_cpu_disable(void);
+void native_cpu_die(unsigned int cpu);
+void native_play_dead(void);
+void play_dead_common(void);
+
+void native_send_call_func_ipi(cpumask_t mask);
+void native_send_call_func_single_ipi(int cpu);
+
+extern void prefill_possible_map(void);
+
+void smp_store_cpu_info(int id);
+#define cpu_physical_id(cpu)	per_cpu(x86_cpu_to_apicid, cpu)
+
+/* We don't mark CPUs online until __cpu_up(), so we need another measure */
+static inline int num_booting_cpus(void)
+{
+	return cpus_weight(cpu_callout_map);
+}
+#else
+static inline void prefill_possible_map(void)
+{
+}
+#endif /* CONFIG_SMP */
+
+extern unsigned disabled_cpus __cpuinitdata;
+
+#ifdef CONFIG_X86_32_SMP
+/*
+ * This function is needed by all SMP systems. It must _always_ be valid
+ * from the initial startup. We map APIC_BASE very early in page_setup(),
+ * so this is correct in the x86 case.
+ */
+#define raw_smp_processor_id() (x86_read_percpu(cpu_number))
+extern int safe_smp_processor_id(void);
+
+#elif defined(CONFIG_X86_64_SMP)
+#define raw_smp_processor_id()	read_pda(cpunumber)
+
+#define stack_smp_processor_id()					\
+({								\
+	struct thread_info *ti;						\
+	__asm__("andq %%rsp,%0; ":"=r" (ti) : "0" (CURRENT_MASK));	\
+	ti->cpu;							\
+})
+#define safe_smp_processor_id()		smp_processor_id()
+
+#else /* !CONFIG_X86_32_SMP && !CONFIG_X86_64_SMP */
+#define cpu_physical_id(cpu)		boot_cpu_physical_apicid
+#define safe_smp_processor_id()		0
+#define stack_smp_processor_id() 	0
+#endif
+
+#ifdef CONFIG_X86_LOCAL_APIC
+
+#ifndef CONFIG_X86_64
+static inline int logical_smp_processor_id(void)
+{
+	/* we don't want to mark this access volatile - bad code generation */
+	return GET_APIC_LOGICAL_ID(*(u32 *)(APIC_BASE + APIC_LDR));
+}
+
+#include <mach_apicdef.h>
+static inline unsigned int read_apic_id(void)
+{
+	unsigned int reg;
+
+	reg = *(u32 *)(APIC_BASE + APIC_ID);
+
+	return GET_APIC_ID(reg);
+}
+#endif
+
+
+# if defined(APIC_DEFINITION) || defined(CONFIG_X86_64)
+extern int hard_smp_processor_id(void);
+# else
+#include <mach_apicdef.h>
+static inline int hard_smp_processor_id(void)
+{
+	/* we don't want to mark this access volatile - bad code generation */
+	return read_apic_id();
+}
+# endif /* APIC_DEFINITION */
+
+#else /* CONFIG_X86_LOCAL_APIC */
+
+# ifndef CONFIG_SMP
+#  define hard_smp_processor_id()	0
+# endif
+
+#endif /* CONFIG_X86_LOCAL_APIC */
+
+#endif /* __ASSEMBLY__ */
+#endif /* ASM_X86__SMP_H */
