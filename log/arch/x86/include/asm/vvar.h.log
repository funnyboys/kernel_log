commit 550a77a74c87ecfdadc2214fef4b25ff125f65ab
Author: Dmitry Safonov <dima@arista.com>
Date:   Tue Nov 12 01:27:11 2019 +0000

    x86/vdso: Add time napespace page
    
    To support time namespaces in the VDSO with a minimal impact on regular non
    time namespace affected tasks, the namespace handling needs to be hidden in
    a slow path.
    
    The most obvious place is vdso_seq_begin(). If a task belongs to a time
    namespace then the VVAR page which contains the system wide VDSO data is
    replaced with a namespace specific page which has the same layout as the
    VVAR page. That page has vdso_data->seq set to 1 to enforce the slow path
    and vdso_data->clock_mode set to VCLOCK_TIMENS to enforce the time
    namespace handling path.
    
    The extra check in the case that vdso_data->seq is odd, e.g. a concurrent
    update of the VDSO data is in progress, is not really affecting regular
    tasks which are not part of a time namespace as the task is spin waiting
    for the update to finish and vdso_data->seq to become even again.
    
    If a time namespace task hits that code path, it invokes the corresponding
    time getter function which retrieves the real VVAR page, reads host time
    and then adds the offset for the requested clock which is stored in the
    special VVAR page.
    
    Allocate the time namespace page among VVAR pages and place vdso_data on
    it.  Provide __arch_get_timens_vdso_data() helper for VDSO code to get the
    code-relative position of VVARs on that special page.
    
    Co-developed-by: Andrei Vagin <avagin@openvz.org>
    Signed-off-by: Andrei Vagin <avagin@openvz.org>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-23-dima@arista.com

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index ff2de3025388..183e98e49ab9 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -33,9 +33,12 @@ extern char __vvar_page;
 
 #define DECLARE_VVAR(offset, type, name)				\
 	extern type vvar_ ## name[CS_BASES]				\
-	__attribute__((visibility("hidden")));
+	__attribute__((visibility("hidden")));				\
+	extern type timens_ ## name[CS_BASES]				\
+	__attribute__((visibility("hidden")));				\
 
 #define VVAR(name) (vvar_ ## name)
+#define TIMENS(name) (timens_ ## name)
 
 #define DEFINE_VVAR(type, name)						\
 	type name[CS_BASES]						\

commit 64b302ab66c5965702693e79690823ca120288b9
Author: Dmitry Safonov <dima@arista.com>
Date:   Tue Nov 12 01:27:10 2019 +0000

    x86/vdso: Provide vdso_data offset on vvar_page
    
    VDSO support for time namespaces needs to set up a page with the same
    layout as VVAR. That timens page will be placed on position of VVAR page
    inside namespace. That page has vdso_data->seq set to 1 to enforce
    the slow path and vdso_data->clock_mode set to VCLOCK_TIMENS to enforce
    the time namespace handling path.
    
    To prepare the time namespace page the kernel needs to know the vdso_data
    offset.  Provide arch_get_vdso_data() helper for locating vdso_data on VVAR
    page.
    
    Co-developed-by: Andrei Vagin <avagin@openvz.org>
    Signed-off-by: Andrei Vagin <avagin@openvz.org>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-22-dima@arista.com

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 32f5d9a0b90e..ff2de3025388 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -19,10 +19,10 @@
 #ifndef _ASM_X86_VVAR_H
 #define _ASM_X86_VVAR_H
 
-#if defined(__VVAR_KERNEL_LDS)
-
-/* The kernel linker script defines its own magic to put vvars in the
- * right place.
+#ifdef EMIT_VVAR
+/*
+ * EMIT_VVAR() is used by the kernel linker script to put vvars in the
+ * right place. Also, it's used by kernel code to import offsets values.
  */
 #define DECLARE_VVAR(offset, type, name) \
 	EMIT_VVAR(name, offset)

commit 7ac8707479886c75f353bfb6a8273f423cfccb23
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Jun 21 10:52:49 2019 +0100

    x86/vdso: Switch to generic vDSO implementation
    
    The x86 vDSO library requires some adaptations to take advantage of the
    newly introduced generic vDSO library.
    
    Introduce the following changes:
     - Modification of vdso.c to be compliant with the common vdso datapage
     - Use of lib/vdso for gettimeofday
    
    [ tglx: Massaged changelog and cleaned up the function signature formatting ]
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kselftest@vger.kernel.org
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Peter Collingbourne <pcc@google.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Huw Davies <huw@codeweavers.com>
    Cc: Shijith Thotton <sthotton@marvell.com>
    Cc: Andre Przywara <andre.przywara@arm.com>
    Link: https://lkml.kernel.org/r/20190621095252.32307-23-vincenzo.frascino@arm.com

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index e474f5c6e387..32f5d9a0b90e 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -32,19 +32,20 @@
 extern char __vvar_page;
 
 #define DECLARE_VVAR(offset, type, name)				\
-	extern type vvar_ ## name __attribute__((visibility("hidden")));
+	extern type vvar_ ## name[CS_BASES]				\
+	__attribute__((visibility("hidden")));
 
 #define VVAR(name) (vvar_ ## name)
 
 #define DEFINE_VVAR(type, name)						\
-	type name							\
+	type name[CS_BASES]						\
 	__attribute__((section(".vvar_" #name), aligned(16))) __visible
 
 #endif
 
 /* DECLARE_VVAR(offset, type, name) */
 
-DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
+DECLARE_VVAR(128, struct vdso_data, _vdso_data)
 
 #undef DECLARE_VVAR
 

commit 6776e83edbf79de2dec017f1a0594dbc09564ffd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 28 09:57:09 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 180
    
    Based on 1 normalized pattern(s):
    
      subject to the gnu general public license version 2
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Steve Winslow <swinslow@gmail.com>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190528170026.343113277@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 3f32dfc2ab73..e474f5c6e387 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -1,7 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * vvar.h: Shared vDSO/kernel variable declarations
  * Copyright (c) 2011 Andy Lutomirski
- * Subject to the GNU General Public License, version 2
  *
  * A handful of variables are accessible (read-only) from userspace
  * code in the vsyscall page and the vdso.  They are declared here.

commit e76b027e6408f5570dc940b731ec9ae870c6188a
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Oct 30 14:58:01 2014 -0700

    x86,vdso: Use LSL unconditionally for vgetcpu
    
    LSL is faster than RDTSCP and works everywhere; there's no need to
    switch between them depending on CPU.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Andi Kleen <andi@firstfloor.org>
    Link: http://lkml.kernel.org/r/72f73d5ec4514e02bba345b9759177ef03742efb.1414706021.git.luto@amacapital.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 5f6d40734a3b..3f32dfc2ab73 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -44,7 +44,6 @@ extern char __vvar_page;
 
 /* DECLARE_VVAR(offset, type, name) */
 
-DECLARE_VVAR(16, int, vgetcpu_mode)
 DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
 
 #undef DECLARE_VVAR

commit 61a492fb1759f3e892ad0408e36d3575c5f890d0
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Tue Sep 23 10:50:56 2014 -0700

    x86_64/vdso: Remove jiffies from the vvar page
    
    I think that the jiffies vvar was once used for the vgetcpu
    cache. That code is long gone, so let's just make jiffies be a
    normal variable.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/fcfee6f8749af14d96373a9e2656354ad0b95499.1411494540.git.luto@amacapital.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 5d2b9ad2c6d2..5f6d40734a3b 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -44,7 +44,6 @@ extern char __vvar_page;
 
 /* DECLARE_VVAR(offset, type, name) */
 
-DECLARE_VVAR(0, volatile unsigned long, jiffies)
 DECLARE_VVAR(16, int, vgetcpu_mode)
 DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
 

commit f40c330091c7aa9956ab66f97a3abc8a68b67240
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon May 5 12:19:36 2014 -0700

    x86, vdso: Move the vvar and hpet mappings next to the 64-bit vDSO
    
    This makes the 64-bit and x32 vdsos use the same mechanism as the
    32-bit vdso.  Most of the churn is deleting all the old fixmap code.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/8af87023f57f6bb96ec8d17fce3f88018195b49b.1399317206.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 081d909bc495..5d2b9ad2c6d2 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -29,31 +29,13 @@
 
 #else
 
-#ifdef BUILD_VDSO32
+extern char __vvar_page;
 
 #define DECLARE_VVAR(offset, type, name)				\
 	extern type vvar_ ## name __attribute__((visibility("hidden")));
 
 #define VVAR(name) (vvar_ ## name)
 
-#else
-
-extern char __vvar_page;
-
-/* Base address of vvars.  This is not ABI. */
-#ifdef CONFIG_X86_64
-#define VVAR_ADDRESS (-10*1024*1024 - 4096)
-#else
-#define VVAR_ADDRESS (&__vvar_page)
-#endif
-
-#define DECLARE_VVAR(offset, type, name)				\
-	static type const * const vvaraddr_ ## name =			\
-		(void *)(VVAR_ADDRESS + (offset));
-
-#define VVAR(name) (*vvaraddr_ ## name)
-#endif
-
 #define DEFINE_VVAR(type, name)						\
 	type name							\
 	__attribute__((section(".vvar_" #name), aligned(16))) __visible

commit 7c03156f34d113f885f045d8fb8cc3efd9e64751
Author: Stefani Seibold <stefani@seibold.net>
Date:   Mon Mar 17 23:22:10 2014 +0100

    x86, vdso: Add 32 bit VDSO time support for 64 bit kernel
    
    This patch add the VDSO time support for the IA32 Emulation Layer.
    
    Due the nature of the kernel headers and the LP64 compiler where the
    size of a long and a pointer differs against a 32 bit compiler, there
    is some type hacking necessary for optimal performance.
    
    The vsyscall_gtod_data struture must be a rearranged to serve 32- and
    64-bit code access at the same time:
    
    - The seqcount_t was replaced by an unsigned, this makes the
      vsyscall_gtod_data intedepend of kernel configuration and internal functions.
    - All kernel internal structures are replaced by fix size elements
      which works for 32- and 64-bit access
    - The inner struct clock was removed to pack the whole struct.
    
    The "unsigned seq" would be handled by functions derivated from seqcount_t.
    
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/1395094933-14252-11-git-send-email-stefani@seibold.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 52c79ffc3161..081d909bc495 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -16,6 +16,9 @@
  * you mess up, the linker will catch it.)
  */
 
+#ifndef _ASM_X86_VVAR_H
+#define _ASM_X86_VVAR_H
+
 #if defined(__VVAR_KERNEL_LDS)
 
 /* The kernel linker script defines its own magic to put vvars in the
@@ -64,3 +67,5 @@ DECLARE_VVAR(16, int, vgetcpu_mode)
 DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
 
 #undef DECLARE_VVAR
+
+#endif

commit ef721987aef0cc0abba08c88810f2155f76b0b1f
Author: Stefani Seibold <stefani@seibold.net>
Date:   Mon Mar 17 23:22:07 2014 +0100

    x86, vdso: Introduce VVAR marco for vdso32
    
    This patch revamps the vvar.h for introduce the VVAR macro for vdso32.
    
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/1395094933-14252-8-git-send-email-stefani@seibold.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 0a534eac5f56..52c79ffc3161 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -26,6 +26,15 @@
 
 #else
 
+#ifdef BUILD_VDSO32
+
+#define DECLARE_VVAR(offset, type, name)				\
+	extern type vvar_ ## name __attribute__((visibility("hidden")));
+
+#define VVAR(name) (vvar_ ## name)
+
+#else
+
 extern char __vvar_page;
 
 /* Base address of vvars.  This is not ABI. */
@@ -39,12 +48,13 @@ extern char __vvar_page;
 	static type const * const vvaraddr_ ## name =			\
 		(void *)(VVAR_ADDRESS + (offset));
 
+#define VVAR(name) (*vvaraddr_ ## name)
+#endif
+
 #define DEFINE_VVAR(type, name)						\
 	type name							\
 	__attribute__((section(".vvar_" #name), aligned(16))) __visible
 
-#define VVAR(name) (*vvaraddr_ ## name)
-
 #endif
 
 /* DECLARE_VVAR(offset, type, name) */

commit d2312e3379d581d2c3603357a0181046448e1de3
Author: Stefani Seibold <stefani@seibold.net>
Date:   Mon Mar 17 23:22:01 2014 +0100

    x86, vdso: Make vsyscall_gtod_data handling x86 generic
    
    This patch move the vsyscall_gtod_data handling out of vsyscall_64.c
    into an additonal file vsyscall_gtod.c to make the functionality
    available for x86 32 bit kernel.
    
    It also adds a new vsyscall_32.c which setup the VVAR page.
    
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/1395094933-14252-2-git-send-email-stefani@seibold.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index d76ac40da206..0a534eac5f56 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -16,9 +16,6 @@
  * you mess up, the linker will catch it.)
  */
 
-/* Base address of vvars.  This is not ABI. */
-#define VVAR_ADDRESS (-10*1024*1024 - 4096)
-
 #if defined(__VVAR_KERNEL_LDS)
 
 /* The kernel linker script defines its own magic to put vvars in the
@@ -29,6 +26,15 @@
 
 #else
 
+extern char __vvar_page;
+
+/* Base address of vvars.  This is not ABI. */
+#ifdef CONFIG_X86_64
+#define VVAR_ADDRESS (-10*1024*1024 - 4096)
+#else
+#define VVAR_ADDRESS (&__vvar_page)
+#endif
+
 #define DECLARE_VVAR(offset, type, name)				\
 	static type const * const vvaraddr_ ## name =			\
 		(void *)(VVAR_ADDRESS + (offset));

commit 28596b6a8779b736829ad837f95fdc2e81bdd1ee
Author: Andi Kleen <ak@linux.intel.com>
Date:   Mon Aug 5 15:02:50 2013 -0700

    x86, asmlinkage, vdso: Mark vdso variables __visible
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1375740170-7446-17-git-send-email-andi@firstfloor.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index de656ac2af41..d76ac40da206 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -35,7 +35,7 @@
 
 #define DEFINE_VVAR(type, name)						\
 	type name							\
-	__attribute__((section(".vvar_" #name), aligned(16)))
+	__attribute__((section(".vvar_" #name), aligned(16))) __visible
 
 #define VVAR(name) (*vvaraddr_ ## name)
 

commit 9fd67b4ed0714ab718f1f9bd14c344af336a6df7
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Sun Jun 5 13:50:19 2011 -0400

    x86-64: Give vvars their own page
    
    Move vvars out of the vsyscall page into their own page and mark
    it NX.
    
    Without this patch, an attacker who can force a daemon to call
    some fixed address could wait until the time contains, say,
    0xCD80, and then execute the current time.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Jesper Juhl <jj@chaosbits.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: richard -rw- weinberger <richard.weinberger@gmail.com>
    Cc: Mikael Pettersson <mikpe@it.uu.se>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: Valdis.Kletnieks@vt.edu
    Cc: pageexec@freemail.hu
    Link: http://lkml.kernel.org/r/b1460f81dc4463d66ea3f2b5ce240f58d48effec.1307292171.git.luto@mit.edu
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index a4eaca4a6133..de656ac2af41 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -10,15 +10,14 @@
  * In normal kernel code, they are used like any other variable.
  * In user code, they are accessed through the VVAR macro.
  *
- * Each of these variables lives in the vsyscall page, and each
- * one needs a unique offset within the little piece of the page
- * reserved for vvars.  Specify that offset in DECLARE_VVAR.
- * (There are 896 bytes available.  If you mess up, the linker will
- * catch it.)
+ * These variables live in a page of kernel data that has an extra RO
+ * mapping for userspace.  Each variable needs a unique offset within
+ * that page; specify that offset with the DECLARE_VVAR macro.  (If
+ * you mess up, the linker will catch it.)
  */
 
-/* Offset of vars within vsyscall page */
-#define VSYSCALL_VARS_OFFSET (3072 + 128)
+/* Base address of vvars.  This is not ABI. */
+#define VVAR_ADDRESS (-10*1024*1024 - 4096)
 
 #if defined(__VVAR_KERNEL_LDS)
 
@@ -26,17 +25,17 @@
  * right place.
  */
 #define DECLARE_VVAR(offset, type, name) \
-	EMIT_VVAR(name, VSYSCALL_VARS_OFFSET + offset)
+	EMIT_VVAR(name, offset)
 
 #else
 
 #define DECLARE_VVAR(offset, type, name)				\
 	static type const * const vvaraddr_ ## name =			\
-		(void *)(VSYSCALL_START + VSYSCALL_VARS_OFFSET + (offset));
+		(void *)(VVAR_ADDRESS + (offset));
 
 #define DEFINE_VVAR(type, name)						\
-	type __vvar_ ## name						\
-	__attribute__((section(".vsyscall_var_" #name), aligned(16)))
+	type name							\
+	__attribute__((section(".vvar_" #name), aligned(16)))
 
 #define VVAR(name) (*vvaraddr_ ## name)
 
@@ -49,4 +48,3 @@ DECLARE_VVAR(16, int, vgetcpu_mode)
 DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
 
 #undef DECLARE_VVAR
-#undef VSYSCALL_VARS_OFFSET

commit 6879eb2deed7171a81b2f904c9ad14b9648689a7
Author: Andy Lutomirski <luto@mit.edu>
Date:   Sun Jun 5 13:50:17 2011 -0400

    x86-64: Fix alignment of jiffies variable
    
    It's declared __attribute__((aligned(16)) but it's explicitly
    not aligned.  This is probably harmless but it's a bit
    embarrassing.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Jesper Juhl <jj@chaosbits.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: richard -rw- weinberger <richard.weinberger@gmail.com>
    Cc: Mikael Pettersson <mikpe@it.uu.se>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: Valdis.Kletnieks@vt.edu
    Cc: pageexec@freemail.hu
    Link: http://lkml.kernel.org/r/5f3bc5542e9aaa9382d53f153f54373165cdef89.1307292171.git.luto@mit.edu
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
index 341b3559452b..a4eaca4a6133 100644
--- a/arch/x86/include/asm/vvar.h
+++ b/arch/x86/include/asm/vvar.h
@@ -45,7 +45,7 @@
 /* DECLARE_VVAR(offset, type, name) */
 
 DECLARE_VVAR(0, volatile unsigned long, jiffies)
-DECLARE_VVAR(8, int, vgetcpu_mode)
+DECLARE_VVAR(16, int, vgetcpu_mode)
 DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
 
 #undef DECLARE_VVAR

commit 8c49d9a74bac5ea3f18480307057241b808fcc0c
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Mon May 23 09:31:24 2011 -0400

    x86-64: Clean up vdso/kernel shared variables
    
    Variables that are shared between the vdso and the kernel are
    currently a bit of a mess.  They are each defined with their own
    magic, they are accessed differently in the kernel, the vsyscall page,
    and the vdso, and one of them (vsyscall_clock) doesn't even really
    exist.
    
    This changes them all to use a common mechanism.  All of them are
    delcared in vvar.h with a fixed address (validated by the linker
    script).  In the kernel (as before), they look like ordinary
    read-write variables.  In the vsyscall page and the vdso, they are
    accessed through a new macro VVAR, which gives read-only access.
    
    The vdso is now loaded verbatim into memory without any fixups.  As a
    side bonus, access from the vdso is faster because a level of
    indirection is removed.
    
    While we're at it, pack jiffies and vgetcpu_mode into the same
    cacheline.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Borislav Petkov <bp@amd64.org>
    Link: http://lkml.kernel.org/r/%3C7357882fbb51fa30491636a7b6528747301b7ee9.1306156808.git.luto%40mit.edu%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/vvar.h b/arch/x86/include/asm/vvar.h
new file mode 100644
index 000000000000..341b3559452b
--- /dev/null
+++ b/arch/x86/include/asm/vvar.h
@@ -0,0 +1,52 @@
+/*
+ * vvar.h: Shared vDSO/kernel variable declarations
+ * Copyright (c) 2011 Andy Lutomirski
+ * Subject to the GNU General Public License, version 2
+ *
+ * A handful of variables are accessible (read-only) from userspace
+ * code in the vsyscall page and the vdso.  They are declared here.
+ * Some other file must define them with DEFINE_VVAR.
+ *
+ * In normal kernel code, they are used like any other variable.
+ * In user code, they are accessed through the VVAR macro.
+ *
+ * Each of these variables lives in the vsyscall page, and each
+ * one needs a unique offset within the little piece of the page
+ * reserved for vvars.  Specify that offset in DECLARE_VVAR.
+ * (There are 896 bytes available.  If you mess up, the linker will
+ * catch it.)
+ */
+
+/* Offset of vars within vsyscall page */
+#define VSYSCALL_VARS_OFFSET (3072 + 128)
+
+#if defined(__VVAR_KERNEL_LDS)
+
+/* The kernel linker script defines its own magic to put vvars in the
+ * right place.
+ */
+#define DECLARE_VVAR(offset, type, name) \
+	EMIT_VVAR(name, VSYSCALL_VARS_OFFSET + offset)
+
+#else
+
+#define DECLARE_VVAR(offset, type, name)				\
+	static type const * const vvaraddr_ ## name =			\
+		(void *)(VSYSCALL_START + VSYSCALL_VARS_OFFSET + (offset));
+
+#define DEFINE_VVAR(type, name)						\
+	type __vvar_ ## name						\
+	__attribute__((section(".vsyscall_var_" #name), aligned(16)))
+
+#define VVAR(name) (*vvaraddr_ ## name)
+
+#endif
+
+/* DECLARE_VVAR(offset, type, name) */
+
+DECLARE_VVAR(0, volatile unsigned long, jiffies)
+DECLARE_VVAR(8, int, vgetcpu_mode)
+DECLARE_VVAR(128, struct vsyscall_gtod_data, vsyscall_gtod_data)
+
+#undef DECLARE_VVAR
+#undef VSYSCALL_VARS_OFFSET
