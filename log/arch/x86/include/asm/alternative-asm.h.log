commit ff05ab2305aaeb21a3002ae95a17e176c198b71b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Mar 18 14:33:07 2019 +0100

    x86/nospec, objtool: Introduce ANNOTATE_IGNORE_ALTERNATIVE
    
    To facillitate other usage of ignoring alternatives; rename
    ANNOTATE_NOSPEC_IGNORE to ANNOTATE_IGNORE_ALTERNATIVE.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 31b627b43a8e..464034db299f 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -19,6 +19,17 @@
 	.endm
 #endif
 
+/*
+ * objtool annotation to ignore the alternatives and only consider the original
+ * instruction(s).
+ */
+.macro ANNOTATE_IGNORE_ALTERNATIVE
+	.Lannotate_\@:
+	.pushsection .discard.ignore_alts
+	.long .Lannotate_\@ - .
+	.popsection
+.endm
+
 /*
  * Issue one struct alt_instr descriptor entry (need to put it into
  * the section .altinstructions, see below). This entry contains

commit 851a4cd7cc11fcebfa833824415fc57cf180cadf
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Dec 19 11:20:57 2018 +0100

    Revert "x86/alternatives: Macrofy lock prefixes to work around GCC inlining bugs"
    
    This reverts commit 77f48ec28e4ccff94d2e5f4260a83ac27a7f3099.
    
    See this commit for details about the revert:
    
      e769742d3584 ("Revert "x86/jump-labels: Macrofy inline assembly code to work around GCC inlining bugs"")
    
    Reported-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Richard Biener <rguenther@suse.de>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Segher Boessenkool <segher@kernel.crashing.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Nadav Amit <namit@vmware.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 8e4ea39e55d0..31b627b43a8e 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -7,24 +7,16 @@
 #include <asm/asm.h>
 
 #ifdef CONFIG_SMP
-.macro LOCK_PREFIX_HERE
+	.macro LOCK_PREFIX
+672:	lock
 	.pushsection .smp_locks,"a"
 	.balign 4
-	.long 671f - .		# offset
+	.long 672b - .
 	.popsection
-671:
-.endm
-
-.macro LOCK_PREFIX insn:vararg
-	LOCK_PREFIX_HERE
-	lock \insn
-.endm
+	.endm
 #else
-.macro LOCK_PREFIX_HERE
-.endm
-
-.macro LOCK_PREFIX insn:vararg
-.endm
+	.macro LOCK_PREFIX
+	.endm
 #endif
 
 /*

commit 77f48ec28e4ccff94d2e5f4260a83ac27a7f3099
Author: Nadav Amit <namit@vmware.com>
Date:   Wed Oct 3 14:30:55 2018 -0700

    x86/alternatives: Macrofy lock prefixes to work around GCC inlining bugs
    
    As described in:
    
      77b0bf55bc67: ("kbuild/Makefile: Prepare for using macros in inline assembly code to work around asm() related GCC inlining bugs")
    
    GCC's inlining heuristics are broken with common asm() patterns used in
    kernel code, resulting in the effective disabling of inlining.
    
    The workaround is to set an assembly macro and call it from the inline
    assembly block - i.e. to macrify the affected block.
    
    As a result GCC considers the inline assembly block as a single instruction.
    
    This patch handles the LOCK prefix, allowing more aggresive inlining:
    
          text     data     bss      dec     hex  filename
      18140140 10225284 2957312 31322736 1ddf270  ./vmlinux before
      18146889 10225380 2957312 31329581 1de0d2d  ./vmlinux after (+6845)
    
    This is the reduction in non-inlined functions:
    
      Before: 40286
      After:  40218 (-68)
    
    Tested-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20181003213100.189959-6-namit@vmware.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 31b627b43a8e..8e4ea39e55d0 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -7,16 +7,24 @@
 #include <asm/asm.h>
 
 #ifdef CONFIG_SMP
-	.macro LOCK_PREFIX
-672:	lock
+.macro LOCK_PREFIX_HERE
 	.pushsection .smp_locks,"a"
 	.balign 4
-	.long 672b - .
+	.long 671f - .		# offset
 	.popsection
-	.endm
+671:
+.endm
+
+.macro LOCK_PREFIX insn:vararg
+	LOCK_PREFIX_HERE
+	lock \insn
+.endm
 #else
-	.macro LOCK_PREFIX
-	.endm
+.macro LOCK_PREFIX_HERE
+.endm
+
+.macro LOCK_PREFIX insn:vararg
+.endm
 #endif
 
 /*

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 6c98821fef5e..31b627b43a8e 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_ALTERNATIVE_ASM_H
 #define _ASM_X86_ALTERNATIVE_ASM_H
 

commit 6b32c126d33d5cb379bca280ab8acedc1ca978ff
Author: Mathias Krause <minipli@googlemail.com>
Date:   Thu Oct 5 20:30:12 2017 +0200

    x86/alternatives: Fix alt_max_short macro to really be a max()
    
    The alt_max_short() macro in asm/alternative.h does not work as
    intended, leading to nasty bugs. E.g. alt_max_short("1", "3")
    evaluates to 3, but alt_max_short("3", "1") evaluates to 1 -- not
    exactly the maximum of 1 and 3.
    
    In fact, I had to learn it the hard way by crashing my kernel in not
    so funny ways by attempting to make use of the ALTENATIVE_2 macro
    with alternatives where the first one was larger than the second
    one.
    
    According to [1] and commit dbe4058a6a44 ("x86/alternatives: Fix
    ALTERNATIVE_2 padding generation properly") the right handed side
    should read "-(-(a < b))" not "-(-(a - b))". Fix that, to make the
    macro work as intended.
    
    While at it, fix up the comments regarding the additional "-", too.
    It's not about gas' usage of s32 but brain dead logic of having a
    "true" value of -1 for the < operator ... *sigh*
    
    Btw., the one in asm/alternative-asm.h is correct. And, apparently,
    all current users of ALTERNATIVE_2() pass same sized alternatives,
    avoiding to hit the bug.
    
    [1] http://graphics.stanford.edu/~seander/bithacks.html#IntegerMinOrMax
    
    Reviewed-and-tested-by: Borislav Petkov <bp@suse.de>
    Fixes: dbe4058a6a44 ("x86/alternatives: Fix ALTERNATIVE_2 padding generation properly")
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/1507228213-13095-1-git-send-email-minipli@googlemail.com

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index e7636bac7372..6c98821fef5e 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -62,8 +62,10 @@
 #define new_len2		145f-144f
 
 /*
- * max without conditionals. Idea adapted from:
+ * gas compatible max based on the idea from:
  * http://graphics.stanford.edu/~seander/bithacks.html#IntegerMinOrMax
+ *
+ * The additional "-" is needed because gas uses a "true" value of -1.
  */
 #define alt_max_short(a, b)	((a) ^ (((a) ^ (b)) & -(-((a) < (b)))))
 

commit 5b673a48c54594108aec368014efc7334743f06a
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Apr 4 16:40:45 2015 +0200

    x86/alternatives: Document macros
    
    Add some text to the macro magic for future reference and against
    failing human memory.
    
    Requested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index bdf02eeee765..e7636bac7372 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -18,6 +18,12 @@
 	.endm
 #endif
 
+/*
+ * Issue one struct alt_instr descriptor entry (need to put it into
+ * the section .altinstructions, see below). This entry contains
+ * enough information for the alternatives patching code to patch an
+ * instruction. See apply_alternatives().
+ */
 .macro altinstruction_entry orig alt feature orig_len alt_len pad_len
 	.long \orig - .
 	.long \alt - .
@@ -27,6 +33,12 @@
 	.byte \pad_len
 .endm
 
+/*
+ * Define an alternative between two instructions. If @feature is
+ * present, early code in apply_alternatives() replaces @oldinstr with
+ * @newinstr. ".skip" directive takes care of proper instruction padding
+ * in case @newinstr is longer than @oldinstr.
+ */
 .macro ALTERNATIVE oldinstr, newinstr, feature
 140:
 	\oldinstr
@@ -55,6 +67,12 @@
  */
 #define alt_max_short(a, b)	((a) ^ (((a) ^ (b)) & -(-((a) < (b)))))
 
+
+/*
+ * Same as ALTERNATIVE macro above but for two alternatives. If CPU
+ * has @feature1, it replaces @oldinstr with @newinstr1. If CPU has
+ * @feature2, it replaces @oldinstr with @feature2.
+ */
 .macro ALTERNATIVE_2 oldinstr, newinstr1, feature1, newinstr2, feature2
 140:
 	\oldinstr

commit dbe4058a6a44af4ca5d146aebe01b0a1f9b7fd2a
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Apr 4 15:34:43 2015 +0200

    x86/alternatives: Fix ALTERNATIVE_2 padding generation properly
    
    Quentin caught a corner case with the generation of instruction
    padding in the ALTERNATIVE_2 macro: if len(orig_insn) <
    len(alt1) < len(alt2), then not enough padding gets added and
    that is not good(tm) as we could overwrite the beginning of the
    next instruction.
    
    Luckily, at the time of this writing, we don't have
    ALTERNATIVE_2() invocations which have that problem and even if
    we did, a simple fix would be to prepend the instructions with
    enough prefixes so that that corner case doesn't happen.
    
    However, best it would be if we fixed it properly. See below for
    a simple, abstracted example of what we're doing.
    
    So what we ended up doing is, we compute the
    
            max(len(alt1), len(alt2)) - len(orig_insn)
    
    and feed that value to the .skip gas directive. The max() cannot
    have conditionals due to gas limitations, thus the fancy integer
    math.
    
    With this patch, all ALTERNATIVE_2 sites get padded correctly;
    generating obscure test cases pass too:
    
      #define alt_max_short(a, b)    ((a) ^ (((a) ^ (b)) & -(-((a) < (b)))))
    
      #define gen_skip(orig, alt1, alt2, marker)    \
            .skip -((alt_max_short(alt1, alt2) - (orig)) > 0) * \
                    (alt_max_short(alt1, alt2) - (orig)),marker
    
            .pushsection .text, "ax"
      .globl main
      main:
            gen_skip(1, 2, 4, 0x09)
            gen_skip(4, 1, 2, 0x10)
            ...
            .popsection
    
    Thanks to Quentin for catching it and double-checking the fix!
    
    Reported-by: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20150404133443.GE21152@pd.tnic
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 524bddce0b76..bdf02eeee765 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -45,12 +45,22 @@
 	.popsection
 .endm
 
+#define old_len			141b-140b
+#define new_len1		144f-143f
+#define new_len2		145f-144f
+
+/*
+ * max without conditionals. Idea adapted from:
+ * http://graphics.stanford.edu/~seander/bithacks.html#IntegerMinOrMax
+ */
+#define alt_max_short(a, b)	((a) ^ (((a) ^ (b)) & -(-((a) < (b)))))
+
 .macro ALTERNATIVE_2 oldinstr, newinstr1, feature1, newinstr2, feature2
 140:
 	\oldinstr
 141:
-	.skip -(((144f-143f)-(141b-140b)) > 0) * ((144f-143f)-(141b-140b)),0x90
-	.skip -(((145f-144f)-(144f-143f)-(141b-140b)) > 0) * ((145f-144f)-(144f-143f)-(141b-140b)),0x90
+	.skip -((alt_max_short(new_len1, new_len2) - (old_len)) > 0) * \
+		(alt_max_short(new_len1, new_len2) - (old_len)),0x90
 142:
 
 	.pushsection .altinstructions,"a"

commit 4332195c5615bf748624094ce4ff6797e475024d
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Dec 27 10:41:52 2014 +0100

    x86/alternatives: Add instruction padding
    
    Up until now we have always paid attention to make sure the length of
    the new instruction replacing the old one is at least less or equal to
    the length of the old instruction. If the new instruction is longer, at
    the time it replaces the old instruction it will overwrite the beginning
    of the next instruction in the kernel image and cause your pants to
    catch fire.
    
    So instead of having to pay attention, teach the alternatives framework
    to pad shorter old instructions with NOPs at buildtime - but only in the
    case when
    
      len(old instruction(s)) < len(new instruction(s))
    
    and add nothing in the >= case. (In that case we do add_nops() when
    patching).
    
    This way the alternatives user shouldn't have to care about instruction
    sizes and simply use the macros.
    
    Add asm ALTERNATIVE* flavor macros too, while at it.
    
    Also, we need to save the pad length in a separate struct alt_instr
    member for NOP optimization and the way to do that reliably is to carry
    the pad length instead of trying to detect whether we're looking at
    single-byte NOPs or at pathological instruction offsets like e9 90 90 90
    90, for example, which is a valid instruction.
    
    Thanks to Michael Matz for the great help with toolchain questions.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 372231c22a47..524bddce0b76 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -18,12 +18,53 @@
 	.endm
 #endif
 
-.macro altinstruction_entry orig alt feature orig_len alt_len
+.macro altinstruction_entry orig alt feature orig_len alt_len pad_len
 	.long \orig - .
 	.long \alt - .
 	.word \feature
 	.byte \orig_len
 	.byte \alt_len
+	.byte \pad_len
+.endm
+
+.macro ALTERNATIVE oldinstr, newinstr, feature
+140:
+	\oldinstr
+141:
+	.skip -(((144f-143f)-(141b-140b)) > 0) * ((144f-143f)-(141b-140b)),0x90
+142:
+
+	.pushsection .altinstructions,"a"
+	altinstruction_entry 140b,143f,\feature,142b-140b,144f-143f,142b-141b
+	.popsection
+
+	.pushsection .altinstr_replacement,"ax"
+143:
+	\newinstr
+144:
+	.popsection
+.endm
+
+.macro ALTERNATIVE_2 oldinstr, newinstr1, feature1, newinstr2, feature2
+140:
+	\oldinstr
+141:
+	.skip -(((144f-143f)-(141b-140b)) > 0) * ((144f-143f)-(141b-140b)),0x90
+	.skip -(((145f-144f)-(144f-143f)-(141b-140b)) > 0) * ((145f-144f)-(144f-143f)-(141b-140b)),0x90
+142:
+
+	.pushsection .altinstructions,"a"
+	altinstruction_entry 140b,143f,\feature1,142b-140b,144f-143f,142b-141b
+	altinstruction_entry 140b,144f,\feature2,142b-140b,145f-144f,142b-141b
+	.popsection
+
+	.pushsection .altinstr_replacement,"ax"
+143:
+	\newinstr1
+144:
+	\newinstr2
+145:
+	.popsection
 .endm
 
 #endif  /*  __ASSEMBLY__  */

commit 76f30759f690db21ca567a20665ed2679ad3235b
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Sep 21 12:43:09 2012 -0700

    x86, alternative: Add header guards to <asm/alternative-asm.h>
    
    Add header guards to protect <asm/alternative-asm.h> against multiple
    inclusion.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Link: http://lkml.kernel.org/r/1348256595-29119-6-git-send-email-hpa@linux.intel.com

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 018d29fe634a..372231c22a47 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -1,3 +1,6 @@
+#ifndef _ASM_X86_ALTERNATIVE_ASM_H
+#define _ASM_X86_ALTERNATIVE_ASM_H
+
 #ifdef __ASSEMBLY__
 
 #include <asm/asm.h>
@@ -24,3 +27,5 @@
 .endm
 
 #endif  /*  __ASSEMBLY__  */
+
+#endif /* _ASM_X86_ALTERNATIVE_ASM_H */

commit 9cebed423c84a56b871327dd77e555d1d2186a6b
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Sep 21 12:43:08 2012 -0700

    x86, alternative: Use .pushsection/.popsection
    
    .section/.previous doesn't nest.  Use .pushsection/.popsection in
    <asm/alternative.h> so that they can be properly nested.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Link: http://lkml.kernel.org/r/1348256595-29119-5-git-send-email-hpa@linux.intel.com

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 952bd0100c5c..018d29fe634a 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -5,10 +5,10 @@
 #ifdef CONFIG_SMP
 	.macro LOCK_PREFIX
 672:	lock
-	.section .smp_locks,"a"
+	.pushsection .smp_locks,"a"
 	.balign 4
 	.long 672b - .
-	.previous
+	.popsection
 	.endm
 #else
 	.macro LOCK_PREFIX

commit ceb7b40b65539a771d1bfaf47660ac0ee57e0c4f
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Jan 3 17:35:40 2012 +0100

    x86: Fix atomic64_xxx_cx8() functions
    
    It appears about all functions in arch/x86/lib/atomic64_cx8_32.S
    are wrong in case cmpxchg8b must be restarted, because
    LOCK_PREFIX macro defines a label "1" clashing with other local
    labels :
    
    1:
            some_instructions
            LOCK_PREFIX
            cmpxchg8b (%ebp)
            jne 1b  / jumps to beginning of LOCK_PREFIX !
    
    A possible fix is to use a magic label "672" in LOCK_PREFIX asm
    definition, similar to the "671" one we defined in
    LOCK_PREFIX_HERE.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Jan Beulich <JBeulich@suse.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1325608540.2320.103.camel@edumazet-HP-Compaq-6005-Pro-SFF-PC
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 091508b533b4..952bd0100c5c 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -4,10 +4,10 @@
 
 #ifdef CONFIG_SMP
 	.macro LOCK_PREFIX
-1:	lock
+672:	lock
 	.section .smp_locks,"a"
 	.balign 4
-	.long 1b - .
+	.long 672b - .
 	.previous
 	.endm
 #else

commit a7f934d4f16144cb9521b62e9b8c9ac0118097da
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 15 13:28:33 2011 -0700

    asm alternatives: remove incorrect alignment notes
    
    On x86-64, they were just wasteful: with the explicitly added (now
    unnecessary) padding, the size of the alternatives structure was 16
    bytes, and an alignment of 8 bytes didn't hurt much.
    
    However, it was still silly, since the natural size and alignment for
    the structure is actually just 12 bytes, 4-byte aligned since commit
    59e97e4d6fbc ("x86: Make alternative instruction pointers relative").
    So removing the padding, and removing the extra alignment is just a good
    idea.
    
    On x86-32, the alignment of 4 bytes was correct, but was incorrectly
    hardcoded as 8 bytes in <asm/alternative-asm.h>.  That header file had
    used to be an x86-64 only header file, but various unification efforts
    have made it be used for x86-32 too (ie the unification of rwlock and
    rwsem).
    
    That in turn caused x86-32 boot failures, because the extra alignment
    would result in random zero-filled words in the altinstructions section,
    causing oopses early at boot when doing alternative instruction
    replacement.
    
    So just remove all the alignment noise entirely.  It's wrong, and it's
    unnecessary.  The section itself is already properly aligned by the
    linker scripts, and all additions to the section had better be of the
    proper 12-byte format, keeping it aligned.  So if the align directive
    were to ever make a difference, that would be an indication of a serious
    bug to begin with.
    
    Reported-by: Werner Landgraf <w.landgraf@ru.r>
    Acked-by: Andrew Lutomirski <luto@mit.edu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 4554cc6fb96a..091508b533b4 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -16,7 +16,6 @@
 #endif
 
 .macro altinstruction_entry orig alt feature orig_len alt_len
-	.align 8
 	.long \orig - .
 	.long \alt - .
 	.word \feature

commit 59e97e4d6fbcd5b74a94cb48bcbfc6f8478a5e93
Author: Andy Lutomirski <luto@mit.edu>
Date:   Wed Jul 13 09:24:10 2011 -0400

    x86: Make alternative instruction pointers relative
    
    This save a few bytes on x86-64 and means that future patches can
    apply alternatives to unrelocated code.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Link: http://lkml.kernel.org/r/ff64a6b9a1a3860ca4a7b8b6dc7b4754f9491cd7.1310563276.git.luto@mit.edu
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index 94d420b360d1..4554cc6fb96a 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -17,8 +17,8 @@
 
 .macro altinstruction_entry orig alt feature orig_len alt_len
 	.align 8
-	.quad \orig
-	.quad \alt
+	.long \orig - .
+	.long \alt - .
 	.word \feature
 	.byte \orig_len
 	.byte \alt_len

commit 9072d11da15a71e086eab3b5085184f2c1d06913
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Tue May 17 15:29:13 2011 -0700

    x86, alternative: Add altinstruction_entry macro
    
    Add altinstruction_entry macro to generate .altinstructions section
    entries from assembly code.  This should be less failure-prone than
    open-coding.
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Link: http://lkml.kernel.org/r/1305671358-14478-5-git-send-email-fenghua.yu@intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index a63a68be1cce..94d420b360d1 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -15,4 +15,13 @@
 	.endm
 #endif
 
+.macro altinstruction_entry orig alt feature orig_len alt_len
+	.align 8
+	.quad \orig
+	.quad \alt
+	.word \feature
+	.byte \orig_len
+	.byte \alt_len
+.endm
+
 #endif  /*  __ASSEMBLY__  */

commit 5967ed87ade85a421ef814296c3c7f182b08c225
Author: Jan Beulich <JBeulich@novell.com>
Date:   Wed Apr 21 16:08:14 2010 +0100

    x86-64: Reduce SMP locks table size
    
    Reduce the SMP locks table size by using relative pointers instead of
    absolute ones, thus cutting the table size by half.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <4BCF30FE020000780003B3B6@vpn.id2.novell.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index b97f786a48d5..a63a68be1cce 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -6,8 +6,8 @@
 	.macro LOCK_PREFIX
 1:	lock
 	.section .smp_locks,"a"
-	_ASM_ALIGN
-	_ASM_PTR 1b
+	.balign 4
+	.long 1b - .
 	.previous
 	.endm
 #else

commit 99063c0bcebcc913165a5d168050326eba3e0996
Author: Jan Beulich <JBeulich@novell.com>
Date:   Fri Nov 27 15:06:16 2009 +0000

    x86/alternatives: No need for alternatives-asm.h to re-invent stuff already in asm.h
    
    This at once also gets the alignment specification right for
    x86-64.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <4B0FF8F80200007800022708@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
index e2077d343c33..b97f786a48d5 100644
--- a/arch/x86/include/asm/alternative-asm.h
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -1,17 +1,13 @@
 #ifdef __ASSEMBLY__
 
-#ifdef CONFIG_X86_32
-# define X86_ALIGN .long
-#else
-# define X86_ALIGN .quad
-#endif
+#include <asm/asm.h>
 
 #ifdef CONFIG_SMP
 	.macro LOCK_PREFIX
 1:	lock
 	.section .smp_locks,"a"
-	.align 4
-	X86_ALIGN 1b
+	_ASM_ALIGN
+	_ASM_PTR 1b
 	.previous
 	.endm
 #else

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/alternative-asm.h b/arch/x86/include/asm/alternative-asm.h
new file mode 100644
index 000000000000..e2077d343c33
--- /dev/null
+++ b/arch/x86/include/asm/alternative-asm.h
@@ -0,0 +1,22 @@
+#ifdef __ASSEMBLY__
+
+#ifdef CONFIG_X86_32
+# define X86_ALIGN .long
+#else
+# define X86_ALIGN .quad
+#endif
+
+#ifdef CONFIG_SMP
+	.macro LOCK_PREFIX
+1:	lock
+	.section .smp_locks,"a"
+	.align 4
+	X86_ALIGN 1b
+	.previous
+	.endm
+#else
+	.macro LOCK_PREFIX
+	.endm
+#endif
+
+#endif  /*  __ASSEMBLY__  */
