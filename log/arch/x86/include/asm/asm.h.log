commit cf122cfba5b1d9daf64009d143f51dfec4b1705a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 15 21:10:25 2020 -0500

    kill uaccess_try()
    
    finally
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index cd339b88d5d4..0f63585edf5f 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -138,9 +138,6 @@
 # define _ASM_EXTABLE_FAULT(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
 
-# define _ASM_EXTABLE_EX(from, to)				\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
-
 # define _ASM_NOKPROBE(entry)					\
 	.pushsection "_kprobe_blacklist","aw" ;			\
 	_ASM_ALIGN ;						\
@@ -166,9 +163,6 @@
 # define _ASM_EXTABLE_FAULT(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
 
-# define _ASM_EXTABLE_EX(from, to)				\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
-
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 

commit 168829ad09ca9cdfdc664b2110d0e3569932c12d
Merge: 1ae78780eda5 500543c53a54
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 26 16:02:40 2019 -0800

    Merge branch 'locking-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull locking updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - A comprehensive rewrite of the robust/PI futex code's exit handling
         to fix various exit races. (Thomas Gleixner et al)
    
       - Rework the generic REFCOUNT_FULL implementation using
         atomic_fetch_* operations so that the performance impact of the
         cmpxchg() loops is mitigated for common refcount operations.
    
         With these performance improvements the generic implementation of
         refcount_t should be good enough for everybody - and this got
         confirmed by performance testing, so remove ARCH_HAS_REFCOUNT and
         REFCOUNT_FULL entirely, leaving the generic implementation enabled
         unconditionally. (Will Deacon)
    
       - Other misc changes, fixes, cleanups"
    
    * 'locking-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      lkdtm: Remove references to CONFIG_REFCOUNT_FULL
      locking/refcount: Remove unused 'refcount_error_report()' function
      locking/refcount: Consolidate implementations of refcount_t
      locking/refcount: Consolidate REFCOUNT_{MAX,SATURATED} definitions
      locking/refcount: Move saturation warnings out of line
      locking/refcount: Improve performance of generic REFCOUNT_FULL code
      locking/refcount: Move the bulk of the REFCOUNT_FULL implementation into the <linux/refcount.h> header
      locking/refcount: Remove unused refcount_*_checked() variants
      locking/refcount: Ensure integer operands are treated as signed
      locking/refcount: Define constants for saturation and max refcount values
      futex: Prevent exit livelock
      futex: Provide distinct return value when owner is exiting
      futex: Add mutex around futex exit
      futex: Provide state handling for exec() as well
      futex: Sanitize exit state handling
      futex: Mark the begin of futex exit explicitly
      futex: Set task::futex_state to DEAD right after handling futex exit
      futex: Split futex_mm_release() for exit/exec
      exit/exec: Seperate mm_release()
      futex: Replace PF_EXITPIDONE with a state
      ...

commit fb041bb7c0a918b95c6889fc965cdc4a75b4c0ca
Author: Will Deacon <will@kernel.org>
Date:   Thu Nov 21 11:59:00 2019 +0000

    locking/refcount: Consolidate implementations of refcount_t
    
    The generic implementation of refcount_t should be good enough for
    everybody, so remove ARCH_HAS_REFCOUNT and REFCOUNT_FULL entirely,
    leaving the generic implementation enabled unconditionally.
    
    Signed-off-by: Will Deacon <will@kernel.org>
    Reviewed-by: Ard Biesheuvel <ardb@kernel.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Tested-by: Hanjun Guo <guohanjun@huawei.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Elena Reshetova <elena.reshetova@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20191121115902.2551-9-will@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 3ff577c0b102..5a0c14ebef70 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -139,9 +139,6 @@
 # define _ASM_EXTABLE_EX(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
 
-# define _ASM_EXTABLE_REFCOUNT(from, to)			\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
-
 # define _ASM_NOKPROBE(entry)					\
 	.pushsection "_kprobe_blacklist","aw" ;			\
 	_ASM_ALIGN ;						\
@@ -170,9 +167,6 @@
 # define _ASM_EXTABLE_EX(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
 
-# define _ASM_EXTABLE_REFCOUNT(from, to)			\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
-
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 

commit f7919fd943abf0c77aed4441ea9897a323d132f5
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Fri Sep 6 22:13:48 2019 +0900

    x86/asm: Allow to pass macros to __ASM_FORM()
    
    Use __stringify() at __ASM_FORM() so that user can pass
    code including macros to __ASM_FORM().
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: x86@kernel.org
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Stefano Stabellini <sstabellini@kernel.org>
    Cc: Andrew Cooper <andrew.cooper3@citrix.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lkml.kernel.org/r/156777562873.25081.2288083344657460959.stgit@devnote2

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 3ff577c0b102..1b563f9167ea 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -7,9 +7,11 @@
 # define __ASM_FORM_RAW(x)     x
 # define __ASM_FORM_COMMA(x) x,
 #else
-# define __ASM_FORM(x)	" " #x " "
-# define __ASM_FORM_RAW(x)     #x
-# define __ASM_FORM_COMMA(x) " " #x ","
+#include <linux/stringify.h>
+
+# define __ASM_FORM(x)	" " __stringify(x) " "
+# define __ASM_FORM_RAW(x)     __stringify(x)
+# define __ASM_FORM_COMMA(x) " " __stringify(x) ","
 #endif
 
 #ifndef __x86_64__

commit 3693ca81151eacd498675baae56abede577e8b31
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 1 15:24:33 2019 +0100

    x86/uaccess: Move copy_user_handle_tail() into asm
    
    By writing the function in asm we avoid cross object code flow and
    objtool no longer gets confused about a 'stray' CLAC.
    
    Also; the asm version is actually _simpler_.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 6467757bb39f..3ff577c0b102 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -148,30 +148,6 @@
 	_ASM_PTR (entry);					\
 	.popsection
 
-.macro ALIGN_DESTINATION
-	/* check for bad alignment of destination */
-	movl %edi,%ecx
-	andl $7,%ecx
-	jz 102f				/* already aligned */
-	subl $8,%ecx
-	negl %ecx
-	subl %ecx,%edx
-100:	movb (%rsi),%al
-101:	movb %al,(%rdi)
-	incq %rsi
-	incq %rdi
-	decl %ecx
-	jnz 100b
-102:
-	.section .fixup,"ax"
-103:	addl %ecx,%edx			/* ecx is zerorest also */
-	jmp copy_user_handle_tail
-	.previous
-
-	_ASM_EXTABLE_UA(100b, 103b)
-	_ASM_EXTABLE_UA(101b, 103b)
-	.endm
-
 #else
 # define _EXPAND_EXTABLE_HANDLE(x) #x
 # define _ASM_EXTABLE_HANDLE(from, to, handler)			\

commit 81a68455e795c9094a49c017d974c89223e6cd42
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Dec 19 11:20:37 2018 +0100

    Revert "x86/extable: Macrofy inline assembly code to work around GCC inlining bugs"
    
    This reverts commit 0474d5d9d2f7f3b11262f7bf87d0e7314ead9200.
    
    See this commit for details about the revert:
    
      e769742d3584 ("Revert "x86/jump-labels: Macrofy inline assembly code to work around GCC inlining bugs"")
    
    Reported-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Reviewed-by: Borislav Petkov <bp@alien8.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Richard Biener <rguenther@suse.de>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Segher Boessenkool <segher@kernel.crashing.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Nadav Amit <namit@vmware.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 21b086786404..6467757bb39f 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -120,25 +120,12 @@
 /* Exception table entry */
 #ifdef __ASSEMBLY__
 # define _ASM_EXTABLE_HANDLE(from, to, handler)			\
-	ASM_EXTABLE_HANDLE from to handler
-
-.macro ASM_EXTABLE_HANDLE from:req to:req handler:req
-	.pushsection "__ex_table","a"
-	.balign 4
-	.long (\from) - .
-	.long (\to) - .
-	.long (\handler) - .
+	.pushsection "__ex_table","a" ;				\
+	.balign 4 ;						\
+	.long (from) - . ;					\
+	.long (to) - . ;					\
+	.long (handler) - . ;					\
 	.popsection
-.endm
-#else /* __ASSEMBLY__ */
-
-# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
-	"ASM_EXTABLE_HANDLE from=" #from " to=" #to		\
-	" handler=\"" #handler "\"\n\t"
-
-/* For C file, we already have NOKPROBE_SYMBOL macro */
-
-#endif /* __ASSEMBLY__ */
 
 # define _ASM_EXTABLE(from, to)					\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
@@ -161,7 +148,6 @@
 	_ASM_PTR (entry);					\
 	.popsection
 
-#ifdef __ASSEMBLY__
 .macro ALIGN_DESTINATION
 	/* check for bad alignment of destination */
 	movl %edi,%ecx
@@ -185,7 +171,34 @@
 	_ASM_EXTABLE_UA(100b, 103b)
 	_ASM_EXTABLE_UA(101b, 103b)
 	.endm
-#endif /* __ASSEMBLY__ */
+
+#else
+# define _EXPAND_EXTABLE_HANDLE(x) #x
+# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
+	" .pushsection \"__ex_table\",\"a\"\n"			\
+	" .balign 4\n"						\
+	" .long (" #from ") - .\n"				\
+	" .long (" #to ") - .\n"				\
+	" .long (" _EXPAND_EXTABLE_HANDLE(handler) ") - .\n"	\
+	" .popsection\n"
+
+# define _ASM_EXTABLE(from, to)					\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
+
+# define _ASM_EXTABLE_UA(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_uaccess)
+
+# define _ASM_EXTABLE_FAULT(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
+
+# define _ASM_EXTABLE_EX(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
+
+# define _ASM_EXTABLE_REFCOUNT(from, to)			\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
+
+/* For C file, we already have NOKPROBE_SYMBOL macro */
+#endif
 
 #ifndef __ASSEMBLY__
 /*

commit 0474d5d9d2f7f3b11262f7bf87d0e7314ead9200
Author: Nadav Amit <namit@vmware.com>
Date:   Fri Oct 5 13:27:16 2018 -0700

    x86/extable: Macrofy inline assembly code to work around GCC inlining bugs
    
    As described in:
    
      77b0bf55bc67: ("kbuild/Makefile: Prepare for using macros in inline assembly code to work around asm() related GCC inlining bugs")
    
    GCC's inlining heuristics are broken with common asm() patterns used in
    kernel code, resulting in the effective disabling of inlining.
    
    The workaround is to set an assembly macro and call it from the inline
    assembly block - which is also a minor cleanup for the exception table
    code.
    
    Text size goes up a bit:
    
          text     data     bss      dec     hex  filename
      18162555 10226288 2957312 31346155 1de4deb  ./vmlinux before
      18162879 10226256 2957312 31346447 1de4f0f  ./vmlinux after (+292)
    
    But this allows the inlining of functions such as nested_vmx_exit_reflected(),
    set_segment_reg(), __copy_xstate_to_user() which is a net benefit.
    
    Tested-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20181005202718.229565-2-namit@vmware.com
    Link: https://lore.kernel.org/lkml/20181003213100.189959-9-namit@vmware.com/T/#u
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 6467757bb39f..21b086786404 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -120,12 +120,25 @@
 /* Exception table entry */
 #ifdef __ASSEMBLY__
 # define _ASM_EXTABLE_HANDLE(from, to, handler)			\
-	.pushsection "__ex_table","a" ;				\
-	.balign 4 ;						\
-	.long (from) - . ;					\
-	.long (to) - . ;					\
-	.long (handler) - . ;					\
+	ASM_EXTABLE_HANDLE from to handler
+
+.macro ASM_EXTABLE_HANDLE from:req to:req handler:req
+	.pushsection "__ex_table","a"
+	.balign 4
+	.long (\from) - .
+	.long (\to) - .
+	.long (\handler) - .
 	.popsection
+.endm
+#else /* __ASSEMBLY__ */
+
+# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
+	"ASM_EXTABLE_HANDLE from=" #from " to=" #to		\
+	" handler=\"" #handler "\"\n\t"
+
+/* For C file, we already have NOKPROBE_SYMBOL macro */
+
+#endif /* __ASSEMBLY__ */
 
 # define _ASM_EXTABLE(from, to)					\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
@@ -148,6 +161,7 @@
 	_ASM_PTR (entry);					\
 	.popsection
 
+#ifdef __ASSEMBLY__
 .macro ALIGN_DESTINATION
 	/* check for bad alignment of destination */
 	movl %edi,%ecx
@@ -171,34 +185,7 @@
 	_ASM_EXTABLE_UA(100b, 103b)
 	_ASM_EXTABLE_UA(101b, 103b)
 	.endm
-
-#else
-# define _EXPAND_EXTABLE_HANDLE(x) #x
-# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
-	" .pushsection \"__ex_table\",\"a\"\n"			\
-	" .balign 4\n"						\
-	" .long (" #from ") - .\n"				\
-	" .long (" #to ") - .\n"				\
-	" .long (" _EXPAND_EXTABLE_HANDLE(handler) ") - .\n"	\
-	" .popsection\n"
-
-# define _ASM_EXTABLE(from, to)					\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
-
-# define _ASM_EXTABLE_UA(from, to)				\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_uaccess)
-
-# define _ASM_EXTABLE_FAULT(from, to)				\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
-
-# define _ASM_EXTABLE_EX(from, to)				\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
-
-# define _ASM_EXTABLE_REFCOUNT(from, to)			\
-	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
-
-/* For C file, we already have NOKPROBE_SYMBOL macro */
-#endif
+#endif /* __ASSEMBLY__ */
 
 #ifndef __ASSEMBLY__
 /*

commit 75045f77f7a73e617494d7a1fcf4e9c1849cec39
Author: Jann Horn <jannh@google.com>
Date:   Tue Aug 28 22:14:18 2018 +0200

    x86/extable: Introduce _ASM_EXTABLE_UA for uaccess fixups
    
    Currently, most fixups for attempting to access userspace memory are
    handled using _ASM_EXTABLE, which is also used for various other types of
    fixups (e.g. safe MSR access, IRET failures, and a bunch of other things).
    In order to make it possible to add special safety checks to uaccess fixups
    (in particular, checking whether the fault address is actually in
    userspace), introduce a new exception table handler ex_handler_uaccess()
    and wire it up to all the user access fixups (excluding ones that
    already use _ASM_EXTABLE_EX).
    
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: kernel-hardening@lists.openwall.com
    Cc: dvyukov@google.com
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: "Naveen N. Rao" <naveen.n.rao@linux.vnet.ibm.com>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Link: https://lkml.kernel.org/r/20180828201421.157735-5-jannh@google.com

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 990770f9e76b..6467757bb39f 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -130,6 +130,9 @@
 # define _ASM_EXTABLE(from, to)					\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
 
+# define _ASM_EXTABLE_UA(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_uaccess)
+
 # define _ASM_EXTABLE_FAULT(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
 
@@ -165,8 +168,8 @@
 	jmp copy_user_handle_tail
 	.previous
 
-	_ASM_EXTABLE(100b,103b)
-	_ASM_EXTABLE(101b,103b)
+	_ASM_EXTABLE_UA(100b, 103b)
+	_ASM_EXTABLE_UA(101b, 103b)
 	.endm
 
 #else
@@ -182,6 +185,9 @@
 # define _ASM_EXTABLE(from, to)					\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
 
+# define _ASM_EXTABLE_UA(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_uaccess)
+
 # define _ASM_EXTABLE_FAULT(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
 

commit 0e2e160033283e20f688d8bad5b89460cc5bfcc4
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Thu Jun 21 09:23:23 2018 -0700

    x86/asm: Add _ASM_ARG* constants for argument registers to <asm/asm.h>
    
    i386 and x86-64 uses different registers for arguments; make them
    available so we don't have to #ifdef in the actual code.
    
    Native size and specified size (q, l, w, b) versions are provided.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Reviewed-by: Sedat Dilek <sedat.dilek@gmail.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: acme@redhat.com
    Cc: akataria@vmware.com
    Cc: akpm@linux-foundation.org
    Cc: andrea.parri@amarulasolutions.com
    Cc: ard.biesheuvel@linaro.org
    Cc: arnd@arndb.de
    Cc: aryabinin@virtuozzo.com
    Cc: astrachan@google.com
    Cc: boris.ostrovsky@oracle.com
    Cc: brijesh.singh@amd.com
    Cc: caoj.fnst@cn.fujitsu.com
    Cc: geert@linux-m68k.org
    Cc: ghackmann@google.com
    Cc: gregkh@linuxfoundation.org
    Cc: jan.kiszka@siemens.com
    Cc: jarkko.sakkinen@linux.intel.com
    Cc: joe@perches.com
    Cc: jpoimboe@redhat.com
    Cc: keescook@google.com
    Cc: kirill.shutemov@linux.intel.com
    Cc: kstewart@linuxfoundation.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-kbuild@vger.kernel.org
    Cc: manojgupta@google.com
    Cc: mawilcox@microsoft.com
    Cc: michal.lkml@markovi.net
    Cc: mjg59@google.com
    Cc: mka@chromium.org
    Cc: pombredanne@nexb.com
    Cc: rientjes@google.com
    Cc: rostedt@goodmis.org
    Cc: thomas.lendacky@amd.com
    Cc: tstellar@redhat.com
    Cc: tweek@google.com
    Cc: virtualization@lists.linux-foundation.org
    Cc: will.deacon@arm.com
    Cc: yamada.masahiro@socionext.com
    Link: http://lkml.kernel.org/r/20180621162324.36656-3-ndesaulniers@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 219faaec51df..990770f9e76b 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -46,6 +46,65 @@
 #define _ASM_SI		__ASM_REG(si)
 #define _ASM_DI		__ASM_REG(di)
 
+#ifndef __x86_64__
+/* 32 bit */
+
+#define _ASM_ARG1	_ASM_AX
+#define _ASM_ARG2	_ASM_DX
+#define _ASM_ARG3	_ASM_CX
+
+#define _ASM_ARG1L	eax
+#define _ASM_ARG2L	edx
+#define _ASM_ARG3L	ecx
+
+#define _ASM_ARG1W	ax
+#define _ASM_ARG2W	dx
+#define _ASM_ARG3W	cx
+
+#define _ASM_ARG1B	al
+#define _ASM_ARG2B	dl
+#define _ASM_ARG3B	cl
+
+#else
+/* 64 bit */
+
+#define _ASM_ARG1	_ASM_DI
+#define _ASM_ARG2	_ASM_SI
+#define _ASM_ARG3	_ASM_DX
+#define _ASM_ARG4	_ASM_CX
+#define _ASM_ARG5	r8
+#define _ASM_ARG6	r9
+
+#define _ASM_ARG1Q	rdi
+#define _ASM_ARG2Q	rsi
+#define _ASM_ARG3Q	rdx
+#define _ASM_ARG4Q	rcx
+#define _ASM_ARG5Q	r8
+#define _ASM_ARG6Q	r9
+
+#define _ASM_ARG1L	edi
+#define _ASM_ARG2L	esi
+#define _ASM_ARG3L	edx
+#define _ASM_ARG4L	ecx
+#define _ASM_ARG5L	r8d
+#define _ASM_ARG6L	r9d
+
+#define _ASM_ARG1W	di
+#define _ASM_ARG2W	si
+#define _ASM_ARG3W	dx
+#define _ASM_ARG4W	cx
+#define _ASM_ARG5W	r8w
+#define _ASM_ARG6W	r9w
+
+#define _ASM_ARG1B	dil
+#define _ASM_ARG2B	sil
+#define _ASM_ARG3B	dl
+#define _ASM_ARG4B	cl
+#define _ASM_ARG5B	r8b
+#define _ASM_ARG6B	r9b
+
+#endif
+
 /*
  * Macros to generate condition code outputs from inline assembly,
  * The output operand must be type "bool".

commit fd97d39b0aa49a4beb429aec344604c1b689f089
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 11 18:03:33 2018 -0300

    Revert "x86/asm: Allow again using asm.h when building for the 'bpf' clang target"
    
    This reverts commit ca26cffa4e4aaeb09bb9e308f95c7835cb149248.
    
    Newer clang versions accept that asm(_ASM_SP) construct, and now that
    the bpf-script-test-kbuild.c script, used in one of the 'perf test LLVM'
    subtests doesn't include ptrace.h, which ended up including
    arch/x86/include/asm/asm.h, we can revert this patch.
    
    Suggested-by: Yonghong Song <yhs@fb.com>
    Link: https://lkml.kernel.org/r/613f0a0d-c433-8f4d-dcc1-c9889deae39e@fb.com
    Acked-by: Yonghong Song <yhs@fb.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Dmitriy Vyukov <dvyukov@google.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthias Kaehlcke <mka@chromium.org>
    Cc: Miguel Bernal Marin <miguel.bernal.marin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-nqozcv8loq40tkqpfw997993@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 386a6900e206..219faaec51df 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -136,7 +136,6 @@
 #endif
 
 #ifndef __ASSEMBLY__
-#ifndef __BPF__
 /*
  * This output constraint should be used for any inline asm which has a "call"
  * instruction.  Otherwise the asm may be inserted before the frame pointer
@@ -146,6 +145,5 @@
 register unsigned long current_stack_pointer asm(_ASM_SP);
 #define ASM_CALL_CONSTRAINT "+r" (current_stack_pointer)
 #endif
-#endif
 
 #endif /* _ASM_X86_ASM_H */

commit ca26cffa4e4aaeb09bb9e308f95c7835cb149248
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Dec 4 13:08:47 2017 -0300

    x86/asm: Allow again using asm.h when building for the 'bpf' clang target
    
    Up to f5caf621ee35 ("x86/asm: Fix inline asm call constraints for Clang")
    we were able to use x86 headers to build to the 'bpf' clang target, as
    done by the BPF code in tools/perf/.
    
    With that commit, we ended up with following failure for 'perf test LLVM', this
    is because "clang ... -target bpf ..." fails since 4.0 does not have bpf inline
    asm support and 6.0 does not recognize the register 'esp', fix it by guarding
    that part with an #ifndef __BPF__, that is defined by clang when building to
    the "bpf" target.
    
      # perf test -v LLVM
      37: LLVM search and compile                               :
      37.1: Basic BPF llvm compile                              :
      --- start ---
      test child forked, pid 25526
      Kernel build dir is set to /lib/modules/4.14.0+/build
      set env: KBUILD_DIR=/lib/modules/4.14.0+/build
      unset env: KBUILD_OPTS
      include option is set to  -nostdinc -isystem /usr/lib/gcc/x86_64-redhat-linux/7/include -I/home/acme/git/linux/arch/x86/include -I./arch/x86/include/generated  -I/home/acme/git/linux/include -I./include -I/home/acme/git/linux/arch/x86/include/uapi -I./arch/x86/include/generated/uapi -I/home/acme/git/linux/include/uapi -I./include/generated/uapi -include /home/acme/git/linux/include/linux/kconfig.h
      set env: NR_CPUS=4
      set env: LINUX_VERSION_CODE=0x40e00
      set env: CLANG_EXEC=/usr/local/bin/clang
      set env: CLANG_OPTIONS=-xc
      set env: KERNEL_INC_OPTIONS= -nostdinc -isystem /usr/lib/gcc/x86_64-redhat-linux/7/include -I/home/acme/git/linux/arch/x86/include -I./arch/x86/include/generated  -I/home/acme/git/linux/include -I./include -I/home/acme/git/linux/arch/x86/include/uapi -I./arch/x86/include/generated/uapi -I/home/acme/git/linux/include/uapi -I./include/generated/uapi -include /home/acme/git/linux/include/linux/kconfig.h
      set env: WORKING_DIR=/lib/modules/4.14.0+/build
      set env: CLANG_SOURCE=-
      llvm compiling command template: echo '/*
       * bpf-script-example.c
       * Test basic LLVM building
       */
      #ifndef LINUX_VERSION_CODE
      # error Need LINUX_VERSION_CODE
      # error Example: for 4.2 kernel, put 'clang-opt="-DLINUX_VERSION_CODE=0x40200" into llvm section of ~/.perfconfig'
      #endif
      #define BPF_ANY 0
      #define BPF_MAP_TYPE_ARRAY 2
      #define BPF_FUNC_map_lookup_elem 1
      #define BPF_FUNC_map_update_elem 2
    
      static void *(*bpf_map_lookup_elem)(void *map, void *key) =
              (void *) BPF_FUNC_map_lookup_elem;
      static void *(*bpf_map_update_elem)(void *map, void *key, void *value, int flags) =
              (void *) BPF_FUNC_map_update_elem;
    
      struct bpf_map_def {
              unsigned int type;
              unsigned int key_size;
              unsigned int value_size;
              unsigned int max_entries;
      };
    
      #define SEC(NAME) __attribute__((section(NAME), used))
      struct bpf_map_def SEC("maps") flip_table = {
              .type = BPF_MAP_TYPE_ARRAY,
              .key_size = sizeof(int),
              .value_size = sizeof(int),
              .max_entries = 1,
      };
    
      SEC("func=SyS_epoll_wait")
      int bpf_func__SyS_epoll_wait(void *ctx)
      {
              int ind =0;
              int *flag = bpf_map_lookup_elem(&flip_table, &ind);
              int new_flag;
              if (!flag)
                      return 0;
              /* flip flag and store back */
              new_flag = !*flag;
              bpf_map_update_elem(&flip_table, &ind, &new_flag, BPF_ANY);
              return new_flag;
      }
      char _license[] SEC("license") = "GPL";
      int _version SEC("version") = LINUX_VERSION_CODE;
      ' | $CLANG_EXEC -D__KERNEL__ -D__NR_CPUS__=$NR_CPUS -DLINUX_VERSION_CODE=$LINUX_VERSION_CODE $CLANG_OPTIONS $KERNEL_INC_OPTIONS -Wno-unused-value -Wno-pointer-sign -working-directory $WORKING_DIR -c "$CLANG_SOURCE" -target bpf -O2 -o -
      test child finished with 0
      ---- end ----
      LLVM search and compile subtest 0: Ok
      37.2: kbuild searching                                    :
      --- start ---
      test child forked, pid 25950
      Kernel build dir is set to /lib/modules/4.14.0+/build
      set env: KBUILD_DIR=/lib/modules/4.14.0+/build
      unset env: KBUILD_OPTS
      include option is set to  -nostdinc -isystem /usr/lib/gcc/x86_64-redhat-linux/7/include -I/home/acme/git/linux/arch/x86/include -I./arch/x86/include/generated  -I/home/acme/git/linux/include -I./include -I/home/acme/git/linux/arch/x86/include/uapi -I./arch/x86/include/generated/uapi -I/home/acme/git/linux/include/uapi -I./include/generated/uapi -include /home/acme/git/linux/include/linux/kconfig.h
      set env: NR_CPUS=4
      set env: LINUX_VERSION_CODE=0x40e00
      set env: CLANG_EXEC=/usr/local/bin/clang
      set env: CLANG_OPTIONS=-xc
      set env: KERNEL_INC_OPTIONS= -nostdinc -isystem /usr/lib/gcc/x86_64-redhat-linux/7/include -I/home/acme/git/linux/arch/x86/include -I./arch/x86/include/generated  -I/home/acme/git/linux/include -I./include -I/home/acme/git/linux/arch/x86/include/uapi -I./arch/x86/include/generated/uapi -I/home/acme/git/linux/include/uapi -I./include/generated/uapi -include /home/acme/git/linux/include/linux/kconfig.h
      set env: WORKING_DIR=/lib/modules/4.14.0+/build
      set env: CLANG_SOURCE=-
      llvm compiling command template: echo '/*
       * bpf-script-test-kbuild.c
       * Test include from kernel header
       */
      #ifndef LINUX_VERSION_CODE
      # error Need LINUX_VERSION_CODE
      # error Example: for 4.2 kernel, put 'clang-opt="-DLINUX_VERSION_CODE=0x40200" into llvm section of ~/.perfconfig'
      #endif
      #define SEC(NAME) __attribute__((section(NAME), used))
    
      #include <uapi/linux/fs.h>
      #include <uapi/asm/ptrace.h>
    
      SEC("func=vfs_llseek")
      int bpf_func__vfs_llseek(void *ctx)
      {
              return 0;
      }
    
      char _license[] SEC("license") = "GPL";
      int _version SEC("version") = LINUX_VERSION_CODE;
      ' | $CLANG_EXEC -D__KERNEL__ -D__NR_CPUS__=$NR_CPUS -DLINUX_VERSION_CODE=$LINUX_VERSION_CODE $CLANG_OPTIONS $KERNEL_INC_OPTIONS -Wno-unused-value -Wno-pointer-sign -working-directory $WORKING_DIR -c "$CLANG_SOURCE" -target bpf -O2 -o -
      In file included from <stdin>:12:
      In file included from /home/acme/git/linux/arch/x86/include/uapi/asm/ptrace.h:5:
      In file included from /home/acme/git/linux/include/linux/compiler.h:242:
      In file included from /home/acme/git/linux/arch/x86/include/asm/barrier.h:5:
      In file included from /home/acme/git/linux/arch/x86/include/asm/alternative.h:10:
      /home/acme/git/linux/arch/x86/include/asm/asm.h:145:50: error: unknown register name 'esp' in asm
      register unsigned long current_stack_pointer asm(_ASM_SP);
                                                       ^
      /home/acme/git/linux/arch/x86/include/asm/asm.h:44:18: note: expanded from macro '_ASM_SP'
      #define _ASM_SP         __ASM_REG(sp)
                              ^
      /home/acme/git/linux/arch/x86/include/asm/asm.h:27:32: note: expanded from macro '__ASM_REG'
      #define __ASM_REG(reg)         __ASM_SEL_RAW(e##reg, r##reg)
                                     ^
      /home/acme/git/linux/arch/x86/include/asm/asm.h:18:29: note: expanded from macro '__ASM_SEL_RAW'
      # define __ASM_SEL_RAW(a,b) __ASM_FORM_RAW(a)
                                  ^
      /home/acme/git/linux/arch/x86/include/asm/asm.h:11:32: note: expanded from macro '__ASM_FORM_RAW'
      # define __ASM_FORM_RAW(x)     #x
                                     ^
      <scratch space>:4:1: note: expanded from here
      "esp"
      ^
      1 error generated.
      ERROR:        unable to compile -
      Hint: Check error message shown above.
      Hint: You can also pre-compile it into .o using:
                      clang -target bpf -O2 -c -
              with proper -I and -D options.
      Failed to compile test case: 'kbuild searching'
      test child finished with -1
      ---- end ----
      LLVM search and compile subtest 1: FAILED!
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Dmitriy Vyukov <dvyukov@google.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthias Kaehlcke <mka@chromium.org>
    Cc: Miguel Bernal Marin <miguel.bernal.marin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wang Nan <wangnan0@huawei.com>
    Cc: Yonghong Song <yhs@fb.com>
    Link: https://lkml.kernel.org/r/20171128175948.GL3298@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 219faaec51df..386a6900e206 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -136,6 +136,7 @@
 #endif
 
 #ifndef __ASSEMBLY__
+#ifndef __BPF__
 /*
  * This output constraint should be used for any inline asm which has a "call"
  * instruction.  Otherwise the asm may be inserted before the frame pointer
@@ -145,5 +146,6 @@
 register unsigned long current_stack_pointer asm(_ASM_SP);
 #define ASM_CALL_CONSTRAINT "+r" (current_stack_pointer)
 #endif
+#endif
 
 #endif /* _ASM_X86_ASM_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index b0dc91f4bedc..219faaec51df 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_ASM_H
 #define _ASM_X86_ASM_H
 

commit 196bd485ee4f03ce4c690bfcf38138abfcd0a4bc
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Fri Sep 29 17:15:36 2017 +0300

    x86/asm: Use register variable to get stack pointer value
    
    Currently we use current_stack_pointer() function to get the value
    of the stack pointer register. Since commit:
    
      f5caf621ee35 ("x86/asm: Fix inline asm call constraints for Clang")
    
    ... we have a stack register variable declared. It can be used instead of
    current_stack_pointer() function which allows to optimize away some
    excessive "mov %rsp, %<dst>" instructions:
    
     -mov    %rsp,%rdx
     -sub    %rdx,%rax
     -cmp    $0x3fff,%rax
     -ja     ffffffff810722fd <ist_begin_non_atomic+0x2d>
    
     +sub    %rsp,%rax
     +cmp    $0x3fff,%rax
     +ja     ffffffff810722fa <ist_begin_non_atomic+0x2a>
    
    Remove current_stack_pointer(), rename __asm_call_sp to current_stack_pointer
    and use it instead of the removed function.
    
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20170929141537.29167-1-aryabinin@virtuozzo.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 30c3c9ac784a..b0dc91f4bedc 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -141,8 +141,8 @@
  * gets set up by the containing function.  If you forget to do this, objtool
  * may print a "call without frame pointer save/setup" warning.
  */
-register unsigned long __asm_call_sp asm(_ASM_SP);
-#define ASM_CALL_CONSTRAINT "+r" (__asm_call_sp)
+register unsigned long current_stack_pointer asm(_ASM_SP);
+#define ASM_CALL_CONSTRAINT "+r" (current_stack_pointer)
 #endif
 
 #endif /* _ASM_X86_ASM_H */

commit 520a13c530aeb5f63e011d668c42db1af19ed349
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Thu Sep 28 16:58:26 2017 -0500

    x86/asm: Fix inline asm call constraints for GCC 4.4
    
    The kernel test bot (run by Xiaolong Ye) reported that the following commit:
    
      f5caf621ee35 ("x86/asm: Fix inline asm call constraints for Clang")
    
    is causing double faults in a kernel compiled with GCC 4.4.
    
    Linus subsequently diagnosed the crash pattern and the buggy commit and found that
    the issue is with this code:
    
      register unsigned int __asm_call_sp asm("esp");
      #define ASM_CALL_CONSTRAINT "+r" (__asm_call_sp)
    
    Even on a 64-bit kernel, it's using ESP instead of RSP.  That causes GCC
    to produce the following bogus code:
    
      ffffffff8147461d:       89 e0                   mov    %esp,%eax
      ffffffff8147461f:       4c 89 f7                mov    %r14,%rdi
      ffffffff81474622:       4c 89 fe                mov    %r15,%rsi
      ffffffff81474625:       ba 20 00 00 00          mov    $0x20,%edx
      ffffffff8147462a:       89 c4                   mov    %eax,%esp
      ffffffff8147462c:       e8 bf 52 05 00          callq  ffffffff814c98f0 <copy_user_generic_unrolled>
    
    Despite the absurdity of it backing up and restoring the stack pointer
    for no reason, the bug is actually the fact that it's only backing up
    and restoring the lower 32 bits of the stack pointer.  The upper 32 bits
    are getting cleared out, corrupting the stack pointer.
    
    So change the '__asm_call_sp' register variable to be associated with
    the actual full-size stack pointer.
    
    This also requires changing the __ASM_SEL() macro to be based on the
    actual compiled arch size, rather than the CONFIG value, because
    CONFIG_X86_64 compiles some files with '-m32' (e.g., realmode and vdso).
    Otherwise Clang fails to build the kernel because it complains about the
    use of a 64-bit register (RSP) in a 32-bit file.
    
    Reported-and-Bisected-and-Tested-by: kernel test robot <xiaolong.ye@intel.com>
    Diagnosed-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Dmitriy Vyukov <dvyukov@google.com>
    Cc: LKP <lkp@01.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthias Kaehlcke <mka@chromium.org>
    Cc: Miguel Bernal Marin <miguel.bernal.marin@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: f5caf621ee35 ("x86/asm: Fix inline asm call constraints for Clang")
    Link: http://lkml.kernel.org/r/20170928215826.6sdpmwtkiydiytim@treble
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index c1eadbaf1115..30c3c9ac784a 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -11,10 +11,12 @@
 # define __ASM_FORM_COMMA(x) " " #x ","
 #endif
 
-#ifdef CONFIG_X86_32
+#ifndef __x86_64__
+/* 32 bit */
 # define __ASM_SEL(a,b) __ASM_FORM(a)
 # define __ASM_SEL_RAW(a,b) __ASM_FORM_RAW(a)
 #else
+/* 64 bit */
 # define __ASM_SEL(a,b) __ASM_FORM(b)
 # define __ASM_SEL_RAW(a,b) __ASM_FORM_RAW(b)
 #endif
@@ -139,7 +141,7 @@
  * gets set up by the containing function.  If you forget to do this, objtool
  * may print a "call without frame pointer save/setup" warning.
  */
-register unsigned int __asm_call_sp asm("esp");
+register unsigned long __asm_call_sp asm(_ASM_SP);
 #define ASM_CALL_CONSTRAINT "+r" (__asm_call_sp)
 #endif
 

commit f5caf621ee357279e759c0911daf6d55c7d36f03
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Wed Sep 20 16:24:33 2017 -0500

    x86/asm: Fix inline asm call constraints for Clang
    
    For inline asm statements which have a CALL instruction, we list the
    stack pointer as a constraint to convince GCC to ensure the frame
    pointer is set up first:
    
      static inline void foo()
      {
            register void *__sp asm(_ASM_SP);
            asm("call bar" : "+r" (__sp))
      }
    
    Unfortunately, that pattern causes Clang to corrupt the stack pointer.
    
    The fix is easy: convert the stack pointer register variable to a global
    variable.
    
    It should be noted that the end result is different based on the GCC
    version.  With GCC 6.4, this patch has exactly the same result as
    before:
    
            defconfig       defconfig-nofp  distro          distro-nofp
     before 9820389         9491555         8816046         8516940
     after  9820389         9491555         8816046         8516940
    
    With GCC 7.2, however, GCC's behavior has changed.  It now changes its
    behavior based on the conversion of the register variable to a global.
    That somehow convinces it to *always* set up the frame pointer before
    inserting *any* inline asm.  (Therefore, listing the variable as an
    output constraint is a no-op and is no longer necessary.)  It's a bit
    overkill, but the performance impact should be negligible.  And in fact,
    there's a nice improvement with frame pointers disabled:
    
            defconfig       defconfig-nofp  distro          distro-nofp
     before 9796316         9468236         9076191         8790305
     after  9796957         9464267         9076381         8785949
    
    So in summary, while listing the stack pointer as an output constraint
    is no longer necessary for newer versions of GCC, it's still needed for
    older versions.
    
    Suggested-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reported-by: Matthias Kaehlcke <mka@chromium.org>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Dmitriy Vyukov <dvyukov@google.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Miguel Bernal Marin <miguel.bernal.marin@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/3db862e970c432ae823cf515c52b54fec8270e0e.1505942196.git.jpoimboe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 676ee5807d86..c1eadbaf1115 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -132,4 +132,15 @@
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 
+#ifndef __ASSEMBLY__
+/*
+ * This output constraint should be used for any inline asm which has a "call"
+ * instruction.  Otherwise the asm may be inserted before the frame pointer
+ * gets set up by the containing function.  If you forget to do this, objtool
+ * may print a "call without frame pointer save/setup" warning.
+ */
+register unsigned int __asm_call_sp asm("esp");
+#define ASM_CALL_CONSTRAINT "+r" (__asm_call_sp)
+#endif
+
 #endif /* _ASM_X86_ASM_H */

commit 7a46ec0e2f4850407de5e1d19a44edee6efa58ec
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Aug 15 09:19:24 2017 -0700

    locking/refcounts, x86/asm: Implement fast refcount overflow protection
    
    This implements refcount_t overflow protection on x86 without a noticeable
    performance impact, though without the fuller checking of REFCOUNT_FULL.
    
    This is done by duplicating the existing atomic_t refcount implementation
    but with normally a single instruction added to detect if the refcount
    has gone negative (e.g. wrapped past INT_MAX or below zero). When detected,
    the handler saturates the refcount_t to INT_MIN / 2. With this overflow
    protection, the erroneous reference release that would follow a wrap back
    to zero is blocked from happening, avoiding the class of refcount-overflow
    use-after-free vulnerabilities entirely.
    
    Only the overflow case of refcounting can be perfectly protected, since
    it can be detected and stopped before the reference is freed and left to
    be abused by an attacker. There isn't a way to block early decrements,
    and while REFCOUNT_FULL stops increment-from-zero cases (which would
    be the state _after_ an early decrement and stops potential double-free
    conditions), this fast implementation does not, since it would require
    the more expensive cmpxchg loops. Since the overflow case is much more
    common (e.g. missing a "put" during an error path), this protection
    provides real-world protection. For example, the two public refcount
    overflow use-after-free exploits published in 2016 would have been
    rendered unexploitable:
    
      http://perception-point.io/2016/01/14/analysis-and-exploitation-of-a-linux-kernel-vulnerability-cve-2016-0728/
    
      http://cyseclabs.com/page?n=02012016
    
    This implementation does, however, notice an unchecked decrement to zero
    (i.e. caller used refcount_dec() instead of refcount_dec_and_test() and it
    resulted in a zero). Decrements under zero are noticed (since they will
    have resulted in a negative value), though this only indicates that a
    use-after-free may have already happened. Such notifications are likely
    avoidable by an attacker that has already exploited a use-after-free
    vulnerability, but it's better to have them reported than allow such
    conditions to remain universally silent.
    
    On first overflow detection, the refcount value is reset to INT_MIN / 2
    (which serves as a saturation value) and a report and stack trace are
    produced. When operations detect only negative value results (such as
    changing an already saturated value), saturation still happens but no
    notification is performed (since the value was already saturated).
    
    On the matter of races, since the entire range beyond INT_MAX but before
    0 is negative, every operation at INT_MIN / 2 will trap, leaving no
    overflow-only race condition.
    
    As for performance, this implementation adds a single "js" instruction
    to the regular execution flow of a copy of the standard atomic_t refcount
    operations. (The non-"and_test" refcount_dec() function, which is uncommon
    in regular refcount design patterns, has an additional "jz" instruction
    to detect reaching exactly zero.) Since this is a forward jump, it is by
    default the non-predicted path, which will be reinforced by dynamic branch
    prediction. The result is this protection having virtually no measurable
    change in performance over standard atomic_t operations. The error path,
    located in .text.unlikely, saves the refcount location and then uses UD0
    to fire a refcount exception handler, which resets the refcount, handles
    reporting, and returns to regular execution. This keeps the changes to
    .text size minimal, avoiding return jumps and open-coded calls to the
    error reporting routine.
    
    Example assembly comparison:
    
    refcount_inc() before:
    
      .text:
      ffffffff81546149:       f0 ff 45 f4             lock incl -0xc(%rbp)
    
    refcount_inc() after:
    
      .text:
      ffffffff81546149:       f0 ff 45 f4             lock incl -0xc(%rbp)
      ffffffff8154614d:       0f 88 80 d5 17 00       js     ffffffff816c36d3
      ...
      .text.unlikely:
      ffffffff816c36d3:       48 8d 4d f4             lea    -0xc(%rbp),%rcx
      ffffffff816c36d7:       0f ff                   (bad)
    
    These are the cycle counts comparing a loop of refcount_inc() from 1
    to INT_MAX and back down to 0 (via refcount_dec_and_test()), between
    unprotected refcount_t (atomic_t), fully protected REFCOUNT_FULL
    (refcount_t-full), and this overflow-protected refcount (refcount_t-fast):
    
      2147483646 refcount_inc()s and 2147483647 refcount_dec_and_test()s:
                        cycles              protections
      atomic_t           82249267387        none
      refcount_t-fast    82211446892        overflow, untested dec-to-zero
      refcount_t-full   144814735193        overflow, untested dec-to-zero, inc-from-zero
    
    This code is a modified version of the x86 PAX_REFCOUNT atomic_t
    overflow defense from the last public patch of PaX/grsecurity, based
    on my understanding of the code. Changes or omissions from the original
    code are mine and don't reflect the original grsecurity/PaX code. Thanks
    to PaX Team for various suggestions for improvement for repurposing this
    code to be a refcount-only protection.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Elena Reshetova <elena.reshetova@intel.com>
    Cc: Eric Biggers <ebiggers3@gmail.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Hans Liljestrand <ishkamiel@gmail.com>
    Cc: James Bottomley <James.Bottomley@hansenpartnership.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Serge E. Hallyn <serge@hallyn.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: arozansk@redhat.com
    Cc: axboe@kernel.dk
    Cc: kernel-hardening@lists.openwall.com
    Cc: linux-arch <linux-arch@vger.kernel.org>
    Link: http://lkml.kernel.org/r/20170815161924.GA133115@beast
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 7a9df3beb89b..676ee5807d86 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -74,6 +74,9 @@
 # define _ASM_EXTABLE_EX(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
 
+# define _ASM_EXTABLE_REFCOUNT(from, to)			\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
+
 # define _ASM_NOKPROBE(entry)					\
 	.pushsection "_kprobe_blacklist","aw" ;			\
 	_ASM_ALIGN ;						\
@@ -123,6 +126,9 @@
 # define _ASM_EXTABLE_EX(from, to)				\
 	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
 
+# define _ASM_EXTABLE_REFCOUNT(from, to)			\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_refcount)
+
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 

commit 121843eb02a6e2fa30aefab64bfe183c97230c75
Author: Matthias Kaehlcke <mka@chromium.org>
Date:   Mon May 1 15:47:41 2017 -0700

    x86/mm/kaslr: Use the _ASM_MUL macro for multiplication to work around Clang incompatibility
    
    The constraint "rm" allows the compiler to put mix_const into memory.
    When the input operand is a memory location then MUL needs an operand
    size suffix, since Clang can't infer the multiplication width from the
    operand.
    
    Add and use the _ASM_MUL macro which determines the operand size and
    resolves to the NUL instruction with the corresponding suffix.
    
    This fixes the following error when building with clang:
    
      CC      arch/x86/lib/kaslr.o
      /tmp/kaslr-dfe1ad.s: Assembler messages:
      /tmp/kaslr-dfe1ad.s:182: Error: no instruction mnemonic suffix given and no register operands; can't size instruction
    
    Signed-off-by: Matthias Kaehlcke <mka@chromium.org>
    Cc: Grant Grundler <grundler@chromium.org>
    Cc: Greg Hackmann <ghackmann@google.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Davidson <md@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20170501224741.133938-1-mka@chromium.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 7acb51c49fec..7a9df3beb89b 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -32,6 +32,7 @@
 #define _ASM_ADD	__ASM_SIZE(add)
 #define _ASM_SUB	__ASM_SIZE(sub)
 #define _ASM_XADD	__ASM_SIZE(xadd)
+#define _ASM_MUL	__ASM_SIZE(mul)
 
 #define _ASM_AX		__ASM_REG(ax)
 #define _ASM_BX		__ASM_REG(bx)

commit ff3554b409b82d349f71e9d7082648b7b0a1a5bb
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Jun 8 12:38:40 2016 -0700

    x86, asm: define CC_SET() and CC_OUT() macros
    
    The CC_SET() and CC_OUT() macros can be used together to take
    advantage of the new __GCC_ASM_FLAG_OUTPUTS__ feature in gcc 6+ while
    remaining backwards compatible.  CC_SET() generates a SET instruction
    on older compilers; CC_OUT() makes sure the output is received in the
    correct variable.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Link: http://lkml.kernel.org/r/1465414726-197858-5-git-send-email-hpa@linux.intel.com
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index f5063b6659eb..7acb51c49fec 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -42,6 +42,18 @@
 #define _ASM_SI		__ASM_REG(si)
 #define _ASM_DI		__ASM_REG(di)
 
+/*
+ * Macros to generate condition code outputs from inline assembly,
+ * The output operand must be type "bool".
+ */
+#ifdef __GCC_ASM_FLAG_OUTPUTS__
+# define CC_SET(c) "\n\t/* output condition code " #c "*/\n"
+# define CC_OUT(c) "=@cc" #c
+#else
+# define CC_SET(c) "\n\tset" #c " %[_cc_" #c "]\n"
+# define CC_OUT(c) [_cc_ ## c] "=qm"
+#endif
+
 /* Exception table entry */
 #ifdef __ASSEMBLY__
 # define _ASM_EXTABLE_HANDLE(from, to, handler)			\

commit 548acf19234dbda5a52d5a8e7e205af46e9da840
Author: Tony Luck <tony.luck@intel.com>
Date:   Wed Feb 17 10:20:12 2016 -0800

    x86/mm: Expand the exception table logic to allow new handling options
    
    Huge amounts of help from  Andy Lutomirski and Borislav Petkov to
    produce this. Andy provided the inspiration to add classes to the
    exception table with a clever bit-squeezing trick, Boris pointed
    out how much cleaner it would all be if we just had a new field.
    
    Linus Torvalds blessed the expansion with:
    
      ' I'd rather not be clever in order to save just a tiny amount of space
        in the exception table, which isn't really criticial for anybody. '
    
    The third field is another relative function pointer, this one to a
    handler that executes the actions.
    
    We start out with three handlers:
    
     1: Legacy - just jumps the to fixup IP
     2: Fault - provide the trap number in %ax to the fixup code
     3: Cleaned up legacy for the uaccess error hack
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/f6af78fcbd348cf4939875cfda9c19689b5e50b8.1455732970.git.tony.luck@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 189679aba703..f5063b6659eb 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -44,19 +44,22 @@
 
 /* Exception table entry */
 #ifdef __ASSEMBLY__
-# define _ASM_EXTABLE(from,to)					\
+# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
 	.pushsection "__ex_table","a" ;				\
-	.balign 8 ;						\
+	.balign 4 ;						\
 	.long (from) - . ;					\
 	.long (to) - . ;					\
+	.long (handler) - . ;					\
 	.popsection
 
-# define _ASM_EXTABLE_EX(from,to)				\
-	.pushsection "__ex_table","a" ;				\
-	.balign 8 ;						\
-	.long (from) - . ;					\
-	.long (to) - . + 0x7ffffff0 ;				\
-	.popsection
+# define _ASM_EXTABLE(from, to)					\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
+
+# define _ASM_EXTABLE_FAULT(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
+
+# define _ASM_EXTABLE_EX(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
 
 # define _ASM_NOKPROBE(entry)					\
 	.pushsection "_kprobe_blacklist","aw" ;			\
@@ -89,19 +92,24 @@
 	.endm
 
 #else
-# define _ASM_EXTABLE(from,to)					\
+# define _EXPAND_EXTABLE_HANDLE(x) #x
+# define _ASM_EXTABLE_HANDLE(from, to, handler)			\
 	" .pushsection \"__ex_table\",\"a\"\n"			\
-	" .balign 8\n"						\
+	" .balign 4\n"						\
 	" .long (" #from ") - .\n"				\
 	" .long (" #to ") - .\n"				\
+	" .long (" _EXPAND_EXTABLE_HANDLE(handler) ") - .\n"	\
 	" .popsection\n"
 
-# define _ASM_EXTABLE_EX(from,to)				\
-	" .pushsection \"__ex_table\",\"a\"\n"			\
-	" .balign 8\n"						\
-	" .long (" #from ") - .\n"				\
-	" .long (" #to ") - . + 0x7ffffff0\n"			\
-	" .popsection\n"
+# define _ASM_EXTABLE(from, to)					\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_default)
+
+# define _ASM_EXTABLE_FAULT(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_fault)
+
+# define _ASM_EXTABLE_EX(from, to)				\
+	_ASM_EXTABLE_HANDLE(from, to, ex_handler_ext)
+
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 

commit 9e6b13f761d5914a8c9b83610e8d459653515c94
Author: Borislav Petkov <bp@suse.de>
Date:   Wed May 13 19:42:23 2015 +0200

    x86/asm/uaccess: Unify the ALIGN_DESTINATION macro
    
    Pull it up into the header and kill duplicate versions.
    Separately, both macros are identical:
    
     35948b2bd3431aee7149e85cfe4becbc  /tmp/a
     35948b2bd3431aee7149e85cfe4becbc  /tmp/b
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1431538944-27724-3-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 7730c1c5c83a..189679aba703 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -63,6 +63,31 @@
 	_ASM_ALIGN ;						\
 	_ASM_PTR (entry);					\
 	.popsection
+
+.macro ALIGN_DESTINATION
+	/* check for bad alignment of destination */
+	movl %edi,%ecx
+	andl $7,%ecx
+	jz 102f				/* already aligned */
+	subl $8,%ecx
+	negl %ecx
+	subl %ecx,%edx
+100:	movb (%rsi),%al
+101:	movb %al,(%rdi)
+	incq %rsi
+	incq %rdi
+	decl %ecx
+	jnz 100b
+102:
+	.section .fixup,"ax"
+103:	addl %ecx,%edx			/* ecx is zerorest also */
+	jmp copy_user_handle_tail
+	.previous
+
+	_ASM_EXTABLE(100b,103b)
+	_ASM_EXTABLE(101b,103b)
+	.endm
+
 #else
 # define _ASM_EXTABLE(from,to)					\
 	" .pushsection \"__ex_table\",\"a\"\n"			\

commit 376e242429bf8539ef39a080ac113c8799840b13
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Thu Apr 17 17:17:05 2014 +0900

    kprobes: Introduce NOKPROBE_SYMBOL() macro to maintain kprobes blacklist
    
    Introduce NOKPROBE_SYMBOL() macro which builds a kprobes
    blacklist at kernel build time.
    
    The usage of this macro is similar to EXPORT_SYMBOL(),
    placed after the function definition:
    
      NOKPROBE_SYMBOL(function);
    
    Since this macro will inhibit inlining of static/inline
    functions, this patch also introduces a nokprobe_inline macro
    for static/inline functions. In this case, we must use
    NOKPROBE_SYMBOL() for the inline function caller.
    
    When CONFIG_KPROBES=y, the macro stores the given function
    address in the "_kprobe_blacklist" section.
    
    Since the data structures are not fully initialized by the
    macro (because there is no "size" information),  those
    are re-initialized at boot time by using kallsyms.
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Link: http://lkml.kernel.org/r/20140417081705.26341.96719.stgit@ltc230.yrl.intra.hitachi.co.jp
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Christopher Li <sparse@chrisli.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Jan-Simon Möller <dl9pf@gmx.de>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-sparse@vger.kernel.org
    Cc: virtualization@lists.linux-foundation.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 4582e8e1cd1a..7730c1c5c83a 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -57,6 +57,12 @@
 	.long (from) - . ;					\
 	.long (to) - . + 0x7ffffff0 ;				\
 	.popsection
+
+# define _ASM_NOKPROBE(entry)					\
+	.pushsection "_kprobe_blacklist","aw" ;			\
+	_ASM_ALIGN ;						\
+	_ASM_PTR (entry);					\
+	.popsection
 #else
 # define _ASM_EXTABLE(from,to)					\
 	" .pushsection \"__ex_table\",\"a\"\n"			\
@@ -71,6 +77,7 @@
 	" .long (" #from ") - .\n"				\
 	" .long (" #to ") - . + 0x7ffffff0\n"			\
 	" .popsection\n"
+/* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 
 #endif /* _ASM_X86_ASM_H */

commit 3e9b2327b59801e677a7581fe4d2541ca749dcab
Author: Jan-Simon Möller <dl9pf@gmx.de>
Date:   Thu Aug 29 21:13:04 2013 +0200

    x86, asm: Extend definitions of _ASM_* with a raw format
    
    The __ASM_* macros (e.g. __ASM_DX) are used to return the proper
    register name (e.g. edx for 32bit / rdx for 64bit). We want to use
    this also in arch/x86/include/asm/uaccess.h / get_user() .  For this
    to work, we need a raw form as both gcc and clang choke on the
    whitespace in a register asm() statement, and the __ASM_FORM macro
    surrounds the argument with blanks.  A new macro, __ASM_FORM_RAW was
    added and we change __ASM_REG to use the new RAW form.
    
    Signed-off-by: Jan-Simon Möller <dl9pf@gmx.de>
    Link: http://lkml.kernel.org/r/1377803585-5913-2-git-send-email-dl9pf@gmx.de
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 1c2d247f65ce..4582e8e1cd1a 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -3,21 +3,25 @@
 
 #ifdef __ASSEMBLY__
 # define __ASM_FORM(x)	x
+# define __ASM_FORM_RAW(x)     x
 # define __ASM_FORM_COMMA(x) x,
 #else
 # define __ASM_FORM(x)	" " #x " "
+# define __ASM_FORM_RAW(x)     #x
 # define __ASM_FORM_COMMA(x) " " #x ","
 #endif
 
 #ifdef CONFIG_X86_32
 # define __ASM_SEL(a,b) __ASM_FORM(a)
+# define __ASM_SEL_RAW(a,b) __ASM_FORM_RAW(a)
 #else
 # define __ASM_SEL(a,b) __ASM_FORM(b)
+# define __ASM_SEL_RAW(a,b) __ASM_FORM_RAW(b)
 #endif
 
 #define __ASM_SIZE(inst, ...)	__ASM_SEL(inst##l##__VA_ARGS__, \
 					  inst##q##__VA_ARGS__)
-#define __ASM_REG(reg)		__ASM_SEL(e##reg, r##reg)
+#define __ASM_REG(reg)         __ASM_SEL_RAW(e##reg, r##reg)
 
 #define _ASM_PTR	__ASM_SEL(.long, .quad)
 #define _ASM_ALIGN	__ASM_SEL(.balign 4, .balign 8)

commit 706276543b699d80f546e45f8b12574e7b18d952
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Fri Apr 20 17:12:48 2012 -0700

    x86, extable: Switch to relative exception table entries
    
    Switch to using relative exception table entries on x86.  On i386,
    this has the advantage that the exception table entries don't need to
    be relocated; on x86-64 this means the exception table entries take up
    only half the space.
    
    In either case, a 32-bit delta is sufficient, as the range of kernel
    code addresses is limited.
    
    Since part of the goal is to avoid needing to adjust the entries when
    the kernel is relocated, the old trick of using addresses in the NULL
    pointer range to indicate uaccess_err no longer works (and unlike RISC
    architectures we can't use a flag bit); instead use an delta just
    below +2G to indicate these special entries.  The reach is still
    limited to a single instruction.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/CA%2B55aFyijf43qSu3N9nWHEBwaGbb7T2Oq9A=9EyR=Jtyqfq_cQ@mail.gmail.com

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 0f15e8a4f565..1c2d247f65ce 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -42,26 +42,30 @@
 #ifdef __ASSEMBLY__
 # define _ASM_EXTABLE(from,to)					\
 	.pushsection "__ex_table","a" ;				\
-	_ASM_ALIGN ;						\
-	_ASM_PTR from , to ;					\
+	.balign 8 ;						\
+	.long (from) - . ;					\
+	.long (to) - . ;					\
 	.popsection
 
 # define _ASM_EXTABLE_EX(from,to)				\
 	.pushsection "__ex_table","a" ;				\
-	_ASM_ALIGN ;						\
-	_ASM_PTR from , (to) - (from) ;				\
+	.balign 8 ;						\
+	.long (from) - . ;					\
+	.long (to) - . + 0x7ffffff0 ;				\
 	.popsection
 #else
 # define _ASM_EXTABLE(from,to)					\
 	" .pushsection \"__ex_table\",\"a\"\n"			\
-	_ASM_ALIGN "\n" 					\
-	_ASM_PTR #from "," #to "\n" 				\
+	" .balign 8\n"						\
+	" .long (" #from ") - .\n"				\
+	" .long (" #to ") - .\n"				\
 	" .popsection\n"
 
 # define _ASM_EXTABLE_EX(from,to)				\
 	" .pushsection \"__ex_table\",\"a\"\n"			\
-	_ASM_ALIGN "\n" 					\
-	_ASM_PTR #from ",(" #to ")-(" #from ")\n" 		\
+	" .balign 8\n"						\
+	" .long (" #from ") - .\n"				\
+	" .long (" #to ") - . + 0x7ffffff0\n"			\
 	" .popsection\n"
 #endif
 

commit 535c0c34698061544f81a51c65fc51f4eeeebff6
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Fri Apr 20 16:57:35 2012 -0700

    x86, extable: Add _ASM_EXTABLE_EX() macro
    
    Add _ASM_EXTABLE_EX() to generate the special extable entries that are
    associated with uaccess_err.  This allows us to change the protocol
    associated with these special entries.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/CA%2B55aFyijf43qSu3N9nWHEBwaGbb7T2Oq9A=9EyR=Jtyqfq_cQ@mail.gmail.com

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 53dce41f2517..0f15e8a4f565 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -40,16 +40,28 @@
 
 /* Exception table entry */
 #ifdef __ASSEMBLY__
-# define _ASM_EXTABLE(from,to)			\
-	.pushsection "__ex_table","a" ;		\
-	_ASM_ALIGN ;				\
-	_ASM_PTR from , to ;			\
+# define _ASM_EXTABLE(from,to)					\
+	.pushsection "__ex_table","a" ;				\
+	_ASM_ALIGN ;						\
+	_ASM_PTR from , to ;					\
+	.popsection
+
+# define _ASM_EXTABLE_EX(from,to)				\
+	.pushsection "__ex_table","a" ;				\
+	_ASM_ALIGN ;						\
+	_ASM_PTR from , (to) - (from) ;				\
 	.popsection
 #else
-# define _ASM_EXTABLE(from,to)			\
-	" .pushsection \"__ex_table\",\"a\"\n"	\
-	_ASM_ALIGN "\n" 			\
-	_ASM_PTR #from "," #to "\n" 		\
+# define _ASM_EXTABLE(from,to)					\
+	" .pushsection \"__ex_table\",\"a\"\n"			\
+	_ASM_ALIGN "\n" 					\
+	_ASM_PTR #from "," #to "\n" 				\
+	" .popsection\n"
+
+# define _ASM_EXTABLE_EX(from,to)				\
+	" .pushsection \"__ex_table\",\"a\"\n"			\
+	_ASM_ALIGN "\n" 					\
+	_ASM_PTR #from ",(" #to ")-(" #from ")\n" 		\
 	" .popsection\n"
 #endif
 

commit 447657e31235c692f579c639250317c7f565cd0d
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Fri Apr 20 12:20:30 2012 -0700

    x86, extable: Remove the now-unused __ASM_EX_SEC macros
    
    Nothing should use them anymore; only _ASM_EXTABLE() should ever be
    used.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/CA%2B55aFyijf43qSu3N9nWHEBwaGbb7T2Oq9A=9EyR=Jtyqfq_cQ@mail.gmail.com

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index ff3f6bffcbf9..53dce41f2517 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -4,11 +4,9 @@
 #ifdef __ASSEMBLY__
 # define __ASM_FORM(x)	x
 # define __ASM_FORM_COMMA(x) x,
-# define __ASM_EX_SEC	.section __ex_table, "a"
 #else
 # define __ASM_FORM(x)	" " #x " "
 # define __ASM_FORM_COMMA(x) " " #x ","
-# define __ASM_EX_SEC	" .section __ex_table,\"a\"\n"
 #endif
 
 #ifdef CONFIG_X86_32

commit d4541805e812abb5110d5de83246488fa0aa9a8e
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Fri Apr 20 12:12:27 2012 -0700

    x86, extable: Use .pushsection ... .popsection for _ASM_EXTABLE()
    
    Instead of using .section ... .previous, use .pushsection
    ... .popsection; this is (hopefully) a bit more robust, especially in
    complex assembly code.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/CA%2B55aFyijf43qSu3N9nWHEBwaGbb7T2Oq9A=9EyR=Jtyqfq_cQ@mail.gmail.com

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 9412d6558c88..ff3f6bffcbf9 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -42,17 +42,17 @@
 
 /* Exception table entry */
 #ifdef __ASSEMBLY__
-# define _ASM_EXTABLE(from,to)	    \
-	__ASM_EX_SEC ;		    \
-	_ASM_ALIGN ;		    \
-	_ASM_PTR from , to ;	    \
-	.previous
+# define _ASM_EXTABLE(from,to)			\
+	.pushsection "__ex_table","a" ;		\
+	_ASM_ALIGN ;				\
+	_ASM_PTR from , to ;			\
+	.popsection
 #else
-# define _ASM_EXTABLE(from,to) \
-	__ASM_EX_SEC	\
-	_ASM_ALIGN "\n" \
-	_ASM_PTR #from "," #to "\n" \
-	" .previous\n"
+# define _ASM_EXTABLE(from,to)			\
+	" .pushsection \"__ex_table\",\"a\"\n"	\
+	_ASM_ALIGN "\n" 			\
+	_ASM_PTR #from "," #to "\n" 		\
+	" .popsection\n"
 #endif
 
 #endif /* _ASM_X86_ASM_H */

commit a750036f35cda160ef77408ec92c3dc41f8feebb
Author: Jan Beulich <JBeulich@novell.com>
Date:   Tue Jul 19 13:00:45 2011 +0100

    x86: Fix write lock scalability 64-bit issue
    
    With the write lock path simply subtracting RW_LOCK_BIAS there
    is, on large systems, the theoretical possibility of overflowing
    the 32-bit value that was used so far (namely if 128 or more
    CPUs manage to do the subtraction, but don't get to do the
    inverse addition in the failure path quickly enough).
    
    A first measure is to modify RW_LOCK_BIAS itself - with the new
    value chosen, it is good for up to 2048 CPUs each allowed to
    nest over 2048 times on the read path without causing an issue.
    Quite possibly it would even be sufficient to adjust the bias a
    little further, assuming that allowing for significantly less
    nesting would suffice.
    
    However, as the original value chosen allowed for even more
    nesting levels, to support more than 2048 CPUs (possible
    currently only for 64-bit kernels) the lock itself gets widened
    to 64 bits.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/4E258E0D020000780004E3F0@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 5890beb021c4..9412d6558c88 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -3,9 +3,11 @@
 
 #ifdef __ASSEMBLY__
 # define __ASM_FORM(x)	x
+# define __ASM_FORM_COMMA(x) x,
 # define __ASM_EX_SEC	.section __ex_table, "a"
 #else
 # define __ASM_FORM(x)	" " #x " "
+# define __ASM_FORM_COMMA(x) " " #x ","
 # define __ASM_EX_SEC	" .section __ex_table,\"a\"\n"
 #endif
 

commit 4625cd637919edfb562e0d62abf94f52e9321335
Author: Jan Beulich <JBeulich@novell.com>
Date:   Tue Jul 19 12:59:51 2011 +0100

    x86: Unify rwlock assembly implementation
    
    Rather than having two functionally identical implementations
    for 32- and 64-bit configurations, extend the existing assembly
    abstractions enough to fold the two rwlock implementations into
    a shared one.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/4E258DD7020000780004E3EA@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index b3ed1e1460ff..5890beb021c4 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -15,7 +15,8 @@
 # define __ASM_SEL(a,b) __ASM_FORM(b)
 #endif
 
-#define __ASM_SIZE(inst)	__ASM_SEL(inst##l, inst##q)
+#define __ASM_SIZE(inst, ...)	__ASM_SEL(inst##l##__VA_ARGS__, \
+					  inst##q##__VA_ARGS__)
 #define __ASM_REG(reg)		__ASM_SEL(e##reg, r##reg)
 
 #define _ASM_PTR	__ASM_SEL(.long, .quad)

commit 709972b1f6f70535d1fddbe1243a51b90c408a1c
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Mon Aug 31 11:57:20 2009 -0700

    x86, asm: Make _ASM_EXTABLE() usable from assembly code
    
    We have had this convenient macro _ASM_EXTABLE() to generate exception
    table entry in inline assembly.  Make it also usable for pure
    assembly.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index 56be78f582f0..b3ed1e1460ff 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -3,7 +3,7 @@
 
 #ifdef __ASSEMBLY__
 # define __ASM_FORM(x)	x
-# define __ASM_EX_SEC	.section __ex_table
+# define __ASM_EX_SEC	.section __ex_table, "a"
 #else
 # define __ASM_FORM(x)	" " #x " "
 # define __ASM_EX_SEC	" .section __ex_table,\"a\"\n"
@@ -38,10 +38,18 @@
 #define _ASM_DI		__ASM_REG(di)
 
 /* Exception table entry */
+#ifdef __ASSEMBLY__
+# define _ASM_EXTABLE(from,to)	    \
+	__ASM_EX_SEC ;		    \
+	_ASM_ALIGN ;		    \
+	_ASM_PTR from , to ;	    \
+	.previous
+#else
 # define _ASM_EXTABLE(from,to) \
 	__ASM_EX_SEC	\
 	_ASM_ALIGN "\n" \
 	_ASM_PTR #from "," #to "\n" \
 	" .previous\n"
+#endif
 
 #endif /* _ASM_X86_ASM_H */

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
index e1355f44d7c3..56be78f582f0 100644
--- a/arch/x86/include/asm/asm.h
+++ b/arch/x86/include/asm/asm.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__ASM_H
-#define ASM_X86__ASM_H
+#ifndef _ASM_X86_ASM_H
+#define _ASM_X86_ASM_H
 
 #ifdef __ASSEMBLY__
 # define __ASM_FORM(x)	x
@@ -44,4 +44,4 @@
 	_ASM_PTR #from "," #to "\n" \
 	" .previous\n"
 
-#endif /* ASM_X86__ASM_H */
+#endif /* _ASM_X86_ASM_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h
new file mode 100644
index 000000000000..e1355f44d7c3
--- /dev/null
+++ b/arch/x86/include/asm/asm.h
@@ -0,0 +1,47 @@
+#ifndef ASM_X86__ASM_H
+#define ASM_X86__ASM_H
+
+#ifdef __ASSEMBLY__
+# define __ASM_FORM(x)	x
+# define __ASM_EX_SEC	.section __ex_table
+#else
+# define __ASM_FORM(x)	" " #x " "
+# define __ASM_EX_SEC	" .section __ex_table,\"a\"\n"
+#endif
+
+#ifdef CONFIG_X86_32
+# define __ASM_SEL(a,b) __ASM_FORM(a)
+#else
+# define __ASM_SEL(a,b) __ASM_FORM(b)
+#endif
+
+#define __ASM_SIZE(inst)	__ASM_SEL(inst##l, inst##q)
+#define __ASM_REG(reg)		__ASM_SEL(e##reg, r##reg)
+
+#define _ASM_PTR	__ASM_SEL(.long, .quad)
+#define _ASM_ALIGN	__ASM_SEL(.balign 4, .balign 8)
+
+#define _ASM_MOV	__ASM_SIZE(mov)
+#define _ASM_INC	__ASM_SIZE(inc)
+#define _ASM_DEC	__ASM_SIZE(dec)
+#define _ASM_ADD	__ASM_SIZE(add)
+#define _ASM_SUB	__ASM_SIZE(sub)
+#define _ASM_XADD	__ASM_SIZE(xadd)
+
+#define _ASM_AX		__ASM_REG(ax)
+#define _ASM_BX		__ASM_REG(bx)
+#define _ASM_CX		__ASM_REG(cx)
+#define _ASM_DX		__ASM_REG(dx)
+#define _ASM_SP		__ASM_REG(sp)
+#define _ASM_BP		__ASM_REG(bp)
+#define _ASM_SI		__ASM_REG(si)
+#define _ASM_DI		__ASM_REG(di)
+
+/* Exception table entry */
+# define _ASM_EXTABLE(from,to) \
+	__ASM_EX_SEC	\
+	_ASM_ALIGN "\n" \
+	_ASM_PTR #from "," #to "\n" \
+	" .previous\n"
+
+#endif /* ASM_X86__ASM_H */
