commit 931b94145981e411bd2c934657649347ba8a9083
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 21 22:05:23 2020 +0200

    x86/entry: Provide helpers for executing on the irqstack
    
    Device interrupt handlers and system vector handlers are executed on the
    interrupt stack. The stack switch happens in the low level assembly entry
    code. This conflicts with the efforts to consolidate the exit code in C to
    ensure correctness vs. RCU and tracing.
    
    As there is no way to move #DB away from IST due to the MOV SS issue, the
    requirements vs. #DB and NMI for switching to the interrupt stack do not
    exist anymore. The only requirement is that interrupts are disabled.
    
    That allows the moving of the stack switching to C code, which simplifies the
    entry/exit handling further, because it allows the switching of stacks after
    handling the entry and on exit before handling RCU, returning to usermode and
    kernel preemption in the same way as for regular exceptions.
    
    The initial attempt of having the stack switching in inline ASM caused too
    much headache vs. objtool and the unwinder. After analysing the use cases
    it was agreed on that having the stack switch in ASM for the price of an
    indirect call is acceptable, as the main users are indirect call heavy
    anyway and the few system vectors which are empty shells (scheduler IPI and
    KVM posted interrupt vectors) can run from the regular stack.
    
    Provide helper functions to check whether the interrupt stack is already
    active and whether stack switching is required.
    
    64-bit only for now, as 32-bit has a variant of that already. Once this is
    cleaned up, the two implementations might be consolidated as an additional
    cleanup on top.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20200521202117.763775313@linutronix.de

diff --git a/arch/x86/include/asm/irq_stack.h b/arch/x86/include/asm/irq_stack.h
new file mode 100644
index 000000000000..4ae66f097101
--- /dev/null
+++ b/arch/x86/include/asm/irq_stack.h
@@ -0,0 +1,53 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_X86_IRQ_STACK_H
+#define _ASM_X86_IRQ_STACK_H
+
+#include <linux/ptrace.h>
+
+#include <asm/processor.h>
+
+#ifdef CONFIG_X86_64
+static __always_inline bool irqstack_active(void)
+{
+	return __this_cpu_read(irq_count) != -1;
+}
+
+void asm_call_on_stack(void *sp, void *func, void *arg);
+
+static __always_inline void __run_on_irqstack(void *func, void *arg)
+{
+	void *tos = __this_cpu_read(hardirq_stack_ptr);
+
+	__this_cpu_add(irq_count, 1);
+	asm_call_on_stack(tos - 8, func, arg);
+	__this_cpu_sub(irq_count, 1);
+}
+
+#else /* CONFIG_X86_64 */
+static inline bool irqstack_active(void) { return false; }
+static inline void __run_on_irqstack(void *func, void *arg) { }
+#endif /* !CONFIG_X86_64 */
+
+static __always_inline bool irq_needs_irq_stack(struct pt_regs *regs)
+{
+	if (IS_ENABLED(CONFIG_X86_32))
+		return false;
+	if (!regs)
+		return !irqstack_active();
+	return !user_mode(regs) && !irqstack_active();
+}
+
+static __always_inline void run_on_irqstack_cond(void *func, void *arg,
+						 struct pt_regs *regs)
+{
+	void (*__func)(void *arg) = func;
+
+	lockdep_assert_irqs_disabled();
+
+	if (irq_needs_irq_stack(regs))
+		__run_on_irqstack(__func, arg);
+	else
+		__func(arg);
+}
+
+#endif
