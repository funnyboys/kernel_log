commit 090e77e166334b83f555de408df64b9ab394ea08
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:48:18 2020 -0700

    kmap: consolidate kmap_prot definitions
    
    Most architectures define kmap_prot to be PAGE_KERNEL.
    
    Let sparc and xtensa define there own and define PAGE_KERNEL as the
    default if not overridden.
    
    [akpm@linux-foundation.org: coding style fixes]
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-16-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 28183ee3cc42..b9527a54db99 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -152,7 +152,6 @@ extern void reserve_top_address(unsigned long reserve);
 extern int fixmaps_set;
 
 extern pte_t *kmap_pte;
-#define kmap_prot PAGE_KERNEL
 extern pte_t *pkmap_page_table;
 
 void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);

commit f53e2cd0b8ab7d9e390414470bdbd830f660133f
Author: Sami Tolvanen <samitolvanen@google.com>
Date:   Fri Sep 13 14:14:02 2019 -0700

    x86/mm: Use the correct function type for native_set_fixmap()
    
    We call native_set_fixmap indirectly through the function pointer
    struct pv_mmu_ops::set_fixmap, which expects the first parameter to be
    'unsigned' instead of 'enum fixed_addresses'. This patch changes the
    function type for native_set_fixmap to match the pointer, which fixes
    indirect call mismatches with Control-Flow Integrity (CFI) checking.
    
    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H . Peter Anvin <hpa@zytor.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190913211402.193018-1-samitolvanen@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 0c47aa82e2e2..28183ee3cc42 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -156,7 +156,7 @@ extern pte_t *kmap_pte;
 extern pte_t *pkmap_page_table;
 
 void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
-void native_set_fixmap(enum fixed_addresses idx,
+void native_set_fixmap(unsigned /* enum fixed_addresses */ idx,
 		       phys_addr_t phys, pgprot_t flags);
 
 #ifndef CONFIG_PARAVIRT_XXL

commit c84b82dd3e593db217f23c60f7edae02c76a3c4c
Author: Cao jin <caoj.fnst@cn.fujitsu.com>
Date:   Fri Aug 9 19:46:12 2019 +0800

    x86/fixmap: Cleanup outdated comments
    
    Remove stale comments and fix the not longer valid pagetable entry
    reference.
    
    Signed-off-by: Cao jin <caoj.fnst@cn.fujitsu.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190809114612.2569-1-caoj.fnst@cn.fujitsu.com

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 9da8cccdf3fb..0c47aa82e2e2 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -42,8 +42,7 @@
  * Because of this, FIXADDR_TOP x86 integration was left as later work.
  */
 #ifdef CONFIG_X86_32
-/* used by vmalloc.c, vsyscall.lds.S.
- *
+/*
  * Leave one empty page between vmalloc'ed areas and
  * the start of the fixmap.
  */
@@ -120,7 +119,7 @@ enum fixed_addresses {
 	 * before ioremap() is functional.
 	 *
 	 * If necessary we round it up to the next 512 pages boundary so
-	 * that we can have a single pgd entry and a single pte table:
+	 * that we can have a single pmd entry and a single pte table:
 	 */
 #define NR_FIX_BTMAPS		64
 #define FIX_BTMAPS_SLOTS	8

commit b3fd8e83ada0d51b71a84297480187e2d40e5ded
Author: Nadav Amit <namit@vmware.com>
Date:   Thu Apr 25 17:11:27 2019 -0700

    x86/alternatives: Use temporary mm for text poking
    
    text_poke() can potentially compromise security as it sets temporary
    PTEs in the fixmap. These PTEs might be used to rewrite the kernel code
    from other cores accidentally or maliciously, if an attacker gains the
    ability to write onto kernel memory.
    
    Moreover, since remote TLBs are not flushed after the temporary PTEs are
    removed, the time-window in which the code is writable is not limited if
    the fixmap PTEs - maliciously or accidentally - are cached in the TLB.
    To address these potential security hazards, use a temporary mm for
    patching the code.
    
    Finally, text_poke() is also not conservative enough when mapping pages,
    as it always tries to map 2 pages, even when a single one is sufficient.
    So try to be more conservative, and do not map more than needed.
    
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Signed-off-by: Rick Edgecombe <rick.p.edgecombe@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <akpm@linux-foundation.org>
    Cc: <ard.biesheuvel@linaro.org>
    Cc: <deneen.t.dock@intel.com>
    Cc: <kernel-hardening@lists.openwall.com>
    Cc: <kristen@linux.intel.com>
    Cc: <linux_dti@icloud.com>
    Cc: <will.deacon@arm.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190426001143.4983-8-namit@vmware.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 50ba74a34a37..9da8cccdf3fb 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -103,8 +103,6 @@ enum fixed_addresses {
 #ifdef CONFIG_PARAVIRT
 	FIX_PARAVIRT_BOOTMAP,
 #endif
-	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
-	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
 #ifdef	CONFIG_X86_INTEL_MID
 	FIX_LNW_VRTC,
 #endif

commit f682a7920baf7b721d01dd317f3b532265357cbb
Merge: 99792e0cea1e 3a025de64bf8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 23 17:54:58 2018 +0100

    Merge branch 'x86-paravirt-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 paravirt updates from Ingo Molnar:
     "Two main changes:
    
       - Remove no longer used parts of the paravirt infrastructure and put
         large quantities of paravirt ops under a new config option
         PARAVIRT_XXL=y, which is selected by XEN_PV only. (Joergen Gross)
    
       - Enable PV spinlocks on Hyperv (Yi Sun)"
    
    * 'x86-paravirt-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/hyperv: Enable PV qspinlock for Hyper-V
      x86/hyperv: Add GUEST_IDLE_MSR support
      x86/paravirt: Clean up native_patch()
      x86/paravirt: Prevent redefinition of SAVE_FLAGS macro
      x86/xen: Make xen_reservation_lock static
      x86/paravirt: Remove unneeded mmu related paravirt ops bits
      x86/paravirt: Move the Xen-only pv_mmu_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move the pv_irq_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move the Xen-only pv_cpu_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move items in pv_info under PARAVIRT_XXL umbrella
      x86/paravirt: Introduce new config option PARAVIRT_XXL
      x86/paravirt: Remove unused paravirt bits
      x86/paravirt: Use a single ops structure
      x86/paravirt: Remove clobbers from struct paravirt_patch_site
      x86/paravirt: Remove clobbers parameter from paravirt patch functions
      x86/paravirt: Make paravirt_patch_call() and paravirt_patch_jmp() static
      x86/xen: Add SPDX identifier in arch/x86/xen files
      x86/xen: Link platform-pci-unplug.o only if CONFIG_XEN_PVHVM
      x86/xen: Move pv specific parts of arch/x86/xen/mmu.c to mmu_pv.c
      x86/xen: Move pv irq related functions under CONFIG_XEN_PV umbrella

commit 05ab1d8a4b36ee912b7087c6da127439ed0a903e
Author: Feng Tang <feng.tang@intel.com>
Date:   Thu Sep 20 10:58:28 2018 +0800

    x86/mm: Expand static page table for fixmap space
    
    We met a kernel panic when enabling earlycon, which is due to the fixmap
    address of earlycon is not statically setup.
    
    Currently the static fixmap setup in head_64.S only covers 2M virtual
    address space, while it actually could be in 4M space with different
    kernel configurations, e.g. when VSYSCALL emulation is disabled.
    
    So increase the static space to 4M for now by defining FIXMAP_PMD_NUM to 2,
    and add a build time check to ensure that the fixmap is covered by the
    initial static page tables.
    
    Fixes: 1ad83c858c7d ("x86_64,vsyscall: Make vsyscall emulation configurable")
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: kernel test robot <rong.a.chen@intel.com>
    Reviewed-by: Juergen Gross <jgross@suse.com> (Xen parts)
    Cc: H Peter Anvin <hpa@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20180920025828.23699-1-feng.tang@intel.com

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index e203169931c7..6390bd8c141b 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -14,6 +14,16 @@
 #ifndef _ASM_X86_FIXMAP_H
 #define _ASM_X86_FIXMAP_H
 
+/*
+ * Exposed to assembly code for setting up initial page tables. Cannot be
+ * calculated in assembly code (fixmap entries are an enum), but is sanity
+ * checked in the actual fixmap C code to make sure that the fixmap is
+ * covered fully.
+ */
+#define FIXMAP_PMD_NUM	2
+/* fixmap starts downwards from the 507th entry in level2_fixmap_pgt */
+#define FIXMAP_PMD_TOP	507
+
 #ifndef __ASSEMBLY__
 #include <linux/kernel.h>
 #include <asm/acpi.h>

commit fdc0269e8958a1ec95b8ac685c1d372c24c60faa
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:25 2018 +0200

    x86/paravirt: Move the Xen-only pv_mmu_ops under the PARAVIRT_XXL umbrella
    
    Most of the paravirt ops defined in pv_mmu_ops are for Xen PV guests
    only. Define them only if CONFIG_PARAVIRT_XXL is set.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-15-jgross@suse.com

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index e203169931c7..ac80e7eadc3a 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -152,7 +152,7 @@ void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
 void native_set_fixmap(enum fixed_addresses idx,
 		       phys_addr_t phys, pgprot_t flags);
 
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_XXL
 static inline void __set_fixmap(enum fixed_addresses idx,
 				phys_addr_t phys, pgprot_t flags)
 {

commit 55f49fcb879fbeebf2a8c1ac7c9e6d90df55f798
Author: William Grant <william.grant@canonical.com>
Date:   Tue Jan 30 22:22:55 2018 +1100

    x86/mm: Fix overlap of i386 CPU_ENTRY_AREA with FIX_BTMAP
    
    Since commit 92a0f81d8957 ("x86/cpu_entry_area: Move it out of the
    fixmap"), i386's CPU_ENTRY_AREA has been mapped to the memory area just
    below FIXADDR_START. But already immediately before FIXADDR_START is the
    FIX_BTMAP area, which means that early_ioremap can collide with the entry
    area.
    
    It's especially bad on PAE where FIX_BTMAP_BEGIN gets aligned to exactly
    match CPU_ENTRY_AREA_BASE, so the first early_ioremap slot clobbers the
    IDT and causes interrupts during early boot to reset the system.
    
    The overlap wasn't a problem before the CPU entry area was introduced,
    as the fixmap has classically been preceded by the pkmap or vmalloc
    areas, neither of which is used until early_ioremap is out of the
    picture.
    
    Relocate CPU_ENTRY_AREA to below FIX_BTMAP, not just below the permanent
    fixmap area.
    
    Fixes: commit 92a0f81d8957 ("x86/cpu_entry_area: Move it out of the fixmap")
    Signed-off-by: William Grant <william.grant@canonical.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/7041d181-a019-e8b9-4e4e-48215f841e2c@canonical.com

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 64c4a30e0d39..e203169931c7 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -137,8 +137,10 @@ enum fixed_addresses {
 
 extern void reserve_top_address(unsigned long reserve);
 
-#define FIXADDR_SIZE	(__end_of_permanent_fixed_addresses << PAGE_SHIFT)
-#define FIXADDR_START	(FIXADDR_TOP - FIXADDR_SIZE)
+#define FIXADDR_SIZE		(__end_of_permanent_fixed_addresses << PAGE_SHIFT)
+#define FIXADDR_START		(FIXADDR_TOP - FIXADDR_SIZE)
+#define FIXADDR_TOT_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
+#define FIXADDR_TOT_START	(FIXADDR_TOP - FIXADDR_TOT_SIZE)
 
 extern int fixmaps_set;
 

commit 92a0f81d89571e3e8759366e050ee05cc545ef99
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 20 18:51:31 2017 +0100

    x86/cpu_entry_area: Move it out of the fixmap
    
    Put the cpu_entry_area into a separate P4D entry. The fixmap gets too big
    and 0-day already hit a case where the fixmap PTEs were cleared by
    cleanup_highmap().
    
    Aside of that the fixmap API is a pain as it's all backwards.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index fb801662a230..64c4a30e0d39 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -25,7 +25,6 @@
 #else
 #include <uapi/asm/vsyscall.h>
 #endif
-#include <asm/cpu_entry_area.h>
 
 /*
  * We can't declare FIXADDR_TOP as variable for x86_64 because vsyscall
@@ -84,7 +83,6 @@ enum fixed_addresses {
 	FIX_IO_APIC_BASE_0,
 	FIX_IO_APIC_BASE_END = FIX_IO_APIC_BASE_0 + MAX_IO_APICS - 1,
 #endif
-	FIX_RO_IDT,	/* Virtual mapping for read-only IDT */
 #ifdef CONFIG_X86_32
 	FIX_KMAP_BEGIN,	/* reserved pte's for temporary kernel mappings */
 	FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,
@@ -100,9 +98,6 @@ enum fixed_addresses {
 #ifdef	CONFIG_X86_INTEL_MID
 	FIX_LNW_VRTC,
 #endif
-	/* Fixmap entries to remap the GDTs, one per processor. */
-	FIX_CPU_ENTRY_AREA_TOP,
-	FIX_CPU_ENTRY_AREA_BOTTOM = FIX_CPU_ENTRY_AREA_TOP + (CPU_ENTRY_AREA_PAGES * NR_CPUS) - 1,
 
 #ifdef CONFIG_ACPI_APEI_GHES
 	/* Used for GHES mapping from assorted contexts */
@@ -143,7 +138,7 @@ enum fixed_addresses {
 extern void reserve_top_address(unsigned long reserve);
 
 #define FIXADDR_SIZE	(__end_of_permanent_fixed_addresses << PAGE_SHIFT)
-#define FIXADDR_START		(FIXADDR_TOP - FIXADDR_SIZE)
+#define FIXADDR_START	(FIXADDR_TOP - FIXADDR_SIZE)
 
 extern int fixmaps_set;
 
@@ -191,30 +186,5 @@ void __init *early_memremap_decrypted_wp(resource_size_t phys_addr,
 void __early_set_fixmap(enum fixed_addresses idx,
 			phys_addr_t phys, pgprot_t flags);
 
-static inline unsigned int __get_cpu_entry_area_page_index(int cpu, int page)
-{
-	BUILD_BUG_ON(sizeof(struct cpu_entry_area) % PAGE_SIZE != 0);
-
-	return FIX_CPU_ENTRY_AREA_BOTTOM - cpu*CPU_ENTRY_AREA_PAGES - page;
-}
-
-#define __get_cpu_entry_area_offset_index(cpu, offset) ({		\
-	BUILD_BUG_ON(offset % PAGE_SIZE != 0);				\
-	__get_cpu_entry_area_page_index(cpu, offset / PAGE_SIZE);	\
-	})
-
-#define get_cpu_entry_area_index(cpu, field)				\
-	__get_cpu_entry_area_offset_index((cpu), offsetof(struct cpu_entry_area, field))
-
-static inline struct cpu_entry_area *get_cpu_entry_area(int cpu)
-{
-	return (struct cpu_entry_area *)__fix_to_virt(__get_cpu_entry_area_page_index(cpu, 0));
-}
-
-static inline struct entry_stack *cpu_entry_stack(int cpu)
-{
-	return &get_cpu_entry_area(cpu)->entry_stack_page.stack;
-}
-
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit ed1bbc40a0d10e0c5c74fe7bdc6298295cf40255
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 20 18:28:54 2017 +0100

    x86/cpu_entry_area: Move it to a separate unit
    
    Separate the cpu_entry_area code out of cpu/common.c and the fixmap.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 8153b8d86a3c..fb801662a230 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -25,6 +25,7 @@
 #else
 #include <uapi/asm/vsyscall.h>
 #endif
+#include <asm/cpu_entry_area.h>
 
 /*
  * We can't declare FIXADDR_TOP as variable for x86_64 because vsyscall
@@ -44,46 +45,6 @@ extern unsigned long __FIXADDR_TOP;
 			 PAGE_SIZE)
 #endif
 
-/*
- * cpu_entry_area is a percpu region in the fixmap that contains things
- * needed by the CPU and early entry/exit code.  Real types aren't used
- * for all fields here to avoid circular header dependencies.
- *
- * Every field is a virtual alias of some other allocated backing store.
- * There is no direct allocation of a struct cpu_entry_area.
- */
-struct cpu_entry_area {
-	char gdt[PAGE_SIZE];
-
-	/*
-	 * The GDT is just below entry_stack and thus serves (on x86_64) as
-	 * a a read-only guard page.
-	 */
-	struct entry_stack_page entry_stack_page;
-
-	/*
-	 * On x86_64, the TSS is mapped RO.  On x86_32, it's mapped RW because
-	 * we need task switches to work, and task switches write to the TSS.
-	 */
-	struct tss_struct tss;
-
-	char entry_trampoline[PAGE_SIZE];
-
-#ifdef CONFIG_X86_64
-	/*
-	 * Exception stacks used for IST entries.
-	 *
-	 * In the future, this should have a separate slot for each stack
-	 * with guard pages between them.
-	 */
-	char exception_stacks[(N_EXCEPTION_STACKS - 1) * EXCEPTION_STKSZ + DEBUG_STKSZ];
-#endif
-};
-
-#define CPU_ENTRY_AREA_PAGES (sizeof(struct cpu_entry_area) / PAGE_SIZE)
-
-extern void setup_cpu_entry_areas(void);
-
 /*
  * Here we define all the compile-time 'special' virtual
  * addresses. The point is to have a constant address at

commit 4fe2d8b11a370af286287a2661de9d4e6c9a145a
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Mon Dec 4 17:25:07 2017 -0800

    x86/entry: Rename SYSENTER_stack to CPU_ENTRY_AREA_entry_stack
    
    If the kernel oopses while on the trampoline stack, it will print
    "<SYSENTER>" even if SYSENTER is not involved.  That is rather confusing.
    
    The "SYSENTER" stack is used for a lot more than SYSENTER now.  Give it a
    better string to display in stack dumps, and rename the kernel code to
    match.
    
    Also move the 32-bit code over to the new naming even though it still uses
    the entry stack only for SYSENTER.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 94fc4fa14127..8153b8d86a3c 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -56,10 +56,10 @@ struct cpu_entry_area {
 	char gdt[PAGE_SIZE];
 
 	/*
-	 * The GDT is just below SYSENTER_stack and thus serves (on x86_64) as
+	 * The GDT is just below entry_stack and thus serves (on x86_64) as
 	 * a a read-only guard page.
 	 */
-	struct SYSENTER_stack_page SYSENTER_stack_page;
+	struct entry_stack_page entry_stack_page;
 
 	/*
 	 * On x86_64, the TSS is mapped RO.  On x86_32, it's mapped RW because
@@ -250,9 +250,9 @@ static inline struct cpu_entry_area *get_cpu_entry_area(int cpu)
 	return (struct cpu_entry_area *)__fix_to_virt(__get_cpu_entry_area_page_index(cpu, 0));
 }
 
-static inline struct SYSENTER_stack *cpu_SYSENTER_stack(int cpu)
+static inline struct entry_stack *cpu_entry_stack(int cpu)
 {
-	return &get_cpu_entry_area(cpu)->SYSENTER_stack_page.stack;
+	return &get_cpu_entry_area(cpu)->entry_stack_page.stack;
 }
 
 #endif /* !__ASSEMBLY__ */

commit c482feefe1aeb150156248ba0fd3e029bc886605
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:29 2017 +0100

    x86/entry/64: Make cpu_entry_area.tss read-only
    
    The TSS is a fairly juicy target for exploits, and, now that the TSS
    is in the cpu_entry_area, it's no longer protected by kASLR.  Make it
    read-only on x86_64.
    
    On x86_32, it can't be RO because it's written by the CPU during task
    switches, and we use a task gate for double faults.  I'd also be
    nervous about errata if we tried to make it RO even on configurations
    without double fault handling.
    
    [ tglx: AMD confirmed that there is no problem on 64-bit with TSS RO.  So
            it's probably safe to assume that it's a non issue, though Intel
            might have been creative in that area. Still waiting for
            confirmation. ]
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bpetkov@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150606.733700132@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index cc5d98bdca37..94fc4fa14127 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -56,9 +56,14 @@ struct cpu_entry_area {
 	char gdt[PAGE_SIZE];
 
 	/*
-	 * The GDT is just below cpu_tss and thus serves (on x86_64) as a
-	 * a read-only guard page for the SYSENTER stack at the bottom
-	 * of the TSS region.
+	 * The GDT is just below SYSENTER_stack and thus serves (on x86_64) as
+	 * a a read-only guard page.
+	 */
+	struct SYSENTER_stack_page SYSENTER_stack_page;
+
+	/*
+	 * On x86_64, the TSS is mapped RO.  On x86_32, it's mapped RW because
+	 * we need task switches to work, and task switches write to the TSS.
 	 */
 	struct tss_struct tss;
 
@@ -247,7 +252,7 @@ static inline struct cpu_entry_area *get_cpu_entry_area(int cpu)
 
 static inline struct SYSENTER_stack *cpu_SYSENTER_stack(int cpu)
 {
-	return &get_cpu_entry_area(cpu)->tss.SYSENTER_stack;
+	return &get_cpu_entry_area(cpu)->SYSENTER_stack_page.stack;
 }
 
 #endif /* !__ASSEMBLY__ */

commit 0f9a48100fba3f189724ae88a450c2261bf91c80
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:28 2017 +0100

    x86/entry: Clean up the SYSENTER_stack code
    
    The existing code was a mess, mainly because C arrays are nasty.  Turn
    SYSENTER_stack into a struct, add a helper to find it, and do all the
    obvious cleanups this enables.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bpetkov@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150606.653244723@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 451da7d9a502..cc5d98bdca37 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -245,5 +245,10 @@ static inline struct cpu_entry_area *get_cpu_entry_area(int cpu)
 	return (struct cpu_entry_area *)__fix_to_virt(__get_cpu_entry_area_page_index(cpu, 0));
 }
 
+static inline struct SYSENTER_stack *cpu_SYSENTER_stack(int cpu)
+{
+	return &get_cpu_entry_area(cpu)->tss.SYSENTER_stack;
+}
+
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit 40e7f949e0d9a33968ebde5d67f7e3a47c97742a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:26 2017 +0100

    x86/entry/64: Move the IST stacks into struct cpu_entry_area
    
    The IST stacks are needed when an IST exception occurs and are accessed
    before any kernel code at all runs.  Move them into struct cpu_entry_area.
    
    The IST stacks are unlike the rest of cpu_entry_area: they're used even for
    entries from kernel mode.  This means that they should be set up before we
    load the final IDT.  Move cpu_entry_area setup to trap_init() for the boot
    CPU and set it up for all possible CPUs at once in native_smp_prepare_cpus().
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150606.480598743@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 6a699474c2c7..451da7d9a502 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -63,10 +63,22 @@ struct cpu_entry_area {
 	struct tss_struct tss;
 
 	char entry_trampoline[PAGE_SIZE];
+
+#ifdef CONFIG_X86_64
+	/*
+	 * Exception stacks used for IST entries.
+	 *
+	 * In the future, this should have a separate slot for each stack
+	 * with guard pages between them.
+	 */
+	char exception_stacks[(N_EXCEPTION_STACKS - 1) * EXCEPTION_STKSZ + DEBUG_STKSZ];
+#endif
 };
 
 #define CPU_ENTRY_AREA_PAGES (sizeof(struct cpu_entry_area) / PAGE_SIZE)
 
+extern void setup_cpu_entry_areas(void);
+
 /*
  * Here we define all the compile-time 'special' virtual
  * addresses. The point is to have a constant address at

commit 3386bc8aed825e9f1f65ce38df4b109b2019b71a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:25 2017 +0100

    x86/entry/64: Create a per-CPU SYSCALL entry trampoline
    
    Handling SYSCALL is tricky: the SYSCALL handler is entered with every
    single register (except FLAGS), including RSP, live.  It somehow needs
    to set RSP to point to a valid stack, which means it needs to save the
    user RSP somewhere and find its own stack pointer.  The canonical way
    to do this is with SWAPGS, which lets us access percpu data using the
    %gs prefix.
    
    With PAGE_TABLE_ISOLATION-like pagetable switching, this is
    problematic.  Without a scratch register, switching CR3 is impossible, so
    %gs-based percpu memory would need to be mapped in the user pagetables.
    Doing that without information leaks is difficult or impossible.
    
    Instead, use a different sneaky trick.  Map a copy of the first part
    of the SYSCALL asm at a different address for each CPU.  Now RIP
    varies depending on the CPU, so we can use RIP-relative memory access
    to access percpu memory.  By putting the relevant information (one
    scratch slot and the stack address) at a constant offset relative to
    RIP, we can make SYSCALL work without relying on %gs.
    
    A nice thing about this approach is that we can easily switch it on
    and off if we want pagetable switching to be configurable.
    
    The compat variant of SYSCALL doesn't have this problem in the first
    place -- there are plenty of scratch registers, since we don't care
    about preserving r8-r15.  This patch therefore doesn't touch SYSCALL32
    at all.
    
    This patch actually seems to be a small speedup.  With this patch,
    SYSCALL touches an extra cache line and an extra virtual page, but
    the pipeline no longer stalls waiting for SWAPGS.  It seems that, at
    least in a tight loop, the latter outweights the former.
    
    Thanks to David Laight for an optimization tip.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bpetkov@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150606.403607157@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 84558b611ad3..6a699474c2c7 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -61,6 +61,8 @@ struct cpu_entry_area {
 	 * of the TSS region.
 	 */
 	struct tss_struct tss;
+
+	char entry_trampoline[PAGE_SIZE];
 };
 
 #define CPU_ENTRY_AREA_PAGES (sizeof(struct cpu_entry_area) / PAGE_SIZE)

commit 72f5e08dbba2d01aa90b592cf76c378ea233b00b
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:20 2017 +0100

    x86/entry: Remap the TSS into the CPU entry area
    
    This has a secondary purpose: it puts the entry stack into a region
    with a well-controlled layout.  A subsequent patch will take
    advantage of this to streamline the SYSCALL entry code to be able to
    find it more easily.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bpetkov@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150605.962042855@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index b61f0242f9d0..84558b611ad3 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -54,6 +54,13 @@ extern unsigned long __FIXADDR_TOP;
  */
 struct cpu_entry_area {
 	char gdt[PAGE_SIZE];
+
+	/*
+	 * The GDT is just below cpu_tss and thus serves (on x86_64) as a
+	 * a read-only guard page for the SYSENTER stack at the bottom
+	 * of the TSS region.
+	 */
+	struct tss_struct tss;
 };
 
 #define CPU_ENTRY_AREA_PAGES (sizeof(struct cpu_entry_area) / PAGE_SIZE)

commit ef8813ab280507972bb57e4b1b502811ad4411e9
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Dec 4 15:07:15 2017 +0100

    x86/mm/fixmap: Generalize the GDT fixmap mechanism, introduce struct cpu_entry_area
    
    Currently, the GDT is an ad-hoc array of pages, one per CPU, in the
    fixmap.  Generalize it to be an array of a new 'struct cpu_entry_area'
    so that we can cleanly add new things to it.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Laight <David.Laight@aculab.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eduardo Valentin <eduval@amazon.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: aliguori@amazon.com
    Cc: daniel.gruss@iaik.tugraz.at
    Cc: hughd@google.com
    Cc: keescook@google.com
    Link: https://lkml.kernel.org/r/20171204150605.563271721@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index b0c505fe9a95..b61f0242f9d0 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -44,6 +44,19 @@ extern unsigned long __FIXADDR_TOP;
 			 PAGE_SIZE)
 #endif
 
+/*
+ * cpu_entry_area is a percpu region in the fixmap that contains things
+ * needed by the CPU and early entry/exit code.  Real types aren't used
+ * for all fields here to avoid circular header dependencies.
+ *
+ * Every field is a virtual alias of some other allocated backing store.
+ * There is no direct allocation of a struct cpu_entry_area.
+ */
+struct cpu_entry_area {
+	char gdt[PAGE_SIZE];
+};
+
+#define CPU_ENTRY_AREA_PAGES (sizeof(struct cpu_entry_area) / PAGE_SIZE)
 
 /*
  * Here we define all the compile-time 'special' virtual
@@ -101,8 +114,8 @@ enum fixed_addresses {
 	FIX_LNW_VRTC,
 #endif
 	/* Fixmap entries to remap the GDTs, one per processor. */
-	FIX_GDT_REMAP_BEGIN,
-	FIX_GDT_REMAP_END = FIX_GDT_REMAP_BEGIN + NR_CPUS - 1,
+	FIX_CPU_ENTRY_AREA_TOP,
+	FIX_CPU_ENTRY_AREA_BOTTOM = FIX_CPU_ENTRY_AREA_TOP + (CPU_ENTRY_AREA_PAGES * NR_CPUS) - 1,
 
 #ifdef CONFIG_ACPI_APEI_GHES
 	/* Used for GHES mapping from assorted contexts */
@@ -191,5 +204,25 @@ void __init *early_memremap_decrypted_wp(resource_size_t phys_addr,
 void __early_set_fixmap(enum fixed_addresses idx,
 			phys_addr_t phys, pgprot_t flags);
 
+static inline unsigned int __get_cpu_entry_area_page_index(int cpu, int page)
+{
+	BUILD_BUG_ON(sizeof(struct cpu_entry_area) % PAGE_SIZE != 0);
+
+	return FIX_CPU_ENTRY_AREA_BOTTOM - cpu*CPU_ENTRY_AREA_PAGES - page;
+}
+
+#define __get_cpu_entry_area_offset_index(cpu, offset) ({		\
+	BUILD_BUG_ON(offset % PAGE_SIZE != 0);				\
+	__get_cpu_entry_area_page_index(cpu, offset / PAGE_SIZE);	\
+	})
+
+#define get_cpu_entry_area_index(cpu, field)				\
+	__get_cpu_entry_area_offset_index((cpu), offsetof(struct cpu_entry_area, field))
+
+static inline struct cpu_entry_area *get_cpu_entry_area(int cpu)
+{
+	return (struct cpu_entry_area *)__fix_to_virt(__get_cpu_entry_area_page_index(cpu, 0));
+}
+
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit 4f89fa286f6729312e227e7c2d764e8e7b9d340e
Author: James Morse <james.morse@arm.com>
Date:   Mon Nov 6 18:44:24 2017 +0000

    ACPI / APEI: Replace ioremap_page_range() with fixmap
    
    Replace ghes_io{re,un}map_pfn_{nmi,irq}()s use of ioremap_page_range()
    with __set_fixmap() as ioremap_page_range() may sleep to allocate a new
    level of page-table, even if its passed an existing final-address to
    use in the mapping.
    
    The GHES driver can only be enabled for architectures that select
    HAVE_ACPI_APEI: Add fixmap entries to both x86 and arm64.
    
    clear_fixmap() does the TLB invalidation in __set_fixmap() for arm64
    and __set_pte_vaddr() for x86. In each case its the same as the
    respective arch_apei_flush_tlb_one().
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Tested-by: Tyler Baicar <tbaicar@codeaurora.org>
    Tested-by: Toshi Kani <toshi.kani@hpe.com>
    [ For the arm64 bits: ]
    Acked-by: Will Deacon <will.deacon@arm.com>
    [ For the x86 bits: ]
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: All applicable <stable@vger.kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index dcd9fb55e679..b0c505fe9a95 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -104,6 +104,12 @@ enum fixed_addresses {
 	FIX_GDT_REMAP_BEGIN,
 	FIX_GDT_REMAP_END = FIX_GDT_REMAP_BEGIN + NR_CPUS - 1,
 
+#ifdef CONFIG_ACPI_APEI_GHES
+	/* Used for GHES mapping from assorted contexts */
+	FIX_APEI_GHES_IRQ,
+	FIX_APEI_GHES_NMI,
+#endif
+
 	__end_of_permanent_fixed_addresses,
 
 	/*

commit f88a68facd9a15b94f8c195d9d2c0b30c76c595a
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:09 2017 -0500

    x86/mm: Extend early_memremap() support with additional attrs
    
    Add early_memremap() support to be able to specify encrypted and
    decrypted mappings with and without write-protection. The use of
    write-protection is necessary when encrypting data "in place". The
    write-protect attribute is considered cacheable for loads, but not
    stores. This implies that the hardware will never give the core a
    dirty line with this memtype.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/479b5832c30fae3efa7932e48f81794e86397229.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index d9ff226cb489..dcd9fb55e679 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -164,6 +164,19 @@ static inline void __set_fixmap(enum fixed_addresses idx,
  */
 #define FIXMAP_PAGE_NOCACHE PAGE_KERNEL_IO_NOCACHE
 
+/*
+ * Early memremap routines used for in-place encryption. The mappings created
+ * by these routines are intended to be used as temporary mappings.
+ */
+void __init *early_memremap_encrypted(resource_size_t phys_addr,
+				      unsigned long size);
+void __init *early_memremap_encrypted_wp(resource_size_t phys_addr,
+					 unsigned long size);
+void __init *early_memremap_decrypted(resource_size_t phys_addr,
+				      unsigned long size);
+void __init *early_memremap_decrypted_wp(resource_size_t phys_addr,
+					 unsigned long size);
+
 #include <asm-generic/fixmap.h>
 
 #define __late_set_fixmap(idx, phys, flags) __set_fixmap(idx, phys, flags)

commit 21729f81ce8ae76a6995681d40e16f7ce8075db4
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:07 2017 -0500

    x86/mm: Provide general kernel support for memory encryption
    
    Changes to the existing page table macros will allow the SME support to
    be enabled in a simple fashion with minimal changes to files that use these
    macros.  Since the memory encryption mask will now be part of the regular
    pagetable macros, we introduce two new macros (_PAGE_TABLE_NOENC and
    _KERNPG_TABLE_NOENC) to allow for early pagetable creation/initialization
    without the encryption mask before SME becomes active.  Two new pgprot()
    macros are defined to allow setting or clearing the page encryption mask.
    
    The FIXMAP_PAGE_NOCACHE define is introduced for use with MMIO.  SME does
    not support encryption for MMIO areas so this define removes the encryption
    mask from the page attribute.
    
    Two new macros are introduced (__sme_pa() / __sme_pa_nodebug()) to allow
    creating a physical address with the encryption mask.  These are used when
    working with the cr3 register so that the PGD can be encrypted. The current
    __va() macro is updated so that the virtual address is generated based off
    of the physical address without the encryption mask thus allowing the same
    virtual address to be generated regardless of whether encryption is enabled
    for that physical location or not.
    
    Also, an early initialization function is added for SME.  If SME is active,
    this function:
    
     - Updates the early_pmd_flags so that early page faults create mappings
       with the encryption mask.
    
     - Updates the __supported_pte_mask to include the encryption mask.
    
     - Updates the protection_map entries to include the encryption mask so
       that user-space allocations will automatically have the encryption mask
       applied.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/b36e952c4c39767ae7f0a41cf5345adf27438480.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index b65155cc3760..d9ff226cb489 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -157,6 +157,13 @@ static inline void __set_fixmap(enum fixed_addresses idx,
 }
 #endif
 
+/*
+ * FIXMAP_PAGE_NOCACHE is used for MMIO. Memory encryption is not
+ * supported for MMIO addresses, so make sure that the memory encryption
+ * mask is not part of the page attributes.
+ */
+#define FIXMAP_PAGE_NOCACHE PAGE_KERNEL_IO_NOCACHE
+
 #include <asm-generic/fixmap.h>
 
 #define __late_set_fixmap(idx, phys, flags) __set_fixmap(idx, phys, flags)

commit 69218e47994da614e7af600bf06887750ab6657a
Author: Thomas Garnier <thgarnie@google.com>
Date:   Tue Mar 14 10:05:07 2017 -0700

    x86: Remap GDT tables in the fixmap section
    
    Each processor holds a GDT in its per-cpu structure. The sgdt
    instruction gives the base address of the current GDT. This address can
    be used to bypass KASLR memory randomization. With another bug, an
    attacker could target other per-cpu structures or deduce the base of
    the main memory section (PAGE_OFFSET).
    
    This patch relocates the GDT table for each processor inside the
    fixmap section. The space is reserved based on number of supported
    processors.
    
    For consistency, the remapping is done by default on 32 and 64-bit.
    
    Each processor switches to its remapped GDT at the end of
    initialization. For hibernation, the main processor returns with the
    original GDT and switches back to the remapping at completion.
    
    This patch was tested on both architectures. Hibernation and KVM were
    both tested specially for their usage of the GDT.
    
    Thanks to Boris Ostrovsky <boris.ostrovsky@oracle.com> for testing and
    recommending changes for Xen support.
    
    Signed-off-by: Thomas Garnier <thgarnie@google.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Kosina <jikos@kernel.org>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Lorenzo Stoakes <lstoakes@gmail.com>
    Cc: Luis R . Rodriguez <mcgrof@kernel.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rafael J . Wysocki <rjw@rjwysocki.net>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kernel-hardening@lists.openwall.com
    Cc: kvm@vger.kernel.org
    Cc: lguest@lists.ozlabs.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: linux-pm@vger.kernel.org
    Cc: xen-devel@lists.xenproject.org
    Cc: zijun_hu <zijun_hu@htc.com>
    Link: http://lkml.kernel.org/r/20170314170508.100882-2-thgarnie@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 8554f960e21b..b65155cc3760 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -100,6 +100,10 @@ enum fixed_addresses {
 #ifdef	CONFIG_X86_INTEL_MID
 	FIX_LNW_VRTC,
 #endif
+	/* Fixmap entries to remap the GDTs, one per processor. */
+	FIX_GDT_REMAP_BEGIN,
+	FIX_GDT_REMAP_END = FIX_GDT_REMAP_BEGIN + NR_CPUS - 1,
+
 	__end_of_permanent_fixed_addresses,
 
 	/*

commit 7c360572b430a0e9757bafc0c20f26c920f2a07f
Author: Andy Lutomirski <luto@kernel.org>
Date:   Tue Jan 19 13:38:59 2016 -0800

    x86/mm: Make kmap_prot into a #define
    
    The value (once we initialize it) is a foregone conclusion.
    Make it a #define to save a tiny amount of text and data size
    and to make it more comprehensible.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/0850eb0213de9da88544ff7fae72dc6d06d2b441.1453239349.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 6d7d0e52ed5a..8554f960e21b 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -138,7 +138,7 @@ extern void reserve_top_address(unsigned long reserve);
 extern int fixmaps_set;
 
 extern pte_t *kmap_pte;
-extern pgprot_t kmap_prot;
+#define kmap_prot PAGE_KERNEL
 extern pte_t *pkmap_page_table;
 
 void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);

commit cc1e24fdb064d3126a494716f22ad4fc39306742
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Dec 10 19:20:21 2015 -0800

    x86/vdso: Remove pvclock fixmap machinery
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/4933029991103ae44672c82b97a20035f5c1fe4f.1449702533.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index f80d70009ff8..6d7d0e52ed5a 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -19,7 +19,6 @@
 #include <asm/acpi.h>
 #include <asm/apicdef.h>
 #include <asm/page.h>
-#include <asm/pvclock.h>
 #ifdef CONFIG_X86_32
 #include <linux/threads.h>
 #include <asm/kmap_types.h>
@@ -72,10 +71,6 @@ enum fixed_addresses {
 #ifdef CONFIG_X86_VSYSCALL_EMULATION
 	VSYSCALL_PAGE = (FIXADDR_TOP - VSYSCALL_ADDR) >> PAGE_SHIFT,
 #endif
-#ifdef CONFIG_PARAVIRT_CLOCK
-	PVCLOCK_FIXMAP_BEGIN,
-	PVCLOCK_FIXMAP_END = PVCLOCK_FIXMAP_BEGIN+PVCLOCK_VSYSCALL_NR_PAGES-1,
-#endif
 #endif
 	FIX_DBGP_BASE,
 	FIX_EARLYCON_MEM_BASE,

commit 3100e448e7d74489a96cb7b45d88fe6962774eaa
Merge: c9f861c77269 26893107aa71
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 10 14:24:20 2014 -0800

    Merge branch 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 vdso updates from Ingo Molnar:
     "Various vDSO updates from Andy Lutomirski, mostly cleanups and
      reorganization to improve maintainability, but also some
      micro-optimizations and robustization changes"
    
    * 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86_64/vsyscall: Restore orig_ax after vsyscall seccomp
      x86_64: Add a comment explaining the TASK_SIZE_MAX guard page
      x86_64,vsyscall: Make vsyscall emulation configurable
      x86_64, vsyscall: Rewrite comment and clean up headers in vsyscall code
      x86_64, vsyscall: Turn vsyscalls all the way off when vsyscall==none
      x86,vdso: Use LSL unconditionally for vgetcpu
      x86: vdso: Fix build with older gcc
      x86_64/vdso: Clean up vgetcpu init and merge the vdso initcalls
      x86_64/vdso: Remove jiffies from the vvar page
      x86/vdso: Make the PER_CPU segment 32 bits
      x86/vdso: Make the PER_CPU segment start out accessed
      x86/vdso: Change the PER_CPU segment to use struct desc_struct
      x86_64/vdso: Move getcpu code from vsyscall_64.c to vdso/vma.c
      x86_64/vsyscall: Move all of the gate_area code to vsyscall_64.c

commit 1ad83c858c7d4ea210429142c99a1548e6715a35
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Wed Oct 29 14:33:47 2014 -0700

    x86_64,vsyscall: Make vsyscall emulation configurable
    
    This adds CONFIG_X86_VSYSCALL_EMULATION, guarded by CONFIG_EXPERT.
    Turning it off completely disables vsyscall emulation, saving ~3.5k
    for vsyscall_64.c, 4k for vsyscall_emu_64.S (the fake vsyscall
    page), some tiny amount of core mm code that supports a gate area,
    and possibly 4k for a wasted pagetable.  The latter is because the
    vsyscall addresses are misaligned and fit poorly in the fixmap.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Link: http://lkml.kernel.org/r/406db88b8dd5f0cbbf38216d11be34bbb43c7eae.1414618407.git.luto@amacapital.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index ffb1733ac91f..d8d5bcb2a0b5 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -69,7 +69,9 @@ enum fixed_addresses {
 #ifdef CONFIG_X86_32
 	FIX_HOLE,
 #else
+#ifdef CONFIG_X86_VSYSCALL_EMULATION
 	VSYSCALL_PAGE = (FIXADDR_TOP - VSYSCALL_ADDR) >> PAGE_SHIFT,
+#endif
 #ifdef CONFIG_PARAVIRT_CLOCK
 	PVCLOCK_FIXMAP_BEGIN,
 	PVCLOCK_FIXMAP_END = PVCLOCK_FIXMAP_BEGIN+PVCLOCK_VSYSCALL_NR_PAGES-1,

commit 63e7b6d90c1ebdb73d82eedb945b62ceedc3f963
Author: Minfei Huang <mnfhuang@gmail.com>
Date:   Wed Oct 29 19:38:37 2014 +0800

    x86: mm: Re-use the early_ioremap fixed area
    
    The temp fixed area is only used during boot for early_ioremap(), and
    it is unused when ioremap() is functional. vmalloc/pkmap area become
    available after early boot so the temp fixed area is available for
    re-use.
    
    The virtual address is more precious on i386, especially turning on
    high memory. So we can re-use the virtual address space.
    
    Remove the now unused defines FIXADDR_BOOT_START and FIXADDR_BOOT_SIZE.
    
    Signed-off-by: Minfei Huang <mnfhuang@gmail.com>
    Cc: pbonzini@redhat.com
    Cc: bp@suse.de
    Link: http://lkml.kernel.org/r/1414582717-32729-1-git-send-email-mnfhuang@gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index ffb1733ac91f..bf728e49c53c 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -136,9 +136,7 @@ enum fixed_addresses {
 extern void reserve_top_address(unsigned long reserve);
 
 #define FIXADDR_SIZE	(__end_of_permanent_fixed_addresses << PAGE_SHIFT)
-#define FIXADDR_BOOT_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
 #define FIXADDR_START		(FIXADDR_TOP - FIXADDR_SIZE)
-#define FIXADDR_BOOT_START	(FIXADDR_TOP - FIXADDR_BOOT_SIZE)
 
 extern int fixmaps_set;
 

commit 3eddc69ffeba092d288c386646bfa5ec0fce25fd
Author: Dave Young <dyoung@redhat.com>
Date:   Tue Aug 26 17:06:41 2014 +0800

    x86 early_ioremap: Increase FIX_BTMAPS_SLOTS to 8
    
    3.16 kernel boot fail with earlyprintk=efi, it keeps scrolling at the
    bottom line of screen.
    
    Bisected, the first bad commit is below:
    commit 86dfc6f339886559d80ee0d4bd20fe5ee90450f0
    Author: Lv Zheng <lv.zheng@intel.com>
    Date:   Fri Apr 4 12:38:57 2014 +0800
    
        ACPICA: Tables: Fix table checksums verification before installation.
    
    I did some debugging by enabling both serial and efi earlyprintk, below is
    some debug dmesg, seems early_ioremap fails in scroll up function due to
    no free slot, see below dmesg output:
    
      WARNING: CPU: 0 PID: 0 at mm/early_ioremap.c:116 __early_ioremap+0x90/0x1c4()
      __early_ioremap(ed00c800, 00000c80) not found slot
      Modules linked in:
      CPU: 0 PID: 0 Comm: swapper Not tainted 3.17.0-rc1+ #204
      Hardware name: Hewlett-Packard HP Z420 Workstation/1589, BIOS J61 v03.15 05/09/2013
      Call Trace:
        dump_stack+0x4e/0x7a
        warn_slowpath_common+0x75/0x8e
        ? __early_ioremap+0x90/0x1c4
        warn_slowpath_fmt+0x47/0x49
        __early_ioremap+0x90/0x1c4
        ? sprintf+0x46/0x48
        early_ioremap+0x13/0x15
        early_efi_map+0x24/0x26
        early_efi_scroll_up+0x6d/0xc0
        early_efi_write+0x1b0/0x214
        call_console_drivers.constprop.21+0x73/0x7e
        console_unlock+0x151/0x3b2
        ? vprintk_emit+0x49f/0x532
        vprintk_emit+0x521/0x532
        ? console_unlock+0x383/0x3b2
        printk+0x4f/0x51
        acpi_os_vprintf+0x2b/0x2d
        acpi_os_printf+0x43/0x45
        acpi_info+0x5c/0x63
        ? __acpi_map_table+0x13/0x18
        ? acpi_os_map_iomem+0x21/0x147
        acpi_tb_print_table_header+0x177/0x186
        acpi_tb_install_table_with_override+0x4b/0x62
        acpi_tb_install_standard_table+0xd9/0x215
        ? early_ioremap+0x13/0x15
        ? __acpi_map_table+0x13/0x18
        acpi_tb_parse_root_table+0x16e/0x1b4
        acpi_initialize_tables+0x57/0x59
        acpi_table_init+0x50/0xce
        acpi_boot_table_init+0x1e/0x85
        setup_arch+0x9b7/0xcc4
        start_kernel+0x94/0x42d
        ? early_idt_handlers+0x120/0x120
        x86_64_start_reservations+0x2a/0x2c
        x86_64_start_kernel+0xf3/0x100
    
    Quote reply from Lv.zheng about the early ioremap slot usage in this case:
    
    """
    In early_efi_scroll_up(), 2 mapping entries will be used for the src/dst screen buffer.
    In drivers/acpi/acpica/tbutils.c, we've improved the early table loading code in acpi_tb_parse_root_table().
    We now need 2 mapping entries:
    1. One mapping entry is used for RSDT table mapping. Each RSDT entry contains an address for another ACPI table.
    2. For each entry in RSDP, we need another mapping entry to map the table to perform necessary check/override before installing it.
    
    When acpi_tb_parse_root_table() prints something through EFI earlyprintk console, we'll have 4 mapping entries used.
    The current 4 slots setting of early_ioremap() seems to be too small for such a use case.
    """
    
    Thus increase the slot to 8 in this patch to fix this issue.
    boot-time mappings become 512 page with this patch.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Cc: <stable@vger.kernel.org> # v3.16
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index b0910f97a3ea..ffb1733ac91f 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -106,14 +106,14 @@ enum fixed_addresses {
 	__end_of_permanent_fixed_addresses,
 
 	/*
-	 * 256 temporary boot-time mappings, used by early_ioremap(),
+	 * 512 temporary boot-time mappings, used by early_ioremap(),
 	 * before ioremap() is functional.
 	 *
-	 * If necessary we round it up to the next 256 pages boundary so
+	 * If necessary we round it up to the next 512 pages boundary so
 	 * that we can have a single pgd entry and a single pte table:
 	 */
 #define NR_FIX_BTMAPS		64
-#define FIX_BTMAPS_SLOTS	4
+#define FIX_BTMAPS_SLOTS	8
 #define TOTAL_FIX_BTMAPS	(NR_FIX_BTMAPS * FIX_BTMAPS_SLOTS)
 	FIX_BTMAP_END =
 	 (__end_of_permanent_fixed_addresses ^

commit f40c330091c7aa9956ab66f97a3abc8a68b67240
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon May 5 12:19:36 2014 -0700

    x86, vdso: Move the vvar and hpet mappings next to the 64-bit vDSO
    
    This makes the 64-bit and x32 vdsos use the same mechanism as the
    32-bit vdso.  Most of the churn is deleting all the old fixmap code.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/8af87023f57f6bb96ec8d17fce3f88018195b49b.1399317206.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 43f482a0db37..b0910f97a3ea 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -24,7 +24,7 @@
 #include <linux/threads.h>
 #include <asm/kmap_types.h>
 #else
-#include <asm/vsyscall.h>
+#include <uapi/asm/vsyscall.h>
 #endif
 
 /*
@@ -41,7 +41,8 @@
 extern unsigned long __FIXADDR_TOP;
 #define FIXADDR_TOP	((unsigned long)__FIXADDR_TOP)
 #else
-#define FIXADDR_TOP	(VSYSCALL_END-PAGE_SIZE)
+#define FIXADDR_TOP	(round_up(VSYSCALL_ADDR + PAGE_SIZE, 1<<PMD_SHIFT) - \
+			 PAGE_SIZE)
 #endif
 
 
@@ -68,11 +69,7 @@ enum fixed_addresses {
 #ifdef CONFIG_X86_32
 	FIX_HOLE,
 #else
-	VSYSCALL_LAST_PAGE,
-	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
-			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
-	VVAR_PAGE,
-	VSYSCALL_HPET,
+	VSYSCALL_PAGE = (FIXADDR_TOP - VSYSCALL_ADDR) >> PAGE_SHIFT,
 #ifdef CONFIG_PARAVIRT_CLOCK
 	PVCLOCK_FIXMAP_BEGIN,
 	PVCLOCK_FIXMAP_END = PVCLOCK_FIXMAP_BEGIN+PVCLOCK_VSYSCALL_NR_PAGES-1,

commit 5b7c73e00968c7fdf908c3ced31e1cc83c01ba14
Author: Mark Salter <msalter@redhat.com>
Date:   Mon Apr 7 15:39:49 2014 -0700

    x86: use generic early_ioremap
    
    Move x86 over to the generic early ioremap implementation.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 8dcd35c4c787..43f482a0db37 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -163,5 +163,11 @@ static inline void __set_fixmap(enum fixed_addresses idx,
 
 #include <asm-generic/fixmap.h>
 
+#define __late_set_fixmap(idx, phys, flags) __set_fixmap(idx, phys, flags)
+#define __late_clear_fixmap(idx) __set_fixmap(idx, 0, __pgprot(0))
+
+void __early_set_fixmap(enum fixed_addresses idx,
+			phys_addr_t phys, pgprot_t flags);
+
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit 467cbd207abdbfe29514b5804a22661ab6e80dc6
Merge: 7125764c5d1a b5660ba76b41
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 2 13:15:58 2014 -0700

    Merge branch 'x86-nuke-platforms-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 old platform removal from Peter Anvin:
     "This patchset removes support for several completely obsolete
      platforms, where the maintainers either have completely vanished or
      acked the removal.  For some of them it is questionable if there even
      exists functional specimens of the hardware"
    
    Geert Uytterhoeven apparently thought this was a April Fool's pull request ;)
    
    * 'x86-nuke-platforms-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, platforms: Remove NUMAQ
      x86, platforms: Remove SGI Visual Workstation
      x86, apic: Remove support for IBM Summit/EXA chipset
      x86, apic: Remove support for ia32-based Unisys ES7000

commit b0b49f2673f011cad7deeabf7a683b388c351278
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Mar 13 16:01:26 2014 -0700

    x86, vdso: Remove compat vdso support
    
    The compat vDSO is a complicated hack that's needed to maintain
    compatibility with a small range of glibc versions.
    
    This removes it and replaces it with a much simpler hack: a config
    option to disable the 32-bit vDSO by default.
    
    This also changes the default value of CONFIG_COMPAT_VDSO to n --
    users configuring kernels from scratch almost certainly want that
    choice.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/4bb4690899106eb11430b1186d5cc66ca9d1660c.1394751608.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 7252cd339175..2377f5618fb7 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -40,15 +40,8 @@
  */
 extern unsigned long __FIXADDR_TOP;
 #define FIXADDR_TOP	((unsigned long)__FIXADDR_TOP)
-
-#define FIXADDR_USER_START     __fix_to_virt(FIX_VDSO)
-#define FIXADDR_USER_END       __fix_to_virt(FIX_VDSO - 1)
 #else
 #define FIXADDR_TOP	(VSYSCALL_END-PAGE_SIZE)
-
-/* Only covers 32bit vsyscalls currently. Need another set for 64bit. */
-#define FIXADDR_USER_START	((unsigned long)VSYSCALL32_VSYSCALL)
-#define FIXADDR_USER_END	(FIXADDR_USER_START + PAGE_SIZE)
 #endif
 
 
@@ -74,7 +67,6 @@ extern unsigned long __FIXADDR_TOP;
 enum fixed_addresses {
 #ifdef CONFIG_X86_32
 	FIX_HOLE,
-	FIX_VDSO,
 #else
 	VSYSCALL_LAST_PAGE,
 	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE

commit c5f9ee3d665a7660b296aa1e91949ae3376f0d07
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Tue Feb 25 12:05:34 2014 -0800

    x86, platforms: Remove SGI Visual Workstation
    
    The SGI Visual Workstation seems to be dead; remove support so we
    don't have to continue maintaining it.
    
    Cc: Andrey Panin <pazke@donpac.ru>
    Cc: Michael Reed <mdr@sgi.com>
    Link: http://lkml.kernel.org/r/530CFD6C.7040705@zytor.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 7252cd339175..f690ee420bf4 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -97,12 +97,6 @@ enum fixed_addresses {
 #ifdef CONFIG_X86_IO_APIC
 	FIX_IO_APIC_BASE_0,
 	FIX_IO_APIC_BASE_END = FIX_IO_APIC_BASE_0 + MAX_IO_APICS - 1,
-#endif
-#ifdef CONFIG_X86_VISWS_APIC
-	FIX_CO_CPU,	/* Cobalt timer */
-	FIX_CO_APIC,	/* Cobalt APIC Redirection Table */
-	FIX_LI_PCIA,	/* Lithium PCI Bridge A */
-	FIX_LI_PCIB,	/* Lithium PCI Bridge B */
 #endif
 	FIX_RO_IDT,	/* Virtual mapping for read-only IDT */
 #ifdef CONFIG_X86_32

commit 114cefc87ec445207f6968f584ea5edcb474f541
Author: Mark Salter <msalter@redhat.com>
Date:   Thu Jan 23 15:53:50 2014 -0800

    x86: use generic fixmap.h
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index e846225265ed..7252cd339175 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -175,64 +175,7 @@ static inline void __set_fixmap(enum fixed_addresses idx,
 }
 #endif
 
-#define set_fixmap(idx, phys)				\
-	__set_fixmap(idx, phys, PAGE_KERNEL)
-
-/*
- * Some hardware wants to get fixmapped without caching.
- */
-#define set_fixmap_nocache(idx, phys)			\
-	__set_fixmap(idx, phys, PAGE_KERNEL_NOCACHE)
-
-#define clear_fixmap(idx)			\
-	__set_fixmap(idx, 0, __pgprot(0))
-
-#define __fix_to_virt(x)	(FIXADDR_TOP - ((x) << PAGE_SHIFT))
-#define __virt_to_fix(x)	((FIXADDR_TOP - ((x)&PAGE_MASK)) >> PAGE_SHIFT)
-
-extern void __this_fixmap_does_not_exist(void);
-
-/*
- * 'index to address' translation. If anyone tries to use the idx
- * directly without translation, we catch the bug with a NULL-deference
- * kernel oops. Illegal ranges of incoming indices are caught too.
- */
-static __always_inline unsigned long fix_to_virt(const unsigned int idx)
-{
-	/*
-	 * this branch gets completely eliminated after inlining,
-	 * except when someone tries to use fixaddr indices in an
-	 * illegal way. (such as mixing up address types or using
-	 * out-of-range indices).
-	 *
-	 * If it doesn't get removed, the linker will complain
-	 * loudly with a reasonably clear error message..
-	 */
-	if (idx >= __end_of_fixed_addresses)
-		__this_fixmap_does_not_exist();
-
-	return __fix_to_virt(idx);
-}
-
-static inline unsigned long virt_to_fix(const unsigned long vaddr)
-{
-	BUG_ON(vaddr >= FIXADDR_TOP || vaddr < FIXADDR_START);
-	return __virt_to_fix(vaddr);
-}
-
-/* Return an pointer with offset calculated */
-static __always_inline unsigned long
-__set_fixmap_offset(enum fixed_addresses idx, phys_addr_t phys, pgprot_t flags)
-{
-	__set_fixmap(idx, phys, flags);
-	return fix_to_virt(idx) + (phys & (PAGE_SIZE - 1));
-}
-
-#define set_fixmap_offset(idx, phys)			\
-	__set_fixmap_offset(idx, phys, PAGE_KERNEL)
-
-#define set_fixmap_offset_nocache(idx, phys)			\
-	__set_fixmap_offset(idx, phys, PAGE_KERNEL_NOCACHE)
+#include <asm-generic/fixmap.h>
 
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit cbdce7b251de89deef79ec9e37b6cfa7d5595894
Author: Jan Beulich <JBeulich@suse.com>
Date:   Wed May 29 13:22:23 2013 +0100

    ix86: Don't waste fixmap entries
    
    The vsyscall related pvclock entries can only ever be used on
    x86-64, and hence they shouldn't even get allocated for 32-bit
    kernels (the more that it is there where address space is
    relatively precious).
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Link: http://lkml.kernel.org/r/51A60F1F02000078000D997C@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 0dc7d9e21c34..e846225265ed 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -81,10 +81,10 @@ enum fixed_addresses {
 			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
 	VVAR_PAGE,
 	VSYSCALL_HPET,
-#endif
 #ifdef CONFIG_PARAVIRT_CLOCK
 	PVCLOCK_FIXMAP_BEGIN,
 	PVCLOCK_FIXMAP_END = PVCLOCK_FIXMAP_BEGIN+PVCLOCK_VSYSCALL_NR_PAGES-1,
+#endif
 #endif
 	FIX_DBGP_BASE,
 	FIX_EARLYCON_MEM_BASE,

commit f9b3bcfbc43ac80f2019a5093ad9a1e624e611b1
Merge: 01c7cd0ef5d9 13f72756da86
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 30 08:40:35 2013 -0700

    Merge branch 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 mm changes from Ingo Molnar:
     "Misc smaller changes all over the map"
    
    * 'x86-mm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/iommu/dmar: Remove warning for HPET scope type
      x86/mm/gart: Drop unnecessary check
      x86/mm/hotplug: Put kernel_physical_mapping_remove() declaration in CONFIG_MEMORY_HOTREMOVE
      x86/mm/fixmap: Remove unused FIX_CYCLONE_TIMER
      x86/mm/numa: Simplify some bit mangling
      x86/mm: Re-enable DEBUG_TLBFLUSH for X86_32
      x86/mm/cpa: Cleanup split_large_page() and its callee
      x86: Drop always empty .text..page_aligned section

commit a7e6567585e513cb4e44387831cb75eb5b562cbb
Author: Paul Bolle <pebolle@tiscali.nl>
Date:   Thu Apr 11 18:49:42 2013 +0200

    x86/mm/fixmap: Remove unused FIX_CYCLONE_TIMER
    
    The last users of FIX_CYCLONE_TIMER were removed in v2.6.18. We
    can remove this unneeded constant.
    
    Signed-off-by: Paul Bolle <pebolle@tiscali.nl>
    Link: http://lkml.kernel.org/r/1365698982.1427.3.camel@x61.thuisdomein
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index a09c28571064..83ea2fb5fc75 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -107,9 +107,6 @@ enum fixed_addresses {
 #ifdef CONFIG_X86_F00F_BUG
 	FIX_F00F_IDT,	/* Virtual mapping for IDT */
 #endif
-#ifdef CONFIG_X86_CYCLONE_TIMER
-	FIX_CYCLONE_TIMER, /*cyclone timer register*/
-#endif
 #ifdef CONFIG_X86_32
 	FIX_KMAP_BEGIN,	/* reserved pte's for temporary kernel mappings */
 	FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,

commit 4eefbe792baedb474e256d35370849992fcf1c79
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Apr 10 12:24:22 2013 -0700

    x86: Use a read-only IDT alias on all CPUs
    
    Make a copy of the IDT (as seen via the "sidt" instruction) read-only.
    This primarily removes the IDT from being a target for arbitrary memory
    write attacks, and has the added benefit of also not leaking the kernel
    base offset, if it has been relocated.
    
    We already did this on vendor == Intel and family == 5 because of the
    F0 0F bug -- regardless of if a particular CPU had the F0 0F bug or
    not.  Since the workaround was so cheap, there simply was no reason to
    be very specific.  This patch extends the readonly alias to all CPUs,
    but does not activate the #PF to #UD conversion code needed to deliver
    the proper exception in the F0 0F case except on Intel family 5
    processors.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Link: http://lkml.kernel.org/r/20130410192422.GA17344@www.outflux.net
    Cc: Eric Northup <digitaleric@google.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index a09c28571064..51b9e322cb8f 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -104,9 +104,7 @@ enum fixed_addresses {
 	FIX_LI_PCIA,	/* Lithium PCI Bridge A */
 	FIX_LI_PCIB,	/* Lithium PCI Bridge B */
 #endif
-#ifdef CONFIG_X86_F00F_BUG
-	FIX_F00F_IDT,	/* Virtual mapping for IDT */
-#endif
+	FIX_RO_IDT,	/* Virtual mapping for read-only IDT */
 #ifdef CONFIG_X86_CYCLONE_TIMER
 	FIX_CYCLONE_TIMER, /*cyclone timer register*/
 #endif

commit 71056ae22d43f58d7e0f793af18ace2eaf5b74eb
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Tue Nov 27 23:28:55 2012 -0200

    x86: pvclock: generic pvclock vsyscall initialization
    
    Originally from Jeremy Fitzhardinge.
    
    Introduce generic, non hypervisor specific, pvclock initialization
    routines.
    
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 4da3c0c4c974..a09c28571064 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -19,6 +19,7 @@
 #include <asm/acpi.h>
 #include <asm/apicdef.h>
 #include <asm/page.h>
+#include <asm/pvclock.h>
 #ifdef CONFIG_X86_32
 #include <linux/threads.h>
 #include <asm/kmap_types.h>
@@ -80,6 +81,10 @@ enum fixed_addresses {
 			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
 	VVAR_PAGE,
 	VSYSCALL_HPET,
+#endif
+#ifdef CONFIG_PARAVIRT_CLOCK
+	PVCLOCK_FIXMAP_BEGIN,
+	PVCLOCK_FIXMAP_END = PVCLOCK_FIXMAP_BEGIN+PVCLOCK_VSYSCALL_NR_PAGES-1,
 #endif
 	FIX_DBGP_BASE,
 	FIX_EARLYCON_MEM_BASE,

commit 933b9463a0ef75da681747b2dac06c1754465372
Author: Alan Cox <alan@linux.intel.com>
Date:   Sat Dec 17 17:43:40 2011 +0000

    x86/intel config: Revamp configuration to allow for Moorestown and Medfield
    
    This sets all up the other bits that need to be INTEL_MID
    specific rather than Moorestown specific.
    
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    Link: http://lkml.kernel.org/r/20111217174318.7207.91543.stgit@bob.linux.org.uk
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 460c74e4852c..4da3c0c4c974 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -117,7 +117,7 @@ enum fixed_addresses {
 #endif
 	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
 	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
-#ifdef	CONFIG_X86_MRST
+#ifdef	CONFIG_X86_INTEL_MID
 	FIX_LNW_VRTC,
 #endif
 	__end_of_permanent_fixed_addresses,

commit 9fd67b4ed0714ab718f1f9bd14c344af336a6df7
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Sun Jun 5 13:50:19 2011 -0400

    x86-64: Give vvars their own page
    
    Move vvars out of the vsyscall page into their own page and mark
    it NX.
    
    Without this patch, an attacker who can force a daemon to call
    some fixed address could wait until the time contains, say,
    0xCD80, and then execute the current time.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Jesper Juhl <jj@chaosbits.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: richard -rw- weinberger <richard.weinberger@gmail.com>
    Cc: Mikael Pettersson <mikpe@it.uu.se>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: Valdis.Kletnieks@vt.edu
    Cc: pageexec@freemail.hu
    Link: http://lkml.kernel.org/r/b1460f81dc4463d66ea3f2b5ce240f58d48effec.1307292171.git.luto@mit.edu
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 4729b2b63117..460c74e4852c 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -78,6 +78,7 @@ enum fixed_addresses {
 	VSYSCALL_LAST_PAGE,
 	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
 			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
+	VVAR_PAGE,
 	VSYSCALL_HPET,
 #endif
 	FIX_DBGP_BASE,

commit fa36e956c5027d9a985d555d104d293c0a98d2c3
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Tue Jan 11 10:55:56 2011 +0000

    x86: Fix Moorestown VRTC fixmap placement
    
    The x86 fixmaps need to be all together... unfortunately the
    VRTC one was misplaced.
    
    This patch makes sure the MRST VRTC fixmap is put prior to the
    __end_of_permanent_fixed_addresses marker.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    LKML-Reference: <20110111105544.24448.27607.stgit@bob.linux.org.uk>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 0141b234406f..4729b2b63117 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -116,11 +116,11 @@ enum fixed_addresses {
 #endif
 	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
 	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
-	__end_of_permanent_fixed_addresses,
-
 #ifdef	CONFIG_X86_MRST
 	FIX_LNW_VRTC,
 #endif
+	__end_of_permanent_fixed_addresses,
+
 	/*
 	 * 256 temporary boot-time mappings, used by early_ioremap(),
 	 * before ioremap() is functional.

commit b4c6e2ea5e46b03c764a918f4999a77a3149979f
Merge: 6f46b120a962 991cfffa7c19
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 6 11:06:31 2011 -0800

    Merge branch 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-platform-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, earlyprintk: Move mrst early console to platform/ and fix a typo
      x86, apbt: Setup affinity for apb timers acting as per-cpu timer
      ce4100: Add errata fixes for UART on CE4100
      x86: platform: Move iris to x86/platform where it belongs
      x86, mrst: Check platform_device_register() return code
      x86/platform: Add Eurobraille/Iris power off support
      x86, mrst: Add explanation for using 1960 as the year offset for vrtc
      x86, mrst: Fix dependencies of "select INTEL_SCU_IPC"
      x86, mrst: The shutdown for MRST requires the SCU IPC mechanism
      x86: Ce4100: Add reboot_fixup() for CE4100
      ce4100: Add PCI register emulation for CE4100
      x86: Add CE4100 platform support
      x86: mrst: Set vRTC's IRQ to level trigger type
      x86: mrst: Add audio driver bindings
      rtc: Add drivers/rtc/rtc-mrst.c
      x86: mrst: Add vrtc driver which serves as a wall clock device
      x86: mrst: Add Moorestown specific reboot/shutdown support
      x86: mrst: Parse SFI timer table for all timer configs
      x86/mrst: Add SFI platform device parsing code

commit 91d95fda8594ce5e0ccd81381ee7b956cf513c59
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Wed Nov 24 12:57:18 2010 -0800

    arch/x86/include/asm/fixmap.h: mark __set_fixmap_offset as __always_inline
    
    When compiling arch/x86/kernel/early_printk_mrst.c with i386
    allmodconfig, gcc-4.1.0 generates an out-of-line copy of
    __set_fixmap_offset() which contains a reference to
    __this_fixmap_does_not_exist which the compiler cannot elide.
    
    Marking __set_fixmap_offset() as __always_inline prevents this.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Feng Tang <feng.tang@intel.com>
    Acked-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 4d293dced62f..9479a037419f 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -216,8 +216,8 @@ static inline unsigned long virt_to_fix(const unsigned long vaddr)
 }
 
 /* Return an pointer with offset calculated */
-static inline unsigned long __set_fixmap_offset(enum fixed_addresses idx,
-				phys_addr_t phys, pgprot_t flags)
+static __always_inline unsigned long
+__set_fixmap_offset(enum fixed_addresses idx, phys_addr_t phys, pgprot_t flags)
 {
 	__set_fixmap(idx, phys, flags);
 	return fix_to_virt(idx) + (phys & (PAGE_SIZE - 1));

commit 7309282c90d251cde77fe3b520a8276e25315c49
Author: Feng Tang <feng.tang@intel.com>
Date:   Wed Nov 10 17:29:00 2010 +0000

    x86: mrst: Add vrtc driver which serves as a wall clock device
    
    Moorestown platform doesn't have a m146818 RTC device like traditional
    x86 PC, but a firmware emulated virtual RTC device(vrtc), which provides
    some basic RTC functions like get/set time. vrtc serves as the only
    wall clock device on Moorestown platform.
    
    [ tglx: Changed the exports to _GPL ]
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    LKML-Reference: <20101110172837.3311.40483.stgit@localhost.localdomain>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 4d293dced62f..139591a933f6 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -117,6 +117,10 @@ enum fixed_addresses {
 	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
 	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
 	__end_of_permanent_fixed_addresses,
+
+#ifdef	CONFIG_X86_MRST
+	FIX_LNW_VRTC,
+#endif
 	/*
 	 * 256 temporary boot-time mappings, used by early_ioremap(),
 	 * before ioremap() is functional.

commit 5a47c7dae861c3ca3edf178546641909851bf715
Author: Feng Tang <feng.tang@intel.com>
Date:   Mon Sep 13 15:08:54 2010 +0800

    x86: Add two helper macros for fixed address mapping
    
    Sometimes fixmap will be used to map an physical address which
    is not PAGE align, so to use it we need first map it and then
    add the address offset to the mapped fixed address. These 2 new
    helpers are suggested by Ingo Molnar to make the process
    simpler.
    
    For a physicall address like "phys", a directly usable virtual
    address can be get by
            virt = (void *)set_fixmap_offset(fixed_idx, phys);
    or
            virt = (void *)set_fixmap_offset_nocache(fixed_idx, phys);
    (depends on whether the physical address is cachable or not).
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Cc: alan@linux.intel.com
    Cc: greg@kroah.com
    Cc: x86@kernel.org
    LKML-Reference: <1284361736-23011-3-git-send-email-feng.tang@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index d07b44f7d1dc..4d293dced62f 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -214,5 +214,20 @@ static inline unsigned long virt_to_fix(const unsigned long vaddr)
 	BUG_ON(vaddr >= FIXADDR_TOP || vaddr < FIXADDR_START);
 	return __virt_to_fix(vaddr);
 }
+
+/* Return an pointer with offset calculated */
+static inline unsigned long __set_fixmap_offset(enum fixed_addresses idx,
+				phys_addr_t phys, pgprot_t flags)
+{
+	__set_fixmap(idx, phys, flags);
+	return fix_to_virt(idx) + (phys & (PAGE_SIZE - 1));
+}
+
+#define set_fixmap_offset(idx, phys)			\
+	__set_fixmap_offset(idx, phys, PAGE_KERNEL)
+
+#define set_fixmap_offset_nocache(idx, phys)			\
+	__set_fixmap_offset(idx, phys, PAGE_KERNEL_NOCACHE)
+
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit ff30a0543e9a6cd732582063e7cae951cdb7acf2
Author: Jan Beulich <JBeulich@novell.com>
Date:   Mon Mar 15 10:11:15 2010 +0000

    x86: Fix placement of FIX_OHCI1394_BASE
    
    Ever for 32-bit with sufficiently high NR_CPUS, and starting
    with commit 789d03f584484af85dbdc64935270c8e45f36ef7 also for
    64-bit, the statically allocated early fixmap page tables were
    not covering FIX_OHCI1394_BASE, leading to a boot time crash
    when "ohci1394_dma=early" was used. Despite this entry not being
    a permanently used one, it needs to be moved into the permanent
    range since it has to be close to FIX_DBGP_BASE and
    FIX_EARLYCON_MEM_BASE.
    
    Reported-bisected-and-tested-by: Justin P. Mattock <justinmattock@gmail.com>
    Fixes-bug: http://bugzilla.kernel.org/show_bug.cgi?id=14487
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: <stable@kernel.org> # [as far back as long as it still applies]
    LKML-Reference: <4B9E15D30200007800034D23@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 635f03bb4995..d07b44f7d1dc 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -82,6 +82,9 @@ enum fixed_addresses {
 #endif
 	FIX_DBGP_BASE,
 	FIX_EARLYCON_MEM_BASE,
+#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
+	FIX_OHCI1394_BASE,
+#endif
 #ifdef CONFIG_X86_LOCAL_APIC
 	FIX_APIC_BASE,	/* local (CPU) APIC) -- required for SMP or not */
 #endif
@@ -132,9 +135,6 @@ enum fixed_addresses {
 	   (__end_of_permanent_fixed_addresses & (TOTAL_FIX_BTMAPS - 1))
 	 : __end_of_permanent_fixed_addresses,
 	FIX_BTMAP_BEGIN = FIX_BTMAP_END + TOTAL_FIX_BTMAPS - 1,
-#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
-	FIX_OHCI1394_BASE,
-#endif
 #ifdef CONFIG_X86_32
 	FIX_WP_TEST,
 #endif

commit 499a5f1efa0b0ac56ec5d060412aed84ae68e63e
Author: Jan Beulich <JBeulich@novell.com>
Date:   Fri Dec 18 16:05:51 2009 +0000

    x86: Lift restriction on the location of FIX_BTMAP_*
    
    The early ioremap fixmap entries cover half (or for 32-bit
    non-PAE, a quarter) of a page table, yet they got
    uncondtitionally aligned so far to a 256-entry boundary. This is
    not necessary if the range of page table entries anyway falls
    into a single page table.
    
    This buys back, for (theoretically) 50% of all configurations
    (25% of all non-PAE ones), at least some of the lowmem
    necessarily lost with commit e621bd18958ef5dbace3129ebe17a0a475e127d9.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <4B2BB66F0200007800026AD6@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 14f9890eb495..635f03bb4995 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -118,14 +118,20 @@ enum fixed_addresses {
 	 * 256 temporary boot-time mappings, used by early_ioremap(),
 	 * before ioremap() is functional.
 	 *
-	 * We round it up to the next 256 pages boundary so that we
-	 * can have a single pgd entry and a single pte table:
+	 * If necessary we round it up to the next 256 pages boundary so
+	 * that we can have a single pgd entry and a single pte table:
 	 */
 #define NR_FIX_BTMAPS		64
 #define FIX_BTMAPS_SLOTS	4
-	FIX_BTMAP_END = __end_of_permanent_fixed_addresses + 256 -
-			(__end_of_permanent_fixed_addresses & 255),
-	FIX_BTMAP_BEGIN = FIX_BTMAP_END + NR_FIX_BTMAPS*FIX_BTMAPS_SLOTS - 1,
+#define TOTAL_FIX_BTMAPS	(NR_FIX_BTMAPS * FIX_BTMAPS_SLOTS)
+	FIX_BTMAP_END =
+	 (__end_of_permanent_fixed_addresses ^
+	  (__end_of_permanent_fixed_addresses + TOTAL_FIX_BTMAPS - 1)) &
+	 -PTRS_PER_PTE
+	 ? __end_of_permanent_fixed_addresses + TOTAL_FIX_BTMAPS -
+	   (__end_of_permanent_fixed_addresses & (TOTAL_FIX_BTMAPS - 1))
+	 : __end_of_permanent_fixed_addresses,
+	FIX_BTMAP_BEGIN = FIX_BTMAP_END + TOTAL_FIX_BTMAPS - 1,
 #ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
 	FIX_OHCI1394_BASE,
 #endif

commit 3162534069597e34dd0ac9eb711be8dc23835ae7
Author: Joseph Cihula <joseph.cihula@intel.com>
Date:   Tue Jun 30 19:30:59 2009 -0700

    x86, intel_txt: Intel TXT boot support
    
    This patch adds kernel configuration and boot support for Intel Trusted
    Execution Technology (Intel TXT).
    
    Intel's technology for safer computing, Intel Trusted Execution
    Technology (Intel TXT), defines platform-level enhancements that
    provide the building blocks for creating trusted platforms.
    
    Intel TXT was formerly known by the code name LaGrande Technology (LT).
    
    Intel TXT in Brief:
    o  Provides dynamic root of trust for measurement (DRTM)
    o  Data protection in case of improper shutdown
    o  Measurement and verification of launched environment
    
    Intel TXT is part of the vPro(TM) brand and is also available some
    non-vPro systems.  It is currently available on desktop systems based on
    the Q35, X38, Q45, and Q43 Express chipsets (e.g. Dell Optiplex 755, HP
    dc7800, etc.) and mobile systems based on the GM45, PM45, and GS45
    Express chipsets.
    
    For more information, see http://www.intel.com/technology/security/.
    This site also has a link to the Intel TXT MLE Developers Manual, which
    has been updated for the new released platforms.
    
    A much more complete description of how these patches support TXT, how to
    configure a system for it, etc. is in the Documentation/intel_txt.txt file
    in this patch.
    
    This patch provides the TXT support routines for complete functionality,
    documentation for TXT support and for the changes to the boot_params structure,
    and boot detection of a TXT launch.  Attempts to shutdown (reboot, Sx) the system
    will result in platform resets; subsequent patches will support these shutdown modes
    properly.
    
     Documentation/intel_txt.txt      |  210 +++++++++++++++++++++
     Documentation/x86/zero-page.txt  |    1
     arch/x86/include/asm/bootparam.h |    3
     arch/x86/include/asm/fixmap.h    |    3
     arch/x86/include/asm/tboot.h     |  197 ++++++++++++++++++++
     arch/x86/kernel/Makefile         |    1
     arch/x86/kernel/setup.c          |    4
     arch/x86/kernel/tboot.c          |  379 +++++++++++++++++++++++++++++++++++++++
     security/Kconfig                 |   30 +++
     9 files changed, 827 insertions(+), 1 deletion(-)
    
    Signed-off-by: Joseph Cihula <joseph.cihula@intel.com>
    Signed-off-by: Shane Wang <shane.wang@intel.com>
    Signed-off-by: Gang Wei <gang.wei@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 7b2d71df39a6..14f9890eb495 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -131,6 +131,9 @@ enum fixed_addresses {
 #endif
 #ifdef CONFIG_X86_32
 	FIX_WP_TEST,
+#endif
+#ifdef CONFIG_INTEL_TXT
+	FIX_TBOOT_BASE,
 #endif
 	__end_of_fixed_addresses
 };

commit 12b9d7ccb841805e347fec8f733f368f43ddba40
Author: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date:   Wed Jul 1 17:37:22 2009 -0400

    x86: Fix fixmap page order for FIX_TEXT_POKE0,1
    
    Masami reported:
    
    > Since the fixmap pages are assigned higher address to lower,
    > text_poke() has to use it with inverted order (FIX_TEXT_POKE1
    > to FIX_TEXT_POKE0).
    
    I prefer to just invert the order of the fixmap declaration.
    It's simpler and more straightforward.
    
    Backward fixmaps seems to be used by both x86 32 and 64.
    
    It's really rare but a nasty bug, because it only hurts when
    instructions to patch are crossing a page boundary. If this
    happens, the fixmap write accesses will spill on the following
    fixmap, which may very well crash the system. And this does not
    crash the system, it could leave illegal instructions in place.
    Thanks Masami for finding this.
    
    It seems to have crept into the 2.6.30-rc series, so this calls
    for a -stable inclusion.
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Acked-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: <stable@kernel.org>
    LKML-Reference: <20090701213722.GH19926@Krystal>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 3eb0f79a5320..7b2d71df39a6 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -111,8 +111,8 @@ enum fixed_addresses {
 #ifdef CONFIG_PARAVIRT
 	FIX_PARAVIRT_BOOTMAP,
 #endif
-	FIX_TEXT_POKE0,	/* reserve 2 pages for text_poke() */
-	FIX_TEXT_POKE1,
+	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
+	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
 	__end_of_permanent_fixed_addresses,
 	/*
 	 * 256 temporary boot-time mappings, used by early_ioremap(),

commit 789d03f584484af85dbdc64935270c8e45f36ef7
Author: Jan Beulich <JBeulich@novell.com>
Date:   Tue Jun 30 11:52:23 2009 +0100

    x86: Fix fixmap ordering
    
    The merge of the 32- and 64-bit fixmap headers made a latent
    bug on x86-64 a real one: with the right config settings
    it is possible for FIX_OHCI1394_BASE to overlap the FIX_BTMAP_*
    range.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: <stable@kernel.org> # for 2.6.30.x
    LKML-Reference: <4A4A0A8702000078000082E8@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 2d81af3974a0..3eb0f79a5320 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -114,9 +114,6 @@ enum fixed_addresses {
 	FIX_TEXT_POKE0,	/* reserve 2 pages for text_poke() */
 	FIX_TEXT_POKE1,
 	__end_of_permanent_fixed_addresses,
-#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
-	FIX_OHCI1394_BASE,
-#endif
 	/*
 	 * 256 temporary boot-time mappings, used by early_ioremap(),
 	 * before ioremap() is functional.
@@ -129,6 +126,9 @@ enum fixed_addresses {
 	FIX_BTMAP_END = __end_of_permanent_fixed_addresses + 256 -
 			(__end_of_permanent_fixed_addresses & 255),
 	FIX_BTMAP_BEGIN = FIX_BTMAP_END + NR_FIX_BTMAPS*FIX_BTMAPS_SLOTS - 1,
+#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
+	FIX_OHCI1394_BASE,
+#endif
 #ifdef CONFIG_X86_32
 	FIX_WP_TEST,
 #endif

commit 3b3809ac5375f614bbf8671cddeae3c693aa584e
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Thu Apr 9 10:55:33 2009 -0700

    x86: fix set_fixmap to use phys_addr_t
    
    Use phys_addr_t for receiving a physical address argument instead of
    unsigned long.  This allows fixmap to handle pages higher than 4GB on
    x86-32.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 81937a5dc77c..2d81af3974a0 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -151,11 +151,11 @@ extern pte_t *pkmap_page_table;
 
 void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
 void native_set_fixmap(enum fixed_addresses idx,
-		       unsigned long phys, pgprot_t flags);
+		       phys_addr_t phys, pgprot_t flags);
 
 #ifndef CONFIG_PARAVIRT
 static inline void __set_fixmap(enum fixed_addresses idx,
-				unsigned long phys, pgprot_t flags)
+				phys_addr_t phys, pgprot_t flags)
 {
 	native_set_fixmap(idx, phys, flags);
 }

commit 78ff7fae04554b49d29226ed12536268c2500d1f
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Fri Mar 6 10:37:54 2009 -0500

    x86: implement atomic text_poke() via fixmap
    
    Use fixmaps instead of vmap/vunmap in text_poke() for avoiding
    page allocation and delayed unmapping.
    
    At the result of above change, text_poke() becomes atomic and can be called
    from stop_machine() etc.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Acked-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    LKML-Reference: <49B14352.2040705@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 63a79c77d220..81937a5dc77c 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -111,6 +111,8 @@ enum fixed_addresses {
 #ifdef CONFIG_PARAVIRT
 	FIX_PARAVIRT_BOOTMAP,
 #endif
+	FIX_TEXT_POKE0,	/* reserve 2 pages for text_poke() */
+	FIX_TEXT_POKE1,
 	__end_of_permanent_fixed_addresses,
 #ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
 	FIX_OHCI1394_BASE,

commit a1413c89ae6a4b7a9a43f7768934a81ffb5c629a
Merge: f254f3909efa dd4124a8a06b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 5 21:48:31 2009 +0100

    Merge branch 'x86/urgent' into x86/core
    
    Conflicts:
            arch/x86/include/asm/fixmap_64.h
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit c577b098f9bf467fb05dc279ba83604cb3f7cea0
Author: Gustavo F. Padovan <gustavo@las.ic.unicamp.br>
Date:   Sun Feb 15 21:48:59 2009 -0300

    x86, fixmap: unify fixmap.h
    
    Impact: unification
    
    This patch unify fixmap_32.h and fixmap_64.h into fixmap.h.
    Things that we can't merge now are using CONFIG_X86_{32,64}
    (e.g.:vsyscall and EFI)
    
    Signed-off-by: Gustavo F. Padovan <gustavo@las.ic.unicamp.br>
    Acked-by: Glauber Costa <gcosta@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 23696d44a0af..dca8f03da5b2 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -1,11 +1,155 @@
+/*
+ * fixmap.h: compile-time virtual memory allocation
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1998 Ingo Molnar
+ *
+ * Support of BIGMEM added by Gerhard Wichert, Siemens AG, July 1999
+ * x86_32 and x86_64 integration by Gustavo F. Padovan, February 2009
+ */
+
 #ifndef _ASM_X86_FIXMAP_H
 #define _ASM_X86_FIXMAP_H
 
+#ifndef __ASSEMBLY__
+#include <linux/kernel.h>
+#include <asm/acpi.h>
+#include <asm/apicdef.h>
+#include <asm/page.h>
+#ifdef CONFIG_X86_32
+#include <linux/threads.h>
+#include <asm/kmap_types.h>
+#else
+#include <asm/vsyscall.h>
+#ifdef CONFIG_EFI
+#include <asm/efi.h>
+#endif
+#endif
+
+/*
+ * We can't declare FIXADDR_TOP as variable for x86_64 because vsyscall
+ * uses fixmaps that relies on FIXADDR_TOP for proper address calculation.
+ * Because of this, FIXADDR_TOP x86 integration was left as later work.
+ */
+#ifdef CONFIG_X86_32
+/* used by vmalloc.c, vsyscall.lds.S.
+ *
+ * Leave one empty page between vmalloc'ed areas and
+ * the start of the fixmap.
+ */
+extern unsigned long __FIXADDR_TOP;
+#define FIXADDR_TOP	((unsigned long)__FIXADDR_TOP)
+
+#define FIXADDR_USER_START     __fix_to_virt(FIX_VDSO)
+#define FIXADDR_USER_END       __fix_to_virt(FIX_VDSO - 1)
+#else
+#define FIXADDR_TOP	(VSYSCALL_END-PAGE_SIZE)
+
+/* Only covers 32bit vsyscalls currently. Need another set for 64bit. */
+#define FIXADDR_USER_START	((unsigned long)VSYSCALL32_VSYSCALL)
+#define FIXADDR_USER_END	(FIXADDR_USER_START + PAGE_SIZE)
+#endif
+
+
+/*
+ * Here we define all the compile-time 'special' virtual
+ * addresses. The point is to have a constant address at
+ * compile time, but to set the physical address only
+ * in the boot process.
+ * for x86_32: We allocate these special addresses
+ * from the end of virtual memory (0xfffff000) backwards.
+ * Also this lets us do fail-safe vmalloc(), we
+ * can guarantee that these special addresses and
+ * vmalloc()-ed addresses never overlap.
+ *
+ * These 'compile-time allocated' memory buffers are
+ * fixed-size 4k pages (or larger if used with an increment
+ * higher than 1). Use set_fixmap(idx,phys) to associate
+ * physical memory with fixmap indices.
+ *
+ * TLB entries of such buffers will not be flushed across
+ * task switches.
+ */
+enum fixed_addresses {
 #ifdef CONFIG_X86_32
-# include "fixmap_32.h"
+	FIX_HOLE,
+	FIX_VDSO,
 #else
-# include "fixmap_64.h"
+	VSYSCALL_LAST_PAGE,
+	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
+			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
+	VSYSCALL_HPET,
 #endif
+	FIX_DBGP_BASE,
+	FIX_EARLYCON_MEM_BASE,
+#ifdef CONFIG_X86_LOCAL_APIC
+	FIX_APIC_BASE,	/* local (CPU) APIC) -- required for SMP or not */
+#endif
+#ifdef CONFIG_X86_IO_APIC
+	FIX_IO_APIC_BASE_0,
+	FIX_IO_APIC_BASE_END = FIX_IO_APIC_BASE_0 + MAX_IO_APICS - 1,
+#endif
+#ifdef CONFIG_X86_64
+#ifdef CONFIG_EFI
+	FIX_EFI_IO_MAP_LAST_PAGE,
+	FIX_EFI_IO_MAP_FIRST_PAGE = FIX_EFI_IO_MAP_LAST_PAGE
+				  + MAX_EFI_IO_PAGES - 1,
+#endif
+#endif
+#ifdef CONFIG_X86_VISWS_APIC
+	FIX_CO_CPU,	/* Cobalt timer */
+	FIX_CO_APIC,	/* Cobalt APIC Redirection Table */
+	FIX_LI_PCIA,	/* Lithium PCI Bridge A */
+	FIX_LI_PCIB,	/* Lithium PCI Bridge B */
+#endif
+#ifdef CONFIG_X86_F00F_BUG
+	FIX_F00F_IDT,	/* Virtual mapping for IDT */
+#endif
+#ifdef CONFIG_X86_CYCLONE_TIMER
+	FIX_CYCLONE_TIMER, /*cyclone timer register*/
+#endif
+#ifdef CONFIG_X86_32
+	FIX_KMAP_BEGIN,	/* reserved pte's for temporary kernel mappings */
+	FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,
+#ifdef CONFIG_PCI_MMCONFIG
+	FIX_PCIE_MCFG,
+#endif
+#endif
+#ifdef CONFIG_PARAVIRT
+	FIX_PARAVIRT_BOOTMAP,
+#endif
+	__end_of_permanent_fixed_addresses,
+#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
+	FIX_OHCI1394_BASE,
+#endif
+	/*
+	 * 256 temporary boot-time mappings, used by early_ioremap(),
+	 * before ioremap() is functional.
+	 *
+	 * We round it up to the next 256 pages boundary so that we
+	 * can have a single pgd entry and a single pte table:
+	 */
+#define NR_FIX_BTMAPS		64
+#define FIX_BTMAPS_SLOTS	4
+	FIX_BTMAP_END = __end_of_permanent_fixed_addresses + 256 -
+			(__end_of_permanent_fixed_addresses & 255),
+	FIX_BTMAP_BEGIN = FIX_BTMAP_END + NR_FIX_BTMAPS*FIX_BTMAPS_SLOTS - 1,
+#ifdef CONFIG_X86_32
+	FIX_WP_TEST,
+#endif
+	__end_of_fixed_addresses
+};
+
+
+extern void reserve_top_address(unsigned long reserve);
+
+#define FIXADDR_SIZE	(__end_of_permanent_fixed_addresses << PAGE_SHIFT)
+#define FIXADDR_BOOT_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
+#define FIXADDR_START		(FIXADDR_TOP - FIXADDR_SIZE)
+#define FIXADDR_BOOT_START	(FIXADDR_TOP - FIXADDR_BOOT_SIZE)
 
 extern int fixmaps_set;
 
@@ -69,4 +213,5 @@ static inline unsigned long virt_to_fix(const unsigned long vaddr)
 	BUG_ON(vaddr >= FIXADDR_TOP || vaddr < FIXADDR_START);
 	return __virt_to_fix(vaddr);
 }
+#endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_FIXMAP_H */

commit fd9409343521eac22b6ed51686128a643c7c976b
Author: Keith Packard <keithp@keithp.com>
Date:   Thu Oct 30 19:37:09 2008 -0700

    x86: add iomap_atomic*()/iounmap_atomic() on 32-bit using fixmaps
    
    Impact: introduce new APIs, separate kmap code from CONFIG_HIGHMEM
    
    This takes the code used for CONFIG_HIGHMEM memory mappings except that
    it's designed for dynamic IO resource mapping.
    
    These fixmaps are available even with CONFIG_HIGHMEM turned off.
    
    Signed-off-by: Keith Packard <keithp@keithp.com>
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 8668a94f850e..23696d44a0af 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -9,6 +9,10 @@
 
 extern int fixmaps_set;
 
+extern pte_t *kmap_pte;
+extern pgprot_t kmap_prot;
+extern pte_t *pkmap_page_table;
+
 void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
 void native_set_fixmap(enum fixed_addresses idx,
 		       unsigned long phys, pgprot_t flags);

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 78e33a1bc591..8668a94f850e 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__FIXMAP_H
-#define ASM_X86__FIXMAP_H
+#ifndef _ASM_X86_FIXMAP_H
+#define _ASM_X86_FIXMAP_H
 
 #ifdef CONFIG_X86_32
 # include "fixmap_32.h"
@@ -65,4 +65,4 @@ static inline unsigned long virt_to_fix(const unsigned long vaddr)
 	BUG_ON(vaddr >= FIXADDR_TOP || vaddr < FIXADDR_START);
 	return __virt_to_fix(vaddr);
 }
-#endif /* ASM_X86__FIXMAP_H */
+#endif /* _ASM_X86_FIXMAP_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
new file mode 100644
index 000000000000..78e33a1bc591
--- /dev/null
+++ b/arch/x86/include/asm/fixmap.h
@@ -0,0 +1,68 @@
+#ifndef ASM_X86__FIXMAP_H
+#define ASM_X86__FIXMAP_H
+
+#ifdef CONFIG_X86_32
+# include "fixmap_32.h"
+#else
+# include "fixmap_64.h"
+#endif
+
+extern int fixmaps_set;
+
+void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
+void native_set_fixmap(enum fixed_addresses idx,
+		       unsigned long phys, pgprot_t flags);
+
+#ifndef CONFIG_PARAVIRT
+static inline void __set_fixmap(enum fixed_addresses idx,
+				unsigned long phys, pgprot_t flags)
+{
+	native_set_fixmap(idx, phys, flags);
+}
+#endif
+
+#define set_fixmap(idx, phys)				\
+	__set_fixmap(idx, phys, PAGE_KERNEL)
+
+/*
+ * Some hardware wants to get fixmapped without caching.
+ */
+#define set_fixmap_nocache(idx, phys)			\
+	__set_fixmap(idx, phys, PAGE_KERNEL_NOCACHE)
+
+#define clear_fixmap(idx)			\
+	__set_fixmap(idx, 0, __pgprot(0))
+
+#define __fix_to_virt(x)	(FIXADDR_TOP - ((x) << PAGE_SHIFT))
+#define __virt_to_fix(x)	((FIXADDR_TOP - ((x)&PAGE_MASK)) >> PAGE_SHIFT)
+
+extern void __this_fixmap_does_not_exist(void);
+
+/*
+ * 'index to address' translation. If anyone tries to use the idx
+ * directly without translation, we catch the bug with a NULL-deference
+ * kernel oops. Illegal ranges of incoming indices are caught too.
+ */
+static __always_inline unsigned long fix_to_virt(const unsigned int idx)
+{
+	/*
+	 * this branch gets completely eliminated after inlining,
+	 * except when someone tries to use fixaddr indices in an
+	 * illegal way. (such as mixing up address types or using
+	 * out-of-range indices).
+	 *
+	 * If it doesn't get removed, the linker will complain
+	 * loudly with a reasonably clear error message..
+	 */
+	if (idx >= __end_of_fixed_addresses)
+		__this_fixmap_does_not_exist();
+
+	return __fix_to_virt(idx);
+}
+
+static inline unsigned long virt_to_fix(const unsigned long vaddr)
+{
+	BUG_ON(vaddr >= FIXADDR_TOP || vaddr < FIXADDR_START);
+	return __virt_to_fix(vaddr);
+}
+#endif /* ASM_X86__FIXMAP_H */
