commit 8b4d37db9a566deaf22065ba1ba9b19c9fb964b4
Merge: abfbb29297c2 3798cc4d106e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 9 09:30:21 2020 -0700

    Merge branch 'x86/srbds' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 srbds fixes from Thomas Gleixner:
     "The 9th episode of the dime novel "The performance killer" with the
      subtitle "Slow Randomizing Boosts Denial of Service".
    
      SRBDS is an MDS-like speculative side channel that can leak bits from
      the random number generator (RNG) across cores and threads. New
      microcode serializes the processor access during the execution of
      RDRAND and RDSEED. This ensures that the shared buffer is overwritten
      before it is released for reuse. This is equivalent to a full bus
      lock, which means that many threads running the RNG instructions in
      parallel have the same effect as the same amount of threads issuing a
      locked instruction targeting an address which requires locking of two
      cachelines at once.
    
      The mitigation support comes with the usual pile of unpleasant
      ingredients:
    
       - command line options
    
       - sysfs file
    
       - microcode checks
    
       - a list of vulnerable CPUs identified by model and stepping this
         time which requires stepping match support for the cpu match logic.
    
       - the inevitable slowdown of affected CPUs"
    
    * branch 'x86/srbds' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/speculation: Add Ivy Bridge to affected list
      x86/speculation: Add SRBDS vulnerability and mitigation documentation
      x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation
      x86/cpu: Add 'table' argument to cpu_matches()

commit 5cde265384cad739b162cf08afba6da8857778bd
Author: Stephane Eranian <eranian@google.com>
Date:   Wed May 27 15:46:59 2020 -0700

    perf/x86/rapl: Add AMD Fam17h RAPL support
    
    This patch enables AMD Fam17h RAPL support for the Package level metric.
    The support is as per AMD Fam17h Model31h (Zen2) and model 00-ffh (Zen1) PPR.
    
    The same output is available via the energy-pkg pseudo event:
    
      $ perf stat -a -I 1000 --per-socket -e power/energy-pkg/
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20200527224659.206129-6-eranian@google.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 12c9684d59ba..ef452b817f44 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -301,6 +301,9 @@
 #define MSR_PP1_ENERGY_STATUS		0x00000641
 #define MSR_PP1_POLICY			0x00000642
 
+#define MSR_AMD_PKG_ENERGY_STATUS	0xc001029b
+#define MSR_AMD_RAPL_POWER_UNIT		0xc0010299
+
 /* Config TDP MSRs */
 #define MSR_CONFIG_TDP_NOMINAL		0x00000648
 #define MSR_CONFIG_TDP_LEVEL_1		0x00000649

commit 7e5b3c267d256822407a22fdce6afdf9cd13f9fb
Author: Mark Gross <mgross@linux.intel.com>
Date:   Thu Apr 16 17:54:04 2020 +0200

    x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation
    
    SRBDS is an MDS-like speculative side channel that can leak bits from the
    random number generator (RNG) across cores and threads. New microcode
    serializes the processor access during the execution of RDRAND and
    RDSEED. This ensures that the shared buffer is overwritten before it is
    released for reuse.
    
    While it is present on all affected CPU models, the microcode mitigation
    is not needed on models that enumerate ARCH_CAPABILITIES[MDS_NO] in the
    cases where TSX is not supported or has been disabled with TSX_CTRL.
    
    The mitigation is activated by default on affected processors and it
    increases latency for RDRAND and RDSEED instructions. Among other
    effects this will reduce throughput from /dev/urandom.
    
    * Enable administrator to configure the mitigation off when desired using
      either mitigations=off or srbds=off.
    
    * Export vulnerability status via sysfs
    
    * Rename file-scoped macros to apply for non-whitelist table initializations.
    
     [ bp: Massage,
       - s/VULNBL_INTEL_STEPPING/VULNBL_INTEL_STEPPINGS/g,
       - do not read arch cap MSR a second time in tsx_fused_off() - just pass it in,
       - flip check in cpu_set_bug_bits() to save an indentation level,
       - reflow comments.
       jpoimboe: s/Mitigated/Mitigation/ in user-visible strings
       tglx: Dropped the fused off magic for now
     ]
    
    Signed-off-by: Mark Gross <mgross@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Reviewed-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Neelima Krishnan <neelima.krishnan@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 12c9684d59ba..3efde600a674 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -128,6 +128,10 @@
 #define TSX_CTRL_RTM_DISABLE		BIT(0)	/* Disable RTM feature */
 #define TSX_CTRL_CPUID_CLEAR		BIT(1)	/* Disable TSX enumeration */
 
+/* SRBDS support */
+#define MSR_IA32_MCU_OPT_CTRL		0x00000123
+#define RNGDS_MITG_DIS			BIT(0)
+
 #define MSR_IA32_SYSENTER_CS		0x00000174
 #define MSR_IA32_SYSENTER_ESP		0x00000175
 #define MSR_IA32_SYSENTER_EIP		0x00000176

commit 2853d5fafb1e21707e89aa2e227c90bb2c1ea4a9
Merge: d5f744f9a2ac a6a60741035b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 30 19:35:52 2020 -0700

    Merge tag 'x86-splitlock-2020-03-30' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 splitlock updates from Thomas Gleixner:
     "Support for 'split lock' detection:
    
      Atomic operations (lock prefixed instructions) which span two cache
      lines have to acquire the global bus lock. This is at least 1k cycles
      slower than an atomic operation within a cache line and disrupts
      performance on other cores. Aside of performance disruption this is a
      unpriviledged form of DoS.
    
      Some newer CPUs have the capability to raise an #AC trap when such an
      operation is attempted. The detection is by default enabled in warning
      mode which will warn once when a user space application is caught. A
      command line option allows to disable the detection or to select fatal
      mode which will terminate offending applications with SIGBUS"
    
    * tag 'x86-splitlock-2020-03-30' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/split_lock: Avoid runtime reads of the TEST_CTRL MSR
      x86/split_lock: Rework the initialization flow of split lock detection
      x86/split_lock: Enable split lock detection by kernel

commit 6650cdd9a8ccf00555dbbe743d58541ad8feb6a7
Author: Peter Zijlstra (Intel) <peterz@infradead.org>
Date:   Sun Jan 26 12:05:35 2020 -0800

    x86/split_lock: Enable split lock detection by kernel
    
    A split-lock occurs when an atomic instruction operates on data that spans
    two cache lines. In order to maintain atomicity the core takes a global bus
    lock.
    
    This is typically >1000 cycles slower than an atomic operation within a
    cache line. It also disrupts performance on other cores (which must wait
    for the bus lock to be released before their memory operations can
    complete). For real-time systems this may mean missing deadlines. For other
    systems it may just be very annoying.
    
    Some CPUs have the capability to raise an #AC trap when a split lock is
    attempted.
    
    Provide a command line option to give the user choices on how to handle
    this:
    
    split_lock_detect=
            off     - not enabled (no traps for split locks)
            warn    - warn once when an application does a
                      split lock, but allow it to continue
                      running.
            fatal   - Send SIGBUS to applications that cause split lock
    
    On systems that support split lock detection the default is "warn". Note
    that if the kernel hits a split lock in any mode other than "off" it will
    OOPs.
    
    One implementation wrinkle is that the MSR to control the split lock
    detection is per-core, not per thread. This might result in some short
    lived races on HT systems in "warn" mode if Linux tries to enable on one
    thread while disabling on the other. Race analysis by Sean Christopherson:
    
      - Toggling of split-lock is only done in "warn" mode.  Worst case
        scenario of a race is that a misbehaving task will generate multiple
        #AC exceptions on the same instruction.  And this race will only occur
        if both siblings are running tasks that generate split-lock #ACs, e.g.
        a race where sibling threads are writing different values will only
        occur if CPUx is disabling split-lock after an #AC and CPUy is
        re-enabling split-lock after *its* previous task generated an #AC.
      - Transitioning between off/warn/fatal modes at runtime isn't supported
        and disabling is tracked per task, so hardware will always reach a steady
        state that matches the configured mode.  I.e. split-lock is guaranteed to
        be enabled in hardware once all _TIF_SLD threads have been scheduled out.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Co-developed-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Co-developed-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20200126200535.GB30377@agluck-desk2.amr.corp.intel.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ebe1685e92dd..8821697a7549 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -41,6 +41,10 @@
 
 /* Intel MSRs. Some also available on other CPUs */
 
+#define MSR_TEST_CTRL				0x00000033
+#define MSR_TEST_CTRL_SPLIT_LOCK_DETECT_BIT	29
+#define MSR_TEST_CTRL_SPLIT_LOCK_DETECT		BIT(MSR_TEST_CTRL_SPLIT_LOCK_DETECT_BIT)
+
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
 #define SPEC_CTRL_IBRS			BIT(0)	   /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP_SHIFT		1	   /* Single Thread Indirect Branch Predictor (STIBP) bit */
@@ -70,6 +74,11 @@
  */
 #define MSR_IA32_UMWAIT_CONTROL_TIME_MASK	(~0x03U)
 
+/* Abbreviated from Intel SDM name IA32_CORE_CAPABILITIES */
+#define MSR_IA32_CORE_CAPS			  0x000000cf
+#define MSR_IA32_CORE_CAPS_SPLIT_LOCK_DETECT_BIT  5
+#define MSR_IA32_CORE_CAPS_SPLIT_LOCK_DETECT	  BIT(MSR_IA32_CORE_CAPS_SPLIT_LOCK_DETECT_BIT)
+
 #define MSR_PKG_CST_CONFIG_CONTROL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)

commit 21b5ee59ef18e27d85810584caf1f7ddc705ea83
Author: Kim Phillips <kim.phillips@amd.com>
Date:   Wed Feb 19 18:52:43 2020 +0100

    x86/cpu/amd: Enable the fixed Instructions Retired counter IRPERF
    
    Commit
    
      aaf248848db50 ("perf/x86/msr: Add AMD IRPERF (Instructions Retired)
                      performance counter")
    
    added support for access to the free-running counter via 'perf -e
    msr/irperf/', but when exercised, it always returns a 0 count:
    
    BEFORE:
    
      $ perf stat -e instructions,msr/irperf/ true
    
       Performance counter stats for 'true':
    
                 624,833      instructions
                       0      msr/irperf/
    
    Simply set its enable bit - HWCR bit 30 - to make it start counting.
    
    Enablement is restricted to all machines advertising IRPERF capability,
    except those susceptible to an erratum that makes the IRPERF return
    bad values.
    
    That erratum occurs in Family 17h models 00-1fh [1], but not in F17h
    models 20h and above [2].
    
    AFTER (on a family 17h model 31h machine):
    
      $ perf stat -e instructions,msr/irperf/ true
    
       Performance counter stats for 'true':
    
                 621,690      instructions
                 622,490      msr/irperf/
    
    [1] Revision Guide for AMD Family 17h Models 00h-0Fh Processors
    [2] Revision Guide for AMD Family 17h Models 30h-3Fh Processors
    
    The revision guides are available from the bugzilla Link below.
    
     [ bp: Massage commit message. ]
    
    Fixes: aaf248848db50 ("perf/x86/msr: Add AMD IRPERF (Instructions Retired) performance counter")
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: stable@vger.kernel.org
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=206537
    Link: http://lkml.kernel.org/r/20200214201805.13830-1-kim.phillips@amd.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ebe1685e92dd..d5e517d1c3dd 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -512,6 +512,8 @@
 #define MSR_K7_HWCR			0xc0010015
 #define MSR_K7_HWCR_SMMLOCK_BIT		0
 #define MSR_K7_HWCR_SMMLOCK		BIT_ULL(MSR_K7_HWCR_SMMLOCK_BIT)
+#define MSR_K7_HWCR_IRPERF_EN_BIT	30
+#define MSR_K7_HWCR_IRPERF_EN		BIT_ULL(MSR_K7_HWCR_IRPERF_EN_BIT)
 #define MSR_K7_FID_VID_CTL		0xc0010041
 #define MSR_K7_FID_VID_STATUS		0xc0010042
 

commit 32ad73db7fc5fe7eebafdab3b528f99ab8498e3f
Author: Sean Christopherson <sean.j.christopherson@intel.com>
Date:   Fri Dec 20 20:44:55 2019 -0800

    x86/msr-index: Clean up bit defines for IA32_FEATURE_CONTROL MSR
    
    As pointed out by Boris, the defines for bits in IA32_FEATURE_CONTROL
    are quite a mouthful, especially the VMX bits which must differentiate
    between enabling VMX inside and outside SMX (TXT) operation.  Rename the
    MSR and its bit defines to abbreviate FEATURE_CONTROL as FEAT_CTL to
    make them a little friendlier on the eyes.
    
    Arguably, the MSR itself should keep the full IA32_FEATURE_CONTROL name
    to match Intel's SDM, but a future patch will add a dedicated Kconfig,
    file and functions for the MSR. Using the full name for those assets is
    rather unwieldy, so bite the bullet and use IA32_FEAT_CTL so that its
    nomenclature is consistent throughout the kernel.
    
    Opportunistically, fix a few other annoyances with the defines:
    
      - Relocate the bit defines so that they immediately follow the MSR
        define, e.g. aren't mistaken as belonging to MISC_FEATURE_CONTROL.
      - Add whitespace around the block of feature control defines to make
        it clear they're all related.
      - Use BIT() instead of manually encoding the bit shift.
      - Use "VMX" instead of "VMXON" to match the SDM.
      - Append "_ENABLED" to the LMCE (Local Machine Check Exception) bit to
        be consistent with the kernel's verbiage used for all other feature
        control bits.  Note, the SDM refers to the LMCE bit as LMCE_ON,
        likely to differentiate it from IA32_MCG_EXT_CTL.LMCE_EN.  Ignore
        the (literal) one-off usage of _ON, the SDM is simply "wrong".
    
    Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20191221044513.21680-2-sean.j.christopherson@intel.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 084e98da04a7..ebe1685e92dd 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -558,7 +558,14 @@
 #define MSR_IA32_EBL_CR_POWERON		0x0000002a
 #define MSR_EBC_FREQUENCY_ID		0x0000002c
 #define MSR_SMI_COUNT			0x00000034
-#define MSR_IA32_FEATURE_CONTROL        0x0000003a
+
+/* Referred to as IA32_FEATURE_CONTROL in Intel's SDM. */
+#define MSR_IA32_FEAT_CTL		0x0000003a
+#define FEAT_CTL_LOCKED				BIT(0)
+#define FEAT_CTL_VMX_ENABLED_INSIDE_SMX		BIT(1)
+#define FEAT_CTL_VMX_ENABLED_OUTSIDE_SMX	BIT(2)
+#define FEAT_CTL_LMCE_ENABLED			BIT(20)
+
 #define MSR_IA32_TSC_ADJUST             0x0000003b
 #define MSR_IA32_BNDCFGS		0x00000d90
 
@@ -566,11 +573,6 @@
 
 #define MSR_IA32_XSS			0x00000da0
 
-#define FEATURE_CONTROL_LOCKED				(1<<0)
-#define FEATURE_CONTROL_VMXON_ENABLED_INSIDE_SMX	(1<<1)
-#define FEATURE_CONTROL_VMXON_ENABLED_OUTSIDE_SMX	(1<<2)
-#define FEATURE_CONTROL_LMCE				(1<<20)
-
 #define MSR_IA32_APICBASE		0x0000001b
 #define MSR_IA32_APICBASE_BSP		(1<<8)
 #define MSR_IA32_APICBASE_ENABLE	(1<<11)

commit 3f3c8be973af10875cfa1e7b85a535b6ba76b44f
Merge: 2981dcf333b3 23c1cce9f317
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 25 17:45:31 2019 -0800

    Merge tag 'for-linus-5.5a-rc1-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip
    
    Pull xen updates from Juergen Gross:
    
     - a small series to remove the build constraint of Xen x86 MCE handling
       to 64-bit only
    
     - a bunch of minor cleanups
    
    * tag 'for-linus-5.5a-rc1-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip:
      xen: Fix Kconfig indentation
      xen/mcelog: also allow building for 32-bit kernels
      xen/mcelog: add PPIN to record when available
      xen/mcelog: drop __MC_MSR_MCGCAP
      xen/gntdev: Use select for DMA_SHARED_BUFFER
      xen: mm: make xen_mm_init static
      xen: mm: include <xen/xen-ops.h> for missing declarations

commit 4e3f77d8419b6787f3eb4d4f5178f459d693f9bb
Author: Jan Beulich <jbeulich@suse.com>
Date:   Mon Nov 11 15:46:26 2019 +0100

    xen/mcelog: add PPIN to record when available
    
    This is to augment commit 3f5a7896a5 ("x86/mce: Include the PPIN in MCE
    records when available").
    
    I'm also adding "synd" and "ipid" fields to struct xen_mce, in an
    attempt to keep field offsets in sync with struct mce. These two fields
    won't get populated for now, though.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 20ce682a2540..6ec319ecb001 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -393,6 +393,8 @@
 #define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
 #define MSR_AMD64_OSVW_STATUS		0xc0010141
+#define MSR_AMD_PPIN_CTL		0xc00102f0
+#define MSR_AMD_PPIN			0xc00102f1
 #define MSR_AMD64_LS_CFG		0xc0011020
 #define MSR_AMD64_DC_CFG		0xc0011022
 #define MSR_AMD64_BU_CFG2		0xc001102a

commit db4d30fbb71b47e4ecb11c4efa5d8aad4b03dfae
Author: Vineela Tummalapalli <vineela.tummalapalli@intel.com>
Date:   Mon Nov 4 12:22:01 2019 +0100

    x86/bugs: Add ITLB_MULTIHIT bug infrastructure
    
    Some processors may incur a machine check error possibly resulting in an
    unrecoverable CPU lockup when an instruction fetch encounters a TLB
    multi-hit in the instruction TLB. This can occur when the page size is
    changed along with either the physical address or cache type. The relevant
    erratum can be found here:
    
       https://bugzilla.kernel.org/show_bug.cgi?id=205195
    
    There are other processors affected for which the erratum does not fully
    disclose the impact.
    
    This issue affects both bare-metal x86 page tables and EPT.
    
    It can be mitigated by either eliminating the use of large pages or by
    using careful TLB invalidations when changing the page size in the page
    tables.
    
    Just like Spectre, Meltdown, L1TF and MDS, a new bit has been allocated in
    MSR_IA32_ARCH_CAPABILITIES (PSCHANGE_MC_NO) and will be set on CPUs which
    are mitigated against this issue.
    
    Signed-off-by: Vineela Tummalapalli <vineela.tummalapalli@intel.com>
    Co-developed-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b3a8bb2af0b6..6a3124664289 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -93,6 +93,13 @@
 						  * Microarchitectural Data
 						  * Sampling (MDS) vulnerabilities.
 						  */
+#define ARCH_CAP_PSCHANGE_MC_NO		BIT(6)	 /*
+						  * The processor is not susceptible to a
+						  * machine check error due to modifying the
+						  * code page size along with either the
+						  * physical address or cache type
+						  * without TLB invalidation.
+						  */
 #define ARCH_CAP_TSX_CTRL_MSR		BIT(7)	/* MSR for TSX control is available. */
 #define ARCH_CAP_TAA_NO			BIT(8)	/*
 						 * Not susceptible to

commit 1b42f017415b46c317e71d41c34ec088417a1883
Author: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Date:   Wed Oct 23 11:30:45 2019 +0200

    x86/speculation/taa: Add mitigation for TSX Async Abort
    
    TSX Async Abort (TAA) is a side channel vulnerability to the internal
    buffers in some Intel processors similar to Microachitectural Data
    Sampling (MDS). In this case, certain loads may speculatively pass
    invalid data to dependent operations when an asynchronous abort
    condition is pending in a TSX transaction.
    
    This includes loads with no fault or assist condition. Such loads may
    speculatively expose stale data from the uarch data structures as in
    MDS. Scope of exposure is within the same-thread and cross-thread. This
    issue affects all current processors that support TSX, but do not have
    ARCH_CAP_TAA_NO (bit 8) set in MSR_IA32_ARCH_CAPABILITIES.
    
    On CPUs which have their IA32_ARCH_CAPABILITIES MSR bit MDS_NO=0,
    CPUID.MD_CLEAR=1 and the MDS mitigation is clearing the CPU buffers
    using VERW or L1D_FLUSH, there is no additional mitigation needed for
    TAA. On affected CPUs with MDS_NO=1 this issue can be mitigated by
    disabling the Transactional Synchronization Extensions (TSX) feature.
    
    A new MSR IA32_TSX_CTRL in future and current processors after a
    microcode update can be used to control the TSX feature. There are two
    bits in that MSR:
    
    * TSX_CTRL_RTM_DISABLE disables the TSX sub-feature Restricted
    Transactional Memory (RTM).
    
    * TSX_CTRL_CPUID_CLEAR clears the RTM enumeration in CPUID. The other
    TSX sub-feature, Hardware Lock Elision (HLE), is unconditionally
    disabled with updated microcode but still enumerated as present by
    CPUID(EAX=7).EBX{bit4}.
    
    The second mitigation approach is similar to MDS which is clearing the
    affected CPU buffers on return to user space and when entering a guest.
    Relevant microcode update is required for the mitigation to work.  More
    details on this approach can be found here:
    
      https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/mds.html
    
    The TSX feature can be controlled by the "tsx" command line parameter.
    If it is force-enabled then "Clear CPU buffers" (MDS mitigation) is
    deployed. The effective mitigation state can be read from sysfs.
    
     [ bp:
       - massage + comments cleanup
       - s/TAA_MITIGATION_TSX_DISABLE/TAA_MITIGATION_TSX_DISABLED/g - Josh.
       - remove partial TAA mitigation in update_mds_branch_idle() - Josh.
       - s/tsx_async_abort_cmdline/tsx_async_abort_parse_cmdline/g
     ]
    
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index da4caf6da739..b3a8bb2af0b6 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -94,6 +94,10 @@
 						  * Sampling (MDS) vulnerabilities.
 						  */
 #define ARCH_CAP_TSX_CTRL_MSR		BIT(7)	/* MSR for TSX control is available. */
+#define ARCH_CAP_TAA_NO			BIT(8)	/*
+						 * Not susceptible to
+						 * TSX Async Abort (TAA) vulnerabilities.
+						 */
 
 #define MSR_IA32_FLUSH_CMD		0x0000010b
 #define L1D_FLUSH			BIT(0)	/*

commit c2955f270a84762343000f103e0640d29c7a96f3
Author: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Date:   Wed Oct 23 10:45:50 2019 +0200

    x86/msr: Add the IA32_TSX_CTRL MSR
    
    Transactional Synchronization Extensions (TSX) may be used on certain
    processors as part of a speculative side channel attack.  A microcode
    update for existing processors that are vulnerable to this attack will
    add a new MSR - IA32_TSX_CTRL to allow the system administrator the
    option to disable TSX as one of the possible mitigations.
    
    The CPUs which get this new MSR after a microcode upgrade are the ones
    which do not set MSR_IA32_ARCH_CAPABILITIES.MDS_NO (bit 5) because those
    CPUs have CPUID.MD_CLEAR, i.e., the VERW implementation which clears all
    CPU buffers takes care of the TAA case as well.
    
      [ Note that future processors that are not vulnerable will also
        support the IA32_TSX_CTRL MSR. ]
    
    Add defines for the new IA32_TSX_CTRL MSR and its bits.
    
    TSX has two sub-features:
    
    1. Restricted Transactional Memory (RTM) is an explicitly-used feature
       where new instructions begin and end TSX transactions.
    2. Hardware Lock Elision (HLE) is implicitly used when certain kinds of
       "old" style locks are used by software.
    
    Bit 7 of the IA32_ARCH_CAPABILITIES indicates the presence of the
    IA32_TSX_CTRL MSR.
    
    There are two control bits in IA32_TSX_CTRL MSR:
    
      Bit 0: When set, it disables the Restricted Transactional Memory (RTM)
             sub-feature of TSX (will force all transactions to abort on the
             XBEGIN instruction).
    
      Bit 1: When set, it disables the enumeration of the RTM and HLE feature
             (i.e. it will make CPUID(EAX=7).EBX{bit4} and
              CPUID(EAX=7).EBX{bit11} read as 0).
    
    The other TSX sub-feature, Hardware Lock Elision (HLE), is
    unconditionally disabled by the new microcode but still enumerated
    as present by CPUID(EAX=7).EBX{bit4}, unless disabled by
    IA32_TSX_CTRL_MSR[1] - TSX_CTRL_CPUID_CLEAR.
    
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Neelima Krishnan <neelima.krishnan@intel.com>
    Reviewed-by: Mark Gross <mgross@linux.intel.com>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 20ce682a2540..da4caf6da739 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -93,6 +93,7 @@
 						  * Microarchitectural Data
 						  * Sampling (MDS) vulnerabilities.
 						  */
+#define ARCH_CAP_TSX_CTRL_MSR		BIT(7)	/* MSR for TSX control is available. */
 
 #define MSR_IA32_FLUSH_CMD		0x0000010b
 #define L1D_FLUSH			BIT(0)	/*
@@ -103,6 +104,10 @@
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e
 
+#define MSR_IA32_TSX_CTRL		0x00000122
+#define TSX_CTRL_RTM_DISABLE		BIT(0)	/* Disable RTM feature */
+#define TSX_CTRL_CPUID_CLEAR		BIT(1)	/* Disable TSX enumeration */
+
 #define MSR_IA32_SYSENTER_CS		0x00000174
 #define MSR_IA32_SYSENTER_ESP		0x00000175
 #define MSR_IA32_SYSENTER_EIP		0x00000176

commit 22331f895298bd23ca9f99f6a237aae883c9e1c7
Merge: fc6fd1392a8f 0cc5359d8fd4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 16 18:47:53 2019 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 cpu-feature updates from Ingo Molnar:
    
     - Rework the Intel model names symbols/macros, which were decades of
       ad-hoc extensions and added random noise. It's now a coherent, easy
       to follow nomenclature.
    
     - Add new Intel CPU model IDs:
        - "Tiger Lake" desktop and mobile models
        - "Elkhart Lake" model ID
        - and the "Lightning Mountain" variant of Airmont, plus support code
    
     - Add the new AVX512_VP2INTERSECT instruction to cpufeatures
    
     - Remove Intel MPX user-visible APIs and the self-tests, because the
       toolchain (gcc) is not supporting it going forward. This is the
       first, lowest-risk phase of MPX removal.
    
     - Remove X86_FEATURE_MFENCE_RDTSC
    
     - Various smaller cleanups and fixes
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (25 commits)
      x86/cpu: Update init data for new Airmont CPU model
      x86/cpu: Add new Airmont variant to Intel family
      x86/cpu: Add Elkhart Lake to Intel family
      x86/cpu: Add Tiger Lake to Intel family
      x86: Correct misc typos
      x86/intel: Add common OPTDIFFs
      x86/intel: Aggregate microserver naming
      x86/intel: Aggregate big core graphics naming
      x86/intel: Aggregate big core mobile naming
      x86/intel: Aggregate big core client naming
      x86/cpufeature: Explain the macro duplication
      x86/ftrace: Remove mcount() declaration
      x86/PCI: Remove superfluous returns from void functions
      x86/msr-index: Move AMD MSRs where they belong
      x86/cpu: Use constant definitions for CPU models
      lib: Remove redundant ftrace flag removal
      x86/crash: Remove unnecessary comparison
      x86/bitops: Use __builtin_constant_p() directly instead of IS_IMMEDIATE()
      x86: Remove X86_FEATURE_MFENCE_RDTSC
      x86/mpx: Remove MPX APIs
      ...

commit 42880f726c66f13ae1d9ac9ce4c43abe64ecac84
Author: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Date:   Tue Aug 6 11:46:01 2019 +0300

    perf/x86/intel: Support PEBS output to PT
    
    If PEBS declares ability to output its data to Intel PT stream, use the
    aux_output attribute bit to enable PEBS data output to PT. This requires
    a PT event to be present and scheduled in the same context. Unlike the
    DS area, the kernel does not extract PEBS records from the PT stream to
    generate corresponding records in the perf stream, because that would
    require real time in-kernel PT decoding, which is not feasible. The PMI,
    however, can still be used.
    
    The output setting is per-CPU, so all PEBS events must be either writing
    to PT or to the DS area, therefore, in case of conflict, the conflicting
    event will fail to schedule, allowing the rotation logic to alternate
    between the PEBS->PT and PEBS->DS events.
    
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: kan.liang@linux.intel.com
    Link: https://lkml.kernel.org/r/20190806084606.4021-3-alexander.shishkin@linux.intel.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 271d837d69a8..de753206b427 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -375,6 +375,10 @@
 /* Alternative perfctr range with full access. */
 #define MSR_IA32_PMC0			0x000004c1
 
+/* Auto-reload via MSR instead of DS area */
+#define MSR_RELOAD_PMC0			0x000014c1
+#define MSR_RELOAD_FIXED_CTR0		0x00001309
+
 /* AMD64 MSRs. Not complete. See the architecture manual for a more
    complete list. */
 

commit b3e30c9884407599353e690a4eb36d0c4671bf62
Merge: 342061c53a04 a55aa89aab90
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Aug 26 11:20:55 2019 +0200

    Merge tag 'v5.3-rc6' into x86/cpu, to pick up fixes
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit c49a0a80137c7ca7d6ced4c812c9e07a949f6f24
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Aug 19 15:52:35 2019 +0000

    x86/CPU/AMD: Clear RDRAND CPUID bit on AMD family 15h/16h
    
    There have been reports of RDRAND issues after resuming from suspend on
    some AMD family 15h and family 16h systems. This issue stems from a BIOS
    not performing the proper steps during resume to ensure RDRAND continues
    to function properly.
    
    RDRAND support is indicated by CPUID Fn00000001_ECX[30]. This bit can be
    reset by clearing MSR C001_1004[62]. Any software that checks for RDRAND
    support using CPUID, including the kernel, will believe that RDRAND is
    not supported.
    
    Update the CPU initialization to clear the RDRAND CPUID bit for any family
    15h and 16h processor that supports RDRAND. If it is known that the family
    15h or family 16h system does not have an RDRAND resume issue or that the
    system will not be placed in suspend, the "rdrand=force" kernel parameter
    can be used to stop the clearing of the RDRAND CPUID bit.
    
    Additionally, update the suspend and resume path to save and restore the
    MSR C001_1004 value to ensure that the RDRAND CPUID setting remains in
    place after resuming from suspend.
    
    Note, that clearing the RDRAND CPUID bit does not prevent a processor
    that normally supports the RDRAND instruction from executing it. So any
    code that determined the support based on family and model won't #UD.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Cooper <andrew.cooper3@citrix.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Chen Yu <yu.c.chen@intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: "linux-doc@vger.kernel.org" <linux-doc@vger.kernel.org>
    Cc: "linux-pm@vger.kernel.org" <linux-pm@vger.kernel.org>
    Cc: Nathan Chancellor <natechancellor@gmail.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: <stable@vger.kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "x86@kernel.org" <x86@kernel.org>
    Link: https://lkml.kernel.org/r/7543af91666f491547bd86cebb1e17c66824ab9f.1566229943.git.thomas.lendacky@amd.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6b4fc2788078..271d837d69a8 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -381,6 +381,7 @@
 #define MSR_AMD64_PATCH_LEVEL		0x0000008b
 #define MSR_AMD64_TSC_RATIO		0xc0000104
 #define MSR_AMD64_NB_CFG		0xc001001f
+#define MSR_AMD64_CPUID_FN_1		0xc0011004
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
 #define MSR_AMD64_OSVW_STATUS		0xc0010141

commit 342061c53a049569fc7f56d237753c26b4b2166d
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Aug 19 09:01:40 2019 +0200

    x86/msr-index: Move AMD MSRs where they belong
    
    ... sort them in and fixup comment, while at it.
    
    No functional changes.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20190819070140.23708-1-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6b4fc2788078..f9a01a04c708 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -375,13 +375,17 @@
 /* Alternative perfctr range with full access. */
 #define MSR_IA32_PMC0			0x000004c1
 
-/* AMD64 MSRs. Not complete. See the architecture manual for a more
-   complete list. */
-
+/*
+ * AMD64 MSRs. Not complete. See the architecture manual for a more
+ * complete list.
+ */
 #define MSR_AMD64_PATCH_LEVEL		0x0000008b
 #define MSR_AMD64_TSC_RATIO		0xc0000104
 #define MSR_AMD64_NB_CFG		0xc001001f
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
+#define MSR_AMD_PERF_CTL		0xc0010062
+#define MSR_AMD_PERF_STATUS		0xc0010063
+#define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
 #define MSR_AMD64_OSVW_STATUS		0xc0010141
 #define MSR_AMD64_LS_CFG		0xc0011020
@@ -560,9 +564,6 @@
 #define MSR_IA32_PERF_STATUS		0x00000198
 #define MSR_IA32_PERF_CTL		0x00000199
 #define INTEL_PERF_CTL_MASK		0xffff
-#define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
-#define MSR_AMD_PERF_STATUS		0xc0010063
-#define MSR_AMD_PERF_CTL		0xc0010062
 
 #define MSR_IA32_MPERF			0x000000e7
 #define MSR_IA32_APERF			0x000000e8

commit bd688c69b7e6693de3bd78f38fd63f7850c2711e
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Wed Jun 19 18:33:55 2019 -0700

    x86/umwait: Initialize umwait control values
    
    umwait or tpause allows the processor to enter a light-weight
    power/performance optimized state (C0.1 state) or an improved
    power/performance optimized state (C0.2 state) for a period specified by
    the instruction or until the system time limit or until a store to the
    monitored address range in umwait.
    
    IA32_UMWAIT_CONTROL MSR register allows the OS to enable/disable C0.2 on
    the processor and to set the maximum time the processor can reside in C0.1
    or C0.2.
    
    By default C0.2 is enabled so the user wait instructions can enter the
    C0.2 state to save more power with slower wakeup time.
    
    Andy Lutomirski proposed to set the maximum umwait time to 100000 cycles by
    default. A quote from Andy:
    
      "What I want to avoid is the case where it works dramatically differently
       on NO_HZ_FULL systems as compared to everything else. Also, UMWAIT may
       behave a bit differently if the max timeout is hit, and I'd like that
       path to get exercised widely by making it happen even on default
       configs."
    
    A sysfs interface to adjust the time and the C0.2 enablement is provided in
    a follow up change.
    
    [ tglx: Renamed MSR_IA32_UMWAIT_CONTROL_MAX_TIME to
            MSR_IA32_UMWAIT_CONTROL_TIME_MASK because the constant is used as
            mask throughout the code.
            Massaged comments and changelog ]
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ashok Raj <ashok.raj@intel.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Cc: "Borislav Petkov" <bp@alien8.de>
    Cc: "H Peter Anvin" <hpa@zytor.com>
    Cc: "Peter Zijlstra" <peterz@infradead.org>
    Cc: "Tony Luck" <tony.luck@intel.com>
    Cc: "Ravi V Shankar" <ravi.v.shankar@intel.com>
    Link: https://lkml.kernel.org/r/1560994438-235698-3-git-send-email-fenghua.yu@intel.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 979ef971cc78..6b4fc2788078 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -61,6 +61,15 @@
 #define MSR_PLATFORM_INFO_CPUID_FAULT_BIT	31
 #define MSR_PLATFORM_INFO_CPUID_FAULT		BIT_ULL(MSR_PLATFORM_INFO_CPUID_FAULT_BIT)
 
+#define MSR_IA32_UMWAIT_CONTROL			0xe1
+#define MSR_IA32_UMWAIT_CONTROL_C02_DISABLE	BIT(0)
+#define MSR_IA32_UMWAIT_CONTROL_RESERVED	BIT(1)
+/*
+ * The time field is bit[31:2], but representing a 32bit value with
+ * bit[1:0] zero.
+ */
+#define MSR_IA32_UMWAIT_CONTROL_TIME_MASK	(~0x03U)
+
 #define MSR_PKG_CST_CONFIG_CONTROL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)

commit 0ef0fd351550130129bbdb77362488befd7b69d2
Merge: 4489da718309 c011d23ba046
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 17 10:33:30 2019 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
     "ARM:
       - support for SVE and Pointer Authentication in guests
       - PMU improvements
    
      POWER:
       - support for direct access to the POWER9 XIVE interrupt controller
       - memory and performance optimizations
    
      x86:
       - support for accessing memory not backed by struct page
       - fixes and refactoring
    
      Generic:
       - dirty page tracking improvements"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (155 commits)
      kvm: fix compilation on aarch64
      Revert "KVM: nVMX: Expose RDPMC-exiting only when guest supports PMU"
      kvm: x86: Fix L1TF mitigation for shadow MMU
      KVM: nVMX: Disable intercept for FS/GS base MSRs in vmcs02 when possible
      KVM: PPC: Book3S: Remove useless checks in 'release' method of KVM device
      KVM: PPC: Book3S HV: XIVE: Fix spelling mistake "acessing" -> "accessing"
      KVM: PPC: Book3S HV: Make sure to load LPID for radix VCPUs
      kvm: nVMX: Set nested_run_pending in vmx_set_nested_state after checks complete
      tests: kvm: Add tests for KVM_SET_NESTED_STATE
      KVM: nVMX: KVM_SET_NESTED_STATE - Tear down old EVMCS state before setting new state
      tests: kvm: Add tests for KVM_CAP_MAX_VCPUS and KVM_CAP_MAX_CPU_ID
      tests: kvm: Add tests to .gitignore
      KVM: Introduce KVM_CAP_MANUAL_DIRTY_LOG_PROTECT2
      KVM: Fix kvm_clear_dirty_log_protect off-by-(minus-)one
      KVM: Fix the bitmap range to copy during clear dirty
      KVM: arm64: Fix ptrauth ID register masking logic
      KVM: x86: use direct accessors for RIP and RSP
      KVM: VMX: Use accessors for GPRs outside of dedicated caching logic
      KVM: x86: Omit caching logic for always-available GPRs
      kvm, x86: Properly check whether a pfn is an MMIO or not
      ...

commit fa4bff165070dc40a3de35b78e4f8da8e8d85ec5
Merge: 63863ee8e2f6 95310e348a32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 14 07:57:29 2019 -0700

    Merge branch 'x86-mds-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 MDS mitigations from Thomas Gleixner:
     "Microarchitectural Data Sampling (MDS) is a hardware vulnerability
      which allows unprivileged speculative access to data which is
      available in various CPU internal buffers. This new set of misfeatures
      has the following CVEs assigned:
    
         CVE-2018-12126  MSBDS  Microarchitectural Store Buffer Data Sampling
         CVE-2018-12130  MFBDS  Microarchitectural Fill Buffer Data Sampling
         CVE-2018-12127  MLPDS  Microarchitectural Load Port Data Sampling
         CVE-2019-11091  MDSUM  Microarchitectural Data Sampling Uncacheable Memory
    
      MDS attacks target microarchitectural buffers which speculatively
      forward data under certain conditions. Disclosure gadgets can expose
      this data via cache side channels.
    
      Contrary to other speculation based vulnerabilities the MDS
      vulnerability does not allow the attacker to control the memory target
      address. As a consequence the attacks are purely sampling based, but
      as demonstrated with the TLBleed attack samples can be postprocessed
      successfully.
    
      The mitigation is to flush the microarchitectural buffers on return to
      user space and before entering a VM. It's bolted on the VERW
      instruction and requires a microcode update. As some of the attacks
      exploit data structures shared between hyperthreads, full protection
      requires to disable hyperthreading. The kernel does not do that by
      default to avoid breaking unattended updates.
    
      The mitigation set comes with documentation for administrators and a
      deeper technical view"
    
    * 'x86-mds-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      x86/speculation/mds: Fix documentation typo
      Documentation: Correct the possible MDS sysfs values
      x86/mds: Add MDSUM variant to the MDS documentation
      x86/speculation/mds: Add 'mitigations=' support for MDS
      x86/speculation/mds: Print SMT vulnerable on MSBDS with mitigations off
      x86/speculation/mds: Fix comment
      x86/speculation/mds: Add SMT warning message
      x86/speculation: Move arch_smt_update() call to after mitigation decisions
      x86/speculation/mds: Add mds=full,nosmt cmdline option
      Documentation: Add MDS vulnerability documentation
      Documentation: Move L1TF to separate directory
      x86/speculation/mds: Add mitigation mode VMWERV
      x86/speculation/mds: Add sysfs reporting for MDS
      x86/speculation/mds: Add mitigation control for MDS
      x86/speculation/mds: Conditionally clear CPU buffers on idle entry
      x86/kvm/vmx: Add MDS protection when L1D Flush is not active
      x86/speculation/mds: Clear CPU buffers on exit to user
      x86/speculation/mds: Add mds_clear_cpu_buffers()
      x86/kvm: Expose X86_FEATURE_MD_CLEAR to guests
      x86/speculation/mds: Add BUG_MSBDS_ONLY
      ...

commit c715eb9fe9027ed118630adb0d59acf36b848d4f
Author: Luwei Kang <luwei.kang@intel.com>
Date:   Mon Feb 18 19:26:08 2019 -0500

    KVM: x86: Add support of clear Trace_ToPA_PMI status
    
    Let guests clear the Intel PT ToPA PMI status (bit 55 of
    MSR_CORE_PERF_GLOBAL_OVF_CTRL).
    
    Signed-off-by: Luwei Kang <luwei.kang@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index be40c094bc49..3bf5d84bb64f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -784,6 +784,10 @@
 /* PERF_GLOBAL_OVF_CTL bits */
 #define MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI_BIT	55
 #define MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI		(1ULL << MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI_BIT)
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_OVF_BUF_BIT		62
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_OVF_BUF			(1ULL <<  MSR_CORE_PERF_GLOBAL_OVF_CTRL_OVF_BUF_BIT)
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_COND_CHGD_BIT		63
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_COND_CHGD			(1ULL << MSR_CORE_PERF_GLOBAL_OVF_CTRL_COND_CHGD_BIT)
 
 /* Geode defined MSRs */
 #define MSR_GEODE_BUSCONT_CONF0		0x00001900

commit 8479e04e7d6b1974629a0f657afa8ec5f17d2e90
Author: Luwei Kang <luwei.kang@intel.com>
Date:   Mon Feb 18 19:26:07 2019 -0500

    KVM: x86: Inject PMI for KVM guest
    
    Inject a PMI for KVM guest when Intel PT working
    in Host-Guest mode and Guest ToPA entry memory buffer
    was completely filled.
    
    Signed-off-by: Luwei Kang <luwei.kang@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ca5bc0eacb95..be40c094bc49 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -781,6 +781,10 @@
 #define MSR_CORE_PERF_GLOBAL_CTRL	0x0000038f
 #define MSR_CORE_PERF_GLOBAL_OVF_CTRL	0x00000390
 
+/* PERF_GLOBAL_OVF_CTL bits */
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI_BIT	55
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI		(1ULL << MSR_CORE_PERF_GLOBAL_OVF_CTRL_TRACE_TOPA_PMI_BIT)
+
 /* Geode defined MSRs */
 #define MSR_GEODE_BUSCONT_CONF0		0x00001900
 

commit c22497f5838c237e3094a4dfb99d1c5de6353239
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Tue Apr 2 12:45:02 2019 -0700

    perf/x86/intel: Support adaptive PEBS v4
    
    Adaptive PEBS is a new way to report PEBS sampling information. Instead
    of a fixed size record for all PEBS events it allows to configure the
    PEBS record to only include the information needed. Events can then opt
    in to use such an extended record, or stay with a basic record which
    only contains the IP.
    
    The major new feature is to support LBRs in PEBS record.
    Besides normal LBR, this allows (much faster) large PEBS, while still
    supporting callstacks through callstack LBR. So essentially a lot of
    profiling can now be done without frequent interrupts, dropping the
    overhead significantly.
    
    The main requirement still is to use a period, and not use frequency
    mode, because frequency mode requires reevaluating the frequency on each
    overflow.
    
    The floating point state (XMM) is also supported, which allows efficient
    profiling of FP function arguments.
    
    Introduce specific drain function to handle variable length records.
    Use a new callback to parse the new record format, and also handle the
    STATUS field now being at a different offset.
    
    Add code to set up the configuration register. Since there is only a
    single register, all events either get the full super set of all events,
    or only the basic record.
    
    Originally-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: acme@kernel.org
    Cc: jolsa@kernel.org
    Link: https://lkml.kernel.org/r/20190402194509.2832-6-kan.liang@linux.intel.com
    [ Renamed GPRS => GP. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ca5bc0eacb95..1378518cf63f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -116,6 +116,7 @@
 #define LBR_INFO_CYCLES			0xffff
 
 #define MSR_IA32_PEBS_ENABLE		0x000003f1
+#define MSR_PEBS_DATA_CFG		0x000003f2
 #define MSR_IA32_DS_AREA		0x00000600
 #define MSR_IA32_PERF_CAPABILITIES	0x00000345
 #define MSR_PEBS_LD_LAT_THRESHOLD	0x000003f6

commit ed5194c2732c8084af9fd159c146ea92bf137128
Author: Andi Kleen <ak@linux.intel.com>
Date:   Fri Jan 18 16:50:16 2019 -0800

    x86/speculation/mds: Add basic bug infrastructure for MDS
    
    Microarchitectural Data Sampling (MDS), is a class of side channel attacks
    on internal buffers in Intel CPUs. The variants are:
    
     - Microarchitectural Store Buffer Data Sampling (MSBDS) (CVE-2018-12126)
     - Microarchitectural Fill Buffer Data Sampling (MFBDS) (CVE-2018-12130)
     - Microarchitectural Load Port Data Sampling (MLPDS) (CVE-2018-12127)
    
    MSBDS leaks Store Buffer Entries which can be speculatively forwarded to a
    dependent load (store-to-load forwarding) as an optimization. The forward
    can also happen to a faulting or assisting load operation for a different
    memory address, which can be exploited under certain conditions. Store
    buffers are partitioned between Hyper-Threads so cross thread forwarding is
    not possible. But if a thread enters or exits a sleep state the store
    buffer is repartitioned which can expose data from one thread to the other.
    
    MFBDS leaks Fill Buffer Entries. Fill buffers are used internally to manage
    L1 miss situations and to hold data which is returned or sent in response
    to a memory or I/O operation. Fill buffers can forward data to a load
    operation and also write data to the cache. When the fill buffer is
    deallocated it can retain the stale data of the preceding operations which
    can then be forwarded to a faulting or assisting load operation, which can
    be exploited under certain conditions. Fill buffers are shared between
    Hyper-Threads so cross thread leakage is possible.
    
    MLDPS leaks Load Port Data. Load ports are used to perform load operations
    from memory or I/O. The received data is then forwarded to the register
    file or a subsequent operation. In some implementations the Load Port can
    contain stale data from a previous operation which can be forwarded to
    faulting or assisting loads under certain conditions, which again can be
    exploited eventually. Load ports are shared between Hyper-Threads so cross
    thread leakage is possible.
    
    All variants have the same mitigation for single CPU thread case (SMT off),
    so the kernel can treat them as one MDS issue.
    
    Add the basic infrastructure to detect if the current CPU is affected by
    MDS.
    
    [ tglx: Rewrote changelog ]
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
    Reviewed-by: Jon Masters <jcm@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index e4074556c37b..e2d30636c03f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -79,6 +79,11 @@
 						 * attack, so no Speculative Store Bypass
 						 * control required.
 						 */
+#define ARCH_CAP_MDS_NO			BIT(5)   /*
+						  * Not susceptible to
+						  * Microarchitectural Data
+						  * Sampling (MDS) vulnerabilities.
+						  */
 
 #define MSR_IA32_FLUSH_CMD		0x0000010b
 #define L1D_FLUSH			BIT(0)	/*

commit d8eabc37310a92df40d07c5a8afc53cebf996716
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 21 12:36:50 2019 +0100

    x86/msr-index: Cleanup bit defines
    
    Greg pointed out that speculation related bit defines are using (1 << N)
    format instead of BIT(N). Aside of that (1 << N) is wrong as it should use
    1UL at least.
    
    Clean it up.
    
    [ Josh Poimboeuf: Fix tools build ]
    
    Reported-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
    Reviewed-by: Jon Masters <jcm@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 8e40c2446fd1..e4074556c37b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -2,6 +2,8 @@
 #ifndef _ASM_X86_MSR_INDEX_H
 #define _ASM_X86_MSR_INDEX_H
 
+#include <linux/bits.h>
+
 /*
  * CPU model specific register (MSR) numbers.
  *
@@ -40,14 +42,14 @@
 /* Intel MSRs. Some also available on other CPUs */
 
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
-#define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
+#define SPEC_CTRL_IBRS			BIT(0)	   /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP_SHIFT		1	   /* Single Thread Indirect Branch Predictor (STIBP) bit */
-#define SPEC_CTRL_STIBP			(1 << SPEC_CTRL_STIBP_SHIFT)	/* STIBP mask */
+#define SPEC_CTRL_STIBP			BIT(SPEC_CTRL_STIBP_SHIFT)	/* STIBP mask */
 #define SPEC_CTRL_SSBD_SHIFT		2	   /* Speculative Store Bypass Disable bit */
-#define SPEC_CTRL_SSBD			(1 << SPEC_CTRL_SSBD_SHIFT)	/* Speculative Store Bypass Disable */
+#define SPEC_CTRL_SSBD			BIT(SPEC_CTRL_SSBD_SHIFT)	/* Speculative Store Bypass Disable */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
-#define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */
+#define PRED_CMD_IBPB			BIT(0)	   /* Indirect Branch Prediction Barrier */
 
 #define MSR_PPIN_CTL			0x0000004e
 #define MSR_PPIN			0x0000004f
@@ -69,20 +71,20 @@
 #define MSR_MTRRcap			0x000000fe
 
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
-#define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
-#define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
-#define ARCH_CAP_SKIP_VMENTRY_L1DFLUSH	(1 << 3)   /* Skip L1D flush on vmentry */
-#define ARCH_CAP_SSB_NO			(1 << 4)   /*
-						    * Not susceptible to Speculative Store Bypass
-						    * attack, so no Speculative Store Bypass
-						    * control required.
-						    */
+#define ARCH_CAP_RDCL_NO		BIT(0)	/* Not susceptible to Meltdown */
+#define ARCH_CAP_IBRS_ALL		BIT(1)	/* Enhanced IBRS support */
+#define ARCH_CAP_SKIP_VMENTRY_L1DFLUSH	BIT(3)	/* Skip L1D flush on vmentry */
+#define ARCH_CAP_SSB_NO			BIT(4)	/*
+						 * Not susceptible to Speculative Store Bypass
+						 * attack, so no Speculative Store Bypass
+						 * control required.
+						 */
 
 #define MSR_IA32_FLUSH_CMD		0x0000010b
-#define L1D_FLUSH			(1 << 0)   /*
-						    * Writeback and invalidate the
-						    * L1 data cache.
-						    */
+#define L1D_FLUSH			BIT(0)	/*
+						 * Writeback and invalidate the
+						 * L1 data cache.
+						 */
 
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e

commit 52f64909409c17adf54fcf5f9751e0544ca3a6b4
Author: Peter Zijlstra (Intel) <peterz@infradead.org>
Date:   Tue Mar 5 22:23:17 2019 +0100

    x86: Add TSX Force Abort CPUID/MSR
    
    Skylake systems will receive a microcode update to address a TSX
    errata. This microcode will (by default) clobber PMC3 when TSX
    instructions are (speculatively or not) executed.
    
    It also provides an MSR to cause all TSX transaction to abort and
    preserve PMC3.
    
    Add the CPUID enumeration and MSR definition.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 8e40c2446fd1..ca5bc0eacb95 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -666,6 +666,12 @@
 
 #define MSR_IA32_TSC_DEADLINE		0x000006E0
 
+
+#define MSR_TSX_FORCE_ABORT		0x0000010F
+
+#define MSR_TFA_RTM_FORCE_ABORT_BIT	0
+#define MSR_TFA_RTM_FORCE_ABORT		BIT_ULL(MSR_TFA_RTM_FORCE_ABORT_BIT)
+
 /* P4/Xeon+ specific */
 #define MSR_IA32_MCG_EAX		0x00000180
 #define MSR_IA32_MCG_EBX		0x00000181

commit 42b00f122cfbfed79fc29b0b3610f3abbb1e3864
Merge: 460023a5d1d2 a0aea130afeb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 26 11:46:28 2018 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
     "ARM:
       - selftests improvements
       - large PUD support for HugeTLB
       - single-stepping fixes
       - improved tracing
       - various timer and vGIC fixes
    
      x86:
       - Processor Tracing virtualization
       - STIBP support
       - some correctness fixes
       - refactorings and splitting of vmx.c
       - use the Hyper-V range TLB flush hypercall
       - reduce order of vcpu struct
       - WBNOINVD support
       - do not use -ftrace for __noclone functions
       - nested guest support for PAUSE filtering on AMD
       - more Hyper-V enlightenments (direct mode for synthetic timers)
    
      PPC:
       -  nested VFIO
    
      s390:
       - bugfixes only this time"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (171 commits)
      KVM: x86: Add CPUID support for new instruction WBNOINVD
      kvm: selftests: ucall: fix exit mmio address guessing
      Revert "compiler-gcc: disable -ftracer for __noclone functions"
      KVM: VMX: Move VM-Enter + VM-Exit handling to non-inline sub-routines
      KVM: VMX: Explicitly reference RCX as the vmx_vcpu pointer in asm blobs
      KVM: x86: Use jmp to invoke kvm_spurious_fault() from .fixup
      MAINTAINERS: Add arch/x86/kvm sub-directories to existing KVM/x86 entry
      KVM/x86: Use SVM assembly instruction mnemonics instead of .byte streams
      KVM/MMU: Flush tlb directly in the kvm_zap_gfn_range()
      KVM/MMU: Flush tlb directly in kvm_set_pte_rmapp()
      KVM/MMU: Move tlb flush in kvm_set_pte_rmapp() to kvm_mmu_notifier_change_pte()
      KVM: Make kvm_set_spte_hva() return int
      KVM: Replace old tlb flush function with new one to flush a specified range.
      KVM/MMU: Add tlb flush with range helper function
      KVM/VMX: Add hv tlb range flush support
      x86/hyper-v: Add HvFlushGuestAddressList hypercall support
      KVM: Add tlb_remote_flush_with_range callback in kvm_x86_ops
      KVM: x86: Disable Intel PT when VMXON in L1 guest
      KVM: x86: Set intercept for Intel PT MSRs read/write
      KVM: x86: Implement Intel PT MSRs read/write emulation
      ...

commit f99e3daf94ff35dd4a878d32ff66e1fd35223ad6
Author: Chao Peng <chao.p.peng@linux.intel.com>
Date:   Wed Oct 24 16:05:10 2018 +0800

    KVM: x86: Add Intel PT virtualization work mode
    
    Intel Processor Trace virtualization can be work in one
    of 2 possible modes:
    
    a. System-Wide mode (default):
       When the host configures Intel PT to collect trace packets
       of the entire system, it can leave the relevant VMX controls
       clear to allow VMX-specific packets to provide information
       across VMX transitions.
       KVM guest will not aware this feature in this mode and both
       host and KVM guest trace will output to host buffer.
    
    b. Host-Guest mode:
       Host can configure trace-packet generation while in
       VMX non-root operation for guests and root operation
       for native executing normally.
       Intel PT will be exposed to KVM guest in this mode, and
       the trace output to respective buffer of host and guest.
       In this mode, tht status of PT will be saved and disabled
       before VM-entry and restored after VM-exit if trace
       a virtual machine.
    
    Signed-off-by: Chao Peng <chao.p.peng@linux.intel.com>
    Signed-off-by: Luwei Kang <luwei.kang@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6a900150184b..8f95297371af 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -807,6 +807,7 @@
 #define VMX_BASIC_INOUT		0x0040000000000000LLU
 
 /* MSR_IA32_VMX_MISC bits */
+#define MSR_IA32_VMX_MISC_INTEL_PT                 (1ULL << 14)
 #define MSR_IA32_VMX_MISC_VMWRITE_SHADOW_RO_FIELDS (1ULL << 29)
 #define MSR_IA32_VMX_MISC_PREEMPTION_TIMER_SCALE   0x1F
 /* AMD-V MSRs */

commit 69843a913fc86b3d0ef503d6cc15886ef8943626
Author: Luwei Kang <luwei.kang@intel.com>
Date:   Wed Oct 24 16:05:08 2018 +0800

    perf/x86/intel/pt: Add new bit definitions for PT MSRs
    
    Add bit definitions for Intel PT MSRs to support trace output
    directed to the memeory subsystem and holds a count if packet
    bytes that have been sent out.
    
    These are required by the upcoming PT support in KVM guests
    for MSRs read/write emulation.
    
    Signed-off-by: Luwei Kang <luwei.kang@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 9c8618b885a0..6a900150184b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -127,6 +127,7 @@
 #define RTIT_CTL_USR			BIT(3)
 #define RTIT_CTL_PWR_EVT_EN		BIT(4)
 #define RTIT_CTL_FUP_ON_PTW		BIT(5)
+#define RTIT_CTL_FABRIC_EN		BIT(6)
 #define RTIT_CTL_CR3EN			BIT(7)
 #define RTIT_CTL_TOPA			BIT(8)
 #define RTIT_CTL_MTC_EN			BIT(9)
@@ -155,6 +156,8 @@
 #define RTIT_STATUS_BUFFOVF		BIT(3)
 #define RTIT_STATUS_ERROR		BIT(4)
 #define RTIT_STATUS_STOPPED		BIT(5)
+#define RTIT_STATUS_BYTECNT_OFFSET	32
+#define RTIT_STATUS_BYTECNT		(0x1ffffull << RTIT_STATUS_BYTECNT_OFFSET)
 #define MSR_IA32_RTIT_ADDR0_A		0x00000580
 #define MSR_IA32_RTIT_ADDR0_B		0x00000581
 #define MSR_IA32_RTIT_ADDR1_A		0x00000582

commit 887eda13b570f62a8b7d3eadc91734e44d95e636
Author: Chao Peng <chao.p.peng@linux.intel.com>
Date:   Wed Oct 24 16:05:05 2018 +0800

    perf/x86/intel/pt: Move Intel PT MSRs bit defines to global header
    
    The Intel Processor Trace (PT) MSR bit defines are in a private
    header. The upcoming support for PT virtualization requires these defines
    to be accessible from KVM code.
    
    Move them to the global MSR header file.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Chao Peng <chao.p.peng@linux.intel.com>
    Signed-off-by: Luwei Kang <luwei.kang@intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c8f73efb4ece..9c8618b885a0 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -121,7 +121,40 @@
 #define MSR_PEBS_LD_LAT_THRESHOLD	0x000003f6
 
 #define MSR_IA32_RTIT_CTL		0x00000570
+#define RTIT_CTL_TRACEEN		BIT(0)
+#define RTIT_CTL_CYCLEACC		BIT(1)
+#define RTIT_CTL_OS			BIT(2)
+#define RTIT_CTL_USR			BIT(3)
+#define RTIT_CTL_PWR_EVT_EN		BIT(4)
+#define RTIT_CTL_FUP_ON_PTW		BIT(5)
+#define RTIT_CTL_CR3EN			BIT(7)
+#define RTIT_CTL_TOPA			BIT(8)
+#define RTIT_CTL_MTC_EN			BIT(9)
+#define RTIT_CTL_TSC_EN			BIT(10)
+#define RTIT_CTL_DISRETC		BIT(11)
+#define RTIT_CTL_PTW_EN			BIT(12)
+#define RTIT_CTL_BRANCH_EN		BIT(13)
+#define RTIT_CTL_MTC_RANGE_OFFSET	14
+#define RTIT_CTL_MTC_RANGE		(0x0full << RTIT_CTL_MTC_RANGE_OFFSET)
+#define RTIT_CTL_CYC_THRESH_OFFSET	19
+#define RTIT_CTL_CYC_THRESH		(0x0full << RTIT_CTL_CYC_THRESH_OFFSET)
+#define RTIT_CTL_PSB_FREQ_OFFSET	24
+#define RTIT_CTL_PSB_FREQ		(0x0full << RTIT_CTL_PSB_FREQ_OFFSET)
+#define RTIT_CTL_ADDR0_OFFSET		32
+#define RTIT_CTL_ADDR0			(0x0full << RTIT_CTL_ADDR0_OFFSET)
+#define RTIT_CTL_ADDR1_OFFSET		36
+#define RTIT_CTL_ADDR1			(0x0full << RTIT_CTL_ADDR1_OFFSET)
+#define RTIT_CTL_ADDR2_OFFSET		40
+#define RTIT_CTL_ADDR2			(0x0full << RTIT_CTL_ADDR2_OFFSET)
+#define RTIT_CTL_ADDR3_OFFSET		44
+#define RTIT_CTL_ADDR3			(0x0full << RTIT_CTL_ADDR3_OFFSET)
 #define MSR_IA32_RTIT_STATUS		0x00000571
+#define RTIT_STATUS_FILTEREN		BIT(0)
+#define RTIT_STATUS_CONTEXTEN		BIT(1)
+#define RTIT_STATUS_TRIGGEREN		BIT(2)
+#define RTIT_STATUS_BUFFOVF		BIT(3)
+#define RTIT_STATUS_ERROR		BIT(4)
+#define RTIT_STATUS_STOPPED		BIT(5)
 #define MSR_IA32_RTIT_ADDR0_A		0x00000580
 #define MSR_IA32_RTIT_ADDR0_B		0x00000581
 #define MSR_IA32_RTIT_ADDR1_A		0x00000582

commit 0e1b869fff60c81b510c2d00602d778f8f59dd9a
Author: Eduardo Habkost <ehabkost@redhat.com>
Date:   Mon Dec 17 22:34:18 2018 -0200

    kvm: x86: Add AMD's EX_CFG to the list of ignored MSRs
    
    Some guests OSes (including Windows 10) write to MSR 0xc001102c
    on some cases (possibly while trying to apply a CPU errata).
    Make KVM ignore reads and writes to that MSR, so the guest won't
    crash.
    
    The MSR is documented as "Execution Unit Configuration (EX_CFG)",
    at AMD's "BIOS and Kernel Developer's Guide (BKDG) for AMD Family
    15h Models 00h-0Fh Processors".
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c8f73efb4ece..9e39cc8bd989 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -390,6 +390,7 @@
 #define MSR_F15H_NB_PERF_CTR		0xc0010241
 #define MSR_F15H_PTSC			0xc0010280
 #define MSR_F15H_IC_CFG			0xc0011021
+#define MSR_F15H_EX_CFG			0xc001102c
 
 /* Fam 10h MSRs */
 #define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058

commit 5bfbe3ad5840d941b89bcac54b821ba14f50a0ba
Author: Tim Chen <tim.c.chen@linux.intel.com>
Date:   Sun Nov 25 19:33:46 2018 +0100

    x86/speculation: Prepare for per task indirect branch speculation control
    
    To avoid the overhead of STIBP always on, it's necessary to allow per task
    control of STIBP.
    
    Add a new task flag TIF_SPEC_IB and evaluate it during context switch if
    SMT is active and flag evaluation is enabled by the speculation control
    code. Add the conditional evaluation to x86_virt_spec_ctrl() as well so the
    guest/host switch works properly.
    
    This has no effect because TIF_SPEC_IB cannot be set yet and the static key
    which controls evaluation is off. Preparatory patch for adding the control
    code.
    
    [ tglx: Simplify the context switch logic and make the TIF evaluation
            depend on SMP=y and on the static key controlling the conditional
            update. Rename it to TIF_SPEC_IB because it controls both STIBP and
            IBPB ]
    
    Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Casey Schaufler <casey.schaufler@intel.com>
    Cc: Asit Mallick <asit.k.mallick@intel.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jon Masters <jcm@redhat.com>
    Cc: Waiman Long <longman9394@gmail.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Dave Stewart <david.c.stewart@intel.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20181125185005.176917199@linutronix.de

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 80f4a4f38c79..c8f73efb4ece 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -41,9 +41,10 @@
 
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
 #define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
-#define SPEC_CTRL_STIBP			(1 << 1)   /* Single Thread Indirect Branch Predictors */
+#define SPEC_CTRL_STIBP_SHIFT		1	   /* Single Thread Indirect Branch Predictor (STIBP) bit */
+#define SPEC_CTRL_STIBP			(1 << SPEC_CTRL_STIBP_SHIFT)	/* STIBP mask */
 #define SPEC_CTRL_SSBD_SHIFT		2	   /* Speculative Store Bypass Disable bit */
-#define SPEC_CTRL_SSBD			(1 << SPEC_CTRL_SSBD_SHIFT)   /* Speculative Store Bypass Disable */
+#define SPEC_CTRL_SSBD			(1 << SPEC_CTRL_SSBD_SHIFT)	/* Speculative Store Bypass Disable */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
 #define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */

commit af3bdb991a5cb57c189d34aadbd3aa88995e0d9f
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Aug 8 00:12:07 2018 -0700

    perf/x86/intel: Add a separate Arch Perfmon v4 PMI handler
    
    Implements counter freezing for Arch Perfmon v4 (Skylake and
    newer). This allows to speed up the PMI handler by avoiding
    unnecessary MSR writes and make it more accurate.
    
    The Arch Perfmon v4 PMI handler is substantially different than
    the older PMI handler.
    
    Differences to the old handler:
    
    - It relies on counter freezing, which eliminates several MSR
      writes from the PMI handler and lowers the overhead significantly.
    
      It makes the PMI handler more accurate, as all counters get
      frozen atomically as soon as any counter overflows. So there is
      much less counting of the PMI handler itself.
    
      With the freezing we don't need to disable or enable counters or
      PEBS. Only BTS which does not support auto-freezing still needs to
      be explicitly managed.
    
    - The PMU acking is done at the end, not the beginning.
      This makes it possible to avoid manual enabling/disabling
      of the PMU, instead we just rely on the freezing/acking.
    
    - The APIC is acked before reenabling the PMU, which avoids
      problems with LBRs occasionally not getting unfreezed on Skylake.
    
    - Looping is only needed to workaround a corner case which several PMIs
      are very close to each other. For common cases, the counters are freezed
      during PMI handler. It doesn't need to do re-check.
    
    This patch:
    
    - Adds code to enable v4 counter freezing
    - Fork <=v3 and >=v4 PMI handlers into separate functions.
    - Add kernel parameter to disable counter freezing. It took some time to
      debug counter freezing, so in case there are new problems we added an
      option to turn it off. Would not expect this to be used until there
      are new bugs.
    - Only for big core. The patch for small core will be posted later
      separately.
    
    Performance:
    
    When profiling a kernel build on Kabylake with different perf options,
    measuring the length of all NMI handlers using the nmi handler
    trace point:
    
    V3 is without counter freezing.
    V4 is with counter freezing.
    The value is the average cost of the PMI handler.
    (lower is better)
    
    perf options    `           V3(ns) V4(ns)  delta
    -c 100000                   1088   894     -18%
    -g -c 100000                1862   1646    -12%
    --call-graph lbr -c 100000  3649   3367    -8%
    --c.g. dwarf -c 100000      2248   1982    -12%
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: acme@kernel.org
    Link: http://lkml.kernel.org/r/1533712328-2834-2-git-send-email-kan.liang@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 4731f0cf97c5..80f4a4f38c79 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -164,6 +164,7 @@
 #define DEBUGCTLMSR_BTS_OFF_OS		(1UL <<  9)
 #define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
 #define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
+#define DEBUGCTLMSR_FREEZE_PERFMON_ON_PMI	(1UL << 12)
 #define DEBUGCTLMSR_FREEZE_IN_SMM_BIT	14
 #define DEBUGCTLMSR_FREEZE_IN_SMM	(1UL << DEBUGCTLMSR_FREEZE_IN_SMM_BIT)
 

commit 8e0b2b916662e09dd4d09e5271cdf214c6b80e62
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Sun Aug 5 16:07:46 2018 +0200

    x86/speculation: Use ARCH_CAPABILITIES to skip L1D flush on vmentry
    
    Bit 3 of ARCH_CAPABILITIES tells a hypervisor that L1D flush on vmentry is
    not needed.  Add a new value to enum vmx_l1d_flush_state, which is used
    either if there is no L1TF bug at all, or if bit 3 is set in ARCH_CAPABILITIES.
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 0e7517089b80..4731f0cf97c5 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -70,6 +70,7 @@
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
 #define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
 #define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
+#define ARCH_CAP_SKIP_VMENTRY_L1DFLUSH	(1 << 3)   /* Skip L1D flush on vmentry */
 #define ARCH_CAP_SSB_NO			(1 << 4)   /*
 						    * Not susceptible to Speculative Store Bypass
 						    * attack, so no Speculative Store Bypass

commit 3fa045be4c720146b18a19cea7a767dc6ad5df94
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Mon Jul 2 13:03:48 2018 +0200

    x86/KVM/VMX: Add L1D MSR based flush
    
    336996-Speculative-Execution-Side-Channel-Mitigations.pdf defines a new MSR
    (IA32_FLUSH_CMD aka 0x10B) which has similar write-only semantics to other
    MSRs defined in the document.
    
    The semantics of this MSR is to allow "finer granularity invalidation of
    caching structures than existing mechanisms like WBINVD. It will writeback
    and invalidate the L1 data cache, including all cachelines brought in by
    preceding instructions, without invalidating all caches (eg. L2 or
    LLC). Some processors may also invalidate the first level level instruction
    cache on a L1D_FLUSH command. The L1 data and instruction caches may be
    shared across the logical processors of a core."
    
    Use it instead of the loop based L1 flush algorithm.
    
    A copy of this document is available at
       https://bugzilla.kernel.org/show_bug.cgi?id=199511
    
    [ tglx: Avoid allocating pages when the MSR is available ]
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 68b2c3150de1..0e7517089b80 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -76,6 +76,12 @@
 						    * control required.
 						    */
 
+#define MSR_IA32_FLUSH_CMD		0x0000010b
+#define L1D_FLUSH			(1 << 0)   /*
+						    * Writeback and invalidate the
+						    * L1 data cache.
+						    */
+
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e
 

commit a00072a24a9f5b88cfc56f2dec6afe8ce3874e60
Author: Matt Turner <mattst88@gmail.com>
Date:   Tue Feb 13 11:12:05 2018 -0800

    x86: msr-index.h: Correct SNB_C1/C3_AUTO_UNDEMOTE defines
    
    According to the Intel Software Developers' Manual, Vol. 4, Order No.
    335592, these macros have been reversed since they were added in the
    initial turbostat commit. The reversed definitions were presumably
    copied from turbostat.c to this file.
    
    Fixes: 9c63a650bb10 ("tools/power/x86/turbostat: share kernel MSR #defines")
    Signed-off-by: Matt Turner <mattst88@gmail.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index fda2114197b3..68b2c3150de1 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -62,8 +62,8 @@
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)
 #define ATM_LNC_C6_AUTO_DEMOTE		(1UL << 25)
-#define SNB_C1_AUTO_UNDEMOTE		(1UL << 27)
-#define SNB_C3_AUTO_UNDEMOTE		(1UL << 28)
+#define SNB_C3_AUTO_UNDEMOTE		(1UL << 27)
+#define SNB_C1_AUTO_UNDEMOTE		(1UL << 28)
 
 #define MSR_MTRRcap			0x000000fe
 

commit 240da953fcc6a9008c92fae5b1f727ee5ed167ab
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed May 16 23:18:09 2018 -0400

    x86/bugs: Rename SSBD_NO to SSB_NO
    
    The "336996 Speculative Execution Side Channel Mitigations" from
    May defines this as SSB_NO, hence lets sync-up.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 562414d5b834..fda2114197b3 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -70,7 +70,7 @@
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
 #define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
 #define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
-#define ARCH_CAP_SSBD_NO		(1 << 4)   /*
+#define ARCH_CAP_SSB_NO			(1 << 4)   /*
 						    * Not susceptible to Speculative Store Bypass
 						    * attack, so no Speculative Store Bypass
 						    * control required.

commit 11fb0683493b2da112cd64c9dada221b52463bf7
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Thu May 17 17:09:18 2018 +0200

    x86/speculation: Add virtualized speculative store bypass disable support
    
    Some AMD processors only support a non-architectural means of enabling
    speculative store bypass disable (SSBD).  To allow a simplified view of
    this to a guest, an architectural definition has been created through a new
    CPUID bit, 0x80000008_EBX[25], and a new MSR, 0xc001011f.  With this, a
    hypervisor can virtualize the existence of this definition and provide an
    architectural method for using SSBD to a guest.
    
    Add the new CPUID feature, the new MSR and update the existing SSBD
    support to use this MSR when present.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 0da3ca260b06..562414d5b834 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -347,6 +347,8 @@
 #define MSR_AMD64_SEV_ENABLED_BIT	0
 #define MSR_AMD64_SEV_ENABLED		BIT_ULL(MSR_AMD64_SEV_ENABLED_BIT)
 
+#define MSR_AMD64_VIRT_SPEC_CTRL	0xc001011f
+
 /* Fam 17h MSRs */
 #define MSR_F17H_IRPERF			0xc00000e9
 

commit 9f65fb29374ee37856dbad847b4e121aab72b510
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed May 9 21:41:38 2018 +0200

    x86/bugs: Rename _RDS to _SSBD
    
    Intel collateral will reference the SSB mitigation bit in IA32_SPEC_CTL[2]
    as SSBD (Speculative Store Bypass Disable).
    
    Hence changing it.
    
    It is unclear yet what the MSR_IA32_ARCH_CAPABILITIES (0x10a) Bit(4) name
    is going to be. Following the rename it would be SSBD_NO but that rolls out
    to Speculative Store Bypass Disable No.
    
    Also fixed the missing space in X86_FEATURE_AMD_SSBD.
    
    [ tglx: Fixup x86_amd_rds_enable() and rds_tif_to_amd_ls_cfg() as well ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 810f50bb338d..0da3ca260b06 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -42,8 +42,8 @@
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
 #define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP			(1 << 1)   /* Single Thread Indirect Branch Predictors */
-#define SPEC_CTRL_RDS_SHIFT		2	   /* Reduced Data Speculation bit */
-#define SPEC_CTRL_RDS			(1 << SPEC_CTRL_RDS_SHIFT)   /* Reduced Data Speculation */
+#define SPEC_CTRL_SSBD_SHIFT		2	   /* Speculative Store Bypass Disable bit */
+#define SPEC_CTRL_SSBD			(1 << SPEC_CTRL_SSBD_SHIFT)   /* Speculative Store Bypass Disable */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
 #define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */
@@ -70,10 +70,10 @@
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
 #define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
 #define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
-#define ARCH_CAP_RDS_NO			(1 << 4)   /*
+#define ARCH_CAP_SSBD_NO		(1 << 4)   /*
 						    * Not susceptible to Speculative Store Bypass
-						    * attack, so no Reduced Data Speculation control
-						    * required.
+						    * attack, so no Speculative Store Bypass
+						    * control required.
 						    */
 
 #define MSR_IA32_BBL_CR_CTL		0x00000119

commit 885f82bfbc6fefb6664ea27965c3ab9ac4194b8c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Apr 29 15:21:42 2018 +0200

    x86/process: Allow runtime control of Speculative Store Bypass
    
    The Speculative Store Bypass vulnerability can be mitigated with the
    Reduced Data Speculation (RDS) feature. To allow finer grained control of
    this eventually expensive mitigation a per task mitigation control is
    required.
    
    Add a new TIF_RDS flag and put it into the group of TIF flags which are
    evaluated for mismatch in switch_to(). If these bits differ in the previous
    and the next task, then the slow path function __switch_to_xtra() is
    invoked. Implement the TIF_RDS dependent mitigation control in the slow
    path.
    
    If the prctl for controlling Speculative Store Bypass is disabled or no
    task uses the prctl then there is no overhead in the switch_to() fast
    path.
    
    Update the KVM related speculation control functions to take TID_RDS into
    account as well.
    
    Based on a patch from Tim Chen. Completely rewritten.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 21e1a6df9907..810f50bb338d 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -42,7 +42,8 @@
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
 #define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP			(1 << 1)   /* Single Thread Indirect Branch Predictors */
-#define SPEC_CTRL_RDS			(1 << 2)   /* Reduced Data Speculation */
+#define SPEC_CTRL_RDS_SHIFT		2	   /* Reduced Data Speculation bit */
+#define SPEC_CTRL_RDS			(1 << SPEC_CTRL_RDS_SHIFT)   /* Reduced Data Speculation */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
 #define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */

commit 772439717dbf703b39990be58d8d4e3e4ad0598a
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed Apr 25 22:04:22 2018 -0400

    x86/bugs/intel: Set proper CPU features and setup RDS
    
    Intel CPUs expose methods to:
    
     - Detect whether RDS capability is available via CPUID.7.0.EDX[31],
    
     - The SPEC_CTRL MSR(0x48), bit 2 set to enable RDS.
    
     - MSR_IA32_ARCH_CAPABILITIES, Bit(4) no need to enable RRS.
    
    With that in mind if spec_store_bypass_disable=[auto,on] is selected set at
    boot-time the SPEC_CTRL MSR to enable RDS if the platform requires it.
    
    Note that this does not fix the KVM case where the SPEC_CTRL is exposed to
    guests which can muck with it, see patch titled :
     KVM/SVM/VMX/x86/spectre_v2: Support the combination of guest and host IBRS.
    
    And for the firmware (IBRS to be set), see patch titled:
     x86/spectre_v2: Read SPEC_CTRL MSR during boot and re-use reserved bits
    
    [ tglx: Distangled it from the intel implementation and kept the call order ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 53d5b1b9255e..21e1a6df9907 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -42,6 +42,7 @@
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
 #define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP			(1 << 1)   /* Single Thread Indirect Branch Predictors */
+#define SPEC_CTRL_RDS			(1 << 2)   /* Reduced Data Speculation */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
 #define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */
@@ -68,6 +69,11 @@
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
 #define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
 #define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
+#define ARCH_CAP_RDS_NO			(1 << 4)   /*
+						    * Not susceptible to Speculative Store Bypass
+						    * attack, so no Reduced Data Speculation control
+						    * required.
+						    */
 
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e

commit e84b7119e891556d0786c6dafe53286d89f082cc
Author: Janakarajan Natarajan <Janakarajan.Natarajan@amd.com>
Date:   Mon Feb 5 13:24:51 2018 -0600

    x86/msr: Add AMD Core Perf Extension MSRs
    
    Add the EventSelect and Counter MSRs for AMD Core Perf Extension.
    
    Signed-off-by: Janakarajan Natarajan <Janakarajan.Natarajan@amd.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c9084dedfcfa..53d5b1b9255e 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -353,7 +353,21 @@
 
 /* Fam 15h MSRs */
 #define MSR_F15H_PERF_CTL		0xc0010200
+#define MSR_F15H_PERF_CTL0		MSR_F15H_PERF_CTL
+#define MSR_F15H_PERF_CTL1		(MSR_F15H_PERF_CTL + 2)
+#define MSR_F15H_PERF_CTL2		(MSR_F15H_PERF_CTL + 4)
+#define MSR_F15H_PERF_CTL3		(MSR_F15H_PERF_CTL + 6)
+#define MSR_F15H_PERF_CTL4		(MSR_F15H_PERF_CTL + 8)
+#define MSR_F15H_PERF_CTL5		(MSR_F15H_PERF_CTL + 10)
+
 #define MSR_F15H_PERF_CTR		0xc0010201
+#define MSR_F15H_PERF_CTR0		MSR_F15H_PERF_CTR
+#define MSR_F15H_PERF_CTR1		(MSR_F15H_PERF_CTR + 2)
+#define MSR_F15H_PERF_CTR2		(MSR_F15H_PERF_CTR + 4)
+#define MSR_F15H_PERF_CTR3		(MSR_F15H_PERF_CTR + 6)
+#define MSR_F15H_PERF_CTR4		(MSR_F15H_PERF_CTR + 8)
+#define MSR_F15H_PERF_CTR5		(MSR_F15H_PERF_CTR + 10)
+
 #define MSR_F15H_NB_PERF_CTL		0xc0010240
 #define MSR_F15H_NB_PERF_CTR		0xc0010241
 #define MSR_F15H_PTSC			0xc0010280

commit 7bf14c28ee776be567855bd39ed8ff795ea19f55
Merge: 87cedc6be559 5fa4ec9cb2e6
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Thu Feb 1 15:04:17 2018 +0100

    Merge branch 'x86/hyperv' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Topic branch for stable KVM clockource under Hyper-V.
    
    Thanks to Christoffer Dall for resolving the ARM conflict.

commit 6304672b7f0a5c010002e63a075160856dc4f88d
Merge: 942633523cde 64e16720ea08
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 29 19:08:02 2018 -0800

    Merge branch 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86/pti updates from Thomas Gleixner:
     "Another set of melted spectrum related changes:
    
       - Code simplifications and cleanups for RSB and retpolines.
    
       - Make the indirect calls in KVM speculation safe.
    
       - Whitelist CPUs which are known not to speculate from Meltdown and
         prepare for the new CPUID flag which tells the kernel that a CPU is
         not affected.
    
       - A less rigorous variant of the module retpoline check which merily
         warns when a non-retpoline protected module is loaded and reflects
         that fact in the sysfs file.
    
       - Prepare for Indirect Branch Prediction Barrier support.
    
       - Prepare for exposure of the Speculation Control MSRs to guests, so
         guest OSes which depend on those "features" can use them. Includes
         a blacklist of the broken microcodes. The actual exposure of the
         MSRs through KVM is still being worked on"
    
    * 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/speculation: Simplify indirect_branch_prediction_barrier()
      x86/retpoline: Simplify vmexit_fill_RSB()
      x86/cpufeatures: Clean up Spectre v2 related CPUID flags
      x86/cpu/bugs: Make retpoline module warning conditional
      x86/bugs: Drop one "mitigation" from dmesg
      x86/nospec: Fix header guards names
      x86/alternative: Print unadorned pointers
      x86/speculation: Add basic IBPB (Indirect Branch Prediction Barrier) support
      x86/cpufeature: Blacklist SPEC_CTRL/PRED_CMD on early Spectre v2 microcodes
      x86/pti: Do not enable PTI on CPUs which are not vulnerable to Meltdown
      x86/msr: Add definitions for new speculation control MSRs
      x86/cpufeatures: Add AMD feature bits for Speculation Control
      x86/cpufeatures: Add Intel feature bits for Speculation Control
      x86/cpufeatures: Add CPUID_7_EDX CPUID leaf
      module/retpoline: Warn about missing retpoline in module
      KVM: VMX: Make indirect call speculation safe
      KVM: x86: Make indirect calls in emulator speculation safe

commit 1e340c60d0dd3ae07b5bedc16a0469c14b9f3410
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Thu Jan 25 16:14:12 2018 +0000

    x86/msr: Add definitions for new speculation control MSRs
    
    Add MSR and bit definitions for SPEC_CTRL, PRED_CMD and ARCH_CAPABILITIES.
    
    See Intel's 336996-Speculative-Execution-Side-Channel-Mitigations.pdf
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-5-git-send-email-dwmw@amazon.co.uk

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index fa11fb1fa570..eb83ff1bae8f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -39,6 +39,13 @@
 
 /* Intel MSRs. Some also available on other CPUs */
 
+#define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
+#define SPEC_CTRL_IBRS			(1 << 0)   /* Indirect Branch Restricted Speculation */
+#define SPEC_CTRL_STIBP			(1 << 1)   /* Single Thread Indirect Branch Predictors */
+
+#define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
+#define PRED_CMD_IBPB			(1 << 0)   /* Indirect Branch Prediction Barrier */
+
 #define MSR_PPIN_CTL			0x0000004e
 #define MSR_PPIN			0x0000004f
 
@@ -57,6 +64,11 @@
 #define SNB_C3_AUTO_UNDEMOTE		(1UL << 28)
 
 #define MSR_MTRRcap			0x000000fe
+
+#define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
+#define ARCH_CAP_RDCL_NO		(1 << 0)   /* Not susceptible to Meltdown */
+#define ARCH_CAP_IBRS_ALL		(1 << 1)   /* Enhanced IBRS support */
+
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e
 

commit 40548c6b6c134275c750eb372dc2cf8ee1bbc3d4
Merge: 2c1cfa499018 99a9dc98ba52
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 14 09:51:25 2018 -0800

    Merge branch 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 pti updates from Thomas Gleixner:
     "This contains:
    
       - a PTI bugfix to avoid setting reserved CR3 bits when PCID is
         disabled. This seems to cause issues on a virtual machine at least
         and is incorrect according to the AMD manual.
    
       - a PTI bugfix which disables the perf BTS facility if PTI is
         enabled. The BTS AUX buffer is not globally visible and causes the
         CPU to fault when the mapping disappears on switching CR3 to user
         space. A full fix which restores BTS on PTI is non trivial and will
         be worked on.
    
       - PTI bugfixes for EFI and trusted boot which make sure that the user
         space visible page table entries have the NX bit cleared
    
       - removal of dead code in the PTI pagetable setup functions
    
       - add PTI documentation
    
       - add a selftest for vsyscall to verify that the kernel actually
         implements what it advertises.
    
       - a sysfs interface to expose vulnerability and mitigation
         information so there is a coherent way for users to retrieve the
         status.
    
       - the initial spectre_v2 mitigations, aka retpoline:
    
          + The necessary ASM thunk and compiler support
    
          + The ASM variants of retpoline and the conversion of affected ASM
            code
    
          + Make LFENCE serializing on AMD so it can be used as speculation
            trap
    
          + The RSB fill after vmexit
    
       - initial objtool support for retpoline
    
      As I said in the status mail this is the most of the set of patches
      which should go into 4.15 except two straight forward patches still on
      hold:
    
       - the retpoline add on of LFENCE which waits for ACKs
    
       - the RSB fill after context switch
    
      Both should be ready to go early next week and with that we'll have
      covered the major holes of spectre_v2 and go back to normality"
    
    * 'x86-pti-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (28 commits)
      x86,perf: Disable intel_bts when PTI
      security/Kconfig: Correct the Documentation reference for PTI
      x86/pti: Fix !PCID and sanitize defines
      selftests/x86: Add test_vsyscall
      x86/retpoline: Fill return stack buffer on vmexit
      x86/retpoline/irq32: Convert assembler indirect jumps
      x86/retpoline/checksum32: Convert assembler indirect jumps
      x86/retpoline/xen: Convert Xen hypercall indirect jumps
      x86/retpoline/hyperv: Convert assembler indirect jumps
      x86/retpoline/ftrace: Convert ftrace assembler indirect jumps
      x86/retpoline/entry: Convert entry assembler indirect jumps
      x86/retpoline/crypto: Convert crypto assembler indirect jumps
      x86/spectre: Add boot time option to select Spectre v2 mitigation
      x86/retpoline: Add initial retpoline support
      objtool: Allow alternatives to be ignored
      objtool: Detect jumps to retpoline thunks
      x86/pti: Make unpoison of pgd for trusted boot work for real
      x86/alternatives: Fix optimize_nops() checking
      sysfs/cpu: Fix typos in vulnerability documentation
      x86/cpu/AMD: Use LFENCE_RDTSC in preference to MFENCE_RDTSC
      ...

commit 9c6a73c75864ad9fa49e5fa6513e4c4071c0e29f
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jan 8 16:09:32 2018 -0600

    x86/cpu/AMD: Use LFENCE_RDTSC in preference to MFENCE_RDTSC
    
    With LFENCE now a serializing instruction, use LFENCE_RDTSC in preference
    to MFENCE_RDTSC.  However, since the kernel could be running under a
    hypervisor that does not support writing that MSR, read the MSR back and
    verify that the bit has been set successfully.  If the MSR can be read
    and the bit is set, then set the LFENCE_RDTSC feature, otherwise set the
    MFENCE_RDTSC feature.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linux-foundation.org>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Paul Turner <pjt@google.com>
    Link: https://lkml.kernel.org/r/20180108220932.12580.52458.stgit@tlendack-t1.amdoffice.net

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1e7d710fef43..fa11fb1fa570 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -354,6 +354,7 @@
 #define MSR_FAM10H_NODE_ID		0xc001100c
 #define MSR_F10H_DECFG			0xc0011029
 #define MSR_F10H_DECFG_LFENCE_SERIALIZE_BIT	1
+#define MSR_F10H_DECFG_LFENCE_SERIALIZE		BIT_ULL(MSR_F10H_DECFG_LFENCE_SERIALIZE_BIT)
 
 /* K8 MSRs */
 #define MSR_K8_TOP_MEM1			0xc001001a

commit e4d0e84e490790798691aaa0f2e598637f1867ec
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jan 8 16:09:21 2018 -0600

    x86/cpu/AMD: Make LFENCE a serializing instruction
    
    To aid in speculation control, make LFENCE a serializing instruction
    since it has less overhead than MFENCE.  This is done by setting bit 1
    of MSR 0xc0011029 (DE_CFG).  Some families that support LFENCE do not
    have this MSR.  For these families, the LFENCE instruction is already
    serializing.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linux-foundation.org>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Paul Turner <pjt@google.com>
    Link: https://lkml.kernel.org/r/20180108220921.12580.71694.stgit@tlendack-t1.amdoffice.net

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ab022618a50a..1e7d710fef43 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -352,6 +352,8 @@
 #define FAM10H_MMIO_CONF_BASE_MASK	0xfffffffULL
 #define FAM10H_MMIO_CONF_BASE_SHIFT	20
 #define MSR_FAM10H_NODE_ID		0xc001100c
+#define MSR_F10H_DECFG			0xc0011029
+#define MSR_F10H_DECFG_LFENCE_SERIALIZE_BIT	1
 
 /* K8 MSRs */
 #define MSR_K8_TOP_MEM1			0xc001001a

commit 18c71ce9c8822d48d2b4c50242051535d46082ac
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Dec 4 10:57:23 2017 -0600

    x86/CPU/AMD: Add the Secure Encrypted Virtualization CPU feature
    
    Update the CPU features to include identifying and reporting on the
    Secure Encrypted Virtualization (SEV) feature.  SEV is identified by
    CPUID 0x8000001f, but requires BIOS support to enable it (set bit 23 of
    MSR_K8_SYSCFG and set bit 0 of MSR_K7_HWCR).  Only show the SEV feature
    as available if reported by CPUID and enabled by BIOS.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "Radim Krčmář" <rkrcmar@redhat.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: kvm@vger.kernel.org
    Cc: x86@kernel.org
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 34c4922bbc3f..507d3e30f7fe 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -382,6 +382,8 @@
 #define MSR_K7_PERFCTR3			0xc0010007
 #define MSR_K7_CLK_CTL			0xc001001b
 #define MSR_K7_HWCR			0xc0010015
+#define MSR_K7_HWCR_SMMLOCK_BIT		0
+#define MSR_K7_HWCR_SMMLOCK		BIT_ULL(MSR_K7_HWCR_SMMLOCK_BIT)
 #define MSR_K7_FID_VID_CTL		0xc0010041
 #define MSR_K7_FID_VID_STATUS		0xc0010042
 

commit 1958b5fc401067662ec11a6fcbe0daa26c813603
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Fri Oct 20 09:30:54 2017 -0500

    x86/boot: Add early boot support when running with SEV active
    
    Early in the boot process, add checks to determine if the kernel is
    running with Secure Encrypted Virtualization (SEV) active.
    
    Checking for SEV requires checking that the kernel is running under a
    hypervisor (CPUID 0x00000001, bit 31), that the SEV feature is available
    (CPUID 0x8000001f, bit 1) and then checking a non-interceptable SEV MSR
    (0xc0010131, bit 0).
    
    This check is required so that during early compressed kernel booting the
    pagetables (both the boot pagetables and KASLR pagetables (if enabled) are
    updated to include the encryption mask so that when the kernel is
    decompressed into encrypted memory, it can boot properly.
    
    After the kernel is decompressed and continues booting the same logic is
    used to check if SEV is active and set a flag indicating so.  This allows
    to distinguish between SME and SEV, each of which have unique differences
    in how certain things are handled: e.g. DMA (always bounce buffered with
    SEV) or EFI tables (always access decrypted with SME).
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Tested-by: Borislav Petkov <bp@suse.de>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: kvm@vger.kernel.org
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Link: https://lkml.kernel.org/r/20171020143059.3291-13-brijesh.singh@amd.com

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ab022618a50a..34c4922bbc3f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -324,6 +324,9 @@
 #define MSR_AMD64_IBSBRTARGET		0xc001103b
 #define MSR_AMD64_IBSOPDATA4		0xc001103d
 #define MSR_AMD64_IBS_REG_COUNT_MAX	8 /* includes MSR_AMD64_IBSBRTARGET */
+#define MSR_AMD64_SEV			0xc0010131
+#define MSR_AMD64_SEV_ENABLED_BIT	0
+#define MSR_AMD64_SEV_ENABLED		BIT_ULL(MSR_AMD64_SEV_ENABLED_BIT)
 
 /* Fam 17h MSRs */
 #define MSR_F17H_IRPERF			0xc00000e9

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 17f5c12e1afd..ab022618a50a 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_MSR_INDEX_H
 #define _ASM_X86_MSR_INDEX_H
 

commit 872cbefd2d9c52bd0b1e2c7942c4369e98a5a5ae
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Mon Jul 17 16:10:01 2017 -0500

    x86/cpu/AMD: Add the Secure Memory Encryption CPU feature
    
    Update the CPU features to include identifying and reporting on the
    Secure Memory Encryption (SME) feature.  SME is identified by CPUID
    0x8000001f, but requires BIOS support to enable it (set bit 23 of
    MSR_K8_SYSCFG).  Only show the SME feature as available if reported by
    CPUID, enabled by BIOS and not configured as CONFIG_X86_32=y.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brijesh Singh <brijesh.singh@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Toshimitsu Kani <toshi.kani@hpe.com>
    Cc: kasan-dev@googlegroups.com
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-doc@vger.kernel.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/85c17ff450721abccddc95e611ae8df3f4d9718b.1500319216.git.thomas.lendacky@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 5573c75f8e4c..17f5c12e1afd 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -356,6 +356,8 @@
 #define MSR_K8_TOP_MEM1			0xc001001a
 #define MSR_K8_TOP_MEM2			0xc001001d
 #define MSR_K8_SYSCFG			0xc0010010
+#define MSR_K8_SYSCFG_MEM_ENCRYPT_BIT	23
+#define MSR_K8_SYSCFG_MEM_ENCRYPT	BIT_ULL(MSR_K8_SYSCFG_MEM_ENCRYPT_BIT)
 #define MSR_K8_INT_PENDING_MSG		0xc0010055
 /* C1E active bits in int pending message */
 #define K8_INTP_C1E_ACTIVE_MASK		0x18000000

commit c136b84393d4e340e1b53fc7f737dd5827b19ee5
Merge: e0f25a3f2d05 1372324b328c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 6 18:38:31 2017 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
     "PPC:
       - Better machine check handling for HV KVM
       - Ability to support guests with threads=2, 4 or 8 on POWER9
       - Fix for a race that could cause delayed recognition of signals
       - Fix for a bug where POWER9 guests could sleep with interrupts pending.
    
      ARM:
       - VCPU request overhaul
       - allow timer and PMU to have their interrupt number selected from userspace
       - workaround for Cavium erratum 30115
       - handling of memory poisonning
       - the usual crop of fixes and cleanups
    
      s390:
       - initial machine check forwarding
       - migration support for the CMMA page hinting information
       - cleanups and fixes
    
      x86:
       - nested VMX bugfixes and improvements
       - more reliable NMI window detection on AMD
       - APIC timer optimizations
    
      Generic:
       - VCPU request overhaul + documentation of common code patterns
       - kvm_stat improvements"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (124 commits)
      Update my email address
      kvm: vmx: allow host to access guest MSR_IA32_BNDCFGS
      x86: kvm: mmu: use ept a/d in vmcs02 iff used in vmcs12
      kvm: x86: mmu: allow A/D bits to be disabled in an mmu
      x86: kvm: mmu: make spte mmio mask more explicit
      x86: kvm: mmu: dead code thanks to access tracking
      KVM: PPC: Book3S: Fix typo in XICS-on-XIVE state saving code
      KVM: PPC: Book3S HV: Close race with testing for signals on guest entry
      KVM: PPC: Book3S HV: Simplify dynamic micro-threading code
      KVM: x86: remove ignored type attribute
      KVM: LAPIC: Fix lapic timer injection delay
      KVM: lapic: reorganize restart_apic_timer
      KVM: lapic: reorganize start_hv_timer
      kvm: nVMX: Check memory operand to INVVPID
      KVM: s390: Inject machine check into the nested guest
      KVM: s390: Inject machine check into the guest
      tools/kvm_stat: add new interactive command 'b'
      tools/kvm_stat: add new command line switch '-i'
      tools/kvm_stat: fix error on interactive command 'g'
      KVM: SVM: suppress unnecessary NMI singlestep on GIF=0 and nested exit
      ...

commit 408c9861c6979db974455b9e7a9bcadd60e0934c
Merge: b39de277b02f 8f8e5c3e2796
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 4 13:39:41 2017 -0700

    Merge tag 'pm-4.13-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael Wysocki:
     "The big ticket items here are the rework of suspend-to-idle in order
      to add proper support for power button wakeup from it on recent Dell
      laptops and the rework of interfaces exporting the current CPU
      frequency on x86.
    
      In addition to that, support for a few new pieces of hardware is
      added, the PCI/ACPI device wakeup infrastructure is simplified
      significantly and the wakeup IRQ framework is fixed to unbreak the IRQ
      bus locking infrastructure.
    
      Also, there are some functional improvements for intel_pstate, tools
      updates and small fixes and cleanups all over.
    
      Specifics:
    
       - Rework suspend-to-idle to allow it to take wakeup events signaled
         by the EC into account on ACPI-based platforms in order to properly
         support power button wakeup from suspend-to-idle on recent Dell
         laptops (Rafael Wysocki).
    
         That includes the core suspend-to-idle code rework, support for the
         Low Power S0 _DSM interface, and support for the ACPI INT0002
         Virtual GPIO device from Hans de Goede (required for USB keyboard
         wakeup from suspend-to-idle to work on some machines).
    
       - Stop trying to export the current CPU frequency via /proc/cpuinfo
         on x86 as that is inaccurate and confusing (Len Brown).
    
       - Rework the way in which the current CPU frequency is exported by
         the kernel (over the cpufreq sysfs interface) on x86 systems with
         the APERF and MPERF registers by always using values read from
         these registers, when available, to compute the current frequency
         regardless of which cpufreq driver is in use (Len Brown).
    
       - Rework the PCI/ACPI device wakeup infrastructure to remove the
         questionable and artificial distinction between "devices that can
         wake up the system from sleep states" and "devices that can
         generate wakeup signals in the working state" from it, which allows
         the code to be simplified quite a bit (Rafael Wysocki).
    
       - Fix the wakeup IRQ framework by making it use SRCU instead of RCU
         which doesn't allow sleeping in the read-side critical sections,
         but which in turn is expected to be allowed by the IRQ bus locking
         infrastructure (Thomas Gleixner).
    
       - Modify some computations in the intel_pstate driver to avoid
         rounding errors resulting from them (Srinivas Pandruvada).
    
       - Reduce the overhead of the intel_pstate driver in the HWP
         (hardware-managed P-states) mode and when the "performance" P-state
         selection algorithm is in use by making it avoid registering
         scheduler callbacks in those cases (Len Brown).
    
       - Rework the energy_performance_preference sysfs knob in intel_pstate
         by changing the values that correspond to different symbolic hint
         names used by it (Len Brown).
    
       - Make it possible to use more than one cpuidle driver at the same
         time on ARM (Daniel Lezcano).
    
       - Make it possible to prevent the cpuidle menu governor from using
         the 0 state by disabling it via sysfs (Nicholas Piggin).
    
       - Add support for FFH (Fixed Functional Hardware) MWAIT in ACPI C1 on
         AMD systems (Yazen Ghannam).
    
       - Make the CPPC cpufreq driver take the lowest nonlinear performance
         information into account (Prashanth Prakash).
    
       - Add support for hi3660 to the cpufreq-dt driver, fix the imx6q
         driver and clean up the sfi, exynos5440 and intel_pstate drivers
         (Colin Ian King, Krzysztof Kozlowski, Octavian Purdila, Rafael
         Wysocki, Tao Wang).
    
       - Fix a few minor issues in the generic power domains (genpd)
         framework and clean it up somewhat (Krzysztof Kozlowski, Mikko
         Perttunen, Viresh Kumar).
    
       - Fix a couple of minor issues in the operating performance points
         (OPP) framework and clean it up somewhat (Viresh Kumar).
    
       - Fix a CONFIG dependency in the hibernation core and clean it up
         slightly (Balbir Singh, Arvind Yadav, BaoJun Luo).
    
       - Add rk3228 support to the rockchip-io adaptive voltage scaling
         (AVS) driver (David Wu).
    
       - Fix an incorrect bit shift operation in the RAPL power capping
         driver (Adam Lessnau).
    
       - Add support for the EPP field in the HWP (hardware managed
         P-states) control register, HWP.EPP, to the x86_energy_perf_policy
         tool and update msr-index.h with HWP.EPP values (Len Brown).
    
       - Fix some minor issues in the turbostat tool (Len Brown).
    
       - Add support for AMD family 0x17 CPUs to the cpupower tool and fix a
         minor issue in it (Sherry Hurwitz).
    
       - Assorted cleanups, mostly related to the constification of some
         data structures (Arvind Yadav, Joe Perches, Kees Cook, Krzysztof
         Kozlowski)"
    
    * tag 'pm-4.13-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (69 commits)
      cpufreq: Update scaling_cur_freq documentation
      cpufreq: intel_pstate: Clean up after performance governor changes
      PM: hibernate: constify attribute_group structures.
      cpuidle: menu: allow state 0 to be disabled
      intel_idle: Use more common logging style
      PM / Domains: Fix missing default_power_down_ok comment
      PM / Domains: Fix unsafe iteration over modified list of domains
      PM / Domains: Fix unsafe iteration over modified list of domain providers
      PM / Domains: Fix unsafe iteration over modified list of device links
      PM / Domains: Handle safely genpd_syscore_switch() call on non-genpd device
      PM / Domains: Call driver's noirq callbacks
      PM / core: Drop run_wake flag from struct dev_pm_info
      PCI / PM: Simplify device wakeup settings code
      PCI / PM: Drop pme_interrupt flag from struct pci_dev
      ACPI / PM: Consolidate device wakeup settings code
      ACPI / PM: Drop run_wake from struct acpi_device_wakeup_flags
      PM / QoS: constify *_attribute_group.
      PM / AVS: rockchip-io: add io selectors and supplies for rk3228
      powercap/RAPL: prevent overridding bits outside of the mask
      PM / sysfs: Constify attribute groups
      ...

commit 4531662d1abf6c1f0e5c2b86ddb60e61509786c8
Author: Jim Mattson <jmattson@google.com>
Date:   Tue May 23 11:52:54 2017 -0700

    kvm: vmx: Check value written to IA32_BNDCFGS
    
    Bits 11:2 must be zero and the linear addess in bits 63:12 must be
    canonical. Otherwise, WRMSR(BNDCFGS) should raise #GP.
    
    Fixes: 0dd376e709975779 ("KVM: x86: add MSR_IA32_BNDCFGS to msrs_to_save")
    Signed-off-by: Jim Mattson <jmattson@google.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 673f9ac50f6d..dbf266b0d14a 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -420,6 +420,8 @@
 #define MSR_IA32_TSC_ADJUST             0x0000003b
 #define MSR_IA32_BNDCFGS		0x00000d90
 
+#define MSR_IA32_BNDCFGS_RSVD		0x00000ffc
+
 #define MSR_IA32_XSS			0x00000da0
 
 #define FEATURE_CONTROL_LOCKED				(1<<0)

commit 6089327f5424f227bb6a8cf92363c2617e054453
Author: Kan Liang <Kan.liang@intel.com>
Date:   Fri May 12 07:51:13 2017 -0700

    perf/x86: Add sysfs entry to freeze counters on SMI
    
    Currently, the SMIs are visible to all performance counters, because
    many users want to measure everything including SMIs. But in some
    cases, the SMI cycles should not be counted - for example, to calculate
    the cost of an SMI itself. So a knob is needed.
    
    When setting FREEZE_WHILE_SMM bit in IA32_DEBUGCTL, all performance
    counters will be effected. There is no way to do per-counter freeze
    on SMI. So it should not use the per-event interface (e.g. ioctl or
    event attribute) to set FREEZE_WHILE_SMM bit.
    
    Adds sysfs entry /sys/device/cpu/freeze_on_smi to set FREEZE_WHILE_SMM
    bit in IA32_DEBUGCTL. When set, freezes perfmon and trace messages
    while in SMM.
    
    Value has to be 0 or 1. It will be applied to all processors.
    
    Also serialize the entire setting so we don't get multiple concurrent
    threads trying to update to different values.
    
    Signed-off-by: Kan Liang <Kan.liang@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: acme@kernel.org
    Cc: bp@alien8.de
    Cc: jolsa@kernel.org
    Link: http://lkml.kernel.org/r/1494600673-244667-1-git-send-email-kan.liang@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 673f9ac50f6d..18b162322eff 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -137,6 +137,8 @@
 #define DEBUGCTLMSR_BTS_OFF_OS		(1UL <<  9)
 #define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
 #define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
+#define DEBUGCTLMSR_FREEZE_IN_SMM_BIT	14
+#define DEBUGCTLMSR_FREEZE_IN_SMM	(1UL << DEBUGCTLMSR_FREEZE_IN_SMM_BIT)
 
 #define MSR_PEBS_FRONTEND		0x000003f7
 

commit a32f80b30dae067357f96bc2a7f977e8a91b45ed
Merge: 2ea659a9ef48 3cedbc5a6d7f
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue May 16 03:15:27 2017 +0200

    Merge branch 'utilities' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    Pull power management utilities updates from Len Brown.
    
    * 'utilities' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux:
      intel_pstate: use updated msr-index.h HWP.EPP values
      tools/power x86_energy_perf_policy: support HWP.EPP
      x86: msr-index.h: fix shifts to ULL results in HWP macros.
      x86: msr-index.h: define HWP.EPP values
      x86: msr-index.h: define EPB mid-points

commit 2fc49cb0b508947bf048ecb0f5710169e62ce68e
Author: Len Brown <len.brown@intel.com>
Date:   Sat Apr 29 00:11:46 2017 -0400

    x86: msr-index.h: fix shifts to ULL results in HWP macros.
    
    x = 1
    ulong_long = x << 32;
    
    results in:
    
    warning: left shift count >= width of type
    
    x = 8
    ulong_long = x << 24;
    
    results in a sign extended ulong_long
    
    Cast x to unsigned long long in these macros
    to prevent these errors.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 50c0c3204a92..6da2b30781ff 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -238,13 +238,13 @@
 #define HWP_MIN_PERF(x) 		(x & 0xff)
 #define HWP_MAX_PERF(x) 		((x & 0xff) << 8)
 #define HWP_DESIRED_PERF(x)		((x & 0xff) << 16)
-#define HWP_ENERGY_PERF_PREFERENCE(x)	((x & 0xff) << 24)
+#define HWP_ENERGY_PERF_PREFERENCE(x)	(((unsigned long long) x & 0xff) << 24)
 #define HWP_EPP_PERFORMANCE		0x00
 #define HWP_EPP_BALANCE_PERFORMANCE	0x80
 #define HWP_EPP_BALANCE_POWERSAVE	0xC0
 #define HWP_EPP_POWERSAVE		0xFF
-#define HWP_ACTIVITY_WINDOW(x)		((x & 0xff3) << 32)
-#define HWP_PACKAGE_CONTROL(x)		((x & 0x1) << 42)
+#define HWP_ACTIVITY_WINDOW(x)		((unsigned long long)(x & 0xff3) << 32)
+#define HWP_PACKAGE_CONTROL(x)		((unsigned long long)(x & 0x1) << 42)
 
 /* IA32_HWP_STATUS */
 #define HWP_GUARANTEED_CHANGE(x)	(x & 0x1)

commit 8d84e906f5db80540510e448226f2718a686eb2a
Author: Len Brown <len.brown@intel.com>
Date:   Sat Feb 25 11:56:29 2017 -0500

    x86: msr-index.h: define HWP.EPP values
    
    The Hardware Performance State request MSR has a field
    to express the "Energy Performance Preference" (HWP.EPP).
    
    Decode that field so the definition may be shared by
    by the intel_pstate driver and any utilities that
    decode the same register.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index a92d9bd154f6..50c0c3204a92 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -239,6 +239,10 @@
 #define HWP_MAX_PERF(x) 		((x & 0xff) << 8)
 #define HWP_DESIRED_PERF(x)		((x & 0xff) << 16)
 #define HWP_ENERGY_PERF_PREFERENCE(x)	((x & 0xff) << 24)
+#define HWP_EPP_PERFORMANCE		0x00
+#define HWP_EPP_BALANCE_PERFORMANCE	0x80
+#define HWP_EPP_BALANCE_POWERSAVE	0xC0
+#define HWP_EPP_POWERSAVE		0xFF
 #define HWP_ACTIVITY_WINDOW(x)		((x & 0xff3) << 32)
 #define HWP_PACKAGE_CONTROL(x)		((x & 0x1) << 42)
 

commit e9ea1e7f53b852147cbd568b0568c7ad97ec21a3
Author: Kyle Huey <me@kylehuey.com>
Date:   Mon Mar 20 01:16:26 2017 -0700

    x86/arch_prctl: Add ARCH_[GET|SET]_CPUID
    
    Intel supports faulting on the CPUID instruction beginning with Ivy Bridge.
    When enabled, the processor will fault on attempts to execute the CPUID
    instruction with CPL>0. Exposing this feature to userspace will allow a
    ptracer to trap and emulate the CPUID instruction.
    
    When supported, this feature is controlled by toggling bit 0 of
    MSR_MISC_FEATURES_ENABLES. It is documented in detail in Section 2.3.2 of
    https://bugzilla.kernel.org/attachment.cgi?id=243991
    
    Implement a new pair of arch_prctls, available on both x86-32 and x86-64.
    
    ARCH_GET_CPUID: Returns the current CPUID state, either 0 if CPUID faulting
        is enabled (and thus the CPUID instruction is not available) or 1 if
        CPUID faulting is not enabled.
    
    ARCH_SET_CPUID: Set the CPUID state to the second argument. If
        cpuid_enabled is 0 CPUID faulting will be activated, otherwise it will
        be deactivated. Returns ENODEV if CPUID faulting is not supported on
        this system.
    
    The state of the CPUID faulting flag is propagated across forks, but reset
    upon exec.
    
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: linux-kselftest@vger.kernel.org
    Cc: Nadav Amit <nadav.amit@gmail.com>
    Cc: Robert O'Callahan <robert@ocallahan.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: user-mode-linux-devel@lists.sourceforge.net
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: user-mode-linux-user@lists.sourceforge.net
    Cc: David Matlack <dmatlack@google.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dmitry Safonov <dsafonov@virtuozzo.com>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Link: http://lkml.kernel.org/r/20170320081628.18952-9-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b1f75daca34b..673f9ac50f6d 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -558,6 +558,8 @@
 /* MISC_FEATURES_ENABLES non-architectural features */
 #define MSR_MISC_FEATURES_ENABLES	0x00000140
 
+#define MSR_MISC_FEATURES_ENABLES_CPUID_FAULT_BIT	0
+#define MSR_MISC_FEATURES_ENABLES_CPUID_FAULT		BIT_ULL(MSR_MISC_FEATURES_ENABLES_CPUID_FAULT_BIT)
 #define MSR_MISC_FEATURES_ENABLES_RING3MWAIT_BIT	1
 
 #define MSR_IA32_TSC_DEADLINE		0x000006E0

commit 90218ac77d0582eaf2d0872d8d900cbd5bf1f205
Author: Kyle Huey <me@kylehuey.com>
Date:   Mon Mar 20 01:16:25 2017 -0700

    x86/cpufeature: Detect CPUID faulting support
    
    Intel supports faulting on the CPUID instruction beginning with Ivy Bridge.
    When enabled, the processor will fault on attempts to execute the CPUID
    instruction with CPL>0. This will allow a ptracer to emulate the CPUID
    instruction.
    
    Bit 31 of MSR_PLATFORM_INFO advertises support for this feature. It is
    documented in detail in Section 2.3.2 of
    https://bugzilla.kernel.org/attachment.cgi?id=243991
    
    Detect support for this feature and expose it as X86_FEATURE_CPUID_FAULT.
    
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: linux-kselftest@vger.kernel.org
    Cc: Nadav Amit <nadav.amit@gmail.com>
    Cc: Robert O'Callahan <robert@ocallahan.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: user-mode-linux-devel@lists.sourceforge.net
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: user-mode-linux-user@lists.sourceforge.net
    Cc: David Matlack <dmatlack@google.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dmitry Safonov <dsafonov@virtuozzo.com>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Link: http://lkml.kernel.org/r/20170320081628.18952-8-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index f429b70ebaef..b1f75daca34b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -45,6 +45,8 @@
 #define MSR_IA32_PERFCTR1		0x000000c2
 #define MSR_FSB_FREQ			0x000000cd
 #define MSR_PLATFORM_INFO		0x000000ce
+#define MSR_PLATFORM_INFO_CPUID_FAULT_BIT	31
+#define MSR_PLATFORM_INFO_CPUID_FAULT		BIT_ULL(MSR_PLATFORM_INFO_CPUID_FAULT_BIT)
 
 #define MSR_PKG_CST_CONFIG_CONTROL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)

commit ab6d9468631a6e56e4c071c6ce6710956485fe08
Author: Kyle Huey <me@kylehuey.com>
Date:   Mon Mar 20 01:16:19 2017 -0700

    x86/msr: Rename MISC_FEATURE_ENABLES to MISC_FEATURES_ENABLES
    
    This matches the only public Intel documentation of this MSR, in the
    "Virtualization Technology FlexMigration Application Note"
    (preserved at https://bugzilla.kernel.org/attachment.cgi?id=243991)
    
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: linux-kselftest@vger.kernel.org
    Cc: Nadav Amit <nadav.amit@gmail.com>
    Cc: Robert O'Callahan <robert@ocallahan.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: user-mode-linux-devel@lists.sourceforge.net
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: user-mode-linux-user@lists.sourceforge.net
    Cc: David Matlack <dmatlack@google.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Dmitry Safonov <dsafonov@virtuozzo.com>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Link: http://lkml.kernel.org/r/20170320081628.18952-2-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 4c928f332f8f..f429b70ebaef 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -553,10 +553,10 @@
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT	39
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT)
 
-/* MISC_FEATURE_ENABLES non-architectural features */
-#define MSR_MISC_FEATURE_ENABLES	0x00000140
+/* MISC_FEATURES_ENABLES non-architectural features */
+#define MSR_MISC_FEATURES_ENABLES	0x00000140
 
-#define MSR_MISC_FEATURE_ENABLES_RING3MWAIT_BIT		1
+#define MSR_MISC_FEATURES_ENABLES_RING3MWAIT_BIT	1
 
 #define MSR_IA32_TSC_DEADLINE		0x000006E0
 

commit b9894a2f5bd18b1691cb6872c9afe32b148d0132
Author: Kyle Huey <me@kylehuey.com>
Date:   Tue Feb 14 00:11:03 2017 -0800

    x86/process: Correct and optimize TIF_BLOCKSTEP switch
    
    The debug control MSR is "highly magical" as the blockstep bit can be
    cleared by hardware under not well documented circumstances.
    
    So a task switch relying on the bit set by the previous task (according to
    the previous tasks thread flags) can trip over this and not update the flag
    for the next task.
    
    To fix this its required to handle DEBUGCTLMSR_BTF when either the previous
    or the next or both tasks have the TIF_BLOCKSTEP flag set.
    
    While at it avoid branching within the TIF_BLOCKSTEP case and evaluating
    boot_cpu_data twice in kernels without CONFIG_X86_DEBUGCTLMSR.
    
    x86_64: arch/x86/kernel/process.o
    text    data    bss     dec      hex
    3024    8577    16      11617    2d61   Before
    3008    8577    16      11601    2d51   After
    
    i386: No change
    
    [ tglx: Made the shift value explicit, use a local variable to make the
    code readable and massaged changelog]
    
    Originally-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: http://lkml.kernel.org/r/20170214081104.9244-3-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index d8b5f8ab8ef9..4c928f332f8f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -127,6 +127,7 @@
 
 /* DEBUGCTLMSR bits (others vary by model): */
 #define DEBUGCTLMSR_LBR			(1UL <<  0) /* last branch recording */
+#define DEBUGCTLMSR_BTF_SHIFT		1
 #define DEBUGCTLMSR_BTF			(1UL <<  1) /* single-step on branches */
 #define DEBUGCTLMSR_TR			(1UL <<  6)
 #define DEBUGCTLMSR_BTS			(1UL <<  7)

commit 6bff9c609f3df4e325da08783f691cab9316d643
Merge: 02c3de110522 e3942ed8c66b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Mar 1 23:34:38 2017 +0100

    Merge branch 'turbostat' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    Pull changes related to turbostat for v4.11 from Len Brown.
    
    * 'turbostat' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux: (44 commits)
      tools/power turbostat: version 17.02.24
      tools/power turbostat: bugfix: --add u32 was printed as u64
      tools/power turbostat: show error on exec
      tools/power turbostat: dump p-state software config
      tools/power turbostat: show package number, even without --debug
      tools/power turbostat: support "--hide C1" etc.
      tools/power turbostat: move --Package and --processor into the --cpu option
      tools/power turbostat: turbostat.8 update
      tools/power turbostat: update --list feature
      tools/power turbostat: use wide columns to display large numbers
      tools/power turbostat: Add --list option to show available header names
      tools/power turbostat: fix zero IRQ count shown in one-shot command mode
      tools/power turbostat: add --cpu parameter
      tools/power turbostat: print sysfs C-state stats
      tools/power turbostat: extend --add option to accept /sys path
      tools/power turbostat: skip unused counters on BDX
      tools/power turbostat: fix decoding for GLM, DNV, SKX turbo-ratio limits
      tools/power turbostat: skip unused counters on SKX
      tools/power turbostat: Denverton: use HW CC1 counter, skip C3, C7
      tools/power turbostat: initial Gemini Lake SOC support
      ...

commit 98af74599ea0757098a5776ea29e581b661dcf6f
Author: Len Brown <len.brown@intel.com>
Date:   Sat Jan 21 01:15:09 2017 -0500

    x86 msr_index.h: Define MSR_MISC_FEATURE_CONTROL
    
    This non-architectural MSR has disable bits
    for various prefetchers on modern processors.
    
    While these bits are generally touched only by the BIOS,
    say, via BIOS SETUP, it is useful to dump them
    when examining options that can alter performance.
    
    Cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 83bc672c225c..312fb7e14cdd 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -467,6 +467,7 @@
 
 #define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
 
+#define MSR_MISC_FEATURE_CONTROL	0x000001a4
 #define MSR_MISC_PWR_MGMT		0x000001aa
 
 #define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0

commit 8a34fd0226eaae64d61ff9a113d276e28acb6b5c
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jan 12 23:22:28 2017 -0500

    x86 msr-index.h: Define Atom specific core ratio MSR locations
    
    These MSRs are currently used by the intel_pstate driver,
    using a local definition.
    
    Cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 079db99f6560..83bc672c225c 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -209,6 +209,12 @@
 #define MSR_CC6_DEMOTION_POLICY_CONFIG	0x00000668
 #define MSR_MC6_DEMOTION_POLICY_CONFIG	0x00000669
 
+#define MSR_ATOM_CORE_RATIOS		0x0000066a
+#define MSR_ATOM_CORE_VIDS		0x0000066b
+#define MSR_ATOM_CORE_TURBO_RATIOS	0x0000066c
+#define MSR_ATOM_CORE_TURBO_VIDS	0x0000066d
+
+
 #define MSR_CORE_PERF_LIMIT_REASONS	0x00000690
 #define MSR_GFX_PERF_LIMIT_REASONS	0x000006B0
 #define MSR_RING_PERF_LIMIT_REASONS	0x000006B1

commit 0539ba118fe241b0d03202fda0cd19cb758b7fbd
Author: Len Brown <len.brown@intel.com>
Date:   Fri Feb 10 00:27:20 2017 -0500

    tools/power turbostat: Baytrail c-state support
    
    The Baytrail SOC, with its Silvermont core, has some unique properties:
    
    1. a hardware CC1 residency counter
    2. a module-c6 residency counter
    3. a package-c6 counter at traditional package-c7 counter address.
    
    The SOC does not support c3, pc3, c7 or pc7 counters.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 12ecc6c1e7f8..079db99f6560 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -147,6 +147,7 @@
 /* C-state Residency Counters */
 #define MSR_PKG_C3_RESIDENCY		0x000003f8
 #define MSR_PKG_C6_RESIDENCY		0x000003f9
+#define MSR_ATOM_PKG_C6_RESIDENCY	0x000003fa
 #define MSR_PKG_C7_RESIDENCY		0x000003fa
 #define MSR_CORE_C3_RESIDENCY		0x000003fc
 #define MSR_CORE_C6_RESIDENCY		0x000003fd
@@ -203,6 +204,7 @@
 #define MSR_PKG_BOTH_CORE_GFXE_C0_RES	0x0000065B
 
 #define MSR_CORE_C1_RES			0x00000660
+#define MSR_MODULE_C6_RES_MS		0x00000664
 
 #define MSR_CC6_DEMOTION_POLICY_CONFIG	0x00000668
 #define MSR_MC6_DEMOTION_POLICY_CONFIG	0x00000669

commit 419c9e986ea453d07140bffb9708d730b6317e8e
Author: Len Brown <len.brown@intel.com>
Date:   Sat Jan 7 23:26:22 2017 -0500

    x86: msr-index.h: Remove unused MSR_NHM_SNB_PKG_CST_CFG_CTL
    
    The two users, intel_idle driver and turbostat utility
    are using the new name, MSR_PKG_CST_CONFIG_CONTROL
    
    Cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 975f23eefe14..12ecc6c1e7f8 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -46,7 +46,6 @@
 #define MSR_FSB_FREQ			0x000000cd
 #define MSR_PLATFORM_INFO		0x000000ce
 
-#define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
 #define MSR_PKG_CST_CONFIG_CONTROL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)

commit 40496c8ee73a5ca4fa581badf2247418980586b1
Author: Len Brown <len.brown@intel.com>
Date:   Sat Jan 7 23:21:18 2017 -0500

    x86: msr-index.h: Define MSR_PKG_CST_CONFIG_CONTROL
    
    define MSR_PKG_CST_CONFIG_CONTROL (0xE2),
    which is the string used by Intel Documentation.
    
    We use this MSR in intel_idle and turbostat by a previous name,
    to be updated in the next patch.
    
    Cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 710273c617b8..975f23eefe14 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -47,6 +47,7 @@
 #define MSR_PLATFORM_INFO		0x000000ce
 
 #define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
+#define MSR_PKG_CST_CONFIG_CONTROL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)
 #define ATM_LNC_C6_AUTO_DEMOTE		(1UL << 25)

commit d0117a0e2780f7803fe55d543ab119416d7582e6
Author: Len Brown <len.brown@intel.com>
Date:   Sat Feb 25 18:18:22 2017 -0500

    x86: msr-index.h: define EPB mid-points
    
    These are currently open-coded into intel_pstate.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 710273c617b8..a92d9bd154f6 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -462,9 +462,11 @@
 #define MSR_MISC_PWR_MGMT		0x000001aa
 
 #define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
-#define ENERGY_PERF_BIAS_PERFORMANCE	0
-#define ENERGY_PERF_BIAS_NORMAL		6
-#define ENERGY_PERF_BIAS_POWERSAVE	15
+#define ENERGY_PERF_BIAS_PERFORMANCE		0
+#define ENERGY_PERF_BIAS_BALANCE_PERFORMANCE	4
+#define ENERGY_PERF_BIAS_NORMAL			6
+#define ENERGY_PERF_BIAS_BALANCE_POWERSAVE	8
+#define ENERGY_PERF_BIAS_POWERSAVE		15
 
 #define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
 

commit ae47eda905e61ef6ba0b6f79b967c9de15ca4f8e
Author: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
Date:   Fri Jan 20 14:22:33 2017 +0100

    x86/msr: Add MSR_MISC_FEATURE_ENABLES and RING3MWAIT bit
    
    Define new MSR MISC_FEATURE_ENABLES (0x140).
    
    On supported CPUs if bit 1 of this MSR is set, then calling MONITOR and
    MWAIT instructions outside of ring 0 will not cause invalid-opcode
    exception.
    
    The MSR MISC_FEATURE_ENABLES is not yet documented in the SDM. Here is the
    relevant documentation:
    
    Hex   Dec  Name                     Scope
    140H  320  MISC_FEATURE_ENABLES     Thread
               0    Reserved
               1    If set to 1, the MONITOR and MWAIT instructions do not
                    cause invalid-opcode exceptions when executed with CPL > 0
                    or in virtual-8086 mode. If MWAIT is executed when CPL > 0
                    or in virtual-8086 mode, and if EAX indicates a C-state
                    other than C0 or C1, the instruction operates as if EAX
                    indicated the C-state C1.
               63:2 Reserved
    
    Signed-off-by: Grzegorz Andrejczuk <grzegorz.andrejczuk@intel.com>
    Cc: Piotr.Luc@intel.com
    Cc: dave.hansen@linux.intel.com
    Link: http://lkml.kernel.org/r/1484918557-15481-2-git-send-email-grzegorz.andrejczuk@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 710273c617b8..00293a94ffaf 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -543,6 +543,11 @@
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT	39
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT)
 
+/* MISC_FEATURE_ENABLES non-architectural features */
+#define MSR_MISC_FEATURE_ENABLES	0x00000140
+
+#define MSR_MISC_FEATURE_ENABLES_RING3MWAIT_BIT		1
+
 #define MSR_IA32_TSC_DEADLINE		0x000006E0
 
 /* P4/Xeon+ specific */

commit 3f5a7896a5096fd50030a04d4c3f28a7441e30a5
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Nov 18 09:48:36 2016 -0800

    x86/mce: Include the PPIN in MCE records when available
    
    Intel Xeons from Ivy Bridge onwards support a processor identification
    number set in the factory. To the user this is a handy unique number to
    identify a particular CPU. Intel can decode this to the fab/production
    run to track errors. On systems that have it, include it in the machine
    check record. I'm told that this would be helpful for users that run
    large data centers with multi-socket servers to keep track of which CPUs
    are seeing errors.
    
    Boris:
    * Add some clarifying comments and spacing.
    * Mask out [63:2] in the disabled-but-not-locked case
    * Call the MSR variable "val" for more readability.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: linux-edac <linux-edac@vger.kernel.org>
    Cc: x86-ml <x86@kernel.org>
    Link: http://lkml.kernel.org/r/20161123114855.njguoaygp3qnbkia@pd.tnic
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 78f3760ca1f2..710273c617b8 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -37,6 +37,10 @@
 #define EFER_FFXSR		(1<<_EFER_FFXSR)
 
 /* Intel MSRs. Some also available on other CPUs */
+
+#define MSR_PPIN_CTL			0x0000004e
+#define MSR_PPIN			0x0000004f
+
 #define MSR_IA32_PERFCTR0		0x000000c1
 #define MSR_IA32_PERFCTR1		0x000000c2
 #define MSR_FSB_FREQ			0x000000cd

commit c836eeda3e1e652d424bbbbb908f07eb7380448c
Author: Longpeng(Mike) <longpeng2@huawei.com>
Date:   Fri Oct 14 08:42:20 2016 +0800

    x86: Remove duplicate rtit status MSR macro
    
    The MSR_IA32_RTIT_STATUS is defined twice, so remove one.
    
    Signed-off-by: Longpeng(Mike) <longpeng2@huawei.com>
    Acked-by: Borislav Petkov <bp@suse.de>
    Cc: len.brown@intel.com
    Cc: peterz@infradead.org
    Cc: rafael.j.wysocki@intel.com
    Cc: alexander.shishkin@linux.intel.com
    Cc: ray.huang@amd.com
    Cc: Aravind.Gopalakrishnan@amd.com
    Cc: wu.wubin@huawei.com
    Cc: srinivas.pandruvada@linux.intel.com
    Cc: zhaoshenglong@huawei.com
    Cc: vladimir_zapolskiy@mentor.com
    Link: http://lkml.kernel.org/r/1476405740-80816-1-git-send-email-longpeng2@huawei.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 56f4c6676b29..78f3760ca1f2 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -88,7 +88,6 @@
 
 #define MSR_IA32_RTIT_CTL		0x00000570
 #define MSR_IA32_RTIT_STATUS		0x00000571
-#define MSR_IA32_RTIT_STATUS		0x00000571
 #define MSR_IA32_RTIT_ADDR0_A		0x00000580
 #define MSR_IA32_RTIT_ADDR0_B		0x00000581
 #define MSR_IA32_RTIT_ADDR1_A		0x00000582

commit a0c9b8cc43e0acada4574b33a19b5178520f1218
Author: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
Date:   Wed Jul 6 16:07:57 2016 -0700

    x86: remove duplicate turbo ratio limit MSRs
    
    Remove MSR_NHM_TURBO_RATIO_LIMIT and MSR_IVT_TURBO_RATIO_LIMIT as
    they are duplicate.
    
    Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 5a73a9c62c39..56f4c6676b29 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -64,8 +64,6 @@
 
 #define MSR_OFFCORE_RSP_0		0x000001a6
 #define MSR_OFFCORE_RSP_1		0x000001a7
-#define MSR_NHM_TURBO_RATIO_LIMIT	0x000001ad
-#define MSR_IVT_TURBO_RATIO_LIMIT	0x000001ae
 #define MSR_TURBO_RATIO_LIMIT		0x000001ad
 #define MSR_TURBO_RATIO_LIMIT1		0x000001ae
 #define MSR_TURBO_RATIO_LIMIT2		0x000001af

commit f127fa098d76444c7a47b2f009356979492d77cd
Author: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Date:   Wed Apr 27 18:44:44 2016 +0300

    perf/x86/intel/pt: Add IP filtering register/CPUID bits
    
    New versions of Intel PT support address range-based filtering. Add
    the new registers, bit definitions and relevant CPUID bits.
    
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: vince@deater.net
    Link: http://lkml.kernel.org/r/1461771888-10409-4-git-send-email-alexander.shishkin@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 7193577d8bc9..5a73a9c62c39 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -90,6 +90,15 @@
 
 #define MSR_IA32_RTIT_CTL		0x00000570
 #define MSR_IA32_RTIT_STATUS		0x00000571
+#define MSR_IA32_RTIT_STATUS		0x00000571
+#define MSR_IA32_RTIT_ADDR0_A		0x00000580
+#define MSR_IA32_RTIT_ADDR0_B		0x00000581
+#define MSR_IA32_RTIT_ADDR1_A		0x00000582
+#define MSR_IA32_RTIT_ADDR1_B		0x00000583
+#define MSR_IA32_RTIT_ADDR2_A		0x00000584
+#define MSR_IA32_RTIT_ADDR2_B		0x00000585
+#define MSR_IA32_RTIT_ADDR3_A		0x00000586
+#define MSR_IA32_RTIT_ADDR3_B		0x00000587
 #define MSR_IA32_RTIT_CR3_MATCH		0x00000572
 #define MSR_IA32_RTIT_OUTPUT_BASE	0x00000560
 #define MSR_IA32_RTIT_OUTPUT_MASK	0x00000561

commit 0dd28e2cdaff5319c86cc3ed11d1ca4cf1554046
Author: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Date:   Wed Apr 27 18:44:43 2016 +0300

    perf/x86/intel/pt: Move PT specific MSR bit definitions to a private header
    
    Nothing outside of the Intel PT driver should ever care about its MSR
    bits, so there is no reason to keep them in msr-index.h. This patch
    moves them to a pt-local header.
    
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: vince@deater.net
    Link: http://lkml.kernel.org/r/1461771888-10409-3-git-send-email-alexander.shishkin@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 94555b4d85cf..7193577d8bc9 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -89,27 +89,7 @@
 #define MSR_PEBS_LD_LAT_THRESHOLD	0x000003f6
 
 #define MSR_IA32_RTIT_CTL		0x00000570
-#define RTIT_CTL_TRACEEN		BIT(0)
-#define RTIT_CTL_CYCLEACC		BIT(1)
-#define RTIT_CTL_OS			BIT(2)
-#define RTIT_CTL_USR			BIT(3)
-#define RTIT_CTL_CR3EN			BIT(7)
-#define RTIT_CTL_TOPA			BIT(8)
-#define RTIT_CTL_MTC_EN			BIT(9)
-#define RTIT_CTL_TSC_EN			BIT(10)
-#define RTIT_CTL_DISRETC		BIT(11)
-#define RTIT_CTL_BRANCH_EN		BIT(13)
-#define RTIT_CTL_MTC_RANGE_OFFSET	14
-#define RTIT_CTL_MTC_RANGE		(0x0full << RTIT_CTL_MTC_RANGE_OFFSET)
-#define RTIT_CTL_CYC_THRESH_OFFSET	19
-#define RTIT_CTL_CYC_THRESH		(0x0full << RTIT_CTL_CYC_THRESH_OFFSET)
-#define RTIT_CTL_PSB_FREQ_OFFSET	24
-#define RTIT_CTL_PSB_FREQ      		(0x0full << RTIT_CTL_PSB_FREQ_OFFSET)
 #define MSR_IA32_RTIT_STATUS		0x00000571
-#define RTIT_STATUS_CONTEXTEN		BIT(1)
-#define RTIT_STATUS_TRIGGEREN		BIT(2)
-#define RTIT_STATUS_ERROR		BIT(4)
-#define RTIT_STATUS_STOPPED		BIT(5)
 #define MSR_IA32_RTIT_CR3_MATCH		0x00000572
 #define MSR_IA32_RTIT_OUTPUT_BASE	0x00000560
 #define MSR_IA32_RTIT_OUTPUT_MASK	0x00000561

commit dcee75b3b7f025cc6765e6c92ba0a4e59a4d25f4
Author: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
Date:   Sun Apr 17 15:03:00 2016 -0700

    perf/x86/intel/rapl: Support Skylake RAPL domains
    
    Add Skylake client support for RAPL domains. In addition to RAPL domains
    in Broadwell clients, it has support for platform domain (aka PSys). The
    PSys domain controls the entire SoC instead of just a CPU package. Unlike
    package domain, PSys support requires more than just processor level
    implementation. The other parts in the system need additional HW level
    signaling, which OEMs need to support. When not supported, the energy
    counter register in PSys domain returns 0.
    
    Also corrected error in comment for GPU counter, which previously was
    DRAM counter.
    
    Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com
    [ Cnverted to model_match stuff. ]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: bp@alien8.de
    Cc: hpa@zytor.com
    Cc: jacob.jun.pan@linux.intel.com
    Cc: rjw@rjwysocki.net
    Link: http://lkml.kernel.org/r/1460930581-29748-2-git-send-email-srinivas.pandruvada@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index f882cbf9e3da..94555b4d85cf 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -205,6 +205,8 @@
 #define MSR_CONFIG_TDP_CONTROL		0x0000064B
 #define MSR_TURBO_ACTIVATION_RATIO	0x0000064C
 
+#define MSR_PLATFORM_ENERGY_STATUS	0x0000064D
+
 #define MSR_PKG_WEIGHTED_CORE_C0_RES	0x00000658
 #define MSR_PKG_ANY_CORE_C0_RES		0x00000659
 #define MSR_PKG_ANY_GFXE_C0_RES		0x0000065A

commit 889fac6d67d46a5e781c08fb26fec9016db1c307
Merge: dad38ca64a25 bf1620068911
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Apr 13 08:57:03 2016 +0200

    Merge tag 'v4.6-rc3' into perf/core, to refresh the tree
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 73659be769a4f0ac26a6b3fc6699754adba36485
Merge: fa81e66ec864 16669befb077 462d8083fb2d 9185e988e9d5
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Apr 8 21:46:56 2016 +0200

    Merge branches 'pm-core', 'powercap' and 'pm-tools'
    
    * pm-core:
      PM / wakeirq: fix wakeirq setting after wakup re-configuration from sysfs
      PM / runtime: Document steps for device removal
    
    * powercap:
      powercap: intel_rapl: Add missing Haswell model
    
    * pm-tools:
      tools/power turbostat: work around RC6 counter wrap
      tools/power turbostat: initial KBL support
      tools/power turbostat: initial SKX support
      tools/power turbostat: decode BXT TSC frequency via CPUID
      tools/power turbostat: initial BXT support
      tools/power turbostat: print IRTL MSRs
      tools/power turbostat: SGX state should print only if --debug

commit 5a63426e2a18775ed05b20e3bc90c68bacb1f68a
Author: Len Brown <len.brown@intel.com>
Date:   Wed Apr 6 17:15:55 2016 -0400

    tools/power turbostat: print IRTL MSRs
    
    Some processors use the Interrupt Response Time Limit (IRTL) MSR value
    to describe the maximum IRQ response time latency for deep
    package C-states.  (Though others have the register, but do not use it)
    Lets print it out to give insight into the cases where it is used.
    
    IRTL begain in SNB, with PC3/PC6/PC7, and HSW added PC8/PC9/PC10.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 3fec311f7b9a..7b27e3241e5a 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -162,6 +162,14 @@
 #define MSR_PKG_C9_RESIDENCY		0x00000631
 #define MSR_PKG_C10_RESIDENCY		0x00000632
 
+/* Interrupt Response Limit */
+#define MSR_PKGC3_IRTL			0x0000060a
+#define MSR_PKGC6_IRTL			0x0000060b
+#define MSR_PKGC7_IRTL			0x0000060c
+#define MSR_PKGC8_IRTL			0x00000633
+#define MSR_PKGC9_IRTL			0x00000634
+#define MSR_PKGC10_IRTL			0x00000635
+
 /* Run Time Average Power Limiting (RAPL) Interface */
 
 #define MSR_RAPL_POWER_UNIT		0x00000606

commit aaf248848db503927644d28e239bc399ed45959f
Author: Huang Rui <ray.huang@amd.com>
Date:   Fri Jan 29 16:29:57 2016 +0800

    perf/x86/msr: Add AMD IRPERF (Instructions Retired) performance counter
    
    AMD Zeppelin (Family 17h, Model 00h) introduces an instructions
    retired performance counter which is indicated by
    CPUID.8000_0008H:EBX[1]. A dedicated Instructions Retired MSR register
    (MSR 0xC000_000E9) increments once for every instruction retired.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Jacob Shin <jacob.w.shin@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Robert Richter <rric@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Link: http://lkml.kernel.org/r/1454056197-5893-3-git-send-email-ray.huang@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6e6a5ccfb3f5..e0e2f7dfbd36 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -313,6 +313,9 @@
 #define MSR_AMD64_IBSOPDATA4		0xc001103d
 #define MSR_AMD64_IBS_REG_COUNT_MAX	8 /* includes MSR_AMD64_IBSBRTARGET */
 
+/* Fam 17h MSRs */
+#define MSR_F17H_IRPERF			0xc00000e9
+
 /* Fam 16h MSRs */
 #define MSR_F16H_L2I_PERF_CTL		0xc0010230
 #define MSR_F16H_L2I_PERF_CTR		0xc0010231

commit 8a22426184774d7ced9c1d3aa4d95d34101fb3be
Author: Huang Rui <ray.huang@amd.com>
Date:   Fri Jan 29 16:29:56 2016 +0800

    perf/x86/msr: Add AMD PTSC (Performance Time-Stamp Counter) support
    
    AMD Carrizo (Family 15h, Model 60h) introduces a time-stamp counter
    which is indicated by CPUID.8000_0001H:ECX[27]. It increments at a 100
    MHz rate in all P-states, and C states, S0, or S1. The frequency is
    about 100MHz. This counter will be used to calculate processor power
    and other parts. So add an interface into the MSR PMU to get the PTSC
    counter value.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Jacob Shin <jacob.w.shin@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Robert Richter <rric@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Link: http://lkml.kernel.org/r/1454056197-5893-2-git-send-email-ray.huang@amd.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 984ab75bf621..6e6a5ccfb3f5 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -326,6 +326,7 @@
 #define MSR_F15H_PERF_CTR		0xc0010201
 #define MSR_F15H_NB_PERF_CTL		0xc0010240
 #define MSR_F15H_NB_PERF_CTR		0xc0010241
+#define MSR_F15H_PTSC			0xc0010280
 #define MSR_F15H_IC_CFG			0xc0011021
 
 /* Fam 10h MSRs */

commit 4a6772f514891eaacf26bcb7c2c808c557d23c6f
Author: Vladimir Zapolskiy <vladimir_zapolskiy@mentor.com>
Date:   Sat Mar 26 20:47:00 2016 +0200

    x86/cpufreq: Remove duplicated TDP MSR macro definitions
    
    The list of CPU model specific registers contains two copies of TDP
    registers, remove the one, which is out of numerical order in the
    list.
    
    Fixes: 6a35fc2d6c22 ("cpufreq: intel_pstate: get P1 from TAR when available")
    Signed-off-by: Vladimir Zapolskiy <vladimir_zapolskiy@mentor.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: "Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
    Cc: Kristen Carlson
     Accardi <kristen@linux.intel.com>
    Cc: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
    Link: http://lkml.kernel.org/r/1459018020-24577-1-git-send-email-vladimir_zapolskiy@mentor.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 2da46ac16e37..426e946ed0c0 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -190,6 +190,7 @@
 #define MSR_PP1_ENERGY_STATUS		0x00000641
 #define MSR_PP1_POLICY			0x00000642
 
+/* Config TDP MSRs */
 #define MSR_CONFIG_TDP_NOMINAL		0x00000648
 #define MSR_CONFIG_TDP_LEVEL_1		0x00000649
 #define MSR_CONFIG_TDP_LEVEL_2		0x0000064A
@@ -210,13 +211,6 @@
 #define MSR_GFX_PERF_LIMIT_REASONS	0x000006B0
 #define MSR_RING_PERF_LIMIT_REASONS	0x000006B1
 
-/* Config TDP MSRs */
-#define MSR_CONFIG_TDP_NOMINAL		0x00000648
-#define MSR_CONFIG_TDP_LEVEL1		0x00000649
-#define MSR_CONFIG_TDP_LEVEL2		0x0000064A
-#define MSR_CONFIG_TDP_CONTROL		0x0000064B
-#define MSR_TURBO_ACTIVATION_RATIO	0x0000064C
-
 /* Hardware P state interface */
 #define MSR_PPERF			0x0000064e
 #define MSR_PERF_LIMIT_REASONS		0x0000064f

commit 277edbabf6fece057b14fb6db5e3a34e00f42f42
Merge: 271ecc5253e2 0d571b62dd8e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 16 14:10:53 2016 -0700

    Merge tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management and ACPI updates from Rafael Wysocki:
     "This time the majority of changes go into cpufreq and they are
      significant.
    
      First off, the way CPU frequency updates are triggered is different
      now.  Instead of having to set up and manage a deferrable timer for
      each CPU in the system to evaluate and possibly change its frequency
      periodically, cpufreq governors set up callbacks to be invoked by the
      scheduler on a regular basis (basically on utilization updates).  The
      "old" governors, "ondemand" and "conservative", still do all of their
      work in process context (although that is triggered by the scheduler
      now), but intel_pstate does it all in the callback invoked by the
      scheduler with no need for any additional asynchronous processing.
    
      Of course, this eliminates the overhead related to the management of
      all those timers, but also it allows the cpufreq governor code to be
      simplified quite a bit.  On top of that, the common code and data
      structures used by the "ondemand" and "conservative" governors are
      cleaned up and made more straightforward and some long-standing and
      quite annoying problems are addressed.  In particular, the handling of
      governor sysfs attributes is modified and the related locking becomes
      more fine grained which allows some concurrency problems to be avoided
      (particularly deadlocks with the core cpufreq code).
    
      In principle, the new mechanism for triggering frequency updates
      allows utilization information to be passed from the scheduler to
      cpufreq.  Although the current code doesn't make use of it, in the
      works is a new cpufreq governor that will make decisions based on the
      scheduler's utilization data.  That should allow the scheduler and
      cpufreq to work more closely together in the long run.
    
      In addition to the core and governor changes, cpufreq drivers are
      updated too.  Fixes and optimizations go into intel_pstate, the
      cpufreq-dt driver is updated on top of some modification in the
      Operating Performance Points (OPP) framework and there are fixes and
      other updates in the powernv cpufreq driver.
    
      Apart from the cpufreq updates there is some new ACPICA material,
      including a fix for a problem introduced by previous ACPICA updates,
      and some less significant changes in the ACPI code, like CPPC code
      optimizations, ACPI processor driver cleanups and support for loading
      ACPI tables from initrd.
    
      Also updated are the generic power domains framework, the Intel RAPL
      power capping driver and the turbostat utility and we have a bunch of
      traditional assorted fixes and cleanups.
    
      Specifics:
    
       - Redesign of cpufreq governors and the intel_pstate driver to make
         them use callbacks invoked by the scheduler to trigger CPU
         frequency evaluation instead of using per-CPU deferrable timers for
         that purpose (Rafael Wysocki).
    
       - Reorganization and cleanup of cpufreq governor code to make it more
         straightforward and fix some concurrency problems in it (Rafael
         Wysocki, Viresh Kumar).
    
       - Cleanup and improvements of locking in the cpufreq core (Viresh
         Kumar).
    
       - Assorted cleanups in the cpufreq core (Rafael Wysocki, Viresh
         Kumar, Eric Biggers).
    
       - intel_pstate driver updates including fixes, optimizations and a
         modification to make it enable enable hardware-coordinated P-state
         selection (HWP) by default if supported by the processor (Philippe
         Longepe, Srinivas Pandruvada, Rafael Wysocki, Viresh Kumar, Felipe
         Franciosi).
    
       - Operating Performance Points (OPP) framework updates to improve its
         handling of voltage regulators and device clocks and updates of the
         cpufreq-dt driver on top of that (Viresh Kumar, Jon Hunter).
    
       - Updates of the powernv cpufreq driver to fix initialization and
         cleanup problems in it and correct its worker thread handling with
         respect to CPU offline, new powernv_throttle tracepoint (Shilpasri
         Bhat).
    
       - ACPI cpufreq driver optimization and cleanup (Rafael Wysocki).
    
       - ACPICA updates including one fix for a regression introduced by
         previos changes in the ACPICA code (Bob Moore, Lv Zheng, David Box,
         Colin Ian King).
    
       - Support for installing ACPI tables from initrd (Lv Zheng).
    
       - Optimizations of the ACPI CPPC code (Prashanth Prakash, Ashwin
         Chaugule).
    
       - Support for _HID(ACPI0010) devices (ACPI processor containers) and
         ACPI processor driver cleanups (Sudeep Holla).
    
       - Support for ACPI-based enumeration of the AMBA bus (Graeme Gregory,
         Aleksey Makarov).
    
       - Modification of the ACPI PCI IRQ management code to make it treat
         255 in the Interrupt Line register as "not connected" on x86 (as
         per the specification) and avoid attempts to use that value as a
         valid interrupt vector (Chen Fan).
    
       - ACPI APEI fixes related to resource leaks (Josh Hunt).
    
       - Removal of modularity from a few ACPI drivers (BGRT, GHES,
         intel_pmic_crc) that cannot be built as modules in practice (Paul
         Gortmaker).
    
       - PNP framework update to make it treat ACPI_RESOURCE_TYPE_SERIAL_BUS
         as a valid resource type (Harb Abdulhamid).
    
       - New device ID (future AMD I2C controller) in the ACPI driver for
         AMD SoCs (APD) and in the designware I2C driver (Xiangliang Yu).
    
       - Assorted ACPI cleanups (Colin Ian King, Kaiyen Chang, Oleg Drokin).
    
       - cpuidle menu governor optimization to avoid a square root
         computation in it (Rasmus Villemoes).
    
       - Fix for potential use-after-free in the generic device properties
         framework (Heikki Krogerus).
    
       - Updates of the generic power domains (genpd) framework including
         support for multiple power states of a domain, fixes and debugfs
         output improvements (Axel Haslam, Jon Hunter, Laurent Pinchart,
         Geert Uytterhoeven).
    
       - Intel RAPL power capping driver updates to reduce IPI overhead in
         it (Jacob Pan).
    
       - System suspend/hibernation code cleanups (Eric Biggers, Saurabh
         Sengar).
    
       - Year 2038 fix for the process freezer (Abhilash Jindal).
    
       - turbostat utility updates including new features (decoding of more
         registers and CPUID fields, sub-second intervals support, GFX MHz
         and RC6 printout, --out command line option), fixes (syscall jitter
         detection and workaround, reductioin of the number of syscalls
         made, fixes related to Xeon x200 processors, compiler warning
         fixes) and cleanups (Len Brown, Hubert Chrzaniuk, Chen Yu)"
    
    * tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (182 commits)
      tools/power turbostat: bugfix: TDP MSRs print bits fixing
      tools/power turbostat: correct output for MSR_NHM_SNB_PKG_CST_CFG_CTL dump
      tools/power turbostat: call __cpuid() instead of __get_cpuid()
      tools/power turbostat: indicate SMX and SGX support
      tools/power turbostat: detect and work around syscall jitter
      tools/power turbostat: show GFX%rc6
      tools/power turbostat: show GFXMHz
      tools/power turbostat: show IRQs per CPU
      tools/power turbostat: make fewer systems calls
      tools/power turbostat: fix compiler warnings
      tools/power turbostat: add --out option for saving output in a file
      tools/power turbostat: re-name "%Busy" field to "Busy%"
      tools/power turbostat: Intel Xeon x200: fix turbo-ratio decoding
      tools/power turbostat: Intel Xeon x200: fix erroneous bclk value
      tools/power turbostat: allow sub-sec intervals
      ACPI / APEI: ERST: Fixed leaked resources in erst_init
      ACPI / APEI: Fix leaked resources
      intel_pstate: Do not skip samples partially
      intel_pstate: Remove freq calculation from intel_pstate_calc_busy()
      intel_pstate: Move intel_pstate_calc_busy() into get_target_pstate_use_performance()
      ...

commit 3fdb74649b4f18ccaa88766750b616dec6acb5b0
Merge: 5b3e7e0536bd 685b535b2cdb
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Mar 14 02:13:05 2016 +0100

    Merge branch 'turbostat' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux into pm-tools
    
    Pull turbostat updates for 4.6 from Len Brown.
    
    * 'turbostat' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux:
      tools/power turbostat: bugfix: TDP MSRs print bits fixing
      tools/power turbostat: correct output for MSR_NHM_SNB_PKG_CST_CFG_CTL dump
      tools/power turbostat: call __cpuid() instead of __get_cpuid()
      tools/power turbostat: indicate SMX and SGX support
      tools/power turbostat: detect and work around syscall jitter
      tools/power turbostat: show GFX%rc6
      tools/power turbostat: show GFXMHz
      tools/power turbostat: show IRQs per CPU
      tools/power turbostat: make fewer systems calls
      tools/power turbostat: fix compiler warnings
      tools/power turbostat: add --out option for saving output in a file
      tools/power turbostat: re-name "%Busy" field to "Busy%"
      tools/power turbostat: Intel Xeon x200: fix turbo-ratio decoding
      tools/power turbostat: Intel Xeon x200: fix erroneous bclk value
      tools/power turbostat: allow sub-sec intervals
      tools/power turbostat: Decode MSR_MISC_PWR_MGMT
      tools/power turbostat: decode HWP registers
      x86 msr-index: Simplify syntax for HWP fields
      tools/power turbostat: CPUID(0x16) leaf shows base, max, and bus frequency
      tools/power turbostat: decode more CPUID fields

commit 053080a9d1c8cf1950115ad92ce94242ebc5f25c
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Feb 16 09:43:22 2016 +0100

    x86/msr: Document msr-index.h rule for addition
    
    In order to keep this file's size sensible and not cause too much
    unnecessary churn, make the rule explicit - similar to pci_ids.h - that
    only MSRs which are used in multiple compilation units, should get added
    to it.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Suravee Suthikulpanit <Suravee.Suthikulpanit@amd.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: alex.williamson@redhat.com
    Cc: gleb@kernel.org
    Cc: joro@8bytes.org
    Cc: kvm@vger.kernel.org
    Cc: sherry.hurwitz@amd.com
    Cc: wei@redhat.com
    Link: http://lkml.kernel.org/r/1455612202-14414-5-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b05402ef3b84..984ab75bf621 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -1,7 +1,12 @@
 #ifndef _ASM_X86_MSR_INDEX_H
 #define _ASM_X86_MSR_INDEX_H
 
-/* CPU model specific register (MSR) numbers */
+/*
+ * CPU model specific register (MSR) numbers.
+ *
+ * Do not add new entries to this file unless the definitions are shared
+ * between multiple compilation units.
+ */
 
 /* x86-64 specific MSRs */
 #define MSR_EFER		0xc0000080 /* extended feature register */

commit 670e27d809a9a29943e1d2e45823fa4fc16c29f0
Author: Len Brown <len.brown@intel.com>
Date:   Tue Dec 1 01:36:39 2015 -0500

    x86 msr-index: Simplify syntax for HWP fields
    
    syntax only, no functional change
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 690b4027e17c..5c5e7e53d824 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -230,10 +230,10 @@
 #define HWP_PACKAGE_LEVEL_REQUEST_BIT	(1<<11)
 
 /* IA32_HWP_CAPABILITIES */
-#define HWP_HIGHEST_PERF(x)		(x & 0xff)
-#define HWP_GUARANTEED_PERF(x)		((x & (0xff << 8)) >>8)
-#define HWP_MOSTEFFICIENT_PERF(x)	((x & (0xff << 16)) >>16)
-#define HWP_LOWEST_PERF(x)		((x & (0xff << 24)) >>24)
+#define HWP_HIGHEST_PERF(x)		(((x) >> 0) & 0xff)
+#define HWP_GUARANTEED_PERF(x)		(((x) >> 8) & 0xff)
+#define HWP_MOSTEFFICIENT_PERF(x)	(((x) >> 16) & 0xff)
+#define HWP_LOWEST_PERF(x)		(((x) >> 24) & 0xff)
 
 /* IA32_HWP_REQUEST */
 #define HWP_MIN_PERF(x) 		(x & 0xff)

commit ae8b787543d872cf89a7f9ef8aa302f3ef9bcbd7
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Nov 23 11:12:23 2015 +0100

    x86/cpu/amd, kvm: Satisfy guest kernel reads of IC_CFG MSR
    
    The kernel accesses IC_CFG MSR (0xc0011021) on AMD because it
    checks whether the way access filter is enabled on some F15h
    models, and, if so, disables it.
    
    kvm doesn't handle that MSR access and complains about it, which
    can get really noisy in dmesg when one starts kvm guests all the
    time for testing. And it is useless anyway - guest kernel
    shouldn't be doing such changes anyway so tell it that that
    filter is disabled.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1448273546-2567-4-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 690b4027e17c..b05402ef3b84 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -321,6 +321,7 @@
 #define MSR_F15H_PERF_CTR		0xc0010201
 #define MSR_F15H_NB_PERF_CTL		0xc0010240
 #define MSR_F15H_NB_PERF_CTR		0xc0010241
+#define MSR_F15H_IC_CFG			0xc0011021
 
 /* Fam 10h MSRs */
 #define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058

commit d9f67dbc0f55e67dd18fc18fa05a9d5d2bd52914
Merge: 8005c49d9aea 5369a21e3f26
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Nov 16 22:57:02 2015 +0100

    Merge branch 'pm-tools'
    
    * pm-tools:
      x86: remove unused definition of MSR_NHM_PLATFORM_INFO
      tools/power turbostat: use new name for MSR_PLATFORM_INFO

commit 5369a21e3f26ef9d2bf6ea1b322d6899a4ed08e0
Author: Len Brown <len.brown@intel.com>
Date:   Thu Nov 12 02:42:32 2015 -0500

    x86: remove unused definition of MSR_NHM_PLATFORM_INFO
    
    MSR_NHM_PLATFORM_INFO has been replaced by...
    MSR_PLATFORM_INFO
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b8c14bb7fc8f..705c4082b7f1 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -35,7 +35,7 @@
 #define MSR_IA32_PERFCTR0		0x000000c1
 #define MSR_IA32_PERFCTR1		0x000000c2
 #define MSR_FSB_FREQ			0x000000cd
-#define MSR_NHM_PLATFORM_INFO		0x000000ce
+#define MSR_PLATFORM_INFO		0x000000ce
 
 #define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
@@ -44,7 +44,6 @@
 #define SNB_C1_AUTO_UNDEMOTE		(1UL << 27)
 #define SNB_C3_AUTO_UNDEMOTE		(1UL << 28)
 
-#define MSR_PLATFORM_INFO		0x000000ce
 #define MSR_MTRRcap			0x000000fe
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e

commit 6a35fc2d6c22bafe45117cdc5d8cee332244edbb
Author: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
Date:   Wed Oct 14 16:11:59 2015 -0700

    cpufreq: intel_pstate: get P1 from TAR when available
    
    After Ivybridge, the max non turbo ratio obtained from platform info msr
    is not always guaranteed P1 on client platforms. The max non turbo
    activation ratio (TAR), determines the max for the current level of TDP.
    The ratio in platform info is physical max. The TAR MSR can be locked,
    so updating this value is not possible on all platforms.
    This change gets this ratio from MSR TURBO_ACTIVATION_RATIO if
    available,
    but also do some sanity checking to make sure that this value is
    correct.
    The sanity check involves reading the TDP ratio for the current tdp
    control value when platform has configurable TDP present and matching
    TAC
    with this.
    
    Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
    Acked-by: Kristen Carlson Accardi <kristen@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b8c14bb7fc8f..9f3905697f12 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -206,6 +206,13 @@
 #define MSR_GFX_PERF_LIMIT_REASONS	0x000006B0
 #define MSR_RING_PERF_LIMIT_REASONS	0x000006B1
 
+/* Config TDP MSRs */
+#define MSR_CONFIG_TDP_NOMINAL		0x00000648
+#define MSR_CONFIG_TDP_LEVEL1		0x00000649
+#define MSR_CONFIG_TDP_LEVEL2		0x0000064A
+#define MSR_CONFIG_TDP_CONTROL		0x0000064B
+#define MSR_TURBO_ACTIVATION_RATIO	0x0000064C
+
 /* Hardware P state interface */
 #define MSR_PPERF			0x0000064e
 #define MSR_PERF_LIMIT_REASONS		0x0000064f

commit e3be4266d3488cbbaddf7fcc661f4473db341e46
Merge: 73f479b243fe 2530e39947d8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Sep 27 12:51:39 2015 -0400

    Merge branch 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf fixes from Thomas Gleixner:
     "Another pile of fixes for perf:
    
       - Plug overflows and races in the core code
    
       - Sanitize the flow of the perf syscall so we error out before
         handling the more complex and hard to undo setups
    
       - Improve and fix Broadwell and Skylake hardware support
    
       - Revert a fix which broke what it tried to fix in perf tools
    
       - A couple of smaller fixes in various places of perf tools"
    
    * 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      perf tools: Fix copying of /proc/kcore
      perf intel-pt: Remove no_force_psb from documentation
      perf probe: Use existing routine to look for a kernel module by dso->short_name
      perf/x86: Change test_aperfmperf() and test_intel() to static
      tools lib traceevent: Fix string handling in heterogeneous arch environments
      perf record: Avoid infinite loop at buildid processing with no samples
      perf: Fix races in computing the header sizes
      perf: Fix u16 overflows
      perf: Restructure perf syscall point of no return
      perf/x86/intel: Fix Skylake FRONTEND MSR extrareg mask
      perf/x86/intel/pebs: Add PEBS frontend profiling for Skylake
      perf/x86/intel: Make the CYCLE_ACTIVITY.* constraint on Broadwell more specific
      perf tools: Bool functions shouldn't return -1
      tools build: Add test for presence of __get_cpuid() gcc builtin
      tools build: Add test for presence of numa_num_possible_cpus() in libnuma
      Revert "perf symbols: Fix mismatched declarations for elf_getphdrnum"
      perf stat: Fix per-pkg event reporting bug

commit 3afb1121800128aae9f5722e50097fcf1a9d4d88
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Fri Sep 18 17:33:04 2015 +0200

    KVM: x86: trap AMD MSRs for the TSeg base and mask
    
    These have roughly the same purpose as the SMRR, which we do not need
    to implement in KVM.  However, Linux accesses MSR_K8_TSEG_ADDR at
    boot, which causes problems when running a Xen dom0 under KVM.
    Just return 0, meaning that processor protection of SMRAM is not
    in effect.
    
    Reported-by: M A Young <m.a.young@durham.ac.uk>
    Cc: stable@vger.kernel.org
    Acked-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c1c0a1c14344..b98b471a3b7e 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -331,6 +331,7 @@
 /* C1E active bits in int pending message */
 #define K8_INTP_C1E_ACTIVE_MASK		0x18000000
 #define MSR_K8_TSEG_ADDR		0xc0010112
+#define MSR_K8_TSEG_MASK		0xc0010113
 #define K8_MTRRFIXRANGE_DRAM_ENABLE	0x00040000 /* MtrrFixDramEn bit    */
 #define K8_MTRRFIXRANGE_DRAM_MODIFY	0x00080000 /* MtrrFixDramModEn bit */
 #define K8_MTRR_RDMEM_WRMEM_MASK	0x18181818 /* Mask: RdMem|WrMem    */

commit d0dc8494cd6904f8ad035d9ad97f313948f35d0c
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Sep 9 14:53:59 2015 -0700

    perf/x86/intel/pebs: Add PEBS frontend profiling for Skylake
    
    Skylake has a new FRONTEND_LATENCY PEBS event to accurately profile
    frontend problems (like ITLB or decoding issues).
    
    The new event is configured through a separate MSR, which selects
    a range of sub events.
    
    Define the extra MSR as a extra reg and export support for it
    through sysfs.  To avoid duplicating the existing
    tables use a new function to add new entries to existing tables.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1435707205-6676-4-git-send-email-andi@firstfloor.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c1c0a1c14344..54390bc140dd 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -141,6 +141,8 @@
 #define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
 #define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
 
+#define MSR_PEBS_FRONTEND		0x000003f7
+
 #define MSR_IA32_POWER_CTL		0x000001fc
 
 #define MSR_IA32_MC0_CTL		0x00000400

commit ae982073095a44f004d7ffb9f271077abef9dbcf
Merge: f1a3c0b933e7 e625ccec1fa6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 19:45:46 2015 -0700

    Merge tag 'pm+acpi-4.3-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management and ACPI updates from Rafael Wysocki:
     "From the number of commits perspective, the biggest items are ACPICA
      and cpufreq changes with the latter taking the lead (over 50 commits).
    
      On the cpufreq front, there are many cleanups and minor fixes in the
      core and governors, driver updates etc.  We also have a new cpufreq
      driver for Mediatek MT8173 chips.
    
      ACPICA mostly updates its debug infrastructure and adds a number of
      fixes and cleanups for a good measure.
    
      The Operating Performance Points (OPP) framework is updated with new
      DT bindings and support for them among other things.
    
      We have a few updates of the generic power domains framework and a
      reorganization of the ACPI device enumeration code and bus type
      operations.
    
      And a lot of fixes and cleanups all over.
    
      Included is one branch from the MFD tree as it contains some
      PM-related driver core and ACPI PM changes a few other commits are
      based on.
    
      Specifics:
    
       - ACPICA update to upstream revision 20150818 including method
         tracing extensions to allow more in-depth AML debugging in the
         kernel and a number of assorted fixes and cleanups (Bob Moore, Lv
         Zheng, Markus Elfring).
    
       - ACPI sysfs code updates and a documentation update related to AML
         method tracing (Lv Zheng).
    
       - ACPI EC driver fix related to serialized evaluations of _Qxx
         methods and ACPI tools updates allowing the EC userspace tool to be
         built from the kernel source (Lv Zheng).
    
       - ACPI processor driver updates preparing it for future introduction
         of CPPC support and ACPI PCC mailbox driver updates (Ashwin
         Chaugule).
    
       - ACPI interrupts enumeration fix for a regression related to the
         handling of IRQ attribute conflicts between MADT and the ACPI
         namespace (Jiang Liu).
    
       - Fixes related to ACPI device PM (Mika Westerberg, Srinidhi
         Kasagar).
    
       - ACPI device registration code reorganization to separate the
         sysfs-related code and bus type operations from the rest (Rafael J
         Wysocki).
    
       - Assorted cleanups in the ACPI core (Jarkko Nikula, Mathias Krause,
         Andy Shevchenko, Rafael J Wysocki, Nicolas Iooss).
    
       - ACPI cpufreq driver and ia64 cpufreq driver fixes and cleanups (Pan
         Xinhui, Rafael J Wysocki).
    
       - cpufreq core cleanups on top of the previous changes allowing it to
         preseve its sysfs directories over system suspend/resume (Viresh
         Kumar, Rafael J Wysocki, Sebastian Andrzej Siewior).
    
       - cpufreq fixes and cleanups related to governors (Viresh Kumar).
    
       - cpufreq updates (core and the cpufreq-dt driver) related to the
         turbo/boost mode support (Viresh Kumar, Bartlomiej Zolnierkiewicz).
    
       - New DT bindings for Operating Performance Points (OPP), support for
         them in the OPP framework and in the cpufreq-dt driver plus related
         OPP framework fixes and cleanups (Viresh Kumar).
    
       - cpufreq powernv driver updates (Shilpasri G Bhat).
    
       - New cpufreq driver for Mediatek MT8173 (Pi-Cheng Chen).
    
       - Assorted cpufreq driver (speedstep-lib, sfi, integrator) cleanups
         and fixes (Abhilash Jindal, Andrzej Hajda, Cristian Ardelean).
    
       - intel_pstate driver updates including Skylake-S support, support
         for enabling HW P-states per CPU and an additional vendor bypass
         list entry (Kristen Carlson Accardi, Chen Yu, Ethan Zhao).
    
       - cpuidle core fixes related to the handling of coupled idle states
         (Xunlei Pang).
    
       - intel_idle driver updates including Skylake Client support and
         support for freeze-mode-specific idle states (Len Brown).
    
       - Driver core updates related to power management (Andy Shevchenko,
         Rafael J Wysocki).
    
       - Generic power domains framework fixes and cleanups (Jon Hunter,
         Geert Uytterhoeven, Rajendra Nayak, Ulf Hansson).
    
       - Device PM QoS framework update to allow the latency tolerance
         setting to be exposed to user space via sysfs (Mika Westerberg).
    
       - devfreq support for PPMUv2 in Exynos5433 and a fix for an incorrect
         exynos-ppmu DT binding (Chanwoo Choi, Javier Martinez Canillas).
    
       - System sleep support updates (Alan Stern, Len Brown, SungEun Kim).
    
       - rockchip-io AVS support updates (Heiko Stuebner).
    
       - PM core clocks support fixup (Colin Ian King).
    
       - Power capping RAPL driver update including support for Skylake H/S
         and Broadwell-H (Radivoje Jovanovic, Seiichi Ikarashi).
    
       - Generic device properties framework fixes related to the handling
         of static (driver-provided) property sets (Andy Shevchenko).
    
       - turbostat and cpupower updates (Len Brown, Shilpasri G Bhat,
         Shreyas B Prabhu)"
    
    * tag 'pm+acpi-4.3-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (180 commits)
      cpufreq: speedstep-lib: Use monotonic clock
      cpufreq: powernv: Increase the verbosity of OCC console messages
      cpufreq: sfi: use kmemdup rather than duplicating its implementation
      cpufreq: drop !cpufreq_driver check from cpufreq_parse_governor()
      cpufreq: rename cpufreq_real_policy as cpufreq_user_policy
      cpufreq: remove redundant 'policy' field from user_policy
      cpufreq: remove redundant 'governor' field from user_policy
      cpufreq: update user_policy.* on success
      cpufreq: use memcpy() to copy policy
      cpufreq: remove redundant CPUFREQ_INCOMPATIBLE notifier event
      cpufreq: mediatek: Add MT8173 cpufreq driver
      dt-bindings: mediatek: Add MT8173 CPU DVFS clock bindings
      PM / Domains: Fix typo in description of genpd_dev_pm_detach()
      PM / Domains: Remove unusable governor dummies
      PM / Domains: Make pm_genpd_init() available to modules
      PM / domains: Align column headers and data in pm_genpd_summary output
      powercap / RAPL: disable the 2nd power limit properly
      tools: cpupower: Fix error when running cpupower monitor
      PM / OPP: Drop unlikely before IS_ERR(_OR_NULL)
      PM / OPP: Fix static checker warning (broken 64bit big endian systems)
      ...

commit 82bb70c599d81e6b2535f887b02e1719cc4856ac
Merge: 2e5e8fd1ff9d bd6906ed3d7a
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Aug 24 23:10:02 2015 +0200

    Merge branch 'turbostat' of https://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux into pm-tools
    
    Pull turbostat changes for v4.3 from Len Brown.
    
    * 'turbostat' of https://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux:
      tools/power turbostat: fix typo on DRAM column in Joules-mode
      tools/power turbostat: fix parameter passing for forked command
      tools/power turbostat: dump CONFIG_TDP
      tools/power turbostat: cpu0 is no longer hard-coded, so  update output
      tools/power turbostat: update turbostat(8)

commit b83ff1c8617aac03a1cf807aafa848fe0f0908f2
Author: Andi Kleen <ak@linux.intel.com>
Date:   Sun May 10 12:22:41 2015 -0700

    x86: Add new MSRs and MSR bits used for Intel Skylake PMU support
    
    Add new MSRs (LBR_INFO) and some new MSR bits used by the Intel Skylake
    PMU driver.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: eranian@google.com
    Link: http://lkml.kernel.org/r/1431285767-27027-4-git-send-email-andi@firstfloor.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index c665d34f7285..fcd17c1fc0c6 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -73,6 +73,12 @@
 #define MSR_LBR_CORE_FROM		0x00000040
 #define MSR_LBR_CORE_TO			0x00000060
 
+#define MSR_LBR_INFO_0			0x00000dc0 /* ... 0xddf for _31 */
+#define LBR_INFO_MISPRED		BIT_ULL(63)
+#define LBR_INFO_IN_TX			BIT_ULL(62)
+#define LBR_INFO_ABORT			BIT_ULL(61)
+#define LBR_INFO_CYCLES			0xffff
+
 #define MSR_IA32_PEBS_ENABLE		0x000003f1
 #define MSR_IA32_DS_AREA		0x00000600
 #define MSR_IA32_PERF_CAPABILITIES	0x00000345

commit b1bf72d6691cc33fc7763fc8ec77df42ca1a8702
Author: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Date:   Thu Jul 30 16:15:31 2015 +0300

    perf/x86/intel/pt: Add new timing packet enables
    
    Intel PT chapter in the new Intel Architecture SDM adds several packets
    corresponding enable bits and registers that control packet generation.
    Also, additional bits in the Intel PT CPUID leaf were added to enumerate
    presence and parameters of these new packets and features.
    
    The packets and enables are:
    
      * CYC: cycle accurate mode, provides the number of cycles elapsed since
        previous CYC packet; its presence and available threshold values are
        enumerated via CPUID;
    
      * MTC: mini time counter packets, used for tracking TSC time between
        full TSC packets; its presence and available resolution options are
        enumerated via CPUID;
    
      * PSB packet period is now configurable, available period values are
        enumerated via CPUID.
    
    This patch adds corresponding bit and register definitions, pmu driver
    capabilities based on CPUID enumeration, new attribute format bits for
    the new featurens and extends event configuration validation function
    to take these into account.
    
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: acme@infradead.org
    Cc: adrian.hunter@intel.com
    Cc: hpa@zytor.com
    Link: http://lkml.kernel.org/r/1438262131-12725-1-git-send-email-alexander.shishkin@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 9ebc3d009373..c665d34f7285 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -80,13 +80,21 @@
 
 #define MSR_IA32_RTIT_CTL		0x00000570
 #define RTIT_CTL_TRACEEN		BIT(0)
+#define RTIT_CTL_CYCLEACC		BIT(1)
 #define RTIT_CTL_OS			BIT(2)
 #define RTIT_CTL_USR			BIT(3)
 #define RTIT_CTL_CR3EN			BIT(7)
 #define RTIT_CTL_TOPA			BIT(8)
+#define RTIT_CTL_MTC_EN			BIT(9)
 #define RTIT_CTL_TSC_EN			BIT(10)
 #define RTIT_CTL_DISRETC		BIT(11)
 #define RTIT_CTL_BRANCH_EN		BIT(13)
+#define RTIT_CTL_MTC_RANGE_OFFSET	14
+#define RTIT_CTL_MTC_RANGE		(0x0full << RTIT_CTL_MTC_RANGE_OFFSET)
+#define RTIT_CTL_CYC_THRESH_OFFSET	19
+#define RTIT_CTL_CYC_THRESH		(0x0full << RTIT_CTL_CYC_THRESH_OFFSET)
+#define RTIT_CTL_PSB_FREQ_OFFSET	24
+#define RTIT_CTL_PSB_FREQ      		(0x0full << RTIT_CTL_PSB_FREQ_OFFSET)
 #define MSR_IA32_RTIT_STATUS		0x00000571
 #define RTIT_STATUS_CONTEXTEN		BIT(1)
 #define RTIT_STATUS_TRIGGEREN		BIT(2)

commit b72e7464e4cf80117938e6adb8c22fdc1ca46d42
Author: Borislav Petkov <bp@suse.de>
Date:   Thu Jun 4 18:55:26 2015 +0200

    x86/uapi: Do not export <asm/msr-index.h> as part of the user API headers
    
    This header containing all MSRs and respective bit definitions
    got exported to userspace in conjunction with the big UAPI
    shuffle.
    
    But, it doesn't belong in the UAPI headers because userspace can
    do its own MSR defines and exporting them from the kernel blocks
    us from doing cleanups/renames in that header. Which is
    ridiculous - it is not kernel's job to export such a header and
    keep MSRs list and their names stable.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1433436928-31903-19-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
new file mode 100644
index 000000000000..9ebc3d009373
--- /dev/null
+++ b/arch/x86/include/asm/msr-index.h
@@ -0,0 +1,665 @@
+#ifndef _ASM_X86_MSR_INDEX_H
+#define _ASM_X86_MSR_INDEX_H
+
+/* CPU model specific register (MSR) numbers */
+
+/* x86-64 specific MSRs */
+#define MSR_EFER		0xc0000080 /* extended feature register */
+#define MSR_STAR		0xc0000081 /* legacy mode SYSCALL target */
+#define MSR_LSTAR		0xc0000082 /* long mode SYSCALL target */
+#define MSR_CSTAR		0xc0000083 /* compat mode SYSCALL target */
+#define MSR_SYSCALL_MASK	0xc0000084 /* EFLAGS mask for syscall */
+#define MSR_FS_BASE		0xc0000100 /* 64bit FS base */
+#define MSR_GS_BASE		0xc0000101 /* 64bit GS base */
+#define MSR_KERNEL_GS_BASE	0xc0000102 /* SwapGS GS shadow */
+#define MSR_TSC_AUX		0xc0000103 /* Auxiliary TSC */
+
+/* EFER bits: */
+#define _EFER_SCE		0  /* SYSCALL/SYSRET */
+#define _EFER_LME		8  /* Long mode enable */
+#define _EFER_LMA		10 /* Long mode active (read-only) */
+#define _EFER_NX		11 /* No execute enable */
+#define _EFER_SVME		12 /* Enable virtualization */
+#define _EFER_LMSLE		13 /* Long Mode Segment Limit Enable */
+#define _EFER_FFXSR		14 /* Enable Fast FXSAVE/FXRSTOR */
+
+#define EFER_SCE		(1<<_EFER_SCE)
+#define EFER_LME		(1<<_EFER_LME)
+#define EFER_LMA		(1<<_EFER_LMA)
+#define EFER_NX			(1<<_EFER_NX)
+#define EFER_SVME		(1<<_EFER_SVME)
+#define EFER_LMSLE		(1<<_EFER_LMSLE)
+#define EFER_FFXSR		(1<<_EFER_FFXSR)
+
+/* Intel MSRs. Some also available on other CPUs */
+#define MSR_IA32_PERFCTR0		0x000000c1
+#define MSR_IA32_PERFCTR1		0x000000c2
+#define MSR_FSB_FREQ			0x000000cd
+#define MSR_NHM_PLATFORM_INFO		0x000000ce
+
+#define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
+#define NHM_C3_AUTO_DEMOTE		(1UL << 25)
+#define NHM_C1_AUTO_DEMOTE		(1UL << 26)
+#define ATM_LNC_C6_AUTO_DEMOTE		(1UL << 25)
+#define SNB_C1_AUTO_UNDEMOTE		(1UL << 27)
+#define SNB_C3_AUTO_UNDEMOTE		(1UL << 28)
+
+#define MSR_PLATFORM_INFO		0x000000ce
+#define MSR_MTRRcap			0x000000fe
+#define MSR_IA32_BBL_CR_CTL		0x00000119
+#define MSR_IA32_BBL_CR_CTL3		0x0000011e
+
+#define MSR_IA32_SYSENTER_CS		0x00000174
+#define MSR_IA32_SYSENTER_ESP		0x00000175
+#define MSR_IA32_SYSENTER_EIP		0x00000176
+
+#define MSR_IA32_MCG_CAP		0x00000179
+#define MSR_IA32_MCG_STATUS		0x0000017a
+#define MSR_IA32_MCG_CTL		0x0000017b
+#define MSR_IA32_MCG_EXT_CTL		0x000004d0
+
+#define MSR_OFFCORE_RSP_0		0x000001a6
+#define MSR_OFFCORE_RSP_1		0x000001a7
+#define MSR_NHM_TURBO_RATIO_LIMIT	0x000001ad
+#define MSR_IVT_TURBO_RATIO_LIMIT	0x000001ae
+#define MSR_TURBO_RATIO_LIMIT		0x000001ad
+#define MSR_TURBO_RATIO_LIMIT1		0x000001ae
+#define MSR_TURBO_RATIO_LIMIT2		0x000001af
+
+#define MSR_LBR_SELECT			0x000001c8
+#define MSR_LBR_TOS			0x000001c9
+#define MSR_LBR_NHM_FROM		0x00000680
+#define MSR_LBR_NHM_TO			0x000006c0
+#define MSR_LBR_CORE_FROM		0x00000040
+#define MSR_LBR_CORE_TO			0x00000060
+
+#define MSR_IA32_PEBS_ENABLE		0x000003f1
+#define MSR_IA32_DS_AREA		0x00000600
+#define MSR_IA32_PERF_CAPABILITIES	0x00000345
+#define MSR_PEBS_LD_LAT_THRESHOLD	0x000003f6
+
+#define MSR_IA32_RTIT_CTL		0x00000570
+#define RTIT_CTL_TRACEEN		BIT(0)
+#define RTIT_CTL_OS			BIT(2)
+#define RTIT_CTL_USR			BIT(3)
+#define RTIT_CTL_CR3EN			BIT(7)
+#define RTIT_CTL_TOPA			BIT(8)
+#define RTIT_CTL_TSC_EN			BIT(10)
+#define RTIT_CTL_DISRETC		BIT(11)
+#define RTIT_CTL_BRANCH_EN		BIT(13)
+#define MSR_IA32_RTIT_STATUS		0x00000571
+#define RTIT_STATUS_CONTEXTEN		BIT(1)
+#define RTIT_STATUS_TRIGGEREN		BIT(2)
+#define RTIT_STATUS_ERROR		BIT(4)
+#define RTIT_STATUS_STOPPED		BIT(5)
+#define MSR_IA32_RTIT_CR3_MATCH		0x00000572
+#define MSR_IA32_RTIT_OUTPUT_BASE	0x00000560
+#define MSR_IA32_RTIT_OUTPUT_MASK	0x00000561
+
+#define MSR_MTRRfix64K_00000		0x00000250
+#define MSR_MTRRfix16K_80000		0x00000258
+#define MSR_MTRRfix16K_A0000		0x00000259
+#define MSR_MTRRfix4K_C0000		0x00000268
+#define MSR_MTRRfix4K_C8000		0x00000269
+#define MSR_MTRRfix4K_D0000		0x0000026a
+#define MSR_MTRRfix4K_D8000		0x0000026b
+#define MSR_MTRRfix4K_E0000		0x0000026c
+#define MSR_MTRRfix4K_E8000		0x0000026d
+#define MSR_MTRRfix4K_F0000		0x0000026e
+#define MSR_MTRRfix4K_F8000		0x0000026f
+#define MSR_MTRRdefType			0x000002ff
+
+#define MSR_IA32_CR_PAT			0x00000277
+
+#define MSR_IA32_DEBUGCTLMSR		0x000001d9
+#define MSR_IA32_LASTBRANCHFROMIP	0x000001db
+#define MSR_IA32_LASTBRANCHTOIP		0x000001dc
+#define MSR_IA32_LASTINTFROMIP		0x000001dd
+#define MSR_IA32_LASTINTTOIP		0x000001de
+
+/* DEBUGCTLMSR bits (others vary by model): */
+#define DEBUGCTLMSR_LBR			(1UL <<  0) /* last branch recording */
+#define DEBUGCTLMSR_BTF			(1UL <<  1) /* single-step on branches */
+#define DEBUGCTLMSR_TR			(1UL <<  6)
+#define DEBUGCTLMSR_BTS			(1UL <<  7)
+#define DEBUGCTLMSR_BTINT		(1UL <<  8)
+#define DEBUGCTLMSR_BTS_OFF_OS		(1UL <<  9)
+#define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
+#define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
+
+#define MSR_IA32_POWER_CTL		0x000001fc
+
+#define MSR_IA32_MC0_CTL		0x00000400
+#define MSR_IA32_MC0_STATUS		0x00000401
+#define MSR_IA32_MC0_ADDR		0x00000402
+#define MSR_IA32_MC0_MISC		0x00000403
+
+/* C-state Residency Counters */
+#define MSR_PKG_C3_RESIDENCY		0x000003f8
+#define MSR_PKG_C6_RESIDENCY		0x000003f9
+#define MSR_PKG_C7_RESIDENCY		0x000003fa
+#define MSR_CORE_C3_RESIDENCY		0x000003fc
+#define MSR_CORE_C6_RESIDENCY		0x000003fd
+#define MSR_CORE_C7_RESIDENCY		0x000003fe
+#define MSR_KNL_CORE_C6_RESIDENCY	0x000003ff
+#define MSR_PKG_C2_RESIDENCY		0x0000060d
+#define MSR_PKG_C8_RESIDENCY		0x00000630
+#define MSR_PKG_C9_RESIDENCY		0x00000631
+#define MSR_PKG_C10_RESIDENCY		0x00000632
+
+/* Run Time Average Power Limiting (RAPL) Interface */
+
+#define MSR_RAPL_POWER_UNIT		0x00000606
+
+#define MSR_PKG_POWER_LIMIT		0x00000610
+#define MSR_PKG_ENERGY_STATUS		0x00000611
+#define MSR_PKG_PERF_STATUS		0x00000613
+#define MSR_PKG_POWER_INFO		0x00000614
+
+#define MSR_DRAM_POWER_LIMIT		0x00000618
+#define MSR_DRAM_ENERGY_STATUS		0x00000619
+#define MSR_DRAM_PERF_STATUS		0x0000061b
+#define MSR_DRAM_POWER_INFO		0x0000061c
+
+#define MSR_PP0_POWER_LIMIT		0x00000638
+#define MSR_PP0_ENERGY_STATUS		0x00000639
+#define MSR_PP0_POLICY			0x0000063a
+#define MSR_PP0_PERF_STATUS		0x0000063b
+
+#define MSR_PP1_POWER_LIMIT		0x00000640
+#define MSR_PP1_ENERGY_STATUS		0x00000641
+#define MSR_PP1_POLICY			0x00000642
+
+#define MSR_PKG_WEIGHTED_CORE_C0_RES	0x00000658
+#define MSR_PKG_ANY_CORE_C0_RES		0x00000659
+#define MSR_PKG_ANY_GFXE_C0_RES		0x0000065A
+#define MSR_PKG_BOTH_CORE_GFXE_C0_RES	0x0000065B
+
+#define MSR_CORE_C1_RES			0x00000660
+
+#define MSR_CC6_DEMOTION_POLICY_CONFIG	0x00000668
+#define MSR_MC6_DEMOTION_POLICY_CONFIG	0x00000669
+
+#define MSR_CORE_PERF_LIMIT_REASONS	0x00000690
+#define MSR_GFX_PERF_LIMIT_REASONS	0x000006B0
+#define MSR_RING_PERF_LIMIT_REASONS	0x000006B1
+
+/* Hardware P state interface */
+#define MSR_PPERF			0x0000064e
+#define MSR_PERF_LIMIT_REASONS		0x0000064f
+#define MSR_PM_ENABLE			0x00000770
+#define MSR_HWP_CAPABILITIES		0x00000771
+#define MSR_HWP_REQUEST_PKG		0x00000772
+#define MSR_HWP_INTERRUPT		0x00000773
+#define MSR_HWP_REQUEST 		0x00000774
+#define MSR_HWP_STATUS			0x00000777
+
+/* CPUID.6.EAX */
+#define HWP_BASE_BIT			(1<<7)
+#define HWP_NOTIFICATIONS_BIT		(1<<8)
+#define HWP_ACTIVITY_WINDOW_BIT		(1<<9)
+#define HWP_ENERGY_PERF_PREFERENCE_BIT	(1<<10)
+#define HWP_PACKAGE_LEVEL_REQUEST_BIT	(1<<11)
+
+/* IA32_HWP_CAPABILITIES */
+#define HWP_HIGHEST_PERF(x)		(x & 0xff)
+#define HWP_GUARANTEED_PERF(x)		((x & (0xff << 8)) >>8)
+#define HWP_MOSTEFFICIENT_PERF(x)	((x & (0xff << 16)) >>16)
+#define HWP_LOWEST_PERF(x)		((x & (0xff << 24)) >>24)
+
+/* IA32_HWP_REQUEST */
+#define HWP_MIN_PERF(x) 		(x & 0xff)
+#define HWP_MAX_PERF(x) 		((x & 0xff) << 8)
+#define HWP_DESIRED_PERF(x)		((x & 0xff) << 16)
+#define HWP_ENERGY_PERF_PREFERENCE(x)	((x & 0xff) << 24)
+#define HWP_ACTIVITY_WINDOW(x)		((x & 0xff3) << 32)
+#define HWP_PACKAGE_CONTROL(x)		((x & 0x1) << 42)
+
+/* IA32_HWP_STATUS */
+#define HWP_GUARANTEED_CHANGE(x)	(x & 0x1)
+#define HWP_EXCURSION_TO_MINIMUM(x)	(x & 0x4)
+
+/* IA32_HWP_INTERRUPT */
+#define HWP_CHANGE_TO_GUARANTEED_INT(x)	(x & 0x1)
+#define HWP_EXCURSION_TO_MINIMUM_INT(x)	(x & 0x2)
+
+#define MSR_AMD64_MC0_MASK		0xc0010044
+
+#define MSR_IA32_MCx_CTL(x)		(MSR_IA32_MC0_CTL + 4*(x))
+#define MSR_IA32_MCx_STATUS(x)		(MSR_IA32_MC0_STATUS + 4*(x))
+#define MSR_IA32_MCx_ADDR(x)		(MSR_IA32_MC0_ADDR + 4*(x))
+#define MSR_IA32_MCx_MISC(x)		(MSR_IA32_MC0_MISC + 4*(x))
+
+#define MSR_AMD64_MCx_MASK(x)		(MSR_AMD64_MC0_MASK + (x))
+
+/* These are consecutive and not in the normal 4er MCE bank block */
+#define MSR_IA32_MC0_CTL2		0x00000280
+#define MSR_IA32_MCx_CTL2(x)		(MSR_IA32_MC0_CTL2 + (x))
+
+#define MSR_P6_PERFCTR0			0x000000c1
+#define MSR_P6_PERFCTR1			0x000000c2
+#define MSR_P6_EVNTSEL0			0x00000186
+#define MSR_P6_EVNTSEL1			0x00000187
+
+#define MSR_KNC_PERFCTR0               0x00000020
+#define MSR_KNC_PERFCTR1               0x00000021
+#define MSR_KNC_EVNTSEL0               0x00000028
+#define MSR_KNC_EVNTSEL1               0x00000029
+
+/* Alternative perfctr range with full access. */
+#define MSR_IA32_PMC0			0x000004c1
+
+/* AMD64 MSRs. Not complete. See the architecture manual for a more
+   complete list. */
+
+#define MSR_AMD64_PATCH_LEVEL		0x0000008b
+#define MSR_AMD64_TSC_RATIO		0xc0000104
+#define MSR_AMD64_NB_CFG		0xc001001f
+#define MSR_AMD64_PATCH_LOADER		0xc0010020
+#define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
+#define MSR_AMD64_OSVW_STATUS		0xc0010141
+#define MSR_AMD64_LS_CFG		0xc0011020
+#define MSR_AMD64_DC_CFG		0xc0011022
+#define MSR_AMD64_BU_CFG2		0xc001102a
+#define MSR_AMD64_IBSFETCHCTL		0xc0011030
+#define MSR_AMD64_IBSFETCHLINAD		0xc0011031
+#define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032
+#define MSR_AMD64_IBSFETCH_REG_COUNT	3
+#define MSR_AMD64_IBSFETCH_REG_MASK	((1UL<<MSR_AMD64_IBSFETCH_REG_COUNT)-1)
+#define MSR_AMD64_IBSOPCTL		0xc0011033
+#define MSR_AMD64_IBSOPRIP		0xc0011034
+#define MSR_AMD64_IBSOPDATA		0xc0011035
+#define MSR_AMD64_IBSOPDATA2		0xc0011036
+#define MSR_AMD64_IBSOPDATA3		0xc0011037
+#define MSR_AMD64_IBSDCLINAD		0xc0011038
+#define MSR_AMD64_IBSDCPHYSAD		0xc0011039
+#define MSR_AMD64_IBSOP_REG_COUNT	7
+#define MSR_AMD64_IBSOP_REG_MASK	((1UL<<MSR_AMD64_IBSOP_REG_COUNT)-1)
+#define MSR_AMD64_IBSCTL		0xc001103a
+#define MSR_AMD64_IBSBRTARGET		0xc001103b
+#define MSR_AMD64_IBSOPDATA4		0xc001103d
+#define MSR_AMD64_IBS_REG_COUNT_MAX	8 /* includes MSR_AMD64_IBSBRTARGET */
+
+/* Fam 16h MSRs */
+#define MSR_F16H_L2I_PERF_CTL		0xc0010230
+#define MSR_F16H_L2I_PERF_CTR		0xc0010231
+#define MSR_F16H_DR1_ADDR_MASK		0xc0011019
+#define MSR_F16H_DR2_ADDR_MASK		0xc001101a
+#define MSR_F16H_DR3_ADDR_MASK		0xc001101b
+#define MSR_F16H_DR0_ADDR_MASK		0xc0011027
+
+/* Fam 15h MSRs */
+#define MSR_F15H_PERF_CTL		0xc0010200
+#define MSR_F15H_PERF_CTR		0xc0010201
+#define MSR_F15H_NB_PERF_CTL		0xc0010240
+#define MSR_F15H_NB_PERF_CTR		0xc0010241
+
+/* Fam 10h MSRs */
+#define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058
+#define FAM10H_MMIO_CONF_ENABLE		(1<<0)
+#define FAM10H_MMIO_CONF_BUSRANGE_MASK	0xf
+#define FAM10H_MMIO_CONF_BUSRANGE_SHIFT 2
+#define FAM10H_MMIO_CONF_BASE_MASK	0xfffffffULL
+#define FAM10H_MMIO_CONF_BASE_SHIFT	20
+#define MSR_FAM10H_NODE_ID		0xc001100c
+
+/* K8 MSRs */
+#define MSR_K8_TOP_MEM1			0xc001001a
+#define MSR_K8_TOP_MEM2			0xc001001d
+#define MSR_K8_SYSCFG			0xc0010010
+#define MSR_K8_INT_PENDING_MSG		0xc0010055
+/* C1E active bits in int pending message */
+#define K8_INTP_C1E_ACTIVE_MASK		0x18000000
+#define MSR_K8_TSEG_ADDR		0xc0010112
+#define K8_MTRRFIXRANGE_DRAM_ENABLE	0x00040000 /* MtrrFixDramEn bit    */
+#define K8_MTRRFIXRANGE_DRAM_MODIFY	0x00080000 /* MtrrFixDramModEn bit */
+#define K8_MTRR_RDMEM_WRMEM_MASK	0x18181818 /* Mask: RdMem|WrMem    */
+
+/* K7 MSRs */
+#define MSR_K7_EVNTSEL0			0xc0010000
+#define MSR_K7_PERFCTR0			0xc0010004
+#define MSR_K7_EVNTSEL1			0xc0010001
+#define MSR_K7_PERFCTR1			0xc0010005
+#define MSR_K7_EVNTSEL2			0xc0010002
+#define MSR_K7_PERFCTR2			0xc0010006
+#define MSR_K7_EVNTSEL3			0xc0010003
+#define MSR_K7_PERFCTR3			0xc0010007
+#define MSR_K7_CLK_CTL			0xc001001b
+#define MSR_K7_HWCR			0xc0010015
+#define MSR_K7_FID_VID_CTL		0xc0010041
+#define MSR_K7_FID_VID_STATUS		0xc0010042
+
+/* K6 MSRs */
+#define MSR_K6_WHCR			0xc0000082
+#define MSR_K6_UWCCR			0xc0000085
+#define MSR_K6_EPMR			0xc0000086
+#define MSR_K6_PSOR			0xc0000087
+#define MSR_K6_PFIR			0xc0000088
+
+/* Centaur-Hauls/IDT defined MSRs. */
+#define MSR_IDT_FCR1			0x00000107
+#define MSR_IDT_FCR2			0x00000108
+#define MSR_IDT_FCR3			0x00000109
+#define MSR_IDT_FCR4			0x0000010a
+
+#define MSR_IDT_MCR0			0x00000110
+#define MSR_IDT_MCR1			0x00000111
+#define MSR_IDT_MCR2			0x00000112
+#define MSR_IDT_MCR3			0x00000113
+#define MSR_IDT_MCR4			0x00000114
+#define MSR_IDT_MCR5			0x00000115
+#define MSR_IDT_MCR6			0x00000116
+#define MSR_IDT_MCR7			0x00000117
+#define MSR_IDT_MCR_CTRL		0x00000120
+
+/* VIA Cyrix defined MSRs*/
+#define MSR_VIA_FCR			0x00001107
+#define MSR_VIA_LONGHAUL		0x0000110a
+#define MSR_VIA_RNG			0x0000110b
+#define MSR_VIA_BCR2			0x00001147
+
+/* Transmeta defined MSRs */
+#define MSR_TMTA_LONGRUN_CTRL		0x80868010
+#define MSR_TMTA_LONGRUN_FLAGS		0x80868011
+#define MSR_TMTA_LRTI_READOUT		0x80868018
+#define MSR_TMTA_LRTI_VOLT_MHZ		0x8086801a
+
+/* Intel defined MSRs. */
+#define MSR_IA32_P5_MC_ADDR		0x00000000
+#define MSR_IA32_P5_MC_TYPE		0x00000001
+#define MSR_IA32_TSC			0x00000010
+#define MSR_IA32_PLATFORM_ID		0x00000017
+#define MSR_IA32_EBL_CR_POWERON		0x0000002a
+#define MSR_EBC_FREQUENCY_ID		0x0000002c
+#define MSR_SMI_COUNT			0x00000034
+#define MSR_IA32_FEATURE_CONTROL        0x0000003a
+#define MSR_IA32_TSC_ADJUST             0x0000003b
+#define MSR_IA32_BNDCFGS		0x00000d90
+
+#define MSR_IA32_XSS			0x00000da0
+
+#define FEATURE_CONTROL_LOCKED				(1<<0)
+#define FEATURE_CONTROL_VMXON_ENABLED_INSIDE_SMX	(1<<1)
+#define FEATURE_CONTROL_VMXON_ENABLED_OUTSIDE_SMX	(1<<2)
+#define FEATURE_CONTROL_LMCE				(1<<20)
+
+#define MSR_IA32_APICBASE		0x0000001b
+#define MSR_IA32_APICBASE_BSP		(1<<8)
+#define MSR_IA32_APICBASE_ENABLE	(1<<11)
+#define MSR_IA32_APICBASE_BASE		(0xfffff<<12)
+
+#define MSR_IA32_TSCDEADLINE		0x000006e0
+
+#define MSR_IA32_UCODE_WRITE		0x00000079
+#define MSR_IA32_UCODE_REV		0x0000008b
+
+#define MSR_IA32_SMM_MONITOR_CTL	0x0000009b
+#define MSR_IA32_SMBASE			0x0000009e
+
+#define MSR_IA32_PERF_STATUS		0x00000198
+#define MSR_IA32_PERF_CTL		0x00000199
+#define INTEL_PERF_CTL_MASK		0xffff
+#define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
+#define MSR_AMD_PERF_STATUS		0xc0010063
+#define MSR_AMD_PERF_CTL		0xc0010062
+
+#define MSR_IA32_MPERF			0x000000e7
+#define MSR_IA32_APERF			0x000000e8
+
+#define MSR_IA32_THERM_CONTROL		0x0000019a
+#define MSR_IA32_THERM_INTERRUPT	0x0000019b
+
+#define THERM_INT_HIGH_ENABLE		(1 << 0)
+#define THERM_INT_LOW_ENABLE		(1 << 1)
+#define THERM_INT_PLN_ENABLE		(1 << 24)
+
+#define MSR_IA32_THERM_STATUS		0x0000019c
+
+#define THERM_STATUS_PROCHOT		(1 << 0)
+#define THERM_STATUS_POWER_LIMIT	(1 << 10)
+
+#define MSR_THERM2_CTL			0x0000019d
+
+#define MSR_THERM2_CTL_TM_SELECT	(1ULL << 16)
+
+#define MSR_IA32_MISC_ENABLE		0x000001a0
+
+#define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
+
+#define MSR_MISC_PWR_MGMT		0x000001aa
+
+#define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
+#define ENERGY_PERF_BIAS_PERFORMANCE	0
+#define ENERGY_PERF_BIAS_NORMAL		6
+#define ENERGY_PERF_BIAS_POWERSAVE	15
+
+#define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
+
+#define PACKAGE_THERM_STATUS_PROCHOT		(1 << 0)
+#define PACKAGE_THERM_STATUS_POWER_LIMIT	(1 << 10)
+
+#define MSR_IA32_PACKAGE_THERM_INTERRUPT	0x000001b2
+
+#define PACKAGE_THERM_INT_HIGH_ENABLE		(1 << 0)
+#define PACKAGE_THERM_INT_LOW_ENABLE		(1 << 1)
+#define PACKAGE_THERM_INT_PLN_ENABLE		(1 << 24)
+
+/* Thermal Thresholds Support */
+#define THERM_INT_THRESHOLD0_ENABLE    (1 << 15)
+#define THERM_SHIFT_THRESHOLD0        8
+#define THERM_MASK_THRESHOLD0          (0x7f << THERM_SHIFT_THRESHOLD0)
+#define THERM_INT_THRESHOLD1_ENABLE    (1 << 23)
+#define THERM_SHIFT_THRESHOLD1        16
+#define THERM_MASK_THRESHOLD1          (0x7f << THERM_SHIFT_THRESHOLD1)
+#define THERM_STATUS_THRESHOLD0        (1 << 6)
+#define THERM_LOG_THRESHOLD0           (1 << 7)
+#define THERM_STATUS_THRESHOLD1        (1 << 8)
+#define THERM_LOG_THRESHOLD1           (1 << 9)
+
+/* MISC_ENABLE bits: architectural */
+#define MSR_IA32_MISC_ENABLE_FAST_STRING_BIT		0
+#define MSR_IA32_MISC_ENABLE_FAST_STRING		(1ULL << MSR_IA32_MISC_ENABLE_FAST_STRING_BIT)
+#define MSR_IA32_MISC_ENABLE_TCC_BIT			1
+#define MSR_IA32_MISC_ENABLE_TCC			(1ULL << MSR_IA32_MISC_ENABLE_TCC_BIT)
+#define MSR_IA32_MISC_ENABLE_EMON_BIT			7
+#define MSR_IA32_MISC_ENABLE_EMON			(1ULL << MSR_IA32_MISC_ENABLE_EMON_BIT)
+#define MSR_IA32_MISC_ENABLE_BTS_UNAVAIL_BIT		11
+#define MSR_IA32_MISC_ENABLE_BTS_UNAVAIL		(1ULL << MSR_IA32_MISC_ENABLE_BTS_UNAVAIL_BIT)
+#define MSR_IA32_MISC_ENABLE_PEBS_UNAVAIL_BIT		12
+#define MSR_IA32_MISC_ENABLE_PEBS_UNAVAIL		(1ULL << MSR_IA32_MISC_ENABLE_PEBS_UNAVAIL_BIT)
+#define MSR_IA32_MISC_ENABLE_ENHANCED_SPEEDSTEP_BIT	16
+#define MSR_IA32_MISC_ENABLE_ENHANCED_SPEEDSTEP		(1ULL << MSR_IA32_MISC_ENABLE_ENHANCED_SPEEDSTEP_BIT)
+#define MSR_IA32_MISC_ENABLE_MWAIT_BIT			18
+#define MSR_IA32_MISC_ENABLE_MWAIT			(1ULL << MSR_IA32_MISC_ENABLE_MWAIT_BIT)
+#define MSR_IA32_MISC_ENABLE_LIMIT_CPUID_BIT		22
+#define MSR_IA32_MISC_ENABLE_LIMIT_CPUID		(1ULL << MSR_IA32_MISC_ENABLE_LIMIT_CPUID_BIT)
+#define MSR_IA32_MISC_ENABLE_XTPR_DISABLE_BIT		23
+#define MSR_IA32_MISC_ENABLE_XTPR_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_XTPR_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_XD_DISABLE_BIT		34
+#define MSR_IA32_MISC_ENABLE_XD_DISABLE			(1ULL << MSR_IA32_MISC_ENABLE_XD_DISABLE_BIT)
+
+/* MISC_ENABLE bits: model-specific, meaning may vary from core to core */
+#define MSR_IA32_MISC_ENABLE_X87_COMPAT_BIT		2
+#define MSR_IA32_MISC_ENABLE_X87_COMPAT			(1ULL << MSR_IA32_MISC_ENABLE_X87_COMPAT_BIT)
+#define MSR_IA32_MISC_ENABLE_TM1_BIT			3
+#define MSR_IA32_MISC_ENABLE_TM1			(1ULL << MSR_IA32_MISC_ENABLE_TM1_BIT)
+#define MSR_IA32_MISC_ENABLE_SPLIT_LOCK_DISABLE_BIT	4
+#define MSR_IA32_MISC_ENABLE_SPLIT_LOCK_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_SPLIT_LOCK_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_L3CACHE_DISABLE_BIT	6
+#define MSR_IA32_MISC_ENABLE_L3CACHE_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_L3CACHE_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_SUPPRESS_LOCK_BIT		8
+#define MSR_IA32_MISC_ENABLE_SUPPRESS_LOCK		(1ULL << MSR_IA32_MISC_ENABLE_SUPPRESS_LOCK_BIT)
+#define MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE_BIT	9
+#define MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_FERR_BIT			10
+#define MSR_IA32_MISC_ENABLE_FERR			(1ULL << MSR_IA32_MISC_ENABLE_FERR_BIT)
+#define MSR_IA32_MISC_ENABLE_FERR_MULTIPLEX_BIT		10
+#define MSR_IA32_MISC_ENABLE_FERR_MULTIPLEX		(1ULL << MSR_IA32_MISC_ENABLE_FERR_MULTIPLEX_BIT)
+#define MSR_IA32_MISC_ENABLE_TM2_BIT			13
+#define MSR_IA32_MISC_ENABLE_TM2			(1ULL << MSR_IA32_MISC_ENABLE_TM2_BIT)
+#define MSR_IA32_MISC_ENABLE_ADJ_PREF_DISABLE_BIT	19
+#define MSR_IA32_MISC_ENABLE_ADJ_PREF_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_ADJ_PREF_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_SPEEDSTEP_LOCK_BIT		20
+#define MSR_IA32_MISC_ENABLE_SPEEDSTEP_LOCK		(1ULL << MSR_IA32_MISC_ENABLE_SPEEDSTEP_LOCK_BIT)
+#define MSR_IA32_MISC_ENABLE_L1D_CONTEXT_BIT		24
+#define MSR_IA32_MISC_ENABLE_L1D_CONTEXT		(1ULL << MSR_IA32_MISC_ENABLE_L1D_CONTEXT_BIT)
+#define MSR_IA32_MISC_ENABLE_DCU_PREF_DISABLE_BIT	37
+#define MSR_IA32_MISC_ENABLE_DCU_PREF_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_DCU_PREF_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_TURBO_DISABLE_BIT		38
+#define MSR_IA32_MISC_ENABLE_TURBO_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_TURBO_DISABLE_BIT)
+#define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT	39
+#define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE		(1ULL << MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE_BIT)
+
+#define MSR_IA32_TSC_DEADLINE		0x000006E0
+
+/* P4/Xeon+ specific */
+#define MSR_IA32_MCG_EAX		0x00000180
+#define MSR_IA32_MCG_EBX		0x00000181
+#define MSR_IA32_MCG_ECX		0x00000182
+#define MSR_IA32_MCG_EDX		0x00000183
+#define MSR_IA32_MCG_ESI		0x00000184
+#define MSR_IA32_MCG_EDI		0x00000185
+#define MSR_IA32_MCG_EBP		0x00000186
+#define MSR_IA32_MCG_ESP		0x00000187
+#define MSR_IA32_MCG_EFLAGS		0x00000188
+#define MSR_IA32_MCG_EIP		0x00000189
+#define MSR_IA32_MCG_RESERVED		0x0000018a
+
+/* Pentium IV performance counter MSRs */
+#define MSR_P4_BPU_PERFCTR0		0x00000300
+#define MSR_P4_BPU_PERFCTR1		0x00000301
+#define MSR_P4_BPU_PERFCTR2		0x00000302
+#define MSR_P4_BPU_PERFCTR3		0x00000303
+#define MSR_P4_MS_PERFCTR0		0x00000304
+#define MSR_P4_MS_PERFCTR1		0x00000305
+#define MSR_P4_MS_PERFCTR2		0x00000306
+#define MSR_P4_MS_PERFCTR3		0x00000307
+#define MSR_P4_FLAME_PERFCTR0		0x00000308
+#define MSR_P4_FLAME_PERFCTR1		0x00000309
+#define MSR_P4_FLAME_PERFCTR2		0x0000030a
+#define MSR_P4_FLAME_PERFCTR3		0x0000030b
+#define MSR_P4_IQ_PERFCTR0		0x0000030c
+#define MSR_P4_IQ_PERFCTR1		0x0000030d
+#define MSR_P4_IQ_PERFCTR2		0x0000030e
+#define MSR_P4_IQ_PERFCTR3		0x0000030f
+#define MSR_P4_IQ_PERFCTR4		0x00000310
+#define MSR_P4_IQ_PERFCTR5		0x00000311
+#define MSR_P4_BPU_CCCR0		0x00000360
+#define MSR_P4_BPU_CCCR1		0x00000361
+#define MSR_P4_BPU_CCCR2		0x00000362
+#define MSR_P4_BPU_CCCR3		0x00000363
+#define MSR_P4_MS_CCCR0			0x00000364
+#define MSR_P4_MS_CCCR1			0x00000365
+#define MSR_P4_MS_CCCR2			0x00000366
+#define MSR_P4_MS_CCCR3			0x00000367
+#define MSR_P4_FLAME_CCCR0		0x00000368
+#define MSR_P4_FLAME_CCCR1		0x00000369
+#define MSR_P4_FLAME_CCCR2		0x0000036a
+#define MSR_P4_FLAME_CCCR3		0x0000036b
+#define MSR_P4_IQ_CCCR0			0x0000036c
+#define MSR_P4_IQ_CCCR1			0x0000036d
+#define MSR_P4_IQ_CCCR2			0x0000036e
+#define MSR_P4_IQ_CCCR3			0x0000036f
+#define MSR_P4_IQ_CCCR4			0x00000370
+#define MSR_P4_IQ_CCCR5			0x00000371
+#define MSR_P4_ALF_ESCR0		0x000003ca
+#define MSR_P4_ALF_ESCR1		0x000003cb
+#define MSR_P4_BPU_ESCR0		0x000003b2
+#define MSR_P4_BPU_ESCR1		0x000003b3
+#define MSR_P4_BSU_ESCR0		0x000003a0
+#define MSR_P4_BSU_ESCR1		0x000003a1
+#define MSR_P4_CRU_ESCR0		0x000003b8
+#define MSR_P4_CRU_ESCR1		0x000003b9
+#define MSR_P4_CRU_ESCR2		0x000003cc
+#define MSR_P4_CRU_ESCR3		0x000003cd
+#define MSR_P4_CRU_ESCR4		0x000003e0
+#define MSR_P4_CRU_ESCR5		0x000003e1
+#define MSR_P4_DAC_ESCR0		0x000003a8
+#define MSR_P4_DAC_ESCR1		0x000003a9
+#define MSR_P4_FIRM_ESCR0		0x000003a4
+#define MSR_P4_FIRM_ESCR1		0x000003a5
+#define MSR_P4_FLAME_ESCR0		0x000003a6
+#define MSR_P4_FLAME_ESCR1		0x000003a7
+#define MSR_P4_FSB_ESCR0		0x000003a2
+#define MSR_P4_FSB_ESCR1		0x000003a3
+#define MSR_P4_IQ_ESCR0			0x000003ba
+#define MSR_P4_IQ_ESCR1			0x000003bb
+#define MSR_P4_IS_ESCR0			0x000003b4
+#define MSR_P4_IS_ESCR1			0x000003b5
+#define MSR_P4_ITLB_ESCR0		0x000003b6
+#define MSR_P4_ITLB_ESCR1		0x000003b7
+#define MSR_P4_IX_ESCR0			0x000003c8
+#define MSR_P4_IX_ESCR1			0x000003c9
+#define MSR_P4_MOB_ESCR0		0x000003aa
+#define MSR_P4_MOB_ESCR1		0x000003ab
+#define MSR_P4_MS_ESCR0			0x000003c0
+#define MSR_P4_MS_ESCR1			0x000003c1
+#define MSR_P4_PMH_ESCR0		0x000003ac
+#define MSR_P4_PMH_ESCR1		0x000003ad
+#define MSR_P4_RAT_ESCR0		0x000003bc
+#define MSR_P4_RAT_ESCR1		0x000003bd
+#define MSR_P4_SAAT_ESCR0		0x000003ae
+#define MSR_P4_SAAT_ESCR1		0x000003af
+#define MSR_P4_SSU_ESCR0		0x000003be
+#define MSR_P4_SSU_ESCR1		0x000003bf /* guess: not in manual */
+
+#define MSR_P4_TBPU_ESCR0		0x000003c2
+#define MSR_P4_TBPU_ESCR1		0x000003c3
+#define MSR_P4_TC_ESCR0			0x000003c4
+#define MSR_P4_TC_ESCR1			0x000003c5
+#define MSR_P4_U2L_ESCR0		0x000003b0
+#define MSR_P4_U2L_ESCR1		0x000003b1
+
+#define MSR_P4_PEBS_MATRIX_VERT		0x000003f2
+
+/* Intel Core-based CPU performance counters */
+#define MSR_CORE_PERF_FIXED_CTR0	0x00000309
+#define MSR_CORE_PERF_FIXED_CTR1	0x0000030a
+#define MSR_CORE_PERF_FIXED_CTR2	0x0000030b
+#define MSR_CORE_PERF_FIXED_CTR_CTRL	0x0000038d
+#define MSR_CORE_PERF_GLOBAL_STATUS	0x0000038e
+#define MSR_CORE_PERF_GLOBAL_CTRL	0x0000038f
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL	0x00000390
+
+/* Geode defined MSRs */
+#define MSR_GEODE_BUSCONT_CONF0		0x00001900
+
+/* Intel VT MSRs */
+#define MSR_IA32_VMX_BASIC              0x00000480
+#define MSR_IA32_VMX_PINBASED_CTLS      0x00000481
+#define MSR_IA32_VMX_PROCBASED_CTLS     0x00000482
+#define MSR_IA32_VMX_EXIT_CTLS          0x00000483
+#define MSR_IA32_VMX_ENTRY_CTLS         0x00000484
+#define MSR_IA32_VMX_MISC               0x00000485
+#define MSR_IA32_VMX_CR0_FIXED0         0x00000486
+#define MSR_IA32_VMX_CR0_FIXED1         0x00000487
+#define MSR_IA32_VMX_CR4_FIXED0         0x00000488
+#define MSR_IA32_VMX_CR4_FIXED1         0x00000489
+#define MSR_IA32_VMX_VMCS_ENUM          0x0000048a
+#define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
+#define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
+#define MSR_IA32_VMX_TRUE_PINBASED_CTLS  0x0000048d
+#define MSR_IA32_VMX_TRUE_PROCBASED_CTLS 0x0000048e
+#define MSR_IA32_VMX_TRUE_EXIT_CTLS      0x0000048f
+#define MSR_IA32_VMX_TRUE_ENTRY_CTLS     0x00000490
+#define MSR_IA32_VMX_VMFUNC             0x00000491
+
+/* VMX_BASIC bits and bitmasks */
+#define VMX_BASIC_VMCS_SIZE_SHIFT	32
+#define VMX_BASIC_TRUE_CTLS		(1ULL << 55)
+#define VMX_BASIC_64		0x0001000000000000LLU
+#define VMX_BASIC_MEM_TYPE_SHIFT	50
+#define VMX_BASIC_MEM_TYPE_MASK	0x003c000000000000LLU
+#define VMX_BASIC_MEM_TYPE_WB	6LLU
+#define VMX_BASIC_INOUT		0x0040000000000000LLU
+
+/* MSR_IA32_VMX_MISC bits */
+#define MSR_IA32_VMX_MISC_VMWRITE_SHADOW_RO_FIELDS (1ULL << 29)
+#define MSR_IA32_VMX_MISC_PREEMPTION_TIMER_SCALE   0x1F
+/* AMD-V MSRs */
+
+#define MSR_VM_CR                       0xc0010114
+#define MSR_VM_IGNNE                    0xc0010115
+#define MSR_VM_HSAVE_PA                 0xc0010117
+
+#endif /* _ASM_X86_MSR_INDEX_H */

commit af170c5061dd78512c469e6e2d211980cdb2c193
Author: David Howells <dhowells@redhat.com>
Date:   Fri Dec 14 22:37:13 2012 +0000

    UAPI: (Scripted) Disintegrate arch/x86/include/asm
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
deleted file mode 100644
index 6e930b218724..000000000000
--- a/arch/x86/include/asm/msr-index.h
+++ /dev/null
@@ -1,488 +0,0 @@
-#ifndef _ASM_X86_MSR_INDEX_H
-#define _ASM_X86_MSR_INDEX_H
-
-/* CPU model specific register (MSR) numbers */
-
-/* x86-64 specific MSRs */
-#define MSR_EFER		0xc0000080 /* extended feature register */
-#define MSR_STAR		0xc0000081 /* legacy mode SYSCALL target */
-#define MSR_LSTAR		0xc0000082 /* long mode SYSCALL target */
-#define MSR_CSTAR		0xc0000083 /* compat mode SYSCALL target */
-#define MSR_SYSCALL_MASK	0xc0000084 /* EFLAGS mask for syscall */
-#define MSR_FS_BASE		0xc0000100 /* 64bit FS base */
-#define MSR_GS_BASE		0xc0000101 /* 64bit GS base */
-#define MSR_KERNEL_GS_BASE	0xc0000102 /* SwapGS GS shadow */
-#define MSR_TSC_AUX		0xc0000103 /* Auxiliary TSC */
-
-/* EFER bits: */
-#define _EFER_SCE		0  /* SYSCALL/SYSRET */
-#define _EFER_LME		8  /* Long mode enable */
-#define _EFER_LMA		10 /* Long mode active (read-only) */
-#define _EFER_NX		11 /* No execute enable */
-#define _EFER_SVME		12 /* Enable virtualization */
-#define _EFER_LMSLE		13 /* Long Mode Segment Limit Enable */
-#define _EFER_FFXSR		14 /* Enable Fast FXSAVE/FXRSTOR */
-
-#define EFER_SCE		(1<<_EFER_SCE)
-#define EFER_LME		(1<<_EFER_LME)
-#define EFER_LMA		(1<<_EFER_LMA)
-#define EFER_NX			(1<<_EFER_NX)
-#define EFER_SVME		(1<<_EFER_SVME)
-#define EFER_LMSLE		(1<<_EFER_LMSLE)
-#define EFER_FFXSR		(1<<_EFER_FFXSR)
-
-/* Intel MSRs. Some also available on other CPUs */
-#define MSR_IA32_PERFCTR0		0x000000c1
-#define MSR_IA32_PERFCTR1		0x000000c2
-#define MSR_FSB_FREQ			0x000000cd
-
-#define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
-#define NHM_C3_AUTO_DEMOTE		(1UL << 25)
-#define NHM_C1_AUTO_DEMOTE		(1UL << 26)
-#define ATM_LNC_C6_AUTO_DEMOTE		(1UL << 25)
-
-#define MSR_MTRRcap			0x000000fe
-#define MSR_IA32_BBL_CR_CTL		0x00000119
-#define MSR_IA32_BBL_CR_CTL3		0x0000011e
-
-#define MSR_IA32_SYSENTER_CS		0x00000174
-#define MSR_IA32_SYSENTER_ESP		0x00000175
-#define MSR_IA32_SYSENTER_EIP		0x00000176
-
-#define MSR_IA32_MCG_CAP		0x00000179
-#define MSR_IA32_MCG_STATUS		0x0000017a
-#define MSR_IA32_MCG_CTL		0x0000017b
-
-#define MSR_OFFCORE_RSP_0		0x000001a6
-#define MSR_OFFCORE_RSP_1		0x000001a7
-
-#define MSR_LBR_SELECT			0x000001c8
-#define MSR_LBR_TOS			0x000001c9
-#define MSR_LBR_NHM_FROM		0x00000680
-#define MSR_LBR_NHM_TO			0x000006c0
-#define MSR_LBR_CORE_FROM		0x00000040
-#define MSR_LBR_CORE_TO			0x00000060
-
-#define MSR_IA32_PEBS_ENABLE		0x000003f1
-#define MSR_IA32_DS_AREA		0x00000600
-#define MSR_IA32_PERF_CAPABILITIES	0x00000345
-
-#define MSR_MTRRfix64K_00000		0x00000250
-#define MSR_MTRRfix16K_80000		0x00000258
-#define MSR_MTRRfix16K_A0000		0x00000259
-#define MSR_MTRRfix4K_C0000		0x00000268
-#define MSR_MTRRfix4K_C8000		0x00000269
-#define MSR_MTRRfix4K_D0000		0x0000026a
-#define MSR_MTRRfix4K_D8000		0x0000026b
-#define MSR_MTRRfix4K_E0000		0x0000026c
-#define MSR_MTRRfix4K_E8000		0x0000026d
-#define MSR_MTRRfix4K_F0000		0x0000026e
-#define MSR_MTRRfix4K_F8000		0x0000026f
-#define MSR_MTRRdefType			0x000002ff
-
-#define MSR_IA32_CR_PAT			0x00000277
-
-#define MSR_IA32_DEBUGCTLMSR		0x000001d9
-#define MSR_IA32_LASTBRANCHFROMIP	0x000001db
-#define MSR_IA32_LASTBRANCHTOIP		0x000001dc
-#define MSR_IA32_LASTINTFROMIP		0x000001dd
-#define MSR_IA32_LASTINTTOIP		0x000001de
-
-/* DEBUGCTLMSR bits (others vary by model): */
-#define DEBUGCTLMSR_LBR			(1UL <<  0) /* last branch recording */
-#define DEBUGCTLMSR_BTF			(1UL <<  1) /* single-step on branches */
-#define DEBUGCTLMSR_TR			(1UL <<  6)
-#define DEBUGCTLMSR_BTS			(1UL <<  7)
-#define DEBUGCTLMSR_BTINT		(1UL <<  8)
-#define DEBUGCTLMSR_BTS_OFF_OS		(1UL <<  9)
-#define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
-#define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
-
-#define MSR_IA32_MC0_CTL		0x00000400
-#define MSR_IA32_MC0_STATUS		0x00000401
-#define MSR_IA32_MC0_ADDR		0x00000402
-#define MSR_IA32_MC0_MISC		0x00000403
-
-#define MSR_AMD64_MC0_MASK		0xc0010044
-
-#define MSR_IA32_MCx_CTL(x)		(MSR_IA32_MC0_CTL + 4*(x))
-#define MSR_IA32_MCx_STATUS(x)		(MSR_IA32_MC0_STATUS + 4*(x))
-#define MSR_IA32_MCx_ADDR(x)		(MSR_IA32_MC0_ADDR + 4*(x))
-#define MSR_IA32_MCx_MISC(x)		(MSR_IA32_MC0_MISC + 4*(x))
-
-#define MSR_AMD64_MCx_MASK(x)		(MSR_AMD64_MC0_MASK + (x))
-
-/* These are consecutive and not in the normal 4er MCE bank block */
-#define MSR_IA32_MC0_CTL2		0x00000280
-#define MSR_IA32_MCx_CTL2(x)		(MSR_IA32_MC0_CTL2 + (x))
-
-#define MSR_P6_PERFCTR0			0x000000c1
-#define MSR_P6_PERFCTR1			0x000000c2
-#define MSR_P6_EVNTSEL0			0x00000186
-#define MSR_P6_EVNTSEL1			0x00000187
-
-#define MSR_KNC_PERFCTR0               0x00000020
-#define MSR_KNC_PERFCTR1               0x00000021
-#define MSR_KNC_EVNTSEL0               0x00000028
-#define MSR_KNC_EVNTSEL1               0x00000029
-
-/* AMD64 MSRs. Not complete. See the architecture manual for a more
-   complete list. */
-
-#define MSR_AMD64_PATCH_LEVEL		0x0000008b
-#define MSR_AMD64_TSC_RATIO		0xc0000104
-#define MSR_AMD64_NB_CFG		0xc001001f
-#define MSR_AMD64_PATCH_LOADER		0xc0010020
-#define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
-#define MSR_AMD64_OSVW_STATUS		0xc0010141
-#define MSR_AMD64_DC_CFG		0xc0011022
-#define MSR_AMD64_IBSFETCHCTL		0xc0011030
-#define MSR_AMD64_IBSFETCHLINAD		0xc0011031
-#define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032
-#define MSR_AMD64_IBSFETCH_REG_COUNT	3
-#define MSR_AMD64_IBSFETCH_REG_MASK	((1UL<<MSR_AMD64_IBSFETCH_REG_COUNT)-1)
-#define MSR_AMD64_IBSOPCTL		0xc0011033
-#define MSR_AMD64_IBSOPRIP		0xc0011034
-#define MSR_AMD64_IBSOPDATA		0xc0011035
-#define MSR_AMD64_IBSOPDATA2		0xc0011036
-#define MSR_AMD64_IBSOPDATA3		0xc0011037
-#define MSR_AMD64_IBSDCLINAD		0xc0011038
-#define MSR_AMD64_IBSDCPHYSAD		0xc0011039
-#define MSR_AMD64_IBSOP_REG_COUNT	7
-#define MSR_AMD64_IBSOP_REG_MASK	((1UL<<MSR_AMD64_IBSOP_REG_COUNT)-1)
-#define MSR_AMD64_IBSCTL		0xc001103a
-#define MSR_AMD64_IBSBRTARGET		0xc001103b
-#define MSR_AMD64_IBS_REG_COUNT_MAX	8 /* includes MSR_AMD64_IBSBRTARGET */
-
-/* Fam 15h MSRs */
-#define MSR_F15H_PERF_CTL		0xc0010200
-#define MSR_F15H_PERF_CTR		0xc0010201
-
-/* Fam 10h MSRs */
-#define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058
-#define FAM10H_MMIO_CONF_ENABLE		(1<<0)
-#define FAM10H_MMIO_CONF_BUSRANGE_MASK	0xf
-#define FAM10H_MMIO_CONF_BUSRANGE_SHIFT 2
-#define FAM10H_MMIO_CONF_BASE_MASK	0xfffffffULL
-#define FAM10H_MMIO_CONF_BASE_SHIFT	20
-#define MSR_FAM10H_NODE_ID		0xc001100c
-
-/* K8 MSRs */
-#define MSR_K8_TOP_MEM1			0xc001001a
-#define MSR_K8_TOP_MEM2			0xc001001d
-#define MSR_K8_SYSCFG			0xc0010010
-#define MSR_K8_INT_PENDING_MSG		0xc0010055
-/* C1E active bits in int pending message */
-#define K8_INTP_C1E_ACTIVE_MASK		0x18000000
-#define MSR_K8_TSEG_ADDR		0xc0010112
-#define K8_MTRRFIXRANGE_DRAM_ENABLE	0x00040000 /* MtrrFixDramEn bit    */
-#define K8_MTRRFIXRANGE_DRAM_MODIFY	0x00080000 /* MtrrFixDramModEn bit */
-#define K8_MTRR_RDMEM_WRMEM_MASK	0x18181818 /* Mask: RdMem|WrMem    */
-
-/* K7 MSRs */
-#define MSR_K7_EVNTSEL0			0xc0010000
-#define MSR_K7_PERFCTR0			0xc0010004
-#define MSR_K7_EVNTSEL1			0xc0010001
-#define MSR_K7_PERFCTR1			0xc0010005
-#define MSR_K7_EVNTSEL2			0xc0010002
-#define MSR_K7_PERFCTR2			0xc0010006
-#define MSR_K7_EVNTSEL3			0xc0010003
-#define MSR_K7_PERFCTR3			0xc0010007
-#define MSR_K7_CLK_CTL			0xc001001b
-#define MSR_K7_HWCR			0xc0010015
-#define MSR_K7_FID_VID_CTL		0xc0010041
-#define MSR_K7_FID_VID_STATUS		0xc0010042
-
-/* K6 MSRs */
-#define MSR_K6_WHCR			0xc0000082
-#define MSR_K6_UWCCR			0xc0000085
-#define MSR_K6_EPMR			0xc0000086
-#define MSR_K6_PSOR			0xc0000087
-#define MSR_K6_PFIR			0xc0000088
-
-/* Centaur-Hauls/IDT defined MSRs. */
-#define MSR_IDT_FCR1			0x00000107
-#define MSR_IDT_FCR2			0x00000108
-#define MSR_IDT_FCR3			0x00000109
-#define MSR_IDT_FCR4			0x0000010a
-
-#define MSR_IDT_MCR0			0x00000110
-#define MSR_IDT_MCR1			0x00000111
-#define MSR_IDT_MCR2			0x00000112
-#define MSR_IDT_MCR3			0x00000113
-#define MSR_IDT_MCR4			0x00000114
-#define MSR_IDT_MCR5			0x00000115
-#define MSR_IDT_MCR6			0x00000116
-#define MSR_IDT_MCR7			0x00000117
-#define MSR_IDT_MCR_CTRL		0x00000120
-
-/* VIA Cyrix defined MSRs*/
-#define MSR_VIA_FCR			0x00001107
-#define MSR_VIA_LONGHAUL		0x0000110a
-#define MSR_VIA_RNG			0x0000110b
-#define MSR_VIA_BCR2			0x00001147
-
-/* Transmeta defined MSRs */
-#define MSR_TMTA_LONGRUN_CTRL		0x80868010
-#define MSR_TMTA_LONGRUN_FLAGS		0x80868011
-#define MSR_TMTA_LRTI_READOUT		0x80868018
-#define MSR_TMTA_LRTI_VOLT_MHZ		0x8086801a
-
-/* Intel defined MSRs. */
-#define MSR_IA32_P5_MC_ADDR		0x00000000
-#define MSR_IA32_P5_MC_TYPE		0x00000001
-#define MSR_IA32_TSC			0x00000010
-#define MSR_IA32_PLATFORM_ID		0x00000017
-#define MSR_IA32_EBL_CR_POWERON		0x0000002a
-#define MSR_EBC_FREQUENCY_ID		0x0000002c
-#define MSR_IA32_FEATURE_CONTROL        0x0000003a
-#define MSR_IA32_TSC_ADJUST             0x0000003b
-
-#define FEATURE_CONTROL_LOCKED				(1<<0)
-#define FEATURE_CONTROL_VMXON_ENABLED_INSIDE_SMX	(1<<1)
-#define FEATURE_CONTROL_VMXON_ENABLED_OUTSIDE_SMX	(1<<2)
-
-#define MSR_IA32_APICBASE		0x0000001b
-#define MSR_IA32_APICBASE_BSP		(1<<8)
-#define MSR_IA32_APICBASE_ENABLE	(1<<11)
-#define MSR_IA32_APICBASE_BASE		(0xfffff<<12)
-
-#define MSR_IA32_TSCDEADLINE		0x000006e0
-
-#define MSR_IA32_UCODE_WRITE		0x00000079
-#define MSR_IA32_UCODE_REV		0x0000008b
-
-#define MSR_IA32_PERF_STATUS		0x00000198
-#define MSR_IA32_PERF_CTL		0x00000199
-#define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
-#define MSR_AMD_PERF_STATUS		0xc0010063
-#define MSR_AMD_PERF_CTL		0xc0010062
-
-#define MSR_IA32_MPERF			0x000000e7
-#define MSR_IA32_APERF			0x000000e8
-
-#define MSR_IA32_THERM_CONTROL		0x0000019a
-#define MSR_IA32_THERM_INTERRUPT	0x0000019b
-
-#define THERM_INT_HIGH_ENABLE		(1 << 0)
-#define THERM_INT_LOW_ENABLE		(1 << 1)
-#define THERM_INT_PLN_ENABLE		(1 << 24)
-
-#define MSR_IA32_THERM_STATUS		0x0000019c
-
-#define THERM_STATUS_PROCHOT		(1 << 0)
-#define THERM_STATUS_POWER_LIMIT	(1 << 10)
-
-#define MSR_THERM2_CTL			0x0000019d
-
-#define MSR_THERM2_CTL_TM_SELECT	(1ULL << 16)
-
-#define MSR_IA32_MISC_ENABLE		0x000001a0
-
-#define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
-
-#define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
-#define ENERGY_PERF_BIAS_PERFORMANCE	0
-#define ENERGY_PERF_BIAS_NORMAL		6
-#define ENERGY_PERF_BIAS_POWERSAVE	15
-
-#define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
-
-#define PACKAGE_THERM_STATUS_PROCHOT		(1 << 0)
-#define PACKAGE_THERM_STATUS_POWER_LIMIT	(1 << 10)
-
-#define MSR_IA32_PACKAGE_THERM_INTERRUPT	0x000001b2
-
-#define PACKAGE_THERM_INT_HIGH_ENABLE		(1 << 0)
-#define PACKAGE_THERM_INT_LOW_ENABLE		(1 << 1)
-#define PACKAGE_THERM_INT_PLN_ENABLE		(1 << 24)
-
-/* Thermal Thresholds Support */
-#define THERM_INT_THRESHOLD0_ENABLE    (1 << 15)
-#define THERM_SHIFT_THRESHOLD0        8
-#define THERM_MASK_THRESHOLD0          (0x7f << THERM_SHIFT_THRESHOLD0)
-#define THERM_INT_THRESHOLD1_ENABLE    (1 << 23)
-#define THERM_SHIFT_THRESHOLD1        16
-#define THERM_MASK_THRESHOLD1          (0x7f << THERM_SHIFT_THRESHOLD1)
-#define THERM_STATUS_THRESHOLD0        (1 << 6)
-#define THERM_LOG_THRESHOLD0           (1 << 7)
-#define THERM_STATUS_THRESHOLD1        (1 << 8)
-#define THERM_LOG_THRESHOLD1           (1 << 9)
-
-/* MISC_ENABLE bits: architectural */
-#define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
-#define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)
-#define MSR_IA32_MISC_ENABLE_EMON		(1ULL << 7)
-#define MSR_IA32_MISC_ENABLE_BTS_UNAVAIL	(1ULL << 11)
-#define MSR_IA32_MISC_ENABLE_PEBS_UNAVAIL	(1ULL << 12)
-#define MSR_IA32_MISC_ENABLE_ENHANCED_SPEEDSTEP	(1ULL << 16)
-#define MSR_IA32_MISC_ENABLE_MWAIT		(1ULL << 18)
-#define MSR_IA32_MISC_ENABLE_LIMIT_CPUID	(1ULL << 22)
-#define MSR_IA32_MISC_ENABLE_XTPR_DISABLE	(1ULL << 23)
-#define MSR_IA32_MISC_ENABLE_XD_DISABLE		(1ULL << 34)
-
-/* MISC_ENABLE bits: model-specific, meaning may vary from core to core */
-#define MSR_IA32_MISC_ENABLE_X87_COMPAT		(1ULL << 2)
-#define MSR_IA32_MISC_ENABLE_TM1		(1ULL << 3)
-#define MSR_IA32_MISC_ENABLE_SPLIT_LOCK_DISABLE	(1ULL << 4)
-#define MSR_IA32_MISC_ENABLE_L3CACHE_DISABLE	(1ULL << 6)
-#define MSR_IA32_MISC_ENABLE_SUPPRESS_LOCK	(1ULL << 8)
-#define MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE	(1ULL << 9)
-#define MSR_IA32_MISC_ENABLE_FERR		(1ULL << 10)
-#define MSR_IA32_MISC_ENABLE_FERR_MULTIPLEX	(1ULL << 10)
-#define MSR_IA32_MISC_ENABLE_TM2		(1ULL << 13)
-#define MSR_IA32_MISC_ENABLE_ADJ_PREF_DISABLE	(1ULL << 19)
-#define MSR_IA32_MISC_ENABLE_SPEEDSTEP_LOCK	(1ULL << 20)
-#define MSR_IA32_MISC_ENABLE_L1D_CONTEXT	(1ULL << 24)
-#define MSR_IA32_MISC_ENABLE_DCU_PREF_DISABLE	(1ULL << 37)
-#define MSR_IA32_MISC_ENABLE_TURBO_DISABLE	(1ULL << 38)
-#define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE	(1ULL << 39)
-
-#define MSR_IA32_TSC_DEADLINE		0x000006E0
-
-/* P4/Xeon+ specific */
-#define MSR_IA32_MCG_EAX		0x00000180
-#define MSR_IA32_MCG_EBX		0x00000181
-#define MSR_IA32_MCG_ECX		0x00000182
-#define MSR_IA32_MCG_EDX		0x00000183
-#define MSR_IA32_MCG_ESI		0x00000184
-#define MSR_IA32_MCG_EDI		0x00000185
-#define MSR_IA32_MCG_EBP		0x00000186
-#define MSR_IA32_MCG_ESP		0x00000187
-#define MSR_IA32_MCG_EFLAGS		0x00000188
-#define MSR_IA32_MCG_EIP		0x00000189
-#define MSR_IA32_MCG_RESERVED		0x0000018a
-
-/* Pentium IV performance counter MSRs */
-#define MSR_P4_BPU_PERFCTR0		0x00000300
-#define MSR_P4_BPU_PERFCTR1		0x00000301
-#define MSR_P4_BPU_PERFCTR2		0x00000302
-#define MSR_P4_BPU_PERFCTR3		0x00000303
-#define MSR_P4_MS_PERFCTR0		0x00000304
-#define MSR_P4_MS_PERFCTR1		0x00000305
-#define MSR_P4_MS_PERFCTR2		0x00000306
-#define MSR_P4_MS_PERFCTR3		0x00000307
-#define MSR_P4_FLAME_PERFCTR0		0x00000308
-#define MSR_P4_FLAME_PERFCTR1		0x00000309
-#define MSR_P4_FLAME_PERFCTR2		0x0000030a
-#define MSR_P4_FLAME_PERFCTR3		0x0000030b
-#define MSR_P4_IQ_PERFCTR0		0x0000030c
-#define MSR_P4_IQ_PERFCTR1		0x0000030d
-#define MSR_P4_IQ_PERFCTR2		0x0000030e
-#define MSR_P4_IQ_PERFCTR3		0x0000030f
-#define MSR_P4_IQ_PERFCTR4		0x00000310
-#define MSR_P4_IQ_PERFCTR5		0x00000311
-#define MSR_P4_BPU_CCCR0		0x00000360
-#define MSR_P4_BPU_CCCR1		0x00000361
-#define MSR_P4_BPU_CCCR2		0x00000362
-#define MSR_P4_BPU_CCCR3		0x00000363
-#define MSR_P4_MS_CCCR0			0x00000364
-#define MSR_P4_MS_CCCR1			0x00000365
-#define MSR_P4_MS_CCCR2			0x00000366
-#define MSR_P4_MS_CCCR3			0x00000367
-#define MSR_P4_FLAME_CCCR0		0x00000368
-#define MSR_P4_FLAME_CCCR1		0x00000369
-#define MSR_P4_FLAME_CCCR2		0x0000036a
-#define MSR_P4_FLAME_CCCR3		0x0000036b
-#define MSR_P4_IQ_CCCR0			0x0000036c
-#define MSR_P4_IQ_CCCR1			0x0000036d
-#define MSR_P4_IQ_CCCR2			0x0000036e
-#define MSR_P4_IQ_CCCR3			0x0000036f
-#define MSR_P4_IQ_CCCR4			0x00000370
-#define MSR_P4_IQ_CCCR5			0x00000371
-#define MSR_P4_ALF_ESCR0		0x000003ca
-#define MSR_P4_ALF_ESCR1		0x000003cb
-#define MSR_P4_BPU_ESCR0		0x000003b2
-#define MSR_P4_BPU_ESCR1		0x000003b3
-#define MSR_P4_BSU_ESCR0		0x000003a0
-#define MSR_P4_BSU_ESCR1		0x000003a1
-#define MSR_P4_CRU_ESCR0		0x000003b8
-#define MSR_P4_CRU_ESCR1		0x000003b9
-#define MSR_P4_CRU_ESCR2		0x000003cc
-#define MSR_P4_CRU_ESCR3		0x000003cd
-#define MSR_P4_CRU_ESCR4		0x000003e0
-#define MSR_P4_CRU_ESCR5		0x000003e1
-#define MSR_P4_DAC_ESCR0		0x000003a8
-#define MSR_P4_DAC_ESCR1		0x000003a9
-#define MSR_P4_FIRM_ESCR0		0x000003a4
-#define MSR_P4_FIRM_ESCR1		0x000003a5
-#define MSR_P4_FLAME_ESCR0		0x000003a6
-#define MSR_P4_FLAME_ESCR1		0x000003a7
-#define MSR_P4_FSB_ESCR0		0x000003a2
-#define MSR_P4_FSB_ESCR1		0x000003a3
-#define MSR_P4_IQ_ESCR0			0x000003ba
-#define MSR_P4_IQ_ESCR1			0x000003bb
-#define MSR_P4_IS_ESCR0			0x000003b4
-#define MSR_P4_IS_ESCR1			0x000003b5
-#define MSR_P4_ITLB_ESCR0		0x000003b6
-#define MSR_P4_ITLB_ESCR1		0x000003b7
-#define MSR_P4_IX_ESCR0			0x000003c8
-#define MSR_P4_IX_ESCR1			0x000003c9
-#define MSR_P4_MOB_ESCR0		0x000003aa
-#define MSR_P4_MOB_ESCR1		0x000003ab
-#define MSR_P4_MS_ESCR0			0x000003c0
-#define MSR_P4_MS_ESCR1			0x000003c1
-#define MSR_P4_PMH_ESCR0		0x000003ac
-#define MSR_P4_PMH_ESCR1		0x000003ad
-#define MSR_P4_RAT_ESCR0		0x000003bc
-#define MSR_P4_RAT_ESCR1		0x000003bd
-#define MSR_P4_SAAT_ESCR0		0x000003ae
-#define MSR_P4_SAAT_ESCR1		0x000003af
-#define MSR_P4_SSU_ESCR0		0x000003be
-#define MSR_P4_SSU_ESCR1		0x000003bf /* guess: not in manual */
-
-#define MSR_P4_TBPU_ESCR0		0x000003c2
-#define MSR_P4_TBPU_ESCR1		0x000003c3
-#define MSR_P4_TC_ESCR0			0x000003c4
-#define MSR_P4_TC_ESCR1			0x000003c5
-#define MSR_P4_U2L_ESCR0		0x000003b0
-#define MSR_P4_U2L_ESCR1		0x000003b1
-
-#define MSR_P4_PEBS_MATRIX_VERT		0x000003f2
-
-/* Intel Core-based CPU performance counters */
-#define MSR_CORE_PERF_FIXED_CTR0	0x00000309
-#define MSR_CORE_PERF_FIXED_CTR1	0x0000030a
-#define MSR_CORE_PERF_FIXED_CTR2	0x0000030b
-#define MSR_CORE_PERF_FIXED_CTR_CTRL	0x0000038d
-#define MSR_CORE_PERF_GLOBAL_STATUS	0x0000038e
-#define MSR_CORE_PERF_GLOBAL_CTRL	0x0000038f
-#define MSR_CORE_PERF_GLOBAL_OVF_CTRL	0x00000390
-
-/* Geode defined MSRs */
-#define MSR_GEODE_BUSCONT_CONF0		0x00001900
-
-/* Intel VT MSRs */
-#define MSR_IA32_VMX_BASIC              0x00000480
-#define MSR_IA32_VMX_PINBASED_CTLS      0x00000481
-#define MSR_IA32_VMX_PROCBASED_CTLS     0x00000482
-#define MSR_IA32_VMX_EXIT_CTLS          0x00000483
-#define MSR_IA32_VMX_ENTRY_CTLS         0x00000484
-#define MSR_IA32_VMX_MISC               0x00000485
-#define MSR_IA32_VMX_CR0_FIXED0         0x00000486
-#define MSR_IA32_VMX_CR0_FIXED1         0x00000487
-#define MSR_IA32_VMX_CR4_FIXED0         0x00000488
-#define MSR_IA32_VMX_CR4_FIXED1         0x00000489
-#define MSR_IA32_VMX_VMCS_ENUM          0x0000048a
-#define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
-#define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
-#define MSR_IA32_VMX_TRUE_PINBASED_CTLS  0x0000048d
-#define MSR_IA32_VMX_TRUE_PROCBASED_CTLS 0x0000048e
-#define MSR_IA32_VMX_TRUE_EXIT_CTLS      0x0000048f
-#define MSR_IA32_VMX_TRUE_ENTRY_CTLS     0x00000490
-
-/* VMX_BASIC bits and bitmasks */
-#define VMX_BASIC_VMCS_SIZE_SHIFT	32
-#define VMX_BASIC_64		0x0001000000000000LLU
-#define VMX_BASIC_MEM_TYPE_SHIFT	50
-#define VMX_BASIC_MEM_TYPE_MASK	0x003c000000000000LLU
-#define VMX_BASIC_MEM_TYPE_WB	6LLU
-#define VMX_BASIC_INOUT		0x0040000000000000LLU
-
-/* AMD-V MSRs */
-
-#define MSR_VM_CR                       0xc0010114
-#define MSR_VM_IGNNE                    0xc0010115
-#define MSR_VM_HSAVE_PA                 0xc0010117
-
-#endif /* _ASM_X86_MSR_INDEX_H */

commit 66cdd0ceaf65a18996f561b770eedde1d123b019
Merge: 896ea17d3da5 58b7825bc324
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 13 15:31:08 2012 -0800

    Merge tag 'kvm-3.8-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Marcelo Tosatti:
     "Considerable KVM/PPC work, x86 kvmclock vsyscall support,
      IA32_TSC_ADJUST MSR emulation, amongst others."
    
    Fix up trivial conflict in kernel/sched/core.c due to cross-cpu
    migration notifier added next to rq migration call-back.
    
    * tag 'kvm-3.8-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (156 commits)
      KVM: emulator: fix real mode segment checks in address linearization
      VMX: remove unneeded enable_unrestricted_guest check
      KVM: VMX: fix DPL during entry to protected mode
      x86/kexec: crash_vmclear_local_vmcss needs __rcu
      kvm: Fix irqfd resampler list walk
      KVM: VMX: provide the vmclear function and a bitmap to support VMCLEAR in kdump
      x86/kexec: VMCLEAR VMCSs loaded on all cpus if necessary
      KVM: MMU: optimize for set_spte
      KVM: PPC: booke: Get/set guest EPCR register using ONE_REG interface
      KVM: PPC: bookehv: Add EPCR support in mtspr/mfspr emulation
      KVM: PPC: bookehv: Add guest computation mode for irq delivery
      KVM: PPC: Make EPCR a valid field for booke64 and bookehv
      KVM: PPC: booke: Extend MAS2 EPN mask for 64-bit
      KVM: PPC: e500: Mask MAS2 EPN high 32-bits in 32/64 tlbwe emulation
      KVM: PPC: Mask ea's high 32-bits in 32/64 instr emulation
      KVM: PPC: e500: Add emulation helper for getting instruction ea
      KVM: PPC: bookehv64: Add support for interrupt handling
      KVM: PPC: bookehv: Remove GET_VCPU macro from exception handler
      KVM: PPC: booke: Fix get_tb() compile error on 64-bit
      KVM: PPC: e500: Silence bogus GCC warning in tlb code
      ...

commit ba904635d498fea43fc3610983f9dc430ac324e4
Author: Will Auld <will.auld.intel@gmail.com>
Date:   Thu Nov 29 12:42:50 2012 -0800

    KVM: x86: Emulate IA32_TSC_ADJUST MSR
    
    CPUID.7.0.EBX[1]=1 indicates IA32_TSC_ADJUST MSR 0x3b is supported
    
    Basic design is to emulate the MSR by allowing reads and writes to a guest
    vcpu specific location to store the value of the emulated MSR while adding
    the value to the vmcs tsc_offset. In this way the IA32_TSC_ADJUST value will
    be included in all reads to the TSC MSR whether through rdmsr or rdtsc. This
    is of course as long as the "use TSC counter offsetting" VM-execution control
    is enabled as well as the IA32_TSC_ADJUST control.
    
    However, because hardware will only return the TSC + IA32_TSC_ADJUST +
    vmsc tsc_offset for a guest process when it does and rdtsc (with the correct
    settings) the value of our virtualized IA32_TSC_ADJUST must be stored in one
    of these three locations. The argument against storing it in the actual MSR
    is performance. This is likely to be seldom used while the save/restore is
    required on every transition. IA32_TSC_ADJUST was created as a way to solve
    some issues with writing TSC itself so that is not an option either.
    
    The remaining option, defined above as our solution has the problem of
    returning incorrect vmcs tsc_offset values (unless we intercept and fix, not
    done here) as mentioned above. However, more problematic is that storing the
    data in vmcs tsc_offset will have a different semantic effect on the system
    than does using the actual MSR. This is illustrated in the following example:
    
    The hypervisor set the IA32_TSC_ADJUST, then the guest sets it and a guest
    process performs a rdtsc. In this case the guest process will get
    TSC + IA32_TSC_ADJUST_hyperviser + vmsc tsc_offset including
    IA32_TSC_ADJUST_guest. While the total system semantics changed the semantics
    as seen by the guest do not and hence this will not cause a problem.
    
    Signed-off-by: Will Auld <will.auld@intel.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 7f0edceb7563..c2dea36dd7ac 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -236,6 +236,7 @@
 #define MSR_IA32_EBL_CR_POWERON		0x0000002a
 #define MSR_EBC_FREQUENCY_ID		0x0000002c
 #define MSR_IA32_FEATURE_CONTROL        0x0000003a
+#define MSR_IA32_TSC_ADJUST             0x0000003b
 
 #define FEATURE_CONTROL_LOCKED				(1<<0)
 #define FEATURE_CONTROL_VMXON_ENABLED_INSIDE_SMX	(1<<1)

commit 279f1461432ccdec0b98c0bcbe0a8e2c0f6fdda5
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Oct 22 14:37:58 2012 -0700

    x86: apic: Use tsc deadline for oneshot when available
    
    If the TSC deadline mode is supported, LAPIC timer one-shot mode can be
    implemented using IA32_TSC_DEADLINE MSR. An interrupt will be generated
    when the TSC value equals or exceeds the value in the IA32_TSC_DEADLINE
    MSR.
    
    This enables us to skip the APIC calibration during boot. Also, in
    xapic mode, this enables us to skip the uncached apic access to re-arm
    the APIC timer.
    
    As this timer ticks at the high frequency TSC rate, we use the
    TSC_DIVISOR (32) to work with the 32-bit restrictions in the
    clockevent API's to avoid 64-bit divides etc (frequency is u32 and
    "unsigned long" in the set_next_event(), max_delta limits the next
    event to 32-bit for 32-bit kernel).
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: venki@google.com
    Cc: len.brown@intel.com
    Link: http://lkml.kernel.org/r/1350941878.6017.31.camel@sbsiddha-desk.sc.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 7f0edceb7563..e400cdb2dd65 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -337,6 +337,8 @@
 #define MSR_IA32_MISC_ENABLE_TURBO_DISABLE	(1ULL << 38)
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE	(1ULL << 39)
 
+#define MSR_IA32_TSC_DEADLINE		0x000006E0
+
 /* P4/Xeon+ specific */
 #define MSR_IA32_MCG_EAX		0x00000180
 #define MSR_IA32_MCG_EBX		0x00000181

commit ade0899b298ba2c43bfd6abd8cbc2545944cde0c
Merge: 871a0596cb2f 95cf59ea7233
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 13 10:20:11 2012 +0900

    Merge branch 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf updates from Ingo Molnar:
     "This tree includes some late late perf items that missed the first
      round:
    
      tools:
    
       - Bash auto completion improvements, now we can auto complete the
         tools long options, tracepoint event names, etc, from Namhyung Kim.
    
       - Look up thread using tid instead of pid in 'perf sched'.
    
       - Move global variables into a perf_kvm struct, from David Ahern.
    
       - Hists refactorings, preparatory for improved 'diff' command, from
         Jiri Olsa.
    
       - Hists refactorings, preparatory for event group viewieng work, from
         Namhyung Kim.
    
       - Remove double negation on optional feature macro definitions, from
         Namhyung Kim.
    
       - Remove several cases of needless global variables, on most
         builtins.
    
       - misc fixes
    
      kernel:
    
       - sysfs support for IBS on AMD CPUs, from Robert Richter.
    
       - Support for an upcoming Intel CPU, the Xeon-Phi / Knights Corner
         HPC blade PMU, from Vince Weaver.
    
       - misc fixes"
    
    * 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (46 commits)
      perf: Fix perf_cgroup_switch for sw-events
      perf: Clarify perf_cpu_context::active_pmu usage by renaming it to ::unique_pmu
      perf/AMD/IBS: Add sysfs support
      perf hists: Add more helpers for hist entry stat
      perf hists: Move he->stat.nr_events initialization to a template
      perf hists: Introduce struct he_stat
      perf diff: Removing the total_period argument from output code
      perf tool: Add hpp interface to enable/disable hpp column
      perf tools: Removing hists pair argument from output path
      perf hists: Separate overhead and baseline columns
      perf diff: Refactor diff displacement possition info
      perf hists: Add struct hists pointer to struct hist_entry
      perf tools: Complete tracepoint event names
      perf/x86: Add support for Intel Xeon-Phi Knights Corner PMU
      perf evlist: Remove some unused methods
      perf evlist: Introduce add_newtp method
      perf kvm: Move global variables into a perf_kvm struct
      perf tools: Convert to BACKTRACE_SUPPORT
      perf tools: Long option completion support for each subcommands
      perf tools: Complete long option names of perf command
      ...

commit e717bf4e4fe8adc519f25c4ff93ee50ed0a36710
Author: Vince Weaver <vincent.weaver@maine.edu>
Date:   Wed Sep 26 14:12:52 2012 -0400

    perf/x86: Add support for Intel Xeon-Phi Knights Corner PMU
    
    The following patch adds perf_event support for the Xeon-Phi
    PMU, as documented in the "Intel Xeon Phi Coprocessor (codename:
    Knights Corner) Performance Monitoring Units" manual.
    
    Even though it is a co-processor, a Phi runs a full Linux
    environment and can support performance counters.
    
    This is just barebones support, it does not add support for
    interesting new features such as the SPFLT intruction that
    allows starting/stopping events without entering the kernel.
    
    The PMU internally is just like that of an original Pentium, but
    a "P6-like" MSR interface is provided.  The interface is
    different enough from a real P6 that it's not easy (or
    practical) to re-use the code in  perf_event_p6.c
    
    Acked-by: Lawrence F Meadows <lawrence.f.meadows@intel.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: Vince Weaver <vincent.weaver@maine.edu>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: eranian@gmail.com
    Cc: Lawrence F <lawrence.f.meadows@intel.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1209261405320.8398@vincent-weaver-1.um.maine.edu
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 957ec87385af..07f96cb5cdb9 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -121,6 +121,11 @@
 #define MSR_P6_EVNTSEL0			0x00000186
 #define MSR_P6_EVNTSEL1			0x00000187
 
+#define MSR_KNC_PERFCTR0               0x00000020
+#define MSR_KNC_PERFCTR1               0x00000021
+#define MSR_KNC_EVNTSEL0               0x00000028
+#define MSR_KNC_EVNTSEL1               0x00000029
+
 /* AMD64 MSRs. Not complete. See the architecture manual for a more
    complete list. */
 

commit f594065faf4f9067c2283a34619fc0714e79a98d
Author: Matthew Garrett <mjg@redhat.com>
Date:   Tue Sep 4 08:28:06 2012 +0000

    ACPI: Add fixups for AMD P-state figures
    
    Some AMD systems may round the frequencies in ACPI tables to 100MHz
    boundaries. We can obtain the real frequencies from MSRs, so add a quirk
    to fix these frequencies up on AMD systems.
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Andre Przywara <andre.przywara@amd.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1e1f3eb58638..fbee9714d9ab 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -248,6 +248,7 @@
 
 #define MSR_IA32_PERF_STATUS		0x00000198
 #define MSR_IA32_PERF_CTL		0x00000199
+#define MSR_AMD_PSTATE_DEF_BASE		0xc0010064
 #define MSR_AMD_PERF_STATUS		0xc0010063
 #define MSR_AMD_PERF_CTL		0xc0010062
 

commit 3dc9a633f8a65b39c5897874138027328bfb0a94
Author: Matthew Garrett <mjg@redhat.com>
Date:   Tue Sep 4 08:28:02 2012 +0000

    acpi-cpufreq: Add support for modern AMD CPUs
    
    The programming model for P-states on modern AMD CPUs is very similar to
    that of Intel and VIA. It makes sense to consolidate this support into one
    driver rather than duplicating functionality between two of them. This
    patch adds support for AMDs with hardware P-state control to acpi-cpufreq.
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Andre Przywara <andre.przywara@amd.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 957ec87385af..1e1f3eb58638 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -248,6 +248,8 @@
 
 #define MSR_IA32_PERF_STATUS		0x00000198
 #define MSR_IA32_PERF_CTL		0x00000199
+#define MSR_AMD_PERF_STATUS		0xc0010063
+#define MSR_AMD_PERF_CTL		0xc0010062
 
 #define MSR_IA32_MPERF			0x000000e7
 #define MSR_IA32_APERF			0x000000e8

commit ad8537cda68a8fe81776cceca6c22d54dd652ea5
Merge: 149936a068d8 fab06992de64
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed May 9 15:22:23 2012 +0200

    Merge branch 'perf/x86-ibs' into perf/core

commit b7074f1fbd6149eac1ec25063e4a364c39a85473
Author: Robert Richter <robert.richter@amd.com>
Date:   Thu Dec 15 17:56:37 2011 +0100

    perf/x86: Implement IBS interrupt handler
    
    This patch implements code to handle ibs interrupts. If ibs data
    is available a raw perf_event data sample is created and sent
    back to the userland. This patch only implements the storage of
    ibs data in the raw sample, but this could be extended in a
    later patch by generating generic event data such as the rip
    from the ibs sampling data.
    
    Signed-off-by: Robert Richter <robert.richter@amd.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1323968199-9326-3-git-send-email-robert.richter@amd.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index a6962d9161a0..4e3cd382a06f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -127,6 +127,8 @@
 #define MSR_AMD64_IBSFETCHCTL		0xc0011030
 #define MSR_AMD64_IBSFETCHLINAD		0xc0011031
 #define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032
+#define MSR_AMD64_IBSFETCH_REG_COUNT	3
+#define MSR_AMD64_IBSFETCH_REG_MASK	((1UL<<MSR_AMD64_IBSFETCH_REG_COUNT)-1)
 #define MSR_AMD64_IBSOPCTL		0xc0011033
 #define MSR_AMD64_IBSOPRIP		0xc0011034
 #define MSR_AMD64_IBSOPDATA		0xc0011035
@@ -134,8 +136,11 @@
 #define MSR_AMD64_IBSOPDATA3		0xc0011037
 #define MSR_AMD64_IBSDCLINAD		0xc0011038
 #define MSR_AMD64_IBSDCPHYSAD		0xc0011039
+#define MSR_AMD64_IBSOP_REG_COUNT	7
+#define MSR_AMD64_IBSOP_REG_MASK	((1UL<<MSR_AMD64_IBSOP_REG_COUNT)-1)
 #define MSR_AMD64_IBSCTL		0xc001103a
 #define MSR_AMD64_IBSBRTARGET		0xc001103b
+#define MSR_AMD64_IBS_REG_COUNT_MAX	8 /* includes MSR_AMD64_IBSBRTARGET */
 
 /* Fam 15h MSRs */
 #define MSR_F15H_PERF_CTL		0xc0010200

commit 225ce53910edc3c2322b1e4f2ed049a9196cd0b3
Author: Stephane Eranian <eranian@google.com>
Date:   Thu Feb 9 23:20:52 2012 +0100

    perf/x86: Add Intel LBR MSR definitions
    
    This patch adds the LBR definitions for NHM/WSM/SNB and Core.
    It also adds the definitions for the architected LBR MSR:
    LBR_SELECT, LBRT_TOS.
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1328826068-11713-3-git-send-email-eranian@google.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index a6962d9161a0..ccb805966f68 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -56,6 +56,13 @@
 #define MSR_OFFCORE_RSP_0		0x000001a6
 #define MSR_OFFCORE_RSP_1		0x000001a7
 
+#define MSR_LBR_SELECT			0x000001c8
+#define MSR_LBR_TOS			0x000001c9
+#define MSR_LBR_NHM_FROM		0x00000680
+#define MSR_LBR_NHM_TO			0x000006c0
+#define MSR_LBR_CORE_FROM		0x00000040
+#define MSR_LBR_CORE_TO			0x00000060
+
 #define MSR_IA32_PEBS_ENABLE		0x000003f1
 #define MSR_IA32_DS_AREA		0x00000600
 #define MSR_IA32_PERF_CAPABILITIES	0x00000345

commit b90dfb0419a79a90395e04fee3fbda3c12ba8237
Author: Liu, Jinsong <jinsong.liu@intel.com>
Date:   Thu Sep 22 16:53:58 2011 +0800

    x86: TSC deadline definitions
    
    This pre-defination is preparing for KVM tsc deadline timer emulation, but
    theirself are not kvm specific.
    
    Signed-off-by: Liu, Jinsong <jinsong.liu@intel.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index d52609aeeab8..a6962d9161a0 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -229,6 +229,8 @@
 #define MSR_IA32_APICBASE_ENABLE	(1<<11)
 #define MSR_IA32_APICBASE_BASE		(0xfffff<<12)
 
+#define MSR_IA32_TSCDEADLINE		0x000006e0
+
 #define MSR_IA32_UCODE_WRITE		0x00000079
 #define MSR_IA32_UCODE_REV		0x0000008b
 

commit 5fabc487c96819dd12ddb9414835d170fd9cd6d5
Merge: c61264f98c1a 3f68b0318bbb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jul 24 09:07:03 2011 -0700

    Merge branch 'kvm-updates/3.1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    * 'kvm-updates/3.1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (143 commits)
      KVM: IOMMU: Disable device assignment without interrupt remapping
      KVM: MMU: trace mmio page fault
      KVM: MMU: mmio page fault support
      KVM: MMU: reorganize struct kvm_shadow_walk_iterator
      KVM: MMU: lockless walking shadow page table
      KVM: MMU: do not need atomicly to set/clear spte
      KVM: MMU: introduce the rules to modify shadow page table
      KVM: MMU: abstract some functions to handle fault pfn
      KVM: MMU: filter out the mmio pfn from the fault pfn
      KVM: MMU: remove bypass_guest_pf
      KVM: MMU: split kvm_mmu_free_page
      KVM: MMU: count used shadow pages on prepareing path
      KVM: MMU: rename 'pt_write' to 'emulate'
      KVM: MMU: cleanup for FNAME(fetch)
      KVM: MMU: optimize to handle dirty bit
      KVM: MMU: cache mmio info on page fault path
      KVM: x86: introduce vcpu_mmio_gva_to_gpa to cleanup the code
      KVM: MMU: do not update slot bitmap if spte is nonpresent
      KVM: MMU: fix walking shadow page table
      KVM guest: KVM Steal time registration
      ...

commit 4bb82178f5cb074783aaeaa06f9f840c67af7707
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Thu Jul 14 14:58:44 2011 -0700

    x86, msr: Fix typo in ENERGY_PERF_BIAS_POWERSAVE
    
    Fix a trivial typo in the name of the constant
    ENERGY_PERF_BIAS_POWERSAVE.  This didn't cause trouble because this
    constant is not currently used for anything.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Link: http://lkml.kernel.org/r/tip-abe48b108247e9b90b4c6739662a2e5c765ed114@git.kernel.org

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 23a9d898baad..d96bdb25ca3d 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -261,7 +261,7 @@
 #define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
 #define ENERGY_PERF_BIAS_PERFORMANCE	0
 #define ENERGY_PERF_BIAS_NORMAL		6
-#define ENERGY_PERF_BIAS_POWERSWAVE	15
+#define ENERGY_PERF_BIAS_POWERSAVE	15
 
 #define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
 

commit abe48b108247e9b90b4c6739662a2e5c765ed114
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 14 00:53:24 2011 -0400

    x86, intel, power: Initialize MSR_IA32_ENERGY_PERF_BIAS
    
    Since 2.6.36 (23016bf0d25), Linux prints the existence of "epb" in /proc/cpuinfo,
    Since 2.6.38 (d5532ee7b40), the x86_energy_perf_policy(8) utility has
    been available in-tree to update MSR_IA32_ENERGY_PERF_BIAS.
    
    However, the typical BIOS fails to initialize the MSR, presumably
    because this is handled by high-volume shrink-wrap operating systems...
    
    Linux distros, on the other hand, do not yet invoke x86_energy_perf_policy(8).
    As a result, WSM-EP, SNB, and later hardware from Intel will run in its
    default hardware power-on state (performance), which assumes that users
    care for performance at all costs and not for energy efficiency.
    While that is fine for performance benchmarks, the hardware's intended default
    operating point is "normal" mode...
    
    Initialize the MSR to the "normal" by default during kernel boot.
    
    x86_energy_perf_policy(8) is available to change the default after boot,
    should the user have a different preference.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Link: http://lkml.kernel.org/r/alpine.LFD.2.02.1107140051020.18606@x980
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: <stable@kernel.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 485b4f1f079b..23a9d898baad 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -259,6 +259,9 @@
 #define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
 
 #define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
+#define ENERGY_PERF_BIAS_PERFORMANCE	0
+#define ENERGY_PERF_BIAS_NORMAL		6
+#define ENERGY_PERF_BIAS_POWERSWAVE	15
 
 #define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
 

commit b87a51ae2893a5907f796eadb4beb60747a69209
Author: Nadav Har'El <nyh@il.ibm.com>
Date:   Wed May 25 23:04:25 2011 +0300

    KVM: nVMX: Implement reading and writing of VMX MSRs
    
    When the guest can use VMX instructions (when the "nested" module option is
    on), it should also be able to read and write VMX MSRs, e.g., to query about
    VMX capabilities. This patch adds this support.
    
    Signed-off-by: Nadav Har'El <nyh@il.ibm.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 485b4f1f079b..e3022ccff33b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -438,6 +438,18 @@
 #define MSR_IA32_VMX_VMCS_ENUM          0x0000048a
 #define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
 #define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
+#define MSR_IA32_VMX_TRUE_PINBASED_CTLS  0x0000048d
+#define MSR_IA32_VMX_TRUE_PROCBASED_CTLS 0x0000048e
+#define MSR_IA32_VMX_TRUE_EXIT_CTLS      0x0000048f
+#define MSR_IA32_VMX_TRUE_ENTRY_CTLS     0x00000490
+
+/* VMX_BASIC bits and bitmasks */
+#define VMX_BASIC_VMCS_SIZE_SHIFT	32
+#define VMX_BASIC_64		0x0001000000000000LLU
+#define VMX_BASIC_MEM_TYPE_SHIFT	50
+#define VMX_BASIC_MEM_TYPE_MASK	0x003c000000000000LLU
+#define VMX_BASIC_MEM_TYPE_WB	6LLU
+#define VMX_BASIC_INOUT		0x0040000000000000LLU
 
 /* AMD-V MSRs */
 

commit fbc0db76b77125e0a5131fb886cbaafa1ec5c525
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Mar 25 09:44:46 2011 +0100

    KVM: SVM: Implement infrastructure for TSC_RATE_MSR
    
    This patch enhances the kvm_amd module with functions to
    support the TSC_RATE_MSR which can be used to set a given
    tsc frequency for the guest vcpu.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 3cce71413d0b..485b4f1f079b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -118,6 +118,7 @@
    complete list. */
 
 #define MSR_AMD64_PATCH_LEVEL		0x0000008b
+#define MSR_AMD64_TSC_RATIO		0xc0000104
 #define MSR_AMD64_NB_CFG		0xc001001f
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140

commit 5bbc097d890409d8eff4e3f1d26f11a9d6b7c07e
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Apr 15 14:47:40 2011 +0200

    x86, amd: Disable GartTlbWlkErr when BIOS forgets it
    
    This patch disables GartTlbWlk errors on AMD Fam10h CPUs if
    the BIOS forgets to do is (or is just too old). Letting
    these errors enabled can cause a sync-flood on the CPU
    causing a reboot.
    
    The AMD BKDG recommends disabling GART TLB Wlk Error completely.
    
    This patch is the fix for
    
            https://bugzilla.kernel.org/show_bug.cgi?id=33012
    
    on my machine.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Link: http://lkml.kernel.org/r/20110415131152.GJ18463@8bytes.org
    Tested-by: Alexandre Demers <alexandre.f.demers@gmail.com>
    Cc: <stable@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index fd5a1f365c95..3cce71413d0b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -96,11 +96,15 @@
 #define MSR_IA32_MC0_ADDR		0x00000402
 #define MSR_IA32_MC0_MISC		0x00000403
 
+#define MSR_AMD64_MC0_MASK		0xc0010044
+
 #define MSR_IA32_MCx_CTL(x)		(MSR_IA32_MC0_CTL + 4*(x))
 #define MSR_IA32_MCx_STATUS(x)		(MSR_IA32_MC0_STATUS + 4*(x))
 #define MSR_IA32_MCx_ADDR(x)		(MSR_IA32_MC0_ADDR + 4*(x))
 #define MSR_IA32_MCx_MISC(x)		(MSR_IA32_MC0_MISC + 4*(x))
 
+#define MSR_AMD64_MCx_MASK(x)		(MSR_AMD64_MC0_MASK + (x))
+
 /* These are consecutive and not in the normal 4er MCE bank block */
 #define MSR_IA32_MC0_CTL2		0x00000280
 #define MSR_IA32_MCx_CTL2(x)		(MSR_IA32_MC0_CTL2 + (x))

commit 91c9c3eda4f3066980d13a6907ef84f3a99364bd
Author: john cooper <john.cooper@redhat.com>
Date:   Fri Jan 21 00:21:00 2011 -0500

    KVM: x86: handle guest access to BBL_CR_CTL3 MSR
    
    A correction to Intel cpu model CPUID data (patch queued)
    caused winxp to BSOD when booted with a Penryn model.
    This was traced to the CPUID "model" field correction from
    6 -> 23 (as is proper for a Penryn class of cpu).  Only in
    this case does the problem surface.
    
    The cause for this failure is winxp accessing the BBL_CR_CTL3
    MSR which is unsupported by current kvm, appears to be a
    legacy MSR not fully characterized yet existing in current
    silicon, and is apparently carried forward in MSR space to
    accommodate vintage code as here.  It is not yet conclusive
    whether this MSR implements any of its legacy functionality
    or is just an ornamental dud for compatibility.  While I
    found no silicon version specific documentation link to
    this MSR, a general description exists in Intel's developer's
    reference which agrees with the functional behavior of
    other bootloader/kernel code I've examined accessing
    BBL_CR_CTL3.  Regrettably winxp appears to be setting bit #19
    called out as "reserved" in the above document.
    
    So to minimally accommodate this MSR, kvm msr get will provide
    the equivalent mock data and kvm msr write will simply toss the
    guest passed data without interpretation.  While this treatment
    of BBL_CR_CTL3 addresses the immediate problem, the approach may
    be modified pending clarification from Intel.
    
    Signed-off-by: john cooper <john.cooper@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 823d48223400..fd5a1f365c95 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -43,6 +43,7 @@
 
 #define MSR_MTRRcap			0x000000fe
 #define MSR_IA32_BBL_CR_CTL		0x00000119
+#define MSR_IA32_BBL_CR_CTL3		0x0000011e
 
 #define MSR_IA32_SYSENTER_CS		0x00000174
 #define MSR_IA32_SYSENTER_ESP		0x00000175

commit 86cb2ec7b22a0a89b8660110dc03321fadbef45f
Merge: 7f0030b21157 a5abba989dec
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Mar 8 17:21:49 2011 +0100

    Merge commit 'v2.6.38-rc8' into perf/core
    
    Merge reason: Merge latest fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit a7e3ed1e470116c9d12c2f778431a481a6be8ab6
Author: Andi Kleen <ak@linux.intel.com>
Date:   Thu Mar 3 10:34:47 2011 +0800

    perf: Add support for supplementary event registers
    
    Change logs against Andi's original version:
    
    - Extends perf_event_attr:config to config{,1,2} (Peter Zijlstra)
    - Fixed a major event scheduling issue. There cannot be a ref++ on an
      event that has already done ref++ once and without calling
      put_constraint() in between. (Stephane Eranian)
    - Use thread_cpumask for percore allocation. (Lin Ming)
    - Use MSR names in the extra reg lists. (Lin Ming)
    - Remove redundant "c = NULL" in intel_percore_constraints
    - Fix comment of perf_event_attr::config1
    
    Intel Nehalem/Westmere have a special OFFCORE_RESPONSE event
    that can be used to monitor any offcore accesses from a core.
    This is a very useful event for various tunings, and it's
    also needed to implement the generic LLC-* events correctly.
    
    Unfortunately this event requires programming a mask in a separate
    register. And worse this separate register is per core, not per
    CPU thread.
    
    This patch:
    
    - Teaches perf_events that OFFCORE_RESPONSE needs extra parameters.
      The extra parameters are passed by user space in the
      perf_event_attr::config1 field.
    
    - Adds support to the Intel perf_event core to schedule per
      core resources. This adds fairly generic infrastructure that
      can be also used for other per core resources.
      The basic code has is patterned after the similar AMD northbridge
      constraints code.
    
    Thanks to Stephane Eranian who pointed out some problems
    in the original version and suggested improvements.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1299119690-13991-2-git-send-email-ming.m.lin@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 4d0dfa0d998e..d25e74cc1a50 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -47,6 +47,9 @@
 #define MSR_IA32_MCG_STATUS		0x0000017a
 #define MSR_IA32_MCG_CTL		0x0000017b
 
+#define MSR_OFFCORE_RSP_0		0x000001a6
+#define MSR_OFFCORE_RSP_1		0x000001a7
+
 #define MSR_IA32_PEBS_ENABLE		0x000003f1
 #define MSR_IA32_DS_AREA		0x00000600
 #define MSR_IA32_PERF_CAPABILITIES	0x00000345

commit bfb53ccf1c734b1907df7189eef4c08489827951
Author: Len Brown <len.brown@intel.com>
Date:   Wed Feb 16 01:32:48 2011 -0500

    intel_idle: disable Atom/Lincroft HW C-state auto-demotion
    
    Just as we had to disable auto-demotion for NHM/WSM,
    we need to do the same for Atom (Lincroft version).
    
    In particular, auto-demotion will prevent Lincroft
    from entering the S0i3 idle power saving state.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=25252
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b75eeab2b1ea..43a18c77676d 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -39,6 +39,7 @@
 #define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
 #define NHM_C3_AUTO_DEMOTE		(1UL << 25)
 #define NHM_C1_AUTO_DEMOTE		(1UL << 26)
+#define ATM_LNC_C6_AUTO_DEMOTE		(1UL << 25)
 
 #define MSR_MTRRcap			0x000000fe
 #define MSR_IA32_BBL_CR_CTL		0x00000119

commit 14796fca2bd22acc73dd0887248d003b0f441d08
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jan 18 20:48:27 2011 -0500

    intel_idle: disable NHM/WSM HW C-state auto-demotion
    
    Hardware C-state auto-demotion is a mechanism where the HW overrides
    the OS C-state request, instead demoting to a shallower state,
    which is less expensive, but saves less power.
    
    Modern Linux should generally get exactly the states it requests.
    In particular, when a CPU is taken off-line, it must not be demoted, else
    it can prevent the entire package from reaching deep C-states.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=25252
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 4d0dfa0d998e..b75eeab2b1ea 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -36,6 +36,10 @@
 #define MSR_IA32_PERFCTR1		0x000000c2
 #define MSR_FSB_FREQ			0x000000cd
 
+#define MSR_NHM_SNB_PKG_CST_CFG_CTL	0x000000e2
+#define NHM_C3_AUTO_DEMOTE		(1UL << 25)
+#define NHM_C1_AUTO_DEMOTE		(1UL << 26)
+
 #define MSR_MTRRcap			0x000000fe
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 

commit 47935a731b7b850a4c6c0e55ed0741e3dd25d889
Merge: 77a0dd54ba3c 3fb82d56ad00 fd35fbcdd1b2 9e76a97efd31 c8217b8305e5 3cf9b85b474e f6cd24777513
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 6 11:11:50 2011 -0800

    Merge branches 'x86-alternatives-for-linus', 'x86-fpu-for-linus', 'x86-hwmon-for-linus', 'x86-paravirt-for-linus', 'core-locking-for-linus' and 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-alternatives-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, suspend: Avoid unnecessary smp alternatives switch during suspend/resume
    
    * 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86-64, asm: Use fxsaveq/fxrestorq in more places
    
    * 'x86-hwmon-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, hwmon: Add core threshold notification to therm_throt.c
    
    * 'x86-paravirt-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, paravirt: Use native_halt on a halt, not native_safe_halt
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      locking, lockdep: Convert sprintf_symbol to %pS
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      irq: Better struct irqaction layout

commit 9e76a97efd31a08cb19d0ba12013b8fb4ad3e474
Author: R, Durgadoss <durgadoss.r@intel.com>
Date:   Mon Jan 3 17:22:04 2011 +0530

    x86, hwmon: Add core threshold notification to therm_throt.c
    
    This patch adds code to therm_throt.c to notify core thermal threshold
    events. These thresholds are supported by the IA32_THERM_INTERRUPT register.
    The status/log for the same is monitored using the IA32_THERM_STATUS register.
    The necessary #defines are in msr-index.h. A call back is added to mce.h, to
    further notify the thermal stack, about the threshold events.
    
    Signed-off-by: Durgadoss R <durgadoss.r@intel.com>
    LKML-Reference: <D6D887BA8C9DFF48B5233887EF04654105C1251710@bgsmsx502.gar.corp.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6b89f5e86021..622c80b7dbee 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -253,6 +253,18 @@
 #define PACKAGE_THERM_INT_LOW_ENABLE		(1 << 1)
 #define PACKAGE_THERM_INT_PLN_ENABLE		(1 << 24)
 
+/* Thermal Thresholds Support */
+#define THERM_INT_THRESHOLD0_ENABLE    (1 << 15)
+#define THERM_SHIFT_THRESHOLD0        8
+#define THERM_MASK_THRESHOLD0          (0x7f << THERM_SHIFT_THRESHOLD0)
+#define THERM_INT_THRESHOLD1_ENABLE    (1 << 23)
+#define THERM_SHIFT_THRESHOLD1        16
+#define THERM_MASK_THRESHOLD1          (0x7f << THERM_SHIFT_THRESHOLD1)
+#define THERM_STATUS_THRESHOLD0        (1 << 6)
+#define THERM_LOG_THRESHOLD0           (1 << 7)
+#define THERM_STATUS_THRESHOLD1        (1 << 8)
+#define THERM_LOG_THRESHOLD1           (1 << 9)
+
 /* MISC_ENABLE bits: architectural */
 #define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
 #define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)

commit da169f5df2764a6a937cb3b07562e269edfb1c0e
Author: Robert Richter <robert.richter@amd.com>
Date:   Fri Sep 24 15:54:43 2010 +0200

    oprofile, x86: Add support for 6 counters (AMD family 15h)
    
    This patch adds support for up to 6 hardware counters for AMD family
    15h cpus. There is a new MSR range for hardware counters beginning at
    MSRC001_0200 Performance Event Select (PERF_CTL0).
    
    Signed-off-by: Robert Richter <robert.richter@amd.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6b89f5e86021..86030f63ba02 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -123,6 +123,10 @@
 #define MSR_AMD64_IBSCTL		0xc001103a
 #define MSR_AMD64_IBSBRTARGET		0xc001103b
 
+/* Fam 15h MSRs */
+#define MSR_F15H_PERF_CTL		0xc0010200
+#define MSR_F15H_PERF_CTR		0xc0010201
+
 /* Fam 10h MSRs */
 #define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058
 #define FAM10H_MMIO_CONF_ENABLE		(1<<0)

commit 37db6c8f1d0c4b8f01dc049f3a893b725288660f
Author: Jan Beulich <JBeulich@novell.com>
Date:   Tue Nov 16 08:25:08 2010 +0000

    x86-64: Fix and clean up AMD Fam10 MMCONF enabling
    
    Candidate memory ranges were not calculated properly (start
    addresses got needlessly rounded down, and end addresses didn't
    get rounded up at all), address comparison for secondary CPUs
    was done on only part of the address, and disabled status wasn't
    tracked properly.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Andreas Herrmann <andreas.herrmann3@amd.com>
    LKML-Reference: <4CE24DF40200007800022737@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 3ea3dc487047..6b89f5e86021 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -128,7 +128,7 @@
 #define FAM10H_MMIO_CONF_ENABLE		(1<<0)
 #define FAM10H_MMIO_CONF_BUSRANGE_MASK	0xf
 #define FAM10H_MMIO_CONF_BUSRANGE_SHIFT 2
-#define FAM10H_MMIO_CONF_BASE_MASK	0xfffffff
+#define FAM10H_MMIO_CONF_BASE_MASK	0xfffffffULL
 #define FAM10H_MMIO_CONF_BASE_SHIFT	20
 #define MSR_FAM10H_NODE_ID		0xc001100c
 

commit a042e26137d7674ac04b1cd2d5c06b9ebc1ee2d5
Merge: f66dd539feb8 e25804a0327d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 27 18:48:00 2010 -0700

    Merge branch 'perf-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'perf-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (50 commits)
      perf python scripting: Add futex-contention script
      perf python scripting: Fixup cut'n'paste error in sctop script
      perf scripting: Shut up 'perf record' final status
      perf record: Remove newline character from perror() argument
      perf python scripting: Support fedora 11 (audit 1.7.17)
      perf python scripting: Improve the syscalls-by-pid script
      perf python scripting: print the syscall name on sctop
      perf python scripting: Improve the syscalls-counts script
      perf python scripting: Improve the failed-syscalls-by-pid script
      kprobes: Remove redundant text_mutex lock in optimize
      x86/oprofile: Fix uninitialized variable use in debug printk
      tracing: Fix 'faild' -> 'failed' typo
      perf probe: Fix format specified for Dwarf_Off parameter
      perf trace: Fix detection of script extension
      perf trace: Use $PERF_EXEC_PATH in canned report scripts
      perf tools: Document event modifiers
      perf tools: Remove direct slang.h include
      perf_events: Fix for transaction recovery in group_sched_in()
      perf_events: Revert: Fix transaction recovery in group_sched_in()
      perf, x86: Use NUMA aware allocations for PEBS/BTS/DS allocations
      ...

commit b9a52c4b78ec254ee00cce47d75efd89b09f13dd
Author: Jes Sorensen <Jes.Sorensen@redhat.com>
Date:   Thu Sep 9 12:06:45 2010 +0200

    x86: Define MSR_EBC_FREQUENCY_ID
    
    Signed-off-by: Jes Sorensen <Jes.Sorensen@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 986f7790fdb2..83c4bb1d917d 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -198,6 +198,7 @@
 #define MSR_IA32_TSC			0x00000010
 #define MSR_IA32_PLATFORM_ID		0x00000017
 #define MSR_IA32_EBL_CR_POWERON		0x0000002a
+#define MSR_EBC_FREQUENCY_ID		0x0000002c
 #define MSR_IA32_FEATURE_CONTROL        0x0000003a
 
 #define FEATURE_CONTROL_LOCKED				(1<<0)

commit 25da6950475becb35d7a3bb3b5fbdc715a76887e
Author: Robert Richter <robert.richter@amd.com>
Date:   Tue Sep 21 15:49:31 2010 +0200

    oprofile, x86: Add support for IBS branch target address reporting
    
    This patch adds support for IBS branch target address reporting. A new
    MSR (MSRC001_103B IBS Branch Target Address) has been added that
    provides the logical address in canonical form for the branch
    target. The size of the IBS sample that is transferred to the userland
    has been increased.
    
    For backward compatibility, the userland daemon must explicit enable
    the feature by writing to the oprofilefs file
    
     ibs_op/branch_target
    
    After enabling branch target address reporting, the userland daemon
    must handle the extended size of the IBS sample.
    
    Signed-off-by: Robert Richter <robert.richter@amd.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 986f7790fdb2..91ba8e6b630a 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -121,6 +121,7 @@
 #define MSR_AMD64_IBSDCLINAD		0xc0011038
 #define MSR_AMD64_IBSDCPHYSAD		0xc0011039
 #define MSR_AMD64_IBSCTL		0xc001103a
+#define MSR_AMD64_IBSBRTARGET		0xc001103b
 
 /* Fam 10h MSRs */
 #define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058

commit e8779776afbd5f2d5315cf48c4257ca7e9b250fb
Merge: 3cf8ad3394b8 a2d7b0d48525
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 6 16:24:51 2010 -0700

    Merge branch 'x86-mce-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-mce-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, mce: Use HW_ERR in MCE handler
      x86, mce: Add HW_ERR printk prefix for hardware error logging
      x86, mce: Fix MSR_IA32_MCI_CTL2 CMCI threshold setup
      x86, mce: Rename MSR_IA32_MCx_CTL2 value

commit d9a73c00161f3eaa4c8c035c62f45afd1549e38a
Merge: b304441c6f3a bf676945cb5b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 6 10:07:34 2010 -0700

    Merge branch 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      um, x86: Cast to (u64 *) inside set_64bit()
      x86-32, asm: Directly access per-cpu GDT
      x86-64, asm: Directly access per-cpu IST
      x86, asm: Merge cmpxchg_486_u64() and cmpxchg8b_emu()
      x86, asm: Move cmpxchg emulation code to arch/x86/lib
      x86, asm: Clean up and simplify <asm/cmpxchg.h>
      x86, asm: Clean up and simplify set_64bit()
      x86: Add memory modify constraints to xchg() and cmpxchg()
      x86-64: Simplify loading initial_gs
      x86: Use symbolic MSR names
      x86: Remove redundant K6 MSRs

commit 0f477dd0851bdcee82923da66a7fc4a44cb1bc3d
Merge: c4efd6b569b2 e8c534ec068a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 6 10:02:36 2010 -0700

    Merge branch 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-cpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: Fix keeping track of AMD C1E
      x86, cpu: Package Level Thermal Control, Power Limit Notification definitions
      x86, cpu: Export AMD errata definitions
      x86, cpu: Use AMD errata checking framework for erratum 383
      x86, cpu: Clean up AMD erratum 400 workaround
      x86, cpu: AMD errata checking framework
      x86, cpu: Split addon_cpuid_features.c
      x86, cpu: Clean up formatting in cpufeature.h, remove override
      x86, cpu: Enumerate xsaveopt
      x86, cpu: Add xsaveopt cpufeature
      x86, cpu: Make init_scattered_cpuid_features() consider cpuid subleaves
      x86, cpu: Support the features flags in new CPUID leaf 7
      x86, cpu: Add CPU flags for F16C and RDRND
      x86: Look for IA32_ENERGY_PERF_BIAS support
      x86, AMD: Extend support to future families
      x86, cacheinfo: Carve out L3 cache slot accessors
      x86, xsave: Cleanup return codes in check_for_xstate()

commit eec4b140c924b4c650e9a89e01d223266490e325
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Wed May 5 16:04:44 2010 +0200

    KVM: SVM: Allow EFER.LMSLE to be set with nested svm
    
    This patch enables setting of efer bit 13 which is allowed
    in all SVM capable processors. This is necessary for the
    SLES11 version of Xen 4.0 to boot with nested svm.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 8c7ae4318629..509a42187dc2 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -20,6 +20,7 @@
 #define _EFER_LMA		10 /* Long mode active (read-only) */
 #define _EFER_NX		11 /* No execute enable */
 #define _EFER_SVME		12 /* Enable virtualization */
+#define _EFER_LMSLE		13 /* Long Mode Segment Limit Enable */
 #define _EFER_FFXSR		14 /* Enable Fast FXSAVE/FXRSTOR */
 
 #define EFER_SCE		(1<<_EFER_SCE)
@@ -27,6 +28,7 @@
 #define EFER_LMA		(1<<_EFER_LMA)
 #define EFER_NX			(1<<_EFER_NX)
 #define EFER_SVME		(1<<_EFER_SVME)
+#define EFER_LMSLE		(1<<_EFER_LMSLE)
 #define EFER_FFXSR		(1<<_EFER_FFXSR)
 
 /* Intel MSRs. Some also available on other CPUs */

commit 9792db6174d9927700ed288e6d74b9391bf785d1
Author: Fenghua Yu <fenghua.yu@intel.com>
Date:   Thu Jul 29 17:13:42 2010 -0700

    x86, cpu: Package Level Thermal Control, Power Limit Notification definitions
    
    Add package level thermal and power limit feature support.
    
    The two MSRs and features are new starting with Intel's Sandy Bridge processor.
    
    Please check Intel 64 and IA-32 Architectures SDMV Vol 3A 14.5.6 Power Limit
    Notification and 14.6 Package Level Thermal Management.
    
    This patch also fixes a bug which defines reverse THERM_INT_LOW_ENABLE bit and
    THERM_INT_HIGH_ENABLE bit.
    
    [ hpa: fixed up against current tip:x86/cpu ]
    
    Signed-off-by: Fenghua Yu <fenghua.yu@intel.com>
    LKML-Reference: <1280448826-12004-2-git-send-email-fenghua.yu@intel.com>
    Reviewed-by: Len Brown <len.brown@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 7cc4a026331c..4ea2a7ca7a4b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -224,12 +224,14 @@
 #define MSR_IA32_THERM_CONTROL		0x0000019a
 #define MSR_IA32_THERM_INTERRUPT	0x0000019b
 
-#define THERM_INT_LOW_ENABLE		(1 << 0)
-#define THERM_INT_HIGH_ENABLE		(1 << 1)
+#define THERM_INT_HIGH_ENABLE		(1 << 0)
+#define THERM_INT_LOW_ENABLE		(1 << 1)
+#define THERM_INT_PLN_ENABLE		(1 << 24)
 
 #define MSR_IA32_THERM_STATUS		0x0000019c
 
 #define THERM_STATUS_PROCHOT		(1 << 0)
+#define THERM_STATUS_POWER_LIMIT	(1 << 10)
 
 #define MSR_THERM2_CTL			0x0000019d
 
@@ -241,6 +243,17 @@
 
 #define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
 
+#define MSR_IA32_PACKAGE_THERM_STATUS		0x000001b1
+
+#define PACKAGE_THERM_STATUS_PROCHOT		(1 << 0)
+#define PACKAGE_THERM_STATUS_POWER_LIMIT	(1 << 10)
+
+#define MSR_IA32_PACKAGE_THERM_INTERRUPT	0x000001b2
+
+#define PACKAGE_THERM_INT_HIGH_ENABLE		(1 << 0)
+#define PACKAGE_THERM_INT_LOW_ENABLE		(1 << 1)
+#define PACKAGE_THERM_INT_PLN_ENABLE		(1 << 24)
+
 /* MISC_ENABLE bits: architectural */
 #define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
 #define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)

commit 7d50d07da23995a18ac449636cb42aec2cb2808d
Merge: 2decb194e65a 6aa033d7efb8
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Jul 28 13:11:28 2010 -0700

    Merge remote branch 'linus/master' into x86/cpu

commit 8c06585d6431addadd94903843dfbcd315b42d4e
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sat Jul 17 09:03:26 2010 -0400

    x86: Remove redundant K6 MSRs
    
    MSR_K6_EFER is unused, and MSR_K6_STAR is redundant with MSR_STAR.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    LKML-Reference: <1279371808-24804-1-git-send-email-brgerst@gmail.com>
    Reviewed-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 8c7ae4318629..6068e0e06e00 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -159,8 +159,6 @@
 #define MSR_K7_FID_VID_STATUS		0xc0010042
 
 /* K6 MSRs */
-#define MSR_K6_EFER			0xc0000080
-#define MSR_K6_STAR			0xc0000081
 #define MSR_K6_WHCR			0xc0000082
 #define MSR_K6_UWCCR			0xc0000085
 #define MSR_K6_EPMR			0xc0000086

commit 23016bf0d25d62c45d8b8f61d55b290d704f7a79
Author: Venkatesh Pallipadi <venki@google.com>
Date:   Thu Jun 3 23:22:28 2010 -0400

    x86: Look for IA32_ENERGY_PERF_BIAS support
    
    The new IA32_ENERGY_PERF_BIAS MSR allows system software to give
    hardware a hint whether OS policy favors more power saving,
    or more performance.  This allows the OS to have some influence
    on internal hardware power/performance tradeoffs where the OS
    has previously had no influence.
    
    The support for this feature is indicated by CPUID.06H.ECX.bit3,
    as documented in the Intel Architectures Software Developer's Manual.
    
    This patch discovers support of this feature and displays it
    as "epb" in /proc/cpuinfo.
    
    Signed-off-by: Venkatesh Pallipadi <venki@google.com>
    LKML-Reference: <alpine.LFD.2.00.1006032310160.6669@localhost.localdomain>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b49d8ca228f6..e57bc20683d6 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -238,6 +238,8 @@
 
 #define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
 
+#define MSR_IA32_ENERGY_PERF_BIAS	0x000001b0
+
 /* MISC_ENABLE bits: architectural */
 #define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
 #define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)

commit 1f9a0bd4989fd16842ad71fc89240b48ab191446
Author: Huang Ying <ying.huang@intel.com>
Date:   Tue Jun 8 14:09:08 2010 +0800

    x86, mce: Rename MSR_IA32_MCx_CTL2 value
    
    Rename CMCI_EN to MCI_CTL2_CMCI_EN and CMCI_THRESHOLD_MASK to
    MCI_CTL2_CMCI_THRESHOLD_MASK to make naming consistent.
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    LKML-Reference: <1275977348.3444.659.camel@yhuang-dev.sh.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b49d8ca228f6..38f66eb58541 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -94,9 +94,6 @@
 #define MSR_IA32_MC0_CTL2		0x00000280
 #define MSR_IA32_MCx_CTL2(x)		(MSR_IA32_MC0_CTL2 + (x))
 
-#define CMCI_EN			(1ULL << 30)
-#define CMCI_THRESHOLD_MASK		0xffffULL
-
 #define MSR_P6_PERFCTR0			0x000000c1
 #define MSR_P6_PERFCTR1			0x000000c2
 #define MSR_P6_EVNTSEL0			0x00000186

commit 67ec66077799f2fef84b21a643912b179c422281
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon May 17 14:43:35 2010 +0200

    KVM: SVM: Implement workaround for Erratum 383
    
    This patch implements a workaround for AMD erratum 383 into
    KVM. Without this erratum fix it is possible for a guest to
    kill the host machine. This patch implements the suggested
    workaround for hypervisors which will be published by the
    next revision guide update.
    
    [jan: fix overflow warning on i386]
    [xiao: fix unused variable warning]
    
    Cc: stable@kernel.org
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Jan Kiszka <jan.kiszka@siemens.com>
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b49d8ca228f6..8c7ae4318629 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -110,6 +110,7 @@
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
 #define MSR_AMD64_OSVW_STATUS		0xc0010141
+#define MSR_AMD64_DC_CFG		0xc0011022
 #define MSR_AMD64_IBSFETCHCTL		0xc0011030
 #define MSR_AMD64_IBSFETCHLINAD		0xc0011031
 #define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032

commit a321cedb12904114e2ba5041a3673ca24deb09c9
Author: Carsten Emde <C.Emde@osadl.org>
Date:   Mon May 24 14:33:41 2010 -0700

    drivers/hwmon/coretemp.c: get TjMax value from MSR
    
    The MSR IA32_TEMPERATURE_TARGET contains the TjMax value in the newer
    Intel processors.
    
    Signed-off-by: Huaxu Wan <huaxu.wan@linux.intel.com>
    Signed-off-by: Carsten Emde <C.Emde@osadl.org>
    Cc: Jean Delvare <khali@linux-fr.org>
    Cc: Valdis Kletnieks <valdis.kletnieks@vt.edu>
    Cc: Henrique de Moraes Holschuh <hmh@hmh.eng.br>
    Cc: Yong Wang <yong.y.wang@linux.intel.com>
    Cc: Rudolf Marek <r.marek@assembler.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index f9324851eba0..b49d8ca228f6 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -236,6 +236,8 @@
 
 #define MSR_IA32_MISC_ENABLE		0x000001a0
 
+#define MSR_IA32_TEMPERATURE_TARGET	0x000001a2
+
 /* MISC_ENABLE bits: architectural */
 #define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
 #define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)

commit cafd66595d92591e4bd25c3904e004fc6f897e2d
Author: Shane Wang <shane.wang@intel.com>
Date:   Thu Apr 29 12:09:01 2010 -0400

    KVM: VMX: enable VMXON check with SMX enabled (Intel TXT)
    
    Per document, for feature control MSR:
    
      Bit 1 enables VMXON in SMX operation. If the bit is clear, execution
            of VMXON in SMX operation causes a general-protection exception.
      Bit 2 enables VMXON outside SMX operation. If the bit is clear, execution
            of VMXON outside SMX operation causes a general-protection exception.
    
    This patch is to enable this kind of check with SMX for VMXON in KVM.
    
    Signed-off-by: Shane Wang <shane.wang@intel.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index bc473acfa7f9..f9324851eba0 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -202,8 +202,9 @@
 #define MSR_IA32_EBL_CR_POWERON		0x0000002a
 #define MSR_IA32_FEATURE_CONTROL        0x0000003a
 
-#define FEATURE_CONTROL_LOCKED		(1<<0)
-#define FEATURE_CONTROL_VMXON_ENABLED	(1<<2)
+#define FEATURE_CONTROL_LOCKED				(1<<0)
+#define FEATURE_CONTROL_VMXON_ENABLED_INSIDE_SMX	(1<<1)
+#define FEATURE_CONTROL_VMXON_ENABLED_OUTSIDE_SMX	(1<<2)
 
 #define MSR_IA32_APICBASE		0x0000001b
 #define MSR_IA32_APICBASE_BSP		(1<<8)

commit ec5e61aabeac58670691bd0613388d16697d0d81
Merge: 75ec5a245c77 8bb39f9aa068
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Apr 2 19:37:50 2010 +0200

    Merge branch 'perf/urgent' into perf/core
    
    Conflicts:
            arch/x86/kernel/cpu/perf_event.c
    
    Merge reason: Resolve the conflict, pick up fixes
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7c5ecaf7666617889f337296c610815b519abfa9
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Mar 25 14:51:49 2010 +0100

    perf, x86: Clean up debugctlmsr bit definitions
    
    Move all debugctlmsr thingies into msr-index.h
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <20100325135413.861425293@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index aef562c0a647..06e4cf0d3846 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -71,11 +71,14 @@
 #define MSR_IA32_LASTINTTOIP		0x000001de
 
 /* DEBUGCTLMSR bits (others vary by model): */
-#define _DEBUGCTLMSR_LBR	0 /* last branch recording */
-#define _DEBUGCTLMSR_BTF	1 /* single-step on branches */
-
-#define DEBUGCTLMSR_LBR		(1UL << _DEBUGCTLMSR_LBR)
-#define DEBUGCTLMSR_BTF		(1UL << _DEBUGCTLMSR_BTF)
+#define DEBUGCTLMSR_LBR			(1UL <<  0) /* last branch recording */
+#define DEBUGCTLMSR_BTF			(1UL <<  1) /* single-step on branches */
+#define DEBUGCTLMSR_TR			(1UL <<  6)
+#define DEBUGCTLMSR_BTS			(1UL <<  7)
+#define DEBUGCTLMSR_BTINT		(1UL <<  8)
+#define DEBUGCTLMSR_BTS_OFF_OS		(1UL <<  9)
+#define DEBUGCTLMSR_BTS_OFF_USR		(1UL << 10)
+#define DEBUGCTLMSR_FREEZE_LBRS_ON_PMI	(1UL << 11)
 
 #define MSR_IA32_MC0_CTL		0x00000400
 #define MSR_IA32_MC0_STATUS		0x00000401

commit 035a02c1e1de31888e8b6adac0ff667971ac04db
Author: Andreas Herrmann <andreas.herrmann3@amd.com>
Date:   Fri Mar 19 12:09:22 2010 +0100

    x86, amd: Restrict usage of c1e_idle()
    
    Currently c1e_idle returns true for all CPUs greater than or equal to
    family 0xf model 0x40. This covers too many CPUs.
    
    Meanwhile a respective erratum for the underlying problem was filed
    (#400). This patch adds the logic to check whether erratum #400
    applies to a given CPU.
    Especially for CPUs where SMI/HW triggered C1e is not supported,
    c1e_idle() doesn't need to be used. We can check this by looking at
    the respective OSVW bit for erratum #400.
    
    Cc: <stable@kernel.org> # .32.x .33.x
    Signed-off-by: Andreas Herrmann <andreas.herrmann3@amd.com>
    LKML-Reference: <20100319110922.GA19614@alberich.amd.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1cd58cdbc03f..4604e6a54d36 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -105,6 +105,8 @@
 #define MSR_AMD64_PATCH_LEVEL		0x0000008b
 #define MSR_AMD64_NB_CFG		0xc001001f
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
+#define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
+#define MSR_AMD64_OSVW_STATUS		0xc0010141
 #define MSR_AMD64_IBSFETCHCTL		0xc0011030
 #define MSR_AMD64_IBSFETCHLINAD		0xc0011031
 #define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032

commit cb7d6b5053e86598735d9af19930f5929f007b7f
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Thu Mar 18 18:33:12 2010 +0800

    perf, x86: Add cache events for the Pentium-4 PMU
    
    Move the HT bit setting code from p4_pmu_event_map to
    p4_hw_config. So the cache events can get HT bit set correctly.
    
    Tested on my P4 desktop, below 6 cache events work:
    
     L1-dcache-load-misses
     LLC-load-misses
     dTLB-load-misses
     dTLB-store-misses
     iTLB-loads
     iTLB-load-misses
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Reviewed-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <1268908392.13901.128.camel@minggr.sh.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1cd58cdbc03f..aef562c0a647 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -357,6 +357,8 @@
 #define MSR_P4_U2L_ESCR0		0x000003b0
 #define MSR_P4_U2L_ESCR1		0x000003b1
 
+#define MSR_P4_PEBS_MATRIX_VERT		0x000003f2
+
 /* Intel Core-based CPU performance counters */
 #define MSR_CORE_PERF_FIXED_CTR0	0x00000309
 #define MSR_CORE_PERF_FIXED_CTR1	0x0000030a

commit 9d260ebc09a0ad6b5c73e17676df42c7bc75ff64
Author: Andreas Herrmann <herrmann.der.user@googlemail.com>
Date:   Wed Dec 16 15:43:55 2009 +0100

    x86, amd: Get multi-node CPU info from NodeId MSR instead of PCI config space
    
    Use NodeId MSR to get NodeId and number of nodes per processor.
    
    Signed-off-by: Andreas Herrmann <andreas.herrmann3@amd.com>
    LKML-Reference: <20091216144355.GB28798@alberich.amd.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ac98d2914ebf..1cd58cdbc03f 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -124,6 +124,7 @@
 #define FAM10H_MMIO_CONF_BUSRANGE_SHIFT 2
 #define FAM10H_MMIO_CONF_BASE_MASK	0xfffffff
 #define FAM10H_MMIO_CONF_BASE_SHIFT	20
+#define MSR_FAM10H_NODE_ID		0xc001100c
 
 /* K8 MSRs */
 #define MSR_K8_TOP_MEM1			0xc001001a

commit 5df974009fe513c664303de24725ea0f8b47f12e
Author: Sheng Yang <sheng@linux.intel.com>
Date:   Wed Dec 16 13:48:04 2009 +0800

    x86: Add IA32_TSC_AUX MSR and use it
    
    Clean up write_tsc() and write_tscp_aux() by replacing
    hardcoded values.
    
    No change in functionality.
    
    Signed-off-by: Sheng Yang <sheng@linux.intel.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    LKML-Reference: <1260942485-19156-4-git-send-email-sheng@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 4ffe09b2ad75..ac98d2914ebf 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -12,6 +12,7 @@
 #define MSR_FS_BASE		0xc0000100 /* 64bit FS base */
 #define MSR_GS_BASE		0xc0000101 /* 64bit GS base */
 #define MSR_KERNEL_GS_BASE	0xc0000102 /* SwapGS GS shadow */
+#define MSR_TSC_AUX		0xc0000103 /* Auxiliary TSC */
 
 /* EFER bits: */
 #define _EFER_SCE		0  /* SYSCALL/SYSRET */

commit df58bee21ed218cb7dfb561a590b1bd2a99531cf
Merge: dcbf77b9e86e e34e77ce348f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 17 21:07:08 2009 -0700

    Merge branch 'x86-mce-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-mce-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (21 commits)
      x86, mce: Fix compilation with !CONFIG_DEBUG_FS in mce-severity.c
      x86, mce: CE in last bank prevents panic by unknown MCE
      x86, mce: Fake panic support for MCE testing
      x86, mce: Move debugfs mce dir creating to mce.c
      x86, mce: Support specifying raise mode for software MCE injection
      x86, mce: Support specifying context for software mce injection
      x86, mce: fix reporting of Thermal Monitoring mechanism enabled
      x86, mce: remove never executed code
      x86, mce: add missing __cpuinit tags
      x86, mce: fix "mce" boot option handling for CONFIG_X86_NEW_MCE
      x86, mce: don't log boot MCEs on Pentium M (model == 13) CPUs
      x86: mce: Lower maximum number of banks to architecture limit
      x86: mce: macros to compute banks MSRs
      x86: mce: Move per bank data in a single datastructure
      x86: mce: Move code in mce.c
      x86: mce: Rename CONFIG_X86_NEW_MCE to CONFIG_X86_MCE
      x86: mce: Remove old i386 machine check code
      x86: mce: Update X86_MCE description in x86/Kconfig
      x86: mce: Make CONFIG_X86_ANCIENT_MCE dependent on CONFIG_X86_MCE
      x86, mce: use atomic_inc_return() instead of add by 1
      ...
    
    Manually fixed up trivial conflicts:
            Documentation/feature-removal-schedule.txt
            arch/x86/kernel/cpu/mcheck/mce.c

commit 0367b4330e463c45981437083991b90d25a9d78d
Author: Alexander Graf <agraf@suse.de>
Date:   Mon Jun 15 15:21:22 2009 +0200

    x86: Add definition for IGNNE MSR
    
    Hyper-V accesses MSR_IGNNE while running under KVM.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 6be7fc254b59..bd5549034a95 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -374,6 +374,7 @@
 /* AMD-V MSRs */
 
 #define MSR_VM_CR                       0xc0010114
+#define MSR_VM_IGNNE                    0xc0010115
 #define MSR_VM_HSAVE_PA                 0xc0010117
 
 #endif /* _ASM_X86_MSR_INDEX_H */

commit f3a0867b12e0cf1512c0bd0665f2339fc75ed2a8
Author: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
Date:   Wed Jul 29 00:04:59 2009 +0200

    x86, mce: fix reporting of Thermal Monitoring mechanism enabled
    
    Early Pentium M models use different method for enabling TM2
    (per paragraph 13.5.2.3 of the "Intel 64 and IA-32 Architectures
    Software Developer's Manual Volume 3A: System Programming Guide,
    Part 1").
    
    Tested on the affected Pentium M variant (model == 13).
    
    Signed-off-by: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 3d1ce094586a..cbec06deb68b 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -222,6 +222,10 @@
 
 #define THERM_STATUS_PROCHOT		(1 << 0)
 
+#define MSR_THERM2_CTL			0x0000019d
+
+#define MSR_THERM2_CTL_TM_SELECT	(1ULL << 16)
+
 #define MSR_IA32_MISC_ENABLE		0x000001a0
 
 /* MISC_ENABLE bits: architectural */

commit a2d32bcbc008aa0f9c301a7c6f3494cb23e6af54
Author: Andi Kleen <andi@firstfloor.org>
Date:   Thu Jul 9 00:31:44 2009 +0200

    x86: mce: macros to compute banks MSRs
    
    Instead of open coded calculations for bank MSRs hide the indexing of higher
    banks MCE register MSRs in new macros.
    
    No semantic changes.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1692fb5050e3..3d1ce094586a 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -81,8 +81,15 @@
 #define MSR_IA32_MC0_ADDR		0x00000402
 #define MSR_IA32_MC0_MISC		0x00000403
 
+#define MSR_IA32_MCx_CTL(x)		(MSR_IA32_MC0_CTL + 4*(x))
+#define MSR_IA32_MCx_STATUS(x)		(MSR_IA32_MC0_STATUS + 4*(x))
+#define MSR_IA32_MCx_ADDR(x)		(MSR_IA32_MC0_ADDR + 4*(x))
+#define MSR_IA32_MCx_MISC(x)		(MSR_IA32_MC0_MISC + 4*(x))
+
 /* These are consecutive and not in the normal 4er MCE bank block */
 #define MSR_IA32_MC0_CTL2		0x00000280
+#define MSR_IA32_MCx_CTL2(x)		(MSR_IA32_MC0_CTL2 + (x))
+
 #define CMCI_EN			(1ULL << 30)
 #define CMCI_THRESHOLD_MASK		0xffffULL
 

commit 44973998a111dfda09b952aa0f27cad326a97793
Author: Jaswinder Singh Rajput <jaswinder@kernel.org>
Date:   Wed Jul 1 17:49:38 2009 +0530

    x86: Remove double declaration of MSR_P6_EVNTSEL0 and MSR_P6_EVNTSEL1
    
    MSR_P6_EVNTSEL0 and MSR_P6_EVNTSEL1 is already declared in msr-index.h.
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    LKML-Reference: <1246450778.6940.8.camel@hpdv5.satnam>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 1692fb5050e3..6be7fc254b59 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -246,10 +246,6 @@
 #define MSR_IA32_MISC_ENABLE_TURBO_DISABLE	(1ULL << 38)
 #define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE	(1ULL << 39)
 
-/* Intel Model 6 */
-#define MSR_P6_EVNTSEL0			0x00000186
-#define MSR_P6_EVNTSEL1			0x00000187
-
 /* P4/Xeon+ specific */
 #define MSR_IA32_MCG_EAX		0x00000180
 #define MSR_IA32_MCG_EBX		0x00000181

commit 0d5959723e1db3fd7323c198a50c16cecf96c7a9
Merge: 62fdac5913f7 512626a04e72
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 11 23:31:52 2009 +0200

    Merge branch 'linus' into x86/mce3
    
    Conflicts:
            arch/x86/kernel/cpu/mcheck/mce_64.c
            arch/x86/kernel/irq.c
    
    Merge reason: Resolve the conflicts above.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit ba2d0f2b0c56d7174a0208f7c463271f39040728
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 8 12:31:24 2009 +0200

    x86, mce: Cleanup symbols in intel thermal codes
    
    Decode magic constants and turn them into symbols.
    
    [ Cleanup to use symbols already exists - HS ]
    
    [ Impact: cleanup ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ec41fc16c167..c86404695083 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -208,7 +208,14 @@
 
 #define MSR_IA32_THERM_CONTROL		0x0000019a
 #define MSR_IA32_THERM_INTERRUPT	0x0000019b
+
+#define THERM_INT_LOW_ENABLE		(1 << 0)
+#define THERM_INT_HIGH_ENABLE		(1 << 1)
+
 #define MSR_IA32_THERM_STATUS		0x0000019c
+
+#define THERM_STATUS_PROCHOT		(1 << 0)
+
 #define MSR_IA32_MISC_ENABLE		0x000001a0
 
 /* MISC_ENABLE bits: architectural */

commit bf8b9a63c18a1a7777571650de0c9f4fd4368ca0
Author: Jaswinder Singh Rajput <jaswinder@kernel.org>
Date:   Fri May 8 20:53:58 2009 +0530

    x86: msr-index.h remove duplicate MSR C001_0015 declaration
    
    MSRC001_0015 Hardware Configuration Register (HWCR) is already defined
    as MSR_K7_HWCR.
    
    And HWCR is available for >= K7.
    
    So MSR_K8_HWCR is not required and no-one is using it.
    
    [ Impact: cleanup, no object code change ]
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index ec41fc16c167..4d58d04fca83 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -121,7 +121,6 @@
 #define MSR_K8_TOP_MEM1			0xc001001a
 #define MSR_K8_TOP_MEM2			0xc001001d
 #define MSR_K8_SYSCFG			0xc0010010
-#define MSR_K8_HWCR			0xc0010015
 #define MSR_K8_INT_PENDING_MSG		0xc0010055
 /* C1E active bits in int pending message */
 #define K8_INTP_C1E_ACTIVE_MASK		0x18000000

commit 3fab191002b184e4390aa07c7149c6cc7b638ec7
Merge: 93394a761d78 7c730ccdc118
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Mar 28 22:27:45 2009 +0100

    Merge branch 'linus' into x86/core

commit d20626936dd6aa783760e780dae5abb127564316
Author: Alexander Graf <agraf@suse.de>
Date:   Mon Feb 2 16:23:50 2009 +0100

    x86: Add EFER descriptions for FFXSR
    
    AMD k10 includes support for the FFXSR feature, which leaves out
    XMM registers on FXSAVE/FXSAVE when the EFER_FFXSR bit is set in
    EFER.
    
    The CPUID feature bit exists already, but the EFER bit is missing
    currently, so this patch adds it to the list of known EFER bits.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    CC: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 46e9646e7a66..f4e505f286bc 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -19,12 +19,14 @@
 #define _EFER_LMA		10 /* Long mode active (read-only) */
 #define _EFER_NX		11 /* No execute enable */
 #define _EFER_SVME		12 /* Enable virtualization */
+#define _EFER_FFXSR		14 /* Enable Fast FXSAVE/FXRSTOR */
 
 #define EFER_SCE		(1<<_EFER_SCE)
 #define EFER_LME		(1<<_EFER_LME)
 #define EFER_LMA		(1<<_EFER_LMA)
 #define EFER_NX			(1<<_EFER_NX)
 #define EFER_SVME		(1<<_EFER_SVME)
+#define EFER_FFXSR		(1<<_EFER_FFXSR)
 
 /* Intel MSRs. Some also available on other CPUs */
 #define MSR_IA32_PERFCTR0		0x000000c1

commit 9962d032bbff0268f22068787831405f8468c8b4
Author: Alexander Graf <agraf@suse.de>
Date:   Tue Nov 25 20:17:02 2008 +0100

    KVM: SVM: Move EFER and MSR constants to generic x86 code
    
    MSR_EFER_SVME_MASK, MSR_VM_CR and MSR_VM_HSAVE_PA are set in KVM
    specific headers. Linux does have nice header files to collect
    EFER bits and MSR IDs, so IMHO we should put them there.
    
    While at it, I also changed the naming scheme to match that
    of the other defines.
    
    (introduced in v6)
    
    Acked-by: Joerg Roedel <joro@8bytes.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 358acc59ae04..46e9646e7a66 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -18,11 +18,13 @@
 #define _EFER_LME		8  /* Long mode enable */
 #define _EFER_LMA		10 /* Long mode active (read-only) */
 #define _EFER_NX		11 /* No execute enable */
+#define _EFER_SVME		12 /* Enable virtualization */
 
 #define EFER_SCE		(1<<_EFER_SCE)
 #define EFER_LME		(1<<_EFER_LME)
 #define EFER_LMA		(1<<_EFER_LMA)
 #define EFER_NX			(1<<_EFER_NX)
+#define EFER_SVME		(1<<_EFER_SVME)
 
 /* Intel MSRs. Some also available on other CPUs */
 #define MSR_IA32_PERFCTR0		0x000000c1
@@ -360,4 +362,9 @@
 #define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
 #define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
 
+/* AMD-V MSRs */
+
+#define MSR_VM_CR                       0xc0010114
+#define MSR_VM_HSAVE_PA                 0xc0010117
+
 #endif /* _ASM_X86_MSR_INDEX_H */

commit 03195c6b40f2b4db92545921daa7c3a19b4e4c32
Author: Andi Kleen <andi@firstfloor.org>
Date:   Thu Feb 12 13:49:35 2009 +0100

    x86, mce, cmci: define MSR names and fields for new CMCI registers
    
    Impact: New register definitions only
    
    CMCI means support for raising an interrupt on a corrected machine
    check event instead of having to poll for it. It's a new feature in
    Intel Nehalem CPUs available on some machine check banks.
    
    For details see the IA32 SDM Vol3a 14.5
    
    Define the registers for it as a preparation for further patches.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 358acc59ae04..2dbd2314139e 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -77,6 +77,11 @@
 #define MSR_IA32_MC0_ADDR		0x00000402
 #define MSR_IA32_MC0_MISC		0x00000403
 
+/* These are consecutive and not in the normal 4er MCE bank block */
+#define MSR_IA32_MC0_CTL2		0x00000280
+#define CMCI_EN			(1ULL << 30)
+#define CMCI_THRESHOLD_MASK		0xffffULL
+
 #define MSR_P6_PERFCTR0			0x000000c1
 #define MSR_P6_PERFCTR1			0x000000c2
 #define MSR_P6_EVNTSEL0			0x00000186

commit bdf21a49bab28f0d9613e8d8724ef9c9168b61b9
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Jan 21 15:01:56 2009 -0800

    x86: add MSR_IA32_MISC_ENABLE bits to <asm/msr-index.h>
    
    Impact: None (new bit definitions currently unused)
    
    Add bit definitions for the MSR_IA32_MISC_ENABLE MSRs to
    <asm/msr-index.h>.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index cb58643947b9..358acc59ae04 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -202,6 +202,35 @@
 #define MSR_IA32_THERM_STATUS		0x0000019c
 #define MSR_IA32_MISC_ENABLE		0x000001a0
 
+/* MISC_ENABLE bits: architectural */
+#define MSR_IA32_MISC_ENABLE_FAST_STRING	(1ULL << 0)
+#define MSR_IA32_MISC_ENABLE_TCC		(1ULL << 1)
+#define MSR_IA32_MISC_ENABLE_EMON		(1ULL << 7)
+#define MSR_IA32_MISC_ENABLE_BTS_UNAVAIL	(1ULL << 11)
+#define MSR_IA32_MISC_ENABLE_PEBS_UNAVAIL	(1ULL << 12)
+#define MSR_IA32_MISC_ENABLE_ENHANCED_SPEEDSTEP	(1ULL << 16)
+#define MSR_IA32_MISC_ENABLE_MWAIT		(1ULL << 18)
+#define MSR_IA32_MISC_ENABLE_LIMIT_CPUID	(1ULL << 22)
+#define MSR_IA32_MISC_ENABLE_XTPR_DISABLE	(1ULL << 23)
+#define MSR_IA32_MISC_ENABLE_XD_DISABLE		(1ULL << 34)
+
+/* MISC_ENABLE bits: model-specific, meaning may vary from core to core */
+#define MSR_IA32_MISC_ENABLE_X87_COMPAT		(1ULL << 2)
+#define MSR_IA32_MISC_ENABLE_TM1		(1ULL << 3)
+#define MSR_IA32_MISC_ENABLE_SPLIT_LOCK_DISABLE	(1ULL << 4)
+#define MSR_IA32_MISC_ENABLE_L3CACHE_DISABLE	(1ULL << 6)
+#define MSR_IA32_MISC_ENABLE_SUPPRESS_LOCK	(1ULL << 8)
+#define MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE	(1ULL << 9)
+#define MSR_IA32_MISC_ENABLE_FERR		(1ULL << 10)
+#define MSR_IA32_MISC_ENABLE_FERR_MULTIPLEX	(1ULL << 10)
+#define MSR_IA32_MISC_ENABLE_TM2		(1ULL << 13)
+#define MSR_IA32_MISC_ENABLE_ADJ_PREF_DISABLE	(1ULL << 19)
+#define MSR_IA32_MISC_ENABLE_SPEEDSTEP_LOCK	(1ULL << 20)
+#define MSR_IA32_MISC_ENABLE_L1D_CONTEXT	(1ULL << 24)
+#define MSR_IA32_MISC_ENABLE_DCU_PREF_DISABLE	(1ULL << 37)
+#define MSR_IA32_MISC_ENABLE_TURBO_DISABLE	(1ULL << 38)
+#define MSR_IA32_MISC_ENABLE_IP_PREF_DISABLE	(1ULL << 39)
+
 /* Intel Model 6 */
 #define MSR_P6_EVNTSEL0			0x00000186
 #define MSR_P6_EVNTSEL1			0x00000187

commit 29d0887ffd084cde9d6a1286cb82b71701a974dd
Author: Andreas Herrmann <andreas.herrmann3@amd.com>
Date:   Tue Dec 16 19:16:34 2008 +0100

    x86: microcode_amd: replace inline asm by common rdmsr/wrmsr functions
    
    Impact: cleanup
    
    Signed-off-by: Andreas Herrmann <andreas.herrmann3@amd.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index e38859d577a1..cb58643947b9 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -85,7 +85,9 @@
 /* AMD64 MSRs. Not complete. See the architecture manual for a more
    complete list. */
 
+#define MSR_AMD64_PATCH_LEVEL		0x0000008b
 #define MSR_AMD64_NB_CFG		0xc001001f
+#define MSR_AMD64_PATCH_LOADER		0xc0010020
 #define MSR_AMD64_IBSFETCHCTL		0xc0011030
 #define MSR_AMD64_IBSFETCHLINAD		0xc0011031
 #define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index dabd10f0bbee..e38859d577a1 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__MSR_INDEX_H
-#define ASM_X86__MSR_INDEX_H
+#ifndef _ASM_X86_MSR_INDEX_H
+#define _ASM_X86_MSR_INDEX_H
 
 /* CPU model specific register (MSR) numbers */
 
@@ -329,4 +329,4 @@
 #define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
 #define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
 
-#endif /* ASM_X86__MSR_INDEX_H */
+#endif /* _ASM_X86_MSR_INDEX_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
new file mode 100644
index 000000000000..dabd10f0bbee
--- /dev/null
+++ b/arch/x86/include/asm/msr-index.h
@@ -0,0 +1,332 @@
+#ifndef ASM_X86__MSR_INDEX_H
+#define ASM_X86__MSR_INDEX_H
+
+/* CPU model specific register (MSR) numbers */
+
+/* x86-64 specific MSRs */
+#define MSR_EFER		0xc0000080 /* extended feature register */
+#define MSR_STAR		0xc0000081 /* legacy mode SYSCALL target */
+#define MSR_LSTAR		0xc0000082 /* long mode SYSCALL target */
+#define MSR_CSTAR		0xc0000083 /* compat mode SYSCALL target */
+#define MSR_SYSCALL_MASK	0xc0000084 /* EFLAGS mask for syscall */
+#define MSR_FS_BASE		0xc0000100 /* 64bit FS base */
+#define MSR_GS_BASE		0xc0000101 /* 64bit GS base */
+#define MSR_KERNEL_GS_BASE	0xc0000102 /* SwapGS GS shadow */
+
+/* EFER bits: */
+#define _EFER_SCE		0  /* SYSCALL/SYSRET */
+#define _EFER_LME		8  /* Long mode enable */
+#define _EFER_LMA		10 /* Long mode active (read-only) */
+#define _EFER_NX		11 /* No execute enable */
+
+#define EFER_SCE		(1<<_EFER_SCE)
+#define EFER_LME		(1<<_EFER_LME)
+#define EFER_LMA		(1<<_EFER_LMA)
+#define EFER_NX			(1<<_EFER_NX)
+
+/* Intel MSRs. Some also available on other CPUs */
+#define MSR_IA32_PERFCTR0		0x000000c1
+#define MSR_IA32_PERFCTR1		0x000000c2
+#define MSR_FSB_FREQ			0x000000cd
+
+#define MSR_MTRRcap			0x000000fe
+#define MSR_IA32_BBL_CR_CTL		0x00000119
+
+#define MSR_IA32_SYSENTER_CS		0x00000174
+#define MSR_IA32_SYSENTER_ESP		0x00000175
+#define MSR_IA32_SYSENTER_EIP		0x00000176
+
+#define MSR_IA32_MCG_CAP		0x00000179
+#define MSR_IA32_MCG_STATUS		0x0000017a
+#define MSR_IA32_MCG_CTL		0x0000017b
+
+#define MSR_IA32_PEBS_ENABLE		0x000003f1
+#define MSR_IA32_DS_AREA		0x00000600
+#define MSR_IA32_PERF_CAPABILITIES	0x00000345
+
+#define MSR_MTRRfix64K_00000		0x00000250
+#define MSR_MTRRfix16K_80000		0x00000258
+#define MSR_MTRRfix16K_A0000		0x00000259
+#define MSR_MTRRfix4K_C0000		0x00000268
+#define MSR_MTRRfix4K_C8000		0x00000269
+#define MSR_MTRRfix4K_D0000		0x0000026a
+#define MSR_MTRRfix4K_D8000		0x0000026b
+#define MSR_MTRRfix4K_E0000		0x0000026c
+#define MSR_MTRRfix4K_E8000		0x0000026d
+#define MSR_MTRRfix4K_F0000		0x0000026e
+#define MSR_MTRRfix4K_F8000		0x0000026f
+#define MSR_MTRRdefType			0x000002ff
+
+#define MSR_IA32_CR_PAT			0x00000277
+
+#define MSR_IA32_DEBUGCTLMSR		0x000001d9
+#define MSR_IA32_LASTBRANCHFROMIP	0x000001db
+#define MSR_IA32_LASTBRANCHTOIP		0x000001dc
+#define MSR_IA32_LASTINTFROMIP		0x000001dd
+#define MSR_IA32_LASTINTTOIP		0x000001de
+
+/* DEBUGCTLMSR bits (others vary by model): */
+#define _DEBUGCTLMSR_LBR	0 /* last branch recording */
+#define _DEBUGCTLMSR_BTF	1 /* single-step on branches */
+
+#define DEBUGCTLMSR_LBR		(1UL << _DEBUGCTLMSR_LBR)
+#define DEBUGCTLMSR_BTF		(1UL << _DEBUGCTLMSR_BTF)
+
+#define MSR_IA32_MC0_CTL		0x00000400
+#define MSR_IA32_MC0_STATUS		0x00000401
+#define MSR_IA32_MC0_ADDR		0x00000402
+#define MSR_IA32_MC0_MISC		0x00000403
+
+#define MSR_P6_PERFCTR0			0x000000c1
+#define MSR_P6_PERFCTR1			0x000000c2
+#define MSR_P6_EVNTSEL0			0x00000186
+#define MSR_P6_EVNTSEL1			0x00000187
+
+/* AMD64 MSRs. Not complete. See the architecture manual for a more
+   complete list. */
+
+#define MSR_AMD64_NB_CFG		0xc001001f
+#define MSR_AMD64_IBSFETCHCTL		0xc0011030
+#define MSR_AMD64_IBSFETCHLINAD		0xc0011031
+#define MSR_AMD64_IBSFETCHPHYSAD	0xc0011032
+#define MSR_AMD64_IBSOPCTL		0xc0011033
+#define MSR_AMD64_IBSOPRIP		0xc0011034
+#define MSR_AMD64_IBSOPDATA		0xc0011035
+#define MSR_AMD64_IBSOPDATA2		0xc0011036
+#define MSR_AMD64_IBSOPDATA3		0xc0011037
+#define MSR_AMD64_IBSDCLINAD		0xc0011038
+#define MSR_AMD64_IBSDCPHYSAD		0xc0011039
+#define MSR_AMD64_IBSCTL		0xc001103a
+
+/* Fam 10h MSRs */
+#define MSR_FAM10H_MMIO_CONF_BASE	0xc0010058
+#define FAM10H_MMIO_CONF_ENABLE		(1<<0)
+#define FAM10H_MMIO_CONF_BUSRANGE_MASK	0xf
+#define FAM10H_MMIO_CONF_BUSRANGE_SHIFT 2
+#define FAM10H_MMIO_CONF_BASE_MASK	0xfffffff
+#define FAM10H_MMIO_CONF_BASE_SHIFT	20
+
+/* K8 MSRs */
+#define MSR_K8_TOP_MEM1			0xc001001a
+#define MSR_K8_TOP_MEM2			0xc001001d
+#define MSR_K8_SYSCFG			0xc0010010
+#define MSR_K8_HWCR			0xc0010015
+#define MSR_K8_INT_PENDING_MSG		0xc0010055
+/* C1E active bits in int pending message */
+#define K8_INTP_C1E_ACTIVE_MASK		0x18000000
+#define MSR_K8_TSEG_ADDR		0xc0010112
+#define K8_MTRRFIXRANGE_DRAM_ENABLE	0x00040000 /* MtrrFixDramEn bit    */
+#define K8_MTRRFIXRANGE_DRAM_MODIFY	0x00080000 /* MtrrFixDramModEn bit */
+#define K8_MTRR_RDMEM_WRMEM_MASK	0x18181818 /* Mask: RdMem|WrMem    */
+
+/* K7 MSRs */
+#define MSR_K7_EVNTSEL0			0xc0010000
+#define MSR_K7_PERFCTR0			0xc0010004
+#define MSR_K7_EVNTSEL1			0xc0010001
+#define MSR_K7_PERFCTR1			0xc0010005
+#define MSR_K7_EVNTSEL2			0xc0010002
+#define MSR_K7_PERFCTR2			0xc0010006
+#define MSR_K7_EVNTSEL3			0xc0010003
+#define MSR_K7_PERFCTR3			0xc0010007
+#define MSR_K7_CLK_CTL			0xc001001b
+#define MSR_K7_HWCR			0xc0010015
+#define MSR_K7_FID_VID_CTL		0xc0010041
+#define MSR_K7_FID_VID_STATUS		0xc0010042
+
+/* K6 MSRs */
+#define MSR_K6_EFER			0xc0000080
+#define MSR_K6_STAR			0xc0000081
+#define MSR_K6_WHCR			0xc0000082
+#define MSR_K6_UWCCR			0xc0000085
+#define MSR_K6_EPMR			0xc0000086
+#define MSR_K6_PSOR			0xc0000087
+#define MSR_K6_PFIR			0xc0000088
+
+/* Centaur-Hauls/IDT defined MSRs. */
+#define MSR_IDT_FCR1			0x00000107
+#define MSR_IDT_FCR2			0x00000108
+#define MSR_IDT_FCR3			0x00000109
+#define MSR_IDT_FCR4			0x0000010a
+
+#define MSR_IDT_MCR0			0x00000110
+#define MSR_IDT_MCR1			0x00000111
+#define MSR_IDT_MCR2			0x00000112
+#define MSR_IDT_MCR3			0x00000113
+#define MSR_IDT_MCR4			0x00000114
+#define MSR_IDT_MCR5			0x00000115
+#define MSR_IDT_MCR6			0x00000116
+#define MSR_IDT_MCR7			0x00000117
+#define MSR_IDT_MCR_CTRL		0x00000120
+
+/* VIA Cyrix defined MSRs*/
+#define MSR_VIA_FCR			0x00001107
+#define MSR_VIA_LONGHAUL		0x0000110a
+#define MSR_VIA_RNG			0x0000110b
+#define MSR_VIA_BCR2			0x00001147
+
+/* Transmeta defined MSRs */
+#define MSR_TMTA_LONGRUN_CTRL		0x80868010
+#define MSR_TMTA_LONGRUN_FLAGS		0x80868011
+#define MSR_TMTA_LRTI_READOUT		0x80868018
+#define MSR_TMTA_LRTI_VOLT_MHZ		0x8086801a
+
+/* Intel defined MSRs. */
+#define MSR_IA32_P5_MC_ADDR		0x00000000
+#define MSR_IA32_P5_MC_TYPE		0x00000001
+#define MSR_IA32_TSC			0x00000010
+#define MSR_IA32_PLATFORM_ID		0x00000017
+#define MSR_IA32_EBL_CR_POWERON		0x0000002a
+#define MSR_IA32_FEATURE_CONTROL        0x0000003a
+
+#define FEATURE_CONTROL_LOCKED		(1<<0)
+#define FEATURE_CONTROL_VMXON_ENABLED	(1<<2)
+
+#define MSR_IA32_APICBASE		0x0000001b
+#define MSR_IA32_APICBASE_BSP		(1<<8)
+#define MSR_IA32_APICBASE_ENABLE	(1<<11)
+#define MSR_IA32_APICBASE_BASE		(0xfffff<<12)
+
+#define MSR_IA32_UCODE_WRITE		0x00000079
+#define MSR_IA32_UCODE_REV		0x0000008b
+
+#define MSR_IA32_PERF_STATUS		0x00000198
+#define MSR_IA32_PERF_CTL		0x00000199
+
+#define MSR_IA32_MPERF			0x000000e7
+#define MSR_IA32_APERF			0x000000e8
+
+#define MSR_IA32_THERM_CONTROL		0x0000019a
+#define MSR_IA32_THERM_INTERRUPT	0x0000019b
+#define MSR_IA32_THERM_STATUS		0x0000019c
+#define MSR_IA32_MISC_ENABLE		0x000001a0
+
+/* Intel Model 6 */
+#define MSR_P6_EVNTSEL0			0x00000186
+#define MSR_P6_EVNTSEL1			0x00000187
+
+/* P4/Xeon+ specific */
+#define MSR_IA32_MCG_EAX		0x00000180
+#define MSR_IA32_MCG_EBX		0x00000181
+#define MSR_IA32_MCG_ECX		0x00000182
+#define MSR_IA32_MCG_EDX		0x00000183
+#define MSR_IA32_MCG_ESI		0x00000184
+#define MSR_IA32_MCG_EDI		0x00000185
+#define MSR_IA32_MCG_EBP		0x00000186
+#define MSR_IA32_MCG_ESP		0x00000187
+#define MSR_IA32_MCG_EFLAGS		0x00000188
+#define MSR_IA32_MCG_EIP		0x00000189
+#define MSR_IA32_MCG_RESERVED		0x0000018a
+
+/* Pentium IV performance counter MSRs */
+#define MSR_P4_BPU_PERFCTR0		0x00000300
+#define MSR_P4_BPU_PERFCTR1		0x00000301
+#define MSR_P4_BPU_PERFCTR2		0x00000302
+#define MSR_P4_BPU_PERFCTR3		0x00000303
+#define MSR_P4_MS_PERFCTR0		0x00000304
+#define MSR_P4_MS_PERFCTR1		0x00000305
+#define MSR_P4_MS_PERFCTR2		0x00000306
+#define MSR_P4_MS_PERFCTR3		0x00000307
+#define MSR_P4_FLAME_PERFCTR0		0x00000308
+#define MSR_P4_FLAME_PERFCTR1		0x00000309
+#define MSR_P4_FLAME_PERFCTR2		0x0000030a
+#define MSR_P4_FLAME_PERFCTR3		0x0000030b
+#define MSR_P4_IQ_PERFCTR0		0x0000030c
+#define MSR_P4_IQ_PERFCTR1		0x0000030d
+#define MSR_P4_IQ_PERFCTR2		0x0000030e
+#define MSR_P4_IQ_PERFCTR3		0x0000030f
+#define MSR_P4_IQ_PERFCTR4		0x00000310
+#define MSR_P4_IQ_PERFCTR5		0x00000311
+#define MSR_P4_BPU_CCCR0		0x00000360
+#define MSR_P4_BPU_CCCR1		0x00000361
+#define MSR_P4_BPU_CCCR2		0x00000362
+#define MSR_P4_BPU_CCCR3		0x00000363
+#define MSR_P4_MS_CCCR0			0x00000364
+#define MSR_P4_MS_CCCR1			0x00000365
+#define MSR_P4_MS_CCCR2			0x00000366
+#define MSR_P4_MS_CCCR3			0x00000367
+#define MSR_P4_FLAME_CCCR0		0x00000368
+#define MSR_P4_FLAME_CCCR1		0x00000369
+#define MSR_P4_FLAME_CCCR2		0x0000036a
+#define MSR_P4_FLAME_CCCR3		0x0000036b
+#define MSR_P4_IQ_CCCR0			0x0000036c
+#define MSR_P4_IQ_CCCR1			0x0000036d
+#define MSR_P4_IQ_CCCR2			0x0000036e
+#define MSR_P4_IQ_CCCR3			0x0000036f
+#define MSR_P4_IQ_CCCR4			0x00000370
+#define MSR_P4_IQ_CCCR5			0x00000371
+#define MSR_P4_ALF_ESCR0		0x000003ca
+#define MSR_P4_ALF_ESCR1		0x000003cb
+#define MSR_P4_BPU_ESCR0		0x000003b2
+#define MSR_P4_BPU_ESCR1		0x000003b3
+#define MSR_P4_BSU_ESCR0		0x000003a0
+#define MSR_P4_BSU_ESCR1		0x000003a1
+#define MSR_P4_CRU_ESCR0		0x000003b8
+#define MSR_P4_CRU_ESCR1		0x000003b9
+#define MSR_P4_CRU_ESCR2		0x000003cc
+#define MSR_P4_CRU_ESCR3		0x000003cd
+#define MSR_P4_CRU_ESCR4		0x000003e0
+#define MSR_P4_CRU_ESCR5		0x000003e1
+#define MSR_P4_DAC_ESCR0		0x000003a8
+#define MSR_P4_DAC_ESCR1		0x000003a9
+#define MSR_P4_FIRM_ESCR0		0x000003a4
+#define MSR_P4_FIRM_ESCR1		0x000003a5
+#define MSR_P4_FLAME_ESCR0		0x000003a6
+#define MSR_P4_FLAME_ESCR1		0x000003a7
+#define MSR_P4_FSB_ESCR0		0x000003a2
+#define MSR_P4_FSB_ESCR1		0x000003a3
+#define MSR_P4_IQ_ESCR0			0x000003ba
+#define MSR_P4_IQ_ESCR1			0x000003bb
+#define MSR_P4_IS_ESCR0			0x000003b4
+#define MSR_P4_IS_ESCR1			0x000003b5
+#define MSR_P4_ITLB_ESCR0		0x000003b6
+#define MSR_P4_ITLB_ESCR1		0x000003b7
+#define MSR_P4_IX_ESCR0			0x000003c8
+#define MSR_P4_IX_ESCR1			0x000003c9
+#define MSR_P4_MOB_ESCR0		0x000003aa
+#define MSR_P4_MOB_ESCR1		0x000003ab
+#define MSR_P4_MS_ESCR0			0x000003c0
+#define MSR_P4_MS_ESCR1			0x000003c1
+#define MSR_P4_PMH_ESCR0		0x000003ac
+#define MSR_P4_PMH_ESCR1		0x000003ad
+#define MSR_P4_RAT_ESCR0		0x000003bc
+#define MSR_P4_RAT_ESCR1		0x000003bd
+#define MSR_P4_SAAT_ESCR0		0x000003ae
+#define MSR_P4_SAAT_ESCR1		0x000003af
+#define MSR_P4_SSU_ESCR0		0x000003be
+#define MSR_P4_SSU_ESCR1		0x000003bf /* guess: not in manual */
+
+#define MSR_P4_TBPU_ESCR0		0x000003c2
+#define MSR_P4_TBPU_ESCR1		0x000003c3
+#define MSR_P4_TC_ESCR0			0x000003c4
+#define MSR_P4_TC_ESCR1			0x000003c5
+#define MSR_P4_U2L_ESCR0		0x000003b0
+#define MSR_P4_U2L_ESCR1		0x000003b1
+
+/* Intel Core-based CPU performance counters */
+#define MSR_CORE_PERF_FIXED_CTR0	0x00000309
+#define MSR_CORE_PERF_FIXED_CTR1	0x0000030a
+#define MSR_CORE_PERF_FIXED_CTR2	0x0000030b
+#define MSR_CORE_PERF_FIXED_CTR_CTRL	0x0000038d
+#define MSR_CORE_PERF_GLOBAL_STATUS	0x0000038e
+#define MSR_CORE_PERF_GLOBAL_CTRL	0x0000038f
+#define MSR_CORE_PERF_GLOBAL_OVF_CTRL	0x00000390
+
+/* Geode defined MSRs */
+#define MSR_GEODE_BUSCONT_CONF0		0x00001900
+
+/* Intel VT MSRs */
+#define MSR_IA32_VMX_BASIC              0x00000480
+#define MSR_IA32_VMX_PINBASED_CTLS      0x00000481
+#define MSR_IA32_VMX_PROCBASED_CTLS     0x00000482
+#define MSR_IA32_VMX_EXIT_CTLS          0x00000483
+#define MSR_IA32_VMX_ENTRY_CTLS         0x00000484
+#define MSR_IA32_VMX_MISC               0x00000485
+#define MSR_IA32_VMX_CR0_FIXED0         0x00000486
+#define MSR_IA32_VMX_CR0_FIXED1         0x00000487
+#define MSR_IA32_VMX_CR4_FIXED0         0x00000488
+#define MSR_IA32_VMX_CR4_FIXED1         0x00000489
+#define MSR_IA32_VMX_VMCS_ENUM          0x0000048a
+#define MSR_IA32_VMX_PROCBASED_CTLS2    0x0000048b
+#define MSR_IA32_VMX_EPT_VPID_CAP       0x0000048c
+
+#endif /* ASM_X86__MSR_INDEX_H */
