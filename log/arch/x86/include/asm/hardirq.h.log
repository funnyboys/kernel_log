commit ecca25029473bee6e98ce062e76b7310904bbdd1
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Apr 30 11:45:23 2019 +0800

    x86/Kconfig: Add new X86_HV_CALLBACK_VECTOR config symbol
    
    Add a special Kconfig symbol X86_HV_CALLBACK_VECTOR so that the guests
    using the hypervisor interrupt callback counter can select and thus
    enable that counter. Select it when xen or hyperv support is enabled. No
    functional changes.
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Frederic Weisbecker <frederic@kernel.org>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: linux-hyperv@vger.kernel.org
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sasha Levin <sashal@kernel.org>
    Cc: Stefano Stabellini <sstabellini@kernel.org>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Cc: xen-devel@lists.xenproject.org
    Link: https://lkml.kernel.org/r/1559108037-18813-2-git-send-email-yakui.zhao@intel.com

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index d9069bb26c7f..07533795b8d2 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -37,7 +37,7 @@ typedef struct {
 #ifdef CONFIG_X86_MCE_AMD
 	unsigned int irq_deferred_error_count;
 #endif
-#if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
+#ifdef CONFIG_X86_HV_CALLBACK_VECTOR
 	unsigned int irq_hv_callback_count;
 #endif
 #if IS_ENABLED(CONFIG_HYPERV)

commit 447ae316670230d7d29430e2cbf1f5db4f49d14c
Author: Nicolai Stange <nstange@suse.de>
Date:   Sun Jul 29 12:15:33 2018 +0200

    x86: Don't include linux/irq.h from asm/hardirq.h
    
    The next patch in this series will have to make the definition of
    irq_cpustat_t available to entering_irq().
    
    Inclusion of asm/hardirq.h into asm/apic.h would cause circular header
    dependencies like
    
      asm/smp.h
        asm/apic.h
          asm/hardirq.h
            linux/irq.h
              linux/topology.h
                linux/smp.h
                  asm/smp.h
    
    or
    
      linux/gfp.h
        linux/mmzone.h
          asm/mmzone.h
            asm/mmzone_64.h
              asm/smp.h
                asm/apic.h
                  asm/hardirq.h
                    linux/irq.h
                      linux/irqdesc.h
                        linux/kobject.h
                          linux/sysfs.h
                            linux/kernfs.h
                              linux/idr.h
                                linux/gfp.h
    
    and others.
    
    This causes compilation errors because of the header guards becoming
    effective in the second inclusion: symbols/macros that had been defined
    before wouldn't be available to intermediate headers in the #include chain
    anymore.
    
    A possible workaround would be to move the definition of irq_cpustat_t
    into its own header and include that from both, asm/hardirq.h and
    asm/apic.h.
    
    However, this wouldn't solve the real problem, namely asm/harirq.h
    unnecessarily pulling in all the linux/irq.h cruft: nothing in
    asm/hardirq.h itself requires it. Also, note that there are some other
    archs, like e.g. arm64, which don't have that #include in their
    asm/hardirq.h.
    
    Remove the linux/irq.h #include from x86' asm/hardirq.h.
    
    Fix resulting compilation errors by adding appropriate #includes to *.c
    files as needed.
    
    Note that some of these *.c files could be cleaned up a bit wrt. to their
    set of #includes, but that should better be done from separate patches, if
    at all.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 0b854ebb99df..d9069bb26c7f 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -3,7 +3,6 @@
 #define _ASM_X86_HARDIRQ_H
 
 #include <linux/threads.h>
-#include <linux/irq.h>
 
 typedef struct {
 	u16	     __softirq_pending;

commit 45b575c00d8e72d69d75dd8c112f044b7b01b069
Author: Nicolai Stange <nstange@suse.de>
Date:   Fri Jul 27 13:22:16 2018 +0200

    x86/KVM/VMX: Introduce per-host-cpu analogue of l1tf_flush_l1d
    
    Part of the L1TF mitigation for vmx includes flushing the L1D cache upon
    VMENTRY.
    
    L1D flushes are costly and two modes of operations are provided to users:
    "always" and the more selective "conditional" mode.
    
    If operating in the latter, the cache would get flushed only if a host side
    code path considered unconfined had been traversed. "Unconfined" in this
    context means that it might have pulled in sensitive data like user data
    or kernel crypto keys.
    
    The need for L1D flushes is tracked by means of the per-vcpu flag
    l1tf_flush_l1d. KVM exit handlers considered unconfined set it. A
    vmx_l1d_flush() subsequently invoked before the next VMENTER will conduct a
    L1d flush based on its value and reset that flag again.
    
    Currently, interrupts delivered "normally" while in root operation between
    VMEXIT and VMENTER are not taken into account. Part of the reason is that
    these don't leave any traces and thus, the vmx code is unable to tell if
    any such has happened.
    
    As proposed by Paolo Bonzini, prepare for tracking all interrupts by
    introducing a new per-cpu flag, "kvm_cpu_l1tf_flush_l1d". It will be in
    strong analogy to the per-vcpu ->l1tf_flush_l1d.
    
    A later patch will make interrupt handlers set it.
    
    For the sake of cache locality, group kvm_cpu_l1tf_flush_l1d into x86'
    per-cpu irq_cpustat_t as suggested by Peter Zijlstra.
    
    Provide the helpers kvm_set_cpu_l1tf_flush_l1d(),
    kvm_clear_cpu_l1tf_flush_l1d() and kvm_get_cpu_l1tf_flush_l1d(). Make them
    trivial resp. non-existent for !CONFIG_KVM_INTEL as appropriate.
    
    Let vmx_l1d_flush() handle kvm_cpu_l1tf_flush_l1d in the same way as
    l1tf_flush_l1d.
    
    Suggested-by: Paolo Bonzini <pbonzini@redhat.com>
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index e39c606de6f6..0b854ebb99df 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -7,6 +7,9 @@
 
 typedef struct {
 	u16	     __softirq_pending;
+#if IS_ENABLED(CONFIG_KVM_INTEL)
+	u8	     kvm_cpu_l1tf_flush_l1d;
+#endif
 	unsigned int __nmi_count;	/* arch dependent */
 #ifdef CONFIG_X86_LOCAL_APIC
 	unsigned int apic_timer_irqs;	/* arch dependent */
@@ -58,4 +61,24 @@ extern u64 arch_irq_stat_cpu(unsigned int cpu);
 extern u64 arch_irq_stat(void);
 #define arch_irq_stat		arch_irq_stat
 
+
+#if IS_ENABLED(CONFIG_KVM_INTEL)
+static inline void kvm_set_cpu_l1tf_flush_l1d(void)
+{
+	__this_cpu_write(irq_stat.kvm_cpu_l1tf_flush_l1d, 1);
+}
+
+static inline void kvm_clear_cpu_l1tf_flush_l1d(void)
+{
+	__this_cpu_write(irq_stat.kvm_cpu_l1tf_flush_l1d, 0);
+}
+
+static inline bool kvm_get_cpu_l1tf_flush_l1d(void)
+{
+	return __this_cpu_read(irq_stat.kvm_cpu_l1tf_flush_l1d);
+}
+#else /* !IS_ENABLED(CONFIG_KVM_INTEL) */
+static inline void kvm_set_cpu_l1tf_flush_l1d(void) { }
+#endif /* IS_ENABLED(CONFIG_KVM_INTEL) */
+
 #endif /* _ASM_X86_HARDIRQ_H */

commit 9aee5f8a7e30330d0a8f4c626dc924ca5590aba5
Author: Nicolai Stange <nstange@suse.de>
Date:   Fri Jul 27 12:46:29 2018 +0200

    x86/irq: Demote irq_cpustat_t::__softirq_pending to u16
    
    An upcoming patch will extend KVM's L1TF mitigation in conditional mode
    to also cover interrupts after VMEXITs. For tracking those, stores to a
    new per-cpu flag from interrupt handlers will become necessary.
    
    In order to improve cache locality, this new flag will be added to x86's
    irq_cpustat_t.
    
    Make some space available there by shrinking the ->softirq_pending bitfield
    from 32 to 16 bits: the number of bits actually used is only NR_SOFTIRQS,
    i.e. 10.
    
    Suggested-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 740a428acf1e..e39c606de6f6 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -6,7 +6,7 @@
 #include <linux/irq.h>
 
 typedef struct {
-	unsigned int __softirq_pending;
+	u16	     __softirq_pending;
 	unsigned int __nmi_count;	/* arch dependent */
 #ifdef CONFIG_X86_LOCAL_APIC
 	unsigned int apic_timer_irqs;	/* arch dependent */

commit 1a8bc8f8d6a7980a999975edbd29578fbce09359
Author: Frederic Weisbecker <frederic@kernel.org>
Date:   Tue May 8 15:38:25 2018 +0200

    softirq/x86: Switch to generic local_softirq_pending() implementation
    
    Remove the ad-hoc implementation, the generic code now allows us not to
    reinvent the wheel.
    
    Signed-off-by: Frederic Weisbecker <frederic@kernel.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/1525786706-22846-11-git-send-email-frederic@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 5ea2afd4c871..740a428acf1e 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -50,14 +50,6 @@ DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 
 #define inc_irq_stat(member)	this_cpu_inc(irq_stat.member)
 
-#define local_softirq_pending()	this_cpu_read(irq_stat.__softirq_pending)
-
-#define __ARCH_SET_SOFTIRQ_PENDING
-
-#define set_softirq_pending(x)	\
-		this_cpu_write(irq_stat.__softirq_pending, (x))
-#define or_softirq_pending(x)	this_cpu_or(irq_stat.__softirq_pending, (x))
-
 extern void ack_bad_irq(unsigned int irq);
 
 extern u64 arch_irq_stat_cpu(unsigned int cpu);

commit 248e742a396e7f00b283f1c56e14b1bef6e3ec56
Author: Michael Kelley <mhkelley@outlook.com>
Date:   Sun Mar 4 22:17:18 2018 -0700

    Drivers: hv: vmbus: Implement Direct Mode for stimer0
    
    The 2016 version of Hyper-V offers the option to operate the guest VM
    per-vcpu stimer's in Direct Mode, which means the timer interupts on its
    own vector rather than queueing a VMbus message. Direct Mode reduces
    timer processing overhead in both the hypervisor and the guest, and
    avoids having timer interrupts pollute the VMbus interrupt stream for
    the synthetic NIC and storage.  This patch enables Direct Mode by
    default on stimer0 when running on a version of Hyper-V that supports
    it.
    
    In prep for coming support of Hyper-V on ARM64, the arch independent
    portion of the code contains calls to routines that will be populated
    on ARM64 but are not needed and do nothing on x86.
    
    Signed-off-by: Michael Kelley <mikelley@microsoft.com>
    Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 7c341a74ec8c..5ea2afd4c871 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -40,6 +40,7 @@ typedef struct {
 #endif
 #if IS_ENABLED(CONFIG_HYPERV)
 	unsigned int irq_hv_reenlightenment_count;
+	unsigned int hyperv_stimer0_count;
 #endif
 } ____cacheline_aligned irq_cpustat_t;
 

commit 51d4e5daa32808df4d50db511d167fde19fa114e
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Wed Jan 24 14:23:35 2018 +0100

    x86/irq: Count Hyper-V reenlightenment interrupts
    
    Hyper-V reenlightenment interrupts arrive when the VM is migrated, While
    they are not interesting in general it's important when L2 nested guests
    are running.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Stephen Hemminger <sthemmin@microsoft.com>
    Cc: kvm@vger.kernel.org
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Haiyang Zhang <haiyangz@microsoft.com>
    Cc: "Michael Kelley (EOSG)" <Michael.H.Kelley@microsoft.com>
    Cc: Roman Kagan <rkagan@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: devel@linuxdriverproject.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Cathy Avery <cavery@redhat.com>
    Cc: Mohammed Gamal <mmorsy@redhat.com>
    Link: https://lkml.kernel.org/r/20180124132337.30138-6-vkuznets@redhat.com

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 51cc979dd364..7c341a74ec8c 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -38,6 +38,9 @@ typedef struct {
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
 	unsigned int irq_hv_callback_count;
 #endif
+#if IS_ENABLED(CONFIG_HYPERV)
+	unsigned int irq_hv_reenlightenment_count;
+#endif
 } ____cacheline_aligned irq_cpustat_t;
 
 DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index ad1ed531febc..51cc979dd364 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_HARDIRQ_H
 #define _ASM_X86_HARDIRQ_H
 

commit 210f84b0ca7743f3b2a9acfae81df668dbbb6a12
Author: Wincy Van <fanwenyi0529@gmail.com>
Date:   Fri Apr 28 13:13:58 2017 +0800

    x86: irq: Define a global vector for nested posted interrupts
    
    We are using the same vector for nested/non-nested posted
    interrupts delivery, this may cause interrupts latency in
    L1 since we can't kick the L2 vcpu out of vmx-nonroot mode.
    
    This patch introduces a new vector which is only for nested
    posted interrupts to solve the problems above.
    
    Signed-off-by: Wincy Van <fanwenyi0529@gmail.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 9b76cd331990..ad1ed531febc 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -15,6 +15,7 @@ typedef struct {
 #ifdef CONFIG_HAVE_KVM
 	unsigned int kvm_posted_intr_ipis;
 	unsigned int kvm_posted_intr_wakeup_ipis;
+	unsigned int kvm_posted_intr_nested_ipis;
 #endif
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;

commit ce4a4e565f5264909a18c733b864c3f74467f69e
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sun May 28 10:00:14 2017 -0700

    x86/mm: Remove the UP asm/tlbflush.h code, always use the (formerly) SMP code
    
    The UP asm/tlbflush.h generates somewhat nicer code than the SMP version.
    Aside from that, it's fallen quite a bit behind the SMP code:
    
     - flush_tlb_mm_range() didn't flush individual pages if the range
       was small.
    
     - The lazy TLB code was much weaker.  This usually wouldn't matter,
       but, if a kernel thread flushed its lazy "active_mm" more than
       once (due to reclaim or similar), it wouldn't be unlazied and
       would instead pointlessly flush repeatedly.
    
     - Tracepoints were missing.
    
    Aside from that, simply having the UP code around was a maintanence
    burden, since it means that any change to the TLB flush code had to
    make sure not to break it.
    
    Simplify everything by deleting the UP code.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Nadav Amit <nadav.amit@gmail.com>
    Cc: Nadav Amit <namit@vmware.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 59405a248fc2..9b76cd331990 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -22,8 +22,8 @@ typedef struct {
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;
-	unsigned int irq_tlb_count;
 #endif
+	unsigned int irq_tlb_count;
 #ifdef CONFIG_X86_THERMAL_VECTOR
 	unsigned int irq_thermal_count;
 #endif

commit 82ba4faca1bffad429f15c90c980ffd010366c25
Author: Aaron Lu <aaron.lu@intel.com>
Date:   Thu Aug 11 15:44:30 2016 +0800

    x86/irq: Do not substract irq_tlb_count from irq_call_count
    
    Since commit:
    
      52aec3308db8 ("x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR")
    
    the TLB remote shootdown is done through call function vector. That
    commit didn't take care of irq_tlb_count, which a later commit:
    
      fd0f5869724f ("x86: Distinguish TLB shootdown interrupts from other functions call interrupts")
    
    ... tried to fix.
    
    The fix assumes every increase of irq_tlb_count has a corresponding
    increase of irq_call_count. So the irq_call_count is always bigger than
    irq_tlb_count and we could substract irq_tlb_count from irq_call_count.
    
    Unfortunately this is not true for the smp_call_function_single() case.
    The IPI is only sent if the target CPU's call_single_queue is empty when
    adding a csd into it in generic_exec_single. That means if two threads
    are both adding flush tlb csds to the same CPU's call_single_queue, only
    one IPI is sent. In other words, the irq_call_count is incremented by 1
    but irq_tlb_count is incremented by 2. Over time, irq_tlb_count will be
    bigger than irq_call_count and the substract will produce a very large
    irq_call_count value due to overflow.
    
    Considering that:
    
      1) it's not worth to send more IPIs for the sake of accurate counting of
         irq_call_count in generic_exec_single();
    
      2) it's not easy to tell if the call function interrupt is for TLB
         shootdown in __smp_call_function_single_interrupt().
    
    Not to exclude TLB shootdown from call function count seems to be the
    simplest fix and this patch just does that.
    
    This bug was found by LKP's cyclic performance regression tracking recently
    with the vm-scalability test suite. I have bisected to commit:
    
      3dec0ba0be6a ("mm/rmap: share the i_mmap_rwsem")
    
    This commit didn't do anything wrong but revealed the irq_call_count
    problem. IIUC, the commit makes rwc->remap_one in rmap_walk_file
    concurrent with multiple threads.  When remap_one is try_to_unmap_one(),
    then multiple threads could queue flush TLB to the same CPU but only
    one IPI will be sent.
    
    Since the commit was added in Linux v3.19, the counting problem only
    shows up from v3.19 onwards.
    
    Signed-off-by: Aaron Lu <aaron.lu@intel.com>
    Cc: Alex Shi <alex.shi@linaro.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
    Link: http://lkml.kernel.org/r/20160811074430.GA18163@aaronlu.sh.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 7178043b0e1d..59405a248fc2 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -22,10 +22,6 @@ typedef struct {
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;
-	/*
-	 * irq_tlb_count is double-counted in irq_call_count, so it must be
-	 * subtracted from irq_call_count when displaying irq_call_count
-	 */
 	unsigned int irq_tlb_count;
 #endif
 #ifdef CONFIG_X86_THERMAL_VECTOR

commit c2f9b0af8bb4b2a5c020ae88efc9a624f59a7080
Merge: c8e56d20f2d1 243d657eaf54
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Jun 7 15:35:27 2015 +0200

    Merge branch 'x86/ras' into x86/core, to fix conflicts
    
    Conflicts:
            arch/x86/include/asm/irq_vectors.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit f6b3c72c23661e5534cd2eede16e9bac7ebb761c
Author: Feng Wu <feng.wu@intel.com>
Date:   Tue May 19 17:07:16 2015 +0800

    x86/irq: Define a global vector for VT-d Posted-Interrupts
    
    Currently, we use a global vector as the Posted-Interrupts
    Notification Event for all the vCPUs in the system. We need
    to introduce another global vector for VT-d Posted-Interrtups,
    which will be used to wakeup the sleep vCPU when an external
    interrupt from a direct-assigned device happens for that vCPU.
    
    [ tglx: Removed a gazillion of extra newlines ]
    
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Cc: jiang.liu@linux.intel.com
    Link: http://lkml.kernel.org/r/1432026437-16560-4-git-send-email-feng.wu@intel.com
    Suggested-by: Yang Zhang <yang.z.zhang@intel.com>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 0f5fb6b6567e..986606539395 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -14,6 +14,7 @@ typedef struct {
 #endif
 #ifdef CONFIG_HAVE_KVM
 	unsigned int kvm_posted_intr_ipis;
+	unsigned int kvm_posted_intr_wakeup_ipis;
 #endif
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;

commit 24fd78a81f6d3fe7f7a440c8629f9c52cd5f830e
Author: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
Date:   Wed May 6 06:58:56 2015 -0500

    x86/mce/amd: Introduce deferred error interrupt handler
    
    Deferred errors indicate error conditions that were not corrected, but
    require no action from S/W (or action is optional).These errors provide
    info about a latent UC MCE that can occur when a poisoned data is
    consumed by the processor.
    
    Processors that report these errors can be configured to generate APIC
    interrupts to notify OS about the error.
    
    Provide an interrupt handler in this patch so that OS can catch these
    errors as and when they happen. Currently, we simply log the errors and
    exit the handler as S/W action is not mandated.
    
    Signed-off-by: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: x86-ml <x86@kernel.org>
    Cc: linux-edac <linux-edac@vger.kernel.org>
    Link: http://lkml.kernel.org/r/1430913538-1415-5-git-send-email-Aravind.Gopalakrishnan@amd.com
    Signed-off-by: Borislav Petkov <bp@suse.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 0f5fb6b6567e..db9f536f482f 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -33,6 +33,9 @@ typedef struct {
 #ifdef CONFIG_X86_MCE_THRESHOLD
 	unsigned int irq_threshold_count;
 #endif
+#ifdef CONFIG_X86_MCE_AMD
+	unsigned int irq_deferred_error_count;
+#endif
 #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
 	unsigned int irq_hv_callback_count;
 #endif

commit 3eb2be5f49fdeac5ea2880aec90008f0a8250029
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jun 9 16:19:39 2014 +0800

    x86, irq, trivial: Minor improvements of IRQ related code
    
    1) Kill unused MAX_HARDIRQS_PER_CPU.
    2) Improve function prototype declararions.
    3) Simple typo fix, change "gsit" to "gsi".
    4) Use macro VECTOR_UNDEFINED instead of hard-coded -1.
    5) Kill redundant comments.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Grant Likely <grant.likely@linaro.org>
    Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Jiri Kosina <trivial@kernel.org>
    Link: http://lkml.kernel.org/r/1402302011-23642-11-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 230853da4ec0..0f5fb6b6567e 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -40,9 +40,6 @@ typedef struct {
 
 DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 
-/* We can have at most NR_VECTORS irqs routed to a cpu at a time */
-#define MAX_HARDIRQS_PER_CPU NR_VECTORS
-
 #define __ARCH_IRQ_STAT
 
 #define inc_irq_stat(member)	this_cpu_inc(irq_stat.member)

commit 7ff42473ebdee32ed3ac34f6bf4b4080c7455840
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 6 12:08:37 2014 +0100

    x86: hardirq: Make irq_hv_callback_count available for CONFIG_HYPERV=m  as well
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index afb6536ee3ac..230853da4ec0 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -33,7 +33,7 @@ typedef struct {
 #ifdef CONFIG_X86_MCE_THRESHOLD
 	unsigned int irq_threshold_count;
 #endif
-#if defined(CONFIG_HYPERV) || defined(CONFIG_XEN)
+#if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
 	unsigned int irq_hv_callback_count;
 #endif
 } ____cacheline_aligned irq_cpustat_t;

commit 929320e4b4c10708d3477d7e395f0ce7b0cc8744
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 23 21:40:20 2014 +0000

    x86: Add proper vector accounting for HYPERVISOR_CALLBACK_VECTOR
    
    HyperV abuses a device interrupt to account for the
    HYPERVISOR_CALLBACK_VECTOR.
    
    Provide proper accounting as we have for the other vectors as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: K. Y. Srinivasan <kys@microsoft.com>
    Cc: x86 <x86@kernel.org>
    Link: http://lkml.kernel.org/r/20140223212738.681855582@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index ab0ae1aa6d0a..afb6536ee3ac 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -33,6 +33,9 @@ typedef struct {
 #ifdef CONFIG_X86_MCE_THRESHOLD
 	unsigned int irq_threshold_count;
 #endif
+#if defined(CONFIG_HYPERV) || defined(CONFIG_XEN)
+	unsigned int irq_hv_callback_count;
+#endif
 } ____cacheline_aligned irq_cpustat_t;
 
 DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);

commit d78f2664832f8d70e36422af9a10e44276dced48
Author: Yang Zhang <yang.z.zhang@Intel.com>
Date:   Thu Apr 11 19:25:11 2013 +0800

    KVM: VMX: Register a new IPI for posted interrupt
    
    Posted Interrupt feature requires a special IPI to deliver posted interrupt
    to guest. And it should has a high priority so the interrupt will not be
    blocked by others.
    Normally, the posted interrupt will be consumed by vcpu if target vcpu is
    running and transparent to OS. But in some cases, the interrupt will arrive
    when target vcpu is scheduled out. And host will see it. So we need to
    register a dump handler to handle it.
    
    Signed-off-by: Yang Zhang <yang.z.zhang@Intel.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Gleb Natapov <gleb@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 81f04cee5f74..ab0ae1aa6d0a 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -11,6 +11,9 @@ typedef struct {
 	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq_spurious_count;
 	unsigned int icr_read_retry_count;
+#endif
+#ifdef CONFIG_HAVE_KVM
+	unsigned int kvm_posted_intr_ipis;
 #endif
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;

commit fd0f5869724ff6195c6e7f12f8287c66a132e0ba
Author: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
Date:   Wed Sep 26 11:11:28 2012 +0900

    x86: Distinguish TLB shootdown interrupts from other functions call interrupts
    
    As TLB shootdown requests to other CPU cores are now using function call
    interrupts, TLB shootdowns entry in /proc/interrupts is always shown as 0.
    
    This behavior change was introduced by commit 52aec3308db8 ("x86/tlb:
    replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR").
    
    This patch reverts TLB shootdowns entry in /proc/interrupts to count TLB
    shootdowns separately from the other function call interrupts.
    
    Signed-off-by: Tomoki Sekiyama <tomoki.sekiyama.qu@hitachi.com>
    Link: http://lkml.kernel.org/r/20120926021128.22212.20440.stgit@hpxw
    Acked-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index d3895dbf4ddb..81f04cee5f74 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -18,6 +18,10 @@ typedef struct {
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;
+	/*
+	 * irq_tlb_count is double-counted in irq_call_count, so it must be
+	 * subtracted from irq_call_count when displaying irq_call_count
+	 */
 	unsigned int irq_tlb_count;
 #endif
 #ifdef CONFIG_X86_THERMAL_VECTOR

commit c6ae41e7d469f00d9c92a2b2887c7235d121c009
Author: Alex Shi <alex.shi@intel.com>
Date:   Fri May 11 15:35:27 2012 +0800

    x86: replace percpu_xxx funcs with this_cpu_xxx
    
    Since percpu_xxx() serial functions are duplicated with this_cpu_xxx().
    Removing percpu_xxx() definition and replacing them by this_cpu_xxx()
    in code. There is no function change in this patch, just preparation for
    later percpu_xxx serial function removing.
    
    On x86 machine the this_cpu_xxx() serial functions are same as
    __this_cpu_xxx() without no unnecessary premmpt enable/disable.
    
    Thanks for Stephen Rothwell, he found and fixed a i386 build error in
    the patch.
    
    Also thanks for Andrew Morton, he kept updating the patchset in Linus'
    tree.
    
    Signed-off-by: Alex Shi <alex.shi@intel.com>
    Acked-by: Christoph Lameter <cl@gentwo.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 382f75d735f3..d3895dbf4ddb 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -35,14 +35,15 @@ DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 
 #define __ARCH_IRQ_STAT
 
-#define inc_irq_stat(member)	percpu_inc(irq_stat.member)
+#define inc_irq_stat(member)	this_cpu_inc(irq_stat.member)
 
-#define local_softirq_pending()	percpu_read(irq_stat.__softirq_pending)
+#define local_softirq_pending()	this_cpu_read(irq_stat.__softirq_pending)
 
 #define __ARCH_SET_SOFTIRQ_PENDING
 
-#define set_softirq_pending(x)	percpu_write(irq_stat.__softirq_pending, (x))
-#define or_softirq_pending(x)	percpu_or(irq_stat.__softirq_pending, (x))
+#define set_softirq_pending(x)	\
+		this_cpu_write(irq_stat.__softirq_pending, (x))
+#define or_softirq_pending(x)	this_cpu_or(irq_stat.__softirq_pending, (x))
 
 extern void ack_bad_irq(unsigned int irq);
 

commit d93c4071b78f4676ef70ec8f2d4bae59b6cc5523
Author: Jan Beulich <JBeulich@suse.com>
Date:   Fri Feb 24 11:50:27 2012 +0000

    x86/time: Eliminate unused irq0_irqs counter
    
    As of v2.6.38 this counter is being maintained without ever being
    read.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Link: http://lkml.kernel.org/r/4F4787930200007800074A10@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index da0b3ca815b7..382f75d735f3 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -7,7 +7,6 @@
 typedef struct {
 	unsigned int __softirq_pending;
 	unsigned int __nmi_count;	/* arch dependent */
-	unsigned int irq0_irqs;
 #ifdef CONFIG_X86_LOCAL_APIC
 	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq_spurious_count;

commit b49d7d877ff96428c8cd2076b33ba72bf85ceaba
Author: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
Date:   Thu Dec 15 11:32:24 2011 +0900

    x86: Convert per-cpu counter icr_read_retry_count into a member of irq_stat
    
    LAPIC related statistics are grouped inside the per-cpu
    structure irq_stat, so there is no need for icr_read_retry_count
    to be a standalone per-cpu variable.
    
    This patch moves icr_read_retry_count to where it belongs.
    
    Suggested-y: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
    Cc: Jörn Engel <joern@logfs.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 55e4de613f0e..da0b3ca815b7 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -11,6 +11,7 @@ typedef struct {
 #ifdef CONFIG_X86_LOCAL_APIC
 	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq_spurious_count;
+	unsigned int icr_read_retry_count;
 #endif
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;

commit e360adbe29241a0194e10e20595360dd7b98a2b3
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Oct 14 14:01:34 2010 +0800

    irq_work: Add generic hardirq context callbacks
    
    Provide a mechanism that allows running code in IRQ context. It is
    most useful for NMI code that needs to interact with the rest of the
    system -- like wakeup a task to drain buffers.
    
    Perf currently has such a mechanism, so extract that and provide it as
    a generic feature, independent of perf so that others may also
    benefit.
    
    The IRQ context callback is generated through self-IPIs where
    possible, or on architectures like powerpc the decrementer (the
    built-in timer facility) is set to generate an interrupt immediately.
    
    Architectures that don't have anything like this get to do with a
    callback from the timer tick. These architectures can call
    irq_work_run() at the tail of any IRQ handlers that might enqueue such
    work (like the perf IRQ handler) to avoid undue latencies in
    processing the work.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    [ various fixes ]
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    LKML-Reference: <1287036094.7768.291.camel@yhuang-dev>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index aeab29aee617..55e4de613f0e 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -14,7 +14,7 @@ typedef struct {
 #endif
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;
-	unsigned int apic_pending_irqs;
+	unsigned int apic_irq_work_irqs;
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;

commit 402af0d7c692ddcfa2333e93d3f275ebd0487926
Author: Jan Beulich <JBeulich@novell.com>
Date:   Wed Apr 21 15:21:51 2010 +0100

    x86, asm: Introduce and use percpu_inc()
    
    ... generating slightly smaller code.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    LKML-Reference: <4BCF261F020000780003B33C@vpn.id2.novell.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 0f8576427cfe..aeab29aee617 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -35,7 +35,7 @@ DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 
 #define __ARCH_IRQ_STAT
 
-#define inc_irq_stat(member)	percpu_add(irq_stat.member, 1)
+#define inc_irq_stat(member)	percpu_inc(irq_stat.member)
 
 #define local_softirq_pending()	percpu_read(irq_stat.__softirq_pending)
 

commit 4646575daf21f544fc2f7e8d90d8c488948fcc7c
Merge: 86ed4aa457f9 581f202bcd60
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 8 13:38:21 2009 -0800

    Merge branch 'x86-uv-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-uv-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: UV RTC: Always enable RTC clocksource
      x86: UV RTC: Rename generic_interrupt to x86_platform_ipi
      x86: UV RTC: Clean up error handling
      x86: UV RTC: Add clocksource only boot option
      x86: UV RTC: Fix early expiry handling

commit 0444c9bd0cf4e0eb946a7fcaf34765accfa9404a
Author: Jan Beulich <JBeulich@novell.com>
Date:   Fri Nov 20 14:03:05 2009 +0000

    x86: Tighten conditionals on MCE related statistics
    
    irq_thermal_count is only being maintained when
    X86_THERMAL_VECTOR, and both X86_THERMAL_VECTOR and
    X86_MCE_THRESHOLD don't need extra wrapping in X86_MCE
    conditionals.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Yong Wang <yong.y.wang@intel.com>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    LKML-Reference: <4B06AFA902000078000211F8@vpn.id2.novell.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 82e3e8f01043..108eb6fd1ae7 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -20,11 +20,11 @@ typedef struct {
 	unsigned int irq_call_count;
 	unsigned int irq_tlb_count;
 #endif
-#ifdef CONFIG_X86_MCE
+#ifdef CONFIG_X86_THERMAL_VECTOR
 	unsigned int irq_thermal_count;
-# ifdef CONFIG_X86_MCE_THRESHOLD
+#endif
+#ifdef CONFIG_X86_MCE_THRESHOLD
 	unsigned int irq_threshold_count;
-# endif
 #endif
 } ____cacheline_aligned irq_cpustat_t;
 

commit 4a4de9c7d7111ce4caf422b856756125d8304f9d
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Wed Oct 14 09:22:57 2009 -0500

    x86: UV RTC: Rename generic_interrupt to x86_platform_ipi
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    LKML-Reference: <20091014142257.GE11048@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 82e3e8f01043..beaabd794a10 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -12,7 +12,7 @@ typedef struct {
 	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq_spurious_count;
 #endif
-	unsigned int generic_irqs;	/* arch dependent */
+	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;
 	unsigned int apic_pending_irqs;
 #ifdef CONFIG_SMP

commit 0d5959723e1db3fd7323c198a50c16cecf96c7a9
Merge: 62fdac5913f7 512626a04e72
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 11 23:31:52 2009 +0200

    Merge branch 'linus' into x86/mce3
    
    Conflicts:
            arch/x86/kernel/cpu/mcheck/mce_64.c
            arch/x86/kernel/irq.c
    
    Merge reason: Resolve the conflicts above.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7856f6cce4a8cda8c1f94b99605c07d16b8d8dec
Author: Andi Kleen <ak@linux.intel.com>
Date:   Tue Apr 28 23:32:56 2009 +0200

    x86, mce: enable MCE_INTEL for 32bit new MCE
    
    Enable the 64bit MCE_INTEL code (CMCI, thermal interrupts) for 32bit NEW_MCE.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 37555e52f980..922ee7c29693 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -20,7 +20,7 @@ typedef struct {
 #endif
 #ifdef CONFIG_X86_MCE
 	unsigned int irq_thermal_count;
-# ifdef CONFIG_X86_64
+# ifdef CONFIG_X86_MCE_THRESHOLD
 	unsigned int irq_threshold_count;
 # endif
 #endif

commit e7fd5d4b3d240f42c30a9e3d20a4689c4d3a795a
Merge: 1130b0296184 56a50adda49b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Apr 29 14:46:59 2009 +0200

    Merge branch 'linus' into perfcounters/core
    
    Merge reason: This brach was on -rc1, refresh it to almost-rc4 to pick up
                  the latest upstream fixes.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9b8de7479d0dbab1ed98b5b015d44232c9d3d08e
Author: David Howells <dhowells@redhat.com>
Date:   Tue Apr 21 23:00:24 2009 +0100

    FRV: Fix the section attribute on UP DECLARE_PER_CPU()
    
    In non-SMP mode, the variable section attribute specified by DECLARE_PER_CPU()
    does not agree with that specified by DEFINE_PER_CPU().  This means that
    architectures that have a small data section references relative to a base
    register may throw up linkage errors due to too great a displacement between
    where the base register points and the per-CPU variable.
    
    On FRV, the .h declaration says that the variable is in the .sdata section, but
    the .c definition says it's actually in the .data section.  The linker throws
    up the following errors:
    
    kernel/built-in.o: In function `release_task':
    kernel/exit.c:78: relocation truncated to fit: R_FRV_GPREL12 against symbol `per_cpu__process_counts' defined in .data section in kernel/built-in.o
    kernel/exit.c:78: relocation truncated to fit: R_FRV_GPREL12 against symbol `per_cpu__process_counts' defined in .data section in kernel/built-in.o
    
    To fix this, DECLARE_PER_CPU() should simply apply the same section attribute
    as does DEFINE_PER_CPU().  However, this is made slightly more complex by
    virtue of the fact that there are several variants on DEFINE, so these need to
    be matched by variants on DECLARE.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 039db6aa8e02..37555e52f980 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -26,7 +26,7 @@ typedef struct {
 #endif
 } ____cacheline_aligned irq_cpustat_t;
 
-DECLARE_PER_CPU(irq_cpustat_t, irq_stat);
+DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
 
 /* We can have at most NR_VECTORS irqs routed to a cpu at a time */
 #define MAX_HARDIRQS_PER_CPU NR_VECTORS

commit b6276f353bf490add62dcf7db0ebd75baa3e1a37
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Apr 6 11:45:03 2009 +0200

    perf_counter: x86: self-IPI for pending work
    
    Implement set_perf_counter_pending() with a self-IPI so that it will
    run ASAP in a usable context.
    
    For now use a second IRQ vector, because the primary vector pokes
    the apic in funny ways that seem to confuse things.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    LKML-Reference: <20090406094517.724626696@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 25454427ceea..f5ebe2aaca4b 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -14,6 +14,7 @@ typedef struct {
 #endif
 	unsigned int generic_irqs;	/* arch dependent */
 	unsigned int apic_perf_irqs;
+	unsigned int apic_pending_irqs;
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;

commit f541ae326fa120fa5c57433e4d9a133df212ce41
Merge: e255357764f9 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 09:02:57 2009 +0200

    Merge branch 'linus' into perfcounters/core-v2
    
    Merge reason: we have gathered quite a few conflicts, need to merge upstream
    
    Conflicts:
            arch/powerpc/kernel/Makefile
            arch/x86/ia32/ia32entry.S
            arch/x86/include/asm/hardirq.h
            arch/x86/include/asm/unistd_32.h
            arch/x86/include/asm/unistd_64.h
            arch/x86/kernel/cpu/common.c
            arch/x86/kernel/irq.c
            arch/x86/kernel/syscall_table_32.S
            arch/x86/mm/iomap_32.c
            include/linux/sched.h
            kernel/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit acaabe795a62bba089c185917af86b44654313dc
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Wed Mar 4 12:56:05 2009 -0600

    x86: UV, SGI RTC: add generic system vector
    
    This patch allocates a system interrupt vector for various platform
    specific uses.
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: john stultz <johnstul@us.ibm.com>
    LKML-Reference: <20090304185605.GA24419@sgi.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 176f058e7159..039db6aa8e02 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -12,6 +12,7 @@ typedef struct {
 	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq_spurious_count;
 #endif
+	unsigned int generic_irqs;	/* arch dependent */
 #ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;

commit bfe2a3c3b5bf479788d5d5c5561346be6b169043
Merge: 77835492ed48 35d266a24796
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jan 23 10:20:15 2009 +0100

    Merge branch 'core/percpu' into perfcounters/core
    
    Conflicts:
            arch/x86/include/asm/hardirq_32.h
            arch/x86/include/asm/hardirq_64.h
    
    Semantic merge:
            arch/x86/include/asm/hardirq.h
            [ added apic_perf_irqs field. ]
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 2de3a5f7956eb81447feea3aec68193ddd8534bb
Author: Brian Gerst <brgerst@gmail.com>
Date:   Fri Jan 23 11:03:32 2009 +0900

    x86: make irq_cpustat_t fields conditional
    
    Impact: shrink size of irq_cpustat_t when possible
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index f4a95f20f8ec..176f058e7159 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -7,14 +7,22 @@
 typedef struct {
 	unsigned int __softirq_pending;
 	unsigned int __nmi_count;	/* arch dependent */
-	unsigned int apic_timer_irqs;	/* arch dependent */
 	unsigned int irq0_irqs;
+#ifdef CONFIG_X86_LOCAL_APIC
+	unsigned int apic_timer_irqs;	/* arch dependent */
+	unsigned int irq_spurious_count;
+#endif
+#ifdef CONFIG_SMP
 	unsigned int irq_resched_count;
 	unsigned int irq_call_count;
 	unsigned int irq_tlb_count;
+#endif
+#ifdef CONFIG_X86_MCE
 	unsigned int irq_thermal_count;
-	unsigned int irq_spurious_count;
+# ifdef CONFIG_X86_64
 	unsigned int irq_threshold_count;
+# endif
+#endif
 } ____cacheline_aligned irq_cpustat_t;
 
 DECLARE_PER_CPU(irq_cpustat_t, irq_stat);

commit 22da7b3df3a2e26a87a8581575dbf26e465a6ac7
Author: Brian Gerst <brgerst@gmail.com>
Date:   Fri Jan 23 11:03:31 2009 +0900

    x86: merge hardirq_{32,64}.h into hardirq.h
    
    Impact: cleanup
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 000787df66e6..f4a95f20f8ec 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -1,11 +1,44 @@
-#ifdef CONFIG_X86_32
-# include "hardirq_32.h"
-#else
-# include "hardirq_64.h"
-#endif
+#ifndef _ASM_X86_HARDIRQ_H
+#define _ASM_X86_HARDIRQ_H
+
+#include <linux/threads.h>
+#include <linux/irq.h>
+
+typedef struct {
+	unsigned int __softirq_pending;
+	unsigned int __nmi_count;	/* arch dependent */
+	unsigned int apic_timer_irqs;	/* arch dependent */
+	unsigned int irq0_irqs;
+	unsigned int irq_resched_count;
+	unsigned int irq_call_count;
+	unsigned int irq_tlb_count;
+	unsigned int irq_thermal_count;
+	unsigned int irq_spurious_count;
+	unsigned int irq_threshold_count;
+} ____cacheline_aligned irq_cpustat_t;
+
+DECLARE_PER_CPU(irq_cpustat_t, irq_stat);
+
+/* We can have at most NR_VECTORS irqs routed to a cpu at a time */
+#define MAX_HARDIRQS_PER_CPU NR_VECTORS
+
+#define __ARCH_IRQ_STAT
+
+#define inc_irq_stat(member)	percpu_add(irq_stat.member, 1)
+
+#define local_softirq_pending()	percpu_read(irq_stat.__softirq_pending)
+
+#define __ARCH_SET_SOFTIRQ_PENDING
+
+#define set_softirq_pending(x)	percpu_write(irq_stat.__softirq_pending, (x))
+#define or_softirq_pending(x)	percpu_or(irq_stat.__softirq_pending, (x))
+
+extern void ack_bad_irq(unsigned int irq);
 
 extern u64 arch_irq_stat_cpu(unsigned int cpu);
 #define arch_irq_stat_cpu	arch_irq_stat_cpu
 
 extern u64 arch_irq_stat(void);
 #define arch_irq_stat		arch_irq_stat
+
+#endif /* _ASM_X86_HARDIRQ_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
new file mode 100644
index 000000000000..000787df66e6
--- /dev/null
+++ b/arch/x86/include/asm/hardirq.h
@@ -0,0 +1,11 @@
+#ifdef CONFIG_X86_32
+# include "hardirq_32.h"
+#else
+# include "hardirq_64.h"
+#endif
+
+extern u64 arch_irq_stat_cpu(unsigned int cpu);
+#define arch_irq_stat_cpu	arch_irq_stat_cpu
+
+extern u64 arch_irq_stat(void);
+#define arch_irq_stat		arch_irq_stat
