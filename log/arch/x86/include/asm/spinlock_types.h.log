commit 2ca41f555e857ec5beef6063bfa43a17ee76d7ec
Author: Waiman Long <longman@redhat.com>
Date:   Tue May 26 08:20:14 2020 -0400

    x86/spinlock: Remove obsolete ticket spinlock macros and types
    
    Even though the x86 ticket spinlock code has been removed with
    
      cfd8983f03c7 ("x86, locking/spinlocks: Remove ticket (spin)lock implementation")
    
    a while ago, there are still some ticket spinlock specific macros and
    types left in the asm/spinlock_types.h header file that are no longer
    used. Remove those as well to avoid confusion.
    
    Signed-off-by: Waiman Long <longman@redhat.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20200526122014.25241-1-longman@redhat.com

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index bf3e34b25afc..323db6c5852a 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -3,29 +3,7 @@
 #define _ASM_X86_SPINLOCK_TYPES_H
 
 #include <linux/types.h>
-
-#ifdef CONFIG_PARAVIRT_SPINLOCKS
-#define __TICKET_LOCK_INC	2
-#define TICKET_SLOWPATH_FLAG	((__ticket_t)1)
-#else
-#define __TICKET_LOCK_INC	1
-#define TICKET_SLOWPATH_FLAG	((__ticket_t)0)
-#endif
-
-#if (CONFIG_NR_CPUS < (256 / __TICKET_LOCK_INC))
-typedef u8  __ticket_t;
-typedef u16 __ticketpair_t;
-#else
-typedef u16 __ticket_t;
-typedef u32 __ticketpair_t;
-#endif
-
-#define TICKET_LOCK_INC	((__ticket_t)__TICKET_LOCK_INC)
-
-#define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
-
 #include <asm-generic/qspinlock_types.h>
-
 #include <asm-generic/qrwlock_types.h>
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 25311ebb446c..bf3e34b25afc 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_SPINLOCK_TYPES_H
 #define _ASM_X86_SPINLOCK_TYPES_H
 

commit cfd8983f03c7b2f977faab8dfc4ec5f6dbf9c1f3
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed May 18 20:43:02 2016 +0200

    x86, locking/spinlocks: Remove ticket (spin)lock implementation
    
    We've unconditionally used the queued spinlock for many releases now.
    
    Its time to remove the old ticket lock code.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Waiman Long <waiman.long@hpe.com>
    Cc: Waiman.Long@hpe.com
    Cc: david.vrabel@citrix.com
    Cc: dhowells@redhat.com
    Cc: pbonzini@redhat.com
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/20160518184302.GO3193@twins.programming.kicks-ass.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 65c3e37f879a..25311ebb446c 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -23,20 +23,7 @@ typedef u32 __ticketpair_t;
 
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
 
-#ifdef CONFIG_QUEUED_SPINLOCKS
 #include <asm-generic/qspinlock_types.h>
-#else
-typedef struct arch_spinlock {
-	union {
-		__ticketpair_t head_tail;
-		struct __raw_tickets {
-			__ticket_t head, tail;
-		} tickets;
-	};
-} arch_spinlock_t;
-
-#define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
-#endif /* CONFIG_QUEUED_SPINLOCKS */
 
 #include <asm-generic/qrwlock_types.h>
 

commit 62c7a1e9ae54ef66658df9614bdbc09cbbdaa6f0
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 11 09:47:23 2015 +0200

    locking/pvqspinlock: Rename QUEUED_SPINLOCK to QUEUED_SPINLOCKS
    
    Valentin Rothberg reported that we use CONFIG_QUEUED_SPINLOCKS
    in arch/x86/kernel/paravirt_patch_32.c, while the symbol is
    called CONFIG_QUEUED_SPINLOCK. (Note the extra 'S')
    
    But the typo was natural: the proper English term for such
    a generic object would be 'queued spinlocks' - so rename
    this and related symbols accordingly to the plural form.
    
    Reported-by: Valentin Rothberg <valentinrothberg@gmail.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 5df1f1b9a4b0..65c3e37f879a 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -23,7 +23,7 @@ typedef u32 __ticketpair_t;
 
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
 
-#ifdef CONFIG_QUEUED_SPINLOCK
+#ifdef CONFIG_QUEUED_SPINLOCKS
 #include <asm-generic/qspinlock_types.h>
 #else
 typedef struct arch_spinlock {
@@ -36,7 +36,7 @@ typedef struct arch_spinlock {
 } arch_spinlock_t;
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
-#endif /* CONFIG_QUEUED_SPINLOCK */
+#endif /* CONFIG_QUEUED_SPINLOCKS */
 
 #include <asm-generic/qrwlock_types.h>
 

commit d73a33973f16ab6703e75ea00edee857afa3406e
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Fri Apr 24 14:56:31 2015 -0400

    locking/qspinlock, x86: Enable x86-64 to use queued spinlocks
    
    This patch makes the necessary changes at the x86 architecture
    specific layer to enable the use of queued spinlocks for x86-64. As
    x86-32 machines are typically not multi-socket. The benefit of queue
    spinlock may not be apparent. So queued spinlocks are not enabled.
    
    Currently, there is some incompatibilities between the para-virtualized
    spinlock code (which hard-codes the use of ticket spinlock) and the
    queued spinlocks. Therefore, the use of queued spinlocks is disabled
    when the para-virtualized spinlock is enabled.
    
    The arch/x86/include/asm/qspinlock.h header file includes some x86
    specific optimization which will make the queueds spinlock code
    perform better than the generic implementation.
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Daniel J Blueman <daniel@numascale.com>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paolo Bonzini <paolo.bonzini@gmail.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1429901803-29771-3-git-send-email-Waiman.Long@hp.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 5f9d7572d82b..5df1f1b9a4b0 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -23,6 +23,9 @@ typedef u32 __ticketpair_t;
 
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
 
+#ifdef CONFIG_QUEUED_SPINLOCK
+#include <asm-generic/qspinlock_types.h>
+#else
 typedef struct arch_spinlock {
 	union {
 		__ticketpair_t head_tail;
@@ -33,6 +36,7 @@ typedef struct arch_spinlock {
 } arch_spinlock_t;
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
+#endif /* CONFIG_QUEUED_SPINLOCK */
 
 #include <asm-generic/qrwlock_types.h>
 

commit 2ff810a7ef38b55ba6c7b80bb7ff22847fd3be69
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Thu Aug 14 13:27:30 2014 -0400

    locking/rwlock, x86: Clean up asm/spinlock*.h to remove old rwlock code
    
    As the x86 architecture now uses qrwlock for its read/write lock
    implementation, it is no longer necessary to keep the old rwlock code
    around. This patch removes the old rwlock code in the asm/spinlock.h
    and asm/spinlock_types.h files. Now the ARCH_USE_QUEUE_RWLOCK
    config parameter cannot be removed from x86/Kconfig or there will be
    a compilation error.
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Link: http://lkml.kernel.org/r/1408037251-45918-2-git-send-email-Waiman.Long@hp.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 73c4c007200f..5f9d7572d82b 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -34,10 +34,6 @@ typedef struct arch_spinlock {
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
 
-#ifdef CONFIG_QUEUE_RWLOCK
 #include <asm-generic/qrwlock_types.h>
-#else
-#include <asm/rwlock.h>
-#endif
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit bd01ec1a13f9a327950c8e3080096446c7804753
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Mon Feb 3 13:18:57 2014 +0100

    x86, locking/rwlocks: Enable qrwlocks on x86
    
    Make x86 use the fair rwlock_t.
    
    Implement the custom queue_write_unlock() for best performance.
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    [peterz: near complete rewrite]
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Cc: "Paul E.McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/n/tip-r1xuzmdysvuhl3h86n5fbxi7@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 4f1bea19945b..73c4c007200f 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -34,6 +34,10 @@ typedef struct arch_spinlock {
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
 
+#ifdef CONFIG_QUEUE_RWLOCK
+#include <asm-generic/qrwlock_types.h>
+#else
 #include <asm/rwlock.h>
+#endif
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit 96f853eaa889c7a22718d275b0df7bebdbd6780e
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Aug 9 19:51:58 2013 +0530

    x86, ticketlock: Add slowpath logic
    
    Maintain a flag in the LSB of the ticket lock tail which indicates
    whether anyone is in the lock slowpath and may need kicking when
    the current holder unlocks.  The flags are set when the first locker
    enters the slowpath, and cleared when unlocking to an empty queue (ie,
    no contention).
    
    In the specific implementation of lock_spinning(), make sure to set
    the slowpath flags on the lock just before blocking.  We must do
    this before the last-chance pickup test to prevent a deadlock
    with the unlocker:
    
    Unlocker                        Locker
                                    test for lock pickup
                                            -> fail
    unlock
    test slowpath
            -> false
                                    set slowpath flags
                                    block
    
    Whereas this works in any ordering:
    
    Unlocker                        Locker
                                    set slowpath flags
                                    test for lock pickup
                                            -> fail
                                    block
    unlock
    test slowpath
            -> true, kick
    
    If the unlocker finds that the lock has the slowpath flag set but it is
    actually uncontended (ie, head == tail, so nobody is waiting), then it
    clears the slowpath flag.
    
    The unlock code uses a locked add to update the head counter.  This also
    acts as a full memory barrier so that its safe to subsequently
    read back the slowflag state, knowing that the updated lock is visible
    to the other CPUs.  If it were an unlocked add, then the flag read may
    just be forwarded from the store buffer before it was visible to the other
    CPUs, which could result in a deadlock.
    
    Unfortunately this means we need to do a locked instruction when
    unlocking with PV ticketlocks.  However, if PV ticketlocks are not
    enabled, then the old non-locked "add" is the only unlocking code.
    
    Note: this code relies on gcc making sure that unlikely() code is out of
    line of the fastpath, which only happens when OPTIMIZE_SIZE=n.  If it
    doesn't the generated code isn't too bad, but its definitely suboptimal.
    
    Thanks to Srivatsa Vaddagiri for providing a bugfix to the original
    version of this change, which has been folded in.
    Thanks to Stephan Diestelhorst for commenting on some code which relied
    on an inaccurate reading of the x86 memory ordering rules.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Link: http://lkml.kernel.org/r/1376058122-8248-11-git-send-email-raghavendra.kt@linux.vnet.ibm.com
    Signed-off-by: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Stephan Diestelhorst <stephan.diestelhorst@amd.com>
    Signed-off-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index e96fcbdfbc07..4f1bea19945b 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -5,8 +5,10 @@
 
 #ifdef CONFIG_PARAVIRT_SPINLOCKS
 #define __TICKET_LOCK_INC	2
+#define TICKET_SLOWPATH_FLAG	((__ticket_t)1)
 #else
 #define __TICKET_LOCK_INC	1
+#define TICKET_SLOWPATH_FLAG	((__ticket_t)0)
 #endif
 
 #if (CONFIG_NR_CPUS < (256 / __TICKET_LOCK_INC))

commit 4a1ed4ca681e7df38ed1b609a11aab38cbc515b3
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Aug 9 19:51:56 2013 +0530

    x86, pvticketlock: When paravirtualizing ticket locks, increment by 2
    
    Increment ticket head/tails by 2 rather than 1 to leave the LSB free
    to store a "is in slowpath state" bit.  This halves the number
    of possible CPUs for a given ticket size, but this shouldn't matter
    in practice - kernels built for 32k+ CPU systems are probably
    specially built for the hardware rather than a generic distro
    kernel.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Link: http://lkml.kernel.org/r/1376058122-8248-9-git-send-email-raghavendra.kt@linux.vnet.ibm.com
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Tested-by: Attilio Rao <attilio.rao@citrix.com>
    Signed-off-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 83fd3c75d45c..e96fcbdfbc07 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -3,7 +3,13 @@
 
 #include <linux/types.h>
 
-#if (CONFIG_NR_CPUS < 256)
+#ifdef CONFIG_PARAVIRT_SPINLOCKS
+#define __TICKET_LOCK_INC	2
+#else
+#define __TICKET_LOCK_INC	1
+#endif
+
+#if (CONFIG_NR_CPUS < (256 / __TICKET_LOCK_INC))
 typedef u8  __ticket_t;
 typedef u16 __ticketpair_t;
 #else
@@ -11,6 +17,8 @@ typedef u16 __ticket_t;
 typedef u32 __ticketpair_t;
 #endif
 
+#define TICKET_LOCK_INC	((__ticket_t)__TICKET_LOCK_INC)
+
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
 
 typedef struct arch_spinlock {

commit 545ac13892ab391049a92108cf59a0d05de7e28c
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Aug 9 19:51:49 2013 +0530

    x86, spinlock: Replace pv spinlocks with pv ticketlocks
    
    Rather than outright replacing the entire spinlock implementation in
    order to paravirtualize it, keep the ticket lock implementation but add
    a couple of pvops hooks on the slow patch (long spin on lock, unlocking
    a contended lock).
    
    Ticket locks have a number of nice properties, but they also have some
    surprising behaviours in virtual environments.  They enforce a strict
    FIFO ordering on cpus trying to take a lock; however, if the hypervisor
    scheduler does not schedule the cpus in the correct order, the system can
    waste a huge amount of time spinning until the next cpu can take the lock.
    
    (See Thomas Friebel's talk "Prevent Guests from Spinning Around"
    http://www.xen.org/files/xensummitboston08/LHP.pdf for more details.)
    
    To address this, we add two hooks:
     - __ticket_spin_lock which is called after the cpu has been
       spinning on the lock for a significant number of iterations but has
       failed to take the lock (presumably because the cpu holding the lock
       has been descheduled).  The lock_spinning pvop is expected to block
       the cpu until it has been kicked by the current lock holder.
     - __ticket_spin_unlock, which on releasing a contended lock
       (there are more cpus with tail tickets), it looks to see if the next
       cpu is blocked and wakes it if so.
    
    When compiled with CONFIG_PARAVIRT_SPINLOCKS disabled, a set of stub
    functions causes all the extra code to go away.
    
    Results:
    =======
    setup: 32 core machine with 32 vcpu KVM guest (HT off)  with 8GB RAM
    base = 3.11-rc
    patched = base + pvspinlock V12
    
    +-----------------+----------------+--------+
     dbench (Throughput in MB/sec. Higher is better)
    +-----------------+----------------+--------+
    |   base (stdev %)|patched(stdev%) | %gain  |
    +-----------------+----------------+--------+
    | 15035.3   (0.3) |15150.0   (0.6) |   0.8  |
    |  1470.0   (2.2) | 1713.7   (1.9) |  16.6  |
    |   848.6   (4.3) |  967.8   (4.3) |  14.0  |
    |   652.9   (3.5) |  685.3   (3.7) |   5.0  |
    +-----------------+----------------+--------+
    
    pvspinlock shows benefits for overcommit ratio > 1 for PLE enabled cases,
    and undercommits results are flat
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Link: http://lkml.kernel.org/r/1376058122-8248-2-git-send-email-raghavendra.kt@linux.vnet.ibm.com
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Tested-by: Attilio Rao <attilio.rao@citrix.com>
    [ Raghavendra: Changed SPIN_THRESHOLD, fixed redefinition of arch_spinlock_t]
    Signed-off-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index ad0ad07fc006..83fd3c75d45c 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -1,10 +1,6 @@
 #ifndef _ASM_X86_SPINLOCK_TYPES_H
 #define _ASM_X86_SPINLOCK_TYPES_H
 
-#ifndef __LINUX_SPINLOCK_TYPES_H
-# error "please don't include this file directly"
-#endif
-
 #include <linux/types.h>
 
 #if (CONFIG_NR_CPUS < 256)

commit 7931d493051ea9b09e4fddee2dc40b2eb88d62b9
Author: Jan Beulich <JBeulich@suse.com>
Date:   Fri Feb 3 15:06:26 2012 +0000

    x86/spinlocks: Eliminate TICKET_MASK
    
    The definition of it being questionable already (unnecessarily
    including a cast), and it being used in a single place that can
    be written shorter without it, remove this #define.
    
    Along the same lines, simplify __ticket_spin_is_locked()'s main
    expression, which was the more convoluted way because of needs
    that went away with the recent type changes by Jeremy.
    
    This is pure cleanup, no functional change intended.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Acked-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/4F2C06020200007800071066@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 8ebd5df7451e..ad0ad07fc006 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -16,7 +16,6 @@ typedef u32 __ticketpair_t;
 #endif
 
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
-#define TICKET_MASK	((__ticket_t)((1 << TICKET_SHIFT) - 1))
 
 typedef struct arch_spinlock {
 	union {

commit 229855d6f3b40d01a903120c433d75e483a0b06d
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Tue Jul 13 15:14:26 2010 -0700

    x86, ticketlock: Make __ticket_spin_trylock common
    
    Make trylock code common regardless of ticket size.
    
    (Also, rename arch_spinlock.slock to head_tail.)
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Link: http://lkml.kernel.org/r/4E5BCC40.3030501@goop.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 1c51bd231e49..8ebd5df7451e 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -9,8 +9,10 @@
 
 #if (CONFIG_NR_CPUS < 256)
 typedef u8  __ticket_t;
+typedef u16 __ticketpair_t;
 #else
 typedef u16 __ticket_t;
+typedef u32 __ticketpair_t;
 #endif
 
 #define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
@@ -18,14 +20,14 @@ typedef u16 __ticket_t;
 
 typedef struct arch_spinlock {
 	union {
-		unsigned int slock;
+		__ticketpair_t head_tail;
 		struct __raw_tickets {
 			__ticket_t head, tail;
 		} tickets;
 	};
 } arch_spinlock_t;
 
-#define __ARCH_SPIN_LOCK_UNLOCKED	{ { .slock = 0 } }
+#define __ARCH_SPIN_LOCK_UNLOCKED	{ { 0 } }
 
 #include <asm/rwlock.h>
 

commit 84eb950db13ca40a0572ce9957e14723500943d6
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Fri Jul 2 23:26:36 2010 +0100

    x86, ticketlock: Clean up types and accessors
    
    A few cleanups to the way spinlocks are defined and accessed:
     - define __ticket_t which is the size of a spinlock ticket (ie, enough
       bits to hold all the cpus)
     - Define struct arch_spinlock as a union containing plain slock and
       the head and tail tickets
     - Use head and tail to implement some of the spinlock predicates.
     - Make all ticket variables unsigned.
     - Use TICKET_SHIFT to form constants
    
    Most of this will be used in later patches.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Link: http://lkml.kernel.org/r/4E5BCC40.3030501@goop.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 7c7a486fcb68..1c51bd231e49 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -5,11 +5,27 @@
 # error "please don't include this file directly"
 #endif
 
+#include <linux/types.h>
+
+#if (CONFIG_NR_CPUS < 256)
+typedef u8  __ticket_t;
+#else
+typedef u16 __ticket_t;
+#endif
+
+#define TICKET_SHIFT	(sizeof(__ticket_t) * 8)
+#define TICKET_MASK	((__ticket_t)((1 << TICKET_SHIFT) - 1))
+
 typedef struct arch_spinlock {
-	unsigned int slock;
+	union {
+		unsigned int slock;
+		struct __raw_tickets {
+			__ticket_t head, tail;
+		} tickets;
+	};
 } arch_spinlock_t;
 
-#define __ARCH_SPIN_LOCK_UNLOCKED	{ 0 }
+#define __ARCH_SPIN_LOCK_UNLOCKED	{ { .slock = 0 } }
 
 #include <asm/rwlock.h>
 

commit a750036f35cda160ef77408ec92c3dc41f8feebb
Author: Jan Beulich <JBeulich@novell.com>
Date:   Tue Jul 19 13:00:45 2011 +0100

    x86: Fix write lock scalability 64-bit issue
    
    With the write lock path simply subtracting RW_LOCK_BIAS there
    is, on large systems, the theoretical possibility of overflowing
    the 32-bit value that was used so far (namely if 128 or more
    CPUs manage to do the subtraction, but don't get to do the
    inverse addition in the failure path quickly enough).
    
    A first measure is to modify RW_LOCK_BIAS itself - with the new
    value chosen, it is good for up to 2048 CPUs each allowed to
    nest over 2048 times on the read path without causing an issue.
    Quite possibly it would even be sufficient to adjust the bias a
    little further, assuming that allowing for significantly less
    nesting would suffice.
    
    However, as the original value chosen allowed for even more
    nesting levels, to support more than 2048 CPUs (possible
    currently only for 64-bit kernels) the lock itself gets widened
    to 64 bits.
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/4E258E0D020000780004E3F0@nat28.tlf.novell.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index dcb48b2edc11..7c7a486fcb68 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -11,10 +11,6 @@ typedef struct arch_spinlock {
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ 0 }
 
-typedef struct {
-	unsigned int lock;
-} arch_rwlock_t;
-
-#define __ARCH_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
+#include <asm/rwlock.h>
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit fb3a6bbc912b12347614e5742c7c61416cdb0ca0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 3 20:01:19 2009 +0100

    locking: Convert raw_rwlock to arch_rwlock
    
    Not strictly necessary for -rt as -rt does not have non sleeping
    rwlocks, but it's odd to not have a consistent naming convention.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: linux-arch@vger.kernel.org

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 696f8364a4f3..dcb48b2edc11 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -13,8 +13,8 @@ typedef struct arch_spinlock {
 
 typedef struct {
 	unsigned int lock;
-} raw_rwlock_t;
+} arch_rwlock_t;
 
-#define __RAW_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
+#define __ARCH_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit edc35bd72e2079b25f99c5da7d7a65dbbffc4a26
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 3 12:38:57 2009 +0100

    locking: Rename __RAW_SPIN_LOCK_UNLOCKED to __ARCH_SPIN_LOCK_UNLOCKED
    
    Further name space cleanup. No functional change
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: linux-arch@vger.kernel.org

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 2ae7637ed524..696f8364a4f3 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -9,7 +9,7 @@ typedef struct arch_spinlock {
 	unsigned int slock;
 } arch_spinlock_t;
 
-#define __RAW_SPIN_LOCK_UNLOCKED	{ 0 }
+#define __ARCH_SPIN_LOCK_UNLOCKED	{ 0 }
 
 typedef struct {
 	unsigned int lock;

commit 445c89514be242b1b0080056d50bdc1b72adeb5c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 2 19:49:50 2009 +0100

    locking: Convert raw_spinlock to arch_spinlock
    
    The raw_spin* namespace was taken by lockdep for the architecture
    specific implementations. raw_spin_* would be the ideal name space for
    the spinlocks which are not converted to sleeping locks in preempt-rt.
    
    Linus suggested to convert the raw_ to arch_ locks and cleanup the
    name space instead of using an artifical name like core_spin,
    atomic_spin or whatever
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: linux-arch@vger.kernel.org

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 845f81c87091..2ae7637ed524 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -5,9 +5,9 @@
 # error "please don't include this file directly"
 #endif
 
-typedef struct raw_spinlock {
+typedef struct arch_spinlock {
 	unsigned int slock;
-} raw_spinlock_t;
+} arch_spinlock_t;
 
 #define __RAW_SPIN_LOCK_UNLOCKED	{ 0 }
 

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
index 6aa9b562c508..845f81c87091 100644
--- a/arch/x86/include/asm/spinlock_types.h
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__SPINLOCK_TYPES_H
-#define ASM_X86__SPINLOCK_TYPES_H
+#ifndef _ASM_X86_SPINLOCK_TYPES_H
+#define _ASM_X86_SPINLOCK_TYPES_H
 
 #ifndef __LINUX_SPINLOCK_TYPES_H
 # error "please don't include this file directly"
@@ -17,4 +17,4 @@ typedef struct {
 
 #define __RAW_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
 
-#endif /* ASM_X86__SPINLOCK_TYPES_H */
+#endif /* _ASM_X86_SPINLOCK_TYPES_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/spinlock_types.h b/arch/x86/include/asm/spinlock_types.h
new file mode 100644
index 000000000000..6aa9b562c508
--- /dev/null
+++ b/arch/x86/include/asm/spinlock_types.h
@@ -0,0 +1,20 @@
+#ifndef ASM_X86__SPINLOCK_TYPES_H
+#define ASM_X86__SPINLOCK_TYPES_H
+
+#ifndef __LINUX_SPINLOCK_TYPES_H
+# error "please don't include this file directly"
+#endif
+
+typedef struct raw_spinlock {
+	unsigned int slock;
+} raw_spinlock_t;
+
+#define __RAW_SPIN_LOCK_UNLOCKED	{ 0 }
+
+typedef struct {
+	unsigned int lock;
+} raw_rwlock_t;
+
+#define __RAW_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
+
+#endif /* ASM_X86__SPINLOCK_TYPES_H */
