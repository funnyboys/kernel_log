commit fe557319aa06c23cffc9346000f119547e0f289a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 17 09:37:53 2020 +0200

    maccess: rename probe_kernel_{read,write} to copy_{from,to}_kernel_nofault
    
    Better describe what these functions do.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index ebedeab48704..255b2dde2c1b 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -278,7 +278,7 @@ static inline unsigned long *regs_get_kernel_stack_nth_addr(struct pt_regs *regs
 }
 
 /* To avoid include hell, we can't include uaccess.h */
-extern long probe_kernel_read(void *dst, const void *src, size_t size);
+extern long copy_from_kernel_nofault(void *dst, const void *src, size_t size);
 
 /**
  * regs_get_kernel_stack_nth() - get Nth entry of the stack
@@ -298,7 +298,7 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 
 	addr = regs_get_kernel_stack_nth_addr(regs, n);
 	if (addr) {
-		ret = probe_kernel_read(&val, addr, sizeof(val));
+		ret = copy_from_kernel_nofault(&val, addr, sizeof(val));
 		if (!ret)
 			return val;
 	}

commit 4979fb53ab0ed35eddd20a73c25a5597bc22a57f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jan 21 15:53:09 2020 +0100

    x86/int3: Ensure that poke_int3_handler() is not traced
    
    In order to ensure poke_int3_handler() is completely self contained -- this
    is called while modifying other text, imagine the fun of hitting another
    INT3 -- ensure that everything it uses is not traced.
    
    The primary means here is to force inlining; bsearch() is notrace because
    all of lib/ is.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexandre Chartre <alexandre.chartre@oracle.com>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20200505135313.410702173@linutronix.de

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6d6475fdd327..ebedeab48704 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -123,7 +123,7 @@ static inline void regs_set_return_value(struct pt_regs *regs, unsigned long rc)
  * On x86_64, vm86 mode is mercifully nonexistent, and we don't need
  * the extra check.
  */
-static inline int user_mode(struct pt_regs *regs)
+static __always_inline int user_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32
 	return ((regs->cs & SEGMENT_RPL_MASK) | (regs->flags & X86_VM_MASK)) >= USER_RPL;

commit f6170f0afbe23ad82b4a1195168949c31e3a2527
Merge: 6da49d1abd2c 248ed51048c4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 28 12:28:06 2020 -0800

    Merge branch 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull misc x86 updates from Ingo Molnar:
     "Misc changes:
    
       - Enhance #GP fault printouts by distinguishing between canonical and
         non-canonical address faults, and also add KASAN fault decoding.
    
       - Fix/enhance the x86 NMI handler by putting the duration check into
         a direct function call instead of an irq_work which we know to be
         broken in some cases.
    
       - Clean up do_general_protection() a bit"
    
    * 'x86-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/nmi: Remove irq_work from the long duration NMI handler
      x86/traps: Cleanup do_general_protection()
      x86/kasan: Print original address on #GP
      x86/dumpstack: Introduce die_addr() for die() with #GP fault address
      x86/traps: Print address on #GP
      x86/insn-eval: Add support for 64-bit kernel mode

commit 2b10906f2d25515bba58070b8183babc89063597
Author: Brian Gerst <brgerst@gmail.com>
Date:   Thu Dec 19 06:58:12 2019 -0500

    x86: Remove force_iret()
    
    force_iret() was originally intended to prevent the return to user mode with
    the SYSRET or SYSEXIT instructions, in cases where the register state could
    have been changed to be incompatible with those instructions.  The entry code
    has been significantly reworked since then, and register state is validated
    before SYSRET or SYSEXIT are used.  force_iret() no longer serves its original
    purpose and can be eliminated.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Link: https://lkml.kernel.org/r/20191219115812.102620-1-brgerst@gmail.com

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 5057a8ed100b..78897a8da01f 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -339,22 +339,6 @@ static inline unsigned long regs_get_kernel_argument(struct pt_regs *regs,
 
 #define ARCH_HAS_USER_SINGLE_STEP_REPORT
 
-/*
- * When hitting ptrace_stop(), we cannot return using SYSRET because
- * that does not restore the full CPU state, only a minimal set.  The
- * ptracer can change arbitrary register values, which is usually okay
- * because the usual ptrace stops run off the signal delivery path which
- * forces IRET; however, ptrace_event() stops happen in arbitrary places
- * in the kernel and don't force IRET path.
- *
- * So force IRET path after a ptrace stop.
- */
-#define arch_ptrace_stop_needed(code, info)				\
-({									\
-	force_iret();							\
-	false;								\
-})
-
 struct user_desc;
 extern int do_get_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info);

commit 7be4412721aee25e35583a20a896085dc6b99c3e
Author: Jann Horn <jannh@google.com>
Date:   Thu Dec 19 00:11:47 2019 +0100

    x86/insn-eval: Add support for 64-bit kernel mode
    
    To support evaluating 64-bit kernel mode instructions:
    
    * Replace existing checks for user_64bit_mode() with a new helper that
    checks whether code is being executed in either 64-bit kernel mode or
    64-bit user mode.
    
    * Select the GS base depending on whether the instruction is being
    evaluated in kernel mode.
    
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: "Gustavo A. R. Silva" <gustavo@embeddedor.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: kasan-dev@googlegroups.com
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20191218231150.12139-1-jannh@google.com

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 5057a8ed100b..ac45b06941a5 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -159,6 +159,19 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 #endif
 }
 
+/*
+ * Determine whether the register set came from any context that is running in
+ * 64-bit mode.
+ */
+static inline bool any_64bit_mode(struct pt_regs *regs)
+{
+#ifdef CONFIG_X86_64
+	return !user_mode(regs) || user_64bit_mode(regs);
+#else
+	return false;
+#endif
+}
+
 #ifdef CONFIG_X86_64
 #define current_user_stack_pointer()	current_pt_regs()->sp
 #define compat_user_stack_pointer()	current_pt_regs()->sp

commit 2fff071d28b54f050f62654dad4ec111b8416d8e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Nov 11 23:03:16 2019 +0100

    x86/process: Unify copy_thread_tls()
    
    While looking at the TSS io bitmap it turned out that any change in that
    area would require identical changes to copy_thread_tls(). The 32 and 64
    bit variants share sufficient code to consolidate them into a common
    function to avoid duplication of upcoming modifications.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 332eb3525867..5057a8ed100b 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -361,5 +361,11 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
+#ifdef CONFIG_X86_64
+# define do_set_thread_area_64(p, s, t)	do_arch_prctl_64(p, s, t)
+#else
+# define do_set_thread_area_64(p, s, t)	(0)
+#endif
+
 #endif /* !__ASSEMBLY__ */
 #endif /* _ASM_X86_PTRACE_H */

commit 5f26f1143678d0fed8115afdcc0de99ee7cc9675
Merge: aabfea8dc91c 7f3a8dff1219
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 12 15:41:33 2019 -0700

    Merge tag 'asm-generic-5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic
    
    Pull asm-generic updates from Arnd Bergmann:
     "The asm-generic changes for 5.3 consist of a cleanup series to remove
      ptrace.h from Christoph Hellwig, who explains:
    
        'asm-generic/ptrace.h is a little weird in that it doesn't actually
         implement any functionality, but it provided multiple layers of
         macros that just implement trivial inline functions. We implement
         those directly in the few architectures and be off with a much
         simpler design.'
    
      at https://lore.kernel.org/lkml/20190624054728.30966-1-hch@lst.de/"
    
    * tag 'asm-generic-5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic:
      asm-generic: remove ptrace.h
      x86: don't use asm-generic/ptrace.h
      sh: don't use asm-generic/ptrace.h
      powerpc: don't use asm-generic/ptrace.h
      arm64: don't use asm-generic/ptrace.h

commit 5ad18b2e60b75c7297a998dea702451d33a052ed
Merge: 92c1d6522135 318759b4737c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:48:15 2019 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull force_sig() argument change from Eric Biederman:
     "A source of error over the years has been that force_sig has taken a
      task parameter when it is only safe to use force_sig with the current
      task.
    
      The force_sig function is built for delivering synchronous signals
      such as SIGSEGV where the userspace application caused a synchronous
      fault (such as a page fault) and the kernel responded with a signal.
    
      Because the name force_sig does not make this clear, and because the
      force_sig takes a task parameter the function force_sig has been
      abused for sending other kinds of signals over the years. Slowly those
      have been fixed when the oopses have been tracked down.
    
      This set of changes fixes the remaining abusers of force_sig and
      carefully rips out the task parameter from force_sig and friends
      making this kind of error almost impossible in the future"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (27 commits)
      signal/x86: Move tsk inside of CONFIG_MEMORY_FAILURE in do_sigbus
      signal: Remove the signal number and task parameters from force_sig_info
      signal: Factor force_sig_info_to_task out of force_sig_info
      signal: Generate the siginfo in force_sig
      signal: Move the computation of force into send_signal and correct it.
      signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
      signal: Remove the task parameter from force_sig_fault
      signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
      signal: Explicitly call force_sig_fault on current
      signal/unicore32: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from ptrace_break
      signal/nds32: Remove tsk parameter from send_sigtrap
      signal/riscv: Remove tsk parameter from do_trap
      signal/sh: Remove tsk parameter from force_sig_info_fault
      signal/um: Remove task parameter from send_sigtrap
      signal/x86: Remove task parameter from send_sigtrap
      signal: Remove task parameter from force_sig_mceerr
      signal: Remove task parameter from force_sig
      signal: Remove task parameter from force_sigsegv
      ...

commit 79f2562c326e0731f9c9f089d47c89399ad732e2
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 24 07:47:27 2019 +0200

    x86: don't use asm-generic/ptrace.h
    
    Doing the indirection through macros for the regs accessors just
    makes them harder to read, so implement the helpers directly.
    
    Note that only the helpers actually used are implemented now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 8a7fc0cca2d1..e22816e865ca 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -98,7 +98,6 @@ struct cpuinfo_x86;
 struct task_struct;
 
 extern unsigned long profile_pc(struct pt_regs *regs);
-#define profile_pc profile_pc
 
 extern unsigned long
 convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
@@ -175,11 +174,32 @@ static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
 }
 #endif
 
-#define GET_IP(regs) ((regs)->ip)
-#define GET_FP(regs) ((regs)->bp)
-#define GET_USP(regs) ((regs)->sp)
+static inline unsigned long instruction_pointer(struct pt_regs *regs)
+{
+	return regs->ip;
+}
+
+static inline void instruction_pointer_set(struct pt_regs *regs,
+		unsigned long val)
+{
+	regs->ip = val;
+}
+
+static inline unsigned long frame_pointer(struct pt_regs *regs)
+{
+	return regs->bp;
+}
 
-#include <asm-generic/ptrace.h>
+static inline unsigned long user_stack_pointer(struct pt_regs *regs)
+{
+	return regs->sp;
+}
+
+static inline void user_stack_pointer_set(struct pt_regs *regs,
+		unsigned long val)
+{
+	regs->sp = val;
+}
 
 /* Query offset/name of register from its name/offset */
 extern int regs_query_register_offset(const char *name);

commit 3c88c692c28746473791276f8b42d2c989d6cbe6
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue May 7 23:25:54 2019 +0200

    x86/stackframe/32: Provide consistent pt_regs
    
    Currently pt_regs on x86_32 has an oddity in that kernel regs
    (!user_mode(regs)) are short two entries (esp/ss). This means that any
    code trying to use them (typically: regs->sp) needs to jump through
    some unfortunate hoops.
    
    Change the entry code to fix this up and create a full pt_regs frame.
    
    This then simplifies various trampolines in ftrace and kprobes, the
    stack unwinder, ptrace, kdump and kgdb.
    
    Much thanks to Josh for help with the cleanups!
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 8a7fc0cca2d1..3703c91f441e 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -166,14 +166,10 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 #define compat_user_stack_pointer()	current_pt_regs()->sp
 #endif
 
-#ifdef CONFIG_X86_32
-extern unsigned long kernel_stack_pointer(struct pt_regs *regs);
-#else
 static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
 {
 	return regs->sp;
 }
-#endif
 
 #define GET_IP(regs) ((regs)->ip)
 #define GET_FP(regs) ((regs)->bp)
@@ -201,14 +197,6 @@ static inline unsigned long regs_get_register(struct pt_regs *regs,
 	if (unlikely(offset > MAX_REG_OFFSET))
 		return 0;
 #ifdef CONFIG_X86_32
-	/*
-	 * Traps from the kernel do not save sp and ss.
-	 * Use the helper function to retrieve sp.
-	 */
-	if (offset == offsetof(struct pt_regs, sp) &&
-	    regs->cs == __KERNEL_CS)
-		return kernel_stack_pointer(regs);
-
 	/* The selector fields are 16-bit. */
 	if (offset == offsetof(struct pt_regs, cs) ||
 	    offset == offsetof(struct pt_regs, ss) ||
@@ -234,8 +222,7 @@ static inline unsigned long regs_get_register(struct pt_regs *regs,
 static inline int regs_within_kernel_stack(struct pt_regs *regs,
 					   unsigned long addr)
 {
-	return ((addr & ~(THREAD_SIZE - 1))  ==
-		(kernel_stack_pointer(regs) & ~(THREAD_SIZE - 1)));
+	return ((addr & ~(THREAD_SIZE - 1)) == (regs->sp & ~(THREAD_SIZE - 1)));
 }
 
 /**
@@ -249,7 +236,7 @@ static inline int regs_within_kernel_stack(struct pt_regs *regs,
  */
 static inline unsigned long *regs_get_kernel_stack_nth_addr(struct pt_regs *regs, unsigned int n)
 {
-	unsigned long *addr = (unsigned long *)kernel_stack_pointer(regs);
+	unsigned long *addr = (unsigned long *)regs->sp;
 
 	addr += n;
 	if (regs_within_kernel_stack(regs, (unsigned long)addr))

commit 28d42ea14e489047caeaa89496a3ad7e0ae6a49f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 5 18:25:11 2019 -0600

    signal/x86: Remove task parameter from send_sigtrap
    
    The send_sigtrap function is always called with task == current.  Make
    that explicit by removing the task parameter.
    
    This also makes it clear that the x86 send_sigtrap passes current
    into force_sig_fault.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 8a7fc0cca2d1..28779bf7951f 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -102,8 +102,7 @@ extern unsigned long profile_pc(struct pt_regs *regs);
 
 extern unsigned long
 convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
-extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs,
-			 int error_code, int si_code);
+extern void send_sigtrap(struct pt_regs *regs, int error_code, int si_code);
 
 
 static inline unsigned long regs_return_value(struct pt_regs *regs)

commit 343a9f35409b68b6de66ecd0db90a277aee90ec2
Merge: f4267b3604a8 a2acce536921
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 30 09:49:56 2018 -0700

    Merge tag 'trace-v4.20' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull tracing updates from Steven Rostedt:
     "The biggest change here is the updates to kprobes
    
      Back in January I posted patches to create function based events.
      These were the events that you suggested I make to allow developers to
      easily create events in code where no trace event exists. After
      posting those changes for review, it was suggested that we implement
      this instead with kprobes.
    
      The problem with kprobes is that the interface is too complex and
      needs to be simplified. Masami Hiramatsu posted patches in March and
      I've been playing with them a bit. There's been a bit of clean up in
      the kprobe code that was inspired by the function based event patches,
      and a couple of enhancements to the kprobe event interface.
    
       - If the arch supports it (we added support for x86), you can place a
         kprobe event at the start of a function and use $arg1, $arg2, etc
         to reference the arguments of a function. (Before you needed to
         know what register or where on the stack the argument was).
    
       - The second is a way to see array of events. For example, if you
         reference a mac address, you can add:
    
            echo 'p:mac ip_rcv perm_addr=+574($arg2):x8[6]' > kprobe_events
    
         And this will produce:
    
            mac: (ip_rcv+0x0/0x140) perm_addr={0x52,0x54,0x0,0xc0,0x76,0xec}
    
      Other changes include
    
       - Exporting trace_dump_stack to modules
    
       - Have the stack tracer trace the entire stack (stop trying to remove
         tracing itself, as we keep removing too much).
    
       - Added support for SDT in uprobes"
    
    [ SDT - "Statically Defined Tracing" are userspace markers for tracing.
      Let's not use random TLA's in explanations unless they are fairly
      well-established as generic (at least for kernel people) - Linus ]
    
    * tag 'trace-v4.20' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace: (24 commits)
      tracing: Have stack tracer trace full stack
      tracing: Export trace_dump_stack to modules
      tracing: probeevent: Fix uninitialized used of offset in parse args
      tracing/kprobes: Allow kprobe-events to record module symbol
      tracing/kprobes: Check the probe on unloaded module correctly
      tracing/uprobes: Fix to return -EFAULT if copy_from_user failed
      tracing: probeevent: Add $argN for accessing function args
      x86: ptrace: Add function argument access API
      tracing: probeevent: Add array type support
      tracing: probeevent: Add symbol type
      tracing: probeevent: Unify fetch_insn processing common part
      tracing: probeevent: Append traceprobe_ for exported function
      tracing: probeevent: Return consumed bytes of dynamic area
      tracing: probeevent: Unify fetch type tables
      tracing: probeevent: Introduce new argument fetching code
      tracing: probeevent: Remove NOKPROBE_SYMBOL from print functions
      tracing: probeevent: Cleanup argument field definition
      tracing: probeevent: Cleanup print argument functions
      trace_uprobe: support reference counter in fd-based uprobe
      perf probe: Support SDT markers having reference counter (semaphore)
      ...

commit ba9f6f8954afa5224e3ed60332f7b92242b7ed0f
Merge: a978a5b8d83f a36700589b85
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 24 11:22:39 2018 +0100

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull siginfo updates from Eric Biederman:
     "I have been slowly sorting out siginfo and this is the culmination of
      that work.
    
      The primary result is in several ways the signal infrastructure has
      been made less error prone. The code has been updated so that manually
      specifying SEND_SIG_FORCED is never necessary. The conversion to the
      new siginfo sending functions is now complete, which makes it
      difficult to send a signal without filling in the proper siginfo
      fields.
    
      At the tail end of the patchset comes the optimization of decreasing
      the size of struct siginfo in the kernel from 128 bytes to about 48
      bytes on 64bit. The fundamental observation that enables this is by
      definition none of the known ways to use struct siginfo uses the extra
      bytes.
    
      This comes at the cost of a small user space observable difference.
      For the rare case of siginfo being injected into the kernel only what
      can be copied into kernel_siginfo is delivered to the destination, the
      rest of the bytes are set to 0. For cases where the signal and the
      si_code are known this is safe, because we know those bytes are not
      used. For cases where the signal and si_code combination is unknown
      the bits that won't fit into struct kernel_siginfo are tested to
      verify they are zero, and the send fails if they are not.
    
      I made an extensive search through userspace code and I could not find
      anything that would break because of the above change. If it turns out
      I did break something it will take just the revert of a single change
      to restore kernel_siginfo to the same size as userspace siginfo.
    
      Testing did reveal dependencies on preferring the signo passed to
      sigqueueinfo over si->signo, so bit the bullet and added the
      complexity necessary to handle that case.
    
      Testing also revealed bad things can happen if a negative signal
      number is passed into the system calls. Something no sane application
      will do but something a malicious program or a fuzzer might do. So I
      have fixed the code that performs the bounds checks to ensure negative
      signal numbers are handled"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (80 commits)
      signal: Guard against negative signal numbers in copy_siginfo_from_user32
      signal: Guard against negative signal numbers in copy_siginfo_from_user
      signal: In sigqueueinfo prefer sig not si_signo
      signal: Use a smaller struct siginfo in the kernel
      signal: Distinguish between kernel_siginfo and siginfo
      signal: Introduce copy_siginfo_from_user and use it's return value
      signal: Remove the need for __ARCH_SI_PREABLE_SIZE and SI_PAD_SIZE
      signal: Fail sigqueueinfo if si_signo != sig
      signal/sparc: Move EMT_TAGOVF into the generic siginfo.h
      signal/unicore32: Use force_sig_fault where appropriate
      signal/unicore32: Generate siginfo in ucs32_notify_die
      signal/unicore32: Use send_sig_fault where appropriate
      signal/arc: Use force_sig_fault where appropriate
      signal/arc: Push siginfo generation into unhandled_exception
      signal/ia64: Use force_sig_fault where appropriate
      signal/ia64: Use the force_sig(SIGSEGV,...) in ia64_rt_sigreturn
      signal/ia64: Use the generic force_sigsegv in setup_frame
      signal/arm/kvm: Use send_sig_mceerr
      signal/arm: Use send_sig_fault where appropriate
      signal/arm: Use force_sig_fault where appropriate
      ...

commit f682a7920baf7b721d01dd317f3b532265357cbb
Merge: 99792e0cea1e 3a025de64bf8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 23 17:54:58 2018 +0100

    Merge branch 'x86-paravirt-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 paravirt updates from Ingo Molnar:
     "Two main changes:
    
       - Remove no longer used parts of the paravirt infrastructure and put
         large quantities of paravirt ops under a new config option
         PARAVIRT_XXL=y, which is selected by XEN_PV only. (Joergen Gross)
    
       - Enable PV spinlocks on Hyperv (Yi Sun)"
    
    * 'x86-paravirt-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/hyperv: Enable PV qspinlock for Hyper-V
      x86/hyperv: Add GUEST_IDLE_MSR support
      x86/paravirt: Clean up native_patch()
      x86/paravirt: Prevent redefinition of SAVE_FLAGS macro
      x86/xen: Make xen_reservation_lock static
      x86/paravirt: Remove unneeded mmu related paravirt ops bits
      x86/paravirt: Move the Xen-only pv_mmu_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move the pv_irq_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move the Xen-only pv_cpu_ops under the PARAVIRT_XXL umbrella
      x86/paravirt: Move items in pv_info under PARAVIRT_XXL umbrella
      x86/paravirt: Introduce new config option PARAVIRT_XXL
      x86/paravirt: Remove unused paravirt bits
      x86/paravirt: Use a single ops structure
      x86/paravirt: Remove clobbers from struct paravirt_patch_site
      x86/paravirt: Remove clobbers parameter from paravirt patch functions
      x86/paravirt: Make paravirt_patch_call() and paravirt_patch_jmp() static
      x86/xen: Add SPDX identifier in arch/x86/xen files
      x86/xen: Link platform-pci-unplug.o only if CONFIG_XEN_PVHVM
      x86/xen: Move pv specific parts of arch/x86/xen/mmu.c to mmu_pv.c
      x86/xen: Move pv irq related functions under CONFIG_XEN_PV umbrella

commit c05f3642f4304dd081876e77a68555b6aba4483f
Merge: 0200fbdd4315 dda93b45389f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 23 13:32:18 2018 +0100

    Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf updates from Ingo Molnar:
     "The main updates in this cycle were:
    
       - Lots of perf tooling changes too voluminous to list (big perf trace
         and perf stat improvements, lots of libtraceevent reorganization,
         etc.), so I'll list the authors and refer to the changelog for
         details:
    
           Benjamin Peterson, Jérémie Galarneau, Kim Phillips, Peter
           Zijlstra, Ravi Bangoria, Sangwon Hong, Sean V Kelley, Steven
           Rostedt, Thomas Gleixner, Ding Xiang, Eduardo Habkost, Thomas
           Richter, Andi Kleen, Sanskriti Sharma, Adrian Hunter, Tzvetomir
           Stoyanov, Arnaldo Carvalho de Melo, Jiri Olsa.
    
         ... with the bulk of the changes written by Jiri Olsa, Tzvetomir
         Stoyanov and Arnaldo Carvalho de Melo.
    
       - Continued intel_rdt work with a focus on playing well with perf
         events. This also imported some non-perf RDT work due to
         dependencies. (Reinette Chatre)
    
       - Implement counter freezing for Arch Perfmon v4 (Skylake and newer).
         This allows to speed up the PMI handler by avoiding unnecessary MSR
         writes and make it more accurate. (Andi Kleen)
    
       - kprobes cleanups and simplification (Masami Hiramatsu)
    
       - Intel Goldmont PMU updates (Kan Liang)
    
       - ... plus misc other fixes and updates"
    
    * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (155 commits)
      kprobes/x86: Use preempt_enable() in optimized_callback()
      x86/intel_rdt: Prevent pseudo-locking from using stale pointers
      kprobes, x86/ptrace.h: Make regs_get_kernel_stack_nth() not fault on bad stack
      perf/x86/intel: Export mem events only if there's PEBS support
      x86/cpu: Drop pointless static qualifier in punit_dev_state_show()
      x86/intel_rdt: Fix initial allocation to consider CDP
      x86/intel_rdt: CBM overlap should also check for overlap with CDP peer
      x86/intel_rdt: Introduce utility to obtain CDP peer
      tools lib traceevent, perf tools: Move struct tep_handler definition in a local header file
      tools lib traceevent: Separate out tep_strerror() for strerror_r() issues
      perf python: More portable way to make CFLAGS work with clang
      perf python: Make clang_has_option() work on Python 3
      perf tools: Free temporary 'sys' string in read_event_files()
      perf tools: Avoid double free in read_event_file()
      perf tools: Free 'printk' string in parse_ftrace_printk()
      perf tools: Cleanup trace-event-info 'tdata' leak
      perf strbuf: Match va_{add,copy} with va_end
      perf test: S390 does not support watchpoints in test 22
      perf auxtrace: Include missing asm/bitsperlong.h to get BITS_PER_LONG
      tools include: Adopt linux/bits.h
      ...

commit c2712b858187f5bcd7b042fe4daa3ba3a12635c0
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Wed Oct 17 16:59:51 2018 -0400

    kprobes, x86/ptrace.h: Make regs_get_kernel_stack_nth() not fault on bad stack
    
    Andy had some concerns about using regs_get_kernel_stack_nth() in a new
    function regs_get_kernel_argument() as if there's any error in the stack
    code, it could cause a bad memory access. To be on the safe side, call
    probe_kernel_read() on the stack address to be extra careful in accessing
    the memory. A helper function, regs_get_kernel_stack_nth_addr(), was added
    to just return the stack address (or NULL if not on the stack), that will be
    used to find the address (and could be used by other functions) and read the
    address with kernel_probe_read().
    
    Requested-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Reviewed-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20181017165951.09119177@gandalf.local.home
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6de1fd3d0097..ee696efec99f 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -236,24 +236,52 @@ static inline int regs_within_kernel_stack(struct pt_regs *regs,
 		(kernel_stack_pointer(regs) & ~(THREAD_SIZE - 1)));
 }
 
+/**
+ * regs_get_kernel_stack_nth_addr() - get the address of the Nth entry on stack
+ * @regs:	pt_regs which contains kernel stack pointer.
+ * @n:		stack entry number.
+ *
+ * regs_get_kernel_stack_nth() returns the address of the @n th entry of the
+ * kernel stack which is specified by @regs. If the @n th entry is NOT in
+ * the kernel stack, this returns NULL.
+ */
+static inline unsigned long *regs_get_kernel_stack_nth_addr(struct pt_regs *regs, unsigned int n)
+{
+	unsigned long *addr = (unsigned long *)kernel_stack_pointer(regs);
+
+	addr += n;
+	if (regs_within_kernel_stack(regs, (unsigned long)addr))
+		return addr;
+	else
+		return NULL;
+}
+
+/* To avoid include hell, we can't include uaccess.h */
+extern long probe_kernel_read(void *dst, const void *src, size_t size);
+
 /**
  * regs_get_kernel_stack_nth() - get Nth entry of the stack
  * @regs:	pt_regs which contains kernel stack pointer.
  * @n:		stack entry number.
  *
  * regs_get_kernel_stack_nth() returns @n th entry of the kernel stack which
- * is specified by @regs. If the @n th entry is NOT in the kernel stack,
+ * is specified by @regs. If the @n th entry is NOT in the kernel stack
  * this returns 0.
  */
 static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 						      unsigned int n)
 {
-	unsigned long *addr = (unsigned long *)kernel_stack_pointer(regs);
-	addr += n;
-	if (regs_within_kernel_stack(regs, (unsigned long)addr))
-		return *addr;
-	else
-		return 0;
+	unsigned long *addr;
+	unsigned long val;
+	long ret;
+
+	addr = regs_get_kernel_stack_nth_addr(regs, n);
+	if (addr) {
+		ret = probe_kernel_read(&val, addr, sizeof(val));
+		if (!ret)
+			return val;
+	}
+	return 0;
 }
 
 #define arch_has_single_step()	(1)

commit 3c88ee194c288205733d248b51f0aca516ff4940
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Wed Apr 25 21:20:57 2018 +0900

    x86: ptrace: Add function argument access API
    
    Add regs_get_argument() which returns N th argument of the
    function call.
    Note that this chooses most probably assignment, in some case
    it can be incorrect (e.g. passing data structure or floating
    point etc.)
    
    This is expected to be called from kprobes or ftrace with regs
    where the top of stack is the return address.
    
    Link: http://lkml.kernel.org/r/152465885737.26224.2822487520472783854.stgit@devbox
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6de1fd3d0097..c2304b25e2fd 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -256,6 +256,44 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 		return 0;
 }
 
+/**
+ * regs_get_kernel_argument() - get Nth function argument in kernel
+ * @regs:	pt_regs of that context
+ * @n:		function argument number (start from 0)
+ *
+ * regs_get_argument() returns @n th argument of the function call.
+ * Note that this chooses most probably assignment, in some case
+ * it can be incorrect.
+ * This is expected to be called from kprobes or ftrace with regs
+ * where the top of stack is the return address.
+ */
+static inline unsigned long regs_get_kernel_argument(struct pt_regs *regs,
+						     unsigned int n)
+{
+	static const unsigned int argument_offs[] = {
+#ifdef __i386__
+		offsetof(struct pt_regs, ax),
+		offsetof(struct pt_regs, cx),
+		offsetof(struct pt_regs, dx),
+#define NR_REG_ARGUMENTS 3
+#else
+		offsetof(struct pt_regs, di),
+		offsetof(struct pt_regs, si),
+		offsetof(struct pt_regs, dx),
+		offsetof(struct pt_regs, cx),
+		offsetof(struct pt_regs, r8),
+		offsetof(struct pt_regs, r9),
+#define NR_REG_ARGUMENTS 6
+#endif
+	};
+
+	if (n >= NR_REG_ARGUMENTS) {
+		n -= NR_REG_ARGUMENTS - 1;
+		return regs_get_kernel_stack_nth(regs, n);
+	} else
+		return regs_get_register(regs, argument_offs[n]);
+}
+
 #define arch_has_single_step()	(1)
 #ifdef CONFIG_X86_DEBUGCTLMSR
 #define arch_has_block_step()	(1)

commit efc463adbccf709c5dbaf6cfbf84b7e94b62810a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 16 14:18:26 2018 -0500

    signal: Simplify tracehook_report_syscall_exit
    
    Replace user_single_step_siginfo with user_single_step_report
    that allocates siginfo structure on the stack and sends it.
    
    This allows tracehook_report_syscall_exit to become a simple
    if statement that calls user_single_step_report or ptrace_report_syscall
    depending on the value of step.
    
    Update the default helper function now called user_single_step_report
    to explicitly set si_code to SI_USER and to set si_uid and si_pid to 0.
    The default helper has always been doing this (using memset) but it
    was far from obvious.
    
    The powerpc helper can now just call force_sig_fault.
    The x86 helper can now just call send_sigtrap.
    
    Unfortunately the default implementation of user_single_step_report
    can not use force_sig_fault as it does not use a SIGTRAP si_code.
    So it has to carefully setup the siginfo and use use force_sig_info.
    
    The net result is code that is easier to understand and simpler
    to maintain.
    
    Ref: 85ec7fd9f8e5 ("ptrace: introduce user_single_step_siginfo() helper")
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6de1fd3d0097..e353f08b7fe2 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -263,7 +263,7 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 #define arch_has_block_step()	(boot_cpu_data.x86 >= 6)
 #endif
 
-#define ARCH_HAS_USER_SINGLE_STEP_INFO
+#define ARCH_HAS_USER_SINGLE_STEP_REPORT
 
 /*
  * When hitting ptrace_stop(), we cannot return using SYSRET because

commit 40181646db45fb72f46563a2f3b792adc5380710
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:22 2018 +0200

    x86/paravirt: Move items in pv_info under PARAVIRT_XXL umbrella
    
    All items but name in pv_info are needed by Xen PV only. Define them
    with CONFIG_PARAVIRT_XXL set only.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-12-jgross@suse.com

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6de1fd3d0097..250be50aa257 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -144,7 +144,7 @@ static inline int v8086_mode(struct pt_regs *regs)
 static inline bool user_64bit_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_64
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_XXL
 	/*
 	 * On non-paravirt systems, this is the only long mode CPL 3
 	 * selector.  We do not allow long mode selectors in the LDT.

commit 81fd9c18444ed1199b5a6f6776a395292d4256fb
Author: Jann Horn <jannh@google.com>
Date:   Tue Aug 28 22:14:19 2018 +0200

    x86/fault: Plumb error code and fault address through to fault handlers
    
    This is preparation for looking at trap number and fault address in the
    handlers for uaccess errors. No functional change.
    
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: kernel-hardening@lists.openwall.com
    Cc: linux-kernel@vger.kernel.org
    Cc: dvyukov@google.com
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: "Naveen N. Rao" <naveen.n.rao@linux.vnet.ibm.com>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: linux-fsdevel@vger.kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Link: https://lkml.kernel.org/r/20180828201421.157735-6-jannh@google.com

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6de1fd3d0097..5e58a74bfd3a 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -37,8 +37,10 @@ struct pt_regs {
 	unsigned short __esh;
 	unsigned short fs;
 	unsigned short __fsh;
+	/* On interrupt, gs and __gsh store the vector number. */
 	unsigned short gs;
 	unsigned short __gsh;
+	/* On interrupt, this is the error code. */
 	unsigned long orig_ax;
 	unsigned long ip;
 	unsigned short cs;

commit 9802d86585db91655c7d1929a4f6bbe0952ea88e
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 11 11:36:48 2017 -0500

    bpf: add a bpf_override_function helper
    
    Error injection is sloppy and very ad-hoc.  BPF could fill this niche
    perfectly with it's kprobe functionality.  We could make sure errors are
    only triggered in specific call chains that we care about with very
    specific situations.  Accomplish this with the bpf_override_funciton
    helper.  This will modify the probe'd callers return value to the
    specified value and set the PC to an override function that simply
    returns, bypassing the originally probed function.  This gives us a nice
    clean way to implement systematic error injection for all of our code
    paths.
    
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 14131dd06b29..6de1fd3d0097 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -109,6 +109,11 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 	return regs->ax;
 }
 
+static inline void regs_set_return_value(struct pt_regs *regs, unsigned long rc)
+{
+	regs->ax = rc;
+}
+
 /*
  * user_mode(regs) determines whether a register set came from user
  * mode.  On x86_32, this is true if V8086 mode was enabled OR if the

commit b3d9a136815ca9284ade2a897a3b7d2b0084c33c
Merge: c7da092a1f24 e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:53:06 2017 +0100

    Merge branch 'linus' into x86/asm, to pick up fixes and resolve conflicts
    
    Conflicts:
            arch/x86/kernel/cpu/Makefile
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 91c04c8e67fa..c0e3c45cf6ab 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_X86_PTRACE_H
 #define _ASM_X86_PTRACE_H
 

commit e27c310af5c05cf876d9cad006928076c27f54d4
Author: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
Date:   Fri Oct 27 13:25:30 2017 -0700

    ptrace,x86: Make user_64bit_mode() available to 32-bit builds
    
    In its current form, user_64bit_mode() can only be used when CONFIG_X86_64
    is selected. This implies that code built with CONFIG_X86_64=n cannot use
    it. If a piece of code needs to be built for both CONFIG_X86_64=y and
    CONFIG_X86_64=n and wants to use this function, it needs to wrap it in
    an #ifdef/#endif; potentially, in multiple places.
    
    This can be easily avoided with a single #ifdef/#endif pair within
    user_64bit_mode() itself.
    
    Suggested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: ricardo.neri@intel.com
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Huang Rui <ray.huang@amd.com>
    Cc: Qiaowei Ren <qiaowei.ren@intel.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: "Ravi V. Shankar" <ravi.v.shankar@intel.com>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Colin Ian King <colin.king@canonical.com>
    Cc: Chen Yucong <slaoub@gmail.com>
    Cc: Adam Buchbinder <adam.buchbinder@gmail.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Lorenzo Stoakes <lstoakes@gmail.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Thomas Garnier <thgarnie@google.com>
    Link: https://lkml.kernel.org/r/1509135945-13762-4-git-send-email-ricardo.neri-calderon@linux.intel.com

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 91c04c8e67fa..e2afbf689309 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -135,9 +135,9 @@ static inline int v8086_mode(struct pt_regs *regs)
 #endif
 }
 
-#ifdef CONFIG_X86_64
 static inline bool user_64bit_mode(struct pt_regs *regs)
 {
+#ifdef CONFIG_X86_64
 #ifndef CONFIG_PARAVIRT
 	/*
 	 * On non-paravirt systems, this is the only long mode CPL 3
@@ -148,8 +148,12 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 	/* Headers are too twisted for this to go in paravirt.h. */
 	return regs->cs == __USER_CS || regs->cs == pv_info.extra_user_64bit_cs;
 #endif
+#else /* !CONFIG_X86_64 */
+	return false;
+#endif
 }
 
+#ifdef CONFIG_X86_64
 #define current_user_stack_pointer()	current_pt_regs()->sp
 #define compat_user_stack_pointer()	current_pt_regs()->sp
 #endif

commit 603e492e861861ddfec7139a007abad74f0d3af0
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Aug 9 14:39:45 2017 -0700

    x86/asm/32: Fix regs_get_register() on segment registers
    
    The segment register high words on x86_32 may contain garbage.
    Teach regs_get_register() to read them as u16 instead of unsigned
    long.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/0b76f6dbe477b7b1a81938fddcc3c483d48f0ff2.1502314765.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index a29f82871699..91c04c8e67fa 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -196,6 +196,17 @@ static inline unsigned long regs_get_register(struct pt_regs *regs,
 	if (offset == offsetof(struct pt_regs, sp) &&
 	    regs->cs == __KERNEL_CS)
 		return kernel_stack_pointer(regs);
+
+	/* The selector fields are 16-bit. */
+	if (offset == offsetof(struct pt_regs, cs) ||
+	    offset == offsetof(struct pt_regs, ss) ||
+	    offset == offsetof(struct pt_regs, ds) ||
+	    offset == offsetof(struct pt_regs, es) ||
+	    offset == offsetof(struct pt_regs, fs) ||
+	    offset == offsetof(struct pt_regs, gs)) {
+		return *(u16 *)((unsigned long)regs + offset);
+
+	}
 #endif
 	return *(unsigned long *)((unsigned long)regs + offset);
 }

commit 385eca8f277c4c34f361a4c3a088fd876d29ae21
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jul 28 06:00:30 2017 -0700

    x86/asm/32: Make pt_regs's segment registers be 16 bits
    
    Many 32-bit x86 CPUs do 16-bit writes when storing segment registers to
    memory.  This can cause the high word of regs->[cdefgs]s to
    occasionally contain garbage.
    
    Rather than making the entry code more complicated to fix up the
    garbage, just change pt_regs to reflect reality.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 2b5d686ea9f3..a29f82871699 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -9,6 +9,20 @@
 #ifdef __i386__
 
 struct pt_regs {
+	/*
+	 * NB: 32-bit x86 CPUs are inconsistent as what happens in the
+	 * following cases (where %seg represents a segment register):
+	 *
+	 * - pushl %seg: some do a 16-bit write and leave the high
+	 *   bits alone
+	 * - movl %seg, [mem]: some do a 16-bit write despite the movl
+	 * - IDT entry: some (e.g. 486) will leave the high bits of CS
+	 *   and (if applicable) SS undefined.
+	 *
+	 * Fortunately, x86-32 doesn't read the high bits on POP or IRET,
+	 * so we can just treat all of the segment registers as 16-bit
+	 * values.
+	 */
 	unsigned long bx;
 	unsigned long cx;
 	unsigned long dx;
@@ -16,16 +30,22 @@ struct pt_regs {
 	unsigned long di;
 	unsigned long bp;
 	unsigned long ax;
-	unsigned long ds;
-	unsigned long es;
-	unsigned long fs;
-	unsigned long gs;
+	unsigned short ds;
+	unsigned short __dsh;
+	unsigned short es;
+	unsigned short __esh;
+	unsigned short fs;
+	unsigned short __fsh;
+	unsigned short gs;
+	unsigned short __gsh;
 	unsigned long orig_ax;
 	unsigned long ip;
-	unsigned long cs;
+	unsigned short cs;
+	unsigned short __csh;
 	unsigned long flags;
 	unsigned long sp;
-	unsigned long ss;
+	unsigned short ss;
+	unsigned short __ssh;
 };
 
 #else /* __i386__ */

commit c87a85177e7a7f9a9ee32893fb99a928e02fe23a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri May 27 13:08:59 2016 -0700

    x86/entry: Get rid of two-phase syscall entry work
    
    I added two-phase syscall entry work back when the entry slow path
    was very slow.  Nowadays, the entry slow path is fast and two-phase
    entry work serves no purpose.  Remove it.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6271281f947d..2b5d686ea9f3 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -83,12 +83,6 @@ extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs,
 			 int error_code, int si_code);
 
 
-extern unsigned long syscall_trace_enter_phase1(struct pt_regs *, u32 arch);
-extern long syscall_trace_enter_phase2(struct pt_regs *, u32 arch,
-				       unsigned long phase1_result);
-
-extern long syscall_trace_enter(struct pt_regs *);
-
 static inline unsigned long regs_return_value(struct pt_regs *regs)
 {
 	return regs->ax;

commit 88cd622f9299c4c9e61e978bb9ef9d7599769ed0
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jul 31 14:41:10 2015 -0700

    x86/entry: Remove do_notify_resume(), syscall_trace_leave(), and their TIF masks
    
    They are no longer used. Good riddance!
    
    Deleting the TIF_ macros is really nice. It was never clear why
    there were so many variants.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eric Paris <eparis@parisplace.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/22c61682f446628573dde0f1d573ab821677e06da.1438378274.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 5fabf1362942..6271281f947d 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -88,7 +88,6 @@ extern long syscall_trace_enter_phase2(struct pt_regs *, u32 arch,
 				       unsigned long phase1_result);
 
 extern long syscall_trace_enter(struct pt_regs *);
-extern void syscall_trace_leave(struct pt_regs *);
 
 static inline unsigned long regs_return_value(struct pt_regs *regs)
 {

commit 7ba554b5ac69e5f3edac9ce3233beb5acd480878
Author: Jan Beulich <JBeulich@suse.com>
Date:   Thu May 28 09:16:45 2015 +0100

    x86/asm/entry/32: Really make user_mode() work correctly for VM86 mode
    
    While commit efa7045103 ("x86/asm/entry: Make user_mode() work
    correctly if regs came from VM86 mode") claims that "user_mode()
    is now identical to user_mode_vm()", this wasn't actually the
    case - no prior commit made it so.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/5566EB0D020000780007E655@mail.emea.novell.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 19507ffa5d28..5fabf1362942 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -107,7 +107,7 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 static inline int user_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32
-	return (regs->cs & SEGMENT_RPL_MASK) == USER_RPL;
+	return ((regs->cs & SEGMENT_RPL_MASK) | (regs->flags & X86_VM_MASK)) >= USER_RPL;
 #else
 	return !!(regs->cs & 3);
 #endif

commit 55474c48b4726fd3914c1ec47fced0f931729979
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Mar 29 11:02:34 2015 +0200

    x86/asm/entry: Remove user_mode_ignore_vm86()
    
    user_mode_ignore_vm86() can be used instead of user_mode(), in
    places where we have already done a v8086_mode() security
    check of ptregs.
    
    But doing this check in the wrong place would be a bug that
    could result in security problems, and also the naming still
    isn't very clear.
    
    Furthermore, it only affects 32-bit kernels, while most
    development happens on 64-bit kernels.
    
    If we replace them with user_mode() checks then the cost is only
    a very minor increase in various slowpaths:
    
       text             data   bss     dec              hex    filename
       10573391         703562 1753042 13029995         c6d26b vmlinux.o.before
       10573423         703562 1753042 13030027         c6d28b vmlinux.o.after
    
    So lets get rid of this distinction once and for all.
    
    Acked-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andrew Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20150329090233.GA1963@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index d20bae298852..19507ffa5d28 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -113,23 +113,6 @@ static inline int user_mode(struct pt_regs *regs)
 #endif
 }
 
-/*
- * This is the fastest way to check whether regs come from user space.
- * It is unsafe if regs might come from vm86 mode, though -- in vm86
- * mode, all bits of CS and SS are completely under the user's control.
- * The CPU considers vm86 mode to be CPL 3 regardless of CS and SS.
- *
- * Do NOT use this function unless you have already ruled out the
- * possibility that regs came from vm86 mode.
- *
- * We check for RPL != 0 instead of RPL == 3 because we don't use rings
- * 1 or 2 and this is more efficient.
- */
-static inline int user_mode_ignore_vm86(struct pt_regs *regs)
-{
-	return (regs->cs & SEGMENT_RPL_MASK) != 0;
-}
-
 static inline int v8086_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32

commit 7a2806741e7327a6b20ccef42e8d56588cb2fef5
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Mar 18 18:33:34 2015 -0700

    x86/asm/entry: Remove user_mode_vm()
    
    It has no callers anymore.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/a594afd6a0bddb1311bd7c92a15201c87fbb8681.1426728647.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 70c439f9071b..d20bae298852 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -113,11 +113,6 @@ static inline int user_mode(struct pt_regs *regs)
 #endif
 }
 
-static inline int user_mode_vm(struct pt_regs *regs)
-{
-	return user_mode(regs);
-}
-
 /*
  * This is the fastest way to check whether regs come from user space.
  * It is unsafe if regs might come from vm86 mode, though -- in vm86

commit efa704510342b81ae58d7b8a0c7f676a4289b603
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Mar 18 18:33:32 2015 -0700

    x86/asm/entry: Make user_mode() work correctly if regs came from VM86 mode
    
    user_mode() is now identical to user_mode_vm().  Subsequent patches
    will change all callers of user_mode_vm() to user_mode() and then
    delete user_mode_vm().
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/0dd03eacb5f0a2b5ba0240de25347a31b493c289.1426728647.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 4a040f0078f2..70c439f9071b 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -96,11 +96,13 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 }
 
 /*
- * user_mode_vm(regs) determines whether a register set came from user mode.
- * This is true if V8086 mode was enabled OR if the register set was from
- * protected mode with RPL-3 CS value.  This tricky test checks that with
- * one comparison.  Many places in the kernel can bypass this full check
- * if they have already ruled out V8086 mode, so user_mode(regs) can be used.
+ * user_mode(regs) determines whether a register set came from user
+ * mode.  On x86_32, this is true if V8086 mode was enabled OR if the
+ * register set was from protected mode with RPL-3 CS value.  This
+ * tricky test checks that with one comparison.
+ *
+ * On x86_64, vm86 mode is mercifully nonexistent, and we don't need
+ * the extra check.
  */
 static inline int user_mode(struct pt_regs *regs)
 {
@@ -113,12 +115,7 @@ static inline int user_mode(struct pt_regs *regs)
 
 static inline int user_mode_vm(struct pt_regs *regs)
 {
-#ifdef CONFIG_X86_32
-	return ((regs->cs & SEGMENT_RPL_MASK) | (regs->flags & X86_VM_MASK)) >=
-		USER_RPL;
-#else
 	return user_mode(regs);
-#endif
 }
 
 /*

commit a67e7277d01ccfd39b0db5a198c2643cc19dd79c
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Mar 18 18:33:29 2015 -0700

    x86/asm/entry: Add user_mode_ignore_vm86()
    
    user_mode() is dangerous and user_mode_vm() has a confusing name.
    
    Add user_mode_ignore_vm86() (equivalent to current user_mode()).
    We'll change the small number of legitimate users of user_mode()
    to user_mode_ignore_vm86().
    
    Inspired by grsec, although this works rather differently.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/202c56ca63823c338af8e2e54948dbe222da6343.1426728647.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 83b874da2762..4a040f0078f2 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -121,6 +121,23 @@ static inline int user_mode_vm(struct pt_regs *regs)
 #endif
 }
 
+/*
+ * This is the fastest way to check whether regs come from user space.
+ * It is unsafe if regs might come from vm86 mode, though -- in vm86
+ * mode, all bits of CS and SS are completely under the user's control.
+ * The CPU considers vm86 mode to be CPL 3 regardless of CS and SS.
+ *
+ * Do NOT use this function unless you have already ruled out the
+ * possibility that regs came from vm86 mode.
+ *
+ * We check for RPL != 0 instead of RPL == 3 because we don't use rings
+ * 1 or 2 and this is more efficient.
+ */
+static inline int user_mode_ignore_vm86(struct pt_regs *regs)
+{
+	return (regs->cs & SEGMENT_RPL_MASK) != 0;
+}
+
 static inline int v8086_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32

commit 1daeaa315164c60b937f56fe3848d4328c358eba
Author: Brian Gerst <brgerst@gmail.com>
Date:   Sat Mar 21 18:54:21 2015 -0400

    x86/asm/entry: Fix execve() and sigreturn() syscalls to always return via IRET
    
    Both the execve() and sigreturn() family of syscalls have the
    ability to change registers in ways that may not be compatabile
    with the syscall path they were called from.
    
    In particular, SYSRET and SYSEXIT can't handle non-default %cs and %ss,
    and some bits in eflags.
    
    These syscalls have stubs that are hardcoded to jump to the IRET path,
    and not return to the original syscall path.
    
    The following commit:
    
       76f5df43cab5e76 ("Always allocate a complete "struct pt_regs" on the kernel stack")
    
    recently changed this for some 32-bit compat syscalls, but introduced a bug where
    execve from a 32-bit program to a 64-bit program would fail because it still returned
    via SYSRETL. This caused Wine to fail when built for both 32-bit and 64-bit.
    
    This patch sets TIF_NOTIFY_RESUME for execve() and sigreturn() so
    that the IRET path is always taken on exit to userspace.
    
    Signed-off-by: Brian Gerst <brgerst@gmail.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1426978461-32089-1-git-send-email-brgerst@gmail.com
    [ Improved the changelog and comments. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 74bb2e0f3030..83b874da2762 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -251,7 +251,7 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
  */
 #define arch_ptrace_stop_needed(code, info)				\
 ({									\
-	set_thread_flag(TIF_NOTIFY_RESUME);				\
+	force_iret();							\
 	false;								\
 })
 

commit 263042e4630a85e856b4a8cd72f28dab33ef4741
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Mon Mar 9 19:39:23 2015 +0100

    x86/asm/entry/64: Save user RSP in pt_regs->sp on SYSCALL64 fastpath
    
    Prepare for the removal of 'usersp', by simplifying PER_CPU(old_rsp) usage:
    
      - use it only as temp storage
    
      - store the userspace stack pointer immediately in pt_regs->sp
        on syscall entry, instead of using it later, on syscall exit.
    
      - change C code to use pt_regs->sp only, instead of PER_CPU(old_rsp)
        and task->thread.usersp.
    
    FIXUP/RESTORE_TOP_OF_STACK are simplified as well.
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Will Drewry <wad@chromium.org>
    Link: http://lkml.kernel.org/r/1425926364-9526-4-git-send-email-dvlasenk@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 4077d963a1a0..74bb2e0f3030 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -145,12 +145,8 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 #endif
 }
 
-#define current_user_stack_pointer()	this_cpu_read(old_rsp)
-/* ia32 vs. x32 difference */
-#define compat_user_stack_pointer()	\
-	(test_thread_flag(TIF_IA32) 	\
-	 ? current_pt_regs()->sp 	\
-	 : this_cpu_read(old_rsp))
+#define current_user_stack_pointer()	current_pt_regs()->sp
+#define compat_user_stack_pointer()	current_pt_regs()->sp
 #endif
 
 #ifdef CONFIG_X86_32

commit e90e147cbc0cbc8dcf48000e15190badf75250f4
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Thu Feb 26 14:40:28 2015 -0800

    x86/asm/entry/64: Fix comments
    
     - Misleading and slightly incorrect comments in "struct pt_regs" are
       fixed (four instances).
    
     - Fix incorrect comment atop EMPTY_FRAME macro.
    
     - Explain in more detail what we do with stack layout during hw interrupt.
    
     - Correct comments about "partial stack frame" which are no longer
       true.
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Will Drewry <wad@chromium.org>
    Link: http://lkml.kernel.org/r/1423778052-21038-3-git-send-email-dvlasenk@redhat.com
    Link: http://lkml.kernel.org/r/e1f4429c491fe6ceeddb879dea2786e0f8920f9c.1424989793.git.luto@amacapital.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 86fc2bb82287..4077d963a1a0 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -31,13 +31,17 @@ struct pt_regs {
 #else /* __i386__ */
 
 struct pt_regs {
+/*
+ * C ABI says these regs are callee-preserved. They aren't saved on kernel entry
+ * unless syscall needs a complete, fully filled "struct pt_regs".
+ */
 	unsigned long r15;
 	unsigned long r14;
 	unsigned long r13;
 	unsigned long r12;
 	unsigned long bp;
 	unsigned long bx;
-/* arguments: non interrupts/non tracing syscalls only save up to here*/
+/* These regs are callee-clobbered. Always saved on kernel entry. */
 	unsigned long r11;
 	unsigned long r10;
 	unsigned long r9;
@@ -47,9 +51,12 @@ struct pt_regs {
 	unsigned long dx;
 	unsigned long si;
 	unsigned long di;
+/*
+ * On syscall entry, this is syscall#. On CPU exception, this is error code.
+ * On hw interrupt, it's IRQ number:
+ */
 	unsigned long orig_ax;
-/* end of arguments */
-/* cpu exception frame or undefined */
+/* Return frame for iretq */
 	unsigned long ip;
 	unsigned long cs;
 	unsigned long flags;

commit e0ffbaabc46db508b8717f023c0ce03b980eefac
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Fri Sep 5 15:13:54 2014 -0700

    x86: Split syscall_trace_enter into two phases
    
    This splits syscall_trace_enter into syscall_trace_enter_phase1 and
    syscall_trace_enter_phase2.  Only phase 2 has full pt_regs, and only
    phase 2 is permitted to modify any of pt_regs except for orig_ax.
    
    The intent is that phase 1 can be called from the syscall fast path.
    
    In this implementation, phase1 can handle any combination of
    TIF_NOHZ (RCU context tracking), TIF_SECCOMP, and TIF_SYSCALL_AUDIT,
    unless seccomp requests a ptrace event, in which case phase2 is
    forced.
    
    In principle, this could yield a big speedup for TIF_NOHZ as well as
    for TIF_SECCOMP if syscall exit work were similarly split up.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/2df320a600020fda055fccf2b668145729dd0c04.1409954077.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6205f0c434db..86fc2bb82287 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -75,6 +75,11 @@ convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
 extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs,
 			 int error_code, int si_code);
 
+
+extern unsigned long syscall_trace_enter_phase1(struct pt_regs *, u32 arch);
+extern long syscall_trace_enter_phase2(struct pt_regs *, u32 arch,
+				       unsigned long phase1_result);
+
 extern long syscall_trace_enter(struct pt_regs *);
 extern void syscall_trace_leave(struct pt_regs *);
 

commit b9cd18de4db3c9ffa7e17b0dc0ca99ed5aa4d43a
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jul 3 15:43:15 2014 -0400

    ptrace,x86: force IRET path after a ptrace_stop()
    
    The 'sysret' fastpath does not correctly restore even all regular
    registers, much less any segment registers or reflags values.  That is
    very much part of why it's faster than 'iret'.
    
    Normally that isn't a problem, because the normal ptrace() interface
    catches the process using the signal handler infrastructure, which
    always returns with an iret.
    
    However, some paths can get caught using ptrace_event() instead of the
    signal path, and for those we need to make sure that we aren't going to
    return to user space using 'sysret'.  Otherwise the modifications that
    may have been done to the register set by the tracer wouldn't
    necessarily take effect.
    
    Fix it by forcing IRET path by setting TIF_NOTIFY_RESUME from
    arch_ptrace_stop_needed() which is invoked from ptrace_stop().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Andy Lutomirski <luto@amacapital.net>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 14fd6fd75a19..6205f0c434db 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -231,6 +231,22 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 
 #define ARCH_HAS_USER_SINGLE_STEP_INFO
 
+/*
+ * When hitting ptrace_stop(), we cannot return using SYSRET because
+ * that does not restore the full CPU state, only a minimal set.  The
+ * ptracer can change arbitrary register values, which is usually okay
+ * because the usual ptrace stops run off the signal delivery path which
+ * forces IRET; however, ptrace_event() stops happen in arbitrary places
+ * in the kernel and don't force IRET path.
+ *
+ * So force IRET path after a ptrace stop.
+ */
+#define arch_ptrace_stop_needed(code, info)				\
+({									\
+	set_thread_flag(TIF_NOTIFY_RESUME);				\
+	false;								\
+})
+
 struct user_desc;
 extern int do_get_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info);

commit 663b55b9b39fa9c848cca273ca4e12bf29b32c71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jan 6 19:20:26 2014 -0500

    x86: Delete non-required instances of include <linux/init.h>
    
    None of these files are actually using any __init type directives
    and hence don't need to include <linux/init.h>.  Most are just a
    left over from __devinit and __cpuinit removal, or simply due to
    code getting copied from one driver to the next.
    
    [ hpa: undid incorrect removal from arch/x86/kernel/head_32.S ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Link: http://lkml.kernel.org/r/1389054026-12947-1-git-send-email-paul.gortmaker@windriver.com
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 942a08623a1a..14fd6fd75a19 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -60,7 +60,6 @@ struct pt_regs {
 
 #endif /* !__i386__ */
 
-#include <linux/init.h>
 #ifdef CONFIG_PARAVIRT
 #include <asm/paravirt_types.h>
 #endif

commit 54d46ea993744c5408e39ce0cb4851e13cbea716
Merge: f59dc2bb5a50 50ececcfa7d1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 20 18:05:28 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull signal handling cleanups from Al Viro:
     "sigaltstack infrastructure + conversion for x86, alpha and um,
      COMPAT_SYSCALL_DEFINE infrastructure.
    
      Note that there are several conflicts between "unify
      SS_ONSTACK/SS_DISABLE definitions" and UAPI patches in mainline;
      resolution is trivial - just remove definitions of SS_ONSTACK and
      SS_DISABLED from arch/*/uapi/asm/signal.h; they are all identical and
      include/uapi/linux/signal.h contains the unified variant."
    
    Fixed up conflicts as per Al.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      alpha: switch to generic sigaltstack
      new helpers: __save_altstack/__compat_save_altstack, switch x86 and um to those
      generic compat_sys_sigaltstack()
      introduce generic sys_sigaltstack(), switch x86 and um to it
      new helper: compat_user_stack_pointer()
      new helper: restore_altstack()
      unify SS_ONSTACK/SS_DISABLE definitions
      new helper: current_user_stack_pointer()
      missing user_stack_pointer() instances
      Bury the conditionals from kernel_thread/kernel_execve series
      COMPAT_SYSCALL_DEFINE: infrastructure

commit 9b064fc3f95a8e44e929fdf4d6037334ea03d15b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 14 13:49:35 2012 -0500

    new helper: compat_user_stack_pointer()
    
    Compat counterpart of current_user_stack_pointer(); for most of the biarch
    architectures those two are identical, but e.g. arm64 and arm use different
    registers for stack pointer...
    
    Note that amd64 variants of current_user_stack_pointer/compat_user_stack_pointer
    do *not* rely on pt_regs having been through FIXUP_TOP_OF_STACK.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 19f16ebaf4fa..7e560b6daf5d 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -203,6 +203,13 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 	return regs->cs == __USER_CS || regs->cs == pv_info.extra_user_64bit_cs;
 #endif
 }
+
+#define current_user_stack_pointer()	this_cpu_read(old_rsp)
+/* ia32 vs. x32 difference */
+#define compat_user_stack_pointer()	\
+	(test_thread_flag(TIF_IA32) 	\
+	 ? current_pt_regs()->sp 	\
+	 : this_cpu_read(old_rsp))
 #endif
 
 #ifdef CONFIG_X86_32

commit af170c5061dd78512c469e6e2d211980cdb2c193
Author: David Howells <dhowells@redhat.com>
Date:   Fri Dec 14 22:37:13 2012 +0000

    UAPI: (Scripted) Disintegrate arch/x86/include/asm
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 54d80fddb739..03ca442d8f0d 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -1,44 +1,12 @@
 #ifndef _ASM_X86_PTRACE_H
 #define _ASM_X86_PTRACE_H
 
-#include <linux/compiler.h>	/* For __user */
-#include <asm/ptrace-abi.h>
-#include <asm/processor-flags.h>
-
-#ifdef __KERNEL__
 #include <asm/segment.h>
 #include <asm/page_types.h>
-#endif
+#include <uapi/asm/ptrace.h>
 
 #ifndef __ASSEMBLY__
-
 #ifdef __i386__
-/* this struct defines the way the registers are stored on the
-   stack during a system call. */
-
-#ifndef __KERNEL__
-
-struct pt_regs {
-	long ebx;
-	long ecx;
-	long edx;
-	long esi;
-	long edi;
-	long ebp;
-	long eax;
-	int  xds;
-	int  xes;
-	int  xfs;
-	int  xgs;
-	long orig_eax;
-	long eip;
-	int  xcs;
-	long eflags;
-	long esp;
-	int  xss;
-};
-
-#else /* __KERNEL__ */
 
 struct pt_regs {
 	unsigned long bx;
@@ -60,42 +28,8 @@ struct pt_regs {
 	unsigned long ss;
 };
 
-#endif /* __KERNEL__ */
-
 #else /* __i386__ */
 
-#ifndef __KERNEL__
-
-struct pt_regs {
-	unsigned long r15;
-	unsigned long r14;
-	unsigned long r13;
-	unsigned long r12;
-	unsigned long rbp;
-	unsigned long rbx;
-/* arguments: non interrupts/non tracing syscalls only save up to here*/
-	unsigned long r11;
-	unsigned long r10;
-	unsigned long r9;
-	unsigned long r8;
-	unsigned long rax;
-	unsigned long rcx;
-	unsigned long rdx;
-	unsigned long rsi;
-	unsigned long rdi;
-	unsigned long orig_rax;
-/* end of arguments */
-/* cpu exception frame or undefined */
-	unsigned long rip;
-	unsigned long cs;
-	unsigned long eflags;
-	unsigned long rsp;
-	unsigned long ss;
-/* top of stack page */
-};
-
-#else /* __KERNEL__ */
-
 struct pt_regs {
 	unsigned long r15;
 	unsigned long r14;
@@ -124,12 +58,8 @@ struct pt_regs {
 /* top of stack page */
 };
 
-#endif /* __KERNEL__ */
 #endif /* !__i386__ */
 
-
-#ifdef __KERNEL__
-
 #include <linux/init.h>
 #ifdef CONFIG_PARAVIRT
 #include <asm/paravirt_types.h>
@@ -301,8 +231,5 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
-#endif /* __KERNEL__ */
-
 #endif /* !__ASSEMBLY__ */
-
 #endif /* _ASM_X86_PTRACE_H */

commit 0019fab3558c8c8135c88c3d38f24ab0a5408aa6
Merge: b64c5fda3868 6c8d8b3c69ce
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 11 19:55:20 2012 -0800

    Merge branch 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 asm changes from Ingo Molnar:
     "Two fixlets and a cleanup."
    
    * 'x86-asm-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86_32: Return actual stack when requesting sp from regs
      x86: Don't clobber top of pt_regs in nested NMI
      x86/asm: Clean up copy_page_*() comments and code

commit 1022623842cb72ee4d0dbf02f6937f38c92c3f41
Author: Robert Richter <robert.richter@amd.com>
Date:   Mon Sep 3 20:54:48 2012 +0200

    x86-32: Fix invalid stack address while in softirq
    
    In 32 bit the stack address provided by kernel_stack_pointer() may
    point to an invalid range causing NULL pointer access or page faults
    while in NMI (see trace below). This happens if called in softirq
    context and if the stack is empty. The address at &regs->sp is then
    out of range.
    
    Fixing this by checking if regs and &regs->sp are in the same stack
    context. Otherwise return the previous stack pointer stored in struct
    thread_info. If that address is invalid too, return address of regs.
    
     BUG: unable to handle kernel NULL pointer dereference at 0000000a
     IP: [<c1004237>] print_context_stack+0x6e/0x8d
     *pde = 00000000
     Oops: 0000 [#1] SMP
     Modules linked in:
     Pid: 4434, comm: perl Not tainted 3.6.0-rc3-oprofile-i386-standard-g4411a05 #4 Hewlett-Packard HP xw9400 Workstation/0A1Ch
     EIP: 0060:[<c1004237>] EFLAGS: 00010093 CPU: 0
     EIP is at print_context_stack+0x6e/0x8d
     EAX: ffffe000 EBX: 0000000a ECX: f4435f94 EDX: 0000000a
     ESI: f4435f94 EDI: f4435f94 EBP: f5409ec0 ESP: f5409ea0
      DS: 007b ES: 007b FS: 00d8 GS: 0033 SS: 0068
     CR0: 8005003b CR2: 0000000a CR3: 34ac9000 CR4: 000007d0
     DR0: 00000000 DR1: 00000000 DR2: 00000000 DR3: 00000000
     DR6: ffff0ff0 DR7: 00000400
     Process perl (pid: 4434, ti=f5408000 task=f5637850 task.ti=f4434000)
     Stack:
      000003e8 ffffe000 00001ffc f4e39b00 00000000 0000000a f4435f94 c155198c
      f5409ef0 c1003723 c155198c f5409f04 00000000 f5409edc 00000000 00000000
      f5409ee8 f4435f94 f5409fc4 00000001 f5409f1c c12dce1c 00000000 c155198c
     Call Trace:
      [<c1003723>] dump_trace+0x7b/0xa1
      [<c12dce1c>] x86_backtrace+0x40/0x88
      [<c12db712>] ? oprofile_add_sample+0x56/0x84
      [<c12db731>] oprofile_add_sample+0x75/0x84
      [<c12ddb5b>] op_amd_check_ctrs+0x46/0x260
      [<c12dd40d>] profile_exceptions_notify+0x23/0x4c
      [<c1395034>] nmi_handle+0x31/0x4a
      [<c1029dc5>] ? ftrace_define_fields_irq_handler_entry+0x45/0x45
      [<c13950ed>] do_nmi+0xa0/0x2ff
      [<c1029dc5>] ? ftrace_define_fields_irq_handler_entry+0x45/0x45
      [<c13949e5>] nmi_stack_correct+0x28/0x2d
      [<c1029dc5>] ? ftrace_define_fields_irq_handler_entry+0x45/0x45
      [<c1003603>] ? do_softirq+0x4b/0x7f
      <IRQ>
      [<c102a06f>] irq_exit+0x35/0x5b
      [<c1018f56>] smp_apic_timer_interrupt+0x6c/0x7a
      [<c1394746>] apic_timer_interrupt+0x2a/0x30
     Code: 89 fe eb 08 31 c9 8b 45 0c ff 55 ec 83 c3 04 83 7d 10 00 74 0c 3b 5d 10 73 26 3b 5d e4 73 0c eb 1f 3b 5d f0 76 1a 3b 5d e8 73 15 <8b> 13 89 d0 89 55 e0 e8 ad 42 03 00 85 c0 8b 55 e0 75 a6 eb cc
     EIP: [<c1004237>] print_context_stack+0x6e/0x8d SS:ESP 0068:f5409ea0
     CR2: 000000000000000a
     ---[ end trace 62afee3481b00012 ]---
     Kernel panic - not syncing: Fatal exception in interrupt
    
    V2:
    * add comments to kernel_stack_pointer()
    * always return a valid stack address by falling back to the address
      of regs
    
    Reported-by: Yang Wei <wei.yang@windriver.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Robert Richter <robert.richter@amd.com>
    Link: http://lkml.kernel.org/r/20120912135059.GZ8285@erda.amd.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Jun Zhang <jun.zhang@intel.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index dcfde52979c3..19f16ebaf4fa 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -205,21 +205,14 @@ static inline bool user_64bit_mode(struct pt_regs *regs)
 }
 #endif
 
-/*
- * X86_32 CPUs don't save ss and esp if the CPU is already in kernel mode
- * when it traps.  The previous stack will be directly underneath the saved
- * registers, and 'sp/ss' won't even have been saved. Thus the '&regs->sp'.
- *
- * This is valid only for kernel mode traps.
- */
-static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
-{
 #ifdef CONFIG_X86_32
-	return (unsigned long)(&regs->sp);
+extern unsigned long kernel_stack_pointer(struct pt_regs *regs);
 #else
+static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
+{
 	return regs->sp;
-#endif
 }
+#endif
 
 #define GET_IP(regs) ((regs)->ip)
 #define GET_FP(regs) ((regs)->bp)

commit 6c8d8b3c69cef1330e0c5cbc2a8b9268024927a0
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Fri Jul 13 15:44:14 2012 -0400

    x86_32: Return actual stack when requesting sp from regs
    
    As x86_32 traps do not save sp when taken in kernel mode, we need to
    accommodate the sp when requesting to get the register.
    
    This affects kprobes.
    
    Before:
    
     # echo 'p:ftrace sys_read+4 s=%sp' > /debug/tracing/kprobe_events
     # echo 1 > /debug/tracing/events/kprobes/enable
     # cat trace
                sshd-1345  [000] d...   489.117168: ftrace: (sys_read+0x4/0x70) s=b7e96768
                sshd-1345  [000] d...   489.117191: ftrace: (sys_read+0x4/0x70) s=b7e96768
                 cat-1447  [000] d...   489.117392: ftrace: (sys_read+0x4/0x70) s=5a7
                 cat-1447  [001] d...   489.118023: ftrace: (sys_read+0x4/0x70) s=b77ad05f
                less-1448  [000] d...   489.118079: ftrace: (sys_read+0x4/0x70) s=b7762e06
                less-1448  [000] d...   489.118117: ftrace: (sys_read+0x4/0x70) s=b7764970
    
    After:
                sshd-1352  [000] d...   362.348016: ftrace: (sys_read+0x4/0x70) s=f3febfa8
                sshd-1352  [000] d...   362.348048: ftrace: (sys_read+0x4/0x70) s=f3febfa8
                bash-1355  [001] d...   362.348081: ftrace: (sys_read+0x4/0x70) s=f5075fa8
                sshd-1352  [000] d...   362.348082: ftrace: (sys_read+0x4/0x70) s=f3febfa8
                sshd-1352  [000] d...   362.690950: ftrace: (sys_read+0x4/0x70) s=f3febfa8
                bash-1355  [001] d...   362.691033: ftrace: (sys_read+0x4/0x70) s=f5075fa8
    
    Link: http://lkml.kernel.org/r/1342208654.30075.22.camel@gandalf.stny.rr.com
    
    Reviewed-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index dcfde52979c3..2233713d0297 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -246,6 +246,15 @@ static inline unsigned long regs_get_register(struct pt_regs *regs,
 {
 	if (unlikely(offset > MAX_REG_OFFSET))
 		return 0;
+#ifdef CONFIG_X86_32
+	/*
+	 * Traps from the kernel do not save sp and ss.
+	 * Use the helper function to retrieve sp.
+	 */
+	if (offset == offsetof(struct pt_regs, sp) &&
+	    regs->cs == __KERNEL_CS)
+		return kernel_stack_pointer(regs);
+#endif
 	return *(unsigned long *)((unsigned long)regs + offset);
 }
 

commit f28f0c23576662fb293defe9b1884d5a6e1bd85c
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Sun Feb 19 07:38:43 2012 -0800

    x86: Move some signal-handling definitions to a common header
    
    There are some definitions which are duplicated between
    kernel/signal.c and ia32/ia32_signal.c; move them to a common header
    file.
    
    Rather than adding stuff to existing header files which contain data
    structures, create a new header file; hence the slightly odd name
    ("all the good ones were taken.")
    
    Note: nothing relied on signal_fault() being defined in
    <asm/ptrace.h>.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 35664547125b..dcfde52979c3 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -145,7 +145,6 @@ extern unsigned long
 convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
 extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs,
 			 int error_code, int si_code);
-void signal_fault(struct pt_regs *regs, void __user *frame, char *where);
 
 extern long syscall_trace_enter(struct pt_regs *);
 extern void syscall_trace_leave(struct pt_regs *);

commit 318f5a2a672152328c9fb4dead504b89ec738a43
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Wed Aug 3 09:31:53 2011 -0400

    x86-64: Add user_64bit_mode paravirt op
    
    Three places in the kernel assume that the only long mode CPL 3
    selector is __USER_CS.  This is not true on Xen -- Xen's sysretq
    changes cs to the magic value 0xe033.
    
    Two of the places are corner cases, but as of "x86-64: Improve
    vsyscall emulation CS and RIP handling"
    (c9712944b2a12373cb6ff8059afcfb7e826a6c54), vsyscalls will segfault
    if called with Xen's extra CS selector.  This causes a panic when
    older init builds die.
    
    It seems impossible to make Xen use __USER_CS reliably without
    taking a performance hit on every system call, so this fixes the
    tests instead with a new paravirt op.  It's a little ugly because
    ptrace.h can't include paravirt.h.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Link: http://lkml.kernel.org/r/f4fcb3947340d9e96ce1054a432f183f9da9db83.1312378163.git.luto@mit.edu
    Reported-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 94e7618fcac8..35664547125b 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -131,6 +131,9 @@ struct pt_regs {
 #ifdef __KERNEL__
 
 #include <linux/init.h>
+#ifdef CONFIG_PARAVIRT
+#include <asm/paravirt_types.h>
+#endif
 
 struct cpuinfo_x86;
 struct task_struct;
@@ -187,6 +190,22 @@ static inline int v8086_mode(struct pt_regs *regs)
 #endif
 }
 
+#ifdef CONFIG_X86_64
+static inline bool user_64bit_mode(struct pt_regs *regs)
+{
+#ifndef CONFIG_PARAVIRT
+	/*
+	 * On non-paravirt systems, this is the only long mode CPL 3
+	 * selector.  We do not allow long mode selectors in the LDT.
+	 */
+	return regs->cs == __USER_CS;
+#else
+	/* Headers are too twisted for this to go in paravirt.h. */
+	return regs->cs == __USER_CS || regs->cs == pv_info.extra_user_64bit_cs;
+#endif
+}
+#endif
+
 /*
  * X86_32 CPUs don't save ss and esp if the CPU is already in kernel mode
  * when it traps.  The previous stack will be directly underneath the saved

commit c46dd6b48db02c1fa2f0644809605344660d3956
Author: Mike Frysinger <vapier@gentoo.org>
Date:   Thu May 26 16:25:43 2011 -0700

    x86: convert to asm-generic ptrace.h
    
    Signed-off-by: Mike Frysinger <vapier@gentoo.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Jason Wessel <jason.wessel@windriver.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Sergei Shtylyov <sshtylyov@mvista.com>
    Cc: Dongdong Deng <dongdong.deng@windriver.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 1babf8adecdf..94e7618fcac8 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -136,6 +136,7 @@ struct cpuinfo_x86;
 struct task_struct;
 
 extern unsigned long profile_pc(struct pt_regs *regs);
+#define profile_pc profile_pc
 
 extern unsigned long
 convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
@@ -202,20 +203,11 @@ static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
 #endif
 }
 
-static inline unsigned long instruction_pointer(struct pt_regs *regs)
-{
-	return regs->ip;
-}
-
-static inline unsigned long frame_pointer(struct pt_regs *regs)
-{
-	return regs->bp;
-}
+#define GET_IP(regs) ((regs)->ip)
+#define GET_FP(regs) ((regs)->bp)
+#define GET_USP(regs) ((regs)->sp)
 
-static inline unsigned long user_stack_pointer(struct pt_regs *regs)
-{
-	return regs->sp;
-}
+#include <asm-generic/ptrace.h>
 
 /* Query offset/name of register from its name/offset */
 extern int regs_query_register_offset(const char *name);

commit 0d2eb44f631d9d0a826efa3156f157477fdaecf4
Author: Lucas De Marchi <lucas.de.marchi@gmail.com>
Date:   Thu Mar 17 16:24:16 2011 -0300

    x86: Fix common misspellings
    
    They were generated by 'codespell' and then manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>
    Cc: trivial@kernel.org
    LKML-Reference: <1300389856-1099-3-git-send-email-lucas.demarchi@profusion.mobi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 78cd1ea94500..1babf8adecdf 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -73,7 +73,7 @@ struct pt_regs {
 	unsigned long r12;
 	unsigned long rbp;
 	unsigned long rbx;
-/* arguments: non interrupts/non tracing syscalls only save upto here*/
+/* arguments: non interrupts/non tracing syscalls only save up to here*/
 	unsigned long r11;
 	unsigned long r10;
 	unsigned long r9;
@@ -103,7 +103,7 @@ struct pt_regs {
 	unsigned long r12;
 	unsigned long bp;
 	unsigned long bx;
-/* arguments: non interrupts/non tracing syscalls only save upto here*/
+/* arguments: non interrupts/non tracing syscalls only save up to here*/
 	unsigned long r11;
 	unsigned long r10;
 	unsigned long r9;

commit faa4602e47690fb11221e00f9b9697c8dc0d4b19
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Mar 25 14:51:50 2010 +0100

    x86, perf, bts, mm: Delete the never used BTS-ptrace code
    
    Support for the PMU's BTS features has been upstreamed in
    v2.6.32, but we still have the old and disabled ptrace-BTS,
    as Linus noticed it not so long ago.
    
    It's buggy: TIF_DEBUGCTLMSR is trampling all over that MSR without
    regard for other uses (perf) and doesn't provide the flexibility
    needed for perf either.
    
    Its users are ptrace-block-step and ptrace-bts, since ptrace-bts
    was never used and ptrace-block-step can be implemented using a
    much simpler approach.
    
    So axe all 3000 lines of it. That includes the *locked_memory*()
    APIs in mm/mlock.c as well.
    
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Markus Metzger <markus.t.metzger@intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <20100325135413.938004390@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 69a686a7dff0..78cd1ea94500 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -289,12 +289,6 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
-#ifdef CONFIG_X86_PTRACE_BTS
-extern void ptrace_bts_untrace(struct task_struct *tsk);
-
-#define arch_ptrace_untrace(tsk)	ptrace_bts_untrace(tsk)
-#endif /* CONFIG_X86_PTRACE_BTS */
-
 #endif /* __KERNEL__ */
 
 #endif /* !__ASSEMBLY__ */

commit dacbe41f776db0a5a9aee1e41594f405c95778a5
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Mar 10 15:22:46 2010 -0800

    ptrace: move user_enable_single_step & co prototypes to linux/ptrace.h
    
    While in theory user_enable_single_step/user_disable_single_step/
    user_enable_blockstep could also be provided as an inline or macro there's
    no good reason to do so, and having the prototype in one places keeps code
    size and confusion down.
    
    Roland said:
    
      The original thought there was that user_enable_single_step() et al
      might well be only an instruction or three on a sane machine (as if we
      have any of those!), and since there is only one call site inlining
      would be beneficial.  But I agree that there is no strong reason to care
      about inlining it.
    
      As to the arch changes, there is only one thought I'd add to the
      record.  It was always my thinking that for an arch where
      PTRACE_SINGLESTEP does text-modifying breakpoint insertion,
      user_enable_single_step() should not be provided.  That is,
      arch_has_single_step()=>true means that there is an arch facility with
      "pure" semantics that does not have any unexpected side effects.
      Inserting a breakpoint might do very unexpected strange things in
      multi-threaded situations.  Aside from that, it is a peculiar side
      effect that user_{enable,disable}_single_step() should cause COW
      de-sharing of text pages and so forth.  For PTRACE_SINGLESTEP, all these
      peculiarities are the status quo ante for that arch, so having
      arch_ptrace() itself do those is one thing.  But for building other
      things in the future, it is nicer to have a uniform "pure" semantics
      that arch-independent code can expect.
    
      OTOH, all such arch issues are really up to the arch maintainer.  As
      of today, there is nothing but ptrace using user_enable_single_step() et
      al so it's a distinction without a practical difference.  If/when there
      are other facilities that use user_enable_single_step() and might care,
      the affected arch's can revisit the question when someone cares about
      the quality of the arch support for said new facility.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 20102808b191..69a686a7dff0 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -274,14 +274,7 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 		return 0;
 }
 
-/*
- * These are defined as per linux/ptrace.h, which see.
- */
 #define arch_has_single_step()	(1)
-extern void user_enable_single_step(struct task_struct *);
-extern void user_disable_single_step(struct task_struct *);
-
-extern void user_enable_block_step(struct task_struct *);
 #ifdef CONFIG_X86_DEBUGCTLMSR
 #define arch_has_block_step()	(1)
 #else

commit aa5add93e92019018e905146f8c3d3f8e3c08300
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Tue Jan 5 17:46:56 2010 -0500

    x86/ptrace: Remove unused regs_get_argument_nth API
    
    Because of dropping function argument syntax from kprobe-tracer,
    we don't need this API anymore.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: systemtap <systemtap@sources.redhat.com>
    Cc: DLE <dle-develop@lists.sourceforge.net>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: linuxppc-dev@ozlabs.org
    LKML-Reference: <20100105224656.19431.92588.stgit@dhcp-100-2-132.bos.redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 9d369f680321..20102808b191 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -274,10 +274,6 @@ static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 		return 0;
 }
 
-/* Get Nth argument at function call */
-extern unsigned long regs_get_argument_nth(struct pt_regs *regs,
-					   unsigned int n);
-
 /*
  * These are defined as per linux/ptrace.h, which see.
  */

commit 7f38551fc3ff0e17a38d6f3f0f8831380a88f3cc
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:20 2009 -0800

    ptrace: x86: implement user_single_step_siginfo()
    
    Suggested by Roland.
    
    Implement user_single_step_siginfo() for x86.  Extract this code from
    send_sigtrap().
    
    Since x86 calls tracehook_report_syscall_exit(step => 0) the new helper is
    not used yet.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 3d11fd0f44c5..9d369f680321 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -292,6 +292,8 @@ extern void user_enable_block_step(struct task_struct *);
 #define arch_has_block_step()	(boot_cpu_data.x86 >= 6)
 #endif
 
+#define ARCH_HAS_USER_SINGLE_STEP_INFO
+
 struct user_desc;
 extern int do_get_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info);

commit e859cf8656043f158b4004ccc8cbbf1ba4f97177
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Mon Nov 30 19:02:22 2009 -0500

    x86: Fix comments of register/stack access functions
    
    Fix typos and some redundant comments of register/stack access
    functions in asm/ptrace.h.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: systemtap <systemtap@sources.redhat.com>
    Cc: DLE <dle-develop@lists.sourceforge.net>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Wenji Huang <wenji.huang@oracle.com>
    Cc: Mahesh J Salgaonkar <mahesh@linux.vnet.ibm.com>
    LKML-Reference: <20091201000222.7669.7477.stgit@harusame>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Suggested-by: Wenji Huang <wenji.huang@oracle.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index a3d49dd7d26e..3d11fd0f44c5 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -227,8 +227,8 @@ extern const char *regs_query_register_name(unsigned int offset);
  * @regs:	pt_regs from which register value is gotten.
  * @offset:	offset number of the register.
  *
- * regs_get_register returns the value of a register whose offset from @regs
- * is @offset. The @offset is the offset of the register in struct pt_regs.
+ * regs_get_register returns the value of a register. The @offset is the
+ * offset of the register in struct pt_regs address which specified by @regs.
  * If @offset is bigger than MAX_REG_OFFSET, this returns 0.
  */
 static inline unsigned long regs_get_register(struct pt_regs *regs,
@@ -244,7 +244,7 @@ static inline unsigned long regs_get_register(struct pt_regs *regs,
  * @regs:	pt_regs which contains kernel stack pointer.
  * @addr:	address which is checked.
  *
- * regs_within_kenel_stack() checks @addr is within the kernel stack page(s).
+ * regs_within_kernel_stack() checks @addr is within the kernel stack page(s).
  * If @addr is within the kernel stack, it returns true. If not, returns false.
  */
 static inline int regs_within_kernel_stack(struct pt_regs *regs,
@@ -260,7 +260,7 @@ static inline int regs_within_kernel_stack(struct pt_regs *regs,
  * @n:		stack entry number.
  *
  * regs_get_kernel_stack_nth() returns @n th entry of the kernel stack which
- * is specifined by @regs. If the @n th entry is NOT in the kernel stack,
+ * is specified by @regs. If the @n th entry is NOT in the kernel stack,
  * this returns 0.
  */
 static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,

commit b1cf540f0e5278ecfe8532557e547d833ed269d7
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Thu Aug 13 16:34:44 2009 -0400

    x86: Add pt_regs register and stack access APIs
    
    Add following APIs for accessing registers and stack entries from
    pt_regs.
    These APIs are required by kprobes-based event tracer on ftrace.
    Some other debugging tools might be able to use it too.
    
    - regs_query_register_offset(const char *name)
       Query the offset of "name" register.
    
    - regs_query_register_name(unsigned int offset)
       Query the name of register by its offset.
    
    - regs_get_register(struct pt_regs *regs, unsigned int offset)
       Get the value of a register by its offset.
    
    - regs_within_kernel_stack(struct pt_regs *regs, unsigned long addr)
       Check the address is in the kernel stack.
    
    - regs_get_kernel_stack_nth(struct pt_regs *reg, unsigned int nth)
       Get Nth entry of the kernel stack. (N >= 0)
    
    - regs_get_argument_nth(struct pt_regs *reg, unsigned int nth)
       Get Nth argument at function call. (N >= 0)
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: linux-arch@vger.kernel.org
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Frank Ch. Eigler <fche@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jason Baron <jbaron@redhat.com>
    Cc: Jim Keniston <jkenisto@us.ibm.com>
    Cc: K.Prasad <prasad@linux.vnet.ibm.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Przemysław Pawełczyk <przemyslaw@pawelczyk.it>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    Cc: Vegard Nossum <vegard.nossum@gmail.com>
    LKML-Reference: <20090813203444.31965.26374.stgit@localhost.localdomain>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 0f0d908349aa..a3d49dd7d26e 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -7,6 +7,7 @@
 
 #ifdef __KERNEL__
 #include <asm/segment.h>
+#include <asm/page_types.h>
 #endif
 
 #ifndef __ASSEMBLY__
@@ -216,6 +217,67 @@ static inline unsigned long user_stack_pointer(struct pt_regs *regs)
 	return regs->sp;
 }
 
+/* Query offset/name of register from its name/offset */
+extern int regs_query_register_offset(const char *name);
+extern const char *regs_query_register_name(unsigned int offset);
+#define MAX_REG_OFFSET (offsetof(struct pt_regs, ss))
+
+/**
+ * regs_get_register() - get register value from its offset
+ * @regs:	pt_regs from which register value is gotten.
+ * @offset:	offset number of the register.
+ *
+ * regs_get_register returns the value of a register whose offset from @regs
+ * is @offset. The @offset is the offset of the register in struct pt_regs.
+ * If @offset is bigger than MAX_REG_OFFSET, this returns 0.
+ */
+static inline unsigned long regs_get_register(struct pt_regs *regs,
+					      unsigned int offset)
+{
+	if (unlikely(offset > MAX_REG_OFFSET))
+		return 0;
+	return *(unsigned long *)((unsigned long)regs + offset);
+}
+
+/**
+ * regs_within_kernel_stack() - check the address in the stack
+ * @regs:	pt_regs which contains kernel stack pointer.
+ * @addr:	address which is checked.
+ *
+ * regs_within_kenel_stack() checks @addr is within the kernel stack page(s).
+ * If @addr is within the kernel stack, it returns true. If not, returns false.
+ */
+static inline int regs_within_kernel_stack(struct pt_regs *regs,
+					   unsigned long addr)
+{
+	return ((addr & ~(THREAD_SIZE - 1))  ==
+		(kernel_stack_pointer(regs) & ~(THREAD_SIZE - 1)));
+}
+
+/**
+ * regs_get_kernel_stack_nth() - get Nth entry of the stack
+ * @regs:	pt_regs which contains kernel stack pointer.
+ * @n:		stack entry number.
+ *
+ * regs_get_kernel_stack_nth() returns @n th entry of the kernel stack which
+ * is specifined by @regs. If the @n th entry is NOT in the kernel stack,
+ * this returns 0.
+ */
+static inline unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
+						      unsigned int n)
+{
+	unsigned long *addr = (unsigned long *)kernel_stack_pointer(regs);
+	addr += n;
+	if (regs_within_kernel_stack(regs, (unsigned long)addr))
+		return *addr;
+	else
+		return 0;
+}
+
+/* Get Nth argument at function call */
+extern unsigned long regs_get_argument_nth(struct pt_regs *regs,
+					   unsigned int n);
+
 /*
  * These are defined as per linux/ptrace.h, which see.
  */

commit 862366118026a358882eefc70238dbcc3db37aac
Merge: 57eee9ae7bbc 511b01bdf64a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 10 19:53:40 2009 -0700

    Merge branch 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (244 commits)
      Revert "x86, bts: reenable ptrace branch trace support"
      tracing: do not translate event helper macros in print format
      ftrace/documentation: fix typo in function grapher name
      tracing/events: convert block trace points to TRACE_EVENT(), fix !CONFIG_BLOCK
      tracing: add protection around module events unload
      tracing: add trace_seq_vprint interface
      tracing: fix the block trace points print size
      tracing/events: convert block trace points to TRACE_EVENT()
      ring-buffer: fix ret in rb_add_time_stamp
      ring-buffer: pass in lockdep class key for reader_lock
      tracing: add annotation to what type of stack trace is recorded
      tracing: fix multiple use of __print_flags and __print_symbolic
      tracing/events: fix output format of user stack
      tracing/events: fix output format of kernel stack
      tracing/trace_stack: fix the number of entries in the header
      ring-buffer: discard timestamps that are at the start of the buffer
      ring-buffer: try to discard unneeded timestamps
      ring-buffer: fix bug in ring_buffer_discard_commit
      ftrace: do not profile functions when disabled
      tracing: make trace pipe recognize latency format flag
      ...

commit 7b6c6c77732ca1d2498eda7eabb64f9648896e96
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Mon May 11 17:03:00 2009 -0400

    x86, 32-bit: fix kernel_trap_sp()
    
    Use &regs->sp instead of regs for getting the top of stack in kernel mode.
    (on x86-64, regs->sp always points the top of stack)
    
    [ Impact: Oprofile decodes only stack for backtracing on i386 ]
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    [ v2: rename the API to kernel_stack_pointer(), move variable inside ]
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: systemtap@sources.redhat.com
    Cc: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: Jan Blunck <jblunck@suse.de>
    Cc: Christoph Hellwig <hch@infradead.org>
    LKML-Reference: <20090511210300.17332.67549.stgit@localhost.localdomain>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index e304b66abeea..624f133943ed 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -187,14 +187,15 @@ static inline int v8086_mode(struct pt_regs *regs)
 
 /*
  * X86_32 CPUs don't save ss and esp if the CPU is already in kernel mode
- * when it traps.  So regs will be the current sp.
+ * when it traps.  The previous stack will be directly underneath the saved
+ * registers, and 'sp/ss' won't even have been saved. Thus the '&regs->sp'.
  *
  * This is valid only for kernel mode traps.
  */
-static inline unsigned long kernel_trap_sp(struct pt_regs *regs)
+static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32
-	return (unsigned long)regs;
+	return (unsigned long)(&regs->sp);
 #else
 	return regs->sp;
 #endif

commit 0f4814065ff8c24ca8bfd75c9b73502be152c287
Author: Markus Metzger <markus.t.metzger@intel.com>
Date:   Fri Apr 3 16:43:48 2009 +0200

    x86, ptrace: add bts context unconditionally
    
    Add the ptrace bts context field to task_struct unconditionally.
    
    Initialize the field directly in copy_process().
    Remove all the unneeded functionality used to initialize that field.
    
    Signed-off-by: Markus Metzger <markus.t.metzger@intel.com>
    Cc: roland@redhat.com
    Cc: eranian@googlemail.com
    Cc: oleg@redhat.com
    Cc: juan.villacis@intel.com
    Cc: ak@linux.jf.intel.com
    LKML-Reference: <20090403144603.292754000@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index e304b66abeea..5cdd19f20b5b 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -235,12 +235,11 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
-extern void x86_ptrace_untrace(struct task_struct *);
-extern void x86_ptrace_fork(struct task_struct *child,
-			    unsigned long clone_flags);
+#ifdef CONFIG_X86_PTRACE_BTS
+extern void ptrace_bts_untrace(struct task_struct *tsk);
 
-#define arch_ptrace_untrace(tsk) x86_ptrace_untrace(tsk)
-#define arch_ptrace_fork(child, flags) x86_ptrace_fork(child, flags)
+#define arch_ptrace_untrace(tsk)	ptrace_bts_untrace(tsk)
+#endif /* CONFIG_X86_PTRACE_BTS */
 
 #endif /* __KERNEL__ */
 

commit ccbeed3a05908d201b47b6c3dd1a373138bba566
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Feb 9 22:17:40 2009 +0900

    x86: make lazy %gs optional on x86_32
    
    Impact: pt_regs changed, lazy gs handling made optional, add slight
            overhead to SAVE_ALL, simplifies error_code path a bit
    
    On x86_32, %gs hasn't been used by kernel and handled lazily.  pt_regs
    doesn't have place for it and gs is saved/loaded only when necessary.
    In preparation for stack protector support, this patch makes lazy %gs
    handling optional by doing the followings.
    
    * Add CONFIG_X86_32_LAZY_GS and place for gs in pt_regs.
    
    * Save and restore %gs along with other registers in entry_32.S unless
      LAZY_GS.  Note that this unfortunately adds "pushl $0" on SAVE_ALL
      even when LAZY_GS.  However, it adds no overhead to common exit path
      and simplifies entry path with error code.
    
    * Define different user_gs accessors depending on LAZY_GS and add
      lazy_save_gs() and lazy_load_gs() which are noop if !LAZY_GS.  The
      lazy_*_gs() ops are used to save, load and clear %gs lazily.
    
    * Define ELF_CORE_COPY_KERNEL_REGS() which always read %gs directly.
    
    xen and lguest changes need to be verified.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index 6d34d954c228..e304b66abeea 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -28,7 +28,7 @@ struct pt_regs {
 	int  xds;
 	int  xes;
 	int  xfs;
-	/* int  gs; */
+	int  xgs;
 	long orig_eax;
 	long eip;
 	int  xcs;
@@ -50,7 +50,7 @@ struct pt_regs {
 	unsigned long ds;
 	unsigned long es;
 	unsigned long fs;
-	/* int  gs; */
+	unsigned long gs;
 	unsigned long orig_ax;
 	unsigned long ip;
 	unsigned long cs;

commit bf53de907dfdaac178c92d774aae7370d7b97d20
Author: Markus Metzger <markus.t.metzger@intel.com>
Date:   Fri Dec 19 15:10:24 2008 +0100

    x86, bts: add fork and exit handling
    
    Impact: introduce new ptrace facility
    
    Add arch_ptrace_untrace() function that is called when the tracer
    detaches (either voluntarily or when the tracing task dies);
    ptrace_disable() is only called on a voluntary detach.
    
    Add ptrace_fork() and arch_ptrace_fork(). They are called when a
    traced task is forked.
    
    Clear DS and BTS related fields on fork.
    
    Release DS resources and reclaim memory in ptrace_untrace(). This
    releases resources already when the tracing task dies. We used to do
    that when the traced task dies.
    
    Signed-off-by: Markus Metzger <markus.t.metzger@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index fbf744215911..6d34d954c228 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -235,6 +235,13 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
+extern void x86_ptrace_untrace(struct task_struct *);
+extern void x86_ptrace_fork(struct task_struct *child,
+			    unsigned long clone_flags);
+
+#define arch_ptrace_untrace(tsk) x86_ptrace_untrace(tsk)
+#define arch_ptrace_fork(child, flags) x86_ptrace_fork(child, flags)
+
 #endif /* __KERNEL__ */
 
 #endif /* !__ASSEMBLY__ */

commit c2724775ce57c98b8af9694857b941dc61056516
Author: Markus Metzger <markus.t.metzger@intel.com>
Date:   Thu Dec 11 13:49:59 2008 +0100

    x86, bts: provide in-kernel branch-trace interface
    
    Impact: cleanup
    
    Move the BTS bits from ptrace.c into ds.c.
    
    Signed-off-by: Markus Metzger <markus.t.metzger@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index eefb0594b058..fbf744215911 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -6,7 +6,6 @@
 #include <asm/processor-flags.h>
 
 #ifdef __KERNEL__
-#include <asm/ds.h>		/* the DS BTS struct is used for ptrace too */
 #include <asm/segment.h>
 #endif
 
@@ -128,34 +127,6 @@ struct pt_regs {
 #endif /* !__i386__ */
 
 
-#ifdef CONFIG_X86_PTRACE_BTS
-/* a branch trace record entry
- *
- * In order to unify the interface between various processor versions,
- * we use the below data structure for all processors.
- */
-enum bts_qualifier {
-	BTS_INVALID = 0,
-	BTS_BRANCH,
-	BTS_TASK_ARRIVES,
-	BTS_TASK_DEPARTS
-};
-
-struct bts_struct {
-	__u64 qualifier;
-	union {
-		/* BTS_BRANCH */
-		struct {
-			__u64 from_ip;
-			__u64 to_ip;
-		} lbr;
-		/* BTS_TASK_ARRIVES or
-		   BTS_TASK_DEPARTS */
-		__u64 jiffies;
-	} variant;
-};
-#endif /* CONFIG_X86_PTRACE_BTS */
-
 #ifdef __KERNEL__
 
 #include <linux/init.h>
@@ -163,13 +134,6 @@ struct bts_struct {
 struct cpuinfo_x86;
 struct task_struct;
 
-#ifdef CONFIG_X86_PTRACE_BTS
-extern void __cpuinit ptrace_bts_init_intel(struct cpuinfo_x86 *);
-extern void ptrace_bts_take_timestamp(struct task_struct *, enum bts_qualifier);
-#else
-#define ptrace_bts_init_intel(config) do {} while (0)
-#endif /* CONFIG_X86_PTRACE_BTS */
-
 extern unsigned long profile_pc(struct pt_regs *regs);
 
 extern unsigned long

commit 96b8936a9ed08746e47081458a5eb9e43a751e24
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 25 08:10:03 2008 +0100

    remove __ARCH_WANT_COMPAT_SYS_PTRACE
    
    All architectures now use the generic compat_sys_ptrace, as should every
    new architecture that needs 32bit compat (if we'll ever get another).
    
    Remove the now superflous __ARCH_WANT_COMPAT_SYS_PTRACE define, and also
    kill a comment about __ARCH_SYS_PTRACE that was added after
    __ARCH_SYS_PTRACE was already gone.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index d1531c8480b7..eefb0594b058 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -271,8 +271,6 @@ extern int do_get_thread_area(struct task_struct *p, int idx,
 extern int do_set_thread_area(struct task_struct *p, int idx,
 			      struct user_desc __user *info, int can_allocate);
 
-#define __ARCH_WANT_COMPAT_SYS_PTRACE
-
 #endif /* __KERNEL__ */
 
 #endif /* !__ASSEMBLY__ */

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
index a2025525a15a..d1531c8480b7 100644
--- a/arch/x86/include/asm/ptrace.h
+++ b/arch/x86/include/asm/ptrace.h
@@ -1,5 +1,5 @@
-#ifndef ASM_X86__PTRACE_H
-#define ASM_X86__PTRACE_H
+#ifndef _ASM_X86_PTRACE_H
+#define _ASM_X86_PTRACE_H
 
 #include <linux/compiler.h>	/* For __user */
 #include <asm/ptrace-abi.h>
@@ -277,4 +277,4 @@ extern int do_set_thread_area(struct task_struct *p, int idx,
 
 #endif /* !__ASSEMBLY__ */
 
-#endif /* ASM_X86__PTRACE_H */
+#endif /* _ASM_X86_PTRACE_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
new file mode 100644
index 000000000000..a2025525a15a
--- /dev/null
+++ b/arch/x86/include/asm/ptrace.h
@@ -0,0 +1,280 @@
+#ifndef ASM_X86__PTRACE_H
+#define ASM_X86__PTRACE_H
+
+#include <linux/compiler.h>	/* For __user */
+#include <asm/ptrace-abi.h>
+#include <asm/processor-flags.h>
+
+#ifdef __KERNEL__
+#include <asm/ds.h>		/* the DS BTS struct is used for ptrace too */
+#include <asm/segment.h>
+#endif
+
+#ifndef __ASSEMBLY__
+
+#ifdef __i386__
+/* this struct defines the way the registers are stored on the
+   stack during a system call. */
+
+#ifndef __KERNEL__
+
+struct pt_regs {
+	long ebx;
+	long ecx;
+	long edx;
+	long esi;
+	long edi;
+	long ebp;
+	long eax;
+	int  xds;
+	int  xes;
+	int  xfs;
+	/* int  gs; */
+	long orig_eax;
+	long eip;
+	int  xcs;
+	long eflags;
+	long esp;
+	int  xss;
+};
+
+#else /* __KERNEL__ */
+
+struct pt_regs {
+	unsigned long bx;
+	unsigned long cx;
+	unsigned long dx;
+	unsigned long si;
+	unsigned long di;
+	unsigned long bp;
+	unsigned long ax;
+	unsigned long ds;
+	unsigned long es;
+	unsigned long fs;
+	/* int  gs; */
+	unsigned long orig_ax;
+	unsigned long ip;
+	unsigned long cs;
+	unsigned long flags;
+	unsigned long sp;
+	unsigned long ss;
+};
+
+#endif /* __KERNEL__ */
+
+#else /* __i386__ */
+
+#ifndef __KERNEL__
+
+struct pt_regs {
+	unsigned long r15;
+	unsigned long r14;
+	unsigned long r13;
+	unsigned long r12;
+	unsigned long rbp;
+	unsigned long rbx;
+/* arguments: non interrupts/non tracing syscalls only save upto here*/
+	unsigned long r11;
+	unsigned long r10;
+	unsigned long r9;
+	unsigned long r8;
+	unsigned long rax;
+	unsigned long rcx;
+	unsigned long rdx;
+	unsigned long rsi;
+	unsigned long rdi;
+	unsigned long orig_rax;
+/* end of arguments */
+/* cpu exception frame or undefined */
+	unsigned long rip;
+	unsigned long cs;
+	unsigned long eflags;
+	unsigned long rsp;
+	unsigned long ss;
+/* top of stack page */
+};
+
+#else /* __KERNEL__ */
+
+struct pt_regs {
+	unsigned long r15;
+	unsigned long r14;
+	unsigned long r13;
+	unsigned long r12;
+	unsigned long bp;
+	unsigned long bx;
+/* arguments: non interrupts/non tracing syscalls only save upto here*/
+	unsigned long r11;
+	unsigned long r10;
+	unsigned long r9;
+	unsigned long r8;
+	unsigned long ax;
+	unsigned long cx;
+	unsigned long dx;
+	unsigned long si;
+	unsigned long di;
+	unsigned long orig_ax;
+/* end of arguments */
+/* cpu exception frame or undefined */
+	unsigned long ip;
+	unsigned long cs;
+	unsigned long flags;
+	unsigned long sp;
+	unsigned long ss;
+/* top of stack page */
+};
+
+#endif /* __KERNEL__ */
+#endif /* !__i386__ */
+
+
+#ifdef CONFIG_X86_PTRACE_BTS
+/* a branch trace record entry
+ *
+ * In order to unify the interface between various processor versions,
+ * we use the below data structure for all processors.
+ */
+enum bts_qualifier {
+	BTS_INVALID = 0,
+	BTS_BRANCH,
+	BTS_TASK_ARRIVES,
+	BTS_TASK_DEPARTS
+};
+
+struct bts_struct {
+	__u64 qualifier;
+	union {
+		/* BTS_BRANCH */
+		struct {
+			__u64 from_ip;
+			__u64 to_ip;
+		} lbr;
+		/* BTS_TASK_ARRIVES or
+		   BTS_TASK_DEPARTS */
+		__u64 jiffies;
+	} variant;
+};
+#endif /* CONFIG_X86_PTRACE_BTS */
+
+#ifdef __KERNEL__
+
+#include <linux/init.h>
+
+struct cpuinfo_x86;
+struct task_struct;
+
+#ifdef CONFIG_X86_PTRACE_BTS
+extern void __cpuinit ptrace_bts_init_intel(struct cpuinfo_x86 *);
+extern void ptrace_bts_take_timestamp(struct task_struct *, enum bts_qualifier);
+#else
+#define ptrace_bts_init_intel(config) do {} while (0)
+#endif /* CONFIG_X86_PTRACE_BTS */
+
+extern unsigned long profile_pc(struct pt_regs *regs);
+
+extern unsigned long
+convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs);
+extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs,
+			 int error_code, int si_code);
+void signal_fault(struct pt_regs *regs, void __user *frame, char *where);
+
+extern long syscall_trace_enter(struct pt_regs *);
+extern void syscall_trace_leave(struct pt_regs *);
+
+static inline unsigned long regs_return_value(struct pt_regs *regs)
+{
+	return regs->ax;
+}
+
+/*
+ * user_mode_vm(regs) determines whether a register set came from user mode.
+ * This is true if V8086 mode was enabled OR if the register set was from
+ * protected mode with RPL-3 CS value.  This tricky test checks that with
+ * one comparison.  Many places in the kernel can bypass this full check
+ * if they have already ruled out V8086 mode, so user_mode(regs) can be used.
+ */
+static inline int user_mode(struct pt_regs *regs)
+{
+#ifdef CONFIG_X86_32
+	return (regs->cs & SEGMENT_RPL_MASK) == USER_RPL;
+#else
+	return !!(regs->cs & 3);
+#endif
+}
+
+static inline int user_mode_vm(struct pt_regs *regs)
+{
+#ifdef CONFIG_X86_32
+	return ((regs->cs & SEGMENT_RPL_MASK) | (regs->flags & X86_VM_MASK)) >=
+		USER_RPL;
+#else
+	return user_mode(regs);
+#endif
+}
+
+static inline int v8086_mode(struct pt_regs *regs)
+{
+#ifdef CONFIG_X86_32
+	return (regs->flags & X86_VM_MASK);
+#else
+	return 0;	/* No V86 mode support in long mode */
+#endif
+}
+
+/*
+ * X86_32 CPUs don't save ss and esp if the CPU is already in kernel mode
+ * when it traps.  So regs will be the current sp.
+ *
+ * This is valid only for kernel mode traps.
+ */
+static inline unsigned long kernel_trap_sp(struct pt_regs *regs)
+{
+#ifdef CONFIG_X86_32
+	return (unsigned long)regs;
+#else
+	return regs->sp;
+#endif
+}
+
+static inline unsigned long instruction_pointer(struct pt_regs *regs)
+{
+	return regs->ip;
+}
+
+static inline unsigned long frame_pointer(struct pt_regs *regs)
+{
+	return regs->bp;
+}
+
+static inline unsigned long user_stack_pointer(struct pt_regs *regs)
+{
+	return regs->sp;
+}
+
+/*
+ * These are defined as per linux/ptrace.h, which see.
+ */
+#define arch_has_single_step()	(1)
+extern void user_enable_single_step(struct task_struct *);
+extern void user_disable_single_step(struct task_struct *);
+
+extern void user_enable_block_step(struct task_struct *);
+#ifdef CONFIG_X86_DEBUGCTLMSR
+#define arch_has_block_step()	(1)
+#else
+#define arch_has_block_step()	(boot_cpu_data.x86 >= 6)
+#endif
+
+struct user_desc;
+extern int do_get_thread_area(struct task_struct *p, int idx,
+			      struct user_desc __user *info);
+extern int do_set_thread_area(struct task_struct *p, int idx,
+			      struct user_desc __user *info, int can_allocate);
+
+#define __ARCH_WANT_COMPAT_SYS_PTRACE
+
+#endif /* __KERNEL__ */
+
+#endif /* !__ASSEMBLY__ */
+
+#endif /* ASM_X86__PTRACE_H */
