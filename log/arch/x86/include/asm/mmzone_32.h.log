commit 431732651cc16caebcd334b7b7476bfe0c4a2903
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Sun Feb 23 11:43:22 2020 +0200

    x86/mm: Drop deprecated DISCONTIGMEM support for 32-bit
    
    The DISCONTIGMEM support was marked as deprecated in v5.2 and since there
    were no complaints about it for almost 5 releases it can be completely
    removed.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Dave Hansen <dave.hansen@linux.intel.com>
    Link: https://lkml.kernel.org/r/20200223094322.15206-1-rppt@kernel.org

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 73d8dd14dda2..2d4515e8b7df 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -14,43 +14,4 @@ extern struct pglist_data *node_data[];
 #define NODE_DATA(nid)	(node_data[nid])
 #endif /* CONFIG_NUMA */
 
-#ifdef CONFIG_DISCONTIGMEM
-
-/*
- * generic node memory support, the following assumptions apply:
- *
- * 1) memory comes in 64Mb contiguous chunks which are either present or not
- * 2) we will not have more than 64Gb in total
- *
- * for now assume that 64Gb is max amount of RAM for whole system
- *    64Gb / 4096bytes/page = 16777216 pages
- */
-#define MAX_NR_PAGES 16777216
-#define MAX_SECTIONS 1024
-#define PAGES_PER_SECTION (MAX_NR_PAGES/MAX_SECTIONS)
-
-extern s8 physnode_map[];
-
-static inline int pfn_to_nid(unsigned long pfn)
-{
-#ifdef CONFIG_NUMA
-	return((int) physnode_map[(pfn) / PAGES_PER_SECTION]);
-#else
-	return 0;
-#endif
-}
-
-static inline int pfn_valid(int pfn)
-{
-	int nid = pfn_to_nid(pfn);
-
-	if (nid >= 0)
-		return (pfn < node_end_pfn(nid));
-	return 0;
-}
-
-#define early_pfn_valid(pfn)	pfn_valid((pfn))
-
-#endif /* CONFIG_DISCONTIGMEM */
-
 #endif /* _ASM_X86_MMZONE_32_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 1ec990bd7dc0..73d8dd14dda2 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Written by Pat Gaughen (gone@us.ibm.com) Mar 2002
  *

commit b5660ba76b41af69a0c09d434927bb4b4cadd4b1
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Tue Feb 25 12:14:06 2014 -0800

    x86, platforms: Remove NUMAQ
    
    The NUMAQ support seems to be unmaintained, remove it.
    
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: David Rientjes <rientjes@google.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Link: http://lkml.kernel.org/r/n/530CFD6C.7040705@zytor.com

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 8a9b3e288cb4..1ec990bd7dc0 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -11,9 +11,6 @@
 #ifdef CONFIG_NUMA
 extern struct pglist_data *node_data[];
 #define NODE_DATA(nid)	(node_data[nid])
-
-#include <asm/numaq.h>
-
 #endif /* CONFIG_NUMA */
 
 #ifdef CONFIG_DISCONTIGMEM

commit bb112aec5ee41427e9b9726e3d57b896709598ed
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Thu Jan 31 13:53:10 2013 -0800

    x86-32, mm: Remove reference to resume_map_numa_kva()
    
    Remove reference to removed function resume_map_numa_kva().
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: Dave Hansen <dave@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>
    Link: http://lkml.kernel.org/r/20130131005616.1C79F411@kernel.stglabs.ibm.com

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index eb05fb3b02fb..8a9b3e288cb4 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -14,12 +14,6 @@ extern struct pglist_data *node_data[];
 
 #include <asm/numaq.h>
 
-extern void resume_map_numa_kva(pgd_t *pgd);
-
-#else /* !CONFIG_NUMA */
-
-static inline void resume_map_numa_kva(pgd_t *pgd) {}
-
 #endif /* CONFIG_NUMA */
 
 #ifdef CONFIG_DISCONTIGMEM

commit 302616911da8e868d3f1a00dce517ca30b0e065d
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Fri Apr 6 14:47:35 2012 +0200

    x86: Drop obsolete ARCH_BOOTMEM support
    
    x86 unconditionally uses NO_BOOTMEM so there is no use
    of the HAVE_ARCH_BOOTMEM support as mm/bootmem.c is the
    only file referencing this symbol.
    
    bootmem_arch_preferred_node() is the function referred
    in the mm/bootmem.c code and can thuis be dropped too.
    
    x86 was the sole user of HAVE_ARCH_BOOTMEM - so there is
    an opportunity to clean up a little in mm/bootmem.c too
    if we do not expect other users to emerge.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Cc: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/20120406124735.GA6920@merkur.ravnborg.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 55728e121473..eb05fb3b02fb 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -61,10 +61,4 @@ static inline int pfn_valid(int pfn)
 
 #endif /* CONFIG_DISCONTIGMEM */
 
-#ifdef CONFIG_NEED_MULTIPLE_NODES
-/* always use node 0 for bootmem on this numa platform */
-#define bootmem_arch_preferred_node(__bdata, size, align, goal, limit)	\
-	(NODE_DATA(0)->bdata)
-#endif /* CONFIG_NEED_MULTIPLE_NODES */
-
 #endif /* _ASM_X86_MMZONE_32_H */

commit d0ead157387f19801beb1b419568723b2e9b7c79
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 12 09:44:22 2011 +0200

    x86, mm: s/PAGES_PER_ELEMENT/PAGES_PER_SECTION/
    
    DISCONTIGMEM on x86-32 implements pfn -> nid mapping similarly to
    SPARSEMEM; however, it calls each mapping unit ELEMENT instead of
    SECTION.  This patch renames it to SECTION so that PAGES_PER_SECTION
    is valid for both DISCONTIGMEM and SPARSEMEM.  This will be used by
    the next patch to implement mapping granularity check.
    
    This patch is trivial constant rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Link: http://lkml.kernel.org/r/20110712074422.GA2872@htj.dyndns.org
    Cc: Hans Rosenfeld <hans.rosenfeld@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index ffa037f28d39..55728e121473 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -34,15 +34,15 @@ static inline void resume_map_numa_kva(pgd_t *pgd) {}
  *    64Gb / 4096bytes/page = 16777216 pages
  */
 #define MAX_NR_PAGES 16777216
-#define MAX_ELEMENTS 1024
-#define PAGES_PER_ELEMENT (MAX_NR_PAGES/MAX_ELEMENTS)
+#define MAX_SECTIONS 1024
+#define PAGES_PER_SECTION (MAX_NR_PAGES/MAX_SECTIONS)
 
 extern s8 physnode_map[];
 
 static inline int pfn_to_nid(unsigned long pfn)
 {
 #ifdef CONFIG_NUMA
-	return((int) physnode_map[(pfn) / PAGES_PER_ELEMENT]);
+	return((int) physnode_map[(pfn) / PAGES_PER_SECTION]);
 #else
 	return 0;
 #endif

commit a26474e8649643e82d71e3a386d5c4bcc0b207ef
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 28 11:41:07 2011 +0200

    x86-32, NUMA: Fix boot regression caused by NUMA init unification on highmem machines
    
    During 32/64 NUMA init unification, commit 797390d855 ("x86-32,
    NUMA: use sparse_memory_present_with_active_regions()") made
    32bit mm init call memory_present() automatically from
    active_regions instead of leaving it to each NUMA init path.
    
    This commit description is inaccurate - memory_present() calls
    aren't the same for flat and numaq.  After the commit,
    memory_present() is only called for the intersection of e820 and
    NUMA layout.  Before, on flatmem, memory_present() would be
    called from 0 to max_pfn.  After, it would be called only on the
    areas that e820 indicates to be populated.
    
    This is how x86_64 works and should be okay as memmap is allowed
    to contain holes; however, x86_32 DISCONTIGMEM is missing
    early_pfn_valid(), which makes memmap_init_zone() assume that
    memmap doesn't contain any hole.  This leads to the following
    oops if e820 map contains holes as it often does on machine with
    near or more 4GiB of memory by calling pfn_to_page() on a pfn
    which isn't mapped to a NUMA node, a reported by Conny Seidel:
    
      BUG: unable to handle kernel paging request at 000012b0
      IP: [<c1aa13ce>] memmap_init_zone+0x6c/0xf2
      *pdpt =3D 0000000000000000 *pde =3D f000eef3f000ee00
      Oops: 0000 [#1] SMP
      last sysfs file:
      Modules linked in:
    
      Pid: 0, comm: swapper Not tainted 2.6.39-rc5-00164-g797390d #1 To Be Filled By O.E.M. To Be Filled By O.E.M./E350M1
      EIP: 0060:[<c1aa13ce>] EFLAGS: 00010012 CPU: 0
      EIP is at memmap_init_zone+0x6c/0xf2
      EAX: 00000000 EBX: 000a8000 ECX: 000a7fff EDX: f2c00b80
      ESI: 000a8000 EDI: f2c00800 EBP: c19ffe54 ESP: c19ffe34
       DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: 0068
      Process swapper (pid: 0, ti=3Dc19fe000 task=3Dc1a07f60 task.ti=3Dc19fe000)
      Stack:
       00000002 00000000 0023f000 00000000 10000000 00000a00 f2c00000 f2c00b58
       c19ffeb0 c1a80f24 000375fe 00000000 f2c00800 00000800 00000100 00000030
       c1abb768 0000003c 00000000 00000000 00000004 00207a02 f2c00800 000375fe
      Call Trace:
       [<c1a80f24>] free_area_init_node+0x358/0x385
       [<c1a81384>] free_area_init_nodes+0x420/0x487
       [<c1a79326>] paging_init+0x114/0x11b
       [<c1a6cb13>] setup_arch+0xb37/0xc0a
       [<c1a69554>] start_kernel+0x76/0x316
       [<c1a690a8>] i386_start_kernel+0xa8/0xb0
    
    This patch fixes the bug by defining early_pfn_valid() to be the
    same as pfn_valid() when DISCONTIGMEM.
    
    Reported-bisected-and-tested-by: Conny Seidel <conny.seidel@amd.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: hans.rosenfeld@amd.com
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Conny Seidel <conny.seidel@amd.com>
    Link: http://lkml.kernel.org/r/20110628094107.GB3386@htj.dyndns.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 224e8c5eb307..ffa037f28d39 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -57,6 +57,8 @@ static inline int pfn_valid(int pfn)
 	return 0;
 }
 
+#define early_pfn_valid(pfn)	pfn_valid((pfn))
+
 #endif /* CONFIG_DISCONTIGMEM */
 
 #ifdef CONFIG_NEED_MULTIPLE_NODES

commit c6830c22603aaecf65405af23f6da2d55892f9cb
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Jun 16 17:28:07 2011 +0900

    Fix node_start/end_pfn() definition for mm/page_cgroup.c
    
    commit 21a3c96 uses node_start/end_pfn(nid) for detection start/end
    of nodes. But, it's not defined in linux/mmzone.h but defined in
    /arch/???/include/mmzone.h which is included only under
    CONFIG_NEED_MULTIPLE_NODES=y.
    
    Then, we see
      mm/page_cgroup.c: In function 'page_cgroup_init':
      mm/page_cgroup.c:308: error: implicit declaration of function 'node_start_pfn'
      mm/page_cgroup.c:309: error: implicit declaration of function 'node_end_pfn'
    
    So, fixiing page_cgroup.c is an idea...
    
    But node_start_pfn()/node_end_pfn() is a very generic macro and
    should be implemented in the same manner for all archs.
    (m32r has different implementation...)
    
    This patch removes definitions of node_start/end_pfn() in each archs
    and defines a unified one in linux/mmzone.h. It's not under
    CONFIG_NEED_MULTIPLE_NODES, now.
    
    A result of macro expansion is here (mm/page_cgroup.c)
    
    for !NUMA
     start_pfn = ((&contig_page_data)->node_start_pfn);
      end_pfn = ({ pg_data_t *__pgdat = (&contig_page_data); __pgdat->node_start_pfn + __pgdat->node_spanned_pages;});
    
    for NUMA (x86-64)
      start_pfn = ((node_data[nid])->node_start_pfn);
      end_pfn = ({ pg_data_t *__pgdat = (node_data[nid]); __pgdat->node_start_pfn + __pgdat->node_spanned_pages;});
    
    Changelog:
     - fixed to avoid using "nid" twice in node_end_pfn() macro.
    
    Reported-and-acked-by: Randy Dunlap <randy.dunlap@oracle.com>
    Reported-and-tested-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 5e83a416eca8..224e8c5eb307 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -48,17 +48,6 @@ static inline int pfn_to_nid(unsigned long pfn)
 #endif
 }
 
-/*
- * Following are macros that each numa implmentation must define.
- */
-
-#define node_start_pfn(nid)	(NODE_DATA(nid)->node_start_pfn)
-#define node_end_pfn(nid)						\
-({									\
-	pg_data_t *__pgdat = NODE_DATA(nid);				\
-	__pgdat->node_start_pfn + __pgdat->node_spanned_pages;		\
-})
-
 static inline int pfn_valid(int pfn)
 {
 	int nid = pfn_to_nid(pfn);

commit 5acd91ab837c9d066af7345aea6462dc55695db7
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 2 14:18:53 2011 +0200

    x86-32, NUMA: Replace srat_32.c with srat.c
    
    SRAT support implementation in srat_32.c and srat.c are generally
    similar; however, there are some differences.
    
    First of all, 64bit implementation supports more types of SRAT
    entries.  64bit supports x2apic, affinity, memory and SLIT.  32bit
    only supports processor and memory.
    
    Most other differences stem from different initialization protocols
    employed by 64bit and 32bit NUMA init paths.
    
    On 64bit,
    
    * Mappings among PXM, node and apicid are directly done in each SRAT
      entry callback.
    
    * Memory affinity information is passed to numa_add_memblk() which
      takes care of all interfacing with NUMA init.
    
    * Doesn't directly initialize NUMA configurations.  All the
      information is recorded in numa_nodes_parsed and memblks.
    
    On 32bit,
    
    * Checks numa_off.
    
    * Things go through one more level of indirection via private tables
      but eventually end up initializing the same mappings.
    
    * node_start/end_pfn[] are initialized and
      memblock_x86_register_active_regions() is called for each memory
      chunk.
    
    * node_set_online() is called for each online node.
    
    * sort_node_map() is called.
    
    There are also other minor differences in sanity checking and messages
    but taking 64bit version should be good enough.
    
    This patch drops the 32bit specific implementation and makes the 64bit
    implementation common for both 32 and 64bit.
    
    The init protocol differences are dealt with in two places - the
    numa_add_memblk() shim added in the previous patch and new temporary
    numa_32.c:get_memcfg_from_srat() which wraps invocation of
    x86_acpi_numa_init().
    
    The shim numa_add_memblk() handles the folowings.
    
    * node_start/end_pfn[] initialization.
    
    * node_set_online() for memory nodes.
    
    * Invocation of memblock_x86_register_active_regions().
    
    The shim get_memcfg_from_srat() handles the followings.
    
    * numa_off check.
    
    * node_set_online() for CPU nodes.
    
    * sort_node_map() invocation.
    
    * Clearing of numa_nodes_parsed and active_ranges on failure.
    
    The shims are temporary and will be removed as the generic NUMA init
    path in 32bit is replaced with 64bit one.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 73e5745aef34..5e83a416eca8 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -13,8 +13,6 @@ extern struct pglist_data *node_data[];
 #define NODE_DATA(nid)	(node_data[nid])
 
 #include <asm/numaq.h>
-/* summit or generic arch */
-#include <asm/srat.h>
 
 extern void resume_map_numa_kva(pgd_t *pgd);
 

commit daf4f480ae24270bac06db4293908d36b4834e21
Author: Tejun Heo <tj@kernel.org>
Date:   Mon May 2 14:18:53 2011 +0200

    x86-32, NUMA: Move get_memcfg_numa() into numa_32.c
    
    There's no reason get_memcfg_numa() to be implemented inline in
    mmzone_32.h.  Move it to numa_32.c and also make
    get_memcfg_numa_flag() static.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 91df7c51806c..73e5745aef34 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -16,28 +16,10 @@ extern struct pglist_data *node_data[];
 /* summit or generic arch */
 #include <asm/srat.h>
 
-extern int get_memcfg_numa_flat(void);
-/*
- * This allows any one NUMA architecture to be compiled
- * for, and still fall back to the flat function if it
- * fails.
- */
-static inline void get_memcfg_numa(void)
-{
-
-	if (get_memcfg_numaq())
-		return;
-	if (get_memcfg_from_srat())
-		return;
-	get_memcfg_numa_flat();
-}
-
 extern void resume_map_numa_kva(pgd_t *pgd);
 
 #else /* !CONFIG_NUMA */
 
-#define get_memcfg_numa get_memcfg_numa_flat
-
 static inline void resume_map_numa_kva(pgd_t *pgd) {}
 
 #endif /* CONFIG_NUMA */

commit af901ca181d92aac3a7dc265144a9081a86d8f39
Author: André Goddard Rosa <andre.goddard@gmail.com>
Date:   Sat Nov 14 13:09:05 2009 -0200

    tree-wide: fix assorted typos all over the place
    
    That is "success", "unknown", "through", "performance", "[re|un]mapping"
    , "access", "default", "reasonable", "[con]currently", "temperature"
    , "channel", "[un]used", "application", "example","hierarchy", "therefore"
    , "[over|under]flow", "contiguous", "threshold", "enough" and others.
    
    Signed-off-by: André Goddard Rosa <andre.goddard@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index ede6998bd92c..91df7c51806c 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -47,7 +47,7 @@ static inline void resume_map_numa_kva(pgd_t *pgd) {}
 /*
  * generic node memory support, the following assumptions apply:
  *
- * 1) memory comes in 64Mb contigious chunks which are either present or not
+ * 1) memory comes in 64Mb contiguous chunks which are either present or not
  * 2) we will not have more than 64Gb in total
  *
  * for now assume that 64Gb is max amount of RAM for whole system

commit d0c4f570276cb4d2dc4215b90eb7cb6e2bdd4a15
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Mar 1 16:06:56 2009 +0900

    bootmem, x86: further fixes for arch-specific bootmem wrapping
    
    Impact: fix new breakages introduced by previous fix
    
    Commit c132937556f56ee4b831ef4b23f1846e05fde102 tried to clean up
    bootmem arch wrapper but it wasn't quite correct.  Before the commit,
    the followings were broken.
    
    * Low level interface functions prefixed with __ ignored arch
      preference.
    
    * reserve_bootmem(...) can't be mapped into
      reserve_bootmem_node(NODE_DATA(0)->bdata, ...) because the node is
      not preference here.  The region specified MUST fall into the
      specified region; otherwise, it will panic.
    
    After the commit,
    
    * If allocation fails for the arch preferred node, it should fallback
      to whatever is available.  Instead, it simply failed allocation.
    
    There are too many internal details to allow generic wrapping and
    still keep things simple for archs.  Plus, all that arch wants is a
    way to prefer certain node over another.
    
    This patch drops the generic wrapping around alloc_bootmem_core() and
    add alloc_bootmem_core() instead.  If necessary, arch can define
    bootmem_arch_referred_node() macro or function which takes all
    allocation information and returns the preferred node.  bootmem
    generic code will always try the preferred node first and then
    fallback to other nodes as usual.
    
    Breakages noted and changes reviewed by Johannes Weiner.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index eeacf67de49e..ede6998bd92c 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -92,12 +92,8 @@ static inline int pfn_valid(int pfn)
 
 #ifdef CONFIG_NEED_MULTIPLE_NODES
 /* always use node 0 for bootmem on this numa platform */
-#define alloc_bootmem_core(__bdata, size, align, goal, limit)		\
-({									\
-	bootmem_data_t __maybe_unused *	__abm_bdata_dummy = (__bdata);	\
-	__alloc_bootmem_core(NODE_DATA(0)->bdata,			\
-			     (size), (align), (goal), (limit));		\
-})
+#define bootmem_arch_preferred_node(__bdata, size, align, goal, limit)	\
+	(NODE_DATA(0)->bdata)
 #endif /* CONFIG_NEED_MULTIPLE_NODES */
 
 #endif /* _ASM_X86_MMZONE_32_H */

commit 0edcf8d6926f4038443dbc24e319530177ca0353
Merge: 87b203079ed9 40150d37be7f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 24 21:52:45 2009 +0100

    Merge branch 'tj-percpu' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/misc into core/percpu
    
    Conflicts:
            arch/x86/include/asm/pgtable.h

commit c132937556f56ee4b831ef4b23f1846e05fde102
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 24 11:57:20 2009 +0900

    bootmem: clean up arch-specific bootmem wrapping
    
    Impact: cleaner and consistent bootmem wrapping
    
    By setting CONFIG_HAVE_ARCH_BOOTMEM_NODE, archs can define
    arch-specific wrappers for bootmem allocation.  However, this is done
    a bit strangely in that only the high level convenience macros can be
    changed while lower level, but still exported, interface functions
    can't be wrapped.  This not only is messy but also leads to strange
    situation where alloc_bootmem() does what the arch wants it to do but
    the equivalent __alloc_bootmem() call doesn't although they should be
    able to be used interchangeably.
    
    This patch updates bootmem such that archs can override / wrap the
    backend function - alloc_bootmem_core() instead of the highlevel
    interface functions to allow simpler and consistent wrapping.  Also,
    HAVE_ARCH_BOOTMEM_NODE is renamed to HAVE_ARCH_BOOTMEM.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Johannes Weiner <hannes@saeurebad.de>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 07f1af494ca5..1e0fa9e63afa 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -93,45 +93,12 @@ static inline int pfn_valid(int pfn)
 #endif /* CONFIG_DISCONTIGMEM */
 
 #ifdef CONFIG_NEED_MULTIPLE_NODES
-
-/*
- * Following are macros that are specific to this numa platform.
- */
-#define reserve_bootmem(addr, size, flags) \
-	reserve_bootmem_node(NODE_DATA(0), (addr), (size), (flags))
-#define alloc_bootmem(x) \
-	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES, __pa(MAX_DMA_ADDRESS))
-#define alloc_bootmem_nopanic(x) \
-	__alloc_bootmem_node_nopanic(NODE_DATA(0), (x), SMP_CACHE_BYTES, \
-				__pa(MAX_DMA_ADDRESS))
-#define alloc_bootmem_low(x) \
-	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES, 0)
-#define alloc_bootmem_pages(x) \
-	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, __pa(MAX_DMA_ADDRESS))
-#define alloc_bootmem_pages_nopanic(x) \
-	__alloc_bootmem_node_nopanic(NODE_DATA(0), (x), PAGE_SIZE, \
-				__pa(MAX_DMA_ADDRESS))
-#define alloc_bootmem_low_pages(x) \
-	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, 0)
-#define alloc_bootmem_node(pgdat, x)					\
-({									\
-	struct pglist_data  __maybe_unused			\
-				*__alloc_bootmem_node__pgdat = (pgdat);	\
-	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES,	\
-						__pa(MAX_DMA_ADDRESS));	\
-})
-#define alloc_bootmem_pages_node(pgdat, x)				\
-({									\
-	struct pglist_data  __maybe_unused			\
-				*__alloc_bootmem_node__pgdat = (pgdat);	\
-	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE,		\
-						__pa(MAX_DMA_ADDRESS));	\
-})
-#define alloc_bootmem_low_pages_node(pgdat, x)				\
+/* always use node 0 for bootmem on this numa platform */
+#define alloc_bootmem_core(__bdata, size, align, goal, limit)		\
 ({									\
-	struct pglist_data  __maybe_unused			\
-				*__alloc_bootmem_node__pgdat = (pgdat);	\
-	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, 0);		\
+	bootmem_data_t __maybe_unused *	__abm_bdata_dummy = (__bdata);	\
+	__alloc_bootmem_core(NODE_DATA(0)->bdata,			\
+			     (size), (align), (goal), (limit));		\
 })
 #endif /* CONFIG_NEED_MULTIPLE_NODES */
 

commit f2dbcfa738368c8a40d4a5f0b65dc9879577cb21
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Feb 18 14:48:32 2009 -0800

    mm: clean up for early_pfn_to_nid()
    
    What's happening is that the assertion in mm/page_alloc.c:move_freepages()
    is triggering:
    
            BUG_ON(page_zone(start_page) != page_zone(end_page));
    
    Once I knew this is what was happening, I added some annotations:
    
            if (unlikely(page_zone(start_page) != page_zone(end_page))) {
                    printk(KERN_ERR "move_freepages: Bogus zones: "
                           "start_page[%p] end_page[%p] zone[%p]\n",
                           start_page, end_page, zone);
                    printk(KERN_ERR "move_freepages: "
                           "start_zone[%p] end_zone[%p]\n",
                           page_zone(start_page), page_zone(end_page));
                    printk(KERN_ERR "move_freepages: "
                           "start_pfn[0x%lx] end_pfn[0x%lx]\n",
                           page_to_pfn(start_page), page_to_pfn(end_page));
                    printk(KERN_ERR "move_freepages: "
                           "start_nid[%d] end_nid[%d]\n",
                           page_to_nid(start_page), page_to_nid(end_page));
     ...
    
    And here's what I got:
    
            move_freepages: Bogus zones: start_page[2207d0000] end_page[2207dffc0] zone[fffff8103effcb00]
            move_freepages: start_zone[fffff8103effcb00] end_zone[fffff8003fffeb00]
            move_freepages: start_pfn[0x81f600] end_pfn[0x81f7ff]
            move_freepages: start_nid[1] end_nid[0]
    
    My memory layout on this box is:
    
    [    0.000000] Zone PFN ranges:
    [    0.000000]   Normal   0x00000000 -> 0x0081ff5d
    [    0.000000] Movable zone start PFN for each node
    [    0.000000] early_node_map[8] active PFN ranges
    [    0.000000]     0: 0x00000000 -> 0x00020000
    [    0.000000]     1: 0x00800000 -> 0x0081f7ff
    [    0.000000]     1: 0x0081f800 -> 0x0081fe50
    [    0.000000]     1: 0x0081fed1 -> 0x0081fed8
    [    0.000000]     1: 0x0081feda -> 0x0081fedb
    [    0.000000]     1: 0x0081fedd -> 0x0081fee5
    [    0.000000]     1: 0x0081fee7 -> 0x0081ff51
    [    0.000000]     1: 0x0081ff59 -> 0x0081ff5d
    
    So it's a block move in that 0x81f600-->0x81f7ff region which triggers
    the problem.
    
    This patch:
    
    Declaration of early_pfn_to_nid() is scattered over per-arch include
    files, and it seems it's complicated to know when the declaration is used.
     I think it makes fix-for-memmap-init not easy.
    
    This patch moves all declaration to include/linux/mm.h
    
    After this,
      if !CONFIG_NODES_POPULATES_NODE_MAP && !CONFIG_HAVE_ARCH_EARLY_PFN_TO_NID
         -> Use static definition in include/linux/mm.h
      else if !CONFIG_HAVE_ARCH_EARLY_PFN_TO_NID
         -> Use generic definition in mm/page_alloc.c
      else
         -> per-arch back end function will be called.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Reported-by: David Miller <davem@davemlloft.net>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: <stable@kernel.org>         [2.6.25.x, 2.6.26.x, 2.6.27.x, 2.6.28.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 07f1af494ca5..105fb90a0635 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -32,8 +32,6 @@ static inline void get_memcfg_numa(void)
 	get_memcfg_numa_flat();
 }
 
-extern int early_pfn_to_nid(unsigned long pfn);
-
 extern void resume_map_numa_kva(pgd_t *pgd);
 
 #else /* !CONFIG_NUMA */

commit 97a70e548bd97d5a46ae9d44f24aafcc013fd701
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Nov 12 23:22:35 2008 +0100

    x86, hibernate: fix breakage on x86_32 with CONFIG_NUMA set
    
    Impact: fix crash during hibernation on 32-bit NUMA
    
    The NUMA code on x86_32 creates special memory mapping that allows
    each node's pgdat to be located in this node's memory.  For this
    purpose it allocates a memory area at the end of each node's memory
    and maps this area so that it is accessible with virtual addresses
    belonging to low memory.  As a result, if there is high memory,
    these NUMA-allocated areas are physically located in high memory,
    although they are mapped to low memory addresses.
    
    Our hibernation code does not take that into account and for this
    reason hibernation fails on all x86_32 systems with CONFIG_NUMA=y and
    with high memory present.  Fix this by adding a special mapping for
    the NUMA-allocated memory areas to the temporary page tables created
    during the last phase of resume.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 485bdf059ffb..07f1af494ca5 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -34,10 +34,14 @@ static inline void get_memcfg_numa(void)
 
 extern int early_pfn_to_nid(unsigned long pfn);
 
+extern void resume_map_numa_kva(pgd_t *pgd);
+
 #else /* !CONFIG_NUMA */
 
 #define get_memcfg_numa get_memcfg_numa_flat
 
+static inline void resume_map_numa_kva(pgd_t *pgd) {}
+
 #endif /* CONFIG_NUMA */
 
 #ifdef CONFIG_DISCONTIGMEM

commit 1965aae3c98397aad957412413c07e97b1bd4e64
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Oct 22 22:26:29 2008 -0700

    x86: Fix ASM_X86__ header guards
    
    Change header guards named "ASM_X86__*" to "_ASM_X86_*" since:
    
    a. the double underscore is ugly and pointless.
    b. no leading underscore violates namespace constraints.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
index 121b65d61d86..485bdf059ffb 100644
--- a/arch/x86/include/asm/mmzone_32.h
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -3,8 +3,8 @@
  *
  */
 
-#ifndef ASM_X86__MMZONE_32_H
-#define ASM_X86__MMZONE_32_H
+#ifndef _ASM_X86_MMZONE_32_H
+#define _ASM_X86_MMZONE_32_H
 
 #include <asm/smp.h>
 
@@ -131,4 +131,4 @@ static inline int pfn_valid(int pfn)
 })
 #endif /* CONFIG_NEED_MULTIPLE_NODES */
 
-#endif /* ASM_X86__MMZONE_32_H */
+#endif /* _ASM_X86_MMZONE_32_H */

commit bb8985586b7a906e116db835c64773b7a7d51663
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 17 21:05:42 2008 -0400

    x86, um: ... and asm-x86 move
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/include/asm/mmzone_32.h b/arch/x86/include/asm/mmzone_32.h
new file mode 100644
index 000000000000..121b65d61d86
--- /dev/null
+++ b/arch/x86/include/asm/mmzone_32.h
@@ -0,0 +1,134 @@
+/*
+ * Written by Pat Gaughen (gone@us.ibm.com) Mar 2002
+ *
+ */
+
+#ifndef ASM_X86__MMZONE_32_H
+#define ASM_X86__MMZONE_32_H
+
+#include <asm/smp.h>
+
+#ifdef CONFIG_NUMA
+extern struct pglist_data *node_data[];
+#define NODE_DATA(nid)	(node_data[nid])
+
+#include <asm/numaq.h>
+/* summit or generic arch */
+#include <asm/srat.h>
+
+extern int get_memcfg_numa_flat(void);
+/*
+ * This allows any one NUMA architecture to be compiled
+ * for, and still fall back to the flat function if it
+ * fails.
+ */
+static inline void get_memcfg_numa(void)
+{
+
+	if (get_memcfg_numaq())
+		return;
+	if (get_memcfg_from_srat())
+		return;
+	get_memcfg_numa_flat();
+}
+
+extern int early_pfn_to_nid(unsigned long pfn);
+
+#else /* !CONFIG_NUMA */
+
+#define get_memcfg_numa get_memcfg_numa_flat
+
+#endif /* CONFIG_NUMA */
+
+#ifdef CONFIG_DISCONTIGMEM
+
+/*
+ * generic node memory support, the following assumptions apply:
+ *
+ * 1) memory comes in 64Mb contigious chunks which are either present or not
+ * 2) we will not have more than 64Gb in total
+ *
+ * for now assume that 64Gb is max amount of RAM for whole system
+ *    64Gb / 4096bytes/page = 16777216 pages
+ */
+#define MAX_NR_PAGES 16777216
+#define MAX_ELEMENTS 1024
+#define PAGES_PER_ELEMENT (MAX_NR_PAGES/MAX_ELEMENTS)
+
+extern s8 physnode_map[];
+
+static inline int pfn_to_nid(unsigned long pfn)
+{
+#ifdef CONFIG_NUMA
+	return((int) physnode_map[(pfn) / PAGES_PER_ELEMENT]);
+#else
+	return 0;
+#endif
+}
+
+/*
+ * Following are macros that each numa implmentation must define.
+ */
+
+#define node_start_pfn(nid)	(NODE_DATA(nid)->node_start_pfn)
+#define node_end_pfn(nid)						\
+({									\
+	pg_data_t *__pgdat = NODE_DATA(nid);				\
+	__pgdat->node_start_pfn + __pgdat->node_spanned_pages;		\
+})
+
+static inline int pfn_valid(int pfn)
+{
+	int nid = pfn_to_nid(pfn);
+
+	if (nid >= 0)
+		return (pfn < node_end_pfn(nid));
+	return 0;
+}
+
+#endif /* CONFIG_DISCONTIGMEM */
+
+#ifdef CONFIG_NEED_MULTIPLE_NODES
+
+/*
+ * Following are macros that are specific to this numa platform.
+ */
+#define reserve_bootmem(addr, size, flags) \
+	reserve_bootmem_node(NODE_DATA(0), (addr), (size), (flags))
+#define alloc_bootmem(x) \
+	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES, __pa(MAX_DMA_ADDRESS))
+#define alloc_bootmem_nopanic(x) \
+	__alloc_bootmem_node_nopanic(NODE_DATA(0), (x), SMP_CACHE_BYTES, \
+				__pa(MAX_DMA_ADDRESS))
+#define alloc_bootmem_low(x) \
+	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES, 0)
+#define alloc_bootmem_pages(x) \
+	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, __pa(MAX_DMA_ADDRESS))
+#define alloc_bootmem_pages_nopanic(x) \
+	__alloc_bootmem_node_nopanic(NODE_DATA(0), (x), PAGE_SIZE, \
+				__pa(MAX_DMA_ADDRESS))
+#define alloc_bootmem_low_pages(x) \
+	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, 0)
+#define alloc_bootmem_node(pgdat, x)					\
+({									\
+	struct pglist_data  __maybe_unused			\
+				*__alloc_bootmem_node__pgdat = (pgdat);	\
+	__alloc_bootmem_node(NODE_DATA(0), (x), SMP_CACHE_BYTES,	\
+						__pa(MAX_DMA_ADDRESS));	\
+})
+#define alloc_bootmem_pages_node(pgdat, x)				\
+({									\
+	struct pglist_data  __maybe_unused			\
+				*__alloc_bootmem_node__pgdat = (pgdat);	\
+	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE,		\
+						__pa(MAX_DMA_ADDRESS));	\
+})
+#define alloc_bootmem_low_pages_node(pgdat, x)				\
+({									\
+	struct pglist_data  __maybe_unused			\
+				*__alloc_bootmem_node__pgdat = (pgdat);	\
+	__alloc_bootmem_node(NODE_DATA(0), (x), PAGE_SIZE, 0);		\
+})
+#endif /* CONFIG_NEED_MULTIPLE_NODES */
+
+#endif /* ASM_X86__MMZONE_32_H */
