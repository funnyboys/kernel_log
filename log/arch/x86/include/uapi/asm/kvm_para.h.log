commit 72de5fa4c16195827252b961ba44028a39dfeaff
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Mon May 25 16:41:22 2020 +0200

    KVM: x86: announce KVM_FEATURE_ASYNC_PF_INT
    
    Introduce new capability to indicate that KVM supports interrupt based
    delivery of 'page ready' APF events. This includes support for both
    MSR_KVM_ASYNC_PF_INT and MSR_KVM_ASYNC_PF_ACK.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Message-Id: <20200525144125.143875-8-vkuznets@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 7ac20df80ba8..812e9b4c1114 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -31,6 +31,7 @@
 #define KVM_FEATURE_PV_SEND_IPI	11
 #define KVM_FEATURE_POLL_CONTROL	12
 #define KVM_FEATURE_PV_SCHED_YIELD	13
+#define KVM_FEATURE_ASYNC_PF_INT	14
 
 #define KVM_HINTS_REALTIME      0
 

commit 557a961abbe06ed9dfd3b55ef7bd6e68295cda3d
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Mon May 25 16:41:21 2020 +0200

    KVM: x86: acknowledgment mechanism for async pf page ready notifications
    
    If two page ready notifications happen back to back the second one is not
    delivered and the only mechanism we currently have is
    kvm_check_async_pf_completion() check in vcpu_run() loop. The check will
    only be performed with the next vmexit when it happens and in some cases
    it may take a while. With interrupt based page ready notification delivery
    the situation is even worse: unlike exceptions, interrupts are not handled
    immediately so we must check if the slot is empty. This is slow and
    unnecessary. Introduce dedicated MSR_KVM_ASYNC_PF_ACK MSR to communicate
    the fact that the slot is free and host should check its notification
    queue. Mandate using it for interrupt based 'page ready' APF event
    delivery.
    
    As kvm_check_async_pf_completion() is going away from vcpu_run() we need
    a way to communicate the fact that vcpu->async_pf.done queue has
    transitioned from empty to non-empty state. Introduce
    kvm_arch_async_page_present_queued() and KVM_REQ_APF_READY to do the job.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Message-Id: <20200525144125.143875-7-vkuznets@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 1d37d616b1fc..7ac20df80ba8 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -51,6 +51,7 @@
 #define MSR_KVM_PV_EOI_EN      0x4b564d04
 #define MSR_KVM_POLL_CONTROL	0x4b564d05
 #define MSR_KVM_ASYNC_PF_INT	0x4b564d06
+#define MSR_KVM_ASYNC_PF_ACK	0x4b564d07
 
 struct kvm_steal_time {
 	__u64 steal;

commit 2635b5c4a0e407b84f68e188c719f28ba0e9ae1b
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Mon May 25 16:41:20 2020 +0200

    KVM: x86: interrupt based APF 'page ready' event delivery
    
    Concerns were expressed around APF delivery via synthetic #PF exception as
    in some cases such delivery may collide with real page fault. For 'page
    ready' notifications we can easily switch to using an interrupt instead.
    Introduce new MSR_KVM_ASYNC_PF_INT mechanism and deprecate the legacy one.
    
    One notable difference between the two mechanisms is that interrupt may not
    get handled immediately so whenever we would like to deliver next event
    (regardless of its type) we must be sure the guest had read and cleared
    previous event in the slot.
    
    While on it, get rid on 'type 1/type 2' names for APF events in the
    documentation as they are causing confusion. Use 'page not present'
    and 'page ready' everywhere instead.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Message-Id: <20200525144125.143875-6-vkuznets@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index d1cd5c0f431a..1d37d616b1fc 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -50,6 +50,7 @@
 #define MSR_KVM_STEAL_TIME  0x4b564d03
 #define MSR_KVM_PV_EOI_EN      0x4b564d04
 #define MSR_KVM_POLL_CONTROL	0x4b564d05
+#define MSR_KVM_ASYNC_PF_INT	0x4b564d06
 
 struct kvm_steal_time {
 	__u64 steal;
@@ -81,6 +82,11 @@ struct kvm_clock_pairing {
 #define KVM_ASYNC_PF_ENABLED			(1 << 0)
 #define KVM_ASYNC_PF_SEND_ALWAYS		(1 << 1)
 #define KVM_ASYNC_PF_DELIVERY_AS_PF_VMEXIT	(1 << 2)
+#define KVM_ASYNC_PF_DELIVERY_AS_INT		(1 << 3)
+
+/* MSR_KVM_ASYNC_PF_INT */
+#define KVM_ASYNC_PF_VEC_MASK			GENMASK(7, 0)
+
 
 /* Operations for KVM_HC_MMU_OP */
 #define KVM_MMU_OP_WRITE_PTE            1
@@ -112,8 +118,12 @@ struct kvm_mmu_op_release_pt {
 #define KVM_PV_REASON_PAGE_READY 2
 
 struct kvm_vcpu_pv_apf_data {
+	/* Used for 'page not present' events delivered via #PF */
 	__u32 flags;
-	__u32 token; /* Used for page ready notification only */
+
+	/* Used for 'page ready' events delivered via interrupt notification */
+	__u32 token;
+
 	__u8 pad[56];
 	__u32 enabled;
 };

commit 68fd66f100d196d35ab3008d4c69af3a0d7e7200
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Mon May 25 16:41:17 2020 +0200

    KVM: x86: extend struct kvm_vcpu_pv_apf_data with token info
    
    Currently, APF mechanism relies on the #PF abuse where the token is being
    passed through CR2. If we switch to using interrupts to deliver page-ready
    notifications we need a different way to pass the data. Extent the existing
    'struct kvm_vcpu_pv_apf_data' with token information for page-ready
    notifications.
    
    While on it, rename 'reason' to 'flags'. This doesn't change the semantics
    as we only have reasons '1' and '2' and these can be treated as bit flags
    but KVM_PV_REASON_PAGE_READY is going away with interrupt based delivery
    making 'reason' name misleading.
    
    The newly introduced apf_put_user_ready() temporary puts both flags and
    token information, this will be changed to put token only when we switch
    to interrupt based notifications.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Message-Id: <20200525144125.143875-3-vkuznets@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 2a8e0b6b9805..d1cd5c0f431a 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -112,8 +112,9 @@ struct kvm_mmu_op_release_pt {
 #define KVM_PV_REASON_PAGE_READY 2
 
 struct kvm_vcpu_pv_apf_data {
-	__u32 reason;
-	__u8 pad[60];
+	__u32 flags;
+	__u32 token; /* Used for page ready notification only */
+	__u8 pad[56];
 	__u32 enabled;
 };
 

commit f85f6e7bc9682a6d8b342c010cd6aa58521fdeec
Author: Wanpeng Li <wanpengli@tencent.com>
Date:   Tue Jun 11 20:23:48 2019 +0800

    KVM: X86: Yield to IPI target if necessary
    
    When sending a call-function IPI-many to vCPUs, yield if any of
    the IPI target vCPUs was preempted, we just select the first
    preempted target vCPU which we found since the state of target
    vCPUs can change underneath and to avoid race conditions.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Liran Alon <liran.alon@oracle.com>
    Signed-off-by: Wanpeng Li <wanpengli@tencent.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 21d5f0240595..2a8e0b6b9805 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -30,6 +30,7 @@
 #define KVM_FEATURE_ASYNC_PF_VMEXIT	10
 #define KVM_FEATURE_PV_SEND_IPI	11
 #define KVM_FEATURE_POLL_CONTROL	12
+#define KVM_FEATURE_PV_SCHED_YIELD	13
 
 #define KVM_HINTS_REALTIME      0
 

commit 2d5ba19bdfef4dd06add144eb04287ee98409f75
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Mon Jun 3 19:52:44 2019 -0300

    kvm: x86: add host poll control msrs
    
    Add an MSRs which allows the guest to disable
    host polling (specifically the cpuidle-haltpoll,
    when performing polling in the guest, disables
    host side polling).
    
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 19980ec1a316..21d5f0240595 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -29,6 +29,7 @@
 #define KVM_FEATURE_PV_TLB_FLUSH	9
 #define KVM_FEATURE_ASYNC_PF_VMEXIT	10
 #define KVM_FEATURE_PV_SEND_IPI	11
+#define KVM_FEATURE_POLL_CONTROL	12
 
 #define KVM_HINTS_REALTIME      0
 
@@ -47,6 +48,7 @@
 #define MSR_KVM_ASYNC_PF_EN 0x4b564d02
 #define MSR_KVM_STEAL_TIME  0x4b564d03
 #define MSR_KVM_PV_EOI_EN      0x4b564d04
+#define MSR_KVM_POLL_CONTROL	0x4b564d05
 
 struct kvm_steal_time {
 	__u64 steal;

commit aaffcfd1e82d3378538408d0310b7424b98d8f81
Author: Wanpeng Li <wanpengli@tencent.com>
Date:   Mon Jul 23 14:39:52 2018 +0800

    KVM: X86: Implement PV IPIs in linux guest
    
    Implement paravirtual apic hooks to enable PV IPIs for KVM if the "send IPI"
    hypercall is available.  The hypercall lets a guest send IPIs, with
    at most 128 destinations per hypercall in 64-bit mode and 64 vCPUs per
    hypercall in 32-bit mode.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: Wanpeng Li <wanpengli@tencent.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 0ede697c3961..19980ec1a316 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -28,6 +28,7 @@
 #define KVM_FEATURE_PV_UNHALT		7
 #define KVM_FEATURE_PV_TLB_FLUSH	9
 #define KVM_FEATURE_ASYNC_PF_VMEXIT	10
+#define KVM_FEATURE_PV_SEND_IPI	11
 
 #define KVM_HINTS_REALTIME      0
 

commit 633711e82878dc29083fc5d2605166755e25b57a
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu May 17 17:54:24 2018 +0300

    kvm: rename KVM_HINTS_DEDICATED to KVM_HINTS_REALTIME
    
    KVM_HINTS_DEDICATED seems to be somewhat confusing:
    
    Guest doesn't really care whether it's the only task running on a host
    CPU as long as it's not preempted.
    
    And there are more reasons for Guest to be preempted than host CPU
    sharing, for example, with memory overcommit it can get preempted on a
    memory access, post copy migration can cause preemption, etc.
    
    Let's call it KVM_HINTS_REALTIME which seems to better
    match what guests expect.
    
    Also, the flag most be set on all vCPUs - current guests assume this.
    Note so in the documentation.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 4c851ebb3ceb..0ede697c3961 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -29,7 +29,7 @@
 #define KVM_FEATURE_PV_TLB_FLUSH	9
 #define KVM_FEATURE_ASYNC_PF_VMEXIT	10
 
-#define KVM_HINTS_DEDICATED      0
+#define KVM_HINTS_REALTIME      0
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.

commit 5a485803221777013944cbd1a7cd5c62efba3ffa
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Tue Mar 20 15:02:05 2018 +0100

    x86/hyper-v: move hyperv.h out of uapi
    
    hyperv.h is not part of uapi, there are no (known) users outside of kernel.
    We are making changes to this file to match current Hyper-V Hypervisor
    Top-Level Functional Specification (TLFS, see:
    https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/reference/tlfs)
    and we don't want to maintain backwards compatibility.
    
    Move the file renaming to hyperv-tlfs.h to avoid confusing it with
    mshyperv.h. In future, all definitions from TLFS should go to it and
    all kernel objects should go to mshyperv.h or include/linux/hyperv.h.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 68a41b6ba3da..4c851ebb3ceb 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -3,7 +3,6 @@
 #define _UAPI_ASM_X86_KVM_PARA_H
 
 #include <linux/types.h>
-#include <asm/hyperv.h>
 
 /* This CPUID returns the signature 'KVMKVMKVM' in ebx, ecx, and edx.  It
  * should be used to determine that a VM is running under KVM.

commit a4429e53c9b3082b05e51224c3d58dbdd39306c5
Author: Wanpeng Li <wanpengli@tencent.com>
Date:   Tue Feb 13 09:05:40 2018 +0800

    KVM: Introduce paravirtualization hints and KVM_HINTS_DEDICATED
    
    This patch introduces kvm_para_has_hint() to query for hints about
    the configuration of the guests.  The first hint KVM_HINTS_DEDICATED,
    is set if the guest has dedicated physical CPUs for each vCPU (i.e.
    pinning and no over-commitment).  This allows optimizing spinlocks
    and tells the guest to avoid PV TLB flush.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Wanpeng Li <wanpengli@tencent.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 6cfa9c8cb7d6..68a41b6ba3da 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -10,8 +10,10 @@
  */
 #define KVM_CPUID_SIGNATURE	0x40000000
 
-/* This CPUID returns a feature bitmap in eax.  Before enabling a particular
- * paravirtualization, the appropriate feature bit should be checked.
+/* This CPUID returns two feature bitmaps in eax, edx. Before enabling
+ * a particular paravirtualization, the appropriate feature bit should
+ * be checked in eax. The performance hint feature bit should be checked
+ * in edx.
  */
 #define KVM_CPUID_FEATURES	0x40000001
 #define KVM_FEATURE_CLOCKSOURCE		0
@@ -28,6 +30,8 @@
 #define KVM_FEATURE_PV_TLB_FLUSH	9
 #define KVM_FEATURE_ASYNC_PF_VMEXIT	10
 
+#define KVM_HINTS_DEDICATED      0
+
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.
  */

commit fe2a3027e74e40a3ece3a4c1e4e51403090a907a
Author: Radim Krčmář <rkrcmar@redhat.com>
Date:   Thu Feb 1 22:16:21 2018 +0100

    KVM: x86: fix backward migration with async_PF
    
    Guests on new hypersiors might set KVM_ASYNC_PF_DELIVERY_AS_PF_VMEXIT
    bit when enabling async_PF, but this bit is reserved on old hypervisors,
    which results in a failure upon migration.
    
    To avoid breaking different cases, we are checking for CPUID feature bit
    before enabling the feature and nothing else.
    
    Fixes: 52a5c155cf79 ("KVM: async_pf: Let guest support delivery of async_pf from guest mode")
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Wanpeng Li <wanpengli@tencent.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 7a2ade4aa235..6cfa9c8cb7d6 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -26,6 +26,7 @@
 #define KVM_FEATURE_PV_EOI		6
 #define KVM_FEATURE_PV_UNHALT		7
 #define KVM_FEATURE_PV_TLB_FLUSH	9
+#define KVM_FEATURE_ASYNC_PF_VMEXIT	10
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.

commit 858a43aae23672d46fe802a41f4748f322965182
Author: Wanpeng Li <wanpeng.li@hotmail.com>
Date:   Tue Dec 12 17:33:02 2017 -0800

    KVM: X86: use paravirtualized TLB Shootdown
    
    Remote TLB flush does a busy wait which is fine in bare-metal
    scenario. But with-in the guest, the vcpus might have been pre-empted or
    blocked. In this scenario, the initator vcpu would end up busy-waiting
    for a long amount of time; it also consumes CPU unnecessarily to wake
    up the target of the shootdown.
    
    This patch set adds support for KVM's new paravirtualized TLB flush;
    remote TLB flush does not wait for vcpus that are sleeping, instead
    KVM will flush the TLB as soon as the vCPU starts running again.
    
    The improvement is clearly visible when the host is overcommitted; in this
    case, the PV TLB flush (in addition to avoiding the wait on the main CPU)
    prevents preempted vCPUs from stealing precious execution time from the
    running ones.
    
    Testing on a Xeon Gold 6142 2.6GHz 2 sockets, 32 cores, 64 threads,
    so 64 pCPUs, and each VM is 64 vCPUs.
    
    ebizzy -M
                  vanilla    optimized     boost
    1VM            46799       48670         4%
    2VM            23962       42691        78%
    3VM            16152       37539       132%
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Wanpeng Li <wanpeng.li@hotmail.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 15685bd22faa..7a2ade4aa235 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -25,6 +25,7 @@
 #define KVM_FEATURE_STEAL_TIME		5
 #define KVM_FEATURE_PV_EOI		6
 #define KVM_FEATURE_PV_UNHALT		7
+#define KVM_FEATURE_PV_TLB_FLUSH	9
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.
@@ -52,6 +53,7 @@ struct kvm_steal_time {
 };
 
 #define KVM_VCPU_PREEMPTED          (1 << 0)
+#define KVM_VCPU_FLUSH_TLB          (1 << 1)
 
 #define KVM_CLOCK_PAIRING_WALLCLOCK 0
 struct kvm_clock_pairing {

commit fa55eedd6328d3072e82218a2346b8752253af2d
Author: Wanpeng Li <wanpeng.li@hotmail.com>
Date:   Tue Dec 12 17:33:01 2017 -0800

    KVM: X86: Add KVM_VCPU_PREEMPTED
    
    The next patch will add another bit to the preempted field in
    kvm_steal_time.  Define a constant for bit 0 (the only one that is
    currently used).
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Wanpeng Li <wanpeng.li@hotmail.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 09cc06483bed..15685bd22faa 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -51,6 +51,8 @@ struct kvm_steal_time {
 	__u32 pad[11];
 };
 
+#define KVM_VCPU_PREEMPTED          (1 << 0)
+
 #define KVM_CLOCK_PAIRING_WALLCLOCK 0
 struct kvm_clock_pairing {
 	__s64 sec;

commit 1958b5fc401067662ec11a6fcbe0daa26c813603
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Fri Oct 20 09:30:54 2017 -0500

    x86/boot: Add early boot support when running with SEV active
    
    Early in the boot process, add checks to determine if the kernel is
    running with Secure Encrypted Virtualization (SEV) active.
    
    Checking for SEV requires checking that the kernel is running under a
    hypervisor (CPUID 0x00000001, bit 31), that the SEV feature is available
    (CPUID 0x8000001f, bit 1) and then checking a non-interceptable SEV MSR
    (0xc0010131, bit 0).
    
    This check is required so that during early compressed kernel booting the
    pagetables (both the boot pagetables and KASLR pagetables (if enabled) are
    updated to include the encryption mask so that when the kernel is
    decompressed into encrypted memory, it can boot properly.
    
    After the kernel is decompressed and continues booting the same logic is
    used to check if SEV is active and set a flag indicating so.  This allows
    to distinguish between SME and SEV, each of which have unique differences
    in how certain things are handled: e.g. DMA (always bounce buffered with
    SEV) or EFI tables (always access decrypted with SME).
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Tested-by: Borislav Petkov <bp@suse.de>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: kvm@vger.kernel.org
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Link: https://lkml.kernel.org/r/20171020143059.3291-13-brijesh.singh@amd.com

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 554aa8f24f91..09cc06483bed 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -110,5 +110,4 @@ struct kvm_vcpu_pv_apf_data {
 #define KVM_PV_EOI_ENABLED KVM_PV_EOI_MASK
 #define KVM_PV_EOI_DISABLED 0x0
 
-
 #endif /* _UAPI_ASM_X86_KVM_PARA_H */

commit 6f52b16c5b29b89d92c0e7236f4655dc8491ad70
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:08:43 2017 +0100

    License cleanup: add SPDX license identifier to uapi header files with no license
    
    Many user space API headers are missing licensing information, which
    makes it hard for compliance tools to determine the correct license.
    
    By default are files without license information under the default
    license of the kernel, which is GPLV2.  Marking them GPLV2 would exclude
    them from being included in non GPLV2 code, which is obviously not
    intended. The user space API headers fall under the syscall exception
    which is in the kernels COPYING file:
    
       NOTE! This copyright does *not* cover user programs that use kernel
       services by normal system calls - this is merely considered normal use
       of the kernel, and does *not* fall under the heading of "derived work".
    
    otherwise syscall usage would not be possible.
    
    Update the files which contain no license information with an SPDX
    license identifier.  The chosen identifier is 'GPL-2.0 WITH
    Linux-syscall-note' which is the officially assigned identifier for the
    Linux syscall exception.  SPDX license identifiers are a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.  See the previous patch in this series for the
    methodology of how this patch was researched.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index a965e5b0d328..554aa8f24f91 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
 #ifndef _UAPI_ASM_X86_KVM_PARA_H
 #define _UAPI_ASM_X86_KVM_PARA_H
 

commit 52a5c155cf79f1f059bffebf4d06d0249573e659
Author: Wanpeng Li <wanpeng.li@hotmail.com>
Date:   Thu Jul 13 18:30:42 2017 -0700

    KVM: async_pf: Let guest support delivery of async_pf from guest mode
    
    Adds another flag bit (bit 2) to MSR_KVM_ASYNC_PF_EN. If bit 2 is 1,
    async page faults are delivered to L1 as #PF vmexits; if bit 2 is 0,
    kvm_can_do_async_pf returns 0 if in guest mode.
    
    This is similar to what svm.c wanted to do all along, but it is only
    enabled for Linux as L1 hypervisor.  Foreign hypervisors must never
    receive async page faults as vmexits, because they'd probably be very
    confused about that.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Signed-off-by: Wanpeng Li <wanpeng.li@hotmail.com>
    Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index cff0bb6556f8..a965e5b0d328 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -67,6 +67,7 @@ struct kvm_clock_pairing {
 
 #define KVM_ASYNC_PF_ENABLED			(1 << 0)
 #define KVM_ASYNC_PF_SEND_ALWAYS		(1 << 1)
+#define KVM_ASYNC_PF_DELIVERY_AS_PF_VMEXIT	(1 << 2)
 
 /* Operations for KVM_HC_MMU_OP */
 #define KVM_MMU_OP_WRITE_PTE            1

commit 55dd00a73a518281bc846dc5de1a718349431eb2
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Tue Jan 24 15:09:39 2017 -0200

    KVM: x86: add KVM_HC_CLOCK_PAIRING hypercall
    
    Add a hypercall to retrieve the host realtime clock and the TSC value
    used to calculate that clock read.
    
    Used to implement clock synchronization between host and guest.
    
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 1421a6585126..cff0bb6556f8 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -50,6 +50,15 @@ struct kvm_steal_time {
 	__u32 pad[11];
 };
 
+#define KVM_CLOCK_PAIRING_WALLCLOCK 0
+struct kvm_clock_pairing {
+	__s64 sec;
+	__s64 nsec;
+	__u64 tsc;
+	__u32 flags;
+	__u32 pad[9];
+};
+
 #define KVM_STEAL_ALIGNMENT_BITS 5
 #define KVM_STEAL_VALID_BITS ((-1ULL << (KVM_STEAL_ALIGNMENT_BITS + 1)))
 #define KVM_STEAL_RESERVED_MASK (((1 << KVM_STEAL_ALIGNMENT_BITS) - 1 ) << 1)

commit 0b9f6c4615c993d2b552e0d2bd1ade49b56e5beb
Author: Pan Xinhui <xinhui.pan@linux.vnet.ibm.com>
Date:   Wed Nov 2 05:08:35 2016 -0400

    x86/kvm: Support the vCPU preemption check
    
    Support the vcpu_is_preempted() functionality under KVM. This will
    enhance lock performance on overcommitted hosts (more runnable vCPUs
    than physical CPUs in the system) as doing busy waits for preempted
    vCPUs will hurt system performance far worse than early yielding.
    
    Use struct kvm_steal_time::preempted to indicate that if a vCPU
    is running or not.
    
    Signed-off-by: Pan Xinhui <xinhui.pan@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: David.Laight@ACULAB.COM
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: benh@kernel.crashing.org
    Cc: boqun.feng@gmail.com
    Cc: borntraeger@de.ibm.com
    Cc: bsingharora@gmail.com
    Cc: dave@stgolabs.net
    Cc: jgross@suse.com
    Cc: kernellwp@gmail.com
    Cc: konrad.wilk@oracle.com
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: mpe@ellerman.id.au
    Cc: paulmck@linux.vnet.ibm.com
    Cc: paulus@samba.org
    Cc: rkrcmar@redhat.com
    Cc: virtualization@lists.linux-foundation.org
    Cc: will.deacon@arm.com
    Cc: xen-devel-request@lists.xenproject.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1478077718-37424-9-git-send-email-xinhui.pan@linux.vnet.ibm.com
    [ Typo fixes. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 94dc8ca434e0..1421a6585126 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -45,7 +45,9 @@ struct kvm_steal_time {
 	__u64 steal;
 	__u32 version;
 	__u32 flags;
-	__u32 pad[12];
+	__u8  preempted;
+	__u8  u8_pad[3];
+	__u32 pad[11];
 };
 
 #define KVM_STEAL_ALIGNMENT_BITS 5

commit 3a3bb00d5c73f3ae7833f6534982b5b2f56ac9b4
Author: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
Date:   Fri Aug 9 19:52:00 2013 +0530

    kvm uapi: Add KICK_CPU and PV_UNHALT definition to uapi
    
    These are needed by both guest and host.
    
    Originally-from: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>
    Signed-off-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/r/1376058122-8248-13-git-send-email-raghavendra.kt@linux.vnet.ibm.com
    Acked-by: Gleb Natapov <gleb@redhat.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 06fdbd987e97..94dc8ca434e0 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -23,6 +23,7 @@
 #define KVM_FEATURE_ASYNC_PF		4
 #define KVM_FEATURE_STEAL_TIME		5
 #define KVM_FEATURE_PV_EOI		6
+#define KVM_FEATURE_PV_UNHALT		7
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.

commit af170c5061dd78512c469e6e2d211980cdb2c193
Author: David Howells <dhowells@redhat.com>
Date:   Fri Dec 14 22:37:13 2012 +0000

    UAPI: (Scripted) Disintegrate arch/x86/include/asm
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
new file mode 100644
index 000000000000..06fdbd987e97
--- /dev/null
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -0,0 +1,100 @@
+#ifndef _UAPI_ASM_X86_KVM_PARA_H
+#define _UAPI_ASM_X86_KVM_PARA_H
+
+#include <linux/types.h>
+#include <asm/hyperv.h>
+
+/* This CPUID returns the signature 'KVMKVMKVM' in ebx, ecx, and edx.  It
+ * should be used to determine that a VM is running under KVM.
+ */
+#define KVM_CPUID_SIGNATURE	0x40000000
+
+/* This CPUID returns a feature bitmap in eax.  Before enabling a particular
+ * paravirtualization, the appropriate feature bit should be checked.
+ */
+#define KVM_CPUID_FEATURES	0x40000001
+#define KVM_FEATURE_CLOCKSOURCE		0
+#define KVM_FEATURE_NOP_IO_DELAY	1
+#define KVM_FEATURE_MMU_OP		2
+/* This indicates that the new set of kvmclock msrs
+ * are available. The use of 0x11 and 0x12 is deprecated
+ */
+#define KVM_FEATURE_CLOCKSOURCE2        3
+#define KVM_FEATURE_ASYNC_PF		4
+#define KVM_FEATURE_STEAL_TIME		5
+#define KVM_FEATURE_PV_EOI		6
+
+/* The last 8 bits are used to indicate how to interpret the flags field
+ * in pvclock structure. If no bits are set, all flags are ignored.
+ */
+#define KVM_FEATURE_CLOCKSOURCE_STABLE_BIT	24
+
+#define MSR_KVM_WALL_CLOCK  0x11
+#define MSR_KVM_SYSTEM_TIME 0x12
+
+#define KVM_MSR_ENABLED 1
+/* Custom MSRs falls in the range 0x4b564d00-0x4b564dff */
+#define MSR_KVM_WALL_CLOCK_NEW  0x4b564d00
+#define MSR_KVM_SYSTEM_TIME_NEW 0x4b564d01
+#define MSR_KVM_ASYNC_PF_EN 0x4b564d02
+#define MSR_KVM_STEAL_TIME  0x4b564d03
+#define MSR_KVM_PV_EOI_EN      0x4b564d04
+
+struct kvm_steal_time {
+	__u64 steal;
+	__u32 version;
+	__u32 flags;
+	__u32 pad[12];
+};
+
+#define KVM_STEAL_ALIGNMENT_BITS 5
+#define KVM_STEAL_VALID_BITS ((-1ULL << (KVM_STEAL_ALIGNMENT_BITS + 1)))
+#define KVM_STEAL_RESERVED_MASK (((1 << KVM_STEAL_ALIGNMENT_BITS) - 1 ) << 1)
+
+#define KVM_MAX_MMU_OP_BATCH           32
+
+#define KVM_ASYNC_PF_ENABLED			(1 << 0)
+#define KVM_ASYNC_PF_SEND_ALWAYS		(1 << 1)
+
+/* Operations for KVM_HC_MMU_OP */
+#define KVM_MMU_OP_WRITE_PTE            1
+#define KVM_MMU_OP_FLUSH_TLB	        2
+#define KVM_MMU_OP_RELEASE_PT	        3
+
+/* Payload for KVM_HC_MMU_OP */
+struct kvm_mmu_op_header {
+	__u32 op;
+	__u32 pad;
+};
+
+struct kvm_mmu_op_write_pte {
+	struct kvm_mmu_op_header header;
+	__u64 pte_phys;
+	__u64 pte_val;
+};
+
+struct kvm_mmu_op_flush_tlb {
+	struct kvm_mmu_op_header header;
+};
+
+struct kvm_mmu_op_release_pt {
+	struct kvm_mmu_op_header header;
+	__u64 pt_phys;
+};
+
+#define KVM_PV_REASON_PAGE_NOT_PRESENT 1
+#define KVM_PV_REASON_PAGE_READY 2
+
+struct kvm_vcpu_pv_apf_data {
+	__u32 reason;
+	__u8 pad[60];
+	__u32 enabled;
+};
+
+#define KVM_PV_EOI_BIT 0
+#define KVM_PV_EOI_MASK (0x1 << KVM_PV_EOI_BIT)
+#define KVM_PV_EOI_ENABLED KVM_PV_EOI_MASK
+#define KVM_PV_EOI_DISABLED 0x0
+
+
+#endif /* _UAPI_ASM_X86_KVM_PARA_H */
