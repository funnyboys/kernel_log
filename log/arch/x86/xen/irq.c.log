commit 5c83511bdb9832c86be20fb86b783356e2f58062
Author: Juergen Gross <jgross@suse.com>
Date:   Tue Aug 28 09:40:19 2018 +0200

    x86/paravirt: Use a single ops structure
    
    Instead of using six globally visible paravirt ops structures combine
    them in a single structure, keeping the original structures as
    sub-structures.
    
    This avoids the need to assemble struct paravirt_patch_template at
    runtime on the stack each time apply_paravirt() is being called (i.e.
    when loading a module).
    
    [ tglx: Made the struct and the initializer tabular for readability sake ]
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: akataria@vmware.com
    Cc: rusty@rustcorp.com.au
    Cc: boris.ostrovsky@oracle.com
    Cc: hpa@zytor.com
    Link: https://lkml.kernel.org/r/20180828074026.820-9-jgross@suse.com

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 7515a19fd324..850c93f346c7 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -128,6 +128,6 @@ static const struct pv_irq_ops xen_irq_ops __initconst = {
 
 void __init xen_init_irq_ops(void)
 {
-	pv_irq_ops = xen_irq_ops;
+	pv_ops.irq = xen_irq_ops;
 	x86_init.irqs.intr_init = xen_init_IRQ;
 }

commit 0ce0bba4e5e0eb9b753bb821785de5d23c494392
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Jul 12 17:40:34 2018 +0200

    xen: setup pv irq ops vector earlier
    
    Setting pv_irq_ops for Xen PV domains should be done as early as
    possible in order to support e.g. very early printk() usage.
    
    The same applies to xen_vcpu_info_reset(0), as it is needed for the
    pv irq ops.
    
    Move the call of xen_setup_machphys_mapping() after initializing the
    pv functions as it contains a WARN_ON(), too.
    
    Remove the no longer necessary conditional in xen_init_irq_ops()
    from PVH V1 times to make clear this is a PV only function.
    
    Cc: <stable@vger.kernel.org> # 4.14
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 74179852e46c..7515a19fd324 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -128,8 +128,6 @@ static const struct pv_irq_ops xen_irq_ops __initconst = {
 
 void __init xen_init_irq_ops(void)
 {
-	/* For PVH we use default pv_irq_ops settings. */
-	if (!xen_feature(XENFEAT_hvm_callback_vector))
-		pv_irq_ops = xen_irq_ops;
+	pv_irq_ops = xen_irq_ops;
 	x86_init.irqs.intr_init = xen_init_IRQ;
 }

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index d4eff5676cfa..74179852e46c 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #include <linux/hardirq.h>
 
 #include <asm/x86_init.h>

commit 5878d5d6fdef6447d73b0acc121ba445bef37f53
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Aug 31 19:42:49 2017 +0200

    x86/xen: Get rid of paravirt op adjust_exception_frame
    
    When running as Xen pv-guest the exception frame on the stack contains
    %r11 and %rcx additional to the other data pushed by the processor.
    
    Instead of having a paravirt op being called for each exception type
    prepend the Xen specific code to each exception entry. When running as
    Xen pv-guest just use the exception entry with prepended instructions,
    otherwise use the entry without the Xen specific code.
    
    [ tglx: Merged through tip to avoid ugly merge conflict ]
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: xen-devel@lists.xenproject.org
    Cc: boris.ostrovsky@oracle.com
    Cc: luto@amacapital.net
    Link: http://lkml.kernel.org/r/20170831174249.26853-1-jg@pfupf.net

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 33e92955e09d..d4eff5676cfa 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -123,9 +123,6 @@ static const struct pv_irq_ops xen_irq_ops __initconst = {
 
 	.safe_halt = xen_safe_halt,
 	.halt = xen_halt,
-#ifdef CONFIG_X86_64
-	.adjust_exception_frame = xen_adjust_exception_frame,
-#endif
 };
 
 void __init xen_init_irq_ops(void)

commit ad5475f9faf5186b7f59de2c6481ee3e211f1ed7
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Thu Jun 30 17:56:38 2016 +0200

    x86/xen: use xen_vcpu_id mapping for HYPERVISOR_vcpu_op
    
    HYPERVISOR_vcpu_op() passes Linux's idea of vCPU id as a parameter
    while Xen's idea is expected. In some cases these ideas diverge so we
    need to do remapping.
    
    Convert all callers of HYPERVISOR_vcpu_op() to use xen_vcpu_nr().
    
    Leave xen_fill_possible_map() and xen_filter_cpu_maps() intact as
    they're only being called by PV guests before perpu areas are
    initialized. While the issue could be solved by switching to
    early_percpu for xen_vcpu_id I think it's not worth it: PV guests will
    probably never get to the point where their idea of vCPU id diverges
    from Xen's.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index a1207cb6472a..33e92955e09d 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -109,7 +109,8 @@ static void xen_safe_halt(void)
 static void xen_halt(void)
 {
 	if (irqs_disabled())
-		HYPERVISOR_vcpu_op(VCPUOP_down, smp_processor_id(), NULL);
+		HYPERVISOR_vcpu_op(VCPUOP_down,
+				   xen_vcpu_nr(smp_processor_id()), NULL);
 	else
 		xen_safe_halt();
 }

commit 2605fc216fa492f9e7c488bdc7f687cd6dcc703b
Author: Andi Kleen <ak@linux.intel.com>
Date:   Fri May 2 00:44:37 2014 +0200

    asmlinkage, x86: Add explicit __visible to arch/x86/*
    
    As requested by Linus add explicit __visible to the asmlinkage users.
    This marks all functions visible to assembler.
    
    Tree sweep for arch/x86/*
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1398984278-29319-3-git-send-email-andi@firstfloor.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 08f763de26fe..a1207cb6472a 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -23,7 +23,7 @@ void xen_force_evtchn_callback(void)
 	(void)HYPERVISOR_xen_version(0, NULL);
 }
 
-asmlinkage unsigned long xen_save_fl(void)
+asmlinkage __visible unsigned long xen_save_fl(void)
 {
 	struct vcpu_info *vcpu;
 	unsigned long flags;
@@ -63,7 +63,7 @@ __visible void xen_restore_fl(unsigned long flags)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_restore_fl);
 
-asmlinkage void xen_irq_disable(void)
+asmlinkage __visible void xen_irq_disable(void)
 {
 	/* There's a one instruction preempt window here.  We need to
 	   make sure we're don't switch CPUs between getting the vcpu
@@ -74,7 +74,7 @@ asmlinkage void xen_irq_disable(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_disable);
 
-asmlinkage void xen_irq_enable(void)
+asmlinkage __visible void xen_irq_enable(void)
 {
 	struct vcpu_info *vcpu;
 

commit 12f2bbd609006f983c1c99d240cf61e6e829a14c
Merge: 10ffe3dbf7f9 07ba06d9d293
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 18:15:32 2014 -0800

    Merge branch 'x86-asmlinkage-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 asmlinkage (LTO) changes from Peter Anvin:
     "This patchset adds more infrastructure for link time optimization
      (LTO).
    
      This patchset was pulled into my tree late because of a
      miscommunication (part of the patchset was picked up by other
      maintainers).  However, the patchset is strictly build-related and
      seems to be okay in testing"
    
    * 'x86-asmlinkage-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, asmlinkage, xen: Fix type of NMI
      x86, asmlinkage, xen, kvm: Make {xen,kvm}_lock_spinning global and visible
      x86: Use inline assembler instead of global register variable to get sp
      x86, asmlinkage, paravirt: Make paravirt thunks global
      x86, asmlinkage, paravirt: Don't rely on local assembler labels
      x86, asmlinkage, lguest: Fix C functions used by inline assembler

commit a2e7f0e3a4f0f23fe4cd8cc22da547872f0170bb
Author: Andi Kleen <ak@linux.intel.com>
Date:   Tue Oct 22 09:07:56 2013 -0700

    x86, asmlinkage, paravirt: Make paravirt thunks global
    
    The paravirt thunks use a hack of using a static reference to a static
    function to reference that function from the top level statement.
    
    This assumes that gcc always generates static function names in a specific
    format, which is not necessarily true.
    
    Simply make these functions global and asmlinkage or __visible. This way the
    static __used variables are not needed and everything works.
    
    Functions with arguments are __visible to keep the register calling
    convention on 32bit.
    
    Changed in paravirt and in all users (Xen and vsmp)
    
    v2: Use __visible for functions with arguments
    
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Ido Yariv <ido@wizery.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1382458079-24450-5-git-send-email-andi@firstfloor.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 0da7f863056f..f56c23b60a6c 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -22,7 +22,7 @@ void xen_force_evtchn_callback(void)
 	(void)HYPERVISOR_xen_version(0, NULL);
 }
 
-static unsigned long xen_save_fl(void)
+asmlinkage unsigned long xen_save_fl(void)
 {
 	struct vcpu_info *vcpu;
 	unsigned long flags;
@@ -40,7 +40,7 @@ static unsigned long xen_save_fl(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_save_fl);
 
-static void xen_restore_fl(unsigned long flags)
+__visible void xen_restore_fl(unsigned long flags)
 {
 	struct vcpu_info *vcpu;
 
@@ -62,7 +62,7 @@ static void xen_restore_fl(unsigned long flags)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_restore_fl);
 
-static void xen_irq_disable(void)
+asmlinkage void xen_irq_disable(void)
 {
 	/* There's a one instruction preempt window here.  We need to
 	   make sure we're don't switch CPUs between getting the vcpu
@@ -73,7 +73,7 @@ static void xen_irq_disable(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_disable);
 
-static void xen_irq_enable(void)
+asmlinkage void xen_irq_enable(void)
 {
 	struct vcpu_info *vcpu;
 

commit 2771374d47220c7ec271281437625e9519505bb2
Author: Mukesh Rathor <mukesh.rathor@oracle.com>
Date:   Wed Dec 11 15:36:51 2013 -0500

    xen/pvh: Piggyback on PVHVM for event channels (v2)
    
    PVH is a PV guest with a twist - there are certain things
    that work in it like HVM and some like PV. There is
    a similar mode - PVHVM where we run in HVM mode with
    PV code enabled - and this patch explores that.
    
    The most notable PV interfaces are the XenBus and event channels.
    
    We will piggyback on how the event channel mechanism is
    used in PVHVM - that is we want the normal native IRQ mechanism
    and we will install a vector (hvm callback) for which we
    will call the event channel mechanism.
    
    This means that from a pvops perspective, we can use
    native_irq_ops instead of the Xen PV specific. Albeit in the
    future we could support pirq_eoi_map. But that is
    a feature request that can be shared with PVHVM.
    
    Signed-off-by: Mukesh Rathor <mukesh.rathor@oracle.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Reviewed-by: David Vrabel <david.vrabel@citrix.com>
    Acked-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 0da7f863056f..76ca326105f7 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -5,6 +5,7 @@
 #include <xen/interface/xen.h>
 #include <xen/interface/sched.h>
 #include <xen/interface/vcpu.h>
+#include <xen/features.h>
 #include <xen/events.h>
 
 #include <asm/xen/hypercall.h>
@@ -128,6 +129,8 @@ static const struct pv_irq_ops xen_irq_ops __initconst = {
 
 void __init xen_init_irq_ops(void)
 {
-	pv_irq_ops = xen_irq_ops;
+	/* For PVH we use default pv_irq_ops settings. */
+	if (!xen_feature(XENFEAT_hvm_callback_vector))
+		pv_irq_ops = xen_irq_ops;
 	x86_init.irqs.intr_init = xen_init_IRQ;
 }

commit fb58e30091c74967f6b8e98b3c1f292782f92b41
Author: David Vrabel <david.vrabel@citrix.com>
Date:   Thu Aug 15 13:21:04 2013 +0100

    x86/xen: disable premption when enabling local irqs
    
    If CONFIG_PREEMPT is enabled then xen_enable_irq() (and
    xen_restore_fl()) could be preempted and rescheduled on a different
    VCPU in between the clear of the mask and the check for pending
    events.  This may result in events being lost as the upcall will check
    for pending events on the wrong VCPU.
    
    Fix this by disabling preemption around the unmask and check for
    events.
    
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 01a4dc015ae1..0da7f863056f 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -47,23 +47,18 @@ static void xen_restore_fl(unsigned long flags)
 	/* convert from IF type flag */
 	flags = !(flags & X86_EFLAGS_IF);
 
-	/* There's a one instruction preempt window here.  We need to
-	   make sure we're don't switch CPUs between getting the vcpu
-	   pointer and updating the mask. */
+	/* See xen_irq_enable() for why preemption must be disabled. */
 	preempt_disable();
 	vcpu = this_cpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = flags;
-	preempt_enable_no_resched();
-
-	/* Doesn't matter if we get preempted here, because any
-	   pending event will get dealt with anyway. */
 
 	if (flags == 0) {
-		preempt_check_resched();
 		barrier(); /* unmask then check (avoid races) */
 		if (unlikely(vcpu->evtchn_upcall_pending))
 			xen_force_evtchn_callback();
-	}
+		preempt_enable();
+	} else
+		preempt_enable_no_resched();
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_restore_fl);
 
@@ -82,10 +77,12 @@ static void xen_irq_enable(void)
 {
 	struct vcpu_info *vcpu;
 
-	/* We don't need to worry about being preempted here, since
-	   either a) interrupts are disabled, so no preemption, or b)
-	   the caller is confused and is trying to re-enable interrupts
-	   on an indeterminate processor. */
+	/*
+	 * We may be preempted as soon as vcpu->evtchn_upcall_mask is
+	 * cleared, so disable preemption to ensure we check for
+	 * events on the VCPU we are still running on.
+	 */
+	preempt_disable();
 
 	vcpu = this_cpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = 0;
@@ -96,6 +93,8 @@ static void xen_irq_enable(void)
 	barrier(); /* unmask then check (avoid races) */
 	if (unlikely(vcpu->evtchn_upcall_pending))
 		xen_force_evtchn_callback();
+
+	preempt_enable();
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_enable);
 

commit 0ec53ecf38bcbf95b4b057328a8fbba4d22ef28b
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Fri Sep 14 13:37:32 2012 +0000

    xen/arm: receive Xen events on ARM
    
    Compile events.c on ARM.
    Parse, map and enable the IRQ to get event notifications from the device
    tree (node "/xen").
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 157337657971..01a4dc015ae1 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -5,6 +5,7 @@
 #include <xen/interface/xen.h>
 #include <xen/interface/sched.h>
 #include <xen/interface/vcpu.h>
+#include <xen/events.h>
 
 #include <asm/xen/hypercall.h>
 #include <asm/xen/hypervisor.h>

commit 2113f4691663f033189bf43d7501c6d29cd685a5
Author: Alex Shi <alex.shi@intel.com>
Date:   Fri Jan 13 23:53:35 2012 +0800

    xen: use this_cpu_xxx replace percpu_xxx funcs
    
    percpu_xxx funcs are duplicated with this_cpu_xxx funcs, so replace them
    for further code clean up.
    
    I don't know much of xen code. But, since the code is in x86 architecture,
    the percpu_xxx is exactly same as this_cpu_xxx serials functions. So, the
    change is safe.
    
    Signed-off-by: Alex Shi <alex.shi@intel.com>
    Acked-by: Christoph Lameter <cl@gentwo.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 8bbb465b6f0a..157337657971 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -26,7 +26,7 @@ static unsigned long xen_save_fl(void)
 	struct vcpu_info *vcpu;
 	unsigned long flags;
 
-	vcpu = percpu_read(xen_vcpu);
+	vcpu = this_cpu_read(xen_vcpu);
 
 	/* flag has opposite sense of mask */
 	flags = !vcpu->evtchn_upcall_mask;
@@ -50,7 +50,7 @@ static void xen_restore_fl(unsigned long flags)
 	   make sure we're don't switch CPUs between getting the vcpu
 	   pointer and updating the mask. */
 	preempt_disable();
-	vcpu = percpu_read(xen_vcpu);
+	vcpu = this_cpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = flags;
 	preempt_enable_no_resched();
 
@@ -72,7 +72,7 @@ static void xen_irq_disable(void)
 	   make sure we're don't switch CPUs between getting the vcpu
 	   pointer and updating the mask. */
 	preempt_disable();
-	percpu_read(xen_vcpu)->evtchn_upcall_mask = 1;
+	this_cpu_read(xen_vcpu)->evtchn_upcall_mask = 1;
 	preempt_enable_no_resched();
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_disable);
@@ -86,7 +86,7 @@ static void xen_irq_enable(void)
 	   the caller is confused and is trying to re-enable interrupts
 	   on an indeterminate processor. */
 
-	vcpu = percpu_read(xen_vcpu);
+	vcpu = this_cpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = 0;
 
 	/* Doesn't matter if we get preempted here, because any

commit 251511a18dcfe1868e3edfdc490777dcfaa1f851
Author: Daniel Kiper <dkiper@net-space.pl>
Date:   Wed May 4 20:16:07 2011 +0200

    arch/x86/xen/irq: Cleanup code/data sections definitions
    
    Cleanup code/data sections definitions
    accordingly to include/linux/init.h.
    
    Signed-off-by: Daniel Kiper <dkiper@net-space.pl>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 6a6fe8939645..8bbb465b6f0a 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -113,7 +113,7 @@ static void xen_halt(void)
 		xen_safe_halt();
 }
 
-static const struct pv_irq_ops xen_irq_ops __initdata = {
+static const struct pv_irq_ops xen_irq_ops __initconst = {
 	.save_fl = PV_CALLEE_SAVE(xen_save_fl),
 	.restore_fl = PV_CALLEE_SAVE(xen_restore_fl),
 	.irq_disable = PV_CALLEE_SAVE(xen_irq_disable),

commit 7d81c3b9e2e5057c52256e154205143ad4e6e919
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Sat Jan 8 20:00:36 2011 -0800

    xen: fix non-ANSI function warning in irq.c
    
    Fix sparse warning for non-ANSI function declaration:
    
    arch/x86/xen/irq.c:129:30: warning: non-ANSI function declaration of function 'xen_init_irq_ops'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Cc:     Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 9d30105a0c4a..6a6fe8939645 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -126,7 +126,7 @@ static const struct pv_irq_ops xen_irq_ops __initdata = {
 #endif
 };
 
-void __init xen_init_irq_ops()
+void __init xen_init_irq_ops(void)
 {
 	pv_irq_ops = xen_irq_ops;
 	x86_init.irqs.intr_init = xen_init_IRQ;

commit 66bcaf0bde100a4b54b82fc6fea6ceee2212ffb4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 20 09:59:09 2009 +0200

    x86: Move irq_init to x86_init_ops
    
    irq_init is overridden by x86_quirks and by paravirts. Unify the whole
    mess and make it an unconditional x86_init_ops function which defaults
    to the standard function and can be overridden by the early platform
    code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index cfd17799bd6d..9d30105a0c4a 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -1,5 +1,7 @@
 #include <linux/hardirq.h>
 
+#include <asm/x86_init.h>
+
 #include <xen/interface/xen.h>
 #include <xen/interface/sched.h>
 #include <xen/interface/vcpu.h>
@@ -112,8 +114,6 @@ static void xen_halt(void)
 }
 
 static const struct pv_irq_ops xen_irq_ops __initdata = {
-	.init_IRQ = xen_init_IRQ,
-
 	.save_fl = PV_CALLEE_SAVE(xen_save_fl),
 	.restore_fl = PV_CALLEE_SAVE(xen_restore_fl),
 	.irq_disable = PV_CALLEE_SAVE(xen_irq_disable),
@@ -129,4 +129,5 @@ static const struct pv_irq_ops xen_irq_ops __initdata = {
 void __init xen_init_irq_ops()
 {
 	pv_irq_ops = xen_irq_ops;
+	x86_init.irqs.intr_init = xen_init_IRQ;
 }

commit 792dc4f6cdacf50d3f2b93756d282fc04ee34bd5
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Feb 6 14:09:43 2009 -0800

    xen: use our own eventchannel->irq path
    
    Rather than overloading vectors for event channels, take full
    responsibility for mapping an event channel to irq directly.  With
    this patch Xen has its own irq allocator.
    
    When the kernel gets an event channel upcall, it maps the event
    channel number to an irq and injects it into the normal interrupt
    path.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 5a070900ad35..cfd17799bd6d 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -19,21 +19,6 @@ void xen_force_evtchn_callback(void)
 	(void)HYPERVISOR_xen_version(0, NULL);
 }
 
-static void __init __xen_init_IRQ(void)
-{
-	int i;
-
-	/* Create identity vector->irq map */
-	for(i = 0; i < NR_VECTORS; i++) {
-		int cpu;
-
-		for_each_possible_cpu(cpu)
-			per_cpu(vector_irq, cpu)[i] = i;
-	}
-
-	xen_init_IRQ();
-}
-
 static unsigned long xen_save_fl(void)
 {
 	struct vcpu_info *vcpu;
@@ -127,7 +112,7 @@ static void xen_halt(void)
 }
 
 static const struct pv_irq_ops xen_irq_ops __initdata = {
-	.init_IRQ = __xen_init_IRQ,
+	.init_IRQ = xen_init_IRQ,
 
 	.save_fl = PV_CALLEE_SAVE(xen_save_fl),
 	.restore_fl = PV_CALLEE_SAVE(xen_restore_fl),

commit ecb93d1ccd0aac63f03be2db3cac3fa974716f4c
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Wed Jan 28 14:35:05 2009 -0800

    x86/paravirt: add register-saving thunks to reduce caller register pressure
    
    Impact: Optimization
    
    One of the problems with inserting a pile of C calls where previously
    there were none is that the register pressure is greatly increased.
    The C calling convention says that the caller must expect a certain
    set of registers may be trashed by the callee, and that the callee can
    use those registers without restriction.  This includes the function
    argument registers, and several others.
    
    This patch seeks to alleviate this pressure by introducing wrapper
    thunks that will do the register saving/restoring, so that the
    callsite doesn't need to worry about it, but the callee function can
    be conventional compiler-generated code.  In many cases (particularly
    performance-sensitive cases) the callee will be in assembler anyway,
    and need not use the compiler's calling convention.
    
    Standard calling convention is:
             arguments          return      scratch
    x86-32   eax edx ecx        eax         ?
    x86-64   rdi rsi rdx rcx    rax         r8 r9 r10 r11
    
    The thunk preserves all argument and scratch registers.  The return
    register is not preserved, and is available as a scratch register for
    unwrapped callee code (and of course the return value).
    
    Wrapped function pointers are themselves wrapped in a struct
    paravirt_callee_save structure, in order to get some warning from the
    compiler when functions with mismatched calling conventions are used.
    
    The most common paravirt ops, both statically and dynamically, are
    interrupt enable/disable/save/restore, so handle them first.  This is
    particularly easy since their calls are handled specially anyway.
    
    XXX Deal with VMI.  What's their calling convention?
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 2e8271431e1a..5a070900ad35 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -50,6 +50,7 @@ static unsigned long xen_save_fl(void)
 	*/
 	return (-flags) & X86_EFLAGS_IF;
 }
+PV_CALLEE_SAVE_REGS_THUNK(xen_save_fl);
 
 static void xen_restore_fl(unsigned long flags)
 {
@@ -76,6 +77,7 @@ static void xen_restore_fl(unsigned long flags)
 			xen_force_evtchn_callback();
 	}
 }
+PV_CALLEE_SAVE_REGS_THUNK(xen_restore_fl);
 
 static void xen_irq_disable(void)
 {
@@ -86,6 +88,7 @@ static void xen_irq_disable(void)
 	percpu_read(xen_vcpu)->evtchn_upcall_mask = 1;
 	preempt_enable_no_resched();
 }
+PV_CALLEE_SAVE_REGS_THUNK(xen_irq_disable);
 
 static void xen_irq_enable(void)
 {
@@ -106,6 +109,7 @@ static void xen_irq_enable(void)
 	if (unlikely(vcpu->evtchn_upcall_pending))
 		xen_force_evtchn_callback();
 }
+PV_CALLEE_SAVE_REGS_THUNK(xen_irq_enable);
 
 static void xen_safe_halt(void)
 {
@@ -124,10 +128,12 @@ static void xen_halt(void)
 
 static const struct pv_irq_ops xen_irq_ops __initdata = {
 	.init_IRQ = __xen_init_IRQ,
-	.save_fl = xen_save_fl,
-	.restore_fl = xen_restore_fl,
-	.irq_disable = xen_irq_disable,
-	.irq_enable = xen_irq_enable,
+
+	.save_fl = PV_CALLEE_SAVE(xen_save_fl),
+	.restore_fl = PV_CALLEE_SAVE(xen_restore_fl),
+	.irq_disable = PV_CALLEE_SAVE(xen_irq_disable),
+	.irq_enable = PV_CALLEE_SAVE(xen_irq_enable),
+
 	.safe_halt = xen_safe_halt,
 	.halt = xen_halt,
 #ifdef CONFIG_X86_64

commit 6dbde3530850d4d8bfc1b6bd4006d92786a2787f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jan 15 22:15:53 2009 +0900

    percpu: add optimized generic percpu accessors
    
    It is an optimization and a cleanup, and adds the following new
    generic percpu methods:
    
      percpu_read()
      percpu_write()
      percpu_add()
      percpu_sub()
      percpu_and()
      percpu_or()
      percpu_xor()
    
    and implements support for them on x86. (other architectures will fall
    back to a default implementation)
    
    The advantage is that for example to read a local percpu variable,
    instead of this sequence:
    
     return __get_cpu_var(var);
    
     ffffffff8102ca2b:      48 8b 14 fd 80 09 74    mov    -0x7e8bf680(,%rdi,8),%rdx
     ffffffff8102ca32:      81
     ffffffff8102ca33:      48 c7 c0 d8 59 00 00    mov    $0x59d8,%rax
     ffffffff8102ca3a:      48 8b 04 10             mov    (%rax,%rdx,1),%rax
    
    We can get a single instruction by using the optimized variants:
    
     return percpu_read(var);
    
     ffffffff8102ca3f:      65 48 8b 05 91 8f fd    mov    %gs:0x7efd8f91(%rip),%rax
    
    I also cleaned up the x86-specific APIs and made the x86 code use
    these new generic percpu primitives.
    
    tj: * fixed generic percpu_sub() definition as Roel Kluin pointed out
        * added percpu_and() for completeness's sake
        * made generic percpu ops atomic against preemption
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index bb042608c602..2e8271431e1a 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -39,7 +39,7 @@ static unsigned long xen_save_fl(void)
 	struct vcpu_info *vcpu;
 	unsigned long flags;
 
-	vcpu = x86_read_percpu(xen_vcpu);
+	vcpu = percpu_read(xen_vcpu);
 
 	/* flag has opposite sense of mask */
 	flags = !vcpu->evtchn_upcall_mask;
@@ -62,7 +62,7 @@ static void xen_restore_fl(unsigned long flags)
 	   make sure we're don't switch CPUs between getting the vcpu
 	   pointer and updating the mask. */
 	preempt_disable();
-	vcpu = x86_read_percpu(xen_vcpu);
+	vcpu = percpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = flags;
 	preempt_enable_no_resched();
 
@@ -83,7 +83,7 @@ static void xen_irq_disable(void)
 	   make sure we're don't switch CPUs between getting the vcpu
 	   pointer and updating the mask. */
 	preempt_disable();
-	x86_read_percpu(xen_vcpu)->evtchn_upcall_mask = 1;
+	percpu_read(xen_vcpu)->evtchn_upcall_mask = 1;
 	preempt_enable_no_resched();
 }
 
@@ -96,7 +96,7 @@ static void xen_irq_enable(void)
 	   the caller is confused and is trying to re-enable interrupts
 	   on an indeterminate processor. */
 
-	vcpu = x86_read_percpu(xen_vcpu);
+	vcpu = percpu_read(xen_vcpu);
 	vcpu->evtchn_upcall_mask = 0;
 
 	/* Doesn't matter if we get preempted here, because any

commit bf9d3cf73e8caf0b3ae0b7f508a9f251536f5ff4
Author: Alex Nixon <alex.nixon@citrix.com>
Date:   Mon Aug 18 22:17:08 2008 -0700

    xen: Fix bug `do_IRQ: cannot handle IRQ -1 vector 0x6 cpu 1'
    
    Following commit 9c3f2468d8339866d9ef6a25aae31a8909c6be0d, do_IRQ()
    looks up the IRQ number in the per-cpu variable vector_irq.
    
    This commit makes Xen initialise an identity vector_irq map for both X86_32 and X86_64.
    
    Signed-off-by: Alex Nixon <alex.nixon@citrix.com>
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 28b85ab8422e..bb042608c602 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -21,7 +21,6 @@ void xen_force_evtchn_callback(void)
 
 static void __init __xen_init_IRQ(void)
 {
-#ifdef CONFIG_X86_64
 	int i;
 
 	/* Create identity vector->irq map */
@@ -31,7 +30,6 @@ static void __init __xen_init_IRQ(void)
 		for_each_possible_cpu(cpu)
 			per_cpu(vector_irq, cpu)[i] = i;
 	}
-#endif	/* CONFIG_X86_64 */
 
 	xen_init_IRQ();
 }

commit 0d1edf46ba229b46efacf75c0544b88c05a7b266
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Mon Jul 28 11:53:57 2008 -0700

    xen: compile irq functions without -pg for ftrace
    
    For some reason I managed to miss a bunch of irq-related functions
    which also need to be compiled without -pg when using ftrace.  This
    patch moves them into their own file, and starts a cleanup process
    I've been meaning to do anyway.
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Cc: "Alex Nixon (Intern)" <Alex.Nixon@eu.citrix.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
new file mode 100644
index 000000000000..28b85ab8422e
--- /dev/null
+++ b/arch/x86/xen/irq.c
@@ -0,0 +1,143 @@
+#include <linux/hardirq.h>
+
+#include <xen/interface/xen.h>
+#include <xen/interface/sched.h>
+#include <xen/interface/vcpu.h>
+
+#include <asm/xen/hypercall.h>
+#include <asm/xen/hypervisor.h>
+
+#include "xen-ops.h"
+
+/*
+ * Force a proper event-channel callback from Xen after clearing the
+ * callback mask. We do this in a very simple manner, by making a call
+ * down into Xen. The pending flag will be checked by Xen on return.
+ */
+void xen_force_evtchn_callback(void)
+{
+	(void)HYPERVISOR_xen_version(0, NULL);
+}
+
+static void __init __xen_init_IRQ(void)
+{
+#ifdef CONFIG_X86_64
+	int i;
+
+	/* Create identity vector->irq map */
+	for(i = 0; i < NR_VECTORS; i++) {
+		int cpu;
+
+		for_each_possible_cpu(cpu)
+			per_cpu(vector_irq, cpu)[i] = i;
+	}
+#endif	/* CONFIG_X86_64 */
+
+	xen_init_IRQ();
+}
+
+static unsigned long xen_save_fl(void)
+{
+	struct vcpu_info *vcpu;
+	unsigned long flags;
+
+	vcpu = x86_read_percpu(xen_vcpu);
+
+	/* flag has opposite sense of mask */
+	flags = !vcpu->evtchn_upcall_mask;
+
+	/* convert to IF type flag
+	   -0 -> 0x00000000
+	   -1 -> 0xffffffff
+	*/
+	return (-flags) & X86_EFLAGS_IF;
+}
+
+static void xen_restore_fl(unsigned long flags)
+{
+	struct vcpu_info *vcpu;
+
+	/* convert from IF type flag */
+	flags = !(flags & X86_EFLAGS_IF);
+
+	/* There's a one instruction preempt window here.  We need to
+	   make sure we're don't switch CPUs between getting the vcpu
+	   pointer and updating the mask. */
+	preempt_disable();
+	vcpu = x86_read_percpu(xen_vcpu);
+	vcpu->evtchn_upcall_mask = flags;
+	preempt_enable_no_resched();
+
+	/* Doesn't matter if we get preempted here, because any
+	   pending event will get dealt with anyway. */
+
+	if (flags == 0) {
+		preempt_check_resched();
+		barrier(); /* unmask then check (avoid races) */
+		if (unlikely(vcpu->evtchn_upcall_pending))
+			xen_force_evtchn_callback();
+	}
+}
+
+static void xen_irq_disable(void)
+{
+	/* There's a one instruction preempt window here.  We need to
+	   make sure we're don't switch CPUs between getting the vcpu
+	   pointer and updating the mask. */
+	preempt_disable();
+	x86_read_percpu(xen_vcpu)->evtchn_upcall_mask = 1;
+	preempt_enable_no_resched();
+}
+
+static void xen_irq_enable(void)
+{
+	struct vcpu_info *vcpu;
+
+	/* We don't need to worry about being preempted here, since
+	   either a) interrupts are disabled, so no preemption, or b)
+	   the caller is confused and is trying to re-enable interrupts
+	   on an indeterminate processor. */
+
+	vcpu = x86_read_percpu(xen_vcpu);
+	vcpu->evtchn_upcall_mask = 0;
+
+	/* Doesn't matter if we get preempted here, because any
+	   pending event will get dealt with anyway. */
+
+	barrier(); /* unmask then check (avoid races) */
+	if (unlikely(vcpu->evtchn_upcall_pending))
+		xen_force_evtchn_callback();
+}
+
+static void xen_safe_halt(void)
+{
+	/* Blocking includes an implicit local_irq_enable(). */
+	if (HYPERVISOR_sched_op(SCHEDOP_block, NULL) != 0)
+		BUG();
+}
+
+static void xen_halt(void)
+{
+	if (irqs_disabled())
+		HYPERVISOR_vcpu_op(VCPUOP_down, smp_processor_id(), NULL);
+	else
+		xen_safe_halt();
+}
+
+static const struct pv_irq_ops xen_irq_ops __initdata = {
+	.init_IRQ = __xen_init_IRQ,
+	.save_fl = xen_save_fl,
+	.restore_fl = xen_restore_fl,
+	.irq_disable = xen_irq_disable,
+	.irq_enable = xen_irq_enable,
+	.safe_halt = xen_safe_halt,
+	.halt = xen_halt,
+#ifdef CONFIG_X86_64
+	.adjust_exception_frame = xen_adjust_exception_frame,
+#endif
+};
+
+void __init xen_init_irq_ops()
+{
+	pv_irq_ops = xen_irq_ops;
+}
