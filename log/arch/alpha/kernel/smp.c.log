commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 52995bf413fe..631cc17410d1 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -36,7 +36,6 @@
 
 #include <asm/io.h>
 #include <asm/irq.h>
-#include <asm/pgtable.h>
 #include <asm/pgalloc.h>
 #include <asm/mmu_context.h>
 #include <asm/tlbflush.h>

commit 885f7f8e30468705926b3de53d32925bd7a51a03
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 7 21:42:22 2020 -0700

    mm: rename flush_icache_user_range to flush_icache_user_page
    
    The function currently known as flush_icache_user_range only operates on
    a single page.  Rename it to flush_icache_user_page as we'll need the
    name flush_icache_user_range for something else soon.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Albert Ou <aou@eecs.berkeley.edu>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/20200515143646.3857579-20-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 5f90df30be20..52995bf413fe 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -740,7 +740,7 @@ ipi_flush_icache_page(void *x)
 }
 
 void
-flush_icache_user_range(struct vm_area_struct *vma, struct page *page,
+flush_icache_user_page(struct vm_area_struct *vma, struct page *page,
 			unsigned long addr, int len)
 {
 	struct mm_struct *mm = vma->vm_mm;

commit caa759323c73676b3e48c8d9c86093c88b4aba97
Author: Nadav Amit <namit@vmware.com>
Date:   Wed Jun 12 23:48:05 2019 -0700

    smp: Remove smp_call_function() and on_each_cpu() return values
    
    The return value is fixed. Remove it and amend the callers.
    
    [ tglx: Fixup arm/bL_switcher and powerpc/rtas ]
    
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: https://lkml.kernel.org/r/20190613064813.8102-2-namit@vmware.com

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index d0dccae53ba9..5f90df30be20 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -614,8 +614,7 @@ void
 smp_imb(void)
 {
 	/* Must wait other processors to flush their icache before continue. */
-	if (on_each_cpu(ipi_imb, NULL, 1))
-		printk(KERN_CRIT "smp_imb: timed out\n");
+	on_each_cpu(ipi_imb, NULL, 1);
 }
 EXPORT_SYMBOL(smp_imb);
 
@@ -630,9 +629,7 @@ flush_tlb_all(void)
 {
 	/* Although we don't have any data to pass, we do want to
 	   synchronize with the other processors.  */
-	if (on_each_cpu(ipi_flush_tlb_all, NULL, 1)) {
-		printk(KERN_CRIT "flush_tlb_all: timed out\n");
-	}
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
 }
 
 #define asn_locked() (cpu_data[smp_processor_id()].asn_lock)
@@ -667,9 +664,7 @@ flush_tlb_mm(struct mm_struct *mm)
 		}
 	}
 
-	if (smp_call_function(ipi_flush_tlb_mm, mm, 1)) {
-		printk(KERN_CRIT "flush_tlb_mm: timed out\n");
-	}
+	smp_call_function(ipi_flush_tlb_mm, mm, 1);
 
 	preempt_enable();
 }
@@ -720,9 +715,7 @@ flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)
 	data.mm = mm;
 	data.addr = addr;
 
-	if (smp_call_function(ipi_flush_tlb_page, &data, 1)) {
-		printk(KERN_CRIT "flush_tlb_page: timed out\n");
-	}
+	smp_call_function(ipi_flush_tlb_page, &data, 1);
 
 	preempt_enable();
 }
@@ -772,9 +765,7 @@ flush_icache_user_range(struct vm_area_struct *vma, struct page *page,
 		}
 	}
 
-	if (smp_call_function(ipi_flush_icache_page, mm, 1)) {
-		printk(KERN_CRIT "flush_icache_page: timed out\n");
-	}
+	smp_call_function(ipi_flush_icache_page, mm, 1);
 
 	preempt_enable();
 }

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index f6726a746427..d0dccae53ba9 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *	linux/arch/alpha/kernel/smp.c
  *

commit 69f0678239b9f45652e1914efa20a397b3acac7a
Author: Matt Turner <mattst88@gmail.com>
Date:   Thu Aug 24 08:59:36 2017 -0700

    alpha: Fix section mismatches
    
    Signed-off-by: Matt Turner <mattst88@gmail.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 9fc560459ebd..f6726a746427 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -115,7 +115,7 @@ wait_boot_cpu_to_stop(int cpuid)
 /*
  * Where secondaries begin a life of C.
  */
-void
+void __init
 smp_callin(void)
 {
 	int cpuid = hard_smp_processor_id();

commit 68e21be2916b359fd8afb536c1911dc014cfd03e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 1 19:08:20 2017 +0100

    sched/headers: Move task->mm handling methods to <linux/sched/mm.h>
    
    Move the following task->mm helper APIs into a new header file,
    <linux/sched/mm.h>, to further reduce the size and complexity
    of <linux/sched.h>.
    
    Here are how the APIs are used in various kernel files:
    
      # mm_alloc():
      arch/arm/mach-rpc/ecard.c
      fs/exec.c
      include/linux/sched/mm.h
      kernel/fork.c
    
      # __mmdrop():
      arch/arc/include/asm/mmu_context.h
      include/linux/sched/mm.h
      kernel/fork.c
    
      # mmdrop():
      arch/arm/mach-rpc/ecard.c
      arch/m68k/sun3/mmu_emu.c
      arch/x86/mm/tlb.c
      drivers/gpu/drm/amd/amdkfd/kfd_process.c
      drivers/gpu/drm/i915/i915_gem_userptr.c
      drivers/infiniband/hw/hfi1/file_ops.c
      drivers/vfio/vfio_iommu_spapr_tce.c
      fs/exec.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      fs/proc/task_nommu.c
      fs/userfaultfd.c
      include/linux/mmu_notifier.h
      include/linux/sched/mm.h
      kernel/fork.c
      kernel/futex.c
      kernel/sched/core.c
      mm/khugepaged.c
      mm/ksm.c
      mm/mmu_context.c
      mm/mmu_notifier.c
      mm/oom_kill.c
      virt/kvm/kvm_main.c
    
      # mmdrop_async_fn():
      include/linux/sched/mm.h
    
      # mmdrop_async():
      include/linux/sched/mm.h
      kernel/fork.c
    
      # mmget_not_zero():
      fs/userfaultfd.c
      include/linux/sched/mm.h
      mm/oom_kill.c
    
      # mmput():
      arch/arc/include/asm/mmu_context.h
      arch/arc/kernel/troubleshoot.c
      arch/frv/mm/mmu-context.c
      arch/powerpc/platforms/cell/spufs/context.c
      arch/sparc/include/asm/mmu_context_32.h
      drivers/android/binder.c
      drivers/gpu/drm/etnaviv/etnaviv_gem.c
      drivers/gpu/drm/i915/i915_gem_userptr.c
      drivers/infiniband/core/umem.c
      drivers/infiniband/core/umem_odp.c
      drivers/infiniband/core/uverbs_main.c
      drivers/infiniband/hw/mlx4/main.c
      drivers/infiniband/hw/mlx5/main.c
      drivers/infiniband/hw/usnic/usnic_uiom.c
      drivers/iommu/amd_iommu_v2.c
      drivers/iommu/intel-svm.c
      drivers/lguest/lguest_user.c
      drivers/misc/cxl/fault.c
      drivers/misc/mic/scif/scif_rma.c
      drivers/oprofile/buffer_sync.c
      drivers/vfio/vfio_iommu_type1.c
      drivers/vhost/vhost.c
      drivers/xen/gntdev.c
      fs/exec.c
      fs/proc/array.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      fs/proc/task_nommu.c
      fs/userfaultfd.c
      include/linux/sched/mm.h
      kernel/cpuset.c
      kernel/events/core.c
      kernel/events/uprobes.c
      kernel/exit.c
      kernel/fork.c
      kernel/ptrace.c
      kernel/sys.c
      kernel/trace/trace_output.c
      kernel/tsacct.c
      mm/memcontrol.c
      mm/memory.c
      mm/mempolicy.c
      mm/migrate.c
      mm/mmu_notifier.c
      mm/nommu.c
      mm/oom_kill.c
      mm/process_vm_access.c
      mm/rmap.c
      mm/swapfile.c
      mm/util.c
      virt/kvm/async_pf.c
    
      # mmput_async():
      include/linux/sched/mm.h
      kernel/fork.c
      mm/oom_kill.c
    
      # get_task_mm():
      arch/arc/kernel/troubleshoot.c
      arch/powerpc/platforms/cell/spufs/context.c
      drivers/android/binder.c
      drivers/gpu/drm/etnaviv/etnaviv_gem.c
      drivers/infiniband/core/umem.c
      drivers/infiniband/core/umem_odp.c
      drivers/infiniband/hw/mlx4/main.c
      drivers/infiniband/hw/mlx5/main.c
      drivers/infiniband/hw/usnic/usnic_uiom.c
      drivers/iommu/amd_iommu_v2.c
      drivers/iommu/intel-svm.c
      drivers/lguest/lguest_user.c
      drivers/misc/cxl/fault.c
      drivers/misc/mic/scif/scif_rma.c
      drivers/oprofile/buffer_sync.c
      drivers/vfio/vfio_iommu_type1.c
      drivers/vhost/vhost.c
      drivers/xen/gntdev.c
      fs/proc/array.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      include/linux/sched/mm.h
      kernel/cpuset.c
      kernel/events/core.c
      kernel/exit.c
      kernel/fork.c
      kernel/ptrace.c
      kernel/sys.c
      kernel/trace/trace_output.c
      kernel/tsacct.c
      mm/memcontrol.c
      mm/memory.c
      mm/mempolicy.c
      mm/migrate.c
      mm/mmu_notifier.c
      mm/nommu.c
      mm/util.c
    
      # mm_access():
      fs/proc/base.c
      include/linux/sched/mm.h
      kernel/fork.c
      mm/process_vm_access.c
    
      # mm_release():
      arch/arc/include/asm/mmu_context.h
      fs/exec.c
      include/linux/sched/mm.h
      include/uapi/linux/sched.h
      kernel/exit.c
      kernel/fork.c
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index acb4b146a607..9fc560459ebd 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -14,7 +14,7 @@
 #include <linux/kernel.h>
 #include <linux/kernel_stat.h>
 #include <linux/module.h>
-#include <linux/sched.h>
+#include <linux/sched/mm.h>
 #include <linux/mm.h>
 #include <linux/err.h>
 #include <linux/threads.h>

commit f1f1007644ffc8051a4c11427d58b1967ae7b75a
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Mon Feb 27 14:30:07 2017 -0800

    mm: add new mmgrab() helper
    
    Apart from adding the helper function itself, the rest of the kernel is
    converted mechanically using:
    
      git grep -l 'atomic_inc.*mm_count' | xargs sed -i 's/atomic_inc(&\(.*\)->mm_count);/mmgrab\(\1\);/'
      git grep -l 'atomic_inc.*mm_count' | xargs sed -i 's/atomic_inc(&\(.*\)\.mm_count);/mmgrab\(\&\1\);/'
    
    This is needed for a later patch that hooks into the helper, but might
    be a worthwhile cleanup on its own.
    
    (Michal Hocko provided most of the kerneldoc comment.)
    
    Link: http://lkml.kernel.org/r/20161218123229.22952-1-vegard.nossum@oracle.com
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 46bf263c3153..acb4b146a607 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -144,7 +144,7 @@ smp_callin(void)
 		alpha_mv.smp_callin();
 
 	/* All kernel threads share the same mm context.  */
-	atomic_inc(&init_mm.mm_count);
+	mmgrab(&init_mm);
 	current->active_mm = &init_mm;
 
 	/* inform the notifiers about the new cpu */

commit fc6d73d67436e7784758a831227bd019547a3f73
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 26 18:43:40 2016 +0000

    arch/hotplug: Call into idle with a proper state
    
    Let the non boot cpus call into idle with the corresponding hotplug state, so
    the hotplug core can handle the further bringup. That's a first step to
    convert the boot side of the hotplugged cpus to do all the synchronization
    with the other side through the state machine. For now it'll only start the
    hotplug thread and kick the full bringup of the cpu.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Cc: "Srivatsa S. Bhat" <srivatsa@mit.edu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Sebastian Siewior <bigeasy@linutronix.de>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Turner <pjt@google.com>
    Link: http://lkml.kernel.org/r/20160226182341.614102639@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 2f24447fef92..46bf263c3153 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -168,7 +168,7 @@ smp_callin(void)
 	      cpuid, current, current->active_mm));
 
 	preempt_disable();
-	cpu_startup_entry(CPUHP_ONLINE);
+	cpu_startup_entry(CPUHP_AP_ONLINE_IDLE);
 }
 
 /* Wait until hwrpb->txrdy is clear for cpu.  Return -1 on timeout.  */

commit 614aab527b3d48f481854c215251471407473599
Author: Jiang Liu <liuj97@gmail.com>
Date:   Mon Dec 16 00:36:25 2013 +0800

    smp, alpha: kill SMP single function call interrupt
    
    Commit 9a46ad6d6df3b54 "smp: make smp_call_function_many() use logic
    similar to smp_call_function_single()" has unified the way to handle
    single and multiple cross-CPU function calls. Now only one interrupt
    is needed for architecture specific code to support generic SMP function
    call interfaces, so kill the redundant single function call interrupt.
    
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Shaohua Li <shli@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Jiri Kosina <trivial@kernel.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Acked-by: Matt Turner <mattst88@gmail.com>
    Cc: linux-alpha@vger.kernel.org
    Signed-off-by: Jiang Liu <liuj97@gmail.com>
    Signed-off-by: Matt Turner <mattst88@gmail.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 99ac36d5de4e..2f24447fef92 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -63,7 +63,6 @@ static struct {
 enum ipi_message_type {
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
-	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
 };
 
@@ -506,7 +505,6 @@ setup_profiling_timer(unsigned int multiplier)
 	return -EINVAL;
 }
 
-
 static void
 send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
 {
@@ -552,10 +550,6 @@ handle_ipi(struct pt_regs *regs)
 			generic_smp_call_function_interrupt();
 			break;
 
-		case IPI_CALL_FUNC_SINGLE:
-			generic_smp_call_function_single_interrupt();
-			break;
-
 		case IPI_CPU_STOP:
 			halt();
 
@@ -606,7 +600,7 @@ void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC);
 }
 
 static void

commit a1659d6d128a7e0c2985bce7c957b66af1f71181
Author: Richard Henderson <rth@twiddle.net>
Date:   Sun Jul 14 10:57:34 2013 -0700

    alpha: Switch to GENERIC_CLOCKEVENTS
    
    This allows us to get rid of some hacky code for SMP.  Get rid of
    some cycle counter hackery that's now handled by generic code via
    clocksource + clock_event_device objects.
    
    Signed-off-by: Richard Henderson <rth@twiddle.net>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 9dbbcb3b9146..99ac36d5de4e 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -138,9 +138,11 @@ smp_callin(void)
 
 	/* Get our local ticker going. */
 	smp_setup_percpu_timer(cpuid);
+	init_clockevent();
 
 	/* Call platform-specific callin, if specified */
-	if (alpha_mv.smp_callin) alpha_mv.smp_callin();
+	if (alpha_mv.smp_callin)
+		alpha_mv.smp_callin();
 
 	/* All kernel threads share the same mm context.  */
 	atomic_inc(&init_mm.mm_count);
@@ -498,35 +500,6 @@ smp_cpus_done(unsigned int max_cpus)
 	       ((bogosum + 2500) / (5000/HZ)) % 100);
 }
 
-
-void
-smp_percpu_timer_interrupt(struct pt_regs *regs)
-{
-	struct pt_regs *old_regs;
-	int cpu = smp_processor_id();
-	unsigned long user = user_mode(regs);
-	struct cpuinfo_alpha *data = &cpu_data[cpu];
-
-	old_regs = set_irq_regs(regs);
-
-	/* Record kernel PC.  */
-	profile_tick(CPU_PROFILING);
-
-	if (!--data->prof_counter) {
-		/* We need to make like a normal interrupt -- otherwise
-		   timer interrupts ignore the global interrupt lock,
-		   which would be a Bad Thing.  */
-		irq_enter();
-
-		update_process_times(user);
-
-		data->prof_counter = data->prof_multiplier;
-
-		irq_exit();
-	}
-	set_irq_regs(old_regs);
-}
-
 int
 setup_profiling_timer(unsigned int multiplier)
 {

commit 91b678c8edb7d8abd444705df63b80af31ad13e8
Author: Chen Gang <gang.chen@asianux.com>
Date:   Wed May 29 19:04:09 2013 +0800

    alpha: kernel: typo issue, using '1' instead of '11'
    
    For sending message:
    
            *(unsigned int *)&cpu->ipc_buffer[0] = len;
            cp1 = (char *) &cpu->ipc_buffer[1];
    
    But for receive message:
    
                    cnt = cpu->ipc_buffer[0] >> 32;
                    ...
                           cp1 = (char *) &cpu->ipc_buffer[11];
    
    They are not pairs, it is typo issue of the redundency '1'.
    
    So need use '1' instead of '11'.
    
    Reviewed-by: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Chen Gang <gang.chen@asianux.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 4bc3c414d075..9dbbcb3b9146 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -264,7 +264,7 @@ recv_secondary_console_msg(void)
 		if (cnt <= 0 || cnt >= 80)
 			strcpy(buf, "<<< BOGUS MSG >>>");
 		else {
-			cp1 = (char *) &cpu->ipc_buffer[11];
+			cp1 = (char *) &cpu->ipc_buffer[1];
 			cp2 = buf;
 			memcpy(cp2, cp1, cnt);
 			cp2[cnt] = '\0';

commit 00ee03092a6e4b1d0ddc6b861ebb9ed8d13cc29b
Author: Chen Gang <gang.chen@asianux.com>
Date:   Wed May 29 18:51:28 2013 +0800

    alpha: kernel: using memcpy() instead of strcpy()
    
    When sending message in send_secondary_console_msg(), the length is not
    include the NUL byte, and also not copy NUL to 'ipc_buffer'.
    
    When receive message in recv_secondary_console_msg(), the 'cnt' also
    excludes NUL.
    
    So when get string from ipc_buffer, it may not be NUL terminated.
    
    Then use memcpy() instead of strcpy(), and set last byte NUL.
    
    Reviewed-by: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Chen Gang <gang.chen@asianux.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 53b18a620e1c..4bc3c414d075 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -266,7 +266,8 @@ recv_secondary_console_msg(void)
 		else {
 			cp1 = (char *) &cpu->ipc_buffer[11];
 			cp2 = buf;
-			strcpy(cp2, cp1);
+			memcpy(cp2, cp1, cnt);
+			cp2[cnt] = '\0';
 			
 			while ((cp2 = strchr(cp2, '\r')) != 0) {
 				*cp2 = ' ';

commit ab39c77c3246f8462663fb1b07fa193f3e31e255
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jun 17 15:43:14 2013 -0400

    alpha: delete __cpuinit usage from all users
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    This removes all the alpha uses of the __cpuinit macros.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 7b60834fb4b2..53b18a620e1c 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -116,7 +116,7 @@ wait_boot_cpu_to_stop(int cpuid)
 /*
  * Where secondaries begin a life of C.
  */
-void __cpuinit
+void
 smp_callin(void)
 {
 	int cpuid = hard_smp_processor_id();
@@ -194,7 +194,7 @@ wait_for_txrdy (unsigned long cpumask)
  * Send a message to a secondary's console.  "START" is one such
  * interesting message.  ;-)
  */
-static void __cpuinit
+static void
 send_secondary_console_msg(char *str, int cpuid)
 {
 	struct percpu_struct *cpu;
@@ -285,7 +285,7 @@ recv_secondary_console_msg(void)
 /*
  * Convince the console to have a secondary cpu begin execution.
  */
-static int __cpuinit
+static int
 secondary_cpu_start(int cpuid, struct task_struct *idle)
 {
 	struct percpu_struct *cpu;
@@ -356,7 +356,7 @@ secondary_cpu_start(int cpuid, struct task_struct *idle)
 /*
  * Bring one cpu online.
  */
-static int __cpuinit
+static int
 smp_boot_one_cpu(int cpuid, struct task_struct *idle)
 {
 	unsigned long timeout;
@@ -472,7 +472,7 @@ smp_prepare_boot_cpu(void)
 {
 }
 
-int __cpuinit
+int
 __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	smp_boot_one_cpu(cpu, tidle);

commit a123322d8afcfb5f86e0cc0062024084658aeeb2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 21 22:49:37 2013 +0100

    alpha: Use generic idle loop
    
    The core provides a generic idle poll loop.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Link: http://lkml.kernel.org/r/20130321215233.766017538@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 9603bc234b47..7b60834fb4b2 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -167,8 +167,7 @@ smp_callin(void)
 	      cpuid, current, current->active_mm));
 
 	preempt_disable();
-	/* Do nothing.  */
-	cpu_idle();
+	cpu_startup_entry(CPUHP_ONLINE);
 }
 
 /* Wait until hwrpb->txrdy is clear for cpu.  Return -1 on timeout.  */

commit f8d6c8d98d9ea7afef1e0d93d756a2dca879d1ea
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Dec 21 14:05:55 2012 -0800

    ALPHA: drivers: remove __dev* attributes.
    
    CONFIG_HOTPLUG is going away as an option.  As a result, the __dev*
    markings need to be removed.
    
    This change removes the use of __devinit, __devexit_p, __devinitdata,
    and __devexit from these drivers.
    
    Based on patches originally written by Bill Pemberton, but redone by me
    in order to handle some of the coding style issues better, by hand.
    
    Cc: Bill Pemberton <wfp5p@virginia.edu>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index a41ad90a97a6..9603bc234b47 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -68,7 +68,7 @@ enum ipi_message_type {
 };
 
 /* Set to a secondary's cpuid when it comes online.  */
-static int smp_secondary_alive __devinitdata = 0;
+static int smp_secondary_alive = 0;
 
 int smp_num_probed;		/* Internal processor count */
 int smp_num_cpus = 1;		/* Number that came online.  */
@@ -172,7 +172,7 @@ smp_callin(void)
 }
 
 /* Wait until hwrpb->txrdy is clear for cpu.  Return -1 on timeout.  */
-static int __devinit
+static int
 wait_for_txrdy (unsigned long cpumask)
 {
 	unsigned long timeout;
@@ -468,7 +468,7 @@ smp_prepare_cpus(unsigned int max_cpus)
 	smp_num_cpus = smp_num_probed;
 }
 
-void __devinit
+void
 smp_prepare_boot_cpu(void)
 {
 }

commit 6a6c0272f17cc80a8286d915f2ddf31557c2d559
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Aug 23 14:11:25 2012 +0200

    alpha: Fix preemption handling in idle loop
    
    cpu_idle() is called on the boot CPU by the init code with
    preemption disabled. But the cpu_idle() function in alpha
    doesn't handle this when it calls schedule() directly.
    
    Fix it by converting it into schedule_preempt_disabled().
    
    Also disable preemption before calling cpu_idle() from
    secondary CPU entry code to stay consistent with this
    state.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Tested-by: Michael Cree <mcree@orcon.net.nz>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: alpha <linux-alpha@vger.kernel.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 35ddc02bfa4a..a41ad90a97a6 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -166,6 +166,7 @@ smp_callin(void)
 	DBGS(("smp_callin: commencing CPU %d current %p active_mm %p\n",
 	      cpuid, current, current->active_mm));
 
+	preempt_disable();
 	/* Do nothing.  */
 	cpu_idle();
 }

commit 2ec9415c71a1ddad969602e690a9c848b81256b3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:55 2012 +0000

    alpha: Use generic idle thread allocation
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Link: http://lkml.kernel.org/r/20120420124557.914631081@linutronix.de

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 68d39470fb52..35ddc02bfa4a 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -357,24 +357,10 @@ secondary_cpu_start(int cpuid, struct task_struct *idle)
  * Bring one cpu online.
  */
 static int __cpuinit
-smp_boot_one_cpu(int cpuid)
+smp_boot_one_cpu(int cpuid, struct task_struct *idle)
 {
-	struct task_struct *idle;
 	unsigned long timeout;
 
-	/* Cook up an idler for this guy.  Note that the address we
-	   give to kernel_thread is irrelevant -- it's going to start
-	   where HWRPB.CPU_restart says to start.  But this gets all
-	   the other task-y sort of data structures set up like we
-	   wish.  We can't use kernel_thread since we must avoid
-	   rescheduling the child.  */
-	idle = fork_idle(cpuid);
-	if (IS_ERR(idle))
-		panic("failed fork for CPU %d", cpuid);
-
-	DBGS(("smp_boot_one_cpu: CPU %d state 0x%lx flags 0x%lx\n",
-	      cpuid, idle->state, idle->flags));
-
 	/* Signal the secondary to wait a moment.  */
 	smp_secondary_alive = -1;
 
@@ -489,7 +475,7 @@ smp_prepare_boot_cpu(void)
 int __cpuinit
 __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
-	smp_boot_one_cpu(cpu);
+	smp_boot_one_cpu(cpu, tidle);
 
 	return cpu_online(cpu) ? 0 : -ENOSYS;
 }

commit 8239c25f47d2b318156993b15f33900a86ea5e17
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:42 2012 +0000

    smp: Add task_struct argument to __cpu_up()
    
    Preparatory patch to make the idle thread allocation for secondary
    cpus generic.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20120420124556.964170564@linutronix.de

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 50d438db1f6b..68d39470fb52 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -487,7 +487,7 @@ smp_prepare_boot_cpu(void)
 }
 
 int __cpuinit
-__cpu_up(unsigned int cpu)
+__cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	smp_boot_one_cpu(cpu);
 

commit 5f054e31c63be774bf1ce252f20d56012a00f8a5
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Mar 29 15:38:31 2012 +1030

    documentation: remove references to cpu_*_map.
    
    This has been obsolescent for a while, fix documentation and
    misc comments.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 4087a569b43b..50d438db1f6b 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -450,7 +450,7 @@ setup_smp(void)
 		smp_num_probed = 1;
 	}
 
-	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_map = %lx\n",
+	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_mask = %lx\n",
 	       smp_num_probed, cpumask_bits(cpu_present_mask)[0]);
 }
 

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index d739703608fc..4087a569b43b 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -31,7 +31,7 @@
 
 #include <asm/hwrpb.h>
 #include <asm/ptrace.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 
 #include <asm/io.h>
 #include <asm/irq.h>

commit 81740fc6b2144f5d197affb10f3c4062fddf21e4
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Tue May 24 17:12:56 2011 -0700

    alpha: replace with new cpumask APIs
    
    We plan to remove cpu_xx() old APIs.  Thus convert them.  This patch has
    no functional change.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 5a621c6d22ab..d739703608fc 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -451,7 +451,7 @@ setup_smp(void)
 	}
 
 	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_map = %lx\n",
-	       smp_num_probed, cpu_present_map.bits[0]);
+	       smp_num_probed, cpumask_bits(cpu_present_mask)[0]);
 }
 
 /*
@@ -629,8 +629,9 @@ smp_send_reschedule(int cpu)
 void
 smp_send_stop(void)
 {
-	cpumask_t to_whom = cpu_possible_map;
-	cpu_clear(smp_processor_id(), to_whom);
+	cpumask_t to_whom;
+	cpumask_copy(&to_whom, cpu_possible_mask);
+	cpumask_clear_cpu(smp_processor_id(), &to_whom);
 #ifdef DEBUG_IPI_MSG
 	if (hard_smp_processor_id() != boot_cpu_id)
 		printk(KERN_WARNING "smp_send_stop: Not on boot cpu.\n");

commit 184748cc50b2dceb8287f9fb657eda48ff8fcfe7
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Apr 5 17:23:39 2011 +0200

    sched: Provide scheduler_ipi() callback in response to smp_send_reschedule()
    
    For future rework of try_to_wake_up() we'd like to push part of that
    function onto the CPU the task is actually going to run on.
    
    In order to do so we need a generic callback from the existing scheduler IPI.
    
    This patch introduces such a generic callback: scheduler_ipi() and
    implements it as a NOP.
    
    BenH notes: PowerPC might use this IPI on offline CPUs under rare conditions!
    
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Reviewed-by: Frank Rowand <frank.rowand@am.sony.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20110405152728.744338123@chello.nl

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 42aa078a5e4d..5a621c6d22ab 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -585,8 +585,7 @@ handle_ipi(struct pt_regs *regs)
 
 		switch (which) {
 		case IPI_RESCHEDULE:
-			/* Reschedule callback.  Everything to be done
-			   is done by the interrupt return path.  */
+			scheduler_ipi();
 			break;
 
 		case IPI_CALL_FUNC:

commit 81065e4f2b525410d0c80040140e086abfbf7de2
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Sep 24 09:34:43 2009 -0600

    cpumask: arch_send_call_function_ipi_mask: alpha
    
    We're weaning the core code off handing cpumask's around on-stack.
    This introduces arch_send_call_function_ipi_mask().
    
    We also take the chance to wean the send_ipi_message off the
    obsolescent for_each_cpu_mask(): making it take a pointer seemed the
    most natural way to do this.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index b1fe5674c3a1..42aa078a5e4d 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -548,16 +548,16 @@ setup_profiling_timer(unsigned int multiplier)
 
 
 static void
-send_ipi_message(cpumask_t to_whom, enum ipi_message_type operation)
+send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
 {
 	int i;
 
 	mb();
-	for_each_cpu_mask(i, to_whom)
+	for_each_cpu(i, to_whom)
 		set_bit(operation, &ipi_data[i].bits);
 
 	mb();
-	for_each_cpu_mask(i, to_whom)
+	for_each_cpu(i, to_whom)
 		wripir(i);
 }
 
@@ -624,7 +624,7 @@ smp_send_reschedule(int cpu)
 		printk(KERN_WARNING
 		       "smp_send_reschedule: Sending IPI to self.\n");
 #endif
-	send_ipi_message(cpumask_of_cpu(cpu), IPI_RESCHEDULE);
+	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
 void
@@ -636,17 +636,17 @@ smp_send_stop(void)
 	if (hard_smp_processor_id() != boot_cpu_id)
 		printk(KERN_WARNING "smp_send_stop: Not on boot cpu.\n");
 #endif
-	send_ipi_message(to_whom, IPI_CPU_STOP);
+	send_ipi_message(&to_whom, IPI_CPU_STOP);
 }
 
-void arch_send_call_function_ipi(cpumask_t mask)
+void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
 	send_ipi_message(mask, IPI_CALL_FUNC);
 }
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	send_ipi_message(cpumask_of_cpu(cpu), IPI_CALL_FUNC_SINGLE);
+	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
 static void

commit 1371be0f7c8f6141b2dbfde6a7ae7885bedb9834
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Feb 16 17:31:59 2009 -0600

    cpumask: Use cpu_*_mask accessors code: alpha
    
    Impact: use new API, fix SMP bug.
    
    Use the new accessors rather than frobbing bits directly.
    
    This also removes the bug introduced in ee0c468b (alpha: compile
    fixes) which had Alpha setting bits on an on-stack cpumask, not the
    cpu_online_map.
    
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Acked-by: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 00f1dc3dfd5f..b1fe5674c3a1 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -120,12 +120,12 @@ void __cpuinit
 smp_callin(void)
 {
 	int cpuid = hard_smp_processor_id();
-	cpumask_t mask = cpu_online_map;
 
-	if (cpu_test_and_set(cpuid, mask)) {
+	if (cpu_online(cpuid)) {
 		printk("??, cpu 0x%x already present??\n", cpuid);
 		BUG();
 	}
+	set_cpu_online(cpuid, true);
 
 	/* Turn on machine checks.  */
 	wrmces(7);
@@ -436,8 +436,8 @@ setup_smp(void)
 				((char *)cpubase + i*hwrpb->processor_size);
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
-				cpu_set(i, cpu_possible_map);
-				cpu_set(i, cpu_present_map);
+				set_cpu_possible(i, true);
+				set_cpu_present(i, true);
 				cpu->pal_revision = boot_cpu_palrev;
 			}
 
@@ -470,8 +470,8 @@ smp_prepare_cpus(unsigned int max_cpus)
 
 	/* Nothing to do on a UP box, or when told not to.  */
 	if (smp_num_probed == 1 || max_cpus == 0) {
-		cpu_possible_map = cpumask_of_cpu(boot_cpuid);
-		cpu_present_map = cpumask_of_cpu(boot_cpuid);
+		init_cpu_possible(cpumask_of(boot_cpuid));
+		init_cpu_present(cpumask_of(boot_cpuid));
 		printk(KERN_INFO "SMP mode deactivated.\n");
 		return;
 	}

commit ee0c468bb151aad23281660152d2894f1e214238
Author: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
Date:   Thu Jan 29 14:25:19 2009 -0800

    alpha: compile fixes
    
    - jensen build: fix conflicting declarations for pci_alloc_consistent()
      and undefined virt_to_phys();
    
    - SMP: arch/alpha/kernel/smp.c:124: warning: passing argument 2
           of '__cpu_test_and_set' discards qualifiers from pointer target type
      Interestingly, this only happens with gcc-4.2; gcc <= 4.1 and gcc-4.3
      are OK. Fixed with extra assignment.
    
    Signed-off-by: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index d953e510f68d..00f1dc3dfd5f 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -120,8 +120,9 @@ void __cpuinit
 smp_callin(void)
 {
 	int cpuid = hard_smp_processor_id();
+	cpumask_t mask = cpu_online_map;
 
-	if (cpu_test_and_set(cpuid, cpu_online_map)) {
+	if (cpu_test_and_set(cpuid, mask)) {
 		printk("??, cpu 0x%x already present??\n", cpuid);
 		BUG();
 	}

commit 98a79d6a50181ca1ecf7400eda01d5dc1bc0dbf0
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:19:41 2008 +1030

    cpumask: centralize cpu_online_map and cpu_possible_map
    
    Impact: cleanup
    
    Each SMP arch defines these themselves.  Move them to a central
    location.
    
    Twists:
    1) Some archs (m32, parisc, s390) set possible_map to all 1, so we add a
       CONFIG_INIT_ALL_POSSIBLE for this rather than break them.
    
    2) mips and sparc32 '#define cpu_possible_map phys_cpu_present_map'.
       Those archs simply have phys_cpu_present_map replaced everywhere.
    
    3) Alpha defined cpu_possible_map to cpu_present_map; this is tricky
       so I just manipulate them both in sync.
    
    4) IA64, cris and m32r have gratuitous 'extern cpumask_t cpu_possible_map'
       declarations.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Travis <travis@sgi.com>
    Cc: ink@jurassic.park.msu.ru
    Cc: rmk@arm.linux.org.uk
    Cc: starvik@axis.com
    Cc: tony.luck@intel.com
    Cc: takata@linux-m32r.org
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: paulus@samba.org
    Cc: schwidefsky@de.ibm.com
    Cc: lethal@linux-sh.org
    Cc: wli@holomorphy.com
    Cc: davem@davemloft.net
    Cc: jdike@addtoit.com
    Cc: mingo@redhat.com

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index cf7da10097bb..d953e510f68d 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -70,11 +70,6 @@ enum ipi_message_type {
 /* Set to a secondary's cpuid when it comes online.  */
 static int smp_secondary_alive __devinitdata = 0;
 
-/* Which cpus ids came online.  */
-cpumask_t cpu_online_map;
-
-EXPORT_SYMBOL(cpu_online_map);
-
 int smp_num_probed;		/* Internal processor count */
 int smp_num_cpus = 1;		/* Number that came online.  */
 EXPORT_SYMBOL(smp_num_cpus);
@@ -440,6 +435,7 @@ setup_smp(void)
 				((char *)cpubase + i*hwrpb->processor_size);
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
+				cpu_set(i, cpu_possible_map);
 				cpu_set(i, cpu_present_map);
 				cpu->pal_revision = boot_cpu_palrev;
 			}
@@ -473,6 +469,7 @@ smp_prepare_cpus(unsigned int max_cpus)
 
 	/* Nothing to do on a UP box, or when told not to.  */
 	if (smp_num_probed == 1 || max_cpus == 0) {
+		cpu_possible_map = cpumask_of_cpu(boot_cpuid);
 		cpu_present_map = cpumask_of_cpu(boot_cpuid);
 		printk(KERN_INFO "SMP mode deactivated.\n");
 		return;

commit 7d6a8a1c487422b772201927c454930377d8cf7e
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Sat Nov 22 17:33:34 2008 +0000

    false __cpuinit positives on alpha
    
    pure noise - alpha doesn't have CPU hotplug
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index e657c45d91d2..cf7da10097bb 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -121,7 +121,7 @@ wait_boot_cpu_to_stop(int cpuid)
 /*
  * Where secondaries begin a life of C.
  */
-void __init
+void __cpuinit
 smp_callin(void)
 {
 	int cpuid = hard_smp_processor_id();
@@ -198,7 +198,7 @@ wait_for_txrdy (unsigned long cpumask)
  * Send a message to a secondary's console.  "START" is one such
  * interesting message.  ;-)
  */
-static void __init
+static void __cpuinit
 send_secondary_console_msg(char *str, int cpuid)
 {
 	struct percpu_struct *cpu;
@@ -289,7 +289,7 @@ recv_secondary_console_msg(void)
 /*
  * Convince the console to have a secondary cpu begin execution.
  */
-static int __init
+static int __cpuinit
 secondary_cpu_start(int cpuid, struct task_struct *idle)
 {
 	struct percpu_struct *cpu;

commit 574f34cee2b6574d43bf4506f771c1cec6a5d391
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Wed Oct 15 22:01:19 2008 -0700

    alpha: notify_cpu_starting() compile fixlet
    
    arch/alpha/kernel/smp.c:153: error: implicit declaration of function 'notify_cpu_starting'
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 06b6fdab639f..e657c45d91d2 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -27,6 +27,7 @@
 #include <linux/cache.h>
 #include <linux/profile.h>
 #include <linux/bitops.h>
+#include <linux/cpu.h>
 
 #include <asm/hwrpb.h>
 #include <asm/ptrace.h>

commit e545a6140b698b2494daf0b32107bdcc5e901390
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Sun Sep 7 16:57:22 2008 +0200

    kernel/cpu.c: create a CPU_STARTING cpu_chain notifier
    
    Right now, there is no notifier that is called on a new cpu, before the new
    cpu begins processing interrupts/softirqs.
    Various kernel function would need that notification, e.g. kvm works around
    by calling smp_call_function_single(), rcu polls cpu_online_map.
    
    The patch adds a CPU_STARTING notification. It also adds a helper function
    that sends the message to all cpu_chain handlers.
    
    Tested on x86-64.
    All other archs are untested. Especially on sparc, I'm not sure if I got
    it right.
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 83df541650fc..06b6fdab639f 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -149,6 +149,9 @@ smp_callin(void)
 	atomic_inc(&init_mm.mm_count);
 	current->active_mm = &init_mm;
 
+	/* inform the notifiers about the new cpu */
+	notify_cpu_starting(cpuid);
+
 	/* Must have completely accurate bogos.  */
 	local_irq_enable();
 

commit 15c8b6c1aaaf1c4edd67e2f02e4d8e1bd1a51c0d
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri May 9 09:39:44 2008 +0200

    on_each_cpu(): kill unused 'retry' parameter
    
    It's not even passed on to smp_call_function() anymore, since that
    was removed. So kill it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 44114c8dbb2a..83df541650fc 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -657,7 +657,7 @@ void
 smp_imb(void)
 {
 	/* Must wait other processors to flush their icache before continue. */
-	if (on_each_cpu(ipi_imb, NULL, 1, 1))
+	if (on_each_cpu(ipi_imb, NULL, 1))
 		printk(KERN_CRIT "smp_imb: timed out\n");
 }
 EXPORT_SYMBOL(smp_imb);
@@ -673,7 +673,7 @@ flush_tlb_all(void)
 {
 	/* Although we don't have any data to pass, we do want to
 	   synchronize with the other processors.  */
-	if (on_each_cpu(ipi_flush_tlb_all, NULL, 1, 1)) {
+	if (on_each_cpu(ipi_flush_tlb_all, NULL, 1)) {
 		printk(KERN_CRIT "flush_tlb_all: timed out\n");
 	}
 }

commit 8691e5a8f691cc2a4fda0651e8d307aaba0e7d68
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 6 11:18:06 2008 +0200

    smp_call_function: get rid of the unused nonatomic/retry argument
    
    It's never used and the comments refer to nonatomic and retry
    interchangably. So get rid of it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 95c905be9154..44114c8dbb2a 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -710,7 +710,7 @@ flush_tlb_mm(struct mm_struct *mm)
 		}
 	}
 
-	if (smp_call_function(ipi_flush_tlb_mm, mm, 1, 1)) {
+	if (smp_call_function(ipi_flush_tlb_mm, mm, 1)) {
 		printk(KERN_CRIT "flush_tlb_mm: timed out\n");
 	}
 
@@ -763,7 +763,7 @@ flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)
 	data.mm = mm;
 	data.addr = addr;
 
-	if (smp_call_function(ipi_flush_tlb_page, &data, 1, 1)) {
+	if (smp_call_function(ipi_flush_tlb_page, &data, 1)) {
 		printk(KERN_CRIT "flush_tlb_page: timed out\n");
 	}
 
@@ -815,7 +815,7 @@ flush_icache_user_range(struct vm_area_struct *vma, struct page *page,
 		}
 	}
 
-	if (smp_call_function(ipi_flush_icache_page, mm, 1, 1)) {
+	if (smp_call_function(ipi_flush_icache_page, mm, 1)) {
 		printk(KERN_CRIT "flush_icache_page: timed out\n");
 	}
 

commit c524a1d8914408fd57241d9542fa2d402f004a33
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Jun 10 20:47:29 2008 +0200

    alpha: convert to generic helpers for IPI function calls
    
    This converts alpha to use the new helpers for smp_call_function() and
    friends, and adds support for smp_call_function_single().
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 2525692db0ab..95c905be9154 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -62,6 +62,7 @@ static struct {
 enum ipi_message_type {
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
+	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
 };
 
@@ -558,51 +559,6 @@ send_ipi_message(cpumask_t to_whom, enum ipi_message_type operation)
 		wripir(i);
 }
 
-/* Structure and data for smp_call_function.  This is designed to 
-   minimize static memory requirements.  Plus it looks cleaner.  */
-
-struct smp_call_struct {
-	void (*func) (void *info);
-	void *info;
-	long wait;
-	atomic_t unstarted_count;
-	atomic_t unfinished_count;
-};
-
-static struct smp_call_struct *smp_call_function_data;
-
-/* Atomicly drop data into a shared pointer.  The pointer is free if
-   it is initially locked.  If retry, spin until free.  */
-
-static int
-pointer_lock (void *lock, void *data, int retry)
-{
-	void *old, *tmp;
-
-	mb();
- again:
-	/* Compare and swap with zero.  */
-	asm volatile (
-	"1:	ldq_l	%0,%1\n"
-	"	mov	%3,%2\n"
-	"	bne	%0,2f\n"
-	"	stq_c	%2,%1\n"
-	"	beq	%2,1b\n"
-	"2:"
-	: "=&r"(old), "=m"(*(void **)lock), "=&r"(tmp)
-	: "r"(data)
-	: "memory");
-
-	if (old == 0)
-		return 0;
-	if (! retry)
-		return -EBUSY;
-
-	while (*(void **)lock)
-		barrier();
-	goto again;
-}
-
 void
 handle_ipi(struct pt_regs *regs)
 {
@@ -632,31 +588,12 @@ handle_ipi(struct pt_regs *regs)
 			break;
 
 		case IPI_CALL_FUNC:
-		    {
-			struct smp_call_struct *data;
-			void (*func)(void *info);
-			void *info;
-			int wait;
-
-			data = smp_call_function_data;
-			func = data->func;
-			info = data->info;
-			wait = data->wait;
-
-			/* Notify the sending CPU that the data has been
-			   received, and execution is about to begin.  */
-			mb();
-			atomic_dec (&data->unstarted_count);
-
-			/* At this point the structure may be gone unless
-			   wait is true.  */
-			(*func)(info);
-
-			/* Notify the sending CPU that the task is done.  */
-			mb();
-			if (wait) atomic_dec (&data->unfinished_count);
+			generic_smp_call_function_interrupt();
+			break;
+
+		case IPI_CALL_FUNC_SINGLE:
+			generic_smp_call_function_single_interrupt();
 			break;
-		    }
 
 		case IPI_CPU_STOP:
 			halt();
@@ -700,102 +637,15 @@ smp_send_stop(void)
 	send_ipi_message(to_whom, IPI_CPU_STOP);
 }
 
-/*
- * Run a function on all other CPUs.
- *  <func>	The function to run. This must be fast and non-blocking.
- *  <info>	An arbitrary pointer to pass to the function.
- *  <retry>	If true, keep retrying until ready.
- *  <wait>	If true, wait until function has completed on other CPUs.
- *  [RETURNS]   0 on success, else a negative status code.
- *
- * Does not return until remote CPUs are nearly ready to execute <func>
- * or are or have executed.
- * You must not call this function with disabled interrupts or from a
- * hardware interrupt handler or from a bottom half handler.
- */
-
-int
-smp_call_function_on_cpu (void (*func) (void *info), void *info, int retry,
-			  int wait, cpumask_t to_whom)
+void arch_send_call_function_ipi(cpumask_t mask)
 {
-	struct smp_call_struct data;
-	unsigned long timeout;
-	int num_cpus_to_call;
-	
-	/* Can deadlock when called with interrupts disabled */
-	WARN_ON(irqs_disabled());
-
-	data.func = func;
-	data.info = info;
-	data.wait = wait;
-
-	cpu_clear(smp_processor_id(), to_whom);
-	num_cpus_to_call = cpus_weight(to_whom);
-
-	atomic_set(&data.unstarted_count, num_cpus_to_call);
-	atomic_set(&data.unfinished_count, num_cpus_to_call);
-
-	/* Acquire the smp_call_function_data mutex.  */
-	if (pointer_lock(&smp_call_function_data, &data, retry))
-		return -EBUSY;
-
-	/* Send a message to the requested CPUs.  */
-	send_ipi_message(to_whom, IPI_CALL_FUNC);
-
-	/* Wait for a minimal response.  */
-	timeout = jiffies + HZ;
-	while (atomic_read (&data.unstarted_count) > 0
-	       && time_before (jiffies, timeout))
-		barrier();
-
-	/* If there's no response yet, log a message but allow a longer
-	 * timeout period -- if we get a response this time, log
-	 * a message saying when we got it.. 
-	 */
-	if (atomic_read(&data.unstarted_count) > 0) {
-		long start_time = jiffies;
-		printk(KERN_ERR "%s: initial timeout -- trying long wait\n",
-		       __func__);
-		timeout = jiffies + 30 * HZ;
-		while (atomic_read(&data.unstarted_count) > 0
-		       && time_before(jiffies, timeout))
-			barrier();
-		if (atomic_read(&data.unstarted_count) <= 0) {
-			long delta = jiffies - start_time;
-			printk(KERN_ERR 
-			       "%s: response %ld.%ld seconds into long wait\n",
-			       __func__, delta / HZ,
-			       (100 * (delta - ((delta / HZ) * HZ))) / HZ);
-		}
-	}
-
-	/* We either got one or timed out -- clear the lock. */
-	mb();
-	smp_call_function_data = NULL;
-
-	/* 
-	 * If after both the initial and long timeout periods we still don't
-	 * have a response, something is very wrong...
-	 */
-	BUG_ON(atomic_read (&data.unstarted_count) > 0);
-
-	/* Wait for a complete response, if needed.  */
-	if (wait) {
-		while (atomic_read (&data.unfinished_count) > 0)
-			barrier();
-	}
-
-	return 0;
+	send_ipi_message(mask, IPI_CALL_FUNC);
 }
-EXPORT_SYMBOL(smp_call_function_on_cpu);
 
-int
-smp_call_function (void (*func) (void *info), void *info, int retry, int wait)
+void arch_send_call_function_single_ipi(int cpu)
 {
-	return smp_call_function_on_cpu (func, info, retry, wait,
-					 cpu_online_map);
+	send_ipi_message(cpumask_of_cpu(cpu), IPI_CALL_FUNC_SINGLE);
 }
-EXPORT_SYMBOL(smp_call_function);
 
 static void
 ipi_imb(void *ignored)

commit bbb8d343affd21850849fa4d41bf91c7527a3d04
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Mon Apr 28 02:13:46 2008 -0700

    alpha: remove remaining __FUNCTION__ occurrences
    
    __FUNCTION__ is gcc-specific, use __func__
    
    The change in pci-iommu,c should be safe as arena has not been assigned
    when we get to this point.
    
    Some were within #if 0 blocks, have changed them and left the blocks
    as they appear to be debugging infrastructure.
    
    A #define FN __FUNCTION__ was removed and occurances of FN were replaced
    with __func__ as well.
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Richard Henderson <rth@twiddle.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 63c2073401ee..2525692db0ab 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -755,7 +755,7 @@ smp_call_function_on_cpu (void (*func) (void *info), void *info, int retry,
 	if (atomic_read(&data.unstarted_count) > 0) {
 		long start_time = jiffies;
 		printk(KERN_ERR "%s: initial timeout -- trying long wait\n",
-		       __FUNCTION__);
+		       __func__);
 		timeout = jiffies + 30 * HZ;
 		while (atomic_read(&data.unstarted_count) > 0
 		       && time_before(jiffies, timeout))
@@ -764,7 +764,7 @@ smp_call_function_on_cpu (void (*func) (void *info), void *info, int retry,
 			long delta = jiffies - start_time;
 			printk(KERN_ERR 
 			       "%s: response %ld.%ld seconds into long wait\n",
-			       __FUNCTION__, delta / HZ,
+			       __func__, delta / HZ,
 			       (100 * (delta - ((delta / HZ) * HZ))) / HZ);
 		}
 	}

commit 6c81c32f9616fd6f2795dceae2f70943cb4d8609
Author: Adrian Bunk <bunk@kernel.org>
Date:   Wed Feb 6 01:37:51 2008 -0800

    calibrate_delay() must be __cpuinit
    
    calibrate_delay() must be __cpuinit, not __{dev,}init.
    
    I've verified that this is correct for all users.
    
    While doing the latter, I also did the following cleanups:
    - remove pointless additional prototypes in C files
    - ensure all users #include <linux/delay.h>
    
    This fixes the following section mismatches with CONFIG_HOTPLUG=n,
    CONFIG_HOTPLUG_CPU=y:
    
    WARNING: vmlinux.o(.text+0x1128d): Section mismatch: reference to .init.text.1:calibrate_delay (between 'check_cx686_slop' and 'set_cx86_reorder')
    WARNING: vmlinux.o(.text+0x25102): Section mismatch: reference to .init.text.1:calibrate_delay (between 'smp_callin' and 'cpu_coregroup_map')
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Christian Zankel <chris@zankel.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index f4ab233201b2..63c2073401ee 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -77,10 +77,6 @@ int smp_num_probed;		/* Internal processor count */
 int smp_num_cpus = 1;		/* Number that came online.  */
 EXPORT_SYMBOL(smp_num_cpus);
 
-extern void calibrate_delay(void);
-
-
-
 /*
  * Called by both boot and secondaries to move global data into
  *  per-processor storage.

commit c3a2ddee16e67c86f3b469ccdd396cda034756a9
Author: Simon Arlott <simon@fire.lp0.eu>
Date:   Sat Oct 20 01:04:37 2007 +0200

    spelling fixes: arch/alpha/
    
    Spelling fixes in arch/alpha/.
    
    Signed-off-by: Simon Arlott <simon@fire.lp0.eu>
    Signed-off-by: Adrian Bunk <bunk@kernel.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index ad176441be55..f4ab233201b2 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -439,7 +439,6 @@ setup_smp(void)
 				((char *)cpubase + i*hwrpb->processor_size);
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
-				/* Assume here that "whami" == index */
 				cpu_set(i, cpu_present_map);
 				cpu->pal_revision = boot_cpu_palrev;
 			}

commit 4e950f6f0189f65f8bf069cf2272649ef418f5e4
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Jul 30 02:36:13 2007 +0400

    Remove fs.h from mm.h
    
    Remove fs.h from mm.h. For this,
     1) Uninline vma_wants_writenotify(). It's pretty huge anyway.
     2) Add back fs.h or less bloated headers (err.h) to files that need it.
    
    As result, on x86_64 allyesconfig, fs.h dependencies cut down from 3929 files
    rebuilt down to 3444 (-12.3%).
    
    Cross-compile tested without regressions on my two usual configs and (sigh):
    
    alpha              arm-mx1ads        mips-bigsur          powerpc-ebony
    alpha-allnoconfig  arm-neponset      mips-capcella        powerpc-g5
    alpha-defconfig    arm-netwinder     mips-cobalt          powerpc-holly
    alpha-up           arm-netx          mips-db1000          powerpc-iseries
    arm                arm-ns9xxx        mips-db1100          powerpc-linkstation
    arm-assabet        arm-omap_h2_1610  mips-db1200          powerpc-lite5200
    arm-at91rm9200dk   arm-onearm        mips-db1500          powerpc-maple
    arm-at91rm9200ek   arm-picotux200    mips-db1550          powerpc-mpc7448_hpc2
    arm-at91sam9260ek  arm-pleb          mips-ddb5477         powerpc-mpc8272_ads
    arm-at91sam9261ek  arm-pnx4008       mips-decstation      powerpc-mpc8313_rdb
    arm-at91sam9263ek  arm-pxa255-idp    mips-e55             powerpc-mpc832x_mds
    arm-at91sam9rlek   arm-realview      mips-emma2rh         powerpc-mpc832x_rdb
    arm-ateb9200       arm-realview-smp  mips-excite          powerpc-mpc834x_itx
    arm-badge4         arm-rpc           mips-fulong          powerpc-mpc834x_itxgp
    arm-carmeva        arm-s3c2410       mips-ip22            powerpc-mpc834x_mds
    arm-cerfcube       arm-shannon       mips-ip27            powerpc-mpc836x_mds
    arm-clps7500       arm-shark         mips-ip32            powerpc-mpc8540_ads
    arm-collie         arm-simpad        mips-jazz            powerpc-mpc8544_ds
    arm-corgi          arm-spitz         mips-jmr3927         powerpc-mpc8560_ads
    arm-csb337         arm-trizeps4      mips-malta           powerpc-mpc8568mds
    arm-csb637         arm-versatile     mips-mipssim         powerpc-mpc85xx_cds
    arm-ebsa110        i386              mips-mpc30x          powerpc-mpc8641_hpcn
    arm-edb7211        i386-allnoconfig  mips-msp71xx         powerpc-mpc866_ads
    arm-em_x270        i386-defconfig    mips-ocelot          powerpc-mpc885_ads
    arm-ep93xx         i386-up           mips-pb1100          powerpc-pasemi
    arm-footbridge     ia64              mips-pb1500          powerpc-pmac32
    arm-fortunet       ia64-allnoconfig  mips-pb1550          powerpc-ppc64
    arm-h3600          ia64-bigsur       mips-pnx8550-jbs     powerpc-prpmc2800
    arm-h7201          ia64-defconfig    mips-pnx8550-stb810  powerpc-ps3
    arm-h7202          ia64-gensparse    mips-qemu            powerpc-pseries
    arm-hackkit        ia64-sim          mips-rbhma4200       powerpc-up
    arm-integrator     ia64-sn2          mips-rbhma4500       s390
    arm-iop13xx        ia64-tiger        mips-rm200           s390-allnoconfig
    arm-iop32x         ia64-up           mips-sb1250-swarm    s390-defconfig
    arm-iop33x         ia64-zx1          mips-sead            s390-up
    arm-ixp2000        m68k              mips-tb0219          sparc
    arm-ixp23xx        m68k-amiga        mips-tb0226          sparc-allnoconfig
    arm-ixp4xx         m68k-apollo       mips-tb0287          sparc-defconfig
    arm-jornada720     m68k-atari        mips-workpad         sparc-up
    arm-kafa           m68k-bvme6000     mips-wrppmc          sparc64
    arm-kb9202         m68k-hp300        mips-yosemite        sparc64-allnoconfig
    arm-ks8695         m68k-mac          parisc               sparc64-defconfig
    arm-lart           m68k-mvme147      parisc-allnoconfig   sparc64-up
    arm-lpd270         m68k-mvme16x      parisc-defconfig     um-x86_64
    arm-lpd7a400       m68k-q40          parisc-up            x86_64
    arm-lpd7a404       m68k-sun3         powerpc              x86_64-allnoconfig
    arm-lubbock        m68k-sun3x        powerpc-cell         x86_64-defconfig
    arm-lusl7200       mips              powerpc-celleb       x86_64-up
    arm-mainstone      mips-atlas        powerpc-chrp32
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 0804b6abe203..ad176441be55 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -16,6 +16,7 @@
 #include <linux/module.h>
 #include <linux/sched.h>
 #include <linux/mm.h>
+#include <linux/err.h>
 #include <linux/threads.h>
 #include <linux/smp.h>
 #include <linux/interrupt.h>

commit ed5f6561436a1a0b38f4130bdb1fed00f14e60b5
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jul 26 17:34:19 2007 +0100

    deal with alpha section warnings
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index b28731437c31..0804b6abe203 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -358,7 +358,7 @@ secondary_cpu_start(int cpuid, struct task_struct *idle)
 /*
  * Bring one cpu online.
  */
-static int __devinit
+static int __cpuinit
 smp_boot_one_cpu(int cpuid)
 {
 	struct task_struct *idle;
@@ -487,7 +487,7 @@ smp_prepare_boot_cpu(void)
 {
 }
 
-int __devinit
+int __cpuinit
 __cpu_up(unsigned int cpu)
 {
 	smp_boot_one_cpu(cpu);
@@ -541,7 +541,7 @@ smp_percpu_timer_interrupt(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
-int __init
+int
 setup_profiling_timer(unsigned int multiplier)
 {
 	return -EINVAL;

commit cc040a8a0e8ba95fbb0ae1edcb9ec83623b422e3
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Tue Jul 17 08:49:35 2007 +0100

    alpha __init fixes
    
    __init and __initdata stuff used from __devinit one
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 80cfb758ee2b..b28731437c31 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -65,7 +65,7 @@ enum ipi_message_type {
 };
 
 /* Set to a secondary's cpuid when it comes online.  */
-static int smp_secondary_alive __initdata = 0;
+static int smp_secondary_alive __devinitdata = 0;
 
 /* Which cpus ids came online.  */
 cpumask_t cpu_online_map;
@@ -173,7 +173,7 @@ smp_callin(void)
 }
 
 /* Wait until hwrpb->txrdy is clear for cpu.  Return -1 on timeout.  */
-static int __init
+static int __devinit
 wait_for_txrdy (unsigned long cpumask)
 {
 	unsigned long timeout;
@@ -358,7 +358,7 @@ secondary_cpu_start(int cpuid, struct task_struct *idle)
 /*
  * Bring one cpu online.
  */
-static int __init
+static int __devinit
 smp_boot_one_cpu(int cpuid)
 {
 	struct task_struct *idle;

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index d1ec4f51df1a..80cfb758ee2b 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -18,7 +18,6 @@
 #include <linux/mm.h>
 #include <linux/threads.h>
 #include <linux/smp.h>
-#include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
 #include <linux/delay.h>

commit cff52daffa080eff6353f44df418b080dacefb96
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Wed Oct 11 17:40:22 2006 +0100

    [PATCH] alpha_ksyms.c cleanup
    
    taken exports to actual definitions of symbols being exported.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 596780e2c7da..d1ec4f51df1a 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -52,6 +52,7 @@
 
 /* A collection of per-processor data.  */
 struct cpuinfo_alpha cpu_data[NR_CPUS];
+EXPORT_SYMBOL(cpu_data);
 
 /* A collection of single bit ipi messages.  */
 static struct {
@@ -74,6 +75,7 @@ EXPORT_SYMBOL(cpu_online_map);
 
 int smp_num_probed;		/* Internal processor count */
 int smp_num_cpus = 1;		/* Number that came online.  */
+EXPORT_SYMBOL(smp_num_cpus);
 
 extern void calibrate_delay(void);
 
@@ -790,6 +792,7 @@ smp_call_function_on_cpu (void (*func) (void *info), void *info, int retry,
 
 	return 0;
 }
+EXPORT_SYMBOL(smp_call_function_on_cpu);
 
 int
 smp_call_function (void (*func) (void *info), void *info, int retry, int wait)
@@ -797,6 +800,7 @@ smp_call_function (void (*func) (void *info), void *info, int retry, int wait)
 	return smp_call_function_on_cpu (func, info, retry, wait,
 					 cpu_online_map);
 }
+EXPORT_SYMBOL(smp_call_function);
 
 static void
 ipi_imb(void *ignored)
@@ -811,6 +815,7 @@ smp_imb(void)
 	if (on_each_cpu(ipi_imb, NULL, 1, 1))
 		printk(KERN_CRIT "smp_imb: timed out\n");
 }
+EXPORT_SYMBOL(smp_imb);
 
 static void
 ipi_flush_tlb_all(void *ignored)
@@ -866,6 +871,7 @@ flush_tlb_mm(struct mm_struct *mm)
 
 	preempt_enable();
 }
+EXPORT_SYMBOL(flush_tlb_mm);
 
 struct flush_tlb_page_struct {
 	struct vm_area_struct *vma;
@@ -918,6 +924,7 @@ flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)
 
 	preempt_enable();
 }
+EXPORT_SYMBOL(flush_tlb_page);
 
 void
 flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
@@ -925,6 +932,7 @@ flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long e
 	/* On the Alpha we always flush the whole user tlb.  */
 	flush_tlb_mm(vma->vm_mm);
 }
+EXPORT_SYMBOL(flush_tlb_range);
 
 static void
 ipi_flush_icache_page(void *x)

commit 8774cb815f2492a95b90a927f93a2de555753b32
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Sat Oct 7 14:17:31 2006 +0100

    [PATCH] minimal alpha pt_regs fixes
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Acked-by: Jeff Garzik <jeff@garzik.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 4dc273e537fd..596780e2c7da 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -515,12 +515,15 @@ smp_cpus_done(unsigned int max_cpus)
 void
 smp_percpu_timer_interrupt(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs;
 	int cpu = smp_processor_id();
 	unsigned long user = user_mode(regs);
 	struct cpuinfo_alpha *data = &cpu_data[cpu];
 
+	old_regs = set_irq_regs(regs);
+
 	/* Record kernel PC.  */
-	profile_tick(CPU_PROFILING, regs);
+	profile_tick(CPU_PROFILING);
 
 	if (!--data->prof_counter) {
 		/* We need to make like a normal interrupt -- otherwise
@@ -534,6 +537,7 @@ smp_percpu_timer_interrupt(struct pt_regs *regs)
 
 		irq_exit();
 	}
+	set_irq_regs(old_regs);
 }
 
 int __init

commit c7d2d28b9851d0ffc9924b0e36bac806d18ebf25
Author: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
Date:   Sun Jun 4 02:51:34 2006 -0700

    [PATCH] alpha: SMP IRQ routing fix
    
    From: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    
    After removal of fixup_cpu_present_map() function Alpha ended up with an empty
    cpu_present_map, so secondary CPUs on SMP systems are not being started.
    
    Worse, on some platforms we route interrupts to secondary CPUs using
    cpu_possible_map which is still populated properly.  As a result, these
    interrupts go nowhere so the machines like DP264 aren't able to boot even with
    a primary CPU.
    
    Fixed basically by s/cpu_present_mask/cpu_present_map/.
    
    Thanks to Ernst Herzberg for reporting the bug and testing the fix.
    
    Cc: Ernst Herzberg <list-lkml@net4u.de>
    Cc: Richard Henderson <rth@twiddle.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 185255416e85..4dc273e537fd 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -68,7 +68,6 @@ enum ipi_message_type {
 static int smp_secondary_alive __initdata = 0;
 
 /* Which cpus ids came online.  */
-cpumask_t cpu_present_mask;
 cpumask_t cpu_online_map;
 
 EXPORT_SYMBOL(cpu_online_map);
@@ -439,7 +438,7 @@ setup_smp(void)
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
 				/* Assume here that "whami" == index */
-				cpu_set(i, cpu_present_mask);
+				cpu_set(i, cpu_present_map);
 				cpu->pal_revision = boot_cpu_palrev;
 			}
 
@@ -450,11 +449,10 @@ setup_smp(void)
 		}
 	} else {
 		smp_num_probed = 1;
-		cpu_set(boot_cpuid, cpu_present_mask);
 	}
 
-	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_mask = %lx\n",
-	       smp_num_probed, cpu_possible_map.bits[0]);
+	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_map = %lx\n",
+	       smp_num_probed, cpu_present_map.bits[0]);
 }
 
 /*
@@ -473,7 +471,7 @@ smp_prepare_cpus(unsigned int max_cpus)
 
 	/* Nothing to do on a UP box, or when told not to.  */
 	if (smp_num_probed == 1 || max_cpus == 0) {
-		cpu_present_mask = cpumask_of_cpu(boot_cpuid);
+		cpu_present_map = cpumask_of_cpu(boot_cpuid);
 		printk(KERN_INFO "SMP mode deactivated.\n");
 		return;
 	}
@@ -486,10 +484,6 @@ smp_prepare_cpus(unsigned int max_cpus)
 void __devinit
 smp_prepare_boot_cpu(void)
 {
-	/*
-	 * Mark the boot cpu (current cpu) as online
-	 */ 
-	cpu_set(smp_processor_id(), cpu_online_map);
 }
 
 int __devinit

commit 917b1f78a9871a1985004df09ed1eb2e0dc3bf4f
Author: Brian Uhrain says <buhrain@rosettastone.com>
Date:   Mon Apr 10 22:53:16 2006 -0700

    [PATCH] alpha: SMP boot fixes
    
    I've encountered two problems with 2.6.16 and newer kernels on my API CS20
    (dual 833MHz Alpha 21264b processors).  The first is the kernel OOPSing
    because of a NULL pointer dereference while trying to populate SysFS with the
    CPU information.  The other is that only one processor was being brought up.
    I've included a small Alpha-specific patch that fixes both problems.
    
    The first problem was caused by the CPUs never being properly registered using
    register_cpu(), the way it's done on other architectures.
    
    The second problem has to do with the removal of hwrpb_cpu_present_mask in
    arch/alpha/kernel/smp.c.  In setup_smp() in the 2.6.15 kernel sources,
    hwrpb_cpu_present_mask has a bit set for each processor that is probed, and
    afterwards cpu_present_mask is set to the cpumask for the boot CPU.  In the
    same function of the same file in the 2.6.16 sources, instead of
    hwrpb_cpu_present_mask being set, cpu_possible_map is updated for each probed
    CPU.  cpu_present_mask is still set to the cpumask of the boot CPU afterwards.
     The problem lies in include/asm-alpha/smp.h, where cpu_possible_map is
    #define'd to be cpu_present_mask.
    
    Cleanups from: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    
     - cpu_present_mask and cpu_possible_map are essentially the same thing
       on alpha, as it doesn't support CPU hotplug;
     - allocate "struct cpu" only for present CPUs, like sparc64 does.
       Static array of "struct cpu" is just a waste of memory.
    
    Signed-off-by: Brian Uhrain <buhrain@rosettastone.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 02c2db08114a..185255416e85 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -439,7 +439,7 @@ setup_smp(void)
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
 				/* Assume here that "whami" == index */
-				cpu_set(i, cpu_possible_map);
+				cpu_set(i, cpu_present_mask);
 				cpu->pal_revision = boot_cpu_palrev;
 			}
 
@@ -450,9 +450,8 @@ setup_smp(void)
 		}
 	} else {
 		smp_num_probed = 1;
-		cpu_set(boot_cpuid, cpu_possible_map);
+		cpu_set(boot_cpuid, cpu_present_mask);
 	}
-	cpu_present_mask = cpumask_of_cpu(boot_cpuid);
 
 	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_mask = %lx\n",
 	       smp_num_probed, cpu_possible_map.bits[0]);
@@ -488,9 +487,8 @@ void __devinit
 smp_prepare_boot_cpu(void)
 {
 	/*
-	 * Mark the boot cpu (current cpu) as both present and online
+	 * Mark the boot cpu (current cpu) as online
 	 */ 
-	cpu_set(smp_processor_id(), cpu_present_mask);
 	cpu_set(smp_processor_id(), cpu_online_map);
 }
 

commit 328c2a8a39e1ba43a6e54e43fc752f7035779561
Author: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
Date:   Wed Feb 8 11:55:06 2006 +0300

    [PATCH] alpha: set cpu_possible_map much earlier
    
    All the percpu data structure walkers want cpu_possible_map to be
    initialized early, but alpha instead populated "hwrpb_cpu_present_mask"
    early in setup_smp(), and then initialized cpu_possible_map only much
    later.
    
    Thanks go to Heiko Carstens and Dipankar Sarma for noticing.
    
    This fixes it and we can get rid of hwrpb_cpu_present_mask entirely.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 4b873527ce1c..02c2db08114a 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -73,9 +73,6 @@ cpumask_t cpu_online_map;
 
 EXPORT_SYMBOL(cpu_online_map);
 
-/* cpus reported in the hwrpb */
-static unsigned long hwrpb_cpu_present_mask __initdata = 0;
-
 int smp_num_probed;		/* Internal processor count */
 int smp_num_cpus = 1;		/* Number that came online.  */
 
@@ -442,7 +439,7 @@ setup_smp(void)
 			if ((cpu->flags & 0x1cc) == 0x1cc) {
 				smp_num_probed++;
 				/* Assume here that "whami" == index */
-				hwrpb_cpu_present_mask |= (1UL << i);
+				cpu_set(i, cpu_possible_map);
 				cpu->pal_revision = boot_cpu_palrev;
 			}
 
@@ -453,12 +450,12 @@ setup_smp(void)
 		}
 	} else {
 		smp_num_probed = 1;
-		hwrpb_cpu_present_mask = (1UL << boot_cpuid);
+		cpu_set(boot_cpuid, cpu_possible_map);
 	}
 	cpu_present_mask = cpumask_of_cpu(boot_cpuid);
 
 	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_mask = %lx\n",
-	       smp_num_probed, hwrpb_cpu_present_mask);
+	       smp_num_probed, cpu_possible_map.bits[0]);
 }
 
 /*
@@ -467,8 +464,6 @@ setup_smp(void)
 void __init
 smp_prepare_cpus(unsigned int max_cpus)
 {
-	int cpu_count, i;
-
 	/* Take care of some initial bookkeeping.  */
 	memset(ipi_data, 0, sizeof(ipi_data));
 
@@ -486,19 +481,7 @@ smp_prepare_cpus(unsigned int max_cpus)
 
 	printk(KERN_INFO "SMP starting up secondaries.\n");
 
-	cpu_count = 1;
-	for (i = 0; (i < NR_CPUS) && (cpu_count < max_cpus); i++) {
-		if (i == boot_cpuid)
-			continue;
-
-		if (((hwrpb_cpu_present_mask >> i) & 1) == 0)
-			continue;
-
-		cpu_set(i, cpu_possible_map);
-		cpu_count++;
-	}
-
-	smp_num_cpus = cpu_count;
+	smp_num_cpus = smp_num_probed;
 }
 
 void __devinit

commit 37bfbaf995d2c1f8196ee04c9d6f68258d5ec3e8
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jan 12 01:05:36 2006 -0800

    [PATCH] alpha: task_thread_info()
    
    use task_thread_info() for accesses to thread_info of task in arch/alpha
    and include/asm-alpha
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index da0be3465791..4b873527ce1c 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -302,7 +302,7 @@ secondary_cpu_start(int cpuid, struct task_struct *idle)
 		 + hwrpb->processor_offset
 		 + cpuid * hwrpb->processor_size);
 	hwpcb = (struct pcb_struct *) cpu->hwpcb;
-	ipcb = &idle->thread_info->pcb;
+	ipcb = &task_thread_info(idle)->pcb;
 
 	/* Initialize the CPU's HWPCB to something just good enough for
 	   us to get started.  Immediately after starting, we'll swpctx

commit fb1c8f93d869b34cacb8b8932e2b83d96a19d720
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Sep 10 00:25:56 2005 -0700

    [PATCH] spinlock consolidation
    
    This patch (written by me and also containing many suggestions of Arjan van
    de Ven) does a major cleanup of the spinlock code.  It does the following
    things:
    
     - consolidates and enhances the spinlock/rwlock debugging code
    
     - simplifies the asm/spinlock.h files
    
     - encapsulates the raw spinlock type and moves generic spinlock
       features (such as ->break_lock) into the generic code.
    
     - cleans up the spinlock code hierarchy to get rid of the spaghetti.
    
    Most notably there's now only a single variant of the debugging code,
    located in lib/spinlock_debug.c.  (previously we had one SMP debugging
    variant per architecture, plus a separate generic one for UP builds)
    
    Also, i've enhanced the rwlock debugging facility, it will now track
    write-owners.  There is new spinlock-owner/CPU-tracking on SMP builds too.
    All locks have lockup detection now, which will work for both soft and hard
    spin/rwlock lockups.
    
    The arch-level include files now only contain the minimally necessary
    subset of the spinlock code - all the rest that can be generalized now
    lives in the generic headers:
    
     include/asm-i386/spinlock_types.h       |   16
     include/asm-x86_64/spinlock_types.h     |   16
    
    I have also split up the various spinlock variants into separate files,
    making it easier to see which does what. The new layout is:
    
       SMP                         |  UP
       ----------------------------|-----------------------------------
       asm/spinlock_types_smp.h    |  linux/spinlock_types_up.h
       linux/spinlock_types.h      |  linux/spinlock_types.h
       asm/spinlock_smp.h          |  linux/spinlock_up.h
       linux/spinlock_api_smp.h    |  linux/spinlock_api_up.h
       linux/spinlock.h            |  linux/spinlock.h
    
    /*
     * here's the role of the various spinlock/rwlock related include files:
     *
     * on SMP builds:
     *
     *  asm/spinlock_types.h: contains the raw_spinlock_t/raw_rwlock_t and the
     *                        initializers
     *
     *  linux/spinlock_types.h:
     *                        defines the generic type and initializers
     *
     *  asm/spinlock.h:       contains the __raw_spin_*()/etc. lowlevel
     *                        implementations, mostly inline assembly code
     *
     *   (also included on UP-debug builds:)
     *
     *  linux/spinlock_api_smp.h:
     *                        contains the prototypes for the _spin_*() APIs.
     *
     *  linux/spinlock.h:     builds the final spin_*() APIs.
     *
     * on UP builds:
     *
     *  linux/spinlock_type_up.h:
     *                        contains the generic, simplified UP spinlock type.
     *                        (which is an empty structure on non-debug builds)
     *
     *  linux/spinlock_types.h:
     *                        defines the generic type and initializers
     *
     *  linux/spinlock_up.h:
     *                        contains the __raw_spin_*()/etc. version of UP
     *                        builds. (which are NOPs on non-debug, non-preempt
     *                        builds)
     *
     *   (included on UP-non-debug builds:)
     *
     *  linux/spinlock_api_up.h:
     *                        builds the _spin_*() APIs.
     *
     *  linux/spinlock.h:     builds the final spin_*() APIs.
     */
    
    All SMP and UP architectures are converted by this patch.
    
    arm, i386, ia64, ppc, ppc64, s390/s390x, x64 was build-tested via
    crosscompilers.  m32r, mips, sh, sparc, have not been tested yet, but should
    be mostly fine.
    
    From: Grant Grundler <grundler@parisc-linux.org>
    
      Booted and lightly tested on a500-44 (64-bit, SMP kernel, dual CPU).
      Builds 32-bit SMP kernel (not booted or tested).  I did not try to build
      non-SMP kernels.  That should be trivial to fix up later if necessary.
    
      I converted bit ops atomic_hash lock to raw_spinlock_t.  Doing so avoids
      some ugly nesting of linux/*.h and asm/*.h files.  Those particular locks
      are well tested and contained entirely inside arch specific code.  I do NOT
      expect any new issues to arise with them.
    
     If someone does ever need to use debug/metrics with them, then they will
      need to unravel this hairball between spinlocks, atomic ops, and bit ops
      that exist only because parisc has exactly one atomic instruction: LDCW
      (load and clear word).
    
    From: "Luck, Tony" <tony.luck@intel.com>
    
       ia64 fix
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjanv@infradead.org>
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Cc: Matthew Wilcox <willy@debian.org>
    Signed-off-by: Hirokazu Takata <takata@linux-m32r.org>
    Signed-off-by: Mikael Pettersson <mikpe@csd.uu.se>
    Signed-off-by: Benoit Boissinot <benoit.boissinot@ens-lyon.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index e211aa7404e6..da0be3465791 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -989,175 +989,3 @@ flush_icache_user_range(struct vm_area_struct *vma, struct page *page,
 
 	preempt_enable();
 }
-
-#ifdef CONFIG_DEBUG_SPINLOCK
-void
-_raw_spin_unlock(spinlock_t * lock)
-{
-	mb();
-	lock->lock = 0;
-
-	lock->on_cpu = -1;
-	lock->previous = NULL;
-	lock->task = NULL;
-	lock->base_file = "none";
-	lock->line_no = 0;
-}
-
-void
-debug_spin_lock(spinlock_t * lock, const char *base_file, int line_no)
-{
-	long tmp;
-	long stuck;
-	void *inline_pc = __builtin_return_address(0);
-	unsigned long started = jiffies;
-	int printed = 0;
-	int cpu = smp_processor_id();
-
-	stuck = 1L << 30;
- try_again:
-
-	/* Use sub-sections to put the actual loop at the end
-	   of this object file's text section so as to perfect
-	   branch prediction.  */
-	__asm__ __volatile__(
-	"1:	ldl_l	%0,%1\n"
-	"	subq	%2,1,%2\n"
-	"	blbs	%0,2f\n"
-	"	or	%0,1,%0\n"
-	"	stl_c	%0,%1\n"
-	"	beq	%0,3f\n"
-	"4:	mb\n"
-	".subsection 2\n"
-	"2:	ldl	%0,%1\n"
-	"	subq	%2,1,%2\n"
-	"3:	blt	%2,4b\n"
-	"	blbs	%0,2b\n"
-	"	br	1b\n"
-	".previous"
-	: "=r" (tmp), "=m" (lock->lock), "=r" (stuck)
-	: "m" (lock->lock), "2" (stuck) : "memory");
-
-	if (stuck < 0) {
-		printk(KERN_WARNING
-		       "%s:%d spinlock stuck in %s at %p(%d)"
-		       " owner %s at %p(%d) %s:%d\n",
-		       base_file, line_no,
-		       current->comm, inline_pc, cpu,
-		       lock->task->comm, lock->previous,
-		       lock->on_cpu, lock->base_file, lock->line_no);
-		stuck = 1L << 36;
-		printed = 1;
-		goto try_again;
-	}
-
-	/* Exiting.  Got the lock.  */
-	lock->on_cpu = cpu;
-	lock->previous = inline_pc;
-	lock->task = current;
-	lock->base_file = base_file;
-	lock->line_no = line_no;
-
-	if (printed) {
-		printk(KERN_WARNING
-		       "%s:%d spinlock grabbed in %s at %p(%d) %ld ticks\n",
-		       base_file, line_no, current->comm, inline_pc,
-		       cpu, jiffies - started);
-	}
-}
-
-int
-debug_spin_trylock(spinlock_t * lock, const char *base_file, int line_no)
-{
-	int ret;
-	if ((ret = !test_and_set_bit(0, lock))) {
-		lock->on_cpu = smp_processor_id();
-		lock->previous = __builtin_return_address(0);
-		lock->task = current;
-	} else {
-		lock->base_file = base_file;
-		lock->line_no = line_no;
-	}
-	return ret;
-}
-#endif /* CONFIG_DEBUG_SPINLOCK */
-
-#ifdef CONFIG_DEBUG_RWLOCK
-void _raw_write_lock(rwlock_t * lock)
-{
-	long regx, regy;
-	int stuck_lock, stuck_reader;
-	void *inline_pc = __builtin_return_address(0);
-
- try_again:
-
-	stuck_lock = 1<<30;
-	stuck_reader = 1<<30;
-
-	__asm__ __volatile__(
-	"1:	ldl_l	%1,%0\n"
-	"	blbs	%1,6f\n"
-	"	blt	%1,8f\n"
-	"	mov	1,%1\n"
-	"	stl_c	%1,%0\n"
-	"	beq	%1,6f\n"
-	"4:	mb\n"
-	".subsection 2\n"
-	"6:	blt	%3,4b	# debug\n"
-	"	subl	%3,1,%3	# debug\n"
-	"	ldl	%1,%0\n"
-	"	blbs	%1,6b\n"
-	"8:	blt	%4,4b	# debug\n"
-	"	subl	%4,1,%4	# debug\n"
-	"	ldl	%1,%0\n"
-	"	blt	%1,8b\n"
-	"	br	1b\n"
-	".previous"
-	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (regy),
-	  "=&r" (stuck_lock), "=&r" (stuck_reader)
-	: "m" (*(volatile int *)lock), "3" (stuck_lock), "4" (stuck_reader) : "memory");
-
-	if (stuck_lock < 0) {
-		printk(KERN_WARNING "write_lock stuck at %p\n", inline_pc);
-		goto try_again;
-	}
-	if (stuck_reader < 0) {
-		printk(KERN_WARNING "write_lock stuck on readers at %p\n",
-		       inline_pc);
-		goto try_again;
-	}
-}
-
-void _raw_read_lock(rwlock_t * lock)
-{
-	long regx;
-	int stuck_lock;
-	void *inline_pc = __builtin_return_address(0);
-
- try_again:
-
-	stuck_lock = 1<<30;
-
-	__asm__ __volatile__(
-	"1:	ldl_l	%1,%0;"
-	"	blbs	%1,6f;"
-	"	subl	%1,2,%1;"
-	"	stl_c	%1,%0;"
-	"	beq	%1,6f;"
-	"4:	mb\n"
-	".subsection 2\n"
-	"6:	ldl	%1,%0;"
-	"	blt	%2,4b	# debug\n"
-	"	subl	%2,1,%2	# debug\n"
-	"	blbs	%1,6b;"
-	"	br	1b\n"
-	".previous"
-	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (stuck_lock)
-	: "m" (*(volatile int *)lock), "2" (stuck_lock) : "memory");
-
-	if (stuck_lock < 0) {
-		printk(KERN_WARNING "read_lock stuck at %p\n", inline_pc);
-		goto try_again;
-	}
-}
-#endif /* CONFIG_DEBUG_RWLOCK */

commit 719e5985cf79bb60f4a28816547efd27dde178f5
Author: Al Viro <viro@www.linux.org.uk>
Date:   Tue Aug 23 22:47:12 2005 +0100

    [PATCH] alpha spinlock code and bogus constraints
    
    "=m" (lock->lock) / "1" (lock->lock) makes gcc4 unhappy; fixed by s/1/m/,
    same as in case of i386 rwsem.h where such variant had been accepted
    by both Linus and rth.
    
    Signed-off-by: Al Viro <viro@parcelfarce.linux.theplanet.co.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
index 8f1e78551b1e..e211aa7404e6 100644
--- a/arch/alpha/kernel/smp.c
+++ b/arch/alpha/kernel/smp.c
@@ -1036,7 +1036,7 @@ debug_spin_lock(spinlock_t * lock, const char *base_file, int line_no)
 	"	br	1b\n"
 	".previous"
 	: "=r" (tmp), "=m" (lock->lock), "=r" (stuck)
-	: "1" (lock->lock), "2" (stuck) : "memory");
+	: "m" (lock->lock), "2" (stuck) : "memory");
 
 	if (stuck < 0) {
 		printk(KERN_WARNING
@@ -1115,7 +1115,7 @@ void _raw_write_lock(rwlock_t * lock)
 	".previous"
 	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (regy),
 	  "=&r" (stuck_lock), "=&r" (stuck_reader)
-	: "0" (*(volatile int *)lock), "3" (stuck_lock), "4" (stuck_reader) : "memory");
+	: "m" (*(volatile int *)lock), "3" (stuck_lock), "4" (stuck_reader) : "memory");
 
 	if (stuck_lock < 0) {
 		printk(KERN_WARNING "write_lock stuck at %p\n", inline_pc);
@@ -1153,7 +1153,7 @@ void _raw_read_lock(rwlock_t * lock)
 	"	br	1b\n"
 	".previous"
 	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (stuck_lock)
-	: "0" (*(volatile int *)lock), "2" (stuck_lock) : "memory");
+	: "m" (*(volatile int *)lock), "2" (stuck_lock) : "memory");
 
 	if (stuck_lock < 0) {
 		printk(KERN_WARNING "read_lock stuck at %p\n", inline_pc);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/alpha/kernel/smp.c b/arch/alpha/kernel/smp.c
new file mode 100644
index 000000000000..8f1e78551b1e
--- /dev/null
+++ b/arch/alpha/kernel/smp.c
@@ -0,0 +1,1163 @@
+/*
+ *	linux/arch/alpha/kernel/smp.c
+ *
+ *      2001-07-09 Phil Ezolt (Phillip.Ezolt@compaq.com)
+ *            Renamed modified smp_call_function to smp_call_function_on_cpu()
+ *            Created an function that conforms to the old calling convention
+ *            of smp_call_function().
+ *
+ *            This is helpful for DCPI.
+ *
+ */
+
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/kernel_stat.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/threads.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/interrupt.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/spinlock.h>
+#include <linux/irq.h>
+#include <linux/cache.h>
+#include <linux/profile.h>
+#include <linux/bitops.h>
+
+#include <asm/hwrpb.h>
+#include <asm/ptrace.h>
+#include <asm/atomic.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/pgtable.h>
+#include <asm/pgalloc.h>
+#include <asm/mmu_context.h>
+#include <asm/tlbflush.h>
+
+#include "proto.h"
+#include "irq_impl.h"
+
+
+#define DEBUG_SMP 0
+#if DEBUG_SMP
+#define DBGS(args)	printk args
+#else
+#define DBGS(args)
+#endif
+
+/* A collection of per-processor data.  */
+struct cpuinfo_alpha cpu_data[NR_CPUS];
+
+/* A collection of single bit ipi messages.  */
+static struct {
+	unsigned long bits ____cacheline_aligned;
+} ipi_data[NR_CPUS] __cacheline_aligned;
+
+enum ipi_message_type {
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_CPU_STOP,
+};
+
+/* Set to a secondary's cpuid when it comes online.  */
+static int smp_secondary_alive __initdata = 0;
+
+/* Which cpus ids came online.  */
+cpumask_t cpu_present_mask;
+cpumask_t cpu_online_map;
+
+EXPORT_SYMBOL(cpu_online_map);
+
+/* cpus reported in the hwrpb */
+static unsigned long hwrpb_cpu_present_mask __initdata = 0;
+
+int smp_num_probed;		/* Internal processor count */
+int smp_num_cpus = 1;		/* Number that came online.  */
+
+extern void calibrate_delay(void);
+
+
+
+/*
+ * Called by both boot and secondaries to move global data into
+ *  per-processor storage.
+ */
+static inline void __init
+smp_store_cpu_info(int cpuid)
+{
+	cpu_data[cpuid].loops_per_jiffy = loops_per_jiffy;
+	cpu_data[cpuid].last_asn = ASN_FIRST_VERSION;
+	cpu_data[cpuid].need_new_asn = 0;
+	cpu_data[cpuid].asn_lock = 0;
+}
+
+/*
+ * Ideally sets up per-cpu profiling hooks.  Doesn't do much now...
+ */
+static inline void __init
+smp_setup_percpu_timer(int cpuid)
+{
+	cpu_data[cpuid].prof_counter = 1;
+	cpu_data[cpuid].prof_multiplier = 1;
+}
+
+static void __init
+wait_boot_cpu_to_stop(int cpuid)
+{
+	unsigned long stop = jiffies + 10*HZ;
+
+	while (time_before(jiffies, stop)) {
+	        if (!smp_secondary_alive)
+			return;
+		barrier();
+	}
+
+	printk("wait_boot_cpu_to_stop: FAILED on CPU %d, hanging now\n", cpuid);
+	for (;;)
+		barrier();
+}
+
+/*
+ * Where secondaries begin a life of C.
+ */
+void __init
+smp_callin(void)
+{
+	int cpuid = hard_smp_processor_id();
+
+	if (cpu_test_and_set(cpuid, cpu_online_map)) {
+		printk("??, cpu 0x%x already present??\n", cpuid);
+		BUG();
+	}
+
+	/* Turn on machine checks.  */
+	wrmces(7);
+
+	/* Set trap vectors.  */
+	trap_init();
+
+	/* Set interrupt vector.  */
+	wrent(entInt, 0);
+
+	/* Get our local ticker going. */
+	smp_setup_percpu_timer(cpuid);
+
+	/* Call platform-specific callin, if specified */
+	if (alpha_mv.smp_callin) alpha_mv.smp_callin();
+
+	/* All kernel threads share the same mm context.  */
+	atomic_inc(&init_mm.mm_count);
+	current->active_mm = &init_mm;
+
+	/* Must have completely accurate bogos.  */
+	local_irq_enable();
+
+	/* Wait boot CPU to stop with irq enabled before running
+	   calibrate_delay. */
+	wait_boot_cpu_to_stop(cpuid);
+	mb();
+	calibrate_delay();
+
+	smp_store_cpu_info(cpuid);
+	/* Allow master to continue only after we written loops_per_jiffy.  */
+	wmb();
+	smp_secondary_alive = 1;
+
+	DBGS(("smp_callin: commencing CPU %d current %p active_mm %p\n",
+	      cpuid, current, current->active_mm));
+
+	/* Do nothing.  */
+	cpu_idle();
+}
+
+/* Wait until hwrpb->txrdy is clear for cpu.  Return -1 on timeout.  */
+static int __init
+wait_for_txrdy (unsigned long cpumask)
+{
+	unsigned long timeout;
+
+	if (!(hwrpb->txrdy & cpumask))
+		return 0;
+
+	timeout = jiffies + 10*HZ;
+	while (time_before(jiffies, timeout)) {
+		if (!(hwrpb->txrdy & cpumask))
+			return 0;
+		udelay(10);
+		barrier();
+	}
+
+	return -1;
+}
+
+/*
+ * Send a message to a secondary's console.  "START" is one such
+ * interesting message.  ;-)
+ */
+static void __init
+send_secondary_console_msg(char *str, int cpuid)
+{
+	struct percpu_struct *cpu;
+	register char *cp1, *cp2;
+	unsigned long cpumask;
+	size_t len;
+
+	cpu = (struct percpu_struct *)
+		((char*)hwrpb
+		 + hwrpb->processor_offset
+		 + cpuid * hwrpb->processor_size);
+
+	cpumask = (1UL << cpuid);
+	if (wait_for_txrdy(cpumask))
+		goto timeout;
+
+	cp2 = str;
+	len = strlen(cp2);
+	*(unsigned int *)&cpu->ipc_buffer[0] = len;
+	cp1 = (char *) &cpu->ipc_buffer[1];
+	memcpy(cp1, cp2, len);
+
+	/* atomic test and set */
+	wmb();
+	set_bit(cpuid, &hwrpb->rxrdy);
+
+	if (wait_for_txrdy(cpumask))
+		goto timeout;
+	return;
+
+ timeout:
+	printk("Processor %x not ready\n", cpuid);
+}
+
+/*
+ * A secondary console wants to send a message.  Receive it.
+ */
+static void
+recv_secondary_console_msg(void)
+{
+	int mycpu, i, cnt;
+	unsigned long txrdy = hwrpb->txrdy;
+	char *cp1, *cp2, buf[80];
+	struct percpu_struct *cpu;
+
+	DBGS(("recv_secondary_console_msg: TXRDY 0x%lx.\n", txrdy));
+
+	mycpu = hard_smp_processor_id();
+
+	for (i = 0; i < NR_CPUS; i++) {
+		if (!(txrdy & (1UL << i)))
+			continue;
+
+		DBGS(("recv_secondary_console_msg: "
+		      "TXRDY contains CPU %d.\n", i));
+
+		cpu = (struct percpu_struct *)
+		  ((char*)hwrpb
+		   + hwrpb->processor_offset
+		   + i * hwrpb->processor_size);
+
+ 		DBGS(("recv_secondary_console_msg: on %d from %d"
+		      " HALT_REASON 0x%lx FLAGS 0x%lx\n",
+		      mycpu, i, cpu->halt_reason, cpu->flags));
+
+		cnt = cpu->ipc_buffer[0] >> 32;
+		if (cnt <= 0 || cnt >= 80)
+			strcpy(buf, "<<< BOGUS MSG >>>");
+		else {
+			cp1 = (char *) &cpu->ipc_buffer[11];
+			cp2 = buf;
+			strcpy(cp2, cp1);
+			
+			while ((cp2 = strchr(cp2, '\r')) != 0) {
+				*cp2 = ' ';
+				if (cp2[1] == '\n')
+					cp2[1] = ' ';
+			}
+		}
+
+		DBGS((KERN_INFO "recv_secondary_console_msg: on %d "
+		      "message is '%s'\n", mycpu, buf));
+	}
+
+	hwrpb->txrdy = 0;
+}
+
+/*
+ * Convince the console to have a secondary cpu begin execution.
+ */
+static int __init
+secondary_cpu_start(int cpuid, struct task_struct *idle)
+{
+	struct percpu_struct *cpu;
+	struct pcb_struct *hwpcb, *ipcb;
+	unsigned long timeout;
+	  
+	cpu = (struct percpu_struct *)
+		((char*)hwrpb
+		 + hwrpb->processor_offset
+		 + cpuid * hwrpb->processor_size);
+	hwpcb = (struct pcb_struct *) cpu->hwpcb;
+	ipcb = &idle->thread_info->pcb;
+
+	/* Initialize the CPU's HWPCB to something just good enough for
+	   us to get started.  Immediately after starting, we'll swpctx
+	   to the target idle task's pcb.  Reuse the stack in the mean
+	   time.  Precalculate the target PCBB.  */
+	hwpcb->ksp = (unsigned long)ipcb + sizeof(union thread_union) - 16;
+	hwpcb->usp = 0;
+	hwpcb->ptbr = ipcb->ptbr;
+	hwpcb->pcc = 0;
+	hwpcb->asn = 0;
+	hwpcb->unique = virt_to_phys(ipcb);
+	hwpcb->flags = ipcb->flags;
+	hwpcb->res1 = hwpcb->res2 = 0;
+
+#if 0
+	DBGS(("KSP 0x%lx PTBR 0x%lx VPTBR 0x%lx UNIQUE 0x%lx\n",
+	      hwpcb->ksp, hwpcb->ptbr, hwrpb->vptb, hwpcb->unique));
+#endif
+	DBGS(("Starting secondary cpu %d: state 0x%lx pal_flags 0x%lx\n",
+	      cpuid, idle->state, ipcb->flags));
+
+	/* Setup HWRPB fields that SRM uses to activate secondary CPU */
+	hwrpb->CPU_restart = __smp_callin;
+	hwrpb->CPU_restart_data = (unsigned long) __smp_callin;
+
+	/* Recalculate and update the HWRPB checksum */
+	hwrpb_update_checksum(hwrpb);
+
+	/*
+	 * Send a "start" command to the specified processor.
+	 */
+
+	/* SRM III 3.4.1.3 */
+	cpu->flags |= 0x22;	/* turn on Context Valid and Restart Capable */
+	cpu->flags &= ~1;	/* turn off Bootstrap In Progress */
+	wmb();
+
+	send_secondary_console_msg("START\r\n", cpuid);
+
+	/* Wait 10 seconds for an ACK from the console.  */
+	timeout = jiffies + 10*HZ;
+	while (time_before(jiffies, timeout)) {
+		if (cpu->flags & 1)
+			goto started;
+		udelay(10);
+		barrier();
+	}
+	printk(KERN_ERR "SMP: Processor %d failed to start.\n", cpuid);
+	return -1;
+
+ started:
+	DBGS(("secondary_cpu_start: SUCCESS for CPU %d!!!\n", cpuid));
+	return 0;
+}
+
+/*
+ * Bring one cpu online.
+ */
+static int __init
+smp_boot_one_cpu(int cpuid)
+{
+	struct task_struct *idle;
+	unsigned long timeout;
+
+	/* Cook up an idler for this guy.  Note that the address we
+	   give to kernel_thread is irrelevant -- it's going to start
+	   where HWRPB.CPU_restart says to start.  But this gets all
+	   the other task-y sort of data structures set up like we
+	   wish.  We can't use kernel_thread since we must avoid
+	   rescheduling the child.  */
+	idle = fork_idle(cpuid);
+	if (IS_ERR(idle))
+		panic("failed fork for CPU %d", cpuid);
+
+	DBGS(("smp_boot_one_cpu: CPU %d state 0x%lx flags 0x%lx\n",
+	      cpuid, idle->state, idle->flags));
+
+	/* Signal the secondary to wait a moment.  */
+	smp_secondary_alive = -1;
+
+	/* Whirrr, whirrr, whirrrrrrrrr... */
+	if (secondary_cpu_start(cpuid, idle))
+		return -1;
+
+	/* Notify the secondary CPU it can run calibrate_delay.  */
+	mb();
+	smp_secondary_alive = 0;
+
+	/* We've been acked by the console; wait one second for
+	   the task to start up for real.  */
+	timeout = jiffies + 1*HZ;
+	while (time_before(jiffies, timeout)) {
+		if (smp_secondary_alive == 1)
+			goto alive;
+		udelay(10);
+		barrier();
+	}
+
+	/* We failed to boot the CPU.  */
+
+	printk(KERN_ERR "SMP: Processor %d is stuck.\n", cpuid);
+	return -1;
+
+ alive:
+	/* Another "Red Snapper". */
+	return 0;
+}
+
+/*
+ * Called from setup_arch.  Detect an SMP system and which processors
+ * are present.
+ */
+void __init
+setup_smp(void)
+{
+	struct percpu_struct *cpubase, *cpu;
+	unsigned long i;
+
+	if (boot_cpuid != 0) {
+		printk(KERN_WARNING "SMP: Booting off cpu %d instead of 0?\n",
+		       boot_cpuid);
+	}
+
+	if (hwrpb->nr_processors > 1) {
+		int boot_cpu_palrev;
+
+		DBGS(("setup_smp: nr_processors %ld\n",
+		      hwrpb->nr_processors));
+
+		cpubase = (struct percpu_struct *)
+			((char*)hwrpb + hwrpb->processor_offset);
+		boot_cpu_palrev = cpubase->pal_revision;
+
+		for (i = 0; i < hwrpb->nr_processors; i++) {
+			cpu = (struct percpu_struct *)
+				((char *)cpubase + i*hwrpb->processor_size);
+			if ((cpu->flags & 0x1cc) == 0x1cc) {
+				smp_num_probed++;
+				/* Assume here that "whami" == index */
+				hwrpb_cpu_present_mask |= (1UL << i);
+				cpu->pal_revision = boot_cpu_palrev;
+			}
+
+			DBGS(("setup_smp: CPU %d: flags 0x%lx type 0x%lx\n",
+			      i, cpu->flags, cpu->type));
+			DBGS(("setup_smp: CPU %d: PAL rev 0x%lx\n",
+			      i, cpu->pal_revision));
+		}
+	} else {
+		smp_num_probed = 1;
+		hwrpb_cpu_present_mask = (1UL << boot_cpuid);
+	}
+	cpu_present_mask = cpumask_of_cpu(boot_cpuid);
+
+	printk(KERN_INFO "SMP: %d CPUs probed -- cpu_present_mask = %lx\n",
+	       smp_num_probed, hwrpb_cpu_present_mask);
+}
+
+/*
+ * Called by smp_init prepare the secondaries
+ */
+void __init
+smp_prepare_cpus(unsigned int max_cpus)
+{
+	int cpu_count, i;
+
+	/* Take care of some initial bookkeeping.  */
+	memset(ipi_data, 0, sizeof(ipi_data));
+
+	current_thread_info()->cpu = boot_cpuid;
+
+	smp_store_cpu_info(boot_cpuid);
+	smp_setup_percpu_timer(boot_cpuid);
+
+	/* Nothing to do on a UP box, or when told not to.  */
+	if (smp_num_probed == 1 || max_cpus == 0) {
+		cpu_present_mask = cpumask_of_cpu(boot_cpuid);
+		printk(KERN_INFO "SMP mode deactivated.\n");
+		return;
+	}
+
+	printk(KERN_INFO "SMP starting up secondaries.\n");
+
+	cpu_count = 1;
+	for (i = 0; (i < NR_CPUS) && (cpu_count < max_cpus); i++) {
+		if (i == boot_cpuid)
+			continue;
+
+		if (((hwrpb_cpu_present_mask >> i) & 1) == 0)
+			continue;
+
+		cpu_set(i, cpu_possible_map);
+		cpu_count++;
+	}
+
+	smp_num_cpus = cpu_count;
+}
+
+void __devinit
+smp_prepare_boot_cpu(void)
+{
+	/*
+	 * Mark the boot cpu (current cpu) as both present and online
+	 */ 
+	cpu_set(smp_processor_id(), cpu_present_mask);
+	cpu_set(smp_processor_id(), cpu_online_map);
+}
+
+int __devinit
+__cpu_up(unsigned int cpu)
+{
+	smp_boot_one_cpu(cpu);
+
+	return cpu_online(cpu) ? 0 : -ENOSYS;
+}
+
+void __init
+smp_cpus_done(unsigned int max_cpus)
+{
+	int cpu;
+	unsigned long bogosum = 0;
+
+	for(cpu = 0; cpu < NR_CPUS; cpu++) 
+		if (cpu_online(cpu))
+			bogosum += cpu_data[cpu].loops_per_jiffy;
+	
+	printk(KERN_INFO "SMP: Total of %d processors activated "
+	       "(%lu.%02lu BogoMIPS).\n",
+	       num_online_cpus(), 
+	       (bogosum + 2500) / (500000/HZ),
+	       ((bogosum + 2500) / (5000/HZ)) % 100);
+}
+
+
+void
+smp_percpu_timer_interrupt(struct pt_regs *regs)
+{
+	int cpu = smp_processor_id();
+	unsigned long user = user_mode(regs);
+	struct cpuinfo_alpha *data = &cpu_data[cpu];
+
+	/* Record kernel PC.  */
+	profile_tick(CPU_PROFILING, regs);
+
+	if (!--data->prof_counter) {
+		/* We need to make like a normal interrupt -- otherwise
+		   timer interrupts ignore the global interrupt lock,
+		   which would be a Bad Thing.  */
+		irq_enter();
+
+		update_process_times(user);
+
+		data->prof_counter = data->prof_multiplier;
+
+		irq_exit();
+	}
+}
+
+int __init
+setup_profiling_timer(unsigned int multiplier)
+{
+	return -EINVAL;
+}
+
+
+static void
+send_ipi_message(cpumask_t to_whom, enum ipi_message_type operation)
+{
+	int i;
+
+	mb();
+	for_each_cpu_mask(i, to_whom)
+		set_bit(operation, &ipi_data[i].bits);
+
+	mb();
+	for_each_cpu_mask(i, to_whom)
+		wripir(i);
+}
+
+/* Structure and data for smp_call_function.  This is designed to 
+   minimize static memory requirements.  Plus it looks cleaner.  */
+
+struct smp_call_struct {
+	void (*func) (void *info);
+	void *info;
+	long wait;
+	atomic_t unstarted_count;
+	atomic_t unfinished_count;
+};
+
+static struct smp_call_struct *smp_call_function_data;
+
+/* Atomicly drop data into a shared pointer.  The pointer is free if
+   it is initially locked.  If retry, spin until free.  */
+
+static int
+pointer_lock (void *lock, void *data, int retry)
+{
+	void *old, *tmp;
+
+	mb();
+ again:
+	/* Compare and swap with zero.  */
+	asm volatile (
+	"1:	ldq_l	%0,%1\n"
+	"	mov	%3,%2\n"
+	"	bne	%0,2f\n"
+	"	stq_c	%2,%1\n"
+	"	beq	%2,1b\n"
+	"2:"
+	: "=&r"(old), "=m"(*(void **)lock), "=&r"(tmp)
+	: "r"(data)
+	: "memory");
+
+	if (old == 0)
+		return 0;
+	if (! retry)
+		return -EBUSY;
+
+	while (*(void **)lock)
+		barrier();
+	goto again;
+}
+
+void
+handle_ipi(struct pt_regs *regs)
+{
+	int this_cpu = smp_processor_id();
+	unsigned long *pending_ipis = &ipi_data[this_cpu].bits;
+	unsigned long ops;
+
+#if 0
+	DBGS(("handle_ipi: on CPU %d ops 0x%lx PC 0x%lx\n",
+	      this_cpu, *pending_ipis, regs->pc));
+#endif
+
+	mb();	/* Order interrupt and bit testing. */
+	while ((ops = xchg(pending_ipis, 0)) != 0) {
+	  mb();	/* Order bit clearing and data access. */
+	  do {
+		unsigned long which;
+
+		which = ops & -ops;
+		ops &= ~which;
+		which = __ffs(which);
+
+		switch (which) {
+		case IPI_RESCHEDULE:
+			/* Reschedule callback.  Everything to be done
+			   is done by the interrupt return path.  */
+			break;
+
+		case IPI_CALL_FUNC:
+		    {
+			struct smp_call_struct *data;
+			void (*func)(void *info);
+			void *info;
+			int wait;
+
+			data = smp_call_function_data;
+			func = data->func;
+			info = data->info;
+			wait = data->wait;
+
+			/* Notify the sending CPU that the data has been
+			   received, and execution is about to begin.  */
+			mb();
+			atomic_dec (&data->unstarted_count);
+
+			/* At this point the structure may be gone unless
+			   wait is true.  */
+			(*func)(info);
+
+			/* Notify the sending CPU that the task is done.  */
+			mb();
+			if (wait) atomic_dec (&data->unfinished_count);
+			break;
+		    }
+
+		case IPI_CPU_STOP:
+			halt();
+
+		default:
+			printk(KERN_CRIT "Unknown IPI on CPU %d: %lu\n",
+			       this_cpu, which);
+			break;
+		}
+	  } while (ops);
+
+	  mb();	/* Order data access and bit testing. */
+	}
+
+	cpu_data[this_cpu].ipi_count++;
+
+	if (hwrpb->txrdy)
+		recv_secondary_console_msg();
+}
+
+void
+smp_send_reschedule(int cpu)
+{
+#ifdef DEBUG_IPI_MSG
+	if (cpu == hard_smp_processor_id())
+		printk(KERN_WARNING
+		       "smp_send_reschedule: Sending IPI to self.\n");
+#endif
+	send_ipi_message(cpumask_of_cpu(cpu), IPI_RESCHEDULE);
+}
+
+void
+smp_send_stop(void)
+{
+	cpumask_t to_whom = cpu_possible_map;
+	cpu_clear(smp_processor_id(), to_whom);
+#ifdef DEBUG_IPI_MSG
+	if (hard_smp_processor_id() != boot_cpu_id)
+		printk(KERN_WARNING "smp_send_stop: Not on boot cpu.\n");
+#endif
+	send_ipi_message(to_whom, IPI_CPU_STOP);
+}
+
+/*
+ * Run a function on all other CPUs.
+ *  <func>	The function to run. This must be fast and non-blocking.
+ *  <info>	An arbitrary pointer to pass to the function.
+ *  <retry>	If true, keep retrying until ready.
+ *  <wait>	If true, wait until function has completed on other CPUs.
+ *  [RETURNS]   0 on success, else a negative status code.
+ *
+ * Does not return until remote CPUs are nearly ready to execute <func>
+ * or are or have executed.
+ * You must not call this function with disabled interrupts or from a
+ * hardware interrupt handler or from a bottom half handler.
+ */
+
+int
+smp_call_function_on_cpu (void (*func) (void *info), void *info, int retry,
+			  int wait, cpumask_t to_whom)
+{
+	struct smp_call_struct data;
+	unsigned long timeout;
+	int num_cpus_to_call;
+	
+	/* Can deadlock when called with interrupts disabled */
+	WARN_ON(irqs_disabled());
+
+	data.func = func;
+	data.info = info;
+	data.wait = wait;
+
+	cpu_clear(smp_processor_id(), to_whom);
+	num_cpus_to_call = cpus_weight(to_whom);
+
+	atomic_set(&data.unstarted_count, num_cpus_to_call);
+	atomic_set(&data.unfinished_count, num_cpus_to_call);
+
+	/* Acquire the smp_call_function_data mutex.  */
+	if (pointer_lock(&smp_call_function_data, &data, retry))
+		return -EBUSY;
+
+	/* Send a message to the requested CPUs.  */
+	send_ipi_message(to_whom, IPI_CALL_FUNC);
+
+	/* Wait for a minimal response.  */
+	timeout = jiffies + HZ;
+	while (atomic_read (&data.unstarted_count) > 0
+	       && time_before (jiffies, timeout))
+		barrier();
+
+	/* If there's no response yet, log a message but allow a longer
+	 * timeout period -- if we get a response this time, log
+	 * a message saying when we got it.. 
+	 */
+	if (atomic_read(&data.unstarted_count) > 0) {
+		long start_time = jiffies;
+		printk(KERN_ERR "%s: initial timeout -- trying long wait\n",
+		       __FUNCTION__);
+		timeout = jiffies + 30 * HZ;
+		while (atomic_read(&data.unstarted_count) > 0
+		       && time_before(jiffies, timeout))
+			barrier();
+		if (atomic_read(&data.unstarted_count) <= 0) {
+			long delta = jiffies - start_time;
+			printk(KERN_ERR 
+			       "%s: response %ld.%ld seconds into long wait\n",
+			       __FUNCTION__, delta / HZ,
+			       (100 * (delta - ((delta / HZ) * HZ))) / HZ);
+		}
+	}
+
+	/* We either got one or timed out -- clear the lock. */
+	mb();
+	smp_call_function_data = NULL;
+
+	/* 
+	 * If after both the initial and long timeout periods we still don't
+	 * have a response, something is very wrong...
+	 */
+	BUG_ON(atomic_read (&data.unstarted_count) > 0);
+
+	/* Wait for a complete response, if needed.  */
+	if (wait) {
+		while (atomic_read (&data.unfinished_count) > 0)
+			barrier();
+	}
+
+	return 0;
+}
+
+int
+smp_call_function (void (*func) (void *info), void *info, int retry, int wait)
+{
+	return smp_call_function_on_cpu (func, info, retry, wait,
+					 cpu_online_map);
+}
+
+static void
+ipi_imb(void *ignored)
+{
+	imb();
+}
+
+void
+smp_imb(void)
+{
+	/* Must wait other processors to flush their icache before continue. */
+	if (on_each_cpu(ipi_imb, NULL, 1, 1))
+		printk(KERN_CRIT "smp_imb: timed out\n");
+}
+
+static void
+ipi_flush_tlb_all(void *ignored)
+{
+	tbia();
+}
+
+void
+flush_tlb_all(void)
+{
+	/* Although we don't have any data to pass, we do want to
+	   synchronize with the other processors.  */
+	if (on_each_cpu(ipi_flush_tlb_all, NULL, 1, 1)) {
+		printk(KERN_CRIT "flush_tlb_all: timed out\n");
+	}
+}
+
+#define asn_locked() (cpu_data[smp_processor_id()].asn_lock)
+
+static void
+ipi_flush_tlb_mm(void *x)
+{
+	struct mm_struct *mm = (struct mm_struct *) x;
+	if (mm == current->active_mm && !asn_locked())
+		flush_tlb_current(mm);
+	else
+		flush_tlb_other(mm);
+}
+
+void
+flush_tlb_mm(struct mm_struct *mm)
+{
+	preempt_disable();
+
+	if (mm == current->active_mm) {
+		flush_tlb_current(mm);
+		if (atomic_read(&mm->mm_users) <= 1) {
+			int cpu, this_cpu = smp_processor_id();
+			for (cpu = 0; cpu < NR_CPUS; cpu++) {
+				if (!cpu_online(cpu) || cpu == this_cpu)
+					continue;
+				if (mm->context[cpu])
+					mm->context[cpu] = 0;
+			}
+			preempt_enable();
+			return;
+		}
+	}
+
+	if (smp_call_function(ipi_flush_tlb_mm, mm, 1, 1)) {
+		printk(KERN_CRIT "flush_tlb_mm: timed out\n");
+	}
+
+	preempt_enable();
+}
+
+struct flush_tlb_page_struct {
+	struct vm_area_struct *vma;
+	struct mm_struct *mm;
+	unsigned long addr;
+};
+
+static void
+ipi_flush_tlb_page(void *x)
+{
+	struct flush_tlb_page_struct *data = (struct flush_tlb_page_struct *)x;
+	struct mm_struct * mm = data->mm;
+
+	if (mm == current->active_mm && !asn_locked())
+		flush_tlb_current_page(mm, data->vma, data->addr);
+	else
+		flush_tlb_other(mm);
+}
+
+void
+flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)
+{
+	struct flush_tlb_page_struct data;
+	struct mm_struct *mm = vma->vm_mm;
+
+	preempt_disable();
+
+	if (mm == current->active_mm) {
+		flush_tlb_current_page(mm, vma, addr);
+		if (atomic_read(&mm->mm_users) <= 1) {
+			int cpu, this_cpu = smp_processor_id();
+			for (cpu = 0; cpu < NR_CPUS; cpu++) {
+				if (!cpu_online(cpu) || cpu == this_cpu)
+					continue;
+				if (mm->context[cpu])
+					mm->context[cpu] = 0;
+			}
+			preempt_enable();
+			return;
+		}
+	}
+
+	data.vma = vma;
+	data.mm = mm;
+	data.addr = addr;
+
+	if (smp_call_function(ipi_flush_tlb_page, &data, 1, 1)) {
+		printk(KERN_CRIT "flush_tlb_page: timed out\n");
+	}
+
+	preempt_enable();
+}
+
+void
+flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
+{
+	/* On the Alpha we always flush the whole user tlb.  */
+	flush_tlb_mm(vma->vm_mm);
+}
+
+static void
+ipi_flush_icache_page(void *x)
+{
+	struct mm_struct *mm = (struct mm_struct *) x;
+	if (mm == current->active_mm && !asn_locked())
+		__load_new_mm_context(mm);
+	else
+		flush_tlb_other(mm);
+}
+
+void
+flush_icache_user_range(struct vm_area_struct *vma, struct page *page,
+			unsigned long addr, int len)
+{
+	struct mm_struct *mm = vma->vm_mm;
+
+	if ((vma->vm_flags & VM_EXEC) == 0)
+		return;
+
+	preempt_disable();
+
+	if (mm == current->active_mm) {
+		__load_new_mm_context(mm);
+		if (atomic_read(&mm->mm_users) <= 1) {
+			int cpu, this_cpu = smp_processor_id();
+			for (cpu = 0; cpu < NR_CPUS; cpu++) {
+				if (!cpu_online(cpu) || cpu == this_cpu)
+					continue;
+				if (mm->context[cpu])
+					mm->context[cpu] = 0;
+			}
+			preempt_enable();
+			return;
+		}
+	}
+
+	if (smp_call_function(ipi_flush_icache_page, mm, 1, 1)) {
+		printk(KERN_CRIT "flush_icache_page: timed out\n");
+	}
+
+	preempt_enable();
+}
+
+#ifdef CONFIG_DEBUG_SPINLOCK
+void
+_raw_spin_unlock(spinlock_t * lock)
+{
+	mb();
+	lock->lock = 0;
+
+	lock->on_cpu = -1;
+	lock->previous = NULL;
+	lock->task = NULL;
+	lock->base_file = "none";
+	lock->line_no = 0;
+}
+
+void
+debug_spin_lock(spinlock_t * lock, const char *base_file, int line_no)
+{
+	long tmp;
+	long stuck;
+	void *inline_pc = __builtin_return_address(0);
+	unsigned long started = jiffies;
+	int printed = 0;
+	int cpu = smp_processor_id();
+
+	stuck = 1L << 30;
+ try_again:
+
+	/* Use sub-sections to put the actual loop at the end
+	   of this object file's text section so as to perfect
+	   branch prediction.  */
+	__asm__ __volatile__(
+	"1:	ldl_l	%0,%1\n"
+	"	subq	%2,1,%2\n"
+	"	blbs	%0,2f\n"
+	"	or	%0,1,%0\n"
+	"	stl_c	%0,%1\n"
+	"	beq	%0,3f\n"
+	"4:	mb\n"
+	".subsection 2\n"
+	"2:	ldl	%0,%1\n"
+	"	subq	%2,1,%2\n"
+	"3:	blt	%2,4b\n"
+	"	blbs	%0,2b\n"
+	"	br	1b\n"
+	".previous"
+	: "=r" (tmp), "=m" (lock->lock), "=r" (stuck)
+	: "1" (lock->lock), "2" (stuck) : "memory");
+
+	if (stuck < 0) {
+		printk(KERN_WARNING
+		       "%s:%d spinlock stuck in %s at %p(%d)"
+		       " owner %s at %p(%d) %s:%d\n",
+		       base_file, line_no,
+		       current->comm, inline_pc, cpu,
+		       lock->task->comm, lock->previous,
+		       lock->on_cpu, lock->base_file, lock->line_no);
+		stuck = 1L << 36;
+		printed = 1;
+		goto try_again;
+	}
+
+	/* Exiting.  Got the lock.  */
+	lock->on_cpu = cpu;
+	lock->previous = inline_pc;
+	lock->task = current;
+	lock->base_file = base_file;
+	lock->line_no = line_no;
+
+	if (printed) {
+		printk(KERN_WARNING
+		       "%s:%d spinlock grabbed in %s at %p(%d) %ld ticks\n",
+		       base_file, line_no, current->comm, inline_pc,
+		       cpu, jiffies - started);
+	}
+}
+
+int
+debug_spin_trylock(spinlock_t * lock, const char *base_file, int line_no)
+{
+	int ret;
+	if ((ret = !test_and_set_bit(0, lock))) {
+		lock->on_cpu = smp_processor_id();
+		lock->previous = __builtin_return_address(0);
+		lock->task = current;
+	} else {
+		lock->base_file = base_file;
+		lock->line_no = line_no;
+	}
+	return ret;
+}
+#endif /* CONFIG_DEBUG_SPINLOCK */
+
+#ifdef CONFIG_DEBUG_RWLOCK
+void _raw_write_lock(rwlock_t * lock)
+{
+	long regx, regy;
+	int stuck_lock, stuck_reader;
+	void *inline_pc = __builtin_return_address(0);
+
+ try_again:
+
+	stuck_lock = 1<<30;
+	stuck_reader = 1<<30;
+
+	__asm__ __volatile__(
+	"1:	ldl_l	%1,%0\n"
+	"	blbs	%1,6f\n"
+	"	blt	%1,8f\n"
+	"	mov	1,%1\n"
+	"	stl_c	%1,%0\n"
+	"	beq	%1,6f\n"
+	"4:	mb\n"
+	".subsection 2\n"
+	"6:	blt	%3,4b	# debug\n"
+	"	subl	%3,1,%3	# debug\n"
+	"	ldl	%1,%0\n"
+	"	blbs	%1,6b\n"
+	"8:	blt	%4,4b	# debug\n"
+	"	subl	%4,1,%4	# debug\n"
+	"	ldl	%1,%0\n"
+	"	blt	%1,8b\n"
+	"	br	1b\n"
+	".previous"
+	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (regy),
+	  "=&r" (stuck_lock), "=&r" (stuck_reader)
+	: "0" (*(volatile int *)lock), "3" (stuck_lock), "4" (stuck_reader) : "memory");
+
+	if (stuck_lock < 0) {
+		printk(KERN_WARNING "write_lock stuck at %p\n", inline_pc);
+		goto try_again;
+	}
+	if (stuck_reader < 0) {
+		printk(KERN_WARNING "write_lock stuck on readers at %p\n",
+		       inline_pc);
+		goto try_again;
+	}
+}
+
+void _raw_read_lock(rwlock_t * lock)
+{
+	long regx;
+	int stuck_lock;
+	void *inline_pc = __builtin_return_address(0);
+
+ try_again:
+
+	stuck_lock = 1<<30;
+
+	__asm__ __volatile__(
+	"1:	ldl_l	%1,%0;"
+	"	blbs	%1,6f;"
+	"	subl	%1,2,%1;"
+	"	stl_c	%1,%0;"
+	"	beq	%1,6f;"
+	"4:	mb\n"
+	".subsection 2\n"
+	"6:	ldl	%1,%0;"
+	"	blt	%2,4b	# debug\n"
+	"	subl	%2,1,%2	# debug\n"
+	"	blbs	%1,6b;"
+	"	br	1b\n"
+	".previous"
+	: "=m" (*(volatile int *)lock), "=&r" (regx), "=&r" (stuck_lock)
+	: "0" (*(volatile int *)lock), "2" (stuck_lock) : "memory");
+
+	if (stuck_lock < 0) {
+		printk(KERN_WARNING "read_lock stuck at %p\n", inline_pc);
+		goto try_again;
+	}
+}
+#endif /* CONFIG_DEBUG_RWLOCK */
