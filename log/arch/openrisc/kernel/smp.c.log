commit fc74d716600545304a066bfd9d54cbd07e531701
Author: Julia Lawall <Julia.Lawall@inria.fr>
Date:   Sun Dec 29 16:42:58 2019 +0100

    openrisc: use mmgrab
    
    Mmgrab was introduced in commit f1f1007644ff ("mm: add new mmgrab()
    helper") and most of the kernel was updated to use it. Update a
    remaining file.
    
    The semantic patch that makes this change is as follows:
    (http://coccinelle.lip6.fr/)
    
    <smpl>
    @@ expression e; @@
    - atomic_inc(&e->mm_count);
    + mmgrab(e);
    </smpl>
    
    Signed-off-by: Julia Lawall <Julia.Lawall@inria.fr>
    Signed-off-by: Stafford Horne <shorne@gmail.com>
    [shorne: Added missing sched/mm.h include]

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index 7d518ee8bddc..bd1e660bbc89 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -14,6 +14,7 @@
 #include <linux/smp.h>
 #include <linux/cpu.h>
 #include <linux/sched.h>
+#include <linux/sched/mm.h>
 #include <linux/irq.h>
 #include <asm/cpuinfo.h>
 #include <asm/mmu_context.h>
@@ -113,7 +114,7 @@ asmlinkage __init void secondary_start_kernel(void)
 	 * All kernel threads share the same mm context; grab a
 	 * reference and switch to it.
 	 */
-	atomic_inc(&mm->mm_count);
+	mmgrab(mm);
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));
 

commit 610f01b9a88a9ef8b506709a825c17395c56a62a
Author: Stafford Horne <shorne@gmail.com>
Date:   Fri Nov 3 12:22:27 2017 +0900

    openrisc: fix possible deadlock scenario during timer sync
    
    OpenRISC borrows its timer sync logic from MIPS, Matt helped to review
    the OpenRISC implementation and noted that we may suffer the same
    deadlock case that MIPS has faced. The case being:
    
      "the MIPS timer synchronization code contained the possibility of
      deadlock. If you mark a CPU online before it goes into the synchronize
      loop, then the boot CPU can schedule a different thread and send IPIs to
      all "online" CPUs. It gets stuck waiting for the secondary to ack it's
      IPI, since this secondary CPU has not enabled IRQs yet, and is stuck
      waiting for the master to synchronise with it.  The system then
      deadlocks."
    
    Fix this by moving set_cpu_online() to after timer sync.
    
    Reported-by: Matt Redfearn <matt.redfearn@mips.com>
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index 4d80ce6fa045..7d518ee8bddc 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -127,10 +127,10 @@ asmlinkage __init void secondary_start_kernel(void)
 	/*
 	 * OK, now it's safe to let the boot CPU continue
 	 */
-	set_cpu_online(cpu, true);
 	complete(&cpu_running);
 
 	synchronise_count_slave(cpu);
+	set_cpu_online(cpu, true);
 
 	local_irq_enable();
 

commit 4553474d977d1ee8a81067cfbc588f1df84ce3e9
Author: Stafford Horne <shorne@gmail.com>
Date:   Fri Jul 7 06:06:30 2017 +0900

    openrisc: add tick timer multi-core sync logic
    
    In case timers are not in sync when cpus start (i.e. hot plug / offset
    resets) we need to synchronize the secondary cpus internal timer with
    the main cpu.  This is needed as in OpenRISC SMP there is only one
    clocksource registered which reads from the same ttcr register on each
    cpu.
    
    This synchronization routine heavily borrows from mips implementation that
    does something similar.
    
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index 4763b8b9161e..4d80ce6fa045 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -100,6 +100,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 		pr_crit("CPU%u: failed to start\n", cpu);
 		return -EIO;
 	}
+	synchronise_count_master(cpu);
 
 	return 0;
 }
@@ -129,6 +130,8 @@ asmlinkage __init void secondary_start_kernel(void)
 	set_cpu_online(cpu, true);
 	complete(&cpu_running);
 
+	synchronise_count_slave(cpu);
+
 	local_irq_enable();
 
 	preempt_disable();

commit 4ee93d80ad73980826d582c7c37caa9597822001
Author: Jan Henrik Weinstock <jan.weinstock@ice.rwth-aachen.de>
Date:   Wed Nov 4 17:26:10 2015 +0100

    openrisc: add cacheflush support to fix icache aliasing
    
    On OpenRISC the icache does not snoop data stores.  This can cause
    aliasing as reported by Jan. This patch fixes the issue to ensure icache
    is properly synchronized when code is written to memory.  It supports both
    SMP and UP flushing.
    
    This supports dcache flush as well for architectures that do not support
    write-through caches; most OpenRISC implementations do implement
    write-through cache however. Dcache flushes are done only on a single
    core as OpenRISC dcaches all support snooping of bus stores.
    
    Signed-off-by: Jan Henrik Weinstock <jan.weinstock@ice.rwth-aachen.de>
    [shorne@gmail.com: Squashed patches and wrote commit message]
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index 685b4934fa39..4763b8b9161e 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -18,6 +18,7 @@
 #include <asm/cpuinfo.h>
 #include <asm/mmu_context.h>
 #include <asm/tlbflush.h>
+#include <asm/cacheflush.h>
 #include <asm/time.h>
 
 static void (*smp_cross_call)(const struct cpumask *, unsigned int);
@@ -239,3 +240,17 @@ void flush_tlb_range(struct vm_area_struct *vma,
 {
 	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
 }
+
+/* Instruction cache invalidate - performed on each cpu */
+static void ipi_icache_page_inv(void *arg)
+{
+	struct page *page = arg;
+
+	local_icache_page_inv(page);
+}
+
+void smp_icache_page_inv(struct page *page)
+{
+	on_each_cpu(ipi_icache_page_inv, page, 1);
+}
+EXPORT_SYMBOL(smp_icache_page_inv);

commit c056718464512da06d7f65a27d5e4f1707b24c80
Author: Stafford Horne <shorne@gmail.com>
Date:   Sat Jun 24 07:09:59 2017 +0900

    openrisc: sleep instead of spin on secondary wait
    
    Currently we do a spin on secondary cpus when waiting to boot.  This
    theoretically causes issues with power consumption and does cause issues
    with qemu cycle burning (it starves cpu 0 from actually being able to
    boot.)
    
    This change puts each secondary cpu to sleep if they have a power
    management unit, then signals them to wake via IPI when its time to boot.
    If the cpus have no power management unit they will loop as before.
    
    Note: The wakeup IPI requires a special interrupt handler as on secondary
    cpu's the interrupt infrastructure is not yet established.  This
    interrupt handler is set and reset by updating SPR_EVBAR.
    
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index 154c94a0cfbc..685b4934fa39 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -26,6 +26,7 @@ unsigned long secondary_release = -1;
 struct thread_info *secondary_thread_info;
 
 enum ipi_msg_type {
+	IPI_WAKEUP,
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
 	IPI_CALL_FUNC_SINGLE,
@@ -42,6 +43,7 @@ static void boot_secondary(unsigned int cpu, struct task_struct *idle)
 	spin_lock(&boot_lock);
 
 	secondary_release = cpu;
+	smp_cross_call(cpumask_of(cpu), IPI_WAKEUP);
 
 	/*
 	 * now the secondary core is starting up let it run its
@@ -140,6 +142,9 @@ void handle_IPI(unsigned int ipi_msg)
 	unsigned int cpu = smp_processor_id();
 
 	switch (ipi_msg) {
+	case IPI_WAKEUP:
+		break;
+
 	case IPI_RESCHEDULE:
 		scheduler_ipi();
 		break;

commit b441aab7aa0e15955c432736b08a218a6a4c77f0
Author: Stafford Horne <shorne@gmail.com>
Date:   Wed Jul 12 17:20:38 2017 +0900

    openrisc: fix initial preempt state for secondary cpu tasks
    
    During SMP testing we were getting the below warning after booting the
    secondary cpu:
    
    [    0.060000] BUG: scheduling while atomic: swapper/1/0/0x00000000
    
    This change follows similar patterns from other architectures to start
    the schduler with preempt disabled.
    
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
index fd724123229a..154c94a0cfbc 100644
--- a/arch/openrisc/kernel/smp.c
+++ b/arch/openrisc/kernel/smp.c
@@ -128,6 +128,7 @@ asmlinkage __init void secondary_start_kernel(void)
 
 	local_irq_enable();
 
+	preempt_disable();
 	/*
 	 * OK, it's off to the idle thread for us
 	 */

commit 8e6d08e0a15e7d4d4b608b56597350d4cdd77710
Author: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
Date:   Sun May 11 21:49:34 2014 +0300

    openrisc: initial SMP support
    
    This patch introduces the SMP support for the OpenRISC architecture.
    The SMP architecture requires cores which have multi-core features which
    have been introduced a few years back including:
    
     - New SPRS SPR_COREID SPR_NUMCORES
     - Shadow SPRs
     - Atomic Instructions
     - Cache Coherency
     - A wired in IPI controller
    
    This patch adds all of the SMP specific changes to core infrastructure,
    it looks big but it needs to go all together as its hard to split this
    one up.
    
    Boot loader spinning of second cpu is not supported yet, it's assumed
    that Linux is booted straight after cpu reset.
    
    The bulk of these changes are trivial changes to refactor to use per cpu
    data structures throughout.  The addition of the smp.c and changes in
    time.c are the changes.  Some specific notes:
    
    MM changes
    ----------
    The reason why this is created as an array, and not with DEFINE_PER_CPU
    is that doing it this way, we'll save a load in the tlb-miss handler
    (the load from __per_cpu_offset).
    
    TLB Flush
    ---------
    The SMP implementation of flush_tlb_* works by sending out a
    function-call IPI to all the non-local cpus by using the generic
    on_each_cpu() function.
    
    Currently, all flush_tlb_* functions will result in a flush_tlb_all(),
    which has always been the behaviour in the UP case.
    
    CPU INFO
    --------
    This creates a per cpu cpuinfo struct and fills it out accordingly for
    each activated cpu.  show_cpuinfo is also updated to reflect new version
    information in later versions of the spec.
    
    SMP API
    -------
    This imitates the arm64 implementation by having a smp_cross_call
    callback that can be set by set_smp_cross_call to initiate an IPI and a
    handle_IPI function that is expected to be called from an IPI irqchip
    driver.
    
    Signed-off-by: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    [shorne@gmail.com: added cpu stop, checkpatch fixes, wrote commit message]
    Signed-off-by: Stafford Horne <shorne@gmail.com>

diff --git a/arch/openrisc/kernel/smp.c b/arch/openrisc/kernel/smp.c
new file mode 100644
index 000000000000..fd724123229a
--- /dev/null
+++ b/arch/openrisc/kernel/smp.c
@@ -0,0 +1,235 @@
+/*
+ * Copyright (C) 2014 Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
+ * Copyright (C) 2017 Stafford Horne <shorne@gmail.com>
+ *
+ * Based on arm64 and arc implementations
+ * Copyright (C) 2013 ARM Ltd.
+ * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)
+ *
+ * This file is licensed under the terms of the GNU General Public License
+ * version 2.  This program is licensed "as is" without any warranty of any
+ * kind, whether express or implied.
+ */
+
+#include <linux/smp.h>
+#include <linux/cpu.h>
+#include <linux/sched.h>
+#include <linux/irq.h>
+#include <asm/cpuinfo.h>
+#include <asm/mmu_context.h>
+#include <asm/tlbflush.h>
+#include <asm/time.h>
+
+static void (*smp_cross_call)(const struct cpumask *, unsigned int);
+
+unsigned long secondary_release = -1;
+struct thread_info *secondary_thread_info;
+
+enum ipi_msg_type {
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_CALL_FUNC_SINGLE,
+};
+
+static DEFINE_SPINLOCK(boot_lock);
+
+static void boot_secondary(unsigned int cpu, struct task_struct *idle)
+{
+	/*
+	 * set synchronisation state between this boot processor
+	 * and the secondary one
+	 */
+	spin_lock(&boot_lock);
+
+	secondary_release = cpu;
+
+	/*
+	 * now the secondary core is starting up let it run its
+	 * calibrations, then wait for it to finish
+	 */
+	spin_unlock(&boot_lock);
+}
+
+void __init smp_prepare_boot_cpu(void)
+{
+}
+
+void __init smp_init_cpus(void)
+{
+	int i;
+
+	for (i = 0; i < NR_CPUS; i++)
+		set_cpu_possible(i, true);
+}
+
+void __init smp_prepare_cpus(unsigned int max_cpus)
+{
+	int i;
+
+	/*
+	 * Initialise the present map, which describes the set of CPUs
+	 * actually populated at the present time.
+	 */
+	for (i = 0; i < max_cpus; i++)
+		set_cpu_present(i, true);
+}
+
+void __init smp_cpus_done(unsigned int max_cpus)
+{
+}
+
+static DECLARE_COMPLETION(cpu_running);
+
+int __cpu_up(unsigned int cpu, struct task_struct *idle)
+{
+	if (smp_cross_call == NULL) {
+		pr_warn("CPU%u: failed to start, IPI controller missing",
+			cpu);
+		return -EIO;
+	}
+
+	secondary_thread_info = task_thread_info(idle);
+	current_pgd[cpu] = init_mm.pgd;
+
+	boot_secondary(cpu, idle);
+	if (!wait_for_completion_timeout(&cpu_running,
+					msecs_to_jiffies(1000))) {
+		pr_crit("CPU%u: failed to start\n", cpu);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+asmlinkage __init void secondary_start_kernel(void)
+{
+	struct mm_struct *mm = &init_mm;
+	unsigned int cpu = smp_processor_id();
+	/*
+	 * All kernel threads share the same mm context; grab a
+	 * reference and switch to it.
+	 */
+	atomic_inc(&mm->mm_count);
+	current->active_mm = mm;
+	cpumask_set_cpu(cpu, mm_cpumask(mm));
+
+	pr_info("CPU%u: Booted secondary processor\n", cpu);
+
+	setup_cpuinfo();
+	openrisc_clockevent_init();
+
+	notify_cpu_starting(cpu);
+
+	/*
+	 * OK, now it's safe to let the boot CPU continue
+	 */
+	set_cpu_online(cpu, true);
+	complete(&cpu_running);
+
+	local_irq_enable();
+
+	/*
+	 * OK, it's off to the idle thread for us
+	 */
+	cpu_startup_entry(CPUHP_AP_ONLINE_IDLE);
+}
+
+void handle_IPI(unsigned int ipi_msg)
+{
+	unsigned int cpu = smp_processor_id();
+
+	switch (ipi_msg) {
+	case IPI_RESCHEDULE:
+		scheduler_ipi();
+		break;
+
+	case IPI_CALL_FUNC:
+		generic_smp_call_function_interrupt();
+		break;
+
+	case IPI_CALL_FUNC_SINGLE:
+		generic_smp_call_function_single_interrupt();
+		break;
+
+	default:
+		WARN(1, "CPU%u: Unknown IPI message 0x%x\n", cpu, ipi_msg);
+		break;
+	}
+}
+
+void smp_send_reschedule(int cpu)
+{
+	smp_cross_call(cpumask_of(cpu), IPI_RESCHEDULE);
+}
+
+static void stop_this_cpu(void *dummy)
+{
+	/* Remove this CPU */
+	set_cpu_online(smp_processor_id(), false);
+
+	local_irq_disable();
+	/* CPU Doze */
+	if (mfspr(SPR_UPR) & SPR_UPR_PMP)
+		mtspr(SPR_PMR, mfspr(SPR_PMR) | SPR_PMR_DME);
+	/* If that didn't work, infinite loop */
+	while (1)
+		;
+}
+
+void smp_send_stop(void)
+{
+	smp_call_function(stop_this_cpu, NULL, 0);
+}
+
+/* not supported, yet */
+int setup_profiling_timer(unsigned int multiplier)
+{
+	return -EINVAL;
+}
+
+void __init set_smp_cross_call(void (*fn)(const struct cpumask *, unsigned int))
+{
+	smp_cross_call = fn;
+}
+
+void arch_send_call_function_single_ipi(int cpu)
+{
+	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+}
+
+void arch_send_call_function_ipi_mask(const struct cpumask *mask)
+{
+	smp_cross_call(mask, IPI_CALL_FUNC);
+}
+
+/* TLB flush operations - Performed on each CPU*/
+static inline void ipi_flush_tlb_all(void *ignored)
+{
+	local_flush_tlb_all();
+}
+
+void flush_tlb_all(void)
+{
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+}
+
+/*
+ * FIXME: implement proper functionality instead of flush_tlb_all.
+ * *But*, as things currently stands, the local_tlb_flush_* functions will
+ * all boil down to local_tlb_flush_all anyway.
+ */
+void flush_tlb_mm(struct mm_struct *mm)
+{
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+}
+
+void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
+{
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+}
+
+void flush_tlb_range(struct vm_area_struct *vma,
+		     unsigned long start, unsigned long end)
+{
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+}
