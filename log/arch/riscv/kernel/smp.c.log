commit 5cf998ba8c7bbbfec3e0d6534c9a3f860ab9920e
Author: Anup Patel <anup.patel@wdc.com>
Date:   Mon Jun 1 14:45:38 2020 +0530

    RISC-V: self-contained IPI handling routine
    
    Currently, the IPI handling routine riscv_software_interrupt() does
    not take any argument and also does not perform irq_enter()/irq_exit().
    
    This patch makes IPI handling routine more self-contained by:
    1. Passing "pt_regs *" argument
    2. Explicitly doing irq_enter()/irq_exit()
    3. Explicitly save/restore "pt_regs *" using set_irq_regs()
    
    With above changes, IPI handling routine does not depend on caller
    function to perform irq_enter()/irq_exit() and save/restore of
    "pt_regs *" hence its more self-contained. This also enables us
    to call IPI handling routine from IRQCHIP drivers.
    
    Signed-off-by: Anup Patel <anup.patel@wdc.com>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Acked-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index a65a8fa0c22d..b1d4f452f843 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -123,11 +123,14 @@ static inline void clear_ipi(void)
 		clint_clear_ipi(cpuid_to_hartid_map(smp_processor_id()));
 }
 
-void riscv_software_interrupt(void)
+void handle_IPI(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
 	unsigned long *stats = ipi_data[smp_processor_id()].stats;
 
+	irq_enter();
+
 	clear_ipi();
 
 	while (true) {
@@ -138,7 +141,7 @@ void riscv_software_interrupt(void)
 
 		ops = xchg(pending_ipis, 0);
 		if (ops == 0)
-			return;
+			goto done;
 
 		if (ops & (1 << IPI_RESCHEDULE)) {
 			stats[IPI_RESCHEDULE]++;
@@ -160,6 +163,10 @@ void riscv_software_interrupt(void)
 		/* Order data access and bit testing. */
 		mb();
 	}
+
+done:
+	irq_exit();
+	set_irq_regs(old_regs);
 }
 
 static const char * const ipi_names[] = {

commit 7391efa48d88c8555a802bac562d02a38567127c
Author: Anup Patel <anup.patel@wdc.com>
Date:   Fri Apr 24 10:29:26 2020 +0530

    RISC-V: Export riscv_cpuid_to_hartid_mask() API
    
    The riscv_cpuid_to_hartid_mask() API should be exported to allow
    building KVM RISC-V as loadable module.
    
    Signed-off-by: Anup Patel <anup.patel@wdc.com>
    Reviewed-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index e0a6293093f1..a65a8fa0c22d 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -10,6 +10,7 @@
 
 #include <linux/cpu.h>
 #include <linux/interrupt.h>
+#include <linux/module.h>
 #include <linux/profile.h>
 #include <linux/smp.h>
 #include <linux/sched.h>
@@ -63,6 +64,7 @@ void riscv_cpuid_to_hartid_mask(const struct cpumask *in, struct cpumask *out)
 	for_each_cpu(cpu, in)
 		cpumask_set_cpu(cpuid_to_hartid_map(cpu), out);
 }
+EXPORT_SYMBOL_GPL(riscv_cpuid_to_hartid_mask);
 
 bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
 {

commit 3384b043ea1564560ff19591cb9554867c7c6f77
Author: Greentime Hu <greentime.hu@sifive.com>
Date:   Tue Mar 3 17:34:18 2020 +0800

    riscv: fix the IPI missing issue in nommu mode
    
    This patch fixes the IPI(inner processor interrupt) missing issue. It
    failed because it used hartid_mask to iterate for_each_cpu(), however the
    cpu_mask and hartid_mask may not be always the same. It will never send the
    IPI to hartid 4 because it will be skipped in for_each_cpu loop in my case.
    
    We can reproduce this case in Qemu sifive_u machine by this command.
    qemu-system-riscv64 -nographic -smp 5 -m 1G -M sifive_u -kernel \
    arch/riscv/boot/loader
    
    It will hang in csd_lock_wait(csd) because the csd_unlock(csd) is not
    called. It is not called because hartid 4 doesn't receive the IPI to
    release this lock. The caller hart doesn't send the IPI to hartid 4 is
    because of hartid 4 is skipped in for_each_cpu(). It will be skipped is
    because "(cpu) < nr_cpu_ids" is not true. The hartid is 4 and nr_cpu_ids
    is 4. Therefore it should use cpumask in for_each_cpu() instead of
    hartid_mask.
    
            /* Send a message to all CPUs in the map */
            arch_send_call_function_ipi_mask(cfd->cpumask_ipi);
    
            if (wait) {
                    for_each_cpu(cpu, cfd->cpumask) {
                            call_single_data_t *csd;
                            csd = per_cpu_ptr(cfd->csd, cpu);
                            csd_lock_wait(csd);
                    }
            }
    
            for ((cpu) = -1;                                \
                    (cpu) = cpumask_next((cpu), (mask)),    \
                    (cpu) < nr_cpu_ids;)
    
    It could boot to login console after this patch applied.
    
    Fixes: b2d36b5668f6 ("riscv: provide native clint access for M-mode")
    Signed-off-by: Greentime Hu <greentime.hu@sifive.com>
    Reviewed-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index eb878abcaaf8..e0a6293093f1 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -96,7 +96,7 @@ static void send_ipi_mask(const struct cpumask *mask, enum ipi_message_type op)
 	if (IS_ENABLED(CONFIG_RISCV_SBI))
 		sbi_send_ipi(cpumask_bits(&hartid_mask));
 	else
-		clint_send_ipi_mask(&hartid_mask);
+		clint_send_ipi_mask(mask);
 }
 
 static void send_ipi_single(int cpu, enum ipi_message_type op)

commit fcdc65375186a5cd69cc2eedfb498b86f4f5a21e
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Oct 28 13:10:38 2019 +0100

    riscv: provide native clint access for M-mode
    
    RISC-V has the concept of a cpu level interrupt controller.  The
    interface for it is split between a standardized part that is exposed
    as bits in the mstatus/sstatus register and the mie/mip/sie/sip
    CRS.  But the bit to actually trigger IPIs is not standardized and
    just mentioned as implementable using MMIO.
    
    Add support for IPIs using MMIO using the SiFive clint layout (which
    is also shared by Ariane, Kendryte and the Qemu virt platform).
    Additionally the MMIO block also supports the time value and timer
    compare registers, so they are also set up using the same OF node.
    Support for other layouts should also be relatively easy to add in the
    future.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Anup Patel <anup@brainfault.org>
    [paul.walmsley@sifive.com: update include guard format; fix checkpatch
     issues; minor commit message cleanup]
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index c0fbc04e6810..eb878abcaaf8 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -16,6 +16,7 @@
 #include <linux/seq_file.h>
 #include <linux/delay.h>
 
+#include <asm/clint.h>
 #include <asm/sbi.h>
 #include <asm/tlbflush.h>
 #include <asm/cacheflush.h>
@@ -92,7 +93,10 @@ static void send_ipi_mask(const struct cpumask *mask, enum ipi_message_type op)
 	smp_mb__after_atomic();
 
 	riscv_cpuid_to_hartid_mask(mask, &hartid_mask);
-	sbi_send_ipi(cpumask_bits(&hartid_mask));
+	if (IS_ENABLED(CONFIG_RISCV_SBI))
+		sbi_send_ipi(cpumask_bits(&hartid_mask));
+	else
+		clint_send_ipi_mask(&hartid_mask);
 }
 
 static void send_ipi_single(int cpu, enum ipi_message_type op)
@@ -103,12 +107,18 @@ static void send_ipi_single(int cpu, enum ipi_message_type op)
 	set_bit(op, &ipi_data[cpu].bits);
 	smp_mb__after_atomic();
 
-	sbi_send_ipi(cpumask_bits(cpumask_of(hartid)));
+	if (IS_ENABLED(CONFIG_RISCV_SBI))
+		sbi_send_ipi(cpumask_bits(cpumask_of(hartid)));
+	else
+		clint_send_ipi_single(hartid);
 }
 
 static inline void clear_ipi(void)
 {
-	csr_clear(CSR_IP, IE_SIE);
+	if (IS_ENABLED(CONFIG_RISCV_SBI))
+		csr_clear(CSR_IP, IE_SIE);
+	else
+		clint_clear_ipi(cpuid_to_hartid_map(smp_processor_id()));
 }
 
 void riscv_software_interrupt(void)

commit a4c3733d32a72f11dee86d0731d7565aa6ebe22d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Oct 28 13:10:32 2019 +0100

    riscv: abstract out CSR names for supervisor vs machine mode
    
    Many of the privileged CSRs exist in a supervisor and machine version
    that are used very similarly.  Provide versions of the CSR names and
    fields that map to either the S-mode or M-mode variant depending on
    a new CONFIG_RISCV_M_MODE kconfig symbol.
    
    Contains contributions from Damien Le Moal <Damien.LeMoal@wdc.com>
    and Paul Walmsley <paul.walmsley@sifive.com>.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de> # for drivers/clocksource, drivers/irqchip
    [paul.walmsley@sifive.com: updated to apply]
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 5c9ec78422c2..c0fbc04e6810 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -108,7 +108,7 @@ static void send_ipi_single(int cpu, enum ipi_message_type op)
 
 static inline void clear_ipi(void)
 {
-	csr_clear(CSR_SIP, SIE_SSIE);
+	csr_clear(CSR_IP, IE_SIE);
 }
 
 void riscv_software_interrupt(void)

commit 5ed881bc3afc40d7a23c2211ead1aeb4980dda20
Author: Paul Walmsley <paul.walmsley@sifive.com>
Date:   Thu Oct 17 15:21:28 2019 -0700

    riscv: add missing header file includes
    
    sparse identifies several missing prototypes caused by missing
    preprocessor include directives:
    
    arch/riscv/kernel/cpufeature.c:16:6: warning: symbol 'has_fpu' was not declared. Should it be static?
    arch/riscv/kernel/process.c:26:6: warning: symbol 'arch_cpu_idle' was not declared. Should it be static?
    arch/riscv/kernel/reset.c:15:6: warning: symbol 'pm_power_off' was not declared. Should it be static?
    arch/riscv/kernel/syscall_table.c:15:6: warning: symbol 'sys_call_table' was not declared. Should it be static?
    arch/riscv/kernel/traps.c:149:13: warning: symbol 'trap_init' was not declared. Should it be static?
    arch/riscv/kernel/vdso.c:54:5: warning: symbol 'arch_setup_additional_pages' was not declared. Should it be static?
    arch/riscv/kernel/smp.c:64:6: warning: symbol 'arch_match_cpu_phys_id' was not declared. Should it be static?
    arch/riscv/kernel/module-sections.c:89:5: warning: symbol 'module_frob_arch_sections' was not declared. Should it be static?
    arch/riscv/mm/context.c:42:6: warning: symbol 'switch_mm' was not declared. Should it be static?
    
    Fix by including the appropriate header files in the appropriate
    source files.
    
    This patch should have no functional impact.
    
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index b18cd6c8e8fb..5c9ec78422c2 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -8,7 +8,9 @@
  * Copyright (C) 2017 SiFive
  */
 
+#include <linux/cpu.h>
 #include <linux/interrupt.h>
+#include <linux/profile.h>
 #include <linux/smp.h>
 #include <linux/sched.h>
 #include <linux/seq_file.h>

commit d3d7a0ce020e2d14967159b5351158c80b681760
Author: Atish Patra <atish.patra@wdc.com>
Date:   Wed Sep 4 16:14:06 2019 +0000

    RISC-V: Export kernel symbols for kvm
    
    Export a few symbols used by kvm module. Without this, kvm cannot
    be compiled as a module.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Anup Patel <anup.patel@wdc.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Alexander Graf <graf@amazon.com>
    [paul.walmsley@sifive.com: updated to apply; clarified short patch
     description]
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 3836760d7aaf..b18cd6c8e8fb 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -206,3 +206,4 @@ void smp_send_reschedule(int cpu)
 {
 	send_ipi_single(cpu, IPI_RESCHEDULE);
 }
+EXPORT_SYMBOL_GPL(smp_send_reschedule);

commit f5bf645d10f2c6cc85294021af70f2b7bcc42d8e
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 21 23:58:35 2019 +0900

    riscv: cleanup riscv_cpuid_to_hartid_mask
    
    Move the initial clearing of the mask from the callers to
    riscv_cpuid_to_hartid_mask, and remove the unused !CONFIG_SMP stub.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index a3715d621f60..3836760d7aaf 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -56,6 +56,7 @@ void riscv_cpuid_to_hartid_mask(const struct cpumask *in, struct cpumask *out)
 {
 	int cpu;
 
+	cpumask_clear(out);
 	for_each_cpu(cpu, in)
 		cpumask_set_cpu(cpuid_to_hartid_map(cpu), out);
 }

commit e11ea2a02b93933425ddfa4b4e2012ba0882ac82
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 21 23:58:34 2019 +0900

    riscv: optimize send_ipi_single
    
    Don't go through send_ipi_mask, but just set the op bit and then pass
    a simple generated hartid mask directly to sbi_send_ipi.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    [paul.walmsley@sifive.com: minor patch description fixes]
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 2e21669aa068..a3715d621f60 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -94,7 +94,13 @@ static void send_ipi_mask(const struct cpumask *mask, enum ipi_message_type op)
 
 static void send_ipi_single(int cpu, enum ipi_message_type op)
 {
-	send_ipi_mask(cpumask_of(cpu), op);
+	int hartid = cpuid_to_hartid_map(cpu);
+
+	smp_mb__before_atomic();
+	set_bit(op, &ipi_data[cpu].bits);
+	smp_mb__after_atomic();
+
+	sbi_send_ipi(cpumask_bits(cpumask_of(hartid)));
 }
 
 static inline void clear_ipi(void)

commit 1db7a7ca5ac543d0e360d1e8a3dc10ce74b58027
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 21 23:58:33 2019 +0900

    riscv: cleanup send_ipi_mask
    
    Use the special barriers for atomic bitops to make the intention
    a little more clear, and use riscv_cpuid_to_hartid_mask instead of
    open coding it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 8cd730239613..2e21669aa068 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -80,17 +80,15 @@ static void ipi_stop(void)
 
 static void send_ipi_mask(const struct cpumask *mask, enum ipi_message_type op)
 {
-	int cpuid, hartid;
 	struct cpumask hartid_mask;
+	int cpu;
 
-	cpumask_clear(&hartid_mask);
-	mb();
-	for_each_cpu(cpuid, mask) {
-		set_bit(op, &ipi_data[cpuid].bits);
-		hartid = cpuid_to_hartid_map(cpuid);
-		cpumask_set_cpu(hartid, &hartid_mask);
-	}
-	mb();
+	smp_mb__before_atomic();
+	for_each_cpu(cpu, mask)
+		set_bit(op, &ipi_data[cpu].bits);
+	smp_mb__after_atomic();
+
+	riscv_cpuid_to_hartid_mask(mask, &hartid_mask);
 	sbi_send_ipi(cpumask_bits(&hartid_mask));
 }
 

commit 7e0e50895fdf7d5ad94ceb6a076571f4c6a357fe
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 21 23:58:32 2019 +0900

    riscv: refactor the IPI code
    
    This prepares for adding native non-SBI IPI code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Paul Walmsley <paul.walmsley@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 5a9834503a2f..8cd730239613 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -78,13 +78,38 @@ static void ipi_stop(void)
 		wait_for_interrupt();
 }
 
+static void send_ipi_mask(const struct cpumask *mask, enum ipi_message_type op)
+{
+	int cpuid, hartid;
+	struct cpumask hartid_mask;
+
+	cpumask_clear(&hartid_mask);
+	mb();
+	for_each_cpu(cpuid, mask) {
+		set_bit(op, &ipi_data[cpuid].bits);
+		hartid = cpuid_to_hartid_map(cpuid);
+		cpumask_set_cpu(hartid, &hartid_mask);
+	}
+	mb();
+	sbi_send_ipi(cpumask_bits(&hartid_mask));
+}
+
+static void send_ipi_single(int cpu, enum ipi_message_type op)
+{
+	send_ipi_mask(cpumask_of(cpu), op);
+}
+
+static inline void clear_ipi(void)
+{
+	csr_clear(CSR_SIP, SIE_SSIE);
+}
+
 void riscv_software_interrupt(void)
 {
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
 	unsigned long *stats = ipi_data[smp_processor_id()].stats;
 
-	/* Clear pending IPI */
-	csr_clear(CSR_SIP, SIE_SSIE);
+	clear_ipi();
 
 	while (true) {
 		unsigned long ops;
@@ -118,23 +143,6 @@ void riscv_software_interrupt(void)
 	}
 }
 
-static void
-send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
-{
-	int cpuid, hartid;
-	struct cpumask hartid_mask;
-
-	cpumask_clear(&hartid_mask);
-	mb();
-	for_each_cpu(cpuid, to_whom) {
-		set_bit(operation, &ipi_data[cpuid].bits);
-		hartid = cpuid_to_hartid_map(cpuid);
-		cpumask_set_cpu(hartid, &hartid_mask);
-	}
-	mb();
-	sbi_send_ipi(cpumask_bits(&hartid_mask));
-}
-
 static const char * const ipi_names[] = {
 	[IPI_RESCHEDULE]	= "Rescheduling interrupts",
 	[IPI_CALL_FUNC]		= "Function call interrupts",
@@ -156,12 +164,12 @@ void show_ipi_stats(struct seq_file *p, int prec)
 
 void arch_send_call_function_ipi_mask(struct cpumask *mask)
 {
-	send_ipi_message(mask, IPI_CALL_FUNC);
+	send_ipi_mask(mask, IPI_CALL_FUNC);
 }
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC);
+	send_ipi_single(cpu, IPI_CALL_FUNC);
 }
 
 void smp_send_stop(void)
@@ -176,7 +184,7 @@ void smp_send_stop(void)
 
 		if (system_state <= SYSTEM_RUNNING)
 			pr_crit("SMP: stopping secondary CPUs\n");
-		send_ipi_message(&mask, IPI_CPU_STOP);
+		send_ipi_mask(&mask, IPI_CPU_STOP);
 	}
 
 	/* Wait up to one second for other CPUs to stop */
@@ -191,6 +199,5 @@ void smp_send_stop(void)
 
 void smp_send_reschedule(int cpu)
 {
-	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
+	send_ipi_single(cpu, IPI_RESCHEDULE);
 }
-

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index b2537ffa855c..5a9834503a2f 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * SMP initialisation and IPI support
  * Based on arch/arm64/kernel/smp.c
@@ -5,18 +6,6 @@
  * Copyright (C) 2012 ARM Ltd.
  * Copyright (C) 2015 Regents of the University of California
  * Copyright (C) 2017 SiFive
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #include <linux/interrupt.h>

commit 58de77545e53b94cd6c816776197dade598632c5
Author: Gary Guo <gary@garyguo.net>
Date:   Wed Mar 27 00:41:25 2019 +0000

    riscv: move flush_icache_{all,mm} to cacheflush.c
    
    Currently, flush_icache_all is macro-expanded into a SBI call, yet no
    asm/sbi.h is included in asm/cacheflush.h. This could be moved to
    mm/cacheflush.c instead (SBI call will dominate performance-wise and
    there is no worry to not have it inlined.
    
    Currently, flush_icache_mm stays in kernel/smp.c, which looks like a
    hack to prevent it from being compiled when CONFIG_SMP=n. It should
    also be in mm/cacheflush.c.
    
    Signed-off-by: Gary Guo <gary@garyguo.net>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 9253de5d91b6..b2537ffa855c 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -205,52 +205,3 @@ void smp_send_reschedule(int cpu)
 	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
-/*
- * Performs an icache flush for the given MM context.  RISC-V has no direct
- * mechanism for instruction cache shoot downs, so instead we send an IPI that
- * informs the remote harts they need to flush their local instruction caches.
- * To avoid pathologically slow behavior in a common case (a bunch of
- * single-hart processes on a many-hart machine, ie 'make -j') we avoid the
- * IPIs for harts that are not currently executing a MM context and instead
- * schedule a deferred local instruction cache flush to be performed before
- * execution resumes on each hart.
- */
-void flush_icache_mm(struct mm_struct *mm, bool local)
-{
-	unsigned int cpu;
-	cpumask_t others, hmask, *mask;
-
-	preempt_disable();
-
-	/* Mark every hart's icache as needing a flush for this MM. */
-	mask = &mm->context.icache_stale_mask;
-	cpumask_setall(mask);
-	/* Flush this hart's I$ now, and mark it as flushed. */
-	cpu = smp_processor_id();
-	cpumask_clear_cpu(cpu, mask);
-	local_flush_icache_all();
-
-	/*
-	 * Flush the I$ of other harts concurrently executing, and mark them as
-	 * flushed.
-	 */
-	cpumask_andnot(&others, mm_cpumask(mm), cpumask_of(cpu));
-	local |= cpumask_empty(&others);
-	if (mm != current->active_mm || !local) {
-		cpumask_clear(&hmask);
-		riscv_cpuid_to_hartid_mask(&others, &hmask);
-		sbi_remote_fence_i(hmask.bits);
-	} else {
-		/*
-		 * It's assumed that at least one strongly ordered operation is
-		 * performed on this hart between setting a hart's cpumask bit
-		 * and scheduling this MM context on that hart.  Sending an SBI
-		 * remote message will do this, but in the case where no
-		 * messages are sent we still need to order this hart's writes
-		 * with flush_icache_deferred().
-		 */
-		smp_mb();
-	}
-
-	preempt_enable();
-}

commit a3182c91ef4e7dda90ff080a4132efd3ecb8786a
Author: Anup Patel <Anup.Patel@wdc.com>
Date:   Thu Apr 25 08:38:41 2019 +0000

    RISC-V: Access CSRs using CSR numbers
    
    We should prefer accessing CSRs using their CSR numbers because:
    1. It compiles fine with older toolchains.
    2. We can use latest CSR names in #define macro names of CSR numbers
       as-per RISC-V spec.
    3. We can access newly added CSRs even if toolchain does not recognize
       newly addes CSRs by name.
    
    Signed-off-by: Anup Patel <anup.patel@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 0115db1368a4..9253de5d91b6 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -95,7 +95,7 @@ void riscv_software_interrupt(void)
 	unsigned long *stats = ipi_data[smp_processor_id()].stats;
 
 	/* Clear pending IPI */
-	csr_clear(sip, SIE_SSIE);
+	csr_clear(CSR_SIP, SIE_SSIE);
 
 	while (true) {
 		unsigned long ops;

commit f1f47c6ca34bb389f698cd80c77df4da0777e9c2
Author: Atish Patra <atish.patra@wdc.com>
Date:   Wed Apr 24 14:48:01 2019 -0700

    RISC-V: Fix minor checkpatch issues.
    
    While working on the patches, I found some minor checkpatch issues.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 89251f8ab754..0115db1368a4 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -42,7 +42,7 @@ unsigned long __cpuid_to_hartid_map[NR_CPUS] = {
 
 void __init smp_setup_processor_id(void)
 {
-       cpuid_to_hartid_map(0) = boot_cpu_hartid;
+	cpuid_to_hartid_map(0) = boot_cpu_hartid;
 }
 
 /* A collection of single bit ipi messages.  */
@@ -53,7 +53,7 @@ static struct {
 
 int riscv_hartid_to_cpuid(int hartid)
 {
-	int i = -1;
+	int i;
 
 	for (i = 0; i < NR_CPUS; i++)
 		if (cpuid_to_hartid_map(i) == hartid)

commit 70114560b2855853126c65cccdc49a33187327d0
Author: Atish Patra <atish.patra@wdc.com>
Date:   Wed Apr 24 14:47:58 2019 -0700

    RISC-V: Add RISC-V specific arch_match_cpu_phys_id
    
    OF/DT core has a hook for architecture specific logical cpuid to hartid
    mapping. By implementing this, we can pass the logical cpu id to cpu
    node parsing functions.
    
    Fix the instances where logical cpuid is expected as an argument in
    of_get_cpu_node.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 0c41d07ec281..89251f8ab754 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -70,6 +70,12 @@ void riscv_cpuid_to_hartid_mask(const struct cpumask *in, struct cpumask *out)
 	for_each_cpu(cpu, in)
 		cpumask_set_cpu(cpuid_to_hartid_map(cpu), out);
 }
+
+bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
+{
+	return phys_id == cpuid_to_hartid_map(cpu);
+}
+
 /* Unsupported */
 int setup_profiling_timer(unsigned int multiplier)
 {

commit 13fd5de06514458eb320188b7a815d65696efd99
Merge: f7ccc35aa3bd 823900cd0130
Author: Palmer Dabbelt <palmer@sifive.com>
Date:   Mon Mar 4 11:41:36 2019 -0800

    RISC-V: Fixmap support and MM cleanups
    
    This patchset does:
    1. Moves MM related code from kernel/setup.c to mm/init.c
    2. Implements compile-time fixed mappings
    
    Using fixed mappings, we get earlyprints even without SBI calls.
    
    For example, we can now use kernel parameter
    "earlycon=uart8250,mmio,0x10000000"
    to get early prints on QEMU virt machine without using SBI calls.
    
    The patchset is tested on QEMU virt machine.
    
    Palmer: It looks like some of the code movement here conflicted with the
    patches to move hartid handling around.  As far as I can tell the only
    changed code was in smp_setup_processor_id(), and I've kept the one in
    smp.c.

commit dd641e2686734ff78a1dec592ee82054d06bd456
Author: Atish Patra <atish.patra@wdc.com>
Date:   Fri Feb 22 11:41:38 2019 -0800

    RISC-V: Allow hartid-to-cpuid function to fail.
    
    It is perfectly okay to call riscv_hartid_to_cpuid for a hartid that is
    not mapped with an CPU id. It can happen if the calling functions
    retrieves the hartid from DT.  However, that hartid was never brought
    online by the firmware or kernel for any reasons.
    
    No need to BUG() in the above case. A negative error return is
    sufficient and the calling function should check for the return value
    always.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Anup Patel <anup@brainfault.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index b69883c61f3e..ca99f0fb49b1 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -60,7 +60,6 @@ int riscv_hartid_to_cpuid(int hartid)
 			return i;
 
 	pr_err("Couldn't find cpu id for hartid [%d]\n", hartid);
-	BUG();
 	return i;
 }
 

commit 78d1daa36489d44ecb97b400e75639e79422de67
Author: Atish Patra <atish.patra@wdc.com>
Date:   Fri Feb 22 11:41:36 2019 -0800

    RISC-V: Move cpuid to hartid mapping to SMP.
    
    Currently, logical CPU id to physical hartid mapping is defined for both
    smp and non-smp configurations. This is not required as we need this
    only for smp configuration.  The mapping function can define directly
    boot_cpu_hartid for non-smp use case.
    
    The reverse mapping function i.e. hartid to cpuid can be called for any
    valid but not booted harts. So it should return default cpu 0 only if it
    is a boot hartid.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Anup Patel <anup@brainfault.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 246635eac7bb..b69883c61f3e 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -36,6 +36,15 @@ enum ipi_message_type {
 	IPI_MAX
 };
 
+unsigned long __cpuid_to_hartid_map[NR_CPUS] = {
+	[0 ... NR_CPUS-1] = INVALID_HARTID
+};
+
+void __init smp_setup_processor_id(void)
+{
+	cpuid_to_hartid_map(0) = boot_cpu_hartid;
+}
+
 /* A collection of single bit ipi messages.  */
 static struct {
 	unsigned long stats[IPI_MAX] ____cacheline_aligned;

commit 37a107ff6dcd773da4dc75b62b9bf4349dd7300f
Author: Andreas Schwab <schwab@suse.de>
Date:   Tue Dec 11 11:20:40 2018 +0100

    riscv: don't stop itself in smp_send_stop
    
    Add IPI_CPU_STOP message and use it in smp_send_stop to stop other cpus,
    but not itself.  Mark cpu offline on reception of IPI_CPU_STOP.
    
    Signed-off-by: Andreas Schwab <schwab@suse.de>
    Reviewed-by: Atish Patra <atish.patra@wdc.com>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 57b1383e5ef7..246635eac7bb 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -23,6 +23,7 @@
 #include <linux/smp.h>
 #include <linux/sched.h>
 #include <linux/seq_file.h>
+#include <linux/delay.h>
 
 #include <asm/sbi.h>
 #include <asm/tlbflush.h>
@@ -31,6 +32,7 @@
 enum ipi_message_type {
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
+	IPI_CPU_STOP,
 	IPI_MAX
 };
 
@@ -66,6 +68,13 @@ int setup_profiling_timer(unsigned int multiplier)
 	return -EINVAL;
 }
 
+static void ipi_stop(void)
+{
+	set_cpu_online(smp_processor_id(), false);
+	while (1)
+		wait_for_interrupt();
+}
+
 void riscv_software_interrupt(void)
 {
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
@@ -94,6 +103,11 @@ void riscv_software_interrupt(void)
 			generic_smp_call_function_interrupt();
 		}
 
+		if (ops & (1 << IPI_CPU_STOP)) {
+			stats[IPI_CPU_STOP]++;
+			ipi_stop();
+		}
+
 		BUG_ON((ops >> IPI_MAX) != 0);
 
 		/* Order data access and bit testing. */
@@ -121,6 +135,7 @@ send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
 static const char * const ipi_names[] = {
 	[IPI_RESCHEDULE]	= "Rescheduling interrupts",
 	[IPI_CALL_FUNC]		= "Function call interrupts",
+	[IPI_CPU_STOP]		= "CPU stop interrupts",
 };
 
 void show_ipi_stats(struct seq_file *p, int prec)
@@ -146,15 +161,29 @@ void arch_send_call_function_single_ipi(int cpu)
 	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC);
 }
 
-static void ipi_stop(void *unused)
-{
-	while (1)
-		wait_for_interrupt();
-}
-
 void smp_send_stop(void)
 {
-	on_each_cpu(ipi_stop, NULL, 1);
+	unsigned long timeout;
+
+	if (num_online_cpus() > 1) {
+		cpumask_t mask;
+
+		cpumask_copy(&mask, cpu_online_mask);
+		cpumask_clear_cpu(smp_processor_id(), &mask);
+
+		if (system_state <= SYSTEM_RUNNING)
+			pr_crit("SMP: stopping secondary CPUs\n");
+		send_ipi_message(&mask, IPI_CPU_STOP);
+	}
+
+	/* Wait up to one second for other CPUs to stop */
+	timeout = USEC_PER_SEC;
+	while (num_online_cpus() > 1 && timeout--)
+		udelay(1);
+
+	if (num_online_cpus() > 1)
+		pr_warn("SMP: failed to stop secondary CPUs %*pbl\n",
+			   cpumask_pr_args(cpu_online_mask));
 }
 
 void smp_send_reschedule(int cpu)

commit 8b20d2db0a6d2761e0fc156eb74f7a55b92b3147
Author: Anup Patel <anup@brainfault.org>
Date:   Tue Oct 2 12:15:07 2018 -0700

    RISC-V: Show IPI stats
    
    This patch provides arch_show_interrupts() implementation to
    show IPI stats via /proc/interrupts.
    
    Now the contents of /proc/interrupts" will look like below:
               CPU0       CPU1       CPU2       CPU3
      8:         17          7          6         14  SiFive PLIC   8  virtio0
     10:         10         10          9         11  SiFive PLIC  10  ttyS0
    IPI0:       170        673        251         79  Rescheduling interrupts
    IPI1:         1         12         27          1  Function call interrupts
    
    Signed-off-by: Anup Patel <anup@brainfault.org>
    [Atish - Fixed checkpatch errors]
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Palmer Dabbelt <palmer@sifive.com>
    
    Changes since v2:
     - Remove use of IPI_CALL_WAKEUP because it's being removed
    
    Changes since v1:
     - Add stub inline show_ipi_stats() function for !CONFIG_SMP
     - Make ipi_names[] dynamically sized at compile time
     - Minor beautification of ipi_names[] using tabs
    
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 4eac0094f47e..57b1383e5ef7 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -22,22 +22,24 @@
 #include <linux/interrupt.h>
 #include <linux/smp.h>
 #include <linux/sched.h>
+#include <linux/seq_file.h>
 
 #include <asm/sbi.h>
 #include <asm/tlbflush.h>
 #include <asm/cacheflush.h>
 
-/* A collection of single bit ipi messages.  */
-static struct {
-	unsigned long bits ____cacheline_aligned;
-} ipi_data[NR_CPUS] __cacheline_aligned;
-
 enum ipi_message_type {
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
 	IPI_MAX
 };
 
+/* A collection of single bit ipi messages.  */
+static struct {
+	unsigned long stats[IPI_MAX] ____cacheline_aligned;
+	unsigned long bits ____cacheline_aligned;
+} ipi_data[NR_CPUS] __cacheline_aligned;
+
 int riscv_hartid_to_cpuid(int hartid)
 {
 	int i = -1;
@@ -67,6 +69,7 @@ int setup_profiling_timer(unsigned int multiplier)
 void riscv_software_interrupt(void)
 {
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
+	unsigned long *stats = ipi_data[smp_processor_id()].stats;
 
 	/* Clear pending IPI */
 	csr_clear(sip, SIE_SSIE);
@@ -81,11 +84,15 @@ void riscv_software_interrupt(void)
 		if (ops == 0)
 			return;
 
-		if (ops & (1 << IPI_RESCHEDULE))
+		if (ops & (1 << IPI_RESCHEDULE)) {
+			stats[IPI_RESCHEDULE]++;
 			scheduler_ipi();
+		}
 
-		if (ops & (1 << IPI_CALL_FUNC))
+		if (ops & (1 << IPI_CALL_FUNC)) {
+			stats[IPI_CALL_FUNC]++;
 			generic_smp_call_function_interrupt();
+		}
 
 		BUG_ON((ops >> IPI_MAX) != 0);
 
@@ -111,6 +118,24 @@ send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
 	sbi_send_ipi(cpumask_bits(&hartid_mask));
 }
 
+static const char * const ipi_names[] = {
+	[IPI_RESCHEDULE]	= "Rescheduling interrupts",
+	[IPI_CALL_FUNC]		= "Function call interrupts",
+};
+
+void show_ipi_stats(struct seq_file *p, int prec)
+{
+	unsigned int cpu, i;
+
+	for (i = 0; i < IPI_MAX; i++) {
+		seq_printf(p, "%*s%u:%s", prec - 1, "IPI", i,
+			   prec >= 4 ? " " : "");
+		for_each_online_cpu(cpu)
+			seq_printf(p, "%10lu ", ipi_data[cpu].stats[i]);
+		seq_printf(p, " %s\n", ipi_names[i]);
+	}
+}
+
 void arch_send_call_function_ipi_mask(struct cpumask *mask)
 {
 	send_ipi_message(mask, IPI_CALL_FUNC);

commit f99fb607fb2bc0d4ce6b9adb764c65e37f40a92b
Author: Atish Patra <atish.patra@wdc.com>
Date:   Tue Oct 2 12:15:05 2018 -0700

    RISC-V: Use Linux logical CPU number instead of hartid
    
    Setup the cpu_logical_map during boot. Moreover, every SBI call
    and PLIC context are based on the physical hartid. Use the logical
    CPU to hartid mapping to pass correct hartid to respective functions.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Anup Patel <anup@brainfault.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 0bd48935f886..4eac0094f47e 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -97,14 +97,18 @@ void riscv_software_interrupt(void)
 static void
 send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
 {
-	int i;
+	int cpuid, hartid;
+	struct cpumask hartid_mask;
 
+	cpumask_clear(&hartid_mask);
 	mb();
-	for_each_cpu(i, to_whom)
-		set_bit(operation, &ipi_data[i].bits);
-
+	for_each_cpu(cpuid, to_whom) {
+		set_bit(operation, &ipi_data[cpuid].bits);
+		hartid = cpuid_to_hartid_map(cpuid);
+		cpumask_set_cpu(hartid, &hartid_mask);
+	}
 	mb();
-	sbi_send_ipi(cpumask_bits(to_whom));
+	sbi_send_ipi(cpumask_bits(&hartid_mask));
 }
 
 void arch_send_call_function_ipi_mask(struct cpumask *mask)
@@ -146,7 +150,7 @@ void smp_send_reschedule(int cpu)
 void flush_icache_mm(struct mm_struct *mm, bool local)
 {
 	unsigned int cpu;
-	cpumask_t others, *mask;
+	cpumask_t others, hmask, *mask;
 
 	preempt_disable();
 
@@ -164,9 +168,11 @@ void flush_icache_mm(struct mm_struct *mm, bool local)
 	 */
 	cpumask_andnot(&others, mm_cpumask(mm), cpumask_of(cpu));
 	local |= cpumask_empty(&others);
-	if (mm != current->active_mm || !local)
-		sbi_remote_fence_i(others.bits);
-	else {
+	if (mm != current->active_mm || !local) {
+		cpumask_clear(&hmask);
+		riscv_cpuid_to_hartid_mask(&others, &hmask);
+		sbi_remote_fence_i(hmask.bits);
+	} else {
 		/*
 		 * It's assumed that at least one strongly ordered operation is
 		 * performed on this hart between setting a hart's cpumask bit

commit 6825c7a80f1863b975a00042abe140ea24813af2
Author: Atish Patra <atish.patra@wdc.com>
Date:   Tue Oct 2 12:15:04 2018 -0700

    RISC-V: Add logical CPU indexing for RISC-V
    
    Currently, both Linux CPU id and hart id are same.
    This is not recommended as it will lead to discontinuous CPU
    indexing in Linux. Moreover, kdump kernel will run from CPU0
    which would be absent if we follow existing scheme.
    
    Implement a logical mapping between Linux CPU id and hart
    id to decouple these two. Always mark the boot processor as
    CPU0 and all other CPUs get the logical CPU id based on their
    booting order.
    
    Signed-off-by: Atish Patra <atish.patra@wdc.com>
    Reviewed-by: Anup Patel <anup@brainfault.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 906fe21ea21b..0bd48935f886 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -38,7 +38,26 @@ enum ipi_message_type {
 	IPI_MAX
 };
 
+int riscv_hartid_to_cpuid(int hartid)
+{
+	int i = -1;
+
+	for (i = 0; i < NR_CPUS; i++)
+		if (cpuid_to_hartid_map(i) == hartid)
+			return i;
+
+	pr_err("Couldn't find cpu id for hartid [%d]\n", hartid);
+	BUG();
+	return i;
+}
 
+void riscv_cpuid_to_hartid_mask(const struct cpumask *in, struct cpumask *out)
+{
+	int cpu;
+
+	for_each_cpu(cpu, in)
+		cpumask_set_cpu(cpuid_to_hartid_map(cpu), out);
+}
 /* Unsupported */
 int setup_profiling_timer(unsigned int multiplier)
 {

commit b9d5535746e306a456691177228a08f04b923a7b
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 4 10:23:13 2018 +0200

    RISC-V: simplify software interrupt / IPI code
    
    Rename handle_ipi to riscv_software_interrupt, drop the unused return
    value and move the prototype to irq.h together with riscv_timer_interupt.
    This allows simplifying the upcoming interrupt handling support.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index 6d3962435720..906fe21ea21b 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -45,7 +45,7 @@ int setup_profiling_timer(unsigned int multiplier)
 	return -EINVAL;
 }
 
-irqreturn_t handle_ipi(void)
+void riscv_software_interrupt(void)
 {
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
 
@@ -60,7 +60,7 @@ irqreturn_t handle_ipi(void)
 
 		ops = xchg(pending_ipis, 0);
 		if (ops == 0)
-			return IRQ_HANDLED;
+			return;
 
 		if (ops & (1 << IPI_RESCHEDULE))
 			scheduler_ipi();
@@ -73,8 +73,6 @@ irqreturn_t handle_ipi(void)
 		/* Order data access and bit testing. */
 		mb();
 	}
-
-	return IRQ_HANDLED;
 }
 
 static void

commit 3b62de26cf5ef17340a0e986d3e53eb4f74f96d5
Merge: 185e788c84a9 741fc3ff3a49
Author: Palmer Dabbelt <palmer@sifive.com>
Date:   Fri Dec 1 13:31:31 2017 -0800

    RISC-V: Fixes for clean allmodconfig build
    
    Olaf said: Here's a short series of patches that produces a working
    allmodconfig. Would be nice to see them go in so we can add build
    coverage.
    
    I've dropped patches 8 and 10 from the original set:
    
    * [PATCH 08/10] (RISC-V: Set __ARCH_WANT_RENAMEAT to pick up generic
      version) has a better fix that I've sent out for review, we don't want
      renameat.
    * [PATCH 10/10] (input: joystick: riscv has get_cycles) has already been
      taken into Dmitry Torokhov's tree.

commit 08f051eda33b51e8ee0f45f05bcfe49d0f0caf6b
Author: Andrew Waterman <andrew@sifive.com>
Date:   Wed Oct 25 14:30:32 2017 -0700

    RISC-V: Flush I$ when making a dirty page executable
    
    The RISC-V ISA allows for instruction caches that are not coherent WRT
    stores, even on a single hart.  As a result, we need to explicitly flush
    the instruction cache whenever marking a dirty page as executable in
    order to preserve the correct system behavior.
    
    Local instruction caches aren't that scary (our implementations actually
    flush the cache, but RISC-V is defined to allow higher-performance
    implementations to exist), but RISC-V defines no way to perform an
    instruction cache shootdown.  When explicitly asked to do so we can
    shoot down remote instruction caches via an IPI, but this is a bit on
    the slow side.
    
    Instead of requiring an IPI to all harts whenever marking a page as
    executable, we simply flush the currently running harts.  In order to
    maintain correct behavior, we additionally mark every other hart as
    needing a deferred instruction cache which will be taken before anything
    runs on it.
    
    Signed-off-by: Andrew Waterman <andrew@sifive.com>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index b4a71ec5906f..1b27ade437b4 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -108,3 +108,51 @@ void smp_send_reschedule(int cpu)
 {
 	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
+
+/*
+ * Performs an icache flush for the given MM context.  RISC-V has no direct
+ * mechanism for instruction cache shoot downs, so instead we send an IPI that
+ * informs the remote harts they need to flush their local instruction caches.
+ * To avoid pathologically slow behavior in a common case (a bunch of
+ * single-hart processes on a many-hart machine, ie 'make -j') we avoid the
+ * IPIs for harts that are not currently executing a MM context and instead
+ * schedule a deferred local instruction cache flush to be performed before
+ * execution resumes on each hart.
+ */
+void flush_icache_mm(struct mm_struct *mm, bool local)
+{
+	unsigned int cpu;
+	cpumask_t others, *mask;
+
+	preempt_disable();
+
+	/* Mark every hart's icache as needing a flush for this MM. */
+	mask = &mm->context.icache_stale_mask;
+	cpumask_setall(mask);
+	/* Flush this hart's I$ now, and mark it as flushed. */
+	cpu = smp_processor_id();
+	cpumask_clear_cpu(cpu, mask);
+	local_flush_icache_all();
+
+	/*
+	 * Flush the I$ of other harts concurrently executing, and mark them as
+	 * flushed.
+	 */
+	cpumask_andnot(&others, mm_cpumask(mm), cpumask_of(cpu));
+	local |= cpumask_empty(&others);
+	if (mm != current->active_mm || !local)
+		sbi_remote_fence_i(others.bits);
+	else {
+		/*
+		 * It's assumed that at least one strongly ordered operation is
+		 * performed on this hart between setting a hart's cpumask bit
+		 * and scheduling this MM context on that hart.  Sending an SBI
+		 * remote message will do this, but in the case where no
+		 * messages are sent we still need to order this hart's writes
+		 * with flush_icache_deferred().
+		 */
+		smp_mb();
+	}
+
+	preempt_enable();
+}

commit 4bde63286a6c7c76fe05ff0e03ad253f5260b104
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Nov 29 17:55:17 2017 -0800

    RISC-V: Provide stub of setup_profiling_timer()
    
    Fixes the following on allmodconfig build:
    
    profile.c:(.text+0x3e4): undefined reference to `setup_profiling_timer'
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Palmer Dabbelt <palmer@sifive.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
index b4a71ec5906f..17014c68e9fe 100644
--- a/arch/riscv/kernel/smp.c
+++ b/arch/riscv/kernel/smp.c
@@ -38,6 +38,13 @@ enum ipi_message_type {
 	IPI_MAX
 };
 
+
+/* Unsupported */
+int setup_profiling_timer(unsigned int multiplier)
+{
+	return -EINVAL;
+}
+
 irqreturn_t handle_ipi(void)
 {
 	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;

commit 76d2a0493a17d4c8ecc781366850c3c4f8e1a446
Author: Palmer Dabbelt <palmer@dabbelt.com>
Date:   Mon Jul 10 18:00:26 2017 -0700

    RISC-V: Init and Halt Code
    
    This contains the various __init C functions, the initial assembly
    kernel entry point, and the code to reset the system.  When a file was
    init-related this patch contains the entire file.
    
    Signed-off-by: Palmer Dabbelt <palmer@dabbelt.com>

diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c
new file mode 100644
index 000000000000..b4a71ec5906f
--- /dev/null
+++ b/arch/riscv/kernel/smp.c
@@ -0,0 +1,110 @@
+/*
+ * SMP initialisation and IPI support
+ * Based on arch/arm64/kernel/smp.c
+ *
+ * Copyright (C) 2012 ARM Ltd.
+ * Copyright (C) 2015 Regents of the University of California
+ * Copyright (C) 2017 SiFive
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/interrupt.h>
+#include <linux/smp.h>
+#include <linux/sched.h>
+
+#include <asm/sbi.h>
+#include <asm/tlbflush.h>
+#include <asm/cacheflush.h>
+
+/* A collection of single bit ipi messages.  */
+static struct {
+	unsigned long bits ____cacheline_aligned;
+} ipi_data[NR_CPUS] __cacheline_aligned;
+
+enum ipi_message_type {
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_MAX
+};
+
+irqreturn_t handle_ipi(void)
+{
+	unsigned long *pending_ipis = &ipi_data[smp_processor_id()].bits;
+
+	/* Clear pending IPI */
+	csr_clear(sip, SIE_SSIE);
+
+	while (true) {
+		unsigned long ops;
+
+		/* Order bit clearing and data access. */
+		mb();
+
+		ops = xchg(pending_ipis, 0);
+		if (ops == 0)
+			return IRQ_HANDLED;
+
+		if (ops & (1 << IPI_RESCHEDULE))
+			scheduler_ipi();
+
+		if (ops & (1 << IPI_CALL_FUNC))
+			generic_smp_call_function_interrupt();
+
+		BUG_ON((ops >> IPI_MAX) != 0);
+
+		/* Order data access and bit testing. */
+		mb();
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void
+send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
+{
+	int i;
+
+	mb();
+	for_each_cpu(i, to_whom)
+		set_bit(operation, &ipi_data[i].bits);
+
+	mb();
+	sbi_send_ipi(cpumask_bits(to_whom));
+}
+
+void arch_send_call_function_ipi_mask(struct cpumask *mask)
+{
+	send_ipi_message(mask, IPI_CALL_FUNC);
+}
+
+void arch_send_call_function_single_ipi(int cpu)
+{
+	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC);
+}
+
+static void ipi_stop(void *unused)
+{
+	while (1)
+		wait_for_interrupt();
+}
+
+void smp_send_stop(void)
+{
+	on_each_cpu(ipi_stop, NULL, 1);
+}
+
+void smp_send_reschedule(int cpu)
+{
+	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
+}
