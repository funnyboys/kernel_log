commit 3e4e28c5a8f01ee4174d639e36ed155ade489a6f
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:51 2020 -0700

    mmap locking API: convert mmap_sem API comments
    
    Convert comments that reference old mmap_sem APIs to reference
    corresponding new mmap locking APIs instead.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-12-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 9ef2dd39111e..01b168a90434 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -181,7 +181,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			flags |= FAULT_FLAG_TRIED;
 
 			/*
-			 * No need to up_read(&mm->mmap_sem) as we would
+			 * No need to mmap_read_unlock(mm) as we would
 			 * have already released it in __lock_page_or_retry
 			 * in mm/filemap.c.
 			 */

commit 89154dd5313f774d3a592451360b78442571b1f8
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:29 2020 -0700

    mmap locking API: convert mmap_sem call sites missed by coccinelle
    
    Convert the last few remaining mmap_sem rwsem calls to use the new mmap
    locking API.  These were missed by coccinelle for some reason (I think
    coccinelle does not support some of the preprocessor constructs in these
    files ?)
    
    [akpm@linux-foundation.org: convert linux-next leftovers]
    [akpm@linux-foundation.org: more linux-next leftovers]
    [akpm@linux-foundation.org: more linux-next leftovers]
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-6-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index f8d62cd83b36..9ef2dd39111e 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -97,7 +97,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	if (user_mode(regs))
 		flags |= FAULT_FLAG_USER;
 retry:
-	down_read(&mm->mmap_sem);
+	mmap_read_lock(mm);
 	vma = find_vma(mm, address);
 	if (!vma)
 		goto bad_area;
@@ -190,7 +190,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		}
 	}
 
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 	return;
 
 /*
@@ -198,7 +198,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
  * Fix it, but check if it's kernel or user first..
  */
 bad_area:
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 
 bad_area_nosemaphore:
 	/* User mode accesses just cause a SIGSEGV */
@@ -250,14 +250,14 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * We ran out of memory, call the OOM killer, and return the userspace
 	 * (which will retry the fault, or kill us if we got oom-killed).
 	 */
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 	if (!user_mode(regs))
 		goto no_context;
 	pagefault_out_of_memory();
 	return;
 
 do_sigbus:
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 
 	/* Kernel mode? Handle exceptions or die */
 	if (!user_mode(regs))

commit 5093c5872be3a041917828b2b53e9f981d754768
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Mon Apr 6 20:03:59 2020 -0700

    mm/vma: append unlikely() while testing VMA access permissions
    
    It is unlikely that an inaccessible VMA without required permission flags
    will get a page fault.  Hence lets just append unlikely() directive to
    such checks in order to improve performance while also standardizing it
    across various platforms.
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paulburton@kernel.org>
    Cc: Mike Rapoport <rppt@linux.ibm.com>
    Link: http://lkml.kernel.org/r/1582525304-32113-1-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index fb048ba2b91d..f8d62cd83b36 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -142,7 +142,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 				goto bad_area;
 			}
 		} else {
-			if (!vma_is_accessible(vma))
+			if (unlikely(!vma_is_accessible(vma)))
 				goto bad_area;
 		}
 	}

commit 3122e80efc0faf4a2accba7a46c7ed795edbfded
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Mon Apr 6 20:03:47 2020 -0700

    mm/vma: make vma_is_accessible() available for general use
    
    Lets move vma_is_accessible() helper to include/linux/mm.h which makes it
    available for general use.  While here, this replaces all remaining open
    encodings for VMA access check with vma_is_accessible().
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Acked-by: Guo Ren <guoren@kernel.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paulburton@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.ibm.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Nick Piggin <npiggin@gmail.com>
    Cc: Paul Mackerras <paulus@ozlabs.org>
    Cc: Will Deacon <will@kernel.org>
    Link: http://lkml.kernel.org/r/1582520593-30704-3-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 4a0eafe3d932..fb048ba2b91d 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -142,7 +142,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 				goto bad_area;
 			}
 		} else {
-			if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
+			if (!vma_is_accessible(vma))
 				goto bad_area;
 		}
 	}

commit 4064b982706375025628094e51d11cf1a958a5d3
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:45 2020 -0700

    mm: allow VM_FAULT_RETRY for multiple times
    
    The idea comes from a discussion between Linus and Andrea [1].
    
    Before this patch we only allow a page fault to retry once.  We achieved
    this by clearing the FAULT_FLAG_ALLOW_RETRY flag when doing
    handle_mm_fault() the second time.  This was majorly used to avoid
    unexpected starvation of the system by looping over forever to handle the
    page fault on a single page.  However that should hardly happen, and after
    all for each code path to return a VM_FAULT_RETRY we'll first wait for a
    condition (during which time we should possibly yield the cpu) to happen
    before VM_FAULT_RETRY is really returned.
    
    This patch removes the restriction by keeping the FAULT_FLAG_ALLOW_RETRY
    flag when we receive VM_FAULT_RETRY.  It means that the page fault handler
    now can retry the page fault for multiple times if necessary without the
    need to generate another page fault event.  Meanwhile we still keep the
    FAULT_FLAG_TRIED flag so page fault handler can still identify whether a
    page fault is the first attempt or not.
    
    Then we'll have these combinations of fault flags (only considering
    ALLOW_RETRY flag and TRIED flag):
    
      - ALLOW_RETRY and !TRIED:  this means the page fault allows to
                                 retry, and this is the first try
    
      - ALLOW_RETRY and TRIED:   this means the page fault allows to
                                 retry, and this is not the first try
    
      - !ALLOW_RETRY and !TRIED: this means the page fault does not allow
                                 to retry at all
    
      - !ALLOW_RETRY and TRIED:  this is forbidden and should never be used
    
    In existing code we have multiple places that has taken special care of
    the first condition above by checking against (fault_flags &
    FAULT_FLAG_ALLOW_RETRY).  This patch introduces a simple helper to detect
    the first retry of a page fault by checking against both (fault_flags &
    FAULT_FLAG_ALLOW_RETRY) and !(fault_flag & FAULT_FLAG_TRIED) because now
    even the 2nd try will have the ALLOW_RETRY set, then use that helper in
    all existing special paths.  One example is in __lock_page_or_retry(), now
    we'll drop the mmap_sem only in the first attempt of page fault and we'll
    keep it in follow up retries, so old locking behavior will be retained.
    
    This will be a nice enhancement for current code [2] at the same time a
    supporting material for the future userfaultfd-writeprotect work, since in
    that work there will always be an explicit userfault writeprotect retry
    for protected pages, and if that cannot resolve the page fault (e.g., when
    userfaultfd-writeprotect is used in conjunction with swapped pages) then
    we'll possibly need a 3rd retry of the page fault.  It might also benefit
    other potential users who will have similar requirement like userfault
    write-protection.
    
    GUP code is not touched yet and will be covered in follow up patch.
    
    Please read the thread below for more information.
    
    [1] https://lore.kernel.org/lkml/20171102193644.GB22686@redhat.com/
    [2] https://lore.kernel.org/lkml/20181230154648.GB9832@redhat.com/
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Suggested-by: Andrea Arcangeli <aarcange@redhat.com>
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160246.9790-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index ec464da64656..4a0eafe3d932 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -178,7 +178,6 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			tsk->min_flt++;
 		}
 		if (fault & VM_FAULT_RETRY) {
-			flags &= ~FAULT_FLAG_ALLOW_RETRY;
 			flags |= FAULT_FLAG_TRIED;
 
 			/*

commit dde1607248328cdb7570e3a252e8fb76b3411d66
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:37 2020 -0700

    mm: introduce FAULT_FLAG_DEFAULT
    
    Although there're tons of arch-specific page fault handlers, most of them
    are still sharing the same initial value of the page fault flags.  Say,
    merely all of the page fault handlers would allow the fault to be retried,
    and they also allow the fault to respond to SIGKILL.
    
    Let's define a default value for the fault flags to replace those initial
    page fault flags that were copied over.  With this, it'll be far easier to
    introduce new fault flag that can be used by all the architectures instead
    of touching all the archs.
    
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160238.9694-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 4b52f3d890ea..ec464da64656 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -44,7 +44,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	const int field = sizeof(unsigned long) * 2;
 	int si_code;
 	vm_fault_t fault;
-	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
+	unsigned int flags = FAULT_FLAG_DEFAULT;
 
 	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);
 

commit 4ef873226ceb9c7bf11a922caddc5698a24bcfaf
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:06 2020 -0700

    mm: introduce fault_signal_pending()
    
    For most architectures, we've got a quick path to detect fatal signal
    after a handle_mm_fault().  Introduce a helper for that quick path.
    
    It cleans the current codes a bit so we don't need to duplicate the same
    check across archs.  More importantly, this will be an unified place that
    we handle the signal immediately right after an interrupted page fault, so
    it'll be much easier for us if we want to change the behavior of handling
    signals later on for all the archs.
    
    Note that currently only part of the archs are using this new helper,
    because some archs have their own way to handle signals.  In the follow up
    patches, we'll try to apply this helper to all the rest of archs.
    
    Another note is that the "regs" parameter in the new helper is not used
    yet.  It'll be used very soon.  Now we kept it in this patch only to avoid
    touching all the archs again in the follow up patches.
    
    [peterx@redhat.com: fix sparse warnings]
      Link: http://lkml.kernel.org/r/20200311145921.GD479302@xz-x1
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220155353.8676-4-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 1e8d00793784..4b52f3d890ea 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -154,7 +154,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	 */
 	fault = handle_mm_fault(vma, address, flags);
 
-	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+	if (fault_signal_pending(fault, regs))
 		return;
 
 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);

commit 2bee1b58484f036e3e2dc657e524d095d0d332b3
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Nov 21 18:21:33 2019 +0200

    mips: add support for folded p4d page tables
    
    Implement primitives necessary for the 4th level folding, add walks of p4d
    level where appropriate, replace 5leve-fixup.h with pgtable-nop4d.h and
    drop usage of __ARCH_USE_5LEVEL_HACK.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Paul Burton <paulburton@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: Mike Rapoport <rppt@kernel.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 524af96c8131..1e8d00793784 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -294,6 +294,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		 */
 		int offset = pgd_index(address);
 		pgd_t *pgd, *pgd_k;
+		p4d_t *p4d, *p4d_k;
 		pud_t *pud, *pud_k;
 		pmd_t *pmd, *pmd_k;
 		pte_t *pte_k;
@@ -305,8 +306,13 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			goto no_context;
 		set_pgd(pgd, *pgd_k);
 
-		pud = pud_offset(pgd, address);
-		pud_k = pud_offset(pgd_k, address);
+		p4d = p4d_offset(pgd, address);
+		p4d_k = p4d_offset(pgd_k, address);
+		if (!p4d_present(*p4d_k))
+			goto no_context;
+
+		pud = pud_offset(p4d, address);
+		pud_k = pud_offset(p4d_k, address);
 		if (!pud_present(*pud_k))
 			goto no_context;
 

commit 31168f033e3751d1c9245d9ee847d775af16dcd6
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Nov 21 18:21:32 2019 +0200

    mips: drop __pXd_offset() macros that duplicate pXd_index() ones
    
    The __pXd_offset() macros are identical to the pXd_index() macros and there
    is no point to keep both of them. All architectures define and use
    pXd_index() so let's keep only those to make mips consistent with the rest
    of the kernel.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Paul Burton <paulburton@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Cc: Mike Rapoport <rppt@kernel.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index f589aa8f47d9..524af96c8131 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -292,7 +292,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		 * Do _not_ use "tsk" here. We might be inside
 		 * an interrupt in the middle of a task switch..
 		 */
-		int offset = __pgd_offset(address);
+		int offset = pgd_index(address);
 		pgd_t *pgd, *pgd_k;
 		pud_t *pud, *pud_k;
 		pmd_t *pmd, *pmd_k;

commit 2e1661d2673667d886cd40ad9f414cb6db48d8da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 11:04:24 2019 -0500

    signal: Remove the task parameter from force_sig_fault
    
    As synchronous exceptions really only make sense against the current
    task (otherwise how are you synchronous) remove the task parameter
    from from force_sig_fault to make it explicit that is what is going
    on.
    
    The two known exceptions that deliver a synchronous exception to a
    stopped ptraced task have already been changed to
    force_sig_fault_to_task.
    
    The callers have been changed with the following emacs regular expression
    (with obvious variations on the architectures that take more arguments)
    to avoid typos:
    
    force_sig_fault[(]\([^,]+\)[,]\([^,]+\)[,]\([^,]+\)[,]\W+current[)]
    ->
    force_sig_fault(\1,\2,\3)
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index e63abd492f65..f589aa8f47d9 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -223,7 +223,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			pr_cont("\n");
 		}
 		current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
-		force_sig_fault(SIGSEGV, si_code, (void __user *)address, current);
+		force_sig_fault(SIGSEGV, si_code, (void __user *)address);
 		return;
 	}
 
@@ -279,7 +279,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 #endif
 	current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 	tsk->thread.cp0_badvaddr = address;
-	force_sig_fault(SIGBUS, BUS_ADRERR, (void __user *)address, current);
+	force_sig_fault(SIGBUS, BUS_ADRERR, (void __user *)address);
 
 	return;
 #ifndef CONFIG_64BIT

commit 351b6825b3a9f70bab080fba67aec104ff9a41d6
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Feb 7 09:25:08 2019 -0600

    signal: Explicitly call force_sig_fault on current
    
    Update the calls of force_sig_fault that pass in a variable that is
    set to current earlier to explicitly use current.
    
    This is to make the next change that removes the task parameter
    from force_sig_fault easier to verify.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 73d8a0f0b810..e63abd492f65 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -223,7 +223,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			pr_cont("\n");
 		}
 		current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
-		force_sig_fault(SIGSEGV, si_code, (void __user *)address, tsk);
+		force_sig_fault(SIGSEGV, si_code, (void __user *)address, current);
 		return;
 	}
 
@@ -279,7 +279,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 #endif
 	current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 	tsk->thread.cp0_badvaddr = address;
-	force_sig_fault(SIGBUS, BUS_ADRERR, (void __user *)address, tsk);
+	force_sig_fault(SIGBUS, BUS_ADRERR, (void __user *)address, current);
 
 	return;
 #ifndef CONFIG_64BIT

commit 50a7ca3c6fc86955f99fc432fc8a186b968b365b
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Fri Aug 17 15:44:47 2018 -0700

    mm: convert return type of handle_mm_fault() caller to vm_fault_t
    
    Use new return type vm_fault_t for fault handler.  For now, this is just
    documenting that the function returns a VM_FAULT value rather than an
    errno.  Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Ref-> commit 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    In this patch all the caller of handle_mm_fault() are changed to return
    vm_fault_t type.
    
    Link: http://lkml.kernel.org/r/20180617084810.GA6730@jordon-HP-15-Notebook-PC
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Levin, Alexander (Sasha Levin)" <alexander.levin@verizon.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 5f71f2b903b7..73d8a0f0b810 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -43,7 +43,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	struct mm_struct *mm = tsk->mm;
 	const int field = sizeof(unsigned long) * 2;
 	int si_code;
-	int fault;
+	vm_fault_t fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);

commit f43a54a0d9168dec3b954dcb1b0b7cd740790739
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 15 21:11:06 2018 -0500

    signal/mips: Use force_sig_fault where appropriate
    
    Filling in struct siginfo before calling force_sig_info a tedious and
    error prone process, where once in a great while the wrong fields
    are filled out, and siginfo has been inconsistently cleared.
    
    Simplify this process by using the helper force_sig_fault.  Which
    takes as a parameters all of the information it needs, ensures
    all of the fiddly bits of filling in struct siginfo are done properly
    and then calls force_sig_info.
    
    In short about a 5 line reduction in code for every time force_sig_info
    is called, which makes the calling function clearer.
    
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 75392becd933..5f71f2b903b7 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -42,7 +42,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
 	const int field = sizeof(unsigned long) * 2;
-	siginfo_t info;
+	int si_code;
 	int fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
@@ -63,8 +63,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		return;
 #endif
 
-	clear_siginfo(&info);
-	info.si_code = SEGV_MAPERR;
+	si_code = SEGV_MAPERR;
 
 	/*
 	 * We fault-in kernel-space virtual memory on-demand. The
@@ -113,7 +112,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
  * we can handle it..
  */
 good_area:
-	info.si_code = SEGV_ACCERR;
+	si_code = SEGV_ACCERR;
 
 	if (write) {
 		if (!(vma->vm_flags & VM_WRITE))
@@ -224,11 +223,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			pr_cont("\n");
 		}
 		current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
-		info.si_signo = SIGSEGV;
-		info.si_errno = 0;
-		/* info.si_code has been set above */
-		info.si_addr = (void __user *) address;
-		force_sig_info(SIGSEGV, &info, tsk);
+		force_sig_fault(SIGSEGV, si_code, (void __user *)address, tsk);
 		return;
 	}
 
@@ -284,11 +279,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 #endif
 	current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 	tsk->thread.cp0_badvaddr = address;
-	info.si_signo = SIGBUS;
-	info.si_errno = 0;
-	info.si_code = BUS_ADRERR;
-	info.si_addr = (void __user *) address;
-	force_sig_info(SIGBUS, &info, tsk);
+	force_sig_fault(SIGBUS, BUS_ADRERR, (void __user *)address, tsk);
 
 	return;
 #ifndef CONFIG_64BIT

commit 3eb0f5193b497083391aa05d35210d5645211eef
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 17 15:26:37 2018 -0500

    signal: Ensure every siginfo we send has all bits initialized
    
    Call clear_siginfo to ensure every stack allocated siginfo is properly
    initialized before being passed to the signal sending functions.
    
    Note: It is not safe to depend on C initializers to initialize struct
    siginfo on the stack because C is allowed to skip holes when
    initializing a structure.
    
    The initialization of struct siginfo in tracehook_report_syscall_exit
    was moved from the helper user_single_step_siginfo into
    tracehook_report_syscall_exit itself, to make it clear that the local
    variable siginfo gets fully initialized.
    
    In a few cases the scope of struct siginfo has been reduced to make it
    clear that siginfo siginfo is not used on other paths in the function
    in which it is declared.
    
    Instances of using memset to initialize siginfo have been replaced
    with calls clear_siginfo for clarity.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 4f8f5bf46977..75392becd933 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -63,6 +63,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		return;
 #endif
 
+	clear_siginfo(&info);
 	info.si_code = SEGV_MAPERR;
 
 	/*

commit 72f941af88a543e6a038c75b8467903b7812239c
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Thu Mar 30 14:27:02 2017 -0700

    MIPS: Remove confusing else statement in __do_page_fault()
    
    Commit 41c594ab65fc ("[MIPS] MT: Improved multithreading support.")
    added an else case to an if statement in do_page_fault() (which has
    since gained 2 leading underscores) for some unclear reason. If the
    condition in the if statement evaluates true then we execute a goto &
    branch elsewhere anyway, so the else has no effect. Combined with an #if
    0 block with misleading indentation introduced in the same commit it
    makes the code less clear than it could be.
    
    Remove the unnecessary else statement & de-indent the printk within
    the #if 0 block in order to make the code easier for humans to parse.
    
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Cc: trivial@kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/15842/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 3bef306cdfdb..4f8f5bf46977 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -267,19 +267,19 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	/* Kernel mode? Handle exceptions or die */
 	if (!user_mode(regs))
 		goto no_context;
-	else
+
 	/*
 	 * Send a sigbus, regardless of whether we were in kernel
 	 * or user mode.
 	 */
 #if 0
-		printk("do_page_fault() #3: sending SIGBUS to %s for "
-		       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
-		       tsk->comm,
-		       write ? "write access to" : "read access from",
-		       field, address,
-		       field, (unsigned long) regs->cp0_epc,
-		       field, (unsigned long) regs->regs[31]);
+	printk("do_page_fault() #3: sending SIGBUS to %s for "
+	       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
+	       tsk->comm,
+	       write ? "write access to" : "read access from",
+	       field, address,
+	       field, (unsigned long) regs->cp0_epc,
+	       field, (unsigned long) regs->regs[31]);
 #endif
 	current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 	tsk->thread.cp0_badvaddr = address;

commit 2a872a5dcec7052e9fd948ee77a62187791735ff
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Wed Nov 9 13:26:25 2016 +0000

    MIPS: mm: Fix output of __do_page_fault
    
    Since commit 4bcc595ccd80 ("printk: reinstate KERN_CONT for printing
    continuation lines") the output from __do_page_fault on MIPS has been
    pretty unreadable due to the lack of KERN_CONT markers. Use pr_cont
    to provide the appropriate markers & restore the expected output.
    
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/14544/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index d56a855828c2..3bef306cdfdb 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -209,17 +209,18 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		if (show_unhandled_signals &&
 		    unhandled_signal(tsk, SIGSEGV) &&
 		    __ratelimit(&ratelimit_state)) {
-			pr_info("\ndo_page_fault(): sending SIGSEGV to %s for invalid %s %0*lx",
+			pr_info("do_page_fault(): sending SIGSEGV to %s for invalid %s %0*lx\n",
 				tsk->comm,
 				write ? "write access to" : "read access from",
 				field, address);
 			pr_info("epc = %0*lx in", field,
 				(unsigned long) regs->cp0_epc);
-			print_vma_addr(" ", regs->cp0_epc);
+			print_vma_addr(KERN_CONT " ", regs->cp0_epc);
+			pr_cont("\n");
 			pr_info("ra  = %0*lx in", field,
 				(unsigned long) regs->regs[31]);
-			print_vma_addr(" ", regs->regs[31]);
-			pr_info("\n");
+			print_vma_addr(KERN_CONT " ", regs->regs[31]);
+			pr_cont("\n");
 		}
 		current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 		info.si_signo = SIGSEGV;

commit d9ba57780637bfde6ac1efb65a8685231ffbc715
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sun Aug 21 15:58:14 2016 -0400

    MIPS: mm: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.  The advantage
    in doing so is that module.h itself sources about 15 other headers;
    adding significantly to what we feed cpp, and it can obscure what
    headers we are effectively using.
    
    Since module.h was the source for init.h (for __init) and for
    export.h (for EXPORT_SYMBOL) we consider each obj-y/bool instance
    for the presence of either and replace as needed.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/14033/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 9560ad731120..d56a855828c2 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -18,7 +18,6 @@
 #include <linux/mman.h>
 #include <linux/mm.h>
 #include <linux/smp.h>
-#include <linux/module.h>
 #include <linux/kprobes.h>
 #include <linux/perf_event.h>
 #include <linux/uaccess.h>

commit dcddffd41d3f1d3bdcc1dce3f1cd142779b6d4c1
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:25:18 2016 -0700

    mm: do not pass mm_struct into handle_mm_fault
    
    We always have vma->vm_mm around.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-8-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 4b88fa031891..9560ad731120 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -153,7 +153,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * make sure we exit gracefully rather than endlessly redo
 	 * the fault.
 	 */
-	fault = handle_mm_fault(mm, vma, address, flags);
+	fault = handle_mm_fault(vma, address, flags);
 
 	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
 		return;

commit e3b28831c18c6c95c51b6bb717fa116d2b658ba9
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jul 28 20:37:43 2015 +0200

    MIPS: Set trap_no field in thread_struct on exception.
    
    This reverts commit 7281cd22973008a782860e48ed8d85d00204168c and adds
    actual functionality to use the field.

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 852a41c6da45..4b88fa031891 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -57,12 +57,10 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 
 #ifdef CONFIG_KPROBES
 	/*
-	 * This is to notify the fault handler of the kprobes.	The
-	 * exception code is redundant as it is also carried in REGS,
-	 * but we pass it anyhow.
+	 * This is to notify the fault handler of the kprobes.
 	 */
 	if (notify_die(DIE_PAGE_FAULT, "page fault", regs, -1,
-		       (regs->cp0_cause >> 2) & 0x1f, SIGSEGV) == NOTIFY_STOP)
+		       current->thread.trap_nr, SIGSEGV) == NOTIFY_STOP)
 		return;
 #endif
 
@@ -224,6 +222,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 			print_vma_addr(" ", regs->regs[31]);
 			pr_info("\n");
 		}
+		current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 		info.si_signo = SIGSEGV;
 		info.si_errno = 0;
 		/* info.si_code has been set above */
@@ -282,6 +281,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 		       field, (unsigned long) regs->cp0_epc,
 		       field, (unsigned long) regs->regs[31]);
 #endif
+	current->thread.trap_nr = (regs->cp0_cause >> 2) & 0x1f;
 	tsk->thread.cp0_badvaddr = address;
 	info.si_signo = SIGBUS;
 	info.si_errno = 0;

commit e070dab73523bcbf2409ba8b5c342d53bccc0959
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Thu Jul 23 11:10:38 2015 +0200

    MIPS: Handle page faults of executable but unreadable pages correctly.
    
    Without this we end taking execeptions in an endless loop hanging the
    thread.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 36c0f26fac6b..852a41c6da45 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -133,7 +133,8 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 #endif
 				goto bad_area;
 			}
-			if (!(vma->vm_flags & VM_READ)) {
+			if (!(vma->vm_flags & VM_READ) &&
+			    exception_epc(regs) != address) {
 #if 0
 				pr_notice("Cpu%d[%s:%d:%0*lx:%ld:%0*lx] RI violation\n",
 					  raw_smp_processor_id(),

commit 70ffdb9393a7264a069265edded729078dcf0425
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Mon May 11 17:52:11 2015 +0200

    mm/fault, arch: Use pagefault_disable() to check for disabled pagefaults in the handler
    
    Introduce faulthandler_disabled() and use it to check for irq context and
    disabled pagefaults (via pagefault_disable()) in the pagefault handlers.
    
    Please note that we keep the in_atomic() checks in place - to detect
    whether in irq context (in which case preemption is always properly
    disabled).
    
    In contrast, preempt_disable() should never be used to disable pagefaults.
    With !CONFIG_PREEMPT_COUNT, preempt_disable() doesn't modify the preempt
    counter, and therefore the result of in_atomic() differs.
    We validate that condition by using might_fault() checks when calling
    might_sleep().
    
    Therefore, add a comment to faulthandler_disabled(), describing why this
    is needed.
    
    faulthandler_disabled() and pagefault_disable() are defined in
    linux/uaccess.h, so let's properly add that include to all relevant files.
    
    This patch is based on a patch from Thomas Gleixner.
    
    Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David.Laight@ACULAB.COM
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: airlied@linux.ie
    Cc: akpm@linux-foundation.org
    Cc: benh@kernel.crashing.org
    Cc: bigeasy@linutronix.de
    Cc: borntraeger@de.ibm.com
    Cc: daniel.vetter@intel.com
    Cc: heiko.carstens@de.ibm.com
    Cc: herbert@gondor.apana.org.au
    Cc: hocko@suse.cz
    Cc: hughd@google.com
    Cc: mst@redhat.com
    Cc: paulus@samba.org
    Cc: ralf@linux-mips.org
    Cc: schwidefsky@de.ibm.com
    Cc: yang.shi@windriver.com
    Link: http://lkml.kernel.org/r/1431359540-32227-7-git-send-email-dahi@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 7ff8637e530d..36c0f26fac6b 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -21,10 +21,10 @@
 #include <linux/module.h>
 #include <linux/kprobes.h>
 #include <linux/perf_event.h>
+#include <linux/uaccess.h>
 
 #include <asm/branch.h>
 #include <asm/mmu_context.h>
-#include <asm/uaccess.h>
 #include <asm/ptrace.h>
 #include <asm/highmem.h>		/* For VMALLOC_END */
 #include <linux/kdebug.h>
@@ -94,7 +94,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
 	 */
-	if (in_atomic() || !mm)
+	if (faulthandler_disabled() || !mm)
 		goto bad_area_nosemaphore;
 
 	if (user_mode(regs))

commit a135c717d5cdb311cff7661af4c17fef0562e590
Merge: 217703323308 44923c9cfa1a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 21 19:41:38 2015 -0800

    Merge branch 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus
    
    Pull MIPS updates from Ralf Baechle:
     "This is the main pull request for MIPS:
    
       - a number of fixes that didn't make the 3.19 release.
    
       - a number of cleanups.
    
       - preliminary support for Cavium's Octeon 3 SOCs which feature up to
         48 MIPS64 R3 cores with FPU and hardware virtualization.
    
       - support for MIPS R6 processors.
    
         Revision 6 of the MIPS architecture is a major revision of the MIPS
         architecture which does away with many of original sins of the
         architecture such as branch delay slots.  This and other changes in
         R6 require major changes throughout the entire MIPS core
         architecture code and make up for the lion share of this pull
         request.
    
       - finally some preparatory work for eXtendend Physical Address
         support, which allows support of up to 40 bit of physical address
         space on 32 bit processors"
    
         [ Ahh, MIPS can't leave the PAE brain damage alone.  It's like
           every CPU architect has to make that mistake, but pee in the snow
           by changing the TLA.  But whether it's called PAE, LPAE or XPA,
           it's horrid crud   - Linus ]
    
    * 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus: (114 commits)
      MIPS: sead3: Corrected get_c0_perfcount_int
      MIPS: mm: Remove dead macro definitions
      MIPS: OCTEON: irq: add CIB and other fixes
      MIPS: OCTEON: Don't do acknowledge operations for level triggered irqs.
      MIPS: OCTEON: More OCTEONIII support
      MIPS: OCTEON: Remove setting of processor specific CVMCTL icache bits.
      MIPS: OCTEON: Core-15169 Workaround and general CVMSEG cleanup.
      MIPS: OCTEON: Update octeon-model.h code for new SoCs.
      MIPS: OCTEON: Implement DCache errata workaround for all CN6XXX
      MIPS: OCTEON: Add little-endian support to asm/octeon/octeon.h
      MIPS: OCTEON: Implement the core-16057 workaround
      MIPS: OCTEON: Delete unused COP2 saving code
      MIPS: OCTEON: Use correct instruction to read 64-bit COP0 register
      MIPS: OCTEON: Save and restore CP2 SHA3 state
      MIPS: OCTEON: Fix FP context save.
      MIPS: OCTEON: Save/Restore wider multiply registers in OCTEON III CPUs
      MIPS: boot: Provide more uImage options
      MIPS: Remove unneeded #ifdef __KERNEL__ from asm/processor.h
      MIPS: ip22-gio: Remove legacy suspend/resume support
      mips: pci: Add ifdef around pci_proc_domain
      ...

commit d79d853df126553f9a185151e310f6dc74205ae5
Author: Markos Chandras <markos.chandras@imgtec.com>
Date:   Wed Jan 21 10:54:46 2015 +0000

    MIPS: mm: Add debug information for userland SIGSEGV signals.
    
    Commit 41c594ab65fc ("[MIPS] MT: Improved multithreading support.")
    removed useful debug information for userland segmentation faults.
    This patch bring this back along with the ability to determine the
    name of the object file where the EPC and RA registers point at.
    Furthermore, we select the SYSCTL_EXCEPTION_TRACE symbol for MIPS
    which is the de facto solution to turn userland exception logging
    on and off via the /proc/sys/debug/exception-trace file.
    
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/9089/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index becc42bb1849..ef10886dda46 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -14,6 +14,7 @@
 #include <linux/string.h>
 #include <linux/types.h>
 #include <linux/ptrace.h>
+#include <linux/ratelimit.h>
 #include <linux/mman.h>
 #include <linux/mm.h>
 #include <linux/smp.h>
@@ -28,6 +29,8 @@
 #include <asm/highmem.h>		/* For VMALLOC_END */
 #include <linux/kdebug.h>
 
+int show_unhandled_signals = 1;
+
 /*
  * This routine handles page faults.  It determines the address,
  * and the problem, and then passes it off to one of the appropriate
@@ -44,6 +47,8 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	int fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
+	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);
+
 #if 0
 	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
 	       current->comm, current->pid, field, address, write,
@@ -201,15 +206,21 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	if (user_mode(regs)) {
 		tsk->thread.cp0_badvaddr = address;
 		tsk->thread.error_code = write;
-#if 0
-		printk("do_page_fault() #2: sending SIGSEGV to %s for "
-		       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
-		       tsk->comm,
-		       write ? "write access to" : "read access from",
-		       field, address,
-		       field, (unsigned long) regs->cp0_epc,
-		       field, (unsigned long) regs->regs[31]);
-#endif
+		if (show_unhandled_signals &&
+		    unhandled_signal(tsk, SIGSEGV) &&
+		    __ratelimit(&ratelimit_state)) {
+			pr_info("\ndo_page_fault(): sending SIGSEGV to %s for invalid %s %0*lx",
+				tsk->comm,
+				write ? "write access to" : "read access from",
+				field, address);
+			pr_info("epc = %0*lx in", field,
+				(unsigned long) regs->cp0_epc);
+			print_vma_addr(" ", regs->cp0_epc);
+			pr_info("ra  = %0*lx in", field,
+				(unsigned long) regs->regs[31]);
+			print_vma_addr(" ", regs->regs[31]);
+			pr_info("\n");
+		}
 		info.si_signo = SIGSEGV;
 		info.si_errno = 0;
 		/* info.si_code has been set above */

commit 33692f27597fcab536d7cbbcc8f52905133e4aa7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 29 10:51:32 2015 -0800

    vm: add VM_FAULT_SIGSEGV handling support
    
    The core VM already knows about VM_FAULT_SIGBUS, but cannot return a
    "you should SIGSEGV" error, because the SIGSEGV case was generally
    handled by the caller - usually the architecture fault handler.
    
    That results in lots of duplication - all the architecture fault
    handlers end up doing very similar "look up vma, check permissions, do
    retries etc" - but it generally works.  However, there are cases where
    the VM actually wants to SIGSEGV, and applications _expect_ SIGSEGV.
    
    In particular, when accessing the stack guard page, libsigsegv expects a
    SIGSEGV.  And it usually got one, because the stack growth is handled by
    that duplicated architecture fault handler.
    
    However, when the generic VM layer started propagating the error return
    from the stack expansion in commit fee7e49d4514 ("mm: propagate error
    from stack expansion even for guard page"), that now exposed the
    existing VM_FAULT_SIGBUS result to user space.  And user space really
    expected SIGSEGV, not SIGBUS.
    
    To fix that case, we need to add a VM_FAULT_SIGSEGV, and teach all those
    duplicate architecture fault handlers about it.  They all already have
    the code to handle SIGSEGV, so it's about just tying that new return
    value to the existing code, but it's all a bit annoying.
    
    This is the mindless minimal patch to do this.  A more extensive patch
    would be to try to gather up the mostly shared fault handling logic into
    one generic helper routine, and long-term we really should do that
    cleanup.
    
    Just from this patch, you can generally see that most architectures just
    copied (directly or indirectly) the old x86 way of doing things, but in
    the meantime that original x86 model has been improved to hold the VM
    semaphore for shorter times etc and to handle VM_FAULT_RETRY and other
    "newer" things, so it would be a good idea to bring all those
    improvements to the generic case and teach other architectures about
    them too.
    
    Reported-and-tested-by: Takashi Iwai <tiwai@suse.de>
    Tested-by: Jan Engelhardt <jengelh@inai.de>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com> # "s390 still compiles and boots"
    Cc: linux-arch@vger.kernel.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index becc42bb1849..70ab5d664332 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -158,6 +158,8 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
+		else if (fault & VM_FAULT_SIGSEGV)
+			goto bad_area;
 		else if (fault & VM_FAULT_SIGBUS)
 			goto do_sigbus;
 		BUG();

commit 759496ba6407c6994d6a5ce3a5e74937d7816208
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Sep 12 15:13:39 2013 -0700

    arch: mm: pass userspace fault flag to generic fault handler
    
    Unlike global OOM handling, memory cgroup code will invoke the OOM killer
    in any OOM situation because it has no way of telling faults occuring in
    kernel context - which could be handled more gracefully - from
    user-triggered faults.
    
    Pass a flag that identifies faults originating in user space from the
    architecture-specific fault handlers to generic code so that memcg OOM
    handling can be improved.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: azurIt <azurit@pobox.sk>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 94d3a31ab144..becc42bb1849 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -42,8 +42,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	const int field = sizeof(unsigned long) * 2;
 	siginfo_t info;
 	int fault;
-	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |
-						 (write ? FAULT_FLAG_WRITE : 0);
+	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 #if 0
 	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
@@ -93,6 +92,8 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	if (in_atomic() || !mm)
 		goto bad_area_nosemaphore;
 
+	if (user_mode(regs))
+		flags |= FAULT_FLAG_USER;
 retry:
 	down_read(&mm->mmap_sem);
 	vma = find_vma(mm, address);
@@ -114,6 +115,7 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	if (write) {
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
+		flags |= FAULT_FLAG_WRITE;
 	} else {
 		if (cpu_has_rixi) {
 			if (address == regs->cp0_epc && !(vma->vm_flags & VM_EXEC)) {

commit 871341023c771ad233620b7a1fb3d9c7031c4e5c
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Sep 12 15:13:38 2013 -0700

    arch: mm: do not invoke OOM killer on kernel fault OOM
    
    Kernel faults are expected to handle OOM conditions gracefully (gup,
    uaccess etc.), so they should never invoke the OOM killer.  Reserve this
    for faults triggered in user context when it is the only option.
    
    Most architectures already do this, fix up the remaining few.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: azurIt <azurit@pobox.sk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 85df1cd8d446..94d3a31ab144 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -241,6 +241,8 @@ static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * (which will retry the fault, or kill us if we got oom-killed).
 	 */
 	up_read(&mm->mmap_sem);
+	if (!user_mode(regs))
+		goto no_context;
 	pagefault_out_of_memory();
 	return;
 

commit c3fc5cd5c5a5f4738776a965a020a32c1a37c8fd
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Wed May 29 01:07:19 2013 +0200

    MIPS: Implement HAVE_CONTEXT_TRACKING.
    
    This enables support for CONFIG_NO_HZ_FULL.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 0fead53d1c26..85df1cd8d446 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -5,6 +5,7 @@
  *
  * Copyright (C) 1995 - 2000 by Ralf Baechle
  */
+#include <linux/context_tracking.h>
 #include <linux/signal.h>
 #include <linux/sched.h>
 #include <linux/interrupt.h>
@@ -32,8 +33,8 @@
  * and the problem, and then passes it off to one of the appropriate
  * routines.
  */
-asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long write,
-			      unsigned long address)
+static void __kprobes __do_page_fault(struct pt_regs *regs, unsigned long write,
+	unsigned long address)
 {
 	struct vm_area_struct * vma = NULL;
 	struct task_struct *tsk = current;
@@ -312,3 +313,13 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	}
 #endif
 }
+
+asmlinkage void __kprobes do_page_fault(struct pt_regs *regs,
+	unsigned long write, unsigned long address)
+{
+	enum ctx_state prev_state;
+
+	prev_state = exception_enter();
+	__do_page_fault(regs, write, address);
+	exception_exit(prev_state);
+}

commit 7034228792cc561e79ff8600f02884bd4c80e287
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jan 22 12:59:30 2013 +0100

    MIPS: Whitespace cleanup.
    
    Having received another series of whitespace patches I decided to do this
    once and for all rather than dealing with this kind of patches trickling
    in forever.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index ddcec1e1a0cd..0fead53d1c26 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -52,7 +52,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 
 #ifdef CONFIG_KPROBES
 	/*
-	 * This is to notify the fault handler of the kprobes.  The
+	 * This is to notify the fault handler of the kprobes.	The
 	 * exception code is redundant as it is also carried in REGS,
 	 * but we pass it anyhow.
 	 */
@@ -216,7 +216,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	}
 
 no_context:
-	/* Are we prepared to handle this kernel fault?  */
+	/* Are we prepared to handle this kernel fault?	 */
 	if (fixup_exception(regs)) {
 		current->thread.cp0_baduaddr = address;
 		return;

commit 9e2d8656f5e8aa214e66b462680cf86b210b74a8
Merge: 1ea4f4f8405c 9e695d2ecc84
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 9 16:23:15 2012 +0900

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge patches from Andrew Morton:
     "A few misc things and very nearly all of the MM tree.  A tremendous
      amount of stuff (again), including a significant rbtree library
      rework."
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (160 commits)
      sparc64: Support transparent huge pages.
      mm: thp: Use more portable PMD clearing sequenece in zap_huge_pmd().
      mm: Add and use update_mmu_cache_pmd() in transparent huge page code.
      sparc64: Document PGD and PMD layout.
      sparc64: Eliminate PTE table memory wastage.
      sparc64: Halve the size of PTE tables
      sparc64: Only support 4MB huge pages and 8KB base pages.
      memory-hotplug: suppress "Trying to free nonexistent resource <XXXXXXXXXXXXXXXX-YYYYYYYYYYYYYYYY>" warning
      mm: memcg: clean up mm_match_cgroup() signature
      mm: document PageHuge somewhat
      mm: use %pK for /proc/vmallocinfo
      mm, thp: fix mlock statistics
      mm, thp: fix mapped pages avoiding unevictable list on mlock
      memory-hotplug: update memory block's state and notify userspace
      memory-hotplug: preparation to notify memory block's state at memory hot remove
      mm: avoid section mismatch warning for memblock_type_name
      make GFP_NOTRACK definition unconditional
      cma: decrease cc.nr_migratepages after reclaiming pagelist
      CMA: migrate mlocked pages
      kpageflags: fix wrong KPF_THP on non-huge compound pages
      ...

commit 45cac65b0fcd287ebb877b141d40ba9bbe8e5da7
Author: Shaohua Li <shli@kernel.org>
Date:   Mon Oct 8 16:32:19 2012 -0700

    readahead: fault retry breaks mmap file read random detection
    
    .fault now can retry.  The retry can break state machine of .fault.  In
    filemap_fault, if page is miss, ra->mmap_miss is increased.  In the second
    try, since the page is in page cache now, ra->mmap_miss is decreased.  And
    these are done in one fault, so we can't detect random mmap file access.
    
    Add a new flag to indicate .fault is tried once.  In the second try, skip
    ra->mmap_miss decreasing.  The filemap_fault state machine is ok with it.
    
    I only tested x86, didn't test other archs, but looks the change for other
    archs is obvious, but who knows :)
    
    Signed-off-by: Shaohua Li <shaohua.li@fusionio.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index c14f6dfed995..9f513486af10 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -171,6 +171,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 		}
 		if (fault & VM_FAULT_RETRY) {
 			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+			flags |= FAULT_FLAG_TRIED;
 
 			/*
 			 * No need to up_read(&mm->mmap_sem) as we would

commit 05857c64ecf897209c16ffad9bb3e8d359dd5dca
Author: Steven J. Hill <sjhill@mips.com>
Date:   Thu Sep 13 16:51:46 2012 -0500

    MIPS: Replace 'kernel_uses_smartmips_rixi' with 'cpu_has_rixi'.
    
    Remove usage of the 'kernel_uses_smartmips_rixi' macro from all files
    and use new 'cpu_has_rixi' instead.
    
    Signed-off-by: Steven J. Hill <sjhill@mips.com>
    Acked-by: David Daney <david.daney@cavium.com>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index c14f6dfed995..7a19957735e9 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -114,7 +114,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
-		if (kernel_uses_smartmips_rixi) {
+		if (cpu_has_rixi) {
 			if (address == regs->cp0_epc && !(vma->vm_flags & VM_EXEC)) {
 #if 0
 				pr_notice("Cpu%d[%s:%d:%0*lx:%ld:%0*lx] XI violation\n",

commit b81947c646bfefdf98e2fde5d7d39cbbda8525d4
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for MIPS
    
    Disintegrate asm/system.h for MIPS.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    cc: linux-mips@linux-mips.org

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 69ebd586d7ff..c14f6dfed995 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -22,7 +22,6 @@
 
 #include <asm/branch.h>
 #include <asm/mmu_context.h>
-#include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/ptrace.h>
 #include <asm/highmem.h>		/* For VMALLOC_END */

commit 43ca4957a15a120d0822a60a22998dbb41bbf075
Author: Kautuk Consul <consul.kautuk@gmail.com>
Date:   Fri Dec 23 16:52:42 2011 +0530

    MIPS: fault.c: Port OOM changes to do_page_fault
    
    Commit d065bd810b6deb67d4897a14bfe21f8eb526ba99
    (mm: retry page fault when blocking on disk transfer) and
    commit 37b23e0525d393d48a7d59f870b3bc061a30ccdb
    (x86,mm: make pagefault killable)
    
    The above commits introduced changes into the x86 pagefault handler
    for making the page fault handler retryable as well as killable.
    
    These changes reduce the mmap_sem hold time, which is crucial
    during OOM killer invocation.
    
    Port these changes to MIPS.
    
    Without these changes, my MIPS board encounters many hang and livelock
    scenarios.
    After applying this patch, OOM feature performance improves according to
    my testing.
    
    Signed-off-by: Mohd. Faris <mohdfarisq2010@gmail.com>
    Signed-off-by: Kautuk Consul <consul.kautuk@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/3217/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 937cf3368164..69ebd586d7ff 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -42,6 +42,8 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	const int field = sizeof(unsigned long) * 2;
 	siginfo_t info;
 	int fault;
+	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |
+						 (write ? FAULT_FLAG_WRITE : 0);
 
 #if 0
 	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
@@ -91,6 +93,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	if (in_atomic() || !mm)
 		goto bad_area_nosemaphore;
 
+retry:
 	down_read(&mm->mmap_sem);
 	vma = find_vma(mm, address);
 	if (!vma)
@@ -144,7 +147,11 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	 * make sure we exit gracefully rather than endlessly redo
 	 * the fault.
 	 */
-	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
+	fault = handle_mm_fault(mm, vma, address, flags);
+
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+		return;
+
 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
@@ -153,12 +160,27 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 			goto do_sigbus;
 		BUG();
 	}
-	if (fault & VM_FAULT_MAJOR) {
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, address);
-		tsk->maj_flt++;
-	} else {
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, address);
-		tsk->min_flt++;
+	if (flags & FAULT_FLAG_ALLOW_RETRY) {
+		if (fault & VM_FAULT_MAJOR) {
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,
+						  regs, address);
+			tsk->maj_flt++;
+		} else {
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,
+						  regs, address);
+			tsk->min_flt++;
+		}
+		if (fault & VM_FAULT_RETRY) {
+			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+
+			/*
+			 * No need to up_read(&mm->mmap_sem) as we would
+			 * have already released it in __lock_page_or_retry
+			 * in mm/filemap.c.
+			 */
+
+			goto retry;
+		}
 	}
 
 	up_read(&mm->mmap_sem);

commit a8b0ca17b80e92faab46ee7179ba9e99ccb61233
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Jun 27 14:41:57 2011 +0200

    perf: Remove the nmi parameter from the swevent and overflow interface
    
    The nmi parameter indicated if we could do wakeups from the current
    context, if not, we would set some state and self-IPI and let the
    resulting interrupt do the wakeup.
    
    For the various event classes:
    
      - hardware: nmi=0; PMI is in fact an NMI or we run irq_work_run from
        the PMI-tail (ARM etc.)
      - tracepoint: nmi=0; since tracepoint could be from NMI context.
      - software: nmi=[0,1]; some, like the schedule thing cannot
        perform wakeups, and hence need 0.
    
    As one can see, there is very little nmi=1 usage, and the down-side of
    not using it is that on some platforms some software events can have a
    jiffy delay in wakeup (when arch_irq_work_raise isn't implemented).
    
    The up-side however is that we can remove the nmi parameter and save a
    bunch of conditionals in fast paths.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Michael Cree <mcree@orcon.net.nz>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Deng-Cheng Zhu <dengcheng.zhu@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jason Wessel <jason.wessel@windriver.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Link: http://lkml.kernel.org/n/tip-agjev8eu666tvknpb3iaj0fg@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 137ee76a0045..937cf3368164 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -145,7 +145,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	 * the fault.
 	 */
 	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
-	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, address);
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
@@ -154,12 +154,10 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 		BUG();
 	}
 	if (fault & VM_FAULT_MAJOR) {
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ,
-				1, 0, regs, address);
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, address);
 		tsk->maj_flt++;
 	} else {
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN,
-				1, 0, regs, address);
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, address);
 		tsk->min_flt++;
 	}
 

commit 7f788d2d53085815d474559cd51ef1f38b0a9bb8
Author: Deng-Cheng Zhu <dengcheng.zhu@gmail.com>
Date:   Tue Oct 12 19:37:21 2010 +0800

    MIPS: add support for software performance events
    
    Software events are required as part of the measurable stuff by the
    Linux performance counter subsystem. Here is the list of events added by
    this patch:
    PERF_COUNT_SW_PAGE_FAULTS
    PERF_COUNT_SW_PAGE_FAULTS_MIN
    PERF_COUNT_SW_PAGE_FAULTS_MAJ
    PERF_COUNT_SW_ALIGNMENT_FAULTS
    PERF_COUNT_SW_EMULATION_FAULTS
    
    Signed-off-by: Deng-Cheng Zhu <dengcheng.zhu@gmail.com>
    To: linux-mips@linux-mips.org
    Cc: a.p.zijlstra@chello.nl
    Cc: paulus@samba.org
    Cc: mingo@elte.hu
    Cc: acme@redhat.com
    Cc: jamie.iles@picochip.com
    Acked-by: David Daney <ddaney@caviumnetworks.com>
    Reviewed-by: Matt Fleming <matt@console-pimps.org>
    Patchwork: https://patchwork.linux-mips.org/patch/1686/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 783ad0065fdf..137ee76a0045 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -18,6 +18,7 @@
 #include <linux/smp.h>
 #include <linux/module.h>
 #include <linux/kprobes.h>
+#include <linux/perf_event.h>
 
 #include <asm/branch.h>
 #include <asm/mmu_context.h>
@@ -144,6 +145,7 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 	 * the fault.
 	 */
 	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, address);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
@@ -151,10 +153,15 @@ asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long writ
 			goto do_sigbus;
 		BUG();
 	}
-	if (fault & VM_FAULT_MAJOR)
+	if (fault & VM_FAULT_MAJOR) {
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ,
+				1, 0, regs, address);
 		tsk->maj_flt++;
-	else
+	} else {
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN,
+				1, 0, regs, address);
 		tsk->min_flt++;
+	}
 
 	up_read(&mm->mmap_sem);
 	return;

commit c1bf207d6ee1eb72e9c10365edbdc7c9ff7fb9b0
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Tue Aug 3 11:22:20 2010 -0700

    MIPS: kprobe: Add support.
    
    This patch is based on previous work by Sony and Himanshu Chauhan.
    
    I have done some cleanup and implemented JProbes and KRETPROBES.  The
    KRETPROBES part is pretty much copied verbatim from powerpc.  A possible
    future enhance might be to factor out the common code.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Cc: Himanshu Chauhan <hschauhan@nulltrace.org>
    To: linux-mips@linux-mips.org
    To: ananth@in.ibm.com,
    To: anil.s.keshavamurthy@intel.com
    To: davem@davemloft.net
    To: masami.hiramatsu.pt@hitachi.com
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/1525/
    Patchwork: https://patchwork.linux-mips.org/patch/1530/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index b4aac424b2e9..783ad0065fdf 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -17,6 +17,7 @@
 #include <linux/mm.h>
 #include <linux/smp.h>
 #include <linux/module.h>
+#include <linux/kprobes.h>
 
 #include <asm/branch.h>
 #include <asm/mmu_context.h>
@@ -24,13 +25,14 @@
 #include <asm/uaccess.h>
 #include <asm/ptrace.h>
 #include <asm/highmem.h>		/* For VMALLOC_END */
+#include <linux/kdebug.h>
 
 /*
  * This routine handles page faults.  It determines the address,
  * and the problem, and then passes it off to one of the appropriate
  * routines.
  */
-asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
+asmlinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long write,
 			      unsigned long address)
 {
 	struct vm_area_struct * vma = NULL;
@@ -46,6 +48,17 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	       field, regs->cp0_epc);
 #endif
 
+#ifdef CONFIG_KPROBES
+	/*
+	 * This is to notify the fault handler of the kprobes.  The
+	 * exception code is redundant as it is also carried in REGS,
+	 * but we pass it anyhow.
+	 */
+	if (notify_die(DIE_PAGE_FAULT, "page fault", regs, -1,
+		       (regs->cp0_cause >> 2) & 0x1f, SIGSEGV) == NOTIFY_STOP)
+		return;
+#endif
+
 	info.si_code = SEGV_MAPERR;
 
 	/*

commit ea7a8463be6b5dd824bdf42b8f2af1d34f157877
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Thu Aug 5 13:25:59 2010 +0100

    MIPS: Remove unnecessary header file inclusion from fault.c.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index b78f7d913ca4..b4aac424b2e9 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -16,7 +16,6 @@
 #include <linux/mman.h>
 #include <linux/mm.h>
 #include <linux/smp.h>
-#include <linux/vt_kern.h>		/* For unblank_screen() */
 #include <linux/module.h>
 
 #include <asm/branch.h>

commit 6dd9344cfc41bcc60a01cdc828cb278be7a10e01
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Wed Feb 10 15:12:47 2010 -0800

    MIPS: Implement Read Inhibit/eXecute Inhibit
    
    The SmartMIPS ASE specifies how Read Inhibit (RI) and eXecute Inhibit
    (XI) bits in the page tables work.  The upper two bits of EntryLo{0,1}
    are RI and XI when the feature is enabled in the PageGrain register.
    SmartMIPS only covers 32-bit systems.  Cavium Octeon+ extends this to
    64-bit systems by continuing to place the RI and XI bits in the top of
    EntryLo even when EntryLo is 64-bits wide.
    
    Because we need to carry the RI and XI bits in the PTE, the layout of
    the PTE is changed.  There is a two instruction overhead in the TLB
    refill hot path to get the EntryLo bits into the proper position.
    Also the TLB load exception has to probe the TLB to check if RI or XI
    caused the exception.
    
    Also of note is that the layout of the PTE bits is done at compile and
    runtime rather than statically.  In the 32-bit case this allows for
    the same number of PFN bits as before the patch as the _PAGE_HUGE is
    not supported in 32-bit kernels (we have _PAGE_NO_EXEC and
    _PAGE_NO_READ instead of _PAGE_READ and _PAGE_HUGE).
    
    The patch is tested on Cavium Octeon+, but should also work on 32-bit
    systems with the Smart-MIPS ASE.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    To: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/952/
    Patchwork: http://patchwork.linux-mips.org/patch/956/
    Patchwork: http://patchwork.linux-mips.org/patch/962/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index e97a7a2fb2c0..b78f7d913ca4 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -99,8 +99,31 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
-		if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
-			goto bad_area;
+		if (kernel_uses_smartmips_rixi) {
+			if (address == regs->cp0_epc && !(vma->vm_flags & VM_EXEC)) {
+#if 0
+				pr_notice("Cpu%d[%s:%d:%0*lx:%ld:%0*lx] XI violation\n",
+					  raw_smp_processor_id(),
+					  current->comm, current->pid,
+					  field, address, write,
+					  field, regs->cp0_epc);
+#endif
+				goto bad_area;
+			}
+			if (!(vma->vm_flags & VM_READ)) {
+#if 0
+				pr_notice("Cpu%d[%s:%d:%0*lx:%ld:%0*lx] RI violation\n",
+					  raw_smp_processor_id(),
+					  current->comm, current->pid,
+					  field, address, write,
+					  field, regs->cp0_epc);
+#endif
+				goto bad_area;
+			}
+		} else {
+			if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
+				goto bad_area;
+		}
 	}
 
 	/*

commit 2ca2ebfd952d0338a0972c1f1f56b9b0c1a3b09c
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Wed Sep 2 15:47:34 2009 -0700

    MIPS: Don't corrupt page tables on vmalloc fault.
    
    The code after the vmalloc_fault: label in do_page_fault() modifies
    user page tables, this is not correct for 64-bit kernels.
    
    For 64-bit kernels we should go straight to the no_context handler
    skipping vmalloc_fault.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index f956ecbb8136..e97a7a2fb2c0 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -58,11 +58,17 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * only copy the information from the master page table,
 	 * nothing more.
 	 */
+#ifdef CONFIG_64BIT
+# define VMALLOC_FAULT_TARGET no_context
+#else
+# define VMALLOC_FAULT_TARGET vmalloc_fault
+#endif
+
 	if (unlikely(address >= VMALLOC_START && address <= VMALLOC_END))
-		goto vmalloc_fault;
+		goto VMALLOC_FAULT_TARGET;
 #ifdef MODULE_START
 	if (unlikely(address >= MODULE_START && address < MODULE_END))
-		goto vmalloc_fault;
+		goto VMALLOC_FAULT_TARGET;
 #endif
 
 	/*
@@ -203,6 +209,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	force_sig_info(SIGBUS, &info, tsk);
 
 	return;
+#ifndef CONFIG_64BIT
 vmalloc_fault:
 	{
 		/*
@@ -241,4 +248,5 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 			goto no_context;
 		return;
 	}
+#endif
 }

commit a887b4dada2f23b2ff2aa725e0509c92dc652597
Author: Akinobu Mita <akinobu.mita@gmail.com>
Date:   Sat Jul 4 01:33:09 2009 +0900

    MIPS: Drop mmap_sem in pagefault oom path
    
    Fix the pagefault oom path which does not drop mm->mmap_sem.
    This was introduced by commit c7c1e3846bac1e4b8a8941f6a194812e28b0a519
    
    Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 6751ce9ede9e..f956ecbb8136 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -171,6 +171,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * We ran out of memory, call the OOM killer, and return the userspace
 	 * (which will retry the fault, or kill us if we got oom-killed).
 	 */
+	up_read(&mm->mmap_sem);
 	pagefault_out_of_memory();
 	return;
 

commit d06063cc221fdefcab86589e79ddfdb7c0e14b63
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 10 09:01:23 2009 -0700

    Move FAULT_FLAG_xyz into handle_mm_fault() callers
    
    This allows the callers to now pass down the full set of FAULT_FLAG_xyz
    flags to handle_mm_fault().  All callers have been (mechanically)
    converted to the new calling convention, there's almost certainly room
    for architectures to clean up their code and then add FAULT_FLAG_RETRY
    when that support is added.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 55767ad9f00e..6751ce9ede9e 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -102,7 +102,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * make sure we exit gracefully rather than endlessly redo
 	 * the fault.
 	 */
-	fault = handle_mm_fault(mm, vma, address, write);
+	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;

commit c7c1e3846bac1e4b8a8941f6a194812e28b0a519
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Mon Jan 12 00:09:13 2009 +0000

    MIPS: Port "mm: invoke oom-killer from page fault" from UML / x86
    
    Original commit 1c0fe6e3bda0464728c23c8d84aa47567e8b716c.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index fa636fc6b7b9..55767ad9f00e 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -97,7 +97,6 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 			goto bad_area;
 	}
 
-survive:
 	/*
 	 * If for any reason at all we couldn't handle the fault,
 	 * make sure we exit gracefully rather than endlessly redo
@@ -167,21 +166,13 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	       field,  regs->regs[31]);
 	die("Oops", regs);
 
-/*
- * We ran out of memory, or some other thing happened to us that made
- * us unable to handle the page fault gracefully.
- */
 out_of_memory:
-	up_read(&mm->mmap_sem);
-	if (is_global_init(tsk)) {
-		yield();
-		down_read(&mm->mmap_sem);
-		goto survive;
-	}
-	printk("VM: killing process %s\n", tsk->comm);
-	if (user_mode(regs))
-		do_group_exit(SIGKILL);
-	goto no_context;
+	/*
+	 * We ran out of memory, call the OOM killer, and return the userspace
+	 * (which will retry the fault, or kill us if we got oom-killed).
+	 */
+	pagefault_out_of_memory();
+	return;
 
 do_sigbus:
 	up_read(&mm->mmap_sem);

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 5699c7713e2f..fa636fc6b7b9 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -173,7 +173,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
  */
 out_of_memory:
 	up_read(&mm->mmap_sem);
-	if (is_init(tsk)) {
+	if (is_global_init(tsk)) {
 		yield();
 		down_read(&mm->mmap_sem);
 		goto survive;

commit dcca2bde4f86a14d3291660bede8f1844fe2b3df
Author: Will Schmidt <will_schmidt@vnet.ibm.com>
Date:   Tue Oct 16 01:24:18 2007 -0700

    During VM oom condition, kill all threads in process group
    
    We have had complaints where a threaded application is left in a bad state
    after one of it's threads is killed when we hit a VM: out_of_memory
    condition.
    
    Killing just one of the process threads can leave the application in a bad
    state, whereas killing the entire process group would allow for the
    application to restart, or be otherwise handled, and makes it very obvious
    that something has gone wrong.
    
    This change allows the entire process group to be taken down, rather
    than just the one thread.
    
    Signed-off-by: Will Schmidt <will_schmidt@vnet.ibm.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Chris Zankel <chris@zankel.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 521771b373de..5699c7713e2f 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -180,7 +180,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	}
 	printk("VM: killing process %s\n", tsk->comm);
 	if (user_mode(regs))
-		do_exit(SIGKILL);
+		do_group_exit(SIGKILL);
 	goto no_context;
 
 do_sigbus:

commit 83c54070ee1a2d05c89793884bea1a03f2851ed4
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Jul 19 01:47:05 2007 -0700

    mm: fault feedback #2
    
    This patch completes Linus's wish that the fault return codes be made into
    bit flags, which I agree makes everything nicer.  This requires requires
    all handle_mm_fault callers to be modified (possibly the modifications
    should go further and do things like fault accounting in handle_mm_fault --
    however that would be for another patch).
    
    [akpm@linux-foundation.org: fix alpha build]
    [akpm@linux-foundation.org: fix s390 build]
    [akpm@linux-foundation.org: fix sparc build]
    [akpm@linux-foundation.org: fix sparc64 build]
    [akpm@linux-foundation.org: fix ia64 build]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Bryan Wu <bryan.wu@analog.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Andi Kleen <ak@muc.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    [ Still apparently needs some ARM and PPC loving - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 7ebea331edb8..521771b373de 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -39,6 +39,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	struct mm_struct *mm = tsk->mm;
 	const int field = sizeof(unsigned long) * 2;
 	siginfo_t info;
+	int fault;
 
 #if 0
 	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
@@ -102,20 +103,18 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * make sure we exit gracefully rather than endlessly redo
 	 * the fault.
 	 */
-	switch (handle_mm_fault(mm, vma, address, write)) {
-	case VM_FAULT_MINOR:
-		tsk->min_flt++;
-		break;
-	case VM_FAULT_MAJOR:
-		tsk->maj_flt++;
-		break;
-	case VM_FAULT_SIGBUS:
-		goto do_sigbus;
-	case VM_FAULT_OOM:
-		goto out_of_memory;
-	default:
+	fault = handle_mm_fault(mm, vma, address, write);
+	if (unlikely(fault & VM_FAULT_ERROR)) {
+		if (fault & VM_FAULT_OOM)
+			goto out_of_memory;
+		else if (fault & VM_FAULT_SIGBUS)
+			goto do_sigbus;
 		BUG();
 	}
+	if (fault & VM_FAULT_MAJOR)
+		tsk->maj_flt++;
+	else
+		tsk->min_flt++;
 
 	up_read(&mm->mmap_sem);
 	return;

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index f9c595dceba9..7ebea331edb8 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -16,7 +16,6 @@
 #include <linux/mman.h>
 #include <linux/mm.h>
 #include <linux/smp.h>
-#include <linux/smp_lock.h>
 #include <linux/vt_kern.h>		/* For unblank_screen() */
 #include <linux/module.h>
 

commit d6f703602fee8f8bd5c108af927a420cb8cb0d36
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Thu Mar 29 22:30:01 2007 +0100

    [MIPS] do_page_fault() needs to use raw_smp_processor_id().
    
    Original patch posted by Deepak Saxena <dsaxena@plexity.net>.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 6f90e7ef66ac..f9c595dceba9 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -42,7 +42,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	siginfo_t info;
 
 #if 0
-	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", smp_processor_id(),
+	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
 	       current->comm, current->pid, field, address, write,
 	       field, regs->cp0_epc);
 #endif
@@ -165,7 +165,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 
 	printk(KERN_ALERT "CPU %d Unable to handle kernel paging request at "
 	       "virtual address %0*lx, epc == %0*lx, ra == %0*lx\n",
-	       smp_processor_id(), field, address, field, regs->cp0_epc,
+	       raw_smp_processor_id(), field, address, field, regs->cp0_epc,
 	       field,  regs->regs[31]);
 	die("Oops", regs);
 
@@ -228,7 +228,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 		pmd_t *pmd, *pmd_k;
 		pte_t *pte_k;
 
-		pgd = (pgd_t *) pgd_current[smp_processor_id()] + offset;
+		pgd = (pgd_t *) pgd_current[raw_smp_processor_id()] + offset;
 		pgd_k = init_mm.pgd + offset;
 
 		if (!pgd_present(*pgd_k))

commit 656be92f9ae194ed62bc81310a4589a7cd765f13
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Thu Oct 26 00:08:31 2006 +0900

    [MIPS] Load modules to CKSEG0 if CONFIG_BUILD_ELF64=n
    
    This is a patch to load 64-bit modules to CKSEG0 so that can be
    compiled with -msym32 option.  This makes each module ~10% smaller.
    
    * introduce MODULE_START and MODULE_END
    * custom module_alloc()
    * PGD for modules
    * change XTLB refill handler synthesizer
    * enable -msym32 for modules again
      (revert ca78b1a5c6a6e70e052d3ea253828e49b5d07c8a)
    
    New XTLB refill handler looks like this:
    
    80000080 dmfc0   k0,C0_BADVADDR
    80000084 bltz    k0,800000e4                    # goto l_module_alloc
    80000088 lui     k1,0x8046                      # %high(pgd_current)
    8000008c ld      k1,24600(k1)                   # %low(pgd_current)
    80000090 dsrl    k0,k0,0x1b                     # l_vmalloc_done:
    80000094 andi    k0,k0,0x1ff8
    80000098 daddu   k1,k1,k0
    8000009c dmfc0   k0,C0_BADVADDR
    800000a0 ld      k1,0(k1)
    800000a4 dsrl    k0,k0,0x12
    800000a8 andi    k0,k0,0xff8
    800000ac daddu   k1,k1,k0
    800000b0 dmfc0   k0,C0_XCONTEXT
    800000b4 ld      k1,0(k1)
    800000b8 andi    k0,k0,0xff0
    800000bc daddu   k1,k1,k0
    800000c0 ld      k0,0(k1)
    800000c4 ld      k1,8(k1)
    800000c8 dsrl    k0,k0,0x6
    800000cc mtc0    k0,C0_ENTRYLO0
    800000d0 dsrl    k1,k1,0x6
    800000d4 mtc0    k1,C0_ENTRYL01
    800000d8 nop
    800000dc tlbwr
    800000e0 eret
    800000e4 dsll    k1,k0,0x2                      # l_module_alloc:
    800000e8 bgez    k1,80000008                    # goto l_vmalloc
    800000ec lui     k1,0xc000
    800000f0 dsubu   k0,k0,k1
    800000f4 lui     k1,0x8046                      # %high(module_pg_dir)
    800000f8 beq     zero,zero,80000000
    800000fc nop
    80000000 beq     zero,zero,80000090             # goto l_vmalloc_done
    80000004 daddiu  k1,k1,0x4000
    80000008 dsll32  k1,k1,0x0                      # l_vmalloc:
    8000000c dsubu   k0,k0,k1
    80000010 beq     zero,zero,80000090             # goto l_vmalloc_done
    80000014 lui     k1,0x8046                      # %high(swapper_pg_dir)
    
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 8423d8590779..6f90e7ef66ac 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -60,6 +60,10 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 */
 	if (unlikely(address >= VMALLOC_START && address <= VMALLOC_END))
 		goto vmalloc_fault;
+#ifdef MODULE_START
+	if (unlikely(address >= MODULE_START && address < MODULE_END))
+		goto vmalloc_fault;
+#endif
 
 	/*
 	 * If we're in an interrupt or have no user

commit f400e198b2ed26ce55b22a1412ded0896e7516ac
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Sep 29 02:00:07 2006 -0700

    [PATCH] pidspace: is_init()
    
    This is an updated version of Eric Biederman's is_init() patch.
    (http://lkml.org/lkml/2006/2/6/280).  It applies cleanly to 2.6.18-rc3 and
    replaces a few more instances of ->pid == 1 with is_init().
    
    Further, is_init() checks pid and thus removes dependency on Eric's other
    patches for now.
    
    Eric's original description:
    
            There are a lot of places in the kernel where we test for init
            because we give it special properties.  Most  significantly init
            must not die.  This results in code all over the kernel test
            ->pid == 1.
    
            Introduce is_init to capture this case.
    
            With multiple pid spaces for all of the cases affected we are
            looking for only the first process on the system, not some other
            process that has pid == 1.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: <lxc-devel@lists.sourceforge.net>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index a4f8c45c4e8e..8423d8590779 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -171,7 +171,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
  */
 out_of_memory:
 	up_read(&mm->mmap_sem);
-	if (tsk->pid == 1) {
+	if (is_init(tsk)) {
 		yield();
 		down_read(&mm->mmap_sem);
 		goto survive;

commit 00932ba3052a84ed73fab34ff1ec5a413b77fbab
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Sat Sep 16 01:29:37 2006 +0100

    [MIPS] Make PROT_WRITE imply PROT_READ.

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index e3a617224868..a4f8c45c4e8e 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -89,7 +89,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
-		if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
+		if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
 			goto bad_area;
 	}
 

commit 41c594ab65fc89573af296d192aa5235d09717ab
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Wed Apr 5 09:45:45 2006 +0100

    [MIPS] MT: Improved multithreading support.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 2d9624fd10ec..e3a617224868 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -157,7 +157,6 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * Oops. The kernel tried to access some bad page. We'll have to
 	 * terminate things with extreme prejudice.
 	 */
-
 	bust_spinlocks(1);
 
 	printk(KERN_ALERT "CPU %d Unable to handle kernel paging request at "
@@ -188,11 +187,20 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	/* Kernel mode? Handle exceptions or die */
 	if (!user_mode(regs))
 		goto no_context;
-
+	else
 	/*
 	 * Send a sigbus, regardless of whether we were in kernel
 	 * or user mode.
 	 */
+#if 0
+		printk("do_page_fault() #3: sending SIGBUS to %s for "
+		       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
+		       tsk->comm,
+		       write ? "write access to" : "read access from",
+		       field, address,
+		       field, (unsigned long) regs->cp0_epc,
+		       field, (unsigned long) regs->regs[31]);
+#endif
 	tsk->thread.cp0_badvaddr = address;
 	info.si_signo = SIGBUS;
 	info.si_errno = 0;
@@ -201,7 +209,6 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	force_sig_info(SIGBUS, &info, tsk);
 
 	return;
-
 vmalloc_fault:
 	{
 		/*

commit fe00f943e0ef98b4057abcc2940d631a975b43cd
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Mar 1 19:22:29 2005 +0000

    Sparseify MIPS.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 0eb43151f10a..2d9624fd10ec 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -141,7 +141,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 		info.si_signo = SIGSEGV;
 		info.si_errno = 0;
 		/* info.si_code has been set above */
-		info.si_addr = (void *) address;
+		info.si_addr = (void __user *) address;
 		force_sig_info(SIGSEGV, &info, tsk);
 		return;
 	}
@@ -197,7 +197,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	info.si_signo = SIGBUS;
 	info.si_errno = 0;
 	info.si_code = BUS_ADRERR;
-	info.si_addr = (void *) address;
+	info.si_addr = (void __user *) address;
 	force_sig_info(SIGBUS, &info, tsk);
 
 	return;

commit 16033d6104f1704bea19ca2684b1c97731479048
Author: Thiemo Seufer <ths@networkno.de>
Date:   Sat Feb 19 13:56:04 2005 +0000

    Handle addresses beyond VMALLOC_END correctly.
    
    Signed-off-by: Thiemo Seufer <ths@networkno.de>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 345a4d6ec20f..0eb43151f10a 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -25,6 +25,7 @@
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/ptrace.h>
+#include <asm/highmem.h>		/* For VMALLOC_END */
 
 /*
  * This routine handles page faults.  It determines the address,
@@ -57,7 +58,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	 * only copy the information from the master page table,
 	 * nothing more.
 	 */
-	if (unlikely(address >= VMALLOC_START))
+	if (unlikely(address >= VMALLOC_START && address <= VMALLOC_END))
 		goto vmalloc_fault;
 
 	/*

commit c6e8b587718c486b55c2ebecc6de231a30beba35
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Thu Feb 10 12:19:59 2005 +0000

    Update MIPS to use the 4-level pagetable code thereby getting rid of
    the compacrapability headers.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index ec8077c74e9c..345a4d6ec20f 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -212,6 +212,7 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 		 */
 		int offset = __pgd_offset(address);
 		pgd_t *pgd, *pgd_k;
+		pud_t *pud, *pud_k;
 		pmd_t *pmd, *pmd_k;
 		pte_t *pte_k;
 
@@ -222,8 +223,13 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 			goto no_context;
 		set_pgd(pgd, *pgd_k);
 
-		pmd = pmd_offset(pgd, address);
-		pmd_k = pmd_offset(pgd_k, address);
+		pud = pud_offset(pgd, address);
+		pud_k = pud_offset(pgd_k, address);
+		if (!pud_present(*pud_k))
+			goto no_context;
+
+		pmd = pmd_offset(pud, address);
+		pmd_k = pmd_offset(pud_k, address);
 		if (!pmd_present(*pmd_k))
 			goto no_context;
 		set_pmd(pmd, *pmd_k);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
new file mode 100644
index 000000000000..ec8077c74e9c
--- /dev/null
+++ b/arch/mips/mm/fault.c
@@ -0,0 +1,236 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995 - 2000 by Ralf Baechle
+ */
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/ptrace.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/vt_kern.h>		/* For unblank_screen() */
+#include <linux/module.h>
+
+#include <asm/branch.h>
+#include <asm/mmu_context.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/ptrace.h>
+
+/*
+ * This routine handles page faults.  It determines the address,
+ * and the problem, and then passes it off to one of the appropriate
+ * routines.
+ */
+asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
+			      unsigned long address)
+{
+	struct vm_area_struct * vma = NULL;
+	struct task_struct *tsk = current;
+	struct mm_struct *mm = tsk->mm;
+	const int field = sizeof(unsigned long) * 2;
+	siginfo_t info;
+
+#if 0
+	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", smp_processor_id(),
+	       current->comm, current->pid, field, address, write,
+	       field, regs->cp0_epc);
+#endif
+
+	info.si_code = SEGV_MAPERR;
+
+	/*
+	 * We fault-in kernel-space virtual memory on-demand. The
+	 * 'reference' page table is init_mm.pgd.
+	 *
+	 * NOTE! We MUST NOT take any locks for this case. We may
+	 * be in an interrupt or a critical region, and should
+	 * only copy the information from the master page table,
+	 * nothing more.
+	 */
+	if (unlikely(address >= VMALLOC_START))
+		goto vmalloc_fault;
+
+	/*
+	 * If we're in an interrupt or have no user
+	 * context, we must not take the fault..
+	 */
+	if (in_atomic() || !mm)
+		goto bad_area_nosemaphore;
+
+	down_read(&mm->mmap_sem);
+	vma = find_vma(mm, address);
+	if (!vma)
+		goto bad_area;
+	if (vma->vm_start <= address)
+		goto good_area;
+	if (!(vma->vm_flags & VM_GROWSDOWN))
+		goto bad_area;
+	if (expand_stack(vma, address))
+		goto bad_area;
+/*
+ * Ok, we have a good vm_area for this memory access, so
+ * we can handle it..
+ */
+good_area:
+	info.si_code = SEGV_ACCERR;
+
+	if (write) {
+		if (!(vma->vm_flags & VM_WRITE))
+			goto bad_area;
+	} else {
+		if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
+			goto bad_area;
+	}
+
+survive:
+	/*
+	 * If for any reason at all we couldn't handle the fault,
+	 * make sure we exit gracefully rather than endlessly redo
+	 * the fault.
+	 */
+	switch (handle_mm_fault(mm, vma, address, write)) {
+	case VM_FAULT_MINOR:
+		tsk->min_flt++;
+		break;
+	case VM_FAULT_MAJOR:
+		tsk->maj_flt++;
+		break;
+	case VM_FAULT_SIGBUS:
+		goto do_sigbus;
+	case VM_FAULT_OOM:
+		goto out_of_memory;
+	default:
+		BUG();
+	}
+
+	up_read(&mm->mmap_sem);
+	return;
+
+/*
+ * Something tried to access memory that isn't in our memory map..
+ * Fix it, but check if it's kernel or user first..
+ */
+bad_area:
+	up_read(&mm->mmap_sem);
+
+bad_area_nosemaphore:
+	/* User mode accesses just cause a SIGSEGV */
+	if (user_mode(regs)) {
+		tsk->thread.cp0_badvaddr = address;
+		tsk->thread.error_code = write;
+#if 0
+		printk("do_page_fault() #2: sending SIGSEGV to %s for "
+		       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
+		       tsk->comm,
+		       write ? "write access to" : "read access from",
+		       field, address,
+		       field, (unsigned long) regs->cp0_epc,
+		       field, (unsigned long) regs->regs[31]);
+#endif
+		info.si_signo = SIGSEGV;
+		info.si_errno = 0;
+		/* info.si_code has been set above */
+		info.si_addr = (void *) address;
+		force_sig_info(SIGSEGV, &info, tsk);
+		return;
+	}
+
+no_context:
+	/* Are we prepared to handle this kernel fault?  */
+	if (fixup_exception(regs)) {
+		current->thread.cp0_baduaddr = address;
+		return;
+	}
+
+	/*
+	 * Oops. The kernel tried to access some bad page. We'll have to
+	 * terminate things with extreme prejudice.
+	 */
+
+	bust_spinlocks(1);
+
+	printk(KERN_ALERT "CPU %d Unable to handle kernel paging request at "
+	       "virtual address %0*lx, epc == %0*lx, ra == %0*lx\n",
+	       smp_processor_id(), field, address, field, regs->cp0_epc,
+	       field,  regs->regs[31]);
+	die("Oops", regs);
+
+/*
+ * We ran out of memory, or some other thing happened to us that made
+ * us unable to handle the page fault gracefully.
+ */
+out_of_memory:
+	up_read(&mm->mmap_sem);
+	if (tsk->pid == 1) {
+		yield();
+		down_read(&mm->mmap_sem);
+		goto survive;
+	}
+	printk("VM: killing process %s\n", tsk->comm);
+	if (user_mode(regs))
+		do_exit(SIGKILL);
+	goto no_context;
+
+do_sigbus:
+	up_read(&mm->mmap_sem);
+
+	/* Kernel mode? Handle exceptions or die */
+	if (!user_mode(regs))
+		goto no_context;
+
+	/*
+	 * Send a sigbus, regardless of whether we were in kernel
+	 * or user mode.
+	 */
+	tsk->thread.cp0_badvaddr = address;
+	info.si_signo = SIGBUS;
+	info.si_errno = 0;
+	info.si_code = BUS_ADRERR;
+	info.si_addr = (void *) address;
+	force_sig_info(SIGBUS, &info, tsk);
+
+	return;
+
+vmalloc_fault:
+	{
+		/*
+		 * Synchronize this task's top level page-table
+		 * with the 'reference' page table.
+		 *
+		 * Do _not_ use "tsk" here. We might be inside
+		 * an interrupt in the middle of a task switch..
+		 */
+		int offset = __pgd_offset(address);
+		pgd_t *pgd, *pgd_k;
+		pmd_t *pmd, *pmd_k;
+		pte_t *pte_k;
+
+		pgd = (pgd_t *) pgd_current[smp_processor_id()] + offset;
+		pgd_k = init_mm.pgd + offset;
+
+		if (!pgd_present(*pgd_k))
+			goto no_context;
+		set_pgd(pgd, *pgd_k);
+
+		pmd = pmd_offset(pgd, address);
+		pmd_k = pmd_offset(pgd_k, address);
+		if (!pmd_present(*pmd_k))
+			goto no_context;
+		set_pmd(pmd, *pmd_k);
+
+		pte_k = pte_offset_kernel(pmd_k, address);
+		if (!pte_present(*pte_k))
+			goto no_context;
+		return;
+	}
+}
