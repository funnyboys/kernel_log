commit 4f85c9566cc10e85fa9337456e354e5321c815d0
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Fri Jun 7 13:36:40 2019 +0200

    MIPS: ftrace: Reword prepare_ftrace_return() comment block
    
    Improve the comment block for prepare_ftrace_return().
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 4b5e1f2bfbce..2625232bfe52 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -333,20 +333,21 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 		return;
 
 	/*
-	 * "parent_ra_addr" is the stack address saved the return address of
-	 * the caller of _mcount.
+	 * "parent_ra_addr" is the stack address where the return address of
+	 * the caller of _mcount is saved.
 	 *
-	 * if the gcc < 4.5, a leaf function does not save the return address
-	 * in the stack address, so, we "emulate" one in _mcount's stack space,
-	 * and hijack it directly, but for a non-leaf function, it save the
-	 * return address to the its own stack space, we can not hijack it
-	 * directly, but need to find the real stack address,
-	 * ftrace_get_parent_addr() does it!
+	 * If gcc < 4.5, a leaf function does not save the return address
+	 * in the stack address, so we "emulate" one in _mcount's stack space,
+	 * and hijack it directly.
+	 * For a non-leaf function, it does save the return address to its own
+	 * stack space, so we can not hijack it directly, but need to find the
+	 * real stack address, which is done by ftrace_get_parent_addr().
 	 *
-	 * if gcc>= 4.5, with the new -mmcount-ra-address option, for a
+	 * If gcc >= 4.5, with the new -mmcount-ra-address option, for a
 	 * non-leaf function, the location of the return address will be saved
-	 * to $12 for us, and for a leaf function, only put a zero into $12. we
-	 * do it in ftrace_graph_caller of mcount.S.
+	 * to $12 for us.
+	 * For a leaf function, it just puts a zero into $12, so we handle
+	 * it in ftrace_graph_caller() of mcount.S.
 	 */
 
 	/* old_parent_ra = *parent_ra_addr; */

commit 736706bee3298208343a76096370e4f6a5c55915
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 4 10:39:05 2019 -0800

    get rid of legacy 'get_ds()' function
    
    Every in-kernel use of this function defined it to KERNEL_DS (either as
    an actual define, or as an inline function).  It's an entirely
    historical artifact, and long long long ago used to actually read the
    segment selector valueof '%ds' on x86.
    
    Which in the kernel is always KERNEL_DS.
    
    Inspired by a patch from Jann Horn that just did this for a very small
    subset of users (the ones in fs/), along with Al who suggested a script.
    I then just took it to the logical extreme and removed all the remaining
    gunk.
    
    Roughly scripted with
    
       git grep -l '(get_ds())' -- :^tools/ | xargs sed -i 's/(get_ds())/(KERNEL_DS)/'
       git grep -lw 'get_ds' -- :^tools/ | xargs sed -i '/^#define get_ds()/d'
    
    plus manual fixups to remove a few unusual usage patterns, the couple of
    inline function cases and to fix up a comment that had become stale.
    
    The 'get_ds()' function remains in an x86 kvm selftest, since in user
    space it actually does something relevant.
    
    Inspired-by: Jann Horn <jannh@google.com>
    Inspired-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 2ea0ec95efe9..4b5e1f2bfbce 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -86,7 +86,7 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 		return -EFAULT;
 
 	old_fs = get_fs();
-	set_fs(get_ds());
+	set_fs(KERNEL_DS);
 	flush_icache_range(ip, ip + 8);
 	set_fs(old_fs);
 
@@ -111,7 +111,7 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
 
 	ip -= 4;
 	old_fs = get_fs();
-	set_fs(get_ds());
+	set_fs(KERNEL_DS);
 	flush_icache_range(ip, ip + 8);
 	set_fs(old_fs);
 
@@ -135,7 +135,7 @@ static int ftrace_modify_code_2r(unsigned long ip, unsigned int new_code1,
 		return -EFAULT;
 
 	old_fs = get_fs();
-	set_fs(get_ds());
+	set_fs(KERNEL_DS);
 	flush_icache_range(ip, ip + 8);
 	set_fs(old_fs);
 

commit 89261c57021352045c4af24522c6854c9ee90139
Merge: c2f1f3e0e17d adcc81f148d7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 26 10:45:33 2018 -0800

    Merge tag 'mips_4.21' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux
    
    Pull MIPS updates from Paul Burton:
     "Here's the main MIPS pull for Linux 4.21. Core architecture changes
      include:
    
       - Syscall tables & definitions for unistd.h are now generated by
         scripts, providing greater consistency with other architectures &
         making it easier to add new syscalls.
    
       - Support for building kernels with no floating point support, upon
         which any userland attempting to use floating point instructions
         will receive a SIGILL. Mostly useful to shrink the kernel & as
         preparation for nanoMIPS support which does not yet include FP.
    
       - MIPS SIMD Architecture (MSA) vector register context is now exposed
         by ptrace via a new NT_MIPS_MSA regset.
    
       - ASIDs are now stored as 64b values even for MIPS32 kernels,
         expanding the ASID version field sufficiently that we don't need to
         worry about overflow & avoiding rare issues with reused ASIDs that
         have been observed in the wild.
    
       - The branch delay slot "emulation" page is now mapped without write
         permission for the user, preventing its use as a nice location for
         attacks to execute malicious code from.
    
       - Support for ioremap_prot(), primarily to allow gdb or other ptrace
         users the ability to view their tracee's memory using the same
         cache coherency attribute.
    
       - Optimizations to more cpu_has_* macros, allowing more to be
         compile-time constant where possible.
    
       - Enable building the whole kernel with UBSAN instrumentation.
    
       - Enable building the kernel with link-time dead code & data
         elimination.
    
      Platform specific changes include:
    
       - The Boston board gains a workaround for DMA prefetching issues with
         the EG20T Platform Controller Hub that it uses.
    
       - Cleanups to Cavium Octeon code removing about 20k lines of
         redundant code, mostly unused or duplicate register definitions in
         headers.
    
       - defconfig updates for the DECstation machines, including new
         defconfigs for r4k & 64b machines.
    
       - Further work on Loongson 3 support.
    
       - DMA fixes for SiByte machines"
    
    * tag 'mips_4.21' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux: (95 commits)
      MIPS: math-emu: Write-protect delay slot emulation pages
      MIPS: Remove struct mm_context_t fp_mode_switching field
      mips: generate uapi header and system call table files
      mips: add system call table generation support
      mips: remove syscall table entries
      mips: add +1 to __NR_syscalls in uapi header
      mips: rename scall64-64.S to scall64-n64.S
      mips: remove unused macros
      mips: add __NR_syscalls along with __NR_Linux_syscalls
      MIPS: Expand MIPS32 ASIDs to 64 bits
      MIPS: OCTEON: delete redundant register definitions
      MIPS: OCTEON: cvmx_gmxx_inf_mode: use oldest forward compatible definition
      MIPS: OCTEON: cvmx_mio_fus_dat3: use oldest forward compatible definition
      MIPS: OCTEON: cvmx_pko_mem_debug8: use oldest forward compatible definition
      MIPS: OCTEON: octeon-usb: use common gpio_bit definition
      MIPS: OCTEON: enable all OCTEON drivers in defconfig
      mips: annotate implicit fall throughs
      MIPS: Hardcode cpu_has_mips* where target ISA allows
      MIPS: MT: Remove norps command line parameter
      MIPS: Only include mmzone.h when CONFIG_NEED_MULTIPLE_NODES=y
      ...

commit be856439c998854c009b1f2ef9084a39b1295cec
Author: Firoz Khan <firoz.khan@linaro.org>
Date:   Thu Dec 13 14:37:36 2018 +0530

    mips: add +1 to __NR_syscalls in uapi header
    
    All other architectures are hold a value for __NR_syscalls will
    be equal to the last system call number +1.
    
    But in mips architecture, __NR_syscalls hold the value equal to
    total number of system exits in the architecture. One of the
    patch in this patch series will genarate uapi header files.
    
    In order to make the implementation common across all architect-
    ures, add +1 to __NR_syscalls, which will be equal to the last
    system call number +1.
    
    Signed-off-by: Firoz Khan <firoz.khan@linaro.org>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: linux-mips@vger.kernel.org
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: y2038@lists.linaro.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: arnd@arndb.de
    Cc: deepa.kernel@gmail.com
    Cc: marcin.juszkiewicz@linaro.org

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 7f3dfdbc3657..f32caaff9222 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -410,13 +410,13 @@ unsigned long __init arch_syscall_addr(int nr)
 unsigned long __init arch_syscall_addr(int nr)
 {
 #ifdef CONFIG_MIPS32_N32
-	if (nr >= __NR_N32_Linux && nr <= __NR_N32_Linux + __NR_N32_Linux_syscalls)
+	if (nr >= __NR_N32_Linux && nr < __NR_N32_Linux + __NR_N32_Linux_syscalls)
 		return (unsigned long)sysn32_call_table[nr - __NR_N32_Linux];
 #endif
-	if (nr >= __NR_64_Linux  && nr <= __NR_64_Linux + __NR_64_Linux_syscalls)
+	if (nr >= __NR_64_Linux  && nr < __NR_64_Linux + __NR_64_Linux_syscalls)
 		return (unsigned long)sys_call_table[nr - __NR_64_Linux];
 #ifdef CONFIG_MIPS32_O32
-	if (nr >= __NR_O32_Linux && nr <= __NR_O32_Linux + __NR_O32_Linux_syscalls)
+	if (nr >= __NR_O32_Linux && nr < __NR_O32_Linux + __NR_O32_Linux_syscalls)
 		return (unsigned long)sys32_call_table[nr - __NR_O32_Linux];
 #endif
 

commit 8712b27c5723c26400a2b350faf1d6d9fd7ffaad
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Sun Nov 18 17:25:18 2018 -0500

    MIPS: function_graph: Simplify with function_graph_enter()
    
    The function_graph_enter() function does the work of calling the function
    graph hook function and the management of the shadow stack, simplifying the
    work done in the architecture dependent prepare_ftrace_return().
    
    Have MIPS use the new code, and remove the shadow stack management as well as
    having to set up the trace structure.
    
    This is needed to prepare for a fix of a design bug on how the curr_ret_stack
    is used.
    
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@kernel.org
    Fixes: 03274a3ffb449 ("tracing/fgraph: Adjust fgraph depth before calling trace return callback")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 7f3dfdbc3657..b122cbb4aad1 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -322,7 +322,6 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 			   unsigned long fp)
 {
 	unsigned long old_parent_ra;
-	struct ftrace_graph_ent trace;
 	unsigned long return_hooker = (unsigned long)
 	    &return_to_handler;
 	int faulted, insns;
@@ -369,12 +368,6 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	if (unlikely(faulted))
 		goto out;
 
-	if (ftrace_push_return_trace(old_parent_ra, self_ra, &trace.depth, fp,
-				     NULL) == -EBUSY) {
-		*parent_ra_addr = old_parent_ra;
-		return;
-	}
-
 	/*
 	 * Get the recorded ip of the current mcount calling site in the
 	 * __mcount_loc section, which will be used to filter the function
@@ -382,13 +375,10 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	 */
 
 	insns = core_kernel_text(self_ra) ? 2 : MCOUNT_OFFSET_INSNS + 1;
-	trace.func = self_ra - (MCOUNT_INSN_SIZE * insns);
+	self_ra -= (MCOUNT_INSN_SIZE * insns);
 
-	/* Only trace if the calling function expects to */
-	if (!ftrace_graph_entry(&trace)) {
-		current->curr_ret_stack--;
+	if (function_graph_enter(old_parent_ra, self_ra, fp, NULL))
 		*parent_ra_addr = old_parent_ra;
-	}
 	return;
 out:
 	ftrace_graph_stop();

commit 83aa53eb5f34f48e6ff24aee02f879b50c949982
Author: Mathieu Malaterre <malat@debian.org>
Date:   Wed Jan 17 12:31:57 2018 +0100

    MIPS: ftrace: Remove pointer comparison to 0 in prepare_ftrace_return
    
    Replace pointer comparison to 0 with NULL in prepare_ftrace_return
    to improve code readability. Identified with coccinelle script
    'badzero.cocci'.
    
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Reviewed-by: James Hogan <jhogan@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/18494/
    Signed-off-by: James Hogan <jhogan@kernel.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 99285be0e088..7f3dfdbc3657 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -361,7 +361,7 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	 * If fails when getting the stack address of the non-leaf function's
 	 * ra, stop function graph tracer and return
 	 */
-	if (parent_ra_addr == 0)
+	if (parent_ra_addr == NULL)
 		goto out;
 #endif
 	/* *parent_ra_addr = return_hooker; */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 9d9b8fbae202..99285be0e088 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Code for replacing ftrace calls with jumps.
  *

commit 87051ec120bb9abd9e57aecf2569c00d587b6f33
Author: Marcin Nowakowski <marcin.nowakowski@imgtec.com>
Date:   Tue May 23 12:56:43 2017 +0200

    MIPS: ftrace: fix init functions tracing
    
    Since introduction of tracing for init functions the in_kernel_space()
    check is no longer correct, as it ignores the init sections. As a
    result, when probes are inserted (and disabled) in the init functions,
    a branch instruction is inserted instead of a nop, which is likely to
    result in random crashes during boot.
    
    Remove the MIPS-specific in_kernel_space() method and replace it with a
    generic core_kernel_text() that also checks for init sections during
    system boot stage.
    
    Fixes: 42c269c88dc1 ("ftrace: Allow for function tracing to record init functions on boot up")
    Signed-off-by: Marcin Nowakowski <marcin.nowakowski@imgtec.com>
    Tested-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/16092/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 30a3b75e88eb..9d9b8fbae202 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -38,20 +38,6 @@ void arch_ftrace_update_code(int command)
 
 #endif
 
-/*
- * Check if the address is in kernel space
- *
- * Clone core_kernel_text() from kernel/extable.c, but doesn't call
- * init_kernel_text() for Ftrace doesn't trace functions in init sections.
- */
-static inline int in_kernel_space(unsigned long ip)
-{
-	if (ip >= (unsigned long)_stext &&
-	    ip <= (unsigned long)_etext)
-		return 1;
-	return 0;
-}
-
 #ifdef CONFIG_DYNAMIC_FTRACE
 
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
@@ -198,7 +184,7 @@ int ftrace_make_nop(struct module *mod,
 	 * If ip is in kernel space, no long call, otherwise, long call is
 	 * needed.
 	 */
-	new = in_kernel_space(ip) ? INSN_NOP : INSN_B_1F;
+	new = core_kernel_text(ip) ? INSN_NOP : INSN_B_1F;
 #ifdef CONFIG_64BIT
 	return ftrace_modify_code(ip, new);
 #else
@@ -218,12 +204,12 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	unsigned int new;
 	unsigned long ip = rec->ip;
 
-	new = in_kernel_space(ip) ? insn_jal_ftrace_caller : insn_la_mcount[0];
+	new = core_kernel_text(ip) ? insn_jal_ftrace_caller : insn_la_mcount[0];
 
 #ifdef CONFIG_64BIT
 	return ftrace_modify_code(ip, new);
 #else
-	return ftrace_modify_code_2r(ip, new, in_kernel_space(ip) ?
+	return ftrace_modify_code_2r(ip, new, core_kernel_text(ip) ?
 						INSN_NOP : insn_la_mcount[1]);
 #endif
 }
@@ -289,7 +275,7 @@ unsigned long ftrace_get_parent_ra_addr(unsigned long self_ra, unsigned long
 	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 24), but for
 	 * kernel, move after the instruction "move ra, at"(offset is 16)
 	 */
-	ip = self_ra - (in_kernel_space(self_ra) ? 16 : 24);
+	ip = self_ra - (core_kernel_text(self_ra) ? 16 : 24);
 
 	/*
 	 * search the text until finding the non-store instruction or "s{d,w}
@@ -394,7 +380,7 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	 * entries configured through the tracing/set_graph_function interface.
 	 */
 
-	insns = in_kernel_space(self_ra) ? 2 : MCOUNT_OFFSET_INSNS + 1;
+	insns = core_kernel_text(self_ra) ? 2 : MCOUNT_OFFSET_INSNS + 1;
 	trace.func = self_ra - (MCOUNT_INSN_SIZE * insns);
 
 	/* Only trace if the calling function expects to */

commit 9a7c348ba6a46f6270d4fe49577649dad5664fe7
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Fri Aug 19 06:52:57 2016 -0500

    ftrace: Add return address pointer to ftrace_ret_stack
    
    Storing this value will help prevent unwinders from getting out of sync
    with the function graph tracer ret_stack.  Now instead of needing a
    stateful iterator, they can compare the return address pointer to find
    the right ret_stack entry.
    
    Note that an array of 50 ftrace_ret_stack structs is allocated for every
    task.  So when an arch implements this, it will add either 200 or 400
    bytes of memory usage per task (depending on whether it's a 32-bit or
    64-bit platform).
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Byungchul Park <byungchul.park@lge.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Nilay Vaish <nilayvaish@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/a95cfcc39e8f26b89a430c56926af0bb217bc0a1.1471607358.git.jpoimboe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 937c54bc8ccc..30a3b75e88eb 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -382,8 +382,8 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	if (unlikely(faulted))
 		goto out;
 
-	if (ftrace_push_return_trace(old_parent_ra, self_ra, &trace.depth, fp)
-	    == -EBUSY) {
+	if (ftrace_push_return_trace(old_parent_ra, self_ra, &trace.depth, fp,
+				     NULL) == -EBUSY) {
 		*parent_ra_addr = old_parent_ra;
 		return;
 	}

commit e669830526a0abaf301bf408df69cde33901ac63
Merge: ebb067d2f4e2 475d5928b79b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 7 08:47:00 2014 -0700

    Merge branch 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus
    
    Pull MIPS updates from Ralf Baechle:
     "This is the main pull request for 3.17.  It contains:
    
       - misc Cavium Octeon, BCM47xx, BCM63xx and Alchemy  updates
       - MIPS ptrace updates and cleanups
       - various fixes that will also go to -stable
       - a number of cleanups and small non-critical fixes.
       - NUMA support for the Loongson 3.
       - more support for MSA
       - support for MAAR
       - various FP enhancements and fixes"
    
    * 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus: (139 commits)
      MIPS: jz4740: remove unnecessary null test before debugfs_remove
      MIPS: Octeon: remove unnecessary null test before debugfs_remove_recursive
      MIPS: ZBOOT: implement stack protector in compressed boot phase
      MIPS: mipsreg: remove duplicate MIPS_CONF4_FTLBSETS_SHIFT
      MIPS: Bonito64: remove a duplicate define
      MIPS: Malta: initialise MAARs
      MIPS: Initialise MAARs
      MIPS: detect presence of MAARs
      MIPS: define MAAR register accessors & bits
      MIPS: mark MSA experimental
      MIPS: Don't build MSA support unless it can be used
      MIPS: consistently clear MSA flags when starting & copying threads
      MIPS: 16 byte align MSA vector context
      MIPS: disable preemption whilst initialising MSA
      MIPS: ensure MSA gets disabled during boot
      MIPS: fix read_msa_* & write_msa_* functions on non-MSA toolchains
      MIPS: fix MSA context for tasks which don't use FP first
      MIPS: init upper 64b of vector registers when MSA is first used
      MIPS: save/disable MSA in lose_fpu
      MIPS: preserve scalar FP CSR when switching vector context
      ...

commit dce0e7d54a710400c0056d86d0f0ed972133b25d
Author: Petri Gynther <pgynther@google.com>
Date:   Wed Jul 23 22:55:02 2014 -0700

    MIPS: ftrace: Fix dynamic tracing of kernel modules
    
    Dynamic tracing of kernel modules is broken on 32-bit MIPS. When modules
    are loaded, the kernel crashes when dynamic tracing is enabled with:
     cd /sys/kernel/debug/tracing
     echo > set_ftrace_filter
     echo function > current_tracer
    
    1) arch/mips/kernel/ftrace.c
    When the kernel boots, or when a module is initialized, ftrace_make_nop()
    modifies every _mcount call site to eliminate the ftrace overhead.
    However, when ftrace is later enabled for a call site, ftrace_make_call()
    does not currently restore the _mcount call correctly for module call sites.
    Added ftrace_modify_code_2r() and modified ftrace_make_call() to fix this.
    
    2) arch/mips/kernel/mcount.S
    _mcount assembly routine is supposed to have the caller's _mcount call site
    address in register a0. However, a0 is currently not calculated correctly for
    module call sites. a0 should be (ra - 20) or (ra - 24), depending on whether
    the kernel was built with KBUILD_MCOUNT_RA_ADDRESS or not.
    
    This fix has been tested on Broadcom BMIPS5000 processor. Dynamic tracing
    now works for both built-in functions and module functions.
    
    Signed-off-by: Petri Gynther <pgynther@google.com>
    Cc: linux-mips@linux-mips.org
    Cc: rostedt@goodmis.org
    Cc: alcooperx@gmail.com
    Cc: cminyard@mvista.com
    Patchwork: https://patchwork.linux-mips.org/patch/7476/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 60e7e5e45af1..2a72208e319c 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -63,7 +63,7 @@ static inline int in_kernel_space(unsigned long ip)
 	((unsigned int)(JAL | (((addr) >> 2) & ADDR_MASK)))
 
 static unsigned int insn_jal_ftrace_caller __read_mostly;
-static unsigned int insn_lui_v1_hi16_mcount __read_mostly;
+static unsigned int insn_la_mcount[2] __read_mostly;
 static unsigned int insn_j_ftrace_graph_caller __maybe_unused __read_mostly;
 
 static inline void ftrace_dyn_arch_init_insns(void)
@@ -71,10 +71,10 @@ static inline void ftrace_dyn_arch_init_insns(void)
 	u32 *buf;
 	unsigned int v1;
 
-	/* lui v1, hi16_mcount */
+	/* la v1, _mcount */
 	v1 = 3;
-	buf = (u32 *)&insn_lui_v1_hi16_mcount;
-	UASM_i_LA_mostly(&buf, v1, MCOUNT_ADDR);
+	buf = (u32 *)&insn_la_mcount[0];
+	UASM_i_LA(&buf, v1, MCOUNT_ADDR);
 
 	/* jal (ftrace_caller + 8), jump over the first two instruction */
 	buf = (u32 *)&insn_jal_ftrace_caller;
@@ -111,14 +111,47 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
 				unsigned int new_code2)
 {
 	int faulted;
+	mm_segment_t old_fs;
 
 	safe_store_code(new_code1, ip, faulted);
 	if (unlikely(faulted))
 		return -EFAULT;
-	safe_store_code(new_code2, ip + 4, faulted);
+
+	ip += 4;
+	safe_store_code(new_code2, ip, faulted);
 	if (unlikely(faulted))
 		return -EFAULT;
+
+	ip -= 4;
+	old_fs = get_fs();
+	set_fs(get_ds());
 	flush_icache_range(ip, ip + 8);
+	set_fs(old_fs);
+
+	return 0;
+}
+
+static int ftrace_modify_code_2r(unsigned long ip, unsigned int new_code1,
+				 unsigned int new_code2)
+{
+	int faulted;
+	mm_segment_t old_fs;
+
+	ip += 4;
+	safe_store_code(new_code2, ip, faulted);
+	if (unlikely(faulted))
+		return -EFAULT;
+
+	ip -= 4;
+	safe_store_code(new_code1, ip, faulted);
+	if (unlikely(faulted))
+		return -EFAULT;
+
+	old_fs = get_fs();
+	set_fs(get_ds());
+	flush_icache_range(ip, ip + 8);
+	set_fs(old_fs);
+
 	return 0;
 }
 #endif
@@ -130,13 +163,14 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
  *
  * move at, ra
  * jal _mcount		--> nop
+ *  sub sp, sp, 8	--> nop  (CONFIG_32BIT)
  *
  * 2. For modules:
  *
  * 2.1 For KBUILD_MCOUNT_RA_ADDRESS and CONFIG_32BIT
  *
  * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000005)
- * addiu v1, v1, low_16bit_of_mcount
+ * addiu v1, v1, low_16bit_of_mcount --> nop  (CONFIG_32BIT)
  * move at, ra
  * move $12, ra_address
  * jalr v1
@@ -145,7 +179,7 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
  * 2.2 For the Other situations
  *
  * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000004)
- * addiu v1, v1, low_16bit_of_mcount
+ * addiu v1, v1, low_16bit_of_mcount --> nop  (CONFIG_32BIT)
  * move at, ra
  * jalr v1
  *  nop | move $12, ra_address | sub sp, sp, 8
@@ -184,10 +218,14 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	unsigned int new;
 	unsigned long ip = rec->ip;
 
-	new = in_kernel_space(ip) ? insn_jal_ftrace_caller :
-		insn_lui_v1_hi16_mcount;
+	new = in_kernel_space(ip) ? insn_jal_ftrace_caller : insn_la_mcount[0];
 
+#ifdef CONFIG_64BIT
 	return ftrace_modify_code(ip, new);
+#else
+	return ftrace_modify_code_2r(ip, new, in_kernel_space(ip) ?
+						INSN_NOP : insn_la_mcount[1]);
+#endif
 }
 
 #define FTRACE_CALL_IP ((unsigned long)(&ftrace_call))

commit 6a8a5051130fd2e2b5f978a5a2e222fcc7d2dff4
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Wed Jun 25 09:53:21 2014 -0400

    MIPS: ftrace: Add call to ftrace_graph_is_dead() in function graph code
    
    ftrace_stop() is going away as it disables parts of function tracing
    that affects users that should not be affected. But ftrace_graph_stop()
    is built on ftrace_stop(). Here's another example of killing all of
    function tracing because something went wrong with function graph
    tracing.
    
    Instead of disabling all users of function tracing on function graph
    error, disable only function graph tracing. To do this, the arch code
    must call ftrace_graph_is_dead() before it implements function graph.
    
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Tested-by: James Hogan <james.hogan@imgtec.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 60e7e5e45af1..8b6538750fe1 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -302,6 +302,9 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	    &return_to_handler;
 	int faulted, insns;
 
+	if (unlikely(ftrace_graph_is_dead()))
+		return;
+
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		return;
 

commit 68114e5eb862ad0a7a261b91497281b026102715
Merge: 59ecc26004e7 3862807880ac
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 3 10:26:31 2014 -0700

    Merge tag 'trace-3.15' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull tracing updates from Steven Rostedt:
     "Most of the changes were largely clean ups, and some documentation.
      But there were a few features that were added:
    
      Uprobes now work with event triggers and multi buffers and have
      support under ftrace and perf.
    
      The big feature is that the function tracer can now be used within the
      multi buffer instances.  That is, you can now trace some functions in
      one buffer, others in another buffer, all functions in a third buffer
      and so on.  They are basically agnostic from each other.  This only
      works for the function tracer and not for the function graph trace,
      although you can have the function graph tracer running in the top
      level buffer (or any tracer for that matter) and have different
      function tracing going on in the sub buffers"
    
    * tag 'trace-3.15' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace: (45 commits)
      tracing: Add BUG_ON when stack end location is over written
      tracepoint: Remove unused API functions
      Revert "tracing: Move event storage for array from macro to standalone function"
      ftrace: Constify ftrace_text_reserved
      tracepoints: API doc update to tracepoint_probe_register() return value
      tracepoints: API doc update to data argument
      ftrace: Fix compilation warning about control_ops_free
      ftrace/x86: BUG when ftrace recovery fails
      ftrace: Warn on error when modifying ftrace function
      ftrace: Remove freelist from struct dyn_ftrace
      ftrace: Do not pass data to ftrace_dyn_arch_init
      ftrace: Pass retval through return in ftrace_dyn_arch_init()
      ftrace: Inline the code from ftrace_dyn_table_alloc()
      ftrace: Cleanup of global variables ftrace_new_pgs and ftrace_update_cnt
      tracing: Evaluate len expression only once in __dynamic_array macro
      tracing: Correctly expand len expressions from __dynamic_array macro
      tracing/module: Replace include of tracepoint.h with jump_label.h in module.h
      tracing: Fix event header migrate.h to include tracepoint.h
      tracing: Fix event header writeback.h to include tracepoint.h
      tracing: Warn if a tracepoint is not set via debugfs
      ...

commit ade63aada79c61bcd5f51cbd310f237399892268
Merge: 9a1724c7506b c14af233fbe2
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Mon Mar 31 18:17:33 2014 +0200

    Merge branch '3.14-fixes' into mips-for-linux-next

commit 6ebda44f366478d1eea180d93154e7d97b591f50
Author: Leonid Yegoshin <Leonid.Yegoshin@imgtec.com>
Date:   Mon Dec 16 12:06:55 2013 +0000

    MIPS: kernel: {ftrace,kgdb}: Set correct address limit for cache flushes
    
    When flushing the icache, make sure the address limit is correct
    so the appropriate 'cache' instruction will be used. This has no
    impact on cores operating in non-eva mode. However, when EVA is
    enabled, we ensure that 'cache' will be used instead of 'cachee'.
    
    Signed-off-by: Leonid Yegoshin <Leonid.Yegoshin@imgtec.com>
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 185ba258361b..ddcc3500248d 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -90,6 +90,7 @@ static inline void ftrace_dyn_arch_init_insns(void)
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
 	int faulted;
+	mm_segment_t old_fs;
 
 	/* *(unsigned int *)ip = new_code; */
 	safe_store_code(new_code, ip, faulted);
@@ -97,7 +98,10 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 	if (unlikely(faulted))
 		return -EFAULT;
 
+	old_fs = get_fs();
+	set_fs(get_ds());
 	flush_icache_range(ip, ip + 8);
+	set_fs(old_fs);
 
 	return 0;
 }

commit a4671094227d11985c06ee1178d7205c5fd39f8a
Author: Viller Hsiao <villerhsiao@gmail.com>
Date:   Sat Feb 22 15:46:49 2014 +0800

    MIPS: ftrace: Fix icache flush range error
    
    In 32-bit mode, the start address passed to flush_icache_range is
    shifted by 4 bytes before the second safe_store_code() call.
    
    This causes system crash from time to time because the first 4 bytes
    might not be flushed properly. This bug exists since linux-3.8.
    
    Also remove obsoleted comment while at it.
    
    Signed-off-by: Viller Hsiao <villerhsiao@gmail.com>
    Cc: linux-mips@linux-mips.org
    Cc: rostedt@goodmis.org
    Cc: fweisbec@gmail.com
    Cc: mingo@redhat.com
    Cc: Qais.Yousef@imgtec.com
    Patchwork: https://patchwork.linux-mips.org/patch/6586/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 185ba258361b..374ed74cd516 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -111,11 +111,10 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
 	safe_store_code(new_code1, ip, faulted);
 	if (unlikely(faulted))
 		return -EFAULT;
-	ip += 4;
-	safe_store_code(new_code2, ip, faulted);
+	safe_store_code(new_code2, ip + 4, faulted);
 	if (unlikely(faulted))
 		return -EFAULT;
-	flush_icache_range(ip, ip + 8); /* original ip + 12 */
+	flush_icache_range(ip, ip + 8);
 	return 0;
 }
 #endif

commit 3a36cb11ca65cd6804972eaf1000378ba4384ea7
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Mon Feb 24 19:59:59 2014 +0100

    ftrace: Do not pass data to ftrace_dyn_arch_init
    
    As the data parameter is not really used by any ftrace_dyn_arch_init,
    remove that from ftrace_dyn_arch_init. This also removes the addr
    local variable from ftrace_init which is now unused.
    
    Note the documentation was imprecise as it did not suggest to set
    (*data) to 0.
    
    Link: http://lkml.kernel.org/r/1393268401-24379-4-git-send-email-jslaby@suse.cz
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 013016bec9e1..1ba7afe6ab74 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -198,7 +198,7 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 	return ftrace_modify_code(FTRACE_CALL_IP, new);
 }
 
-int __init ftrace_dyn_arch_init(void *data)
+int __init ftrace_dyn_arch_init(void)
 {
 	/* Encode the instructions when booting */
 	ftrace_dyn_arch_init_insns();

commit af64a7cb09db77344c596a0bf3d57d77257e8bf5
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Mon Feb 24 19:59:58 2014 +0100

    ftrace: Pass retval through return in ftrace_dyn_arch_init()
    
    No architecture uses the "data" parameter in ftrace_dyn_arch_init() in any
    way, it just sets the value to 0. And this is used as a return value
    in the caller -- ftrace_init, which just checks the retval against
    zero.
    
    Note there is also "return 0" in every ftrace_dyn_arch_init.  So it is
    enough to check the retval and remove all the indirect sets of data on
    all archs.
    
    Link: http://lkml.kernel.org/r/1393268401-24379-3-git-send-email-jslaby@suse.cz
    
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 185ba258361b..013016bec9e1 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -206,9 +206,6 @@ int __init ftrace_dyn_arch_init(void *data)
 	/* Remove "b ftrace_stub" to ensure ftrace_caller() is executed */
 	ftrace_modify_code(MCOUNT_ADDR, INSN_NOP);
 
-	/* The return code is retured via data */
-	*(unsigned long *)data = 0;
-
 	return 0;
 }
 #endif	/* CONFIG_DYNAMIC_FTRACE */

commit 46e12c07b3b9603c60fc1d421ff18618241cb081
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Sat Jul 14 09:22:05 2012 +0200

    MIPS: O32 / 32-bit: Always copy 4 stack arguments.
    
    This gets us rid of the hard to maintain table of the number of syscall
    arguments and paves the way for further restructuring of the syscall
    code.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 6e022c44f447..185ba258361b 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -383,7 +383,7 @@ unsigned long __init arch_syscall_addr(int nr)
 {
 #ifdef CONFIG_MIPS32_N32
 	if (nr >= __NR_N32_Linux && nr <= __NR_N32_Linux + __NR_N32_Linux_syscalls)
-		return (unsigned long)sysn32_call_table[(nr - __NR_N32_Linux) * 2];
+		return (unsigned long)sysn32_call_table[nr - __NR_N32_Linux];
 #endif
 	if (nr >= __NR_64_Linux  && nr <= __NR_64_Linux + __NR_64_Linux_syscalls)
 		return (unsigned long)sys_call_table[nr - __NR_64_Linux];

commit 19e2e172f0ed2552793ecef506b00c3fa3421845
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Fri Jul 13 23:38:17 2012 +0200

    MIPS: Provide arch_syscall_addr.
    
    The generic version is wrong for MIPS.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index dba90ec0dc38..6e022c44f447 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -11,11 +11,14 @@
 #include <linux/uaccess.h>
 #include <linux/init.h>
 #include <linux/ftrace.h>
+#include <linux/syscalls.h>
 
 #include <asm/asm.h>
 #include <asm/asm-offsets.h>
 #include <asm/cacheflush.h>
+#include <asm/syscall.h>
 #include <asm/uasm.h>
+#include <asm/unistd.h>
 
 #include <asm-generic/sections.h>
 
@@ -364,3 +367,33 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	WARN_ON(1);
 }
 #endif	/* CONFIG_FUNCTION_GRAPH_TRACER */
+
+#ifdef CONFIG_FTRACE_SYSCALLS
+
+#ifdef CONFIG_32BIT
+unsigned long __init arch_syscall_addr(int nr)
+{
+	return (unsigned long)sys_call_table[nr - __NR_O32_Linux];
+}
+#endif
+
+#ifdef CONFIG_64BIT
+
+unsigned long __init arch_syscall_addr(int nr)
+{
+#ifdef CONFIG_MIPS32_N32
+	if (nr >= __NR_N32_Linux && nr <= __NR_N32_Linux + __NR_N32_Linux_syscalls)
+		return (unsigned long)sysn32_call_table[(nr - __NR_N32_Linux) * 2];
+#endif
+	if (nr >= __NR_64_Linux  && nr <= __NR_64_Linux + __NR_64_Linux_syscalls)
+		return (unsigned long)sys_call_table[nr - __NR_64_Linux];
+#ifdef CONFIG_MIPS32_O32
+	if (nr >= __NR_O32_Linux && nr <= __NR_O32_Linux + __NR_O32_Linux_syscalls)
+		return (unsigned long)sys32_call_table[nr - __NR_O32_Linux];
+#endif
+
+	return (unsigned long) &sys_ni_syscall;
+}
+#endif
+
+#endif /* CONFIG_FTRACE_SYSCALLS */

commit cb2f9938d0a57625644750e66373d3bf4d3a1601
Author: Markos Chandras <markos.chandras@imgtec.com>
Date:   Mon Jun 10 10:35:26 2013 +0000

    MIPS: ftrace: Add missing CONFIG_DYNAMIC_FTRACE
    
    arch_ftrace_update_code and ftrace_modify_all_code are only
    available if CONFIG_DYNAMIC_FTRACE is selected.
    
    Fixes the following build problem on MIPS randconfig:
    
    arch/mips/kernel/ftrace.c: In function 'arch_ftrace_update_code':
    arch/mips/kernel/ftrace.c:31:2: error: implicit declaration of function
    'ftrace_modify_all_code' [-Werror=implicit-function-declaration]
    
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>
    Acked-by: Steven J. Hill <Steven.Hill@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/5435/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index cf5509f13dd5..dba90ec0dc38 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -25,12 +25,16 @@
 #define MCOUNT_OFFSET_INSNS 4
 #endif
 
+#ifdef CONFIG_DYNAMIC_FTRACE
+
 /* Arch override because MIPS doesn't need to run this from stop_machine() */
 void arch_ftrace_update_code(int command)
 {
 	ftrace_modify_all_code(command);
 }
 
+#endif
+
 /*
  * Check if the address is in kernel space
  *

commit 7034228792cc561e79ff8600f02884bd4c80e287
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jan 22 12:59:30 2013 +0100

    MIPS: Whitespace cleanup.
    
    Having received another series of whitespace patches I decided to do this
    once and for all rather than dealing with this kind of patches trickling
    in forever.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 83fa1460e294..cf5509f13dd5 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -125,21 +125,21 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
  *
  * 2.1 For KBUILD_MCOUNT_RA_ADDRESS and CONFIG_32BIT
  *
- * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
+ * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000005)
  * addiu v1, v1, low_16bit_of_mcount
  * move at, ra
  * move $12, ra_address
  * jalr v1
  *  sub sp, sp, 8
- *                                  1: offset = 5 instructions
+ *				    1: offset = 5 instructions
  * 2.2 For the Other situations
  *
- * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
+ * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000004)
  * addiu v1, v1, low_16bit_of_mcount
  * move at, ra
  * jalr v1
  *  nop | move $12, ra_address | sub sp, sp, 8
- *                                  1: offset = 4 instructions
+ *				    1: offset = 4 instructions
  */
 
 #define INSN_B_1F (0x10000000 | MCOUNT_OFFSET_INSNS)
@@ -228,8 +228,8 @@ int ftrace_disable_ftrace_graph_caller(void)
 
 #ifndef KBUILD_MCOUNT_RA_ADDRESS
 
-#define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
-#define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
+#define S_RA_SP (0xafbf << 16)	/* s{d,w} ra, offset(sp) */
+#define S_R_SP	(0xafb0 << 16)	/* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
 
 unsigned long ftrace_get_parent_ra_addr(unsigned long self_ra, unsigned long

commit 58b69401c797e470c8f638c598dddc44a4ce8a96
Author: Al Cooper <alcooperx@gmail.com>
Date:   Wed Jan 16 22:43:28 2013 +0000

    MIPS: Function tracer: Fix broken function tracing
    
    Function tracing is currently broken for all 32 bit MIPS platforms.
    When tracing is enabled, the kernel immediately hangs on boot.
    This is a result of commit b732d439cb43336cd6d7e804ecb2c81193ef63b0
    that changes the kernel/trace/Kconfig file so that is no longer
    forces FRAME_POINTER when FUNCTION_TRACING is enabled.
    
    MIPS frame pointers are generally considered to be useless because
    they cannot be used to unwind the stack. Unfortunately the MIPS
    function tracing code has bugs that are masked by the use of frame
    pointers. This commit fixes the bugs so that MIPS frame pointers
    don't need to be enabled.
    
    The bugs are a result of the odd calling sequence used to call the trace
    routine. This calling sequence is inserted into every traceable function
    when the tracing CONFIG option is enabled. This sequence is generated
    for 32bit MIPS platforms by the compiler via the "-pg" flag.
    
    Part of the sequence is "addiu sp,sp,-8" in the delay slot after every
    call to the trace routine "_mcount" (some legacy thing where 2 arguments
    used to be pushed on the stack). The _mcount routine is expected to
    adjust the sp by +8 before returning.  So when not disabled, the original
    jalr and addiu will be there, so _mcount has to adjust sp.
    
    The problem is that when tracing is disabled for a function, the
    "jalr _mcount" instruction is replaced with a nop, but the
    "addiu sp,sp,-8" is still executed and the stack pointer is left
    trashed. When frame pointers are enabled the problem is masked
    because any access to the stack is done through the frame
    pointer and the stack pointer is restored from the frame pointer when
    the function returns.
    
    This patch writes two nops starting at the address of the "jalr _mcount"
    instruction whenever tracing is disabled. This means that the
    "addiu sp,sp.-8" will be converted to a nop along with the "jalr".  When
    disabled, there will be two nops.
    
    This is SMP safe because the first time this happens is during
    ftrace_init() which is before any other processor has been started.
    Subsequent calls to enable/disable tracing when other CPUs ARE running
    will still be safe because the enable will only change the first nop
    to a "jalr" and the disable, while writing 2 nops, will only be changing
    the "jalr". This patch also stops using stop_machine() to call the
    tracer enable/disable routines and calls them directly because the
    routines are SMP safe.
    
    When the kernel first boots we have to be able to handle the gcc
    generated jalr, addui sequence until ftrace_init gets a chance to run
    and change the sequence. At this point mcount just adjusts the stack
    and returns. When ftrace_init runs, we convert the jalr/addui to nops.
    Then whenever tracing is enabled we convert the first nop to a "jalr
    mcount+8". The mcount+8 entry point skips the stack adjust.
    
    [ralf@linux-mips.org: Folded in  Steven Rostedt's build fix.]
    
    Signed-off-by: Al Cooper <alcooperx@gmail.com>
    Cc: rostedt@goodmis.org
    Cc: ddaney.cavm@gmail.com
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/4806/
    Patchwork: https://patchwork.linux-mips.org/patch/4841/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 6a2d758dd8e9..83fa1460e294 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -25,6 +25,12 @@
 #define MCOUNT_OFFSET_INSNS 4
 #endif
 
+/* Arch override because MIPS doesn't need to run this from stop_machine() */
+void arch_ftrace_update_code(int command)
+{
+	ftrace_modify_all_code(command);
+}
+
 /*
  * Check if the address is in kernel space
  *
@@ -89,6 +95,24 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 	return 0;
 }
 
+#ifndef CONFIG_64BIT
+static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
+				unsigned int new_code2)
+{
+	int faulted;
+
+	safe_store_code(new_code1, ip, faulted);
+	if (unlikely(faulted))
+		return -EFAULT;
+	ip += 4;
+	safe_store_code(new_code2, ip, faulted);
+	if (unlikely(faulted))
+		return -EFAULT;
+	flush_icache_range(ip, ip + 8); /* original ip + 12 */
+	return 0;
+}
+#endif
+
 /*
  * The details about the calling site of mcount on MIPS
  *
@@ -131,8 +155,18 @@ int ftrace_make_nop(struct module *mod,
 	 * needed.
 	 */
 	new = in_kernel_space(ip) ? INSN_NOP : INSN_B_1F;
-
+#ifdef CONFIG_64BIT
 	return ftrace_modify_code(ip, new);
+#else
+	/*
+	 * On 32 bit MIPS platforms, gcc adds a stack adjust
+	 * instruction in the delay slot after the branch to
+	 * mcount and expects mcount to restore the sp on return.
+	 * This is based on a legacy API and does nothing but
+	 * waste instructions so it's being removed at runtime.
+	 */
+	return ftrace_modify_code_2(ip, new, INSN_NOP);
+#endif
 }
 
 int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)

commit 49de830ad7b94d05f6dbfbae97a03f80169a7462
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 23 12:41:23 2011 +0000

    MIPS: Ftrace: Fix the CONFIG_DYNAMIC_FTRACE=n compile
    
    arch/mips/kernel/ftrace.c: In function ‘ftrace_get_parent_ra_addr’:
    arch/mips/kernel/ftrace.c:212: error: implicit declaration of function ‘in_kernel_space’
    arch/mips/kernel/ftrace.c: In function ‘prepare_ftrace_return’:
    arch/mips/kernel/ftrace.c:314: error: ‘MCOUNT_OFFSET_INSNS’ undeclared (first use in this function)
    arch/mips/kernel/ftrace.c:314: error: (Each undeclared identifier is reported only once
    arch/mips/kernel/ftrace.c:314: error: for each function it appears in.)
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    To: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2634/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index feb8021a305f..6a2d758dd8e9 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -19,6 +19,26 @@
 
 #include <asm-generic/sections.h>
 
+#if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
+#define MCOUNT_OFFSET_INSNS 5
+#else
+#define MCOUNT_OFFSET_INSNS 4
+#endif
+
+/*
+ * Check if the address is in kernel space
+ *
+ * Clone core_kernel_text() from kernel/extable.c, but doesn't call
+ * init_kernel_text() for Ftrace doesn't trace functions in init sections.
+ */
+static inline int in_kernel_space(unsigned long ip)
+{
+	if (ip >= (unsigned long)_stext &&
+	    ip <= (unsigned long)_etext)
+		return 1;
+	return 0;
+}
+
 #ifdef CONFIG_DYNAMIC_FTRACE
 
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
@@ -54,20 +74,6 @@ static inline void ftrace_dyn_arch_init_insns(void)
 #endif
 }
 
-/*
- * Check if the address is in kernel space
- *
- * Clone core_kernel_text() from kernel/extable.c, but doesn't call
- * init_kernel_text() for Ftrace doesn't trace functions in init sections.
- */
-static inline int in_kernel_space(unsigned long ip)
-{
-	if (ip >= (unsigned long)_stext &&
-	    ip <= (unsigned long)_etext)
-		return 1;
-	return 0;
-}
-
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
 	int faulted;
@@ -112,11 +118,6 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
  *                                  1: offset = 4 instructions
  */
 
-#if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
-#define MCOUNT_OFFSET_INSNS 5
-#else
-#define MCOUNT_OFFSET_INSNS 4
-#endif
 #define INSN_B_1F (0x10000000 | MCOUNT_OFFSET_INSNS)
 
 int ftrace_make_nop(struct module *mod,

commit c54794d19e61472156e37263c074225574c80df1
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Tue Dec 28 13:21:37 2010 -0800

    MIPS: Mask jump target in ftrace_dyn_arch_init_insns().
    
    The current code is abusing the uasm interface by passing jump target
    addresses with high bits set.  Mask the addresses to avoid annoying
    messages at boot time.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Patchwork: https://patchwork.linux-mips.org/patch/1922/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 94ca2b018af7..feb8021a305f 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -23,6 +23,7 @@
 
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
 #define ADDR_MASK 0x03ffffff	/*  op_code|addr : 31...26|25 ....0 */
+#define JUMP_RANGE_MASK ((1UL << 28) - 1)
 
 #define INSN_NOP 0x00000000	/* nop */
 #define INSN_JAL(addr)	\
@@ -44,12 +45,12 @@ static inline void ftrace_dyn_arch_init_insns(void)
 
 	/* jal (ftrace_caller + 8), jump over the first two instruction */
 	buf = (u32 *)&insn_jal_ftrace_caller;
-	uasm_i_jal(&buf, (FTRACE_ADDR + 8));
+	uasm_i_jal(&buf, (FTRACE_ADDR + 8) & JUMP_RANGE_MASK);
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	/* j ftrace_graph_caller */
 	buf = (u32 *)&insn_j_ftrace_graph_caller;
-	uasm_i_j(&buf, (unsigned long)ftrace_graph_caller);
+	uasm_i_j(&buf, (unsigned long)ftrace_graph_caller & JUMP_RANGE_MASK);
 #endif
 }
 

commit b9f07eb2f25a64098e2ba223c1a2fe2a8f249e01
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Sat Jan 22 02:01:53 2011 +0800

    MIPS, Tracing: Fix set_graph_function of function graph tracer
    
    trace.func should be set to the recorded ip of the mcount calling site
    in the __mcount_loc section to filter the function entries configured
    through the tracing/set_graph_function interface, but before, this is
    set to the self_ra(the return address of mcount), which has made
    set_graph_function not work as expected.
    
    This fixes it via calculating the right recorded ip in the __mcount_loc
    section and assign it to trace.func.
    
    Reported-by: Zhiping Zhong <xzhong86@163.com>
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: Sergei Shtylyov <sshtylyov@mvista.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2017/
    Signed-off-by: Ralf Baechle <ralf@duck.linux-mips.net>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index bc91e4aa08e9..94ca2b018af7 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -257,7 +257,7 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 	struct ftrace_graph_ent trace;
 	unsigned long return_hooker = (unsigned long)
 	    &return_to_handler;
-	int faulted;
+	int faulted, insns;
 
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		return;
@@ -304,7 +304,14 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 		return;
 	}
 
-	trace.func = self_ra;
+	/*
+	 * Get the recorded ip of the current mcount calling site in the
+	 * __mcount_loc section, which will be used to filter the function
+	 * entries configured through the tracing/set_graph_function interface.
+	 */
+
+	insns = in_kernel_space(self_ra) ? 2 : MCOUNT_OFFSET_INSNS + 1;
+	trace.func = self_ra - (MCOUNT_INSN_SIZE * insns);
 
 	/* Only trace if the calling function expects to */
 	if (!ftrace_graph_entry(&trace)) {

commit 7f21a60968221eabad5c53fe760db3d094994011
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Thu Jan 20 03:28:31 2011 +0800

    MIPS, Tracing: Clean up ftrace_make_nop()
    
    This moves the comments out of ftrace_make_nop() and cleans it.  At the
    same time, a macro MCOUNT_OFFSET_INSNS is defined for sharing with the
    next patch.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2008/
    Signed-off-by: Ralf Baechle <ralf@duck.linux-mips.net>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 40ef34ccb76b..bc91e4aa08e9 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -24,8 +24,6 @@
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
 #define ADDR_MASK 0x03ffffff	/*  op_code|addr : 31...26|25 ....0 */
 
-#define INSN_B_1F_4 0x10000004	/* b 1f; offset = 4 */
-#define INSN_B_1F_5 0x10000005	/* b 1f; offset = 5 */
 #define INSN_NOP 0x00000000	/* nop */
 #define INSN_JAL(addr)	\
 	((unsigned int)(JAL | (((addr) >> 2) & ADDR_MASK)))
@@ -84,6 +82,42 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 	return 0;
 }
 
+/*
+ * The details about the calling site of mcount on MIPS
+ *
+ * 1. For kernel:
+ *
+ * move at, ra
+ * jal _mcount		--> nop
+ *
+ * 2. For modules:
+ *
+ * 2.1 For KBUILD_MCOUNT_RA_ADDRESS and CONFIG_32BIT
+ *
+ * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
+ * addiu v1, v1, low_16bit_of_mcount
+ * move at, ra
+ * move $12, ra_address
+ * jalr v1
+ *  sub sp, sp, 8
+ *                                  1: offset = 5 instructions
+ * 2.2 For the Other situations
+ *
+ * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
+ * addiu v1, v1, low_16bit_of_mcount
+ * move at, ra
+ * jalr v1
+ *  nop | move $12, ra_address | sub sp, sp, 8
+ *                                  1: offset = 4 instructions
+ */
+
+#if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
+#define MCOUNT_OFFSET_INSNS 5
+#else
+#define MCOUNT_OFFSET_INSNS 4
+#endif
+#define INSN_B_1F (0x10000000 | MCOUNT_OFFSET_INSNS)
+
 int ftrace_make_nop(struct module *mod,
 		    struct dyn_ftrace *rec, unsigned long addr)
 {
@@ -94,36 +128,8 @@ int ftrace_make_nop(struct module *mod,
 	 * If ip is in kernel space, no long call, otherwise, long call is
 	 * needed.
 	 */
-	if (in_kernel_space(ip)) {
-		/*
-		 * move at, ra
-		 * jal _mcount		--> nop
-		 */
-		new = INSN_NOP;
-	} else {
-#if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
-		/*
-		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
-		 * addiu v1, v1, low_16bit_of_mcount
-		 * move at, ra
-		 * move $12, ra_address
-		 * jalr v1
-		 *  sub sp, sp, 8
-		 *                                  1: offset = 5 instructions
-		 */
-		new = INSN_B_1F_5;
-#else
-		/*
-		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
-		 * addiu v1, v1, low_16bit_of_mcount
-		 * move at, ra
-		 * jalr v1
-		 *  nop | move $12, ra_address | sub sp, sp, 8
-		 *                                  1: offset = 4 instructions
-		 */
-		new = INSN_B_1F_4;
-#endif
-	}
+	new = in_kernel_space(ip) ? INSN_NOP : INSN_B_1F;
+
 	return ftrace_modify_code(ip, new);
 }
 

commit 2816e325969396af5bd1d5f70c7360074ae1d63c
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Thu Jan 20 03:28:30 2011 +0800

    MIPS, Tracing: Clean up prepare_ftrace_return()
    
    The old prepare_ftrace_return() for MIPS is confused and have introduced
    some problem. This patch cleans up the names of the arguments, variables
    and related functions.
    
    For MIPS, the 2nd argument of prepare_ftrace_return() is not really the
    'selfpc' described in ftrace-design.txt but instead it is the self
    return address. This did break the compatibility of the generic
    interface but really reduced one unneeded calculation for to get the
    current function name, the parent return address and the self return
    address are enough, no need to tranform the self return address to the
    self address.
    
    But set_graph_function of function graph tracer is an exception, it does
    need the 2nd argument of prepare_ftrace_return() as 'selfpc', for it
    will use 'selfpc' to match user's configuration of function graph
    entries, but in reality, it doesn't need the 'selfpc' but the recorded
    ip address of the mcount calling site in the __mcount_loc section. So,
    the 2nd argument of prepare_ftrace_return() is not important, the real
    requirement is the right recorded ip address should be calculated and
    assign to trace.func, this will be fixed in the next patches.
    
    Reported-by: Zhiping Zhong <xzhong86@163.com>
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2007/
    Signed-off-by: Ralf Baechle <ralf@duck.linux-mips.net>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 5970286131dd..40ef34ccb76b 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -190,21 +190,19 @@ int ftrace_disable_ftrace_graph_caller(void)
 #define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
 
-unsigned long ftrace_get_parent_addr(unsigned long self_addr,
-				     unsigned long parent,
-				     unsigned long parent_addr,
-				     unsigned long fp)
+unsigned long ftrace_get_parent_ra_addr(unsigned long self_ra, unsigned long
+		old_parent_ra, unsigned long parent_ra_addr, unsigned long fp)
 {
-	unsigned long sp, ip, ra;
+	unsigned long sp, ip, tmp;
 	unsigned int code;
 	int faulted;
 
 	/*
-	 * For module, move the ip from calling site of mcount after the
+	 * For module, move the ip from the return address after the
 	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 24), but for
 	 * kernel, move after the instruction "move ra, at"(offset is 16)
 	 */
-	ip = self_addr - (in_kernel_space(self_addr) ? 16 : 24);
+	ip = self_ra - (in_kernel_space(self_ra) ? 16 : 24);
 
 	/*
 	 * search the text until finding the non-store instruction or "s{d,w}
@@ -222,7 +220,7 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 		 * store the ra on the stack
 		 */
 		if ((code & S_R_SP) != S_R_SP)
-			return parent_addr;
+			return parent_ra_addr;
 
 		/* Move to the next instruction */
 		ip -= 4;
@@ -230,12 +228,12 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 
 	sp = fp + (code & OFFSET_MASK);
 
-	/* ra = *(unsigned long *)sp; */
-	safe_load_stack(ra, sp, faulted);
+	/* tmp = *(unsigned long *)sp; */
+	safe_load_stack(tmp, sp, faulted);
 	if (unlikely(faulted))
 		return 0;
 
-	if (ra == parent)
+	if (tmp == old_parent_ra)
 		return sp;
 	return 0;
 }
@@ -246,10 +244,10 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
  * Hook the return address and push it in the stack of return addrs
  * in current thread info.
  */
-void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
+void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 			   unsigned long fp)
 {
-	unsigned long old;
+	unsigned long old_parent_ra;
 	struct ftrace_graph_ent trace;
 	unsigned long return_hooker = (unsigned long)
 	    &return_to_handler;
@@ -259,8 +257,8 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 		return;
 
 	/*
-	 * "parent" is the stack address saved the return address of the caller
-	 * of _mcount.
+	 * "parent_ra_addr" is the stack address saved the return address of
+	 * the caller of _mcount.
 	 *
 	 * if the gcc < 4.5, a leaf function does not save the return address
 	 * in the stack address, so, we "emulate" one in _mcount's stack space,
@@ -275,37 +273,37 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	 * do it in ftrace_graph_caller of mcount.S.
 	 */
 
-	/* old = *parent; */
-	safe_load_stack(old, parent, faulted);
+	/* old_parent_ra = *parent_ra_addr; */
+	safe_load_stack(old_parent_ra, parent_ra_addr, faulted);
 	if (unlikely(faulted))
 		goto out;
 #ifndef KBUILD_MCOUNT_RA_ADDRESS
-	parent = (unsigned long *)ftrace_get_parent_addr(self_addr, old,
-			(unsigned long)parent, fp);
+	parent_ra_addr = (unsigned long *)ftrace_get_parent_ra_addr(self_ra,
+			old_parent_ra, (unsigned long)parent_ra_addr, fp);
 	/*
 	 * If fails when getting the stack address of the non-leaf function's
 	 * ra, stop function graph tracer and return
 	 */
-	if (parent == 0)
+	if (parent_ra_addr == 0)
 		goto out;
 #endif
-	/* *parent = return_hooker; */
-	safe_store_stack(return_hooker, parent, faulted);
+	/* *parent_ra_addr = return_hooker; */
+	safe_store_stack(return_hooker, parent_ra_addr, faulted);
 	if (unlikely(faulted))
 		goto out;
 
-	if (ftrace_push_return_trace(old, self_addr, &trace.depth, fp) ==
-	    -EBUSY) {
-		*parent = old;
+	if (ftrace_push_return_trace(old_parent_ra, self_ra, &trace.depth, fp)
+	    == -EBUSY) {
+		*parent_ra_addr = old_parent_ra;
 		return;
 	}
 
-	trace.func = self_addr;
+	trace.func = self_ra;
 
 	/* Only trace if the calling function expects to */
 	if (!ftrace_graph_entry(&trace)) {
 		current->curr_ret_stack--;
-		*parent = old;
+		*parent_ra_addr = old_parent_ra;
 	}
 	return;
 out:

commit d9cdb2f1038143c945fcb1a366aae4fa2998419e
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Thu Jan 20 03:28:29 2011 +0800

    MIPS, Tracing: Substitute in_kernel_space() for in_module()
    
    The old in_module() may not work in some situations(e.g. when module &
    kernel are in the same address space when CONFIG_MAPPED_KERNEL=y), The
    in_kernel_space() is more generic and it is also easy to be implemented
    via cloning the existing core_kernel_text(), so, replace the in_module()
    with in_kernel_space().
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2005/
    Signed-off-by: Ralf Baechle <ralf@duck.linux-mips.net>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 635c1dcdc4fc..5970286131dd 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -17,21 +17,7 @@
 #include <asm/cacheflush.h>
 #include <asm/uasm.h>
 
-/*
- * If the Instruction Pointer is in module space (0xc0000000), return true;
- * otherwise, it is in kernel space (0x80000000), return false.
- *
- * FIXME: This will not work when the kernel space and module space are the
- * same. If they are the same, we need to modify scripts/recordmcount.pl,
- * ftrace_make_nop/call() and the other related parts to ensure the
- * enabling/disabling of the calling site to _mcount is right for both kernel
- * and module.
- */
-
-static inline int in_module(unsigned long ip)
-{
-	return ip & 0x40000000;
-}
+#include <asm-generic/sections.h>
 
 #ifdef CONFIG_DYNAMIC_FTRACE
 
@@ -69,6 +55,20 @@ static inline void ftrace_dyn_arch_init_insns(void)
 #endif
 }
 
+/*
+ * Check if the address is in kernel space
+ *
+ * Clone core_kernel_text() from kernel/extable.c, but doesn't call
+ * init_kernel_text() for Ftrace doesn't trace functions in init sections.
+ */
+static inline int in_kernel_space(unsigned long ip)
+{
+	if (ip >= (unsigned long)_stext &&
+	    ip <= (unsigned long)_etext)
+		return 1;
+	return 0;
+}
+
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
 	int faulted;
@@ -91,10 +91,16 @@ int ftrace_make_nop(struct module *mod,
 	unsigned long ip = rec->ip;
 
 	/*
-	 * We have compiled module with -mlong-calls, but compiled the kernel
-	 * without it, we need to cope with them respectively.
+	 * If ip is in kernel space, no long call, otherwise, long call is
+	 * needed.
 	 */
-	if (in_module(ip)) {
+	if (in_kernel_space(ip)) {
+		/*
+		 * move at, ra
+		 * jal _mcount		--> nop
+		 */
+		new = INSN_NOP;
+	} else {
 #if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
 		/*
 		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
@@ -117,12 +123,6 @@ int ftrace_make_nop(struct module *mod,
 		 */
 		new = INSN_B_1F_4;
 #endif
-	} else {
-		/*
-		 * move at, ra
-		 * jal _mcount		--> nop
-		 */
-		new = INSN_NOP;
 	}
 	return ftrace_modify_code(ip, new);
 }
@@ -132,8 +132,8 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	unsigned int new;
 	unsigned long ip = rec->ip;
 
-	/* ip, module: 0xc0000000, kernel: 0x80000000 */
-	new = in_module(ip) ? insn_lui_v1_hi16_mcount : insn_jal_ftrace_caller;
+	new = in_kernel_space(ip) ? insn_jal_ftrace_caller :
+		insn_lui_v1_hi16_mcount;
 
 	return ftrace_modify_code(ip, new);
 }
@@ -204,7 +204,7 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 24), but for
 	 * kernel, move after the instruction "move ra, at"(offset is 16)
 	 */
-	ip = self_addr - (in_module(self_addr) ? 24 : 16);
+	ip = self_addr - (in_kernel_space(self_addr) ? 16 : 24);
 
 	/*
 	 * search the text until finding the non-store instruction or "s{d,w}

commit 9a620a559be65023b5fd5d0eaf37dae884c4f404
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Thu Jan 20 03:28:27 2011 +0800

    MIPS, Tracing: Speed up function graph tracer
    
    This simply moves the "ip-=4" statement down to the end of the do { ...
    } while (...); loop, which reduces one unneeded subtration and the
    subsequent memory loading and comparison.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2006/
    Signed-off-by: Ralf Baechle <ralf@duck.linux-mips.net>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 5a84a1f11231..635c1dcdc4fc 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -200,19 +200,17 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	int faulted;
 
 	/*
-	 * For module, move the ip from calling site of mcount to the
-	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 20), but for
-	 * kernel, move to the instruction "move ra, at"(offset is 12)
+	 * For module, move the ip from calling site of mcount after the
+	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 24), but for
+	 * kernel, move after the instruction "move ra, at"(offset is 16)
 	 */
-	ip = self_addr - (in_module(self_addr) ? 20 : 12);
+	ip = self_addr - (in_module(self_addr) ? 24 : 16);
 
 	/*
 	 * search the text until finding the non-store instruction or "s{d,w}
 	 * ra, offset(sp)" instruction
 	 */
 	do {
-		ip -= 4;
-
 		/* get the code at "ip": code = *(unsigned int *)ip; */
 		safe_load_code(code, ip, faulted);
 
@@ -226,7 +224,9 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 		if ((code & S_R_SP) != S_R_SP)
 			return parent_addr;
 
-	} while (((code & S_RA_SP) != S_RA_SP));
+		/* Move to the next instruction */
+		ip -= 4;
+	} while ((code & S_RA_SP) != S_RA_SP);
 
 	sp = fp + (code & OFFSET_MASK);
 

commit c9f84873c1231621508cd438bb2991ddba770a69
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri May 14 19:08:34 2010 +0800

    MIPS: Tracing: Cleanup of address space checking
    
    This patch adds an inline function in_module() to check which space the
    instruction pointer in, kernel space or module space.
    
    Note:  This will not work when the kernel space and module space are the
    same. If they are the same, we need to modify scripts/recordmcount.pl,
    ftrace_make_nop/call() and the other related parts to ensure the
    enabling/disabling of the calling site to _mcount is right for both
    kernel and module.
    
    [Ralf: It also is still incorrect for some 64-bit kernels.]
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips <linux-mips@linux-mips.org>
    Cc: David Daney <david.s.daney@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/1232/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 628e90b992d1..5a84a1f11231 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -17,6 +17,22 @@
 #include <asm/cacheflush.h>
 #include <asm/uasm.h>
 
+/*
+ * If the Instruction Pointer is in module space (0xc0000000), return true;
+ * otherwise, it is in kernel space (0x80000000), return false.
+ *
+ * FIXME: This will not work when the kernel space and module space are the
+ * same. If they are the same, we need to modify scripts/recordmcount.pl,
+ * ftrace_make_nop/call() and the other related parts to ensure the
+ * enabling/disabling of the calling site to _mcount is right for both kernel
+ * and module.
+ */
+
+static inline int in_module(unsigned long ip)
+{
+	return ip & 0x40000000;
+}
+
 #ifdef CONFIG_DYNAMIC_FTRACE
 
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
@@ -78,7 +94,7 @@ int ftrace_make_nop(struct module *mod,
 	 * We have compiled module with -mlong-calls, but compiled the kernel
 	 * without it, we need to cope with them respectively.
 	 */
-	if (ip & 0x40000000) {
+	if (in_module(ip)) {
 #if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
 		/*
 		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
@@ -117,7 +133,7 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	unsigned long ip = rec->ip;
 
 	/* ip, module: 0xc0000000, kernel: 0x80000000 */
-	new = (ip & 0x40000000) ? insn_lui_v1_hi16_mcount : insn_jal_ftrace_caller;
+	new = in_module(ip) ? insn_lui_v1_hi16_mcount : insn_jal_ftrace_caller;
 
 	return ftrace_modify_code(ip, new);
 }
@@ -188,7 +204,7 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 20), but for
 	 * kernel, move to the instruction "move ra, at"(offset is 12)
 	 */
-	ip = self_addr - ((self_addr & 0x40000000) ? 20 : 12);
+	ip = self_addr - (in_module(self_addr) ? 20 : 12);
 
 	/*
 	 * search the text until finding the non-store instruction or "s{d,w}

commit 68ccf7521dc89bfcf01432fd1bf8cb4d7d534e4c
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri May 14 19:08:33 2010 +0800

    MIPS: Tracing: Cleanup of function graph tracer
    
    Cleans up comments and ftrace_get_parent_addr() of function graph tracer.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips <linux-mips@linux-mips.org>
    Cc: David Daney <david.s.daney@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/1231/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index c4042cad836e..628e90b992d1 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -146,7 +146,7 @@ int __init ftrace_dyn_arch_init(void *data)
 
 	return 0;
 }
-#endif				/* CONFIG_DYNAMIC_FTRACE */
+#endif	/* CONFIG_DYNAMIC_FTRACE */
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 
@@ -166,9 +166,10 @@ int ftrace_disable_ftrace_graph_caller(void)
 	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP, INSN_NOP);
 }
 
-#endif				/* !CONFIG_DYNAMIC_FTRACE */
+#endif	/* CONFIG_DYNAMIC_FTRACE */
 
 #ifndef KBUILD_MCOUNT_RA_ADDRESS
+
 #define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
 #define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
@@ -182,17 +183,17 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	unsigned int code;
 	int faulted;
 
-	/* in module or kernel? */
-	if (self_addr & 0x40000000) {
-		/* module: move to the instruction "lui v1, HI_16BIT_OF_MCOUNT" */
-		ip = self_addr - 20;
-	} else {
-		/* kernel: move to the instruction "move ra, at" */
-		ip = self_addr - 12;
-	}
+	/*
+	 * For module, move the ip from calling site of mcount to the
+	 * instruction "lui v1, hi_16bit_of_mcount"(offset is 20), but for
+	 * kernel, move to the instruction "move ra, at"(offset is 12)
+	 */
+	ip = self_addr - ((self_addr & 0x40000000) ? 20 : 12);
 
-	/* search the text until finding the non-store instruction or "s{d,w}
-	 * ra, offset(sp)" instruction */
+	/*
+	 * search the text until finding the non-store instruction or "s{d,w}
+	 * ra, offset(sp)" instruction
+	 */
 	do {
 		ip -= 4;
 
@@ -201,10 +202,11 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 
 		if (unlikely(faulted))
 			return 0;
-
-		/* If we hit the non-store instruction before finding where the
+		/*
+		 * If we hit the non-store instruction before finding where the
 		 * ra is stored, then this is a leaf function and it does not
-		 * store the ra on the stack. */
+		 * store the ra on the stack
+		 */
 		if ((code & S_R_SP) != S_R_SP)
 			return parent_addr;
 
@@ -222,7 +224,7 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	return 0;
 }
 
-#endif
+#endif	/* !KBUILD_MCOUNT_RA_ADDRESS */
 
 /*
  * Hook the return address and push it in the stack of return addrs
@@ -240,7 +242,8 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		return;
 
-	/* "parent" is the stack address saved the return address of the caller
+	/*
+	 * "parent" is the stack address saved the return address of the caller
 	 * of _mcount.
 	 *
 	 * if the gcc < 4.5, a leaf function does not save the return address
@@ -262,10 +265,11 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 		goto out;
 #ifndef KBUILD_MCOUNT_RA_ADDRESS
 	parent = (unsigned long *)ftrace_get_parent_addr(self_addr, old,
-							 (unsigned long)parent,
-							 fp);
-	/* If fails when getting the stack address of the non-leaf function's
-	 * ra, stop function graph tracer and return */
+			(unsigned long)parent, fp);
+	/*
+	 * If fails when getting the stack address of the non-leaf function's
+	 * ra, stop function graph tracer and return
+	 */
 	if (parent == 0)
 		goto out;
 #endif
@@ -292,4 +296,4 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	ftrace_graph_stop();
 	WARN_ON(1);
 }
-#endif				/* CONFIG_FUNCTION_GRAPH_TRACER */
+#endif	/* CONFIG_FUNCTION_GRAPH_TRACER */

commit e424054000878d7eb11e44289242886d6e219d22
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri May 14 19:08:32 2010 +0800

    MIPS: Tracing: Reduce the overhead of dynamic Function Tracer
    
    With the help of uasm this patch encodes the instructions of the dynamic
    function tracer in ftrace_dyn_arch_init() when initializing it.
    
    As a result we can remove the dynamic encoding of instructions in
    ftrace_make_nop()/call(), ftrace_enable_ftrace_graph_caller() and remove
    the macro jump_insn_encode() and at last this reduce the overhead of
    dynamic Function Tracer.  This also is cleaner.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips <linux-mips@linux-mips.org>
    Cc: David Daney <david.s.daney@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/1230/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index b1b8fec2432f..c4042cad836e 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -2,7 +2,7 @@
  * Code for replacing ftrace calls with jumps.
  *
  * Copyright (C) 2007-2008 Steven Rostedt <srostedt@redhat.com>
- * Copyright (C) 2009 DSLab, Lanzhou University, China
+ * Copyright (C) 2009, 2010 DSLab, Lanzhou University, China
  * Author: Wu Zhangjin <wuzhangjin@gmail.com>
  *
  * Thanks goes to Steven Rostedt for writing the original x86 version.
@@ -12,21 +12,46 @@
 #include <linux/init.h>
 #include <linux/ftrace.h>
 
-#include <asm/cacheflush.h>
 #include <asm/asm.h>
 #include <asm/asm-offsets.h>
+#include <asm/cacheflush.h>
+#include <asm/uasm.h>
 
 #ifdef CONFIG_DYNAMIC_FTRACE
 
 #define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
 #define ADDR_MASK 0x03ffffff	/*  op_code|addr : 31...26|25 ....0 */
-#define jump_insn_encode(op_code, addr) \
-	((unsigned int)((op_code) | (((addr) >> 2) & ADDR_MASK)))
 
 #define INSN_B_1F_4 0x10000004	/* b 1f; offset = 4 */
 #define INSN_B_1F_5 0x10000005	/* b 1f; offset = 5 */
 #define INSN_NOP 0x00000000	/* nop */
-#define INSN_JAL(addr)	jump_insn_encode(JAL, addr)
+#define INSN_JAL(addr)	\
+	((unsigned int)(JAL | (((addr) >> 2) & ADDR_MASK)))
+
+static unsigned int insn_jal_ftrace_caller __read_mostly;
+static unsigned int insn_lui_v1_hi16_mcount __read_mostly;
+static unsigned int insn_j_ftrace_graph_caller __maybe_unused __read_mostly;
+
+static inline void ftrace_dyn_arch_init_insns(void)
+{
+	u32 *buf;
+	unsigned int v1;
+
+	/* lui v1, hi16_mcount */
+	v1 = 3;
+	buf = (u32 *)&insn_lui_v1_hi16_mcount;
+	UASM_i_LA_mostly(&buf, v1, MCOUNT_ADDR);
+
+	/* jal (ftrace_caller + 8), jump over the first two instruction */
+	buf = (u32 *)&insn_jal_ftrace_caller;
+	uasm_i_jal(&buf, (FTRACE_ADDR + 8));
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+	/* j ftrace_graph_caller */
+	buf = (u32 *)&insn_j_ftrace_graph_caller;
+	uasm_i_j(&buf, (unsigned long)ftrace_graph_caller);
+#endif
+}
 
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
@@ -43,30 +68,20 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 	return 0;
 }
 
-static int lui_v1;
-static int jal_mcount;
-
 int ftrace_make_nop(struct module *mod,
 		    struct dyn_ftrace *rec, unsigned long addr)
 {
 	unsigned int new;
-	int faulted;
 	unsigned long ip = rec->ip;
 
-	/* We have compiled module with -mlong-calls, but compiled the kernel
-	 * without it, we need to cope with them respectively. */
+	/*
+	 * We have compiled module with -mlong-calls, but compiled the kernel
+	 * without it, we need to cope with them respectively.
+	 */
 	if (ip & 0x40000000) {
-		/* record it for ftrace_make_call */
-		if (lui_v1 == 0) {
-			/* lui_v1 = *(unsigned int *)ip; */
-			safe_load_code(lui_v1, ip, faulted);
-
-			if (unlikely(faulted))
-				return -EFAULT;
-		}
-
 #if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
-		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
+		/*
+		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
 		 * addiu v1, v1, low_16bit_of_mcount
 		 * move at, ra
 		 * move $12, ra_address
@@ -76,7 +91,8 @@ int ftrace_make_nop(struct module *mod,
 		 */
 		new = INSN_B_1F_5;
 #else
-		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
+		/*
+		 * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
 		 * addiu v1, v1, low_16bit_of_mcount
 		 * move at, ra
 		 * jalr v1
@@ -86,36 +102,22 @@ int ftrace_make_nop(struct module *mod,
 		new = INSN_B_1F_4;
 #endif
 	} else {
-		/* record/calculate it for ftrace_make_call */
-		if (jal_mcount == 0) {
-			/* We can record it directly like this:
-			 *     jal_mcount = *(unsigned int *)ip;
-			 * Herein, jump over the first two nop instructions */
-			jal_mcount = INSN_JAL(MCOUNT_ADDR + 8);
-		}
-
-		/* move at, ra
-		 * jalr v1		--> nop
+		/*
+		 * move at, ra
+		 * jal _mcount		--> nop
 		 */
 		new = INSN_NOP;
 	}
 	return ftrace_modify_code(ip, new);
 }
 
-static int modified;	/* initialized as 0 by default */
-
 int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 {
 	unsigned int new;
 	unsigned long ip = rec->ip;
 
-	/* We just need to remove the "b ftrace_stub" at the fist time! */
-	if (modified == 0) {
-		modified = 1;
-		ftrace_modify_code(addr, INSN_NOP);
-	}
 	/* ip, module: 0xc0000000, kernel: 0x80000000 */
-	new = (ip & 0x40000000) ? lui_v1 : jal_mcount;
+	new = (ip & 0x40000000) ? insn_lui_v1_hi16_mcount : insn_jal_ftrace_caller;
 
 	return ftrace_modify_code(ip, new);
 }
@@ -133,6 +135,12 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 
 int __init ftrace_dyn_arch_init(void *data)
 {
+	/* Encode the instructions when booting */
+	ftrace_dyn_arch_init_insns();
+
+	/* Remove "b ftrace_stub" to ensure ftrace_caller() is executed */
+	ftrace_modify_code(MCOUNT_ADDR, INSN_NOP);
+
 	/* The return code is retured via data */
 	*(unsigned long *)data = 0;
 
@@ -145,15 +153,12 @@ int __init ftrace_dyn_arch_init(void *data)
 #ifdef CONFIG_DYNAMIC_FTRACE
 
 extern void ftrace_graph_call(void);
-#define JMP	0x08000000	/* jump to target directly */
-#define CALL_FTRACE_GRAPH_CALLER \
-	jump_insn_encode(JMP, (unsigned long)(&ftrace_graph_caller))
 #define FTRACE_GRAPH_CALL_IP	((unsigned long)(&ftrace_graph_call))
 
 int ftrace_enable_ftrace_graph_caller(void)
 {
 	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP,
-				  CALL_FTRACE_GRAPH_CALLER);
+			insn_j_ftrace_graph_caller);
 }
 
 int ftrace_disable_ftrace_graph_caller(void)

commit 4d6829f92a02d96e1bec2ffe6ee674ef3b49722b
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri May 14 19:08:31 2010 +0800

    MIPS: Tracing: Cleanup of instructions used
    
    This patch adds some cleanups of the instructions:
      o use macros instead of magic numbers
      o use macros instead of variables to reduce some overhead
      o add new macro for the jal instruction
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips <linux-mips@linux-mips.org>
    Cc: David Daney <david.s.daney@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/1229/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 37aa7677e76d..b1b8fec2432f 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -23,7 +23,10 @@
 #define jump_insn_encode(op_code, addr) \
 	((unsigned int)((op_code) | (((addr) >> 2) & ADDR_MASK)))
 
-static unsigned int ftrace_nop = 0x00000000;
+#define INSN_B_1F_4 0x10000004	/* b 1f; offset = 4 */
+#define INSN_B_1F_5 0x10000005	/* b 1f; offset = 5 */
+#define INSN_NOP 0x00000000	/* nop */
+#define INSN_JAL(addr)	jump_insn_encode(JAL, addr)
 
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
@@ -71,7 +74,7 @@ int ftrace_make_nop(struct module *mod,
 		 *  sub sp, sp, 8
 		 *                                  1: offset = 5 instructions
 		 */
-		new = 0x10000005;
+		new = INSN_B_1F_5;
 #else
 		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
 		 * addiu v1, v1, low_16bit_of_mcount
@@ -80,7 +83,7 @@ int ftrace_make_nop(struct module *mod,
 		 *  nop | move $12, ra_address | sub sp, sp, 8
 		 *                                  1: offset = 4 instructions
 		 */
-		new = 0x10000004;
+		new = INSN_B_1F_4;
 #endif
 	} else {
 		/* record/calculate it for ftrace_make_call */
@@ -88,13 +91,13 @@ int ftrace_make_nop(struct module *mod,
 			/* We can record it directly like this:
 			 *     jal_mcount = *(unsigned int *)ip;
 			 * Herein, jump over the first two nop instructions */
-			jal_mcount = jump_insn_encode(JAL, (MCOUNT_ADDR + 8));
+			jal_mcount = INSN_JAL(MCOUNT_ADDR + 8);
 		}
 
 		/* move at, ra
 		 * jalr v1		--> nop
 		 */
-		new = ftrace_nop;
+		new = INSN_NOP;
 	}
 	return ftrace_modify_code(ip, new);
 }
@@ -109,7 +112,7 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	/* We just need to remove the "b ftrace_stub" at the fist time! */
 	if (modified == 0) {
 		modified = 1;
-		ftrace_modify_code(addr, ftrace_nop);
+		ftrace_modify_code(addr, INSN_NOP);
 	}
 	/* ip, module: 0xc0000000, kernel: 0x80000000 */
 	new = (ip & 0x40000000) ? lui_v1 : jal_mcount;
@@ -123,7 +126,7 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 {
 	unsigned int new;
 
-	new = jump_insn_encode(JAL, (unsigned long)func);
+	new = INSN_JAL((unsigned long)func);
 
 	return ftrace_modify_code(FTRACE_CALL_IP, new);
 }
@@ -155,7 +158,7 @@ int ftrace_enable_ftrace_graph_caller(void)
 
 int ftrace_disable_ftrace_graph_caller(void)
 {
-	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP, ftrace_nop);
+	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP, INSN_NOP);
 }
 
 #endif				/* !CONFIG_DYNAMIC_FTRACE */

commit 3a2af2dc1bcbfe86b1f39e9e5f9c2c5447943f16
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri May 14 19:08:30 2010 +0800

    MIPS: Tracing: Fix 32-bit support with -mmcount-ra-address
    
    For 32-bit kernel the -mmcount-ra-address option of gcc 4.5 emits one
    extra instruction before calling to _mcount so we need to use a different
    "b 1f" for it.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips <linux-mips@linux-mips.org>
    Cc: David Daney <david.s.daney@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/1228/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index e9e64e0ff7aa..37aa7677e76d 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -62,14 +62,26 @@ int ftrace_make_nop(struct module *mod,
 				return -EFAULT;
 		}
 
+#if defined(KBUILD_MCOUNT_RA_ADDRESS) && defined(CONFIG_32BIT)
+		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
+		 * addiu v1, v1, low_16bit_of_mcount
+		 * move at, ra
+		 * move $12, ra_address
+		 * jalr v1
+		 *  sub sp, sp, 8
+		 *                                  1: offset = 5 instructions
+		 */
+		new = 0x10000005;
+#else
 		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
 		 * addiu v1, v1, low_16bit_of_mcount
 		 * move at, ra
 		 * jalr v1
-		 * nop
-		 * 				     1f: (ip + 12)
+		 *  nop | move $12, ra_address | sub sp, sp, 8
+		 *                                  1: offset = 4 instructions
 		 */
 		new = 0x10000004;
+#endif
 	} else {
 		/* record/calculate it for ftrace_make_call */
 		if (jal_mcount == 0) {

commit f7a904dffe30a02636053d8022498ced7e44d31c
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Mon Jan 4 17:16:51 2010 +0800

    MIPS: Loongson: Change the Email address of Wu Zhangjin
    
    Currently wuzj@lemote.com is not usable; change it to wuzhangjin@gmail.com.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: linux-mips@linux-mips.org
    Cc: yanh@lemote.com
    Cc: huhb@lemote.com
    Cc: zhangfx@lemote.com
    Patchwork: http://patchwork.linux-mips.org/patch/829/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 68b067040d8b..e9e64e0ff7aa 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -3,7 +3,7 @@
  *
  * Copyright (C) 2007-2008 Steven Rostedt <srostedt@redhat.com>
  * Copyright (C) 2009 DSLab, Lanzhou University, China
- * Author: Wu Zhangjin <wuzj@lemote.com>
+ * Author: Wu Zhangjin <wuzhangjin@gmail.com>
  *
  * Thanks goes to Steven Rostedt for writing the original x86 version.
  */

commit 7326c4e567b50e689d13c04d58aeffa515277ebb
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:38 2009 +0800

    MIPS: Tracing: Make function graph tracer work with -mmcount-ra-address
    
    That thread "MIPS: Add option to pass return address location to
    _mcount" from "David Daney <ddaney@caviumnetworks.com>" have added a new
    option -mmcount-ra-address to gcc(4.5) for MIPS to transfer the location
    of the return address to _mcount.
    
    Benefit from this new feature, function graph tracer on MIPS will be
    easier and safer to hijack the return address of the kernel function,
    which will save some overhead and make the whole thing more reliable.
    
    In this patch, at first, try to enable the option -mmcount-ra-address in
    arch/mips/Makefile with cc-option, if gcc support it, it will be
    enabled, otherwise, no side effect.
    
    and then, we need to support this new option of gcc 4.5 and also support
    the old gcc versions.
    
    with _mcount in the old gcc versions, it's not easy to get the location
    of return address(tracing: add function graph tracer support for MIPS),
       so, we do it in a C function: ftrace_get_parent_addr(ftrace.c), but
       with -mmcount-ra-address, only several instructions need to get what
       we want, so, I put into asm(mcount.S). and also, as the $12(t0) is
       used by -mmcount-ra-address for transferring the localtion of return
       address to _mcount, we need to save it into the stack and restore it
       when enabled dynamic function tracer, 'Cause we have called
       "ftrace_call" before "ftrace_graph_caller", which may destroy
       $12(t0).
    
    (Thanks to David for providing that -mcount-ra-address and giving the
     idea of KBUILD_MCOUNT_RA_ADDRESS, both of them have made the whole
     thing more beautiful!)
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/681/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index e363fc69aabd..68b067040d8b 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -148,6 +148,7 @@ int ftrace_disable_ftrace_graph_caller(void)
 
 #endif				/* !CONFIG_DYNAMIC_FTRACE */
 
+#ifndef KBUILD_MCOUNT_RA_ADDRESS
 #define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
 #define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
@@ -201,6 +202,8 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	return 0;
 }
 
+#endif
+
 /*
  * Hook the return address and push it in the stack of return addrs
  * in current thread info.
@@ -218,19 +221,26 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 		return;
 
 	/* "parent" is the stack address saved the return address of the caller
-	 * of _mcount, for a leaf function not save the return address in the
-	 * stack address, so, we "emulate" one in _mcount's stack space, and
-	 * hijack it directly, but for a non-leaf function, it will save the
-	 * return address to the its stack space, so, we can not hijack the
-	 * "parent" directly, but need to find the real stack address,
+	 * of _mcount.
+	 *
+	 * if the gcc < 4.5, a leaf function does not save the return address
+	 * in the stack address, so, we "emulate" one in _mcount's stack space,
+	 * and hijack it directly, but for a non-leaf function, it save the
+	 * return address to the its own stack space, we can not hijack it
+	 * directly, but need to find the real stack address,
 	 * ftrace_get_parent_addr() does it!
+	 *
+	 * if gcc>= 4.5, with the new -mmcount-ra-address option, for a
+	 * non-leaf function, the location of the return address will be saved
+	 * to $12 for us, and for a leaf function, only put a zero into $12. we
+	 * do it in ftrace_graph_caller of mcount.S.
 	 */
 
 	/* old = *parent; */
 	safe_load_stack(old, parent, faulted);
 	if (unlikely(faulted))
 		goto out;
-
+#ifndef KBUILD_MCOUNT_RA_ADDRESS
 	parent = (unsigned long *)ftrace_get_parent_addr(self_addr, old,
 							 (unsigned long)parent,
 							 fp);
@@ -238,7 +248,7 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	 * ra, stop function graph tracer and return */
 	if (parent == 0)
 		goto out;
-
+#endif
 	/* *parent = return_hooker; */
 	safe_store_stack(return_hooker, parent, faulted);
 	if (unlikely(faulted))

commit 046199cae714a7f9e88f5a7940b077f4515f48cb
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:36 2009 +0800

    MIPS: Tracing: Make ftrace for MIPS work without -fno-omit-frame-pointer
    
    When remove the -fno-omit-frame-pointer, gcc will not save the frame
    pointer for us, we need to save one ourselves.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/679/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index e981a497c98f..e363fc69aabd 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -27,7 +27,13 @@ static unsigned int ftrace_nop = 0x00000000;
 
 static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 {
-	*(unsigned int *)ip = new_code;
+	int faulted;
+
+	/* *(unsigned int *)ip = new_code; */
+	safe_store_code(new_code, ip, faulted);
+
+	if (unlikely(faulted))
+		return -EFAULT;
 
 	flush_icache_range(ip, ip + 8);
 
@@ -41,14 +47,20 @@ int ftrace_make_nop(struct module *mod,
 		    struct dyn_ftrace *rec, unsigned long addr)
 {
 	unsigned int new;
+	int faulted;
 	unsigned long ip = rec->ip;
 
 	/* We have compiled module with -mlong-calls, but compiled the kernel
 	 * without it, we need to cope with them respectively. */
 	if (ip & 0x40000000) {
 		/* record it for ftrace_make_call */
-		if (lui_v1 == 0)
-			lui_v1 = *(unsigned int *)ip;
+		if (lui_v1 == 0) {
+			/* lui_v1 = *(unsigned int *)ip; */
+			safe_load_code(lui_v1, ip, faulted);
+
+			if (unlikely(faulted))
+				return -EFAULT;
+		}
 
 		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
 		 * addiu v1, v1, low_16bit_of_mcount
@@ -147,6 +159,7 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 {
 	unsigned long sp, ip, ra;
 	unsigned int code;
+	int faulted;
 
 	/* in module or kernel? */
 	if (self_addr & 0x40000000) {
@@ -162,8 +175,11 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	do {
 		ip -= 4;
 
-		/* get the code at "ip" */
-		code = *(unsigned int *)ip;
+		/* get the code at "ip": code = *(unsigned int *)ip; */
+		safe_load_code(code, ip, faulted);
+
+		if (unlikely(faulted))
+			return 0;
 
 		/* If we hit the non-store instruction before finding where the
 		 * ra is stored, then this is a leaf function and it does not
@@ -174,11 +190,14 @@ unsigned long ftrace_get_parent_addr(unsigned long self_addr,
 	} while (((code & S_RA_SP) != S_RA_SP));
 
 	sp = fp + (code & OFFSET_MASK);
-	ra = *(unsigned long *)sp;
+
+	/* ra = *(unsigned long *)sp; */
+	safe_load_stack(ra, sp, faulted);
+	if (unlikely(faulted))
+		return 0;
 
 	if (ra == parent)
 		return sp;
-
 	return 0;
 }
 
@@ -193,6 +212,7 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	struct ftrace_graph_ent trace;
 	unsigned long return_hooker = (unsigned long)
 	    &return_to_handler;
+	int faulted;
 
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		return;
@@ -206,21 +226,23 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	 * ftrace_get_parent_addr() does it!
 	 */
 
-	old = *parent;
+	/* old = *parent; */
+	safe_load_stack(old, parent, faulted);
+	if (unlikely(faulted))
+		goto out;
 
 	parent = (unsigned long *)ftrace_get_parent_addr(self_addr, old,
 							 (unsigned long)parent,
 							 fp);
-
 	/* If fails when getting the stack address of the non-leaf function's
 	 * ra, stop function graph tracer and return */
-	if (parent == 0) {
-		ftrace_graph_stop();
-		WARN_ON(1);
-		return;
-	}
+	if (parent == 0)
+		goto out;
 
-	*parent = return_hooker;
+	/* *parent = return_hooker; */
+	safe_store_stack(return_hooker, parent, faulted);
+	if (unlikely(faulted))
+		goto out;
 
 	if (ftrace_push_return_trace(old, self_addr, &trace.depth, fp) ==
 	    -EBUSY) {
@@ -235,5 +257,9 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 		current->curr_ret_stack--;
 		*parent = old;
 	}
+	return;
+out:
+	ftrace_graph_stop();
+	WARN_ON(1);
 }
 #endif				/* CONFIG_FUNCTION_GRAPH_TRACER */

commit e17ff5fec65a0213416efbe7ceae5f2f9887dda2
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:35 2009 +0800

    MIPS: Tracing: Add dynamic function graph tracer for MIPS
    
    This patch make function graph tracer work with dynamic function tracer.
    
    To share the source code of dynamic function tracer(MCOUNT_SAVE_REGS),
    and avoid restoring the whole saved registers, we need to restore the ra
    register from the stack.
    
    (NOTE: This not work with 32bit! need to ensure why!)
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/678/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 65a3f8a89927..e981a497c98f 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -115,6 +115,27 @@ int __init ftrace_dyn_arch_init(void *data)
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 
+#ifdef CONFIG_DYNAMIC_FTRACE
+
+extern void ftrace_graph_call(void);
+#define JMP	0x08000000	/* jump to target directly */
+#define CALL_FTRACE_GRAPH_CALLER \
+	jump_insn_encode(JMP, (unsigned long)(&ftrace_graph_caller))
+#define FTRACE_GRAPH_CALL_IP	((unsigned long)(&ftrace_graph_call))
+
+int ftrace_enable_ftrace_graph_caller(void)
+{
+	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP,
+				  CALL_FTRACE_GRAPH_CALLER);
+}
+
+int ftrace_disable_ftrace_graph_caller(void)
+{
+	return ftrace_modify_code(FTRACE_GRAPH_CALL_IP, ftrace_nop);
+}
+
+#endif				/* !CONFIG_DYNAMIC_FTRACE */
+
 #define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
 #define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */

commit 29c5d3462f7c8f17bb9e0a29f0a299036468074d
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:34 2009 +0800

    MIPS: Tracing: Add function graph tracer support for MIPS
    
    The implementation of function graph tracer for MIPS is a little
    different from X86.
    
    in MIPS, gcc(with -pg) only transfer the caller's return address(at) and
    the _mcount's return address(ra) to us.
    
    For the kernel part without -mlong-calls:
    
    move at, ra
    jal _mcount
    
    For the module part with -mlong-calls:
    
    lui v1, hi16bit_of_mcount
    addiu v1, v1, low16bit_of_mcount
    move at, ra
    jal _mcount
    
    Without -mlong-calls,
    
    if the function is a leaf, it will not save the return address(ra):
    
    ffffffff80101298 <au1k_wait>:
    ffffffff80101298:       67bdfff0        daddiu  sp,sp,-16
    ffffffff8010129c:       ffbe0008        sd      s8,8(sp)
    ffffffff801012a0:       03a0f02d        move    s8,sp
    ffffffff801012a4:       03e0082d        move    at,ra
    ffffffff801012a8:       0c042930        jal     ffffffff8010a4c0 <_mcount>
    ffffffff801012ac:       00020021        nop
    
    so, we can hijack it directly in _mcount, but if the function is non-leaf, the
    return address is saved in the stack.
    
    ffffffff80133030 <copy_process>:
    ffffffff80133030:       67bdff50        daddiu  sp,sp,-176
    ffffffff80133034:       ffbe00a0        sd      s8,160(sp)
    ffffffff80133038:       03a0f02d        move    s8,sp
    ffffffff8013303c:       ffbf00a8        sd      ra,168(sp)
    ffffffff80133040:       ffb70098        sd      s7,152(sp)
    ffffffff80133044:       ffb60090        sd      s6,144(sp)
    ffffffff80133048:       ffb50088        sd      s5,136(sp)
    ffffffff8013304c:       ffb40080        sd      s4,128(sp)
    ffffffff80133050:       ffb30078        sd      s3,120(sp)
    ffffffff80133054:       ffb20070        sd      s2,112(sp)
    ffffffff80133058:       ffb10068        sd      s1,104(sp)
    ffffffff8013305c:       ffb00060        sd      s0,96(sp)
    ffffffff80133060:       03e0082d        move    at,ra
    ffffffff80133064:       0c042930        jal     ffffffff8010a4c0 <_mcount>
    ffffffff80133068:       00020021        nop
    
    but we can not get the exact stack address(which saved ra) directly in
    _mcount, we need to search the content of at register in the stack space
    or search the "s{d,w} ra, offset(sp)" instruction in the text. 'Cause we
    can not prove there is only a match in the stack space, so, we search
    the text instead.
    
    as we can see, if the first instruction above "move at, ra" is not a
    store instruction, there should be a leaf function, so we hijack the at
    register directly via putting &return_to_handler into it, otherwise, we
    search the "s{d,w} ra, offset(sp)" instruction to get the stack offset,
    and then the stack address. we use the above copy_process() as an
    example, we at last find "ffbf00a8", 0xa8 is the stack offset, we plus
    it with s8(fp), that is the stack address, we hijack the content via
    writing the &return_to_handler in.
    
    If with -mlong-calls, since there are two more instructions above "move
    at, ra", so, we can move the pointer to the position above "lui v1,
    hi16bit_of_mcount".
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/677/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 5459a7838370..65a3f8a89927 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -13,6 +13,8 @@
 #include <linux/ftrace.h>
 
 #include <asm/cacheflush.h>
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
 
 #ifdef CONFIG_DYNAMIC_FTRACE
 
@@ -110,3 +112,107 @@ int __init ftrace_dyn_arch_init(void *data)
 	return 0;
 }
 #endif				/* CONFIG_DYNAMIC_FTRACE */
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+
+#define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
+#define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
+#define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
+
+unsigned long ftrace_get_parent_addr(unsigned long self_addr,
+				     unsigned long parent,
+				     unsigned long parent_addr,
+				     unsigned long fp)
+{
+	unsigned long sp, ip, ra;
+	unsigned int code;
+
+	/* in module or kernel? */
+	if (self_addr & 0x40000000) {
+		/* module: move to the instruction "lui v1, HI_16BIT_OF_MCOUNT" */
+		ip = self_addr - 20;
+	} else {
+		/* kernel: move to the instruction "move ra, at" */
+		ip = self_addr - 12;
+	}
+
+	/* search the text until finding the non-store instruction or "s{d,w}
+	 * ra, offset(sp)" instruction */
+	do {
+		ip -= 4;
+
+		/* get the code at "ip" */
+		code = *(unsigned int *)ip;
+
+		/* If we hit the non-store instruction before finding where the
+		 * ra is stored, then this is a leaf function and it does not
+		 * store the ra on the stack. */
+		if ((code & S_R_SP) != S_R_SP)
+			return parent_addr;
+
+	} while (((code & S_RA_SP) != S_RA_SP));
+
+	sp = fp + (code & OFFSET_MASK);
+	ra = *(unsigned long *)sp;
+
+	if (ra == parent)
+		return sp;
+
+	return 0;
+}
+
+/*
+ * Hook the return address and push it in the stack of return addrs
+ * in current thread info.
+ */
+void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
+			   unsigned long fp)
+{
+	unsigned long old;
+	struct ftrace_graph_ent trace;
+	unsigned long return_hooker = (unsigned long)
+	    &return_to_handler;
+
+	if (unlikely(atomic_read(&current->tracing_graph_pause)))
+		return;
+
+	/* "parent" is the stack address saved the return address of the caller
+	 * of _mcount, for a leaf function not save the return address in the
+	 * stack address, so, we "emulate" one in _mcount's stack space, and
+	 * hijack it directly, but for a non-leaf function, it will save the
+	 * return address to the its stack space, so, we can not hijack the
+	 * "parent" directly, but need to find the real stack address,
+	 * ftrace_get_parent_addr() does it!
+	 */
+
+	old = *parent;
+
+	parent = (unsigned long *)ftrace_get_parent_addr(self_addr, old,
+							 (unsigned long)parent,
+							 fp);
+
+	/* If fails when getting the stack address of the non-leaf function's
+	 * ra, stop function graph tracer and return */
+	if (parent == 0) {
+		ftrace_graph_stop();
+		WARN_ON(1);
+		return;
+	}
+
+	*parent = return_hooker;
+
+	if (ftrace_push_return_trace(old, self_addr, &trace.depth, fp) ==
+	    -EBUSY) {
+		*parent = old;
+		return;
+	}
+
+	trace.func = self_addr;
+
+	/* Only trace if the calling function expects to */
+	if (!ftrace_graph_entry(&trace)) {
+		current->curr_ret_stack--;
+		*parent = old;
+	}
+}
+#endif				/* CONFIG_FUNCTION_GRAPH_TRACER */

commit 538f19526e40ce7a5a296fad6a3121409c890adc
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:32 2009 +0800

    MIPS: Tracing: Add dynamic function tracer support
    
    With dynamic function tracer, by default, _mcount is defined as an
    "empty" function, it returns directly without any more action . When
    enabling it in user-space, it will jump to a real tracing
    function(ftrace_caller), and do the real job for us.
    
    Differ from the static function tracer, dynamic function tracer provides
    two functions ftrace_make_call()/ftrace_make_nop() to enable/disable the
    tracing of some indicated kernel functions(set_ftrace_filter).
    
    In the -v4 version, the implementation of this support is basically the same as
    X86 version does: _mcount is implemented as an empty function and ftrace_caller
    is implemented as a real tracing function respectively.
    
    But in this version, to support module tracing with the help of
    -mlong-calls in arch/mips/Makefile:
    
    MODFLAGS += -mlong-calls.
    
    The stuff becomes a little more complex. We need to cope with two
    different type of calling to _mcount.
    
    For the kernel part, the calling to _mcount(result of "objdump -hdr
    vmlinux"). is like this:
    
            108:   03e0082d        move    at,ra
            10c:   0c000000        jal     0 <fpcsr_pending>
                            10c: R_MIPS_26  _mcount
                            10c: R_MIPS_NONE        *ABS*
                            10c: R_MIPS_NONE        *ABS*
            110:   00020021        nop
    
    For the module with -mlong-calls, it looks like this:
    
            c:      3c030000        lui     v1,0x0
                            c: R_MIPS_HI16  _mcount
                            c: R_MIPS_NONE  *ABS*
                            c: R_MIPS_NONE  *ABS*
            10:     64630000        daddiu  v1,v1,0
                            10: R_MIPS_LO16 _mcount
                            10: R_MIPS_NONE *ABS*
                            10: R_MIPS_NONE *ABS*
            14:     03e0082d        move    at,ra
            18:     0060f809        jalr    v1
    
    In the kernel version, there is only one "_mcount" string for every
    kernel function, so, we just need to match this one in mcount_regex of
    scripts/recordmcount.pl, but in the module version, we need to choose
    one of the two to match. Herein, I choose the first one with
    "R_MIPS_HI16 _mcount".
    
    and In the kernel verion, without module tracing support, we just need
    to replace "jal _mcount" by "jal ftrace_caller" to do real tracing, and
    filter the tracing of some kernel functions via replacing it by a nop
    instruction.
    
    but as we have described before, the instruction "jal ftrace_caller" only left
    32bit length for the address of ftrace_caller, it will fail when calling from
    the module space. so, herein, we must replace something else.
    
    the basic idea is loading the address of ftrace_caller to v1 via changing these
    two instructions:
    
            lui     v1,0x0
            addiu   v1,v1,0
    
    If we want to enable the tracing, we need to replace the above instructions to:
    
            lui     v1, HI_16BIT_ftrace_caller
            addiu   v1, v1, LOW_16BIT_ftrace_caller
    
    If we want to stop the tracing of the indicated kernel functions, we
    just need to replace the "jalr v1" to a nop instruction. but we need to
    replace two instructions and encode the above two instructions
    oursevles.
    
    Is there a simpler solution? Yes! Here it is, in this version, we put _mcount
    and ftrace_caller together, which means the address of _mcount and
    ftrace_caller is the same:
    
    _mcount:
    ftrace_caller:
            j       ftrace_stub
             nop
    
            ...(do real tracing here)...
    
    ftrace_stub:
            jr      ra
             move   ra, at
    
    By default, the kernel functions call _mcount, and then jump to ftrace_stub and
    return. and when we want to do real tracing, we just need to remove that "j
    ftrace_stub", and it will run through the two "nop" instructions and then do
    the real tracing job.
    
    what about filtering job? we just need to do this:
    
             lui v1, hi_16bit_of_mcount        <--> b 1f (0x10000004)
             addiu v1, v1, low_16bit_of_mcount
             move at, ra
             jalr v1
             nop
                                                 1f: (rec->ip + 12)
    
    In linux-mips64, there will be some local symbols, whose name are
    prefixed by $L, which need to be filtered. thanks goes to Steven for
    writing the mips64-specific function_regex.
    
    In a conclusion, with RISC, things becomes easier with such a "stupid"
    trick, RISC is something like K.I.S.S, and also, there are lots of
    "simple" tricks in the whole ftrace support, thanks goes to Steven and
    the other folks for providing such a wonderful tracing framework!
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/675/
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
new file mode 100644
index 000000000000..5459a7838370
--- /dev/null
+++ b/arch/mips/kernel/ftrace.c
@@ -0,0 +1,112 @@
+/*
+ * Code for replacing ftrace calls with jumps.
+ *
+ * Copyright (C) 2007-2008 Steven Rostedt <srostedt@redhat.com>
+ * Copyright (C) 2009 DSLab, Lanzhou University, China
+ * Author: Wu Zhangjin <wuzj@lemote.com>
+ *
+ * Thanks goes to Steven Rostedt for writing the original x86 version.
+ */
+
+#include <linux/uaccess.h>
+#include <linux/init.h>
+#include <linux/ftrace.h>
+
+#include <asm/cacheflush.h>
+
+#ifdef CONFIG_DYNAMIC_FTRACE
+
+#define JAL 0x0c000000		/* jump & link: ip --> ra, jump to target */
+#define ADDR_MASK 0x03ffffff	/*  op_code|addr : 31...26|25 ....0 */
+#define jump_insn_encode(op_code, addr) \
+	((unsigned int)((op_code) | (((addr) >> 2) & ADDR_MASK)))
+
+static unsigned int ftrace_nop = 0x00000000;
+
+static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
+{
+	*(unsigned int *)ip = new_code;
+
+	flush_icache_range(ip, ip + 8);
+
+	return 0;
+}
+
+static int lui_v1;
+static int jal_mcount;
+
+int ftrace_make_nop(struct module *mod,
+		    struct dyn_ftrace *rec, unsigned long addr)
+{
+	unsigned int new;
+	unsigned long ip = rec->ip;
+
+	/* We have compiled module with -mlong-calls, but compiled the kernel
+	 * without it, we need to cope with them respectively. */
+	if (ip & 0x40000000) {
+		/* record it for ftrace_make_call */
+		if (lui_v1 == 0)
+			lui_v1 = *(unsigned int *)ip;
+
+		/* lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
+		 * addiu v1, v1, low_16bit_of_mcount
+		 * move at, ra
+		 * jalr v1
+		 * nop
+		 * 				     1f: (ip + 12)
+		 */
+		new = 0x10000004;
+	} else {
+		/* record/calculate it for ftrace_make_call */
+		if (jal_mcount == 0) {
+			/* We can record it directly like this:
+			 *     jal_mcount = *(unsigned int *)ip;
+			 * Herein, jump over the first two nop instructions */
+			jal_mcount = jump_insn_encode(JAL, (MCOUNT_ADDR + 8));
+		}
+
+		/* move at, ra
+		 * jalr v1		--> nop
+		 */
+		new = ftrace_nop;
+	}
+	return ftrace_modify_code(ip, new);
+}
+
+static int modified;	/* initialized as 0 by default */
+
+int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
+{
+	unsigned int new;
+	unsigned long ip = rec->ip;
+
+	/* We just need to remove the "b ftrace_stub" at the fist time! */
+	if (modified == 0) {
+		modified = 1;
+		ftrace_modify_code(addr, ftrace_nop);
+	}
+	/* ip, module: 0xc0000000, kernel: 0x80000000 */
+	new = (ip & 0x40000000) ? lui_v1 : jal_mcount;
+
+	return ftrace_modify_code(ip, new);
+}
+
+#define FTRACE_CALL_IP ((unsigned long)(&ftrace_call))
+
+int ftrace_update_ftrace_func(ftrace_func_t func)
+{
+	unsigned int new;
+
+	new = jump_insn_encode(JAL, (unsigned long)func);
+
+	return ftrace_modify_code(FTRACE_CALL_IP, new);
+}
+
+int __init ftrace_dyn_arch_init(void *data)
+{
+	/* The return code is retured via data */
+	*(unsigned long *)data = 0;
+
+	return 0;
+}
+#endif				/* CONFIG_DYNAMIC_FTRACE */
