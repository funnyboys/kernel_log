commit 5fdc66e046206306bf61ff2d626bfa52ca087f7b
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Mon Jul 10 09:43:31 2017 +0100

    MIPS: Fix minimum alignment requirement of IRQ stack
    
    Commit db8466c581cc ("MIPS: IRQ Stack: Unwind IRQ stack onto task
    stack") erroneously set the initial stack pointer of the IRQ stack to a
    value with a 4 byte alignment. The MIPS32 ABI requires that the minimum
    stack alignment is 8 byte, and the MIPS64 ABIs(n32/n64) require 16 byte
    minimum alignment. Fix IRQ_STACK_START such that it leaves space for the
    dummy stack frame (containing interrupted task kernel stack pointer)
    while also meeting minimum alignment requirements.
    
    Fixes: db8466c581cc ("MIPS: IRQ Stack: Unwind IRQ stack onto task stack")
    Reported-by: Darius Ivanauskas <dasilt@yahoo.com>
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Jason A. Donenfeld <jason@zx2c4.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/16760/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index ddd1c918103b..c5d351786416 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -18,7 +18,7 @@
 #include <irq.h>
 
 #define IRQ_STACK_SIZE			THREAD_SIZE
-#define IRQ_STACK_START			(IRQ_STACK_SIZE - sizeof(unsigned long))
+#define IRQ_STACK_START			(IRQ_STACK_SIZE - 16)
 
 extern void *irq_stack[NR_CPUS];
 

commit db8466c581cca1a08b505f1319c3ecd246f16fa8
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Tue Mar 21 14:52:25 2017 +0000

    MIPS: IRQ Stack: Unwind IRQ stack onto task stack
    
    When the separate IRQ stack was introduced, stack unwinding only
    proceeded as far as the top of the IRQ stack, leading to kernel
    backtraces being less useful, lacking the trace of what was interrupted.
    
    Fix this by providing a means for the kernel to unwind the IRQ stack
    onto the interrupted task stack. The processor state is saved to the
    kernel task stack on interrupt. The IRQ_STACK_START macro reserves an
    unsigned long at the top of the IRQ stack where the interrupted task
    stack pointer can be saved. After the active stack is switched to the
    IRQ stack, save the interrupted tasks stack pointer to the reserved
    location.
    
    Fix the stack unwinding code to look for the frame being the top of the
    IRQ stack and if so get the next frame from the saved location. The
    existing test does not work with the separate stack since the ra is no
    longer pointed at ret_from_{irq,exception}.
    
    The test to stop unwinding the stack 32 bytes from the top of a stack
    must be modified to allow unwinding to continue up to the location of
    the saved task stack pointer when on the IRQ stack. The low / high marks
    of the stack are set depending on whether the sp is on an irq stack or
    not.
    
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Marcin Nowakowski <marcin.nowakowski@imgtec.com>
    Cc: Masanari Iida <standby24x7@gmail.com>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jason A. Donenfeld <jason@zx2c4.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/15788/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 956db6e201d1..ddd1c918103b 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -18,9 +18,24 @@
 #include <irq.h>
 
 #define IRQ_STACK_SIZE			THREAD_SIZE
+#define IRQ_STACK_START			(IRQ_STACK_SIZE - sizeof(unsigned long))
 
 extern void *irq_stack[NR_CPUS];
 
+/*
+ * The highest address on the IRQ stack contains a dummy frame put down in
+ * genex.S (handle_int & except_vec_vi_handler) which is structured as follows:
+ *
+ *   top ------------
+ *       | task sp  | <- irq_stack[cpu] + IRQ_STACK_START
+ *       ------------
+ *       |          | <- First frame of IRQ context
+ *       ------------
+ *
+ * task sp holds a copy of the task stack pointer where the struct pt_regs
+ * from exception entry can be found.
+ */
+
 static inline bool on_irq_stack(int cpu, unsigned long sp)
 {
 	unsigned long low = (unsigned long)irq_stack[cpu];

commit fe8bd18ffea5327344d4ec2bf11f47951212abd0
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Mon Dec 19 14:20:56 2016 +0000

    MIPS: Introduce irq_stack
    
    Allocate a per-cpu irq stack for use within interrupt handlers.
    
    Also add a utility function on_irq_stack to determine if a given stack
    pointer is within the irq stack for that cpu.
    
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Acked-by: Jason A. Donenfeld <jason@zx2c4.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/14740/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 6bf10e796553..956db6e201d1 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -17,6 +17,18 @@
 
 #include <irq.h>
 
+#define IRQ_STACK_SIZE			THREAD_SIZE
+
+extern void *irq_stack[NR_CPUS];
+
+static inline bool on_irq_stack(int cpu, unsigned long sp)
+{
+	unsigned long low = (unsigned long)irq_stack[cpu];
+	unsigned long high = low + IRQ_STACK_SIZE;
+
+	return (low <= sp && sp <= high);
+}
+
 #ifdef CONFIG_I8259
 static inline int irq_canonicalize(int irq)
 {

commit 9a01c3ed5cdb35d9004eb92510ee6ea11b4a5f16
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Fri Oct 7 17:02:45 2016 -0700

    nmi_backtrace: add more trigger_*_cpu_backtrace() methods
    
    Patch series "improvements to the nmi_backtrace code" v9.
    
    This patch series modifies the trigger_xxx_backtrace() NMI-based remote
    backtracing code to make it more flexible, and makes a few small
    improvements along the way.
    
    The motivation comes from the task isolation code, where there are
    scenarios where we want to be able to diagnose a case where some cpu is
    about to interrupt a task-isolated cpu.  It can be helpful to see both
    where the interrupting cpu is, and also an approximation of where the
    cpu that is being interrupted is.  The nmi_backtrace framework allows us
    to discover the stack of the interrupted cpu.
    
    I've tested that the change works as desired on tile, and build-tested
    x86, arm, mips, and sparc64.  For x86 I confirmed that the generic
    cpuidle stuff as well as the architecture-specific routines are in the
    new cpuidle section.  For arm, mips, and sparc I just build-tested it
    and made sure the generic cpuidle routines were in the new cpuidle
    section, but I didn't attempt to figure out which the platform-specific
    idle routines might be.  That might be more usefully done by someone
    with platform experience in follow-up patches.
    
    This patch (of 4):
    
    Currently you can only request a backtrace of either all cpus, or all
    cpus but yourself.  It can also be helpful to request a remote backtrace
    of a single cpu, and since we want that, the logical extension is to
    support a cpumask as the underlying primitive.
    
    This change modifies the existing lib/nmi_backtrace.c code to take a
    cpumask as its basic primitive, and modifies the linux/nmi.h code to use
    the new "cpumask" method instead.
    
    The existing clients of nmi_backtrace (arm and x86) are converted to
    using the new cpumask approach in this change.
    
    The other users of the backtracing API (sparc64 and mips) are converted
    to use the cpumask approach rather than the all/allbutself approach.
    The mips code ignored the "include_self" boolean but with this change it
    will now also dump a local backtrace if requested.
    
    Link: http://lkml.kernel.org/r/1472487169-14923-2-git-send-email-cmetcalf@mellanox.com
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Tested-by: Daniel Thompson <daniel.thompson@linaro.org> [arm]
    Reviewed-by: Aaron Tomlin <atomlin@redhat.com>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 15e0fecbc300..6bf10e796553 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -51,7 +51,8 @@ extern int cp0_fdc_irq;
 
 extern int get_c0_fdc_int(void);
 
-void arch_trigger_all_cpu_backtrace(bool);
-#define arch_trigger_all_cpu_backtrace arch_trigger_all_cpu_backtrace
+void arch_trigger_cpumask_backtrace(const struct cpumask *mask,
+				    bool exclude_self);
+#define arch_trigger_cpumask_backtrace arch_trigger_cpumask_backtrace
 
 #endif /* _ASM_IRQ_H */

commit 770847bad0200b62af2d93808b4e69d82f14264e
Author: Bjorn Helgaas <bhelgaas@google.com>
Date:   Sun Jul 12 18:11:46 2015 -0500

    MIPS: Remove "weak" from get_c0_fdc_int() declaration
    
    Weak header file declarations are error-prone because they make every
    definition weak, and the linker chooses one based on link order (see
    10629d711ed7 ("PCI: Remove __weak annotation from pcibios_get_phb_of_node
    decl")).
    
    The most elegant solution is to have a weak default implementation and
    allow a strong function to override it.  Then we don't have to test
    whether a definition is present, and if there are ever multiple strong
    definitions, we get a link error instead of calling a random definition.
    
    Add a weak get_c0_fdc_int() definition with the default code and remove the
    weak annotation from the declaration.
    
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: James Hogan <james.hogan@imgtec.com>
    Cc: Andrew Bresticker <abrestic@chromium.org>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/10687/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index f0db99f8defe..15e0fecbc300 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -49,7 +49,7 @@ extern int cp0_compare_irq_shift;
 extern int cp0_perfcount_irq;
 extern int cp0_fdc_irq;
 
-extern int __weak get_c0_fdc_int(void);
+extern int get_c0_fdc_int(void);
 
 void arch_trigger_all_cpu_backtrace(bool);
 #define arch_trigger_all_cpu_backtrace arch_trigger_all_cpu_backtrace

commit 8f7ff027965619b17488141a5f39d14c850696ab
Author: James Hogan <james.hogan@imgtec.com>
Date:   Thu Jan 29 11:14:07 2015 +0000

    MIPS: Read CPU IRQ line that FDC to routed to
    
    Read the CPU IRQ line reportedly used for the Fast Debug Channel (FDC)
    interrupt from the IntCtl register and store it in cp0_fdc_irq where
    platform implementations of the new weak platform function
    get_c0_fdc_int() can refer to it.
    
    [ralf@linux-mips.org: Fixed conflict.]
    
    Signed-off-by: James Hogan <james.hogan@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Cc: James Hogan <james.hogan@imgtec.com>
    Patchwork: https://patchwork.linux-mips.org/patch/9140/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 5a4e1bb8fb1b..f0db99f8defe 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -47,6 +47,9 @@ extern void free_irqno(unsigned int irq);
 extern int cp0_compare_irq;
 extern int cp0_compare_irq_shift;
 extern int cp0_perfcount_irq;
+extern int cp0_fdc_irq;
+
+extern int __weak get_c0_fdc_int(void);
 
 void arch_trigger_all_cpu_backtrace(bool);
 #define arch_trigger_all_cpu_backtrace arch_trigger_all_cpu_backtrace

commit 856839b76836a2ee524a8638f568275da57f719c
Author: Eunbong Song <eunb.song@samsung.com>
Date:   Wed Oct 22 06:39:56 2014 +0000

    MIPS: Add arch_trigger_all_cpu_backtrace() function
    
    Currently, arch_trigger_all_cpu_backtrace() is defined in only x86 and
    sparc which have an NMI.  But in case of softlockup, it could be possible
    to dump backtrace of all cpus. and this could be helpful for debugging.
    
    for example, if system has 2 cpus.
    
            CPU 0                           CPU 1
     acquire read_lock()
    
                                    try to do write_lock()
    
     ,,,
     missing read_unlock()
    
    In this case, softlockup will occur becasuse CPU 0 does not call
    read_unlock().  And dump_stack() print only backtrace for "CPU 0". If
    CPU1's backtrace is printed it's very helpful.
    
    [ralf@linux-mips.org: Fixed whitespace and formatting issues.]
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/8200/

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 39f07aec640c..5a4e1bb8fb1b 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -48,4 +48,7 @@ extern int cp0_compare_irq;
 extern int cp0_compare_irq_shift;
 extern int cp0_perfcount_irq;
 
+void arch_trigger_all_cpu_backtrace(bool);
+#define arch_trigger_all_cpu_backtrace arch_trigger_all_cpu_backtrace
+
 #endif /* _ASM_IRQ_H */

commit 950e97ca50942efb1066785ce3a40836c93306e2
Author: Sergey Ryazanov <ryazanov.s.a@gmail.com>
Date:   Thu Aug 14 02:09:36 2014 +0400

    MIPS: Add common plat_irq_dispatch declaration
    
    Add common declaration to get rid of following sparse warning: "symbol
    'plat_irq_dispatch' was not declared. Should it be static?"
    
    Signed-off-by: Sergey Ryazanov <ryazanov.s.a@gmail.com>
    Cc: Linux MIPS <linux-mips@linux-mips.org>
    Patchwork: https://patchwork.linux-mips.org/patch/7539/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index ae1f7b24dd1a..39f07aec640c 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -26,6 +26,8 @@ static inline int irq_canonicalize(int irq)
 #define irq_canonicalize(irq) (irq)	/* Sane hardware, sane code ... */
 #endif
 
+asmlinkage void plat_irq_dispatch(void);
+
 extern void do_IRQ(unsigned int irq);
 
 extern void arch_init_irq(void);

commit b633648c5ad3cfbda0b3daea50d2135d44899259
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Fri May 23 16:29:44 2014 +0200

    MIPS: MT: Remove SMTC support
    
    Nobody is maintaining SMTC anymore and there also seems to be no userbase.
    Which is a pity - the SMTC technology primarily developed by Kevin D.
    Kissell <kevink@paralogos.com> is an ingenious demonstration for the MT
    ASE's power and elegance.
    
    Based on Markos Chandras <Markos.Chandras@imgtec.com> patch
    https://patchwork.linux-mips.org/patch/6719/ which while very similar did
    no longer apply cleanly when I tried to merge it plus some additional
    post-SMTC cleanup - SMTC was a feature as tricky to remove as it was to
    merge once upon a time.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 7bc2cdb35057..ae1f7b24dd1a 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -26,104 +26,8 @@ static inline int irq_canonicalize(int irq)
 #define irq_canonicalize(irq) (irq)	/* Sane hardware, sane code ... */
 #endif
 
-#ifdef CONFIG_MIPS_MT_SMTC
-
-struct irqaction;
-
-extern unsigned long irq_hwmask[];
-extern int setup_irq_smtc(unsigned int irq, struct irqaction * new,
-			  unsigned long hwmask);
-
-static inline void smtc_im_ack_irq(unsigned int irq)
-{
-	if (irq_hwmask[irq] & ST0_IM)
-		set_c0_status(irq_hwmask[irq] & ST0_IM);
-}
-
-#else
-
-static inline void smtc_im_ack_irq(unsigned int irq)
-{
-}
-
-#endif /* CONFIG_MIPS_MT_SMTC */
-
-#ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
-#include <linux/cpumask.h>
-
-extern int plat_set_irq_affinity(struct irq_data *d,
-				 const struct cpumask *affinity, bool force);
-extern void smtc_forward_irq(struct irq_data *d);
-
-/*
- * IRQ affinity hook invoked at the beginning of interrupt dispatch
- * if option is enabled.
- *
- * Up through Linux 2.6.22 (at least) cpumask operations are very
- * inefficient on MIPS.	 Initial prototypes of SMTC IRQ affinity
- * used a "fast path" per-IRQ-descriptor cache of affinity information
- * to reduce latency.  As there is a project afoot to optimize the
- * cpumask implementations, this version is optimistically assuming
- * that cpumask.h macro overhead is reasonable during interrupt dispatch.
- */
-static inline int handle_on_other_cpu(unsigned int irq)
-{
-	struct irq_data *d = irq_get_irq_data(irq);
-
-	if (cpumask_test_cpu(smp_processor_id(), d->affinity))
-		return 0;
-	smtc_forward_irq(d);
-	return 1;
-}
-
-#else /* Not doing SMTC affinity */
-
-static inline int handle_on_other_cpu(unsigned int irq) { return 0; }
-
-#endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
-
-#ifdef CONFIG_MIPS_MT_SMTC_IM_BACKSTOP
-
-static inline void smtc_im_backstop(unsigned int irq)
-{
-	if (irq_hwmask[irq] & 0x0000ff00)
-		write_c0_tccontext(read_c0_tccontext() &
-				   ~(irq_hwmask[irq] & 0x0000ff00));
-}
-
-/*
- * Clear interrupt mask handling "backstop" if irq_hwmask
- * entry so indicates. This implies that the ack() or end()
- * functions will take over re-enabling the low-level mask.
- * Otherwise it will be done on return from exception.
- */
-static inline int smtc_handle_on_other_cpu(unsigned int irq)
-{
-	int ret = handle_on_other_cpu(irq);
-
-	if (!ret)
-		smtc_im_backstop(irq);
-	return ret;
-}
-
-#else
-
-static inline void smtc_im_backstop(unsigned int irq) { }
-static inline int smtc_handle_on_other_cpu(unsigned int irq)
-{
-	return handle_on_other_cpu(irq);
-}
-
-#endif
-
 extern void do_IRQ(unsigned int irq);
 
-#ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
-
-extern void do_IRQ_no_affinity(unsigned int irq);
-
-#endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
-
 extern void arch_init_irq(void);
 extern void spurious_interrupt(void);
 

commit 7034228792cc561e79ff8600f02884bd4c80e287
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jan 22 12:59:30 2013 +0100

    MIPS: Whitespace cleanup.
    
    Having received another series of whitespace patches I decided to do this
    once and for all rather than dealing with this kind of patches trickling
    in forever.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 78dbb8a86da2..7bc2cdb35057 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -32,7 +32,7 @@ struct irqaction;
 
 extern unsigned long irq_hwmask[];
 extern int setup_irq_smtc(unsigned int irq, struct irqaction * new,
-                          unsigned long hwmask);
+			  unsigned long hwmask);
 
 static inline void smtc_im_ack_irq(unsigned int irq)
 {
@@ -60,7 +60,7 @@ extern void smtc_forward_irq(struct irq_data *d);
  * if option is enabled.
  *
  * Up through Linux 2.6.22 (at least) cpumask operations are very
- * inefficient on MIPS.  Initial prototypes of SMTC IRQ affinity
+ * inefficient on MIPS.	 Initial prototypes of SMTC IRQ affinity
  * used a "fast path" per-IRQ-descriptor cache of affinity information
  * to reduce latency.  As there is a project afoot to optimize the
  * cpumask implementations, this version is optimistically assuming
@@ -133,7 +133,7 @@ extern void free_irqno(unsigned int irq);
 
 /*
  * Before R2 the timer and performance counter interrupts were both fixed to
- * IE7.  Since R2 their number has to be read from the c0_intctl register.
+ * IE7.	 Since R2 their number has to be read from the c0_intctl register.
  */
 #define CP0_LEGACY_COMPARE_IRQ 7
 #define CP0_LEGACY_PERFCNT_IRQ 7

commit c6a4ebb9ae30ead7684bce623955f74b17df496d
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Fri Jul 6 23:56:00 2012 +0200

    MIPS: Provide a symbol for the legacy performance counter interrupt.
    
    Based on https://patchwork.linux-mips.org/patch/3576 - but this really
    deserves its own patchset and the symbol should also be used :)
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index fb698dc09bc9..78dbb8a86da2 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -136,6 +136,7 @@ extern void free_irqno(unsigned int irq);
  * IE7.  Since R2 their number has to be read from the c0_intctl register.
  */
 #define CP0_LEGACY_COMPARE_IRQ 7
+#define CP0_LEGACY_PERFCNT_IRQ 7
 
 extern int cp0_compare_irq;
 extern int cp0_compare_irq_shift;

commit abd2363f6a5f1030b935e0bdc15cf917313b3b10
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Fri Feb 24 08:07:06 2012 -0700

    irq_domain/mips: Allow irq_domain on MIPS
    
    This patch makes IRQ_DOMAIN usable on MIPS.  It uses an ugly workaround
    to preserve current behaviour so that MIPS has time to add irq_domain
    registration to the irq controller drivers.  The workaround will be
    removed in Linux v3.6
    
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Rob Herring <rob.herring@calxeda.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mips@linux-mips.org

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 2354c870a63a..fb698dc09bc9 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -11,15 +11,12 @@
 
 #include <linux/linkage.h>
 #include <linux/smp.h>
+#include <linux/irqdomain.h>
 
 #include <asm/mipsmtregs.h>
 
 #include <irq.h>
 
-static inline void irq_dispose_mapping(unsigned int virq)
-{
-}
-
 #ifdef CONFIG_I8259
 static inline int irq_canonicalize(int irq)
 {

commit 98f4a2c27c76e7eaf75c2f3f25487fabca62ef3d
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Mon Jul 25 17:26:55 2011 +0100

    MIPS: Remove pointless return statement from empty void functions.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    To: Sergei Shtylyov <sshtylyov@mvista.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2391/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 0ec01294b063..2354c870a63a 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -18,7 +18,6 @@
 
 static inline void irq_dispose_mapping(unsigned int virq)
 {
-	return;
 }
 
 #ifdef CONFIG_I8259

commit 930cd54b3bd78e52991a89b39b5ef58355ad2b6d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 23 21:09:04 2011 +0000

    MIPS: SMTC: Cleanup the hook mess and use irq_data
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    To: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2194/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index bdc8b8c18328..0ec01294b063 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -57,7 +57,7 @@ static inline void smtc_im_ack_irq(unsigned int irq)
 
 extern int plat_set_irq_affinity(struct irq_data *d,
 				 const struct cpumask *affinity, bool force);
-extern void smtc_forward_irq(unsigned int irq);
+extern void smtc_forward_irq(struct irq_data *d);
 
 /*
  * IRQ affinity hook invoked at the beginning of interrupt dispatch
@@ -70,51 +70,53 @@ extern void smtc_forward_irq(unsigned int irq);
  * cpumask implementations, this version is optimistically assuming
  * that cpumask.h macro overhead is reasonable during interrupt dispatch.
  */
-#define IRQ_AFFINITY_HOOK(irq)						\
-do {									\
-    if (!cpumask_test_cpu(smp_processor_id(), irq_desc[irq].affinity)) {\
-	smtc_forward_irq(irq);						\
-	irq_exit();							\
-	return;								\
-    }									\
-} while (0)
+static inline int handle_on_other_cpu(unsigned int irq)
+{
+	struct irq_data *d = irq_get_irq_data(irq);
+
+	if (cpumask_test_cpu(smp_processor_id(), d->affinity))
+		return 0;
+	smtc_forward_irq(d);
+	return 1;
+}
 
 #else /* Not doing SMTC affinity */
 
-#define IRQ_AFFINITY_HOOK(irq) do { } while (0)
+static inline int handle_on_other_cpu(unsigned int irq) { return 0; }
 
 #endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
 
 #ifdef CONFIG_MIPS_MT_SMTC_IM_BACKSTOP
 
+static inline void smtc_im_backstop(unsigned int irq)
+{
+	if (irq_hwmask[irq] & 0x0000ff00)
+		write_c0_tccontext(read_c0_tccontext() &
+				   ~(irq_hwmask[irq] & 0x0000ff00));
+}
+
 /*
  * Clear interrupt mask handling "backstop" if irq_hwmask
  * entry so indicates. This implies that the ack() or end()
  * functions will take over re-enabling the low-level mask.
  * Otherwise it will be done on return from exception.
  */
-#define __DO_IRQ_SMTC_HOOK(irq)						\
-do {									\
-	IRQ_AFFINITY_HOOK(irq);						\
-	if (irq_hwmask[irq] & 0x0000ff00)				\
-		write_c0_tccontext(read_c0_tccontext() &		\
-				   ~(irq_hwmask[irq] & 0x0000ff00));	\
-} while (0)
-
-#define __NO_AFFINITY_IRQ_SMTC_HOOK(irq)				\
-do {									\
-	if (irq_hwmask[irq] & 0x0000ff00)                               \
-		write_c0_tccontext(read_c0_tccontext() &		\
-				   ~(irq_hwmask[irq] & 0x0000ff00));	\
-} while (0)
+static inline int smtc_handle_on_other_cpu(unsigned int irq)
+{
+	int ret = handle_on_other_cpu(irq);
+
+	if (!ret)
+		smtc_im_backstop(irq);
+	return ret;
+}
 
 #else
 
-#define __DO_IRQ_SMTC_HOOK(irq)						\
-do {									\
-	IRQ_AFFINITY_HOOK(irq);						\
-} while (0)
-#define __NO_AFFINITY_IRQ_SMTC_HOOK(irq) do { } while (0)
+static inline void smtc_im_backstop(unsigned int irq) { }
+static inline int smtc_handle_on_other_cpu(unsigned int irq)
+{
+	return handle_on_other_cpu(irq);
+}
 
 #endif
 

commit 7c8d948f1633da5ff81e4f5b31ef237d74c40127
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 23 21:08:57 2011 +0000

    MIPS: i8259: Convert to new irq_chip functions
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    To: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/2185/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index b003ed52ed17..bdc8b8c18328 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -55,8 +55,8 @@ static inline void smtc_im_ack_irq(unsigned int irq)
 #ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
 #include <linux/cpumask.h>
 
-extern int plat_set_irq_affinity(unsigned int irq,
-				  const struct cpumask *affinity);
+extern int plat_set_irq_affinity(struct irq_data *d,
+				 const struct cpumask *affinity, bool force);
 extern void smtc_forward_irq(unsigned int irq);
 
 /*

commit f2ffa5ab74f4dfd598860f96ca37a71c4d0a28a8
Author: Dezhong Diao <dediao@cisco.com>
Date:   Wed Oct 13 00:52:46 2010 -0600

    of/mips: Add device tree support to MIPS
    
    Add the ability to enable CONFIG_OF on the MIPS architecture.
    
    Signed-off-by: Dezhong Diao <dediao@cisco.com>
    [grant.likely@secretlab.ca: cleared out obsolete hooks,
            removed ARCH_HAS_DEVTREE_MEM,
            remove __init tags from header file,
            removed debugfs support hunk]
    [ddaney@linux-mips.org: backed out over aggressive trimming of hooks]
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Tested-by: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index dea4aed6478f..b003ed52ed17 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -16,6 +16,11 @@
 
 #include <irq.h>
 
+static inline void irq_dispose_mapping(unsigned int virq)
+{
+	return;
+}
+
 #ifdef CONFIG_I8259
 static inline int irq_canonicalize(int irq)
 {

commit 010c108d7af708d9e09b83724a058a76803fbc66
Author: David VomLehn <dvomlehn@cisco.com>
Date:   Mon Dec 21 17:49:22 2009 -0800

    MIPS: PowerTV: Fix support for timer interrupts with > 64 external IRQs
    
    The MIPS processor is limited to 64 external interrupt sources. Using a
    greater number without IRQ sharing requires reading platform-specific
    registers. On such platforms, reading the IntCtl register to determine
    which interrupt corresponds to a timer interrupt will not work.
    
    On MIPSR2 systems there is a solution - the TI bit in the Cause register,
    specifically indicates that a timer interrupt has occured. This patch uses
    that bit to detect interrupts for MIPSR2 processors, which may be expected
    to work regardless of how the timer interrupt may be routed in the hardware.
    
    Signed-off-by: David VomLehn (dvomlehn@cisco.com)
    To: linux-mips@linux-mips.org
    Patchwork: http://patchwork.linux-mips.org/patch/804/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 06960364c96b..dea4aed6478f 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -135,6 +135,7 @@ extern void free_irqno(unsigned int irq);
 #define CP0_LEGACY_COMPARE_IRQ 7
 
 extern int cp0_compare_irq;
+extern int cp0_compare_irq_shift;
 extern int cp0_perfcount_irq;
 
 #endif /* _ASM_IRQ_H */

commit 8f99a162653531ef25a3dd0f92bfb6332cd2b295
Author: Wu Zhangjin <wuzhangjin@gmail.com>
Date:   Fri Nov 20 20:34:33 2009 +0800

    MIPS: Tracing: Add IRQENTRY_EXIT section for MIPS
    
    This patch add a new section for MIPS to record the block of the hardirq
    handling for function graph tracer(print_graph_irq) via adding the
    __irq_entry annotation to the the entrypoints of the hardirqs(the block
    with irq_enter()...irq_exit()).
    
    Thanks goes to Steven & Frederic Weisbecker for their feedbacks.
    
    Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Mc Guire <der.herr@hofr.at>
    Cc: zhangfx@lemote.com
    Cc: Wu Zhangjin <wuzhangjin@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Reviewed-by: Frederic Weisbecker <fweisbec@gmail.com>
    Patchwork: http://patchwork.linux-mips.org/patch/676/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 09b08d05ff72..06960364c96b 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -113,36 +113,11 @@ do {									\
 
 #endif
 
-/*
- * do_IRQ handles all normal device IRQ's (the special
- * SMP cross-CPU interrupts have their own specific
- * handlers).
- *
- * Ideally there should be away to get this into kernel/irq/handle.c to
- * avoid the overhead of a call for just a tiny function ...
- */
-#define do_IRQ(irq)							\
-do {									\
-	irq_enter();							\
-	__DO_IRQ_SMTC_HOOK(irq);					\
-	generic_handle_irq(irq);					\
-	irq_exit();							\
-} while (0)
+extern void do_IRQ(unsigned int irq);
 
 #ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
-/*
- * To avoid inefficient and in some cases pathological re-checking of
- * IRQ affinity, we have this variant that skips the affinity check.
- */
-
 
-#define do_IRQ_no_affinity(irq)						\
-do {									\
-	irq_enter();							\
-	__NO_AFFINITY_IRQ_SMTC_HOOK(irq);				\
-	generic_handle_irq(irq);					\
-	irq_exit();							\
-} while (0)
+extern void do_IRQ_no_affinity(unsigned int irq);
 
 #endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
 

commit 631330f5847b3f8a7ea67d689e9f7c56833ccaa6
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Fri Jun 19 14:05:26 2009 +0100

    MIPS: Build fix - include <linux/smp.h> into all smp_processor_id() users.
    
    Some of the were relying into smp.h being dragged in by another header
    which of course is fragile.  <asm/cpu-info.h> uses smp_processor_id()
    only in macros and including smp.h there leads to an include loop, so
    don't change cpu-info.h.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 4f1eed107b08..09b08d05ff72 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -10,6 +10,7 @@
 #define _ASM_IRQ_H
 
 #include <linux/linkage.h>
+#include <linux/smp.h>
 
 #include <asm/mipsmtregs.h>
 

commit d5dedd4507d307eb3f35f21b6e16f336fdc0d82a
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 27 17:59:21 2009 -0700

    irq: change ->set_affinity() to return status
    
    according to Ingo, change set_affinity() in irq_chip should return int,
    because that way we can handle failure cases in a much cleaner way, in
    the genirq layer.
    
    v2: fix two typos
    
    [ Impact: extend API ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: linux-arch@vger.kernel.org
    LKML-Reference: <49F654E9.4070809@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index 3214ade02d10..4f1eed107b08 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -49,7 +49,7 @@ static inline void smtc_im_ack_irq(unsigned int irq)
 #ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
 #include <linux/cpumask.h>
 
-extern void plat_set_irq_affinity(unsigned int irq,
+extern int plat_set_irq_affinity(unsigned int irq,
 				  const struct cpumask *affinity);
 extern void smtc_forward_irq(unsigned int irq);
 

commit e65e49d0f3714f4a6a42f6f6a19926ba33fcda75
Author: Mike Travis <travis@sgi.com>
Date:   Mon Jan 12 15:27:13 2009 -0800

    irq: update all arches for new irq_desc
    
    Impact: cleanup, update to new cpumask API
    
    Irq_desc.affinity and irq_desc.pending_mask are now cpumask_var_t's
    so access to them should be using the new cpumask API.
    
    Signed-off-by: Mike Travis <travis@sgi.com>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index abc62aa744ac..3214ade02d10 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -66,7 +66,7 @@ extern void smtc_forward_irq(unsigned int irq);
  */
 #define IRQ_AFFINITY_HOOK(irq)						\
 do {									\
-    if (!cpu_isset(smp_processor_id(), irq_desc[irq].affinity)) {	\
+    if (!cpumask_test_cpu(smp_processor_id(), irq_desc[irq].affinity)) {\
 	smtc_forward_irq(irq);						\
 	irq_exit();							\
 	return;								\

commit 0de26520c7cabf36e1de090ea8092f011a6106ce
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: make irq_set_affinity() take a const struct cpumask
    
    Impact: change existing irq_chip API
    
    Not much point with gentle transition here: the struct irq_chip's
    setaffinity method signature needs to change.
    
    Fortunately, not widely used code, but hits a few architectures.
    
    Note: In irq_select_affinity() I save a temporary in by mangling
    irq_desc[irq].affinity directly.  Ingo, does this break anything?
    
    (Folded in fix from KOSAKI Motohiro)
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: jeremy@xensource.com
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
index a58f0eecc68f..abc62aa744ac 100644
--- a/arch/mips/include/asm/irq.h
+++ b/arch/mips/include/asm/irq.h
@@ -49,7 +49,8 @@ static inline void smtc_im_ack_irq(unsigned int irq)
 #ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
 #include <linux/cpumask.h>
 
-extern void plat_set_irq_affinity(unsigned int irq, cpumask_t affinity);
+extern void plat_set_irq_affinity(unsigned int irq,
+				  const struct cpumask *affinity);
 extern void smtc_forward_irq(unsigned int irq);
 
 /*

commit 384740dc49ea651ba350704d13ff6be9976e37fe
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Sep 16 19:48:51 2008 +0200

    MIPS: Move headfiles to new location below arch/mips/include
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/irq.h b/arch/mips/include/asm/irq.h
new file mode 100644
index 000000000000..a58f0eecc68f
--- /dev/null
+++ b/arch/mips/include/asm/irq.h
@@ -0,0 +1,163 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994 by Waldorf GMBH, written by Ralf Baechle
+ * Copyright (C) 1995, 96, 97, 98, 99, 2000, 01, 02, 03 by Ralf Baechle
+ */
+#ifndef _ASM_IRQ_H
+#define _ASM_IRQ_H
+
+#include <linux/linkage.h>
+
+#include <asm/mipsmtregs.h>
+
+#include <irq.h>
+
+#ifdef CONFIG_I8259
+static inline int irq_canonicalize(int irq)
+{
+	return ((irq == I8259A_IRQ_BASE + 2) ? I8259A_IRQ_BASE + 9 : irq);
+}
+#else
+#define irq_canonicalize(irq) (irq)	/* Sane hardware, sane code ... */
+#endif
+
+#ifdef CONFIG_MIPS_MT_SMTC
+
+struct irqaction;
+
+extern unsigned long irq_hwmask[];
+extern int setup_irq_smtc(unsigned int irq, struct irqaction * new,
+                          unsigned long hwmask);
+
+static inline void smtc_im_ack_irq(unsigned int irq)
+{
+	if (irq_hwmask[irq] & ST0_IM)
+		set_c0_status(irq_hwmask[irq] & ST0_IM);
+}
+
+#else
+
+static inline void smtc_im_ack_irq(unsigned int irq)
+{
+}
+
+#endif /* CONFIG_MIPS_MT_SMTC */
+
+#ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
+#include <linux/cpumask.h>
+
+extern void plat_set_irq_affinity(unsigned int irq, cpumask_t affinity);
+extern void smtc_forward_irq(unsigned int irq);
+
+/*
+ * IRQ affinity hook invoked at the beginning of interrupt dispatch
+ * if option is enabled.
+ *
+ * Up through Linux 2.6.22 (at least) cpumask operations are very
+ * inefficient on MIPS.  Initial prototypes of SMTC IRQ affinity
+ * used a "fast path" per-IRQ-descriptor cache of affinity information
+ * to reduce latency.  As there is a project afoot to optimize the
+ * cpumask implementations, this version is optimistically assuming
+ * that cpumask.h macro overhead is reasonable during interrupt dispatch.
+ */
+#define IRQ_AFFINITY_HOOK(irq)						\
+do {									\
+    if (!cpu_isset(smp_processor_id(), irq_desc[irq].affinity)) {	\
+	smtc_forward_irq(irq);						\
+	irq_exit();							\
+	return;								\
+    }									\
+} while (0)
+
+#else /* Not doing SMTC affinity */
+
+#define IRQ_AFFINITY_HOOK(irq) do { } while (0)
+
+#endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
+
+#ifdef CONFIG_MIPS_MT_SMTC_IM_BACKSTOP
+
+/*
+ * Clear interrupt mask handling "backstop" if irq_hwmask
+ * entry so indicates. This implies that the ack() or end()
+ * functions will take over re-enabling the low-level mask.
+ * Otherwise it will be done on return from exception.
+ */
+#define __DO_IRQ_SMTC_HOOK(irq)						\
+do {									\
+	IRQ_AFFINITY_HOOK(irq);						\
+	if (irq_hwmask[irq] & 0x0000ff00)				\
+		write_c0_tccontext(read_c0_tccontext() &		\
+				   ~(irq_hwmask[irq] & 0x0000ff00));	\
+} while (0)
+
+#define __NO_AFFINITY_IRQ_SMTC_HOOK(irq)				\
+do {									\
+	if (irq_hwmask[irq] & 0x0000ff00)                               \
+		write_c0_tccontext(read_c0_tccontext() &		\
+				   ~(irq_hwmask[irq] & 0x0000ff00));	\
+} while (0)
+
+#else
+
+#define __DO_IRQ_SMTC_HOOK(irq)						\
+do {									\
+	IRQ_AFFINITY_HOOK(irq);						\
+} while (0)
+#define __NO_AFFINITY_IRQ_SMTC_HOOK(irq) do { } while (0)
+
+#endif
+
+/*
+ * do_IRQ handles all normal device IRQ's (the special
+ * SMP cross-CPU interrupts have their own specific
+ * handlers).
+ *
+ * Ideally there should be away to get this into kernel/irq/handle.c to
+ * avoid the overhead of a call for just a tiny function ...
+ */
+#define do_IRQ(irq)							\
+do {									\
+	irq_enter();							\
+	__DO_IRQ_SMTC_HOOK(irq);					\
+	generic_handle_irq(irq);					\
+	irq_exit();							\
+} while (0)
+
+#ifdef CONFIG_MIPS_MT_SMTC_IRQAFF
+/*
+ * To avoid inefficient and in some cases pathological re-checking of
+ * IRQ affinity, we have this variant that skips the affinity check.
+ */
+
+
+#define do_IRQ_no_affinity(irq)						\
+do {									\
+	irq_enter();							\
+	__NO_AFFINITY_IRQ_SMTC_HOOK(irq);				\
+	generic_handle_irq(irq);					\
+	irq_exit();							\
+} while (0)
+
+#endif /* CONFIG_MIPS_MT_SMTC_IRQAFF */
+
+extern void arch_init_irq(void);
+extern void spurious_interrupt(void);
+
+extern int allocate_irqno(void);
+extern void alloc_legacy_irqno(void);
+extern void free_irqno(unsigned int irq);
+
+/*
+ * Before R2 the timer and performance counter interrupts were both fixed to
+ * IE7.  Since R2 their number has to be read from the c0_intctl register.
+ */
+#define CP0_LEGACY_COMPARE_IRQ 7
+
+extern int cp0_compare_irq;
+extern int cp0_perfcount_irq;
+
+#endif /* _ASM_IRQ_H */
