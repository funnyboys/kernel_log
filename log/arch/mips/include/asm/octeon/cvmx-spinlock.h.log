commit 7034228792cc561e79ff8600f02884bd4c80e287
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jan 22 12:59:30 2013 +0100

    MIPS: Whitespace cleanup.
    
    Having received another series of whitespace patches I decided to do this
    once and for all rather than dealing with this kind of patches trickling
    in forever.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/octeon/cvmx-spinlock.h b/arch/mips/include/asm/octeon/cvmx-spinlock.h
index a672abb1bc4f..4f09cff8b8c0 100644
--- a/arch/mips/include/asm/octeon/cvmx-spinlock.h
+++ b/arch/mips/include/asm/octeon/cvmx-spinlock.h
@@ -26,7 +26,7 @@
  ***********************license end**************************************/
 
 /**
- * Implementation of spinlocks for Octeon CVMX.  Although similar in
+ * Implementation of spinlocks for Octeon CVMX.	 Although similar in
  * function to Linux kernel spinlocks, they are not compatible.
  * Octeon CVMX spinlocks are only used to synchronize with the boot
  * monitor and other non-Linux programs running in the system.
@@ -50,8 +50,8 @@ typedef struct {
 } cvmx_spinlock_t;
 
 /* note - macros not expanded in inline ASM, so values hardcoded */
-#define  CVMX_SPINLOCK_UNLOCKED_VAL  0
-#define  CVMX_SPINLOCK_LOCKED_VAL    1
+#define	 CVMX_SPINLOCK_UNLOCKED_VAL  0
+#define	 CVMX_SPINLOCK_LOCKED_VAL    1
 
 #define CVMX_SPINLOCK_UNLOCKED_INITIALIZER  {CVMX_SPINLOCK_UNLOCKED_VAL}
 
@@ -96,7 +96,7 @@ static inline void cvmx_spinlock_unlock(cvmx_spinlock_t *lock)
  * @lock:   pointer to lock structure
  *
  * Returns 0: lock successfully taken
- *         1: lock not taken, held by someone else
+ *	   1: lock not taken, held by someone else
  * These return values match the Linux semantics.
  */
 
@@ -104,16 +104,16 @@ static inline unsigned int cvmx_spinlock_trylock(cvmx_spinlock_t *lock)
 {
 	unsigned int tmp;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set noreorder	     \n"
 			     "1: ll   %[tmp], %[val] \n"
 			/* if lock held, fail immediately */
-			     "   bnez %[tmp], 2f     \n"
-			     "   li   %[tmp], 1      \n"
-			     "   sc   %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n"
-			     "   li   %[tmp], 0      \n"
-			     "2:                     \n"
-			     ".set reorder           \n" :
+			     "	 bnez %[tmp], 2f     \n"
+			     "	 li   %[tmp], 1	     \n"
+			     "	 sc   %[tmp], %[val] \n"
+			     "	 beqz %[tmp], 1b     \n"
+			     "	 li   %[tmp], 0	     \n"
+			     "2:		     \n"
+			     ".set reorder	     \n" :
 			[val] "+m"(lock->value), [tmp] "=&r"(tmp)
 			     : : "memory");
 
@@ -129,14 +129,14 @@ static inline void cvmx_spinlock_lock(cvmx_spinlock_t *lock)
 {
 	unsigned int tmp;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set noreorder	     \n"
 			     "1: ll   %[tmp], %[val]  \n"
-			     "   bnez %[tmp], 1b     \n"
-			     "   li   %[tmp], 1      \n"
-			     "   sc   %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n"
-			     "   nop                \n"
-			     ".set reorder           \n" :
+			     "	 bnez %[tmp], 1b     \n"
+			     "	 li   %[tmp], 1	     \n"
+			     "	 sc   %[tmp], %[val] \n"
+			     "	 beqz %[tmp], 1b     \n"
+			     "	 nop		    \n"
+			     ".set reorder	     \n" :
 			[val] "+m"(lock->value), [tmp] "=&r"(tmp)
 			: : "memory");
 
@@ -163,17 +163,17 @@ static inline void cvmx_spinlock_bit_lock(uint32_t *word)
 	unsigned int tmp;
 	unsigned int sav;
 
-	__asm__ __volatile__(".set noreorder         \n"
-			     ".set noat              \n"
+	__asm__ __volatile__(".set noreorder	     \n"
+			     ".set noat		     \n"
 			     "1: ll    %[tmp], %[val]  \n"
-			     "   bbit1 %[tmp], 31, 1b    \n"
-			     "   li    $at, 1      \n"
-			     "   ins   %[tmp], $at, 31, 1  \n"
-			     "   sc    %[tmp], %[val] \n"
-			     "   beqz  %[tmp], 1b     \n"
-			     "   nop                \n"
-			     ".set at              \n"
-			     ".set reorder           \n" :
+			     "	 bbit1 %[tmp], 31, 1b	 \n"
+			     "	 li    $at, 1	   \n"
+			     "	 ins   %[tmp], $at, 31, 1  \n"
+			     "	 sc    %[tmp], %[val] \n"
+			     "	 beqz  %[tmp], 1b     \n"
+			     "	 nop		    \n"
+			     ".set at		   \n"
+			     ".set reorder	     \n" :
 			[val] "+m"(*word), [tmp] "=&r"(tmp), [sav] "=&r"(sav)
 			     : : "memory");
 
@@ -187,7 +187,7 @@ static inline void cvmx_spinlock_bit_lock(uint32_t *word)
  *
  * @word:  word to lock bit 31 of
  * Returns 0: lock successfully taken
- *         1: lock not taken, held by someone else
+ *	   1: lock not taken, held by someone else
  * These return values match the Linux semantics.
  */
 static inline unsigned int cvmx_spinlock_bit_trylock(uint32_t *word)
@@ -198,15 +198,15 @@ static inline unsigned int cvmx_spinlock_bit_trylock(uint32_t *word)
 			     ".set noat\n"
 			     "1: ll    %[tmp], %[val] \n"
 			/* if lock held, fail immediately */
-			     "   bbit1 %[tmp], 31, 2f     \n"
-			     "   li    $at, 1      \n"
-			     "   ins   %[tmp], $at, 31, 1  \n"
-			     "   sc    %[tmp], %[val] \n"
-			     "   beqz  %[tmp], 1b     \n"
-			     "   li    %[tmp], 0      \n"
-			     "2:                     \n"
-			     ".set at              \n"
-			     ".set reorder           \n" :
+			     "	 bbit1 %[tmp], 31, 2f	  \n"
+			     "	 li    $at, 1	   \n"
+			     "	 ins   %[tmp], $at, 31, 1  \n"
+			     "	 sc    %[tmp], %[val] \n"
+			     "	 beqz  %[tmp], 1b     \n"
+			     "	 li    %[tmp], 0      \n"
+			     "2:		     \n"
+			     ".set at		   \n"
+			     ".set reorder	     \n" :
 			[val] "+m"(*word), [tmp] "=&r"(tmp)
 			: : "memory");
 

commit a1ce39288e6fbefdd8d607021d02384eb4a20b99
Author: David Howells <dhowells@redhat.com>
Date:   Tue Oct 2 18:01:25 2012 +0100

    UAPI: (Scripted) Convert #include "..." to #include <path/...> in kernel system headers
    
    Convert #include "..." to #include <path/...> in kernel system headers.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/arch/mips/include/asm/octeon/cvmx-spinlock.h b/arch/mips/include/asm/octeon/cvmx-spinlock.h
index 2fbf0871df11..a672abb1bc4f 100644
--- a/arch/mips/include/asm/octeon/cvmx-spinlock.h
+++ b/arch/mips/include/asm/octeon/cvmx-spinlock.h
@@ -35,7 +35,7 @@
 #ifndef __CVMX_SPINLOCK_H__
 #define __CVMX_SPINLOCK_H__
 
-#include "cvmx-asm.h"
+#include <asm/octeon/cvmx-asm.h>
 
 /* Spinlocks for Octeon */
 

commit 58f07778ce9d32c22cecb1d8ef348001f0e705c9
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Tue Dec 23 15:22:14 2008 -0800

    MIPS: Add Cavium OCTEON processor support files to arch/mips/cavium-octeon/executive and asm/octeon.
    
    These files are used to coordinate resource sharing between all of
    the programs running on the OCTEON SOC.  The OCTEON processor has many
    CPU cores (current parts have up to 16, but more are possible).  It
    also has a variety of on-chip hardware blocks for things like network
    acceleration, encryption and RAID.
    
    One typical configuration is to run Linux on several of the CPU cores,
    and other dedicated applications on the other cores.
    
    Resource allocation between the various programs running on the system
    (Linux kernel and other dedicated applications) needs to be
    coordinated.  The code we use to do this we call the 'executive'.  All
    of this resource allocation and sharing code is gathered together in
    the executive directory.
    
    Included in the patch set are the following files:
    
    cvmx-bootmem.c and cvmx-sysinfo.c -- Coordinate memory allocation.
    All memory used by the Linux kernel is obtained here at boot time.
    
    cvmx-l2c.c -- Coordinates operations on the shared level 2 cache.
    
    octeon-model.c  -- Probes chip capabilities and version.
    
    The corresponding headers are in asm/octeon.
    
    Signed-off-by: Tomaso Paoletti <tpaoletti@caviumnetworks.com>
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    
     create mode 100644 arch/mips/cavium-octeon/executive/Makefile
     create mode 100644 arch/mips/cavium-octeon/executive/cvmx-bootmem.c
     create mode 100644 arch/mips/cavium-octeon/executive/cvmx-l2c.c
     create mode 100644 arch/mips/cavium-octeon/executive/cvmx-sysinfo.c
     create mode 100644 arch/mips/cavium-octeon/executive/octeon-model.c
     create mode 100644 arch/mips/include/asm/octeon/cvmx-asm.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-bootinfo.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-bootmem.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-l2c.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-packet.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-spinlock.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx-sysinfo.h
     create mode 100644 arch/mips/include/asm/octeon/cvmx.h
     create mode 100644 arch/mips/include/asm/octeon/octeon-feature.h
     create mode 100644 arch/mips/include/asm/octeon/octeon-model.h

diff --git a/arch/mips/include/asm/octeon/cvmx-spinlock.h b/arch/mips/include/asm/octeon/cvmx-spinlock.h
new file mode 100644
index 000000000000..2fbf0871df11
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-spinlock.h
@@ -0,0 +1,232 @@
+/***********************license start***************
+ * Author: Cavium Networks
+ *
+ * Contact: support@caviumnetworks.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2008 Cavium Networks
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Networks for more information
+ ***********************license end**************************************/
+
+/**
+ * Implementation of spinlocks for Octeon CVMX.  Although similar in
+ * function to Linux kernel spinlocks, they are not compatible.
+ * Octeon CVMX spinlocks are only used to synchronize with the boot
+ * monitor and other non-Linux programs running in the system.
+ */
+
+#ifndef __CVMX_SPINLOCK_H__
+#define __CVMX_SPINLOCK_H__
+
+#include "cvmx-asm.h"
+
+/* Spinlocks for Octeon */
+
+/* define these to enable recursive spinlock debugging */
+/*#define CVMX_SPINLOCK_DEBUG */
+
+/**
+ * Spinlocks for Octeon CVMX
+ */
+typedef struct {
+	volatile uint32_t value;
+} cvmx_spinlock_t;
+
+/* note - macros not expanded in inline ASM, so values hardcoded */
+#define  CVMX_SPINLOCK_UNLOCKED_VAL  0
+#define  CVMX_SPINLOCK_LOCKED_VAL    1
+
+#define CVMX_SPINLOCK_UNLOCKED_INITIALIZER  {CVMX_SPINLOCK_UNLOCKED_VAL}
+
+/**
+ * Initialize a spinlock
+ *
+ * @lock:   Lock to initialize
+ */
+static inline void cvmx_spinlock_init(cvmx_spinlock_t *lock)
+{
+	lock->value = CVMX_SPINLOCK_UNLOCKED_VAL;
+}
+
+/**
+ * Return non-zero if the spinlock is currently locked
+ *
+ * @lock:   Lock to check
+ * Returns Non-zero if locked
+ */
+static inline int cvmx_spinlock_locked(cvmx_spinlock_t *lock)
+{
+	return lock->value != CVMX_SPINLOCK_UNLOCKED_VAL;
+}
+
+/**
+ * Releases lock
+ *
+ * @lock:   pointer to lock structure
+ */
+static inline void cvmx_spinlock_unlock(cvmx_spinlock_t *lock)
+{
+	CVMX_SYNCWS;
+	lock->value = 0;
+	CVMX_SYNCWS;
+}
+
+/**
+ * Attempts to take the lock, but does not spin if lock is not available.
+ * May take some time to acquire the lock even if it is available
+ * due to the ll/sc not succeeding.
+ *
+ * @lock:   pointer to lock structure
+ *
+ * Returns 0: lock successfully taken
+ *         1: lock not taken, held by someone else
+ * These return values match the Linux semantics.
+ */
+
+static inline unsigned int cvmx_spinlock_trylock(cvmx_spinlock_t *lock)
+{
+	unsigned int tmp;
+
+	__asm__ __volatile__(".set noreorder         \n"
+			     "1: ll   %[tmp], %[val] \n"
+			/* if lock held, fail immediately */
+			     "   bnez %[tmp], 2f     \n"
+			     "   li   %[tmp], 1      \n"
+			     "   sc   %[tmp], %[val] \n"
+			     "   beqz %[tmp], 1b     \n"
+			     "   li   %[tmp], 0      \n"
+			     "2:                     \n"
+			     ".set reorder           \n" :
+			[val] "+m"(lock->value), [tmp] "=&r"(tmp)
+			     : : "memory");
+
+	return tmp != 0;		/* normalize to 0 or 1 */
+}
+
+/**
+ * Gets lock, spins until lock is taken
+ *
+ * @lock:   pointer to lock structure
+ */
+static inline void cvmx_spinlock_lock(cvmx_spinlock_t *lock)
+{
+	unsigned int tmp;
+
+	__asm__ __volatile__(".set noreorder         \n"
+			     "1: ll   %[tmp], %[val]  \n"
+			     "   bnez %[tmp], 1b     \n"
+			     "   li   %[tmp], 1      \n"
+			     "   sc   %[tmp], %[val] \n"
+			     "   beqz %[tmp], 1b     \n"
+			     "   nop                \n"
+			     ".set reorder           \n" :
+			[val] "+m"(lock->value), [tmp] "=&r"(tmp)
+			: : "memory");
+
+}
+
+/** ********************************************************************
+ * Bit spinlocks
+ * These spinlocks use a single bit (bit 31) of a 32 bit word for locking.
+ * The rest of the bits in the word are left undisturbed.  This enables more
+ * compact data structures as only 1 bit is consumed for the lock.
+ *
+ */
+
+/**
+ * Gets lock, spins until lock is taken
+ * Preserves the low 31 bits of the 32 bit
+ * word used for the lock.
+ *
+ *
+ * @word:  word to lock bit 31 of
+ */
+static inline void cvmx_spinlock_bit_lock(uint32_t *word)
+{
+	unsigned int tmp;
+	unsigned int sav;
+
+	__asm__ __volatile__(".set noreorder         \n"
+			     ".set noat              \n"
+			     "1: ll    %[tmp], %[val]  \n"
+			     "   bbit1 %[tmp], 31, 1b    \n"
+			     "   li    $at, 1      \n"
+			     "   ins   %[tmp], $at, 31, 1  \n"
+			     "   sc    %[tmp], %[val] \n"
+			     "   beqz  %[tmp], 1b     \n"
+			     "   nop                \n"
+			     ".set at              \n"
+			     ".set reorder           \n" :
+			[val] "+m"(*word), [tmp] "=&r"(tmp), [sav] "=&r"(sav)
+			     : : "memory");
+
+}
+
+/**
+ * Attempts to get lock, returns immediately with success/failure
+ * Preserves the low 31 bits of the 32 bit
+ * word used for the lock.
+ *
+ *
+ * @word:  word to lock bit 31 of
+ * Returns 0: lock successfully taken
+ *         1: lock not taken, held by someone else
+ * These return values match the Linux semantics.
+ */
+static inline unsigned int cvmx_spinlock_bit_trylock(uint32_t *word)
+{
+	unsigned int tmp;
+
+	__asm__ __volatile__(".set noreorder\n\t"
+			     ".set noat\n"
+			     "1: ll    %[tmp], %[val] \n"
+			/* if lock held, fail immediately */
+			     "   bbit1 %[tmp], 31, 2f     \n"
+			     "   li    $at, 1      \n"
+			     "   ins   %[tmp], $at, 31, 1  \n"
+			     "   sc    %[tmp], %[val] \n"
+			     "   beqz  %[tmp], 1b     \n"
+			     "   li    %[tmp], 0      \n"
+			     "2:                     \n"
+			     ".set at              \n"
+			     ".set reorder           \n" :
+			[val] "+m"(*word), [tmp] "=&r"(tmp)
+			: : "memory");
+
+	return tmp != 0;		/* normalize to 0 or 1 */
+}
+
+/**
+ * Releases bit lock
+ *
+ * Unconditionally clears bit 31 of the lock word.  Note that this is
+ * done non-atomically, as this implementation assumes that the rest
+ * of the bits in the word are protected by the lock.
+ *
+ * @word:  word to unlock bit 31 in
+ */
+static inline void cvmx_spinlock_bit_unlock(uint32_t *word)
+{
+	CVMX_SYNCWS;
+	*word &= ~(1UL << 31);
+	CVMX_SYNCWS;
+}
+
+#endif /* __CVMX_SPINLOCK_H__ */
