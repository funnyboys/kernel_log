commit 3315b6b336c88969547f7e9f2e105a815eea529a
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Feb 7 19:07:04 2019 +0000

    MIPS: Delete unused flush_cache_sigtramp()
    
    Commit adcc81f148d7 ("MIPS: math-emu: Write-protect delay slot emulation
    pages") left flush_cache_sigtramp() unused. Delete the dead code.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: linux-mips@vger.kernel.org

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 4812d1fed0c2..d687b40b9fbb 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -25,7 +25,6 @@
  *
  * MIPS specific flush operations:
  *
- *  - flush_cache_sigtramp() flush signal trampoline
  *  - flush_icache_all() flush the entire instruction cache
  *  - flush_data_cache_page() flushes a page from the data cache
  *  - __flush_icache_user_range(start, end) flushes range of user instructions
@@ -110,7 +109,6 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 	struct page *page, unsigned long vaddr, void *dst, const void *src,
 	unsigned long len);
 
-extern void (*flush_cache_sigtramp)(unsigned long addr);
 extern void (*flush_icache_all)(void);
 extern void (*local_flush_data_cache_page)(void * addr);
 extern void (*flush_data_cache_page)(unsigned long addr);

commit 01882b4d5eae2800c8e86a29d279020f87e5d4f3
Author: James Hogan <james.hogan@imgtec.com>
Date:   Thu Sep 1 17:30:11 2016 +0100

    MIPS: c-r4k: Split user/kernel flush_icache_range()
    
    flush_icache_range() is used for both user addresses (i.e.
    cacheflush(2)), and kernel addresses (as the API documentation
    describes).
    
    This isn't really suitable however for Enhanced Virtual Addressing (EVA)
    where cache operations on usermode addresses must use a different
    instruction, and the protected cache ops assume user addresses, making
    flush_icache_range() ineffective on kernel addresses.
    
    Split out a new __flush_icache_user_range() and
    __local_flush_icache_user_range() for users which actually want to flush
    usermode addresses (note that flush_icache_user_range() already exists
    on various architectures but with different arguments).
    
    The implementation of flush_icache_range() will be changed in an
    upcoming commit to use unprotected normal cache ops so as to always work
    on the kernel mode address space.
    
    Signed-off-by: James Hogan <james.hogan@imgtec.com>
    Cc: Leonid Yegoshin <leonid.yegoshin@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/14152/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 34ed22ec6c33..4812d1fed0c2 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -28,6 +28,7 @@
  *  - flush_cache_sigtramp() flush signal trampoline
  *  - flush_icache_all() flush the entire instruction cache
  *  - flush_data_cache_page() flushes a page from the data cache
+ *  - __flush_icache_user_range(start, end) flushes range of user instructions
  */
 
  /*
@@ -80,6 +81,10 @@ static inline void flush_icache_page(struct vm_area_struct *vma,
 
 extern void (*flush_icache_range)(unsigned long start, unsigned long end);
 extern void (*local_flush_icache_range)(unsigned long start, unsigned long end);
+extern void (*__flush_icache_user_range)(unsigned long start,
+					 unsigned long end);
+extern void (*__local_flush_icache_user_range)(unsigned long start,
+					       unsigned long end);
 
 extern void (*__flush_cache_vmap)(void);
 

commit 37d22a0d798b5c938b277d32cfd86dc231381342
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Tue Mar 1 02:37:59 2016 +0000

    MIPS: Sync icache & dcache in set_pte_at
    
    It's possible for pages to become visible prior to update_mmu_cache
    running if a thread within the same address space preempts the current
    thread or runs simultaneously on another CPU. That is, the following
    scenario is possible:
    
        CPU0                            CPU1
    
        write to page
        flush_dcache_page
        flush_icache_page
        set_pte_at
                                        map page
        update_mmu_cache
    
    If CPU1 maps the page in between CPU0's set_pte_at, which marks it valid
    & visible, and update_mmu_cache where the dcache flush occurs then CPU1s
    icache will fill from stale data (unless it fills from the dcache, in
    which case all is good, but most MIPS CPUs don't have this property).
    Commit 4d46a67a3eb8 ("MIPS: Fix race condition in lazy cache flushing.")
    attempted to fix that by performing the dcache flush in
    flush_icache_page such that it occurs before the set_pte_at call makes
    the page visible. However it has the problem that not all code that
    writes to pages exposed to userland call flush_icache_page. There are
    many callers of set_pte_at under mm/ and only 2 of them do call
    flush_icache_page. Thus the race window between a page becoming visible
    & being coherent between the icache & dcache remains open in some cases.
    
    To illustrate some of the cases, a WARN was added to __update_cache with
    this patch applied that triggered in cases where a page about to be
    flushed from the dcache was not the last page provided to
    flush_icache_page. That is, backtraces were obtained for cases in which
    the race window is left open without this patch. The 2 standout examples
    follow.
    
    When forking a process:
    
    [   15.271842] [<80417630>] __update_cache+0xcc/0x188
    [   15.277274] [<80530394>] copy_page_range+0x56c/0x6ac
    [   15.282861] [<8042936c>] copy_process.part.54+0xd40/0x17ac
    [   15.289028] [<80429f80>] do_fork+0xe4/0x420
    [   15.293747] [<80413808>] handle_sys+0x128/0x14c
    
    When exec'ing an ELF binary:
    
    [   14.445964] [<80417630>] __update_cache+0xcc/0x188
    [   14.451369] [<80538d88>] move_page_tables+0x414/0x498
    [   14.457075] [<8055d848>] setup_arg_pages+0x220/0x318
    [   14.462685] [<805b0f38>] load_elf_binary+0x530/0x12a0
    [   14.468374] [<8055ec3c>] search_binary_handler+0xbc/0x214
    [   14.474444] [<8055f6c0>] do_execveat_common+0x43c/0x67c
    [   14.480324] [<8055f938>] do_execve+0x38/0x44
    [   14.485137] [<80413808>] handle_sys+0x128/0x14c
    
    These code paths write into a page, call flush_dcache_page then call
    set_pte_at without flush_icache_page inbetween. The end result is that
    the icache can become corrupted & userland processes may execute
    unexpected or invalid code, typically resulting in a reserved
    instruction exception, a trap or a segfault.
    
    Fix this race condition fully by performing any cache maintenance
    required to keep the icache & dcache in sync in set_pte_at, before the
    page is made valid. This has the added bonus of ensuring the cache
    maintenance always happens in one location, rather than being duplicated
    in flush_icache_page & update_mmu_cache. It also matches the way other
    architectures solve the same problem (see arm, ia64 & powerpc).
    
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>
    Reported-by: Ionela Voinescu <ionela.voinescu@imgtec.com>
    Cc: Lars Persson <lars.persson@axis.com>
    Fixes: 4d46a67a3eb8 ("MIPS: Fix race condition in lazy cache flushing.")
    Cc: Steven J. Hill <sjhill@realitydiluted.com>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Huacai Chen <chenhc@lemote.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Cc: stable <stable@vger.kernel.org> # v4.1+
    Patchwork: https://patchwork.linux-mips.org/patch/12722/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 7e9f46818eba..34ed22ec6c33 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -51,7 +51,6 @@ extern void (*flush_cache_range)(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end);
 extern void (*flush_cache_page)(struct vm_area_struct *vma, unsigned long page, unsigned long pfn);
 extern void __flush_dcache_page(struct page *page);
-extern void __flush_icache_page(struct vm_area_struct *vma, struct page *page);
 
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
@@ -77,11 +76,6 @@ static inline void flush_anon_page(struct vm_area_struct *vma,
 static inline void flush_icache_page(struct vm_area_struct *vma,
 	struct page *page)
 {
-	if (!cpu_has_ic_fills_f_dc && (vma->vm_flags & VM_EXEC) &&
-	    Page_dcache_dirty(page)) {
-		__flush_icache_page(vma, page);
-		ClearPageDcacheDirty(page);
-	}
 }
 
 extern void (*flush_icache_range)(unsigned long start, unsigned long end);

commit 763fee97e743acb4f6e683a00fd2e7f5ad2484fb
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Tue Mar 1 02:37:56 2016 +0000

    MIPS: Flush dcache for flush_kernel_dcache_page
    
    The flush_kernel_dcache_page function was previously essentially a nop.
    This is incorrect for MIPS, where if a page has been modified & either
    it aliases or it's executable & the icache doesn't fill from dcache then
    the content needs to be written back from dcache to the next level of
    the cache hierarchy (which is shared with the icache).
    
    Implement this by simply calling flush_dcache_page, treating this
    kmapped cache flush function (flush_kernel_dcache_page) exactly the same
    as its non-kmapped counterpart (flush_dcache_page).
    
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>
    Cc: Lars Persson <lars.persson@axis.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/12719/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 723229f4cf27..7e9f46818eba 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -132,6 +132,7 @@ static inline void kunmap_noncoherent(void)
 static inline void flush_kernel_dcache_page(struct page *page)
 {
 	BUG_ON(cpu_has_dc_aliases && PageHighMem(page));
+	flush_dcache_page(page);
 }
 
 /*

commit 4d46a67a3eb827ccf1125959936fd51ba318dabc
Author: Lars Persson <lars.persson@axis.com>
Date:   Thu Feb 26 14:16:03 2015 +0100

    MIPS: Fix race condition in lazy cache flushing.
    
    The lazy cache flushing implemented in the MIPS kernel suffers from a
    race condition that is exposed by do_set_pte() in mm/memory.c.
    
    A pre-condition is a file-system that writes to the page from the CPU
    in its readpage method and then calls flush_dcache_page(). One example
    is ubifs. Another pre-condition is that the dcache flush is postponed
    in __flush_dcache_page().
    
    Upon a page fault for an executable mapping not existing in the
    page-cache, the following will happen:
    1. Write to the page
    2. flush_dcache_page
    3. flush_icache_page
    4. set_pte_at
    5. update_mmu_cache (commits the flush of a dcache-dirty page)
    
    Between steps 4 and 5 another thread can hit the same page and it will
    encounter a valid pte. Because the data still is in the L1 dcache the CPU
    will fetch stale data from L2 into the icache and execute garbage.
    
    This fix moves the commit of the cache flush to step 3 to close the
    race window. It also reduces the amount of flushes on non-executable
    mappings because we never enter __flush_dcache_page() for non-aliasing
    CPUs.
    
    Regressions can occur in drivers that mistakenly relies on the
    flush_dcache_page() in get_user_pages() for DMA operations.
    
    [ralf@linux-mips.org: Folded in patch 9346 to fix highmem issue.]
    
    Signed-off-by: Lars Persson <larper@axis.com>
    Cc: linux-mips@linux-mips.org
    Cc: paul.burton@imgtec.com
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/9346/
    Patchwork: https://patchwork.linux-mips.org/patch/9738/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index e08381a37f8b..723229f4cf27 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -29,6 +29,20 @@
  *  - flush_icache_all() flush the entire instruction cache
  *  - flush_data_cache_page() flushes a page from the data cache
  */
+
+ /*
+ * This flag is used to indicate that the page pointed to by a pte
+ * is dirty and requires cleaning before returning it to the user.
+ */
+#define PG_dcache_dirty			PG_arch_1
+
+#define Page_dcache_dirty(page)		\
+	test_bit(PG_dcache_dirty, &(page)->flags)
+#define SetPageDcacheDirty(page)	\
+	set_bit(PG_dcache_dirty, &(page)->flags)
+#define ClearPageDcacheDirty(page)	\
+	clear_bit(PG_dcache_dirty, &(page)->flags)
+
 extern void (*flush_cache_all)(void);
 extern void (*__flush_cache_all)(void);
 extern void (*flush_cache_mm)(struct mm_struct *mm);
@@ -37,13 +51,15 @@ extern void (*flush_cache_range)(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end);
 extern void (*flush_cache_page)(struct vm_area_struct *vma, unsigned long page, unsigned long pfn);
 extern void __flush_dcache_page(struct page *page);
+extern void __flush_icache_page(struct vm_area_struct *vma, struct page *page);
 
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
 {
-	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)
+	if (cpu_has_dc_aliases)
 		__flush_dcache_page(page);
-
+	else if (!cpu_has_ic_fills_f_dc)
+		SetPageDcacheDirty(page);
 }
 
 #define flush_dcache_mmap_lock(mapping)		do { } while (0)
@@ -61,6 +77,11 @@ static inline void flush_anon_page(struct vm_area_struct *vma,
 static inline void flush_icache_page(struct vm_area_struct *vma,
 	struct page *page)
 {
+	if (!cpu_has_ic_fills_f_dc && (vma->vm_flags & VM_EXEC) &&
+	    Page_dcache_dirty(page)) {
+		__flush_icache_page(vma, page);
+		ClearPageDcacheDirty(page);
+	}
 }
 
 extern void (*flush_icache_range)(unsigned long start, unsigned long end);
@@ -95,19 +116,6 @@ extern void (*flush_icache_all)(void);
 extern void (*local_flush_data_cache_page)(void * addr);
 extern void (*flush_data_cache_page)(unsigned long addr);
 
-/*
- * This flag is used to indicate that the page pointed to by a pte
- * is dirty and requires cleaning before returning it to the user.
- */
-#define PG_dcache_dirty			PG_arch_1
-
-#define Page_dcache_dirty(page)		\
-	test_bit(PG_dcache_dirty, &(page)->flags)
-#define SetPageDcacheDirty(page)	\
-	set_bit(PG_dcache_dirty, &(page)->flags)
-#define ClearPageDcacheDirty(page)	\
-	clear_bit(PG_dcache_dirty, &(page)->flags)
-
 /* Run kernel code uncached, useful for cache probing functions. */
 unsigned long run_uncached(void *func);
 

commit e2a9e5ad719fb424ab3c30520733aa0e8fbcf1ce
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Mon Mar 3 12:08:40 2014 +0000

    MIPS: add kmap_noncoherent to wire a cached non-coherent TLB entry
    
    This is identical to kmap_coherent apart from the cache coherency
    attribute used for the TLB entry, so kmap_coherent is abstracted to
    kmap_prot which is then called for both kmap_coherent &
    kmap_noncoherent. This will be used by a subsequent patch.
    
    Suggested-by: Leonid Yegoshin <leonid.yegoshin@imgtec.com>
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 69468ded2828..e08381a37f8b 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -113,6 +113,12 @@ unsigned long run_uncached(void *func);
 
 extern void *kmap_coherent(struct page *page, unsigned long addr);
 extern void kunmap_coherent(void);
+extern void *kmap_noncoherent(struct page *page, unsigned long addr);
+
+static inline void kunmap_noncoherent(void)
+{
+	kunmap_coherent();
+}
 
 #define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
 static inline void flush_kernel_dcache_page(struct page *page)

commit d9cdc901af0f92da7f90c750d8c187f5500be067
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Fri Jun 17 16:20:28 2011 +0100

    MIPS: cache: Provide cache flush operations for XFS
    
    Until now flush_kernel_vmap_range() and invalidate_kernel_vmap_range() did
    not exist on MIPS resulting in heavy cache corruption on XFS filesystems.
    
    Left for the post-3.0 time: optimization and make this work with highmem,
    too.  Since the combination of highmem + cache aliases atm doesn't work
    this isn't a regression.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Patchwork: https://patchwork.linux-mips.org/patch/2505/

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 40bb9fde205f..69468ded2828 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -114,4 +114,28 @@ unsigned long run_uncached(void *func);
 extern void *kmap_coherent(struct page *page, unsigned long addr);
 extern void kunmap_coherent(void);
 
+#define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
+static inline void flush_kernel_dcache_page(struct page *page)
+{
+	BUG_ON(cpu_has_dc_aliases && PageHighMem(page));
+}
+
+/*
+ * For now flush_kernel_vmap_range and invalidate_kernel_vmap_range both do a
+ * cache writeback and invalidate operation.
+ */
+extern void (*__flush_kernel_vmap_range)(unsigned long vaddr, int size);
+
+static inline void flush_kernel_vmap_range(void *vaddr, int size)
+{
+	if (cpu_has_dc_aliases)
+		__flush_kernel_vmap_range((unsigned long) vaddr, size);
+}
+
+static inline void invalidate_kernel_vmap_range(void *vaddr, int size)
+{
+	if (cpu_has_dc_aliases)
+		__flush_kernel_vmap_range((unsigned long) vaddr, size);
+}
+
 #endif /* _ASM_CACHEFLUSH_H */

commit 2d4dc890b5c8fabd818a8586607e6843c4375e62
Author: Ilya Loginov <isloginov@gmail.com>
Date:   Thu Nov 26 09:16:19 2009 +0100

    block: add helpers to run flush_dcache_page() against a bio and a request's pages
    
    Mtdblock driver doesn't call flush_dcache_page for pages in request.  So,
    this causes problems on architectures where the icache doesn't fill from
    the dcache or with dcache aliases.  The patch fixes this.
    
    The ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE symbol was introduced to avoid
    pointless empty cache-thrashing loops on architectures for which
    flush_dcache_page() is a no-op.  Every architecture was provided with this
    flush pages on architectires where ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE is
    equal 1 or do nothing otherwise.
    
    See "fix mtd_blkdevs problem with caches on some architectures" discussion
    on LKML for more information.
    
    Signed-off-by: Ilya Loginov <isloginov@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Peter Horton <phorton@bitbox.co.uk>
    Cc: "Ed L. Cashin" <ecashin@coraid.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 03b1d69b142f..40bb9fde205f 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -38,6 +38,7 @@ extern void (*flush_cache_range)(struct vm_area_struct *vma,
 extern void (*flush_cache_page)(struct vm_area_struct *vma, unsigned long page, unsigned long pfn);
 extern void __flush_dcache_page(struct page *page);
 
+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
 {
 	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)

commit 384740dc49ea651ba350704d13ff6be9976e37fe
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Sep 16 19:48:51 2008 +0200

    MIPS: Move headfiles to new location below arch/mips/include
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
new file mode 100644
index 000000000000..03b1d69b142f
--- /dev/null
+++ b/arch/mips/include/asm/cacheflush.h
@@ -0,0 +1,116 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994, 95, 96, 97, 98, 99, 2000, 01, 02, 03 by Ralf Baechle
+ * Copyright (C) 1999, 2000, 2001 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_CACHEFLUSH_H
+#define _ASM_CACHEFLUSH_H
+
+/* Keep includes the same across arches.  */
+#include <linux/mm.h>
+#include <asm/cpu-features.h>
+
+/* Cache flushing:
+ *
+ *  - flush_cache_all() flushes entire cache
+ *  - flush_cache_mm(mm) flushes the specified mm context's cache lines
+ *  - flush_cache_dup mm(mm) handles cache flushing when forking
+ *  - flush_cache_page(mm, vmaddr, pfn) flushes a single page
+ *  - flush_cache_range(vma, start, end) flushes a range of pages
+ *  - flush_icache_range(start, end) flush a range of instructions
+ *  - flush_dcache_page(pg) flushes(wback&invalidates) a page for dcache
+ *
+ * MIPS specific flush operations:
+ *
+ *  - flush_cache_sigtramp() flush signal trampoline
+ *  - flush_icache_all() flush the entire instruction cache
+ *  - flush_data_cache_page() flushes a page from the data cache
+ */
+extern void (*flush_cache_all)(void);
+extern void (*__flush_cache_all)(void);
+extern void (*flush_cache_mm)(struct mm_struct *mm);
+#define flush_cache_dup_mm(mm)	do { (void) (mm); } while (0)
+extern void (*flush_cache_range)(struct vm_area_struct *vma,
+	unsigned long start, unsigned long end);
+extern void (*flush_cache_page)(struct vm_area_struct *vma, unsigned long page, unsigned long pfn);
+extern void __flush_dcache_page(struct page *page);
+
+static inline void flush_dcache_page(struct page *page)
+{
+	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)
+		__flush_dcache_page(page);
+
+}
+
+#define flush_dcache_mmap_lock(mapping)		do { } while (0)
+#define flush_dcache_mmap_unlock(mapping)	do { } while (0)
+
+#define ARCH_HAS_FLUSH_ANON_PAGE
+extern void __flush_anon_page(struct page *, unsigned long);
+static inline void flush_anon_page(struct vm_area_struct *vma,
+	struct page *page, unsigned long vmaddr)
+{
+	if (cpu_has_dc_aliases && PageAnon(page))
+		__flush_anon_page(page, vmaddr);
+}
+
+static inline void flush_icache_page(struct vm_area_struct *vma,
+	struct page *page)
+{
+}
+
+extern void (*flush_icache_range)(unsigned long start, unsigned long end);
+extern void (*local_flush_icache_range)(unsigned long start, unsigned long end);
+
+extern void (*__flush_cache_vmap)(void);
+
+static inline void flush_cache_vmap(unsigned long start, unsigned long end)
+{
+	if (cpu_has_dc_aliases)
+		__flush_cache_vmap();
+}
+
+extern void (*__flush_cache_vunmap)(void);
+
+static inline void flush_cache_vunmap(unsigned long start, unsigned long end)
+{
+	if (cpu_has_dc_aliases)
+		__flush_cache_vunmap();
+}
+
+extern void copy_to_user_page(struct vm_area_struct *vma,
+	struct page *page, unsigned long vaddr, void *dst, const void *src,
+	unsigned long len);
+
+extern void copy_from_user_page(struct vm_area_struct *vma,
+	struct page *page, unsigned long vaddr, void *dst, const void *src,
+	unsigned long len);
+
+extern void (*flush_cache_sigtramp)(unsigned long addr);
+extern void (*flush_icache_all)(void);
+extern void (*local_flush_data_cache_page)(void * addr);
+extern void (*flush_data_cache_page)(unsigned long addr);
+
+/*
+ * This flag is used to indicate that the page pointed to by a pte
+ * is dirty and requires cleaning before returning it to the user.
+ */
+#define PG_dcache_dirty			PG_arch_1
+
+#define Page_dcache_dirty(page)		\
+	test_bit(PG_dcache_dirty, &(page)->flags)
+#define SetPageDcacheDirty(page)	\
+	set_bit(PG_dcache_dirty, &(page)->flags)
+#define ClearPageDcacheDirty(page)	\
+	clear_bit(PG_dcache_dirty, &(page)->flags)
+
+/* Run kernel code uncached, useful for cache probing functions. */
+unsigned long run_uncached(void *func);
+
+extern void *kmap_coherent(struct page *page, unsigned long addr);
+extern void kunmap_coherent(void);
+
+#endif /* _ASM_CACHEFLUSH_H */
