commit d257b8fe173a4b22ca32780a6e65b075a3b88301
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 16 17:00:10 2020 +0200

    MIPS: move ioremap_prot und iounmap out of line
    
    Neither of these interfaces is anywhere near the fast path.  Move them
    out of line and avoid exposing implementation details to the drivers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index f007571e036d..346fffd9e972 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -30,8 +30,6 @@
 #include <asm/pgtable-bits.h>
 #include <asm/processor.h>
 #include <asm/string.h>
-
-#include <ioremap.h>
 #include <mangle-port.h>
 
 /*
@@ -153,87 +151,9 @@ static inline void *isa_bus_to_virt(unsigned long address)
  */
 #define page_to_phys(page)	((dma_addr_t)page_to_pfn(page) << PAGE_SHIFT)
 
-#ifdef CONFIG_64BIT
-static inline void __iomem *ioremap_prot(phys_addr_t offset,
-		unsigned long size, unsigned long prot_val)
-{
-	unsigned long flags = prot_val & _CACHE_MASK;
-	u64 base = (flags == _CACHE_UNCACHED ? IO_BASE : UNCAC_BASE);
-	void __iomem *addr;
-
-	addr = plat_ioremap(offset, size, flags);
-	if (!addr)
-		addr = (void __iomem *)(unsigned long)(base + offset);
-	return addr;
-}
-
-static inline void iounmap(const volatile void __iomem *addr)
-{
-	plat_iounmap(addr);
-}
-#else /* CONFIG_64BIT */
-extern void __iomem * __ioremap(phys_addr_t offset, phys_addr_t size, unsigned long flags);
-extern void __iounmap(const volatile void __iomem *addr);
-
-/*
- * ioremap_prot     -   map bus memory into CPU space
- * @offset:    bus address of the memory
- * @size:      size of the resource to map
-
- * ioremap_prot gives the caller control over cache coherency attributes (CCA)
- */
-static inline void __iomem *ioremap_prot(phys_addr_t offset,
-		unsigned long size, unsigned long prot_val)
-{
-	unsigned long flags = prot_val & _CACHE_MASK;
-	void __iomem *addr = plat_ioremap(offset, size, flags);
-
-	if (addr)
-		return addr;
-
-#define __IS_LOW512(addr) (!((phys_addr_t)(addr) & (phys_addr_t) ~0x1fffffffULL))
-
-	if (__builtin_constant_p(offset) &&
-	    __builtin_constant_p(size) && __builtin_constant_p(flags)) {
-		phys_addr_t phys_addr, last_addr;
-
-		phys_addr = fixup_bigphys_addr(offset, size);
-
-		/* Don't allow wraparound or zero size. */
-		last_addr = phys_addr + size - 1;
-		if (!size || last_addr < phys_addr)
-			return NULL;
-
-		/*
-		 * Map uncached objects in the low 512MB of address
-		 * space using KSEG1.
-		 */
-		if (__IS_LOW512(phys_addr) && __IS_LOW512(last_addr) &&
-		    flags == _CACHE_UNCACHED)
-			return (void __iomem *)
-				(unsigned long)CKSEG1ADDR(phys_addr);
-	}
-
-	return __ioremap(offset, size, flags);
-
-#undef __IS_LOW512
-}
-
-static inline void iounmap(const volatile void __iomem *addr)
-{
-	if (plat_iounmap(addr))
-		return;
-
-#define __IS_KSEG1(addr) (((unsigned long)(addr) & ~0x1fffffffUL) == CKSEG1)
-
-	if (__builtin_constant_p(addr) && __IS_KSEG1(addr))
-		return;
-
-	__iounmap(addr);
-
-#undef __IS_KSEG1
-}
-#endif /* !CONFIG_64BIT */
+void __iomem *ioremap_prot(phys_addr_t offset, unsigned long size,
+		unsigned long prot_val);
+void iounmap(const volatile void __iomem *addr);
 
 /*
  * ioremap     -   map bus memory into CPU space

commit 8e487c153c302a4cf274c1645c705ad6f551f138
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 16 17:00:09 2020 +0200

    MIPS: split out the 64-bit ioremap implementation
    
    Split out the mips64 ioremap implementation entirely, as it will never use
    page table based remapping.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 60513250f8f8..f007571e036d 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -153,6 +153,25 @@ static inline void *isa_bus_to_virt(unsigned long address)
  */
 #define page_to_phys(page)	((dma_addr_t)page_to_pfn(page) << PAGE_SHIFT)
 
+#ifdef CONFIG_64BIT
+static inline void __iomem *ioremap_prot(phys_addr_t offset,
+		unsigned long size, unsigned long prot_val)
+{
+	unsigned long flags = prot_val & _CACHE_MASK;
+	u64 base = (flags == _CACHE_UNCACHED ? IO_BASE : UNCAC_BASE);
+	void __iomem *addr;
+
+	addr = plat_ioremap(offset, size, flags);
+	if (!addr)
+		addr = (void __iomem *)(unsigned long)(base + offset);
+	return addr;
+}
+
+static inline void iounmap(const volatile void __iomem *addr)
+{
+	plat_iounmap(addr);
+}
+#else /* CONFIG_64BIT */
 extern void __iomem * __ioremap(phys_addr_t offset, phys_addr_t size, unsigned long flags);
 extern void __iounmap(const volatile void __iomem *addr);
 
@@ -174,18 +193,8 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
 
 #define __IS_LOW512(addr) (!((phys_addr_t)(addr) & (phys_addr_t) ~0x1fffffffULL))
 
-	if (IS_ENABLED(CONFIG_64BIT)) {
-		u64 base = UNCAC_BASE;
-
-		/*
-		 * R10000 supports a 2 bit uncached attribute therefore
-		 * UNCAC_BASE may not equal IO_BASE.
-		 */
-		if (flags == _CACHE_UNCACHED)
-			base = (u64) IO_BASE;
-		return (void __iomem *) (unsigned long) (base + offset);
-	} else if (__builtin_constant_p(offset) &&
-		   __builtin_constant_p(size) && __builtin_constant_p(flags)) {
+	if (__builtin_constant_p(offset) &&
+	    __builtin_constant_p(size) && __builtin_constant_p(flags)) {
 		phys_addr_t phys_addr, last_addr;
 
 		phys_addr = fixup_bigphys_addr(offset, size);
@@ -210,6 +219,22 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
 #undef __IS_LOW512
 }
 
+static inline void iounmap(const volatile void __iomem *addr)
+{
+	if (plat_iounmap(addr))
+		return;
+
+#define __IS_KSEG1(addr) (((unsigned long)(addr) & ~0x1fffffffUL) == CKSEG1)
+
+	if (__builtin_constant_p(addr) && __IS_KSEG1(addr))
+		return;
+
+	__iounmap(addr);
+
+#undef __IS_KSEG1
+}
+#endif /* !CONFIG_64BIT */
+
 /*
  * ioremap     -   map bus memory into CPU space
  * @offset:    bus address of the memory
@@ -264,22 +289,6 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
 #define ioremap_wc(offset, size)					\
 	ioremap_prot((offset), (size), boot_cpu_data.writecombine)
 
-static inline void iounmap(const volatile void __iomem *addr)
-{
-	if (plat_iounmap(addr))
-		return;
-
-#define __IS_KSEG1(addr) (((unsigned long)(addr) & ~0x1fffffffUL) == CKSEG1)
-
-	if (IS_ENABLED(CONFIG_64BIT) ||
-	    (__builtin_constant_p(addr) && __IS_KSEG1(addr)))
-		return;
-
-	__iounmap(addr);
-
-#undef __IS_KSEG1
-}
-
 #if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_CPU_LOONGSON64)
 #define war_io_reorder_wmb()		wmb()
 #else

commit 5c9ff5709dcf82bfd9a6d0d99a13b15ca522f510
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 16 17:00:08 2020 +0200

    MIPS: merge __ioremap_mode into ioremap_prot
    
    There is no reason to have two ioremap with flags interfaces.  Merge
    the historic mips __ioremap_mode into ioremap_prot which is a generic
    kernel interface.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 7be323ed2bfd..60513250f8f8 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -156,9 +156,17 @@ static inline void *isa_bus_to_virt(unsigned long address)
 extern void __iomem * __ioremap(phys_addr_t offset, phys_addr_t size, unsigned long flags);
 extern void __iounmap(const volatile void __iomem *addr);
 
-static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long size,
-	unsigned long flags)
+/*
+ * ioremap_prot     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+
+ * ioremap_prot gives the caller control over cache coherency attributes (CCA)
+ */
+static inline void __iomem *ioremap_prot(phys_addr_t offset,
+		unsigned long size, unsigned long prot_val)
 {
+	unsigned long flags = prot_val & _CACHE_MASK;
 	void __iomem *addr = plat_ioremap(offset, size, flags);
 
 	if (addr)
@@ -202,18 +210,6 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 #undef __IS_LOW512
 }
 
-/*
- * ioremap_prot     -   map bus memory into CPU space
- * @offset:    bus address of the memory
- * @size:      size of the resource to map
-
- * ioremap_prot gives the caller control over cache coherency attributes (CCA)
- */
-static inline void __iomem *ioremap_prot(phys_addr_t offset,
-		unsigned long size, unsigned long prot_val) {
-	return __ioremap_mode(offset, size, prot_val & _CACHE_MASK);
-}
-
 /*
  * ioremap     -   map bus memory into CPU space
  * @offset:    bus address of the memory
@@ -226,7 +222,7 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  * address.
  */
 #define ioremap(offset, size)						\
-	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
+	ioremap_prot((offset), (size), _CACHE_UNCACHED)
 #define ioremap_uc		ioremap
 
 /*
@@ -245,7 +241,7 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  * memory-like regions on I/O busses.
  */
 #define ioremap_cache(offset, size)					\
-	__ioremap_mode((offset), (size), _page_cachable_default)
+	ioremap_prot((offset), (size), _page_cachable_default)
 
 /*
  * ioremap_wc     -   map bus memory into CPU space
@@ -266,7 +262,7 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  * _CACHE_UNCACHED option (see cpu_probe() method).
  */
 #define ioremap_wc(offset, size)					\
-	__ioremap_mode((offset), (size), boot_cpu_data.writecombine)
+	ioremap_prot((offset), (size), boot_cpu_data.writecombine)
 
 static inline void iounmap(const volatile void __iomem *addr)
 {

commit b604d4973af7df4bbe970b2c380f5a0477fa53ec
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 16 17:00:06 2020 +0200

    MIPS: remove cpu_has_64bit_addresses
    
    This macro is identical to CONFIG_64BIT, and using a Kconfig variable
    for the only places that checks them (the ioremap implementation) will
    simplify later patches in this series.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index cf1f2a4a2418..7be323ed2bfd 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -166,7 +166,7 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 
 #define __IS_LOW512(addr) (!((phys_addr_t)(addr) & (phys_addr_t) ~0x1fffffffULL))
 
-	if (cpu_has_64bit_addresses) {
+	if (IS_ENABLED(CONFIG_64BIT)) {
 		u64 base = UNCAC_BASE;
 
 		/*
@@ -275,7 +275,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 
 #define __IS_KSEG1(addr) (((unsigned long)(addr) & ~0x1fffffffUL) == CKSEG1)
 
-	if (cpu_has_64bit_addresses ||
+	if (IS_ENABLED(CONFIG_64BIT) ||
 	    (__builtin_constant_p(addr) && __IS_KSEG1(addr)))
 		return;
 

commit 4bdc0d676a643140bdf17dbf7eafedee3d496a3c
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 6 09:43:50 2020 +0100

    remove ioremap_nocache and devm_ioremap_nocache
    
    ioremap has provided non-cached semantics by default since the Linux 2.6
    days, so remove the additional ioremap_nocache interface.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index d9caa811a2fa..cf1f2a4a2418 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -227,7 +227,6 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  */
 #define ioremap(offset, size)						\
 	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
-#define ioremap_nocache		ioremap
 #define ioremap_uc		ioremap
 
 /*

commit d23cc635889cacdbb84de7ca099c2ee0a522fd0c
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Dec 6 09:46:22 2019 +0100

    MIPS: define ioremap_nocache to ioremap
    
    They are both defined the same way, but this makes it easier to validate
    the scripted ioremap_nocache removal following soon.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Paul Burton <paulburton@kernel.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 3f6ce74335b4..d9caa811a2fa 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -227,29 +227,8 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  */
 #define ioremap(offset, size)						\
 	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
-
-/*
- * ioremap_nocache     -   map bus memory into CPU space
- * @offset:    bus address of the memory
- * @size:      size of the resource to map
- *
- * ioremap_nocache performs a platform specific sequence of operations to
- * make bus memory CPU accessible via the readb/readw/readl/writeb/
- * writew/writel functions and the other mmio helpers. The returned
- * address is not guaranteed to be usable directly as a virtual
- * address.
- *
- * This version of ioremap ensures that the memory is marked uncachable
- * on the CPU as well as honouring existing caching rules from things like
- * the PCI bus. Note that there are other caches and buffers on many
- * busses. In particular driver authors should read up on PCI writes
- *
- * It's useful if some control registers are in such an area and
- * write combining or read caching is not desirable:
- */
-#define ioremap_nocache(offset, size)					\
-	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
-#define ioremap_uc ioremap_nocache
+#define ioremap_nocache		ioremap
+#define ioremap_uc		ioremap
 
 /*
  * ioremap_cache -	map bus memory into CPU space

commit 268a2d60013049cfd9a0aada77284aa6ea8ad26a
Author: Jiaxun Yang <jiaxun.yang@flygoat.com>
Date:   Sun Oct 20 22:43:13 2019 +0800

    MIPS: Loongson64: Rename CPU TYPES
    
    CPU_LOONGSON2 -> CPU_LOONGSON2EF
    CPU_LOONGSON3 -> CPU_LOONGSON64
    
    As newer loongson-2 products (2G/2H/2K1000) can share kernel
    implementation with loongson-3 while 2E/2F are less similar with
    other LOONGSON64 products.
    
    Signed-off-by: Jiaxun Yang <jiaxun.yang@flygoat.com>
    Signed-off-by: Paul Burton <paulburton@kernel.org>
    Cc: linux-mips@vger.kernel.org
    Cc: chenhc@lemote.com
    Cc: paul.burton@mips.com

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 2b7b56736372..3f6ce74335b4 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -306,7 +306,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 #undef __IS_KSEG1
 }
 
-#if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_CPU_LOONGSON3)
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_CPU_LOONGSON64)
 #define war_io_reorder_wmb()		wmb()
 #else
 #define war_io_reorder_wmb()		barrier()

commit 60af0d94cc37287525c396d87e942a52b742743f
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 17 09:32:31 2019 +0200

    mips: remove ioremap_cachable
    
    Just define ioremap_cache directly.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index d58ff2229738..2b7b56736372 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -252,11 +252,11 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
 #define ioremap_uc ioremap_nocache
 
 /*
- * ioremap_cachable -	map bus memory into CPU space
+ * ioremap_cache -	map bus memory into CPU space
  * @offset:	    bus address of the memory
  * @size:	    size of the resource to map
  *
- * ioremap_nocache performs a platform specific sequence of operations to
+ * ioremap_cache performs a platform specific sequence of operations to
  * make bus memory CPU accessible via the readb/readw/readl/writeb/
  * writew/writel functions and the other mmio helpers. The returned
  * address is not guaranteed to be usable directly as a virtual
@@ -266,9 +266,8 @@ static inline void __iomem *ioremap_prot(phys_addr_t offset,
  * the CPU.  Also enables full write-combining.	 Useful for some
  * memory-like regions on I/O busses.
  */
-#define ioremap_cachable(offset, size)					\
+#define ioremap_cache(offset, size)					\
 	__ioremap_mode((offset), (size), _page_cachable_default)
-#define ioremap_cache ioremap_cachable
 
 /*
  * ioremap_wc     -   map bus memory into CPU space

commit 12051b318bc3ce5b42d6d786191008284b067d83
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Mon Jul 29 14:10:12 2019 -0700

    mips: avoid explicit UB in assignment of mips_io_port_base
    
    The code in question is modifying a variable declared const through
    pointer manipulation.  Such code is explicitly undefined behavior, and
    is the lone issue preventing malta_defconfig from booting when built
    with Clang:
    
    If an attempt is made to modify an object defined with a const-qualified
    type through use of an lvalue with non-const-qualified type, the
    behavior is undefined.
    
    LLVM is removing such assignments. A simple fix is to not declare
    variables const that you plan on modifying.  Limiting the scope would be
    a better method of preventing unwanted writes to such a variable.
    
    Further, the code in question mentions "compiler bugs" without any links
    to bug reports, so it is difficult to know if the issue is resolved in
    GCC. The patch was authored in 2006, which would have been GCC 4.0.3 or
    4.1.1. The minimal supported version of GCC in the Linux kernel is
    currently 4.6.
    
    For what its worth, there was UB before the commit in question, it just
    added a barrier and got lucky IRT codegen. I don't think there's any
    actual compiler bugs related, just runtime bugs due to UB.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/610
    Fixes: 966f4406d903 ("[MIPS] Work around bad code generation for <asm/io.h>.")
    Reported-by: Nathan Chancellor <natechancellor@gmail.com>
    Debugged-by: Nathan Chancellor <natechancellor@gmail.com>
    Suggested-by: Eli Friedman <efriedma@quicinc.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Reviewed-by: Nathan Chancellor <natechancellor@gmail.com>
    Tested-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: ralf@linux-mips.org
    Cc: jhogan@kernel.org
    Cc: Maciej W. Rozycki <macro@linux-mips.org>
    Cc: Hassan Naveed <hnaveed@wavecomp.com>
    Cc: Stephen Kitt <steve@sk2.org>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: clang-built-linux@googlegroups.com

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 97a280640daf..d58ff2229738 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -63,21 +63,11 @@
  * instruction, so the lower 16 bits must be zero.  Should be true on
  * on any sane architecture; generic code does not use this assumption.
  */
-extern const unsigned long mips_io_port_base;
+extern unsigned long mips_io_port_base;
 
-/*
- * Gcc will generate code to load the value of mips_io_port_base after each
- * function call which may be fairly wasteful in some cases.  So we don't
- * play quite by the book.  We tell gcc mips_io_port_base is a long variable
- * which solves the code generation issue.  Now we need to violate the
- * aliasing rules a little to make initialization possible and finally we
- * will need the barrier() to fight side effects of the aliasing chat.
- * This trickery will eventually collapse under gcc's optimizer.  Oh well.
- */
 static inline void set_io_port_base(unsigned long base)
 {
-	* (unsigned long *) &mips_io_port_base = base;
-	barrier();
+	mips_io_port_base = base;
 }
 
 /*

commit fa121bb3fed6313b1f0af23952301e06cf6d32ed
Merge: 7d4901c08ae5 e5793cd1b5fe
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 17 09:42:03 2019 -0700

    Merge tag 'mips_5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux
    
    Pull MIPS updates from Paul Burton:
     "A light batch this time around but significant improvements for
      certain systems:
    
       - Removal of readq & writeq for MIPS32 kernels where they would
         simply BUG() anyway, allowing drivers or other code that #ifdefs on
         their presence to work properly.
    
       - Improvements for Ingenic JZ4740 systems, including support for the
         external memory controller & pinmuxing fixes for qi_lb60/NanoNote
         systems.
    
       - Improvements for Lantiq systems, in particular around SMP & IPIs.
    
       - DT updates for ralink/MediaTek MT7628a systems to probe & configure
         a bunch more devices.
    
       - Miscellaneous cleanups & build fixes"
    
    * tag 'mips_5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux: (30 commits)
      MIPS: fix some more fall through errors in arch/mips
      MIPS: perf events: handle switch statement falling through warnings
      mips/kprobes: Export kprobe_fault_handler()
      MAINTAINERS: Add myself as Ingenic SoCs maintainer
      MIPS: ralink: mt7628a.dtsi: Add watchdog controller DT node
      MIPS: ralink: mt7628a.dtsi: Add SPI controller DT node
      MIPS: ralink: mt7628a.dtsi: Add GPIO controller DT node
      MIPS: ralink: mt7628a.dtsi: Add pinctrl DT properties to the UART nodes
      MIPS: ralink: mt7628a.dtsi: Add pinmux DT node
      MIPS: ralink: mt7628a.dtsi: Add SPDX GPL-2.0 license identifier
      MIPS: lantiq: Add SMP support for lantiq interrupt controller
      MIPS: lantiq: Shorten register names, remove unused macros
      MIPS: lantiq: Fix bitfield masking
      MIPS: lantiq: Remove unused macros
      MIPS: lantiq: Fix attributes of of_device_id structure
      MIPS: lantiq: Change variables to the same type as the source
      MIPS: lantiq: Move macro directly to iomem function
      mips: Remove q-accessors from non-64bit platforms
      FDDI: defza: Include linux/io-64-nonatomic-lo-hi.h
      MIPS: configs: Remove useless UEVENT_HELPER_PATH
      ...

commit 3a7f0adfe7c27cdaf6dc3456226a430398732e2c
Author: Stephen Kitt <steve@sk2.org>
Date:   Tue Jul 16 16:27:04 2019 -0700

    arch/*: remove unused isa_page_to_bus()
    
    isa_page_to_bus() is deprecated and is no longer used anywhere.  Remove
    it entirely.
    
    Link: http://lkml.kernel.org/r/20190613161155.16946-1-steve@sk2.org
    Signed-off-by: Stephen Kitt <steve@sk2.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 29997e42480e..1790274c27eb 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -149,8 +149,6 @@ static inline void *isa_bus_to_virt(unsigned long address)
 	return phys_to_virt(address);
 }
 
-#define isa_page_to_bus page_to_phys
-
 /*
  * However PCI ones are not necessarily 1:1 and therefore these interfaces
  * are forbidden in portable PCI drivers.

commit 1e2791448b922069b1d76cb863290c7341ff5eb5
Author: Serge Semin <fancer.lancer@gmail.com>
Date:   Fri Jun 14 09:33:42 2019 +0300

    mips: Remove q-accessors from non-64bit platforms
    
    There are some generic drivers in the kernel, which make use of the
    q-accessors or their derivatives. While at current asm/io.h the accessors
    are defined, their implementation is only applicable either for 64bit
    systems, or for systems with cpu_has_64bits flag set. Obviously there
    are MIPS systems which are neither of these, but still need to have
    those drivers supported. In this case the solution is to define some
    generic versions of the q-accessors, but with a limitation to be
    non-atomic. Such accessors are defined in the
    io-64-nonatomic-{hi-lo,lo-hi}.h file. The drivers which utilize the
    q-suffixed IO-methods are supposed to include the header file, so
    in case if these accessors aren't defined for the platform, the generic
    non-atomic versions are utilized. Currently the MIPS-specific asm/io.h
    file provides the q-accessors for any MIPS system even for ones, which
    in fact don't support them and raise BUG() in case if any of them is
    called. Due to this the generic versions of the accessors are never
    used while an attempt to call the IO-methods causes the kernel BUG().
    In order to fix this we need to define the q-accessors only for
    the MIPS systems, which actually support them, and don't define them
    otherwise, so to let the corresponding drivers to use the non-atomic
    q-suffixed accessors.
    
    Signed-off-by: Serge Semin <fancer.lancer@gmail.com>
    Suggested-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Vadim V. Vlasov <vadim.vlasov@t-platforms.ru>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Serge Semin <Sergey.Semin@t-platforms.ru>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 29997e42480e..4597017f147b 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -462,7 +462,12 @@ __BUILD_MEMORY_PFX(, bwlq, type, 0)
 BUILDIO_MEM(b, u8)
 BUILDIO_MEM(w, u16)
 BUILDIO_MEM(l, u32)
+#ifdef CONFIG_64BIT
 BUILDIO_MEM(q, u64)
+#else
+__BUILD_MEMORY_PFX(__raw_, q, u64, 0)
+__BUILD_MEMORY_PFX(__mem_, q, u64, 0)
+#endif
 
 #define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
 	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1, 0,)			\
@@ -488,12 +493,16 @@ __BUILDIO(q, u64)
 #define readb_relaxed			__relaxed_readb
 #define readw_relaxed			__relaxed_readw
 #define readl_relaxed			__relaxed_readl
+#ifdef CONFIG_64BIT
 #define readq_relaxed			__relaxed_readq
+#endif
 
 #define writeb_relaxed			__relaxed_writeb
 #define writew_relaxed			__relaxed_writew
 #define writel_relaxed			__relaxed_writel
+#ifdef CONFIG_64BIT
 #define writeq_relaxed			__relaxed_writeq
+#endif
 
 #define readb_be(addr)							\
 	__raw_readb((__force unsigned *)(addr))
@@ -516,8 +525,10 @@ __BUILDIO(q, u64)
 /*
  * Some code tests for these symbols
  */
+#ifdef CONFIG_64BIT
 #define readq				readq
 #define writeq				writeq
+#endif
 
 #define __BUILD_MEMORY_STRING(bwlq, type)				\
 									\

commit 346e91ee090b07da8d15e36bc3169ddea6968713
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Feb 22 13:37:21 2019 +0000

    mips/mmiowb: Add unconditional mmiowb() to arch_spin_unlock()
    
    The mmiowb() macro is horribly difficult to use and drivers will continue
    to work most of the time if they omit a call when it is required.
    
    Rather than rely on driver authors getting this right, push mmiowb() into
    arch_spin_unlock() for mips. If this is deemed to be a performance issue,
    a subsequent optimisation could make use of ARCH_HAS_MMIOWB to elide
    the barrier in cases where no I/O writes were performed inside the
    critical section.
    
    Acked-by: Paul Burton <paul.burton@mips.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 845fbbc7a2e3..29997e42480e 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -102,9 +102,6 @@ static inline void set_io_port_base(unsigned long base)
 #define iobarrier_w() wmb()
 #define iobarrier_sync() iob()
 
-/* Some callers use this older API instead.  */
-#define mmiowb() iobarrier_w()
-
 /*
  *     virt_to_phys    -       map virtual addresses to physical
  *     @address: address to remap

commit 378ed6f0e3c525e3b12827e7b7fb0a078ee48a32
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Nov 8 20:14:38 2018 +0000

    MIPS: Avoid using .set mips0 to restore ISA
    
    We currently have 2 commonly used methods for switching ISA within
    assembly code, then restoring the original ISA.
    
      1) Using a pair of .set push & .set pop directives. For example:
    
         .set       push
         .set       mips32r2
         <some_insn>
         .set       pop
    
      2) Using .set mips0 to restore the ISA originally specified on the
         command line. For example:
    
         .set       mips32r2
         <some_insn>
         .set       mips0
    
    Unfortunately method 2 does not work with nanoMIPS toolchains, where the
    assembler rejects the .set mips0 directive like so:
    
         Error: cannot change ISA from nanoMIPS to mips0
    
    In preparation for supporting nanoMIPS builds, switch all instances of
    method 2 in generic non-platform-specific code to use push & pop as in
    method 1 instead. The .set push & .set pop is arguably cleaner anyway,
    and if nothing else it's good to consistently use one method.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/21037/
    Cc: linux-mips@linux-mips.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index b5322f7386bf..845fbbc7a2e3 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -354,13 +354,14 @@ static inline void pfx##write##bwlq(type val,				\
 		if (irq)						\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
-			".set	arch=r4000"	"\t\t# __writeq""\n\t"	\
+			".set	push"		"\t\t# __writeq""\n\t"	\
+			".set	arch=r4000"			"\n\t"	\
 			"dsll32 %L0, %L0, 0"			"\n\t"	\
 			"dsrl32 %L0, %L0, 0"			"\n\t"	\
 			"dsll32 %M0, %M0, 0"			"\n\t"	\
 			"or	%L0, %L0, %M0"			"\n\t"	\
 			"sd	%L0, %2"			"\n\t"	\
-			".set	mips0"				"\n"	\
+			".set	pop"				"\n"	\
 			: "=r" (__tmp)					\
 			: "0" (__val), "m" (*__mem));			\
 		if (irq)						\
@@ -387,11 +388,12 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 		if (irq)						\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
-			".set	arch=r4000"	"\t\t# __readq" "\n\t"	\
+			".set	push"		"\t\t# __readq" "\n\t"	\
+			".set	arch=r4000"			"\n\t"	\
 			"ld	%L0, %1"			"\n\t"	\
 			"dsra32 %M0, %L0, 0"			"\n\t"	\
 			"sll	%L0, %L0, 0"			"\n\t"	\
-			".set	mips0"				"\n"	\
+			".set	pop"				"\n"	\
 			: "=r" (__val)					\
 			: "m" (*__mem));				\
 		if (irq)						\

commit b3a428b4b18d495a06f39515568850f8db4c98ea
Author: Hassan Naveed <hnaveed@wavecomp.com>
Date:   Mon Oct 29 18:27:41 2018 -0700

    MIPS: Enable IOREMAP_PROT config option for MIPS cpus
    
    Allows the users of ptrace to access memory mapped by the ptraced process
    using the same cache coherency attributes as the original process.
    For example while using gdb with ioremap_prot() incorporated, both gdb and
    the process being traced will have same cache coherency attributes.
    
    Signed-off-by: Hassan Naveed <hnaveed@wavecomp.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20955/
    Cc: <linux-mips@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 266257d56fb6..b5322f7386bf 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -217,6 +217,18 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 #undef __IS_LOW512
 }
 
+/*
+ * ioremap_prot     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+
+ * ioremap_prot gives the caller control over cache coherency attributes (CCA)
+ */
+static inline void __iomem *ioremap_prot(phys_addr_t offset,
+		unsigned long size, unsigned long prot_val) {
+	return __ioremap_mode(offset, size, prot_val & _CACHE_MASK);
+}
+
 /*
  * ioremap     -   map bus memory into CPU space
  * @offset:    bus address of the memory

commit 8b656253a7a4526f413f6b5ad0b03e11daa1d62d
Author: Maciej W. Rozycki <macro@linux-mips.org>
Date:   Mon Oct 8 01:37:23 2018 +0100

    MIPS: Provide actually relaxed MMIO accessors
    
    Improve performance for the relevant systems and remove the DMA ordering
    barrier from `readX_relaxed' and `writeX_relaxed' MMIO accessors, where
    it is not needed according to our requirements[1].  For consistency make
    the same arrangement with low-level port I/O accessors, but do not
    actually provide any accessors making use of it.
    
    References:
    
    [1] "LINUX KERNEL MEMORY BARRIERS", Documentation/memory-barriers.txt,
        Section "KERNEL I/O BARRIER EFFECTS"
    
    Signed-off-by: Maciej W. Rozycki <macro@linux-mips.org>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20865/
    Cc: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 9833a67eb9e6..266257d56fb6 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -46,6 +46,11 @@
 # define __raw_ioswabq(a, x)	(x)
 # define ____raw_ioswabq(a, x)	(x)
 
+# define __relaxed_ioswabb ioswabb
+# define __relaxed_ioswabw ioswabw
+# define __relaxed_ioswabl ioswabl
+# define __relaxed_ioswabq ioswabq
+
 /* ioswab[bwlq], __mem_ioswab[bwlq] are defined in mangle-port.h */
 
 #define IO_SPACE_LIMIT 0xffff
@@ -311,7 +316,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 #define war_io_reorder_wmb()		barrier()
 #endif
 
-#define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, barrier, irq)		\
+#define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, barrier, relax, irq)	\
 									\
 static inline void pfx##write##bwlq(type val,				\
 				    volatile void __iomem *mem)		\
@@ -385,11 +390,12 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 	}								\
 									\
 	/* prevent prefetching of coherent DMA data prematurely */	\
-	rmb();								\
+	if (!relax)							\
+		rmb();							\
 	return pfx##ioswab##bwlq(__mem, __val);				\
 }
 
-#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, barrier, p)		\
+#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, barrier, relax, p)	\
 									\
 static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 {									\
@@ -426,19 +432,21 @@ static inline type pfx##in##bwlq##p(unsigned long port)			\
 	__val = *__addr;						\
 									\
 	/* prevent prefetching of coherent DMA data prematurely */	\
-	rmb();								\
+	if (!relax)							\
+		rmb();							\
 	return pfx##ioswab##bwlq(__addr, __val);			\
 }
 
-#define __BUILD_MEMORY_PFX(bus, bwlq, type)				\
+#define __BUILD_MEMORY_PFX(bus, bwlq, type, relax)			\
 									\
-__BUILD_MEMORY_SINGLE(bus, bwlq, type, 1, 1)
+__BUILD_MEMORY_SINGLE(bus, bwlq, type, 1, relax, 1)
 
 #define BUILDIO_MEM(bwlq, type)						\
 									\
-__BUILD_MEMORY_PFX(__raw_, bwlq, type)					\
-__BUILD_MEMORY_PFX(, bwlq, type)					\
-__BUILD_MEMORY_PFX(__mem_, bwlq, type)					\
+__BUILD_MEMORY_PFX(__raw_, bwlq, type, 0)				\
+__BUILD_MEMORY_PFX(__relaxed_, bwlq, type, 1)				\
+__BUILD_MEMORY_PFX(__mem_, bwlq, type, 0)				\
+__BUILD_MEMORY_PFX(, bwlq, type, 0)
 
 BUILDIO_MEM(b, u8)
 BUILDIO_MEM(w, u16)
@@ -446,8 +454,8 @@ BUILDIO_MEM(l, u32)
 BUILDIO_MEM(q, u64)
 
 #define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1,)			\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1, _p)
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1, 0,)			\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1, 0, _p)
 
 #define BUILDIO_IOPORT(bwlq, type)					\
 	__BUILD_IOPORT_PFX(, bwlq, type)				\
@@ -462,19 +470,19 @@ BUILDIO_IOPORT(q, u64)
 
 #define __BUILDIO(bwlq, type)						\
 									\
-__BUILD_MEMORY_SINGLE(____raw_, bwlq, type, 1, 0)
+__BUILD_MEMORY_SINGLE(____raw_, bwlq, type, 1, 0, 0)
 
 __BUILDIO(q, u64)
 
-#define readb_relaxed			readb
-#define readw_relaxed			readw
-#define readl_relaxed			readl
-#define readq_relaxed			readq
+#define readb_relaxed			__relaxed_readb
+#define readw_relaxed			__relaxed_readw
+#define readl_relaxed			__relaxed_readl
+#define readq_relaxed			__relaxed_readq
 
-#define writeb_relaxed			writeb
-#define writew_relaxed			writew
-#define writel_relaxed			writel
-#define writeq_relaxed			writeq
+#define writeb_relaxed			__relaxed_writeb
+#define writew_relaxed			__relaxed_writew
+#define writel_relaxed			__relaxed_writel
+#define writeq_relaxed			__relaxed_writeq
 
 #define readb_be(addr)							\
 	__raw_readb((__force unsigned *)(addr))

commit 3d474dacae72ac0f28228b328cfa953b05484b7f
Author: Maciej W. Rozycki <macro@linux-mips.org>
Date:   Mon Oct 8 01:37:16 2018 +0100

    MIPS: Enforce strong ordering for MMIO accessors
    
    Architecturally the MIPS ISA does not specify ordering requirements for
    uncached bus accesses such as MMIO operations normally use and therefore
    explicit barriers have to be inserted between MMIO accesses where
    unspecified ordering of operations would cause unpredictable results.
    
    For example the R2020 write buffer implements write gathering and
    combining[1] and as used with the DECstation models 2100 and 3100 for
    MMIO accesses it bypasses the read buffer entirely, because conflicts
    are resolved by the memory controller for DRAM accesses only[2] (NB the
    R2020 and R3020 buffers are the same except for the maximum clock rate).
    
    Consequently if a device has say a 16-bit control register at offset 0,
    a 16-bit event mask register at offset 2 and a 16-bit reset register at
    offset 4, and the initial value of the control register is 0x1111, then
    in the absence of barriers a hypothetical code sequence like this:
    
    u16 init_dev(u16 __iomem *dev);
            u16 x;
    
            write16(dev + 2, 0xffff);
            write16(dev + 0, 0x2222);
            x = read16(dev + 0);
            write16(dev + 1, 0x3333);
            write16(dev + 0, 0x4444);
    
            return x;
    }
    
    will return 0x1111 and issue a single 32-bit write of 0x33334444 (in the
    little-endian bus configuration) to offset 0 on the system bus.
    
    This is because the read to set `x' from offset 0 bypasses the write of
    0x2222 that is still in the write buffer pending the completion of the
    write of 0xffff to the reset register.  Then the write of 0x3333 to the
    event mask register is merged with the preceding write to the control
    register as they share the same word address, making it a 32-bit write
    of 0x33332222 to offset 0.  Finally the write of 0x4444 to the control
    register is combined with the outstanding 32-bit write of 0x33332222 to
    offset 0, because, again, it shares the same address.
    
    This is an example from a legacy system, given here because it is well
    documented and affects a machine we actually support.  But likewise
    modern MIPS systems may implement weak MMIO ordering, possibly even
    without having it clearly documented except for being compliant with the
    architecture specification with respect to the currently defined SYNC
    instruction variants[3].
    
    Considering the above and that we are required to implement MMIO
    accessors such that individual accesses made with them are strongly
    ordered with respect to each other[4], add the necessary barriers to our
    `inX', `outX', `readX' and `writeX' handlers, as well the associated
    special use variants.  It's up to platforms then to possibly define the
    respective barriers so as to expand to nil if no ordering enforcement is
    actually needed for a given system; SYNC is supposed to be as cheap as
    a NOP on strongly ordered MIPS implementations though.
    
    Retain the option to generate weakly-ordered accessors, so that the
    arrangement for `war_io_reorder_wmb' is not lost in case we need it for
    fully raw accessors in the future.  The reason for this is that it is
    unclear from commit 1e820da3c9af ("MIPS: Loongson-3: Introduce
    CONFIG_LOONGSON3_ENHANCEMENT") and especially commit 8faca49a6731
    ("MIPS: Modify core io.h macros to account for the Octeon Errata
    Core-301.") why they are needed there under the previous assumption that
    these accessors can be weakly ordered.
    
    References:
    
    [1] "LR3020 Write Buffer", LSI Logic Corporation, September 1988,
        Section "Byte Gathering", pp. 6-7
    
    [2] "DECstation 3100 Desktop Workstation Functional Specification",
        Digital Equipment Corporation, Revision 1.3, August 28, 1990,
        Section 6.1 "Processor", p. 4
    
    [3] "MIPS Architecture For Programmers, Volume II-A: The MIPS32
        Instruction Set Manual", Imagination Technologies LTD, Document
        Number: MD00086, Revision 6.06, December 15, 2016, Table 5.5
        "Encodings of the Bits[10:6] of the SYNC instruction; the SType
        Field", p. 409
    
    [4] "LINUX KERNEL MEMORY BARRIERS", Documentation/memory-barriers.txt,
        Section "KERNEL I/O BARRIER EFFECTS"
    
    Signed-off-by: Maciej W. Rozycki <macro@linux-mips.org>
    References: 8faca49a6731 ("MIPS: Modify core io.h macros to account for the Octeon Errata Core-301.")
    References: 1e820da3c9af ("MIPS: Loongson-3: Introduce CONFIG_LOONGSON3_ENHANCEMENT")
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20864/
    Cc: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 65d2a4d481fc..9833a67eb9e6 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -311,7 +311,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 #define war_io_reorder_wmb()		barrier()
 #endif
 
-#define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\
+#define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, barrier, irq)		\
 									\
 static inline void pfx##write##bwlq(type val,				\
 				    volatile void __iomem *mem)		\
@@ -319,7 +319,10 @@ static inline void pfx##write##bwlq(type val,				\
 	volatile type *__mem;						\
 	type __val;							\
 									\
-	war_io_reorder_wmb();					\
+	if (barrier)							\
+		iobarrier_rw();						\
+	else								\
+		war_io_reorder_wmb();					\
 									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
@@ -356,6 +359,9 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
+	if (barrier)							\
+		iobarrier_rw();						\
+									\
 	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long)) \
 		__val = *__mem;						\
 	else if (cpu_has_64bits) {					\
@@ -383,14 +389,17 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 	return pfx##ioswab##bwlq(__mem, __val);				\
 }
 
-#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, p)			\
+#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, barrier, p)		\
 									\
 static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 {									\
 	volatile type *__addr;						\
 	type __val;							\
 									\
-	war_io_reorder_wmb();					\
+	if (barrier)							\
+		iobarrier_rw();						\
+	else								\
+		war_io_reorder_wmb();					\
 									\
 	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
 									\
@@ -411,6 +420,9 @@ static inline type pfx##in##bwlq##p(unsigned long port)			\
 									\
 	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
 									\
+	if (barrier)							\
+		iobarrier_rw();						\
+									\
 	__val = *__addr;						\
 									\
 	/* prevent prefetching of coherent DMA data prematurely */	\
@@ -420,7 +432,7 @@ static inline type pfx##in##bwlq##p(unsigned long port)			\
 
 #define __BUILD_MEMORY_PFX(bus, bwlq, type)				\
 									\
-__BUILD_MEMORY_SINGLE(bus, bwlq, type, 1)
+__BUILD_MEMORY_SINGLE(bus, bwlq, type, 1, 1)
 
 #define BUILDIO_MEM(bwlq, type)						\
 									\
@@ -434,8 +446,8 @@ BUILDIO_MEM(l, u32)
 BUILDIO_MEM(q, u64)
 
 #define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type,)				\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type, _p)
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1,)			\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, 1, _p)
 
 #define BUILDIO_IOPORT(bwlq, type)					\
 	__BUILD_IOPORT_PFX(, bwlq, type)				\
@@ -450,7 +462,7 @@ BUILDIO_IOPORT(q, u64)
 
 #define __BUILDIO(bwlq, type)						\
 									\
-__BUILD_MEMORY_SINGLE(____raw_, bwlq, type, 0)
+__BUILD_MEMORY_SINGLE(____raw_, bwlq, type, 1, 0)
 
 __BUILDIO(q, u64)
 

commit a711d43cbbaa4800a15885c1044348982b6c0c4b
Author: Maciej W. Rozycki <macro@linux-mips.org>
Date:   Mon Oct 8 01:37:07 2018 +0100

    MIPS: Correct `mmiowb' barrier for `wbflush' platforms
    
    Redefine `mmiowb' in terms of `iobarrier_w' so that it works correctly
    for MIPS I platforms, which have no SYNC machine instruction and use a
    call to `wbflush' instead.
    
    This doesn't change the semantics for CONFIG_CPU_CAVIUM_OCTEON, because
    `iobarrier_w' expands to `wmb', which is ultimately the same as the
    current arrangement.  For MIPS I platforms this not only makes any code
    that would happen to use `mmiowb' build and run, but it actually
    enforces the ordering required as well, as `iobarrier_w' has it already
    covered with the use of `wmb'.
    
    Signed-off-by: Maciej W. Rozycki <macro@linux-mips.org>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20863/
    Cc: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 312eeed7c5bd..65d2a4d481fc 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -97,6 +97,9 @@ static inline void set_io_port_base(unsigned long base)
 #define iobarrier_w() wmb()
 #define iobarrier_sync() iob()
 
+/* Some callers use this older API instead.  */
+#define mmiowb() iobarrier_w()
+
 /*
  *     virt_to_phys    -       map virtual addresses to physical
  *     @address: address to remap
@@ -545,14 +548,6 @@ BUILDSTRING(l, u32)
 BUILDSTRING(q, u64)
 #endif
 
-
-#ifdef CONFIG_CPU_CAVIUM_OCTEON
-#define mmiowb() wmb()
-#else
-/* Depends on MIPS II instruction set */
-#define mmiowb() asm volatile ("sync" ::: "memory")
-#endif
-
 static inline void memset_io(volatile void __iomem *addr, unsigned char val, int count)
 {
 	memset((void __force *) addr, val, count);

commit 4ae0452bddca8b59e9258759123a652161d07871
Author: Maciej W. Rozycki <macro@linux-mips.org>
Date:   Mon Oct 8 01:37:01 2018 +0100

    MIPS: Define MMIO ordering barriers
    
    Define MMIO ordering barriers as separate operations so as to allow
    making places where such a barrier is required distinct from places
    where a memory or a DMA barrier is needed.
    
    Architecturally MIPS does not specify ordering requirements for uncached
    bus accesses such as MMIO operations normally use and therefore explicit
    barriers have to be inserted between MMIO accesses where unspecified
    ordering of operations would cause unpredictable results.
    
    MIPS MMIO ordering barriers are implemented using the same underlying
    mechanism that memory or a DMA barrier ordering barriers use, that is
    either a suitable SYNC instruction or a platform-specific `wbflush'
    call.  However platforms may implement different ordering rules for
    different kinds of bus activity, so having a separate API makes it
    possible to remove unnecessary barriers and avoid a performance hit they
    may cause due to unrelated bus activity by making their implementation
    expand to nil while keeping the necessary ones.
    
    Also having distinct barriers for each kind of use makes it easier for
    the reader to understand what code has been intended to do.
    
    Signed-off-by: Maciej W. Rozycki <macro@linux-mips.org>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20862/
    Cc: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index eb357c92c8ee..312eeed7c5bd 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -20,6 +20,7 @@
 #include <linux/irqflags.h>
 
 #include <asm/addrspace.h>
+#include <asm/barrier.h>
 #include <asm/bug.h>
 #include <asm/byteorder.h>
 #include <asm/cpu.h>
@@ -79,11 +80,23 @@ static inline void set_io_port_base(unsigned long base)
  * mips_io_port_base for iomap(), but we don't reserve any low addresses for
  * use with I/O ports.
  */
+
 #define HAVE_ARCH_PIO_SIZE
 #define PIO_OFFSET	mips_io_port_base
 #define PIO_MASK	IO_SPACE_LIMIT
 #define PIO_RESERVED	0x0UL
 
+/*
+ * Enforce in-order execution of data I/O.  In the MIPS architecture
+ * these are equivalent to corresponding platform-specific memory
+ * barriers defined in <asm/barrier.h>.  API pinched from PowerPC,
+ * with sync additionally defined.
+ */
+#define iobarrier_rw() mb()
+#define iobarrier_r() rmb()
+#define iobarrier_w() wmb()
+#define iobarrier_sync() iob()
+
 /*
  *     virt_to_phys    -       map virtual addresses to physical
  *     @address: address to remap

commit c824ad164760484f709daa1339df40a184f4170a
Author: Huacai Chen <chenhc@lemote.com>
Date:   Wed Sep 5 17:33:01 2018 +0800

    MIPS: Loongson-3: Enable Store Fill Buffer at runtime
    
    New Loongson-3 (Loongson-3A R2, Loongson-3A R3, and newer) has SFB
    (Store Fill Buffer) which can improve the performance of memory access.
    Now, SFB enablement is controlled by CONFIG_LOONGSON3_ENHANCEMENT, and
    the generic kernel has no benefit from SFB (even it is running on a new
    Loongson-3 machine). With this patch, we can enable SFB at runtime by
    detecting the CPU type (the expense is war_io_reorder_wmb() will always
    be a 'sync', which will hurt the performance of old Loongson-3).
    
    [paul.burton@mips.com: Further info from Huacai:
      In practise, I found that sometimes there are boot failures if I
      enable SFB/LPA in cpu_probe(). I don't know why because processor
      designers also haven't give me an explaination, but I think this may
      have some relationships to speculative execution.]
    
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20426/
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: Fuxin Zhang <zhangfx@lemote.com>
    Cc: Zhangjin Wu <wuzhangjin@gmail.com>
    Cc: Huacai Chen <chenhuacai@gmail.com>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 44f766b6b5af..eb357c92c8ee 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -289,7 +289,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 #undef __IS_KSEG1
 }
 
-#if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_LOONGSON3_ENHANCEMENT)
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_CPU_LOONGSON3)
 #define war_io_reorder_wmb()		wmb()
 #else
 #define war_io_reorder_wmb()		barrier()

commit e966d3084596c62f152bf1dd8028d94792c9c380
Author: Paul Burton <paul.burton@mips.com>
Date:   Wed Aug 29 14:54:01 2018 -0700

    MIPS: Remove SLOW_DOWN_IO
    
    arch/mips appears to have inherited SLOW_DOWN_IO from arch/x86 in
    antiquity, but we never define CONF_SLOWDOWN_IO so this is unused code.
    
    Perhaps it was once useful to keep the MIPS header close to the x86
    version to ease comparisons or porting changes, but they've diverged
    significantly at this point & x86 does this differently now anyway.
    
    Delete the dead code.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20343/
    Cc: linux-mips@linux-mips.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index bbbeede9fea1..44f766b6b5af 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -33,11 +33,6 @@
 #include <ioremap.h>
 #include <mangle-port.h>
 
-/*
- * Slowdown I/O port space accesses for antique hardware.
- */
-#undef CONF_SLOWDOWN_IO
-
 /*
  * Raw operations are never swapped in software.  OTOH values that raw
  * operations are working on may or may not have been swapped by the bus
@@ -89,33 +84,6 @@ static inline void set_io_port_base(unsigned long base)
 #define PIO_MASK	IO_SPACE_LIMIT
 #define PIO_RESERVED	0x0UL
 
-/*
- * Thanks to James van Artsdalen for a better timing-fix than
- * the two short jumps: using outb's to a nonexistent port seems
- * to guarantee better timings even on fast machines.
- *
- * On the other hand, I'd like to be sure of a non-existent port:
- * I feel a bit unsafe about using 0x80 (should be safe, though)
- *
- *		Linus
- *
- */
-
-#define __SLOW_DOWN_IO \
-	__asm__ __volatile__( \
-		"sb\t$0,0x80(%0)" \
-		: : "r" (mips_io_port_base));
-
-#ifdef CONF_SLOWDOWN_IO
-#ifdef REALLY_SLOW_IO
-#define SLOW_DOWN_IO { __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; }
-#else
-#define SLOW_DOWN_IO __SLOW_DOWN_IO
-#endif
-#else
-#define SLOW_DOWN_IO
-#endif
-
 /*
  *     virt_to_phys    -       map virtual addresses to physical
  *     @address: address to remap
@@ -399,7 +367,7 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 	return pfx##ioswab##bwlq(__mem, __val);				\
 }
 
-#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, p, slow)			\
+#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, p)			\
 									\
 static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 {									\
@@ -416,7 +384,6 @@ static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
 									\
 	*__addr = __val;						\
-	slow;								\
 }									\
 									\
 static inline type pfx##in##bwlq##p(unsigned long port)			\
@@ -429,7 +396,6 @@ static inline type pfx##in##bwlq##p(unsigned long port)			\
 	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
 									\
 	__val = *__addr;						\
-	slow;								\
 									\
 	/* prevent prefetching of coherent DMA data prematurely */	\
 	rmb();								\
@@ -452,8 +418,8 @@ BUILDIO_MEM(l, u32)
 BUILDIO_MEM(q, u64)
 
 #define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type, ,)			\
-	__BUILD_IOPORT_SINGLE(bus, bwlq, type, _p, SLOW_DOWN_IO)
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type,)				\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, _p)
 
 #define BUILDIO_IOPORT(bwlq, type)					\
 	__BUILD_IOPORT_PFX(, bwlq, type)				\

commit b962aeb022051915c26dcaba97d3ed0883bef9f5
Author: Paul Burton <paul.burton@mips.com>
Date:   Wed Aug 29 14:54:00 2018 -0700

    MIPS: Use GENERIC_IOMAP
    
    MIPS has a copy of lib/iomap.c with minor alterations, none of which are
    necessary given appropriate definitions of PIO_OFFSET, PIO_MASK &
    PIO_RESERVED. Provide such definitions, select GENERIC_IOMAP & remove
    arch/mips/lib/iomap.c to cut back on the needless duplication.
    
    The one change this does make is to our mmio_{in,out}s[bwl] functions,
    which began to deviate from their generic counterparts with commit
    0845bb721ebb ("MIPS: iomap: Use __mem_{read,write}{b,w,l} for MMIO"). I
    suspect that this commit was incorrect, and that the SEAD-3 platform
    should have instead selected CONFIG_SWAP_IO_SPACE. Since the SEAD-3
    platform code is now gone & the board is instead supported by the
    generic platform (CONFIG_MIPS_GENERIC) which selects
    CONFIG_SWAP_IO_SPACE anyway, this shouldn't be a problem any more.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20342/
    Cc: linux-mips@linux-mips.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 54c730aed327..bbbeede9fea1 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -79,6 +79,16 @@ static inline void set_io_port_base(unsigned long base)
 	barrier();
 }
 
+/*
+ * Provide the necessary definitions for generic iomap. We make use of
+ * mips_io_port_base for iomap(), but we don't reserve any low addresses for
+ * use with I/O ports.
+ */
+#define HAVE_ARCH_PIO_SIZE
+#define PIO_OFFSET	mips_io_port_base
+#define PIO_MASK	IO_SPACE_LIMIT
+#define PIO_RESERVED	0x0UL
+
 /*
  * Thanks to James van Artsdalen for a better timing-fix than
  * the two short jumps: using outb's to a nonexistent port seems
@@ -172,11 +182,6 @@ static inline void *isa_bus_to_virt(unsigned long address)
 extern void __iomem * __ioremap(phys_addr_t offset, phys_addr_t size, unsigned long flags);
 extern void __iounmap(const volatile void __iomem *addr);
 
-#ifndef CONFIG_PCI
-struct pci_dev;
-static inline void pci_iounmap(struct pci_dev *dev, void __iomem *addr) {}
-#endif
-
 static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long size,
 	unsigned long flags)
 {

commit 0494d7ffdcebc6935410ea0719b24ab626675351
Author: Paul Burton <paul.burton@mips.com>
Date:   Fri Jul 27 18:23:19 2018 -0700

    MIPS: Fix ISA virt/bus conversion for non-zero PHYS_OFFSET
    
    isa_virt_to_bus() & isa_bus_to_virt() claim to treat ISA bus addresses
    as being identical to physical addresses, but they fail to do so in the
    presence of a non-zero PHYS_OFFSET.
    
    Correct this by having them use virt_to_phys() & phys_to_virt(), which
    consolidates the calculations to one place & ensures that ISA bus
    addresses do indeed match physical addresses.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/20047/
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: Vladimir Kondratiev <vladimir.kondratiev@intel.com>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index cd170d920d55..54c730aed327 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -143,14 +143,14 @@ static inline void * phys_to_virt(unsigned long address)
 /*
  * ISA I/O bus memory addresses are 1:1 with the physical address.
  */
-static inline unsigned long isa_virt_to_bus(volatile void * address)
+static inline unsigned long isa_virt_to_bus(volatile void *address)
 {
-	return (unsigned long)address - PAGE_OFFSET;
+	return virt_to_phys(address);
 }
 
-static inline void * isa_bus_to_virt(unsigned long address)
+static inline void *isa_bus_to_virt(unsigned long address)
 {
-	return (void *)(address + PAGE_OFFSET);
+	return phys_to_virt(address);
 }
 
 #define isa_page_to_bus page_to_phys

commit 788654285da76dc853ebd25a5ecb4043de22d0e5
Author: Serge Semin <fancer.lancer@gmail.com>
Date:   Fri Jul 20 23:14:27 2018 +0300

    mips: mm: Discard ioremap_cacheable_cow() method
    
    This macro substitution is the shortcut to map cacheable IO memory
    with coherent and write-back attributes. Since it is entirely unused
    by kernel, lets just remove it.
    
    Signed-off-by: Serge Semin <fancer.lancer@gmail.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Patchwork: https://patchwork.linux-mips.org/patch/19937/
    CC: Paul Burton <paul.burton@mips.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Sinan Kaya <okaya@codeaurora.org>
    Cc: Huacai Chen <chenhc@lemote.com>
    Cc: Sergey.Semin@t-platforms.ru
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index f613d1df66c0..cd170d920d55 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -300,13 +300,6 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 #define ioremap_wc(offset, size)					\
 	__ioremap_mode((offset), (size), boot_cpu_data.writecombine)
 
-/*
- * This is a MIPS specific ioremap variant. ioremap_cacheable_cow
- * requests a cachable mapping with CWB attribute enabled.
- */
-#define ioremap_cacheable_cow(offset, size)				\
-	__ioremap_mode((offset), (size), _CACHE_CACHABLE_COW)
-
 static inline void iounmap(const volatile void __iomem *addr)
 {
 	if (plat_iounmap(addr))

commit ddba595b7b24ac17d553814d9d525fe4472c89e6
Author: Serge Semin <fancer.lancer@gmail.com>
Date:   Mon Jul 9 16:57:13 2018 +0300

    mips: mm: Discard ioremap_uncached_accelerated() method
    
    Adaptive ioremap_wc() method is now available as of commit 9748e33e26c6
    ("mips: mm: Create UCA-based ioremap_wc() method"). We can use it to
    obtain UnCached Accelerated (UCA) mappings safely on all MIPS systems,
    and so we don't need the MIPS-specific ioremap_uncached_accelerated()
    any longer. This macro hard-coded the UCA Cache Coherency Attribute
    (CCA) in a manner that isn't safe for kernels that may run on different
    CPUs, and it is also entirely unused so we can trivially remove it.
    
    [paul.burton@mips.com:
      - Reword the commit message a little.
      - Remove CC stable.]
    
    Signed-off-by: Serge Semin <fancer.lancer@gmail.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/19790/
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: okaya@codeaurora.org
    Cc: chenhc@lemote.com
    Cc: Sergey.Semin@t-platforms.ru
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 01e1f62d9d12..f613d1df66c0 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -301,15 +301,11 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 	__ioremap_mode((offset), (size), boot_cpu_data.writecombine)
 
 /*
- * These two are MIPS specific ioremap variant.	 ioremap_cacheable_cow
- * requests a cachable mapping, ioremap_uncached_accelerated requests a
- * mapping using the uncached accelerated mode which isn't supported on
- * all processors.
+ * This is a MIPS specific ioremap variant. ioremap_cacheable_cow
+ * requests a cachable mapping with CWB attribute enabled.
  */
 #define ioremap_cacheable_cow(offset, size)				\
 	__ioremap_mode((offset), (size), _CACHE_CACHABLE_COW)
-#define ioremap_uncached_accelerated(offset, size)			\
-	__ioremap_mode((offset), (size), _CACHE_UNCACHED_ACCELERATED)
 
 static inline void iounmap(const volatile void __iomem *addr)
 {

commit 9748e33e26c65d84a0fb09df93c963d023f90a3f
Author: Serge Semin <fancer.lancer@gmail.com>
Date:   Mon Jul 9 16:57:12 2018 +0300

    mips: mm: Create UCA-based ioremap_wc() method
    
    Modern MIPS cores (like P5600/6600, M5150/6520, end so on) which
    got L2-cache on chip also can enable a special type Cache-Coherency
    attribute (CCA) named UnCached Accelerated attribute (UCA). In this
    way uncached accelerated accesses are treated the same way as
    non-accelerated uncached accesses, but uncached stores are gathered
    together for more efficient bus utilization. So to speak this CCA
    enables uncached transactions to better utilize bus bandwidth via
    burst transactions.
    
    This is exactly why ioremap_wc() method has been introduced in Linux.
    Alas MIPS-platform code hasn't implemented it so far, instead default
    one has been used which was an alias to ioremap_nocache. In order to
    fix this we added MIPS-specific ioremap_wc() macro substituted by
    generic __ioremap_mode() method call with writecombine CPU-info
    field passed. It shall create real ioremap_wc() method if CPU-cache
    supports UCA feature and fall-back to _CACHE_UNCACHED attribute
    if one doesn't. Additionally platform-specific io.h shall declare
    ARCH_HAS_IOREMAP_WC macro as indication of architectural definition
    of ioremap_wc() (similar to x86/powerpc).
    
    [paul.burton@mips.com:
      - Remove CC stable, this is new functionality.]
    
    Signed-off-by: Serge Semin <fancer.lancer@gmail.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/19789/
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: okaya@codeaurora.org
    Cc: chenhc@lemote.com
    Cc: Sergey.Semin@t-platforms.ru
    Cc: linux-kernel@vger.kernel.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index a363d5fa281f..01e1f62d9d12 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -12,6 +12,8 @@
 #ifndef _ASM_IO_H
 #define _ASM_IO_H
 
+#define ARCH_HAS_IOREMAP_WC
+
 #include <linux/compiler.h>
 #include <linux/kernel.h>
 #include <linux/types.h>
@@ -277,6 +279,27 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
 	__ioremap_mode((offset), (size), _page_cachable_default)
 #define ioremap_cache ioremap_cachable
 
+/*
+ * ioremap_wc     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+ *
+ * ioremap_wc performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ *
+ * This version of ioremap ensures that the memory is marked uncachable
+ * but accelerated by means of write-combining feature. It is specifically
+ * useful for PCIe prefetchable windows, which may vastly improve a
+ * communications performance. If it was determined on boot stage, what
+ * CPU CCA doesn't support UCA, the method shall fall-back to the
+ * _CACHE_UNCACHED option (see cpu_probe() method).
+ */
+#define ioremap_wc(offset, size)					\
+	__ioremap_mode((offset), (size), boot_cpu_data.writecombine)
+
 /*
  * These two are MIPS specific ioremap variant.	 ioremap_cacheable_cow
  * requests a cachable mapping, ioremap_uncached_accelerated requests a

commit 972dc3b79f421b5ae553b1073708cbd0d4da4a91
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 15 13:08:31 2018 +0200

    MIPS: simplify CONFIG_DMA_NONCOHERENT ifdefs
    
    CONFIG_DMA_MAYBE_COHERENT already selects CONFIG_DMA_NONCOHERENT, so we
    can remove the extra conditions.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Paul Burton <paul.burton@mips.com>
    Patchwork: https://patchwork.linux-mips.org/patch/19529/
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: Florian Fainelli <f.fainelli@gmail.com>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Kevin Cernekee <cernekee@gmail.com>
    Cc: Jiaxun Yang <jiaxun.yang@flygoat.com>
    Cc: Tom Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Huacai Chen <chenhc@lemote.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: linux-mips@linux-mips.org

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index cea8ad864b3f..a363d5fa281f 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -590,7 +590,7 @@ static inline void memcpy_toio(volatile void __iomem *dst, const void *src, int
  *
  * This API used to be exported; it now is for arch code internal use only.
  */
-#if defined(CONFIG_DMA_NONCOHERENT) || defined(CONFIG_DMA_MAYBE_COHERENT)
+#ifdef CONFIG_DMA_NONCOHERENT
 
 extern void (*_dma_cache_wback_inv)(unsigned long start, unsigned long size);
 extern void (*_dma_cache_wback)(unsigned long start, unsigned long size);
@@ -609,7 +609,7 @@ extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
 #define dma_cache_inv(start,size)	\
 	do { (void) (start); (void) (size); } while (0)
 
-#endif /* CONFIG_DMA_NONCOHERENT || CONFIG_DMA_MAYBE_COHERENT */
+#endif /* CONFIG_DMA_NONCOHERENT */
 
 /*
  * Read a 32-bit register that requires a 64-bit read cycle on the bus.

commit 18f3e95b90b28318ef35910d21c39908de672331
Author: Huacai Chen <chenhc@lemote.com>
Date:   Tue Jun 12 17:54:42 2018 +0800

    MIPS: io: Add barrier after register read in inX()
    
    While a barrier is present in the outX() functions before the register
    write, a similar barrier is missing in the inX() functions after the
    register read. This could allow memory accesses following inX() to
    observe stale data.
    
    This patch is very similar to commit a1cc7034e33d12dc1 ("MIPS: io: Add
    barrier after register read in readX()"). Because war_io_reorder_wmb()
    is both used by writeX() and outX(), if readX() need a barrier then so
    does inX().
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Patchwork: https://patchwork.linux-mips.org/patch/19516/
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: James Hogan <james.hogan@mips.com>
    Cc: linux-mips@linux-mips.org
    Cc: Fuxin Zhang <zhangfx@lemote.com>
    Cc: Zhangjin Wu <wuzhangjin@gmail.com>
    Cc: Huacai Chen <chenhuacai@gmail.com>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index a7d0b836f2f7..cea8ad864b3f 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -414,6 +414,8 @@ static inline type pfx##in##bwlq##p(unsigned long port)			\
 	__val = *__addr;						\
 	slow;								\
 									\
+	/* prevent prefetching of coherent DMA data prematurely */	\
+	rmb();								\
 	return pfx##ioswab##bwlq(__addr, __val);			\
 }
 

commit a1cc7034e33d12dc17d13fbcd7d597d552889097
Author: Sinan Kaya <okaya@codeaurora.org>
Date:   Thu Apr 12 22:30:44 2018 -0400

    MIPS: io: Add barrier after register read in readX()
    
    While a barrier is present in the writeX() functions before the register
    write, a similar barrier is missing in the readX() functions after the
    register read. This could allow memory accesses following readX() to
    observe stale data.
    
    Signed-off-by: Sinan Kaya <okaya@codeaurora.org>
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/19069/
    [jhogan@kernel.org: Tidy commit message]
    Signed-off-by: James Hogan <jhogan@kernel.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index fd00ddafb425..a7d0b836f2f7 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -377,6 +377,8 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 		BUG();							\
 	}								\
 									\
+	/* prevent prefetching of coherent DMA data prematurely */	\
+	rmb();								\
 	return pfx##ioswab##bwlq(__mem, __val);				\
 }
 

commit f6b7aeee8f167409195fbf1364d02988fecad1d0
Author: Sinan Kaya <okaya@codeaurora.org>
Date:   Tue Apr 3 08:55:03 2018 -0400

    MIPS: io: Prevent compiler reordering writeX()
    
    writeX() has strong ordering semantics with respect to memory updates.
    In the absence of a write barrier or a compiler barrier, the compiler
    can reorder register and memory update instructions. This breaks the
    writeX() API.
    
    Signed-off-by: Sinan Kaya <okaya@codeaurora.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/18997/
    [jhogan@kernel.org: Tidy commit message]
    Signed-off-by: James Hogan <jhogan@kernel.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 0cbf3af37eca..fd00ddafb425 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -307,7 +307,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 #if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_LOONGSON3_ENHANCEMENT)
 #define war_io_reorder_wmb()		wmb()
 #else
-#define war_io_reorder_wmb()		do { } while (0)
+#define war_io_reorder_wmb()		barrier()
 #endif
 
 #define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\

commit d8c825e2a05390efa4a5750c5c17e168139c1d48
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Sat Aug 12 21:36:15 2017 -0700

    MIPS: Add __ioread64_copy
    
    We currently have __ioread32_copy, __iowrite32_copy & __iowrite64_copy
    helpers in lib/iomap_copy.c. This patch adds __ioread64_copy to round
    out the set, allowing copies from I/O memory using 32 or 64 bit reads.
    
    [ralf@linux-mips.org: Changed to move all the code of this patch to be
    applied to arch/mips temporarily.]
    
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/17025/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index ecabc00c1e66..0cbf3af37eca 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -632,4 +632,6 @@ extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
  */
 #define xlate_dev_kmem_ptr(p)	p
 
+void __ioread64_copy(void *to, const void __iomem *from, size_t count);
+
 #endif /* _ASM_IO_H */

commit 1e820da3c9af4f5771d2ad47099919429b906ac6
Author: Huacai Chen <chenhc@lemote.com>
Date:   Thu Mar 3 09:45:13 2016 +0800

    MIPS: Loongson-3: Introduce CONFIG_LOONGSON3_ENHANCEMENT
    
    New Loongson 3 CPU (since Loongson-3A R2, as opposed to Loongson-3A R1,
    Loongson-3B R1 and Loongson-3B R2) has many enhancements, such as FTLB,
    L1-VCache, EI/DI/Wait/Prefetch instruction, DSP/DSPv2 ASE, User Local
    register, Read-Inhibit/Execute-Inhibit, SFB (Store Fill Buffer), Fast
    TLB refill support, etc.
    
    This patch introduce a config option, CONFIG_LOONGSON3_ENHANCEMENT, to
    enable those enhancements which are not probed at run time. If you want
    a generic kernel to run on all Loongson 3 machines, please say 'N'
    here. If you want a high-performance kernel to run on new Loongson 3
    machines only, please say 'Y' here.
    
    Some additional explanations:
    1) SFB locates between core and L1 cache, it causes memory access out
       of order, so writel/outl (and other similar functions) need a I/O
       reorder barrier.
    2) Loongson 3 has a bug that di instruction can not save the irqflag,
       so arch_local_irq_save() is modified. Since CPU_MIPSR2 is selected
       by CONFIG_LOONGSON3_ENHANCEMENT, generic kernel doesn't use ei/di
       at all.
    3) CPU_HAS_PREFETCH is selected by CONFIG_LOONGSON3_ENHANCEMENT, so
       MIPS_CPU_PREFETCH (used by uasm) probing is also put in this patch.
    
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Cc: Aurelien Jarno <aurelien@aurel32.net>
    Cc: Steven J . Hill <sjhill@realitydiluted.com>
    Cc: Fuxin Zhang <zhangfx@lemote.com>
    Cc: Zhangjin Wu <wuzhangjin@gmail.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/12755/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 2b4dc7ad53b8..ecabc00c1e66 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -304,10 +304,10 @@ static inline void iounmap(const volatile void __iomem *addr)
 #undef __IS_KSEG1
 }
 
-#ifdef CONFIG_CPU_CAVIUM_OCTEON
-#define war_octeon_io_reorder_wmb()		wmb()
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) || defined(CONFIG_LOONGSON3_ENHANCEMENT)
+#define war_io_reorder_wmb()		wmb()
 #else
-#define war_octeon_io_reorder_wmb()		do { } while (0)
+#define war_io_reorder_wmb()		do { } while (0)
 #endif
 
 #define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\
@@ -318,7 +318,7 @@ static inline void pfx##write##bwlq(type val,				\
 	volatile type *__mem;						\
 	type __val;							\
 									\
-	war_octeon_io_reorder_wmb();					\
+	war_io_reorder_wmb();					\
 									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
@@ -387,7 +387,7 @@ static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 	volatile type *__addr;						\
 	type __val;							\
 									\
-	war_octeon_io_reorder_wmb();					\
+	war_io_reorder_wmb();					\
 									\
 	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
 									\

commit a68f376844605399cbd28b662d5ed213639f46f7
Author: Maciej W. Rozycki <macro@imgtec.com>
Date:   Sat Jan 9 02:05:31 2016 +0000

    MIPS: io.h: Define `ioremap_cache'
    
    Signed-off-by: Maciej W. Rozycki <macro@imgtec.com>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: Rafa Miecki <zajec5@gmail.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/12040/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index d10fd80dbb7e..2b4dc7ad53b8 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -275,6 +275,7 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
  */
 #define ioremap_cachable(offset, size)					\
 	__ioremap_mode((offset), (size), _page_cachable_default)
+#define ioremap_cache ioremap_cachable
 
 /*
  * These two are MIPS specific ioremap variant.	 ioremap_cacheable_cow

commit da11f98fd018319f65af9c10174ccc829207d937
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Tue Oct 6 00:56:56 2015 +0100

    MIPS: Define ioremap_uc
    
    All architectures must now define ioremap_uc(), but MIPS currently
    only has ioremap_nocache().
    
    Fixes: 4c73e8926623 ("arch/*/io.h: Add ioremap_uc() to all architectures")
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Cc: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/11263/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 9e777cd42b67..d10fd80dbb7e 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -256,6 +256,7 @@ static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long si
  */
 #define ioremap_nocache(offset, size)					\
 	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
+#define ioremap_uc ioremap_nocache
 
 /*
  * ioremap_cachable -	map bus memory into CPU space

commit 15d45cce3a0e0716fa49c768f887c6406dfb91f7
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Sat Nov 22 00:22:09 2014 +0100

    MIPS: Replace use of phys_t with phys_addr_t.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 933b50e125a0..9e777cd42b67 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -167,7 +167,7 @@ static inline void * isa_bus_to_virt(unsigned long address)
  */
 #define page_to_phys(page)	((dma_addr_t)page_to_pfn(page) << PAGE_SHIFT)
 
-extern void __iomem * __ioremap(phys_t offset, phys_t size, unsigned long flags);
+extern void __iomem * __ioremap(phys_addr_t offset, phys_addr_t size, unsigned long flags);
 extern void __iounmap(const volatile void __iomem *addr);
 
 #ifndef CONFIG_PCI
@@ -175,7 +175,7 @@ struct pci_dev;
 static inline void pci_iounmap(struct pci_dev *dev, void __iomem *addr) {}
 #endif
 
-static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
+static inline void __iomem * __ioremap_mode(phys_addr_t offset, unsigned long size,
 	unsigned long flags)
 {
 	void __iomem *addr = plat_ioremap(offset, size, flags);
@@ -183,7 +183,7 @@ static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
 	if (addr)
 		return addr;
 
-#define __IS_LOW512(addr) (!((phys_t)(addr) & (phys_t) ~0x1fffffffULL))
+#define __IS_LOW512(addr) (!((phys_addr_t)(addr) & (phys_addr_t) ~0x1fffffffULL))
 
 	if (cpu_has_64bit_addresses) {
 		u64 base = UNCAC_BASE;
@@ -197,7 +197,7 @@ static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
 		return (void __iomem *) (unsigned long) (base + offset);
 	} else if (__builtin_constant_p(offset) &&
 		   __builtin_constant_p(size) && __builtin_constant_p(flags)) {
-		phys_t phys_addr, last_addr;
+		phys_addr_t phys_addr, last_addr;
 
 		phys_addr = fixup_bigphys_addr(offset, size);
 

commit a809d46066d5171ed446d59a51cd1e57d99fcfc3
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Sun Mar 30 13:20:10 2014 +0200

    MIPS: Fix gigaton of warning building with microMIPS.
    
    With binutils 2.24 the attempt to switch with microMIPS mode to MIPS III
    mode through .set mips3 results in *lots* of warnings like
    
    {standard input}: Assembler messages:
    {standard input}:397: Warning: the 64-bit MIPS architecture does not support the `smartmips' extension
    
    during a kernel build.  Fixed by using .set arch=r4000 instead.
    
    This breaks support for building the kernel with binutils 2.13 which
    was supported for 32 bit kernels only anyway and 2.14 which was a bad
    vintage for MIPS anyway.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index e221d1de32f3..933b50e125a0 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -331,7 +331,7 @@ static inline void pfx##write##bwlq(type val,				\
 		if (irq)						\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
-			".set	mips3"		"\t\t# __writeq""\n\t"	\
+			".set	arch=r4000"	"\t\t# __writeq""\n\t"	\
 			"dsll32 %L0, %L0, 0"			"\n\t"	\
 			"dsrl32 %L0, %L0, 0"			"\n\t"	\
 			"dsll32 %M0, %M0, 0"			"\n\t"	\
@@ -361,7 +361,7 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 		if (irq)						\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
-			".set	mips3"		"\t\t# __readq" "\n\t"	\
+			".set	arch=r4000"	"\t\t# __readq" "\n\t"	\
 			"ld	%L0, %1"			"\n\t"	\
 			"dsra32 %M0, %L0, 0"			"\n\t"	\
 			"sll	%L0, %L0, 0"			"\n\t"	\

commit 8005711c8d80e452748e9572bead54493818f042
Author: Manuel Lauss <manuel.lauss@gmail.com>
Date:   Thu Feb 20 14:59:22 2014 +0100

    MIPS: Extend DMA_MAYBE_COHERENT logic to DMA_NONCOHERENT use
    
    Setting DMA_MAYBE_COHERENT gives a platform the opportunity to select
    use of cache ops at boot.
    
    Signed-off-by: Manuel Lauss <manuel.lauss@gmail.com>
    Cc: Linux-MIPS <linux-mips@linux-mips.org>
    Patchwork: https://patchwork.linux-mips.org/patch/6575/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 3321dd5a8872..e221d1de32f3 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -584,7 +584,7 @@ static inline void memcpy_toio(volatile void __iomem *dst, const void *src, int
  *
  * This API used to be exported; it now is for arch code internal use only.
  */
-#ifdef CONFIG_DMA_NONCOHERENT
+#if defined(CONFIG_DMA_NONCOHERENT) || defined(CONFIG_DMA_MAYBE_COHERENT)
 
 extern void (*_dma_cache_wback_inv)(unsigned long start, unsigned long size);
 extern void (*_dma_cache_wback)(unsigned long start, unsigned long size);
@@ -603,7 +603,7 @@ extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
 #define dma_cache_inv(start,size)	\
 	do { (void) (start); (void) (size); } while (0)
 
-#endif /* CONFIG_DMA_NONCOHERENT */
+#endif /* CONFIG_DMA_NONCOHERENT || CONFIG_DMA_MAYBE_COHERENT */
 
 /*
  * Read a 32-bit register that requires a 64-bit read cycle on the bus.

commit edd4201ebc2f1a7ab2158ad91ddc0af71e58dce7
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Fri May 31 13:07:44 2013 +0000

    MIPS: define write{b,w,l,q}_relaxed
    
    MIPS does define read{b,w,l,q}_relaxed but does not define their write
    counterparts: write{b,w,l,q}_relaxed. This patch adds the missing
    definitions for the write*_relaxed I/O accessors.
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Acked-by: John Crispin <blogic@openwrt.org>
    Cc: linux-mips@linux-mips.org
    Cc: cernekee@gmail.com
    Cc: jogo@openwrt.org
    Patchwork: https://patchwork.linux-mips.org/patch/5352/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index b84e1fb3fabf..3321dd5a8872 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -454,6 +454,11 @@ __BUILDIO(q, u64)
 #define readl_relaxed			readl
 #define readq_relaxed			readq
 
+#define writeb_relaxed			writeb
+#define writew_relaxed			writew
+#define writel_relaxed			writel
+#define writeq_relaxed			writeq
+
 #define readb_be(addr)							\
 	__raw_readb((__force unsigned *)(addr))
 #define readw_be(addr)							\

commit 78857614104a26cdada4c53eea104752042bf5a1
Author: Markos Chandras <markos.chandras@imgtec.com>
Date:   Mon Jun 17 08:09:00 2013 +0000

    MIPS: Expose missing pci_io{map,unmap} declarations
    
    The GENERIC_PCI_IOMAP does not depend on CONFIG_PCI so move
    it to the CONFIG_MIPS symbol so it's always selected for MIPS.
    This fixes the missing pci_iomap declaration for MIPS.
    Moreover, the pci_iounmap function was not defined in the
    io.h header file if the CONFIG_PCI symbol is not set,
    but it should since MIPS is not using CONFIG_GENERIC_IOMAP.
    
    This fixes the following problem on a allyesconfig:
    
    drivers/net/ethernet/3com/3c59x.c:1031:2: error: implicit declaration of
    function 'pci_iomap' [-Werror=implicit-function-declaration]
    drivers/net/ethernet/3com/3c59x.c:1044:3: error: implicit declaration of
    function 'pci_iounmap' [-Werror=implicit-function-declaration]
    
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>
    Acked-by: Steven J. Hill <Steven.Hill@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/5478/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index b7e59853fd33..b84e1fb3fabf 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -170,6 +170,11 @@ static inline void * isa_bus_to_virt(unsigned long address)
 extern void __iomem * __ioremap(phys_t offset, phys_t size, unsigned long flags);
 extern void __iounmap(const volatile void __iomem *addr);
 
+#ifndef CONFIG_PCI
+struct pci_dev;
+static inline void pci_iounmap(struct pci_dev *dev, void __iomem *addr) {}
+#endif
+
 static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
 	unsigned long flags)
 {

commit 49c426ba445f83d304a5eab3d49efa123329cf2b
Author: David Daney <david.daney@cavium.com>
Date:   Tue May 7 17:11:16 2013 +0000

    MIPS: Make virt_to_phys() work for all unmapped addresses.
    
    As reported:
      This problem was discovered when doing BGP traffic with the TCP MD5 option
      activated, where the following call chain caused a crash:
    
       * tcp_v4_rcv
       *  tcp_v4_timewait_ack
       *   tcp_v4_send_ack -> follow stack variable rep.th
       *    tcp_v4_md5_hash_hdr
       *     tcp_md5_hash_header
       *      sg_init_one
       *       sg_set_buf
       *        virt_to_page
    
      I noticed that tcp_v4_send_reset uses a similar stack variable and
      also calls tcp_v4_md5_hash_hdr, so it has the same problem.
    
    The networking core can indirectly call virt_to_phys() on stack
    addresses, if this is done from PID 0, the stack will usually be in
    CKSEG0, so virt_to_phys() needs to work there as well
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Cc: linux-mips@linux-mips.org
    Cc: Jiang Liu <liuj97@gmail.com>
    Cc: eunb.song@samsung.com
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/5220/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 1be13727323f..b7e59853fd33 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -118,7 +118,7 @@ static inline void set_io_port_base(unsigned long base)
  */
 static inline unsigned long virt_to_phys(volatile const void *address)
 {
-	return (unsigned long)address - PAGE_OFFSET + PHYS_OFFSET;
+	return __pa(address);
 }
 
 /*

commit 7034228792cc561e79ff8600f02884bd4c80e287
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Jan 22 12:59:30 2013 +0100

    MIPS: Whitespace cleanup.
    
    Having received another series of whitespace patches I decided to do this
    once and for all rather than dealing with this kind of patches trickling
    in forever.
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index ff2e0345e013..1be13727323f 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -7,7 +7,7 @@
  * Copyright (C) 1994 - 2000, 06 Ralf Baechle
  * Copyright (C) 1999, 2000 Silicon Graphics, Inc.
  * Copyright (C) 2004, 2005  MIPS Technologies, Inc.  All rights reserved.
- *	Author:	Maciej W. Rozycki <macro@mips.com>
+ *	Author: Maciej W. Rozycki <macro@mips.com>
  */
 #ifndef _ASM_IO_H
 #define _ASM_IO_H
@@ -253,9 +253,9 @@ static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
 	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
 
 /*
- * ioremap_cachable -   map bus memory into CPU space
- * @offset:         bus address of the memory
- * @size:           size of the resource to map
+ * ioremap_cachable -	map bus memory into CPU space
+ * @offset:	    bus address of the memory
+ * @size:	    size of the resource to map
  *
  * ioremap_nocache performs a platform specific sequence of operations to
  * make bus memory CPU accessible via the readb/readw/readl/writeb/
@@ -264,14 +264,14 @@ static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
  * address.
  *
  * This version of ioremap ensures that the memory is marked cachable by
- * the CPU.  Also enables full write-combining.  Useful for some
+ * the CPU.  Also enables full write-combining.	 Useful for some
  * memory-like regions on I/O busses.
  */
 #define ioremap_cachable(offset, size)					\
 	__ioremap_mode((offset), (size), _page_cachable_default)
 
 /*
- * These two are MIPS specific ioremap variant.  ioremap_cacheable_cow
+ * These two are MIPS specific ioremap variant.	 ioremap_cacheable_cow
  * requests a cachable mapping, ioremap_uncached_accelerated requests a
  * mapping using the uncached accelerated mode which isn't supported on
  * all processors.
@@ -298,7 +298,7 @@ static inline void iounmap(const volatile void __iomem *addr)
 }
 
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
-#define war_octeon_io_reorder_wmb()  		wmb()
+#define war_octeon_io_reorder_wmb()		wmb()
 #else
 #define war_octeon_io_reorder_wmb()		do { } while (0)
 #endif
@@ -317,7 +317,7 @@ static inline void pfx##write##bwlq(type val,				\
 									\
 	__val = pfx##ioswab##bwlq(__mem, val);				\
 									\
-	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long))	\
+	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long)) \
 		*__mem = __val;						\
 	else if (cpu_has_64bits) {					\
 		unsigned long __flags;					\
@@ -327,9 +327,9 @@ static inline void pfx##write##bwlq(type val,				\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
 			".set	mips3"		"\t\t# __writeq""\n\t"	\
-			"dsll32	%L0, %L0, 0"			"\n\t"	\
-			"dsrl32	%L0, %L0, 0"			"\n\t"	\
-			"dsll32	%M0, %M0, 0"			"\n\t"	\
+			"dsll32 %L0, %L0, 0"			"\n\t"	\
+			"dsrl32 %L0, %L0, 0"			"\n\t"	\
+			"dsll32 %M0, %M0, 0"			"\n\t"	\
 			"or	%L0, %L0, %M0"			"\n\t"	\
 			"sd	%L0, %2"			"\n\t"	\
 			".set	mips0"				"\n"	\
@@ -348,7 +348,7 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
-	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long))	\
+	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long)) \
 		__val = *__mem;						\
 	else if (cpu_has_64bits) {					\
 		unsigned long __flags;					\
@@ -356,9 +356,9 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 		if (irq)						\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
-			".set	mips3"		"\t\t# __readq"	"\n\t"	\
+			".set	mips3"		"\t\t# __readq" "\n\t"	\
 			"ld	%L0, %1"			"\n\t"	\
-			"dsra32	%M0, %L0, 0"			"\n\t"	\
+			"dsra32 %M0, %L0, 0"			"\n\t"	\
 			"sll	%L0, %L0, 0"			"\n\t"	\
 			".set	mips0"				"\n"	\
 			: "=r" (__val)					\
@@ -586,7 +586,7 @@ extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
 
 #else /* Sane hardware */
 
-#define dma_cache_wback_inv(start,size)	\
+#define dma_cache_wback_inv(start,size) \
 	do { (void) (start); (void) (size); } while (0)
 #define dma_cache_wback(start,size)	\
 	do { (void) (start); (void) (size); } while (0)

commit 92d11594f688c8b55b51e80f2eac4417396237a4
Author: Jim Quinlan <jim2101024@gmail.com>
Date:   Thu Sep 6 11:36:55 2012 -0400

    MIPS: Remove irqflags.h dependency from bitops.h
    
    The "else clause" of most functions in bitops.h invoked
    raw_local_irq_{save,restore}() and in doing so had a dependency on
    irqflags.h.  This fix moves said code to bitops.c, removing the
    dependency.
    
    Signed-off-by: Jim Quinlan <jim2101024@gmail.com>
    Cc: linux-mips@linux-mips.org
    Cc: David Daney <ddaney.cavm@gmail.com>
    Cc: Kevin Cernekee cernekee@gmail.com
    Cc: Jim Quinlan <jim2101024@gmail.com>
    Patchwork: https://patchwork.linux-mips.org/patch/4320/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 29d9c23c20c7..ff2e0345e013 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -15,6 +15,7 @@
 #include <linux/compiler.h>
 #include <linux/kernel.h>
 #include <linux/types.h>
+#include <linux/irqflags.h>
 
 #include <asm/addrspace.h>
 #include <asm/bug.h>

commit 893a0574de0c90a4e52c8f7070023b2eb58cd220
Author: Yoichi Yuasa <yuasa@linux-mips.org>
Date:   Wed Jul 18 14:12:01 2012 -0700

    mips: fix bug.h build regression
    
    Commit 377780887 ("bug.h: need linux/kernel.h for TAINT_WARN.") broke
    all MIPS builds:
    
        CC      arch/mips/kernel/machine_kexec.o
      include/linux/log2.h: In function '__ilog2_u32':
      include/linux/log2.h:34:2: error: implicit declaration of function 'fls' [-Werror=implicit-function-declaration]
      include/linux/log2.h: In function '__ilog2_u64':
      include/linux/log2.h:42:2: error: implicit declaration of function 'fls64' [-Werror=implicit-function-declaration]
      ...
    
    Signed-off-by: Yoichi Yuasa <yuasa@linux-mips.org>
    Tested-by: John Crispin <blogic@openwrt.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index a58f22998a86..29d9c23c20c7 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -17,6 +17,7 @@
 #include <linux/types.h>
 
 #include <asm/addrspace.h>
+#include <asm/bug.h>
 #include <asm/byteorder.h>
 #include <asm/cpu.h>
 #include <asm/cpu-features.h>

commit b77bb37a2ad7689d9ef8048df9cc30ee770f5a94
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Thu Jun 30 14:43:14 2011 +0100

    Revert "MIPS: LD/SD o32 macro GAS fix update"
    
    This reverts commit 97475f8b42e83be2966aa2d70ab9c98477701c53 (lmo) /
    82b89152f00f7ad17844d5614d5011e8d7944ac9 (kernel.org) [MIPS: LD/SD o32
    macro GAS fix update].
    
    Turns out this patch is producing many build errors with gcc 4.2.  Based
    on further testing with a test case extracted from the build errors found
    further build errors and suboptimal generation even in violation of the
    "R" constraint.
    
    To make matters worse, the binutils changes also don't work quite as
    intended so revert this patch for now.

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index b04e4de5dd2e..a58f22998a86 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -329,14 +329,10 @@ static inline void pfx##write##bwlq(type val,				\
 			"dsrl32	%L0, %L0, 0"			"\n\t"	\
 			"dsll32	%M0, %M0, 0"			"\n\t"	\
 			"or	%L0, %L0, %M0"			"\n\t"	\
-			".set	push"				"\n\t"	\
-			".set	noreorder"			"\n\t"	\
-			".set	nomacro"			"\n\t"	\
 			"sd	%L0, %2"			"\n\t"	\
-			".set	pop"				"\n\t"	\
 			".set	mips0"				"\n"	\
 			: "=r" (__tmp)					\
-			: "0" (__val), "R" (*__mem));			\
+			: "0" (__val), "m" (*__mem));			\
 		if (irq)						\
 			local_irq_restore(__flags);			\
 	} else								\
@@ -359,16 +355,12 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
 			".set	mips3"		"\t\t# __readq"	"\n\t"	\
-			".set	push"				"\n\t"	\
-			".set	noreorder"			"\n\t"	\
-			".set	nomacro"			"\n\t"	\
 			"ld	%L0, %1"			"\n\t"	\
-			".set	pop"				"\n\t"	\
 			"dsra32	%M0, %L0, 0"			"\n\t"	\
 			"sll	%L0, %L0, 0"			"\n\t"	\
 			".set	mips0"				"\n"	\
 			: "=r" (__val)					\
-			: "R" (*__mem));				\
+			: "m" (*__mem));				\
 		if (irq)						\
 			local_irq_restore(__flags);			\
 	} else {							\

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 5b017f23e243..b04e4de5dd2e 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -242,7 +242,7 @@ static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
  * This version of ioremap ensures that the memory is marked uncachable
  * on the CPU as well as honouring existing caching rules from things like
  * the PCI bus. Note that there are other caches and buffers on many
- * busses. In paticular driver authors should read up on PCI writes
+ * busses. In particular driver authors should read up on PCI writes
  *
  * It's useful if some control registers are in such an area and
  * write combining or read caching is not desirable:

commit 82b89152f00f7ad17844d5614d5011e8d7944ac9
Author: Maciej W. Rozycki <macro@linux-mips.org>
Date:   Sun Oct 10 10:42:12 2010 +0100

    MIPS: LD/SD o32 macro GAS fix update
    
    I am about to commit:
    
    http://sourceware.org/ml/binutils/2010-10/msg00033.html
    
    that fixes a problem with the LD/SD macro currently implemented by GAS for
    the o32 ABI in an inconsistent way.  This is best illustrated with a
    simple program, which I'm copying here from the message above for easier
    reference:
    
    $ cat ld.s
            ld      $5,32767($4)
            ld      $5,32768($4)
    
    This gets assebled into the following output:
    
    $ mips-linux-as -32 -mips3 -o ld.o ld.s
    $ mips-linux-objdump -d ld.o
    
    ld.o:     file format elf32-tradbigmips
    
    Disassembly of section .text:
    
    00000000 <.text>:
       0:   dc857fff        ld      a1,32767(a0)
       4:   3c010001        lui     at,0x1
       8:   00810821        addu    at,a0,at
       c:   8c258000        lw      a1,-32768(at)
      10:   8c268004        lw      a2,-32764(at)
            ...
    
    Oops!
    
     The GAS fix makes the macro behave in a consistent way and pairs of LW/SW
    instructions to be output as appropriate regardless of the size of the
    offset associated with the address used.  The machine instruction is still
    available, but to reach it macros have to be disabled first.  This has a
    side effect of requiring the use of a machine-addressable memory operand.
    
     As some platforms require 64-bit operations for accesses to some I/O
    registers LD/SD instructions are used in a couple of places in Linux
    regardless of the ABI selected.  Here's a fix for some pieces of code
    affected I've been able to track down.  The fix should be backwards
    compatible with all supported binutils releases in existence and can be
    used as a reference for any other places or off-tree code.  The use of the
    "R" constraint guarantees a machine-addressable operand.
    
    Signed-off-by: Maciej W. Rozycki <macro@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/1680/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index c98bf514ec7d..5b017f23e243 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -329,10 +329,14 @@ static inline void pfx##write##bwlq(type val,				\
 			"dsrl32	%L0, %L0, 0"			"\n\t"	\
 			"dsll32	%M0, %M0, 0"			"\n\t"	\
 			"or	%L0, %L0, %M0"			"\n\t"	\
+			".set	push"				"\n\t"	\
+			".set	noreorder"			"\n\t"	\
+			".set	nomacro"			"\n\t"	\
 			"sd	%L0, %2"			"\n\t"	\
+			".set	pop"				"\n\t"	\
 			".set	mips0"				"\n"	\
 			: "=r" (__tmp)					\
-			: "0" (__val), "m" (*__mem));			\
+			: "0" (__val), "R" (*__mem));			\
 		if (irq)						\
 			local_irq_restore(__flags);			\
 	} else								\
@@ -355,12 +359,16 @@ static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
 			local_irq_save(__flags);			\
 		__asm__ __volatile__(					\
 			".set	mips3"		"\t\t# __readq"	"\n\t"	\
+			".set	push"				"\n\t"	\
+			".set	noreorder"			"\n\t"	\
+			".set	nomacro"			"\n\t"	\
 			"ld	%L0, %1"			"\n\t"	\
+			".set	pop"				"\n\t"	\
 			"dsra32	%M0, %L0, 0"			"\n\t"	\
 			"sll	%L0, %L0, 0"			"\n\t"	\
 			".set	mips0"				"\n"	\
 			: "=r" (__val)					\
-			: "m" (*__mem));				\
+			: "R" (*__mem));				\
 		if (irq)						\
 			local_irq_restore(__flags);			\
 	} else {							\

commit f868ba29723be46e0981226d7455090d515b08ef
Author: Florian Fainelli <ffainelli@freebox.fr>
Date:   Wed Dec 16 11:29:06 2009 +0100

    MIPS: add readl/write_be accessors
    
    MIPS currently lacks the readl_be and writel_be accessors
    which are required by BCM63xx for OHCI and EHCI support.
    Let's define them globally for MIPS. This also fixes the
    compilation of the bcm63xx defconfig against USB.
    
    Signed-off-by: Florian Fainelli <ffainelli@freebox.fr>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: linux-mips@linux-mips.org
    Cc: Maxime Bizon <mbizon@freebox.fr>
    Patchwork: http://patchwork.linux-mips.org/patch/793/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 436878e4e063..c98bf514ec7d 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -447,6 +447,24 @@ __BUILDIO(q, u64)
 #define readl_relaxed			readl
 #define readq_relaxed			readq
 
+#define readb_be(addr)							\
+	__raw_readb((__force unsigned *)(addr))
+#define readw_be(addr)							\
+	be16_to_cpu(__raw_readw((__force unsigned *)(addr)))
+#define readl_be(addr)							\
+	be32_to_cpu(__raw_readl((__force unsigned *)(addr)))
+#define readq_be(addr)							\
+	be64_to_cpu(__raw_readq((__force unsigned *)(addr)))
+
+#define writeb_be(val, addr)						\
+	__raw_writeb((val), (__force unsigned *)(addr))
+#define writew_be(val, addr)						\
+	__raw_writew(cpu_to_be16((val)), (__force unsigned *)(addr))
+#define writel_be(val, addr)						\
+	__raw_writel(cpu_to_be32((val)), (__force unsigned *)(addr))
+#define writeq_be(val, addr)						\
+	__raw_writeq(cpu_to_be64((val)), (__force unsigned *)(addr))
+
 /*
  * Some code tests for these symbols
  */

commit 8faca49a6731299c32b333fd6535db8d21557ce3
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Thu Dec 11 15:33:29 2008 -0800

    MIPS: Modify core io.h macros to account for the Octeon Errata Core-301.
    
    Signed-off-by: Tomaso Paoletti <tpaoletti@caviumnetworks.com>
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index 501a40b9f18d..436878e4e063 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -295,6 +295,12 @@ static inline void iounmap(const volatile void __iomem *addr)
 #undef __IS_KSEG1
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define war_octeon_io_reorder_wmb()  		wmb()
+#else
+#define war_octeon_io_reorder_wmb()		do { } while (0)
+#endif
+
 #define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\
 									\
 static inline void pfx##write##bwlq(type val,				\
@@ -303,6 +309,8 @@ static inline void pfx##write##bwlq(type val,				\
 	volatile type *__mem;						\
 	type __val;							\
 									\
+	war_octeon_io_reorder_wmb();					\
+									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
 	__val = pfx##ioswab##bwlq(__mem, val);				\
@@ -370,6 +378,8 @@ static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 	volatile type *__addr;						\
 	type __val;							\
 									\
+	war_octeon_io_reorder_wmb();					\
+									\
 	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
 									\
 	__val = pfx##ioswab##bwlq(__addr, val);				\
@@ -504,8 +514,12 @@ BUILDSTRING(q, u64)
 #endif
 
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define mmiowb() wmb()
+#else
 /* Depends on MIPS II instruction set */
 #define mmiowb() asm volatile ("sync" ::: "memory")
+#endif
 
 static inline void memset_io(volatile void __iomem *addr, unsigned char val, int count)
 {

commit 384740dc49ea651ba350704d13ff6be9976e37fe
Author: Ralf Baechle <ralf@linux-mips.org>
Date:   Tue Sep 16 19:48:51 2008 +0200

    MIPS: Move headfiles to new location below arch/mips/include
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
new file mode 100644
index 000000000000..501a40b9f18d
--- /dev/null
+++ b/arch/mips/include/asm/io.h
@@ -0,0 +1,589 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994, 1995 Waldorf GmbH
+ * Copyright (C) 1994 - 2000, 06 Ralf Baechle
+ * Copyright (C) 1999, 2000 Silicon Graphics, Inc.
+ * Copyright (C) 2004, 2005  MIPS Technologies, Inc.  All rights reserved.
+ *	Author:	Maciej W. Rozycki <macro@mips.com>
+ */
+#ifndef _ASM_IO_H
+#define _ASM_IO_H
+
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+
+#include <asm/addrspace.h>
+#include <asm/byteorder.h>
+#include <asm/cpu.h>
+#include <asm/cpu-features.h>
+#include <asm-generic/iomap.h>
+#include <asm/page.h>
+#include <asm/pgtable-bits.h>
+#include <asm/processor.h>
+#include <asm/string.h>
+
+#include <ioremap.h>
+#include <mangle-port.h>
+
+/*
+ * Slowdown I/O port space accesses for antique hardware.
+ */
+#undef CONF_SLOWDOWN_IO
+
+/*
+ * Raw operations are never swapped in software.  OTOH values that raw
+ * operations are working on may or may not have been swapped by the bus
+ * hardware.  An example use would be for flash memory that's used for
+ * execute in place.
+ */
+# define __raw_ioswabb(a, x)	(x)
+# define __raw_ioswabw(a, x)	(x)
+# define __raw_ioswabl(a, x)	(x)
+# define __raw_ioswabq(a, x)	(x)
+# define ____raw_ioswabq(a, x)	(x)
+
+/* ioswab[bwlq], __mem_ioswab[bwlq] are defined in mangle-port.h */
+
+#define IO_SPACE_LIMIT 0xffff
+
+/*
+ * On MIPS I/O ports are memory mapped, so we access them using normal
+ * load/store instructions. mips_io_port_base is the virtual address to
+ * which all ports are being mapped.  For sake of efficiency some code
+ * assumes that this is an address that can be loaded with a single lui
+ * instruction, so the lower 16 bits must be zero.  Should be true on
+ * on any sane architecture; generic code does not use this assumption.
+ */
+extern const unsigned long mips_io_port_base;
+
+/*
+ * Gcc will generate code to load the value of mips_io_port_base after each
+ * function call which may be fairly wasteful in some cases.  So we don't
+ * play quite by the book.  We tell gcc mips_io_port_base is a long variable
+ * which solves the code generation issue.  Now we need to violate the
+ * aliasing rules a little to make initialization possible and finally we
+ * will need the barrier() to fight side effects of the aliasing chat.
+ * This trickery will eventually collapse under gcc's optimizer.  Oh well.
+ */
+static inline void set_io_port_base(unsigned long base)
+{
+	* (unsigned long *) &mips_io_port_base = base;
+	barrier();
+}
+
+/*
+ * Thanks to James van Artsdalen for a better timing-fix than
+ * the two short jumps: using outb's to a nonexistent port seems
+ * to guarantee better timings even on fast machines.
+ *
+ * On the other hand, I'd like to be sure of a non-existent port:
+ * I feel a bit unsafe about using 0x80 (should be safe, though)
+ *
+ *		Linus
+ *
+ */
+
+#define __SLOW_DOWN_IO \
+	__asm__ __volatile__( \
+		"sb\t$0,0x80(%0)" \
+		: : "r" (mips_io_port_base));
+
+#ifdef CONF_SLOWDOWN_IO
+#ifdef REALLY_SLOW_IO
+#define SLOW_DOWN_IO { __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; __SLOW_DOWN_IO; }
+#else
+#define SLOW_DOWN_IO __SLOW_DOWN_IO
+#endif
+#else
+#define SLOW_DOWN_IO
+#endif
+
+/*
+ *     virt_to_phys    -       map virtual addresses to physical
+ *     @address: address to remap
+ *
+ *     The returned physical address is the physical (CPU) mapping for
+ *     the memory address given. It is only valid to use this function on
+ *     addresses directly mapped or allocated via kmalloc.
+ *
+ *     This function does not give bus mappings for DMA transfers. In
+ *     almost all conceivable cases a device driver should not be using
+ *     this function
+ */
+static inline unsigned long virt_to_phys(volatile const void *address)
+{
+	return (unsigned long)address - PAGE_OFFSET + PHYS_OFFSET;
+}
+
+/*
+ *     phys_to_virt    -       map physical address to virtual
+ *     @address: address to remap
+ *
+ *     The returned virtual address is a current CPU mapping for
+ *     the memory address given. It is only valid to use this function on
+ *     addresses that have a kernel mapping
+ *
+ *     This function does not handle bus mappings for DMA transfers. In
+ *     almost all conceivable cases a device driver should not be using
+ *     this function
+ */
+static inline void * phys_to_virt(unsigned long address)
+{
+	return (void *)(address + PAGE_OFFSET - PHYS_OFFSET);
+}
+
+/*
+ * ISA I/O bus memory addresses are 1:1 with the physical address.
+ */
+static inline unsigned long isa_virt_to_bus(volatile void * address)
+{
+	return (unsigned long)address - PAGE_OFFSET;
+}
+
+static inline void * isa_bus_to_virt(unsigned long address)
+{
+	return (void *)(address + PAGE_OFFSET);
+}
+
+#define isa_page_to_bus page_to_phys
+
+/*
+ * However PCI ones are not necessarily 1:1 and therefore these interfaces
+ * are forbidden in portable PCI drivers.
+ *
+ * Allow them for x86 for legacy drivers, though.
+ */
+#define virt_to_bus virt_to_phys
+#define bus_to_virt phys_to_virt
+
+/*
+ * Change "struct page" to physical address.
+ */
+#define page_to_phys(page)	((dma_addr_t)page_to_pfn(page) << PAGE_SHIFT)
+
+extern void __iomem * __ioremap(phys_t offset, phys_t size, unsigned long flags);
+extern void __iounmap(const volatile void __iomem *addr);
+
+static inline void __iomem * __ioremap_mode(phys_t offset, unsigned long size,
+	unsigned long flags)
+{
+	void __iomem *addr = plat_ioremap(offset, size, flags);
+
+	if (addr)
+		return addr;
+
+#define __IS_LOW512(addr) (!((phys_t)(addr) & (phys_t) ~0x1fffffffULL))
+
+	if (cpu_has_64bit_addresses) {
+		u64 base = UNCAC_BASE;
+
+		/*
+		 * R10000 supports a 2 bit uncached attribute therefore
+		 * UNCAC_BASE may not equal IO_BASE.
+		 */
+		if (flags == _CACHE_UNCACHED)
+			base = (u64) IO_BASE;
+		return (void __iomem *) (unsigned long) (base + offset);
+	} else if (__builtin_constant_p(offset) &&
+		   __builtin_constant_p(size) && __builtin_constant_p(flags)) {
+		phys_t phys_addr, last_addr;
+
+		phys_addr = fixup_bigphys_addr(offset, size);
+
+		/* Don't allow wraparound or zero size. */
+		last_addr = phys_addr + size - 1;
+		if (!size || last_addr < phys_addr)
+			return NULL;
+
+		/*
+		 * Map uncached objects in the low 512MB of address
+		 * space using KSEG1.
+		 */
+		if (__IS_LOW512(phys_addr) && __IS_LOW512(last_addr) &&
+		    flags == _CACHE_UNCACHED)
+			return (void __iomem *)
+				(unsigned long)CKSEG1ADDR(phys_addr);
+	}
+
+	return __ioremap(offset, size, flags);
+
+#undef __IS_LOW512
+}
+
+/*
+ * ioremap     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+ *
+ * ioremap performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ */
+#define ioremap(offset, size)						\
+	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
+
+/*
+ * ioremap_nocache     -   map bus memory into CPU space
+ * @offset:    bus address of the memory
+ * @size:      size of the resource to map
+ *
+ * ioremap_nocache performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ *
+ * This version of ioremap ensures that the memory is marked uncachable
+ * on the CPU as well as honouring existing caching rules from things like
+ * the PCI bus. Note that there are other caches and buffers on many
+ * busses. In paticular driver authors should read up on PCI writes
+ *
+ * It's useful if some control registers are in such an area and
+ * write combining or read caching is not desirable:
+ */
+#define ioremap_nocache(offset, size)					\
+	__ioremap_mode((offset), (size), _CACHE_UNCACHED)
+
+/*
+ * ioremap_cachable -   map bus memory into CPU space
+ * @offset:         bus address of the memory
+ * @size:           size of the resource to map
+ *
+ * ioremap_nocache performs a platform specific sequence of operations to
+ * make bus memory CPU accessible via the readb/readw/readl/writeb/
+ * writew/writel functions and the other mmio helpers. The returned
+ * address is not guaranteed to be usable directly as a virtual
+ * address.
+ *
+ * This version of ioremap ensures that the memory is marked cachable by
+ * the CPU.  Also enables full write-combining.  Useful for some
+ * memory-like regions on I/O busses.
+ */
+#define ioremap_cachable(offset, size)					\
+	__ioremap_mode((offset), (size), _page_cachable_default)
+
+/*
+ * These two are MIPS specific ioremap variant.  ioremap_cacheable_cow
+ * requests a cachable mapping, ioremap_uncached_accelerated requests a
+ * mapping using the uncached accelerated mode which isn't supported on
+ * all processors.
+ */
+#define ioremap_cacheable_cow(offset, size)				\
+	__ioremap_mode((offset), (size), _CACHE_CACHABLE_COW)
+#define ioremap_uncached_accelerated(offset, size)			\
+	__ioremap_mode((offset), (size), _CACHE_UNCACHED_ACCELERATED)
+
+static inline void iounmap(const volatile void __iomem *addr)
+{
+	if (plat_iounmap(addr))
+		return;
+
+#define __IS_KSEG1(addr) (((unsigned long)(addr) & ~0x1fffffffUL) == CKSEG1)
+
+	if (cpu_has_64bit_addresses ||
+	    (__builtin_constant_p(addr) && __IS_KSEG1(addr)))
+		return;
+
+	__iounmap(addr);
+
+#undef __IS_KSEG1
+}
+
+#define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\
+									\
+static inline void pfx##write##bwlq(type val,				\
+				    volatile void __iomem *mem)		\
+{									\
+	volatile type *__mem;						\
+	type __val;							\
+									\
+	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
+									\
+	__val = pfx##ioswab##bwlq(__mem, val);				\
+									\
+	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long))	\
+		*__mem = __val;						\
+	else if (cpu_has_64bits) {					\
+		unsigned long __flags;					\
+		type __tmp;						\
+									\
+		if (irq)						\
+			local_irq_save(__flags);			\
+		__asm__ __volatile__(					\
+			".set	mips3"		"\t\t# __writeq""\n\t"	\
+			"dsll32	%L0, %L0, 0"			"\n\t"	\
+			"dsrl32	%L0, %L0, 0"			"\n\t"	\
+			"dsll32	%M0, %M0, 0"			"\n\t"	\
+			"or	%L0, %L0, %M0"			"\n\t"	\
+			"sd	%L0, %2"			"\n\t"	\
+			".set	mips0"				"\n"	\
+			: "=r" (__tmp)					\
+			: "0" (__val), "m" (*__mem));			\
+		if (irq)						\
+			local_irq_restore(__flags);			\
+	} else								\
+		BUG();							\
+}									\
+									\
+static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
+{									\
+	volatile type *__mem;						\
+	type __val;							\
+									\
+	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
+									\
+	if (sizeof(type) != sizeof(u64) || sizeof(u64) == sizeof(long))	\
+		__val = *__mem;						\
+	else if (cpu_has_64bits) {					\
+		unsigned long __flags;					\
+									\
+		if (irq)						\
+			local_irq_save(__flags);			\
+		__asm__ __volatile__(					\
+			".set	mips3"		"\t\t# __readq"	"\n\t"	\
+			"ld	%L0, %1"			"\n\t"	\
+			"dsra32	%M0, %L0, 0"			"\n\t"	\
+			"sll	%L0, %L0, 0"			"\n\t"	\
+			".set	mips0"				"\n"	\
+			: "=r" (__val)					\
+			: "m" (*__mem));				\
+		if (irq)						\
+			local_irq_restore(__flags);			\
+	} else {							\
+		__val = 0;						\
+		BUG();							\
+	}								\
+									\
+	return pfx##ioswab##bwlq(__mem, __val);				\
+}
+
+#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, p, slow)			\
+									\
+static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
+{									\
+	volatile type *__addr;						\
+	type __val;							\
+									\
+	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
+									\
+	__val = pfx##ioswab##bwlq(__addr, val);				\
+									\
+	/* Really, we want this to be atomic */				\
+	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
+									\
+	*__addr = __val;						\
+	slow;								\
+}									\
+									\
+static inline type pfx##in##bwlq##p(unsigned long port)			\
+{									\
+	volatile type *__addr;						\
+	type __val;							\
+									\
+	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
+									\
+	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
+									\
+	__val = *__addr;						\
+	slow;								\
+									\
+	return pfx##ioswab##bwlq(__addr, __val);			\
+}
+
+#define __BUILD_MEMORY_PFX(bus, bwlq, type)				\
+									\
+__BUILD_MEMORY_SINGLE(bus, bwlq, type, 1)
+
+#define BUILDIO_MEM(bwlq, type)						\
+									\
+__BUILD_MEMORY_PFX(__raw_, bwlq, type)					\
+__BUILD_MEMORY_PFX(, bwlq, type)					\
+__BUILD_MEMORY_PFX(__mem_, bwlq, type)					\
+
+BUILDIO_MEM(b, u8)
+BUILDIO_MEM(w, u16)
+BUILDIO_MEM(l, u32)
+BUILDIO_MEM(q, u64)
+
+#define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, ,)			\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, _p, SLOW_DOWN_IO)
+
+#define BUILDIO_IOPORT(bwlq, type)					\
+	__BUILD_IOPORT_PFX(, bwlq, type)				\
+	__BUILD_IOPORT_PFX(__mem_, bwlq, type)
+
+BUILDIO_IOPORT(b, u8)
+BUILDIO_IOPORT(w, u16)
+BUILDIO_IOPORT(l, u32)
+#ifdef CONFIG_64BIT
+BUILDIO_IOPORT(q, u64)
+#endif
+
+#define __BUILDIO(bwlq, type)						\
+									\
+__BUILD_MEMORY_SINGLE(____raw_, bwlq, type, 0)
+
+__BUILDIO(q, u64)
+
+#define readb_relaxed			readb
+#define readw_relaxed			readw
+#define readl_relaxed			readl
+#define readq_relaxed			readq
+
+/*
+ * Some code tests for these symbols
+ */
+#define readq				readq
+#define writeq				writeq
+
+#define __BUILD_MEMORY_STRING(bwlq, type)				\
+									\
+static inline void writes##bwlq(volatile void __iomem *mem,		\
+				const void *addr, unsigned int count)	\
+{									\
+	const volatile type *__addr = addr;				\
+									\
+	while (count--) {						\
+		__mem_write##bwlq(*__addr, mem);			\
+		__addr++;						\
+	}								\
+}									\
+									\
+static inline void reads##bwlq(volatile void __iomem *mem, void *addr,	\
+			       unsigned int count)			\
+{									\
+	volatile type *__addr = addr;					\
+									\
+	while (count--) {						\
+		*__addr = __mem_read##bwlq(mem);			\
+		__addr++;						\
+	}								\
+}
+
+#define __BUILD_IOPORT_STRING(bwlq, type)				\
+									\
+static inline void outs##bwlq(unsigned long port, const void *addr,	\
+			      unsigned int count)			\
+{									\
+	const volatile type *__addr = addr;				\
+									\
+	while (count--) {						\
+		__mem_out##bwlq(*__addr, port);				\
+		__addr++;						\
+	}								\
+}									\
+									\
+static inline void ins##bwlq(unsigned long port, void *addr,		\
+			     unsigned int count)			\
+{									\
+	volatile type *__addr = addr;					\
+									\
+	while (count--) {						\
+		*__addr = __mem_in##bwlq(port);				\
+		__addr++;						\
+	}								\
+}
+
+#define BUILDSTRING(bwlq, type)						\
+									\
+__BUILD_MEMORY_STRING(bwlq, type)					\
+__BUILD_IOPORT_STRING(bwlq, type)
+
+BUILDSTRING(b, u8)
+BUILDSTRING(w, u16)
+BUILDSTRING(l, u32)
+#ifdef CONFIG_64BIT
+BUILDSTRING(q, u64)
+#endif
+
+
+/* Depends on MIPS II instruction set */
+#define mmiowb() asm volatile ("sync" ::: "memory")
+
+static inline void memset_io(volatile void __iomem *addr, unsigned char val, int count)
+{
+	memset((void __force *) addr, val, count);
+}
+static inline void memcpy_fromio(void *dst, const volatile void __iomem *src, int count)
+{
+	memcpy(dst, (void __force *) src, count);
+}
+static inline void memcpy_toio(volatile void __iomem *dst, const void *src, int count)
+{
+	memcpy((void __force *) dst, src, count);
+}
+
+/*
+ * The caches on some architectures aren't dma-coherent and have need to
+ * handle this in software.  There are three types of operations that
+ * can be applied to dma buffers.
+ *
+ *  - dma_cache_wback_inv(start, size) makes caches and coherent by
+ *    writing the content of the caches back to memory, if necessary.
+ *    The function also invalidates the affected part of the caches as
+ *    necessary before DMA transfers from outside to memory.
+ *  - dma_cache_wback(start, size) makes caches and coherent by
+ *    writing the content of the caches back to memory, if necessary.
+ *    The function also invalidates the affected part of the caches as
+ *    necessary before DMA transfers from outside to memory.
+ *  - dma_cache_inv(start, size) invalidates the affected parts of the
+ *    caches.  Dirty lines of the caches may be written back or simply
+ *    be discarded.  This operation is necessary before dma operations
+ *    to the memory.
+ *
+ * This API used to be exported; it now is for arch code internal use only.
+ */
+#ifdef CONFIG_DMA_NONCOHERENT
+
+extern void (*_dma_cache_wback_inv)(unsigned long start, unsigned long size);
+extern void (*_dma_cache_wback)(unsigned long start, unsigned long size);
+extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
+
+#define dma_cache_wback_inv(start, size)	_dma_cache_wback_inv(start, size)
+#define dma_cache_wback(start, size)		_dma_cache_wback(start, size)
+#define dma_cache_inv(start, size)		_dma_cache_inv(start, size)
+
+#else /* Sane hardware */
+
+#define dma_cache_wback_inv(start,size)	\
+	do { (void) (start); (void) (size); } while (0)
+#define dma_cache_wback(start,size)	\
+	do { (void) (start); (void) (size); } while (0)
+#define dma_cache_inv(start,size)	\
+	do { (void) (start); (void) (size); } while (0)
+
+#endif /* CONFIG_DMA_NONCOHERENT */
+
+/*
+ * Read a 32-bit register that requires a 64-bit read cycle on the bus.
+ * Avoid interrupt mucking, just adjust the address for 4-byte access.
+ * Assume the addresses are 8-byte aligned.
+ */
+#ifdef __MIPSEB__
+#define __CSR_32_ADJUST 4
+#else
+#define __CSR_32_ADJUST 0
+#endif
+
+#define csr_out32(v, a) (*(volatile u32 *)((unsigned long)(a) + __CSR_32_ADJUST) = (v))
+#define csr_in32(a)    (*(volatile u32 *)((unsigned long)(a) + __CSR_32_ADJUST))
+
+/*
+ * Convert a physical pointer to a virtual kernel pointer for /dev/mem
+ * access
+ */
+#define xlate_dev_mem_ptr(p)	__va(p)
+
+/*
+ * Convert a virtual cached pointer to an uncached pointer
+ */
+#define xlate_dev_kmem_ptr(p)	p
+
+#endif /* _ASM_IO_H */
