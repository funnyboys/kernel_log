commit 6137fed0823247e32306bde2b48cac627c24f894
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Sep 4 17:04:07 2018 +0200

    arch/tlb: Clean up simple architectures
    
    For the architectures that do not implement their own tlb_flush() but
    do already use the generic mmu_gather, there are two options:
    
     1) the platform has an efficient flush_tlb_range() and
        asm-generic/tlb.h doesn't need any overrides at all.
    
     2) the platform lacks an efficient flush_tlb_range() and
        we select MMU_GATHER_NO_RANGE to minimize full invalidates.
    
    Convert all 'simple' architectures to one of these two forms.
    
    alpha:      has no range invalidate -> 2
    arc:        already used flush_tlb_range() -> 1
    c6x:        has no range invalidate -> 2
    hexagon:    has an efficient flush_tlb_range() -> 1
                (flush_tlb_mm() is in fact a full range invalidate,
                 so no need to shoot down everything)
    m68k:       has inefficient flush_tlb_range() -> 2
    microblaze: has no flush_tlb_range() -> 2
    mips:       has efficient flush_tlb_range() -> 1
                (even though it currently seems to use flush_tlb_mm())
    nds32:      already uses flush_tlb_range() -> 1
    nios2:      has inefficient flush_tlb_range() -> 2
                (no limit on range iteration)
    openrisc:   has inefficient flush_tlb_range() -> 2
                (no limit on range iteration)
    parisc:     already uses flush_tlb_range() -> 1
    sparc32:    already uses flush_tlb_range() -> 1
    unicore32:  has inefficient flush_tlb_range() -> 2
                (no limit on range iteration)
    xtensa:     has efficient flush_tlb_range() -> 1
    
    Note this also fixes a bug in the existing code for a number
    platforms. Those platforms that did:
    
      tlb_end_vma() -> if (!full_mm) flush_tlb_*()
      tlb_flush -> if (full_mm) flush_tlb_mm()
    
    missed the case of shift_arg_pages(), which doesn't have @fullmm set,
    nor calls into tlb_*vma(), but still frees page-tables and thus needs
    an invalidate. The new code handles this by detecting a non-empty
    range, and either issuing the matching range invalidate or a full
    invalidate, depending on the capabilities.
    
    No change in behavior intended.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Piggin <npiggin@gmail.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/nios2/include/asm/tlb.h b/arch/nios2/include/asm/tlb.h
index 9b518c6d0f62..f9f2e27e32dd 100644
--- a/arch/nios2/include/asm/tlb.h
+++ b/arch/nios2/include/asm/tlb.h
@@ -11,12 +11,12 @@
 #ifndef _ASM_NIOS2_TLB_H
 #define _ASM_NIOS2_TLB_H
 
-#define tlb_flush(tlb)	flush_tlb_mm((tlb)->mm)
-
 extern void set_mmu_pid(unsigned long pid);
 
-#define tlb_end_vma(tlb, vma)	do { } while (0)
-#define __tlb_remove_tlb_entry(tlb, ptep, address)	do { } while (0)
+/*
+ * NIOS32 does have flush_tlb_range(), but it lacks a limit and fallback to
+ * full mm invalidation. So use flush_tlb_mm() for everything.
+ */
 
 #include <linux/pagemap.h>
 #include <asm-generic/tlb.h>

commit e7fd28a706bfaf9cd65dccf18140187f7ad04839
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 27 13:00:17 2018 +0200

    asm-generic/tlb, arch: Provide generic VIPT cache flush
    
    The one obvious thing SH and ARM want is a sensible default for
    tlb_start_vma(). (also: https://lkml.org/lkml/2004/1/15/6 )
    
    Avoid all VIPT architectures providing their own tlb_start_vma()
    implementation and rely on architectures to provide a no-op
    flush_cache_range() when it is not relevant.
    
    This patch makes tlb_start_vma() default to flush_cache_range(), which
    should be right and sufficient. The only exceptions that I found where
    (oddly):
    
      - m68k-mmu
      - sparc64
      - unicore
    
    Those architectures appear to have flush_cache_range(), but their
    current tlb_start_vma() does not call it.
    
    No change in behavior intended.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Miller <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Nick Piggin <npiggin@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/nios2/include/asm/tlb.h b/arch/nios2/include/asm/tlb.h
index d3bc648e08b5..9b518c6d0f62 100644
--- a/arch/nios2/include/asm/tlb.h
+++ b/arch/nios2/include/asm/tlb.h
@@ -15,16 +15,6 @@
 
 extern void set_mmu_pid(unsigned long pid);
 
-/*
- * NiosII doesn't need any special per-pte or per-vma handling, except
- * we need to flush cache for the area to be unmapped.
- */
-#define tlb_start_vma(tlb, vma)					\
-	do {							\
-		if (!tlb->fullmm)				\
-			flush_cache_range(vma, vma->vm_start, vma->vm_end); \
-	}  while (0)
-
 #define tlb_end_vma(tlb, vma)	do { } while (0)
 #define __tlb_remove_tlb_entry(tlb, ptep, address)	do { } while (0)
 

commit c983e92fcba7c7e54c796941f42514d94dd6cccc
Author: Ley Foon Tan <lftan@altera.com>
Date:   Thu Nov 6 15:19:50 2014 +0800

    nios2: TLB handling
    
    This patch adds the TLB maintenance functions.
    
    Signed-off-by: Ley Foon Tan <lftan@altera.com>

diff --git a/arch/nios2/include/asm/tlb.h b/arch/nios2/include/asm/tlb.h
new file mode 100644
index 000000000000..d3bc648e08b5
--- /dev/null
+++ b/arch/nios2/include/asm/tlb.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2010 Tobias Klauser <tklauser@distanz.ch>
+ * Copyright (C) 2009 Wind River Systems Inc
+ * Copyright (C) 2004 Microtronix Datacom Ltd.
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#ifndef _ASM_NIOS2_TLB_H
+#define _ASM_NIOS2_TLB_H
+
+#define tlb_flush(tlb)	flush_tlb_mm((tlb)->mm)
+
+extern void set_mmu_pid(unsigned long pid);
+
+/*
+ * NiosII doesn't need any special per-pte or per-vma handling, except
+ * we need to flush cache for the area to be unmapped.
+ */
+#define tlb_start_vma(tlb, vma)					\
+	do {							\
+		if (!tlb->fullmm)				\
+			flush_cache_range(vma, vma->vm_start, vma->vm_end); \
+	}  while (0)
+
+#define tlb_end_vma(tlb, vma)	do { } while (0)
+#define __tlb_remove_tlb_entry(tlb, ptep, address)	do { } while (0)
+
+#include <linux/pagemap.h>
+#include <asm-generic/tlb.h>
+
+#endif /* _ASM_NIOS2_TLB_H */
