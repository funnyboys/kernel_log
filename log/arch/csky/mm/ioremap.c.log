commit 0055f67b596c3a8963192a42e25797b0e7fc0e92
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 13 11:41:57 2019 +0200

    csky: use generic ioremap
    
    Use the generic ioremap_prot and iounmap helpers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Guo Ren <guoren@kernel.org>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index ae78256a56fd..70c8268d3b2b 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -3,53 +3,8 @@
 
 #include <linux/export.h>
 #include <linux/mm.h>
-#include <linux/vmalloc.h>
 #include <linux/io.h>
 
-#include <asm/pgtable.h>
-
-static void __iomem *__ioremap_caller(phys_addr_t addr, size_t size,
-				      pgprot_t prot, void *caller)
-{
-	phys_addr_t last_addr;
-	unsigned long offset, vaddr;
-	struct vm_struct *area;
-
-	last_addr = addr + size - 1;
-	if (!size || last_addr < addr)
-		return NULL;
-
-	offset = addr & (~PAGE_MASK);
-	addr &= PAGE_MASK;
-	size = PAGE_ALIGN(size + offset);
-
-	area = get_vm_area_caller(size, VM_IOREMAP, caller);
-	if (!area)
-		return NULL;
-
-	vaddr = (unsigned long)area->addr;
-
-	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
-		free_vm_area(area);
-		return NULL;
-	}
-
-	return (void __iomem *)(vaddr + offset);
-}
-
-void __iomem *__ioremap(phys_addr_t phys_addr, size_t size, pgprot_t prot)
-{
-	return __ioremap_caller(phys_addr, size, prot,
-				__builtin_return_address(0));
-}
-EXPORT_SYMBOL(__ioremap);
-
-void iounmap(void __iomem *addr)
-{
-	vunmap((void *)((unsigned long)addr & PAGE_MASK));
-}
-EXPORT_SYMBOL(iounmap);
-
 pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
 			      unsigned long size, pgprot_t vma_prot)
 {

commit 1246b8146c550641b3217eef65792685ca2dcdc5
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 16 08:11:43 2019 +0200

    csky: remove ioremap_cache
    
    No driver that can be used on csky uses ioremap_cache, and this
    interface has been deprecated in favor of memremap.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Guo Ren <guoren@kernel.org>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index e13cd3497628..ae78256a56fd 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -44,13 +44,6 @@ void __iomem *__ioremap(phys_addr_t phys_addr, size_t size, pgprot_t prot)
 }
 EXPORT_SYMBOL(__ioremap);
 
-void __iomem *ioremap_cache(phys_addr_t phys_addr, size_t size)
-{
-	return __ioremap_caller(phys_addr, size, PAGE_KERNEL,
-				__builtin_return_address(0));
-}
-EXPORT_SYMBOL(ioremap_cache);
-
 void iounmap(void __iomem *addr)
 {
 	vunmap((void *)((unsigned long)addr & PAGE_MASK));

commit 5336c17928cc464845ff765ce45b368c22f848e0
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Thu Aug 15 16:24:56 2019 +0800

    csky: Fixup ioremap function losing
    
    Implement the following apis to meet usage in different scenarios.
    
     - ioremap          (NonCache + StrongOrder)
     - ioremap_nocache  (NonCache + StrongOrder)
     - ioremap_wc       (NonCache + WeakOrder  )
     - ioremap_cache    (   Cache + WeakOrder  )
    
    Also change flag VM_ALLOC to VM_IOREMAP in get_vm_area_caller.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Christoph Hellwig <hch@infradead.org>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index 48531115fd9d..e13cd3497628 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -8,12 +8,12 @@
 
 #include <asm/pgtable.h>
 
-void __iomem *ioremap(phys_addr_t addr, size_t size)
+static void __iomem *__ioremap_caller(phys_addr_t addr, size_t size,
+				      pgprot_t prot, void *caller)
 {
 	phys_addr_t last_addr;
 	unsigned long offset, vaddr;
 	struct vm_struct *area;
-	pgprot_t prot;
 
 	last_addr = addr + size - 1;
 	if (!size || last_addr < addr)
@@ -23,14 +23,12 @@ void __iomem *ioremap(phys_addr_t addr, size_t size)
 	addr &= PAGE_MASK;
 	size = PAGE_ALIGN(size + offset);
 
-	area = get_vm_area_caller(size, VM_ALLOC, __builtin_return_address(0));
+	area = get_vm_area_caller(size, VM_IOREMAP, caller);
 	if (!area)
 		return NULL;
 
 	vaddr = (unsigned long)area->addr;
 
-	prot = pgprot_noncached(PAGE_KERNEL);
-
 	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
 		free_vm_area(area);
 		return NULL;
@@ -38,7 +36,20 @@ void __iomem *ioremap(phys_addr_t addr, size_t size)
 
 	return (void __iomem *)(vaddr + offset);
 }
-EXPORT_SYMBOL(ioremap);
+
+void __iomem *__ioremap(phys_addr_t phys_addr, size_t size, pgprot_t prot)
+{
+	return __ioremap_caller(phys_addr, size, prot,
+				__builtin_return_address(0));
+}
+EXPORT_SYMBOL(__ioremap);
+
+void __iomem *ioremap_cache(phys_addr_t phys_addr, size_t size)
+{
+	return __ioremap_caller(phys_addr, size, PAGE_KERNEL,
+				__builtin_return_address(0));
+}
+EXPORT_SYMBOL(ioremap_cache);
 
 void iounmap(void __iomem *addr)
 {

commit 7f80fe207de9602aaff028c79345caa68c90cd31
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Tue Jul 30 14:43:22 2019 +0800

    csky: Fixup dma_alloc_coherent with PAGE_SO attribute
    
    This bug is from commit: 2b070ccdf8c0 (fixup abiv2 mmap(... O_SYNC)
    failed). In that patch we remove the _PAGE_SO for memory noncache
    mapping and this will cause problem when drivers use dma descriptors
    to control the transcations without dma_w/rmb().
    
    After referencing other archs' implementation, pgprot_writecombine is
    introduced for mmap(... O_SYNC).
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index 8473b6bdf512..48531115fd9d 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -29,8 +29,7 @@ void __iomem *ioremap(phys_addr_t addr, size_t size)
 
 	vaddr = (unsigned long)area->addr;
 
-	prot = __pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE |
-			_PAGE_GLOBAL | _CACHE_UNCACHED | _PAGE_SO);
+	prot = pgprot_noncached(PAGE_KERNEL);
 
 	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
 		free_vm_area(area);
@@ -51,10 +50,9 @@ pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
 			      unsigned long size, pgprot_t vma_prot)
 {
 	if (!pfn_valid(pfn)) {
-		vma_prot.pgprot |= _PAGE_SO;
 		return pgprot_noncached(vma_prot);
 	} else if (file->f_flags & O_SYNC) {
-		return pgprot_noncached(vma_prot);
+		return pgprot_writecombine(vma_prot);
 	}
 
 	return vma_prot;

commit 76d21d186a65523b08ea5f70302e2c29ee8f6a8d
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Wed Jan 30 20:13:11 2019 +0800

    csky: Fixup io-range page attribute for mmap("/dev/mem")
    
    Some user space drivers need accessing IO address and IO remap need
    SO(strong order) page-attribute to make IO operation correct. So we
    need add SO-page-attr for all non-memory address.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Reported-by: Fan Xiaodong <xiaodong.fan@boyahualu.com>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index cb7c03e5cd21..8473b6bdf512 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -46,3 +46,17 @@ void iounmap(void __iomem *addr)
 	vunmap((void *)((unsigned long)addr & PAGE_MASK));
 }
 EXPORT_SYMBOL(iounmap);
+
+pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
+			      unsigned long size, pgprot_t vma_prot)
+{
+	if (!pfn_valid(pfn)) {
+		vma_prot.pgprot |= _PAGE_SO;
+		return pgprot_noncached(vma_prot);
+	} else if (file->f_flags & O_SYNC) {
+		return pgprot_noncached(vma_prot);
+	}
+
+	return vma_prot;
+}
+EXPORT_SYMBOL(phys_mem_access_prot);

commit 2b070ccdf8c020fb6c4911263852c021d8aa843c
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Sun Dec 30 21:47:28 2018 +0800

    csky: fixup abiv2 mmap(... O_SYNC) failed.
    
    Glibc function mmap(... O_SYNC) will make page to _PAGE_UNCACHE +
    _PAGE_SO and strong-order page couldn't support unalignment access.
    So remove _PAGE_SO from _PAGE_UNCACHE, also sync abiv1 with the macro
    of _PAGE_SO.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Reported-by: Liu Renwei <Renwei.Liu@verisilicon.com>
    Tested-by: Yuan Qiyun <qiyun_yuan@c-sky.com>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
index 7ad3ff103f4a..cb7c03e5cd21 100644
--- a/arch/csky/mm/ioremap.c
+++ b/arch/csky/mm/ioremap.c
@@ -30,7 +30,7 @@ void __iomem *ioremap(phys_addr_t addr, size_t size)
 	vaddr = (unsigned long)area->addr;
 
 	prot = __pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE |
-			_PAGE_GLOBAL | _CACHE_UNCACHED);
+			_PAGE_GLOBAL | _CACHE_UNCACHED | _PAGE_SO);
 
 	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
 		free_vm_area(area);

commit 013de2d6671d89de3397904749c86a69ac0686f7
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Wed Sep 5 14:25:12 2018 +0800

    csky: MMU and page table management
    
    This patch adds files related to memory management and here is our
    memory-layout:
    
       Fixmap       : 0xffc02000 – 0xfffff000       (4 MB - 12KB)
       Pkmap        : 0xff800000 – 0xffc00000       (4 MB)
       Vmalloc      : 0xf0200000 – 0xff000000       (238 MB)
       Lowmem       : 0x80000000 – 0xc0000000       (1GB)
    
    abiv1 CPU (CK610) is VIPT cache and it doesn't support highmem.
    abiv2 CPUs are all PIPT cache and they could support highmem.
    
    Lowmem is directly mapped by msa0 & msa1 reg, and we needn't setup
    memory page table for it.
    
    Link:https://lore.kernel.org/lkml/20180518215548.GH17671@n2100.armlinux.org.uk/
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
new file mode 100644
index 000000000000..7ad3ff103f4a
--- /dev/null
+++ b/arch/csky/mm/ioremap.c
@@ -0,0 +1,48 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.
+
+#include <linux/export.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/io.h>
+
+#include <asm/pgtable.h>
+
+void __iomem *ioremap(phys_addr_t addr, size_t size)
+{
+	phys_addr_t last_addr;
+	unsigned long offset, vaddr;
+	struct vm_struct *area;
+	pgprot_t prot;
+
+	last_addr = addr + size - 1;
+	if (!size || last_addr < addr)
+		return NULL;
+
+	offset = addr & (~PAGE_MASK);
+	addr &= PAGE_MASK;
+	size = PAGE_ALIGN(size + offset);
+
+	area = get_vm_area_caller(size, VM_ALLOC, __builtin_return_address(0));
+	if (!area)
+		return NULL;
+
+	vaddr = (unsigned long)area->addr;
+
+	prot = __pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE |
+			_PAGE_GLOBAL | _CACHE_UNCACHED);
+
+	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
+		free_vm_area(area);
+		return NULL;
+	}
+
+	return (void __iomem *)(vaddr + offset);
+}
+EXPORT_SYMBOL(ioremap);
+
+void iounmap(void __iomem *addr)
+{
+	vunmap((void *)((unsigned long)addr & PAGE_MASK));
+}
+EXPORT_SYMBOL(iounmap);
