commit aefd9461d34a1b0a2acad0750c43216c1c27b9d4
Author: Guo Ren <guoren@linux.alibaba.com>
Date:   Sat Mar 28 19:14:37 2020 +0800

    csky: Fixup cpu speculative execution to IO area
    
    For the memory size ( > 512MB, < 1GB), the MSA setting is:
    
     - SSEG0: PHY_START        , PHY_START + 512MB
     - SSEG1: PHY_START + 512MB, PHY_START + 1GB
    
    But the real memory is no more than 1GB, there is a gap between the
    end size of memory and border of 1GB. CPU could speculatively
    execute to that gap and if the gap of the bus couldn't respond to
    the CPU request, then the crash will happen.
    
    Now make the setting with:
    
     - SSEG0: PHY_START        , PHY_START + 512MB (no change)
     - SSEG1: Disabled (We use highmem to use the memory of 512MB~1GB)
    
    We also deprecated zhole_szie[] settings, it's only used by arm
    style CPUs. All memory gap should use Reserved setting of dts in
    csky system.
    
    Signed-off-by: Guo Ren <guoren@linux.alibaba.com>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index df2e2174dbd0..b5c5bc3afeb5 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -159,6 +159,8 @@ volatile unsigned int secondary_hint;
 volatile unsigned int secondary_ccr;
 volatile unsigned int secondary_stack;
 
+unsigned long secondary_msa1;
+
 int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	unsigned long mask = 1 << cpu;
@@ -167,6 +169,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 		(unsigned int) task_stack_page(tidle) + THREAD_SIZE - 8;
 	secondary_hint = mfcr("cr31");
 	secondary_ccr  = mfcr("cr18");
+	secondary_msa1 = read_mmu_msa1();
 
 	/*
 	 * Because other CPUs are in reset status, we must flush data

commit 12879bda3c2a974b7e4fe199a9c21f0c5f6bca04
Author: Guo Ren <guoren@linux.alibaba.com>
Date:   Wed Feb 26 10:23:26 2020 +0800

    csky: Fixup init_fpu compile warning with __init
    
    WARNING: vmlinux.o(.text+0x2366): Section mismatch in reference from the
    function csky_start_secondary() to the function .init.text:init_fpu()
    
    The function csky_start_secondary() references
    the function __init init_fpu().
    This is often because csky_start_secondary lacks a __init
    annotation or the annotation of init_fpu is wrong.
    
    Reported-by: Lu Chongzhi <chongzhi.lcz@alibaba-inc.com>
    Signed-off-by: Guo Ren <guoren@linux.alibaba.com>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index 0bb0954d5570..df2e2174dbd0 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -22,6 +22,9 @@
 #include <asm/sections.h>
 #include <asm/mmu_context.h>
 #include <asm/pgalloc.h>
+#ifdef CONFIG_CPU_HAS_FPU
+#include <abi/fpu.h>
+#endif
 
 struct ipi_data_struct {
 	unsigned long bits ____cacheline_aligned;

commit c9492737b25ca32679ba3163609d938c9abfd508
Author: Guo Ren <guoren@linux.alibaba.com>
Date:   Tue Jan 7 12:21:25 2020 +0800

    csky/smp: Fixup boot failed when CONFIG_SMP
    
    If we use a non-ipi-support interrupt controller, it will cause panic here.
    We should let cpu up and work with CONFIG_SMP, when we use a non-ipi intc.
    
    Signed-off-by: Guo Ren <guoren@linux.alibaba.com>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index b753d382e4ce..0bb0954d5570 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -120,7 +120,7 @@ void __init setup_smp_ipi(void)
 	int rc;
 
 	if (ipi_irq == 0)
-		panic("%s IRQ mapping failed\n", __func__);
+		return;
 
 	rc = request_percpu_irq(ipi_irq, handle_ipi, "IPI Interrupt",
 				&ipi_dummy_dev);

commit 9d35dc3006a9865eb5b55cc79df49933601131f8
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Tue Jun 18 17:20:10 2019 +0800

    csky: Revert mmu ASID mechanism
    
    Current C-SKY ASID mechanism is from mips and it doesn't work well
    with multi-cores. ASID per core mechanism is not suitable for C-SKY
    SMP tlb maintain operations, eg: tlbi.vas need share the same asid
    in all processors and it'll invalid the tlb entry in all cores with
    the same asid.
    
    This patch is prepare for new ASID mechanism.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Cc: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index b07a534b3062..b753d382e4ce 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -212,8 +212,6 @@ void csky_start_secondary(void)
 	TLBMISS_HANDLER_SETUP_PGD(swapper_pg_dir);
 	TLBMISS_HANDLER_SETUP_PGD_KERNEL(swapper_pg_dir);
 
-	asid_cache(smp_processor_id()) = ASID_FIRST_VERSION;
-
 #ifdef CONFIG_CPU_HAS_FPU
 	init_fpu();
 #endif

commit 0f231dcfc664aaafa75a006ee10e55f3ae0c9b3c
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Thu Jan 24 22:43:58 2019 +0800

    csky: coding convention: Use task_stack_page
    
    Use task_stack_page instead of p->stack to get stack. Follow the coding
    convention style. Also for init_stack, the same with other archs.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index ddc4dd79f282..b07a534b3062 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -160,7 +160,8 @@ int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	unsigned long mask = 1 << cpu;
 
-	secondary_stack = (unsigned int)tidle->stack + THREAD_SIZE - 8;
+	secondary_stack =
+		(unsigned int) task_stack_page(tidle) + THREAD_SIZE - 8;
 	secondary_hint = mfcr("cr31");
 	secondary_ccr  = mfcr("cr18");
 

commit 859e5f45cbb33fe5d591a8e429667f0b7d4f4be8
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Wed Dec 19 19:56:14 2018 +0800

    csky: CPU-hotplug supported for SMP
    
    This is a simple implement of CPU-hotplug for power saving. CPU use
    wait instruction to enter power saving mode and waiting for IPI wakeup
    signal.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index 74d627300c55..ddc4dd79f282 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -16,6 +16,7 @@
 #include <linux/of.h>
 #include <linux/sched/task_stack.h>
 #include <linux/sched/mm.h>
+#include <linux/sched/hotplug.h>
 #include <asm/irq.h>
 #include <asm/traps.h>
 #include <asm/sections.h>
@@ -112,12 +113,8 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 {
 }
 
-static void __init enable_smp_ipi(void)
-{
-	enable_percpu_irq(ipi_irq, 0);
-}
-
 static int ipi_dummy_dev;
+
 void __init setup_smp_ipi(void)
 {
 	int rc;
@@ -130,7 +127,7 @@ void __init setup_smp_ipi(void)
 	if (rc)
 		panic("%s IRQ request failed\n", __func__);
 
-	enable_smp_ipi();
+	enable_percpu_irq(ipi_irq, 0);
 }
 
 void __init setup_smp(void)
@@ -161,12 +158,10 @@ volatile unsigned int secondary_stack;
 
 int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
-	unsigned int tmp;
-
-	secondary_stack = (unsigned int)tidle->stack + THREAD_SIZE;
+	unsigned long mask = 1 << cpu;
 
+	secondary_stack = (unsigned int)tidle->stack + THREAD_SIZE - 8;
 	secondary_hint = mfcr("cr31");
-
 	secondary_ccr  = mfcr("cr18");
 
 	/*
@@ -176,10 +171,13 @@ int __cpu_up(unsigned int cpu, struct task_struct *tidle)
 	 */
 	mtcr("cr17", 0x22);
 
-	/* Enable cpu in SMP reset ctrl reg */
-	tmp = mfcr("cr<29, 0>");
-	tmp |= 1 << cpu;
-	mtcr("cr<29, 0>", tmp);
+	if (mask & mfcr("cr<29, 0>")) {
+		send_arch_ipi(cpumask_of(cpu));
+	} else {
+		/* Enable cpu in SMP reset ctrl reg */
+		mask |= mfcr("cr<29, 0>");
+		mtcr("cr<29, 0>", mask);
+	}
 
 	/* Wait for the cpu online */
 	while (!cpu_online(cpu));
@@ -219,7 +217,7 @@ void csky_start_secondary(void)
 	init_fpu();
 #endif
 
-	enable_smp_ipi();
+	enable_percpu_irq(ipi_irq, 0);
 
 	mmget(mm);
 	mmgrab(mm);
@@ -235,3 +233,46 @@ void csky_start_secondary(void)
 	preempt_disable();
 	cpu_startup_entry(CPUHP_AP_ONLINE_IDLE);
 }
+
+#ifdef CONFIG_HOTPLUG_CPU
+int __cpu_disable(void)
+{
+	unsigned int cpu = smp_processor_id();
+
+	set_cpu_online(cpu, false);
+
+	irq_migrate_all_off_this_cpu();
+
+	clear_tasks_mm_cpumask(cpu);
+
+	return 0;
+}
+
+void __cpu_die(unsigned int cpu)
+{
+	if (!cpu_wait_death(cpu, 5)) {
+		pr_crit("CPU%u: shutdown failed\n", cpu);
+		return;
+	}
+	pr_notice("CPU%u: shutdown\n", cpu);
+}
+
+void arch_cpu_idle_dead(void)
+{
+	idle_task_exit();
+
+	cpu_report_death();
+
+	while (!secondary_stack)
+		arch_cpu_idle();
+
+	local_irq_disable();
+
+	asm volatile(
+		"mov	sp, %0\n"
+		"mov	r8, %0\n"
+		"jmpi	csky_start_secondary"
+		:
+		: "r" (secondary_stack));
+}
+#endif

commit 398539dd69341f8e3b87b8fea9355c7edfb6d99a
Author: Yangtao Li <tiny.windzz@gmail.com>
Date:   Thu Dec 27 12:45:51 2018 -0500

    csky: Don't leak device tree node reference
    
    of_find_node_by_type() acquires a reference to the node returned by it
    and that reference needs to be dropped by its caller. setup_smp()
    doesn't do that, so fix it by converting to for_each_of_cpu_node().
    
    Signed-off-by: Yangtao Li <tiny.windzz@gmail.com>
    Signed-off-by: Guo Ren <guoren@kernel.org>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
index 36ebaf9834e1..74d627300c55 100644
--- a/arch/csky/kernel/smp.c
+++ b/arch/csky/kernel/smp.c
@@ -138,7 +138,7 @@ void __init setup_smp(void)
 	struct device_node *node = NULL;
 	int cpu;
 
-	while ((node = of_find_node_by_type(node, "cpu"))) {
+	for_each_of_cpu_node(node) {
 		if (!of_device_is_available(node))
 			continue;
 

commit 991069865796f8ad31ee54aca8a0f1b7a522e94b
Author: Guo Ren <ren_guo@c-sky.com>
Date:   Wed Sep 5 14:25:20 2018 +0800

    csky: SMP support
    
    This patch adds boot, ipi, hotplug codes for SMP.
    
    Signed-off-by: Guo Ren <ren_guo@c-sky.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/csky/kernel/smp.c b/arch/csky/kernel/smp.c
new file mode 100644
index 000000000000..36ebaf9834e1
--- /dev/null
+++ b/arch/csky/kernel/smp.c
@@ -0,0 +1,237 @@
+// SPDX-License-Identifier: GPL-2.0
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+#include <linux/kernel_stat.h>
+#include <linux/notifier.h>
+#include <linux/cpu.h>
+#include <linux/percpu.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/irq.h>
+#include <linux/irqdomain.h>
+#include <linux/of.h>
+#include <linux/sched/task_stack.h>
+#include <linux/sched/mm.h>
+#include <asm/irq.h>
+#include <asm/traps.h>
+#include <asm/sections.h>
+#include <asm/mmu_context.h>
+#include <asm/pgalloc.h>
+
+struct ipi_data_struct {
+	unsigned long bits ____cacheline_aligned;
+};
+static DEFINE_PER_CPU(struct ipi_data_struct, ipi_data);
+
+enum ipi_message_type {
+	IPI_EMPTY,
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_MAX
+};
+
+static irqreturn_t handle_ipi(int irq, void *dev)
+{
+	while (true) {
+		unsigned long ops;
+
+		ops = xchg(&this_cpu_ptr(&ipi_data)->bits, 0);
+		if (ops == 0)
+			return IRQ_HANDLED;
+
+		if (ops & (1 << IPI_RESCHEDULE))
+			scheduler_ipi();
+
+		if (ops & (1 << IPI_CALL_FUNC))
+			generic_smp_call_function_interrupt();
+
+		BUG_ON((ops >> IPI_MAX) != 0);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void (*send_arch_ipi)(const struct cpumask *mask);
+
+static int ipi_irq;
+void __init set_send_ipi(void (*func)(const struct cpumask *mask), int irq)
+{
+	if (send_arch_ipi)
+		return;
+
+	send_arch_ipi = func;
+	ipi_irq = irq;
+}
+
+static void
+send_ipi_message(const struct cpumask *to_whom, enum ipi_message_type operation)
+{
+	int i;
+
+	for_each_cpu(i, to_whom)
+		set_bit(operation, &per_cpu_ptr(&ipi_data, i)->bits);
+
+	smp_mb();
+	send_arch_ipi(to_whom);
+}
+
+void arch_send_call_function_ipi_mask(struct cpumask *mask)
+{
+	send_ipi_message(mask, IPI_CALL_FUNC);
+}
+
+void arch_send_call_function_single_ipi(int cpu)
+{
+	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC);
+}
+
+static void ipi_stop(void *unused)
+{
+	while (1);
+}
+
+void smp_send_stop(void)
+{
+	on_each_cpu(ipi_stop, NULL, 1);
+}
+
+void smp_send_reschedule(int cpu)
+{
+	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
+}
+
+void __init smp_prepare_boot_cpu(void)
+{
+}
+
+void __init smp_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+static void __init enable_smp_ipi(void)
+{
+	enable_percpu_irq(ipi_irq, 0);
+}
+
+static int ipi_dummy_dev;
+void __init setup_smp_ipi(void)
+{
+	int rc;
+
+	if (ipi_irq == 0)
+		panic("%s IRQ mapping failed\n", __func__);
+
+	rc = request_percpu_irq(ipi_irq, handle_ipi, "IPI Interrupt",
+				&ipi_dummy_dev);
+	if (rc)
+		panic("%s IRQ request failed\n", __func__);
+
+	enable_smp_ipi();
+}
+
+void __init setup_smp(void)
+{
+	struct device_node *node = NULL;
+	int cpu;
+
+	while ((node = of_find_node_by_type(node, "cpu"))) {
+		if (!of_device_is_available(node))
+			continue;
+
+		if (of_property_read_u32(node, "reg", &cpu))
+			continue;
+
+		if (cpu >= NR_CPUS)
+			continue;
+
+		set_cpu_possible(cpu, true);
+		set_cpu_present(cpu, true);
+	}
+}
+
+extern void _start_smp_secondary(void);
+
+volatile unsigned int secondary_hint;
+volatile unsigned int secondary_ccr;
+volatile unsigned int secondary_stack;
+
+int __cpu_up(unsigned int cpu, struct task_struct *tidle)
+{
+	unsigned int tmp;
+
+	secondary_stack = (unsigned int)tidle->stack + THREAD_SIZE;
+
+	secondary_hint = mfcr("cr31");
+
+	secondary_ccr  = mfcr("cr18");
+
+	/*
+	 * Because other CPUs are in reset status, we must flush data
+	 * from cache to out and secondary CPUs use them in
+	 * csky_start_secondary(void)
+	 */
+	mtcr("cr17", 0x22);
+
+	/* Enable cpu in SMP reset ctrl reg */
+	tmp = mfcr("cr<29, 0>");
+	tmp |= 1 << cpu;
+	mtcr("cr<29, 0>", tmp);
+
+	/* Wait for the cpu online */
+	while (!cpu_online(cpu));
+
+	secondary_stack = 0;
+
+	return 0;
+}
+
+void __init smp_cpus_done(unsigned int max_cpus)
+{
+}
+
+int setup_profiling_timer(unsigned int multiplier)
+{
+	return -EINVAL;
+}
+
+void csky_start_secondary(void)
+{
+	struct mm_struct *mm = &init_mm;
+	unsigned int cpu = smp_processor_id();
+
+	mtcr("cr31", secondary_hint);
+	mtcr("cr18", secondary_ccr);
+
+	mtcr("vbr", vec_base);
+
+	flush_tlb_all();
+	write_mmu_pagemask(0);
+	TLBMISS_HANDLER_SETUP_PGD(swapper_pg_dir);
+	TLBMISS_HANDLER_SETUP_PGD_KERNEL(swapper_pg_dir);
+
+	asid_cache(smp_processor_id()) = ASID_FIRST_VERSION;
+
+#ifdef CONFIG_CPU_HAS_FPU
+	init_fpu();
+#endif
+
+	enable_smp_ipi();
+
+	mmget(mm);
+	mmgrab(mm);
+	current->active_mm = mm;
+	cpumask_set_cpu(cpu, mm_cpumask(mm));
+
+	notify_cpu_starting(cpu);
+	set_cpu_online(cpu, true);
+
+	pr_info("CPU%u Online: %s...\n", cpu, __func__);
+
+	local_irq_enable();
+	preempt_disable();
+	cpu_startup_entry(CPUHP_AP_ONLINE_IDLE);
+}
