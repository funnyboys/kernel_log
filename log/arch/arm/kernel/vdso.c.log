commit c1e8d7c6a7a682e1405e3e242d32fc377fd196ff
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:54 2020 -0700

    mmap locking API: convert mmap_sem comments
    
    Convert comments that reference mmap_sem to reference mmap_lock instead.
    
    [akpm@linux-foundation.org: fix up linux-next leftovers]
    [akpm@linux-foundation.org: s/lockaphore/lock/, per Vlastimil]
    [akpm@linux-foundation.org: more linux-next fixups, per Michel]
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-13-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index e0330a25e1c6..6bfdca4769a7 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -240,7 +240,7 @@ static int install_vvar(struct mm_struct *mm, unsigned long addr)
 	return PTR_ERR_OR_ZERO(vma);
 }
 
-/* assumes mmap_sem is write-locked */
+/* assumes mmap_lock is write-locked */
 void arm_install_vdso(struct mm_struct *mm, unsigned long addr)
 {
 	struct vm_area_struct *vma;

commit 45939ce292b4b11159719faaf60aba7d58d5fe33
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index c89ac1b9d28b..e0330a25e1c6 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -94,6 +94,8 @@ static bool __init cntvct_functional(void)
 	 * this.
 	 */
 	np = of_find_compatible_node(NULL, NULL, "arm,armv7-timer");
+	if (!np)
+		np = of_find_compatible_node(NULL, NULL, "arm,armv8-timer");
 	if (!np)
 		goto out_put;
 

commit 20e2fc42312f960f497ac2d617e3742754e1fa5e
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Mon Nov 4 11:59:59 2019 +0100

    ARM: 8930/1: Add support for generic vDSO
    
    The arm vDSO library requires some adaptations to take advantage of
    the newly introduced generic vDSO library.
    
    Introduce the following changes:
     - Modification vdso.c to be compliant with the common vdso datapage
     - Use of lib/vdso for gettimeofday
     - Implementation of elf note
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 9bf16c93ee6a..c89ac1b9d28b 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -23,6 +23,8 @@
 #include <asm/vdso.h>
 #include <asm/vdso_datapage.h>
 #include <clocksource/arm_arch_timer.h>
+#include <vdso/helpers.h>
+#include <vdso/vsyscall.h>
 
 #define MAX_SYMNAME	64
 
@@ -37,7 +39,7 @@ unsigned int vdso_total_pages __ro_after_init;
  * The VDSO data page.
  */
 static union vdso_data_store vdso_data_store __page_aligned_data;
-static struct vdso_data *vdso_data = &vdso_data_store.data;
+struct vdso_data *vdso_data = vdso_data_store.data;
 
 static struct page *vdso_data_page __ro_after_init;
 static const struct vm_special_mapping vdso_data_mapping = {
@@ -77,7 +79,7 @@ struct elfinfo {
 /* Cached result of boot-time check for whether the arch timer exists,
  * and if so, whether the virtual counter is useable.
  */
-static bool cntvct_ok __ro_after_init;
+bool cntvct_ok __ro_after_init;
 
 static bool __init cntvct_functional(void)
 {
@@ -262,84 +264,3 @@ void arm_install_vdso(struct mm_struct *mm, unsigned long addr)
 		mm->context.vdso = addr;
 }
 
-static void vdso_write_begin(struct vdso_data *vdata)
-{
-	++vdso_data->seq_count;
-	smp_wmb(); /* Pairs with smp_rmb in vdso_read_retry */
-}
-
-static void vdso_write_end(struct vdso_data *vdata)
-{
-	smp_wmb(); /* Pairs with smp_rmb in vdso_read_begin */
-	++vdso_data->seq_count;
-}
-
-static bool tk_is_cntvct(const struct timekeeper *tk)
-{
-	if (!IS_ENABLED(CONFIG_ARM_ARCH_TIMER))
-		return false;
-
-	if (!tk->tkr_mono.clock->archdata.vdso_direct)
-		return false;
-
-	return true;
-}
-
-/**
- * update_vsyscall - update the vdso data page
- *
- * Increment the sequence counter, making it odd, indicating to
- * userspace that an update is in progress.  Update the fields used
- * for coarse clocks and, if the architected system timer is in use,
- * the fields used for high precision clocks.  Increment the sequence
- * counter again, making it even, indicating to userspace that the
- * update is finished.
- *
- * Userspace is expected to sample seq_count before reading any other
- * fields from the data page.  If seq_count is odd, userspace is
- * expected to wait until it becomes even.  After copying data from
- * the page, userspace must sample seq_count again; if it has changed
- * from its previous value, userspace must retry the whole sequence.
- *
- * Calls to update_vsyscall are serialized by the timekeeping core.
- */
-void update_vsyscall(struct timekeeper *tk)
-{
-	struct timespec64 *wtm = &tk->wall_to_monotonic;
-
-	if (!cntvct_ok) {
-		/* The entry points have been zeroed, so there is no
-		 * point in updating the data page.
-		 */
-		return;
-	}
-
-	vdso_write_begin(vdso_data);
-
-	vdso_data->tk_is_cntvct			= tk_is_cntvct(tk);
-	vdso_data->xtime_coarse_sec		= tk->xtime_sec;
-	vdso_data->xtime_coarse_nsec		= (u32)(tk->tkr_mono.xtime_nsec >>
-							tk->tkr_mono.shift);
-	vdso_data->wtm_clock_sec		= wtm->tv_sec;
-	vdso_data->wtm_clock_nsec		= wtm->tv_nsec;
-
-	if (vdso_data->tk_is_cntvct) {
-		vdso_data->cs_cycle_last	= tk->tkr_mono.cycle_last;
-		vdso_data->xtime_clock_sec	= tk->xtime_sec;
-		vdso_data->xtime_clock_snsec	= tk->tkr_mono.xtime_nsec;
-		vdso_data->cs_mult		= tk->tkr_mono.mult;
-		vdso_data->cs_shift		= tk->tkr_mono.shift;
-		vdso_data->cs_mask		= tk->tkr_mono.mask;
-	}
-
-	vdso_write_end(vdso_data);
-
-	flush_dcache_page(virt_to_page(vdso_data));
-}
-
-void update_vsyscall_tz(void)
-{
-	vdso_data->tz_minuteswest	= sys_tz.tz_minuteswest;
-	vdso_data->tz_dsttime		= sys_tz.tz_dsttime;
-	flush_dcache_page(virt_to_page(vdso_data));
-}

commit 3e07590e7248db951fed6a2039403b5a39010be7
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Wed Jul 31 12:38:48 2019 +0100

    ARM: 8896/1: VDSO: Don't leak kernel addresses
    
    Since commit ad67b74d2469d9b8 ("printk: hash addresses printed with
    %p"), an obfuscated kernel pointer is printed at every boot if
    debugging is enabled:
    
        vdso: 1 text pages at base (____ptrval____)
    
    Remove the print completely, as it's useless without the address.
    
    Based on commit 0f1bf7e39822476b ("arm64/vdso: don't leak kernel
    addresses").
    
    Fixes: ad67b74d2469d9b8 ("printk: hash addresses printed with %p")
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 8872acf9ff99..9bf16c93ee6a 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -194,7 +194,6 @@ static int __init vdso_init(void)
 	}
 
 	text_pages = (vdso_end - vdso_start) >> PAGE_SHIFT;
-	pr_debug("vdso: %i text pages at base %p\n", text_pages, vdso_start);
 
 	/* Allocate the VDSO text pagelist */
 	vdso_text_pagelist = kcalloc(text_pages, sizeof(struct page *),

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index f4dd7f9663c1..8872acf9ff99 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -1,20 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Adapted from arm64 version.
  *
  * Copyright (C) 2012 ARM Limited
  * Copyright (C) 2015 Mentor Graphics Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #include <linux/cache.h>

commit 73b9160d0dfe44dfdaffd6465dc1224c38a4a73c
Author: Jinbum Park <jinb.park7@gmail.com>
Date:   Tue Mar 6 01:37:21 2018 +0100

    ARM: 8748/1: mm: Define vdso_start, vdso_end as array
    
    Define vdso_start, vdso_end as array to avoid compile-time analysis error
    for the case of built with CONFIG_FORTIFY_SOURCE.
    
    and, since vdso_start, vdso_end are used in vdso.c only,
    move extern-declaration from vdso.h to vdso.c.
    
    If kernel is built with CONFIG_FORTIFY_SOURCE,
    compile-time error happens at this code.
    - if (memcmp(&vdso_start, "177ELF", 4))
    
    The size of "&vdso_start" is recognized as 1 byte, but n is 4,
    So that compile-time error is reported.
    
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Jinbum Park <jinb.park7@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index a4d6dc0f2427..f4dd7f9663c1 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -39,6 +39,8 @@
 
 static struct page **vdso_text_pagelist;
 
+extern char vdso_start[], vdso_end[];
+
 /* Total number of pages needed for the data and text portions of the VDSO. */
 unsigned int vdso_total_pages __ro_after_init;
 
@@ -197,13 +199,13 @@ static int __init vdso_init(void)
 	unsigned int text_pages;
 	int i;
 
-	if (memcmp(&vdso_start, "\177ELF", 4)) {
+	if (memcmp(vdso_start, "\177ELF", 4)) {
 		pr_err("VDSO is not a valid ELF object!\n");
 		return -ENOEXEC;
 	}
 
-	text_pages = (&vdso_end - &vdso_start) >> PAGE_SHIFT;
-	pr_debug("vdso: %i text pages at base %p\n", text_pages, &vdso_start);
+	text_pages = (vdso_end - vdso_start) >> PAGE_SHIFT;
+	pr_debug("vdso: %i text pages at base %p\n", text_pages, vdso_start);
 
 	/* Allocate the VDSO text pagelist */
 	vdso_text_pagelist = kcalloc(text_pages, sizeof(struct page *),
@@ -218,7 +220,7 @@ static int __init vdso_init(void)
 	for (i = 0; i < text_pages; i++) {
 		struct page *page;
 
-		page = virt_to_page(&vdso_start + i * PAGE_SIZE);
+		page = virt_to_page(vdso_start + i * PAGE_SIZE);
 		vdso_text_pagelist[i] = page;
 	}
 
@@ -229,7 +231,7 @@ static int __init vdso_init(void)
 
 	cntvct_ok = cntvct_functional();
 
-	patch_vdso(&vdso_start);
+	patch_vdso(vdso_start);
 
 	return 0;
 }

commit 280e87e98c09b85b617c7b2752c8b504c4ea98f6
Author: Dmitry Safonov <dsafonov@virtuozzo.com>
Date:   Mon Jun 19 17:32:42 2017 +0100

    ARM: 8683/1: ARM32: Support mremap() for sigpage/vDSO
    
    CRIU restores application mappings on the same place where they
    were before Checkpoint. That means, that we need to move vDSO
    and sigpage during restore on exactly the same place where
    they were before C/R.
    
    Make mremap() code update mm->context.{sigpage,vdso} pointers
    during VMA move. Sigpage is used for landing after handling
    a signal - if the pointer is not updated during moving, the
    application might crash on any signal after mremap().
    
    vDSO pointer on ARM32 is used only for setting auxv at this moment,
    update it during mremap() in case of future usage.
    
    Without those updates, current work of CRIU on ARM32 is not reliable.
    Historically, we error Checkpointing if we find vDSO page on ARM32
    and suggest user to disable CONFIG_VDSO.
    But that's not correct - it goes from x86 where signal processing
    is ended in vDSO blob. For arm32 it's sigpage, which is not disabled
    with `CONFIG_VDSO=n'.
    
    Looks like C/R was working by luck - because userspace on ARM32 at
    this moment always sets SA_RESTORER.
    
    Signed-off-by: Dmitry Safonov <dsafonov@virtuozzo.com>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Pavel Emelyanov <xemul@virtuozzo.com>
    Cc: Christopher Covington <cov@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 53cf86cf2d1a..a4d6dc0f2427 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -54,8 +54,26 @@ static const struct vm_special_mapping vdso_data_mapping = {
 	.pages = &vdso_data_page,
 };
 
+static int vdso_mremap(const struct vm_special_mapping *sm,
+		struct vm_area_struct *new_vma)
+{
+	unsigned long new_size = new_vma->vm_end - new_vma->vm_start;
+	unsigned long vdso_size;
+
+	/* without VVAR page */
+	vdso_size = (vdso_total_pages - 1) << PAGE_SHIFT;
+
+	if (vdso_size != new_size)
+		return -EINVAL;
+
+	current->mm->context.vdso = new_vma->vm_start;
+
+	return 0;
+}
+
 static struct vm_special_mapping vdso_text_mapping __ro_after_init = {
 	.name = "[vdso]",
+	.mremap = vdso_mremap,
 };
 
 struct elfinfo {

commit 82fa407da081d05323171577d86f62d77df17465
Merge: c7f5d36a3cc2 81a63001862f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 6 07:59:37 2016 -0700

    Merge branch 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - Correct ARMs dma-mapping to use the correct printk format strings.
    
     - Avoid defining OBJCOPYFLAGS globally which upsets lkdtm rodata
       testing.
    
     - Cleanups to ARMs asm/memory.h include.
    
     - L2 cache cleanups.
    
     - Allow flat nommu binaries to be executed on ARM MMU systems.
    
     - Kernel hardening - add more read-only after init annotations,
       including making some kernel vdso variables const.
    
     - Ensure AMBA primecell clocks are appropriately defaulted.
    
     - ARM breakpoint cleanup.
    
     - Various StrongARM 11x0 and companion chip (SA1111) updates to bring
       this legacy platform to use more modern APIs for (eg) GPIOs and
       interrupts, which will allow us in the future to reduce some of the
       board-level driver clutter and elimate function callbacks into board
       code via platform data. There still appears to be interest in these
       platforms!
    
     - Remove the now redundant secure_flush_area() API.
    
     - Module PLT relocation optimisations. Ard says: This series of 4
       patches optimizes the ARM PLT generation code that is invoked at
       module load time, to get rid of the O(n^2) algorithm that results in
       pathological load times of 10 seconds or more for large modules on
       certain STB platforms.
    
     - ARMv7M cache maintanence support.
    
     - L2 cache PMU support
    
    * 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (35 commits)
      ARM: sa1111: provide to_sa1111_device() macro
      ARM: sa1111: add sa1111_get_irq()
      ARM: sa1111: clean up duplication in IRQ chip implementation
      ARM: sa1111: implement a gpio_chip for SA1111 GPIOs
      ARM: sa1111: move irq cleanup to separate function
      ARM: sa1111: use devm_clk_get()
      ARM: sa1111: use devm_kzalloc()
      ARM: sa1111: ensure we only touch RAB bus type devices when removing
      ARM: 8611/1: l2x0: add PMU support
      ARM: 8610/1: V7M: Add dsb before jumping in handler mode
      ARM: 8609/1: V7M: Add support for the Cortex-M7 processor
      ARM: 8608/1: V7M: Indirect proc_info construction for V7M CPUs
      ARM: 8607/1: V7M: Wire up caches for V7M processors with cache support.
      ARM: 8606/1: V7M: introduce cache operations
      ARM: 8605/1: V7M: fix notrace variant of save_and_disable_irqs
      ARM: 8604/1: V7M: Add support for reading the CTR with read_cpuid_cachetype()
      ARM: 8603/1: V7M: Add addresses for mem-mapped V7M cache operations
      ARM: 8602/1: factor out CSSELR/CCSIDR operations that use cp15 directly
      ARM: kernel: avoid brute force search on PLT generation
      ARM: kernel: sort relocation sections before allocating PLTs
      ...

commit 1d8f51d41fc7116f3753fe9f9a5dd93e0b550a2c
Author: Scott Wood <oss@buserror.net>
Date:   Thu Sep 22 03:35:18 2016 -0500

    arm/arm64: arch_timer: Use archdata to indicate vdso suitability
    
    Instead of comparing the name to a magic string, use archdata to
    explicitly communicate whether the arch timer is suitable for
    direct vdso access.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Scott Wood <oss@buserror.net>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 994e971a8538..a0affd14086a 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -270,7 +270,7 @@ static bool tk_is_cntvct(const struct timekeeper *tk)
 	if (!IS_ENABLED(CONFIG_ARM_ARCH_TIMER))
 		return false;
 
-	if (strcmp(tk->tkr_mono.clock->name, "arch_sys_counter") != 0)
+	if (!tk->tkr_mono.clock->archdata.vdso_direct)
 		return false;
 
 	return true;

commit 92bb8d5d55f7fe1a7a1201c42120c1611840807c
Author: Jisheng Zhang <jszhang@marvell.com>
Date:   Mon Aug 15 09:20:21 2016 +0100

    ARM: 8597/1: VDSO: put RO and RO after init objects into proper sections
    
    vdso_data_mapping is never modified, so mark it as const.
    
    vdso_total_pages, vdso_data_page, vdso_text_mapping and cntvct_ok are
    initialized by vdso_init(), thereafter are read only.
    
    The fact that they are read only after init makes them candidates for
    __ro_after_init declarations.
    
    Signed-off-by: Jisheng Zhang <jszhang@marvell.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 994e971a8538..bbbffe946122 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -17,6 +17,7 @@
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+#include <linux/cache.h>
 #include <linux/elf.h>
 #include <linux/err.h>
 #include <linux/kernel.h>
@@ -39,7 +40,7 @@
 static struct page **vdso_text_pagelist;
 
 /* Total number of pages needed for the data and text portions of the VDSO. */
-unsigned int vdso_total_pages __read_mostly;
+unsigned int vdso_total_pages __ro_after_init;
 
 /*
  * The VDSO data page.
@@ -47,13 +48,13 @@ unsigned int vdso_total_pages __read_mostly;
 static union vdso_data_store vdso_data_store __page_aligned_data;
 static struct vdso_data *vdso_data = &vdso_data_store.data;
 
-static struct page *vdso_data_page;
-static struct vm_special_mapping vdso_data_mapping = {
+static struct page *vdso_data_page __ro_after_init;
+static const struct vm_special_mapping vdso_data_mapping = {
 	.name = "[vvar]",
 	.pages = &vdso_data_page,
 };
 
-static struct vm_special_mapping vdso_text_mapping = {
+static struct vm_special_mapping vdso_text_mapping __ro_after_init = {
 	.name = "[vdso]",
 };
 
@@ -67,7 +68,7 @@ struct elfinfo {
 /* Cached result of boot-time check for whether the arch timer exists,
  * and if so, whether the virtual counter is useable.
  */
-static bool cntvct_ok __read_mostly;
+static bool cntvct_ok __ro_after_init;
 
 static bool __init cntvct_functional(void)
 {

commit 38fc2f6c98262913388de338d5b0cda67e3f78cd
Author: Prasanna Karthik <mkarthi3@visteon.com>
Date:   Tue Dec 8 17:30:25 2015 +0100

    ARM: 8476/1: VDSO: use PTR_ERR_OR_ZERO for vma check
    
    Use PTR_ERR_OR_ZERO rather than if(IS_ERR(...)) + PTR_ERR
    
    Signed-off-by: Prasanna Karthik <mkarthi3@visteon.com>
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index 54a5aeab988d..994e971a8538 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -224,7 +224,7 @@ static int install_vvar(struct mm_struct *mm, unsigned long addr)
 				       VM_READ | VM_MAYREAD,
 				       &vdso_data_mapping);
 
-	return IS_ERR(vma) ? PTR_ERR(vma) : 0;
+	return PTR_ERR_OR_ZERO(vma);
 }
 
 /* assumes mmap_sem is write-locked */

commit 09edea4f8fdeb4e292b80d493296070f5ec64e6e
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Mon Aug 10 17:36:06 2015 +0100

    ARM: 8410/1: VDSO: fix coarse clock monotonicity regression
    
    Since 906c55579a63 ("timekeeping: Copy the shadow-timekeeper over the
    real timekeeper last") it has become possible on ARM to:
    
    - Obtain a CLOCK_MONOTONIC_COARSE or CLOCK_REALTIME_COARSE timestamp
      via syscall.
    - Subsequently obtain a timestamp for the same clock ID via VDSO which
      predates the first timestamp (by one jiffy).
    
    This is because ARM's update_vsyscall is deriving the coarse time
    using the __current_kernel_time interface, when it should really be
    using the timekeeper object provided to it by the timekeeping core.
    It happened to work before only because __current_kernel_time would
    access the same timekeeper object which had been passed to
    update_vsyscall.  This is no longer the case.
    
    Cc: stable@vger.kernel.org
    Fixes: 906c55579a63 ("timekeeping: Copy the shadow-timekeeper over the real timekeeper last")
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
index efe17dd9b921..54a5aeab988d 100644
--- a/arch/arm/kernel/vdso.c
+++ b/arch/arm/kernel/vdso.c
@@ -296,7 +296,6 @@ static bool tk_is_cntvct(const struct timekeeper *tk)
  */
 void update_vsyscall(struct timekeeper *tk)
 {
-	struct timespec xtime_coarse;
 	struct timespec64 *wtm = &tk->wall_to_monotonic;
 
 	if (!cntvct_ok) {
@@ -308,10 +307,10 @@ void update_vsyscall(struct timekeeper *tk)
 
 	vdso_write_begin(vdso_data);
 
-	xtime_coarse = __current_kernel_time();
 	vdso_data->tk_is_cntvct			= tk_is_cntvct(tk);
-	vdso_data->xtime_coarse_sec		= xtime_coarse.tv_sec;
-	vdso_data->xtime_coarse_nsec		= xtime_coarse.tv_nsec;
+	vdso_data->xtime_coarse_sec		= tk->xtime_sec;
+	vdso_data->xtime_coarse_nsec		= (u32)(tk->tkr_mono.xtime_nsec >>
+							tk->tkr_mono.shift);
 	vdso_data->wtm_clock_sec		= wtm->tv_sec;
 	vdso_data->wtm_clock_nsec		= wtm->tv_nsec;
 

commit bb0fd7ab0986105765d11baa82e619c618a235aa
Merge: bdfa54dfd9ee 4b2f8838479e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 14 21:03:26 2015 -0700

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "Included in this update are both some long term fixes and some new
      features.
    
      Fixes:
    
       - An integer overflow in the calculation of ELF_ET_DYN_BASE.
    
       - Avoiding OOMs for high-order IOMMU allocations
    
       - SMP requires the data cache to be enabled for synchronisation
         primitives to work, so prevent the CPU_DCACHE_DISABLE option being
         visible on SMP builds.
    
       - A bug going back 10+ years in the noMMU ARM94* CPU support code,
         where it corrupts registers.  Found by folk getting Linux running
         on their cameras.
    
       - Versatile Express needs an errata workaround enabled for CPU
         hot-unplug to work.
    
      Features:
    
       - Clean up module linker by handling out of range relocations
         separately from relocation cases we don't handle.
    
       - Fix a long term bug in the pci_mmap_page_range() code, which we
         hope won't impact userspace (we hope there's no users of the
         existing broken interface.)
    
       - Don't map DMA coherent allocations when we don't have a MMU.
    
       - Drop experimental status for SMP_ON_UP.
    
       - Warn when DT doesn't specify ePAPR mandatory cache properties.
    
       - Add documentation concerning how we find the start of physical
         memory for AUTO_ZRELADDR kernels, detailing why we have chosen the
         mask and the implications of changing it.
    
       - Updates from Ard Biesheuvel to address some issues with large
         kernels (such as allyesconfig) failing to link.
    
       - Allow hibernation to work on modern (ARMv7) CPUs - this appears to
         have never worked in the past on these CPUs.
    
       - Enable IRQ_SHOW_LEVEL, which changes the /proc/interrupts output
         format (hopefully without userspace breaking...  let's hope that if
         it causes someone a problem, they tell us.)
    
       - Fix tegra-ahb DT offsets.
    
       - Rework ARM errata 643719 code (and ARMv7 flush_cache_louis()/
         flush_dcache_all()) code to be more efficient, and enable this
         errata workaround by default for ARMv7+SMP CPUs.  This complements
         the Versatile Express fix above.
    
       - Rework ARMv7 context code for errata 430973, so that only Cortex A8
         CPUs are impacted by the branch target buffer flush when this
         errata is enabled.  Also update the help text to indicate that all
         r1p* A8 CPUs are impacted.
    
       - Switch ARM to the generic show_mem() implementation, it conveys all
         the information which we were already reporting.
    
       - Prevent slow timer sources being used for udelay() - timers running
         at less than 1MHz are not useful for this, and can cause udelay()
         to return immediately, without any wait.  Using such a slow timer
         is silly.
    
       - VDSO support for 32-bit ARM, mainly for gettimeofday() using the
         ARM architected timer.
    
       - Perf support for Scorpion performance monitoring units"
    
    vdso semantic conflict fixed up as per linux-next.
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (52 commits)
      ARM: update errata 430973 documentation to cover Cortex A8 r1p*
      ARM: ensure delay timer has sufficient accuracy for delays
      ARM: switch to use the generic show_mem() implementation
      ARM: proc-v7: avoid errata 430973 workaround for non-Cortex A8 CPUs
      ARM: enable ARM errata 643719 workaround by default
      ARM: cache-v7: optimise test for Cortex A9 r0pX devices
      ARM: cache-v7: optimise branches in v7_flush_cache_louis
      ARM: cache-v7: consolidate initialisation of cache level index
      ARM: cache-v7: shift CLIDR to extract appropriate field before masking
      ARM: cache-v7: use movw/movt instructions
      ARM: allow 16-bit instructions in ALT_UP()
      ARM: proc-arm94*.S: fix setup function
      ARM: vexpress: fix CPU hotplug with CT9x4 tile.
      ARM: 8276/1: Make CPU_DCACHE_DISABLE depend on !SMP
      ARM: 8335/1: Documentation: DT bindings: Tegra AHB: document the legacy base address
      ARM: 8334/1: amba: tegra-ahb: detect and correct bogus base address
      ARM: 8333/1: amba: tegra-ahb: fix register offsets in the macros
      ARM: 8339/1: Enable CONFIG_GENERIC_IRQ_SHOW_LEVEL
      ARM: 8338/1: kexec: Relax SMP validation to improve DT compatibility
      ARM: 8337/1: mm: Do not invoke OOM for higher order IOMMU DMA allocations
      ...

commit ecf99a439105ebd0a507af1a9cd901a2e166bf9a
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Mar 25 19:15:08 2015 +0100

    ARM: 8331/1: VDSO initialization, mapping, and synchronization
    
    Initialize the VDSO page list at boot, install the VDSO mapping at
    exec time, and update the data page during timer ticks.  This code is
    not built if CONFIG_VDSO is not enabled.
    
    Account for the VDSO length when randomizing the offset from the
    stack.  The [vdso] and [vvar] pages are placed immediately following
    the sigpage with separate _install_special_mapping calls.
    
    We want to "penalize" systems lacking the arch timer as little
    as possible.  Previous versions of this code installed the VDSO
    unconditionally and unmodified, making it a measurably slower way for
    glibc to invoke the real syscalls on such systems.  E.g. calling
    gettimeofday via glibc goes from ~560ns to ~630ns on i.MX6Q.
    
    If we can indicate to glibc that the time-related APIs in the VDSO are
    not accelerated, glibc can continue to invoke the syscalls directly
    instead of dispatching through the VDSO only to fall back to the slow
    path.
    
    Thus, if the architected timer is unusable for whatever reason, patch
    the VDSO at boot time so that symbol lookups for gettimeofday and
    clock_gettime return NULL.  (This is similar to what powerpc does and
    borrows code from there.)  This allows glibc to perform the syscall
    directly instead of passing control to the VDSO, which minimizes the
    penalty.  In my measurements the time taken for a gettimeofday call
    via glibc goes from ~560ns to ~580ns (again on i.MX6Q), and this is
    solely due to adding a test and branch to glibc's gettimeofday syscall
    wrapper.
    
    An alternative to patching the VDSO at boot would be to not install
    the VDSO at all when the arch timer isn't usable.  Another alternative
    is to include a separate "dummy" vdso.so without gettimeofday and
    clock_gettime, which would be selected at boot time.  Either of these
    would get cumbersome if the VDSO were to gain support for an API such
    as getcpu which is unrelated to arch timer support.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/vdso.c b/arch/arm/kernel/vdso.c
new file mode 100644
index 000000000000..0d31d3ccab81
--- /dev/null
+++ b/arch/arm/kernel/vdso.c
@@ -0,0 +1,337 @@
+/*
+ * Adapted from arm64 version.
+ *
+ * Copyright (C) 2012 ARM Limited
+ * Copyright (C) 2015 Mentor Graphics Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/elf.h>
+#include <linux/err.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/of.h>
+#include <linux/printk.h>
+#include <linux/slab.h>
+#include <linux/timekeeper_internal.h>
+#include <linux/vmalloc.h>
+#include <asm/arch_timer.h>
+#include <asm/barrier.h>
+#include <asm/cacheflush.h>
+#include <asm/page.h>
+#include <asm/vdso.h>
+#include <asm/vdso_datapage.h>
+#include <clocksource/arm_arch_timer.h>
+
+#define MAX_SYMNAME	64
+
+static struct page **vdso_text_pagelist;
+
+/* Total number of pages needed for the data and text portions of the VDSO. */
+unsigned int vdso_total_pages __read_mostly;
+
+/*
+ * The VDSO data page.
+ */
+static union vdso_data_store vdso_data_store __page_aligned_data;
+static struct vdso_data *vdso_data = &vdso_data_store.data;
+
+static struct page *vdso_data_page;
+static struct vm_special_mapping vdso_data_mapping = {
+	.name = "[vvar]",
+	.pages = &vdso_data_page,
+};
+
+static struct vm_special_mapping vdso_text_mapping = {
+	.name = "[vdso]",
+};
+
+struct elfinfo {
+	Elf32_Ehdr	*hdr;		/* ptr to ELF */
+	Elf32_Sym	*dynsym;	/* ptr to .dynsym section */
+	unsigned long	dynsymsize;	/* size of .dynsym section */
+	char		*dynstr;	/* ptr to .dynstr section */
+};
+
+/* Cached result of boot-time check for whether the arch timer exists,
+ * and if so, whether the virtual counter is useable.
+ */
+static bool cntvct_ok __read_mostly;
+
+static bool __init cntvct_functional(void)
+{
+	struct device_node *np;
+	bool ret = false;
+
+	if (!IS_ENABLED(CONFIG_ARM_ARCH_TIMER))
+		goto out;
+
+	/* The arm_arch_timer core should export
+	 * arch_timer_use_virtual or similar so we don't have to do
+	 * this.
+	 */
+	np = of_find_compatible_node(NULL, NULL, "arm,armv7-timer");
+	if (!np)
+		goto out_put;
+
+	if (of_property_read_bool(np, "arm,cpu-registers-not-fw-configured"))
+		goto out_put;
+
+	ret = true;
+
+out_put:
+	of_node_put(np);
+out:
+	return ret;
+}
+
+static void * __init find_section(Elf32_Ehdr *ehdr, const char *name,
+				  unsigned long *size)
+{
+	Elf32_Shdr *sechdrs;
+	unsigned int i;
+	char *secnames;
+
+	/* Grab section headers and strings so we can tell who is who */
+	sechdrs = (void *)ehdr + ehdr->e_shoff;
+	secnames = (void *)ehdr + sechdrs[ehdr->e_shstrndx].sh_offset;
+
+	/* Find the section they want */
+	for (i = 1; i < ehdr->e_shnum; i++) {
+		if (strcmp(secnames + sechdrs[i].sh_name, name) == 0) {
+			if (size)
+				*size = sechdrs[i].sh_size;
+			return (void *)ehdr + sechdrs[i].sh_offset;
+		}
+	}
+
+	if (size)
+		*size = 0;
+	return NULL;
+}
+
+static Elf32_Sym * __init find_symbol(struct elfinfo *lib, const char *symname)
+{
+	unsigned int i;
+
+	for (i = 0; i < (lib->dynsymsize / sizeof(Elf32_Sym)); i++) {
+		char name[MAX_SYMNAME], *c;
+
+		if (lib->dynsym[i].st_name == 0)
+			continue;
+		strlcpy(name, lib->dynstr + lib->dynsym[i].st_name,
+			MAX_SYMNAME);
+		c = strchr(name, '@');
+		if (c)
+			*c = 0;
+		if (strcmp(symname, name) == 0)
+			return &lib->dynsym[i];
+	}
+	return NULL;
+}
+
+static void __init vdso_nullpatch_one(struct elfinfo *lib, const char *symname)
+{
+	Elf32_Sym *sym;
+
+	sym = find_symbol(lib, symname);
+	if (!sym)
+		return;
+
+	sym->st_name = 0;
+}
+
+static void __init patch_vdso(void *ehdr)
+{
+	struct elfinfo einfo;
+
+	einfo = (struct elfinfo) {
+		.hdr = ehdr,
+	};
+
+	einfo.dynsym = find_section(einfo.hdr, ".dynsym", &einfo.dynsymsize);
+	einfo.dynstr = find_section(einfo.hdr, ".dynstr", NULL);
+
+	/* If the virtual counter is absent or non-functional we don't
+	 * want programs to incur the slight additional overhead of
+	 * dispatching through the VDSO only to fall back to syscalls.
+	 */
+	if (!cntvct_ok) {
+		vdso_nullpatch_one(&einfo, "__vdso_gettimeofday");
+		vdso_nullpatch_one(&einfo, "__vdso_clock_gettime");
+	}
+}
+
+static int __init vdso_init(void)
+{
+	unsigned int text_pages;
+	int i;
+
+	if (memcmp(&vdso_start, "\177ELF", 4)) {
+		pr_err("VDSO is not a valid ELF object!\n");
+		return -ENOEXEC;
+	}
+
+	text_pages = (&vdso_end - &vdso_start) >> PAGE_SHIFT;
+	pr_debug("vdso: %i text pages at base %p\n", text_pages, &vdso_start);
+
+	/* Allocate the VDSO text pagelist */
+	vdso_text_pagelist = kcalloc(text_pages, sizeof(struct page *),
+				     GFP_KERNEL);
+	if (vdso_text_pagelist == NULL)
+		return -ENOMEM;
+
+	/* Grab the VDSO data page. */
+	vdso_data_page = virt_to_page(vdso_data);
+
+	/* Grab the VDSO text pages. */
+	for (i = 0; i < text_pages; i++) {
+		struct page *page;
+
+		page = virt_to_page(&vdso_start + i * PAGE_SIZE);
+		vdso_text_pagelist[i] = page;
+	}
+
+	vdso_text_mapping.pages = vdso_text_pagelist;
+
+	vdso_total_pages = 1; /* for the data/vvar page */
+	vdso_total_pages += text_pages;
+
+	cntvct_ok = cntvct_functional();
+
+	patch_vdso(&vdso_start);
+
+	return 0;
+}
+arch_initcall(vdso_init);
+
+static int install_vvar(struct mm_struct *mm, unsigned long addr)
+{
+	struct vm_area_struct *vma;
+
+	vma = _install_special_mapping(mm, addr, PAGE_SIZE,
+				       VM_READ | VM_MAYREAD,
+				       &vdso_data_mapping);
+
+	return IS_ERR(vma) ? PTR_ERR(vma) : 0;
+}
+
+/* assumes mmap_sem is write-locked */
+void arm_install_vdso(struct mm_struct *mm, unsigned long addr)
+{
+	struct vm_area_struct *vma;
+	unsigned long len;
+
+	mm->context.vdso = 0;
+
+	if (vdso_text_pagelist == NULL)
+		return;
+
+	if (install_vvar(mm, addr))
+		return;
+
+	/* Account for vvar page. */
+	addr += PAGE_SIZE;
+	len = (vdso_total_pages - 1) << PAGE_SHIFT;
+
+	vma = _install_special_mapping(mm, addr, len,
+		VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC,
+		&vdso_text_mapping);
+
+	if (!IS_ERR(vma))
+		mm->context.vdso = addr;
+}
+
+static void vdso_write_begin(struct vdso_data *vdata)
+{
+	++vdso_data->seq_count;
+	smp_wmb(); /* Pairs with smp_rmb in vdso_read_retry */
+}
+
+static void vdso_write_end(struct vdso_data *vdata)
+{
+	smp_wmb(); /* Pairs with smp_rmb in vdso_read_begin */
+	++vdso_data->seq_count;
+}
+
+static bool tk_is_cntvct(const struct timekeeper *tk)
+{
+	if (!IS_ENABLED(CONFIG_ARM_ARCH_TIMER))
+		return false;
+
+	if (strcmp(tk->tkr.clock->name, "arch_sys_counter") != 0)
+		return false;
+
+	return true;
+}
+
+/**
+ * update_vsyscall - update the vdso data page
+ *
+ * Increment the sequence counter, making it odd, indicating to
+ * userspace that an update is in progress.  Update the fields used
+ * for coarse clocks and, if the architected system timer is in use,
+ * the fields used for high precision clocks.  Increment the sequence
+ * counter again, making it even, indicating to userspace that the
+ * update is finished.
+ *
+ * Userspace is expected to sample seq_count before reading any other
+ * fields from the data page.  If seq_count is odd, userspace is
+ * expected to wait until it becomes even.  After copying data from
+ * the page, userspace must sample seq_count again; if it has changed
+ * from its previous value, userspace must retry the whole sequence.
+ *
+ * Calls to update_vsyscall are serialized by the timekeeping core.
+ */
+void update_vsyscall(struct timekeeper *tk)
+{
+	struct timespec xtime_coarse;
+	struct timespec64 *wtm = &tk->wall_to_monotonic;
+
+	if (!cntvct_ok) {
+		/* The entry points have been zeroed, so there is no
+		 * point in updating the data page.
+		 */
+		return;
+	}
+
+	vdso_write_begin(vdso_data);
+
+	xtime_coarse = __current_kernel_time();
+	vdso_data->tk_is_cntvct			= tk_is_cntvct(tk);
+	vdso_data->xtime_coarse_sec		= xtime_coarse.tv_sec;
+	vdso_data->xtime_coarse_nsec		= xtime_coarse.tv_nsec;
+	vdso_data->wtm_clock_sec		= wtm->tv_sec;
+	vdso_data->wtm_clock_nsec		= wtm->tv_nsec;
+
+	if (vdso_data->tk_is_cntvct) {
+		vdso_data->cs_cycle_last	= tk->tkr.cycle_last;
+		vdso_data->xtime_clock_sec	= tk->xtime_sec;
+		vdso_data->xtime_clock_snsec	= tk->tkr.xtime_nsec;
+		vdso_data->cs_mult		= tk->tkr.mult;
+		vdso_data->cs_shift		= tk->tkr.shift;
+		vdso_data->cs_mask		= tk->tkr.mask;
+	}
+
+	vdso_write_end(vdso_data);
+
+	flush_dcache_page(virt_to_page(vdso_data));
+}
+
+void update_vsyscall_tz(void)
+{
+	vdso_data->tz_minuteswest	= sys_tz.tz_minuteswest;
+	vdso_data->tz_dsttime		= sys_tz.tz_dsttime;
+	flush_dcache_page(virt_to_page(vdso_data));
+}
