commit fe557319aa06c23cffc9346000f119547e0f289a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 17 09:37:53 2020 +0200

    maccess: rename probe_kernel_{read,write} to copy_{from,to}_kernel_nofault
    
    Better describe what these functions do.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 10499d44964a..9a79ef6b1876 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -84,7 +84,8 @@ static int ftrace_modify_code(unsigned long pc, unsigned long old,
 		old = __opcode_to_mem_arm(old);
 
 	if (validate) {
-		if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))
+		if (copy_from_kernel_nofault(&replaced, (void *)pc,
+				MCOUNT_INSN_SIZE))
 			return -EFAULT;
 
 		if (replaced != old)

commit be993e44badc448add6a18d6f12b20615692c4c3
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Feb 7 12:57:36 2020 +0100

    arm/ftrace: Fix BE text poking
    
    The __patch_text() function already applies __opcode_to_mem_*(), so
    when __opcode_to_mem_*() is not the identity (BE*), it is applied
    twice, wrecking the instruction.
    
    Fixes: 42e51f187f86 ("arm/ftrace: Use __patch_text()")
    Reported-by: Dmitry Osipenko <digetx@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Tested-by: Dmitry Osipenko <digetx@gmail.com>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 2a5ff69c28e6..10499d44964a 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -78,13 +78,10 @@ static int ftrace_modify_code(unsigned long pc, unsigned long old,
 {
 	unsigned long replaced;
 
-	if (IS_ENABLED(CONFIG_THUMB2_KERNEL)) {
+	if (IS_ENABLED(CONFIG_THUMB2_KERNEL))
 		old = __opcode_to_mem_thumb32(old);
-		new = __opcode_to_mem_thumb32(new);
-	} else {
+	else
 		old = __opcode_to_mem_arm(old);
-		new = __opcode_to_mem_arm(new);
-	}
 
 	if (validate) {
 		if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))

commit 5a735583b764750726621b0396d03e4782911b77
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 15 21:07:35 2019 +0200

    arm/ftrace: Use __patch_text()
    
    Instead of flipping text protection, use the patch_text infrastructure
    that uses a fixmap alias where required.
    
    This removes the last user of set_all_modules_text_*().
    
    Tested-by: Will Deacon <will@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: ard.biesheuvel@linaro.org
    Cc: james.morse@arm.com
    Cc: rabin@rab.in
    Link: https://lkml.kernel.org/r/20191113092636.GG4131@hirez.programming.kicks-ass.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index bda949fd84e8..2a5ff69c28e6 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -22,6 +22,7 @@
 #include <asm/ftrace.h>
 #include <asm/insn.h>
 #include <asm/set_memory.h>
+#include <asm/patch.h>
 
 #ifdef CONFIG_THUMB2_KERNEL
 #define	NOP		0xf85deb04	/* pop.w {lr} */
@@ -35,9 +36,7 @@ static int __ftrace_modify_code(void *data)
 {
 	int *command = data;
 
-	set_kernel_text_rw();
 	ftrace_modify_all_code(*command);
-	set_kernel_text_ro();
 
 	return 0;
 }
@@ -59,13 +58,11 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 
 int ftrace_arch_code_modify_prepare(void)
 {
-	set_all_modules_text_rw();
 	return 0;
 }
 
 int ftrace_arch_code_modify_post_process(void)
 {
-	set_all_modules_text_ro();
 	/* Make sure any TLB misses during machine stop are cleared. */
 	flush_tlb_all();
 	return 0;
@@ -97,10 +94,7 @@ static int ftrace_modify_code(unsigned long pc, unsigned long old,
 			return -EINVAL;
 	}
 
-	if (probe_kernel_write((void *)pc, &new, MCOUNT_INSN_SIZE))
-		return -EPERM;
-
-	flush_icache_range(pc, pc + MCOUNT_INSN_SIZE);
+	__patch_text((void *)pc, new);
 
 	return 0;
 }

commit f1f5b14afd7cce39e6a9b25c685e1ea34c231096
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Sun Nov 18 17:19:26 2018 -0500

    ARM: function_graph: Simplify with function_graph_enter()
    
    The function_graph_enter() function does the work of calling the function
    graph hook function and the management of the shadow stack, simplifying the
    work done in the architecture dependent prepare_ftrace_return().
    
    Have ARM use the new code, and remove the shadow stack management as well as
    having to set up the trace structure.
    
    This is needed to prepare for a fix of a design bug on how the curr_ret_stack
    is used.
    
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: stable@kernel.org
    Fixes: 03274a3ffb449 ("tracing/fgraph: Adjust fgraph depth before calling trace return callback")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 0142fcfcc3d3..bda949fd84e8 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -183,9 +183,7 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 			   unsigned long frame_pointer)
 {
 	unsigned long return_hooker = (unsigned long) &return_to_handler;
-	struct ftrace_graph_ent trace;
 	unsigned long old;
-	int err;
 
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		return;
@@ -193,21 +191,8 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	old = *parent;
 	*parent = return_hooker;
 
-	trace.func = self_addr;
-	trace.depth = current->curr_ret_stack + 1;
-
-	/* Only trace if the calling function expects to */
-	if (!ftrace_graph_entry(&trace)) {
+	if (function_graph_enter(old, self_addr, frame_pointer, NULL))
 		*parent = old;
-		return;
-	}
-
-	err = ftrace_push_return_trace(old, self_addr, &trace.depth,
-				       frame_pointer, NULL);
-	if (err == -EBUSY) {
-		*parent = old;
-		return;
-	}
 }
 
 #ifdef CONFIG_DYNAMIC_FTRACE

commit d3c61619568c88d48eccd5e74b4f84faa1440652
Author: Stefan Agner <stefan@agner.ch>
Date:   Tue Sep 11 04:31:49 2018 +0100

    ARM: 8788/1: ftrace: remove old mcount support
    
    Commit cafa0010cd51 ("Raise the minimum required gcc version to 4.6")
    raised the minimum GCC version to 4.6. Old mcount is only required for
    GCC versions older than 4.4.0. Hence old mcount support can be dropped
    too.
    
    Signed-off-by: Stefan Agner <stefan@agner.ch>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 5617932a83df..0142fcfcc3d3 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -47,30 +47,6 @@ void arch_ftrace_update_code(int command)
 	stop_machine(__ftrace_modify_code, &command, NULL);
 }
 
-#ifdef CONFIG_OLD_MCOUNT
-#define OLD_MCOUNT_ADDR	((unsigned long) mcount)
-#define OLD_FTRACE_ADDR ((unsigned long) ftrace_caller_old)
-
-#define	OLD_NOP		0xe1a00000	/* mov r0, r0 */
-
-static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
-{
-	return rec->arch.old_mcount ? OLD_NOP : NOP;
-}
-
-static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
-{
-	if (!rec->arch.old_mcount)
-		return addr;
-
-	if (addr == MCOUNT_ADDR)
-		addr = OLD_MCOUNT_ADDR;
-	else if (addr == FTRACE_ADDR)
-		addr = OLD_FTRACE_ADDR;
-
-	return addr;
-}
-#else
 static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
 {
 	return NOP;
@@ -80,7 +56,6 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 {
 	return addr;
 }
-#endif
 
 int ftrace_arch_code_modify_prepare(void)
 {
@@ -150,15 +125,6 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 	}
 #endif
 
-#ifdef CONFIG_OLD_MCOUNT
-	if (!ret) {
-		pc = (unsigned long)&ftrace_call_old;
-		new = ftrace_call_replace(pc, (unsigned long)func);
-
-		ret = ftrace_modify_code(pc, 0, new, false);
-	}
-#endif
-
 	return ret;
 }
 
@@ -203,16 +169,6 @@ int ftrace_make_nop(struct module *mod,
 	new = ftrace_nop_replace(rec);
 	ret = ftrace_modify_code(ip, old, new, true);
 
-#ifdef CONFIG_OLD_MCOUNT
-	if (ret == -EINVAL && addr == MCOUNT_ADDR) {
-		rec->arch.old_mcount = true;
-
-		old = ftrace_call_replace(ip, adjust_address(rec, addr));
-		new = ftrace_nop_replace(rec);
-		ret = ftrace_modify_code(ip, old, new, true);
-	}
-#endif
-
 	return ret;
 }
 
@@ -290,13 +246,6 @@ static int ftrace_modify_graph_caller(bool enable)
 #endif
 
 
-#ifdef CONFIG_OLD_MCOUNT
-	if (!ret)
-		ret = __ftrace_modify_caller(&ftrace_graph_call_old,
-					     ftrace_graph_caller_old,
-					     enable);
-#endif
-
 	return ret;
 }
 

commit 620176f335017fbfcbc79d26a8c9beb6e64f4868
Author: Abel Vesa <abelvesa@linux.com>
Date:   Fri May 26 21:49:47 2017 +0100

    ARM: 8678/1: ftrace: Adds support for CONFIG_DYNAMIC_FTRACE_WITH_REGS
    
    The DYNAMIC_FTRACE_WITH_REGS configuration makes it possible for a
    ftrace operation to specify if registers need to saved/restored by
    the ftrace handler. This is needed by kgraft and possibly other
    ftrace-based tools, and the ARM architecture is currently lacking
    this feature. It would also be the first step to support the
    "Kprobes-on-ftrace" optimization on ARM.
    
    This patch introduces a new ftrace handler that stores the registers
    on the stack before calling the next stage. The registers are restored
    from the stack before going back to the instrumented function.
    
    A side-effect of this patch is to activate the support for
    ftrace_modify_call() as it defines ARCH_SUPPORTS_FTRACE_OPS for the
    ARM architecture.
    
    Signed-off-by: Abel Vesa <abelvesa@linux.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 833c991075a1..5617932a83df 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -141,6 +141,15 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 
 	ret = ftrace_modify_code(pc, 0, new, false);
 
+#ifdef CONFIG_DYNAMIC_FTRACE_WITH_REGS
+	if (!ret) {
+		pc = (unsigned long)&ftrace_regs_call;
+		new = ftrace_call_replace(pc, (unsigned long)func);
+
+		ret = ftrace_modify_code(pc, 0, new, false);
+	}
+#endif
+
 #ifdef CONFIG_OLD_MCOUNT
 	if (!ret) {
 		pc = (unsigned long)&ftrace_call_old;
@@ -159,11 +168,29 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	unsigned long ip = rec->ip;
 
 	old = ftrace_nop_replace(rec);
+
+	new = ftrace_call_replace(ip, adjust_address(rec, addr));
+
+	return ftrace_modify_code(rec->ip, old, new, true);
+}
+
+#ifdef CONFIG_DYNAMIC_FTRACE_WITH_REGS
+
+int ftrace_modify_call(struct dyn_ftrace *rec, unsigned long old_addr,
+				unsigned long addr)
+{
+	unsigned long new, old;
+	unsigned long ip = rec->ip;
+
+	old = ftrace_call_replace(ip, adjust_address(rec, old_addr));
+
 	new = ftrace_call_replace(ip, adjust_address(rec, addr));
 
 	return ftrace_modify_code(rec->ip, old, new, true);
 }
 
+#endif
+
 int ftrace_make_nop(struct module *mod,
 		    struct dyn_ftrace *rec, unsigned long addr)
 {
@@ -231,6 +258,8 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 extern unsigned long ftrace_graph_call;
 extern unsigned long ftrace_graph_call_old;
 extern void ftrace_graph_caller_old(void);
+extern unsigned long ftrace_graph_regs_call;
+extern void ftrace_graph_regs_caller(void);
 
 static int __ftrace_modify_caller(unsigned long *callsite,
 				  void (*func) (void), bool enable)
@@ -253,6 +282,14 @@ static int ftrace_modify_graph_caller(bool enable)
 				     ftrace_graph_caller,
 				     enable);
 
+#ifdef CONFIG_DYNAMIC_FTRACE_WITH_REGS
+	if (!ret)
+		ret = __ftrace_modify_caller(&ftrace_graph_regs_call,
+				     ftrace_graph_regs_caller,
+				     enable);
+#endif
+
+
 #ifdef CONFIG_OLD_MCOUNT
 	if (!ret)
 		ret = __ftrace_modify_caller(&ftrace_graph_call_old,

commit bf5f89463f5b3109a72ed13ca62b57e90213387d
Merge: 2d3e4866dea9 4d2b5bcab53f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 8 18:17:56 2017 -0700

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - the rest of MM
    
     - various misc things
    
     - procfs updates
    
     - lib/ updates
    
     - checkpatch updates
    
     - kdump/kexec updates
    
     - add kvmalloc helpers, use them
    
     - time helper updates for Y2038 issues. We're almost ready to remove
       current_fs_time() but that awaits a btrfs merge.
    
     - add tracepoints to DAX
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (114 commits)
      drivers/staging/ccree/ssi_hash.c: fix build with gcc-4.4.4
      selftests/vm: add a test for virtual address range mapping
      dax: add tracepoint to dax_insert_mapping()
      dax: add tracepoint to dax_writeback_one()
      dax: add tracepoints to dax_writeback_mapping_range()
      dax: add tracepoints to dax_load_hole()
      dax: add tracepoints to dax_pfn_mkwrite()
      dax: add tracepoints to dax_iomap_pte_fault()
      mtd: nand: nandsim: convert to memalloc_noreclaim_*()
      treewide: convert PF_MEMALLOC manipulations to new helpers
      mm: introduce memalloc_noreclaim_{save,restore}
      mm: prevent potential recursive reclaim due to clearing PF_MEMALLOC
      mm/huge_memory.c: deposit a pgtable for DAX PMD faults when required
      mm/huge_memory.c: use zap_deposited_table() more
      time: delete CURRENT_TIME_SEC and CURRENT_TIME
      gfs2: replace CURRENT_TIME with current_time
      apparmorfs: replace CURRENT_TIME with current_time()
      lustre: replace CURRENT_TIME macro
      fs: ubifs: replace CURRENT_TIME_SEC with current_time
      fs: ufs: use ktime_get_real_ts64() for birthtime
      ...

commit 74d86a70636a0a5eec76efcff24bee9681e01804
Author: Laura Abbott <labbott@redhat.com>
Date:   Mon May 8 15:58:02 2017 -0700

    arm: use set_memory.h header
    
    set_memory_* functions have moved to set_memory.h.  Switch to this
    explicitly
    
    Link: http://lkml.kernel.org/r/1488920133-27229-3-git-send-email-labbott@redhat.com
    Signed-off-by: Laura Abbott <labbott@redhat.com>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 3f1759411d51..dea3e965fe88 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -21,6 +21,7 @@
 #include <asm/opcodes.h>
 #include <asm/ftrace.h>
 #include <asm/insn.h>
+#include <asm/set_memory.h>
 
 #ifdef CONFIG_THUMB2_KERNEL
 #define	NOP		0xf85deb04	/* pop.w {lr} */

commit 6f05d0761af612e04572ba4d65b4c0274a88444f
Author: Abel Vesa <abelvesa@linux.com>
Date:   Mon Apr 3 23:58:54 2017 +0100

    ARM: 8668/1: ftrace: Fix dynamic ftrace with DEBUG_RODATA and !FRAME_POINTER
    
    The support for dynamic ftrace with CONFIG_DEBUG_RODATA involves
    overriding the weak arch_ftrace_update_code() with a variant which makes
    the kernel text writable around the patching.
    
    This override was however added under the CONFIG_OLD_MCOUNT ifdef, and
    CONFIG_OLD_MCOUNT is only enabled if frame pointers are enabled.
    
    This leads to non-functional dynamic ftrace (ftrace triggers a
    WARN_ON()) when CONFIG_DEBUG_RODATA is enabled and CONFIG_FRAME_POINTER
    is not.
    
    Move the override out of that ifdef and into the CONFIG_DYNAMIC_FTRACE
    ifdef where it belongs.
    
    Fixes: 80d6b0c2eed2a ("ARM: mm: allow text and rodata sections to be read-only")
    Suggested-by: Nicolai Stange <nicstange@gmail.com>
    Suggested-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Abel Vesa <abelvesa@gmail.com>
    Acked-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 3f1759411d51..414e60ed0257 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -29,11 +29,6 @@
 #endif
 
 #ifdef CONFIG_DYNAMIC_FTRACE
-#ifdef CONFIG_OLD_MCOUNT
-#define OLD_MCOUNT_ADDR	((unsigned long) mcount)
-#define OLD_FTRACE_ADDR ((unsigned long) ftrace_caller_old)
-
-#define	OLD_NOP		0xe1a00000	/* mov r0, r0 */
 
 static int __ftrace_modify_code(void *data)
 {
@@ -51,6 +46,12 @@ void arch_ftrace_update_code(int command)
 	stop_machine(__ftrace_modify_code, &command, NULL);
 }
 
+#ifdef CONFIG_OLD_MCOUNT
+#define OLD_MCOUNT_ADDR	((unsigned long) mcount)
+#define OLD_FTRACE_ADDR ((unsigned long) ftrace_caller_old)
+
+#define	OLD_NOP		0xe1a00000	/* mov r0, r0 */
+
 static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
 {
 	return rec->arch.old_mcount ? OLD_NOP : NOP;

commit 9a7c348ba6a46f6270d4fe49577649dad5664fe7
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Fri Aug 19 06:52:57 2016 -0500

    ftrace: Add return address pointer to ftrace_ret_stack
    
    Storing this value will help prevent unwinders from getting out of sync
    with the function graph tracer ret_stack.  Now instead of needing a
    stateful iterator, they can compare the return address pointer to find
    the right ret_stack entry.
    
    Note that an array of 50 ftrace_ret_stack structs is allocated for every
    task.  So when an arch implements this, it will add either 200 or 400
    bytes of memory usage per task (depending on whether it's a 32-bit or
    64-bit platform).
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Byungchul Park <byungchul.park@lge.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Nilay Vaish <nilayvaish@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/a95cfcc39e8f26b89a430c56926af0bb217bc0a1.1471607358.git.jpoimboe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 709ee1d6d4df..3f1759411d51 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -218,7 +218,7 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	}
 
 	err = ftrace_push_return_trace(old, self_addr, &trace.depth,
-				       frame_pointer);
+				       frame_pointer, NULL);
 	if (err == -EBUSY) {
 		*parent = old;
 		return;

commit 0dc016dbd820260b8ea74337980735b8c88d4ef2
Author: Wang Nan <wangnan0@huawei.com>
Date:   Fri Jan 9 14:37:36 2015 +0800

    ARM: kprobes: enable OPTPROBES for ARM 32
    
    This patch introduce kprobeopt for ARM 32.
    
    Limitations:
     - Currently only kernel compiled with ARM ISA is supported.
    
     - Offset between probe point and optinsn slot must not larger than
       32MiB. Masami Hiramatsu suggests replacing 2 words, it will make
       things complex. Futher patch can make such optimization.
    
    Kprobe opt on ARM is relatively simpler than kprobe opt on x86 because
    ARM instruction is always 4 bytes aligned and 4 bytes long. This patch
    replace probed instruction by a 'b', branch to trampoline code and then
    calls optimized_callback(). optimized_callback() calls opt_pre_handler()
    to execute kprobe handler. It also emulate/simulate replaced instruction.
    
    When unregistering kprobe, the deferred manner of unoptimizer may leave
    branch instruction before optimizer is called. Different from x86_64,
    which only copy the probed insn after optprobe_template_end and
    reexecute them, this patch call singlestep to emulate/simulate the insn
    directly. Futher patch can optimize this behavior.
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Acked-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Jon Medhurst (Tixy) <tixy@linaro.org>
    Signed-off-by: Jon Medhurst <tixy@linaro.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index b8c75e45a950..709ee1d6d4df 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -20,8 +20,7 @@
 #include <asm/cacheflush.h>
 #include <asm/opcodes.h>
 #include <asm/ftrace.h>
-
-#include "insn.h"
+#include <asm/insn.h>
 
 #ifdef CONFIG_THUMB2_KERNEL
 #define	NOP		0xf85deb04	/* pop.w {lr} */

commit 80d6b0c2eed2a504f6740cd1f5ea76dc50abfc4d
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Apr 3 13:29:50 2014 -0700

    ARM: mm: allow text and rodata sections to be read-only
    
    This introduces CONFIG_DEBUG_RODATA, making kernel text and rodata
    read-only. Additionally, this splits rodata from text so that rodata can
    also be NX, which may lead to wasted memory when aligning to SECTION_SIZE.
    The read-only areas are made writable during ftrace updates and kexec.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Tested-by: Laura Abbott <lauraa@codeaurora.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index af9a8a927a4e..b8c75e45a950 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -15,6 +15,7 @@
 #include <linux/ftrace.h>
 #include <linux/uaccess.h>
 #include <linux/module.h>
+#include <linux/stop_machine.h>
 
 #include <asm/cacheflush.h>
 #include <asm/opcodes.h>
@@ -35,6 +36,22 @@
 
 #define	OLD_NOP		0xe1a00000	/* mov r0, r0 */
 
+static int __ftrace_modify_code(void *data)
+{
+	int *command = data;
+
+	set_kernel_text_rw();
+	ftrace_modify_all_code(*command);
+	set_kernel_text_ro();
+
+	return 0;
+}
+
+void arch_ftrace_update_code(int command)
+{
+	stop_machine(__ftrace_modify_code, &command, NULL);
+}
+
 static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
 {
 	return rec->arch.old_mcount ? OLD_NOP : NOP;
@@ -73,6 +90,8 @@ int ftrace_arch_code_modify_prepare(void)
 int ftrace_arch_code_modify_post_process(void)
 {
 	set_all_modules_text_ro();
+	/* Make sure any TLB misses during machine stop are cleared. */
+	flush_tlb_all();
 	return 0;
 }
 

commit a672917ab8964228f83ac1f0728468b309d6ea19
Author: Rabin Vincent <rabin@rab.in>
Date:   Thu Apr 3 18:46:45 2014 +0100

    ARM: 8022/1: ftrace: work with CONFIG_DEBUG_SET_MODULE_RONX
    
    Make ftrace work with CONFIG_DEBUG_SET_MODULE_RONX by making module text
    writable around the place where ftrace does its work, like it is done on
    x86 in the patch which introduced CONFIG_DEBUG_SET_MODULE_RONX,
    84e1c6bb38eb ("x86: Add RO/NX protection for loadable kernel modules").
    
    Tested-by: Mitchel Humpherys <mitchelh@codeaurora.org>
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index c108ddcb9ba4..af9a8a927a4e 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -14,6 +14,7 @@
 
 #include <linux/ftrace.h>
 #include <linux/uaccess.h>
+#include <linux/module.h>
 
 #include <asm/cacheflush.h>
 #include <asm/opcodes.h>
@@ -63,6 +64,18 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 }
 #endif
 
+int ftrace_arch_code_modify_prepare(void)
+{
+	set_all_modules_text_rw();
+	return 0;
+}
+
+int ftrace_arch_code_modify_post_process(void)
+{
+	set_all_modules_text_ro();
+	return 0;
+}
+
 static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 {
 	return arm_gen_branch_link(pc, addr);

commit 3a36cb11ca65cd6804972eaf1000378ba4384ea7
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Mon Feb 24 19:59:59 2014 +0100

    ftrace: Do not pass data to ftrace_dyn_arch_init
    
    As the data parameter is not really used by any ftrace_dyn_arch_init,
    remove that from ftrace_dyn_arch_init. This also removes the addr
    local variable from ftrace_init which is now unused.
    
    Note the documentation was imprecise as it did not suggest to set
    (*data) to 0.
    
    Link: http://lkml.kernel.org/r/1393268401-24379-4-git-send-email-jslaby@suse.cz
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 5cd0d05edf35..c108ddcb9ba4 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -156,7 +156,7 @@ int ftrace_make_nop(struct module *mod,
 	return ret;
 }
 
-int __init ftrace_dyn_arch_init(void *data)
+int __init ftrace_dyn_arch_init(void)
 {
 	return 0;
 }

commit af64a7cb09db77344c596a0bf3d57d77257e8bf5
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Mon Feb 24 19:59:58 2014 +0100

    ftrace: Pass retval through return in ftrace_dyn_arch_init()
    
    No architecture uses the "data" parameter in ftrace_dyn_arch_init() in any
    way, it just sets the value to 0. And this is used as a return value
    in the caller -- ftrace_init, which just checks the retval against
    zero.
    
    Note there is also "return 0" in every ftrace_dyn_arch_init.  So it is
    enough to check the retval and remove all the indirect sets of data on
    all archs.
    
    Link: http://lkml.kernel.org/r/1393268401-24379-3-git-send-email-jslaby@suse.cz
    
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 34e56647dcee..5cd0d05edf35 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -158,8 +158,6 @@ int ftrace_make_nop(struct module *mod,
 
 int __init ftrace_dyn_arch_init(void *data)
 {
-	*(unsigned long *)data = 0;
-
 	return 0;
 }
 #endif /* CONFIG_DYNAMIC_FTRACE */

commit 4c36595ec87115f2f876f7d4fdec8ca284a42b9c
Author: Colin Cross <ccross@android.com>
Date:   Wed Jul 18 19:15:25 2012 +0100

    ARM: 7468/1: ftrace: Trace function entry before updating index
    
    Commit 722b3c74695377d11d18a52f3da08114d37f3f37 modified x86 ftrace to
    avoid tracing all functions called from irqs when function graph was
    used with a filter.  Port the same fix to ARM.
    
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Colin Cross <ccross@android.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index df0bf0c8cb79..34e56647dcee 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -179,19 +179,20 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 	old = *parent;
 	*parent = return_hooker;
 
-	err = ftrace_push_return_trace(old, self_addr, &trace.depth,
-				       frame_pointer);
-	if (err == -EBUSY) {
-		*parent = old;
-		return;
-	}
-
 	trace.func = self_addr;
+	trace.depth = current->curr_ret_stack + 1;
 
 	/* Only trace if the calling function expects to */
 	if (!ftrace_graph_entry(&trace)) {
-		current->curr_ret_stack--;
 		*parent = old;
+		return;
+	}
+
+	err = ftrace_push_return_trace(old, self_addr, &trace.depth,
+				       frame_pointer);
+	if (err == -EBUSY) {
+		*parent = old;
+		return;
 	}
 }
 

commit d82227cf8f0b42ff42c21ed47025fdf54cb1698d
Author: Rabin Vincent <rabin@rab.in>
Date:   Sat Feb 18 17:50:06 2012 +0100

    ARM: 7331/1: extract out insn generation code from ftrace
    
    Extract out the instruction generation code so that it can be used
    for jump labels too.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 5c9cecfaeb21..df0bf0c8cb79 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -19,6 +19,8 @@
 #include <asm/opcodes.h>
 #include <asm/ftrace.h>
 
+#include "insn.h"
+
 #ifdef CONFIG_THUMB2_KERNEL
 #define	NOP		0xf85deb04	/* pop.w {lr} */
 #else
@@ -61,64 +63,9 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 }
 #endif
 
-#ifdef CONFIG_THUMB2_KERNEL
-static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
-				       bool link)
-{
-	unsigned long s, j1, j2, i1, i2, imm10, imm11;
-	unsigned long first, second;
-	long offset;
-
-	offset = (long)addr - (long)(pc + 4);
-	if (offset < -16777216 || offset > 16777214) {
-		WARN_ON_ONCE(1);
-		return 0;
-	}
-
-	s	= (offset >> 24) & 0x1;
-	i1	= (offset >> 23) & 0x1;
-	i2	= (offset >> 22) & 0x1;
-	imm10	= (offset >> 12) & 0x3ff;
-	imm11	= (offset >>  1) & 0x7ff;
-
-	j1 = (!i1) ^ s;
-	j2 = (!i2) ^ s;
-
-	first = 0xf000 | (s << 10) | imm10;
-	second = 0x9000 | (j1 << 13) | (j2 << 11) | imm11;
-	if (link)
-		second |= 1 << 14;
-
-	return __opcode_thumb32_compose(first, second);
-}
-#else
-static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
-				       bool link)
-{
-	unsigned long opcode = 0xea000000;
-	long offset;
-
-	if (link)
-		opcode |= 1 << 24;
-
-	offset = (long)addr - (long)(pc + 8);
-	if (unlikely(offset < -33554432 || offset > 33554428)) {
-		/* Can't generate branches that far (from ARM ARM). Ftrace
-		 * doesn't generate branches outside of kernel text.
-		 */
-		WARN_ON_ONCE(1);
-		return 0;
-	}
-
-	offset = (offset >> 2) & 0x00ffffff;
-
-	return opcode | offset;
-}
-#endif
-
 static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 {
-	return ftrace_gen_branch(pc, addr, true);
+	return arm_gen_branch_link(pc, addr);
 }
 
 static int ftrace_modify_code(unsigned long pc, unsigned long old,
@@ -258,7 +205,7 @@ static int __ftrace_modify_caller(unsigned long *callsite,
 {
 	unsigned long caller_fn = (unsigned long) func;
 	unsigned long pc = (unsigned long) callsite;
-	unsigned long branch = ftrace_gen_branch(pc, caller_fn, false);
+	unsigned long branch = arm_gen_branch(pc, caller_fn);
 	unsigned long nop = 0xe1a00000;	/* mov r0, r0 */
 	unsigned long old = enable ? nop : branch;
 	unsigned long new = enable ? branch : nop;

commit 4394e2824c8d97d81a336edb469b13c8806604e4
Author: Rabin Vincent <rabin@rab.in>
Date:   Sat Feb 18 17:47:03 2012 +0100

    ARM: 7330/1: ftrace: use canonical Thumb-2 wide instruction format
    
    As commit 592201a9f15 (ARM: Thumb-2: Support Thumb-2 in undefined
    instruction handler) says:
    
        32-bit Thumb instructions are specified in the form:
            ((first_half << 16 ) | second_half)
        which matches the layout used by the ARM ARM.
    
    Convert the ftrace code to use the same format to avoid the usage of
    different formats in kernel code.
    
    Acked-by: Dave Martin <dave.martin@linaro.org>
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 6fd7c4a1e532..5c9cecfaeb21 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -16,10 +16,11 @@
 #include <linux/uaccess.h>
 
 #include <asm/cacheflush.h>
+#include <asm/opcodes.h>
 #include <asm/ftrace.h>
 
 #ifdef CONFIG_THUMB2_KERNEL
-#define	NOP		0xeb04f85d	/* pop.w {lr} */
+#define	NOP		0xf85deb04	/* pop.w {lr} */
 #else
 #define	NOP		0xe8bd4000	/* pop {lr} */
 #endif
@@ -88,7 +89,7 @@ static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
 	if (link)
 		second |= 1 << 14;
 
-	return (second << 16) | first;
+	return __opcode_thumb32_compose(first, second);
 }
 #else
 static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
@@ -125,6 +126,14 @@ static int ftrace_modify_code(unsigned long pc, unsigned long old,
 {
 	unsigned long replaced;
 
+	if (IS_ENABLED(CONFIG_THUMB2_KERNEL)) {
+		old = __opcode_to_mem_thumb32(old);
+		new = __opcode_to_mem_thumb32(new);
+	} else {
+		old = __opcode_to_mem_arm(old);
+		new = __opcode_to_mem_arm(new);
+	}
+
 	if (validate) {
 		if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))
 			return -EFAULT;

commit dc283d7037555aa6891188719be2f1b4af9535c9
Author: Rabin Vincent <rabin@rab.in>
Date:   Wed Feb 29 15:59:07 2012 +0100

    ARM: 7351/1: ftrace: remove useless memory checks
    
    Before replacing an instruction, the ftrace code determines what the old
    instruction should be and verifies that that's what's really there in
    memory before replacing it.  This is useful if for example a bug in
    mcountrecord causes it to record wrong locations.
    
    However, in cases where we replace call sites in entry-common.S, these
    checks are not needed.  For these, we currently just memcpy() the memory
    content and then "verify" it -- this is quite useless and can be
    removed.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index c0062ad1e847..6fd7c4a1e532 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -121,15 +121,17 @@ static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 }
 
 static int ftrace_modify_code(unsigned long pc, unsigned long old,
-			      unsigned long new)
+			      unsigned long new, bool validate)
 {
 	unsigned long replaced;
 
-	if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))
-		return -EFAULT;
+	if (validate) {
+		if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))
+			return -EFAULT;
 
-	if (replaced != old)
-		return -EINVAL;
+		if (replaced != old)
+			return -EINVAL;
+	}
 
 	if (probe_kernel_write((void *)pc, &new, MCOUNT_INSN_SIZE))
 		return -EPERM;
@@ -141,23 +143,21 @@ static int ftrace_modify_code(unsigned long pc, unsigned long old,
 
 int ftrace_update_ftrace_func(ftrace_func_t func)
 {
-	unsigned long pc, old;
+	unsigned long pc;
 	unsigned long new;
 	int ret;
 
 	pc = (unsigned long)&ftrace_call;
-	memcpy(&old, &ftrace_call, MCOUNT_INSN_SIZE);
 	new = ftrace_call_replace(pc, (unsigned long)func);
 
-	ret = ftrace_modify_code(pc, old, new);
+	ret = ftrace_modify_code(pc, 0, new, false);
 
 #ifdef CONFIG_OLD_MCOUNT
 	if (!ret) {
 		pc = (unsigned long)&ftrace_call_old;
-		memcpy(&old, &ftrace_call_old, MCOUNT_INSN_SIZE);
 		new = ftrace_call_replace(pc, (unsigned long)func);
 
-		ret = ftrace_modify_code(pc, old, new);
+		ret = ftrace_modify_code(pc, 0, new, false);
 	}
 #endif
 
@@ -172,7 +172,7 @@ int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 	old = ftrace_nop_replace(rec);
 	new = ftrace_call_replace(ip, adjust_address(rec, addr));
 
-	return ftrace_modify_code(rec->ip, old, new);
+	return ftrace_modify_code(rec->ip, old, new, true);
 }
 
 int ftrace_make_nop(struct module *mod,
@@ -185,7 +185,7 @@ int ftrace_make_nop(struct module *mod,
 
 	old = ftrace_call_replace(ip, adjust_address(rec, addr));
 	new = ftrace_nop_replace(rec);
-	ret = ftrace_modify_code(ip, old, new);
+	ret = ftrace_modify_code(ip, old, new, true);
 
 #ifdef CONFIG_OLD_MCOUNT
 	if (ret == -EINVAL && addr == MCOUNT_ADDR) {
@@ -193,7 +193,7 @@ int ftrace_make_nop(struct module *mod,
 
 		old = ftrace_call_replace(ip, adjust_address(rec, addr));
 		new = ftrace_nop_replace(rec);
-		ret = ftrace_modify_code(ip, old, new);
+		ret = ftrace_modify_code(ip, old, new, true);
 	}
 #endif
 
@@ -254,7 +254,7 @@ static int __ftrace_modify_caller(unsigned long *callsite,
 	unsigned long old = enable ? nop : branch;
 	unsigned long new = enable ? branch : nop;
 
-	return ftrace_modify_code(pc, old, new);
+	return ftrace_modify_code(pc, old, new, true);
 }
 
 static int ftrace_modify_graph_caller(bool enable)

commit dd686eb13959e49a1112fd608c124ab711050582
Author: Rabin Vincent <rabin@rab.in>
Date:   Sat Nov 6 23:03:21 2010 +0530

    ARM: ftrace: graph tracer + dynamic ftrace
    
    Support the graph tracer + dynamic ftrace combination on ARM.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 7a702a502871..c0062ad1e847 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -60,9 +60,9 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 }
 #endif
 
-/* construct a branch (BL) instruction to addr */
 #ifdef CONFIG_THUMB2_KERNEL
-static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
+static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
+				       bool link)
 {
 	unsigned long s, j1, j2, i1, i2, imm10, imm11;
 	unsigned long first, second;
@@ -84,15 +84,22 @@ static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 	j2 = (!i2) ^ s;
 
 	first = 0xf000 | (s << 10) | imm10;
-	second = 0xd000 | (j1 << 13) | (j2 << 11) | imm11;
+	second = 0x9000 | (j1 << 13) | (j2 << 11) | imm11;
+	if (link)
+		second |= 1 << 14;
 
 	return (second << 16) | first;
 }
 #else
-static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
+static unsigned long ftrace_gen_branch(unsigned long pc, unsigned long addr,
+				       bool link)
 {
+	unsigned long opcode = 0xea000000;
 	long offset;
 
+	if (link)
+		opcode |= 1 << 24;
+
 	offset = (long)addr - (long)(pc + 8);
 	if (unlikely(offset < -33554432 || offset > 33554428)) {
 		/* Can't generate branches that far (from ARM ARM). Ftrace
@@ -104,10 +111,15 @@ static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 
 	offset = (offset >> 2) & 0x00ffffff;
 
-	return 0xeb000000 | offset;
+	return opcode | offset;
 }
 #endif
 
+static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
+{
+	return ftrace_gen_branch(pc, addr, true);
+}
+
 static int ftrace_modify_code(unsigned long pc, unsigned long old,
 			      unsigned long new)
 {
@@ -226,4 +238,51 @@ void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
 		*parent = old;
 	}
 }
+
+#ifdef CONFIG_DYNAMIC_FTRACE
+extern unsigned long ftrace_graph_call;
+extern unsigned long ftrace_graph_call_old;
+extern void ftrace_graph_caller_old(void);
+
+static int __ftrace_modify_caller(unsigned long *callsite,
+				  void (*func) (void), bool enable)
+{
+	unsigned long caller_fn = (unsigned long) func;
+	unsigned long pc = (unsigned long) callsite;
+	unsigned long branch = ftrace_gen_branch(pc, caller_fn, false);
+	unsigned long nop = 0xe1a00000;	/* mov r0, r0 */
+	unsigned long old = enable ? nop : branch;
+	unsigned long new = enable ? branch : nop;
+
+	return ftrace_modify_code(pc, old, new);
+}
+
+static int ftrace_modify_graph_caller(bool enable)
+{
+	int ret;
+
+	ret = __ftrace_modify_caller(&ftrace_graph_call,
+				     ftrace_graph_caller,
+				     enable);
+
+#ifdef CONFIG_OLD_MCOUNT
+	if (!ret)
+		ret = __ftrace_modify_caller(&ftrace_graph_call_old,
+					     ftrace_graph_caller_old,
+					     enable);
+#endif
+
+	return ret;
+}
+
+int ftrace_enable_ftrace_graph_caller(void)
+{
+	return ftrace_modify_graph_caller(true);
+}
+
+int ftrace_disable_ftrace_graph_caller(void)
+{
+	return ftrace_modify_graph_caller(false);
+}
+#endif /* CONFIG_DYNAMIC_FTRACE */
 #endif /* CONFIG_FUNCTION_GRAPH_TRACER */

commit 376cfa8730c08c0394d0aa1d4a80fd8c9971f323
Author: Tim Bird <tim.bird@am.sony.com>
Date:   Sat Oct 9 22:24:38 2010 +0530

    ARM: ftrace: function graph tracer support
    
    Cc: Tim Bird <tim.bird@am.sony.com>
    [rabin@rab.in: rebase on top of latest code,
                   keep code in ftrace.c instead of separate file,
                   check for ftrace_graph_entry also]
    Signed-off-by: Rabin Vincent <rabin@rab.in>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 971ac8c36ea7..7a702a502871 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -24,6 +24,7 @@
 #define	NOP		0xe8bd4000	/* pop {lr} */
 #endif
 
+#ifdef CONFIG_DYNAMIC_FTRACE
 #ifdef CONFIG_OLD_MCOUNT
 #define OLD_MCOUNT_ADDR	((unsigned long) mcount)
 #define OLD_FTRACE_ADDR ((unsigned long) ftrace_caller_old)
@@ -193,3 +194,36 @@ int __init ftrace_dyn_arch_init(void *data)
 
 	return 0;
 }
+#endif /* CONFIG_DYNAMIC_FTRACE */
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr,
+			   unsigned long frame_pointer)
+{
+	unsigned long return_hooker = (unsigned long) &return_to_handler;
+	struct ftrace_graph_ent trace;
+	unsigned long old;
+	int err;
+
+	if (unlikely(atomic_read(&current->tracing_graph_pause)))
+		return;
+
+	old = *parent;
+	*parent = return_hooker;
+
+	err = ftrace_push_return_trace(old, self_addr, &trace.depth,
+				       frame_pointer);
+	if (err == -EBUSY) {
+		*parent = old;
+		return;
+	}
+
+	trace.func = self_addr;
+
+	/* Only trace if the calling function expects to */
+	if (!ftrace_graph_entry(&trace)) {
+		current->curr_ret_stack--;
+		*parent = old;
+	}
+}
+#endif /* CONFIG_FUNCTION_GRAPH_TRACER */

commit 72dc43a9eb123d2742bd413c80dbeab0c588f622
Author: Rabin Vincent <rabin@rab.in>
Date:   Tue Aug 10 19:52:35 2010 +0100

    ARM: 6319/1: ftrace: add Thumb-2 support to dynamic ftrace
    
    Handle the different nop and call instructions for Thumb-2.  Also, we
    need to adjust the recorded mcount_loc addresses because they have the
    lsb set.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org> [recordmcount.pl change]
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index f09014cfbf2c..971ac8c36ea7 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -18,7 +18,11 @@
 #include <asm/cacheflush.h>
 #include <asm/ftrace.h>
 
+#ifdef CONFIG_THUMB2_KERNEL
+#define	NOP		0xeb04f85d	/* pop.w {lr} */
+#else
 #define	NOP		0xe8bd4000	/* pop {lr} */
+#endif
 
 #ifdef CONFIG_OLD_MCOUNT
 #define OLD_MCOUNT_ADDR	((unsigned long) mcount)
@@ -56,6 +60,34 @@ static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 #endif
 
 /* construct a branch (BL) instruction to addr */
+#ifdef CONFIG_THUMB2_KERNEL
+static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
+{
+	unsigned long s, j1, j2, i1, i2, imm10, imm11;
+	unsigned long first, second;
+	long offset;
+
+	offset = (long)addr - (long)(pc + 4);
+	if (offset < -16777216 || offset > 16777214) {
+		WARN_ON_ONCE(1);
+		return 0;
+	}
+
+	s	= (offset >> 24) & 0x1;
+	i1	= (offset >> 23) & 0x1;
+	i2	= (offset >> 22) & 0x1;
+	imm10	= (offset >> 12) & 0x3ff;
+	imm11	= (offset >>  1) & 0x7ff;
+
+	j1 = (!i1) ^ s;
+	j2 = (!i2) ^ s;
+
+	first = 0xf000 | (s << 10) | imm10;
+	second = 0xd000 | (j1 << 13) | (j2 << 11) | imm11;
+
+	return (second << 16) | first;
+}
+#else
 static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 {
 	long offset;
@@ -73,6 +105,7 @@ static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 
 	return 0xeb000000 | offset;
 }
+#endif
 
 static int ftrace_modify_code(unsigned long pc, unsigned long old,
 			      unsigned long new)

commit 3b6c223b1b97ad60bbb0f4efda57d649414ac2a2
Author: Rabin Vincent <rabin@rab.in>
Date:   Tue Aug 10 19:43:28 2010 +0100

    ARM: 6318/1: ftrace: fix and update dynamic ftrace
    
    This adds mcount recording and updates dynamic ftrace for ARM to work
    with the new ftrace dyamic tracing implementation.  It also adds support
    for the mcount format used by newer ARM compilers.
    
    With dynamic tracing, mcount() is implemented as a nop.  Callsites are
    patched on startup with nops, and dynamically patched to call to the
    ftrace_caller() routine as needed.
    
    Acked-by: Steven Rostedt <rostedt@goodmis.org> [recordmcount.pl change]
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 0298286ad4ad..f09014cfbf2c 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -2,102 +2,161 @@
  * Dynamic function tracing support.
  *
  * Copyright (C) 2008 Abhishek Sagar <sagar.abhishek@gmail.com>
+ * Copyright (C) 2010 Rabin Vincent <rabin@rab.in>
  *
  * For licencing details, see COPYING.
  *
  * Defines low-level handling of mcount calls when the kernel
  * is compiled with the -pg flag. When using dynamic ftrace, the
- * mcount call-sites get patched lazily with NOP till they are
- * enabled. All code mutation routines here take effect atomically.
+ * mcount call-sites get patched with NOP till they are enabled.
+ * All code mutation routines here are called under stop_machine().
  */
 
 #include <linux/ftrace.h>
+#include <linux/uaccess.h>
 
 #include <asm/cacheflush.h>
 #include <asm/ftrace.h>
 
-#define PC_OFFSET      8
-#define BL_OPCODE      0xeb000000
-#define BL_OFFSET_MASK 0x00ffffff
+#define	NOP		0xe8bd4000	/* pop {lr} */
 
-static unsigned long bl_insn;
-static const unsigned long NOP = 0xe1a00000; /* mov r0, r0 */
+#ifdef CONFIG_OLD_MCOUNT
+#define OLD_MCOUNT_ADDR	((unsigned long) mcount)
+#define OLD_FTRACE_ADDR ((unsigned long) ftrace_caller_old)
 
-unsigned char *ftrace_nop_replace(void)
+#define	OLD_NOP		0xe1a00000	/* mov r0, r0 */
+
+static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
+{
+	return rec->arch.old_mcount ? OLD_NOP : NOP;
+}
+
+static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
+{
+	if (!rec->arch.old_mcount)
+		return addr;
+
+	if (addr == MCOUNT_ADDR)
+		addr = OLD_MCOUNT_ADDR;
+	else if (addr == FTRACE_ADDR)
+		addr = OLD_FTRACE_ADDR;
+
+	return addr;
+}
+#else
+static unsigned long ftrace_nop_replace(struct dyn_ftrace *rec)
+{
+	return NOP;
+}
+
+static unsigned long adjust_address(struct dyn_ftrace *rec, unsigned long addr)
 {
-	return (char *)&NOP;
+	return addr;
 }
+#endif
 
 /* construct a branch (BL) instruction to addr */
-unsigned char *ftrace_call_replace(unsigned long pc, unsigned long addr)
+static unsigned long ftrace_call_replace(unsigned long pc, unsigned long addr)
 {
 	long offset;
 
-	offset = (long)addr - (long)(pc + PC_OFFSET);
+	offset = (long)addr - (long)(pc + 8);
 	if (unlikely(offset < -33554432 || offset > 33554428)) {
 		/* Can't generate branches that far (from ARM ARM). Ftrace
 		 * doesn't generate branches outside of kernel text.
 		 */
 		WARN_ON_ONCE(1);
-		return NULL;
+		return 0;
 	}
-	offset = (offset >> 2) & BL_OFFSET_MASK;
-	bl_insn = BL_OPCODE | offset;
-	return (unsigned char *)&bl_insn;
-}
 
-int ftrace_modify_code(unsigned long pc, unsigned char *old_code,
-		       unsigned char *new_code)
-{
-	unsigned long err = 0, replaced = 0, old, new;
+	offset = (offset >> 2) & 0x00ffffff;
 
-	old = *(unsigned long *)old_code;
-	new = *(unsigned long *)new_code;
+	return 0xeb000000 | offset;
+}
 
-	__asm__ __volatile__ (
-		"1:  ldr    %1, [%2]  \n"
-		"    cmp    %1, %4    \n"
-		"2:  streq  %3, [%2]  \n"
-		"    cmpne  %1, %3    \n"
-		"    movne  %0, #2    \n"
-		"3:\n"
+static int ftrace_modify_code(unsigned long pc, unsigned long old,
+			      unsigned long new)
+{
+	unsigned long replaced;
 
-		".pushsection .fixup, \"ax\"\n"
-		"4:  mov  %0, #1  \n"
-		"    b    3b      \n"
-		".popsection\n"
+	if (probe_kernel_read(&replaced, (void *)pc, MCOUNT_INSN_SIZE))
+		return -EFAULT;
 
-		".pushsection __ex_table, \"a\"\n"
-		"    .long 1b, 4b \n"
-		"    .long 2b, 4b \n"
-		".popsection\n"
+	if (replaced != old)
+		return -EINVAL;
 
-		: "=r"(err), "=r"(replaced)
-		: "r"(pc), "r"(new), "r"(old), "0"(err), "1"(replaced)
-		: "memory");
+	if (probe_kernel_write((void *)pc, &new, MCOUNT_INSN_SIZE))
+		return -EPERM;
 
-	if (!err && (replaced == old))
-		flush_icache_range(pc, pc + MCOUNT_INSN_SIZE);
+	flush_icache_range(pc, pc + MCOUNT_INSN_SIZE);
 
-	return err;
+	return 0;
 }
 
 int ftrace_update_ftrace_func(ftrace_func_t func)
 {
-	int ret;
 	unsigned long pc, old;
-	unsigned char *new;
+	unsigned long new;
+	int ret;
 
 	pc = (unsigned long)&ftrace_call;
 	memcpy(&old, &ftrace_call, MCOUNT_INSN_SIZE);
 	new = ftrace_call_replace(pc, (unsigned long)func);
-	ret = ftrace_modify_code(pc, (unsigned char *)&old, new);
+
+	ret = ftrace_modify_code(pc, old, new);
+
+#ifdef CONFIG_OLD_MCOUNT
+	if (!ret) {
+		pc = (unsigned long)&ftrace_call_old;
+		memcpy(&old, &ftrace_call_old, MCOUNT_INSN_SIZE);
+		new = ftrace_call_replace(pc, (unsigned long)func);
+
+		ret = ftrace_modify_code(pc, old, new);
+	}
+#endif
+
+	return ret;
+}
+
+int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
+{
+	unsigned long new, old;
+	unsigned long ip = rec->ip;
+
+	old = ftrace_nop_replace(rec);
+	new = ftrace_call_replace(ip, adjust_address(rec, addr));
+
+	return ftrace_modify_code(rec->ip, old, new);
+}
+
+int ftrace_make_nop(struct module *mod,
+		    struct dyn_ftrace *rec, unsigned long addr)
+{
+	unsigned long ip = rec->ip;
+	unsigned long old;
+	unsigned long new;
+	int ret;
+
+	old = ftrace_call_replace(ip, adjust_address(rec, addr));
+	new = ftrace_nop_replace(rec);
+	ret = ftrace_modify_code(ip, old, new);
+
+#ifdef CONFIG_OLD_MCOUNT
+	if (ret == -EINVAL && addr == MCOUNT_ADDR) {
+		rec->arch.old_mcount = true;
+
+		old = ftrace_call_replace(ip, adjust_address(rec, addr));
+		new = ftrace_nop_replace(rec);
+		ret = ftrace_modify_code(ip, old, new);
+	}
+#endif
+
 	return ret;
 }
 
-/* run from ftrace_init with irqs disabled */
 int __init ftrace_dyn_arch_init(void *data)
 {
-	ftrace_mcount_set(data);
+	*(unsigned long *)data = 0;
+
 	return 0;
 }

commit 4260415f6a3b92c5c986398d96c314df37a4ccbf
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Apr 19 10:15:03 2010 +0100

    ARM: fix build error in arch/arm/kernel/process.c
    
    /tmp/ccJ3ssZW.s: Assembler messages:
    /tmp/ccJ3ssZW.s:1952: Error: can't resolve `.text' {.text section} - `.LFB1077'
    
    This is caused because:
    
            .section .data
            .section .text
            .section .text
            .previous
    
    does not return us to the .text section, but the .data section; this
    makes use of .previous dangerous if the ordering of previous sections
    is not known.
    
    Fix up the other users of .previous; .pushsection and .popsection are
    a safer pairing to use than .section and .previous.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index c63842766229..0298286ad4ad 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -62,15 +62,15 @@ int ftrace_modify_code(unsigned long pc, unsigned char *old_code,
 		"    movne  %0, #2    \n"
 		"3:\n"
 
-		".section .fixup, \"ax\"\n"
+		".pushsection .fixup, \"ax\"\n"
 		"4:  mov  %0, #1  \n"
 		"    b    3b      \n"
-		".previous\n"
+		".popsection\n"
 
-		".section __ex_table, \"a\"\n"
+		".pushsection __ex_table, \"a\"\n"
 		"    .long 1b, 4b \n"
 		"    .long 2b, 4b \n"
-		".previous\n"
+		".popsection\n"
 
 		: "=r"(err), "=r"(replaced)
 		: "r"(pc), "r"(new), "r"(old), "0"(err), "1"(replaced)

commit 6ed70a792af1f7961d8c74c2ded78aebd42c658e
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Fri Dec 12 11:15:45 2008 +0100

    small doc fix: ftrace_dyn_arch_init is called by ftrace_init
    
    ... not kstop_machine.  Add a note that irqs are disabled.
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 6c90479e8974..c63842766229 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -95,7 +95,7 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 	return ret;
 }
 
-/* run from kstop_machine */
+/* run from ftrace_init with irqs disabled */
 int __init ftrace_dyn_arch_init(void *data)
 {
 	ftrace_mcount_set(data);

commit 4d296c24326783bff1282ac72f310d8bac8df413
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Thu Oct 23 09:33:06 2008 -0400

    ftrace: remove mcount set
    
    The arch dependent function ftrace_mcount_set was only used by the daemon
    start up code. This patch removes it.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 76d50e6091bc..6c90479e8974 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -95,19 +95,6 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 	return ret;
 }
 
-int ftrace_mcount_set(unsigned long *data)
-{
-	unsigned long pc, old;
-	unsigned long *addr = data;
-	unsigned char *new;
-
-	pc = (unsigned long)&mcount_call;
-	memcpy(&old, &mcount_call, MCOUNT_INSN_SIZE);
-	new = ftrace_call_replace(pc, *addr);
-	*addr = ftrace_modify_code(pc, (unsigned char *)&old, new);
-	return 0;
-}
-
 /* run from kstop_machine */
 int __init ftrace_dyn_arch_init(void *data)
 {

commit 395a59d0f8e86bb39cd700c3d185d30c670bb958
Author: Abhishek Sagar <sagar.abhishek@gmail.com>
Date:   Sat Jun 21 23:47:27 2008 +0530

    ftrace: store mcount address in rec->ip
    
    Record the address of the mcount call-site. Currently all archs except sparc64
    record the address of the instruction following the mcount call-site. Some
    general cleanups are entailed. Storing mcount addresses in rec->ip enables
    looking them up in the kprobe hash table later on to check if they're kprobe'd.
    
    Signed-off-by: Abhishek Sagar <sagar.abhishek@gmail.com>
    Cc: davem@davemloft.net
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index 22f3d6e309f9..76d50e6091bc 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -12,9 +12,10 @@
  */
 
 #include <linux/ftrace.h>
+
 #include <asm/cacheflush.h>
+#include <asm/ftrace.h>
 
-#define INSN_SIZE      4
 #define PC_OFFSET      8
 #define BL_OPCODE      0xeb000000
 #define BL_OFFSET_MASK 0x00ffffff
@@ -32,10 +33,10 @@ unsigned char *ftrace_call_replace(unsigned long pc, unsigned long addr)
 {
 	long offset;
 
-	offset = (long)addr - (long)(pc - INSN_SIZE + PC_OFFSET);
+	offset = (long)addr - (long)(pc + PC_OFFSET);
 	if (unlikely(offset < -33554432 || offset > 33554428)) {
 		/* Can't generate branches that far (from ARM ARM). Ftrace
-		 * doesn't generate branches outside of core kernel text.
+		 * doesn't generate branches outside of kernel text.
 		 */
 		WARN_ON_ONCE(1);
 		return NULL;
@@ -52,7 +53,6 @@ int ftrace_modify_code(unsigned long pc, unsigned char *old_code,
 
 	old = *(unsigned long *)old_code;
 	new = *(unsigned long *)new_code;
-	pc -= INSN_SIZE;
 
 	__asm__ __volatile__ (
 		"1:  ldr    %1, [%2]  \n"
@@ -77,7 +77,7 @@ int ftrace_modify_code(unsigned long pc, unsigned char *old_code,
 		: "memory");
 
 	if (!err && (replaced == old))
-		flush_icache_range(pc, pc + INSN_SIZE);
+		flush_icache_range(pc, pc + MCOUNT_INSN_SIZE);
 
 	return err;
 }
@@ -89,8 +89,7 @@ int ftrace_update_ftrace_func(ftrace_func_t func)
 	unsigned char *new;
 
 	pc = (unsigned long)&ftrace_call;
-	pc += INSN_SIZE;
-	memcpy(&old, &ftrace_call, INSN_SIZE);
+	memcpy(&old, &ftrace_call, MCOUNT_INSN_SIZE);
 	new = ftrace_call_replace(pc, (unsigned long)func);
 	ret = ftrace_modify_code(pc, (unsigned char *)&old, new);
 	return ret;
@@ -103,8 +102,7 @@ int ftrace_mcount_set(unsigned long *data)
 	unsigned char *new;
 
 	pc = (unsigned long)&mcount_call;
-	pc += INSN_SIZE;
-	memcpy(&old, &mcount_call, INSN_SIZE);
+	memcpy(&old, &mcount_call, MCOUNT_INSN_SIZE);
 	new = ftrace_call_replace(pc, *addr);
 	*addr = ftrace_modify_code(pc, (unsigned char *)&old, new);
 	return 0;

commit 1d74f2a0f64b4091e5e91b55ac1b17dff93f4b59
Author: Abhishek Sagar <sagar.abhishek@gmail.com>
Date:   Sun Jun 1 21:47:42 2008 +0530

    ftrace: remove ftrace_ip_converted()
    
    Remove the unneeded function ftrace_ip_converted().
    
    Signed-off-by: Abhishek Sagar <sagar.abhishek@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
index f4cb4cc3fa0c..22f3d6e309f9 100644
--- a/arch/arm/kernel/ftrace.c
+++ b/arch/arm/kernel/ftrace.c
@@ -22,16 +22,6 @@
 static unsigned long bl_insn;
 static const unsigned long NOP = 0xe1a00000; /* mov r0, r0 */
 
-/* return true if mcount call site is already patched/no-op'ed */
-int ftrace_ip_converted(unsigned long pc)
-{
-	unsigned long save;
-
-	pc -= INSN_SIZE;
-	save = *(unsigned long *)pc;
-	return save == NOP;
-}
-
 unsigned char *ftrace_nop_replace(void)
 {
 	return (char *)&NOP;

commit 014c257cce65e9d1cd2d28ec1c89a37c536b151d
Author: Abhishek Sagar <sagar.abhishek@gmail.com>
Date:   Sat May 31 14:23:50 2008 +0530

    ftrace: core support for ARM
    
    Core ftrace support for the ARM architecture, which includes support
    for dynamic function tracing.
    
    Signed-off-by: Abhishek Sagar <sagar.abhishek@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/ftrace.c b/arch/arm/kernel/ftrace.c
new file mode 100644
index 000000000000..f4cb4cc3fa0c
--- /dev/null
+++ b/arch/arm/kernel/ftrace.c
@@ -0,0 +1,128 @@
+/*
+ * Dynamic function tracing support.
+ *
+ * Copyright (C) 2008 Abhishek Sagar <sagar.abhishek@gmail.com>
+ *
+ * For licencing details, see COPYING.
+ *
+ * Defines low-level handling of mcount calls when the kernel
+ * is compiled with the -pg flag. When using dynamic ftrace, the
+ * mcount call-sites get patched lazily with NOP till they are
+ * enabled. All code mutation routines here take effect atomically.
+ */
+
+#include <linux/ftrace.h>
+#include <asm/cacheflush.h>
+
+#define INSN_SIZE      4
+#define PC_OFFSET      8
+#define BL_OPCODE      0xeb000000
+#define BL_OFFSET_MASK 0x00ffffff
+
+static unsigned long bl_insn;
+static const unsigned long NOP = 0xe1a00000; /* mov r0, r0 */
+
+/* return true if mcount call site is already patched/no-op'ed */
+int ftrace_ip_converted(unsigned long pc)
+{
+	unsigned long save;
+
+	pc -= INSN_SIZE;
+	save = *(unsigned long *)pc;
+	return save == NOP;
+}
+
+unsigned char *ftrace_nop_replace(void)
+{
+	return (char *)&NOP;
+}
+
+/* construct a branch (BL) instruction to addr */
+unsigned char *ftrace_call_replace(unsigned long pc, unsigned long addr)
+{
+	long offset;
+
+	offset = (long)addr - (long)(pc - INSN_SIZE + PC_OFFSET);
+	if (unlikely(offset < -33554432 || offset > 33554428)) {
+		/* Can't generate branches that far (from ARM ARM). Ftrace
+		 * doesn't generate branches outside of core kernel text.
+		 */
+		WARN_ON_ONCE(1);
+		return NULL;
+	}
+	offset = (offset >> 2) & BL_OFFSET_MASK;
+	bl_insn = BL_OPCODE | offset;
+	return (unsigned char *)&bl_insn;
+}
+
+int ftrace_modify_code(unsigned long pc, unsigned char *old_code,
+		       unsigned char *new_code)
+{
+	unsigned long err = 0, replaced = 0, old, new;
+
+	old = *(unsigned long *)old_code;
+	new = *(unsigned long *)new_code;
+	pc -= INSN_SIZE;
+
+	__asm__ __volatile__ (
+		"1:  ldr    %1, [%2]  \n"
+		"    cmp    %1, %4    \n"
+		"2:  streq  %3, [%2]  \n"
+		"    cmpne  %1, %3    \n"
+		"    movne  %0, #2    \n"
+		"3:\n"
+
+		".section .fixup, \"ax\"\n"
+		"4:  mov  %0, #1  \n"
+		"    b    3b      \n"
+		".previous\n"
+
+		".section __ex_table, \"a\"\n"
+		"    .long 1b, 4b \n"
+		"    .long 2b, 4b \n"
+		".previous\n"
+
+		: "=r"(err), "=r"(replaced)
+		: "r"(pc), "r"(new), "r"(old), "0"(err), "1"(replaced)
+		: "memory");
+
+	if (!err && (replaced == old))
+		flush_icache_range(pc, pc + INSN_SIZE);
+
+	return err;
+}
+
+int ftrace_update_ftrace_func(ftrace_func_t func)
+{
+	int ret;
+	unsigned long pc, old;
+	unsigned char *new;
+
+	pc = (unsigned long)&ftrace_call;
+	pc += INSN_SIZE;
+	memcpy(&old, &ftrace_call, INSN_SIZE);
+	new = ftrace_call_replace(pc, (unsigned long)func);
+	ret = ftrace_modify_code(pc, (unsigned char *)&old, new);
+	return ret;
+}
+
+int ftrace_mcount_set(unsigned long *data)
+{
+	unsigned long pc, old;
+	unsigned long *addr = data;
+	unsigned char *new;
+
+	pc = (unsigned long)&mcount_call;
+	pc += INSN_SIZE;
+	memcpy(&old, &mcount_call, INSN_SIZE);
+	new = ftrace_call_replace(pc, *addr);
+	*addr = ftrace_modify_code(pc, (unsigned char *)&old, new);
+	return 0;
+}
+
+/* run from kstop_machine */
+int __init ftrace_dyn_arch_init(void *data)
+{
+	ftrace_mcount_set(data);
+	return 0;
+}
