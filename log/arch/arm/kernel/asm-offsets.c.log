commit 6ec4476ac82512f09c94aff5972654b70f3772b2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 8 10:48:35 2020 -0700

    Raise gcc version requirement to 4.9
    
    I realize that we fairly recently raised it to 4.8, but the fact is, 4.9
    is a much better minimum version to target.
    
    We have a number of workarounds for actual bugs in pre-4.9 gcc versions
    (including things like internal compiler errors on ARM), but we also
    have some syntactic workarounds for lacking features.
    
    In particular, raising the minimum to 4.9 means that we can now just
    assume _Generic() exists, which is likely the much better replacement
    for a lot of very convoluted built-time magic with conditionals on
    sizeof and/or __builtin_choose_expr() with same_type() etc.
    
    Using _Generic also means that you will need to have a very recent
    version of 'sparse', but thats easy to build yourself, and much less of
    a hassle than some old gcc version can be.
    
    The latest (in a long string) of reasons for minimum compiler version
    upgrades was commit 5435f73d5c4a ("efi/x86: Fix build with gcc 4").
    
    Ard points out that RHEL 7 uses gcc-4.8, but the people who stay back on
    old RHEL versions persumably also don't build their own kernels anyway.
    And maybe they should cross-built or just have a little side affair with
    a newer compiler?
    
    Acked-by: Ard Biesheuvel <ardb@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index c036a4a2f8e2..a1570c8bab25 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -31,15 +31,6 @@
 #if defined(__APCS_26__)
 #error Sorry, your compiler targets APCS-26 but this kernel requires APCS-32
 #endif
-/*
- * GCC 4.8.0-4.8.2: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58854
- *	      miscompiles find_get_entry(), and can result in EXT3 and EXT4
- *	      filesystem corruption (possibly other FS too).
- */
-#if defined(GCC_VERSION) && GCC_VERSION >= 40800 && GCC_VERSION < 40803
-#error Your compiler is too buggy; it is known to miscompile kernels
-#error and result in filesystem corruption and oopses.
-#endif
 
 int main(void)
 {

commit 541ad0150ca4aa663a2dcb9c834ab493168fe494
Author: Marc Zyngier <maz@kernel.org>
Date:   Fri Jan 24 22:42:15 2020 +0000

    arm: Remove 32bit KVM host support
    
    That's it. Remove all references to KVM itself, and document
    that although it is no more, the ABI between SVC and HYP still
    exists.
    
    Signed-off-by: Marc Zyngier <maz@kernel.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Acked-by: Christoffer Dall <christoffer.dall@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index c773b829ee8e..c036a4a2f8e2 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -11,9 +11,6 @@
 #include <linux/sched.h>
 #include <linux/mm.h>
 #include <linux/dma-mapping.h>
-#ifdef CONFIG_KVM_ARM_HOST
-#include <linux/kvm_host.h>
-#endif
 #include <asm/cacheflush.h>
 #include <asm/glue-df.h>
 #include <asm/glue-pf.h>
@@ -167,14 +164,6 @@ int main(void)
   DEFINE(CACHE_WRITEBACK_ORDER, __CACHE_WRITEBACK_ORDER);
   DEFINE(CACHE_WRITEBACK_GRANULE, __CACHE_WRITEBACK_GRANULE);
   BLANK();
-#ifdef CONFIG_KVM_ARM_HOST
-  DEFINE(VCPU_GUEST_CTXT,	offsetof(struct kvm_vcpu, arch.ctxt));
-  DEFINE(VCPU_HOST_CTXT,	offsetof(struct kvm_vcpu, arch.host_cpu_context));
-  DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
-  DEFINE(CPU_CTXT_GP_REGS,	offsetof(struct kvm_cpu_context, gp_regs));
-  DEFINE(GP_REGS_USR,		offsetof(struct kvm_regs, usr_regs));
-#endif
-  BLANK();
 #ifdef CONFIG_VDSO
   DEFINE(VDSO_DATA_SIZE,	sizeof(union vdso_data_store));
 #endif

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 28b27104ac0c..c773b829ee8e 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Copyright (C) 1995-2003 Russell King
  *               2001-2002 Keith Owens
@@ -5,10 +6,6 @@
  * Generate definitions needed by assembly language modules.
  * This code generates raw asm output which is post-processed to extract
  * and format the required data.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/compiler.h>
 #include <linux/sched.h>

commit 189af4657186da08a2e79fb8e906cfd82b2ccddc
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Dec 6 09:32:57 2018 +0100

    ARM: smp: add support for per-task stack canaries
    
    On ARM, we currently only change the value of the stack canary when
    switching tasks if the kernel was built for UP. On SMP kernels, this
    is impossible since the stack canary value is obtained via a global
    symbol reference, which means
    a) all running tasks on all CPUs must use the same value
    b) we can only modify the value when no kernel stack frames are live
       on any CPU, which is effectively never.
    
    So instead, use a GCC plugin to add a RTL pass that replaces each
    reference to the address of the __stack_chk_guard symbol with an
    expression that produces the address of the 'stack_canary' field
    that is added to struct thread_info. This way, each task will use
    its own randomized value.
    
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Laura Abbott <labbott@redhat.com>
    Cc: kernel-hardening@lists.openwall.com
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 3968d6c22455..28b27104ac0c 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -79,6 +79,10 @@ int main(void)
 #ifdef CONFIG_CRUNCH
   DEFINE(TI_CRUNCH_STATE,	offsetof(struct thread_info, crunchstate));
 #endif
+#ifdef CONFIG_STACKPROTECTOR_PER_TASK
+  DEFINE(TI_STACK_CANARY,	offsetof(struct thread_info, stack_canary));
+#endif
+  DEFINE(THREAD_SZ_ORDER,	THREAD_SIZE_ORDER);
   BLANK();
   DEFINE(S_R0,			offsetof(struct pt_regs, ARM_r0));
   DEFINE(S_R1,			offsetof(struct pt_regs, ARM_r1));

commit 815f0ddb346c196018d4d8f8f55c12b83da1de3f
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Wed Aug 22 16:37:24 2018 -0700

    include/linux/compiler*.h: make compiler-*.h mutually exclusive
    
    Commit cafa0010cd51 ("Raise the minimum required gcc version to 4.6")
    recently exposed a brittle part of the build for supporting non-gcc
    compilers.
    
    Both Clang and ICC define __GNUC__, __GNUC_MINOR__, and
    __GNUC_PATCHLEVEL__ for quick compatibility with code bases that haven't
    added compiler specific checks for __clang__ or __INTEL_COMPILER.
    
    This is brittle, as they happened to get compatibility by posing as a
    certain version of GCC.  This broke when upgrading the minimal version
    of GCC required to build the kernel, to a version above what ICC and
    Clang claim to be.
    
    Rather than always including compiler-gcc.h then undefining or
    redefining macros in compiler-intel.h or compiler-clang.h, let's
    separate out the compiler specific macro definitions into mutually
    exclusive headers, do more proper compiler detection, and keep shared
    definitions in compiler_types.h.
    
    Fixes: cafa0010cd51 ("Raise the minimum required gcc version to 4.6")
    Reported-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Suggested-by: Eli Friedman <efriedma@codeaurora.org>
    Suggested-by: Joe Perches <joe@perches.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 974d8d7d1bcd..3968d6c22455 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -38,25 +38,14 @@
 #error Sorry, your compiler targets APCS-26 but this kernel requires APCS-32
 #endif
 /*
- * GCC 3.0, 3.1: general bad code generation.
- * GCC 3.2.0: incorrect function argument offset calculation.
- * GCC 3.2.x: miscompiles NEW_AUX_ENT in fs/binfmt_elf.c
- *            (http://gcc.gnu.org/PR8896) and incorrect structure
- *	      initialisation in fs/jffs2/erase.c
  * GCC 4.8.0-4.8.2: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58854
  *	      miscompiles find_get_entry(), and can result in EXT3 and EXT4
  *	      filesystem corruption (possibly other FS too).
  */
-#ifdef __GNUC__
-#if (__GNUC__ == 3 && __GNUC_MINOR__ < 3)
-#error Your compiler is too buggy; it is known to miscompile kernels.
-#error    Known good compilers: 3.3, 4.x
-#endif
-#if GCC_VERSION >= 40800 && GCC_VERSION < 40803
+#if defined(GCC_VERSION) && GCC_VERSION >= 40800 && GCC_VERSION < 40803
 #error Your compiler is too buggy; it is known to miscompile kernels
 #error and result in filesystem corruption and oopses.
 #endif
-#endif
 
 int main(void)
 {

commit 050e9baa9dc9fbd9ce2b27f0056990fc9e0a08a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 14 12:21:18 2018 +0900

    Kbuild: rename CC_STACKPROTECTOR[_STRONG] config variables
    
    The changes to automatically test for working stack protector compiler
    support in the Kconfig files removed the special STACKPROTECTOR_AUTO
    option that picked the strongest stack protector that the compiler
    supported.
    
    That was all a nice cleanup - it makes no sense to have the AUTO case
    now that the Kconfig phase can just determine the compiler support
    directly.
    
    HOWEVER.
    
    It also meant that doing "make oldconfig" would now _disable_ the strong
    stackprotector if you had AUTO enabled, because in a legacy config file,
    the sane stack protector configuration would look like
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      # CONFIG_CC_STACKPROTECTOR_NONE is not set
      # CONFIG_CC_STACKPROTECTOR_REGULAR is not set
      # CONFIG_CC_STACKPROTECTOR_STRONG is not set
      CONFIG_CC_STACKPROTECTOR_AUTO=y
    
    and when you ran this through "make oldconfig" with the Kbuild changes,
    it would ask you about the regular CONFIG_CC_STACKPROTECTOR (that had
    been renamed from CONFIG_CC_STACKPROTECTOR_REGULAR to just
    CONFIG_CC_STACKPROTECTOR), but it would think that the STRONG version
    used to be disabled (because it was really enabled by AUTO), and would
    disable it in the new config, resulting in:
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      CONFIG_CC_HAS_STACKPROTECTOR_NONE=y
      CONFIG_CC_STACKPROTECTOR=y
      # CONFIG_CC_STACKPROTECTOR_STRONG is not set
      CONFIG_CC_HAS_SANE_STACKPROTECTOR=y
    
    That's dangerously subtle - people could suddenly find themselves with
    the weaker stack protector setup without even realizing.
    
    The solution here is to just rename not just the old RECULAR stack
    protector option, but also the strong one.  This does that by just
    removing the CC_ prefix entirely for the user choices, because it really
    is not about the compiler support (the compiler support now instead
    automatially impacts _visibility_ of the options to users).
    
    This results in "make oldconfig" actually asking the user for their
    choice, so that we don't have any silent subtle security model changes.
    The end result would generally look like this:
    
      CONFIG_HAVE_CC_STACKPROTECTOR=y
      CONFIG_CC_HAS_STACKPROTECTOR_NONE=y
      CONFIG_STACKPROTECTOR=y
      CONFIG_STACKPROTECTOR_STRONG=y
      CONFIG_CC_HAS_SANE_STACKPROTECTOR=y
    
    where the "CC_" versions really are about internal compiler
    infrastructure, not the user selections.
    
    Acked-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 27c5381518d8..974d8d7d1bcd 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -61,7 +61,7 @@
 int main(void)
 {
   DEFINE(TSK_ACTIVE_MM,		offsetof(struct task_struct, active_mm));
-#ifdef CONFIG_CC_STACKPROTECTOR
+#ifdef CONFIG_STACKPROTECTOR
   DEFINE(TSK_STACK_CANARY,	offsetof(struct task_struct, stack_canary));
 #endif
   BLANK();

commit 046835b4aa22b9ab6aa0bb274e3b71047c4b887d
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Tue Apr 3 10:39:23 2018 +0100

    ARM: 8757/1: NOMMU: Support PMSAv8 MPU
    
    ARMv8R/M architecture defines new memory protection scheme - PMSAv8
    which is not compatible with PMSAv7.
    
    Key differences to PMSAv7 are:
     - Region geometry is defined by base and limit addresses
     - Addresses need to be either 32 or 64 byte aligned
     - No region priority due to overlapping regions are not allowed
     - It is unified, i.e. no distinction between data/instruction regions
     - Memory attributes are controlled via MAIR
    
    This patch implements support for PMSAv8 MPU defined by ARMv8R/M
    architecture.
    
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 250a98544ca6..27c5381518d8 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -197,6 +197,8 @@ int main(void)
   DEFINE(MPU_RGN_DRBAR,	offsetof(struct mpu_rgn, drbar));
   DEFINE(MPU_RGN_DRSR,	offsetof(struct mpu_rgn, drsr));
   DEFINE(MPU_RGN_DRACR,	offsetof(struct mpu_rgn, dracr));
+  DEFINE(MPU_RGN_PRBAR,	offsetof(struct mpu_rgn, prbar));
+  DEFINE(MPU_RGN_PRLAR,	offsetof(struct mpu_rgn, prlar));
 #endif
   return 0; 
 }

commit 9cfb541a4ad45168925078f7d1fe3a7363ba27e2
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Tue Apr 3 10:36:37 2018 +0100

    ARM: 8754/1: NOMMU: Move PMSAv7 MPU under it's own namespace
    
    We are going to support different MPU which programming model is not
    compatible to PMSAv7, so move PMSAv7 MPU under it's own namespace.
    
    Tested-by: Szemz? András <sza@esh.hu>
    Tested-by: Alexandre TORGUE <alexandre.torgue@st.com>
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index f369ece99958..250a98544ca6 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -194,9 +194,9 @@ int main(void)
   DEFINE(MPU_RNG_INFO_USED,	offsetof(struct mpu_rgn_info, used));
 
   DEFINE(MPU_RNG_SIZE,		sizeof(struct mpu_rgn));
-  DEFINE(MPU_RGN_DRBAR,		offsetof(struct mpu_rgn, drbar));
-  DEFINE(MPU_RGN_DRSR,		offsetof(struct mpu_rgn, drsr));
-  DEFINE(MPU_RGN_DRACR,		offsetof(struct mpu_rgn, dracr));
+  DEFINE(MPU_RGN_DRBAR,	offsetof(struct mpu_rgn, drbar));
+  DEFINE(MPU_RGN_DRSR,	offsetof(struct mpu_rgn, drsr));
+  DEFINE(MPU_RGN_DRACR,	offsetof(struct mpu_rgn, dracr));
 #endif
   return 0; 
 }

commit a0995c0805b63c930b99970f2c9d5e4f167ca65b
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Mon Oct 16 12:54:05 2017 +0100

    ARM: 8708/1: NOMMU: Rework MPU to be mostly done in C
    
    Currently, there are several issues with how MPU is setup:
    
     1. We won't boot if MPU is missing
     2. We won't boot if use XIP
     3. Further extension of MPU setup requires asm skills
    
    The 1st point can be relaxed, so we can continue with boot CPU even if
    MPU is missed and fail boot for secondaries only. To address the 2nd
    point we could create region covering CONFIG_XIP_PHYS_ADDR - _end and
    that might work for the first stage of MPU enable, but due to MPU's
    alignment requirement we could cover too much, IOW we need more
    flexibility in how we're partitioning memory regions... and it'd be
    hardly possible to archive because of the 3rd point.
    
    This patch is trying to address 1st and 3rd issues and paves the path
    for 2nd and further improvements.
    
    The most visible change introduced with this patch is that we start
    using mpu_rgn_info array (as it was supposed?), so change in MPU setup
    done by boot CPU is recorded there and feed to secondaries. It
    allows us to keep minimal region setup for boot CPU and do the rest in
    C. Since we start programming MPU regions in C evaluation of MPU
    constrains (number of regions supported and minimal region order) can
    be done once, which in turn open possibility to free-up "probe"
    region early.
    
    Tested-by: Szemző András <sza@esh.hu>
    Tested-by: Alexandre TORGUE <alexandre.torgue@st.com>
    Tested-by: Benjamin Gaignard <benjamin.gaignard@linaro.org>
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 13c155850822..f369ece99958 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -23,6 +23,7 @@
 #include <asm/mach/arch.h>
 #include <asm/thread_info.h>
 #include <asm/memory.h>
+#include <asm/mpu.h>
 #include <asm/procinfo.h>
 #include <asm/suspend.h>
 #include <asm/vdso_datapage.h>
@@ -186,6 +187,16 @@ int main(void)
   BLANK();
 #ifdef CONFIG_VDSO
   DEFINE(VDSO_DATA_SIZE,	sizeof(union vdso_data_store));
+#endif
+  BLANK();
+#ifdef CONFIG_ARM_MPU
+  DEFINE(MPU_RNG_INFO_RNGS,	offsetof(struct mpu_rgn_info, rgns));
+  DEFINE(MPU_RNG_INFO_USED,	offsetof(struct mpu_rgn_info, used));
+
+  DEFINE(MPU_RNG_SIZE,		sizeof(struct mpu_rgn));
+  DEFINE(MPU_RGN_DRBAR,		offsetof(struct mpu_rgn, drbar));
+  DEFINE(MPU_RGN_DRSR,		offsetof(struct mpu_rgn, drsr));
+  DEFINE(MPU_RGN_DRACR,		offsetof(struct mpu_rgn, dracr));
 #endif
   return 0; 
 }

commit 5c16595353e0743af99294db48549c3145e3a5ad
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Wed Aug 9 23:42:51 2017 -0400

    ARM: signal handling support for FDPIC_FUNCPTRS functions
    
    Signal handlers are not direct function pointers but pointers to function
    descriptor in that case. Therefore we must retrieve the actual function
    address and load the GOT value into r9 from the descriptor before branching
    to the actual handler.
    
    If a restorer is provided, we also have to load its address and GOT from
    its descriptor. That descriptor address and the code to load it is pushed
    onto the stack to be executed as soon as the signal handler returns.
    
    However, to be compatible with NX stacks, the FDPIC bounce code is also
    copied to the signal page along with the other code stubs. Therefore this
    code must get at the descriptor address whether it executes from the stack
    or the signal page. To do so we use the stack pointer which points at the
    signal stack frame where the descriptor address was stored. Because the
    rt signal frame is different from the simpler frame, two versions of the
    bounce code are needed, and two variants (ARM and Thumb) as well. The
    asm-offsets facility is used to determine the actual offset in the signal
    frame for each version, meaning that struct sigframe and rt_sigframe had
    to be moved to a separate file.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Mickael GUENE <mickael.guene@st.com>
    Tested-by: Vincent Abriou <vincent.abriou@st.com>
    Tested-by: Andras Szemzo <szemzo.andras@gmail.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 608008229c7d..13c155850822 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -28,6 +28,7 @@
 #include <asm/vdso_datapage.h>
 #include <asm/hardware/cache-l2x0.h>
 #include <linux/kbuild.h>
+#include "signal.h"
 
 /*
  * Make sure that the compiler and target are compatible.
@@ -112,6 +113,9 @@ int main(void)
   DEFINE(SVC_ADDR_LIMIT,	offsetof(struct svc_pt_regs, addr_limit));
   DEFINE(SVC_REGS_SIZE,		sizeof(struct svc_pt_regs));
   BLANK();
+  DEFINE(SIGFRAME_RC3_OFFSET,	offsetof(struct sigframe, retcode[3]));
+  DEFINE(RT_SIGFRAME_RC3_OFFSET, offsetof(struct rt_sigframe, sig.retcode[3]));
+  BLANK();
 #ifdef CONFIG_CACHE_L2X0
   DEFINE(L2X0_R_PHY_BASE,	offsetof(struct l2x0_regs, phy_base));
   DEFINE(L2X0_R_AUX_CTRL,	offsetof(struct l2x0_regs, aux_ctrl));

commit e6978e4bf181fb3b5f8cb6f71b4fe30fbf1b655c
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Fri May 13 11:40:20 2016 +0100

    ARM: save and reset the address limit when entering an exception
    
    When we enter an exception, the current address limit should not apply
    to the exception context: if the exception context wishes to access
    kernel space via the user accessors (eg, perf code), it must explicitly
    request such access.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 9a8ce342cd82..608008229c7d 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -109,6 +109,7 @@ int main(void)
   DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
   DEFINE(PT_REGS_SIZE,		sizeof(struct pt_regs));
   DEFINE(SVC_DACR,		offsetof(struct svc_pt_regs, dacr));
+  DEFINE(SVC_ADDR_LIMIT,	offsetof(struct svc_pt_regs, addr_limit));
   DEFINE(SVC_REGS_SIZE,		sizeof(struct svc_pt_regs));
   BLANK();
 #ifdef CONFIG_CACHE_L2X0

commit e6a9dc6129d23cd3025e841c4e13a70910a37135
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Fri May 13 10:22:38 2016 +0100

    ARM: introduce svc_pt_regs structure
    
    Since the privileged mode pt_regs are an extended version of the saved
    userland pt_regs, introduce a new svc_pt_regs structure to describe this
    layout.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 2841c9980bcd..9a8ce342cd82 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -108,6 +108,8 @@ int main(void)
   DEFINE(S_PSR,			offsetof(struct pt_regs, ARM_cpsr));
   DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
   DEFINE(PT_REGS_SIZE,		sizeof(struct pt_regs));
+  DEFINE(SVC_DACR,		offsetof(struct svc_pt_regs, dacr));
+  DEFINE(SVC_REGS_SIZE,		sizeof(struct svc_pt_regs));
   BLANK();
 #ifdef CONFIG_CACHE_L2X0
   DEFINE(L2X0_R_PHY_BASE,	offsetof(struct l2x0_regs, phy_base));

commit 5745eef6b813194b4dd3e2aee1dd712d8512bf91
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue May 10 16:34:27 2016 +0100

    ARM: rename S_FRAME_SIZE to PT_REGS_SIZE
    
    S_FRAME_SIZE is no longer the size of the kernel stack frame, so this
    name is misleading.  It is the size of the kernel pt_regs structure.
    Name it so.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 27d05813ff09..2841c9980bcd 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -107,7 +107,7 @@ int main(void)
   DEFINE(S_PC,			offsetof(struct pt_regs, ARM_pc));
   DEFINE(S_PSR,			offsetof(struct pt_regs, ARM_cpsr));
   DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
-  DEFINE(S_FRAME_SIZE,		sizeof(struct pt_regs));
+  DEFINE(PT_REGS_SIZE,		sizeof(struct pt_regs));
   BLANK();
 #ifdef CONFIG_CACHE_L2X0
   DEFINE(L2X0_R_PHY_BASE,	offsetof(struct l2x0_regs, phy_base));

commit 311b5b363cd28aa778de083178f147f32622e331
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Jan 5 18:57:36 2016 +0000

    ARM: KVM: Remove unused hyp_pc field
    
    This field was never populated, and the panic code already
    does something similar. Delete the related code.
    
    Acked-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 1f24c32e11fe..27d05813ff09 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -175,7 +175,6 @@ int main(void)
   DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
   DEFINE(CPU_CTXT_GP_REGS,	offsetof(struct kvm_cpu_context, gp_regs));
   DEFINE(GP_REGS_USR,		offsetof(struct kvm_regs, usr_regs));
-  DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.fault.hyp_pc));
 #endif
   BLANK();
 #ifdef CONFIG_VDSO

commit ff3a01d1e029847abb2d0735843ac6f7ae1385ea
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Jan 5 18:54:07 2016 +0000

    ARM: KVM: Cleanup asm-offsets.c
    
    Since we don't have much assembler left, most of the KVM stuff
    in asm-offsets.c is now superfluous. Let's get rid of it.
    
    Acked-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 2f3e0b064066..1f24c32e11fe 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -170,42 +170,12 @@ int main(void)
   DEFINE(CACHE_WRITEBACK_GRANULE, __CACHE_WRITEBACK_GRANULE);
   BLANK();
 #ifdef CONFIG_KVM_ARM_HOST
-  DEFINE(VCPU_KVM,		offsetof(struct kvm_vcpu, kvm));
-  DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));
   DEFINE(VCPU_GUEST_CTXT,	offsetof(struct kvm_vcpu, arch.ctxt));
   DEFINE(VCPU_HOST_CTXT,	offsetof(struct kvm_vcpu, arch.host_cpu_context));
   DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
-  DEFINE(CPU_CTXT_CP15,		offsetof(struct kvm_cpu_context, cp15));
   DEFINE(CPU_CTXT_GP_REGS,	offsetof(struct kvm_cpu_context, gp_regs));
   DEFINE(GP_REGS_USR,		offsetof(struct kvm_regs, usr_regs));
-  DEFINE(GP_REGS_SVC,		offsetof(struct kvm_regs, svc_regs));
-  DEFINE(GP_REGS_ABT,		offsetof(struct kvm_regs, abt_regs));
-  DEFINE(GP_REGS_UND,		offsetof(struct kvm_regs, und_regs));
-  DEFINE(GP_REGS_IRQ,		offsetof(struct kvm_regs, irq_regs));
-  DEFINE(GP_REGS_FIQ,		offsetof(struct kvm_regs, fiq_regs));
-  DEFINE(GP_REGS_PC,		offsetof(struct kvm_regs, usr_regs.ARM_pc));
-  DEFINE(GP_REGS_CPSR,		offsetof(struct kvm_regs, usr_regs.ARM_cpsr));
-  DEFINE(VCPU_HCR,		offsetof(struct kvm_vcpu, arch.hcr));
-  DEFINE(VCPU_IRQ_LINES,	offsetof(struct kvm_vcpu, arch.irq_lines));
-  DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.fault.hsr));
-  DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.fault.hxfar));
-  DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.fault.hpfar));
   DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.fault.hyp_pc));
-  DEFINE(VCPU_VGIC_CPU,		offsetof(struct kvm_vcpu, arch.vgic_cpu));
-  DEFINE(VGIC_V2_CPU_HCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_hcr));
-  DEFINE(VGIC_V2_CPU_VMCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_vmcr));
-  DEFINE(VGIC_V2_CPU_MISR,	offsetof(struct vgic_cpu, vgic_v2.vgic_misr));
-  DEFINE(VGIC_V2_CPU_EISR,	offsetof(struct vgic_cpu, vgic_v2.vgic_eisr));
-  DEFINE(VGIC_V2_CPU_ELRSR,	offsetof(struct vgic_cpu, vgic_v2.vgic_elrsr));
-  DEFINE(VGIC_V2_CPU_APR,	offsetof(struct vgic_cpu, vgic_v2.vgic_apr));
-  DEFINE(VGIC_V2_CPU_LR,	offsetof(struct vgic_cpu, vgic_v2.vgic_lr));
-  DEFINE(VGIC_CPU_NR_LR,	offsetof(struct vgic_cpu, nr_lr));
-  DEFINE(VCPU_TIMER_CNTV_CTL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_ctl));
-  DEFINE(VCPU_TIMER_CNTV_CVAL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_cval));
-  DEFINE(KVM_TIMER_CNTVOFF,	offsetof(struct kvm, arch.timer.cntvoff));
-  DEFINE(KVM_TIMER_ENABLED,	offsetof(struct kvm, arch.timer.enabled));
-  DEFINE(KVM_VGIC_VCTRL,	offsetof(struct kvm, arch.vgic.vctrl_base));
-  DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));
 #endif
   BLANK();
 #ifdef CONFIG_VDSO

commit c2a8dab507ca6f8990c12372052efc830f51dd3f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Sun Jan 3 11:26:01 2016 +0000

    ARM: KVM: Move GP registers into the CPU context structure
    
    Continuing our rework of the CPU context, we now move the GP
    registers into the CPU context structure.
    
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 43f8b01072c1..2f3e0b064066 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -176,15 +176,15 @@ int main(void)
   DEFINE(VCPU_HOST_CTXT,	offsetof(struct kvm_vcpu, arch.host_cpu_context));
   DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
   DEFINE(CPU_CTXT_CP15,		offsetof(struct kvm_cpu_context, cp15));
-  DEFINE(VCPU_REGS,		offsetof(struct kvm_vcpu, arch.regs));
-  DEFINE(VCPU_USR_REGS,		offsetof(struct kvm_vcpu, arch.regs.usr_regs));
-  DEFINE(VCPU_SVC_REGS,		offsetof(struct kvm_vcpu, arch.regs.svc_regs));
-  DEFINE(VCPU_ABT_REGS,		offsetof(struct kvm_vcpu, arch.regs.abt_regs));
-  DEFINE(VCPU_UND_REGS,		offsetof(struct kvm_vcpu, arch.regs.und_regs));
-  DEFINE(VCPU_IRQ_REGS,		offsetof(struct kvm_vcpu, arch.regs.irq_regs));
-  DEFINE(VCPU_FIQ_REGS,		offsetof(struct kvm_vcpu, arch.regs.fiq_regs));
-  DEFINE(VCPU_PC,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_pc));
-  DEFINE(VCPU_CPSR,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_cpsr));
+  DEFINE(CPU_CTXT_GP_REGS,	offsetof(struct kvm_cpu_context, gp_regs));
+  DEFINE(GP_REGS_USR,		offsetof(struct kvm_regs, usr_regs));
+  DEFINE(GP_REGS_SVC,		offsetof(struct kvm_regs, svc_regs));
+  DEFINE(GP_REGS_ABT,		offsetof(struct kvm_regs, abt_regs));
+  DEFINE(GP_REGS_UND,		offsetof(struct kvm_regs, und_regs));
+  DEFINE(GP_REGS_IRQ,		offsetof(struct kvm_regs, irq_regs));
+  DEFINE(GP_REGS_FIQ,		offsetof(struct kvm_regs, fiq_regs));
+  DEFINE(GP_REGS_PC,		offsetof(struct kvm_regs, usr_regs.ARM_pc));
+  DEFINE(GP_REGS_CPSR,		offsetof(struct kvm_regs, usr_regs.ARM_cpsr));
   DEFINE(VCPU_HCR,		offsetof(struct kvm_vcpu, arch.hcr));
   DEFINE(VCPU_IRQ_LINES,	offsetof(struct kvm_vcpu, arch.irq_lines));
   DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.fault.hsr));

commit fb32a52a1d4487f3ac5b7ccb659d0beb11ec504f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Sun Jan 3 11:26:01 2016 +0000

    ARM: KVM: Move CP15 array into the CPU context structure
    
    Continuing our rework of the CPU context, we now move the CP15
    array into the CPU context structure. As this causes quite a bit
    of churn, we introduce the vcpu_cp15() macro that abstract the
    location of the actual array. This will probably help next time
    we have to revisit that code.
    
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 346bfca29720..43f8b01072c1 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -172,10 +172,10 @@ int main(void)
 #ifdef CONFIG_KVM_ARM_HOST
   DEFINE(VCPU_KVM,		offsetof(struct kvm_vcpu, kvm));
   DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));
-  DEFINE(VCPU_CP15,		offsetof(struct kvm_vcpu, arch.cp15));
   DEFINE(VCPU_GUEST_CTXT,	offsetof(struct kvm_vcpu, arch.ctxt));
   DEFINE(VCPU_HOST_CTXT,	offsetof(struct kvm_vcpu, arch.host_cpu_context));
   DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
+  DEFINE(CPU_CTXT_CP15,		offsetof(struct kvm_cpu_context, cp15));
   DEFINE(VCPU_REGS,		offsetof(struct kvm_vcpu, arch.regs));
   DEFINE(VCPU_USR_REGS,		offsetof(struct kvm_vcpu, arch.regs.usr_regs));
   DEFINE(VCPU_SVC_REGS,		offsetof(struct kvm_vcpu, arch.regs.svc_regs));

commit 0ca5565df8ef7534c0d85ec87e6c74f8ebe86e88
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Sun Jan 3 11:01:49 2016 +0000

    ARM: KVM: Move VFP registers to a CPU context structure
    
    In order to turn the WS code into something that looks a bit
    more like the arm64 version, move the VFP registers into a
    CPU context container for both the host and the guest.
    
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 871b8267d211..346bfca29720 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -173,8 +173,9 @@ int main(void)
   DEFINE(VCPU_KVM,		offsetof(struct kvm_vcpu, kvm));
   DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));
   DEFINE(VCPU_CP15,		offsetof(struct kvm_vcpu, arch.cp15));
-  DEFINE(VCPU_VFP_GUEST,	offsetof(struct kvm_vcpu, arch.vfp_guest));
-  DEFINE(VCPU_VFP_HOST,		offsetof(struct kvm_vcpu, arch.host_cpu_context));
+  DEFINE(VCPU_GUEST_CTXT,	offsetof(struct kvm_vcpu, arch.ctxt));
+  DEFINE(VCPU_HOST_CTXT,	offsetof(struct kvm_vcpu, arch.host_cpu_context));
+  DEFINE(CPU_CTXT_VFP,		offsetof(struct kvm_cpu_context, vfp));
   DEFINE(VCPU_REGS,		offsetof(struct kvm_vcpu, arch.regs));
   DEFINE(VCPU_USR_REGS,		offsetof(struct kvm_vcpu, arch.regs.usr_regs));
   DEFINE(VCPU_SVC_REGS,		offsetof(struct kvm_vcpu, arch.regs.svc_regs));

commit fa2e5c073a355465a2a8c9a2fbecf404f9857c3a
Merge: e44740c1a94b 97b2f0dc3314
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 15 13:53:55 2015 -0700

    Merge branch 'exec_domain_rip_v2' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/misc
    
    Pull exec domain removal from Richard Weinberger:
     "This series removes execution domain support from Linux.
    
      The idea behind exec domains was to support different ABIs.  The
      feature was never complete nor stable.  Let's rip it out and make the
      kernel signal handling code less complicated"
    
    * 'exec_domain_rip_v2' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/misc: (27 commits)
      arm64: Removed unused variable
      sparc: Fix execution domain removal
      Remove rest of exec domains.
      arch: Remove exec_domain from remaining archs
      arc: Remove signal translation and exec_domain
      xtensa: Remove signal translation and exec_domain
      xtensa: Autogenerate offsets in struct thread_info
      x86: Remove signal translation and exec_domain
      unicore32: Remove signal translation and exec_domain
      um: Remove signal translation and exec_domain
      tile: Remove signal translation and exec_domain
      sparc: Remove signal translation and exec_domain
      sh: Remove signal translation and exec_domain
      s390: Remove signal translation and exec_domain
      mn10300: Remove signal translation and exec_domain
      microblaze: Remove signal translation and exec_domain
      m68k: Remove signal translation and exec_domain
      m32r: Remove signal translation and exec_domain
      m32r: Autogenerate offsets in struct thread_info
      frv: Remove signal translation and exec_domain
      ...

commit bb0fd7ab0986105765d11baa82e619c618a235aa
Merge: bdfa54dfd9ee 4b2f8838479e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 14 21:03:26 2015 -0700

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "Included in this update are both some long term fixes and some new
      features.
    
      Fixes:
    
       - An integer overflow in the calculation of ELF_ET_DYN_BASE.
    
       - Avoiding OOMs for high-order IOMMU allocations
    
       - SMP requires the data cache to be enabled for synchronisation
         primitives to work, so prevent the CPU_DCACHE_DISABLE option being
         visible on SMP builds.
    
       - A bug going back 10+ years in the noMMU ARM94* CPU support code,
         where it corrupts registers.  Found by folk getting Linux running
         on their cameras.
    
       - Versatile Express needs an errata workaround enabled for CPU
         hot-unplug to work.
    
      Features:
    
       - Clean up module linker by handling out of range relocations
         separately from relocation cases we don't handle.
    
       - Fix a long term bug in the pci_mmap_page_range() code, which we
         hope won't impact userspace (we hope there's no users of the
         existing broken interface.)
    
       - Don't map DMA coherent allocations when we don't have a MMU.
    
       - Drop experimental status for SMP_ON_UP.
    
       - Warn when DT doesn't specify ePAPR mandatory cache properties.
    
       - Add documentation concerning how we find the start of physical
         memory for AUTO_ZRELADDR kernels, detailing why we have chosen the
         mask and the implications of changing it.
    
       - Updates from Ard Biesheuvel to address some issues with large
         kernels (such as allyesconfig) failing to link.
    
       - Allow hibernation to work on modern (ARMv7) CPUs - this appears to
         have never worked in the past on these CPUs.
    
       - Enable IRQ_SHOW_LEVEL, which changes the /proc/interrupts output
         format (hopefully without userspace breaking...  let's hope that if
         it causes someone a problem, they tell us.)
    
       - Fix tegra-ahb DT offsets.
    
       - Rework ARM errata 643719 code (and ARMv7 flush_cache_louis()/
         flush_dcache_all()) code to be more efficient, and enable this
         errata workaround by default for ARMv7+SMP CPUs.  This complements
         the Versatile Express fix above.
    
       - Rework ARMv7 context code for errata 430973, so that only Cortex A8
         CPUs are impacted by the branch target buffer flush when this
         errata is enabled.  Also update the help text to indicate that all
         r1p* A8 CPUs are impacted.
    
       - Switch ARM to the generic show_mem() implementation, it conveys all
         the information which we were already reporting.
    
       - Prevent slow timer sources being used for udelay() - timers running
         at less than 1MHz are not useful for this, and can cause udelay()
         to return immediately, without any wait.  Using such a slow timer
         is silly.
    
       - VDSO support for 32-bit ARM, mainly for gettimeofday() using the
         ARM architected timer.
    
       - Perf support for Scorpion performance monitoring units"
    
    vdso semantic conflict fixed up as per linux-next.
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (52 commits)
      ARM: update errata 430973 documentation to cover Cortex A8 r1p*
      ARM: ensure delay timer has sufficient accuracy for delays
      ARM: switch to use the generic show_mem() implementation
      ARM: proc-v7: avoid errata 430973 workaround for non-Cortex A8 CPUs
      ARM: enable ARM errata 643719 workaround by default
      ARM: cache-v7: optimise test for Cortex A9 r0pX devices
      ARM: cache-v7: optimise branches in v7_flush_cache_louis
      ARM: cache-v7: consolidate initialisation of cache level index
      ARM: cache-v7: shift CLIDR to extract appropriate field before masking
      ARM: cache-v7: use movw/movt instructions
      ARM: allow 16-bit instructions in ALT_UP()
      ARM: proc-arm94*.S: fix setup function
      ARM: vexpress: fix CPU hotplug with CT9x4 tile.
      ARM: 8276/1: Make CPU_DCACHE_DISABLE depend on !SMP
      ARM: 8335/1: Documentation: DT bindings: Tegra AHB: document the legacy base address
      ARM: 8334/1: amba: tegra-ahb: detect and correct bogus base address
      ARM: 8333/1: amba: tegra-ahb: fix register offsets in the macros
      ARM: 8339/1: Enable CONFIG_GENERIC_IRQ_SHOW_LEVEL
      ARM: 8338/1: kexec: Relax SMP validation to improve DT compatibility
      ARM: 8337/1: mm: Do not invoke OOM for higher order IOMMU DMA allocations
      ...

commit a4980448ed658db313da3195bcca634c7a5adafa
Author: Richard Weinberger <richard@nod.at>
Date:   Sun Jul 13 15:24:03 2014 +0200

    arm: Remove signal translation and exec_domain
    
    As execution domain support is gone we can remove
    signal translation from the signal code and remove
    exec_domain from thread_info.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 2d2d6087b9b1..70d277ce235f 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -66,7 +66,6 @@ int main(void)
   DEFINE(TI_PREEMPT,		offsetof(struct thread_info, preempt_count));
   DEFINE(TI_ADDR_LIMIT,		offsetof(struct thread_info, addr_limit));
   DEFINE(TI_TASK,		offsetof(struct thread_info, task));
-  DEFINE(TI_EXEC_DOMAIN,	offsetof(struct thread_info, exec_domain));
   DEFINE(TI_CPU,		offsetof(struct thread_info, cpu));
   DEFINE(TI_CPU_DOMAIN,		offsetof(struct thread_info, cpu_domain));
   DEFINE(TI_CPU_SAVE,		offsetof(struct thread_info, cpu_context));

commit 8512287a8165592466cb9cb347ba94892e9c56a5
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Mar 25 19:14:22 2015 +0100

    ARM: 8330/1: add VDSO user-space code
    
    Place VDSO-related user-space code in arch/arm/kernel/vdso/.
    
    It is almost completely written in C with some assembly helpers to
    load the data page address, sample the counter, and fall back to
    system calls when necessary.
    
    The VDSO can service gettimeofday and clock_gettime when
    CONFIG_ARM_ARCH_TIMER is enabled and the architected timer is present
    (and correctly configured).  It reads the CP15-based virtual counter
    to compute high-resolution timestamps.
    
    Of particular note is that a post-processing step ("vdsomunge") is
    necessary to produce a shared object which is architecturally allowed
    to be used by both soft- and hard-float EABI programs.
    
    The 2012 edition of the ARM ABI defines Tag_ABI_VFP_args = 3 "Code is
    compatible with both the base and VFP variants; the user did not
    permit non-variadic functions to pass FP parameters/results."
    Unfortunately current toolchains do not support this tag, which is
    ideally what we would use.
    
    The best available option is to ensure that both EF_ARM_ABI_FLOAT_SOFT
    and EF_ARM_ABI_FLOAT_HARD are unset in the ELF header's e_flags,
    indicating that the shared object is "old" and should be accepted for
    backward compatibility's sake.  While binutils < 2.24 appear to
    produce a vdso.so with both flags clear, 2.24 always sets
    EF_ARM_ABI_FLOAT_SOFT, with no way to inhibit this behavior.  So we
    have to fix things up with a custom post-processing step.
    
    In fact, the VDSO code in glibc does much less validation (including
    checking these flags) than the code for handling conventional
    file-backed shared libraries, so this is a bit moot unless glibc's
    VDSO code becomes more strict.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 2d2d6087b9b1..9147008f0d51 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -25,6 +25,7 @@
 #include <asm/memory.h>
 #include <asm/procinfo.h>
 #include <asm/suspend.h>
+#include <asm/vdso_datapage.h>
 #include <asm/hardware/cache-l2x0.h>
 #include <linux/kbuild.h>
 
@@ -209,6 +210,10 @@ int main(void)
   DEFINE(KVM_VGIC_VCTRL,	offsetof(struct kvm, arch.vgic.vctrl_base));
 #endif
   DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));
+#endif
+  BLANK();
+#ifdef CONFIG_VDSO
+  DEFINE(VDSO_DATA_SIZE,	sizeof(union vdso_data_store));
 #endif
   return 0; 
 }

commit 662d9715840aef44dcb573b0f9fab9e8319c868a
Author: Christoffer Dall <christoffer.dall@linaro.org>
Date:   Wed Mar 11 14:21:31 2015 +0100

    arm/arm64: KVM: Kill CONFIG_KVM_ARM_{VGIC,TIMER}
    
    We can definitely decide at run-time whether to use the GIC and timers
    or not, and the extra code and data structures that we allocate space
    for is really negligable with this config option, so I don't think it's
    worth the extra complexity of always having to define stub static
    inlines.  The !CONFIG_KVM_ARM_VGIC/TIMER case is pretty much an untested
    code path anyway, so we're better off just getting rid of it.
    
    Signed-off-by: Christoffer Dall <christoffer.dall@linaro.org>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 2d2d6087b9b1..488eaac56028 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -190,7 +190,6 @@ int main(void)
   DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.fault.hxfar));
   DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.fault.hpfar));
   DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.fault.hyp_pc));
-#ifdef CONFIG_KVM_ARM_VGIC
   DEFINE(VCPU_VGIC_CPU,		offsetof(struct kvm_vcpu, arch.vgic_cpu));
   DEFINE(VGIC_V2_CPU_HCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_hcr));
   DEFINE(VGIC_V2_CPU_VMCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_vmcr));
@@ -200,14 +199,11 @@ int main(void)
   DEFINE(VGIC_V2_CPU_APR,	offsetof(struct vgic_cpu, vgic_v2.vgic_apr));
   DEFINE(VGIC_V2_CPU_LR,	offsetof(struct vgic_cpu, vgic_v2.vgic_lr));
   DEFINE(VGIC_CPU_NR_LR,	offsetof(struct vgic_cpu, nr_lr));
-#ifdef CONFIG_KVM_ARM_TIMER
   DEFINE(VCPU_TIMER_CNTV_CTL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_ctl));
   DEFINE(VCPU_TIMER_CNTV_CVAL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_cval));
   DEFINE(KVM_TIMER_CNTVOFF,	offsetof(struct kvm, arch.timer.cntvoff));
   DEFINE(KVM_TIMER_ENABLED,	offsetof(struct kvm, arch.timer.enabled));
-#endif
   DEFINE(KVM_VGIC_VCTRL,	offsetof(struct kvm, arch.vgic.vctrl_base));
-#endif
   DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));
 #endif
   return 0; 

commit 7fc150543c73de71859631c8a6b17e3067fe7617
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 15 22:37:13 2014 +0100

    ARM: Blacklist GCC 4.8.0 to GCC 4.8.2 - PR58854
    
    These stock GCC versions miscompile the kernel by incorrectly optimising
    the function epilogue code - by first increasing the stack pointer, and
    then loading entries from below the stack.  This means that an opportune
    interrupt or exception will corrupt the current function's saved state,
    which may result in the parent function seeing different register
    values.
    
    As this bug has been known to result in corrupted filesystems, and these
    buggy compiler versions seem to be frequently used, we have little
    option but to blacklist these compiler versions.
    
    Distributions may have fixed PR58854, but as their compilers are totally
    indistinguishable from the buggy versions, it is unfortunate that this
    also results in those also being blacklisted.  Given the filesystem
    corruption potential of the original, this is the lesser evil.  People
    who want to build with their fixed compiler versions will need to adjust
    the kernel source.  (Distros need to think about the implications of
    fixing such a compiler bug, and consider how to ensure that their fixed
    compiler versions can be detected if they wish to avoid this.)
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 713e807621d2..2d2d6087b9b1 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -10,6 +10,7 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
+#include <linux/compiler.h>
 #include <linux/sched.h>
 #include <linux/mm.h>
 #include <linux/dma-mapping.h>
@@ -39,10 +40,19 @@
  * GCC 3.2.x: miscompiles NEW_AUX_ENT in fs/binfmt_elf.c
  *            (http://gcc.gnu.org/PR8896) and incorrect structure
  *	      initialisation in fs/jffs2/erase.c
+ * GCC 4.8.0-4.8.2: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58854
+ *	      miscompiles find_get_entry(), and can result in EXT3 and EXT4
+ *	      filesystem corruption (possibly other FS too).
  */
+#ifdef __GNUC__
 #if (__GNUC__ == 3 && __GNUC_MINOR__ < 3)
 #error Your compiler is too buggy; it is known to miscompile kernels.
-#error    Known good compilers: 3.3
+#error    Known good compilers: 3.3, 4.x
+#endif
+#if GCC_VERSION >= 40800 && GCC_VERSION < 40803
+#error Your compiler is too buggy; it is known to miscompile kernels
+#error and result in filesystem corruption and oopses.
+#endif
 #endif
 
 int main(void)

commit eede821dbfd58df89edb072da64e006321eaef58
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Thu May 30 10:20:36 2013 +0100

    KVM: arm/arm64: vgic: move GICv2 registers to their own structure
    
    In order to make way for the GICv3 registers, move the v2-specific
    registers to their own structure.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 85598b5d1efd..713e807621d2 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -182,13 +182,13 @@ int main(void)
   DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.fault.hyp_pc));
 #ifdef CONFIG_KVM_ARM_VGIC
   DEFINE(VCPU_VGIC_CPU,		offsetof(struct kvm_vcpu, arch.vgic_cpu));
-  DEFINE(VGIC_CPU_HCR,		offsetof(struct vgic_cpu, vgic_hcr));
-  DEFINE(VGIC_CPU_VMCR,		offsetof(struct vgic_cpu, vgic_vmcr));
-  DEFINE(VGIC_CPU_MISR,		offsetof(struct vgic_cpu, vgic_misr));
-  DEFINE(VGIC_CPU_EISR,		offsetof(struct vgic_cpu, vgic_eisr));
-  DEFINE(VGIC_CPU_ELRSR,	offsetof(struct vgic_cpu, vgic_elrsr));
-  DEFINE(VGIC_CPU_APR,		offsetof(struct vgic_cpu, vgic_apr));
-  DEFINE(VGIC_CPU_LR,		offsetof(struct vgic_cpu, vgic_lr));
+  DEFINE(VGIC_V2_CPU_HCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_hcr));
+  DEFINE(VGIC_V2_CPU_VMCR,	offsetof(struct vgic_cpu, vgic_v2.vgic_vmcr));
+  DEFINE(VGIC_V2_CPU_MISR,	offsetof(struct vgic_cpu, vgic_v2.vgic_misr));
+  DEFINE(VGIC_V2_CPU_EISR,	offsetof(struct vgic_cpu, vgic_v2.vgic_eisr));
+  DEFINE(VGIC_V2_CPU_ELRSR,	offsetof(struct vgic_cpu, vgic_v2.vgic_elrsr));
+  DEFINE(VGIC_V2_CPU_APR,	offsetof(struct vgic_cpu, vgic_v2.vgic_apr));
+  DEFINE(VGIC_V2_CPU_LR,	offsetof(struct vgic_cpu, vgic_v2.vgic_lr));
   DEFINE(VGIC_CPU_NR_LR,	offsetof(struct vgic_cpu, nr_lr));
 #ifdef CONFIG_KVM_ARM_TIMER
   DEFINE(VCPU_TIMER_CNTV_CTL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_ctl));

commit ac30a11e8e92a03dbe236b285c5cbae0bf563141
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Jan 22 09:43:38 2014 +0000

    ARM: KVM: introduce per-vcpu HYP Configuration Register
    
    So far, KVM/ARM used a fixed HCR configuration per guest, except for
    the VI/VF/VA bits to control the interrupt in absence of VGIC.
    
    With the upcoming need to dynamically reconfigure trapping, it becomes
    necessary to allow the HCR to be changed on a per-vcpu basis.
    
    The fix here is to mimic what KVM/arm64 already does: a per vcpu HCR
    field, initialized at setup time.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index ded041711beb..85598b5d1efd 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -174,6 +174,7 @@ int main(void)
   DEFINE(VCPU_FIQ_REGS,		offsetof(struct kvm_vcpu, arch.regs.fiq_regs));
   DEFINE(VCPU_PC,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_pc));
   DEFINE(VCPU_CPSR,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_cpsr));
+  DEFINE(VCPU_HCR,		offsetof(struct kvm_vcpu, arch.hcr));
   DEFINE(VCPU_IRQ_LINES,	offsetof(struct kvm_vcpu, arch.irq_lines));
   DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.fault.hsr));
   DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.fault.hxfar));

commit 7604537bbb5720376e8c9e6bc74a8e6305e3094d
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Thu May 16 10:34:30 2013 +0100

    ARM: kernel: implement stack pointer save array through MPIDR hashing
    
    Current implementation of cpu_{suspend}/cpu_{resume} relies on the MPIDR
    to index the array of pointers where the context is saved and restored.
    The current approach works as long as the MPIDR can be considered a
    linear index, so that the pointers array can simply be dereferenced by
    using the MPIDR[7:0] value.
    On ARM multi-cluster systems, where the MPIDR may not be a linear index,
    to properly dereference the stack pointer array, a mapping function should
    be applied to it so that it can be used for arrays look-ups.
    
    This patch adds code in the cpu_{suspend}/cpu_{resume} implementation
    that relies on shifting and ORing hashing method to map a MPIDR value to a
    set of buckets precomputed at boot to have a collision free mapping from
    MPIDR to context pointers.
    
    The hashing algorithm must be simple, fast, and implementable with few
    instructions since in the cpu_resume path the mapping is carried out with
    the MMU off and the I-cache off, hence code and data are fetched from DRAM
    with no-caching available. Simplicity is counterbalanced with a little
    increase of memory (allocated dynamically) for stack pointers buckets, that
    should be anyway fairly limited on most systems.
    
    Memory for context pointers is allocated in a early_initcall with
    size precomputed and stashed previously in kernel data structures.
    Memory for context pointers is allocated through kmalloc; this
    guarantees contiguous physical addresses for the allocated memory which
    is fundamental to the correct functioning of the resume mechanism that
    relies on the context pointer array to be a chunk of contiguous physical
    memory. Virtual to physical address conversion for the context pointer
    array base is carried out at boot to avoid fiddling with virt_to_phys
    conversions in the cpu_resume path which is quite fragile and should be
    optimized to execute as few instructions as possible.
    Virtual and physical context pointer base array addresses are stashed in a
    struct that is accessible from assembly using values generated through the
    asm-offsets.c mechanism.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Colin Cross <ccross@android.com>
    Cc: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Amit Kucheria <amit.kucheria@linaro.org>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Reviewed-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Tested-by: Kevin Hilman <khilman@linaro.org>
    Tested-by: Stephen Warren <swarren@wwwdotorg.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index ee68cce6b48e..ded041711beb 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -23,6 +23,7 @@
 #include <asm/thread_info.h>
 #include <asm/memory.h>
 #include <asm/procinfo.h>
+#include <asm/suspend.h>
 #include <asm/hardware/cache-l2x0.h>
 #include <linux/kbuild.h>
 
@@ -144,6 +145,11 @@ int main(void)
 #endif
 #ifdef MULTI_CACHE
   DEFINE(CACHE_FLUSH_KERN_ALL,	offsetof(struct cpu_cache_fns, flush_kern_all));
+#endif
+#ifdef CONFIG_ARM_CPU_SUSPEND
+  DEFINE(SLEEP_SAVE_SP_SZ,	sizeof(struct sleep_save_sp));
+  DEFINE(SLEEP_SAVE_SP_PHYS,	offsetof(struct sleep_save_sp, save_ptr_stash_phys));
+  DEFINE(SLEEP_SAVE_SP_VIRT,	offsetof(struct sleep_save_sp, save_ptr_stash));
 #endif
   BLANK();
   DEFINE(DMA_BIDIRECTIONAL,	DMA_BIDIRECTIONAL);

commit 01227a889ed56ae53aeebb9f93be9d54dd8b2de8
Merge: 9e6879460c8e db6ae6158186
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun May 5 14:47:31 2013 -0700

    Merge tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Gleb Natapov:
     "Highlights of the updates are:
    
      general:
       - new emulated device API
       - legacy device assignment is now optional
       - irqfd interface is more generic and can be shared between arches
    
      x86:
       - VMCS shadow support and other nested VMX improvements
       - APIC virtualization and Posted Interrupt hardware support
       - Optimize mmio spte zapping
    
      ppc:
        - BookE: in-kernel MPIC emulation with irqfd support
        - Book3S: in-kernel XICS emulation (incomplete)
        - Book3S: HV: migration fixes
        - BookE: more debug support preparation
        - BookE: e6500 support
    
      ARM:
       - reworking of Hyp idmaps
    
      s390:
       - ioeventfd for virtio-ccw
    
      And many other bug fixes, cleanups and improvements"
    
    * tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (204 commits)
      kvm: Add compat_ioctl for device control API
      KVM: x86: Account for failing enable_irq_window for NMI window request
      KVM: PPC: Book3S: Add API for in-kernel XICS emulation
      kvm/ppc/mpic: fix missing unlock in set_base_addr()
      kvm/ppc: Hold srcu lock when calling kvm_io_bus_read/write
      kvm/ppc/mpic: remove users
      kvm/ppc/mpic: fix mmio region lists when multiple guests used
      kvm/ppc/mpic: remove default routes from documentation
      kvm: KVM_CAP_IOMMU only available with device assignment
      ARM: KVM: iterate over all CPUs for CPU compatibility check
      KVM: ARM: Fix spelling in error message
      ARM: KVM: define KVM_ARM_MAX_VCPUS unconditionally
      KVM: ARM: Fix API documentation for ONE_REG encoding
      ARM: KVM: promote vfp_host pointer to generic host cpu context
      ARM: KVM: add architecture specific hook for capabilities
      ARM: KVM: perform HYP initilization for hotplugged CPUs
      ARM: KVM: switch to a dual-step HYP init code
      ARM: KVM: rework HYP page table freeing
      ARM: KVM: enforce maximum size for identity mapped code
      ARM: KVM: move to a KVM provided HYP idmap
      ...

commit 3de50da6901521f9e520b8eb47d092779512e83c
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Apr 8 16:47:19 2013 +0100

    ARM: KVM: promote vfp_host pointer to generic host cpu context
    
    We use the vfp_host pointer to store the host VFP context, should
    the guest start using VFP itself.
    
    Actually, we can use this pointer in a more generic way to store
    CPU speficic data, and arm64 is using it to dump the whole host
    state before switching to the guest.
    
    Simply rename the vfp_host field to host_cpu_context, and the
    corresponding type to kvm_cpu_context_t. No change in functionnality.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Christoffer Dall <cdall@cs.columbia.edu>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index ee1ac39a58f0..92562a2e9793 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -154,7 +154,7 @@ int main(void)
   DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));
   DEFINE(VCPU_CP15,		offsetof(struct kvm_vcpu, arch.cp15));
   DEFINE(VCPU_VFP_GUEST,	offsetof(struct kvm_vcpu, arch.vfp_guest));
-  DEFINE(VCPU_VFP_HOST,		offsetof(struct kvm_vcpu, arch.vfp_host));
+  DEFINE(VCPU_VFP_HOST,		offsetof(struct kvm_vcpu, arch.host_cpu_context));
   DEFINE(VCPU_REGS,		offsetof(struct kvm_vcpu, arch.regs));
   DEFINE(VCPU_USR_REGS,		offsetof(struct kvm_vcpu, arch.regs.usr_regs));
   DEFINE(VCPU_SVC_REGS,		offsetof(struct kvm_vcpu, arch.regs.svc_regs));

commit 2dfee7b2715b3ef3009979879d4387991f51b3a2
Merge: 660696d1d16a f42798c6898b
Author: Gleb Natapov <gleb@redhat.com>
Date:   Thu Apr 25 18:23:48 2013 +0300

    Merge branch 'kvm-arm-cleanup' from git://github.com/columbia/linux-kvm-arm.git

commit a126f7c41d80322b42ae0383ed3dcb17ee0296fc
Merge: 0098fc39e6d5 a7eb7c6f9a65
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Apr 25 09:42:42 2013 +0100

    Merge branch 'mcpm' of git://git.linaro.org/people/nico/linux into devel-stable

commit 1ae98561b16f305e43151405f226727c00ee52bc
Author: Dave Martin <dave.martin@linaro.org>
Date:   Fri Aug 17 16:07:02 2012 +0100

    ARM: mcpm_head.S: vlock-based first man election
    
    Instead of requiring the first man to be elected in advance (which
    can be suboptimal in some situations), this patch uses a per-
    cluster mutex to co-ordinate selection of the first man.
    
    This should also make it more feasible to reuse this code path for
    asynchronous cluster resume (as in CPUidle scenarios).
    
    We must ensure that the vlock data doesn't share a cacheline with
    anything else, or dirty cache eviction could corrupt it.
    
    Signed-off-by: Dave Martin <dave.martin@linaro.org>
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 1bed82a0a9e0..3f088225e71c 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -150,6 +150,7 @@ int main(void)
   DEFINE(DMA_TO_DEVICE,		DMA_TO_DEVICE);
   DEFINE(DMA_FROM_DEVICE,	DMA_FROM_DEVICE);
   BLANK();
+  DEFINE(CACHE_WRITEBACK_ORDER, __CACHE_WRITEBACK_ORDER);
   DEFINE(CACHE_WRITEBACK_GRANULE, __CACHE_WRITEBACK_GRANULE);
   BLANK();
 #ifdef CONFIG_KVM_ARM_HOST

commit 7fe31d28e839f9565c8176ec584676a045970802
Author: Dave Martin <dave.martin@linaro.org>
Date:   Tue Jul 17 14:25:42 2012 +0100

    ARM: mcpm: introduce helpers for platform coherency exit/setup
    
    This provides helper methods to coordinate between CPUs coming down
    and CPUs going up, as well as documentation on the used algorithms,
    so that cluster teardown and setup
    operations are not done for a cluster simultaneously.
    
    For use in the power_down() implementation:
      * __mcpm_cpu_going_down(unsigned int cluster, unsigned int cpu)
      * __mcpm_outbound_enter_critical(unsigned int cluster)
      * __mcpm_outbound_leave_critical(unsigned int cluster)
      * __mcpm_cpu_down(unsigned int cluster, unsigned int cpu)
    
    The power_up_setup() helper should do platform-specific setup in
    preparation for turning the CPU on, such as invalidating local caches
    or entering coherency.  It must be assembler for now, since it must
    run before the MMU can be switched on.  It is passed the affinity level
    for which initialization should be performed.
    
    Because the mcpm_sync_struct content is looked-up and modified
    with the cache enabled or disabled depending on the code path, it is
    crucial to always ensure proper cache maintenance to update main memory
    right away.  The sync_cache_*() helpers are used to that end.
    
    Also, in order to prevent a cached writer from interfering with an
    adjacent non-cached writer, we ensure each state variable is located to
    a separate cache line.
    
    Thanks to Nicolas Pitre and Achin Gupta for the help with this
    patch.
    
    Signed-off-by: Dave Martin <dave.martin@linaro.org>
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Reviewed-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 923eec7105cf..1bed82a0a9e0 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -149,6 +149,9 @@ int main(void)
   DEFINE(DMA_BIDIRECTIONAL,	DMA_BIDIRECTIONAL);
   DEFINE(DMA_TO_DEVICE,		DMA_TO_DEVICE);
   DEFINE(DMA_FROM_DEVICE,	DMA_FROM_DEVICE);
+  BLANK();
+  DEFINE(CACHE_WRITEBACK_GRANULE, __CACHE_WRITEBACK_GRANULE);
+  BLANK();
 #ifdef CONFIG_KVM_ARM_HOST
   DEFINE(VCPU_KVM,		offsetof(struct kvm_vcpu, kvm));
   DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));

commit 7393b599177d301d4c9ca2c7f69a6849aba793c7
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Sep 17 19:27:09 2012 +0100

    ARM: KVM: abstract fault register accesses
    
    Instead of directly accessing the fault registers, use proper accessors
    so the core code can be shared.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 5ce738b43508..3c09d8c7798b 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -165,10 +165,10 @@ int main(void)
   DEFINE(VCPU_PC,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_pc));
   DEFINE(VCPU_CPSR,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_cpsr));
   DEFINE(VCPU_IRQ_LINES,	offsetof(struct kvm_vcpu, arch.irq_lines));
-  DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.hsr));
-  DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.hxfar));
-  DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.hpfar));
-  DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.hyp_pc));
+  DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.fault.hsr));
+  DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.fault.hxfar));
+  DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.fault.hpfar));
+  DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.fault.hyp_pc));
 #ifdef CONFIG_KVM_ARM_VGIC
   DEFINE(VCPU_VGIC_CPU,		offsetof(struct kvm_vcpu, arch.vgic_cpu));
   DEFINE(VGIC_CPU_HCR,		offsetof(struct vgic_cpu, vgic_hcr));

commit 8a4e3a9ead7e37ce1505602b564c15da09ac039f
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Feb 28 17:47:36 2013 +0100

    ARM: 7659/1: mm: make mm->context.id an atomic64_t variable
    
    mm->context.id is updated under asid_lock when a new ASID is allocated
    to an mm_struct. However, it is also read without the lock when a task
    is being scheduled and checking whether or not the current ASID
    generation is up-to-date.
    
    If two threads of the same process are being scheduled in parallel and
    the bottom bits of the generation in their mm->context.id match the
    current generation (that is, the mm_struct has not been used for ~2^24
    rollovers) then the non-atomic, lockless access to mm->context.id may
    yield the incorrect ASID.
    
    This patch fixes this issue by making mm->context.id and atomic64_t,
    ensuring that the generation is always read consistently. For code that
    only requires access to the ASID bits (e.g. TLB flushing by mm), then
    the value is accessed directly, which GCC converts to an ldrb.
    
    Cc: <stable@vger.kernel.org> # 3.8
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 5ce738b43508..923eec7105cf 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -110,7 +110,7 @@ int main(void)
   BLANK();
 #endif
 #ifdef CONFIG_CPU_HAS_ASID
-  DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
+  DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id.counter));
   BLANK();
 #endif
   DEFINE(VMA_VM_MM,		offsetof(struct vm_area_struct, vm_mm));

commit c7e3ba64ba16eddfbfc66ec099860f40e808e124
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Jan 23 13:21:59 2013 -0500

    ARM: KVM: arch_timers: Add timer world switch
    
    Do the necessary save/restore dance for the timers in the world
    switch code. In the process, allow the guest to read the physical
    counter, which is useful for its own clock_event_device.
    
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Christoffer Dall <c.dall@virtualopensystems.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 17cea2e78d88..5ce738b43508 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -179,6 +179,12 @@ int main(void)
   DEFINE(VGIC_CPU_APR,		offsetof(struct vgic_cpu, vgic_apr));
   DEFINE(VGIC_CPU_LR,		offsetof(struct vgic_cpu, vgic_lr));
   DEFINE(VGIC_CPU_NR_LR,	offsetof(struct vgic_cpu, nr_lr));
+#ifdef CONFIG_KVM_ARM_TIMER
+  DEFINE(VCPU_TIMER_CNTV_CTL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_ctl));
+  DEFINE(VCPU_TIMER_CNTV_CVAL,	offsetof(struct kvm_vcpu, arch.timer_cpu.cntv_cval));
+  DEFINE(KVM_TIMER_CNTVOFF,	offsetof(struct kvm, arch.timer.cntvoff));
+  DEFINE(KVM_TIMER_ENABLED,	offsetof(struct kvm, arch.timer.enabled));
+#endif
   DEFINE(KVM_VGIC_VCTRL,	offsetof(struct kvm, arch.vgic.vctrl_base));
 #endif
   DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));

commit 348b2b0708f6cdd3d0db95f8d02aa4ad2b3e2fa9
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Jan 21 19:36:15 2013 -0500

    ARM: KVM: VGIC control interface world switch
    
    Enable the VGIC control interface to be save-restored on world switch.
    
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Christoffer Dall <c.dall@virtualopensystems.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index c8b3272dfed1..17cea2e78d88 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -169,6 +169,18 @@ int main(void)
   DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.hxfar));
   DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.hpfar));
   DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.hyp_pc));
+#ifdef CONFIG_KVM_ARM_VGIC
+  DEFINE(VCPU_VGIC_CPU,		offsetof(struct kvm_vcpu, arch.vgic_cpu));
+  DEFINE(VGIC_CPU_HCR,		offsetof(struct vgic_cpu, vgic_hcr));
+  DEFINE(VGIC_CPU_VMCR,		offsetof(struct vgic_cpu, vgic_vmcr));
+  DEFINE(VGIC_CPU_MISR,		offsetof(struct vgic_cpu, vgic_misr));
+  DEFINE(VGIC_CPU_EISR,		offsetof(struct vgic_cpu, vgic_eisr));
+  DEFINE(VGIC_CPU_ELRSR,	offsetof(struct vgic_cpu, vgic_elrsr));
+  DEFINE(VGIC_CPU_APR,		offsetof(struct vgic_cpu, vgic_apr));
+  DEFINE(VGIC_CPU_LR,		offsetof(struct vgic_cpu, vgic_lr));
+  DEFINE(VGIC_CPU_NR_LR,	offsetof(struct vgic_cpu, nr_lr));
+  DEFINE(KVM_VGIC_VCTRL,	offsetof(struct kvm, arch.vgic.vctrl_base));
+#endif
   DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));
 #endif
   return 0; 

commit f7ed45be3ba524e06a6d933f0517dc7ad2d06703
Author: Christoffer Dall <c.dall@virtualopensystems.com>
Date:   Sun Jan 20 18:47:42 2013 -0500

    KVM: ARM: World-switch implementation
    
    Provides complete world-switch implementation to switch to other guests
    running in non-secure modes. Includes Hyp exception handlers that
    capture necessary exception information and stores the information on
    the VCPU and KVM structures.
    
    The following Hyp-ABI is also documented in the code:
    
    Hyp-ABI: Calling HYP-mode functions from host (in SVC mode):
       Switching to Hyp mode is done through a simple HVC #0 instruction. The
       exception vector code will check that the HVC comes from VMID==0 and if
       so will push the necessary state (SPSR, lr_usr) on the Hyp stack.
       - r0 contains a pointer to a HYP function
       - r1, r2, and r3 contain arguments to the above function.
       - The HYP function will be called with its arguments in r0, r1 and r2.
       On HYP function return, we return directly to SVC.
    
    A call to a function executing in Hyp mode is performed like the following:
    
            <svc code>
            ldr     r0, =BSYM(my_hyp_fn)
            ldr     r1, =my_param
            hvc #0  ; Call my_hyp_fn(my_param) from HYP mode
            <svc code>
    
    Otherwise, the world-switch is pretty straight-forward. All state that
    can be modified by the guest is first backed up on the Hyp stack and the
    VCPU values is loaded onto the hardware. State, which is not loaded, but
    theoretically modifiable by the guest is protected through the
    virtualiation features to generate a trap and cause software emulation.
    Upon guest returns, all state is restored from hardware onto the VCPU
    struct and the original state is restored from the Hyp-stack onto the
    hardware.
    
    SMP support using the VMPIDR calculated on the basis of the host MPIDR
    and overriding the low bits with KVM vcpu_id contributed by Marc Zyngier.
    
    Reuse of VMIDs has been implemented by Antonios Motakis and adapated from
    a separate patch into the appropriate patches introducing the
    functionality. Note that the VMIDs are stored per VM as required by the ARM
    architecture reference manual.
    
    To support VFP/NEON we trap those instructions using the HPCTR. When
    we trap, we switch the FPU.  After a guest exit, the VFP state is
    returned to the host.  When disabling access to floating point
    instructions, we also mask FPEXC_EN in order to avoid the guest
    receiving Undefined instruction exceptions before we have a chance to
    switch back the floating point state.  We are reusing vfp_hard_struct,
    so we depend on VFPv3 being enabled in the host kernel, if not, we still
    trap cp10 and cp11 in order to inject an undefined instruction exception
    whenever the guest tries to use VFP/NEON. VFP/NEON developed by
    Antionios Motakis and Rusty Russell.
    
    Aborts that are permission faults, and not stage-1 page table walk, do
    not report the faulting address in the HPFAR.  We have to resolve the
    IPA, and store it just like the HPFAR register on the VCPU struct. If
    the IPA cannot be resolved, it means another CPU is playing with the
    page tables, and we simply restart the guest.  This quirk was fixed by
    Marc Zyngier.
    
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Antonios Motakis <a.motakis@virtualopensystems.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Christoffer Dall <c.dall@virtualopensystems.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index c985b481192c..c8b3272dfed1 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -13,6 +13,9 @@
 #include <linux/sched.h>
 #include <linux/mm.h>
 #include <linux/dma-mapping.h>
+#ifdef CONFIG_KVM_ARM_HOST
+#include <linux/kvm_host.h>
+#endif
 #include <asm/cacheflush.h>
 #include <asm/glue-df.h>
 #include <asm/glue-pf.h>
@@ -146,5 +149,27 @@ int main(void)
   DEFINE(DMA_BIDIRECTIONAL,	DMA_BIDIRECTIONAL);
   DEFINE(DMA_TO_DEVICE,		DMA_TO_DEVICE);
   DEFINE(DMA_FROM_DEVICE,	DMA_FROM_DEVICE);
+#ifdef CONFIG_KVM_ARM_HOST
+  DEFINE(VCPU_KVM,		offsetof(struct kvm_vcpu, kvm));
+  DEFINE(VCPU_MIDR,		offsetof(struct kvm_vcpu, arch.midr));
+  DEFINE(VCPU_CP15,		offsetof(struct kvm_vcpu, arch.cp15));
+  DEFINE(VCPU_VFP_GUEST,	offsetof(struct kvm_vcpu, arch.vfp_guest));
+  DEFINE(VCPU_VFP_HOST,		offsetof(struct kvm_vcpu, arch.vfp_host));
+  DEFINE(VCPU_REGS,		offsetof(struct kvm_vcpu, arch.regs));
+  DEFINE(VCPU_USR_REGS,		offsetof(struct kvm_vcpu, arch.regs.usr_regs));
+  DEFINE(VCPU_SVC_REGS,		offsetof(struct kvm_vcpu, arch.regs.svc_regs));
+  DEFINE(VCPU_ABT_REGS,		offsetof(struct kvm_vcpu, arch.regs.abt_regs));
+  DEFINE(VCPU_UND_REGS,		offsetof(struct kvm_vcpu, arch.regs.und_regs));
+  DEFINE(VCPU_IRQ_REGS,		offsetof(struct kvm_vcpu, arch.regs.irq_regs));
+  DEFINE(VCPU_FIQ_REGS,		offsetof(struct kvm_vcpu, arch.regs.fiq_regs));
+  DEFINE(VCPU_PC,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_pc));
+  DEFINE(VCPU_CPSR,		offsetof(struct kvm_vcpu, arch.regs.usr_regs.ARM_cpsr));
+  DEFINE(VCPU_IRQ_LINES,	offsetof(struct kvm_vcpu, arch.irq_lines));
+  DEFINE(VCPU_HSR,		offsetof(struct kvm_vcpu, arch.hsr));
+  DEFINE(VCPU_HxFAR,		offsetof(struct kvm_vcpu, arch.hxfar));
+  DEFINE(VCPU_HPFAR,		offsetof(struct kvm_vcpu, arch.hpfar));
+  DEFINE(VCPU_HYP_PC,		offsetof(struct kvm_vcpu, arch.hyp_pc));
+  DEFINE(KVM_VTTBR,		offsetof(struct kvm, arch.vttbr));
+#endif
   return 0; 
 }

commit 9fc31ddc70ac594b5a1d8a83303b65008221088c
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Aug 29 11:16:59 2012 +0100

    ARM: Don't unconditionally bloat thread_info
    
    There is no point reserving space at the bottom of the kernel stack for
    per-thread crunch state, and per-thread VFP state if these are not being
    supported by the kernel being built.  Remove these members from the
    thread union when these features are disabled.
    
    Reported-by: Tim Bird <tim.bird@am.sony.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 1429d8989fb9..c985b481192c 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -59,10 +59,12 @@ int main(void)
   DEFINE(TI_USED_CP,		offsetof(struct thread_info, used_cp));
   DEFINE(TI_TP_VALUE,		offsetof(struct thread_info, tp_value));
   DEFINE(TI_FPSTATE,		offsetof(struct thread_info, fpstate));
+#ifdef CONFIG_VFP
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
 #ifdef CONFIG_SMP
   DEFINE(VFP_CPU,		offsetof(union vfp_state, hard.cpu));
 #endif
+#endif
 #ifdef CONFIG_ARM_THUMBEE
   DEFINE(TI_THUMBEE_STATE,	offsetof(struct thread_info, thumbee_state));
 #endif

commit 91c2ebb90b1890abc648ba9dec5608cbc97e1cb9
Author: Barry Song <Baohua.Song@csr.com>
Date:   Fri Sep 30 14:43:12 2011 +0100

    ARM: 7114/1: cache-l2x0: add resume entry for l2 in secure mode
    
    we save the l2x0 registers at the first initialization, and platform codes
    can get them to restore l2x0 status after wakeup.
    
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Signed-off-by: Barry Song <Baohua.Song@csr.com>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 16baba2e4369..1429d8989fb9 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -20,6 +20,7 @@
 #include <asm/thread_info.h>
 #include <asm/memory.h>
 #include <asm/procinfo.h>
+#include <asm/hardware/cache-l2x0.h>
 #include <linux/kbuild.h>
 
 /*
@@ -92,6 +93,17 @@ int main(void)
   DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
   DEFINE(S_FRAME_SIZE,		sizeof(struct pt_regs));
   BLANK();
+#ifdef CONFIG_CACHE_L2X0
+  DEFINE(L2X0_R_PHY_BASE,	offsetof(struct l2x0_regs, phy_base));
+  DEFINE(L2X0_R_AUX_CTRL,	offsetof(struct l2x0_regs, aux_ctrl));
+  DEFINE(L2X0_R_TAG_LATENCY,	offsetof(struct l2x0_regs, tag_latency));
+  DEFINE(L2X0_R_DATA_LATENCY,	offsetof(struct l2x0_regs, data_latency));
+  DEFINE(L2X0_R_FILTER_START,	offsetof(struct l2x0_regs, filter_start));
+  DEFINE(L2X0_R_FILTER_END,	offsetof(struct l2x0_regs, filter_end));
+  DEFINE(L2X0_R_PREFETCH_CTRL,	offsetof(struct l2x0_regs, prefetch_ctrl));
+  DEFINE(L2X0_R_PWR_CTRL,	offsetof(struct l2x0_regs, pwr_ctrl));
+  BLANK();
+#endif
 #ifdef CONFIG_CPU_HAS_ASID
   DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
   BLANK();

commit f8f2a8522a88aacd62a310ce49e8dac530d1b403
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jul 9 16:09:43 2011 +0100

    ARM: vfp: fix a hole in VFP thread migration
    
    Fix a hole in the VFP thread migration.  Lets define two threads.
    
    Thread 1, we'll call 'interesting_thread' which is a thread which is
    running on CPU0, using VFP (so vfp_current_hw_state[0] =
    &interesting_thread->vfpstate) and gets migrated off to CPU1, where
    it continues execution of VFP instructions.
    
    Thread 2, we'll call 'new_cpu0_thread' which is the thread which takes
    over on CPU0.  This has also been using VFP, and last used VFP on CPU0,
    but doesn't use it again.
    
    The following code will be executed twice:
    
                    cpu = thread->cpu;
    
                    /*
                     * On SMP, if VFP is enabled, save the old state in
                     * case the thread migrates to a different CPU. The
                     * restoring is done lazily.
                     */
                    if ((fpexc & FPEXC_EN) && vfp_current_hw_state[cpu]) {
                            vfp_save_state(vfp_current_hw_state[cpu], fpexc);
                            vfp_current_hw_state[cpu]->hard.cpu = cpu;
                    }
                    /*
                     * Thread migration, just force the reloading of the
                     * state on the new CPU in case the VFP registers
                     * contain stale data.
                     */
                    if (thread->vfpstate.hard.cpu != cpu)
                            vfp_current_hw_state[cpu] = NULL;
    
    The first execution will be on CPU0 to switch away from 'interesting_thread'.
    interesting_thread->cpu will be 0.
    
    So, vfp_current_hw_state[0] points at interesting_thread->vfpstate.
    The hardware state will be saved, along with the CPU number (0) that
    it was executing on.
    
    'thread' will be 'new_cpu0_thread' with new_cpu0_thread->cpu = 0.
    Also, because it was executing on CPU0, new_cpu0_thread->vfpstate.hard.cpu = 0,
    and so the thread migration check is not triggered.
    
    This means that vfp_current_hw_state[0] remains pointing at interesting_thread.
    
    The second execution will be on CPU1 to switch _to_ 'interesting_thread'.
    So, 'thread' will be 'interesting_thread' and interesting_thread->cpu now
    will be 1.  The previous thread executing on CPU1 is not relevant to this
    so we shall ignore that.
    
    We get to the thread migration check.  Here, we discover that
    interesting_thread->vfpstate.hard.cpu = 0, yet interesting_thread->cpu is
    now 1, indicating thread migration.  We set vfp_current_hw_state[1] to
    NULL.
    
    So, at this point vfp_current_hw_state[] contains the following:
    
    [0] = &interesting_thread->vfpstate
    [1] = NULL
    
    Our interesting thread now executes a VFP instruction, takes a fault
    which loads the state into the VFP hardware.  Now, through the assembly
    we now have:
    
    [0] = &interesting_thread->vfpstate
    [1] = &interesting_thread->vfpstate
    
    CPU1 stops due to ptrace (and so saves its VFP state) using the thread
    switch code above), and CPU0 calls vfp_sync_hwstate().
    
            if (vfp_current_hw_state[cpu] == &thread->vfpstate) {
                    vfp_save_state(&thread->vfpstate, fpexc | FPEXC_EN);
    
    BANG, we corrupt interesting_thread's VFP state by overwriting the
    more up-to-date state saved by CPU1 with the old VFP state from CPU0.
    
    Fix this by ensuring that we have sane semantics for the various state
    describing variables:
    
    1. vfp_current_hw_state[] points to the current owner of the context
       information stored in each CPUs hardware, or NULL if that state
       information is invalid.
    2. thread->vfpstate.hard.cpu always contains the most recent CPU number
       which the state was loaded into or NR_CPUS if no CPU owns the state.
    
    So, for a particular CPU to be a valid owner of the VFP state for a
    particular thread t, two things must be true:
    
     vfp_current_hw_state[cpu] == &t->vfpstate && t->vfpstate.hard.cpu == cpu.
    
    and that is valid from the moment a CPU loads the saved VFP context
    into the hardware.  This gives clear and consistent semantics to
    interpreting these variables.
    
    This patch also fixes thread copying, ensuring that t->vfpstate.hard.cpu
    is invalidated, otherwise CPU0 may believe it was the last owner.  The
    hole can happen thus:
    
    - thread1 runs on CPU2 using VFP, migrates to CPU3, exits and thread_info
      freed.
    - New thread allocated from a previously running thread on CPU2, reusing
      memory for thread1 and copying vfp.hard.cpu.
    
    At this point, the following are true:
    
            new_thread1->vfpstate.hard.cpu == 2
            &new_thread1->vfpstate == vfp_current_hw_state[2]
    
    Lastly, this also addresses thread flushing in a similar way to thread
    copying.  Hole is:
    
    - thread runs on CPU0, using VFP, migrates to CPU1 but does not use VFP.
    - thread calls execve(), so thread flush happens, leaving
      vfp_current_hw_state[0] intact.  This vfpstate is memset to 0 causing
      thread->vfpstate.hard.cpu = 0.
    - thread migrates back to CPU0 before using VFP.
    
    At this point, the following are true:
    
            thread->vfpstate.hard.cpu == 0
            &thread->vfpstate == vfp_current_hw_state[0]
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 927522cfc12e..16baba2e4369 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -59,6 +59,9 @@ int main(void)
   DEFINE(TI_TP_VALUE,		offsetof(struct thread_info, tp_value));
   DEFINE(TI_FPSTATE,		offsetof(struct thread_info, fpstate));
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
+#ifdef CONFIG_SMP
+  DEFINE(VFP_CPU,		offsetof(union vfp_state, hard.cpu));
+#endif
 #ifdef CONFIG_ARM_THUMBEE
   DEFINE(TI_THUMBEE_STATE,	offsetof(struct thread_info, thumbee_state));
 #endif

commit f6b0fa02e8b0708d17d631afce456524eadf87ff
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Feb 6 15:48:39 2011 +0000

    ARM: pm: add generic CPU suspend/resume support
    
    This adds core support for saving and restoring CPU coprocessor
    registers for suspend/resume support.  This contains support for suspend
    with ARM920, ARM926, SA11x0, PXA25x, PXA27x, PXA3xx, V6 and V7 CPUs.
    Tested on Assabet and Tegra 2.
    
    Tested-by: Colin Cross <ccross@android.com>
    Tested-by: Kukjin Kim <kgene.kim@samsung.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 5302a917271b..927522cfc12e 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -13,6 +13,7 @@
 #include <linux/sched.h>
 #include <linux/mm.h>
 #include <linux/dma-mapping.h>
+#include <asm/cacheflush.h>
 #include <asm/glue-df.h>
 #include <asm/glue-pf.h>
 #include <asm/mach/arch.h>
@@ -115,6 +116,14 @@ int main(void)
 #endif
 #ifdef MULTI_PABORT
   DEFINE(PROCESSOR_PABT_FUNC,	offsetof(struct processor, _prefetch_abort));
+#endif
+#ifdef MULTI_CPU
+  DEFINE(CPU_SLEEP_SIZE,	offsetof(struct processor, suspend_size));
+  DEFINE(CPU_DO_SUSPEND,	offsetof(struct processor, do_suspend));
+  DEFINE(CPU_DO_RESUME,		offsetof(struct processor, do_resume));
+#endif
+#ifdef MULTI_CACHE
+  DEFINE(CACHE_FLUSH_KERN_ALL,	offsetof(struct cpu_cache_fns, flush_kern_all));
 #endif
   BLANK();
   DEFINE(DMA_BIDIRECTIONAL,	DMA_BIDIRECTIONAL);

commit 753790e713d80b50b867fa1ed32ec0eb5e82ae8e
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Feb 6 15:32:24 2011 +0000

    ARM: move cache/processor/fault glue to separate include files
    
    This allows the cache/processor/fault glue to be more easily used
    from assembler code.  Tested on Assabet and Tegra 2.
    
    Tested-by: Colin Cross <ccross@android.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 82da66172132..5302a917271b 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -13,6 +13,8 @@
 #include <linux/sched.h>
 #include <linux/mm.h>
 #include <linux/dma-mapping.h>
+#include <asm/glue-df.h>
+#include <asm/glue-pf.h>
 #include <asm/mach/arch.h>
 #include <asm/thread_info.h>
 #include <asm/memory.h>

commit 6451d7783ba5ff24eb1a544eaa6665b890f30466
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Thu Oct 14 22:21:46 2010 -0400

    arm: remove machine_desc.io_pg_offst and .phys_io
    
    Since we're now using addruart to establish the debug mapping, we can
    remove the io_pg_offst and phys_io members of struct machine_desc.
    
    The various declarations were removed using the following script:
    
      grep -rl MACHINE_START arch/arm | xargs \
      sed -i '/MACHINE_START/,/MACHINE_END/ { /\.\(phys_io\|io_pg_offst\)/d }'
    
    [ Initial patch was from Jeremy Kerr, example script from Russell King ]
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Acked-by: Eric Miao <eric.miao at canonical.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 85f2a019f77b..82da66172132 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -102,8 +102,6 @@ int main(void)
   DEFINE(SIZEOF_MACHINE_DESC,	sizeof(struct machine_desc));
   DEFINE(MACHINFO_TYPE,		offsetof(struct machine_desc, nr));
   DEFINE(MACHINFO_NAME,		offsetof(struct machine_desc, name));
-  DEFINE(MACHINFO_PHYSIO,	offsetof(struct machine_desc, phys_io));
-  DEFINE(MACHINFO_PGOFFIO,	offsetof(struct machine_desc, io_pg_offst));
   BLANK();
   DEFINE(PROC_INFO_SZ,		sizeof(struct proc_info_list));
   DEFINE(PROCINFO_INITFUNC,	offsetof(struct proc_info_list, __cpu_flush));

commit df0698be14c6683606d5df2d83e3ae40f85ed0d9
Author: Nicolas Pitre <nico@fluxnic.net>
Date:   Mon Jun 7 21:50:33 2010 -0400

    ARM: stack protector: change the canary value per task
    
    A new random value for the canary is stored in the task struct whenever
    a new task is forked.  This is meant to allow for different canary values
    per task.  On ARM, GCC expects the canary value to be found in a global
    variable called __stack_chk_guard.  So this variable has to be updated
    with the value stored in the task struct whenever a task switch occurs.
    
    Because the variable GCC expects is global, this cannot work on SMP
    unfortunately.  So, on SMP, the same initial canary value is kept
    throughout, making this feature a bit less effective although it is still
    useful.
    
    One way to overcome this GCC limitation would be to locate the
    __stack_chk_guard variable into a memory page of its own for each CPU,
    and then use TLB locking to have each CPU see its own page at the same
    virtual address for each of them.
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 883511522fca..85f2a019f77b 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -40,6 +40,9 @@
 int main(void)
 {
   DEFINE(TSK_ACTIVE_MM,		offsetof(struct task_struct, active_mm));
+#ifdef CONFIG_CC_STACKPROTECTOR
+  DEFINE(TSK_STACK_CANARY,	offsetof(struct task_struct, stack_canary));
+#endif
   BLANK();
   DEFINE(TI_FLAGS,		offsetof(struct thread_info, flags));
   DEFINE(TI_PREEMPT,		offsetof(struct thread_info, preempt_count));

commit a9c9147eb9b1dba0ce567a41897c7773b4d1b0bc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Nov 26 16:19:58 2009 +0000

    ARM: dma-mapping: provide per-cpu type map/unmap functions
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Tested-By: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 4a881258bb17..883511522fca 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -12,6 +12,7 @@
  */
 #include <linux/sched.h>
 #include <linux/mm.h>
+#include <linux/dma-mapping.h>
 #include <asm/mach/arch.h>
 #include <asm/thread_info.h>
 #include <asm/memory.h>
@@ -112,5 +113,9 @@ int main(void)
 #ifdef MULTI_PABORT
   DEFINE(PROCESSOR_PABT_FUNC,	offsetof(struct processor, _prefetch_abort));
 #endif
+  BLANK();
+  DEFINE(DMA_BIDIRECTIONAL,	DMA_BIDIRECTIONAL);
+  DEFINE(DMA_TO_DEVICE,		DMA_TO_DEVICE);
+  DEFINE(DMA_FROM_DEVICE,	DMA_FROM_DEVICE);
   return 0; 
 }

commit 02cbe4749a79f880b29ce42bbb5441b8d57222e4
Author: Christoph Lameter <clameter@sgi.com>
Date:   Tue Apr 29 01:03:59 2008 -0700

    arm: use kbuild.h instead of macros in asm-offsets.c
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 0a0d2479274b..4a881258bb17 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -16,6 +16,7 @@
 #include <asm/thread_info.h>
 #include <asm/memory.h>
 #include <asm/procinfo.h>
+#include <linux/kbuild.h>
 
 /*
  * Make sure that the compiler and target are compatible.
@@ -35,13 +36,6 @@
 #error    Known good compilers: 3.3
 #endif
 
-/* Use marker if you need to separate the values later */
-
-#define DEFINE(sym, val) \
-        asm volatile("\n->" #sym " %0 " #val : : "i" (val))
-
-#define BLANK() asm volatile("\n->" : : )
-
 int main(void)
 {
   DEFINE(TSK_ACTIVE_MM,		offsetof(struct task_struct, active_mm));

commit 48d7927bdf071d05cf5d15b816cf06b0937cb84f
Author: Paul Brook <paul@codesourcery.com>
Date:   Fri Apr 18 22:43:07 2008 +0100

    Add a prefetch abort handler
    
    This patch adds a prefetch abort handler similar to the data abort one
    and renames the latter for consistency. Initial implementation by Paul
    Brook with some renaming by Catalin Marinas.
    
    Signed-off-by: Paul Brook <paul@codesourcery.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 6604b474cfd7..0a0d2479274b 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -111,5 +111,12 @@ int main(void)
   DEFINE(PROCINFO_INITFUNC,	offsetof(struct proc_info_list, __cpu_flush));
   DEFINE(PROCINFO_MM_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_mm_mmu_flags));
   DEFINE(PROCINFO_IO_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_io_mmu_flags));
+  BLANK();
+#ifdef MULTI_DABORT
+  DEFINE(PROCESSOR_DABT_FUNC,	offsetof(struct processor, _data_abort));
+#endif
+#ifdef MULTI_PABORT
+  DEFINE(PROCESSOR_PABT_FUNC,	offsetof(struct processor, _prefetch_abort));
+#endif
   return 0; 
 }

commit d7f864be8323e5394040e2877594645b0e7da85d
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Apr 18 22:43:06 2008 +0100

    ARMv7: Add support for the ThumbEE state saving/restoring
    
    This patch adds the detection and handling of the ThumbEE extension on
    ARMv7 CPUs.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 3278e713c32a..6604b474cfd7 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -58,6 +58,9 @@ int main(void)
   DEFINE(TI_TP_VALUE,		offsetof(struct thread_info, tp_value));
   DEFINE(TI_FPSTATE,		offsetof(struct thread_info, fpstate));
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
+#ifdef CONFIG_ARM_THUMBEE
+  DEFINE(TI_THUMBEE_STATE,	offsetof(struct thread_info, thumbee_state));
+#endif
 #ifdef CONFIG_IWMMXT
   DEFINE(TI_IWMMXT_STATE,	offsetof(struct thread_info, fpstate.iwmmxt));
 #endif

commit 516793c61b3db1f60e0b0d0e3c382bcca9ae84fd
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu May 17 10:19:23 2007 +0100

    [ARM] ARMv6: add CPU_HAS_ASID configuration
    
    Presently, we check for the minimum ARM architecture that we're
    building for to determine whether we need ASID support.  This is
    wrong - if we're going to support a range of CPUs which include
    ARMv6 or higher, we need the ASID.
    
    Convert the checks to use a new configuration symbol, and arrange
    for ARMv6 and higher CPU entries to select it.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 3c078e346753..3278e713c32a 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -85,7 +85,7 @@ int main(void)
   DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
   DEFINE(S_FRAME_SIZE,		sizeof(struct pt_regs));
   BLANK();
-#if __LINUX_ARM_ARCH__ >= 6
+#ifdef CONFIG_CPU_HAS_ASID
   DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
   BLANK();
 #endif

commit ee90dabcadd053d5dd69f3a7f8161afa2c751ace
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Nov 9 14:20:47 2006 +0000

    [ARM] Include asm/elf.h instead of asm/procinfo.h
    
    These files want to provide/access ELF hwcap information, so should
    be including asm/elf.h rather than asm/procinfo.h
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index cc2d58d028e1..3c078e346753 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -15,6 +15,7 @@
 #include <asm/mach/arch.h>
 #include <asm/thread_info.h>
 #include <asm/memory.h>
+#include <asm/procinfo.h>
 
 /*
  * Make sure that the compiler and target are compatible.

commit 8799ee9f49f6171fd58f4d64f8c067ca49006a5d
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Jun 29 18:24:21 2006 +0100

    [ARM] Set bit 4 on section mappings correctly depending on CPU
    
    On some CPUs, bit 4 of section mappings means "update the
    cache when written to".  On others, this bit is required to
    be one, and others it's required to be zero.  Finally, on
    ARMv6 and above, setting it turns on "no execute" and prevents
    speculative prefetches.
    
    With all these combinations, no one value fits all CPUs, so we
    have to pick a value depending on the CPU type, and the area
    we're mapping.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 447ede5143a8..cc2d58d028e1 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -105,6 +105,7 @@ int main(void)
   BLANK();
   DEFINE(PROC_INFO_SZ,		sizeof(struct proc_info_list));
   DEFINE(PROCINFO_INITFUNC,	offsetof(struct proc_info_list, __cpu_flush));
-  DEFINE(PROCINFO_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_mmu_flags));
+  DEFINE(PROCINFO_MM_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_mm_mmu_flags));
+  DEFINE(PROCINFO_IO_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_io_mmu_flags));
   return 0; 
 }

commit c17fad11f3105ca4d5bbb2686725aad208f5ead4
Author: Lennert Buytenhek <buytenh@wantstofly.org>
Date:   Tue Jun 27 23:03:03 2006 +0100

    [ARM] 3370/2: ep93xx: add crunch support
    
    Patch from Lennert Buytenhek
    
    Add the necessary kernel bits for crunch task switching.
    
    Signed-off-by: Lennert Buytenhek <buytenh@wantstofly.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 396efba9bacd..447ede5143a8 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -59,6 +59,9 @@ int main(void)
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
 #ifdef CONFIG_IWMMXT
   DEFINE(TI_IWMMXT_STATE,	offsetof(struct thread_info, fpstate.iwmmxt));
+#endif
+#ifdef CONFIG_CRUNCH
+  DEFINE(TI_CRUNCH_STATE,	offsetof(struct thread_info, crunchstate));
 #endif
   BLANK();
   DEFINE(S_R0,			offsetof(struct pt_regs, ARM_r0));

commit 2ceec0c8c6e2780d58dece91b4b787729405d9e7
Author: Uwe Zeisberger <Uwe_Zeisberger@digi.com>
Date:   Wed May 10 18:11:05 2006 +0100

    [ARM] 3517/1: move definition of PROC_INFO_SZ from procinfo.h to asm-offsets.h
    
    Patch from Uwe Zeisberger
    
    The symbol is only used in arch/arm/kernel/head-common.S.  This in turn
    is included from arch/arm/kernel/head.S and arch/arm/kernel/head-nommu.S
    which include asm-offsets.h .
    
    Signed-off-by: Uwe Zeisberger <Uwe_Zeisberger@digi.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 45fdf4a51a2a..396efba9bacd 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -99,6 +99,8 @@ int main(void)
   DEFINE(MACHINFO_NAME,		offsetof(struct machine_desc, name));
   DEFINE(MACHINFO_PHYSIO,	offsetof(struct machine_desc, phys_io));
   DEFINE(MACHINFO_PGOFFIO,	offsetof(struct machine_desc, io_pg_offst));
+  BLANK();
+  DEFINE(PROC_INFO_SZ,		sizeof(struct proc_info_list));
   DEFINE(PROCINFO_INITFUNC,	offsetof(struct proc_info_list, __cpu_flush));
   DEFINE(PROCINFO_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_mmu_flags));
   return 0; 

commit 2eb9d3157107497fdccb51e1570fea677f6e3c82
Author: Uwe Zeisberger <Uwe_Zeisberger@digi.com>
Date:   Fri May 5 15:11:14 2006 +0100

    [ARM] 3496/1: more constants for asm-offsets.h
    
    Patch from Uwe Zeisberger
    
    added the following constants:
    - MACHINFO_TYPE
    - MACHINFO_NAME
    - MACHINFO_PHYSIO
    - MACHINFO_PGOFFIO
    - PROCINFO_INITFUNC
    - PROCINFO_MMUFLAGS
    
    and removed their definition from head.S and head-nommu.S
    
    Signed-off-by: Uwe Zeisberger <Uwe_Zeisberger@digi.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index b324dcac1c56..45fdf4a51a2a 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -95,5 +95,11 @@ int main(void)
   DEFINE(SYS_ERROR0,		0x9f0000);
   BLANK();
   DEFINE(SIZEOF_MACHINE_DESC,	sizeof(struct machine_desc));
+  DEFINE(MACHINFO_TYPE,		offsetof(struct machine_desc, nr));
+  DEFINE(MACHINFO_NAME,		offsetof(struct machine_desc, name));
+  DEFINE(MACHINFO_PHYSIO,	offsetof(struct machine_desc, phys_io));
+  DEFINE(MACHINFO_PGOFFIO,	offsetof(struct machine_desc, io_pg_offst));
+  DEFINE(PROCINFO_INITFUNC,	offsetof(struct proc_info_list, __cpu_flush));
+  DEFINE(PROCINFO_MMUFLAGS,	offsetof(struct proc_info_list, __cpu_mmu_flags));
   return 0; 
 }

commit cdaabbd74b15296acf09215355a7f3b07b92b83e
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun Mar 12 22:36:06 2006 +0000

    [ARM] iwmmxt thread state alignment
    
    This patch removes the reliance of iwmmxt on hand coded alignments.
    Since thread_info is always 8K aligned, specifying that fpstate is
    8-byte aligned achieves the same effect without needing to resort
    to hand coded alignments.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 0abbce8c70bc..b324dcac1c56 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -57,7 +57,9 @@ int main(void)
   DEFINE(TI_TP_VALUE,		offsetof(struct thread_info, tp_value));
   DEFINE(TI_FPSTATE,		offsetof(struct thread_info, fpstate));
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
-  DEFINE(TI_IWMMXT_STATE,	(offsetof(struct thread_info, fpstate)+4)&~7);
+#ifdef CONFIG_IWMMXT
+  DEFINE(TI_IWMMXT_STATE,	offsetof(struct thread_info, fpstate.iwmmxt));
+#endif
   BLANK();
   DEFINE(S_R0,			offsetof(struct pt_regs, ARM_r0));
   DEFINE(S_R1,			offsetof(struct pt_regs, ARM_r1));

commit a1365647022eb05a5993f270a78e9bef3bf554eb
Author: Andrew Morton <akpm@osdl.org>
Date:   Sun Jan 8 01:04:09 2006 -0800

    [PATCH] remove gcc-2 checks
    
    Remove various things which were checking for gcc-1.x and gcc-2.x compilers.
    
    From: Adrian Bunk <bunk@stusta.de>
    
        Some documentation updates and removes some code paths for gcc < 3.2.
    
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 04d3082a7b94..0abbce8c70bc 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -23,20 +23,15 @@
 #error Sorry, your compiler targets APCS-26 but this kernel requires APCS-32
 #endif
 /*
- * GCC 2.95.1, 2.95.2: ignores register clobber list in asm().
  * GCC 3.0, 3.1: general bad code generation.
  * GCC 3.2.0: incorrect function argument offset calculation.
  * GCC 3.2.x: miscompiles NEW_AUX_ENT in fs/binfmt_elf.c
  *            (http://gcc.gnu.org/PR8896) and incorrect structure
  *	      initialisation in fs/jffs2/erase.c
  */
-#if __GNUC__ < 2 || \
-   (__GNUC__ == 2 && __GNUC_MINOR__ < 95) || \
-   (__GNUC__ == 2 && __GNUC_MINOR__ == 95 && __GNUC_PATCHLEVEL__ != 0 && \
-					     __GNUC_PATCHLEVEL__ < 3) || \
-   (__GNUC__ == 3 && __GNUC_MINOR__ < 3)
+#if (__GNUC__ == 3 && __GNUC_MINOR__ < 3)
 #error Your compiler is too buggy; it is known to miscompile kernels.
-#error    Known good compilers: 2.95.3, 2.95.4, 2.96, 3.3
+#error    Known good compilers: 3.3
 #endif
 
 /* Use marker if you need to separate the values later */

commit f09b99799991c7c3ba441162406247f5df077322
Author: Nicolas Pitre <nico@cam.org>
Date:   Sat Oct 29 21:44:55 2005 +0100

    [ARM] 3060/1: allow constants found in asm/memory.h to be used in asm code
    
    Patch from Nicolas Pitre
    
    This patch allows for assorted type of cleanups by letting assembly code
    use the same set of defines for constant values and avoid duplicated
    definitions that might not always be in sync, or that might simply be
    confusing due to the different names for the same thing.
    
    Signed-off-by: Nicolas Pitre <nico@cam.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index c1ff4d1f1bfd..04d3082a7b94 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -94,7 +94,6 @@ int main(void)
   DEFINE(VM_EXEC,	       	VM_EXEC);
   BLANK();
   DEFINE(PAGE_SZ,	       	PAGE_SIZE);
-  DEFINE(VIRT_OFFSET,		PAGE_OFFSET);
   BLANK();
   DEFINE(SYS_ERROR0,		0x9f0000);
   BLANK();

commit 925c8a1a8cb9d7a33a8e39516d7fb679030553fc
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Apr 26 15:18:59 2005 +0100

    [PATCH] ARM: pt_regs offsets
    
    Generate pt_regs S_xx offsets from the structure itself instead
    of #defining them.
    
    Signed-off-by: Russell King <rmk@arm.linux.org.uk>

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
index 99d43259ff89..c1ff4d1f1bfd 100644
--- a/arch/arm/kernel/asm-offsets.c
+++ b/arch/arm/kernel/asm-offsets.c
@@ -64,6 +64,26 @@ int main(void)
   DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
   DEFINE(TI_IWMMXT_STATE,	(offsetof(struct thread_info, fpstate)+4)&~7);
   BLANK();
+  DEFINE(S_R0,			offsetof(struct pt_regs, ARM_r0));
+  DEFINE(S_R1,			offsetof(struct pt_regs, ARM_r1));
+  DEFINE(S_R2,			offsetof(struct pt_regs, ARM_r2));
+  DEFINE(S_R3,			offsetof(struct pt_regs, ARM_r3));
+  DEFINE(S_R4,			offsetof(struct pt_regs, ARM_r4));
+  DEFINE(S_R5,			offsetof(struct pt_regs, ARM_r5));
+  DEFINE(S_R6,			offsetof(struct pt_regs, ARM_r6));
+  DEFINE(S_R7,			offsetof(struct pt_regs, ARM_r7));
+  DEFINE(S_R8,			offsetof(struct pt_regs, ARM_r8));
+  DEFINE(S_R9,			offsetof(struct pt_regs, ARM_r9));
+  DEFINE(S_R10,			offsetof(struct pt_regs, ARM_r10));
+  DEFINE(S_FP,			offsetof(struct pt_regs, ARM_fp));
+  DEFINE(S_IP,			offsetof(struct pt_regs, ARM_ip));
+  DEFINE(S_SP,			offsetof(struct pt_regs, ARM_sp));
+  DEFINE(S_LR,			offsetof(struct pt_regs, ARM_lr));
+  DEFINE(S_PC,			offsetof(struct pt_regs, ARM_pc));
+  DEFINE(S_PSR,			offsetof(struct pt_regs, ARM_cpsr));
+  DEFINE(S_OLD_R0,		offsetof(struct pt_regs, ARM_ORIG_r0));
+  DEFINE(S_FRAME_SIZE,		sizeof(struct pt_regs));
+  BLANK();
 #if __LINUX_ARM_ARCH__ >= 6
   DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
   BLANK();

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/arm/kernel/asm-offsets.c b/arch/arm/kernel/asm-offsets.c
new file mode 100644
index 000000000000..99d43259ff89
--- /dev/null
+++ b/arch/arm/kernel/asm-offsets.c
@@ -0,0 +1,83 @@
+/*
+ * Copyright (C) 1995-2003 Russell King
+ *               2001-2002 Keith Owens
+ *     
+ * Generate definitions needed by assembly language modules.
+ * This code generates raw asm output which is post-processed to extract
+ * and format the required data.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <asm/mach/arch.h>
+#include <asm/thread_info.h>
+#include <asm/memory.h>
+
+/*
+ * Make sure that the compiler and target are compatible.
+ */
+#if defined(__APCS_26__)
+#error Sorry, your compiler targets APCS-26 but this kernel requires APCS-32
+#endif
+/*
+ * GCC 2.95.1, 2.95.2: ignores register clobber list in asm().
+ * GCC 3.0, 3.1: general bad code generation.
+ * GCC 3.2.0: incorrect function argument offset calculation.
+ * GCC 3.2.x: miscompiles NEW_AUX_ENT in fs/binfmt_elf.c
+ *            (http://gcc.gnu.org/PR8896) and incorrect structure
+ *	      initialisation in fs/jffs2/erase.c
+ */
+#if __GNUC__ < 2 || \
+   (__GNUC__ == 2 && __GNUC_MINOR__ < 95) || \
+   (__GNUC__ == 2 && __GNUC_MINOR__ == 95 && __GNUC_PATCHLEVEL__ != 0 && \
+					     __GNUC_PATCHLEVEL__ < 3) || \
+   (__GNUC__ == 3 && __GNUC_MINOR__ < 3)
+#error Your compiler is too buggy; it is known to miscompile kernels.
+#error    Known good compilers: 2.95.3, 2.95.4, 2.96, 3.3
+#endif
+
+/* Use marker if you need to separate the values later */
+
+#define DEFINE(sym, val) \
+        asm volatile("\n->" #sym " %0 " #val : : "i" (val))
+
+#define BLANK() asm volatile("\n->" : : )
+
+int main(void)
+{
+  DEFINE(TSK_ACTIVE_MM,		offsetof(struct task_struct, active_mm));
+  BLANK();
+  DEFINE(TI_FLAGS,		offsetof(struct thread_info, flags));
+  DEFINE(TI_PREEMPT,		offsetof(struct thread_info, preempt_count));
+  DEFINE(TI_ADDR_LIMIT,		offsetof(struct thread_info, addr_limit));
+  DEFINE(TI_TASK,		offsetof(struct thread_info, task));
+  DEFINE(TI_EXEC_DOMAIN,	offsetof(struct thread_info, exec_domain));
+  DEFINE(TI_CPU,		offsetof(struct thread_info, cpu));
+  DEFINE(TI_CPU_DOMAIN,		offsetof(struct thread_info, cpu_domain));
+  DEFINE(TI_CPU_SAVE,		offsetof(struct thread_info, cpu_context));
+  DEFINE(TI_USED_CP,		offsetof(struct thread_info, used_cp));
+  DEFINE(TI_TP_VALUE,		offsetof(struct thread_info, tp_value));
+  DEFINE(TI_FPSTATE,		offsetof(struct thread_info, fpstate));
+  DEFINE(TI_VFPSTATE,		offsetof(struct thread_info, vfpstate));
+  DEFINE(TI_IWMMXT_STATE,	(offsetof(struct thread_info, fpstate)+4)&~7);
+  BLANK();
+#if __LINUX_ARM_ARCH__ >= 6
+  DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
+  BLANK();
+#endif
+  DEFINE(VMA_VM_MM,		offsetof(struct vm_area_struct, vm_mm));
+  DEFINE(VMA_VM_FLAGS,		offsetof(struct vm_area_struct, vm_flags));
+  BLANK();
+  DEFINE(VM_EXEC,	       	VM_EXEC);
+  BLANK();
+  DEFINE(PAGE_SZ,	       	PAGE_SIZE);
+  DEFINE(VIRT_OFFSET,		PAGE_OFFSET);
+  BLANK();
+  DEFINE(SYS_ERROR0,		0x9f0000);
+  BLANK();
+  DEFINE(SIZEOF_MACHINE_DESC,	sizeof(struct machine_desc));
+  return 0; 
+}
