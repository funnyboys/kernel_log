commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 46e1be9e57a8..9a6432557871 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -37,7 +37,6 @@
 #include <asm/idmap.h>
 #include <asm/topology.h>
 #include <asm/mmu_context.h>
-#include <asm/pgtable.h>
 #include <asm/pgalloc.h>
 #include <asm/procinfo.h>
 #include <asm/processor.h>

commit ff98a5f624d2910de050f1fc7f2a32769da86b51
Author: Dietmar Eggemann <dietmar.eggemann@arm.com>
Date:   Fri Nov 29 16:23:02 2019 +0100

    ARM: 8943/1: Fix topology setup in case of CPU hotplug for CONFIG_SCHED_MC
    
    Commit ca74b316df96 ("arm: Use common cpu_topology structure and
    functions.") changed cpu_coregroup_mask() from the ARM32 specific
    implementation in arch/arm/include/asm/topology.h to the one shared
    with ARM64 and RISCV in drivers/base/arch_topology.c.
    
    Currently on ARM32 (TC2 w/ CONFIG_SCHED_MC) the task scheduler setup
    code (w/ CONFIG_SCHED_DEBUG) shows this during CPU hotplug:
    
      ERROR: groups don't span domain->span
    
    It happens to CPUs of the cluster of the CPU which gets hot-plugged
    out on scheduler domain MC.
    
    Turns out that the shared cpu_coregroup_mask() requires that the
    hot-plugged CPU is removed from the core_sibling mask via
    remove_cpu_topology(). Otherwise the 'is core_sibling subset of
    cpumask_of_node()' doesn't work. In this case the task scheduler has to
    deal with cpumask_of_node instead of core_sibling which is wrong on
    scheduler domain MC.
    
    e.g. CPU3 hot-plugged out on TC2 [cluster0: 0,3-4 cluster1: 1-2]:
    
      cpu_coregroup_mask(): CPU3 cpumask_of_node=0-2,4 core_sibling=0,3-4
                                                                      ^
    should be:
    
      cpu_coregroup_mask(): CPU3 cpumask_of_node=0-2,4 core_sibling=0,4
    
    Add remove_cpu_topology() to __cpu_disable() to remove the CPU from the
    topology masks in case of a CPU hotplug out operation.
    
    At the same time tweak store_cpu_topology() slightly so it will call
    update_siblings_masks() in case of CPU hotplug in operation via
    secondary_start_kernel()->smp_store_cpu_info().
    
    This aligns the ARM32 implementation with the ARM64 one.
    
    Guarding remove_cpu_topology() with CONFIG_GENERIC_ARCH_TOPOLOGY is
    necessary since some Arm32 defconfigs (aspeed_g5_defconfig,
    milbeaut_m10v_defconfig, spear13xx_defconfig) specify an explicit
    
     # CONFIG_ARM_CPU_TOPOLOGY is not set
    
    w/ ./arch/arm/Kconfig: select GENERIC_ARCH_TOPOLOGY if ARM_CPU_TOPOLOGY
    
    Fixes: ca74b316df96 ("arm: Use common cpu_topology structure and functions")
    Reviewed-by: Sudeep Holla <sudeep.holla@arm.com>
    Reviewed-by: Lukasz Luba <lukasz.luba@arm.com>
    Tested-by: Lukasz Luba <lukasz.luba@arm.com>
    Tested-by: Ondrej Jirman <megous@megous.com>
    Signed-off-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 4b0bab2607e4..46e1be9e57a8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -240,6 +240,10 @@ int __cpu_disable(void)
 	if (ret)
 		return ret;
 
+#ifdef CONFIG_GENERIC_ARCH_TOPOLOGY
+	remove_cpu_topology(cpu);
+#endif
+
 	/*
 	 * Take this CPU offline.  Once we clear this, we can't return,
 	 * and we must not schedule until we're ready to give up the cpu.

commit 1d5087ab964d84e5a0cfe5059cf5e929127d573f
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 12 14:50:06 2015 -0700

    arm: Use common outgoing-CPU-notification code
    
    This commit removes the open-coded CPU-offline notification with new
    common code.  In particular, this change avoids calling scheduler code
    using RCU from an offline CPU that RCU is ignoring.  This is a minimal
    change.  A more intrusive change might invoke the cpu_check_up_prepare()
    and cpu_set_state_online() functions at CPU-online time, which would
    allow onlining throw an error if the CPU did not go offline properly.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Dietmar Eggemann <dietmar.eggemann@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index aab8ba40ce38..4b0bab2607e4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -264,15 +264,13 @@ int __cpu_disable(void)
 	return 0;
 }
 
-static DECLARE_COMPLETION(cpu_died);
-
 /*
  * called on the thread which is asking for a CPU to be shutdown -
  * waits until shutdown has completed, or it is timed out.
  */
 void __cpu_die(unsigned int cpu)
 {
-	if (!wait_for_completion_timeout(&cpu_died, msecs_to_jiffies(5000))) {
+	if (!cpu_wait_death(cpu, 5)) {
 		pr_err("CPU%u: cpu didn't die\n", cpu);
 		return;
 	}
@@ -319,7 +317,7 @@ void arch_cpu_idle_dead(void)
 	 * this returns, power and/or clocks can be removed at any point
 	 * from this CPU and its cache by platform_cpu_kill().
 	 */
-	complete(&cpu_died);
+	(void)cpu_report_death();
 
 	/*
 	 * Ensure that the cache lines associated with that completion are

commit 2b49350b16fa3171136d7cf351ac7e9e6673b8f2
Merge: 4d2fa8b44b89 5ccd3bd992cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:08:34 2019 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - Add a "cut here" to make it clearer where oops dumps should be cut
       from - we already have a marker for the end of the dumps.
    
     - Add logging severity to show_pte()
    
     - Drop unnecessary common-page-size linker flag
    
     - Errata workarounds for Cortex A12 857271, Cortex A17 857272 and
       Cortex A7 814220.
    
     - Remove some unused variables that had started to provoke a compiler
       warning.
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm:
      ARM: 8863/1: stm32: select ARM errata 814220
      ARM: 8862/1: errata: 814220-B-Cache maintenance by set/way operations can execute out of order
      ARM: 8865/1: mm: remove unused variables
      ARM: 8864/1: Add workaround for I-Cache line size mismatch between CPU cores
      ARM: 8861/1: errata: Workaround errata A12 857271 / A17 857272
      ARM: 8860/1: VDSO: Drop implicit common-page-size linker flag
      ARM: arrange show_pte() to issue severity-based messages
      ARM: add "8<--- cut here ---" to kernel dumps

commit 5f41f9198f296091c6a58bc2e86af1e9f019b2a3
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Tue May 28 09:38:14 2019 +0100

    ARM: 8864/1: Add workaround for I-Cache line size mismatch between CPU cores
    
    Some big.LITTLE systems have I-Cache line size mismatch between
    LITTLE and big cores. This patch adds a workaround for proper I-Cache
    support on such systems. Without it, some class of the userspace code
    (typically self-modifying) might suffer from random SIGILL failures.
    
    Similar workaround already exists for ARM64 architecture. I has been
    added by commit 116c81f427ff ("arm64: Work around systems with mismatched
    cache line sizes").
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebc53804d57b..12cf7c4324a9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -375,6 +375,7 @@ static void smp_store_cpu_info(unsigned int cpuid)
 	cpu_info->cpuid = read_cpuid_id();
 
 	store_cpu_topology(cpuid);
+	check_cpu_icache_size(cpuid);
 }
 
 /*

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebc53804d57b..a137608cd197 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -1,11 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/arch/arm/kernel/smp.c
  *
  *  Copyright (C) 2002 ARM Limited, All Rights Reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/module.h>
 #include <linux/delay.h>

commit bfbfbf7368627860dd769567599d73ad8f6d8191
Merge: 88f76bc31b93 2a8d69f6139b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 15 08:46:44 2019 -0700

    Merge tag 'pm-5.2-rc1-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull more power management updates from Rafael Wysocki:
     "These fix a recent regression causing kernels built with CONFIG_PM
      unset to crash on systems that support the Performance and Energy Bias
      Hint (EPB), clean up the cpufreq core and some users of transition
      notifiers and introduce a new power domain flag into the generic power
      domains framework (genpd).
    
      Specifics:
    
       - Fix recent regression causing kernels built with CONFIG_PM unset to
         crash on systems that support the Performance and Energy Bias Hint
         (EPB) by avoiding to compile the EPB-related code depending on
         CONFIG_PM when it is unset (Rafael Wysocki).
    
       - Clean up the transition notifier invocation code in the cpufreq
         core and change some users of cpufreq transition notifiers
         accordingly (Viresh Kumar).
    
       - Change MAINTAINERS to cover the schedutil governor as part of
         cpufreq (Viresh Kumar).
    
       - Simplify cpufreq_init_policy() to avoid redundant computations (Yue
         Hu).
    
       - Add explanatory comment to the cpufreq core (Rafael Wysocki).
    
       - Introduce a new flag, GENPD_FLAG_RPM_ALWAYS_ON, to the generic
         power domains (genpd) framework along with the first user of it
         (Leonard Crestez)"
    
    * tag 'pm-5.2-rc1-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm:
      soc: imx: gpc: Use GENPD_FLAG_RPM_ALWAYS_ON for ERR009619
      PM / Domains: Add GENPD_FLAG_RPM_ALWAYS_ON flag
      cpufreq: Update MAINTAINERS to include schedutil governor
      cpufreq: Don't find governor for setpolicy drivers in cpufreq_init_policy()
      cpufreq: Explain the kobject_put() in cpufreq_policy_alloc()
      cpufreq: Call transition notifier only once for each policy
      x86: intel_epb: Take CONFIG_PM into account

commit be167862ae7dd85c56d385209a4890678e1b0488
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue May 14 15:41:48 2019 -0700

    ARM: prevent tracing IPI_CPU_BACKTRACE
    
    Patch series "compiler: allow all arches to enable
    CONFIG_OPTIMIZE_INLINING", v3.
    
    This patch (of 11):
    
    When function tracing for IPIs is enabled, we get a warning for an
    overflow of the ipi_types array with the IPI_CPU_BACKTRACE type as
    triggered by raise_nmi():
    
      arch/arm/kernel/smp.c: In function 'raise_nmi':
      arch/arm/kernel/smp.c:489:2: error: array subscript is above array bounds [-Werror=array-bounds]
        trace_ipi_raise(target, ipi_types[ipinr]);
    
    This is a correct warning as we actually overflow the array here.
    
    This patch raise_nmi() to call __smp_cross_call() instead of
    smp_cross_call(), to avoid calling into ftrace.  For clarification, I'm
    also adding a two new code comments describing how this one is special.
    
    The warning appears to have shown up after commit e7273ff49acf ("ARM:
    8488/1: Make IPI_CPU_BACKTRACE a "non-secure" SGI"), which changed the
    number assignment from '15' to '8', but as far as I can tell has existed
    since the IPI tracepoints were first introduced.  If we decide to
    backport this patch to stable kernels, we probably need to backport
    e7273ff49acf as well.
    
    [yamada.masahiro@socionext.com: rebase on v5.1-rc1]
    Link: http://lkml.kernel.org/r/20190423034959.13525-2-yamada.masahiro@socionext.com
    Fixes: e7273ff49acf ("ARM: 8488/1: Make IPI_CPU_BACKTRACE a "non-secure" SGI")
    Fixes: 365ec7b17327 ("ARM: add IPI tracepoints") # v3.17
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Mathieu Malaterre <malat@debian.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Stefan Agner <stefan@agner.ch>
    Cc: Boris Brezillon <bbrezillon@kernel.org>
    Cc: Miquel Raynal <miquel.raynal@bootlin.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index facd4240ca02..c93fe0f256de 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -70,6 +70,10 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 	IPI_IRQ_WORK,
 	IPI_COMPLETION,
+	/*
+	 * CPU_BACKTRACE is special and not included in NR_IPI
+	 * or tracable with trace_ipi_*
+	 */
 	IPI_CPU_BACKTRACE,
 	/*
 	 * SGI8-15 can be reserved by secure firmware, and thus may
@@ -797,7 +801,7 @@ core_initcall(register_cpufreq_notifier);
 
 static void raise_nmi(cpumask_t *mask)
 {
-	smp_cross_call(mask, IPI_CPU_BACKTRACE);
+	__smp_cross_call(mask, IPI_CPU_BACKTRACE);
 }
 
 void arch_trigger_cpumask_backtrace(const cpumask_t *mask, bool exclude_self)

commit df24014abe3694e7c34ce5e50248611b7a93fe83
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Mon Apr 29 15:03:58 2019 +0530

    cpufreq: Call transition notifier only once for each policy
    
    Currently, the notifiers are called once for each CPU of the policy->cpus
    cpumask. It would be more optimal if the notifier can be called only
    once and all the relevant information be provided to it. Out of the 23
    drivers that register for the transition notifiers today, only 4 of them
    do per-cpu updates and the callback for the rest can be called only once
    for the policy without any impact.
    
    This would also avoid multiple function calls to the notifier callbacks
    and reduce multiple iterations of notifier core's code (which does
    locking as well).
    
    This patch adds pointer to the cpufreq policy to the struct
    cpufreq_freqs, so the notifier callback has all the information
    available to it with a single call. The five drivers which perform
    per-cpu updates are updated to use the cpufreq policy. The freqs->cpu
    field is redundant now and is removed.
    
    Acked-by: David S. Miller <davem@davemloft.net> (sparc)
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index facd4240ca02..c6d37563610a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -754,15 +754,20 @@ static int cpufreq_callback(struct notifier_block *nb,
 					unsigned long val, void *data)
 {
 	struct cpufreq_freqs *freq = data;
-	int cpu = freq->cpu;
+	struct cpumask *cpus = freq->policy->cpus;
+	int cpu, first = cpumask_first(cpus);
+	unsigned int lpj;
 
 	if (freq->flags & CPUFREQ_CONST_LOOPS)
 		return NOTIFY_OK;
 
-	if (!per_cpu(l_p_j_ref, cpu)) {
-		per_cpu(l_p_j_ref, cpu) =
-			per_cpu(cpu_data, cpu).loops_per_jiffy;
-		per_cpu(l_p_j_ref_freq, cpu) = freq->old;
+	if (!per_cpu(l_p_j_ref, first)) {
+		for_each_cpu(cpu, cpus) {
+			per_cpu(l_p_j_ref, cpu) =
+				per_cpu(cpu_data, cpu).loops_per_jiffy;
+			per_cpu(l_p_j_ref_freq, cpu) = freq->old;
+		}
+
 		if (!global_l_p_j_ref) {
 			global_l_p_j_ref = loops_per_jiffy;
 			global_l_p_j_ref_freq = freq->old;
@@ -774,10 +779,11 @@ static int cpufreq_callback(struct notifier_block *nb,
 		loops_per_jiffy = cpufreq_scale(global_l_p_j_ref,
 						global_l_p_j_ref_freq,
 						freq->new);
-		per_cpu(cpu_data, cpu).loops_per_jiffy =
-			cpufreq_scale(per_cpu(l_p_j_ref, cpu),
-					per_cpu(l_p_j_ref_freq, cpu),
-					freq->new);
+
+		lpj = cpufreq_scale(per_cpu(l_p_j_ref, first),
+				    per_cpu(l_p_j_ref_freq, first), freq->new);
+		for_each_cpu(cpu, cpus)
+			per_cpu(cpu_data, cpu).loops_per_jiffy = lpj;
 	}
 	return NOTIFY_OK;
 }

commit 4c2741ac5e103ef2a63a1d4be2c762f52cb3593e
Merge: d410a8a49e3e 9db043d36bd3 6213f70e7c10
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Fri Mar 15 15:12:56 2019 +0000

    Merge branches 'fixes', 'misc' and 'smp-hotplug' into for-next

commit 5388a5b82199facacd3d7ac0d05aca6e8f902fed
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Apr 10 11:35:36 2018 +0100

    ARM: avoid Cortex-A9 livelock on tight dmb loops
    
    machine_crash_nonpanic_core() does this:
    
            while (1)
                    cpu_relax();
    
    because the kernel has crashed, and we have no known safe way to deal
    with the CPU.  So, we place the CPU into an infinite loop which we
    expect it to never exit - at least not until the system as a whole is
    reset by some method.
    
    In the absence of erratum 754327, this code assembles to:
    
            b       .
    
    In other words, an infinite loop.  When erratum 754327 is enabled,
    this becomes:
    
    1:      dmb
            b       1b
    
    It has been observed that on some systems (eg, OMAP4) where, if a
    crash is triggered, the system tries to kexec into the panic kernel,
    but fails after taking the secondary CPU down - placing it into one
    of these loops.  This causes the system to livelock, and the most
    noticable effect is the system stops after issuing:
    
            Loading crashdump kernel...
    
    to the system console.
    
    The tested as working solution I came up with was to add wfe() to
    these infinite loops thusly:
    
            while (1) {
                    cpu_relax();
                    wfe();
            }
    
    which, without 754327 builds to:
    
    1:      wfe
            b       1b
    
    or with 754327 is enabled:
    
    1:      dmb
            wfe
            b       1b
    
    Adding "wfe" does two things depending on the environment we're running
    under:
    - where we're running on bare metal, and the processor implements
      "wfe", it stops us spinning endlessly in a loop where we're never
      going to do any useful work.
    - if we're running in a VM, it allows the CPU to be given back to the
      hypervisor and rescheduled for other purposes (maybe a different VM)
      rather than wasting CPU cycles inside a crashed VM.
    
    However, in light of erratum 794072, Will Deacon wanted to see 10 nops
    as well - which is reasonable to cover the case where we have erratum
    754327 enabled _and_ we have a processor that doesn't implement the
    wfe hint.
    
    So, we now end up with:
    
    1:      wfe
            b       1b
    
    when erratum 754327 is disabled, or:
    
    1:      dmb
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            wfe
            b       1b
    
    when erratum 754327 is enabled.  We also get the dmb + 10 nop
    sequence elsewhere in the kernel, in terminating loops.
    
    This is reasonable - it means we get the workaround for erratum
    794072 when erratum 754327 is enabled, but still relinquish the dead
    processor - either by placing it in a lower power mode when wfe is
    implemented as such or by returning it to the hypervisior, or in the
    case where wfe is a no-op, we use the workaround specified in erratum
    794072 to avoid the problem.
    
    These as two entirely orthogonal problems - the 10 nops addresses
    erratum 794072, and the wfe is an optimisation that makes the system
    more efficient when crashed either in terms of power consumption or
    by allowing the host/other VMs to make use of the CPU.
    
    I don't see any reason not to use kexec() inside a VM - it has the
    potential to provide automated recovery from a failure of the VMs
    kernel with the opportunity for saving a crashdump of the failure.
    A panic() with a reboot timeout won't do that, and reading the
    libvirt documentation, setting on_reboot to "preserve" won't either
    (the documentation states "The preserve action for an on_reboot event
    is treated as a destroy".)  Surely it has to be a good thing to
    avoiding having CPUs spinning inside a VM that is doing no useful
    work.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3bf82232b1be..7f0b99e1fff3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -604,8 +604,10 @@ static void ipi_cpu_stop(unsigned int cpu)
 	local_fiq_disable();
 	local_irq_disable();
 
-	while (1)
+	while (1) {
 		cpu_relax();
+		wfe();
+	}
 }
 
 static DEFINE_PER_CPU(struct completion *, cpu_completion);

commit 6213f70e7c10fd4a01b65bad3826648fc78df8a8
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Thu Dec 13 14:02:48 2018 +0000

    ARM: smp: remove arch-provided "pen_release"
    
    Consolidating the "pen_release" stuff amongst the various SoC
    implementations gives credence to having a CPU holding pen for
    secondary CPUs.  However, this is far from the truth.
    
    Many SoC implementations cargo-cult copied various bits of the pen
    release implementation from the initial Realview/Versatile Express
    implementation without understanding what it was or why it existed.
    The reason it existed is because these are _development_ platforms,
    and some board firmware is unable to individually control the
    startup of secondary CPUs.  Moreover, they do not have a way to
    power down or reset secondary CPUs for hot-unplug.  Hence, the
    pen_release implementation was designed for ARM Ltd's development
    platforms to provide a working implementation, even though it is
    very far from what is required.
    
    It was decided a while back to reduce the duplication by consolidating
    the "pen_release" variable, but this only made the situation worse -
    we have ended up with several implementations that read this variable
    but do not write it - again, showing the cargo-cult mentality at work,
    lack of proper review of new code, and in some cases a lack of testing.
    
    While it would be preferable to remove pen_release entirely from the
    kernel, this is not possible without help from the SoC maintainers,
    which seems to be lacking.  However, I want to remove pen_release from
    arch code to remove the credence that having it gives.
    
    This patch removes pen_release from the arch code entirely, adding
    private per-SoC definitions for it instead, and explicitly stating
    that write_pen_release() is cargo-cult copied and should not be
    copied any further.  Rename write_pen_release() in a similar fashion
    as well.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3bf82232b1be..051b0e8e7d30 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -62,12 +62,6 @@
  */
 struct secondary_data secondary_data;
 
-/*
- * control for which core is the next to come out of the secondary
- * boot "holding pen"
- */
-volatile int pen_release = -1;
-
 enum ipi_msg_type {
 	IPI_WAKEUP,
 	IPI_TIMER,

commit 1b5ba350784242eb1f899bcffd95d2c7cff61e84
Author: Dietmar Eggemann <dietmar.eggemann@arm.com>
Date:   Mon Jan 21 14:42:42 2019 +0100

    ARM: 8824/1: fix a migrating irq bug when hotplug cpu
    
    Arm TC2 fails cpu hotplug stress test.
    
    This issue was tracked down to a missing copy of the new affinity
    cpumask for the vexpress-spc interrupt into struct
    irq_common_data.affinity when the interrupt is migrated in
    migrate_one_irq().
    
    Fix it by replacing the arm specific hotplug cpu migration with the
    generic irq code.
    
    This is the counterpart implementation to commit 217d453d473c ("arm64:
    fix a migrating irq bug when hotplug cpu").
    
    Tested with cpu hotplug stress test on Arm TC2 (multi_v7_defconfig plus
    CONFIG_ARM_BIG_LITTLE_CPUFREQ=y and CONFIG_ARM_VEXPRESS_SPC_CPUFREQ=y).
    The vexpress-spc interrupt (irq=22) on this board is affine to CPU0.
    Its affinity cpumask now changes correctly e.g. from 0 to 1-4 when
    CPU0 is hotplugged out.
    
    Suggested-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3bf82232b1be..1d6f5ea522f4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -254,7 +254,7 @@ int __cpu_disable(void)
 	/*
 	 * OK - migrate IRQs away from this CPU
 	 */
-	migrate_irqs();
+	irq_migrate_all_off_this_cpu();
 
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU

commit 97b6f89f7269b746b68e7985c16d2354c688d29a
Merge: 344eb5539abf 039bc3b7f29f d6951f582cc5
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Wed Jan 2 10:37:05 2019 +0000

    Merge branches 'misc', 'sa1100-for-next' and 'spectre' into for-linus

commit 383fb3ee8024d596f488d2dbaf45e572897acbdb
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Thu Jul 19 12:21:31 2018 +0100

    ARM: spectre-v2: per-CPU vtables to work around big.Little systems
    
    In big.Little systems, some CPUs require the Spectre workarounds in
    paths such as the context switch, but other CPUs do not.  In order
    to handle these differences, we need per-CPU vtables.
    
    We are unable to use the kernel's per-CPU variables to support this
    as per-CPU is not initialised at times when we need access to the
    vtables, so we have to use an array indexed by logical CPU number.
    
    We use an array-of-pointers to avoid having function pointers in
    the kernel's read/write .data section.
    
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 5ad0b67b9e33..82b879db32ee 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -42,6 +42,7 @@
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
+#include <asm/procinfo.h>
 #include <asm/processor.h>
 #include <asm/sections.h>
 #include <asm/tlbflush.h>
@@ -102,6 +103,30 @@ static unsigned long get_arch_pgd(pgd_t *pgd)
 #endif
 }
 
+#if defined(CONFIG_BIG_LITTLE) && defined(CONFIG_HARDEN_BRANCH_PREDICTOR)
+static int secondary_biglittle_prepare(unsigned int cpu)
+{
+	if (!cpu_vtable[cpu])
+		cpu_vtable[cpu] = kzalloc(sizeof(*cpu_vtable[cpu]), GFP_KERNEL);
+
+	return cpu_vtable[cpu] ? 0 : -ENOMEM;
+}
+
+static void secondary_biglittle_init(void)
+{
+	init_proc_vtable(lookup_processor(read_cpuid_id())->proc);
+}
+#else
+static int secondary_biglittle_prepare(unsigned int cpu)
+{
+	return 0;
+}
+
+static void secondary_biglittle_init(void)
+{
+}
+#endif
+
 int __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
 	int ret;
@@ -109,6 +134,10 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 	if (!smp_ops.smp_boot_secondary)
 		return -ENOSYS;
 
+	ret = secondary_biglittle_prepare(cpu);
+	if (ret)
+		return ret;
+
 	/*
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
@@ -360,6 +389,8 @@ asmlinkage void secondary_start_kernel(void)
 	struct mm_struct *mm = &init_mm;
 	unsigned int cpu;
 
+	secondary_biglittle_init();
+
 	/*
 	 * The identity mapping is uncached (strongly ordered), so
 	 * switch away from it before attempting any exclusive accesses.

commit 82c08c3e7f171aa7f579b231d0abbc1d62e91974
Author: Yufen Wang <wangyufen@huawei.com>
Date:   Fri Nov 2 11:51:31 2018 +0100

    ARM: 8808/1: kexec:offline panic_smp_self_stop CPU
    
    In case panic() and panic() called at the same time on different CPUS.
    For example:
    CPU 0:
      panic()
         __crash_kexec
           machine_crash_shutdown
             crash_smp_send_stop
           machine_kexec
             BUG_ON(num_online_cpus() > 1);
    
    CPU 1:
      panic()
        local_irq_disable
        panic_smp_self_stop
    
    If CPU 1 calls panic_smp_self_stop() before crash_smp_send_stop(), kdump
    fails. CPU1 can't receive the ipi irq, CPU1 will be always online.
    To fix this problem, this patch split out the panic_smp_self_stop()
    and add set_cpu_online(smp_processor_id(), false).
    
    Signed-off-by: Yufen Wang <wangyufen@huawei.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 0978282d5fc2..f574a5e0d589 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -693,6 +693,21 @@ void smp_send_stop(void)
 		pr_warn("SMP: failed to stop secondary CPUs\n");
 }
 
+/* In case panic() and panic() called at the same time on CPU1 and CPU2,
+ * and CPU 1 calls panic_smp_self_stop() before crash_smp_send_stop()
+ * CPU1 can't receive the ipi irqs from CPU2, CPU1 will be always online,
+ * kdump fails. So split out the panic_smp_self_stop() and add
+ * set_cpu_online(smp_processor_id(), false).
+ */
+void panic_smp_self_stop(void)
+{
+	pr_debug("CPU %u will stop doing anything useful since another CPU has paniced\n",
+	         smp_processor_id());
+	set_cpu_online(smp_processor_id(), false);
+	while (1)
+		cpu_relax();
+}
+
 /*
  * not supported here
  */

commit 0ac000e86703dedea1000513dbb8a64d02930668
Merge: 92d44a42af81 83d41fb9c0eb 10573ae547c8
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Jun 5 10:03:27 2018 +0100

    Merge branches 'fixes', 'misc' and 'spectre' into for-linus

commit 26602161b5ba795928a5a719fe1d5d9f2ab5c3ef
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Thu May 10 13:00:43 2018 +0100

    ARM: bugs: hook processor bug checking into SMP and suspend paths
    
    Check for CPU bugs when secondary processors are being brought online,
    and also when CPUs are resuming from a low power mode.  This gives an
    opportunity to check that processor specific bug workarounds are
    correctly enabled for all paths that a CPU re-enters the kernel.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Boot-tested-by: Tony Lindgren <tony@atomide.com>
    Reviewed-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 2da087926ebe..5ad0b67b9e33 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -31,6 +31,7 @@
 #include <linux/irq_work.h>
 
 #include <linux/atomic.h>
+#include <asm/bugs.h>
 #include <asm/smp.h>
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
@@ -405,6 +406,9 @@ asmlinkage void secondary_start_kernel(void)
 	 * before we continue - which happens after __cpu_up returns.
 	 */
 	set_cpu_online(cpu, true);
+
+	check_other_bugs();
+
 	complete(&cpu_running);
 
 	local_irq_enable();

commit 98f1b5a762f7bee20785ed576630386ddcc62483
Author: Grygorii Strashko <grygorii.strashko@ti.com>
Date:   Tue May 8 15:19:40 2018 +0100

    ARM: 8765/1: smp: Move clear_tasks_mm_cpumask() call to __cpu_die()
    
    Suspending a CPU on a RT kernel results in the following backtrace:
    
    | Disabling non-boot CPUs ...
    | BUG: sleeping function called from invalid context at kernel/locking/rtmutex.c:917
    | in_atomic(): 1, irqs_disabled(): 128, pid: 18, name: migration/1
    | INFO: lockdep is turned off.
    | irq event stamp: 122
    | hardirqs last  enabled at (121): [<c06ac0ac>] _raw_spin_unlock_irqrestore+0x88/0x90
    | hardirqs last disabled at (122): [<c06abed0>] _raw_spin_lock_irq+0x28/0x5c
    |  CPU: 1 PID: 18 Comm: migration/1 Tainted: G        W       4.1.4-rt3-01046-g96ac8da #204
    | Hardware name: Generic DRA74X (Flattened Device Tree)
    | [<c0019134>] (unwind_backtrace) from [<c0014774>] (show_stack+0x20/0x24)
    | [<c0014774>] (show_stack) from [<c06a70f4>] (dump_stack+0x88/0xdc)
    | [<c06a70f4>] (dump_stack) from [<c006cab8>] (___might_sleep+0x198/0x2a8)
    | [<c006cab8>] (___might_sleep) from [<c06ac4dc>] (rt_spin_lock+0x30/0x70)
    | [<c06ac4dc>] (rt_spin_lock) from [<c013f790>] (find_lock_task_mm+0x9c/0x174)
    | [<c013f790>] (find_lock_task_mm) from [<c00409ac>] (clear_tasks_mm_cpumask+0xb4/0x1ac)
    | [<c00409ac>] (clear_tasks_mm_cpumask) from [<c00166a4>] (__cpu_disable+0x98/0xbc)
    | [<c00166a4>] (__cpu_disable) from [<c06a2e8c>] (take_cpu_down+0x1c/0x50)
    | [<c06a2e8c>] (take_cpu_down) from [<c00f2600>] (multi_cpu_stop+0x11c/0x158)
    | [<c00f2600>] (multi_cpu_stop) from [<c00f2a9c>] (cpu_stopper_thread+0xc4/0x184)
    | [<c00f2a9c>] (cpu_stopper_thread) from [<c0069058>] (smpboot_thread_fn+0x18c/0x324)
    | [<c0069058>] (smpboot_thread_fn) from [<c00649c4>] (kthread+0xe8/0x104)
    | [<c00649c4>] (kthread) from [<c0010058>] (ret_from_fork+0x14/0x3c)
    | CPU1: shutdown
    
    The root cause of above backtrace is task_lock() which takes a sleeping
    lock on -RT.
    
    To fix the issue, move clear_tasks_mm_cpumask() call from __cpu_disable()
    to __cpu_die() which is called on the thread which is asking for a target
    CPU to be shutdown. In addition, this change restores CPU hotplug
    functionality on ARM CPU1 can be unplugged/plugged many times.
    
    Link: http://lkml.kernel.org/r/1441995683-30817-1-git-send-email-grygorii.strashko@ti.com
    [bigeasy: slighty edited the commit message]
    
    Signed-off-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: <linux-arm-kernel@lists.infradead.org>
    Cc: Sekhar Nori <nsekhar@ti.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 2da087926ebe..b9e08f50df41 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -236,8 +236,6 @@ int __cpu_disable(void)
 	flush_cache_louis();
 	local_flush_tlb_all();
 
-	clear_tasks_mm_cpumask(cpu);
-
 	return 0;
 }
 
@@ -255,6 +253,7 @@ void __cpu_die(unsigned int cpu)
 	}
 	pr_debug("CPU%u: shutdown\n", cpu);
 
+	clear_tasks_mm_cpumask(cpu);
 	/*
 	 * platform_cpu_kill() is generally expected to do the powering off
 	 * and/or cutting of clocks to the dying CPU.  Optionally, this may

commit 62d1c95d577ce4d40189e4c01025b616917e3c65
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Wed Dec 27 10:38:55 2017 +0100

    ARM: 8739/1: NOMMU: Setup VBAR/Hivecs for secondaries cores
    
    With switch to dynamic exception base address setting, VBAR/Hivecs
    set only for boot CPU, but secondaries stay unaware of that. That
    might lead to weird effects when trying up to bring up secondaries.
    
    Fixes: ad475117d201 ("ARM: 8649/2: nommu: remove Hivecs configuration is asm")
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Acked-by: afzal mohammed <afzal.mohd.ma@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b4fbf00ee4ad..2da087926ebe 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -379,6 +379,9 @@ asmlinkage void secondary_start_kernel(void)
 
 	cpu_init();
 
+#ifndef CONFIG_MMU
+	setup_vectors_base();
+#endif
 	pr_debug("CPU%u: Booted secondary processor\n", cpu);
 
 	preempt_disable();

commit a0995c0805b63c930b99970f2c9d5e4f167ca65b
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Mon Oct 16 12:54:05 2017 +0100

    ARM: 8708/1: NOMMU: Rework MPU to be mostly done in C
    
    Currently, there are several issues with how MPU is setup:
    
     1. We won't boot if MPU is missing
     2. We won't boot if use XIP
     3. Further extension of MPU setup requires asm skills
    
    The 1st point can be relaxed, so we can continue with boot CPU even if
    MPU is missed and fail boot for secondaries only. To address the 2nd
    point we could create region covering CONFIG_XIP_PHYS_ADDR - _end and
    that might work for the first stage of MPU enable, but due to MPU's
    alignment requirement we could cover too much, IOW we need more
    flexibility in how we're partitioning memory regions... and it'd be
    hardly possible to archive because of the 3rd point.
    
    This patch is trying to address 1st and 3rd issues and paves the path
    for 2nd and further improvements.
    
    The most visible change introduced with this patch is that we start
    using mpu_rgn_info array (as it was supposed?), so change in MPU setup
    done by boot CPU is recorded there and feed to secondaries. It
    allows us to keep minimal region setup for boot CPU and do the rest in
    C. Since we start programming MPU regions in C evaluation of MPU
    constrains (number of regions supported and minimal region order) can
    be done once, which in turn open possibility to free-up "probe"
    region early.
    
    Tested-by: Szemző András <sza@esh.hu>
    Tested-by: Alexandre TORGUE <alexandre.torgue@st.com>
    Tested-by: Benjamin Gaignard <benjamin.gaignard@linaro.org>
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index c9a0a5299827..b4fbf00ee4ad 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -114,7 +114,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
 #ifdef CONFIG_ARM_MPU
-	secondary_data.mpu_rgn_szr = mpu_rgn_info.rgns[MPU_RAM_REGION].drsr;
+	secondary_data.mpu_rgn_info = &mpu_rgn_info;
 #endif
 
 #ifdef CONFIG_MMU

commit 5976a66913a8bf42465d96776fd37fb5631edc19
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 16 20:42:33 2017 +0200

    arm: Adjust system_state check
    
    To enable smp_processor_id() and might_sleep() debug checks earlier, it's
    required to add system states between SYSTEM_BOOTING and SYSTEM_RUNNING.
    
    Adjust the system_state check in ipi_cpu_stop() to handle the extra states.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/20170516184735.020718977@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 572a8df1b766..c9a0a5299827 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -555,8 +555,7 @@ static DEFINE_RAW_SPINLOCK(stop_lock);
  */
 static void ipi_cpu_stop(unsigned int cpu)
 {
-	if (system_state == SYSTEM_BOOTING ||
-	    system_state == SYSTEM_RUNNING) {
+	if (system_state <= SYSTEM_RUNNING) {
 		raw_spin_lock(&stop_lock);
 		pr_crit("CPU%u: stopping\n", cpu);
 		dump_stack();

commit 68e21be2916b359fd8afb536c1911dc014cfd03e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 1 19:08:20 2017 +0100

    sched/headers: Move task->mm handling methods to <linux/sched/mm.h>
    
    Move the following task->mm helper APIs into a new header file,
    <linux/sched/mm.h>, to further reduce the size and complexity
    of <linux/sched.h>.
    
    Here are how the APIs are used in various kernel files:
    
      # mm_alloc():
      arch/arm/mach-rpc/ecard.c
      fs/exec.c
      include/linux/sched/mm.h
      kernel/fork.c
    
      # __mmdrop():
      arch/arc/include/asm/mmu_context.h
      include/linux/sched/mm.h
      kernel/fork.c
    
      # mmdrop():
      arch/arm/mach-rpc/ecard.c
      arch/m68k/sun3/mmu_emu.c
      arch/x86/mm/tlb.c
      drivers/gpu/drm/amd/amdkfd/kfd_process.c
      drivers/gpu/drm/i915/i915_gem_userptr.c
      drivers/infiniband/hw/hfi1/file_ops.c
      drivers/vfio/vfio_iommu_spapr_tce.c
      fs/exec.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      fs/proc/task_nommu.c
      fs/userfaultfd.c
      include/linux/mmu_notifier.h
      include/linux/sched/mm.h
      kernel/fork.c
      kernel/futex.c
      kernel/sched/core.c
      mm/khugepaged.c
      mm/ksm.c
      mm/mmu_context.c
      mm/mmu_notifier.c
      mm/oom_kill.c
      virt/kvm/kvm_main.c
    
      # mmdrop_async_fn():
      include/linux/sched/mm.h
    
      # mmdrop_async():
      include/linux/sched/mm.h
      kernel/fork.c
    
      # mmget_not_zero():
      fs/userfaultfd.c
      include/linux/sched/mm.h
      mm/oom_kill.c
    
      # mmput():
      arch/arc/include/asm/mmu_context.h
      arch/arc/kernel/troubleshoot.c
      arch/frv/mm/mmu-context.c
      arch/powerpc/platforms/cell/spufs/context.c
      arch/sparc/include/asm/mmu_context_32.h
      drivers/android/binder.c
      drivers/gpu/drm/etnaviv/etnaviv_gem.c
      drivers/gpu/drm/i915/i915_gem_userptr.c
      drivers/infiniband/core/umem.c
      drivers/infiniband/core/umem_odp.c
      drivers/infiniband/core/uverbs_main.c
      drivers/infiniband/hw/mlx4/main.c
      drivers/infiniband/hw/mlx5/main.c
      drivers/infiniband/hw/usnic/usnic_uiom.c
      drivers/iommu/amd_iommu_v2.c
      drivers/iommu/intel-svm.c
      drivers/lguest/lguest_user.c
      drivers/misc/cxl/fault.c
      drivers/misc/mic/scif/scif_rma.c
      drivers/oprofile/buffer_sync.c
      drivers/vfio/vfio_iommu_type1.c
      drivers/vhost/vhost.c
      drivers/xen/gntdev.c
      fs/exec.c
      fs/proc/array.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      fs/proc/task_nommu.c
      fs/userfaultfd.c
      include/linux/sched/mm.h
      kernel/cpuset.c
      kernel/events/core.c
      kernel/events/uprobes.c
      kernel/exit.c
      kernel/fork.c
      kernel/ptrace.c
      kernel/sys.c
      kernel/trace/trace_output.c
      kernel/tsacct.c
      mm/memcontrol.c
      mm/memory.c
      mm/mempolicy.c
      mm/migrate.c
      mm/mmu_notifier.c
      mm/nommu.c
      mm/oom_kill.c
      mm/process_vm_access.c
      mm/rmap.c
      mm/swapfile.c
      mm/util.c
      virt/kvm/async_pf.c
    
      # mmput_async():
      include/linux/sched/mm.h
      kernel/fork.c
      mm/oom_kill.c
    
      # get_task_mm():
      arch/arc/kernel/troubleshoot.c
      arch/powerpc/platforms/cell/spufs/context.c
      drivers/android/binder.c
      drivers/gpu/drm/etnaviv/etnaviv_gem.c
      drivers/infiniband/core/umem.c
      drivers/infiniband/core/umem_odp.c
      drivers/infiniband/hw/mlx4/main.c
      drivers/infiniband/hw/mlx5/main.c
      drivers/infiniband/hw/usnic/usnic_uiom.c
      drivers/iommu/amd_iommu_v2.c
      drivers/iommu/intel-svm.c
      drivers/lguest/lguest_user.c
      drivers/misc/cxl/fault.c
      drivers/misc/mic/scif/scif_rma.c
      drivers/oprofile/buffer_sync.c
      drivers/vfio/vfio_iommu_type1.c
      drivers/vhost/vhost.c
      drivers/xen/gntdev.c
      fs/proc/array.c
      fs/proc/base.c
      fs/proc/task_mmu.c
      include/linux/sched/mm.h
      kernel/cpuset.c
      kernel/events/core.c
      kernel/exit.c
      kernel/fork.c
      kernel/ptrace.c
      kernel/sys.c
      kernel/trace/trace_output.c
      kernel/tsacct.c
      mm/memcontrol.c
      mm/memory.c
      mm/mempolicy.c
      mm/migrate.c
      mm/mmu_notifier.c
      mm/nommu.c
      mm/util.c
    
      # mm_access():
      fs/proc/base.c
      include/linux/sched/mm.h
      kernel/fork.c
      mm/process_vm_access.c
    
      # mm_release():
      arch/arc/include/asm/mmu_context.h
      fs/exec.c
      include/linux/sched/mm.h
      include/uapi/linux/sched.h
      kernel/exit.c
      kernel/fork.c
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b724cff7ad60..572a8df1b766 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -11,7 +11,7 @@
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/spinlock.h>
-#include <linux/sched.h>
+#include <linux/sched/mm.h>
 #include <linux/sched/hotplug.h>
 #include <linux/sched/task_stack.h>
 #include <linux/interrupt.h>

commit 68db0cf10678630d286f4bbbbdfa102951a35faa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:37 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task_stack.h>
    
    We are going to split <linux/sched/task_stack.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task_stack.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 2083a5370308..b724cff7ad60 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -13,6 +13,7 @@
 #include <linux/spinlock.h>
 #include <linux/sched.h>
 #include <linux/sched/hotplug.h>
+#include <linux/sched/task_stack.h>
 #include <linux/interrupt.h>
 #include <linux/cache.h>
 #include <linux/profile.h>

commit ef8bd77f332bb0a4e467d7171bbfc6c57aa08a88
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/hotplug.h>
    
    We are going to split <linux/sched/hotplug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/hotplug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 5a07c5a4b894..2083a5370308 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -12,6 +12,7 @@
 #include <linux/init.h>
 #include <linux/spinlock.h>
 #include <linux/sched.h>
+#include <linux/sched/hotplug.h>
 #include <linux/interrupt.h>
 #include <linux/cache.h>
 #include <linux/profile.h>

commit d4f4cf77b37eaea58ef863a4cbc95dad3880b524
Merge: f89db789de21 17a870bea3b8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 28 11:50:53 2017 -0800

    Merge branch 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - nommu updates from Afzal Mohammed cleaning up the vectors support
    
     - allow DMA memory "mapping" for nommu Benjamin Gaignard
    
     - fixing a correctness issue with R_ARM_PREL31 relocations in the
       module linker
    
     - add strlen() prototype for the decompressor
    
     - support for DEBUG_VIRTUAL from Florian Fainelli
    
     - adjusting memory bounds after memory reservations have been
       registered
    
     - unipher cache handling updates from Masahiro Yamada
    
     - initrd and Thumb Kconfig cleanups
    
    * 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (23 commits)
      ARM: mm: round the initrd reservation to page boundaries
      ARM: mm: clean up initrd initialisation
      ARM: mm: move initrd init code out of arm_memblock_init()
      ARM: 8655/1: improve NOMMU definition of pgprot_*()
      ARM: 8654/1: decompressor: add strlen prototype
      ARM: 8652/1: cache-uniphier: clean up active way setup code
      ARM: 8651/1: cache-uniphier: include <linux/errno.h> instead of <linux/types.h>
      ARM: 8650/1: module: handle negative R_ARM_PREL31 addends correctly
      ARM: 8649/2: nommu: remove Hivecs configuration is asm
      ARM: 8648/2: nommu: display vectors base
      ARM: 8647/2: nommu: dynamic exception base address setting
      ARM: 8646/1: mmu: decouple VECTORS_BASE from Kconfig
      ARM: 8644/1: Reduce "CPU: shutdown" message to debug level
      ARM: 8641/1: treewide: Replace uses of virt_to_phys with __pa_symbol
      ARM: 8640/1: Add support for CONFIG_DEBUG_VIRTUAL
      ARM: 8639/1: Define KERNEL_START and KERNEL_END
      ARM: 8638/1: mtd: lart: Rename partition defines to be prefixed with PART_
      ARM: 8637/1: Adjust memory boundaries after reservations
      ARM: 8636/1: Cleanup sanity_check_meminfo
      ARM: add CPU_THUMB_CAPABLE to indicate possible Thumb support
      ...

commit 035e787543de709f29b38752251d4724200ec353
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Thu Jan 19 01:26:28 2017 +0100

    ARM: 8644/1: Reduce "CPU: shutdown" message to debug level
    
    Similar to c68b0274fb3c ("ARM: reduce "Booted secondary processor"
    message to debug level"), demote the "CPU: shutdown" pr_notice() into a
    pr_debug().
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7dd14e8395e6..46377c40d056 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -251,7 +251,7 @@ void __cpu_die(unsigned int cpu)
 		pr_err("CPU%u: cpu didn't die\n", cpu);
 		return;
 	}
-	pr_notice("CPU%u: shutdown\n", cpu);
+	pr_debug("CPU%u: shutdown\n", cpu);
 
 	/*
 	 * platform_cpu_kill() is generally expected to do the powering off

commit f1f1007644ffc8051a4c11427d58b1967ae7b75a
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Mon Feb 27 14:30:07 2017 -0800

    mm: add new mmgrab() helper
    
    Apart from adding the helper function itself, the rest of the kernel is
    converted mechanically using:
    
      git grep -l 'atomic_inc.*mm_count' | xargs sed -i 's/atomic_inc(&\(.*\)->mm_count);/mmgrab\(\1\);/'
      git grep -l 'atomic_inc.*mm_count' | xargs sed -i 's/atomic_inc(&\(.*\)\.mm_count);/mmgrab\(\&\1\);/'
    
    This is needed for a later patch that hooks into the helper, but might
    be a worthwhile cleanup on its own.
    
    (Michal Hocko provided most of the kerneldoc comment.)
    
    Link: http://lkml.kernel.org/r/20161218123229.22952-1-vegard.nossum@oracle.com
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7dd14e8395e6..c6514ce0fcbc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -371,7 +371,7 @@ asmlinkage void secondary_start_kernel(void)
 	 * reference and switch to it.
 	 */
 	cpu = smp_processor_id();
-	atomic_inc(&mm->mm_count);
+	mmgrab(mm);
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));
 

commit 677664895278267a80bda0e3b26821d60cdbebf5
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Fri Oct 7 17:02:49 2016 -0700

    nmi_backtrace: do a local dump_stack() instead of a self-NMI
    
    Currently on arm there is code that checks whether it should call
    dump_stack() explicitly, to avoid trying to raise an NMI when the
    current context is not preemptible by the backtrace IPI.  Similarly, the
    forthcoming arch/tile support uses an IPI mechanism that does not
    support generating an NMI to self.
    
    Accordingly, move the code that guards this case into the generic
    mechanism, and invoke it unconditionally whenever we want a backtrace of
    the current cpu.  It seems plausible that in all cases, dump_stack()
    will generate better information than generating a stack from the NMI
    handler.  The register state will be missing, but that state is likely
    not particularly helpful in any case.
    
    Or, if we think it is helpful, we should be capturing and emitting the
    current register state in all cases when regs == NULL is passed to
    nmi_cpu_backtrace().
    
    Link: http://lkml.kernel.org/r/1472487169-14923-3-git-send-email-cmetcalf@mellanox.com
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Tested-by: Daniel Thompson <daniel.thompson@linaro.org> [arm]
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Aaron Tomlin <atomlin@redhat.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 5abc5697e4e5..7dd14e8395e6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -748,15 +748,6 @@ core_initcall(register_cpufreq_notifier);
 
 static void raise_nmi(cpumask_t *mask)
 {
-	/*
-	 * Generate the backtrace directly if we are running in a calling
-	 * context that is not preemptible by the backtrace IPI. Note
-	 * that nmi_cpu_backtrace() automatically removes the current cpu
-	 * from mask.
-	 */
-	if (cpumask_test_cpu(smp_processor_id(), mask) && irqs_disabled())
-		nmi_cpu_backtrace(NULL);
-
 	smp_cross_call(mask, IPI_CPU_BACKTRACE);
 }
 

commit 9a01c3ed5cdb35d9004eb92510ee6ea11b4a5f16
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Fri Oct 7 17:02:45 2016 -0700

    nmi_backtrace: add more trigger_*_cpu_backtrace() methods
    
    Patch series "improvements to the nmi_backtrace code" v9.
    
    This patch series modifies the trigger_xxx_backtrace() NMI-based remote
    backtracing code to make it more flexible, and makes a few small
    improvements along the way.
    
    The motivation comes from the task isolation code, where there are
    scenarios where we want to be able to diagnose a case where some cpu is
    about to interrupt a task-isolated cpu.  It can be helpful to see both
    where the interrupting cpu is, and also an approximation of where the
    cpu that is being interrupted is.  The nmi_backtrace framework allows us
    to discover the stack of the interrupted cpu.
    
    I've tested that the change works as desired on tile, and build-tested
    x86, arm, mips, and sparc64.  For x86 I confirmed that the generic
    cpuidle stuff as well as the architecture-specific routines are in the
    new cpuidle section.  For arm, mips, and sparc I just build-tested it
    and made sure the generic cpuidle routines were in the new cpuidle
    section, but I didn't attempt to figure out which the platform-specific
    idle routines might be.  That might be more usefully done by someone
    with platform experience in follow-up patches.
    
    This patch (of 4):
    
    Currently you can only request a backtrace of either all cpus, or all
    cpus but yourself.  It can also be helpful to request a remote backtrace
    of a single cpu, and since we want that, the logical extension is to
    support a cpumask as the underlying primitive.
    
    This change modifies the existing lib/nmi_backtrace.c code to take a
    cpumask as its basic primitive, and modifies the linux/nmi.h code to use
    the new "cpumask" method instead.
    
    The existing clients of nmi_backtrace (arm and x86) are converted to
    using the new cpumask approach in this change.
    
    The other users of the backtracing API (sparc64 and mips) are converted
    to use the cpumask approach rather than the all/allbutself approach.
    The mips code ignored the "include_self" boolean but with this change it
    will now also dump a local backtrace if requested.
    
    Link: http://lkml.kernel.org/r/1472487169-14923-2-git-send-email-cmetcalf@mellanox.com
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Tested-by: Daniel Thompson <daniel.thompson@linaro.org> [arm]
    Reviewed-by: Aaron Tomlin <atomlin@redhat.com>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 937c8920d741..5abc5697e4e5 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -760,7 +760,7 @@ static void raise_nmi(cpumask_t *mask)
 	smp_cross_call(mask, IPI_CPU_BACKTRACE);
 }
 
-void arch_trigger_all_cpu_backtrace(bool include_self)
+void arch_trigger_cpumask_backtrace(const cpumask_t *mask, bool exclude_self)
 {
-	nmi_trigger_all_cpu_backtrace(include_self, raise_nmi);
+	nmi_trigger_cpumask_backtrace(mask, exclude_self, raise_nmi);
 }

commit 7619751f8c900fa5fdd76db06f4caf095c56de8e
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 10 22:46:49 2016 +0100

    ARM: 8595/2: apply more __ro_after_init
    
    Guided by grsecurity's analogous __read_only markings in arch/arm,
    this applies several uses of __ro_after_init to structures that are
    only updated during __init.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 861521606c6d..937c8920d741 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -82,7 +82,7 @@ enum ipi_msg_type {
 
 static DECLARE_COMPLETION(cpu_running);
 
-static struct smp_operations smp_ops;
+static struct smp_operations smp_ops __ro_after_init;
 
 void __init smp_set_ops(const struct smp_operations *ops)
 {

commit 9503427e916aea7ec2cc429504f82d7200ab4bcd
Merge: 0e289e534af1 d279f7a7e95a
Author: Olof Johansson <olof@lixom.net>
Date:   Sat Jun 18 22:21:52 2016 -0700

    Merge tag 'fixes-rcu-fiq-signed' of git://git.kernel.org/pub/scm/linux/kernel/git/tmlind/linux-omap into fixes
    
    Fixes for omaps for v4.7-rc cycle:
    
    - Two boot warning fixes from the RCU tree that should have gotten
      merged several weeks ago already but did not because of issues
      with who merges them. Paul has now split the RCU warning fixes into
      sets for various maintainers.
    
    - Fix ams-delta FIQ regression caused by omap1 sparse IRQ changes
    
    - Fix PM for omap3 boards using timer12 and gptimer, like the
      original beagleboard
    
    - Fix hangs on am437x-sk-evm by lowering the I2C bus speed
    
    * tag 'fixes-rcu-fiq-signed' of git://git.kernel.org/pub/scm/linux/kernel/git/tmlind/linux-omap:
      ARM: dts: am437x-sk-evm: Reduce i2c0 bus speed for tps65218
      ARM: OMAP2+: timer: add probe for clocksources
      ARM: OMAP1: fix ams-delta FIQ handler to work with sparse IRQ
      arm: Use _rcuidle for smp_cross_call() tracepoints
      arm: Use _rcuidle tracepoint to allow use from idle
    
    Signed-off-by: Olof Johansson <olof@lixom.net>

commit 7c64cc0531fa0d9720f9e15a0a0d97bcad1d1cd1
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 26 10:42:25 2016 -0700

    arm: Use _rcuidle for smp_cross_call() tracepoints
    
    Further testing with false negatives suppressed by commit 293e2421fe25
    ("rcu: Remove superfluous versions of rcu_read_lock_sched_held()")
    identified another unprotected use of RCU from the idle loop.  Because RCU
    actively ignores idle-loop code (for energy-efficiency reasons, among
    other things), using RCU from the idle loop can result in too-short
    grace periods, in turn resulting in arbitrary misbehavior.
    
    The resulting lockdep-RCU splat is as follows:
    
    ------------------------------------------------------------------------
    
    ===============================
    [ INFO: suspicious RCU usage. ]
    4.6.0-rc5-next-20160426+ #1112 Not tainted
    -------------------------------
    include/trace/events/ipi.h:35 suspicious rcu_dereference_check() usage!
    
    other info that might help us debug this:
    
    RCU used illegally from idle CPU!
    rcu_scheduler_active = 1, debug_locks = 0
    RCU used illegally from extended quiescent state!
    no locks held by swapper/0/0.
    
    stack backtrace:
    CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.6.0-rc5-next-20160426+ #1112
    Hardware name: Generic OMAP4 (Flattened Device Tree)
    [<c0110308>] (unwind_backtrace) from [<c010c3a8>] (show_stack+0x10/0x14)
    [<c010c3a8>] (show_stack) from [<c047fec8>] (dump_stack+0xb0/0xe4)
    [<c047fec8>] (dump_stack) from [<c010dcfc>] (smp_cross_call+0xbc/0x188)
    [<c010dcfc>] (smp_cross_call) from [<c01c9e28>] (generic_exec_single+0x9c/0x15c)
    [<c01c9e28>] (generic_exec_single) from [<c01ca0a0>] (smp_call_function_single_async+0 x38/0x9c)
    [<c01ca0a0>] (smp_call_function_single_async) from [<c0603728>] (cpuidle_coupled_poke_others+0x8c/0xa8)
    [<c0603728>] (cpuidle_coupled_poke_others) from [<c0603c10>] (cpuidle_enter_state_coupled+0x26c/0x390)
    [<c0603c10>] (cpuidle_enter_state_coupled) from [<c0183c74>] (cpu_startup_entry+0x198/0x3a0)
    [<c0183c74>] (cpu_startup_entry) from [<c0b00c0c>] (start_kernel+0x354/0x3c8)
    [<c0b00c0c>] (start_kernel) from [<8000807c>] (0x8000807c)
    
    ------------------------------------------------------------------------
    
    Reported-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: <linux-omap@vger.kernel.org>
    Cc: <linux-arm-kernel@lists.infradead.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index baee70267f29..7afe48ae5d76 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -486,7 +486,7 @@ static const char *ipi_types[NR_IPI] __tracepoint_string = {
 
 static void smp_cross_call(const struct cpumask *target, unsigned int ipinr)
 {
-	trace_ipi_raise(target, ipi_types[ipinr]);
+	trace_ipi_raise_rcuidle(target, ipi_types[ipinr]);
 	__smp_cross_call(target, ipinr);
 }
 

commit 42a0bb3f71383b457a7db362f1c69e7afb96732b
Author: Petr Mladek <pmladek@suse.com>
Date:   Fri May 20 17:00:33 2016 -0700

    printk/nmi: generic solution for safe printk in NMI
    
    printk() takes some locks and could not be used a safe way in NMI
    context.
    
    The chance of a deadlock is real especially when printing stacks from
    all CPUs.  This particular problem has been addressed on x86 by the
    commit a9edc8809328 ("x86/nmi: Perform a safe NMI stack trace on all
    CPUs").
    
    The patchset brings two big advantages.  First, it makes the NMI
    backtraces safe on all architectures for free.  Second, it makes all NMI
    messages almost safe on all architectures (the temporary buffer is
    limited.  We still should keep the number of messages in NMI context at
    minimum).
    
    Note that there already are several messages printed in NMI context:
    WARN_ON(in_nmi()), BUG_ON(in_nmi()), anything being printed out from MCE
    handlers.  These are not easy to avoid.
    
    This patch reuses most of the code and makes it generic.  It is useful
    for all messages and architectures that support NMI.
    
    The alternative printk_func is set when entering and is reseted when
    leaving NMI context.  It queues IRQ work to copy the messages into the
    main ring buffer in a safe context.
    
    __printk_nmi_flush() copies all available messages and reset the buffer.
    Then we could use a simple cmpxchg operations to get synchronized with
    writers.  There is also used a spinlock to get synchronized with other
    flushers.
    
    We do not longer use seq_buf because it depends on external lock.  It
    would be hard to make all supported operations safe for a lockless use.
    It would be confusing and error prone to make only some operations safe.
    
    The code is put into separate printk/nmi.c as suggested by Steven
    Rostedt.  It needs a per-CPU buffer and is compiled only on
    architectures that call nmi_enter().  This is achieved by the new
    HAVE_NMI Kconfig flag.
    
    The are MN10300 and Xtensa architectures.  We need to clean up NMI
    handling there first.  Let's do it separately.
    
    The patch is heavily based on the draft from Peter Zijlstra, see
    
      https://lkml.org/lkml/2015/6/10/327
    
    [arnd@arndb.de: printk-nmi: use %zu format string for size_t]
    [akpm@linux-foundation.org: min_t->min - all types are size_t here]
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Suggested-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Jan Kara <jack@suse.cz>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>    [arm part]
    Cc: Daniel Thompson <daniel.thompson@linaro.org>
    Cc: Jiri Kosina <jkosina@suse.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: David Miller <davem@davemloft.net>
    Cc: Daniel Thompson <daniel.thompson@linaro.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index baee70267f29..df90bc59bfce 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -644,9 +644,11 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		break;
 
 	case IPI_CPU_BACKTRACE:
+		printk_nmi_enter();
 		irq_enter();
 		nmi_cpu_backtrace(regs);
 		irq_exit();
+		printk_nmi_exit();
 		break;
 
 	default:

commit fc6d73d67436e7784758a831227bd019547a3f73
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 26 18:43:40 2016 +0000

    arch/hotplug: Call into idle with a proper state
    
    Let the non boot cpus call into idle with the corresponding hotplug state, so
    the hotplug core can handle the further bringup. That's a first step to
    convert the boot side of the hotplugged cpus to do all the synchronization
    with the other side through the state machine. For now it'll only start the
    hotplug thread and kick the full bringup of the cpu.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Cc: "Srivatsa S. Bhat" <srivatsa@mit.edu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Sebastian Siewior <bigeasy@linutronix.de>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Turner <pjt@google.com>
    Link: http://lkml.kernel.org/r/20160226182341.614102639@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 37312f6749f3..baee70267f29 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -409,7 +409,7 @@ asmlinkage void secondary_start_kernel(void)
 	/*
 	 * OK, it's off to the idle thread for us
 	 */
-	cpu_startup_entry(CPUHP_ONLINE);
+	cpu_startup_entry(CPUHP_AP_ONLINE_IDLE);
 }
 
 void __init smp_cpus_done(unsigned int max_cpus)

commit e7273ff49acf58a5ca9c656f3f0a5dd713390853
Author: Marc Zyngier <Marc.Zyngier@arm.com>
Date:   Fri Dec 18 11:06:47 2015 +0100

    ARM: 8488/1: Make IPI_CPU_BACKTRACE a "non-secure" SGI
    
    Having IPI_CPU_BACKTRACE as SGI15 may not work if the kernel is
    running in non-secure mode and that the secure firmware has
    decided to follow ARM's recommendations that SGI8-15 should
    be reserved for secure purpose.
    
    Now that we are "only" using SGI0-6, change IPI_CPU_BACKTRACE
    to use SGI7, which makes it more likely to work.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d50a77d638d3..37312f6749f3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -72,7 +72,12 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 	IPI_IRQ_WORK,
 	IPI_COMPLETION,
-	IPI_CPU_BACKTRACE = 15,
+	IPI_CPU_BACKTRACE,
+	/*
+	 * SGI8-15 can be reserved by secure firmware, and thus may
+	 * not be usable by the kernel. Please keep the above limited
+	 * to at most 8 entries.
+	 */
 };
 
 static DECLARE_COMPLETION(cpu_running);

commit 89d798b73dc64b3be2a653cabb4cb622675a9a36
Author: Marc Zyngier <Marc.Zyngier@arm.com>
Date:   Fri Dec 18 11:06:19 2015 +0100

    ARM: 8487/1: Remove IPI_CALL_FUNC_SINGLE
    
    Since 9a46ad6d6df3 ("smp: make smp_call_function_many() use logic
    similar to smp_call_function_single()"), the core IPI handling
    has been simplified, and generic_smp_call_function_interrupt is
    now the same as generic_smp_call_function_single_interrupt.
    
    This means that one of IPI_CALL_FUNC and IPI_CALL_FUNC_SINGLE has
    become redundant. We can then safely drop IPI_CALL_FUNC_SINGLE,
    and use only IPI_CALL_FUNC.
    
    This has the advantage of reducing the number of SGI IDs we're using
    (a fairly scarse resource).
    
    Tested on a dual A7 board.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b26361355dae..d50a77d638d3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -69,7 +69,6 @@ enum ipi_msg_type {
 	IPI_TIMER,
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
-	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
 	IPI_IRQ_WORK,
 	IPI_COMPLETION,
@@ -475,7 +474,6 @@ static const char *ipi_types[NR_IPI] __tracepoint_string = {
 	S(IPI_TIMER, "Timer broadcast interrupts"),
 	S(IPI_RESCHEDULE, "Rescheduling interrupts"),
 	S(IPI_CALL_FUNC, "Function call interrupts"),
-	S(IPI_CALL_FUNC_SINGLE, "Single function call interrupts"),
 	S(IPI_CPU_STOP, "CPU stop interrupts"),
 	S(IPI_IRQ_WORK, "IRQ work interrupts"),
 	S(IPI_COMPLETION, "completion interrupts"),
@@ -525,7 +523,7 @@ void arch_send_wakeup_ipi_mask(const struct cpumask *mask)
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC);
 }
 
 #ifdef CONFIG_IRQ_WORK
@@ -620,12 +618,6 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		irq_exit();
 		break;
 
-	case IPI_CALL_FUNC_SINGLE:
-		irq_enter();
-		generic_smp_call_function_single_interrupt();
-		irq_exit();
-		break;
-
 	case IPI_CPU_STOP:
 		irq_enter();
 		ipi_cpu_stop(cpu);

commit 0768330d46435f324a0b4860c889057524af17c2
Author: Daniel Thompson <daniel.thompson@linaro.org>
Date:   Tue Sep 22 17:12:10 2015 +0100

    ARM: 8439/1: Fix backtrace generation when IPI is masked
    
    Currently on ARM when <SysRq-L> is triggered from an interrupt handler
    (e.g. a SysRq issued using UART or kbd) the main CPU will wedge for ten
    seconds with interrupts masked before issuing a backtrace for every CPU
    except itself.
    
    The new backtrace code introduced by commit 96f0e00378d4 ("ARM: add
    basic support for on-demand backtrace of other CPUs") does not work
    correctly when run from an interrupt handler because IPI_CPU_BACKTRACE
    is used to generate the backtrace on all CPUs but cannot preempt the
    current calling context.
    
    This can be fixed by detecting that the calling context cannot be
    preempted and issuing the backtrace directly in this case. Issuing
    directly leaves us without any pt_regs to pass to nmi_cpu_backtrace()
    so we also modify the generic code to call dump_stack() when its
    argument is NULL.
    
    Acked-by: Hillf Danton <hillf.zj@alibaba-inc.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Daniel Thompson <daniel.thompson@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7c467c5b048e..b26361355dae 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -749,6 +749,15 @@ core_initcall(register_cpufreq_notifier);
 
 static void raise_nmi(cpumask_t *mask)
 {
+	/*
+	 * Generate the backtrace directly if we are running in a calling
+	 * context that is not preemptible by the backtrace IPI. Note
+	 * that nmi_cpu_backtrace() automatically removes the current cpu
+	 * from mask.
+	 */
+	if (cpumask_test_cpu(smp_processor_id(), mask) && irqs_disabled())
+		nmi_cpu_backtrace(NULL);
+
 	smp_cross_call(mask, IPI_CPU_BACKTRACE);
 }
 

commit 4caa9dda388f34f957a9eb52b9f5ef1a8c975c7b
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Wed Aug 26 07:49:11 2015 +0100

    ARM: 8424/1: add const qualifier to the argument of smp_set_ops()
    
    This function just copies '*ops' to 'smp_ops', so the given
    structure '*ops' is not modified at all.
    
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Acked-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 36045e8ced01..7c467c5b048e 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -80,7 +80,7 @@ static DECLARE_COMPLETION(cpu_running);
 
 static struct smp_operations smp_ops;
 
-void __init smp_set_ops(struct smp_operations *ops)
+void __init smp_set_ops(const struct smp_operations *ops)
 {
 	if (ops)
 		smp_ops = *ops;

commit bbeb9209515989ff47802d4e5d5702178c8e42c4
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Tue Aug 25 13:52:09 2015 +0100

    ARM: 8422/1: enable imprecise aborts during early kernel startup
    
    This patch adds imprecise abort enable/disable macros and uses them to
    enable imprecise aborts early when starting the kernel.
    
    This helps in tracking down the real cause for such imprecise abort, as
    they are handled as soon as they occur. Until now those aborts would
    only be enabled when entering the userspace and as a consequence crash
    the first userspace process if any abort had been raised during kernel
    startup.
    
    Signed-off-by: Fabrice Gasnier <fabrice.gasnier@st.com>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 48185a773852..36045e8ced01 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -400,6 +400,7 @@ asmlinkage void secondary_start_kernel(void)
 
 	local_irq_enable();
 	local_fiq_enable();
+	local_abt_enable();
 
 	/*
 	 * OK, it's off to the idle thread for us

commit 6f0a2fc1feb19bd142961a39dc118e7e55418b3f
Merge: 752240e74d65 96f0e00378d4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 8 12:28:10 2015 -0700

    Merge branch 'nmi' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull NMI backtrace update from Russell King:
     "These changes convert the x86 NMI handling to be a library
      implementation which other architectures can make use of.  Thomas
      Gleixner has reviewed and tested these changes, and wishes me to send
      these rather than taking them through the tip tree.
    
      The final patch in the set adds an initial implementation using this
      infrastructure to ARM, even though it doesn't send the IPI at "NMI"
      level.  Patches are in progress to add the ARM equivalent of NMI, but
      we still need the IRQ-level fallback for systems where the "NMI" isn't
      available due to secure firmware denying access to it"
    
    * 'nmi' of git://ftp.arm.linux.org.uk/~rmk/linux-arm:
      ARM: add basic support for on-demand backtrace of other CPUs
      nmi: x86: convert to generic nmi handler
      nmi: create generic NMI backtrace implementation

commit 40d3f02851577da27b5cbb1538888301245ef1e7
Merge: e0aa3a665782 3939f3345050 9205b797dbe5 3fa609755c11 a5e090acbf54
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Sep 3 15:28:37 2015 +0100

    Merge branches 'cleanup', 'fixes', 'misc', 'omap-barrier' and 'uaccess' into for-linus

commit 9205b797dbe519a629267ec8c5766cd973d35063
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Mon Aug 24 21:49:30 2015 +0100

    ARM: 8421/1: smp: Collapse arch_cpu_idle_dead() into cpu_die()
    
    The only caller of cpu_die() on ARM is arch_cpu_idle_dead(), so
    let's simplify the code by renaming cpu_die() to
    arch_cpu_idle_dead(). While were here, drop the __ref annotation
    because __cpuinit is gone nowadays.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3cd846f48eaf..0aad7cdf2e58 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -266,7 +266,7 @@ void __cpu_die(unsigned int cpu)
  * of the other hotplug-cpu capable cores, so presumably coming
  * out of idle fixes this.
  */
-void __ref cpu_die(void)
+void arch_cpu_idle_dead(void)
 {
 	unsigned int cpu = smp_processor_id();
 

commit 787047eea24a2443c366679ae6b5a3873a33b64e
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Wed Jul 29 00:34:48 2015 +0100

    ARM: 8392/3: smp: Only expose /sys/.../cpuX/online if hotpluggable
    
    Writes to /sys/.../cpuX/online fail if we determine the platform
    doesn't support hotplug for that CPU. Furthermore, if the cpu_die
    op isn't specified the system hangs when we try to offline a CPU
    and it comes right back online unexpectedly. Let's figure this
    stuff out before we make the sysfs nodes so that the online file
    doesn't even exist if it isn't (at least sometimes) possible to
    hotplug the CPU.
    
    Add a new 'cpu_can_disable' op and repoint all 'cpu_disable'
    implementations at it because all implementers use the op to
    indicate if a CPU can be hotplugged or not in a static fashion.
    With PSCI we may need to add a 'cpu_disable' op so that the
    secure OS can be migrated off the CPU we're trying to hotplug.
    In this case, the 'cpu_can_disable' op will indicate that all
    CPUs are hotpluggable by returning true, but the 'cpu_disable' op
    will make a PSCI migration call and occasionally fail, denying
    the hotplug of a CPU. This shouldn't be any worse than x86 where
    we may indicate that all CPUs are hotpluggable but occasionally
    we can't offline a CPU due to check_irq_vectors_for_cpu_disable()
    failing to find a CPU to move vectors to.
    
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Simon Horman <horms@verge.net.au> [shmobile portion]
    Tested-by: Simon Horman <horms@verge.net.au>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: <linux-sh@vger.kernel.org>
    Tested-by: Tyler Baker <tyler.baker@linaro.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 90dfbedfbfb8..3cd846f48eaf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -175,13 +175,26 @@ static int platform_cpu_disable(unsigned int cpu)
 	if (smp_ops.cpu_disable)
 		return smp_ops.cpu_disable(cpu);
 
+	return 0;
+}
+
+int platform_can_hotplug_cpu(unsigned int cpu)
+{
+	/* cpu_die must be specified to support hotplug */
+	if (!smp_ops.cpu_die)
+		return 0;
+
+	if (smp_ops.cpu_can_disable)
+		return smp_ops.cpu_can_disable(cpu);
+
 	/*
 	 * By default, allow disabling all CPUs except the first one,
 	 * since this is special on a lot of platforms, e.g. because
 	 * of clock tick interrupts.
 	 */
-	return cpu == 0 ? -EPERM : 0;
+	return cpu != 0;
 }
+
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */

commit 96f0e00378d4a1fc1b79933ef84e1595015de808
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Sep 3 23:57:13 2014 +0100

    ARM: add basic support for on-demand backtrace of other CPUs
    
    As we now have generic infrastructure to support backtracing of other
    CPUs in the system on lockups, we can start to implement this for ARM.
    Initially, we add an IPI based implementation, as the GIC code needs
    modification to support the generation of FIQ IPIs, and not all ARM
    platforms have the ability to raise a FIQ in the non-secure world.
    
    This provides us with a "best efforts" implementation in the absence
    of FIQs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 90dfbedfbfb8..3a20c386fd33 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -21,6 +21,7 @@
 #include <linux/cpu.h>
 #include <linux/seq_file.h>
 #include <linux/irq.h>
+#include <linux/nmi.h>
 #include <linux/percpu.h>
 #include <linux/clockchips.h>
 #include <linux/completion.h>
@@ -72,6 +73,7 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 	IPI_IRQ_WORK,
 	IPI_COMPLETION,
+	IPI_CPU_BACKTRACE = 15,
 };
 
 static DECLARE_COMPLETION(cpu_running);
@@ -630,6 +632,12 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		irq_exit();
 		break;
 
+	case IPI_CPU_BACKTRACE:
+		irq_enter();
+		nmi_cpu_backtrace(regs);
+		irq_exit();
+		break;
+
 	default:
 		pr_crit("CPU%u: Unknown IPI message 0x%x\n",
 		        cpu, ipinr);
@@ -724,3 +732,13 @@ static int __init register_cpufreq_notifier(void)
 core_initcall(register_cpufreq_notifier);
 
 #endif
+
+static void raise_nmi(cpumask_t *mask)
+{
+	smp_cross_call(mask, IPI_CPU_BACKTRACE);
+}
+
+void arch_trigger_all_cpu_backtrace(bool include_self)
+{
+	nmi_trigger_all_cpu_backtrace(include_self, raise_nmi);
+}

commit 06be5eefe1192eb8ce8d07497f67595b6bfe9741
Merge: 11b8b25ce4f8 1bd46782d08b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jul 7 12:35:33 2015 +0100

    Merge branches 'fixes' and 'ioremap' into for-linus

commit 398f74569cebbf06bc6b069442bcd0e9616ca465
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Fri Jun 19 21:37:56 2015 +0100

    ARM: 8393/1: smp: Fix suspicious RCU usage with ipi tracepoints
    
    John Stultz reports an RCU splat on boot with ARM ipi trace
    events enabled.
    
    ===============================
    [ INFO: suspicious RCU usage. ]
    4.1.0-rc7-00033-gb5bed2f #153 Not tainted
    -------------------------------
    include/trace/events/ipi.h:68 suspicious rcu_dereference_check() usage!
    
    other info that might help us debug this:
    
    RCU used illegally from idle CPU!
    rcu_scheduler_active = 1, debug_locks = 0
    RCU used illegally from extended quiescent state!
    no locks held by swapper/0/0.
    
    stack backtrace:
    CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.1.0-rc7-00033-gb5bed2f #153
    Hardware name: Qualcomm (Flattened Device Tree)
    [<c0216b08>] (unwind_backtrace) from [<c02136e8>] (show_stack+0x10/0x14)
    [<c02136e8>] (show_stack) from [<c075e678>] (dump_stack+0x70/0xbc)
    [<c075e678>] (dump_stack) from [<c0215a80>] (handle_IPI+0x428/0x604)
    [<c0215a80>] (handle_IPI) from [<c020942c>] (gic_handle_irq+0x54/0x5c)
    [<c020942c>] (gic_handle_irq) from [<c0766604>] (__irq_svc+0x44/0x7c)
    Exception stack(0xc09f3f48 to 0xc09f3f90)
    3f40:                   00000001 00000001 00000000 c09f73b8 c09f4528 c0a5de9c
    3f60: c076b4f0 00000000 00000000 c09ef108 c0a5cec1 00000001 00000000 c09f3f90
    3f80: c026bf60 c0210ab8 20000113 ffffffff
    [<c0766604>] (__irq_svc) from [<c0210ab8>] (arch_cpu_idle+0x20/0x3c)
    [<c0210ab8>] (arch_cpu_idle) from [<c02647f0>] (cpu_startup_entry+0x2c0/0x5dc)
    [<c02647f0>] (cpu_startup_entry) from [<c099bc1c>] (start_kernel+0x358/0x3c4)
    [<c099bc1c>] (start_kernel) from [<8020807c>] (0x8020807c)
    
    At this point in the IPI handling path we haven't called
    irq_enter() yet, so RCU doesn't know that we're about to exit
    idle and properly warns that we're using RCU from an idle CPU.
    Use trace_ipi_entry_rcuidle() instead of trace_ipi_entry() so
    that RCU is informed about our exit from idle.
    
    Fixes: 365ec7b17327 ("ARM: add IPI tracepoints")
    Reported-by: John Stultz <john.stultz@linaro.org>
    Tested-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index cca5b8758185..f11d82527076 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -576,7 +576,7 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	if ((unsigned)ipinr < NR_IPI) {
-		trace_ipi_entry(ipi_types[ipinr]);
+		trace_ipi_entry_rcuidle(ipi_types[ipinr]);
 		__inc_irq_stat(cpu, ipi_irqs[ipinr]);
 	}
 
@@ -635,7 +635,7 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 	}
 
 	if ((unsigned)ipinr < NR_IPI)
-		trace_ipi_exit(ipi_types[ipinr]);
+		trace_ipi_exit_rcuidle(ipi_types[ipinr]);
 	set_irq_regs(old_regs);
 }
 

commit b2c3e38a54714e917c9e8675ff5812dca1c0f39d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Apr 4 20:09:46 2015 +0100

    ARM: redo TTBR setup code for LPAE
    
    Re-engineer the LPAE TTBR setup code.  Rather than passing some shifted
    address in order to fit in a CPU register, pass either a full physical
    address (in the case of r4, r5 for TTBR0) or a PFN (for TTBR1).
    
    This removes the ARCH_PGD_SHIFT hack, and the last dangerous user of
    cpu_set_ttbr() in the secondary CPU startup code path (which was there
    to re-set TTBR1 to the appropriate high physical address space on
    Keystone2.)
    
    Tested-by: Murali Karicheri <m-karicheri2@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index cca5b8758185..90dfbedfbfb8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -86,9 +86,11 @@ void __init smp_set_ops(struct smp_operations *ops)
 
 static unsigned long get_arch_pgd(pgd_t *pgd)
 {
-	phys_addr_t pgdir = virt_to_idmap(pgd);
-	BUG_ON(pgdir & ARCH_PGD_MASK);
-	return pgdir >> ARCH_PGD_SHIFT;
+#ifdef CONFIG_ARM_LPAE
+	return __phys_to_pfn(virt_to_phys(pgd));
+#else
+	return virt_to_phys(pgd);
+#endif
 }
 
 int __cpu_up(unsigned int cpu, struct task_struct *idle)
@@ -108,7 +110,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 #endif
 
 #ifdef CONFIG_MMU
-	secondary_data.pgdir = get_arch_pgd(idmap_pgd);
+	secondary_data.pgdir = virt_to_phys(idmap_pgd);
 	secondary_data.swapper_pg_dir = get_arch_pgd(swapper_pg_dir);
 #endif
 	sync_cache_w(&secondary_data);

commit fee3fd4fd2ad136b26226346c3f8b446cc120bf5
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Wed Apr 1 13:36:57 2015 +0100

    ARM: 8338/1: kexec: Relax SMP validation to improve DT compatibility
    
    When trying to kexec into a new kernel on a platform where multiple CPU
    cores are present, but no SMP bringup code is available yet, the
    kexec_load system call fails with:
    
        kexec_load failed: Invalid argument
    
    The SMP test added to machine_kexec_prepare() in commit 2103f6cba61a8b8b
    ("ARM: 7807/1: kexec: validate CPU hotplug support") wants to prohibit
    kexec on SMP platforms where it cannot disable secondary CPUs.
    However, this test is too strict: if the secondary CPUs couldn't be
    enabled in the first place, there's no need to disable them later at
    kexec time.  Hence skip the test in the absence of SMP bringup code.
    
    This allows to add all CPU cores to the DTS from the beginning, without
    having to implement SMP bringup first, improving DT compatibility.
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Acked-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 86ef244c5a24..cca5b8758185 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -145,6 +145,11 @@ void __init smp_init_cpus(void)
 		smp_ops.smp_init_cpus();
 }
 
+int platform_can_secondary_boot(void)
+{
+	return !!smp_ops.smp_boot_secondary;
+}
+
 int platform_can_cpu_hotplug(void)
 {
 #ifdef CONFIG_HOTPLUG_CPU

commit 4bf9636c39ac70da091d5a2e28d3448eaa7f115c
Author: Pavel Machek <pavel@ucw.cz>
Date:   Sun Jan 4 20:01:23 2015 +0100

    Revert "ARM: 7830/1: delay: don't bother reporting bogomips in /proc/cpuinfo"
    
    Commit 9fc2105aeaaf ("ARM: 7830/1: delay: don't bother reporting
    bogomips in /proc/cpuinfo") breaks audio in python, and probably
    elsewhere, with message
    
      FATAL: cannot locate cpu MHz in /proc/cpuinfo
    
    I'm not the first one to hit it, see for example
    
      https://theredblacktree.wordpress.com/2014/08/10/fatal-cannot-locate-cpu-mhz-in-proccpuinfo/
      https://devtalk.nvidia.com/default/topic/765800/workaround-for-fatal-cannot-locate-cpu-mhz-in-proc-cpuinf/?offset=1
    
    Reading original changelog, I have to say "Stop breaking working setups.
    You know who you are!".
    
    Signed-off-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 5e6052e18850..86ef244c5a24 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -387,6 +387,18 @@ asmlinkage void secondary_start_kernel(void)
 
 void __init smp_cpus_done(unsigned int max_cpus)
 {
+	int cpu;
+	unsigned long bogosum = 0;
+
+	for_each_online_cpu(cpu)
+		bogosum += per_cpu(cpu_data, cpu).loops_per_jiffy;
+
+	printk(KERN_INFO "SMP: Total of %d processors activated "
+	       "(%lu.%02lu BogoMIPS).\n",
+	       num_online_cpus(),
+	       bogosum / (500000/HZ),
+	       (bogosum / (5000/HZ)) % 100);
+
 	hyp_mode_check();
 }
 

commit 1381c5a65fc6abc8b22f179da6a6577b0deb0687
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 28 12:13:59 2014 +0000

    ARM: remove "SMP: Total of %d processors activated." message
    
    The "SMP: Total of %d processors activated." message which we print in
    smp_cpus_done() provides no further information than the message in
    genreic code in smp_announce().  Kill it.
    
    Tested-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7b18a1be179c..5e6052e18850 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -387,9 +387,6 @@ asmlinkage void secondary_start_kernel(void)
 
 void __init smp_cpus_done(unsigned int max_cpus)
 {
-	pr_info("SMP: Total of %d processors activated.\n",
-		num_online_cpus());
-
 	hyp_mode_check();
 }
 

commit c68b0274fb3cf8b98c3696354833c03e49963bf4
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 28 12:08:34 2014 +0000

    ARM: reduce "Booted secondary processor" message to debug level
    
    Drop the "CPUn: Booted secondary processor" message from info to debug
    level.  We later print how many CPUs came online, so listing each one
    is redundant, and when using hotplug, can be quite noisy.
    
    Tested-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3138d8ea9e55..7b18a1be179c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -351,7 +351,7 @@ asmlinkage void secondary_start_kernel(void)
 
 	cpu_init();
 
-	pr_info("CPU%u: Booted secondary processor\n", cpu);
+	pr_debug("CPU%u: Booted secondary processor\n", cpu);
 
 	preempt_disable();
 	trace_hardirqs_off();

commit 4ed89f2228061422ce5f62545fd0b6f6648bd2cc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 28 11:26:42 2014 +0000

    ARM: convert printk(KERN_* to pr_*
    
    Convert many (but not all) printk(KERN_* to pr_* to simplify the code.
    We take the opportunity to join some printk lines together so we don't
    split the message across several lines, and we also add a few levels
    to some messages which were previously missing them.
    
    Tested-by: Andrew Lunn <andrew@lunn.ch>
    Tested-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 13396d3d600e..3138d8ea9e55 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -225,7 +225,7 @@ void __cpu_die(unsigned int cpu)
 		pr_err("CPU%u: cpu didn't die\n", cpu);
 		return;
 	}
-	printk(KERN_NOTICE "CPU%u: shutdown\n", cpu);
+	pr_notice("CPU%u: shutdown\n", cpu);
 
 	/*
 	 * platform_cpu_kill() is generally expected to do the powering off
@@ -235,7 +235,7 @@ void __cpu_die(unsigned int cpu)
 	 * the requesting CPU and the dying CPU actually losing power.
 	 */
 	if (!platform_cpu_kill(cpu))
-		printk("CPU%u: unable to kill\n", cpu);
+		pr_err("CPU%u: unable to kill\n", cpu);
 }
 
 /*
@@ -351,7 +351,7 @@ asmlinkage void secondary_start_kernel(void)
 
 	cpu_init();
 
-	printk("CPU%u: Booted secondary processor\n", cpu);
+	pr_info("CPU%u: Booted secondary processor\n", cpu);
 
 	preempt_disable();
 	trace_hardirqs_off();
@@ -387,8 +387,8 @@ asmlinkage void secondary_start_kernel(void)
 
 void __init smp_cpus_done(unsigned int max_cpus)
 {
-	printk(KERN_INFO "SMP: Total of %d processors activated.\n",
-	       num_online_cpus());
+	pr_info("SMP: Total of %d processors activated.\n",
+		num_online_cpus());
 
 	hyp_mode_check();
 }
@@ -521,7 +521,7 @@ static void ipi_cpu_stop(unsigned int cpu)
 	if (system_state == SYSTEM_BOOTING ||
 	    system_state == SYSTEM_RUNNING) {
 		raw_spin_lock(&stop_lock);
-		printk(KERN_CRIT "CPU%u: stopping\n", cpu);
+		pr_crit("CPU%u: stopping\n", cpu);
 		dump_stack();
 		raw_spin_unlock(&stop_lock);
 	}
@@ -615,8 +615,8 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		break;
 
 	default:
-		printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
-		       cpu, ipinr);
+		pr_crit("CPU%u: Unknown IPI message 0x%x\n",
+		        cpu, ipinr);
 		break;
 	}
 

commit afa3536be88b435a057cb727b48fd3d760a497d2
Merge: 35a9ad8af0bb 9b01f5bf3999
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 9 06:30:57 2014 -0400

    Merge branch 'timers-nohz-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer fixes from Ingo Molnar:
     "Main changes:
    
      - Fix the deadlock reported by Dave Jones et al
      - Clean up and fix nohz_full interaction with arch abilities
      - nohz init code consolidation/cleanup"
    
    * 'timers-nohz-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      nohz: nohz full depends on irq work self IPI support
      nohz: Consolidate nohz full init code
      arm64: Tell irq work about self IPI support
      arm: Tell irq work about self IPI support
      x86: Tell irq work about self IPI support
      irq_work: Force raised irq work to run on irq work interrupt
      irq_work: Introduce arch_irq_work_has_interrupt()
      nohz: Move nohz full init call to tick init

commit 8b521cb2947d8811b4cf7fc6a7a6ebde35218243
Author: Joe Perches <joe@perches.com>
Date:   Tue Sep 16 20:41:43 2014 +0100

    ARM: 8152/1: Convert pr_warning to pr_warn
    
    Use the more common pr_warn.
    
    Other miscellanea:
    
    o Coalesce formats
    o Realign arguments
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d19aea4385d9..39c74a2c3df9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -646,7 +646,7 @@ void smp_send_stop(void)
 		udelay(1);
 
 	if (num_online_cpus() > 1)
-		pr_warning("SMP: failed to stop secondary CPUs\n");
+		pr_warn("SMP: failed to stop secondary CPUs\n");
 }
 
 /*

commit 09f6edd424218eb69078551b2ecfada1f2d098eb
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Aug 16 18:47:53 2014 +0200

    arm: Tell irq work about self IPI support
    
    ARM irq work IPI support depends on SMP support. That information is
    partly known at early boottime. Lets implement
    arch_irq_work_has_interrupt() accordingly.
    
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 9388a3d479e1..bbe22fcb78f6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -503,7 +503,7 @@ void arch_send_call_function_single_ipi(int cpu)
 #ifdef CONFIG_IRQ_WORK
 void arch_irq_work_raise(void)
 {
-	if (is_smp())
+	if (arch_irq_work_has_interrupt())
 		smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
 }
 #endif

commit 084bb5bc00c19ec32b45f44d11ba6a0ca2514ec3
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Wed Aug 20 20:49:54 2014 +0100

    ARM: 8131/1: arm/smp: Absorb boot_secondary()
    
    After becoming a mandatory function, boot_secondary() is no longer used
    outside arch/arm/kernel/smp.c. Hence remove its public prototype, and,
    as suggested by Arnd, let it be absorbed by its single caller.
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 9388a3d479e1..d19aea4385d9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -95,6 +95,9 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
 	int ret;
 
+	if (!smp_ops.smp_boot_secondary)
+		return -ENOSYS;
+
 	/*
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
@@ -113,7 +116,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 	/*
 	 * Now bring the CPU into our world.
 	 */
-	ret = boot_secondary(cpu, idle);
+	ret = smp_ops.smp_boot_secondary(cpu, idle);
 	if (ret == 0) {
 		/*
 		 * CPU was successfully started, wait for it
@@ -142,13 +145,6 @@ void __init smp_init_cpus(void)
 		smp_ops.smp_init_cpus();
 }
 
-int boot_secondary(unsigned int cpu, struct task_struct *idle)
-{
-	if (smp_ops.smp_boot_secondary)
-		return smp_ops.smp_boot_secondary(cpu, idle);
-	return -ENOSYS;
-}
-
 int platform_can_cpu_hotplug(void)
 {
 #ifdef CONFIG_HOTPLUG_CPU

commit 365ec7b17327329efc71276722ca8db3f21f2edd
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Fri Jul 25 16:05:31 2014 -0400

    ARM: add IPI tracepoints
    
    The strings used to list IPIs in /proc/interrupts are reused for tracing
    purposes.
    
    While at it, prevent a negative ipinr from escaping the range check
    in handle_IPI().
    
    Link: http://lkml.kernel.org/p/1406318733-26754-4-git-send-email-nicolas.pitre@linaro.org
    
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7c4fada440f0..9388a3d479e1 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -47,6 +47,9 @@
 #include <asm/mach/arch.h>
 #include <asm/mpu.h>
 
+#define CREATE_TRACE_POINTS
+#include <trace/events/ipi.h>
+
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
  * so we need some other way of telling a new secondary core
@@ -430,38 +433,15 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 	}
 }
 
-static void (*smp_cross_call)(const struct cpumask *, unsigned int);
+static void (*__smp_cross_call)(const struct cpumask *, unsigned int);
 
 void __init set_smp_cross_call(void (*fn)(const struct cpumask *, unsigned int))
 {
-	if (!smp_cross_call)
-		smp_cross_call = fn;
-}
-
-void arch_send_call_function_ipi_mask(const struct cpumask *mask)
-{
-	smp_cross_call(mask, IPI_CALL_FUNC);
-}
-
-void arch_send_wakeup_ipi_mask(const struct cpumask *mask)
-{
-	smp_cross_call(mask, IPI_WAKEUP);
-}
-
-void arch_send_call_function_single_ipi(int cpu)
-{
-	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+	if (!__smp_cross_call)
+		__smp_cross_call = fn;
 }
 
-#ifdef CONFIG_IRQ_WORK
-void arch_irq_work_raise(void)
-{
-	if (is_smp())
-		smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
-}
-#endif
-
-static const char *ipi_types[NR_IPI] = {
+static const char *ipi_types[NR_IPI] __tracepoint_string = {
 #define S(x,s)	[x] = s
 	S(IPI_WAKEUP, "CPU wakeup interrupts"),
 	S(IPI_TIMER, "Timer broadcast interrupts"),
@@ -473,6 +453,12 @@ static const char *ipi_types[NR_IPI] = {
 	S(IPI_COMPLETION, "completion interrupts"),
 };
 
+static void smp_cross_call(const struct cpumask *target, unsigned int ipinr)
+{
+	trace_ipi_raise(target, ipi_types[ipinr]);
+	__smp_cross_call(target, ipinr);
+}
+
 void show_ipi_list(struct seq_file *p, int prec)
 {
 	unsigned int cpu, i;
@@ -499,6 +485,29 @@ u64 smp_irq_stat_cpu(unsigned int cpu)
 	return sum;
 }
 
+void arch_send_call_function_ipi_mask(const struct cpumask *mask)
+{
+	smp_cross_call(mask, IPI_CALL_FUNC);
+}
+
+void arch_send_wakeup_ipi_mask(const struct cpumask *mask)
+{
+	smp_cross_call(mask, IPI_WAKEUP);
+}
+
+void arch_send_call_function_single_ipi(int cpu)
+{
+	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+}
+
+#ifdef CONFIG_IRQ_WORK
+void arch_irq_work_raise(void)
+{
+	if (is_smp())
+		smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
+}
+#endif
+
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 void tick_broadcast(const struct cpumask *mask)
 {
@@ -556,8 +565,10 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 	unsigned int cpu = smp_processor_id();
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	if (ipinr < NR_IPI)
+	if ((unsigned)ipinr < NR_IPI) {
+		trace_ipi_entry(ipi_types[ipinr]);
 		__inc_irq_stat(cpu, ipi_irqs[ipinr]);
+	}
 
 	switch (ipinr) {
 	case IPI_WAKEUP:
@@ -612,6 +623,9 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		       cpu, ipinr);
 		break;
 	}
+
+	if ((unsigned)ipinr < NR_IPI)
+		trace_ipi_exit(ipi_types[ipinr]);
 	set_irq_regs(old_regs);
 }
 

commit 0b443ead714f0cba797a7f2476dd756f22b5421e
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Wed Mar 19 11:24:58 2014 +0530

    cpufreq: remove unused notifier: CPUFREQ_{SUSPENDCHANGE|RESUMECHANGE}
    
    Two cpufreq notifiers CPUFREQ_RESUMECHANGE and CPUFREQ_SUSPENDCHANGE have
    not been used for some time, so remove them to clean up code a bit.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Reviewed-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    [rjw: Changelog]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b7b4c86e338b..7c4fada440f0 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -674,8 +674,7 @@ static int cpufreq_callback(struct notifier_block *nb,
 	}
 
 	if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
-	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new) ||
-	    (val == CPUFREQ_RESUMECHANGE || val == CPUFREQ_SUSPENDCHANGE)) {
+	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new)) {
 		loops_per_jiffy = cpufreq_scale(global_l_p_j_ref,
 						global_l_p_j_ref_freq,
 						freq->new);

commit 668bc38669f9a6d5e91846e9435b22b196cee9d1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jan 11 11:25:37 2014 +0000

    ARM: SMP implementations are not supposed to return from smp_ops.cpu_die()
    
    Although we allow recovery in this case, this is not supposed to be
    the normal path for hotplugging a CPU back in.  This path only exists
    to serve those rare platforms where it's not possible to power down
    the CPU or reset the CPU.  This patch causes the kernel to print a
    message when a platform uses this path.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c61325b8bfc..b7b4c86e338b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -293,6 +293,9 @@ void __ref cpu_die(void)
 	if (smp_ops.cpu_die)
 		smp_ops.cpu_die(cpu);
 
+	pr_warn("CPU%u: smp_ops.cpu_die() returned, trying to resuscitate\n",
+		cpu);
+
 	/*
 	 * Do not return to the idle loop - jump back to the secondary
 	 * cpu initialisation.  There's some initialisation which needs

commit efcfc46e8a654c3dddb51a6c4f46cd818dd926cc
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Mon Dec 9 16:10:18 2013 +0100

    ARM: 7918/1: clean up cache handling in core code
    
    We have a handy macro to replace open coded __cpuc_flush_dcache_area(()
    and outer_clean_range() sequences. Let's use it. No functional change.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index dc894ab3622b..8c61325b8bfc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -105,8 +105,7 @@ int __cpu_up(unsigned int cpu, struct task_struct *idle)
 	secondary_data.pgdir = get_arch_pgd(idmap_pgd);
 	secondary_data.swapper_pg_dir = get_arch_pgd(swapper_pg_dir);
 #endif
-	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
-	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
+	sync_cache_w(&secondary_data);
 
 	/*
 	 * Now bring the CPU into our world.

commit df762eccbadf87850fbee444d729e0f1b1e946f1
Merge: ec1e20a02fe3 70d42126877b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Nov 12 10:58:59 2013 +0000

    Merge branch 'devel-stable' into for-next
    
    Conflicts:
            arch/arm/include/asm/atomic.h
            arch/arm/include/asm/hardirq.h
            arch/arm/kernel/smp.c

commit c682e51dbc9837f4aa61180775e9ca4f2a463adf
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Sat Nov 9 00:38:24 2013 +0100

    ARM: 7887/1: Don't smp_cross_call() on UP devices in arch_irq_work_raise()
    
    If we're running a kernel compiled with SMP_ON_UP=y and the
    hardware only supports UP operation there isn't any
    smp_cross_call function assigned. Unfortunately, we call
    smp_cross_call() unconditionally in arch_irq_work_raise() and
    crash the kernel on UP devices. Check to make sure we're running
    on an SMP device before calling smp_cross_call() here.
    
    Unable to handle kernel NULL pointer dereference at virtual address 00000000
    pgd = c0004000
    [00000000] *pgd=00000000
    Internal error: Oops: 80000005 [#1] SMP ARM
    Modules linked in:
    CPU: 0 PID: 1 Comm: swapper/0 Not tainted 3.12.0-rc6-00018-g8d45144-dirty #16
    task: de05b440 ti: de05c000 task.ti: de05c000
    PC is at 0x0
    LR is at arch_irq_work_raise+0x3c/0x48
    pc : [<00000000>]    lr : [<c0019590>]    psr: 60000193
    sp : de05dd60  ip : 00000001  fp : 00000000
    r10: c085e2f0  r9 : de05c000  r8 : c07be0a4
    r7 : de05c000  r6 : de05c000  r5 : c07c5778  r4 : c0824554
    r3 : 00000000  r2 : 00000000  r1 : 00000006  r0 : c0529a58
    Flags: nZCv  IRQs off  FIQs on  Mode SVC_32  ISA ARM Segment kernel
    Control: 10c5387d  Table: 80004019  DAC: 00000017
    Process swapper/0 (pid: 1, stack limit = 0xde05c248)
    Stack: (0xde05dd60 to 0xde05e000)
    dd60: c07b9dbc c00cb2dc 00000001 c08242c0 c08242c0 60000113 c07be0a8 c00b0590
    dd80: de05c000 c085e2f0 c08242c0 c08242c0 c1414c28 c00b07cc de05b440 c1414c28
    dda0: c08242c0 c00b0af8 c0862bb0 c0862db0 c1414cd8 de05c028 c0824840 de05ddb8
    ddc0: 00000000 00000009 00000001 00000024 c07be0a8 c07be0a4 de05c000 c085e2f0
    dde0: 00000000 c004a4b0 00000010 de00d2dc 00000054 00000100 00000024 00000000
    de00: de05c028 0000000a ffff8ae7 00200040 00000016 de05c000 60000193 de05c000
    de20: 00000054 00000000 00000000 00000000 00000000 c004a704 00000000 de05c008
    de40: c07ba254 c004aa1c c07c5778 c0014b70 fa200000 00000054 de05de80 c0861244
    de60: 00000000 c0008634 de05b440 c051c778 20000113 ffffffff de05deb4 c051d0a4
    de80: 00000001 00000001 00000000 de05b440 c082afac de057ac0 de057ac0 de0443c0
    dea0: 00000000 00000000 00000000 00000000 c082afbc de05dec8 c009f2a0 c051c778
    dec0: 20000113 ffffffff 00000000 c016edb0 00000000 000002b0 de057ac0 de057ac0
    dee0: 00000000 c016ee40 c0875e50 de05df2e de057ac0 00000000 00000013 00000000
    df00: 00000000 c016f054 de043600 de0443c0 c008eb38 de004ec0 c0875e50 c008eb44
    df20: 00000012 00000000 00000000 3931f0f8 00000000 00000000 00000014 c0822e84
    df40: 00000000 c008ed2c 00000000 00000000 00000000 c07b7490 c07b7490 c075ab3c
    df60: 00000000 c00701ac 00000002 00000000 c0070160 dffadb73 7bf8edb4 00000000
    df80: c051092c 00000000 00000000 00000000 00000000 00000000 00000000 c0510934
    dfa0: de05aa40 00000000 c051092c c0013ce8 00000000 00000000 00000000 00000000
    dfc0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
    dfe0: 00000000 00000000 00000000 00000000 00000013 00000000 07efffe5 4dfac6f5
    [<c0019590>] (arch_irq_work_raise+0x3c/0x48) from [<c00cb2dc>] (irq_work_queue+0xe4/0xf8)
    [<c00cb2dc>] (irq_work_queue+0xe4/0xf8) from [<c00b0590>] (rcu_accelerate_cbs+0x1d4/0x1d8)
    [<c00b0590>] (rcu_accelerate_cbs+0x1d4/0x1d8) from [<c00b07cc>] (rcu_start_gp+0x34/0x48)
    [<c00b07cc>] (rcu_start_gp+0x34/0x48) from [<c00b0af8>] (rcu_process_callbacks+0x318/0x608)
    [<c00b0af8>] (rcu_process_callbacks+0x318/0x608) from [<c004a4b0>] (__do_softirq+0x114/0x2a0)
    [<c004a4b0>] (__do_softirq+0x114/0x2a0) from [<c004a704>] (do_softirq+0x6c/0x74)
    [<c004a704>] (do_softirq+0x6c/0x74) from [<c004aa1c>] (irq_exit+0xac/0x100)
    [<c004aa1c>] (irq_exit+0xac/0x100) from [<c0014b70>] (handle_IRQ+0x54/0xb4)
    [<c0014b70>] (handle_IRQ+0x54/0xb4) from [<c0008634>] (omap3_intc_handle_irq+0x60/0x74)
    [<c0008634>] (omap3_intc_handle_irq+0x60/0x74) from [<c051d0a4>] (__irq_svc+0x44/0x5c)
    Exception stack(0xde05de80 to 0xde05dec8)
    de80: 00000001 00000001 00000000 de05b440 c082afac de057ac0 de057ac0 de0443c0
    dea0: 00000000 00000000 00000000 00000000 c082afbc de05dec8 c009f2a0 c051c778
    dec0: 20000113 ffffffff
    [<c051d0a4>] (__irq_svc+0x44/0x5c) from [<c051c778>] (_raw_spin_unlock_irq+0x28/0x2c)
    [<c051c778>] (_raw_spin_unlock_irq+0x28/0x2c) from [<c016edb0>] (proc_alloc_inum+0x30/0xa8)
    [<c016edb0>] (proc_alloc_inum+0x30/0xa8) from [<c016ee40>] (proc_register+0x18/0x130)
    [<c016ee40>] (proc_register+0x18/0x130) from [<c016f054>] (proc_mkdir_data+0x44/0x6c)
    [<c016f054>] (proc_mkdir_data+0x44/0x6c) from [<c008eb44>] (register_irq_proc+0x6c/0x128)
    [<c008eb44>] (register_irq_proc+0x6c/0x128) from [<c008ed2c>] (init_irq_proc+0x74/0xb0)
    [<c008ed2c>] (init_irq_proc+0x74/0xb0) from [<c075ab3c>] (kernel_init_freeable+0x84/0x1c8)
    [<c075ab3c>] (kernel_init_freeable+0x84/0x1c8) from [<c0510934>] (kernel_init+0x8/0x150)
    [<c0510934>] (kernel_init+0x8/0x150) from [<c0013ce8>] (ret_from_fork+0x14/0x2c)
    Code: bad PC value
    
    Fixes: bf18525fd79 "ARM: 7872/1: Support arch_irq_work_raise() via self IPIs"
    
    Reported-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Tested-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index bf9a0d6d91dc..e115cbb0d25a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -453,7 +453,8 @@ void arch_send_call_function_single_ipi(int cpu)
 #ifdef CONFIG_IRQ_WORK
 void arch_irq_work_raise(void)
 {
-	smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
+	if (is_smp())
+		smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
 }
 #endif
 

commit bf18525fd793101df42a1344ecc48b49b62e48c9
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Tue Oct 29 20:32:56 2013 +0100

    ARM: 7872/1: Support arch_irq_work_raise() via self IPIs
    
    By default, IRQ work is run from the tick interrupt (see
    irq_work_run() in update_process_times()). When we're in full
    NOHZ mode, restarting the tick requires the use of IRQ work and
    if the only place we run IRQ work is in the tick interrupt we
    have an unbreakable cycle. Implement arch_irq_work_raise() via
    self IPIs to break this cycle and get the tick started again.
    Note that we implement this via IPIs which are only available on
    SMP builds. This shouldn't be a problem because full NOHZ is only
    supported on SMP builds anyway.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Reviewed-by: Kevin Hilman <khilman@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 72024ea8a3a6..bf9a0d6d91dc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -25,6 +25,7 @@
 #include <linux/clockchips.h>
 #include <linux/completion.h>
 #include <linux/cpufreq.h>
+#include <linux/irq_work.h>
 
 #include <linux/atomic.h>
 #include <asm/smp.h>
@@ -66,6 +67,7 @@ enum ipi_msg_type {
 	IPI_CALL_FUNC,
 	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
+	IPI_IRQ_WORK,
 };
 
 static DECLARE_COMPLETION(cpu_running);
@@ -448,6 +450,13 @@ void arch_send_call_function_single_ipi(int cpu)
 	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
+#ifdef CONFIG_IRQ_WORK
+void arch_irq_work_raise(void)
+{
+	smp_cross_call(cpumask_of(smp_processor_id()), IPI_IRQ_WORK);
+}
+#endif
+
 static const char *ipi_types[NR_IPI] = {
 #define S(x,s)	[x] = s
 	S(IPI_WAKEUP, "CPU wakeup interrupts"),
@@ -456,6 +465,7 @@ static const char *ipi_types[NR_IPI] = {
 	S(IPI_CALL_FUNC, "Function call interrupts"),
 	S(IPI_CALL_FUNC_SINGLE, "Single function call interrupts"),
 	S(IPI_CPU_STOP, "CPU stop interrupts"),
+	S(IPI_IRQ_WORK, "IRQ work interrupts"),
 };
 
 void show_ipi_list(struct seq_file *p, int prec)
@@ -565,6 +575,14 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		irq_exit();
 		break;
 
+#ifdef CONFIG_IRQ_WORK
+	case IPI_IRQ_WORK:
+		irq_enter();
+		irq_work_run();
+		irq_exit();
+		break;
+#endif
+
 	default:
 		printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
 		       cpu, ipinr);

commit 8754c4bf2ac1a64d5c1409a0ae98e21a8f3541c5
Merge: 75c912a367fb a77e0c7b2774
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 15 14:12:24 2013 +0100

    Merge branch 'for-rmk/arm-mm-lpae' of git://git.kernel.org/pub/scm/linux/kernel/git/ssantosh/linux-keystone into devel-stable
    
    This series extends the existing ARM v2p runtime patching for 64 bit.
    Needed for LPAE machines which have physical memory beyond 4GB.

commit 4dc9a81715973cb137a14399420bb35b0ed7d6ef
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Wed Jul 31 12:44:42 2013 -0400

    ARM: mm: Introduce virt_to_idmap() with an arch hook
    
    On some PAE systems (e.g. TI Keystone), memory is above the
    32-bit addressable limit, and the interconnect provides an
    aliased view of parts of physical memory in the 32-bit addressable
    space.  This alias is strictly for boot time usage, and is not
    otherwise usable because of coherency limitations. On such systems,
    the idmap mechanism needs to take this aliased mapping into account.
    
    This patch introduces virt_to_idmap() and a arch function pointer which
    can be populated by platform which needs it. Also populate necessary
    idmap spots with now available virt_to_idmap(). Avoided #ifdef approach
    to be compatible with multi-platform builds.
    
    Most architecture won't touch it and in that case virt_to_idmap()
    fall-back to existing virt_to_phys() macro.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 72024ea8a3a6..a0eb830c3daf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -80,7 +80,7 @@ void __init smp_set_ops(struct smp_operations *ops)
 
 static unsigned long get_arch_pgd(pgd_t *pgd)
 {
-	phys_addr_t pgdir = virt_to_phys(pgd);
+	phys_addr_t pgdir = virt_to_idmap(pgd);
 	BUG_ON(pgdir & ARCH_PGD_MASK);
 	return pgdir >> ARCH_PGD_SHIFT;
 }

commit 5135d875e1457ef946a055003d8f80713e862135
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Tue Nov 27 21:54:41 2012 -0500

    ARM: SMP: basic IPI triggered completion support
    
    We need a mechanism to let an inbound CPU signal that it is alive before
    even getting into the kernel environment i.e. from early assembly code.
    Using an IPI is the simplest way to achieve that.
    
    This adds some basic infrastructure to register a struct completion
    pointer to be "completed" when the dedicated IPI for this task is
    received.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 72024ea8a3a6..7d80a549cae5 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -66,6 +66,7 @@ enum ipi_msg_type {
 	IPI_CALL_FUNC,
 	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
+	IPI_COMPLETION,
 };
 
 static DECLARE_COMPLETION(cpu_running);
@@ -456,6 +457,7 @@ static const char *ipi_types[NR_IPI] = {
 	S(IPI_CALL_FUNC, "Function call interrupts"),
 	S(IPI_CALL_FUNC_SINGLE, "Single function call interrupts"),
 	S(IPI_CPU_STOP, "CPU stop interrupts"),
+	S(IPI_COMPLETION, "completion interrupts"),
 };
 
 void show_ipi_list(struct seq_file *p, int prec)
@@ -515,6 +517,19 @@ static void ipi_cpu_stop(unsigned int cpu)
 		cpu_relax();
 }
 
+static DEFINE_PER_CPU(struct completion *, cpu_completion);
+
+int register_ipi_completion(struct completion *completion, int cpu)
+{
+	per_cpu(cpu_completion, cpu) = completion;
+	return IPI_COMPLETION;
+}
+
+static void ipi_complete(unsigned int cpu)
+{
+	complete(per_cpu(cpu_completion, cpu));
+}
+
 /*
  * Main handler for inter-processor interrupts
  */
@@ -565,6 +580,12 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		irq_exit();
 		break;
 
+	case IPI_COMPLETION:
+		irq_enter();
+		ipi_complete(cpu);
+		irq_exit();
+		break;
+
 	default:
 		printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
 		       cpu, ipinr);

commit 8e73e367f7dc50f1d1bc22a63e5764bb4eea9b48
Merge: d2f3e9eb7c9e 7323f219533e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 6 13:21:16 2013 -0700

    Merge tag 'cleanup-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull ARM SoC cleanups from Olof Johansson:
     "This branch contains code cleanups, moves and removals for 3.12.
    
      There's a large number of various cleanups, and a nice net removal of
      13500 lines of code.
    
      Highlights worth mentioning are:
    
       - A series of patches from Stephen Boyd removing the ARM local timer
         API.
       - Move of Qualcomm MSM IOMMU code to drivers/iommu.
       - Samsung PWM driver cleanups from Tomasz Figa, removing legacy PWM
         driver and switching over to the drivers/pwm one.
       - Removal of some unusued auto-generated headers for OMAP2+ (PRM/CM).
    
      There's also a move of a header file out of include/linux/i2c/ to
      platform_data, where it really belongs.  It touches mostly ARM
      platform code for include changes so we took it through our tree"
    
    * tag 'cleanup-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (83 commits)
      ARM: OMAP2+: Add back the define for AM33XX_RST_GLOBAL_WARM_SW_MASK
      gpio: (gpio-pca953x) move header to linux/platform_data/
      arm: zynq: hotplug: Remove unreachable code
      ARM: SAMSUNG: Remove unnecessary exynos4_default_sdhci*()
      tegra: simplify use of devm_ioremap_resource
      ARM: SAMSUNG: Remove plat/regs-timer.h header
      ARM: SAMSUNG: Remove remaining uses of plat/regs-timer.h header
      ARM: SAMSUNG: Remove pwm-clock infrastructure
      ARM: SAMSUNG: Remove old PWM timer platform devices
      pwm: Remove superseded pwm-samsung-legacy driver
      ARM: SAMSUNG: Modify board files to use new PWM platform device
      ARM: SAMSUNG: Rework private data handling in dev-backlight
      pwm: Add new pwm-samsung driver
      ARM: mach-mvebu: remove redundant DT parsing and validation
      ARM: msm: Only compile io.c on platforms that use it
      iommu/msm: Move mach includes to iommu directory
      ARM: msm: Remove devices-iommu.c
      ARM: msm: Move mach/board.h contents to common.h
      ARM: msm: Migrate msm_timer to CLOCKSOURCE_OF_DECLARE
      ARM: msm: Remove TMR and TMR0 static mappings
      ...

commit 141b97433d77e39ac3ac111a7b3852192035259c
Merge: d8dfad3876e4 8d258beb76e3 5cc91e046088 9fc2105aeaaf
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Sep 5 10:34:15 2013 +0100

    Merge branches 'debug-choice', 'devel-stable' and 'misc' into for-linus

commit 9fc2105aeaaf56b0cf75296a84702d0f9e64437b
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Aug 30 18:10:16 2013 +0100

    ARM: 7830/1: delay: don't bother reporting bogomips in /proc/cpuinfo
    
    Now that we support a timer-backed delay loop, I'm quickly getting sick
    and tired of people complaining that their beloved bogomips value has
    decreased. You know who you are!
    
    This patch removes the bogomips line from /proc/cpuinfo, based on the
    reasoning that any program parsing this is already broken and, as such,
    won't be further broken if the field is removed.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index c2b4f8f0be9a..89f0e5ed2e4d 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -388,17 +388,8 @@ asmlinkage void secondary_start_kernel(void)
 
 void __init smp_cpus_done(unsigned int max_cpus)
 {
-	int cpu;
-	unsigned long bogosum = 0;
-
-	for_each_online_cpu(cpu)
-		bogosum += per_cpu(cpu_data, cpu).loops_per_jiffy;
-
-	printk(KERN_INFO "SMP: Total of %d processors activated "
-	       "(%lu.%02lu BogoMIPS).\n",
-	       num_online_cpus(),
-	       bogosum / (500000/HZ),
-	       (bogosum / (5000/HZ)) % 100);
+	printk(KERN_INFO "SMP: Total of %d processors activated.\n",
+	       num_online_cpus());
 
 	hyp_mode_check();
 }

commit 2103f6cba61a8b8bea3fc1b63661d830a2125e76
Author: Stephen Warren <swarren@nvidia.com>
Date:   Fri Aug 2 20:52:49 2013 +0100

    ARM: 7807/1: kexec: validate CPU hotplug support
    
    Architectures should fully validate whether kexec is possible as part of
    machine_kexec_prepare(), so that user-space's kexec_load() operation can
    report any problems. Performing validation in machine_kexec() itself is
    too late, since it is not allowed to return.
    
    Prior to this patch, ARM's machine_kexec() was testing after-the-fact
    whether machine_kexec_prepare() was able to disable all but one CPU.
    Instead, modify machine_kexec_prepare() to validate all conditions
    necessary for machine_kexec_prepare()'s to succeed. BUG if the validation
    succeeded, yet disabling the CPUs didn't actually work.
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index c2b4f8f0be9a..2dc19349eb19 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -145,6 +145,16 @@ int boot_secondary(unsigned int cpu, struct task_struct *idle)
 	return -ENOSYS;
 }
 
+int platform_can_cpu_hotplug(void)
+{
+#ifdef CONFIG_HOTPLUG_CPU
+	if (smp_ops.cpu_kill)
+		return 1;
+#endif
+
+	return 0;
+}
+
 #ifdef CONFIG_HOTPLUG_CPU
 static void percpu_timer_stop(void);
 

commit 47dcd3563e45fc5a59bf7f3326ef56087be8bebe
Merge: 3b2f64d00c46 060fd3043e5e
Author: Olof Johansson <olof@lixom.net>
Date:   Tue Jul 23 14:51:34 2013 -0700

    Merge tag 'remove-local-timers' of git://git.kernel.org/pub/scm/linux/kernel/git/davidb/linux-msm into next/cleanup
    
    From Stephen Boyd:
    
    Now that we have a generic arch hook for broadcast we can remove the
    local timer API entirely. Doing so will reduce code in ARM core, reduce
    the architecture dependencies of our timer drivers, and simplify the code
    because we no longer go through an architecture layer that is essentially
    a hotplug notifier.
    
    * tag 'remove-local-timers' of git://git.kernel.org/pub/scm/linux/kernel/git/davidb/linux-msm:
      ARM: smp: Remove local timer API
      clocksource: time-armada-370-xp: Divorce from local timer API
      clocksource: time-armada-370-xp: Fix sparse warning
      ARM: msm: Divorce msm_timer from local timer API
      ARM: PRIMA2: Divorce timer-marco from local timer API
      ARM: EXYNOS4: Divorce mct from local timer API
      ARM: OMAP2+: Divorce from local timer API
      ARM: smp_twd: Divorce smp_twd from local timer API
      ARM: smp: Remove duplicate dummy timer implementation
    
    Resolved a large number of conflicts due to __cpuinit cleanups, etc.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>

commit 8bd26e3a7e49af2697449bbcb7187a39dc85d672
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jun 17 15:43:14 2013 -0400

    arm: delete __cpuinit/__CPUINIT usage from all ARM users
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    and are flagged as __cpuinit  -- so if we remove the __cpuinit from
    the arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    related content into no-ops as early as possible, since that will get
    rid of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the ARM uses of the __cpuinit macros from C code,
    and all __CPUINIT from assembly code.  It also had two ".previous"
    section statements that were paired off against __CPUINIT
    (aka .section ".cpuinit.text") that also get removed here.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index c5fb5469054b..c2b4f8f0be9a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -58,7 +58,7 @@ struct secondary_data secondary_data;
  * control for which core is the next to come out of the secondary
  * boot "holding pen"
  */
-volatile int __cpuinitdata pen_release = -1;
+volatile int pen_release = -1;
 
 enum ipi_msg_type {
 	IPI_WAKEUP,
@@ -86,7 +86,7 @@ static unsigned long get_arch_pgd(pgd_t *pgd)
 	return pgdir >> ARCH_PGD_SHIFT;
 }
 
-int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
+int __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
 	int ret;
 
@@ -138,7 +138,7 @@ void __init smp_init_cpus(void)
 		smp_ops.smp_init_cpus();
 }
 
-int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
+int boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
 	if (smp_ops.smp_boot_secondary)
 		return smp_ops.smp_boot_secondary(cpu, idle);
@@ -170,7 +170,7 @@ static int platform_cpu_disable(unsigned int cpu)
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */
-int __cpuinit __cpu_disable(void)
+int __cpu_disable(void)
 {
 	unsigned int cpu = smp_processor_id();
 	int ret;
@@ -216,7 +216,7 @@ static DECLARE_COMPLETION(cpu_died);
  * called on the thread which is asking for a CPU to be shutdown -
  * waits until shutdown has completed, or it is timed out.
  */
-void __cpuinit __cpu_die(unsigned int cpu)
+void __cpu_die(unsigned int cpu)
 {
 	if (!wait_for_completion_timeout(&cpu_died, msecs_to_jiffies(5000))) {
 		pr_err("CPU%u: cpu didn't die\n", cpu);
@@ -306,7 +306,7 @@ void __ref cpu_die(void)
  * Called by both boot and secondaries to move global data into
  * per-processor storage.
  */
-static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
+static void smp_store_cpu_info(unsigned int cpuid)
 {
 	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
 
@@ -322,7 +322,7 @@ static void percpu_timer_setup(void);
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.
  */
-asmlinkage void __cpuinit secondary_start_kernel(void)
+asmlinkage void secondary_start_kernel(void)
 {
 	struct mm_struct *mm = &init_mm;
 	unsigned int cpu;
@@ -521,7 +521,7 @@ static void broadcast_timer_set_mode(enum clock_event_mode mode,
 {
 }
 
-static void __cpuinit broadcast_timer_setup(struct clock_event_device *evt)
+static void broadcast_timer_setup(struct clock_event_device *evt)
 {
 	evt->name	= "dummy_timer";
 	evt->features	= CLOCK_EVT_FEAT_ONESHOT |
@@ -550,7 +550,7 @@ int local_timer_register(struct local_timer_ops *ops)
 }
 #endif
 
-static void __cpuinit percpu_timer_setup(void)
+static void percpu_timer_setup(void)
 {
 	unsigned int cpu = smp_processor_id();
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);

commit 3c0c01ab742ddfaf6b6f2d64b890e77cda4b7727
Merge: cbd379b10019 809e660f438f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jun 29 11:44:43 2013 +0100

    Merge branch 'devel-stable' into for-next
    
    Conflicts:
            arch/arm/Makefile
            arch/arm/include/asm/glue-proc.h

commit 060fd3043e5e3488504b9e70182e188dd9113aea
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Fri Feb 15 17:35:19 2013 -0800

    ARM: smp: Remove local timer API
    
    There are no more users of this API, remove it.
    
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 4dc883a77adc..54aa994c4b20 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -41,7 +41,6 @@
 #include <asm/sections.h>
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
-#include <asm/localtimer.h>
 #include <asm/smp_plat.h>
 #include <asm/virt.h>
 #include <asm/mach/arch.h>
@@ -133,8 +132,6 @@ int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
-static void percpu_timer_stop(void);
-
 static int platform_cpu_kill(unsigned int cpu)
 {
 	if (smp_ops.cpu_kill)
@@ -177,11 +174,6 @@ int __cpuinit __cpu_disable(void)
 	 */
 	migrate_irqs();
 
-	/*
-	 * Stop the local timer for this CPU.
-	 */
-	percpu_timer_stop();
-
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU
 	 * from the vm mask set of all processes.
@@ -303,8 +295,6 @@ static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
 	store_cpu_topology(cpuid);
 }
 
-static void percpu_timer_setup(void);
-
 /*
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.
@@ -359,11 +349,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	set_cpu_online(cpu, true);
 	complete(&cpu_running);
 
-	/*
-	 * Setup the percpu timer for this CPU.
-	 */
-	percpu_timer_setup();
-
 	local_irq_enable();
 	local_fiq_enable();
 
@@ -409,12 +394,6 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 	if (max_cpus > ncores)
 		max_cpus = ncores;
 	if (ncores > 1 && max_cpus) {
-		/*
-		 * Enable the local timer or broadcast device for the
-		 * boot CPU, but only if we have more than one CPU.
-		 */
-		percpu_timer_setup();
-
 		/*
 		 * Initialise the present map, which describes the set of CPUs
 		 * actually populated at the present time. A platform should
@@ -491,11 +470,6 @@ u64 smp_irq_stat_cpu(unsigned int cpu)
 	return sum;
 }
 
-/*
- * Timer (local or broadcast) support
- */
-static DEFINE_PER_CPU(struct clock_event_device, percpu_clockevent);
-
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 void tick_broadcast(const struct cpumask *mask)
 {
@@ -503,49 +477,6 @@ void tick_broadcast(const struct cpumask *mask)
 }
 #endif
 
-static struct local_timer_ops *lt_ops;
-
-#ifdef CONFIG_LOCAL_TIMERS
-int local_timer_register(struct local_timer_ops *ops)
-{
-	if (!is_smp() || !setup_max_cpus)
-		return -ENXIO;
-
-	if (lt_ops)
-		return -EBUSY;
-
-	lt_ops = ops;
-	return 0;
-}
-#endif
-
-static void __cpuinit percpu_timer_setup(void)
-{
-	unsigned int cpu = smp_processor_id();
-	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
-
-	evt->cpumask = cpumask_of(cpu);
-
-	if (lt_ops)
-		lt_ops->setup(evt);
-}
-
-#ifdef CONFIG_HOTPLUG_CPU
-/*
- * The generic clock events code purposely does not stop the local timer
- * on CPU_DEAD/CPU_DEAD_FROZEN hotplug events, so we have to do it
- * manually here.
- */
-static void percpu_timer_stop(void)
-{
-	unsigned int cpu = smp_processor_id();
-	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
-
-	if (lt_ops)
-		lt_ops->stop(evt);
-}
-#endif
-
 static DEFINE_RAW_SPINLOCK(stop_lock);
 
 /*

commit 3d53ceeca7bae807e5aba0935347f3757127a821
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Mon Mar 4 17:15:19 2013 -0800

    ARM: smp: Remove duplicate dummy timer implementation
    
    Drop ARM's version of the dummy timer now that we have a generic
    implementation in drivers/clocksource.
    
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 47ab90563bf4..4dc883a77adc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -503,24 +503,6 @@ void tick_broadcast(const struct cpumask *mask)
 }
 #endif
 
-static void broadcast_timer_set_mode(enum clock_event_mode mode,
-	struct clock_event_device *evt)
-{
-}
-
-static void __cpuinit broadcast_timer_setup(struct clock_event_device *evt)
-{
-	evt->name	= "dummy_timer";
-	evt->features	= CLOCK_EVT_FEAT_ONESHOT |
-			  CLOCK_EVT_FEAT_PERIODIC |
-			  CLOCK_EVT_FEAT_DUMMY;
-	evt->rating	= 100;
-	evt->mult	= 1;
-	evt->set_mode	= broadcast_timer_set_mode;
-
-	clockevents_register_device(evt);
-}
-
 static struct local_timer_ops *lt_ops;
 
 #ifdef CONFIG_LOCAL_TIMERS
@@ -544,8 +526,8 @@ static void __cpuinit percpu_timer_setup(void)
 
 	evt->cpumask = cpumask_of(cpu);
 
-	if (!lt_ops || lt_ops->setup(evt))
-		broadcast_timer_setup(evt);
+	if (lt_ops)
+		lt_ops->setup(evt);
 }
 
 #ifdef CONFIG_HOTPLUG_CPU

commit 3fbd55ec21e698221ffb43526090137b07c32586
Merge: b3f288de7c8a a469abd0f868
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jun 18 20:11:32 2013 +0100

    Merge branch 'for-rmk/lpae' of git://git.kernel.org/pub/scm/linux/kernel/git/will/linux into devel-stable
    
    Conflicts:
            arch/arm/kernel/smp.c
    
    Please pull these miscellaneous LPAE fixes I've been collecting for a while
    now for 3.11. They've been tested and reviewed by quite a few people, and most
    of the patches are pretty trivial. -- Will Deacon.

commit 19ab428f4b7988ef3ac727c680efc193ef53ce14
Author: Stephen Warren <swarren@nvidia.com>
Date:   Fri Jun 14 16:14:14 2013 +0100

    ARM: 7759/1: decouple CPU offlining from reboot/shutdown
    
    Add comments to machine_shutdown()/halt()/power_off()/restart() that
    describe their purpose and/or requirements re: CPUs being active/not.
    
    In machine_shutdown(), replace the call to smp_send_stop() with a call to
    disable_nonboot_cpus(). This completely disables all but one CPU, thus
    satisfying the requirement that only a single CPU be active for kexec.
    Adjust Kconfig dependencies for this change.
    
    In machine_halt()/power_off()/restart(), call smp_send_stop() directly,
    rather than via machine_shutdown(); these functions don't need to
    completely de-activate all CPUs using hotplug, but rather just quiesce
    them.
    
    Remove smp_kill_cpus(), and its call from smp_send_stop().
    smp_kill_cpus() was indirectly calling smp_ops.cpu_kill() without calling
    smp_ops.cpu_die() on the target CPUs first. At least some implementations
    of smp_ops had issues with this; it caused cpu_kill() to hang on Tegra,
    for example. Since smp_send_stop() is only used for shutdown, halt, and
    power-off, there is no need to attempt any kind of CPU hotplug here.
    
    Adjust Kconfig to reflect that machine_shutdown() (and hence kexec)
    relies upon disable_nonboot_cpus(). However, this alone doesn't guarantee
    that hotplug will work, or even that hotplug is implemented for a
    particular piece of HW that a multi-platform zImage runs on. Hence, add
    error-checking to machine_kexec() to determine whether it did work.
    
    Suggested-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Tested-by:  Zhangfei Gao <zhangfei.gao@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 550d63cef68e..5919eb451bb9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -651,17 +651,6 @@ void smp_send_reschedule(int cpu)
 	smp_cross_call(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
-#ifdef CONFIG_HOTPLUG_CPU
-static void smp_kill_cpus(cpumask_t *mask)
-{
-	unsigned int cpu;
-	for_each_cpu(cpu, mask)
-		platform_cpu_kill(cpu);
-}
-#else
-static void smp_kill_cpus(cpumask_t *mask) { }
-#endif
-
 void smp_send_stop(void)
 {
 	unsigned long timeout;
@@ -679,8 +668,6 @@ void smp_send_stop(void)
 
 	if (num_online_cpus() > 1)
 		pr_warning("SMP: failed to stop secondary CPUs\n");
-
-	smp_kill_cpus(&mask);
 }
 
 /*

commit eb08375ea66e63c5e11dea69b43c5633d531ce81
Author: Jonathan Austin <jonathan.austin@arm.com>
Date:   Fri Feb 22 18:51:30 2013 +0000

    ARM: mpu: add MPU initialisation for secondary cores
    
    The MPU initialisation on the primary core is performed in two stages, one
    minimal stage to ensure the CPU can boot and a second one after
    sanity_check_meminfo. As the memory configuration is known by the time we
    boot secondary cores only a single step is necessary, provided the values
    for DRSR are passed to secondaries.
    
    This patch implements this arrangement. The configuration generated for the
    MPU regions is made available to the secondary core, which can then use the
    asm MPU intialisation code to program a complete region configuration.
    
    This is necessary for SMP configurations without an MMU, as the MPU
    initialisation is the only way to ensure that memory is specified as
    'shared'.
    
    Signed-off-by: Jonathan Austin <jonathan.austin@arm.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    CC: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 44d1c00dc45f..e17d9346baee 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -45,6 +45,7 @@
 #include <asm/smp_plat.h>
 #include <asm/virt.h>
 #include <asm/mach/arch.h>
+#include <asm/mpu.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -87,6 +88,10 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 	 * its stack and the page tables.
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
+#ifdef CONFIG_ARM_MPU
+	secondary_data.mpu_rgn_szr = mpu_rgn_info.rgns[MPU_RAM_REGION].drsr;
+#endif
+
 #ifdef CONFIG_MMU
 	secondary_data.pgdir = virt_to_phys(idmap_pgd);
 	secondary_data.swapper_pg_dir = virt_to_phys(swapper_pg_dir);
@@ -114,9 +119,8 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 		pr_err("CPU%u: failed to boot: %d\n", cpu, ret);
 	}
 
-	secondary_data.stack = NULL;
-	secondary_data.pgdir = 0;
 
+	memset(&secondary_data, 0, sizeof(secondary_data));
 	return ret;
 }
 

commit c4a1f032ed35d744e3d74b8aebe8d85f29aecd88
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 28 13:02:59 2012 +0000

    ARM: nommu: do not initialise page tables in secondary_data structure
    
    nommu systems do not require any page tables, so don't try to initialise
    them when bringing up secondary cores.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 550d63cef68e..44d1c00dc45f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -87,8 +87,10 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 	 * its stack and the page tables.
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
+#ifdef CONFIG_MMU
 	secondary_data.pgdir = virt_to_phys(idmap_pgd);
 	secondary_data.swapper_pg_dir = virt_to_phys(swapper_pg_dir);
+#endif
 	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
 	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
 

commit 4756dcbfd37819a8359d3c69a22be2ee41666d0f
Author: Cyril Chemparathy <cyril@ti.com>
Date:   Sat Jul 21 15:55:04 2012 -0400

    ARM: LPAE: accomodate >32-bit addresses for page table base
    
    This patch redefines the early boot time use of the R4 register to steal a few
    low order bits (ARCH_PGD_SHIFT bits) on LPAE systems.  This allows for up to
    38-bit physical addresses.
    
    Signed-off-by: Cyril Chemparathy <cyril@ti.com>
    Signed-off-by: Vitaly Andrianov <vitalya@ti.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Subash Patel <subash.rp@samsung.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 550d63cef68e..217b755aadd4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -78,6 +78,13 @@ void __init smp_set_ops(struct smp_operations *ops)
 		smp_ops = *ops;
 };
 
+static unsigned long get_arch_pgd(pgd_t *pgd)
+{
+	phys_addr_t pgdir = virt_to_phys(pgd);
+	BUG_ON(pgdir & ARCH_PGD_MASK);
+	return pgdir >> ARCH_PGD_SHIFT;
+}
+
 int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
 	int ret;
@@ -87,8 +94,8 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 	 * its stack and the page tables.
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
-	secondary_data.pgdir = virt_to_phys(idmap_pgd);
-	secondary_data.swapper_pg_dir = virt_to_phys(swapper_pg_dir);
+	secondary_data.pgdir = get_arch_pgd(idmap_pgd);
+	secondary_data.swapper_pg_dir = get_arch_pgd(swapper_pg_dir);
 	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
 	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
 

commit aa033810461ee56abbef6cef10aabd6b97f5caee
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Mon May 20 17:57:16 2013 -0700

    ARM: smp: Drop RCU_NONIDLE usage in cpu_die()
    
    Before f7b861b7a6d9 ("arm: Use generic idle loop") ARM would kill the
    CPU within the rcu idle section.  Now that the rcu_idle_enter()/exit()
    pair have been pushed lower down in the idle loop this is no longer true
    and so using RCU_NONIDLE here is no longer necessary and also harmful
    because RCU is not actually idle at this point.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 47ab90563bf4..550d63cef68e 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -251,7 +251,7 @@ void __ref cpu_die(void)
 	 * this returns, power and/or clocks can be removed at any point
 	 * from this CPU and its cache by platform_cpu_kill().
 	 */
-	RCU_NONIDLE(complete(&cpu_died));
+	complete(&cpu_died);
 
 	/*
 	 * Ensure that the cache lines associated with that completion are

commit 8546dc1d4b671480961c3eaf4c0c102ae6848340
Merge: 9992ba72327f 33b9f582c5c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 3 09:13:19 2013 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "The major items included in here are:
    
       - MCPM, multi-cluster power management, part of the infrastructure
         required for ARMs big.LITTLE support.
    
       - A rework of the ARM KVM code to allow re-use by ARM64.
    
       - Error handling cleanups of the IS_ERR_OR_NULL() madness and fixes
         of that stuff for arch/arm
    
       - Preparatory patches for Cortex-M3 support from Uwe Kleine-König.
    
      There is also a set of three patches in here from Hugh/Catalin to
      address freeing of inappropriate page tables on LPAE.  You already
      have these from akpm, but they were already part of my tree at the
      time he sent them, so unfortunately they'll end up with duplicate
      commits"
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (77 commits)
      ARM: EXYNOS: remove unnecessary use of IS_ERR_VALUE()
      ARM: IMX: remove unnecessary use of IS_ERR_VALUE()
      ARM: OMAP: use consistent error checking
      ARM: cleanup: OMAP hwmod error checking
      ARM: 7709/1: mcpm: Add explicit AFLAGS to support v6/v7 multiplatform kernels
      ARM: 7700/2: Make cpu_init() notrace
      ARM: 7702/1: Set the page table freeing ceiling to TASK_SIZE
      ARM: 7701/1: mm: Allow arch code to control the user page table ceiling
      ARM: 7703/1: Disable preemption in broadcast_tlb*_a15_erratum()
      ARM: mcpm: provide an interface to set the SMP ops at run time
      ARM: mcpm: generic SMP secondary bringup and hotplug support
      ARM: mcpm_head.S: vlock-based first man election
      ARM: mcpm: Add baremetal voting mutexes
      ARM: mcpm: introduce helpers for platform coherency exit/setup
      ARM: mcpm: introduce the CPU/cluster power API
      ARM: multi-cluster PM: secondary kernel entry code
      ARM: cacheflush: add synchronization helpers for mixed cache state accesses
      ARM: cpu hotplug: remove majority of cache flushing from platforms
      ARM: smp: flush L1 cache in cpu_die()
      ARM: tegra: remove tegra specific cpu_disable()
      ...

commit 51acdfd1fa38a2bf1003255be9f105c19fbc0176
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Apr 18 18:05:29 2013 +0100

    ARM: smp: flush L1 cache in cpu_die()
    
    Flush the L1 cache for the CPU which is going down in cpu_die() so
    that we don't end up with all platforms doing this.  This ensures
    that any cache lines we own are pushed out before the cache becomes
    inaccessible.
    
    We may end up subsequently creating some dirty cache lines - for
    example, with the complete() call, but this update must become
    visible to other CPUs before __cpu_die() can proceed.  Subsequent
    accesses from the platforms cpu_die() function should _not_ matter.
    
    Also place a mb() after the complete() call to ensure that this is
    visible to other CPUs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1f2ccccaf009..4231034b8128 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -211,6 +211,13 @@ void __cpuinit __cpu_die(unsigned int cpu)
 	}
 	printk(KERN_NOTICE "CPU%u: shutdown\n", cpu);
 
+	/*
+	 * platform_cpu_kill() is generally expected to do the powering off
+	 * and/or cutting of clocks to the dying CPU.  Optionally, this may
+	 * be done by the CPU which is dying in preference to supporting
+	 * this call, but that means there is _no_ synchronisation between
+	 * the requesting CPU and the dying CPU actually losing power.
+	 */
 	if (!platform_cpu_kill(cpu))
 		printk("CPU%u: unable to kill\n", cpu);
 }
@@ -230,14 +237,41 @@ void __ref cpu_die(void)
 	idle_task_exit();
 
 	local_irq_disable();
-	mb();
 
-	/* Tell __cpu_die() that this CPU is now safe to dispose of */
+	/*
+	 * Flush the data out of the L1 cache for this CPU.  This must be
+	 * before the completion to ensure that data is safely written out
+	 * before platform_cpu_kill() gets called - which may disable
+	 * *this* CPU and power down its cache.
+	 */
+	flush_cache_louis();
+
+	/*
+	 * Tell __cpu_die() that this CPU is now safe to dispose of.  Once
+	 * this returns, power and/or clocks can be removed at any point
+	 * from this CPU and its cache by platform_cpu_kill().
+	 */
 	RCU_NONIDLE(complete(&cpu_died));
 
 	/*
-	 * actual CPU shutdown procedure is at least platform (if not
-	 * CPU) specific.
+	 * Ensure that the cache lines associated with that completion are
+	 * written out.  This covers the case where _this_ CPU is doing the
+	 * powering down, to ensure that the completion is visible to the
+	 * CPU waiting for this one.
+	 */
+	flush_cache_louis();
+
+	/*
+	 * The actual CPU shutdown procedure is at least platform (if not
+	 * CPU) specific.  This may remove power, or it may simply spin.
+	 *
+	 * Platforms are generally expected *NOT* to return from this call,
+	 * although there are some which do because they have no way to
+	 * power down the CPU.  These platforms are the _only_ reason we
+	 * have a return path which uses the fragment of assembly below.
+	 *
+	 * The return path should not be used for platforms which can
+	 * power off the CPU.
 	 */
 	if (smp_ops.cpu_die)
 		smp_ops.cpu_die(cpu);

commit f7b861b7a6d9d1838cbbb5f4053e61578b86d134
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 21 22:49:38 2013 +0100

    arm: Use generic idle loop
    
    Use the generic idle loop and replace enable/disable_hlt with the
    respective core functions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Tested-by: Kevin Hilman <khilman@linaro.org> # OMAP
    Link: http://lkml.kernel.org/r/20130321215233.826238797@linutronix.de

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1f2ccccaf009..4619177bcfe6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -336,7 +336,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * OK, it's off to the idle thread for us
 	 */
-	cpu_idle();
+	cpu_startup_entry(CPUHP_ONLINE);
 }
 
 void __init smp_cpus_done(unsigned int max_cpus)

commit 6f3d90e55660ba42301b5e9c7eed332cc9f70fd7
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Mar 28 11:17:55 2013 +0100

    ARM: 7685/1: delay: use private ticks_per_jiffy field for timer-based delay ops
    
    Commit 70264367a243 ("ARM: 7653/2: do not scale loops_per_jiffy when
    using a constant delay clock") fixed a problem with our timer-based
    delay loop, where loops_per_jiffy is scaled by cpufreq yet used directly
    by the timer delay ops.
    
    This patch fixes the problem in a more elegant way by keeping a private
    ticks_per_jiffy field in the delay ops, independent of loops_per_jiffy
    and therefore not subject to scaling. The loop-based delay continues to
    use loops_per_jiffy directly, as it should.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 79078edbb9bc..1f2ccccaf009 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -673,9 +673,6 @@ static int cpufreq_callback(struct notifier_block *nb,
 	if (freq->flags & CPUFREQ_CONST_LOOPS)
 		return NOTIFY_OK;
 
-	if (arm_delay_ops.const_clock)
-		return NOTIFY_OK;
-
 	if (!per_cpu(l_p_j_ref, cpu)) {
 		per_cpu(l_p_j_ref, cpu) =
 			per_cpu(cpu_data, cpu).loops_per_jiffy;

commit f7db706b132f11c79ae1d74b2382e0926cf31644
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Thu Mar 14 10:03:03 2013 +0100

    ARM: 7674/1: smp: Avoid dummy clockevent being preferred over real hardware clock-event
    
    With recent arm broadcast time clean-up from Mark Rutland, the dummy
    broadcast device is always registered with timer subsystem. And since
    the rating of the dummy clock event is very high, it may be preferred
    over a real clock event.
    
    This is a change in behavior from past and not an intended one. So
    reduce the rating of the dummy clock-event so that real clock-event
    device is selected when available.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 31644f1978d5..79078edbb9bc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -480,7 +480,7 @@ static void __cpuinit broadcast_timer_setup(struct clock_event_device *evt)
 	evt->features	= CLOCK_EVT_FEAT_ONESHOT |
 			  CLOCK_EVT_FEAT_PERIODIC |
 			  CLOCK_EVT_FEAT_DUMMY;
-	evt->rating	= 400;
+	evt->rating	= 100;
 	evt->mult	= 1;
 	evt->set_mode	= broadcast_timer_set_mode;
 

commit 89c7e4b8bbb3d4fa52df5746a8ad38e610143651
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Feb 28 17:48:40 2013 +0100

    ARM: 7661/1: mm: perform explicit branch predictor maintenance when required
    
    The ARM ARM requires branch predictor maintenance if, for a given ASID,
    the instructions at a specific virtual address appear to change.
    
    From the kernel's point of view, that means:
    
            - Changing the kernel's view of memory (e.g. switching to the
              identity map)
            - ASID rollover (since ASIDs will be re-allocated to new tasks)
    
    This patch adds explicit branch predictor maintenance when either of the
    two conditions above are met.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1bdfd87c8e41..31644f1978d5 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -285,6 +285,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 * switch away from it before attempting any exclusive accesses.
 	 */
 	cpu_switch_mm(mm->pgd, mm);
+	local_flush_bp_all();
 	enter_lazy_tlb(mm, current);
 	local_flush_tlb_all();
 

commit 529e5fbcd8d3cb48cf824ac8fde91cc80a9e985f
Merge: 686c09407d24 16af43fef875
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Mar 3 11:54:39 2013 -0800

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull late ARM updates from Russell King:
     "Here is the late set of ARM updates for this merge window; in here is:
    
       - The ARM parts of the broadcast timer support, core parts merged
         through tglx's tree.  This was left over from the previous merge to
         allow the dependency on tglx's tree to be resolved.
    
       - A fix to the VFP code which shows up on Raspberry Pi's, as well as
         fixing the fallout from a previous commit in this area.
    
       - A number of smaller fixes scattered throughout the ARM tree"
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm:
      ARM: Fix broken commit 0cc41e4a21d43 corrupting kernel messages
      ARM: fix scheduling while atomic warning in alignment handling code
      ARM: VFP: fix emulation of second VFP instruction
      ARM: 7656/1: uImage: Error out on build of multiplatform without LOADADDR
      ARM: 7640/1: memory: tegra_ahb_enable_smmu() depends on TEGRA_IOMMU_SMMU
      ARM: 7654/1: Preserve L_PTE_VALID in pte_modify()
      ARM: 7653/2: do not scale loops_per_jiffy when using a constant delay clock
      ARM: 7651/1: remove unused smp_timer_broadcast #define

commit 16af43fef87512f7324205783526f543ddcf09cf
Merge: 9664ffe6a166 ded3ef0fa716 653a761e4ba7
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Mar 3 00:32:50 2013 +0000

    Merge branches 'devel-stable', 'fixes' and 'mmci' into for-linus

commit 8b5628ab83b671f96ac9f174c1bd51c92589fc82
Merge: a8f3740feb12 fe7dc7202d7d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 21 15:40:16 2013 -0800

    Merge tag 'virt' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull ARM virtualization changes:
     "This contains parts of the ARM KVM support that have dependencies on
      other patches merged through the arm-soc tree.  In combination with
      patches coming through Russell's tree, this will finally add full
      support for the kernel based virtual machine on ARM, which has been
      awaited for some time now.
    
      Further, we now have a separate platform for virtual machines and qemu
      booting that is used by both Xen and KVM, separating these from the
      Versatile Express reference implementation.  Obviously, this new
      platform is multiplatform capable so it can be combined with existing
      machines in the same kernel."
    
    * tag 'virt' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (38 commits)
      ARM: arch_timer: include linux/errno.h
      arm: arch_timer: add missing inline in stub function
      ARM: KVM: arch_timers: Wire the init code and config option
      ARM: KVM: arch_timers: Add timer world switch
      ARM: KVM: arch_timers: Add guest timer core support
      ARM: KVM: Add VGIC configuration option
      ARM: KVM: VGIC initialisation code
      ARM: KVM: VGIC control interface world switch
      ARM: KVM: VGIC interrupt injection
      ARM: KVM: vgic: retire queued, disabled interrupts
      ARM: KVM: VGIC virtual CPU interface management
      ARM: KVM: VGIC distributor handling
      ARM: KVM: VGIC accept vcpu and dist base addresses from user space
      ARM: KVM: Initial VGIC infrastructure code
      ARM: KVM: Keep track of currently running vcpus
      KVM: ARM: Introduce KVM_ARM_SET_DEVICE_ADDR ioctl
      ARM: gic: add __ASSEMBLY__ guard to C definitions
      ARM: gic: define GICH offsets for VGIC support
      ARM: gic: add missing distributor defintions
      ARM: mach-virt: fixup machine descriptor after removal of sys_timer
      ...

commit b274776c54c320763bc12eb035c0e244f76ccb43
Merge: b24174b0cbbe 3b1209e7994c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 21 14:58:40 2013 -0800

    Merge tag 'cleanup' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull ARM SoC cleanups from Arnd Bergmann:
     "A large number of cleanups, all over the platforms.  This is dominated
      largely by the Samsung platforms (s3c, s5p, exynos) and a few of the
      others moving code out of arch/arm into more appropriate subsystems.
    
      The clocksource and irqchip drivers are now abstracted to the point
      where platforms that are already cleaned up do not need to even
      specify the driver they use, it can all get configured from the device
      tree as we do for normal device drivers.  The clocksource changes
      basically touch every single platform in the process.
    
      We further clean up the use of platform specific header files here,
      with the goal of turning more of the platforms over to being
      "multiplatform" enabled, which implies that they cannot expose their
      headers to architecture independent code any more.
    
      It is expected that no functional changes are part of the cleanup.
      The overall reduction in total code lines is mostly the result of
      removing broken and obsolete code."
    
    * tag 'cleanup' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (133 commits)
      ARM: mvebu: correct gated clock documentation
      ARM: kirkwood: add missing include for nsa310
      ARM: exynos: move exynos4210-combiner to drivers/irqchip
      mfd: db8500-prcmu: update resource passing
      drivers/db8500-cpufreq: delete dangling include
      ARM: at91: remove NEOCORE 926 board
      sunxi: Cleanup the reset code and add meaningful registers defines
      ARM: S3C24XX: header mach/regs-mem.h local
      ARM: S3C24XX: header mach/regs-power.h local
      ARM: S3C24XX: header mach/regs-s3c2412-mem.h local
      ARM: S3C24XX: Remove plat-s3c24xx directory in arch/arm/
      ARM: S3C24XX: transform s3c2443 subirqs into new structure
      ARM: S3C24XX: modify s3c2443 irq init to initialize all irqs
      ARM: S3C24XX: move s3c2443 irq code to irq.c
      ARM: S3C24XX: transform s3c2416 irqs into new structure
      ARM: S3C24XX: modify s3c2416 irq init to initialize all irqs
      ARM: S3C24XX: move s3c2416 irq init to common irq code
      ARM: S3C24XX: Modify s3c_irq_wake to use the hwirq property
      ARM: S3C24XX: Move irq syscore-ops to irq-pm
      clocksource: always define CLOCKSOURCE_OF_DECLARE
      ...

commit 70264367a243a68b1d5636ffb570183449803cbe
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Mon Feb 18 16:36:13 2013 +0100

    ARM: 7653/2: do not scale loops_per_jiffy when using a constant delay clock
    
    When udelay() is implemented using an architected timer, it is wrong
    to scale loops_per_jiffy when changing the CPU clock frequency since
    the timer clock remains constant.
    
    The lpj should probably become an implementation detail relevant to
    the CPU loop based delay routine only and more confined to it. In the
    mean time this is the minimal fix needed to have expected delays with
    the timer based implementation when cpufreq is also in use.
    
    Reported-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Viresh Kumar <viresh.kumar@linaro.org>
    Acked-by: Liviu Dudau <Liviu.Dudau@arm.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 84f4cbf652e5..58af91c2a2f7 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -693,6 +693,9 @@ static int cpufreq_callback(struct notifier_block *nb,
 	if (freq->flags & CPUFREQ_CONST_LOOPS)
 		return NOTIFY_OK;
 
+	if (arm_delay_ops.const_clock)
+		return NOTIFY_OK;
+
 	if (!per_cpu(l_p_j_ref, cpu)) {
 		per_cpu(l_p_j_ref, cpu) =
 			per_cpu(cpu_data, cpu).loops_per_jiffy;

commit 9664ffe6a16676fa4d6a238ad3d9bb6cc24825a1
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Feb 12 18:22:14 2013 +0100

    ARM: 7651/1: remove unused smp_timer_broadcast #define
    
    The assignment of clock_event_device::broadcast can be done by timer
    core as of 12ad100046: "clockevents: Add generic timer broadcast
    function", and the arm code moved over to this as of 3d06770eef: "arm:
    Add generic timer broadcast support", but left a dangling #define when
    !CONFIG_GENERIC_TIMER_BROADCAST.
    
    This patch removes the now unused #define.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b7e3b506219b..ab9458d62cbb 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -480,8 +480,6 @@ void tick_broadcast(const struct cpumask *mask)
 {
 	smp_cross_call(mask, IPI_TIMER);
 }
-#else
-#define smp_timer_broadcast	NULL
 #endif
 
 static void broadcast_timer_set_mode(enum clock_event_mode mode,

commit 4f5c1c04f8623387ce4af942b2bf547d3bba40ae
Merge: 37a42fca282c 9e47b8bf9815
Author: Olof Johansson <olof@lixom.net>
Date:   Mon Feb 11 09:05:29 2013 -0800

    Merge branch 'irqchip/gic-vic-move' into next/virt

commit 3d06770eef43eaad606e77246bfcc7e82b1d9fb4
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Oct 30 12:13:42 2012 +0000

    arm: Add generic timer broadcast support
    
    Implement timer_broadcast for the arm architecture, allowing for the use
    of clock_event_device_drivers decoupled from the timer tick broadcast
    mechanism.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 930851912b37..b7e3b506219b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -476,7 +476,7 @@ u64 smp_irq_stat_cpu(unsigned int cpu)
 static DEFINE_PER_CPU(struct clock_event_device, percpu_clockevent);
 
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
-static void smp_timer_broadcast(const struct cpumask *mask)
+void tick_broadcast(const struct cpumask *mask)
 {
 	smp_cross_call(mask, IPI_TIMER);
 }
@@ -524,7 +524,6 @@ static void __cpuinit percpu_timer_setup(void)
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
 
 	evt->cpumask = cpumask_of(cpu);
-	evt->broadcast = smp_timer_broadcast;
 
 	if (!lt_ops || lt_ops->setup(evt))
 		broadcast_timer_setup(evt);

commit e2c501190c7d4bf9d7febb9e1f1094cbde59ed89
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Oct 30 11:17:01 2012 +0000

    arm: Use generic timer broadcast receiver
    
    Currently, the ARM backend must maintain a redundant list of timers for
    the purpose of centralising timer broadcast functionality. This prevents
    sharing timer drivers across architectures.
    
    This patch moves the pain of dealing with timer broadcasts to the core
    clockevents tick broadcast code, which already maintains its own list
    of timers.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 84f4cbf652e5..930851912b37 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -475,12 +475,6 @@ u64 smp_irq_stat_cpu(unsigned int cpu)
  */
 static DEFINE_PER_CPU(struct clock_event_device, percpu_clockevent);
 
-static void ipi_timer(void)
-{
-	struct clock_event_device *evt = &__get_cpu_var(percpu_clockevent);
-	evt->event_handler(evt);
-}
-
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 static void smp_timer_broadcast(const struct cpumask *mask)
 {
@@ -596,11 +590,13 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 	case IPI_WAKEUP:
 		break;
 
+#ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 	case IPI_TIMER:
 		irq_enter();
-		ipi_timer();
+		tick_receive_broadcast();
 		irq_exit();
 		break;
+#endif
 
 	case IPI_RESCHEDULE:
 		scheduler_ipi();

commit 0a301110b7bd33ef10164c184fe2c1d8c4c3ab6b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jan 14 15:54:28 2013 +0000

    ARM: smp: remove wrapper functions
    
    Remove some silly wrapper functions which aren't really required:
            platform_smp_prepare_cpus
            platform_secondary_init
            platform_cpu_die
    
    This simplifies the code.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 84f4cbf652e5..365c8d92e2eb 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -125,18 +125,6 @@ void __init smp_init_cpus(void)
 		smp_ops.smp_init_cpus();
 }
 
-static void __init platform_smp_prepare_cpus(unsigned int max_cpus)
-{
-	if (smp_ops.smp_prepare_cpus)
-		smp_ops.smp_prepare_cpus(max_cpus);
-}
-
-static void __cpuinit platform_secondary_init(unsigned int cpu)
-{
-	if (smp_ops.smp_secondary_init)
-		smp_ops.smp_secondary_init(cpu);
-}
-
 int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
 	if (smp_ops.smp_boot_secondary)
@@ -154,12 +142,6 @@ static int platform_cpu_kill(unsigned int cpu)
 	return 1;
 }
 
-static void platform_cpu_die(unsigned int cpu)
-{
-	if (smp_ops.cpu_die)
-		smp_ops.cpu_die(cpu);
-}
-
 static int platform_cpu_disable(unsigned int cpu)
 {
 	if (smp_ops.cpu_disable)
@@ -257,7 +239,8 @@ void __ref cpu_die(void)
 	 * actual CPU shutdown procedure is at least platform (if not
 	 * CPU) specific.
 	 */
-	platform_cpu_die(cpu);
+	if (smp_ops.cpu_die)
+		smp_ops.cpu_die(cpu);
 
 	/*
 	 * Do not return to the idle loop - jump back to the secondary
@@ -324,7 +307,8 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * Give the platform a chance to do its own initialisation.
 	 */
-	platform_secondary_init(cpu);
+	if (smp_ops.smp_secondary_init)
+		smp_ops.smp_secondary_init(cpu);
 
 	notify_cpu_starting(cpu);
 
@@ -399,8 +383,8 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 		/*
 		 * Initialise the present map, which describes the set of CPUs
 		 * actually populated at the present time. A platform should
-		 * re-initialize the map in platform_smp_prepare_cpus() if
-		 * present != possible (e.g. physical hotplug).
+		 * re-initialize the map in the platforms smp_prepare_cpus()
+		 * if present != possible (e.g. physical hotplug).
 		 */
 		init_cpu_present(cpu_possible_mask);
 
@@ -408,7 +392,8 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 		 * Initialise the SCU if there are more than one CPU
 		 * and let them know where to start.
 		 */
-		platform_smp_prepare_cpus(max_cpus);
+		if (smp_ops.smp_prepare_cpus)
+			smp_ops.smp_prepare_cpus(max_cpus);
 	}
 }
 

commit b1cffebf1029c87e1f1984d48463ee21093a6bc7
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Mon Nov 26 15:05:48 2012 -0600

    ARM: GIC: remove direct use of gic_raise_softirq
    
    In preparation of moving gic code to drivers/irqchip, remove the direct
    platform dependencies on gic_raise_softirq. Move the setup of
    smp_cross_call into the gic code and use arch_send_wakeup_ipi_mask
    function to trigger wake-up IPIs.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: Sascha Hauer <kernel@pengutronix.de>
    Cc: David Brown <davidb@codeaurora.org>
    Cc: Daniel Walker <dwalker@fifo99.com>
    Cc: Bryan Huntsman <bryanh@codeaurora.org>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: Shiraz Hashim <shiraz.hashim@st.com>
    Acked-by: Stephen Warren <swarren@nvidia.com>
    Cc: Srinidhi Kasagar <srinidhi.kasagar@stericsson.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 84f4cbf652e5..3fc96db2a4b6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -416,7 +416,8 @@ static void (*smp_cross_call)(const struct cpumask *, unsigned int);
 
 void __init set_smp_cross_call(void (*fn)(const struct cpumask *, unsigned int))
 {
-	smp_cross_call = fn;
+	if (!smp_cross_call)
+		smp_cross_call = fn;
 }
 
 void arch_send_call_function_ipi_mask(const struct cpumask *mask)

commit 0fa5d3996dbda1ee9653c43d39b7ef159fb57ee7
Merge: 0b99cb73105f 14318efb322e
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Dec 11 10:01:53 2012 +0000

    Merge branch 'devel-stable' into for-linus

commit 0b99cb73105f0527c1c4096960796b8772343a39
Merge: b8db6b886a1f 810883f05982 95e629b761ce b10bca0bc699 4b85da08c4d1 946c59a08a24 60d6dd530a6a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Dec 11 00:20:18 2012 +0000

    Merge branches 'cache-l2x0', 'fixes', 'hdrs', 'misc', 'mmci', 'vic' and 'warnings' into for-next

commit 026b7c6bf0bf044aa03e2affbda73b6c6a302538
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Mon Dec 3 21:13:03 2012 +0100

    ARM: 7590/1: /proc/interrupts: limit the display of IPIs to online CPUs only
    
    This is what is done for the regular interrupts in kernel/irqs/proc.c
    already, before calling arch_show_interrupts().  Not doing so for the
    IPIs causes the column headers not to match with the content whenever
    some CPUs are offline.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index fbc8b2623d82..fc4d526e2906 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -443,7 +443,7 @@ void show_ipi_list(struct seq_file *p, int prec)
 	for (i = 0; i < NR_IPI; i++) {
 		seq_printf(p, "%*s%u: ", prec - 1, "IPI", i);
 
-		for_each_present_cpu(cpu)
+		for_each_online_cpu(cpu)
 			seq_printf(p, "%10u ",
 				   __get_irq_stat(cpu, ipi_irqs[i]));
 

commit 14318efb322e2fe1a034c69463d725209eb9d548
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Thu Nov 29 20:39:54 2012 +0100

    ARM: 7587/1: implement optimized percpu variable access
    
    Use the previously unused TPIDRPRW register to store percpu offsets.
    TPIDRPRW is only accessible in PL1, so it can only be used in the kernel.
    
    This replaces 2 loads with a mrc instruction for each percpu variable
    access. With hackbench, the performance improvement is 1.4% on Cortex-A9
    (highbank). Taking an average of 30 runs of "hackbench -l 1000" yields:
    
    Before: 6.2191
    After: 6.1348
    
    Will Deacon reported similar delta on v6 with 11MPCore.
    
    The asm "memory clobber" are needed here to ensure the percpu offset
    gets reloaded. Testing by Will found that this would not happen in
    __schedule() which is a bit of a special case as preemption is disabled
    but the execution can move cores.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7eacd84cdc9c..f3a2be5837aa 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -314,9 +314,10 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));
 
+	cpu_init();
+
 	printk("CPU%u: Booted secondary processor\n", cpu);
 
-	cpu_init();
 	preempt_disable();
 	trace_hardirqs_off();
 
@@ -372,6 +373,7 @@ void __init smp_cpus_done(unsigned int max_cpus)
 
 void __init smp_prepare_boot_cpu(void)
 {
+	set_my_cpu_offset(per_cpu_offset(smp_processor_id()));
 }
 
 void __init smp_prepare_cpus(unsigned int max_cpus)

commit e8d432c9cf0a3d569b2d00877d12c9ffe9e55286
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Tue Nov 6 11:57:43 2012 +0000

    ARM: kernel: add MIDR to per-CPU information data
    
    The advent of big.LITTLE ARM platforms requires the kernel to be able
    to identify the MIDRs of all online CPUs upon request. MIDRs are stashed
    at boot time so that kernel subsystems can detect the MIDR of online CPUs
    by simply retrieving per-CPU data updated by all booted CPUs.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index fbc8b2623d82..7eacd84cdc9c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -281,6 +281,7 @@ static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
 	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
 
 	cpu_info->loops_per_jiffy = loops_per_jiffy;
+	cpu_info->cpuid = read_cpuid_id();
 
 	store_cpu_topology(cpuid);
 }

commit b62655f4c6f3e4d21934eee14ac2ac5cd479c97c
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Tue Nov 6 03:48:40 2012 +0100

    ARM: 7571/1: SMP: add function arch_send_wakeup_ipi_mask()
    
    Add function arch_send_wakeup_ipi_mask(), so that platform code can
    use it as an easy way to wake up cores that are in WFI.
    
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8e20754dd31d..dd5dd0248b88 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -415,6 +415,11 @@ void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 	smp_cross_call(mask, IPI_CALL_FUNC);
 }
 
+void arch_send_wakeup_ipi_mask(const struct cpumask *mask)
+{
+	smp_cross_call(mask, IPI_WAKEUP);
+}
+
 void arch_send_call_function_single_ipi(int cpu)
 {
 	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);

commit 5f40b909728ad784eb43aa309d3c4e9bdf050781
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Oct 19 17:53:01 2012 +0100

    ARM: 7559/1: smp: switch away from the idmap before updating init_mm.mm_count
    
    When booting a secondary CPU, the primary CPU hands two sets of page
    tables via the secondary_data struct:
    
            (1) swapper_pg_dir: a normal, cacheable, shared (if SMP) mapping
                of the kernel image (i.e. the tables used by init_mm).
    
            (2) idmap_pgd: an uncached mapping of the .idmap.text ELF
                section.
    
    The idmap is generally used when enabling and disabling the MMU, which
    includes early CPU boot. In this case, the secondary CPU switches to
    swapper as soon as it enters C code:
    
            struct mm_struct *mm = &init_mm;
            unsigned int cpu = smp_processor_id();
    
            /*
             * All kernel threads share the same mm context; grab a
             * reference and switch to it.
             */
            atomic_inc(&mm->mm_count);
            current->active_mm = mm;
            cpumask_set_cpu(cpu, mm_cpumask(mm));
            cpu_switch_mm(mm->pgd, mm);
    
    This causes a problem on ARMv7, where the identity mapping is treated as
    strongly-ordered leading to architecturally UNPREDICTABLE behaviour of
    exclusive accesses, such as those used by atomic_inc.
    
    This patch re-orders the secondary_start_kernel function so that we
    switch to swapper before performing any exclusive accesses.
    
    Cc: <stable@vger.kernel.org>
    Cc: David McKay <david.mckay@st.com>
    Reported-by: Gilles Chanteperdrix <gilles.chanteperdrix@xenomai.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8e20754dd31d..fbc8b2623d82 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -294,18 +294,24 @@ static void percpu_timer_setup(void);
 asmlinkage void __cpuinit secondary_start_kernel(void)
 {
 	struct mm_struct *mm = &init_mm;
-	unsigned int cpu = smp_processor_id();
+	unsigned int cpu;
+
+	/*
+	 * The identity mapping is uncached (strongly ordered), so
+	 * switch away from it before attempting any exclusive accesses.
+	 */
+	cpu_switch_mm(mm->pgd, mm);
+	enter_lazy_tlb(mm, current);
+	local_flush_tlb_all();
 
 	/*
 	 * All kernel threads share the same mm context; grab a
 	 * reference and switch to it.
 	 */
+	cpu = smp_processor_id();
 	atomic_inc(&mm->mm_count);
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));
-	cpu_switch_mm(mm->pgd, mm);
-	enter_lazy_tlb(mm, current);
-	local_flush_tlb_all();
 
 	printk("CPU%u: Booted secondary processor\n", cpu);
 

commit a0f0dd57f4a85310d9936f1770a0424b49fef876
Merge: 2a552d5e63d7 846a136881b8
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Oct 11 10:55:04 2012 +0100

    Merge branch 'fixes' into for-linus
    
    Conflicts:
            arch/arm/kernel/smp.c

commit 0e51793e162ca432fc5f04178cf82b80a92c2659
Merge: 5cad3598ea0c b4874a3d2986
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 7 21:20:57 2012 +0900

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "This is the first chunk of ARM updates for this merge window.
      Conflicts are expected in two files - asm/timex.h and
      mach-integrator/integrator_cp.c.  Nothing particularly stands out more
      than anything else.
    
      Most of the growth is down to the opcodes stuff from Dave Martin,
      which is countered by Rob's patches to use more of the asm-generic
      headers on ARM."
    
    (A few more conflicts grew since then, but it all looked fairly trivial)
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (44 commits)
      ARM: 7548/1: include linux/sched.h in syscall.h
      ARM: 7541/1: Add ARM ERRATA 775420 workaround
      ARM: ensure vm_struct has its phys_addr member filled in
      ARM: 7540/1: kexec: Check segment memory addresses
      ARM: 7539/1: kexec: scan for dtb magic in segments
      ARM: 7538/1: delay: add registration mechanism for delay timer sources
      ARM: 7536/1: smp: Formalize an IPI for wakeup
      ARM: 7525/1: ptrace: use updated syscall number for syscall auditing
      ARM: 7524/1: support syscall tracing
      ARM: 7519/1: integrator: convert platform devices to Device Tree
      ARM: 7518/1: integrator: convert AMBA devices to device tree
      ARM: 7517/1: integrator: initial device tree support
      ARM: 7516/1: plat-versatile: add DT support to FPGA IRQ
      ARM: 7515/1: integrator: check PL010 base address from resource
      ARM: 7514/1: integrator: call common init function from machine
      ARM: 7522/1: arch_timers: register a time/cycle counter
      ARM: 7523/1: arch_timers: enable the use of the virtual timer
      ARM: 7531/1: mark kernelmode mem{cpy,set} non-experimental
      ARM: 7520/1: Build dtb files in all target
      ARM: Fix build warning in arch/arm/mm/alignment.c
      ...

commit 16642a2e7be23bbda013fc32d8f6c68982eab603
Merge: 51562cba9893 b9142167a2bb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 18:32:35 2012 -0700

    Merge tag 'pm-for-3.7-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael J Wysocki:
    
     - Improved system suspend/resume and runtime PM handling for the SH
       TMU, CMT and MTU2 clock event devices (also used by ARM/shmobile).
    
     - Generic PM domains framework extensions related to cpuidle support
       and domain objects lookup using names.
    
     - ARM/shmobile power management updates including improved support for
       the SH7372's A4S power domain containing the CPU core.
    
     - cpufreq changes related to AMD CPUs support from Matthew Garrett,
       Andre Przywara and Borislav Petkov.
    
     - cpu0 cpufreq driver from Shawn Guo.
    
     - cpufreq governor fixes related to the relaxing of limit from Michal
       Pecio.
    
     - OMAP cpufreq updates from Axel Lin and Richard Zhao.
    
     - cpuidle ladder governor fixes related to the disabling of states from
       Carsten Emde and me.
    
     - Runtime PM core updates related to the interactions with the system
       suspend core from Alan Stern and Kevin Hilman.
    
     - Wakeup sources modification allowing more helper functions to be
       called from interrupt context from John Stultz and additional
       diagnostic code from Todd Poynor.
    
     - System suspend error code path fix from Feng Hong.
    
    Fixed up conflicts in cpufreq/powernow-k8 that stemmed from the
    workqueue fixes conflicting fairly badly with the removal of support for
    hardware P-state chips.  The changes were independent but somewhat
    intertwined.
    
    * tag 'pm-for-3.7-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (76 commits)
      Revert "PM QoS: Use spinlock in the per-device PM QoS constraints code"
      PM / Runtime: let rpm_resume() succeed if RPM_ACTIVE, even when disabled, v2
      cpuidle: rename function name "__cpuidle_register_driver", v2
      cpufreq: OMAP: Check IS_ERR() instead of NULL for omap_device_get_by_hwmod_name
      cpuidle: remove some empty lines
      PM: Prevent runtime suspend during system resume
      PM QoS: Use spinlock in the per-device PM QoS constraints code
      PM / Sleep: use resume event when call dpm_resume_early
      cpuidle / ACPI : move cpuidle_device field out of the acpi_processor_power structure
      ACPI / processor: remove pointless variable initialization
      ACPI / processor: remove unused function parameter
      cpufreq: OMAP: remove loops_per_jiffy recalculate for smp
      sections: fix section conflicts in drivers/cpufreq
      cpufreq: conservative: update frequency when limits are relaxed
      cpufreq / ondemand: update frequency when limits are relaxed
      properly __init-annotate pm_sysrq_init()
      cpufreq: Add a generic cpufreq-cpu0 driver
      PM / OPP: Initialize OPP table from device tree
      ARM: add cpufreq transiton notifier to adjust loops_per_jiffy for smp
      cpufreq: Remove support for hardware P-state chips from powernow-k8
      ...

commit 648f3b69986b4d0ade57e59504a431b973ce2875
Merge: 8ee777fd915b 8ec58be9f3ff
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 30 09:03:44 2012 +0100

    Merge branch 'hyp-boot-mode-rmk' of git://git.kernel.org/pub/scm/linux/kernel/git/maz/arm-platforms into devel-stable

commit e6b866e954a7f0d0144a951c158f3922dac1e6b9
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Fri Sep 7 11:09:15 2012 +0530

    ARM: kernel: update __cpu_disable to use cache LoUIS maintenance API
    
    When a CPU is hotplugged out caches that reside in its power domain
    lose their contents and so must be cleaned to the next memory level.
    
    Currently, __cpu_disable calls flush_cache_all() that for new generation
    processor like A15/A7 ends up cleaning and invalidating all cache levels
    up to Level of Coherency, which includes the unified L2.
    
    This ends up being a waste of cycles since the L2 cache contents are not
    lost on power down.
    
    This patch updates __cpu_disable to use the new LoUIS API cache operations.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebd8ad274d76..199558b9462e 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -134,8 +134,11 @@ int __cpu_disable(void)
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU
 	 * from the vm mask set of all processes.
+	 *
+	 * Caches are flushed to the Level of Unification Inner Shareable
+	 * to write-back dirty lines to unified caches shared by all CPUs.
 	 */
-	flush_cache_all();
+	flush_cache_louis();
 	local_flush_tlb_all();
 
 	clear_tasks_mm_cpumask(cpu);

commit 559a593905e583fca23229b916c016e5211c6766
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Wed Sep 19 08:16:07 2012 +0100

    ARM: 7536/1: smp: Formalize an IPI for wakeup
    
    Remove the offset from ipi_msg_type and assume that SGI0 is the
    wakeup interrupt now that all WFI hotplug users call
    gic_raise_softirq() with 0 instead of 1. This allows us to
    track how many wakeup interrupts are sent and also removes the
    unknown IPI printk message for WFI hotplug based systems.
    
    Reviewed-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebd8ad274d76..d98c37e97d9d 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -51,7 +51,8 @@
 struct secondary_data secondary_data;
 
 enum ipi_msg_type {
-	IPI_TIMER = 2,
+	IPI_WAKEUP,
+	IPI_TIMER,
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
 	IPI_CALL_FUNC_SINGLE,
@@ -347,7 +348,8 @@ void arch_send_call_function_single_ipi(int cpu)
 }
 
 static const char *ipi_types[NR_IPI] = {
-#define S(x,s)	[x - IPI_TIMER] = s
+#define S(x,s)	[x] = s
+	S(IPI_WAKEUP, "CPU wakeup interrupts"),
 	S(IPI_TIMER, "Timer broadcast interrupts"),
 	S(IPI_RESCHEDULE, "Rescheduling interrupts"),
 	S(IPI_CALL_FUNC, "Function call interrupts"),
@@ -500,10 +502,13 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 	unsigned int cpu = smp_processor_id();
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	if (ipinr >= IPI_TIMER && ipinr < IPI_TIMER + NR_IPI)
-		__inc_irq_stat(cpu, ipi_irqs[ipinr - IPI_TIMER]);
+	if (ipinr < NR_IPI)
+		__inc_irq_stat(cpu, ipi_irqs[ipinr]);
 
 	switch (ipinr) {
+	case IPI_WAKEUP:
+		break;
+
 	case IPI_TIMER:
 		irq_enter();
 		ipi_timer();

commit 4588c34daabb5aebee9cbe90f0ca6ab11412f207
Author: Dave Martin <dave.martin@linaro.org>
Date:   Fri Feb 17 16:54:28 2012 +0000

    ARM: virt: Add boot-time diagnostics
    
    In order to easily detect pathological cases, print some diagnostics
    when the kernel boots.
    
    This also provides helpers to detect that HYP mode is actually available,
    which can be used by other subsystems to enable HYP specific features.
    
    Signed-off-by: Dave Martin <dave.martin@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebd8ad274d76..adf226e718d2 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -42,6 +42,7 @@
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
 #include <asm/smp_plat.h>
+#include <asm/virt.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -287,6 +288,8 @@ void __init smp_cpus_done(unsigned int max_cpus)
 	       num_online_cpus(),
 	       bogosum / (500000/HZ),
 	       (bogosum / (5000/HZ)) % 100);
+
+	hyp_mode_check();
 }
 
 void __init smp_prepare_boot_cpu(void)

commit 28e8e29c616f947348cc66bea684d0035c76021a
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Jun 12 11:16:27 2012 +0100

    ARM: consolidate pen_release instead of having per platform definitions
    
    Almost each SMP platform defines pen_release to manage booting secondary
    CPUs. This of course clashes with the single zImage effort.
    
    Add the pen_release definition to the ARM SMP code, and remove all others.
    This should only be used by platforms which lack any kind of CPU power
    management...
    
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ac3ce029afb8..aa4ffe6e5ecf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -51,6 +51,12 @@
  */
 struct secondary_data secondary_data;
 
+/*
+ * control for which core is the next to come out of the secondary
+ * boot "holding pen"
+ */
+volatile int __cpuinitdata pen_release = -1;
+
 enum ipi_msg_type {
 	IPI_TIMER = 2,
 	IPI_RESCHEDULE,

commit ac6c7998712d55bd15aa2dd5ae85f5988c0cb526
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Sep 27 14:48:23 2011 +0100

    ARM: smp: Make SMP operations mandatory
    
    Now that all SMP platforms have been converted to use struct
    smp_operations, remove the "weak" attribute from the hooks
    in smp.c, and make the functions static wherever possible.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d9241885521b..ac3ce029afb8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -110,25 +110,25 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 }
 
 /* platform specific SMP operations */
-void __attribute__((weak)) __init smp_init_cpus(void)
+void __init smp_init_cpus(void)
 {
 	if (smp_ops.smp_init_cpus)
 		smp_ops.smp_init_cpus();
 }
 
-void __attribute__((weak)) __init platform_smp_prepare_cpus(unsigned int max_cpus)
+static void __init platform_smp_prepare_cpus(unsigned int max_cpus)
 {
 	if (smp_ops.smp_prepare_cpus)
 		smp_ops.smp_prepare_cpus(max_cpus);
 }
 
-void __attribute__((weak)) __cpuinit platform_secondary_init(unsigned int cpu)
+static void __cpuinit platform_secondary_init(unsigned int cpu)
 {
 	if (smp_ops.smp_secondary_init)
 		smp_ops.smp_secondary_init(cpu);
 }
 
-int __attribute__((weak)) __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
+int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
 	if (smp_ops.smp_boot_secondary)
 		return smp_ops.smp_boot_secondary(cpu, idle);
@@ -138,20 +138,20 @@ int __attribute__((weak)) __cpuinit boot_secondary(unsigned int cpu, struct task
 #ifdef CONFIG_HOTPLUG_CPU
 static void percpu_timer_stop(void);
 
-int __attribute__((weak)) platform_cpu_kill(unsigned int cpu)
+static int platform_cpu_kill(unsigned int cpu)
 {
 	if (smp_ops.cpu_kill)
 		return smp_ops.cpu_kill(cpu);
 	return 1;
 }
 
-void __attribute__((weak)) platform_cpu_die(unsigned int cpu)
+static void platform_cpu_die(unsigned int cpu)
 {
 	if (smp_ops.cpu_die)
 		smp_ops.cpu_die(cpu);
 }
 
-int __attribute__((weak)) platform_cpu_disable(unsigned int cpu)
+static int platform_cpu_disable(unsigned int cpu)
 {
 	if (smp_ops.cpu_disable)
 		return smp_ops.cpu_disable(cpu);
@@ -166,7 +166,7 @@ int __attribute__((weak)) platform_cpu_disable(unsigned int cpu)
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */
-int __cpu_disable(void)
+int __cpuinit __cpu_disable(void)
 {
 	unsigned int cpu = smp_processor_id();
 	int ret;
@@ -209,7 +209,7 @@ static DECLARE_COMPLETION(cpu_died);
  * called on the thread which is asking for a CPU to be shutdown -
  * waits until shutdown has completed, or it is timed out.
  */
-void __cpu_die(unsigned int cpu)
+void __cpuinit __cpu_die(unsigned int cpu)
 {
 	if (!wait_for_completion_timeout(&cpu_died, msecs_to_jiffies(5000))) {
 		pr_err("CPU%u: cpu didn't die\n", cpu);

commit abcee5fb0dfbb248d883a2f6bdb4820abe3ac524
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Thu Sep 8 09:06:10 2011 +0100

    ARM: SoC: add per-platform SMP operations
    
    This adds a 'struct smp_operations' to abstract the CPU initialization
    and hot plugging functions on SMP systems, which otherwise conflict
    in a multiplatform kernel. This also helps shmobile and potentially
    others that have more than one method to do these.
    
    To allow the kernel to continue building, the platform hooks are
    defined as weak symbols which are overrided by the platform code.
    Once all platforms are converted, the "weak" attribute will be
    removed and the function made static.
    
    Unlike the original version from Marc, this new version from Arnd
    does not use a generalized abstraction for per-soc data structures
    but only tries to solve the problem for the SMP operations. This
    way, we can collapse the previous four data structures into a
    single struct, which is less systematic but also easier to follow
    as a causal reader.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Nicolas Pitre <nico@fluxnic.net>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebd8ad274d76..d9241885521b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -19,7 +19,6 @@
 #include <linux/mm.h>
 #include <linux/err.h>
 #include <linux/cpu.h>
-#include <linux/smp.h>
 #include <linux/seq_file.h>
 #include <linux/irq.h>
 #include <linux/percpu.h>
@@ -27,6 +26,7 @@
 #include <linux/completion.h>
 
 #include <linux/atomic.h>
+#include <asm/smp.h>
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
@@ -42,6 +42,7 @@
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
 #include <asm/smp_plat.h>
+#include <asm/mach/arch.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -60,6 +61,14 @@ enum ipi_msg_type {
 
 static DECLARE_COMPLETION(cpu_running);
 
+static struct smp_operations smp_ops;
+
+void __init smp_set_ops(struct smp_operations *ops)
+{
+	if (ops)
+		smp_ops = *ops;
+};
+
 int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
 	int ret;
@@ -100,9 +109,60 @@ int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 	return ret;
 }
 
+/* platform specific SMP operations */
+void __attribute__((weak)) __init smp_init_cpus(void)
+{
+	if (smp_ops.smp_init_cpus)
+		smp_ops.smp_init_cpus();
+}
+
+void __attribute__((weak)) __init platform_smp_prepare_cpus(unsigned int max_cpus)
+{
+	if (smp_ops.smp_prepare_cpus)
+		smp_ops.smp_prepare_cpus(max_cpus);
+}
+
+void __attribute__((weak)) __cpuinit platform_secondary_init(unsigned int cpu)
+{
+	if (smp_ops.smp_secondary_init)
+		smp_ops.smp_secondary_init(cpu);
+}
+
+int __attribute__((weak)) __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
+{
+	if (smp_ops.smp_boot_secondary)
+		return smp_ops.smp_boot_secondary(cpu, idle);
+	return -ENOSYS;
+}
+
 #ifdef CONFIG_HOTPLUG_CPU
 static void percpu_timer_stop(void);
 
+int __attribute__((weak)) platform_cpu_kill(unsigned int cpu)
+{
+	if (smp_ops.cpu_kill)
+		return smp_ops.cpu_kill(cpu);
+	return 1;
+}
+
+void __attribute__((weak)) platform_cpu_die(unsigned int cpu)
+{
+	if (smp_ops.cpu_die)
+		smp_ops.cpu_die(cpu);
+}
+
+int __attribute__((weak)) platform_cpu_disable(unsigned int cpu)
+{
+	if (smp_ops.cpu_disable)
+		return smp_ops.cpu_disable(cpu);
+
+	/*
+	 * By default, allow disabling all CPUs except the first one,
+	 * since this is special on a lot of platforms, e.g. because
+	 * of clock tick interrupts.
+	 */
+	return cpu == 0 ? -EPERM : 0;
+}
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */

commit ec971ea5f2426a0bf9d5cca9a103743918c12978
Author: Richard Zhao <richard.zhao@linaro.org>
Date:   Wed Sep 5 01:08:59 2012 +0200

    ARM: add cpufreq transiton notifier to adjust loops_per_jiffy for smp
    
    If CONFIG_SMP, cpufreq skips loops_per_jiffy update, because different
    arch has different per-cpu loops_per_jiffy definition.
    
    Signed-off-by: Richard Zhao <richard.zhao@linaro.org>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ebd8ad274d76..8e03567c9583 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -25,6 +25,7 @@
 #include <linux/percpu.h>
 #include <linux/clockchips.h>
 #include <linux/completion.h>
+#include <linux/cpufreq.h>
 
 #include <linux/atomic.h>
 #include <asm/cacheflush.h>
@@ -584,3 +585,56 @@ int setup_profiling_timer(unsigned int multiplier)
 {
 	return -EINVAL;
 }
+
+#ifdef CONFIG_CPU_FREQ
+
+static DEFINE_PER_CPU(unsigned long, l_p_j_ref);
+static DEFINE_PER_CPU(unsigned long, l_p_j_ref_freq);
+static unsigned long global_l_p_j_ref;
+static unsigned long global_l_p_j_ref_freq;
+
+static int cpufreq_callback(struct notifier_block *nb,
+					unsigned long val, void *data)
+{
+	struct cpufreq_freqs *freq = data;
+	int cpu = freq->cpu;
+
+	if (freq->flags & CPUFREQ_CONST_LOOPS)
+		return NOTIFY_OK;
+
+	if (!per_cpu(l_p_j_ref, cpu)) {
+		per_cpu(l_p_j_ref, cpu) =
+			per_cpu(cpu_data, cpu).loops_per_jiffy;
+		per_cpu(l_p_j_ref_freq, cpu) = freq->old;
+		if (!global_l_p_j_ref) {
+			global_l_p_j_ref = loops_per_jiffy;
+			global_l_p_j_ref_freq = freq->old;
+		}
+	}
+
+	if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
+	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new) ||
+	    (val == CPUFREQ_RESUMECHANGE || val == CPUFREQ_SUSPENDCHANGE)) {
+		loops_per_jiffy = cpufreq_scale(global_l_p_j_ref,
+						global_l_p_j_ref_freq,
+						freq->new);
+		per_cpu(cpu_data, cpu).loops_per_jiffy =
+			cpufreq_scale(per_cpu(l_p_j_ref, cpu),
+					per_cpu(l_p_j_ref_freq, cpu),
+					freq->new);
+	}
+	return NOTIFY_OK;
+}
+
+static struct notifier_block cpufreq_notifier = {
+	.notifier_call  = cpufreq_callback,
+};
+
+static int __init register_cpufreq_notifier(void)
+{
+	return cpufreq_register_notifier(&cpufreq_notifier,
+						CPUFREQ_TRANSITION_NOTIFIER);
+}
+core_initcall(register_cpufreq_notifier);
+
+#endif

commit c5dff4ffd327088d85035bec535b7d0c9ea03151
Author: Javier Martinez Canillas <javier@dowhile0.org>
Date:   Sat Jul 28 15:19:55 2012 +0100

    ARM: 7480/1: only call smp_send_stop() on SMP
    
    On reboot or poweroff (machine_shutdown()) a call to smp_send_stop() is
    made (to stop the others CPU's) when CONFIG_SMP=y.
    
    arch/arm/kernel/process.c:
    
    void machine_shutdown(void)
    {
     #ifdef CONFIG_SMP
           smp_send_stop();
     #endif
    }
    
    smp_send_stop() calls the function pointer smp_cross_call(), which is set
    on the smp_init_cpus() function for OMAP processors.
    
    arch/arm/mach-omap2/omap-smp.c:
    
    void __init smp_init_cpus(void)
    {
    ...
            set_smp_cross_call(gic_raise_softirq);
    ...
    }
    
    But the ARM setup_arch() function only calls smp_init_cpus()
    if CONFIG_SMP=y && is_smp().
    
    arm/kernel/setup.c:
    
    void __init setup_arch(char **cmdline_p)
    {
    ...
     #ifdef CONFIG_SMP
            if (is_smp())
                    smp_init_cpus();
     #endif
    ...
    }
    
    Newer OMAP CPU's are SMP machines so omap2plus_defconfig sets
    CONFIG_SMP=y. Unfortunately on an OMAP UP machine is_smp()
    returns false and smp_init_cpus() is never called and the
    smp_cross_call() function remains NULL.
    
    If the machine is rebooted or powered off, smp_send_stop() will
    be called (since CONFIG_SMP=y) leading to the following error:
    
    [   42.815551] Restarting system.
    [   42.819030] Unable to handle kernel NULL pointer dereference at virtual address 00000000
    [   42.827667] pgd = d7a74000
    [   42.830566] [00000000] *pgd=96ce7831, *pte=00000000, *ppte=00000000
    [   42.837249] Internal error: Oops: 80000007 [#1] SMP ARM
    [   42.842773] Modules linked in:
    [   42.846008] CPU: 0    Not tainted  (3.5.0-rc3-next-20120622-00002-g62e87ba-dirty #44)
    [   42.854278] PC is at 0x0
    [   42.856994] LR is at smp_send_stop+0x4c/0xe4
    [   42.861511] pc : [<00000000>]    lr : [<c00183a4>]    psr: 60000013
    [   42.861511] sp : d6c85e70  ip : 00000000  fp : 00000000
    [   42.873626] r10: 00000000  r9 : d6c84000  r8 : 00000002
    [   42.879150] r7 : c07235a0  r6 : c06dd2d0  r5 : 000f4241  r4 : d6c85e74
    [   42.886047] r3 : 00000000  r2 : 00000000  r1 : 00000006  r0 : d6c85e74
    [   42.892944] Flags: nZCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment user
    [   42.900482] Control: 10c5387d  Table: 97a74019  DAC: 00000015
    [   42.906555] Process reboot (pid: 1166, stack limit = 0xd6c842f8)
    [   42.912902] Stack: (0xd6c85e70 to 0xd6c86000)
    [   42.917510] 5e60:                                     c07235a0 00000000 00000000 d6c84000
    [   42.926177] 5e80: 01234567 c00143d0 4321fedc c00511bc d6c85ebc 00000168 00000460 00000000
    [   42.934814] 5ea0: c1017950 a0000013 c1017900 d8014390 d7ec3858 c0498e48 c1017950 00000000
    [   42.943481] 5ec0: d6ddde10 d6c85f78 00000003 00000000 d6ddde10 d6c84000 00000000 00000000
    [   42.952117] 5ee0: 00000002 00000000 00000000 c0088c88 00000002 00000000 00000000 c00f4b90
    [   42.960784] 5f00: 00000000 d6c85ebc d8014390 d7e311c8 60000013 00000103 00000002 d6c84000
    [   42.969421] 5f20: c00f3274 d6e00a00 00000001 60000013 d6c84000 00000000 00000000 c00895d4
    [   42.978057] 5f40: 00000002 d8007c80 d781f000 c00f6150 d8010cc0 c00f3274 d781f000 d6c84000
    [   42.986694] 5f60: c0013020 d6e00a00 00000001 20000010 0001257c ef000000 00000000 c00895d4
    [   42.995361] 5f80: 00000002 00000001 00000003 00000000 00000001 00000003 00000000 00000058
    [   43.003997] 5fa0: c00130c8 c0012f00 00000001 00000003 fee1dead 28121969 01234567 00000002
    [   43.012634] 5fc0: 00000001 00000003 00000000 00000058 00012584 0001257c 00000001 00000000
    [   43.021270] 5fe0: 000124bc bec5cc6c 00008f9c 4a2f7c40 20000010 fee1dead 00000000 00000000
    [   43.029968] [<c00183a4>] (smp_send_stop+0x4c/0xe4) from [<c00143d0>] (machine_restart+0xc/0x4c)
    [   43.039154] [<c00143d0>] (machine_restart+0xc/0x4c) from [<c00511bc>] (sys_reboot+0x144/0x1f0)
    [   43.048278] [<c00511bc>] (sys_reboot+0x144/0x1f0) from [<c0012f00>] (ret_fast_syscall+0x0/0x3c)
    [   43.057464] Code: bad PC value
    [   43.060760] ---[ end trace c3988d1dd0b8f0fb ]---
    
    Add a check so smp_cross_call() is only called when there is more than one CPU on-line.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Javier Martinez Canillas <javier at dowhile0.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index aea74f5bc34a..ebd8ad274d76 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -563,7 +563,8 @@ void smp_send_stop(void)
 
 	cpumask_copy(&mask, cpu_online_mask);
 	cpumask_clear_cpu(smp_processor_id(), &mask);
-	smp_cross_call(&mask, IPI_CPU_STOP);
+	if (!cpumask_empty(&mask))
+		smp_cross_call(&mask, IPI_CPU_STOP);
 
 	/* Wait up to one second for other CPUs to stop */
 	timeout = USEC_PER_SEC;

commit ff081e05bfba3461119cd280201d163b6858eda2
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Fri Jul 6 22:03:42 2012 +0100

    ARM: 7457/1: smp: Fix suspicious RCU originating from cpu_die()
    
    While running hotplug tests I ran into this RCU splat
    
    ===============================
    [ INFO: suspicious RCU usage. ]
    3.4.0 #3275 Tainted: G        W
    -------------------------------
    include/linux/rcupdate.h:729 rcu_read_lock() used illegally while idle!
    
    other info that might help us debug this:
    
    RCU used illegally from idle CPU!
    rcu_scheduler_active = 1, debug_locks = 0
    RCU used illegally from extended quiescent state!
    4 locks held by swapper/2/0:
     #0:  ((cpu_died).wait.lock){......}, at: [<c00ab128>] complete+0x1c/0x5c
     #1:  (&p->pi_lock){-.-.-.}, at: [<c00b275c>] try_to_wake_up+0x2c/0x388
     #2:  (&rq->lock){-.-.-.}, at: [<c00b2860>] try_to_wake_up+0x130/0x388
     #3:  (rcu_read_lock){.+.+..}, at: [<c00abe5c>] cpuacct_charge+0x28/0x1f4
    
    stack backtrace:
    [<c001521c>] (unwind_backtrace+0x0/0x12c) from [<c00abec8>] (cpuacct_charge+0x94/0x1f4)
    [<c00abec8>] (cpuacct_charge+0x94/0x1f4) from [<c00b395c>] (update_curr+0x24c/0x2c8)
    [<c00b395c>] (update_curr+0x24c/0x2c8) from [<c00b59c4>] (enqueue_task_fair+0x50/0x194)
    [<c00b59c4>] (enqueue_task_fair+0x50/0x194) from [<c00afea4>] (enqueue_task+0x30/0x34)
    [<c00afea4>] (enqueue_task+0x30/0x34) from [<c00b0908>] (ttwu_activate+0x14/0x38)
    [<c00b0908>] (ttwu_activate+0x14/0x38) from [<c00b28a8>] (try_to_wake_up+0x178/0x388)
    [<c00b28a8>] (try_to_wake_up+0x178/0x388) from [<c00a82a0>] (__wake_up_common+0x34/0x78)
    [<c00a82a0>] (__wake_up_common+0x34/0x78) from [<c00ab154>] (complete+0x48/0x5c)
    [<c00ab154>] (complete+0x48/0x5c) from [<c07db7cc>] (cpu_die+0x2c/0x58)
    [<c07db7cc>] (cpu_die+0x2c/0x58) from [<c000f954>] (cpu_idle+0x64/0xfc)
    [<c000f954>] (cpu_idle+0x64/0xfc) from [<80208160>] (0x80208160)
    
    When a cpu is marked offline during its idle thread it calls
    cpu_die() during an RCU idle period. cpu_die() calls complete()
    to notify the killing process that the cpu has died. complete()
    calls into the scheduler code and eventually grabs an RCU read
    lock in cpuacct_charge().
    
    Mark complete() as RCU_NONIDLE so that RCU pays attention to this
    CPU for the duration of the complete() function even though it's
    in idle.
    
    Suggested-by: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 2c7217d971db..aea74f5bc34a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -179,7 +179,7 @@ void __ref cpu_die(void)
 	mb();
 
 	/* Tell __cpu_die() that this CPU is now safe to dispose of */
-	complete(&cpu_died);
+	RCU_NONIDLE(complete(&cpu_died));
 
 	/*
 	 * actual CPU shutdown procedure is at least platform (if not

commit 3eaa73bde2fb475b731a0fde7dd11c3ecfb8679c
Author: Anton Vorontsov <anton.vorontsov@linaro.org>
Date:   Thu May 31 16:26:22 2012 -0700

    arm: use clear_tasks_mm_cpumask()
    
    Checking for process->mm is not enough because process' main thread may
    exit or detach its mm via use_mm(), but other threads may still have a
    valid mm.
    
    To fix this we would need to use find_lock_task_mm(), which would walk up
    all threads and returns an appropriate task (with task lock held).
    
    clear_tasks_mm_cpumask() has this issue fixed, so let's use it.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Anton Vorontsov <anton.vorontsov@linaro.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b735521a4a54..2c7217d971db 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -109,7 +109,6 @@ static void percpu_timer_stop(void);
 int __cpu_disable(void)
 {
 	unsigned int cpu = smp_processor_id();
-	struct task_struct *p;
 	int ret;
 
 	ret = platform_cpu_disable(cpu);
@@ -139,12 +138,7 @@ int __cpu_disable(void)
 	flush_cache_all();
 	local_flush_tlb_all();
 
-	read_lock(&tasklist_lock);
-	for_each_process(p) {
-		if (p->mm)
-			cpumask_clear_cpu(cpu, mm_cpumask(p->mm));
-	}
-	read_unlock(&tasklist_lock);
+	clear_tasks_mm_cpumask(cpu);
 
 	return 0;
 }

commit bf67f3a5c456a18f2e8d062f7e88506ef2cd9837
Merge: 226da0dbc84e 203dacbdca97
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 21 19:43:57 2012 -0700

    Merge branch 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull smp hotplug cleanups from Thomas Gleixner:
     "This series is merily a cleanup of code copied around in arch/* and
      not changing any of the real cpu hotplug horrors yet.  I wish I'd had
      something more substantial for 3.5, but I underestimated the lurking
      horror..."
    
    Fix up trivial conflicts in arch/{arm,sparc,x86}/Kconfig and
    arch/sparc/include/asm/thread_info_32.h
    
    * 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (79 commits)
      um: Remove leftover declaration of alloc_task_struct_node()
      task_allocator: Use config switches instead of magic defines
      sparc: Use common threadinfo allocator
      score: Use common threadinfo allocator
      sh-use-common-threadinfo-allocator
      mn10300: Use common threadinfo allocator
      powerpc: Use common threadinfo allocator
      mips: Use common threadinfo allocator
      hexagon: Use common threadinfo allocator
      m32r: Use common threadinfo allocator
      frv: Use common threadinfo allocator
      cris: Use common threadinfo allocator
      x86: Use common threadinfo allocator
      c6x: Use common threadinfo allocator
      fork: Provide kmemcache based thread_info allocator
      tile: Use common threadinfo allocator
      fork: Provide weak arch_release_[task_struct|thread_info] functions
      fork: Move thread info gfp flags to header
      fork: Remove the weak insanity
      sh: Remove cpu_idle_wait()
      ...

commit ddf90a2ff2c4a9da99acc898a4afeab3e4251fcd
Merge: dfb85185bda3 5693188a6e88 56cb248428ea d098bc7d58eb 34fd421349ff 90cf2418f5c4 d12379acaf55
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 21 15:15:10 2012 +0100

    Merge branches 'amba', 'devel-stable', 'fixes', 'mach-types', 'mmci', 'pci' and 'versatile' into for-linus

commit 67ba5293f705eb1d1b98710e5ccb0f615936a6fc
Merge: 86627c93b350 d909a81b198a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 8 14:07:48 2012 +0200

    Merge branch 'smp/threadalloc' into smp/hotplug
    
    Reason: Pull in the separate branch which was created so arch/tile can
    base further work on it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit fde165b2a29673aabf18ceff14dea1f1cfb0daad
Author: Colin Cross <ccross@android.com>
Date:   Sat May 5 20:58:13 2012 +0100

    ARM: 7414/1: SMP: prevent use of the console when using idmap_pgd
    
    Commit 4e8ee7de227e3ab9a72040b448ad728c5428a042 (ARM: SMP: use
    idmap_pgd for mapping MMU enable during secondary booting)
    switched secondary boot to use idmap_pgd, which is initialized
    during early_initcall, instead of a page table initialized during
    __cpu_up.  This causes idmap_pgd to contain the static mappings
    but be missing all dynamic mappings.
    
    If a console is registered that creates a dynamic mapping, the
    printk in secondary_start_kernel will trigger a data abort on
    the missing mapping before the exception handlers have been
    initialized, leading to a hang.  Initial boot is not affected
    because no consoles have been registered, and resume is usually
    not affected because the offending console is suspended.
    Onlining a cpu with hotplug triggers the problem.
    
    A workaround is to the printk in secondary_start_kernel until
    after the page tables have been switched back to init_mm.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Colin Cross <ccross@android.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index f6a4d32b0421..8f4644659777 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -251,8 +251,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	struct mm_struct *mm = &init_mm;
 	unsigned int cpu = smp_processor_id();
 
-	printk("CPU%u: Booted secondary processor\n", cpu);
-
 	/*
 	 * All kernel threads share the same mm context; grab a
 	 * reference and switch to it.
@@ -264,6 +262,8 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	enter_lazy_tlb(mm, current);
 	local_flush_tlb_all();
 
+	printk("CPU%u: Booted secondary processor\n", cpu);
+
 	cpu_init();
 	preempt_disable();
 	trace_hardirqs_off();

commit 6fa99b7f80b4a7ed2cf616eae393bb6d9d51ba8f
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Apr 27 12:51:43 2012 +0100

    ARM: 7405/1: kexec: call platform_cpu_kill on the killer rather than the victim
    
    When performing a kexec on an SMP system, the secondary cores are stopped
    by calling machine_shutdown(), which in turn issues IPIs to offline the
    other CPUs. Unfortunately, this isn't enough to reboot the cores into
    a new kernel (since they are just executing a cpu_relax loop somewhere
    in memory) so we make use of platform_cpu_kill, part of the CPU hotplug
    implementation, to place the cores somewhere safe. This function expects
    to be called on the killing CPU for each core that it takes out.
    
    This patch moves the platform_cpu_kill callback out of the IPI handler
    and into smp_send_stop, therefore ensuring that it executes on the
    killing CPU rather than on the victim, matching what the hotplug code
    requires.
    
    Cc: stable@vger.kernel.org
    Reported-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index addbbe8028c2..f6a4d32b0421 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -510,10 +510,6 @@ static void ipi_cpu_stop(unsigned int cpu)
 	local_fiq_disable();
 	local_irq_disable();
 
-#ifdef CONFIG_HOTPLUG_CPU
-	platform_cpu_kill(cpu);
-#endif
-
 	while (1)
 		cpu_relax();
 }
@@ -576,17 +572,25 @@ void smp_send_reschedule(int cpu)
 	smp_cross_call(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+static void smp_kill_cpus(cpumask_t *mask)
+{
+	unsigned int cpu;
+	for_each_cpu(cpu, mask)
+		platform_cpu_kill(cpu);
+}
+#else
+static void smp_kill_cpus(cpumask_t *mask) { }
+#endif
+
 void smp_send_stop(void)
 {
 	unsigned long timeout;
+	struct cpumask mask;
 
-	if (num_online_cpus() > 1) {
-		struct cpumask mask;
-		cpumask_copy(&mask, cpu_online_mask);
-		cpumask_clear_cpu(smp_processor_id(), &mask);
-
-		smp_cross_call(&mask, IPI_CPU_STOP);
-	}
+	cpumask_copy(&mask, cpu_online_mask);
+	cpumask_clear_cpu(smp_processor_id(), &mask);
+	smp_cross_call(&mask, IPI_CPU_STOP);
 
 	/* Wait up to one second for other CPUs to stop */
 	timeout = USEC_PER_SEC;
@@ -595,6 +599,8 @@ void smp_send_stop(void)
 
 	if (num_online_cpus() > 1)
 		pr_warning("SMP: failed to stop secondary CPUs\n");
+
+	smp_kill_cpus(&mask);
 }
 
 /*

commit bfa05f4f3398b61205567f3a5cad90804a5a1fdc
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Feb 14 11:25:58 2012 +0000

    ARM: local timers: reserve local_timer_register() to SMP
    
    When running an SMP_ON_UP enabled kernel on UP, or with nosmp
    passed to the kernel, we want to be able to detect that a local
    timer is not going to be used (local timers are only used on
    SMP platforms), so we could register it as a global timer instead.
    
    Return -ENXIO when the above case is detected.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index addbbe8028c2..11c4148b8abb 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -454,6 +454,9 @@ static struct local_timer_ops *lt_ops;
 #ifdef CONFIG_LOCAL_TIMERS
 int local_timer_register(struct local_timer_ops *ops)
 {
+	if (!is_smp() || !setup_max_cpus)
+		return -ENXIO;
+
 	if (lt_ops)
 		return -EBUSY;
 

commit 84ec6d5796e095e2f8698bd2b5d33849ed26d9e2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:50 2012 +0000

    arm: Use generic idle thread allocation
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Tested-by: Frank Rowand <frank.rowand@am.sony.com>
    Link: http://lkml.kernel.org/r/20120420124557.448826362@linutronix.de

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index f0e2cbbd837d..5e86f7c47824 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -60,31 +60,10 @@ enum ipi_msg_type {
 
 static DECLARE_COMPLETION(cpu_running);
 
-int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *tidle)
+int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *idle)
 {
-	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
-	struct task_struct *idle = ci->idle;
 	int ret;
 
-	/*
-	 * Spawn a new process manually, if not already done.
-	 * Grab a pointer to its task struct so we can mess with it
-	 */
-	if (!idle) {
-		idle = fork_idle(cpu);
-		if (IS_ERR(idle)) {
-			printk(KERN_ERR "CPU%u: fork() failed\n", cpu);
-			return PTR_ERR(idle);
-		}
-		ci->idle = idle;
-	} else {
-		/*
-		 * Since this idle thread is being re-used, call
-		 * init_idle() to reinitialize the thread structure.
-		 */
-		init_idle(idle, cpu);
-	}
-
 	/*
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
@@ -318,9 +297,6 @@ void __init smp_cpus_done(unsigned int max_cpus)
 
 void __init smp_prepare_boot_cpu(void)
 {
-	unsigned int cpu = smp_processor_id();
-
-	per_cpu(cpu_data, cpu).idle = current;
 }
 
 void __init smp_prepare_cpus(unsigned int max_cpus)

commit 8239c25f47d2b318156993b15f33900a86ea5e17
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 20 13:05:42 2012 +0000

    smp: Add task_struct argument to __cpu_up()
    
    Preparatory patch to make the idle thread allocation for secondary
    cpus generic.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/20120420124556.964170564@linutronix.de

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index addbbe8028c2..f0e2cbbd837d 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -60,7 +60,7 @@ enum ipi_msg_type {
 
 static DECLARE_COMPLETION(cpu_running);
 
-int __cpuinit __cpu_up(unsigned int cpu)
+int __cpuinit __cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
 	struct task_struct *idle = ci->idle;

commit deb74f5ca1f22f9e1c5da93143a250dbb96535af
Merge: dd775ae25492 615399c84d1b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 2 08:53:24 2012 -0700

    Merge tag 'for-linus' of git://github.com/rustyrussell/linux
    
    Pull cpumask cleanups from Rusty Russell:
     "(Somehow forgot to send this out; it's been sitting in linux-next, and
      if you don't want it, it can sit there another cycle)"
    
    I'm a sucker for things that actually delete lines of code.
    
    Fix up trivial conflict in arch/arm/kernel/kprobes.c, where Rusty fixed
    a user of &cpu_online_map to be cpu_online_mask, but that code got
    deleted by commit b21d55e98ac2 ("ARM: 7332/1: extract out code patch
    function from kprobes").
    
    * tag 'for-linus' of git://github.com/rustyrussell/linux:
      cpumask: remove old cpu_*_map.
      documentation: remove references to cpu_*_map.
      drivers/cpufreq/db8500-cpufreq: remove references to cpu_*_map.
      remove references to cpu_*_map in arch/

commit 12679a2d7e3bfbdc7586e3e86d1ca90c46659363
Merge: 1c036588772d b0df89868006
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 16:53:48 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull more ARM updates from Russell King.
    
    This got a fair number of conflicts with the <asm/system.h> split, but
    also with some other sparse-irq and header file include cleanups.  They
    all looked pretty trivial, though.
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (59 commits)
      ARM: fix Kconfig warning for HAVE_BPF_JIT
      ARM: 7361/1: provide XIP_VIRT_ADDR for no-MMU builds
      ARM: 7349/1: integrator: convert to sparse irqs
      ARM: 7259/3: net: JIT compiler for packet filters
      ARM: 7334/1: add jump label support
      ARM: 7333/2: jump label: detect %c support for ARM
      ARM: 7338/1: add support for early console output via semihosting
      ARM: use set_current_blocked() and block_sigmask()
      ARM: exec: remove redundant set_fs(USER_DS)
      ARM: 7332/1: extract out code patch function from kprobes
      ARM: 7331/1: extract out insn generation code from ftrace
      ARM: 7330/1: ftrace: use canonical Thumb-2 wide instruction format
      ARM: 7351/1: ftrace: remove useless memory checks
      ARM: 7316/1: kexec: EOI active and mask all interrupts in kexec crash path
      ARM: Versatile Express: add NO_IOPORT
      ARM: get rid of asm/irq.h in asm/prom.h
      ARM: 7319/1: Print debug info for SIGBUS in user faults
      ARM: 7318/1: gic: refactor irq_start assignment
      ARM: 7317/1: irq: avoid NULL check in for_each_irq_desc loop
      ARM: 7315/1: perf: add support for the Cortex-A7 PMU
      ...

commit 0b5f9c005def154f9c21f9be0223b65b50d54368
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Mar 29 15:38:30 2012 +1030

    remove references to cpu_*_map in arch/
    
    This has been obsolescent for a while; time for the final push.
    
    In adjacent context, replaced old cpus_* with cpumask_*.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: David S. Miller <davem@davemloft.net> (arch/sparc)
    Acked-by: Chris Metcalf <cmetcalf@tilera.com> (arch/tile)
    Cc: user-mode-linux-devel@lists.sourceforge.net
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: linux-hexagon@vger.kernel.org
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Helge Deller <deller@gmx.de>
    Cc: sparclinux@vger.kernel.org

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8f8cce2c46c4..9a4bdde909ce 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -354,7 +354,7 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 		 * re-initialize the map in platform_smp_prepare_cpus() if
 		 * present != possible (e.g. physical hotplug).
 		 */
-		init_cpu_present(&cpu_possible_map);
+		init_cpu_present(cpu_possible_mask);
 
 		/*
 		 * Initialise the SCU if there are more than one CPU
@@ -586,8 +586,9 @@ void smp_send_stop(void)
 	unsigned long timeout;
 
 	if (num_online_cpus() > 1) {
-		cpumask_t mask = cpu_online_map;
-		cpu_clear(smp_processor_id(), mask);
+		struct cpumask mask;
+		cpumask_copy(&mask, cpu_online_mask);
+		cpumask_clear_cpu(smp_processor_id(), &mask);
 
 		smp_cross_call(&mask, IPI_CPU_STOP);
 	}

commit 48d554418d3bfbba5e9dc1ebdf352f1b1f3ff4ee
Merge: d61b7a572b29 2cbe23e3a432
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 27 16:06:17 2012 -0700

    Merge tag 'timer' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull "ARM: timer cleanup work" from Arnd Bergmann:
     "These are split out from the generic soc and driver updates because
      there was a lot of conflicting work by multiple people.  Marc Zyngier
      worked on simplifying the "localtimer" interfaces, and some of the
      platforms are touching the same code as they move to device tree based
      booting.
    
      Signed-off-by: Arnd Bergmann <arnd@arndb.de>"
    
    * tag 'timer' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (61 commits)
      ARM: tegra: select USB_ULPI if USB is selected
      arm/tegra: pcie: fix return value of function
      ARM: ux500: fix compilation after local timer rework
      ARM: shmobile: remove additional __io() macro use
      ARM: local timers: make the runtime registration interface mandatory
      ARM: local timers: convert MSM to runtime registration interface
      ARM: local timers: convert exynos to runtime registration interface
      ARM: smp_twd: remove old local timer interface
      ARM: imx6q: convert to twd_local_timer_register() interface
      ARM: highbank: convert to twd_local_timer_register() interface
      ARM: ux500: convert to twd_local_timer_register() interface
      ARM: shmobile: convert to twd_local_timer_register() interface
      ARM: tegra: convert to twd_local_timer_register() interface
      ARM: plat-versatile: convert to twd_local_timer_register() interface
      ARM: OMAP4: convert to twd_local_timer_register() interface
      ARM: smp_twd: add device tree support
      ARM: smp_twd: add runtime registration support
      ARM: local timers: introduce a new registration interface
      ARM: smp_twd: make local_timer_stop a symbol instead of a #define
      ARM: mach-shmobile: default to no earlytimer
      ...

commit 149c24151e8577b2a033639722dc5734de5e6eaf
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Jan 18 15:59:45 2012 +0000

    ARM: SMP: use a timing out completion for cpu hotplug
    
    Rather than open-coding the jiffy-based wait, and polling for the
    secondary CPU to come online, use a completion instead.  This
    removes the need to poll, instead we will be notified when the
    secondary CPU has initialized.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 57db122a4f62..2b26dca2168b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -58,6 +58,8 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 };
 
+static DECLARE_COMPLETION(cpu_running);
+
 int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
@@ -98,20 +100,12 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 */
 	ret = boot_secondary(cpu, idle);
 	if (ret == 0) {
-		unsigned long timeout;
-
 		/*
 		 * CPU was successfully started, wait for it
 		 * to come online or time out.
 		 */
-		timeout = jiffies + HZ;
-		while (time_before(jiffies, timeout)) {
-			if (cpu_online(cpu))
-				break;
-
-			udelay(10);
-			barrier();
-		}
+		wait_for_completion_timeout(&cpu_running,
+						 msecs_to_jiffies(1000));
 
 		if (!cpu_online(cpu)) {
 			pr_crit("CPU%u: failed to come online\n", cpu);
@@ -300,9 +294,10 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * OK, now it's safe to let the boot CPU continue.  Wait for
 	 * the CPU migration code to notice that the CPU is online
-	 * before we continue.
+	 * before we continue - which happens after __cpu_up returns.
 	 */
 	set_cpu_online(cpu, true);
+	complete(&cpu_running);
 
 	/*
 	 * Setup the percpu timer for this CPU.

commit d45785929f1248d2e769f959f180f0504e326622
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Jan 10 23:38:25 2012 +0000

    ARM: local timers: make the runtime registration interface mandatory
    
    Remove all traces of the compile-time local timer interface,
    and make the runtime selection mandatory.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 89bb02c90ae1..1ad84a6c9bfb 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -246,6 +246,8 @@ static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
 	store_cpu_topology(cpuid);
 }
 
+static void percpu_timer_setup(void);
+
 /*
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.
@@ -472,21 +474,7 @@ int local_timer_register(struct local_timer_ops *ops)
 }
 #endif
 
-int __cpuinit __attribute__ ((weak)) local_timer_setup(struct clock_event_device *clk)
-{
-	if (lt_ops)
-		return lt_ops->setup(clk);
-
-	return -ENXIO;
-}
-
-void __attribute__ ((weak)) local_timer_stop(struct clock_event_device *clk)
-{
-	if (lt_ops)
-		lt_ops->stop(clk);
-}
-
-void __cpuinit percpu_timer_setup(void)
+static void __cpuinit percpu_timer_setup(void)
 {
 	unsigned int cpu = smp_processor_id();
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
@@ -494,7 +482,7 @@ void __cpuinit percpu_timer_setup(void)
 	evt->cpumask = cpumask_of(cpu);
 	evt->broadcast = smp_timer_broadcast;
 
-	if (local_timer_setup(evt))
+	if (!lt_ops || lt_ops->setup(evt))
 		broadcast_timer_setup(evt);
 }
 
@@ -509,7 +497,8 @@ static void percpu_timer_stop(void)
 	unsigned int cpu = smp_processor_id();
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
 
-	local_timer_stop(evt);
+	if (lt_ops)
+		lt_ops->stop(evt);
 }
 #endif
 

commit 0ef330e10dcdbca8f4566e9eaf77015f8ce039d3
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Jan 10 19:26:45 2012 +0000

    ARM: local timers: introduce a new registration interface
    
    In order to switch to a runtime selectable local timer,
    add a registration interface that timer drivers can use to
    register to the core.
    
    local_timer_setup() and local_timer_stop() are made weak symbols
    in order not to break existing setups.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index cdeb727527d3..89bb02c90ae1 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -459,6 +459,33 @@ static void __cpuinit broadcast_timer_setup(struct clock_event_device *evt)
 	clockevents_register_device(evt);
 }
 
+static struct local_timer_ops *lt_ops;
+
+#ifdef CONFIG_LOCAL_TIMERS
+int local_timer_register(struct local_timer_ops *ops)
+{
+	if (lt_ops)
+		return -EBUSY;
+
+	lt_ops = ops;
+	return 0;
+}
+#endif
+
+int __cpuinit __attribute__ ((weak)) local_timer_setup(struct clock_event_device *clk)
+{
+	if (lt_ops)
+		return lt_ops->setup(clk);
+
+	return -ENXIO;
+}
+
+void __attribute__ ((weak)) local_timer_stop(struct clock_event_device *clk)
+{
+	if (lt_ops)
+		lt_ops->stop(clk);
+}
+
 void __cpuinit percpu_timer_setup(void)
 {
 	unsigned int cpu = smp_processor_id();

commit 5fbd036b552f633abb394a319f7c62a5c86a9cd7
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Dec 15 17:09:22 2011 +0100

    sched: Cleanup cpu_active madness
    
    Stepan found:
    
    CPU0            CPUn
    
    _cpu_up()
      __cpu_up()
    
                    boostrap()
                      notify_cpu_starting()
                      set_cpu_online()
                      while (!cpu_active())
                        cpu_relax()
    
    <PREEMPT-out>
    
    smp_call_function(.wait=1)
      /* we find cpu_online() is true */
      arch_send_call_function_ipi_mask()
    
      /* wait-forever-more */
    
    <PREEMPT-in>
                      local_irq_enable()
    
      cpu_notify(CPU_ONLINE)
        sched_cpu_active()
          set_cpu_active()
    
    Now the purpose of cpu_active is mostly with bringing down a cpu, where
    we mark it !active to avoid the load-balancer from moving tasks to it
    while we tear down the cpu. This is required because we only update the
    sched_domain tree after we brought the cpu-down. And this is needed so
    that some tasks can still run while we bring it down, we just don't want
    new tasks to appear.
    
    On cpu-up however the sched_domain tree doesn't yet include the new cpu,
    so its invisible to the load-balancer, regardless of the active state.
    So instead of setting the active state after we boot the new cpu (and
    consequently having to wait for it before enabling interrupts) set the
    cpu active before we set it online and avoid the whole mess.
    
    Reported-by: Stepan Moskovchenko <stepanm@codeaurora.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1323965362.18942.71.camel@twins
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index cdeb727527d3..d616ed51e7a7 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -295,13 +295,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 */
 	percpu_timer_setup();
 
-	while (!cpu_active(cpu))
-		cpu_relax();
-
-	/*
-	 * cpu_active bit is set, so it's safe to enalbe interrupts
-	 * now.
-	 */
 	local_irq_enable();
 	local_fiq_enable();
 

commit eb50439b92b6298bf209a982f295ba9c0f7cb30b
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Jan 20 12:01:12 2012 +0100

    ARM: 7293/1: logical_cpu_map: decouple CPU mapping from SMP
    
    It turns out that the logical CPU mapping is useful even when !CONFIG_SMP
    for manipulation of devices like interrupt and power controllers when
    running a UP kernel on a CPU other than 0. This can happen when kexecing
    a UP image from an SMP kernel.
    
    In the future, multi-cluster systems running AMP configurations will
    require something similar for mapping cluster IDs, so it makes sense to
    decouple this logic in preparation for this support.
    
    Acked-by: Yang Bai <hamo.by@gmail.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Reported-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 26cdc494ee9b..cdeb727527d3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -233,20 +233,6 @@ void __ref cpu_die(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
-int __cpu_logical_map[NR_CPUS];
-
-void __init smp_setup_processor_id(void)
-{
-	int i;
-	u32 cpu = is_smp() ? read_cpuid_mpidr() & 0xff : 0;
-
-	cpu_logical_map(0) = cpu;
-	for (i = 1; i < NR_CPUS; ++i)
-		cpu_logical_map(i) = i == cpu ? 0 : i;
-
-	printk(KERN_INFO "Booting Linux on physical CPU %d\n", cpu);
-}
-
 /*
  * Called by both boot and secondaries to move global data into
  * per-processor storage.

commit 7deabca0acfe02b8e18f59a4c95676012f49a304
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jan 19 15:20:58 2012 +0000

    ARM: fix rcu stalls on SMP platforms
    
    We can stall RCU processing on SMP platforms if a CPU sits in its idle
    loop for a long time.  This happens because we don't call irq_enter()
    and irq_exit() around generic_smp_call_function_interrupt() and
    friends.  Add the necessary calls, and remove the one from within
    ipi_timer(), so that they're all in a common place.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 57db122a4f62..26cdc494ee9b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -443,9 +443,7 @@ static DEFINE_PER_CPU(struct clock_event_device, percpu_clockevent);
 static void ipi_timer(void)
 {
 	struct clock_event_device *evt = &__get_cpu_var(percpu_clockevent);
-	irq_enter();
 	evt->event_handler(evt);
-	irq_exit();
 }
 
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
@@ -548,7 +546,9 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 
 	switch (ipinr) {
 	case IPI_TIMER:
+		irq_enter();
 		ipi_timer();
+		irq_exit();
 		break;
 
 	case IPI_RESCHEDULE:
@@ -556,15 +556,21 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		break;
 
 	case IPI_CALL_FUNC:
+		irq_enter();
 		generic_smp_call_function_interrupt();
+		irq_exit();
 		break;
 
 	case IPI_CALL_FUNC_SINGLE:
+		irq_enter();
 		generic_smp_call_function_single_interrupt();
+		irq_exit();
 		break;
 
 	case IPI_CPU_STOP:
+		irq_enter();
 		ipi_cpu_stop(cpu);
+		irq_exit();
 		break;
 
 	default:

commit 02b73e2e9c288cbbb6ec96bef628cf08e29824c4
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jun 6 15:49:23 2011 +0100

    ARM: stop: execute platform callback from cpu_stop code
    
    Sending IPI_CPU_STOP to a CPU causes it to execute a busy cpu_relax
    loop forever. This makes it impossible to kexec successfully on an SMP
    system since the secondary CPUs do not reset.
    
    This patch adds a callback to platform_cpu_kill, defined when
    CONFIG_HOTPLUG_CPU=y, from the ipi_cpu_stop handling code. This function
    currently just returns 1 on all platforms that define it but allows them
    to do something more sophisticated in the future.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 76ff28d87bf3..57db122a4f62 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -522,6 +522,10 @@ static void ipi_cpu_stop(unsigned int cpu)
 	local_fiq_disable();
 	local_irq_disable();
 
+#ifdef CONFIG_HOTPLUG_CPU
+	platform_cpu_kill(cpu);
+#endif
+
 	while (1)
 		cpu_relax();
 }

commit 4e8ee7de227e3ab9a72040b448ad728c5428a042
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Nov 23 12:26:25 2011 +0000

    ARM: SMP: use idmap_pgd for mapping MMU enable during secondary booting
    
    The ARM SMP booting code allocates a temporary set of page tables
    containing an identity mapping of the kernel image and provides this
    to secondary CPUs for initial booting.
    
    In reality, we only need to include the __turn_mmu_on function in the
    identity mapping since the rest of the kernel is executing from virtual
    addresses after this point.
    
    This patch adds __turn_mmu_on to the .idmap.text section, allowing the
    SMP booting code to use the idmap_pgd directly and not have to populate
    its own set of page table.
    
    As a result of this patch, we can make the identity_mapping_add function
    static (since it is only used within mm/idmap.c) and also remove the
    identity_mapping_del function. The identity map population is moved to
    an early initcall so that it is setup in time for secondary CPU bringup.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8afadda37459..76ff28d87bf3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -62,7 +62,6 @@ int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
 	struct task_struct *idle = ci->idle;
-	pgd_t *pgd;
 	int ret;
 
 	/*
@@ -84,30 +83,12 @@ int __cpuinit __cpu_up(unsigned int cpu)
 		init_idle(idle, cpu);
 	}
 
-	/*
-	 * Allocate initial page tables to allow the new CPU to
-	 * enable the MMU safely.  This essentially means a set
-	 * of our "standard" page tables, with the addition of
-	 * a 1:1 mapping for the physical address of the kernel.
-	 */
-	pgd = pgd_alloc(&init_mm);
-	if (!pgd)
-		return -ENOMEM;
-
-	if (PHYS_OFFSET != PAGE_OFFSET) {
-#ifndef CONFIG_HOTPLUG_CPU
-		identity_mapping_add(pgd, __pa(__init_begin), __pa(__init_end));
-#endif
-		identity_mapping_add(pgd, __pa(_stext), __pa(_etext));
-		identity_mapping_add(pgd, __pa(_sdata), __pa(_edata));
-	}
-
 	/*
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
-	secondary_data.pgdir = virt_to_phys(pgd);
+	secondary_data.pgdir = virt_to_phys(idmap_pgd);
 	secondary_data.swapper_pg_dir = virt_to_phys(swapper_pg_dir);
 	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
 	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
@@ -143,16 +124,6 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	secondary_data.stack = NULL;
 	secondary_data.pgdir = 0;
 
-	if (PHYS_OFFSET != PAGE_OFFSET) {
-#ifndef CONFIG_HOTPLUG_CPU
-		identity_mapping_del(pgd, __pa(__init_begin), __pa(__init_end));
-#endif
-		identity_mapping_del(pgd, __pa(_stext), __pa(_etext));
-		identity_mapping_del(pgd, __pa(_sdata), __pa(_edata));
-	}
-
-	pgd_free(&init_mm, pgd);
-
 	return ret;
 }
 

commit 8903826d0cd99aed9267e792d38284cf3092042b
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Sep 30 11:43:29 2011 +0100

    ARM: idmap: populate identity map pgd at init time using .init.text
    
    When disabling and re-enabling the MMU, it is necessary to take out an
    identity mapping for the code that manipulates the SCTLR in order to
    avoid it disappearing from under our feet. This is useful when soft
    rebooting and returning from CPU suspend.
    
    This patch allocates a set of page tables during boot and populates them
    with an identity mapping for the .idmap.text section. This means that
    users of the identity map do not need to manage their own pgd and can
    instead annotate their functions with __idmap or, in the case of assembly
    code, place them in the correct section.
    
    Acked-by: Dave Martin <dave.martin@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Lorenzo Pieralisi <Lorenzo.Pieralisi@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ef5640b9e218..8afadda37459 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -31,6 +31,7 @@
 #include <asm/cpu.h>
 #include <asm/cputype.h>
 #include <asm/exception.h>
+#include <asm/idmap.h>
 #include <asm/topology.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>

commit 1fdb24e969110fafea36d3b393bea438f702c87f
Merge: f362f98e7c44 531a6a941745
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 28 12:02:27 2011 -0700

    Merge branch 'devel-stable' of http://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm
    
    * 'devel-stable' of http://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm: (178 commits)
      ARM: 7139/1: fix compilation with CONFIG_ARM_ATAG_DTB_COMPAT and large TEXT_OFFSET
      ARM: gic, local timers: use the request_percpu_irq() interface
      ARM: gic: consolidate PPI handling
      ARM: switch from NO_MACH_MEMORY_H to NEED_MACH_MEMORY_H
      ARM: mach-s5p64x0: remove mach/memory.h
      ARM: mach-s3c64xx: remove mach/memory.h
      ARM: plat-mxc: remove mach/memory.h
      ARM: mach-prima2: remove mach/memory.h
      ARM: mach-zynq: remove mach/memory.h
      ARM: mach-bcmring: remove mach/memory.h
      ARM: mach-davinci: remove mach/memory.h
      ARM: mach-pxa: remove mach/memory.h
      ARM: mach-ixp4xx: remove mach/memory.h
      ARM: mach-h720x: remove mach/memory.h
      ARM: mach-vt8500: remove mach/memory.h
      ARM: mach-s5pc100: remove mach/memory.h
      ARM: mach-tegra: remove mach/memory.h
      ARM: plat-tcc: remove mach/memory.h
      ARM: mach-mmp: remove mach/memory.h
      ARM: mach-cns3xxx: remove mach/memory.h
      ...
    
    Fix up mostly pretty trivial conflicts in:
     - arch/arm/Kconfig
     - arch/arm/include/asm/localtimer.h
     - arch/arm/kernel/Makefile
     - arch/arm/mach-shmobile/board-ap4evb.c
     - arch/arm/mach-u300/core.c
     - arch/arm/mm/dma-mapping.c
     - arch/arm/mm/proc-v7.S
     - arch/arm/plat-omap/Kconfig
    largely due to some CONFIG option renaming (ie CONFIG_PM_SLEEP ->
    CONFIG_ARM_CPU_SUSPEND for the arm-specific suspend code etc) and
    addition of NEED_MACH_MEMORY_H next to HAVE_IDE.

commit 3cfef9524677a4ecb392d6fbffe6ebce6302f1d4
Merge: 982653009b88 68cc3990a545
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 26 16:17:32 2011 +0200

    Merge branch 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      rtmutex: Add missing rcu_read_unlock() in debug_rt_mutex_print_deadlock()
      lockdep: Comment all warnings
      lib: atomic64: Change the type of local lock to raw_spinlock_t
      locking, lib/atomic64: Annotate atomic64_lock::lock as raw
      locking, x86, iommu: Annotate qi->q_lock as raw
      locking, x86, iommu: Annotate irq_2_ir_lock as raw
      locking, x86, iommu: Annotate iommu->register_lock as raw
      locking, dma, ipu: Annotate bank_lock as raw
      locking, ARM: Annotate low level hw locks as raw
      locking, drivers/dca: Annotate dca_lock as raw
      locking, powerpc: Annotate uic->lock as raw
      locking, x86: mce: Annotate cmci_discover_lock as raw
      locking, ACPI: Annotate c3_lock as raw
      locking, oprofile: Annotate oprofilefs lock as raw
      locking, video: Annotate vga console lock as raw
      locking, latencytop: Annotate latency_lock as raw
      locking, timer_stats: Annotate table_lock as raw
      locking, rwsem: Annotate inner lock as raw
      locking, semaphores: Annotate inner lock as raw
      locking, sched: Annotate thread_group_cputimer as raw
      ...
    
    Fix up conflicts in kernel/posix-cpu-timers.c manually: making
    cputimer->cputime a raw lock conflicted with the ABBA fix in commit
    bcd5cff7216f ("cputimer: Cure lock inversion").

commit bdf4e9482360a3ddc1619efbd5d1c928ede8c3fa
Merge: 06afb1a087d4 eb0474544bc1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 25 08:19:59 2011 +0100

    Merge branch 'misc' into for-linus
    
    Conflicts:
            arch/arm/mach-integrator/integrator_ap.c

commit eb0474544bc16a9dab53b26abd846e86ba814eb1
Author: Thomas Gleinxer <tglx@linutronix.de>
Date:   Fri Oct 14 12:44:41 2011 +0100

    ARM: 7133/1: SMP: fix per cpu timer setup before the cpu is marked online
    
    The problem is related to the early enabling of interrupts and the
    per cpu timer setup before the cpu is marked online. This doesn't
    need to be done in order to call calibrate_delay().
    
    calibrate_delay() monitors jiffies, which are updated from the CPU
    which is waiting for the new CPU to set the online bit.
    
    So simply calibrate_delay() can be called on the new CPU just from
    the interrupt disabled region and move the local timer setup after
    stored the cpu data and before enabling interrupts.
    
    This solves both the cpu_online vs. cpu_active problem and the
    affinity setting of the per cpu timers.
    
    Signed-off-by: Thomas Gleinxer <tglx@linutronix.de>
    Signed-off-by: Kukjin Kim <kgene.kim@samsung.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d88ff0230e82..697e9a8cbdd8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -301,17 +301,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 */
 	platform_secondary_init(cpu);
 
-	/*
-	 * Enable local interrupts.
-	 */
 	notify_cpu_starting(cpu);
-	local_irq_enable();
-	local_fiq_enable();
-
-	/*
-	 * Setup the percpu timer for this CPU.
-	 */
-	percpu_timer_setup();
 
 	calibrate_delay();
 
@@ -323,9 +313,22 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 * before we continue.
 	 */
 	set_cpu_online(cpu, true);
+
+	/*
+	 * Setup the percpu timer for this CPU.
+	 */
+	percpu_timer_setup();
+
 	while (!cpu_active(cpu))
 		cpu_relax();
 
+	/*
+	 * cpu_active bit is set, so it's safe to enalbe interrupts
+	 * now.
+	 */
+	local_irq_enable();
+	local_fiq_enable();
+
 	/*
 	 * OK, it's off to the idle thread for us
 	 */

commit 28af690a284dfcb627bd69d0963db1c0f412cb8c
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Jul 22 12:52:37 2011 +0100

    ARM: gic, local timers: use the request_percpu_irq() interface
    
    This patch remove the hardcoded link between local timers and PPIs,
    and convert the PPI users (TWD, MCT and MSM timers) to the new
    *_percpu_irq interface. Also some collateral cleanup
    (local_timer_ack() is gone, and the interrupt handler is strictly
    private to each driver).
    
    PPIs are now useable for more than just the local timers.
    
    Additional testing by David Brown (msm8250 and msm8660) and
    Shawn Guo (imx6q).
    
    Cc: David Brown <davidb@codeaurora.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: David Brown <davidb@codeaurora.org>
    Tested-by: David Brown <davidb@codeaurora.org>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 917ed2fa4e4c..a96c08cd6125 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -473,20 +473,6 @@ static void ipi_timer(void)
 	irq_exit();
 }
 
-#ifdef CONFIG_LOCAL_TIMERS
-irqreturn_t percpu_timer_handler(int irq, void *dev_id)
-{
-	struct clock_event_device *evt = &__get_cpu_var(percpu_clockevent);
-
-	if (local_timer_ack()) {
-		evt->event_handler(evt);
-		return IRQ_HANDLED;
-	}
-
-	return IRQ_NONE;
-}
-#endif
-
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 static void smp_timer_broadcast(const struct cpumask *mask)
 {
@@ -537,7 +523,7 @@ static void percpu_timer_stop(void)
 	unsigned int cpu = smp_processor_id();
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
 
-	evt->set_mode(CLOCK_EVT_MODE_UNUSED, evt);
+	local_timer_stop(evt);
 }
 #endif
 

commit 292b293ceef2eda1f96f0c90b96e954d7bdabd1c
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Jul 20 16:24:14 2011 +0100

    ARM: gic: consolidate PPI handling
    
    PPI handling is a bit of an odd beast. It uses its own low level
    handling code and is hardwired to the local timers (hence lacking
    a registration interface).
    
    Instead, switch the low handling to the normal SPI handling code.
    PPIs are handled by the handle_percpu_devid_irq flow.
    
    This also allows the removal of some duplicated code.
    
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: David Brown <davidb@codeaurora.org>
    Cc: Bryan Huntsman <bryanh@codeaurora.org>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: David Brown <davidb@codeaurora.org>
    Tested-by: David Brown <davidb@codeaurora.org>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 35417d0fb8ab..917ed2fa4e4c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -457,10 +457,6 @@ u64 smp_irq_stat_cpu(unsigned int cpu)
 	for (i = 0; i < NR_IPI; i++)
 		sum += __get_irq_stat(cpu, ipi_irqs[i]);
 
-#ifdef CONFIG_LOCAL_TIMERS
-	sum += __get_irq_stat(cpu, local_timer_irqs);
-#endif
-
 	return sum;
 }
 
@@ -478,34 +474,16 @@ static void ipi_timer(void)
 }
 
 #ifdef CONFIG_LOCAL_TIMERS
-asmlinkage void __exception_irq_entry do_local_timer(struct pt_regs *regs)
-{
-	handle_local_timer(regs);
-}
-
-void handle_local_timer(struct pt_regs *regs)
+irqreturn_t percpu_timer_handler(int irq, void *dev_id)
 {
-	struct pt_regs *old_regs = set_irq_regs(regs);
-	int cpu = smp_processor_id();
+	struct clock_event_device *evt = &__get_cpu_var(percpu_clockevent);
 
 	if (local_timer_ack()) {
-		__inc_irq_stat(cpu, local_timer_irqs);
-		ipi_timer();
+		evt->event_handler(evt);
+		return IRQ_HANDLED;
 	}
 
-	set_irq_regs(old_regs);
-}
-
-void show_local_irqs(struct seq_file *p, int prec)
-{
-	unsigned int cpu;
-
-	seq_printf(p, "%*s: ", prec, "LOC");
-
-	for_each_present_cpu(cpu)
-		seq_printf(p, "%10u ", __get_irq_stat(cpu, local_timer_irqs));
-
-	seq_printf(p, " Local timer interrupts\n");
+	return IRQ_NONE;
 }
 #endif
 

commit 5a567d78c437e3be1c512734cdfe64b4ae6b82d7
Author: Jamie Iles <jamie@jamieiles.com>
Date:   Sat Oct 8 11:20:42 2011 +0100

    ARM: 7115/4: move __exception and friends to asm/exception.h
    
    The definition of __exception_irq_entry for
    CONFIG_FUNCTION_GRAPH_TRACER=y needs linux/ftrace.h, but this creates a
    circular dependency with it's current home in asm/system.h. Create
    asm/exception.h and update all current users.
    
    v4:     - rebase to rmk/for-next
    v3:     - remove redundant includes of linux/ftrace.h
    v2:     - document the usage restricitions of __exception*
    
    Cc: Zoltan Devai <zdevai@gmail.com>
    Signed-off-by: Jamie Iles <jamie@jamieiles.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 0949007d09a8..35417d0fb8ab 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -16,7 +16,6 @@
 #include <linux/cache.h>
 #include <linux/profile.h>
 #include <linux/errno.h>
-#include <linux/ftrace.h>
 #include <linux/mm.h>
 #include <linux/err.h>
 #include <linux/cpu.h>
@@ -31,6 +30,7 @@
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
+#include <asm/exception.h>
 #include <asm/topology.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>

commit 0af8aa0069e43f90d59666510342c05e97d8c4b8
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Thu Oct 6 15:19:14 2011 +0100

    ARM: 7124/1: smp: Add a localtimer handler callable from C code
    
    In order to be able to handle localtimer directly from C code instead of
    assembly code, introduce handle_local_timer(), which is modeled after
    handle_IRQ().
    
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 2e49f1883fe9..0949007d09a8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -479,6 +479,11 @@ static void ipi_timer(void)
 
 #ifdef CONFIG_LOCAL_TIMERS
 asmlinkage void __exception_irq_entry do_local_timer(struct pt_regs *regs)
+{
+	handle_local_timer(regs);
+}
+
+void handle_local_timer(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	int cpu = smp_processor_id();

commit 0b5a1b95dcdfa451125132d5ce3f79a27ffb0950
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Thu Oct 6 15:18:14 2011 +0100

    ARM: 7123/1: smp: Add an IPI handler callable from C code
    
    In order to be able to handle IPI directly from C code instead of
    assembly code, introduce handle_IPI(), which is modeled after handle_IRQ().
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3f12ce9b0796..2e49f1883fe9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -586,6 +586,11 @@ static void ipi_cpu_stop(unsigned int cpu)
  * Main handler for inter-processor interrupts
  */
 asmlinkage void __exception_irq_entry do_IPI(int ipinr, struct pt_regs *regs)
+{
+	handle_IPI(ipinr, regs);
+}
+
+void handle_IPI(int ipinr, struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct pt_regs *old_regs = set_irq_regs(regs);

commit d6257288c4052465feeff7e283e35ec0ed06ca03
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Aug 23 22:19:29 2011 +0100

    ARM: 7060/1: smp: populate logical CPU mapping during boot
    
    To allow booting Linux on a CPU with physical ID != 0, we need to
    provide a mapping from the logical CPU number to the physical CPU
    number.
    
    This patch adds such a mapping and populates it during boot.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 62775c5c5ba0..3f12ce9b0796 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -40,6 +40,7 @@
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
+#include <asm/smp_plat.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -260,6 +261,20 @@ void __ref cpu_die(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
+int __cpu_logical_map[NR_CPUS];
+
+void __init smp_setup_processor_id(void)
+{
+	int i;
+	u32 cpu = is_smp() ? read_cpuid_mpidr() & 0xff : 0;
+
+	cpu_logical_map(0) = cpu;
+	for (i = 1; i < NR_CPUS; ++i)
+		cpu_logical_map(i) = i == cpu ? 0 : i;
+
+	printk(KERN_INFO "Booting Linux on physical CPU %d\n", cpu);
+}
+
 /*
  * Called by both boot and secondaries to move global data into
  * per-processor storage.

commit c9018aab8eee24b993c12c7aff7fc99d3d73f298
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Mon Aug 8 13:21:59 2011 +0100

    ARM: 7011/1: Add ARM cpu topology definition
    
    The affinity between ARM processors is defined in the MPIDR register.
    We can identify which processors are in the same cluster,
    and which ones have performance interdependency. We can define the
    cpu topology of ARM platform, that is then used by sched_mc and sched_smt.
    
    The default state of sched_mc and sched_smt config is disable.
    When enabled, the behavior of the scheduler can be modified with
    sched_mc_power_savings and sched_smt_power_savings sysfs interfaces.
    
    Changes since v4 :
    *  Remove unnecessary parentheses and blank lines
    
    Changes since v3 :
    * Update the format of printk message
    * Remove blank line
    
    Changes since v2 :
    * Update the commit message and some comments
    
    Changes since v1 :
    * Update the commit message
    * Add read_cpuid_mpidr in arch/arm/include/asm/cputype.h
    * Modify header of arch/arm/kernel/topology.c
    * Modify tests and manipulation of MPIDR's bitfields
    * Modify the place and dependancy of the config
    * Modify Noop functions
    
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Amit Kucheria <amit.kucheria@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d88ff0230e82..62775c5c5ba0 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -31,6 +31,7 @@
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
+#include <asm/topology.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
@@ -268,6 +269,8 @@ static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
 	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
 
 	cpu_info->loops_per_jiffy = loops_per_jiffy;
+
+	store_cpu_topology(cpuid);
 }
 
 /*
@@ -358,6 +361,8 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 {
 	unsigned int ncores = num_possible_cpus();
 
+	init_cpu_topology();
+
 	smp_store_cpu_info(smp_processor_id());
 
 	/*

commit bd31b85960a7fcb2d7ede216460b8da71a88411c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 3 08:44:46 2009 -0500

    locking, ARM: Annotate low level hw locks as raw
    
    Annotate the low level hardware locks which must not be preempted.
    
    In mainline this change documents the low level nature of
    the lock - otherwise there's no functional difference. Lockdep
    and Sparse checking will work as usual.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d88ff0230e82..4e76e0cf09fb 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -538,7 +538,7 @@ static void percpu_timer_stop(void)
 }
 #endif
 
-static DEFINE_SPINLOCK(stop_lock);
+static DEFINE_RAW_SPINLOCK(stop_lock);
 
 /*
  * ipi_cpu_stop - handle IPI from smp_send_stop()
@@ -547,10 +547,10 @@ static void ipi_cpu_stop(unsigned int cpu)
 {
 	if (system_state == SYSTEM_BOOTING ||
 	    system_state == SYSTEM_RUNNING) {
-		spin_lock(&stop_lock);
+		raw_spin_lock(&stop_lock);
 		printk(KERN_CRIT "CPU%u: stopping\n", cpu);
 		dump_stack();
-		spin_unlock(&stop_lock);
+		raw_spin_unlock(&stop_lock);
 	}
 
 	set_cpu_online(cpu, false);

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 167e3cbe1f2f..d88ff0230e82 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -27,7 +27,7 @@
 #include <linux/clockchips.h>
 #include <linux/completion.h>
 
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>

commit 06f365acef5ca54fd5708a0d853c4a89609536f1
Merge: 4348810a241a 022ae537b23c 30891c90d811 e7d59db91a34 e2f81844efa2 4cde7e0dca98 7f294e4983b6 29cb3cd208dd 19dad35fe0f1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 22 23:08:48 2011 +0100

    Merge branches 'btc', 'dma', 'entry', 'fixes', 'linker-layout', 'misc', 'mmci', 'suspend' and 'vfp' into for-next

commit 7fa22bd5460bb2021729fa5a1012c60b9b3a56e2
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Thu Jul 7 01:56:51 2011 +0100

    ARM: 6993/1: platsmp: Allow secondary cpu hotplug with maxcpus=1
    
    If an ARM system has multiple cpus in the same socket and the
    kernel is booted with maxcpus=1, secondary cpus are possible but
    not present due to how platform_smp_prepare_cpus() is called.
    Since most typical ARM processors don't actually support physical
    hotplug, initialize the present map to be equal to the possible
    map in generic ARM SMP code. Also, always call
    platform_smp_prepare_cpus() as long as max_cpus is non-zero (0
    means no SMP) to allow platform code to do any SMP setup.
    
    After applying this patch it's possible to boot an ARM system
    with maxcpus=1 on the command line and then hotplug in secondary
    cpus via sysfs. This is more in line with how x86 does things.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: David Brown <davidb@codeaurora.org>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Srinidhi Kasagar <srinidhi.kasagar@stericsson.com>
    Cc: Linus Walleij <linus.walleij@stericsson.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 344e52b16c8c..0ffcf5c0da43 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -361,14 +361,21 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 	 */
 	if (max_cpus > ncores)
 		max_cpus = ncores;
-
-	if (max_cpus > 1) {
+	if (ncores > 1 && max_cpus) {
 		/*
 		 * Enable the local timer or broadcast device for the
 		 * boot CPU, but only if we have more than one CPU.
 		 */
 		percpu_timer_setup();
 
+		/*
+		 * Initialise the present map, which describes the set of CPUs
+		 * actually populated at the present time. A platform should
+		 * re-initialize the map in platform_smp_prepare_cpus() if
+		 * present != possible (e.g. physical hotplug).
+		 */
+		init_cpu_present(&cpu_possible_map);
+
 		/*
 		 * Initialise the SCU if there are more than one CPU
 		 * and let them know where to start.

commit 573619d165b85152eeddd3b3871002c48cd94e42
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jun 20 16:46:01 2011 +0100

    ARM: SMP: wait for CPU to be marked active
    
    When we bring a CPU online, we should wait for it to become active
    before entering the idle thread, so we know that the scheduler and
    thread migration is going to work.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 344e52b16c8c..e7f92a4321f3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -318,9 +318,13 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	smp_store_cpu_info(cpu);
 
 	/*
-	 * OK, now it's safe to let the boot CPU continue
+	 * OK, now it's safe to let the boot CPU continue.  Wait for
+	 * the CPU migration code to notice that the CPU is online
+	 * before we continue.
 	 */
 	set_cpu_online(cpu, true);
+	while (!cpu_active(cpu))
+		cpu_relax();
 
 	/*
 	 * OK, it's off to the idle thread for us

commit d427958a46af24f75d0017c45eadd172273bbf33
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu May 26 11:22:44 2011 +0100

    ARM: 6942/1: mm: make TTBR1 always point to swapper_pg_dir on ARMv6/7
    
    This patch makes TTBR1 point to swapper_pg_dir so that global, kernel
    mappings can be used exclusively on v6 and v7 cores where they are
    needed.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index d439a8f4c078..344e52b16c8c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -105,6 +105,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
 	secondary_data.pgdir = virt_to_phys(pgd);
+	secondary_data.swapper_pg_dir = virt_to_phys(swapper_pg_dir);
 	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
 	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
 

commit 4b60e5f90dec4ae251386f20464336369e962e9c
Merge: e8765afe54b7 667f390bee98 a35d4e587371 4d5336d50a7b 041f10d46f97 be20902ba67d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 23 18:05:10 2011 +0100

    Merge branches 'consolidate-clksrc', 'consolidate-flash', 'consolidate-generic', 'consolidate-smp', 'consolidate-stmp' and 'consolidate-zones' into consolidate

commit 0f7b332f9777819a39a3b325690379a7efef89d1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Apr 3 13:01:30 2011 +0100

    ARM: consolidate SMP cross call implementation
    
    Rather than having each platform class provide a mach/smp.h header for
    smp_cross_call(), arrange for them to register the function with the
    core ARM SMP code instead.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8fe05ad932e4..a0ad0540761f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -376,6 +376,13 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 	}
 }
 
+static void (*smp_cross_call)(const struct cpumask *, unsigned int);
+
+void __init set_smp_cross_call(void (*fn)(const struct cpumask *, unsigned int))
+{
+	smp_cross_call = fn;
+}
+
 void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
 	smp_cross_call(mask, IPI_CALL_FUNC);

commit 9cb5baba5e3acba0994ad899ee908799104c9965
Merge: 7142d17e8f93 693d92a1bbc9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu May 12 09:36:18 2011 +0200

    Merge commit 'v2.6.39-rc7' into sched/core

commit a8d2518c2a7235f0b772c1f1bd30218130e631a7
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Wed Apr 27 01:34:27 2011 +0100

    ARM: 6887/1: Mark broadcast_timer_setup() __cpuinit
    
    This function is only called by percpu_timer_setup() which is
    also __cpuinit marked. Thus it's safe to mark this function as
    __cpuinit as well.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8fe05ad932e4..f29b8a29b174 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -479,7 +479,7 @@ static void broadcast_timer_set_mode(enum clock_event_mode mode,
 {
 }
 
-static void broadcast_timer_setup(struct clock_event_device *evt)
+static void __cpuinit broadcast_timer_setup(struct clock_event_device *evt)
 {
 	evt->name	= "dummy_timer";
 	evt->features	= CLOCK_EVT_FEAT_ONESHOT |

commit 184748cc50b2dceb8287f9fb657eda48ff8fcfe7
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Apr 5 17:23:39 2011 +0200

    sched: Provide scheduler_ipi() callback in response to smp_send_reschedule()
    
    For future rework of try_to_wake_up() we'd like to push part of that
    function onto the CPU the task is actually going to run on.
    
    In order to do so we need a generic callback from the existing scheduler IPI.
    
    This patch introduces such a generic callback: scheduler_ipi() and
    implements it as a NOP.
    
    BenH notes: PowerPC might use this IPI on offline CPUs under rare conditions!
    
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Reviewed-by: Frank Rowand <frank.rowand@am.sony.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20110405152728.744338123@chello.nl

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8fe05ad932e4..7a561eb731ea 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -560,10 +560,7 @@ asmlinkage void __exception_irq_entry do_IPI(int ipinr, struct pt_regs *regs)
 		break;
 
 	case IPI_RESCHEDULE:
-		/*
-		 * nothing more to do - eveything is
-		 * done on the interrupt return path
-		 */
+		scheduler_ipi();
 		break;
 
 	case IPI_CALL_FUNC:

commit af90f10d3826525306c96d423df240210640cb72
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Wed Feb 23 18:53:15 2011 +0100

    ARM: 6759/1: smp: Select local timers vs broadcast timer support runtime
    
    The current code support of dummy timers in absence of local
    timer is compile time. This is an attempt to convert it to runtime
    so that on few SOC version if the local timers aren't supported
    kernel can switch to dummy timers. OMAP4430 ES1.0 does suffer from
    this limitation.
    
    This patch should not have any functional impact on affected
    files.
    
    Cc: Daniel Walker <dwalker@codeaurora.org>
    Cc: Bryan Huntsman <bryanh@codeaurora.org>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Colin Cross <ccross@android.com>
    Cc: Erik Gilling <konkers@android.com>
    Cc: Srinidhi Kasagar <srinidhi.kasagar@stericsson.com>
    Cc: Linus Walleij <linus.walleij@stericsson.com>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: David Brown <davidb@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 4539ebcb089f..8fe05ad932e4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -474,13 +474,12 @@ static void smp_timer_broadcast(const struct cpumask *mask)
 #define smp_timer_broadcast	NULL
 #endif
 
-#ifndef CONFIG_LOCAL_TIMERS
 static void broadcast_timer_set_mode(enum clock_event_mode mode,
 	struct clock_event_device *evt)
 {
 }
 
-static void local_timer_setup(struct clock_event_device *evt)
+static void broadcast_timer_setup(struct clock_event_device *evt)
 {
 	evt->name	= "dummy_timer";
 	evt->features	= CLOCK_EVT_FEAT_ONESHOT |
@@ -492,7 +491,6 @@ static void local_timer_setup(struct clock_event_device *evt)
 
 	clockevents_register_device(evt);
 }
-#endif
 
 void __cpuinit percpu_timer_setup(void)
 {
@@ -502,7 +500,8 @@ void __cpuinit percpu_timer_setup(void)
 	evt->cpumask = cpumask_of(cpu);
 	evt->broadcast = smp_timer_broadcast;
 
-	local_timer_setup(evt);
+	if (local_timer_setup(evt))
+		broadcast_timer_setup(evt);
 }
 
 #ifdef CONFIG_HOTPLUG_CPU

commit 28cdac6690cb113856293bf79b40de33dbd8f974
Merge: 4073723acb9c 36bb94ba36f3
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jan 6 22:33:19 2011 +0000

    Merge branch 'pgt' (early part) into devel

commit 4073723acb9cdcdbe4df9c0e0c376c65d1697e43
Merge: 58daf18cdcab 4ec3eb136345
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jan 6 22:32:52 2011 +0000

    Merge branch 'misc' into devel
    
    Conflicts:
            arch/arm/Kconfig
            arch/arm/common/Makefile
            arch/arm/kernel/Makefile
            arch/arm/kernel/smp.c

commit 58daf18cdcab550262a5f4681e1f1e073e21965a
Merge: aa312be1987d 0af85dda39d9
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Jan 5 18:09:03 2011 +0000

    Merge branch 'clksrc' into devel
    
    Conflicts:
            arch/arm/mach-vexpress/v2m.c
            arch/arm/plat-omap/counter_32k.c
            arch/arm/plat-versatile/Makefile

commit 614dd0585f376a25c638abbed9c5fbd21d7baece
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Nov 21 11:41:57 2010 +0000

    ARM: pgtable: collect up identity mapping functions
    
    We have two places where we create identity mappings - one when we bring
    secondary CPUs online, and one where we setup some mappings for soft-
    reboot.  Combine these two into a single implementation.  Also collect
    the identity mapping deletion function.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 46313805f430..73cef403352a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -68,40 +68,6 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 };
 
-static inline void identity_mapping_add(pgd_t *pgd, unsigned long start,
-	unsigned long end)
-{
-	unsigned long addr, prot;
-	pmd_t *pmd;
-
-	prot = PMD_TYPE_SECT | PMD_SECT_AP_WRITE;
-	if (cpu_architecture() <= CPU_ARCH_ARMv5TEJ && !cpu_is_xscale())
-		prot |= PMD_BIT4;
-
-	for (addr = start & PGDIR_MASK; addr < end;) {
-		pmd = pmd_offset(pgd + pgd_index(addr), addr);
-		pmd[0] = __pmd(addr | prot);
-		addr += SECTION_SIZE;
-		pmd[1] = __pmd(addr | prot);
-		addr += SECTION_SIZE;
-		flush_pmd_entry(pmd);
-	}
-}
-
-static inline void identity_mapping_del(pgd_t *pgd, unsigned long start,
-	unsigned long end)
-{
-	unsigned long addr;
-	pmd_t *pmd;
-
-	for (addr = start & PGDIR_MASK; addr < end; addr += PGDIR_SIZE) {
-		pmd = pmd_offset(pgd + pgd_index(addr), addr);
-		pmd[0] = __pmd(0);
-		pmd[1] = __pmd(0);
-		clean_pmd_entry(pmd);
-	}
-}
-
 int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);

commit 26bbf0b57a0848932f725076bcb1245ca696e8d3
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Nov 21 11:30:36 2010 +0000

    ARM: pgtable: remove L2 cache flushes for SMP page table bring-up
    
    The MMU is always configured to read page tables from the L2 cache
    so there's little point flushing them out of the L2 cache back to
    RAM.  Remove these flushes.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c1959590252..46313805f430 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -85,7 +85,6 @@ static inline void identity_mapping_add(pgd_t *pgd, unsigned long start,
 		pmd[1] = __pmd(addr | prot);
 		addr += SECTION_SIZE;
 		flush_pmd_entry(pmd);
-		outer_clean_range(__pa(pmd), __pa(pmd + 1));
 	}
 }
 
@@ -100,7 +99,6 @@ static inline void identity_mapping_del(pgd_t *pgd, unsigned long start,
 		pmd[0] = __pmd(0);
 		pmd[1] = __pmd(0);
 		clean_pmd_entry(pmd);
-		outer_clean_range(__pa(pmd), __pa(pmd + 1));
 	}
 }
 

commit faabfa0816916b0a7cfc93f6a9be382830658c80
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Dec 20 16:58:19 2010 +0000

    ARM: SMP: ensure frame pointer is reinitialized for soft-CPU hotplug
    
    When we soft-CPU hotplug a CPU, we reset the stack pointer and
    jump back to start_secondary().  This allows us to restart as if
    the CPU was actually reset.
    
    However, we weren't resetting the frame pointer, which could cause
    problems with backtracing.  Reset the frame pointer to zero (which
    means no parent frame) just like the early assembly code also does.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 6d0c66bc434d..5341b0b19701 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -286,6 +286,7 @@ void __ref cpu_die(void)
 	 * to be repeated to undo the effects of taking the CPU offline.
 	 */
 	__asm__("mov	sp, %0\n"
+	"	mov	fp, #0\n"
 	"	b	secondary_start_kernel"
 		:
 		: "r" (task_stack_page(current) + THREAD_SIZE - 8));

commit 03b505eae6a276b8c38b6222694afb6cea10b1cc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Dec 20 14:44:32 2010 +0000

    ARM: SMP: split out software TLB maintainence broadcasting
    
    smp.c is becoming too large, so split out the TLB maintainence
    broadcasting into a separate smp_tlb.c file.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 4dc864ef9cdf..6d0c66bc434d 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -38,7 +38,6 @@
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
-#include <asm/smp_plat.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -655,128 +654,3 @@ int setup_profiling_timer(unsigned int multiplier)
 {
 	return -EINVAL;
 }
-
-static void
-on_each_cpu_mask(void (*func)(void *), void *info, int wait,
-		const struct cpumask *mask)
-{
-	preempt_disable();
-
-	smp_call_function_many(mask, func, info, wait);
-	if (cpumask_test_cpu(smp_processor_id(), mask))
-		func(info);
-
-	preempt_enable();
-}
-
-/**********************************************************************/
-
-/*
- * TLB operations
- */
-struct tlb_args {
-	struct vm_area_struct *ta_vma;
-	unsigned long ta_start;
-	unsigned long ta_end;
-};
-
-static inline void ipi_flush_tlb_all(void *ignored)
-{
-	local_flush_tlb_all();
-}
-
-static inline void ipi_flush_tlb_mm(void *arg)
-{
-	struct mm_struct *mm = (struct mm_struct *)arg;
-
-	local_flush_tlb_mm(mm);
-}
-
-static inline void ipi_flush_tlb_page(void *arg)
-{
-	struct tlb_args *ta = (struct tlb_args *)arg;
-
-	local_flush_tlb_page(ta->ta_vma, ta->ta_start);
-}
-
-static inline void ipi_flush_tlb_kernel_page(void *arg)
-{
-	struct tlb_args *ta = (struct tlb_args *)arg;
-
-	local_flush_tlb_kernel_page(ta->ta_start);
-}
-
-static inline void ipi_flush_tlb_range(void *arg)
-{
-	struct tlb_args *ta = (struct tlb_args *)arg;
-
-	local_flush_tlb_range(ta->ta_vma, ta->ta_start, ta->ta_end);
-}
-
-static inline void ipi_flush_tlb_kernel_range(void *arg)
-{
-	struct tlb_args *ta = (struct tlb_args *)arg;
-
-	local_flush_tlb_kernel_range(ta->ta_start, ta->ta_end);
-}
-
-void flush_tlb_all(void)
-{
-	if (tlb_ops_need_broadcast())
-		on_each_cpu(ipi_flush_tlb_all, NULL, 1);
-	else
-		local_flush_tlb_all();
-}
-
-void flush_tlb_mm(struct mm_struct *mm)
-{
-	if (tlb_ops_need_broadcast())
-		on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, mm_cpumask(mm));
-	else
-		local_flush_tlb_mm(mm);
-}
-
-void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
-{
-	if (tlb_ops_need_broadcast()) {
-		struct tlb_args ta;
-		ta.ta_vma = vma;
-		ta.ta_start = uaddr;
-		on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, mm_cpumask(vma->vm_mm));
-	} else
-		local_flush_tlb_page(vma, uaddr);
-}
-
-void flush_tlb_kernel_page(unsigned long kaddr)
-{
-	if (tlb_ops_need_broadcast()) {
-		struct tlb_args ta;
-		ta.ta_start = kaddr;
-		on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1);
-	} else
-		local_flush_tlb_kernel_page(kaddr);
-}
-
-void flush_tlb_range(struct vm_area_struct *vma,
-                     unsigned long start, unsigned long end)
-{
-	if (tlb_ops_need_broadcast()) {
-		struct tlb_args ta;
-		ta.ta_vma = vma;
-		ta.ta_start = start;
-		ta.ta_end = end;
-		on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, mm_cpumask(vma->vm_mm));
-	} else
-		local_flush_tlb_range(vma, start, end);
-}
-
-void flush_tlb_kernel_range(unsigned long start, unsigned long end)
-{
-	if (tlb_ops_need_broadcast()) {
-		struct tlb_args ta;
-		ta.ta_start = start;
-		ta.ta_end = end;
-		on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1);
-	} else
-		local_flush_tlb_kernel_range(start, end);
-}

commit 10034aabca9032246762daaca3152f3e79380ea0
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Dec 20 14:28:02 2010 +0000

    ARM: localtimer: clean up local timer on hot unplug
    
    When a CPU is hot unplugged, the generic tick code cleans up the
    clock event device, but fails to call down to the device's set_mode
    function to actually shut the device down.
    
    To work around this, we've historically had a local_timer_stop()
    callback out of the hotplug code.  However, this adds needless
    complexity when we have the clock event device itself available.
    
    Explicitly call the clock event device's set_mode function with
    CLOCK_EVT_MODE_UNUSED, so that the hardware can be cleanly shutdown
    without any special external callbacks.  When/if the generic code
    is fixed, percpu_timer_stop() can be killed off.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 6afaf6f73069..4dc864ef9cdf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -189,6 +189,8 @@ int __cpuinit __cpu_up(unsigned int cpu)
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
+static void percpu_timer_stop(void);
+
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */
@@ -216,7 +218,7 @@ int __cpu_disable(void)
 	/*
 	 * Stop the local timer for this CPU.
 	 */
-	local_timer_stop();
+	percpu_timer_stop();
 
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU
@@ -539,6 +541,21 @@ void __cpuinit percpu_timer_setup(void)
 	local_timer_setup(evt);
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/*
+ * The generic clock events code purposely does not stop the local timer
+ * on CPU_DEAD/CPU_DEAD_FROZEN hotplug events, so we have to do it
+ * manually here.
+ */
+static void percpu_timer_stop(void)
+{
+	unsigned int cpu = smp_processor_id();
+	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
+
+	evt->set_mode(CLOCK_EVT_MODE_UNUSED, evt);
+}
+#endif
+
 static DEFINE_SPINLOCK(stop_lock);
 
 /*

commit 58613cd1d4f8c2d5f25b6c57ad7fbed80e75a67b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Dec 18 12:34:39 2010 +0000

    ARM: smp: improve CPU bringup failure diagnostics
    
    We used to print a bland error message which gave no clue as to the
    failure when we failed to bring up a secondary CPU.  Resolve this by
    separating the two failure cases.
    
    If boot_secondary() fails, we print a message indicating the returned
    error code from boot_secondary():
            "CPU%u: failed to boot: %d\n", cpu, ret.
    
    However, if boot_secondary() succeeded, but the CPU did not appear to
    mark itself online within the timeout, indicate that it failed to come
    online:
            "CPU%u: failed to come online\n", cpu
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1a1c5e2b3ef9..6afaf6f73069 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -164,8 +164,12 @@ int __cpuinit __cpu_up(unsigned int cpu)
 			barrier();
 		}
 
-		if (!cpu_online(cpu))
+		if (!cpu_online(cpu)) {
+			pr_crit("CPU%u: failed to come online\n", cpu);
 			ret = -EIO;
+		}
+	} else {
+		pr_err("CPU%u: failed to boot: %d\n", cpu, ret);
 	}
 
 	secondary_data.stack = NULL;
@@ -181,14 +185,6 @@ int __cpuinit __cpu_up(unsigned int cpu)
 
 	pgd_free(&init_mm, pgd);
 
-	if (ret) {
-		printk(KERN_CRIT "CPU%u: processor failed to boot\n", cpu);
-
-		/*
-		 * FIXME: We need to clean up the new idle thread. --rmk
-		 */
-	}
-
 	return ret;
 }
 

commit f36d340122ae8744e64af0a92a6f77b97542c0a4
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Nov 30 12:21:30 2010 +0000

    ARM: CPU hotplug: ensure correct ordering of unplug
    
    Don't call idle_task_exit() with interrupts disabled, and ensure
    that we have a memory barrier after interrupts are disabled but
    before signalling that this CPU has shut down.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c81ff9b3732..1a1c5e2b3ef9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -269,9 +269,11 @@ void __ref cpu_die(void)
 {
 	unsigned int cpu = smp_processor_id();
 
-	local_irq_disable();
 	idle_task_exit();
 
+	local_irq_disable();
+	mb();
+
 	/* Tell __cpu_die() that this CPU is now safe to dispose of */
 	complete(&cpu_died);
 

commit 3c030beabf937b1d3b4ecaedfd1fb2f1e2aa0c70
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Nov 30 11:07:35 2010 +0000

    ARM: CPU hotplug: move cpu_killed completion to core code
    
    We always need to wait for the dying CPU to reach a safe state before
    taking it down, irrespective of the requirements of the platform.
    Move the completion code into the ARM SMP hotplug code rather than
    having each platform re-implement this.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index a30c4094db3a..8c81ff9b3732 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -24,6 +24,7 @@
 #include <linux/irq.h>
 #include <linux/percpu.h>
 #include <linux/clockchips.h>
+#include <linux/completion.h>
 
 #include <asm/atomic.h>
 #include <asm/cacheflush.h>
@@ -238,12 +239,20 @@ int __cpu_disable(void)
 	return 0;
 }
 
+static DECLARE_COMPLETION(cpu_died);
+
 /*
  * called on the thread which is asking for a CPU to be shutdown -
  * waits until shutdown has completed, or it is timed out.
  */
 void __cpu_die(unsigned int cpu)
 {
+	if (!wait_for_completion_timeout(&cpu_died, msecs_to_jiffies(5000))) {
+		pr_err("CPU%u: cpu didn't die\n", cpu);
+		return;
+	}
+	printk(KERN_NOTICE "CPU%u: shutdown\n", cpu);
+
 	if (!platform_cpu_kill(cpu))
 		printk("CPU%u: unable to kill\n", cpu);
 }
@@ -263,9 +272,12 @@ void __ref cpu_die(void)
 	local_irq_disable();
 	idle_task_exit();
 
+	/* Tell __cpu_die() that this CPU is now safe to dispose of */
+	complete(&cpu_died);
+
 	/*
 	 * actual CPU shutdown procedure is at least platform (if not
-	 * CPU) specific
+	 * CPU) specific.
 	 */
 	platform_cpu_die(cpu);
 

commit 2c0136dba4e43b0916ccc9ecc7f11e6d6b73f046
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Dec 3 15:00:49 2010 +0000

    ARM: SMP: consolidate trace_hardirqs_off() into common SMP code
    
    All platforms call trace_hardirqs_off() in their secondary startup code,
    so move this into the core SMP code - it doesn't need to be in the
    per-platform code.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index c66f2d3f65d3..a30c4094db3a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -317,6 +317,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 
 	cpu_init();
 	preempt_disable();
+	trace_hardirqs_off();
 
 	/*
 	 * Give the platform a chance to do its own initialisation.

commit 05c74a6cbcfb416286a947668ba32f63d99fe74a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Dec 3 11:09:48 2010 +0000

    ARM: SMP: consolidate the common parts of smp_prepare_cpus()
    
    There is a certain amount of smp_prepare_cpus() which doesn't belong
    in the platform support code - that is, code which is invariant to the
    SMP implementation.  Move this code into arch/arm/kernel/smp.c, and
    add a platform_ prefix to the original function.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 64f2d198c764..c66f2d3f65d3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -281,6 +281,17 @@ void __ref cpu_die(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
+/*
+ * Called by both boot and secondaries to move global data into
+ * per-processor storage.
+ */
+static void __cpuinit smp_store_cpu_info(unsigned int cpuid)
+{
+	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
+
+	cpu_info->loops_per_jiffy = loops_per_jiffy;
+}
+
 /*
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.
@@ -339,17 +350,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	cpu_idle();
 }
 
-/*
- * Called by both boot and secondaries to move global data into
- * per-processor storage.
- */
-void __cpuinit smp_store_cpu_info(unsigned int cpuid)
-{
-	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
-
-	cpu_info->loops_per_jiffy = loops_per_jiffy;
-}
-
 void __init smp_cpus_done(unsigned int max_cpus)
 {
 	int cpu;
@@ -372,6 +372,33 @@ void __init smp_prepare_boot_cpu(void)
 	per_cpu(cpu_data, cpu).idle = current;
 }
 
+void __init smp_prepare_cpus(unsigned int max_cpus)
+{
+	unsigned int ncores = num_possible_cpus();
+
+	smp_store_cpu_info(smp_processor_id());
+
+	/*
+	 * are we trying to boot more cores than exist?
+	 */
+	if (max_cpus > ncores)
+		max_cpus = ncores;
+
+	if (max_cpus > 1) {
+		/*
+		 * Enable the local timer or broadcast device for the
+		 * boot CPU, but only if we have more than one CPU.
+		 */
+		percpu_timer_setup();
+
+		/*
+		 * Initialise the SCU if there are more than one CPU
+		 * and let them know where to start.
+		 */
+		platform_smp_prepare_cpus(max_cpus);
+	}
+}
+
 void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
 	smp_cross_call(mask, IPI_CALL_FUNC);

commit 28e18293cf0f8d23a0950d7b1d2212d11af494dc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Dec 2 09:53:54 2010 +0000

    ARM: SMP: ensure smp_send_stop() waits for CPUs to stop
    
    Wait for CPUs to indicate that they've stopped, after sending the
    stop IPI, rather than blindly continuing on and hoping that they've
    stopped in time.  Print a warning if we fail to stop the other CPUs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1de3e13a42a1..64f2d198c764 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -575,10 +575,22 @@ void smp_send_reschedule(int cpu)
 
 void smp_send_stop(void)
 {
-	cpumask_t mask = cpu_online_map;
-	cpu_clear(smp_processor_id(), mask);
-	if (!cpus_empty(mask))
+	unsigned long timeout;
+
+	if (num_online_cpus() > 1) {
+		cpumask_t mask = cpu_online_map;
+		cpu_clear(smp_processor_id(), mask);
+
 		smp_cross_call(&mask, IPI_CPU_STOP);
+	}
+
+	/* Wait up to one second for other CPUs to stop */
+	timeout = USEC_PER_SEC;
+	while (num_online_cpus() > 1 && timeout--)
+		udelay(1);
+
+	if (num_online_cpus() > 1)
+		pr_warning("SMP: failed to stop secondary CPUs\n");
 }
 
 /*

commit b54992fe1b4bad7b7488d58b8696e4e8974fdab0
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 14:46:46 2010 +0000

    ARM: SMP: collect IPI and local timer IRQs for /proc/stat
    
    The IPI and local timer interrupts weren't being properly accounted
    for in /proc/stat.  Collect them from the irq_stat structure, and
    return their sum.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index fa0c5f6e1587..1de3e13a42a1 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -406,6 +406,21 @@ void show_ipi_list(struct seq_file *p, int prec)
 	}
 }
 
+u64 smp_irq_stat_cpu(unsigned int cpu)
+{
+	u64 sum = 0;
+	int i;
+
+	for (i = 0; i < NR_IPI; i++)
+		sum += __get_irq_stat(cpu, ipi_irqs[i]);
+
+#ifdef CONFIG_LOCAL_TIMERS
+	sum += __get_irq_stat(cpu, local_timer_irqs);
+#endif
+
+	return sum;
+}
+
 /*
  * Timer (local or broadcast) support
  */

commit 4a88abd7b48e8ec8084b1252d0f5ebdab43c2508
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 14:40:29 2010 +0000

    ARM: SMP: provide individual IPI interrupt statistics
    
    This separates out the individual IPI interrupt counts from the
    total IPI count, which allows better visibility of what IPIs are
    being used for.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 269237ed76a0..fa0c5f6e1587 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -382,16 +382,28 @@ void arch_send_call_function_single_ipi(int cpu)
 	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
+static const char *ipi_types[NR_IPI] = {
+#define S(x,s)	[x - IPI_TIMER] = s
+	S(IPI_TIMER, "Timer broadcast interrupts"),
+	S(IPI_RESCHEDULE, "Rescheduling interrupts"),
+	S(IPI_CALL_FUNC, "Function call interrupts"),
+	S(IPI_CALL_FUNC_SINGLE, "Single function call interrupts"),
+	S(IPI_CPU_STOP, "CPU stop interrupts"),
+};
+
 void show_ipi_list(struct seq_file *p, int prec)
 {
-	unsigned int cpu;
+	unsigned int cpu, i;
 
-	seq_printf(p, "%*s: ", prec, "IPI");
+	for (i = 0; i < NR_IPI; i++) {
+		seq_printf(p, "%*s%u: ", prec - 1, "IPI", i);
 
-	for_each_present_cpu(cpu)
-		seq_printf(p, "%10u ", __get_irq_stat(cpu, ipi_irqs));
+		for_each_present_cpu(cpu)
+			seq_printf(p, "%10u ",
+				   __get_irq_stat(cpu, ipi_irqs[i]));
 
-	seq_printf(p, " Inter-processor interrupts\n");
+		seq_printf(p, " %s\n", ipi_types[i]);
+	}
 }
 
 /*
@@ -506,7 +518,8 @@ asmlinkage void __exception do_IPI(int ipinr, struct pt_regs *regs)
 	unsigned int cpu = smp_processor_id();
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	__inc_irq_stat(cpu, ipi_irqs);
+	if (ipinr >= IPI_TIMER && ipinr < IPI_TIMER + NR_IPI)
+		__inc_irq_stat(cpu, ipi_irqs[ipinr - IPI_TIMER]);
 
 	switch (ipinr) {
 	case IPI_TIMER:

commit f13cd4170ee789f63b3c9585c1ae34e028bd549d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 14:33:51 2010 +0000

    ARM: fix /proc/interrupts formatting
    
    As per x86, align the initial column according to how many IRQs we
    have.  Also, provide an english explaination for the 'LOC:' and
    'IPI:' lines.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 65b5ba867805..269237ed76a0 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -382,16 +382,16 @@ void arch_send_call_function_single_ipi(int cpu)
 	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
-void show_ipi_list(struct seq_file *p)
+void show_ipi_list(struct seq_file *p, int prec)
 {
 	unsigned int cpu;
 
-	seq_puts(p, "IPI:");
+	seq_printf(p, "%*s: ", prec, "IPI");
 
 	for_each_present_cpu(cpu)
-		seq_printf(p, " %10u", __get_irq_stat(cpu, ipi_irqs));
+		seq_printf(p, "%10u ", __get_irq_stat(cpu, ipi_irqs));
 
-	seq_putc(p, '\n');
+	seq_printf(p, " Inter-processor interrupts\n");
 }
 
 /*
@@ -421,16 +421,16 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
-void show_local_irqs(struct seq_file *p)
+void show_local_irqs(struct seq_file *p, int prec)
 {
 	unsigned int cpu;
 
-	seq_printf(p, "LOC: ");
+	seq_printf(p, "%*s: ", prec, "LOC");
 
 	for_each_present_cpu(cpu)
 		seq_printf(p, "%10u ", __get_irq_stat(cpu, local_timer_irqs));
 
-	seq_putc(p, '\n');
+	seq_printf(p, " Local timer interrupts\n");
 }
 #endif
 

commit cab8c6f3053c1b147bba825844c8e208f8b3b9f4
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 14:20:41 2010 +0000

    ARM: SMP: move ipi_count into irq_stat structure
    
    Move the ipi_count into irq_stat, which allows the ipi_data structure
    to be entirely removed.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 24131264ec2c..65b5ba867805 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -46,15 +46,6 @@
  */
 struct secondary_data secondary_data;
 
-/*
- * structures for inter-processor calls
- */
-struct ipi_data {
-	unsigned long ipi_count;
-};
-
-static DEFINE_PER_CPU(struct ipi_data, ipi_data);
-
 enum ipi_msg_type {
 	IPI_TIMER = 2,
 	IPI_RESCHEDULE,
@@ -398,7 +389,7 @@ void show_ipi_list(struct seq_file *p)
 	seq_puts(p, "IPI:");
 
 	for_each_present_cpu(cpu)
-		seq_printf(p, " %10lu", per_cpu(ipi_data, cpu).ipi_count);
+		seq_printf(p, " %10u", __get_irq_stat(cpu, ipi_irqs));
 
 	seq_putc(p, '\n');
 }
@@ -513,10 +504,9 @@ static void ipi_cpu_stop(unsigned int cpu)
 asmlinkage void __exception do_IPI(int ipinr, struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
-	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
-	ipi->ipi_count++;
+	__inc_irq_stat(cpu, ipi_irqs);
 
 	switch (ipinr) {
 	case IPI_TIMER:

commit 46c48f222f568decb881a552caa1c8f9c96c521e
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 14:15:03 2010 +0000

    ARM: SMP: provide accessors for irq_stat data
    
    Provide __inc_irq_stat() and __get_irq_stat() to increment and
    read the irq stat counters.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 36d4b9140dcf..24131264ec2c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -423,7 +423,7 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 	int cpu = smp_processor_id();
 
 	if (local_timer_ack()) {
-		irq_stat[cpu].local_timer_irqs++;
+		__inc_irq_stat(cpu, local_timer_irqs);
 		ipi_timer();
 	}
 
@@ -437,7 +437,7 @@ void show_local_irqs(struct seq_file *p)
 	seq_printf(p, "LOC: ");
 
 	for_each_present_cpu(cpu)
-		seq_printf(p, "%10u ", irq_stat[cpu].local_timer_irqs);
+		seq_printf(p, "%10u ", __get_irq_stat(cpu, local_timer_irqs));
 
 	seq_putc(p, '\n');
 }

commit ec405ea9fe5fdeb40824edba7082803b3e98f176
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 13:38:06 2010 +0000

    ARM: include local timer irq stats only when local timers configured
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 3772cfc6953a..36d4b9140dcf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -403,18 +403,6 @@ void show_ipi_list(struct seq_file *p)
 	seq_putc(p, '\n');
 }
 
-void show_local_irqs(struct seq_file *p)
-{
-	unsigned int cpu;
-
-	seq_printf(p, "LOC: ");
-
-	for_each_present_cpu(cpu)
-		seq_printf(p, "%10u ", irq_stat[cpu].local_timer_irqs);
-
-	seq_putc(p, '\n');
-}
-
 /*
  * Timer (local or broadcast) support
  */
@@ -441,6 +429,18 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 
 	set_irq_regs(old_regs);
 }
+
+void show_local_irqs(struct seq_file *p)
+{
+	unsigned int cpu;
+
+	seq_printf(p, "LOC: ");
+
+	for_each_present_cpu(cpu)
+		seq_printf(p, "%10u ", irq_stat[cpu].local_timer_irqs);
+
+	seq_putc(p, '\n');
+}
 #endif
 
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST

commit e3fbb087650df130788d8e3ac29875ee56819249
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Dec 20 14:47:19 2010 +0000

    ARM: SMP: remove send_ipi_message()
    
    send_ipi_message() does nothing except call smp_cross_call().  As
    this is a static function, nothing external to this file calls it,
    so we can easily clean up this now unnecessary indirection.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 4878e51561f9..3772cfc6953a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -381,22 +381,14 @@ void __init smp_prepare_boot_cpu(void)
 	per_cpu(cpu_data, cpu).idle = current;
 }
 
-static void send_ipi_message(const struct cpumask *mask, enum ipi_msg_type msg)
-{
-	/*
-	 * Call the platform specific cross-CPU call function.
-	 */
-	smp_cross_call(mask, msg);
-}
-
 void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
-	send_ipi_message(mask, IPI_CALL_FUNC);
+	smp_cross_call(mask, IPI_CALL_FUNC);
 }
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
+	smp_cross_call(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
 void show_ipi_list(struct seq_file *p)
@@ -454,7 +446,7 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 static void smp_timer_broadcast(const struct cpumask *mask)
 {
-	send_ipi_message(mask, IPI_TIMER);
+	smp_cross_call(mask, IPI_TIMER);
 }
 #else
 #define smp_timer_broadcast	NULL
@@ -560,7 +552,7 @@ asmlinkage void __exception do_IPI(int ipinr, struct pt_regs *regs)
 
 void smp_send_reschedule(int cpu)
 {
-	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
+	smp_cross_call(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
 void smp_send_stop(void)
@@ -568,7 +560,7 @@ void smp_send_stop(void)
 	cpumask_t mask = cpu_online_map;
 	cpu_clear(smp_processor_id(), mask);
 	if (!cpus_empty(mask))
-		send_ipi_message(&mask, IPI_CPU_STOP);
+		smp_cross_call(&mask, IPI_CPU_STOP);
 }
 
 /*

commit 1ae1b5f053cf36bd0f913e83f3b136fec8152d4d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Dec 18 13:57:00 2010 +0000

    ARM: smp: avoid incrementing mm_users on CPU startup
    
    We should not be incrementing mm_users when we startup a secondary
    CPU - doing so results in mm_users incrementing by one each time we
    hotplug a CPU, which will eventually wrap, and will cause problems.
    
    Other architectures such as x86 do not increment mm_users, but only
    mm_count, so we follow that pattern.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c1959590252..9066473c0ebc 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -310,7 +310,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 * All kernel threads share the same mm context; grab a
 	 * reference and switch to it.
 	 */
-	atomic_inc(&mm->mm_users);
 	atomic_inc(&mm->mm_count);
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));

commit 0df7095205cbf6ea1cdfe6254e0d6a3b823caa3b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Dec 2 19:16:56 2010 +0000

    ARM: SMP: remove IRQ-disabling for smp_cross_call()
    
    As we've now removed the spinlock and bitmask, we have nothing left
    which requires interrupts to be disabled when sending an IPI.  All
    current IPI-sending implementations use the GIC, which also does not
    require interrupts disabled when calling gic_raise_softirq().
    
    Remove the now unnecessary IRQ disable.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 78d55c681a4f..4878e51561f9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -383,16 +383,10 @@ void __init smp_prepare_boot_cpu(void)
 
 static void send_ipi_message(const struct cpumask *mask, enum ipi_msg_type msg)
 {
-	unsigned long flags;
-
-	local_irq_save(flags);
-
 	/*
 	 * Call the platform specific cross-CPU call function.
 	 */
 	smp_cross_call(mask, msg);
-
-	local_irq_restore(flags);
 }
 
 void arch_send_call_function_ipi_mask(const struct cpumask *mask)

commit 24480d980e9063b3ebd0dfdf2f396c305956c356
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 09:54:18 2010 +0000

    ARM: SMP: avoid using bitmasks and locks for IPIs, use hardware instead
    
    Avoid using bitmasks and locks in the percpu area for IPIs, and instead
    use individual software generated interrupts to identify the reason for
    the IPI.  This avoids the problems of having spinlocks in the percpu
    area.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7a236db03fb5..78d55c681a4f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -48,20 +48,15 @@ struct secondary_data secondary_data;
 
 /*
  * structures for inter-processor calls
- * - A collection of single bit ipi messages.
  */
 struct ipi_data {
-	spinlock_t lock;
 	unsigned long ipi_count;
-	unsigned long bits;
 };
 
-static DEFINE_PER_CPU(struct ipi_data, ipi_data) = {
-	.lock	= SPIN_LOCK_UNLOCKED,
-};
+static DEFINE_PER_CPU(struct ipi_data, ipi_data);
 
 enum ipi_msg_type {
-	IPI_TIMER,
+	IPI_TIMER = 2,
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
 	IPI_CALL_FUNC_SINGLE,
@@ -389,22 +384,13 @@ void __init smp_prepare_boot_cpu(void)
 static void send_ipi_message(const struct cpumask *mask, enum ipi_msg_type msg)
 {
 	unsigned long flags;
-	unsigned int cpu;
 
 	local_irq_save(flags);
 
-	for_each_cpu(cpu, mask) {
-		struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
-
-		spin_lock(&ipi->lock);
-		ipi->bits |= 1 << msg;
-		spin_unlock(&ipi->lock);
-	}
-
 	/*
 	 * Call the platform specific cross-CPU call function.
 	 */
-	smp_cross_call(mask, 1);
+	smp_cross_call(mask, msg);
 
 	local_irq_restore(flags);
 }
@@ -546,56 +532,35 @@ asmlinkage void __exception do_IPI(int ipinr, struct pt_regs *regs)
 
 	ipi->ipi_count++;
 
-	for (;;) {
-		unsigned long msgs;
-
-		spin_lock(&ipi->lock);
-		msgs = ipi->bits;
-		ipi->bits = 0;
-		spin_unlock(&ipi->lock);
-
-		if (!msgs)
-			break;
-
-		do {
-			unsigned nextmsg;
-
-			nextmsg = msgs & -msgs;
-			msgs &= ~nextmsg;
-			nextmsg = ffz(~nextmsg);
-
-			switch (nextmsg) {
-			case IPI_TIMER:
-				ipi_timer();
-				break;
+	switch (ipinr) {
+	case IPI_TIMER:
+		ipi_timer();
+		break;
 
-			case IPI_RESCHEDULE:
-				/*
-				 * nothing more to do - eveything is
-				 * done on the interrupt return path
-				 */
-				break;
+	case IPI_RESCHEDULE:
+		/*
+		 * nothing more to do - eveything is
+		 * done on the interrupt return path
+		 */
+		break;
 
-			case IPI_CALL_FUNC:
-				generic_smp_call_function_interrupt();
-				break;
+	case IPI_CALL_FUNC:
+		generic_smp_call_function_interrupt();
+		break;
 
-			case IPI_CALL_FUNC_SINGLE:
-				generic_smp_call_function_single_interrupt();
-				break;
+	case IPI_CALL_FUNC_SINGLE:
+		generic_smp_call_function_single_interrupt();
+		break;
 
-			case IPI_CPU_STOP:
-				ipi_cpu_stop(cpu);
-				break;
+	case IPI_CPU_STOP:
+		ipi_cpu_stop(cpu);
+		break;
 
-			default:
-				printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
-				       cpu, nextmsg);
-				break;
-			}
-		} while (msgs);
+	default:
+		printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
+		       cpu, ipinr);
+		break;
 	}
-
 	set_irq_regs(old_regs);
 }
 

commit ad3b6993b9c5482e8a2ec5aed181538c921fdcbd
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 15 09:42:08 2010 +0000

    ARM: SMP: pass an ipi number to smp_cross_call()
    
    This allows us to use smp_cross_call() to trigger a number of different
    software generated interrupts, rather than combining them all on one
    SGI.  Recover the SGI number via do_IPI.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c1959590252..7a236db03fb5 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -404,7 +404,7 @@ static void send_ipi_message(const struct cpumask *mask, enum ipi_msg_type msg)
 	/*
 	 * Call the platform specific cross-CPU call function.
 	 */
-	smp_cross_call(mask);
+	smp_cross_call(mask, 1);
 
 	local_irq_restore(flags);
 }
@@ -537,14 +537,8 @@ static void ipi_cpu_stop(unsigned int cpu)
 
 /*
  * Main handler for inter-processor interrupts
- *
- * For ARM, the ipimask now only identifies a single
- * category of IPI (Bit 1 IPIs have been replaced by a
- * different mechanism):
- *
- *  Bit 0 - Inter-processor function call
  */
-asmlinkage void __exception do_IPI(struct pt_regs *regs)
+asmlinkage void __exception do_IPI(int ipinr, struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);

commit 61b5cb1c3bff8875d2fd289c7b6ac344f95261fa
Author: Rabin Vincent <rabin@rab.in>
Date:   Thu Oct 7 20:51:58 2010 +0530

    ARM: place C irq handlers in IRQ_ENTRY for ftrace
    
    When FUNCTION_GRAPH_TRACER is enabled, place do_IRQ() and friends in the
    IRQ_ENTRY section so that the irq-related features of the function graph
    tracer work.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 8c1959590252..bbca89872c18 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -16,6 +16,7 @@
 #include <linux/cache.h>
 #include <linux/profile.h>
 #include <linux/errno.h>
+#include <linux/ftrace.h>
 #include <linux/mm.h>
 #include <linux/err.h>
 #include <linux/cpu.h>
@@ -457,7 +458,7 @@ static void ipi_timer(void)
 }
 
 #ifdef CONFIG_LOCAL_TIMERS
-asmlinkage void __exception do_local_timer(struct pt_regs *regs)
+asmlinkage void __exception_irq_entry do_local_timer(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	int cpu = smp_processor_id();
@@ -544,7 +545,7 @@ static void ipi_cpu_stop(unsigned int cpu)
  *
  *  Bit 0 - Inter-processor function call
  */
-asmlinkage void __exception do_IPI(struct pt_regs *regs)
+asmlinkage void __exception_irq_entry do_IPI(struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);

commit a0a55682b83fd5f012afadcf415b030d7424ae68
Merge: 23beab76b490 865a4fae7793
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Oct 18 22:34:47 2010 +0100

    Merge branch 'hotplug' into devel
    
    Conflicts:
            arch/arm/kernel/head-common.S

commit 37b05b63754e995b8cb76f4fbe7ed7219b3ca896
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Oct 1 15:38:24 2010 +0100

    ARM: hotplug cpu: setup 1:1 map for entire kernel image for secondary CPUs
    
    Make the entire kernel image available for secondary CPUs rather
    than just the first MB of memory.  This allows the startup code
    to appear in the cpuinit sections.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 40dc74f2b27f..14070549e051 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -33,6 +33,7 @@
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
 #include <asm/processor.h>
+#include <asm/sections.h>
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
@@ -67,12 +68,47 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 };
 
+static inline void identity_mapping_add(pgd_t *pgd, unsigned long start,
+	unsigned long end)
+{
+	unsigned long addr, prot;
+	pmd_t *pmd;
+
+	prot = PMD_TYPE_SECT | PMD_SECT_AP_WRITE;
+	if (cpu_architecture() <= CPU_ARCH_ARMv5TEJ && !cpu_is_xscale())
+		prot |= PMD_BIT4;
+
+	for (addr = start & PGDIR_MASK; addr < end;) {
+		pmd = pmd_offset(pgd + pgd_index(addr), addr);
+		pmd[0] = __pmd(addr | prot);
+		addr += SECTION_SIZE;
+		pmd[1] = __pmd(addr | prot);
+		addr += SECTION_SIZE;
+		flush_pmd_entry(pmd);
+		outer_clean_range(__pa(pmd), __pa(pmd + 1));
+	}
+}
+
+static inline void identity_mapping_del(pgd_t *pgd, unsigned long start,
+	unsigned long end)
+{
+	unsigned long addr;
+	pmd_t *pmd;
+
+	for (addr = start & PGDIR_MASK; addr < end; addr += PGDIR_SIZE) {
+		pmd = pmd_offset(pgd + pgd_index(addr), addr);
+		pmd[0] = __pmd(0);
+		pmd[1] = __pmd(0);
+		clean_pmd_entry(pmd);
+		outer_clean_range(__pa(pmd), __pa(pmd + 1));
+	}
+}
+
 int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
 	struct task_struct *idle = ci->idle;
 	pgd_t *pgd;
-	pmd_t *pmd;
 	int ret;
 
 	/*
@@ -101,11 +137,16 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 * a 1:1 mapping for the physical address of the kernel.
 	 */
 	pgd = pgd_alloc(&init_mm);
-	pmd = pmd_offset(pgd + pgd_index(PHYS_OFFSET), PHYS_OFFSET);
-	*pmd = __pmd((PHYS_OFFSET & PGDIR_MASK) |
-		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE);
-	flush_pmd_entry(pmd);
-	outer_clean_range(__pa(pmd), __pa(pmd + 1));
+	if (!pgd)
+		return -ENOMEM;
+
+	if (PHYS_OFFSET != PAGE_OFFSET) {
+#ifndef CONFIG_HOTPLUG_CPU
+		identity_mapping_add(pgd, __pa(__init_begin), __pa(__init_end));
+#endif
+		identity_mapping_add(pgd, __pa(_stext), __pa(_etext));
+		identity_mapping_add(pgd, __pa(_sdata), __pa(_edata));
+	}
 
 	/*
 	 * We need to tell the secondary core where to find
@@ -143,8 +184,14 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	secondary_data.stack = NULL;
 	secondary_data.pgdir = 0;
 
-	*pmd = __pmd(0);
-	clean_pmd_entry(pmd);
+	if (PHYS_OFFSET != PAGE_OFFSET) {
+#ifndef CONFIG_HOTPLUG_CPU
+		identity_mapping_del(pgd, __pa(__init_begin), __pa(__init_end));
+#endif
+		identity_mapping_del(pgd, __pa(_stext), __pa(_etext));
+		identity_mapping_del(pgd, __pa(_sdata), __pa(_edata));
+	}
+
 	pgd_free(&init_mm, pgd);
 
 	if (ret) {

commit f9e417e901e891d139f4d5fd750959e4a862d9f7
Author: Tony Lindgren <tony@atomide.com>
Date:   Tue Sep 21 00:43:19 2010 +0100

    ARM: 6402/1: Don't send IPI in smp_send_stop if there's only one CPU
    
    No need to send IPI if there's one CPU, especially when booting
    systems with CONFIG_SMP_ON_UP that may not even support IPI.
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 40dc74f2b27f..32e16da5cbce 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -567,7 +567,8 @@ void smp_send_stop(void)
 {
 	cpumask_t mask = cpu_online_map;
 	cpu_clear(smp_processor_id(), mask);
-	send_ipi_message(&mask, IPI_CPU_STOP);
+	if (!cpus_empty(mask))
+		send_ipi_message(&mask, IPI_CPU_STOP);
 }
 
 /*

commit 3d3f78d752bfada5b6041f2f7bd0833d8bdf7a4a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jul 26 13:31:27 2010 +0100

    ARM: call machine_shutdown() from machine_halt(), etc
    
    x86 calls machine_shutdown() from the various machine_*() calls which
    take the machine down ready for halting, restarting, etc, and uses
    this to bring the system safely to a point where those actions can be
    performed.  Such actions are stopping the secondary CPUs.
    
    So, change the ARM implementation of these to reflect what x86 does.
    
    This solves kexec problems on ARM SMP platforms, where the secondary
    CPUs were left running across the kexec call.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 0170e248a1dd..40dc74f2b27f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -471,10 +471,13 @@ static DEFINE_SPINLOCK(stop_lock);
  */
 static void ipi_cpu_stop(unsigned int cpu)
 {
-	spin_lock(&stop_lock);
-	printk(KERN_CRIT "CPU%u: stopping\n", cpu);
-	dump_stack();
-	spin_unlock(&stop_lock);
+	if (system_state == SYSTEM_BOOTING ||
+	    system_state == SYSTEM_RUNNING) {
+		spin_lock(&stop_lock);
+		printk(KERN_CRIT "CPU%u: stopping\n", cpu);
+		dump_stack();
+		spin_unlock(&stop_lock);
+	}
 
 	set_cpu_online(cpu, false);
 

commit 5388a6b266e9c3357353332ba0cd5549082887f1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jul 26 13:19:43 2010 +0100

    ARM: SMP: Always enable clock event broadcast support
    
    The TWD local timers are unable to wake up the CPU when it is placed
    into a low power mode, eg. C3.  Therefore, we need to adapt things
    such that the TWD code can cope with this.
    
    We do this by always providing a broadcast tick function, and marking
    the fact that the TWD local timer will stop in low power modes.  This
    means that when the CPU is placed into a low power mode, the core
    timer code marks this fact, and allows an IPI to be given to the core.
    
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b8c3d0f689d9..0170e248a1dd 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -429,7 +429,11 @@ static void smp_timer_broadcast(const struct cpumask *mask)
 {
 	send_ipi_message(mask, IPI_TIMER);
 }
+#else
+#define smp_timer_broadcast	NULL
+#endif
 
+#ifndef CONFIG_LOCAL_TIMERS
 static void broadcast_timer_set_mode(enum clock_event_mode mode,
 	struct clock_event_device *evt)
 {
@@ -444,7 +448,6 @@ static void local_timer_setup(struct clock_event_device *evt)
 	evt->rating	= 400;
 	evt->mult	= 1;
 	evt->set_mode	= broadcast_timer_set_mode;
-	evt->broadcast	= smp_timer_broadcast;
 
 	clockevents_register_device(evt);
 }
@@ -456,6 +459,7 @@ void __cpuinit percpu_timer_setup(void)
 	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
 
 	evt->cpumask = cpumask_of(cpu);
+	evt->broadcast = smp_timer_broadcast;
 
 	local_timer_setup(evt);
 }

commit ac1d426e825ab5778995f2f6f053ca2e6b45c622
Merge: fda0e18c8a7a a3685f00652a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 17 17:24:04 2010 +0100

    Merge branch 'devel-stable' into devel
    
    Conflicts:
            arch/arm/Kconfig
            arch/arm/include/asm/system.h
            arch/arm/mm/Kconfig

commit 8e2a43f5f5e1255879064924917fb1a6e5be7cb3
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat May 15 10:18:05 2010 +0100

    ARM: rename mach_cpu_disable() to platform_cpu_disable()
    
    Consistently name all SMP platform related functions.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 577543f3857f..7a3cc0266934 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -162,7 +162,7 @@ int __cpu_disable(void)
 	struct task_struct *p;
 	int ret;
 
-	ret = mach_cpu_disable(cpu);
+	ret = platform_cpu_disable(cpu);
 	if (ret)
 		return ret;
 

commit 13ea9cc82138691856d7cd855dff9aef1479adb9
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Fri Apr 30 06:51:20 2010 +0100

    ARM: 6066/1: Fix "BUG: scheduling while atomic: swapper/0/0x00000002
    
    This patch fixes the preempt leak in the cpuidle path invoked from
    cpu-hotplug. The fix is suggested by Russell King and is based
    on x86 idea of calling init_idle() on the idle task when it's
    re-used which also resets the preempt count amongst other things
    
    dump:
    BUG: scheduling while atomic: swapper/0/0x00000002
    Modules linked in:
    Backtrace:
    [<c0024f90>] (dump_backtrace+0x0/0x110) from [<c0173bc4>] (dump_stack+0x18/0x1c)
     r7:c02149e4 r6:c033df00 r5:c7836000 r4:00000000
    [<c0173bac>] (dump_stack+0x0/0x1c) from [<c003b4f0>] (__schedule_bug+0x60/0x70)
    [<c003b490>] (__schedule_bug+0x0/0x70) from [<c0174214>] (schedule+0x98/0x7b8)
     r5:c7836000 r4:c7836000
    [<c017417c>] (schedule+0x0/0x7b8) from [<c00228c4>] (cpu_idle+0xb4/0xd4)
    # [<c0022810>] (cpu_idle+0x0/0xd4) from [<c0171dd8>] (secondary_start_kernel+0xe0/0xf0)
     r5:c7836000 r4:c0205f40
    [<c0171cf8>] (secondary_start_kernel+0x0/0xf0) from [<c002d57c>] (prm_rmw_mod_reg_bits+0x88/0xa4)
     r7:c02149e4 r6:00000001 r5:00000001 r4:c7836000
    Backtrace aborted due to bad frame pointer <c7837fbc>
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 577543f3857f..a01194e583ff 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -86,6 +86,12 @@ int __cpuinit __cpu_up(unsigned int cpu)
 			return PTR_ERR(idle);
 		}
 		ci->idle = idle;
+	} else {
+		/*
+		 * Since this idle thread is being re-used, call
+		 * init_idle() to reinitialize the thread structure.
+		 */
+		init_idle(idle, cpu);
 	}
 
 	/*

commit 1027247f6eb727db6c600b9eb02796f0766ae704
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Feb 12 14:36:24 2010 +0000

    ARM: Add L2 cache handling to smp boot support
    
    The page table and secondary data which we're asking the secondary CPU
    to make use of has to hit RAM to ensure that the secondary CPU can see
    it since it may not be taking part in coherency or cache searches at
    this point.
    
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 57162af53dc9..577543f3857f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -99,6 +99,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	*pmd = __pmd((PHYS_OFFSET & PGDIR_MASK) |
 		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE);
 	flush_pmd_entry(pmd);
+	outer_clean_range(__pa(pmd), __pa(pmd + 1));
 
 	/*
 	 * We need to tell the secondary core where to find
@@ -106,7 +107,8 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 */
 	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
 	secondary_data.pgdir = virt_to_phys(pgd);
-	wmb();
+	__cpuc_flush_dcache_area(&secondary_data, sizeof(secondary_data));
+	outer_clean_range(__pa(&secondary_data), __pa(&secondary_data + 1));
 
 	/*
 	 * Now bring the CPU into our world.

commit 90140c30a7b8c77e8872a389d48678d78e58789f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 27 21:04:48 2009 +0100

    ARM: Fix __cpuexit section mismatch warnings
    
    Fix:
    
    WARNING: vmlinux.o(.text+0x247c): Section mismatch in reference from the function cpu_idle() to the function .cpuexit.text:cpu_die()
    The function cpu_idle() references a function in an exit section.
    Often the function cpu_die() has valid usage outside the exit section
    and the fix is to remove the __cpuexit annotation of cpu_die.
    
    WARNING: vmlinux.o(.cpuexit.text+0x3c): Section mismatch in reference from the function cpu_die() to the function .cpuinit.text:secondary_start_kernel()
    The function __cpuexit cpu_die() references
    a function __cpuinit secondary_start_kernel().
    This is often seen when error handling in the exit function
    uses functionality in the init path.
    The fix is often to remove the __cpuinit annotation of
    secondary_start_kernel() so it may be used outside an init section.
    
    Sam says:
    > The annotation of cpu_die() is wrong.
    > To be annotated __cpuexit the function shall:
    > - be used in exit context and only in exit context with HOTPLUG_CPU=n
    > - be used outside exit context with HOTPLUG_CPU=y
    
    So, this also means __cpu_disable(), __cpu_die() and twd_timer_stop() are
    also wrong.  However, removing __cpuexit from cpu_die() creates:
    
    WARNING: vmlinux.o(.text+0x6834): Section mismatch in reference from the function cpu_die() to the function .cpuinit.text:secondary_start_kernel()
    The function cpu_die() references
    the function __cpuinit secondary_start_kernel().
    This is often because cpu_die lacks a __cpuinit
    annotation or the annotation of secondary_start_kernel is wrong.
    
    so fix this using __ref.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: Sam Ravnborg <sam@ravnborg.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 9d015ee5747a..57162af53dc9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -154,7 +154,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 /*
  * __cpu_disable runs on the processor to be shutdown.
  */
-int __cpuexit __cpu_disable(void)
+int __cpu_disable(void)
 {
 	unsigned int cpu = smp_processor_id();
 	struct task_struct *p;
@@ -201,7 +201,7 @@ int __cpuexit __cpu_disable(void)
  * called on the thread which is asking for a CPU to be shutdown -
  * waits until shutdown has completed, or it is timed out.
  */
-void __cpuexit __cpu_die(unsigned int cpu)
+void __cpu_die(unsigned int cpu)
 {
 	if (!platform_cpu_kill(cpu))
 		printk("CPU%u: unable to kill\n", cpu);
@@ -215,7 +215,7 @@ void __cpuexit __cpu_die(unsigned int cpu)
  * of the other hotplug-cpu capable cores, so presumably coming
  * out of idle fixes this.
  */
-void __cpuexit cpu_die(void)
+void __ref cpu_die(void)
 {
 	unsigned int cpu = smp_processor_id();
 

commit e616c591405c168f6dc3dfd1221e105adfe49b8d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 27 20:55:43 2009 +0100

    ARM: Don't allow highmem on SMP platforms without h/w TLB ops broadcast
    
    We suffer an unfortunate combination of "features" which makes highmem
    support on platforms without hardware TLB maintainence broadcast difficult:
    
    - we need kmap_high_get() support for DMA cache coherence
    - this requires kmap_high() to take a spinlock with IRQs disabled
    - kmap_high() occasionally calls flush_all_zero_pkmaps() to clear
      out old mappings
    - flush_all_zero_pkmaps() calls flush_tlb_kernel_range(), which
      on s/w IPI'd systems eventually calls smp_call_function_many()
    - smp_call_function_many() must not be called with IRQs disabled:
    
    WARNING: at kernel/smp.c:380 smp_call_function_many+0xc4/0x240()
    Modules linked in:
    Backtrace:
    [<c00306f0>] (dump_backtrace+0x0/0x108) from [<c0286e6c>] (dump_stack+0x18/0x1c)
     r6:c007cd18 r5:c02ff228 r4:0000017c
    [<c0286e54>] (dump_stack+0x0/0x1c) from [<c0053e08>] (warn_slowpath_common+0x50/0x80)
    [<c0053db8>] (warn_slowpath_common+0x0/0x80) from [<c0053e50>] (warn_slowpath_null+0x18/0x1c)
     r7:00000003 r6:00000001 r5:c1ff4000 r4:c035fa34
    [<c0053e38>] (warn_slowpath_null+0x0/0x1c) from [<c007cd18>] (smp_call_function_many+0xc4/0x240)
    [<c007cc54>] (smp_call_function_many+0x0/0x240) from [<c007cec0>] (smp_call_function+0x2c/0x38)
    [<c007ce94>] (smp_call_function+0x0/0x38) from [<c005980c>] (on_each_cpu+0x1c/0x38)
    [<c00597f0>] (on_each_cpu+0x0/0x38) from [<c0031788>] (flush_tlb_kernel_range+0x50/0x58)
     r6:00000001 r5:00000800 r4:c05f3590
    [<c0031738>] (flush_tlb_kernel_range+0x0/0x58) from [<c009c600>] (flush_all_zero_pkmaps+0xc0/0xe8)
    [<c009c540>] (flush_all_zero_pkmaps+0x0/0xe8) from [<c009c6b4>] (kmap_high+0x8c/0x1e0)
    [<c009c628>] (kmap_high+0x0/0x1e0) from [<c00364a8>] (kmap+0x44/0x5c)
    [<c0036464>] (kmap+0x0/0x5c) from [<c0109dfc>] (cramfs_readpage+0x3c/0x194)
    [<c0109dc0>] (cramfs_readpage+0x0/0x194) from [<c0090c14>] (__do_page_cache_readahead+0x1f0/0x290)
    [<c0090a24>] (__do_page_cache_readahead+0x0/0x290) from [<c0090ce4>] (ra_submit+0x30/0x38)
    [<c0090cb4>] (ra_submit+0x0/0x38) from [<c0089384>] (filemap_fault+0x3dc/0x438)
     r4:c1819988
    [<c0088fa8>] (filemap_fault+0x0/0x438) from [<c009d21c>] (__do_fault+0x58/0x43c)
    [<c009d1c4>] (__do_fault+0x0/0x43c) from [<c009e8cc>] (handle_mm_fault+0x104/0x318)
    [<c009e7c8>] (handle_mm_fault+0x0/0x318) from [<c0033c98>] (do_page_fault+0x188/0x1e4)
    [<c0033b10>] (do_page_fault+0x0/0x1e4) from [<c0033ddc>] (do_translation_fault+0x7c/0x84)
    [<c0033d60>] (do_translation_fault+0x0/0x84) from [<c002b474>] (do_DataAbort+0x40/0xa4)
     r8:c1ff5e20 r7:c0340120 r6:00000805 r5:c1ff5e54 r4:c03400d0
    [<c002b434>] (do_DataAbort+0x0/0xa4) from [<c002bcac>] (__dabt_svc+0x4c/0x60)
    ...
    
    So we disable highmem support on these systems.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e0d32770bb3d..9d015ee5747a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -36,6 +36,7 @@
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
 #include <asm/localtimer.h>
+#include <asm/smp_plat.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -586,12 +587,6 @@ struct tlb_args {
 	unsigned long ta_end;
 };
 
-/* all SMP configurations have the extended CPUID registers */
-static inline int tlb_ops_need_broadcast(void)
-{
-	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
-}
-
 static inline void ipi_flush_tlb_all(void *ignored)
 {
 	local_flush_tlb_all();

commit 56f8ba83a52b9f9e3711eff8e54168ac14aa288f
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Sep 24 09:34:49 2009 -0600

    cpumask: use mm_cpumask() wrapper: arm
    
    Makes code futureproof against the impending change to mm->cpu_vm_mask.
    
    It's also a chance to use the new cpumask_ ops which take a pointer
    (the older ones are deprecated, but there's no hurry for arch code).
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index de885fd256c5..e0d32770bb3d 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -189,7 +189,7 @@ int __cpuexit __cpu_disable(void)
 	read_lock(&tasklist_lock);
 	for_each_process(p) {
 		if (p->mm)
-			cpu_clear(cpu, p->mm->cpu_vm_mask);
+			cpumask_clear_cpu(cpu, mm_cpumask(p->mm));
 	}
 	read_unlock(&tasklist_lock);
 
@@ -257,7 +257,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	atomic_inc(&mm->mm_users);
 	atomic_inc(&mm->mm_count);
 	current->active_mm = mm;
-	cpu_set(cpu, mm->cpu_vm_mask);
+	cpumask_set_cpu(cpu, mm_cpumask(mm));
 	cpu_switch_mm(mm->pgd, mm);
 	enter_lazy_tlb(mm, current);
 	local_flush_tlb_all();
@@ -643,7 +643,7 @@ void flush_tlb_all(void)
 void flush_tlb_mm(struct mm_struct *mm)
 {
 	if (tlb_ops_need_broadcast())
-		on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, &mm->cpu_vm_mask);
+		on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, mm_cpumask(mm));
 	else
 		local_flush_tlb_mm(mm);
 }
@@ -654,7 +654,7 @@ void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
 		struct tlb_args ta;
 		ta.ta_vma = vma;
 		ta.ta_start = uaddr;
-		on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+		on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, mm_cpumask(vma->vm_mm));
 	} else
 		local_flush_tlb_page(vma, uaddr);
 }
@@ -677,7 +677,7 @@ void flush_tlb_range(struct vm_area_struct *vma,
 		ta.ta_vma = vma;
 		ta.ta_start = start;
 		ta.ta_end = end;
-		on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+		on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, mm_cpumask(vma->vm_mm));
 	} else
 		local_flush_tlb_range(vma, start, end);
 }

commit 42578c82e0f1810a07ebe29cb05e874893243d8c
Merge: 2631182bf939 85d6943af505
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Jun 11 15:35:00 2009 +0100

    Merge branch 'for-rmk' of git://linux-arm.org/linux-2.6 into devel
    
    Conflicts:
            arch/arm/Kconfig
            arch/arm/kernel/smp.c
            arch/arm/mach-realview/Makefile
            arch/arm/mach-realview/platsmp.c

commit faa7bc51c11d5bbe440ac04710fd7a3208782000
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Sat May 30 14:00:14 2009 +0100

    Check whether the TLB operations need broadcasting on SMP systems
    
    ARMv7 SMP hardware can handle the TLB maintenance operations
    broadcasting in hardware so that the software can avoid the costly IPIs.
    This patch adds the necessary checks (the MMFR3 CPUID register) to avoid
    the broadcasting if already supported by the hardware.
    
    (this patch is based on the work done by Tony Thompson @ ARM)
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 6014dfd22af4..ece658e773a6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -32,6 +32,7 @@
 #include <asm/processor.h>
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
+#include <asm/cputype.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -545,6 +546,12 @@ struct tlb_args {
 	unsigned long ta_end;
 };
 
+/* all SMP configurations have the extended CPUID registers */
+static inline int tlb_ops_need_broadcast(void)
+{
+	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
+}
+
 static inline void ipi_flush_tlb_all(void *ignored)
 {
 	local_flush_tlb_all();
@@ -587,51 +594,61 @@ static inline void ipi_flush_tlb_kernel_range(void *arg)
 
 void flush_tlb_all(void)
 {
-	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+	if (tlb_ops_need_broadcast())
+		on_each_cpu(ipi_flush_tlb_all, NULL, 1);
+	else
+		local_flush_tlb_all();
 }
 
 void flush_tlb_mm(struct mm_struct *mm)
 {
-	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, &mm->cpu_vm_mask);
+	if (tlb_ops_need_broadcast())
+		on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, &mm->cpu_vm_mask);
+	else
+		local_flush_tlb_mm(mm);
 }
 
 void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
 {
-	struct tlb_args ta;
-
-	ta.ta_vma = vma;
-	ta.ta_start = uaddr;
-
-	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+	if (tlb_ops_need_broadcast()) {
+		struct tlb_args ta;
+		ta.ta_vma = vma;
+		ta.ta_start = uaddr;
+		on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+	} else
+		local_flush_tlb_page(vma, uaddr);
 }
 
 void flush_tlb_kernel_page(unsigned long kaddr)
 {
-	struct tlb_args ta;
-
-	ta.ta_start = kaddr;
-
-	on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1);
+	if (tlb_ops_need_broadcast()) {
+		struct tlb_args ta;
+		ta.ta_start = kaddr;
+		on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1);
+	} else
+		local_flush_tlb_kernel_page(kaddr);
 }
 
 void flush_tlb_range(struct vm_area_struct *vma,
                      unsigned long start, unsigned long end)
 {
-	struct tlb_args ta;
-
-	ta.ta_vma = vma;
-	ta.ta_start = start;
-	ta.ta_end = end;
-
-	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+	if (tlb_ops_need_broadcast()) {
+		struct tlb_args ta;
+		ta.ta_vma = vma;
+		ta.ta_start = start;
+		ta.ta_end = end;
+		on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, &vma->vm_mm->cpu_vm_mask);
+	} else
+		local_flush_tlb_range(vma, start, end);
 }
 
 void flush_tlb_kernel_range(unsigned long start, unsigned long end)
 {
-	struct tlb_args ta;
-
-	ta.ta_start = start;
-	ta.ta_end = end;
-
-	on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1);
+	if (tlb_ops_need_broadcast()) {
+		struct tlb_args ta;
+		ta.ta_start = start;
+		ta.ta_end = end;
+		on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1);
+	} else
+		local_flush_tlb_kernel_range(start, end);
 }

commit e03cdade0ca945a04e982525e50fef275190b77b
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu May 28 14:16:52 2009 +0100

    [ARM] smp: use new cpumask functions
    
    Convert cpu_*_mask bit twiddling to the new set_cpu_*() API.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 91130e218aef..0d8097fa4ca5 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -166,7 +166,7 @@ int __cpuexit __cpu_disable(void)
 	 * Take this CPU offline.  Once we clear this, we can't return,
 	 * and we must not schedule until we're ready to give up the cpu.
 	 */
-	cpu_clear(cpu, cpu_online_map);
+	set_cpu_online(cpu, false);
 
 	/*
 	 * OK - migrate IRQs away from this CPU
@@ -288,7 +288,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * OK, now it's safe to let the boot CPU continue
 	 */
-	cpu_set(cpu, cpu_online_map);
+	set_cpu_online(cpu, true);
 
 	/*
 	 * OK, it's off to the idle thread for us
@@ -462,7 +462,7 @@ static void ipi_cpu_stop(unsigned int cpu)
 	dump_stack();
 	spin_unlock(&stop_lock);
 
-	cpu_clear(cpu, cpu_online_map);
+	set_cpu_online(cpu, false);
 
 	local_fiq_disable();
 	local_irq_disable();

commit bc28248ee25e5c239cbe6afca35a100b08401de5
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun May 17 18:58:34 2009 +0100

    [ARM] smp: move core localtimer support out of platform specific files
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 6014dfd22af4..91130e218aef 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -22,6 +22,8 @@
 #include <linux/smp.h>
 #include <linux/seq_file.h>
 #include <linux/irq.h>
+#include <linux/percpu.h>
+#include <linux/clockchips.h>
 
 #include <asm/atomic.h>
 #include <asm/cacheflush.h>
@@ -32,6 +34,7 @@
 #include <asm/processor.h>
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
+#include <asm/localtimer.h>
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
@@ -274,9 +277,9 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	local_fiq_enable();
 
 	/*
-	 * Setup local timer for this CPU.
+	 * Setup the percpu timer for this CPU.
 	 */
-	local_timer_setup();
+	percpu_timer_setup();
 
 	calibrate_delay();
 
@@ -383,10 +386,16 @@ void show_local_irqs(struct seq_file *p)
 	seq_putc(p, '\n');
 }
 
+/*
+ * Timer (local or broadcast) support
+ */
+static DEFINE_PER_CPU(struct clock_event_device, percpu_clockevent);
+
 static void ipi_timer(void)
 {
+	struct clock_event_device *evt = &__get_cpu_var(percpu_clockevent);
 	irq_enter();
-	local_timer_interrupt();
+	evt->event_handler(evt);
 	irq_exit();
 }
 
@@ -405,6 +414,42 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 }
 #endif
 
+#ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
+static void smp_timer_broadcast(const struct cpumask *mask)
+{
+	send_ipi_message(mask, IPI_TIMER);
+}
+
+static void broadcast_timer_set_mode(enum clock_event_mode mode,
+	struct clock_event_device *evt)
+{
+}
+
+static void local_timer_setup(struct clock_event_device *evt)
+{
+	evt->name	= "dummy_timer";
+	evt->features	= CLOCK_EVT_FEAT_ONESHOT |
+			  CLOCK_EVT_FEAT_PERIODIC |
+			  CLOCK_EVT_FEAT_DUMMY;
+	evt->rating	= 400;
+	evt->mult	= 1;
+	evt->set_mode	= broadcast_timer_set_mode;
+	evt->broadcast	= smp_timer_broadcast;
+
+	clockevents_register_device(evt);
+}
+#endif
+
+void __cpuinit percpu_timer_setup(void)
+{
+	unsigned int cpu = smp_processor_id();
+	struct clock_event_device *evt = &per_cpu(percpu_clockevent, cpu);
+
+	evt->cpumask = cpumask_of(cpu);
+
+	local_timer_setup(evt);
+}
+
 static DEFINE_SPINLOCK(stop_lock);
 
 /*
@@ -501,11 +546,6 @@ void smp_send_reschedule(int cpu)
 	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
-void smp_timer_broadcast(const struct cpumask *mask)
-{
-	send_ipi_message(mask, IPI_TIMER);
-}
-
 void smp_send_stop(void)
 {
 	cpumask_t mask = cpu_online_map;

commit 826681043d7184b4d650cab5b007b9a86b628eb5
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun May 17 16:20:18 2009 +0100

    [ARM] smp: fix cpumask usage in ARM SMP code
    
    The ARM SMP code wasn't properly updated for the cpumask changes, which
    results in smp_timer_broadcast() broadcasting ticks to non-online CPUs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7801aac3c043..6014dfd22af4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -326,14 +326,14 @@ void __init smp_prepare_boot_cpu(void)
 	per_cpu(cpu_data, cpu).idle = current;
 }
 
-static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)
+static void send_ipi_message(const struct cpumask *mask, enum ipi_msg_type msg)
 {
 	unsigned long flags;
 	unsigned int cpu;
 
 	local_irq_save(flags);
 
-	for_each_cpu_mask(cpu, callmap) {
+	for_each_cpu(cpu, mask) {
 		struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
 
 		spin_lock(&ipi->lock);
@@ -344,19 +344,19 @@ static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)
 	/*
 	 * Call the platform specific cross-CPU call function.
 	 */
-	smp_cross_call(callmap);
+	smp_cross_call(mask);
 
 	local_irq_restore(flags);
 }
 
-void arch_send_call_function_ipi(cpumask_t mask)
+void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
 	send_ipi_message(mask, IPI_CALL_FUNC);
 }
 
 void arch_send_call_function_single_ipi(int cpu)
 {
-	send_ipi_message(cpumask_of_cpu(cpu), IPI_CALL_FUNC_SINGLE);
+	send_ipi_message(cpumask_of(cpu), IPI_CALL_FUNC_SINGLE);
 }
 
 void show_ipi_list(struct seq_file *p)
@@ -498,17 +498,10 @@ asmlinkage void __exception do_IPI(struct pt_regs *regs)
 
 void smp_send_reschedule(int cpu)
 {
-	send_ipi_message(cpumask_of_cpu(cpu), IPI_RESCHEDULE);
+	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
 
-void smp_send_timer(void)
-{
-	cpumask_t mask = cpu_online_map;
-	cpu_clear(smp_processor_id(), mask);
-	send_ipi_message(mask, IPI_TIMER);
-}
-
-void smp_timer_broadcast(cpumask_t mask)
+void smp_timer_broadcast(const struct cpumask *mask)
 {
 	send_ipi_message(mask, IPI_TIMER);
 }
@@ -517,7 +510,7 @@ void smp_send_stop(void)
 {
 	cpumask_t mask = cpu_online_map;
 	cpu_clear(smp_processor_id(), mask);
-	send_ipi_message(mask, IPI_CPU_STOP);
+	send_ipi_message(&mask, IPI_CPU_STOP);
 }
 
 /*
@@ -528,20 +521,17 @@ int setup_profiling_timer(unsigned int multiplier)
 	return -EINVAL;
 }
 
-static int
-on_each_cpu_mask(void (*func)(void *), void *info, int wait, cpumask_t mask)
+static void
+on_each_cpu_mask(void (*func)(void *), void *info, int wait,
+		const struct cpumask *mask)
 {
-	int ret = 0;
-
 	preempt_disable();
 
-	ret = smp_call_function_mask(mask, func, info, wait);
-	if (cpu_isset(smp_processor_id(), mask))
+	smp_call_function_many(mask, func, info, wait);
+	if (cpumask_test_cpu(smp_processor_id(), mask))
 		func(info);
 
 	preempt_enable();
-
-	return ret;
 }
 
 /**********************************************************************/
@@ -602,20 +592,17 @@ void flush_tlb_all(void)
 
 void flush_tlb_mm(struct mm_struct *mm)
 {
-	cpumask_t mask = mm->cpu_vm_mask;
-
-	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, &mm->cpu_vm_mask);
 }
 
 void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
 {
-	cpumask_t mask = vma->vm_mm->cpu_vm_mask;
 	struct tlb_args ta;
 
 	ta.ta_vma = vma;
 	ta.ta_start = uaddr;
 
-	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, &vma->vm_mm->cpu_vm_mask);
 }
 
 void flush_tlb_kernel_page(unsigned long kaddr)
@@ -630,14 +617,13 @@ void flush_tlb_kernel_page(unsigned long kaddr)
 void flush_tlb_range(struct vm_area_struct *vma,
                      unsigned long start, unsigned long end)
 {
-	cpumask_t mask = vma->vm_mm->cpu_vm_mask;
 	struct tlb_args ta;
 
 	ta.ta_vma = vma;
 	ta.ta_start = start;
 	ta.ta_end = end;
 
-	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, &vma->vm_mm->cpu_vm_mask);
 }
 
 void flush_tlb_kernel_range(unsigned long start, unsigned long end)

commit e9fc78230cb77647eb79d4b2f7c4d6c070f611f1
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Wed Feb 11 13:14:57 2009 +0100

    [ARM] 5389/1: Make sure the pmd entries are visible by the secondary CPU
    
    The __cpu_up() function in arch/arm/kernel/smp.c sets the pmd entries
    without flushing or cleaning them.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 55fa7ff96a3e..7801aac3c043 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -93,6 +93,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	pmd = pmd_offset(pgd + pgd_index(PHYS_OFFSET), PHYS_OFFSET);
 	*pmd = __pmd((PHYS_OFFSET & PGDIR_MASK) |
 		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE);
+	flush_pmd_entry(pmd);
 
 	/*
 	 * We need to tell the secondary core where to find
@@ -130,6 +131,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	secondary_data.pgdir = 0;
 
 	*pmd = __pmd(0);
+	clean_pmd_entry(pmd);
 	pgd_free(&init_mm, pgd);
 
 	if (ret) {

commit b840d79631c882786925303c2b0f4fefc31845ed
Merge: 597b0d21626d c3d80000e3a8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 2 11:44:09 2009 -0800

    Merge branch 'cpus4096-for-linus-2' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'cpus4096-for-linus-2' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (66 commits)
      x86: export vector_used_by_percpu_irq
      x86: use logical apicid in x2apic_cluster's x2apic_cpu_mask_to_apicid_and()
      sched: nominate preferred wakeup cpu, fix
      x86: fix lguest used_vectors breakage, -v2
      x86: fix warning in arch/x86/kernel/io_apic.c
      sched: fix warning in kernel/sched.c
      sched: move test_sd_parent() to an SMP section of sched.h
      sched: add SD_BALANCE_NEWIDLE at MC and CPU level for sched_mc>0
      sched: activate active load balancing in new idle cpus
      sched: bias task wakeups to preferred semi-idle packages
      sched: nominate preferred wakeup cpu
      sched: favour lower logical cpu number for sched_mc balance
      sched: framework for sched_mc/smt_power_savings=N
      sched: convert BALANCE_FOR_xx_POWER to inline functions
      x86: use possible_cpus=NUM to extend the possible cpus allowed
      x86: fix cpu_mask_to_apicid_and to include cpu_online_mask
      x86: update io_apic.c to the new cpumask code
      x86: Introduce topology_core_cpumask()/topology_thread_cpumask()
      x86: xen: use smp_call_function_many()
      x86: use work_on_cpu in x86/kernel/cpu/mcheck/mce_amd_64.c
      ...
    
    Fixed up trivial conflict in kernel/time/tick-sched.c manually

commit 98a79d6a50181ca1ecf7400eda01d5dc1bc0dbf0
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:19:41 2008 +1030

    cpumask: centralize cpu_online_map and cpu_possible_map
    
    Impact: cleanup
    
    Each SMP arch defines these themselves.  Move them to a central
    location.
    
    Twists:
    1) Some archs (m32, parisc, s390) set possible_map to all 1, so we add a
       CONFIG_INIT_ALL_POSSIBLE for this rather than break them.
    
    2) mips and sparc32 '#define cpu_possible_map phys_cpu_present_map'.
       Those archs simply have phys_cpu_present_map replaced everywhere.
    
    3) Alpha defined cpu_possible_map to cpu_present_map; this is tricky
       so I just manipulate them both in sync.
    
    4) IA64, cris and m32r have gratuitous 'extern cpumask_t cpu_possible_map'
       declarations.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Travis <travis@sgi.com>
    Cc: ink@jurassic.park.msu.ru
    Cc: rmk@arm.linux.org.uk
    Cc: starvik@axis.com
    Cc: tony.luck@intel.com
    Cc: takata@linux-m32r.org
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: paulus@samba.org
    Cc: schwidefsky@de.ibm.com
    Cc: lethal@linux-sh.org
    Cc: wli@holomorphy.com
    Cc: davem@davemloft.net
    Cc: jdike@addtoit.com
    Cc: mingo@redhat.com

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e42a749a56dd..bd905c0a7365 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -33,16 +33,6 @@
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
 
-/*
- * bitmask of present and online CPUs.
- * The present bitmask indicates that the CPU is physically present.
- * The online bitmask indicates that the CPU is up and running.
- */
-cpumask_t cpu_possible_map;
-EXPORT_SYMBOL(cpu_possible_map);
-cpumask_t cpu_online_map;
-EXPORT_SYMBOL(cpu_online_map);
-
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
  * so we need some other way of telling a new secondary core

commit ebac6546df7e8bd17f66f029c616ea9ee3c595ae
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Dec 1 14:54:57 2008 +0000

    RealView: Use only the shadow mapping of ARM11MPCore local timers
    
    All the cases where the local timer for a CPU is accessed happen on the
    corresponding current CPU, hence no need to access the per-CPU local
    timer mappings.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e42a749a56dd..019237d21622 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -181,7 +181,7 @@ int __cpuexit __cpu_disable(void)
 	/*
 	 * Stop the local timer for this CPU.
 	 */
-	local_timer_stop(cpu);
+	local_timer_stop();
 
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU
@@ -284,7 +284,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * Setup local timer for this CPU.
 	 */
-	local_timer_setup(cpu);
+	local_timer_setup();
 
 	calibrate_delay();
 

commit e545a6140b698b2494daf0b32107bdcc5e901390
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Sun Sep 7 16:57:22 2008 +0200

    kernel/cpu.c: create a CPU_STARTING cpu_chain notifier
    
    Right now, there is no notifier that is called on a new cpu, before the new
    cpu begins processing interrupts/softirqs.
    Various kernel function would need that notification, e.g. kvm works around
    by calling smp_call_function_single(), rcu polls cpu_online_map.
    
    The patch adds a CPU_STARTING notification. It also adds a helper function
    that sends the message to all cpu_chain handlers.
    
    Tested on x86-64.
    All other archs are untested. Especially on sparc, I'm not sure if I got
    it right.
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e9842f6767f9..e42a749a56dd 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -277,6 +277,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	/*
 	 * Enable local interrupts.
 	 */
+	notify_cpu_starting(cpu);
 	local_irq_enable();
 	local_fiq_enable();
 

commit 058ddee5625ade9e9e011b9ae155ac3b8d4eda3a
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Aug 7 22:36:59 2008 +0100

    [ARM] Fix SMP booting with non-zero PHYS_OFFSET
    
    The existing code tries to get the pmd for the temporary page table
    by doing:
    
            pgd = pgd_alloc(&init_mm);
            pmd = pmd_offset(pgd, PHYS_OFFSET);
    
    Since we have a two level page table, pmd_offset() is a no-op, so
    this just has a casting effect from a pgd to a pmd - the address
    argument is unused.  So this can't work.
    
    Normally, we'd do:
    
            pgd = pgd_offset(&init_mm, PHYS_OFFSET);
            ...
            pmd = pmd_offset(pgd, PHYS_OFFSET);
    
    to get the pmd you want.  However, pgd_offset() takes the mm_struct,
    not the (unattached) pgd we just allocated.  So, instead use:
    
            pgd = pgd_alloc(&init_mm);
            pmd = pmd_offset(pgd + pgd_index(PHYS_OFFSET), PHYS_OFFSET);
    
    Reported-by: Antti P Miettinen <ananaza@iki.fi>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 5a7c09564d13..e9842f6767f9 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -100,7 +100,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 * a 1:1 mapping for the physical address of the kernel.
 	 */
 	pgd = pgd_alloc(&init_mm);
-	pmd = pmd_offset(pgd, PHYS_OFFSET);
+	pmd = pmd_offset(pgd + pgd_index(PHYS_OFFSET), PHYS_OFFSET);
 	*pmd = __pmd((PHYS_OFFSET & PGDIR_MASK) |
 		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE);
 
@@ -139,7 +139,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	secondary_data.stack = NULL;
 	secondary_data.pgdir = 0;
 
-	*pmd_offset(pgd, PHYS_OFFSET) = __pmd(0);
+	*pmd = __pmd(0);
 	pgd_free(&init_mm, pgd);
 
 	if (ret) {

commit 15c8b6c1aaaf1c4edd67e2f02e4d8e1bd1a51c0d
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri May 9 09:39:44 2008 +0200

    on_each_cpu(): kill unused 'retry' parameter
    
    It's not even passed on to smp_call_function() anymore, since that
    was removed. So kill it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 6344466b2113..5a7c09564d13 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -604,7 +604,7 @@ static inline void ipi_flush_tlb_kernel_range(void *arg)
 
 void flush_tlb_all(void)
 {
-	on_each_cpu(ipi_flush_tlb_all, NULL, 1, 1);
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1);
 }
 
 void flush_tlb_mm(struct mm_struct *mm)
@@ -631,7 +631,7 @@ void flush_tlb_kernel_page(unsigned long kaddr)
 
 	ta.ta_start = kaddr;
 
-	on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1, 1);
+	on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1);
 }
 
 void flush_tlb_range(struct vm_area_struct *vma,
@@ -654,5 +654,5 @@ void flush_tlb_kernel_range(unsigned long start, unsigned long end)
 	ta.ta_start = start;
 	ta.ta_end = end;
 
-	on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1, 1);
+	on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1);
 }

commit f6dd9fa5a75a3dae16c6843e74e56bf75be51c7c
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Jun 10 20:48:30 2008 +0200

    arm: convert to generic helpers for IPI function calls
    
    This converts arm to use the new helpers for smp_call_function() and
    friends, and adds support for smp_call_function_single().
    
    Fixups and testing done by Catalin Marinas <catalin.marinas@arm.com>
    
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index eefae1de334c..6344466b2113 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -68,20 +68,10 @@ enum ipi_msg_type {
 	IPI_TIMER,
 	IPI_RESCHEDULE,
 	IPI_CALL_FUNC,
+	IPI_CALL_FUNC_SINGLE,
 	IPI_CPU_STOP,
 };
 
-struct smp_call_struct {
-	void (*func)(void *info);
-	void *info;
-	int wait;
-	cpumask_t pending;
-	cpumask_t unfinished;
-};
-
-static struct smp_call_struct * volatile smp_call_function_data;
-static DEFINE_SPINLOCK(smp_call_function_lock);
-
 int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
@@ -366,114 +356,15 @@ static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)
 	local_irq_restore(flags);
 }
 
-/*
- * You must not call this function with disabled interrupts, from a
- * hardware interrupt handler, nor from a bottom half handler.
- */
-static int smp_call_function_on_cpu(void (*func)(void *info), void *info,
-				    int retry, int wait, cpumask_t callmap)
-{
-	struct smp_call_struct data;
-	unsigned long timeout;
-	int ret = 0;
-
-	data.func = func;
-	data.info = info;
-	data.wait = wait;
-
-	cpu_clear(smp_processor_id(), callmap);
-	if (cpus_empty(callmap))
-		goto out;
-
-	data.pending = callmap;
-	if (wait)
-		data.unfinished = callmap;
-
-	/*
-	 * try to get the mutex on smp_call_function_data
-	 */
-	spin_lock(&smp_call_function_lock);
-	smp_call_function_data = &data;
-
-	send_ipi_message(callmap, IPI_CALL_FUNC);
-
-	timeout = jiffies + HZ;
-	while (!cpus_empty(data.pending) && time_before(jiffies, timeout))
-		barrier();
-
-	/*
-	 * did we time out?
-	 */
-	if (!cpus_empty(data.pending)) {
-		/*
-		 * this may be causing our panic - report it
-		 */
-		printk(KERN_CRIT
-		       "CPU%u: smp_call_function timeout for %p(%p)\n"
-		       "      callmap %lx pending %lx, %swait\n",
-		       smp_processor_id(), func, info, *cpus_addr(callmap),
-		       *cpus_addr(data.pending), wait ? "" : "no ");
-
-		/*
-		 * TRACE
-		 */
-		timeout = jiffies + (5 * HZ);
-		while (!cpus_empty(data.pending) && time_before(jiffies, timeout))
-			barrier();
-
-		if (cpus_empty(data.pending))
-			printk(KERN_CRIT "     RESOLVED\n");
-		else
-			printk(KERN_CRIT "     STILL STUCK\n");
-	}
-
-	/*
-	 * whatever happened, we're done with the data, so release it
-	 */
-	smp_call_function_data = NULL;
-	spin_unlock(&smp_call_function_lock);
-
-	if (!cpus_empty(data.pending)) {
-		ret = -ETIMEDOUT;
-		goto out;
-	}
-
-	if (wait)
-		while (!cpus_empty(data.unfinished))
-			barrier();
- out:
-
-	return 0;
-}
-
-int smp_call_function(void (*func)(void *info), void *info, int retry,
-                      int wait)
+void arch_send_call_function_ipi(cpumask_t mask)
 {
-	return smp_call_function_on_cpu(func, info, retry, wait,
-					cpu_online_map);
+	send_ipi_message(mask, IPI_CALL_FUNC);
 }
-EXPORT_SYMBOL_GPL(smp_call_function);
 
-int smp_call_function_single(int cpu, void (*func)(void *info), void *info,
-			     int retry, int wait)
+void arch_send_call_function_single_ipi(int cpu)
 {
-	/* prevent preemption and reschedule on another processor */
-	int current_cpu = get_cpu();
-	int ret = 0;
-
-	if (cpu == current_cpu) {
-		local_irq_disable();
-		func(info);
-		local_irq_enable();
-	} else
-		ret = smp_call_function_on_cpu(func, info, retry, wait,
-					       cpumask_of_cpu(cpu));
-
-	put_cpu();
-
-	return ret;
+	send_ipi_message(cpumask_of_cpu(cpu), IPI_CALL_FUNC_SINGLE);
 }
-EXPORT_SYMBOL_GPL(smp_call_function_single);
 
 void show_ipi_list(struct seq_file *p)
 {
@@ -521,27 +412,6 @@ asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 }
 #endif
 
-/*
- * ipi_call_function - handle IPI from smp_call_function()
- *
- * Note that we copy data out of the cross-call structure and then
- * let the caller know that we're here and have done with their data
- */
-static void ipi_call_function(unsigned int cpu)
-{
-	struct smp_call_struct *data = smp_call_function_data;
-	void (*func)(void *info) = data->func;
-	void *info = data->info;
-	int wait = data->wait;
-
-	cpu_clear(cpu, data->pending);
-
-	func(info);
-
-	if (wait)
-		cpu_clear(cpu, data->unfinished);
-}
-
 static DEFINE_SPINLOCK(stop_lock);
 
 /*
@@ -611,7 +481,11 @@ asmlinkage void __exception do_IPI(struct pt_regs *regs)
 				break;
 
 			case IPI_CALL_FUNC:
-				ipi_call_function(cpu);
+				generic_smp_call_function_interrupt();
+				break;
+
+			case IPI_CALL_FUNC_SINGLE:
+				generic_smp_call_function_single_interrupt();
 				break;
 
 			case IPI_CPU_STOP:
@@ -662,14 +536,13 @@ int setup_profiling_timer(unsigned int multiplier)
 }
 
 static int
-on_each_cpu_mask(void (*func)(void *), void *info, int retry, int wait,
-		 cpumask_t mask)
+on_each_cpu_mask(void (*func)(void *), void *info, int wait, cpumask_t mask)
 {
 	int ret = 0;
 
 	preempt_disable();
 
-	ret = smp_call_function_on_cpu(func, info, retry, wait, mask);
+	ret = smp_call_function_mask(mask, func, info, wait);
 	if (cpu_isset(smp_processor_id(), mask))
 		func(info);
 
@@ -738,7 +611,7 @@ void flush_tlb_mm(struct mm_struct *mm)
 {
 	cpumask_t mask = mm->cpu_vm_mask;
 
-	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, mask);
 }
 
 void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
@@ -749,7 +622,7 @@ void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
 	ta.ta_vma = vma;
 	ta.ta_start = uaddr;
 
-	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, mask);
 }
 
 void flush_tlb_kernel_page(unsigned long kaddr)
@@ -771,7 +644,7 @@ void flush_tlb_range(struct vm_area_struct *vma,
 	ta.ta_start = start;
 	ta.ta_end = end;
 
-	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, 1, mask);
+	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, mask);
 }
 
 void flush_tlb_kernel_range(unsigned long start, unsigned long end)

commit 5e5419734c8719cbc01af959ad9c0844002c0df5
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Feb 4 22:29:14 2008 -0800

    add mm argument to pte/pmd/pud/pgd_free
    
    (with Martin Schwidefsky <schwidefsky@de.ibm.com>)
    
    The pgd/pud/pmd/pte page table allocation functions get a mm_struct pointer as
    first argument.  The free functions do not get the mm_struct argument.  This
    is 1) asymmetrical and 2) to do mm related page table allocations the mm
    argument is needed on the free function as well.
    
    [kamalesh@linux.vnet.ibm.com: i386 fix]
    [akpm@linux-foundation.org: coding-syle fixes]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Kamalesh Babulal <kamalesh@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e9dfbab46cb6..eefae1de334c 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -150,7 +150,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	secondary_data.pgdir = 0;
 
 	*pmd_offset(pgd, PHYS_OFFSET) = __pmd(0);
-	pgd_free(pgd);
+	pgd_free(&init_mm, pgd);
 
 	if (ret) {
 		printk(KERN_CRIT "CPU%u: processor failed to boot\n", cpu);

commit a8655e83fc44ec2b92cbea9f3ff3cc0da05a991c
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Feb 4 17:30:57 2008 +0100

    [ARM] 4814/1: RealView: Add broadcasting clockevents support for ARM11MPCore
    
    This patch adds dummy local timers for each CPU so that the board clock
    device is used to broadcast events to the other CPUs. The patch also
    adds the declaration for the dummy_timer_setup function (the equivalent
    of local_timer_setup when CONFIG_LOCAL_TIMERS is not set).
    
    Due to the way clockevents work, the dummy timer on the first CPU has to
    be registered before the board timer.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index aef6f9ab900e..e9dfbab46cb6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -290,6 +290,11 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	local_irq_enable();
 	local_fiq_enable();
 
+	/*
+	 * Setup local timer for this CPU.
+	 */
+	local_timer_setup(cpu);
+
 	calibrate_delay();
 
 	smp_store_cpu_info(cpu);
@@ -299,11 +304,6 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 */
 	cpu_set(cpu, cpu_online_map);
 
-	/*
-	 * Setup local timer for this CPU.
-	 */
-	local_timer_setup(cpu);
-
 	/*
 	 * OK, it's off to the idle thread for us
 	 */

commit 3e459990961db7f3f2dcf21e2b38a7216dfd10dd
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Feb 4 17:28:56 2008 +0100

    [ARM] 4813/1: Add SMP helper functions for clockevents support
    
    This patch adds the smp_call_function_single and smp_timer_broadcast
    functions and modifies ipi_timer to call the platform-specific function
    local_timer_interrupt.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index eafbb2b05eb8..aef6f9ab900e 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -454,6 +454,27 @@ int smp_call_function(void (*func)(void *info), void *info, int retry,
 }
 EXPORT_SYMBOL_GPL(smp_call_function);
 
+int smp_call_function_single(int cpu, void (*func)(void *info), void *info,
+			     int retry, int wait)
+{
+	/* prevent preemption and reschedule on another processor */
+	int current_cpu = get_cpu();
+	int ret = 0;
+
+	if (cpu == current_cpu) {
+		local_irq_disable();
+		func(info);
+		local_irq_enable();
+	} else
+		ret = smp_call_function_on_cpu(func, info, retry, wait,
+					       cpumask_of_cpu(cpu));
+
+	put_cpu();
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(smp_call_function_single);
+
 void show_ipi_list(struct seq_file *p)
 {
 	unsigned int cpu;
@@ -481,8 +502,7 @@ void show_local_irqs(struct seq_file *p)
 static void ipi_timer(void)
 {
 	irq_enter();
-	profile_tick(CPU_PROFILING);
-	update_process_times(user_mode(get_irq_regs()));
+	local_timer_interrupt();
 	irq_exit();
 }
 
@@ -621,6 +641,11 @@ void smp_send_timer(void)
 	send_ipi_message(mask, IPI_TIMER);
 }
 
+void smp_timer_broadcast(cpumask_t mask)
+{
+	send_ipi_message(mask, IPI_TIMER);
+}
+
 void smp_send_stop(void)
 {
 	cpumask_t mask = cpu_online_map;

commit 4e950f6f0189f65f8bf069cf2272649ef418f5e4
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Jul 30 02:36:13 2007 +0400

    Remove fs.h from mm.h
    
    Remove fs.h from mm.h. For this,
     1) Uninline vma_wants_writenotify(). It's pretty huge anyway.
     2) Add back fs.h or less bloated headers (err.h) to files that need it.
    
    As result, on x86_64 allyesconfig, fs.h dependencies cut down from 3929 files
    rebuilt down to 3444 (-12.3%).
    
    Cross-compile tested without regressions on my two usual configs and (sigh):
    
    alpha              arm-mx1ads        mips-bigsur          powerpc-ebony
    alpha-allnoconfig  arm-neponset      mips-capcella        powerpc-g5
    alpha-defconfig    arm-netwinder     mips-cobalt          powerpc-holly
    alpha-up           arm-netx          mips-db1000          powerpc-iseries
    arm                arm-ns9xxx        mips-db1100          powerpc-linkstation
    arm-assabet        arm-omap_h2_1610  mips-db1200          powerpc-lite5200
    arm-at91rm9200dk   arm-onearm        mips-db1500          powerpc-maple
    arm-at91rm9200ek   arm-picotux200    mips-db1550          powerpc-mpc7448_hpc2
    arm-at91sam9260ek  arm-pleb          mips-ddb5477         powerpc-mpc8272_ads
    arm-at91sam9261ek  arm-pnx4008       mips-decstation      powerpc-mpc8313_rdb
    arm-at91sam9263ek  arm-pxa255-idp    mips-e55             powerpc-mpc832x_mds
    arm-at91sam9rlek   arm-realview      mips-emma2rh         powerpc-mpc832x_rdb
    arm-ateb9200       arm-realview-smp  mips-excite          powerpc-mpc834x_itx
    arm-badge4         arm-rpc           mips-fulong          powerpc-mpc834x_itxgp
    arm-carmeva        arm-s3c2410       mips-ip22            powerpc-mpc834x_mds
    arm-cerfcube       arm-shannon       mips-ip27            powerpc-mpc836x_mds
    arm-clps7500       arm-shark         mips-ip32            powerpc-mpc8540_ads
    arm-collie         arm-simpad        mips-jazz            powerpc-mpc8544_ds
    arm-corgi          arm-spitz         mips-jmr3927         powerpc-mpc8560_ads
    arm-csb337         arm-trizeps4      mips-malta           powerpc-mpc8568mds
    arm-csb637         arm-versatile     mips-mipssim         powerpc-mpc85xx_cds
    arm-ebsa110        i386              mips-mpc30x          powerpc-mpc8641_hpcn
    arm-edb7211        i386-allnoconfig  mips-msp71xx         powerpc-mpc866_ads
    arm-em_x270        i386-defconfig    mips-ocelot          powerpc-mpc885_ads
    arm-ep93xx         i386-up           mips-pb1100          powerpc-pasemi
    arm-footbridge     ia64              mips-pb1500          powerpc-pmac32
    arm-fortunet       ia64-allnoconfig  mips-pb1550          powerpc-ppc64
    arm-h3600          ia64-bigsur       mips-pnx8550-jbs     powerpc-prpmc2800
    arm-h7201          ia64-defconfig    mips-pnx8550-stb810  powerpc-ps3
    arm-h7202          ia64-gensparse    mips-qemu            powerpc-pseries
    arm-hackkit        ia64-sim          mips-rbhma4200       powerpc-up
    arm-integrator     ia64-sn2          mips-rbhma4500       s390
    arm-iop13xx        ia64-tiger        mips-rm200           s390-allnoconfig
    arm-iop32x         ia64-up           mips-sb1250-swarm    s390-defconfig
    arm-iop33x         ia64-zx1          mips-sead            s390-up
    arm-ixp2000        m68k              mips-tb0219          sparc
    arm-ixp23xx        m68k-amiga        mips-tb0226          sparc-allnoconfig
    arm-ixp4xx         m68k-apollo       mips-tb0287          sparc-defconfig
    arm-jornada720     m68k-atari        mips-workpad         sparc-up
    arm-kafa           m68k-bvme6000     mips-wrppmc          sparc64
    arm-kb9202         m68k-hp300        mips-yosemite        sparc64-allnoconfig
    arm-ks8695         m68k-mac          parisc               sparc64-defconfig
    arm-lart           m68k-mvme147      parisc-allnoconfig   sparc64-up
    arm-lpd270         m68k-mvme16x      parisc-defconfig     um-x86_64
    arm-lpd7a400       m68k-q40          parisc-up            x86_64
    arm-lpd7a404       m68k-sun3         powerpc              x86_64-allnoconfig
    arm-lubbock        m68k-sun3x        powerpc-cell         x86_64-defconfig
    arm-lusl7200       mips              powerpc-celleb       x86_64-up
    arm-mainstone      mips-atlas        powerpc-chrp32
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 9746e5293249..eafbb2b05eb8 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -17,6 +17,7 @@
 #include <linux/profile.h>
 #include <linux/errno.h>
 #include <linux/mm.h>
+#include <linux/err.h>
 #include <linux/cpu.h>
 #include <linux/smp.h>
 #include <linux/seq_file.h>

commit 5048bcba4d27d975593ef5c55f217aafe015ec3b
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Jul 23 12:59:46 2007 +0100

    [ARM] setup_profiling_timer must not be __init
    
    It's called by writes to /proc/profile, so it must not be marked __init
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1b76d87fa335..9746e5293249 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -630,7 +630,7 @@ void smp_send_stop(void)
 /*
  * not supported here
  */
-int __init setup_profiling_timer(unsigned int multiplier)
+int setup_profiling_timer(unsigned int multiplier)
 {
 	return -EINVAL;
 }

commit b9811d7fde6136bb3dc78dd4f4dd4f54be725b25
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue May 8 11:31:07 2007 +0100

    [ARM] Mark SMP local timer and IPI as exception entries
    
    This allows the backtrace to dump the exception stack contents.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 070bcb7a6306..1b76d87fa335 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -486,7 +486,7 @@ static void ipi_timer(void)
 }
 
 #ifdef CONFIG_LOCAL_TIMERS
-asmlinkage void do_local_timer(struct pt_regs *regs)
+asmlinkage void __exception do_local_timer(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	int cpu = smp_processor_id();
@@ -551,7 +551,7 @@ static void ipi_cpu_stop(unsigned int cpu)
  *
  *  Bit 0 - Inter-processor function call
  */
-asmlinkage void do_IPI(struct pt_regs *regs)
+asmlinkage void __exception do_IPI(struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);

commit e730bf96c89b27b2a90ae3e8054dae6133b4f90b
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Nov 25 20:15:12 2006 +0000

    [ARM] Export smp_call_function()
    
    smp_call_function() will be used with the MP/core oprofile support
    patch.  Export it as _GPL.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index a07d202143c3..070bcb7a6306 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -451,6 +451,7 @@ int smp_call_function(void (*func)(void *info), void *info, int retry,
 	return smp_call_function_on_cpu(func, info, retry, wait,
 					cpu_online_map);
 }
+EXPORT_SYMBOL_GPL(smp_call_function);
 
 void show_ipi_list(struct seq_file *p)
 {

commit c97d4869a23c439d2bc23cb26c1147c099f9ff78
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Oct 25 13:59:16 2006 +0100

    [ARM] Fix SMP irqflags support
    
    The IRQ changes a while back broke the build for SMP machines.
    Fix up the SMP code to use set_irq_regs/get_irq_regs as
    appropriate.  Also, fix a warning in arch/arm/kernel/time.c
    where 'regs' becomes unused for SMP builds.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 421329f5e18e..a07d202143c3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -7,6 +7,7 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
+#include <linux/module.h>
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/spinlock.h>
@@ -19,6 +20,7 @@
 #include <linux/cpu.h>
 #include <linux/smp.h>
 #include <linux/seq_file.h>
+#include <linux/irq.h>
 
 #include <asm/atomic.h>
 #include <asm/cacheflush.h>
@@ -474,25 +476,26 @@ void show_local_irqs(struct seq_file *p)
 	seq_putc(p, '\n');
 }
 
-static void ipi_timer(struct pt_regs *regs)
+static void ipi_timer(void)
 {
-	int user = user_mode(regs);
-
 	irq_enter();
-	profile_tick(CPU_PROFILING, regs);
-	update_process_times(user);
+	profile_tick(CPU_PROFILING);
+	update_process_times(user_mode(get_irq_regs()));
 	irq_exit();
 }
 
 #ifdef CONFIG_LOCAL_TIMERS
 asmlinkage void do_local_timer(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs = set_irq_regs(regs);
 	int cpu = smp_processor_id();
 
 	if (local_timer_ack()) {
 		irq_stat[cpu].local_timer_irqs++;
-		ipi_timer(regs);
+		ipi_timer();
 	}
+
+	set_irq_regs(old_regs);
 }
 #endif
 
@@ -551,6 +554,7 @@ asmlinkage void do_IPI(struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
+	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	ipi->ipi_count++;
 
@@ -574,7 +578,7 @@ asmlinkage void do_IPI(struct pt_regs *regs)
 
 			switch (nextmsg) {
 			case IPI_TIMER:
-				ipi_timer(regs);
+				ipi_timer();
 				break;
 
 			case IPI_RESCHEDULE:
@@ -599,6 +603,8 @@ asmlinkage void do_IPI(struct pt_regs *regs)
 			}
 		} while (msgs);
 	}
+
+	set_irq_regs(old_regs);
 }
 
 void smp_send_reschedule(int cpu)

commit e16b38f71322efd8a221f64b6ddc0748d21d2e1a
Author: Greg Banks <gnb@melbourne.sgi.com>
Date:   Mon Oct 2 02:17:40 2006 -0700

    [PATCH] cpumask: export cpu_online_map and cpu_possible_map consistently
    
    cpumask: ensure that the cpu_online_map and cpu_possible_map bitmasks, and
    hence all the macros in <linux/cpumask.h> that require them, are available to
    modules for all supported combinations of architecture and CONFIG_SMP.
    
    Signed-off-by: Greg Banks <gnb@melbourne.sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 68e9634d260a..421329f5e18e 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -36,7 +36,9 @@
  * The online bitmask indicates that the CPU is up and running.
  */
 cpumask_t cpu_possible_map;
+EXPORT_SYMBOL(cpu_possible_map);
 cpumask_t cpu_online_map;
+EXPORT_SYMBOL(cpu_online_map);
 
 /*
  * as from 2.5, kernels no longer have an init_tasks structure

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 1370d726dc10..68e9634d260a 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -7,7 +7,6 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
-#include <linux/config.h>
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/spinlock.h>

commit 091c539f08a6700e0cca8cd620c3d72dd9f9e2bb
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Mar 25 21:37:29 2006 +0000

    [ARM] SMP: don't set cpu_*_map in smp_prepare_boot_cpu
    
    The recent addition of boot_cpu_init() implements the initialisation
    of the online, present and possible cpu maps for the boot CPU, so
    there is no reason to duplicate this in the architecture
    smp_prepare_boot_cpu() hook.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 02aa300c4633..1370d726dc10 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -337,9 +337,6 @@ void __init smp_prepare_boot_cpu(void)
 	unsigned int cpu = smp_processor_id();
 
 	per_cpu(cpu_data, cpu).idle = current;
-
-	cpu_set(cpu, cpu_present_map);
-	cpu_set(cpu, cpu_online_map);
 }
 
 static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)

commit 7bbb79403163e047c6e333ff169db34e3c969e65
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Feb 16 11:08:09 2006 +0000

    [ARM] Fix SMP initialisation oops
    
    A change to the SMP initialisation caused the following oops:
    
     CPU1: Booted secondary processor
     CPU1: D VIPT write-back cache
     CPU1: I cache: 32768 bytes, associativity 4, 32 byte lines, 256 sets
     CPU1: D cache: 32768 bytes, associativity 4, 32 byte lines, 256 sets
     <7>Calibrating delay loop... 83.14 BogoMIPS (lpj=415744)
     <1>Unable to handle kernel NULL pointer dereference at virtual address 0000001c
     ...
     PC is at enqueue_task+0x1c/0x64
     LR is at activate_task+0xcc/0xe4
    
    SMP initialisation now requires cpu_possible_map to be initialised in
    setup_arch().  Move this from smp_prepare_cpus() to smp_init_cpus()
    and call it from our setup_arch() if CONFIG_SMP is enabled.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7338948bd7d3..02aa300c4633 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -338,7 +338,6 @@ void __init smp_prepare_boot_cpu(void)
 
 	per_cpu(cpu_data, cpu).idle = current;
 
-	cpu_set(cpu, cpu_possible_map);
 	cpu_set(cpu, cpu_present_map);
 	cpu_set(cpu, cpu_online_map);
 }

commit 32d39a9355780bc9aadcf76a2d2004bdbe0f4665
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jan 12 01:05:58 2006 -0800

    [PATCH] arm: task_stack_page()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 373c0959bc2f..7338948bd7d3 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -114,7 +114,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
 	 */
-	secondary_data.stack = (void *)idle->thread_info + THREAD_START_SP;
+	secondary_data.stack = task_stack_page(idle) + THREAD_START_SP;
 	secondary_data.pgdir = virt_to_phys(pgd);
 	wmb();
 
@@ -245,7 +245,7 @@ void __cpuexit cpu_die(void)
 	__asm__("mov	sp, %0\n"
 	"	b	secondary_start_kernel"
 		:
-		: "r" ((void *)current->thread_info + THREAD_SIZE - 8));
+		: "r" (task_stack_page(current) + THREAD_SIZE - 8));
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 

commit da2660d2c40496b1699c4de652f6d0cfd13937c0
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Nov 12 17:21:47 2005 +0000

    [ARM] Restore apparant pointless change in arch/arm/kernel/smp.c
    
    Restore smp.c back to how it used to be.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e55ea952f7aa..373c0959bc2f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -256,9 +256,7 @@ void __cpuexit cpu_die(void)
 asmlinkage void __cpuinit secondary_start_kernel(void)
 {
 	struct mm_struct *mm = &init_mm;
-	unsigned int cpu;
-
-	cpu = smp_processor_id();
+	unsigned int cpu = smp_processor_id();
 
 	printk("CPU%u: Booted secondary processor\n", cpu);
 

commit 5bfb5d690f36d316a5f3b4f7775fda996faa6b12
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Tue Nov 8 21:39:01 2005 -0800

    [PATCH] sched: disable preempt in idle tasks
    
    Run idle threads with preempt disabled.
    
    Also corrected a bugs in arm26's cpu_idle (make it actually call schedule()).
    How did it ever work before?
    
    Might fix the CPU hotplugging hang which Nigel Cunningham noted.
    
    We think the bug hits if the idle thread is preempted after checking
    need_resched() and before going to sleep, then the CPU offlined.
    
    After calling stop_machine_run, the CPU eventually returns from preemption and
    into the idle thread and goes to sleep.  The CPU will continue executing
    previous idle and have no chance to call play_dead.
    
    By disabling preemption until we are ready to explicitly schedule, this bug is
    fixed and the idle threads generally become more robust.
    
    From: alexs <ashepard@u.washington.edu>
    
      PPC build fix
    
    From: Yoichi Yuasa <yuasa@hh.iij4u.or.jp>
    
      MIPS build fix
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Yoichi Yuasa <yuasa@hh.iij4u.or.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 77e2e9ca89fa..e55ea952f7aa 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -256,7 +256,9 @@ void __cpuexit cpu_die(void)
 asmlinkage void __cpuinit secondary_start_kernel(void)
 {
 	struct mm_struct *mm = &init_mm;
-	unsigned int cpu = smp_processor_id();
+	unsigned int cpu;
+
+	cpu = smp_processor_id();
 
 	printk("CPU%u: Booted secondary processor\n", cpu);
 
@@ -273,6 +275,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	local_flush_tlb_all();
 
 	cpu_init();
+	preempt_disable();
 
 	/*
 	 * Give the platform a chance to do its own initialisation.

commit 37ee16ae93a3e4ae7dd51beb81d249f5f12a55c2
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Nov 8 19:08:05 2005 +0000

    [ARM SMP] Add core ARM support for local timers
    
    Add infrastructure for supporting per-cpu local timers to update
    the profiling information and update system time accounting.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index f5fc57e0fe41..77e2e9ca89fa 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -184,6 +184,11 @@ int __cpuexit __cpu_disable(void)
 	 */
 	migrate_irqs();
 
+	/*
+	 * Stop the local timer for this CPU.
+	 */
+	local_timer_stop(cpu);
+
 	/*
 	 * Flush user cache and TLB mappings, and then remove this CPU
 	 * from the vm mask set of all processes.
@@ -289,6 +294,11 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 */
 	cpu_set(cpu, cpu_online_map);
 
+	/*
+	 * Setup local timer for this CPU.
+	 */
+	local_timer_setup(cpu);
+
 	/*
 	 * OK, it's off to the idle thread for us
 	 */
@@ -454,6 +464,18 @@ void show_ipi_list(struct seq_file *p)
 	seq_putc(p, '\n');
 }
 
+void show_local_irqs(struct seq_file *p)
+{
+	unsigned int cpu;
+
+	seq_printf(p, "LOC: ");
+
+	for_each_present_cpu(cpu)
+		seq_printf(p, "%10u ", irq_stat[cpu].local_timer_irqs);
+
+	seq_putc(p, '\n');
+}
+
 static void ipi_timer(struct pt_regs *regs)
 {
 	int user = user_mode(regs);
@@ -464,6 +486,18 @@ static void ipi_timer(struct pt_regs *regs)
 	irq_exit();
 }
 
+#ifdef CONFIG_LOCAL_TIMERS
+asmlinkage void do_local_timer(struct pt_regs *regs)
+{
+	int cpu = smp_processor_id();
+
+	if (local_timer_ack()) {
+		irq_stat[cpu].local_timer_irqs++;
+		ipi_timer(regs);
+	}
+}
+#endif
+
 /*
  * ipi_call_function - handle IPI from smp_call_function()
  *

commit 2c250134952aac06edbdce5e61f0bd8737dcf3ad
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Nov 8 14:44:15 2005 +0000

    [ARM] More sparse fixes
    
    arch/arm/kernel/irq.c:998:26: warning: Using plain integer as NULL pointer
    arch/arm/kernel/smp.c:145:25: warning: Using plain integer as NULL pointer
    arch/arm/kernel/smp.c:362:5: warning: symbol 'smp_call_function_on_cpu' was not declared. Should it be static?
    drivers/video/amba-clcd.c:521:12: warning: symbol 'amba_clcdfb_init' was not declared. Should it be static?
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index f65750a3d28b..f5fc57e0fe41 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -515,7 +515,7 @@ static void ipi_cpu_stop(unsigned int cpu)
  *
  *  Bit 0 - Inter-processor function call
  */
-void do_IPI(struct pt_regs *regs)
+asmlinkage void do_IPI(struct pt_regs *regs)
 {
 	unsigned int cpu = smp_processor_id();
 	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);

commit 5d43045bcd296f9f269ab266bf26cd667d8d560c
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Nov 8 10:44:46 2005 +0000

    [ARM SMP] Fix some sparse warnings in SMP code
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index edb5a406922f..f65750a3d28b 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -142,7 +142,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 			ret = -EIO;
 	}
 
-	secondary_data.stack = 0;
+	secondary_data.stack = NULL;
 	secondary_data.pgdir = 0;
 
 	*pmd_offset(pgd, PHYS_OFFSET) = __pmd(0);
@@ -359,8 +359,8 @@ static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)
  * You must not call this function with disabled interrupts, from a
  * hardware interrupt handler, nor from a bottom half handler.
  */
-int smp_call_function_on_cpu(void (*func)(void *info), void *info, int retry,
-                             int wait, cpumask_t callmap)
+static int smp_call_function_on_cpu(void (*func)(void *info), void *info,
+				    int retry, int wait, cpumask_t callmap)
 {
 	struct smp_call_struct data;
 	unsigned long timeout;

commit a054a811597a17ffbe92bc4db04a4dc2f1b1ea55
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Nov 2 22:24:33 2005 +0000

    [ARM SMP] Add hotplug CPU infrastructure
    
    This patch adds the infrastructure to support hotplug CPU on ARM
    platforms.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b40915dcd533..edb5a406922f 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -159,6 +159,91 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	return ret;
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/*
+ * __cpu_disable runs on the processor to be shutdown.
+ */
+int __cpuexit __cpu_disable(void)
+{
+	unsigned int cpu = smp_processor_id();
+	struct task_struct *p;
+	int ret;
+
+	ret = mach_cpu_disable(cpu);
+	if (ret)
+		return ret;
+
+	/*
+	 * Take this CPU offline.  Once we clear this, we can't return,
+	 * and we must not schedule until we're ready to give up the cpu.
+	 */
+	cpu_clear(cpu, cpu_online_map);
+
+	/*
+	 * OK - migrate IRQs away from this CPU
+	 */
+	migrate_irqs();
+
+	/*
+	 * Flush user cache and TLB mappings, and then remove this CPU
+	 * from the vm mask set of all processes.
+	 */
+	flush_cache_all();
+	local_flush_tlb_all();
+
+	read_lock(&tasklist_lock);
+	for_each_process(p) {
+		if (p->mm)
+			cpu_clear(cpu, p->mm->cpu_vm_mask);
+	}
+	read_unlock(&tasklist_lock);
+
+	return 0;
+}
+
+/*
+ * called on the thread which is asking for a CPU to be shutdown -
+ * waits until shutdown has completed, or it is timed out.
+ */
+void __cpuexit __cpu_die(unsigned int cpu)
+{
+	if (!platform_cpu_kill(cpu))
+		printk("CPU%u: unable to kill\n", cpu);
+}
+
+/*
+ * Called from the idle thread for the CPU which has been shutdown.
+ *
+ * Note that we disable IRQs here, but do not re-enable them
+ * before returning to the caller. This is also the behaviour
+ * of the other hotplug-cpu capable cores, so presumably coming
+ * out of idle fixes this.
+ */
+void __cpuexit cpu_die(void)
+{
+	unsigned int cpu = smp_processor_id();
+
+	local_irq_disable();
+	idle_task_exit();
+
+	/*
+	 * actual CPU shutdown procedure is at least platform (if not
+	 * CPU) specific
+	 */
+	platform_cpu_die(cpu);
+
+	/*
+	 * Do not return to the idle loop - jump back to the secondary
+	 * cpu initialisation.  There's some initialisation which needs
+	 * to be repeated to undo the effects of taking the CPU offline.
+	 */
+	__asm__("mov	sp, %0\n"
+	"	b	secondary_start_kernel"
+		:
+		: "r" ((void *)current->thread_info + THREAD_SIZE - 8));
+}
+#endif /* CONFIG_HOTPLUG_CPU */
+
 /*
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.

commit 273c2cdb2b6d6743d85ddbde82e71f8adbf5bf10
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Nov 2 21:54:14 2005 +0000

    [ARM SMP] Fix a couple of warnings
    
    Use *cpus_addr() to display the mask of pending/to be called CPUs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 45877f5d5717..b40915dcd533 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -315,8 +315,8 @@ int smp_call_function_on_cpu(void (*func)(void *info), void *info, int retry,
 		printk(KERN_CRIT
 		       "CPU%u: smp_call_function timeout for %p(%p)\n"
 		       "      callmap %lx pending %lx, %swait\n",
-		       smp_processor_id(), func, info, callmap, data.pending,
-		       wait ? "" : "no ");
+		       smp_processor_id(), func, info, *cpus_addr(callmap),
+		       *cpus_addr(data.pending), wait ? "" : "no ");
 
 		/*
 		 * TRACE

commit 71f512e89704f5aa6fc0b97e4a719184080b8938
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Nov 2 21:51:40 2005 +0000

    [ARM SMP] Track CPU idle threads
    
    Track the idle thread task_struct for each CPU.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 826164945747..45877f5d5717 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -80,19 +80,23 @@ static DEFINE_SPINLOCK(smp_call_function_lock);
 
 int __cpuinit __cpu_up(unsigned int cpu)
 {
-	struct task_struct *idle;
+	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
+	struct task_struct *idle = ci->idle;
 	pgd_t *pgd;
 	pmd_t *pmd;
 	int ret;
 
 	/*
-	 * Spawn a new process manually.  Grab a pointer to
-	 * its task struct so we can mess with it
+	 * Spawn a new process manually, if not already done.
+	 * Grab a pointer to its task struct so we can mess with it
 	 */
-	idle = fork_idle(cpu);
-	if (IS_ERR(idle)) {
-		printk(KERN_ERR "CPU%u: fork() failed\n", cpu);
-		return PTR_ERR(idle);
+	if (!idle) {
+		idle = fork_idle(cpu);
+		if (IS_ERR(idle)) {
+			printk(KERN_ERR "CPU%u: fork() failed\n", cpu);
+			return PTR_ERR(idle);
+		}
+		ci->idle = idle;
 	}
 
 	/*
@@ -236,6 +240,8 @@ void __init smp_prepare_boot_cpu(void)
 {
 	unsigned int cpu = smp_processor_id();
 
+	per_cpu(cpu_data, cpu).idle = current;
+
 	cpu_set(cpu, cpu_possible_map);
 	cpu_set(cpu, cpu_present_map);
 	cpu_set(cpu, cpu_online_map);

commit 7db078be194469490caacac7d13bace38eaebdf5
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun Sep 4 11:03:15 2005 +0100

    [ARM] Stack starts at THREAD_START_SP offset, not THREAD_SIZE-8
    
    Use the correct constants.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index b2085735a2ba..826164945747 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -110,7 +110,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 	 * We need to tell the secondary core where to find
 	 * its stack and the page tables.
 	 */
-	secondary_data.stack = (void *)idle->thread_info + THREAD_SIZE - 8;
+	secondary_data.stack = (void *)idle->thread_info + THREAD_START_SP;
 	secondary_data.pgdir = virt_to_phys(pgd);
 	wmb();
 

commit 505d7b193181be029f4f9aea59e6bdbfdd1e9e76
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Jul 28 20:32:47 2005 +0100

    [ARM SMP] Ensure secondary CPUs have a clean TLB
    
    Since ARMv6 CPUs will not flush the TLB on context switches, it is
    possible that we may end up with some global TLB entries remaining
    present, eventually upsetting userspace.  Explicitly flush the
    entire TLB on secondary CPUs as they startup, after we have switched
    to the init_mm page tables.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 295e0a8379cf..b2085735a2ba 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -176,6 +176,7 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	cpu_set(cpu, mm->cpu_vm_mask);
 	cpu_switch_mm(mm->pgd, mm);
 	enter_lazy_tlb(mm, current);
+	local_flush_tlb_all();
 
 	cpu_init();
 

commit bd6f68af298cab4e059f8489b56e46ae36243fcc
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun Jul 17 21:35:41 2005 +0100

    [PATCH] ARM SMP: Mark CPU init functions/data with __cpuinit/...data
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 7ae45c3fc834..295e0a8379cf 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -78,7 +78,7 @@ struct smp_call_struct {
 static struct smp_call_struct * volatile smp_call_function_data;
 static DEFINE_SPINLOCK(smp_call_function_lock);
 
-int __init __cpu_up(unsigned int cpu)
+int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct task_struct *idle;
 	pgd_t *pgd;
@@ -159,7 +159,7 @@ int __init __cpu_up(unsigned int cpu)
  * This is the secondary CPU boot entry.  We're using this CPUs
  * idle thread stack, but a set of temporary page tables.
  */
-asmlinkage void __init secondary_start_kernel(void)
+asmlinkage void __cpuinit secondary_start_kernel(void)
 {
 	struct mm_struct *mm = &init_mm;
 	unsigned int cpu = smp_processor_id();
@@ -209,7 +209,7 @@ asmlinkage void __init secondary_start_kernel(void)
  * Called by both boot and secondaries to move global data into
  * per-processor storage.
  */
-void __init smp_store_cpu_info(unsigned int cpuid)
+void __cpuinit smp_store_cpu_info(unsigned int cpuid)
 {
 	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
 

commit 73eb7d9e8cfd16813eec94d0ec8fa2a5262a85cc
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Jul 11 19:42:58 2005 +0100

    [PATCH] ARM SMP: Initialise cpu_present_map
    
    Rather than relying on the fixup code in init/main.c, explicitly
    initialise cpu_present_map.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 78c24a1266b1..7ae45c3fc834 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -236,6 +236,7 @@ void __init smp_prepare_boot_cpu(void)
 	unsigned int cpu = smp_processor_id();
 
 	cpu_set(cpu, cpu_possible_map);
+	cpu_set(cpu, cpu_present_map);
 	cpu_set(cpu, cpu_online_map);
 }
 

commit e11b2236eace94ad9a2e421904742e83976405ed
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Jul 11 19:26:31 2005 +0100

    [PATCH] ARM SMP: We list IRQs for present CPUs, not online CPUs
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 44a27b2a3c29..78c24a1266b1 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -355,7 +355,7 @@ void show_ipi_list(struct seq_file *p)
 
 	seq_puts(p, "IPI:");
 
-	for_each_online_cpu(cpu)
+	for_each_present_cpu(cpu)
 		seq_printf(p, " %10lu", per_cpu(ipi_data, cpu).ipi_count);
 
 	seq_putc(p, '\n');

commit d12734d14e5602816f0b16b17a8cef5ea70afb5a
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Jul 11 17:38:36 2005 +0100

    [PATCH] ARM SMP: Rename cpu_present_mask to cpu_possible_map
    
    The kernel's terminology for this is cpu_possible_map not
    cpu_present_mask.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index a931409c8fe4..44a27b2a3c29 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -36,7 +36,7 @@
  * The present bitmask indicates that the CPU is physically present.
  * The online bitmask indicates that the CPU is up and running.
  */
-cpumask_t cpu_present_mask;
+cpumask_t cpu_possible_map;
 cpumask_t cpu_online_map;
 
 /*
@@ -235,7 +235,7 @@ void __init smp_prepare_boot_cpu(void)
 {
 	unsigned int cpu = smp_processor_id();
 
-	cpu_set(cpu, cpu_present_mask);
+	cpu_set(cpu, cpu_possible_map);
 	cpu_set(cpu, cpu_online_map);
 }
 

commit 4b0ef3b1127776d4a2787d7530ac0c4da82c2331
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Jun 28 13:49:16 2005 +0100

    [PATCH] ARM SMP: Add IPI support code for SMP TLB flushing
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 34892758f098..a931409c8fe4 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -502,3 +502,126 @@ int __init setup_profiling_timer(unsigned int multiplier)
 {
 	return -EINVAL;
 }
+
+static int
+on_each_cpu_mask(void (*func)(void *), void *info, int retry, int wait,
+		 cpumask_t mask)
+{
+	int ret = 0;
+
+	preempt_disable();
+
+	ret = smp_call_function_on_cpu(func, info, retry, wait, mask);
+	if (cpu_isset(smp_processor_id(), mask))
+		func(info);
+
+	preempt_enable();
+
+	return ret;
+}
+
+/**********************************************************************/
+
+/*
+ * TLB operations
+ */
+struct tlb_args {
+	struct vm_area_struct *ta_vma;
+	unsigned long ta_start;
+	unsigned long ta_end;
+};
+
+static inline void ipi_flush_tlb_all(void *ignored)
+{
+	local_flush_tlb_all();
+}
+
+static inline void ipi_flush_tlb_mm(void *arg)
+{
+	struct mm_struct *mm = (struct mm_struct *)arg;
+
+	local_flush_tlb_mm(mm);
+}
+
+static inline void ipi_flush_tlb_page(void *arg)
+{
+	struct tlb_args *ta = (struct tlb_args *)arg;
+
+	local_flush_tlb_page(ta->ta_vma, ta->ta_start);
+}
+
+static inline void ipi_flush_tlb_kernel_page(void *arg)
+{
+	struct tlb_args *ta = (struct tlb_args *)arg;
+
+	local_flush_tlb_kernel_page(ta->ta_start);
+}
+
+static inline void ipi_flush_tlb_range(void *arg)
+{
+	struct tlb_args *ta = (struct tlb_args *)arg;
+
+	local_flush_tlb_range(ta->ta_vma, ta->ta_start, ta->ta_end);
+}
+
+static inline void ipi_flush_tlb_kernel_range(void *arg)
+{
+	struct tlb_args *ta = (struct tlb_args *)arg;
+
+	local_flush_tlb_kernel_range(ta->ta_start, ta->ta_end);
+}
+
+void flush_tlb_all(void)
+{
+	on_each_cpu(ipi_flush_tlb_all, NULL, 1, 1);
+}
+
+void flush_tlb_mm(struct mm_struct *mm)
+{
+	cpumask_t mask = mm->cpu_vm_mask;
+
+	on_each_cpu_mask(ipi_flush_tlb_mm, mm, 1, 1, mask);
+}
+
+void flush_tlb_page(struct vm_area_struct *vma, unsigned long uaddr)
+{
+	cpumask_t mask = vma->vm_mm->cpu_vm_mask;
+	struct tlb_args ta;
+
+	ta.ta_vma = vma;
+	ta.ta_start = uaddr;
+
+	on_each_cpu_mask(ipi_flush_tlb_page, &ta, 1, 1, mask);
+}
+
+void flush_tlb_kernel_page(unsigned long kaddr)
+{
+	struct tlb_args ta;
+
+	ta.ta_start = kaddr;
+
+	on_each_cpu(ipi_flush_tlb_kernel_page, &ta, 1, 1);
+}
+
+void flush_tlb_range(struct vm_area_struct *vma,
+                     unsigned long start, unsigned long end)
+{
+	cpumask_t mask = vma->vm_mm->cpu_vm_mask;
+	struct tlb_args ta;
+
+	ta.ta_vma = vma;
+	ta.ta_start = start;
+	ta.ta_end = end;
+
+	on_each_cpu_mask(ipi_flush_tlb_range, &ta, 1, 1, mask);
+}
+
+void flush_tlb_kernel_range(unsigned long start, unsigned long end)
+{
+	struct tlb_args ta;
+
+	ta.ta_start = start;
+	ta.ta_end = end;
+
+	on_each_cpu(ipi_flush_tlb_kernel_range, &ta, 1, 1);
+}

commit 0908db22b189b28664cba3965ebb7e0df59c749a
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun Jun 19 19:48:16 2005 +0100

    [PATCH] ARM SMP: Messages about CPUs should be prefixed by CPU%u
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 45ed036336e0..34892758f098 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -145,7 +145,8 @@ int __init __cpu_up(unsigned int cpu)
 	pgd_free(pgd);
 
 	if (ret) {
-		printk(KERN_CRIT "cpu_up: processor %d failed to boot\n", cpu);
+		printk(KERN_CRIT "CPU%u: processor failed to boot\n", cpu);
+
 		/*
 		 * FIXME: We need to clean up the new idle thread. --rmk
 		 */

commit e65f38ed0bb7af367ff919c573cf29643fc5f9e8
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Jun 18 09:33:31 2005 +0100

    [PATCH] ARM SMP: Add support for startup of secondary processors
    
    Create a temporary page table to startup secondary processors.  This
    page table must have a 1:1 virtual/physical mapping for the kernel
    in addition to the standard mappings to ensure that the secondary
    CPU can enable its MMU safely.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index ecc8c3332408..45ed036336e0 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -24,6 +24,9 @@
 #include <asm/atomic.h>
 #include <asm/cacheflush.h>
 #include <asm/cpu.h>
+#include <asm/mmu_context.h>
+#include <asm/pgtable.h>
+#include <asm/pgalloc.h>
 #include <asm/processor.h>
 #include <asm/tlbflush.h>
 #include <asm/ptrace.h>
@@ -36,6 +39,13 @@
 cpumask_t cpu_present_mask;
 cpumask_t cpu_online_map;
 
+/*
+ * as from 2.5, kernels no longer have an init_tasks structure
+ * so we need some other way of telling a new secondary core
+ * where to place its SVC stack
+ */
+struct secondary_data secondary_data;
+
 /*
  * structures for inter-processor calls
  * - A collection of single bit ipi messages.
@@ -71,6 +81,8 @@ static DEFINE_SPINLOCK(smp_call_function_lock);
 int __init __cpu_up(unsigned int cpu)
 {
 	struct task_struct *idle;
+	pgd_t *pgd;
+	pmd_t *pmd;
 	int ret;
 
 	/*
@@ -83,10 +95,55 @@ int __init __cpu_up(unsigned int cpu)
 		return PTR_ERR(idle);
 	}
 
+	/*
+	 * Allocate initial page tables to allow the new CPU to
+	 * enable the MMU safely.  This essentially means a set
+	 * of our "standard" page tables, with the addition of
+	 * a 1:1 mapping for the physical address of the kernel.
+	 */
+	pgd = pgd_alloc(&init_mm);
+	pmd = pmd_offset(pgd, PHYS_OFFSET);
+	*pmd = __pmd((PHYS_OFFSET & PGDIR_MASK) |
+		     PMD_TYPE_SECT | PMD_SECT_AP_WRITE);
+
+	/*
+	 * We need to tell the secondary core where to find
+	 * its stack and the page tables.
+	 */
+	secondary_data.stack = (void *)idle->thread_info + THREAD_SIZE - 8;
+	secondary_data.pgdir = virt_to_phys(pgd);
+	wmb();
+
 	/*
 	 * Now bring the CPU into our world.
 	 */
 	ret = boot_secondary(cpu, idle);
+	if (ret == 0) {
+		unsigned long timeout;
+
+		/*
+		 * CPU was successfully started, wait for it
+		 * to come online or time out.
+		 */
+		timeout = jiffies + HZ;
+		while (time_before(jiffies, timeout)) {
+			if (cpu_online(cpu))
+				break;
+
+			udelay(10);
+			barrier();
+		}
+
+		if (!cpu_online(cpu))
+			ret = -EIO;
+	}
+
+	secondary_data.stack = 0;
+	secondary_data.pgdir = 0;
+
+	*pmd_offset(pgd, PHYS_OFFSET) = __pmd(0);
+	pgd_free(pgd);
+
 	if (ret) {
 		printk(KERN_CRIT "cpu_up: processor %d failed to boot\n", cpu);
 		/*
@@ -97,6 +154,56 @@ int __init __cpu_up(unsigned int cpu)
 	return ret;
 }
 
+/*
+ * This is the secondary CPU boot entry.  We're using this CPUs
+ * idle thread stack, but a set of temporary page tables.
+ */
+asmlinkage void __init secondary_start_kernel(void)
+{
+	struct mm_struct *mm = &init_mm;
+	unsigned int cpu = smp_processor_id();
+
+	printk("CPU%u: Booted secondary processor\n", cpu);
+
+	/*
+	 * All kernel threads share the same mm context; grab a
+	 * reference and switch to it.
+	 */
+	atomic_inc(&mm->mm_users);
+	atomic_inc(&mm->mm_count);
+	current->active_mm = mm;
+	cpu_set(cpu, mm->cpu_vm_mask);
+	cpu_switch_mm(mm->pgd, mm);
+	enter_lazy_tlb(mm, current);
+
+	cpu_init();
+
+	/*
+	 * Give the platform a chance to do its own initialisation.
+	 */
+	platform_secondary_init(cpu);
+
+	/*
+	 * Enable local interrupts.
+	 */
+	local_irq_enable();
+	local_fiq_enable();
+
+	calibrate_delay();
+
+	smp_store_cpu_info(cpu);
+
+	/*
+	 * OK, now it's safe to let the boot CPU continue
+	 */
+	cpu_set(cpu, cpu_online_map);
+
+	/*
+	 * OK, it's off to the idle thread for us
+	 */
+	cpu_idle();
+}
+
 /*
  * Called by both boot and secondaries to move global data into
  * per-processor storage.

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
new file mode 100644
index 000000000000..ecc8c3332408
--- /dev/null
+++ b/arch/arm/kernel/smp.c
@@ -0,0 +1,396 @@
+/*
+ *  linux/arch/arm/kernel/smp.c
+ *
+ *  Copyright (C) 2002 ARM Limited, All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/config.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/cache.h>
+#include <linux/profile.h>
+#include <linux/errno.h>
+#include <linux/mm.h>
+#include <linux/cpu.h>
+#include <linux/smp.h>
+#include <linux/seq_file.h>
+
+#include <asm/atomic.h>
+#include <asm/cacheflush.h>
+#include <asm/cpu.h>
+#include <asm/processor.h>
+#include <asm/tlbflush.h>
+#include <asm/ptrace.h>
+
+/*
+ * bitmask of present and online CPUs.
+ * The present bitmask indicates that the CPU is physically present.
+ * The online bitmask indicates that the CPU is up and running.
+ */
+cpumask_t cpu_present_mask;
+cpumask_t cpu_online_map;
+
+/*
+ * structures for inter-processor calls
+ * - A collection of single bit ipi messages.
+ */
+struct ipi_data {
+	spinlock_t lock;
+	unsigned long ipi_count;
+	unsigned long bits;
+};
+
+static DEFINE_PER_CPU(struct ipi_data, ipi_data) = {
+	.lock	= SPIN_LOCK_UNLOCKED,
+};
+
+enum ipi_msg_type {
+	IPI_TIMER,
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_CPU_STOP,
+};
+
+struct smp_call_struct {
+	void (*func)(void *info);
+	void *info;
+	int wait;
+	cpumask_t pending;
+	cpumask_t unfinished;
+};
+
+static struct smp_call_struct * volatile smp_call_function_data;
+static DEFINE_SPINLOCK(smp_call_function_lock);
+
+int __init __cpu_up(unsigned int cpu)
+{
+	struct task_struct *idle;
+	int ret;
+
+	/*
+	 * Spawn a new process manually.  Grab a pointer to
+	 * its task struct so we can mess with it
+	 */
+	idle = fork_idle(cpu);
+	if (IS_ERR(idle)) {
+		printk(KERN_ERR "CPU%u: fork() failed\n", cpu);
+		return PTR_ERR(idle);
+	}
+
+	/*
+	 * Now bring the CPU into our world.
+	 */
+	ret = boot_secondary(cpu, idle);
+	if (ret) {
+		printk(KERN_CRIT "cpu_up: processor %d failed to boot\n", cpu);
+		/*
+		 * FIXME: We need to clean up the new idle thread. --rmk
+		 */
+	}
+
+	return ret;
+}
+
+/*
+ * Called by both boot and secondaries to move global data into
+ * per-processor storage.
+ */
+void __init smp_store_cpu_info(unsigned int cpuid)
+{
+	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpuid);
+
+	cpu_info->loops_per_jiffy = loops_per_jiffy;
+}
+
+void __init smp_cpus_done(unsigned int max_cpus)
+{
+	int cpu;
+	unsigned long bogosum = 0;
+
+	for_each_online_cpu(cpu)
+		bogosum += per_cpu(cpu_data, cpu).loops_per_jiffy;
+
+	printk(KERN_INFO "SMP: Total of %d processors activated "
+	       "(%lu.%02lu BogoMIPS).\n",
+	       num_online_cpus(),
+	       bogosum / (500000/HZ),
+	       (bogosum / (5000/HZ)) % 100);
+}
+
+void __init smp_prepare_boot_cpu(void)
+{
+	unsigned int cpu = smp_processor_id();
+
+	cpu_set(cpu, cpu_present_mask);
+	cpu_set(cpu, cpu_online_map);
+}
+
+static void send_ipi_message(cpumask_t callmap, enum ipi_msg_type msg)
+{
+	unsigned long flags;
+	unsigned int cpu;
+
+	local_irq_save(flags);
+
+	for_each_cpu_mask(cpu, callmap) {
+		struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
+
+		spin_lock(&ipi->lock);
+		ipi->bits |= 1 << msg;
+		spin_unlock(&ipi->lock);
+	}
+
+	/*
+	 * Call the platform specific cross-CPU call function.
+	 */
+	smp_cross_call(callmap);
+
+	local_irq_restore(flags);
+}
+
+/*
+ * You must not call this function with disabled interrupts, from a
+ * hardware interrupt handler, nor from a bottom half handler.
+ */
+int smp_call_function_on_cpu(void (*func)(void *info), void *info, int retry,
+                             int wait, cpumask_t callmap)
+{
+	struct smp_call_struct data;
+	unsigned long timeout;
+	int ret = 0;
+
+	data.func = func;
+	data.info = info;
+	data.wait = wait;
+
+	cpu_clear(smp_processor_id(), callmap);
+	if (cpus_empty(callmap))
+		goto out;
+
+	data.pending = callmap;
+	if (wait)
+		data.unfinished = callmap;
+
+	/*
+	 * try to get the mutex on smp_call_function_data
+	 */
+	spin_lock(&smp_call_function_lock);
+	smp_call_function_data = &data;
+
+	send_ipi_message(callmap, IPI_CALL_FUNC);
+
+	timeout = jiffies + HZ;
+	while (!cpus_empty(data.pending) && time_before(jiffies, timeout))
+		barrier();
+
+	/*
+	 * did we time out?
+	 */
+	if (!cpus_empty(data.pending)) {
+		/*
+		 * this may be causing our panic - report it
+		 */
+		printk(KERN_CRIT
+		       "CPU%u: smp_call_function timeout for %p(%p)\n"
+		       "      callmap %lx pending %lx, %swait\n",
+		       smp_processor_id(), func, info, callmap, data.pending,
+		       wait ? "" : "no ");
+
+		/*
+		 * TRACE
+		 */
+		timeout = jiffies + (5 * HZ);
+		while (!cpus_empty(data.pending) && time_before(jiffies, timeout))
+			barrier();
+
+		if (cpus_empty(data.pending))
+			printk(KERN_CRIT "     RESOLVED\n");
+		else
+			printk(KERN_CRIT "     STILL STUCK\n");
+	}
+
+	/*
+	 * whatever happened, we're done with the data, so release it
+	 */
+	smp_call_function_data = NULL;
+	spin_unlock(&smp_call_function_lock);
+
+	if (!cpus_empty(data.pending)) {
+		ret = -ETIMEDOUT;
+		goto out;
+	}
+
+	if (wait)
+		while (!cpus_empty(data.unfinished))
+			barrier();
+ out:
+
+	return 0;
+}
+
+int smp_call_function(void (*func)(void *info), void *info, int retry,
+                      int wait)
+{
+	return smp_call_function_on_cpu(func, info, retry, wait,
+					cpu_online_map);
+}
+
+void show_ipi_list(struct seq_file *p)
+{
+	unsigned int cpu;
+
+	seq_puts(p, "IPI:");
+
+	for_each_online_cpu(cpu)
+		seq_printf(p, " %10lu", per_cpu(ipi_data, cpu).ipi_count);
+
+	seq_putc(p, '\n');
+}
+
+static void ipi_timer(struct pt_regs *regs)
+{
+	int user = user_mode(regs);
+
+	irq_enter();
+	profile_tick(CPU_PROFILING, regs);
+	update_process_times(user);
+	irq_exit();
+}
+
+/*
+ * ipi_call_function - handle IPI from smp_call_function()
+ *
+ * Note that we copy data out of the cross-call structure and then
+ * let the caller know that we're here and have done with their data
+ */
+static void ipi_call_function(unsigned int cpu)
+{
+	struct smp_call_struct *data = smp_call_function_data;
+	void (*func)(void *info) = data->func;
+	void *info = data->info;
+	int wait = data->wait;
+
+	cpu_clear(cpu, data->pending);
+
+	func(info);
+
+	if (wait)
+		cpu_clear(cpu, data->unfinished);
+}
+
+static DEFINE_SPINLOCK(stop_lock);
+
+/*
+ * ipi_cpu_stop - handle IPI from smp_send_stop()
+ */
+static void ipi_cpu_stop(unsigned int cpu)
+{
+	spin_lock(&stop_lock);
+	printk(KERN_CRIT "CPU%u: stopping\n", cpu);
+	dump_stack();
+	spin_unlock(&stop_lock);
+
+	cpu_clear(cpu, cpu_online_map);
+
+	local_fiq_disable();
+	local_irq_disable();
+
+	while (1)
+		cpu_relax();
+}
+
+/*
+ * Main handler for inter-processor interrupts
+ *
+ * For ARM, the ipimask now only identifies a single
+ * category of IPI (Bit 1 IPIs have been replaced by a
+ * different mechanism):
+ *
+ *  Bit 0 - Inter-processor function call
+ */
+void do_IPI(struct pt_regs *regs)
+{
+	unsigned int cpu = smp_processor_id();
+	struct ipi_data *ipi = &per_cpu(ipi_data, cpu);
+
+	ipi->ipi_count++;
+
+	for (;;) {
+		unsigned long msgs;
+
+		spin_lock(&ipi->lock);
+		msgs = ipi->bits;
+		ipi->bits = 0;
+		spin_unlock(&ipi->lock);
+
+		if (!msgs)
+			break;
+
+		do {
+			unsigned nextmsg;
+
+			nextmsg = msgs & -msgs;
+			msgs &= ~nextmsg;
+			nextmsg = ffz(~nextmsg);
+
+			switch (nextmsg) {
+			case IPI_TIMER:
+				ipi_timer(regs);
+				break;
+
+			case IPI_RESCHEDULE:
+				/*
+				 * nothing more to do - eveything is
+				 * done on the interrupt return path
+				 */
+				break;
+
+			case IPI_CALL_FUNC:
+				ipi_call_function(cpu);
+				break;
+
+			case IPI_CPU_STOP:
+				ipi_cpu_stop(cpu);
+				break;
+
+			default:
+				printk(KERN_CRIT "CPU%u: Unknown IPI message 0x%x\n",
+				       cpu, nextmsg);
+				break;
+			}
+		} while (msgs);
+	}
+}
+
+void smp_send_reschedule(int cpu)
+{
+	send_ipi_message(cpumask_of_cpu(cpu), IPI_RESCHEDULE);
+}
+
+void smp_send_timer(void)
+{
+	cpumask_t mask = cpu_online_map;
+	cpu_clear(smp_processor_id(), mask);
+	send_ipi_message(mask, IPI_TIMER);
+}
+
+void smp_send_stop(void)
+{
+	cpumask_t mask = cpu_online_map;
+	cpu_clear(smp_processor_id(), mask);
+	send_ipi_message(mask, IPI_CPU_STOP);
+}
+
+/*
+ * not supported here
+ */
+int __init setup_profiling_timer(unsigned int multiplier)
+{
+	return -EINVAL;
+}
