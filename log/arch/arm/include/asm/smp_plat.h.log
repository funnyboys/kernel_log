commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index f9080717fc88..f2c36acf9886 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * ARM specific SMP header, this contains our implementation
  * details.

commit 787047eea24a2443c366679ae6b5a3873a33b64e
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Wed Jul 29 00:34:48 2015 +0100

    ARM: 8392/3: smp: Only expose /sys/.../cpuX/online if hotpluggable
    
    Writes to /sys/.../cpuX/online fail if we determine the platform
    doesn't support hotplug for that CPU. Furthermore, if the cpu_die
    op isn't specified the system hangs when we try to offline a CPU
    and it comes right back online unexpectedly. Let's figure this
    stuff out before we make the sysfs nodes so that the online file
    doesn't even exist if it isn't (at least sometimes) possible to
    hotplug the CPU.
    
    Add a new 'cpu_can_disable' op and repoint all 'cpu_disable'
    implementations at it because all implementers use the op to
    indicate if a CPU can be hotplugged or not in a static fashion.
    With PSCI we may need to add a 'cpu_disable' op so that the
    secure OS can be migrated off the CPU we're trying to hotplug.
    In this case, the 'cpu_can_disable' op will indicate that all
    CPUs are hotpluggable by returning true, but the 'cpu_disable' op
    will make a PSCI migration call and occasionally fail, denying
    the hotplug of a CPU. This shouldn't be any worse than x86 where
    we may indicate that all CPUs are hotpluggable but occasionally
    we can't offline a CPU due to check_irq_vectors_for_cpu_disable()
    failing to find a CPU to move vectors to.
    
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Simon Horman <horms@verge.net.au> [shmobile portion]
    Tested-by: Simon Horman <horms@verge.net.au>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: <linux-sh@vger.kernel.org>
    Tested-by: Tyler Baker <tyler.baker@linaro.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 993e5224d8f7..f9080717fc88 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -107,4 +107,13 @@ static inline u32 mpidr_hash_size(void)
 extern int platform_can_secondary_boot(void);
 extern int platform_can_cpu_hotplug(void);
 
+#ifdef CONFIG_HOTPLUG_CPU
+extern int platform_can_hotplug_cpu(unsigned int cpu);
+#else
+static inline int platform_can_hotplug_cpu(unsigned int cpu)
+{
+	return 0;
+}
+#endif
+
 #endif

commit fee3fd4fd2ad136b26226346c3f8b446cc120bf5
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Wed Apr 1 13:36:57 2015 +0100

    ARM: 8338/1: kexec: Relax SMP validation to improve DT compatibility
    
    When trying to kexec into a new kernel on a platform where multiple CPU
    cores are present, but no SMP bringup code is available yet, the
    kexec_load system call fails with:
    
        kexec_load failed: Invalid argument
    
    The SMP test added to machine_kexec_prepare() in commit 2103f6cba61a8b8b
    ("ARM: 7807/1: kexec: validate CPU hotplug support") wants to prohibit
    kexec on SMP platforms where it cannot disable secondary CPUs.
    However, this test is too strict: if the secondary CPUs couldn't be
    enabled in the first place, there's no need to disable them later at
    kexec time.  Hence skip the test in the absence of SMP bringup code.
    
    This allows to add all CPU cores to the DTS from the beginning, without
    having to implement SMP bringup first, improving DT compatibility.
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Acked-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 0ad7d490ee6f..993e5224d8f7 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -104,6 +104,7 @@ static inline u32 mpidr_hash_size(void)
 	return 1 << mpidr_hash.bits;
 }
 
+extern int platform_can_secondary_boot(void);
 extern int platform_can_cpu_hotplug(void);
 
 #endif

commit eba1c71819d210f5e0d522571f9b8abce94fe9c5
Author: Juri Lelli <juri.lelli@arm.com>
Date:   Fri Aug 15 15:53:14 2014 +0100

    ARM: 8130/1: cpuidle/cpuidle-big_little: fix reading cpu id part number
    
    Commit af040ffc9ba1 ("ARM: make it easier to check the CPU part number
    correctly") changed ARM_CPU_PART_X masks, and the way they are returned and
    checked against. Usage of read_cpuid_part_number() is now deprecated, and
    calling places updated accordingly. This actually broke cpuidle-big_little
    initialization, as bl_idle_driver_init() performs a check using an hardcoded
    mask on cpu_id.
    
    Create an interface to perform the check (that is now even easier to read).
    Define also a proper mask (ARM_CPU_PART_MASK) that makes this kind of checks
    cleaner and helps preventing bugs in the future. Update usage accordingly.
    
    Signed-off-by: Juri Lelli <juri.lelli@arm.com>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index a252c0bfacf5..0ad7d490ee6f 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -8,6 +8,7 @@
 #include <linux/cpumask.h>
 #include <linux/err.h>
 
+#include <asm/cpu.h>
 #include <asm/cputype.h>
 
 /*
@@ -25,6 +26,20 @@ static inline bool is_smp(void)
 #endif
 }
 
+/**
+ * smp_cpuid_part() - return part id for a given cpu
+ * @cpu:	logical cpu id.
+ *
+ * Return: part id of logical cpu passed as argument.
+ */
+static inline unsigned int smp_cpuid_part(int cpu)
+{
+	struct cpuinfo_arm *cpu_info = &per_cpu(cpu_data, cpu);
+
+	return is_smp() ? cpu_info->cpuid & ARM_CPU_PART_MASK :
+			  read_cpuid_part();
+}
+
 /* all SMP configurations have the extended CPUID registers */
 #ifndef CONFIG_MMU
 #define tlb_ops_need_broadcast()	0

commit 2103f6cba61a8b8bea3fc1b63661d830a2125e76
Author: Stephen Warren <swarren@nvidia.com>
Date:   Fri Aug 2 20:52:49 2013 +0100

    ARM: 7807/1: kexec: validate CPU hotplug support
    
    Architectures should fully validate whether kexec is possible as part of
    machine_kexec_prepare(), so that user-space's kexec_load() operation can
    report any problems. Performing validation in machine_kexec() itself is
    too late, since it is not allowed to return.
    
    Prior to this patch, ARM's machine_kexec() was testing after-the-fact
    whether machine_kexec_prepare() was able to disable all but one CPU.
    Instead, modify machine_kexec_prepare() to validate all conditions
    necessary for machine_kexec_prepare()'s to succeed. BUG if the validation
    succeeded, yet disabling the CPUs didn't actually work.
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 6462a721ebd4..a252c0bfacf5 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -88,4 +88,7 @@ static inline u32 mpidr_hash_size(void)
 {
 	return 1 << mpidr_hash.bits;
 }
+
+extern int platform_can_cpu_hotplug(void);
+
 #endif

commit 3c0c01ab742ddfaf6b6f2d64b890e77cda4b7727
Merge: cbd379b10019 809e660f438f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jun 29 11:44:43 2013 +0100

    Merge branch 'devel-stable' into for-next
    
    Conflicts:
            arch/arm/Makefile
            arch/arm/include/asm/glue-proc.h

commit 18d7f152df31e5a326301fdaad385e40874dff80
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Wed Jun 19 10:40:48 2013 +0100

    ARM: 7763/1: kernel: fix __cpu_logical_map default initialization
    
    The __cpu_logical_map array is statically initialized to 0, which is a valid
    MPIDR value. To prevent issues with the current implementation, this patch
    defines an MPIDR_INVALID value, and statically initializes the
    __cpu_logical_map[] array to it. Entries in the arm_dt_init_cpu_maps()
    tmp_map array used to stash DT reg properties while parsing DT are initialized
    with the MPIDR_INVALID value as well for consistency.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index aaa61b6f50ff..e78983202737 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -49,7 +49,7 @@ static inline int cache_ops_need_broadcast(void)
 /*
  * Logical CPU mapping.
  */
-extern int __cpu_logical_map[];
+extern u32 __cpu_logical_map[];
 #define cpu_logical_map(cpu)	__cpu_logical_map[cpu]
 /*
  * Retrieve logical cpu index corresponding to a given MPIDR[23:0]

commit 7604537bbb5720376e8c9e6bc74a8e6305e3094d
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Thu May 16 10:34:30 2013 +0100

    ARM: kernel: implement stack pointer save array through MPIDR hashing
    
    Current implementation of cpu_{suspend}/cpu_{resume} relies on the MPIDR
    to index the array of pointers where the context is saved and restored.
    The current approach works as long as the MPIDR can be considered a
    linear index, so that the pointers array can simply be dereferenced by
    using the MPIDR[7:0] value.
    On ARM multi-cluster systems, where the MPIDR may not be a linear index,
    to properly dereference the stack pointer array, a mapping function should
    be applied to it so that it can be used for arrays look-ups.
    
    This patch adds code in the cpu_{suspend}/cpu_{resume} implementation
    that relies on shifting and ORing hashing method to map a MPIDR value to a
    set of buckets precomputed at boot to have a collision free mapping from
    MPIDR to context pointers.
    
    The hashing algorithm must be simple, fast, and implementable with few
    instructions since in the cpu_resume path the mapping is carried out with
    the MMU off and the I-cache off, hence code and data are fetched from DRAM
    with no-caching available. Simplicity is counterbalanced with a little
    increase of memory (allocated dynamically) for stack pointers buckets, that
    should be anyway fairly limited on most systems.
    
    Memory for context pointers is allocated in a early_initcall with
    size precomputed and stashed previously in kernel data structures.
    Memory for context pointers is allocated through kmalloc; this
    guarantees contiguous physical addresses for the allocated memory which
    is fundamental to the correct functioning of the resume mechanism that
    relies on the context pointer array to be a chunk of contiguous physical
    memory. Virtual to physical address conversion for the context pointer
    array base is carried out at boot to avoid fiddling with virt_to_phys
    conversions in the cpu_resume path which is quite fragile and should be
    optimized to execute as few instructions as possible.
    Virtual and physical context pointer base array addresses are stashed in a
    struct that is accessible from assembly using values generated through the
    asm-offsets.c mechanism.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Colin Cross <ccross@android.com>
    Cc: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Amit Kucheria <amit.kucheria@linaro.org>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Reviewed-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Tested-by: Kevin Hilman <khilman@linaro.org>
    Tested-by: Stephen Warren <swarren@wwwdotorg.org>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index f75f8a234b3f..6e63f29f41b7 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -70,9 +70,15 @@ static inline int get_logical_index(u32 mpidr)
 	return -EINVAL;
 }
 
+/*
+ * NOTE ! Assembly code relies on the following
+ * structure memory layout in order to carry out load
+ * multiple from its base address. For more
+ * information check arch/arm/kernel/sleep.S
+ */
 struct mpidr_hash {
-	u32	mask;
-	u32	shift_aff[3];
+	u32	mask; /* used by sleep.S */
+	u32	shift_aff[3]; /* used by sleep.S */
 	u32	bits;
 };
 

commit 8cf72172d739639f2699131821a3ebc291287cf2
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Thu May 16 10:32:09 2013 +0100

    ARM: kernel: build MPIDR hash function data structure
    
    On ARM SMP systems, cores are identified by their MPIDR register.
    The MPIDR guidelines in the ARM ARM do not provide strict enforcement of
    MPIDR layout, only recommendations that, if followed, split the MPIDR
    on ARM 32 bit platforms in three affinity levels. In multi-cluster
    systems like big.LITTLE, if the affinity guidelines are followed, the
    MPIDR can not be considered an index anymore. This means that the
    association between logical CPU in the kernel and the HW CPU identifier
    becomes somewhat more complicated requiring methods like hashing to
    associate a given MPIDR to a CPU logical index, in order for the look-up
    to be carried out in an efficient and scalable way.
    
    This patch provides a function in the kernel that starting from the
    cpu_logical_map, implement collision-free hashing of MPIDR values by checking
    all significative bits of MPIDR affinity level bitfields. The hashing
    can then be carried out through bits shifting and ORing; the resulting
    hash algorithm is a collision-free though not minimal hash that can be
    executed with few assembly instructions. The mpidr is filtered through a
    mpidr mask that is built by checking all bits that toggle in the set of
    MPIDRs corresponding to possible CPUs. Bits that do not toggle do not carry
    information so they do not contribute to the resulting hash.
    
    Pseudo code:
    
    /* check all bits that toggle, so they are required */
    for (i = 1, mpidr_mask = 0; i < num_possible_cpus(); i++)
            mpidr_mask |= (cpu_logical_map(i) ^ cpu_logical_map(0));
    
    /*
     * Build shifts to be applied to aff0, aff1, aff2 values to hash the mpidr
     * fls() returns the last bit set in a word, 0 if none
     * ffs() returns the first bit set in a word, 0 if none
     */
    fs0 = mpidr_mask[7:0] ? ffs(mpidr_mask[7:0]) - 1 : 0;
    fs1 = mpidr_mask[15:8] ? ffs(mpidr_mask[15:8]) - 1 : 0;
    fs2 = mpidr_mask[23:16] ? ffs(mpidr_mask[23:16]) - 1 : 0;
    ls0 = fls(mpidr_mask[7:0]);
    ls1 = fls(mpidr_mask[15:8]);
    ls2 = fls(mpidr_mask[23:16]);
    bits0 = ls0 - fs0;
    bits1 = ls1 - fs1;
    bits2 = ls2 - fs2;
    aff0_shift = fs0;
    aff1_shift = 8 + fs1 - bits0;
    aff2_shift = 16 + fs2 - (bits0 + bits1);
    u32 hash(u32 mpidr) {
            u32 l0, l1, l2;
            u32 mpidr_masked = mpidr & mpidr_mask;
            l0 = mpidr_masked & 0xff;
            l1 = mpidr_masked & 0xff00;
            l2 = mpidr_masked & 0xff0000;
            return (l0 >> aff0_shift | l1 >> aff1_shift | l2 >> aff2_shift);
    }
    
    The hashing algorithm relies on the inherent properties set in the ARM ARM
    recommendations for the MPIDR. Exotic configurations, where for instance the
    MPIDR values at a given affinity level have large holes, can end up requiring
    big hash tables since the compression of values that can be achieved through
    shifting is somewhat crippled when holes are present. Kernel warns if
    the number of buckets of the resulting hash table exceeds the number of
    possible CPUs by a factor of 4, which is a symptom of a very sparse HW
    MPIDR configuration.
    
    The hash algorithm is quite simple and can easily be implemented in assembly
    code, to be used in code paths where the kernel virtual address space is
    not set-up (ie cpu_resume) and instruction and data fetches are strongly
    ordered so code must be compact and must carry out few data accesses.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Colin Cross <ccross@android.com>
    Cc: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Amit Kucheria <amit.kucheria@linaro.org>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Reviewed-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Shawn Guo <shawn.guo@linaro.org>
    Tested-by: Kevin Hilman <khilman@linaro.org>
    Tested-by: Stephen Warren <swarren@wwwdotorg.org>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 1c7b6f8101ae..f75f8a234b3f 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -70,4 +70,16 @@ static inline int get_logical_index(u32 mpidr)
 	return -EINVAL;
 }
 
+struct mpidr_hash {
+	u32	mask;
+	u32	shift_aff[3];
+	u32	bits;
+};
+
+extern struct mpidr_hash mpidr_hash;
+
+static inline u32 mpidr_hash_size(void)
+{
+	return 1 << mpidr_hash.bits;
+}
 #endif

commit 5c709e699881afd1cf9244c719eb063c3476a405
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 28 12:56:06 2012 +0000

    ARM: nommu: define dummy TLB operations for nommu configurations
    
    nommu platforms do not perform address translation and therefore clearly
    don't have TLBs. However, some SMP code assumes the presence of the TLB
    flushing routines and will therefore fail to compile for a nommu system.
    
    This patch defines dummy local_* TLB operations and #defines
    tlb_ops_need_broadcast() as 0, therefore causing the usual ARM SMP TLB
    operations to call the local variants instead.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    CC: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    CC: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index aaa61b6f50ff..1c7b6f8101ae 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -26,6 +26,9 @@ static inline bool is_smp(void)
 }
 
 /* all SMP configurations have the extended CPUID registers */
+#ifndef CONFIG_MMU
+#define tlb_ops_need_broadcast()	0
+#else
 static inline int tlb_ops_need_broadcast(void)
 {
 	if (!is_smp())
@@ -33,6 +36,7 @@ static inline int tlb_ops_need_broadcast(void)
 
 	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
 }
+#endif
 
 #if !defined(CONFIG_SMP) || __LINUX_ARM_ARCH__ >= 7
 #define cache_ops_need_broadcast()	0

commit 7f124aaf01439d2fa54283f3c375ce3b9fc776d4
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Thu Nov 17 17:36:24 2011 +0000

    ARM: kernel: add logical mappings look-up
    
    In ARM SMP systems the MPIDR register ([23:0] bits) is used to uniquely
    identify CPUs.
    
    In order to retrieve the logical CPU index corresponding to a given
    MPIDR value and guarantee a consistent translation throughout the kernel,
    this patch adds a look-up based on the MPIDR[23:0] so that kernel subsystems
    can use it whenever the logical cpu index corresponding to a given MPIDR
    value is needed.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 558d6c80aca9..aaa61b6f50ff 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -5,6 +5,9 @@
 #ifndef __ASMARM_SMP_PLAT_H
 #define __ASMARM_SMP_PLAT_H
 
+#include <linux/cpumask.h>
+#include <linux/err.h>
+
 #include <asm/cputype.h>
 
 /*
@@ -48,5 +51,19 @@ static inline int cache_ops_need_broadcast(void)
  */
 extern int __cpu_logical_map[];
 #define cpu_logical_map(cpu)	__cpu_logical_map[cpu]
+/*
+ * Retrieve logical cpu index corresponding to a given MPIDR[23:0]
+ *  - mpidr: MPIDR[23:0] to be used for the look-up
+ *
+ * Returns the cpu logical index or -EINVAL on look-up error
+ */
+static inline int get_logical_index(u32 mpidr)
+{
+	int cpu;
+	for (cpu = 0; cpu < nr_cpu_ids; cpu++)
+		if (cpu_logical_map(cpu) == mpidr)
+			return cpu;
+	return -EINVAL;
+}
 
 #endif

commit eb50439b92b6298bf209a982f295ba9c0f7cb30b
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Jan 20 12:01:12 2012 +0100

    ARM: 7293/1: logical_cpu_map: decouple CPU mapping from SMP
    
    It turns out that the logical CPU mapping is useful even when !CONFIG_SMP
    for manipulation of devices like interrupt and power controllers when
    running a UP kernel on a CPU other than 0. This can happen when kexecing
    a UP image from an SMP kernel.
    
    In the future, multi-cluster systems running AMP configurations will
    require something similar for mapping cluster IDs, so it makes sense to
    decouple this logic in preparation for this support.
    
    Acked-by: Yang Bai <hamo.by@gmail.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Reported-by: Joerg Roedel <joerg.roedel@amd.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index f24c1b9e211d..558d6c80aca9 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -43,4 +43,10 @@ static inline int cache_ops_need_broadcast(void)
 }
 #endif
 
+/*
+ * Logical CPU mapping.
+ */
+extern int __cpu_logical_map[];
+#define cpu_logical_map(cpu)	__cpu_logical_map[cpu]
+
 #endif

commit 23beab76b490172a9ff3d52843e4d27a35b2a4c6
Merge: 8ed9059533eb 5fb31a96e1e0 80be7a7f6427 19852e59002f 29e29f27486e 725343fa748f 9e978f096241 f3af03de0b1c 5333a3de3cdd
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Oct 18 22:34:25 2010 +0100

    Merge branches 'at91', 'dcache', 'ftrace', 'hwbpt', 'misc', 'mmci', 's3c', 'st-ux' and 'unwind' into devel

commit 7511db9d25080d53e5427bf4b8849278c07019bc
Author: Tony Lindgren <tony@atomide.com>
Date:   Tue Oct 5 16:40:13 2010 +0100

    ARM: 6429/1: Check for is_smp for tlb_ops and cache_ops broadcast
    
    Broadcast should not be needed when running SMP kernel on UP systems.
    
    Also, this fixes an undefined instruction for SMP_ON_UP on earlier ARM
    cores without the extended CPUID_EXT_MMFR3 register.
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 7de5aa56c18b..7f4e6633f753 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -7,17 +7,6 @@
 
 #include <asm/cputype.h>
 
-/* all SMP configurations have the extended CPUID registers */
-static inline int tlb_ops_need_broadcast(void)
-{
-	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
-}
-
-static inline int cache_ops_need_broadcast(void)
-{
-	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 1;
-}
-
 /*
  * Return true if we are running on a SMP platform
  */
@@ -33,4 +22,21 @@ static inline bool is_smp(void)
 #endif
 }
 
+/* all SMP configurations have the extended CPUID registers */
+static inline int tlb_ops_need_broadcast(void)
+{
+	if (!is_smp())
+		return 0;
+
+	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
+}
+
+static inline int cache_ops_need_broadcast(void)
+{
+	if (!is_smp())
+		return 0;
+
+	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 1;
+}
+
 #endif

commit f00ec48fadf5e37e7889f14cff900aa70d18b644
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Sep 4 10:47:48 2010 +0100

    ARM: Allow SMP kernels to boot on UP systems
    
    UP systems do not implement all the instructions that SMP systems have,
    so in order to boot a SMP kernel on a UP system, we need to rewrite
    parts of the kernel.
    
    Do this using an 'alternatives' scheme, where the kernel code and data
    is modified prior to initialization to replace the SMP instructions,
    thereby rendering the problematical code ineffectual.  We use the linker
    to generate a list of 32-bit word locations and their replacement values,
    and run through these replacements when we detect a UP system.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index e6215305544a..7de5aa56c18b 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -18,4 +18,19 @@ static inline int cache_ops_need_broadcast(void)
 	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 1;
 }
 
+/*
+ * Return true if we are running on a SMP platform
+ */
+static inline bool is_smp(void)
+{
+#ifndef CONFIG_SMP
+	return false;
+#elif defined(CONFIG_SMP_ON_UP)
+	extern unsigned int smp_on_up;
+	return !!smp_on_up;
+#else
+	return true;
+#endif
+}
+
 #endif

commit 85848dd7ab75fce1134856228582a8df522c91d9
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Sep 13 15:58:37 2010 +0100

    ARM: 6381/1: Use lazy cache flushing on ARMv7 SMP systems
    
    ARMv7 processors like Cortex-A9 broadcast the cache maintenance
    operations in hardware. This patch allows the
    flush_dcache_page/update_mmu_cache pair to work in lazy flushing mode
    similar to the UP case.
    
    Note that cache flushing on SMP systems now takes place via the
    set_pte_at() call (__sync_icache_dcache) and there is no race with other
    CPUs executing code from the new PTE before the cache flushing took
    place.
    
    Tested-by: Rabin Vincent <rabin.vincent@stericsson.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index e6215305544a..963a338d567b 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -13,9 +13,13 @@ static inline int tlb_ops_need_broadcast(void)
 	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
 }
 
+#if !defined(CONFIG_SMP) || __LINUX_ARM_ARCH__ >= 7
+#define cache_ops_need_broadcast()	0
+#else
 static inline int cache_ops_need_broadcast(void)
 {
 	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 1;
 }
+#endif
 
 #endif

commit 2ef7f3dbd7a70a48c3f09b498df528cb00ea03a4
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Nov 5 13:29:36 2009 +0000

    ARM: Fix ptrace accesses
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
index 59303e200845..e6215305544a 100644
--- a/arch/arm/include/asm/smp_plat.h
+++ b/arch/arm/include/asm/smp_plat.h
@@ -13,4 +13,9 @@ static inline int tlb_ops_need_broadcast(void)
 	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
 }
 
+static inline int cache_ops_need_broadcast(void)
+{
+	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 1;
+}
+
 #endif

commit e616c591405c168f6dc3dfd1221e105adfe49b8d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 27 20:55:43 2009 +0100

    ARM: Don't allow highmem on SMP platforms without h/w TLB ops broadcast
    
    We suffer an unfortunate combination of "features" which makes highmem
    support on platforms without hardware TLB maintainence broadcast difficult:
    
    - we need kmap_high_get() support for DMA cache coherence
    - this requires kmap_high() to take a spinlock with IRQs disabled
    - kmap_high() occasionally calls flush_all_zero_pkmaps() to clear
      out old mappings
    - flush_all_zero_pkmaps() calls flush_tlb_kernel_range(), which
      on s/w IPI'd systems eventually calls smp_call_function_many()
    - smp_call_function_many() must not be called with IRQs disabled:
    
    WARNING: at kernel/smp.c:380 smp_call_function_many+0xc4/0x240()
    Modules linked in:
    Backtrace:
    [<c00306f0>] (dump_backtrace+0x0/0x108) from [<c0286e6c>] (dump_stack+0x18/0x1c)
     r6:c007cd18 r5:c02ff228 r4:0000017c
    [<c0286e54>] (dump_stack+0x0/0x1c) from [<c0053e08>] (warn_slowpath_common+0x50/0x80)
    [<c0053db8>] (warn_slowpath_common+0x0/0x80) from [<c0053e50>] (warn_slowpath_null+0x18/0x1c)
     r7:00000003 r6:00000001 r5:c1ff4000 r4:c035fa34
    [<c0053e38>] (warn_slowpath_null+0x0/0x1c) from [<c007cd18>] (smp_call_function_many+0xc4/0x240)
    [<c007cc54>] (smp_call_function_many+0x0/0x240) from [<c007cec0>] (smp_call_function+0x2c/0x38)
    [<c007ce94>] (smp_call_function+0x0/0x38) from [<c005980c>] (on_each_cpu+0x1c/0x38)
    [<c00597f0>] (on_each_cpu+0x0/0x38) from [<c0031788>] (flush_tlb_kernel_range+0x50/0x58)
     r6:00000001 r5:00000800 r4:c05f3590
    [<c0031738>] (flush_tlb_kernel_range+0x0/0x58) from [<c009c600>] (flush_all_zero_pkmaps+0xc0/0xe8)
    [<c009c540>] (flush_all_zero_pkmaps+0x0/0xe8) from [<c009c6b4>] (kmap_high+0x8c/0x1e0)
    [<c009c628>] (kmap_high+0x0/0x1e0) from [<c00364a8>] (kmap+0x44/0x5c)
    [<c0036464>] (kmap+0x0/0x5c) from [<c0109dfc>] (cramfs_readpage+0x3c/0x194)
    [<c0109dc0>] (cramfs_readpage+0x0/0x194) from [<c0090c14>] (__do_page_cache_readahead+0x1f0/0x290)
    [<c0090a24>] (__do_page_cache_readahead+0x0/0x290) from [<c0090ce4>] (ra_submit+0x30/0x38)
    [<c0090cb4>] (ra_submit+0x0/0x38) from [<c0089384>] (filemap_fault+0x3dc/0x438)
     r4:c1819988
    [<c0088fa8>] (filemap_fault+0x0/0x438) from [<c009d21c>] (__do_fault+0x58/0x43c)
    [<c009d1c4>] (__do_fault+0x0/0x43c) from [<c009e8cc>] (handle_mm_fault+0x104/0x318)
    [<c009e7c8>] (handle_mm_fault+0x0/0x318) from [<c0033c98>] (do_page_fault+0x188/0x1e4)
    [<c0033b10>] (do_page_fault+0x0/0x1e4) from [<c0033ddc>] (do_translation_fault+0x7c/0x84)
    [<c0033d60>] (do_translation_fault+0x0/0x84) from [<c002b474>] (do_DataAbort+0x40/0xa4)
     r8:c1ff5e20 r7:c0340120 r6:00000805 r5:c1ff5e54 r4:c03400d0
    [<c002b434>] (do_DataAbort+0x0/0xa4) from [<c002bcac>] (__dabt_svc+0x4c/0x60)
    ...
    
    So we disable highmem support on these systems.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/smp_plat.h b/arch/arm/include/asm/smp_plat.h
new file mode 100644
index 000000000000..59303e200845
--- /dev/null
+++ b/arch/arm/include/asm/smp_plat.h
@@ -0,0 +1,16 @@
+/*
+ * ARM specific SMP header, this contains our implementation
+ * details.
+ */
+#ifndef __ASMARM_SMP_PLAT_H
+#define __ASMARM_SMP_PLAT_H
+
+#include <asm/cputype.h>
+
+/* all SMP configurations have the extended CPUID registers */
+static inline int tlb_ops_need_broadcast(void)
+{
+	return ((read_cpuid_ext(CPUID_EXT_MMFR3) >> 12) & 0xf) < 2;
+}
+
+#endif
