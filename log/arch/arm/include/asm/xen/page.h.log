commit 2fbadc3002c5f172d20aa2e7e48920c5f14ed11f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Dec 2 14:19:35 2016 +0000

    arm/arm64: xen: Move shared architecture headers to include/xen/arm
    
    ARM and arm64 Xen ports share a number of headers, leading to
    packaging issues when these headers needs to be exported, as it
    breaks the reasonable requirement that an architecture port
    has self-contained headers.
    
    Fix the issue by moving the 5 header files to include/xen/arm,
    and keep local placeholders to include the relevant files.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Stefano Stabellini <sstabellini@kernel.org>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 415dbc6e43fd..31bbc803cecb 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -1,122 +1 @@
-#ifndef _ASM_ARM_XEN_PAGE_H
-#define _ASM_ARM_XEN_PAGE_H
-
-#include <asm/page.h>
-#include <asm/pgtable.h>
-
-#include <linux/pfn.h>
-#include <linux/types.h>
-#include <linux/dma-mapping.h>
-
-#include <xen/xen.h>
-#include <xen/interface/grant_table.h>
-
-#define phys_to_machine_mapping_valid(pfn) (1)
-
-/* Xen machine address */
-typedef struct xmaddr {
-	phys_addr_t maddr;
-} xmaddr_t;
-
-/* Xen pseudo-physical address */
-typedef struct xpaddr {
-	phys_addr_t paddr;
-} xpaddr_t;
-
-#define XMADDR(x)	((xmaddr_t) { .maddr = (x) })
-#define XPADDR(x)	((xpaddr_t) { .paddr = (x) })
-
-#define INVALID_P2M_ENTRY      (~0UL)
-
-/*
- * The pseudo-physical frame (pfn) used in all the helpers is always based
- * on Xen page granularity (i.e 4KB).
- *
- * A Linux page may be split across multiple non-contiguous Xen page so we
- * have to keep track with frame based on 4KB page granularity.
- *
- * PV drivers should never make a direct usage of those helpers (particularly
- * pfn_to_gfn and gfn_to_pfn).
- */
-
-unsigned long __pfn_to_mfn(unsigned long pfn);
-extern struct rb_root phys_to_mach;
-
-/* Pseudo-physical <-> Guest conversion */
-static inline unsigned long pfn_to_gfn(unsigned long pfn)
-{
-	return pfn;
-}
-
-static inline unsigned long gfn_to_pfn(unsigned long gfn)
-{
-	return gfn;
-}
-
-/* Pseudo-physical <-> BUS conversion */
-static inline unsigned long pfn_to_bfn(unsigned long pfn)
-{
-	unsigned long mfn;
-
-	if (phys_to_mach.rb_node != NULL) {
-		mfn = __pfn_to_mfn(pfn);
-		if (mfn != INVALID_P2M_ENTRY)
-			return mfn;
-	}
-
-	return pfn;
-}
-
-static inline unsigned long bfn_to_pfn(unsigned long bfn)
-{
-	return bfn;
-}
-
-#define bfn_to_local_pfn(bfn)	bfn_to_pfn(bfn)
-
-/* VIRT <-> GUEST conversion */
-#define virt_to_gfn(v)		(pfn_to_gfn(virt_to_phys(v) >> XEN_PAGE_SHIFT))
-#define gfn_to_virt(m)		(__va(gfn_to_pfn(m) << XEN_PAGE_SHIFT))
-
-/* Only used in PV code. But ARM guests are always HVM. */
-static inline xmaddr_t arbitrary_virt_to_machine(void *vaddr)
-{
-	BUG();
-}
-
-/* TODO: this shouldn't be here but it is because the frontend drivers
- * are using it (its rolled in headers) even though we won't hit the code path.
- * So for right now just punt with this.
- */
-static inline pte_t *lookup_address(unsigned long address, unsigned int *level)
-{
-	BUG();
-	return NULL;
-}
-
-extern int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,
-				   struct gnttab_map_grant_ref *kmap_ops,
-				   struct page **pages, unsigned int count);
-
-extern int clear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,
-				     struct gnttab_unmap_grant_ref *kunmap_ops,
-				     struct page **pages, unsigned int count);
-
-bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);
-bool __set_phys_to_machine_multi(unsigned long pfn, unsigned long mfn,
-		unsigned long nr_pages);
-
-static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
-{
-	return __set_phys_to_machine(pfn, mfn);
-}
-
-#define xen_remap(cookie, size) ioremap_cache((cookie), (size))
-#define xen_unmap(cookie) iounmap((cookie))
-
-bool xen_arch_need_swiotlb(struct device *dev,
-			   phys_addr_t phys,
-			   dma_addr_t dev_addr);
-unsigned long xen_get_swiotlb_free_pages(unsigned int order);
-
-#endif /* _ASM_ARM_XEN_PAGE_H */
+#include <xen/arm/page.h>

commit 291be10fd7511101d44cf98166d049bd31bc7600
Author: Julien Grall <julien.grall@citrix.com>
Date:   Wed Sep 9 15:17:33 2015 +0100

    xen/swiotlb: Pass addresses rather than frame numbers to xen_arch_need_swiotlb
    
    With 64KB page granularity support, the frame number will be different.
    
    It will be easier to modify the behavior in a single place rather than
    in each caller.
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index e3d94cfa4d46..415dbc6e43fd 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -115,8 +115,8 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 #define xen_unmap(cookie) iounmap((cookie))
 
 bool xen_arch_need_swiotlb(struct device *dev,
-			   unsigned long pfn,
-			   unsigned long bfn);
+			   phys_addr_t phys,
+			   dma_addr_t dev_addr);
 unsigned long xen_get_swiotlb_free_pages(unsigned int order);
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 250c9af3d831139317009eaebbe82e20d23a581f
Author: Julien Grall <julien.grall@citrix.com>
Date:   Tue May 5 16:36:56 2015 +0100

    arm/xen: Add support for 64KB page granularity
    
    The hypercall interface is always using 4KB page granularity. This is
    requiring to use xen page definition macro when we deal with hypercall.
    
    Note that pfn_to_gfn is working with a Xen pfn (i.e 4KB). We may want to
    rename pfn_gfn to make this explicit.
    
    We also allocate a 64KB page for the shared page even though only the
    first 4KB is used. I don't think this is really important for now as it
    helps to have the pointer 4KB aligned (XENMEM_add_to_physmap is taking a
    Xen PFN).
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 98c9fc38b945..e3d94cfa4d46 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -28,6 +28,17 @@ typedef struct xpaddr {
 
 #define INVALID_P2M_ENTRY      (~0UL)
 
+/*
+ * The pseudo-physical frame (pfn) used in all the helpers is always based
+ * on Xen page granularity (i.e 4KB).
+ *
+ * A Linux page may be split across multiple non-contiguous Xen page so we
+ * have to keep track with frame based on 4KB page granularity.
+ *
+ * PV drivers should never make a direct usage of those helpers (particularly
+ * pfn_to_gfn and gfn_to_pfn).
+ */
+
 unsigned long __pfn_to_mfn(unsigned long pfn);
 extern struct rb_root phys_to_mach;
 
@@ -64,8 +75,8 @@ static inline unsigned long bfn_to_pfn(unsigned long bfn)
 #define bfn_to_local_pfn(bfn)	bfn_to_pfn(bfn)
 
 /* VIRT <-> GUEST conversion */
-#define virt_to_gfn(v)		(pfn_to_gfn(virt_to_pfn(v)))
-#define gfn_to_virt(m)		(__va(gfn_to_pfn(m) << PAGE_SHIFT))
+#define virt_to_gfn(v)		(pfn_to_gfn(virt_to_phys(v) >> XEN_PAGE_SHIFT))
+#define gfn_to_virt(m)		(__va(gfn_to_pfn(m) << XEN_PAGE_SHIFT))
 
 /* Only used in PV code. But ARM guests are always HVM. */
 static inline xmaddr_t arbitrary_virt_to_machine(void *vaddr)

commit 5031612b5eaf15cb6471c6e936a515090810c8f1
Author: Julien Grall <julien.grall@citrix.com>
Date:   Tue Jul 21 17:57:20 2015 +0100

    arm/xen: Drop pte_mfn and mfn_pte
    
    They are not used in common code expect in one place in balloon.c which is
    only compiled when Linux is using PV MMU. It's not the case on ARM.
    
    Rather than worrying how to handle the 64KB case, drop them.
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 127956353b00..98c9fc38b945 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -13,9 +13,6 @@
 
 #define phys_to_machine_mapping_valid(pfn) (1)
 
-#define pte_mfn	    pte_pfn
-#define mfn_pte	    pfn_pte
-
 /* Xen machine address */
 typedef struct xmaddr {
 	phys_addr_t maddr;

commit 0df4f266b3af90442bbeb5e685a84a80745beba0
Author: Julien Grall <julien.grall@citrix.com>
Date:   Fri Aug 7 17:34:37 2015 +0100

    xen: Use correctly the Xen memory terminologies
    
    Based on include/xen/mm.h [1], Linux is mistakenly using MFN when GFN
    is meant, I suspect this is because the first support for Xen was for
    PV. This resulted in some misimplementation of helpers on ARM and
    confused developers about the expected behavior.
    
    For instance, with pfn_to_mfn, we expect to get an MFN based on the name.
    Although, if we look at the implementation on x86, it's returning a GFN.
    
    For clarity and avoid new confusion, replace any reference to mfn with
    gfn in any helpers used by PV drivers. The x86 code will still keep some
    reference of pfn_to_mfn which may be used by all kind of guests
    No changes as been made in the hypercall field, even
    though they may be invalid, in order to keep the same as the defintion
    in xen repo.
    
    Note that page_to_mfn has been renamed to xen_page_to_gfn to avoid a
    name to close to the KVM function gfn_to_page.
    
    Take also the opportunity to simplify simple construction such
    as pfn_to_mfn(page_to_pfn(page)) into xen_page_to_gfn. More complex clean up
    will come in follow-up patches.
    
    [1] http://xenbits.xen.org/gitweb/?p=xen.git;a=commitdiff;h=e758ed14f390342513405dd766e874934573e6cb
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Acked-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Acked-by: Wei Liu <wei.liu2@citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 911d62b4df26..127956353b00 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -34,14 +34,15 @@ typedef struct xpaddr {
 unsigned long __pfn_to_mfn(unsigned long pfn);
 extern struct rb_root phys_to_mach;
 
-static inline unsigned long pfn_to_mfn(unsigned long pfn)
+/* Pseudo-physical <-> Guest conversion */
+static inline unsigned long pfn_to_gfn(unsigned long pfn)
 {
 	return pfn;
 }
 
-static inline unsigned long mfn_to_pfn(unsigned long mfn)
+static inline unsigned long gfn_to_pfn(unsigned long gfn)
 {
-	return mfn;
+	return gfn;
 }
 
 /* Pseudo-physical <-> BUS conversion */
@@ -65,9 +66,9 @@ static inline unsigned long bfn_to_pfn(unsigned long bfn)
 
 #define bfn_to_local_pfn(bfn)	bfn_to_pfn(bfn)
 
-/* VIRT <-> MACHINE conversion */
-#define virt_to_mfn(v)		(pfn_to_mfn(virt_to_pfn(v)))
-#define mfn_to_virt(m)		(__va(mfn_to_pfn(m) << PAGE_SHIFT))
+/* VIRT <-> GUEST conversion */
+#define virt_to_gfn(v)		(pfn_to_gfn(virt_to_pfn(v)))
+#define gfn_to_virt(m)		(__va(gfn_to_pfn(m) << PAGE_SHIFT))
 
 /* Only used in PV code. But ARM guests are always HVM. */
 static inline xmaddr_t arbitrary_virt_to_machine(void *vaddr)

commit 5192b35de47e47a0f736fe30da199f32030680e7
Author: Julien Grall <julien.grall@citrix.com>
Date:   Fri Aug 7 17:34:36 2015 +0100

    arm/xen: implement correctly pfn_to_mfn
    
    After the commit introducing convertion between DMA and guest addresses,
    all the callers of pfn_to_mfn are expecting to get a GFN (Guest Frame
    Number). On ARM, all the guests are auto-translated so the GFN is equal
    to the Linux PFN (Pseudo-physical Frame Number).
    
    The current implementation may return an MFN if the caller is passing a
    PFN associated to a mapped foreign grant. In pratice, I haven't seen
    the problem on running guest but we should fix it for the sake of
    correctness.
    
    Correct the implementation by always returning the pfn passed in parameter.
    
    A follow-up patch will take care to rename pfn_to_mfn to a suitable
    name.
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 5f76a9e7ef1b..911d62b4df26 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -36,14 +36,6 @@ extern struct rb_root phys_to_mach;
 
 static inline unsigned long pfn_to_mfn(unsigned long pfn)
 {
-	unsigned long mfn;
-
-	if (phys_to_mach.rb_node != NULL) {
-		mfn = __pfn_to_mfn(pfn);
-		if (mfn != INVALID_P2M_ENTRY)
-			return mfn;
-	}
-
 	return pfn;
 }
 

commit 32e09870eedfb501a6cb5729d8c23f44f8a7cbdd
Author: Julien Grall <julien.grall@citrix.com>
Date:   Fri Aug 7 17:34:35 2015 +0100

    xen: Make clear that swiotlb and biomerge are dealing with DMA address
    
    The swiotlb is required when programming a DMA address on ARM when a
    device is not protected by an IOMMU.
    
    In this case, the DMA address should always be equal to the machine address.
    For DOM0 memory, Xen ensure it by have an identity mapping between the
    guest address and host address. However, when mapping a foreign grant
    reference, the 1:1 model doesn't work.
    
    For ARM guest, most of the callers of pfn_to_mfn expects to get a GFN
    (Guest Frame Number), i.e a PFN (Page Frame Number) from the Linux point
    of view given that all ARM guest are auto-translated.
    
    Even though the name pfn_to_mfn is misleading, we need to ensure that
    those caller get a GFN and not by mistake a MFN. In pratical, I haven't
    seen error related to this but we should fix it for the sake of
    correctness.
    
    In order to fix the implementation of pfn_to_mfn on ARM in a follow-up
    patch, we have to introduce new helpers to return the DMA from a PFN and
    the invert.
    
    On x86, the new helpers will be an alias of pfn_to_mfn and mfn_to_pfn.
    
    The helpers will be used in swiotlb and xen_biovec_phys_mergeable.
    
    This is necessary in the latter because we have to ensure that the
    biovec code will not try to merge a biovec using foreign page and
    another using Linux memory.
    
    Lastly, the helper mfn_to_local_pfn has been renamed to bfn_to_local_pfn
    given that the only usage was in swiotlb.
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 98b1084f8282..5f76a9e7ef1b 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -52,7 +52,26 @@ static inline unsigned long mfn_to_pfn(unsigned long mfn)
 	return mfn;
 }
 
-#define mfn_to_local_pfn(mfn) mfn_to_pfn(mfn)
+/* Pseudo-physical <-> BUS conversion */
+static inline unsigned long pfn_to_bfn(unsigned long pfn)
+{
+	unsigned long mfn;
+
+	if (phys_to_mach.rb_node != NULL) {
+		mfn = __pfn_to_mfn(pfn);
+		if (mfn != INVALID_P2M_ENTRY)
+			return mfn;
+	}
+
+	return pfn;
+}
+
+static inline unsigned long bfn_to_pfn(unsigned long bfn)
+{
+	return bfn;
+}
+
+#define bfn_to_local_pfn(bfn)	bfn_to_pfn(bfn)
 
 /* VIRT <-> MACHINE conversion */
 #define virt_to_mfn(v)		(pfn_to_mfn(virt_to_pfn(v)))
@@ -96,7 +115,7 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 
 bool xen_arch_need_swiotlb(struct device *dev,
 			   unsigned long pfn,
-			   unsigned long mfn);
+			   unsigned long bfn);
 unsigned long xen_get_swiotlb_free_pages(unsigned int order);
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 724afaea2020f3bd98891b535f3ce5d3935bcf63
Author: Julien Grall <julien.grall@citrix.com>
Date:   Fri Aug 7 17:34:34 2015 +0100

    arm/xen: Remove helpers which are PV specific
    
    ARM guests are always HVM. The current implementation is assuming a 1:1
    mapping which is only true for DOM0 and may not be at all in the future.
    
    Furthermore, all the helpers but arbitrary_virt_to_machine are used in
    x86 specific code (or only compiled for).
    
    The helper arbitrary_virt_to_machine is only used in PV specific code.
    Therefore we should never call the function.
    
    Add a BUG() in this helper and drop all the others.
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Acked-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 1bee8ca12494..98b1084f8282 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -54,26 +54,14 @@ static inline unsigned long mfn_to_pfn(unsigned long mfn)
 
 #define mfn_to_local_pfn(mfn) mfn_to_pfn(mfn)
 
-static inline xmaddr_t phys_to_machine(xpaddr_t phys)
-{
-	unsigned offset = phys.paddr & ~PAGE_MASK;
-	return XMADDR(PFN_PHYS(pfn_to_mfn(PFN_DOWN(phys.paddr))) | offset);
-}
-
-static inline xpaddr_t machine_to_phys(xmaddr_t machine)
-{
-	unsigned offset = machine.maddr & ~PAGE_MASK;
-	return XPADDR(PFN_PHYS(mfn_to_pfn(PFN_DOWN(machine.maddr))) | offset);
-}
 /* VIRT <-> MACHINE conversion */
-#define virt_to_machine(v)	(phys_to_machine(XPADDR(__pa(v))))
 #define virt_to_mfn(v)		(pfn_to_mfn(virt_to_pfn(v)))
 #define mfn_to_virt(m)		(__va(mfn_to_pfn(m) << PAGE_SHIFT))
 
+/* Only used in PV code. But ARM guests are always HVM. */
 static inline xmaddr_t arbitrary_virt_to_machine(void *vaddr)
 {
-	/* TODO: assuming it is mapped in the kernel 1:1 */
-	return virt_to_machine(vaddr);
+	BUG();
 }
 
 /* TODO: this shouldn't be here but it is because the frontend drivers

commit 90d73c4f43630ca45398cee7f32f0fe51271b2ce
Author: Julien Grall <julien.grall@linaro.org>
Date:   Wed Jun 17 15:28:05 2015 +0100

    arm/xen: Drop duplicate define mfn_to_virt
    
    Signed-off-by: Julien Grall <julien.grall@citrix.com>
    Cc: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 0b579b2f4e0e..1bee8ca12494 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -12,7 +12,6 @@
 #include <xen/interface/grant_table.h>
 
 #define phys_to_machine_mapping_valid(pfn) (1)
-#define mfn_to_virt(m)			(__va(mfn_to_pfn(m) << PAGE_SHIFT))
 
 #define pte_mfn	    pte_pfn
 #define mfn_pte	    pfn_pte

commit 8746515d7f04c9ea94cf43e2db1fd2cfca93276d
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Fri Apr 24 10:16:40 2015 +0100

    xen: Add __GFP_DMA flag when xen_swiotlb_init gets free pages on ARM
    
    Make sure that xen_swiotlb_init allocates buffers that are DMA capable
    when at least one memblock is available below 4G. Otherwise we assume
    that all devices on the SoC can cope with >4G addresses. We do this on
    ARM and ARM64, where dom0 is mapped 1:1, so pfn == mfn in this case.
    
    No functional changes on x86.
    
    From: Chen Baozi <baozich@gmail.com>
    
    Signed-off-by: Chen Baozi <baozich@gmail.com>
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Tested-by: Chen Baozi <baozich@gmail.com>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 2f7e6ff67d51..0b579b2f4e0e 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -110,5 +110,6 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 bool xen_arch_need_swiotlb(struct device *dev,
 			   unsigned long pfn,
 			   unsigned long mfn);
+unsigned long xen_get_swiotlb_free_pages(unsigned int order);
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 853d0289340026b30f93fd0e768340221d4e605c
Author: David Vrabel <david.vrabel@citrix.com>
Date:   Mon Jan 5 14:13:41 2015 +0000

    xen/grant-table: pre-populate kernel unmap ops for xen_gnttab_unmap_refs()
    
    When unmapping grants, instead of converting the kernel map ops to
    unmap ops on the fly, pre-populate the set of unmap ops.
    
    This allows the grant unmap for the kernel mappings to be trivially
    batched in the future.
    
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 68c739b3fdf4..2f7e6ff67d51 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -92,7 +92,7 @@ extern int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,
 				   struct page **pages, unsigned int count);
 
 extern int clear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,
-				     struct gnttab_map_grant_ref *kmap_ops,
+				     struct gnttab_unmap_grant_ref *kunmap_ops,
 				     struct page **pages, unsigned int count);
 
 bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);

commit a4dba130891271084344c12537731542ec77cb85
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Fri Nov 21 11:07:39 2014 +0000

    xen/arm/arm64: introduce xen_arch_need_swiotlb
    
    Introduce an arch specific function to find out whether a particular dma
    mapping operation needs to bounce on the swiotlb buffer.
    
    On ARM and ARM64, if the page involved is a foreign page and the device
    is not coherent, we need to bounce because at unmap time we cannot
    execute any required cache maintenance operations (we don't know how to
    find the pfn from the mfn).
    
    No change of behaviour for x86.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Reviewed-by: David Vrabel <david.vrabel@citrix.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Ian Campbell <ian.campbell@citrix.com>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 135c24a5ba26..68c739b3fdf4 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -107,4 +107,8 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 #define xen_remap(cookie, size) ioremap_cache((cookie), (size))
 #define xen_unmap(cookie) iounmap((cookie))
 
+bool xen_arch_need_swiotlb(struct device *dev,
+			   unsigned long pfn,
+			   unsigned long mfn);
+
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit d50582e06fd5a58281151e097ff68b02ca65cf2d
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Wed Sep 10 22:49:48 2014 +0000

    xen/arm: remove mach_to_phys rbtree
    
    Remove the rbtree used to keep track of machine to physical mappings:
    the frontend can grant the same page multiple times, leading to errors
    inserting or removing entries from the mach_to_phys tree.
    
    Linux only needed to know the physical address corresponding to a given
    machine address in swiotlb-xen. Now that swiotlb-xen can call the
    xen_dma_* functions passing the machine address directly, we can remove
    it.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Tested-by: Denis Schneider <v1ne2go@gmail.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index ded062f9b358..135c24a5ba26 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -33,7 +33,6 @@ typedef struct xpaddr {
 #define INVALID_P2M_ENTRY      (~0UL)
 
 unsigned long __pfn_to_mfn(unsigned long pfn);
-unsigned long __mfn_to_pfn(unsigned long mfn);
 extern struct rb_root phys_to_mach;
 
 static inline unsigned long pfn_to_mfn(unsigned long pfn)
@@ -51,14 +50,6 @@ static inline unsigned long pfn_to_mfn(unsigned long pfn)
 
 static inline unsigned long mfn_to_pfn(unsigned long mfn)
 {
-	unsigned long pfn;
-
-	if (phys_to_mach.rb_node != NULL) {
-		pfn = __mfn_to_pfn(mfn);
-		if (pfn != INVALID_P2M_ENTRY)
-			return pfn;
-	}
-
 	return mfn;
 }
 

commit 063aa8e68e53cc0d0961ea90c12cea40c6b94828
Author: Julien Grall <julien.grall@linaro.org>
Date:   Fri Apr 18 16:54:34 2014 +0100

    arm/xen: Remove definiition of virt_to_pfn in asm/xen/page.h
    
    virt_to_pfn has been defined in asm/memory.h by the commit e26a9e0 "ARM: Better
    virt_to_page() handling"
    
    This will result of a compilation warning when CONFIG_XEN is enabled.
    
    arch/arm/include/asm/xen/page.h:80:0: warning: "virt_to_pfn" redefined [enabled by default]
     #define virt_to_pfn(v)          (PFN_DOWN(__pa(v)))
     ^
    In file included from arch/arm/include/asm/page.h:163:0,
                     from arch/arm/include/asm/xen/page.h:4,
                     from include/xen/page.h:4,
                     from arch/arm/xen/grant-table.c:33:
    
    The definition in memory.h is nearly the same (it directly expand PFN_DOWN),
    so we can safely drop virt_to_pfn in xen include.
    
    Signed-off-by: Julien Grall <julien.grall@linaro.org>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index cf4f3e867395..ded062f9b358 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -77,7 +77,6 @@ static inline xpaddr_t machine_to_phys(xmaddr_t machine)
 }
 /* VIRT <-> MACHINE conversion */
 #define virt_to_machine(v)	(phys_to_machine(XPADDR(__pa(v))))
-#define virt_to_pfn(v)          (PFN_DOWN(__pa(v)))
 #define virt_to_mfn(v)		(pfn_to_mfn(virt_to_pfn(v)))
 #define mfn_to_virt(m)		(__va(mfn_to_pfn(m) << PAGE_SHIFT))
 

commit 1429d46df4c538d28460d0b493997006a62a1093
Author: Zoltan Kiss <zoltan.kiss@citrix.com>
Date:   Thu Feb 27 15:55:30 2014 +0000

    xen/grant-table: Refactor gnttab_[un]map_refs to avoid m2p_override
    
    The grant mapping API does m2p_override unnecessarily: only gntdev needs it,
    for blkback and future netback patches it just cause a lock contention, as
    those pages never go to userspace. Therefore this series does the following:
    - the bulk of the original function (everything after the mapping hypercall)
      is moved to arch-dependent set/clear_foreign_p2m_mapping
    - the "if (xen_feature(XENFEAT_auto_translated_physmap))" branch goes to ARM
    - therefore the ARM function could be much smaller, the m2p_override stubs
      could be also removed
    - on x86 the set_phys_to_machine calls were moved up to this new funcion
      from m2p_override functions
    - and m2p_override functions are only called when there is a kmap_ops param
    
    It also removes a stray space from arch/x86/include/asm/xen/page.h.
    
    Signed-off-by: Zoltan Kiss <zoltan.kiss@citrix.com>
    Suggested-by: Anthony Liguori <aliguori@amazon.com>
    Suggested-by: David Vrabel <david.vrabel@citrix.com>
    Suggested-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index e0965abacb7d..cf4f3e867395 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -97,16 +97,13 @@ static inline pte_t *lookup_address(unsigned long address, unsigned int *level)
 	return NULL;
 }
 
-static inline int m2p_add_override(unsigned long mfn, struct page *page,
-		struct gnttab_map_grant_ref *kmap_op)
-{
-	return 0;
-}
+extern int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,
+				   struct gnttab_map_grant_ref *kmap_ops,
+				   struct page **pages, unsigned int count);
 
-static inline int m2p_remove_override(struct page *page, bool clear_pte)
-{
-	return 0;
-}
+extern int clear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,
+				     struct gnttab_map_grant_ref *kmap_ops,
+				     struct page **pages, unsigned int count);
 
 bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);
 bool __set_phys_to_machine_multi(unsigned long pfn, unsigned long mfn,

commit 84621c9b18d0bb6cb267e3395c7f3131ecf4d39c
Merge: 7ebd3faa9b5b c9f6e9977e38
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 22 22:00:18 2014 -0800

    Merge tag 'stable/for-linus-3.14-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip
    
    Pull Xen updates from Konrad Rzeszutek Wilk:
     "Two major features that Xen community is excited about:
    
      The first is event channel scalability by David Vrabel - we switch
      over from an two-level per-cpu bitmap of events (IRQs) - to an FIFO
      queue with priorities.  This lets us be able to handle more events,
      have lower latency, and better scalability.  Good stuff.
    
      The other is PVH by Mukesh Rathor.  In short, PV is a mode where the
      kernel lets the hypervisor program page-tables, segments, etc.  With
      EPT/NPT capabilities in current processors, the overhead of doing this
      in an HVM (Hardware Virtual Machine) container is much lower than the
      hypervisor doing it for us.
    
      In short we let a PV guest run without doing page-table, segment,
      syscall, etc updates through the hypervisor - instead it is all done
      within the guest container.  It is a "hybrid" PV - hence the 'PVH'
      name - a PV guest within an HVM container.
    
      The major benefits are less code to deal with - for example we only
      use one function from the the pv_mmu_ops (which has 39 function
      calls); faster performance for syscall (no context switches into the
      hypervisor); less traps on various operations; etc.
    
      It is still being baked - the ABI is not yet set in stone.  But it is
      pretty awesome and we are excited about it.
    
      Lastly, there are some changes to ARM code - you should get a simple
      conflict which has been resolved in #linux-next.
    
      In short, this pull has awesome features.
    
      Features:
       - FIFO event channels.  Key advantages: support for over 100,000
         events (2^17), 16 different event priorities, improved fairness in
         event latency through the use of FIFOs.
       - Xen PVH support.  "It’s a fully PV kernel mode, running with
         paravirtualized disk and network, paravirtualized interrupts and
         timers, no emulated devices of any kind (and thus no qemu), no BIOS
         or legacy boot — but instead of requiring PV MMU, it uses the HVM
         hardware extensions to virtualize the pagetables, as well as system
         calls and other privileged operations." (from "The
         Paravirtualization Spectrum, Part 2: From poles to a spectrum")
    
      Bug-fixes:
       - Fixes in balloon driver (refactor and make it work under ARM)
       - Allow xenfb to be used in HVM guests.
       - Allow xen_platform_pci=0 to work properly.
       - Refactors in event channels"
    
    * tag 'stable/for-linus-3.14-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip: (52 commits)
      xen/pvh: Set X86_CR0_WP and others in CR0 (v2)
      MAINTAINERS: add git repository for Xen
      xen/pvh: Use 'depend' instead of 'select'.
      xen: delete new instances of __cpuinit usage
      xen/fb: allow xenfb initialization for hvm guests
      xen/evtchn_fifo: fix error return code in evtchn_fifo_setup()
      xen-platform: fix error return code in platform_pci_init()
      xen/pvh: remove duplicated include from enlighten.c
      xen/pvh: Fix compile issues with xen_pvh_domain()
      xen: Use dev_is_pci() to check whether it is pci device
      xen/grant-table: Force to use v1 of grants.
      xen/pvh: Support ParaVirtualized Hardware extensions (v3).
      xen/pvh: Piggyback on PVHVM XenBus.
      xen/pvh: Piggyback on PVHVM for grant driver (v4)
      xen/grant: Implement an grant frame array struct (v3).
      xen/grant-table: Refactor gnttab_init
      xen/grants: Remove gnttab_max_grant_frames dependency on gnttab_init.
      xen/pvh: Piggyback on PVHVM for event channels (v2)
      xen/pvh: Update E820 to work with PVH (v2)
      xen/pvh: Secondary VCPU bringup (non-bootup CPUs)
      ...

commit efaf30a3357872cf0fc7d555b1f9968ec71535d3
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Mon Jan 6 10:40:36 2014 -0500

    xen/grant: Implement an grant frame array struct (v3).
    
    The 'xen_hvm_resume_frames' used to be an 'unsigned long'
    and contain the virtual address of the grants. That was OK
    for most architectures (PVHVM, ARM) were the grants are contiguous
    in memory. That however is not the case for PVH - in which case
    we will have to do a lookup for each virtual address for the PFN.
    
    Instead of doing that, lets make it a structure which will contain
    the array of PFNs, the virtual address and the count of said PFNs.
    
    Also provide a generic functions: gnttab_setup_auto_xlat_frames and
    gnttab_free_auto_xlat_frames to populate said structure with
    appropriate values for PVHVM and ARM.
    
    To round it off, change the name from 'xen_hvm_resume_frames' to
    a more descriptive one - 'xen_auto_xlat_grant_frames'.
    
    For PVH, in patch "xen/pvh: Piggyback on PVHVM for grant driver"
    we will populate the 'xen_auto_xlat_grant_frames' by ourselves.
    
    v2 moves the xen_remap in the gnttab_setup_auto_xlat_frames
    and also introduces xen_unmap for gnttab_free_auto_xlat_frames.
    
    Suggested-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    [v3: Based on top of 'asm/xen/page.h: remove redundant semicolon']
    Acked-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index ac6789aad059..709c4b4d2f1d 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -118,5 +118,6 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 }
 
 #define xen_remap(cookie, size) ioremap_cached((cookie), (size))
+#define xen_unmap(cookie) iounmap((cookie))
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 02bcf053e9c5dfbb541b8e27a8eeb962a54d577b
Author: Wei Liu <liuw@liuw.name>
Date:   Fri Jan 3 14:03:35 2014 +0000

    asm/xen/page.h: remove redundant semicolon
    
    Signed-off-by: Wei Liu <liuw@liuw.name>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Acked-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 75579a9d6f76..ac6789aad059 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -117,6 +117,6 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 	return __set_phys_to_machine(pfn, mfn);
 }
 
-#define xen_remap(cookie, size) ioremap_cached((cookie), (size));
+#define xen_remap(cookie, size) ioremap_cached((cookie), (size))
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 0a5ccc86507f45b80831dac1049197c4d45be955
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Fri Jan 3 16:17:44 2014 +0100

    ARM: 7933/1: rename ioremap_cached to ioremap_cache
    
    ioremap_cache is more aligned with other architectures.
    There are only 2 users of this in the kernel: pxa2xx-flash and Xen.
    
    This fixes Xen build failures on arm64:
    
    drivers/tty/hvc/hvc_xen.c:233:2: error: implicit declaration of function 'ioremap_cached' [-Werror=implicit-function-declaration]
    drivers/xen/grant-table.c:1174:3: error: implicit declaration of function 'ioremap_cached' [-Werror=implicit-function-declaration]
    drivers/xen/xenbus/xenbus_probe.c:778:4: error: implicit declaration of function 'ioremap_cached' [-Werror=implicit-function-declaration]
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 75579a9d6f76..3759cacdd7f8 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -117,6 +117,6 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 	return __set_phys_to_machine(pfn, mfn);
 }
 
-#define xen_remap(cookie, size) ioremap_cached((cookie), (size));
+#define xen_remap(cookie, size) ioremap_cache((cookie), (size));
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 18c51e1a3fabb455ff1f5cd610097d89f577b8f7
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Mon Nov 11 12:50:30 2013 +0000

    xen/arm: pfn_to_mfn and mfn_to_pfn return the argument if nothing is in the p2m
    
    Some common Xen drivers, like balloon.c, call pfn_to_mfn and mfn_to_pfn
    even for autotranslate guests, expecting the argument back.
    The following commit broke these drivers by changing the behavior of
    pfn_to_mfn and mfn_to_pfn:
    
    commit 4a19138c6505e224d9f4cc2fe9ada9188d7100ea
    Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Date:   Thu Oct 17 16:22:27 2013 +0000
    
        arm/xen,arm64/xen: introduce p2m
    
    They now return INVALID_P2M_ENTRY if Linux doesn't actually know what is
    the mfn backing a pfn or what is the pfn corresponding to an mfn.
    Fix the regression by switching to the old behavior.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Acked-by: Ian Campbell <ian.campbell@citrix.com>
    Tested-by: Ian Campbell <ian.campbell@citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 71bb779f2761..75579a9d6f76 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -46,10 +46,7 @@ static inline unsigned long pfn_to_mfn(unsigned long pfn)
 			return mfn;
 	}
 
-	if (xen_initial_domain())
-		return pfn;
-	else
-		return INVALID_P2M_ENTRY;
+	return pfn;
 }
 
 static inline unsigned long mfn_to_pfn(unsigned long mfn)
@@ -62,10 +59,7 @@ static inline unsigned long mfn_to_pfn(unsigned long mfn)
 			return pfn;
 	}
 
-	if (xen_initial_domain())
-		return mfn;
-	else
-		return INVALID_P2M_ENTRY;
+	return mfn;
 }
 
 #define mfn_to_local_pfn(mfn) mfn_to_pfn(mfn)

commit e1d8f62ad49a6a7068aa1bdc30252911d71c4dc4
Merge: bad97817dece 15177608c703
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Fri Nov 8 15:36:09 2013 -0500

    Merge remote-tracking branch 'stefano/swiotlb-xen-9.1' into stable/for-linus-3.13
    
    * stefano/swiotlb-xen-9.1:
      swiotlb-xen: fix error code returned by xen_swiotlb_map_sg_attrs
      swiotlb-xen: static inline xen_phys_to_bus, xen_bus_to_phys, xen_virt_to_bus and range_straddles_page_boundary
      grant-table: call set_phys_to_machine after mapping grant refs
      arm,arm64: do not always merge biovec if we are running on Xen
      swiotlb: print a warning when the swiotlb is full
      swiotlb-xen: use xen_dma_map/unmap_page, xen_dma_sync_single_for_cpu/device
      xen: introduce xen_dma_map/unmap_page and xen_dma_sync_single_for_cpu/device
      swiotlb-xen: use xen_alloc/free_coherent_pages
      xen: introduce xen_alloc/free_coherent_pages
      arm64/xen: get_dma_ops: return xen_dma_ops if we are running as xen_initial_domain
      arm/xen: get_dma_ops: return xen_dma_ops if we are running as xen_initial_domain
      swiotlb-xen: introduce xen_swiotlb_set_dma_mask
      xen/arm,arm64: enable SWIOTLB_XEN
      xen: make xen_create_contiguous_region return the dma address
      xen/x86: allow __set_phys_to_machine for autotranslate guests
      arm/xen,arm64/xen: introduce p2m
      arm64: define DMA_ERROR_CODE
      arm: make SWIOTLB available
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    
    Conflicts:
            arch/arm/include/asm/dma-mapping.h
            drivers/xen/swiotlb-xen.c
    
    [Conflicts arose b/c "arm: make SWIOTLB available" v8 was in Stefano's
    branch, while I had v9 + Ack from Russel. I also fixed up white-space
    issues]

commit 83862ccfc0a03212fde43b4ac29c28381828768b
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Thu Oct 10 13:40:44 2013 +0000

    xen/arm,arm64: enable SWIOTLB_XEN
    
    Xen on arm and arm64 needs SWIOTLB_XEN: when running on Xen we need to
    program the hardware with mfns rather than pfns for dma addresses.
    Remove SWIOTLB_XEN dependency on X86 and PCI and make XEN select
    SWIOTLB_XEN on arm and arm64.
    
    At the moment always rely on swiotlb-xen, but when Xen starts supporting
    hardware IOMMUs we'll be able to avoid it conditionally on the presence
    of an IOMMU on the platform.
    
    Implement xen_create_contiguous_region on arm and arm64: for the moment
    we assume that dom0 has been mapped 1:1 (physical addresses == machine
    addresses) therefore we don't need to call XENMEM_exchange. Simply
    return the physical address as dma address.
    
    Initialize the xen-swiotlb from xen_early_init (before the native
    dma_ops are initialized), set xen_dma_ops to &xen_swiotlb_dma_ops.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    
    
    Changes in v8:
    - assume dom0 is mapped 1:1, no need to call XENMEM_exchange.
    
    Changes in v7:
    - call __set_phys_to_machine_multi from xen_create_contiguous_region and
    xen_destroy_contiguous_region to update the P2M;
    - don't call XENMEM_unpin, it has been removed;
    - call XENMEM_exchange instead of XENMEM_exchange_and_pin;
    - set nr_exchanged to 0 before calling the hypercall.
    
    Changes in v6:
    - introduce and export xen_dma_ops;
    - call xen_mm_init from as arch_initcall.
    
    Changes in v4:
    - remove redefinition of DMA_ERROR_CODE;
    - update the code to use XENMEM_exchange_and_pin and XENMEM_unpin;
    - add a note about hardware IOMMU in the commit message.
    
    Changes in v3:
    - code style changes;
    - warn on XENMEM_put_dma_buf failures.

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index d1b5dd566472..5d0e4c5dc711 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -6,6 +6,7 @@
 
 #include <linux/pfn.h>
 #include <linux/types.h>
+#include <linux/dma-mapping.h>
 
 #include <xen/xen.h>
 #include <xen/interface/grant_table.h>

commit 4a19138c6505e224d9f4cc2fe9ada9188d7100ea
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Thu Oct 17 16:22:27 2013 +0000

    arm/xen,arm64/xen: introduce p2m
    
    Introduce physical to machine and machine to physical tracking
    mechanisms based on rbtrees for arm/xen and arm64/xen.
    
    We need it because any guests on ARM are an autotranslate guests,
    therefore a physical address is potentially different from a machine
    address. When programming a device to do DMA, we need to be
    extra-careful to use machine addresses rather than physical addresses to
    program the device. Therefore we need to know the physical to machine
    mappings.
    
    For the moment we assume that dom0 starts with a 1:1 physical to machine
    mapping, in other words physical addresses correspond to machine
    addresses. However when mapping a foreign grant reference, obviously the
    1:1 model doesn't work anymore. So at the very least we need to be able
    to track grant mappings.
    
    We need locking to protect accesses to the two trees.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    
    Changes in v8:
    - move pfn_to_mfn and mfn_to_pfn to page.h as static inline functions;
    - no need to walk the tree if phys_to_mach.rb_node is NULL;
    - correctly handle multipage p2m entries;
    - substitute the spin_lock with a rwlock.

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 359a7b50b158..d1b5dd566472 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -7,11 +7,10 @@
 #include <linux/pfn.h>
 #include <linux/types.h>
 
+#include <xen/xen.h>
 #include <xen/interface/grant_table.h>
 
-#define pfn_to_mfn(pfn)			(pfn)
 #define phys_to_machine_mapping_valid(pfn) (1)
-#define mfn_to_pfn(mfn)			(mfn)
 #define mfn_to_virt(m)			(__va(mfn_to_pfn(m) << PAGE_SHIFT))
 
 #define pte_mfn	    pte_pfn
@@ -32,6 +31,44 @@ typedef struct xpaddr {
 
 #define INVALID_P2M_ENTRY      (~0UL)
 
+unsigned long __pfn_to_mfn(unsigned long pfn);
+unsigned long __mfn_to_pfn(unsigned long mfn);
+extern struct rb_root phys_to_mach;
+
+static inline unsigned long pfn_to_mfn(unsigned long pfn)
+{
+	unsigned long mfn;
+	
+	if (phys_to_mach.rb_node != NULL) {
+		mfn = __pfn_to_mfn(pfn);
+		if (mfn != INVALID_P2M_ENTRY)
+			return mfn;
+	}
+
+	if (xen_initial_domain())
+		return pfn;
+	else
+		return INVALID_P2M_ENTRY;
+}
+
+static inline unsigned long mfn_to_pfn(unsigned long mfn)
+{
+	unsigned long pfn;
+
+	if (phys_to_mach.rb_node != NULL) {
+		pfn = __mfn_to_pfn(mfn);
+		if (pfn != INVALID_P2M_ENTRY)
+			return pfn;
+	}
+
+	if (xen_initial_domain())
+		return mfn;
+	else
+		return INVALID_P2M_ENTRY;
+}
+
+#define mfn_to_local_pfn(mfn) mfn_to_pfn(mfn)
+
 static inline xmaddr_t phys_to_machine(xpaddr_t phys)
 {
 	unsigned offset = phys.paddr & ~PAGE_MASK;
@@ -76,11 +113,9 @@ static inline int m2p_remove_override(struct page *page, bool clear_pte)
 	return 0;
 }
 
-static inline bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn)
-{
-	BUG_ON(pfn != mfn && mfn != INVALID_P2M_ENTRY);
-	return true;
-}
+bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);
+bool __set_phys_to_machine_multi(unsigned long pfn, unsigned long mfn,
+		unsigned long nr_pages);
 
 static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 {

commit f0a8d597913bba310a519a149294b835b6c8c9c5
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Tue Jun 4 16:32:15 2013 +0000

    arm/xen: define xen_remap as ioremap_cached
    
    Define xen_remap as ioremap_cache (MT_MEMORY and MT_DEVICE_CACHED end up
    having the same AttrIndx encoding).
    
    Remove include asm/mach/map.h, not unneeded.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 30cdacb675af..359a7b50b158 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -1,7 +1,6 @@
 #ifndef _ASM_ARM_XEN_PAGE_H
 #define _ASM_ARM_XEN_PAGE_H
 
-#include <asm/mach/map.h>
 #include <asm/page.h>
 #include <asm/pgtable.h>
 
@@ -88,6 +87,6 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 	return __set_phys_to_machine(pfn, mfn);
 }
 
-#define xen_remap(cookie, size) __arm_ioremap((cookie), (size), MT_MEMORY);
+#define xen_remap(cookie, size) ioremap_cached((cookie), (size));
 
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 3216dceb31c08be08ea98814a9ca5775fa680389
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Tue Feb 19 13:59:19 2013 +0000

    xen: introduce xen_remap, use it instead of ioremap
    
    ioremap can't be used to map ring pages on ARM because it uses device
    memory caching attributes (MT_DEVICE*).
    
    Introduce a Xen specific abstraction to map ring pages, called
    xen_remap, that is defined as ioremap on x86 (no behavioral changes).
    On ARM it explicitly calls __arm_ioremap with the right caching
    attributes: MT_MEMORY.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index c6b9096cef95..30cdacb675af 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -1,6 +1,7 @@
 #ifndef _ASM_ARM_XEN_PAGE_H
 #define _ASM_ARM_XEN_PAGE_H
 
+#include <asm/mach/map.h>
 #include <asm/page.h>
 #include <asm/pgtable.h>
 
@@ -86,4 +87,7 @@ static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 {
 	return __set_phys_to_machine(pfn, mfn);
 }
+
+#define xen_remap(cookie, size) __arm_ioremap((cookie), (size), MT_MEMORY);
+
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit ee7b5958e2494619ee3ff52de68580feed6906a2
Author: Ian Campbell <ian.campbell@citrix.com>
Date:   Wed Oct 17 09:39:17 2012 +0100

    xen: arm: make p2m operations NOPs
    
    This makes common code less ifdef-y and is consistent with PVHVM on
    x86.
    
    Also note that phys_to_machine_mapping_valid should take a pfn
    argument and make it do so.
    
    Add __set_phys_to_machine, make set_phys_to_machine a simple wrapper
    (on systems with non-nop implementations the outer one can allocate
    new p2m pages).
    
    Make __set_phys_to_machine check for identity mapping or invalid only.
    
    Acked-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Ian Campbell <ian.campbell@citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
index 174202318dff..c6b9096cef95 100644
--- a/arch/arm/include/asm/xen/page.h
+++ b/arch/arm/include/asm/xen/page.h
@@ -10,7 +10,7 @@
 #include <xen/interface/grant_table.h>
 
 #define pfn_to_mfn(pfn)			(pfn)
-#define phys_to_machine_mapping_valid	(1)
+#define phys_to_machine_mapping_valid(pfn) (1)
 #define mfn_to_pfn(mfn)			(mfn)
 #define mfn_to_virt(m)			(__va(mfn_to_pfn(m) << PAGE_SHIFT))
 
@@ -30,6 +30,8 @@ typedef struct xpaddr {
 #define XMADDR(x)	((xmaddr_t) { .maddr = (x) })
 #define XPADDR(x)	((xpaddr_t) { .paddr = (x) })
 
+#define INVALID_P2M_ENTRY      (~0UL)
+
 static inline xmaddr_t phys_to_machine(xpaddr_t phys)
 {
 	unsigned offset = phys.paddr & ~PAGE_MASK;
@@ -74,9 +76,14 @@ static inline int m2p_remove_override(struct page *page, bool clear_pte)
 	return 0;
 }
 
+static inline bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn)
+{
+	BUG_ON(pfn != mfn && mfn != INVALID_P2M_ENTRY);
+	return true;
+}
+
 static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
 {
-	BUG();
-	return false;
+	return __set_phys_to_machine(pfn, mfn);
 }
 #endif /* _ASM_ARM_XEN_PAGE_H */

commit 36a67abce227af005b4a595735556942b74f6741
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Wed Aug 8 16:33:46 2012 +0000

    xen/arm: page.h definitions
    
    ARM Xen guests always use paging in hardware, like PV on HVM guests in
    the X86 world.
    
    Changes in v3:
    
    - improve comments.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/arch/arm/include/asm/xen/page.h b/arch/arm/include/asm/xen/page.h
new file mode 100644
index 000000000000..174202318dff
--- /dev/null
+++ b/arch/arm/include/asm/xen/page.h
@@ -0,0 +1,82 @@
+#ifndef _ASM_ARM_XEN_PAGE_H
+#define _ASM_ARM_XEN_PAGE_H
+
+#include <asm/page.h>
+#include <asm/pgtable.h>
+
+#include <linux/pfn.h>
+#include <linux/types.h>
+
+#include <xen/interface/grant_table.h>
+
+#define pfn_to_mfn(pfn)			(pfn)
+#define phys_to_machine_mapping_valid	(1)
+#define mfn_to_pfn(mfn)			(mfn)
+#define mfn_to_virt(m)			(__va(mfn_to_pfn(m) << PAGE_SHIFT))
+
+#define pte_mfn	    pte_pfn
+#define mfn_pte	    pfn_pte
+
+/* Xen machine address */
+typedef struct xmaddr {
+	phys_addr_t maddr;
+} xmaddr_t;
+
+/* Xen pseudo-physical address */
+typedef struct xpaddr {
+	phys_addr_t paddr;
+} xpaddr_t;
+
+#define XMADDR(x)	((xmaddr_t) { .maddr = (x) })
+#define XPADDR(x)	((xpaddr_t) { .paddr = (x) })
+
+static inline xmaddr_t phys_to_machine(xpaddr_t phys)
+{
+	unsigned offset = phys.paddr & ~PAGE_MASK;
+	return XMADDR(PFN_PHYS(pfn_to_mfn(PFN_DOWN(phys.paddr))) | offset);
+}
+
+static inline xpaddr_t machine_to_phys(xmaddr_t machine)
+{
+	unsigned offset = machine.maddr & ~PAGE_MASK;
+	return XPADDR(PFN_PHYS(mfn_to_pfn(PFN_DOWN(machine.maddr))) | offset);
+}
+/* VIRT <-> MACHINE conversion */
+#define virt_to_machine(v)	(phys_to_machine(XPADDR(__pa(v))))
+#define virt_to_pfn(v)          (PFN_DOWN(__pa(v)))
+#define virt_to_mfn(v)		(pfn_to_mfn(virt_to_pfn(v)))
+#define mfn_to_virt(m)		(__va(mfn_to_pfn(m) << PAGE_SHIFT))
+
+static inline xmaddr_t arbitrary_virt_to_machine(void *vaddr)
+{
+	/* TODO: assuming it is mapped in the kernel 1:1 */
+	return virt_to_machine(vaddr);
+}
+
+/* TODO: this shouldn't be here but it is because the frontend drivers
+ * are using it (its rolled in headers) even though we won't hit the code path.
+ * So for right now just punt with this.
+ */
+static inline pte_t *lookup_address(unsigned long address, unsigned int *level)
+{
+	BUG();
+	return NULL;
+}
+
+static inline int m2p_add_override(unsigned long mfn, struct page *page,
+		struct gnttab_map_grant_ref *kmap_op)
+{
+	return 0;
+}
+
+static inline int m2p_remove_override(struct page *page, bool clear_pte)
+{
+	return 0;
+}
+
+static inline bool set_phys_to_machine(unsigned long pfn, unsigned long mfn)
+{
+	BUG();
+	return false;
+}
+#endif /* _ASM_ARM_XEN_PAGE_H */
