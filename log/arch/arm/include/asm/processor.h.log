commit 78c8516141014cf6322ac899c3832f66612504bb
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Mar 20 14:53:49 2020 +0000

    arm: vdso: Enable arm to use common headers
    
    Enable arm to use only the common headers in the implementation
    of the vDSO library.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King <linux@armlinux.org.uk>
    Link: https://lkml.kernel.org/r/20200320145351.32292-25-vincenzo.frascino@arm.com

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 614bf829e454..b9241051e5cb 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -14,6 +14,7 @@
 #include <asm/ptrace.h>
 #include <asm/types.h>
 #include <asm/unified.h>
+#include <asm/vdso/processor.h>
 
 #ifdef __KERNEL__
 #define STACK_TOP	((current->personality & ADDR_LIMIT_32BIT) ? \
@@ -85,16 +86,6 @@ extern void release_thread(struct task_struct *);
 
 unsigned long get_wchan(struct task_struct *p);
 
-#if __LINUX_ARM_ARCH__ == 6 || defined(CONFIG_ARM_ERRATA_754327)
-#define cpu_relax()						\
-	do {							\
-		smp_mb();					\
-		__asm__ __volatile__("nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;");	\
-	} while (0)
-#else
-#define cpu_relax()			barrier()
-#endif
-
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)
 

commit dba79c3df4a2275132759b0bc04c64b7a510af4a
Author: Alexandre Ghiti <alex@ghiti.fr>
Date:   Mon Sep 23 15:39:01 2019 -0700

    arm: use generic mmap top-down layout and brk randomization
    
    arm uses a top-down mmap layout by default that exactly fits the generic
    functions, so get rid of arch specific code and use the generic version by
    selecting ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT.
    
    As ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT selects ARCH_HAS_ELF_RANDOMIZE,
    use the generic version of arch_randomize_brk since it also fits.  Note
    that this commit also removes the possibility for arm to have elf
    randomization and no MMU: without MMU, the security added by randomization
    is worth nothing.
    
    Note that it is safe to remove STACK_RND_MASK since it matches the default
    value.
    
    Link: http://lkml.kernel.org/r/20190730055113.23635-9-alex@ghiti.fr
    Signed-off-by: Alexandre Ghiti <alex@ghiti.fr>
    Acked-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Luis Chamberlain <mcgrof@kernel.org>
    Cc: Albert Ou <aou@eecs.berkeley.edu>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 20c2f42454b8..614bf829e454 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -140,8 +140,6 @@ static inline void prefetchw(const void *ptr)
 #endif
 #endif
 
-#define HAVE_ARCH_PICK_MMAP_LAYOUT
-
 #endif
 
 #endif /* __ASM_ARM_PROCESSOR_H */

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 5d06f75ffad4..20c2f42454b8 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -1,11 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  *  arch/arm/include/asm/processor.h
  *
  *  Copyright (C) 1995-1999 Russell King
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 
 #ifndef __ASM_ARM_PROCESSOR_H

commit 43947b8890b4734e34e889a2df52734e0081a097
Author: Stefan Agner <stefan@agner.ch>
Date:   Sat Mar 23 12:13:14 2019 +0100

    ARM: 8853/1: drop WASM to work around LLVM issue
    
    Currently LLVM's integrated assembler does not recognize .w form
    of the pld instructions (LLVM Bug 40972 [0]):
    
      ./arch/arm/include/asm/processor.h:133:5: error: invalid instruction
                              "pldw.wt%a0 n"
                               ^
      <inline asm>:2:1: note: instantiated into assembly here
      pldw.w  [r0]
      ^
      1 error generated.
    
    The W macro for generating wide instructions when targeting Thumb-2
    is not strictly required for the preload data instructions (pld, pldw)
    since they are only available as wide instructions. The GNU assembler
    works with or without the .w appended when compiling an Thumb-2 kernel.
    
    Drop the macro to work around LLVM Bug 40972 issue.
    
    [0] https://bugs.llvm.org/show_bug.cgi?id=40972
    
    Signed-off-by: Stefan Agner <stefan@agner.ch>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 57fe73ea0f72..5d06f75ffad4 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -135,8 +135,8 @@ static inline void prefetchw(const void *ptr)
 	__asm__ __volatile__(
 		".arch_extension	mp\n"
 		__ALT_SMP_ASM(
-			WASM(pldw)		"\t%a0",
-			WASM(pld)		"\t%a0"
+			"pldw\t%a0",
+			"pld\t%a0"
 		)
 		:: "p" (ptr));
 }

commit 5388a5b82199facacd3d7ac0d05aca6e8f902fed
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Apr 10 11:35:36 2018 +0100

    ARM: avoid Cortex-A9 livelock on tight dmb loops
    
    machine_crash_nonpanic_core() does this:
    
            while (1)
                    cpu_relax();
    
    because the kernel has crashed, and we have no known safe way to deal
    with the CPU.  So, we place the CPU into an infinite loop which we
    expect it to never exit - at least not until the system as a whole is
    reset by some method.
    
    In the absence of erratum 754327, this code assembles to:
    
            b       .
    
    In other words, an infinite loop.  When erratum 754327 is enabled,
    this becomes:
    
    1:      dmb
            b       1b
    
    It has been observed that on some systems (eg, OMAP4) where, if a
    crash is triggered, the system tries to kexec into the panic kernel,
    but fails after taking the secondary CPU down - placing it into one
    of these loops.  This causes the system to livelock, and the most
    noticable effect is the system stops after issuing:
    
            Loading crashdump kernel...
    
    to the system console.
    
    The tested as working solution I came up with was to add wfe() to
    these infinite loops thusly:
    
            while (1) {
                    cpu_relax();
                    wfe();
            }
    
    which, without 754327 builds to:
    
    1:      wfe
            b       1b
    
    or with 754327 is enabled:
    
    1:      dmb
            wfe
            b       1b
    
    Adding "wfe" does two things depending on the environment we're running
    under:
    - where we're running on bare metal, and the processor implements
      "wfe", it stops us spinning endlessly in a loop where we're never
      going to do any useful work.
    - if we're running in a VM, it allows the CPU to be given back to the
      hypervisor and rescheduled for other purposes (maybe a different VM)
      rather than wasting CPU cycles inside a crashed VM.
    
    However, in light of erratum 794072, Will Deacon wanted to see 10 nops
    as well - which is reasonable to cover the case where we have erratum
    754327 enabled _and_ we have a processor that doesn't implement the
    wfe hint.
    
    So, we now end up with:
    
    1:      wfe
            b       1b
    
    when erratum 754327 is disabled, or:
    
    1:      dmb
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            nop
            wfe
            b       1b
    
    when erratum 754327 is enabled.  We also get the dmb + 10 nop
    sequence elsewhere in the kernel, in terminating loops.
    
    This is reasonable - it means we get the workaround for erratum
    794072 when erratum 754327 is enabled, but still relinquish the dead
    processor - either by placing it in a lower power mode when wfe is
    implemented as such or by returning it to the hypervisior, or in the
    case where wfe is a no-op, we use the workaround specified in erratum
    794072 to avoid the problem.
    
    These as two entirely orthogonal problems - the 10 nops addresses
    erratum 794072, and the wfe is an optimisation that makes the system
    more efficient when crashed either in terms of power consumption or
    by allowing the host/other VMs to make use of the CPU.
    
    I don't see any reason not to use kexec() inside a VM - it has the
    potential to provide automated recovery from a failure of the VMs
    kernel with the opportunity for saving a crashdump of the failure.
    A panic() with a reboot timeout won't do that, and reading the
    libvirt documentation, setting on_reboot to "preserve" won't either
    (the documentation states "The preserve action for an on_reboot event
    is treated as a destroy".)  Surely it has to be a good thing to
    avoiding having CPUs spinning inside a VM that is doing no useful
    work.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 120f4c9bbfde..57fe73ea0f72 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -89,7 +89,11 @@ extern void release_thread(struct task_struct *);
 unsigned long get_wchan(struct task_struct *p);
 
 #if __LINUX_ARM_ARCH__ == 6 || defined(CONFIG_ARM_ERRATA_754327)
-#define cpu_relax()			smp_mb()
+#define cpu_relax()						\
+	do {							\
+		smp_mb();					\
+		__asm__ __volatile__("nop; nop; nop; nop; nop; nop; nop; nop; nop; nop;");	\
+	} while (0)
 #else
 #define cpu_relax()			barrier()
 #endif

commit de0d22e50cd3d57277f073ccf65d57aa519d6888
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Tue Oct 30 15:04:47 2018 -0700

    treewide: remove current_text_addr
    
    Prefer _THIS_IP_ defined in linux/kernel.h.
    
    Most definitions of current_text_addr were the same as _THIS_IP_, but
    a few archs had inline assembly instead.
    
    This patch removes the final call site of current_text_addr, making all
    of the definitions dead code.
    
    [akpm@linux-foundation.org: fix arch/csky/include/asm/processor.h]
    Link: http://lkml.kernel.org/r/20180911182413.180715-1-ndesaulniers@google.com
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 1bf65b47808a..120f4c9bbfde 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -11,12 +11,6 @@
 #ifndef __ASM_ARM_PROCESSOR_H
 #define __ASM_ARM_PROCESSOR_H
 
-/*
- * Default implementation of macro that returns current
- * instruction pointer ("program counter").
- */
-#define current_text_addr() ({ __label__ _l; _l: &&_l;})
-
 #ifdef __KERNEL__
 
 #include <asm/hw_breakpoint.h>

commit 08626a6056aad824c43d34ce587ab2b01f49d1a4
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 16 14:09:13 2017 -0700

    arm: Implement thread_struct whitelist for hardened usercopy
    
    While ARM32 carries FPU state in the thread structure that is saved and
    restored during signal handling, it doesn't need to declare a usercopy
    whitelist, since existing accessors are all either using a bounce buffer
    (for which whitelisting isn't checking the slab), are statically sized
    (which will bypass the hardened usercopy check), or both.
    
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: "Peter Zijlstra (Intel)" <peterz@infradead.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 338cbe0a18ef..1bf65b47808a 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -45,6 +45,16 @@ struct thread_struct {
 	struct debug_info	debug;
 };
 
+/*
+ * Everything usercopied to/from thread_struct is statically-sized, so
+ * no hardened usercopy whitelist is needed.
+ */
+static inline void arch_thread_struct_whitelist(unsigned long *offset,
+						unsigned long *size)
+{
+	*offset = *size = 0;
+}
+
 #define INIT_THREAD  {	}
 
 #define start_thread(regs,pc,sp)					\

commit 5e5881143297c97207486349ec1cf9fd833b1510
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Fri Jul 28 18:48:48 2017 -0400

    ARM: start_thread(): don't always clear all regs
    
    The elf_fdpic binary format driver has to initialize extra registers
    beside the stack and program counter as required by the corresponding
    ABI. So reinstate them after the regs structure has been cleared.
    
    While at it let's get rid of start_thread_nommu().
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Mickael GUENE <mickael.guene@st.com>
    Tested-by: Vincent Abriou <vincent.abriou@st.com>
    Tested-by: Andras Szemzo <szemzo.andras@gmail.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index c3d5fc124a05..338cbe0a18ef 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -47,15 +47,24 @@ struct thread_struct {
 
 #define INIT_THREAD  {	}
 
-#ifdef CONFIG_MMU
-#define nommu_start_thread(regs) do { } while (0)
-#else
-#define nommu_start_thread(regs) regs->ARM_r10 = current->mm->start_data
-#endif
-
 #define start_thread(regs,pc,sp)					\
 ({									\
+	unsigned long r7, r8, r9;					\
+									\
+	if (IS_ENABLED(CONFIG_BINFMT_ELF_FDPIC)) {			\
+		r7 = regs->ARM_r7;					\
+		r8 = regs->ARM_r8;					\
+		r9 = regs->ARM_r9;					\
+	}								\
 	memset(regs->uregs, 0, sizeof(regs->uregs));			\
+	if (IS_ENABLED(CONFIG_BINFMT_ELF_FDPIC) &&			\
+	    current->personality & FDPIC_FUNCPTRS) {			\
+		regs->ARM_r7 = r7;					\
+		regs->ARM_r8 = r8;					\
+		regs->ARM_r9 = r9;					\
+		regs->ARM_r10 = current->mm->start_data;		\
+	} else if (!IS_ENABLED(CONFIG_MMU))				\
+		regs->ARM_r10 = current->mm->start_data;		\
 	if (current->personality & ADDR_LIMIT_32BIT)			\
 		regs->ARM_cpsr = USR_MODE;				\
 	else								\
@@ -65,7 +74,6 @@ struct thread_struct {
 	regs->ARM_cpsr |= PSR_ENDSTATE;					\
 	regs->ARM_pc = pc & ~1;		/* pc */			\
 	regs->ARM_sp = sp;		/* sp */			\
-	nommu_start_thread(regs);					\
 })
 
 /* Forward declaration, a strange C thing */

commit 6d0d287891a022ebba572327cbd70b5de69a63a2
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Wed Nov 16 13:23:05 2016 +0100

    locking/core: Provide common cpu_relax_yield() definition
    
    No need to duplicate the same define everywhere. Since
    the only user is stop-machine and the only provider is
    s390, we can use a default implementation of cpu_relax_yield()
    in sched.h.
    
    Suggested-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-s390 <linux-s390@vger.kernel.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: sparclinux@vger.kernel.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1479298985-191589-1-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 9e71c58bfa6f..c3d5fc124a05 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -82,8 +82,6 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
-#define cpu_relax_yield()  	              cpu_relax()
-
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)
 

commit 5bd0b85ba8bb9de6f61f33f3752fc85f4c87fc22
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:15 2016 +0200

    locking/core, arch: Remove cpu_relax_lowlatency()
    
    As there are no users left, we can remove cpu_relax_lowlatency()
    implementations from every architecture.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Cc: <linux-arch@vger.kernel.org>
    Link: http://lkml.kernel.org/r/1477386195-32736-6-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index db660e0b4bd3..9e71c58bfa6f 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -83,7 +83,6 @@ unsigned long get_wchan(struct task_struct *p);
 #endif
 
 #define cpu_relax_yield()  	              cpu_relax()
-#define cpu_relax_lowlatency()                cpu_relax()
 
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)

commit 79ab11cdb90d8536817ab7357ecb6b1ff76be26c
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:11 2016 +0200

    locking/core: Introduce cpu_relax_yield()
    
    For spinning loops people do often use barrier() or cpu_relax().
    For most architectures cpu_relax and barrier are the same, but on
    some architectures cpu_relax can add some latency.
    For example on power,sparc64 and arc, cpu_relax can shift the CPU
    towards other hardware threads in an SMT environment.
    On s390 cpu_relax does even more, it uses an hypercall to the
    hypervisor to give up the timeslice.
    In contrast to the SMT yielding this can result in larger latencies.
    In some places this latency is unwanted, so another variant
    "cpu_relax_lowlatency" was introduced. Before this is used in more
    and more places, lets revert the logic and provide a cpu_relax_yield
    that can be called in places where yielding is more important than
    latency. By default this is the same as cpu_relax on all architectures.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1477386195-32736-2-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 8a1e8e995dae..db660e0b4bd3 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -82,6 +82,7 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
+#define cpu_relax_yield()  	              cpu_relax()
 #define cpu_relax_lowlatency()                cpu_relax()
 
 #define task_pt_regs(p) \

commit 3a6bfbc91df04b081a44d419e0260bad54abddf7
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Sun Jun 29 15:09:33 2014 -0700

    arch, locking: Ciao arch_mutex_cpu_relax()
    
    The arch_mutex_cpu_relax() function, introduced by 34b133f, is
    hacky and ugly. It was added a few years ago to address the fact
    that common cpu_relax() calls include yielding on s390, and thus
    impact the optimistic spinning functionality of mutexes. Nowadays
    we use this function well beyond mutexes: rwsem, qrwlock, mcs and
    lockref. Since the macro that defines the call is in the mutex header,
    any users must include mutex.h and the naming is misleading as well.
    
    This patch (i) renames the call to cpu_relax_lowlatency  ("relax, but
    only if you can do it with very low latency") and (ii) defines it in
    each arch's asm/processor.h local header, just like for regular cpu_relax
    functions. On all archs, except s390, cpu_relax_lowlatency is simply cpu_relax,
    and thus we can take it out of mutex.h. While this can seem redundant,
    I believe it is a good choice as it allows us to move out arch specific
    logic from generic locking primitives and enables future(?) archs to
    transparently define it, similarly to System Z.
    
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Bharat Bhushan <r65777@freescale.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Joseph Myers <joseph@codesourcery.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Qais Yousef <qais.yousef@imgtec.com>
    Cc: Qiaowei Ren <qiaowei.ren@intel.com>
    Cc: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: Stratos Karafotis <stratosk@semaphore.gr>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Vineet Gupta <Vineet.Gupta1@synopsys.com>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Wolfram Sang <wsa@the-dreams.de>
    Cc: adi-buildroot-devel@lists.sourceforge.net
    Cc: linux390@de.ibm.com
    Cc: linux-alpha@vger.kernel.org
    Cc: linux-am33-list@redhat.com
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: linux-cris-kernel@axis.com
    Cc: linux-hexagon@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux@lists.openrisc.net
    Cc: linux-m32r-ja@ml.linux-m32r.org
    Cc: linux-m32r@ml.linux-m32r.org
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: linux-metag@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: linux-xtensa@linux-xtensa.org
    Cc: sparclinux@vger.kernel.org
    Link: http://lkml.kernel.org/r/1404079773.2619.4.camel@buesod1.americas.hpqcorp.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index c3d5fc124a05..8a1e8e995dae 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -82,6 +82,8 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
+#define cpu_relax_lowlatency()                cpu_relax()
+
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)
 

commit d8f57aa4bc5860df68d4c332d2a89c131417ee7b
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Jun 26 17:03:40 2013 +0100

    ARM: prefetch: add support for prefetchw using pldw on SMP ARMv7+ CPUs
    
    SMP ARMv7 CPUs implement the pldw instruction, which allows them to
    prefetch data cachelines in an exclusive state.
    
    This patch defines the prefetchw macro using pldw for CPUs that support
    it.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 26164c92fa30..c3d5fc124a05 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -112,12 +112,19 @@ static inline void prefetch(const void *ptr)
 		:: "p" (ptr));
 }
 
+#if __LINUX_ARM_ARCH__ >= 7 && defined(CONFIG_SMP)
 #define ARCH_HAS_PREFETCHW
-#define prefetchw(ptr)	prefetch(ptr)
-
-#define ARCH_HAS_SPINLOCK_PREFETCH
-#define spin_lock_prefetch(x) do { } while (0)
-
+static inline void prefetchw(const void *ptr)
+{
+	__asm__ __volatile__(
+		".arch_extension	mp\n"
+		__ALT_SMP_ASM(
+			WASM(pldw)		"\t%a0",
+			WASM(pld)		"\t%a0"
+		)
+		:: "p" (ptr));
+}
+#endif
 #endif
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT

commit 27a84793e42084392181ef2ef51a954f1cf0c519
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Jul 2 12:10:42 2013 +0100

    ARM: smp_on_up: move inline asm ALT_SMP patching macro out of spinlock.h
    
    Patching UP/SMP alternatives inside inline assembly blocks is useful
    outside of the spinlock implementation, where it is used for sev and wfe.
    
    This patch lifts the macro into processor.h and gives it a scarier name
    to (a) avoid conflicts in the global namespace and (b) to try and deter
    its usage unless you "know what you're doing". The W macro for generating
    wide instructions when targetting Thumb-2 is also made available under
    the name WASM, to reduce the potential for conflicts with other headers.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 514a989cbd4b..26164c92fa30 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -22,6 +22,7 @@
 #include <asm/hw_breakpoint.h>
 #include <asm/ptrace.h>
 #include <asm/types.h>
+#include <asm/unified.h>
 
 #ifdef __KERNEL__
 #define STACK_TOP	((current->personality & ADDR_LIMIT_32BIT) ? \
@@ -87,6 +88,17 @@ unsigned long get_wchan(struct task_struct *p);
 #define KSTK_EIP(tsk)	task_pt_regs(tsk)->ARM_pc
 #define KSTK_ESP(tsk)	task_pt_regs(tsk)->ARM_sp
 
+#ifdef CONFIG_SMP
+#define __ALT_SMP_ASM(smp, up)						\
+	"9998:	" smp "\n"						\
+	"	.pushsection \".alt.smp.init\", \"a\"\n"		\
+	"	.long	9998b\n"					\
+	"	" up "\n"						\
+	"	.popsection\n"
+#else
+#define __ALT_SMP_ASM(smp, up)	up
+#endif
+
 /*
  * Prefetching support - only ARMv5.
  */

commit e744dff72bcd4d9588af91e1feb662702222ca12
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Jun 26 16:47:35 2013 +0100

    ARM: prefetch: remove redundant "cc" clobber
    
    The pld instruction does not affect the condition flags, so don't bother
    clobbering them.
    
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 413f3876341c..514a989cbd4b 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -97,9 +97,7 @@ static inline void prefetch(const void *ptr)
 {
 	__asm__ __volatile__(
 		"pld\t%a0"
-		:
-		: "p" (ptr)
-		: "cc");
+		:: "p" (ptr));
 }
 
 #define ARCH_HAS_PREFETCHW

commit acfdd4b1f7590d02e9bae3b73bdbbc4a31b05d38
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jul 25 11:44:48 2013 +0100

    ARM: 7791/1: a.out: remove partial a.out support
    
    a.out support on ARM requires that argc, argv and envp are passed in
    r0-r2 respectively, which requires hacking load_aout_binary to
    prevent argc being clobbered by the return code. Whilst mainline kernels
    do set the registers up in start_thread, the aout loader has never
    carried the hack in mainline.
    
    Initialising the registers in this way actually goes against the libc
    expectations for ELF binaries, where argc, argv and envp are passed on
    the stack, with r0 being used to hold a pointer to an exit function for
    cleaning up after the dynamic linker if required. If the pointer is
    NULL, then it is ignored. When execing an ELF binary, Linux currently
    zeroes r0, then sets it to argc and then finally clobbers it with the
    return value of the execve syscall, so we actually end up with:
    
            r0 = 0
            stack[0] = argc
            r1 = stack[1] = argv
            r2 = stack[2] = envp
    
    libc treats r1 and r2 as undefined. The clobbering of r0 by sys_execve
    works for user-spawned threads, but when executing an ELF binary from a
    kernel thread (via call_usermodehelper), the execve is performed on the
    ret_from_fork path, which restores r0 from the saved pt_regs, resulting
    in argc being presented to the C library. This has horrible consequences
    when the application exits, since we have an exit function registered
    using argc, resulting in a jump to hyperspace.
    
    This patch solves the problem by removing the partial a.out support from
    arch/arm/ altogether.
    
    Cc: <stable@vger.kernel.org>
    Cc: Ashish Sangwan <ashishsangwan2@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 06e7d509eaac..413f3876341c 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -54,7 +54,6 @@ struct thread_struct {
 
 #define start_thread(regs,pc,sp)					\
 ({									\
-	unsigned long *stack = (unsigned long *)sp;			\
 	memset(regs->uregs, 0, sizeof(regs->uregs));			\
 	if (current->personality & ADDR_LIMIT_32BIT)			\
 		regs->ARM_cpsr = USR_MODE;				\
@@ -65,9 +64,6 @@ struct thread_struct {
 	regs->ARM_cpsr |= PSR_ENDSTATE;					\
 	regs->ARM_pc = pc & ~1;		/* pc */			\
 	regs->ARM_sp = sp;		/* sp */			\
-	regs->ARM_r2 = stack[2];	/* r2 (envp) */			\
-	regs->ARM_r1 = stack[1];	/* r1 (argv) */			\
-	regs->ARM_r0 = stack[0];	/* r0 (argc) */			\
 	nommu_start_thread(regs);					\
 })
 

commit 9e14f828ee4a7a4a98703e380d180717a579fb35
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 9 21:31:07 2012 -0400

    arm: split ret_from_fork, simplify kernel_thread() [based on patch by rmk]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 99afa7498260..06e7d509eaac 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -85,11 +85,6 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
-/*
- * Create a new kernel thread
- */
-extern int kernel_thread(int (*fn)(void *), void *arg, unsigned long flags);
-
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)
 

commit ec0d7f18ab7b5097d7c0c8f3d909ca1031b9d5cd
Merge: 269af9a1a08d 1dcc8d7ba235
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 10:59:07 2012 -0700

    Merge branch 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull fpu state cleanups from Ingo Molnar:
     "This tree streamlines further aspects of FPU handling by eliminating
      the prepare_to_copy() complication and moving that logic to
      arch_dup_task_struct().
    
      It also fixes the FPU dumps in threaded core dumps, removes and old
      (and now invalid) assumption plus micro-optimizes the exit path by
      avoiding an FPU save for dead tasks."
    
    Fixed up trivial add-add conflict in arch/sh/kernel/process.c that came
    in because we now do the FPU handling in arch_dup_task_struct() rather
    than the legacy (and now gone) prepare_to_copy().
    
    * 'x86-fpu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, fpu: drop the fpu state during thread exit
      x86, xsave: remove thread_has_fpu() bug check in __sanitize_i387_state()
      coredump: ensure the fpu state is flushed for proper multi-threaded core dump
      fork: move the real prepare_to_copy() users to arch_dup_task_struct()

commit 55ccf3fe3f9a3441731aa79cf42a628fc4ecace9
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Wed May 16 15:03:51 2012 -0700

    fork: move the real prepare_to_copy() users to arch_dup_task_struct()
    
    Historical prepare_to_copy() is mostly a no-op, duplicated for majority of
    the architectures and the rest following the x86 model of flushing the extended
    register state like fpu there.
    
    Remove it and use the arch_dup_task_struct() instead.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/1336692811-30576-1-git-send-email-suresh.b.siddha@intel.com
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Chen Liqin <liqin.chen@sunplusct.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 5ac8d3d3e025..6354224f980d 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -77,9 +77,6 @@ struct task_struct;
 /* Free all resources held by a thread. */
 extern void release_thread(struct task_struct *);
 
-/* Prepare to copy thread state - unlazy all lazy status */
-#define prepare_to_copy(tsk)	do { } while (0)
-
 unsigned long get_wchan(struct task_struct *p);
 
 #if __LINUX_ARM_ARCH__ == 6 || defined(CONFIG_ARM_ERRATA_754327)

commit 448eca90932d97856b6a6097fc50eef96d77dec0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 7 17:59:49 2012 +0000

    arm: Remove unused cpu_idle_wait()
    
    cpuidle uses a generic function now. Remove the unused code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Link: http://lkml.kernel.org/r/20120507175652.260797846@linutronix.de

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 5ac8d3d3e025..d7038fa22343 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -88,8 +88,6 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
-void cpu_idle_wait(void);
-
 /*
  * Create a new kernel thread
  */

commit 12679a2d7e3bfbdc7586e3e86d1ca90c46659363
Merge: 1c036588772d b0df89868006
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 16:53:48 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull more ARM updates from Russell King.
    
    This got a fair number of conflicts with the <asm/system.h> split, but
    also with some other sparse-irq and header file include cleanups.  They
    all looked pretty trivial, though.
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (59 commits)
      ARM: fix Kconfig warning for HAVE_BPF_JIT
      ARM: 7361/1: provide XIP_VIRT_ADDR for no-MMU builds
      ARM: 7349/1: integrator: convert to sparse irqs
      ARM: 7259/3: net: JIT compiler for packet filters
      ARM: 7334/1: add jump label support
      ARM: 7333/2: jump label: detect %c support for ARM
      ARM: 7338/1: add support for early console output via semihosting
      ARM: use set_current_blocked() and block_sigmask()
      ARM: exec: remove redundant set_fs(USER_DS)
      ARM: 7332/1: extract out code patch function from kprobes
      ARM: 7331/1: extract out insn generation code from ftrace
      ARM: 7330/1: ftrace: use canonical Thumb-2 wide instruction format
      ARM: 7351/1: ftrace: remove useless memory checks
      ARM: 7316/1: kexec: EOI active and mask all interrupts in kexec crash path
      ARM: Versatile Express: add NO_IOPORT
      ARM: get rid of asm/irq.h in asm/prom.h
      ARM: 7319/1: Print debug info for SIGBUS in user faults
      ARM: 7318/1: gic: refactor irq_start assignment
      ARM: 7317/1: irq: avoid NULL check in for_each_irq_desc loop
      ARM: 7315/1: perf: add support for the Cortex-A7 PMU
      ...

commit 9f97da78bf018206fb623cd351d454af2f105fe0
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:01 2012 +0100

    Disintegrate asm/system.h for ARM
    
    Disintegrate asm/system.h for ARM.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Russell King <linux@arm.linux.org.uk>
    cc: linux-arm-kernel@lists.infradead.org

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index cb8d638924fd..f4d7f56ee51f 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -22,7 +22,6 @@
 #include <asm/hw_breakpoint.h>
 #include <asm/ptrace.h>
 #include <asm/types.h>
-#include <asm/system.h>
 
 #ifdef __KERNEL__
 #define STACK_TOP	((current->personality & ADDR_LIMIT_32BIT) ? \
@@ -90,6 +89,8 @@ unsigned long get_wchan(struct task_struct *p);
 #define cpu_relax()			barrier()
 #endif
 
+void cpu_idle_wait(void);
+
 /*
  * Create a new kernel thread
  */

commit e88443cdfc61af5cd22d6aeb245ee94833c473bc
Author: Mathias Krause <minipli@googlemail.com>
Date:   Mon Mar 5 15:05:34 2012 -0800

    ARM: exec: remove redundant set_fs(USER_DS)
    
    The address limit is already set in flush_old_exec() so this
    set_fs(USER_DS) is redundant.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index ce280b8d613c..d7038fa22343 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -55,7 +55,6 @@ struct thread_struct {
 #define start_thread(regs,pc,sp)					\
 ({									\
 	unsigned long *stack = (unsigned long *)sp;			\
-	set_fs(USER_DS);						\
 	memset(regs->uregs, 0, sizeof(regs->uregs));			\
 	if (current->personality & ADDR_LIMIT_32BIT)			\
 		regs->ARM_cpsr = USR_MODE;				\

commit fee6a3c33a8f137f39cd9997b0476411f73576c7
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Feb 15 21:17:12 2012 +0100

    ARM: 7327/1: need to include asm/system.h in asm/processor.h
    
    For files that include asm/processor.h but not asm/system.h:
    
    arch/arm/mach-msm/include/mach/uncompress.h: In function 'putc':
    arch/arm/mach-msm/include/mach/uncompress.h:48:3: error: implicit declaration of function 'smp_mb' [-Werror=implicit-function-declaration]
    
    In this case, smp_mb() is from the cpu_relax() call in the msm putc().
    
    It likely went uncaught when the uncompress.h change went in since the
    defconfig didn't enable that code path, but later changes (e76f4750f4:
    ARM: debug: arrange Kconfig options more logically) resulted in the
    option being on for msm_defconfig and thus exposed it.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index ce280b8d613c..cb8d638924fd 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -22,6 +22,7 @@
 #include <asm/hw_breakpoint.h>
 #include <asm/ptrace.h>
 #include <asm/types.h>
+#include <asm/system.h>
 
 #ifdef __KERNEL__
 #define STACK_TOP	((current->personality & ADDR_LIMIT_32BIT) ? \

commit 7dbaa466780a754154531b44c2086f6618cee3a8
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Tue Nov 22 04:01:07 2011 +0100

    ARM: 7169/1: topdown mmap support
    
    Similar to other architectures, this adds topdown mmap support in user
    process address space allocation policy. This allows mmap sizes greater
    than 2GB. This support is largely copied from MIPS and the generic
    implementations.
    
    The address space randomization is moved into arch_pick_mmap_layout.
    
    Tested on V-Express with ubuntu and a mmap test from here:
    https://bugs.launchpad.net/bugs/861296
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index b2d9df5667af..ce280b8d613c 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -123,6 +123,8 @@ static inline void prefetch(const void *ptr)
 
 #endif
 
+#define HAVE_ARCH_PICK_MMAP_LAYOUT
+
 #endif
 
 #endif /* __ASM_ARM_PROCESSOR_H */

commit 1f0090a1eaa1b750a2fc5c99c91b790d5322a1fd
Merge: 2472f3c8d8fc 10a8c3839810
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Mar 16 23:35:25 2011 +0000

    Merge branch 'misc' into devel
    
    Conflicts:
            arch/arm/Kconfig

commit 5dab26af1bacad9a7189d904fbc8b4fe8e95dd81
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Mar 4 12:38:54 2011 +0100

    ARM: 6784/1: errata: no automatic Store Buffer drain on Cortex-A9
    
    On revisions of the Cortex-A9 prior to r2p0, the Store Buffer does not
    have any automatic draining mechanism and therefore a livelock may occur
    if an external agent continuously polls a memory location waiting to
    observe an update.
    
    This workaround defines cpu_relax() as smp_mb(), preventing correctly
    written polling loops from denying visibility of updates to memory.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 67357baaeeeb..7a1f03c10f1b 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -95,7 +95,7 @@ extern void release_thread(struct task_struct *);
 
 unsigned long get_wchan(struct task_struct *p);
 
-#if __LINUX_ARM_ARCH__ == 6
+#if __LINUX_ARM_ARCH__ == 6 || defined(CONFIG_ARM_ERRATA_754327)
 #define cpu_relax()			smp_mb()
 #else
 #define cpu_relax()			barrier()

commit 425fc47adb5bb69f76285be77a09a3341a30799e
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Feb 14 14:31:09 2011 +0100

    ARM: 6668/1: ptrace: remove single-step emulation code
    
    PTRACE_SINGLESTEP is a ptrace request designed to offer single-stepping
    support to userspace when the underlying architecture has hardware
    support for this operation.
    
    On ARM, we set arch_has_single_step() to 1 and attempt to emulate hardware
    single-stepping by disassembling the current instruction to determine the
    next pc and placing a software breakpoint on that location.
    
    Unfortunately this has the following problems:
    
    1.) Only a subset of ARMv7 instructions are supported
    2.) Thumb-2 is unsupported
    3.) The code is not SMP safe
    
    We could try to fix this code, but it turns out that because of the above
    issues it is rarely used in practice.  GDB, for example, uses PTRACE_POKETEXT
    and PTRACE_PEEKTEXT to manage breakpoints itself and does not require any
    kernel assistance.
    
    This patch removes the single-step emulation code from ptrace meaning that
    the PTRACE_SINGLESTEP request will return -EIO on ARM. Portable code must
    check the return value from a ptrace call and handle the failure gracefully.
    
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 67357baaeeeb..b439b41aeac1 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -29,19 +29,7 @@
 #define STACK_TOP_MAX	TASK_SIZE
 #endif
 
-union debug_insn {
-	u32	arm;
-	u16	thumb;
-};
-
-struct debug_entry {
-	u32			address;
-	union debug_insn	insn;
-};
-
 struct debug_info {
-	int			nsaved;
-	struct debug_entry	bp[2];
 #ifdef CONFIG_HAVE_HW_BREAKPOINT
 	struct perf_event	*hbp[ARM_MAX_HBP_SLOTS];
 #endif

commit 864232fa1a2f8dfe003438ef0851a56722740f3e
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Sep 3 10:42:55 2010 +0100

    ARM: 6357/1: hw-breakpoint: add new ptrace requests for hw-breakpoint interaction
    
    For debuggers to take advantage of the hw-breakpoint framework in the kernel,
    it is necessary to expose the API calls via a ptrace interface.
    
    This patch exposes the hardware breakpoints framework as a collection of
    virtual registers, accesible using PTRACE_SETHBPREGS and PTRACE_GETHBPREGS
    requests. The breakpoints are stored in the debug_info struct of the running
    thread.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: S. Karthikeyan <informkarthik@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 7bed3daf83b8..67357baaeeeb 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -19,6 +19,7 @@
 
 #ifdef __KERNEL__
 
+#include <asm/hw_breakpoint.h>
 #include <asm/ptrace.h>
 #include <asm/types.h>
 
@@ -41,6 +42,9 @@ struct debug_entry {
 struct debug_info {
 	int			nsaved;
 	struct debug_entry	bp[2];
+#ifdef CONFIG_HAVE_HW_BREAKPOINT
+	struct perf_event	*hbp[ARM_MAX_HBP_SLOTS];
+#endif
 };
 
 struct thread_struct {

commit 534be1d5a2da940ecc5e528992ea4ace8658157a
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jun 21 15:29:03 2010 +0100

    ARM: 6194/1: change definition of cpu_relax() for ARM11MPCore
    
    Linux expects that if a CPU modifies a memory location, then that
    modification will eventually become visible to other CPUs in the system.
    
    On an ARM11MPCore processor, loads are prioritised over stores so it is
    possible for a store operation to be postponed if a polling loop immediately
    follows it. If the variable being polled indirectly depends on the outstanding
    store [for example, another CPU may be polling the variable that is pending
    modification] then there is the potential for deadlock if interrupts are
    disabled. This deadlock occurs in the KGDB testsuire when executing on an
    SMP ARM11MPCore configuration.
    
    This patch changes the definition of cpu_relax() to smp_mb() for ARMv6 cores,
    forcing a flushing of the write buffer on SMP systems before the next load
    takes place. If the Kernel is not compiled for SMP support, this will expand
    to a barrier() as before.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 6a89567ffc5b..7bed3daf83b8 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -91,7 +91,11 @@ extern void release_thread(struct task_struct *);
 
 unsigned long get_wchan(struct task_struct *p);
 
+#if __LINUX_ARM_ARCH__ == 6
+#define cpu_relax()			smp_mb()
+#else
 #define cpu_relax()			barrier()
+#endif
 
 /*
  * Create a new kernel thread

commit 26584853a44c58f3d6ac7360d697a2ddcd1a3efa
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Sat May 30 14:00:18 2009 +0100

    Add core support for ARMv6/v7 big-endian
    
    Starting with ARMv6, the CPUs support the BE-8 variant of big-endian
    (byte-invariant). This patch adds the core support:
    
    - setting of the BE-8 mode via the CPSR.E register for both kernel and
      user threads
    - big-endian page table walking
    - REV used to rotate instructions read from memory during fault
      processing as they are still little-endian format
    - Kconfig and Makefile support for BE-8. The --be8 option must be passed
      to the final linking stage to convert the instructions to
      little-endian
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 1845892260e7..6a89567ffc5b 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -71,6 +71,7 @@ struct thread_struct {
 		regs->ARM_cpsr = USR26_MODE;				\
 	if (elf_hwcap & HWCAP_THUMB && pc & 1)				\
 		regs->ARM_cpsr |= PSR_T_BIT;				\
+	regs->ARM_cpsr |= PSR_ENDSTATE;					\
 	regs->ARM_pc = pc & ~1;		/* pc */			\
 	regs->ARM_sp = sp;		/* sp */			\
 	regs->ARM_r2 = stack[2];	/* r2 (envp) */			\

commit 7e1548a597ef7e26d5d62f8be3be6da9e101b26c
Merge: 1f7f569c0ae6 2619bc327417
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Dec 15 22:13:26 2008 +0000

    Merge branch 'omap3-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/tmlind/linux-omap-2.6 into devel

commit 794baba637999b81aa40e60fae1fa91978e08808
Author: Lennert Buytenhek <buytenh@wantstofly.org>
Date:   Fri Dec 5 03:25:47 2008 +0100

    [ARM] 5340/1: fix stack placement after noexecstack changes
    
    Commit 8ec53663d2698076468b3e1edc4e1b418bd54de3 ("[ARM] Improve
    non-executable support") added support for detecting non-executable
    stack binaries.  One of the things it does is to make READ_IMPLIES_EXEC
    be set in ->personality if we are running on a CPU that doesn't support
    the XN ("Execute Never") page table bit or if we are running a binary
    that needs an executable stack.
    
    This exposed a latent bug in ARM's asm/processor.h due to which we'll
    end up placing the stack at a very low address, where it will bump into
    the heap on any application that uses significant amount of stack or
    heap or both, causing many interesting crashes.
    
    Fix this by testing the ADDR_LIMIT_32BIT bit in ->personality instead
    of testing for equality against PER_LINUX_32BIT.
    
    Reviewed-by: Nicolas Pitre <nico@marvell.com>
    
    Signed-off-by: Lennert Buytenhek <buytenh@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 517a4d6ffc74..6ff33790f47b 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -23,7 +23,7 @@
 #include <asm/types.h>
 
 #ifdef __KERNEL__
-#define STACK_TOP	((current->personality == PER_LINUX_32BIT) ? \
+#define STACK_TOP	((current->personality & ADDR_LIMIT_32BIT) ? \
 			 TASK_SIZE : TASK_SIZE_26)
 #define STACK_TOP_MAX	TASK_SIZE
 #endif

commit 59f0cb0fddc14ffc6676ae62e911f8115ebc8ccf
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Oct 27 11:24:09 2008 +0000

    [ARM] remove memzero()
    
    As suggested by Andrew Morton, remove memzero() - it's not supported
    on other architectures so use of it is a potential build breaking bug.
    Since the compiler optimizes memset(x,0,n) to __memzero() perfectly
    well, we don't miss out on the underlying benefits of memzero().
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index 517a4d6ffc74..2320508443a5 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -64,7 +64,7 @@ struct thread_struct {
 ({									\
 	unsigned long *stack = (unsigned long *)sp;			\
 	set_fs(USER_DS);						\
-	memzero(regs->uregs, sizeof(regs->uregs));			\
+	memset(regs->uregs, 0, sizeof(regs->uregs));			\
 	if (current->personality & ADDR_LIMIT_32BIT)			\
 		regs->ARM_cpsr = USR_MODE;				\
 	else								\

commit 16f719de62809e224e37c320760c3ce59098d862
Author: Nicolas Pitre <nico@cam.org>
Date:   Tue Aug 12 22:10:59 2008 +0100

    [ARM] 5196/1: fix inline asm constraints for preload
    
    With gcc 4.3 and later, a pointer that has already been dereferenced is
    assumed not to be null since it should have caused a segmentation fault
    otherwise, hence any subsequent test against NULL is optimized away.
    
    Current inline asm constraint used in the implementation of prefetch()
    makes gcc believe that the pointer is dereferenced even though the PLD
    instruction does not load any data and does not cause a segmentation
    fault on null pointers, which causes all sorts of interesting results
    when reaching the end of a linked lists for example.
    
    Let's use a better constraint to properly represent the actual usage of
    the pointer value.
    
    Problem reported by Chris Steel.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
index b01d5e7e3d5a..517a4d6ffc74 100644
--- a/arch/arm/include/asm/processor.h
+++ b/arch/arm/include/asm/processor.h
@@ -112,9 +112,9 @@ extern int kernel_thread(int (*fn)(void *), void *arg, unsigned long flags);
 static inline void prefetch(const void *ptr)
 {
 	__asm__ __volatile__(
-		"pld\t%0"
+		"pld\t%a0"
 		:
-		: "o" (*(char *)ptr)
+		: "p" (ptr)
 		: "cc");
 }
 

commit 4baa9922430662431231ac637adedddbb0cfb2d7
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Aug 2 10:55:55 2008 +0100

    [ARM] move include/asm-arm to arch/arm/include/asm
    
    Move platform independent header files to arch/arm/include/asm, leaving
    those in asm/arch* and asm/plat* alone.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/include/asm/processor.h b/arch/arm/include/asm/processor.h
new file mode 100644
index 000000000000..b01d5e7e3d5a
--- /dev/null
+++ b/arch/arm/include/asm/processor.h
@@ -0,0 +1,131 @@
+/*
+ *  arch/arm/include/asm/processor.h
+ *
+ *  Copyright (C) 1995-1999 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __ASM_ARM_PROCESSOR_H
+#define __ASM_ARM_PROCESSOR_H
+
+/*
+ * Default implementation of macro that returns current
+ * instruction pointer ("program counter").
+ */
+#define current_text_addr() ({ __label__ _l; _l: &&_l;})
+
+#ifdef __KERNEL__
+
+#include <asm/ptrace.h>
+#include <asm/types.h>
+
+#ifdef __KERNEL__
+#define STACK_TOP	((current->personality == PER_LINUX_32BIT) ? \
+			 TASK_SIZE : TASK_SIZE_26)
+#define STACK_TOP_MAX	TASK_SIZE
+#endif
+
+union debug_insn {
+	u32	arm;
+	u16	thumb;
+};
+
+struct debug_entry {
+	u32			address;
+	union debug_insn	insn;
+};
+
+struct debug_info {
+	int			nsaved;
+	struct debug_entry	bp[2];
+};
+
+struct thread_struct {
+							/* fault info	  */
+	unsigned long		address;
+	unsigned long		trap_no;
+	unsigned long		error_code;
+							/* debugging	  */
+	struct debug_info	debug;
+};
+
+#define INIT_THREAD  {	}
+
+#ifdef CONFIG_MMU
+#define nommu_start_thread(regs) do { } while (0)
+#else
+#define nommu_start_thread(regs) regs->ARM_r10 = current->mm->start_data
+#endif
+
+#define start_thread(regs,pc,sp)					\
+({									\
+	unsigned long *stack = (unsigned long *)sp;			\
+	set_fs(USER_DS);						\
+	memzero(regs->uregs, sizeof(regs->uregs));			\
+	if (current->personality & ADDR_LIMIT_32BIT)			\
+		regs->ARM_cpsr = USR_MODE;				\
+	else								\
+		regs->ARM_cpsr = USR26_MODE;				\
+	if (elf_hwcap & HWCAP_THUMB && pc & 1)				\
+		regs->ARM_cpsr |= PSR_T_BIT;				\
+	regs->ARM_pc = pc & ~1;		/* pc */			\
+	regs->ARM_sp = sp;		/* sp */			\
+	regs->ARM_r2 = stack[2];	/* r2 (envp) */			\
+	regs->ARM_r1 = stack[1];	/* r1 (argv) */			\
+	regs->ARM_r0 = stack[0];	/* r0 (argc) */			\
+	nommu_start_thread(regs);					\
+})
+
+/* Forward declaration, a strange C thing */
+struct task_struct;
+
+/* Free all resources held by a thread. */
+extern void release_thread(struct task_struct *);
+
+/* Prepare to copy thread state - unlazy all lazy status */
+#define prepare_to_copy(tsk)	do { } while (0)
+
+unsigned long get_wchan(struct task_struct *p);
+
+#define cpu_relax()			barrier()
+
+/*
+ * Create a new kernel thread
+ */
+extern int kernel_thread(int (*fn)(void *), void *arg, unsigned long flags);
+
+#define task_pt_regs(p) \
+	((struct pt_regs *)(THREAD_START_SP + task_stack_page(p)) - 1)
+
+#define KSTK_EIP(tsk)	task_pt_regs(tsk)->ARM_pc
+#define KSTK_ESP(tsk)	task_pt_regs(tsk)->ARM_sp
+
+/*
+ * Prefetching support - only ARMv5.
+ */
+#if __LINUX_ARM_ARCH__ >= 5
+
+#define ARCH_HAS_PREFETCH
+static inline void prefetch(const void *ptr)
+{
+	__asm__ __volatile__(
+		"pld\t%0"
+		:
+		: "o" (*(char *)ptr)
+		: "cc");
+}
+
+#define ARCH_HAS_PREFETCHW
+#define prefetchw(ptr)	prefetch(ptr)
+
+#define ARCH_HAS_SPINLOCK_PREFETCH
+#define spin_lock_prefetch(x) do { } while (0)
+
+#endif
+
+#endif
+
+#endif /* __ASM_ARM_PROCESSOR_H */
