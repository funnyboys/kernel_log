commit 6c6b3f1f260b24dc0ab9cbbf369e4fa36819ab8b
Author: Quanyang Wang <quanyang.wang@windriver.com>
Date:   Tue Oct 22 11:23:28 2019 +0800

    ARM: zynq: use physical cpuid in zynq_slcr_cpu_stop/start
    
    When kernel booting, it will create a cpuid map between the logical cpus
    and physical cpus. In a normal boot, the cpuid map is as below:
    
        Physical      Logical
            0    ==>     0
            1    ==>     1
    
    But in kdump, there is a condition that the crash happens at the
    physical cpu1, and the crash kernel will run at the physical cpu1 too,
    so the cpuid map in crash kernel is as below:
    
        Physical      Logical
            1    ==>     0
            0    ==>     1
    
    The functions zynq_slcr_cpu_stop/start is to stop/start the physical
    cpus, the parameter cpu should be the physical cpuid. So use
    cpu_logical_map to translate the logical cpuid to physical cpuid.
    Or else the logical cpu0(physical cpu1) will stop itself and
    the processor will hang.
    
    Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
    Tested-by: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index a10085be9073..68ec303fa278 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -15,6 +15,7 @@
 #include <linux/init.h>
 #include <linux/io.h>
 #include <asm/cacheflush.h>
+#include <asm/smp_plat.h>
 #include <asm/smp_scu.h>
 #include <linux/irqchip/arm-gic.h>
 #include "common.h"
@@ -30,6 +31,7 @@ int zynq_cpun_start(u32 address, int cpu)
 {
 	u32 trampoline_code_size = &zynq_secondary_trampoline_end -
 						&zynq_secondary_trampoline;
+	u32 phy_cpuid = cpu_logical_map(cpu);
 
 	/* MS: Expectation that SLCR are directly map and accessible */
 	/* Not possible to jump to non aligned address */
@@ -39,7 +41,7 @@ int zynq_cpun_start(u32 address, int cpu)
 		u32 trampoline_size = &zynq_secondary_trampoline_jump -
 						&zynq_secondary_trampoline;
 
-		zynq_slcr_cpu_stop(cpu);
+		zynq_slcr_cpu_stop(phy_cpuid);
 		if (address) {
 			if (__pa(PAGE_OFFSET)) {
 				zero = ioremap(0, trampoline_code_size);
@@ -68,7 +70,7 @@ int zynq_cpun_start(u32 address, int cpu)
 			if (__pa(PAGE_OFFSET))
 				iounmap(zero);
 		}
-		zynq_slcr_cpu_start(cpu);
+		zynq_slcr_cpu_start(phy_cpuid);
 
 		return 0;
 	}

commit b7005d4ef4f3aa2dc24019ffba03a322557ac43d
Author: Luis Araneda <luaraneda@gmail.com>
Date:   Thu Aug 8 08:52:43 2019 -0400

    ARM: zynq: Use memcpy_toio instead of memcpy on smp bring-up
    
    This fixes a kernel panic on memcpy when
    FORTIFY_SOURCE is enabled.
    
    The initial smp implementation on commit aa7eb2bb4e4a
    ("arm: zynq: Add smp support")
    used memcpy, which worked fine until commit ee333554fed5
    ("ARM: 8749/1: Kconfig: Add ARCH_HAS_FORTIFY_SOURCE")
    enabled overflow checks at runtime, producing a read
    overflow panic.
    
    The computed size of memcpy args are:
    - p_size (dst): 4294967295 = (size_t) -1
    - q_size (src): 1
    - size (len): 8
    
    Additionally, the memory is marked as __iomem, so one of
    the memcpy_* functions should be used for read/write.
    
    Fixes: aa7eb2bb4e4a ("arm: zynq: Add smp support")
    Signed-off-by: Luis Araneda <luaraneda@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 38728badabd4..a10085be9073 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -57,7 +57,7 @@ int zynq_cpun_start(u32 address, int cpu)
 			* 0x4: Jump by mov instruction
 			* 0x8: Jumping address
 			*/
-			memcpy((__force void *)zero, &zynq_secondary_trampoline,
+			memcpy_toio(zero, &zynq_secondary_trampoline,
 							trampoline_size);
 			writel(address, zero + trampoline_size);
 

commit 5f595063affa8590a03a4f3d30bb28b1560f9d49
Author: Luis Araneda <luaraneda@gmail.com>
Date:   Thu Aug 8 08:52:42 2019 -0400

    ARM: zynq: Support smp in thumb mode
    
    Add .arm directive to headsmp.S to ensure that the
    CPU starts in 32-bit ARM mode and the correct code
    size is copied on smp bring-up.
    This is related to the fix applied to SoCFPGA by
    commit 5616f36713ea
    ("ARM: SoCFPGA: Fix secondary CPU startup in thumb2 kernel")
    
    Additionally, start secondary CPUs on secondary_startup_arm
    to automatically switch from ARM to thumb on a thumb kernel
    
    Signed-off-by: Luis Araneda <luaraneda@gmail.com>
    Suggested-by: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index a7cfe07156f4..38728badabd4 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -81,7 +81,7 @@ EXPORT_SYMBOL(zynq_cpun_start);
 
 static int zynq_boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
-	return zynq_cpun_start(__pa_symbol(secondary_startup), cpu);
+	return zynq_cpun_start(__pa_symbol(secondary_startup_arm), cpu);
 }
 
 /*

commit 9c92ab61914157664a2fbdf926df0eb937838e45
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 07:17:56 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 282
    
    Based on 1 normalized pattern(s):
    
      this software is licensed under the terms of the gnu general public
      license version 2 as published by the free software foundation and
      may be copied distributed and modified under those terms this
      program is distributed in the hope that it will be useful but
      without any warranty without even the implied warranty of
      merchantability or fitness for a particular purpose see the gnu
      general public license for more details
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 285 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190529141900.642774971@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index caa6d5fe9078..a7cfe07156f4 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * This file contains Xilinx specific SMP code, used to start up
  * the second processor.
@@ -7,15 +8,6 @@
  * based on linux/arch/arm/mach-realview/platsmp.c
  *
  * Copyright (C) 2002 ARM Ltd.
- *
- * This software is licensed under the terms of the GNU General Public
- * License version 2, as published by the Free Software Foundation, and
- * may be copied, distributed, and modified under those terms.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
  */
 
 #include <linux/export.h>

commit 64fc2a947a9873700929ec0ef02b4654a04e0476
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Sun Jan 15 03:59:29 2017 +0100

    ARM: 8641/1: treewide: Replace uses of virt_to_phys with __pa_symbol
    
    All low-level PM/SMP code using virt_to_phys() should actually use
    __pa_symbol() against kernel symbols. Update code where relevant to move
    away from virt_to_phys().
    
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Reviewed-by: Laura Abbott <labbott@redhat.com>
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 7cd9865bdeb7..caa6d5fe9078 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -89,7 +89,7 @@ EXPORT_SYMBOL(zynq_cpun_start);
 
 static int zynq_boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
-	return zynq_cpun_start(virt_to_phys(secondary_startup), cpu);
+	return zynq_cpun_start(__pa_symbol(secondary_startup), cpu);
 }
 
 /*

commit 75305275a721d33ae9abfaeed2817cec8b2fee9a
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Sun Nov 15 10:39:53 2015 +0900

    ARM: use const and __initconst for smp_operations
    
    These smp_operations structures are not over-written, so add "const"
    qualifier and replace __initdata with __initconst.
    
    Also, add "static" where it is possible.
    
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Acked-by: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Acked-by: Maxime Ripard <maxime.ripard@free-electrons.com>
    Acked-by: Moritz Fischer <moritz.fischer@ettus.com>
    Acked-by: Stephen Boyd <sboyd@codeaurora.org> # qcom part
    Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
    Acked-by: Patrice Chotard <patrice.chotard@st.com>
    Acked-by: Heiko Stuebner <heiko@sntech.de>
    Acked-by: Wei Xu <xuwei5@hisilicon.com>
    Acked-by: Florian Fainelli <f.fainelli@gmail.com>
    Acked-by: Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
    Acked-by: Gregory CLEMENT <gregory.clement@free-electrons.com>
    Acked-by: Shawn Guo <shawnguo@kernel.org>
    Acked-by: Matthias Brugger <matthias.bgg@gmail.com>
    Acked-by: Thierry Reding <treding@nvidia.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Liviu Dudau <Liviu.Dudau@arm.com>
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index f66816c49186..7cd9865bdeb7 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -157,7 +157,7 @@ static void zynq_cpu_die(unsigned int cpu)
 }
 #endif
 
-struct smp_operations zynq_smp_ops __initdata = {
+const struct smp_operations zynq_smp_ops __initconst = {
 	.smp_init_cpus		= zynq_smp_init_cpus,
 	.smp_prepare_cpus	= zynq_smp_prepare_cpus,
 	.smp_boot_secondary	= zynq_boot_secondary,

commit 02b4e2756e01c623cc4dbceae4b07be75252db5b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue May 19 17:06:44 2015 +0100

    ARM: v7 setup function should invalidate L1 cache
    
    All ARMv5 and older CPUs invalidate their caches in the early assembly
    setup function, prior to enabling the MMU.  This is because the L1
    cache should not contain any data relevant to the execution of the
    kernel at this point; all data should have been flushed out to memory.
    
    This requirement should also be true for ARMv6 and ARMv7 CPUs - indeed,
    these typically do not search their caches when caching is disabled (as
    it needs to be when the MMU is disabled) so this change should be safe.
    
    ARMv7 allows there to be CPUs which search their caches while caching is
    disabled, and it's permitted that the cache is uninitialised at boot;
    for these, the architecture reference manual requires that an
    implementation specific code sequence is used immediately after reset
    to ensure that the cache is placed into a sane state.  Such
    functionality is definitely outside the remit of the Linux kernel, and
    must be done by the SoC's firmware before _any_ CPU gets to the Linux
    kernel.
    
    Changing the data cache clean+invalidate to a mere invalidate allows us
    to get rid of a lot of platform specific hacks around this issue for
    their secondary CPU bringup paths - some of which were buggy.
    
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Tested-by: Florian Fainelli <f.fainelli@gmail.com>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Tested-by: Dinh Nguyen <dinguyen@opensource.altera.com>
    Acked-by: Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
    Tested-by: Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
    Acked-by: Shawn Guo <shawn.guo@linaro.org>
    Tested-by: Thierry Reding <treding@nvidia.com>
    Acked-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Tested-by: Michal Simek <michal.simek@xilinx.com>
    Tested-by: Wei Xu <xuwei5@hisilicon.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 52d768ff7857..f66816c49186 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -87,10 +87,9 @@ int zynq_cpun_start(u32 address, int cpu)
 }
 EXPORT_SYMBOL(zynq_cpun_start);
 
-static int zynq_boot_secondary(unsigned int cpu,
-						struct task_struct *idle)
+static int zynq_boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
-	return zynq_cpun_start(virt_to_phys(zynq_secondary_startup), cpu);
+	return zynq_cpun_start(virt_to_phys(secondary_startup), cpu);
 }
 
 /*

commit ed62e330948dea39b455d94dc14522386291688a
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Tue Sep 2 14:19:14 2014 -0700

    ARM: zynq: Rename 'zynq_platform_cpu_die'
    
    Match the naming pattern of all other SMP ops and rename
    zynq_platform_cpu_die --> zynq_cpu_die.
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index f722b5a83a45..52d768ff7857 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -137,12 +137,14 @@ static int zynq_cpu_kill(unsigned cpu)
 	return 1;
 }
 
-/*
- * platform-specific code to shutdown a CPU
+/**
+ * zynq_cpu_die - Let a CPU core die
+ * @cpu:	Dying CPU
  *
- * Called with IRQs disabled
+ * Platform-specific code to shutdown a CPU.
+ * Called with IRQs disabled on the dying CPU.
  */
-static void zynq_platform_cpu_die(unsigned int cpu)
+static void zynq_cpu_die(unsigned int cpu)
 {
 	zynq_slcr_cpu_state_write(cpu, true);
 
@@ -162,7 +164,7 @@ struct smp_operations zynq_smp_ops __initdata = {
 	.smp_boot_secondary	= zynq_boot_secondary,
 	.smp_secondary_init	= zynq_secondary_init,
 #ifdef CONFIG_HOTPLUG_CPU
-	.cpu_die		= zynq_platform_cpu_die,
+	.cpu_die		= zynq_cpu_die,
 	.cpu_kill		= zynq_cpu_kill,
 #endif
 };

commit caf86a73eab4132f870e883216850d9eee40b04b
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Tue Sep 2 14:19:13 2014 -0700

    ARM: zynq: Remove hotplug.c
    
    The hotplug code contains only a single function, which is an SMP
    function. Move that to platsmp.c where all other SMP runctions reside.
    That allows removing hotplug.c and declaring the cpu_die function
    static.
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 06415eeba7e6..f722b5a83a45 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -136,6 +136,24 @@ static int zynq_cpu_kill(unsigned cpu)
 	zynq_slcr_cpu_stop(cpu);
 	return 1;
 }
+
+/*
+ * platform-specific code to shutdown a CPU
+ *
+ * Called with IRQs disabled
+ */
+static void zynq_platform_cpu_die(unsigned int cpu)
+{
+	zynq_slcr_cpu_state_write(cpu, true);
+
+	/*
+	 * there is no power-control hardware on this platform, so all
+	 * we can do is put the core into WFI; this is safe as the calling
+	 * code will have already disabled interrupts
+	 */
+	for (;;)
+		cpu_do_idle();
+}
 #endif
 
 struct smp_operations zynq_smp_ops __initdata = {

commit 50c7960a4517d6c93226351cd8c43c86f104c919
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Tue Sep 2 14:19:12 2014 -0700

    ARM: zynq: Synchronise zynq_cpu_die/kill
    
    Avoid races and add synchronisation between the arch specific
    kill and die routines.
    
    The same synchronisation issue was fixed on IMX platform
    by this commit:
    "ARM: imx: fix sync issue between imx_cpu_die and imx_cpu_kill"
    (sha1: 2f3edfd7e27ad4206acbc2ae99c9df5f46353024)
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 6c7843108c7f..06415eeba7e6 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -127,6 +127,12 @@ static void zynq_secondary_init(unsigned int cpu)
 #ifdef CONFIG_HOTPLUG_CPU
 static int zynq_cpu_kill(unsigned cpu)
 {
+	unsigned long timeout = jiffies + msecs_to_jiffies(50);
+
+	while (zynq_slcr_cpu_state_read(cpu))
+		if (time_after(jiffies, timeout))
+			return 0;
+
 	zynq_slcr_cpu_stop(cpu);
 	return 1;
 }

commit ae88b85e801ba77939b07eb9214f1d6542fa23f7
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Tue Sep 2 14:19:06 2014 -0700

    ARM: zynq: PM: Enable A9 internal clock gating feature
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index abc82ef085c1..6c7843108c7f 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -112,6 +112,18 @@ static void __init zynq_smp_prepare_cpus(unsigned int max_cpus)
 	scu_enable(zynq_scu_base);
 }
 
+/**
+ * zynq_secondary_init - Initialize secondary CPU cores
+ * @cpu:	CPU that is initialized
+ *
+ * This function is in the hotplug path. Don't move it into the
+ * init section!!
+ */
+static void zynq_secondary_init(unsigned int cpu)
+{
+	zynq_core_pm_init();
+}
+
 #ifdef CONFIG_HOTPLUG_CPU
 static int zynq_cpu_kill(unsigned cpu)
 {
@@ -124,6 +136,7 @@ struct smp_operations zynq_smp_ops __initdata = {
 	.smp_init_cpus		= zynq_smp_init_cpus,
 	.smp_prepare_cpus	= zynq_smp_prepare_cpus,
 	.smp_boot_secondary	= zynq_boot_secondary,
+	.smp_secondary_init	= zynq_secondary_init,
 #ifdef CONFIG_HOTPLUG_CPU
 	.cpu_die		= zynq_platform_cpu_die,
 	.cpu_kill		= zynq_cpu_kill,

commit 2605f85275a7d5ccc5a59b05eed139656ad4e8a2
Author: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
Date:   Tue Jul 23 12:32:44 2013 +0100

    ARM: zynq: remove unnecessary setting of cpu_present_mask
    
    This patch also removes setting cpu_present_mask as platforms should
    only re-initialize it in smp_prepare_cpus() if present != possible.
    
    Cc: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 8021499e7b70..abc82ef085c1 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -109,15 +109,6 @@ static void __init zynq_smp_init_cpus(void)
 
 static void __init zynq_smp_prepare_cpus(unsigned int max_cpus)
 {
-	int i;
-
-	/*
-	 * Initialise the present map, which describes the set of CPUs
-	 * actually populated at the present time.
-	 */
-	for (i = 0; i < max_cpus; i++)
-		set_cpu_present(i, true);
-
 	scu_enable(zynq_scu_base);
 }
 

commit f1fd2fa62da103ccac5a076457d8dca1b940ba43
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Thu Oct 31 09:10:16 2013 -0700

    arm: zynq: Add support for zynq_cpu_kill function
    
    Use simple hook to slcr to stop cpu.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index f6e62c4a0afc..8021499e7b70 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -121,11 +121,20 @@ static void __init zynq_smp_prepare_cpus(unsigned int max_cpus)
 	scu_enable(zynq_scu_base);
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+static int zynq_cpu_kill(unsigned cpu)
+{
+	zynq_slcr_cpu_stop(cpu);
+	return 1;
+}
+#endif
+
 struct smp_operations zynq_smp_ops __initdata = {
 	.smp_init_cpus		= zynq_smp_init_cpus,
 	.smp_prepare_cpus	= zynq_smp_prepare_cpus,
 	.smp_boot_secondary	= zynq_boot_secondary,
 #ifdef CONFIG_HOTPLUG_CPU
 	.cpu_die		= zynq_platform_cpu_die,
+	.cpu_kill		= zynq_cpu_kill,
 #endif
 };

commit 6a37ff388a0b5f39062b883ae2a0f5c742c2492b
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Thu Oct 31 09:10:15 2013 -0700

    arm: zynq: Invalidate L1 in secondary boot
    
    During boot, Linux initiates a clean-invalidate operation only, resulting
    in faulty data to be written to the memory system during resume.
    Therefore invalidate the L1 in the secondary boot path to avoid these
    issues.
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 03a62d5df8f4..f6e62c4a0afc 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -90,7 +90,7 @@ EXPORT_SYMBOL(zynq_cpun_start);
 static int zynq_boot_secondary(unsigned int cpu,
 						struct task_struct *idle)
 {
-	return zynq_cpun_start(virt_to_phys(secondary_startup), cpu);
+	return zynq_cpun_start(virt_to_phys(zynq_secondary_startup), cpu);
 }
 
 /*

commit 11e031308ba660b31ffaf31f0295a2c1c358b574
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Thu Oct 31 10:37:09 2013 -0700

    arm: zynq: platsmp: Remove CPU presence check
    
    The generic code already checks that the CPU being requested is legal if
    the cpu possible/present masks are set correctly.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 689fbbc3d9c8..03a62d5df8f4 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -39,11 +39,6 @@ int zynq_cpun_start(u32 address, int cpu)
 	u32 trampoline_code_size = &zynq_secondary_trampoline_end -
 						&zynq_secondary_trampoline;
 
-	if (cpu > ncores) {
-		pr_warn("CPU No. is not available in the system\n");
-		return -1;
-	}
-
 	/* MS: Expectation that SLCR are directly map and accessible */
 	/* Not possible to jump to non aligned address */
 	if (!(address & 3) && (!address || (address >= trampoline_code_size))) {

commit 8bd26e3a7e49af2697449bbcb7187a39dc85d672
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jun 17 15:43:14 2013 -0400

    arm: delete __cpuinit/__CPUINIT usage from all ARM users
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    and are flagged as __cpuinit  -- so if we remove the __cpuinit from
    the arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    related content into no-ops as early as possible, since that will get
    rid of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the ARM uses of the __cpuinit macros from C code,
    and all __CPUINIT from assembly code.  It also had two ".previous"
    section statements that were paired off against __CPUINIT
    (aka .section ".cpuinit.text") that also get removed here.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 023f225493f2..689fbbc3d9c8 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -30,11 +30,11 @@
 /*
  * Store number of cores in the system
  * Because of scu_get_core_count() must be in __init section and can't
- * be called from zynq_cpun_start() because it is in __cpuinit section.
+ * be called from zynq_cpun_start() because it is not in __init section.
  */
 static int ncores;
 
-int __cpuinit zynq_cpun_start(u32 address, int cpu)
+int zynq_cpun_start(u32 address, int cpu)
 {
 	u32 trampoline_code_size = &zynq_secondary_trampoline_end -
 						&zynq_secondary_trampoline;
@@ -92,7 +92,7 @@ int __cpuinit zynq_cpun_start(u32 address, int cpu)
 }
 EXPORT_SYMBOL(zynq_cpun_start);
 
-static int __cpuinit zynq_boot_secondary(unsigned int cpu,
+static int zynq_boot_secondary(unsigned int cpu,
 						struct task_struct *idle)
 {
 	return zynq_cpun_start(virt_to_phys(secondary_startup), cpu);

commit 88cd4e882de73c2e62c38591abfe8c13fcc8386a
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Fri May 24 17:58:55 2013 +0200

    ARM: zynq: Not to rewrite jump code when starting address is 0x0
    
    This configuration is used by remoteproc.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index 5fc167e07619..023f225493f2 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -53,34 +53,34 @@ int __cpuinit zynq_cpun_start(u32 address, int cpu)
 						&zynq_secondary_trampoline;
 
 		zynq_slcr_cpu_stop(cpu);
-
-		if (__pa(PAGE_OFFSET)) {
-			zero = ioremap(0, trampoline_code_size);
-			if (!zero) {
-				pr_warn("BOOTUP jump vectors not accessible\n");
-				return -1;
+		if (address) {
+			if (__pa(PAGE_OFFSET)) {
+				zero = ioremap(0, trampoline_code_size);
+				if (!zero) {
+					pr_warn("BOOTUP jump vectors not accessible\n");
+					return -1;
+				}
+			} else {
+				zero = (__force u8 __iomem *)PAGE_OFFSET;
 			}
-		} else {
-			zero = (__force u8 __iomem *)PAGE_OFFSET;
-		}
-
-		/*
-		 * This is elegant way how to jump to any address
-		 * 0x0: Load address at 0x8 to r0
-		 * 0x4: Jump by mov instruction
-		 * 0x8: Jumping address
-		 */
-		memcpy((__force void *)zero, &zynq_secondary_trampoline,
-						trampoline_size);
-		writel(address, zero + trampoline_size);
-
-		flush_cache_all();
-		outer_flush_range(0, trampoline_code_size);
-		smp_wmb();
-
-		if (__pa(PAGE_OFFSET))
-			iounmap(zero);
 
+			/*
+			* This is elegant way how to jump to any address
+			* 0x0: Load address at 0x8 to r0
+			* 0x4: Jump by mov instruction
+			* 0x8: Jumping address
+			*/
+			memcpy((__force void *)zero, &zynq_secondary_trampoline,
+							trampoline_size);
+			writel(address, zero + trampoline_size);
+
+			flush_cache_all();
+			outer_flush_range(0, trampoline_code_size);
+			smp_wmb();
+
+			if (__pa(PAGE_OFFSET))
+				iounmap(zero);
+		}
 		zynq_slcr_cpu_start(cpu);
 
 		return 0;

commit 797b3a9ee790e8de2a34d427de96a1bb560fe0db
Merge: c985d7e325fd bc895b5987dd
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Apr 8 18:59:19 2013 +0200

    Merge branch 'gic/cleanup' into next/soc2
    
    Both zynq and shmobile have conflicts against the gic cleanup
    series, resolved here.
    
    Conflicts:
            arch/arm/mach-shmobile/smp-emev2.c
            arch/arm/mach-shmobile/smp-r8a7779.c
            arch/arm/mach-shmobile/smp-sh73a0.c
            arch/arm/mach-zynq/platsmp.c
            drivers/gpio/gpio-pl061.c
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

commit c7c28b0fdd06d8eb9414d21f8956b7c773ceea93
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Wed Mar 20 13:56:15 2013 +0100

    arm: zynq: Add hotplug support
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
index cdfd888ca783..3072cbd7ec6f 100644
--- a/arch/arm/mach-zynq/platsmp.c
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -146,4 +146,7 @@ struct smp_operations zynq_smp_ops __initdata = {
 	.smp_prepare_cpus	= zynq_smp_prepare_cpus,
 	.smp_secondary_init	= zynq_secondary_init,
 	.smp_boot_secondary	= zynq_boot_secondary,
+#ifdef CONFIG_HOTPLUG_CPU
+	.cpu_die		= zynq_platform_cpu_die,
+#endif
 };

commit aa7eb2bb4e4a22e41bbe4612ff46e5885b13c33e
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Wed Mar 20 13:50:12 2013 +0100

    arm: zynq: Add smp support
    
    Zynq is dual core Cortex A9 which starts always
    at zero. Using simple trampoline ensure long jump
    to secondary_startup code.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Steffen Trumtrar <s.trumtrar@pengutronix.de>

diff --git a/arch/arm/mach-zynq/platsmp.c b/arch/arm/mach-zynq/platsmp.c
new file mode 100644
index 000000000000..cdfd888ca783
--- /dev/null
+++ b/arch/arm/mach-zynq/platsmp.c
@@ -0,0 +1,149 @@
+/*
+ * This file contains Xilinx specific SMP code, used to start up
+ * the second processor.
+ *
+ * Copyright (C) 2011-2013 Xilinx
+ *
+ * based on linux/arch/arm/mach-realview/platsmp.c
+ *
+ * Copyright (C) 2002 ARM Ltd.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/export.h>
+#include <linux/jiffies.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <asm/cacheflush.h>
+#include <asm/smp_scu.h>
+#include <linux/irqchip/arm-gic.h>
+#include "common.h"
+
+/*
+ * Store number of cores in the system
+ * Because of scu_get_core_count() must be in __init section and can't
+ * be called from zynq_cpun_start() because it is in __cpuinit section.
+ */
+static int ncores;
+
+/* Secondary CPU kernel startup is a 2 step process. The primary CPU
+ * starts the secondary CPU by giving it the address of the kernel and
+ * then sending it an event to wake it up. The secondary CPU then
+ * starts the kernel and tells the primary CPU it's up and running.
+ */
+static void __cpuinit zynq_secondary_init(unsigned int cpu)
+{
+	/*
+	 * if any interrupts are already enabled for the primary
+	 * core (e.g. timer irq), then they will not have been enabled
+	 * for us: do so
+	 */
+	gic_secondary_init(0);
+}
+
+int __cpuinit zynq_cpun_start(u32 address, int cpu)
+{
+	u32 trampoline_code_size = &zynq_secondary_trampoline_end -
+						&zynq_secondary_trampoline;
+
+	if (cpu > ncores) {
+		pr_warn("CPU No. is not available in the system\n");
+		return -1;
+	}
+
+	/* MS: Expectation that SLCR are directly map and accessible */
+	/* Not possible to jump to non aligned address */
+	if (!(address & 3) && (!address || (address >= trampoline_code_size))) {
+		/* Store pointer to ioremap area which points to address 0x0 */
+		static u8 __iomem *zero;
+		u32 trampoline_size = &zynq_secondary_trampoline_jump -
+						&zynq_secondary_trampoline;
+
+		zynq_slcr_cpu_stop(cpu);
+
+		if (__pa(PAGE_OFFSET)) {
+			zero = ioremap(0, trampoline_code_size);
+			if (!zero) {
+				pr_warn("BOOTUP jump vectors not accessible\n");
+				return -1;
+			}
+		} else {
+			zero = (__force u8 __iomem *)PAGE_OFFSET;
+		}
+
+		/*
+		 * This is elegant way how to jump to any address
+		 * 0x0: Load address at 0x8 to r0
+		 * 0x4: Jump by mov instruction
+		 * 0x8: Jumping address
+		 */
+		memcpy((__force void *)zero, &zynq_secondary_trampoline,
+						trampoline_size);
+		writel(address, zero + trampoline_size);
+
+		flush_cache_all();
+		outer_flush_range(0, trampoline_code_size);
+		smp_wmb();
+
+		if (__pa(PAGE_OFFSET))
+			iounmap(zero);
+
+		zynq_slcr_cpu_start(cpu);
+
+		return 0;
+	}
+
+	pr_warn("Can't start CPU%d: Wrong starting address %x\n", cpu, address);
+
+	return -1;
+}
+EXPORT_SYMBOL(zynq_cpun_start);
+
+static int __cpuinit zynq_boot_secondary(unsigned int cpu,
+						struct task_struct *idle)
+{
+	return zynq_cpun_start(virt_to_phys(secondary_startup), cpu);
+}
+
+/*
+ * Initialise the CPU possible map early - this describes the CPUs
+ * which may be present or become present in the system.
+ */
+static void __init zynq_smp_init_cpus(void)
+{
+	int i;
+
+	ncores = scu_get_core_count(zynq_scu_base);
+
+	for (i = 0; i < ncores && i < CONFIG_NR_CPUS; i++)
+		set_cpu_possible(i, true);
+}
+
+static void __init zynq_smp_prepare_cpus(unsigned int max_cpus)
+{
+	int i;
+
+	/*
+	 * Initialise the present map, which describes the set of CPUs
+	 * actually populated at the present time.
+	 */
+	for (i = 0; i < max_cpus; i++)
+		set_cpu_present(i, true);
+
+	scu_enable(zynq_scu_base);
+}
+
+struct smp_operations zynq_smp_ops __initdata = {
+	.smp_init_cpus		= zynq_smp_init_cpus,
+	.smp_prepare_cpus	= zynq_smp_prepare_cpus,
+	.smp_secondary_init	= zynq_secondary_init,
+	.smp_boot_secondary	= zynq_boot_secondary,
+};
