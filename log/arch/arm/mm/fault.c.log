commit c1e8d7c6a7a682e1405e3e242d32fc377fd196ff
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:54 2020 -0700

    mmap locking API: convert mmap_sem comments
    
    Convert comments that reference mmap_sem to reference mmap_lock instead.
    
    [akpm@linux-foundation.org: fix up linux-next leftovers]
    [akpm@linux-foundation.org: s/lockaphore/lock/, per Vlastimil]
    [akpm@linux-foundation.org: more linux-next fixups, per Michel]
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-13-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 8e56c43981b4..c6550eddfce1 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -293,7 +293,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	fault = __do_page_fault(mm, addr, fsr, flags, tsk);
 
 	/* If we need to retry but a fatal signal is pending, handle the
-	 * signal first. We do not need to release the mmap_sem because
+	 * signal first. We do not need to release the mmap_lock because
 	 * it would already be released in __lock_page_or_retry in
 	 * mm/filemap.c. */
 	if (fault_signal_pending(fault, regs)) {

commit d8ed45c5dcd455fc5848d47f86883a1b872ac0d0
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:25 2020 -0700

    mmap locking API: use coccinelle to convert mmap_sem rwsem call sites
    
    This change converts the existing mmap_sem rwsem calls to use the new mmap
    locking API instead.
    
    The change is generated using coccinelle with the following rule:
    
    // spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir .
    
    @@
    expression mm;
    @@
    (
    -init_rwsem
    +mmap_init_lock
    |
    -down_write
    +mmap_write_lock
    |
    -down_write_killable
    +mmap_write_lock_killable
    |
    -down_write_trylock
    +mmap_write_trylock
    |
    -up_write
    +mmap_write_unlock
    |
    -downgrade_write
    +mmap_write_downgrade
    |
    -down_read
    +mmap_read_lock
    |
    -down_read_killable
    +mmap_read_lock_killable
    |
    -down_read_trylock
    +mmap_read_trylock
    |
    -up_read
    +mmap_read_unlock
    )
    -(&mm->mmap_sem)
    +(mm)
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-5-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 6229e9d2da6e..8e56c43981b4 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -271,11 +271,11 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * validly references user space from well defined areas of the code,
 	 * we can bug out early if this is from code which shouldn't.
 	 */
-	if (!down_read_trylock(&mm->mmap_sem)) {
+	if (!mmap_read_trylock(mm)) {
 		if (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))
 			goto no_context;
 retry:
-		down_read(&mm->mmap_sem);
+		mmap_read_lock(mm);
 	} else {
 		/*
 		 * The above down_read_trylock() might have succeeded in
@@ -325,7 +325,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		}
 	}
 
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR

commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ff230e9affc4..6229e9d2da6e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -18,7 +18,6 @@
 #include <linux/highmem.h>
 #include <linux/perf_event.h>
 
-#include <asm/pgtable.h>
 #include <asm/system_misc.h>
 #include <asm/system_info.h>
 #include <asm/tlbflush.h>

commit 84e6ffb2c49c7901a9efb54b497d2eb84c3bef8c
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Jun 4 16:46:19 2020 -0700

    arm: add support for folded p4d page tables
    
    Implement primitives necessary for the 4th level folding, add walks of p4d
    level where appropriate, and remove __ARCH_USE_5LEVEL_HACK.
    
    [rppt@linux.ibm.com: fix kexec]
      Link: http://lkml.kernel.org/r/20200508174232.GA759899@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: James Morse <james.morse@arm.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Julien Thierry <julien.thierry.kdev@gmail.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200414153455.21744-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 2dd5c41cbb8d..ff230e9affc4 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -43,19 +43,21 @@ void show_pte(const char *lvl, struct mm_struct *mm, unsigned long addr)
 	printk("%s[%08lx] *pgd=%08llx", lvl, addr, (long long)pgd_val(*pgd));
 
 	do {
+		p4d_t *p4d;
 		pud_t *pud;
 		pmd_t *pmd;
 		pte_t *pte;
 
-		if (pgd_none(*pgd))
+		p4d = p4d_offset(pgd, addr);
+		if (p4d_none(*p4d))
 			break;
 
-		if (pgd_bad(*pgd)) {
+		if (p4d_bad(*p4d)) {
 			pr_cont("(bad)");
 			break;
 		}
 
-		pud = pud_offset(pgd, addr);
+		pud = pud_offset(p4d, addr);
 		if (PTRS_PER_PUD != 1)
 			pr_cont(", *pud=%08llx", (long long)pud_val(*pud));
 
@@ -405,6 +407,7 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 {
 	unsigned int index;
 	pgd_t *pgd, *pgd_k;
+	p4d_t *p4d, *p4d_k;
 	pud_t *pud, *pud_k;
 	pmd_t *pmd, *pmd_k;
 
@@ -419,13 +422,16 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	pgd = cpu_get_pgd() + index;
 	pgd_k = init_mm.pgd + index;
 
-	if (pgd_none(*pgd_k))
+	p4d = p4d_offset(pgd, addr);
+	p4d_k = p4d_offset(pgd_k, addr);
+
+	if (p4d_none(*p4d_k))
 		goto bad_area;
-	if (!pgd_present(*pgd))
-		set_pgd(pgd, *pgd_k);
+	if (!p4d_present(*p4d))
+		set_p4d(p4d, *p4d_k);
 
-	pud = pud_offset(pgd, addr);
-	pud_k = pud_offset(pgd_k, addr);
+	pud = pud_offset(p4d, addr);
+	pud_k = pud_offset(p4d_k, addr);
 
 	if (pud_none(*pud_k))
 		goto bad_area;

commit 6cb4d9a2870d2062e34c93bfef4d52fca3fe42d1
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Fri Apr 10 14:33:09 2020 -0700

    mm/vma: introduce VM_ACCESS_FLAGS
    
    There are many places where all basic VMA access flags (read, write,
    exec) are initialized or checked against as a group.  One such example
    is during page fault.  Existing vma_is_accessible() wrapper already
    creates the notion of VMA accessibility as a group access permissions.
    
    Hence lets just create VM_ACCESS_FLAGS (VM_READ|VM_WRITE|VM_EXEC) which
    will not only reduce code duplication but also extend the VMA
    accessibility concept in general.
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Rob Springer <rspringer@google.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Link: http://lkml.kernel.org/r/1583391014-8170-3-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index b598e6978b29..2dd5c41cbb8d 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -189,7 +189,7 @@ void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  */
 static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
 {
-	unsigned int mask = VM_READ | VM_WRITE | VM_EXEC;
+	unsigned int mask = VM_ACCESS_FLAGS;
 
 	if ((fsr & FSR_WRITE) && !(fsr & FSR_CM))
 		mask = VM_WRITE;

commit 4064b982706375025628094e51d11cf1a958a5d3
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:45 2020 -0700

    mm: allow VM_FAULT_RETRY for multiple times
    
    The idea comes from a discussion between Linus and Andrea [1].
    
    Before this patch we only allow a page fault to retry once.  We achieved
    this by clearing the FAULT_FLAG_ALLOW_RETRY flag when doing
    handle_mm_fault() the second time.  This was majorly used to avoid
    unexpected starvation of the system by looping over forever to handle the
    page fault on a single page.  However that should hardly happen, and after
    all for each code path to return a VM_FAULT_RETRY we'll first wait for a
    condition (during which time we should possibly yield the cpu) to happen
    before VM_FAULT_RETRY is really returned.
    
    This patch removes the restriction by keeping the FAULT_FLAG_ALLOW_RETRY
    flag when we receive VM_FAULT_RETRY.  It means that the page fault handler
    now can retry the page fault for multiple times if necessary without the
    need to generate another page fault event.  Meanwhile we still keep the
    FAULT_FLAG_TRIED flag so page fault handler can still identify whether a
    page fault is the first attempt or not.
    
    Then we'll have these combinations of fault flags (only considering
    ALLOW_RETRY flag and TRIED flag):
    
      - ALLOW_RETRY and !TRIED:  this means the page fault allows to
                                 retry, and this is the first try
    
      - ALLOW_RETRY and TRIED:   this means the page fault allows to
                                 retry, and this is not the first try
    
      - !ALLOW_RETRY and !TRIED: this means the page fault does not allow
                                 to retry at all
    
      - !ALLOW_RETRY and TRIED:  this is forbidden and should never be used
    
    In existing code we have multiple places that has taken special care of
    the first condition above by checking against (fault_flags &
    FAULT_FLAG_ALLOW_RETRY).  This patch introduces a simple helper to detect
    the first retry of a page fault by checking against both (fault_flags &
    FAULT_FLAG_ALLOW_RETRY) and !(fault_flag & FAULT_FLAG_TRIED) because now
    even the 2nd try will have the ALLOW_RETRY set, then use that helper in
    all existing special paths.  One example is in __lock_page_or_retry(), now
    we'll drop the mmap_sem only in the first attempt of page fault and we'll
    keep it in follow up retries, so old locking behavior will be retained.
    
    This will be a nice enhancement for current code [2] at the same time a
    supporting material for the future userfaultfd-writeprotect work, since in
    that work there will always be an explicit userfault writeprotect retry
    for protected pages, and if that cannot resolve the page fault (e.g., when
    userfaultfd-writeprotect is used in conjunction with swapped pages) then
    we'll possibly need a 3rd retry of the page fault.  It might also benefit
    other potential users who will have similar requirement like userfault
    write-protection.
    
    GUP code is not touched yet and will be covered in follow up patch.
    
    Please read the thread below for more information.
    
    [1] https://lore.kernel.org/lkml/20171102193644.GB22686@redhat.com/
    [2] https://lore.kernel.org/lkml/20181230154648.GB9832@redhat.com/
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Suggested-by: Andrea Arcangeli <aarcange@redhat.com>
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160246.9790-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 18ef0b143ac2..b598e6978b29 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -319,9 +319,6 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 					regs, addr);
 		}
 		if (fault & VM_FAULT_RETRY) {
-			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
-			* of starvation. */
-			flags &= ~FAULT_FLAG_ALLOW_RETRY;
 			flags |= FAULT_FLAG_TRIED;
 			goto retry;
 		}

commit dde1607248328cdb7570e3a252e8fb76b3411d66
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:37 2020 -0700

    mm: introduce FAULT_FLAG_DEFAULT
    
    Although there're tons of arch-specific page fault handlers, most of them
    are still sharing the same initial value of the page fault flags.  Say,
    merely all of the page fault handlers would allow the fault to be retried,
    and they also allow the fault to respond to SIGKILL.
    
    Let's define a default value for the fault flags to replace those initial
    page fault flags that were copied over.  With this, it'll be far easier to
    introduce new fault flag that can be used by all the architectures instead
    of touching all the archs.
    
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160238.9694-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 937b81ff8649..18ef0b143ac2 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -241,7 +241,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	struct mm_struct *mm;
 	int sig, code;
 	vm_fault_t fault;
-	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
+	unsigned int flags = FAULT_FLAG_DEFAULT;
 
 	if (kprobe_page_fault(regs, fsr))
 		return 0;

commit 4ef873226ceb9c7bf11a922caddc5698a24bcfaf
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:06 2020 -0700

    mm: introduce fault_signal_pending()
    
    For most architectures, we've got a quick path to detect fatal signal
    after a handle_mm_fault().  Introduce a helper for that quick path.
    
    It cleans the current codes a bit so we don't need to duplicate the same
    check across archs.  More importantly, this will be an unified place that
    we handle the signal immediately right after an interrupted page fault, so
    it'll be much easier for us if we want to change the behavior of handling
    signals later on for all the archs.
    
    Note that currently only part of the archs are using this new helper,
    because some archs have their own way to handle signals.  In the follow up
    patches, we'll try to apply this helper to all the rest of archs.
    
    Another note is that the "regs" parameter in the new helper is not used
    yet.  It'll be used very soon.  Now we kept it in this patch only to avoid
    touching all the archs again in the follow up patches.
    
    [peterx@redhat.com: fix sparse warnings]
      Link: http://lkml.kernel.org/r/20200311145921.GD479302@xz-x1
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220155353.8676-4-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bd0f4821f7e1..937b81ff8649 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -295,7 +295,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * signal first. We do not need to release the mmap_sem because
 	 * it would already be released in __lock_page_or_retry in
 	 * mm/filemap.c. */
-	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current)) {
+	if (fault_signal_pending(fault, regs)) {
 		if (!user_mode(regs))
 			goto no_context;
 		return 0;

commit 834020366da9ab3fb87d1eb9a3160eb22dbed63a
Author: Will Deacon <will@kernel.org>
Date:   Thu Aug 8 16:51:00 2019 +0100

    ARM: 8898/1: mm: Don't treat faults reported from cache maintenance as writes
    
    Translation faults arising from cache maintenance instructions are
    rather unhelpfully reported with an FSR value where the WnR field is set
    to 1, indicating that the faulting access was a write. Since cache
    maintenance instructions on 32-bit ARM do not require any particular
    permissions, this can cause our private 'cacheflush' system call to fail
    spuriously if a translation fault is generated due to page aging when
    targetting a read-only VMA.
    
    In this situation, we will return -EFAULT to userspace, although this is
    unfortunately suppressed by the popular '__builtin___clear_cache()'
    intrinsic provided by GCC, which returns void.
    
    Although it's tempting to write this off as a userspace issue, we can
    actually do a little bit better on CPUs that support LPAE, even if the
    short-descriptor format is in use. On these CPUs, cache maintenance
    faults additionally set the CM field in the FSR, which we can use to
    suppress the write permission checks in the page fault handler and
    succeed in performing cache maintenance to read-only areas even in the
    presence of a translation fault.
    
    Reported-by: Orion Hodson <oth@google.com>
    Signed-off-by: Will Deacon <will@kernel.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 890eeaac3cbb..bd0f4821f7e1 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -191,7 +191,7 @@ static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
 {
 	unsigned int mask = VM_READ | VM_WRITE | VM_EXEC;
 
-	if (fsr & FSR_WRITE)
+	if ((fsr & FSR_WRITE) && !(fsr & FSR_CM))
 		mask = VM_WRITE;
 	if (fsr & FSR_LNX_PF)
 		mask = VM_EXEC;
@@ -262,7 +262,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 
 	if (user_mode(regs))
 		flags |= FAULT_FLAG_USER;
-	if (fsr & FSR_WRITE)
+	if ((fsr & FSR_WRITE) && !(fsr & FSR_CM))
 		flags |= FAULT_FLAG_WRITE;
 
 	/*

commit b98cca444d287a63dd96df04af7fb9793567599e
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Tue Jul 16 16:28:00 2019 -0700

    mm, kprobes: generalize and rename notify_page_fault() as kprobe_page_fault()
    
    Architectures which support kprobes have very similar boilerplate around
    calling kprobe_fault_handler().  Use a helper function in kprobes.h to
    unify them, based on the x86 code.
    
    This changes the behaviour for other architectures when preemption is
    enabled.  Previously, they would have disabled preemption while calling
    the kprobe handler.  However, preemption would be disabled if this fault
    was due to a kprobe, so we know the fault was not due to a kprobe
    handler and can simply return failure.
    
    This behaviour was introduced in commit a980c0ef9f6d ("x86/kprobes:
    Refactor kprobes_fault() like kprobe_exceptions_notify()")
    
    [anshuman.khandual@arm.com: export kprobe_fault_handler()]
      Link: http://lkml.kernel.org/r/1561133358-8876-1-git-send-email-anshuman.khandual@arm.com
    Link: http://lkml.kernel.org/r/1560420444-25737-1-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Reviewed-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 0e417233dad7..890eeaac3cbb 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -27,28 +27,6 @@
 
 #ifdef CONFIG_MMU
 
-#ifdef CONFIG_KPROBES
-static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
-{
-	int ret = 0;
-
-	if (!user_mode(regs)) {
-		/* kprobe_running() needs smp_processor_id() */
-		preempt_disable();
-		if (kprobe_running() && kprobe_fault_handler(regs, fsr))
-			ret = 1;
-		preempt_enable();
-	}
-
-	return ret;
-}
-#else
-static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
-{
-	return 0;
-}
-#endif
-
 /*
  * This is useful to dump out the page tables associated with
  * 'addr' in mm 'mm'.
@@ -265,7 +243,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	vm_fault_t fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
-	if (notify_page_fault(regs, fsr))
+	if (kprobe_page_fault(regs, fsr))
 		return 0;
 
 	tsk = current;

commit 5ad18b2e60b75c7297a998dea702451d33a052ed
Merge: 92c1d6522135 318759b4737c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:48:15 2019 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull force_sig() argument change from Eric Biederman:
     "A source of error over the years has been that force_sig has taken a
      task parameter when it is only safe to use force_sig with the current
      task.
    
      The force_sig function is built for delivering synchronous signals
      such as SIGSEGV where the userspace application caused a synchronous
      fault (such as a page fault) and the kernel responded with a signal.
    
      Because the name force_sig does not make this clear, and because the
      force_sig takes a task parameter the function force_sig has been
      abused for sending other kinds of signals over the years. Slowly those
      have been fixed when the oopses have been tracked down.
    
      This set of changes fixes the remaining abusers of force_sig and
      carefully rips out the task parameter from force_sig and friends
      making this kind of error almost impossible in the future"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (27 commits)
      signal/x86: Move tsk inside of CONFIG_MEMORY_FAILURE in do_sigbus
      signal: Remove the signal number and task parameters from force_sig_info
      signal: Factor force_sig_info_to_task out of force_sig_info
      signal: Generate the siginfo in force_sig
      signal: Move the computation of force into send_signal and correct it.
      signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
      signal: Remove the task parameter from force_sig_fault
      signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
      signal: Explicitly call force_sig_fault on current
      signal/unicore32: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from ptrace_break
      signal/nds32: Remove tsk parameter from send_sigtrap
      signal/riscv: Remove tsk parameter from do_trap
      signal/sh: Remove tsk parameter from force_sig_info_fault
      signal/um: Remove task parameter from send_sigtrap
      signal/x86: Remove task parameter from send_sigtrap
      signal: Remove task parameter from force_sig_mceerr
      signal: Remove task parameter from force_sig
      signal: Remove task parameter from force_sigsegv
      ...

commit 2b49350b16fa3171136d7cf351ac7e9e6673b8f2
Merge: 4d2fa8b44b89 5ccd3bd992cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:08:34 2019 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - Add a "cut here" to make it clearer where oops dumps should be cut
       from - we already have a marker for the end of the dumps.
    
     - Add logging severity to show_pte()
    
     - Drop unnecessary common-page-size linker flag
    
     - Errata workarounds for Cortex A12 857271, Cortex A17 857272 and
       Cortex A7 814220.
    
     - Remove some unused variables that had started to provoke a compiler
       warning.
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm:
      ARM: 8863/1: stm32: select ARM errata 814220
      ARM: 8862/1: errata: 814220-B-Cache maintenance by set/way operations can execute out of order
      ARM: 8865/1: mm: remove unused variables
      ARM: 8864/1: Add workaround for I-Cache line size mismatch between CPU cores
      ARM: 8861/1: errata: Workaround errata A12 857271 / A17 857272
      ARM: 8860/1: VDSO: Drop implicit common-page-size linker flag
      ARM: arrange show_pte() to issue severity-based messages
      ARM: add "8<--- cut here ---" to kernel dumps

commit 49b38c345baa1bfdb79ff7f546755c29ea59e028
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Jan 29 15:44:38 2019 +0000

    ARM: arrange show_pte() to issue severity-based messages
    
    show_pte() is used to print information after various other kernel
    messages, which themselves are printed at different severities.
    Include the severity in the show_pte() information so that associated
    messages are printed with the same severity.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 743a9e0a1fda..b4cade58ed7b 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -56,17 +56,16 @@ static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
  * This is useful to dump out the page tables associated with
  * 'addr' in mm 'mm'.
  */
-void show_pte(struct mm_struct *mm, unsigned long addr)
+void show_pte(const char *lvl, struct mm_struct *mm, unsigned long addr)
 {
 	pgd_t *pgd;
 
 	if (!mm)
 		mm = &init_mm;
 
-	pr_alert("pgd = %p\n", mm->pgd);
+	printk("%spgd = %p\n", lvl, mm->pgd);
 	pgd = pgd_offset(mm, addr);
-	pr_alert("[%08lx] *pgd=%08llx",
-			addr, (long long)pgd_val(*pgd));
+	printk("%s[%08lx] *pgd=%08llx", lvl, addr, (long long)pgd_val(*pgd));
 
 	do {
 		pud_t *pud;
@@ -121,7 +120,7 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 	pr_cont("\n");
 }
 #else					/* CONFIG_MMU */
-void show_pte(struct mm_struct *mm, unsigned long addr)
+void show_pte(const char *lvl, struct mm_struct *mm, unsigned long addr)
 { }
 #endif					/* CONFIG_MMU */
 
@@ -147,7 +146,7 @@ __do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		 (addr < PAGE_SIZE) ? "NULL pointer dereference" :
 		 "paging request", addr);
 
-	show_pte(mm, addr);
+	show_pte(KERN_ALERT, mm, addr);
 	die("Oops", regs, fsr);
 	bust_spinlocks(0);
 	do_exit(SIGKILL);
@@ -169,9 +168,9 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
 	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {
 		pr_err("8<--- cut here ---\n");
-		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
+		pr_err("%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
 		       tsk->comm, sig, addr, fsr);
-		show_pte(tsk->mm, addr);
+		show_pte(KERN_ERR, tsk->mm, addr);
 		show_regs(regs);
 	}
 #endif
@@ -561,7 +560,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	pr_alert("8<--- cut here ---\n");
 	pr_alert("Unhandled fault: %s (0x%03x) at 0x%08lx\n",
 		inf->name, fsr, addr);
-	show_pte(current->mm, addr);
+	show_pte(KERN_ALERT, current->mm, addr);
 
 	arm_notify_die("", regs, inf->sig, inf->code, (void __user *)addr,
 		       fsr, 0);

commit bafeb7a0d9213e64a0e09d149b52abeb0c8798b5
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Jan 29 14:07:58 2019 +0000

    ARM: add "8<--- cut here ---" to kernel dumps
    
    Add a "8<--- cut here ---" marker to kernel dumps to help users cut
    the dump at the right place when emailing list, rather than cutting
    off the first line which gives the reason for the dump.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 58f69fa07df9..743a9e0a1fda 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -142,6 +142,7 @@ __do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * No handler, we'll have to terminate things with extreme prejudice.
 	 */
 	bust_spinlocks(1);
+	pr_alert("8<--- cut here ---\n");
 	pr_alert("Unable to handle kernel %s at virtual address %08lx\n",
 		 (addr < PAGE_SIZE) ? "NULL pointer dereference" :
 		 "paging request", addr);
@@ -167,6 +168,7 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 #ifdef CONFIG_DEBUG_USER
 	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
 	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {
+		pr_err("8<--- cut here ---\n");
 		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
 		       tsk->comm, sig, addr, fsr);
 		show_pte(tsk->mm, addr);
@@ -556,6 +558,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
 		return;
 
+	pr_alert("8<--- cut here ---\n");
 	pr_alert("Unhandled fault: %s (0x%03x) at 0x%08lx\n",
 		inf->name, fsr, addr);
 	show_pte(current->mm, addr);

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 58f69fa07df9..0048eadd0681 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/arch/arm/mm/fault.c
  *
  *  Copyright (C) 1995  Linus Torvalds
  *  Modifications for ARM processor (c) 1995-2004 Russell King
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/extable.h>
 #include <linux/signal.h>

commit 2e1661d2673667d886cd40ad9f414cb6db48d8da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 11:04:24 2019 -0500

    signal: Remove the task parameter from force_sig_fault
    
    As synchronous exceptions really only make sense against the current
    task (otherwise how are you synchronous) remove the task parameter
    from from force_sig_fault to make it explicit that is what is going
    on.
    
    The two known exceptions that deliver a synchronous exception to a
    stopped ptraced task have already been changed to
    force_sig_fault_to_task.
    
    The callers have been changed with the following emacs regular expression
    (with obvious variations on the architectures that take more arguments)
    to avoid typos:
    
    force_sig_fault[(]\([^,]+\)[,]\([^,]+\)[,]\([^,]+\)[,]\W+current[)]
    ->
    force_sig_fault(\1,\2,\3)
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 03007ea4cc72..49e8ec2e9e7b 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -184,7 +184,7 @@ __do_user_fault(unsigned long addr, unsigned int fsr, unsigned int sig,
 	tsk->thread.address = addr;
 	tsk->thread.error_code = fsr;
 	tsk->thread.trap_no = 14;
-	force_sig_fault(sig, code, (void __user *)addr, current);
+	force_sig_fault(sig, code, (void __user *)addr);
 }
 
 void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)

commit 351b6825b3a9f70bab080fba67aec104ff9a41d6
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Feb 7 09:25:08 2019 -0600

    signal: Explicitly call force_sig_fault on current
    
    Update the calls of force_sig_fault that pass in a variable that is
    set to current earlier to explicitly use current.
    
    This is to make the next change that removes the task parameter
    from force_sig_fault easier to verify.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 324def0279b2..03007ea4cc72 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -184,7 +184,7 @@ __do_user_fault(unsigned long addr, unsigned int fsr, unsigned int sig,
 	tsk->thread.address = addr;
 	tsk->thread.error_code = fsr;
 	tsk->thread.trap_no = 14;
-	force_sig_fault(sig, code, (void __user *)addr, tsk);
+	force_sig_fault(sig, code, (void __user *)addr, current);
 }
 
 void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)

commit fd65cc848e3f50281eb163e2d54f1e33f28e15bf
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 5 19:39:11 2019 -0600

    signal/arm: Remove tsk parameter from __do_user_fault
    
    The __do_user_fault function is always called with tsk == current.
    Make that obvious by removing the tsk parameter.
    
    This makes it clear that __do_user_fault calls force_sig_fault
    on the current task.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 58f69fa07df9..324def0279b2 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -157,10 +157,11 @@ __do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
  * User mode accesses just cause a SIGSEGV
  */
 static void
-__do_user_fault(struct task_struct *tsk, unsigned long addr,
-		unsigned int fsr, unsigned int sig, int code,
-		struct pt_regs *regs)
+__do_user_fault(unsigned long addr, unsigned int fsr, unsigned int sig,
+		int code, struct pt_regs *regs)
 {
+	struct task_struct *tsk = current;
+
 	if (addr > TASK_SIZE)
 		harden_branch_predictor();
 
@@ -196,7 +197,7 @@ void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * have no context to handle this fault with.
 	 */
 	if (user_mode(regs))
-		__do_user_fault(tsk, addr, fsr, SIGSEGV, SEGV_MAPERR, regs);
+		__do_user_fault(addr, fsr, SIGSEGV, SEGV_MAPERR, regs);
 	else
 		__do_kernel_fault(mm, addr, fsr, regs);
 }
@@ -392,7 +393,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 			SEGV_ACCERR : SEGV_MAPERR;
 	}
 
-	__do_user_fault(tsk, addr, fsr, sig, code, regs);
+	__do_user_fault(addr, fsr, sig, code, regs);
 	return 0;
 
 no_context:

commit e2b85f709a705808a71560de60732fd49e4516a5
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Wed Oct 31 23:53:12 2018 +0100

    ARM: 8807/1: mm: Facilitate debugging CONFIG_KUSER_HELPERS disabled
    
    Some software such as perf makes unconditional use of the special
    [vectors] page which is only provided when CONFIG_KUSER_HELPERS is
    enabled in the kernel.
    
    Facilitate the debugging of such situations by printing a debug message
    to the kernel log showing the task name and the faulting address.
    
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Suggested-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index f4ea4c62c613..58f69fa07df9 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -173,6 +173,12 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 		show_regs(regs);
 	}
 #endif
+#ifndef CONFIG_KUSER_HELPERS
+	if ((sig == SIGSEGV) && ((addr & PAGE_MASK) == 0xffff0000))
+		printk_ratelimited(KERN_DEBUG
+				   "%s: CONFIG_KUSER_HELPERS disabled at 0x%08lx\n",
+				   tsk->comm, addr);
+#endif
 
 	tsk->thread.address = addr;
 	tsk->thread.error_code = fsr;

commit 3ee6a4498724a464ba9882007c4aef8ec01eba10
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jun 18 14:50:26 2018 -0500

    signal/arm: Use force_sig_fault where appropriate
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 544d2c8c2775..f4ea4c62c613 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -161,13 +161,9 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 		unsigned int fsr, unsigned int sig, int code,
 		struct pt_regs *regs)
 {
-	struct siginfo si;
-
 	if (addr > TASK_SIZE)
 		harden_branch_predictor();
 
-	clear_siginfo(&si);
-
 #ifdef CONFIG_DEBUG_USER
 	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
 	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {
@@ -181,11 +177,7 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 	tsk->thread.address = addr;
 	tsk->thread.error_code = fsr;
 	tsk->thread.trap_no = 14;
-	si.si_signo = sig;
-	si.si_errno = 0;
-	si.si_code = code;
-	si.si_addr = (void __user *)addr;
-	force_sig_info(sig, &si, tsk);
+	force_sig_fault(sig, code, (void __user *)addr, tsk);
 }
 
 void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)

commit 05e792e30ed039b5d202d31b86ba0d0491cd6f3c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 16 13:25:24 2018 -0500

    signal/arm: Push siginfo generation into arm_notify_die
    
    In arm_notify_die call force_sig_fault to let the generic
    code handle siginfo generation.
    
    This removes some boiler plate making the code easier to
    maintain in the long run.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 3232afb6fdc0..544d2c8c2775 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -554,7 +554,6 @@ asmlinkage void
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = fsr_info + fsr_fs(fsr);
-	struct siginfo info;
 
 	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
 		return;
@@ -563,12 +562,8 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		inf->name, fsr, addr);
 	show_pte(current->mm, addr);
 
-	clear_siginfo(&info);
-	info.si_signo = inf->sig;
-	info.si_errno = 0;
-	info.si_code  = inf->code;
-	info.si_addr  = (void __user *)addr;
-	arm_notify_die("", regs, &info, fsr, 0);
+	arm_notify_die("", regs, inf->sig, inf->code, (void __user *)addr,
+		       fsr, 0);
 }
 
 void __init
@@ -588,7 +583,6 @@ asmlinkage void
 do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = ifsr_info + fsr_fs(ifsr);
-	struct siginfo info;
 
 	if (!inf->fn(addr, ifsr | FSR_LNX_PF, regs))
 		return;
@@ -596,12 +590,8 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	pr_alert("Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",
 		inf->name, ifsr, addr);
 
-	clear_siginfo(&info);
-	info.si_signo = inf->sig;
-	info.si_errno = 0;
-	info.si_code  = inf->code;
-	info.si_addr  = (void __user *)addr;
-	arm_notify_die("", regs, &info, ifsr, 0);
+	arm_notify_die("", regs, inf->sig, inf->code, (void __user *)addr,
+		       ifsr, 0);
 }
 
 /*

commit 50a7ca3c6fc86955f99fc432fc8a186b968b365b
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Fri Aug 17 15:44:47 2018 -0700

    mm: convert return type of handle_mm_fault() caller to vm_fault_t
    
    Use new return type vm_fault_t for fault handler.  For now, this is just
    documenting that the function returns a VM_FAULT value rather than an
    errno.  Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Ref-> commit 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    In this patch all the caller of handle_mm_fault() are changed to return
    vm_fault_t type.
    
    Link: http://lkml.kernel.org/r/20180617084810.GA6730@jordon-HP-15-Notebook-PC
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Levin, Alexander (Sasha Levin)" <alexander.levin@verizon.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 84becc911ee3..3232afb6fdc0 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -224,12 +224,12 @@ static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
 	return vma->vm_flags & mask ? false : true;
 }
 
-static int __kprobes
+static vm_fault_t __kprobes
 __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		unsigned int flags, struct task_struct *tsk)
 {
 	struct vm_area_struct *vma;
-	int fault;
+	vm_fault_t fault;
 
 	vma = find_vma(mm, addr);
 	fault = VM_FAULT_BADMAP;
@@ -264,7 +264,8 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	struct task_struct *tsk;
 	struct mm_struct *mm;
-	int fault, sig, code;
+	int sig, code;
+	vm_fault_t fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	if (notify_page_fault(regs, fsr))

commit 311da4975894aab7a4bb94aa83f38f052d7ffda4
Merge: ca95bf62fcf5 0ac000e86703
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 6 13:49:25 2018 -0700

    Merge branch 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - Initial round of Spectre variant 1 and variant 2 fixes for 32-bit ARM
    
     - Clang support improvements
    
     - nommu updates for v8 MPU
    
     - enable ARM_MODULE_PLTS by default to avoid problems loading modules
       with larger kernels
    
     - vmlinux.lds and dma-mapping cleanups
    
    * 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (31 commits)
      ARM: spectre-v1: fix syscall entry
      ARM: spectre-v1: add array_index_mask_nospec() implementation
      ARM: spectre-v1: add speculation barrier (csdb) macros
      ARM: KVM: report support for SMCCC_ARCH_WORKAROUND_1
      ARM: KVM: Add SMCCC_ARCH_WORKAROUND_1 fast handling
      ARM: spectre-v2: KVM: invalidate icache on guest exit for Brahma B15
      ARM: KVM: invalidate icache on guest exit for Cortex-A15
      ARM: KVM: invalidate BTB on guest exit for Cortex-A12/A17
      ARM: spectre-v2: warn about incorrect context switching functions
      ARM: spectre-v2: add firmware based hardening
      ARM: spectre-v2: harden user aborts in kernel space
      ARM: spectre-v2: add Cortex A8 and A15 validation of the IBE bit
      ARM: spectre-v2: harden branch predictor on context switches
      ARM: spectre: add Kconfig symbol for CPUs vulnerable to Spectre
      ARM: bugs: add support for per-processor bug checking
      ARM: bugs: hook processor bug checking into SMP and suspend paths
      ARM: bugs: prepare processor bug infrastructure
      ARM: add more CPU part numbers for Cortex and Brahma B15 CPUs
      ARM: 8774/1: remove no-op macro VMLINUX_SYMBOL()
      ARM: 8773/1: amba: Export amba_bustype
      ...

commit f5fe12b1eaee220ce62ff9afb8b90929c396595f
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Mon May 14 14:20:21 2018 +0100

    ARM: spectre-v2: harden user aborts in kernel space
    
    In order to prevent aliasing attacks on the branch predictor,
    invalidate the BTB or instruction cache on CPUs that are known to be
    affected when taking an abort on a address that is outside of a user
    task limit:
    
    Cortex A8, A9, A12, A17, A73, A75: flush BTB.
    Cortex A15, Brahma B15: invalidate icache.
    
    If the IBE bit is not set, then there is little point to enabling the
    workaround.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Boot-tested-by: Tony Lindgren <tony@atomide.com>
    Reviewed-by: Tony Lindgren <tony@atomide.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index b75eada23d0a..3b1ba003c4f9 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -163,6 +163,9 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 {
 	struct siginfo si;
 
+	if (addr > TASK_SIZE)
+		harden_branch_predictor();
+
 #ifdef CONFIG_DEBUG_USER
 	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
 	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {

commit 3eb0f5193b497083391aa05d35210d5645211eef
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 17 15:26:37 2018 -0500

    signal: Ensure every siginfo we send has all bits initialized
    
    Call clear_siginfo to ensure every stack allocated siginfo is properly
    initialized before being passed to the signal sending functions.
    
    Note: It is not safe to depend on C initializers to initialize struct
    siginfo on the stack because C is allowed to skip holes when
    initializing a structure.
    
    The initialization of struct siginfo in tracehook_report_syscall_exit
    was moved from the helper user_single_step_siginfo into
    tracehook_report_syscall_exit itself, to make it clear that the local
    variable siginfo gets fully initialized.
    
    In a few cases the scope of struct siginfo has been reduced to make it
    clear that siginfo siginfo is not used on other paths in the function
    in which it is declared.
    
    Instances of using memset to initialize siginfo have been replaced
    with calls clear_siginfo for clarity.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index b75eada23d0a..32034543f49c 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -163,6 +163,8 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 {
 	struct siginfo si;
 
+	clear_siginfo(&si);
+
 #ifdef CONFIG_DEBUG_USER
 	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
 	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {
@@ -557,6 +559,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		inf->name, fsr, addr);
 	show_pte(current->mm, addr);
 
+	clear_siginfo(&info);
 	info.si_signo = inf->sig;
 	info.si_errno = 0;
 	info.si_code  = inf->code;
@@ -589,6 +592,7 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	pr_alert("Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",
 		inf->name, ifsr, addr);
 
+	clear_siginfo(&info);
 	info.si_signo = inf->sig;
 	info.si_errno = 0;
 	info.si_code  = inf->code;

commit c608906165355089a4de3c9133c72e81e011096c
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Fri Nov 24 23:54:22 2017 +0000

    ARM: probes: avoid adding kprobes to sensitive kernel-entry/exit code
    
    Avoid adding kprobes to any of the kernel entry/exit or startup
    assembly code, or code in the identity-mapped region.  This code does
    not conform to the standard C conventions, which means that the
    expectations of the kprobes code is not forfilled.
    
    Placing kprobes at some of these locations results in the kernel trying
    to return to userspace addresses while retaining the CPU in kernel mode.
    
    Tested-by: Naresh Kamboju <naresh.kamboju@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 42f585379e19..b75eada23d0a 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -21,7 +21,6 @@
 #include <linux/highmem.h>
 #include <linux/perf_event.h>
 
-#include <asm/exception.h>
 #include <asm/pgtable.h>
 #include <asm/system_misc.h>
 #include <asm/system_info.h>
@@ -545,7 +544,7 @@ hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *)
 /*
  * Dispatch a data abort to the relevant handler.
  */
-asmlinkage void __exception
+asmlinkage void
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = fsr_info + fsr_fs(fsr);
@@ -578,7 +577,7 @@ hook_ifault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *
 	ifsr_info[nr].name = name;
 }
 
-asmlinkage void __exception
+asmlinkage void
 do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = ifsr_info + fsr_fs(ifsr);

commit 746a272e44141af24a02f6c9b0f65f4c4598ed42
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Aug 22 11:36:17 2017 +0100

    ARM: 8692/1: mm: abort uaccess retries upon fatal signal
    
    When there's a fatal signal pending, arm's do_page_fault()
    implementation returns 0. The intent is that we'll return to the
    faulting userspace instruction, delivering the signal on the way.
    
    However, if we take a fatal signal during fixing up a uaccess, this
    results in a return to the faulting kernel instruction, which will be
    instantly retried, resulting in the same fault being taken forever. As
    the task never reaches userspace, the signal is not delivered, and the
    task is left unkillable. While the task is stuck in this state, it can
    inhibit the forward progress of the system.
    
    To avoid this, we must ensure that when a fatal signal is pending, we
    apply any necessary fixup for a faulting kernel instruction. Thus we
    will return to an error path, and it is up to that code to make forward
    progress towards delivering the fatal signal.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ff8b0aa2dfde..42f585379e19 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -315,8 +315,11 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * signal first. We do not need to release the mmap_sem because
 	 * it would already be released in __lock_page_or_retry in
 	 * mm/filemap.c. */
-	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current)) {
+		if (!user_mode(regs))
+			goto no_context;
 		return 0;
+	}
 
 	/*
 	 * Major/minor page fault accounting is only done on the

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 520c7778d330..ff8b0aa2dfde 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -17,6 +17,7 @@
 #include <linux/uaccess.h>
 #include <linux/page-flags.h>
 #include <linux/sched/signal.h>
+#include <linux/sched/debug.h>
 #include <linux/highmem.h>
 #include <linux/perf_event.h>
 

commit 3f07c0144132e4f59d88055ac8ff3e691a5fa2b8
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/signal.h>
    
    We are going to split <linux/sched/signal.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/signal.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index c2b5b9892fd1..520c7778d330 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -16,7 +16,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/page-flags.h>
-#include <linux/sched.h>
+#include <linux/sched/signal.h>
 #include <linux/highmem.h>
 #include <linux/perf_event.h>
 

commit 6d1c42d9b93e38595ad46eeb4634853ca2755c92
Merge: 0f002fddbe15 90858794c960
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 21 14:28:55 2017 -0800

    Merge tag 'extable-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    Pull exception table module split from Paul Gortmaker:
     "Final extable.h related changes.
    
      This completes the separation of exception table content from the
      module.h header file. This is achieved with the final commit that
      removes the one line back compatible change that sourced extable.h
      into the module.h file.
    
      The commits are unchanged since January, with the exception of a
      couple Acks that came in for the last two commits a bit later. The
      changes have been in linux-next for quite some time[1] and have got
      widespread arch coverage via toolchains I have and also from
      additional ones the kbuild bot has.
    
      Maintaners of the various arch were Cc'd during the postings to
      lkml[2] and informed that the intention was to take the remaining arch
      specific changes and lump them together with the final two non-arch
      specific changes and submit for this merge window.
    
      The ia64 diffstat stands out and probably warrants a mention. In an
      earlier review, Al Viro made a valid comment that the original header
      separation of content left something to be desired, and that it get
      fixed as a part of this change, hence the larger diffstat"
    
    * tag 'extable-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (21 commits)
      module.h: remove extable.h include now users have migrated
      core: migrate exception table users off module.h and onto extable.h
      cris: migrate exception table users off module.h and onto extable.h
      hexagon: migrate exception table users off module.h and onto extable.h
      microblaze: migrate exception table users off module.h and onto extable.h
      unicore32: migrate exception table users off module.h and onto extable.h
      score: migrate exception table users off module.h and onto extable.h
      metag: migrate exception table users off module.h and onto extable.h
      arc: migrate exception table users off module.h and onto extable.h
      nios2: migrate exception table users off module.h and onto extable.h
      sparc: migrate exception table users onto extable.h
      openrisc: migrate exception table users off module.h and onto extable.h
      frv: migrate exception table users off module.h and onto extable.h
      sh: migrate exception table users off module.h and onto extable.h
      xtensa: migrate exception table users off module.h and onto extable.h
      mn10300: migrate exception table users off module.h and onto extable.h
      alpha: migrate exception table users off module.h and onto extable.h
      arm: migrate exception table users off module.h and onto extable.h
      m32r: migrate exception table users off module.h and onto extable.h
      ia64: ensure exception table search users include extable.h
      ...

commit 97a98ae5b8acf08d07d972c087b2def060bc9b73
Author: Alexander Sverdlin <alexander.sverdlin@gmail.com>
Date:   Tue Jan 17 21:10:11 2017 +0100

    ARM: 8642/1: LPAE: catch pending imprecise abort on unmask
    
    Asynchronous external abort is coded differently in DFSR with LPAE enabled.
    
    Fixes: 9254970c "ARM: 8447/1: catch pending imprecise abort on unmask".
    Signed-off-by: Alexander Sverdlin <alexander.sverdlin@nokia.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 3a2e678b8d30..0122ad1a6027 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -610,9 +610,9 @@ static int __init early_abort_handler(unsigned long addr, unsigned int fsr,
 
 void __init early_abt_enable(void)
 {
-	fsr_info[22].fn = early_abort_handler;
+	fsr_info[FSR_FS_AEA].fn = early_abort_handler;
 	local_abt_enable();
-	fsr_info[22].fn = do_bad;
+	fsr_info[FSR_FS_AEA].fn = do_bad;
 }
 
 #ifndef CONFIG_ARM_LPAE

commit 0ea9365a51f9993d4b62fe10e523988d3feb4ad7
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sat Jul 23 14:01:45 2016 -0400

    arm: migrate exception table users off module.h and onto extable.h
    
    These files were only including module.h for exception table
    related functions.  We've now separated that content out into its
    own file "extable.h" so now move over to that and avoid all the
    extra header content in module.h that we don't really need to compile
    these files.
    
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 3a2e678b8d30..94de590db99e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -8,7 +8,7 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
-#include <linux/module.h>
+#include <linux/extable.h>
 #include <linux/signal.h>
 #include <linux/mm.h>
 #include <linux/hardirq.h>

commit dcddffd41d3f1d3bdcc1dce3f1cd142779b6d4c1
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:25:18 2016 -0700

    mm: do not pass mm_struct into handle_mm_fault
    
    We always have vma->vm_mm around.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-8-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ad5841856007..3a2e678b8d30 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -243,7 +243,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		goto out;
 	}
 
-	return handle_mm_fault(mm, vma, addr & PAGE_MASK, flags);
+	return handle_mm_fault(vma, addr & PAGE_MASK, flags);
 
 check_stack:
 	/* Don't allow expansion below FIRST_USER_ADDRESS */

commit 0e8fb9312fbaf1a687dd731b04d8ab3121c4ff5a
Author: Jan Kara <jack@suse.cz>
Date:   Thu Mar 17 14:19:55 2016 -0700

    mm: remove VM_FAULT_MINOR
    
    The define has a comment from Nick Piggin from 2007:
    
     /* For backwards compat. Remove me quickly. */
    
    I guess 9 years should not be too hurried sense of 'quickly' even for
    kernel measures.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index daafcf121ce0..ad5841856007 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -346,7 +346,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	up_read(&mm->mmap_sem);
 
 	/*
-	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
+	 * Handle the "normal" case first - VM_FAULT_MAJOR
 	 */
 	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP | VM_FAULT_BADACCESS))))
 		return 0;

commit 9254970cbbf542a0085e491810f0144a27885702
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Mon Oct 19 13:38:09 2015 +0100

    ARM: 8447/1: catch pending imprecise abort on unmask
    
    Install a non-faulting handler just before unmasking imprecise aborts
    and switch back to the regular one after unmasking is done.
    
    This catches any pending imprecise abort that the firmware/bootloader
    may have left behind that would normally crash the kernel at that point.
    As there are apparently a lot of bootlaoders out there that do such a
    thing it makes sense to handle it in the common startup code.
    
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Tested-by: Tyler Baker <tyler.baker@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 0d629b8f973f..daafcf121ce0 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -593,6 +593,28 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	arm_notify_die("", regs, &info, ifsr, 0);
 }
 
+/*
+ * Abort handler to be used only during first unmasking of asynchronous aborts
+ * on the boot CPU. This makes sure that the machine will not die if the
+ * firmware/bootloader left an imprecise abort pending for us to trip over.
+ */
+static int __init early_abort_handler(unsigned long addr, unsigned int fsr,
+				      struct pt_regs *regs)
+{
+	pr_warn("Hit pending asynchronous external abort (FSR=0x%08x) during "
+		"first unmask, this is most likely caused by a "
+		"firmware/bootloader bug.\n", fsr);
+
+	return 0;
+}
+
+void __init early_abt_enable(void)
+{
+	fsr_info[22].fn = early_abort_handler;
+	local_abt_enable();
+	fsr_info[22].fn = do_bad;
+}
+
 #ifndef CONFIG_ARM_LPAE
 static int __init exceptions_init(void)
 {

commit 70ffdb9393a7264a069265edded729078dcf0425
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Mon May 11 17:52:11 2015 +0200

    mm/fault, arch: Use pagefault_disable() to check for disabled pagefaults in the handler
    
    Introduce faulthandler_disabled() and use it to check for irq context and
    disabled pagefaults (via pagefault_disable()) in the pagefault handlers.
    
    Please note that we keep the in_atomic() checks in place - to detect
    whether in irq context (in which case preemption is always properly
    disabled).
    
    In contrast, preempt_disable() should never be used to disable pagefaults.
    With !CONFIG_PREEMPT_COUNT, preempt_disable() doesn't modify the preempt
    counter, and therefore the result of in_atomic() differs.
    We validate that condition by using might_fault() checks when calling
    might_sleep().
    
    Therefore, add a comment to faulthandler_disabled(), describing why this
    is needed.
    
    faulthandler_disabled() and pagefault_disable() are defined in
    linux/uaccess.h, so let's properly add that include to all relevant files.
    
    This patch is based on a patch from Thomas Gleixner.
    
    Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David.Laight@ACULAB.COM
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: airlied@linux.ie
    Cc: akpm@linux-foundation.org
    Cc: benh@kernel.crashing.org
    Cc: bigeasy@linutronix.de
    Cc: borntraeger@de.ibm.com
    Cc: daniel.vetter@intel.com
    Cc: heiko.carstens@de.ibm.com
    Cc: herbert@gondor.apana.org.au
    Cc: hocko@suse.cz
    Cc: hughd@google.com
    Cc: mst@redhat.com
    Cc: paulus@samba.org
    Cc: ralf@linux-mips.org
    Cc: schwidefsky@de.ibm.com
    Cc: yang.shi@windriver.com
    Link: http://lkml.kernel.org/r/1431359540-32227-7-git-send-email-dahi@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 6333d9c17875..0d629b8f973f 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -276,7 +276,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
 	 */
-	if (in_atomic() || !mm)
+	if (faulthandler_disabled() || !mm)
 		goto no_context;
 
 	if (user_mode(regs))

commit 6d021b724481fbb908eb29384898deb9f00dfe70
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Mar 10 19:40:55 2015 +0000

    ARM: dump pgd, pmd and pte states on unhandled data abort faults
    
    It can be useful to dump the page table entries when an unhandled data
    abort fault occurs.  This can aid debugging of these situations, for
    example, a STREX instruction causing an external abort on non-linefetch
    fault, as has been reported recently.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index a982dc3190df..6333d9c17875 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -552,6 +552,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 
 	pr_alert("Unhandled fault: %s (0x%03x) at 0x%08lx\n",
 		inf->name, fsr, addr);
+	show_pte(current->mm, addr);
 
 	info.si_signo = inf->sig;
 	info.si_errno = 0;

commit 4ed89f2228061422ce5f62545fd0b6f6648bd2cc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 28 11:26:42 2014 +0000

    ARM: convert printk(KERN_* to pr_*
    
    Convert many (but not all) printk(KERN_* to pr_* to simplify the code.
    We take the opportunity to join some printk lines together so we don't
    split the message across several lines, and we also add a few levels
    to some messages which were previously missing them.
    
    Tested-by: Andrew Lunn <andrew@lunn.ch>
    Tested-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index eb8830a4c5ed..a982dc3190df 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -63,9 +63,9 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 	if (!mm)
 		mm = &init_mm;
 
-	printk(KERN_ALERT "pgd = %p\n", mm->pgd);
+	pr_alert("pgd = %p\n", mm->pgd);
 	pgd = pgd_offset(mm, addr);
-	printk(KERN_ALERT "[%08lx] *pgd=%08llx",
+	pr_alert("[%08lx] *pgd=%08llx",
 			addr, (long long)pgd_val(*pgd));
 
 	do {
@@ -77,31 +77,31 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 
 		if (pgd_bad(*pgd)) {
-			printk("(bad)");
+			pr_cont("(bad)");
 			break;
 		}
 
 		pud = pud_offset(pgd, addr);
 		if (PTRS_PER_PUD != 1)
-			printk(", *pud=%08llx", (long long)pud_val(*pud));
+			pr_cont(", *pud=%08llx", (long long)pud_val(*pud));
 
 		if (pud_none(*pud))
 			break;
 
 		if (pud_bad(*pud)) {
-			printk("(bad)");
+			pr_cont("(bad)");
 			break;
 		}
 
 		pmd = pmd_offset(pud, addr);
 		if (PTRS_PER_PMD != 1)
-			printk(", *pmd=%08llx", (long long)pmd_val(*pmd));
+			pr_cont(", *pmd=%08llx", (long long)pmd_val(*pmd));
 
 		if (pmd_none(*pmd))
 			break;
 
 		if (pmd_bad(*pmd)) {
-			printk("(bad)");
+			pr_cont("(bad)");
 			break;
 		}
 
@@ -110,15 +110,15 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 
 		pte = pte_offset_map(pmd, addr);
-		printk(", *pte=%08llx", (long long)pte_val(*pte));
+		pr_cont(", *pte=%08llx", (long long)pte_val(*pte));
 #ifndef CONFIG_ARM_LPAE
-		printk(", *ppte=%08llx",
+		pr_cont(", *ppte=%08llx",
 		       (long long)pte_val(pte[PTE_HWTABLE_PTRS]));
 #endif
 		pte_unmap(pte);
 	} while(0);
 
-	printk("\n");
+	pr_cont("\n");
 }
 #else					/* CONFIG_MMU */
 void show_pte(struct mm_struct *mm, unsigned long addr)
@@ -142,10 +142,9 @@ __do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * No handler, we'll have to terminate things with extreme prejudice.
 	 */
 	bust_spinlocks(1);
-	printk(KERN_ALERT
-		"Unable to handle kernel %s at virtual address %08lx\n",
-		(addr < PAGE_SIZE) ? "NULL pointer dereference" :
-		"paging request", addr);
+	pr_alert("Unable to handle kernel %s at virtual address %08lx\n",
+		 (addr < PAGE_SIZE) ? "NULL pointer dereference" :
+		 "paging request", addr);
 
 	show_pte(mm, addr);
 	die("Oops", regs, fsr);
@@ -551,7 +550,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
 		return;
 
-	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
+	pr_alert("Unhandled fault: %s (0x%03x) at 0x%08lx\n",
 		inf->name, fsr, addr);
 
 	info.si_signo = inf->sig;
@@ -583,7 +582,7 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	if (!inf->fn(addr, ifsr | FSR_LNX_PF, regs))
 		return;
 
-	printk(KERN_ALERT "Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",
+	pr_alert("Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",
 		inf->name, ifsr, addr);
 
 	info.si_signo = inf->sig;

commit 759496ba6407c6994d6a5ce3a5e74937d7816208
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Sep 12 15:13:39 2013 -0700

    arch: mm: pass userspace fault flag to generic fault handler
    
    Unlike global OOM handling, memory cgroup code will invoke the OOM killer
    in any OOM situation because it has no way of telling faults occuring in
    kernel context - which could be handled more gracefully - from
    user-triggered faults.
    
    Pass a flag that identifies faults originating in user space from the
    architecture-specific fault handlers to generic code so that memcg OOM
    handling can be improved.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: azurIt <azurit@pobox.sk>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 217bcbfde42e..eb8830a4c5ed 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -261,9 +261,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
-	int write = fsr & FSR_WRITE;
-	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |
-				(write ? FAULT_FLAG_WRITE : 0);
+	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	if (notify_page_fault(regs, fsr))
 		return 0;
@@ -282,6 +280,11 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (in_atomic() || !mm)
 		goto no_context;
 
+	if (user_mode(regs))
+		flags |= FAULT_FLAG_USER;
+	if (fsr & FSR_WRITE)
+		flags |= FAULT_FLAG_WRITE;
+
 	/*
 	 * As per x86, we may deadlock here.  However, since the kernel only
 	 * validly references user space from well defined areas of the code,

commit 871341023c771ad233620b7a1fb3d9c7031c4e5c
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Sep 12 15:13:38 2013 -0700

    arch: mm: do not invoke OOM killer on kernel fault OOM
    
    Kernel faults are expected to handle OOM conditions gracefully (gup,
    uaccess etc.), so they should never invoke the OOM killer.  Reserve this
    for faults triggered in user context when it is the only option.
    
    Most architectures already do this, fix up the remaining few.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: azurIt <azurit@pobox.sk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index c97f7940cb95..217bcbfde42e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -349,6 +349,13 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP | VM_FAULT_BADACCESS))))
 		return 0;
 
+	/*
+	 * If we are in kernel mode at this point, we
+	 * have no context to handle this fault with.
+	 */
+	if (!user_mode(regs))
+		goto no_context;
+
 	if (fault & VM_FAULT_OOM) {
 		/*
 		 * We ran out of memory, call the OOM killer, and return to
@@ -359,13 +366,6 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		return 0;
 	}
 
-	/*
-	 * If we are in kernel mode at this point, we
-	 * have no context to handle this fault with.
-	 */
-	if (!user_mode(regs))
-		goto no_context;
-
 	if (fault & VM_FAULT_SIGBUS) {
 		/*
 		 * We had some memory, but were unable to

commit 809e660f438fc5a69bf57630a85bcd8112263f37
Author: Steven Capper <steve.capper@linaro.org>
Date:   Tue Jun 25 08:45:51 2013 +0100

    ARM: 7775/1: mm: Remove do_sect_fault from LPAE code
    
    For LPAE, do_sect_fault used to be invoked as the second level access
    flag handler. When transparent huge pages were introduced for LPAE,
    do_page_fault was used instead.
    
    Unfortunately, do_sect_fault remains defined but not used for LPAE code
    resulting in a compile warning.
    
    This patch surrounds do_sect_fault with #ifndef CONFIG_ARM_LPAE to fix
    this warning.
    
    Signed-off-by: Steve Capper <steve.capper@linaro.org>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 5dbf13f954f6..c97f7940cb95 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -491,12 +491,14 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
  * Some section permission faults need to be handled gracefully.
  * They can happen due to a __{get,put}_user during an oops.
  */
+#ifndef CONFIG_ARM_LPAE
 static int
 do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	do_bad_area(addr, fsr, regs);
 	return 0;
 }
+#endif /* CONFIG_ARM_LPAE */
 
 /*
  * This abort handler always returns "fault".

commit 45cac65b0fcd287ebb877b141d40ba9bbe8e5da7
Author: Shaohua Li <shli@kernel.org>
Date:   Mon Oct 8 16:32:19 2012 -0700

    readahead: fault retry breaks mmap file read random detection
    
    .fault now can retry.  The retry can break state machine of .fault.  In
    filemap_fault, if page is miss, ra->mmap_miss is increased.  In the second
    try, since the page is in page cache now, ra->mmap_miss is decreased.  And
    these are done in one fault, so we can't detect random mmap file access.
    
    Add a new flag to indicate .fault is tried once.  In the second try, skip
    ra->mmap_miss decreasing.  The filemap_fault state machine is ok with it.
    
    I only tested x86, didn't test other archs, but looks the change for other
    archs is obvious, but who knows :)
    
    Signed-off-by: Shaohua Li <shaohua.li@fusionio.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index c3bd83450227..5dbf13f954f6 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -336,6 +336,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
 			* of starvation. */
 			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+			flags |= FAULT_FLAG_TRIED;
 			goto retry;
 		}
 	}

commit 4ab1056766a4e49f6b9ef324313dd1583f8f8f4e
Merge: 4175160b065e 4cdfc2ec72e9
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 21 15:15:33 2012 +0100

    Merge branch 'v3-removal' into for-linus
    
    Conflicts:
            arch/arm/boot/compressed/head.S

commit 9b61a4d1b2064dbd0c9e61754305ac852170509f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed May 16 15:19:20 2012 +0100

    ARM: prevent VM_GROWSDOWN mmaps extending below FIRST_USER_ADDRESS
    
    Cc: <stable@vger.kernel.org>
    Reported-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index f07467533365..5bb48356d217 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -247,7 +247,9 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	return handle_mm_fault(mm, vma, addr & PAGE_MASK, flags);
 
 check_stack:
-	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
+	/* Don't allow expansion below FIRST_USER_ADDRESS */
+	if (vma->vm_flags & VM_GROWSDOWN &&
+	    addr >= FIRST_USER_ADDRESS && !expand_stack(vma, addr))
 		goto good_area;
 out:
 	return fault;

commit 357c9c1f07d4546bc3fbc0fd1044d96b114d14ed
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri May 4 12:04:26 2012 +0100

    ARM: Remove support for ARMv3 ARM610 and ARM710 CPUs
    
    This patch removes support for ARMv3 CPUs, which haven't worked properly
    for quite some time (see the FIXME comment in arch/arm/mm/fault.c).  The
    only V3 parts left is the cache model for ARMv3, which is needed for some
    odd reason by ARM740T CPUs, and being able to build with -march=armv3,
    which is required for the RiscPC platform due to its bus structure.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Jean-Christophe PLAGNIOL-VILLARD <plagnioj@jcrosoft.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index f07467533365..84aec37404bc 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -430,9 +430,6 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 
 	index = pgd_index(addr);
 
-	/*
-	 * FIXME: CP15 C1 is write only on ARMv3 architectures.
-	 */
 	pgd = cpu_get_pgd() + index;
 	pgd_k = init_mm.pgd + index;
 

commit dff2aa7af8c96a11f75d858859f0e0c78b193d12
Author: Kautuk Consul <consul.kautuk@gmail.com>
Date:   Mon Apr 2 18:19:49 2012 +0100

    ARM: 7368/1: fault.c: correct how the tsk->[maj|min]_flt gets incremented
    
    commit 8878a539ff19a43cf3729e7562cd528f490246ae was done by me
    to make the page fault handler retryable as well as interruptible.
    
    Due to this commit, there is a mistake in the way in which
    tsk->[maj|min]_flt counter gets incremented for VM_FAULT_ERROR:
    If VM_FAULT_ERROR is returned in the fault flags by handle_mm_fault,
    then either maj_flt or min_flt will get incremented. This is wrong
    as in the case of a VM_FAULT_ERROR we need to be skip ahead to the
    error handling code in do_page_fault.
    
    Added a check after the call to __do_page_fault() to check for
    (fault & VM_FAULT_ERROR).
    
    Signed-off-by: Kautuk Consul <consul.kautuk@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 9055b5a84ec5..f07467533365 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -320,7 +320,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 */
 
 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
-	if (flags & FAULT_FLAG_ALLOW_RETRY) {
+	if (!(fault & VM_FAULT_ERROR) && flags & FAULT_FLAG_ALLOW_RETRY) {
 		if (fault & VM_FAULT_MAJOR) {
 			tsk->maj_flt++;
 			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,

commit 12679a2d7e3bfbdc7586e3e86d1ca90c46659363
Merge: 1c036588772d b0df89868006
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 16:53:48 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull more ARM updates from Russell King.
    
    This got a fair number of conflicts with the <asm/system.h> split, but
    also with some other sparse-irq and header file include cleanups.  They
    all looked pretty trivial, though.
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (59 commits)
      ARM: fix Kconfig warning for HAVE_BPF_JIT
      ARM: 7361/1: provide XIP_VIRT_ADDR for no-MMU builds
      ARM: 7349/1: integrator: convert to sparse irqs
      ARM: 7259/3: net: JIT compiler for packet filters
      ARM: 7334/1: add jump label support
      ARM: 7333/2: jump label: detect %c support for ARM
      ARM: 7338/1: add support for early console output via semihosting
      ARM: use set_current_blocked() and block_sigmask()
      ARM: exec: remove redundant set_fs(USER_DS)
      ARM: 7332/1: extract out code patch function from kprobes
      ARM: 7331/1: extract out insn generation code from ftrace
      ARM: 7330/1: ftrace: use canonical Thumb-2 wide instruction format
      ARM: 7351/1: ftrace: remove useless memory checks
      ARM: 7316/1: kexec: EOI active and mask all interrupts in kexec crash path
      ARM: Versatile Express: add NO_IOPORT
      ARM: get rid of asm/irq.h in asm/prom.h
      ARM: 7319/1: Print debug info for SIGBUS in user faults
      ARM: 7318/1: gic: refactor irq_start assignment
      ARM: 7317/1: irq: avoid NULL check in for_each_irq_desc loop
      ARM: 7315/1: perf: add support for the Cortex-A7 PMU
      ...

commit 9f97da78bf018206fb623cd351d454af2f105fe0
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:01 2012 +0100

    Disintegrate asm/system.h for ARM
    
    Disintegrate asm/system.h for ARM.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Russell King <linux@arm.linux.org.uk>
    cc: linux-arm-kernel@lists.infradead.org

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bb7eac381a8e..5bdff5c3e6cb 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -21,8 +21,9 @@
 #include <linux/perf_event.h>
 
 #include <asm/exception.h>
-#include <asm/system.h>
 #include <asm/pgtable.h>
+#include <asm/system_misc.h>
+#include <asm/system_info.h>
 #include <asm/tlbflush.h>
 
 #include "fault.h"

commit f5274c2d0d8d91076af8605187d762dfa0b92825
Author: Javi Merino <javi.merino@arm.com>
Date:   Mon Feb 6 15:45:36 2012 +0100

    ARM: 7319/1: Print debug info for SIGBUS in user faults
    
    Print debug information on user faults for SIGBUS if user_debug = 16
    in the kernel command line.
    
    Reference: <1327333344-26340-1-git-send-email-javi.merino@arm.com>
    
    Signed-off-by: Javi Merino <javi.merino@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bb7eac381a8e..40c43a94ba72 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -164,7 +164,8 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 	struct siginfo si;
 
 #ifdef CONFIG_DEBUG_USER
-	if (user_debug & UDBG_SEGV) {
+	if (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||
+	    ((user_debug & UDBG_BUS)  && (sig == SIGBUS))) {
 		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
 		       tsk->comm, sig, addr, fsr);
 		show_pte(tsk->mm, addr);

commit 2e0e943436912ffe0848ece58167edfe754edb96
Merge: a32737e1ca65 ef3a0bf5bfad
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jan 5 13:24:33 2012 +0000

    Merge branch 'devel-stable' into for-linus
    
    Conflicts:
            arch/arm/kernel/setup.c
            arch/arm/mach-shmobile/board-kota2.c

commit f7b8156d150f7383b42622a9219b230b36435b4a
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue Nov 22 17:30:31 2011 +0000

    ARM: LPAE: Add fault handling support
    
    The DFSR and IFSR register format is different when LPAE is enabled. In
    addition, DFSR and IFSR have similar definitions for the fault type.
    This modifies the fault code to correctly handle the new format.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 2a0271677725..eb5520fc755f 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -110,8 +110,10 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 		pte = pte_offset_map(pmd, addr);
 		printk(", *pte=%08llx", (long long)pte_val(*pte));
+#ifndef CONFIG_ARM_LPAE
 		printk(", *ppte=%08llx",
 		       (long long)pte_val(pte[PTE_HWTABLE_PTRS]));
+#endif
 		pte_unmap(pte);
 	} while(0);
 
@@ -428,6 +430,12 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	pmd = pmd_offset(pud, addr);
 	pmd_k = pmd_offset(pud_k, addr);
 
+#ifdef CONFIG_ARM_LPAE
+	/*
+	 * Only one hardware entry per PMD with LPAE.
+	 */
+	index = 0;
+#else
 	/*
 	 * On ARM one Linux PGD entry contains two hardware entries (see page
 	 * tables layout in pgtable.h). We normally guarantee that we always
@@ -437,6 +445,7 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	 * for the first of pair.
 	 */
 	index = (addr >> SECTION_SHIFT) & 1;
+#endif
 	if (pmd_none(pmd_k[index]))
 		goto bad_area;
 
@@ -484,7 +493,11 @@ struct fsr_info {
 };
 
 /* FSR definition */
+#ifdef CONFIG_ARM_LPAE
+#include "fsr-3level.c"
+#else
 #include "fsr-2level.c"
+#endif
 
 void __init
 hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
@@ -553,6 +566,7 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	arm_notify_die("", regs, &info, ifsr, 0);
 }
 
+#ifndef CONFIG_ARM_LPAE
 static int __init exceptions_init(void)
 {
 	if (cpu_architecture() >= CPU_ARCH_ARMv6) {
@@ -575,3 +589,4 @@ static int __init exceptions_init(void)
 }
 
 arch_initcall(exceptions_init);
+#endif

commit 136848d4ca9cf6f08edf6e50cb9bbe19de55c32a
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue Nov 22 17:30:28 2011 +0000

    ARM: LPAE: Move the FSR definitions to separate files
    
    The FSR structure is different with LPAE and this patch moves the
    classic MMU specific definition to a separate fsr-2level.c file that is
    included in fault.c. It also moves the fsr_fs and FSR bits to the
    fault.h file.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index aa33949fef60..2a0271677725 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -27,19 +27,6 @@
 
 #include "fault.h"
 
-/*
- * Fault status register encodings.  We steal bit 31 for our own purposes.
- */
-#define FSR_LNX_PF		(1 << 31)
-#define FSR_WRITE		(1 << 11)
-#define FSR_FS4			(1 << 10)
-#define FSR_FS3_0		(15)
-
-static inline int fsr_fs(unsigned int fsr)
-{
-	return (fsr & FSR_FS3_0) | (fsr & FSR_FS4) >> 6;
-}
-
 #ifdef CONFIG_MMU
 
 #ifdef CONFIG_KPROBES
@@ -489,55 +476,16 @@ do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	return 1;
 }
 
-static struct fsr_info {
+struct fsr_info {
 	int	(*fn)(unsigned long addr, unsigned int fsr, struct pt_regs *regs);
 	int	sig;
 	int	code;
 	const char *name;
-} fsr_info[] = {
-	/*
-	 * The following are the standard ARMv3 and ARMv4 aborts.  ARMv5
-	 * defines these to be "precise" aborts.
-	 */
-	{ do_bad,		SIGSEGV, 0,		"vector exception"		   },
-	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
-	{ do_bad,		SIGKILL, 0,		"terminal exception"		   },
-	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
-	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
-	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section domain fault"		   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page domain fault"		   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
-	{ do_sect_fault,	SIGSEGV, SEGV_ACCERR,	"section permission fault"	   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
-	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	"page permission fault"		   },
-	/*
-	 * The following are "imprecise" aborts, which are signalled by bit
-	 * 10 of the FSR, and may not be recoverable.  These are only
-	 * supported if the CPU abort handler supports bit 10.
-	 */
-	{ do_bad,		SIGBUS,  0,		"unknown 16"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 17"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 18"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 19"			   },
-	{ do_bad,		SIGBUS,  0,		"lock abort"			   }, /* xscale */
-	{ do_bad,		SIGBUS,  0,		"unknown 21"			   },
-	{ do_bad,		SIGBUS,  BUS_OBJERR,	"imprecise external abort"	   }, /* xscale */
-	{ do_bad,		SIGBUS,  0,		"unknown 23"			   },
-	{ do_bad,		SIGBUS,  0,		"dcache parity error"		   }, /* xscale */
-	{ do_bad,		SIGBUS,  0,		"unknown 25"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 26"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 27"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 28"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 29"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 30"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 31"			   }
 };
 
+/* FSR definition */
+#include "fsr-2level.c"
+
 void __init
 hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
 		int sig, int code, const char *name)
@@ -573,42 +521,6 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	arm_notify_die("", regs, &info, fsr, 0);
 }
 
-
-static struct fsr_info ifsr_info[] = {
-	{ do_bad,		SIGBUS,  0,		"unknown 0"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 1"			   },
-	{ do_bad,		SIGBUS,  0,		"debug event"			   },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section access flag fault"	   },
-	{ do_bad,		SIGBUS,  0,		"unknown 4"			   },
-	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page access flag fault"	   },
-	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section domain fault"		   },
-	{ do_bad,		SIGBUS,  0,		"unknown 10"			   },
-	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page domain fault"		   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
-	{ do_sect_fault,	SIGSEGV, SEGV_ACCERR,	"section permission fault"	   },
-	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
-	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	"page permission fault"		   },
-	{ do_bad,		SIGBUS,  0,		"unknown 16"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 17"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 18"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 19"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 20"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 21"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 22"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 23"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 24"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 25"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 26"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 27"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 28"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 29"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 30"			   },
-	{ do_bad,		SIGBUS,  0,		"unknown 31"			   },
-};
-
 void __init
 hook_ifault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
 		 int sig, int code, const char *name)

commit 8878a539ff19a43cf3729e7562cd528f490246ae
Author: Kautuk Consul <consul.kautuk@gmail.com>
Date:   Sun Nov 27 17:49:50 2011 +0100

    ARM: 7178/1: fault.c: Port OOM changes into do_page_fault
    
    Commit d065bd810b6deb67d4897a14bfe21f8eb526ba99
    (mm: retry page fault when blocking on disk transfer) and
    commit 37b23e0525d393d48a7d59f870b3bc061a30ccdb
    (x86,mm: make pagefault killable)
    
    The above commits introduced changes into the x86 pagefault handler
    for making the page fault handler retryable as well as killable.
    
    These changes reduce the mmap_sem hold time, which is crucial
    during OOM killer invocation.
    
    Port these changes to ARM.
    
    Without these changes, my ARM board encounters many hang and livelock
    scenarios.
    After applying this patch, OOM feature performance improves according to
    my testing.
    
    Signed-off-by: Kautuk Consul <consul.kautuk@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index aa33949fef60..4aabeaec25df 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -231,7 +231,7 @@ static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
 
 static int __kprobes
 __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
-		struct task_struct *tsk)
+		unsigned int flags, struct task_struct *tsk)
 {
 	struct vm_area_struct *vma;
 	int fault;
@@ -253,18 +253,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		goto out;
 	}
 
-	/*
-	 * If for any reason at all we couldn't handle the fault, make
-	 * sure we exit gracefully rather than endlessly redo the fault.
-	 */
-	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, (fsr & FSR_WRITE) ? FAULT_FLAG_WRITE : 0);
-	if (unlikely(fault & VM_FAULT_ERROR))
-		return fault;
-	if (fault & VM_FAULT_MAJOR)
-		tsk->maj_flt++;
-	else
-		tsk->min_flt++;
-	return fault;
+	return handle_mm_fault(mm, vma, addr & PAGE_MASK, flags);
 
 check_stack:
 	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
@@ -279,6 +268,9 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
+	int write = fsr & FSR_WRITE;
+	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |
+				(write ? FAULT_FLAG_WRITE : 0);
 
 	if (notify_page_fault(regs, fsr))
 		return 0;
@@ -305,6 +297,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!down_read_trylock(&mm->mmap_sem)) {
 		if (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))
 			goto no_context;
+retry:
 		down_read(&mm->mmap_sem);
 	} else {
 		/*
@@ -320,14 +313,41 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 #endif
 	}
 
-	fault = __do_page_fault(mm, addr, fsr, tsk);
-	up_read(&mm->mmap_sem);
+	fault = __do_page_fault(mm, addr, fsr, flags, tsk);
+
+	/* If we need to retry but a fatal signal is pending, handle the
+	 * signal first. We do not need to release the mmap_sem because
+	 * it would already be released in __lock_page_or_retry in
+	 * mm/filemap.c. */
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+		return 0;
+
+	/*
+	 * Major/minor page fault accounting is only done on the
+	 * initial attempt. If we go through a retry, it is extremely
+	 * likely that the page will be found in page cache at that point.
+	 */
 
 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
-	if (fault & VM_FAULT_MAJOR)
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, addr);
-	else if (fault & VM_FAULT_MINOR)
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, addr);
+	if (flags & FAULT_FLAG_ALLOW_RETRY) {
+		if (fault & VM_FAULT_MAJOR) {
+			tsk->maj_flt++;
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,
+					regs, addr);
+		} else {
+			tsk->min_flt++;
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,
+					regs, addr);
+		}
+		if (fault & VM_FAULT_RETRY) {
+			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
+			* of starvation. */
+			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+			goto retry;
+		}
+	}
+
+	up_read(&mm->mmap_sem);
 
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR

commit 5a567d78c437e3be1c512734cdfe64b4ae6b82d7
Author: Jamie Iles <jamie@jamieiles.com>
Date:   Sat Oct 8 11:20:42 2011 +0100

    ARM: 7115/4: move __exception and friends to asm/exception.h
    
    The definition of __exception_irq_entry for
    CONFIG_FUNCTION_GRAPH_TRACER=y needs linux/ftrace.h, but this creates a
    circular dependency with it's current home in asm/system.h. Create
    asm/exception.h and update all current users.
    
    v4:     - rebase to rmk/for-next
    v3:     - remove redundant includes of linux/ftrace.h
    v2:     - document the usage restricitions of __exception*
    
    Cc: Zoltan Devai <zdevai@gmail.com>
    Signed-off-by: Jamie Iles <jamie@jamieiles.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 3b5ea68acbb8..aa33949fef60 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -20,6 +20,7 @@
 #include <linux/highmem.h>
 #include <linux/perf_event.h>
 
+#include <asm/exception.h>
 #include <asm/system.h>
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>

commit b6844e8f64920cdee620157252169ba63afb0c89
Merge: 2f175074e681 3ad55155b222
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jul 24 10:20:54 2011 -0700

    Merge branch 'for-linus' of master.kernel.org:/home/rmk/linux-2.6-arm
    
    * 'for-linus' of master.kernel.org:/home/rmk/linux-2.6-arm: (237 commits)
      ARM: 7004/1: fix traps.h compile warnings
      ARM: 6998/2: kernel: use proper memory barriers for bitops
      ARM: 6997/1: ep93xx: increase NR_BANKS to 16 for support of 128MB RAM
      ARM: Fix build errors caused by adding generic macros
      ARM: CPU hotplug: ensure we migrate all IRQs off a downed CPU
      ARM: CPU hotplug: pass in proper affinity mask on IRQ migration
      ARM: GIC: avoid routing interrupts to offline CPUs
      ARM: CPU hotplug: fix abuse of irqdesc->node
      ARM: 6981/2: mmci: adjust calculation of f_min
      ARM: 7000/1: LPAE: Use long long printk format for displaying the pud
      ARM: 6999/1: head, zImage: Always Enter the kernel in ARM state
      ARM: btc: avoid invalidating the branch target cache on kernel TLB maintanence
      ARM: ARM_DMA_ZONE_SIZE is no more
      ARM: mach-shark: move ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-sa1100: move ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-realview: move from ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-pxa: move from ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-ixp4xx: move from ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-h720x: move from ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ARM: mach-davinci: move from ARM_DMA_ZONE_SIZE to mdesc->dma_zone_size
      ...

commit 06f365acef5ca54fd5708a0d853c4a89609536f1
Merge: 4348810a241a 022ae537b23c 30891c90d811 e7d59db91a34 e2f81844efa2 4cde7e0dca98 7f294e4983b6 29cb3cd208dd 19dad35fe0f1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 22 23:08:48 2011 +0100

    Merge branches 'btc', 'dma', 'entry', 'fixes', 'linker-layout', 'misc', 'mmci', 'suspend' and 'vfp' into for-next

commit 140d5dc1d7d86d766951b7a9aef5b66f1dfdfae2
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Wed Jul 13 16:32:58 2011 +0100

    ARM: 7000/1: LPAE: Use long long printk format for displaying the pud
    
    Currently using just long but this is not enough for the LPAE format
    (64-bit entries).
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bc0e1d88fd3b..ee7692341576 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -94,7 +94,7 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 		pud = pud_offset(pgd, addr);
 		if (PTRS_PER_PUD != 1)
-			printk(", *pud=%08lx", pud_val(*pud));
+			printk(", *pud=%08llx", (long long)pud_val(*pud));
 
 		if (pud_none(*pud))
 			break;

commit 02fe2845d6a837ab02f0738f6cf4591a02cc88d4
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jun 25 11:44:06 2011 +0100

    ARM: entry: avoid enabling interrupts in prefetch/data abort handlers
    
    Avoid enabling interrupts if the parent context had interrupts enabled
    in the abort handler assembly code, and move this into the breakpoint/
    page/alignment fault handlers instead.
    
    This gets rid of some special-casing for the breakpoint fault handlers
    from the low level abort handler path.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bc0e1d88fd3b..20e5d5120609 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -285,6 +285,10 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	tsk = current;
 	mm  = tsk->mm;
 
+	/* Enable interrupts if they were enabled in the parent context. */
+	if (interrupts_enabled(regs))
+		local_irq_enable();
+
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..

commit a8b0ca17b80e92faab46ee7179ba9e99ccb61233
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Jun 27 14:41:57 2011 +0200

    perf: Remove the nmi parameter from the swevent and overflow interface
    
    The nmi parameter indicated if we could do wakeups from the current
    context, if not, we would set some state and self-IPI and let the
    resulting interrupt do the wakeup.
    
    For the various event classes:
    
      - hardware: nmi=0; PMI is in fact an NMI or we run irq_work_run from
        the PMI-tail (ARM etc.)
      - tracepoint: nmi=0; since tracepoint could be from NMI context.
      - software: nmi=[0,1]; some, like the schedule thing cannot
        perform wakeups, and hence need 0.
    
    As one can see, there is very little nmi=1 usage, and the down-side of
    not using it is that on some platforms some software events can have a
    jiffy delay in wakeup (when arch_irq_work_raise isn't implemented).
    
    The up-side however is that we can remove the nmi parameter and save a
    bunch of conditionals in fast paths.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Michael Cree <mcree@orcon.net.nz>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Deng-Cheng Zhu <dengcheng.zhu@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jason Wessel <jason.wessel@windriver.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Link: http://lkml.kernel.org/n/tip-agjev8eu666tvknpb3iaj0fg@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bc0e1d88fd3b..9ea4f7ddd665 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -318,11 +318,11 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	fault = __do_page_fault(mm, addr, fsr, tsk);
 	up_read(&mm->mmap_sem);
 
-	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, addr);
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
 	if (fault & VM_FAULT_MAJOR)
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0, regs, addr);
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, addr);
 	else if (fault & VM_FAULT_MINOR)
-		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0, regs, addr);
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, addr);
 
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR

commit 516295e5ab4bf986865cfff856d484ec678e3b0b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Nov 21 16:27:49 2010 +0000

    ARM: pgtable: add pud-level code
    
    Add pud_offset() et.al. between the pgd and pmd code in preparation of
    using pgtable-nopud.h rather than 4level-fixup.h.
    
    This incorporates a fix from Jamie Iles <jamie@jamieiles.com> for
    uaccess_with_memcpy.c.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ef0e24f578ef..bc0e1d88fd3b 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -80,6 +80,7 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			addr, (long long)pgd_val(*pgd));
 
 	do {
+		pud_t *pud;
 		pmd_t *pmd;
 		pte_t *pte;
 
@@ -91,7 +92,19 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 		}
 
-		pmd = pmd_offset(pgd, addr);
+		pud = pud_offset(pgd, addr);
+		if (PTRS_PER_PUD != 1)
+			printk(", *pud=%08lx", pud_val(*pud));
+
+		if (pud_none(*pud))
+			break;
+
+		if (pud_bad(*pud)) {
+			printk("(bad)");
+			break;
+		}
+
+		pmd = pmd_offset(pud, addr);
 		if (PTRS_PER_PMD != 1)
 			printk(", *pmd=%08llx", (long long)pmd_val(*pmd));
 
@@ -390,6 +403,7 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 {
 	unsigned int index;
 	pgd_t *pgd, *pgd_k;
+	pud_t *pud, *pud_k;
 	pmd_t *pmd, *pmd_k;
 
 	if (addr < TASK_SIZE)
@@ -408,12 +422,19 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 
 	if (pgd_none(*pgd_k))
 		goto bad_area;
-
 	if (!pgd_present(*pgd))
 		set_pgd(pgd, *pgd_k);
 
-	pmd_k = pmd_offset(pgd_k, addr);
-	pmd   = pmd_offset(pgd, addr);
+	pud = pud_offset(pgd, addr);
+	pud_k = pud_offset(pgd_k, addr);
+
+	if (pud_none(*pud_k))
+		goto bad_area;
+	if (!pud_present(*pud))
+		set_pud(pud, *pud_k);
+
+	pmd = pmd_offset(pud, addr);
+	pmd_k = pmd_offset(pud_k, addr);
 
 	/*
 	 * On ARM one Linux PGD entry contains two hardware entries (see page

commit 29a38193c15bd72ba96c57a805443ef46ea6a6ac
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 15 14:31:37 2011 +0100

    ARM: 6674/1: LPAE: use long long format when printing physical addresses and ptes
    
    For the Kernel to support 2 level and 3 level page tables, physical
    addresses (and also page table entries) need to be 32 or 64-bits depending
    upon the configuration.
    
    This patch uses the %08llx conversion specifier for physical addresses
    and page table entries, ensuring that they are cast to (long long) so
    that common code can be used regardless of the datatype widths.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index f10f9bac2206..ef0e24f578ef 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -76,7 +76,8 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 	printk(KERN_ALERT "pgd = %p\n", mm->pgd);
 	pgd = pgd_offset(mm, addr);
-	printk(KERN_ALERT "[%08lx] *pgd=%08lx", addr, pgd_val(*pgd));
+	printk(KERN_ALERT "[%08lx] *pgd=%08llx",
+			addr, (long long)pgd_val(*pgd));
 
 	do {
 		pmd_t *pmd;
@@ -92,7 +93,7 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 		pmd = pmd_offset(pgd, addr);
 		if (PTRS_PER_PMD != 1)
-			printk(", *pmd=%08lx", pmd_val(*pmd));
+			printk(", *pmd=%08llx", (long long)pmd_val(*pmd));
 
 		if (pmd_none(*pmd))
 			break;
@@ -107,8 +108,9 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 
 		pte = pte_offset_map(pmd, addr);
-		printk(", *pte=%08lx", pte_val(*pte));
-		printk(", *ppte=%08lx", pte_val(pte[PTE_HWTABLE_PTRS]));
+		printk(", *pte=%08llx", (long long)pte_val(*pte));
+		printk(", *ppte=%08llx",
+		       (long long)pte_val(pte[PTE_HWTABLE_PTRS]));
 		pte_unmap(pte);
 	} while(0);
 

commit d30e45eeabefadc6039d7f876a59e5f5f6cb11c6
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Nov 16 00:16:01 2010 +0000

    ARM: pgtable: switch order of Linux vs hardware page tables
    
    This switches the ordering of the Linux vs hardware page tables in
    each page, thereby eliminating some of the arithmetic in the page
    table walks.  As we now place the Linux page table at the beginning
    of the page, we can deal with the offset in the pgt by simply masking
    it away, along with the other control bits.
    
    This also makes the arithmetic all be positive, rather than a mixture.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 1e21e125fe3a..f10f9bac2206 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -108,7 +108,7 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 		pte = pte_offset_map(pmd, addr);
 		printk(", *pte=%08lx", pte_val(*pte));
-		printk(", *ppte=%08lx", pte_val(pte[-PTRS_PER_PTE]));
+		printk(", *ppte=%08lx", pte_val(pte[PTE_HWTABLE_PTRS]));
 		pte_unmap(pte);
 	} while(0);
 

commit 3a4b5dca53aecb16db9e007d782b2d1e757e941a
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Sep 3 10:39:59 2010 +0100

    ARM: 6355/1: hw-breakpoint: add mechanism for hooking into prefetch aborts
    
    On ARM processors with hardware breakpoint and watchpoint support,
    triggering these events results in a debug exception. These manifest
    as prefetch and data aborts respectively.
    
    arch/arm/mm/fault.c already provides hook_fault_code for hooking
    into data aborts dependent on the DFSR. This patch adds a new function,
    hook_ifault_code for hooking into prefetch aborts in the same manner.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: S. Karthikeyan <informkarthik@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 23b0b03af5ea..1e21e125fe3a 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -581,6 +581,19 @@ static struct fsr_info ifsr_info[] = {
 	{ do_bad,		SIGBUS,  0,		"unknown 31"			   },
 };
 
+void __init
+hook_ifault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
+		 int sig, int code, const char *name)
+{
+	if (nr < 0 || nr >= ARRAY_SIZE(ifsr_info))
+		BUG();
+
+	ifsr_info[nr].fn   = fn;
+	ifsr_info[nr].sig  = sig;
+	ifsr_info[nr].code = code;
+	ifsr_info[nr].name = name;
+}
+
 asmlinkage void __exception
 do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 {

commit b8ab5397bcbd92e3fd4a9770e0bf59315fa38dab
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Mon Jul 26 11:20:41 2010 +0100

    ARM: 6268/1: ARMv6K and ARMv7 use fault statuses 3 and 6 as Access Flag fault
    
    Statuses 3 (0b00011) and 6 (0x00110) of DFSR are Access Flags faults on
    ARMv6K and ARMv7. Let's patch fsr_info[] at runtime if we are on ARMv7
    or later.
    
    Unfortunately, we don't have runtime check for 'K' extension, so we
    can't check for it.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 5835e63454ff..23b0b03af5ea 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -607,6 +607,17 @@ static int __init exceptions_init(void)
 				"I-cache maintenance fault");
 	}
 
+	if (cpu_architecture() >= CPU_ARCH_ARMv7) {
+		/*
+		 * TODO: Access flag faults introduced in ARMv6K.
+		 * Runtime check for 'K' extension is needed
+		 */
+		hook_fault_code(3, do_bad, SIGSEGV, SEGV_MAPERR,
+				"section access flag fault");
+		hook_fault_code(6, do_bad, SIGSEGV, SEGV_MAPERR,
+				"section access flag fault");
+	}
+
 	return 0;
 }
 

commit 993bf4ec8c2a2b7979389ab196bf2fe217117158
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Thu Jul 22 13:23:25 2010 +0100

    ARM: 6256/1: Check arch version and modify fsr_info[] depends on it at runtime
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 564b1c4829e4..5835e63454ff 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -475,12 +475,7 @@ static struct fsr_info {
 	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
 	{ do_bad,		SIGKILL, 0,		"terminal exception"		   },
 	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
-/* Do we need runtime check ? */
-#if __LINUX_ARM_ARCH__ < 6
 	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
-#else
-	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"I-cache maintenance fault"	   },
-#endif
 	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
 	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
 	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },
@@ -605,3 +600,14 @@ do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 	arm_notify_die("", regs, &info, ifsr, 0);
 }
 
+static int __init exceptions_init(void)
+{
+	if (cpu_architecture() >= CPU_ARCH_ARMv6) {
+		hook_fault_code(4, do_translation_fault, SIGSEGV, SEGV_MAPERR,
+				"I-cache maintenance fault");
+	}
+
+	return 0;
+}
+
+arch_initcall(exceptions_init);

commit 33a9c41bf5d8adae9d882513e617c4c645195e71
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Thu Jul 22 13:20:22 2010 +0100

    ARM: 6255/1: Workaround infinity loop in handling of translation faults
    
    On ARM one Linux PGD entry contains two hardware entries (see page
    tables layout in pgtable.h). We normally guarantee that we always
    fill both L1 entries. But create_mapping() doesn't follow the rule.
    It can create inidividual L1 entries, so here we have to call
    pmd_none() check in do_translation_fault() for the entry really
    corresponded to address, not for the first of pair.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 84131c832430..564b1c4829e4 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -413,7 +413,16 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	pmd_k = pmd_offset(pgd_k, addr);
 	pmd   = pmd_offset(pgd, addr);
 
-	if (pmd_none(*pmd_k))
+	/*
+	 * On ARM one Linux PGD entry contains two hardware entries (see page
+	 * tables layout in pgtable.h). We normally guarantee that we always
+	 * fill both L1 entries. But create_mapping() doesn't follow the rule.
+	 * It can create inidividual L1 entries, so here we have to call
+	 * pmd_none() check for the entry really corresponded to address, not
+	 * for the first of pair.
+	 */
+	index = (addr >> SECTION_SHIFT) & 1;
+	if (pmd_none(pmd_k[index]))
 		goto bad_area;
 
 	copy_pmd(pmd, pmd_k);

commit 6338a6aa7c082f11d55712251e14178c68bf5869
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Thu Jul 22 13:18:19 2010 +0100

    ARM: 6269/1: Add 'code' parameter for hook_fault_code()
    
    Add one more parameter to hook_fault_code() to be able to set 'code'
    field of struct fsr_info.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ce6f3a422c81..84131c832430 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -508,13 +508,15 @@ static struct fsr_info {
 
 void __init
 hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
-		int sig, const char *name)
+		int sig, int code, const char *name)
 {
-	if (nr >= 0 && nr < ARRAY_SIZE(fsr_info)) {
-		fsr_info[nr].fn   = fn;
-		fsr_info[nr].sig  = sig;
-		fsr_info[nr].name = name;
-	}
+	if (nr < 0 || nr >= ARRAY_SIZE(fsr_info))
+		BUG();
+
+	fsr_info[nr].fn   = fn;
+	fsr_info[nr].sig  = sig;
+	fsr_info[nr].code = code;
+	fsr_info[nr].name = name;
 }
 
 /*

commit 3dc91aff9c3ef54b15cdaf32f61f973489fe69eb
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Thu Jul 22 13:16:49 2010 +0100

    ARM: 6252/1: Use SIGBUS for unaligned access instead of SIGILL
    
    POSIX specify to use signal SIGBUS with code BUS_ADRALN for invalid
    address alignment.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index cbfb2edcf7d1..ce6f3a422c81 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -463,9 +463,9 @@ static struct fsr_info {
 	 * defines these to be "precise" aborts.
 	 */
 	{ do_bad,		SIGSEGV, 0,		"vector exception"		   },
-	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
+	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
 	{ do_bad,		SIGKILL, 0,		"terminal exception"		   },
-	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
+	{ do_bad,		SIGBUS,	 BUS_ADRALN,	"alignment exception"		   },
 /* Do we need runtime check ? */
 #if __LINUX_ARM_ARCH__ < 6
 	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },

commit 5e27fb78df95e027723af2c90ecc9b4527ae59e9
Author: Anfei <anfei.zhou@gmail.com>
Date:   Tue Jun 8 15:16:49 2010 +0100

    ARM: 6166/1: Proper prefetch abort handling on pre-ARMv6
    
    Instruction faults on pre-ARMv6 CPUs are interpreted as
    a 'translation fault', but do_translation_fault doesn't
    handle well if user mode trying to run instruction above
    TASK_SIZE, and result in the infinite retry of that
    instruction.
    
    CC: <stable@kernel.org>
    Signed-off-by: Anfei Zhou <anfei.zhou@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 92f5801f99c1..cbfb2edcf7d1 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -393,6 +393,9 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	if (addr < TASK_SIZE)
 		return do_page_fault(addr, fsr, regs);
 
+	if (user_mode(regs))
+		goto bad_area;
+
 	index = pgd_index(addr);
 
 	/*

commit 8c0b742ca7a7d21de0ddc87eda6ef0b282e4de18
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Sat May 15 09:57:06 2010 +0100

    ARM: 6134/1: Handle instruction cache maintenance fault properly
    
    Between "clean D line..." and "invalidate I line" operations in
    v7_coherent_user_range(), the memory page may get swapped out.
    And the fault on "invalidate I line" could not be properly handled
    causing the oops.
    
    In ARMv6 "external abort on linefetch" replaced by "instruction cache
    maintenance fault". Let's handle it as translation fault. It fixes the
    issue.
    
    I'm not sure if it's reasonable to check arch version in run-time.
    Let's do it in compile time for now.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Siarhei Siamashka <siarhei.siamashka@nokia.com>
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 9d40c341e07e..92f5801f99c1 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -463,7 +463,12 @@ static struct fsr_info {
 	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
 	{ do_bad,		SIGKILL, 0,		"terminal exception"		   },
 	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
+/* Do we need runtime check ? */
+#if __LINUX_ARM_ARCH__ < 6
 	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
+#else
+	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"I-cache maintenance fault"	   },
+#endif
 	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
 	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
 	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },

commit 7ada189f5c8627662c23f49b3e68463f86fc511e
Author: Jamie Iles <jamie.iles@picochip.com>
Date:   Tue Feb 2 20:24:58 2010 +0100

    ARM: 5900/2: arm: enable support for software perf events
    
    The perf events subsystem allows counting of both hardware and
    software events. This patch implements the bare minimum for software
    performance events.
    
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Jamie Iles <jamie.iles@picochip.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 10e06801afb3..9d40c341e07e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -18,6 +18,7 @@
 #include <linux/page-flags.h>
 #include <linux/sched.h>
 #include <linux/highmem.h>
+#include <linux/perf_event.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>
@@ -302,6 +303,12 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	fault = __do_page_fault(mm, addr, fsr, tsk);
 	up_read(&mm->mmap_sem);
 
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, addr);
+	if (fault & VM_FAULT_MAJOR)
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0, regs, addr);
+	else if (fault & VM_FAULT_MINOR)
+		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0, regs, addr);
+
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
 	 */

commit 1d2127123db9b1821959c2b8b7473dd7ffcdf527
Author: Imre Deak <imre.deak@nokia.com>
Date:   Mon Oct 5 13:40:44 2009 +0100

    ARM: 5742/1: ARM: add debug check for invalid kernel page faults
    
    According to the following in arch/arm/mm/fault.c page faults from
    kernel mode are invalid if mmap_sem is already held and there is
    no exception handler defined for the faulting instruction:
    
    /*
     * As per x86, we may deadlock here.  However, since the kernel only
     * validly references user space from well defined areas of the code,
     * we can bug out early if this is from code which shouldn't.
     */
    if (!down_read_trylock(&mm->mmap_sem)) {
            if (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))
                    goto no_context;
    
    Since mmap_sem can be held at arbitrary times by another thread this
    also means that any page faults from kernel mode are invalid if no
    exception handler is defined for them, regardless whether mmap_sem is
    held at the time of fault.
    
    To easier detect code that can trigger the above error, add a check
    also for the case where mmap_sem is acquired. As this has an overhead
    make it a VM debug check.
    
    Signed-off-by: Imre Deak <imre.deak@nokia.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ae0e25f5a70e..10e06801afb3 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -292,6 +292,11 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		 * down_read()
 		 */
 		might_sleep();
+#ifdef CONFIG_DEBUG_VM
+		if (!user_mode(regs) &&
+		    !search_exception_tables(regs->ARM_pc))
+			goto no_context;
+#endif
 	}
 
 	fault = __do_page_fault(mm, addr, fsr, tsk);

commit d25ef8b86e6a58f5476bf6e4a8da730b335f68fa
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Fri Sep 25 13:40:49 2009 +0100

    ARM: 5728/1: Proper prefetch abort handling on ARMv6 and ARMv7
    
    Currently, on ARMv6 and ARMv7, if an application tries to execute
    code (or garbage) on non-executable page it hangs. It caused by
    incorrect prefetch abort handling. Now every prefetch abort
    processes as a translation fault.
    
    To fix this we have to analyze instruction fault status register
    to figure out reason why we've got the abort and process it
    accordingly.
    
    To make IFSR different from DFSR we set bit 31 which is reserved in
    both IFSR and DFSR.
    
    This patch also tries to protect from future hangs on unexpected
    exceptions. An application will be killed if unexpected exception
    type was received.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index fd2375f84994..ae0e25f5a70e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -519,9 +519,58 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	arm_notify_die("", regs, &info, fsr, 0);
 }
 
+
+static struct fsr_info ifsr_info[] = {
+	{ do_bad,		SIGBUS,  0,		"unknown 0"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 1"			   },
+	{ do_bad,		SIGBUS,  0,		"debug event"			   },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section access flag fault"	   },
+	{ do_bad,		SIGBUS,  0,		"unknown 4"			   },
+	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page access flag fault"	   },
+	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section domain fault"		   },
+	{ do_bad,		SIGBUS,  0,		"unknown 10"			   },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page domain fault"		   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
+	{ do_sect_fault,	SIGSEGV, SEGV_ACCERR,	"section permission fault"	   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
+	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	"page permission fault"		   },
+	{ do_bad,		SIGBUS,  0,		"unknown 16"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 17"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 18"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 19"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 20"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 21"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 22"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 23"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 24"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 25"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 26"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 27"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 28"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 29"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 30"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 31"			   },
+};
+
 asmlinkage void __exception
 do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 {
-	do_translation_fault(addr, FSR_LNX_PF, regs);
+	const struct fsr_info *inf = ifsr_info + fsr_fs(ifsr);
+	struct siginfo info;
+
+	if (!inf->fn(addr, ifsr | FSR_LNX_PF, regs))
+		return;
+
+	printk(KERN_ALERT "Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",
+		inf->name, ifsr, addr);
+
+	info.si_signo = inf->sig;
+	info.si_errno = 0;
+	info.si_code  = inf->code;
+	info.si_addr  = (void __user *)addr;
+	arm_notify_die("", regs, &info, ifsr, 0);
 }
 

commit 4fb2847437d871fe579f820ceb18031db3359901
Author: Kirill A. Shutemov <kirill@shutemov.name>
Date:   Fri Sep 25 13:39:47 2009 +0100

    ARM: 5727/1: Pass IFSR register to do_PrefetchAbort()
    
    Instruction fault status register, IFSR, was introduced on ARMv6 to
    provide status information about the last insturction fault. It
    needed for proper prefetch abort handling.
    
    Now we have three prefetch abort model:
    
      * legacy - for CPUs before ARMv6. They doesn't provide neither
        IFSR nor IFAR. We simulate IFSR with section translation fault
        status for them to generalize code;
      * ARMv6 - provides IFSR, but not IFAR;
      * ARMv7 - provides both IFSR and IFAR.
    
    Signed-off-by: Kirill A. Shutemov <kirill@shutemov.name>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 379f78556055..fd2375f84994 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -520,7 +520,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 }
 
 asmlinkage void __exception
-do_PrefetchAbort(unsigned long addr, struct pt_regs *regs)
+do_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)
 {
 	do_translation_fault(addr, FSR_LNX_PF, regs);
 }

commit df297bf6c7933e7b021cdc1bf3f9e319ea3a7e9c
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 20 13:18:47 2009 +0100

    ARM: Add support for checking access permissions on prefetch aborts
    
    ARMv6 introduces non-executable mappings, which can cause prefetch aborts
    when an attempt is made to execute from such a mapping.  Currently, this
    causes us to loop in the page fault handler since we don't correctly
    check for proper permissions.
    
    Fix this by checking that VMAs have VM_EXEC set for prefetch aborts.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index b7ce07d416cd..379f78556055 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -26,8 +26,9 @@
 #include "fault.h"
 
 /*
- * Fault status register encodings
+ * Fault status register encodings.  We steal bit 31 for our own purposes.
  */
+#define FSR_LNX_PF		(1 << 31)
 #define FSR_WRITE		(1 << 11)
 #define FSR_FS4			(1 << 10)
 #define FSR_FS3_0		(15)
@@ -205,6 +206,8 @@ static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
 
 	if (fsr & FSR_WRITE)
 		mask = VM_WRITE;
+	if (fsr & FSR_LNX_PF)
+		mask = VM_EXEC;
 
 	return vma->vm_flags & mask ? false : true;
 }
@@ -503,7 +506,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	const struct fsr_info *inf = fsr_info + fsr_fs(fsr);
 	struct siginfo info;
 
-	if (!inf->fn(addr, fsr, regs))
+	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
 		return;
 
 	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
@@ -519,6 +522,6 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 asmlinkage void __exception
 do_PrefetchAbort(unsigned long addr, struct pt_regs *regs)
 {
-	do_translation_fault(addr, 0, regs);
+	do_translation_fault(addr, FSR_LNX_PF, regs);
 }
 

commit d374bf14a5ff18133bd6a6cc00f189949f7ba8fb
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 20 12:53:01 2009 +0100

    ARM: Separate out access error checking
    
    Since we get notified separately about prefetch aborts, which may be
    permission faults, we need to check for appropriate access permissions
    when handling a fault.  This patch prepares us for doing this by
    separating out the access error checking.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index b8b3bb4423cf..b7ce07d416cd 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -194,18 +194,33 @@ void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 #define VM_FAULT_BADMAP		0x010000
 #define VM_FAULT_BADACCESS	0x020000
 
-static int
+/*
+ * Check that the permissions on the VMA allow for the fault which occurred.
+ * If we encountered a write fault, we must have write permission, otherwise
+ * we allow any permission.
+ */
+static inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)
+{
+	unsigned int mask = VM_READ | VM_WRITE | VM_EXEC;
+
+	if (fsr & FSR_WRITE)
+		mask = VM_WRITE;
+
+	return vma->vm_flags & mask ? false : true;
+}
+
+static int __kprobes
 __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		struct task_struct *tsk)
 {
 	struct vm_area_struct *vma;
-	int fault, mask;
+	int fault;
 
 	vma = find_vma(mm, addr);
 	fault = VM_FAULT_BADMAP;
-	if (!vma)
+	if (unlikely(!vma))
 		goto out;
-	if (vma->vm_start > addr)
+	if (unlikely(vma->vm_start > addr))
 		goto check_stack;
 
 	/*
@@ -213,14 +228,10 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * memory access, so we can handle it.
 	 */
 good_area:
-	if (fsr & FSR_WRITE)
-		mask = VM_WRITE;
-	else
-		mask = VM_READ|VM_EXEC|VM_WRITE;
-
-	fault = VM_FAULT_BADACCESS;
-	if (!(vma->vm_flags & mask))
+	if (access_error(fsr, vma)) {
+		fault = VM_FAULT_BADACCESS;
 		goto out;
+	}
 
 	/*
 	 * If for any reason at all we couldn't handle the fault, make

commit bf4569922b97824f33e5d08d0bbe4b34fe43e4cd
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 20 12:52:19 2009 +0100

    ARM: Ensure correct might_sleep() check in pagefault path
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 501304f7e30c..b8b3bb4423cf 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -271,6 +271,13 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		if (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))
 			goto no_context;
 		down_read(&mm->mmap_sem);
+	} else {
+		/*
+		 * The above down_read_trylock() might have succeeded in
+		 * which case, we'll have missed the might_sleep() from
+		 * down_read()
+		 */
+		might_sleep();
 	}
 
 	fault = __do_page_fault(mm, addr, fsr, tsk);

commit b42c6344b091db680fd1ec7a0483e8b6796f802b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 20 12:47:40 2009 +0100

    ARM: Update page fault handling for new OOM techniques
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 1bb38712c86b..501304f7e30c 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -223,37 +223,18 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		goto out;
 
 	/*
-	 * If for any reason at all we couldn't handle
-	 * the fault, make sure we exit gracefully rather
-	 * than endlessly redo the fault.
+	 * If for any reason at all we couldn't handle the fault, make
+	 * sure we exit gracefully rather than endlessly redo the fault.
 	 */
-survive:
 	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, (fsr & FSR_WRITE) ? FAULT_FLAG_WRITE : 0);
-	if (unlikely(fault & VM_FAULT_ERROR)) {
-		if (fault & VM_FAULT_OOM)
-			goto out_of_memory;
-		else if (fault & VM_FAULT_SIGBUS)
-			return fault;
-		BUG();
-	}
+	if (unlikely(fault & VM_FAULT_ERROR))
+		return fault;
 	if (fault & VM_FAULT_MAJOR)
 		tsk->maj_flt++;
 	else
 		tsk->min_flt++;
 	return fault;
 
-out_of_memory:
-	if (!is_global_init(tsk))
-		goto out;
-
-	/*
-	 * If we are out of memory for pid1, sleep for a while and retry
-	 */
-	up_read(&mm->mmap_sem);
-	yield();
-	down_read(&mm->mmap_sem);
-	goto survive;
-
 check_stack:
 	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
 		goto good_area;
@@ -301,6 +282,16 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP | VM_FAULT_BADACCESS))))
 		return 0;
 
+	if (fault & VM_FAULT_OOM) {
+		/*
+		 * We ran out of memory, call the OOM killer, and return to
+		 * userspace (which will retry the fault, or kill us if we
+		 * got oom-killed)
+		 */
+		pagefault_out_of_memory();
+		return 0;
+	}
+
 	/*
 	 * If we are in kernel mode at this point, we
 	 * have no context to handle this fault with.
@@ -308,16 +299,6 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!user_mode(regs))
 		goto no_context;
 
-	if (fault & VM_FAULT_OOM) {
-		/*
-		 * We ran out of memory, or some other thing
-		 * happened to us that made us unable to handle
-		 * the page fault gracefully.
-		 */
-		printk("VM: killing process %s\n", tsk->comm);
-		do_group_exit(SIGKILL);
-		return 0;
-	}
 	if (fault & VM_FAULT_SIGBUS) {
 		/*
 		 * We had some memory, but were unable to

commit c88d6aa71bd2ad7b4da2f281bd64ada65d533d83
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Sep 20 12:41:58 2009 +0100

    ARM: Provide definitions and helpers for decoding the FSR register
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index cc8829d7e116..1bb38712c86b 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -25,6 +25,18 @@
 
 #include "fault.h"
 
+/*
+ * Fault status register encodings
+ */
+#define FSR_WRITE		(1 << 11)
+#define FSR_FS4			(1 << 10)
+#define FSR_FS3_0		(15)
+
+static inline int fsr_fs(unsigned int fsr)
+{
+	return (fsr & FSR_FS3_0) | (fsr & FSR_FS4) >> 6;
+}
+
 #ifdef CONFIG_MMU
 
 #ifdef CONFIG_KPROBES
@@ -201,7 +213,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * memory access, so we can handle it.
 	 */
 good_area:
-	if (fsr & (1 << 11)) /* write? */
+	if (fsr & FSR_WRITE)
 		mask = VM_WRITE;
 	else
 		mask = VM_READ|VM_EXEC|VM_WRITE;
@@ -216,7 +228,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * than endlessly redo the fault.
 	 */
 survive:
-	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, (fsr & (1 << 11)) ? FAULT_FLAG_WRITE : 0);
+	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, (fsr & FSR_WRITE) ? FAULT_FLAG_WRITE : 0);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
@@ -489,7 +501,7 @@ hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *)
 asmlinkage void __exception
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
-	const struct fsr_info *inf = fsr_info + (fsr & 15) + ((fsr & (1 << 10)) >> 6);
+	const struct fsr_info *inf = fsr_info + fsr_fs(fsr);
 	struct siginfo info;
 
 	if (!inf->fn(addr, fsr, regs))

commit ddd559b13f6d2fe3ad68c4b3f5235fd3c2eae4e3
Merge: cf7a2b4fb6a9 f17a1f06d2fa
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Sep 12 12:02:26 2009 +0100

    Merge branch 'devel-stable' into devel
    
    Conflicts:
            MAINTAINERS
            arch/arm/mm/fault.c

commit 65cec8e3db606608fd1f8dfc4a1c7c37bfba9173
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Aug 17 20:02:06 2009 +0100

    ARM: implement highpte
    
    Add the ARM implementation of highpte, which allows PTE tables to be
    placed in highmem.  Unfortunately, we do not offer highpte support
    when support for L2 cache is enabled.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 6fdcbb709827..5fa8dea5a371 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -16,6 +16,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/page-flags.h>
+#include <linux/highmem.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>

commit 412bb0a6224f96661c042a109c4978649c00ed52
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Jul 24 12:37:09 2009 +0100

    Include linux/sched.h in arch/arm/mm/fault.c
    
    When building with !MMU, task_struct is not defined. Just include the
    relevant file.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index ee01ccae3f58..556c8daf087d 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -16,6 +16,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/page-flags.h>
+#include <linux/sched.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>

commit 09529f7a1a010cc364267fc5895a71c3853eb82c
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Jul 24 12:34:55 2009 +0100

    nommu: Fix the fault processing for the MMU-less case
    
    The patch adds the necessary ifdefs around functions that only make
    sense when the MMU is enabled.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 6fdcbb709827..ee01ccae3f58 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -23,6 +23,7 @@
 
 #include "fault.h"
 
+#ifdef CONFIG_MMU
 
 #ifdef CONFIG_KPROBES
 static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
@@ -97,6 +98,10 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 
 	printk("\n");
 }
+#else					/* CONFIG_MMU */
+void show_pte(struct mm_struct *mm, unsigned long addr)
+{ }
+#endif					/* CONFIG_MMU */
 
 /*
  * Oops.  The kernel tried to access some page that wasn't present.
@@ -171,6 +176,7 @@ void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		__do_kernel_fault(mm, addr, fsr, regs);
 }
 
+#ifdef CONFIG_MMU
 #define VM_FAULT_BADMAP		0x010000
 #define VM_FAULT_BADACCESS	0x020000
 
@@ -322,6 +328,13 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	__do_kernel_fault(mm, addr, fsr, regs);
 	return 0;
 }
+#else					/* CONFIG_MMU */
+static int
+do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
+{
+	return 0;
+}
+#endif					/* CONFIG_MMU */
 
 /*
  * First Level Translation Fault Handler
@@ -340,6 +353,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  * interrupt or a critical region, and should only copy the information
  * from the master page table, nothing more.
  */
+#ifdef CONFIG_MMU
 static int __kprobes
 do_translation_fault(unsigned long addr, unsigned int fsr,
 		     struct pt_regs *regs)
@@ -378,6 +392,14 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	do_bad_area(addr, fsr, regs);
 	return 0;
 }
+#else					/* CONFIG_MMU */
+static int
+do_translation_fault(unsigned long addr, unsigned int fsr,
+		     struct pt_regs *regs)
+{
+	return 0;
+}
+#endif					/* CONFIG_MMU */
 
 /*
  * Some section permission faults need to be handled gracefully.

commit d06063cc221fdefcab86589e79ddfdb7c0e14b63
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 10 09:01:23 2009 -0700

    Move FAULT_FLAG_xyz into handle_mm_fault() callers
    
    This allows the callers to now pass down the full set of FAULT_FLAG_xyz
    flags to handle_mm_fault().  All callers have been (mechanically)
    converted to the new calling convention, there's almost certainly room
    for architectures to clean up their code and then add FAULT_FLAG_RETRY
    when that support is added.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 0455557a2899..6fdcbb709827 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -208,7 +208,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 * than endlessly redo the fault.
 	 */
 survive:
-	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, fsr & (1 << 11));
+	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, (fsr & (1 << 11)) ? FAULT_FLAG_WRITE : 0);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;

commit c613bbba6f39c8804f1f26e96fb68a117cc9e282
Merge: cd4348339c21 80eee6bca406
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Dec 17 20:04:45 2008 +0000

    Merge branch 'mxc-pu-imxfb' of git://pasiphae.extern.pengutronix.de/git/imx/linux-2.6 into devel

commit 67306da610a3e4824192e92888634d3d8700bfc1
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sun Dec 14 18:01:44 2008 +0000

    [ARM] Ensure linux/hardirqs.h is included where required
    
    ... for the removal of it from asm-generic/local.h
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 2df8d9facf57..22c9530e91e2 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -11,6 +11,7 @@
 #include <linux/module.h>
 #include <linux/signal.h>
 #include <linux/mm.h>
+#include <linux/hardirq.h>
 #include <linux/init.h>
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>

commit 252d4c276dc0895834af48743579cf19d1fa150b
Author: Nicolas Pitre <nico@cam.org>
Date:   Thu Sep 11 11:52:02 2008 -0400

    [ARM] remove bogus #ifdef CONFIG_HIGHMEM in show_pte()
    
    The restriction on !CONFIG_HIGHMEM is unneeded since page tables are
    currently never allocated with highmem pages, and actually disable PTE
    dump whenever highmem is configured.  Let's have a dynamic test to better
    describe the current limitation instead.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 2df8d9facf57..ffd8b228a139 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -14,6 +14,7 @@
 #include <linux/init.h>
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
+#include <linux/page-flags.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>
@@ -83,13 +84,14 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 		}
 
-#ifndef CONFIG_HIGHMEM
 		/* We must not map this if we have highmem enabled */
+		if (PageHighMem(pfn_to_page(pmd_val(*pmd) >> PAGE_SHIFT)))
+			break;
+
 		pte = pte_offset_map(pmd, addr);
 		printk(", *pte=%08lx", pte_val(*pte));
 		printk(", *ppte=%08lx", pte_val(pte[-PTRS_PER_PTE]));
 		pte_unmap(pte);
-#endif
 	} while(0);
 
 	printk("\n");

commit da46c79a5418dd6ba006665c1535af0713bb77b9
Author: Nicolas Pitre <nico@cam.org>
Date:   Tue Sep 30 16:10:11 2008 +0100

    [ARM] 5272/1: remove conditional compilation in show_pte()
    
    The PTRS_PER_PMD != 1 condition can be evaluated with C code and
    optimized at compile time.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index fcdae537a28f..2df8d9facf57 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -72,9 +72,8 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 		}
 
 		pmd = pmd_offset(pgd, addr);
-#if PTRS_PER_PMD != 1
-		printk(", *pmd=%08lx", pmd_val(*pmd));
-#endif
+		if (PTRS_PER_PMD != 1)
+			printk(", *pmd=%08lx", pmd_val(*pmd));
 
 		if (pmd_none(*pmd))
 			break;

commit 33fa9b13285e76fb95d940120964562e4c7081c2
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Sep 6 11:35:55 2008 +0100

    [ARM] Convert asm/uaccess.h to linux/uaccess.h
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 28ad7ab1c0cd..fcdae537a28f 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -13,11 +13,11 @@
 #include <linux/mm.h>
 #include <linux/init.h>
 #include <linux/kprobes.h>
+#include <linux/uaccess.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>
-#include <asm/uaccess.h>
 
 #include "fault.h"
 

commit 785d3cd286f0bf67d1bf692559b9ae5de12678f5
Author: Nicolas Pitre <nico@cam.org>
Date:   Mon Dec 3 15:27:56 2007 -0500

    ARM kprobes: prevent some functions involved with kprobes from being probed
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 1e7b1ed304d8..28ad7ab1c0cd 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -239,7 +239,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	return fault;
 }
 
-static int
+static int __kprobes
 do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	struct task_struct *tsk;
@@ -338,7 +338,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  * interrupt or a critical region, and should only copy the information
  * from the master page table, nothing more.
  */
-static int
+static int __kprobes
 do_translation_fault(unsigned long addr, unsigned int fsr,
 		     struct pt_regs *regs)
 {

commit 25ce1dd71b8326f2542cf030f68e0e64c3d94dc1
Author: Nicolas Pitre <nico@cam.org>
Date:   Mon Dec 3 15:21:57 2007 -0500

    ARM kprobes: add the kprobes hook to the page fault handler
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index a8a7dab757eb..1e7b1ed304d8 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -12,6 +12,7 @@
 #include <linux/signal.h>
 #include <linux/mm.h>
 #include <linux/init.h>
+#include <linux/kprobes.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>
@@ -20,6 +21,29 @@
 
 #include "fault.h"
 
+
+#ifdef CONFIG_KPROBES
+static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
+{
+	int ret = 0;
+
+	if (!user_mode(regs)) {
+		/* kprobe_running() needs smp_processor_id() */
+		preempt_disable();
+		if (kprobe_running() && kprobe_fault_handler(regs, fsr))
+			ret = 1;
+		preempt_enable();
+	}
+
+	return ret;
+}
+#else
+static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)
+{
+	return 0;
+}
+#endif
+
 /*
  * This is useful to dump out the page tables associated with
  * 'addr' in mm 'mm'.
@@ -222,6 +246,9 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	struct mm_struct *mm;
 	int fault, sig, code;
 
+	if (notify_page_fault(regs, fsr))
+		return 0;
+
 	tsk = current;
 	mm  = tsk->mm;
 

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 59ed1d05b71b..a8a7dab757eb 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -197,7 +197,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	return fault;
 
 out_of_memory:
-	if (!is_init(tsk))
+	if (!is_global_init(tsk))
 		goto out;
 
 	/*

commit dcca2bde4f86a14d3291660bede8f1844fe2b3df
Author: Will Schmidt <will_schmidt@vnet.ibm.com>
Date:   Tue Oct 16 01:24:18 2007 -0700

    During VM oom condition, kill all threads in process group
    
    We have had complaints where a threaded application is left in a bad state
    after one of it's threads is killed when we hit a VM: out_of_memory
    condition.
    
    Killing just one of the process threads can leave the application in a bad
    state, whereas killing the entire process group would allow for the
    application to restart, or be otherwise handled, and makes it very obvious
    that something has gone wrong.
    
    This change allows the entire process group to be taken down, rather
    than just the one thread.
    
    Signed-off-by: Will Schmidt <will_schmidt@vnet.ibm.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Chris Zankel <chris@zankel.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 846cce48e2b7..59ed1d05b71b 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -266,7 +266,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		 * the page fault gracefully.
 		 */
 		printk("VM: killing process %s\n", tsk->comm);
-		do_exit(SIGKILL);
+		do_group_exit(SIGKILL);
 		return 0;
 	}
 	if (fault & VM_FAULT_SIGBUS) {

commit 5c72fc5cad68f5e1bfe0910cca9f63723e4a5c4a
Author: Nick Piggin <npiggin@suse.de>
Date:   Fri Jul 20 09:21:06 2007 +0200

    arm: fix up handle_mm_fault changes
    
    Update arm to use bitwise types for its VM_FAULT_ constants.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index c04124a095cf..846cce48e2b7 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -145,8 +145,8 @@ void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		__do_kernel_fault(mm, addr, fsr, regs);
 }
 
-#define VM_FAULT_BADMAP		(-20)
-#define VM_FAULT_BADACCESS	(-21)
+#define VM_FAULT_BADMAP		0x010000
+#define VM_FAULT_BADACCESS	0x020000
 
 static int
 __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
@@ -249,7 +249,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
 	 */
-	if (likely(!(fault & VM_FAULT_ERROR)))
+	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP | VM_FAULT_BADACCESS))))
 		return 0;
 
 	/*

commit 83c54070ee1a2d05c89793884bea1a03f2851ed4
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Jul 19 01:47:05 2007 -0700

    mm: fault feedback #2
    
    This patch completes Linus's wish that the fault return codes be made into
    bit flags, which I agree makes everything nicer.  This requires requires
    all handle_mm_fault callers to be modified (possibly the modifications
    should go further and do things like fault accounting in handle_mm_fault --
    however that would be for another patch).
    
    [akpm@linux-foundation.org: fix alpha build]
    [akpm@linux-foundation.org: fix s390 build]
    [akpm@linux-foundation.org: fix sparc build]
    [akpm@linux-foundation.org: fix sparc64 build]
    [akpm@linux-foundation.org: fix ia64 build]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Bryan Wu <bryan.wu@analog.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Andi Kleen <ak@muc.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    [ Still apparently needs some ARM and PPC loving - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 75d491448e45..c04124a095cf 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -183,20 +183,20 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	 */
 survive:
 	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, fsr & (1 << 11));
-
-	/*
-	 * Handle the "normal" cases first - successful and sigbus
-	 */
-	switch (fault) {
-	case VM_FAULT_MAJOR:
+	if (unlikely(fault & VM_FAULT_ERROR)) {
+		if (fault & VM_FAULT_OOM)
+			goto out_of_memory;
+		else if (fault & VM_FAULT_SIGBUS)
+			return fault;
+		BUG();
+	}
+	if (fault & VM_FAULT_MAJOR)
 		tsk->maj_flt++;
-		return fault;
-	case VM_FAULT_MINOR:
+	else
 		tsk->min_flt++;
-	case VM_FAULT_SIGBUS:
-		return fault;
-	}
+	return fault;
 
+out_of_memory:
 	if (!is_init(tsk))
 		goto out;
 
@@ -249,7 +249,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	/*
 	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
 	 */
-	if (fault >= VM_FAULT_MINOR)
+	if (likely(!(fault & VM_FAULT_ERROR)))
 		return 0;
 
 	/*
@@ -259,8 +259,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!user_mode(regs))
 		goto no_context;
 
-	switch (fault) {
-	case VM_FAULT_OOM:
+	if (fault & VM_FAULT_OOM) {
 		/*
 		 * We ran out of memory, or some other thing
 		 * happened to us that made us unable to handle
@@ -269,17 +268,15 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		printk("VM: killing process %s\n", tsk->comm);
 		do_exit(SIGKILL);
 		return 0;
-
-	case VM_FAULT_SIGBUS:
+	}
+	if (fault & VM_FAULT_SIGBUS) {
 		/*
 		 * We had some memory, but were unable to
 		 * successfully fix up this page fault.
 		 */
 		sig = SIGBUS;
 		code = BUS_ADRERR;
-		break;
-
-	default:
+	} else {
 		/*
 		 * Something tried to access memory that
 		 * isn't in our memory map..
@@ -287,7 +284,6 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		sig = SIGSEGV;
 		code = fault == VM_FAULT_BADACCESS ?
 			SEGV_ACCERR : SEGV_MAPERR;
-		break;
 	}
 
 	__do_user_fault(tsk, addr, fsr, sig, code, regs);

commit 1eeb66a1bb973534dc3d064920a5ca683823372e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 8 00:27:03 2007 -0700

    move die notifier handling to common code
    
    This patch moves the die notifier handling to common code.  Previous
    various architectures had exactly the same code for it.  Note that the new
    code is compiled unconditionally, this should be understood as an appel to
    the other architecture maintainer to implement support for it aswell (aka
    sprinkling a notify_die or two in the proper place)
    
    arm had a notifiy_die that did something totally different, I renamed it to
    arm_notify_die as part of the patch and made it static to the file it's
    declared and used at.  avr32 used to pass slightly less information through
    this interface and I brought it into line with the other architectures.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix vmalloc_sync_all bustage]
    [bryan.wu@analog.com: fix vmalloc_sync_all in nommu]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Bryan Wu <bryan.wu@analog.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 5d9ce7deb4a7..75d491448e45 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -453,7 +453,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	info.si_errno = 0;
 	info.si_code  = inf->code;
 	info.si_addr  = (void __user *)addr;
-	notify_die("", regs, &info, fsr, 0);
+	arm_notify_die("", regs, &info, fsr, 0);
 }
 
 asmlinkage void __exception

commit 0f0a00beb80624a446ba7c0152cd171008eeab2e
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Mar 3 19:45:25 2007 +0000

    [ARM] Remove needless linux/ptrace.h includes
    
    Lots of places in arch/arm were needlessly including linux/ptrace.h,
    resumably because we used to pass a struct pt_regs to interrupt
    handlers.  Now that we don't, all these ptrace.h includes are
    redundant.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index fa2d107f0d44..5d9ce7deb4a7 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -10,7 +10,6 @@
  */
 #include <linux/module.h>
 #include <linux/signal.h>
-#include <linux/ptrace.h>
 #include <linux/mm.h>
 #include <linux/init.h>
 

commit 7ab3f8d595a1b1e5cf8d726b72fd476fe0d0226c
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Fri Mar 2 15:01:36 2007 +0000

    [ARM] Add ability to dump exception stacks to kernel backtraces
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 9fd6d2eafb40..fa2d107f0d44 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -438,7 +438,7 @@ hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *)
 /*
  * Dispatch a data abort to the relevant handler.
  */
-asmlinkage void
+asmlinkage void __exception
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = fsr_info + (fsr & 15) + ((fsr & (1 << 10)) >> 6);
@@ -457,7 +457,7 @@ do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	notify_die("", regs, &info, fsr, 0);
 }
 
-asmlinkage void
+asmlinkage void __exception
 do_PrefetchAbort(unsigned long addr, struct pt_regs *regs)
 {
 	do_translation_fault(addr, 0, regs);

commit 6edaf68a87d17570790fd55f0c451a29ec1d6703
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Dec 6 20:32:18 2006 -0800

    [PATCH] mm: arch do_page_fault() vs in_atomic()
    
    In light of the recent pagefault and filemap_copy_from_user work I've gone
    through all the arch pagefault handlers to make sure the inc_preempt_count()
    'feature' works as expected.
    
    Several sections of code (including the new filemap_copy_from_user) rely on
    the fact that faults do not take locks under increased preempt count.
    
    arch/x86_64 - good
    arch/powerpc - good
    arch/cris - fixed
    arch/i386 - good
    arch/parisc - fixed
    arch/sh - good
    arch/sparc - good
    arch/s390 - good
    arch/m68k - fixed
    arch/ppc - good
    arch/alpha - fixed
    arch/mips - good
    arch/sparc64 - good
    arch/ia64 - good
    arch/arm - fixed
    arch/um - good
    arch/avr32 - good
    arch/h8300 - NA
    arch/m32r - good
    arch/v850 - good
    arch/frv - fixed
    arch/m68knommu - NA
    arch/arm26 - fixed
    arch/sh64 - fixed
    arch/xtensa - good
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 5e658a874498..9fd6d2eafb40 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -230,7 +230,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
 	 */
-	if (in_interrupt() || !mm)
+	if (in_atomic() || !mm)
 		goto no_context;
 
 	/*

commit f400e198b2ed26ce55b22a1412ded0896e7516ac
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Sep 29 02:00:07 2006 -0700

    [PATCH] pidspace: is_init()
    
    This is an updated version of Eric Biederman's is_init() patch.
    (http://lkml.org/lkml/2006/2/6/280).  It applies cleanly to 2.6.18-rc3 and
    replaces a few more instances of ->pid == 1 with is_init().
    
    Further, is_init() checks pid and thus removes dependency on Eric's other
    patches for now.
    
    Eric's original description:
    
            There are a lot of places in the kernel where we test for init
            because we give it special properties.  Most  significantly init
            must not die.  This results in code all over the kernel test
            ->pid == 1.
    
            Introduce is_init to capture this case.
    
            With multiple pid spaces for all of the cases affected we are
            looking for only the first process on the system, not some other
            process that has pid == 1.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: <lxc-devel@lists.sourceforge.net>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index a5b33ff3924e..5e658a874498 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -198,7 +198,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		return fault;
 	}
 
-	if (tsk->pid != 1)
+	if (!is_init(tsk))
 		goto out;
 
 	/*

commit df67b3daea602728b51325a4debaeeb912ee51d1
Author: Jason Baron <jbaron@redhat.com>
Date:   Fri Sep 29 01:58:58 2006 -0700

    [PATCH] make PROT_WRITE imply PROT_READ
    
    Make PROT_WRITE imply PROT_READ for a number of architectures which don't
    support write only in hardware.
    
    While looking at this, I noticed that some architectures which do not
    support write only mappings already take the exact same approach.  For
    example, in arch/alpha/mm/fault.c:
    
    "
            if (cause < 0) {
                    if (!(vma->vm_flags & VM_EXEC))
                            goto bad_area;
            } else if (!cause) {
                    /* Allow reads even for write-only mappings */
                    if (!(vma->vm_flags & (VM_READ | VM_WRITE)))
                            goto bad_area;
            } else {
                    if (!(vma->vm_flags & VM_WRITE))
                            goto bad_area;
            }
    "
    
    Thus, this patch brings other architectures which do not support write only
    mappings in-line and consistent with the rest.  I've verified the patch on
    ia64, x86_64 and x86.
    
    Additional discussion:
    
    Several architectures, including x86, can not support write-only mappings.
    The pte for x86 reserves a single bit for protection and its two states are
    read only or read/write.  Thus, write only is not supported in h/w.
    
    Currently, if i 'mmap' a page write-only, the first read attempt on that page
    creates a page fault and will SEGV.  That check is enforced in
    arch/blah/mm/fault.c.  However, if i first write that page it will fault in
    and the pte will be set to read/write.  Thus, any subsequent reads to the page
    will succeed.  It is this inconsistency in behavior that this patch is
    attempting to address.  Furthermore, if the page is swapped out, and then
    brought back the first read will also cause a SEGV.  Thus, any arbitrary read
    on a page can potentially result in a SEGV.
    
    According to the SuSv3 spec, "if the application requests only PROT_WRITE, the
    implementation may also allow read access." Also as mentioned, some
    archtectures, such as alpha, shown above already take the approach that i am
    suggesting.
    
    The counter-argument to this raised by Arjan, is that the kernel is enforcing
    the write only mapping the best it can given the h/w limitations.  This is
    true, however Alan Cox, and myself would argue that the inconsitency in
    behavior, that is applications can sometimes work/sometimes fails is highly
    undesireable.  If you read through the thread, i think people, came to an
    agreement on the last patch i posted, as nobody has objected to it...
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Andi Kleen <ak@muc.de>
    Acked-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Ian Molton <spyro@f2s.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index f0943d160ffe..a5b33ff3924e 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -171,7 +171,7 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 	if (fsr & (1 << 11)) /* write? */
 		mask = VM_WRITE;
 	else
-		mask = VM_READ|VM_EXEC;
+		mask = VM_READ|VM_EXEC|VM_WRITE;
 
 	fault = VM_FAULT_BADACCESS;
 	if (!(vma->vm_flags & mask))

commit e5beac371af0af47bcbd6819f4c2a0a2721a1735
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Sep 27 16:13:48 2006 +0100

    [ARM] do_bad_area() always takes current and current->active_mm
    
    Since do_bad_area() always takes the currently active task and
    (supposed to) take the currently active MM, there's no point passing
    them to this function.  Instead, obtain references to them inside
    do_bad_area().
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index c5e0622c7765..f0943d160ffe 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -131,10 +131,11 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 	force_sig_info(sig, &si, tsk);
 }
 
-void
-do_bad_area(struct task_struct *tsk, struct mm_struct *mm, unsigned long addr,
-	    unsigned int fsr, struct pt_regs *regs)
+void do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
+	struct task_struct *tsk = current;
+	struct mm_struct *mm = tsk->active_mm;
+
 	/*
 	 * If we are in kernel mode at this point, we
 	 * have no context to handle this fault with.
@@ -319,7 +320,6 @@ static int
 do_translation_fault(unsigned long addr, unsigned int fsr,
 		     struct pt_regs *regs)
 {
-	struct task_struct *tsk;
 	unsigned int index;
 	pgd_t *pgd, *pgd_k;
 	pmd_t *pmd, *pmd_k;
@@ -351,9 +351,7 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 	return 0;
 
 bad_area:
-	tsk = current;
-
-	do_bad_area(tsk, tsk->active_mm, addr, fsr, regs);
+	do_bad_area(addr, fsr, regs);
 	return 0;
 }
 
@@ -364,8 +362,7 @@ do_translation_fault(unsigned long addr, unsigned int fsr,
 static int
 do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
-	struct task_struct *tsk = current;
-	do_bad_area(tsk, tsk->active_mm, addr, fsr, regs);
+	do_bad_area(addr, fsr, regs);
 	return 0;
 }
 

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 4a884baf3b9c..c5e0622c7765 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -8,7 +8,6 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
-#include <linux/config.h>
 #include <linux/module.h>
 #include <linux/signal.h>
 #include <linux/ptrace.h>

commit 840ff6a4f6174d7fe19c206b5f36ff64123a2f45
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Sep 20 17:52:13 2005 +0100

    [ARM] Prevent deadlock in page fault handler
    
    As per x86, we may deadlock while trying to get the mmap semaphore.
    Implement the same fix, which allows (eg) recursive faults to cause
    an oops instead of deadlocking.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 0b6c4db44e08..4a884baf3b9c 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -233,7 +233,17 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (in_interrupt() || !mm)
 		goto no_context;
 
-	down_read(&mm->mmap_sem);
+	/*
+	 * As per x86, we may deadlock here.  However, since the kernel only
+	 * validly references user space from well defined areas of the code,
+	 * we can bug out early if this is from code which shouldn't.
+	 */
+	if (!down_read_trylock(&mm->mmap_sem)) {
+		if (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))
+			goto no_context;
+		down_read(&mm->mmap_sem);
+	}
+
 	fault = __do_page_fault(mm, addr, fsr, tsk);
 	up_read(&mm->mmap_sem);
 

commit ff2afb9df607dfcaacdaf67ea84b773c6fb08f4c
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Aug 4 14:17:33 2005 +0100

    [PATCH] ARM: Fix ARM fault handler for get_user_pages() fixes.
    
    The ARM fault handler is optimised to make the fast path, err, fast.
    The renumbering of the VM_FAULT_* codes broke this because numbers
    were used instead of the definitions.  Fix this.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 65bfe84b6d67..0b6c4db44e08 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -238,9 +238,9 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	up_read(&mm->mmap_sem);
 
 	/*
-	 * Handle the "normal" case first
+	 * Handle the "normal" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
 	 */
-	if (fault > 0)
+	if (fault >= VM_FAULT_MINOR)
 		return 0;
 
 	/*
@@ -261,7 +261,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 		do_exit(SIGKILL);
 		return 0;
 
-	case 0:
+	case VM_FAULT_SIGBUS:
 		/*
 		 * We had some memory, but were unable to
 		 * successfully fix up this page fault.

commit cfb0810eab39d1162f45b73fc96f45ab1cbcbe8b
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Jun 30 11:06:49 2005 +0100

    [PATCH] ARM: Don't try to send a signal to pid0
    
    If we receive an unrecognised abort during boot, don't try to
    send a signal to pid0, but instead report the current state.
    This leads to less confusing debug reports.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index e25b4fd8412c..65bfe84b6d67 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -372,49 +372,50 @@ do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 static struct fsr_info {
 	int	(*fn)(unsigned long addr, unsigned int fsr, struct pt_regs *regs);
 	int	sig;
+	int	code;
 	const char *name;
 } fsr_info[] = {
 	/*
 	 * The following are the standard ARMv3 and ARMv4 aborts.  ARMv5
 	 * defines these to be "precise" aborts.
 	 */
-	{ do_bad,		SIGSEGV, "vector exception"		   },
-	{ do_bad,		SIGILL,	 "alignment exception"		   },
-	{ do_bad,		SIGKILL, "terminal exception"		   },
-	{ do_bad,		SIGILL,	 "alignment exception"		   },
-	{ do_bad,		SIGBUS,	 "external abort on linefetch"	   },
-	{ do_translation_fault,	SIGSEGV, "section translation fault"	   },
-	{ do_bad,		SIGBUS,	 "external abort on linefetch"	   },
-	{ do_page_fault,	SIGSEGV, "page translation fault"	   },
-	{ do_bad,		SIGBUS,	 "external abort on non-linefetch" },
-	{ do_bad,		SIGSEGV, "section domain fault"		   },
-	{ do_bad,		SIGBUS,	 "external abort on non-linefetch" },
-	{ do_bad,		SIGSEGV, "page domain fault"		   },
-	{ do_bad,		SIGBUS,	 "external abort on translation"   },
-	{ do_sect_fault,	SIGSEGV, "section permission fault"	   },
-	{ do_bad,		SIGBUS,	 "external abort on translation"   },
-	{ do_page_fault,	SIGSEGV, "page permission fault"	   },
+	{ do_bad,		SIGSEGV, 0,		"vector exception"		   },
+	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
+	{ do_bad,		SIGKILL, 0,		"terminal exception"		   },
+	{ do_bad,		SIGILL,	 BUS_ADRALN,	"alignment exception"		   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
+	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	"section translation fault"	   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on linefetch"	   },
+	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	"page translation fault"	   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"section domain fault"		   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on non-linefetch"  },
+	{ do_bad,		SIGSEGV, SEGV_ACCERR,	"page domain fault"		   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
+	{ do_sect_fault,	SIGSEGV, SEGV_ACCERR,	"section permission fault"	   },
+	{ do_bad,		SIGBUS,	 0,		"external abort on translation"	   },
+	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	"page permission fault"		   },
 	/*
 	 * The following are "imprecise" aborts, which are signalled by bit
 	 * 10 of the FSR, and may not be recoverable.  These are only
 	 * supported if the CPU abort handler supports bit 10.
 	 */
-	{ do_bad,		SIGBUS,  "unknown 16"			   },
-	{ do_bad,		SIGBUS,  "unknown 17"			   },
-	{ do_bad,		SIGBUS,  "unknown 18"			   },
-	{ do_bad,		SIGBUS,  "unknown 19"			   },
-	{ do_bad,		SIGBUS,  "lock abort"			   }, /* xscale */
-	{ do_bad,		SIGBUS,  "unknown 21"			   },
-	{ do_bad,		SIGBUS,  "imprecise external abort"	   }, /* xscale */
-	{ do_bad,		SIGBUS,  "unknown 23"			   },
-	{ do_bad,		SIGBUS,  "dcache parity error"		   }, /* xscale */
-	{ do_bad,		SIGBUS,  "unknown 25"			   },
-	{ do_bad,		SIGBUS,  "unknown 26"			   },
-	{ do_bad,		SIGBUS,  "unknown 27"			   },
-	{ do_bad,		SIGBUS,  "unknown 28"			   },
-	{ do_bad,		SIGBUS,  "unknown 29"			   },
-	{ do_bad,		SIGBUS,  "unknown 30"			   },
-	{ do_bad,		SIGBUS,  "unknown 31"			   }
+	{ do_bad,		SIGBUS,  0,		"unknown 16"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 17"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 18"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 19"			   },
+	{ do_bad,		SIGBUS,  0,		"lock abort"			   }, /* xscale */
+	{ do_bad,		SIGBUS,  0,		"unknown 21"			   },
+	{ do_bad,		SIGBUS,  BUS_OBJERR,	"imprecise external abort"	   }, /* xscale */
+	{ do_bad,		SIGBUS,  0,		"unknown 23"			   },
+	{ do_bad,		SIGBUS,  0,		"dcache parity error"		   }, /* xscale */
+	{ do_bad,		SIGBUS,  0,		"unknown 25"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 26"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 27"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 28"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 29"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 30"			   },
+	{ do_bad,		SIGBUS,  0,		"unknown 31"			   }
 };
 
 void __init
@@ -435,15 +436,19 @@ asmlinkage void
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = fsr_info + (fsr & 15) + ((fsr & (1 << 10)) >> 6);
+	struct siginfo info;
 
 	if (!inf->fn(addr, fsr, regs))
 		return;
 
 	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
 		inf->name, fsr, addr);
-	force_sig(inf->sig, current);
-	show_pte(current->mm, addr);
-	die_if_kernel("Oops", regs, 0);
+
+	info.si_signo = inf->sig;
+	info.si_errno = 0;
+	info.si_code  = inf->code;
+	info.si_addr  = (void __user *)addr;
+	notify_die("", regs, &info, fsr, 0);
 }
 
 asmlinkage void

commit 2d137c24e9f433e37ffd10b3d5f418157589a8d2
Author: akpm@osdl.org <akpm@osdl.org>
Date:   Sat Apr 16 15:23:55 2005 -0700

    [PATCH] arm: fix SIGBUS handling
    
    )
    
    
    From: Russell King <rmk+lkml@arm.linux.org.uk>
    
    ARM wasn't raising a SIGBUS with a siginfo structure.  Fix
    __do_user_fault() to allow us to use it for SIGBUS conditions, and arrange
    for the sigbus path to use this.
    
    We need to prevent the siginfo code being called if we do not have a user
    space context to call it, so consolidate the "user_mode()" tests.
    
    Thanks to Ian Campbell who spotted this oversight.
    
    Signed-off-by: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index 29be1c018949..e25b4fd8412c 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -108,14 +108,15 @@ __do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
  */
 static void
 __do_user_fault(struct task_struct *tsk, unsigned long addr,
-		unsigned int fsr, int code, struct pt_regs *regs)
+		unsigned int fsr, unsigned int sig, int code,
+		struct pt_regs *regs)
 {
 	struct siginfo si;
 
 #ifdef CONFIG_DEBUG_USER
 	if (user_debug & UDBG_SEGV) {
-		printk(KERN_DEBUG "%s: unhandled page fault at 0x%08lx, code 0x%03x\n",
-		       tsk->comm, addr, fsr);
+		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
+		       tsk->comm, sig, addr, fsr);
 		show_pte(tsk->mm, addr);
 		show_regs(regs);
 	}
@@ -124,11 +125,11 @@ __do_user_fault(struct task_struct *tsk, unsigned long addr,
 	tsk->thread.address = addr;
 	tsk->thread.error_code = fsr;
 	tsk->thread.trap_no = 14;
-	si.si_signo = SIGSEGV;
+	si.si_signo = sig;
 	si.si_errno = 0;
 	si.si_code = code;
 	si.si_addr = (void __user *)addr;
-	force_sig_info(SIGSEGV, &si, tsk);
+	force_sig_info(sig, &si, tsk);
 }
 
 void
@@ -140,7 +141,7 @@ do_bad_area(struct task_struct *tsk, struct mm_struct *mm, unsigned long addr,
 	 * have no context to handle this fault with.
 	 */
 	if (user_mode(regs))
-		__do_user_fault(tsk, addr, fsr, SEGV_MAPERR, regs);
+		__do_user_fault(tsk, addr, fsr, SIGSEGV, SEGV_MAPERR, regs);
 	else
 		__do_kernel_fault(mm, addr, fsr, regs);
 }
@@ -201,10 +202,11 @@ __do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
 		goto out;
 
 	/*
-	 * If we are out of memory for pid1,
-	 * sleep for a while and retry
+	 * If we are out of memory for pid1, sleep for a while and retry
 	 */
+	up_read(&mm->mmap_sem);
 	yield();
+	down_read(&mm->mmap_sem);
 	goto survive;
 
 check_stack:
@@ -219,7 +221,7 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	struct task_struct *tsk;
 	struct mm_struct *mm;
-	int fault;
+	int fault, sig, code;
 
 	tsk = current;
 	mm  = tsk->mm;
@@ -241,13 +243,6 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (fault > 0)
 		return 0;
 
-	/*
-	 * We had some memory, but were unable to
-	 * successfully fix up this page fault.
-	 */
-	if (fault == 0)
-		goto do_sigbus;
-
 	/*
 	 * If we are in kernel mode at this point, we
 	 * have no context to handle this fault with.
@@ -255,42 +250,39 @@ do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 	if (!user_mode(regs))
 		goto no_context;
 
-	if (fault == VM_FAULT_OOM) {
+	switch (fault) {
+	case VM_FAULT_OOM:
 		/*
-		 * We ran out of memory, or some other thing happened to
-		 * us that made us unable to handle the page fault gracefully.
+		 * We ran out of memory, or some other thing
+		 * happened to us that made us unable to handle
+		 * the page fault gracefully.
 		 */
 		printk("VM: killing process %s\n", tsk->comm);
 		do_exit(SIGKILL);
-	} else
-		__do_user_fault(tsk, addr, fsr, fault == VM_FAULT_BADACCESS ?
-				SEGV_ACCERR : SEGV_MAPERR, regs);
-	return 0;
+		return 0;
 
+	case 0:
+		/*
+		 * We had some memory, but were unable to
+		 * successfully fix up this page fault.
+		 */
+		sig = SIGBUS;
+		code = BUS_ADRERR;
+		break;
 
-/*
- * We ran out of memory, or some other thing happened to us that made
- * us unable to handle the page fault gracefully.
- */
-do_sigbus:
-	/*
-	 * Send a sigbus, regardless of whether we were in kernel
-	 * or user mode.
-	 */
-	tsk->thread.address = addr;
-	tsk->thread.error_code = fsr;
-	tsk->thread.trap_no = 14;
-	force_sig(SIGBUS, tsk);
-#ifdef CONFIG_DEBUG_USER
-	if (user_debug & UDBG_BUS) {
-		printk(KERN_DEBUG "%s: sigbus at 0x%08lx, pc=0x%08lx\n",
-			current->comm, addr, instruction_pointer(regs));
+	default:
+		/*
+		 * Something tried to access memory that
+		 * isn't in our memory map..
+		 */
+		sig = SIGSEGV;
+		code = fault == VM_FAULT_BADACCESS ?
+			SEGV_ACCERR : SEGV_MAPERR;
+		break;
 	}
-#endif
 
-	/* Kernel mode? Handle exceptions or die */
-	if (user_mode(regs))
-		return 0;
+	__do_user_fault(tsk, addr, fsr, sig, code, regs);
+	return 0;
 
 no_context:
 	__do_kernel_fault(mm, addr, fsr, regs);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
new file mode 100644
index 000000000000..29be1c018949
--- /dev/null
+++ b/arch/arm/mm/fault.c
@@ -0,0 +1,462 @@
+/*
+ *  linux/arch/arm/mm/fault.c
+ *
+ *  Copyright (C) 1995  Linus Torvalds
+ *  Modifications for ARM processor (c) 1995-2004 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/signal.h>
+#include <linux/ptrace.h>
+#include <linux/mm.h>
+#include <linux/init.h>
+
+#include <asm/system.h>
+#include <asm/pgtable.h>
+#include <asm/tlbflush.h>
+#include <asm/uaccess.h>
+
+#include "fault.h"
+
+/*
+ * This is useful to dump out the page tables associated with
+ * 'addr' in mm 'mm'.
+ */
+void show_pte(struct mm_struct *mm, unsigned long addr)
+{
+	pgd_t *pgd;
+
+	if (!mm)
+		mm = &init_mm;
+
+	printk(KERN_ALERT "pgd = %p\n", mm->pgd);
+	pgd = pgd_offset(mm, addr);
+	printk(KERN_ALERT "[%08lx] *pgd=%08lx", addr, pgd_val(*pgd));
+
+	do {
+		pmd_t *pmd;
+		pte_t *pte;
+
+		if (pgd_none(*pgd))
+			break;
+
+		if (pgd_bad(*pgd)) {
+			printk("(bad)");
+			break;
+		}
+
+		pmd = pmd_offset(pgd, addr);
+#if PTRS_PER_PMD != 1
+		printk(", *pmd=%08lx", pmd_val(*pmd));
+#endif
+
+		if (pmd_none(*pmd))
+			break;
+
+		if (pmd_bad(*pmd)) {
+			printk("(bad)");
+			break;
+		}
+
+#ifndef CONFIG_HIGHMEM
+		/* We must not map this if we have highmem enabled */
+		pte = pte_offset_map(pmd, addr);
+		printk(", *pte=%08lx", pte_val(*pte));
+		printk(", *ppte=%08lx", pte_val(pte[-PTRS_PER_PTE]));
+		pte_unmap(pte);
+#endif
+	} while(0);
+
+	printk("\n");
+}
+
+/*
+ * Oops.  The kernel tried to access some page that wasn't present.
+ */
+static void
+__do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
+		  struct pt_regs *regs)
+{
+	/*
+	 * Are we prepared to handle this kernel fault?
+	 */
+	if (fixup_exception(regs))
+		return;
+
+	/*
+	 * No handler, we'll have to terminate things with extreme prejudice.
+	 */
+	bust_spinlocks(1);
+	printk(KERN_ALERT
+		"Unable to handle kernel %s at virtual address %08lx\n",
+		(addr < PAGE_SIZE) ? "NULL pointer dereference" :
+		"paging request", addr);
+
+	show_pte(mm, addr);
+	die("Oops", regs, fsr);
+	bust_spinlocks(0);
+	do_exit(SIGKILL);
+}
+
+/*
+ * Something tried to access memory that isn't in our memory map..
+ * User mode accesses just cause a SIGSEGV
+ */
+static void
+__do_user_fault(struct task_struct *tsk, unsigned long addr,
+		unsigned int fsr, int code, struct pt_regs *regs)
+{
+	struct siginfo si;
+
+#ifdef CONFIG_DEBUG_USER
+	if (user_debug & UDBG_SEGV) {
+		printk(KERN_DEBUG "%s: unhandled page fault at 0x%08lx, code 0x%03x\n",
+		       tsk->comm, addr, fsr);
+		show_pte(tsk->mm, addr);
+		show_regs(regs);
+	}
+#endif
+
+	tsk->thread.address = addr;
+	tsk->thread.error_code = fsr;
+	tsk->thread.trap_no = 14;
+	si.si_signo = SIGSEGV;
+	si.si_errno = 0;
+	si.si_code = code;
+	si.si_addr = (void __user *)addr;
+	force_sig_info(SIGSEGV, &si, tsk);
+}
+
+void
+do_bad_area(struct task_struct *tsk, struct mm_struct *mm, unsigned long addr,
+	    unsigned int fsr, struct pt_regs *regs)
+{
+	/*
+	 * If we are in kernel mode at this point, we
+	 * have no context to handle this fault with.
+	 */
+	if (user_mode(regs))
+		__do_user_fault(tsk, addr, fsr, SEGV_MAPERR, regs);
+	else
+		__do_kernel_fault(mm, addr, fsr, regs);
+}
+
+#define VM_FAULT_BADMAP		(-20)
+#define VM_FAULT_BADACCESS	(-21)
+
+static int
+__do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,
+		struct task_struct *tsk)
+{
+	struct vm_area_struct *vma;
+	int fault, mask;
+
+	vma = find_vma(mm, addr);
+	fault = VM_FAULT_BADMAP;
+	if (!vma)
+		goto out;
+	if (vma->vm_start > addr)
+		goto check_stack;
+
+	/*
+	 * Ok, we have a good vm_area for this
+	 * memory access, so we can handle it.
+	 */
+good_area:
+	if (fsr & (1 << 11)) /* write? */
+		mask = VM_WRITE;
+	else
+		mask = VM_READ|VM_EXEC;
+
+	fault = VM_FAULT_BADACCESS;
+	if (!(vma->vm_flags & mask))
+		goto out;
+
+	/*
+	 * If for any reason at all we couldn't handle
+	 * the fault, make sure we exit gracefully rather
+	 * than endlessly redo the fault.
+	 */
+survive:
+	fault = handle_mm_fault(mm, vma, addr & PAGE_MASK, fsr & (1 << 11));
+
+	/*
+	 * Handle the "normal" cases first - successful and sigbus
+	 */
+	switch (fault) {
+	case VM_FAULT_MAJOR:
+		tsk->maj_flt++;
+		return fault;
+	case VM_FAULT_MINOR:
+		tsk->min_flt++;
+	case VM_FAULT_SIGBUS:
+		return fault;
+	}
+
+	if (tsk->pid != 1)
+		goto out;
+
+	/*
+	 * If we are out of memory for pid1,
+	 * sleep for a while and retry
+	 */
+	yield();
+	goto survive;
+
+check_stack:
+	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
+		goto good_area;
+out:
+	return fault;
+}
+
+static int
+do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
+{
+	struct task_struct *tsk;
+	struct mm_struct *mm;
+	int fault;
+
+	tsk = current;
+	mm  = tsk->mm;
+
+	/*
+	 * If we're in an interrupt or have no user
+	 * context, we must not take the fault..
+	 */
+	if (in_interrupt() || !mm)
+		goto no_context;
+
+	down_read(&mm->mmap_sem);
+	fault = __do_page_fault(mm, addr, fsr, tsk);
+	up_read(&mm->mmap_sem);
+
+	/*
+	 * Handle the "normal" case first
+	 */
+	if (fault > 0)
+		return 0;
+
+	/*
+	 * We had some memory, but were unable to
+	 * successfully fix up this page fault.
+	 */
+	if (fault == 0)
+		goto do_sigbus;
+
+	/*
+	 * If we are in kernel mode at this point, we
+	 * have no context to handle this fault with.
+	 */
+	if (!user_mode(regs))
+		goto no_context;
+
+	if (fault == VM_FAULT_OOM) {
+		/*
+		 * We ran out of memory, or some other thing happened to
+		 * us that made us unable to handle the page fault gracefully.
+		 */
+		printk("VM: killing process %s\n", tsk->comm);
+		do_exit(SIGKILL);
+	} else
+		__do_user_fault(tsk, addr, fsr, fault == VM_FAULT_BADACCESS ?
+				SEGV_ACCERR : SEGV_MAPERR, regs);
+	return 0;
+
+
+/*
+ * We ran out of memory, or some other thing happened to us that made
+ * us unable to handle the page fault gracefully.
+ */
+do_sigbus:
+	/*
+	 * Send a sigbus, regardless of whether we were in kernel
+	 * or user mode.
+	 */
+	tsk->thread.address = addr;
+	tsk->thread.error_code = fsr;
+	tsk->thread.trap_no = 14;
+	force_sig(SIGBUS, tsk);
+#ifdef CONFIG_DEBUG_USER
+	if (user_debug & UDBG_BUS) {
+		printk(KERN_DEBUG "%s: sigbus at 0x%08lx, pc=0x%08lx\n",
+			current->comm, addr, instruction_pointer(regs));
+	}
+#endif
+
+	/* Kernel mode? Handle exceptions or die */
+	if (user_mode(regs))
+		return 0;
+
+no_context:
+	__do_kernel_fault(mm, addr, fsr, regs);
+	return 0;
+}
+
+/*
+ * First Level Translation Fault Handler
+ *
+ * We enter here because the first level page table doesn't contain
+ * a valid entry for the address.
+ *
+ * If the address is in kernel space (>= TASK_SIZE), then we are
+ * probably faulting in the vmalloc() area.
+ *
+ * If the init_task's first level page tables contains the relevant
+ * entry, we copy the it to this task.  If not, we send the process
+ * a signal, fixup the exception, or oops the kernel.
+ *
+ * NOTE! We MUST NOT take any locks for this case. We may be in an
+ * interrupt or a critical region, and should only copy the information
+ * from the master page table, nothing more.
+ */
+static int
+do_translation_fault(unsigned long addr, unsigned int fsr,
+		     struct pt_regs *regs)
+{
+	struct task_struct *tsk;
+	unsigned int index;
+	pgd_t *pgd, *pgd_k;
+	pmd_t *pmd, *pmd_k;
+
+	if (addr < TASK_SIZE)
+		return do_page_fault(addr, fsr, regs);
+
+	index = pgd_index(addr);
+
+	/*
+	 * FIXME: CP15 C1 is write only on ARMv3 architectures.
+	 */
+	pgd = cpu_get_pgd() + index;
+	pgd_k = init_mm.pgd + index;
+
+	if (pgd_none(*pgd_k))
+		goto bad_area;
+
+	if (!pgd_present(*pgd))
+		set_pgd(pgd, *pgd_k);
+
+	pmd_k = pmd_offset(pgd_k, addr);
+	pmd   = pmd_offset(pgd, addr);
+
+	if (pmd_none(*pmd_k))
+		goto bad_area;
+
+	copy_pmd(pmd, pmd_k);
+	return 0;
+
+bad_area:
+	tsk = current;
+
+	do_bad_area(tsk, tsk->active_mm, addr, fsr, regs);
+	return 0;
+}
+
+/*
+ * Some section permission faults need to be handled gracefully.
+ * They can happen due to a __{get,put}_user during an oops.
+ */
+static int
+do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
+{
+	struct task_struct *tsk = current;
+	do_bad_area(tsk, tsk->active_mm, addr, fsr, regs);
+	return 0;
+}
+
+/*
+ * This abort handler always returns "fault".
+ */
+static int
+do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
+{
+	return 1;
+}
+
+static struct fsr_info {
+	int	(*fn)(unsigned long addr, unsigned int fsr, struct pt_regs *regs);
+	int	sig;
+	const char *name;
+} fsr_info[] = {
+	/*
+	 * The following are the standard ARMv3 and ARMv4 aborts.  ARMv5
+	 * defines these to be "precise" aborts.
+	 */
+	{ do_bad,		SIGSEGV, "vector exception"		   },
+	{ do_bad,		SIGILL,	 "alignment exception"		   },
+	{ do_bad,		SIGKILL, "terminal exception"		   },
+	{ do_bad,		SIGILL,	 "alignment exception"		   },
+	{ do_bad,		SIGBUS,	 "external abort on linefetch"	   },
+	{ do_translation_fault,	SIGSEGV, "section translation fault"	   },
+	{ do_bad,		SIGBUS,	 "external abort on linefetch"	   },
+	{ do_page_fault,	SIGSEGV, "page translation fault"	   },
+	{ do_bad,		SIGBUS,	 "external abort on non-linefetch" },
+	{ do_bad,		SIGSEGV, "section domain fault"		   },
+	{ do_bad,		SIGBUS,	 "external abort on non-linefetch" },
+	{ do_bad,		SIGSEGV, "page domain fault"		   },
+	{ do_bad,		SIGBUS,	 "external abort on translation"   },
+	{ do_sect_fault,	SIGSEGV, "section permission fault"	   },
+	{ do_bad,		SIGBUS,	 "external abort on translation"   },
+	{ do_page_fault,	SIGSEGV, "page permission fault"	   },
+	/*
+	 * The following are "imprecise" aborts, which are signalled by bit
+	 * 10 of the FSR, and may not be recoverable.  These are only
+	 * supported if the CPU abort handler supports bit 10.
+	 */
+	{ do_bad,		SIGBUS,  "unknown 16"			   },
+	{ do_bad,		SIGBUS,  "unknown 17"			   },
+	{ do_bad,		SIGBUS,  "unknown 18"			   },
+	{ do_bad,		SIGBUS,  "unknown 19"			   },
+	{ do_bad,		SIGBUS,  "lock abort"			   }, /* xscale */
+	{ do_bad,		SIGBUS,  "unknown 21"			   },
+	{ do_bad,		SIGBUS,  "imprecise external abort"	   }, /* xscale */
+	{ do_bad,		SIGBUS,  "unknown 23"			   },
+	{ do_bad,		SIGBUS,  "dcache parity error"		   }, /* xscale */
+	{ do_bad,		SIGBUS,  "unknown 25"			   },
+	{ do_bad,		SIGBUS,  "unknown 26"			   },
+	{ do_bad,		SIGBUS,  "unknown 27"			   },
+	{ do_bad,		SIGBUS,  "unknown 28"			   },
+	{ do_bad,		SIGBUS,  "unknown 29"			   },
+	{ do_bad,		SIGBUS,  "unknown 30"			   },
+	{ do_bad,		SIGBUS,  "unknown 31"			   }
+};
+
+void __init
+hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
+		int sig, const char *name)
+{
+	if (nr >= 0 && nr < ARRAY_SIZE(fsr_info)) {
+		fsr_info[nr].fn   = fn;
+		fsr_info[nr].sig  = sig;
+		fsr_info[nr].name = name;
+	}
+}
+
+/*
+ * Dispatch a data abort to the relevant handler.
+ */
+asmlinkage void
+do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
+{
+	const struct fsr_info *inf = fsr_info + (fsr & 15) + ((fsr & (1 << 10)) >> 6);
+
+	if (!inf->fn(addr, fsr, regs))
+		return;
+
+	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
+		inf->name, fsr, addr);
+	force_sig(inf->sig, current);
+	show_pte(current->mm, addr);
+	die_if_kernel("Oops", regs, 0);
+}
+
+asmlinkage void
+do_PrefetchAbort(unsigned long addr, struct pt_regs *regs)
+{
+	do_translation_fault(addr, 0, regs);
+}
+
