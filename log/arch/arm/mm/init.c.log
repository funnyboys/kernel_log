commit 84e6ffb2c49c7901a9efb54b497d2eb84c3bef8c
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Jun 4 16:46:19 2020 -0700

    arm: add support for folded p4d page tables
    
    Implement primitives necessary for the 4th level folding, add walks of p4d
    level where appropriate, and remove __ARCH_USE_5LEVEL_HACK.
    
    [rppt@linux.ibm.com: fix kexec]
      Link: http://lkml.kernel.org/r/20200508174232.GA759899@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: James Morse <james.morse@arm.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Julien Thierry <julien.thierry.kdev@gmail.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200414153455.21744-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4e43455fab84..01e18e43b174 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -519,7 +519,7 @@ static inline void section_update(unsigned long addr, pmdval_t mask,
 {
 	pmd_t *pmd;
 
-	pmd = pmd_offset(pud_offset(pgd_offset(mm, addr), addr), addr);
+	pmd = pmd_offset(pud_offset(p4d_offset(pgd_offset(mm, addr), addr), addr), addr);
 
 #ifdef CONFIG_ARM_LPAE
 	pmd[0] = __pmd((pmd_val(pmd[0]) & mask) | prot);

commit a32c1c61212d93a8fa5bab56605982d2451852bb
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Wed Jun 3 15:57:19 2020 -0700

    arm: simplify detection of memory zone boundaries
    
    free_area_init() only requires the definition of maximal PFN for each of
    the supported zone rater than calculation of actual zone sizes and the
    sizes of the holes between the zones.
    
    After removal of CONFIG_HAVE_MEMBLOCK_NODE_MAP the free_area_init() is
    available to all architectures.
    
    Using this function instead of free_area_init_node() simplifies the zone
    detection.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Hoan Tran <hoan@os.amperecomputing.com>      [arm64]
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200412194859.12663-8-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 054be44d1cdb..4e43455fab84 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -92,18 +92,6 @@ EXPORT_SYMBOL(arm_dma_zone_size);
  */
 phys_addr_t arm_dma_limit;
 unsigned long arm_dma_pfn_limit;
-
-static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
-	unsigned long dma_size)
-{
-	if (size[0] <= dma_size)
-		return;
-
-	size[ZONE_NORMAL] = size[0] - dma_size;
-	size[ZONE_DMA] = dma_size;
-	hole[ZONE_NORMAL] = hole[0];
-	hole[ZONE_DMA] = 0;
-}
 #endif
 
 void __init setup_dma_zone(const struct machine_desc *mdesc)
@@ -121,56 +109,16 @@ void __init setup_dma_zone(const struct machine_desc *mdesc)
 static void __init zone_sizes_init(unsigned long min, unsigned long max_low,
 	unsigned long max_high)
 {
-	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
-	struct memblock_region *reg;
-
-	/*
-	 * initialise the zones.
-	 */
-	memset(zone_size, 0, sizeof(zone_size));
+	unsigned long max_zone_pfn[MAX_NR_ZONES] = { 0 };
 
-	/*
-	 * The memory size has already been determined.  If we need
-	 * to do anything fancy with the allocation of this memory
-	 * to the zones, now is the time to do it.
-	 */
-	zone_size[0] = max_low - min;
-#ifdef CONFIG_HIGHMEM
-	zone_size[ZONE_HIGHMEM] = max_high - max_low;
+#ifdef CONFIG_ZONE_DMA
+	max_zone_pfn[ZONE_DMA] = min(arm_dma_pfn_limit, max_low);
 #endif
-
-	/*
-	 * Calculate the size of the holes.
-	 *  holes = node_size - sum(bank_sizes)
-	 */
-	memcpy(zhole_size, zone_size, sizeof(zhole_size));
-	for_each_memblock(memory, reg) {
-		unsigned long start = memblock_region_memory_base_pfn(reg);
-		unsigned long end = memblock_region_memory_end_pfn(reg);
-
-		if (start < max_low) {
-			unsigned long low_end = min(end, max_low);
-			zhole_size[0] -= low_end - start;
-		}
+	max_zone_pfn[ZONE_NORMAL] = max_low;
 #ifdef CONFIG_HIGHMEM
-		if (end > max_low) {
-			unsigned long high_start = max(start, max_low);
-			zhole_size[ZONE_HIGHMEM] -= end - high_start;
-		}
+	max_zone_pfn[ZONE_HIGHMEM] = max_high;
 #endif
-	}
-
-#ifdef CONFIG_ZONE_DMA
-	/*
-	 * Adjust the sizes according to any special requirements for
-	 * this machine type.
-	 */
-	if (arm_dma_zone_size)
-		arm_adjust_dma_zone(zone_size, zhole_size,
-			arm_dma_zone_size >> PAGE_SHIFT);
-#endif
-
-	free_area_init_node(0, zone_size, min, zhole_size);
+	free_area_init(max_zone_pfn);
 }
 
 #ifdef CONFIG_HAVE_ARCH_PFN_VALID
@@ -306,7 +254,7 @@ void __init bootmem_init(void)
 	sparse_init();
 
 	/*
-	 * Now free the memory - free_area_init_node needs
+	 * Now free the memory - free_area_init needs
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */

commit 31f3010e60522ede237fb145a63b4af5a41718c2
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Dec 18 01:18:49 2019 +0100

    ARM: 8949/1: mm: mark free_memmap as __init
    
    As of commit ac7c3e4ff401 ("compiler: enable CONFIG_OPTIMIZE_INLINING
    forcibly"), free_memmap() might not always be inlined, and thus is
    triggering a section warning:
    
    WARNING: vmlinux.o(.text.unlikely+0x904): Section mismatch in reference from the function free_memmap() to the function .meminit.text:memblock_free()
    
    Mark it as __init, since the faller (free_unused_memmap) already is.
    
    Fixes: ac7c3e4ff401 ("compiler: enable CONFIG_OPTIMIZE_INLINING forcibly")
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3ef204137e73..054be44d1cdb 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -324,7 +324,7 @@ static inline void poison_init_mem(void *s, size_t count)
 		*p++ = 0xe7fddef0;
 }
 
-static inline void
+static inline void __init
 free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 {
 	struct page *start_pg, *end_pg;

commit 9110f3e78c02026ebc9e65d6208b1e2bb8a851a1
Author: Ben Dooks (Codethink) <ben.dooks@codethink.co.uk>
Date:   Fri Oct 11 13:51:43 2019 +0100

    ARM: 8917/1: mm: include <asm/set_memory.h>
    
    The definitions of set_kernel_text_rw() and
    set_kernel_text_ro() are in <asm/set_memory.h>
    but this is not included in init.c which defines
    these. Silence the following warnings by including
    the <asm/set_memory.h> header.
    
    arch/arm/mm/init.c:669:6: warning: symbol 'set_kernel_text_rw' was not declared. Should it be static?
    arch/arm/mm/init.c:678:6: warning: symbol 'set_kernel_text_ro' was not declared. Should it be static?
    
    Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b743272eacb3..3ef204137e73 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -30,6 +30,7 @@
 #include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
+#include <asm/set_memory.h>
 #include <asm/system_info.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>

commit ea5379be539e2a83cd582d79b9a12323ea1bae78
Author: Ben Dooks (Codethink) <ben.dooks@codethink.co.uk>
Date:   Fri Oct 11 13:51:52 2019 +0100

    ARM: 8916/1: mm: make set_section_perms() static
    
    The set_section_perms() is not defined outside of the
    init.c file, so make it static to avoid the following
    warning:
    
    arch/arm/mm/init.c:596:6: warning: symbol 'set_section_perms' was not declared. Should it be static?
    
    Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a373e9f59fd4..b743272eacb3 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -593,8 +593,8 @@ static inline bool arch_has_strict_perms(void)
 	return !!(get_cr() & CR_XP);
 }
 
-void set_section_perms(struct section_perm *perms, int n, bool set,
-			struct mm_struct *mm)
+static void set_section_perms(struct section_perm *perms, int n, bool set,
+			      struct mm_struct *mm)
 {
 	size_t i;
 	unsigned long addr;

commit 032be72806d1b34db7057f2c7982d87ed2274751
Author: Clemens Gruber <clemens.gruber@pqgruber.com>
Date:   Sun Sep 22 14:25:51 2019 +0100

    ARM: 8907/1: arch: reuse addr variable in pfn_valid
    
    Avoid calling __pfn_to_phys twice.
    
    Signed-off-by: Clemens Gruber <clemens.gruber@pqgruber.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b4be3baa83d4..a373e9f59fd4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -180,7 +180,7 @@ int pfn_valid(unsigned long pfn)
 	if (__phys_to_pfn(addr) != pfn)
 		return 0;
 
-	return memblock_is_map_memory(__pfn_to_phys(pfn));
+	return memblock_is_map_memory(addr);
 }
 EXPORT_SYMBOL(pfn_valid);
 #endif

commit 5b3efa4f1479c91cb8361acef55f9c6662feba57
Author: zhaoyang <huangzhaoyang@gmail.com>
Date:   Mon Aug 26 04:07:37 2019 +0100

    ARM: 8901/1: add a criteria for pfn_valid of arm
    
    pfn_valid can be wrong when parsing a invalid pfn whose phys address
    exceeds BITS_PER_LONG as the MSB will be trimed when shifted.
    
    The issue originally arise from bellowing call stack, which corresponding to
    an access of the /proc/kpageflags from userspace with a invalid pfn parameter
    and leads to kernel panic.
    
    [46886.723249] c7 [<c031ff98>] (stable_page_flags) from [<c03203f8>]
    [46886.723264] c7 [<c0320368>] (kpageflags_read) from [<c0312030>]
    [46886.723280] c7 [<c0311fb0>] (proc_reg_read) from [<c02a6e6c>]
    [46886.723290] c7 [<c02a6e24>] (__vfs_read) from [<c02a7018>]
    [46886.723301] c7 [<c02a6f74>] (vfs_read) from [<c02a778c>]
    [46886.723315] c7 [<c02a770c>] (SyS_pread64) from [<c0108620>]
    (ret_fast_syscall+0x0/0x28)
    
    Signed-off-by: Zhaoyang Huang <zhaoyang.huang@unisoc.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3a65ded832df..b4be3baa83d4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -175,6 +175,11 @@ static void __init zone_sizes_init(unsigned long min, unsigned long max_low,
 #ifdef CONFIG_HAVE_ARCH_PFN_VALID
 int pfn_valid(unsigned long pfn)
 {
+	phys_addr_t addr = __pfn_to_phys(pfn);
+
+	if (__phys_to_pfn(addr) != pfn)
+		return 0;
+
 	return memblock_is_map_memory(__pfn_to_phys(pfn));
 }
 EXPORT_SYMBOL(pfn_valid);

commit c51bc12d06b3a5494fbfcbd788a8e307932a06e9
Author: Doug Berger <opendmb@gmail.com>
Date:   Mon Jul 1 18:50:11 2019 +0100

    ARM: 8874/1: mm: only adjust sections of valid mm structures
    
    A timing hazard exists when an early fork/exec thread begins
    exiting and sets its mm pointer to NULL while a separate core
    tries to update the section information.
    
    This commit ensures that the mm pointer is not NULL before
    setting its section parameters. The arguments provided by
    commit 11ce4b33aedc ("ARM: 8672/1: mm: remove tasklist locking
    from update_sections_early()") are equally valid for not
    requiring grabbing the task_lock around this check.
    
    Fixes: 08925c2f124f ("ARM: 8464/1: Update all mm structures with section adjustments")
    Signed-off-by: Doug Berger <opendmb@gmail.com>
    Acked-by: Laura Abbott <labbott@redhat.com>
    Cc: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Florian Fainelli <f.fainelli@gmail.com>
    Cc: Rob Herring <robh@kernel.org>
    Cc: "Steven Rostedt (VMware)" <rostedt@goodmis.org>
    Cc: Peng Fan <peng.fan@nxp.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 16d373d587c4..3a65ded832df 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -628,7 +628,8 @@ static void update_sections_early(struct section_perm perms[], int n)
 		if (t->flags & PF_KTHREAD)
 			continue;
 		for_each_thread(t, s)
-			set_section_perms(perms, n, true, s->mm);
+			if (s->mm)
+				set_section_perms(perms, n, true, s->mm);
 	}
 	set_section_perms(perms, n, true, current->active_mm);
 	set_section_perms(perms, n, true, &init_mm);

commit ad3c7b18c5b362be5dbd0f2c0bcf1fd5fd659315
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jul 23 11:33:12 2019 +0200

    arm: use swiotlb for bounce buffering on LPAE configs
    
    The DMA API requires that 32-bit DMA masks are always supported, but on
    arm LPAE configs they do not currently work when memory is present
    above 4GB.  Wire up the swiotlb code like for all other architectures
    to provide the bounce buffering in that case.
    
    Fixes: 21e07dba9fb11 ("scsi: reduce use of block bounce buffers").
    Reported-by: Roger Quadros <rogerq@ti.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Vignesh Raghavendra <vigneshr@ti.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4920a206dce9..16d373d587c4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -21,6 +21,7 @@
 #include <linux/dma-contiguous.h>
 #include <linux/sizes.h>
 #include <linux/stop_machine.h>
+#include <linux/swiotlb.h>
 
 #include <asm/cp15.h>
 #include <asm/mach-types.h>
@@ -463,6 +464,10 @@ static void __init free_highpages(void)
  */
 void __init mem_init(void)
 {
+#ifdef CONFIG_ARM_LPAE
+	swiotlb_init(1);
+#endif
+
 	set_max_mapnr(pfn_to_page(max_pfn) - mem_map);
 
 	/* this will put all unused low memory onto the freelists */

commit 2b49350b16fa3171136d7cf351ac7e9e6673b8f2
Merge: 4d2fa8b44b89 5ccd3bd992cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:08:34 2019 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - Add a "cut here" to make it clearer where oops dumps should be cut
       from - we already have a marker for the end of the dumps.
    
     - Add logging severity to show_pte()
    
     - Drop unnecessary common-page-size linker flag
    
     - Errata workarounds for Cortex A12 857271, Cortex A17 857272 and
       Cortex A7 814220.
    
     - Remove some unused variables that had started to provoke a compiler
       warning.
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm:
      ARM: 8863/1: stm32: select ARM errata 814220
      ARM: 8862/1: errata: 814220-B-Cache maintenance by set/way operations can execute out of order
      ARM: 8865/1: mm: remove unused variables
      ARM: 8864/1: Add workaround for I-Cache line size mismatch between CPU cores
      ARM: 8861/1: errata: Workaround errata A12 857271 / A17 857272
      ARM: 8860/1: VDSO: Drop implicit common-page-size linker flag
      ARM: arrange show_pte() to issue severity-based messages
      ARM: add "8<--- cut here ---" to kernel dumps

commit e6c4375f7c9293ffa65469d16f8ebd2586cb03f2
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Tue Jun 4 07:19:57 2019 +0100

    ARM: 8865/1: mm: remove unused variables
    
    Fix gcc warnings:
    
    arch/arm/mm/init.c: In function 'mem_init':
    arch/arm/mm/init.c:456:13: warning: unused variable 'itcm_end' [-Wunused-variable]
      extern u32 itcm_end;
                 ^
    arch/arm/mm/init.c:455:13: warning: unused variable 'dtcm_end' [-Wunused-variable]
      extern u32 dtcm_end;
                 ^
    
    They are not used any more since
    commit 1c31d4e96b8c ("ARM: 8820/1: mm: Stop printing the virtual memory layout")
    
    Link: https://lkml.org/lkml/2019/5/12/82
    
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Reviewed-by: Krzysztof Kozlowski <krzk@kernel.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1a66af5bd259..581c6ffc3056 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -466,12 +466,6 @@ static void __init free_highpages(void)
  */
 void __init mem_init(void)
 {
-#ifdef CONFIG_HAVE_TCM
-	/* These pointers are filled in on TCM detection */
-	extern u32 dtcm_end;
-	extern u32 itcm_end;
-#endif
-
 	set_max_mapnr(pfn_to_page(max_pfn) - mem_map);
 
 	/* this will put all unused low memory onto the freelists */

commit 5f41f9198f296091c6a58bc2e86af1e9f019b2a3
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Tue May 28 09:38:14 2019 +0100

    ARM: 8864/1: Add workaround for I-Cache line size mismatch between CPU cores
    
    Some big.LITTLE systems have I-Cache line size mismatch between
    LITTLE and big cores. This patch adds a workaround for proper I-Cache
    support on such systems. Without it, some class of the userspace code
    (typically self-modifying) might suffer from random SIGILL failures.
    
    Similar workaround already exists for ARM64 architecture. I has been
    added by commit 116c81f427ff ("arm64: Work around systems with mismatched
    cache line sizes").
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index be0b42937888..1a66af5bd259 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -242,6 +242,22 @@ static void __init arm_initrd_init(void)
 #endif
 }
 
+#ifdef CONFIG_CPU_ICACHE_MISMATCH_WORKAROUND
+void check_cpu_icache_size(int cpuid)
+{
+	u32 size, ctr;
+
+	asm("mrc p15, 0, %0, c0, c0, 1" : "=r" (ctr));
+
+	size = 1 << ((ctr & 0xf) + 2);
+	if (cpuid != 0 && icache_size != size)
+		pr_info("CPU%u: detected I-Cache line size mismatch, workaround enabled\n",
+			cpuid);
+	if (icache_size > size)
+		icache_size = size;
+}
+#endif
+
 void __init arm_memblock_init(const struct machine_desc *mdesc)
 {
 	/* Register the kernel text, kernel data and initrd with memblock. */

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index be0b42937888..749a5a6f6143 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -1,11 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/arch/arm/mm/init.c
  *
  *  Copyright (C) 1995-2005 Russell King
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 #include <linux/kernel.h>
 #include <linux/errno.h>

commit 8c05f3b965da14e7790711026b32cc10a4c06213
Merge: ab02888e3921 b752bb405a13
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 16 09:41:54 2019 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "ARM development updates:
    
       - more unified assembly conversions for clang
    
       - drop obsolete -mauto-it assembler option
    
       - remove arm_memory_present in preference to the generic version
    
       - remove unused asm/limits.h header
    
       - vdso linker update
    
      We tried to make the assembler warn if unified syntax was not used,
      but unfortunately older versions of GCC warn, so the commit had to be
      reverted"
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm:
      Revert "ARM: 8846/1: warn if divided syntax assembler is used"
      ARM: 8858/1: vdso: use $(LD) instead of $(CC) to link VDSO
      ARM: 8855/1: remove unused <asm/limits.h>
      ARM: 8850/1: use memblocks_present
      ARM: 8854/1: drop -mauto-it
      ARM: 8846/1: warn if divided syntax assembler is used
      ARM: 8853/1: drop WASM to work around LLVM issue
      ARM: 8852/1: uaccess: use unified assembler language syntax
      ARM: 8851/1: add TUSERCOND() macro for conditional postfix

commit d8ae8a3765bfa1f9bf977e2496fcc9cf64fbfabd
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 13 17:18:30 2019 -0700

    initramfs: move the legacy keepinitrd parameter to core code
    
    No need to handle the freeing disable in arch code when we already have a
    core hook (and a different name for the option) for it.
    
    Link: http://lkml.kernel.org/r/20190213174621.29297-7-hch@lst.de
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>     [arm64]
    Acked-by: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>   [m68k]
    Cc: Steven Price <steven.price@arm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c2daabbe0af0..68dcd5f8d7c6 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -695,27 +695,14 @@ void free_initmem(void)
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
-
-static int keep_initrd;
-
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	if (!keep_initrd) {
-		if (start == initrd_start)
-			start = round_down(start, PAGE_SIZE);
-		if (end == initrd_end)
-			end = round_up(end, PAGE_SIZE);
+	if (start == initrd_start)
+		start = round_down(start, PAGE_SIZE);
+	if (end == initrd_end)
+		end = round_up(end, PAGE_SIZE);
 
-		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
-		free_reserved_area((void *)start, (void *)end, -1, "initrd");
-	}
+	poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
+	free_reserved_area((void *)start, (void *)end, -1, "initrd");
 }
-
-static int __init keepinitrd_setup(char *__unused)
-{
-	keep_initrd = 1;
-	return 1;
-}
-
-__setup("keepinitrd", keepinitrd_setup);
 #endif

commit 14b5f54b78292fdcf12ffb5e914f8fd2d190bcf5
Author: Peng Fan <peng.fan@nxp.com>
Date:   Tue Mar 19 14:34:32 2019 +0100

    ARM: 8850/1: use memblocks_present
    
    arm_memory_present is doing same thing as memblocks_present, so
    let's use common code memblocks_present instead of platform
    specific arm_memory_present.
    
    Patchwork: https://patchwork.kernel.org/patch/10805693/
    
    Signed-off-by: Peng Fan <peng.fan@nxp.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c2daabbe0af0..b2fbb4a711fc 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -182,21 +182,6 @@ int pfn_valid(unsigned long pfn)
 EXPORT_SYMBOL(pfn_valid);
 #endif
 
-#ifndef CONFIG_SPARSEMEM
-static void __init arm_memory_present(void)
-{
-}
-#else
-static void __init arm_memory_present(void)
-{
-	struct memblock_region *reg;
-
-	for_each_memblock(memory, reg)
-		memory_present(0, memblock_region_memory_base_pfn(reg),
-			       memblock_region_memory_end_pfn(reg));
-}
-#endif
-
 static bool arm_memblock_steal_permitted = true;
 
 phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
@@ -293,7 +278,7 @@ void __init bootmem_init(void)
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations
 	 */
-	arm_memory_present();
+	memblocks_present();
 
 	/*
 	 * sparse_init() needs the bootmem allocator up and running.

commit 0be288630752e6358d02eba7b283c1783a5c7c38
Merge: e8a71a386689 4c2741ac5e10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 15 14:37:46 2019 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - An improvement from Ard Biesheuvel, who noted that the identity map
       setup was taking a long time due to flush_cache_louis().
    
     - Update a comment about dma_ops from Wolfram Sang.
    
     - Remove use of "-p" with ld, where this flag has been a no-op since
       2004.
    
     - Remove the printing of the virtual memory layout, which is no longer
       useful since we hide pointers.
    
     - Correct SCU help text.
    
     - Remove legacy TWD registration method.
    
     - Add pgprot_device() implementation for mapping PCI sysfs resource
       files.
    
     - Initialise PFN limits earlier for kmemleak.
    
     - Fix argument count to match macro definition (affects clang builds)
    
     - Use unified assembler language almost everywhere for clang, and other
       clang improvements (from Stefan Agner, Nathan Chancellor).
    
     - Support security extension for noMMU and other noMMU cleanups (from
       Vladimir Murzin).
    
     - Remove unnecessary SMP bringup code (which was incorrectly copy'n'
       pasted from the ARM platform implementations) and remove it from the
       arch code to discourge further copys of it appearing.
    
     - Add Cortex A9 erratum preventing kexec working on some SoCs.
    
     - AMBA bus identification updates from Mike Leach.
    
     - More use of raw spinlocks to avoid -RT kernel issues (from Yang Shi
       and Sebastian Andrzej Siewior).
    
     - MCPM hyp/svc mode mismatch fixes from Marek Szyprowski.
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (32 commits)
      ARM: 8849/1: NOMMU: Fix encodings for PMSAv8's PRBAR4/PRLAR4
      ARM: 8848/1: virt: Align GIC version check with arm64 counterpart
      ARM: 8847/1: pm: fix HYP/SVC mode mismatch when MCPM is used
      ARM: 8845/1: use unified assembler in c files
      ARM: 8844/1: use unified assembler in assembly files
      ARM: 8843/1: use unified assembler in headers
      ARM: 8841/1: use unified assembler in macros
      ARM: 8840/1: use a raw_spinlock_t in unwind
      ARM: 8839/1: kprobe: make patch_lock a raw_spinlock_t
      ARM: 8837/1: coresight: etmv4: Update ID register table to add UCI support
      ARM: 8836/1: drivers: amba: Update component matching to use the CoreSight UCI values.
      ARM: 8838/1: drivers: amba: Updates to component identification for driver matching.
      ARM: 8833/1: Ensure that NEON code always compiles with Clang
      ARM: avoid Cortex-A9 livelock on tight dmb loops
      ARM: smp: remove arch-provided "pen_release"
      ARM: actions: remove boot_lock and pen_release
      ARM: oxnas: remove CPU hotplug implementation
      ARM: qcom: remove unnecessary boot_lock
      ARM: 8832/1: NOMMU: Limit visibility for CONFIG_FLASH_{MEM_BASE,SIZE}
      ARM: 8831/1: NOMMU: pmsa-v8: remove unneeded semicolon
      ...

commit ecc3e771f4ca98c52a072e41804434b4979bdf84
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Mar 11 23:29:26 2019 -0700

    memblock: memblock_phys_alloc(): don't panic
    
    Make the memblock_phys_alloc() function an inline wrapper for
    memblock_phys_alloc_range() and update the memblock_phys_alloc() callers
    to check the returned value and panic in case of error.
    
    Link: http://lkml.kernel.org/r/1548057848-15136-8-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Dennis Zhou <dennis@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Guo Ren <ren_guo@c-sky.com>                         [c-sky]
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Juergen Gross <jgross@suse.com>                     [Xen]
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b76b90eb9356..15dddfe43319 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -206,6 +206,10 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 	BUG_ON(!arm_memblock_steal_permitted);
 
 	phys = memblock_phys_alloc(size, align);
+	if (!phys)
+		panic("Failed to steal %pa bytes at %pS\n",
+		      &size, (void *)_RET_IP_);
+
 	memblock_free(phys, size);
 	memblock_remove(phys, size);
 

commit f240ec09bb8a08003a6e2cb51682705ab19b78cd
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Mar 11 23:29:06 2019 -0700

    memblock: replace memblock_alloc_base(ANYWHERE) with memblock_phys_alloc
    
    The calls to memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ANYWHERE)
    and memblock_phys_alloc(size, align) are equivalent as both try to
    allocate 'size' bytes with 'align' alignment anywhere in the memory and
    panic if hte allocation fails.
    
    The conversion is done using the following semantic patch:
    
      @@
      expression size, align;
      @@
      - memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ANYWHERE)
      + memblock_phys_alloc(size, align)
    
    Link: http://lkml.kernel.org/r/1548057848-15136-4-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Dennis Zhou <dennis@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Guo Ren <ren_guo@c-sky.com>                         [c-sky]
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Juergen Gross <jgross@suse.com>                     [Xen]
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 478ea8b7db87..b76b90eb9356 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -205,7 +205,7 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 
 	BUG_ON(!arm_memblock_steal_permitted);
 
-	phys = memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ANYWHERE);
+	phys = memblock_phys_alloc(size, align);
 	memblock_free(phys, size);
 	memblock_remove(phys, size);
 

commit 071d184a19f673bbb69a593c2ff4bd7acc0d1fe6
Author: Doug Berger <opendmb@gmail.com>
Date:   Tue Jan 22 21:05:10 2019 +0100

    ARM: 8826/1: mm: initialize pfn limits with find_limits()
    
    The max_low_pfn value must be set before sparse_init() is called to
    keep the early memblock allocations and frees balanced for kmemleak
    initialization when sparsemem is enabled.
    
    This commit accomplishes that by replacing the local variables min,
    max_low, and max_high with the global limit variables min_low_pfn,
    max_low_pfn, and max_pfn respectively in bootmem_init(). The global
    variables are initialized directly by find_limits() and used in the
    remainder of the function.
    
    Fixes: 9099daed9c69 ("mm: kmemleak: avoid using __va() on addresses that don't have a lowmem mapping")
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Doug Berger <opendmb@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 57962080e47a..a6b0805b7977 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -278,15 +278,12 @@ void __init arm_memblock_init(const struct machine_desc *mdesc)
 
 void __init bootmem_init(void)
 {
-	unsigned long min, max_low, max_high;
-
 	memblock_allow_resize();
-	max_low = max_high = 0;
 
-	find_limits(&min, &max_low, &max_high);
+	find_limits(&min_low_pfn, &max_low_pfn, &max_pfn);
 
-	early_memtest((phys_addr_t)min << PAGE_SHIFT,
-		      (phys_addr_t)max_low << PAGE_SHIFT);
+	early_memtest((phys_addr_t)min_low_pfn << PAGE_SHIFT,
+		      (phys_addr_t)max_low_pfn << PAGE_SHIFT);
 
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),
@@ -304,16 +301,7 @@ void __init bootmem_init(void)
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */
-	zone_sizes_init(min, max_low, max_high);
-
-	/*
-	 * This doesn't seem to be used by the Linux memory manager any
-	 * more, but is used by ll_rw_block.  If we can get rid of it, we
-	 * also get rid of some of the stuff above as well.
-	 */
-	min_low_pfn = min;
-	max_low_pfn = max_low;
-	max_pfn = max_high;
+	zone_sizes_init(min_low_pfn, max_low_pfn, max_pfn);
 }
 
 /*

commit 1c31d4e96b8c205fe3aa8e73e930a0ccbf4b9a2b
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Jan 8 14:27:01 2019 +0100

    ARM: 8820/1: mm: Stop printing the virtual memory layout
    
    Since commit ad67b74d2469d9b8 ("printk: hash addresses printed with
    %p"), the virtual memory layout printed during boot up contains "ptrval"
    instead of actual addresses:
    
        Memory: 501296K/524288K available (6144K kernel code, 528K rwdata, 1944K rodata, 1024K init, 7584K bss, 22992K reserved, 0K cma-reserved)
        Virtual kernel memory layout:
            vector  : 0xffff0000 - 0xffff1000   (   4 kB)
            fixmap  : 0xffc00000 - 0xfff00000   (3072 kB)
            vmalloc : 0xe0800000 - 0xff800000   ( 496 MB)
            lowmem  : 0xc0000000 - 0xe0000000   ( 512 MB)
            modules : 0xbf000000 - 0xc0000000   (  16 MB)
              .text : 0x(ptrval) - 0x(ptrval)   (7136 kB)
              .init : 0x(ptrval) - 0x(ptrval)   (1024 kB)
              .data : 0x(ptrval) - 0x(ptrval)   ( 529 kB)
               .bss : 0x(ptrval) - 0x(ptrval)   (7585 kB)
    
    Instead of changing the printing to "%px", and leaking virtual memory
    layout information again, just remove the printing completely, cfr. e.g.
    commits 071929dbdd865f77 ("arm64: Stop printing the virtual memory
    layout") and  31833332f7987636 ("m68k/mm: Stop printing the virtual
    memory layout").
    
    All interesting information (actual section sizes) is already printed by
    mem_init_print_info() just above anyway.
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 478ea8b7db87..57962080e47a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -494,55 +494,6 @@ void __init mem_init(void)
 
 	mem_init_print_info(NULL);
 
-#define MLK(b, t) b, t, ((t) - (b)) >> 10
-#define MLM(b, t) b, t, ((t) - (b)) >> 20
-#define MLK_ROUNDUP(b, t) b, t, DIV_ROUND_UP(((t) - (b)), SZ_1K)
-
-	pr_notice("Virtual kernel memory layout:\n"
-			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-#ifdef CONFIG_HAVE_TCM
-			"    DTCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-			"    ITCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-#endif
-			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-			"    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-			"    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-#ifdef CONFIG_HIGHMEM
-			"    pkmap   : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-#endif
-#ifdef CONFIG_MODULES
-			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-#endif
-			"      .text : 0x%p" " - 0x%p" "   (%4td kB)\n"
-			"      .init : 0x%p" " - 0x%p" "   (%4td kB)\n"
-			"      .data : 0x%p" " - 0x%p" "   (%4td kB)\n"
-			"       .bss : 0x%p" " - 0x%p" "   (%4td kB)\n",
-
-			MLK(VECTORS_BASE, VECTORS_BASE + PAGE_SIZE),
-#ifdef CONFIG_HAVE_TCM
-			MLK(DTCM_OFFSET, (unsigned long) dtcm_end),
-			MLK(ITCM_OFFSET, (unsigned long) itcm_end),
-#endif
-			MLK(FIXADDR_START, FIXADDR_END),
-			MLM(VMALLOC_START, VMALLOC_END),
-			MLM(PAGE_OFFSET, (unsigned long)high_memory),
-#ifdef CONFIG_HIGHMEM
-			MLM(PKMAP_BASE, (PKMAP_BASE) + (LAST_PKMAP) *
-				(PAGE_SIZE)),
-#endif
-#ifdef CONFIG_MODULES
-			MLM(MODULES_VADDR, MODULES_END),
-#endif
-
-			MLK_ROUNDUP(_text, _etext),
-			MLK_ROUNDUP(__init_begin, __init_end),
-			MLK_ROUNDUP(_sdata, _edata),
-			MLK_ROUNDUP(__bss_start, __bss_stop));
-
-#undef MLK
-#undef MLM
-#undef MLK_ROUNDUP
-
 	/*
 	 * Check boundaries twice: Some fundamental inconsistencies can
 	 * be detected at build time already.

commit 229c55ccb487c0c10721fdb92af874d7b8671cda
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Mon Nov 5 14:54:31 2018 -0800

    arch: Move initrd= parsing into do_mounts_initrd.c
    
    ARC, ARM, ARM64 and Unicore32 are all capable of parsing the "initrd="
    command line parameter to allow specifying the physical address and size
    of an initrd. Move that parsing into init/do_mounts_initrd.c such that
    we no longer duplicate that logic.
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Reviewed-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Rob Herring <robh@kernel.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a3b6f1f1cbaf..478ea8b7db87 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -51,23 +51,6 @@ unsigned long __init __clear_cr(unsigned long mask)
 #endif
 
 #ifdef CONFIG_BLK_DEV_INITRD
-static int __init early_initrd(char *p)
-{
-	phys_addr_t start;
-	unsigned long size;
-	char *endp;
-
-	start = memparse(p, &endp);
-	if (*endp == ',') {
-		size = memparse(endp + 1, NULL);
-
-		phys_initrd_start = start;
-		phys_initrd_size = size;
-	}
-	return 0;
-}
-early_param("initrd", early_initrd);
-
 static int __init parse_tag_initrd(const struct tag *tag)
 {
 	pr_warn("ATAG_INITRD is deprecated; "

commit fe7db7570379dafec67430bb843d2e78df89e7f1
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Mon Nov 5 14:54:28 2018 -0800

    of/fdt: Populate phys_initrd_start/phys_initrd_size from FDT
    
    Now that we have central and global variables holding the physical
    address and size of the initrd, we can have
    early_init_dt_check_for_initrd() populate
    phys_initrd_start/phys_initrd_size for us.
    
    This allows us to remove a chunk of code from arch/arm/mm/init.c
    introduced with commit 65939301acdb ("arm: set initrd_start/initrd_end
    for fdt scan").
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Reviewed-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Rob Herring <robh@kernel.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 438625764ccd..a3b6f1f1cbaf 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -235,12 +235,6 @@ static void __init arm_initrd_init(void)
 	phys_addr_t start;
 	unsigned long size;
 
-	/* FDT scan will populate initrd_start */
-	if (initrd_start && !phys_initrd_size) {
-		phys_initrd_start = __virt_to_phys(initrd_start);
-		phys_initrd_size = initrd_end - initrd_start;
-	}
-
 	initrd_start = initrd_end = 0;
 
 	if (!phys_initrd_size)

commit b1ab95c63622e9d9bd0ce685e149034d393afc2e
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Mon Nov 5 14:54:27 2018 -0800

    arch: Make phys_initrd_start and phys_initrd_size global variables
    
    Make phys_initrd_start and phys_initrd_size global variables declared in
    init/do_mounts_initrd.c such that we can later have generic code in
    drivers/of/fdt.c populate those variables for us.
    
    This requires both the ARM and unicore32 implementations to be properly
    guarded against CONFIG_BLK_DEV_INITRD, and also initialize the variables
    to the expected default values (unicore32).
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Reviewed-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Rob Herring <robh@kernel.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 32e4845af2b6..438625764ccd 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -50,9 +50,7 @@ unsigned long __init __clear_cr(unsigned long mask)
 }
 #endif
 
-static phys_addr_t phys_initrd_start __initdata = 0;
-static unsigned long phys_initrd_size __initdata = 0;
-
+#ifdef CONFIG_BLK_DEV_INITRD
 static int __init early_initrd(char *p)
 {
 	phys_addr_t start;
@@ -89,6 +87,7 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 }
 
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
+#endif
 
 static void __init find_limits(unsigned long *min, unsigned long *max_low,
 			       unsigned long *max_high)

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index d421a10c93a8..32e4845af2b6 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -11,7 +11,6 @@
 #include <linux/errno.h>
 #include <linux/swap.h>
 #include <linux/init.h>
-#include <linux/bootmem.h>
 #include <linux/mman.h>
 #include <linux/sched/signal.h>
 #include <linux/sched/task.h>

commit c6ffc5ca8fb311a89cb6de5c31b6511308ddac8d
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:30 2018 -0700

    memblock: rename free_all_bootmem to memblock_free_all
    
    The conversion is done using
    
    sed -i 's@free_all_bootmem@memblock_free_all@' \
        $(git grep -l free_all_bootmem)
    
    Link: http://lkml.kernel.org/r/1536927045-23536-26-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 0cc8e04295a4..d421a10c93a8 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -508,7 +508,7 @@ void __init mem_init(void)
 
 	/* this will put all unused low memory onto the freelists */
 	free_unused_memmap();
-	free_all_bootmem();
+	memblock_free_all();
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */

commit b4c7e2bd2eb4764afe3af9409ff3b1b87116fa30
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Tue Jul 10 08:22:40 2018 +0100

    ARM: 8780/1: ftrace: Only set kernel memory back to read-only after boot
    
    Dynamic ftrace requires modifying the code segments that are usually
    set to read-only. To do this, a per arch function is called both before
    and after the ftrace modifications are performed. The "before" function
    will set kernel code text to read-write to allow for ftrace to make the
    modifications, and the "after" function will set the kernel code text
    back to "read-only" to keep the kernel code text protected.
    
    The issue happens when dynamic ftrace is tested at boot up. The test is
    done before the kernel code text has been set to read-only. But the
    "before" and "after" calls are still performed. The "after" call will
    change the kernel code text to read-only prematurely, and other boot
    code that expects this code to be read-write will fail.
    
    The solution is to add a variable that is set when the kernel code text
    is expected to be converted to read-only, and make the ftrace "before"
    and "after" calls do nothing if that variable is not yet set. This is
    similar to the x86 solution from commit 162396309745 ("ftrace, x86:
    make kernel text writable only for conversions").
    
    Link: http://lkml.kernel.org/r/20180620212906.24b7b66e@vmware.local.home
    
    Reported-by: Stefan Agner <stefan@agner.ch>
    Tested-by: Stefan Agner <stefan@agner.ch>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c186474422f3..0cc8e04295a4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -736,20 +736,29 @@ static int __mark_rodata_ro(void *unused)
 	return 0;
 }
 
+static int kernel_set_to_readonly __read_mostly;
+
 void mark_rodata_ro(void)
 {
+	kernel_set_to_readonly = 1;
 	stop_machine(__mark_rodata_ro, NULL, NULL);
 	debug_checkwx();
 }
 
 void set_kernel_text_rw(void)
 {
+	if (!kernel_set_to_readonly)
+		return;
+
 	set_section_perms(ro_perms, ARRAY_SIZE(ro_perms), false,
 				current->active_mm);
 }
 
 void set_kernel_text_ro(void)
 {
+	if (!kernel_set_to_readonly)
+		return;
+
 	set_section_perms(ro_perms, ARRAY_SIZE(ro_perms), true,
 				current->active_mm);
 }

commit b54290e51accea4f696f5dacef8e609d0ccbe54a
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Thu Mar 8 21:12:04 2018 -0500

    ARM: simplify and fix linker script for TCM
    
    Let's put the TCM stuff in the __init section directly. No need for
    a separately freed memory area.
    
    Remove redundant linker sections, as well as comments that were more
    confusing than no comments at all. Finally make it XIP compatible by
    using LOAD_OFFSET in the section LMA specification.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Chris Brandt <Chris.Brandt@renesas.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index bd6f4513539a..c186474422f3 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -758,20 +758,9 @@ void set_kernel_text_ro(void)
 static inline void fix_kernmem_perms(void) { }
 #endif /* CONFIG_STRICT_KERNEL_RWX */
 
-void free_tcmmem(void)
-{
-#ifdef CONFIG_HAVE_TCM
-	extern char __tcm_start, __tcm_end;
-
-	poison_init_mem(&__tcm_start, &__tcm_end - &__tcm_start);
-	free_reserved_area(&__tcm_start, &__tcm_end, -1, "TCM link");
-#endif
-}
-
 void free_initmem(void)
 {
 	fix_kernmem_perms();
-	free_tcmmem();
 
 	poison_init_mem(__init_begin, __init_end - __init_begin);
 	if (!machine_is_integrator() && !machine_is_cintegrator())

commit a8e53c151fe7ac52a1c13a6ace0c9e8e0f61260c
Author: Jinbum Park <jinb.park7@gmail.com>
Date:   Tue Dec 12 01:43:57 2017 +0100

    ARM: 8737/1: mm: dump: add checking for writable and executable
    
    Page mappings with full RWX permissions are a security risk.
    x86, arm64 has an option to walk the page tables
    and dump any bad pages.
    
    (1404d6f13e47
    ("arm64: dump: Add checking for writable and exectuable pages"))
    Add a similar implementation for arm.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Reviewed-by: Laura Abbott <labbott@redhat.com>
    Signed-off-by: Jinbum Park <jinb.park7@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a1f11a7ee81b..bd6f4513539a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -36,6 +36,7 @@
 #include <asm/system_info.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
+#include <asm/ptdump.h>
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
@@ -738,6 +739,7 @@ static int __mark_rodata_ro(void *unused)
 void mark_rodata_ro(void)
 {
 	stop_machine(__mark_rodata_ro, NULL, NULL);
+	debug_checkwx();
 }
 
 void set_kernel_text_rw(void)

commit bbecb1cfcca55f98cfcb62fa36a32d79975d8816
Merge: dec0029a5977 8bafae202c82
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 26 15:03:49 2017 -0800

    Merge branch 'fixes' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM fixes from Russell King:
    
     - LPAE fixes for kernel-readonly regions
    
     - Fix for get_user_pages_fast on LPAE systems
    
     - avoid tying decompressor to a particular platform if DEBUG_LL is
       enabled
    
     - BUG if we attempt to return to userspace but the to-be-restored PSR
       value keeps us in privileged mode (defeating an issue that ftracetest
       found)
    
    * 'fixes' of git://git.armlinux.org.uk/~rmk/linux-arm:
      ARM: BUG if jumping to usermode address in kernel mode
      ARM: 8722/1: mm: make STRICT_KERNEL_RWX effective for LPAE
      ARM: 8721/1: mm: dump: check hardware RO bit for LPAE
      ARM: make decompressor debug output user selectable
      ARM: fix get_user_pages_fast

commit 400eeffaffc7232c0ae1134fe04e14ae4fb48d8c
Author: Philip Derrin <philip@cog.systems>
Date:   Tue Nov 14 00:55:25 2017 +0100

    ARM: 8722/1: mm: make STRICT_KERNEL_RWX effective for LPAE
    
    Currently, for ARM kernels with CONFIG_ARM_LPAE and
    CONFIG_STRICT_KERNEL_RWX enabled, the 2MiB pages mapping the
    kernel code and rodata are writable. They are marked read-only in
    a software bit (L_PMD_SECT_RDONLY) but the hardware read-only bit
    is not set (PMD_SECT_AP2).
    
    For user mappings, the logic that propagates the software bit
    to the hardware bit is in set_pmd_at(); but for the kernel,
    section_update() writes the PMDs directly, skipping this logic.
    
    The fix is to set PMD_SECT_AP2 for read-only sections in
    section_update(), at the same time as L_PMD_SECT_RDONLY.
    
    Fixes: 1e3479225acb ("ARM: 8275/1: mm: fix PMD_SECT_RDONLY undeclared compile error")
    Signed-off-by: Philip Derrin <philip@cog.systems>
    Reported-by: Neil Dick <neil@cog.systems>
    Tested-by: Neil Dick <neil@cog.systems>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Cc: stable@vger.kernel.org
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ad80548325fe..0f6d1537f330 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -639,8 +639,8 @@ static struct section_perm ro_perms[] = {
 		.start  = (unsigned long)_stext,
 		.end    = (unsigned long)__init_begin,
 #ifdef CONFIG_ARM_LPAE
-		.mask   = ~L_PMD_SECT_RDONLY,
-		.prot   = L_PMD_SECT_RDONLY,
+		.mask   = ~(L_PMD_SECT_RDONLY | PMD_SECT_AP2),
+		.prot   = L_PMD_SECT_RDONLY | PMD_SECT_AP2,
 #else
 		.mask   = ~(PMD_SECT_APX | PMD_SECT_AP_WRITE),
 		.prot   = PMD_SECT_APX | PMD_SECT_AP_WRITE,

commit 0d9ac1625ac1041742c72c3b680198f0304539b2
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Mon Sep 4 09:17:48 2017 +0100

    ARM: 8696/1: mm: Remove dead code in mem_init()
    
    The code in question checks memory constrains to set default policy for
    overcommit; however we support page size of 4K only thus condition is
    always evaluated to false. Remove that dead code.
    
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ad80548325fe..81d4482b6861 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -580,16 +580,6 @@ void __init mem_init(void)
 	BUILD_BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE > PAGE_OFFSET);
 	BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE	> PAGE_OFFSET);
 #endif
-
-	if (PAGE_SIZE >= 16384 && get_num_physpages() <= 128) {
-		extern int sysctl_overcommit_memory;
-		/*
-		 * On a machine this small we won't get
-		 * anywhere without overcommit, so turn
-		 * it on by default.
-		 */
-		sysctl_overcommit_memory = OVERCOMMIT_ALWAYS;
-	}
 }
 
 #ifdef CONFIG_STRICT_KERNEL_RWX

commit 11ce4b33aedc65198d7bc9669344ebca5ee36a41
Author: Grygorii Strashko <grygorii.strashko@linaro.org>
Date:   Tue Apr 25 21:20:52 2017 +0100

    ARM: 8672/1: mm: remove tasklist locking from update_sections_early()
    
    The below backtrace can be observed on -rt kernel with
    CONFIG_DEBUG_MODULE_RONX (4.9 kernel CONFIG_DEBUG_RODATA) option enabled:
    
     BUG: sleeping function called from invalid context at kernel/locking/rtmutex.c:993
     in_atomic(): 1, irqs_disabled(): 128, pid: 14, name: migration/0
     1 lock held by migration/0/14:
      #0:  (tasklist_lock){+.+...}, at: [<c01183e8>] update_sections_early+0x24/0xdc
     irq event stamp: 38
     hardirqs last  enabled at (37): [<c08f6f7c>] _raw_spin_unlock_irq+0x24/0x68
     hardirqs last disabled at (38): [<c01fdfe8>] multi_cpu_stop+0xd8/0x138
     softirqs last  enabled at (0): [<c01303ec>] copy_process.part.5+0x238/0x1b64
     softirqs last disabled at (0): [<  (null)>]   (null)
     Preemption disabled at: [<c01fe244>] cpu_stopper_thread+0x80/0x10c
     CPU: 0 PID: 14 Comm: migration/0 Not tainted 4.9.21-rt16-02220-g49e319c #15
     Hardware name: Generic DRA74X (Flattened Device Tree)
     [<c0112014>] (unwind_backtrace) from [<c010d370>] (show_stack+0x10/0x14)
     [<c010d370>] (show_stack) from [<c049beb8>] (dump_stack+0xa8/0xd4)
     [<c049beb8>] (dump_stack) from [<c01631a0>] (___might_sleep+0x1bc/0x2ac)
     [<c01631a0>] (___might_sleep) from [<c08f7244>] (__rt_spin_lock+0x1c/0x30)
     [<c08f7244>] (__rt_spin_lock) from [<c08f77a4>] (rt_read_lock+0x54/0x68)
     [<c08f77a4>] (rt_read_lock) from [<c01183e8>] (update_sections_early+0x24/0xdc)
     [<c01183e8>] (update_sections_early) from [<c01184b0>] (__fix_kernmem_perms+0x10/0x1c)
     [<c01184b0>] (__fix_kernmem_perms) from [<c01fe010>] (multi_cpu_stop+0x100/0x138)
     [<c01fe010>] (multi_cpu_stop) from [<c01fe24c>] (cpu_stopper_thread+0x88/0x10c)
     [<c01fe24c>] (cpu_stopper_thread) from [<c015edc4>] (smpboot_thread_fn+0x174/0x31c)
     [<c015edc4>] (smpboot_thread_fn) from [<c015a988>] (kthread+0xf0/0x108)
     [<c015a988>] (kthread) from [<c0108818>] (ret_from_fork+0x14/0x3c)
     Freeing unused kernel memory: 1024K (c0d00000 - c0e00000)
    
    The stop_machine() is called with cpus = NULL from fix_kernmem_perms() and
    mark_rodata_ro() which means only one CPU will execute
    update_sections_early() while all other CPUs will spin and wait. Hence,
    it's safe to remove tasklist locking from update_sections_early(). As part
    of this change also mark functions which are local to this module as
    static.
    
    Signed-off-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Acked-by: Laura Abbott <labbott@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1d8558ff9827..ad80548325fe 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -709,34 +709,37 @@ void set_section_perms(struct section_perm *perms, int n, bool set,
 
 }
 
+/**
+ * update_sections_early intended to be called only through stop_machine
+ * framework and executed by only one CPU while all other CPUs will spin and
+ * wait, so no locking is required in this function.
+ */
 static void update_sections_early(struct section_perm perms[], int n)
 {
 	struct task_struct *t, *s;
 
-	read_lock(&tasklist_lock);
 	for_each_process(t) {
 		if (t->flags & PF_KTHREAD)
 			continue;
 		for_each_thread(t, s)
 			set_section_perms(perms, n, true, s->mm);
 	}
-	read_unlock(&tasklist_lock);
 	set_section_perms(perms, n, true, current->active_mm);
 	set_section_perms(perms, n, true, &init_mm);
 }
 
-int __fix_kernmem_perms(void *unused)
+static int __fix_kernmem_perms(void *unused)
 {
 	update_sections_early(nx_perms, ARRAY_SIZE(nx_perms));
 	return 0;
 }
 
-void fix_kernmem_perms(void)
+static void fix_kernmem_perms(void)
 {
 	stop_machine(__fix_kernmem_perms, NULL, NULL);
 }
 
-int __mark_rodata_ro(void *unused)
+static int __mark_rodata_ro(void *unused)
 {
 	update_sections_early(ro_perms, ARRAY_SIZE(ro_perms));
 	return 0;

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2a9040dcf47e..1d8558ff9827 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -14,6 +14,7 @@
 #include <linux/bootmem.h>
 #include <linux/mman.h>
 #include <linux/sched/signal.h>
+#include <linux/sched/task.h>
 #include <linux/export.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>

commit 3f07c0144132e4f59d88055ac8ff3e691a5fa2b8
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/signal.h>
    
    We are going to split <linux/sched/signal.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/signal.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index bf4d3bc41a7a..2a9040dcf47e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -13,6 +13,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/mman.h>
+#include <linux/sched/signal.h>
 #include <linux/export.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>

commit d4f4cf77b37eaea58ef863a4cbc95dad3880b524
Merge: f89db789de21 17a870bea3b8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 28 11:50:53 2017 -0800

    Merge branch 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - nommu updates from Afzal Mohammed cleaning up the vectors support
    
     - allow DMA memory "mapping" for nommu Benjamin Gaignard
    
     - fixing a correctness issue with R_ARM_PREL31 relocations in the
       module linker
    
     - add strlen() prototype for the decompressor
    
     - support for DEBUG_VIRTUAL from Florian Fainelli
    
     - adjusting memory bounds after memory reservations have been
       registered
    
     - unipher cache handling updates from Masahiro Yamada
    
     - initrd and Thumb Kconfig cleanups
    
    * 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (23 commits)
      ARM: mm: round the initrd reservation to page boundaries
      ARM: mm: clean up initrd initialisation
      ARM: mm: move initrd init code out of arm_memblock_init()
      ARM: 8655/1: improve NOMMU definition of pgprot_*()
      ARM: 8654/1: decompressor: add strlen prototype
      ARM: 8652/1: cache-uniphier: clean up active way setup code
      ARM: 8651/1: cache-uniphier: include <linux/errno.h> instead of <linux/types.h>
      ARM: 8650/1: module: handle negative R_ARM_PREL31 addends correctly
      ARM: 8649/2: nommu: remove Hivecs configuration is asm
      ARM: 8648/2: nommu: display vectors base
      ARM: 8647/2: nommu: dynamic exception base address setting
      ARM: 8646/1: mmu: decouple VECTORS_BASE from Kconfig
      ARM: 8644/1: Reduce "CPU: shutdown" message to debug level
      ARM: 8641/1: treewide: Replace uses of virt_to_phys with __pa_symbol
      ARM: 8640/1: Add support for CONFIG_DEBUG_VIRTUAL
      ARM: 8639/1: Define KERNEL_START and KERNEL_END
      ARM: 8638/1: mtd: lart: Rename partition defines to be prefixed with PART_
      ARM: 8637/1: Adjust memory boundaries after reservations
      ARM: 8636/1: Cleanup sanity_check_meminfo
      ARM: add CPU_THUMB_CAPABLE to indicate possible Thumb support
      ...

commit cdcc5fa0415d943288c6316bd32e76befb1027c5
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Mon Jan 16 15:21:05 2017 +0000

    ARM: mm: round the initrd reservation to page boundaries
    
    Round the initrd memblock reservation to page boundaries to prevent
    other data sharing the initrd pages.  This prevents an allocation
    possibly overlapping with the initrd, which would later get trampled
    on in free_initrd_mem().
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 15739a95552a..d1e26610977d 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -231,6 +231,9 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 static void __init arm_initrd_init(void)
 {
 #ifdef CONFIG_BLK_DEV_INITRD
+	phys_addr_t start;
+	unsigned long size;
+
 	/* FDT scan will populate initrd_start */
 	if (initrd_start && !phys_initrd_size) {
 		phys_initrd_start = __virt_to_phys(initrd_start);
@@ -242,19 +245,29 @@ static void __init arm_initrd_init(void)
 	if (!phys_initrd_size)
 		return;
 
-	if (!memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
+	/*
+	 * Round the memory region to page boundaries as per free_initrd_mem()
+	 * This allows us to detect whether the pages overlapping the initrd
+	 * are in use, but more importantly, reserves the entire set of pages
+	 * as we don't want these pages allocated for other purposes.
+	 */
+	start = round_down(phys_initrd_start, PAGE_SIZE);
+	size = phys_initrd_size + (phys_initrd_start - start);
+	size = round_up(size, PAGE_SIZE);
+
+	if (!memblock_is_region_memory(start, size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx is not a memory region - disabling initrd\n",
-		       (u64)phys_initrd_start, phys_initrd_size);
+		       (u64)start, size);
 		return;
 	}
 
-	if (memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
+	if (memblock_is_region_reserved(start, size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx overlaps in-use memory region - disabling initrd\n",
-		       (u64)phys_initrd_start, phys_initrd_size);
+		       (u64)start, size);
 		return;
 	}
 
-	memblock_reserve(phys_initrd_start, phys_initrd_size);
+	memblock_reserve(start, size);
 
 	/* Now convert initrd to virtual addresses */
 	initrd_start = __phys_to_virt(phys_initrd_start);

commit 68b32f361f3892fc376051b1702954b2dc692d13
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Mon Jan 16 15:13:25 2017 +0000

    ARM: mm: clean up initrd initialisation
    
    Rather than repeatedly testing phys_initrd_size to see if the initrd
    is still enabled, return from the new function to avoid executing the
    remaining initialisation.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 43d8825e59bb..15739a95552a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -236,26 +236,29 @@ static void __init arm_initrd_init(void)
 		phys_initrd_start = __virt_to_phys(initrd_start);
 		phys_initrd_size = initrd_end - initrd_start;
 	}
+
 	initrd_start = initrd_end = 0;
-	if (phys_initrd_size &&
-	    !memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
+
+	if (!phys_initrd_size)
+		return;
+
+	if (!memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx is not a memory region - disabling initrd\n",
 		       (u64)phys_initrd_start, phys_initrd_size);
-		phys_initrd_start = phys_initrd_size = 0;
+		return;
 	}
-	if (phys_initrd_size &&
-	    memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
+
+	if (memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx overlaps in-use memory region - disabling initrd\n",
 		       (u64)phys_initrd_start, phys_initrd_size);
-		phys_initrd_start = phys_initrd_size = 0;
+		return;
 	}
-	if (phys_initrd_size) {
-		memblock_reserve(phys_initrd_start, phys_initrd_size);
 
-		/* Now convert initrd to virtual addresses */
-		initrd_start = __phys_to_virt(phys_initrd_start);
-		initrd_end = initrd_start + phys_initrd_size;
-	}
+	memblock_reserve(phys_initrd_start, phys_initrd_size);
+
+	/* Now convert initrd to virtual addresses */
+	initrd_start = __phys_to_virt(phys_initrd_start);
+	initrd_end = initrd_start + phys_initrd_size;
 #endif
 }
 

commit 3928624812dcfa39b6a67f9de46efcb51c573ad0
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Mon Jan 16 15:11:10 2017 +0000

    ARM: mm: move initrd init code out of arm_memblock_init()
    
    Move the ARM initrd initialisation code out of arm_memblock_init() into
    its own function, so it can be cleaned up.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 50e5402a8ef3..43d8825e59bb 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -228,11 +228,8 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 	return phys;
 }
 
-void __init arm_memblock_init(const struct machine_desc *mdesc)
+static void __init arm_initrd_init(void)
 {
-	/* Register the kernel text, kernel data and initrd with memblock. */
-	memblock_reserve(__pa(KERNEL_START), KERNEL_END - KERNEL_START);
-
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* FDT scan will populate initrd_start */
 	if (initrd_start && !phys_initrd_size) {
@@ -260,6 +257,14 @@ void __init arm_memblock_init(const struct machine_desc *mdesc)
 		initrd_end = initrd_start + phys_initrd_size;
 	}
 #endif
+}
+
+void __init arm_memblock_init(const struct machine_desc *mdesc)
+{
+	/* Register the kernel text, kernel data and initrd with memblock. */
+	memblock_reserve(__pa(KERNEL_START), KERNEL_END - KERNEL_START);
+
+	arm_initrd_init();
 
 	arm_mm_memblock_reserve();
 

commit d2ca5f2491c1246adf3847101fdc538a3b89439c
Author: Afzal Mohammed <afzal.mohd.ma@gmail.com>
Date:   Sun Jan 29 17:31:32 2017 +0100

    ARM: 8646/1: mmu: decouple VECTORS_BASE from Kconfig
    
    For MMU configurations, VECTORS_BASE is always 0xffff0000, a macro
    definition will suffice.
    
    For no-MMU, exception base address is dynamically determined in
    subsequent patches. To preserve bisectability, now make the
    macro applicable for no-MMU scenario too.
    
    Thanks to 0-DAY kernel test infrastructure that found the
    bisectability issue. This macro will be restricted to MMU case upon
    dynamically determining exception base address for no-MMU.
    
    Once exception address is handled dynamically for no-MMU,
    VECTORS_BASE can be removed from Kconfig.
    
    Signed-off-by: afzal mohammed <afzal.mohd.ma@gmail.com>
    Tested-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4127f578086c..50e5402a8ef3 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -27,6 +27,7 @@
 #include <asm/cp15.h>
 #include <asm/mach-types.h>
 #include <asm/memblock.h>
+#include <asm/memory.h>
 #include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
@@ -518,8 +519,7 @@ void __init mem_init(void)
 			"      .data : 0x%p" " - 0x%p" "   (%4td kB)\n"
 			"       .bss : 0x%p" " - 0x%p" "   (%4td kB)\n",
 
-			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
-				(PAGE_SIZE)),
+			MLK(VECTORS_BASE, VECTORS_BASE + PAGE_SIZE),
 #ifdef CONFIG_HAVE_TCM
 			MLK(DTCM_OFFSET, (unsigned long) dtcm_end),
 			MLK(ITCM_OFFSET, (unsigned long) itcm_end),

commit a09975bf6c756e4555a95258ff4b2286dcfddc4e
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Sun Jan 15 03:57:40 2017 +0100

    ARM: 8639/1: Define KERNEL_START and KERNEL_END
    
    In preparation for adding CONFIG_DEBUG_VIRTUAL support, define a set of
    common constants: KERNEL_START and KERNEL_END which abstract
    CONFIG_XIP_KERNEL vs. !CONFIG_XIP_KERNEL. Update the code where
    relevant.
    
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 370581aeb871..4127f578086c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -230,11 +230,8 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 void __init arm_memblock_init(const struct machine_desc *mdesc)
 {
 	/* Register the kernel text, kernel data and initrd with memblock. */
-#ifdef CONFIG_XIP_KERNEL
-	memblock_reserve(__pa(_sdata), _end - _sdata);
-#else
-	memblock_reserve(__pa(_stext), _end - _stext);
-#endif
+	memblock_reserve(__pa(KERNEL_START), KERNEL_END - KERNEL_START);
+
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* FDT scan will populate initrd_start */
 	if (initrd_start && !phys_initrd_size) {

commit 0f5bf6d0afe4be6e1391908ff2d6dc9730e91550
Author: Laura Abbott <labbott@redhat.com>
Date:   Mon Feb 6 16:31:58 2017 -0800

    arch: Rename CONFIG_DEBUG_RODATA and CONFIG_DEBUG_MODULE_RONX
    
    Both of these options are poorly named. The features they provide are
    necessary for system security and should not be considered debug only.
    Change the names to CONFIG_STRICT_KERNEL_RWX and
    CONFIG_STRICT_MODULE_RWX to better describe what these options do.
    
    Signed-off-by: Laura Abbott <labbott@redhat.com>
    Acked-by: Jessica Yu <jeyu@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 370581aeb871..4be0bee4c357 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -572,7 +572,7 @@ void __init mem_init(void)
 	}
 }
 
-#ifdef CONFIG_DEBUG_RODATA
+#ifdef CONFIG_STRICT_KERNEL_RWX
 struct section_perm {
 	const char *name;
 	unsigned long start;
@@ -741,7 +741,7 @@ void set_kernel_text_ro(void)
 
 #else
 static inline void fix_kernmem_perms(void) { }
-#endif /* CONFIG_DEBUG_RODATA */
+#endif /* CONFIG_STRICT_KERNEL_RWX */
 
 void free_tcmmem(void)
 {

commit 64ac2e74f0b21505606faf725cb5633d63b8b728
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jan 26 01:20:21 2016 +0100

    ARM: 8502/1: mm: mark section-aligned portion of rodata NX
    
    When rodata is large enough that it crosses a section boundary after the
    kernel text, mark the rest NX. This is as close to full NX of rodata as
    we can get without splitting page tables or doing section alignment via
    CONFIG_DEBUG_ALIGN_RODATA.
    
    When the config is:
    
     CONFIG_DEBUG_RODATA=y
     # CONFIG_DEBUG_ALIGN_RODATA is not set
    
    Before:
    
    ---[ Kernel Mapping ]---
    0x80000000-0x80100000           1M     RW NX SHD
    0x80100000-0x80a00000           9M     ro x  SHD
    0x80a00000-0xa0000000         502M     RW NX SHD
    
    After:
    
    ---[ Kernel Mapping ]---
    0x80000000-0x80100000           1M     RW NX SHD
    0x80100000-0x80700000           6M     ro x  SHD
    0x80700000-0x80a00000           3M     ro NX SHD
    0x80a00000-0xa0000000         502M     RW NX SHD
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 53f42508025b..370581aeb871 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -582,6 +582,9 @@ struct section_perm {
 	pmdval_t clear;
 };
 
+/* First section-aligned location at or after __start_rodata. */
+extern char __start_rodata_section_aligned[];
+
 static struct section_perm nx_perms[] = {
 	/* Make pages tables, etc before _stext RW (set NX). */
 	{
@@ -599,16 +602,14 @@ static struct section_perm nx_perms[] = {
 		.mask	= ~PMD_SECT_XN,
 		.prot	= PMD_SECT_XN,
 	},
-#ifdef CONFIG_DEBUG_ALIGN_RODATA
 	/* Make rodata NX (set RO in ro_perms below). */
 	{
 		.name	= "rodata NX",
-		.start  = (unsigned long)__start_rodata,
+		.start  = (unsigned long)__start_rodata_section_aligned,
 		.end    = (unsigned long)__init_begin,
 		.mask   = ~PMD_SECT_XN,
 		.prot   = PMD_SECT_XN,
 	},
-#endif
 };
 
 static struct section_perm ro_perms[] = {

commit 25362dc496edaf17f714c0fecd8b3eb79670207b
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jan 26 01:19:36 2016 +0100

    ARM: 8501/1: mm: flip priority of CONFIG_DEBUG_RODATA
    
    The use of CONFIG_DEBUG_RODATA is generally seen as an essential part of
    kernel self-protection:
    http://www.openwall.com/lists/kernel-hardening/2015/11/30/13
    Additionally, its name has grown to mean things beyond just rodata. To
    get ARM closer to this, we ought to rearrange the names of the configs
    that control how the kernel protects its memory. What was called
    CONFIG_ARM_KERNMEM_PERMS is realy doing the work that other architectures
    call CONFIG_DEBUG_RODATA.
    
    This redefines CONFIG_DEBUG_RODATA to actually do the bulk of the
    ROing (and NXing). In the place of the old CONFIG_DEBUG_RODATA, use
    CONFIG_DEBUG_ALIGN_RODATA, since that's what the option does: adds
    section alignment for making rodata explicitly NX, as arm does not split
    the page tables like arm64 does without _ALIGN_RODATA.
    
    Also adds human readable names to the sections so I could more easily
    debug my typos, and makes CONFIG_DEBUG_RODATA default "y" for CPU_V7.
    
    Results in /sys/kernel/debug/kernel_page_tables for each config state:
    
     # CONFIG_DEBUG_RODATA is not set
     # CONFIG_DEBUG_ALIGN_RODATA is not set
    
    ---[ Kernel Mapping ]---
    0x80000000-0x80900000           9M     RW x  SHD
    0x80900000-0xa0000000         503M     RW NX SHD
    
     CONFIG_DEBUG_RODATA=y
     CONFIG_DEBUG_ALIGN_RODATA=y
    
    ---[ Kernel Mapping ]---
    0x80000000-0x80100000           1M     RW NX SHD
    0x80100000-0x80700000           6M     ro x  SHD
    0x80700000-0x80a00000           3M     ro NX SHD
    0x80a00000-0xa0000000         502M     RW NX SHD
    
     CONFIG_DEBUG_RODATA=y
     # CONFIG_DEBUG_ALIGN_RODATA is not set
    
    ---[ Kernel Mapping ]---
    0x80000000-0x80100000           1M     RW NX SHD
    0x80100000-0x80a00000           9M     ro x  SHD
    0x80a00000-0xa0000000         502M     RW NX SHD
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Laura Abbott <labbott@fedoraproject.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 49bd08178008..53f42508025b 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -572,8 +572,9 @@ void __init mem_init(void)
 	}
 }
 
-#ifdef CONFIG_ARM_KERNMEM_PERMS
+#ifdef CONFIG_DEBUG_RODATA
 struct section_perm {
+	const char *name;
 	unsigned long start;
 	unsigned long end;
 	pmdval_t mask;
@@ -584,6 +585,7 @@ struct section_perm {
 static struct section_perm nx_perms[] = {
 	/* Make pages tables, etc before _stext RW (set NX). */
 	{
+		.name	= "pre-text NX",
 		.start	= PAGE_OFFSET,
 		.end	= (unsigned long)_stext,
 		.mask	= ~PMD_SECT_XN,
@@ -591,14 +593,16 @@ static struct section_perm nx_perms[] = {
 	},
 	/* Make init RW (set NX). */
 	{
+		.name	= "init NX",
 		.start	= (unsigned long)__init_begin,
 		.end	= (unsigned long)_sdata,
 		.mask	= ~PMD_SECT_XN,
 		.prot	= PMD_SECT_XN,
 	},
-#ifdef CONFIG_DEBUG_RODATA
+#ifdef CONFIG_DEBUG_ALIGN_RODATA
 	/* Make rodata NX (set RO in ro_perms below). */
 	{
+		.name	= "rodata NX",
 		.start  = (unsigned long)__start_rodata,
 		.end    = (unsigned long)__init_begin,
 		.mask   = ~PMD_SECT_XN,
@@ -607,10 +611,10 @@ static struct section_perm nx_perms[] = {
 #endif
 };
 
-#ifdef CONFIG_DEBUG_RODATA
 static struct section_perm ro_perms[] = {
 	/* Make kernel code and rodata RX (set RO). */
 	{
+		.name	= "text/rodata RO",
 		.start  = (unsigned long)_stext,
 		.end    = (unsigned long)__init_begin,
 #ifdef CONFIG_ARM_LPAE
@@ -623,7 +627,6 @@ static struct section_perm ro_perms[] = {
 #endif
 	},
 };
-#endif
 
 /*
  * Updates section permissions only for the current mm (sections are
@@ -670,8 +673,8 @@ void set_section_perms(struct section_perm *perms, int n, bool set,
 	for (i = 0; i < n; i++) {
 		if (!IS_ALIGNED(perms[i].start, SECTION_SIZE) ||
 		    !IS_ALIGNED(perms[i].end, SECTION_SIZE)) {
-			pr_err("BUG: section %lx-%lx not aligned to %lx\n",
-				perms[i].start, perms[i].end,
+			pr_err("BUG: %s section %lx-%lx not aligned to %lx\n",
+				perms[i].name, perms[i].start, perms[i].end,
 				SECTION_SIZE);
 			continue;
 		}
@@ -712,7 +715,6 @@ void fix_kernmem_perms(void)
 	stop_machine(__fix_kernmem_perms, NULL, NULL);
 }
 
-#ifdef CONFIG_DEBUG_RODATA
 int __mark_rodata_ro(void *unused)
 {
 	update_sections_early(ro_perms, ARRAY_SIZE(ro_perms));
@@ -735,11 +737,10 @@ void set_kernel_text_ro(void)
 	set_section_perms(ro_perms, ARRAY_SIZE(ro_perms), true,
 				current->active_mm);
 }
-#endif /* CONFIG_DEBUG_RODATA */
 
 #else
 static inline void fix_kernmem_perms(void) { }
-#endif /* CONFIG_ARM_KERNMEM_PERMS */
+#endif /* CONFIG_DEBUG_RODATA */
 
 void free_tcmmem(void)
 {

commit 6660800fb7fd0f66faecb3c550fe59709220ade5
Merge: 598bcc6ea6ec 06312f44ad63
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jan 12 13:41:03 2016 +0000

    Merge branch 'devel-stable' into for-linus

commit 09414d00a137cf7f42b6dc7415f346258d60e8da
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Oct 1 17:58:11 2015 +0200

    ARM: only consider memblocks with NOMAP cleared for linear mapping
    
    Take the new memblock attribute MEMBLOCK_NOMAP into account when
    deciding whether a certain region is or should be covered by the
    kernel direct mapping.
    
    Tested-by: Ryan Harkin <ryan.harkin@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8a63b4cdc0f2..16104b1e2661 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -191,7 +191,7 @@ static void __init zone_sizes_init(unsigned long min, unsigned long max_low,
 #ifdef CONFIG_HAVE_ARCH_PFN_VALID
 int pfn_valid(unsigned long pfn)
 {
-	return memblock_is_memory(__pfn_to_phys(pfn));
+	return memblock_is_map_memory(__pfn_to_phys(pfn));
 }
 EXPORT_SYMBOL(pfn_valid);
 #endif
@@ -432,6 +432,9 @@ static void __init free_highpages(void)
 		if (end <= max_low)
 			continue;
 
+		if (memblock_is_nomap(mem))
+			continue;
+
 		/* Truncate partial highmem entries */
 		if (start < max_low)
 			start = max_low;

commit 08925c2f124f1bac6152a8b234268f9874fc70a5
Author: Laura Abbott <labbott@redhat.com>
Date:   Mon Nov 30 19:36:28 2015 +0100

    ARM: 8464/1: Update all mm structures with section adjustments
    
    Currently, when updating section permissions to mark areas RO
    or NX, the only mm updated is current->mm. This is working off
    the assumption that there are no additional mm structures at
    the time. This may not always hold true. (Example: calling
    modprobe early will trigger a fork/exec). Ensure all mm structres
    get updated with the new section information.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Laura Abbott <labbott@fedoraproject.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8a63b4cdc0f2..7f8cd1b3557f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -22,6 +22,7 @@
 #include <linux/memblock.h>
 #include <linux/dma-contiguous.h>
 #include <linux/sizes.h>
+#include <linux/stop_machine.h>
 
 #include <asm/cp15.h>
 #include <asm/mach-types.h>
@@ -627,12 +628,10 @@ static struct section_perm ro_perms[] = {
  * safe to be called with preemption disabled, as under stop_machine().
  */
 static inline void section_update(unsigned long addr, pmdval_t mask,
-				  pmdval_t prot)
+				  pmdval_t prot, struct mm_struct *mm)
 {
-	struct mm_struct *mm;
 	pmd_t *pmd;
 
-	mm = current->active_mm;
 	pmd = pmd_offset(pud_offset(pgd_offset(mm, addr), addr), addr);
 
 #ifdef CONFIG_ARM_LPAE
@@ -656,49 +655,82 @@ static inline bool arch_has_strict_perms(void)
 	return !!(get_cr() & CR_XP);
 }
 
-#define set_section_perms(perms, field)	{				\
-	size_t i;							\
-	unsigned long addr;						\
-									\
-	if (!arch_has_strict_perms())					\
-		return;							\
-									\
-	for (i = 0; i < ARRAY_SIZE(perms); i++) {			\
-		if (!IS_ALIGNED(perms[i].start, SECTION_SIZE) ||	\
-		    !IS_ALIGNED(perms[i].end, SECTION_SIZE)) {		\
-			pr_err("BUG: section %lx-%lx not aligned to %lx\n", \
-				perms[i].start, perms[i].end,		\
-				SECTION_SIZE);				\
-			continue;					\
-		}							\
-									\
-		for (addr = perms[i].start;				\
-		     addr < perms[i].end;				\
-		     addr += SECTION_SIZE)				\
-			section_update(addr, perms[i].mask,		\
-				       perms[i].field);			\
-	}								\
+void set_section_perms(struct section_perm *perms, int n, bool set,
+			struct mm_struct *mm)
+{
+	size_t i;
+	unsigned long addr;
+
+	if (!arch_has_strict_perms())
+		return;
+
+	for (i = 0; i < n; i++) {
+		if (!IS_ALIGNED(perms[i].start, SECTION_SIZE) ||
+		    !IS_ALIGNED(perms[i].end, SECTION_SIZE)) {
+			pr_err("BUG: section %lx-%lx not aligned to %lx\n",
+				perms[i].start, perms[i].end,
+				SECTION_SIZE);
+			continue;
+		}
+
+		for (addr = perms[i].start;
+		     addr < perms[i].end;
+		     addr += SECTION_SIZE)
+			section_update(addr, perms[i].mask,
+				set ? perms[i].prot : perms[i].clear, mm);
+	}
+
 }
 
-static inline void fix_kernmem_perms(void)
+static void update_sections_early(struct section_perm perms[], int n)
 {
-	set_section_perms(nx_perms, prot);
+	struct task_struct *t, *s;
+
+	read_lock(&tasklist_lock);
+	for_each_process(t) {
+		if (t->flags & PF_KTHREAD)
+			continue;
+		for_each_thread(t, s)
+			set_section_perms(perms, n, true, s->mm);
+	}
+	read_unlock(&tasklist_lock);
+	set_section_perms(perms, n, true, current->active_mm);
+	set_section_perms(perms, n, true, &init_mm);
+}
+
+int __fix_kernmem_perms(void *unused)
+{
+	update_sections_early(nx_perms, ARRAY_SIZE(nx_perms));
+	return 0;
+}
+
+void fix_kernmem_perms(void)
+{
+	stop_machine(__fix_kernmem_perms, NULL, NULL);
 }
 
 #ifdef CONFIG_DEBUG_RODATA
+int __mark_rodata_ro(void *unused)
+{
+	update_sections_early(ro_perms, ARRAY_SIZE(ro_perms));
+	return 0;
+}
+
 void mark_rodata_ro(void)
 {
-	set_section_perms(ro_perms, prot);
+	stop_machine(__mark_rodata_ro, NULL, NULL);
 }
 
 void set_kernel_text_rw(void)
 {
-	set_section_perms(ro_perms, clear);
+	set_section_perms(ro_perms, ARRAY_SIZE(ro_perms), false,
+				current->active_mm);
 }
 
 void set_kernel_text_ro(void)
 {
-	set_section_perms(ro_perms, prot);
+	set_section_perms(ro_perms, ARRAY_SIZE(ro_perms), true,
+				current->active_mm);
 }
 #endif /* CONFIG_DEBUG_RODATA */
 

commit 24bbd929e6b9e62afd263c42b4318d3b603c956c
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Jun 1 13:40:31 2015 +0200

    of/fdt: split off FDT self reservation from memreserve processing
    
    This splits off the reservation of the memory occupied by the FDT
    binary itself from the processing of the memory reservations it
    contains. This is necessary because the physical address of the FDT,
    which is needed to perform the reservation, may not be known to the
    FDT driver core, i.e., it may be mapped outside the linear direct
    mapping, in which case __pa() returns a bogus value.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Acked-by: Rob Herring <robh@kernel.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index be92fa0f2f35..8a63b4cdc0f2 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -268,6 +268,7 @@ void __init arm_memblock_init(const struct machine_desc *mdesc)
 	if (mdesc->reserve)
 		mdesc->reserve();
 
+	early_init_fdt_reserve_self();
 	early_init_fdt_scan_reserved_mem();
 
 	/* reserve memory for DMA contiguous allocations */

commit bb0fd7ab0986105765d11baa82e619c618a235aa
Merge: bdfa54dfd9ee 4b2f8838479e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 14 21:03:26 2015 -0700

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "Included in this update are both some long term fixes and some new
      features.
    
      Fixes:
    
       - An integer overflow in the calculation of ELF_ET_DYN_BASE.
    
       - Avoiding OOMs for high-order IOMMU allocations
    
       - SMP requires the data cache to be enabled for synchronisation
         primitives to work, so prevent the CPU_DCACHE_DISABLE option being
         visible on SMP builds.
    
       - A bug going back 10+ years in the noMMU ARM94* CPU support code,
         where it corrupts registers.  Found by folk getting Linux running
         on their cameras.
    
       - Versatile Express needs an errata workaround enabled for CPU
         hot-unplug to work.
    
      Features:
    
       - Clean up module linker by handling out of range relocations
         separately from relocation cases we don't handle.
    
       - Fix a long term bug in the pci_mmap_page_range() code, which we
         hope won't impact userspace (we hope there's no users of the
         existing broken interface.)
    
       - Don't map DMA coherent allocations when we don't have a MMU.
    
       - Drop experimental status for SMP_ON_UP.
    
       - Warn when DT doesn't specify ePAPR mandatory cache properties.
    
       - Add documentation concerning how we find the start of physical
         memory for AUTO_ZRELADDR kernels, detailing why we have chosen the
         mask and the implications of changing it.
    
       - Updates from Ard Biesheuvel to address some issues with large
         kernels (such as allyesconfig) failing to link.
    
       - Allow hibernation to work on modern (ARMv7) CPUs - this appears to
         have never worked in the past on these CPUs.
    
       - Enable IRQ_SHOW_LEVEL, which changes the /proc/interrupts output
         format (hopefully without userspace breaking...  let's hope that if
         it causes someone a problem, they tell us.)
    
       - Fix tegra-ahb DT offsets.
    
       - Rework ARM errata 643719 code (and ARMv7 flush_cache_louis()/
         flush_dcache_all()) code to be more efficient, and enable this
         errata workaround by default for ARMv7+SMP CPUs.  This complements
         the Versatile Express fix above.
    
       - Rework ARMv7 context code for errata 430973, so that only Cortex A8
         CPUs are impacted by the branch target buffer flush when this
         errata is enabled.  Also update the help text to indicate that all
         r1p* A8 CPUs are impacted.
    
       - Switch ARM to the generic show_mem() implementation, it conveys all
         the information which we were already reporting.
    
       - Prevent slow timer sources being used for udelay() - timers running
         at less than 1MHz are not useful for this, and can cause udelay()
         to return immediately, without any wait.  Using such a slow timer
         is silly.
    
       - VDSO support for 32-bit ARM, mainly for gettimeofday() using the
         ARM architected timer.
    
       - Perf support for Scorpion performance monitoring units"
    
    vdso semantic conflict fixed up as per linux-next.
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (52 commits)
      ARM: update errata 430973 documentation to cover Cortex A8 r1p*
      ARM: ensure delay timer has sufficient accuracy for delays
      ARM: switch to use the generic show_mem() implementation
      ARM: proc-v7: avoid errata 430973 workaround for non-Cortex A8 CPUs
      ARM: enable ARM errata 643719 workaround by default
      ARM: cache-v7: optimise test for Cortex A9 r0pX devices
      ARM: cache-v7: optimise branches in v7_flush_cache_louis
      ARM: cache-v7: consolidate initialisation of cache level index
      ARM: cache-v7: shift CLIDR to extract appropriate field before masking
      ARM: cache-v7: use movw/movt instructions
      ARM: allow 16-bit instructions in ALT_UP()
      ARM: proc-arm94*.S: fix setup function
      ARM: vexpress: fix CPU hotplug with CT9x4 tile.
      ARM: 8276/1: Make CPU_DCACHE_DISABLE depend on !SMP
      ARM: 8335/1: Documentation: DT bindings: Tegra AHB: document the legacy base address
      ARM: 8334/1: amba: tegra-ahb: detect and correct bogus base address
      ARM: 8333/1: amba: tegra-ahb: fix register offsets in the macros
      ARM: 8339/1: Enable CONFIG_GENERIC_IRQ_SHOW_LEVEL
      ARM: 8338/1: kexec: Relax SMP validation to improve DT compatibility
      ARM: 8337/1: mm: Do not invoke OOM for higher order IOMMU DMA allocations
      ...

commit d30eae473360aea25e0584d4fbf6a70417d89784
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Tue Apr 14 15:48:37 2015 -0700

    arm: add support for memtest
    
    Add support for memtest command line option.
    
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1609b022a72f..3d0e9aed4b40 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -335,6 +335,9 @@ void __init bootmem_init(void)
 
 	find_limits(&min, &max_low, &max_high);
 
+	early_memtest((phys_addr_t)min << PAGE_SHIFT,
+		      (phys_addr_t)max_low << PAGE_SHIFT);
+
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations

commit 37463be8658ae5fba153f4029ca3ec3f8a64fd51
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Mar 26 11:43:51 2015 +0000

    ARM: switch to use the generic show_mem() implementation
    
    Switch ARM to use the generic show_mem() implementation, which displays
    the statistics from the mm zone rather than walking the page arrays.
    
    Acked-by: Mel Gorman <mgorman <mgorman@suse.de>
    Tested-by: Gregory Fong <gregory.0xf0@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1609b022a72f..ae369c1066e6 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -86,55 +86,6 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
-/*
- * This keeps memory configuration data used by a couple memory
- * initialization functions, as well as show_mem() for the skipping
- * of holes in the memory map.  It is populated by arm_add_memory().
- */
-void show_mem(unsigned int filter)
-{
-	int free = 0, total = 0, reserved = 0;
-	int shared = 0, cached = 0, slab = 0;
-	struct memblock_region *reg;
-
-	printk("Mem-info:\n");
-	show_free_areas(filter);
-
-	for_each_memblock (memory, reg) {
-		unsigned int pfn1, pfn2;
-		struct page *page, *end;
-
-		pfn1 = memblock_region_memory_base_pfn(reg);
-		pfn2 = memblock_region_memory_end_pfn(reg);
-
-		page = pfn_to_page(pfn1);
-		end  = pfn_to_page(pfn2 - 1) + 1;
-
-		do {
-			total++;
-			if (PageReserved(page))
-				reserved++;
-			else if (PageSwapCache(page))
-				cached++;
-			else if (PageSlab(page))
-				slab++;
-			else if (!page_count(page))
-				free++;
-			else
-				shared += page_count(page) - 1;
-			pfn1++;
-			page = pfn_to_page(pfn1);
-		} while (pfn1 < pfn2);
-	}
-
-	printk("%d pages of RAM\n", total);
-	printk("%d free pages\n", free);
-	printk("%d reserved pages\n", reserved);
-	printk("%d slab pages\n", slab);
-	printk("%d pages shared\n", shared);
-	printk("%d pages swap cached\n", cached);
-}
-
 static void __init find_limits(unsigned long *min, unsigned long *max_low,
 			       unsigned long *max_high)
 {

commit ed8f8ce38d0f7b505d7da2d79522972e962457c2
Merge: a61cbf51f0a6 8e6480667246 1d88967900b8 3cf385713460 e461894dc2ce
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Feb 10 10:26:27 2015 +0000

    Merge branches 'debug', 'fixes', 'l2c' (early part), 'misc' and 'sa1100' into for-next

commit 99a468d779f6851a31053e6a33bf91391034010b
Author: George G. Davis <ggdavisiv@gmail.com>
Date:   Fri Jan 16 11:21:05 2015 +0100

    ARM: 8286/1: mm: Fix dma_contiguous_reserve comment
    
    DMA contiguous allocations have been able to use highmem since commit
    "95b0e65 ARM: mm: don't limit default CMA region only to low memory"
    but a comment still notes the earlier "low memory" limitation.  Update
    the comment to remove the low memory limitation and fix the
    s/contigouos/contiguous/ typo while we're at it.
    
    Signed-off-by: George G. Davis <george_davis@mentor.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 98ad9c79ea0e..d538dc73fcb0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -319,10 +319,7 @@ void __init arm_memblock_init(const struct machine_desc *mdesc)
 
 	early_init_fdt_scan_reserved_mem();
 
-	/*
-	 * reserve memory for DMA contigouos allocations,
-	 * must come from DMA area inside low memory
-	 */
+	/* reserve memory for DMA contiguous allocations */
 	dma_contiguous_reserve(arm_dma_limit);
 
 	arm_memblock_steal_permitted = false;

commit 1e3479225acbb7ae048ac30fb7c6090fa7f0df02
Author: Victor Kamensky <victor.kamensky@linaro.org>
Date:   Fri Jan 9 18:55:45 2015 +0100

    ARM: 8275/1: mm: fix PMD_SECT_RDONLY undeclared compile error
    
    In v3.19-rc3 tree when CONFIG_ARM_LPAE and CONFIG_DEBUG_RODATA are enabled
    image failed to compile with the following error:
    
    arch/arm/mm/init.c:661:14: error: ‘PMD_SECT_RDONLY’ undeclared here (not in a function)
    
    It seems that '80d6b0c ARM: mm: allow text and rodata sections to be read-only'
    and 'ded9477 ARM: 8109/1: mm: Modify pte_write and pmd_write logic for LPAE'
    commits crossed. 80d6b0c uses PMD_SECT_RDONLY macro but ded9477 renames it
    and uses software bits L_PMD_SECT_RDONLY instead.
    
    Fix is to use L_PMD_SECT_RDONLY instead PMD_SECT_RDONLY as ded9477 does in
    another places.
    
    Signed-off-by: Victor Kamensky <victor.kamensky@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 98ad9c79ea0e..2495c8cb47ba 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -658,8 +658,8 @@ static struct section_perm ro_perms[] = {
 		.start  = (unsigned long)_stext,
 		.end    = (unsigned long)__init_begin,
 #ifdef CONFIG_ARM_LPAE
-		.mask   = ~PMD_SECT_RDONLY,
-		.prot   = PMD_SECT_RDONLY,
+		.mask   = ~L_PMD_SECT_RDONLY,
+		.prot   = L_PMD_SECT_RDONLY,
 #else
 		.mask   = ~(PMD_SECT_APX | PMD_SECT_AP_WRITE),
 		.prot   = PMD_SECT_APX | PMD_SECT_AP_WRITE,

commit 26ceb127f7bcf473db926c6a026b18ddd6f274e8
Merge: 8d1406675559 e9f2d6d66037
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 12 15:26:48 2014 -0800

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "The major updates included in this update are:
    
       - Clang compatible stack pointer accesses by Behan Webster.
       - SA11x0 updates from Dmitry Eremin-Solenikov.
       - kgdb handling of breakpoints with read-only text/modules
       - Support for Privileged-no-execute feature on ARMv7 to prevent
         userspace code execution by the kernel.
       - AMBA primecell bus handling of irq-safe runtime PM
       - Unwinding support for memset/memzero/memmove/memcpy functions
       - VFP fixes for Krait CPUs and improvements in detecting the VFP
         architecture
       - A number of code cleanups (using pr_*, removing or reducing the
         severity of a couple of kernel messages, splitting ftrace asm code
         out to a separate file, etc.)
       - Add machine name to stack dump output"
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (62 commits)
      ARM: 8247/2: pcmcia: sa1100: make use of device clock
      ARM: 8246/2: pcmcia: sa1111: provide device clock
      ARM: 8245/1: pcmcia: soc-common: enable/disable socket clocks
      ARM: 8244/1: fbdev: sa1100fb: make use of device clock
      ARM: 8243/1: sa1100: add a clock alias for sa1111 pcmcia device
      ARM: 8242/1: sa1100: add cpu clock
      ARM: 8221/1: PJ4: allow building in Thumb-2 mode
      ARM: 8234/1: sa1100: reorder IRQ handling code
      ARM: 8233/1: sa1100: switch to hwirq usage
      ARM: 8232/1: sa1100: merge GPIO multiplexer IRQ to "normal" irq domain
      ARM: 8231/1: sa1100: introduce irqdomains support
      ARM: 8230/1: sa1100: shift IRQs by one
      ARM: 8229/1: sa1100: replace irq numbers with names in irq driver
      ARM: 8228/1: sa1100: drop entry-macro.S
      ARM: 8227/1: sa1100: switch to MULTI_IRQ_HANDLER
      ARM: 8241/1: Update processor_modes for hyp and monitor mode
      ARM: 8240/1: MCPM: document mcpm_sync_init()
      ARM: 8239/1: Introduce {set,clear}_pte_bit
      ARM: 8238/1: mm: Refine set_memory_* functions
      ARM: 8237/1: fix flush_pfn_alias
      ...

commit e9f2d6d66037cdf97487491e04053f411abc5d16
Merge: fbe4dd088f44 06e944b8e5fc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Dec 5 16:30:54 2014 +0000

    Merge branch 'devel-stable' into for-next

commit 4ed89f2228061422ce5f62545fd0b6f6648bd2cc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Oct 28 11:26:42 2014 +0000

    ARM: convert printk(KERN_* to pr_*
    
    Convert many (but not all) printk(KERN_* to pr_* to simplify the code.
    We take the opportunity to join some printk lines together so we don't
    split the message across several lines, and we also add a few levels
    to some messages which were previously missing them.
    
    Tested-by: Andrew Lunn <andrew@lunn.ch>
    Tested-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 92bba32d9230..6ca53c338519 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -67,7 +67,7 @@ early_param("initrd", early_initrd);
 
 static int __init parse_tag_initrd(const struct tag *tag)
 {
-	printk(KERN_WARNING "ATAG_INITRD is deprecated; "
+	pr_warn("ATAG_INITRD is deprecated; "
 		"please update your bootloader.\n");
 	phys_initrd_start = __virt_to_phys(tag->u.initrd.start);
 	phys_initrd_size = tag->u.initrd.size;
@@ -544,7 +544,7 @@ void __init mem_init(void)
 #define MLM(b, t) b, t, ((t) - (b)) >> 20
 #define MLK_ROUNDUP(b, t) b, t, DIV_ROUND_UP(((t) - (b)), SZ_1K)
 
-	printk(KERN_NOTICE "Virtual kernel memory layout:\n"
+	pr_notice("Virtual kernel memory layout:\n"
 			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 #ifdef CONFIG_HAVE_TCM
 			"    DTCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"

commit 06e944b8e5fc4bec83f102f98c1ee4f972f5f072
Merge: f114040e3ea6 80d6b0c2eed2
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Nov 3 10:12:13 2014 +0000

    Merge tag 'ronx-next' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux into devel-stable
    
    generic fixmaps
    ARM support for CONFIG_DEBUG_RODATA

commit 6e2028aaa1373081e553d4442736ce0d1dd279e8
Merge: ce9ec37bddb6 178c3dfe853a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 28 13:17:11 2014 -0700

    Merge branch 'fixes' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM fixes from Russell King:
     "A couple of ARM fixes.
    
      We fix some printk formats for ptrdiff_t quantities which cause GCC
      4.9 to complain, and we also blacklist known buggy GCC 4.8.x compilers
      as their miscompilation is serious enough to cause filesystem
      corruption, even through many distros have fixed their versions"
    
    * 'fixes' of git://ftp.arm.linux.org.uk/~rmk/linux-arm:
      ARM: fix some printk formats
      ARM: Blacklist GCC 4.8.0 to GCC 4.8.2 - PR58854

commit 178c3dfe853a18391b029e6b62e1eed22be1871e
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Oct 19 22:42:42 2014 +0100

    ARM: fix some printk formats
    
    GCC 4.9 complains if we take the difference of two pointers, and it's
    printed with "%d".  Fix this by using the proper flag - "t" for
    ptrdiff_t.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 659c75d808dc..1dfcc0822074 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -559,10 +559,10 @@ void __init mem_init(void)
 #ifdef CONFIG_MODULES
 			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 #endif
-			"      .text : 0x%p" " - 0x%p" "   (%4d kB)\n"
-			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
-			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n"
-			"       .bss : 0x%p" " - 0x%p" "   (%4d kB)\n",
+			"      .text : 0x%p" " - 0x%p" "   (%4td kB)\n"
+			"      .init : 0x%p" " - 0x%p" "   (%4td kB)\n"
+			"      .data : 0x%p" " - 0x%p" "   (%4td kB)\n"
+			"       .bss : 0x%p" " - 0x%p" "   (%4td kB)\n",
 
 			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
 				(PAGE_SIZE)),

commit 80d6b0c2eed2a504f6740cd1f5ea76dc50abfc4d
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Apr 3 13:29:50 2014 -0700

    ARM: mm: allow text and rodata sections to be read-only
    
    This introduces CONFIG_DEBUG_RODATA, making kernel text and rodata
    read-only. Additionally, this splits rodata from text so that rodata can
    also be NX, which may lead to wasted memory when aligning to SECTION_SIZE.
    The read-only areas are made writable during ftrace updates and kexec.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Tested-by: Laura Abbott <lauraa@codeaurora.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e6bfe76b2f59..dc2db779cdf4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -622,9 +622,10 @@ struct section_perm {
 	unsigned long end;
 	pmdval_t mask;
 	pmdval_t prot;
+	pmdval_t clear;
 };
 
-struct section_perm nx_perms[] = {
+static struct section_perm nx_perms[] = {
 	/* Make pages tables, etc before _stext RW (set NX). */
 	{
 		.start	= PAGE_OFFSET,
@@ -639,8 +640,35 @@ struct section_perm nx_perms[] = {
 		.mask	= ~PMD_SECT_XN,
 		.prot	= PMD_SECT_XN,
 	},
+#ifdef CONFIG_DEBUG_RODATA
+	/* Make rodata NX (set RO in ro_perms below). */
+	{
+		.start  = (unsigned long)__start_rodata,
+		.end    = (unsigned long)__init_begin,
+		.mask   = ~PMD_SECT_XN,
+		.prot   = PMD_SECT_XN,
+	},
+#endif
 };
 
+#ifdef CONFIG_DEBUG_RODATA
+static struct section_perm ro_perms[] = {
+	/* Make kernel code and rodata RX (set RO). */
+	{
+		.start  = (unsigned long)_stext,
+		.end    = (unsigned long)__init_begin,
+#ifdef CONFIG_ARM_LPAE
+		.mask   = ~PMD_SECT_RDONLY,
+		.prot   = PMD_SECT_RDONLY,
+#else
+		.mask   = ~(PMD_SECT_APX | PMD_SECT_AP_WRITE),
+		.prot   = PMD_SECT_APX | PMD_SECT_AP_WRITE,
+		.clear  = PMD_SECT_AP_WRITE,
+#endif
+	},
+};
+#endif
+
 /*
  * Updates section permissions only for the current mm (sections are
  * copied into each mm). During startup, this is the init_mm. Is only
@@ -704,6 +732,24 @@ static inline void fix_kernmem_perms(void)
 {
 	set_section_perms(nx_perms, prot);
 }
+
+#ifdef CONFIG_DEBUG_RODATA
+void mark_rodata_ro(void)
+{
+	set_section_perms(ro_perms, prot);
+}
+
+void set_kernel_text_rw(void)
+{
+	set_section_perms(ro_perms, clear);
+}
+
+void set_kernel_text_ro(void)
+{
+	set_section_perms(ro_perms, prot);
+}
+#endif /* CONFIG_DEBUG_RODATA */
+
 #else
 static inline void fix_kernmem_perms(void) { }
 #endif /* CONFIG_ARM_KERNMEM_PERMS */

commit 1e6b48116a95046ec51f3d40f83aff8b006674d7
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Apr 3 17:28:11 2014 -0700

    ARM: mm: allow non-text sections to be non-executable
    
    Adds CONFIG_ARM_KERNMEM_PERMS to separate the kernel memory regions
    into section-sized areas that can have different permisions. Performs
    the NX permission changes during free_initmem, so that init memory can be
    reclaimed.
    
    This uses section size instead of PMD size to reduce memory lost to
    padding on non-LPAE systems.
    
    Based on work by Brad Spengler, Larry Bassel, and Laura Abbott.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Tested-by: Laura Abbott <lauraa@codeaurora.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ad82c05bfc3a..e6bfe76b2f59 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -29,6 +29,7 @@
 #include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
+#include <asm/system_info.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
 
@@ -615,7 +616,99 @@ void __init mem_init(void)
 	}
 }
 
-void free_initmem(void)
+#ifdef CONFIG_ARM_KERNMEM_PERMS
+struct section_perm {
+	unsigned long start;
+	unsigned long end;
+	pmdval_t mask;
+	pmdval_t prot;
+};
+
+struct section_perm nx_perms[] = {
+	/* Make pages tables, etc before _stext RW (set NX). */
+	{
+		.start	= PAGE_OFFSET,
+		.end	= (unsigned long)_stext,
+		.mask	= ~PMD_SECT_XN,
+		.prot	= PMD_SECT_XN,
+	},
+	/* Make init RW (set NX). */
+	{
+		.start	= (unsigned long)__init_begin,
+		.end	= (unsigned long)_sdata,
+		.mask	= ~PMD_SECT_XN,
+		.prot	= PMD_SECT_XN,
+	},
+};
+
+/*
+ * Updates section permissions only for the current mm (sections are
+ * copied into each mm). During startup, this is the init_mm. Is only
+ * safe to be called with preemption disabled, as under stop_machine().
+ */
+static inline void section_update(unsigned long addr, pmdval_t mask,
+				  pmdval_t prot)
+{
+	struct mm_struct *mm;
+	pmd_t *pmd;
+
+	mm = current->active_mm;
+	pmd = pmd_offset(pud_offset(pgd_offset(mm, addr), addr), addr);
+
+#ifdef CONFIG_ARM_LPAE
+	pmd[0] = __pmd((pmd_val(pmd[0]) & mask) | prot);
+#else
+	if (addr & SECTION_SIZE)
+		pmd[1] = __pmd((pmd_val(pmd[1]) & mask) | prot);
+	else
+		pmd[0] = __pmd((pmd_val(pmd[0]) & mask) | prot);
+#endif
+	flush_pmd_entry(pmd);
+	local_flush_tlb_kernel_range(addr, addr + SECTION_SIZE);
+}
+
+/* Make sure extended page tables are in use. */
+static inline bool arch_has_strict_perms(void)
+{
+	if (cpu_architecture() < CPU_ARCH_ARMv6)
+		return false;
+
+	return !!(get_cr() & CR_XP);
+}
+
+#define set_section_perms(perms, field)	{				\
+	size_t i;							\
+	unsigned long addr;						\
+									\
+	if (!arch_has_strict_perms())					\
+		return;							\
+									\
+	for (i = 0; i < ARRAY_SIZE(perms); i++) {			\
+		if (!IS_ALIGNED(perms[i].start, SECTION_SIZE) ||	\
+		    !IS_ALIGNED(perms[i].end, SECTION_SIZE)) {		\
+			pr_err("BUG: section %lx-%lx not aligned to %lx\n", \
+				perms[i].start, perms[i].end,		\
+				SECTION_SIZE);				\
+			continue;					\
+		}							\
+									\
+		for (addr = perms[i].start;				\
+		     addr < perms[i].end;				\
+		     addr += SECTION_SIZE)				\
+			section_update(addr, perms[i].mask,		\
+				       perms[i].field);			\
+	}								\
+}
+
+static inline void fix_kernmem_perms(void)
+{
+	set_section_perms(nx_perms, prot);
+}
+#else
+static inline void fix_kernmem_perms(void) { }
+#endif /* CONFIG_ARM_KERNMEM_PERMS */
+
+void free_tcmmem(void)
 {
 #ifdef CONFIG_HAVE_TCM
 	extern char __tcm_start, __tcm_end;
@@ -623,6 +716,12 @@ void free_initmem(void)
 	poison_init_mem(&__tcm_start, &__tcm_end - &__tcm_start);
 	free_reserved_area(&__tcm_start, &__tcm_end, -1, "TCM link");
 #endif
+}
+
+void free_initmem(void)
+{
+	fix_kernmem_perms();
+	free_tcmmem();
 
 	poison_init_mem(__init_begin, __init_end - __init_begin);
 	if (!machine_is_integrator() && !machine_is_cintegrator())

commit b615bbbff1c4d6fcd13007e75d75f6510aeb3808
Author: Mark Salter <msalter@redhat.com>
Date:   Wed Aug 13 09:04:49 2014 -0700

    arm: use generic fixmap.h
    
    ARM is different from other architectures in that fixmap pages are indexed
    with a positive offset from FIXADDR_START.  Other architectures index with
    a negative offset from FIXADDR_TOP.  In order to use the generic fixmap.h
    definitions, this patch redefines FIXADDR_TOP to be inclusive of the
    useable range.  That is, FIXADDR_TOP is the virtual address of the topmost
    fixed page.  The newly defined FIXADDR_END is the first virtual address
    past the fixed mappings.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Reviewed-by: Doug Anderson <dianders@chromium.org>
    [kees: update for a05e54c103b0 ("ARM: 8031/2: change fixmap ...")]
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Laura Abbott <lauraa@codeaurora.org>
    Cc: Rob Herring <robh@kernel.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 659c75d808dc..ad82c05bfc3a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -570,7 +570,7 @@ void __init mem_init(void)
 			MLK(DTCM_OFFSET, (unsigned long) dtcm_end),
 			MLK(ITCM_OFFSET, (unsigned long) itcm_end),
 #endif
-			MLK(FIXADDR_START, FIXADDR_TOP),
+			MLK(FIXADDR_START, FIXADDR_END),
 			MLM(VMALLOC_START, VMALLOC_END),
 			MLM(PAGE_OFFSET, (unsigned long)high_memory),
 #ifdef CONFIG_HIGHMEM

commit 95b0e655f9148881907fdbe5baba6a9f5d094fee
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Thu Oct 9 15:26:49 2014 -0700

    ARM: mm: don't limit default CMA region only to low memory
    
    DMA-mapping supports CMA regions places either in low or high memory, so
    there is no longer needed to limit default CMA regions only to low memory.
     The real limit is still defined by architecture specific DMA limit.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Reported-by: Russell King - ARM Linux <linux@arm.linux.org.uk>
    Acked-by: Michal Nazarewicz <mina86@mina86.com>
    Cc: Daniel Drake <drake@endlessm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9221645dd192..92bba32d9230 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -322,7 +322,7 @@ void __init arm_memblock_init(const struct machine_desc *mdesc)
 	 * reserve memory for DMA contigouos allocations,
 	 * must come from DMA area inside low memory
 	 */
-	dma_contiguous_reserve(min(arm_dma_limit, arm_lowmem_limit));
+	dma_contiguous_reserve(arm_dma_limit);
 
 	arm_memblock_steal_permitted = false;
 	memblock_dump_all();

commit 421520ba98290a73b35b7644e877a48f18e06004
Author: Yalin Wang <Yalin.Wang@sonymobile.com>
Date:   Fri Sep 26 03:07:09 2014 +0100

    ARM: 8167/1: extend the reserved memory for initrd to be page aligned
    
    This patch extends the start and end address of initrd to be page aligned,
    so that we can free all memory including the un-page aligned head or tail
    page of initrd, if the start or end address of initrd are not page
    aligned, the page can't be freed by free_initrd_mem() function.
    
    Signed-off-by: Yalin Wang <yalin.wang@sonymobile.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 659c75d808dc..9221645dd192 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -636,6 +636,11 @@ static int keep_initrd;
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
 	if (!keep_initrd) {
+		if (start == initrd_start)
+			start = round_down(start, PAGE_SIZE);
+		if (end == initrd_end)
+			end = round_up(end, PAGE_SIZE);
+
 		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
 		free_reserved_area((void *)start, (void *)end, -1, "initrd");
 	}

commit eb3d3ec567e868c8a3bfbfdfc9465ffd52983d11
Merge: c3c55a072039 bd63ce27d9d6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 5 15:57:04 2014 -0700

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm into next
    
    Pull ARM updates from Russell King:
    
     - Major clean-up of the L2 cache support code.  The existing mess was
       becoming rather unmaintainable through all the additions that others
       have done over time.  This turns it into a much nicer structure, and
       implements a few performance improvements as well.
    
     - Clean up some of the CP15 control register tweaks for alignment
       support, moving some code and data into alignment.c
    
     - DMA properties for ARM, from Santosh and reviewed by DT people.  This
       adds DT properties to specify bus translations we can't discover
       automatically, and to indicate whether devices are coherent.
    
     - Hibernation support for ARM
    
     - Make ftrace work with read-only text in modules
    
     - add suspend support for PJ4B CPUs
    
     - rework interrupt masking for undefined instruction handling, which
       allows us to enable interrupts earlier in the handling of these
       exceptions.
    
     - support for big endian page tables
    
     - fix stacktrace support to exclude stacktrace functions from the
       trace, and add save_stack_trace_regs() implementation so that kprobes
       can record stack traces.
    
     - Add support for the Cortex-A17 CPU.
    
     - Remove last vestiges of ARM710 support.
    
     - Removal of ARM "meminfo" structure, finally converting us solely to
       memblock to handle the early memory initialisation.
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (142 commits)
      ARM: ensure C page table setup code follows assembly code (part II)
      ARM: ensure C page table setup code follows assembly code
      ARM: consolidate last remaining open-coded alignment trap enable
      ARM: remove global cr_no_alignment
      ARM: remove CPU_CP15 conditional from alignment.c
      ARM: remove unused adjust_cr() function
      ARM: move "noalign" command line option to alignment.c
      ARM: provide common method to clear bits in CPU control register
      ARM: 8025/1: Get rid of meminfo
      ARM: 8060/1: mm: allow sub-architectures to override PCI I/O memory type
      ARM: 8066/1: correction for ARM patch 8031/2
      ARM: 8049/1: ftrace/add save_stack_trace_regs() implementation
      ARM: 8065/1: remove last use of CONFIG_CPU_ARM710
      ARM: 8062/1: Modify ldrt fixup handler to re-execute the userspace instruction
      ARM: 8047/1: rwsem: use asm-generic rwsem implementation
      ARM: l2c: trial at enabling some Cortex-A9 optimisations
      ARM: l2c: add warnings for stuff modifying aux_ctrl register values
      ARM: l2c: print a warning with L2C-310 caches if the cache size is modified
      ARM: l2c: remove old .set_debug method
      ARM: l2c: kill L2X0_AUX_CTRL_MASK before anyone else makes use of this
      ...

commit 1fb333489fb917c704ad43e51b45c12f52215a9c
Merge: 20e7e364331d 3f8517e7937d 8ef418c7178f 1c2f87c22566
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jun 5 12:35:52 2014 +0100

    Merge branches 'alignment', 'fixes', 'l2c' (early part) and 'misc' into for-next

commit 0aeb3408ca9773283b0ae63771c4b17f39e204df
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Apr 13 19:43:26 2014 +0100

    ARM: remove global cr_no_alignment
    
    cr_no_alignment is really only used by the alignment code.  Since we no
    longer change the setting of cr_alignment after boot, we can localise
    this to alignment.c
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 94332b1ad4bc..13ce33e096b5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -40,7 +40,6 @@
 #ifdef CONFIG_CPU_CP15_MMU
 unsigned long __init __clear_cr(unsigned long mask)
 {
-	cr_no_alignment = cr_no_alignment & ~mask;
 	cr_alignment = cr_alignment & ~mask;
 	return cr_alignment;
 }

commit b4b20ad881f5a5c19ae9199547ddbb00fa4825eb
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Apr 13 18:57:29 2014 +0100

    ARM: provide common method to clear bits in CPU control register
    
    Several places open-code this manipulation, let's consolidate this.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2a77ba8796ae..94332b1ad4bc 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -23,6 +23,7 @@
 #include <linux/dma-contiguous.h>
 #include <linux/sizes.h>
 
+#include <asm/cp15.h>
 #include <asm/mach-types.h>
 #include <asm/memblock.h>
 #include <asm/prom.h>
@@ -36,6 +37,15 @@
 
 #include "mm.h"
 
+#ifdef CONFIG_CPU_CP15_MMU
+unsigned long __init __clear_cr(unsigned long mask)
+{
+	cr_no_alignment = cr_no_alignment & ~mask;
+	cr_alignment = cr_alignment & ~mask;
+	return cr_alignment;
+}
+#endif
+
 static phys_addr_t phys_initrd_start __initdata = 0;
 static unsigned long phys_initrd_size __initdata = 0;
 

commit 1c2f87c22566cd057bc8cde10c37ae9da1a1bb76
Author: Laura Abbott <lauraa@codeaurora.org>
Date:   Sun Apr 13 22:54:58 2014 +0100

    ARM: 8025/1: Get rid of meminfo
    
    memblock is now fully integrated into the kernel and is the prefered
    method for tracking memory. Rather than reinvent the wheel with
    meminfo, migrate to using memblock directly instead of meminfo as
    an intermediate.
    
    Acked-by: Jason Cooper <jason@lakedaemon.net>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Kukjin Kim <kgene.kim@samsung.com>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Laura Abbott <lauraa@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2a77ba8796ae..c8ab21dc2178 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -81,24 +81,21 @@ __tagtable(ATAG_INITRD2, parse_tag_initrd2);
  * initialization functions, as well as show_mem() for the skipping
  * of holes in the memory map.  It is populated by arm_add_memory().
  */
-struct meminfo meminfo;
-
 void show_mem(unsigned int filter)
 {
 	int free = 0, total = 0, reserved = 0;
-	int shared = 0, cached = 0, slab = 0, i;
-	struct meminfo * mi = &meminfo;
+	int shared = 0, cached = 0, slab = 0;
+	struct memblock_region *reg;
 
 	printk("Mem-info:\n");
 	show_free_areas(filter);
 
-	for_each_bank (i, mi) {
-		struct membank *bank = &mi->bank[i];
+	for_each_memblock (memory, reg) {
 		unsigned int pfn1, pfn2;
 		struct page *page, *end;
 
-		pfn1 = bank_pfn_start(bank);
-		pfn2 = bank_pfn_end(bank);
+		pfn1 = memblock_region_memory_base_pfn(reg);
+		pfn2 = memblock_region_memory_end_pfn(reg);
 
 		page = pfn_to_page(pfn1);
 		end  = pfn_to_page(pfn2 - 1) + 1;
@@ -115,8 +112,9 @@ void show_mem(unsigned int filter)
 				free++;
 			else
 				shared += page_count(page) - 1;
-			page++;
-		} while (page < end);
+			pfn1++;
+			page = pfn_to_page(pfn1);
+		} while (pfn1 < pfn2);
 	}
 
 	printk("%d pages of RAM\n", total);
@@ -130,16 +128,9 @@ void show_mem(unsigned int filter)
 static void __init find_limits(unsigned long *min, unsigned long *max_low,
 			       unsigned long *max_high)
 {
-	struct meminfo *mi = &meminfo;
-	int i;
-
-	/* This assumes the meminfo array is properly sorted */
-	*min = bank_pfn_start(&mi->bank[0]);
-	for_each_bank (i, mi)
-		if (mi->bank[i].highmem)
-				break;
-	*max_low = bank_pfn_end(&mi->bank[i - 1]);
-	*max_high = bank_pfn_end(&mi->bank[mi->nr_banks - 1]);
+	*max_low = PFN_DOWN(memblock_get_current_limit());
+	*min = PFN_UP(memblock_start_of_DRAM());
+	*max_high = PFN_DOWN(memblock_end_of_DRAM());
 }
 
 #ifdef CONFIG_ZONE_DMA
@@ -274,14 +265,8 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 	return phys;
 }
 
-void __init arm_memblock_init(struct meminfo *mi,
-	const struct machine_desc *mdesc)
+void __init arm_memblock_init(const struct machine_desc *mdesc)
 {
-	int i;
-
-	for (i = 0; i < mi->nr_banks; i++)
-		memblock_add(mi->bank[i].start, mi->bank[i].size);
-
 	/* Register the kernel text, kernel data and initrd with memblock. */
 #ifdef CONFIG_XIP_KERNEL
 	memblock_reserve(__pa(_sdata), _end - _sdata);
@@ -413,54 +398,53 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 /*
  * The mem_map array can get very big.  Free the unused area of the memory map.
  */
-static void __init free_unused_memmap(struct meminfo *mi)
+static void __init free_unused_memmap(void)
 {
-	unsigned long bank_start, prev_bank_end = 0;
-	unsigned int i;
+	unsigned long start, prev_end = 0;
+	struct memblock_region *reg;
 
 	/*
 	 * This relies on each bank being in address order.
 	 * The banks are sorted previously in bootmem_init().
 	 */
-	for_each_bank(i, mi) {
-		struct membank *bank = &mi->bank[i];
-
-		bank_start = bank_pfn_start(bank);
+	for_each_memblock(memory, reg) {
+		start = memblock_region_memory_base_pfn(reg);
 
 #ifdef CONFIG_SPARSEMEM
 		/*
 		 * Take care not to free memmap entries that don't exist
 		 * due to SPARSEMEM sections which aren't present.
 		 */
-		bank_start = min(bank_start,
-				 ALIGN(prev_bank_end, PAGES_PER_SECTION));
+		start = min(start,
+				 ALIGN(prev_end, PAGES_PER_SECTION));
 #else
 		/*
 		 * Align down here since the VM subsystem insists that the
 		 * memmap entries are valid from the bank start aligned to
 		 * MAX_ORDER_NR_PAGES.
 		 */
-		bank_start = round_down(bank_start, MAX_ORDER_NR_PAGES);
+		start = round_down(start, MAX_ORDER_NR_PAGES);
 #endif
 		/*
 		 * If we had a previous bank, and there is a space
 		 * between the current bank and the previous, free it.
 		 */
-		if (prev_bank_end && prev_bank_end < bank_start)
-			free_memmap(prev_bank_end, bank_start);
+		if (prev_end && prev_end < start)
+			free_memmap(prev_end, start);
 
 		/*
 		 * Align up here since the VM subsystem insists that the
 		 * memmap entries are valid from the bank end aligned to
 		 * MAX_ORDER_NR_PAGES.
 		 */
-		prev_bank_end = ALIGN(bank_pfn_end(bank), MAX_ORDER_NR_PAGES);
+		prev_end = ALIGN(memblock_region_memory_end_pfn(reg),
+				 MAX_ORDER_NR_PAGES);
 	}
 
 #ifdef CONFIG_SPARSEMEM
-	if (!IS_ALIGNED(prev_bank_end, PAGES_PER_SECTION))
-		free_memmap(prev_bank_end,
-			    ALIGN(prev_bank_end, PAGES_PER_SECTION));
+	if (!IS_ALIGNED(prev_end, PAGES_PER_SECTION))
+		free_memmap(prev_end,
+			    ALIGN(prev_end, PAGES_PER_SECTION));
 #endif
 }
 
@@ -536,7 +520,7 @@ void __init mem_init(void)
 	set_max_mapnr(pfn_to_page(max_pfn) - mem_map);
 
 	/* this will put all unused low memory onto the freelists */
-	free_unused_memmap(&meminfo);
+	free_unused_memmap();
 	free_all_bootmem();
 
 #ifdef CONFIG_SA1111

commit d1552ce449eb0a8d2f0bd6599da3a8a3d7f77a84
Author: Rob Herring <robh@kernel.org>
Date:   Tue Apr 1 22:46:48 2014 -0500

    of/fdt: move memreserve and dtb memory reservations into core
    
    Move the /memreserve/ processing and dtb memory reservations into
    early_init_fdt_scan_reserved_mem. This converts arm, arm64, and powerpc
    as they are the only users of early_init_fdt_scan_reserved_mem.
    
    memblock_reserve is safe to call on the same region twice, so the
    reservation check for the dtb in powerpc 32-bit reservations is safe to
    remove.
    
    Signed-off-by: Rob Herring <robh@kernel.org>
    Tested-by: Michal Simek <michal.simek@xilinx.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Tested-by: Grant Likely <grant.likely@linaro.org>
    Tested-by: Stephen Chivers <schivers@csc.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2a77ba8796ae..928d596d9ab4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -317,7 +317,6 @@ void __init arm_memblock_init(struct meminfo *mi,
 #endif
 
 	arm_mm_memblock_reserve();
-	arm_dt_memblock_reserve();
 
 	/* reserve any platform specific memblock areas */
 	if (mdesc->reserve)

commit bcedb5f9bd74662968fc1b4cb22f24abb4b7723d
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Fri Feb 28 14:42:54 2014 +0100

    arm: add support for reserved memory defined by device tree
    
    Enable reserved memory initialization from device tree.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 804d61566a53..2a77ba8796ae 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -323,6 +323,8 @@ void __init arm_memblock_init(struct meminfo *mi,
 	if (mdesc->reserve)
 		mdesc->reserve();
 
+	early_init_fdt_scan_reserved_mem();
+
 	/*
 	 * reserve memory for DMA contigouos allocations,
 	 * must come from DMA area inside low memory

commit f5137a45c20713f06535b7d952b72b673c27488f
Merge: 54c0a4b46150 d326b65c57d6 c5ca95b507c8
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jan 28 21:38:48 2014 +0000

    Merge branches 'fixes' and 'misc' into for-linus

commit 4c235cb9e35407bdb4a2debeef4dc8721e8f91f2
Author: Ben Peddell <klightspeed@killerwolves.net>
Date:   Mon Jan 13 23:25:18 2014 +0100

    ARM: 7941/2: Fix incorrect FDT initrd parameter override
    
    Commit 65939301acdb (arm: set initrd_start/initrd_end for fdt scan)
    caused the FDT initrd_start and initrd_end to override the
    phys_initrd_start and phys_initrd_size set by the initrd= kernel
    parameter.  With this patch initrd_start and initrd_end will be
    overridden if phys_initrd_start and phys_initrd_size are set by the
    kernel initrd= parameter.
    
    Fixes: 65939301acdb (arm: set initrd_start/initrd_end for fdt scan)
    
    Signed-off-by: Ben Peddell <klightspeed@killerwolves.net>
    Acked-by: Jason Cooper <jason@lakedaemon.net>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3e8f106ee5fe..ac1d883460c7 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -345,10 +345,11 @@ void __init arm_memblock_init(struct meminfo *mi,
 #endif
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* FDT scan will populate initrd_start */
-	if (initrd_start) {
+	if (initrd_start && !phys_initrd_size) {
 		phys_initrd_start = __virt_to_phys(initrd_start);
 		phys_initrd_size = initrd_end - initrd_start;
 	}
+	initrd_start = initrd_end = 0;
 	if (phys_initrd_size &&
 	    !memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx is not a memory region - disabling initrd\n",

commit f341535193c338b4ce4af8e32be51e6aae7f22a6
Merge: 13c789a6b219 857989a7fdd2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 23 18:34:03 2014 -0800

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
     "In this set, we have:
       - Refactoring of some of the old StrongARM-1100 GPIO code to make
         things simpler by Dmitry Eremin-Solenikov
       - Read-only and non-executable support for modules on ARM from Laura
         Abbot
       - Removal of unnecessary set_drvdata() calls in AMBA code
       - Some non-executable support for kernel lowmem mappings at the 1MB
         section granularity, and dumping of kernel page tables via debugfs
       - Some improvements for the timer/clock code on Footbridge platforms,
         and cleanup some of the LED code there
       - Fix fls/ffs() signatures to match x86 to prevent build warnings,
         particularly where these are used with min/max() macros
       - Avoid using the bootmem allocator on ARM (patches from Santosh
         Shilimkar)
       - Various asid/unaligned access updates from Will Deacon"
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (51 commits)
      ARM: SMP implementations are not supposed to return from smp_ops.cpu_die()
      ARM: ignore memory below PHYS_OFFSET
      Fix select-induced Kconfig warning for ZBOOT_ROM
      ARM: fix ffs/fls implementations to match x86
      ARM: 7935/1: sa1100: collie: add gpio-keys configuration
      ARM: 7932/1: bcm: Add DEBUG_LL console support
      ARM: 7929/1: Remove duplicate SCHED_HRTICK config option
      ARM: 7928/1: kconfig: select HAVE_EFFICIENT_UNALIGNED_ACCESS for CPUv6+ && MMU
      ARM: 7927/1: dcache: select DCACHE_WORD_ACCESS for big-endian CPUs
      ARM: 7926/1: mm: flesh out and fix the comments in the ASID allocator
      ARM: 7925/1: mm: keep track of last ASID allocation to improve bitmap searching
      ARM: 7924/1: mm: don't bother with reserved ttbr0 when running with LPAE
      ARM: PCI: add legacy IDE IRQ implementation
      ARM: footbridge: cleanup LEDs code
      ARM: pgd allocation: retry on failure
      ARM: footbridge: add one-shot mode for DC21285 timer
      ARM: footbridge: add sched_clock implementation
      ARM: 7922/1: l2x0: add Marvell Tauros3 support
      ARM: 7877/1: use built-in byte swap function
      ARM: 7921/1: mcpm: remove redundant dsb instructions prior to sev
      ...

commit cfb665864e54ee7a160750b4815bfe6b7eb13d0d
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Tue Jan 21 15:50:49 2014 -0800

    arch/arm/mm/init.c: use memblock apis for early memory allocations
    
    Switch to memblock interfaces for early memory allocator instead of
    bootmem allocator.  No functional change in beahvior than what it is in
    current code from bootmem users points of view.
    
    Archs already converted to NO_BOOTMEM now directly use memblock
    interfaces instead of bootmem wrappers build on top of memblock.  And
    the archs which still uses bootmem, these new apis just fallback to
    exiting bootmem APIs.
    
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Paul Walmsley <paul@pwsan.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2e71e245df90..11eb8add7820 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -458,7 +458,7 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * free the section of the memmap array.
 	 */
 	if (pg < pgend)
-		free_bootmem(pg, pgend - pg);
+		memblock_free_early(pg, pgend - pg);
 }
 
 /*

commit aec6a8889a98a0cd58357cd0937a25189908f191
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jan 21 15:49:13 2014 -0800

    mm, show_mem: remove SHOW_MEM_FILTER_PAGE_COUNT
    
    Commit 4b59e6c47309 ("mm, show_mem: suppress page counts in
    non-blockable contexts") introduced SHOW_MEM_FILTER_PAGE_COUNT to
    suppress PFN walks on large memory machines.  Commit c78e93630d15 ("mm:
    do not walk all of system memory during show_mem") avoided a PFN walk in
    the generic show_mem helper which removes the requirement for
    SHOW_MEM_FILTER_PAGE_COUNT in that case.
    
    This patch removes PFN walkers from the arch-specific implementations
    that report on a per-node or per-zone granularity.  ARM and unicore32
    still do a PFN walk as they report memory usage on each bank which is a
    much finer granularity where the debugging information may still be of
    use.  As the remaining arches doing PFN walks have relatively small
    amounts of memory, this patch simply removes SHOW_MEM_FILTER_PAGE_COUNT.
    
    [akpm@linux-foundation.org: fix parisc]
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: James Bottomley <jejb@parisc-linux.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3e8f106ee5fe..2e71e245df90 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -92,9 +92,6 @@ void show_mem(unsigned int filter)
 	printk("Mem-info:\n");
 	show_free_areas(filter);
 
-	if (filter & SHOW_MEM_FILTER_PAGE_COUNT)
-		return;
-
 	for_each_bank (i, mi) {
 		struct membank *bank = &mi->bank[i];
 		unsigned int pfn1, pfn2;

commit 857989a7fdd2f6de42272578b8aaa413ed6e63e4
Merge: 6f14d778c15f 7990ac9cb25d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jan 21 21:26:51 2014 +0000

    Merge branch 'devel-stable' into for-next

commit 7990ac9cb25d378b6311f3591f010e53a9967066
Merge: 23f6620a360d 84f452b1e8fc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jan 13 23:36:45 2014 +0000

    Merge branch 'for_3.14/arm-no-bootmem' of git://git.kernel.org/pub/scm/linux/kernel/git/ssantosh/linux-keystone into devel-stable

commit 6bcac805bacb3b637911244d95368512ae389abc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jan 7 17:53:54 2014 +0000

    Revert "ARM: 7908/1: mm: Fix the arm_dma_limit calculation"
    
    This reverts commit 787b0d5c1ca7ff24feb6f92e4c7f4410ee7d81a8 since
    it is no longer required after 7909/1 was applied, and it causes
    build regressions when ARM_PATCH_PHYS_VIRT is disabled and DMA_ZONE
    is enabled.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1f7b19a47060..3e8f106ee5fe 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -229,7 +229,7 @@ void __init setup_dma_zone(const struct machine_desc *mdesc)
 #ifdef CONFIG_ZONE_DMA
 	if (mdesc->dma_zone_size) {
 		arm_dma_zone_size = mdesc->dma_zone_size;
-		arm_dma_limit = __pv_phys_offset + arm_dma_zone_size - 1;
+		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
 	} else
 		arm_dma_limit = 0xffffffff;
 	arm_dma_pfn_limit = arm_dma_limit >> PAGE_SHIFT;

commit 787b0d5c1ca7ff24feb6f92e4c7f4410ee7d81a8
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Mon Dec 2 20:29:12 2013 +0100

    ARM: 7908/1: mm: Fix the arm_dma_limit calculation
    
    Current code is using PHYS_OFFSET to calculate the arm_dma_limit which
    will lead to wrong calculations in cases where PHYS_OFFSET is updated
    runtime.
    
    So fix the code by using __pv_phys_offset instead of PHYS_OFFSET.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3e8f106ee5fe..1f7b19a47060 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -229,7 +229,7 @@ void __init setup_dma_zone(const struct machine_desc *mdesc)
 #ifdef CONFIG_ZONE_DMA
 	if (mdesc->dma_zone_size) {
 		arm_dma_zone_size = mdesc->dma_zone_size;
-		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
+		arm_dma_limit = __pv_phys_offset + arm_dma_zone_size - 1;
 	} else
 		arm_dma_limit = 0xffffffff;
 	arm_dma_pfn_limit = arm_dma_limit >> PAGE_SHIFT;

commit 84f452b1e8fc73ac0e31254c66e3e2260ce5263d
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Sun Jun 30 00:28:46 2013 -0400

    ARM: mm: Remove bootmem code and switch to NO_BOOTMEM
    
    Now with dma_mask series merged and max*pfn has consistent meaning on ARM
    as rest of the arch's thanks to RMK's mega series, lets switch ARM code
    to NO_BOOTMEM. With NO_BOOTMEM change, now we use memblock allocator to
    reserve space for crash kernel to have one less dependency with nobootmem
    allocator wrapper.
    
    Tested with both flat memory and sparse (faked) memory models with highmem
    enabled.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ea66341779d4..6dd66a999d9f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -145,58 +145,6 @@ static void __init find_limits(unsigned long *min, unsigned long *max_low,
 	*max_high = bank_pfn_end(&mi->bank[mi->nr_banks - 1]);
 }
 
-static void __init arm_bootmem_init(unsigned long start_pfn,
-	unsigned long end_pfn)
-{
-	struct memblock_region *reg;
-	unsigned int boot_pages;
-	phys_addr_t bitmap;
-	pg_data_t *pgdat;
-
-	/*
-	 * Allocate the bootmem bitmap page.  This must be in a region
-	 * of memory which has already been mapped.
-	 */
-	boot_pages = bootmem_bootmap_pages(end_pfn - start_pfn);
-	bitmap = memblock_alloc_base(boot_pages << PAGE_SHIFT, L1_CACHE_BYTES,
-				__pfn_to_phys(end_pfn));
-
-	/*
-	 * Initialise the bootmem allocator, handing the
-	 * memory banks over to bootmem.
-	 */
-	node_set_online(0);
-	pgdat = NODE_DATA(0);
-	init_bootmem_node(pgdat, __phys_to_pfn(bitmap), start_pfn, end_pfn);
-
-	/* Free the lowmem regions from memblock into bootmem. */
-	for_each_memblock(memory, reg) {
-		unsigned long start = memblock_region_memory_base_pfn(reg);
-		unsigned long end = memblock_region_memory_end_pfn(reg);
-
-		if (end >= end_pfn)
-			end = end_pfn;
-		if (start >= end)
-			break;
-
-		free_bootmem(__pfn_to_phys(start), (end - start) << PAGE_SHIFT);
-	}
-
-	/* Reserve the lowmem memblock reserved regions in bootmem. */
-	for_each_memblock(reserved, reg) {
-		unsigned long start = memblock_region_reserved_base_pfn(reg);
-		unsigned long end = memblock_region_reserved_end_pfn(reg);
-
-		if (end >= end_pfn)
-			end = end_pfn;
-		if (start >= end)
-			break;
-
-		reserve_bootmem(__pfn_to_phys(start),
-			        (end - start) << PAGE_SHIFT, BOOTMEM_DEFAULT);
-	}
-}
-
 #ifdef CONFIG_ZONE_DMA
 
 phys_addr_t arm_dma_zone_size __read_mostly;
@@ -236,7 +184,7 @@ void __init setup_dma_zone(const struct machine_desc *mdesc)
 #endif
 }
 
-static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
+static void __init zone_sizes_init(unsigned long min, unsigned long max_low,
 	unsigned long max_high)
 {
 	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
@@ -396,8 +344,6 @@ void __init bootmem_init(void)
 
 	find_limits(&min, &max_low, &max_high);
 
-	arm_bootmem_init(min, max_low);
-
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations
@@ -414,7 +360,7 @@ void __init bootmem_init(void)
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */
-	arm_bootmem_free(min, max_low, max_high);
+	zone_sizes_init(min, max_low, max_high);
 
 	/*
 	 * This doesn't seem to be used by the Linux memory manager any

commit 8e58caefd96c8ee249ab26a2fe00aab3785df9ea
Author: Grygorii Strashko <grygorii.strashko@ti.com>
Date:   Sat Nov 23 14:42:18 2013 -0500

    ARM: mm: Don't allow resizing of memblock data until "low" memory is not mapped
    
    If allowed by call to memblock_allow_resize() - The Memblock core will
    try to allocate additional memory and rearrange its internal data in
    case, if there are more then INIT_MEMBLOCK_REGIONS(128) memory regions
    of any type have been allocated. If this happens before Low memory is
    mapped (which is done now by map_lowmem()) the system will hang, because
    the Memblock core will try to operate with virtual addresses which
    aren't mapped yet.
    
    In ARM code, the memblock resizing is allowed (memblock_allow_resize())
    from arm_memblock_init() which is called before map_lowmem(), so
    this may lead to an error as described above.
    
    Hence, allow Memblock resizing later during init, from bootmem_init()
    when all appropriate mappings are ready.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4c7bab44bf5c..ea66341779d4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -384,7 +384,6 @@ void __init arm_memblock_init(struct meminfo *mi,
 	dma_contiguous_reserve(min(arm_dma_limit, arm_lowmem_limit));
 
 	arm_memblock_steal_permitted = false;
-	memblock_allow_resize();
 	memblock_dump_all();
 }
 
@@ -392,6 +391,7 @@ void __init bootmem_init(void)
 {
 	unsigned long min, max_low, max_high;
 
+	memblock_allow_resize();
 	max_low = max_high = 0;
 
 	find_limits(&min, &max_low, &max_high);

commit b3ba41f28f7fe147c23bfadf6280b3492c9696b1
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Sat Nov 23 14:36:42 2013 -0500

    ARM: mm: Fix max_mapnr with recent max*pfn updates
    
    With commit  26ba47b1 {ARM: 7805/1: mm: change max*pfn to include
    the physical offset of memory}, the max_pfn already contain
    PHYS_PFN_OFFSET, so it shouldn't be taken into account again.
    
    While at it, use use set_max_mapnr() helper.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3e8f106ee5fe..4c7bab44bf5c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -587,7 +587,7 @@ void __init mem_init(void)
 	extern u32 itcm_end;
 #endif
 
-	max_mapnr   = pfn_to_page(max_pfn + PHYS_PFN_OFFSET) - mem_map;
+	set_max_mapnr(pfn_to_page(max_pfn) - mem_map);
 
 	/* this will put all unused low memory onto the freelists */
 	free_unused_memmap(&meminfo);

commit 8ceafbfa91ffbdbb2afaea5c24ccb519ffb8b587
Merge: 42a2d923cc34 26ba47b18318
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 14 07:55:21 2013 +0900

    Merge branch 'for-linus-dma-masks' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull DMA mask updates from Russell King:
     "This series cleans up the handling of DMA masks in a lot of drivers,
      fixing some bugs as we go.
    
      Some of the more serious errors include:
       - drivers which only set their coherent DMA mask if the attempt to
         set the streaming mask fails.
       - drivers which test for a NULL dma mask pointer, and then set the
         dma mask pointer to a location in their module .data section -
         which will cause problems if the module is reloaded.
    
      To counter these, I have introduced two helper functions:
       - dma_set_mask_and_coherent() takes care of setting both the
         streaming and coherent masks at the same time, with the correct
         error handling as specified by the API.
       - dma_coerce_mask_and_coherent() which resolves the problem of
         drivers forcefully setting DMA masks.  This is more a marker for
         future work to further clean these locations up - the code which
         creates the devices really should be initialising these, but to fix
         that in one go along with this change could potentially be very
         disruptive.
    
      The last thing this series does is prise away some of Linux's addition
      to "DMA addresses are physical addresses and RAM always starts at
      zero".  We have ARM LPAE systems where all system memory is above 4GB
      physical, hence having DMA masks interpreted by (eg) the block layers
      as describing physical addresses in the range 0..DMAMASK fails on
      these platforms.  Santosh Shilimkar addresses this in this series; the
      patches were copied to the appropriate people multiple times but were
      ignored.
    
      Fixing this also gets rid of some ARM weirdness in the setup of the
      max*pfn variables, and brings ARM into line with every other Linux
      architecture as far as those go"
    
    * 'for-linus-dma-masks' of git://git.linaro.org/people/rmk/linux-arm: (52 commits)
      ARM: 7805/1: mm: change max*pfn to include the physical offset of memory
      ARM: 7797/1: mmc: Use dma_max_pfn(dev) helper for bounce_limit calculations
      ARM: 7796/1: scsi: Use dma_max_pfn(dev) helper for bounce_limit calculations
      ARM: 7795/1: mm: dma-mapping: Add dma_max_pfn(dev) helper function
      ARM: 7794/1: block: Rename parameter dma_mask to max_addr for blk_queue_bounce_limit()
      ARM: DMA-API: better handing of DMA masks for coherent allocations
      ARM: 7857/1: dma: imx-sdma: setup dma mask
      DMA-API: firmware/google/gsmi.c: avoid direct access to DMA masks
      DMA-API: dcdbas: update DMA mask handing
      DMA-API: dma: edma.c: no need to explicitly initialize DMA masks
      DMA-API: usb: musb: use platform_device_register_full() to avoid directly messing with dma masks
      DMA-API: crypto: remove last references to 'static struct device *dev'
      DMA-API: crypto: fix ixp4xx crypto platform device support
      DMA-API: others: use dma_set_coherent_mask()
      DMA-API: staging: use dma_set_coherent_mask()
      DMA-API: usb: use new dma_coerce_mask_and_coherent()
      DMA-API: usb: use dma_set_coherent_mask()
      DMA-API: parport: parport_pc.c: use dma_coerce_mask_and_coherent()
      DMA-API: net: octeon: use dma_coerce_mask_and_coherent()
      DMA-API: net: nxp/lpc_eth: use dma_coerce_mask_and_coherent()
      ...

commit 10d0c9705e80bbd3d587c5fad24599aabaca6688
Merge: 85b656cf1560 c11eede69b6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 16:52:17 2013 +0900

    Merge tag 'devicetree-for-3.13' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux
    
    Pull devicetree updates from Rob Herring:
     "DeviceTree updates for 3.13.  This is a bit larger pull request than
      usual for this cycle with lots of clean-up.
    
       - Cross arch clean-up and consolidation of early DT scanning code.
       - Clean-up and removal of arch prom.h headers.  Makes arch specific
         prom.h optional on all but Sparc.
       - Addition of interrupts-extended property for devices connected to
         multiple interrupt controllers.
       - Refactoring of DT interrupt parsing code in preparation for
         deferred probe of interrupts.
       - ARM cpu and cpu topology bindings documentation.
       - Various DT vendor binding documentation updates"
    
    * tag 'devicetree-for-3.13' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux: (82 commits)
      powerpc: add missing explicit OF includes for ppc
      dt/irq: add empty of_irq_count for !OF_IRQ
      dt: disable self-tests for !OF_IRQ
      of: irq: Fix interrupt-map entry matching
      MIPS: Netlogic: replace early_init_devtree() call
      of: Add Panasonic Corporation vendor prefix
      of: Add Chunghwa Picture Tubes Ltd. vendor prefix
      of: Add AU Optronics Corporation vendor prefix
      of/irq: Fix potential buffer overflow
      of/irq: Fix bug in interrupt parsing refactor.
      of: set dma_mask to point to coherent_dma_mask
      of: add vendor prefix for PHYTEC Messtechnik GmbH
      DT: sort vendor-prefixes.txt
      of: Add vendor prefix for Cadence
      of: Add empty for_each_available_child_of_node() macro definition
      arm/versatile: Fix versatile irq specifications.
      of/irq: create interrupts-extended property
      microblaze/pci: Drop PowerPC-ism from irq parsing
      of/irq: Create of_irq_parse_and_map_pci() to consolidate arch code.
      of/irq: Use irq_of_parse_and_map()
      ...

commit 26ba47b18318abe7dadbe9294a611c0e932651d8
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Thu Aug 1 03:12:01 2013 +0100

    ARM: 7805/1: mm: change max*pfn to include the physical offset of memory
    
    Most of the kernel code assumes that max*pfn is maximum pfns because
    the physical start of memory is expected to be PFN0. Since this
    assumption is not true on ARM architectures, the meaning of max*pfn
    is number of memory pages. This is done to keep drivers happy which
    are making use of of these variable to calculate the dma bounce limit
    using dma_mask.
    
    Now since we have a architecture override possibility for DMAable
    maximum pfns, lets make meaning of max*pfns as maximum pnfs on ARM
    as well.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8aab24f35a5e..d50533c2b409 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -426,12 +426,10 @@ void __init bootmem_init(void)
 	 * This doesn't seem to be used by the Linux memory manager any
 	 * more, but is used by ll_rw_block.  If we can get rid of it, we
 	 * also get rid of some of the stuff above as well.
-	 *
-	 * Note: max_low_pfn and max_pfn reflect the number of _pages_ in
-	 * the system, not the maximum PFN.
 	 */
-	max_low_pfn = max_low - PHYS_PFN_OFFSET;
-	max_pfn = max_high - PHYS_PFN_OFFSET;
+	min_low_pfn = min;
+	max_low_pfn = max_low;
+	max_pfn = max_high;
 }
 
 /*
@@ -537,7 +535,7 @@ static inline void free_area_high(unsigned long pfn, unsigned long end)
 static void __init free_highpages(void)
 {
 #ifdef CONFIG_HIGHMEM
-	unsigned long max_low = max_low_pfn + PHYS_PFN_OFFSET;
+	unsigned long max_low = max_low_pfn;
 	struct memblock_region *mem, *res;
 
 	/* set highmem page free */

commit 4dcfa60071b3d23f0181f27d8519f12e37cefbb9
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jul 9 12:14:49 2013 +0100

    ARM: DMA-API: better handing of DMA masks for coherent allocations
    
    We need to start treating DMA masks as something which is specific to
    the bus that the device resides on, otherwise we're going to hit all
    sorts of nasty issues with LPAE and 32-bit DMA controllers in >32-bit
    systems, where memory is offset from PFN 0.
    
    In order to start doing this, we convert the DMA mask to a PFN using
    the device specific dma_to_pfn() macro.  This is the reverse of the
    pfn_to_dma() macro which is used to get the DMA address for the device.
    
    This gives us a PFN mask, which we can then check against the PFN
    limit of the DMA zone.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index febaee7ca57b..8aab24f35a5e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -218,6 +218,7 @@ EXPORT_SYMBOL(arm_dma_zone_size);
  * so a successful GFP_DMA allocation will always satisfy this.
  */
 phys_addr_t arm_dma_limit;
+unsigned long arm_dma_pfn_limit;
 
 static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
 	unsigned long dma_size)
@@ -240,6 +241,7 @@ void __init setup_dma_zone(const struct machine_desc *mdesc)
 		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
 	} else
 		arm_dma_limit = 0xffffffff;
+	arm_dma_pfn_limit = arm_dma_limit >> PAGE_SHIFT;
 #endif
 }
 

commit cebf3e40b01bbf88d38dc954397414afaa280023
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Fri Oct 11 09:27:27 2013 +0200

    Revert "ARM: init: add support for reserved memory defined by device tree"
    
    This reverts commit 10bcdfb8ba24760f715f0a700c3812747eddddf5. There is
    no consensus on the bindings for the reserved memory, so the code for
    handing it will be reverted.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index febaee7ca57b..18ec4c504abf 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -17,7 +17,6 @@
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
 #include <linux/of_fdt.h>
-#include <linux/of_reserved_mem.h>
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
@@ -379,8 +378,6 @@ void __init arm_memblock_init(struct meminfo *mi,
 	if (mdesc->reserve)
 		mdesc->reserve();
 
-	early_init_dt_scan_reserved_mem();
-
 	/*
 	 * reserve memory for DMA contigouos allocations,
 	 * must come from DMA area inside low memory

commit 29eb45a9ab4839a1e9cef2bcf369b918c9c4fcad
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Fri Aug 30 17:06:53 2013 -0500

    of: remove early_init_dt_setup_initrd_arch
    
    All arches do essentially the same thing now for
    early_init_dt_setup_initrd_arch, so it can now be removed.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: x86@kernel.org
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Acked-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9eeb1cd1c401..9d0b91dccf37 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -77,14 +77,6 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
-#if defined(CONFIG_OF_FLATTREE) && defined(CONFIG_BLK_DEV_INITRD)
-void __init early_init_dt_setup_initrd_arch(u64 start, u64 end)
-{
-	initrd_start = (unsigned long)__va(start);
-	initrd_end = (unsigned long)__va(end);
-}
-#endif /* CONFIG_OF_FLATTREE */
-
 /*
  * This keeps memory configuration data used by a couple memory
  * initialization functions, as well as show_mem() for the skipping

commit 65939301acdb1e593fdb424bd356f0b9bc7ba5be
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Fri Aug 30 10:54:26 2013 -0500

    arm: set initrd_start/initrd_end for fdt scan
    
    In order to unify the initrd scanning for DT across architectures, make
    arm set initrd_start and initrd_end instead of the physical addresses.
    This is aligned with all other architectures.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Acked-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index febaee7ca57b..9eeb1cd1c401 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -77,11 +77,11 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
-#ifdef CONFIG_OF_FLATTREE
+#if defined(CONFIG_OF_FLATTREE) && defined(CONFIG_BLK_DEV_INITRD)
 void __init early_init_dt_setup_initrd_arch(u64 start, u64 end)
 {
-	phys_initrd_start = start;
-	phys_initrd_size = end - start;
+	initrd_start = (unsigned long)__va(start);
+	initrd_end = (unsigned long)__va(end);
 }
 #endif /* CONFIG_OF_FLATTREE */
 
@@ -351,6 +351,11 @@ void __init arm_memblock_init(struct meminfo *mi,
 	memblock_reserve(__pa(_stext), _end - _stext);
 #endif
 #ifdef CONFIG_BLK_DEV_INITRD
+	/* FDT scan will populate initrd_start */
+	if (initrd_start) {
+		phys_initrd_start = __virt_to_phys(initrd_start);
+		phys_initrd_size = initrd_end - initrd_start;
+	}
 	if (phys_initrd_size &&
 	    !memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
 		pr_err("INITRD: 0x%08llx+0x%08lx is not a memory region - disabling initrd\n",

commit 31f7c3a688f75bceaf2fd009efc489659ad6aa61
Merge: ec5b103ecfde 2bc552df76d8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 10 13:53:52 2013 -0700

    Merge tag 'devicetree-for-linus' of git://git.secretlab.ca/git/linux
    
    Pull device tree core updates from Grant Likely:
     "Generally minor changes.  A bunch of bug fixes, particularly for
      initialization and some refactoring.  Most notable change if feeding
      the entire flattened tree into the random pool at boot.  May not be
      significant, but shouldn't hurt either"
    
    Tim Bird questions whether the boot time cost of the random feeding may
    be noticeable.  And "add_device_randomness()" is definitely not some
    speed deamon of a function.
    
    * tag 'devicetree-for-linus' of git://git.secretlab.ca/git/linux:
      of/platform: add error reporting to of_amba_device_create()
      irq/of: Fix comment typo for irq_of_parse_and_map
      of: Feed entire flattened device tree into the random pool
      of/fdt: Clean up casting in unflattening path
      of/fdt: Remove duplicate memory clearing on FDT unflattening
      gpio: implement gpio-ranges binding document fix
      of: call __of_parse_phandle_with_args from of_parse_phandle
      of: introduce of_parse_phandle_with_fixed_args
      of: move of_parse_phandle()
      of: move documentation of of_parse_phandle_with_args
      of: Fix missing memory initialization on FDT unflattening
      of: consolidate definition of early_init_dt_alloc_memory_arch()
      of: Make of_get_phy_mode() return int i.s.o. const int
      include: dt-binding: input: create a DT header defining key codes.
      of/platform: Staticize of_platform_device_create_pdata()
      of: Specify initrd location using 64-bit
      dt: Typo fix
      OF: make of_property_for_each_{u32|string}() use parameters if OF is not enabled

commit 640414171818c6293c23e74a28d1c69b2a1a7fe5
Merge: fa91515cbf23 a2bdc32a527e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 9 16:35:29 2013 -0700

    Merge tag 'late-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull ARM SoC late changes from Kevin Hilman:
     "These are changes that arrived a little late before the merge window,
      or had dependencies on previous branches.
    
      Highlights:
       - ux500: misc.  cleanup, fixup I2C devices
       - exynos: DT updates for RTC; PM updates
       - at91: DT updates for NAND; new platforms added to generic defconfig
       - sunxi: DT updates: cubieboard2, pinctrl driver, gated clocks
       - highbank: LPAE fixes, select necessary ARM errata
       - omap: PM fixes and improvements; OMAP5 mailbox support
       - omap: basic support for new DRA7xx SoCs"
    
    * tag 'late-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (60 commits)
      ARM: dts: vexpress: Add CCI node to TC2 device-tree
      ARM: EXYNOS: Skip C1 cpuidle state for exynos5440
      ARM: EXYNOS: always enable PM domains support for EXYNOS4X12
      ARM: highbank: clean-up some unused includes
      ARM: sun7i: Enable the A20 clocks in the DTSI
      ARM: sun6i: Enable clock support in the DTSI
      ARM: sun5i: dt: Use the A10s gates in the DTSI
      ARM: at91: at91_dt_defconfig: enable rm9200 support
      ARM: dts: add ADC device tree node for exynos5420/5250
      ARM: dts: Add RTC DT node to Exynos5420 SoC
      ARM: dts: Update the "status" property of RTC DT node for Exynos5250 SoC
      ARM: dts: Fix the RTC DT node name for Exynos5250
      irqchip: mmp: avoid to include irqs head file
      ARM: mmp: avoid to include head file in mach-mmp
      irqchip: mmp: support irqchip
      irqchip: move mmp irq driver
      ARM: OMAP: AM33xx: clock: Add RNG clock data
      ARM: OMAP: TI81XX: add always-on powerdomain for TI81XX
      ARM: OMAP4: clock: Lock PLLs in the right sequence
      ARM: OMAP: AM33XX: hwmod: Add hwmod data for debugSS
      ...

commit 64c353864e3f7ccba0ade1bd6f562f9a3bc7e68d
Merge: d8cacd3a259b 10bcdfb8ba24
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 9 10:26:33 2013 -0700

    Merge branch 'for-v3.12' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping
    
    Pull DMA mapping update from Marek Szyprowski:
     "This contains an addition of Device Tree support for reserved memory
      regions (Contiguous Memory Allocator is one of the drivers for it) and
      changes required by the KVM extensions for PowerPC architectue"
    
    * 'for-v3.12' of git://git.linaro.org/people/mszyprowski/linux-dma-mapping:
      ARM: init: add support for reserved memory defined by device tree
      drivers: of: add initialization code for dma reserved memory
      drivers: of: add function to scan fdt nodes given by path
      drivers: dma-contiguous: clean source code and prepare for device tree

commit 10bcdfb8ba24760f715f0a700c3812747eddddf5
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Fri Aug 9 13:01:08 2013 +0200

    ARM: init: add support for reserved memory defined by device tree
    
    Enable reserved memory initialization from device tree.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Kyungmin Park <kyungmin.park@samsung.com>
    Acked-by: Michal Nazarewicz <mina86@mina86.com>
    Acked-by: Tomasz Figa <t.figa@samsung.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 15225d829d71..6a2fe4453eee 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -17,6 +17,7 @@
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
 #include <linux/of_fdt.h>
+#include <linux/of_reserved_mem.h>
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
@@ -377,6 +378,8 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	if (mdesc->reserve)
 		mdesc->reserve();
 
+	early_init_dt_scan_reserved_mem();
+
 	/*
 	 * reserve memory for DMA contigouos allocations,
 	 * must come from DMA area inside low memory

commit 364230b9952143eb2062dc071e919fb751540ae8
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Thu Aug 1 15:29:29 2013 -0500

    ARM: use phys_addr_t for DMA zone sizes
    
    In order to specify a DMA zone size of 4GB on LPAE systems, the sizes need
    to be 64-bit. So make machine_desc.dma_zone_size and arm_dma_zone_size be
    phys_addr_t instead of unsigned long.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 15225d829d71..c0bb66e69999 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -207,7 +207,7 @@ static void __init arm_bootmem_init(unsigned long start_pfn,
 
 #ifdef CONFIG_ZONE_DMA
 
-unsigned long arm_dma_zone_size __read_mostly;
+phys_addr_t arm_dma_zone_size __read_mostly;
 EXPORT_SYMBOL(arm_dma_zone_size);
 
 /*

commit ff69a4c855066592f9e293cff8f54813614dd544
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 26 14:55:59 2013 +0100

    ARM: constify machine_desc structure uses
    
    struct machine_desc records are defined everywhere as a 'const'
    structure, but unfortuantely it loses its const-ness through the use of
    linker magic - the symbols which surround the section are not declared
    const so it becomes possible not to use 'const' for pointers to these
    const structures.
    
    Let's fix this oversight - all pointers to these structures should be
    marked const too.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 15225d829d71..2958e74fc42c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -231,7 +231,7 @@ static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
 }
 #endif
 
-void __init setup_dma_zone(struct machine_desc *mdesc)
+void __init setup_dma_zone(const struct machine_desc *mdesc)
 {
 #ifdef CONFIG_ZONE_DMA
 	if (mdesc->dma_zone_size) {
@@ -335,7 +335,8 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 	return phys;
 }
 
-void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
+void __init arm_memblock_init(struct meminfo *mi,
+	const struct machine_desc *mdesc)
 {
 	int i;
 

commit 374d5c9964c10373ba39bbe934f4262eb87d7114
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Mon Jul 1 14:20:35 2013 -0400

    of: Specify initrd location using 64-bit
    
    On some PAE architectures, the entire range of physical memory could reside
    outside the 32-bit limit.  These systems need the ability to specify the
    initrd location using 64-bit numbers.
    
    This patch globally modifies the early_init_dt_setup_initrd_arch() function to
    use 64-bit numbers instead of the current unsigned long.
    
    There has been quite a bit of debate about whether to use u64 or phys_addr_t.
    It was concluded to stick to u64 to be consistent with rest of the device
    tree code. As summarized by Geert, "The address to load the initrd is decided
    by the bootloader/user and set at that point later in time. The dtb should not
    be tied to the kernel you are booting"
    
    More details on the discussion can be found here:
    https://lkml.org/lkml/2013/6/20/690
    https://lkml.org/lkml/2012/9/13/544
    
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Acked-by: Jean-Christophe PLAGNIOL-VILLARD <plagnioj@jcrosoft.com>
    Signed-off-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 15225d829d71..81484177c9b8 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -77,7 +77,7 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
 #ifdef CONFIG_OF_FLATTREE
-void __init early_init_dt_setup_initrd_arch(unsigned long start, unsigned long end)
+void __init early_init_dt_setup_initrd_arch(u64 start, u64 end)
 {
 	phys_initrd_start = start;
 	phys_initrd_size = end - start;

commit bfd65dd9fe42b54c6f4eabbabc40bda9e25dcf93
Merge: d14474647899 cbbe6f82b489
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 13 14:58:36 2013 -0700

    Merge branch 'fixes' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull ARM fixes from Russell King:
     "A few fixes for ARM, mostly just one liners with the exception of the
      missing section specification.  We decided not to rely on .previous to
      fix this but to explicitly state the section we want the code to be
      in."
    
    * 'fixes' of git://git.linaro.org/people/rmk/linux-arm:
      ARM: 7778/1: smp_twd: twd_update_frequency need be run on all online CPUs
      ARM: 7782/1: Kconfig: Let ARM_ERRATA_364296 not depend on CONFIG_SMP
      ARM: mm: fix boot on SA1110 Assabet
      ARM: 7781/1: mmu: Add debug_ll_io_init() mappings to early mappings
      ARM: 7780/1: add missing linker section markup to head-common.S

commit 319e0b4f02f73983c03a2ca38595fc6367929edf
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jul 9 09:52:55 2013 +0100

    ARM: mm: fix boot on SA1110 Assabet
    
    Commit 83db0384 (mm/ARM: use common help functions to free reserved
    pages) broke booting on the Assabet by trying to convert a PFN to
    a virtual address using the __va() macro.  This macro takes the
    physical address, not a PFN.  Fix this.
    
    Cc: <stable@vger.kernel.org> # 3.10
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9a5cdc01fcdf..0ecc43fd6229 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -600,7 +600,7 @@ void __init mem_init(void)
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */
-	free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, 0, NULL);
+	free_reserved_area(__va(PHYS_OFFSET), swapper_pg_dir, 0, NULL);
 #endif
 
 	free_highpages();

commit 2450c97323e635a04f7b2f4b68680ab2c151bbbf
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:03:48 2013 -0700

    mm/ARM: prepare for removing num_physpages and simplify mem_init()
    
    Prepare for removing num_physpages and simplify mem_init().
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 06e9ce17d1d2..6833cbead6cc 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -583,9 +583,6 @@ static void __init free_highpages(void)
  */
 void __init mem_init(void)
 {
-	unsigned long reserved_pages, free_pages;
-	struct memblock_region *reg;
-	int i;
 #ifdef CONFIG_HAVE_TCM
 	/* These pointers are filled in on TCM detection */
 	extern u32 dtcm_end;
@@ -605,47 +602,7 @@ void __init mem_init(void)
 
 	free_highpages();
 
-	reserved_pages = free_pages = 0;
-
-	for_each_bank(i, &meminfo) {
-		struct membank *bank = &meminfo.bank[i];
-		unsigned int pfn1, pfn2;
-		struct page *page, *end;
-
-		pfn1 = bank_pfn_start(bank);
-		pfn2 = bank_pfn_end(bank);
-
-		page = pfn_to_page(pfn1);
-		end  = pfn_to_page(pfn2 - 1) + 1;
-
-		do {
-			if (PageReserved(page))
-				reserved_pages++;
-			else if (!page_count(page))
-				free_pages++;
-			page++;
-		} while (page < end);
-	}
-
-	/*
-	 * Since our memory may not be contiguous, calculate the
-	 * real number of pages we have in this system
-	 */
-	printk(KERN_INFO "Memory:");
-	num_physpages = 0;
-	for_each_memblock(memory, reg) {
-		unsigned long pages = memblock_region_memory_end_pfn(reg) -
-			memblock_region_memory_base_pfn(reg);
-		num_physpages += pages;
-		printk(" %ldMB", pages >> (20 - PAGE_SHIFT));
-	}
-	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
-
-	printk(KERN_NOTICE "Memory: %luk/%luk available, %luk reserved, %luK highmem\n",
-		nr_free_pages() << (PAGE_SHIFT-10),
-		free_pages << (PAGE_SHIFT-10),
-		reserved_pages << (PAGE_SHIFT-10),
-		totalhigh_pages << (PAGE_SHIFT-10));
+	mem_init_print_info(NULL);
 
 #define MLK(b, t) b, t, ((t) - (b)) >> 10
 #define MLM(b, t) b, t, ((t) - (b)) >> 20
@@ -711,7 +668,7 @@ void __init mem_init(void)
 	BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE	> PAGE_OFFSET);
 #endif
 
-	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
+	if (PAGE_SIZE >= 16384 && get_num_physpages() <= 128) {
 		extern int sysctl_overcommit_memory;
 		/*
 		 * On a machine this small we won't get

commit 0c988534737a358fdff42fcce78f0ff1a12dbfc5
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:03:24 2013 -0700

    mm: concentrate modification of totalram_pages into the mm core
    
    Concentrate code to modify totalram_pages into the mm core, so the arch
    memory initialized code doesn't need to take care of it.  With these
    changes applied, only following functions from mm core modify global
    variable totalram_pages: free_bootmem_late(), free_all_bootmem(),
    free_all_bootmem_node(), adjust_managed_page_count().
    
    With this patch applied, it will be much more easier for us to keep
    totalram_pages and zone->managed_pages in consistence.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2070651c1bb4..06e9ce17d1d2 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -596,8 +596,7 @@ void __init mem_init(void)
 
 	/* this will put all unused low memory onto the freelists */
 	free_unused_memmap(&meminfo);
-
-	totalram_pages += free_all_bootmem();
+	free_all_bootmem();
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */

commit dbe67df4ba78c79db547c7864e1120981c144c97
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:02:51 2013 -0700

    mm: enhance free_reserved_area() to support poisoning memory with zero
    
    Address more review comments from last round of code review.
    1) Enhance free_reserved_area() to support poisoning freed memory with
       pattern '0'. This could be used to get rid of poison_init_mem()
       on ARM64.
    2) A previous patch has disabled memory poison for initmem on s390
       by mistake, so restore to the original behavior.
    3) Remove redundant PAGE_ALIGN() when calling free_reserved_area().
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7fae391caf86..2070651c1bb4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -601,7 +601,7 @@ void __init mem_init(void)
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */
-	free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, 0, NULL);
+	free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, -1, NULL);
 #endif
 
 	free_highpages();
@@ -729,12 +729,12 @@ void free_initmem(void)
 	extern char __tcm_start, __tcm_end;
 
 	poison_init_mem(&__tcm_start, &__tcm_end - &__tcm_start);
-	free_reserved_area(&__tcm_start, &__tcm_end, 0, "TCM link");
+	free_reserved_area(&__tcm_start, &__tcm_end, -1, "TCM link");
 #endif
 
 	poison_init_mem(__init_begin, __init_end - __init_begin);
 	if (!machine_is_integrator() && !machine_is_cintegrator())
-		free_initmem_default(0);
+		free_initmem_default(-1);
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -745,7 +745,7 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 {
 	if (!keep_initrd) {
 		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
-		free_reserved_area((void *)start, (void *)end, 0, "initrd");
+		free_reserved_area((void *)start, (void *)end, -1, "initrd");
 	}
 }
 

commit 11199692d83dd3fe1511203024fb9853d176ec4c
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:02:48 2013 -0700

    mm: change signature of free_reserved_area() to fix building warnings
    
    Change signature of free_reserved_area() according to Russell King's
    suggestion to fix following build warnings:
    
      arch/arm/mm/init.c: In function 'mem_init':
      arch/arm/mm/init.c:603:2: warning: passing argument 1 of 'free_reserved_area' makes integer from pointer without a cast [enabled by default]
        free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, 0, NULL);
        ^
      In file included from include/linux/mman.h:4:0,
                       from arch/arm/mm/init.c:15:
      include/linux/mm.h:1301:22: note: expected 'long unsigned int' but argument is of type 'void *'
       extern unsigned long free_reserved_area(unsigned long start, unsigned long end,
    
       mm/page_alloc.c: In function 'free_reserved_area':
    >> mm/page_alloc.c:5134:3: warning: passing argument 1 of 'virt_to_phys' makes pointer from integer without a cast [enabled by default]
       In file included from arch/mips/include/asm/page.h:49:0,
                        from include/linux/mmzone.h:20,
                        from include/linux/gfp.h:4,
                        from include/linux/mm.h:8,
                        from mm/page_alloc.c:18:
       arch/mips/include/asm/io.h:119:29: note: expected 'const volatile void *' but argument is of type 'long unsigned int'
       mm/page_alloc.c: In function 'free_area_init_nodes':
       mm/page_alloc.c:5030:34: warning: array subscript is below array bounds [-Warray-bounds]
    
    Also address some minor code review comments.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2ffee02d1d5c..7fae391caf86 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -745,7 +745,7 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 {
 	if (!keep_initrd) {
 		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
-		free_reserved_area(start, end, 0, "initrd");
+		free_reserved_area((void *)start, (void *)end, 0, "initrd");
 	}
 }
 

commit de22cc6e33449d8d6fb339619e32138ea4fcc2a4
Author: Vitaly Andrianov <vitalya@ti.com>
Date:   Fri Jun 22 14:26:04 2012 -0400

    ARM: LPAE: use phys_addr_t for initrd location
    
    This patch fixes the initrd setup code to use phys_addr_t instead of assuming
    32-bit addressing.  Without this we cannot boot on systems where initrd is
    located above the 4G physical address limit.
    
    Signed-off-by: Vitaly Andrianov <vitalya@ti.com>
    Signed-off-by: Cyril Chemparathy <cyril@ti.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Subash Patel <subash.rp@samsung.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 68c914e8544e..2ffee02d1d5c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -36,12 +36,13 @@
 
 #include "mm.h"
 
-static unsigned long phys_initrd_start __initdata = 0;
+static phys_addr_t phys_initrd_start __initdata = 0;
 static unsigned long phys_initrd_size __initdata = 0;
 
 static int __init early_initrd(char *p)
 {
-	unsigned long start, size;
+	phys_addr_t start;
+	unsigned long size;
 	char *endp;
 
 	start = memparse(p, &endp);
@@ -350,14 +351,14 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (phys_initrd_size &&
 	    !memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
-		pr_err("INITRD: 0x%08lx+0x%08lx is not a memory region - disabling initrd\n",
-		       phys_initrd_start, phys_initrd_size);
+		pr_err("INITRD: 0x%08llx+0x%08lx is not a memory region - disabling initrd\n",
+		       (u64)phys_initrd_start, phys_initrd_size);
 		phys_initrd_start = phys_initrd_size = 0;
 	}
 	if (phys_initrd_size &&
 	    memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
-		pr_err("INITRD: 0x%08lx+0x%08lx overlaps in-use memory region - disabling initrd\n",
-		       phys_initrd_start, phys_initrd_size);
+		pr_err("INITRD: 0x%08llx+0x%08lx overlaps in-use memory region - disabling initrd\n",
+		       (u64)phys_initrd_start, phys_initrd_size);
 		phys_initrd_start = phys_initrd_size = 0;
 	}
 	if (phys_initrd_size) {

commit 56bc628666b39dc8cb395c7686d8c032efd731f4
Author: Vitaly Andrianov <vitalya@ti.com>
Date:   Thu Jun 21 08:09:05 2012 -0400

    ARM: LPAE: use phys_addr_t in free_memmap()
    
    The free_memmap() was mistakenly using unsigned long type to represent
    physical addresses.  This breaks on PAE systems where memory could be placed
    above the 32-bit addressible limit.
    
    This patch fixes this function to properly use phys_addr_t instead.
    
    Signed-off-by: Vitaly Andrianov <vitalya@ti.com>
    Signed-off-by: Cyril Chemparathy <cyril@ti.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Subash Patel <subash.rp@samsung.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9a5cdc01fcdf..68c914e8544e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -442,7 +442,7 @@ static inline void
 free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 {
 	struct page *start_pg, *end_pg;
-	unsigned long pg, pgend;
+	phys_addr_t pg, pgend;
 
 	/*
 	 * Convert start_pfn/end_pfn to a struct page pointer.
@@ -454,8 +454,8 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * Convert to physical addresses, and
 	 * round start upwards and end downwards.
 	 */
-	pg = (unsigned long)PAGE_ALIGN(__pa(start_pg));
-	pgend = (unsigned long)__pa(end_pg) & PAGE_MASK;
+	pg = PAGE_ALIGN(__pa(start_pg));
+	pgend = __pa(end_pg) & PAGE_MASK;
 
 	/*
 	 * If there are free pages between these,

commit dd6911efb54ce04cc9dc81745b6a96ecf1b4ce5e
Author: Jiang Liu <liuj97@gmail.com>
Date:   Mon Apr 29 15:07:03 2013 -0700

    mm/ARM: use free_highmem_page() to free highmem pages into buddy system
    
    Use helper function free_highmem_page() to free highmem pages into
    the buddy system.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 611f21772fa8..9a5cdc01fcdf 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -522,10 +522,8 @@ static void __init free_unused_memmap(struct meminfo *mi)
 #ifdef CONFIG_HIGHMEM
 static inline void free_area_high(unsigned long pfn, unsigned long end)
 {
-	for (; pfn < end; pfn++) {
-		__free_reserved_page(pfn_to_page(pfn));
-		totalhigh_pages++;
-	}
+	for (; pfn < end; pfn++)
+		free_highmem_page(pfn_to_page(pfn));
 }
 #endif
 
@@ -574,7 +572,6 @@ static void __init free_highpages(void)
 		if (start < end)
 			free_area_high(start, end);
 	}
-	totalram_pages += totalhigh_pages;
 #endif
 }
 

commit 83db0384a92ac4e52dccd275bc1a58dca86d629d
Author: Jiang Liu <liuj97@gmail.com>
Date:   Mon Apr 29 15:06:26 2013 -0700

    mm/ARM: use common help functions to free reserved pages
    
    Use common help functions to free reserved pages.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ad9a9f3f0322..611f21772fa8 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -427,24 +427,6 @@ void __init bootmem_init(void)
 	max_pfn = max_high - PHYS_PFN_OFFSET;
 }
 
-static inline int free_area(unsigned long pfn, unsigned long end, char *s)
-{
-	unsigned int pages = 0, size = (end - pfn) << (PAGE_SHIFT - 10);
-
-	for (; pfn < end; pfn++) {
-		struct page *page = pfn_to_page(pfn);
-		ClearPageReserved(page);
-		init_page_count(page);
-		__free_page(page);
-		pages++;
-	}
-
-	if (size && s)
-		printk(KERN_INFO "Freeing %s memory: %dK\n", s, size);
-
-	return pages;
-}
-
 /*
  * Poison init memory with an undefined instruction (ARM) or a branch to an
  * undefined instruction (Thumb).
@@ -537,6 +519,16 @@ static void __init free_unused_memmap(struct meminfo *mi)
 #endif
 }
 
+#ifdef CONFIG_HIGHMEM
+static inline void free_area_high(unsigned long pfn, unsigned long end)
+{
+	for (; pfn < end; pfn++) {
+		__free_reserved_page(pfn_to_page(pfn));
+		totalhigh_pages++;
+	}
+}
+#endif
+
 static void __init free_highpages(void)
 {
 #ifdef CONFIG_HIGHMEM
@@ -572,8 +564,7 @@ static void __init free_highpages(void)
 			if (res_end > end)
 				res_end = end;
 			if (res_start != start)
-				totalhigh_pages += free_area(start, res_start,
-							     NULL);
+				free_area_high(start, res_start);
 			start = res_end;
 			if (start == end)
 				break;
@@ -581,7 +572,7 @@ static void __init free_highpages(void)
 
 		/* And now free anything which remains */
 		if (start < end)
-			totalhigh_pages += free_area(start, end, NULL);
+			free_area_high(start, end);
 	}
 	totalram_pages += totalhigh_pages;
 #endif
@@ -612,8 +603,7 @@ void __init mem_init(void)
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */
-	totalram_pages += free_area(PHYS_PFN_OFFSET,
-				    __phys_to_pfn(__pa(swapper_pg_dir)), NULL);
+	free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, 0, NULL);
 #endif
 
 	free_highpages();
@@ -741,16 +731,12 @@ void free_initmem(void)
 	extern char __tcm_start, __tcm_end;
 
 	poison_init_mem(&__tcm_start, &__tcm_end - &__tcm_start);
-	totalram_pages += free_area(__phys_to_pfn(__pa(&__tcm_start)),
-				    __phys_to_pfn(__pa(&__tcm_end)),
-				    "TCM link");
+	free_reserved_area(&__tcm_start, &__tcm_end, 0, "TCM link");
 #endif
 
 	poison_init_mem(__init_begin, __init_end - __init_begin);
 	if (!machine_is_integrator() && !machine_is_cintegrator())
-		totalram_pages += free_area(__phys_to_pfn(__pa(__init_begin)),
-					    __phys_to_pfn(__pa(__init_end)),
-					    "init");
+		free_initmem_default(0);
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -761,9 +747,7 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 {
 	if (!keep_initrd) {
 		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
-		totalram_pages += free_area(__phys_to_pfn(__pa(start)),
-					    __phys_to_pfn(__pa(end)),
-					    "initrd");
+		free_reserved_area(start, end, 0, "initrd");
 	}
 }
 

commit 4b59e6c4730978679b414a8da61514a2518da512
Author: David Rientjes <rientjes@google.com>
Date:   Mon Apr 29 15:06:11 2013 -0700

    mm, show_mem: suppress page counts in non-blockable contexts
    
    On large systems with a lot of memory, walking all RAM to determine page
    types may take a half second or even more.
    
    In non-blockable contexts, the page allocator will emit a page allocation
    failure warning unless __GFP_NOWARN is specified.  In such contexts, irqs
    are typically disabled and such a lengthy delay may even result in NMI
    watchdog timeouts.
    
    To fix this, suppress the page walk in such contexts when printing the
    page allocation failure warning.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Dave Hansen <dave@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ad722f1208a5..ad9a9f3f0322 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -99,6 +99,9 @@ void show_mem(unsigned int filter)
 	printk("Mem-info:\n");
 	show_free_areas(filter);
 
+	if (filter & SHOW_MEM_FILTER_PAGE_COUNT)
+		return;
+
 	for_each_bank (i, mi) {
 		struct membank *bank = &mi->bank[i];
 		unsigned int pfn1, pfn2;

commit 7ac68a4c1de6aac5b0bb231fe6d8505ebe5686d9
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Aug 13 00:22:28 2012 +0100

    ARM: Allow arm_memblock_steal() to remove memory from any RAM region
    
    Allow arm_memblock_steal() to remove memory from any RAM region,
    including highmem areas.  This allows memory to be stolen from the
    very top of declared memory, including highmem areas, rather than
    our precious lowmem.
    
    Acked-by: Sascha Hauer <s.hauer@pengutronix.de>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9aec41fa80ae..ad722f1208a5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -324,7 +324,7 @@ phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 
 	BUG_ON(!arm_memblock_steal_permitted);
 
-	phys = memblock_alloc(size, align);
+	phys = memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ANYWHERE);
 	memblock_free(phys, size);
 	memblock_remove(phys, size);
 

commit 91b006def384d8f07f9f324ab211fefe2b085c90
Merge: 28a33cbc24e4 ad722541147e d0a533b18235 ff081e05bfba 339ca09d7ada cb70706c822c
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 27 23:06:32 2012 +0100

    Merge branches 'audit', 'delay', 'fixes', 'misc' and 'sta2x11' into for-linus

commit 158e8bfe802f730f9ea7cde32eee8b43285bdd4a
Author: Alessandro Rubini <rubini@gnudd.com>
Date:   Sun Jun 24 12:46:26 2012 +0100

    ARM: 7432/1: use the new linux/sizes.h
    
    Signed-off-by: Alessandro Rubini <rubini@gnudd.com>
    Acked-by: Giancarlo Asnaghi <giancarlo.asnaghi@st.com>
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Cc: Alan Cox <alan@linux.intel.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c21d06c7dd7e..ad7fd8ae8258 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -21,13 +21,13 @@
 #include <linux/gfp.h>
 #include <linux/memblock.h>
 #include <linux/dma-contiguous.h>
+#include <linux/sizes.h>
 
 #include <asm/mach-types.h>
 #include <asm/memblock.h>
 #include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
-#include <asm/sizes.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
 

commit 4986e5c7cd91817d0f58dd15073c9080d47980cf
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Wed Jun 6 12:05:01 2012 +0200

    ARM: mm: fix type of the arm_dma_limit global variable
    
    arm_dma_limit stores physical address of maximal address accessible by DMA,
    so the phys_addr_t type makes much more sense for it instead of u32. This
    patch fixes the following build warning:
    
    arch/arm/mm/init.c:380: warning: comparison of distinct pointer types lacks a cast
    
    Reported-by: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c21d06c7dd7e..f54d59219764 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -212,7 +212,7 @@ EXPORT_SYMBOL(arm_dma_zone_size);
  * allocations.  This must be the smallest DMA mask in the system,
  * so a successful GFP_DMA allocation will always satisfy this.
  */
-u32 arm_dma_limit;
+phys_addr_t arm_dma_limit;
 
 static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
 	unsigned long dma_size)

commit c79095092834a18ae74cfc08def1a5a101dc106c
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Thu Dec 29 13:09:51 2011 +0100

    ARM: integrate CMA with DMA-mapping subsystem
    
    This patch adds support for CMA to dma-mapping subsystem for ARM
    architecture. By default a global CMA area is used, but specific devices
    are allowed to have their private memory areas if required (they can be
    created with dma_declare_contiguous() function during board
    initialisation).
    
    Contiguous memory areas reserved for DMA are remapped with 2-level page
    tables on boot. Once a buffer is requested, a low memory kernel mapping
    is updated to to match requested memory access type.
    
    GFP_ATOMIC allocations are performed from special pool which is created
    early during boot. This way remapping page attributes is not needed on
    allocation time.
    
    CMA has been enabled unconditionally for ARMv6+ systems.
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    CC: Michal Nazarewicz <mina86@mina86.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Tested-by: Rob Clark <rob.clark@linaro.org>
    Tested-by: Ohad Ben-Cohen <ohad@wizery.com>
    Tested-by: Benjamin Gaignard <benjamin.gaignard@linaro.org>
    Tested-by: Robert Nelson <robertcnelson@gmail.com>
    Tested-by: Barry Song <Baohua.Song@csr.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8f5813bbffb5..c21d06c7dd7e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -20,6 +20,7 @@
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
+#include <linux/dma-contiguous.h>
 
 #include <asm/mach-types.h>
 #include <asm/memblock.h>
@@ -226,6 +227,17 @@ static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
 }
 #endif
 
+void __init setup_dma_zone(struct machine_desc *mdesc)
+{
+#ifdef CONFIG_ZONE_DMA
+	if (mdesc->dma_zone_size) {
+		arm_dma_zone_size = mdesc->dma_zone_size;
+		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
+	} else
+		arm_dma_limit = 0xffffffff;
+#endif
+}
+
 static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 	unsigned long max_high)
 {
@@ -273,12 +285,9 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 	 * Adjust the sizes according to any special requirements for
 	 * this machine type.
 	 */
-	if (arm_dma_zone_size) {
+	if (arm_dma_zone_size)
 		arm_adjust_dma_zone(zone_size, zhole_size,
 			arm_dma_zone_size >> PAGE_SHIFT);
-		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
-	} else
-		arm_dma_limit = 0xffffffff;
 #endif
 
 	free_area_init_node(0, zone_size, min, zhole_size);
@@ -364,6 +373,12 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	if (mdesc->reserve)
 		mdesc->reserve();
 
+	/*
+	 * reserve memory for DMA contigouos allocations,
+	 * must come from DMA area inside low memory
+	 */
+	dma_contiguous_reserve(min(arm_dma_limit, arm_lowmem_limit));
+
 	arm_memblock_steal_permitted = false;
 	memblock_allow_resize();
 	memblock_dump_all();

commit 14904927fcef6bb881fd995b478a0d2e700c1818
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Fri Apr 27 01:40:10 2012 +0100

    ARM: 7401/1: mm: Fix section mismatches
    
    WARNING: vmlinux.o(.text+0x111b8): Section mismatch in reference
    from the function arm_memory_present() to the function
    .init.text:memory_present()
    The function arm_memory_present() references
    the function __init memory_present().
    This is often because arm_memory_present lacks a __init
    annotation or the annotation of memory_present is wrong.
    
    WARNING: arch/arm/mm/built-in.o(.text+0x1edc): Section mismatch
    in reference from the function alloc_init_pud() to the function
    .init.text:alloc_init_section()
    The function alloc_init_pud() references
    the function __init alloc_init_section().
    This is often because alloc_init_pud lacks a __init
    annotation or the annotation of alloc_init_section is wrong.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 595079fa9d1d..8f5813bbffb5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -293,11 +293,11 @@ EXPORT_SYMBOL(pfn_valid);
 #endif
 
 #ifndef CONFIG_SPARSEMEM
-static void arm_memory_present(void)
+static void __init arm_memory_present(void)
 {
 }
 #else
-static void arm_memory_present(void)
+static void __init arm_memory_present(void)
 {
 	struct memblock_region *reg;
 

commit 12679a2d7e3bfbdc7586e3e86d1ca90c46659363
Merge: 1c036588772d b0df89868006
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 16:53:48 2012 -0700

    Merge branch 'for-linus' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull more ARM updates from Russell King.
    
    This got a fair number of conflicts with the <asm/system.h> split, but
    also with some other sparse-irq and header file include cleanups.  They
    all looked pretty trivial, though.
    
    * 'for-linus' of git://git.linaro.org/people/rmk/linux-arm: (59 commits)
      ARM: fix Kconfig warning for HAVE_BPF_JIT
      ARM: 7361/1: provide XIP_VIRT_ADDR for no-MMU builds
      ARM: 7349/1: integrator: convert to sparse irqs
      ARM: 7259/3: net: JIT compiler for packet filters
      ARM: 7334/1: add jump label support
      ARM: 7333/2: jump label: detect %c support for ARM
      ARM: 7338/1: add support for early console output via semihosting
      ARM: use set_current_blocked() and block_sigmask()
      ARM: exec: remove redundant set_fs(USER_DS)
      ARM: 7332/1: extract out code patch function from kprobes
      ARM: 7331/1: extract out insn generation code from ftrace
      ARM: 7330/1: ftrace: use canonical Thumb-2 wide instruction format
      ARM: 7351/1: ftrace: remove useless memory checks
      ARM: 7316/1: kexec: EOI active and mask all interrupts in kexec crash path
      ARM: Versatile Express: add NO_IOPORT
      ARM: get rid of asm/irq.h in asm/prom.h
      ARM: 7319/1: Print debug info for SIGBUS in user faults
      ARM: 7318/1: gic: refactor irq_start assignment
      ARM: 7317/1: irq: avoid NULL check in for_each_irq_desc loop
      ARM: 7315/1: perf: add support for the Cortex-A7 PMU
      ...

commit d9277d51a8eeaa097d3c1385f458c99d65ffc4f4
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Wed Feb 1 11:16:51 2012 +0100

    ARM: 7312/1: only show modules in the memory layout for MODULES=y
    
    This line is irritating and wrong when modules are not supported, so
    don't show it then.
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 6ec1226fc62d..42d906f89964 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -659,7 +659,9 @@ void __init mem_init(void)
 #ifdef CONFIG_HIGHMEM
 			"    pkmap   : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 #endif
+#ifdef CONFIG_MODULES
 			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+#endif
 			"      .text : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n"
@@ -678,7 +680,9 @@ void __init mem_init(void)
 			MLM(PKMAP_BASE, (PKMAP_BASE) + (LAST_PKMAP) *
 				(PAGE_SIZE)),
 #endif
+#ifdef CONFIG_MODULES
 			MLM(MODULES_VADDR, MODULES_END),
+#endif
 
 			MLK_ROUNDUP(_text, _etext),
 			MLK_ROUNDUP(__init_begin, __init_end),

commit 9e45dd688a1860a5e1e84844e43abf881564edb5
Author: Jesper Juhl <jj@chaosbits.net>
Date:   Sun Feb 5 01:22:29 2012 +0100

    ARM: Remove duplicate asm/memblock.h include from arch/arm/mm/init.c
    
    There's no need to include the header twice, so get rid of the
    duplicate.
    
    Signed-off-by: Jesper Juhl <jj@chaosbits.net>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 5dc7d127a40f..245a55a0a5bb 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -32,7 +32,6 @@
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
-#include <asm/memblock.h>
 
 #include "mm.h"
 

commit bc2827d08cb31de5ab3a467a3e1572d8437340e6
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jan 19 14:35:19 2012 +0000

    ARM: fix a section mismatch warning with our use of memblock
    
    Commit 716a3dc2008 (ARM: Add arm_memblock_steal() to allocate memory
    away from the kernel) added a function which calls memblock_alloc().
    This causes a section conflict:
    
    WARNING: vmlinux.o(.text+0xc614): Section mismatch in reference from the function arm_memblock_steal() to the function .init.text:memblock_alloc()
    The function arm_memblock_steal() references
    the function __init memblock_alloc().
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 6ec1226fc62d..5dc7d127a40f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -310,7 +310,7 @@ static void arm_memory_present(void)
 
 static bool arm_memblock_steal_permitted = true;
 
-phys_addr_t arm_memblock_steal(phys_addr_t size, phys_addr_t align)
+phys_addr_t __init arm_memblock_steal(phys_addr_t size, phys_addr_t align)
 {
 	phys_addr_t phys;
 

commit 716a3dc20084da9b3ab17bd125005a5345e23e3b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jan 13 15:00:51 2012 +0000

    ARM: Add arm_memblock_steal() to allocate memory away from the kernel
    
    Several platforms are now using the memblock_alloc+memblock_free+
    memblock_remove trick to obtain memory which won't be mapped in the
    kernel's page tables.  Most platforms do this (correctly) in the
    ->reserve callback.  However, OMAP has started to call these functions
    outside of this callback, and this is extremely unsafe - memory will
    not be unmapped, and could well be given out after memblock is no
    longer responsible for its management.
    
    So, provide arm_memblock_steal() to perform this function, and ensure
    that it panic()s if it is used inappropriately.  Convert everyone
    over, including OMAP.
    
    As a result, OMAP with OMAP4_ERRATA_I688 enabled will panic on boot
    with this change.  Mark this option as BROKEN and make it depend on
    BROKEN.  OMAP needs to be fixed, or 137d105d50 (ARM: OMAP4: Fix
    errata i688 with MPU interconnect barriers.) reverted until such
    time it can be fixed correctly.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e34ea8adc1f9..6ec1226fc62d 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -22,6 +22,7 @@
 #include <linux/memblock.h>
 
 #include <asm/mach-types.h>
+#include <asm/memblock.h>
 #include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
@@ -307,6 +308,21 @@ static void arm_memory_present(void)
 }
 #endif
 
+static bool arm_memblock_steal_permitted = true;
+
+phys_addr_t arm_memblock_steal(phys_addr_t size, phys_addr_t align)
+{
+	phys_addr_t phys;
+
+	BUG_ON(!arm_memblock_steal_permitted);
+
+	phys = memblock_alloc(size, align);
+	memblock_free(phys, size);
+	memblock_remove(phys, size);
+
+	return phys;
+}
+
 void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 {
 	int i;
@@ -349,6 +365,7 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	if (mdesc->reserve)
 		mdesc->reserve();
 
+	arm_memblock_steal_permitted = false;
 	memblock_allow_resize();
 	memblock_dump_all();
 }

commit 770e1b035dcb6ec3f8ee69dda0815dd1e220a683
Merge: d3d0b024348c 7b9dd47136c0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 6 18:15:25 2012 -0800

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm: (207 commits)
      ARM: 7267/1: Remove BUILD_BUG_ON from asm/bug.h
      ARM: 7269/1: mach-sa1100: fix sched_clock breakage
      ARM: 7198/1: arm/imx6: add restart support for imx6q
      ARM: restart: remove the now empty arch_reset()
      ARM: restart: remove comments about adding code to arch_reset()
      ARM: restart: lpc32xx & u300: remove unnecessary printk
      ARM: restart: plat-samsung: remove plat/reset.h and s5p_reset_hook
      ARM: restart: w90x900: use new restart hook
      ARM: restart: Versatile Express: use new restart hook
      ARM: restart: versatile: use new restart hook
      ARM: restart: u300: use new restart hook
      ARM: restart: tegra: use new restart hook
      ARM: restart: spear: use new restart hook
      ARM: restart: shark: use new restart hook
      ARM: restart: sa1100: use new restart hook
      ARM: 7252/1: restart: S5PV210: use new restart hook
      ARM: 7251/1: restart: S5PC100: use new restart hook
      ARM: 7250/1: restart: S5P64X0: use new restart hook
      ARM: 7266/1: restart: S3C64XX: use new restart hook
      ARM: 7265/1: restart: S3C24XX: use new restart hook
      ...
    
    Fix up trivial conflict in arch/arm/mm/init.c due to removal of
    memblock_init() clashing with the movement of the sorting of the meminfo
    array.

commit 1aadc0560f46530f8a0f11055285b876a8a31770
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 8 10:22:08 2011 -0800

    memblock: s/memblock_analyze()/memblock_allow_resize()/ and update users
    
    The only function of memblock_analyze() is now allowing resize of
    memblock region arrays.  Rename it to memblock_allow_resize() and
    update its users.
    
    * The following users remain the same other than renaming.
    
      arm/mm/init.c::arm_memblock_init()
      microblaze/kernel/prom.c::early_init_devtree()
      powerpc/kernel/prom.c::early_init_devtree()
      openrisc/kernel/prom.c::early_init_devtree()
      sh/mm/init.c::paging_init()
      sparc/mm/init_64.c::paging_init()
      unicore32/mm/init.c::uc32_memblock_init()
    
    * In the following users, analyze was used to update total size which
      is no longer necessary.
    
      powerpc/kernel/machine_kexec.c::reserve_crashkernel()
      powerpc/kernel/prom.c::early_init_devtree()
      powerpc/mm/init_32.c::MMU_init()
      powerpc/mm/tlb_nohash.c::__early_init_mmu()
      powerpc/platforms/ps3/mm.c::ps3_mm_add_memory()
      powerpc/platforms/embedded6xx/wii.c::wii_memory_fixups()
      sh/kernel/machine_kexec.c::reserve_crashkernel()
    
    * x86/kernel/e820.c::memblock_x86_fill() was directly setting
      memblock_can_resize before populating memblock and calling analyze
      afterwards.  Call memblock_allow_resize() before start populating.
    
    memblock_can_resize is now static inside memblock.c.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: "H. Peter Anvin" <hpa@zytor.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4140843399ca..7c38474e533a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -371,7 +371,7 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	if (mdesc->reserve)
 		mdesc->reserve();
 
-	memblock_analyze();
+	memblock_allow_resize();
 	memblock_dump_all();
 }
 

commit fe091c208a40299fba40e62292a610fb91e44b4e
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 8 10:22:07 2011 -0800

    memblock: Kill memblock_init()
    
    memblock_init() initializes arrays for regions and memblock itself;
    however, all these can be done with struct initializers and
    memblock_init() can be removed.  This patch kills memblock_init() and
    initializes memblock with struct initializer.
    
    The only difference is that the first dummy entries don't have .nid
    set to MAX_NUMNODES initially.  This doesn't cause any behavior
    difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: "H. Peter Anvin" <hpa@zytor.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9863f03097d0..4140843399ca 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -333,7 +333,6 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 
 	sort(&meminfo.bank, meminfo.nr_banks, sizeof(meminfo.bank[0]), meminfo_cmp, NULL);
 
-	memblock_init();
 	for (i = 0; i < mi->nr_banks; i++)
 		memblock_add(mi->bank[i].start, mi->bank[i].size);
 

commit 1c16d242aa441c11ccaeaa63b49712555b8bfaeb
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Dec 8 10:22:06 2011 -0800

    memblock: Fix include breakages caused by 24aa07882b
    
    24aa07882b (memblock, x86: Replace memblock_x86_reserve/free_range()
    with generic ones) removed arch/x86/include/asm/memblock.h and dropped
    its inclusion from include/linux/memblock.h which breaks other
    architectures which depended on the generic memblock.h pulling in the
    arch specific one.
    
    However, the proper fix isn't adding back the asm inclusion.  memblock
    doesn't have any arch dependent part and doesn't need arch specific
    header file and asm/memblock.h files are either practically empty or
    contain mostly unrelated arch specific stuff.
    
    * In microblaze, sh, powerpc, sparc and openrisc, asm/memblock.h is
      either empty or just contains unused MEMBLOCK_DBG() macro.  Remove
      them.
    
    * In arm and unicore32, asm/memblock.h contains arch specific stuff.
      Include it directly from its users.  It might be a good idea to
      rename the header file to avoid confusion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index fbdd12ea3a58..9863f03097d0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -32,6 +32,7 @@
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
+#include <asm/memblock.h>
 
 #include "mm.h"
 

commit 55a8173cfe1c6b489f8f5705282c762aed2e265e
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Sun Sep 18 22:40:00 2011 -0400

    ARM: move initialization of the high_memory variable earlier
    
    Some upcoming changes must know the VMALLOC_START value, which is based
    on high_memory, before bootmem_init() is called.
    
    The best location to set it is in sanity_check_meminfo() where the needed
    computation is already done, and in the non MMU case it is trivial to do
    now that the meminfo array is already sorted at that point.
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index d366051e14fe..786adddf1a86 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -381,8 +381,6 @@ void __init bootmem_init(void)
 	 */
 	arm_bootmem_free(min, max_low, max_high);
 
-	high_memory = __va(((phys_addr_t)max_low << PAGE_SHIFT) - 1) + 1;
-
 	/*
 	 * This doesn't seem to be used by the Linux memory manager any
 	 * more, but is used by ll_rw_block.  If we can get rid of it, we

commit 27a3f0e91bed0f4dcf0a363e5f5938126d1ff4e5
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Thu Aug 25 19:10:29 2011 -0400

    ARM: sort the meminfo array earlier
    
    The meminfo array has to be sorted before sanity_check_meminfo() in
    arch/arm/mm/mmu.c is called for it to work properly.  This also allows
    for a simpler find_limits() in arch/arm/mm/init.c.
    
    The sort is moved to arch/arm/kernel/setup.c because that's where the
    meminfo array is populated.  Eventually this should be improved upon
    to make the memory bank parser a bit more robust against problems
    such as overlapping memory ranges.
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index fbdd12ea3a58..d366051e14fe 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -20,7 +20,6 @@
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
-#include <linux/sort.h>
 
 #include <asm/mach-types.h>
 #include <asm/prom.h>
@@ -134,30 +133,18 @@ void show_mem(unsigned int filter)
 }
 
 static void __init find_limits(unsigned long *min, unsigned long *max_low,
-	unsigned long *max_high)
+			       unsigned long *max_high)
 {
 	struct meminfo *mi = &meminfo;
 	int i;
 
-	*min = -1UL;
-	*max_low = *max_high = 0;
-
-	for_each_bank (i, mi) {
-		struct membank *bank = &mi->bank[i];
-		unsigned long start, end;
-
-		start = bank_pfn_start(bank);
-		end = bank_pfn_end(bank);
-
-		if (*min > start)
-			*min = start;
-		if (*max_high < end)
-			*max_high = end;
-		if (bank->highmem)
-			continue;
-		if (*max_low < end)
-			*max_low = end;
-	}
+	/* This assumes the meminfo array is properly sorted */
+	*min = bank_pfn_start(&mi->bank[0]);
+	for_each_bank (i, mi)
+		if (mi->bank[i].highmem)
+				break;
+	*max_low = bank_pfn_end(&mi->bank[i - 1]);
+	*max_high = bank_pfn_end(&mi->bank[mi->nr_banks - 1]);
 }
 
 static void __init arm_bootmem_init(unsigned long start_pfn,
@@ -319,19 +306,10 @@ static void arm_memory_present(void)
 }
 #endif
 
-static int __init meminfo_cmp(const void *_a, const void *_b)
-{
-	const struct membank *a = _a, *b = _b;
-	long cmp = bank_pfn_start(a) - bank_pfn_start(b);
-	return cmp < 0 ? -1 : cmp > 0 ? 1 : 0;
-}
-
 void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 {
 	int i;
 
-	sort(&meminfo.bank, meminfo.nr_banks, sizeof(meminfo.bank[0]), meminfo_cmp, NULL);
-
 	memblock_init();
 	for (i = 0; i < mi->nr_banks; i++)
 		memblock_add(mi->bank[i].start, mi->bank[i].size);

commit dc28094b905a872f8884f1f1c48ca86b3b78583a
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sun Jul 31 16:17:29 2011 -0400

    arm: Add export.h to ARM specific files as required.
    
    These files all make use of one of the EXPORT_SYMBOL variants
    or the THIS_MODULE macro.  So they will need <linux/export.h>
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 04e9a92bb47a..fbdd12ea3a58 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -13,6 +13,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/mman.h>
+#include <linux/export.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
 #include <linux/of_fdt.h>

commit 1fdb24e969110fafea36d3b393bea438f702c87f
Merge: f362f98e7c44 531a6a941745
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 28 12:02:27 2011 -0700

    Merge branch 'devel-stable' of http://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm
    
    * 'devel-stable' of http://ftp.arm.linux.org.uk/pub/linux/arm/kernel/git-cur/linux-2.6-arm: (178 commits)
      ARM: 7139/1: fix compilation with CONFIG_ARM_ATAG_DTB_COMPAT and large TEXT_OFFSET
      ARM: gic, local timers: use the request_percpu_irq() interface
      ARM: gic: consolidate PPI handling
      ARM: switch from NO_MACH_MEMORY_H to NEED_MACH_MEMORY_H
      ARM: mach-s5p64x0: remove mach/memory.h
      ARM: mach-s3c64xx: remove mach/memory.h
      ARM: plat-mxc: remove mach/memory.h
      ARM: mach-prima2: remove mach/memory.h
      ARM: mach-zynq: remove mach/memory.h
      ARM: mach-bcmring: remove mach/memory.h
      ARM: mach-davinci: remove mach/memory.h
      ARM: mach-pxa: remove mach/memory.h
      ARM: mach-ixp4xx: remove mach/memory.h
      ARM: mach-h720x: remove mach/memory.h
      ARM: mach-vt8500: remove mach/memory.h
      ARM: mach-s5pc100: remove mach/memory.h
      ARM: mach-tegra: remove mach/memory.h
      ARM: plat-tcc: remove mach/memory.h
      ARM: mach-mmp: remove mach/memory.h
      ARM: mach-cns3xxx: remove mach/memory.h
      ...
    
    Fix up mostly pretty trivial conflicts in:
     - arch/arm/Kconfig
     - arch/arm/include/asm/localtimer.h
     - arch/arm/kernel/Makefile
     - arch/arm/mach-shmobile/board-ap4evb.c
     - arch/arm/mach-u300/core.c
     - arch/arm/mm/dma-mapping.c
     - arch/arm/mm/proc-v7.S
     - arch/arm/plat-omap/Kconfig
    largely due to some CONFIG option renaming (ie CONFIG_PM_SLEEP ->
    CONFIG_ARM_CPU_SUSPEND for the arm-specific suspend code etc) and
    addition of NEED_MACH_MEMORY_H next to HAVE_IDE.

commit 002ea9eefec98dada56fd5f8e432a4e8570c2a26
Author: Linus Walleij <linus.walleij@linaro.org>
Date:   Thu Sep 29 09:37:23 2011 +0100

    ARM: 7113/1: mm: Align bank start to MAX_ORDER_NR_PAGES
    
    The VM subsystem assumes that there are valid memmap entries from
    the bank start aligned to MAX_ORDER_NR_PAGES.
    
    On the Ux500 we have a lot of mem=N arguments on the commandline
    triggering this bug several times over and causing kernel
    oops messages.
    
    Cc: stable@kernel.org
    Cc: Michael Bohan <mbohan@codeaurora.org>
    Cc: Nicolas Pitre <nico@fluxnic.net>
    Signed-off-by: Johan Palsson <johan.palsson@stericsson.com>
    Signed-off-by: Rabin Vincent <rabin.vincent@stericsson.com>
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index cc7e2d8be9aa..f8037ba338ac 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -496,6 +496,13 @@ static void __init free_unused_memmap(struct meminfo *mi)
 		 */
 		bank_start = min(bank_start,
 				 ALIGN(prev_bank_end, PAGES_PER_SECTION));
+#else
+		/*
+		 * Align down here since the VM subsystem insists that the
+		 * memmap entries are valid from the bank start aligned to
+		 * MAX_ORDER_NR_PAGES.
+		 */
+		bank_start = round_down(bank_start, MAX_ORDER_NR_PAGES);
 #endif
 		/*
 		 * If we had a previous bank, and there is a space

commit f70cac8d9c7125f83048f8b3d1c60f5a041a165c
Merge: 4722cd7741c6 08aab447c56a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Sep 21 08:48:33 2011 +0100

    Merge branch 'kprobes-test' of git://git.yxit.co.uk/linux into devel-stable

commit fb492c9160f3d40d09456a79cc669fba74d7d9cc
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Aug 30 17:45:10 2011 +0100

    ARM: 7067/1: mm: keep significant bits in pfn_valid
    
    When ARCH_HAS_HOLES_MEMORYMODEL is selected, pfn_valid calls
    memblock_is_memory to test validity of a pfn:
    
    > memblock_is_memory(pfn << PAGE_SHIFT);
    
    On LPAE systems this cuts off the top bits, as the shift occurs before
    the value is promoted to a phys_addr_t.
    
    This patch replaces the shift with a call to __pfn_to_phys (which casts
    pfn to phys_addr_t before shifting), preventing the loss of significant
    bits.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 91bca355cd31..cc7e2d8be9aa 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -298,7 +298,7 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 #ifdef CONFIG_HAVE_ARCH_PFN_VALID
 int pfn_valid(unsigned long pfn)
 {
-	return memblock_is_memory(pfn << PAGE_SHIFT);
+	return memblock_is_memory(__pfn_to_phys(pfn));
 }
 EXPORT_SYMBOL(pfn_valid);
 #endif

commit 99d1717dd7fecf2b10195b0d864323b952b4eba0
Author: Jon Medhurst <tixy@yxit.co.uk>
Date:   Tue Aug 2 17:28:27 2011 +0100

    ARM: Add init_consistent_dma_size()
    
    This function can be called during boot to increase the size of the consistent
    DMA region above it's default value of 2MB. It must be called before the memory
    allocator is initialised, i.e. before any core_initcall.
    
    Signed-off-by: Jon Medhurst <tixy@yxit.co.uk>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 91bca355cd31..64ab41348f30 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -653,9 +653,6 @@ void __init mem_init(void)
 			"    ITCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 #endif
 			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-#ifdef CONFIG_MMU
-			"    DMA     : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-#endif
 			"    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 			"    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 #ifdef CONFIG_HIGHMEM
@@ -674,9 +671,6 @@ void __init mem_init(void)
 			MLK(ITCM_OFFSET, (unsigned long) itcm_end),
 #endif
 			MLK(FIXADDR_START, FIXADDR_TOP),
-#ifdef CONFIG_MMU
-			MLM(CONSISTENT_BASE, CONSISTENT_END),
-#endif
 			MLM(VMALLOC_START, VMALLOC_END),
 			MLM(PAGE_OFFSET, (unsigned long)high_memory),
 #ifdef CONFIG_HIGHMEM
@@ -699,9 +693,6 @@ void __init mem_init(void)
 	 * be detected at build time already.
 	 */
 #ifdef CONFIG_MMU
-	BUILD_BUG_ON(VMALLOC_END			> CONSISTENT_BASE);
-	BUG_ON(VMALLOC_END				> CONSISTENT_BASE);
-
 	BUILD_BUG_ON(TASK_SIZE				> MODULES_VADDR);
 	BUG_ON(TASK_SIZE 				> MODULES_VADDR);
 #endif

commit bf912d99e94cd1f43a7decce2e9b79a3ca7f2418
Author: Jamie Iles <jamie@jamieiles.com>
Date:   Thu Aug 4 09:39:31 2011 +0100

    ARM: 7010/1: mm: fix invalid loop for poison_init_mem
    
    poison_init_mem() used a loop of:
    
            while ((count = count - 4))
    
    which has 2 problems - an off by one error so that we do one less word
    than we should, and the other is that if count == 0 then we loop forever
    and poison too much.  On a platform with HAVE_TCM=y but nothing in the
    TCM's, this caused corruption and the platform failed to boot.
    
    Acked-by: Stephen Boyd <sboyd@codeaurora.org>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Jamie Iles <jamie@jamieiles.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2fee782077c1..91bca355cd31 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -441,7 +441,7 @@ static inline int free_area(unsigned long pfn, unsigned long end, char *s)
 static inline void poison_init_mem(void *s, size_t count)
 {
 	u32 *p = (u32 *)s;
-	while ((count = count - 4))
+	for (; count != 0; count -= 4)
 		*p++ = 0xe7fddef0;
 }
 

commit 3ad55155b222f2a901405dea20ff7c68828ecd92
Merge: 06f365acef5c 6645cb61f3a1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 22 23:09:07 2011 +0100

    Merge branch 'devel-stable' into for-next
    
    Conflicts:
            arch/arm/kernel/entry-armv.S

commit 06f365acef5ca54fd5708a0d853c4a89609536f1
Merge: 4348810a241a 022ae537b23c 30891c90d811 e7d59db91a34 e2f81844efa2 4cde7e0dca98 7f294e4983b6 29cb3cd208dd 19dad35fe0f1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 22 23:08:48 2011 +0100

    Merge branches 'btc', 'dma', 'entry', 'fixes', 'linker-layout', 'misc', 'mmci', 'suspend' and 'vfp' into for-next

commit fb89fcfb151698776be6c900aec8161b01990e92
Author: Nicolas Pitre <nico@fluxnic.net>
Date:   Mon Jul 18 15:17:15 2011 -0400

    ARM: ARM_DMA_ZONE_SIZE is no more
    
    One less dependency on mach/memory.h.
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4a8a01e0c3ab..90a38c6baca4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -28,7 +28,6 @@
 #include <asm/sizes.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
-#include <asm/memory.h>
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
@@ -214,11 +213,7 @@ static void __init arm_bootmem_init(unsigned long start_pfn,
 
 #ifdef CONFIG_ZONE_DMA
 
-#ifdef ARM_DMA_ZONE_SIZE
-unsigned long arm_dma_zone_size = ARM_DMA_ZONE_SIZE;
-#else
 unsigned long arm_dma_zone_size __read_mostly;
-#endif
 EXPORT_SYMBOL(arm_dma_zone_size);
 
 /*

commit 650320181a08b64d4421c65c639cf47ad8cc2cd6
Author: Nicolas Pitre <nico@fluxnic.net>
Date:   Mon Jul 18 15:05:10 2011 -0400

    ARM: change ARM_DMA_ZONE_SIZE into a variable
    
    Having this value defined at compile time prevents multiple machines with
    conflicting definitions to coexist.  Move it to a variable in preparation
    for having a per machine value selected at run time.  This is relevant
    only when CONFIG_ZONE_DMA is selected.
    
    Signed-off-by: Nicolas Pitre <nicolas.pitre@linaro.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 17d6cd0c57ed..4a8a01e0c3ab 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -28,6 +28,7 @@
 #include <asm/sizes.h>
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
+#include <asm/memory.h>
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
@@ -212,6 +213,14 @@ static void __init arm_bootmem_init(unsigned long start_pfn,
 }
 
 #ifdef CONFIG_ZONE_DMA
+
+#ifdef ARM_DMA_ZONE_SIZE
+unsigned long arm_dma_zone_size = ARM_DMA_ZONE_SIZE;
+#else
+unsigned long arm_dma_zone_size __read_mostly;
+#endif
+EXPORT_SYMBOL(arm_dma_zone_size);
+
 /*
  * The DMA mask corresponding to the maximum bus address allocatable
  * using GFP_DMA.  The default here places no restriction on DMA
@@ -275,19 +284,17 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 #endif
 	}
 
-#ifdef ARM_DMA_ZONE_SIZE
-#ifndef CONFIG_ZONE_DMA
-#error ARM_DMA_ZONE_SIZE set but no DMA zone to limit allocations
-#endif
-
+#ifdef CONFIG_ZONE_DMA
 	/*
 	 * Adjust the sizes according to any special requirements for
 	 * this machine type.
 	 */
-	arm_adjust_dma_zone(zone_size, zhole_size,
-		ARM_DMA_ZONE_SIZE >> PAGE_SHIFT);
-
-	arm_dma_limit = PHYS_OFFSET + ARM_DMA_ZONE_SIZE - 1;
+	if (arm_dma_zone_size) {
+		arm_adjust_dma_zone(zone_size, zhole_size,
+			arm_dma_zone_size >> PAGE_SHIFT);
+		arm_dma_limit = PHYS_OFFSET + arm_dma_zone_size - 1;
+	} else
+		arm_dma_limit = 0xffffffff;
 #endif
 
 	free_area_init_node(0, zone_size, min, zhole_size);

commit 022ae537b23cb14a391565e9ad9e9945f4b17138
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 8 21:26:59 2011 +0100

    ARM: dma: replace ISA_DMA_THRESHOLD with a variable
    
    ISA_DMA_THRESHOLD has been unused by non-arch code, so lets now get
    rid of it from ARM by replacing it with arm_dma_zone_mask.  Move
    dma_supported() and dma_set_mask() out of line, and have
    dma_supported() check this new variable instead.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c19571c40a21..17d6cd0c57ed 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -212,6 +212,14 @@ static void __init arm_bootmem_init(unsigned long start_pfn,
 }
 
 #ifdef CONFIG_ZONE_DMA
+/*
+ * The DMA mask corresponding to the maximum bus address allocatable
+ * using GFP_DMA.  The default here places no restriction on DMA
+ * allocations.  This must be the smallest DMA mask in the system,
+ * so a successful GFP_DMA allocation will always satisfy this.
+ */
+u32 arm_dma_limit;
+
 static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
 	unsigned long dma_size)
 {
@@ -278,6 +286,8 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 	 */
 	arm_adjust_dma_zone(zone_size, zhole_size,
 		ARM_DMA_ZONE_SIZE >> PAGE_SHIFT);
+
+	arm_dma_limit = PHYS_OFFSET + ARM_DMA_ZONE_SIZE - 1;
 #endif
 
 	free_area_init_node(0, zone_size, min, zhole_size);

commit 54d525735140e930d87c5afd1b0b3393ffdac021
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Thu Jul 7 18:43:36 2011 +0100

    ARM: 6996/1: mm: Poison freed init memory
    
    Poisoning __init marked memory can be useful when tracking down
    obscure memory corruption bugs. Therefore, poison init memory
    with 0xe7fddef0 to catch bugs earlier. The poison value is an
    undefined instruction in ARM mode and branch to an undefined
    instruction in Thumb mode.
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2c2cce9cd8c8..fdc87f9bda55 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -416,6 +416,17 @@ static inline int free_area(unsigned long pfn, unsigned long end, char *s)
 	return pages;
 }
 
+/*
+ * Poison init memory with an undefined instruction (ARM) or a branch to an
+ * undefined instruction (Thumb).
+ */
+static inline void poison_init_mem(void *s, size_t count)
+{
+	u32 *p = (u32 *)s;
+	while ((count = count - 4))
+		*p++ = 0xe7fddef0;
+}
+
 static inline void
 free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 {
@@ -696,11 +707,13 @@ void free_initmem(void)
 #ifdef CONFIG_HAVE_TCM
 	extern char __tcm_start, __tcm_end;
 
+	poison_init_mem(&__tcm_start, &__tcm_end - &__tcm_start);
 	totalram_pages += free_area(__phys_to_pfn(__pa(&__tcm_start)),
 				    __phys_to_pfn(__pa(&__tcm_end)),
 				    "TCM link");
 #endif
 
+	poison_init_mem(__init_begin, __init_end - __init_begin);
 	if (!machine_is_integrator() && !machine_is_cintegrator())
 		totalram_pages += free_area(__phys_to_pfn(__pa(__init_begin)),
 					    __phys_to_pfn(__pa(__init_end)),
@@ -713,10 +726,12 @@ static int keep_initrd;
 
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	if (!keep_initrd)
+	if (!keep_initrd) {
+		poison_init_mem((void *)start, PAGE_ALIGN(end) - start);
 		totalram_pages += free_area(__phys_to_pfn(__pa(start)),
 					    __phys_to_pfn(__pa(end)),
 					    "initrd");
+	}
 }
 
 static int __init keepinitrd_setup(char *__unused)

commit 3835d69a6c7048a28d0aea3cb8403d5e83a0f867
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Jul 6 10:39:34 2011 +0100

    ARM: vmlinux.lds: move init sections between text and data sections
    
    Place the init sections between the text and data sections.  This
    means all code is grouped together at the beginning of the kernel
    image, and all data is at the end of the image.  This avoids problems
    with the 24-bit branch instruction relocations becoming invalid with
    large initramfs images.
    
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Tested-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c19571c40a21..b8e891243153 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -639,8 +639,8 @@ void __init mem_init(void)
 			"    pkmap   : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 #endif
 			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
-			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"      .text : 0x%p" " - 0x%p" "   (%4d kB)\n"
+			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"       .bss : 0x%p" " - 0x%p" "   (%4d kB)\n",
 
@@ -662,8 +662,8 @@ void __init mem_init(void)
 #endif
 			MLM(MODULES_VADDR, MODULES_END),
 
-			MLK_ROUNDUP(__init_begin, __init_end),
 			MLK_ROUNDUP(_text, _etext),
+			MLK_ROUNDUP(__init_begin, __init_end),
 			MLK_ROUNDUP(_sdata, _edata),
 			MLK_ROUNDUP(__bss_start, __bss_stop));
 

commit 8f4b8c7613928d5c6da43715fedc00a7b1ee53be
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jun 11 00:43:21 2011 +0100

    ARM: initrd: disable initrds outside of memory
    
    We can't cope with initrds outside of memory, so check that the
    initrd is within some declared memory to the kernel before using
    it.  Otherwise we're likely to OOPS during boot.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b2cf9460ea60..c19571c40a21 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -330,6 +330,12 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	memblock_reserve(__pa(_stext), _end - _stext);
 #endif
 #ifdef CONFIG_BLK_DEV_INITRD
+	if (phys_initrd_size &&
+	    !memblock_is_region_memory(phys_initrd_start, phys_initrd_size)) {
+		pr_err("INITRD: 0x%08lx+0x%08lx is not a memory region - disabling initrd\n",
+		       phys_initrd_start, phys_initrd_size);
+		phys_initrd_start = phys_initrd_size = 0;
+	}
 	if (phys_initrd_size &&
 	    memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
 		pr_err("INITRD: 0x%08lx+0x%08lx overlaps in-use memory region - disabling initrd\n",

commit 45f6d7e0e634d49744c1a590461ed1bb3d2201ac
Author: Rabin Vincent <rabin@rab.in>
Date:   Thu Jun 2 15:01:36 2011 +0100

    ARM: 6951/1: include .bss in memory layout information
    
    The "Virtual memory kernel layout" message at startup already prints
    .text and .data.  Print .bss too.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 2c2cce9cd8c8..b2cf9460ea60 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -635,7 +635,8 @@ void __init mem_init(void)
 			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
 			"      .text : 0x%p" " - 0x%p" "   (%4d kB)\n"
-			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n",
+			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n"
+			"       .bss : 0x%p" " - 0x%p" "   (%4d kB)\n",
 
 			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
 				(PAGE_SIZE)),
@@ -657,7 +658,8 @@ void __init mem_init(void)
 
 			MLK_ROUNDUP(__init_begin, __init_end),
 			MLK_ROUNDUP(_text, _etext),
-			MLK_ROUNDUP(_sdata, _edata));
+			MLK_ROUNDUP(_sdata, _edata),
+			MLK_ROUNDUP(__bss_start, __bss_stop));
 
 #undef MLK
 #undef MLM

commit 239df0fd5ee25588f8a5ba7f7ee646940cc403f4
Merge: cc780af5aca0 ae1d3b974e09 81479c246c07
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri May 27 22:59:57 2011 +0100

    Merge branches 'devel', 'devel-stable' and 'fixes' into for-linus

commit 7b7bf499f79de3f6c85a340c8453a78789523f85
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu May 19 13:21:14 2011 +0100

    ARM: 6913/1: sparsemem: allow pfn_valid to be overridden when using SPARSEMEM
    
    In commit eb33575c ("[ARM] Double check memmap is actually valid with a
    memmap has unexpected holes V2"), a new function, memmap_valid_within,
    was introduced to mmzone.h so that holes in the memmap which pass
    pfn_valid in SPARSEMEM configurations can be detected and avoided.
    
    The fix to this problem checks that the pfn <-> page linkages are
    correct by calculating the page for the pfn and then checking that
    page_to_pfn on that page returns the original pfn. Unfortunately, in
    SPARSEMEM configurations, this results in reading from the page flags to
    determine the correct section. Since the memmap here has been freed,
    junk is read from memory and the check is no longer robust.
    
    In the best case, reading from /proc/pagetypeinfo will give you the
    wrong answer. In the worst case, you get SEGVs, Kernel OOPses and hung
    CPUs. Furthermore, ioremap implementations that use pfn_valid to
    disallow the remapping of normal memory will break.
    
    This patch allows architectures to provide their own pfn_valid function
    instead of using the default implementation used by sparsemem. The
    architecture-specific version is aware of the memmap state and will
    return false when passed a pfn for a freed page within a valid section.
    
    Acked-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3f17ea146f0e..bbc3346e8bcd 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -273,13 +273,15 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 	free_area_init_node(0, zone_size, min, zhole_size);
 }
 
-#ifndef CONFIG_SPARSEMEM
+#ifdef CONFIG_HAVE_ARCH_PFN_VALID
 int pfn_valid(unsigned long pfn)
 {
 	return memblock_is_memory(pfn << PAGE_SHIFT);
 }
 EXPORT_SYMBOL(pfn_valid);
+#endif
 
+#ifndef CONFIG_SPARSEMEM
 static void arm_memory_present(void)
 {
 }

commit 7bf02ea22c6cdd09e2d3f1d3c3fe366b834ae9af
Author: David Rientjes <rientjes@google.com>
Date:   Tue May 24 17:11:16 2011 -0700

    arch, mm: filter disallowed nodes from arch specific show_mem functions
    
    Architectures that implement their own show_mem() function did not pass
    the filter argument to show_free_areas() to appropriately avoid emitting
    the state of nodes that are disallowed in the current context.  This patch
    now passes the filter argument to show_free_areas() so those nodes are now
    avoided.
    
    This patch also removes the show_free_areas() wrapper around
    __show_free_areas() and converts existing callers to pass an empty filter.
    
    ia64 emits additional information for each node, so skip_free_areas_zone()
    must be made global to filter disallowed nodes and it is converted to use
    a nid argument rather than a zone for this use case.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Helge Deller <deller@gmx.de>
    Cc: James Bottomley <jejb@parisc-linux.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 76f82ae44efb..3f17ea146f0e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -85,7 +85,7 @@ void show_mem(unsigned int filter)
 	struct meminfo * mi = &meminfo;
 
 	printk("Mem-info:\n");
-	show_free_areas();
+	show_free_areas(filter);
 
 	for_each_bank (i, mi) {
 		struct membank *bank = &mi->bank[i];

commit 03eb14199e8a2ff2bc170b283305990151b0d619
Merge: d762f4383100 ede338f4ce2f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed May 25 00:08:17 2011 +0100

    Merge branch 'devicetree/arm-next' of git://git.secretlab.ca/git/linux-2.6 into devel-stable

commit 4b60e5f90dec4ae251386f20464336369e962e9c
Merge: e8765afe54b7 667f390bee98 a35d4e587371 4d5336d50a7b 041f10d46f97 be20902ba67d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 23 18:05:10 2011 +0100

    Merge branches 'consolidate-clksrc', 'consolidate-flash', 'consolidate-generic', 'consolidate-smp', 'consolidate-stmp' and 'consolidate-zones' into consolidate

commit 93c02ab40ae6e06cb24d14845d9f008fdd24f43d
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Thu Apr 28 14:27:21 2011 -0600

    arm/dt: probe for platforms via the device tree
    
    If a dtb is passed to the kernel then the kernel needs to iterate
    through compiled-in mdescs looking for one that matches and move the
    dtb data to a safe location before it gets accidentally overwritten by
    the kernel.
    
    This patch creates a new function, setup_machine_fdt() which is
    analogous to the setup_machine_atags() created in the previous patch.
    It does all the early setup needed to use a device tree machine
    description.
    
    v5: - Print warning with neither dtb nor atags are passed to the kernel
        - Fix bug in setting of __machine_arch_type to the selected machine,
          not just the last machine in the list.
          Reported-by: Tixy <tixy@yxit.co.uk>
        - Copy command line directly into boot_command_line instead of cmd_line
    v4: - Dump some output when a matching machine_desc cannot be found
    v3: - Added processing of reserved list.
        - Backed out the v2 change that copied instead of reserved the
          dtb.  dtb is reserved again and the real problem was fixed by
          using alloc_bootmem_align() for early allocation of RAM for
          unflattening the tree.
        - Moved cmd_line and initrd changes to earlier patch to make series
          bisectable.
    v2: Changed to save the dtb by copying into an allocated buffer.
        - Since the dtb will very likely be passed in the first 16k of ram
          where the interrupt vectors live, memblock_reserve() is
          insufficient to protect the dtb data.
    
    [based on work originally written by Jeremy Kerr <jeremy.kerr@canonical.com>]
    Tested-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 26c405421f4e..b26597552ebc 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -22,6 +22,7 @@
 #include <linux/sort.h>
 
 #include <asm/mach-types.h>
+#include <asm/prom.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
 #include <asm/sizes.h>
@@ -322,6 +323,7 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 #endif
 
 	arm_mm_memblock_reserve();
+	arm_dt_memblock_reserve();
 
 	/* reserve any platform specific memblock areas */
 	if (mdesc->reserve)

commit 9af386c8dc5a9dce56f36b484647ad6401758c85
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Apr 28 18:44:31 2011 +0100

    ARM: 6890/1: memmap: only free allocated memmap entries when using SPARSEMEM
    
    The SPARSEMEM code allocates memmap entries only for sections which are
    present (i.e. those which contain some valid memory). The membank checks
    in free_unused_memmap do not take this into account and can incorrectly
    attempt to free memory which is not allocated, resulting in a BUG() in
    the bootmem code.
    
    However, if memory is configured as follows:
    
        |<----section---->|<----hole---->|<----section---->|
        +--------+--------+--------------+--------+--------+
        | bank 0 | unused |              | bank 1 | unused |
        +--------+--------+--------------+--------+--------+
    
    where a bank only occupies part of a section, the memmap allocated for
    the remainder of the section *can* be freed.
    
    This patch modifies the checks in free_unused_memmap so that only valid
    memmap entries are considered for removal.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e5f6fc428348..e591513bb53e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -392,7 +392,7 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * Convert start_pfn/end_pfn to a struct page pointer.
 	 */
 	start_pg = pfn_to_page(start_pfn - 1) + 1;
-	end_pg = pfn_to_page(end_pfn);
+	end_pg = pfn_to_page(end_pfn - 1) + 1;
 
 	/*
 	 * Convert to physical addresses, and
@@ -426,6 +426,14 @@ static void __init free_unused_memmap(struct meminfo *mi)
 
 		bank_start = bank_pfn_start(bank);
 
+#ifdef CONFIG_SPARSEMEM
+		/*
+		 * Take care not to free memmap entries that don't exist
+		 * due to SPARSEMEM sections which aren't present.
+		 */
+		bank_start = min(bank_start,
+				 ALIGN(prev_bank_end, PAGES_PER_SECTION));
+#endif
 		/*
 		 * If we had a previous bank, and there is a space
 		 * between the current bank and the previous, free it.
@@ -440,6 +448,12 @@ static void __init free_unused_memmap(struct meminfo *mi)
 		 */
 		prev_bank_end = ALIGN(bank_pfn_end(bank), MAX_ORDER_NR_PAGES);
 	}
+
+#ifdef CONFIG_SPARSEMEM
+	if (!IS_ALIGNED(prev_bank_end, PAGES_PER_SECTION))
+		free_memmap(prev_bank_end,
+			    ALIGN(prev_bank_end, PAGES_PER_SECTION));
+#endif
 }
 
 static void __init free_highpages(void)

commit be20902ba67de70b38c995903321f4152dee57b7
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed May 11 15:39:00 2011 +0100

    ARM: use ARM_DMA_ZONE_SIZE to adjust the zone sizes
    
    Rather than each platform providing its own function to adjust the
    zone sizes, use the new ARM_DMA_ZONE_SIZE definition to perform this
    adjustment.  This ensures that the actual DMA zone size and the
    ISA_DMA_THRESHOLD/MAX_DMA_ADDRESS definitions are consistent with
    each other, and moves this complexity out of the platform code.
    
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e5f6fc428348..49eaad9136a7 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -201,6 +201,20 @@ static void __init arm_bootmem_init(unsigned long start_pfn,
 	}
 }
 
+#ifdef CONFIG_ZONE_DMA
+static void __init arm_adjust_dma_zone(unsigned long *size, unsigned long *hole,
+	unsigned long dma_size)
+{
+	if (size[0] <= dma_size)
+		return;
+
+	size[ZONE_NORMAL] = size[0] - dma_size;
+	size[ZONE_DMA] = dma_size;
+	hole[ZONE_NORMAL] = hole[0];
+	hole[ZONE_DMA] = 0;
+}
+#endif
+
 static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 	unsigned long max_high)
 {
@@ -243,11 +257,18 @@ static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
 #endif
 	}
 
+#ifdef ARM_DMA_ZONE_SIZE
+#ifndef CONFIG_ZONE_DMA
+#error ARM_DMA_ZONE_SIZE set but no DMA zone to limit allocations
+#endif
+
 	/*
 	 * Adjust the sizes according to any special requirements for
 	 * this machine type.
 	 */
-	arch_adjust_zones(zone_size, zhole_size);
+	arm_adjust_dma_zone(zone_size, zhole_size,
+		ARM_DMA_ZONE_SIZE >> PAGE_SHIFT);
+#endif
 
 	free_area_init_node(0, zone_size, min, zhole_size);
 }

commit 9eb8f6743b076b67f00776cda4330c802e157b41
Author: Grant Likely <grant.likely@secretlab.ca>
Date:   Thu Apr 28 14:27:20 2011 -0600

    arm/dt: Allow CONFIG_OF on ARM
    
    Add some basic empty infrastructure for DT support on ARM.
    
    v5: - Fix off-by-one error in size calculation of initrd
        - Stop mucking with cmd_line, and load command line from dt into
          boot_command_line instead which matches the behaviour of ATAGS booting
    v3: - moved cmd_line export and initrd setup to this patch to make the
          series bisectable.
        - switched to alloc_bootmem_align() for allocation when
          unflattening the device tree.  memblock_alloc() was not the
          right interface.
    
    Signed-off-by: Jeremy Kerr <jeremy.kerr@canonical.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Grant Likely <grant.likely@secretlab.ca>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e5f6fc428348..26c405421f4e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -15,6 +15,7 @@
 #include <linux/mman.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
+#include <linux/of_fdt.h>
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
@@ -71,6 +72,14 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
+#ifdef CONFIG_OF_FLATTREE
+void __init early_init_dt_setup_initrd_arch(unsigned long start, unsigned long end)
+{
+	phys_initrd_start = start;
+	phys_initrd_size = end - start;
+}
+#endif /* CONFIG_OF_FLATTREE */
+
 /*
  * This keeps memory configuration data used by a couple memory
  * initialization functions, as well as show_mem() for the skipping

commit b2b755b5f10eb32fbdc73a9907c07006b17f714b
Author: David Rientjes <rientjes@google.com>
Date:   Thu Mar 24 15:18:15 2011 -0700

    lib, arch: add filter argument to show_mem and fix private implementations
    
    Commit ddd588b5dd55 ("oom: suppress nodes that are not allowed from
    meminfo on oom kill") moved lib/show_mem.o out of lib/lib.a, which
    resulted in build warnings on all architectures that implement their own
    versions of show_mem():
    
            lib/lib.a(show_mem.o): In function `show_mem':
            show_mem.c:(.text+0x1f4): multiple definition of `show_mem'
            arch/sparc/mm/built-in.o:(.text+0xd70): first defined here
    
    The fix is to remove __show_mem() and add its argument to show_mem() in
    all implementations to prevent this breakage.
    
    Architectures that implement their own show_mem() actually don't do
    anything with the argument yet, but they could be made to filter nodes
    that aren't allowed in the current context in the future just like the
    generic implementation.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Reported-by: James Bottomley <James.Bottomley@hansenpartnership.com>
    Suggested-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b3b0f0f5053d..e5f6fc428348 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -78,7 +78,7 @@ __tagtable(ATAG_INITRD2, parse_tag_initrd2);
  */
 struct meminfo meminfo;
 
-void show_mem(void)
+void show_mem(unsigned int filter)
 {
 	int free = 0, total = 0, reserved = 0;
 	int shared = 0, cached = 0, slab = 0, i;

commit 196f020fbbb83d246960548e73a40fd08f3e7866
Merge: 6d7ed21d17e6 7d85d61f6ad6 516295e5ab4b 3de4ade3d696
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Mar 20 09:32:12 2011 +0000

    Merge branches 'fixes', 'pgt-next' and 'versatile' into devel

commit cae6292b653f5e3308bf2787a54b7dcd2cc7e2b3
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 15 12:42:57 2011 +0100

    ARM: 6672/1: LPAE: use phys_addr_t instead of unsigned long in mapping functions
    
    The unsigned long datatype is not sufficient for mapping physical addresses
    >= 4GB.
    
    This patch ensures that the phys_addr_t datatype is used to represent physical
    addresses when converting from a PFN.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 5164069ced42..14a00a1ef52f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -344,7 +344,7 @@ void __init bootmem_init(void)
 	 */
 	arm_bootmem_free(min, max_low, max_high);
 
-	high_memory = __va((max_low << PAGE_SHIFT) - 1) + 1;
+	high_memory = __va(((phys_addr_t)max_low << PAGE_SHIFT) - 1) + 1;
 
 	/*
 	 * This doesn't seem to be used by the Linux memory manager any
@@ -392,8 +392,8 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * Convert to physical addresses, and
 	 * round start upwards and end downwards.
 	 */
-	pg = PAGE_ALIGN(__pa(start_pg));
-	pgend = __pa(end_pg) & PAGE_MASK;
+	pg = (unsigned long)PAGE_ALIGN(__pa(start_pg));
+	pgend = (unsigned long)__pa(end_pg) & PAGE_MASK;
 
 	/*
 	 * If there are free pages between these,

commit b0a2679d27408d97ce31e5f800b44227d3388b84
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sun Jan 30 11:21:05 2011 +0000

    ARM: initrd: disable initrd if passed address overlaps reserved region
    
    Disable the initrd if the passed address already overlaps the reserved
    region.  This avoids oopses on Netwinders when NeTTrom tells the kernel
    that an initrd is located at mem+4MB, but this overlaps the BSS,
    resulting in the kernels in-use BSS being freed.
    
    This should be applied to v2.6.37-stable.
    
    Cc: <stable@kernel.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 5164069ced42..cddd684364da 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -297,6 +297,12 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 	memblock_reserve(__pa(_stext), _end - _stext);
 #endif
 #ifdef CONFIG_BLK_DEV_INITRD
+	if (phys_initrd_size &&
+	    memblock_is_region_reserved(phys_initrd_start, phys_initrd_size)) {
+		pr_err("INITRD: 0x%08lx+0x%08lx overlaps in-use memory region - disabling initrd\n",
+		       phys_initrd_start, phys_initrd_size);
+		phys_initrd_start = phys_initrd_size = 0;
+	}
 	if (phys_initrd_size) {
 		memblock_reserve(phys_initrd_start, phys_initrd_size);
 

commit f25b4b4c89ff118df72421dd2cb080a6380896ac
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:49:33 2010 +0100

    ARM: memblock: move meminfo into find_limits directly
    
    bootmem_init() no longer makes several uses of the membank
    information, so move this into the one remaining called function
    which does use it.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 5422821d372f..5164069ced42 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -122,9 +122,10 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
-static void __init find_limits(struct meminfo *mi,
-	unsigned long *min, unsigned long *max_low, unsigned long *max_high)
+static void __init find_limits(unsigned long *min, unsigned long *max_low,
+	unsigned long *max_high)
 {
+	struct meminfo *mi = &meminfo;
 	int i;
 
 	*min = -1UL;
@@ -317,12 +318,11 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 
 void __init bootmem_init(void)
 {
-	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
 
 	max_low = max_high = 0;
 
-	find_limits(mi, &min, &max_low, &max_high);
+	find_limits(&min, &max_low, &max_high);
 
 	arm_bootmem_init(min, max_low);
 

commit df4f14c7b22e43e67c0e4e3b005ff897a0a72f4d
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:45:49 2010 +0100

    ARM: memblock: convert free_highpages() to use memblock
    
    Free the high pages using the memblock memory lists - and more
    importantly, exclude any memblock allocations in highmem from the
    free'd memory.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1b4e0abf113a..5422821d372f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -439,13 +439,47 @@ static void __init free_unused_memmap(struct meminfo *mi)
 static void __init free_highpages(void)
 {
 #ifdef CONFIG_HIGHMEM
-	int i;
+	unsigned long max_low = max_low_pfn + PHYS_PFN_OFFSET;
+	struct memblock_region *mem, *res;
 
 	/* set highmem page free */
-	for_each_bank (i, &meminfo) {
-		unsigned long start = bank_pfn_start(&meminfo.bank[i]);
-		unsigned long end = bank_pfn_end(&meminfo.bank[i]);
-		if (start >= max_low_pfn + PHYS_PFN_OFFSET)
+	for_each_memblock(memory, mem) {
+		unsigned long start = memblock_region_memory_base_pfn(mem);
+		unsigned long end = memblock_region_memory_end_pfn(mem);
+
+		/* Ignore complete lowmem entries */
+		if (end <= max_low)
+			continue;
+
+		/* Truncate partial highmem entries */
+		if (start < max_low)
+			start = max_low;
+
+		/* Find and exclude any reserved regions */
+		for_each_memblock(reserved, res) {
+			unsigned long res_start, res_end;
+
+			res_start = memblock_region_reserved_base_pfn(res);
+			res_end = memblock_region_reserved_end_pfn(res);
+
+			if (res_end < start)
+				continue;
+			if (res_start < start)
+				res_start = start;
+			if (res_start > end)
+				res_start = end;
+			if (res_end > end)
+				res_end = end;
+			if (res_start != start)
+				totalhigh_pages += free_area(start, res_start,
+							     NULL);
+			start = res_end;
+			if (start == end)
+				break;
+		}
+
+		/* And now free anything which remains */
+		if (start < end)
 			totalhigh_pages += free_area(start, end, NULL);
 	}
 	totalram_pages += totalhigh_pages;

commit d0e775afb94d9b61ba6c63299169ef7a87b68189
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:37:06 2010 +0100

    ARM: move freeing of highmem pages out of mem_init()
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 58b90ad4949f..1b4e0abf113a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -436,6 +436,22 @@ static void __init free_unused_memmap(struct meminfo *mi)
 	}
 }
 
+static void __init free_highpages(void)
+{
+#ifdef CONFIG_HIGHMEM
+	int i;
+
+	/* set highmem page free */
+	for_each_bank (i, &meminfo) {
+		unsigned long start = bank_pfn_start(&meminfo.bank[i]);
+		unsigned long end = bank_pfn_end(&meminfo.bank[i]);
+		if (start >= max_low_pfn + PHYS_PFN_OFFSET)
+			totalhigh_pages += free_area(start, end, NULL);
+	}
+	totalram_pages += totalhigh_pages;
+#endif
+}
+
 /*
  * mem_init() marks the free areas in the mem_map and tells us how much
  * memory is free.  This is done after various parts of the system have
@@ -465,16 +481,7 @@ void __init mem_init(void)
 				    __phys_to_pfn(__pa(swapper_pg_dir)), NULL);
 #endif
 
-#ifdef CONFIG_HIGHMEM
-	/* set highmem page free */
-	for_each_bank (i, &meminfo) {
-		unsigned long start = bank_pfn_start(&meminfo.bank[i]);
-		unsigned long end = bank_pfn_end(&meminfo.bank[i]);
-		if (start >= max_low_pfn + PHYS_PFN_OFFSET)
-			totalhigh_pages += free_area(start, end, NULL);
-	}
-	totalram_pages += totalhigh_pages;
-#endif
+	free_highpages();
 
 	reserved_pages = free_pages = 0;
 

commit 47ea3c15498154f634c304e08dee284efdd7dceb
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:35:29 2010 +0100

    ARM: memblock: convert memory detail printing to use memblock
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8e1edbc6116f..58b90ad4949f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -444,6 +444,7 @@ static void __init free_unused_memmap(struct meminfo *mi)
 void __init mem_init(void)
 {
 	unsigned long reserved_pages, free_pages;
+	struct memblock_region *reg;
 	int i;
 #ifdef CONFIG_HAVE_TCM
 	/* These pointers are filled in on TCM detection */
@@ -503,9 +504,11 @@ void __init mem_init(void)
 	 */
 	printk(KERN_INFO "Memory:");
 	num_physpages = 0;
-	for (i = 0; i < meminfo.nr_banks; i++) {
-		num_physpages += bank_pfn_size(&meminfo.bank[i]);
-		printk(" %ldMB", bank_phys_size(&meminfo.bank[i]) >> 20);
+	for_each_memblock(memory, reg) {
+		unsigned long pages = memblock_region_memory_end_pfn(reg) -
+			memblock_region_memory_base_pfn(reg);
+		num_physpages += pages;
+		printk(" %ldMB", pages >> (20 - PAGE_SHIFT));
 	}
 	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
 

commit a801d2764033063b313d0c55704de8fb36e1efd1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:27:44 2010 +0100

    ARM: memblock: use memblock to free memory into arm_bootmem_init()
    
    Switch arm_bootmem_init() to use memblock instead of membank to
    free memory into bootmem.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index f68c93bb1fde..8e1edbc6116f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -148,14 +148,13 @@ static void __init find_limits(struct meminfo *mi,
 	}
 }
 
-static void __init arm_bootmem_init(struct meminfo *mi,
-	unsigned long start_pfn, unsigned long end_pfn)
+static void __init arm_bootmem_init(unsigned long start_pfn,
+	unsigned long end_pfn)
 {
 	struct memblock_region *reg;
 	unsigned int boot_pages;
 	phys_addr_t bitmap;
 	pg_data_t *pgdat;
-	int i;
 
 	/*
 	 * Allocate the bootmem bitmap page.  This must be in a region
@@ -173,22 +172,31 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	pgdat = NODE_DATA(0);
 	init_bootmem_node(pgdat, __phys_to_pfn(bitmap), start_pfn, end_pfn);
 
-	for_each_bank(i, mi) {
-		struct membank *bank = &mi->bank[i];
-		if (!bank->highmem)
-			free_bootmem(bank_phys_start(bank), bank_phys_size(bank));
+	/* Free the lowmem regions from memblock into bootmem. */
+	for_each_memblock(memory, reg) {
+		unsigned long start = memblock_region_memory_base_pfn(reg);
+		unsigned long end = memblock_region_memory_end_pfn(reg);
+
+		if (end >= end_pfn)
+			end = end_pfn;
+		if (start >= end)
+			break;
+
+		free_bootmem(__pfn_to_phys(start), (end - start) << PAGE_SHIFT);
 	}
 
-	/*
-	 * Reserve the memblock reserved regions in bootmem.
-	 */
+	/* Reserve the lowmem memblock reserved regions in bootmem. */
 	for_each_memblock(reserved, reg) {
-		phys_addr_t start = memblock_region_reserved_base_pfn(reg);
-		phys_addr_t end = memblock_region_reserved_end_pfn(reg);
-		if (start >= start_pfn && end <= end_pfn)
-			reserve_bootmem_node(pgdat, __pfn_to_phys(start),
-					     (end - start) << PAGE_SHIFT,
-					     BOOTMEM_DEFAULT);
+		unsigned long start = memblock_region_reserved_base_pfn(reg);
+		unsigned long end = memblock_region_reserved_end_pfn(reg);
+
+		if (end >= end_pfn)
+			end = end_pfn;
+		if (start >= end)
+			break;
+
+		reserve_bootmem(__pfn_to_phys(start),
+			        (end - start) << PAGE_SHIFT, BOOTMEM_DEFAULT);
 	}
 }
 
@@ -316,7 +324,7 @@ void __init bootmem_init(void)
 
 	find_limits(mi, &min, &max_low, &max_high);
 
-	arm_bootmem_init(mi, min, max_low);
+	arm_bootmem_init(min, max_low);
 
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),

commit a2c54d2af848fafd53f0314947d0741313205dbc
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 19:17:31 2010 +0100

    ARM: memblock: use memblock when initializing memory allocators
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 759878355a05..f68c93bb1fde 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -192,11 +192,11 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	}
 }
 
-static void __init arm_bootmem_free(struct meminfo *mi, unsigned long min,
-	unsigned long max_low, unsigned long max_high)
+static void __init arm_bootmem_free(unsigned long min, unsigned long max_low,
+	unsigned long max_high)
 {
 	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
-	int i;
+	struct memblock_region *reg;
 
 	/*
 	 * initialise the zones.
@@ -218,13 +218,20 @@ static void __init arm_bootmem_free(struct meminfo *mi, unsigned long min,
 	 *  holes = node_size - sum(bank_sizes)
 	 */
 	memcpy(zhole_size, zone_size, sizeof(zhole_size));
-	for_each_bank(i, mi) {
-		int idx = 0;
+	for_each_memblock(memory, reg) {
+		unsigned long start = memblock_region_memory_base_pfn(reg);
+		unsigned long end = memblock_region_memory_end_pfn(reg);
+
+		if (start < max_low) {
+			unsigned long low_end = min(end, max_low);
+			zhole_size[0] -= low_end - start;
+		}
 #ifdef CONFIG_HIGHMEM
-		if (mi->bank[i].highmem)
-			idx = ZONE_HIGHMEM;
+		if (end > max_low) {
+			unsigned long high_start = max(start, max_low);
+			zhole_size[ZONE_HIGHMEM] -= end - high_start;
+		}
 #endif
-		zhole_size[idx] -= bank_pfn_size(&mi->bank[i]);
 	}
 
 	/*
@@ -327,7 +334,7 @@ void __init bootmem_init(void)
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */
-	arm_bootmem_free(mi, min, max_low, max_high);
+	arm_bootmem_free(min, max_low, max_high);
 
 	high_memory = __va((max_low << PAGE_SHIFT) - 1) + 1;
 

commit 7dc50ec7283391dd7a29a80e2a0fb76731a6a7c7
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Oct 27 18:14:56 2010 +0100

    ARM: ensure membank array is always sorted
    
    This was missing from the noMMU code, so there was the possibility
    of things not working as expected if out of order memory information
    was passed.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7fd9b5eb177f..759878355a05 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -18,6 +18,7 @@
 #include <linux/highmem.h>
 #include <linux/gfp.h>
 #include <linux/memblock.h>
+#include <linux/sort.h>
 
 #include <asm/mach-types.h>
 #include <asm/sections.h>
@@ -256,10 +257,19 @@ static void arm_memory_present(void)
 }
 #endif
 
+static int __init meminfo_cmp(const void *_a, const void *_b)
+{
+	const struct membank *a = _a, *b = _b;
+	long cmp = bank_pfn_start(a) - bank_pfn_start(b);
+	return cmp < 0 ? -1 : cmp > 0 ? 1 : 0;
+}
+
 void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 {
 	int i;
 
+	sort(&meminfo.bank, meminfo.nr_banks, sizeof(meminfo.bank[0]), meminfo_cmp, NULL);
+
 	memblock_init();
 	for (i = 0; i < mi->nr_banks; i++)
 		memblock_add(mi->bank[i].start, mi->bank[i].size);

commit 3044100e58c84e133791c8b60a2f5bef69d732e4
Merge: b5153163ed58 67e87f0a1c5c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 21 18:52:11 2010 -0700

    Merge branch 'core-memblock-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-memblock-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (74 commits)
      x86-64: Only set max_pfn_mapped to 512 MiB if we enter via head_64.S
      xen: Cope with unmapped pages when initializing kernel pagetable
      memblock, bootmem: Round pfn properly for memory and reserved regions
      memblock: Annotate memblock functions with __init_memblock
      memblock: Allow memblock_init to be called early
      memblock/arm: Fix memblock_region_is_memory() typo
      x86, memblock: Remove __memblock_x86_find_in_range_size()
      memblock: Fix wraparound in find_region()
      x86-32, memblock: Make add_highpages honor early reserved ranges
      x86, memblock: Fix crashkernel allocation
      arm, memblock: Fix the sparsemem build
      memblock: Fix section mismatch warnings
      powerpc, memblock: Fix memblock API change fallout
      memblock, microblaze: Fix memblock API change fallout
      x86: Remove old bootmem code
      x86, memblock: Use memblock_memory_size()/memblock_free_memory_size() to get correct dma_reserve
      x86: Remove not used early_res code
      x86, memblock: Replace e820_/_early string with memblock_
      x86: Use memblock to replace early_res
      x86, memblock: Use memblock_debug to control debug message print out
      ...
    
    Fix up trivial conflicts in arch/x86/kernel/setup.c and kernel/Makefile

commit c7fc2de0c83dbd2eaf759c5cd0e2b9cf1eb4df3a
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Tue Oct 12 14:07:09 2010 -0700

    memblock, bootmem: Round pfn properly for memory and reserved regions
    
    We need to round memory regions correctly -- specifically, we need to
    round reserved region in the more expansive direction (lower limit
    down, upper limit up) whereas usable memory regions need to be rounded
    in the more restrictive direction (lower limit up, upper limit down).
    
    This introduces two set of inlines:
    
            memblock_region_memory_base_pfn()
            memblock_region_memory_end_pfn()
            memblock_region_reserved_base_pfn()
            memblock_region_reserved_end_pfn()
    
    Although they are antisymmetric (and therefore are technically
    duplicates) the use of the different inlines explicitly documents the
    programmer's intention.
    
    The lack of proper rounding caused a bug on ARM, which was then found
    to also affect other architectures.
    
    Reported-by: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    LKML-Reference: <4CB4CDFD.4020105@kernel.org>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index d6022d1f51d1..63f441797c96 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -182,8 +182,8 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	 * Reserve the memblock reserved regions in bootmem.
 	 */
 	for_each_memblock(reserved, reg) {
-		phys_addr_t start = memblock_region_base_pfn(reg);
-		phys_addr_t end = memblock_region_end_pfn(reg);
+		phys_addr_t start = memblock_region_reserved_base_pfn(reg);
+		phys_addr_t end = memblock_region_reserved_end_pfn(reg);
 		if (start >= start_pfn && end <= end_pfn)
 			reserve_bootmem_node(pgdat, __pfn_to_phys(start),
 					     (end - start) << PAGE_SHIFT,
@@ -251,8 +251,8 @@ static void arm_memory_present(void)
 	struct memblock_region *reg;
 
 	for_each_memblock(memory, reg)
-		memory_present(0, memblock_region_base_pfn(reg),
-			       memblock_region_end_pfn(reg));
+		memory_present(0, memblock_region_memory_base_pfn(reg),
+			       memblock_region_memory_end_pfn(reg));
 }
 #endif
 

commit 842eab40b6920819fff5caeefdb709f07d3f8e23
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Oct 1 14:12:22 2010 +0100

    ARM: vmlinux.lds: Refer to start of .data using _sdata rather than _data
    
    Use _sdata as the start of the data section, rather than _data.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7185b00650fe..36c4553ffcce 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -277,7 +277,7 @@ void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 
 	/* Register the kernel text, kernel data and initrd with memblock. */
 #ifdef CONFIG_XIP_KERNEL
-	memblock_reserve(__pa(_data), _end - _data);
+	memblock_reserve(__pa(_sdata), _end - _sdata);
 #else
 	memblock_reserve(__pa(_stext), _end - _stext);
 #endif
@@ -545,7 +545,7 @@ void __init mem_init(void)
 
 			MLK_ROUNDUP(__init_begin, __init_end),
 			MLK_ROUNDUP(_text, _etext),
-			MLK_ROUNDUP(_data, _edata));
+			MLK_ROUNDUP(_sdata, _edata));
 
 #undef MLK
 #undef MLM

commit 7c996361ef0d02ef8c1435902c909d14195adcdc
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Thu Sep 16 00:20:36 2010 -0700

    arm, memblock: Fix the sparsemem build
    
    Stephen Rothwell reported this build failure:
    
      arch/arm/mm/init.c: In function 'arm_memory_present':
      arch/arm/mm/init.c:260: warning: ISO C90 forbids mixed declarations and code
    
    Caused by commit 719c1514f2 ("memblock/arm: Use new accessors")
    which forgot a closing brace on a new for_each_memblock() in
    arm_memory_present().
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    LKML-Reference: <4C91C544.5050907@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8504906b147f..d6022d1f51d1 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -249,9 +249,8 @@ static void arm_memory_present(void)
 static void arm_memory_present(void)
 {
 	struct memblock_region *reg;
-	int i;
 
-	for_each_memblock(memory, reg) {
+	for_each_memblock(memory, reg)
 		memory_present(0, memblock_region_base_pfn(reg),
 			       memblock_region_end_pfn(reg));
 }

commit 719c1514f2fef5f01fcfa2bba81b7bb079c7c6a1
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Aug 5 12:55:55 2010 +1000

    memblock/arm: Use new accessors
    
    CC: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e739223e2a54..8504906b147f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -150,6 +150,7 @@ static void __init find_limits(struct meminfo *mi,
 static void __init arm_bootmem_init(struct meminfo *mi,
 	unsigned long start_pfn, unsigned long end_pfn)
 {
+	struct memblock_region *reg;
 	unsigned int boot_pages;
 	phys_addr_t bitmap;
 	pg_data_t *pgdat;
@@ -180,13 +181,13 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	/*
 	 * Reserve the memblock reserved regions in bootmem.
 	 */
-	for (i = 0; i < memblock.reserved.cnt; i++) {
-		phys_addr_t start = memblock_start_pfn(&memblock.reserved, i);
-		if (start >= start_pfn &&
-		    memblock_end_pfn(&memblock.reserved, i) <= end_pfn)
+	for_each_memblock(reserved, reg) {
+		phys_addr_t start = memblock_region_base_pfn(reg);
+		phys_addr_t end = memblock_region_end_pfn(reg);
+		if (start >= start_pfn && end <= end_pfn)
 			reserve_bootmem_node(pgdat, __pfn_to_phys(start),
-				memblock_size_bytes(&memblock.reserved, i),
-				BOOTMEM_DEFAULT);
+					     (end - start) << PAGE_SHIFT,
+					     BOOTMEM_DEFAULT);
 	}
 }
 
@@ -247,10 +248,12 @@ static void arm_memory_present(void)
 #else
 static void arm_memory_present(void)
 {
+	struct memblock_region *reg;
 	int i;
-	for (i = 0; i < memblock.memory.cnt; i++)
-		memory_present(0, memblock_start_pfn(&memblock.memory, i),
-				  memblock_end_pfn(&memblock.memory, i));
+
+	for_each_memblock(memory, reg) {
+		memory_present(0, memblock_region_base_pfn(reg),
+			       memblock_region_end_pfn(reg));
 }
 #endif
 

commit 5e6f6aa1c243fafeb2648cf4ebd5abd99ab2531b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Aug 4 13:23:02 2010 +1000

    memblock/arm: pfn_valid uses memblock_is_memory()
    
    The implementation is pretty much similar. There is a -small- added
    overhead by having another function call and the address shift.
    
    If that becomes a concern, I suppose we could actually have memblock
    itself expose a memblock_pfn_valid() which then ARM can use directly
    with an appropriate #define...
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index d1496e65dc2d..e739223e2a54 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -237,20 +237,7 @@ static void __init arm_bootmem_free(struct meminfo *mi, unsigned long min,
 #ifndef CONFIG_SPARSEMEM
 int pfn_valid(unsigned long pfn)
 {
-	struct memblock_type *mem = &memblock.memory;
-	unsigned int left = 0, right = mem->cnt;
-
-	do {
-		unsigned int mid = (right + left) / 2;
-
-		if (pfn < memblock_start_pfn(mem, mid))
-			right = mid;
-		else if (pfn >= memblock_end_pfn(mem, mid))
-			left = mid + 1;
-		else
-			return 1;
-	} while (left < right);
-	return 0;
+	return memblock_is_memory(pfn << PAGE_SHIFT);
 }
 EXPORT_SYMBOL(pfn_valid);
 

commit e3239ff92a17976ac5d26fa0fe40ef3a9daf2523
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Aug 4 14:06:41 2010 +1000

    memblock: Rename memblock_region to memblock_type and memblock_property to memblock_region
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7185b00650fe..d1496e65dc2d 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -237,7 +237,7 @@ static void __init arm_bootmem_free(struct meminfo *mi, unsigned long min,
 #ifndef CONFIG_SPARSEMEM
 int pfn_valid(unsigned long pfn)
 {
-	struct memblock_region *mem = &memblock.memory;
+	struct memblock_type *mem = &memblock.memory;
 	unsigned int left = 0, right = mem->cnt;
 
 	do {

commit 7b70c4275f28702b76b273c8534c38f8313812e9
Merge: ceb0885d3b01 a20df564d15b
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jul 31 14:20:16 2010 +0100

    Merge branch 'devel-stable' into devel
    
    Conflicts:
            arch/arm/kernel/entry-armv.S
            arch/arm/kernel/setup.c
            arch/arm/mm/init.c

commit ceb0885d3b01bb2e2f18765770e212914f2864be
Merge: b31fc7af78e1 08458ef6eede
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat Jul 31 14:20:02 2010 +0100

    Merge branch 'misc' into devel
    
    Conflicts:
            arch/arm/mm/init.c

commit 1dbd30e9890fd69e50b17edd70ca583546b0fe4e
Author: Linus Walleij <linus.walleij@stericsson.com>
Date:   Mon Jul 12 21:53:28 2010 +0100

    ARM: 6225/1: make TCM allocation static and common for all archs
    
    This changes the TCM handling so that a fixed area is reserved at
    0xfffe0000-0xfffeffff for TCM. This areas is used by XScale but
    XScale does not have TCM so the mechanisms are mutually exclusive.
    
    This change is needed to make TCM detection more dynamic while
    still being able to compile code into it, and is a must for the
    unified ARM goals: the current TCM allocation at different places
    in memory for each machine would be a nightmare if you want to
    compile a single image for more than one machine with TCM so it
    has to be nailed down in one place.
    
    Signed-off-by: Linus Walleij <linus.walleij@stericsson.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 526af48b1271..e00404e6f45b 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -529,6 +529,11 @@ void __init mem_init(void)
 {
 	unsigned long reserved_pages, free_pages;
 	int i, node;
+#ifdef CONFIG_HAVE_TCM
+	/* These pointers are filled in on TCM detection */
+	extern u32 dtcm_end;
+	extern u32 itcm_end;
+#endif
 
 #ifndef CONFIG_DISCONTIGMEM
 	max_mapnr   = pfn_to_page(max_pfn + PHYS_PFN_OFFSET) - mem_map;
@@ -612,12 +617,8 @@ void __init mem_init(void)
 	printk(KERN_NOTICE "Virtual kernel memory layout:\n"
 			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 #ifdef CONFIG_HAVE_TCM
-#ifdef DTCM_OFFSET
 			"    DTCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-#endif
-#ifdef ITCM_OFFSET
 			"    ITCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
-#endif
 #endif
 			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 #ifdef CONFIG_MMU
@@ -636,12 +637,8 @@ void __init mem_init(void)
 			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
 				(PAGE_SIZE)),
 #ifdef CONFIG_HAVE_TCM
-#ifdef DTCM_OFFSET
-			MLK(UL(DTCM_OFFSET), UL(DTCM_END + 1)),
-#endif
-#ifdef ITCM_OFFSET
-			MLK(UL(ITCM_OFFSET), UL(ITCM_END + 1)),
-#endif
+			MLK(DTCM_OFFSET, (unsigned long) dtcm_end),
+			MLK(ITCM_OFFSET, (unsigned long) itcm_end),
 #endif
 			MLK(FIXADDR_START, FIXADDR_TOP),
 #ifdef CONFIG_MMU

commit a9deb137e4eb94d0a4fa0c3535b2c056d9363bef
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jul 1 18:35:07 2010 +0100

    ARM: Remove unnecessary call to find_limits()
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c357bfb464ae..599d121c81e7 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -190,14 +190,12 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	}
 }
 
-static void __init arm_bootmem_free(struct meminfo *mi)
+static void __init arm_bootmem_free(struct meminfo *mi, unsigned long min,
+	unsigned long max_low, unsigned long max_high)
 {
 	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
-	unsigned long min, max_low, max_high;
 	int i;
 
-	find_limits(mi, &min, &max_low, &max_high);
-
 	/*
 	 * initialise the zones.
 	 */
@@ -330,7 +328,7 @@ void __init bootmem_init(void)
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */
-	arm_bootmem_free(mi);
+	arm_bootmem_free(mi, min, max_low, max_high);
 
 	high_memory = __va((max_low << PAGE_SHIFT) - 1) + 1;
 

commit e07b9e08601b400aee7e076e7b31799d3dd48c1e
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jul 1 12:03:29 2010 +0100

    ARM: LMB: convert pfn_valid to use LMB
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a453982fdcef..c357bfb464ae 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -239,16 +239,15 @@ static void __init arm_bootmem_free(struct meminfo *mi)
 #ifndef CONFIG_SPARSEMEM
 int pfn_valid(unsigned long pfn)
 {
-	struct meminfo *mi = &meminfo;
-	unsigned int left = 0, right = mi->nr_banks;
+	struct memblock_region *mem = &memblock.memory;
+	unsigned int left = 0, right = mem->cnt;
 
 	do {
 		unsigned int mid = (right + left) / 2;
-		struct membank *bank = &mi->bank[mid];
 
-		if (pfn < bank_pfn_start(bank))
+		if (pfn < memblock_start_pfn(mem, mid))
 			right = mid;
-		else if (pfn >= bank_pfn_end(bank))
+		else if (pfn >= memblock_end_pfn(mem, mid))
 			left = mid + 1;
 		else
 			return 1;

commit eda2e5dcc914b4d70f665443efc9780e89a5e5c1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Jul 1 12:00:57 2010 +0100

    ARM: LMB: Convert arm_memory_present() to use LMB memory information
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 99d6bc9b89bb..a453982fdcef 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -257,17 +257,16 @@ int pfn_valid(unsigned long pfn)
 }
 EXPORT_SYMBOL(pfn_valid);
 
-static void arm_memory_present(struct meminfo *mi)
+static void arm_memory_present(void)
 {
 }
 #else
-static void arm_memory_present(struct meminfo *mi)
+static void arm_memory_present(void)
 {
 	int i;
-	for_each_bank(i, mi) {
-		struct membank *bank = &mi->bank[i];
-		memory_present(0, bank_pfn_start(bank), bank_pfn_end(bank));
-	}
+	for (i = 0; i < memblock.memory.cnt; i++)
+		memory_present(0, memblock_start_pfn(&memblock.memory, i),
+				  memblock_end_pfn(&memblock.memory, i));
 }
 #endif
 
@@ -320,7 +319,7 @@ void __init bootmem_init(void)
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations
 	 */
-	arm_memory_present(mi);
+	arm_memory_present();
 
 	/*
 	 * sparse_init() needs the bootmem allocator up and running.

commit 8d717a52d1b0959128be5134dd12608e8e4f2115
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat May 22 19:47:18 2010 +0100

    ARM: Convert platform reservations to use LMB rather than bootmem
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4877e06308b7..99d6bc9b89bb 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -271,7 +271,7 @@ static void arm_memory_present(struct meminfo *mi)
 }
 #endif
 
-void __init arm_memblock_init(struct meminfo *mi)
+void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
 {
 	int i;
 
@@ -297,11 +297,15 @@ void __init arm_memblock_init(struct meminfo *mi)
 
 	arm_mm_memblock_reserve();
 
+	/* reserve any platform specific memblock areas */
+	if (mdesc->reserve)
+		mdesc->reserve();
+
 	memblock_analyze();
 	memblock_dump_all();
 }
 
-void __init bootmem_init(struct machine_desc *mdesc)
+void __init bootmem_init(void)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
@@ -312,9 +316,6 @@ void __init bootmem_init(struct machine_desc *mdesc)
 
 	arm_bootmem_init(mi, min, max_low);
 
-	if (mdesc->reserve)
-		mdesc->reserve();
-
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations

commit 2778f62056ada442414392d7ccd41188bb631619
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri Jul 9 16:27:52 2010 +0100

    ARM: initial LMB trial
    
    Acked-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1a227eea64bd..4877e06308b7 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -17,6 +17,7 @@
 #include <linux/initrd.h>
 #include <linux/highmem.h>
 #include <linux/gfp.h>
+#include <linux/memblock.h>
 
 #include <asm/mach-types.h>
 #include <asm/sections.h>
@@ -146,95 +147,21 @@ static void __init find_limits(struct meminfo *mi,
 	}
 }
 
-/*
- * FIXME: We really want to avoid allocating the bootmap bitmap
- * over the top of the initrd.  Hopefully, this is located towards
- * the start of a bank, so if we allocate the bootmap bitmap at
- * the end, we won't clash.
- */
-static unsigned int __init
-find_bootmap_pfn(struct meminfo *mi, unsigned int bootmap_pages)
-{
-	unsigned int start_pfn, i, bootmap_pfn;
-
-	start_pfn   = PAGE_ALIGN(__pa(_end)) >> PAGE_SHIFT;
-	bootmap_pfn = 0;
-
-	for_each_bank(i, mi) {
-		struct membank *bank = &mi->bank[i];
-		unsigned int start, end;
-
-		start = bank_pfn_start(bank);
-		end   = bank_pfn_end(bank);
-
-		if (end < start_pfn)
-			continue;
-
-		if (start < start_pfn)
-			start = start_pfn;
-
-		if (end <= start)
-			continue;
-
-		if (end - start >= bootmap_pages) {
-			bootmap_pfn = start;
-			break;
-		}
-	}
-
-	if (bootmap_pfn == 0)
-		BUG();
-
-	return bootmap_pfn;
-}
-
-static int __init check_initrd(struct meminfo *mi)
-{
-	int initrd = -2;
-#ifdef CONFIG_BLK_DEV_INITRD
-	unsigned long end = phys_initrd_start + phys_initrd_size;
-
-	/*
-	 * Make sure that the initrd is within a valid area of
-	 * memory.
-	 */
-	if (phys_initrd_size) {
-		unsigned int i;
-
-		initrd = -1;
-
-		for (i = 0; i < mi->nr_banks; i++) {
-			struct membank *bank = &mi->bank[i];
-			if (bank_phys_start(bank) <= phys_initrd_start &&
-			    end <= bank_phys_end(bank))
-				initrd = 0;
-		}
-	}
-
-	if (initrd == -1) {
-		printk(KERN_ERR "INITRD: 0x%08lx+0x%08lx extends beyond "
-		       "physical memory - disabling initrd\n",
-		       phys_initrd_start, phys_initrd_size);
-		phys_initrd_start = phys_initrd_size = 0;
-	}
-#endif
-
-	return initrd;
-}
-
 static void __init arm_bootmem_init(struct meminfo *mi,
 	unsigned long start_pfn, unsigned long end_pfn)
 {
-	unsigned long boot_pfn;
 	unsigned int boot_pages;
+	phys_addr_t bitmap;
 	pg_data_t *pgdat;
 	int i;
 
 	/*
-	 * Allocate the bootmem bitmap page.
+	 * Allocate the bootmem bitmap page.  This must be in a region
+	 * of memory which has already been mapped.
 	 */
 	boot_pages = bootmem_bootmap_pages(end_pfn - start_pfn);
-	boot_pfn = find_bootmap_pfn(mi, boot_pages);
+	bitmap = memblock_alloc_base(boot_pages << PAGE_SHIFT, L1_CACHE_BYTES,
+				__pfn_to_phys(end_pfn));
 
 	/*
 	 * Initialise the bootmem allocator, handing the
@@ -242,7 +169,7 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	 */
 	node_set_online(0);
 	pgdat = NODE_DATA(0);
-	init_bootmem_node(pgdat, boot_pfn, start_pfn, end_pfn);
+	init_bootmem_node(pgdat, __phys_to_pfn(bitmap), start_pfn, end_pfn);
 
 	for_each_bank(i, mi) {
 		struct membank *bank = &mi->bank[i];
@@ -251,30 +178,16 @@ static void __init arm_bootmem_init(struct meminfo *mi,
 	}
 
 	/*
-	 * Reserve the bootmem bitmap.
+	 * Reserve the memblock reserved regions in bootmem.
 	 */
-	reserve_bootmem(boot_pfn << PAGE_SHIFT,
-			boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
-}
-
-static void __init bootmem_reserve_initrd(void)
-{
-#ifdef CONFIG_BLK_DEV_INITRD
-	int res;
-
-	res = reserve_bootmem(phys_initrd_start,
-			      phys_initrd_size, BOOTMEM_EXCLUSIVE);
-
-	if (res == 0) {
-		initrd_start = __phys_to_virt(phys_initrd_start);
-		initrd_end = initrd_start + phys_initrd_size;
-	} else {
-		printk(KERN_ERR
-			"INITRD: 0x%08lx+0x%08lx overlaps in-use "
-			"memory region - disabling initrd\n",
-			phys_initrd_start, phys_initrd_size);
+	for (i = 0; i < memblock.reserved.cnt; i++) {
+		phys_addr_t start = memblock_start_pfn(&memblock.reserved, i);
+		if (start >= start_pfn &&
+		    memblock_end_pfn(&memblock.reserved, i) <= end_pfn)
+			reserve_bootmem_node(pgdat, __pfn_to_phys(start),
+				memblock_size_bytes(&memblock.reserved, i),
+				BOOTMEM_DEFAULT);
 	}
-#endif
 }
 
 static void __init arm_bootmem_free(struct meminfo *mi)
@@ -358,16 +271,40 @@ static void arm_memory_present(struct meminfo *mi)
 }
 #endif
 
+void __init arm_memblock_init(struct meminfo *mi)
+{
+	int i;
+
+	memblock_init();
+	for (i = 0; i < mi->nr_banks; i++)
+		memblock_add(mi->bank[i].start, mi->bank[i].size);
+
+	/* Register the kernel text, kernel data and initrd with memblock. */
+#ifdef CONFIG_XIP_KERNEL
+	memblock_reserve(__pa(_data), _end - _data);
+#else
+	memblock_reserve(__pa(_stext), _end - _stext);
+#endif
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (phys_initrd_size) {
+		memblock_reserve(phys_initrd_start, phys_initrd_size);
+
+		/* Now convert initrd to virtual addresses */
+		initrd_start = __phys_to_virt(phys_initrd_start);
+		initrd_end = initrd_start + phys_initrd_size;
+	}
+#endif
+
+	arm_mm_memblock_reserve();
+
+	memblock_analyze();
+	memblock_dump_all();
+}
+
 void __init bootmem_init(struct machine_desc *mdesc)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
-	int initrd;
-
-	/*
-	 * Locate the ramdisk image, if any.
-	 */
-	initrd = check_initrd(mi);
 
 	max_low = max_high = 0;
 
@@ -375,20 +312,9 @@ void __init bootmem_init(struct machine_desc *mdesc)
 
 	arm_bootmem_init(mi, min, max_low);
 
-	/*
-	 * Reserve any special regions.
-	 */
-	reserve_special_regions();
-
 	if (mdesc->reserve)
 		mdesc->reserve();
 
-	/*
-	 * If the initrd is present, reserve its memory.
-	 */
-	if (initrd == 0)
-		bootmem_reserve_initrd();
-
 	/*
 	 * Sparsemem tries to allocate bootmem in memory_present(),
 	 * so must be done after the fixed reservations

commit 07d2a5c721c6aa2bd69812a74c8b3b116abf3e56
Author: Linus Walleij <linus.walleij@stericsson.com>
Date:   Mon Jul 12 21:52:34 2010 +0100

    ARM: 6224/1: print TCM whereabouts in init message
    
    If TCM is in use, we should display it in the virtual memory
    layout along with everything else.
    
    Signed-off-by: Linus Walleij <linus.walleij@stericsson.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index f6a999465323..526af48b1271 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -611,6 +611,14 @@ void __init mem_init(void)
 
 	printk(KERN_NOTICE "Virtual kernel memory layout:\n"
 			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+#ifdef CONFIG_HAVE_TCM
+#ifdef DTCM_OFFSET
+			"    DTCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+#endif
+#ifdef ITCM_OFFSET
+			"    ITCM    : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+#endif
+#endif
 			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 #ifdef CONFIG_MMU
 			"    DMA     : 0x%08lx - 0x%08lx   (%4ld MB)\n"
@@ -627,6 +635,14 @@ void __init mem_init(void)
 
 			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
 				(PAGE_SIZE)),
+#ifdef CONFIG_HAVE_TCM
+#ifdef DTCM_OFFSET
+			MLK(UL(DTCM_OFFSET), UL(DTCM_END + 1)),
+#endif
+#ifdef ITCM_OFFSET
+			MLK(UL(ITCM_OFFSET), UL(ITCM_END + 1)),
+#endif
+#endif
 			MLK(FIXADDR_START, FIXADDR_TOP),
 #ifdef CONFIG_MMU
 			MLM(CONSISTENT_BASE, CONSISTENT_END),

commit 98c672cf1fa2a56f6f43e3f48b1208b83845582c
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat May 22 18:18:57 2010 +0100

    ARM: Move platform memory reservations out of generic code
    
    Move the platform specific bootmem memory reservations out of
    arch/arm/mm/mmu.c into their respective platform files.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4d2720888c50..1a227eea64bd 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -358,7 +358,7 @@ static void arm_memory_present(struct meminfo *mi)
 }
 #endif
 
-void __init bootmem_init(void)
+void __init bootmem_init(struct machine_desc *mdesc)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
@@ -380,6 +380,9 @@ void __init bootmem_init(void)
 	 */
 	reserve_special_regions();
 
+	if (mdesc->reserve)
+		mdesc->reserve();
+
 	/*
 	 * If the initrd is present, reserve its memory.
 	 */

commit b65b4781fbd5846a82cdac0c32818af1a7452d1f
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Sat May 22 20:58:51 2010 +0100

    ARM: Remove 'node' argument form arch_adjust_zones()
    
    Since we no longer support discontigmem, node is always zero, so
    remove this argument.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 4011e524cb1d..4d2720888c50 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -318,7 +318,7 @@ static void __init arm_bootmem_free(struct meminfo *mi)
 	 * Adjust the sizes according to any special requirements for
 	 * this machine type.
 	 */
-	arch_adjust_zones(0, zone_size, zhole_size);
+	arch_adjust_zones(zone_size, zhole_size);
 
 	free_area_init_node(0, zone_size, min, zhole_size);
 }

commit be370302742ff9948f2a42b15cb2ba174d97b930
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Fri May 7 17:40:33 2010 +0100

    ARM: Remove DISCONTIGMEM support
    
    Everything should now be using sparsemem rather than discontigmem, so
    remove the code supporting discontigmem from ARM.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index f6a999465323..4011e524cb1d 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -79,38 +79,37 @@ struct meminfo meminfo;
 void show_mem(void)
 {
 	int free = 0, total = 0, reserved = 0;
-	int shared = 0, cached = 0, slab = 0, node, i;
+	int shared = 0, cached = 0, slab = 0, i;
 	struct meminfo * mi = &meminfo;
 
 	printk("Mem-info:\n");
 	show_free_areas();
-	for_each_online_node(node) {
-		for_each_nodebank (i,mi,node) {
-			struct membank *bank = &mi->bank[i];
-			unsigned int pfn1, pfn2;
-			struct page *page, *end;
-
-			pfn1 = bank_pfn_start(bank);
-			pfn2 = bank_pfn_end(bank);
-
-			page = pfn_to_page(pfn1);
-			end  = pfn_to_page(pfn2 - 1) + 1;
-
-			do {
-				total++;
-				if (PageReserved(page))
-					reserved++;
-				else if (PageSwapCache(page))
-					cached++;
-				else if (PageSlab(page))
-					slab++;
-				else if (!page_count(page))
-					free++;
-				else
-					shared += page_count(page) - 1;
-				page++;
-			} while (page < end);
-		}
+
+	for_each_bank (i, mi) {
+		struct membank *bank = &mi->bank[i];
+		unsigned int pfn1, pfn2;
+		struct page *page, *end;
+
+		pfn1 = bank_pfn_start(bank);
+		pfn2 = bank_pfn_end(bank);
+
+		page = pfn_to_page(pfn1);
+		end  = pfn_to_page(pfn2 - 1) + 1;
+
+		do {
+			total++;
+			if (PageReserved(page))
+				reserved++;
+			else if (PageSwapCache(page))
+				cached++;
+			else if (PageSlab(page))
+				slab++;
+			else if (!page_count(page))
+				free++;
+			else
+				shared += page_count(page) - 1;
+			page++;
+		} while (page < end);
 	}
 
 	printk("%d pages of RAM\n", total);
@@ -121,7 +120,7 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
-static void __init find_node_limits(int node, struct meminfo *mi,
+static void __init find_limits(struct meminfo *mi,
 	unsigned long *min, unsigned long *max_low, unsigned long *max_high)
 {
 	int i;
@@ -129,7 +128,7 @@ static void __init find_node_limits(int node, struct meminfo *mi,
 	*min = -1UL;
 	*max_low = *max_high = 0;
 
-	for_each_nodebank(i, mi, node) {
+	for_each_bank (i, mi) {
 		struct membank *bank = &mi->bank[i];
 		unsigned long start, end;
 
@@ -154,14 +153,14 @@ static void __init find_node_limits(int node, struct meminfo *mi,
  * the end, we won't clash.
  */
 static unsigned int __init
-find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
+find_bootmap_pfn(struct meminfo *mi, unsigned int bootmap_pages)
 {
 	unsigned int start_pfn, i, bootmap_pfn;
 
 	start_pfn   = PAGE_ALIGN(__pa(_end)) >> PAGE_SHIFT;
 	bootmap_pfn = 0;
 
-	for_each_nodebank(i, mi, node) {
+	for_each_bank(i, mi) {
 		struct membank *bank = &mi->bank[i];
 		unsigned int start, end;
 
@@ -191,7 +190,7 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 
 static int __init check_initrd(struct meminfo *mi)
 {
-	int initrd_node = -2;
+	int initrd = -2;
 #ifdef CONFIG_BLK_DEV_INITRD
 	unsigned long end = phys_initrd_start + phys_initrd_size;
 
@@ -202,17 +201,17 @@ static int __init check_initrd(struct meminfo *mi)
 	if (phys_initrd_size) {
 		unsigned int i;
 
-		initrd_node = -1;
+		initrd = -1;
 
 		for (i = 0; i < mi->nr_banks; i++) {
 			struct membank *bank = &mi->bank[i];
 			if (bank_phys_start(bank) <= phys_initrd_start &&
 			    end <= bank_phys_end(bank))
-				initrd_node = bank->node;
+				initrd = 0;
 		}
 	}
 
-	if (initrd_node == -1) {
+	if (initrd == -1) {
 		printk(KERN_ERR "INITRD: 0x%08lx+0x%08lx extends beyond "
 		       "physical memory - disabling initrd\n",
 		       phys_initrd_start, phys_initrd_size);
@@ -220,10 +219,10 @@ static int __init check_initrd(struct meminfo *mi)
 	}
 #endif
 
-	return initrd_node;
+	return initrd;
 }
 
-static void __init bootmem_init_node(int node, struct meminfo *mi,
+static void __init arm_bootmem_init(struct meminfo *mi,
 	unsigned long start_pfn, unsigned long end_pfn)
 {
 	unsigned long boot_pfn;
@@ -235,37 +234,36 @@ static void __init bootmem_init_node(int node, struct meminfo *mi,
 	 * Allocate the bootmem bitmap page.
 	 */
 	boot_pages = bootmem_bootmap_pages(end_pfn - start_pfn);
-	boot_pfn = find_bootmap_pfn(node, mi, boot_pages);
+	boot_pfn = find_bootmap_pfn(mi, boot_pages);
 
 	/*
-	 * Initialise the bootmem allocator for this node, handing the
+	 * Initialise the bootmem allocator, handing the
 	 * memory banks over to bootmem.
 	 */
-	node_set_online(node);
-	pgdat = NODE_DATA(node);
+	node_set_online(0);
+	pgdat = NODE_DATA(0);
 	init_bootmem_node(pgdat, boot_pfn, start_pfn, end_pfn);
 
-	for_each_nodebank(i, mi, node) {
+	for_each_bank(i, mi) {
 		struct membank *bank = &mi->bank[i];
 		if (!bank->highmem)
-			free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
+			free_bootmem(bank_phys_start(bank), bank_phys_size(bank));
 	}
 
 	/*
-	 * Reserve the bootmem bitmap for this node.
+	 * Reserve the bootmem bitmap.
 	 */
-	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
-			     boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
+	reserve_bootmem(boot_pfn << PAGE_SHIFT,
+			boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
 }
 
-static void __init bootmem_reserve_initrd(int node)
+static void __init bootmem_reserve_initrd(void)
 {
 #ifdef CONFIG_BLK_DEV_INITRD
-	pg_data_t *pgdat = NODE_DATA(node);
 	int res;
 
-	res = reserve_bootmem_node(pgdat, phys_initrd_start,
-			     phys_initrd_size, BOOTMEM_EXCLUSIVE);
+	res = reserve_bootmem(phys_initrd_start,
+			      phys_initrd_size, BOOTMEM_EXCLUSIVE);
 
 	if (res == 0) {
 		initrd_start = __phys_to_virt(phys_initrd_start);
@@ -279,23 +277,23 @@ static void __init bootmem_reserve_initrd(int node)
 #endif
 }
 
-static void __init bootmem_free_node(int node, struct meminfo *mi)
+static void __init arm_bootmem_free(struct meminfo *mi)
 {
 	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
 	unsigned long min, max_low, max_high;
 	int i;
 
-	find_node_limits(node, mi, &min, &max_low, &max_high);
+	find_limits(mi, &min, &max_low, &max_high);
 
 	/*
-	 * initialise the zones within this node.
+	 * initialise the zones.
 	 */
 	memset(zone_size, 0, sizeof(zone_size));
 
 	/*
-	 * The size of this node has already been determined.  If we need
-	 * to do anything fancy with the allocation of this memory to the
-	 * zones, now is the time to do it.
+	 * The memory size has already been determined.  If we need
+	 * to do anything fancy with the allocation of this memory
+	 * to the zones, now is the time to do it.
 	 */
 	zone_size[0] = max_low - min;
 #ifdef CONFIG_HIGHMEM
@@ -303,11 +301,11 @@ static void __init bootmem_free_node(int node, struct meminfo *mi)
 #endif
 
 	/*
-	 * For each bank in this node, calculate the size of the holes.
-	 *  holes = node_size - sum(bank_sizes_in_node)
+	 * Calculate the size of the holes.
+	 *  holes = node_size - sum(bank_sizes)
 	 */
 	memcpy(zhole_size, zone_size, sizeof(zhole_size));
-	for_each_nodebank(i, mi, node) {
+	for_each_bank(i, mi) {
 		int idx = 0;
 #ifdef CONFIG_HIGHMEM
 		if (mi->bank[i].highmem)
@@ -320,9 +318,9 @@ static void __init bootmem_free_node(int node, struct meminfo *mi)
 	 * Adjust the sizes according to any special requirements for
 	 * this machine type.
 	 */
-	arch_adjust_zones(node, zone_size, zhole_size);
+	arch_adjust_zones(0, zone_size, zhole_size);
 
-	free_area_init_node(node, zone_size, min, zhole_size);
+	free_area_init_node(0, zone_size, min, zhole_size);
 }
 
 #ifndef CONFIG_SPARSEMEM
@@ -346,16 +344,16 @@ int pfn_valid(unsigned long pfn)
 }
 EXPORT_SYMBOL(pfn_valid);
 
-static void arm_memory_present(struct meminfo *mi, int node)
+static void arm_memory_present(struct meminfo *mi)
 {
 }
 #else
-static void arm_memory_present(struct meminfo *mi, int node)
+static void arm_memory_present(struct meminfo *mi)
 {
 	int i;
-	for_each_nodebank(i, mi, node) {
+	for_each_bank(i, mi) {
 		struct membank *bank = &mi->bank[i];
-		memory_present(node, bank_pfn_start(bank), bank_pfn_end(bank));
+		memory_present(0, bank_pfn_start(bank), bank_pfn_end(bank));
 	}
 }
 #endif
@@ -364,55 +362,35 @@ void __init bootmem_init(void)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
-	int node, initrd_node;
+	int initrd;
 
 	/*
-	 * Locate which node contains the ramdisk image, if any.
+	 * Locate the ramdisk image, if any.
 	 */
-	initrd_node = check_initrd(mi);
+	initrd = check_initrd(mi);
 
 	max_low = max_high = 0;
 
-	/*
-	 * Run through each node initialising the bootmem allocator.
-	 */
-	for_each_node(node) {
-		unsigned long node_low, node_high;
-
-		find_node_limits(node, mi, &min, &node_low, &node_high);
+	find_limits(mi, &min, &max_low, &max_high);
 
-		if (node_low > max_low)
-			max_low = node_low;
-		if (node_high > max_high)
-			max_high = node_high;
+	arm_bootmem_init(mi, min, max_low);
 
-		/*
-		 * If there is no memory in this node, ignore it.
-		 * (We can't have nodes which have no lowmem)
-		 */
-		if (node_low == 0)
-			continue;
-
-		bootmem_init_node(node, mi, min, node_low);
-
-		/*
-		 * Reserve any special node zero regions.
-		 */
-		if (node == 0)
-			reserve_node_zero(NODE_DATA(node));
+	/*
+	 * Reserve any special regions.
+	 */
+	reserve_special_regions();
 
-		/*
-		 * If the initrd is in this node, reserve its memory.
-		 */
-		if (node == initrd_node)
-			bootmem_reserve_initrd(node);
+	/*
+	 * If the initrd is present, reserve its memory.
+	 */
+	if (initrd == 0)
+		bootmem_reserve_initrd();
 
-		/*
-		 * Sparsemem tries to allocate bootmem in memory_present(),
-		 * so must be done after the fixed reservations
-		 */
-		arm_memory_present(mi, node);
-	}
+	/*
+	 * Sparsemem tries to allocate bootmem in memory_present(),
+	 * so must be done after the fixed reservations
+	 */
+	arm_memory_present(mi);
 
 	/*
 	 * sparse_init() needs the bootmem allocator up and running.
@@ -420,12 +398,11 @@ void __init bootmem_init(void)
 	sparse_init();
 
 	/*
-	 * Now free memory in each node - free_area_init_node needs
+	 * Now free the memory - free_area_init_node needs
 	 * the sparse mem_map arrays initialized by sparse_init()
 	 * for memmap_init_zone(), otherwise all PFNs are invalid.
 	 */
-	for_each_node(node)
-		bootmem_free_node(node, mi);
+	arm_bootmem_free(mi);
 
 	high_memory = __va((max_low << PAGE_SHIFT) - 1) + 1;
 
@@ -460,7 +437,7 @@ static inline int free_area(unsigned long pfn, unsigned long end, char *s)
 }
 
 static inline void
-free_memmap(int node, unsigned long start_pfn, unsigned long end_pfn)
+free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 {
 	struct page *start_pg, *end_pg;
 	unsigned long pg, pgend;
@@ -483,13 +460,13 @@ free_memmap(int node, unsigned long start_pfn, unsigned long end_pfn)
 	 * free the section of the memmap array.
 	 */
 	if (pg < pgend)
-		free_bootmem_node(NODE_DATA(node), pg, pgend - pg);
+		free_bootmem(pg, pgend - pg);
 }
 
 /*
  * The mem_map array can get very big.  Free the unused area of the memory map.
  */
-static void __init free_unused_memmap_node(int node, struct meminfo *mi)
+static void __init free_unused_memmap(struct meminfo *mi)
 {
 	unsigned long bank_start, prev_bank_end = 0;
 	unsigned int i;
@@ -499,7 +476,7 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 	 * may not be the case, especially if the user has provided the
 	 * information on the command line.
 	 */
-	for_each_nodebank(i, mi, node) {
+	for_each_bank(i, mi) {
 		struct membank *bank = &mi->bank[i];
 
 		bank_start = bank_pfn_start(bank);
@@ -514,7 +491,7 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 		 * between the current bank and the previous, free it.
 		 */
 		if (prev_bank_end && prev_bank_end != bank_start)
-			free_memmap(node, prev_bank_end, bank_start);
+			free_memmap(prev_bank_end, bank_start);
 
 		prev_bank_end = bank_pfn_end(bank);
 	}
@@ -528,21 +505,14 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 void __init mem_init(void)
 {
 	unsigned long reserved_pages, free_pages;
-	int i, node;
+	int i;
 
-#ifndef CONFIG_DISCONTIGMEM
 	max_mapnr   = pfn_to_page(max_pfn + PHYS_PFN_OFFSET) - mem_map;
-#endif
 
 	/* this will put all unused low memory onto the freelists */
-	for_each_online_node(node) {
-		pg_data_t *pgdat = NODE_DATA(node);
-
-		free_unused_memmap_node(node, &meminfo);
+	free_unused_memmap(&meminfo);
 
-		if (pgdat->node_spanned_pages != 0)
-			totalram_pages += free_all_bootmem_node(pgdat);
-	}
+	totalram_pages += free_all_bootmem();
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */
@@ -552,39 +522,35 @@ void __init mem_init(void)
 
 #ifdef CONFIG_HIGHMEM
 	/* set highmem page free */
-	for_each_online_node(node) {
-		for_each_nodebank (i, &meminfo, node) {
-			unsigned long start = bank_pfn_start(&meminfo.bank[i]);
-			unsigned long end = bank_pfn_end(&meminfo.bank[i]);
-			if (start >= max_low_pfn + PHYS_PFN_OFFSET)
-				totalhigh_pages += free_area(start, end, NULL);
-		}
+	for_each_bank (i, &meminfo) {
+		unsigned long start = bank_pfn_start(&meminfo.bank[i]);
+		unsigned long end = bank_pfn_end(&meminfo.bank[i]);
+		if (start >= max_low_pfn + PHYS_PFN_OFFSET)
+			totalhigh_pages += free_area(start, end, NULL);
 	}
 	totalram_pages += totalhigh_pages;
 #endif
 
 	reserved_pages = free_pages = 0;
 
-	for_each_online_node(node) {
-		for_each_nodebank(i, &meminfo, node) {
-			struct membank *bank = &meminfo.bank[i];
-			unsigned int pfn1, pfn2;
-			struct page *page, *end;
-
-			pfn1 = bank_pfn_start(bank);
-			pfn2 = bank_pfn_end(bank);
-
-			page = pfn_to_page(pfn1);
-			end  = pfn_to_page(pfn2 - 1) + 1;
-
-			do {
-				if (PageReserved(page))
-					reserved_pages++;
-				else if (!page_count(page))
-					free_pages++;
-				page++;
-			} while (page < end);
-		}
+	for_each_bank(i, &meminfo) {
+		struct membank *bank = &meminfo.bank[i];
+		unsigned int pfn1, pfn2;
+		struct page *page, *end;
+
+		pfn1 = bank_pfn_start(bank);
+		pfn2 = bank_pfn_end(bank);
+
+		page = pfn_to_page(pfn1);
+		end  = pfn_to_page(pfn2 - 1) + 1;
+
+		do {
+			if (PageReserved(page))
+				reserved_pages++;
+			else if (!page_count(page))
+				free_pages++;
+			page++;
+		} while (page < end);
 	}
 
 	/*

commit 3260e5293727f16ffdce9a6a6203fd9a6b149e58
Author: Michael Bohan <mbohan@codeaurora.org>
Date:   Mon Jun 14 13:06:56 2010 -0700

    arm: mm: Don't free prohibited memmap entries
    
    The VM subsystem assumes that there are valid memmap entries to
    the bank end aligned to MAX_ORDER_NR_PAGES. It will try and read
    these page structs, and so we cannot free any memmap entries that
    it may inspect.
    
    Signed-off-by: Michael Bohan <mbohan@codeaurora.org>
    Signed-off-by: Daniel Walker <dwalker@codeaurora.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index f6a999465323..e18c7cedb482 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -495,28 +495,27 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 	unsigned int i;
 
 	/*
-	 * [FIXME] This relies on each bank being in address order.  This
-	 * may not be the case, especially if the user has provided the
-	 * information on the command line.
+	 * This relies on each bank being in address order.
+	 * The banks are sorted previously in bootmem_init().
 	 */
 	for_each_nodebank(i, mi, node) {
 		struct membank *bank = &mi->bank[i];
 
 		bank_start = bank_pfn_start(bank);
-		if (bank_start < prev_bank_end) {
-			printk(KERN_ERR "MEM: unordered memory banks.  "
-				"Not freeing memmap.\n");
-			break;
-		}
 
 		/*
 		 * If we had a previous bank, and there is a space
 		 * between the current bank and the previous, free it.
 		 */
-		if (prev_bank_end && prev_bank_end != bank_start)
+		if (prev_bank_end && prev_bank_end < bank_start)
 			free_memmap(node, prev_bank_end, bank_start);
 
-		prev_bank_end = bank_pfn_end(bank);
+		/*
+		 * Align up here since the VM subsystem insists that the
+		 * memmap entries are valid from the bank end aligned to
+		 * MAX_ORDER_NR_PAGES.
+		 */
+		prev_bank_end = ALIGN(bank_pfn_end(bank), MAX_ORDER_NR_PAGES);
 	}
 }
 

commit ea208f646c8fb91c39c852e952fc911e1ad045ab
Author: Linus Walleij <linus.walleij@stericsson.com>
Date:   Wed May 26 07:37:57 2010 +0100

    ARM: 6144/1: TCM memory bug freeing bug
    
    This fixes a bug in mm/init.c when freeing the TCM compile memory,
    this was being referred to as a char * which is incorrect: this
    will dereference the pointer and feed in the value at the location
    instead of the address to it. Change it to a plain char and use
    &(char) to reference it.
    
    Signed-off-by: Linus Walleij <linus.walleij@stericsson.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1ba6cf5a2c02..f6a999465323 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -678,10 +678,10 @@ void __init mem_init(void)
 void free_initmem(void)
 {
 #ifdef CONFIG_HAVE_TCM
-	extern char *__tcm_start, *__tcm_end;
+	extern char __tcm_start, __tcm_end;
 
-	totalram_pages += free_area(__phys_to_pfn(__pa(__tcm_start)),
-				    __phys_to_pfn(__pa(__tcm_end)),
+	totalram_pages += free_area(__phys_to_pfn(__pa(&__tcm_start)),
+				    __phys_to_pfn(__pa(&__tcm_end)),
 				    "TCM link");
 #endif
 

commit ac1d426e825ab5778995f2f6f053ca2e6b45c622
Merge: fda0e18c8a7a a3685f00652a
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon May 17 17:24:04 2010 +0100

    Merge branch 'devel-stable' into devel
    
    Conflicts:
            arch/arm/Kconfig
            arch/arm/include/asm/system.h
            arch/arm/mm/Kconfig

commit a2227120eead4ea7d2ea04d8ce0947f1dd23dedf
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Mar 25 18:56:05 2010 +0000

    ARM: Move memory mapping into mmu.c
    
    Acked-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8bbb9a972e71..105d1d4f420b 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -225,20 +225,6 @@ static int __init check_initrd(struct meminfo *mi)
 	return initrd_node;
 }
 
-static inline void map_memory_bank(struct membank *bank)
-{
-#ifdef CONFIG_MMU
-	struct map_desc map;
-
-	map.pfn = bank_pfn_start(bank);
-	map.virtual = __phys_to_virt(bank_phys_start(bank));
-	map.length = bank_phys_size(bank);
-	map.type = MT_MEMORY;
-
-	create_mapping(&map);
-#endif
-}
-
 static void __init bootmem_init_node(int node, struct meminfo *mi,
 	unsigned long start_pfn, unsigned long end_pfn)
 {
@@ -247,16 +233,6 @@ static void __init bootmem_init_node(int node, struct meminfo *mi,
 	pg_data_t *pgdat;
 	int i;
 
-	/*
-	 * Map the memory banks for this node.
-	 */
-	for_each_nodebank(i, mi, node) {
-		struct membank *bank = &mi->bank[i];
-
-		if (!bank->highmem)
-			map_memory_bank(bank);
-	}
-
 	/*
 	 * Allocate the bootmem bitmap page.
 	 */

commit ceb683d3bc36f213aeef0c5d79e6fbb1e16bd459
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Mar 25 18:47:20 2010 +0000

    ARM: Ensure meminfo is sorted prior to sanity_check_meminfo
    
    Acked-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7829cb5425f5..8bbb9a972e71 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -15,7 +15,6 @@
 #include <linux/mman.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
-#include <linux/sort.h>
 #include <linux/highmem.h>
 
 #include <asm/mach-types.h>
@@ -387,21 +386,12 @@ static void arm_memory_present(struct meminfo *mi, int node)
 }
 #endif
 
-static int __init meminfo_cmp(const void *_a, const void *_b)
-{
-	const struct membank *a = _a, *b = _b;
-	long cmp = bank_pfn_start(a) - bank_pfn_start(b);
-	return cmp < 0 ? -1 : cmp > 0 ? 1 : 0;
-}
-
 void __init bootmem_init(void)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
 	int node, initrd_node;
 
-	sort(&mi->bank, mi->nr_banks, sizeof(mi->bank[0]), meminfo_cmp, NULL);
-
 	/*
 	 * Locate which node contains the ramdisk image, if any.
 	 */

commit ea056df7965fc46cfff28fd3808bf3ada23d5059
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue May 4 17:27:43 2010 +0100

    ARM: 6093/1: Fix kernel memory printing for sparsemem
    
    The show_mem() and mem_init() function are assuming that the page map is
    contiguous and calculates the start and end page of a bank using (map +
    pfn). This fails with SPARSEMEM where pfn_to_page() must be used.
    
    Tested-by: Will Deacon <Will.Deacon@arm.com>
    Tested-by: Marek Vasut <marek.vasut@gmail.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 83db12a68d56..0ed29bfeba1c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -86,9 +86,6 @@ void show_mem(void)
 	printk("Mem-info:\n");
 	show_free_areas();
 	for_each_online_node(node) {
-		pg_data_t *n = NODE_DATA(node);
-		struct page *map = pgdat_page_nr(n, 0) - n->node_start_pfn;
-
 		for_each_nodebank (i,mi,node) {
 			struct membank *bank = &mi->bank[i];
 			unsigned int pfn1, pfn2;
@@ -97,8 +94,8 @@ void show_mem(void)
 			pfn1 = bank_pfn_start(bank);
 			pfn2 = bank_pfn_end(bank);
 
-			page = map + pfn1;
-			end  = map + pfn2;
+			page = pfn_to_page(pfn1);
+			end  = pfn_to_page(pfn2 - 1) + 1;
 
 			do {
 				total++;
@@ -603,9 +600,6 @@ void __init mem_init(void)
 	reserved_pages = free_pages = 0;
 
 	for_each_online_node(node) {
-		pg_data_t *n = NODE_DATA(node);
-		struct page *map = pgdat_page_nr(n, 0) - n->node_start_pfn;
-
 		for_each_nodebank(i, &meminfo, node) {
 			struct membank *bank = &meminfo.bank[i];
 			unsigned int pfn1, pfn2;
@@ -614,8 +608,8 @@ void __init mem_init(void)
 			pfn1 = bank_pfn_start(bank);
 			pfn2 = bank_pfn_end(bank);
 
-			page = map + pfn1;
-			end  = map + pfn2;
+			page = pfn_to_page(pfn1);
+			end  = pfn_to_page(pfn2 - 1) + 1;
 
 			do {
 				if (PageReserved(page))

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7829cb5425f5..83db12a68d56 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -17,6 +17,7 @@
 #include <linux/initrd.h>
 #include <linux/sort.h>
 #include <linux/highmem.h>
+#include <linux/gfp.h>
 
 #include <asm/mach-types.h>
 #include <asm/sections.h>

commit a183927213df225bd93d21857b6aaafbb95e590d
Author: Fenkart/Bostandzhyan <andreas.fenkart@streamunlimited.com>
Date:   Sun Feb 7 21:47:58 2010 +0100

    ARM: 5929/1: Add checks to detect overlap of memory regions.
    
    Tested-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3a2077239474..7829cb5425f5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -686,6 +686,23 @@ void __init mem_init(void)
 #undef MLM
 #undef MLK_ROUNDUP
 
+	/*
+	 * Check boundaries twice: Some fundamental inconsistencies can
+	 * be detected at build time already.
+	 */
+#ifdef CONFIG_MMU
+	BUILD_BUG_ON(VMALLOC_END			> CONSISTENT_BASE);
+	BUG_ON(VMALLOC_END				> CONSISTENT_BASE);
+
+	BUILD_BUG_ON(TASK_SIZE				> MODULES_VADDR);
+	BUG_ON(TASK_SIZE 				> MODULES_VADDR);
+#endif
+
+#ifdef CONFIG_HIGHMEM
+	BUILD_BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE > PAGE_OFFSET);
+	BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE	> PAGE_OFFSET);
+#endif
+
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
 		extern int sysctl_overcommit_memory;
 		/*

commit c931b4f655a1b86c929384e674eb8c31795f3bd7
Author: Fenkart/Bostandzhyan <andreas.fenkart@streamunlimited.com>
Date:   Sun Feb 7 21:47:17 2010 +0100

    ARM: 5928/1: Change type of VMALLOC_END to unsigned long.
    
    Makes it consistent with VMALLOC_START
    
    Tested-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index bda481e6bc0f..3a2077239474 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -670,7 +670,7 @@ void __init mem_init(void)
 #ifdef CONFIG_MMU
 			MLM(CONSISTENT_BASE, CONSISTENT_END),
 #endif
-			MLM(VMALLOC_START, (unsigned long)VMALLOC_END),
+			MLM(VMALLOC_START, VMALLOC_END),
 			MLM(PAGE_OFFSET, (unsigned long)high_memory),
 #ifdef CONFIG_HIGHMEM
 			MLM(PKMAP_BASE, (PKMAP_BASE) + (LAST_PKMAP) *

commit a7bd08c82e4f74387a39eeebb942712f23967420
Author: Fenkart/Bostandzhyan <andreas.fenkart@streamunlimited.com>
Date:   Sun Feb 7 21:46:33 2010 +0100

    ARM: 5927/1: Make delimiters of DMA area globally visibly.
    
    Adds DMA area to 'virtual memory map' startup message
    
    Tested-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e8e3a74ac5b5..bda481e6bc0f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -651,6 +651,9 @@ void __init mem_init(void)
 	printk(KERN_NOTICE "Virtual kernel memory layout:\n"
 			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
 			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+#ifdef CONFIG_MMU
+			"    DMA     : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+#endif
 			"    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 			"    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n"
 #ifdef CONFIG_HIGHMEM
@@ -664,6 +667,9 @@ void __init mem_init(void)
 			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
 				(PAGE_SIZE)),
 			MLK(FIXADDR_START, FIXADDR_TOP),
+#ifdef CONFIG_MMU
+			MLM(CONSISTENT_BASE, CONSISTENT_END),
+#endif
 			MLM(VMALLOC_START, (unsigned long)VMALLOC_END),
 			MLM(PAGE_OFFSET, (unsigned long)high_memory),
 #ifdef CONFIG_HIGHMEM

commit db9ef1af4879c121c354ad2f653f185f1d50fd89
Author: Fenkart/Bostandzhyan <andreas.fenkart@streamunlimited.com>
Date:   Sun Feb 7 21:45:47 2010 +0100

    ARM: 5926/1: Add "Virtual kernel memory..." printout.
    
    Code based on parisc and x86_32.
    
    Tested-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a340569b991e..e8e3a74ac5b5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -23,6 +23,7 @@
 #include <asm/setup.h>
 #include <asm/sizes.h>
 #include <asm/tlb.h>
+#include <asm/fixmap.h>
 
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
@@ -562,7 +563,7 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
  */
 void __init mem_init(void)
 {
-	unsigned int codesize, datasize, initsize;
+	unsigned long reserved_pages, free_pages;
 	int i, node;
 
 #ifndef CONFIG_DISCONTIGMEM
@@ -598,6 +599,33 @@ void __init mem_init(void)
 	totalram_pages += totalhigh_pages;
 #endif
 
+	reserved_pages = free_pages = 0;
+
+	for_each_online_node(node) {
+		pg_data_t *n = NODE_DATA(node);
+		struct page *map = pgdat_page_nr(n, 0) - n->node_start_pfn;
+
+		for_each_nodebank(i, &meminfo, node) {
+			struct membank *bank = &meminfo.bank[i];
+			unsigned int pfn1, pfn2;
+			struct page *page, *end;
+
+			pfn1 = bank_pfn_start(bank);
+			pfn2 = bank_pfn_end(bank);
+
+			page = map + pfn1;
+			end  = map + pfn2;
+
+			do {
+				if (PageReserved(page))
+					reserved_pages++;
+				else if (!page_count(page))
+					free_pages++;
+				page++;
+			} while (page < end);
+		}
+	}
+
 	/*
 	 * Since our memory may not be contiguous, calculate the
 	 * real number of pages we have in this system
@@ -610,16 +638,48 @@ void __init mem_init(void)
 	}
 	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
 
-	codesize = _etext - _text;
-	datasize = _end - _data;
-	initsize = __init_end - __init_begin;
-
-	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
-		"%dK data, %dK init, %luK highmem)\n",
-		nr_free_pages() << (PAGE_SHIFT-10), codesize >> 10,
-		datasize >> 10, initsize >> 10,
+	printk(KERN_NOTICE "Memory: %luk/%luk available, %luk reserved, %luK highmem\n",
+		nr_free_pages() << (PAGE_SHIFT-10),
+		free_pages << (PAGE_SHIFT-10),
+		reserved_pages << (PAGE_SHIFT-10),
 		totalhigh_pages << (PAGE_SHIFT-10));
 
+#define MLK(b, t) b, t, ((t) - (b)) >> 10
+#define MLM(b, t) b, t, ((t) - (b)) >> 20
+#define MLK_ROUNDUP(b, t) b, t, DIV_ROUND_UP(((t) - (b)), SZ_1K)
+
+	printk(KERN_NOTICE "Virtual kernel memory layout:\n"
+			"    vector  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+			"    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n"
+			"    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+			"    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+#ifdef CONFIG_HIGHMEM
+			"    pkmap   : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+#endif
+			"    modules : 0x%08lx - 0x%08lx   (%4ld MB)\n"
+			"      .init : 0x%p" " - 0x%p" "   (%4d kB)\n"
+			"      .text : 0x%p" " - 0x%p" "   (%4d kB)\n"
+			"      .data : 0x%p" " - 0x%p" "   (%4d kB)\n",
+
+			MLK(UL(CONFIG_VECTORS_BASE), UL(CONFIG_VECTORS_BASE) +
+				(PAGE_SIZE)),
+			MLK(FIXADDR_START, FIXADDR_TOP),
+			MLM(VMALLOC_START, (unsigned long)VMALLOC_END),
+			MLM(PAGE_OFFSET, (unsigned long)high_memory),
+#ifdef CONFIG_HIGHMEM
+			MLM(PKMAP_BASE, (PKMAP_BASE) + (LAST_PKMAP) *
+				(PAGE_SIZE)),
+#endif
+			MLM(MODULES_VADDR, MODULES_END),
+
+			MLK_ROUNDUP(__init_begin, __init_end),
+			MLK_ROUNDUP(_text, _etext),
+			MLK_ROUNDUP(_data, _edata));
+
+#undef MLK
+#undef MLM
+#undef MLK_ROUNDUP
+
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
 		extern int sysctl_overcommit_memory;
 		/*

commit 2b0d8c251b8876d530a6bf671eb5425838fa698a
Author: Jeremy Kerr <jeremy.kerr@canonical.com>
Date:   Mon Jan 11 23:17:34 2010 +0100

    ARM: 5880/1: arm: use generic infrastructure for early params
    
    The ARM setup code includes its own parser for early params, there's
    also one in the generic init code.
    
    This patch removes __early_init (and related code) from
    arch/arm/kernel/setup.c, and changes users to the generic early_init
    macro instead.
    
    The generic macro takes a char * argument, rather than char **, so we
    need to update the parser functions a little.
    
    Signed-off-by: Jeremy Kerr <jeremy.kerr@canonical.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index a04ffbbbe253..a340569b991e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -32,19 +32,21 @@
 static unsigned long phys_initrd_start __initdata = 0;
 static unsigned long phys_initrd_size __initdata = 0;
 
-static void __init early_initrd(char **p)
+static int __init early_initrd(char *p)
 {
 	unsigned long start, size;
+	char *endp;
 
-	start = memparse(*p, p);
-	if (**p == ',') {
-		size = memparse((*p) + 1, p);
+	start = memparse(p, &endp);
+	if (*endp == ',') {
+		size = memparse(endp + 1, NULL);
 
 		phys_initrd_start = start;
 		phys_initrd_size = size;
 	}
+	return 0;
 }
-__early_param("initrd=", early_initrd);
+early_param("initrd", early_initrd);
 
 static int __init parse_tag_initrd(const struct tag *tag)
 {

commit 4b529401c5089cf33f7165607cbc2fde43357bfb
Author: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
Date:   Fri Jan 8 14:42:31 2010 -0800

    mm: make totalhigh_pages unsigned long
    
    Makes it consistent with the extern declaration, used when CONFIG_HIGHMEM
    is set Removes redundant casts in printout messages
    
    Signed-off-by: Andreas Fenkart <andreas.fenkart@streamunlimited.com>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Chen Liqin <liqin.chen@sunplusct.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 52c40d155672..a04ffbbbe253 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -616,7 +616,7 @@ void __init mem_init(void)
 		"%dK data, %dK init, %luK highmem)\n",
 		nr_free_pages() << (PAGE_SHIFT-10), codesize >> 10,
 		datasize >> 10, initsize >> 10,
-		(unsigned long) (totalhigh_pages << (PAGE_SHIFT-10)));
+		totalhigh_pages << (PAGE_SHIFT-10));
 
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
 		extern int sysctl_overcommit_memory;

commit 657e12fd388899502d47f9f6f9d276ec9ced8add
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Oct 29 17:06:17 2009 +0000

    ARM: Fix sparsemem with SPARSEMEM_EXTREME enabled
    
    When SPARSEMEM_EXTREME is enabled, memory_present() wants to use bootmem
    to allocate data structures.  However, we call memory_present() after
    declaring memory to bootmem, but before we've reserved areas.
    
    This leads to sparsemem data structures being overwritten later in the
    kernel's initialization (when slab initializes.)
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 40940d7ce4ff..52c40d155672 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -273,7 +273,6 @@ static void __init bootmem_init_node(int node, struct meminfo *mi,
 		struct membank *bank = &mi->bank[i];
 		if (!bank->highmem)
 			free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
-		memory_present(node, bank_pfn_start(bank), bank_pfn_end(bank));
 	}
 
 	/*
@@ -370,6 +369,19 @@ int pfn_valid(unsigned long pfn)
 	return 0;
 }
 EXPORT_SYMBOL(pfn_valid);
+
+static void arm_memory_present(struct meminfo *mi, int node)
+{
+}
+#else
+static void arm_memory_present(struct meminfo *mi, int node)
+{
+	int i;
+	for_each_nodebank(i, mi, node) {
+		struct membank *bank = &mi->bank[i];
+		memory_present(node, bank_pfn_start(bank), bank_pfn_end(bank));
+	}
+}
 #endif
 
 static int __init meminfo_cmp(const void *_a, const void *_b)
@@ -427,6 +439,12 @@ void __init bootmem_init(void)
 		 */
 		if (node == initrd_node)
 			bootmem_reserve_initrd(node);
+
+		/*
+		 * Sparsemem tries to allocate bootmem in memory_present(),
+		 * so must be done after the fixed reservations
+		 */
+		arm_memory_present(mi, node);
 	}
 
 	/*

commit 3257f43d9296ed7adcc84e48f6ddf5313cf29266
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue Oct 6 17:57:22 2009 +0100

    ARM: 5747/1: Fix the start_pg value in free_memmap()
    
    If sparsemem is enabled, the start_pfn passed to the free_memmap()
    function corresponds to an area of memory not known to the kernel and
    pfn_to_page returns a wrong value. The (start_pfn - 1), however, is
    known to the kernel.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 877c492f8e10..40940d7ce4ff 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -483,7 +483,7 @@ free_memmap(int node, unsigned long start_pfn, unsigned long end_pfn)
 	/*
 	 * Convert start_pfn/end_pfn to a struct page pointer.
 	 */
-	start_pg = pfn_to_page(start_pfn);
+	start_pg = pfn_to_page(start_pfn - 1) + 1;
 	end_pg = pfn_to_page(end_pfn);
 
 	/*

commit baea7b946f00a291b166ccae7fcfed6c01530cc6
Merge: ae19ffbadc1b 94e0fb086fc5
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Thu Sep 24 21:22:33 2009 +0100

    Merge branch 'origin' into for-linus
    
    Conflicts:
            MAINTAINERS

commit cc013a88906bad9d2832d6316de1c7dbc1c2a794
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Mon Sep 21 17:02:36 2009 -0700

    arches: drop superfluous casts in nr_free_pages() callers
    
    Commit 96177299416dbccb73b54e6b344260154a445375 ("Drop free_pages()")
    modified nr_free_pages() to return 'unsigned long' instead of 'unsigned
    int'.  This made the casts to 'unsigned long' in most callers superfluous,
    so remove them.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Reviewed-by: Christoph Lameter <cl@linux-foundation.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Chris Zankel <zankel@tensilica.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ea36186f32c3..f982606d7bf9 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -596,8 +596,8 @@ void __init mem_init(void)
 
 	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
 		"%dK data, %dK init, %luK highmem)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
-		codesize >> 10, datasize >> 10, initsize >> 10,
+		nr_free_pages() << (PAGE_SHIFT-10), codesize >> 10,
+		datasize >> 10, initsize >> 10,
 		(unsigned long) (totalhigh_pages << (PAGE_SHIFT-10)));
 
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {

commit bc581770cfdd8c17ea17d324dc05e2f9c599e7ca
Author: Linus Walleij <linus.walleij@stericsson.com>
Date:   Tue Sep 15 17:30:37 2009 +0100

    ARM: 5580/2: ARM TCM (Tightly-Coupled Memory) support v3
    
    This adds the TCM interface to Linux, when active, it will
    detect and report TCM memories and sizes early in boot if
    present, introduce generic TCM memory handling, provide a
    generic TCM memory pool and select TCM memory for the U300
    platform.
    
    See the Documentation/arm/tcm.txt for documentation.
    
    Signed-off-by: Linus Walleij <linus.walleij@stericsson.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ea36186f32c3..764d5dc9af76 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -613,6 +613,14 @@ void __init mem_init(void)
 
 void free_initmem(void)
 {
+#ifdef CONFIG_HAVE_TCM
+	extern char *__tcm_start, *__tcm_end;
+
+	totalram_pages += free_area(__phys_to_pfn(__pa(__tcm_start)),
+				    __phys_to_pfn(__pa(__tcm_end)),
+				    "TCM link");
+#endif
+
 	if (!machine_is_integrator() && !machine_is_cintegrator())
 		totalram_pages += free_area(__phys_to_pfn(__pa(__init_begin)),
 					    __phys_to_pfn(__pa(__init_end)),

commit b7cfda9fc3d7aa60cffab5367f2a72a4a70060cd
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Sep 7 15:06:42 2009 +0100

    ARM: Fix pfn_valid() for sparse memory
    
    On OMAP platforms, some people want to declare to segment up the memory
    between the kernel and a separate application such that there is a hole
    in the middle of the memory as far as Linux is concerned.  However,
    they want to be able to mmap() the hole.
    
    This currently causes problems, because update_mmu_cache() thinks that
    there are valid struct pages for the "hole".  Fix this by making
    pfn_valid() slightly more expensive, by checking whether the PFN is
    contained within the meminfo array.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Tested-by: Khasim Syed Mohammed <khasim@ti.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 3a7279c1ce5e..ea36186f32c3 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -15,6 +15,7 @@
 #include <linux/mman.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
+#include <linux/sort.h>
 #include <linux/highmem.h>
 
 #include <asm/mach-types.h>
@@ -349,12 +350,43 @@ static void __init bootmem_free_node(int node, struct meminfo *mi)
 	free_area_init_node(node, zone_size, min, zhole_size);
 }
 
+#ifndef CONFIG_SPARSEMEM
+int pfn_valid(unsigned long pfn)
+{
+	struct meminfo *mi = &meminfo;
+	unsigned int left = 0, right = mi->nr_banks;
+
+	do {
+		unsigned int mid = (right + left) / 2;
+		struct membank *bank = &mi->bank[mid];
+
+		if (pfn < bank_pfn_start(bank))
+			right = mid;
+		else if (pfn >= bank_pfn_end(bank))
+			left = mid + 1;
+		else
+			return 1;
+	} while (left < right);
+	return 0;
+}
+EXPORT_SYMBOL(pfn_valid);
+#endif
+
+static int __init meminfo_cmp(const void *_a, const void *_b)
+{
+	const struct membank *a = _a, *b = _b;
+	long cmp = bank_pfn_start(a) - bank_pfn_start(b);
+	return cmp < 0 ? -1 : cmp > 0 ? 1 : 0;
+}
+
 void __init bootmem_init(void)
 {
 	struct meminfo *mi = &meminfo;
 	unsigned long min, max_low, max_high;
 	int node, initrd_node;
 
+	sort(&mi->bank, mi->nr_banks, sizeof(mi->bank[0]), meminfo_cmp, NULL);
+
 	/*
 	 * Locate which node contains the ramdisk image, if any.
 	 */

commit dde5828f56cb2c1aa70365c476e6830482127258
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Aug 15 12:36:00 2009 +0100

    ARM: Fix broken highmem support
    
    Currently, highmem is selectable, and you can request an increased
    vmalloc area.  However, none of this has any effect on the memory
    layout since a patch in the highmem series was accidentally dropped.
    Moreover, even if you did want highmem, all memory would still be
    registered as lowmem, possibly resulting in overflow of the available
    virtual mapping space.
    
    The highmem boundary is determined by the highest allowed beginning
    of the vmalloc area, which depends on its configurable minimum size
    (see commit 60296c71f6c5063e3c1f1d2619ca0b60940162e7 for details on
    this).
    
    We should create mappings and initialize bootmem only for low memory,
    while the zone allocator must still be told about highmem.
    
    Currently, memory nodes which are completely located in high memory
    are not supported.  This is not a huge limitation since systems
    relying on highmem support are unlikely to have discontiguous memory
    with large holes.
    
    [ A similar patch was meant to be merged before commit 5f0fbf9ecaf3
      and be available  in Linux v2.6.30, however some git rebase screw-up
      of mine dropped the first commit of the series, and that goofage
      escaped testing somehow as well. -- Nico ]
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Reviewed-by: Nicolas Pitre <nico@marvell.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8277802ec859..3a7279c1ce5e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -120,6 +120,32 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
+static void __init find_node_limits(int node, struct meminfo *mi,
+	unsigned long *min, unsigned long *max_low, unsigned long *max_high)
+{
+	int i;
+
+	*min = -1UL;
+	*max_low = *max_high = 0;
+
+	for_each_nodebank(i, mi, node) {
+		struct membank *bank = &mi->bank[i];
+		unsigned long start, end;
+
+		start = bank_pfn_start(bank);
+		end = bank_pfn_end(bank);
+
+		if (*min > start)
+			*min = start;
+		if (*max_high < end)
+			*max_high = end;
+		if (bank->highmem)
+			continue;
+		if (*max_low < end)
+			*max_low = end;
+	}
+}
+
 /*
  * FIXME: We really want to avoid allocating the bootmap bitmap
  * over the top of the initrd.  Hopefully, this is located towards
@@ -210,40 +236,24 @@ static inline void map_memory_bank(struct membank *bank)
 #endif
 }
 
-static unsigned long __init bootmem_init_node(int node, struct meminfo *mi)
+static void __init bootmem_init_node(int node, struct meminfo *mi,
+	unsigned long start_pfn, unsigned long end_pfn)
 {
-	unsigned long start_pfn, end_pfn, boot_pfn;
+	unsigned long boot_pfn;
 	unsigned int boot_pages;
 	pg_data_t *pgdat;
 	int i;
 
-	start_pfn = -1UL;
-	end_pfn = 0;
-
 	/*
-	 * Calculate the pfn range, and map the memory banks for this node.
+	 * Map the memory banks for this node.
 	 */
 	for_each_nodebank(i, mi, node) {
 		struct membank *bank = &mi->bank[i];
-		unsigned long start, end;
 
-		start = bank_pfn_start(bank);
-		end = bank_pfn_end(bank);
-
-		if (start_pfn > start)
-			start_pfn = start;
-		if (end_pfn < end)
-			end_pfn = end;
-
-		map_memory_bank(bank);
+		if (!bank->highmem)
+			map_memory_bank(bank);
 	}
 
-	/*
-	 * If there is no memory in this node, ignore it.
-	 */
-	if (end_pfn == 0)
-		return end_pfn;
-
 	/*
 	 * Allocate the bootmem bitmap page.
 	 */
@@ -260,7 +270,8 @@ static unsigned long __init bootmem_init_node(int node, struct meminfo *mi)
 
 	for_each_nodebank(i, mi, node) {
 		struct membank *bank = &mi->bank[i];
-		free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
+		if (!bank->highmem)
+			free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
 		memory_present(node, bank_pfn_start(bank), bank_pfn_end(bank));
 	}
 
@@ -269,8 +280,6 @@ static unsigned long __init bootmem_init_node(int node, struct meminfo *mi)
 	 */
 	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
 			     boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
-
-	return end_pfn;
 }
 
 static void __init bootmem_reserve_initrd(int node)
@@ -297,33 +306,39 @@ static void __init bootmem_reserve_initrd(int node)
 static void __init bootmem_free_node(int node, struct meminfo *mi)
 {
 	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
-	unsigned long start_pfn, end_pfn;
-	pg_data_t *pgdat = NODE_DATA(node);
+	unsigned long min, max_low, max_high;
 	int i;
 
-	start_pfn = pgdat->bdata->node_min_pfn;
-	end_pfn = pgdat->bdata->node_low_pfn;
+	find_node_limits(node, mi, &min, &max_low, &max_high);
 
 	/*
 	 * initialise the zones within this node.
 	 */
 	memset(zone_size, 0, sizeof(zone_size));
-	memset(zhole_size, 0, sizeof(zhole_size));
 
 	/*
 	 * The size of this node has already been determined.  If we need
 	 * to do anything fancy with the allocation of this memory to the
 	 * zones, now is the time to do it.
 	 */
-	zone_size[0] = end_pfn - start_pfn;
+	zone_size[0] = max_low - min;
+#ifdef CONFIG_HIGHMEM
+	zone_size[ZONE_HIGHMEM] = max_high - max_low;
+#endif
 
 	/*
 	 * For each bank in this node, calculate the size of the holes.
 	 *  holes = node_size - sum(bank_sizes_in_node)
 	 */
-	zhole_size[0] = zone_size[0];
-	for_each_nodebank(i, mi, node)
-		zhole_size[0] -= bank_pfn_size(&mi->bank[i]);
+	memcpy(zhole_size, zone_size, sizeof(zhole_size));
+	for_each_nodebank(i, mi, node) {
+		int idx = 0;
+#ifdef CONFIG_HIGHMEM
+		if (mi->bank[i].highmem)
+			idx = ZONE_HIGHMEM;
+#endif
+		zhole_size[idx] -= bank_pfn_size(&mi->bank[i]);
+	}
 
 	/*
 	 * Adjust the sizes according to any special requirements for
@@ -331,13 +346,13 @@ static void __init bootmem_free_node(int node, struct meminfo *mi)
 	 */
 	arch_adjust_zones(node, zone_size, zhole_size);
 
-	free_area_init_node(node, zone_size, start_pfn, zhole_size);
+	free_area_init_node(node, zone_size, min, zhole_size);
 }
 
 void __init bootmem_init(void)
 {
 	struct meminfo *mi = &meminfo;
-	unsigned long memend_pfn = 0;
+	unsigned long min, max_low, max_high;
 	int node, initrd_node;
 
 	/*
@@ -345,11 +360,29 @@ void __init bootmem_init(void)
 	 */
 	initrd_node = check_initrd(mi);
 
+	max_low = max_high = 0;
+
 	/*
 	 * Run through each node initialising the bootmem allocator.
 	 */
 	for_each_node(node) {
-		unsigned long end_pfn = bootmem_init_node(node, mi);
+		unsigned long node_low, node_high;
+
+		find_node_limits(node, mi, &min, &node_low, &node_high);
+
+		if (node_low > max_low)
+			max_low = node_low;
+		if (node_high > max_high)
+			max_high = node_high;
+
+		/*
+		 * If there is no memory in this node, ignore it.
+		 * (We can't have nodes which have no lowmem)
+		 */
+		if (node_low == 0)
+			continue;
+
+		bootmem_init_node(node, mi, min, node_low);
 
 		/*
 		 * Reserve any special node zero regions.
@@ -362,12 +395,6 @@ void __init bootmem_init(void)
 		 */
 		if (node == initrd_node)
 			bootmem_reserve_initrd(node);
-
-		/*
-		 * Remember the highest memory PFN.
-		 */
-		if (end_pfn > memend_pfn)
-			memend_pfn = end_pfn;
 	}
 
 	/*
@@ -383,7 +410,7 @@ void __init bootmem_init(void)
 	for_each_node(node)
 		bootmem_free_node(node, mi);
 
-	high_memory = __va((memend_pfn << PAGE_SHIFT) - 1) + 1;
+	high_memory = __va((max_low << PAGE_SHIFT) - 1) + 1;
 
 	/*
 	 * This doesn't seem to be used by the Linux memory manager any
@@ -393,7 +420,8 @@ void __init bootmem_init(void)
 	 * Note: max_low_pfn and max_pfn reflect the number of _pages_ in
 	 * the system, not the maximum PFN.
 	 */
-	max_pfn = max_low_pfn = memend_pfn - PHYS_PFN_OFFSET;
+	max_low_pfn = max_low - PHYS_PFN_OFFSET;
+	max_pfn = max_high - PHYS_PFN_OFFSET;
 }
 
 static inline int free_area(unsigned long pfn, unsigned long end, char *s)

commit 3835f6cb645bdb9a58aa6e062fe1d5777f1a9748
Author: Nicolas Pitre <nico@cam.org>
Date:   Wed Sep 17 15:21:55 2008 -0400

    [ARM] mem_init(): make highmem pages available for use
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 80fd3b69ae1f..8277802ec859 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -15,6 +15,7 @@
 #include <linux/mman.h>
 #include <linux/nodemask.h>
 #include <linux/initrd.h>
+#include <linux/highmem.h>
 
 #include <asm/mach-types.h>
 #include <asm/sections.h>
@@ -485,7 +486,7 @@ void __init mem_init(void)
 	int i, node;
 
 #ifndef CONFIG_DISCONTIGMEM
-	max_mapnr   = virt_to_page(high_memory) - mem_map;
+	max_mapnr   = pfn_to_page(max_pfn + PHYS_PFN_OFFSET) - mem_map;
 #endif
 
 	/* this will put all unused low memory onto the freelists */
@@ -504,6 +505,19 @@ void __init mem_init(void)
 				    __phys_to_pfn(__pa(swapper_pg_dir)), NULL);
 #endif
 
+#ifdef CONFIG_HIGHMEM
+	/* set highmem page free */
+	for_each_online_node(node) {
+		for_each_nodebank (i, &meminfo, node) {
+			unsigned long start = bank_pfn_start(&meminfo.bank[i]);
+			unsigned long end = bank_pfn_end(&meminfo.bank[i]);
+			if (start >= max_low_pfn + PHYS_PFN_OFFSET)
+				totalhigh_pages += free_area(start, end, NULL);
+		}
+	}
+	totalram_pages += totalhigh_pages;
+#endif
+
 	/*
 	 * Since our memory may not be contiguous, calculate the
 	 * real number of pages we have in this system
@@ -521,9 +535,10 @@ void __init mem_init(void)
 	initsize = __init_end - __init_begin;
 
 	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
-		"%dK data, %dK init)\n",
+		"%dK data, %dK init, %luK highmem)\n",
 		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
-		codesize >> 10, datasize >> 10, initsize >> 10);
+		codesize >> 10, datasize >> 10, initsize >> 10,
+		(unsigned long) (totalhigh_pages << (PAGE_SHIFT-10)));
 
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
 		extern int sysctl_overcommit_memory;

commit 1522ac3ec95ff0230e7aa516f86b674fdf72866c
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Mar 12 17:03:48 2009 +0000

    [ARM] Fix virtual to physical translation macro corner cases
    
    The current use of these macros works well when the conversion is
    entirely linear.  In this case, we can be assured that the following
    holds true:
    
            __va(p + s) - s = __va(p)
    
    However, this is not always the case, especially when there is a
    non-linear conversion (eg, when there is a 3.5GB hole in memory.)
    In this case, if 's' is the size of the region (eg, PAGE_SIZE) and
    'p' is the final page, the above is most definitely not true.
    
    So, we must ensure that __va() and __pa() are only used with valid
    kernel direct mapped RAM addresses.  This patch tweaks the code
    to achieve this.
    
    Tested-by: Charles Moschel <fred99@carolina.rr.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 34df4d9d03a6..80fd3b69ae1f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -382,7 +382,7 @@ void __init bootmem_init(void)
 	for_each_node(node)
 		bootmem_free_node(node, mi);
 
-	high_memory = __va(memend_pfn << PAGE_SHIFT);
+	high_memory = __va((memend_pfn << PAGE_SHIFT) - 1) + 1;
 
 	/*
 	 * This doesn't seem to be used by the Linux memory manager any

commit 37efe6427dd50e889473fb3c7fcec02dbbd098eb
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Dec 1 11:53:07 2008 +0000

    [ARM] use asm/sections.h
    
    Update to use the asm/sections.h header rather than declaring these
    symbols ourselves.  Change __data_start to _data to conform with the
    naming found within asm/sections.h.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ab5c9abd5c34..34df4d9d03a6 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -17,6 +17,7 @@
 #include <linux/initrd.h>
 
 #include <asm/mach-types.h>
+#include <asm/sections.h>
 #include <asm/setup.h>
 #include <asm/sizes.h>
 #include <asm/tlb.h>
@@ -129,7 +130,7 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 {
 	unsigned int start_pfn, i, bootmap_pfn;
 
-	start_pfn   = PAGE_ALIGN(__pa(&_end)) >> PAGE_SHIFT;
+	start_pfn   = PAGE_ALIGN(__pa(_end)) >> PAGE_SHIFT;
 	bootmap_pfn = 0;
 
 	for_each_nodebank(i, mi, node) {
@@ -515,9 +516,9 @@ void __init mem_init(void)
 	}
 	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
 
-	codesize = &_etext - &_text;
-	datasize = &_end - &__data_start;
-	initsize = &__init_end - &__init_begin;
+	codesize = _etext - _text;
+	datasize = _end - _data;
+	initsize = __init_end - __init_begin;
 
 	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
 		"%dK data, %dK init)\n",
@@ -538,8 +539,8 @@ void __init mem_init(void)
 void free_initmem(void)
 {
 	if (!machine_is_integrator() && !machine_is_cintegrator())
-		totalram_pages += free_area(__phys_to_pfn(__pa(&__init_begin)),
-					    __phys_to_pfn(__pa(&__init_end)),
+		totalram_pages += free_area(__phys_to_pfn(__pa(__init_begin)),
+					    __phys_to_pfn(__pa(__init_end)),
 					    "init");
 }
 

commit 6db015e49c03d42247d2a985475b833635406a4f
Author: Nicolas Pitre <nico@cam.org>
Date:   Wed Sep 17 14:50:42 2008 -0400

    [ARM] mem_init() cleanups
    
    Make free_area() arguments pfn based, and return number of freed pages.
    This will simplify highmem initialization later.
    
    Also, codepages, datapages and initpages are actually codesize, datasize
    and initsize.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b43da2479fa0..ab5c9abd5c34 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -394,20 +394,22 @@ void __init bootmem_init(void)
 	max_pfn = max_low_pfn = memend_pfn - PHYS_PFN_OFFSET;
 }
 
-static inline void free_area(unsigned long addr, unsigned long end, char *s)
+static inline int free_area(unsigned long pfn, unsigned long end, char *s)
 {
-	unsigned int size = (end - addr) >> 10;
+	unsigned int pages = 0, size = (end - pfn) << (PAGE_SHIFT - 10);
 
-	for (; addr < end; addr += PAGE_SIZE) {
-		struct page *page = virt_to_page(addr);
+	for (; pfn < end; pfn++) {
+		struct page *page = pfn_to_page(pfn);
 		ClearPageReserved(page);
 		init_page_count(page);
-		free_page(addr);
-		totalram_pages++;
+		__free_page(page);
+		pages++;
 	}
 
 	if (size && s)
 		printk(KERN_INFO "Freeing %s memory: %dK\n", s, size);
+
+	return pages;
 }
 
 static inline void
@@ -478,13 +480,9 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
  */
 void __init mem_init(void)
 {
-	unsigned int codepages, datapages, initpages;
+	unsigned int codesize, datasize, initsize;
 	int i, node;
 
-	codepages = &_etext - &_text;
-	datapages = &_end - &__data_start;
-	initpages = &__init_end - &__init_begin;
-
 #ifndef CONFIG_DISCONTIGMEM
 	max_mapnr   = virt_to_page(high_memory) - mem_map;
 #endif
@@ -501,7 +499,8 @@ void __init mem_init(void)
 
 #ifdef CONFIG_SA1111
 	/* now that our DMA memory is actually so designated, we can free it */
-	free_area(PAGE_OFFSET, (unsigned long)swapper_pg_dir, NULL);
+	totalram_pages += free_area(PHYS_PFN_OFFSET,
+				    __phys_to_pfn(__pa(swapper_pg_dir)), NULL);
 #endif
 
 	/*
@@ -509,18 +508,21 @@ void __init mem_init(void)
 	 * real number of pages we have in this system
 	 */
 	printk(KERN_INFO "Memory:");
-
 	num_physpages = 0;
 	for (i = 0; i < meminfo.nr_banks; i++) {
 		num_physpages += bank_pfn_size(&meminfo.bank[i]);
 		printk(" %ldMB", bank_phys_size(&meminfo.bank[i]) >> 20);
 	}
-
 	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
+
+	codesize = &_etext - &_text;
+	datasize = &_end - &__data_start;
+	initsize = &__init_end - &__init_begin;
+
 	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
 		"%dK data, %dK init)\n",
 		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
-		codepages >> 10, datapages >> 10, initpages >> 10);
+		codesize >> 10, datasize >> 10, initsize >> 10);
 
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
 		extern int sysctl_overcommit_memory;
@@ -535,11 +537,10 @@ void __init mem_init(void)
 
 void free_initmem(void)
 {
-	if (!machine_is_integrator() && !machine_is_cintegrator()) {
-		free_area((unsigned long)(&__init_begin),
-			  (unsigned long)(&__init_end),
-			  "init");
-	}
+	if (!machine_is_integrator() && !machine_is_cintegrator())
+		totalram_pages += free_area(__phys_to_pfn(__pa(&__init_begin)),
+					    __phys_to_pfn(__pa(&__init_end)),
+					    "init");
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -549,7 +550,9 @@ static int keep_initrd;
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
 	if (!keep_initrd)
-		free_area(start, end, "initrd");
+		totalram_pages += free_area(__phys_to_pfn(__pa(start)),
+					    __phys_to_pfn(__pa(end)),
+					    "initrd");
 }
 
 static int __init keepinitrd_setup(char *__unused)

commit 4b5f32cee0cce7b9783ced5cbeabd17aa53c51fb
Author: Nicolas Pitre <nico@cam.org>
Date:   Mon Oct 6 13:24:40 2008 -0400

    [ARM] rationalize memory configuration code some more
    
    Currently there are two instances of struct meminfo: one in
    kernel/setup.c marked __initdata, and another in mm/init.c with
    permanent storage.  Let's keep only the later to directly populate
    the permanent version from arm_add_memory().
    
    Also move common validation tests between the MMU and non-MMU cases
    into arm_add_memory() to remove some duplication.  Protection against
    overflowing the membank array is also moved in there in order to cover
    the kernel cmdline parsing path as well.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 82c4b4217989..b43da2479fa0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -64,10 +64,11 @@ static int __init parse_tag_initrd2(const struct tag *tag)
 __tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
 /*
- * This is used to pass memory configuration data from paging_init
- * to mem_init, and by show_mem() to skip holes in the memory map.
+ * This keeps memory configuration data used by a couple memory
+ * initialization functions, as well as show_mem() for the skipping
+ * of holes in the memory map.  It is populated by arm_add_memory().
  */
-static struct meminfo meminfo = { 0, };
+struct meminfo meminfo;
 
 void show_mem(void)
 {
@@ -331,13 +332,12 @@ static void __init bootmem_free_node(int node, struct meminfo *mi)
 	free_area_init_node(node, zone_size, start_pfn, zhole_size);
 }
 
-void __init bootmem_init(struct meminfo *mi)
+void __init bootmem_init(void)
 {
+	struct meminfo *mi = &meminfo;
 	unsigned long memend_pfn = 0;
 	int node, initrd_node;
 
-	memcpy(&meminfo, mi, sizeof(meminfo));
-
 	/*
 	 * Locate which node contains the ramdisk image, if any.
 	 */

commit b7a69ac303cbfc8d6fa8e91d10e8049244ba6847
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Oct 1 16:58:32 2008 +0100

    [ARM] mm: finish ARM sparsemem support
    
    ... including some comments about the ordering required to bring
    sparsemem up.  You have to repeatedly guess, test, reguess, try
    again and again to work out what the right ordering is.  Many
    hours later...
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9b7f0bf26f57..82c4b4217989 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -79,7 +79,7 @@ void show_mem(void)
 	show_free_areas();
 	for_each_online_node(node) {
 		pg_data_t *n = NODE_DATA(node);
-		struct page *map = n->node_mem_map - n->node_start_pfn;
+		struct page *map = pgdat_page_nr(n, 0) - n->node_start_pfn;
 
 		for_each_nodebank (i,mi,node) {
 			struct membank *bank = &mi->bank[i];
@@ -207,10 +207,8 @@ static inline void map_memory_bank(struct membank *bank)
 #endif
 }
 
-static unsigned long __init
-bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
+static unsigned long __init bootmem_init_node(int node, struct meminfo *mi)
 {
-	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
 	unsigned long start_pfn, end_pfn, boot_pfn;
 	unsigned int boot_pages;
 	pg_data_t *pgdat;
@@ -260,6 +258,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	for_each_nodebank(i, mi, node) {
 		struct membank *bank = &mi->bank[i];
 		free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
+		memory_present(node, bank_pfn_start(bank), bank_pfn_end(bank));
 	}
 
 	/*
@@ -268,31 +267,39 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
 			     boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
 
-	/*
-	 * Reserve any special node zero regions.
-	 */
-	if (node == 0)
-		reserve_node_zero(pgdat);
+	return end_pfn;
+}
 
+static void __init bootmem_reserve_initrd(int node)
+{
 #ifdef CONFIG_BLK_DEV_INITRD
-	/*
-	 * If the initrd is in this node, reserve its memory.
-	 */
-	if (node == initrd_node) {
-		int res = reserve_bootmem_node(pgdat, phys_initrd_start,
-				     phys_initrd_size, BOOTMEM_EXCLUSIVE);
-
-		if (res == 0) {
-			initrd_start = __phys_to_virt(phys_initrd_start);
-			initrd_end = initrd_start + phys_initrd_size;
-		} else {
-			printk(KERN_ERR
-				"INITRD: 0x%08lx+0x%08lx overlaps in-use "
-				"memory region - disabling initrd\n",
-				phys_initrd_start, phys_initrd_size);
-		}
+	pg_data_t *pgdat = NODE_DATA(node);
+	int res;
+
+	res = reserve_bootmem_node(pgdat, phys_initrd_start,
+			     phys_initrd_size, BOOTMEM_EXCLUSIVE);
+
+	if (res == 0) {
+		initrd_start = __phys_to_virt(phys_initrd_start);
+		initrd_end = initrd_start + phys_initrd_size;
+	} else {
+		printk(KERN_ERR
+			"INITRD: 0x%08lx+0x%08lx overlaps in-use "
+			"memory region - disabling initrd\n",
+			phys_initrd_start, phys_initrd_size);
 	}
 #endif
+}
+
+static void __init bootmem_free_node(int node, struct meminfo *mi)
+{
+	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
+	unsigned long start_pfn, end_pfn;
+	pg_data_t *pgdat = NODE_DATA(node);
+	int i;
+
+	start_pfn = pgdat->bdata->node_min_pfn;
+	end_pfn = pgdat->bdata->node_low_pfn;
 
 	/*
 	 * initialise the zones within this node.
@@ -322,8 +329,6 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	arch_adjust_zones(node, zone_size, zhole_size);
 
 	free_area_init_node(node, zone_size, start_pfn, zhole_size);
-
-	return end_pfn;
 }
 
 void __init bootmem_init(struct meminfo *mi)
@@ -342,9 +347,19 @@ void __init bootmem_init(struct meminfo *mi)
 	 * Run through each node initialising the bootmem allocator.
 	 */
 	for_each_node(node) {
-		unsigned long end_pfn;
+		unsigned long end_pfn = bootmem_init_node(node, mi);
 
-		end_pfn = bootmem_init_node(node, initrd_node, mi);
+		/*
+		 * Reserve any special node zero regions.
+		 */
+		if (node == 0)
+			reserve_node_zero(NODE_DATA(node));
+
+		/*
+		 * If the initrd is in this node, reserve its memory.
+		 */
+		if (node == initrd_node)
+			bootmem_reserve_initrd(node);
 
 		/*
 		 * Remember the highest memory PFN.
@@ -353,6 +368,19 @@ void __init bootmem_init(struct meminfo *mi)
 			memend_pfn = end_pfn;
 	}
 
+	/*
+	 * sparse_init() needs the bootmem allocator up and running.
+	 */
+	sparse_init();
+
+	/*
+	 * Now free memory in each node - free_area_init_node needs
+	 * the sparse mem_map arrays initialized by sparse_init()
+	 * for memmap_init_zone(), otherwise all PFNs are invalid.
+	 */
+	for_each_node(node)
+		bootmem_free_node(node, mi);
+
 	high_memory = __va(memend_pfn << PAGE_SHIFT);
 
 	/*

commit d2a38ef9c1585b47462c7be5501228ac57fbd3b1
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Oct 1 16:56:15 2008 +0100

    [ARM] mm: provide helpers for accessing membanks
    
    Provide helpers for getting physical addresses or pfns from the
    meminfo array, and use them.  Move for_each_nodebank() to
    asm/setup.h alongside the meminfo structure definition.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ffff901cf627..9b7f0bf26f57 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -69,10 +69,6 @@ __tagtable(ATAG_INITRD2, parse_tag_initrd2);
  */
 static struct meminfo meminfo = { 0, };
 
-#define for_each_nodebank(iter,mi,no)			\
-	for (iter = 0; iter < mi->nr_banks; iter++)	\
-		if (mi->bank[iter].node == no)
-
 void show_mem(void)
 {
 	int free = 0, total = 0, reserved = 0;
@@ -86,11 +82,12 @@ void show_mem(void)
 		struct page *map = n->node_mem_map - n->node_start_pfn;
 
 		for_each_nodebank (i,mi,node) {
+			struct membank *bank = &mi->bank[i];
 			unsigned int pfn1, pfn2;
 			struct page *page, *end;
 
-			pfn1 = __phys_to_pfn(mi->bank[i].start);
-			pfn2 = __phys_to_pfn(mi->bank[i].size + mi->bank[i].start);
+			pfn1 = bank_pfn_start(bank);
+			pfn2 = bank_pfn_end(bank);
 
 			page = map + pfn1;
 			end  = map + pfn2;
@@ -129,17 +126,17 @@ void show_mem(void)
 static unsigned int __init
 find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 {
-	unsigned int start_pfn, bank, bootmap_pfn;
+	unsigned int start_pfn, i, bootmap_pfn;
 
 	start_pfn   = PAGE_ALIGN(__pa(&_end)) >> PAGE_SHIFT;
 	bootmap_pfn = 0;
 
-	for_each_nodebank(bank, mi, node) {
+	for_each_nodebank(i, mi, node) {
+		struct membank *bank = &mi->bank[i];
 		unsigned int start, end;
 
-		start = mi->bank[bank].start >> PAGE_SHIFT;
-		end   = (mi->bank[bank].size +
-			 mi->bank[bank].start) >> PAGE_SHIFT;
+		start = bank_pfn_start(bank);
+		end   = bank_pfn_end(bank);
 
 		if (end < start_pfn)
 			continue;
@@ -178,13 +175,10 @@ static int __init check_initrd(struct meminfo *mi)
 		initrd_node = -1;
 
 		for (i = 0; i < mi->nr_banks; i++) {
-			unsigned long bank_end;
-
-			bank_end = mi->bank[i].start + mi->bank[i].size;
-
-			if (mi->bank[i].start <= phys_initrd_start &&
-			    end <= bank_end)
-				initrd_node = mi->bank[i].node;
+			struct membank *bank = &mi->bank[i];
+			if (bank_phys_start(bank) <= phys_initrd_start &&
+			    end <= bank_phys_end(bank))
+				initrd_node = bank->node;
 		}
 	}
 
@@ -204,9 +198,9 @@ static inline void map_memory_bank(struct membank *bank)
 #ifdef CONFIG_MMU
 	struct map_desc map;
 
-	map.pfn = __phys_to_pfn(bank->start);
-	map.virtual = __phys_to_virt(bank->start);
-	map.length = bank->size;
+	map.pfn = bank_pfn_start(bank);
+	map.virtual = __phys_to_virt(bank_phys_start(bank));
+	map.length = bank_phys_size(bank);
 	map.type = MT_MEMORY;
 
 	create_mapping(&map);
@@ -232,8 +226,8 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 		struct membank *bank = &mi->bank[i];
 		unsigned long start, end;
 
-		start = bank->start >> PAGE_SHIFT;
-		end = (bank->start + bank->size) >> PAGE_SHIFT;
+		start = bank_pfn_start(bank);
+		end = bank_pfn_end(bank);
 
 		if (start_pfn > start)
 			start_pfn = start;
@@ -263,8 +257,10 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	pgdat = NODE_DATA(node);
 	init_bootmem_node(pgdat, boot_pfn, start_pfn, end_pfn);
 
-	for_each_nodebank(i, mi, node)
-		free_bootmem_node(pgdat, mi->bank[i].start, mi->bank[i].size);
+	for_each_nodebank(i, mi, node) {
+		struct membank *bank = &mi->bank[i];
+		free_bootmem_node(pgdat, bank_phys_start(bank), bank_phys_size(bank));
+	}
 
 	/*
 	 * Reserve the bootmem bitmap for this node.
@@ -317,7 +313,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	 */
 	zhole_size[0] = zone_size[0];
 	for_each_nodebank(i, mi, node)
-		zhole_size[0] -= mi->bank[i].size >> PAGE_SHIFT;
+		zhole_size[0] -= bank_pfn_size(&mi->bank[i]);
 
 	/*
 	 * Adjust the sizes according to any special requirements for
@@ -427,7 +423,9 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 	 * information on the command line.
 	 */
 	for_each_nodebank(i, mi, node) {
-		bank_start = mi->bank[i].start >> PAGE_SHIFT;
+		struct membank *bank = &mi->bank[i];
+
+		bank_start = bank_pfn_start(bank);
 		if (bank_start < prev_bank_end) {
 			printk(KERN_ERR "MEM: unordered memory banks.  "
 				"Not freeing memmap.\n");
@@ -441,8 +439,7 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 		if (prev_bank_end && prev_bank_end != bank_start)
 			free_memmap(node, prev_bank_end, bank_start);
 
-		prev_bank_end = (mi->bank[i].start +
-				 mi->bank[i].size) >> PAGE_SHIFT;
+		prev_bank_end = bank_pfn_end(bank);
 	}
 }
 
@@ -487,8 +484,8 @@ void __init mem_init(void)
 
 	num_physpages = 0;
 	for (i = 0; i < meminfo.nr_banks; i++) {
-		num_physpages += meminfo.bank[i].size >> PAGE_SHIFT;
-		printk(" %ldMB", meminfo.bank[i].size >> 20);
+		num_physpages += bank_pfn_size(&meminfo.bank[i]);
+		printk(" %ldMB", bank_phys_size(&meminfo.bank[i]) >> 20);
 	}
 
 	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));

commit eca73214c9c50e290b8dc823b41730b01788872d
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Sep 30 19:29:25 2008 +0100

    [ARM] mm: move validation of membanks to one place
    
    The newly introduced sanity_check_meminfo() function should be
    used to collect all validation of the meminfo array, which we
    have in bootmem_init().  Move it there.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 80584bd7f03e..ffff901cf627 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -333,14 +333,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 void __init bootmem_init(struct meminfo *mi)
 {
 	unsigned long memend_pfn = 0;
-	int node, initrd_node, i;
-
-	/*
-	 * Invalidate the node number for empty or invalid memory banks
-	 */
-	for (i = 0; i < mi->nr_banks; i++)
-		if (mi->bank[i].size == 0 || mi->bank[i].node >= MAX_NUMNODES)
-			mi->bank[i].node = -1;
+	int node, initrd_node;
 
 	memcpy(&meminfo, mi, sizeof(meminfo));
 

commit 5ed5fdf50cbe8195522e2176d6356b357c0c963f
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Sep 6 11:23:30 2008 +0100

    [ARM] clean up a load of old declarations
    
    ... some of which are now in linux/*.h headers.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c70fb1d18903..80584bd7f03e 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -26,8 +26,6 @@
 
 #include "mm.h"
 
-extern void _text, _etext, __data_start, _end, __init_begin, __init_end;
-
 static unsigned long phys_initrd_start __initdata = 0;
 static unsigned long phys_initrd_size __initdata = 0;
 

commit 012d1f4af1b07e5ccfcd23b7c1dcdcc30a068257
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Sep 6 10:57:03 2008 +0100

    [ARM] move initrd code from kernel/setup.c to mm/init.c
    
    This quietens some sparse warnings about phys_initrd_start and
    phys_initrd_size.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 30a69d67d673..c70fb1d18903 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -27,8 +27,43 @@
 #include "mm.h"
 
 extern void _text, _etext, __data_start, _end, __init_begin, __init_end;
-extern unsigned long phys_initrd_start;
-extern unsigned long phys_initrd_size;
+
+static unsigned long phys_initrd_start __initdata = 0;
+static unsigned long phys_initrd_size __initdata = 0;
+
+static void __init early_initrd(char **p)
+{
+	unsigned long start, size;
+
+	start = memparse(*p, p);
+	if (**p == ',') {
+		size = memparse((*p) + 1, p);
+
+		phys_initrd_start = start;
+		phys_initrd_size = size;
+	}
+}
+__early_param("initrd=", early_initrd);
+
+static int __init parse_tag_initrd(const struct tag *tag)
+{
+	printk(KERN_WARNING "ATAG_INITRD is deprecated; "
+		"please update your bootloader.\n");
+	phys_initrd_start = __virt_to_phys(tag->u.initrd.start);
+	phys_initrd_size = tag->u.initrd.size;
+	return 0;
+}
+
+__tagtable(ATAG_INITRD, parse_tag_initrd);
+
+static int __init parse_tag_initrd2(const struct tag *tag)
+{
+	phys_initrd_start = tag->u.initrd.start;
+	phys_initrd_size = tag->u.initrd.size;
+	return 0;
+}
+
+__tagtable(ATAG_INITRD2, parse_tag_initrd2);
 
 /*
  * This is used to pass memory configuration data from paging_init

commit b962a286e500c6259af8ba133361f8528eed9172
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Jul 30 21:24:56 2008 +0100

    [ARM] initrd: claim initrd memory exclusively
    
    Claim the initrd memory exclusively, and order other memory
    reservations beforehand.  This allows us to determine whether
    the initrd memory was overwritten, and disable the initrd in
    that case.
    
    This avoids a 'bad page state' bug.
    
    Tested-by: Ralph Siemsen <ralphs@netwinder.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index e6352946dde0..30a69d67d673 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -156,9 +156,9 @@ static int __init check_initrd(struct meminfo *mi)
 	}
 
 	if (initrd_node == -1) {
-		printk(KERN_ERR "initrd (0x%08lx - 0x%08lx) extends beyond "
+		printk(KERN_ERR "INITRD: 0x%08lx+0x%08lx extends beyond "
 		       "physical memory - disabling initrd\n",
-		       phys_initrd_start, end);
+		       phys_initrd_start, phys_initrd_size);
 		phys_initrd_start = phys_initrd_size = 0;
 	}
 #endif
@@ -239,24 +239,32 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
 			     boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
 
+	/*
+	 * Reserve any special node zero regions.
+	 */
+	if (node == 0)
+		reserve_node_zero(pgdat);
+
 #ifdef CONFIG_BLK_DEV_INITRD
 	/*
 	 * If the initrd is in this node, reserve its memory.
 	 */
 	if (node == initrd_node) {
-		reserve_bootmem_node(pgdat, phys_initrd_start,
-				     phys_initrd_size, BOOTMEM_DEFAULT);
-		initrd_start = __phys_to_virt(phys_initrd_start);
-		initrd_end = initrd_start + phys_initrd_size;
+		int res = reserve_bootmem_node(pgdat, phys_initrd_start,
+				     phys_initrd_size, BOOTMEM_EXCLUSIVE);
+
+		if (res == 0) {
+			initrd_start = __phys_to_virt(phys_initrd_start);
+			initrd_end = initrd_start + phys_initrd_size;
+		} else {
+			printk(KERN_ERR
+				"INITRD: 0x%08lx+0x%08lx overlaps in-use "
+				"memory region - disabling initrd\n",
+				phys_initrd_start, phys_initrd_size);
+		}
 	}
 #endif
 
-	/*
-	 * Finally, reserve any node zero regions.
-	 */
-	if (node == 0)
-		reserve_node_zero(pgdat);
-
 	/*
 	 * initialise the zones within this node.
 	 */

commit 9109fb7b3520de187ebc3646c209d66a233f7169
Author: Johannes Weiner <hannes@saeurebad.de>
Date:   Wed Jul 23 21:27:20 2008 -0700

    mm: drop unneeded pgdat argument from free_area_init_node()
    
    free_area_init_node() gets passed in the node id as well as the node
    descriptor.  This is redundant as the function can trivially get the node
    descriptor itself by means of NODE_DATA() and the node's id.
    
    I checked all the users and NODE_DATA() seems to be usable everywhere
    from where this function is called.
    
    Signed-off-by: Johannes Weiner <hannes@saeurebad.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b657f1719af0..e6352946dde0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -284,7 +284,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	 */
 	arch_adjust_zones(node, zone_size, zhole_size);
 
-	free_area_init_node(node, pgdat, zone_size, start_pfn, zhole_size);
+	free_area_init_node(node, zone_size, start_pfn, zhole_size);
 
 	return end_pfn;
 }

commit c48b2e90aecf037f53913fc8d198d01fce0fbf3c
Author: Johannes Weiner <hannes@saeurebad.de>
Date:   Fri Apr 18 13:29:47 2008 -0700

    [ARM] remove redundant display of free swap space in show_mem()
    
    Signed-off-by: Johannes Weiner <hannes@saeurebad.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index ec00f26bffa4..b657f1719af0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -48,8 +48,6 @@ void show_mem(void)
 
 	printk("Mem-info:\n");
 	show_free_areas();
-	printk("Free swap:       %6ldkB\n", nr_swap_pages<<(PAGE_SHIFT-10));
-
 	for_each_online_node(node) {
 		pg_data_t *n = NODE_DATA(node);
 		struct page *map = n->node_mem_map - n->node_start_pfn;

commit 72a7fe3967dbf86cb34e24fbf1d957fe24d2f246
Author: Bernhard Walle <bwalle@suse.de>
Date:   Thu Feb 7 00:15:17 2008 -0800

    Introduce flags for reserve_bootmem()
    
    This patchset adds a flags variable to reserve_bootmem() and uses the
    BOOTMEM_EXCLUSIVE flag in crashkernel reservation code to detect collisions
    between crashkernel area and already used memory.
    
    This patch:
    
    Change the reserve_bootmem() function to accept a new flag BOOTMEM_EXCLUSIVE.
    If that flag is set, the function returns with -EBUSY if the memory already
    has been reserved in the past.  This is to avoid conflicts.
    
    Because that code runs before SMP initialisation, there's no race condition
    inside reserve_bootmem_core().
    
    [akpm@linux-foundation.org: coding-style fixes]
    [akpm@linux-foundation.org: fix powerpc build]
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: <linux-arch@vger.kernel.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Vivek Goyal <vgoyal@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c0ad7c0fbae0..ec00f26bffa4 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -239,7 +239,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	 * Reserve the bootmem bitmap for this node.
 	 */
 	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
-			     boot_pages << PAGE_SHIFT);
+			     boot_pages << PAGE_SHIFT, BOOTMEM_DEFAULT);
 
 #ifdef CONFIG_BLK_DEV_INITRD
 	/*
@@ -247,7 +247,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	 */
 	if (node == initrd_node) {
 		reserve_bootmem_node(pgdat, phys_initrd_start,
-				     phys_initrd_size);
+				     phys_initrd_size, BOOTMEM_DEFAULT);
 		initrd_start = __phys_to_virt(phys_initrd_start);
 		initrd_end = initrd_start + phys_initrd_size;
 	}

commit 0f0a00beb80624a446ba7c0152cd171008eeab2e
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Mar 3 19:45:25 2007 +0000

    [ARM] Remove needless linux/ptrace.h includes
    
    Lots of places in arch/arm were needlessly including linux/ptrace.h,
    resumably because we used to pass a struct pt_regs to interrupt
    handlers.  Now that we don't, all these ptrace.h includes are
    redundant.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 7760193e74cc..c0ad7c0fbae0 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -9,7 +9,6 @@
  */
 #include <linux/kernel.h>
 #include <linux/errno.h>
-#include <linux/ptrace.h>
 #include <linux/swap.h>
 #include <linux/init.h>
 #include <linux/bootmem.h>

commit 204ecae4e10c235e6987cb7b2809a665511ab174
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Jan 16 14:01:47 2007 +0000

    [ARM] Fix show_mem() for discontigmem
    
    show_mem() was assuming incorrectly that the mem_map for any
    node started at PFN 0.  This is obviously wrong; fix it to
    take account of node_start_pfn.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index b5814b4b6f35..7760193e74cc 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -52,15 +52,18 @@ void show_mem(void)
 	printk("Free swap:       %6ldkB\n", nr_swap_pages<<(PAGE_SHIFT-10));
 
 	for_each_online_node(node) {
+		pg_data_t *n = NODE_DATA(node);
+		struct page *map = n->node_mem_map - n->node_start_pfn;
+
 		for_each_nodebank (i,mi,node) {
 			unsigned int pfn1, pfn2;
 			struct page *page, *end;
 
-			pfn1 = mi->bank[i].start >> PAGE_SHIFT;
-			pfn2 = (mi->bank[i].size + mi->bank[i].start) >> PAGE_SHIFT;
+			pfn1 = __phys_to_pfn(mi->bank[i].start);
+			pfn2 = __phys_to_pfn(mi->bank[i].size + mi->bank[i].start);
 
-			page = NODE_MEM_MAP(node) + pfn1;
-			end  = NODE_MEM_MAP(node) + pfn2;
+			page = map + pfn1;
+			end  = map + pfn2;
 
 			do {
 				total++;

commit 5e7098275094ec405f2b19285ec0c38aead42d53
Author: Ray Lehtiniemi <rayl@com.rmk.(none)>
Date:   Tue Nov 7 03:19:15 2006 +0100

    [ARM] 3927/1: Allow show_mem() to work with holes in memory map.
    
    show_mem() was not correctly handling holes in the memory
    map.  It was treating the freed sections of the map as
    though they contained valid struct page entries.  This
    could cause incorrect debugging output or even a kernel
    panic.
    
    This patch keeps the struct meminfo around after system
    initialization so that show_mem() can use it when
    scanning memory.  show_mem() now walks over each bank
    of each online node, rather than assuming that each node
    contains a single contiguous bank.
    
    Signed-off-by: Ray Lehtiniemi <rayl@mail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 22217fe2650b..b5814b4b6f35 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -32,40 +32,51 @@ extern unsigned long phys_initrd_start;
 extern unsigned long phys_initrd_size;
 
 /*
- * The sole use of this is to pass memory configuration
- * data from paging_init to mem_init.
+ * This is used to pass memory configuration data from paging_init
+ * to mem_init, and by show_mem() to skip holes in the memory map.
  */
-static struct meminfo meminfo __initdata = { 0, };
+static struct meminfo meminfo = { 0, };
+
+#define for_each_nodebank(iter,mi,no)			\
+	for (iter = 0; iter < mi->nr_banks; iter++)	\
+		if (mi->bank[iter].node == no)
 
 void show_mem(void)
 {
 	int free = 0, total = 0, reserved = 0;
-	int shared = 0, cached = 0, slab = 0, node;
+	int shared = 0, cached = 0, slab = 0, node, i;
+	struct meminfo * mi = &meminfo;
 
 	printk("Mem-info:\n");
 	show_free_areas();
 	printk("Free swap:       %6ldkB\n", nr_swap_pages<<(PAGE_SHIFT-10));
 
 	for_each_online_node(node) {
-		struct page *page, *end;
-
-		page = NODE_MEM_MAP(node);
-		end  = page + NODE_DATA(node)->node_spanned_pages;
-
-		do {
-			total++;
-			if (PageReserved(page))
-				reserved++;
-			else if (PageSwapCache(page))
-				cached++;
-			else if (PageSlab(page))
-				slab++;
-			else if (!page_count(page))
-				free++;
-			else
-				shared += page_count(page) - 1;
-			page++;
-		} while (page < end);
+		for_each_nodebank (i,mi,node) {
+			unsigned int pfn1, pfn2;
+			struct page *page, *end;
+
+			pfn1 = mi->bank[i].start >> PAGE_SHIFT;
+			pfn2 = (mi->bank[i].size + mi->bank[i].start) >> PAGE_SHIFT;
+
+			page = NODE_MEM_MAP(node) + pfn1;
+			end  = NODE_MEM_MAP(node) + pfn2;
+
+			do {
+				total++;
+				if (PageReserved(page))
+					reserved++;
+				else if (PageSwapCache(page))
+					cached++;
+				else if (PageSlab(page))
+					slab++;
+				else if (!page_count(page))
+					free++;
+				else
+					shared += page_count(page) - 1;
+				page++;
+			} while (page < end);
+		}
 	}
 
 	printk("%d pages of RAM\n", total);
@@ -76,10 +87,6 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
-#define for_each_nodebank(iter,mi,no)			\
-	for (iter = 0; iter < mi->nr_banks; iter++)	\
-		if (mi->bank[iter].node == no)
-
 /*
  * FIXME: We really want to avoid allocating the bootmap bitmap
  * over the top of the initrd.  Hopefully, this is located towards

commit d111e8f9644aa585c1a7e198d74a4d2682ef1374
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Sep 27 15:27:33 2006 +0100

    [ARM] Split ARM MM initialisation for !mmu
    
    Move the MMU specific code from init.c into mmu.c, and add nommu
    fixups to nommu.c
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 83145d1d3389..22217fe2650b 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -27,10 +27,7 @@
 
 #include "mm.h"
 
-DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
-
-extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
-extern void _stext, _text, _etext, __data_start, _end, __init_begin, __init_end;
+extern void _text, _etext, __data_start, _end, __init_begin, __init_end;
 extern unsigned long phys_initrd_start;
 extern unsigned long phys_initrd_size;
 
@@ -40,17 +37,6 @@ extern unsigned long phys_initrd_size;
  */
 static struct meminfo meminfo __initdata = { 0, };
 
-/*
- * empty_zero_page is a special page that is used for
- * zero-initialized data and COW.
- */
-struct page *empty_zero_page;
-
-/*
- * The pmd table for the upper-most set of pages.
- */
-pmd_t *top_pmd;
-
 void show_mem(void)
 {
 	int free = 0, total = 0, reserved = 0;
@@ -173,87 +159,9 @@ static int __init check_initrd(struct meminfo *mi)
 	return initrd_node;
 }
 
-/*
- * Reserve the various regions of node 0
- */
-static __init void reserve_node_zero(pg_data_t *pgdat)
-{
-	unsigned long res_size = 0;
-
-	/*
-	 * Register the kernel text and data with bootmem.
-	 * Note that this can only be in node 0.
-	 */
-#ifdef CONFIG_XIP_KERNEL
-	reserve_bootmem_node(pgdat, __pa(&__data_start), &_end - &__data_start);
-#else
-	reserve_bootmem_node(pgdat, __pa(&_stext), &_end - &_stext);
-#endif
-
-	/*
-	 * Reserve the page tables.  These are already in use,
-	 * and can only be in node 0.
-	 */
-	reserve_bootmem_node(pgdat, __pa(swapper_pg_dir),
-			     PTRS_PER_PGD * sizeof(pgd_t));
-
-	/*
-	 * Hmm... This should go elsewhere, but we really really need to
-	 * stop things allocating the low memory; ideally we need a better
-	 * implementation of GFP_DMA which does not assume that DMA-able
-	 * memory starts at zero.
-	 */
-	if (machine_is_integrator() || machine_is_cintegrator())
-		res_size = __pa(swapper_pg_dir) - PHYS_OFFSET;
-
-	/*
-	 * These should likewise go elsewhere.  They pre-reserve the
-	 * screen memory region at the start of main system memory.
-	 */
-	if (machine_is_edb7211())
-		res_size = 0x00020000;
-	if (machine_is_p720t())
-		res_size = 0x00014000;
-
-#ifdef CONFIG_SA1111
-	/*
-	 * Because of the SA1111 DMA bug, we want to preserve our
-	 * precious DMA-able memory...
-	 */
-	res_size = __pa(swapper_pg_dir) - PHYS_OFFSET;
-#endif
-	if (res_size)
-		reserve_bootmem_node(pgdat, PHYS_OFFSET, res_size);
-}
-
-static inline void prepare_page_table(struct meminfo *mi)
-{
-	unsigned long addr;
-
-	/*
-	 * Clear out all the mappings below the kernel image.
-	 */
-	for (addr = 0; addr < MODULE_START; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-
-#ifdef CONFIG_XIP_KERNEL
-	/* The XIP kernel is mapped in the module area -- skip over it */
-	addr = ((unsigned long)&_etext + PGDIR_SIZE - 1) & PGDIR_MASK;
-#endif
-	for ( ; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-
-	/*
-	 * Clear out all the kernel space mappings, except for the first
-	 * memory bank, up to the end of the vmalloc region.
-	 */
-	for (addr = __phys_to_virt(mi->bank[0].start + mi->bank[0].size);
-	     addr < VMALLOC_END; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-}
-
 static inline void map_memory_bank(struct membank *bank)
 {
+#ifdef CONFIG_MMU
 	struct map_desc map;
 
 	map.pfn = __phys_to_pfn(bank->start);
@@ -262,6 +170,7 @@ static inline void map_memory_bank(struct membank *bank)
 	map.type = MT_MEMORY;
 
 	create_mapping(&map);
+#endif
 }
 
 static unsigned long __init
@@ -373,7 +282,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	return end_pfn;
 }
 
-static void __init bootmem_init(struct meminfo *mi)
+void __init bootmem_init(struct meminfo *mi)
 {
 	unsigned long memend_pfn = 0;
 	int node, initrd_node, i;
@@ -387,8 +296,6 @@ static void __init bootmem_init(struct meminfo *mi)
 
 	memcpy(&meminfo, mi, sizeof(meminfo));
 
-	prepare_page_table(mi);
-
 	/*
 	 * Locate which node contains the ramdisk image, if any.
 	 */
@@ -422,114 +329,6 @@ static void __init bootmem_init(struct meminfo *mi)
 	max_pfn = max_low_pfn = memend_pfn - PHYS_PFN_OFFSET;
 }
 
-/*
- * Set up device the mappings.  Since we clear out the page tables for all
- * mappings above VMALLOC_END, we will remove any debug device mappings.
- * This means you have to be careful how you debug this function, or any
- * called function.  This means you can't use any function or debugging
- * method which may touch any device, otherwise the kernel _will_ crash.
- */
-static void __init devicemaps_init(struct machine_desc *mdesc)
-{
-	struct map_desc map;
-	unsigned long addr;
-	void *vectors;
-
-	/*
-	 * Allocate the vector page early.
-	 */
-	vectors = alloc_bootmem_low_pages(PAGE_SIZE);
-	BUG_ON(!vectors);
-
-	for (addr = VMALLOC_END; addr; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-
-	/*
-	 * Map the kernel if it is XIP.
-	 * It is always first in the modulearea.
-	 */
-#ifdef CONFIG_XIP_KERNEL
-	map.pfn = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & SECTION_MASK);
-	map.virtual = MODULE_START;
-	map.length = ((unsigned long)&_etext - map.virtual + ~SECTION_MASK) & SECTION_MASK;
-	map.type = MT_ROM;
-	create_mapping(&map);
-#endif
-
-	/*
-	 * Map the cache flushing regions.
-	 */
-#ifdef FLUSH_BASE
-	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS);
-	map.virtual = FLUSH_BASE;
-	map.length = SZ_1M;
-	map.type = MT_CACHECLEAN;
-	create_mapping(&map);
-#endif
-#ifdef FLUSH_BASE_MINICACHE
-	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS + SZ_1M);
-	map.virtual = FLUSH_BASE_MINICACHE;
-	map.length = SZ_1M;
-	map.type = MT_MINICLEAN;
-	create_mapping(&map);
-#endif
-
-	/*
-	 * Create a mapping for the machine vectors at the high-vectors
-	 * location (0xffff0000).  If we aren't using high-vectors, also
-	 * create a mapping at the low-vectors virtual address.
-	 */
-	map.pfn = __phys_to_pfn(virt_to_phys(vectors));
-	map.virtual = 0xffff0000;
-	map.length = PAGE_SIZE;
-	map.type = MT_HIGH_VECTORS;
-	create_mapping(&map);
-
-	if (!vectors_high()) {
-		map.virtual = 0;
-		map.type = MT_LOW_VECTORS;
-		create_mapping(&map);
-	}
-
-	/*
-	 * Ask the machine support to map in the statically mapped devices.
-	 */
-	if (mdesc->map_io)
-		mdesc->map_io();
-
-	/*
-	 * Finally flush the caches and tlb to ensure that we're in a
-	 * consistent state wrt the writebuffer.  This also ensures that
-	 * any write-allocated cache lines in the vector page are written
-	 * back.  After this point, we can start to touch devices again.
-	 */
-	local_flush_tlb_all();
-	flush_cache_all();
-}
-
-/*
- * paging_init() sets up the page tables, initialises the zone memory
- * maps, and sets up the zero page, bad page and bad page tables.
- */
-void __init paging_init(struct meminfo *mi, struct machine_desc *mdesc)
-{
-	void *zero_page;
-
-	build_mem_type_table();
-	bootmem_init(mi);
-	devicemaps_init(mdesc);
-
-	top_pmd = pmd_off_k(0xffff0000);
-
-	/*
-	 * allocate the zero page.  Note that we count on this going ok.
-	 */
-	zero_page = alloc_bootmem_low_pages(PAGE_SIZE);
-	memzero(zero_page, PAGE_SIZE);
-	empty_zero_page = virt_to_page(zero_page);
-	flush_dcache_page(empty_zero_page);
-}
-
 static inline void free_area(unsigned long addr, unsigned long end, char *s)
 {
 	unsigned int size = (end - addr) >> 10;

commit 456335e2072fb35bf290b45e61d51916c322c145
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Sep 27 10:00:54 2006 +0100

    [ARM] Separate page table manipulation code from bootmem initialisation
    
    nommu does not require the page table manipulation code in the
    bootmem initialisation paths.  Move this into separate inline
    functions.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 64262bda8e54..83145d1d3389 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -226,6 +226,44 @@ static __init void reserve_node_zero(pg_data_t *pgdat)
 		reserve_bootmem_node(pgdat, PHYS_OFFSET, res_size);
 }
 
+static inline void prepare_page_table(struct meminfo *mi)
+{
+	unsigned long addr;
+
+	/*
+	 * Clear out all the mappings below the kernel image.
+	 */
+	for (addr = 0; addr < MODULE_START; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
+
+#ifdef CONFIG_XIP_KERNEL
+	/* The XIP kernel is mapped in the module area -- skip over it */
+	addr = ((unsigned long)&_etext + PGDIR_SIZE - 1) & PGDIR_MASK;
+#endif
+	for ( ; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
+
+	/*
+	 * Clear out all the kernel space mappings, except for the first
+	 * memory bank, up to the end of the vmalloc region.
+	 */
+	for (addr = __phys_to_virt(mi->bank[0].start + mi->bank[0].size);
+	     addr < VMALLOC_END; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
+}
+
+static inline void map_memory_bank(struct membank *bank)
+{
+	struct map_desc map;
+
+	map.pfn = __phys_to_pfn(bank->start);
+	map.virtual = __phys_to_virt(bank->start);
+	map.length = bank->size;
+	map.type = MT_MEMORY;
+
+	create_mapping(&map);
+}
+
 static unsigned long __init
 bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 {
@@ -242,23 +280,18 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 	 * Calculate the pfn range, and map the memory banks for this node.
 	 */
 	for_each_nodebank(i, mi, node) {
+		struct membank *bank = &mi->bank[i];
 		unsigned long start, end;
-		struct map_desc map;
 
-		start = mi->bank[i].start >> PAGE_SHIFT;
-		end = (mi->bank[i].start + mi->bank[i].size) >> PAGE_SHIFT;
+		start = bank->start >> PAGE_SHIFT;
+		end = (bank->start + bank->size) >> PAGE_SHIFT;
 
 		if (start_pfn > start)
 			start_pfn = start;
 		if (end_pfn < end)
 			end_pfn = end;
 
-		map.pfn = __phys_to_pfn(mi->bank[i].start);
-		map.virtual = __phys_to_virt(mi->bank[i].start);
-		map.length = mi->bank[i].size;
-		map.type = MT_MEMORY;
-
-		create_mapping(&map);
+		map_memory_bank(bank);
 	}
 
 	/*
@@ -342,7 +375,7 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 
 static void __init bootmem_init(struct meminfo *mi)
 {
-	unsigned long addr, memend_pfn = 0;
+	unsigned long memend_pfn = 0;
 	int node, initrd_node, i;
 
 	/*
@@ -354,25 +387,7 @@ static void __init bootmem_init(struct meminfo *mi)
 
 	memcpy(&meminfo, mi, sizeof(meminfo));
 
-	/*
-	 * Clear out all the mappings below the kernel image.
-	 */
-	for (addr = 0; addr < MODULE_START; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-#ifdef CONFIG_XIP_KERNEL
-	/* The XIP kernel is mapped in the module area -- skip over it */
-	addr = ((unsigned long)&_etext + PGDIR_SIZE - 1) & PGDIR_MASK;
-#endif
-	for ( ; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
-
-	/*
-	 * Clear out all the kernel space mappings, except for the first
-	 * memory bank, up to the end of the vmalloc region.
-	 */
-	for (addr = __phys_to_virt(mi->bank[0].start + mi->bank[0].size);
-	     addr < VMALLOC_END; addr += PGDIR_SIZE)
-		pmd_clear(pmd_off_k(addr));
+	prepare_page_table(mi);
 
 	/*
 	 * Locate which node contains the ramdisk image, if any.

commit 4052ebb7a2729bd7c28260cdf8e470c0d81b9c56
Author: George G. Davis <davis_g@mvista.com>
Date:   Fri Sep 22 18:36:38 2006 +0100

    [ARM] 3859/1: Fix devicemaps_init() XIP_KERNEL odd 1MiB XIP_PHYS_ADDR translation error
    
    The ARM XIP_KERNEL map created in devicemaps_init() is wrong.
    The map.pfn is rounded down to an even 1MiB section boundary
    which results in va/pa translations errors when XIP_PHYS_ADDR
    starts on an odd 1MiB boundary and this causes the kernel to
    hang.  This patch fixes ARM XIP_KERNEL translation errors for
    the odd 1MiB XIP_PHYS_ADDR boundary case.
    
    Signed-off-by: George G. Davis <gdavis@mvista.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 1099af6d470a..64262bda8e54 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -434,9 +434,9 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	 * It is always first in the modulearea.
 	 */
 #ifdef CONFIG_XIP_KERNEL
-	map.pfn = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & PGDIR_MASK);
+	map.pfn = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & SECTION_MASK);
 	map.virtual = MODULE_START;
-	map.length = ((unsigned long)&_etext - map.virtual + ~PGDIR_MASK) & PGDIR_MASK;
+	map.length = ((unsigned long)&_etext - map.virtual + ~SECTION_MASK) & SECTION_MASK;
 	map.type = MT_ROM;
 	create_mapping(&map);
 #endif

commit 1b2e2b73b4c84c918686c04a00724197036c0847
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Aug 21 17:06:38 2006 +0100

    [ARM] Cleanup arch/arm/mm a little
    
    Move top_pmd into arch/arm/mm/mm.h - nothing outside arch/arm/mm
    references it.
    
    Move the repeated definition of TOP_PTE into mm/mm.h, as well as
    a few function prototypes.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index fe3f7f625008..1099af6d470a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -25,6 +25,8 @@
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
 
+#include "mm.h"
+
 DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
 
 extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
@@ -44,6 +46,11 @@ static struct meminfo meminfo __initdata = { 0, };
  */
 struct page *empty_zero_page;
 
+/*
+ * The pmd table for the upper-most set of pages.
+ */
+pmd_t *top_pmd;
+
 void show_mem(void)
 {
 	int free = 0, total = 0, reserved = 0;
@@ -83,16 +90,6 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
-static inline pmd_t *pmd_off(pgd_t *pgd, unsigned long virt)
-{
-	return pmd_offset(pgd, virt);
-}
-
-static inline pmd_t *pmd_off_k(unsigned long virt)
-{
-	return pmd_off(pgd_offset_k(virt), virt);
-}
-
 #define for_each_nodebank(iter,mi,no)			\
 	for (iter = 0; iter < mi->nr_banks; iter++)	\
 		if (mi->bank[iter].node == no)
@@ -229,9 +226,6 @@ static __init void reserve_node_zero(pg_data_t *pgdat)
 		reserve_bootmem_node(pgdat, PHYS_OFFSET, res_size);
 }
 
-void __init build_mem_type_table(void);
-void __init create_mapping(struct map_desc *md);
-
 static unsigned long __init
 bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 {

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 989fd681c822..fe3f7f625008 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -7,7 +7,6 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
-#include <linux/config.h>
 #include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/ptrace.h>

commit 888e7bf166a0059480da137f3bd28dcd51175f3d
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Jun 24 17:20:13 2006 +0100

    [ARM] Remove TABLE_SIZE, and several unused function prototypes
    
    TABLE_SIZE is never used in arch/arm/mm/init.c.  create_memmap_holes(),
    memtable_init, and setup_io_desc() no longer exist in the kernel.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 9ea1f87a7079..989fd681c822 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -26,8 +26,6 @@
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
 
-#define TABLE_SIZE	(2 * PTRS_PER_PTE * sizeof(pte_t))
-
 DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
 
 extern pgd_t swapper_pg_dir[PTRS_PER_PGD];

commit 74d02fb9543ec85b04319b5b50926c78e7f07f3e
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Apr 4 21:47:43 2006 +0100

    [ARM] Move FLUSH_BASE macros to asm/arch/memory.h
    
    FLUSH_BASE must be visible to arch/arm/mm/init.c in order for the
    memory region to be setup.  Move these definitions from
    asm-arm/arch-*/hardware.h into asm-arm/arch-*/memory.h where mm
    stuff can see them.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 88279124317a..9ea1f87a7079 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -20,6 +20,7 @@
 
 #include <asm/mach-types.h>
 #include <asm/setup.h>
+#include <asm/sizes.h>
 #include <asm/tlb.h>
 
 #include <asm/mach/arch.h>
@@ -455,14 +456,14 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 #ifdef FLUSH_BASE
 	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS);
 	map.virtual = FLUSH_BASE;
-	map.length = PGDIR_SIZE;
+	map.length = SZ_1M;
 	map.type = MT_CACHECLEAN;
 	create_mapping(&map);
 #endif
 #ifdef FLUSH_BASE_MINICACHE
-	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS + PGDIR_SIZE);
+	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS + SZ_1M);
 	map.virtual = FLUSH_BASE_MINICACHE;
-	map.length = PGDIR_SIZE;
+	map.length = SZ_1M;
 	map.type = MT_MINICLEAN;
 	create_mapping(&map);
 #endif

commit 591eb85ecd7e6eb8596c6129ae074e16636b99f4
Merge: 4658f79bec0b 3a2916aa2895
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Wed Mar 22 17:32:09 2006 -0800

    Merge master.kernel.org:/home/rmk/linux-2.6-arm
    
    * master.kernel.org:/home/rmk/linux-2.6-arm: (45 commits)
      [ARM] 3389/1: typo and grammar fix
      [ARM] 3386/1: AT91RM9200 Clock update
      [ARM] 3384/1: AT91RM9200: Timer
      [ARM] 3382/1: ixp2000: unify defconfigs
      [ARM] 3381/1: ixp2000: fix slowport write timing control register fields
      [ARM] 3380/1: ixp2000: simplify ixdp2x00_master_npu() check
      [ARM] 3379/1: ixp2000: use generic 8250 debug macros
      [ARM] 3378/1: ixp2000: fix gpio interrupt handling
      [ARM] Quieten spurious IRQ detection
      [ARM] Use kcalloc to allocate counter_config array rather than kmalloc
      [ARM] Oprofile: dynamically allocate counter_config
      [ARM] Oprofile: Convert semaphore to mutex
      [ARM] 3376/2: S3C2410 - update defconfig
      [ARM] 3375/1: S3C2440 - fix osiris machine build
      [ARM] 3374/1: ep93xx: gpio interrupt support
      [ARM] 3361/1: S3C24XX - add USB bus clock source
      [ARM] 3360/1: S3C2440 - add set rate methods and camera clock
      [ARM] 3359/1: S3C24XX - add support for clk_set_rate
      [ARM] Convert kmalloc+memset to kzalloc
      [ARM] 3373/1: move uengine loader to arch/arm/common
      ...

commit 7835e98b2e3c66dba79cb0ff8ebb90a2fe030c29
Author: Nick Piggin <npiggin@suse.de>
Date:   Wed Mar 22 00:08:40 2006 -0800

    [PATCH] remove set_page_count() outside mm/
    
    set_page_count usage outside mm/ is limited to setting the refcount to 1.
    Remove set_page_count from outside mm/, and replace those users with
    init_page_count() and set_page_refcounted().
    
    This allows more debug checking, and tighter control on how code is allowed
    to play around with page->_count.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8b276ee38acf..b0321e943b76 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -531,7 +531,7 @@ static inline void free_area(unsigned long addr, unsigned long end, char *s)
 	for (; addr < end; addr += PAGE_SIZE) {
 		struct page *page = virt_to_page(addr);
 		ClearPageReserved(page);
-		set_page_count(page, 1);
+		init_page_count(page);
 		free_page(addr);
 		totalram_pages++;
 	}

commit f78f10436806660f39440a729acbaf03e3a01023
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Sat Mar 4 11:04:12 2006 +0000

    [ARM] Remove unnecessary asm/hardware.h includes
    
    asm/hardware.h is not required for the majority of processor support
    files, ioremap support, mm initialisation, acorn IO support, nor
    the debug code (which picks up its machine specific includes via
    debug-macros.S)
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 8b276ee38acf..efda9710ee68 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -19,7 +19,6 @@
 #include <linux/initrd.h>
 
 #include <asm/mach-types.h>
-#include <asm/hardware.h>
 #include <asm/setup.h>
 #include <asm/tlb.h>
 

commit 02b30839220fa3ef80a34ed6ee174fa2d9937eac
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Thu Nov 17 22:43:30 2005 +0000

    [ARM] Fix some corner cases in new mm initialisation
    
    Document that the VMALLOC_END address must be aligned to 2MB since
    it must align with a PGD boundary.
    
    Allocate the vectors page early so that the flush_cache_all() later
    will cause any dirty cache lines in the direct mapping will be safely
    written back.
    
    Move the flush_cache_all() to the second local_flush_cache_tlb() and
    remove the now redundant first local_flush_cache_tlb().
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c168f322ef8c..8b276ee38acf 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -420,7 +420,8 @@ static void __init bootmem_init(struct meminfo *mi)
  * Set up device the mappings.  Since we clear out the page tables for all
  * mappings above VMALLOC_END, we will remove any debug device mappings.
  * This means you have to be careful how you debug this function, or any
- * called function.  (Do it by code inspection!)
+ * called function.  This means you can't use any function or debugging
+ * method which may touch any device, otherwise the kernel _will_ crash.
  */
 static void __init devicemaps_init(struct machine_desc *mdesc)
 {
@@ -428,6 +429,12 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	unsigned long addr;
 	void *vectors;
 
+	/*
+	 * Allocate the vector page early.
+	 */
+	vectors = alloc_bootmem_low_pages(PAGE_SIZE);
+	BUG_ON(!vectors);
+
 	for (addr = VMALLOC_END; addr; addr += PGDIR_SIZE)
 		pmd_clear(pmd_off_k(addr));
 
@@ -461,12 +468,6 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	create_mapping(&map);
 #endif
 
-	flush_cache_all();
-	local_flush_tlb_all();
-
-	vectors = alloc_bootmem_low_pages(PAGE_SIZE);
-	BUG_ON(!vectors);
-
 	/*
 	 * Create a mapping for the machine vectors at the high-vectors
 	 * location (0xffff0000).  If we aren't using high-vectors, also
@@ -491,12 +492,13 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 		mdesc->map_io();
 
 	/*
-	 * Finally flush the tlb again - this ensures that we're in a
-	 * consistent state wrt the writebuffer if the writebuffer needs
-	 * draining.  After this point, we can start to touch devices
-	 * again.
+	 * Finally flush the caches and tlb to ensure that we're in a
+	 * consistent state wrt the writebuffer.  This also ensures that
+	 * any write-allocated cache lines in the vector page are written
+	 * back.  After this point, we can start to touch devices again.
 	 */
 	local_flush_tlb_all();
+	flush_cache_all();
 }
 
 /*

commit 6bf7bd6967b1cdde1fe953b0edb951966799fb44
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Nov 2 14:11:35 2005 +0000

    [ARM] Fix mm initialisation with write buffered write allocate caches
    
    It seems that without the extra tlb flush, we may end up faulting
    during the early kernel initialisation because the TLB can't see
    the updated page tables.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index fd079ff1fc53..c168f322ef8c 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -486,10 +486,17 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 
 	/*
 	 * Ask the machine support to map in the statically mapped devices.
-	 * After this point, we can start to touch devices again.
 	 */
 	if (mdesc->map_io)
 		mdesc->map_io();
+
+	/*
+	 * Finally flush the tlb again - this ensures that we're in a
+	 * consistent state wrt the writebuffer if the writebuffer needs
+	 * draining.  After this point, we can start to touch devices
+	 * again.
+	 */
+	local_flush_tlb_all();
 }
 
 /*

commit 1a47ebc0d971fbc47cd859a09956f7c7d001f5fd
Author: Nicolas Pitre <nico@cam.org>
Date:   Sat Oct 29 16:28:29 2005 +0100

    [ARM] 3059/1: fix XIP support
    
    Patch from Nicolas Pitre
    
    Fix XIP support after recent bootmem code refactoring.
    
    Signed-off-by: Nicolas Pitre <nico@cam.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index f4496813615a..fd079ff1fc53 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -363,20 +363,16 @@ static void __init bootmem_init(struct meminfo *mi)
 
 	memcpy(&meminfo, mi, sizeof(meminfo));
 
-#ifdef CONFIG_XIP_KERNEL
-#error needs fixing
-	p->pfn        = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & PMD_MASK);
-	p->virtual    = (unsigned long)&_stext & PMD_MASK;
-	p->length     = ((unsigned long)&_etext - p->virtual + ~PMD_MASK) & PMD_MASK;
-	p->type       = MT_ROM;
-	p ++;
-#endif
-
 	/*
 	 * Clear out all the mappings below the kernel image.
-	 * FIXME: what about XIP?
 	 */
-	for (addr = 0; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
+	for (addr = 0; addr < MODULE_START; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
+#ifdef CONFIG_XIP_KERNEL
+	/* The XIP kernel is mapped in the module area -- skip over it */
+	addr = ((unsigned long)&_etext + PGDIR_SIZE - 1) & PGDIR_MASK;
+#endif
+	for ( ; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
 		pmd_clear(pmd_off_k(addr));
 
 	/*
@@ -435,6 +431,18 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	for (addr = VMALLOC_END; addr; addr += PGDIR_SIZE)
 		pmd_clear(pmd_off_k(addr));
 
+	/*
+	 * Map the kernel if it is XIP.
+	 * It is always first in the modulearea.
+	 */
+#ifdef CONFIG_XIP_KERNEL
+	map.pfn = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & PGDIR_MASK);
+	map.virtual = MODULE_START;
+	map.length = ((unsigned long)&_etext - map.virtual + ~PGDIR_MASK) & PGDIR_MASK;
+	map.type = MT_ROM;
+	create_mapping(&map);
+#endif
+
 	/*
 	 * Map the cache flushing regions.
 	 */

commit 9769c2468d423a1562dd59a5db250bd0a5533ec9
Author: Deepak Saxena <dsaxena@plexity.net>
Date:   Fri Oct 28 15:19:11 2005 +0100

    [ARM] 3016/1: Replace map_desc.physical with map_desc.pfn
    
    Patch from Deepak Saxena
    
    Convert map_desc.physical to map_desc.pfn. This allows us to add
    support for 36-bit addressed physical devices in the static maps
    without having to resort to u64 variables.
    
    Signed-off-by: Deepak Saxena <dsaxena@plexity.net>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index d1f1ec73500f..f4496813615a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -262,8 +262,8 @@ bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 		if (end_pfn < end)
 			end_pfn = end;
 
-		map.physical = mi->bank[i].start;
-		map.virtual = __phys_to_virt(map.physical);
+		map.pfn = __phys_to_pfn(mi->bank[i].start);
+		map.virtual = __phys_to_virt(mi->bank[i].start);
 		map.length = mi->bank[i].size;
 		map.type = MT_MEMORY;
 
@@ -365,7 +365,7 @@ static void __init bootmem_init(struct meminfo *mi)
 
 #ifdef CONFIG_XIP_KERNEL
 #error needs fixing
-	p->physical   = CONFIG_XIP_PHYS_ADDR & PMD_MASK;
+	p->pfn        = __phys_to_pfn(CONFIG_XIP_PHYS_ADDR & PMD_MASK);
 	p->virtual    = (unsigned long)&_stext & PMD_MASK;
 	p->length     = ((unsigned long)&_etext - p->virtual + ~PMD_MASK) & PMD_MASK;
 	p->type       = MT_ROM;
@@ -439,14 +439,14 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	 * Map the cache flushing regions.
 	 */
 #ifdef FLUSH_BASE
-	map.physical = FLUSH_BASE_PHYS;
+	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS);
 	map.virtual = FLUSH_BASE;
 	map.length = PGDIR_SIZE;
 	map.type = MT_CACHECLEAN;
 	create_mapping(&map);
 #endif
 #ifdef FLUSH_BASE_MINICACHE
-	map.physical = FLUSH_BASE_PHYS + PGDIR_SIZE;
+	map.pfn = __phys_to_pfn(FLUSH_BASE_PHYS + PGDIR_SIZE);
 	map.virtual = FLUSH_BASE_MINICACHE;
 	map.length = PGDIR_SIZE;
 	map.type = MT_MINICLEAN;
@@ -464,7 +464,7 @@ static void __init devicemaps_init(struct machine_desc *mdesc)
 	 * location (0xffff0000).  If we aren't using high-vectors, also
 	 * create a mapping at the low-vectors virtual address.
 	 */
-	map.physical = virt_to_phys(vectors);
+	map.pfn = __phys_to_pfn(virt_to_phys(vectors));
 	map.virtual = 0xffff0000;
 	map.length = PAGE_SIZE;
 	map.type = MT_HIGH_VECTORS;

commit 90072059d2963dec237ae0cf49831ef77ddb5739
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Fri Oct 28 14:48:37 2005 +0100

    [ARM] Re-jig bootmem initialisation
    
    Make ARM independent of the way bootmem operates internally.  We
    now map each node as we initialise it, and place the bootmem bitmap
    inside each node, rather than all in the first node.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index edffa47a4b2a..d1f1ec73500f 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -1,7 +1,7 @@
 /*
  *  linux/arch/arm/mm/init.c
  *
- *  Copyright (C) 1995-2002 Russell King
+ *  Copyright (C) 1995-2005 Russell King
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -86,14 +86,19 @@ void show_mem(void)
 	printk("%d pages swap cached\n", cached);
 }
 
-struct node_info {
-	unsigned int start;
-	unsigned int end;
-	int bootmap_pages;
-};
+static inline pmd_t *pmd_off(pgd_t *pgd, unsigned long virt)
+{
+	return pmd_offset(pgd, virt);
+}
+
+static inline pmd_t *pmd_off_k(unsigned long virt)
+{
+	return pmd_off(pgd_offset_k(virt), virt);
+}
 
-#define O_PFN_DOWN(x)	((x) >> PAGE_SHIFT)
-#define O_PFN_UP(x)	(PAGE_ALIGN(x) >> PAGE_SHIFT)
+#define for_each_nodebank(iter,mi,no)			\
+	for (iter = 0; iter < mi->nr_banks; iter++)	\
+		if (mi->bank[iter].node == no)
 
 /*
  * FIXME: We really want to avoid allocating the bootmap bitmap
@@ -106,15 +111,12 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 {
 	unsigned int start_pfn, bank, bootmap_pfn;
 
-	start_pfn   = O_PFN_UP(__pa(&_end));
+	start_pfn   = PAGE_ALIGN(__pa(&_end)) >> PAGE_SHIFT;
 	bootmap_pfn = 0;
 
-	for (bank = 0; bank < mi->nr_banks; bank ++) {
+	for_each_nodebank(bank, mi, node) {
 		unsigned int start, end;
 
-		if (mi->bank[bank].node != node)
-			continue;
-
 		start = mi->bank[bank].start >> PAGE_SHIFT;
 		end   = (mi->bank[bank].size +
 			 mi->bank[bank].start) >> PAGE_SHIFT;
@@ -140,92 +142,6 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 	return bootmap_pfn;
 }
 
-/*
- * Scan the memory info structure and pull out:
- *  - the end of memory
- *  - the number of nodes
- *  - the pfn range of each node
- *  - the number of bootmem bitmap pages
- */
-static unsigned int __init
-find_memend_and_nodes(struct meminfo *mi, struct node_info *np)
-{
-	unsigned int i, bootmem_pages = 0, memend_pfn = 0;
-
-	for (i = 0; i < MAX_NUMNODES; i++) {
-		np[i].start = -1U;
-		np[i].end = 0;
-		np[i].bootmap_pages = 0;
-	}
-
-	for (i = 0; i < mi->nr_banks; i++) {
-		unsigned long start, end;
-		int node;
-
-		if (mi->bank[i].size == 0) {
-			/*
-			 * Mark this bank with an invalid node number
-			 */
-			mi->bank[i].node = -1;
-			continue;
-		}
-
-		node = mi->bank[i].node;
-
-		/*
-		 * Make sure we haven't exceeded the maximum number of nodes
-		 * that we have in this configuration.  If we have, we're in
-		 * trouble.  (maybe we ought to limit, instead of bugging?)
-		 */
-		if (node >= MAX_NUMNODES)
-			BUG();
-		node_set_online(node);
-
-		/*
-		 * Get the start and end pfns for this bank
-		 */
-		start = mi->bank[i].start >> PAGE_SHIFT;
-		end   = (mi->bank[i].start + mi->bank[i].size) >> PAGE_SHIFT;
-
-		if (np[node].start > start)
-			np[node].start = start;
-
-		if (np[node].end < end)
-			np[node].end = end;
-
-		if (memend_pfn < end)
-			memend_pfn = end;
-	}
-
-	/*
-	 * Calculate the number of pages we require to
-	 * store the bootmem bitmaps.
-	 */
-	for_each_online_node(i) {
-		if (np[i].end == 0)
-			continue;
-
-		np[i].bootmap_pages = bootmem_bootmap_pages(np[i].end -
-							    np[i].start);
-		bootmem_pages += np[i].bootmap_pages;
-	}
-
-	high_memory = __va(memend_pfn << PAGE_SHIFT);
-
-	/*
-	 * This doesn't seem to be used by the Linux memory
-	 * manager any more.  If we can get rid of it, we
-	 * also get rid of some of the stuff above as well.
-	 *
-	 * Note: max_low_pfn and max_pfn reflect the number
-	 * of _pages_ in the system, not the maximum PFN.
-	 */
-	max_low_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);
-	max_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);
-
-	return bootmem_pages;
-}
-
 static int __init check_initrd(struct meminfo *mi)
 {
 	int initrd_node = -2;
@@ -266,9 +182,8 @@ static int __init check_initrd(struct meminfo *mi)
 /*
  * Reserve the various regions of node 0
  */
-static __init void reserve_node_zero(unsigned int bootmap_pfn, unsigned int bootmap_pages)
+static __init void reserve_node_zero(pg_data_t *pgdat)
 {
-	pg_data_t *pgdat = NODE_DATA(0);
 	unsigned long res_size = 0;
 
 	/*
@@ -288,13 +203,6 @@ static __init void reserve_node_zero(unsigned int bootmap_pfn, unsigned int boot
 	reserve_bootmem_node(pgdat, __pa(swapper_pg_dir),
 			     PTRS_PER_PGD * sizeof(pgd_t));
 
-	/*
-	 * And don't forget to reserve the allocator bitmap,
-	 * which will be freed later.
-	 */
-	reserve_bootmem_node(pgdat, bootmap_pfn << PAGE_SHIFT,
-			     bootmap_pages << PAGE_SHIFT);
-
 	/*
 	 * Hmm... This should go elsewhere, but we really really need to
 	 * stop things allocating the low memory; ideally we need a better
@@ -324,183 +232,276 @@ static __init void reserve_node_zero(unsigned int bootmap_pfn, unsigned int boot
 		reserve_bootmem_node(pgdat, PHYS_OFFSET, res_size);
 }
 
-/*
- * Register all available RAM in this node with the bootmem allocator.
- */
-static inline void free_bootmem_node_bank(int node, struct meminfo *mi)
+void __init build_mem_type_table(void);
+void __init create_mapping(struct map_desc *md);
+
+static unsigned long __init
+bootmem_init_node(int node, int initrd_node, struct meminfo *mi)
 {
-	pg_data_t *pgdat = NODE_DATA(node);
-	int bank;
+	unsigned long zone_size[MAX_NR_ZONES], zhole_size[MAX_NR_ZONES];
+	unsigned long start_pfn, end_pfn, boot_pfn;
+	unsigned int boot_pages;
+	pg_data_t *pgdat;
+	int i;
 
-	for (bank = 0; bank < mi->nr_banks; bank++)
-		if (mi->bank[bank].node == node)
-			free_bootmem_node(pgdat, mi->bank[bank].start,
-					  mi->bank[bank].size);
-}
+	start_pfn = -1UL;
+	end_pfn = 0;
 
-/*
- * Initialise the bootmem allocator for all nodes.  This is called
- * early during the architecture specific initialisation.
- */
-static void __init bootmem_init(struct meminfo *mi)
-{
-	struct node_info node_info[MAX_NUMNODES], *np = node_info;
-	unsigned int bootmap_pages, bootmap_pfn, map_pg;
-	int node, initrd_node;
+	/*
+	 * Calculate the pfn range, and map the memory banks for this node.
+	 */
+	for_each_nodebank(i, mi, node) {
+		unsigned long start, end;
+		struct map_desc map;
 
-	bootmap_pages = find_memend_and_nodes(mi, np);
-	bootmap_pfn   = find_bootmap_pfn(0, mi, bootmap_pages);
-	initrd_node   = check_initrd(mi);
+		start = mi->bank[i].start >> PAGE_SHIFT;
+		end = (mi->bank[i].start + mi->bank[i].size) >> PAGE_SHIFT;
 
-	map_pg = bootmap_pfn;
+		if (start_pfn > start)
+			start_pfn = start;
+		if (end_pfn < end)
+			end_pfn = end;
+
+		map.physical = mi->bank[i].start;
+		map.virtual = __phys_to_virt(map.physical);
+		map.length = mi->bank[i].size;
+		map.type = MT_MEMORY;
+
+		create_mapping(&map);
+	}
 
 	/*
-	 * Initialise the bootmem nodes.
-	 *
-	 * What we really want to do is:
-	 *
-	 *   unmap_all_regions_except_kernel();
-	 *   for_each_node_in_reverse_order(node) {
-	 *     map_node(node);
-	 *     allocate_bootmem_map(node);
-	 *     init_bootmem_node(node);
-	 *     free_bootmem_node(node);
-	 *   }
-	 *
-	 * but this is a 2.5-type change.  For now, we just set
-	 * the nodes up in reverse order.
-	 *
-	 * (we could also do with rolling bootmem_init and paging_init
-	 * into one generic "memory_init" type function).
+	 * If there is no memory in this node, ignore it.
 	 */
-	np += num_online_nodes() - 1;
-	for (node = num_online_nodes() - 1; node >= 0; node--, np--) {
-		/*
-		 * If there are no pages in this node, ignore it.
-		 * Note that node 0 must always have some pages.
-		 */
-		if (np->end == 0 || !node_online(node)) {
-			if (node == 0)
-				BUG();
-			continue;
-		}
+	if (end_pfn == 0)
+		return end_pfn;
 
-		/*
-		 * Initialise the bootmem allocator.
-		 */
-		init_bootmem_node(NODE_DATA(node), map_pg, np->start, np->end);
-		free_bootmem_node_bank(node, mi);
-		map_pg += np->bootmap_pages;
+	/*
+	 * Allocate the bootmem bitmap page.
+	 */
+	boot_pages = bootmem_bootmap_pages(end_pfn - start_pfn);
+	boot_pfn = find_bootmap_pfn(node, mi, boot_pages);
 
-		/*
-		 * If this is node 0, we need to reserve some areas ASAP -
-		 * we may use bootmem on node 0 to setup the other nodes.
-		 */
-		if (node == 0)
-			reserve_node_zero(bootmap_pfn, bootmap_pages);
-	}
+	/*
+	 * Initialise the bootmem allocator for this node, handing the
+	 * memory banks over to bootmem.
+	 */
+	node_set_online(node);
+	pgdat = NODE_DATA(node);
+	init_bootmem_node(pgdat, boot_pfn, start_pfn, end_pfn);
 
+	for_each_nodebank(i, mi, node)
+		free_bootmem_node(pgdat, mi->bank[i].start, mi->bank[i].size);
+
+	/*
+	 * Reserve the bootmem bitmap for this node.
+	 */
+	reserve_bootmem_node(pgdat, boot_pfn << PAGE_SHIFT,
+			     boot_pages << PAGE_SHIFT);
 
 #ifdef CONFIG_BLK_DEV_INITRD
-	if (phys_initrd_size && initrd_node >= 0) {
-		reserve_bootmem_node(NODE_DATA(initrd_node), phys_initrd_start,
+	/*
+	 * If the initrd is in this node, reserve its memory.
+	 */
+	if (node == initrd_node) {
+		reserve_bootmem_node(pgdat, phys_initrd_start,
 				     phys_initrd_size);
 		initrd_start = __phys_to_virt(phys_initrd_start);
 		initrd_end = initrd_start + phys_initrd_size;
 	}
 #endif
 
-	BUG_ON(map_pg != bootmap_pfn + bootmap_pages);
+	/*
+	 * Finally, reserve any node zero regions.
+	 */
+	if (node == 0)
+		reserve_node_zero(pgdat);
+
+	/*
+	 * initialise the zones within this node.
+	 */
+	memset(zone_size, 0, sizeof(zone_size));
+	memset(zhole_size, 0, sizeof(zhole_size));
+
+	/*
+	 * The size of this node has already been determined.  If we need
+	 * to do anything fancy with the allocation of this memory to the
+	 * zones, now is the time to do it.
+	 */
+	zone_size[0] = end_pfn - start_pfn;
+
+	/*
+	 * For each bank in this node, calculate the size of the holes.
+	 *  holes = node_size - sum(bank_sizes_in_node)
+	 */
+	zhole_size[0] = zone_size[0];
+	for_each_nodebank(i, mi, node)
+		zhole_size[0] -= mi->bank[i].size >> PAGE_SHIFT;
+
+	/*
+	 * Adjust the sizes according to any special requirements for
+	 * this machine type.
+	 */
+	arch_adjust_zones(node, zone_size, zhole_size);
+
+	free_area_init_node(node, pgdat, zone_size, start_pfn, zhole_size);
+
+	return end_pfn;
 }
 
-/*
- * paging_init() sets up the page tables, initialises the zone memory
- * maps, and sets up the zero page, bad page and bad page tables.
- */
-void __init paging_init(struct meminfo *mi, struct machine_desc *mdesc)
+static void __init bootmem_init(struct meminfo *mi)
 {
-	void *zero_page;
-	int node;
+	unsigned long addr, memend_pfn = 0;
+	int node, initrd_node, i;
 
-	bootmem_init(mi);
+	/*
+	 * Invalidate the node number for empty or invalid memory banks
+	 */
+	for (i = 0; i < mi->nr_banks; i++)
+		if (mi->bank[i].size == 0 || mi->bank[i].node >= MAX_NUMNODES)
+			mi->bank[i].node = -1;
 
 	memcpy(&meminfo, mi, sizeof(meminfo));
 
+#ifdef CONFIG_XIP_KERNEL
+#error needs fixing
+	p->physical   = CONFIG_XIP_PHYS_ADDR & PMD_MASK;
+	p->virtual    = (unsigned long)&_stext & PMD_MASK;
+	p->length     = ((unsigned long)&_etext - p->virtual + ~PMD_MASK) & PMD_MASK;
+	p->type       = MT_ROM;
+	p ++;
+#endif
+
 	/*
-	 * allocate the zero page.  Note that we count on this going ok.
+	 * Clear out all the mappings below the kernel image.
+	 * FIXME: what about XIP?
 	 */
-	zero_page = alloc_bootmem_low_pages(PAGE_SIZE);
+	for (addr = 0; addr < PAGE_OFFSET; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
 
 	/*
-	 * initialise the page tables.
+	 * Clear out all the kernel space mappings, except for the first
+	 * memory bank, up to the end of the vmalloc region.
 	 */
-	memtable_init(mi);
-	if (mdesc->map_io)
-		mdesc->map_io();
-	local_flush_tlb_all();
+	for (addr = __phys_to_virt(mi->bank[0].start + mi->bank[0].size);
+	     addr < VMALLOC_END; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
 
 	/*
-	 * initialise the zones within each node
+	 * Locate which node contains the ramdisk image, if any.
 	 */
-	for_each_online_node(node) {
-		unsigned long zone_size[MAX_NR_ZONES];
-		unsigned long zhole_size[MAX_NR_ZONES];
-		struct bootmem_data *bdata;
-		pg_data_t *pgdat;
-		int i;
+	initrd_node = check_initrd(mi);
 
-		/*
-		 * Initialise the zone size information.
-		 */
-		for (i = 0; i < MAX_NR_ZONES; i++) {
-			zone_size[i]  = 0;
-			zhole_size[i] = 0;
-		}
+	/*
+	 * Run through each node initialising the bootmem allocator.
+	 */
+	for_each_node(node) {
+		unsigned long end_pfn;
 
-		pgdat = NODE_DATA(node);
-		bdata = pgdat->bdata;
+		end_pfn = bootmem_init_node(node, initrd_node, mi);
 
 		/*
-		 * The size of this node has already been determined.
-		 * If we need to do anything fancy with the allocation
-		 * of this memory to the zones, now is the time to do
-		 * it.
+		 * Remember the highest memory PFN.
 		 */
-		zone_size[0] = bdata->node_low_pfn -
-				(bdata->node_boot_start >> PAGE_SHIFT);
+		if (end_pfn > memend_pfn)
+			memend_pfn = end_pfn;
+	}
 
-		/*
-		 * If this zone has zero size, skip it.
-		 */
-		if (!zone_size[0])
-			continue;
+	high_memory = __va(memend_pfn << PAGE_SHIFT);
 
-		/*
-		 * For each bank in this node, calculate the size of the
-		 * holes.  holes = node_size - sum(bank_sizes_in_node)
-		 */
-		zhole_size[0] = zone_size[0];
-		for (i = 0; i < mi->nr_banks; i++) {
-			if (mi->bank[i].node != node)
-				continue;
+	/*
+	 * This doesn't seem to be used by the Linux memory manager any
+	 * more, but is used by ll_rw_block.  If we can get rid of it, we
+	 * also get rid of some of the stuff above as well.
+	 *
+	 * Note: max_low_pfn and max_pfn reflect the number of _pages_ in
+	 * the system, not the maximum PFN.
+	 */
+	max_pfn = max_low_pfn = memend_pfn - PHYS_PFN_OFFSET;
+}
 
-			zhole_size[0] -= mi->bank[i].size >> PAGE_SHIFT;
-		}
+/*
+ * Set up device the mappings.  Since we clear out the page tables for all
+ * mappings above VMALLOC_END, we will remove any debug device mappings.
+ * This means you have to be careful how you debug this function, or any
+ * called function.  (Do it by code inspection!)
+ */
+static void __init devicemaps_init(struct machine_desc *mdesc)
+{
+	struct map_desc map;
+	unsigned long addr;
+	void *vectors;
 
-		/*
-		 * Adjust the sizes according to any special
-		 * requirements for this machine type.
-		 */
-		arch_adjust_zones(node, zone_size, zhole_size);
+	for (addr = VMALLOC_END; addr; addr += PGDIR_SIZE)
+		pmd_clear(pmd_off_k(addr));
 
-		free_area_init_node(node, pgdat, zone_size,
-				bdata->node_boot_start >> PAGE_SHIFT, zhole_size);
+	/*
+	 * Map the cache flushing regions.
+	 */
+#ifdef FLUSH_BASE
+	map.physical = FLUSH_BASE_PHYS;
+	map.virtual = FLUSH_BASE;
+	map.length = PGDIR_SIZE;
+	map.type = MT_CACHECLEAN;
+	create_mapping(&map);
+#endif
+#ifdef FLUSH_BASE_MINICACHE
+	map.physical = FLUSH_BASE_PHYS + PGDIR_SIZE;
+	map.virtual = FLUSH_BASE_MINICACHE;
+	map.length = PGDIR_SIZE;
+	map.type = MT_MINICLEAN;
+	create_mapping(&map);
+#endif
+
+	flush_cache_all();
+	local_flush_tlb_all();
+
+	vectors = alloc_bootmem_low_pages(PAGE_SIZE);
+	BUG_ON(!vectors);
+
+	/*
+	 * Create a mapping for the machine vectors at the high-vectors
+	 * location (0xffff0000).  If we aren't using high-vectors, also
+	 * create a mapping at the low-vectors virtual address.
+	 */
+	map.physical = virt_to_phys(vectors);
+	map.virtual = 0xffff0000;
+	map.length = PAGE_SIZE;
+	map.type = MT_HIGH_VECTORS;
+	create_mapping(&map);
+
+	if (!vectors_high()) {
+		map.virtual = 0;
+		map.type = MT_LOW_VECTORS;
+		create_mapping(&map);
 	}
 
 	/*
-	 * finish off the bad pages once
-	 * the mem_map is initialised
+	 * Ask the machine support to map in the statically mapped devices.
+	 * After this point, we can start to touch devices again.
+	 */
+	if (mdesc->map_io)
+		mdesc->map_io();
+}
+
+/*
+ * paging_init() sets up the page tables, initialises the zone memory
+ * maps, and sets up the zero page, bad page and bad page tables.
+ */
+void __init paging_init(struct meminfo *mi, struct machine_desc *mdesc)
+{
+	void *zero_page;
+
+	build_mem_type_table();
+	bootmem_init(mi);
+	devicemaps_init(mdesc);
+
+	top_pmd = pmd_off_k(0xffff0000);
+
+	/*
+	 * allocate the zero page.  Note that we count on this going ok.
 	 */
+	zero_page = alloc_bootmem_low_pages(PAGE_SIZE);
 	memzero(zero_page, PAGE_SIZE);
 	empty_zero_page = virt_to_page(zero_page);
 	flush_dcache_page(empty_zero_page);
@@ -562,10 +563,7 @@ static void __init free_unused_memmap_node(int node, struct meminfo *mi)
 	 * may not be the case, especially if the user has provided the
 	 * information on the command line.
 	 */
-	for (i = 0; i < mi->nr_banks; i++) {
-		if (mi->bank[i].size == 0 || mi->bank[i].node != node)
-			continue;
-
+	for_each_nodebank(i, mi, node) {
 		bank_start = mi->bank[i].start >> PAGE_SHIFT;
 		if (bank_start < prev_bank_end) {
 			printk(KERN_ERR "MEM: unordered memory banks.  "

commit 564c90aa07cd43dc434d46cef8a15773a23d49a2
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Tue Jun 28 13:46:09 2005 +0100

    [PATCH] ARM SMP: Use local_flush_tlb* where we really want to be local
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 6dcb23d64bf5..edffa47a4b2a 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -437,7 +437,7 @@ void __init paging_init(struct meminfo *mi, struct machine_desc *mdesc)
 	memtable_init(mi);
 	if (mdesc->map_io)
 		mdesc->map_io();
-	flush_tlb_all();
+	local_flush_tlb_all();
 
 	/*
 	 * initialise the zones within each node

commit a013053d4965d9a45300938e713a4b512e0257d8
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Mon Jun 27 14:16:47 2005 +0100

    [PATCH] ARM: Move memmap freeing into init.c
    
    It doesn't make sense for this to be in mm-armv.c now that 26-bit
    ARM support is no longer integrated into arch/arm.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index c08710b1ff02..6dcb23d64bf5 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -522,6 +522,69 @@ static inline void free_area(unsigned long addr, unsigned long end, char *s)
 		printk(KERN_INFO "Freeing %s memory: %dK\n", s, size);
 }
 
+static inline void
+free_memmap(int node, unsigned long start_pfn, unsigned long end_pfn)
+{
+	struct page *start_pg, *end_pg;
+	unsigned long pg, pgend;
+
+	/*
+	 * Convert start_pfn/end_pfn to a struct page pointer.
+	 */
+	start_pg = pfn_to_page(start_pfn);
+	end_pg = pfn_to_page(end_pfn);
+
+	/*
+	 * Convert to physical addresses, and
+	 * round start upwards and end downwards.
+	 */
+	pg = PAGE_ALIGN(__pa(start_pg));
+	pgend = __pa(end_pg) & PAGE_MASK;
+
+	/*
+	 * If there are free pages between these,
+	 * free the section of the memmap array.
+	 */
+	if (pg < pgend)
+		free_bootmem_node(NODE_DATA(node), pg, pgend - pg);
+}
+
+/*
+ * The mem_map array can get very big.  Free the unused area of the memory map.
+ */
+static void __init free_unused_memmap_node(int node, struct meminfo *mi)
+{
+	unsigned long bank_start, prev_bank_end = 0;
+	unsigned int i;
+
+	/*
+	 * [FIXME] This relies on each bank being in address order.  This
+	 * may not be the case, especially if the user has provided the
+	 * information on the command line.
+	 */
+	for (i = 0; i < mi->nr_banks; i++) {
+		if (mi->bank[i].size == 0 || mi->bank[i].node != node)
+			continue;
+
+		bank_start = mi->bank[i].start >> PAGE_SHIFT;
+		if (bank_start < prev_bank_end) {
+			printk(KERN_ERR "MEM: unordered memory banks.  "
+				"Not freeing memmap.\n");
+			break;
+		}
+
+		/*
+		 * If we had a previous bank, and there is a space
+		 * between the current bank and the previous, free it.
+		 */
+		if (prev_bank_end && prev_bank_end != bank_start)
+			free_memmap(node, prev_bank_end, bank_start);
+
+		prev_bank_end = (mi->bank[i].start +
+				 mi->bank[i].size) >> PAGE_SHIFT;
+	}
+}
+
 /*
  * mem_init() marks the free areas in the mem_map and tells us how much
  * memory is free.  This is done after various parts of the system have
@@ -540,16 +603,12 @@ void __init mem_init(void)
 	max_mapnr   = virt_to_page(high_memory) - mem_map;
 #endif
 
-	/*
-	 * We may have non-contiguous memory.
-	 */
-	if (meminfo.nr_banks != 1)
-		create_memmap_holes(&meminfo);
-
 	/* this will put all unused low memory onto the freelists */
 	for_each_online_node(node) {
 		pg_data_t *pgdat = NODE_DATA(node);
 
+		free_unused_memmap_node(node, &meminfo);
+
 		if (pgdat->node_spanned_pages != 0)
 			totalram_pages += free_all_bootmem_node(pgdat);
 	}

commit 92a8cbed29eb9bf6e8eec16ca29d54015bc0e8a2
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Wed Jun 22 21:47:25 2005 +0100

    [PATCH] ARM: Remove explicit page-alignments in memory init
    
    Since meminfo.bank[] array contains page-aligned start/size, we
    no longer need to explicitly round up/down the addresses when
    converting to PFNs.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 72a2b8cee319..c08710b1ff02 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -93,14 +93,7 @@ struct node_info {
 };
 
 #define O_PFN_DOWN(x)	((x) >> PAGE_SHIFT)
-#define V_PFN_DOWN(x)	O_PFN_DOWN(__pa(x))
-
 #define O_PFN_UP(x)	(PAGE_ALIGN(x) >> PAGE_SHIFT)
-#define V_PFN_UP(x)	O_PFN_UP(__pa(x))
-
-#define PFN_SIZE(x)	((x) >> PAGE_SHIFT)
-#define PFN_RANGE(s,e)	PFN_SIZE(PAGE_ALIGN((unsigned long)(e)) - \
-				(((unsigned long)(s)) & PAGE_MASK))
 
 /*
  * FIXME: We really want to avoid allocating the bootmap bitmap
@@ -113,7 +106,7 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 {
 	unsigned int start_pfn, bank, bootmap_pfn;
 
-	start_pfn   = V_PFN_UP(&_end);
+	start_pfn   = O_PFN_UP(__pa(&_end));
 	bootmap_pfn = 0;
 
 	for (bank = 0; bank < mi->nr_banks; bank ++) {
@@ -122,9 +115,9 @@ find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
 		if (mi->bank[bank].node != node)
 			continue;
 
-		start = O_PFN_UP(mi->bank[bank].start);
-		end   = O_PFN_DOWN(mi->bank[bank].size +
-				   mi->bank[bank].start);
+		start = mi->bank[bank].start >> PAGE_SHIFT;
+		end   = (mi->bank[bank].size +
+			 mi->bank[bank].start) >> PAGE_SHIFT;
 
 		if (end < start_pfn)
 			continue;
@@ -191,8 +184,8 @@ find_memend_and_nodes(struct meminfo *mi, struct node_info *np)
 		/*
 		 * Get the start and end pfns for this bank
 		 */
-		start = O_PFN_UP(mi->bank[i].start);
-		end   = O_PFN_DOWN(mi->bank[i].start + mi->bank[i].size);
+		start = mi->bank[i].start >> PAGE_SHIFT;
+		end   = (mi->bank[i].start + mi->bank[i].size) >> PAGE_SHIFT;
 
 		if (np[node].start > start)
 			np[node].start = start;

commit d42ce812b8a32adddeee3a692005f82f95ff15a3
Author: akpm@osdl.org <akpm@osdl.org>
Date:   Sat Apr 16 15:23:57 2005 -0700

    [PATCH] arm: add comment about max_low_pfn/max_pfn
    
    )
    
    
    From: Russell King <rmk+lkml@arm.linux.org.uk>
    
    Oddly, max_low_pfn/max_pfn end up being the number of pages in the system,
    rather than the maximum PFN on ARM.  This doesn't seem to cause any problems,
    so just add a note about it.
    
    Signed-off-by: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
index 41156c5370f7..72a2b8cee319 100644
--- a/arch/arm/mm/init.c
+++ b/arch/arm/mm/init.c
@@ -223,6 +223,9 @@ find_memend_and_nodes(struct meminfo *mi, struct node_info *np)
 	 * This doesn't seem to be used by the Linux memory
 	 * manager any more.  If we can get rid of it, we
 	 * also get rid of some of the stuff above as well.
+	 *
+	 * Note: max_low_pfn and max_pfn reflect the number
+	 * of _pages_ in the system, not the maximum PFN.
 	 */
 	max_low_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);
 	max_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c
new file mode 100644
index 000000000000..41156c5370f7
--- /dev/null
+++ b/arch/arm/mm/init.c
@@ -0,0 +1,621 @@
+/*
+ *  linux/arch/arm/mm/init.c
+ *
+ *  Copyright (C) 1995-2002 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/ptrace.h>
+#include <linux/swap.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <linux/mman.h>
+#include <linux/nodemask.h>
+#include <linux/initrd.h>
+
+#include <asm/mach-types.h>
+#include <asm/hardware.h>
+#include <asm/setup.h>
+#include <asm/tlb.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+
+#define TABLE_SIZE	(2 * PTRS_PER_PTE * sizeof(pte_t))
+
+DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
+
+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
+extern void _stext, _text, _etext, __data_start, _end, __init_begin, __init_end;
+extern unsigned long phys_initrd_start;
+extern unsigned long phys_initrd_size;
+
+/*
+ * The sole use of this is to pass memory configuration
+ * data from paging_init to mem_init.
+ */
+static struct meminfo meminfo __initdata = { 0, };
+
+/*
+ * empty_zero_page is a special page that is used for
+ * zero-initialized data and COW.
+ */
+struct page *empty_zero_page;
+
+void show_mem(void)
+{
+	int free = 0, total = 0, reserved = 0;
+	int shared = 0, cached = 0, slab = 0, node;
+
+	printk("Mem-info:\n");
+	show_free_areas();
+	printk("Free swap:       %6ldkB\n", nr_swap_pages<<(PAGE_SHIFT-10));
+
+	for_each_online_node(node) {
+		struct page *page, *end;
+
+		page = NODE_MEM_MAP(node);
+		end  = page + NODE_DATA(node)->node_spanned_pages;
+
+		do {
+			total++;
+			if (PageReserved(page))
+				reserved++;
+			else if (PageSwapCache(page))
+				cached++;
+			else if (PageSlab(page))
+				slab++;
+			else if (!page_count(page))
+				free++;
+			else
+				shared += page_count(page) - 1;
+			page++;
+		} while (page < end);
+	}
+
+	printk("%d pages of RAM\n", total);
+	printk("%d free pages\n", free);
+	printk("%d reserved pages\n", reserved);
+	printk("%d slab pages\n", slab);
+	printk("%d pages shared\n", shared);
+	printk("%d pages swap cached\n", cached);
+}
+
+struct node_info {
+	unsigned int start;
+	unsigned int end;
+	int bootmap_pages;
+};
+
+#define O_PFN_DOWN(x)	((x) >> PAGE_SHIFT)
+#define V_PFN_DOWN(x)	O_PFN_DOWN(__pa(x))
+
+#define O_PFN_UP(x)	(PAGE_ALIGN(x) >> PAGE_SHIFT)
+#define V_PFN_UP(x)	O_PFN_UP(__pa(x))
+
+#define PFN_SIZE(x)	((x) >> PAGE_SHIFT)
+#define PFN_RANGE(s,e)	PFN_SIZE(PAGE_ALIGN((unsigned long)(e)) - \
+				(((unsigned long)(s)) & PAGE_MASK))
+
+/*
+ * FIXME: We really want to avoid allocating the bootmap bitmap
+ * over the top of the initrd.  Hopefully, this is located towards
+ * the start of a bank, so if we allocate the bootmap bitmap at
+ * the end, we won't clash.
+ */
+static unsigned int __init
+find_bootmap_pfn(int node, struct meminfo *mi, unsigned int bootmap_pages)
+{
+	unsigned int start_pfn, bank, bootmap_pfn;
+
+	start_pfn   = V_PFN_UP(&_end);
+	bootmap_pfn = 0;
+
+	for (bank = 0; bank < mi->nr_banks; bank ++) {
+		unsigned int start, end;
+
+		if (mi->bank[bank].node != node)
+			continue;
+
+		start = O_PFN_UP(mi->bank[bank].start);
+		end   = O_PFN_DOWN(mi->bank[bank].size +
+				   mi->bank[bank].start);
+
+		if (end < start_pfn)
+			continue;
+
+		if (start < start_pfn)
+			start = start_pfn;
+
+		if (end <= start)
+			continue;
+
+		if (end - start >= bootmap_pages) {
+			bootmap_pfn = start;
+			break;
+		}
+	}
+
+	if (bootmap_pfn == 0)
+		BUG();
+
+	return bootmap_pfn;
+}
+
+/*
+ * Scan the memory info structure and pull out:
+ *  - the end of memory
+ *  - the number of nodes
+ *  - the pfn range of each node
+ *  - the number of bootmem bitmap pages
+ */
+static unsigned int __init
+find_memend_and_nodes(struct meminfo *mi, struct node_info *np)
+{
+	unsigned int i, bootmem_pages = 0, memend_pfn = 0;
+
+	for (i = 0; i < MAX_NUMNODES; i++) {
+		np[i].start = -1U;
+		np[i].end = 0;
+		np[i].bootmap_pages = 0;
+	}
+
+	for (i = 0; i < mi->nr_banks; i++) {
+		unsigned long start, end;
+		int node;
+
+		if (mi->bank[i].size == 0) {
+			/*
+			 * Mark this bank with an invalid node number
+			 */
+			mi->bank[i].node = -1;
+			continue;
+		}
+
+		node = mi->bank[i].node;
+
+		/*
+		 * Make sure we haven't exceeded the maximum number of nodes
+		 * that we have in this configuration.  If we have, we're in
+		 * trouble.  (maybe we ought to limit, instead of bugging?)
+		 */
+		if (node >= MAX_NUMNODES)
+			BUG();
+		node_set_online(node);
+
+		/*
+		 * Get the start and end pfns for this bank
+		 */
+		start = O_PFN_UP(mi->bank[i].start);
+		end   = O_PFN_DOWN(mi->bank[i].start + mi->bank[i].size);
+
+		if (np[node].start > start)
+			np[node].start = start;
+
+		if (np[node].end < end)
+			np[node].end = end;
+
+		if (memend_pfn < end)
+			memend_pfn = end;
+	}
+
+	/*
+	 * Calculate the number of pages we require to
+	 * store the bootmem bitmaps.
+	 */
+	for_each_online_node(i) {
+		if (np[i].end == 0)
+			continue;
+
+		np[i].bootmap_pages = bootmem_bootmap_pages(np[i].end -
+							    np[i].start);
+		bootmem_pages += np[i].bootmap_pages;
+	}
+
+	high_memory = __va(memend_pfn << PAGE_SHIFT);
+
+	/*
+	 * This doesn't seem to be used by the Linux memory
+	 * manager any more.  If we can get rid of it, we
+	 * also get rid of some of the stuff above as well.
+	 */
+	max_low_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);
+	max_pfn = memend_pfn - O_PFN_DOWN(PHYS_OFFSET);
+
+	return bootmem_pages;
+}
+
+static int __init check_initrd(struct meminfo *mi)
+{
+	int initrd_node = -2;
+#ifdef CONFIG_BLK_DEV_INITRD
+	unsigned long end = phys_initrd_start + phys_initrd_size;
+
+	/*
+	 * Make sure that the initrd is within a valid area of
+	 * memory.
+	 */
+	if (phys_initrd_size) {
+		unsigned int i;
+
+		initrd_node = -1;
+
+		for (i = 0; i < mi->nr_banks; i++) {
+			unsigned long bank_end;
+
+			bank_end = mi->bank[i].start + mi->bank[i].size;
+
+			if (mi->bank[i].start <= phys_initrd_start &&
+			    end <= bank_end)
+				initrd_node = mi->bank[i].node;
+		}
+	}
+
+	if (initrd_node == -1) {
+		printk(KERN_ERR "initrd (0x%08lx - 0x%08lx) extends beyond "
+		       "physical memory - disabling initrd\n",
+		       phys_initrd_start, end);
+		phys_initrd_start = phys_initrd_size = 0;
+	}
+#endif
+
+	return initrd_node;
+}
+
+/*
+ * Reserve the various regions of node 0
+ */
+static __init void reserve_node_zero(unsigned int bootmap_pfn, unsigned int bootmap_pages)
+{
+	pg_data_t *pgdat = NODE_DATA(0);
+	unsigned long res_size = 0;
+
+	/*
+	 * Register the kernel text and data with bootmem.
+	 * Note that this can only be in node 0.
+	 */
+#ifdef CONFIG_XIP_KERNEL
+	reserve_bootmem_node(pgdat, __pa(&__data_start), &_end - &__data_start);
+#else
+	reserve_bootmem_node(pgdat, __pa(&_stext), &_end - &_stext);
+#endif
+
+	/*
+	 * Reserve the page tables.  These are already in use,
+	 * and can only be in node 0.
+	 */
+	reserve_bootmem_node(pgdat, __pa(swapper_pg_dir),
+			     PTRS_PER_PGD * sizeof(pgd_t));
+
+	/*
+	 * And don't forget to reserve the allocator bitmap,
+	 * which will be freed later.
+	 */
+	reserve_bootmem_node(pgdat, bootmap_pfn << PAGE_SHIFT,
+			     bootmap_pages << PAGE_SHIFT);
+
+	/*
+	 * Hmm... This should go elsewhere, but we really really need to
+	 * stop things allocating the low memory; ideally we need a better
+	 * implementation of GFP_DMA which does not assume that DMA-able
+	 * memory starts at zero.
+	 */
+	if (machine_is_integrator() || machine_is_cintegrator())
+		res_size = __pa(swapper_pg_dir) - PHYS_OFFSET;
+
+	/*
+	 * These should likewise go elsewhere.  They pre-reserve the
+	 * screen memory region at the start of main system memory.
+	 */
+	if (machine_is_edb7211())
+		res_size = 0x00020000;
+	if (machine_is_p720t())
+		res_size = 0x00014000;
+
+#ifdef CONFIG_SA1111
+	/*
+	 * Because of the SA1111 DMA bug, we want to preserve our
+	 * precious DMA-able memory...
+	 */
+	res_size = __pa(swapper_pg_dir) - PHYS_OFFSET;
+#endif
+	if (res_size)
+		reserve_bootmem_node(pgdat, PHYS_OFFSET, res_size);
+}
+
+/*
+ * Register all available RAM in this node with the bootmem allocator.
+ */
+static inline void free_bootmem_node_bank(int node, struct meminfo *mi)
+{
+	pg_data_t *pgdat = NODE_DATA(node);
+	int bank;
+
+	for (bank = 0; bank < mi->nr_banks; bank++)
+		if (mi->bank[bank].node == node)
+			free_bootmem_node(pgdat, mi->bank[bank].start,
+					  mi->bank[bank].size);
+}
+
+/*
+ * Initialise the bootmem allocator for all nodes.  This is called
+ * early during the architecture specific initialisation.
+ */
+static void __init bootmem_init(struct meminfo *mi)
+{
+	struct node_info node_info[MAX_NUMNODES], *np = node_info;
+	unsigned int bootmap_pages, bootmap_pfn, map_pg;
+	int node, initrd_node;
+
+	bootmap_pages = find_memend_and_nodes(mi, np);
+	bootmap_pfn   = find_bootmap_pfn(0, mi, bootmap_pages);
+	initrd_node   = check_initrd(mi);
+
+	map_pg = bootmap_pfn;
+
+	/*
+	 * Initialise the bootmem nodes.
+	 *
+	 * What we really want to do is:
+	 *
+	 *   unmap_all_regions_except_kernel();
+	 *   for_each_node_in_reverse_order(node) {
+	 *     map_node(node);
+	 *     allocate_bootmem_map(node);
+	 *     init_bootmem_node(node);
+	 *     free_bootmem_node(node);
+	 *   }
+	 *
+	 * but this is a 2.5-type change.  For now, we just set
+	 * the nodes up in reverse order.
+	 *
+	 * (we could also do with rolling bootmem_init and paging_init
+	 * into one generic "memory_init" type function).
+	 */
+	np += num_online_nodes() - 1;
+	for (node = num_online_nodes() - 1; node >= 0; node--, np--) {
+		/*
+		 * If there are no pages in this node, ignore it.
+		 * Note that node 0 must always have some pages.
+		 */
+		if (np->end == 0 || !node_online(node)) {
+			if (node == 0)
+				BUG();
+			continue;
+		}
+
+		/*
+		 * Initialise the bootmem allocator.
+		 */
+		init_bootmem_node(NODE_DATA(node), map_pg, np->start, np->end);
+		free_bootmem_node_bank(node, mi);
+		map_pg += np->bootmap_pages;
+
+		/*
+		 * If this is node 0, we need to reserve some areas ASAP -
+		 * we may use bootmem on node 0 to setup the other nodes.
+		 */
+		if (node == 0)
+			reserve_node_zero(bootmap_pfn, bootmap_pages);
+	}
+
+
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (phys_initrd_size && initrd_node >= 0) {
+		reserve_bootmem_node(NODE_DATA(initrd_node), phys_initrd_start,
+				     phys_initrd_size);
+		initrd_start = __phys_to_virt(phys_initrd_start);
+		initrd_end = initrd_start + phys_initrd_size;
+	}
+#endif
+
+	BUG_ON(map_pg != bootmap_pfn + bootmap_pages);
+}
+
+/*
+ * paging_init() sets up the page tables, initialises the zone memory
+ * maps, and sets up the zero page, bad page and bad page tables.
+ */
+void __init paging_init(struct meminfo *mi, struct machine_desc *mdesc)
+{
+	void *zero_page;
+	int node;
+
+	bootmem_init(mi);
+
+	memcpy(&meminfo, mi, sizeof(meminfo));
+
+	/*
+	 * allocate the zero page.  Note that we count on this going ok.
+	 */
+	zero_page = alloc_bootmem_low_pages(PAGE_SIZE);
+
+	/*
+	 * initialise the page tables.
+	 */
+	memtable_init(mi);
+	if (mdesc->map_io)
+		mdesc->map_io();
+	flush_tlb_all();
+
+	/*
+	 * initialise the zones within each node
+	 */
+	for_each_online_node(node) {
+		unsigned long zone_size[MAX_NR_ZONES];
+		unsigned long zhole_size[MAX_NR_ZONES];
+		struct bootmem_data *bdata;
+		pg_data_t *pgdat;
+		int i;
+
+		/*
+		 * Initialise the zone size information.
+		 */
+		for (i = 0; i < MAX_NR_ZONES; i++) {
+			zone_size[i]  = 0;
+			zhole_size[i] = 0;
+		}
+
+		pgdat = NODE_DATA(node);
+		bdata = pgdat->bdata;
+
+		/*
+		 * The size of this node has already been determined.
+		 * If we need to do anything fancy with the allocation
+		 * of this memory to the zones, now is the time to do
+		 * it.
+		 */
+		zone_size[0] = bdata->node_low_pfn -
+				(bdata->node_boot_start >> PAGE_SHIFT);
+
+		/*
+		 * If this zone has zero size, skip it.
+		 */
+		if (!zone_size[0])
+			continue;
+
+		/*
+		 * For each bank in this node, calculate the size of the
+		 * holes.  holes = node_size - sum(bank_sizes_in_node)
+		 */
+		zhole_size[0] = zone_size[0];
+		for (i = 0; i < mi->nr_banks; i++) {
+			if (mi->bank[i].node != node)
+				continue;
+
+			zhole_size[0] -= mi->bank[i].size >> PAGE_SHIFT;
+		}
+
+		/*
+		 * Adjust the sizes according to any special
+		 * requirements for this machine type.
+		 */
+		arch_adjust_zones(node, zone_size, zhole_size);
+
+		free_area_init_node(node, pgdat, zone_size,
+				bdata->node_boot_start >> PAGE_SHIFT, zhole_size);
+	}
+
+	/*
+	 * finish off the bad pages once
+	 * the mem_map is initialised
+	 */
+	memzero(zero_page, PAGE_SIZE);
+	empty_zero_page = virt_to_page(zero_page);
+	flush_dcache_page(empty_zero_page);
+}
+
+static inline void free_area(unsigned long addr, unsigned long end, char *s)
+{
+	unsigned int size = (end - addr) >> 10;
+
+	for (; addr < end; addr += PAGE_SIZE) {
+		struct page *page = virt_to_page(addr);
+		ClearPageReserved(page);
+		set_page_count(page, 1);
+		free_page(addr);
+		totalram_pages++;
+	}
+
+	if (size && s)
+		printk(KERN_INFO "Freeing %s memory: %dK\n", s, size);
+}
+
+/*
+ * mem_init() marks the free areas in the mem_map and tells us how much
+ * memory is free.  This is done after various parts of the system have
+ * claimed their memory after the kernel image.
+ */
+void __init mem_init(void)
+{
+	unsigned int codepages, datapages, initpages;
+	int i, node;
+
+	codepages = &_etext - &_text;
+	datapages = &_end - &__data_start;
+	initpages = &__init_end - &__init_begin;
+
+#ifndef CONFIG_DISCONTIGMEM
+	max_mapnr   = virt_to_page(high_memory) - mem_map;
+#endif
+
+	/*
+	 * We may have non-contiguous memory.
+	 */
+	if (meminfo.nr_banks != 1)
+		create_memmap_holes(&meminfo);
+
+	/* this will put all unused low memory onto the freelists */
+	for_each_online_node(node) {
+		pg_data_t *pgdat = NODE_DATA(node);
+
+		if (pgdat->node_spanned_pages != 0)
+			totalram_pages += free_all_bootmem_node(pgdat);
+	}
+
+#ifdef CONFIG_SA1111
+	/* now that our DMA memory is actually so designated, we can free it */
+	free_area(PAGE_OFFSET, (unsigned long)swapper_pg_dir, NULL);
+#endif
+
+	/*
+	 * Since our memory may not be contiguous, calculate the
+	 * real number of pages we have in this system
+	 */
+	printk(KERN_INFO "Memory:");
+
+	num_physpages = 0;
+	for (i = 0; i < meminfo.nr_banks; i++) {
+		num_physpages += meminfo.bank[i].size >> PAGE_SHIFT;
+		printk(" %ldMB", meminfo.bank[i].size >> 20);
+	}
+
+	printk(" = %luMB total\n", num_physpages >> (20 - PAGE_SHIFT));
+	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
+		"%dK data, %dK init)\n",
+		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		codepages >> 10, datapages >> 10, initpages >> 10);
+
+	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
+		extern int sysctl_overcommit_memory;
+		/*
+		 * On a machine this small we won't get
+		 * anywhere without overcommit, so turn
+		 * it on by default.
+		 */
+		sysctl_overcommit_memory = OVERCOMMIT_ALWAYS;
+	}
+}
+
+void free_initmem(void)
+{
+	if (!machine_is_integrator() && !machine_is_cintegrator()) {
+		free_area((unsigned long)(&__init_begin),
+			  (unsigned long)(&__init_end),
+			  "init");
+	}
+}
+
+#ifdef CONFIG_BLK_DEV_INITRD
+
+static int keep_initrd;
+
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+	if (!keep_initrd)
+		free_area(start, end, "initrd");
+}
+
+static int __init keepinitrd_setup(char *__unused)
+{
+	keep_initrd = 1;
+	return 1;
+}
+
+__setup("keepinitrd", keepinitrd_setup);
+#endif
