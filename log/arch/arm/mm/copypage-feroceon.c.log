commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index cc819732d9b8..064b19e63571 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/arch/arm/mm/copypage-feroceon.S
  *
  *  Copyright (C) 2008 Marvell Semiconductors
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
  * This handles copy_user_highpage and clear_user_page on Feroceon
  * more optimally than the generic implementations.
  */

commit b99afae1390140f5b0039e6b37a7380de31ae874
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Wed Nov 7 17:49:00 2018 +0100

    ARM: 8805/2: remove unneeded naked function usage
    
    The naked attribute is known to confuse some old gcc versions when
    function arguments aren't explicitly listed as inline assembly operands
    despite the gcc documentation. That resulted in commit 9a40ac86152c
    ("ARM: 6164/1: Add kto and kfrom to input operands list.").
    
    Yet that commit has problems of its own by having assembly operand
    constraints completely wrong. If the generated code has been OK since
    then, it is due to luck rather than correctness. So this patch also
    provides proper assembly operand constraints, and removes two instances
    of redundant register usages in the implementation while at it.
    
    Inspection of the generated code with this patch doesn't show any
    obvious quality degradation either, so not relying on __naked at all
    will make the code less fragile, and avoid some issues with clang.
    
    The only remaining __naked instances (excluding the kprobes test cases)
    are exynos_pm_power_up_setup(), tc2_pm_power_up_setup() and
    
    cci_enable_port_for_self(. But in the first two cases, only the function
    address is used by the compiler with no chance of inlining it by
    mistake, and the third case is called from assembly code only. And the
    fact that no stack is available when the corresponding code is executed
    does warrant the __naked usage in those cases.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Reviewed-by: Stefan Agner <stefan@agner.ch>
    Tested-by: Stefan Agner <stefan@agner.ch>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index 49ee0c1a7209..cc819732d9b8 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -13,58 +13,56 @@
 #include <linux/init.h>
 #include <linux/highmem.h>
 
-static void __naked
-feroceon_copy_user_page(void *kto, const void *kfrom)
+static void feroceon_copy_user_page(void *kto, const void *kfrom)
 {
-	asm("\
-	stmfd	sp!, {r4-r9, lr}		\n\
-	mov	ip, %2				\n\
-1:	mov	lr, r1				\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	pld	[lr, #32]			\n\
-	pld	[lr, #64]			\n\
-	pld	[lr, #96]			\n\
-	pld	[lr, #128]			\n\
-	pld	[lr, #160]			\n\
-	pld	[lr, #192]			\n\
-	pld	[lr, #224]			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	ldmia	r1!, {r2 - r9}			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
-	stmia	r0, {r2 - r9}			\n\
-	subs	ip, ip, #(32 * 8)		\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
+	int tmp;
+
+	asm volatile ("\
+1:	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	pld	[%1, #0]			\n\
+	pld	[%1, #32]			\n\
+	pld	[%1, #64]			\n\
+	pld	[%1, #96]			\n\
+	pld	[%1, #128]			\n\
+	pld	[%1, #160]			\n\
+	pld	[%1, #192]			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	ldmia	%1!, {r2 - r7, ip, lr}		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
+	stmia	%0, {r2 - r7, ip, lr}		\n\
+	subs	%2, %2, #(32 * 8)		\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	%0, %0, #32			\n\
 	bne	1b				\n\
-	mcr	p15, 0, ip, c7, c10, 4		@ drain WB\n\
-	ldmfd	sp!, {r4-r9, pc}"
-	:
-	: "r" (kto), "r" (kfrom), "I" (PAGE_SIZE));
+	mcr	p15, 0, %2, c7, c10, 4		@ drain WB"
+	: "+&r" (kto), "+&r" (kfrom), "=&r" (tmp)
+	: "2" (PAGE_SIZE)
+	: "r2", "r3", "r4", "r5", "r6", "r7", "ip", "lr");
 }
 
 void feroceon_copy_user_highpage(struct page *to, struct page *from,

commit 5472e862de2bc4a47f18d216a4a626d5c7eeef90
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:15 2011 +0800

    arm: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index ac163de7dc01..49ee0c1a7209 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -72,17 +72,17 @@ void feroceon_copy_user_highpage(struct page *to, struct page *from,
 {
 	void *kto, *kfrom;
 
-	kto = kmap_atomic(to, KM_USER0);
-	kfrom = kmap_atomic(from, KM_USER1);
+	kto = kmap_atomic(to);
+	kfrom = kmap_atomic(from);
 	flush_cache_page(vma, vaddr, page_to_pfn(from));
 	feroceon_copy_user_page(kto, kfrom);
-	kunmap_atomic(kfrom, KM_USER1);
-	kunmap_atomic(kto, KM_USER0);
+	kunmap_atomic(kfrom);
+	kunmap_atomic(kto);
 }
 
 void feroceon_clear_user_highpage(struct page *page, unsigned long vaddr)
 {
-	void *ptr, *kaddr = kmap_atomic(page, KM_USER0);
+	void *ptr, *kaddr = kmap_atomic(page);
 	asm volatile ("\
 	mov	r1, %2				\n\
 	mov	r2, #0				\n\
@@ -102,7 +102,7 @@ void feroceon_clear_user_highpage(struct page *page, unsigned long vaddr)
 	: "=r" (ptr)
 	: "0" (kaddr), "I" (PAGE_SIZE / 32)
 	: "r1", "r2", "r3", "r4", "r5", "r6", "r7", "ip", "lr");
-	kunmap_atomic(kaddr, KM_USER0);
+	kunmap_atomic(kaddr);
 }
 
 struct cpu_user_fns feroceon_user_fns __initdata = {

commit 9a40ac86152c9cffd3dca482a15ddf9a8c5716b3
Author: Khem Raj <raj.khem@gmail.com>
Date:   Fri Jun 4 04:05:15 2010 +0100

    ARM: 6164/1: Add kto and kfrom to input operands list.
    
    When functions incoming parameters are not in input operands list gcc
    4.5 does not load the parameters into registers before calling this
    function but the inline assembly assumes valid addresses inside this
    function. This breaks the code because r0 and r1 are invalid when
    execution enters v4wb_copy_user_page ()
    
    Also the constant needs to be used as third input operand so account
    for that as well.
    
    Tested on qemu arm.
    
    CC: <stable@kernel.org>
    Signed-off-by: Khem Raj <raj.khem@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index 5eb4fd93893d..ac163de7dc01 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -18,7 +18,7 @@ feroceon_copy_user_page(void *kto, const void *kfrom)
 {
 	asm("\
 	stmfd	sp!, {r4-r9, lr}		\n\
-	mov	ip, %0				\n\
+	mov	ip, %2				\n\
 1:	mov	lr, r1				\n\
 	ldmia	r1!, {r2 - r9}			\n\
 	pld	[lr, #32]			\n\
@@ -64,7 +64,7 @@ feroceon_copy_user_page(void *kto, const void *kfrom)
 	mcr	p15, 0, ip, c7, c10, 4		@ drain WB\n\
 	ldmfd	sp!, {r4-r9, pc}"
 	:
-	: "I" (PAGE_SIZE));
+	: "r" (kto), "r" (kfrom), "I" (PAGE_SIZE));
 }
 
 void feroceon_copy_user_highpage(struct page *to, struct page *from,

commit 2725898fc9bb2121ac0fb1b5e4faf4fc09014729
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Oct 5 15:34:22 2009 +0100

    ARM: Flush user mapping on VIVT processors when copying a page
    
    Steven Walter <stevenrwalter@gmail.com> writes:
    > I've been tracking down an instance of userspace data corruption,
    > and I believe I have found a window during fork where data can be
    > lost.  The corruption is occurring on an ARMv5 system with VIVT
    > caches.  Here's the scenario in question.  Thread A is forking,
    > Thread B is running in userspace:
    >
    > Thread A: flush_cache_mm() (dup_mmap)
    > Thread B: writes to a page in the above mm
    > Thread A: pte_wrprotect() the above page (copy_one_pte)
    > Thread B: writes to the same page again
    >
    > During thread B's second write, he'll take a fault and enter the
    > do_wp_page() case.  We'll end up calling copy_page(), which notably
    > uses the kernel virtual addresses for the old and new pages.  This
    > means that the new page does not necessarily have the data from the
    > first write.  Now there are two conflicting copies of the same
    > cache-line in dcache.  If the userspace cache-line flushes before
    > the kernel cache-line, we lose the changes made during the first
    > write.  do_wp_page does call flush_dcache_page on the newly-copied
    > page, but there's still a window where the CPU could flush the
    > userspace cache-line before then.
    
    Resolve this by flushing the user mapping before copying the page
    on processors with a writeback VIVT cache.
    
    Note: this does have a performance impact, and so needs further
    consideration before being merged - can we optimize out some of
    the cache flushes if, eg, we know that the page isn't yet mapped?
    
    Thread: <e06498070903061426o5875ad13hc6328aa0d3f08ed7@mail.gmail.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index e2e8d29c548b..5eb4fd93893d 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -74,6 +74,7 @@ void feroceon_copy_user_highpage(struct page *to, struct page *from,
 
 	kto = kmap_atomic(to, KM_USER0);
 	kfrom = kmap_atomic(from, KM_USER1);
+	flush_cache_page(vma, vaddr, page_to_pfn(from));
 	feroceon_copy_user_page(kto, kfrom);
 	kunmap_atomic(kfrom, KM_USER1);
 	kunmap_atomic(kto, KM_USER0);

commit f00a75c094c340c4e7435665816c3273c870e849
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Oct 5 15:17:45 2009 +0100

    ARM: Pass VMA to copy_user_highpage() implementations
    
    Our copy_user_highpage() implementations may require cache maintainence.
    Ensure that implementations have all necessary details to perform this
    maintainence.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index 70997d5bee2d..e2e8d29c548b 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -68,7 +68,7 @@ feroceon_copy_user_page(void *kto, const void *kfrom)
 }
 
 void feroceon_copy_user_highpage(struct page *to, struct page *from,
-	unsigned long vaddr)
+	unsigned long vaddr, struct vm_area_struct *vma)
 {
 	void *kto, *kfrom;
 

commit 446c92b2901bedb3725d29b4e73def8aba623ffc
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Thu Mar 12 18:03:16 2009 +0100

    [ARM] 5421/1: ftrace: fix crash due to tracing of __naked functions
    
    This is a fix for the following crash observed in 2.6.29-rc3:
    http://lkml.org/lkml/2009/1/29/150
    
    On ARM it doesn't make sense to trace a naked function because then
    mcount is called without stack and frame pointer being set up and there
    is no chance to restore the lr register to the value before mcount was
    called.
    
    Reported-by: Matthias Kaehlcke <matthias@kaehlcke.net>
    Tested-by: Matthias Kaehlcke <matthias@kaehlcke.net>
    
    Cc: Abhishek Sagar <sagar.abhishek@gmail.com>
    Cc: Steven Rostedt <rostedt@home.goodmis.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index c3ba6a94da0c..70997d5bee2d 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -13,7 +13,7 @@
 #include <linux/init.h>
 #include <linux/highmem.h>
 
-static void __attribute__((naked))
+static void __naked
 feroceon_copy_user_page(void *kto, const void *kfrom)
 {
 	asm("\

commit 43ae286b7d4d8c4983bc263ef2e3cccc10dedb2b
Author: Nicolas Pitre <nico@cam.org>
Date:   Tue Nov 4 02:42:27 2008 -0500

    [ARM] fix a couple clear_user_highpage assembly constraints
    
    In all cases the kaddr is assigned an input register even though it is
    modified in the assembly code.  Let's assign a new variable to the
    modified value and mark those inline asm with volatile otherwise they
    get optimized away because the output variable is otherwise not used.
    
    Also fix a few conversion errors in copypage-feroceon.c and
    copypage-v4mc.c.
    
    Signed-off-by: Nicolas Pitre <nico@marvell.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index c3651b2939c7..c3ba6a94da0c 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -81,9 +81,9 @@ void feroceon_copy_user_highpage(struct page *to, struct page *from,
 
 void feroceon_clear_user_highpage(struct page *page, unsigned long vaddr)
 {
-	void *kaddr = kmap_atomic(page, KM_USER0);
-	asm("\
-	mov	r1, %1				\n\
+	void *ptr, *kaddr = kmap_atomic(page, KM_USER0);
+	asm volatile ("\
+	mov	r1, %2				\n\
 	mov	r2, #0				\n\
 	mov	r3, #0				\n\
 	mov	r4, #0				\n\
@@ -95,11 +95,11 @@ void feroceon_clear_user_highpage(struct page *page, unsigned long vaddr)
 1:	stmia	%0, {r2-r7, ip, lr}		\n\
 	subs	r1, r1, #1			\n\
 	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
-	add	r0, r0, #32			\n\
+	add	%0, %0, #32			\n\
 	bne	1b				\n\
 	mcr	p15, 0, r1, c7, c10, 4		@ drain WB"
-	:
-	: "r" (kaddr), "I" (PAGE_SIZE / 32)
+	: "=r" (ptr)
+	: "0" (kaddr), "I" (PAGE_SIZE / 32)
 	: "r1", "r2", "r3", "r4", "r5", "r6", "r7", "ip", "lr");
 	kunmap_atomic(kaddr, KM_USER0);
 }

commit 303c6443659bc1dc911356f5de149f48ff1d97b8
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Fri Oct 31 16:32:19 2008 +0000

    [ARM] clearpage: provide our own clear_user_highpage()
    
    For similar reasons as copy_user_page(), we want to avoid the
    additional kmap_atomic if it's unnecessary.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index edd71686b8df..c3651b2939c7 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -79,12 +79,11 @@ void feroceon_copy_user_highpage(struct page *to, struct page *from,
 	kunmap_atomic(kto, KM_USER0);
 }
 
-void __attribute__((naked))
-feroceon_clear_user_page(void *kaddr, unsigned long vaddr)
+void feroceon_clear_user_highpage(struct page *page, unsigned long vaddr)
 {
+	void *kaddr = kmap_atomic(page, KM_USER0);
 	asm("\
-	stmfd	sp!, {r4-r7, lr}		\n\
-	mov	r1, %0				\n\
+	mov	r1, %1				\n\
 	mov	r2, #0				\n\
 	mov	r3, #0				\n\
 	mov	r4, #0				\n\
@@ -93,19 +92,20 @@ feroceon_clear_user_page(void *kaddr, unsigned long vaddr)
 	mov	r7, #0				\n\
 	mov	ip, #0				\n\
 	mov	lr, #0				\n\
-1:	stmia	r0, {r2-r7, ip, lr}		\n\
+1:	stmia	%0, {r2-r7, ip, lr}		\n\
 	subs	r1, r1, #1			\n\
-	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	mcr	p15, 0, %0, c7, c14, 1		@ clean and invalidate D line\n\
 	add	r0, r0, #32			\n\
 	bne	1b				\n\
-	mcr	p15, 0, r1, c7, c10, 4		@ drain WB\n\
-	ldmfd	sp!, {r4-r7, pc}"
+	mcr	p15, 0, r1, c7, c10, 4		@ drain WB"
 	:
-	: "I" (PAGE_SIZE / 32));
+	: "r" (kaddr), "I" (PAGE_SIZE / 32)
+	: "r1", "r2", "r3", "r4", "r5", "r6", "r7", "ip", "lr");
+	kunmap_atomic(kaddr, KM_USER0);
 }
 
 struct cpu_user_fns feroceon_user_fns __initdata = {
-	.cpu_clear_user_page	= feroceon_clear_user_page,
+	.cpu_clear_user_highpage = feroceon_clear_user_highpage,
 	.cpu_copy_user_highpage	= feroceon_copy_user_highpage,
 };
 

commit 063b0a4207e43acbeff3d4b09f43e750e0212b48
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Fri Oct 31 15:08:35 2008 +0000

    [ARM] copypage: provide our own copy_user_highpage()
    
    We used to override the copy_user_page() function.  However, this
    is not only inefficient, it also causes additional complexity for
    highmem support, since we convert from a struct page to a kernel
    direct mapped address and back to a struct page again.
    
    Moreover, with highmem support, we end up pointlessly setting up
    kmap entries for pages which we're going to remap.  So, push the
    kmapping down into the copypage implementation files where it's
    required.
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
index c8347670ab00..edd71686b8df 100644
--- a/arch/arm/mm/copypage-feroceon.c
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -7,15 +7,14 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
- * This handles copy_user_page and clear_user_page on Feroceon
+ * This handles copy_user_highpage and clear_user_page on Feroceon
  * more optimally than the generic implementations.
  */
 #include <linux/init.h>
+#include <linux/highmem.h>
 
-#include <asm/page.h>
-
-void __attribute__((naked))
-feroceon_copy_user_page(void *kto, const void *kfrom, unsigned long vaddr)
+static void __attribute__((naked))
+feroceon_copy_user_page(void *kto, const void *kfrom)
 {
 	asm("\
 	stmfd	sp!, {r4-r9, lr}		\n\
@@ -68,6 +67,18 @@ feroceon_copy_user_page(void *kto, const void *kfrom, unsigned long vaddr)
 	: "I" (PAGE_SIZE));
 }
 
+void feroceon_copy_user_highpage(struct page *to, struct page *from,
+	unsigned long vaddr)
+{
+	void *kto, *kfrom;
+
+	kto = kmap_atomic(to, KM_USER0);
+	kfrom = kmap_atomic(from, KM_USER1);
+	feroceon_copy_user_page(kto, kfrom);
+	kunmap_atomic(kfrom, KM_USER1);
+	kunmap_atomic(kto, KM_USER0);
+}
+
 void __attribute__((naked))
 feroceon_clear_user_page(void *kaddr, unsigned long vaddr)
 {
@@ -95,6 +106,6 @@ feroceon_clear_user_page(void *kaddr, unsigned long vaddr)
 
 struct cpu_user_fns feroceon_user_fns __initdata = {
 	.cpu_clear_user_page	= feroceon_clear_user_page,
-	.cpu_copy_user_page	= feroceon_copy_user_page,
+	.cpu_copy_user_highpage	= feroceon_copy_user_highpage,
 };
 

commit d73e60b7144a86baf0fdfcc9537a70bb4f72e11c
Author: Russell King <rmk@dyn-67.arm.linux.org.uk>
Date:   Fri Oct 31 13:08:02 2008 +0000

    [ARM] copypage: convert assembly files to C
    
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/arch/arm/mm/copypage-feroceon.c b/arch/arm/mm/copypage-feroceon.c
new file mode 100644
index 000000000000..c8347670ab00
--- /dev/null
+++ b/arch/arm/mm/copypage-feroceon.c
@@ -0,0 +1,100 @@
+/*
+ *  linux/arch/arm/mm/copypage-feroceon.S
+ *
+ *  Copyright (C) 2008 Marvell Semiconductors
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This handles copy_user_page and clear_user_page on Feroceon
+ * more optimally than the generic implementations.
+ */
+#include <linux/init.h>
+
+#include <asm/page.h>
+
+void __attribute__((naked))
+feroceon_copy_user_page(void *kto, const void *kfrom, unsigned long vaddr)
+{
+	asm("\
+	stmfd	sp!, {r4-r9, lr}		\n\
+	mov	ip, %0				\n\
+1:	mov	lr, r1				\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	pld	[lr, #32]			\n\
+	pld	[lr, #64]			\n\
+	pld	[lr, #96]			\n\
+	pld	[lr, #128]			\n\
+	pld	[lr, #160]			\n\
+	pld	[lr, #192]			\n\
+	pld	[lr, #224]			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	ldmia	r1!, {r2 - r9}			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	stmia	r0, {r2 - r9}			\n\
+	subs	ip, ip, #(32 * 8)		\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	bne	1b				\n\
+	mcr	p15, 0, ip, c7, c10, 4		@ drain WB\n\
+	ldmfd	sp!, {r4-r9, pc}"
+	:
+	: "I" (PAGE_SIZE));
+}
+
+void __attribute__((naked))
+feroceon_clear_user_page(void *kaddr, unsigned long vaddr)
+{
+	asm("\
+	stmfd	sp!, {r4-r7, lr}		\n\
+	mov	r1, %0				\n\
+	mov	r2, #0				\n\
+	mov	r3, #0				\n\
+	mov	r4, #0				\n\
+	mov	r5, #0				\n\
+	mov	r6, #0				\n\
+	mov	r7, #0				\n\
+	mov	ip, #0				\n\
+	mov	lr, #0				\n\
+1:	stmia	r0, {r2-r7, ip, lr}		\n\
+	subs	r1, r1, #1			\n\
+	mcr	p15, 0, r0, c7, c14, 1		@ clean and invalidate D line\n\
+	add	r0, r0, #32			\n\
+	bne	1b				\n\
+	mcr	p15, 0, r1, c7, c10, 4		@ drain WB\n\
+	ldmfd	sp!, {r4-r7, pc}"
+	:
+	: "I" (PAGE_SIZE / 32));
+}
+
+struct cpu_user_fns feroceon_user_fns __initdata = {
+	.cpu_clear_user_page	= feroceon_clear_user_page,
+	.cpu_copy_user_page	= feroceon_copy_user_page,
+};
+
