commit 04ad99a0b160450ae615e41b839e444eccb5c99b
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Mar 13 14:34:59 2020 +0530

    arm64: unwind: strip PAC from kernel addresses
    
    When we enable pointer authentication in the kernel, LR values saved to
    the stack will have a PAC which we must strip in order to retrieve the
    real return address.
    
    Strip PACs when unwinding the stack in order to account for this.
    
    When function graph tracer is used with patchable-function-entry then
    return_to_handler will also have pac bits so strip it too.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: James Morse <james.morse@arm.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Kristina Martsenko <kristina.martsenko@arm.com>
    [Amit: Re-position ptrauth_strip_insn_pac, comment]
    Signed-off-by: Amit Daniel Kachhap <amit.kachhap@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index a336cb124320..139679c745bf 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -14,6 +14,7 @@
 #include <linux/stacktrace.h>
 
 #include <asm/irq.h>
+#include <asm/pointer_auth.h>
 #include <asm/stack_pointer.h>
 #include <asm/stacktrace.h>
 
@@ -86,7 +87,7 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&
-			(frame->pc == (unsigned long)return_to_handler)) {
+		(ptrauth_strip_insn_pac(frame->pc) == (unsigned long)return_to_handler)) {
 		struct ftrace_ret_stack *ret_stack;
 		/*
 		 * This is a case where function graph tracer has
@@ -101,6 +102,8 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	}
 #endif /* CONFIG_FUNCTION_GRAPH_TRACER */
 
+	frame->pc = ptrauth_strip_insn_pac(frame->pc);
+
 	/*
 	 * Frames created upon entry from EL0 have NULL FP and PC values, so
 	 * don't bother reporting these. Frames created by __noreturn functions

commit ee07b93e7721ccd5d5b9fa6f0c10cb3fe2f1f4f9
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Thu Jul 25 17:16:05 2019 +0900

    arm64: unwind: Prohibit probing on return_address()
    
    Prohibit probing on return_address() and subroutines which
    is called from return_address(), since the it is invoked from
    trace_hardirqs_off() which is also kprobe blacklisted.
    
    Reported-by: Naresh Kamboju <naresh.kamboju@linaro.org>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 2b160ae594eb..a336cb124320 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -7,6 +7,7 @@
 #include <linux/kernel.h>
 #include <linux/export.h>
 #include <linux/ftrace.h>
+#include <linux/kprobes.h>
 #include <linux/sched.h>
 #include <linux/sched/debug.h>
 #include <linux/sched/task_stack.h>
@@ -111,6 +112,7 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 
 	return 0;
 }
+NOKPROBE_SYMBOL(unwind_frame);
 
 void notrace walk_stackframe(struct task_struct *tsk, struct stackframe *frame,
 		     int (*fn)(struct stackframe *, void *), void *data)
@@ -125,6 +127,7 @@ void notrace walk_stackframe(struct task_struct *tsk, struct stackframe *frame,
 			break;
 	}
 }
+NOKPROBE_SYMBOL(walk_stackframe);
 
 #ifdef CONFIG_STACKTRACE
 struct stack_trace_data {

commit 592700f094be229b5c9cc1192d5cea46eb4c7afc
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Jul 2 14:07:29 2019 +0100

    arm64: stacktrace: Better handle corrupted stacks
    
    The arm64 stacktrace code is careful to only dereference frame records
    in valid stack ranges, ensuring that a corrupted frame record won't
    result in a faulting access.
    
    However, it's still possible for corrupt frame records to result in
    infinite loops in the stacktrace code, which is also undesirable.
    
    This patch ensures that we complete a stacktrace in finite time, by
    keeping track of which stacks we have already completed unwinding, and
    verifying that if the next frame record is on the same stack, it is at a
    higher address.
    
    As this has turned out to be particularly subtle, comments are added to
    explain the procedure.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: James Morse <james.morse@arm.com>
    Tested-by: James Morse <james.morse@arm.com>
    Acked-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Tengfei Fan <tengfeif@codeaurora.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 017972c2de90..2b160ae594eb 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -29,9 +29,18 @@
  *	ldp	x29, x30, [sp]
  *	add	sp, sp, #0x10
  */
+
+/*
+ * Unwind from one frame record (A) to the next frame record (B).
+ *
+ * We terminate early if the location of B indicates a malformed chain of frame
+ * records (e.g. a cycle), determined based on the location and fp value of A
+ * and the location (but not the fp value) of B.
+ */
 int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 {
 	unsigned long fp = frame->fp;
+	struct stack_info info;
 
 	if (fp & 0xf)
 		return -EINVAL;
@@ -39,11 +48,40 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	if (!tsk)
 		tsk = current;
 
-	if (!on_accessible_stack(tsk, fp, NULL))
+	if (!on_accessible_stack(tsk, fp, &info))
 		return -EINVAL;
 
+	if (test_bit(info.type, frame->stacks_done))
+		return -EINVAL;
+
+	/*
+	 * As stacks grow downward, any valid record on the same stack must be
+	 * at a strictly higher address than the prior record.
+	 *
+	 * Stacks can nest in several valid orders, e.g.
+	 *
+	 * TASK -> IRQ -> OVERFLOW -> SDEI_NORMAL
+	 * TASK -> SDEI_NORMAL -> SDEI_CRITICAL -> OVERFLOW
+	 *
+	 * ... but the nesting itself is strict. Once we transition from one
+	 * stack to another, it's never valid to unwind back to that first
+	 * stack.
+	 */
+	if (info.type == frame->prev_type) {
+		if (fp <= frame->prev_fp)
+			return -EINVAL;
+	} else {
+		set_bit(frame->prev_type, frame->stacks_done);
+	}
+
+	/*
+	 * Record this frame record's values and location. The prev_fp and
+	 * prev_type are only meaningful to the next unwind_frame() invocation.
+	 */
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));
 	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
+	frame->prev_fp = fp;
+	frame->prev_type = info.type;
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&

commit f3dcbe67ed424f1cf92065f9ad0cc647f2b44eac
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Jul 2 14:07:28 2019 +0100

    arm64: stacktrace: Factor out backtrace initialisation
    
    Some common code is required by each stacktrace user to initialise
    struct stackframe before the first call to unwind_frame().
    
    In preparation for adding to the common code, this patch factors it
    out into a separate function start_backtrace(), and modifies the
    stacktrace callers appropriately.
    
    No functional change.
    
    Signed-off-by: Dave Martin <dave.martin@arm.com>
    [Mark: drop tsk argument, update more callsites]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: James Morse <james.morse@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 62d395151abe..017972c2de90 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -122,12 +122,7 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 	data.skip = trace->skip;
 	data.no_sched_functions = 0;
 
-	frame.fp = regs->regs[29];
-	frame.pc = regs->pc;
-#ifdef CONFIG_FUNCTION_GRAPH_TRACER
-	frame.graph = 0;
-#endif
-
+	start_backtrace(&frame, regs->regs[29], regs->pc);
 	walk_stackframe(current, &frame, save_trace, &data);
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_regs);
@@ -146,17 +141,15 @@ static noinline void __save_stack_trace(struct task_struct *tsk,
 	data.no_sched_functions = nosched;
 
 	if (tsk != current) {
-		frame.fp = thread_saved_fp(tsk);
-		frame.pc = thread_saved_pc(tsk);
+		start_backtrace(&frame, thread_saved_fp(tsk),
+				thread_saved_pc(tsk));
 	} else {
 		/* We don't want this function nor the caller */
 		data.skip += 2;
-		frame.fp = (unsigned long)__builtin_frame_address(0);
-		frame.pc = (unsigned long)__save_stack_trace;
+		start_backtrace(&frame,
+				(unsigned long)__builtin_frame_address(0),
+				(unsigned long)__save_stack_trace);
 	}
-#ifdef CONFIG_FUNCTION_GRAPH_TRACER
-	frame.graph = 0;
-#endif
 
 	walk_stackframe(tsk, &frame, save_trace, &data);
 

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index b00ec7d483d1..62d395151abe 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -1,19 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Stack tracing support
  *
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #include <linux/kernel.h>
 #include <linux/export.h>

commit 7b2c7b6233497bfab8826ece574bc1c26e97478d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 10 12:28:01 2019 +0200

    arm64/stacktrace: Remove the pointless ULONG_MAX marker
    
    Terminating the last trace entry with ULONG_MAX is a completely pointless
    exercise and none of the consumers can rely on it because it's
    inconsistently implemented across architectures. In fact quite some of the
    callers remove the entry and adjust stack_trace.nr_entries afterwards.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: https://lkml.kernel.org/r/20190410103644.220247845@linutronix.de

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d908b5e9e949..b00ec7d483d1 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -140,8 +140,6 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 #endif
 
 	walk_stackframe(current, &frame, save_trace, &data);
-	if (trace->nr_entries < trace->max_entries)
-		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_regs);
 
@@ -172,8 +170,6 @@ static noinline void __save_stack_trace(struct task_struct *tsk,
 #endif
 
 	walk_stackframe(tsk, &frame, save_trace, &data);
-	if (trace->nr_entries < trace->max_entries)
-		trace->entries[trace->nr_entries++] = ULONG_MAX;
 
 	put_task_stack(tsk);
 }

commit c82fd1e6bd55ecc001e610e5484e292a7d8a39fc
Author: William Cohen <wcohen@redhat.com>
Date:   Fri Mar 1 15:00:41 2019 -0500

    arm64/stacktrace: Export save_stack_trace_regs()
    
    The ARM64 implements the save_stack_trace_regs function, but it is
    unusable for any diagnostic tooling compiled as a kernel module due
    the missing EXPORT_SYMBOL_GPL for the function.  Export
    save_stack_trace_regs() to align with other architectures such as
    s390, openrisc, and powerpc. This is similar to the ARM64 export of
    save_stack_trace_tsk() added in git commit e27c7fa015d6.
    
    Signed-off-by: William Cohen <wcohen@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 1a29f2695ff2..d908b5e9e949 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -143,6 +143,7 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
+EXPORT_SYMBOL_GPL(save_stack_trace_regs);
 
 static noinline void __save_stack_trace(struct task_struct *tsk,
 	struct stack_trace *trace, unsigned int nosched)

commit a448276ce515c91cde4675be497364b91c764d95
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Dec 7 13:13:28 2018 -0500

    arm64: Use ftrace_graph_get_ret_stack() instead of curr_ret_stack
    
    The structure of the ret_stack array on the task struct is going to
    change, and accessing it directly via the curr_ret_stack index will no
    longer give the ret_stack entry that holds the return address. To access
    that, architectures must now use ftrace_graph_get_ret_stack() to get the
    associated ret_stack that matches the saved return address.
    
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 7723dadf25be..1a29f2695ff2 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -59,15 +59,17 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&
 			(frame->pc == (unsigned long)return_to_handler)) {
-		if (WARN_ON_ONCE(frame->graph == -1))
-			return -EINVAL;
+		struct ftrace_ret_stack *ret_stack;
 		/*
 		 * This is a case where function graph tracer has
 		 * modified a return address (LR) in a stack frame
 		 * to hook a function return.
 		 * So replace it to an original value.
 		 */
-		frame->pc = tsk->ret_stack[frame->graph--].ret;
+		ret_stack = ftrace_graph_get_ret_stack(tsk, frame->graph++);
+		if (WARN_ON_ONCE(!ret_stack))
+			return -EINVAL;
+		frame->pc = ret_stack->ret;
 	}
 #endif /* CONFIG_FUNCTION_GRAPH_TRACER */
 
@@ -134,7 +136,7 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 	frame.fp = regs->regs[29];
 	frame.pc = regs->pc;
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
-	frame.graph = current->curr_ret_stack;
+	frame.graph = 0;
 #endif
 
 	walk_stackframe(current, &frame, save_trace, &data);
@@ -165,7 +167,7 @@ static noinline void __save_stack_trace(struct task_struct *tsk,
 		frame.pc = (unsigned long)__save_stack_trace;
 	}
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
-	frame.graph = tsk->curr_ret_stack;
+	frame.graph = 0;
 #endif
 
 	walk_stackframe(tsk, &frame, save_trace, &data);

commit 421d1069cd85f6fee9f36984a071a73b6a431f65
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Sun Nov 18 18:41:46 2018 -0500

    arm64: function_graph: Remove use of FTRACE_NOTRACE_DEPTH
    
    Functions in the set_graph_notrace no longer subtract FTRACE_NOTRACE_DEPTH
    from curr_ret_stack, as that is now implemented via the trace_recursion
    flags. Access to curr_ret_stack no longer needs to worry about checking for
    this. curr_ret_stack is still initialized to -1, when there's not a shadow
    stack allocated.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Acked-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 4989f7ea1e59..7723dadf25be 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -61,9 +61,6 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 			(frame->pc == (unsigned long)return_to_handler)) {
 		if (WARN_ON_ONCE(frame->graph == -1))
 			return -EINVAL;
-		if (frame->graph < -1)
-			frame->graph += FTRACE_NOTRACE_DEPTH;
-
 		/*
 		 * This is a case where function graph tracer has
 		 * modified a return address (LR) in a stack frame

commit 8a1ccfbc9e0256baafbbce85ccdb72ec89af2aab
Author: Laura Abbott <labbott@redhat.com>
Date:   Fri Jul 20 14:41:53 2018 -0700

    arm64: Add stack information to on_accessible_stack
    
    In preparation for enabling the stackleak plugin on arm64,
    we need a way to get the bounds of the current stack. Extend
    on_accessible_stack to get this information.
    
    Acked-by: Alexander Popov <alex.popov@linux.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Laura Abbott <labbott@redhat.com>
    [will: folded in fix for allmodconfig build breakage w/ sdei]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d5718a060672..4989f7ea1e59 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -50,7 +50,7 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	if (!tsk)
 		tsk = current;
 
-	if (!on_accessible_stack(tsk, fp))
+	if (!on_accessible_stack(tsk, fp, NULL))
 		return -EINVAL;
 
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));

commit e87a4a92fba3721eb06ba8d061b550e09e3d063a
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jul 12 11:37:40 2018 +0100

    Revert "arm64: fix infinite stacktrace"
    
    This reverts commit 7e7df71fd57ff2894d96abb0080922bf39460a79.
    
    When unwinding out of the IRQ stack and onto the interrupted EL1 stack,
    we cannot rely on the frame pointer being strictly increasing, as this
    could terminate the backtrace early depending on how the stacks have
    been allocated.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index e160ca123da3..d5718a060672 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -56,9 +56,6 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));
 	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
 
-	if (frame->fp <= fp)
-		return -EINVAL;
-
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&
 			(frame->pc == (unsigned long)return_to_handler)) {

commit 7e7df71fd57ff2894d96abb0080922bf39460a79
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Jun 14 14:58:21 2018 -0400

    arm64: fix infinite stacktrace
    
    I've got this infinite stacktrace when debugging another problem:
    [  908.795225] INFO: rcu_preempt detected stalls on CPUs/tasks:
    [  908.796176]  1-...!: (1 GPs behind) idle=952/1/4611686018427387904 softirq=1462/1462 fqs=355
    [  908.797692]  2-...!: (1 GPs behind) idle=f42/1/4611686018427387904 softirq=1550/1551 fqs=355
    [  908.799189]  (detected by 0, t=2109 jiffies, g=130, c=129, q=235)
    [  908.800284] Task dump for CPU 1:
    [  908.800871] kworker/1:1     R  running task        0    32      2 0x00000022
    [  908.802127] Workqueue: writecache-writeabck writecache_writeback [dm_writecache]
    [  908.820285] Call trace:
    [  908.824785]  __switch_to+0x68/0x90
    [  908.837661]  0xfffffe00603afd90
    [  908.844119]  0xfffffe00603afd90
    [  908.850091]  0xfffffe00603afd90
    [  908.854285]  0xfffffe00603afd90
    [  908.863538]  0xfffffe00603afd90
    [  908.865523]  0xfffffe00603afd90
    
    The machine just locked up and kept on printing the same line over and
    over again. This patch fixes it.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d5718a060672..e160ca123da3 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -56,6 +56,9 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));
 	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
 
+	if (frame->fp <= fp)
+		return -EINVAL;
+
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&
 			(frame->pc == (unsigned long)return_to_handler)) {

commit 9f416319f40cd857d2bb517630e5855a905ef3fb
Author: Pratyush Anand <panand@redhat.com>
Date:   Mon Feb 5 14:28:01 2018 +0100

    arm64: fix unwind_frame() for filtered out fn for function graph tracing
    
    do_task_stat() calls get_wchan(), which further does unwind_frame().
    unwind_frame() restores frame->pc to original value in case function
    graph tracer has modified a return address (LR) in a stack frame to hook
    a function return. However, if function graph tracer has hit a filtered
    function, then we can't unwind it as ftrace_push_return_trace() has
    biased the index(frame->graph) with a 'huge negative'
    offset(-FTRACE_NOTRACE_DEPTH).
    
    Moreover, arm64 stack walker defines index(frame->graph) as unsigned
    int, which can not compare a -ve number.
    
    Similar problem we can have with calling of walk_stackframe() from
    save_stack_trace_tsk() or dump_backtrace().
    
    This patch fixes unwind_frame() to test the index for -ve value and
    restore index accordingly before we can restore frame->pc.
    
    Reproducer:
    
    cd /sys/kernel/debug/tracing/
    echo schedule > set_graph_notrace
    echo 1 > options/display-graph
    echo wakeup > current_tracer
    ps -ef | grep -i agent
    
    Above commands result in:
    Unable to handle kernel paging request at virtual address ffff801bd3d1e000
    pgd = ffff8003cbe97c00
    [ffff801bd3d1e000] *pgd=0000000000000000, *pud=0000000000000000
    Internal error: Oops: 96000006 [#1] SMP
    [...]
    CPU: 5 PID: 11696 Comm: ps Not tainted 4.11.0+ #33
    [...]
    task: ffff8003c21ba000 task.stack: ffff8003cc6c0000
    PC is at unwind_frame+0x12c/0x180
    LR is at get_wchan+0xd4/0x134
    pc : [<ffff00000808892c>] lr : [<ffff0000080860b8>] pstate: 60000145
    sp : ffff8003cc6c3ab0
    x29: ffff8003cc6c3ab0 x28: 0000000000000001
    x27: 0000000000000026 x26: 0000000000000026
    x25: 00000000000012d8 x24: 0000000000000000
    x23: ffff8003c1c04000 x22: ffff000008c83000
    x21: ffff8003c1c00000 x20: 000000000000000f
    x19: ffff8003c1bc0000 x18: 0000fffffc593690
    x17: 0000000000000000 x16: 0000000000000001
    x15: 0000b855670e2b60 x14: 0003e97f22cf1d0f
    x13: 0000000000000001 x12: 0000000000000000
    x11: 00000000e8f4883e x10: 0000000154f47ec8
    x9 : 0000000070f367c0 x8 : 0000000000000000
    x7 : 00008003f7290000 x6 : 0000000000000018
    x5 : 0000000000000000 x4 : ffff8003c1c03cb0
    x3 : ffff8003c1c03ca0 x2 : 00000017ffe80000
    x1 : ffff8003cc6c3af8 x0 : ffff8003d3e9e000
    
    Process ps (pid: 11696, stack limit = 0xffff8003cc6c0000)
    Stack: (0xffff8003cc6c3ab0 to 0xffff8003cc6c4000)
    [...]
    [<ffff00000808892c>] unwind_frame+0x12c/0x180
    [<ffff000008305008>] do_task_stat+0x864/0x870
    [<ffff000008305c44>] proc_tgid_stat+0x3c/0x48
    [<ffff0000082fde0c>] proc_single_show+0x5c/0xb8
    [<ffff0000082b27e0>] seq_read+0x160/0x414
    [<ffff000008289e6c>] __vfs_read+0x58/0x164
    [<ffff00000828b164>] vfs_read+0x88/0x144
    [<ffff00000828c2e8>] SyS_read+0x60/0xc0
    [<ffff0000080834a0>] __sys_trace_return+0x0/0x4
    
    Fixes: 20380bb390a4 (arm64: ftrace: fix a stack tracer's output under function graph tracer)
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Signed-off-by: Jerome Marchand <jmarchan@redhat.com>
    [catalin.marinas@arm.com: replace WARN_ON with WARN_ON_ONCE]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 76809ccd309c..d5718a060672 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -59,6 +59,11 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk->ret_stack &&
 			(frame->pc == (unsigned long)return_to_handler)) {
+		if (WARN_ON_ONCE(frame->graph == -1))
+			return -EINVAL;
+		if (frame->graph < -1)
+			frame->graph += FTRACE_NOTRACE_DEPTH;
+
 		/*
 		 * This is a case where function graph tracer has
 		 * modified a return address (LR) in a stack frame

commit bb53c820c5b0f1a52804e32683aa7874db27392d
Author: Prakash Gupta <guptap@codeaurora.org>
Date:   Wed Sep 13 16:28:32 2017 -0700

    arm64: stacktrace: avoid listing stacktrace functions in stacktrace
    
    The stacktraces always begin as follows:
    
      [<c00117b4>] save_stack_trace_tsk+0x0/0x98
      [<c0011870>] save_stack_trace+0x24/0x28
      ...
    
    This is because the stack trace code includes the stack frames for
    itself.  This is incorrect behaviour, and also leads to "skip" doing the
    wrong thing (which is the number of stack frames to avoid recording.)
    
    Perversely, it does the right thing when passed a non-current thread.
    Fix this by ensuring that we have a known constant number of frames
    above the main stack trace function, and always skip these.
    
    This was fixed for arch arm by commit 3683f44c42e9 ("ARM: stacktrace:
    avoid listing stacktrace functions in stacktrace")
    
    Link: http://lkml.kernel.org/r/1504078343-28754-1-git-send-email-guptap@codeaurora.org
    Signed-off-by: Prakash Gupta <guptap@codeaurora.org>
    Cc: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 3144584617e7..76809ccd309c 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -140,7 +140,8 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 
-void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+static noinline void __save_stack_trace(struct task_struct *tsk,
+	struct stack_trace *trace, unsigned int nosched)
 {
 	struct stack_trace_data data;
 	struct stackframe frame;
@@ -150,15 +151,16 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 
 	data.trace = trace;
 	data.skip = trace->skip;
+	data.no_sched_functions = nosched;
 
 	if (tsk != current) {
-		data.no_sched_functions = 1;
 		frame.fp = thread_saved_fp(tsk);
 		frame.pc = thread_saved_pc(tsk);
 	} else {
-		data.no_sched_functions = 0;
+		/* We don't want this function nor the caller */
+		data.skip += 2;
 		frame.fp = (unsigned long)__builtin_frame_address(0);
-		frame.pc = (unsigned long)save_stack_trace_tsk;
+		frame.pc = (unsigned long)__save_stack_trace;
 	}
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	frame.graph = tsk->curr_ret_stack;
@@ -172,9 +174,15 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
 
+void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+{
+	__save_stack_trace(tsk, trace, 1);
+}
+
 void save_stack_trace(struct stack_trace *trace)
 {
-	save_stack_trace_tsk(current, trace);
+	__save_stack_trace(current, trace, 0);
 }
+
 EXPORT_SYMBOL_GPL(save_stack_trace);
 #endif

commit 12964443e8d1914010f9269f9f9abc4e122bc6ca
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Aug 1 18:51:15 2017 +0100

    arm64: add on_accessible_stack()
    
    Both unwind_frame() and dump_backtrace() try to check whether a stack
    address is sane to access, with very similar logic. Both will need
    updating in order to handle overflow stacks.
    
    Factor out this logic into a helper, so that we can avoid further
    duplication when we add overflow stacks.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 35588caad9d0..3144584617e7 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -50,12 +50,7 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	if (!tsk)
 		tsk = current;
 
-	/*
-	 * Switching between stacks is valid when tracing current and in
-	 * non-preemptible context.
-	 */
-	if (!(tsk == current && !preemptible() && on_irq_stack(fp)) &&
-	    !on_task_stack(tsk, fp))
+	if (!on_accessible_stack(tsk, fp))
 		return -EINVAL;
 
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));

commit 31e43ad3b74a5d7b282023b72f25fc677c14c727
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sun Jul 23 09:05:38 2017 +0100

    arm64: unwind: remove sp from struct stackframe
    
    The unwind code sets the sp member of struct stackframe to
    'frame pointer + 0x10' unconditionally, without regard for whether
    doing so produces a legal value. So let's simply remove it now that
    we have stopped using it anyway.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 81d9262acaf0..35588caad9d0 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -58,7 +58,6 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	    !on_task_stack(tsk, fp))
 		return -EINVAL;
 
-	frame->sp = fp + 0x10;
 	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));
 	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
 
@@ -136,7 +135,6 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 	data.no_sched_functions = 0;
 
 	frame.fp = regs->regs[29];
-	frame.sp = regs->sp;
 	frame.pc = regs->pc;
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	frame.graph = current->curr_ret_stack;
@@ -161,12 +159,10 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	if (tsk != current) {
 		data.no_sched_functions = 1;
 		frame.fp = thread_saved_fp(tsk);
-		frame.sp = thread_saved_sp(tsk);
 		frame.pc = thread_saved_pc(tsk);
 	} else {
 		data.no_sched_functions = 0;
 		frame.fp = (unsigned long)__builtin_frame_address(0);
-		frame.sp = current_stack_pointer;
 		frame.pc = (unsigned long)save_stack_trace_tsk;
 	}
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER

commit 7326749801396105aef0ed9229df746ac9e24300
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sat Jul 22 18:45:33 2017 +0100

    arm64: unwind: reference pt_regs via embedded stack frame
    
    As it turns out, the unwind code is slightly broken, and probably has
    been for a while. The problem is in the dumping of the exception stack,
    which is intended to dump the contents of the pt_regs struct at each
    level in the call stack where an exception was taken and routed to a
    routine marked as __exception (which means its stack frame is right
    below the pt_regs struct on the stack).
    
    'Right below the pt_regs struct' is ill defined, though: the unwind
    code assigns 'frame pointer + 0x10' to the .sp member of the stackframe
    struct at each level, and dump_backtrace() happily dereferences that as
    the pt_regs pointer when encountering an __exception routine. However,
    the actual size of the stack frame created by this routine (which could
    be one of many __exception routines we have in the kernel) is not known,
    and so frame.sp is pretty useless to figure out where struct pt_regs
    really is.
    
    So it seems the only way to ensure that we can find our struct pt_regs
    when walking the stack frames is to put it at a known fixed offset of
    the stack frame pointer that is passed to such __exception routines.
    The simplest way to do that is to put it inside pt_regs itself, which is
    the main change implemented by this patch. As a bonus, doing this allows
    us to get rid of a fair amount of cruft related to walking from one stack
    to the other, which is especially nice since we intend to introduce yet
    another stack for overflow handling once we add support for vmapped
    stacks. It also fixes an inconsistency where we only add a stack frame
    pointing to ELR_EL1 if we are executing from the IRQ stack but not when
    we are executing from the task stack.
    
    To consistly identify exceptions regs even in the presence of exceptions
    taken from entry code, we must check whether the next frame was created
    by entry text, rather than whether the current frame was crated by
    exception text.
    
    To avoid backtracing using PCs that fall in the idmap, or are controlled
    by userspace, we must explcitly zero the FP and LR in startup paths, and
    must ensure that the frame embedded in pt_regs is zeroed upon entry from
    EL0. To avoid these NULL entries showin in the backtrace, unwind_frame()
    is updated to avoid them.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    [Mark: compare current frame against .entry.text, avoid bogus PCs]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index beaf51fb3088..81d9262acaf0 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -76,34 +76,13 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 #endif /* CONFIG_FUNCTION_GRAPH_TRACER */
 
 	/*
-	 * Check whether we are going to walk through from interrupt stack
-	 * to task stack.
-	 * If we reach the end of the stack - and its an interrupt stack,
-	 * unpack the dummy frame to find the original elr.
-	 *
-	 * Check the frame->fp we read from the bottom of the irq_stack,
-	 * and the original task stack pointer are both in current->stack.
+	 * Frames created upon entry from EL0 have NULL FP and PC values, so
+	 * don't bother reporting these. Frames created by __noreturn functions
+	 * might have a valid FP even if PC is bogus, so only terminate where
+	 * both are NULL.
 	 */
-	if (frame->sp == IRQ_STACK_PTR()) {
-		struct pt_regs *irq_args;
-		unsigned long orig_sp = IRQ_STACK_TO_TASK_STACK(frame->sp);
-
-		if (object_is_on_stack((void *)orig_sp) &&
-		   object_is_on_stack((void *)frame->fp)) {
-			frame->sp = orig_sp;
-
-			/* orig_sp is the saved pt_regs, find the elr */
-			irq_args = (struct pt_regs *)orig_sp;
-			frame->pc = irq_args->pc;
-		} else {
-			/*
-			 * This frame has a non-standard format, and we
-			 * didn't fix it, because the data looked wrong.
-			 * Refuse to output this frame.
-			 */
-			return -EINVAL;
-		}
-	}
+	if (!frame->fp && !frame->pc)
+		return -EINVAL;
 
 	return 0;
 }

commit c7365330753c55a061db0a1837a27fd5e44b1408
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sat Jul 22 12:48:34 2017 +0100

    arm64: unwind: disregard frame.sp when validating frame pointer
    
    Currently, when unwinding the call stack, we validate the frame pointer
    of each frame against frame.sp, whose value is not clearly defined, and
    which makes it more difficult to link stack frames together across
    different stacks. It is far better to simply check whether the frame
    pointer itself points into a valid stack.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 6ffb965be641..beaf51fb3088 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -42,9 +42,10 @@
  */
 int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 {
-	unsigned long high, low;
 	unsigned long fp = frame->fp;
-	unsigned long irq_stack_ptr;
+
+	if (fp & 0xf)
+		return -EINVAL;
 
 	if (!tsk)
 		tsk = current;
@@ -53,19 +54,8 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	 * Switching between stacks is valid when tracing current and in
 	 * non-preemptible context.
 	 */
-	if (tsk == current && !preemptible())
-		irq_stack_ptr = IRQ_STACK_PTR();
-	else
-		irq_stack_ptr = 0;
-
-	low  = frame->sp;
-	/* irq stacks are not THREAD_SIZE aligned */
-	if (on_irq_stack(frame->sp))
-		high = irq_stack_ptr;
-	else
-		high = ALIGN(low, THREAD_SIZE) - 0x20;
-
-	if (fp < low || fp > high || fp & 0xf)
+	if (!(tsk == current && !preemptible() && on_irq_stack(fp)) &&
+	    !on_task_stack(tsk, fp))
 		return -EINVAL;
 
 	frame->sp = fp + 0x10;
@@ -94,9 +84,9 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	 * Check the frame->fp we read from the bottom of the irq_stack,
 	 * and the original task stack pointer are both in current->stack.
 	 */
-	if (frame->sp == irq_stack_ptr) {
+	if (frame->sp == IRQ_STACK_PTR()) {
 		struct pt_regs *irq_args;
-		unsigned long orig_sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
+		unsigned long orig_sp = IRQ_STACK_TO_TASK_STACK(frame->sp);
 
 		if (object_is_on_stack((void *)orig_sp) &&
 		   object_is_on_stack((void *)frame->fp)) {

commit 096683724cb2eb95fea759a2580996df1039fdd0
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Jul 20 14:01:01 2017 +0100

    arm64: unwind: avoid percpu indirection for irq stack
    
    Our IRQ_STACK_PTR() and on_irq_stack() helpers both take a cpu argument,
    used to generate a percpu address. In all cases, they are passed
    {raw_,}smp_processor_id(), so this parameter is redundant.
    
    Since {raw_,}smp_processor_id() use a percpu variable internally, this
    approach means we generate a percpu offset to find the current cpu, then
    use this to index an array of percpu offsets, which we then use to find
    the current CPU's IRQ stack pointer. Thus, most of the work is
    redundant.
    
    Instead, we can consistently use raw_cpu_ptr() to generate the CPU's
    irq_stack pointer by simply adding the percpu offset to the irq_stack
    address, which is simpler in both respects.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 09d37d66b630..6ffb965be641 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -54,13 +54,13 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	 * non-preemptible context.
 	 */
 	if (tsk == current && !preemptible())
-		irq_stack_ptr = IRQ_STACK_PTR(smp_processor_id());
+		irq_stack_ptr = IRQ_STACK_PTR();
 	else
 		irq_stack_ptr = 0;
 
 	low  = frame->sp;
 	/* irq stacks are not THREAD_SIZE aligned */
-	if (on_irq_stack(frame->sp, raw_smp_processor_id()))
+	if (on_irq_stack(frame->sp))
 		high = irq_stack_ptr;
 	else
 		high = ALIGN(low, THREAD_SIZE) - 0x20;

commit e27c7fa015d61c8be6a2c32b2144aad2ae6ec975
Author: Dustin Brown <dustinb@codeaurora.org>
Date:   Tue Jun 13 11:40:56 2017 -0700

    arm64: Export save_stack_trace_tsk()
    
    The kernel watchdog is a great debugging tool for finding tasks that
    consume a disproportionate amount of CPU time in contiguous chunks. One
    can imagine building a similar watchdog for arbitrary driver threads
    using save_stack_trace_tsk() and print_stack_trace(). However, this is
    not viable for dynamically loaded driver modules on ARM platforms
    because save_stack_trace_tsk() is not exported for those architectures.
    Export save_stack_trace_tsk() for the ARM64 architecture to align with
    x86 and support various debugging use cases such as arbitrary driver
    thread watchdog timers.
    
    Signed-off-by: Dustin Brown <dustinb@codeaurora.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index feac80c22f61..09d37d66b630 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -210,6 +210,7 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 
 	put_task_stack(tsk);
 }
+EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
 
 void save_stack_trace(struct stack_trace *trace)
 {

commit 68db0cf10678630d286f4bbbbdfa102951a35faa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:37 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task_stack.h>
    
    We are going to split <linux/sched/task_stack.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task_stack.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 7597e42feeea..feac80c22f61 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -20,6 +20,7 @@
 #include <linux/ftrace.h>
 #include <linux/sched.h>
 #include <linux/sched/debug.h>
+#include <linux/sched/task_stack.h>
 #include <linux/stacktrace.h>
 
 #include <asm/irq.h>

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 8a552a33c6ef..7597e42feeea 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -19,6 +19,7 @@
 #include <linux/export.h>
 #include <linux/ftrace.h>
 #include <linux/sched.h>
+#include <linux/sched/debug.h>
 #include <linux/stacktrace.h>
 
 #include <asm/irq.h>

commit 9bbd4c56b0b642f04396da378296e68096d5afca
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Nov 3 20:23:08 2016 +0000

    arm64: prep stack walkers for THREAD_INFO_IN_TASK
    
    When CONFIG_THREAD_INFO_IN_TASK is selected, task stacks may be freed
    before a task is destroyed. To account for this, the stacks are
    refcounted, and when manipulating the stack of another task, it is
    necessary to get/put the stack to ensure it isn't freed and/or re-used
    while we do so.
    
    This patch reworks the arm64 stack walking code to account for this.
    When CONFIG_THREAD_INFO_IN_TASK is not selected these perform no
    refcounting, and this should only be a structural change that does not
    affect behaviour.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Cc: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d53f99d4c223..8a552a33c6ef 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -181,6 +181,9 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	struct stack_trace_data data;
 	struct stackframe frame;
 
+	if (!try_get_task_stack(tsk))
+		return;
+
 	data.trace = trace;
 	data.skip = trace->skip;
 
@@ -202,6 +205,8 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	walk_stackframe(tsk, &frame, save_trace, &data);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
+
+	put_task_stack(tsk);
 }
 
 void save_stack_trace(struct stack_trace *trace)

commit 2020a5ae7c8c2c8504565004915017507b135c63
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Nov 3 20:23:07 2016 +0000

    arm64: unexport walk_stackframe
    
    The walk_stackframe functions is architecture-specific, with a varying
    prototype, and common code should not use it directly. None of its
    current users can be built as modules. With THREAD_INFO_IN_TASK, users
    will also need to hold a stack reference before calling it.
    
    There's no reason for it to be exported, and it's very easy to misuse,
    so unexport it for now.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 5b8006819cde..d53f99d4c223 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -129,7 +129,6 @@ void notrace walk_stackframe(struct task_struct *tsk, struct stackframe *frame,
 			break;
 	}
 }
-EXPORT_SYMBOL(walk_stackframe);
 
 #ifdef CONFIG_STACKTRACE
 struct stack_trace_data {

commit a9ea0017ebe8889dfa136cac2aa7ae0ee6915e1f
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Nov 3 20:23:05 2016 +0000

    arm64: factor out current_stack_pointer
    
    We define current_stack_pointer in <asm/thread_info.h>, though other
    files and header relying upon it do not have this necessary include, and
    are thus fragile to changes in the header soup.
    
    Subsequent patches will affect the header soup such that directly
    including <asm/thread_info.h> may result in a circular header include in
    some of these cases, so we can't simply include <asm/thread_info.h>.
    
    Instead, factor current_thread_info into its own header, and have all
    existing users include this explicitly.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index c2efddfca18c..5b8006819cde 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -22,6 +22,7 @@
 #include <linux/stacktrace.h>
 
 #include <asm/irq.h>
+#include <asm/stack_pointer.h>
 #include <asm/stacktrace.h>
 
 /*

commit b5e7307d9d5a340d2c9fabbe1cee137d4c682c71
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Sep 23 17:55:05 2016 +0100

    arm64: fix dump_backtrace/unwind_frame with NULL tsk
    
    In some places, dump_backtrace() is called with a NULL tsk parameter,
    e.g. in bug_handler() in arch/arm64, or indirectly via show_stack() in
    core code. The expectation is that this is treated as if current were
    passed instead of NULL. Similar is true of unwind_frame().
    
    Commit a80a0eb70c358f8c ("arm64: make irq_stack_ptr more robust") didn't
    take this into account. In dump_backtrace() it compares tsk against
    current *before* we check if tsk is NULL, and in unwind_frame() we never
    set tsk if it is NULL.
    
    Due to this, we won't initialise irq_stack_ptr in either function. In
    dump_backtrace() this results in calling dump_mem() for memory
    immediately above the IRQ stack range, rather than for the relevant
    range on the task stack. In unwind_frame we'll reject unwinding frames
    on the IRQ stack.
    
    In either case this results in incomplete or misleading backtrace
    information, but is not otherwise problematic. The initial percpu areas
    (including the IRQ stacks) are allocated in the linear map, and dump_mem
    uses __get_user(), so we shouldn't access anything with side-effects,
    and will handle holes safely.
    
    This patch fixes the issue by having both functions handle the NULL tsk
    case before doing anything else with tsk.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Fixes: a80a0eb70c358f8c ("arm64: make irq_stack_ptr more robust")
    Acked-by: James Morse <james.morse@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yang Shi <yang.shi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index ca01addf8c4c..c2efddfca18c 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -43,6 +43,9 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	unsigned long fp = frame->fp;
 	unsigned long irq_stack_ptr;
 
+	if (!tsk)
+		tsk = current;
+
 	/*
 	 * Switching between stacks is valid when tracing current and in
 	 * non-preemptible context.
@@ -67,7 +70,7 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
-	if (tsk && tsk->ret_stack &&
+	if (tsk->ret_stack &&
 			(frame->pc == (unsigned long)return_to_handler)) {
 		/*
 		 * This is a case where function graph tracer has

commit 98ab10e9770e3ce9fbd263689644be9d81a06885
Author: Pratyush Anand <panand@redhat.com>
Date:   Mon Sep 5 08:03:16 2016 +0530

    arm64: ftrace: add save_stack_trace_regs()
    
    Currently, enabling stacktrace of a kprobe events generates warning:
    
      echo stacktrace > /sys/kernel/debug/tracing/trace_options
      echo "p xhci_irq" > /sys/kernel/debug/tracing/kprobe_events
      echo 1 > /sys/kernel/debug/tracing/events/kprobes/enable
    
    save_stack_trace_regs() not implemented yet.
    ------------[ cut here ]------------
    WARNING: CPU: 1 PID: 0 at ../kernel/stacktrace.c:74 save_stack_trace_regs+0x3c/0x48
    Modules linked in:
    
    CPU: 1 PID: 0 Comm: swapper/1 Not tainted 4.8.0-rc4-dirty #5128
    Hardware name: ARM Juno development board (r1) (DT)
    task: ffff800975dd1900 task.stack: ffff800975ddc000
    PC is at save_stack_trace_regs+0x3c/0x48
    LR is at save_stack_trace_regs+0x3c/0x48
    pc : [<ffff000008126c64>] lr : [<ffff000008126c64>] pstate: 600003c5
    sp : ffff80097ef52c00
    
    Call trace:
       save_stack_trace_regs+0x3c/0x48
       __ftrace_trace_stack+0x168/0x208
       trace_buffer_unlock_commit_regs+0x5c/0x7c
       kprobe_trace_func+0x308/0x3d8
       kprobe_dispatcher+0x58/0x60
       kprobe_breakpoint_handler+0xbc/0x18c
       brk_handler+0x50/0x90
       do_debug_exception+0x50/0xbc
    
    This patch implements save_stack_trace_regs(), so that stacktrace of a
    kprobe events can be obtained.
    
    After this patch, there is no warning and we can see the stacktrace for
    kprobe events in trace buffer.
    
    more /sys/kernel/debug/tracing/trace
              <idle>-0     [004] d.h.  1356.000496: p_xhci_irq_0:(xhci_irq+0x0/0x9ac)
              <idle>-0     [004] d.h.  1356.000497: <stack trace>
      => xhci_irq
      => __handle_irq_event_percpu
      => handle_irq_event_percpu
      => handle_irq_event
      => handle_fasteoi_irq
      => generic_handle_irq
      => __handle_domain_irq
      => gic_handle_irq
      => el1_irq
      => arch_cpu_idle
      => default_idle_call
      => cpu_startup_entry
      => secondary_start_kernel
      =>
    
    Tested-by: David A. Long <dave.long@linaro.org>
    Reviewed-by: James Morse <james.morse@arm.com>
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d9751a4769e7..ca01addf8c4c 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -152,6 +152,27 @@ static int save_trace(struct stackframe *frame, void *d)
 	return trace->nr_entries >= trace->max_entries;
 }
 
+void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
+{
+	struct stack_trace_data data;
+	struct stackframe frame;
+
+	data.trace = trace;
+	data.skip = trace->skip;
+	data.no_sched_functions = 0;
+
+	frame.fp = regs->regs[29];
+	frame.sp = regs->sp;
+	frame.pc = regs->pc;
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+	frame.graph = current->curr_ret_stack;
+#endif
+
+	walk_stackframe(current, &frame, save_trace, &data);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
+}
+
 void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 {
 	struct stack_trace_data data;

commit a80a0eb70c358f8c7dda4bb62b2278dc6285217b
Author: Yang Shi <yang.shi@linaro.org>
Date:   Thu Feb 11 13:53:10 2016 -0800

    arm64: make irq_stack_ptr more robust
    
    Switching between stacks is only valid if we are tracing ourselves while on the
    irq_stack, so it is only valid when in current and non-preemptible context,
    otherwise is is just zeroed off.
    
    Fixes: 132cd887b5c5 ("arm64: Modify stack trace and dump for use with irq_stack")
    Acked-by: James Morse <james.morse@arm.com>
    Tested-by: James Morse <james.morse@arm.com>
    Signed-off-by: Yang Shi <yang.shi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 12a18cbc4295..d9751a4769e7 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -44,14 +44,13 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	unsigned long irq_stack_ptr;
 
 	/*
-	 * Use raw_smp_processor_id() to avoid false-positives from
-	 * CONFIG_DEBUG_PREEMPT. get_wchan() calls unwind_frame() on sleeping
-	 * task stacks, we can be pre-empted in this case, so
-	 * {raw_,}smp_processor_id() may give us the wrong value. Sleeping
-	 * tasks can't ever be on an interrupt stack, so regardless of cpu,
-	 * the checks will always fail.
+	 * Switching between stacks is valid when tracing current and in
+	 * non-preemptible context.
 	 */
-	irq_stack_ptr = IRQ_STACK_PTR(raw_smp_processor_id());
+	if (tsk == current && !preemptible())
+		irq_stack_ptr = IRQ_STACK_PTR(smp_processor_id());
+	else
+		irq_stack_ptr = 0;
 
 	low  = frame->sp;
 	/* irq stacks are not THREAD_SIZE aligned */

commit bcaf669b4bdbad09888df086d266a34e293ace85
Author: Yang Shi <yang.shi@linaro.org>
Date:   Mon Feb 8 09:13:09 2016 -0800

    arm64: disable kasan when accessing frame->fp in unwind_frame
    
    When boot arm64 kernel with KASAN enabled, the below error is reported by
    kasan:
    
    BUG: KASAN: out-of-bounds in unwind_frame+0xec/0x260 at addr ffffffc064d57ba0
    Read of size 8 by task pidof/499
    page:ffffffbdc39355c0 count:0 mapcount:0 mapping:          (null) index:0x0
    flags: 0x0()
    page dumped because: kasan: bad access detected
    CPU: 2 PID: 499 Comm: pidof Not tainted 4.5.0-rc1 #119
    Hardware name: Freescale Layerscape 2085a RDB Board (DT)
    Call trace:
    [<ffffffc00008d078>] dump_backtrace+0x0/0x290
    [<ffffffc00008d32c>] show_stack+0x24/0x30
    [<ffffffc0006a981c>] dump_stack+0x8c/0xd8
    [<ffffffc0002e4400>] kasan_report_error+0x558/0x588
    [<ffffffc0002e4958>] kasan_report+0x60/0x70
    [<ffffffc0002e3188>] __asan_load8+0x60/0x78
    [<ffffffc00008c92c>] unwind_frame+0xec/0x260
    [<ffffffc000087e60>] get_wchan+0x110/0x160
    [<ffffffc0003b647c>] do_task_stat+0xb44/0xb68
    [<ffffffc0003b7730>] proc_tgid_stat+0x40/0x50
    [<ffffffc0003ac840>] proc_single_show+0x88/0xd8
    [<ffffffc000345be8>] seq_read+0x370/0x770
    [<ffffffc00030aba0>] __vfs_read+0xc8/0x1d8
    [<ffffffc00030c0ec>] vfs_read+0x94/0x168
    [<ffffffc00030d458>] SyS_read+0xb8/0x128
    [<ffffffc000086530>] el0_svc_naked+0x24/0x28
    Memory state around the buggy address:
     ffffffc064d57a80: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 00 00 f4 f4
     ffffffc064d57b00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    >ffffffc064d57b80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
                                      ^
     ffffffc064d57c00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
     ffffffc064d57c80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    
    Since the shadow byte pointed by the report is 0, so it may mean it is just hit
    oob in non-current task. So, disable the instrumentation to silence these
    warnings.
    
    Acked-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Signed-off-by: Yang Shi <yang.shi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 4fad9787ab46..12a18cbc4295 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -64,8 +64,8 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 		return -EINVAL;
 
 	frame->sp = fp + 0x10;
-	frame->fp = *(unsigned long *)(fp);
-	frame->pc = *(unsigned long *)(fp + 8);
+	frame->fp = READ_ONCE_NOCHECK(*(unsigned long *)(fp));
+	frame->pc = READ_ONCE_NOCHECK(*(unsigned long *)(fp + 8));
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	if (tsk && tsk->ret_stack &&

commit 20380bb390a443b2c5c8800cec59743faf8151b4
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Tue Dec 15 17:33:41 2015 +0900

    arm64: ftrace: fix a stack tracer's output under function graph tracer
    
    Function graph tracer modifies a return address (LR) in a stack frame
    to hook a function return. This will result in many useless entries
    (return_to_handler) showing up in
     a) a stack tracer's output
     b) perf call graph (with perf record -g)
     c) dump_backtrace (at panic et al.)
    
    For example, in case of a),
      $ echo function_graph > /sys/kernel/debug/tracing/current_tracer
      $ echo 1 > /proc/sys/kernel/stack_trace_enabled
      $ cat /sys/kernel/debug/tracing/stack_trace
            Depth    Size   Location    (54 entries)
            -----    ----   --------
      0)     4504      16   gic_raise_softirq+0x28/0x150
      1)     4488      80   smp_cross_call+0x38/0xb8
      2)     4408      48   return_to_handler+0x0/0x40
      3)     4360      32   return_to_handler+0x0/0x40
      ...
    
    In case of b),
      $ echo function_graph > /sys/kernel/debug/tracing/current_tracer
      $ perf record -e mem:XXX:x -ag -- sleep 10
      $ perf report
                      ...
                      |          |          |--0.22%-- 0x550f8
                      |          |          |          0x10888
                      |          |          |          el0_svc_naked
                      |          |          |          sys_openat
                      |          |          |          return_to_handler
                      |          |          |          return_to_handler
                      ...
    
    In case of c),
      $ echo function_graph > /sys/kernel/debug/tracing/current_tracer
      $ echo c > /proc/sysrq-trigger
      ...
      Call trace:
      [<ffffffc00044d3ac>] sysrq_handle_crash+0x24/0x30
      [<ffffffc000092250>] return_to_handler+0x0/0x40
      [<ffffffc000092250>] return_to_handler+0x0/0x40
      ...
    
    This patch replaces such entries with real addresses preserved in
    current->ret_stack[] at unwind_frame(). This way, we can cover all
    the cases.
    
    Reviewed-by: Jungseok Lee <jungseoklee85@gmail.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    [will: fixed minor context changes conflicting with irq stack bits]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index f7ee597ec883..4fad9787ab46 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -17,6 +17,7 @@
  */
 #include <linux/kernel.h>
 #include <linux/export.h>
+#include <linux/ftrace.h>
 #include <linux/sched.h>
 #include <linux/stacktrace.h>
 
@@ -66,6 +67,19 @@ int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 	frame->fp = *(unsigned long *)(fp);
 	frame->pc = *(unsigned long *)(fp + 8);
 
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+	if (tsk && tsk->ret_stack &&
+			(frame->pc == (unsigned long)return_to_handler)) {
+		/*
+		 * This is a case where function graph tracer has
+		 * modified a return address (LR) in a stack frame
+		 * to hook a function return.
+		 * So replace it to an original value.
+		 */
+		frame->pc = tsk->ret_stack[frame->graph--].ret;
+	}
+#endif /* CONFIG_FUNCTION_GRAPH_TRACER */
+
 	/*
 	 * Check whether we are going to walk through from interrupt stack
 	 * to task stack.
@@ -158,6 +172,9 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 		frame.sp = current_stack_pointer;
 		frame.pc = (unsigned long)save_stack_trace_tsk;
 	}
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+	frame.graph = tsk->curr_ret_stack;
+#endif
 
 	walk_stackframe(tsk, &frame, save_trace, &data);
 	if (trace->nr_entries < trace->max_entries)

commit fe13f95b720075327a761fe6ddb45b0c90cab504
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Tue Dec 15 17:33:40 2015 +0900

    arm64: pass a task parameter to unwind_frame()
    
    Function graph tracer modifies a return address (LR) in a stack frame
    to hook a function's return. This will result in many useless entries
    (return_to_handler) showing up in a call stack list.
    We will fix this problem in a later patch ("arm64: ftrace: fix a stack
    tracer's output under function graph tracer"). But since real return
    addresses are saved in ret_stack[] array in struct task_struct,
    unwind functions need to be notified of, in addition to a stack pointer
    address, which task is being traced in order to find out real return
    addresses.
    
    This patch extends unwind functions' interfaces by adding an extra
    argument of a pointer to task_struct.
    
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index b9fd3a8abfc1..f7ee597ec883 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -36,7 +36,7 @@
  *	ldp	x29, x30, [sp]
  *	add	sp, sp, #0x10
  */
-int notrace unwind_frame(struct stackframe *frame)
+int notrace unwind_frame(struct task_struct *tsk, struct stackframe *frame)
 {
 	unsigned long high, low;
 	unsigned long fp = frame->fp;
@@ -99,7 +99,7 @@ int notrace unwind_frame(struct stackframe *frame)
 	return 0;
 }
 
-void notrace walk_stackframe(struct stackframe *frame,
+void notrace walk_stackframe(struct task_struct *tsk, struct stackframe *frame,
 		     int (*fn)(struct stackframe *, void *), void *data)
 {
 	while (1) {
@@ -107,7 +107,7 @@ void notrace walk_stackframe(struct stackframe *frame,
 
 		if (fn(frame, data))
 			break;
-		ret = unwind_frame(frame);
+		ret = unwind_frame(tsk, frame);
 		if (ret < 0)
 			break;
 	}
@@ -159,7 +159,7 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 		frame.pc = (unsigned long)save_stack_trace_tsk;
 	}
 
-	walk_stackframe(&frame, save_trace, &data);
+	walk_stackframe(tsk, &frame, save_trace, &data);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit 971c67ce37cfeeaf560e792a2c3bc21d8b67163a
Author: James Morse <james.morse@arm.com>
Date:   Tue Dec 15 11:21:25 2015 +0000

    arm64: reduce stack use in irq_handler
    
    The code for switching to irq_stack stores three pieces of information on
    the stack, fp+lr, as a fake stack frame (that lets us walk back onto the
    interrupted tasks stack frame), and the address of the struct pt_regs that
    contains the register values from kernel entry. (which dump_backtrace()
    will print in any stack trace).
    
    To reduce this, we store fp, and the pointer to the struct pt_regs.
    unwind_frame() can recognise this as the irq_stack dummy frame, (as it only
    appears at the top of the irq_stack), and use the struct pt_regs values
    to find the missing interrupted link-register.
    
    Suggested-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d916d5b6aef6..b9fd3a8abfc1 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -70,17 +70,30 @@ int notrace unwind_frame(struct stackframe *frame)
 	 * Check whether we are going to walk through from interrupt stack
 	 * to task stack.
 	 * If we reach the end of the stack - and its an interrupt stack,
-	 * read the original task stack pointer from the dummy frame.
+	 * unpack the dummy frame to find the original elr.
 	 *
 	 * Check the frame->fp we read from the bottom of the irq_stack,
 	 * and the original task stack pointer are both in current->stack.
 	 */
 	if (frame->sp == irq_stack_ptr) {
+		struct pt_regs *irq_args;
 		unsigned long orig_sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
 
-		if(object_is_on_stack((void *)orig_sp) &&
-		   object_is_on_stack((void *)frame->fp))
+		if (object_is_on_stack((void *)orig_sp) &&
+		   object_is_on_stack((void *)frame->fp)) {
 			frame->sp = orig_sp;
+
+			/* orig_sp is the saved pt_regs, find the elr */
+			irq_args = (struct pt_regs *)orig_sp;
+			frame->pc = irq_args->pc;
+		} else {
+			/*
+			 * This frame has a non-standard format, and we
+			 * didn't fix it, because the data looked wrong.
+			 * Refuse to output this frame.
+			 */
+			return -EINVAL;
+		}
 	}
 
 	return 0;

commit 1ffe199b1c9b72a8e752a9ae2a7af10128ab2ca1
Author: James Morse <james.morse@arm.com>
Date:   Thu Dec 10 10:22:40 2015 +0000

    arm64: when walking onto the task stack, check sp & fp are in current->stack
    
    When unwind_frame() reaches the bottom of the irq_stack, the last fp
    points to the original task stack. unwind_frame() uses
    IRQ_STACK_TO_TASK_STACK() to find the sp value. If either values is
    wrong, we may end up walking a corrupt stack.
    
    Check these values are sane by testing if they are both on the stack
    pointed to by current->stack.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index b947eeffa5b2..d916d5b6aef6 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -71,9 +71,17 @@ int notrace unwind_frame(struct stackframe *frame)
 	 * to task stack.
 	 * If we reach the end of the stack - and its an interrupt stack,
 	 * read the original task stack pointer from the dummy frame.
+	 *
+	 * Check the frame->fp we read from the bottom of the irq_stack,
+	 * and the original task stack pointer are both in current->stack.
 	 */
-	if (frame->sp == irq_stack_ptr)
-		frame->sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
+	if (frame->sp == irq_stack_ptr) {
+		unsigned long orig_sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
+
+		if(object_is_on_stack((void *)orig_sp) &&
+		   object_is_on_stack((void *)frame->fp))
+			frame->sp = orig_sp;
+	}
 
 	return 0;
 }

commit 132cd887b5c54758d04bf25c52fa48f45e843a30
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Fri Dec 4 11:02:26 2015 +0000

    arm64: Modify stack trace and dump for use with irq_stack
    
    This patch allows unwind_frame() to traverse from interrupt stack to task
    stack correctly. It requires data from a dummy stack frame, created
    during irq_stack_entry(), added by a later patch.
    
    A similar approach is taken to modify dump_backtrace(), which expects to
    find struct pt_regs underneath any call to functions marked __exception.
    When on an irq_stack, the struct pt_regs is stored on the old task stack,
    the location of which is stored in the dummy stack frame.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    [james.morse: merged two patches, reworked for per_cpu irq_stacks, and
     no alignment guarantees, added irq_stack definitions]
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index ccb6078ed9f2..b947eeffa5b2 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -20,6 +20,7 @@
 #include <linux/sched.h>
 #include <linux/stacktrace.h>
 
+#include <asm/irq.h>
 #include <asm/stacktrace.h>
 
 /*
@@ -39,17 +40,41 @@ int notrace unwind_frame(struct stackframe *frame)
 {
 	unsigned long high, low;
 	unsigned long fp = frame->fp;
+	unsigned long irq_stack_ptr;
+
+	/*
+	 * Use raw_smp_processor_id() to avoid false-positives from
+	 * CONFIG_DEBUG_PREEMPT. get_wchan() calls unwind_frame() on sleeping
+	 * task stacks, we can be pre-empted in this case, so
+	 * {raw_,}smp_processor_id() may give us the wrong value. Sleeping
+	 * tasks can't ever be on an interrupt stack, so regardless of cpu,
+	 * the checks will always fail.
+	 */
+	irq_stack_ptr = IRQ_STACK_PTR(raw_smp_processor_id());
 
 	low  = frame->sp;
-	high = ALIGN(low, THREAD_SIZE);
+	/* irq stacks are not THREAD_SIZE aligned */
+	if (on_irq_stack(frame->sp, raw_smp_processor_id()))
+		high = irq_stack_ptr;
+	else
+		high = ALIGN(low, THREAD_SIZE) - 0x20;
 
-	if (fp < low || fp > high - 0x18 || fp & 0xf)
+	if (fp < low || fp > high || fp & 0xf)
 		return -EINVAL;
 
 	frame->sp = fp + 0x10;
 	frame->fp = *(unsigned long *)(fp);
 	frame->pc = *(unsigned long *)(fp + 8);
 
+	/*
+	 * Check whether we are going to walk through from interrupt stack
+	 * to task stack.
+	 * If we reach the end of the stack - and its an interrupt stack,
+	 * read the original task stack pointer from the dummy frame.
+	 */
+	if (frame->sp == irq_stack_ptr)
+		frame->sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
+
 	return 0;
 }
 

commit 9702970c7bd3e2d6fecb642a190269131d4ac16c
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Oct 28 16:56:13 2015 +0000

    Revert "ARM64: unwind: Fix PC calculation"
    
    This reverts commit e306dfd06fcb44d21c80acb8e5a88d55f3d1cf63.
    
    With this patch applied, we were the only architecture making this sort
    of adjustment to the PC calculation in the unwinder. This causes
    problems for ftrace, where the PC values are matched against the
    contents of the stack frames in the callchain and fail to match any
    records after the address adjustment.
    
    Whilst there has been some effort to change ftrace to workaround this,
    those patches are not yet ready for mainline and, since we're the odd
    architecture in this regard, let's just step in line with other
    architectures (like arch/arm/) for now.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 407991bf79f5..ccb6078ed9f2 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -48,11 +48,7 @@ int notrace unwind_frame(struct stackframe *frame)
 
 	frame->sp = fp + 0x10;
 	frame->fp = *(unsigned long *)(fp);
-	/*
-	 * -4 here because we care about the PC at time of bl,
-	 * not where the return will go.
-	 */
-	frame->pc = *(unsigned long *)(fp + 8) - 4;
+	frame->pc = *(unsigned long *)(fp + 8);
 
 	return 0;
 }

commit bb28cec4ea2f5151c08e061c6de825a8c853bbd6
Author: Behan Webster <behanw@converseincode.com>
Date:   Wed Aug 27 05:29:30 2014 +0100

    arm64: LLVMLinux: Use current_stack_pointer in save_stack_trace_tsk
    
    Use the global current_stack_pointer to get the value of the stack pointer.
    This change supports being able to compile the kernel with both gcc and clang.
    
    Signed-off-by: Behan Webster <behanw@converseincode.com>
    Signed-off-by: Mark Charlebois <charlebm@gmail.com>
    Reviewed-by: Jan-Simon Möller <dl9pf@gmx.de>
    Reviewed-by: Olof Johansson <olof@lixom.net>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 55437ba1f5a4..407991bf79f5 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -111,10 +111,9 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 		frame.sp = thread_saved_sp(tsk);
 		frame.pc = thread_saved_pc(tsk);
 	} else {
-		register unsigned long current_sp asm("sp");
 		data.no_sched_functions = 0;
 		frame.fp = (unsigned long)__builtin_frame_address(0);
-		frame.sp = current_sp;
+		frame.sp = current_stack_pointer;
 		frame.pc = (unsigned long)save_stack_trace_tsk;
 	}
 

commit 26e2ae39995469b9289aa1ec0144e256d56eb044
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Wed Apr 30 10:54:31 2014 +0100

    arm64: Add 'notrace' attribute to unwind_frame() for ftrace
    
    walk_stackframe() calls unwind_frame(), and if walk_stackframe() is
    "notrace", unwind_frame() should be also "notrace".
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index 38f0558f0c0a..55437ba1f5a4 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -35,7 +35,7 @@
  *	ldp	x29, x30, [sp]
  *	add	sp, sp, #0x10
  */
-int unwind_frame(struct stackframe *frame)
+int notrace unwind_frame(struct stackframe *frame)
 {
 	unsigned long high, low;
 	unsigned long fp = frame->fp;

commit e306dfd06fcb44d21c80acb8e5a88d55f3d1cf63
Author: Olof Johansson <olof@lixom.net>
Date:   Fri Feb 14 19:35:15 2014 +0000

    ARM64: unwind: Fix PC calculation
    
    The frame PC value in the unwind code used to just take the saved LR
    value and use that.  That's incorrect as a stack trace, since it shows
    the return path stack, not the call path stack.
    
    In particular, it shows faulty information in case the bl is done as
    the very last instruction of one label, since the return point will be
    in the next label. That can easily be seen with tail calls to panic(),
    which is marked __noreturn and thus doesn't have anything useful after it.
    
    Easiest here is to just correct the unwind code and do a -4, to get the
    actual call site for the backtrace instead of the return site.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Cc: stable@vger.kernel.org
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index c3b6c63ea5fb..38f0558f0c0a 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -48,7 +48,11 @@ int unwind_frame(struct stackframe *frame)
 
 	frame->sp = fp + 0x10;
 	frame->fp = *(unsigned long *)(fp);
-	frame->pc = *(unsigned long *)(fp + 8);
+	/*
+	 * -4 here because we care about the PC at time of bl,
+	 * not where the return will go.
+	 */
+	frame->pc = *(unsigned long *)(fp + 8) - 4;
 
 	return 0;
 }

commit 26920dd2da79a3207803da9453c0e6c82ac968ca
Author: Konstantin Khlebnikov <k.khlebnikov@samsung.com>
Date:   Thu Dec 5 13:30:16 2013 +0000

    ARM64: fix framepointer check in unwind_frame
    
    We need at least 24 bytes above frame pointer.
    
    Signed-off-by: Konstantin Khlebnikov <k.khlebnikov@samsung.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index d25459ff57fc..c3b6c63ea5fb 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -43,7 +43,7 @@ int unwind_frame(struct stackframe *frame)
 	low  = frame->sp;
 	high = ALIGN(low, THREAD_SIZE);
 
-	if (fp < low || fp > high || fp & 0xf)
+	if (fp < low || fp > high - 0x18 || fp & 0xf)
 		return -EINVAL;
 
 	frame->sp = fp + 0x10;

commit 60ffc30d5652810dd34ea2eec41504222f5d5791
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Mar 5 11:49:27 2012 +0000

    arm64: Exception handling
    
    The patch contains the exception entry code (kernel/entry.S), pt_regs
    structure and related accessors, undefined instruction trapping and
    stack tracing.
    
    AArch64 Linux kernel (including kernel threads) runs in EL1 mode using
    the SP1 stack. The vectors don't have a fixed address, only alignment
    (2^11) requirements.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
new file mode 100644
index 000000000000..d25459ff57fc
--- /dev/null
+++ b/arch/arm64/kernel/stacktrace.c
@@ -0,0 +1,127 @@
+/*
+ * Stack tracing support
+ *
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#include <linux/kernel.h>
+#include <linux/export.h>
+#include <linux/sched.h>
+#include <linux/stacktrace.h>
+
+#include <asm/stacktrace.h>
+
+/*
+ * AArch64 PCS assigns the frame pointer to x29.
+ *
+ * A simple function prologue looks like this:
+ * 	sub	sp, sp, #0x10
+ *   	stp	x29, x30, [sp]
+ *	mov	x29, sp
+ *
+ * A simple function epilogue looks like this:
+ *	mov	sp, x29
+ *	ldp	x29, x30, [sp]
+ *	add	sp, sp, #0x10
+ */
+int unwind_frame(struct stackframe *frame)
+{
+	unsigned long high, low;
+	unsigned long fp = frame->fp;
+
+	low  = frame->sp;
+	high = ALIGN(low, THREAD_SIZE);
+
+	if (fp < low || fp > high || fp & 0xf)
+		return -EINVAL;
+
+	frame->sp = fp + 0x10;
+	frame->fp = *(unsigned long *)(fp);
+	frame->pc = *(unsigned long *)(fp + 8);
+
+	return 0;
+}
+
+void notrace walk_stackframe(struct stackframe *frame,
+		     int (*fn)(struct stackframe *, void *), void *data)
+{
+	while (1) {
+		int ret;
+
+		if (fn(frame, data))
+			break;
+		ret = unwind_frame(frame);
+		if (ret < 0)
+			break;
+	}
+}
+EXPORT_SYMBOL(walk_stackframe);
+
+#ifdef CONFIG_STACKTRACE
+struct stack_trace_data {
+	struct stack_trace *trace;
+	unsigned int no_sched_functions;
+	unsigned int skip;
+};
+
+static int save_trace(struct stackframe *frame, void *d)
+{
+	struct stack_trace_data *data = d;
+	struct stack_trace *trace = data->trace;
+	unsigned long addr = frame->pc;
+
+	if (data->no_sched_functions && in_sched_functions(addr))
+		return 0;
+	if (data->skip) {
+		data->skip--;
+		return 0;
+	}
+
+	trace->entries[trace->nr_entries++] = addr;
+
+	return trace->nr_entries >= trace->max_entries;
+}
+
+void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+{
+	struct stack_trace_data data;
+	struct stackframe frame;
+
+	data.trace = trace;
+	data.skip = trace->skip;
+
+	if (tsk != current) {
+		data.no_sched_functions = 1;
+		frame.fp = thread_saved_fp(tsk);
+		frame.sp = thread_saved_sp(tsk);
+		frame.pc = thread_saved_pc(tsk);
+	} else {
+		register unsigned long current_sp asm("sp");
+		data.no_sched_functions = 0;
+		frame.fp = (unsigned long)__builtin_frame_address(0);
+		frame.sp = current_sp;
+		frame.pc = (unsigned long)save_stack_trace_tsk;
+	}
+
+	walk_stackframe(&frame, save_trace, &data);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
+}
+
+void save_stack_trace(struct stack_trace *trace)
+{
+	save_stack_trace_tsk(current, trace);
+}
+EXPORT_SYMBOL_GPL(save_stack_trace);
+#endif
