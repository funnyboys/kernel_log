commit 8b1e0f81fb6fcf3109465a168b2e2da3f711fa86
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Thu Jul 11 20:58:43 2019 -0700

    mm/pgtable: drop pgtable_t variable from pte_fn_t functions
    
    Drop the pgtable_t variable from all implementation for pte_fn_t as none
    of them use it.  apply_to_pte_range() should stop computing it as well.
    Should help us save some cycles.
    
    Link: http://lkml.kernel.org/r/1556803126-26596-1-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Acked-by: Matthew Wilcox <willy@infradead.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Logan Gunthorpe <logang@deltatee.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: <jglisse@redhat.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 3c33d0dd8e0e..d0cf596db82c 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -82,8 +82,7 @@ int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 	return 0;
 }
 
-static int __init set_permissions(pte_t *ptep, pgtable_t token,
-				  unsigned long addr, void *data)
+static int __init set_permissions(pte_t *ptep, unsigned long addr, void *data)
 {
 	efi_memory_desc_t *md = data;
 	pte_t pte = READ_ONCE(*ptep);

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4f9acb5fbe97..3c33d0dd8e0e 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -1,14 +1,10 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Extensible Firmware Interface
  *
  * Based on Extensible Firmware Interface Specification version 2.4
  *
  * Copyright (C) 2013, 2014 Linaro Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
  */
 
 #include <linux/efi.h>

commit 7e611e7dbb235938fca1dd359bad5e5f86ceabcb
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Mar 8 08:00:13 2018 +0000

    efi/arm64: Check whether x18 is preserved by runtime services calls
    
    Whether or not we will ever decide to start using x18 as a platform
    register in Linux is uncertain, but by that time, we will need to
    ensure that UEFI runtime services calls don't corrupt it.
    
    So let's start issuing warnings now for this, and increase the
    likelihood that these firmware images have all been replaced by that time.
    
    This has been fixed on the EDK2 side in commit:
    
      6d73863b5464 ("BaseTools/tools_def AARCH64: mark register x18 as reserved")
    
    dated July 13, 2017.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180308080020.22828-6-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index a8bf1c892b90..4f9acb5fbe97 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -126,3 +126,9 @@ bool efi_poweroff_required(void)
 {
 	return efi_enabled(EFI_RUNTIME_SERVICES);
 }
+
+asmlinkage efi_status_t efi_handle_corrupted_x18(efi_status_t s, const char *f)
+{
+	pr_err_ratelimited(FW_BUG "register x18 corrupted by EFI %s\n", f);
+	return s;
+}

commit 20a004e7b017cce282a46ac5d02c2b9c6b9bb1fa
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Feb 15 11:14:56 2018 +0000

    arm64: mm: Use READ_ONCE/WRITE_ONCE when accessing page tables
    
    In many cases, page tables can be accessed concurrently by either another
    CPU (due to things like fast gup) or by the hardware page table walker
    itself, which may set access/dirty bits. In such cases, it is important
    to use READ_ONCE/WRITE_ONCE when accessing page table entries so that
    entries cannot be torn, merged or subject to apparent loss of coherence
    due to compiler transformations.
    
    Whilst there are some scenarios where this cannot happen (e.g. pinned
    kernel mappings for the linear region), the overhead of using READ_ONCE
    /WRITE_ONCE everywhere is minimal and makes the code an awful lot easier
    to reason about. This patch consistently uses these macros in the arch
    code, as well as explicitly namespacing pointers to page table entries
    from the entries themselves by using adopting a 'p' suffix for the former
    (as is sometimes used elsewhere in the kernel source).
    
    Tested-by: Yury Norov <ynorov@caviumnetworks.com>
    Tested-by: Richard Ruigrok <rruigrok@codeaurora.org>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index f85ac58d08a3..a8bf1c892b90 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -90,7 +90,7 @@ static int __init set_permissions(pte_t *ptep, pgtable_t token,
 				  unsigned long addr, void *data)
 {
 	efi_memory_desc_t *md = data;
-	pte_t pte = *ptep;
+	pte_t pte = READ_ONCE(*ptep);
 
 	if (md->attribute & EFI_MEMORY_RO)
 		pte = set_pte_bit(pte, __pgprot(PTE_RDONLY));

commit 1e9de1d2207d67b97bb0b62e38454b663d6542fa
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Jan 2 18:10:39 2018 +0000

    arm64/efi: Ignore EFI_MEMORY_XP attribute if RP and/or WP are set
    
    The UEFI memory map is a bit vague about how to interpret the
    EFI_MEMORY_XP attribute when it is combined with EFI_MEMORY_RP and/or
    EFI_MEMORY_WP, which have retroactively been redefined as cacheability
    attributes rather than permission attributes.
    
    So let's ignore EFI_MEMORY_XP if _RP and/or _WP are also set. In this
    case, it is likely that they are being used to describe the capability
    of the region (i.e., whether it has the controls to reconfigure it as
    non-executable) rather than the nature of the contents of the region
    (i.e., whether it contains data that we will never attempt to execute)
    
    Reported-by: Stephen Boyd <sboyd@codeaurora.org>
    Tested-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Arvind Yadav <arvind.yadav.cs@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tyler Baicar <tbaicar@codeaurora.org>
    Cc: Vasyl Gomonovych <gomonovych@gmail.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180102181042.19074-3-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 82cd07592519..f85ac58d08a3 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -48,7 +48,9 @@ static __init pteval_t create_mapping_protection(efi_memory_desc_t *md)
 		return pgprot_val(PAGE_KERNEL_ROX);
 
 	/* RW- */
-	if (attr & EFI_MEMORY_XP || type != EFI_RUNTIME_SERVICES_CODE)
+	if (((attr & (EFI_MEMORY_RP | EFI_MEMORY_WP | EFI_MEMORY_XP)) ==
+	     EFI_MEMORY_XP) ||
+	    type != EFI_RUNTIME_SERVICES_CODE)
 		return pgprot_val(PAGE_KERNEL);
 
 	/* RWX */

commit bb817bef3b1989a9cdb40362cfb8d2aa224ac1bc
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Jun 2 13:52:07 2017 +0000

    efi/arm: Enable DMI/SMBIOS
    
    Wire up the existing arm64 support for SMBIOS tables (aka DMI) for ARM as
    well, by moving the arm64 init code to drivers/firmware/efi/arm-runtime.c
    (which is shared between ARM and arm64), and adding a asm/dmi.h header to
    ARM that defines the mapping routines for the firmware tables.
    
    This allows userspace to access these tables to discover system information
    exposed by the firmware. It also sets the hardware name used in crash
    dumps, e.g.:
    
      Unable to handle kernel NULL pointer dereference at virtual address 00000000
      pgd = ed3c0000
      [00000000] *pgd=bf1f3835
      Internal error: Oops: 817 [#1] SMP THUMB2
      Modules linked in:
      CPU: 0 PID: 759 Comm: bash Not tainted 4.10.0-09601-g0e8f38792120-dirty #112
      Hardware name: QEMU KVM Virtual Machine, BIOS 0.0.0 02/06/2015
      ^^^
    
    NOTE: This does *NOT* enable or encourage the use of DMI quirks, i.e., the
          the practice of identifying the platform via DMI to decide whether
          certain workarounds for buggy hardware and/or firmware need to be
          enabled. This would require the DMI subsystem to be enabled much
          earlier than we do on ARM, which is non-trivial.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170602135207.21708-14-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 5d17f377d905..82cd07592519 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -11,7 +11,6 @@
  *
  */
 
-#include <linux/dmi.h>
 #include <linux/efi.h>
 #include <linux/init.h>
 
@@ -117,20 +116,6 @@ int __init efi_set_mapping_permissions(struct mm_struct *mm,
 				   set_permissions, md);
 }
 
-static int __init arm64_dmi_init(void)
-{
-	/*
-	 * On arm64, DMI depends on UEFI, and dmi_scan_machine() needs to
-	 * be called early because dmi_id_init(), which is an arch_initcall
-	 * itself, depends on dmi_scan_machine() having been called already.
-	 */
-	dmi_scan_machine();
-	if (dmi_available)
-		dmi_set_dump_stack_arch_desc();
-	return 0;
-}
-core_initcall(arm64_dmi_init);
-
 /*
  * UpdateCapsule() depends on the system being shutdown via
  * ResetSystem().

commit f14c66ce81b5595a483bd83df151539dbe1058fa
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Oct 21 12:22:57 2016 +0100

    arm64: mm: replace 'block_mappings_allowed' with 'page_mappings_only'
    
    In preparation of adding support for contiguous PTE and PMD mappings,
    let's replace 'block_mappings_allowed' with 'page_mappings_only', which
    will be a more accurate description of the nature of the setting once we
    add such contiguous mappings into the mix.
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index ba9bee389fd5..5d17f377d905 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -62,8 +62,8 @@ struct screen_info screen_info __section(.data);
 int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 {
 	pteval_t prot_val = create_mapping_protection(md);
-	bool allow_block_mappings = (md->type != EFI_RUNTIME_SERVICES_CODE &&
-				     md->type != EFI_RUNTIME_SERVICES_DATA);
+	bool page_mappings_only = (md->type == EFI_RUNTIME_SERVICES_CODE ||
+				   md->type == EFI_RUNTIME_SERVICES_DATA);
 
 	if (!PAGE_ALIGNED(md->phys_addr) ||
 	    !PAGE_ALIGNED(md->num_pages << EFI_PAGE_SHIFT)) {
@@ -76,12 +76,12 @@ int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 		 * from the MMU routines. So avoid block mappings altogether in
 		 * that case.
 		 */
-		allow_block_mappings = false;
+		page_mappings_only = true;
 	}
 
 	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
 			   md->num_pages << EFI_PAGE_SHIFT,
-			   __pgprot(prot_val | PTE_NG), allow_block_mappings);
+			   __pgprot(prot_val | PTE_NG), page_mappings_only);
 	return 0;
 }
 

commit 74c102c988cd48fff8055a0bfb84234fd3509419
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Jun 29 14:51:28 2016 +0200

    arm64: efi: avoid block mappings for unaligned UEFI memory regions
    
    When running the OS with a page size > 4 KB, we need to round up mappings
    for regions that are not aligned to the OS's page size. We already avoid
    block mappings for EfiRuntimeServicesCode/Data regions for other reasons,
    but in the unlikely event that other unaliged regions exists that have the
    EFI_MEMORY_RUNTIME attribute set, ensure that unaligned regions are always
    mapped down to pages. This way, the overlapping page is guaranteed not to
    be covered by a block mapping that needs to be split.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4aef89f37049..ba9bee389fd5 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -65,6 +65,20 @@ int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 	bool allow_block_mappings = (md->type != EFI_RUNTIME_SERVICES_CODE &&
 				     md->type != EFI_RUNTIME_SERVICES_DATA);
 
+	if (!PAGE_ALIGNED(md->phys_addr) ||
+	    !PAGE_ALIGNED(md->num_pages << EFI_PAGE_SHIFT)) {
+		/*
+		 * If the end address of this region is not aligned to page
+		 * size, the mapping is rounded up, and may end up sharing a
+		 * page frame with the next UEFI memory region. If we create
+		 * a block entry now, we may need to split it again when mapping
+		 * the next region, and support for that is going to be removed
+		 * from the MMU routines. So avoid block mappings altogether in
+		 * that case.
+		 */
+		allow_block_mappings = false;
+	}
+
 	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
 			   md->num_pages << EFI_PAGE_SHIFT,
 			   __pgprot(prot_val | PTE_NG), allow_block_mappings);

commit bd264d046aad25e9922a142a7831e6841a2f0474
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Jun 29 14:51:27 2016 +0200

    arm64: efi: always map runtime services code and data regions down to pages
    
    To avoid triggering diagnostics in the MMU code that are finicky about
    splitting block mappings into more granular mappings, ensure that regions
    that are likely to appear in the Memory Attributes table as well as the
    UEFI memory map are always mapped down to pages. This way, we can use
    apply_to_page_range() instead of create_pgd_mapping() for the second pass,
    which cannot split or merge block entries, and operates strictly on PTEs.
    
    Note that this aligns the arm64 Memory Attributes table handling code with
    the ARM code, which already uses apply_to_page_range() to set the strict
    permissions.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 981604948521..4aef89f37049 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -62,13 +62,47 @@ struct screen_info screen_info __section(.data);
 int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 {
 	pteval_t prot_val = create_mapping_protection(md);
+	bool allow_block_mappings = (md->type != EFI_RUNTIME_SERVICES_CODE &&
+				     md->type != EFI_RUNTIME_SERVICES_DATA);
 
 	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
 			   md->num_pages << EFI_PAGE_SHIFT,
-			   __pgprot(prot_val | PTE_NG), true);
+			   __pgprot(prot_val | PTE_NG), allow_block_mappings);
 	return 0;
 }
 
+static int __init set_permissions(pte_t *ptep, pgtable_t token,
+				  unsigned long addr, void *data)
+{
+	efi_memory_desc_t *md = data;
+	pte_t pte = *ptep;
+
+	if (md->attribute & EFI_MEMORY_RO)
+		pte = set_pte_bit(pte, __pgprot(PTE_RDONLY));
+	if (md->attribute & EFI_MEMORY_XP)
+		pte = set_pte_bit(pte, __pgprot(PTE_PXN));
+	set_pte(ptep, pte);
+	return 0;
+}
+
+int __init efi_set_mapping_permissions(struct mm_struct *mm,
+				       efi_memory_desc_t *md)
+{
+	BUG_ON(md->type != EFI_RUNTIME_SERVICES_CODE &&
+	       md->type != EFI_RUNTIME_SERVICES_DATA);
+
+	/*
+	 * Calling apply_to_page_range() is only safe on regions that are
+	 * guaranteed to be mapped down to pages. Since we are only called
+	 * for regions that have been mapped using efi_create_mapping() above
+	 * (and this is checked by the generic Memory Attributes table parsing
+	 * routines), there is no need to check that again here.
+	 */
+	return apply_to_page_range(mm, md->virt_addr,
+				   md->num_pages << EFI_PAGE_SHIFT,
+				   set_permissions, md);
+}
+
 static int __init arm64_dmi_init(void)
 {
 	/*

commit 53e1b32910a3bc94d9f122321442b79b314219f8
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Jun 29 14:51:26 2016 +0200

    arm64: mm: add param to force create_pgd_mapping() to use page mappings
    
    Add a bool parameter 'allow_block_mappings' to create_pgd_mapping() and
    the various helper functions that it descends into, to give the caller
    control over whether block entries may be used to create the mapping.
    
    The UEFI runtime mapping routines will use this to avoid creating block
    entries that would need to split up into page entries when applying the
    permissions listed in the Memory Attributes firmware table.
    
    This also replaces the block_mappings_allowed() helper function that was
    added for DEBUG_PAGEALLOC functionality, but the resulting code is
    functionally equivalent (given that debug_page_alloc does not operate on
    EFI page table entries anyway)
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 78f52488f9ff..981604948521 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -65,7 +65,7 @@ int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 
 	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
 			   md->num_pages << EFI_PAGE_SHIFT,
-			   __pgprot(prot_val | PTE_NG));
+			   __pgprot(prot_val | PTE_NG), true);
 	return 0;
 }
 

commit 57fdb89aeb7b0e3aab19847ab7399e5d76f11e6f
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Apr 25 21:06:52 2016 +0100

    arm64/efi/libstub: Make screen_info accessible to the UEFI stub
    
    Unlike on 32-bit ARM, where we need to pass the stub's version of struct
    screen_info to the kernel proper via a configuration table, on 64-bit ARM
    it simply involves making the core kernel's copy of struct screen_info
    visible to the stub by exposing an __efistub_ alias for it.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: David Herrmann <dh.herrmann@gmail.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Jones <pjones@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1461614832-17633-21-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 33a6da160a50..78f52488f9ff 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -56,6 +56,9 @@ static __init pteval_t create_mapping_protection(efi_memory_desc_t *md)
 	return pgprot_val(PAGE_KERNEL_EXEC);
 }
 
+/* we will fill this structure from the stub, so don't put it in .bss */
+struct screen_info screen_info __section(.data);
+
 int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
 {
 	pteval_t prot_val = create_mapping_protection(md);

commit 1fd55a9a09b0293af95ab4299b108f030fef4464
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Apr 25 21:06:43 2016 +0100

    arm64/efi: Apply strict permissions to UEFI Runtime Services regions
    
    Recent UEFI versions expose permission attributes for runtime services
    memory regions, either in the UEFI memory map or in the separate memory
    attributes table. This allows the kernel to map these regions with
    stricter permissions, rather than the RWX permissions that are used by
    default. So wire this up in our mapping routine.
    
    Note that in the absence of permission attributes, we still only map
    regions of type EFI_RUNTIME_SERVICE_CODE with the executable bit set.
    Also, we base the mapping attributes of EFI_MEMORY_MAPPED_IO on the
    type directly rather than on the absence of the EFI_MEMORY_WB attribute.
    This is more correct, but is also required for compatibility with the
    upcoming support for the Memory Attributes Table, which only carries
    permission attributes, not memory type attributes.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Leif Lindholm <leif.lindholm@linaro.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Jones <pjones@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/1461614832-17633-12-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index b6abc852f2a1..33a6da160a50 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -17,22 +17,48 @@
 
 #include <asm/efi.h>
 
-int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
+/*
+ * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
+ * executable, everything else can be mapped with the XN bits
+ * set. Also take the new (optional) RO/XP bits into account.
+ */
+static __init pteval_t create_mapping_protection(efi_memory_desc_t *md)
 {
-	pteval_t prot_val;
+	u64 attr = md->attribute;
+	u32 type = md->type;
 
-	/*
-	 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
-	 * executable, everything else can be mapped with the XN bits
-	 * set.
-	 */
-	if ((md->attribute & EFI_MEMORY_WB) == 0)
-		prot_val = PROT_DEVICE_nGnRE;
-	else if (md->type == EFI_RUNTIME_SERVICES_CODE ||
-		 !PAGE_ALIGNED(md->phys_addr))
-		prot_val = pgprot_val(PAGE_KERNEL_EXEC);
-	else
-		prot_val = pgprot_val(PAGE_KERNEL);
+	if (type == EFI_MEMORY_MAPPED_IO)
+		return PROT_DEVICE_nGnRE;
+
+	if (WARN_ONCE(!PAGE_ALIGNED(md->phys_addr),
+		      "UEFI Runtime regions are not aligned to 64 KB -- buggy firmware?"))
+		/*
+		 * If the region is not aligned to the page size of the OS, we
+		 * can not use strict permissions, since that would also affect
+		 * the mapping attributes of the adjacent regions.
+		 */
+		return pgprot_val(PAGE_KERNEL_EXEC);
+
+	/* R-- */
+	if ((attr & (EFI_MEMORY_XP | EFI_MEMORY_RO)) ==
+	    (EFI_MEMORY_XP | EFI_MEMORY_RO))
+		return pgprot_val(PAGE_KERNEL_RO);
+
+	/* R-X */
+	if (attr & EFI_MEMORY_RO)
+		return pgprot_val(PAGE_KERNEL_ROX);
+
+	/* RW- */
+	if (attr & EFI_MEMORY_XP || type != EFI_RUNTIME_SERVICES_CODE)
+		return pgprot_val(PAGE_KERNEL);
+
+	/* RWX */
+	return pgprot_val(PAGE_KERNEL_EXEC);
+}
+
+int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
+{
+	pteval_t prot_val = create_mapping_protection(md);
 
 	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
 			   md->num_pages << EFI_PAGE_SHIFT,

commit f7d924894265794f447ea799dd853400749b5a22
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Nov 30 13:28:19 2015 +0100

    arm64/efi: refactor EFI init and runtime code for reuse by 32-bit ARM
    
    This refactors the EFI init and runtime code that will be shared
    between arm64 and ARM so that it can be built for both archs.
    
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index bd3b2f5adf0c..b6abc852f2a1 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -17,6 +17,29 @@
 
 #include <asm/efi.h>
 
+int __init efi_create_mapping(struct mm_struct *mm, efi_memory_desc_t *md)
+{
+	pteval_t prot_val;
+
+	/*
+	 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
+	 * executable, everything else can be mapped with the XN bits
+	 * set.
+	 */
+	if ((md->attribute & EFI_MEMORY_WB) == 0)
+		prot_val = PROT_DEVICE_nGnRE;
+	else if (md->type == EFI_RUNTIME_SERVICES_CODE ||
+		 !PAGE_ALIGNED(md->phys_addr))
+		prot_val = pgprot_val(PAGE_KERNEL_EXEC);
+	else
+		prot_val = pgprot_val(PAGE_KERNEL);
+
+	create_pgd_mapping(mm, md->phys_addr, md->virt_addr,
+			   md->num_pages << EFI_PAGE_SHIFT,
+			   __pgprot(prot_val | PTE_NG));
+	return 0;
+}
+
 static int __init arm64_dmi_init(void)
 {
 	/*

commit e5bc22a42e4d46cc203fdfb6d2c76202b08666a0
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Nov 30 13:28:18 2015 +0100

    arm64/efi: split off EFI init and runtime code for reuse by 32-bit ARM
    
    This splits off the early EFI init and runtime code that
    - discovers the EFI params and the memory map from the FDT, and installs
      the memblocks and config tables.
    - prepares and installs the EFI page tables so that UEFI Runtime Services
      can be invoked at the virtual address installed by the stub.
    
    This will allow it to be reused for 32-bit ARM.
    
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 04531d35f1df..bd3b2f5adf0c 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -11,318 +11,11 @@
  *
  */
 
-#include <linux/atomic.h>
 #include <linux/dmi.h>
 #include <linux/efi.h>
-#include <linux/export.h>
-#include <linux/memblock.h>
-#include <linux/mm_types.h>
-#include <linux/bootmem.h>
-#include <linux/of.h>
-#include <linux/of_fdt.h>
-#include <linux/preempt.h>
-#include <linux/rbtree.h>
-#include <linux/rwsem.h>
-#include <linux/sched.h>
-#include <linux/slab.h>
-#include <linux/spinlock.h>
+#include <linux/init.h>
 
-#include <asm/cacheflush.h>
 #include <asm/efi.h>
-#include <asm/tlbflush.h>
-#include <asm/mmu_context.h>
-#include <asm/mmu.h>
-#include <asm/pgtable.h>
-
-struct efi_memory_map memmap;
-
-static u64 efi_system_table;
-
-static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
-
-static struct mm_struct efi_mm = {
-	.mm_rb			= RB_ROOT,
-	.pgd			= efi_pgd,
-	.mm_users		= ATOMIC_INIT(2),
-	.mm_count		= ATOMIC_INIT(1),
-	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
-	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
-	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
-};
-
-static int __init is_normal_ram(efi_memory_desc_t *md)
-{
-	if (md->attribute & EFI_MEMORY_WB)
-		return 1;
-	return 0;
-}
-
-/*
- * Translate a EFI virtual address into a physical address: this is necessary,
- * as some data members of the EFI system table are virtually remapped after
- * SetVirtualAddressMap() has been called.
- */
-static phys_addr_t efi_to_phys(unsigned long addr)
-{
-	efi_memory_desc_t *md;
-
-	for_each_efi_memory_desc(&memmap, md) {
-		if (!(md->attribute & EFI_MEMORY_RUNTIME))
-			continue;
-		if (md->virt_addr == 0)
-			/* no virtual mapping has been installed by the stub */
-			break;
-		if (md->virt_addr <= addr &&
-		    (addr - md->virt_addr) < (md->num_pages << EFI_PAGE_SHIFT))
-			return md->phys_addr + addr - md->virt_addr;
-	}
-	return addr;
-}
-
-static int __init uefi_init(void)
-{
-	efi_char16_t *c16;
-	void *config_tables;
-	u64 table_size;
-	char vendor[100] = "unknown";
-	int i, retval;
-
-	efi.systab = early_memremap(efi_system_table,
-				    sizeof(efi_system_table_t));
-	if (efi.systab == NULL) {
-		pr_warn("Unable to map EFI system table.\n");
-		return -ENOMEM;
-	}
-
-	set_bit(EFI_BOOT, &efi.flags);
-	set_bit(EFI_64BIT, &efi.flags);
-
-	/*
-	 * Verify the EFI Table
-	 */
-	if (efi.systab->hdr.signature != EFI_SYSTEM_TABLE_SIGNATURE) {
-		pr_err("System table signature incorrect\n");
-		retval = -EINVAL;
-		goto out;
-	}
-	if ((efi.systab->hdr.revision >> 16) < 2)
-		pr_warn("Warning: EFI system table version %d.%02d, expected 2.00 or greater\n",
-			efi.systab->hdr.revision >> 16,
-			efi.systab->hdr.revision & 0xffff);
-
-	/* Show what we know for posterity */
-	c16 = early_memremap(efi_to_phys(efi.systab->fw_vendor),
-			     sizeof(vendor) * sizeof(efi_char16_t));
-	if (c16) {
-		for (i = 0; i < (int) sizeof(vendor) - 1 && *c16; ++i)
-			vendor[i] = c16[i];
-		vendor[i] = '\0';
-		early_memunmap(c16, sizeof(vendor) * sizeof(efi_char16_t));
-	}
-
-	pr_info("EFI v%u.%.02u by %s\n",
-		efi.systab->hdr.revision >> 16,
-		efi.systab->hdr.revision & 0xffff, vendor);
-
-	table_size = sizeof(efi_config_table_64_t) * efi.systab->nr_tables;
-	config_tables = early_memremap(efi_to_phys(efi.systab->tables),
-				       table_size);
-	if (config_tables == NULL) {
-		pr_warn("Unable to map EFI config table array.\n");
-		retval = -ENOMEM;
-		goto out;
-	}
-	retval = efi_config_parse_tables(config_tables, efi.systab->nr_tables,
-					 sizeof(efi_config_table_64_t), NULL);
-
-	early_memunmap(config_tables, table_size);
-out:
-	early_memunmap(efi.systab,  sizeof(efi_system_table_t));
-	return retval;
-}
-
-/*
- * Return true for RAM regions we want to permanently reserve.
- */
-static __init int is_reserve_region(efi_memory_desc_t *md)
-{
-	switch (md->type) {
-	case EFI_LOADER_CODE:
-	case EFI_LOADER_DATA:
-	case EFI_BOOT_SERVICES_CODE:
-	case EFI_BOOT_SERVICES_DATA:
-	case EFI_CONVENTIONAL_MEMORY:
-	case EFI_PERSISTENT_MEMORY:
-		return 0;
-	default:
-		break;
-	}
-	return is_normal_ram(md);
-}
-
-static __init void reserve_regions(void)
-{
-	efi_memory_desc_t *md;
-	u64 paddr, npages, size;
-
-	if (efi_enabled(EFI_DBG))
-		pr_info("Processing EFI memory map:\n");
-
-	for_each_efi_memory_desc(&memmap, md) {
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-
-		if (efi_enabled(EFI_DBG)) {
-			char buf[64];
-
-			pr_info("  0x%012llx-0x%012llx %s",
-				paddr, paddr + (npages << EFI_PAGE_SHIFT) - 1,
-				efi_md_typeattr_format(buf, sizeof(buf), md));
-		}
-
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-
-		if (is_normal_ram(md))
-			early_init_dt_add_memory_arch(paddr, size);
-
-		if (is_reserve_region(md)) {
-			memblock_mark_nomap(paddr, size);
-			if (efi_enabled(EFI_DBG))
-				pr_cont("*");
-		}
-
-		if (efi_enabled(EFI_DBG))
-			pr_cont("\n");
-	}
-
-	set_bit(EFI_MEMMAP, &efi.flags);
-}
-
-void __init efi_init(void)
-{
-	struct efi_fdt_params params;
-
-	/* Grab UEFI information placed in FDT by stub */
-	if (!efi_get_fdt_params(&params))
-		return;
-
-	efi_system_table = params.system_table;
-
-	memmap.phys_map = params.mmap;
-	memmap.map = early_memremap(params.mmap, params.mmap_size);
-	if (memmap.map == NULL) {
-		/*
-		* If we are booting via UEFI, the UEFI memory map is the only
-		* description of memory we have, so there is little point in
-		* proceeding if we cannot access it.
-		*/
-		panic("Unable to map EFI memory map.\n");
-	}
-	memmap.map_end = memmap.map + params.mmap_size;
-	memmap.desc_size = params.desc_size;
-	memmap.desc_version = params.desc_ver;
-
-	if (uefi_init() < 0)
-		return;
-
-	reserve_regions();
-	early_memunmap(memmap.map, params.mmap_size);
-	memblock_mark_nomap(params.mmap & PAGE_MASK,
-			    PAGE_ALIGN(params.mmap_size +
-				       (params.mmap & ~PAGE_MASK)));
-}
-
-static bool __init efi_virtmap_init(void)
-{
-	efi_memory_desc_t *md;
-
-	init_new_context(NULL, &efi_mm);
-
-	for_each_efi_memory_desc(&memmap, md) {
-		pgprot_t prot;
-
-		if (!(md->attribute & EFI_MEMORY_RUNTIME))
-			continue;
-		if (md->virt_addr == 0)
-			return false;
-
-		pr_info("  EFI remap 0x%016llx => %p\n",
-			md->phys_addr, (void *)md->virt_addr);
-
-		/*
-		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
-		 * executable, everything else can be mapped with the XN bits
-		 * set.
-		 */
-		if (!is_normal_ram(md))
-			prot = __pgprot(PROT_DEVICE_nGnRE);
-		else if (md->type == EFI_RUNTIME_SERVICES_CODE ||
-			 !PAGE_ALIGNED(md->phys_addr))
-			prot = PAGE_KERNEL_EXEC;
-		else
-			prot = PAGE_KERNEL;
-
-		create_pgd_mapping(&efi_mm, md->phys_addr, md->virt_addr,
-				   md->num_pages << EFI_PAGE_SHIFT, 
-				   __pgprot(pgprot_val(prot) | PTE_NG));
-	}
-	return true;
-}
-
-/*
- * Enable the UEFI Runtime Services if all prerequisites are in place, i.e.,
- * non-early mapping of the UEFI system table and virtual mappings for all
- * EFI_MEMORY_RUNTIME regions.
- */
-static int __init arm64_enable_runtime_services(void)
-{
-	u64 mapsize;
-
-	if (!efi_enabled(EFI_BOOT)) {
-		pr_info("EFI services will not be available.\n");
-		return 0;
-	}
-
-	if (efi_runtime_disabled()) {
-		pr_info("EFI runtime services will be disabled.\n");
-		return 0;
-	}
-
-	pr_info("Remapping and enabling EFI services.\n");
-
-	mapsize = memmap.map_end - memmap.map;
-	memmap.map = (__force void *)ioremap_cache(memmap.phys_map,
-						   mapsize);
-	if (!memmap.map) {
-		pr_err("Failed to remap EFI memory map\n");
-		return -ENOMEM;
-	}
-	memmap.map_end = memmap.map + mapsize;
-	efi.memmap = &memmap;
-
-	efi.systab = (__force void *)ioremap_cache(efi_system_table,
-						   sizeof(efi_system_table_t));
-	if (!efi.systab) {
-		pr_err("Failed to remap EFI System Table\n");
-		return -ENOMEM;
-	}
-	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
-
-	if (!efi_virtmap_init()) {
-		pr_err("No UEFI virtual mapping was installed -- runtime services will not be available\n");
-		return -ENOMEM;
-	}
-
-	/* Set up runtime services function pointers */
-	efi_native_runtime_setup();
-	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
-
-	efi.runtime_version = efi.systab->hdr.revision;
-
-	return 0;
-}
-early_initcall(arm64_enable_runtime_services);
 
 static int __init arm64_dmi_init(void)
 {
@@ -338,23 +31,6 @@ static int __init arm64_dmi_init(void)
 }
 core_initcall(arm64_dmi_init);
 
-static void efi_set_pgd(struct mm_struct *mm)
-{
-	switch_mm(NULL, mm, NULL);
-}
-
-void efi_virtmap_load(void)
-{
-	preempt_disable();
-	efi_set_pgd(&efi_mm);
-}
-
-void efi_virtmap_unload(void)
-{
-	efi_set_pgd(current->active_mm);
-	preempt_enable();
-}
-
 /*
  * UpdateCapsule() depends on the system being shutdown via
  * ResetSystem().

commit 4dffbfc48d65e5d8157a634fd670065d237a9377
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Nov 30 13:28:17 2015 +0100

    arm64/efi: mark UEFI reserved regions as MEMBLOCK_NOMAP
    
    Change the EFI memory reservation logic to use memblock_mark_nomap()
    rather than memblock_reserve() to mark UEFI reserved regions as
    occupied. In addition to reserving them against allocations done by
    memblock, this will also prevent them from being covered by the linear
    mapping.
    
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4eeb17198cfa..04531d35f1df 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -187,7 +187,7 @@ static __init void reserve_regions(void)
 			early_init_dt_add_memory_arch(paddr, size);
 
 		if (is_reserve_region(md)) {
-			memblock_reserve(paddr, size);
+			memblock_mark_nomap(paddr, size);
 			if (efi_enabled(EFI_DBG))
 				pr_cont("*");
 		}
@@ -209,8 +209,6 @@ void __init efi_init(void)
 
 	efi_system_table = params.system_table;
 
-	memblock_reserve(params.mmap & PAGE_MASK,
-			 PAGE_ALIGN(params.mmap_size + (params.mmap & ~PAGE_MASK)));
 	memmap.phys_map = params.mmap;
 	memmap.map = early_memremap(params.mmap, params.mmap_size);
 	if (memmap.map == NULL) {
@@ -230,6 +228,9 @@ void __init efi_init(void)
 
 	reserve_regions();
 	early_memunmap(memmap.map, params.mmap_size);
+	memblock_mark_nomap(params.mmap & PAGE_MASK,
+			    PAGE_ALIGN(params.mmap_size +
+				       (params.mmap & ~PAGE_MASK)));
 }
 
 static bool __init efi_virtmap_init(void)

commit 66362c9afc1d4a806280b9e3646d2d0a26cf83e9
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Nov 23 08:43:24 2015 +0100

    arm64: efi: fix initcall return values
    
    Even though initcall return values are typically ignored, the
    prototype is to return 0 on success or a negative errno value on
    error. So fix the arm_enable_runtime_services() implementation to
    return 0 on conditions that are not in fact errors, and return a
    meaningful error code otherwise.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 96e4b1b7de46..4eeb17198cfa 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -280,12 +280,12 @@ static int __init arm64_enable_runtime_services(void)
 
 	if (!efi_enabled(EFI_BOOT)) {
 		pr_info("EFI services will not be available.\n");
-		return -1;
+		return 0;
 	}
 
 	if (efi_runtime_disabled()) {
 		pr_info("EFI runtime services will be disabled.\n");
-		return -1;
+		return 0;
 	}
 
 	pr_info("Remapping and enabling EFI services.\n");
@@ -295,7 +295,7 @@ static int __init arm64_enable_runtime_services(void)
 						   mapsize);
 	if (!memmap.map) {
 		pr_err("Failed to remap EFI memory map\n");
-		return -1;
+		return -ENOMEM;
 	}
 	memmap.map_end = memmap.map + mapsize;
 	efi.memmap = &memmap;
@@ -304,13 +304,13 @@ static int __init arm64_enable_runtime_services(void)
 						   sizeof(efi_system_table_t));
 	if (!efi.systab) {
 		pr_err("Failed to remap EFI System Table\n");
-		return -1;
+		return -ENOMEM;
 	}
 	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
 
 	if (!efi_virtmap_init()) {
 		pr_err("No UEFI virtual mapping was installed -- runtime services will not be available\n");
-		return -1;
+		return -ENOMEM;
 	}
 
 	/* Set up runtime services function pointers */

commit 81d945772afccc77660374aa6e512184b9107580
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Nov 23 08:43:23 2015 +0100

    arm64: efi: deal with NULL return value of early_memremap()
    
    Add NULL return value checks to two invocations of early_memremap()
    in the UEFI init code. For the UEFI configuration tables, we just
    warn since we have a better chance of being able to report the issue
    in a way that can actually be noticed by a human operator if we don't
    abort right away. For the UEFI memory map, however, all we can do is
    panic() since we cannot proceed without a description of memory.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index fe7cd1afa109..96e4b1b7de46 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -127,7 +127,11 @@ static int __init uefi_init(void)
 	table_size = sizeof(efi_config_table_64_t) * efi.systab->nr_tables;
 	config_tables = early_memremap(efi_to_phys(efi.systab->tables),
 				       table_size);
-
+	if (config_tables == NULL) {
+		pr_warn("Unable to map EFI config table array.\n");
+		retval = -ENOMEM;
+		goto out;
+	}
 	retval = efi_config_parse_tables(config_tables, efi.systab->nr_tables,
 					 sizeof(efi_config_table_64_t), NULL);
 
@@ -209,6 +213,14 @@ void __init efi_init(void)
 			 PAGE_ALIGN(params.mmap_size + (params.mmap & ~PAGE_MASK)));
 	memmap.phys_map = params.mmap;
 	memmap.map = early_memremap(params.mmap, params.mmap_size);
+	if (memmap.map == NULL) {
+		/*
+		* If we are booting via UEFI, the UEFI memory map is the only
+		* description of memory we have, so there is little point in
+		* proceeding if we cannot access it.
+		*/
+		panic("Unable to map EFI memory map.\n");
+	}
 	memmap.map_end = memmap.map + params.mmap_size;
 	memmap.desc_size = params.desc_size;
 	memmap.desc_version = params.desc_ver;

commit 3b12acf4c999abaf93023af4bd78d931bce2520c
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Nov 23 11:09:11 2015 +0000

    arm64: efi: correctly map runtime regions
    
    The kernel may use a page granularity of 4K, 16K, or 64K depending on
    configuration.
    
    When mapping EFI runtime regions, we use memrange_efi_to_native to round
    the physical base address of a region down to a kernel page boundary,
    and round the size up to a kernel page boundary, adding the residue left
    over from rounding down the physical base address. We do not round down
    the virtual base address.
    
    In __create_mapping we account for the offset of the virtual base from a
    granule boundary, adding the residue to the size before rounding the
    base down to said granule boundary.
    
    Thus we account for the residue twice, and when the residue is non-zero
    will cause __create_mapping to map an additional page at the end of the
    region. Depending on the memory map, this page may be in a region we are
    not intended/permitted to map, or may clash with a different region that
    we wish to map. In typical cases, mapping the next item in the memory
    map will overwrite the erroneously created entry, as we sort the memory
    map in the stub.
    
    As __create_mapping can cope with base addresses which are not page
    aligned, we can instead rely on it to map the region appropriately, and
    simplify efi_virtmap_init by removing the unnecessary code.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Leif Lindholm <leif.lindholm@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index fc5508e0df57..fe7cd1afa109 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -227,7 +227,6 @@ static bool __init efi_virtmap_init(void)
 	init_new_context(NULL, &efi_mm);
 
 	for_each_efi_memory_desc(&memmap, md) {
-		u64 paddr, npages, size;
 		pgprot_t prot;
 
 		if (!(md->attribute & EFI_MEMORY_RUNTIME))
@@ -235,11 +234,6 @@ static bool __init efi_virtmap_init(void)
 		if (md->virt_addr == 0)
 			return false;
 
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-
 		pr_info("  EFI remap 0x%016llx => %p\n",
 			md->phys_addr, (void *)md->virt_addr);
 
@@ -256,7 +250,8 @@ static bool __init efi_virtmap_init(void)
 		else
 			prot = PAGE_KERNEL;
 
-		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size,
+		create_pgd_mapping(&efi_mm, md->phys_addr, md->virt_addr,
+				   md->num_pages << EFI_PAGE_SHIFT, 
 				   __pgprot(pgprot_val(prot) | PTE_NG));
 	}
 	return true;

commit 65da0a8e34a857f2ba9ccb91dc8f8f964cf938b7
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Nov 17 09:53:31 2015 +0100

    arm64: use non-global mappings for UEFI runtime regions
    
    As pointed out by Russell King in response to the proposed ARM version
    of this code, the sequence to switch between the UEFI runtime mapping
    and current's actual userland mapping (and vice versa) is potentially
    unsafe, since it leaves a time window between the switch to the new
    page tables and the TLB flush where speculative accesses may hit on
    stale global TLB entries.
    
    So instead, use non-global mappings, and perform the switch via the
    ordinary ASID-aware context switch routines.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index de46b50f4cdf..fc5508e0df57 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -224,6 +224,8 @@ static bool __init efi_virtmap_init(void)
 {
 	efi_memory_desc_t *md;
 
+	init_new_context(NULL, &efi_mm);
+
 	for_each_efi_memory_desc(&memmap, md) {
 		u64 paddr, npages, size;
 		pgprot_t prot;
@@ -254,7 +256,8 @@ static bool __init efi_virtmap_init(void)
 		else
 			prot = PAGE_KERNEL;
 
-		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
+		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size,
+				   __pgprot(pgprot_val(prot) | PTE_NG));
 	}
 	return true;
 }
@@ -329,14 +332,7 @@ core_initcall(arm64_dmi_init);
 
 static void efi_set_pgd(struct mm_struct *mm)
 {
-	if (mm == &init_mm)
-		cpu_set_reserved_ttbr0();
-	else
-		cpu_switch_mm(mm->pgd, mm);
-
-	local_flush_tlb_all();
-	if (icache_is_aivivt())
-		__local_flush_icache_all();
+	switch_mm(NULL, mm, NULL);
 }
 
 void efi_virtmap_load(void)

commit 2dc10ad81fc017837037e60439662e1b16bdffb9
Merge: e627078a0cbd f8f8bdc48851
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 4 14:47:13 2015 -0800

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - "genirq: Introduce generic irq migration for cpu hotunplugged" patch
       merged from tip/irq/for-arm to allow the arm64-specific part to be
       upstreamed via the arm64 tree
    
     - CPU feature detection reworked to cope with heterogeneous systems
       where CPUs may not have exactly the same features.  The features
       reported by the kernel via internal data structures or ELF_HWCAP are
       delayed until all the CPUs are up (and before user space starts)
    
     - Support for 16KB pages, with the additional bonus of a 36-bit VA
       space, though the latter only depending on EXPERT
    
     - Implement native {relaxed, acquire, release} atomics for arm64
    
     - New ASID allocation algorithm which avoids IPI on roll-over, together
       with TLB invalidation optimisations (using local vs global where
       feasible)
    
     - KASan support for arm64
    
     - EFI_STUB clean-up and isolation for the kernel proper (required by
       KASan)
    
     - copy_{to,from,in}_user optimisations (sharing the memcpy template)
    
     - perf: moving arm64 to the arm32/64 shared PMU framework
    
     - L1_CACHE_BYTES increased to 128 to accommodate Cavium hardware
    
     - Support for the contiguous PTE hint on kernel mapping (16 consecutive
       entries may be able to use a single TLB entry)
    
     - Generic CONFIG_HZ now used on arm64
    
     - defconfig updates
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (91 commits)
      arm64/efi: fix libstub build under CONFIG_MODVERSIONS
      ARM64: Enable multi-core scheduler support by default
      arm64/efi: move arm64 specific stub C code to libstub
      arm64: page-align sections for DEBUG_RODATA
      arm64: Fix build with CONFIG_ZONE_DMA=n
      arm64: Fix compat register mappings
      arm64: Increase the max granular size
      arm64: remove bogus TASK_SIZE_64 check
      arm64: make Timer Interrupt Frequency selectable
      arm64/mm: use PAGE_ALIGNED instead of IS_ALIGNED
      arm64: cachetype: fix definitions of ICACHEF_* flags
      arm64: cpufeature: declare enable_cpu_capabilities as static
      genirq: Make the cpuhotplug migration code less noisy
      arm64: Constify hwcap name string arrays
      arm64/kvm: Make use of the system wide safe values
      arm64/debug: Make use of the system wide safe value
      arm64: Move FP/ASIMD hwcap handling to common code
      arm64/HWCAP: Use system wide safe values
      arm64/capabilities: Make use of system wide safe value
      arm64: Delay cpu feature capability checks
      ...

commit 44511fb9e55ada760822b0b0d7be9d150576f17f
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Oct 23 11:48:16 2015 +0200

    efi: Use correct type for struct efi_memory_map::phys_map
    
    We have been getting away with using a void* for the physical
    address of the UEFI memory map, since, even on 32-bit platforms
    with 64-bit physical addresses, no truncation takes place if the
    memory map has been allocated by the firmware (which only uses
    1:1 virtually addressable memory), which is usually the case.
    
    However, commit:
    
      0f96a99dab36 ("efi: Add "efi_fake_mem" boot option")
    
    adds code that clones and modifies the UEFI memory map, and the
    clone may live above 4 GB on 32-bit platforms.
    
    This means our use of void* for struct efi_memory_map::phys_map has
    graduated from 'incorrect but working' to 'incorrect and
    broken', and we need to fix it.
    
    So redefine struct efi_memory_map::phys_map as phys_addr_t, and
    get rid of a bunch of casts that are now unneeded.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Matt Fleming <matt@codeblueprint.co.uk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: izumi.taku@jp.fujitsu.com
    Cc: kamezawa.hiroyu@jp.fujitsu.com
    Cc: linux-efi@vger.kernel.org
    Cc: matt.fleming@intel.com
    Link: http://lkml.kernel.org/r/1445593697-1342-1-git-send-email-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4b7df346e388..61eb1d17586a 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -208,7 +208,7 @@ void __init efi_init(void)
 
 	memblock_reserve(params.mmap & PAGE_MASK,
 			 PAGE_ALIGN(params.mmap_size + (params.mmap & ~PAGE_MASK)));
-	memmap.phys_map = (void *)params.mmap;
+	memmap.phys_map = params.mmap;
 	memmap.map = early_memremap(params.mmap, params.mmap_size);
 	memmap.map_end = memmap.map + params.mmap_size;
 	memmap.desc_size = params.desc_size;
@@ -282,7 +282,7 @@ static int __init arm64_enable_runtime_services(void)
 	pr_info("Remapping and enabling EFI services.\n");
 
 	mapsize = memmap.map_end - memmap.map;
-	memmap.map = (__force void *)ioremap_cache((phys_addr_t)memmap.phys_map,
+	memmap.map = (__force void *)ioremap_cache(memmap.phys_map,
 						   mapsize);
 	if (!memmap.map) {
 		pr_err("Failed to remap EFI memory map\n");

commit 790a2ee2427852cff50993c98f15ed88511e9af0
Merge: c7d77a7980e4 0f96a99dab36
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Oct 14 16:05:40 2015 +0200

    Merge tag 'efi-next' of git://git.kernel.org/pub/scm/linux/kernel/git/mfleming/efi into core/efi
    
    Pull v4.4 EFI updates from Matt Fleming:
    
      - Make the EFI System Resource Table (ESRT) driver explicitly
        non-modular by ripping out the module_* code since Kconfig doesn't
        allow it to be built as a module anyway. (Paul Gortmaker)
    
      - Make the x86 efi=debug kernel parameter, which enables EFI debug
        code and output, generic and usable by arm64. (Leif Lindholm)
    
      - Add support to the x86 EFI boot stub for 64-bit Graphics Output
        Protocol frame buffer addresses. (Matt Fleming)
    
      - Detect when the UEFI v2.5 EFI_PROPERTIES_TABLE feature is enabled
        in the firmware and set an efi.flags bit so the kernel knows when
        it can apply more strict runtime mapping attributes - Ard Biesheuvel
    
      - Auto-load the efi-pstore module on EFI systems, just like we
        currently do for the efivars module. (Ben Hutchings)
    
      - Add "efi_fake_mem" kernel parameter which allows the system's EFI
        memory map to be updated with additional attributes for specific
        memory ranges. This is useful for testing the kernel code that handles
        the EFI_MEMORY_MORE_RELIABLE memmap bit even if your firmware
        doesn't include support. (Taku Izumi)
    
    Note: there is a semantic conflict between the following two commits:
    
      8a53554e12e9 ("x86/efi: Fix multiple GOP device support")
      ae2ee627dc87 ("efifb: Add support for 64-bit frame buffer addresses")
    
    I fixed up the interaction in the merge commit, changing the type of
    current_fb_base from u32 to u64.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 7968c0e338085eba0ee2f0e0b0d833057a966679
Author: Leif Lindholm <leif.lindholm@linaro.org>
Date:   Wed Aug 26 14:24:58 2015 +0100

    efi/arm64: Clean up efi_get_fdt_params() interface
    
    As we now have a common debug infrastructure between core and arm64 efi,
    drop the bit of the interface passing verbose output flags around.
    
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 612ad5ec1d2e..ab5eeb63e2ca 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -201,7 +201,7 @@ void __init efi_init(void)
 	struct efi_fdt_params params;
 
 	/* Grab UEFI information placed in FDT by stub */
-	if (!efi_get_fdt_params(&params, efi_enabled(EFI_DBG)))
+	if (!efi_get_fdt_params(&params))
 		return;
 
 	efi_system_table = params.system_table;

commit c9494dc818755f2dd934c93faa933317fae51594
Author: Leif Lindholm <leif.lindholm@linaro.org>
Date:   Wed Aug 26 14:24:57 2015 +0100

    arm64: Use core efi=debug instead of uefi_debug command line parameter
    
    Now that we have an efi=debug command line option in the core code, use
    this instead of the arm64-specific uefi_debug option.
    
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index e8ca6eaedd02..612ad5ec1d2e 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -51,15 +51,6 @@ static struct mm_struct efi_mm = {
 	INIT_MM_CONTEXT(efi_mm)
 };
 
-static int uefi_debug __initdata;
-static int __init uefi_debug_setup(char *str)
-{
-	uefi_debug = 1;
-
-	return 0;
-}
-early_param("uefi_debug", uefi_debug_setup);
-
 static int __init is_normal_ram(efi_memory_desc_t *md)
 {
 	if (md->attribute & EFI_MEMORY_WB)
@@ -171,14 +162,14 @@ static __init void reserve_regions(void)
 	efi_memory_desc_t *md;
 	u64 paddr, npages, size;
 
-	if (uefi_debug)
+	if (efi_enabled(EFI_DBG))
 		pr_info("Processing EFI memory map:\n");
 
 	for_each_efi_memory_desc(&memmap, md) {
 		paddr = md->phys_addr;
 		npages = md->num_pages;
 
-		if (uefi_debug) {
+		if (efi_enabled(EFI_DBG)) {
 			char buf[64];
 
 			pr_info("  0x%012llx-0x%012llx %s",
@@ -194,11 +185,11 @@ static __init void reserve_regions(void)
 
 		if (is_reserve_region(md)) {
 			memblock_reserve(paddr, size);
-			if (uefi_debug)
+			if (efi_enabled(EFI_DBG))
 				pr_cont("*");
 		}
 
-		if (uefi_debug)
+		if (efi_enabled(EFI_DBG))
 			pr_cont("\n");
 	}
 
@@ -210,7 +201,7 @@ void __init efi_init(void)
 	struct efi_fdt_params params;
 
 	/* Grab UEFI information placed in FDT by stub */
-	if (!efi_get_fdt_params(&params, uefi_debug))
+	if (!efi_get_fdt_params(&params, efi_enabled(EFI_DBG)))
 		return;
 
 	efi_system_table = params.system_table;

commit 5aec715d7d3122f77cabaa7578d9d25a0c1ed20e
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Oct 6 18:46:24 2015 +0100

    arm64: mm: rewrite ASID allocator and MM context-switching code
    
    Our current switch_mm implementation suffers from a number of problems:
    
      (1) The ASID allocator relies on IPIs to synchronise the CPUs on a
          rollover event
    
      (2) Because of (1), we cannot allocate ASIDs with interrupts disabled
          and therefore make use of a TIF_SWITCH_MM flag to postpone the
          actual switch to finish_arch_post_lock_switch
    
      (3) We run context switch with a reserved (invalid) TTBR0 value, even
          though the ASID and pgd are updated atomically
    
      (4) We take a global spinlock (cpu_asid_lock) during context-switch
    
      (5) We use h/w broadcast TLB operations when they are not required
          (e.g. in flush_context)
    
    This patch addresses these problems by rewriting the ASID algorithm to
    match the bitmap-based arch/arm/ implementation more closely. This in
    turn allows us to remove much of the complications surrounding switch_mm,
    including the ugly thread flag.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4d12926ea40d..a48d1f477b2e 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -48,7 +48,6 @@ static struct mm_struct efi_mm = {
 	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
 	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
 	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
-	INIT_MM_CONTEXT(efi_mm)
 };
 
 static int uefi_debug __initdata;

commit 8e63d38876691756f9bc6930850f1fb77809be1b
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Oct 6 18:46:23 2015 +0100

    arm64: flush: use local TLB and I-cache invalidation
    
    There are a number of places where a single CPU is running with a
    private page-table and we need to perform maintenance on the TLB and
    I-cache in order to ensure correctness, but do not require the operation
    to be broadcast to other CPUs.
    
    This patch adds local variants of tlb_flush_all and __flush_icache_all
    to support these use-cases and updates the callers respectively.
    __local_flush_icache_all also implies an isb, since it is intended to be
    used synchronously.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: David Daney <david.daney@cavium.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 13671a9cf016..4d12926ea40d 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -344,9 +344,9 @@ static void efi_set_pgd(struct mm_struct *mm)
 	else
 		cpu_switch_mm(mm->pgd, mm);
 
-	flush_tlb_all();
+	local_flush_tlb_all();
 	if (icache_is_aivivt())
-		__flush_icache_all();
+		__local_flush_icache_all();
 }
 
 void efi_virtmap_load(void)

commit 0ce3cc008ec04258b6a6314b09f1a6012810881a
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Sep 25 23:02:19 2015 +0100

    arm64/efi: Fix boot crash by not padding between EFI_MEMORY_RUNTIME regions
    
    The new Properties Table feature introduced in UEFIv2.5 may
    split memory regions that cover PE/COFF memory images into
    separate code and data regions. Since these regions only differ
    in the type (runtime code vs runtime data) and the permission
    bits, but not in the memory type attributes (UC/WC/WT/WB), the
    spec does not require them to be aligned to 64 KB.
    
    Since the relative offset of PE/COFF .text and .data segments
    cannot be changed on the fly, this means that we can no longer
    pad out those regions to be mappable using 64 KB pages.
    Unfortunately, there is no annotation in the UEFI memory map
    that identifies data regions that were split off from a code
    region, so we must apply this logic to all adjacent runtime
    regions whose attributes only differ in the permission bits.
    
    So instead of rounding each memory region to 64 KB alignment at
    both ends, only round down regions that are not directly
    preceded by another runtime region with the same type
    attributes. Since the UEFI spec does not mandate that the memory
    map be sorted, this means we also need to sort it first.
    
    Note that this change will result in all EFI_MEMORY_RUNTIME
    regions whose start addresses are not aligned to the OS page
    size to be mapped with executable permissions (i.e., on kernels
    compiled with 64 KB pages). However, since these mappings are
    only active during the time that UEFI Runtime Services are being
    invoked, the window for abuse is rather small.
    
    Tested-by: Mark Salter <msalter@redhat.com>
    Tested-by: Mark Rutland <mark.rutland@arm.com> [UEFI 2.4 only]
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Reviewed-by: Mark Salter <msalter@redhat.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Cc: <stable@vger.kernel.org> # v4.0+
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Leif Lindholm <leif.lindholm@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/1443218539-7610-3-git-send-email-matt@codeblueprint.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index e8ca6eaedd02..13671a9cf016 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -258,7 +258,8 @@ static bool __init efi_virtmap_init(void)
 		 */
 		if (!is_normal_ram(md))
 			prot = __pgprot(PROT_DEVICE_nGnRE);
-		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
+		else if (md->type == EFI_RUNTIME_SERVICES_CODE ||
+			 !PAGE_ALIGNED(md->phys_addr))
 			prot = PAGE_KERNEL_EXEC;
 		else
 			prot = PAGE_KERNEL;

commit f91b1feada0b6f0a4d33648155b3ded2c4e0707e
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sun Jul 26 14:59:00 2015 +0200

    arm64/efi: map the entire UEFI vendor string before reading it
    
    At boot, the UTF-16 UEFI vendor string is copied from the system
    table into a char array with a size of 100 bytes. However, this
    size of 100 bytes is also used for memremapping() the source,
    which may not be sufficient if the vendor string exceeds 50
    UTF-16 characters, and the placement of the vendor string inside
    a 4 KB page happens to leave the end unmapped.
    
    So use the correct '100 * sizeof(efi_char16_t)' for the size of
    the mapping.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Fixes: f84d02755f5a ("arm64: add EFI runtime services")
    Cc: <stable@vger.kernel.org> # 3.16+
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 9d4aa18f2a82..e8ca6eaedd02 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -122,12 +122,12 @@ static int __init uefi_init(void)
 
 	/* Show what we know for posterity */
 	c16 = early_memremap(efi_to_phys(efi.systab->fw_vendor),
-			     sizeof(vendor));
+			     sizeof(vendor) * sizeof(efi_char16_t));
 	if (c16) {
 		for (i = 0; i < (int) sizeof(vendor) - 1 && *c16; ++i)
 			vendor[i] = c16[i];
 		vendor[i] = '\0';
-		early_memunmap(c16, sizeof(vendor));
+		early_memunmap(c16, sizeof(vendor) * sizeof(efi_char16_t));
 	}
 
 	pr_info("EFI v%u.%.02u by %s\n",

commit ad5fb870c486d932a1749d7853dd70f436a7e03f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Apr 3 12:05:28 2015 -0400

    e820, efi: add ACPI 6.0 persistent memory types
    
    ACPI 6.0 formalizes e820-type-7 and efi-type-14 as persistent memory.
    Mark it "reserved" and allow it to be claimed by a persistent memory
    device driver.
    
    This definition is in addition to the Linux kernel's existing type-12
    definition that was recently added in support of shipping platforms with
    NVDIMM support that predate ACPI 6.0 (which now classifies type-12 as
    OEM reserved).
    
    Note, /proc/iomem can be consulted for differentiating legacy
    "Persistent Memory (legacy)" E820_PRAM vs standard "Persistent Memory"
    E820_PMEM.
    
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Jeff Moyer <jmoyer@redhat.com>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index ab21e0d58278..9d4aa18f2a82 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -158,6 +158,7 @@ static __init int is_reserve_region(efi_memory_desc_t *md)
 	case EFI_BOOT_SERVICES_CODE:
 	case EFI_BOOT_SERVICES_DATA:
 	case EFI_CONVENTIONAL_MEMORY:
+	case EFI_PERSISTENT_MEMORY:
 		return 0;
 	default:
 		break;

commit 130c93fd10c4d150e39d8879420c1351aa207fa9
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Mar 19 15:43:00 2015 +0000

    arm64: efi: don't restore TTBR0 if active_mm points at init_mm
    
    init_mm isn't a normal mm: it has swapper_pg_dir as its pgd (which
    contains kernel mappings) and is used as the active_mm for the idle
    thread.
    
    When restoring the pgd after an EFI call, we write current->active_mm
    into TTBR0. If the current task is actually the idle thread (e.g. when
    initialising the EFI RTC before entering userspace), then the TLB can
    erroneously populate itself with junk global entries as a result of
    speculative table walks.
    
    When we do eventually return to userspace, the task can end up hitting
    these junk mappings leading to lockups, corruption or crashes.
    
    This patch fixes the problem in the same way as the CPU suspend code by
    ensuring that we never switch to the init_mm in efi_set_pgd and instead
    point TTBR0 at the zero page. A check is also added to cpu_switch_mm to
    BUG if we get passed swapper_pg_dir.
    
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Fixes: f3cdfd239da5 ("arm64/efi: move SetVirtualAddressMap() to UEFI stub")
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 2b8d70164428..ab21e0d58278 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -337,7 +337,11 @@ core_initcall(arm64_dmi_init);
 
 static void efi_set_pgd(struct mm_struct *mm)
 {
-	cpu_switch_mm(mm->pgd, mm);
+	if (mm == &init_mm)
+		cpu_set_reserved_ttbr0();
+	else
+		cpu_switch_mm(mm->pgd, mm);
+
 	flush_tlb_all();
 	if (icache_is_aivivt())
 		__flush_icache_all();

commit 60c0d45a7f7ab4e30452fa14deb23a33e29adbc2
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Mar 6 15:49:24 2015 +0100

    efi/arm64: use UEFI for system reset and poweroff
    
    If UEFI Runtime Services are available, they are preferred over direct
    PSCI calls or other methods to reset the system.
    
    For the reset case, we need to hook into machine_restart(), as the
    arm_pm_restart function pointer may be overwritten by modules.
    
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Matt Fleming <matt.fleming@intel.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index b42c7b480e1e..2b8d70164428 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -354,3 +354,12 @@ void efi_virtmap_unload(void)
 	efi_set_pgd(current->active_mm);
 	preempt_enable();
 }
+
+/*
+ * UpdateCapsule() depends on the system being shutdown via
+ * ResetSystem().
+ */
+bool efi_poweroff_required(void)
+{
+	return efi_enabled(EFI_RUNTIME_SERVICES);
+}

commit 60305db9884515ca063474e262b454f6da04e4e2
Author: Ard Biesheuvel <ard.biesheuvel-QSEj5FYQhm4dnm+yROfE0A@public.gmane.org>
Date:   Thu Jan 22 10:01:40 2015 +0000

    arm64/efi: move virtmap init to early initcall
    
    Now that the create_mapping() code in mm/mmu.c is able to support
    setting up kernel page tables at initcall time, we can move the whole
    virtmap creation to arm64_enable_runtime_services() instead of having
    a distinct stage during early boot. This also allows us to drop the
    arm64-specific EFI_VIRTMAP flag.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel-QSEj5FYQhm4dnm+yROfE0A@public.gmane.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index c9cb0fbe7aa4..b42c7b480e1e 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -38,6 +38,19 @@ struct efi_memory_map memmap;
 
 static u64 efi_system_table;
 
+static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
+
+static struct mm_struct efi_mm = {
+	.mm_rb			= RB_ROOT,
+	.pgd			= efi_pgd,
+	.mm_users		= ATOMIC_INIT(2),
+	.mm_count		= ATOMIC_INIT(1),
+	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
+	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
+	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
+	INIT_MM_CONTEXT(efi_mm)
+};
+
 static int uefi_debug __initdata;
 static int __init uefi_debug_setup(char *str)
 {
@@ -213,6 +226,45 @@ void __init efi_init(void)
 		return;
 
 	reserve_regions();
+	early_memunmap(memmap.map, params.mmap_size);
+}
+
+static bool __init efi_virtmap_init(void)
+{
+	efi_memory_desc_t *md;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		u64 paddr, npages, size;
+		pgprot_t prot;
+
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+		if (md->virt_addr == 0)
+			return false;
+
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+
+		pr_info("  EFI remap 0x%016llx => %p\n",
+			md->phys_addr, (void *)md->virt_addr);
+
+		/*
+		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
+		 * executable, everything else can be mapped with the XN bits
+		 * set.
+		 */
+		if (!is_normal_ram(md))
+			prot = __pgprot(PROT_DEVICE_nGnRE);
+		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
+			prot = PAGE_KERNEL_EXEC;
+		else
+			prot = PAGE_KERNEL;
+
+		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
+	}
+	return true;
 }
 
 /*
@@ -254,7 +306,7 @@ static int __init arm64_enable_runtime_services(void)
 	}
 	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
 
-	if (!efi_enabled(EFI_VIRTMAP)) {
+	if (!efi_virtmap_init()) {
 		pr_err("No UEFI virtual mapping was installed -- runtime services will not be available\n");
 		return -1;
 	}
@@ -283,19 +335,6 @@ static int __init arm64_dmi_init(void)
 }
 core_initcall(arm64_dmi_init);
 
-static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
-
-static struct mm_struct efi_mm = {
-	.mm_rb			= RB_ROOT,
-	.pgd			= efi_pgd,
-	.mm_users		= ATOMIC_INIT(2),
-	.mm_count		= ATOMIC_INIT(1),
-	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
-	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
-	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
-	INIT_MM_CONTEXT(efi_mm)
-};
-
 static void efi_set_pgd(struct mm_struct *mm)
 {
 	cpu_switch_mm(mm->pgd, mm);
@@ -315,47 +354,3 @@ void efi_virtmap_unload(void)
 	efi_set_pgd(current->active_mm);
 	preempt_enable();
 }
-
-void __init efi_virtmap_init(void)
-{
-	efi_memory_desc_t *md;
-
-	if (!efi_enabled(EFI_BOOT))
-		return;
-
-	for_each_efi_memory_desc(&memmap, md) {
-		u64 paddr, npages, size;
-		pgprot_t prot;
-
-		if (!(md->attribute & EFI_MEMORY_RUNTIME))
-			continue;
-		if (WARN(md->virt_addr == 0,
-			 "UEFI virtual mapping incomplete or missing -- no entry found for 0x%llx\n",
-			 md->phys_addr))
-			return;
-
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-
-		pr_info("  EFI remap 0x%016llx => %p\n",
-			md->phys_addr, (void *)md->virt_addr);
-
-		/*
-		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
-		 * executable, everything else can be mapped with the XN bits
-		 * set.
-		 */
-		if (!is_normal_ram(md))
-			prot = __pgprot(PROT_DEVICE_nGnRE);
-		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
-			prot = PAGE_KERNEL_EXEC;
-		else
-			prot = PAGE_KERNEL;
-
-		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
-	}
-	set_bit(EFI_VIRTMAP, &efi.flags);
-	early_memunmap(memmap.map, memmap.map_end - memmap.map);
-}

commit 7fe5d2b1daf6fd82857a8d0ee47547d7852ebe7b
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Jan 15 12:01:06 2015 +0000

    arm64/efi: handle potential failure to remap memory map
    
    When remapping the UEFI memory map using ioremap_cache(), we
    have to deal with potential failure. Note that, even if the
    common case is for ioremap_cache() to return the existing linear
    mapping of the memory map, we cannot rely on that to be always the
    case, e.g., in the presence of a mem= kernel parameter.
    
    At the same time, remove a stale comment and move the memmap code
    together.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Mark Salter <msalter@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index a98415b5979c..c9cb0fbe7aa4 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -229,19 +229,21 @@ static int __init arm64_enable_runtime_services(void)
 		return -1;
 	}
 
-	mapsize = memmap.map_end - memmap.map;
-
 	if (efi_runtime_disabled()) {
 		pr_info("EFI runtime services will be disabled.\n");
 		return -1;
 	}
 
 	pr_info("Remapping and enabling EFI services.\n");
-	/* replace early memmap mapping with permanent mapping */
+
+	mapsize = memmap.map_end - memmap.map;
 	memmap.map = (__force void *)ioremap_cache((phys_addr_t)memmap.phys_map,
 						   mapsize);
+	if (!memmap.map) {
+		pr_err("Failed to remap EFI memory map\n");
+		return -1;
+	}
 	memmap.map_end = memmap.map + mapsize;
-
 	efi.memmap = &memmap;
 
 	efi.systab = (__force void *)ioremap_cache(efi_system_table,

commit 9679be103108926cfe9e6fd2f6829cefa77e47b0
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 16:41:38 2014 +0200

    arm64/efi: remove idmap manipulations from UEFI code
    
    Now that we have moved the call to SetVirtualAddressMap() to the stub,
    UEFI has no use for the ID map, so we can drop the code that installs
    ID mappings for UEFI memory regions.
    
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 4a5d7343dddd..a98415b5979c 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -54,27 +54,6 @@ static int __init is_normal_ram(efi_memory_desc_t *md)
 	return 0;
 }
 
-static void __init efi_setup_idmap(void)
-{
-	struct memblock_region *r;
-	efi_memory_desc_t *md;
-	u64 paddr, npages, size;
-
-	for_each_memblock(memory, r)
-		create_id_mapping(r->base, r->size, 0);
-
-	/* map runtime io spaces */
-	for_each_efi_memory_desc(&memmap, md) {
-		if (!(md->attribute & EFI_MEMORY_RUNTIME) || is_normal_ram(md))
-			continue;
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-		create_id_mapping(paddr, size, 1);
-	}
-}
-
 /*
  * Translate a EFI virtual address into a physical address: this is necessary,
  * as some data members of the EFI system table are virtually remapped after
@@ -236,16 +215,6 @@ void __init efi_init(void)
 	reserve_regions();
 }
 
-void __init efi_idmap_init(void)
-{
-	if (!efi_enabled(EFI_BOOT))
-		return;
-
-	/* boot time idmap_pg_dir is incomplete, so fill in missing parts */
-	efi_setup_idmap();
-	early_memunmap(memmap.map, memmap.map_end - memmap.map);
-}
-
 /*
  * Enable the UEFI Runtime Services if all prerequisites are in place, i.e.,
  * non-early mapping of the UEFI system table and virtual mappings for all
@@ -386,4 +355,5 @@ void __init efi_virtmap_init(void)
 		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
 	}
 	set_bit(EFI_VIRTMAP, &efi.flags);
+	early_memunmap(memmap.map, memmap.map_end - memmap.map);
 }

commit 3033b84596eaec0093b68c5711c265738eb0745d
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 16:35:21 2014 +0200

    arm64/efi: remove free_boot_services() and friends
    
    Now that we are calling SetVirtualAddressMap() from the stub, there is no
    need to reserve boot-only memory regions, which implies that there is also
    no reason to free them again later.
    
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 755e545144ea..4a5d7343dddd 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -199,9 +199,7 @@ static __init void reserve_regions(void)
 		if (is_normal_ram(md))
 			early_init_dt_add_memory_arch(paddr, size);
 
-		if (is_reserve_region(md) ||
-		    md->type == EFI_BOOT_SERVICES_CODE ||
-		    md->type == EFI_BOOT_SERVICES_DATA) {
+		if (is_reserve_region(md)) {
 			memblock_reserve(paddr, size);
 			if (uefi_debug)
 				pr_cont("*");
@@ -214,123 +212,6 @@ static __init void reserve_regions(void)
 	set_bit(EFI_MEMMAP, &efi.flags);
 }
 
-
-static u64 __init free_one_region(u64 start, u64 end)
-{
-	u64 size = end - start;
-
-	if (uefi_debug)
-		pr_info("  EFI freeing: 0x%012llx-0x%012llx\n",	start, end - 1);
-
-	free_bootmem_late(start, size);
-	return size;
-}
-
-static u64 __init free_region(u64 start, u64 end)
-{
-	u64 map_start, map_end, total = 0;
-
-	if (end <= start)
-		return total;
-
-	map_start = (u64)memmap.phys_map;
-	map_end = PAGE_ALIGN(map_start + (memmap.map_end - memmap.map));
-	map_start &= PAGE_MASK;
-
-	if (start < map_end && end > map_start) {
-		/* region overlaps UEFI memmap */
-		if (start < map_start)
-			total += free_one_region(start, map_start);
-
-		if (map_end < end)
-			total += free_one_region(map_end, end);
-	} else
-		total += free_one_region(start, end);
-
-	return total;
-}
-
-static void __init free_boot_services(void)
-{
-	u64 total_freed = 0;
-	u64 keep_end, free_start, free_end;
-	efi_memory_desc_t *md;
-
-	/*
-	 * If kernel uses larger pages than UEFI, we have to be careful
-	 * not to inadvertantly free memory we want to keep if there is
-	 * overlap at the kernel page size alignment. We do not want to
-	 * free is_reserve_region() memory nor the UEFI memmap itself.
-	 *
-	 * The memory map is sorted, so we keep track of the end of
-	 * any previous region we want to keep, remember any region
-	 * we want to free and defer freeing it until we encounter
-	 * the next region we want to keep. This way, before freeing
-	 * it, we can clip it as needed to avoid freeing memory we
-	 * want to keep for UEFI.
-	 */
-
-	keep_end = 0;
-	free_start = 0;
-
-	for_each_efi_memory_desc(&memmap, md) {
-		u64 paddr, npages, size;
-
-		if (is_reserve_region(md)) {
-			/*
-			 * We don't want to free any memory from this region.
-			 */
-			if (free_start) {
-				/* adjust free_end then free region */
-				if (free_end > md->phys_addr)
-					free_end -= PAGE_SIZE;
-				total_freed += free_region(free_start, free_end);
-				free_start = 0;
-			}
-			keep_end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
-			continue;
-		}
-
-		if (md->type != EFI_BOOT_SERVICES_CODE &&
-		    md->type != EFI_BOOT_SERVICES_DATA) {
-			/* no need to free this region */
-			continue;
-		}
-
-		/*
-		 * We want to free memory from this region.
-		 */
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-
-		if (free_start) {
-			if (paddr <= free_end)
-				free_end = paddr + size;
-			else {
-				total_freed += free_region(free_start, free_end);
-				free_start = paddr;
-				free_end = paddr + size;
-			}
-		} else {
-			free_start = paddr;
-			free_end = paddr + size;
-		}
-		if (free_start < keep_end) {
-			free_start += PAGE_SIZE;
-			if (free_start >= free_end)
-				free_start = 0;
-		}
-	}
-	if (free_start)
-		total_freed += free_region(free_start, free_end);
-
-	if (total_freed)
-		pr_info("Freed 0x%llx bytes of EFI boot services memory",
-			total_freed);
-}
-
 void __init efi_init(void)
 {
 	struct efi_fdt_params params;
@@ -402,8 +283,6 @@ static int __init arm64_enable_runtime_services(void)
 	}
 	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
 
-	free_boot_services();
-
 	if (!efi_enabled(EFI_VIRTMAP)) {
 		pr_err("No UEFI virtual mapping was installed -- runtime services will not be available\n");
 		return -1;

commit f3cdfd239da56a4cea75a2920dc326f0f45f67e3
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 16:27:26 2014 +0200

    arm64/efi: move SetVirtualAddressMap() to UEFI stub
    
    In order to support kexec, the kernel needs to be able to deal with the
    state of the UEFI firmware after SetVirtualAddressMap() has been called.
    To avoid having separate code paths for non-kexec and kexec, let's move
    the call to SetVirtualAddressMap() to the stub: this will guarantee us
    that it will only be called once (since the stub is not executed during
    kexec), and ensures that the UEFI state is identical between kexec and
    normal boot.
    
    This implies that the layout of the virtual mapping needs to be created
    by the stub as well. All regions are rounded up to a naturally aligned
    multiple of 64 KB (for compatibility with 64k pages kernels) and recorded
    in the UEFI memory map. The kernel proper reads those values and installs
    the mappings in a dedicated set of page tables that are swapped in during
    UEFI Runtime Services calls.
    
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Matt Fleming <matt.fleming@intel.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 2bb4347d0edf..755e545144ea 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -11,25 +11,31 @@
  *
  */
 
+#include <linux/atomic.h>
 #include <linux/dmi.h>
 #include <linux/efi.h>
 #include <linux/export.h>
 #include <linux/memblock.h>
+#include <linux/mm_types.h>
 #include <linux/bootmem.h>
 #include <linux/of.h>
 #include <linux/of_fdt.h>
+#include <linux/preempt.h>
+#include <linux/rbtree.h>
+#include <linux/rwsem.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
+#include <linux/spinlock.h>
 
 #include <asm/cacheflush.h>
 #include <asm/efi.h>
 #include <asm/tlbflush.h>
 #include <asm/mmu_context.h>
+#include <asm/mmu.h>
+#include <asm/pgtable.h>
 
 struct efi_memory_map memmap;
 
-static efi_runtime_services_t *runtime;
-
 static u64 efi_system_table;
 
 static int uefi_debug __initdata;
@@ -69,9 +75,33 @@ static void __init efi_setup_idmap(void)
 	}
 }
 
+/*
+ * Translate a EFI virtual address into a physical address: this is necessary,
+ * as some data members of the EFI system table are virtually remapped after
+ * SetVirtualAddressMap() has been called.
+ */
+static phys_addr_t efi_to_phys(unsigned long addr)
+{
+	efi_memory_desc_t *md;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+		if (md->virt_addr == 0)
+			/* no virtual mapping has been installed by the stub */
+			break;
+		if (md->virt_addr <= addr &&
+		    (addr - md->virt_addr) < (md->num_pages << EFI_PAGE_SHIFT))
+			return md->phys_addr + addr - md->virt_addr;
+	}
+	return addr;
+}
+
 static int __init uefi_init(void)
 {
 	efi_char16_t *c16;
+	void *config_tables;
+	u64 table_size;
 	char vendor[100] = "unknown";
 	int i, retval;
 
@@ -99,7 +129,7 @@ static int __init uefi_init(void)
 			efi.systab->hdr.revision & 0xffff);
 
 	/* Show what we know for posterity */
-	c16 = early_memremap(efi.systab->fw_vendor,
+	c16 = early_memremap(efi_to_phys(efi.systab->fw_vendor),
 			     sizeof(vendor));
 	if (c16) {
 		for (i = 0; i < (int) sizeof(vendor) - 1 && *c16; ++i)
@@ -112,8 +142,14 @@ static int __init uefi_init(void)
 		efi.systab->hdr.revision >> 16,
 		efi.systab->hdr.revision & 0xffff, vendor);
 
-	retval = efi_config_init(NULL);
+	table_size = sizeof(efi_config_table_64_t) * efi.systab->nr_tables;
+	config_tables = early_memremap(efi_to_phys(efi.systab->tables),
+				       table_size);
+
+	retval = efi_config_parse_tables(config_tables, efi.systab->nr_tables,
+					 sizeof(efi_config_table_64_t), NULL);
 
+	early_memunmap(config_tables, table_size);
 out:
 	early_memunmap(efi.systab,  sizeof(efi_system_table_t));
 	return retval;
@@ -329,51 +365,14 @@ void __init efi_idmap_init(void)
 	early_memunmap(memmap.map, memmap.map_end - memmap.map);
 }
 
-static int __init remap_region(efi_memory_desc_t *md, void **new)
-{
-	u64 paddr, vaddr, npages, size;
-
-	paddr = md->phys_addr;
-	npages = md->num_pages;
-	memrange_efi_to_native(&paddr, &npages);
-	size = npages << PAGE_SHIFT;
-
-	if (is_normal_ram(md))
-		vaddr = (__force u64)ioremap_cache(paddr, size);
-	else
-		vaddr = (__force u64)ioremap(paddr, size);
-
-	if (!vaddr) {
-		pr_err("Unable to remap 0x%llx pages @ %p\n",
-		       npages, (void *)paddr);
-		return 0;
-	}
-
-	/* adjust for any rounding when EFI and system pagesize differs */
-	md->virt_addr = vaddr + (md->phys_addr - paddr);
-
-	if (uefi_debug)
-		pr_info("  EFI remap 0x%012llx => %p\n",
-			md->phys_addr, (void *)md->virt_addr);
-
-	memcpy(*new, md, memmap.desc_size);
-	*new += memmap.desc_size;
-
-	return 1;
-}
-
 /*
- * Switch UEFI from an identity map to a kernel virtual map
+ * Enable the UEFI Runtime Services if all prerequisites are in place, i.e.,
+ * non-early mapping of the UEFI system table and virtual mappings for all
+ * EFI_MEMORY_RUNTIME regions.
  */
-static int __init arm64_enter_virtual_mode(void)
+static int __init arm64_enable_runtime_services(void)
 {
-	efi_memory_desc_t *md;
-	phys_addr_t virtmap_phys;
-	void *virtmap, *virt_md;
-	efi_status_t status;
 	u64 mapsize;
-	int count = 0;
-	unsigned long flags;
 
 	if (!efi_enabled(EFI_BOOT)) {
 		pr_info("EFI services will not be available.\n");
@@ -395,81 +394,30 @@ static int __init arm64_enter_virtual_mode(void)
 
 	efi.memmap = &memmap;
 
-	/* Map the runtime regions */
-	virtmap = kmalloc(mapsize, GFP_KERNEL);
-	if (!virtmap) {
-		pr_err("Failed to allocate EFI virtual memmap\n");
-		return -1;
-	}
-	virtmap_phys = virt_to_phys(virtmap);
-	virt_md = virtmap;
-
-	for_each_efi_memory_desc(&memmap, md) {
-		if (!(md->attribute & EFI_MEMORY_RUNTIME))
-			continue;
-		if (!remap_region(md, &virt_md))
-			goto err_unmap;
-		++count;
-	}
-
-	efi.systab = (__force void *)efi_lookup_mapped_addr(efi_system_table);
+	efi.systab = (__force void *)ioremap_cache(efi_system_table,
+						   sizeof(efi_system_table_t));
 	if (!efi.systab) {
-		/*
-		 * If we have no virtual mapping for the System Table at this
-		 * point, the memory map doesn't cover the physical offset where
-		 * it resides. This means the System Table will be inaccessible
-		 * to Runtime Services themselves once the virtual mapping is
-		 * installed.
-		 */
-		pr_err("Failed to remap EFI System Table -- buggy firmware?\n");
-		goto err_unmap;
+		pr_err("Failed to remap EFI System Table\n");
+		return -1;
 	}
 	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
 
-	local_irq_save(flags);
-	cpu_switch_mm(idmap_pg_dir, &init_mm);
-
-	/* Call SetVirtualAddressMap with the physical address of the map */
-	runtime = efi.systab->runtime;
-	efi.set_virtual_address_map = runtime->set_virtual_address_map;
-
-	status = efi.set_virtual_address_map(count * memmap.desc_size,
-					     memmap.desc_size,
-					     memmap.desc_version,
-					     (efi_memory_desc_t *)virtmap_phys);
-	cpu_set_reserved_ttbr0();
-	flush_tlb_all();
-	local_irq_restore(flags);
-
-	kfree(virtmap);
-
 	free_boot_services();
 
-	if (status != EFI_SUCCESS) {
-		pr_err("Failed to set EFI virtual address map! [%lx]\n",
-			status);
+	if (!efi_enabled(EFI_VIRTMAP)) {
+		pr_err("No UEFI virtual mapping was installed -- runtime services will not be available\n");
 		return -1;
 	}
 
 	/* Set up runtime services function pointers */
-	runtime = efi.systab->runtime;
 	efi_native_runtime_setup();
 	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
 
 	efi.runtime_version = efi.systab->hdr.revision;
 
 	return 0;
-
-err_unmap:
-	/* unmap all mappings that succeeded: there are 'count' of those */
-	for (virt_md = virtmap; count--; virt_md += memmap.desc_size) {
-		md = virt_md;
-		iounmap((__force void __iomem *)md->virt_addr);
-	}
-	kfree(virtmap);
-	return -1;
 }
-early_initcall(arm64_enter_virtual_mode);
+early_initcall(arm64_enable_runtime_services);
 
 static int __init arm64_dmi_init(void)
 {
@@ -484,3 +432,79 @@ static int __init arm64_dmi_init(void)
 	return 0;
 }
 core_initcall(arm64_dmi_init);
+
+static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
+
+static struct mm_struct efi_mm = {
+	.mm_rb			= RB_ROOT,
+	.pgd			= efi_pgd,
+	.mm_users		= ATOMIC_INIT(2),
+	.mm_count		= ATOMIC_INIT(1),
+	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
+	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
+	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
+	INIT_MM_CONTEXT(efi_mm)
+};
+
+static void efi_set_pgd(struct mm_struct *mm)
+{
+	cpu_switch_mm(mm->pgd, mm);
+	flush_tlb_all();
+	if (icache_is_aivivt())
+		__flush_icache_all();
+}
+
+void efi_virtmap_load(void)
+{
+	preempt_disable();
+	efi_set_pgd(&efi_mm);
+}
+
+void efi_virtmap_unload(void)
+{
+	efi_set_pgd(current->active_mm);
+	preempt_enable();
+}
+
+void __init efi_virtmap_init(void)
+{
+	efi_memory_desc_t *md;
+
+	if (!efi_enabled(EFI_BOOT))
+		return;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		u64 paddr, npages, size;
+		pgprot_t prot;
+
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+		if (WARN(md->virt_addr == 0,
+			 "UEFI virtual mapping incomplete or missing -- no entry found for 0x%llx\n",
+			 md->phys_addr))
+			return;
+
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+
+		pr_info("  EFI remap 0x%016llx => %p\n",
+			md->phys_addr, (void *)md->virt_addr);
+
+		/*
+		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
+		 * executable, everything else can be mapped with the XN bits
+		 * set.
+		 */
+		if (!is_normal_ram(md))
+			prot = __pgprot(PROT_DEVICE_nGnRE);
+		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
+			prot = PAGE_KERNEL_EXEC;
+		else
+			prot = PAGE_KERNEL;
+
+		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
+	}
+	set_bit(EFI_VIRTMAP, &efi.flags);
+}

commit 0e63ea48b4d8035dd0e91a3fa6fb79458b47adfb
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Jan 8 09:54:58 2015 +0000

    arm64/efi: add missing call to early_ioremap_reset()
    
    The early ioremap support introduced by patch bf4b558eba92
    ("arm64: add early_ioremap support") failed to add a call to
    early_ioremap_reset() at an appropriate time. Without this call,
    invocations of early_ioremap etc. that are done too late will go
    unnoticed and may cause corruption.
    
    This is exactly what happened when the first user of this feature
    was added in patch f84d02755f5a ("arm64: add EFI runtime services").
    The early mapping of the EFI memory map is unmapped during an early
    initcall, at which time the early ioremap support is long gone.
    
    Fix by adding the missing call to early_ioremap_reset() to
    setup_arch(), and move the offending early_memunmap() to right after
    the point where the early mapping of the EFI memory map is last used.
    
    Fixes: f84d02755f5a ("arm64: add EFI runtime services")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 6fac253bc783..2bb4347d0edf 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -326,6 +326,7 @@ void __init efi_idmap_init(void)
 
 	/* boot time idmap_pg_dir is incomplete, so fill in missing parts */
 	efi_setup_idmap();
+	early_memunmap(memmap.map, memmap.map_end - memmap.map);
 }
 
 static int __init remap_region(efi_memory_desc_t *md, void **new)
@@ -380,7 +381,6 @@ static int __init arm64_enter_virtual_mode(void)
 	}
 
 	mapsize = memmap.map_end - memmap.map;
-	early_memunmap(memmap.map, mapsize);
 
 	if (efi_runtime_disabled()) {
 		pr_info("EFI runtime services will be disabled.\n");

commit b07bfaa3c126e4e36a2b59350b3b930aa1b121ac
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Oct 15 09:36:50 2014 +0200

    arm64: dmi: set DMI string as dump stack arch description
    
    This sets the DMI string, containing system type, serial number,
    firmware version etc. as dump stack arch description, so that oopses
    and other kernel stack dumps automatically have this information
    included, if available.
    
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 9ae5e7918b8f..6fac253bc783 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -479,6 +479,8 @@ static int __init arm64_dmi_init(void)
 	 * itself, depends on dmi_scan_machine() having been called already.
 	 */
 	dmi_scan_machine();
+	if (dmi_available)
+		dmi_set_dump_stack_arch_desc();
 	return 0;
 }
 core_initcall(arm64_dmi_init);

commit d1ae8c0057921681ca489bba7efbfacbb60d0f28
Author: Yi Li <yi.li@linaro.org>
Date:   Sat Oct 4 23:46:43 2014 +0800

    arm64: dmi: Add SMBIOS/DMI support
    
    SMBIOS is important for server hardware vendors. It implements a spec for
    providing descriptive information about the platform. Things like serial
    numbers, physical layout of the ports, build configuration data, and the like.
    
    Signed-off-by: Yi Li <yi.li@linaro.org>
    Tested-by: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 558572ef1ea3..9ae5e7918b8f 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -11,6 +11,7 @@
  *
  */
 
+#include <linux/dmi.h>
 #include <linux/efi.h>
 #include <linux/export.h>
 #include <linux/memblock.h>
@@ -469,3 +470,15 @@ static int __init arm64_enter_virtual_mode(void)
 	return -1;
 }
 early_initcall(arm64_enter_virtual_mode);
+
+static int __init arm64_dmi_init(void)
+{
+	/*
+	 * On arm64, DMI depends on UEFI, and dmi_scan_machine() needs to
+	 * be called early because dmi_id_init(), which is an arch_initcall
+	 * itself, depends on dmi_scan_machine() having been called already.
+	 */
+	dmi_scan_machine();
+	return 0;
+}
+core_initcall(arm64_dmi_init);

commit 4e27d4754e8990da264c1e01e2f6bd8340e30cb3
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Oct 17 12:44:11 2014 +0200

    arm64/efi: drop redundant set_bit(EFI_CONFIG_TABLES)
    
    The EFI_CONFIG_TABLES bit already gets set by efi_config_init(),
    so there is no reason to set it again after this function returns
    successfully.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 2e829148fb36..558572ef1ea3 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -112,8 +112,6 @@ static int __init uefi_init(void)
 		efi.systab->hdr.revision & 0xffff, vendor);
 
 	retval = efi_config_init(NULL);
-	if (retval == 0)
-		set_bit(EFI_CONFIG_TABLES, &efi.flags);
 
 out:
 	early_memunmap(efi.systab,  sizeof(efi_system_table_t));

commit 61139eb04056bba69aeef6c481802c4ea028bf4d
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 15:31:57 2014 +0200

    arm64/efi: invert UEFI memory region reservation logic
    
    Instead of reserving the memory regions based on which types we know
    need to be reserved, consider only regions of the following types as
    free for general use by the OS:
    
    EFI_LOADER_CODE
    EFI_LOADER_DATA
    EFI_BOOT_SERVICES_CODE
    EFI_BOOT_SERVICES_DATA
    EFI_CONVENTIONAL_MEMORY
    
    Note that this also fixes a problem with the original code, which would
    misidentify a EFI_RUNTIME_SERVICES_DATA region as not reserved if it
    does not have the EFI_MEMORY_RUNTIME attribute set. However, it is
    perfectly legal for the firmware not to request a virtual mapping for
    EFI_RUNTIME_SERVICES_DATA regions that contain configuration tables, in
    which case the EFI_MEMORY_RUNTIME attribute would not be set.
    
    Acked-by: Roy Franz <roy.franz@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 95c49ebc660d..2e829148fb36 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -125,17 +125,17 @@ static int __init uefi_init(void)
  */
 static __init int is_reserve_region(efi_memory_desc_t *md)
 {
-	if (!is_normal_ram(md))
+	switch (md->type) {
+	case EFI_LOADER_CODE:
+	case EFI_LOADER_DATA:
+	case EFI_BOOT_SERVICES_CODE:
+	case EFI_BOOT_SERVICES_DATA:
+	case EFI_CONVENTIONAL_MEMORY:
 		return 0;
-
-	if (md->attribute & EFI_MEMORY_RUNTIME)
-		return 1;
-
-	if (md->type == EFI_ACPI_RECLAIM_MEMORY ||
-	    md->type == EFI_RESERVED_TYPE)
-		return 1;
-
-	return 0;
+	default:
+		break;
+	}
+	return is_normal_ram(md);
 }
 
 static __init void reserve_regions(void)

commit 75b128573b275d5a5a7210b98c4b8cb3b39c12e7
Merge: fe82dcec6442 7efe665903d0
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Oct 3 22:15:56 2014 +0100

    Merge branch 'next' into efi-next-merge
    
    Conflicts:
            arch/x86/boot/compressed/eboot.c

commit 65ba758f3e7d99c49b5710f6010bc6ba1e50d16c
Author: Laszlo Ersek <lersek@redhat.com>
Date:   Wed Sep 3 13:32:23 2014 +0200

    arm64: efi: Format EFI memory type & attrs with efi_md_typeattr_format()
    
    An example log excerpt demonstrating the change:
    
    Before the patch:
    
    > Processing EFI memory map:
    >   0x000040000000-0x000040000fff [Loader Data]
    >   0x000040001000-0x00004007ffff [Conventional Memory]
    >   0x000040080000-0x00004072afff [Loader Data]
    >   0x00004072b000-0x00005fdfffff [Conventional Memory]
    >   0x00005fe00000-0x00005fe0ffff [Loader Data]
    >   0x00005fe10000-0x0000964e8fff [Conventional Memory]
    >   0x0000964e9000-0x0000964e9fff [Loader Data]
    >   0x0000964ea000-0x000096c52fff [Loader Code]
    >   0x000096c53000-0x00009709dfff [Boot Code]*
    >   0x00009709e000-0x0000970b3fff [Runtime Code]*
    >   0x0000970b4000-0x0000970f4fff [Runtime Data]*
    >   0x0000970f5000-0x000097117fff [Runtime Code]*
    >   0x000097118000-0x000097199fff [Runtime Data]*
    >   0x00009719a000-0x0000971dffff [Runtime Code]*
    >   0x0000971e0000-0x0000997f8fff [Conventional Memory]
    >   0x0000997f9000-0x0000998f1fff [Boot Data]*
    >   0x0000998f2000-0x0000999eafff [Conventional Memory]
    >   0x0000999eb000-0x00009af09fff [Boot Data]*
    >   0x00009af0a000-0x00009af21fff [Conventional Memory]
    >   0x00009af22000-0x00009af46fff [Boot Data]*
    >   0x00009af47000-0x00009af5bfff [Conventional Memory]
    >   0x00009af5c000-0x00009afe1fff [Boot Data]*
    >   0x00009afe2000-0x00009afe2fff [Conventional Memory]
    >   0x00009afe3000-0x00009c01ffff [Boot Data]*
    >   0x00009c020000-0x00009efbffff [Conventional Memory]
    >   0x00009efc0000-0x00009f14efff [Boot Code]*
    >   0x00009f14f000-0x00009f162fff [Runtime Code]*
    >   0x00009f163000-0x00009f194fff [Runtime Data]*
    >   0x00009f195000-0x00009f197fff [Boot Data]*
    >   0x00009f198000-0x00009f198fff [Runtime Data]*
    >   0x00009f199000-0x00009f1acfff [Conventional Memory]
    >   0x00009f1ad000-0x00009f1affff [Boot Data]*
    >   0x00009f1b0000-0x00009f1b0fff [Runtime Data]*
    >   0x00009f1b1000-0x00009fffffff [Boot Data]*
    >   0x000004000000-0x000007ffffff [Memory Mapped I/O]
    >   0x000009010000-0x000009010fff [Memory Mapped I/O]
    
    After the patch:
    
    > Processing EFI memory map:
    >   0x000040000000-0x000040000fff [Loader Data        |   |  |  |  |   |WB|WT|WC|UC]
    >   0x000040001000-0x00004007ffff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x000040080000-0x00004072afff [Loader Data        |   |  |  |  |   |WB|WT|WC|UC]
    >   0x00004072b000-0x00005fdfffff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00005fe00000-0x00005fe0ffff [Loader Data        |   |  |  |  |   |WB|WT|WC|UC]
    >   0x00005fe10000-0x0000964e8fff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x0000964e9000-0x0000964e9fff [Loader Data        |   |  |  |  |   |WB|WT|WC|UC]
    >   0x0000964ea000-0x000096c52fff [Loader Code        |   |  |  |  |   |WB|WT|WC|UC]
    >   0x000096c53000-0x00009709dfff [Boot Code          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009709e000-0x0000970b3fff [Runtime Code       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x0000970b4000-0x0000970f4fff [Runtime Data       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x0000970f5000-0x000097117fff [Runtime Code       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x000097118000-0x000097199fff [Runtime Data       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x00009719a000-0x0000971dffff [Runtime Code       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x0000971e0000-0x0000997f8fff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x0000997f9000-0x0000998f1fff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x0000998f2000-0x0000999eafff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x0000999eb000-0x00009af09fff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009af0a000-0x00009af21fff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00009af22000-0x00009af46fff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009af47000-0x00009af5bfff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00009af5c000-0x00009afe1fff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009afe2000-0x00009afe2fff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00009afe3000-0x00009c01ffff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009c020000-0x00009efbffff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00009efc0000-0x00009f14efff [Boot Code          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f14f000-0x00009f162fff [Runtime Code       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f163000-0x00009f194fff [Runtime Data       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f195000-0x00009f197fff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f198000-0x00009f198fff [Runtime Data       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f199000-0x00009f1acfff [Conventional Memory|   |  |  |  |   |WB|WT|WC|UC]
    >   0x00009f1ad000-0x00009f1affff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f1b0000-0x00009f1b0fff [Runtime Data       |RUN|  |  |  |   |WB|WT|WC|UC]*
    >   0x00009f1b1000-0x00009fffffff [Boot Data          |   |  |  |  |   |WB|WT|WC|UC]*
    >   0x000004000000-0x000007ffffff [Memory Mapped I/O  |RUN|  |  |  |   |  |  |  |UC]
    >   0x000009010000-0x000009010fff [Memory Mapped I/O  |RUN|  |  |  |   |  |  |  |UC]
    
    The attribute bitmap is now displayed, in decoded form.
    
    Signed-off-by: Laszlo Ersek <lersek@redhat.com>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 8f5db4a3c9d9..865fdf5c7344 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -120,23 +120,6 @@ static int __init uefi_init(void)
 	return retval;
 }
 
-static __initdata char memory_type_name[][32] = {
-	{"Reserved"},
-	{"Loader Code"},
-	{"Loader Data"},
-	{"Boot Code"},
-	{"Boot Data"},
-	{"Runtime Code"},
-	{"Runtime Data"},
-	{"Conventional Memory"},
-	{"Unusable Memory"},
-	{"ACPI Reclaim Memory"},
-	{"ACPI Memory NVS"},
-	{"Memory Mapped I/O"},
-	{"MMIO Port Space"},
-	{"PAL Code"},
-};
-
 /*
  * Return true for RAM regions we want to permanently reserve.
  */
@@ -167,10 +150,13 @@ static __init void reserve_regions(void)
 		paddr = md->phys_addr;
 		npages = md->num_pages;
 
-		if (uefi_debug)
-			pr_info("  0x%012llx-0x%012llx [%s]",
+		if (uefi_debug) {
+			char buf[64];
+
+			pr_info("  0x%012llx-0x%012llx %s",
 				paddr, paddr + (npages << EFI_PAGE_SHIFT) - 1,
-				memory_type_name[md->type]);
+				efi_md_typeattr_format(buf, sizeof(buf), md));
+		}
 
 		memrange_efi_to_native(&paddr, &npages);
 		size = npages << PAGE_SHIFT;

commit 6632210f50530ea53dd21f786f2854609d928689
Author: Dave Young <dyoung@redhat.com>
Date:   Mon Aug 18 09:30:07 2014 +0800

    arm64/efi: Do not enter virtual mode if booting with efi=noruntime or noefi
    
    In case efi runtime disabled via noefi kernel cmdline
    arm64_enter_virtual_mode should error out.
    
    At the same time move early_memunmap(memmap.map, mapsize) to the
    beginning of the function or it will leak early mem.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 6ed0362dd579..8f5db4a3c9d9 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -392,11 +392,16 @@ static int __init arm64_enter_virtual_mode(void)
 		return -1;
 	}
 
-	pr_info("Remapping and enabling EFI services.\n");
-
-	/* replace early memmap mapping with permanent mapping */
 	mapsize = memmap.map_end - memmap.map;
 	early_memunmap(memmap.map, mapsize);
+
+	if (efi_runtime_disabled()) {
+		pr_info("EFI runtime services will be disabled.\n");
+		return -1;
+	}
+
+	pr_info("Remapping and enabling EFI services.\n");
+	/* replace early memmap mapping with permanent mapping */
 	memmap.map = (__force void *)ioremap_cache((phys_addr_t)memmap.phys_map,
 						   mapsize);
 	memmap.map_end = memmap.map + mapsize;

commit 88f8abd594082b9c08789e8527e4e38116a963ec
Author: Dave Young <dyoung@redhat.com>
Date:   Thu Aug 14 17:15:29 2014 +0800

    arm64/efi: uefi_init error handling fix
    
    There's one early memmap leak in uefi_init error path, fix it and
    slightly tune the error handling code.
    
    Signed-off-by: Dave Young <dyoung@redhat.com>
    Acked-by: Mark Salter <msalter@redhat.com>
    Reported-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index e72f3100958f..6ed0362dd579 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -89,7 +89,8 @@ static int __init uefi_init(void)
 	 */
 	if (efi.systab->hdr.signature != EFI_SYSTEM_TABLE_SIGNATURE) {
 		pr_err("System table signature incorrect\n");
-		return -EINVAL;
+		retval = -EINVAL;
+		goto out;
 	}
 	if ((efi.systab->hdr.revision >> 16) < 2)
 		pr_warn("Warning: EFI system table version %d.%02d, expected 2.00 or greater\n",
@@ -103,6 +104,7 @@ static int __init uefi_init(void)
 		for (i = 0; i < (int) sizeof(vendor) - 1 && *c16; ++i)
 			vendor[i] = c16[i];
 		vendor[i] = '\0';
+		early_memunmap(c16, sizeof(vendor));
 	}
 
 	pr_info("EFI v%u.%.02u by %s\n",
@@ -113,9 +115,8 @@ static int __init uefi_init(void)
 	if (retval == 0)
 		set_bit(EFI_CONFIG_TABLES, &efi.flags);
 
-	early_memunmap(c16, sizeof(vendor));
+out:
 	early_memunmap(efi.systab,  sizeof(efi_system_table_t));
-
 	return retval;
 }
 

commit 7be141d0554921751db103b54e9f794956aa4f65
Merge: 44744bb344ab 80b304fd00e8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Aug 24 16:17:41 2014 -0700

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 fixes from Ingo Molnar:
     "A couple of EFI fixes, plus misc fixes all around the map"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      efi/arm64: Store Runtime Services revision
      firmware: Do not use WARN_ON(!spin_is_locked())
      x86_32, entry: Clean up sysenter_badsys declaration
      x86/doc: Fix the 'tlb_single_page_flush_ceiling' sysconfig path
      x86/mm: Fix sparse 'tlb_single_page_flush_ceiling' warning and make the variable read-mostly
      x86/mm: Fix RCU splat from new TLB tracepoints

commit 6a7519e81321343165f89abb8b616df186d3e57a
Author: Semen Protsenko <semen.protsenko@linaro.org>
Date:   Fri Aug 15 16:22:44 2014 +0300

    efi/arm64: Store Runtime Services revision
    
    "efi" global data structure contains "runtime_version" field which must
    be assigned in order to use it later in Runtime Services virtual calls
    (virt_efi_* functions).
    
    Before this patch "runtime_version" was unassigned (0), so each
    Runtime Service virtual call that checks revision would fail.
    
    Signed-off-by: Semen Protsenko <semen.protsenko@linaro.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index e72f3100958f..5dbb7bd3b838 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -463,6 +463,8 @@ static int __init arm64_enter_virtual_mode(void)
 	efi_native_runtime_setup();
 	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
 
+	efi.runtime_version = efi.systab->hdr.revision;
+
 	return 0;
 
 err_unmap:

commit 86c8b27a01cf6c16fc159ade223cb2ccc70dc4b5
Author: Leif Lindholm <leif.lindholm@linaro.org>
Date:   Mon Jul 28 19:03:03 2014 +0100

    arm64: ignore DT memreserve entries when booting in UEFI mode
    
    UEFI provides its own method for marking regions to reserve, via the
    memory map which is also used to initialise memblock. So when using the
    UEFI memory map, ignore any memreserve entries present in the DT.
    
    Reported-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index e72f3100958f..24f0c6fb61d8 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -188,6 +188,8 @@ static __init void reserve_regions(void)
 		if (uefi_debug)
 			pr_cont("\n");
 	}
+
+	set_bit(EFI_MEMMAP, &efi.flags);
 }
 
 

commit 99a5603e2a1f146ac0c6414d8a3669aa749ccff8
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Jul 4 17:25:09 2014 +0200

    efi/arm64: Handle missing virtual mapping for UEFI System Table
    
    If we cannot resolve the virtual address of the UEFI System Table, its
    physical offset must be missing from the virtual memory map, and there
    is really no point in proceeding with installing the virtual memory map
    and the runtime services dispatch table. So back out gracefully.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Mark Salter <msalter@redhat.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 56c3327bbf79..e72f3100958f 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -414,13 +414,24 @@ static int __init arm64_enter_virtual_mode(void)
 	for_each_efi_memory_desc(&memmap, md) {
 		if (!(md->attribute & EFI_MEMORY_RUNTIME))
 			continue;
-		if (remap_region(md, &virt_md))
-			++count;
+		if (!remap_region(md, &virt_md))
+			goto err_unmap;
+		++count;
 	}
 
 	efi.systab = (__force void *)efi_lookup_mapped_addr(efi_system_table);
-	if (efi.systab)
-		set_bit(EFI_SYSTEM_TABLES, &efi.flags);
+	if (!efi.systab) {
+		/*
+		 * If we have no virtual mapping for the System Table at this
+		 * point, the memory map doesn't cover the physical offset where
+		 * it resides. This means the System Table will be inaccessible
+		 * to Runtime Services themselves once the virtual mapping is
+		 * installed.
+		 */
+		pr_err("Failed to remap EFI System Table -- buggy firmware?\n");
+		goto err_unmap;
+	}
+	set_bit(EFI_SYSTEM_TABLES, &efi.flags);
 
 	local_irq_save(flags);
 	cpu_switch_mm(idmap_pg_dir, &init_mm);
@@ -453,5 +464,14 @@ static int __init arm64_enter_virtual_mode(void)
 	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
 
 	return 0;
+
+err_unmap:
+	/* unmap all mappings that succeeded: there are 'count' of those */
+	for (virt_md = virtmap; count--; virt_md += memmap.desc_size) {
+		md = virt_md;
+		iounmap((__force void __iomem *)md->virt_addr);
+	}
+	kfree(virtmap);
+	return -1;
 }
 early_initcall(arm64_enter_virtual_mode);

commit e15dd4949a937d8e8482f37f8fe493357417f203
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Jul 4 19:41:53 2014 +0200

    efi/arm64: Preserve FP/SIMD registers on UEFI runtime services calls
    
    According to the UEFI spec section 2.3.6.4, the use of FP/SIMD
    instructions is allowed, and should adhere to the AAPCS64 calling
    convention, which states that 'only the bottom 64 bits of each value
    stored in registers v8-v15 need to be preserved' (section 5.1.2).
    
    This applies equally to UEFI Runtime Services called by the kernel, so
    make sure the FP/SIMD register file is preserved in this case. We do this
    by enabling the wrappers for UEFI Runtime Services (CONFIG_EFI_RUNTIME_WRAPPERS)
    and inserting calls to kernel_neon_begin()and kernel_neon_end() into
    these wrappers.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 14db1f6e8d7f..56c3327bbf79 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -449,19 +449,7 @@ static int __init arm64_enter_virtual_mode(void)
 
 	/* Set up runtime services function pointers */
 	runtime = efi.systab->runtime;
-	efi.get_time = runtime->get_time;
-	efi.set_time = runtime->set_time;
-	efi.get_wakeup_time = runtime->get_wakeup_time;
-	efi.set_wakeup_time = runtime->set_wakeup_time;
-	efi.get_variable = runtime->get_variable;
-	efi.get_next_variable = runtime->get_next_variable;
-	efi.set_variable = runtime->set_variable;
-	efi.query_variable_info = runtime->query_variable_info;
-	efi.update_capsule = runtime->update_capsule;
-	efi.query_capsule_caps = runtime->query_capsule_caps;
-	efi.get_next_high_mono_count = runtime->get_next_high_mono_count;
-	efi.reset_system = runtime->reset_system;
-
+	efi_native_runtime_setup();
 	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
 
 	return 0;

commit 74bcc2499291d38b6253f9dbd6af33a195222208
Author: Leif Lindholm <leif.lindholm@linaro.org>
Date:   Fri May 23 14:16:56 2014 +0100

    arm64: efi: only attempt efi map setup if booting via EFI
    
    Booting a kernel with CONFIG_EFI enabled on a non-EFI system caused
    an oops with the current UEFI support code.
    Add the required test to prevent this.
    
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 7bfd65097210..14db1f6e8d7f 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -333,6 +333,9 @@ void __init efi_init(void)
 
 void __init efi_idmap_init(void)
 {
+	if (!efi_enabled(EFI_BOOT))
+		return;
+
 	/* boot time idmap_pg_dir is incomplete, so fill in missing parts */
 	efi_setup_idmap();
 }

commit f84d02755f5a9f3b88e8d15d6384da25ad6dcf5e
Author: Mark Salter <msalter@redhat.com>
Date:   Tue Apr 15 21:59:30 2014 -0400

    arm64: add EFI runtime services
    
    This patch adds EFI runtime support for arm64. This runtime support allows
    the kernel to access various EFI runtime services provided by EFI firmware.
    Things like reboot, real time clock, EFI boot variables, and others.
    
    This functionality is supported for little endian kernels only. The UEFI
    firmware standard specifies that the firmware be little endian. A future
    patch is expected to add support for big endian kernels running with
    little endian firmware.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    [ Remove unnecessary cache/tlb maintenance. ]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
new file mode 100644
index 000000000000..7bfd65097210
--- /dev/null
+++ b/arch/arm64/kernel/efi.c
@@ -0,0 +1,466 @@
+/*
+ * Extensible Firmware Interface
+ *
+ * Based on Extensible Firmware Interface Specification version 2.4
+ *
+ * Copyright (C) 2013, 2014 Linaro Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/efi.h>
+#include <linux/export.h>
+#include <linux/memblock.h>
+#include <linux/bootmem.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+
+#include <asm/cacheflush.h>
+#include <asm/efi.h>
+#include <asm/tlbflush.h>
+#include <asm/mmu_context.h>
+
+struct efi_memory_map memmap;
+
+static efi_runtime_services_t *runtime;
+
+static u64 efi_system_table;
+
+static int uefi_debug __initdata;
+static int __init uefi_debug_setup(char *str)
+{
+	uefi_debug = 1;
+
+	return 0;
+}
+early_param("uefi_debug", uefi_debug_setup);
+
+static int __init is_normal_ram(efi_memory_desc_t *md)
+{
+	if (md->attribute & EFI_MEMORY_WB)
+		return 1;
+	return 0;
+}
+
+static void __init efi_setup_idmap(void)
+{
+	struct memblock_region *r;
+	efi_memory_desc_t *md;
+	u64 paddr, npages, size;
+
+	for_each_memblock(memory, r)
+		create_id_mapping(r->base, r->size, 0);
+
+	/* map runtime io spaces */
+	for_each_efi_memory_desc(&memmap, md) {
+		if (!(md->attribute & EFI_MEMORY_RUNTIME) || is_normal_ram(md))
+			continue;
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+		create_id_mapping(paddr, size, 1);
+	}
+}
+
+static int __init uefi_init(void)
+{
+	efi_char16_t *c16;
+	char vendor[100] = "unknown";
+	int i, retval;
+
+	efi.systab = early_memremap(efi_system_table,
+				    sizeof(efi_system_table_t));
+	if (efi.systab == NULL) {
+		pr_warn("Unable to map EFI system table.\n");
+		return -ENOMEM;
+	}
+
+	set_bit(EFI_BOOT, &efi.flags);
+	set_bit(EFI_64BIT, &efi.flags);
+
+	/*
+	 * Verify the EFI Table
+	 */
+	if (efi.systab->hdr.signature != EFI_SYSTEM_TABLE_SIGNATURE) {
+		pr_err("System table signature incorrect\n");
+		return -EINVAL;
+	}
+	if ((efi.systab->hdr.revision >> 16) < 2)
+		pr_warn("Warning: EFI system table version %d.%02d, expected 2.00 or greater\n",
+			efi.systab->hdr.revision >> 16,
+			efi.systab->hdr.revision & 0xffff);
+
+	/* Show what we know for posterity */
+	c16 = early_memremap(efi.systab->fw_vendor,
+			     sizeof(vendor));
+	if (c16) {
+		for (i = 0; i < (int) sizeof(vendor) - 1 && *c16; ++i)
+			vendor[i] = c16[i];
+		vendor[i] = '\0';
+	}
+
+	pr_info("EFI v%u.%.02u by %s\n",
+		efi.systab->hdr.revision >> 16,
+		efi.systab->hdr.revision & 0xffff, vendor);
+
+	retval = efi_config_init(NULL);
+	if (retval == 0)
+		set_bit(EFI_CONFIG_TABLES, &efi.flags);
+
+	early_memunmap(c16, sizeof(vendor));
+	early_memunmap(efi.systab,  sizeof(efi_system_table_t));
+
+	return retval;
+}
+
+static __initdata char memory_type_name[][32] = {
+	{"Reserved"},
+	{"Loader Code"},
+	{"Loader Data"},
+	{"Boot Code"},
+	{"Boot Data"},
+	{"Runtime Code"},
+	{"Runtime Data"},
+	{"Conventional Memory"},
+	{"Unusable Memory"},
+	{"ACPI Reclaim Memory"},
+	{"ACPI Memory NVS"},
+	{"Memory Mapped I/O"},
+	{"MMIO Port Space"},
+	{"PAL Code"},
+};
+
+/*
+ * Return true for RAM regions we want to permanently reserve.
+ */
+static __init int is_reserve_region(efi_memory_desc_t *md)
+{
+	if (!is_normal_ram(md))
+		return 0;
+
+	if (md->attribute & EFI_MEMORY_RUNTIME)
+		return 1;
+
+	if (md->type == EFI_ACPI_RECLAIM_MEMORY ||
+	    md->type == EFI_RESERVED_TYPE)
+		return 1;
+
+	return 0;
+}
+
+static __init void reserve_regions(void)
+{
+	efi_memory_desc_t *md;
+	u64 paddr, npages, size;
+
+	if (uefi_debug)
+		pr_info("Processing EFI memory map:\n");
+
+	for_each_efi_memory_desc(&memmap, md) {
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+
+		if (uefi_debug)
+			pr_info("  0x%012llx-0x%012llx [%s]",
+				paddr, paddr + (npages << EFI_PAGE_SHIFT) - 1,
+				memory_type_name[md->type]);
+
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+
+		if (is_normal_ram(md))
+			early_init_dt_add_memory_arch(paddr, size);
+
+		if (is_reserve_region(md) ||
+		    md->type == EFI_BOOT_SERVICES_CODE ||
+		    md->type == EFI_BOOT_SERVICES_DATA) {
+			memblock_reserve(paddr, size);
+			if (uefi_debug)
+				pr_cont("*");
+		}
+
+		if (uefi_debug)
+			pr_cont("\n");
+	}
+}
+
+
+static u64 __init free_one_region(u64 start, u64 end)
+{
+	u64 size = end - start;
+
+	if (uefi_debug)
+		pr_info("  EFI freeing: 0x%012llx-0x%012llx\n",	start, end - 1);
+
+	free_bootmem_late(start, size);
+	return size;
+}
+
+static u64 __init free_region(u64 start, u64 end)
+{
+	u64 map_start, map_end, total = 0;
+
+	if (end <= start)
+		return total;
+
+	map_start = (u64)memmap.phys_map;
+	map_end = PAGE_ALIGN(map_start + (memmap.map_end - memmap.map));
+	map_start &= PAGE_MASK;
+
+	if (start < map_end && end > map_start) {
+		/* region overlaps UEFI memmap */
+		if (start < map_start)
+			total += free_one_region(start, map_start);
+
+		if (map_end < end)
+			total += free_one_region(map_end, end);
+	} else
+		total += free_one_region(start, end);
+
+	return total;
+}
+
+static void __init free_boot_services(void)
+{
+	u64 total_freed = 0;
+	u64 keep_end, free_start, free_end;
+	efi_memory_desc_t *md;
+
+	/*
+	 * If kernel uses larger pages than UEFI, we have to be careful
+	 * not to inadvertantly free memory we want to keep if there is
+	 * overlap at the kernel page size alignment. We do not want to
+	 * free is_reserve_region() memory nor the UEFI memmap itself.
+	 *
+	 * The memory map is sorted, so we keep track of the end of
+	 * any previous region we want to keep, remember any region
+	 * we want to free and defer freeing it until we encounter
+	 * the next region we want to keep. This way, before freeing
+	 * it, we can clip it as needed to avoid freeing memory we
+	 * want to keep for UEFI.
+	 */
+
+	keep_end = 0;
+	free_start = 0;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		u64 paddr, npages, size;
+
+		if (is_reserve_region(md)) {
+			/*
+			 * We don't want to free any memory from this region.
+			 */
+			if (free_start) {
+				/* adjust free_end then free region */
+				if (free_end > md->phys_addr)
+					free_end -= PAGE_SIZE;
+				total_freed += free_region(free_start, free_end);
+				free_start = 0;
+			}
+			keep_end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
+			continue;
+		}
+
+		if (md->type != EFI_BOOT_SERVICES_CODE &&
+		    md->type != EFI_BOOT_SERVICES_DATA) {
+			/* no need to free this region */
+			continue;
+		}
+
+		/*
+		 * We want to free memory from this region.
+		 */
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+
+		if (free_start) {
+			if (paddr <= free_end)
+				free_end = paddr + size;
+			else {
+				total_freed += free_region(free_start, free_end);
+				free_start = paddr;
+				free_end = paddr + size;
+			}
+		} else {
+			free_start = paddr;
+			free_end = paddr + size;
+		}
+		if (free_start < keep_end) {
+			free_start += PAGE_SIZE;
+			if (free_start >= free_end)
+				free_start = 0;
+		}
+	}
+	if (free_start)
+		total_freed += free_region(free_start, free_end);
+
+	if (total_freed)
+		pr_info("Freed 0x%llx bytes of EFI boot services memory",
+			total_freed);
+}
+
+void __init efi_init(void)
+{
+	struct efi_fdt_params params;
+
+	/* Grab UEFI information placed in FDT by stub */
+	if (!efi_get_fdt_params(&params, uefi_debug))
+		return;
+
+	efi_system_table = params.system_table;
+
+	memblock_reserve(params.mmap & PAGE_MASK,
+			 PAGE_ALIGN(params.mmap_size + (params.mmap & ~PAGE_MASK)));
+	memmap.phys_map = (void *)params.mmap;
+	memmap.map = early_memremap(params.mmap, params.mmap_size);
+	memmap.map_end = memmap.map + params.mmap_size;
+	memmap.desc_size = params.desc_size;
+	memmap.desc_version = params.desc_ver;
+
+	if (uefi_init() < 0)
+		return;
+
+	reserve_regions();
+}
+
+void __init efi_idmap_init(void)
+{
+	/* boot time idmap_pg_dir is incomplete, so fill in missing parts */
+	efi_setup_idmap();
+}
+
+static int __init remap_region(efi_memory_desc_t *md, void **new)
+{
+	u64 paddr, vaddr, npages, size;
+
+	paddr = md->phys_addr;
+	npages = md->num_pages;
+	memrange_efi_to_native(&paddr, &npages);
+	size = npages << PAGE_SHIFT;
+
+	if (is_normal_ram(md))
+		vaddr = (__force u64)ioremap_cache(paddr, size);
+	else
+		vaddr = (__force u64)ioremap(paddr, size);
+
+	if (!vaddr) {
+		pr_err("Unable to remap 0x%llx pages @ %p\n",
+		       npages, (void *)paddr);
+		return 0;
+	}
+
+	/* adjust for any rounding when EFI and system pagesize differs */
+	md->virt_addr = vaddr + (md->phys_addr - paddr);
+
+	if (uefi_debug)
+		pr_info("  EFI remap 0x%012llx => %p\n",
+			md->phys_addr, (void *)md->virt_addr);
+
+	memcpy(*new, md, memmap.desc_size);
+	*new += memmap.desc_size;
+
+	return 1;
+}
+
+/*
+ * Switch UEFI from an identity map to a kernel virtual map
+ */
+static int __init arm64_enter_virtual_mode(void)
+{
+	efi_memory_desc_t *md;
+	phys_addr_t virtmap_phys;
+	void *virtmap, *virt_md;
+	efi_status_t status;
+	u64 mapsize;
+	int count = 0;
+	unsigned long flags;
+
+	if (!efi_enabled(EFI_BOOT)) {
+		pr_info("EFI services will not be available.\n");
+		return -1;
+	}
+
+	pr_info("Remapping and enabling EFI services.\n");
+
+	/* replace early memmap mapping with permanent mapping */
+	mapsize = memmap.map_end - memmap.map;
+	early_memunmap(memmap.map, mapsize);
+	memmap.map = (__force void *)ioremap_cache((phys_addr_t)memmap.phys_map,
+						   mapsize);
+	memmap.map_end = memmap.map + mapsize;
+
+	efi.memmap = &memmap;
+
+	/* Map the runtime regions */
+	virtmap = kmalloc(mapsize, GFP_KERNEL);
+	if (!virtmap) {
+		pr_err("Failed to allocate EFI virtual memmap\n");
+		return -1;
+	}
+	virtmap_phys = virt_to_phys(virtmap);
+	virt_md = virtmap;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+		if (remap_region(md, &virt_md))
+			++count;
+	}
+
+	efi.systab = (__force void *)efi_lookup_mapped_addr(efi_system_table);
+	if (efi.systab)
+		set_bit(EFI_SYSTEM_TABLES, &efi.flags);
+
+	local_irq_save(flags);
+	cpu_switch_mm(idmap_pg_dir, &init_mm);
+
+	/* Call SetVirtualAddressMap with the physical address of the map */
+	runtime = efi.systab->runtime;
+	efi.set_virtual_address_map = runtime->set_virtual_address_map;
+
+	status = efi.set_virtual_address_map(count * memmap.desc_size,
+					     memmap.desc_size,
+					     memmap.desc_version,
+					     (efi_memory_desc_t *)virtmap_phys);
+	cpu_set_reserved_ttbr0();
+	flush_tlb_all();
+	local_irq_restore(flags);
+
+	kfree(virtmap);
+
+	free_boot_services();
+
+	if (status != EFI_SUCCESS) {
+		pr_err("Failed to set EFI virtual address map! [%lx]\n",
+			status);
+		return -1;
+	}
+
+	/* Set up runtime services function pointers */
+	runtime = efi.systab->runtime;
+	efi.get_time = runtime->get_time;
+	efi.set_time = runtime->set_time;
+	efi.get_wakeup_time = runtime->get_wakeup_time;
+	efi.set_wakeup_time = runtime->set_wakeup_time;
+	efi.get_variable = runtime->get_variable;
+	efi.get_next_variable = runtime->get_next_variable;
+	efi.set_variable = runtime->set_variable;
+	efi.query_variable_info = runtime->query_variable_info;
+	efi.update_capsule = runtime->update_capsule;
+	efi.query_capsule_caps = runtime->query_capsule_caps;
+	efi.get_next_high_mono_count = runtime->get_next_high_mono_count;
+	efi.reset_system = runtime->reset_system;
+
+	set_bit(EFI_RUNTIME_SERVICES, &efi.flags);
+
+	return 0;
+}
+early_initcall(arm64_enter_virtual_mode);
