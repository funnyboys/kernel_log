commit ac2081cdc4d99c57f219c1a6171526e0fa0a6fff
Author: Will Deacon <will@kernel.org>
Date:   Thu Jul 2 21:16:20 2020 +0100

    arm64: ptrace: Consistently use pseudo-singlestep exceptions
    
    Although the arm64 single-step state machine can be fast-forwarded in
    cases where we wish to generate a SIGTRAP without actually executing an
    instruction, this has two major limitations outside of simply skipping
    an instruction due to emulation.
    
    1. Stepping out of a ptrace signal stop into a signal handler where
       SIGTRAP is blocked. Fast-forwarding the stepping state machine in
       this case will result in a forced SIGTRAP, with the handler reset to
       SIG_DFL.
    
    2. The hardware implicitly fast-forwards the state machine when executing
       an SVC instruction for issuing a system call. This can interact badly
       with subsequent ptrace stops signalled during the execution of the
       system call (e.g. SYSCALL_EXIT or seccomp traps), as they may corrupt
       the stepping state by updating the PSTATE for the tracee.
    
    Resolve both of these issues by injecting a pseudo-singlestep exception
    on entry to a signal handler and also on return to userspace following a
    system call.
    
    Cc: <stable@vger.kernel.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Luis Machado <luis.machado@linaro.org>
    Reported-by: Keno Fischer <keno@juliacomputing.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 801d56cdf701..3b4f31f35e45 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -800,7 +800,6 @@ static void setup_restart_syscall(struct pt_regs *regs)
  */
 static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 {
-	struct task_struct *tsk = current;
 	sigset_t *oldset = sigmask_to_save();
 	int usig = ksig->sig;
 	int ret;
@@ -824,14 +823,8 @@ static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	 */
 	ret |= !valid_user_regs(&regs->user_regs, current);
 
-	/*
-	 * Fast forward the stepping logic so we step into the signal
-	 * handler.
-	 */
-	if (!ret)
-		user_fastforward_single_step(tsk);
-
-	signal_setup_done(ret, ksig, 0);
+	/* Step into the signal handler if we are stepping */
+	signal_setup_done(ret, ksig, test_thread_flag(TIF_SINGLESTEP));
 }
 
 /*

commit 8ef8f360cf30be12382f89ff48a57fbbd9b31c14
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Mon Mar 16 16:50:45 2020 +0000

    arm64: Basic Branch Target Identification support
    
    This patch adds the bare minimum required to expose the ARMv8.5
    Branch Target Identification feature to userspace.
    
    By itself, this does _not_ automatically enable BTI for any initial
    executable pages mapped by execve().  This will come later, but for
    now it should be possible to enable BTI manually on those pages by
    using mprotect() from within the target process.
    
    Other arches already using the generic mman.h are already using
    0x10 for arch-specific prot flags, so we use that for PROT_BTI
    here.
    
    For consistency, signal handler entry points in BTI guarded pages
    are required to be annotated as such, just like any other function.
    This blocks a relatively minor attack vector, but comforming
    userspace will have the annotations anyway, so we may as well
    enforce them.
    
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 339882db5a91..801d56cdf701 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -732,6 +732,22 @@ static void setup_return(struct pt_regs *regs, struct k_sigaction *ka,
 	regs->regs[29] = (unsigned long)&user->next_frame->fp;
 	regs->pc = (unsigned long)ka->sa.sa_handler;
 
+	/*
+	 * Signal delivery is a (wacky) indirect function call in
+	 * userspace, so simulate the same setting of BTYPE as a BLR
+	 * <register containing the signal handler entry point>.
+	 * Signal delivery to a location in a PROT_BTI guarded page
+	 * that is not a function entry point will now trigger a
+	 * SIGILL in userspace.
+	 *
+	 * If the signal handler entry point is not in a PROT_BTI
+	 * guarded page, this is harmless.
+	 */
+	if (system_supports_bti()) {
+		regs->pstate &= ~PSR_BTYPE_MASK;
+		regs->pstate |= PSR_BTYPE_C;
+	}
+
 	if (ka->sa.sa_flags & SA_RESTORER)
 		sigtramp = ka->sa.sa_restorer;
 	else

commit 6d502b6ba1b267b35a70708aa0f61bbd05cf065b
Author: Suzuki K Poulose <suzuki.poulose@arm.com>
Date:   Mon Jan 13 23:30:22 2020 +0000

    arm64: signal: nofpsimd: Handle fp/simd context for signal frames
    
    Make sure we try to save/restore the vfp/fpsimd context for signal
    handling only when the fp/simd support is available. Otherwise, skip
    the frames.
    
    Cc: Will Deacon <will@kernel.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Ard Biesheuvel <ardb@kernel.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index dd2cdc0d5be2..339882db5a91 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -371,6 +371,8 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			goto done;
 
 		case FPSIMD_MAGIC:
+			if (!system_supports_fpsimd())
+				goto invalid;
 			if (user->fpsimd)
 				goto invalid;
 
@@ -506,7 +508,7 @@ static int restore_sigframe(struct pt_regs *regs,
 	if (err == 0)
 		err = parse_user_sigframe(&user, sf);
 
-	if (err == 0) {
+	if (err == 0 && system_supports_fpsimd()) {
 		if (!user.fpsimd)
 			return -EINVAL;
 
@@ -623,7 +625,7 @@ static int setup_sigframe(struct rt_sigframe_user_layout *user,
 
 	err |= __copy_to_user(&sf->uc.uc_sigmask, set, sizeof(*set));
 
-	if (err == 0) {
+	if (err == 0 && system_supports_fpsimd()) {
 		struct fpsimd_context __user *fpsimd_ctx =
 			apply_user_offset(user, user->fpsimd_offset);
 		err |= preserve_fpsimd_context(fpsimd_ctx);

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index a9b0485df074..dd2cdc0d5be2 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -1,20 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Based on arch/arm/kernel/signal.c
  *
  * Copyright (C) 1995-2009 Russell King
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #include <linux/cache.h>

commit efbc20249fee68c5740ac49704f437ecee7eda6f
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Fri Sep 28 14:39:05 2018 +0100

    arm64: fpsimd: Always set TIF_FOREIGN_FPSTATE on task state flush
    
    This patch updates fpsimd_flush_task_state() to mirror the new
    semantics of fpsimd_flush_cpu_state() introduced by commit
    d8ad71fa38a9 ("arm64: fpsimd: Fix TIF_FOREIGN_FPSTATE after
    invalidating cpu regs").  Both functions now implicitly set
    TIF_FOREIGN_FPSTATE to indicate that the task's FPSIMD state is not
    loaded into the cpu.
    
    As a side-effect, fpsimd_flush_task_state() now sets
    TIF_FOREIGN_FPSTATE even for non-running tasks.  In the case of
    non-running tasks this is not useful but also harmless, because the
    flag is live only while the corresponding task is running.  This
    function is not called from fast paths, so special-casing this for
    the task == current case is not really worth it.
    
    Compiler barriers previously present in restore_sve_fpsimd_context()
    are pulled into fpsimd_flush_task_state() so that it can be safely
    called with preemption enabled if necessary.
    
    Explicit calls to set TIF_FOREIGN_FPSTATE that accompany
    fpsimd_flush_task_state() calls and are now redundant are removed
    as appropriate.
    
    fpsimd_flush_task_state() is used to get exclusive access to the
    representation of the task's state via task_struct, for the purpose
    of replacing the state.  Thus, the call to this function should
    happen before manipulating fpsimd_state or sve_state etc. in
    task_struct.  Anomalous cases are reordered appropriately in order
    to make the code more consistent, although there should be no
    functional difference since these cases are protected by
    local_bh_disable() anyway.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Alex Bennée <alex.bennee@linaro.org>
    Reviewed-by: Julien Grall <julien.grall@arm.com>
    Tested-by: zhang.lei <zhang.lei@jp.fujitsu.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 867a7cea70e5..a9b0485df074 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -296,11 +296,6 @@ static int restore_sve_fpsimd_context(struct user_ctxs *user)
 	 */
 
 	fpsimd_flush_task_state(current);
-	barrier();
-	/* From now, fpsimd_thread_switch() won't clear TIF_FOREIGN_FPSTATE */
-
-	set_thread_flag(TIF_FOREIGN_FPSTATE);
-	barrier();
 	/* From now, fpsimd_thread_switch() won't touch thread.sve_state */
 
 	sve_alloc(current);

commit 96d4f267e40f9509e8a66e2b39e8b95655617693
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 3 18:57:57 2019 -0800

    Remove 'type' argument from access_ok() function
    
    Nobody has actually used the type (VERIFY_READ vs VERIFY_WRITE) argument
    of the user address range verification function since we got rid of the
    old racy i386-only code to walk page tables by hand.
    
    It existed because the original 80386 would not honor the write protect
    bit when in kernel mode, so you had to do COW by hand before doing any
    user access.  But we haven't supported that in a long time, and these
    days the 'type' argument is a purely historical artifact.
    
    A discussion about extending 'user_access_begin()' to do the range
    checking resulted this patch, because there is no way we're going to
    move the old VERIFY_xyz interface to that model.  And it's best done at
    the end of the merge window when I've done most of my merges, so let's
    just get this done once and for all.
    
    This patch was mostly done with a sed-script, with manual fix-ups for
    the cases that weren't of the trivial 'access_ok(VERIFY_xyz' form.
    
    There were a couple of notable cases:
    
     - csky still had the old "verify_area()" name as an alias.
    
     - the iter_iov code had magical hardcoded knowledge of the actual
       values of VERIFY_{READ,WRITE} (not that they mattered, since nothing
       really used it)
    
     - microblaze used the type argument for a debug printout
    
    but other than those oddities this should be a total no-op patch.
    
    I tried to fix up all architectures, did fairly extensive grepping for
    access_ok() uses, and the changes are trivial, but I may have missed
    something.  Any missed conversion should be trivially fixable, though.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 5dcc942906db..867a7cea70e5 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -470,7 +470,7 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			offset = 0;
 			limit = extra_size;
 
-			if (!access_ok(VERIFY_READ, base, limit))
+			if (!access_ok(base, limit))
 				goto invalid;
 
 			continue;
@@ -556,7 +556,7 @@ SYSCALL_DEFINE0(rt_sigreturn)
 
 	frame = (struct rt_sigframe __user *)regs->sp;
 
-	if (!access_ok(VERIFY_READ, frame, sizeof (*frame)))
+	if (!access_ok(frame, sizeof (*frame)))
 		goto badframe;
 
 	if (restore_sigframe(regs, frame))
@@ -730,7 +730,7 @@ static int get_sigframe(struct rt_sigframe_user_layout *user,
 	/*
 	 * Check that we can actually write to the signal frame.
 	 */
-	if (!access_ok(VERIFY_WRITE, user->sigframe, sp_top - sp))
+	if (!access_ok(user->sigframe, sp_top - sp))
 		return -EFAULT;
 
 	return 0;

commit bf4ce5cc23c9f8357bfd9c0328bf59685664cbc7
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jul 11 14:56:53 2018 +0100

    arm64: use {COMPAT,}SYSCALL_DEFINE0 for sigreturn
    
    We don't currently annotate our various sigreturn functions as syscalls,
    as we need to do to use pt_regs syscall wrappers.
    
    Let's mark them as real syscalls.
    
    For compat_sys_sigreturn and compat_sys_rt_sigreturn, this changes the
    return type from int to long, matching the prototypes in sys32.c.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index b6f3c3d76901..5dcc942906db 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -539,7 +539,7 @@ static int restore_sigframe(struct pt_regs *regs,
 	return err;
 }
 
-asmlinkage long sys_rt_sigreturn(void)
+SYSCALL_DEFINE0(rt_sigreturn)
 {
 	struct pt_regs *regs = current_pt_regs();
 	struct rt_sigframe __user *frame;

commit 3085e1645e23888125224f66a710077cdb03106a
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jul 11 14:56:41 2018 +0100

    arm64: remove sigreturn wrappers
    
    The arm64 sigreturn* syscall handlers are non-standard. Rather than
    taking a number of user parameters in registers as per the AAPCS,
    they expect the pt_regs as their sole argument.
    
    To make this work, we override the syscall definitions to invoke
    wrappers written in assembly, which mov the SP into x0, and branch to
    their respective C functions.
    
    On other architectures (such as x86), the sigreturn* functions take no
    argument and instead use current_pt_regs() to acquire the user
    registers. This requires less boilerplate code, and allows for other
    features such as interposing C code in this path.
    
    This patch takes the same approach for arm64.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Tentatively-reviewed-by: Dave Martin <dave.martin@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 5a8df96dc4ab..b6f3c3d76901 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -539,8 +539,9 @@ static int restore_sigframe(struct pt_regs *regs,
 	return err;
 }
 
-asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
+asmlinkage long sys_rt_sigreturn(void)
 {
+	struct pt_regs *regs = current_pt_regs();
 	struct rt_sigframe __user *frame;
 
 	/* Always make any pending restarted system calls return -EINTR */

commit 3eb6f1f9e6364d5eca1ddf3c9e963c5916069190
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jul 11 14:56:36 2018 +0100

    arm64: consistently use unsigned long for thread flags
    
    In do_notify_resume, we manipulate thread_flags as a 32-bit unsigned
    int, whereas thread_info::flags is a 64-bit unsigned long, and elsewhere
    (e.g. in the entry assembly) we manipulate the flags as a 64-bit
    quantity.
    
    For consistency, and to avoid problems if we end up with more than 32
    flags, let's make do_notify_resume take the flags as a 64-bit unsigned
    long.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Dave Martin <dave.martin@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index e3b1d1b0aee8..5a8df96dc4ab 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -912,7 +912,7 @@ static void do_signal(struct pt_regs *regs)
 }
 
 asmlinkage void do_notify_resume(struct pt_regs *regs,
-				 unsigned int thread_flags)
+				 unsigned long thread_flags)
 {
 	/*
 	 * The assembly code enters us with IRQs off, but it hasn't

commit 409d5db49867c20d226a1fc50a73d646bd733dae
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Jun 20 14:46:50 2018 +0100

    arm64: rseq: Implement backend rseq calls and select HAVE_RSEQ
    
    Implement calls to rseq_signal_deliver, rseq_handle_notify_resume
    and rseq_syscall so that we can select HAVE_RSEQ on arm64.
    
    Acked-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 511af13e8d8f..e3b1d1b0aee8 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -802,6 +802,8 @@ static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	int usig = ksig->sig;
 	int ret;
 
+	rseq_signal_deliver(ksig, regs);
+
 	/*
 	 * Set up the stack frame
 	 */
@@ -940,6 +942,7 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 			if (thread_flags & _TIF_NOTIFY_RESUME) {
 				clear_thread_flag(TIF_NOTIFY_RESUME);
 				tracehook_notify_resume(regs);
+				rseq_handle_notify_resume(NULL, regs);
 			}
 
 			if (thread_flags & _TIF_FOREIGN_FPSTATE)

commit 0fe42512b2f03f9e5a20b9f55ef1013a68b4cd48
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Jun 7 12:32:05 2018 +0100

    arm64: Fix syscall restarting around signal suppressed by tracer
    
    Commit 17c2895 ("arm64: Abstract syscallno manipulation") abstracts
    out the pt_regs.syscallno value for a syscall cancelled by a tracer
    as NO_SYSCALL, and provides helpers to set and check for this
    condition.  However, the way this was implemented has the
    unintended side-effect of disabling part of the syscall restart
    logic.
    
    This comes about because the second in_syscall() check in
    do_signal() re-evaluates the "in a syscall" condition based on the
    updated pt_regs instead of the original pt_regs.  forget_syscall()
    is explicitly called prior to the second check in order to prevent
    restart logic in the ret_to_user path being spuriously triggered,
    which means that the second in_syscall() check always yields false.
    
    This triggers a failure in
    tools/testing/selftests/seccomp/seccomp_bpf.c, when using ptrace to
    suppress a signal that interrups a nanosleep() syscall.
    
    Misbehaviour of this type is only expected in the case where a
    tracer suppresses a signal and the target process is either being
    single-stepped or the interrupted syscall attempts to restart via
    -ERESTARTBLOCK.
    
    This patch restores the old behaviour by performing the
    in_syscall() check only once at the start of the function.
    
    Fixes: 17c289586009 ("arm64: Abstract syscallno manipulation")
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Reported-by: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org> # 4.14.x-
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index e7da5dba7ba8..511af13e8d8f 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -843,11 +843,12 @@ static void do_signal(struct pt_regs *regs)
 	unsigned long continue_addr = 0, restart_addr = 0;
 	int retval = 0;
 	struct ksignal ksig;
+	bool syscall = in_syscall(regs);
 
 	/*
 	 * If we were from a system call, check for system call restarting...
 	 */
-	if (in_syscall(regs)) {
+	if (syscall) {
 		continue_addr = regs->pc;
 		restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
 		retval = regs->regs[0];
@@ -899,7 +900,7 @@ static void do_signal(struct pt_regs *regs)
 	 * Handle restarting a different system call. As above, if a debugger
 	 * has chosen to restart at a different PC, ignore the restart.
 	 */
-	if (in_syscall(regs) && regs->pc == restart_addr) {
+	if (syscall && regs->pc == restart_addr) {
 		if (retval == -ERESTART_RESTARTBLOCK)
 			setup_restart_syscall(regs);
 		user_rewind_single_step(current);

commit 94b07c1f8c39c6d839df35fa28ffd1785d385897
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Fri Jun 1 11:10:14 2018 +0100

    arm64: signal: Report signal frame size to userspace via auxv
    
    Stateful CPU architecture extensions may require the signal frame
    to grow to a size that exceeds the arch's MINSIGSTKSZ #define.
    However, changing this #define is an ABI break.
    
    To allow userspace the option of determining the signal frame size
    in a more forwards-compatible way, this patch adds a new auxv entry
    tagged with AT_MINSIGSTKSZ, which provides the maximum signal frame
    size that the process can observe during its lifetime.
    
    If AT_MINSIGSTKSZ is absent from the aux vector, the caller can
    assume that the MINSIGSTKSZ #define is sufficient.  This allows for
    a consistent interface with older kernels that do not provide
    AT_MINSIGSTKSZ.
    
    The idea is that libc could expose this via sysconf() or some
    similar mechanism.
    
    There is deliberately no AT_SIGSTKSZ.  The kernel knows nothing
    about userspace's own stack overheads and should not pretend to
    know.
    
    For arm64:
    
    The primary motivation for this interface is the Scalable Vector
    Extension, which can require at least 4KB or so of extra space
    in the signal frame for the largest hardware implementations.
    
    To determine the correct value, a "Christmas tree" mode (via the
    add_all argument) is added to setup_sigframe_layout(), to simulate
    addition of all possible records to the signal frame at maximum
    possible size.
    
    If this procedure goes wrong somehow, resulting in a stupidly large
    frame layout and hence failure of sigframe_alloc() to allocate a
    record to the frame, then this is indicative of a kernel bug.  In
    this case, we WARN() and no attempt is made to populate
    AT_MINSIGSTKSZ for userspace.
    
    For arm64 SVE:
    
    The SVE context block in the signal frame needs to be considered
    too when computing the maximum possible signal frame size.
    
    Because the size of this block depends on the vector length, this
    patch computes the size based not on the thread's current vector
    length but instead on the maximum possible vector length: this
    determines the maximum size of SVE context block that can be
    observed in any signal frame for the lifetime of the process.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Alex Bennée <alex.bennee@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 154b7d30145d..e7da5dba7ba8 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -17,6 +17,7 @@
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+#include <linux/cache.h>
 #include <linux/compat.h>
 #include <linux/errno.h>
 #include <linux/kernel.h>
@@ -570,8 +571,15 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	return 0;
 }
 
-/* Determine the layout of optional records in the signal frame */
-static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
+/*
+ * Determine the layout of optional records in the signal frame
+ *
+ * add_all: if true, lays out the biggest possible signal frame for
+ *	this task; otherwise, generates a layout for the current state
+ *	of the task.
+ */
+static int setup_sigframe_layout(struct rt_sigframe_user_layout *user,
+				 bool add_all)
 {
 	int err;
 
@@ -581,7 +589,7 @@ static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 		return err;
 
 	/* fault information, if valid */
-	if (current->thread.fault_code) {
+	if (add_all || current->thread.fault_code) {
 		err = sigframe_alloc(user, &user->esr_offset,
 				     sizeof(struct esr_context));
 		if (err)
@@ -591,8 +599,14 @@ static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 	if (system_supports_sve()) {
 		unsigned int vq = 0;
 
-		if (test_thread_flag(TIF_SVE))
-			vq = sve_vq_from_vl(current->thread.sve_vl);
+		if (add_all || test_thread_flag(TIF_SVE)) {
+			int vl = sve_max_vl;
+
+			if (!add_all)
+				vl = current->thread.sve_vl;
+
+			vq = sve_vq_from_vl(vl);
+		}
 
 		err = sigframe_alloc(user, &user->sve_offset,
 				     SVE_SIG_CONTEXT_SIZE(vq));
@@ -603,7 +617,6 @@ static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 	return sigframe_alloc_end(user);
 }
 
-
 static int setup_sigframe(struct rt_sigframe_user_layout *user,
 			  struct pt_regs *regs, sigset_t *set)
 {
@@ -701,7 +714,7 @@ static int get_sigframe(struct rt_sigframe_user_layout *user,
 	int err;
 
 	init_user_layout(user);
-	err = setup_sigframe_layout(user);
+	err = setup_sigframe_layout(user, false);
 	if (err)
 		return err;
 
@@ -936,3 +949,28 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 		thread_flags = READ_ONCE(current_thread_info()->flags);
 	} while (thread_flags & _TIF_WORK_MASK);
 }
+
+unsigned long __ro_after_init signal_minsigstksz;
+
+/*
+ * Determine the stack space required for guaranteed signal devliery.
+ * This function is used to populate AT_MINSIGSTKSZ at process startup.
+ * cpufeatures setup is assumed to be complete.
+ */
+void __init minsigstksz_setup(void)
+{
+	struct rt_sigframe_user_layout user;
+
+	init_user_layout(&user);
+
+	/*
+	 * If this fails, SIGFRAME_MAXSZ needs to be enlarged.  It won't
+	 * be big enough, but it's our best guess:
+	 */
+	if (WARN_ON(setup_sigframe_layout(&user, true)))
+		return;
+
+	signal_minsigstksz = sigframe_size(&user) +
+		round_up(sizeof(struct frame_record), 16) +
+		16; /* max alignment padding */
+}

commit 65896545b69ffaac947c12e11d3dcc57fd1fb772
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Wed Mar 28 10:50:49 2018 +0100

    arm64: uaccess: Fix omissions from usercopy whitelist
    
    When the hardend usercopy support was added for arm64, it was
    concluded that all cases of usercopy into and out of thread_struct
    were statically sized and so didn't require explicit whitelisting
    of the appropriate fields in thread_struct.
    
    Testing with usercopy hardening enabled has revealed that this is
    not the case for certain ptrace regset manipulation calls on arm64.
    This occurs because the sizes of usercopies associated with the
    regset API are dynamic by construction, and because arm64 does not
    always stage such copies via the stack: indeed the regset API is
    designed to avoid the need for that by adding some bounds checking.
    
    This is currently believed to affect only the fpsimd and TLS
    registers.
    
    Because the whitelisted fields in thread_struct must be contiguous,
    this patch groups them together in a nested struct.  It is also
    necessary to be able to determine the location and size of that
    struct, so rather than making the struct anonymous (which would
    save on edits elsewhere) or adding an anonymous union containing
    named and unnamed instances of the same struct (gross), this patch
    gives the struct a name and makes the necessary edits to code that
    references it (noisy but simple).
    
    Care is needed to ensure that the new struct does not contain
    padding (which the usercopy hardening would fail to protect).
    
    For this reason, the presence of tp2_value is made unconditional,
    since a padding field would be needed there in any case.  This pads
    up to the 16-byte alignment required by struct user_fpsimd_state.
    
    Acked-by: Kees Cook <keescook@chromium.org>
    Reported-by: Mark Rutland <mark.rutland@arm.com>
    Fixes: 9e8084d3f761 ("arm64: Implement thread_struct whitelist for hardened usercopy")
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index bfeee9a51cee..154b7d30145d 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -179,7 +179,8 @@ static void __user *apply_user_offset(
 
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 {
-	struct user_fpsimd_state const *fpsimd = &current->thread.fpsimd_state;
+	struct user_fpsimd_state const *fpsimd =
+		&current->thread.uw.fpsimd_state;
 	int err;
 
 	/* copy the FP and status/control registers */

commit 20b8547277a6e8ee1d928792c1b2782c9a2a6cf5
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Wed Mar 28 10:50:48 2018 +0100

    arm64: fpsimd: Split cpu field out from struct fpsimd_state
    
    In preparation for using a common representation of the FPSIMD
    state for tasks and KVM vcpus, this patch separates out the "cpu"
    field that is used to track the cpu on which the state was most
    recently loaded.
    
    This will allow common code to operate on task and vcpu contexts
    without requiring the cpu field to be stored at the same offset
    from the FPSIMD register data in both cases.  This should avoid the
    need for messing with the definition of those parts of struct
    vcpu_arch that are exposed in the KVM user ABI.
    
    The resulting change is also convenient for grouping and defining
    the set of thread_struct fields that are supposed to be accessible
    to copy_{to,from}_user(), which includes user_fpsimd_state but
    should exclude the cpu field.  This patch does not amend the
    usercopy whitelist to match: that will be addressed in a subsequent
    patch.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    [will: inline fpsimd_flush_state for now]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index e5c656d0e316..bfeee9a51cee 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -179,8 +179,7 @@ static void __user *apply_user_offset(
 
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 {
-	struct user_fpsimd_state const *fpsimd =
-		&current->thread.fpsimd_state.user_fpsimd;
+	struct user_fpsimd_state const *fpsimd = &current->thread.fpsimd_state;
 	int err;
 
 	/* copy the FP and status/control registers */

commit f71016a8a8c5696530ec7173ee969c68e91d3719
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 20 15:05:17 2018 +0000

    arm64: signal: Call arm64_notify_segfault when failing to deliver signal
    
    If we fail to deliver a signal due to taking an unhandled fault on the
    stackframe, we can call arm64_notify_segfault to deliver a SEGV can deal
    with printing any unhandled signal messages for us, rather than roll our
    own printing code.
    
    A side-effect of this change is that we now deliver the frame address
    in si_addr along with an si_code of SEGV_{ACC,MAP}ERR, rather than an
    si_addr of 0 and an si_code of SI_KERNEL as before.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index f60c052e8d1c..e5c656d0e316 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -40,6 +40,7 @@
 #include <asm/fpsimd.h>
 #include <asm/ptrace.h>
 #include <asm/signal32.h>
+#include <asm/traps.h>
 #include <asm/vdso.h>
 
 /*
@@ -565,11 +566,7 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	return regs->regs[0];
 
 badframe:
-	if (show_unhandled_signals)
-		pr_info_ratelimited("%s[%d]: bad frame in %s: pc=%08llx sp=%08llx\n",
-				    current->comm, task_pid_nr(current), __func__,
-				    regs->pc, regs->sp);
-	force_sig(SIGSEGV, current);
+	arm64_notify_segfault(regs->sp);
 	return 0;
 }
 

commit 0abdeff598a66e2bf9bfcb016eb159b11fc2887a
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Fri Dec 15 18:34:38 2017 +0000

    arm64: fpsimd: Fix state leakage when migrating after sigreturn
    
    When refactoring the sigreturn code to handle SVE, I changed the
    sigreturn implementation to store the new FPSIMD state from the
    user sigframe into task_struct before reloading the state into the
    CPU regs.  This makes it easier to convert the data for SVE when
    needed.
    
    However, it turns out that the fpsimd_state structure passed into
    fpsimd_update_current_state is not fully initialised, so assigning
    the structure as a whole corrupts current->thread.fpsimd_state.cpu
    with uninitialised data.
    
    This means that if the garbage data written to .cpu happens to be a
    valid cpu number, and the task is subsequently migrated to the cpu
    identified by the that number, and then tries to enter userspace,
    the CPU FPSIMD regs will be assumed to be correct for the task and
    not reloaded as they should be.  This can result in returning to
    userspace with the FPSIMD registers containing data that is stale or
    that belongs to another task or to the kernel.
    
    Knowingly handing around a kernel structure that is incompletely
    initialised with user data is a potential source of mistakes,
    especially across source file boundaries.  To help avoid a repeat
    of this issue, this patch adapts the relevant internal API to hand
    around the user-accessible subset only: struct user_fpsimd_state.
    
    To avoid future surprises, this patch also converts all uses of
    struct fpsimd_state that really only access the user subset, to use
    struct user_fpsimd_state.  A few missing consts are added to
    function prototypes for good measure.
    
    Thanks to Will for spotting the cause of the bug here.
    
    Reported-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index b120111a46be..f60c052e8d1c 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -178,7 +178,8 @@ static void __user *apply_user_offset(
 
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 {
-	struct fpsimd_state *fpsimd = &current->thread.fpsimd_state;
+	struct user_fpsimd_state const *fpsimd =
+		&current->thread.fpsimd_state.user_fpsimd;
 	int err;
 
 	/* copy the FP and status/control registers */
@@ -195,7 +196,7 @@ static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 
 static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
 {
-	struct fpsimd_state fpsimd;
+	struct user_fpsimd_state fpsimd;
 	__u32 magic, size;
 	int err = 0;
 
@@ -266,7 +267,7 @@ static int restore_sve_fpsimd_context(struct user_ctxs *user)
 {
 	int err;
 	unsigned int vq;
-	struct fpsimd_state fpsimd;
+	struct user_fpsimd_state fpsimd;
 	struct sve_context sve;
 
 	if (__copy_from_user(&sve, user->sve, sizeof(sve)))

commit 8cd969d28fd2848dbfd86f6954dbd71f394f55f3
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Oct 31 15:51:07 2017 +0000

    arm64/sve: Signal handling support
    
    This patch implements support for saving and restoring the SVE
    registers around signals.
    
    A fixed-size header struct sve_context is always included in the
    signal frame encoding the thread's vector length at the time of
    signal delivery, optionally followed by a variable-layout structure
    encoding the SVE registers.
    
    Because of the need to preserve backwards compatibility, the FPSIMD
    view of the SVE registers is always dumped as a struct
    fpsimd_context in the usual way, in addition to any sve_context.
    
    The SVE vector registers are dumped in full, including bits 127:0
    of each register which alias the corresponding FPSIMD vector
    registers in the hardware.  To avoid any ambiguity about which
    alias to restore during sigreturn, the kernel always restores bits
    127:0 of each SVE vector register from the fpsimd_context in the
    signal frame (which must be present): userspace needs to take this
    into account if it wants to modify the SVE vector register contents
    on return from a signal.
    
    FPSR and FPCR, which are used by both FPSIMD and SVE, are not
    included in sve_context because they are always present in
    fpsimd_context anyway.
    
    For signal delivery, a new helper
    fpsimd_signal_preserve_current_state() is added to update _both_
    the FPSIMD and SVE views in the task struct, to make it easier to
    populate this information into the signal frame.  Because of the
    redundancy between the two views of the state, only one is updated
    otherwise.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Cc: Alex Bennée <alex.bennee@linaro.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index a032906cf4f7..b120111a46be 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -64,6 +64,7 @@ struct rt_sigframe_user_layout {
 
 	unsigned long fpsimd_offset;
 	unsigned long esr_offset;
+	unsigned long sve_offset;
 	unsigned long extra_offset;
 	unsigned long end_offset;
 };
@@ -180,9 +181,6 @@ static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 	struct fpsimd_state *fpsimd = &current->thread.fpsimd_state;
 	int err;
 
-	/* dump the hardware registers to the fpsimd_state structure */
-	fpsimd_preserve_current_state();
-
 	/* copy the FP and status/control registers */
 	err = __copy_to_user(ctx->vregs, fpsimd->vregs, sizeof(fpsimd->vregs));
 	__put_user_error(fpsimd->fpsr, &ctx->fpsr, err);
@@ -215,6 +213,8 @@ static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
 	__get_user_error(fpsimd.fpsr, &ctx->fpsr, err);
 	__get_user_error(fpsimd.fpcr, &ctx->fpcr, err);
 
+	clear_thread_flag(TIF_SVE);
+
 	/* load the hardware registers from the fpsimd_state structure */
 	if (!err)
 		fpsimd_update_current_state(&fpsimd);
@@ -222,10 +222,118 @@ static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
 	return err ? -EFAULT : 0;
 }
 
+
 struct user_ctxs {
 	struct fpsimd_context __user *fpsimd;
+	struct sve_context __user *sve;
 };
 
+#ifdef CONFIG_ARM64_SVE
+
+static int preserve_sve_context(struct sve_context __user *ctx)
+{
+	int err = 0;
+	u16 reserved[ARRAY_SIZE(ctx->__reserved)];
+	unsigned int vl = current->thread.sve_vl;
+	unsigned int vq = 0;
+
+	if (test_thread_flag(TIF_SVE))
+		vq = sve_vq_from_vl(vl);
+
+	memset(reserved, 0, sizeof(reserved));
+
+	__put_user_error(SVE_MAGIC, &ctx->head.magic, err);
+	__put_user_error(round_up(SVE_SIG_CONTEXT_SIZE(vq), 16),
+			 &ctx->head.size, err);
+	__put_user_error(vl, &ctx->vl, err);
+	BUILD_BUG_ON(sizeof(ctx->__reserved) != sizeof(reserved));
+	err |= __copy_to_user(&ctx->__reserved, reserved, sizeof(reserved));
+
+	if (vq) {
+		/*
+		 * This assumes that the SVE state has already been saved to
+		 * the task struct by calling preserve_fpsimd_context().
+		 */
+		err |= __copy_to_user((char __user *)ctx + SVE_SIG_REGS_OFFSET,
+				      current->thread.sve_state,
+				      SVE_SIG_REGS_SIZE(vq));
+	}
+
+	return err ? -EFAULT : 0;
+}
+
+static int restore_sve_fpsimd_context(struct user_ctxs *user)
+{
+	int err;
+	unsigned int vq;
+	struct fpsimd_state fpsimd;
+	struct sve_context sve;
+
+	if (__copy_from_user(&sve, user->sve, sizeof(sve)))
+		return -EFAULT;
+
+	if (sve.vl != current->thread.sve_vl)
+		return -EINVAL;
+
+	if (sve.head.size <= sizeof(*user->sve)) {
+		clear_thread_flag(TIF_SVE);
+		goto fpsimd_only;
+	}
+
+	vq = sve_vq_from_vl(sve.vl);
+
+	if (sve.head.size < SVE_SIG_CONTEXT_SIZE(vq))
+		return -EINVAL;
+
+	/*
+	 * Careful: we are about __copy_from_user() directly into
+	 * thread.sve_state with preemption enabled, so protection is
+	 * needed to prevent a racing context switch from writing stale
+	 * registers back over the new data.
+	 */
+
+	fpsimd_flush_task_state(current);
+	barrier();
+	/* From now, fpsimd_thread_switch() won't clear TIF_FOREIGN_FPSTATE */
+
+	set_thread_flag(TIF_FOREIGN_FPSTATE);
+	barrier();
+	/* From now, fpsimd_thread_switch() won't touch thread.sve_state */
+
+	sve_alloc(current);
+	err = __copy_from_user(current->thread.sve_state,
+			       (char __user const *)user->sve +
+					SVE_SIG_REGS_OFFSET,
+			       SVE_SIG_REGS_SIZE(vq));
+	if (err)
+		return -EFAULT;
+
+	set_thread_flag(TIF_SVE);
+
+fpsimd_only:
+	/* copy the FP and status/control registers */
+	/* restore_sigframe() already checked that user->fpsimd != NULL. */
+	err = __copy_from_user(fpsimd.vregs, user->fpsimd->vregs,
+			       sizeof(fpsimd.vregs));
+	__get_user_error(fpsimd.fpsr, &user->fpsimd->fpsr, err);
+	__get_user_error(fpsimd.fpcr, &user->fpsimd->fpcr, err);
+
+	/* load the hardware registers from the fpsimd_state structure */
+	if (!err)
+		fpsimd_update_current_state(&fpsimd);
+
+	return err ? -EFAULT : 0;
+}
+
+#else /* ! CONFIG_ARM64_SVE */
+
+/* Turn any non-optimised out attempts to use these into a link error: */
+extern int preserve_sve_context(void __user *ctx);
+extern int restore_sve_fpsimd_context(struct user_ctxs *user);
+
+#endif /* ! CONFIG_ARM64_SVE */
+
+
 static int parse_user_sigframe(struct user_ctxs *user,
 			       struct rt_sigframe __user *sf)
 {
@@ -238,6 +346,7 @@ static int parse_user_sigframe(struct user_ctxs *user,
 	char const __user *const sfp = (char const __user *)sf;
 
 	user->fpsimd = NULL;
+	user->sve = NULL;
 
 	if (!IS_ALIGNED((unsigned long)base, 16))
 		goto invalid;
@@ -288,6 +397,19 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			/* ignore */
 			break;
 
+		case SVE_MAGIC:
+			if (!system_supports_sve())
+				goto invalid;
+
+			if (user->sve)
+				goto invalid;
+
+			if (size < sizeof(*user->sve))
+				goto invalid;
+
+			user->sve = (struct sve_context __user *)head;
+			break;
+
 		case EXTRA_MAGIC:
 			if (have_extra_context)
 				goto invalid;
@@ -364,9 +486,6 @@ static int parse_user_sigframe(struct user_ctxs *user,
 	}
 
 done:
-	if (!user->fpsimd)
-		goto invalid;
-
 	return 0;
 
 invalid:
@@ -400,8 +519,19 @@ static int restore_sigframe(struct pt_regs *regs,
 	if (err == 0)
 		err = parse_user_sigframe(&user, sf);
 
-	if (err == 0)
-		err = restore_fpsimd_context(user.fpsimd);
+	if (err == 0) {
+		if (!user.fpsimd)
+			return -EINVAL;
+
+		if (user.sve) {
+			if (!system_supports_sve())
+				return -EINVAL;
+
+			err = restore_sve_fpsimd_context(&user);
+		} else {
+			err = restore_fpsimd_context(user.fpsimd);
+		}
+	}
 
 	return err;
 }
@@ -460,6 +590,18 @@ static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 			return err;
 	}
 
+	if (system_supports_sve()) {
+		unsigned int vq = 0;
+
+		if (test_thread_flag(TIF_SVE))
+			vq = sve_vq_from_vl(current->thread.sve_vl);
+
+		err = sigframe_alloc(user, &user->sve_offset,
+				     SVE_SIG_CONTEXT_SIZE(vq));
+		if (err)
+			return err;
+	}
+
 	return sigframe_alloc_end(user);
 }
 
@@ -501,6 +643,13 @@ static int setup_sigframe(struct rt_sigframe_user_layout *user,
 		__put_user_error(current->thread.fault_code, &esr_ctx->esr, err);
 	}
 
+	/* Scalable Vector Extension state, if present */
+	if (system_supports_sve() && err == 0 && user->sve_offset) {
+		struct sve_context __user *sve_ctx =
+			apply_user_offset(user, user->sve_offset);
+		err |= preserve_sve_context(sve_ctx);
+	}
+
 	if (err == 0 && user->extra_offset) {
 		char __user *sfp = (char __user *)user->sigframe;
 		char __user *userp =
@@ -600,6 +749,8 @@ static int setup_rt_frame(int usig, struct ksignal *ksig, sigset_t *set,
 	struct rt_sigframe __user *frame;
 	int err = 0;
 
+	fpsimd_signal_preserve_current_state();
+
 	if (get_sigframe(&user, ksig, regs))
 		return 1;
 

commit abf73988a7c2b2130fbee7cd19d2f57695566050
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Oct 31 15:50:55 2017 +0000

    arm64: signal: Verify extra data is user-readable in sys_rt_sigreturn
    
    Currently sys_rt_sigreturn() verifies that the base sigframe is
    readable, but no similar check is performed on the extra data to
    which an extra_context record points.
    
    This matters because the extra data will be read with the
    unprotected user accessors.  However, this is not a problem at
    present because the extra data base address is required to be
    exactly at the end of the base sigframe.  So, there would need to
    be a non-user-readable kernel address within about 59K
    (SIGFRAME_MAXSZ - sizeof(struct rt_sigframe)) of some address for
    which access_ok(VERIFY_READ) returns true, in order for sigreturn
    to be able to read kernel memory that should be inaccessible to the
    user task.  This is currently impossible due to the untranslatable
    address hole between the TTBR0 and TTBR1 address ranges.
    
    Disappearance of the hole between the TTBR0 and TTBR1 mapping
    ranges would require the VA size for TTBR0 and TTBR1 to grow to at
    least 55 bits, and either the disabling of tagged pointers for
    userspace or enabling of tagged pointers for kernel space; none of
    which is currently envisaged.
    
    Even so, it is wrong to use the unprotected user accessors without
    an accompanying access_ok() check.
    
    To avoid the potential for future surprises, this patch does an
    explicit access_ok() check on the extra data space when parsing an
    extra_context record.
    
    Fixes: 33f082614c34 ("arm64: signal: Allow expansion of the signal frame")
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 8e6500c9471b..a032906cf4f7 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -344,6 +344,10 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			 */
 			offset = 0;
 			limit = extra_size;
+
+			if (!access_ok(VERIFY_READ, base, limit))
+				goto invalid;
+
 			continue;
 
 		default:

commit 8d66772e869e79ffb94eed7492ca3d2267e150e8
Author: James Morse <james.morse@arm.com>
Date:   Thu Nov 2 12:12:37 2017 +0000

    arm64: Mask all exceptions during kernel_exit
    
    To take RAS Exceptions as quickly as possible we need to keep SError
    unmasked as much as possible. We need to mask it during kernel_exit
    as taking an error from this code will overwrite the exception-registers.
    
    Adding a naked 'disable_daif' to kernel_exit causes a performance problem
    for micro-benchmarks that do no real work, (e.g. calling getpid() in a
    loop). This is because the ret_to_user loop has already masked IRQs so
    that the TIF_WORK_MASK thread flags can't change underneath it, adding
    disable_daif is an additional self-synchronising operation.
    
    In the future, the RAS APEI code may need to modify the TIF_WORK_MASK
    flags from an SError, in which case the ret_to_user loop must mask SError
    while it examines the flags.
    
    Disable all exceptions for return to EL1. For return to EL0 get the
    ret_to_user loop to leave all exceptions masked once it has done its
    work, this avoids an extra pstate-write.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 0bdc96c61bc0..8e6500c9471b 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -31,6 +31,7 @@
 #include <linux/ratelimit.h>
 #include <linux/syscalls.h>
 
+#include <asm/daifflags.h>
 #include <asm/debug-monitors.h>
 #include <asm/elf.h>
 #include <asm/cacheflush.h>
@@ -756,9 +757,12 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 		addr_limit_user_check();
 
 		if (thread_flags & _TIF_NEED_RESCHED) {
+			/* Unmask Debug and SError for the next task */
+			local_daif_restore(DAIF_PROCCTX_NOIRQ);
+
 			schedule();
 		} else {
-			local_irq_enable();
+			local_daif_restore(DAIF_PROCCTX);
 
 			if (thread_flags & _TIF_UPROBE)
 				uprobe_notify_resume(regs);
@@ -775,7 +779,7 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 				fpsimd_restore_current_state();
 		}
 
-		local_irq_disable();
+		local_daif_mask();
 		thread_flags = READ_ONCE(current_thread_info()->flags);
 	} while (thread_flags & _TIF_WORK_MASK);
 }

commit a2048e34d4655c06d31400646ae495bbfeb16b27
Author: Thomas Garnier <thgarnie@google.com>
Date:   Thu Sep 7 08:30:47 2017 -0700

    arm64/syscalls: Move address limit check in loop
    
    A bug was reported on ARM where set_fs might be called after it was
    checked on the work pending function. ARM64 is not affected by this bug
    but has a similar construct. In order to avoid any similar problems in
    the future, the addr_limit_user_check function is moved at the beginning
    of the loop.
    
    Fixes: cf7de27ab351 ("arm64/syscalls: Check address limit on user-mode return")
    Reported-by: Leonard Crestez <leonard.crestez@nxp.com>
    Signed-off-by: Thomas Garnier <thgarnie@google.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Pratyush Anand <panand@redhat.com>
    Cc: Dave Martin <Dave.Martin@arm.com>
    Cc: Will Drewry <wad@chromium.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: linux-api@vger.kernel.org
    Cc: Yonghong Song <yhs@fb.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/1504798247-48833-5-git-send-email-keescook@chromium.org

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index c45214f8fb54..0bdc96c61bc0 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -751,10 +751,10 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 	 */
 	trace_hardirqs_off();
 
-	/* Check valid user FS if needed */
-	addr_limit_user_check();
-
 	do {
+		/* Check valid user FS if needed */
+		addr_limit_user_check();
+
 		if (thread_flags & _TIF_NEED_RESCHED) {
 			schedule();
 		} else {

commit 04759194dc447ff0b9ef35bc641ce3bb076c2930
Merge: 9e85ae6af6e9 d1be5c99a034
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 5 09:53:37 2017 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - VMAP_STACK support, allowing the kernel stacks to be allocated in the
       vmalloc space with a guard page for trapping stack overflows. One of
       the patches introduces THREAD_ALIGN and changes the generic
       alloc_thread_stack_node() to use this instead of THREAD_SIZE (no
       functional change for other architectures)
    
     - Contiguous PTE hugetlb support re-enabled (after being reverted a
       couple of times). We now have the semantics agreed in the generic mm
       layer together with API improvements so that the architecture code
       can detect between contiguous and non-contiguous huge PTEs
    
     - Initial support for persistent memory on ARM: DC CVAP instruction
       exposed to user space (HWCAP) and the in-kernel pmem API implemented
    
     - raid6 improvements for arm64: faster algorithm for the delta syndrome
       and implementation of the recovery routines using Neon
    
     - FP/SIMD refactoring and removal of support for Neon in interrupt
       context. This is in preparation for full SVE support
    
     - PTE accessors converted from inline asm to cmpxchg so that we can use
       LSE atomics if available (ARMv8.1)
    
     - Perf support for Cortex-A35 and A73
    
     - Non-urgent fixes and cleanups
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (75 commits)
      arm64: cleanup {COMPAT_,}SET_PERSONALITY() macro
      arm64: introduce separated bits for mm_context_t flags
      arm64: hugetlb: Cleanup setup_hugepagesz
      arm64: Re-enable support for contiguous hugepages
      arm64: hugetlb: Override set_huge_swap_pte_at() to support contiguous hugepages
      arm64: hugetlb: Override huge_pte_clear() to support contiguous hugepages
      arm64: hugetlb: Handle swap entries in huge_pte_offset() for contiguous hugepages
      arm64: hugetlb: Add break-before-make logic for contiguous entries
      arm64: hugetlb: Spring clean huge pte accessors
      arm64: hugetlb: Introduce pte_pgprot helper
      arm64: hugetlb: set_huge_pte_at Add WARN_ON on !pte_present
      arm64: kexec: have own crash_smp_send_stop() for crash dump for nonpanic cores
      arm64: dma-mapping: Mark atomic_pool as __ro_after_init
      arm64: dma-mapping: Do not pass data to gen_pool_set_algo()
      arm64: Remove the !CONFIG_ARM64_HW_AFDBM alternative code paths
      arm64: Ignore hardware dirty bit updates in ptep_set_wrprotect()
      arm64: Move PTE_RDONLY bit handling out of set_pte_at()
      kvm: arm64: Convert kvm_set_s2pte_readonly() from inline asm to cmpxchg()
      arm64: Convert pte handling from inline asm to using (cmp)xchg
      arm64: neon/efi: Make EFI fpsimd save/restore variables static
      ...

commit 6c51e67b64d169419fb13318035bb442f9176612
Merge: e0a195b5225e cf7de27ab351
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 4 11:18:17 2017 -0700

    Merge branch 'x86-syscall-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull syscall updates from Ingo Molnar:
     "Improve the security of set_fs(): we now check the address limit on a
      number of key platforms (x86, arm, arm64) before returning to
      user-space - without adding overhead to the typical system call fast
      path"
    
    * 'x86-syscall-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      arm64/syscalls: Check address limit on user-mode return
      arm/syscalls: Check address limit on user-mode return
      x86/syscalls: Check address limit on user-mode return

commit 17c28958600928109049a3bcc814b0d5bfb1ff3a
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Aug 1 15:35:54 2017 +0100

    arm64: Abstract syscallno manipulation
    
    The -1 "no syscall" value is written in various ways, shared with
    the user ABI in some places, and generally obscure.
    
    This patch attempts to make things a little more consistent and
    readable by replacing all these uses with a single #define.  A
    couple of symbolic helpers are provided to clarify the intent
    further.
    
    Because the in-syscall check in do_signal() is changed from >= 0 to
    != NO_SYSCALL by this patch, different behaviour may be observable
    if syscallno is set to values less than -1 by a tracer.  However,
    this is not different from the behaviour that is already observable
    if a tracer sets syscallno to a value >= __NR_(compat_)syscalls.
    
    It appears that this can cause spurious syscall restarting, but
    that is not a new behaviour either, and does not appear harmful.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 4d04b891c00d..4991e87f80cc 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -36,6 +36,7 @@
 #include <asm/ucontext.h>
 #include <asm/unistd.h>
 #include <asm/fpsimd.h>
+#include <asm/ptrace.h>
 #include <asm/signal32.h>
 #include <asm/vdso.h>
 
@@ -387,7 +388,7 @@ static int restore_sigframe(struct pt_regs *regs,
 	/*
 	 * Avoid sys_rt_sigreturn() restarting.
 	 */
-	regs->syscallno = ~0;
+	forget_syscall(regs);
 
 	err |= !valid_user_regs(&regs->user_regs, current);
 	if (err == 0)
@@ -673,13 +674,12 @@ static void do_signal(struct pt_regs *regs)
 {
 	unsigned long continue_addr = 0, restart_addr = 0;
 	int retval = 0;
-	int syscall = regs->syscallno;
 	struct ksignal ksig;
 
 	/*
 	 * If we were from a system call, check for system call restarting...
 	 */
-	if (syscall >= 0) {
+	if (in_syscall(regs)) {
 		continue_addr = regs->pc;
 		restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
 		retval = regs->regs[0];
@@ -687,7 +687,7 @@ static void do_signal(struct pt_regs *regs)
 		/*
 		 * Avoid additional syscall restarting via ret_to_user.
 		 */
-		regs->syscallno = ~0;
+		forget_syscall(regs);
 
 		/*
 		 * Prepare for system call restart. We do this here so that a
@@ -731,7 +731,7 @@ static void do_signal(struct pt_regs *regs)
 	 * Handle restarting a different system call. As above, if a debugger
 	 * has chosen to restart at a different PC, ignore the restart.
 	 */
-	if (syscall >= 0 && regs->pc == restart_addr) {
+	if (in_syscall(regs) && regs->pc == restart_addr) {
 		if (retval == -ERESTART_RESTARTBLOCK)
 			setup_restart_syscall(regs);
 		user_rewind_single_step(current);

commit 35d0e6fb4d219d64ab3b7cffef7a11a0662140f5
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Aug 1 15:35:53 2017 +0100

    arm64: syscallno is secretly an int, make it official
    
    The upper 32 bits of the syscallno field in thread_struct are
    handled inconsistently, being sometimes zero extended and sometimes
    sign-extended.  In fact, only the lower 32 bits seem to have any
    real significance for the behaviour of the code: it's been OK to
    handle the upper bits inconsistently because they don't matter.
    
    Currently, the only place I can find where those bits are
    significant is in calling trace_sys_enter(), which may be
    unintentional: for example, if a compat tracer attempts to cancel a
    syscall by passing -1 to (COMPAT_)PTRACE_SET_SYSCALL at the
    syscall-enter-stop, it will be traced as syscall 4294967295
    rather than -1 as might be expected (and as occurs for a native
    tracer doing the same thing).  Elsewhere, reads of syscallno cast
    it to an int or truncate it.
    
    There's also a conspicuous amount of code and casting to bodge
    around the fact that although semantically an int, syscallno is
    stored as a u64.
    
    Let's not pretend any more.
    
    In order to preserve the stp x instruction that stores the syscall
    number in entry.S, this patch special-cases the layout of struct
    pt_regs for big endian so that the newly 32-bit syscallno field
    maps onto the low bits of the stored value.  This is not beautiful,
    but benchmarking of the getpid syscall on Juno suggests indicates a
    minor slowdown if the stp is split into an stp x and stp w.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 089c3747995d..4d04b891c00d 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -387,7 +387,7 @@ static int restore_sigframe(struct pt_regs *regs,
 	/*
 	 * Avoid sys_rt_sigreturn() restarting.
 	 */
-	regs->syscallno = ~0UL;
+	regs->syscallno = ~0;
 
 	err |= !valid_user_regs(&regs->user_regs, current);
 	if (err == 0)
@@ -673,7 +673,7 @@ static void do_signal(struct pt_regs *regs)
 {
 	unsigned long continue_addr = 0, restart_addr = 0;
 	int retval = 0;
-	int syscall = (int)regs->syscallno;
+	int syscall = regs->syscallno;
 	struct ksignal ksig;
 
 	/*
@@ -687,7 +687,7 @@ static void do_signal(struct pt_regs *regs)
 		/*
 		 * Avoid additional syscall restarting via ret_to_user.
 		 */
-		regs->syscallno = ~0UL;
+		regs->syscallno = ~0;
 
 		/*
 		 * Prepare for system call restart. We do this here so that a

commit cf7de27ab35172a9240f079477cae3146a182998
Author: Thomas Garnier <thgarnie@google.com>
Date:   Wed Jun 14 18:12:03 2017 -0700

    arm64/syscalls: Check address limit on user-mode return
    
    Ensure the address limit is a user-mode segment before returning to
    user-mode. Otherwise a process can corrupt kernel-mode memory and
    elevate privileges [1].
    
    The set_fs function sets the TIF_SETFS flag to force a slow path on
    return. In the slow path, the address limit is checked to be USER_DS if
    needed.
    
    [1] https://bugs.chromium.org/p/project-zero/issues/detail?id=990
    
    Signed-off-by: Thomas Garnier <thgarnie@google.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: kernel-hardening@lists.openwall.com
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Miroslav Benes <mbenes@suse.cz>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Pratyush Anand <panand@redhat.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Will Drewry <wad@chromium.org>
    Cc: linux-api@vger.kernel.org
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Link: http://lkml.kernel.org/r/20170615011203.144108-3-thgarnie@google.com

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index c7b6de62f9d3..0f0279148bdc 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -25,6 +25,7 @@
 #include <linux/uaccess.h>
 #include <linux/tracehook.h>
 #include <linux/ratelimit.h>
+#include <linux/syscalls.h>
 
 #include <asm/debug-monitors.h>
 #include <asm/elf.h>
@@ -408,6 +409,10 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 	 * Update the trace code with the current status.
 	 */
 	trace_hardirqs_off();
+
+	/* Check valid user FS if needed */
+	addr_limit_user_check();
+
 	do {
 		if (thread_flags & _TIF_NEED_RESCHED) {
 			schedule();

commit 33f082614c3443d937f50fe936f284f62bbb4a1b
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Jun 20 18:23:39 2017 +0100

    arm64: signal: Allow expansion of the signal frame
    
    This patch defines an extra_context signal frame record that can be
    used to describe an expanded signal frame, and modifies the context
    block allocator and signal frame setup and parsing code to create,
    populate, parse and decode this block as necessary.
    
    To avoid abuse by userspace, parse_user_sigframe() attempts to
    ensure that:
    
     * no more than one extra_context is accepted;
     * the extra context data is a sensible size, and properly placed
       and aligned.
    
    The extra_context data is required to start at the first 16-byte
    aligned address immediately after the dummy terminator record
    following extra_context in rt_sigframe.__reserved[] (as ensured
    during signal delivery).  This serves as a sanity-check that the
    signal frame has not been moved or copied without taking the extra
    data into account.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    [will: add __force annotation when casting extra_datap to __user pointer]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index fa787e6ac7c2..089c3747995d 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -25,6 +25,7 @@
 #include <linux/freezer.h>
 #include <linux/stddef.h>
 #include <linux/uaccess.h>
+#include <linux/sizes.h>
 #include <linux/string.h>
 #include <linux/tracehook.h>
 #include <linux/ratelimit.h>
@@ -60,18 +61,27 @@ struct rt_sigframe_user_layout {
 
 	unsigned long fpsimd_offset;
 	unsigned long esr_offset;
+	unsigned long extra_offset;
 	unsigned long end_offset;
 };
 
+#define BASE_SIGFRAME_SIZE round_up(sizeof(struct rt_sigframe), 16)
+#define TERMINATOR_SIZE round_up(sizeof(struct _aarch64_ctx), 16)
+#define EXTRA_CONTEXT_SIZE round_up(sizeof(struct extra_context), 16)
+
 static void init_user_layout(struct rt_sigframe_user_layout *user)
 {
+	const size_t reserved_size =
+		sizeof(user->sigframe->uc.uc_mcontext.__reserved);
+
 	memset(user, 0, sizeof(*user));
 	user->size = offsetof(struct rt_sigframe, uc.uc_mcontext.__reserved);
 
-	user->limit = user->size +
-		sizeof(user->sigframe->uc.uc_mcontext.__reserved) -
-		round_up(sizeof(struct _aarch64_ctx), 16);
-		/* ^ reserve space for terminator */
+	user->limit = user->size + reserved_size;
+
+	user->limit -= TERMINATOR_SIZE;
+	user->limit -= EXTRA_CONTEXT_SIZE;
+	/* Reserve space for extension and terminator ^ */
 }
 
 static size_t sigframe_size(struct rt_sigframe_user_layout const *user)
@@ -79,6 +89,52 @@ static size_t sigframe_size(struct rt_sigframe_user_layout const *user)
 	return round_up(max(user->size, sizeof(struct rt_sigframe)), 16);
 }
 
+/*
+ * Sanity limit on the approximate maximum size of signal frame we'll
+ * try to generate.  Stack alignment padding and the frame record are
+ * not taken into account.  This limit is not a guarantee and is
+ * NOT ABI.
+ */
+#define SIGFRAME_MAXSZ SZ_64K
+
+static int __sigframe_alloc(struct rt_sigframe_user_layout *user,
+			    unsigned long *offset, size_t size, bool extend)
+{
+	size_t padded_size = round_up(size, 16);
+
+	if (padded_size > user->limit - user->size &&
+	    !user->extra_offset &&
+	    extend) {
+		int ret;
+
+		user->limit += EXTRA_CONTEXT_SIZE;
+		ret = __sigframe_alloc(user, &user->extra_offset,
+				       sizeof(struct extra_context), false);
+		if (ret) {
+			user->limit -= EXTRA_CONTEXT_SIZE;
+			return ret;
+		}
+
+		/* Reserve space for the __reserved[] terminator */
+		user->size += TERMINATOR_SIZE;
+
+		/*
+		 * Allow expansion up to SIGFRAME_MAXSZ, ensuring space for
+		 * the terminator:
+		 */
+		user->limit = SIGFRAME_MAXSZ - TERMINATOR_SIZE;
+	}
+
+	/* Still not enough space?  Bad luck! */
+	if (padded_size > user->limit - user->size)
+		return -ENOMEM;
+
+	*offset = user->size;
+	user->size += padded_size;
+
+	return 0;
+}
+
 /*
  * Allocate space for an optional record of <size> bytes in the user
  * signal frame.  The offset from the signal frame base address to the
@@ -87,11 +143,24 @@ static size_t sigframe_size(struct rt_sigframe_user_layout const *user)
 static int sigframe_alloc(struct rt_sigframe_user_layout *user,
 			  unsigned long *offset, size_t size)
 {
-	size_t padded_size = round_up(size, 16);
+	return __sigframe_alloc(user, offset, size, true);
+}
 
-	*offset = user->size;
-	user->size += padded_size;
+/* Allocate the null terminator record and prevent further allocations */
+static int sigframe_alloc_end(struct rt_sigframe_user_layout *user)
+{
+	int ret;
+
+	/* Un-reserve the space reserved for the terminator: */
+	user->limit += TERMINATOR_SIZE;
 
+	ret = sigframe_alloc(user, &user->end_offset,
+			     sizeof(struct _aarch64_ctx));
+	if (ret)
+		return ret;
+
+	/* Prevent further allocation: */
+	user->limit = user->size;
 	return 0;
 }
 
@@ -162,6 +231,8 @@ static int parse_user_sigframe(struct user_ctxs *user,
 	char __user *base = (char __user *)&sc->__reserved;
 	size_t offset = 0;
 	size_t limit = sizeof(sc->__reserved);
+	bool have_extra_context = false;
+	char const __user *const sfp = (char const __user *)sf;
 
 	user->fpsimd = NULL;
 
@@ -171,6 +242,12 @@ static int parse_user_sigframe(struct user_ctxs *user,
 	while (1) {
 		int err = 0;
 		u32 magic, size;
+		char const __user *userp;
+		struct extra_context const __user *extra;
+		u64 extra_datap;
+		u32 extra_size;
+		struct _aarch64_ctx const __user *end;
+		u32 end_magic, end_size;
 
 		if (limit - offset < sizeof(*head))
 			goto invalid;
@@ -208,6 +285,64 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			/* ignore */
 			break;
 
+		case EXTRA_MAGIC:
+			if (have_extra_context)
+				goto invalid;
+
+			if (size < sizeof(*extra))
+				goto invalid;
+
+			userp = (char const __user *)head;
+
+			extra = (struct extra_context const __user *)userp;
+			userp += size;
+
+			__get_user_error(extra_datap, &extra->datap, err);
+			__get_user_error(extra_size, &extra->size, err);
+			if (err)
+				return err;
+
+			/* Check for the dummy terminator in __reserved[]: */
+
+			if (limit - offset - size < TERMINATOR_SIZE)
+				goto invalid;
+
+			end = (struct _aarch64_ctx const __user *)userp;
+			userp += TERMINATOR_SIZE;
+
+			__get_user_error(end_magic, &end->magic, err);
+			__get_user_error(end_size, &end->size, err);
+			if (err)
+				return err;
+
+			if (end_magic || end_size)
+				goto invalid;
+
+			/* Prevent looping/repeated parsing of extra_context */
+			have_extra_context = true;
+
+			base = (__force void __user *)extra_datap;
+			if (!IS_ALIGNED((unsigned long)base, 16))
+				goto invalid;
+
+			if (!IS_ALIGNED(extra_size, 16))
+				goto invalid;
+
+			if (base != userp)
+				goto invalid;
+
+			/* Reject "unreasonably large" frames: */
+			if (extra_size > sfp + SIGFRAME_MAXSZ - userp)
+				goto invalid;
+
+			/*
+			 * Ignore trailing terminator in __reserved[]
+			 * and start parsing extra data:
+			 */
+			offset = 0;
+			limit = extra_size;
+			continue;
+
 		default:
 			goto invalid;
 		}
@@ -318,17 +453,7 @@ static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 			return err;
 	}
 
-	/*
-	 * Allocate space for the terminator record.
-	 * HACK: here we undo the reservation of space for the end record.
-	 * This bodge should be replaced with a cleaner approach later on.
-	 */
-	user->limit = offsetof(struct rt_sigframe, uc.uc_mcontext.__reserved) +
-		sizeof(user->sigframe->uc.uc_mcontext.__reserved);
-
-	err = sigframe_alloc(user, &user->end_offset,
-			     sizeof(struct _aarch64_ctx));
-	return err;
+	return sigframe_alloc_end(user);
 }
 
 
@@ -369,6 +494,40 @@ static int setup_sigframe(struct rt_sigframe_user_layout *user,
 		__put_user_error(current->thread.fault_code, &esr_ctx->esr, err);
 	}
 
+	if (err == 0 && user->extra_offset) {
+		char __user *sfp = (char __user *)user->sigframe;
+		char __user *userp =
+			apply_user_offset(user, user->extra_offset);
+
+		struct extra_context __user *extra;
+		struct _aarch64_ctx __user *end;
+		u64 extra_datap;
+		u32 extra_size;
+
+		extra = (struct extra_context __user *)userp;
+		userp += EXTRA_CONTEXT_SIZE;
+
+		end = (struct _aarch64_ctx __user *)userp;
+		userp += TERMINATOR_SIZE;
+
+		/*
+		 * extra_datap is just written to the signal frame.
+		 * The value gets cast back to a void __user *
+		 * during sigreturn.
+		 */
+		extra_datap = (__force u64)userp;
+		extra_size = sfp + round_up(user->size, 16) - userp;
+
+		__put_user_error(EXTRA_MAGIC, &extra->head.magic, err);
+		__put_user_error(EXTRA_CONTEXT_SIZE, &extra->head.size, err);
+		__put_user_error(extra_datap, &extra->datap, err);
+		__put_user_error(extra_size, &extra->size, err);
+
+		/* Add the terminator */
+		__put_user_error(0, &end->magic, err);
+		__put_user_error(0, &end->size, err);
+	}
+
 	/* set the "end" magic */
 	if (err == 0) {
 		struct _aarch64_ctx __user *end =

commit bb4322f74340de578bc61ed0cfb9690ddeb9ef76
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Jun 15 15:03:41 2017 +0100

    arm64: signal: factor out signal frame record allocation
    
    This patch factors out the allocator for signal frame optional
    records into a separate function, to ensure consistency and
    facilitate later expansion.
    
    No overrun checking is currently done, because the allocation is in
    user memory and anyway the kernel never tries to allocate enough
    space in the signal frame yet for an overrun to occur.  This
    behaviour will be refined in future patches.
    
    The approach taken in this patch to allocation of the terminator
    record is not very clean: this will also be replaced in subsequent
    patches.
    
    For future extension, a comment is added in sigcontext.h
    documenting the current static allocations in __reserved[].  This
    will be important for determining under what circumstances
    userspace may or may not see an expanded signal frame.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index eaef530579f8..fa787e6ac7c2 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -79,6 +79,22 @@ static size_t sigframe_size(struct rt_sigframe_user_layout const *user)
 	return round_up(max(user->size, sizeof(struct rt_sigframe)), 16);
 }
 
+/*
+ * Allocate space for an optional record of <size> bytes in the user
+ * signal frame.  The offset from the signal frame base address to the
+ * allocated block is assigned to *offset.
+ */
+static int sigframe_alloc(struct rt_sigframe_user_layout *user,
+			  unsigned long *offset, size_t size)
+{
+	size_t padded_size = round_up(size, 16);
+
+	*offset = user->size;
+	user->size += padded_size;
+
+	return 0;
+}
+
 static void __user *apply_user_offset(
 	struct rt_sigframe_user_layout const *user, unsigned long offset)
 {
@@ -287,19 +303,32 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 /* Determine the layout of optional records in the signal frame */
 static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
 {
-	user->fpsimd_offset = user->size;
-	user->size += round_up(sizeof(struct fpsimd_context), 16);
+	int err;
+
+	err = sigframe_alloc(user, &user->fpsimd_offset,
+			     sizeof(struct fpsimd_context));
+	if (err)
+		return err;
 
 	/* fault information, if valid */
 	if (current->thread.fault_code) {
-		user->esr_offset = user->size;
-		user->size += round_up(sizeof(struct esr_context), 16);
+		err = sigframe_alloc(user, &user->esr_offset,
+				     sizeof(struct esr_context));
+		if (err)
+			return err;
 	}
 
-	/* set the "end" magic */
-	user->end_offset = user->size;
+	/*
+	 * Allocate space for the terminator record.
+	 * HACK: here we undo the reservation of space for the end record.
+	 * This bodge should be replaced with a cleaner approach later on.
+	 */
+	user->limit = offsetof(struct rt_sigframe, uc.uc_mcontext.__reserved) +
+		sizeof(user->sigframe->uc.uc_mcontext.__reserved);
 
-	return 0;
+	err = sigframe_alloc(user, &user->end_offset,
+			     sizeof(struct _aarch64_ctx));
+	return err;
 }
 
 

commit bb4891a6c3551f27fa4d548b87a66c258bdb100b
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Jun 15 15:03:40 2017 +0100

    arm64: signal: factor frame layout and population into separate passes
    
    In preparation for expanding the signal frame, this patch refactors
    the signal frame setup code in setup_sigframe() into two separate
    passes.
    
    The first pass, setup_sigframe_layout(), determines the size of the
    signal frame and its internal layout, including the presence and
    location of optional records.  The resulting knowledge is used to
    allocate and locate the user stack space required for the signal
    frame and to determine which optional records to include.
    
    The second pass, setup_sigframe(), is called once the stack frame
    is allocated in order to populate it with the necessary context
    information.
    
    As a result of these changes, it becomes more natural to represent
    locations in the signal frame by a base pointer and an offset,
    since the absolute address of each location is not known during the
    layout pass.  To be more consistent with this logic,
    parse_user_sigframe() is refactored to describe signal frame
    locations in a similar way.
    
    This change has no effect on the signal ABI, but will make it
    easier to expand the signal frame in future patches.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 67769f68ae06..eaef530579f8 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -25,6 +25,7 @@
 #include <linux/freezer.h>
 #include <linux/stddef.h>
 #include <linux/uaccess.h>
+#include <linux/string.h>
 #include <linux/tracehook.h>
 #include <linux/ratelimit.h>
 
@@ -53,8 +54,39 @@ struct frame_record {
 struct rt_sigframe_user_layout {
 	struct rt_sigframe __user *sigframe;
 	struct frame_record __user *next_frame;
+
+	unsigned long size;	/* size of allocated sigframe data */
+	unsigned long limit;	/* largest allowed size */
+
+	unsigned long fpsimd_offset;
+	unsigned long esr_offset;
+	unsigned long end_offset;
 };
 
+static void init_user_layout(struct rt_sigframe_user_layout *user)
+{
+	memset(user, 0, sizeof(*user));
+	user->size = offsetof(struct rt_sigframe, uc.uc_mcontext.__reserved);
+
+	user->limit = user->size +
+		sizeof(user->sigframe->uc.uc_mcontext.__reserved) -
+		round_up(sizeof(struct _aarch64_ctx), 16);
+		/* ^ reserve space for terminator */
+}
+
+static size_t sigframe_size(struct rt_sigframe_user_layout const *user)
+{
+	return round_up(max(user->size, sizeof(struct rt_sigframe)), 16);
+}
+
+static void __user *apply_user_offset(
+	struct rt_sigframe_user_layout const *user, unsigned long offset)
+{
+	char __user *base = (char __user *)user->sigframe;
+
+	return base + offset;
+}
+
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 {
 	struct fpsimd_state *fpsimd = &current->thread.fpsimd_state;
@@ -110,26 +142,35 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			       struct rt_sigframe __user *sf)
 {
 	struct sigcontext __user *const sc = &sf->uc.uc_mcontext;
-	struct _aarch64_ctx __user *head =
-		(struct _aarch64_ctx __user *)&sc->__reserved;
+	struct _aarch64_ctx __user *head;
+	char __user *base = (char __user *)&sc->__reserved;
 	size_t offset = 0;
+	size_t limit = sizeof(sc->__reserved);
 
 	user->fpsimd = NULL;
 
+	if (!IS_ALIGNED((unsigned long)base, 16))
+		goto invalid;
+
 	while (1) {
-		int err;
+		int err = 0;
 		u32 magic, size;
 
-		head = (struct _aarch64_ctx __user *)&sc->__reserved[offset];
-		if (!IS_ALIGNED((unsigned long)head, 16))
+		if (limit - offset < sizeof(*head))
 			goto invalid;
 
-		err = 0;
+		if (!IS_ALIGNED(offset, 16))
+			goto invalid;
+
+		head = (struct _aarch64_ctx __user *)(base + offset);
 		__get_user_error(magic, &head->magic, err);
 		__get_user_error(size, &head->size, err);
 		if (err)
 			return err;
 
+		if (limit - offset < size)
+			goto invalid;
+
 		switch (magic) {
 		case 0:
 			if (size)
@@ -141,9 +182,7 @@ static int parse_user_sigframe(struct user_ctxs *user,
 			if (user->fpsimd)
 				goto invalid;
 
-			if (offset > sizeof(sc->__reserved) -
-					sizeof(*user->fpsimd) ||
-			    size < sizeof(*user->fpsimd))
+			if (size < sizeof(*user->fpsimd))
 				goto invalid;
 
 			user->fpsimd = (struct fpsimd_context __user *)head;
@@ -160,7 +199,7 @@ static int parse_user_sigframe(struct user_ctxs *user,
 		if (size < sizeof(*head))
 			goto invalid;
 
-		if (size > sizeof(sc->__reserved) - (sizeof(*head) + offset))
+		if (limit - offset < size)
 			goto invalid;
 
 		offset += size;
@@ -245,13 +284,30 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	return 0;
 }
 
+/* Determine the layout of optional records in the signal frame */
+static int setup_sigframe_layout(struct rt_sigframe_user_layout *user)
+{
+	user->fpsimd_offset = user->size;
+	user->size += round_up(sizeof(struct fpsimd_context), 16);
+
+	/* fault information, if valid */
+	if (current->thread.fault_code) {
+		user->esr_offset = user->size;
+		user->size += round_up(sizeof(struct esr_context), 16);
+	}
+
+	/* set the "end" magic */
+	user->end_offset = user->size;
+
+	return 0;
+}
+
+
 static int setup_sigframe(struct rt_sigframe_user_layout *user,
 			  struct pt_regs *regs, sigset_t *set)
 {
 	int i, err = 0;
 	struct rt_sigframe __user *sf = user->sigframe;
-	void *aux = sf->uc.uc_mcontext.__reserved;
-	struct _aarch64_ctx *end;
 
 	/* set up the stack frame for unwinding */
 	__put_user_error(regs->regs[29], &user->next_frame->fp, err);
@@ -269,26 +325,29 @@ static int setup_sigframe(struct rt_sigframe_user_layout *user,
 	err |= __copy_to_user(&sf->uc.uc_sigmask, set, sizeof(*set));
 
 	if (err == 0) {
-		struct fpsimd_context *fpsimd_ctx =
-			container_of(aux, struct fpsimd_context, head);
+		struct fpsimd_context __user *fpsimd_ctx =
+			apply_user_offset(user, user->fpsimd_offset);
 		err |= preserve_fpsimd_context(fpsimd_ctx);
-		aux += sizeof(*fpsimd_ctx);
 	}
 
 	/* fault information, if valid */
-	if (current->thread.fault_code) {
-		struct esr_context *esr_ctx =
-			container_of(aux, struct esr_context, head);
+	if (err == 0 && user->esr_offset) {
+		struct esr_context __user *esr_ctx =
+			apply_user_offset(user, user->esr_offset);
+
 		__put_user_error(ESR_MAGIC, &esr_ctx->head.magic, err);
 		__put_user_error(sizeof(*esr_ctx), &esr_ctx->head.size, err);
 		__put_user_error(current->thread.fault_code, &esr_ctx->esr, err);
-		aux += sizeof(*esr_ctx);
 	}
 
 	/* set the "end" magic */
-	end = aux;
-	__put_user_error(0, &end->magic, err);
-	__put_user_error(0, &end->size, err);
+	if (err == 0) {
+		struct _aarch64_ctx __user *end =
+			apply_user_offset(user, user->end_offset);
+
+		__put_user_error(0, &end->magic, err);
+		__put_user_error(0, &end->size, err);
+	}
 
 	return err;
 }
@@ -297,13 +356,19 @@ static int get_sigframe(struct rt_sigframe_user_layout *user,
 			 struct ksignal *ksig, struct pt_regs *regs)
 {
 	unsigned long sp, sp_top;
+	int err;
+
+	init_user_layout(user);
+	err = setup_sigframe_layout(user);
+	if (err)
+		return err;
 
 	sp = sp_top = sigsp(regs->sp, ksig);
 
 	sp = round_down(sp - sizeof(struct frame_record), 16);
 	user->next_frame = (struct frame_record __user *)sp;
 
-	sp = round_down(sp - sizeof(struct rt_sigframe), 16);
+	sp = round_down(sp, 16) - sigframe_size(user);
 	user->sigframe = (struct rt_sigframe __user *)sp;
 
 	/*

commit 47ccb02868cead34578d953b5fe0cdd58394605e
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Jun 15 15:03:39 2017 +0100

    arm64: signal: Refactor sigcontext parsing in rt_sigreturn
    
    Currently, rt_sigreturn does very limited checking on the
    sigcontext coming from userspace.
    
    Future additions to the sigcontext data will increase the potential
    for surprises.  Also, it is not clear whether the sigcontext
    extension records are supposed to occur in a particular order.
    
    To allow the parsing code to be extended more easily, this patch
    factors out the sigcontext parsing into a separate function, and
    adds extra checks to validate the well-formedness of the sigcontext
    structure.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 1e5ed3be78ed..67769f68ae06 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -23,6 +23,7 @@
 #include <linux/signal.h>
 #include <linux/personality.h>
 #include <linux/freezer.h>
+#include <linux/stddef.h>
 #include <linux/uaccess.h>
 #include <linux/tracehook.h>
 #include <linux/ratelimit.h>
@@ -101,12 +102,86 @@ static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
 	return err ? -EFAULT : 0;
 }
 
+struct user_ctxs {
+	struct fpsimd_context __user *fpsimd;
+};
+
+static int parse_user_sigframe(struct user_ctxs *user,
+			       struct rt_sigframe __user *sf)
+{
+	struct sigcontext __user *const sc = &sf->uc.uc_mcontext;
+	struct _aarch64_ctx __user *head =
+		(struct _aarch64_ctx __user *)&sc->__reserved;
+	size_t offset = 0;
+
+	user->fpsimd = NULL;
+
+	while (1) {
+		int err;
+		u32 magic, size;
+
+		head = (struct _aarch64_ctx __user *)&sc->__reserved[offset];
+		if (!IS_ALIGNED((unsigned long)head, 16))
+			goto invalid;
+
+		err = 0;
+		__get_user_error(magic, &head->magic, err);
+		__get_user_error(size, &head->size, err);
+		if (err)
+			return err;
+
+		switch (magic) {
+		case 0:
+			if (size)
+				goto invalid;
+
+			goto done;
+
+		case FPSIMD_MAGIC:
+			if (user->fpsimd)
+				goto invalid;
+
+			if (offset > sizeof(sc->__reserved) -
+					sizeof(*user->fpsimd) ||
+			    size < sizeof(*user->fpsimd))
+				goto invalid;
+
+			user->fpsimd = (struct fpsimd_context __user *)head;
+			break;
+
+		case ESR_MAGIC:
+			/* ignore */
+			break;
+
+		default:
+			goto invalid;
+		}
+
+		if (size < sizeof(*head))
+			goto invalid;
+
+		if (size > sizeof(sc->__reserved) - (sizeof(*head) + offset))
+			goto invalid;
+
+		offset += size;
+	}
+
+done:
+	if (!user->fpsimd)
+		goto invalid;
+
+	return 0;
+
+invalid:
+	return -EINVAL;
+}
+
 static int restore_sigframe(struct pt_regs *regs,
 			    struct rt_sigframe __user *sf)
 {
 	sigset_t set;
 	int i, err;
-	void *aux = sf->uc.uc_mcontext.__reserved;
+	struct user_ctxs user;
 
 	err = __copy_from_user(&set, &sf->uc.uc_sigmask, sizeof(set));
 	if (err == 0)
@@ -125,12 +200,11 @@ static int restore_sigframe(struct pt_regs *regs,
 	regs->syscallno = ~0UL;
 
 	err |= !valid_user_regs(&regs->user_regs, current);
+	if (err == 0)
+		err = parse_user_sigframe(&user, sf);
 
-	if (err == 0) {
-		struct fpsimd_context *fpsimd_ctx =
-			container_of(aux, struct fpsimd_context, head);
-		err |= restore_fpsimd_context(fpsimd_ctx);
-	}
+	if (err == 0)
+		err = restore_fpsimd_context(user.fpsimd);
 
 	return err;
 }

commit 20987de3c2c45c314e0386f724aa85f55d984ef2
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Jun 15 15:03:38 2017 +0100

    arm64: signal: split frame link record from sigcontext structure
    
    In order to be able to increase the amount of the data currently
    written to the __reserved[] array in the signal frame, it is
    necessary to overwrite the locations currently occupied by the
    {fp,lr} frame link record pushed at the top of the signal stack.
    
    In order for this to work, this patch detaches the frame link
    record from struct rt_sigframe and places it separately at the top
    of the signal stack.  This will allow subsequent patches to insert
    data between it and __reserved[].
    
    This change relies on the non-ABI status of the placement of the
    frame record with respect to struct sigframe: this status is
    undocumented, but the placement is not declared or described in the
    user headers, and known unwinder implementations (libgcc,
    libunwind, gdb) appear not to rely on it.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index c7b6de62f9d3..1e5ed3be78ed 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -19,6 +19,7 @@
 
 #include <linux/compat.h>
 #include <linux/errno.h>
+#include <linux/kernel.h>
 #include <linux/signal.h>
 #include <linux/personality.h>
 #include <linux/freezer.h>
@@ -41,10 +42,18 @@
 struct rt_sigframe {
 	struct siginfo info;
 	struct ucontext uc;
+};
+
+struct frame_record {
 	u64 fp;
 	u64 lr;
 };
 
+struct rt_sigframe_user_layout {
+	struct rt_sigframe __user *sigframe;
+	struct frame_record __user *next_frame;
+};
+
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 {
 	struct fpsimd_state *fpsimd = &current->thread.fpsimd_state;
@@ -162,16 +171,17 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	return 0;
 }
 
-static int setup_sigframe(struct rt_sigframe __user *sf,
+static int setup_sigframe(struct rt_sigframe_user_layout *user,
 			  struct pt_regs *regs, sigset_t *set)
 {
 	int i, err = 0;
+	struct rt_sigframe __user *sf = user->sigframe;
 	void *aux = sf->uc.uc_mcontext.__reserved;
 	struct _aarch64_ctx *end;
 
 	/* set up the stack frame for unwinding */
-	__put_user_error(regs->regs[29], &sf->fp, err);
-	__put_user_error(regs->regs[30], &sf->lr, err);
+	__put_user_error(regs->regs[29], &user->next_frame->fp, err);
+	__put_user_error(regs->regs[30], &user->next_frame->lr, err);
 
 	for (i = 0; i < 31; i++)
 		__put_user_error(regs->regs[i], &sf->uc.uc_mcontext.regs[i],
@@ -209,34 +219,36 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 	return err;
 }
 
-static struct rt_sigframe __user *get_sigframe(struct ksignal *ksig,
-					       struct pt_regs *regs)
+static int get_sigframe(struct rt_sigframe_user_layout *user,
+			 struct ksignal *ksig, struct pt_regs *regs)
 {
 	unsigned long sp, sp_top;
-	struct rt_sigframe __user *frame;
 
 	sp = sp_top = sigsp(regs->sp, ksig);
 
-	sp = (sp - sizeof(struct rt_sigframe)) & ~15;
-	frame = (struct rt_sigframe __user *)sp;
+	sp = round_down(sp - sizeof(struct frame_record), 16);
+	user->next_frame = (struct frame_record __user *)sp;
+
+	sp = round_down(sp - sizeof(struct rt_sigframe), 16);
+	user->sigframe = (struct rt_sigframe __user *)sp;
 
 	/*
 	 * Check that we can actually write to the signal frame.
 	 */
-	if (!access_ok(VERIFY_WRITE, frame, sp_top - sp))
-		frame = NULL;
+	if (!access_ok(VERIFY_WRITE, user->sigframe, sp_top - sp))
+		return -EFAULT;
 
-	return frame;
+	return 0;
 }
 
 static void setup_return(struct pt_regs *regs, struct k_sigaction *ka,
-			 void __user *frame, int usig)
+			 struct rt_sigframe_user_layout *user, int usig)
 {
 	__sigrestore_t sigtramp;
 
 	regs->regs[0] = usig;
-	regs->sp = (unsigned long)frame;
-	regs->regs[29] = regs->sp + offsetof(struct rt_sigframe, fp);
+	regs->sp = (unsigned long)user->sigframe;
+	regs->regs[29] = (unsigned long)&user->next_frame->fp;
 	regs->pc = (unsigned long)ka->sa.sa_handler;
 
 	if (ka->sa.sa_flags & SA_RESTORER)
@@ -250,20 +262,22 @@ static void setup_return(struct pt_regs *regs, struct k_sigaction *ka,
 static int setup_rt_frame(int usig, struct ksignal *ksig, sigset_t *set,
 			  struct pt_regs *regs)
 {
+	struct rt_sigframe_user_layout user;
 	struct rt_sigframe __user *frame;
 	int err = 0;
 
-	frame = get_sigframe(ksig, regs);
-	if (!frame)
+	if (get_sigframe(&user, ksig, regs))
 		return 1;
 
+	frame = user.sigframe;
+
 	__put_user_error(0, &frame->uc.uc_flags, err);
 	__put_user_error(NULL, &frame->uc.uc_link, err);
 
 	err |= __save_altstack(&frame->uc.uc_stack, regs->sp);
-	err |= setup_sigframe(frame, regs, set);
+	err |= setup_sigframe(&user, regs, set);
 	if (err == 0) {
-		setup_return(regs, &ksig->ka, frame, usig);
+		setup_return(regs, &ksig->ka, &user, usig);
 		if (ksig->ka.sa.sa_flags & SA_SIGINFO) {
 			err |= copy_siginfo_to_user(&frame->info, &ksig->info);
 			regs->regs[1] = (unsigned long)&frame->info;

commit 9842ceae9fa8deae141533d52a6ead7666962c09
Author: Pratyush Anand <panand@redhat.com>
Date:   Wed Nov 2 14:40:46 2016 +0530

    arm64: Add uprobe support
    
    This patch adds support for uprobe on ARM64 architecture.
    
    Unit tests for following have been done so far and they have been found
    working
        1. Step-able instructions, like sub, ldr, add etc.
        2. Simulation-able like ret, cbnz, cbz etc.
        3. uretprobe
        4. Reject-able instructions like sev, wfe etc.
        5. trapped and abort xol path
        6. probe at unaligned user address.
        7. longjump test cases
    
    Currently it does not support aarch32 instruction probing.
    
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 404dd67080b9..c7b6de62f9d3 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -414,6 +414,9 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 		} else {
 			local_irq_enable();
 
+			if (thread_flags & _TIF_UPROBE)
+				uprobe_notify_resume(regs);
+
 			if (thread_flags & _TIF_SIGPENDING)
 				do_signal(regs);
 

commit 421dd6fa6709ebee4f888ed89da5c103c77caee1
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Thu Jul 14 16:48:14 2016 -0400

    arm64: factor work_pending state machine to C
    
    Currently ret_fast_syscall, work_pending, and ret_to_user form an ad-hoc
    state machine that can be difficult to reason about due to duplicated
    code and a large number of branch targets.
    
    This patch factors the common logic out into the existing
    do_notify_resume function, converting the code to C in the process,
    making the code more legible.
    
    This patch tries to closely mirror the existing behaviour while using
    the usual C control flow primitives. As local_irq_{disable,enable} may
    be instrumented, we balance exception entry (where we will almost most
    likely enable IRQs) with a call to trace_hardirqs_on just before the
    return to userspace.
    
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index a8eafdbc7cb8..404dd67080b9 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -402,15 +402,31 @@ static void do_signal(struct pt_regs *regs)
 asmlinkage void do_notify_resume(struct pt_regs *regs,
 				 unsigned int thread_flags)
 {
-	if (thread_flags & _TIF_SIGPENDING)
-		do_signal(regs);
-
-	if (thread_flags & _TIF_NOTIFY_RESUME) {
-		clear_thread_flag(TIF_NOTIFY_RESUME);
-		tracehook_notify_resume(regs);
-	}
-
-	if (thread_flags & _TIF_FOREIGN_FPSTATE)
-		fpsimd_restore_current_state();
+	/*
+	 * The assembly code enters us with IRQs off, but it hasn't
+	 * informed the tracing code of that for efficiency reasons.
+	 * Update the trace code with the current status.
+	 */
+	trace_hardirqs_off();
+	do {
+		if (thread_flags & _TIF_NEED_RESCHED) {
+			schedule();
+		} else {
+			local_irq_enable();
+
+			if (thread_flags & _TIF_SIGPENDING)
+				do_signal(regs);
+
+			if (thread_flags & _TIF_NOTIFY_RESUME) {
+				clear_thread_flag(TIF_NOTIFY_RESUME);
+				tracehook_notify_resume(regs);
+			}
+
+			if (thread_flags & _TIF_FOREIGN_FPSTATE)
+				fpsimd_restore_current_state();
+		}
 
+		local_irq_disable();
+		thread_flags = READ_ONCE(current_thread_info()->flags);
+	} while (thread_flags & _TIF_WORK_MASK);
 }

commit dbd4d7ca563fd0a8949718d35ce197e5642d5d9d
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Mar 1 14:18:50 2016 +0000

    arm64: Rework valid_user_regs
    
    We validate pstate using PSR_MODE32_BIT, which is part of the
    user-provided pstate (and cannot be trusted). Also, we conflate
    validation of AArch32 and AArch64 pstate values, making the code
    difficult to reason about.
    
    Instead, validate the pstate value based on the associated task. The
    task may or may not be current (e.g. when using ptrace), so this must be
    passed explicitly by callers. To avoid circular header dependencies via
    sched.h, is_compat_task is pulled out of asm/ptrace.h.
    
    To make the code possible to reason about, the AArch64 and AArch32
    validation is split into separate functions. Software must respect the
    RES0 policy for SPSR bits, and thus the kernel mirrors the hardware
    policy (RAZ/WI) for bits as-yet unallocated. When these acquire an
    architected meaning writes may be permitted (potentially with additional
    validation).
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Dave Martin <dave.martin@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Peter Maydell <peter.maydell@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index e18c48cb6db1..a8eafdbc7cb8 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -115,7 +115,7 @@ static int restore_sigframe(struct pt_regs *regs,
 	 */
 	regs->syscallno = ~0UL;
 
-	err |= !valid_user_regs(&regs->user_regs);
+	err |= !valid_user_regs(&regs->user_regs, current);
 
 	if (err == 0) {
 		struct fpsimd_context *fpsimd_ctx =
@@ -307,7 +307,7 @@ static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	/*
 	 * Check that the resulting registers are actually sane.
 	 */
-	ret |= !valid_user_regs(&regs->user_regs);
+	ret |= !valid_user_regs(&regs->user_regs, current);
 
 	/*
 	 * Fast forward the stepping logic so we step into the signal

commit 97b2f0dc331474fb80ba4f4e4aee1d8e9ffbf7ce
Author: Richard Weinberger <richard@nod.at>
Date:   Mon Apr 13 20:40:10 2015 +0200

    arm64: Removed unused variable
    
    arch/arm64/kernel/signal.c: In function ‘handle_signal’:
    arch/arm64/kernel/signal.c:290:22: warning: unused variable ‘thread’ [-Wunused-variable]
    
    Fixes: arm64: Remove signal translation and exec_domain
    Reported-by: Thierry Reding <thierry.reding@gmail.com>
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 9f28eaa97123..e18c48cb6db1 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -287,7 +287,6 @@ static void setup_restart_syscall(struct pt_regs *regs)
  */
 static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 {
-	struct thread_info *thread = current_thread_info();
 	struct task_struct *tsk = current;
 	sigset_t *oldset = sigmask_to_save();
 	int usig = ksig->sig;

commit 9699a517e0029c4dc34159787a26a746dfab858b
Author: Richard Weinberger <richard@nod.at>
Date:   Sun Jul 13 17:09:40 2014 +0200

    arm64: Remove signal translation and exec_domain
    
    As execution domain support is gone we can remove
    signal translation from the signal code and remove
    exec_domain from thread_info.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 660ccf9f7524..9f28eaa97123 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -293,12 +293,6 @@ static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	int usig = ksig->sig;
 	int ret;
 
-	/*
-	 * translate the signal
-	 */
-	if (usig < 32 && thread->exec_domain && thread->exec_domain->signal_invmap)
-		usig = thread->exec_domain->signal_invmap[usig];
-
 	/*
 	 * Set up the stack frame
 	 */

commit f56141e3e2d9aabf7e6b89680ab572c2cdbb2a24
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Feb 12 15:01:14 2015 -0800

    all arches, signal: move restart_block to struct task_struct
    
    If an attacker can cause a controlled kernel stack overflow, overwriting
    the restart block is a very juicy exploit target.  This is because the
    restart_block is held in the same memory allocation as the kernel stack.
    
    Moving the restart block to struct task_struct prevents this exploit by
    making the restart_block harder to locate.
    
    Note that there are other fields in thread_info that are also easy
    targets, at least on some architectures.
    
    It's also a decent simplification, since the restart code is more or less
    identical on all architectures.
    
    [james.hogan@imgtec.com: metag: align thread_info::supervisor_stack]
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: David Miller <davem@davemloft.net>
    Acked-by: Richard Weinberger <richard@nod.at>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Tested-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: James Hogan <james.hogan@imgtec.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 6fa792137eda..660ccf9f7524 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -131,7 +131,7 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	struct rt_sigframe __user *frame;
 
 	/* Always make any pending restarted system calls return -EINTR */
-	current_thread_info()->restart_block.fn = do_no_restart_syscall;
+	current->restart_block.fn = do_no_restart_syscall;
 
 	/*
 	 * Since we stacked the signal on a 128-bit boundary, then 'sp' should

commit 38a7be3c280bb9f9c4c892cf5ff51c847e959cf1
Author: Richard Weinberger <richard@nod.at>
Date:   Wed Mar 5 13:31:20 2014 +0100

    arm64: Use sigsp()
    
    Use sigsp() instead of the open coded variant.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index b29f5dab77ae..6fa792137eda 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -209,19 +209,13 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 	return err;
 }
 
-static struct rt_sigframe __user *get_sigframe(struct k_sigaction *ka,
+static struct rt_sigframe __user *get_sigframe(struct ksignal *ksig,
 					       struct pt_regs *regs)
 {
 	unsigned long sp, sp_top;
 	struct rt_sigframe __user *frame;
 
-	sp = sp_top = regs->sp;
-
-	/*
-	 * This is the X/Open sanctioned signal stack switching.
-	 */
-	if ((ka->sa.sa_flags & SA_ONSTACK) && !sas_ss_flags(sp))
-		sp = sp_top = current->sas_ss_sp + current->sas_ss_size;
+	sp = sp_top = sigsp(regs->sp, ksig);
 
 	sp = (sp - sizeof(struct rt_sigframe)) & ~15;
 	frame = (struct rt_sigframe __user *)sp;
@@ -259,7 +253,7 @@ static int setup_rt_frame(int usig, struct ksignal *ksig, sigset_t *set,
 	struct rt_sigframe __user *frame;
 	int err = 0;
 
-	frame = get_sigframe(&ksig->ka, regs);
+	frame = get_sigframe(ksig, regs);
 	if (!frame)
 		return 1;
 

commit 00554fa4f80279db92f82c4f52c8ae72711f173e
Author: Richard Weinberger <richard@nod.at>
Date:   Sun Oct 6 22:52:44 2013 +0200

    arm64: Use get_signal() signal_setup_done()
    
    Use the more generic functions get_signal() signal_setup_done()
    for signal delivery.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 6357b9c6c90e..b29f5dab77ae 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -253,13 +253,13 @@ static void setup_return(struct pt_regs *regs, struct k_sigaction *ka,
 	regs->regs[30] = (unsigned long)sigtramp;
 }
 
-static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
-			  sigset_t *set, struct pt_regs *regs)
+static int setup_rt_frame(int usig, struct ksignal *ksig, sigset_t *set,
+			  struct pt_regs *regs)
 {
 	struct rt_sigframe __user *frame;
 	int err = 0;
 
-	frame = get_sigframe(ka, regs);
+	frame = get_sigframe(&ksig->ka, regs);
 	if (!frame)
 		return 1;
 
@@ -269,9 +269,9 @@ static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
 	err |= __save_altstack(&frame->uc.uc_stack, regs->sp);
 	err |= setup_sigframe(frame, regs, set);
 	if (err == 0) {
-		setup_return(regs, ka, frame, usig);
-		if (ka->sa.sa_flags & SA_SIGINFO) {
-			err |= copy_siginfo_to_user(&frame->info, info);
+		setup_return(regs, &ksig->ka, frame, usig);
+		if (ksig->ka.sa.sa_flags & SA_SIGINFO) {
+			err |= copy_siginfo_to_user(&frame->info, &ksig->info);
 			regs->regs[1] = (unsigned long)&frame->info;
 			regs->regs[2] = (unsigned long)&frame->uc;
 		}
@@ -291,13 +291,12 @@ static void setup_restart_syscall(struct pt_regs *regs)
 /*
  * OK, we're invoking a handler
  */
-static void handle_signal(unsigned long sig, struct k_sigaction *ka,
-			  siginfo_t *info, struct pt_regs *regs)
+static void handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 {
 	struct thread_info *thread = current_thread_info();
 	struct task_struct *tsk = current;
 	sigset_t *oldset = sigmask_to_save();
-	int usig = sig;
+	int usig = ksig->sig;
 	int ret;
 
 	/*
@@ -310,13 +309,12 @@ static void handle_signal(unsigned long sig, struct k_sigaction *ka,
 	 * Set up the stack frame
 	 */
 	if (is_compat_task()) {
-		if (ka->sa.sa_flags & SA_SIGINFO)
-			ret = compat_setup_rt_frame(usig, ka, info, oldset,
-						    regs);
+		if (ksig->ka.sa.sa_flags & SA_SIGINFO)
+			ret = compat_setup_rt_frame(usig, ksig, oldset, regs);
 		else
-			ret = compat_setup_frame(usig, ka, oldset, regs);
+			ret = compat_setup_frame(usig, ksig, oldset, regs);
 	} else {
-		ret = setup_rt_frame(usig, ka, info, oldset, regs);
+		ret = setup_rt_frame(usig, ksig, oldset, regs);
 	}
 
 	/*
@@ -324,18 +322,14 @@ static void handle_signal(unsigned long sig, struct k_sigaction *ka,
 	 */
 	ret |= !valid_user_regs(&regs->user_regs);
 
-	if (ret != 0) {
-		force_sigsegv(sig, tsk);
-		return;
-	}
-
 	/*
 	 * Fast forward the stepping logic so we step into the signal
 	 * handler.
 	 */
-	user_fastforward_single_step(tsk);
+	if (!ret)
+		user_fastforward_single_step(tsk);
 
-	signal_delivered(sig, info, ka, regs, 0);
+	signal_setup_done(ret, ksig, 0);
 }
 
 /*
@@ -350,10 +344,9 @@ static void handle_signal(unsigned long sig, struct k_sigaction *ka,
 static void do_signal(struct pt_regs *regs)
 {
 	unsigned long continue_addr = 0, restart_addr = 0;
-	struct k_sigaction ka;
-	siginfo_t info;
-	int signr, retval = 0;
+	int retval = 0;
 	int syscall = (int)regs->syscallno;
+	struct ksignal ksig;
 
 	/*
 	 * If we were from a system call, check for system call restarting...
@@ -387,8 +380,7 @@ static void do_signal(struct pt_regs *regs)
 	 * Get the signal to deliver. When running under ptrace, at this point
 	 * the debugger may change all of our registers.
 	 */
-	signr = get_signal_to_deliver(&info, &ka, regs, NULL);
-	if (signr > 0) {
+	if (get_signal(&ksig)) {
 		/*
 		 * Depending on the signal settings, we may need to revert the
 		 * decision to restart the system call, but skip this if a
@@ -398,12 +390,12 @@ static void do_signal(struct pt_regs *regs)
 		    (retval == -ERESTARTNOHAND ||
 		     retval == -ERESTART_RESTARTBLOCK ||
 		     (retval == -ERESTARTSYS &&
-		      !(ka.sa.sa_flags & SA_RESTART)))) {
+		      !(ksig.ka.sa.sa_flags & SA_RESTART)))) {
 			regs->regs[0] = -EINTR;
 			regs->pc = continue_addr;
 		}
 
-		handle_signal(signr, &ka, &info, regs);
+		handle_signal(&ksig, regs);
 		return;
 	}
 

commit cf5c95db57ffa02e430c3840c08d1ee0403849d4
Merge: fd92d4a54a06 49788fe2a128
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri May 16 10:05:11 2014 +0100

    Merge tag 'for-3.16' of git://git.linaro.org/people/ard.biesheuvel/linux-arm into upstream
    
    FPSIMD register bank context switching and crypto algorithms
    optimisations for arm64 from Ard Biesheuvel.
    
    * tag 'for-3.16' of git://git.linaro.org/people/ard.biesheuvel/linux-arm:
      arm64/crypto: AES-ECB/CBC/CTR/XTS using ARMv8 NEON and Crypto Extensions
      arm64: pull in <asm/simd.h> from asm-generic
      arm64/crypto: AES in CCM mode using ARMv8 Crypto Extensions
      arm64/crypto: AES using ARMv8 Crypto Extensions
      arm64/crypto: GHASH secure hash using ARMv8 Crypto Extensions
      arm64/crypto: SHA-224/SHA-256 using ARMv8 Crypto Extensions
      arm64/crypto: SHA-1 using ARMv8 Crypto Extensions
      arm64: add support for kernel mode NEON in interrupt context
      arm64: defer reloading a task's FPSIMD state to userland resume
      arm64: add abstractions for FPSIMD state manipulation
      asm-generic: allow generic unaligned access if the arch supports it
    
    Conflicts:
            arch/arm64/include/asm/thread_info.h

commit fd92d4a54a069953b4679958121317f2a25389cd
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Wed Apr 30 10:51:32 2014 +0100

    arm64: is_compat_task is defined both in asm/compat.h and linux/compat.h
    
    Some kernel files may include both linux/compat.h and asm/compat.h directly
    or indirectly. Since both header files contain is_compat_task() under
    !CONFIG_COMPAT, compiling them with !CONFIG_COMPAT will eventually fail.
    Such files include kernel/auditsc.c, kernel/seccomp.c and init/do_mountfs.c
    (do_mountfs.c may read asm/compat.h via asm/ftrace.h once ftrace is
    implemented).
    
    So this patch proactively
    1) removes is_compat_task() under !CONFIG_COMPAT from asm/compat.h
    2) replaces asm/compat.h to linux/compat.h in kernel/*.c,
       but asm/compat.h is still necessary in ptrace.c and process.c because
       they use is_compat_thread().
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index dc2ab1b0ac0d..2ba72a11629f 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -17,6 +17,7 @@
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+#include <linux/compat.h>
 #include <linux/errno.h>
 #include <linux/signal.h>
 #include <linux/personality.h>
@@ -25,7 +26,6 @@
 #include <linux/tracehook.h>
 #include <linux/ratelimit.h>
 
-#include <asm/compat.h>
 #include <asm/debug-monitors.h>
 #include <asm/elf.h>
 #include <asm/cacheflush.h>

commit 15af1942dd61ee236a48b3de14d6f31c0b9e8116
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Sep 16 15:19:27 2013 +0100

    arm64: Expose ESR_EL1 information to user when SIGSEGV/SIGBUS
    
    This information is useful for instruction emulators to detect
    read/write and access size without having to decode the faulting
    instruction. The current patch exports it via sigcontext (struct
    esr_context) and is only valid for SIGSEGV and SIGBUS.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 7ff2eee96c6b..dc2ab1b0ac0d 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -194,6 +194,16 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 		aux += sizeof(*fpsimd_ctx);
 	}
 
+	/* fault information, if valid */
+	if (current->thread.fault_code) {
+		struct esr_context *esr_ctx =
+			container_of(aux, struct esr_context, head);
+		__put_user_error(ESR_MAGIC, &esr_ctx->head.magic, err);
+		__put_user_error(sizeof(*esr_ctx), &esr_ctx->head.size, err);
+		__put_user_error(current->thread.fault_code, &esr_ctx->esr, err);
+		aux += sizeof(*esr_ctx);
+	}
+
 	/* set the "end" magic */
 	end = aux;
 	__put_user_error(0, &end->magic, err);

commit 0e0276d1e1dd063cd14ce377707970d0417a0792
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Apr 4 15:42:16 2014 +0100

    arm64: Remove the aux_context structure
    
    This patch removes the aux_context structure (and the containing file)
    to allow the placement of the _aarch64_ctx end magic based on the
    context stored on the signal stack.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 890a591f75dd..7ff2eee96c6b 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -100,8 +100,7 @@ static int restore_sigframe(struct pt_regs *regs,
 {
 	sigset_t set;
 	int i, err;
-	struct aux_context __user *aux =
-		(struct aux_context __user *)sf->uc.uc_mcontext.__reserved;
+	void *aux = sf->uc.uc_mcontext.__reserved;
 
 	err = __copy_from_user(&set, &sf->uc.uc_sigmask, sizeof(set));
 	if (err == 0)
@@ -121,8 +120,11 @@ static int restore_sigframe(struct pt_regs *regs,
 
 	err |= !valid_user_regs(&regs->user_regs);
 
-	if (err == 0)
-		err |= restore_fpsimd_context(&aux->fpsimd);
+	if (err == 0) {
+		struct fpsimd_context *fpsimd_ctx =
+			container_of(aux, struct fpsimd_context, head);
+		err |= restore_fpsimd_context(fpsimd_ctx);
+	}
 
 	return err;
 }
@@ -167,8 +169,8 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 			  struct pt_regs *regs, sigset_t *set)
 {
 	int i, err = 0;
-	struct aux_context __user *aux =
-		(struct aux_context __user *)sf->uc.uc_mcontext.__reserved;
+	void *aux = sf->uc.uc_mcontext.__reserved;
+	struct _aarch64_ctx *end;
 
 	/* set up the stack frame for unwinding */
 	__put_user_error(regs->regs[29], &sf->fp, err);
@@ -185,12 +187,17 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 
 	err |= __copy_to_user(&sf->uc.uc_sigmask, set, sizeof(*set));
 
-	if (err == 0)
-		err |= preserve_fpsimd_context(&aux->fpsimd);
+	if (err == 0) {
+		struct fpsimd_context *fpsimd_ctx =
+			container_of(aux, struct fpsimd_context, head);
+		err |= preserve_fpsimd_context(fpsimd_ctx);
+		aux += sizeof(*fpsimd_ctx);
+	}
 
 	/* set the "end" magic */
-	__put_user_error(0, &aux->end.magic, err);
-	__put_user_error(0, &aux->end.size, err);
+	end = aux;
+	__put_user_error(0, &end->magic, err);
+	__put_user_error(0, &end->size, err);
 
 	return err;
 }

commit 005f78cd88494457ed38ce817f4e3fe5d372f0cb
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu May 8 11:20:23 2014 +0200

    arm64: defer reloading a task's FPSIMD state to userland resume
    
    If a task gets scheduled out and back in again and nothing has touched
    its FPSIMD state in the mean time, there is really no reason to reload
    it from memory. Similarly, repeated calls to kernel_neon_begin() and
    kernel_neon_end() will preserve and restore the FPSIMD state every time.
    
    This patch defers the FPSIMD state restore to the last possible moment,
    i.e., right before the task returns to userland. If a task does not return to
    userland at all (for any reason), the existing FPSIMD state is preserved
    and may be reused by the owning task if it gets scheduled in again on the
    same CPU.
    
    This patch adds two more functions to abstract away from straight FPSIMD
    register file saves and restores:
    - fpsimd_restore_current_state -> ensure current's FPSIMD state is loaded
    - fpsimd_flush_task_state -> invalidate live copies of a task's FPSIMD state
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 06448a77ff53..882f01774365 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -413,4 +413,8 @@ asmlinkage void do_notify_resume(struct pt_regs *regs,
 		clear_thread_flag(TIF_NOTIFY_RESUME);
 		tracehook_notify_resume(regs);
 	}
+
+	if (thread_flags & _TIF_FOREIGN_FPSTATE)
+		fpsimd_restore_current_state();
+
 }

commit c51f92693c35c141cf7d9b7e2fcbb81128324eb4
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Feb 24 15:26:27 2014 +0100

    arm64: add abstractions for FPSIMD state manipulation
    
    There are two tacit assumptions in the FPSIMD handling code that will no longer
    hold after the next patch that optimizes away some FPSIMD state restores:
    . the FPSIMD registers of this CPU contain the userland FPSIMD state of
      task 'current';
    . when switching to a task, its FPSIMD state will always be restored from
      memory.
    
    This patch adds the following functions to abstract away from straight FPSIMD
    register file saves and restores:
    - fpsimd_preserve_current_state -> ensure current's FPSIMD state is saved
    - fpsimd_update_current_state -> replace current's FPSIMD state
    
    Where necessary, the signal handling and fork code are updated to use the above
    wrappers instead of poking into the FPSIMD registers directly.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 890a591f75dd..06448a77ff53 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -51,7 +51,7 @@ static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
 	int err;
 
 	/* dump the hardware registers to the fpsimd_state structure */
-	fpsimd_save_state(fpsimd);
+	fpsimd_preserve_current_state();
 
 	/* copy the FP and status/control registers */
 	err = __copy_to_user(ctx->vregs, fpsimd->vregs, sizeof(fpsimd->vregs));
@@ -86,11 +86,8 @@ static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
 	__get_user_error(fpsimd.fpcr, &ctx->fpcr, err);
 
 	/* load the hardware registers from the fpsimd_state structure */
-	if (!err) {
-		preempt_disable();
-		fpsimd_load_state(&fpsimd);
-		preempt_enable();
-	}
+	if (!err)
+		fpsimd_update_current_state(&fpsimd);
 
 	return err ? -EFAULT : 0;
 }

commit 207bdae452e6d3eeba19cc3912e5dfb088adc376
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Dec 23 01:56:45 2012 -0500

    arm64: switch to generic sigaltstack
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index abd756315cb5..890a591f75dd 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -149,8 +149,7 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	if (restore_sigframe(regs, frame))
 		goto badframe;
 
-	if (do_sigaltstack(&frame->uc.uc_stack,
-			   NULL, regs->sp) == -EFAULT)
+	if (restore_altstack(&frame->uc.uc_stack))
 		goto badframe;
 
 	return regs->regs[0];
@@ -164,12 +163,6 @@ asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
 	return 0;
 }
 
-asmlinkage long sys_sigaltstack(const stack_t __user *uss, stack_t __user *uoss,
-				unsigned long sp)
-{
-	return do_sigaltstack(uss, uoss, sp);
-}
-
 static int setup_sigframe(struct rt_sigframe __user *sf,
 			  struct pt_regs *regs, sigset_t *set)
 {
@@ -250,7 +243,6 @@ static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
 			  sigset_t *set, struct pt_regs *regs)
 {
 	struct rt_sigframe __user *frame;
-	stack_t stack;
 	int err = 0;
 
 	frame = get_sigframe(ka, regs);
@@ -260,12 +252,7 @@ static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
 	__put_user_error(0, &frame->uc.uc_flags, err);
 	__put_user_error(NULL, &frame->uc.uc_link, err);
 
-	memset(&stack, 0, sizeof(stack));
-	stack.ss_sp = (void __user *)current->sas_ss_sp;
-	stack.ss_flags = sas_ss_flags(regs->sp);
-	stack.ss_size = current->sas_ss_size;
-	err |= __copy_to_user(&frame->uc.uc_stack, &stack, sizeof(stack));
-
+	err |= __save_altstack(&frame->uc.uc_stack, regs->sp);
 	err |= setup_sigframe(frame, regs, set);
 	if (err == 0) {
 		setup_return(regs, ka, frame, usig);

commit b64e1c6139c5007b7773b0ce416ef9ea035e8724
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Nov 23 11:01:04 2012 +0000

    arm64: signal: return struct rt_sigframe from get_sigframe
    
    We only have one type of frame (rt_sigframe) for arm64, so just return
    that type directly and dispense with the framesize argument, which is
    presumably a hangover from code copied from arch/arm/.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 051bb523ba2c..abd756315cb5 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -202,11 +202,11 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 	return err;
 }
 
-static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
-				 int framesize)
+static struct rt_sigframe __user *get_sigframe(struct k_sigaction *ka,
+					       struct pt_regs *regs)
 {
 	unsigned long sp, sp_top;
-	void __user *frame;
+	struct rt_sigframe __user *frame;
 
 	sp = sp_top = regs->sp;
 
@@ -216,8 +216,8 @@ static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
 	if ((ka->sa.sa_flags & SA_ONSTACK) && !sas_ss_flags(sp))
 		sp = sp_top = current->sas_ss_sp + current->sas_ss_size;
 
-	sp = (sp - framesize) & ~15;
-	frame = (void __user *)sp;
+	sp = (sp - sizeof(struct rt_sigframe)) & ~15;
+	frame = (struct rt_sigframe __user *)sp;
 
 	/*
 	 * Check that we can actually write to the signal frame.
@@ -253,7 +253,7 @@ static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
 	stack_t stack;
 	int err = 0;
 
-	frame = get_sigframe(ka, regs, sizeof(*frame));
+	frame = get_sigframe(ka, regs);
 	if (!frame)
 		return 1;
 

commit 304ef4e8367244b547734143c792a2ab764831e8
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Nov 23 12:34:13 2012 +0000

    arm64: signal: push the unwinding prologue on the signal stack
    
    To allow debuggers to unwind through signal frames, we create a fake
    stack unwinding prologue containing the link register and frame pointer
    of the interrupted context. The signal frame is then offset by 16 bytes
    to make room for the two saved registers which are pushed onto the frame
    of the *interrupted* context, rather than placed directly above the
    signal stack.
    
    This doesn't work when an alternative signal stack is set up for a SEGV
    handler, which is raised in response to RLIMIT_STACK being reached. In
    this case, we try to push the unwinding prologue onto the full stack and
    subsequently take a fault which we fail to resolve, causing setup_return
    to return -EFAULT and handle_signal to force_sigsegv on the current task.
    
    This patch fixes the problem by including the unwinding prologue as part
    of the rt_sigframe definition, which is populated during setup_sigframe,
    ensuring that it always ends up on the signal stack.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: <stable@vger.kernel.org>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
index 8807ba2cf262..051bb523ba2c 100644
--- a/arch/arm64/kernel/signal.c
+++ b/arch/arm64/kernel/signal.c
@@ -41,6 +41,8 @@
 struct rt_sigframe {
 	struct siginfo info;
 	struct ucontext uc;
+	u64 fp;
+	u64 lr;
 };
 
 static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
@@ -175,6 +177,10 @@ static int setup_sigframe(struct rt_sigframe __user *sf,
 	struct aux_context __user *aux =
 		(struct aux_context __user *)sf->uc.uc_mcontext.__reserved;
 
+	/* set up the stack frame for unwinding */
+	__put_user_error(regs->regs[29], &sf->fp, err);
+	__put_user_error(regs->regs[30], &sf->lr, err);
+
 	for (i = 0; i < 31; i++)
 		__put_user_error(regs->regs[i], &sf->uc.uc_mcontext.regs[i],
 				 err);
@@ -210,9 +216,6 @@ static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
 	if ((ka->sa.sa_flags & SA_ONSTACK) && !sas_ss_flags(sp))
 		sp = sp_top = current->sas_ss_sp + current->sas_ss_size;
 
-	/* room for stack frame (FP, LR) */
-	sp -= 16;
-
 	sp = (sp - framesize) & ~15;
 	frame = (void __user *)sp;
 
@@ -225,20 +228,14 @@ static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
 	return frame;
 }
 
-static int setup_return(struct pt_regs *regs, struct k_sigaction *ka,
-			void __user *frame, int usig)
+static void setup_return(struct pt_regs *regs, struct k_sigaction *ka,
+			 void __user *frame, int usig)
 {
-	int err = 0;
 	__sigrestore_t sigtramp;
-	unsigned long __user *sp = (unsigned long __user *)regs->sp;
-
-	/* set up the stack frame */
-	__put_user_error(regs->regs[29], sp - 2, err);
-	__put_user_error(regs->regs[30], sp - 1, err);
 
 	regs->regs[0] = usig;
-	regs->regs[29] = regs->sp - 16;
 	regs->sp = (unsigned long)frame;
+	regs->regs[29] = regs->sp + offsetof(struct rt_sigframe, fp);
 	regs->pc = (unsigned long)ka->sa.sa_handler;
 
 	if (ka->sa.sa_flags & SA_RESTORER)
@@ -247,8 +244,6 @@ static int setup_return(struct pt_regs *regs, struct k_sigaction *ka,
 		sigtramp = VDSO_SYMBOL(current->mm->context.vdso, sigtramp);
 
 	regs->regs[30] = (unsigned long)sigtramp;
-
-	return err;
 }
 
 static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
@@ -272,13 +267,13 @@ static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
 	err |= __copy_to_user(&frame->uc.uc_stack, &stack, sizeof(stack));
 
 	err |= setup_sigframe(frame, regs, set);
-	if (err == 0)
-		err = setup_return(regs, ka, frame, usig);
-
-	if (err == 0 && ka->sa.sa_flags & SA_SIGINFO) {
-		err |= copy_siginfo_to_user(&frame->info, info);
-		regs->regs[1] = (unsigned long)&frame->info;
-		regs->regs[2] = (unsigned long)&frame->uc;
+	if (err == 0) {
+		setup_return(regs, ka, frame, usig);
+		if (ka->sa.sa_flags & SA_SIGINFO) {
+			err |= copy_siginfo_to_user(&frame->info, info);
+			regs->regs[1] = (unsigned long)&frame->info;
+			regs->regs[2] = (unsigned long)&frame->uc;
+		}
 	}
 
 	return err;

commit 2c020ed8d148f7562c01abaf875c9bbfb9a40a83
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Mar 5 11:49:31 2012 +0000

    arm64: Signal handling support
    
    This patch adds support for signal handling. The sigreturn is done via
    VDSO, introduced by a previous patch. The SA_RESTORER is still defined
    as it is required for 32-bit (compat) support but it is not to be used
    for 64-bit applications.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm64/kernel/signal.c b/arch/arm64/kernel/signal.c
new file mode 100644
index 000000000000..8807ba2cf262
--- /dev/null
+++ b/arch/arm64/kernel/signal.c
@@ -0,0 +1,437 @@
+/*
+ * Based on arch/arm/kernel/signal.c
+ *
+ * Copyright (C) 1995-2009 Russell King
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/personality.h>
+#include <linux/freezer.h>
+#include <linux/uaccess.h>
+#include <linux/tracehook.h>
+#include <linux/ratelimit.h>
+
+#include <asm/compat.h>
+#include <asm/debug-monitors.h>
+#include <asm/elf.h>
+#include <asm/cacheflush.h>
+#include <asm/ucontext.h>
+#include <asm/unistd.h>
+#include <asm/fpsimd.h>
+#include <asm/signal32.h>
+#include <asm/vdso.h>
+
+/*
+ * Do a signal return; undo the signal stack. These are aligned to 128-bit.
+ */
+struct rt_sigframe {
+	struct siginfo info;
+	struct ucontext uc;
+};
+
+static int preserve_fpsimd_context(struct fpsimd_context __user *ctx)
+{
+	struct fpsimd_state *fpsimd = &current->thread.fpsimd_state;
+	int err;
+
+	/* dump the hardware registers to the fpsimd_state structure */
+	fpsimd_save_state(fpsimd);
+
+	/* copy the FP and status/control registers */
+	err = __copy_to_user(ctx->vregs, fpsimd->vregs, sizeof(fpsimd->vregs));
+	__put_user_error(fpsimd->fpsr, &ctx->fpsr, err);
+	__put_user_error(fpsimd->fpcr, &ctx->fpcr, err);
+
+	/* copy the magic/size information */
+	__put_user_error(FPSIMD_MAGIC, &ctx->head.magic, err);
+	__put_user_error(sizeof(struct fpsimd_context), &ctx->head.size, err);
+
+	return err ? -EFAULT : 0;
+}
+
+static int restore_fpsimd_context(struct fpsimd_context __user *ctx)
+{
+	struct fpsimd_state fpsimd;
+	__u32 magic, size;
+	int err = 0;
+
+	/* check the magic/size information */
+	__get_user_error(magic, &ctx->head.magic, err);
+	__get_user_error(size, &ctx->head.size, err);
+	if (err)
+		return -EFAULT;
+	if (magic != FPSIMD_MAGIC || size != sizeof(struct fpsimd_context))
+		return -EINVAL;
+
+	/* copy the FP and status/control registers */
+	err = __copy_from_user(fpsimd.vregs, ctx->vregs,
+			       sizeof(fpsimd.vregs));
+	__get_user_error(fpsimd.fpsr, &ctx->fpsr, err);
+	__get_user_error(fpsimd.fpcr, &ctx->fpcr, err);
+
+	/* load the hardware registers from the fpsimd_state structure */
+	if (!err) {
+		preempt_disable();
+		fpsimd_load_state(&fpsimd);
+		preempt_enable();
+	}
+
+	return err ? -EFAULT : 0;
+}
+
+static int restore_sigframe(struct pt_regs *regs,
+			    struct rt_sigframe __user *sf)
+{
+	sigset_t set;
+	int i, err;
+	struct aux_context __user *aux =
+		(struct aux_context __user *)sf->uc.uc_mcontext.__reserved;
+
+	err = __copy_from_user(&set, &sf->uc.uc_sigmask, sizeof(set));
+	if (err == 0)
+		set_current_blocked(&set);
+
+	for (i = 0; i < 31; i++)
+		__get_user_error(regs->regs[i], &sf->uc.uc_mcontext.regs[i],
+				 err);
+	__get_user_error(regs->sp, &sf->uc.uc_mcontext.sp, err);
+	__get_user_error(regs->pc, &sf->uc.uc_mcontext.pc, err);
+	__get_user_error(regs->pstate, &sf->uc.uc_mcontext.pstate, err);
+
+	/*
+	 * Avoid sys_rt_sigreturn() restarting.
+	 */
+	regs->syscallno = ~0UL;
+
+	err |= !valid_user_regs(&regs->user_regs);
+
+	if (err == 0)
+		err |= restore_fpsimd_context(&aux->fpsimd);
+
+	return err;
+}
+
+asmlinkage long sys_rt_sigreturn(struct pt_regs *regs)
+{
+	struct rt_sigframe __user *frame;
+
+	/* Always make any pending restarted system calls return -EINTR */
+	current_thread_info()->restart_block.fn = do_no_restart_syscall;
+
+	/*
+	 * Since we stacked the signal on a 128-bit boundary, then 'sp' should
+	 * be word aligned here.
+	 */
+	if (regs->sp & 15)
+		goto badframe;
+
+	frame = (struct rt_sigframe __user *)regs->sp;
+
+	if (!access_ok(VERIFY_READ, frame, sizeof (*frame)))
+		goto badframe;
+
+	if (restore_sigframe(regs, frame))
+		goto badframe;
+
+	if (do_sigaltstack(&frame->uc.uc_stack,
+			   NULL, regs->sp) == -EFAULT)
+		goto badframe;
+
+	return regs->regs[0];
+
+badframe:
+	if (show_unhandled_signals)
+		pr_info_ratelimited("%s[%d]: bad frame in %s: pc=%08llx sp=%08llx\n",
+				    current->comm, task_pid_nr(current), __func__,
+				    regs->pc, regs->sp);
+	force_sig(SIGSEGV, current);
+	return 0;
+}
+
+asmlinkage long sys_sigaltstack(const stack_t __user *uss, stack_t __user *uoss,
+				unsigned long sp)
+{
+	return do_sigaltstack(uss, uoss, sp);
+}
+
+static int setup_sigframe(struct rt_sigframe __user *sf,
+			  struct pt_regs *regs, sigset_t *set)
+{
+	int i, err = 0;
+	struct aux_context __user *aux =
+		(struct aux_context __user *)sf->uc.uc_mcontext.__reserved;
+
+	for (i = 0; i < 31; i++)
+		__put_user_error(regs->regs[i], &sf->uc.uc_mcontext.regs[i],
+				 err);
+	__put_user_error(regs->sp, &sf->uc.uc_mcontext.sp, err);
+	__put_user_error(regs->pc, &sf->uc.uc_mcontext.pc, err);
+	__put_user_error(regs->pstate, &sf->uc.uc_mcontext.pstate, err);
+
+	__put_user_error(current->thread.fault_address, &sf->uc.uc_mcontext.fault_address, err);
+
+	err |= __copy_to_user(&sf->uc.uc_sigmask, set, sizeof(*set));
+
+	if (err == 0)
+		err |= preserve_fpsimd_context(&aux->fpsimd);
+
+	/* set the "end" magic */
+	__put_user_error(0, &aux->end.magic, err);
+	__put_user_error(0, &aux->end.size, err);
+
+	return err;
+}
+
+static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
+				 int framesize)
+{
+	unsigned long sp, sp_top;
+	void __user *frame;
+
+	sp = sp_top = regs->sp;
+
+	/*
+	 * This is the X/Open sanctioned signal stack switching.
+	 */
+	if ((ka->sa.sa_flags & SA_ONSTACK) && !sas_ss_flags(sp))
+		sp = sp_top = current->sas_ss_sp + current->sas_ss_size;
+
+	/* room for stack frame (FP, LR) */
+	sp -= 16;
+
+	sp = (sp - framesize) & ~15;
+	frame = (void __user *)sp;
+
+	/*
+	 * Check that we can actually write to the signal frame.
+	 */
+	if (!access_ok(VERIFY_WRITE, frame, sp_top - sp))
+		frame = NULL;
+
+	return frame;
+}
+
+static int setup_return(struct pt_regs *regs, struct k_sigaction *ka,
+			void __user *frame, int usig)
+{
+	int err = 0;
+	__sigrestore_t sigtramp;
+	unsigned long __user *sp = (unsigned long __user *)regs->sp;
+
+	/* set up the stack frame */
+	__put_user_error(regs->regs[29], sp - 2, err);
+	__put_user_error(regs->regs[30], sp - 1, err);
+
+	regs->regs[0] = usig;
+	regs->regs[29] = regs->sp - 16;
+	regs->sp = (unsigned long)frame;
+	regs->pc = (unsigned long)ka->sa.sa_handler;
+
+	if (ka->sa.sa_flags & SA_RESTORER)
+		sigtramp = ka->sa.sa_restorer;
+	else
+		sigtramp = VDSO_SYMBOL(current->mm->context.vdso, sigtramp);
+
+	regs->regs[30] = (unsigned long)sigtramp;
+
+	return err;
+}
+
+static int setup_rt_frame(int usig, struct k_sigaction *ka, siginfo_t *info,
+			  sigset_t *set, struct pt_regs *regs)
+{
+	struct rt_sigframe __user *frame;
+	stack_t stack;
+	int err = 0;
+
+	frame = get_sigframe(ka, regs, sizeof(*frame));
+	if (!frame)
+		return 1;
+
+	__put_user_error(0, &frame->uc.uc_flags, err);
+	__put_user_error(NULL, &frame->uc.uc_link, err);
+
+	memset(&stack, 0, sizeof(stack));
+	stack.ss_sp = (void __user *)current->sas_ss_sp;
+	stack.ss_flags = sas_ss_flags(regs->sp);
+	stack.ss_size = current->sas_ss_size;
+	err |= __copy_to_user(&frame->uc.uc_stack, &stack, sizeof(stack));
+
+	err |= setup_sigframe(frame, regs, set);
+	if (err == 0)
+		err = setup_return(regs, ka, frame, usig);
+
+	if (err == 0 && ka->sa.sa_flags & SA_SIGINFO) {
+		err |= copy_siginfo_to_user(&frame->info, info);
+		regs->regs[1] = (unsigned long)&frame->info;
+		regs->regs[2] = (unsigned long)&frame->uc;
+	}
+
+	return err;
+}
+
+static void setup_restart_syscall(struct pt_regs *regs)
+{
+	if (is_compat_task())
+		compat_setup_restart_syscall(regs);
+	else
+		regs->regs[8] = __NR_restart_syscall;
+}
+
+/*
+ * OK, we're invoking a handler
+ */
+static void handle_signal(unsigned long sig, struct k_sigaction *ka,
+			  siginfo_t *info, struct pt_regs *regs)
+{
+	struct thread_info *thread = current_thread_info();
+	struct task_struct *tsk = current;
+	sigset_t *oldset = sigmask_to_save();
+	int usig = sig;
+	int ret;
+
+	/*
+	 * translate the signal
+	 */
+	if (usig < 32 && thread->exec_domain && thread->exec_domain->signal_invmap)
+		usig = thread->exec_domain->signal_invmap[usig];
+
+	/*
+	 * Set up the stack frame
+	 */
+	if (is_compat_task()) {
+		if (ka->sa.sa_flags & SA_SIGINFO)
+			ret = compat_setup_rt_frame(usig, ka, info, oldset,
+						    regs);
+		else
+			ret = compat_setup_frame(usig, ka, oldset, regs);
+	} else {
+		ret = setup_rt_frame(usig, ka, info, oldset, regs);
+	}
+
+	/*
+	 * Check that the resulting registers are actually sane.
+	 */
+	ret |= !valid_user_regs(&regs->user_regs);
+
+	if (ret != 0) {
+		force_sigsegv(sig, tsk);
+		return;
+	}
+
+	/*
+	 * Fast forward the stepping logic so we step into the signal
+	 * handler.
+	 */
+	user_fastforward_single_step(tsk);
+
+	signal_delivered(sig, info, ka, regs, 0);
+}
+
+/*
+ * Note that 'init' is a special process: it doesn't get signals it doesn't
+ * want to handle. Thus you cannot kill init even with a SIGKILL even by
+ * mistake.
+ *
+ * Note that we go through the signals twice: once to check the signals that
+ * the kernel can handle, and then we build all the user-level signal handling
+ * stack-frames in one go after that.
+ */
+static void do_signal(struct pt_regs *regs)
+{
+	unsigned long continue_addr = 0, restart_addr = 0;
+	struct k_sigaction ka;
+	siginfo_t info;
+	int signr, retval = 0;
+	int syscall = (int)regs->syscallno;
+
+	/*
+	 * If we were from a system call, check for system call restarting...
+	 */
+	if (syscall >= 0) {
+		continue_addr = regs->pc;
+		restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
+		retval = regs->regs[0];
+
+		/*
+		 * Avoid additional syscall restarting via ret_to_user.
+		 */
+		regs->syscallno = ~0UL;
+
+		/*
+		 * Prepare for system call restart. We do this here so that a
+		 * debugger will see the already changed PC.
+		 */
+		switch (retval) {
+		case -ERESTARTNOHAND:
+		case -ERESTARTSYS:
+		case -ERESTARTNOINTR:
+		case -ERESTART_RESTARTBLOCK:
+			regs->regs[0] = regs->orig_x0;
+			regs->pc = restart_addr;
+			break;
+		}
+	}
+
+	/*
+	 * Get the signal to deliver. When running under ptrace, at this point
+	 * the debugger may change all of our registers.
+	 */
+	signr = get_signal_to_deliver(&info, &ka, regs, NULL);
+	if (signr > 0) {
+		/*
+		 * Depending on the signal settings, we may need to revert the
+		 * decision to restart the system call, but skip this if a
+		 * debugger has chosen to restart at a different PC.
+		 */
+		if (regs->pc == restart_addr &&
+		    (retval == -ERESTARTNOHAND ||
+		     retval == -ERESTART_RESTARTBLOCK ||
+		     (retval == -ERESTARTSYS &&
+		      !(ka.sa.sa_flags & SA_RESTART)))) {
+			regs->regs[0] = -EINTR;
+			regs->pc = continue_addr;
+		}
+
+		handle_signal(signr, &ka, &info, regs);
+		return;
+	}
+
+	/*
+	 * Handle restarting a different system call. As above, if a debugger
+	 * has chosen to restart at a different PC, ignore the restart.
+	 */
+	if (syscall >= 0 && regs->pc == restart_addr) {
+		if (retval == -ERESTART_RESTARTBLOCK)
+			setup_restart_syscall(regs);
+		user_rewind_single_step(current);
+	}
+
+	restore_saved_sigmask();
+}
+
+asmlinkage void do_notify_resume(struct pt_regs *regs,
+				 unsigned int thread_flags)
+{
+	if (thread_flags & _TIF_SIGPENDING)
+		do_signal(regs);
+
+	if (thread_flags & _TIF_NOTIFY_RESUME) {
+		clear_thread_flag(TIF_NOTIFY_RESUME);
+		tracehook_notify_resume(regs);
+	}
+}
