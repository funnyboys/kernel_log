commit dd4bc60765873445893037ae73a5f75398a8cd19
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Thu Jun 11 14:43:30 2020 +0200

    arm64: warn on incorrect placement of the kernel by the bootloader
    
    Commit cfa7ede20f133c ("arm64: set TEXT_OFFSET to 0x0 in preparation for
    removing it entirely") results in boot failures when booting kernels that
    are built without KASLR support on broken bootloaders that ignore the
    TEXT_OFFSET value passed via the header, and use the default of 0x80000
    instead.
    
    To work around this, turn CONFIG_RELOCATABLE on by default, even if KASLR
    itself (CONFIG_RANDOMIZE_BASE) is turned off, and require CONFIG_EXPERT
    to be enabled to deviate from this. Then, emit a warning into the kernel
    log if we are not booting via the EFI stub (which is permitted to deviate
    from the placement restrictions) and the kernel base address is not placed
    according to the rules as laid out in Documentation/arm64/booting.rst.
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Link: https://lore.kernel.org/r/20200611124330.252163-1-ardb@kernel.org
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3fd2c11c09fc..93b3844cf442 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -319,6 +319,10 @@ void __init setup_arch(char **cmdline_p)
 
 	xen_early_init();
 	efi_init();
+
+	if (!efi_enabled(EFI_BOOT) && ((u64)_text % MIN_KIMG_ALIGN) != 0)
+	     pr_warn(FW_BUG "Kernel image misaligned at boot, please fix your bootloader!");
+
 	arm64_memblock_init();
 
 	paging_init();

commit de58ed5e16e62f36c7ed05552f18b7f9c647dcaf
Author: Gavin Shan <gshan@redhat.com>
Date:   Thu Mar 19 10:01:44 2020 +1100

    arm64: Introduce get_cpu_ops() helper function
    
    This introduces get_cpu_ops() to return the CPU operations according to
    the given CPU index. For now, it simply returns the @cpu_ops[cpu] as
    before. Also, helper function __cpu_try_die() is introduced to be shared
    by cpu_die() and ipi_cpu_crash_stop(). So it shouldn't introduce any
    functional changes.
    
    Signed-off-by: Gavin Shan <gshan@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f66bd260cce8..3fd2c11c09fc 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -371,8 +371,10 @@ void __init setup_arch(char **cmdline_p)
 static inline bool cpu_can_disable(unsigned int cpu)
 {
 #ifdef CONFIG_HOTPLUG_CPU
-	if (cpu_ops[cpu] && cpu_ops[cpu]->cpu_can_disable)
-		return cpu_ops[cpu]->cpu_can_disable(cpu);
+	const struct cpu_operations *ops = get_cpu_ops(cpu);
+
+	if (ops && ops->cpu_can_disable)
+		return ops->cpu_can_disable(cpu);
 #endif
 	return false;
 }

commit 6885fb129be30c627eb2f5b1498dba498ff6c037
Author: Gavin Shan <gshan@redhat.com>
Date:   Thu Mar 19 10:01:43 2020 +1100

    arm64: Rename cpu_read_ops() to init_cpu_ops()
    
    This renames cpu_read_ops() to init_cpu_ops() as the function is only
    called in initialization phase. Also, we will introduce get_cpu_ops() in
    the subsequent patches, to retireve the CPU operation by the given CPU
    index. The usage of cpu_read_ops() and get_cpu_ops() are difficult to be
    distinguished from their names.
    
    Signed-off-by: Gavin Shan <gshan@redhat.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index a34890bf309f..f66bd260cce8 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -344,7 +344,7 @@ void __init setup_arch(char **cmdline_p)
 	else
 		psci_acpi_init();
 
-	cpu_read_bootcpu_ops();
+	init_bootcpu_ops();
 	smp_init_cpus();
 	smp_build_mpidr_hash();
 

commit ca9b5b6283984f67434cee810f3b08e19630226d
Merge: aac96626713f 85f4c95172d6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 29 10:13:27 2020 -0800

    Merge tag 'tty-5.6-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty
    
    Pull tty/serial driver updates from Greg KH:
     "Here are the big set of tty and serial driver updates for 5.6-rc1
    
      Included in here are:
       - dummy_con cleanups (touches lots of arch code)
       - sysrq logic cleanups (touches lots of serial drivers)
       - samsung driver fixes (wasn't really being built)
       - conmakeshash move to tty subdir out of scripts
       - lots of small tty/serial driver updates
    
      All of these have been in linux-next for a while with no reported
      issues"
    
    * tag 'tty-5.6-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty: (140 commits)
      tty: n_hdlc: Use flexible-array member and struct_size() helper
      tty: baudrate: SPARC supports few more baud rates
      tty: baudrate: Synchronise baud_table[] and baud_bits[]
      tty: serial: meson_uart: Add support for kernel debugger
      serial: imx: fix a race condition in receive path
      serial: 8250_bcm2835aux: Document struct bcm2835aux_data
      serial: 8250_bcm2835aux: Use generic remapping code
      serial: 8250_bcm2835aux: Allocate uart_8250_port on stack
      serial: 8250_bcm2835aux: Suppress register_port error on -EPROBE_DEFER
      serial: 8250_bcm2835aux: Suppress clk_get error on -EPROBE_DEFER
      serial: 8250_bcm2835aux: Fix line mismatch on driver unbind
      serial_core: Remove unused member in uart_port
      vt: Correct comment documenting do_take_over_console()
      vt: Delete comment referencing non-existent unbind_con_driver()
      arch/xtensa/setup: Drop dummy_con initialization
      arch/x86/setup: Drop dummy_con initialization
      arch/unicore32/setup: Drop dummy_con initialization
      arch/sparc/setup: Drop dummy_con initialization
      arch/sh/setup: Drop dummy_con initialization
      arch/s390/setup: Drop dummy_con initialization
      ...

commit 09e3c22a86f6889db0e93fb29d9255081a126f64
Author: Mark Brown <broonie@kernel.org>
Date:   Mon Dec 9 18:12:17 2019 +0000

    arm64: Use a variable to store non-global mappings decision
    
    Refactor the code which checks to see if we need to use non-global
    mappings to use a variable instead of checking with the CPU capabilities
    each time, doing the initial check for KPTI early in boot before we
    start allocating memory so we still avoid transitioning to non-global
    mappings in common cases.
    
    Since this variable always matches our decision about non-global
    mappings this means we can also combine arm64_kernel_use_ng_mappings()
    and arm64_unmap_kernel_at_el0() into a single function, the variable
    simply stores the result and the decision code is elsewhere. We could
    just have the users check the variable directly but having a function
    makes it clear that these uses are read-only.
    
    The result is that we simplify the code a bit and reduces the amount of
    code executed at runtime.
    
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 56f664561754..b6f9455d7ca3 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -285,6 +285,13 @@ void __init setup_arch(char **cmdline_p)
 
 	*cmdline_p = boot_command_line;
 
+	/*
+	 * If know now we are going to need KPTI then use non-global
+	 * mappings from the start, avoiding the cost of rewriting
+	 * everything later.
+	 */
+	arm64_use_ng_mappings = kaslr_requires_kpti();
+
 	early_fixmap_init();
 	early_ioremap_init();
 

commit 46cbe2f39976197a11da2abf27883530f3d0ddc2
Author: Arvind Sankar <nivedita@alum.mit.edu>
Date:   Wed Dec 18 16:44:48 2019 -0500

    arch/arm64/setup: Drop dummy_con initialization
    
    con_init in tty/vt.c will now set conswitchp to dummy_con if it's unset.
    Drop it from arch setup code.
    
    Signed-off-by: Arvind Sankar <nivedita@alum.mit.edu>
    Link: https://lore.kernel.org/r/20191218214506.49252-7-nivedita@alum.mit.edu
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 56f664561754..2a86676b693a 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -353,9 +353,6 @@ void __init setup_arch(char **cmdline_p)
 	init_task.thread_info.ttbr0 = __pa_symbol(empty_zero_page);
 #endif
 
-#ifdef CONFIG_VT
-	conswitchp = &dummy_con;
-#endif
 	if (boot_args[1] || boot_args[2] || boot_args[3]) {
 		pr_err("WARNING: x1-x3 nonzero in violation of boot protocol:\n"
 			"\tx1: %016llx\n\tx2: %016llx\n\tx3: %016llx\n"

commit ac12cf85d682a2c1948210c65f7fb21ef01dd9f6
Merge: f32c7a8e4510 b333b0ba2346 d06fa5a118f1 42d038c4fb00 3724e186fead d55c5f28afaf dd753d961c48 ebef746543fd 92af2b696119 5c062ef4155b
Author: Will Deacon <will@kernel.org>
Date:   Fri Aug 30 12:46:12 2019 +0100

    Merge branches 'for-next/52-bit-kva', 'for-next/cpu-topology', 'for-next/error-injection', 'for-next/perf', 'for-next/psci-cpuidle', 'for-next/rng', 'for-next/smpboot', 'for-next/tbi' and 'for-next/tlbi' into for-next/core
    
    * for-next/52-bit-kva: (25 commits)
      Support for 52-bit virtual addressing in kernel space
    
    * for-next/cpu-topology: (9 commits)
      Move CPU topology parsing into core code and add support for ACPI 6.3
    
    * for-next/error-injection: (2 commits)
      Support for function error injection via kprobes
    
    * for-next/perf: (8 commits)
      Support for i.MX8 DDR PMU and proper SMMUv3 group validation
    
    * for-next/psci-cpuidle: (7 commits)
      Move PSCI idle code into a new CPUidle driver
    
    * for-next/rng: (4 commits)
      Support for 'rng-seed' property being passed in the devicetree
    
    * for-next/smpboot: (3 commits)
      Reduce fragility of secondary CPU bringup in debug configurations
    
    * for-next/tbi: (10 commits)
      Introduce new syscall ABI with relaxed requirements for pointer tags
    
    * for-next/tlbi: (6 commits)
      Handle spurious page faults arising from kernel space

commit e112b032a72c78f15d0c803c5dc6be444c2e6c66
Author: Hsin-Yi Wang <hsinyi@chromium.org>
Date:   Fri Aug 23 14:24:50 2019 +0800

    arm64: map FDT as RW for early_init_dt_scan()
    
    Currently in arm64, FDT is mapped to RO before it's passed to
    early_init_dt_scan(). However, there might be some codes
    (eg. commit "fdt: add support for rng-seed") that need to modify FDT
    during init. Map FDT to RO after early fixups are done.
    
    Signed-off-by: Hsin-Yi Wang <hsinyi@chromium.org>
    Reviewed-by: Stephen Boyd <swboyd@chromium.org>
    Reviewed-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 9c4bad7d7131..25f5127210f8 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -170,9 +170,13 @@ static void __init smp_build_mpidr_hash(void)
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
-	void *dt_virt = fixmap_remap_fdt(dt_phys);
+	int size;
+	void *dt_virt = fixmap_remap_fdt(dt_phys, &size, PAGE_KERNEL);
 	const char *name;
 
+	if (dt_virt)
+		memblock_reserve(dt_phys, size);
+
 	if (!dt_virt || !early_init_dt_scan(dt_virt)) {
 		pr_crit("\n"
 			"Error: invalid device tree blob at physical address %pa (virtual address 0x%p)\n"
@@ -184,6 +188,9 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 			cpu_relax();
 	}
 
+	/* Early fixups are done, map the FDT as read-only now */
+	fixmap_remap_fdt(dt_phys, &size, PAGE_KERNEL_RO);
+
 	name = of_flat_dt_get_machine_name();
 	if (!name)
 		return;

commit d55c5f28afafb6b1f0a6978916b23338b383faab
Author: Sudeep Holla <sudeep.holla@arm.com>
Date:   Wed Jun 12 13:51:37 2019 +0100

    arm64: smp: disable hotplug on trusted OS resident CPU
    
    The trusted OS may reject CPU_OFF calls to its resident CPU, so we must
    avoid issuing those. We never migrate a Trusted OS and we already take
    care to prevent CPU_OFF PSCI call. However, this is not reflected
    explicitly to the userspace. Any user can attempt to hotplug trusted OS
    resident CPU. The entire motion of going through the various state
    transitions in the CPU hotplug state machine gets executed and the
    PSCI layer finally refuses to make CPU_OFF call.
    
    This results is unnecessary unwinding of CPU hotplug state machine in
    the kernel. Instead we can mark the trusted OS resident CPU as not
    available for hotplug, so that the user attempt or request to do the
    same will get immediately rejected.
    
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 9c4bad7d7131..57ff38600828 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -357,6 +357,15 @@ void __init setup_arch(char **cmdline_p)
 	}
 }
 
+static inline bool cpu_can_disable(unsigned int cpu)
+{
+#ifdef CONFIG_HOTPLUG_CPU
+	if (cpu_ops[cpu] && cpu_ops[cpu]->cpu_can_disable)
+		return cpu_ops[cpu]->cpu_can_disable(cpu);
+#endif
+	return false;
+}
+
 static int __init topology_init(void)
 {
 	int i;
@@ -366,7 +375,7 @@ static int __init topology_init(void)
 
 	for_each_possible_cpu(i) {
 		struct cpu *cpu = &per_cpu(cpu_data.cpu, i);
-		cpu->hotpluggable = 1;
+		cpu->hotpluggable = cpu_can_disable(i);
 		register_cpu(cpu, i);
 	}
 

commit ba5c5e4a5da443e80a3722e67515de5e37375b18
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jul 11 20:59:15 2019 -0700

    arm64: move jump_label_init() before parse_early_param()
    
    While jump_label_init() was moved earlier in the boot process in
    efd9e03facd0 ("arm64: Use static keys for CPU features"), it wasn't early
    enough for early params to use it.  The old state of things was as
    described here...
    
    init/main.c calls out to arch-specific things before general jump label
    and early param handling:
    
      asmlinkage __visible void __init start_kernel(void)
      {
            ...
            setup_arch(&command_line);
            ...
            smp_prepare_boot_cpu();
            ...
            /* parameters may set static keys */
            jump_label_init();
            parse_early_param();
            ...
      }
    
    x86 setup_arch() wants those earlier, so it handles jump label and
    early param:
    
      void __init setup_arch(char **cmdline_p)
      {
            ...
            jump_label_init();
            ...
            parse_early_param();
            ...
      }
    
    arm64 setup_arch() only had early param:
    
      void __init setup_arch(char **cmdline_p)
      {
            ...
            parse_early_param();
            ...
    }
    
    with jump label later in smp_prepare_boot_cpu():
    
      void __init smp_prepare_boot_cpu(void)
      {
            ...
            jump_label_init();
            ...
      }
    
    This moves arm64 jump_label_init() from smp_prepare_boot_cpu() to
    setup_arch(), as done already on x86, in preparation from early param
    usage in the init_on_alloc/free() series:
    https://lkml.kernel.org/r/1561572949.5154.81.camel@lca.pw
    
    Link: http://lkml.kernel.org/r/201906271003.005303B52@keescook
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Qian Cai <cai@lca.pw>
    Cc: Will Deacon <will@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7e541f947b4c..9c4bad7d7131 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -283,6 +283,11 @@ void __init setup_arch(char **cmdline_p)
 
 	setup_machine_fdt(__fdt_pointer);
 
+	/*
+	 * Initialise the static keys early as they may be enabled by the
+	 * cpufeature code and early parameters.
+	 */
+	jump_label_init();
 	parse_early_param();
 
 	/*

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 413d566405d1..7e541f947b4c 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -1,20 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Based on arch/arm/kernel/setup.c
  *
  * Copyright (C) 1995-2001 Russell King
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #include <linux/acpi.h>

commit 9e0a17db517d83d568bb7fa983b54759d4e34f1f
Author: Chen Zhou <chenzhou10@huawei.com>
Date:   Wed Mar 27 21:51:16 2019 +0800

    arm64: replace memblock_alloc_low with memblock_alloc
    
    If we use "crashkernel=Y[@X]" and the start address is above 4G,
    the arm64 kdump capture kernel may call memblock_alloc_low() failure
    in request_standard_resources(). Replacing memblock_alloc_low() with
    memblock_alloc().
    
    [    0.000000] MEMBLOCK configuration:
    [    0.000000]  memory size = 0x0000000040650000 reserved size = 0x0000000004db7f39
    [    0.000000]  memory.cnt  = 0x6
    [    0.000000]  memory[0x0]     [0x00000000395f0000-0x000000003968ffff], 0x00000000000a0000 bytes on node 0 flags: 0x4
    [    0.000000]  memory[0x1]     [0x0000000039730000-0x000000003973ffff], 0x0000000000010000 bytes on node 0 flags: 0x4
    [    0.000000]  memory[0x2]     [0x0000000039780000-0x000000003986ffff], 0x00000000000f0000 bytes on node 0 flags: 0x4
    [    0.000000]  memory[0x3]     [0x0000000039890000-0x0000000039d0ffff], 0x0000000000480000 bytes on node 0 flags: 0x4
    [    0.000000]  memory[0x4]     [0x000000003ed00000-0x000000003ed2ffff], 0x0000000000030000 bytes on node 0 flags: 0x4
    [    0.000000]  memory[0x5]     [0x0000002040000000-0x000000207fffffff], 0x0000000040000000 bytes on node 0 flags: 0x0
    [    0.000000]  reserved.cnt  = 0x7
    [    0.000000]  reserved[0x0]   [0x0000002040080000-0x0000002041c4dfff], 0x0000000001bce000 bytes flags: 0x0
    [    0.000000]  reserved[0x1]   [0x0000002041c53000-0x0000002042c203f8], 0x0000000000fcd3f9 bytes flags: 0x0
    [    0.000000]  reserved[0x2]   [0x000000207da00000-0x000000207dbfffff], 0x0000000000200000 bytes flags: 0x0
    [    0.000000]  reserved[0x3]   [0x000000207ddef000-0x000000207fbfffff], 0x0000000001e11000 bytes flags: 0x0
    [    0.000000]  reserved[0x4]   [0x000000207fdf2b00-0x000000207fdfc03f], 0x0000000000009540 bytes flags: 0x0
    [    0.000000]  reserved[0x5]   [0x000000207fdfd000-0x000000207ffff3ff], 0x0000000000202400 bytes flags: 0x0
    [    0.000000]  reserved[0x6]   [0x000000207ffffe00-0x000000207fffffff], 0x0000000000000200 bytes flags: 0x0
    [    0.000000] Kernel panic - not syncing: request_standard_resources: Failed to allocate 384 bytes
    [    0.000000] CPU: 0 PID: 0 Comm: swapper Not tainted 5.1.0-next-20190321+ #4
    [    0.000000] Call trace:
    [    0.000000]  dump_backtrace+0x0/0x188
    [    0.000000]  show_stack+0x24/0x30
    [    0.000000]  dump_stack+0xa8/0xcc
    [    0.000000]  panic+0x14c/0x31c
    [    0.000000]  setup_arch+0x2b0/0x5e0
    [    0.000000]  start_kernel+0x90/0x52c
    [    0.000000] ---[ end Kernel panic - not syncing: request_standard_resources: Failed to allocate 384 bytes ]---
    
    Link: https://www.spinics.net/lists/arm-kernel/msg715293.html
    Signed-off-by: Chen Zhou <chenzhou10@huawei.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f8482fe5a190..413d566405d1 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -217,7 +217,7 @@ static void __init request_standard_resources(void)
 
 	num_standard_resources = memblock.memory.cnt;
 	res_size = num_standard_resources * sizeof(*standard_resources);
-	standard_resources = memblock_alloc_low(res_size, SMP_CACHE_BYTES);
+	standard_resources = memblock_alloc(res_size, SMP_CACHE_BYTES);
 	if (!standard_resources)
 		panic("%s: Failed to allocate %zu bytes\n", __func__, res_size);
 

commit 8a7f97b902f4fb0d94b355b6b3f1fbd7154cafb9
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Mar 11 23:30:31 2019 -0700

    treewide: add checks for the return value of memblock_alloc*()
    
    Add check for the return value of memblock_alloc*() functions and call
    panic() in case of error.  The panic message repeats the one used by
    panicing memblock allocators with adjustment of parameters to include
    only relevant ones.
    
    The replacement was mostly automated with semantic patches like the one
    below with manual massaging of format strings.
    
      @@
      expression ptr, size, align;
      @@
      ptr = memblock_alloc(size, align);
      + if (!ptr)
      +     panic("%s: Failed to allocate %lu bytes align=0x%lx\n", __func__, size, align);
    
    [anders.roxell@linaro.org: use '%pa' with 'phys_addr_t' type]
      Link: http://lkml.kernel.org/r/20190131161046.21886-1-anders.roxell@linaro.org
    [rppt@linux.ibm.com: fix format strings for panics after memblock_alloc]
      Link: http://lkml.kernel.org/r/1548950940-15145-1-git-send-email-rppt@linux.ibm.com
    [rppt@linux.ibm.com: don't panic if the allocation in sparse_buffer_init fails]
      Link: http://lkml.kernel.org/r/20190131074018.GD28876@rapoport-lnx
    [akpm@linux-foundation.org: fix xtensa printk warning]
    Link: http://lkml.kernel.org/r/1548057848-15136-20-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Anders Roxell <anders.roxell@linaro.org>
    Reviewed-by: Guo Ren <ren_guo@c-sky.com>                [c-sky]
    Acked-by: Paul Burton <paul.burton@mips.com>            [MIPS]
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>    [s390]
    Reviewed-by: Juergen Gross <jgross@suse.com>            [Xen]
    Reviewed-by: Geert Uytterhoeven <geert@linux-m68k.org>  [m68k]
    Acked-by: Max Filippov <jcmvbkbc@gmail.com>             [xtensa]
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Dennis Zhou <dennis@kernel.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 834b321a88f8..f8482fe5a190 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -208,6 +208,7 @@ static void __init request_standard_resources(void)
 	struct memblock_region *region;
 	struct resource *res;
 	unsigned long i = 0;
+	size_t res_size;
 
 	kernel_code.start   = __pa_symbol(_text);
 	kernel_code.end     = __pa_symbol(__init_begin - 1);
@@ -215,9 +216,10 @@ static void __init request_standard_resources(void)
 	kernel_data.end     = __pa_symbol(_end - 1);
 
 	num_standard_resources = memblock.memory.cnt;
-	standard_resources = memblock_alloc_low(num_standard_resources *
-					        sizeof(*standard_resources),
-					        SMP_CACHE_BYTES);
+	res_size = num_standard_resources * sizeof(*standard_resources);
+	standard_resources = memblock_alloc_low(res_size, SMP_CACHE_BYTES);
+	if (!standard_resources)
+		panic("%s: Failed to allocate %zu bytes\n", __func__, res_size);
 
 	for_each_memblock(memory, region) {
 		res = &standard_resources[i++];

commit 3d8dfe75ef69f4dd4ba35c09b20a5aa58b4a5078
Merge: d60752629693 b855b58ac1b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Mar 10 10:17:23 2019 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - Pseudo NMI support for arm64 using GICv3 interrupt priorities
    
     - uaccess macros clean-up (unsafe user accessors also merged but
       reverted, waiting for objtool support on arm64)
    
     - ptrace regsets for Pointer Authentication (ARMv8.3) key management
    
     - inX() ordering w.r.t. delay() on arm64 and riscv (acks in place by
       the riscv maintainers)
    
     - arm64/perf updates: PMU bindings converted to json-schema, unused
       variable and misleading comment removed
    
     - arm64/debug fixes to ensure checking of the triggering exception
       level and to avoid the propagation of the UNKNOWN FAR value into the
       si_code for debug signals
    
     - Workaround for Fujitsu A64FX erratum 010001
    
     - lib/raid6 ARM NEON optimisations
    
     - NR_CPUS now defaults to 256 on arm64
    
     - Minor clean-ups (documentation/comments, Kconfig warning, unused
       asm-offsets, clang warnings)
    
     - MAINTAINERS update for list information to the ARM64 ACPI entry
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (54 commits)
      arm64: mmu: drop paging_init comments
      arm64: debug: Ensure debug handlers check triggering exception level
      arm64: debug: Don't propagate UNKNOWN FAR into si_code for debug signals
      Revert "arm64: uaccess: Implement unsafe accessors"
      arm64: avoid clang warning about self-assignment
      arm64: Kconfig.platforms: fix warning unmet direct dependencies
      lib/raid6: arm: optimize away a mask operation in NEON recovery routine
      lib/raid6: use vdupq_n_u8 to avoid endianness warnings
      arm64: io: Hook up __io_par() for inX() ordering
      riscv: io: Update __io_[p]ar() macros to take an argument
      asm-generic/io: Pass result of I/O accessor to __io_[p]ar()
      arm64: Add workaround for Fujitsu A64FX erratum 010001
      arm64: Rename get_thread_info()
      arm64: Remove documentation about TIF_USEDFPU
      arm64: irqflags: Fix clang build warnings
      arm64: Enable the support of pseudo-NMIs
      arm64: Skip irqflags tracing for NMI in IRQs disabled context
      arm64: Skip preemption when exiting an NMI
      arm64: Handle serror in NMI context
      irqchip/gic-v3: Allow interrupts to be set as pseudo-NMI
      ...

commit 3f41b609382388f95c0a05b69b8db0d706adafb4
Author: Andrey Konovalov <andreyknvl@google.com>
Date:   Wed Feb 20 22:20:15 2019 -0800

    kasan: fix random seed generation for tag-based mode
    
    There are two issues with assigning random percpu seeds right now:
    
    1. We use for_each_possible_cpu() to iterate over cpus, but cpumask is
       not set up yet at the moment of kasan_init(), and thus we only set
       the seed for cpu #0.
    
    2. A call to get_random_u32() always returns the same number and produces
       a message in dmesg, since the random subsystem is not yet initialized.
    
    Fix 1 by calling kasan_init_tags() after cpumask is set up.
    
    Fix 2 by using get_cycles() instead of get_random_u32(). This gives us
    lower quality random numbers, but it's good enough, as KASAN is meant to
    be used as a debugging tool and not a mitigation.
    
    Link: http://lkml.kernel.org/r/1f815cc914b61f3516ed4cc9bfd9eeca9bd5d9de.1550677973.git.andreyknvl@google.com
    Signed-off-by: Andrey Konovalov <andreyknvl@google.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index d09ec76f08cf..009849328289 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -339,6 +339,9 @@ void __init setup_arch(char **cmdline_p)
 	smp_init_cpus();
 	smp_build_mpidr_hash();
 
+	/* Init percpu seeds for random tags after cpus are set up. */
+	kasan_init_tags();
+
 #ifdef CONFIG_ARM64_SW_TTBR0_PAN
 	/*
 	 * Make sure init_thread_info.ttbr0 always generates translation

commit 582a32e708823e5957fd73ccd78dc4a9e49d21ea
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Feb 15 13:33:33 2019 +0100

    efi/arm: Revert "Defer persistent reservations until after paging_init()"
    
    This reverts commit eff896288872d687d9662000ec9ae11b6d61766f, which
    deferred the processing of persistent memory reservations to a point
    where the memory may have already been allocated and overwritten,
    defeating the purpose.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20190215123333.21209-3-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4b0e1231625c..d09ec76f08cf 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -313,7 +313,6 @@ void __init setup_arch(char **cmdline_p)
 	arm64_memblock_init();
 
 	paging_init();
-	efi_apply_persistent_mem_reservations();
 
 	acpi_table_upgrade();
 

commit 83504032e6ddcc8b0942aa24dfad5db849090c9f
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jan 14 14:22:24 2019 +0000

    arm64: Remove asm/memblock.h
    
    The arm64 asm/memblock.h header exists only to provide a function
    prototype for arm64_memblock_init(), which is called only from
    setup_arch().
    
    Move the declaration into mmu.h, where it can live alongside other
    init functions such as paging_init() and bootmem_init() without the
    need for its own special header file.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4b0e1231625c..71f5fbb12608 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -58,7 +58,6 @@
 #include <asm/cacheflush.h>
 #include <asm/tlbflush.h>
 #include <asm/traps.h>
-#include <asm/memblock.h>
 #include <asm/efi.h>
 #include <asm/xen/hypervisor.h>
 #include <asm/mmu_context.h>

commit 12f799c8c739518e12248bbd000eb0a246e8e5f8
Author: Miles Chen <miles.chen@mediatek.com>
Date:   Wed Dec 12 18:56:49 2018 +0800

    arm64: kaslr: print PHYS_OFFSET in dump_kernel_offset()
    
    When debug with kaslr, it is sometimes necessary to have PHYS_OFFSET to
    perform linear virtual address to physical address translation.
    Sometimes we're debugging with only few information such as a kernel log
    and a symbol file, print PHYS_OFFSET in dump_kernel_offset() for that case.
    
    Tested by:
    echo c > /proc/sysrq-trigger
    [   11.996161] SMP: stopping secondary CPUs
    [   11.996732] Kernel Offset: 0x2522200000 from 0xffffff8008000000
    [   11.996881] PHYS_OFFSET: 0xffffffeb40000000
    
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Miles Chen <miles.chen@mediatek.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f4fc1e0544b7..4b0e1231625c 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -388,6 +388,7 @@ static int dump_kernel_offset(struct notifier_block *self, unsigned long v,
 	if (IS_ENABLED(CONFIG_RANDOMIZE_BASE) && offset > 0) {
 		pr_emerg("Kernel Offset: 0x%lx from 0x%lx\n",
 			 offset, KIMAGE_VADDR);
+		pr_emerg("PHYS_OFFSET: 0x%llx\n", PHYS_OFFSET);
 	} else {
 		pr_emerg("Kernel Offset: disabled\n");
 	}

commit eff896288872d687d9662000ec9ae11b6d61766f
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Nov 14 09:55:43 2018 -0800

    efi/arm: Defer persistent reservations until after paging_init()
    
    The new memory EFI reservation feature we introduced to allow memory
    reservations to persist across kexec may trigger an unbounded number
    of calls to memblock_reserve(). The memblock subsystem can deal with
    this fine, but not before memblock resizing is enabled, which we can
    only do after paging_init(), when the memory we reallocate the array
    into is actually mapped.
    
    So break out the memreserve table processing into a separate routine
    and call it after paging_init() on arm64. On ARM, because of limited
    reviewing bandwidth of the maintainer, we cannot currently fix this,
    so instead, disable the EFI persistent memreserve entirely on ARM so
    we can fix it later.
    
    Tested-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-efi@vger.kernel.org
    Link: http://lkml.kernel.org/r/20181114175544.12860-5-ard.biesheuvel@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 953e316521fc..f4fc1e0544b7 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -313,6 +313,7 @@ void __init setup_arch(char **cmdline_p)
 	arm64_memblock_init();
 
 	paging_init();
+	efi_apply_persistent_mem_reservations();
 
 	acpi_table_upgrade();
 

commit 7e1c4e27928e5f87b9b1eaf06dc31773b2f1e7f1
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:57 2018 -0700

    memblock: stop using implicit alignment to SMP_CACHE_BYTES
    
    When a memblock allocation APIs are called with align = 0, the alignment
    is implicitly set to SMP_CACHE_BYTES.
    
    Implicit alignment is done deep in the memblock allocator and it can
    come as a surprise.  Not that such an alignment would be wrong even
    when used incorrectly but it is better to be explicit for the sake of
    clarity and the prinicple of the least surprise.
    
    Replace all such uses of memblock APIs with the 'align' parameter
    explicitly set to SMP_CACHE_BYTES and stop implicit alignment assignment
    in the memblock internal allocation functions.
    
    For the case when memblock APIs are used via helper functions, e.g.  like
    iommu_arena_new_node() in Alpha, the helper functions were detected with
    Coccinelle's help and then manually examined and updated where
    appropriate.
    
    The direct memblock APIs users were updated using the semantic patch below:
    
    @@
    expression size, min_addr, max_addr, nid;
    @@
    (
    |
    - memblock_alloc_try_nid_raw(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid_raw(size, SMP_CACHE_BYTES, min_addr, max_addr,
    nid)
    |
    - memblock_alloc_try_nid_nopanic(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid_nopanic(size, SMP_CACHE_BYTES, min_addr, max_addr,
    nid)
    |
    - memblock_alloc_try_nid(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid(size, SMP_CACHE_BYTES, min_addr, max_addr, nid)
    |
    - memblock_alloc(size, 0)
    + memblock_alloc(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_raw(size, 0)
    + memblock_alloc_raw(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_from(size, 0, min_addr)
    + memblock_alloc_from(size, SMP_CACHE_BYTES, min_addr)
    |
    - memblock_alloc_nopanic(size, 0)
    + memblock_alloc_nopanic(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_low(size, 0)
    + memblock_alloc_low(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_low_nopanic(size, 0)
    + memblock_alloc_low_nopanic(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_from_nopanic(size, 0, min_addr)
    + memblock_alloc_from_nopanic(size, SMP_CACHE_BYTES, min_addr)
    |
    - memblock_alloc_node(size, 0, nid)
    + memblock_alloc_node(size, SMP_CACHE_BYTES, nid)
    )
    
    [mhocko@suse.com: changelog update]
    [akpm@linux-foundation.org: coding-style fixes]
    [rppt@linux.ibm.com: fix missed uses of implicit alignment]
      Link: http://lkml.kernel.org/r/20181016133656.GA10925@rapoport-lnx
    Link: http://lkml.kernel.org/r/1538687224-17535-1-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Suggested-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Paul Burton <paul.burton@mips.com>    [MIPS]
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> [powerpc]
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7ce7306f1d75..953e316521fc 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -218,7 +218,7 @@ static void __init request_standard_resources(void)
 	num_standard_resources = memblock.memory.cnt;
 	standard_resources = memblock_alloc_low(num_standard_resources *
 					        sizeof(*standard_resources),
-					        0);
+					        SMP_CACHE_BYTES);
 
 	for_each_memblock(memory, region) {
 		res = &standard_resources[i++];

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3428427f6c93..7ce7306f1d75 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -26,7 +26,6 @@
 #include <linux/initrd.h>
 #include <linux/console.h>
 #include <linux/cache.h>
-#include <linux/bootmem.h>
 #include <linux/screen_info.h>
 #include <linux/init.h>
 #include <linux/kexec.h>

commit 510d22f44d1621d32deb6c510a258504c8946750
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:08:26 2018 -0700

    memblock: replace alloc_bootmem_low with memblock_alloc_low (2)
    
    The alloc_bootmem_low(size) allocates low memory with default alignment
    and can be replaced by memblock_alloc_low(size, 0)
    
    Link: http://lkml.kernel.org/r/1536927045-23536-13-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index d0f62dd24c90..3428427f6c93 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -217,8 +217,9 @@ static void __init request_standard_resources(void)
 	kernel_data.end     = __pa_symbol(_end - 1);
 
 	num_standard_resources = memblock.memory.cnt;
-	standard_resources = alloc_bootmem_low(num_standard_resources *
-					       sizeof(*standard_resources));
+	standard_resources = memblock_alloc_low(num_standard_resources *
+					        sizeof(*standard_resources),
+					        0);
 
 	for_each_memblock(memory, region) {
 		res = &standard_resources[i++];

commit 528985117126f11beea339cf39120ee99da04cd2
Merge: 84df9525b0c2 4debef551007
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 22 17:30:06 2018 +0100

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
     "Apart from some new arm64 features and clean-ups, this also contains
      the core mmu_gather changes for tracking the levels of the page table
      being cleared and a minor update to the generic
      compat_sys_sigaltstack() introducing COMPAT_SIGMINSKSZ.
    
      Summary:
    
       - Core mmu_gather changes which allow tracking the levels of
         page-table being cleared together with the arm64 low-level flushing
         routines
    
       - Support for the new ARMv8.5 PSTATE.SSBS bit which can be used to
         mitigate Spectre-v4 dynamically without trapping to EL3 firmware
    
       - Introduce COMPAT_SIGMINSTKSZ for use in compat_sys_sigaltstack
    
       - Optimise emulation of MRS instructions to ID_* registers on ARMv8.4
    
       - Support for Common Not Private (CnP) translations allowing threads
         of the same CPU to share the TLB entries
    
       - Accelerated crc32 routines
    
       - Move swapper_pg_dir to the rodata section
    
       - Trap WFI instruction executed in user space
    
       - ARM erratum 1188874 workaround (arch_timer)
    
       - Miscellaneous fixes and clean-ups"
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (78 commits)
      arm64: KVM: Guests can skip __install_bp_hardening_cb()s HYP work
      arm64: cpufeature: Trap CTR_EL0 access only where it is necessary
      arm64: cpufeature: Fix handling of CTR_EL0.IDC field
      arm64: cpufeature: ctr: Fix cpu capability check for late CPUs
      Documentation/arm64: HugeTLB page implementation
      arm64: mm: Use __pa_symbol() for set_swapper_pgd()
      arm64: Add silicon-errata.txt entry for ARM erratum 1188873
      Revert "arm64: uaccess: implement unsafe accessors"
      arm64: mm: Drop the unused cpu parameter
      MAINTAINERS: fix bad sdei paths
      arm64: mm: Use #ifdef for the __PAGETABLE_P?D_FOLDED defines
      arm64: Fix typo in a comment in arch/arm64/mm/kasan_init.c
      arm64: xen: Use existing helper to check interrupt status
      arm64: Use daifflag_restore after bp_hardening
      arm64: daifflags: Use irqflags functions for daifflags
      arm64: arch_timer: avoid unused function warning
      arm64: Trap WFI executed in userspace
      arm64: docs: Document SSBS HWCAP
      arm64: docs: Fix typos in ELF hwcaps
      arm64/kprobes: remove an extra semicolon in arch_prepare_kprobe
      ...

commit d91680e687f47984ffd3200c8e5d587903e7bd11
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Oct 11 11:29:14 2018 +0100

    arm64: Fix /proc/iomem for reserved but not memory regions
    
    We describe ranges of 'reserved' memory to userspace via /proc/iomem.
    Commit 50d7ba36b916 ("arm64: export memblock_reserve()d regions via
    /proc/iomem") updated the logic to export regions that were reserved
    because their contents should be preserved. This allowed kexec-tools
    to tell the difference between 'reserved' memory that must be
    preserved and not overwritten, (e.g. the ACPI tables), and 'nomap'
    memory that must not be touched without knowing the memory-attributes
    (e.g. RAS CPER regions).
    
    The above commit wrongly assumed that memblock_reserve() would not
    be used to reserve regions that aren't memory. It turns out this is
    exactly what early_init_dt_reserve_memory_arch() will do if it finds
    a DT reserved-memory that was also carved out of the memory node, which
    results in a WARN_ON_ONCE() and the region being reserved instead of
    ignored. The ramoops description on hikey and dragonboard-410c both do
    this, so we can't simply write this configuration off as "buggy firmware".
    
    Avoid this issue by rewriting reserve_memblock_reserved_regions() so
    that only the portions of reserved regions which overlap with mapped
    memory are actually reserved.
    
    Fixes: 50d7ba36b916 ("arm64: export memblock_reserve()d regions via /proc/iomem")
    Reported-by: John Stultz <john.stultz@linaro.org>
    Reported-by: Paolo Pisati <p.pisati@gmail.com>
    CC: Akashi Takahiro <takahiro.akashi@linaro.org>
    CC: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 5b4fac434c84..b3354ff94e79 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -64,6 +64,9 @@
 #include <asm/xen/hypervisor.h>
 #include <asm/mmu_context.h>
 
+static int num_standard_resources;
+static struct resource *standard_resources;
+
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -206,14 +209,19 @@ static void __init request_standard_resources(void)
 {
 	struct memblock_region *region;
 	struct resource *res;
+	unsigned long i = 0;
 
 	kernel_code.start   = __pa_symbol(_text);
 	kernel_code.end     = __pa_symbol(__init_begin - 1);
 	kernel_data.start   = __pa_symbol(_sdata);
 	kernel_data.end     = __pa_symbol(_end - 1);
 
+	num_standard_resources = memblock.memory.cnt;
+	standard_resources = alloc_bootmem_low(num_standard_resources *
+					       sizeof(*standard_resources));
+
 	for_each_memblock(memory, region) {
-		res = alloc_bootmem_low(sizeof(*res));
+		res = &standard_resources[i++];
 		if (memblock_is_nomap(region)) {
 			res->name  = "reserved";
 			res->flags = IORESOURCE_MEM;
@@ -243,36 +251,26 @@ static void __init request_standard_resources(void)
 
 static int __init reserve_memblock_reserved_regions(void)
 {
-	phys_addr_t start, end, roundup_end = 0;
-	struct resource *mem, *res;
-	u64 i;
-
-	for_each_reserved_mem_region(i, &start, &end) {
-		if (end <= roundup_end)
-			continue; /* done already */
-
-		start = __pfn_to_phys(PFN_DOWN(start));
-		end = __pfn_to_phys(PFN_UP(end)) - 1;
-		roundup_end = end;
-
-		res = kzalloc(sizeof(*res), GFP_ATOMIC);
-		if (WARN_ON(!res))
-			return -ENOMEM;
-		res->start = start;
-		res->end = end;
-		res->name  = "reserved";
-		res->flags = IORESOURCE_MEM;
-
-		mem = request_resource_conflict(&iomem_resource, res);
-		/*
-		 * We expected memblock_reserve() regions to conflict with
-		 * memory created by request_standard_resources().
-		 */
-		if (WARN_ON_ONCE(!mem))
+	u64 i, j;
+
+	for (i = 0; i < num_standard_resources; ++i) {
+		struct resource *mem = &standard_resources[i];
+		phys_addr_t r_start, r_end, mem_size = resource_size(mem);
+
+		if (!memblock_is_region_reserved(mem->start, mem_size))
 			continue;
-		kfree(res);
 
-		reserve_region_with_split(mem, start, end, "reserved");
+		for_each_reserved_mem_region(j, &r_start, &r_end) {
+			resource_size_t start, end;
+
+			start = max(PFN_PHYS(PFN_DOWN(r_start)), mem->start);
+			end = min(PFN_PHYS(PFN_UP(r_end)) - 1, mem->end);
+
+			if (start > mem->end || end < mem->start)
+				continue;
+
+			reserve_region_with_split(mem, start, end, "reserved");
+		}
 	}
 
 	return 0;

commit 0b8af74549c2f985bfc3d2a983961b2a66882890
Author: Andrew Murray <andrew.murray@arm.com>
Date:   Thu Sep 13 12:56:40 2018 +0100

    arm64: Remove unused VGA console support
    
    Support for VGA_CONSOLE is not allowable due to commit ee23794b8668
    ("video: vgacon: Don't build on arm64"), thus remove the associated
    unused code.
    
    Whilst PCI on arm64 would support VGA a valid screen_info structure
    is missing.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Murray <andrew.murray@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 5b4fac434c84..95670a1eafb0 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -351,11 +351,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 #ifdef CONFIG_VT
-#if defined(CONFIG_VGA_CONSOLE)
-	conswitchp = &vga_con;
-#elif defined(CONFIG_DUMMY_CONSOLE)
 	conswitchp = &dummy_con;
-#endif
 #endif
 	if (boot_args[1] || boot_args[2] || boot_args[3]) {
 		pr_err("WARNING: x1-x3 nonzero in violation of boot protocol:\n"

commit 50d7ba36b916d0fd4687149ec143bf49c326523f
Author: James Morse <james.morse@arm.com>
Date:   Mon Jul 23 10:57:28 2018 +0900

    arm64: export memblock_reserve()d regions via /proc/iomem
    
    There has been some confusion around what is necessary to prevent kexec
    overwriting important memory regions. memblock: reserve, or nomap?
    Only memblock nomap regions are reported via /proc/iomem, kexec's
    user-space doesn't know about memblock_reserve()d regions.
    
    Until commit f56ab9a5b73ca ("efi/arm: Don't mark ACPI reclaim memory
    as MEMBLOCK_NOMAP") the ACPI tables were nomap, now they are reserved
    and thus possible for kexec to overwrite with the new kernel or initrd.
    But this was always broken, as the UEFI memory map is also reserved
    and not marked as nomap.
    
    Exporting both nomap and reserved memblock types is a nuisance as
    they live in different memblock structures which we can't walk at
    the same time.
    
    Take a second walk over memblock.reserved and add new 'reserved'
    subnodes for the memblock_reserved() regions that aren't already
    described by the existing code. (e.g. Kernel Code)
    
    We use reserve_region_with_split() to find the gaps in existing named
    regions. This handles the gap between 'kernel code' and 'kernel data'
    which is memblock_reserve()d, but already partially described by
    request_standard_resources(). e.g.:
    | 80000000-dfffffff : System RAM
    |   80080000-80ffffff : Kernel code
    |   81000000-8158ffff : reserved
    |   81590000-8237efff : Kernel data
    |   a0000000-dfffffff : Crash kernel
    | e00f0000-f949ffff : System RAM
    
    reserve_region_with_split needs kzalloc() which isn't available when
    request_standard_resources() is called, use an initcall.
    
    Reported-by: Bhupesh Sharma <bhsharma@redhat.com>
    Reported-by: Tyler Baicar <tbaicar@codeaurora.org>
    Suggested-by: Akashi Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: James Morse <james.morse@arm.com>
    Fixes: d28f6df1305a ("arm64/kexec: Add core kexec support")
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    CC: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 30ad2f085d1f..5b4fac434c84 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -241,6 +241,44 @@ static void __init request_standard_resources(void)
 	}
 }
 
+static int __init reserve_memblock_reserved_regions(void)
+{
+	phys_addr_t start, end, roundup_end = 0;
+	struct resource *mem, *res;
+	u64 i;
+
+	for_each_reserved_mem_region(i, &start, &end) {
+		if (end <= roundup_end)
+			continue; /* done already */
+
+		start = __pfn_to_phys(PFN_DOWN(start));
+		end = __pfn_to_phys(PFN_UP(end)) - 1;
+		roundup_end = end;
+
+		res = kzalloc(sizeof(*res), GFP_ATOMIC);
+		if (WARN_ON(!res))
+			return -ENOMEM;
+		res->start = start;
+		res->end = end;
+		res->name  = "reserved";
+		res->flags = IORESOURCE_MEM;
+
+		mem = request_resource_conflict(&iomem_resource, res);
+		/*
+		 * We expected memblock_reserve() regions to conflict with
+		 * memory created by request_standard_resources().
+		 */
+		if (WARN_ON_ONCE(!mem))
+			continue;
+		kfree(res);
+
+		reserve_region_with_split(mem, start, end, "reserved");
+	}
+
+	return 0;
+}
+arch_initcall(reserve_memblock_reserved_regions);
+
 u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)

commit 41bd5b5d22b77c7300df2a2fa5397cbe785189b4
Author: James Morse <james.morse@arm.com>
Date:   Thu Nov 2 12:12:36 2017 +0000

    arm64: Move the async/fiq helpers to explicitly set process context flags
    
    Remove the local_{async,fiq}_{en,dis}able macros as they don't respect
    our newly defined order and are only used to set the flags for process
    context when we bring CPUs online.
    
    Add a helper to do this. The IRQ flag varies as we want it masked on
    the boot CPU until we are ready to handle interrupts.
    The boot CPU unmasks SError during early boot once it can print an error
    message. If we can print an error message about SError, we can do the
    same for FIQ. Debug exceptions are already enabled by __cpu_setup(),
    which has also configured MDSCR_EL1 to disable MDE and KDE.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4bab73e80e33..30ad2f085d1f 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -47,6 +47,7 @@
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
+#include <asm/daifflags.h>
 #include <asm/elf.h>
 #include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
@@ -259,10 +260,11 @@ void __init setup_arch(char **cmdline_p)
 	parse_early_param();
 
 	/*
-	 *  Unmask asynchronous aborts after bringing up possible earlycon.
-	 * (Report possible System Errors once we can report this occurred)
+	 * Unmask asynchronous aborts and fiq after bringing up possible
+	 * earlycon. (Report possible System Errors once we can report this
+	 * occurred).
 	 */
-	local_async_enable();
+	local_daif_restore(DAIF_PROCCTX_NOIRQ);
 
 	/*
 	 * TTBR0 is only used for the identity mapping at this stage. Make it

commit ccaac16287f9b46c58777f5538c4ba3a9d4c3aeb
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Sep 27 14:50:38 2017 +0100

    arm64: consistently log boot/secondary CPU IDs
    
    Currently we inconsistently log identifying information for the boot CPU
    and secondary CPUs. For the boot CPU, we log the MIDR and MPIDR across
    separate messages, whereas for the secondary CPUs we only log the MIDR.
    
    In some cases, it would be useful to know the MPIDR of secondary CPUs,
    and it would be nice for these messages to be consistent.
    
    This patch ensures that in the primary and secondary boot paths, we log
    both the MPIDR and MIDR in a single message, with a consistent format.
    the MPIDR is consistently padded to 10 hex characters to cover Aff3 in
    bits 39:32, so that IDs can be compared easily.
    
    The newly redundant message in setup_arch() is removed.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Al Stone <ahs3@redhat.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    [will: added '0x' prefixes consistently]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b2fdb59b69f6..4bab73e80e33 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -102,7 +102,8 @@ void __init smp_setup_processor_id(void)
 	 * access percpu variable inside lock_release
 	 */
 	set_my_cpu_offset(0);
-	pr_info("Booting Linux on physical CPU 0x%lx\n", (unsigned long)mpidr);
+	pr_info("Booting Linux on physical CPU 0x%010lx [0x%08x]\n",
+		(unsigned long)mpidr, read_cpuid_id());
 }
 
 bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
@@ -243,8 +244,6 @@ u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
 {
-	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
-
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code   = (unsigned long) _etext;
 	init_mm.end_data   = (unsigned long) _edata;

commit c2f0b54f10b12620c57f6e31233589b704a00ed5
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Thu Sep 14 20:40:04 2017 +0900

    arm64: remove unneeded copy to init_utsname()->machine
    
    As you see in init/version.c, init_uts_ns.name.machine is initially
    set to UTS_MACHINE.  There is no point to copy the same string.
    
    I dug the git history to figure out why this line is here.  My best
    guess is like this:
    
     - This line has been around here since the initial support of arm64
       by commit 9703d9d7f77c ("arm64: Kernel booting and initialisation").
       If ARCH (=arm64) and UTS_MACHINE (=aarch64) do not match,
       arch/$(ARCH)/Makefile is supposed to override UTS_MACHINE, but the
       initial version of arch/arm64/Makefile missed to do that.  Instead,
       the boot code copied "aarch64" to init_utsname()->machine.
    
     - Commit 94ed1f2cb5d4 ("arm64: setup: report ELF_PLATFORM as the
       machine for utsname") replaced "aarch64" with ELF_PLATFORM to
       make "uname" to reflect the endianness.
    
     - ELF_PLATFORM does not help to provide the UTS machine name to rpm
       target, so commit cfa88c79462d ("arm64: Set UTS_MACHINE in the
       Makefile") fixed it.  The commit simply replaced ELF_PLATFORM with
       UTS_MACHINE, but missed the fact the string copy itself is no longer
       needed.
    
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index d4b740538ad5..b2fdb59b69f6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -23,7 +23,6 @@
 #include <linux/stddef.h>
 #include <linux/ioport.h>
 #include <linux/delay.h>
-#include <linux/utsname.h>
 #include <linux/initrd.h>
 #include <linux/console.h>
 #include <linux/cache.h>
@@ -246,7 +245,6 @@ void __init setup_arch(char **cmdline_p)
 {
 	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
 
-	sprintf(init_utsname()->machine, UTS_MACHINE);
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code   = (unsigned long) _etext;
 	init_mm.end_data   = (unsigned long) _edata;

commit 690e95dd4d67be2eb905e1480b692c84e612a71a
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Tue May 16 15:36:16 2017 +0800

    arm64: check return value of of_flat_dt_get_machine_name
    
    It's useless to print machine name and setup arch-specific system
    identifiers if of_flat_dt_get_machine_name() return NULL, especially
    when ACPI-based boot.
    
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 2c822ef94f34..d4b740538ad5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -194,6 +194,9 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 	}
 
 	name = of_flat_dt_get_machine_name();
+	if (!name)
+		return;
+
 	pr_info("Machine model: %s\n", name);
 	dump_stack_set_arch_desc("%s (DT)", name);
 }

commit 2f9a0bec659700554744338bf780841f641cec40
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Thu Apr 27 14:33:05 2017 +0200

    arm64: Print DT machine model in setup_machine_fdt()
    
    On arm32, the machine model specified in the device tree is printed
    during boot-up, courtesy of of_flat_dt_match_machine().
    
    On arm64, of_flat_dt_match_machine() is not called, and the machine
    model information is not available from the kernel log.
    
    Print the machine model to make it easier to derive the machine model
    from an arbitrary kernel boot log.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 28855ec1be95..2c822ef94f34 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -180,6 +180,7 @@ static void __init smp_build_mpidr_hash(void)
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
 	void *dt_virt = fixmap_remap_fdt(dt_phys);
+	const char *name;
 
 	if (!dt_virt || !early_init_dt_scan(dt_virt)) {
 		pr_crit("\n"
@@ -192,7 +193,9 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 			cpu_relax();
 	}
 
-	dump_stack_set_arch_desc("%s (DT)", of_flat_dt_get_machine_name());
+	name = of_flat_dt_get_machine_name();
+	pr_info("Machine model: %s\n", name);
+	dump_stack_set_arch_desc("%s (DT)", name);
 }
 
 static void __init request_standard_resources(void)

commit 764b51ead10d5f428cb5f167bf98e336bdc23f8c
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Mon Apr 3 11:24:32 2017 +0900

    arm64: kdump: reserve memory for crash dump kernel
    
    "crashkernel=" kernel parameter specifies the size (and optionally
    the start address) of the system ram to be used by crash dump kernel.
    reserve_crashkernel() will allocate and reserve that memory at boot time
    of primary kernel.
    
    The memory range will be exposed to userspace as a resource named
    "Crash kernel" in /proc/iomem.
    
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Reviewed-by: James Morse <james.morse@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 42274bda0ccb..28855ec1be95 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -31,7 +31,6 @@
 #include <linux/screen_info.h>
 #include <linux/init.h>
 #include <linux/kexec.h>
-#include <linux/crash_dump.h>
 #include <linux/root_dev.h>
 #include <linux/cpu.h>
 #include <linux/interrupt.h>
@@ -226,6 +225,12 @@ static void __init request_standard_resources(void)
 		if (kernel_data.start >= res->start &&
 		    kernel_data.end <= res->end)
 			request_resource(res, &kernel_data);
+#ifdef CONFIG_KEXEC_CORE
+		/* Userspace will find "Crash kernel" region in /proc/iomem. */
+		if (crashk_res.end && crashk_res.start >= res->start &&
+		    crashk_res.end <= res->end)
+			request_resource(res, &crashk_res);
+#endif
 	}
 }
 

commit 9164bb4a18dfa592cd0aca455ea57abf89ca4526
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Feb 4 01:20:53 2017 +0100

    sched/headers: Prepare to move 'init_task' and 'init_thread_union' from <linux/sched.h> to <linux/sched/task.h>
    
    Update all usage sites first.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 952e2c0dabd5..42274bda0ccb 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -42,6 +42,7 @@
 #include <linux/of_fdt.h>
 #include <linux/efi.h>
 #include <linux/psci.h>
+#include <linux/sched/task.h>
 #include <linux/mm.h>
 
 #include <asm/acpi.h>

commit 79ba11d24b28ead94b976c4d7c8bf8e6c349eb36
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Jan 24 17:11:40 2017 +0000

    arm64: kernel: do not mark reserved memory regions as IORESOURCE_BUSY
    
    Memory regions marked as NOMAP should not be used for general allocation
    by the kernel, and should not even be covered by the linear mapping
    (hence the name). However, drivers or other subsystems (such as ACPI)
    that access the firmware directly may legally access them, which means
    it is also reasonable for such drivers to claim them by invoking
    request_resource(). Currently, this is prevented by the fact that arm64's
    request_standard_resources() marks reserved regions as IORESOURCE_BUSY.
    
    So drop the IORESOURCE_BUSY flag from these requests.
    
    Reported-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b5222094ab52..952e2c0dabd5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -209,7 +209,7 @@ static void __init request_standard_resources(void)
 		res = alloc_bootmem_low(sizeof(*res));
 		if (memblock_is_nomap(region)) {
 			res->name  = "reserved";
-			res->flags = IORESOURCE_MEM | IORESOURCE_BUSY;
+			res->flags = IORESOURCE_MEM;
 		} else {
 			res->name  = "System RAM";
 			res->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;

commit cbb999dd0b452991f4f698142aa7ffe566c0b415
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Tue Jan 24 12:43:40 2017 +0100

    arm64: Use __pa_symbol for empty_zero_page
    
    If CONFIG_DEBUG_VIRTUAL=y and CONFIG_ARM64_SW_TTBR0_PAN=y:
    
        virt_to_phys used for non-linear address: ffffff8008cc0000 (empty_zero_page+0x0/0x1000)
        WARNING: CPU: 0 PID: 0 at arch/arm64/mm/physaddr.c:14 __virt_to_phys+0x28/0x60
        ...
        [<ffffff800809abb4>] __virt_to_phys+0x28/0x60
        [<ffffff8008a02600>] setup_arch+0x46c/0x4d4
    
    Fixes: 2077be6783b5936c ("arm64: Use __pa_symbol for kernel symbols")
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Laura Abbott <labbott@redhat.com>
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 669fc9ff728b..b5222094ab52 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -298,7 +298,7 @@ void __init setup_arch(char **cmdline_p)
 	 * faults in case uaccess_enable() is inadvertently called by the init
 	 * thread.
 	 */
-	init_task.thread_info.ttbr0 = virt_to_phys(empty_zero_page);
+	init_task.thread_info.ttbr0 = __pa_symbol(empty_zero_page);
 #endif
 
 #ifdef CONFIG_VT

commit 2077be6783b5936c3daa838d8addbb635667927f
Author: Laura Abbott <labbott@redhat.com>
Date:   Tue Jan 10 13:35:49 2017 -0800

    arm64: Use __pa_symbol for kernel symbols
    
    __pa_symbol is technically the marcro that should be used for kernel
    symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL which
    will do bounds checking.
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Laura Abbott <labbott@redhat.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b051367e2149..669fc9ff728b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -42,6 +42,7 @@
 #include <linux/of_fdt.h>
 #include <linux/efi.h>
 #include <linux/psci.h>
+#include <linux/mm.h>
 
 #include <asm/acpi.h>
 #include <asm/fixmap.h>
@@ -199,10 +200,10 @@ static void __init request_standard_resources(void)
 	struct memblock_region *region;
 	struct resource *res;
 
-	kernel_code.start   = virt_to_phys(_text);
-	kernel_code.end     = virt_to_phys(__init_begin - 1);
-	kernel_data.start   = virt_to_phys(_sdata);
-	kernel_data.end     = virt_to_phys(_end - 1);
+	kernel_code.start   = __pa_symbol(_text);
+	kernel_code.end     = __pa_symbol(__init_begin - 1);
+	kernel_data.start   = __pa_symbol(_sdata);
+	kernel_data.end     = __pa_symbol(_end - 1);
 
 	for_each_memblock(memory, region) {
 		res = alloc_bootmem_low(sizeof(*res));

commit 7ede8665f27cde7da69e8b2fbeaa1ed0664879c5
Author: Alexander Popov <alex.popov@linux.com>
Date:   Mon Dec 19 16:23:06 2016 -0800

    arm64: setup: introduce kaslr_offset()
    
    Introduce kaslr_offset() similar to x86_64 to fix kcov.
    
    [ Updated by Will Deacon ]
    
    Link: http://lkml.kernel.org/r/1481417456-28826-2-git-send-email-alex.popov@linux.com
    Signed-off-by: Alexander Popov <alex.popov@linux.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Kefeng Wang <wangkefeng.wang@huawei.com>
    Cc: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Cc: Jon Masters <jcm@redhat.com>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Ganapatrao Kulkarni <gkulkarni@caviumnetworks.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Nicolai Stange <nicstange@gmail.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Cc: Alexander Popov <alex.popov@linux.com>
    Cc: syzkaller <syzkaller@googlegroups.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index a53f52ac81c6..b051367e2149 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -338,11 +338,11 @@ subsys_initcall(topology_init);
 static int dump_kernel_offset(struct notifier_block *self, unsigned long v,
 			      void *p)
 {
-	u64 const kaslr_offset = kimage_vaddr - KIMAGE_VADDR;
+	const unsigned long offset = kaslr_offset();
 
-	if (IS_ENABLED(CONFIG_RANDOMIZE_BASE) && kaslr_offset > 0) {
-		pr_emerg("Kernel Offset: 0x%llx from 0x%lx\n",
-			 kaslr_offset, KIMAGE_VADDR);
+	if (IS_ENABLED(CONFIG_RANDOMIZE_BASE) && offset > 0) {
+		pr_emerg("Kernel Offset: 0x%lx from 0x%lx\n",
+			 offset, KIMAGE_VADDR);
 	} else {
 		pr_emerg("Kernel Offset: disabled\n");
 	}

commit 39bc88e5e38e9b213bd7d833ce0df6ec029761ad
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Sep 2 14:54:03 2016 +0100

    arm64: Disable TTBR0_EL1 during normal kernel execution
    
    When the TTBR0 PAN feature is enabled, the kernel entry points need to
    disable access to TTBR0_EL1. The PAN status of the interrupted context
    is stored as part of the saved pstate, reusing the PSR_PAN_BIT (22).
    Restoring access to TTBR0_EL1 is done on exception return if returning
    to user or returning to a context where PAN was disabled.
    
    Context switching via switch_mm() must defer the update of TTBR0_EL1
    until a return to user or an explicit uaccess_enable() call.
    
    Special care needs to be taken for two cases where TTBR0_EL1 is set
    outside the normal kernel context switch operation: EFI run-time
    services (via efi_set_pgd) and CPU suspend (via cpu_(un)install_idmap).
    Code has been added to avoid deferred TTBR0_EL1 switching as in
    switch_mm() and restore the reserved TTBR0_EL1 when uninstalling the
    special TTBR0_EL1.
    
    User cache maintenance (user_cache_maint_handler and
    __flush_cache_user_range) needs the TTBR0_EL1 re-instated since the
    operations are performed by user virtual address.
    
    This patch also removes a stale comment on the switch_mm() function.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f534f492a268..a53f52ac81c6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -291,6 +291,15 @@ void __init setup_arch(char **cmdline_p)
 	smp_init_cpus();
 	smp_build_mpidr_hash();
 
+#ifdef CONFIG_ARM64_SW_TTBR0_PAN
+	/*
+	 * Make sure init_thread_info.ttbr0 always generates translation
+	 * faults in case uaccess_enable() is inadvertently called by the init
+	 * thread.
+	 */
+	init_task.thread_info.ttbr0 = virt_to_phys(empty_zero_page);
+#endif
+
 #ifdef CONFIG_VT
 #if defined(CONFIG_VGA_CONSOLE)
 	conswitchp = &vga_con;

commit cfa88c79462d15098db29edebe623428c3620a4b
Author: Michal Marek <mmarek@suse.com>
Date:   Tue Aug 30 10:31:35 2016 +0200

    arm64: Set UTS_MACHINE in the Makefile
    
    The make rpm target depends on proper UTS_MACHINE definition.  Also, use
    the variable in arch/arm64/kernel/setup.c, so that it's not accidentally
    removed in the future.
    
    Reported-and-tested-by: Fabian Vogt <fvogt@suse.com>
    Signed-off-by: Michal Marek <mmarek@suse.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 514b4e3ba029..f534f492a268 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -233,7 +233,7 @@ void __init setup_arch(char **cmdline_p)
 {
 	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
 
-	sprintf(init_utsname()->machine, ELF_PLATFORM);
+	sprintf(init_utsname()->machine, UTS_MACHINE);
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code   = (unsigned long) _etext;
 	init_mm.end_data   = (unsigned long) _edata;

commit e7cd190385d17790cc3eb3821b1094b00aacf325
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Mon Aug 22 15:55:24 2016 +0900

    arm64: mark reserved memblock regions explicitly in iomem
    
    Kdump(kexec-tools) parses /proc/iomem to identify all the memory regions
    on the system. Since the current kernel names "nomap" regions, like UEFI
    runtime services code/data, as "System RAM," kexec-tools sets up elf core
    header to include them in a crash dump file (/proc/vmcore).
    
    Then crash dump kernel parses UEFI memory map again, re-marks those regions
    as "nomap" and does not create a memory mapping for them unlike the other
    areas of System RAM. In this case, copying /proc/vmcore through
    copy_oldmem_page() on crash dump kernel will end up with a kernel abort,
    as reported in [1].
    
    This patch names all the "nomap" regions explicitly as "reserved" so that
    we can exclude them from a crash dump file. acpi_os_ioremap() must also
    be modified because those regions have WB attributes [2].
    
    Apart from kdump, this change also matches x86's use of acpi (and
    /proc/iomem).
    
    [1] http://lists.infradead.org/pipermail/linux-arm-kernel/2016-August/448186.html
    [2] http://lists.infradead.org/pipermail/linux-arm-kernel/2016-August/450089.html
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: James Morse <james.morse@arm.com>
    Reviewed-by: James Morse <james.morse@arm.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 536dce22fe76..514b4e3ba029 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -206,10 +206,15 @@ static void __init request_standard_resources(void)
 
 	for_each_memblock(memory, region) {
 		res = alloc_bootmem_low(sizeof(*res));
-		res->name  = "System RAM";
+		if (memblock_is_nomap(region)) {
+			res->name  = "reserved";
+			res->flags = IORESOURCE_MEM | IORESOURCE_BUSY;
+		} else {
+			res->name  = "System RAM";
+			res->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;
+		}
 		res->start = __pfn_to_phys(memblock_region_memory_base_pfn(region));
 		res->end = __pfn_to_phys(memblock_region_memory_end_pfn(region)) - 1;
-		res->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;
 
 		request_resource(&iomem_resource, res);
 

commit f64d6e2aaa79f0ad588fd7ad595a0a8eb8f04645
Merge: 1056c9bd2702 099c0cbd2025
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 30 11:32:01 2016 -0700

    Merge tag 'devicetree-for-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux
    
    Pull DeviceTree updates from Rob Herring:
    
     - remove most of_platform_populate() calls in arch code.  Now the DT
       core code calls it in the default case and platforms only need to
       call it if they have special needs
    
     - use pr_fmt on all the DT core print statements
    
     - CoreSight binding doc improvements to block name descriptions
    
     - add dt_to_config script which can parse dts files and list
       corresponding kernel config options
    
     - fix memory leak hit with a PowerMac DT
    
     - correct a bunch of STMicro compatible strings to use the correct
       vendor prefix
    
     - fix DA9052 PMIC binding doc to match what is actually used in dts
       files
    
    * tag 'devicetree-for-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux: (35 commits)
      documentation: da9052: Update regulator bindings names to match DA9052/53 DTS expectations
      xtensa: Partially Revert "xtensa: Remove unnecessary of_platform_populate with default match table"
      xtensa: Fix build error due to missing include file
      MIPS: ath79: Add missing include file
      Fix spelling errors in Documentation/devicetree
      ARM: dts: fix STMicroelectronics compatible strings
      powerpc/dts: fix STMicroelectronics compatible strings
      Documentation: dt: i2c: use correct STMicroelectronics vendor prefix
      scripts/dtc: dt_to_config - kernel config options for a devicetree
      of: fdt: mark unflattened tree as detached
      of: overlay: add resolver error prints
      coresight: document binding acronyms
      Documentation/devicetree: document cavium-pip rx-delay/tx-delay properties
      of: use pr_fmt prefix for all console printing
      of/irq: Mark initialised interrupt controllers as populated
      of: fix memory leak related to safe_name()
      Revert "of/platform: export of_default_bus_match_table"
      of: unittest: use of_platform_default_populate() to populate default bus
      memory: omap-gpmc: use of_platform_default_populate() to populate default bus
      bus: uniphier-system-bus: use of_platform_default_populate() to populate default bus
      ...

commit 08fd8c17686c6b09fa410a26d516548dd80ff147
Merge: e831101a73fb d34c30cc1fa8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 11:35:37 2016 -0700

    Merge tag 'for-linus-4.8-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip
    
    Pull xen updates from David Vrabel:
     "Features and fixes for 4.8-rc0:
    
       - ACPI support for guests on ARM platforms.
       - Generic steal time support for arm and x86.
       - Support cases where kernel cpu is not Xen VCPU number (e.g., if
         in-guest kexec is used).
       - Use the system workqueue instead of a custom workqueue in various
         places"
    
    * tag 'for-linus-4.8-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip: (47 commits)
      xen: add static initialization of steal_clock op to xen_time_ops
      xen/pvhvm: run xen_vcpu_setup() for the boot CPU
      xen/evtchn: use xen_vcpu_id mapping
      xen/events: fifo: use xen_vcpu_id mapping
      xen/events: use xen_vcpu_id mapping in events_base
      x86/xen: use xen_vcpu_id mapping when pointing vcpu_info to shared_info
      x86/xen: use xen_vcpu_id mapping for HYPERVISOR_vcpu_op
      xen: introduce xen_vcpu_id mapping
      x86/acpi: store ACPI ids from MADT for future usage
      x86/xen: update cpuid.h from Xen-4.7
      xen/evtchn: add IOCTL_EVTCHN_RESTRICT
      xen-blkback: really don't leak mode property
      xen-blkback: constify instance of "struct attribute_group"
      xen-blkfront: prefer xenbus_scanf() over xenbus_gather()
      xen-blkback: prefer xenbus_scanf() over xenbus_gather()
      xen: support runqueue steal time on xen
      arm/xen: add support for vm_assist hypercall
      xen: update xen headers
      xen-pciback: drop superfluous variables
      xen-pciback: short-circuit read path used for merging write values
      ...

commit e831101a73fbc8339ef1d1909dad3ef64f089e70
Merge: f9abf53af4c7 fd6380b75065
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 11:16:05 2016 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - Kexec support for arm64
    
     - Kprobes support
    
     - Expose MIDR_EL1 and REVIDR_EL1 CPU identification registers to sysfs
    
     - Trapping of user space cache maintenance operations and emulation in
       the kernel (CPU errata workaround)
    
     - Clean-up of the early page tables creation (kernel linear mapping,
       EFI run-time maps) to avoid splitting larger blocks (e.g.  pmds) into
       smaller ones (e.g.  ptes)
    
     - VDSO support for CLOCK_MONOTONIC_RAW in clock_gettime()
    
     - ARCH_HAS_KCOV enabled for arm64
    
     - Optimise IP checksum helpers
    
     - SWIOTLB optimisation to only allocate/initialise the buffer if the
       available RAM is beyond the 32-bit mask
    
     - Properly handle the "nosmp" command line argument
    
     - Fix for the initialisation of the CPU debug state during early boot
    
     - vdso-offsets.h build dependency workaround
    
     - Build fix when RANDOMIZE_BASE is enabled with MODULES off
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (64 commits)
      arm64: arm: Fix-up the removal of the arm64 regs_query_register_name() prototype
      arm64: Only select ARM64_MODULE_PLTS if MODULES=y
      arm64: mm: run pgtable_page_ctor() on non-swapper translation table pages
      arm64: mm: make create_mapping_late() non-allocating
      arm64: Honor nosmp kernel command line option
      arm64: Fix incorrect per-cpu usage for boot CPU
      arm64: kprobes: Add KASAN instrumentation around stack accesses
      arm64: kprobes: Cleanup jprobe_return
      arm64: kprobes: Fix overflow when saving stack
      arm64: kprobes: WARN if attempting to step with PSTATE.D=1
      arm64: debug: remove unused local_dbg_{enable, disable} macros
      arm64: debug: remove redundant spsr manipulation
      arm64: debug: unmask PSTATE.D earlier
      arm64: localise Image objcopy flags
      arm64: ptrace: remove extra define for CPSR's E bit
      kprobes: Add arm64 case in kprobe example module
      arm64: Add kernel return probes support (kretprobes)
      arm64: Add trampoline code for kretprobes
      arm64: kprobes instruction simulation support
      arm64: Treat all entry code as non-kprobe-able
      ...

commit 9b08aaa3199a4dffca73c7cdec813b483b5b2d3b
Author: Shannon Zhao <shannon.zhao@linaro.org>
Date:   Thu Apr 7 20:03:28 2016 +0800

    ARM: XEN: Move xen_early_init() before efi_init()
    
    Move xen_early_init() before efi_init(), then when calling efi_init()
    could initialize Xen specific UEFI.
    
    Check if it runs on Xen hypervisor through the flat dts.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Signed-off-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Reviewed-by: Julien Grall <julien.grall@arm.com>
    Tested-by: Julien Grall <julien.grall@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3279defabaa2..feab2eebb283 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -257,6 +257,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	cpu_uninstall_idmap();
 
+	xen_early_init();
 	efi_init();
 	arm64_memblock_init();
 
@@ -281,8 +282,6 @@ void __init setup_arch(char **cmdline_p)
 	else
 		psci_acpi_init();
 
-	xen_early_init();
-
 	cpu_read_bootcpu_ops();
 	smp_init_cpus();
 	smp_build_mpidr_hash();

commit 9fdc14c55cd6579d619ccd9d40982e0805e62b6d
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Jun 23 15:53:17 2016 +0200

    arm64: mm: fix location of _etext
    
    As Kees Cook notes in the ARM counterpart of this patch [0]:
    
      The _etext position is defined to be the end of the kernel text code,
      and should not include any part of the data segments. This interferes
      with things that might check memory ranges and expect executable code
      up to _etext.
    
    In particular, Kees is referring to the HARDENED_USERCOPY patch set [1],
    which rejects attempts to call copy_to_user() on kernel ranges containing
    executable code, but does allow access to the .rodata segment. Regardless
    of whether one may or may not agree with the distinction, it makes sense
    for _etext to have the same meaning across architectures.
    
    So let's put _etext where it belongs, between .text and .rodata, and fix
    up existing references to use __init_begin instead, which unlike _end_rodata
    includes the exception and notes sections as well.
    
    The _etext references in kaslr.c are left untouched, since its references
    to [_stext, _etext) are meant to capture potential jump instruction targets,
    and so disregarding .rodata is actually an improvement here.
    
    [0] http://article.gmane.org/gmane.linux.kernel/2245084
    [1] http://thread.gmane.org/gmane.linux.kernel.hardened.devel/2502
    
    Reported-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3279defabaa2..c1509e654190 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -202,7 +202,7 @@ static void __init request_standard_resources(void)
 	struct resource *res;
 
 	kernel_code.start   = virt_to_phys(_text);
-	kernel_code.end     = virt_to_phys(_etext - 1);
+	kernel_code.end     = virt_to_phys(__init_begin - 1);
 	kernel_data.start   = virt_to_phys(_sdata);
 	kernel_data.end     = virt_to_phys(_end - 1);
 

commit 9a4ef881d25957f149864bd46a2099e92ec9c53c
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Wed Jun 1 14:52:57 2016 +0800

    arm64: Remove unnecessary of_platform_populate with default match table
    
    After patch "of/platform: Add common method to populate default bus",
    it is possible for arch code to remove unnecessary callers of
    of_platform_populate with default match table.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Rob Herring <robh@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 8412520ef62d..c907e2f8b516 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -40,7 +40,6 @@
 #include <linux/proc_fs.h>
 #include <linux/memblock.h>
 #include <linux/of_fdt.h>
-#include <linux/of_platform.h>
 #include <linux/efi.h>
 #include <linux/psci.h>
 
@@ -301,18 +300,6 @@ void __init setup_arch(char **cmdline_p)
 	}
 }
 
-static int __init arm64_device_init(void)
-{
-	if (of_have_populated_dt()) {
-		of_platform_populate(NULL, of_default_bus_match_table,
-				     NULL, NULL);
-	} else if (acpi_disabled) {
-		pr_crit("Device tree not populated\n");
-	}
-	return 0;
-}
-arch_initcall_sync(arm64_device_init);
-
 static int __init topology_init(void)
 {
 	int i;

commit bb8e15d60462a84a25a3bf33e8bc29b46c6d470a
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Wed Jun 1 14:06:15 2016 +0800

    of: iommu: make of_iommu_init() postcore_initcall_sync
    
    The of_iommu_init() is called multiple times by arch code,
    make it postcore_initcall_sync, then we can drop relevant
    calls fully.
    
    Note, the IOMMUs should have a chance to perform some basic
    initialisation before we start adding masters to them. So
    postcore_initcall_sync is good choice, it ensures of_iommu_init()
    called before of_platform_populate.
    
    Acked-by: Rich Felker <dalias@libc.org>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Acked-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Rob Herring <robh@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3279defabaa2..8412520ef62d 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -39,7 +39,6 @@
 #include <linux/fs.h>
 #include <linux/proc_fs.h>
 #include <linux/memblock.h>
-#include <linux/of_iommu.h>
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
@@ -305,7 +304,6 @@ void __init setup_arch(char **cmdline_p)
 static int __init arm64_device_init(void)
 {
 	if (of_have_populated_dt()) {
-		of_iommu_init();
 		of_platform_populate(NULL, of_default_bus_match_table,
 				     NULL, NULL);
 	} else if (acpi_disabled) {

commit 38b04a74c58749231ee706752f81f7dc7c281a15
Author: Jon Masters <jcm@redhat.com>
Date:   Mon Jun 20 13:56:13 2016 +0300

    ACPI: ARM64: support for ACPI_TABLE_UPGRADE
    
    This patch adds support for ACPI_TABLE_UPGRADE for ARM64
    
    To access initrd image we need to move initialization
    of linear mapping a bit earlier.
    
    The implementation of the feature acpi_table_upgrade()
    (drivers/acpi/tables.c) works with initrd data represented as an array
    in virtual memory.  It uses some library utility to find the redefined
    tables in that array and iterates over it to copy the data to new
    allocated memory.  So to access the initrd data via fixmap
    we need to rewrite it considerably.
    
    In x86 arch, kernel memory is already mapped by the time when
    acpi_table_upgrade() and acpi_boot_table_init() are called so I
    think that we can just move this mapping one function earlier too.
    
    Signed-off-by: Jon Masters <jcm@redhat.com>
    Signed-off-by: Aleksey Makarov <aleksey.makarov@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3279defabaa2..92f0e1e767cf 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -260,11 +260,13 @@ void __init setup_arch(char **cmdline_p)
 	efi_init();
 	arm64_memblock_init();
 
+	paging_init();
+
+	acpi_table_upgrade();
+
 	/* Parse the ACPI tables for possible boot-time configuration */
 	acpi_boot_table_init();
 
-	paging_init();
-
 	if (acpi_disabled)
 		unflatten_device_tree();
 

commit cabe1c81ea5be983425d117912d7883e252a3b09
Author: James Morse <james.morse@arm.com>
Date:   Wed Apr 27 17:47:07 2016 +0100

    arm64: Change cpu_resume() to enable mmu early then access sleep_sp by va
    
    By enabling the MMU early in cpu_resume(), the sleep_save_sp and stack can
    be accessed by VA, which avoids the need to convert-addresses and clean to
    PoC on the suspend path.
    
    MMU setup is shared with the boot path, meaning the swapper_pg_dir is
    restored directly: ttbr1_el1 is no longer saved/restored.
    
    struct sleep_save_sp is removed, replacing it with a single array of
    pointers.
    
    cpu_do_{suspend,resume} could be further reduced to not restore: cpacr_el1,
    mdscr_el1, tcr_el1, vbar_el1 and sctlr_el1, all of which are set by
    __cpu_setup(). However these values all contain res0 bits that may be used
    to enable future features.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 65f515949baa..3279defabaa2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -176,7 +176,6 @@ static void __init smp_build_mpidr_hash(void)
 	 */
 	if (mpidr_hash_size() > 4 * num_possible_cpus())
 		pr_warn("Large number of MPIDR hash buckets detected\n");
-	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
 }
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)

commit 1a2db300348b799479d2d22b84d51b27ad0458c7
Author: Ganapatrao Kulkarni <gkulkarni@caviumnetworks.com>
Date:   Fri Apr 8 15:50:27 2016 -0700

    arm64, numa: Add NUMA support for arm64 platforms.
    
    Attempt to get the memory and CPU NUMA node via of_numa.  If that
    fails, default the dummy NUMA node and map all memory and CPUs to node
    0.
    
    Tested-by: Shannon Zhao <shannon.zhao@linaro.org>
    Reviewed-by: Robert Richter <rrichter@cavium.com>
    Signed-off-by: Ganapatrao Kulkarni <gkulkarni@caviumnetworks.com>
    Signed-off-by: David Daney <david.daney@cavium.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 432bc7f1dc45..65f515949baa 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -53,6 +53,7 @@
 #include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
 #include <asm/kasan.h>
+#include <asm/numa.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
 #include <asm/smp_plat.h>
@@ -319,6 +320,9 @@ static int __init topology_init(void)
 {
 	int i;
 
+	for_each_online_node(i)
+		register_one_node(i);
+
 	for_each_possible_cpu(i) {
 		struct cpu *cpu = &per_cpu(cpu_data.cpu, i);
 		cpu->hotpluggable = 1;

commit 3194ac6e66cc7a00c1fa9fecf33a7c376b489497
Author: David Daney <david.daney@cavium.com>
Date:   Fri Apr 8 15:50:26 2016 -0700

    arm64: Move unflatten_device_tree() call earlier.
    
    In order to extract NUMA information from the device tree, we need to
    have the tree in its unflattened form.
    
    Move the call to bootmem_init() in the tail of paging_init() into
    setup_arch, and adjust header files so that its declaration is
    visible.
    
    Move the unflatten_device_tree() call between the calls to
    paging_init() and bootmem_init().  Follow on patches add NUMA handling
    to bootmem_init().
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7b85b1d6a6fb..432bc7f1dc45 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -265,18 +265,22 @@ void __init setup_arch(char **cmdline_p)
 
 	paging_init();
 
+	if (acpi_disabled)
+		unflatten_device_tree();
+
+	bootmem_init();
+
 	kasan_init();
 
 	request_standard_resources();
 
 	early_ioremap_reset();
 
-	if (acpi_disabled) {
-		unflatten_device_tree();
+	if (acpi_disabled)
 		psci_dt_init();
-	} else {
+	else
 		psci_acpi_init();
-	}
+
 	xen_early_init();
 
 	cpu_read_bootcpu_ops();

commit 8923a16686569375bfa25b877769f9a3093e9f22
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Mar 30 15:18:43 2016 +0200

    arm64: remove the now unneeded relocate_initrd()
    
    This removes the relocate_initrd() implementation and invocation, which are
    no longer needed now that the placement of the initrd is guaranteed to be
    covered by the linear mapping.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 9dc67769b6a4..7b85b1d6a6fb 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -224,69 +224,6 @@ static void __init request_standard_resources(void)
 	}
 }
 
-#ifdef CONFIG_BLK_DEV_INITRD
-/*
- * Relocate initrd if it is not completely within the linear mapping.
- * This would be the case if mem= cuts out all or part of it.
- */
-static void __init relocate_initrd(void)
-{
-	phys_addr_t orig_start = __virt_to_phys(initrd_start);
-	phys_addr_t orig_end = __virt_to_phys(initrd_end);
-	phys_addr_t ram_end = memblock_end_of_DRAM();
-	phys_addr_t new_start;
-	unsigned long size, to_free = 0;
-	void *dest;
-
-	if (orig_end <= ram_end)
-		return;
-
-	/*
-	 * Any of the original initrd which overlaps the linear map should
-	 * be freed after relocating.
-	 */
-	if (orig_start < ram_end)
-		to_free = ram_end - orig_start;
-
-	size = orig_end - orig_start;
-	if (!size)
-		return;
-
-	/* initrd needs to be relocated completely inside linear mapping */
-	new_start = memblock_find_in_range(0, PFN_PHYS(max_pfn),
-					   size, PAGE_SIZE);
-	if (!new_start)
-		panic("Cannot relocate initrd of size %ld\n", size);
-	memblock_reserve(new_start, size);
-
-	initrd_start = __phys_to_virt(new_start);
-	initrd_end   = initrd_start + size;
-
-	pr_info("Moving initrd from [%llx-%llx] to [%llx-%llx]\n",
-		orig_start, orig_start + size - 1,
-		new_start, new_start + size - 1);
-
-	dest = (void *)initrd_start;
-
-	if (to_free) {
-		memcpy(dest, (void *)__phys_to_virt(orig_start), to_free);
-		dest += to_free;
-	}
-
-	copy_from_early_mem(dest, orig_start + to_free, size - to_free);
-
-	if (to_free) {
-		pr_info("Freeing original RAMDISK from [%llx-%llx]\n",
-			orig_start, orig_start + to_free - 1);
-		memblock_free(orig_start, to_free);
-	}
-}
-#else
-static inline void __init relocate_initrd(void)
-{
-}
-#endif
-
 u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
@@ -327,7 +264,6 @@ void __init setup_arch(char **cmdline_p)
 	acpi_boot_table_init();
 
 	paging_init();
-	relocate_initrd();
 
 	kasan_init();
 

commit 588ab3f9afdfa1a6b1e5761c858b2c4ab6098285
Merge: 3d15cfdb1b77 2776e0e8ef68
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 17 20:03:47 2016 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
     "Here are the main arm64 updates for 4.6.  There are some relatively
      intrusive changes to support KASLR, the reworking of the kernel
      virtual memory layout and initial page table creation.
    
      Summary:
    
       - Initial page table creation reworked to avoid breaking large block
         mappings (huge pages) into smaller ones.  The ARM architecture
         requires break-before-make in such cases to avoid TLB conflicts but
         that's not always possible on live page tables
    
       - Kernel virtual memory layout: the kernel image is no longer linked
         to the bottom of the linear mapping (PAGE_OFFSET) but at the bottom
         of the vmalloc space, allowing the kernel to be loaded (nearly)
         anywhere in physical RAM
    
       - Kernel ASLR: position independent kernel Image and modules being
         randomly mapped in the vmalloc space with the randomness is
         provided by UEFI (efi_get_random_bytes() patches merged via the
         arm64 tree, acked by Matt Fleming)
    
       - Implement relative exception tables for arm64, required by KASLR
         (initial code for ARCH_HAS_RELATIVE_EXTABLE added to lib/extable.c
         but actual x86 conversion to deferred to 4.7 because of the merge
         dependencies)
    
       - Support for the User Access Override feature of ARMv8.2: this
         allows uaccess functions (get_user etc.) to be implemented using
         LDTR/STTR instructions.  Such instructions, when run by the kernel,
         perform unprivileged accesses adding an extra level of protection.
         The set_fs() macro is used to "upgrade" such instruction to
         privileged accesses via the UAO bit
    
       - Half-precision floating point support (part of ARMv8.2)
    
       - Optimisations for CPUs with or without a hardware prefetcher (using
         run-time code patching)
    
       - copy_page performance improvement to deal with 128 bytes at a time
    
       - Sanity checks on the CPU capabilities (via CPUID) to prevent
         incompatible secondary CPUs from being brought up (e.g.  weird
         big.LITTLE configurations)
    
       - valid_user_regs() reworked for better sanity check of the
         sigcontext information (restored pstate information)
    
       - ACPI parking protocol implementation
    
       - CONFIG_DEBUG_RODATA enabled by default
    
       - VDSO code marked as read-only
    
       - DEBUG_PAGEALLOC support
    
       - ARCH_HAS_UBSAN_SANITIZE_ALL enabled
    
       - Erratum workaround Cavium ThunderX SoC
    
       - set_pte_at() fix for PROT_NONE mappings
    
       - Code clean-ups"
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (99 commits)
      arm64: kasan: Fix zero shadow mapping overriding kernel image shadow
      arm64: kasan: Use actual memory node when populating the kernel image shadow
      arm64: Update PTE_RDONLY in set_pte_at() for PROT_NONE permission
      arm64: Fix misspellings in comments.
      arm64: efi: add missing frame pointer assignment
      arm64: make mrs_s prefixing implicit in read_cpuid
      arm64: enable CONFIG_DEBUG_RODATA by default
      arm64: Rework valid_user_regs
      arm64: mm: check at build time that PAGE_OFFSET divides the VA space evenly
      arm64: KVM: Move kvm_call_hyp back to its original localtion
      arm64: mm: treat memstart_addr as a signed quantity
      arm64: mm: list kernel sections in order
      arm64: lse: deal with clobbered IP registers after branch via PLT
      arm64: mm: dump: Use VA_START directly instead of private LOWEST_ADDR
      arm64: kconfig: add submenu for 8.2 architectural features
      arm64: kernel: acpi: fix ioremap in ACPI parking protocol cpu_postboot
      arm64: Add support for Half precision floating point
      arm64: Remove fixmap include fragility
      arm64: Add workaround for Cavium erratum 27456
      arm64: mm: Mark .rodata as RO
      ...

commit f80fb3a3d50843a401dac4b566b3b131da8077a2
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Jan 26 14:12:01 2016 +0100

    arm64: add support for kernel ASLR
    
    This adds support for KASLR is implemented, based on entropy provided by
    the bootloader in the /chosen/kaslr-seed DT property. Depending on the size
    of the address space (VA_BITS) and the page size, the entropy in the
    virtual displacement is up to 13 bits (16k/2 levels) and up to 25 bits (all
    4 levels), with the sidenote that displacements that result in the kernel
    image straddling a 1GB/32MB/512MB alignment boundary (for 4KB/16KB/64KB
    granule kernels, respectively) are not allowed, and will be rounded up to
    an acceptable value.
    
    If CONFIG_RANDOMIZE_MODULE_REGION_FULL is enabled, the module region is
    randomized independently from the core kernel. This makes it less likely
    that the location of core kernel data structures can be determined by an
    adversary, but causes all function calls from modules into the core kernel
    to be resolved via entries in the module PLTs.
    
    If CONFIG_RANDOMIZE_MODULE_REGION_FULL is not enabled, the module region is
    randomized by choosing a page aligned 128 MB region inside the interval
    [_etext - 128 MB, _stext + 128 MB). This gives between 10 and 14 bits of
    entropy (depending on page size), independently of the kernel randomization,
    but still guarantees that modules are within the range of relative branch
    and jump instructions (with the caveat that, since the module region is
    shared with other uses of the vmalloc area, modules may need to be loaded
    further away if the module region is exhausted)
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index cfed56f0ad26..42371f69def3 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -388,3 +388,32 @@ static int __init topology_init(void)
 	return 0;
 }
 subsys_initcall(topology_init);
+
+/*
+ * Dump out kernel offset information on panic.
+ */
+static int dump_kernel_offset(struct notifier_block *self, unsigned long v,
+			      void *p)
+{
+	u64 const kaslr_offset = kimage_vaddr - KIMAGE_VADDR;
+
+	if (IS_ENABLED(CONFIG_RANDOMIZE_BASE) && kaslr_offset > 0) {
+		pr_emerg("Kernel Offset: 0x%llx from 0x%lx\n",
+			 kaslr_offset, KIMAGE_VADDR);
+	} else {
+		pr_emerg("Kernel Offset: disabled\n");
+	}
+	return 0;
+}
+
+static struct notifier_block kernel_offset_notifier = {
+	.notifier_call = dump_kernel_offset
+};
+
+static int __init register_kernel_offset_dumper(void)
+{
+	atomic_notifier_chain_register(&panic_notifier_list,
+				       &kernel_offset_notifier);
+	return 0;
+}
+__initcall(register_kernel_offset_dumper);

commit 86ccce896cb0aa800a7a6dcd29b41ffc4eeb1a75
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Jan 25 11:44:59 2016 +0000

    arm64: unmap idmap earlier
    
    During boot we leave the idmap in place until paging_init, as we
    previously had to wait for the zero page to become allocated and
    accessible.
    
    Now that we have a statically-allocated zero page, we can uninstall the
    idmap much earlier in the boot process, making it far easier to spot
    accidental use of physical addresses. This also brings the cold boot
    path in line with the secondary boot path.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Tested-by: Jeremy Linton <jeremy.linton@arm.com>
    Cc: Laura Abbott <labbott@fedoraproject.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f6621ba071f9..cfed56f0ad26 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -314,6 +314,12 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	local_async_enable();
 
+	/*
+	 * TTBR0 is only used for the identity mapping at this stage. Make it
+	 * point to zero page to avoid speculatively fetching new entries.
+	 */
+	cpu_uninstall_idmap();
+
 	efi_init();
 	arm64_memblock_init();
 

commit 9e8e865bbe294a69666a1996bda3e87825b258c0
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Jan 25 11:44:58 2016 +0000

    arm64: unify idmap removal
    
    We currently open-code the removal of the idmap and restoration of the
    current task's MMU state in a few places.
    
    Before introducing yet more copies of this sequence, unify these to call
    a new helper, cpu_uninstall_idmap.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Tested-by: Jeremy Linton <jeremy.linton@arm.com>
    Cc: Laura Abbott <labbott@fedoraproject.org>
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 8119479147db..f6621ba071f9 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -62,6 +62,7 @@
 #include <asm/memblock.h>
 #include <asm/efi.h>
 #include <asm/xen/hypervisor.h>
+#include <asm/mmu_context.h>
 
 phys_addr_t __fdt_pointer __initdata;
 

commit 35d98e93fe6a7ab612f6b389ce42c1dc135d6eef
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue Jan 26 21:57:22 2016 +0100

    arch: Set IORESOURCE_SYSTEM_RAM flag for System RAM
    
    Set IORESOURCE_SYSTEM_RAM in flags of resource ranges with
    "System RAM", "Kernel code", "Kernel data", and "Kernel bss".
    
    Note that:
    
     - IORESOURCE_SYSRAM (i.e. modifier bit) is set in flags when
       IORESOURCE_MEM is already set. IORESOURCE_SYSTEM_RAM is defined
       as (IORESOURCE_MEM|IORESOURCE_SYSRAM).
    
     - Some archs do not set 'flags' for children nodes, such as
       "Kernel code".  This patch does not change 'flags' in this
       case.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-mips@linux-mips.org
    Cc: linux-mm <linux-mm@kvack.org>
    Cc: linux-parisc@vger.kernel.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: sparclinux@vger.kernel.org
    Link: http://lkml.kernel.org/r/1453841853-11383-7-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 8119479147db..450987d99b9b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -73,13 +73,13 @@ static struct resource mem_res[] = {
 		.name = "Kernel code",
 		.start = 0,
 		.end = 0,
-		.flags = IORESOURCE_MEM
+		.flags = IORESOURCE_SYSTEM_RAM
 	},
 	{
 		.name = "Kernel data",
 		.start = 0,
 		.end = 0,
-		.flags = IORESOURCE_MEM
+		.flags = IORESOURCE_SYSTEM_RAM
 	}
 };
 
@@ -210,7 +210,7 @@ static void __init request_standard_resources(void)
 		res->name  = "System RAM";
 		res->start = __pfn_to_phys(memblock_region_memory_base_pfn(region));
 		res->end = __pfn_to_phys(memblock_region_memory_end_pfn(region)) - 1;
-		res->flags = IORESOURCE_MEM | IORESOURCE_BUSY;
+		res->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;
 
 		request_resource(&iomem_resource, res);
 

commit 2dc10ad81fc017837037e60439662e1b16bdffb9
Merge: e627078a0cbd f8f8bdc48851
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 4 14:47:13 2015 -0800

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - "genirq: Introduce generic irq migration for cpu hotunplugged" patch
       merged from tip/irq/for-arm to allow the arm64-specific part to be
       upstreamed via the arm64 tree
    
     - CPU feature detection reworked to cope with heterogeneous systems
       where CPUs may not have exactly the same features.  The features
       reported by the kernel via internal data structures or ELF_HWCAP are
       delayed until all the CPUs are up (and before user space starts)
    
     - Support for 16KB pages, with the additional bonus of a 36-bit VA
       space, though the latter only depending on EXPERT
    
     - Implement native {relaxed, acquire, release} atomics for arm64
    
     - New ASID allocation algorithm which avoids IPI on roll-over, together
       with TLB invalidation optimisations (using local vs global where
       feasible)
    
     - KASan support for arm64
    
     - EFI_STUB clean-up and isolation for the kernel proper (required by
       KASan)
    
     - copy_{to,from,in}_user optimisations (sharing the memcpy template)
    
     - perf: moving arm64 to the arm32/64 shared PMU framework
    
     - L1_CACHE_BYTES increased to 128 to accommodate Cavium hardware
    
     - Support for the contiguous PTE hint on kernel mapping (16 consecutive
       entries may be able to use a single TLB entry)
    
     - Generic CONFIG_HZ now used on arm64
    
     - defconfig updates
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (91 commits)
      arm64/efi: fix libstub build under CONFIG_MODVERSIONS
      ARM64: Enable multi-core scheduler support by default
      arm64/efi: move arm64 specific stub C code to libstub
      arm64: page-align sections for DEBUG_RODATA
      arm64: Fix build with CONFIG_ZONE_DMA=n
      arm64: Fix compat register mappings
      arm64: Increase the max granular size
      arm64: remove bogus TASK_SIZE_64 check
      arm64: make Timer Interrupt Frequency selectable
      arm64/mm: use PAGE_ALIGNED instead of IS_ALIGNED
      arm64: cachetype: fix definitions of ICACHEF_* flags
      arm64: cpufeature: declare enable_cpu_capabilities as static
      genirq: Make the cpuhotplug migration code less noisy
      arm64: Constify hwcap name string arrays
      arm64/kvm: Make use of the system wide safe values
      arm64/debug: Make use of the system wide safe value
      arm64: Move FP/ASIMD hwcap handling to common code
      arm64/HWCAP: Use system wide safe values
      arm64/capabilities: Make use of system wide safe value
      arm64: Delay cpu feature capability checks
      ...

commit 12d11817eaafa414eeb47af684093eb2165ebe37
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Mon Oct 19 14:24:43 2015 +0100

    arm64: Move /proc/cpuinfo handling code
    
    This patch moves the /proc/cpuinfo handling code:
    
    arch/arm64/kernel/{setup.c to cpuinfo.c}
    
    No functional changes
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Tested-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index baf0da8c7d8a..556301fbeeef 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -28,7 +28,6 @@
 #include <linux/console.h>
 #include <linux/cache.h>
 #include <linux/bootmem.h>
-#include <linux/seq_file.h>
 #include <linux/screen_info.h>
 #include <linux/init.h>
 #include <linux/kexec.h>
@@ -44,7 +43,6 @@
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
-#include <linux/personality.h>
 #include <linux/psci.h>
 
 #include <asm/acpi.h>
@@ -381,124 +379,3 @@ static int __init topology_init(void)
 	return 0;
 }
 subsys_initcall(topology_init);
-
-static const char *hwcap_str[] = {
-	"fp",
-	"asimd",
-	"evtstrm",
-	"aes",
-	"pmull",
-	"sha1",
-	"sha2",
-	"crc32",
-	"atomics",
-	NULL
-};
-
-#ifdef CONFIG_COMPAT
-static const char *compat_hwcap_str[] = {
-	"swp",
-	"half",
-	"thumb",
-	"26bit",
-	"fastmult",
-	"fpa",
-	"vfp",
-	"edsp",
-	"java",
-	"iwmmxt",
-	"crunch",
-	"thumbee",
-	"neon",
-	"vfpv3",
-	"vfpv3d16",
-	"tls",
-	"vfpv4",
-	"idiva",
-	"idivt",
-	"vfpd32",
-	"lpae",
-	"evtstrm"
-};
-
-static const char *compat_hwcap2_str[] = {
-	"aes",
-	"pmull",
-	"sha1",
-	"sha2",
-	"crc32",
-	NULL
-};
-#endif /* CONFIG_COMPAT */
-
-static int c_show(struct seq_file *m, void *v)
-{
-	int i, j;
-
-	for_each_online_cpu(i) {
-		struct cpuinfo_arm64 *cpuinfo = &per_cpu(cpu_data, i);
-		u32 midr = cpuinfo->reg_midr;
-
-		/*
-		 * glibc reads /proc/cpuinfo to determine the number of
-		 * online processors, looking for lines beginning with
-		 * "processor".  Give glibc what it expects.
-		 */
-		seq_printf(m, "processor\t: %d\n", i);
-
-		/*
-		 * Dump out the common processor features in a single line.
-		 * Userspace should read the hwcaps with getauxval(AT_HWCAP)
-		 * rather than attempting to parse this, but there's a body of
-		 * software which does already (at least for 32-bit).
-		 */
-		seq_puts(m, "Features\t:");
-		if (personality(current->personality) == PER_LINUX32) {
-#ifdef CONFIG_COMPAT
-			for (j = 0; compat_hwcap_str[j]; j++)
-				if (compat_elf_hwcap & (1 << j))
-					seq_printf(m, " %s", compat_hwcap_str[j]);
-
-			for (j = 0; compat_hwcap2_str[j]; j++)
-				if (compat_elf_hwcap2 & (1 << j))
-					seq_printf(m, " %s", compat_hwcap2_str[j]);
-#endif /* CONFIG_COMPAT */
-		} else {
-			for (j = 0; hwcap_str[j]; j++)
-				if (elf_hwcap & (1 << j))
-					seq_printf(m, " %s", hwcap_str[j]);
-		}
-		seq_puts(m, "\n");
-
-		seq_printf(m, "CPU implementer\t: 0x%02x\n",
-			   MIDR_IMPLEMENTOR(midr));
-		seq_printf(m, "CPU architecture: 8\n");
-		seq_printf(m, "CPU variant\t: 0x%x\n", MIDR_VARIANT(midr));
-		seq_printf(m, "CPU part\t: 0x%03x\n", MIDR_PARTNUM(midr));
-		seq_printf(m, "CPU revision\t: %d\n\n", MIDR_REVISION(midr));
-	}
-
-	return 0;
-}
-
-static void *c_start(struct seq_file *m, loff_t *pos)
-{
-	return *pos < 1 ? (void *)1 : NULL;
-}
-
-static void *c_next(struct seq_file *m, void *v, loff_t *pos)
-{
-	++*pos;
-	return NULL;
-}
-
-static void c_stop(struct seq_file *m, void *v)
-{
-}
-
-const struct seq_operations cpuinfo_op = {
-	.start	= c_start,
-	.next	= c_next,
-	.stop	= c_stop,
-	.show	= c_show
-};

commit 9cdf8ec4a86b9310111f741bbaf11df9120e0482
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Mon Oct 19 14:24:41 2015 +0100

    arm64: Move cpu feature detection code
    
    This patch moves the CPU feature detection code from
     arch/arm64/kernel/{setup.c to cpufeature.c}
    
    The plan is to consolidate all the CPU feature handling
    in cpufeature.c.
    
    Apart from changing pr_fmt from "alternatives" to "cpu features",
    there are no functional changes.
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Tested-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 47e005141598..baf0da8c7d8a 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -65,23 +65,6 @@
 #include <asm/efi.h>
 #include <asm/xen/hypervisor.h>
 
-unsigned long elf_hwcap __read_mostly;
-EXPORT_SYMBOL_GPL(elf_hwcap);
-
-#ifdef CONFIG_COMPAT
-#define COMPAT_ELF_HWCAP_DEFAULT	\
-				(COMPAT_HWCAP_HALF|COMPAT_HWCAP_THUMB|\
-				 COMPAT_HWCAP_FAST_MULT|COMPAT_HWCAP_EDSP|\
-				 COMPAT_HWCAP_TLS|COMPAT_HWCAP_VFP|\
-				 COMPAT_HWCAP_VFPv3|COMPAT_HWCAP_VFPv4|\
-				 COMPAT_HWCAP_NEON|COMPAT_HWCAP_IDIV|\
-				 COMPAT_HWCAP_LPAE)
-unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
-unsigned int compat_elf_hwcap2 __read_mostly;
-#endif
-
-DECLARE_BITMAP(cpu_hwcaps, ARM64_NCAPS);
-
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -196,96 +179,6 @@ static void __init smp_build_mpidr_hash(void)
 	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
 }
 
-void __init setup_cpu_features(void)
-{
-	u64 features;
-	s64 block;
-	u32 cwg;
-	int cls;
-
-	/*
-	 * Check for sane CTR_EL0.CWG value.
-	 */
-	cwg = cache_type_cwg();
-	cls = cache_line_size();
-	if (!cwg)
-		pr_warn("No Cache Writeback Granule information, assuming cache line size %d\n",
-			cls);
-	if (L1_CACHE_BYTES < cls)
-		pr_warn("L1_CACHE_BYTES smaller than the Cache Writeback Granule (%d < %d)\n",
-			L1_CACHE_BYTES, cls);
-
-	/*
-	 * ID_AA64ISAR0_EL1 contains 4-bit wide signed feature blocks.
-	 * The blocks we test below represent incremental functionality
-	 * for non-negative values. Negative values are reserved.
-	 */
-	features = read_cpuid(ID_AA64ISAR0_EL1);
-	block = cpuid_feature_extract_field(features, 4);
-	if (block > 0) {
-		switch (block) {
-		default:
-		case 2:
-			elf_hwcap |= HWCAP_PMULL;
-		case 1:
-			elf_hwcap |= HWCAP_AES;
-		case 0:
-			break;
-		}
-	}
-
-	if (cpuid_feature_extract_field(features, 8) > 0)
-		elf_hwcap |= HWCAP_SHA1;
-
-	if (cpuid_feature_extract_field(features, 12) > 0)
-		elf_hwcap |= HWCAP_SHA2;
-
-	if (cpuid_feature_extract_field(features, 16) > 0)
-		elf_hwcap |= HWCAP_CRC32;
-
-	block = cpuid_feature_extract_field(features, 20);
-	if (block > 0) {
-		switch (block) {
-		default:
-		case 2:
-			elf_hwcap |= HWCAP_ATOMICS;
-		case 1:
-			/* RESERVED */
-		case 0:
-			break;
-		}
-	}
-
-#ifdef CONFIG_COMPAT
-	/*
-	 * ID_ISAR5_EL1 carries similar information as above, but pertaining to
-	 * the AArch32 32-bit execution state.
-	 */
-	features = read_cpuid(ID_ISAR5_EL1);
-	block = cpuid_feature_extract_field(features, 4);
-	if (block > 0) {
-		switch (block) {
-		default:
-		case 2:
-			compat_elf_hwcap2 |= COMPAT_HWCAP2_PMULL;
-		case 1:
-			compat_elf_hwcap2 |= COMPAT_HWCAP2_AES;
-		case 0:
-			break;
-		}
-	}
-
-	if (cpuid_feature_extract_field(features, 8) > 0)
-		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA1;
-
-	if (cpuid_feature_extract_field(features, 12) > 0)
-		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA2;
-
-	if (cpuid_feature_extract_field(features, 16) > 0)
-		compat_elf_hwcap2 |= COMPAT_HWCAP2_CRC32;
-#endif
-}
-
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
 	void *dt_virt = fixmap_remap_fdt(dt_phys);

commit 4b998ff1885eecd3dc330bf057e24667c1db84a4
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Mon Oct 19 14:24:40 2015 +0100

    arm64: Delay cpuinfo_store_boot_cpu
    
    At the moment the boot CPU stores the cpuinfo long before the
    PERCPU areas are initialised by the kernel. This could be problematic
    as the non-boot CPU data structures might get copied with the data
    from the boot CPU, giving us no chance to detect if a particular CPU
    updated its cpuinfo. This patch delays the boot cpu store to
    smp_prepare_boot_cpu().
    
    Also kills the setup_processor() which no longer does meaningful
    work.
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Tested-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4f0408e1df0d..47e005141598 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -286,13 +286,6 @@ void __init setup_cpu_features(void)
 #endif
 }
 
-static void __init setup_processor(void)
-{
-	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
-	sprintf(init_utsname()->machine, ELF_PLATFORM);
-	cpuinfo_store_boot_cpu();
-}
-
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
 	void *dt_virt = fixmap_remap_fdt(dt_phys);
@@ -404,8 +397,9 @@ u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
 {
-	setup_processor();
+	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
 
+	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code   = (unsigned long) _etext;
 	init_mm.end_data   = (unsigned long) _edata;

commit 3a75578efae64b94d76eacbf8adf2a3ab13c6aa1
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Mon Oct 19 14:24:39 2015 +0100

    arm64: Delay ELF HWCAP initialisation until all CPUs are up
    
    Delay the ELF HWCAP initialisation until all the (enabled) CPUs are
    up, i.e, smp_cpus_done(). This is in preparation for detecting the
    common features across the CPUS and creating a consistent ELF HWCAP
    for the system.
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Tested-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 1d503e2d6957..4f0408e1df0d 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -196,20 +196,13 @@ static void __init smp_build_mpidr_hash(void)
 	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
 }
 
-static void __init setup_processor(void)
+void __init setup_cpu_features(void)
 {
 	u64 features;
 	s64 block;
 	u32 cwg;
 	int cls;
 
-	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
-
-	sprintf(init_utsname()->machine, ELF_PLATFORM);
-	elf_hwcap = 0;
-
-	cpuinfo_store_boot_cpu();
-
 	/*
 	 * Check for sane CTR_EL0.CWG value.
 	 */
@@ -293,6 +286,13 @@ static void __init setup_processor(void)
 #endif
 }
 
+static void __init setup_processor(void)
+{
+	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
+	sprintf(init_utsname()->machine, ELF_PLATFORM);
+	cpuinfo_store_boot_cpu();
+}
+
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
 	void *dt_virt = fixmap_remap_fdt(dt_phys);

commit 64f17818977d0989f7d05347670777611b295799
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Mon Oct 19 14:24:38 2015 +0100

    arm64: Make the CPU information more clear
    
    At early boot, we print the CPU version/revision. On a heterogeneous
    system, we could have different types of CPUs. Print the CPU info for
    all active cpus. Also, the secondary CPUs prints the message only when
    they turn online.
    
    Also, remove the redundant 'revision' information which doesn't
    make any sense without the 'variant' field.
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Tested-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 79df79a2ea61..1d503e2d6957 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -203,8 +203,7 @@ static void __init setup_processor(void)
 	u32 cwg;
 	int cls;
 
-	printk("CPU: AArch64 Processor [%08x] revision %d\n",
-	       read_cpuid_id(), read_cpuid_id() & 15);
+	pr_info("Boot CPU: AArch64 Processor [%08x]\n", read_cpuid_id());
 
 	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;

commit 39d114ddc68223022c12ae3a1573912bc4b585e5
Author: Andrey Ryabinin <ryabinin.a.a@gmail.com>
Date:   Mon Oct 12 18:52:58 2015 +0300

    arm64: add KASAN support
    
    This patch adds arch specific code for kernel address sanitizer
    (see Documentation/kasan.txt).
    
    1/8 of kernel addresses reserved for shadow memory. There was no
    big enough hole for this, so virtual addresses for shadow were
    stolen from vmalloc area.
    
    At early boot stage the whole shadow region populated with just
    one physical page (kasan_zero_page). Later, this page reused
    as readonly zero shadow for some memory that KASan currently
    don't track (vmalloc).
    After mapping the physical memory, pages for shadow memory are
    allocated and mapped.
    
    Functions like memset/memmove/memcpy do a lot of memory accesses.
    If bad pointer passed to one of these function it is important
    to catch this. Compiler's instrumentation cannot do this since
    these functions are written in assembly.
    KASan replaces memory functions with manually instrumented variants.
    Original functions declared as weak symbols so strong definitions
    in mm/kasan/kasan.c could replace them. Original functions have aliases
    with '__' prefix in name, so we could call non-instrumented variant
    if needed.
    Some files built without kasan instrumentation (e.g. mm/slub.c).
    Original mem* function replaced (via #define) with prefixed variants
    to disable memory access checks for such files.
    
    Signed-off-by: Andrey Ryabinin <ryabinin.a.a@gmail.com>
    Tested-by: Linus Walleij <linus.walleij@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 6bab21f84a9f..79df79a2ea61 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -54,6 +54,7 @@
 #include <asm/elf.h>
 #include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
+#include <asm/kasan.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
 #include <asm/smp_plat.h>
@@ -434,6 +435,9 @@ void __init setup_arch(char **cmdline_p)
 
 	paging_init();
 	relocate_initrd();
+
+	kasan_init();
+
 	request_standard_resources();
 
 	early_ioremap_reset();

commit 4ca3bc86bea23f38596ce7508f75e072839bde44
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Oct 6 18:24:37 2015 +0100

    arm64: Don't relocate non-existent initrd
    
    When booting a kernel without an initrd, the kernel reports that it
    moves -1 bytes worth, having gone through the motions with initrd_start
    equal to initrd_end:
    
        Moving initrd from [4080000000-407fffffff] to [9fff49000-9fff48fff]
    
    Prevent this by bailing out early when the initrd size is zero (i.e. we
    have no initrd), avoiding the confusing message and other associated
    work.
    
    Fixes: 1570f0d7ab425c1e ("arm64: support initrd outside kernel linear map")
    Cc: Mark Salter <msalter@redhat.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 6bab21f84a9f..232247945b1c 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -364,6 +364,8 @@ static void __init relocate_initrd(void)
 		to_free = ram_end - orig_start;
 
 	size = orig_end - orig_start;
+	if (!size)
+		return;
 
 	/* initrd needs to be relocated completely inside linear mapping */
 	new_start = memblock_find_in_range(0, PFN_PHYS(max_pfn),

commit 1570f0d7ab425c1e0905715bf9cc98b2a82e723f
Author: Mark Salter <msalter@redhat.com>
Date:   Tue Sep 8 15:03:04 2015 -0700

    arm64: support initrd outside kernel linear map
    
    The use of mem= could leave part or all of the initrd outside of the
    kernel linear map.  This will lead to an error when unpacking the initrd
    and a probable failure to boot.  This patch catches that situation and
    relocates the initrd to be fully within the linear map.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 888478881243..6bab21f84a9f 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -339,6 +339,67 @@ static void __init request_standard_resources(void)
 	}
 }
 
+#ifdef CONFIG_BLK_DEV_INITRD
+/*
+ * Relocate initrd if it is not completely within the linear mapping.
+ * This would be the case if mem= cuts out all or part of it.
+ */
+static void __init relocate_initrd(void)
+{
+	phys_addr_t orig_start = __virt_to_phys(initrd_start);
+	phys_addr_t orig_end = __virt_to_phys(initrd_end);
+	phys_addr_t ram_end = memblock_end_of_DRAM();
+	phys_addr_t new_start;
+	unsigned long size, to_free = 0;
+	void *dest;
+
+	if (orig_end <= ram_end)
+		return;
+
+	/*
+	 * Any of the original initrd which overlaps the linear map should
+	 * be freed after relocating.
+	 */
+	if (orig_start < ram_end)
+		to_free = ram_end - orig_start;
+
+	size = orig_end - orig_start;
+
+	/* initrd needs to be relocated completely inside linear mapping */
+	new_start = memblock_find_in_range(0, PFN_PHYS(max_pfn),
+					   size, PAGE_SIZE);
+	if (!new_start)
+		panic("Cannot relocate initrd of size %ld\n", size);
+	memblock_reserve(new_start, size);
+
+	initrd_start = __phys_to_virt(new_start);
+	initrd_end   = initrd_start + size;
+
+	pr_info("Moving initrd from [%llx-%llx] to [%llx-%llx]\n",
+		orig_start, orig_start + size - 1,
+		new_start, new_start + size - 1);
+
+	dest = (void *)initrd_start;
+
+	if (to_free) {
+		memcpy(dest, (void *)__phys_to_virt(orig_start), to_free);
+		dest += to_free;
+	}
+
+	copy_from_early_mem(dest, orig_start + to_free, size - to_free);
+
+	if (to_free) {
+		pr_info("Freeing original RAMDISK from [%llx-%llx]\n",
+			orig_start, orig_start + to_free - 1);
+		memblock_free(orig_start, to_free);
+	}
+}
+#else
+static inline void __init relocate_initrd(void)
+{
+}
+#endif
+
 u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
@@ -372,6 +433,7 @@ void __init setup_arch(char **cmdline_p)
 	acpi_boot_table_init();
 
 	paging_init();
+	relocate_initrd();
 	request_standard_resources();
 
 	early_ioremap_reset();

commit a4fdb2a46f617b8b2cd47acec026ec16532edbc6
Merge: 807249d3ada1 674c242c9323
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 4 07:18:09 2015 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Will Deacon:
    
     - Support for new architectural features introduced in ARMv8.1:
       * Privileged Access Never (PAN) to catch user pointer dereferences in
         the kernel
       * Large System Extension (LSE) for building scalable atomics and locks
         (depends on locking/arch-atomic from tip, which is included here)
       * Hardware Dirty Bit Management (DBM) for updating clean PTEs
         automatically
    
     - Move our PSCI implementation out into drivers/firmware/, where it can
       be shared with arch/arm/. RMK has also pulled this component branch
       and has additional patches moving arch/arm/ over. MAINTAINERS is
       updated accordingly.
    
     - Better BUG implementation based on the BRK instruction for trapping
    
     - Leaf TLB invalidation for unmapping user pages
    
     - Support for PROBE_ONLY PCI configurations
    
     - Various cleanups and non-critical fixes, including:
       * Always flush FP/SIMD state over exec()
       * Restrict memblock additions based on range of linear mapping
       * Ensure *(LIST_POISON) generates a fatal fault
       * Context-tracking syscall return no longer corrupts return value when
         not forced on.
       * Alternatives patching synchronisation/stability improvements
       * Signed sub-word cmpxchg compare fix (tickled by HAVE_CMPXCHG_LOCAL)
       * Force SMP=y
       * Hide direct DCC access from userspace
       * Fix EFI stub memory allocation when DRAM starts at 0x0
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (92 commits)
      arm64: flush FP/SIMD state correctly after execve()
      arm64: makefile: fix perf_callchain.o kconfig dependency
      arm64: set MAX_MEMBLOCK_ADDR according to linear region size
      of/fdt: make memblock maximum physical address arch configurable
      arm64: Fix source code file path in comments
      arm64: entry: always restore x0 from the stack on syscall return
      arm64: mdscr_el1: avoid exposing DCC to userspace
      arm64: kconfig: Move LIST_POISON to a safe value
      arm64: Add __exception_irq_entry definition for function graph
      arm64: mm: ensure patched kernel text is fetched from PoU
      arm64: alternatives: ensure secondary CPUs execute ISB after patching
      arm64: make ll/sc __cmpxchg_case_##name asm consistent
      arm64: dma-mapping: Simplify pgprot handling
      arm64: restore cpu suspend/resume functionality
      ARM64: PCI: do not enable resources on PROBE_ONLY systems
      arm64: cmpxchg: truncate sub-word signed types before comparison
      arm64: alternative: put secondary CPUs into polling loop during patch
      arm64/Documentation: clarify wording regarding memory below the Image
      arm64: lse: fix lse cmpxchg code indentation
      arm64: remove redundant object file list
      ...

commit c706c7eb0d08098f0d768aeef945d7cf1f8858b4
Merge: 79b0691d0c1d 3ff32a0def6e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 3 16:27:01 2015 -0700

    Merge branch 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm
    
    Pull ARM development updates from Russell King:
     "Included in this update:
    
       - moving PSCI code from ARM64/ARM to drivers/
    
       - removal of some architecture internals from global kernel view
    
       - addition of software based "privileged no access" support using the
         old domains register to turn off the ability for kernel
         loads/stores to access userspace.  Only the proper accessors will
         be usable.
    
       - addition of early fixup support for early console
    
       - re-addition (and reimplementation) of OMAP special interconnect
         barrier
    
       - removal of finish_arch_switch()
    
       - only expose cpuX/online in sysfs if hotpluggable
    
       - a number of code cleanups"
    
    * 'for-linus' of git://ftp.arm.linux.org.uk/~rmk/linux-arm: (41 commits)
      ARM: software-based priviledged-no-access support
      ARM: entry: provide uaccess assembly macro hooks
      ARM: entry: get rid of multiple macro definitions
      ARM: 8421/1: smp: Collapse arch_cpu_idle_dead() into cpu_die()
      ARM: uaccess: provide uaccess_save_and_enable() and uaccess_restore()
      ARM: mm: improve do_ldrd_abort macro
      ARM: entry: ensure that IRQs are enabled when calling syscall_trace_exit()
      ARM: entry: efficiency cleanups
      ARM: entry: get rid of asm_trace_hardirqs_on_cond
      ARM: uaccess: simplify user access assembly
      ARM: domains: remove DOMAIN_TABLE
      ARM: domains: keep vectors in separate domain
      ARM: domains: get rid of manager mode for user domain
      ARM: domains: move initial domain setting value to asm/domains.h
      ARM: domains: provide domain_mask()
      ARM: domains: switch to keeping domain value in register
      ARM: 8419/1: dma-mapping: harmonize definition of DMA_ERROR_CODE
      ARM: 8417/1: refactor bitops functions with BIT_MASK() and BIT_WORD()
      ARM: 8416/1: Feroceon: use of_iomap() to map register base
      ARM: 8415/1: early fixmap support for earlycon
      ...

commit d422e62562e0dcef0ace4cd4fc4b4519d0a55ab4
Merge: 8ec41987436d 514f161abcda
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Aug 5 14:14:06 2015 +0100

    Merge branch 'aarch64/psci/drivers' into aarch64/for-next/core
    
    Move our PSCI implementation out into drivers/firmware/ where it can be
    shared with arch/arm/.
    
    Conflicts:
            arch/arm64/kernel/psci.c

commit bff60792f994a87324ab57e89e945b4572b1ef77
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Jul 31 15:46:16 2015 +0100

    arm64: psci: factor invocation code to drivers
    
    To enable sharing with arm, move the core PSCI framework code to
    drivers/firmware. This results in a minor gain in lines of code, but
    this will quickly be amortised by the removal of code currently
    duplicated in arch/arm.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Hanjun Guo <hanjun.guo@linaro.org>
    Tested-by: Hanjun Guo <hanjun.guo@linaro.org>
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f3067d4d4e35..96ce26428f82 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -46,6 +46,7 @@
 #include <linux/of_platform.h>
 #include <linux/efi.h>
 #include <linux/personality.h>
+#include <linux/psci.h>
 
 #include <asm/acpi.h>
 #include <asm/fixmap.h>
@@ -61,7 +62,6 @@
 #include <asm/tlbflush.h>
 #include <asm/traps.h>
 #include <asm/memblock.h>
-#include <asm/psci.h>
 #include <asm/efi.h>
 #include <asm/virt.h>
 #include <asm/xen/hypervisor.h>

commit 377bcff9a38a78083d7fff8e8a41cc894cf7813b
Author: Jonas Rabenstein <jonas.rabenstein@studium.uni-erlangen.de>
Date:   Wed Jul 29 12:07:57 2015 +0100

    arm64: remove dead-code depending on CONFIG_UP_LATE_INIT
    
    Commit 4b3dc9679cf7 ("arm64: force CONFIG_SMP=y and remove redundant
    and therfore can not be selected anymore.
    
    Remove dead #ifdef-block depending on UP_LATE_INIT in
    arch/arm64/kernel/setup.c
    
    Signed-off-by: Jonas Rabenstein <jonas.rabenstein@studium.uni-erlangen.de>
    [will: kill do_post_cpus_up_work altogether]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index be65ecc89e82..0c8fd975306b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -63,7 +63,6 @@
 #include <asm/memblock.h>
 #include <asm/psci.h>
 #include <asm/efi.h>
-#include <asm/virt.h>
 #include <asm/xen/hypervisor.h>
 
 unsigned long elf_hwcap __read_mostly;
@@ -197,30 +196,6 @@ static void __init smp_build_mpidr_hash(void)
 	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
 }
 
-static void __init hyp_mode_check(void)
-{
-	if (is_hyp_mode_available())
-		pr_info("CPU: All CPU(s) started at EL2\n");
-	else if (is_hyp_mode_mismatched())
-		WARN_TAINT(1, TAINT_CPU_OUT_OF_SPEC,
-			   "CPU: CPUs started in inconsistent modes");
-	else
-		pr_info("CPU: All CPU(s) started at EL1\n");
-}
-
-void __init do_post_cpus_up_work(void)
-{
-	hyp_mode_check();
-	apply_alternatives_all();
-}
-
-#ifdef CONFIG_UP_LATE_INIT
-void __init up_late_init(void)
-{
-	do_post_cpus_up_work();
-}
-#endif /* CONFIG_UP_LATE_INIT */
-
 static void __init setup_processor(void)
 {
 	u64 features;

commit 309585b0b931b291d0525b2830161ee76a2f23ff
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jul 27 16:55:32 2015 +0100

    arm64: elf: use cpuid_feature_extract_field for hwcap detection
    
    cpuid_feature_extract_field takes care of the fiddly ID register
    field sign-extension, so use that instead of rolling our own version.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b2f9895ecf7b..be65ecc89e82 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -223,7 +223,8 @@ void __init up_late_init(void)
 
 static void __init setup_processor(void)
 {
-	u64 features, block;
+	u64 features;
+	s64 block;
 	u32 cwg;
 	int cls;
 
@@ -253,8 +254,8 @@ static void __init setup_processor(void)
 	 * for non-negative values. Negative values are reserved.
 	 */
 	features = read_cpuid(ID_AA64ISAR0_EL1);
-	block = (features >> 4) & 0xf;
-	if (!(block & 0x8)) {
+	block = cpuid_feature_extract_field(features, 4);
+	if (block > 0) {
 		switch (block) {
 		default:
 		case 2:
@@ -266,20 +267,17 @@ static void __init setup_processor(void)
 		}
 	}
 
-	block = (features >> 8) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 8) > 0)
 		elf_hwcap |= HWCAP_SHA1;
 
-	block = (features >> 12) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 12) > 0)
 		elf_hwcap |= HWCAP_SHA2;
 
-	block = (features >> 16) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 16) > 0)
 		elf_hwcap |= HWCAP_CRC32;
 
-	block = (features >> 20) & 0xf;
-	if (!(block & 0x8)) {
+	block = cpuid_feature_extract_field(features, 20);
+	if (block > 0) {
 		switch (block) {
 		default:
 		case 2:
@@ -294,11 +292,11 @@ static void __init setup_processor(void)
 #ifdef CONFIG_COMPAT
 	/*
 	 * ID_ISAR5_EL1 carries similar information as above, but pertaining to
-	 * the Aarch32 32-bit execution state.
+	 * the AArch32 32-bit execution state.
 	 */
 	features = read_cpuid(ID_ISAR5_EL1);
-	block = (features >> 4) & 0xf;
-	if (!(block & 0x8)) {
+	block = cpuid_feature_extract_field(features, 4);
+	if (block > 0) {
 		switch (block) {
 		default:
 		case 2:
@@ -310,16 +308,13 @@ static void __init setup_processor(void)
 		}
 	}
 
-	block = (features >> 8) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 8) > 0)
 		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA1;
 
-	block = (features >> 12) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 12) > 0)
 		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA2;
 
-	block = (features >> 16) & 0xf;
-	if (block && !(block & 0x8))
+	if (cpuid_feature_extract_field(features, 16) > 0)
 		compat_elf_hwcap2 |= COMPAT_HWCAP2_CRC32;
 #endif
 }

commit 2e94da13790336eb3fd00fb5e97610dd9aebe213
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jul 27 16:23:58 2015 +0100

    arm64: lse: use generic cpufeature detection for LSE atomics
    
    Rework the cpufeature detection to support ISAR0 and use that for
    detecting the presence of LSE atomics.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 82ae8429baf2..b2f9895ecf7b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -284,10 +284,6 @@ static void __init setup_processor(void)
 		default:
 		case 2:
 			elf_hwcap |= HWCAP_ATOMICS;
-			cpus_set_cap(ARM64_HAS_LSE_ATOMICS);
-			if (IS_ENABLED(CONFIG_AS_LSE) &&
-			    IS_ENABLED(CONFIG_ARM64_LSE_ATOMICS))
-				pr_info("LSE atomics supported\n");
 		case 1:
 			/* RESERVED */
 		case 0:

commit c739dc83a0b6db01abfbcc5246a30c7a575e4272
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jul 27 14:11:55 2015 +0100

    arm64: lse: rename ARM64_CPU_FEAT_LSE_ATOMICS for consistency
    
    Other CPU features follow an 'ARM64_HAS_*' naming scheme, so do the same
    for the LSE atomics.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 97785c01acbf..82ae8429baf2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -284,7 +284,7 @@ static void __init setup_processor(void)
 		default:
 		case 2:
 			elf_hwcap |= HWCAP_ATOMICS;
-			cpus_set_cap(ARM64_CPU_FEAT_LSE_ATOMICS);
+			cpus_set_cap(ARM64_HAS_LSE_ATOMICS);
 			if (IS_ENABLED(CONFIG_AS_LSE) &&
 			    IS_ENABLED(CONFIG_ARM64_LSE_ATOMICS))
 				pr_info("LSE atomics supported\n");

commit c09d6a04d17d730b0463207a26ece082772b59ee
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 3 16:14:13 2015 +0000

    arm64: atomics: patch in lse instructions when supported by the CPU
    
    On CPUs which support the LSE atomic instructions introduced in ARMv8.1,
    it makes sense to use them in preference to ll/sc sequences.
    
    This patch introduces runtime patching of atomic_t and atomic64_t
    routines so that the call-site for the out-of-line ll/sc sequences is
    patched with an LSE atomic instruction when we detect that
    the CPU supports it.
    
    If binutils is not recent enough to assemble the LSE instructions, then
    the ll/sc sequences are inlined as though CONFIG_ARM64_LSE_ATOMICS=n.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f4fbbc884893..97785c01acbf 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -285,6 +285,9 @@ static void __init setup_processor(void)
 		case 2:
 			elf_hwcap |= HWCAP_ATOMICS;
 			cpus_set_cap(ARM64_CPU_FEAT_LSE_ATOMICS);
+			if (IS_ENABLED(CONFIG_AS_LSE) &&
+			    IS_ENABLED(CONFIG_ARM64_LSE_ATOMICS))
+				pr_info("LSE atomics supported\n");
 		case 1:
 			/* RESERVED */
 		case 0:

commit d964b7229e7f94428a1e8d26999adffbe8a69db2
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Feb 4 12:17:55 2015 +0000

    arm64: alternatives: add cpu feature for lse atomics
    
    Add a CPU feature for the LSE atomic instructions, so that they can be
    patched in at runtime when we detect that they are supported.
    
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b2f9895ecf7b..f4fbbc884893 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -284,6 +284,7 @@ static void __init setup_processor(void)
 		default:
 		case 2:
 			elf_hwcap |= HWCAP_ATOMICS;
+			cpus_set_cap(ARM64_CPU_FEAT_LSE_ATOMICS);
 		case 1:
 			/* RESERVED */
 		case 0:

commit 40a1db2434a1b62332b1af25cfa14d7b8c0301fe
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jan 26 18:46:19 2015 +0000

    arm64: elf: advertise 8.1 atomic instructions as new hwcap
    
    The ARM v8.1 architecture introduces new atomic instructions to the A64
    instruction set for things like cmpxchg, so advertise their availability
    to userspace using a hwcap.
    
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index e7a1e719f127..b2f9895ecf7b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -278,6 +278,19 @@ static void __init setup_processor(void)
 	if (block && !(block & 0x8))
 		elf_hwcap |= HWCAP_CRC32;
 
+	block = (features >> 20) & 0xf;
+	if (!(block & 0x8)) {
+		switch (block) {
+		default:
+		case 2:
+			elf_hwcap |= HWCAP_ATOMICS;
+		case 1:
+			/* RESERVED */
+		case 0:
+			break;
+		}
+	}
+
 #ifdef CONFIG_COMPAT
 	/*
 	 * ID_ISAR5_EL1 carries similar information as above, but pertaining to
@@ -457,6 +470,7 @@ static const char *hwcap_str[] = {
 	"sha1",
 	"sha2",
 	"crc32",
+	"atomics",
 	NULL
 };
 

commit e094d44568680d4e5e2722c4ad090ff0810719b9
Author: Sudeep Holla <sudeep.holla@arm.com>
Date:   Thu Jul 23 18:28:26 2015 +0100

    arm64: kernel: remove non-legit DT warnings when booting using ACPI
    
    Since both CONFIG_ACPI and CONFIG_OF are enabled when booting using ACPI
    tables on ARM64 platforms, we get few device tree warnings which are not
    valid for ACPI boot. We can use of_have_populated_dt to check if the
    device tree is populated or not before throwing out those errors.
    
    This patch uses of_have_populated_dt to remove non legitimate device
    tree warning when booting using ACPI tables.
    
    Cc: Lorenzo Pieralisi <Lorenzo.Pieralisi@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index cf609cf3fcb5..e7a1e719f127 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -423,8 +423,13 @@ void __init setup_arch(char **cmdline_p)
 
 static int __init arm64_device_init(void)
 {
-	of_iommu_init();
-	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
+	if (of_have_populated_dt()) {
+		of_iommu_init();
+		of_platform_populate(NULL, of_default_bus_match_table,
+				     NULL, NULL);
+	} else if (acpi_disabled) {
+		pr_crit("Device tree not populated\n");
+	}
 	return 0;
 }
 arch_initcall_sync(arm64_device_init);

commit 4b3dc9679cf779339d9049800803dfc3c83433d1
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri May 29 18:28:44 2015 +0100

    arm64: force CONFIG_SMP=y and remove redundant #ifdefs
    
    Nobody seems to be producing !SMP systems anymore, so this is just
    becoming a source of kernel bugs, particularly if people want to use
    coherent DMA with non-shared pages.
    
    This patch forces CONFIG_SMP=y for arm64, removing a modest amount of
    code in the process.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f3067d4d4e35..cf609cf3fcb5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -131,7 +131,6 @@ bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
 }
 
 struct mpidr_hash mpidr_hash;
-#ifdef CONFIG_SMP
 /**
  * smp_build_mpidr_hash - Pre-compute shifts required at each affinity
  *			  level in order to build a linear index from an
@@ -197,7 +196,6 @@ static void __init smp_build_mpidr_hash(void)
 		pr_warn("Large number of MPIDR hash buckets detected\n");
 	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
 }
-#endif
 
 static void __init hyp_mode_check(void)
 {
@@ -405,10 +403,8 @@ void __init setup_arch(char **cmdline_p)
 	xen_early_init();
 
 	cpu_read_bootcpu_ops();
-#ifdef CONFIG_SMP
 	smp_init_cpus();
 	smp_build_mpidr_hash();
-#endif
 
 #ifdef CONFIG_VT
 #if defined(CONFIG_VGA_CONSOLE)
@@ -508,9 +504,7 @@ static int c_show(struct seq_file *m, void *v)
 		 * online processors, looking for lines beginning with
 		 * "processor".  Give glibc what it expects.
 		 */
-#ifdef CONFIG_SMP
 		seq_printf(m, "processor\t: %d\n", i);
-#endif
 
 		/*
 		 * Dump out the common processor features in a single line.

commit d4e14ca303e0e6aa56e1573a38ff91b8eb121600
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Fri Jun 19 15:00:46 2015 -0700

    arm64: Remove clk-provider.h include
    
    This file doesn't use the clk provider APIs. Remove the include.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f3067d4d4e35..926ae8d9abc5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -34,7 +34,6 @@
 #include <linux/kexec.h>
 #include <linux/crash_dump.h>
 #include <linux/root_dev.h>
-#include <linux/clk-provider.h>
 #include <linux/cpu.h>
 #include <linux/interrupt.h>
 #include <linux/smp.h>

commit 7adf12b87f45a77d364464018fb8e9e1ac875152
Merge: 02201e3f1b46 6684fa1cdb1e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 1 11:53:46 2015 -0700

    Merge tag 'for-linus-4.2-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip
    
    Pull xen updates from David Vrabel:
     "Xen features and cleanups for 4.2-rc0:
    
       - add "make xenconfig" to assist in generating configs for Xen guests
    
       - preparatory cleanups necessary for supporting 64 KiB pages in ARM
         guests
    
       - automatically use hvc0 as the default console in ARM guests"
    
    * tag 'for-linus-4.2-rc0-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip:
      block/xen-blkback: s/nr_pages/nr_segs/
      block/xen-blkfront: Remove invalid comment
      block/xen-blkfront: Remove unused macro MAXIMUM_OUTSTANDING_BLOCK_REQS
      arm/xen: Drop duplicate define mfn_to_virt
      xen/grant-table: Remove unused macro SPP
      xen/xenbus: client: Fix call of virt_to_mfn in xenbus_grant_ring
      xen: Include xen/page.h rather than asm/xen/page.h
      kconfig: add xenconfig defconfig helper
      kconfig: clarify kvmconfig is for kvm
      xen/pcifront: Remove usage of struct timeval
      xen/tmem: use BUILD_BUG_ON() in favor of BUG_ON()
      hvc_xen: avoid uninitialized variable warning
      xenbus: avoid uninitialized variable warning
      xen/arm: allow console=hvc0 to be omitted for guests
      arm,arm64/xen: move Xen initialization earlier
      arm/xen: Correctly check if the event channel interrupt is present

commit 61bd93ce801bb6df36eda257a9d2d16c02863cdd
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Jun 1 13:40:32 2015 +0200

    arm64: use fixmap region for permanent FDT mapping
    
    Currently, the FDT blob needs to be in the same 512 MB region as
    the kernel, so that it can be mapped into the kernel virtual memory
    space very early on using a minimal set of statically allocated
    translation tables.
    
    Now that we have early fixmap support, we can relax this restriction,
    by moving the permanent FDT mapping to the fixmap region instead.
    This way, the FDT blob may be anywhere in memory.
    
    This also moves the vetting of the FDT to mmu.c, since the early
    init code in head.S does not handle mapping of the FDT anymore.
    At the same time, fix up some comments in head.S that have gone stale.
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 508cca1f8dce..ffd3970721bf 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -105,18 +105,6 @@ static struct resource mem_res[] = {
 #define kernel_code mem_res[0]
 #define kernel_data mem_res[1]
 
-void __init early_print(const char *str, ...)
-{
-	char buf[256];
-	va_list ap;
-
-	va_start(ap, str);
-	vsnprintf(buf, sizeof(buf), str, ap);
-	va_end(ap);
-
-	printk("%s", buf);
-}
-
 /*
  * The recorded values of x0 .. x3 upon kernel entry.
  */
@@ -326,12 +314,14 @@ static void __init setup_processor(void)
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
-	if (!dt_phys || !early_init_dt_scan(phys_to_virt(dt_phys))) {
-		early_print("\n"
-			"Error: invalid device tree blob at physical address 0x%p (virtual address 0x%p)\n"
-			"The dtb must be 8-byte aligned and passed in the first 512MB of memory\n"
-			"\nPlease check your bootloader.\n",
-			dt_phys, phys_to_virt(dt_phys));
+	void *dt_virt = fixmap_remap_fdt(dt_phys);
+
+	if (!dt_virt || !early_init_dt_scan(dt_virt)) {
+		pr_crit("\n"
+			"Error: invalid device tree blob at physical address %pa (virtual address 0x%p)\n"
+			"The dtb must be 8-byte aligned and must not exceed 2 MB in size\n"
+			"\nPlease check your bootloader.",
+			&dt_phys, dt_virt);
 
 		while (true)
 			cpu_relax();
@@ -374,8 +364,6 @@ void __init setup_arch(char **cmdline_p)
 {
 	setup_processor();
 
-	setup_machine_fdt(__fdt_pointer);
-
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code   = (unsigned long) _etext;
 	init_mm.end_data   = (unsigned long) _edata;
@@ -386,6 +374,8 @@ void __init setup_arch(char **cmdline_p)
 	early_fixmap_init();
 	early_ioremap_init();
 
+	setup_machine_fdt(__fdt_pointer);
+
 	parse_early_param();
 
 	/*

commit 5882bfef6327093bff63569be19795170ff71e5f
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Wed May 6 14:13:31 2015 +0000

    arm,arm64/xen: move Xen initialization earlier
    
    Currently, Xen is initialized/discovered in an initcall. This doesn't
    allow us to support earlyprintk or choosing the preferred console when
    running on Xen.
    
    The current function xen_guest_init is now split in 2 parts:
        - xen_early_init: Check if there is a Xen node in the device tree
        and setup domain type
        - xen_guest_init: Retrieve the information from the device node and
        initialize Xen (grant table, shared page...)
    
    The former is called in setup_arch, while the latter is an initcall.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Signed-off-by: Julien Grall <julien.grall@linaro.org>
    Acked-by: Ian Campbell <ian.campbell@citrix.com>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 74753132c3ac..1b36ba9b73ac 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -64,6 +64,7 @@
 #include <asm/psci.h>
 #include <asm/efi.h>
 #include <asm/virt.h>
+#include <asm/xen/hypervisor.h>
 
 unsigned long elf_hwcap __read_mostly;
 EXPORT_SYMBOL_GPL(elf_hwcap);
@@ -416,6 +417,7 @@ void __init setup_arch(char **cmdline_p)
 		psci_acpi_init();
 		acpi_init_cpus();
 	}
+	xen_early_init();
 
 #ifdef CONFIG_SMP
 	smp_build_mpidr_hash();

commit 0f0783365cbb7ec13a8f02198f6e1a146d94a5a9
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Wed May 13 14:12:47 2015 +0100

    ARM64: kernel: unify ACPI and DT cpus initialization
    
    The code that initializes cpus on arm64 is currently split in two
    different code paths that carry out DT and ACPI cpus initialization.
    
    Most of the code executing SMP initialization is common and should
    be merged to reduce discrepancies between ACPI and DT initialization
    and to have code initializing cpus in a single common place in the
    kernel.
    
    This patch refactors arm64 SMP cpus initialization code to merge
    ACPI and DT boot paths in a common file and to create sanity
    checks that can be reused by both boot methods.
    
    Current code assumes PSCI is the only available boot method
    when arm64 boots with ACPI; this can be easily extended if/when
    the ACPI parking protocol is merged into the kernel.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Hanjun Guo <hanjun.guo@linaro.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Hanjun Guo <hanjun.guo@linaro.org>
    Tested-by: Mark Rutland <mark.rutland@arm.com> [DT]
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 74753132c3ac..508cca1f8dce 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -408,16 +408,13 @@ void __init setup_arch(char **cmdline_p)
 	if (acpi_disabled) {
 		unflatten_device_tree();
 		psci_dt_init();
-		cpu_read_bootcpu_ops();
-#ifdef CONFIG_SMP
-		of_smp_init_cpus();
-#endif
 	} else {
 		psci_acpi_init();
-		acpi_init_cpus();
 	}
 
+	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
+	smp_init_cpus();
 	smp_build_mpidr_hash();
 #endif
 

commit 836ee4874e201a5907f9658fb2bf3527dd952d30
Merge: fb65d872d7a8 7676fa70feb2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 24 08:23:45 2015 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull initial ACPI support for arm64 from Will Deacon:
     "This series introduces preliminary ACPI 5.1 support to the arm64
      kernel using the "hardware reduced" profile.  We don't support any
      peripherals yet, so it's fairly limited in scope:
    
       - MEMORY init (UEFI)
    
       - ACPI discovery (RSDP via UEFI)
    
       - CPU init (FADT)
    
       - GIC init (MADT)
    
       - SMP boot (MADT + PSCI)
    
       - ACPI Kconfig options (dependent on EXPERT)
    
      ACPI for arm64 has been in development for a while now and hardware
      has been available that can boot with either FDT or ACPI tables.  This
      has been made possible by both changes to the ACPI spec to cater for
      ARM-based machines (known as "hardware-reduced" in ACPI parlance) but
      also a Linaro-driven effort to get this supported on top of the Linux
      kernel.  This pull request is the result of that work.
    
      These changes allow us to initialise the CPUs, interrupt controller,
      and timers via ACPI tables, with memory information and cmdline coming
      from EFI.  We don't support a hybrid ACPI/FDT scheme.  Of course,
      there is still plenty of work to do (a serial console would be nice!)
      but I expect that to happen on a per-driver basis after this core
      series has been merged.
    
      Anyway, the diff stat here is fairly horrible, but splitting this up
      and merging it via all the different subsystems would have been
      extremely painful.  Instead, we've got all the relevant Acks in place
      and I've not seen anything other than trivial (Kconfig) conflicts in
      -next (for completeness, I've included my resolution below).  Nearly
      half of the insertions fall under Documentation/.
    
      So, we'll see how this goes.  Right now, it all depends on EXPERT and
      I fully expect people to use FDT by default for the immediate future"
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (31 commits)
      ARM64 / ACPI: make acpi_map_gic_cpu_interface() as void function
      ARM64 / ACPI: Ignore the return error value of acpi_map_gic_cpu_interface()
      ARM64 / ACPI: fix usage of acpi_map_gic_cpu_interface
      ARM64: kernel: acpi: honour acpi=force command line parameter
      ARM64: kernel: acpi: refactor ACPI tables init and checks
      ARM64: kernel: psci: let ACPI probe PSCI version
      ARM64: kernel: psci: factor out probe function
      ACPI: move arm64 GSI IRQ model to generic GSI IRQ layer
      ARM64 / ACPI: Don't unflatten device tree if acpi=force is passed
      ARM64 / ACPI: additions of ACPI documentation for arm64
      Documentation: ACPI for ARM64
      ARM64 / ACPI: Enable ARM64 in Kconfig
      XEN / ACPI: Make XEN ACPI depend on X86
      ARM64 / ACPI: Select ACPI_REDUCED_HARDWARE_ONLY if ACPI is enabled on ARM64
      clocksource / arch_timer: Parse GTDT to initialize arch timer
      irqchip: Add GICv2 specific ACPI boot support
      ARM64 / ACPI: Introduce ACPI_IRQ_MODEL_GIC and register device's gsi
      ACPI / processor: Make it possible to get CPU hardware ID via GICC
      ACPI / processor: Introduce phys_cpuid_t for CPU hardware ID
      ARM64 / ACPI: Parse MADT for SMP initialization
      ...

commit fb094eb19900937322848beaf1a622c6afb6250b
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Wed Mar 25 15:22:13 2015 +0000

    ARM64: kernel: acpi: honour acpi=force command line parameter
    
    If acpi=force is passed on the command line, it forces ACPI to be
    the only available boot method, hence it must be left enabled even
    if the initialization and sanity checks on ACPI tables fails.
    
    This patch refactors ACPI initialization to prevent disabling ACPI
    if acpi=force is passed on the command line.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Hanjun Guo <hanjun.guo@linaro.org>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Hanjun Guo <hanjun.guo@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index d60b1adc7500..b2783111fd52 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -390,7 +390,7 @@ void __init setup_arch(char **cmdline_p)
 
 	early_ioremap_reset();
 
-	if (acpi_disabled  && !param_acpi_force) {
+	if (acpi_disabled) {
 		unflatten_device_tree();
 		psci_dt_init();
 		cpu_read_bootcpu_ops();

commit 33757ded074918eb49243968a82e7c9ec2d71720
Author: Hanjun Guo <hanjun.guo@linaro.org>
Date:   Tue Mar 24 14:02:56 2015 +0000

    ARM64 / ACPI: Don't unflatten device tree if acpi=force is passed
    
    Since the policy is that once we pass acpi=force in the early
    param, we will not unflatten device tree even if ACPI is disabled
    in ACPI table init fails, so fix the code by comparinging both
    acpi_disabled and param_acpi_force before the device tree is
    unflattened.
    
    CC: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b2783111fd52..d60b1adc7500 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -390,7 +390,7 @@ void __init setup_arch(char **cmdline_p)
 
 	early_ioremap_reset();
 
-	if (acpi_disabled) {
+	if (acpi_disabled  && !param_acpi_force) {
 		unflatten_device_tree();
 		psci_dt_init();
 		cpu_read_bootcpu_ops();

commit fccb9a81fd08b61bed91ddef88341694f8ecbfd1
Author: Hanjun Guo <hanjun.guo@linaro.org>
Date:   Tue Mar 24 22:02:45 2015 +0800

    ARM64 / ACPI: Parse MADT for SMP initialization
    
    MADT contains the information for MPIDR which is essential for
    SMP initialization, parse the GIC cpu interface structures to
    get the MPIDR value and map it to cpu_logical_map(), and add
    enabled cpu with valid MPIDR into cpu_possible_map.
    
    ACPI 5.1 only has two explicit methods to boot up SMP, PSCI and
    Parking protocol, but the Parking protocol is only specified for
    ARMv7 now, so make PSCI as the only way for the SMP boot protocol
    before some updates for the ACPI spec or the Parking protocol spec.
    
    Parking protocol patches for SMP boot will be sent to upstream when
    the new version of Parking protocol is ready.
    
    CC: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    CC: Catalin Marinas <catalin.marinas@arm.com>
    CC: Will Deacon <will.deacon@arm.com>
    CC: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Suravee Suthikulpanit <Suravee.Suthikulpanit@amd.com>
    Tested-by: Yijing Wang <wangyijing@huawei.com>
    Tested-by: Mark Langsdorf <mlangsdo@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>
    Tested-by: Timur Tabi <timur@codeaurora.org>
    Tested-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Reviewed-by: Grant Likely <grant.likely@linaro.org>
    Signed-off-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Tomasz Nowicki <tomasz.nowicki@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 97fa7f31981d..b2783111fd52 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -393,13 +393,16 @@ void __init setup_arch(char **cmdline_p)
 	if (acpi_disabled) {
 		unflatten_device_tree();
 		psci_dt_init();
+		cpu_read_bootcpu_ops();
+#ifdef CONFIG_SMP
+		of_smp_init_cpus();
+#endif
 	} else {
 		psci_acpi_init();
+		acpi_init_cpus();
 	}
 
-	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
-	smp_init_cpus();
 	smp_build_mpidr_hash();
 #endif
 

commit 7c59a3df15df29c8402a05b92385e83e55355778
Author: Graeme Gregory <graeme.gregory@linaro.org>
Date:   Tue Mar 24 14:02:43 2015 +0000

    ARM64 / ACPI: Get PSCI flags in FADT for PSCI init
    
    There are two flags: PSCI_COMPLIANT and PSCI_USE_HVC. When set,
    the former signals to the OS that the firmware is PSCI compliant.
    The latter selects the appropriate conduit for PSCI calls by
    toggling between Hypervisor Calls (HVC) and Secure Monitor Calls
    (SMC).
    
    FADT table contains such information in ACPI 5.1, FADT table was
    parsed in ACPI table init and copy to struct acpi_gbl_FADT, so
    use the flags in struct acpi_gbl_FADT for PSCI init.
    
    Since ACPI 5.1 doesn't support self defined PSCI function IDs,
    which means that only PSCI 0.2+ is supported in ACPI.
    
    CC: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    CC: Catalin Marinas <catalin.marinas@arm.com>
    CC: Will Deacon <will.deacon@arm.com>
    Tested-by: Suravee Suthikulpanit <Suravee.Suthikulpanit@amd.com>
    Tested-by: Yijing Wang <wangyijing@huawei.com>
    Tested-by: Mark Langsdorf <mlangsdo@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>
    Tested-by: Timur Tabi <timur@codeaurora.org>
    Tested-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Grant Likely <grant.likely@linaro.org>
    Signed-off-by: Graeme Gregory <graeme.gregory@linaro.org>
    Signed-off-by: Tomasz Nowicki <tomasz.nowicki@linaro.org>
    Signed-off-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index e8c7000af5ba..97fa7f31981d 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -390,10 +390,12 @@ void __init setup_arch(char **cmdline_p)
 
 	early_ioremap_reset();
 
-	if (acpi_disabled)
+	if (acpi_disabled) {
 		unflatten_device_tree();
-
-	psci_init();
+		psci_dt_init();
+	} else {
+		psci_acpi_init();
+	}
 
 	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP

commit 3505f30fb6a980283116390e9a962d60cf8e2a57
Author: Graeme Gregory <graeme.gregory@linaro.org>
Date:   Tue Mar 24 14:02:42 2015 +0000

    ARM64 / ACPI: If we chose to boot from acpi then disable FDT
    
    If the early boot methods of acpi are happy that we have valid ACPI
    tables and acpi=force has been passed, then do not unflat devicetree
    effectively disabling further hardware probing from DT.
    
    CC: Catalin Marinas <catalin.marinas@arm.com>
    CC: Will Deacon <will.deacon@arm.com>
    Tested-by: Suravee Suthikulpanit <Suravee.Suthikulpanit@amd.com>
    Tested-by: Yijing Wang <wangyijing@huawei.com>
    Tested-by: Mark Langsdorf <mlangsdo@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>
    Tested-by: Timur Tabi <timur@codeaurora.org>
    Tested-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Grant Likely <grant.likely@linaro.org>
    Signed-off-by: Graeme Gregory <graeme.gregory@linaro.org>
    Signed-off-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4f1a014ace39..e8c7000af5ba 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -390,7 +390,8 @@ void __init setup_arch(char **cmdline_p)
 
 	early_ioremap_reset();
 
-	unflatten_device_tree();
+	if (acpi_disabled)
+		unflatten_device_tree();
 
 	psci_init();
 

commit 37655163ce1a3ef2635a9bba0ad614f25e01484e
Author: Al Stone <al.stone@linaro.org>
Date:   Tue Mar 24 14:02:37 2015 +0000

    ARM64 / ACPI: Get RSDP and ACPI boot-time tables
    
    As we want to get ACPI tables to parse and then use the information
    for system initialization, we should get the RSDP (Root System
    Description Pointer) first, it then locates Extended Root Description
    Table (XSDT) which contains all the 64-bit physical address that
    pointer to other boot-time tables.
    
    Introduce acpi.c and its related head file in this patch to provide
    fundamental needs of extern variables and functions for ACPI core,
    and then get boot-time tables as needed.
      - asm/acenv.h for arch specific ACPICA environments and
        implementation, It is needed unconditionally by ACPI core;
      - asm/acpi.h for arch specific variables and functions needed by
        ACPI driver core;
      - acpi.c for ARM64 related ACPI implementation for ACPI driver
        core;
    
    acpi_boot_table_init() is introduced to get RSDP and boot-time tables,
    it will be called in setup_arch() before paging_init(), so we should
    use eary_memremap() mechanism here to get the RSDP and all the table
    pointers.
    
    FADT Major.Minor version was introduced in ACPI 5.1, it is the same
    as ACPI version.
    
    In ACPI 5.1, some major gaps are fixed for ARM, such as updates in
    MADT table for GIC and SMP init, without those updates, we can not
    get the MPIDR for SMP init, and GICv2/3 related init information, so
    we can't boot arm64 ACPI properly with table versions predating 5.1.
    
    If firmware provides ACPI tables with ACPI version less than 5.1,
    OS has no way to retrieve the configuration data that is necessary
    to init SMP boot protocol and the GIC properly, so disable ACPI if
    we get an FADT table with version less that 5.1 when acpi_boot_table_init()
    called.
    
    CC: Catalin Marinas <catalin.marinas@arm.com>
    CC: Will Deacon <will.deacon@arm.com>
    CC: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Tested-by: Suravee Suthikulpanit <Suravee.Suthikulpanit@amd.com>
    Tested-by: Yijing Wang <wangyijing@huawei.com>
    Tested-by: Mark Langsdorf <mlangsdo@redhat.com>
    Tested-by: Jon Masters <jcm@redhat.com>
    Tested-by: Timur Tabi <timur@codeaurora.org>
    Tested-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Robert Richter <rrichter@cavium.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Grant Likely <grant.likely@linaro.org>
    Signed-off-by: Al Stone <al.stone@linaro.org>
    Signed-off-by: Graeme Gregory <graeme.gregory@linaro.org>
    Signed-off-by: Tomasz Nowicki <tomasz.nowicki@linaro.org>
    Signed-off-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index e8420f635bd4..4f1a014ace39 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -17,6 +17,7 @@
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+#include <linux/acpi.h>
 #include <linux/export.h>
 #include <linux/kernel.h>
 #include <linux/stddef.h>
@@ -46,6 +47,7 @@
 #include <linux/efi.h>
 #include <linux/personality.h>
 
+#include <asm/acpi.h>
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
@@ -380,6 +382,9 @@ void __init setup_arch(char **cmdline_p)
 	efi_init();
 	arm64_memblock_init();
 
+	/* Parse the ACPI tables for possible boot-time configuration */
+	acpi_boot_table_init();
+
 	paging_init();
 	request_standard_resources();
 

commit da9c177de88679c2948dc9a5e2325b0dff4677b9
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Mar 17 10:55:12 2015 +0100

    arm64: enforce x1|x2|x3 == 0 upon kernel entry as per boot protocol
    
    According to the arm64 boot protocol, registers x1 to x3 should be
    zero upon kernel entry, and non-zero values are reserved for future
    use. This future use is going to be problematic if we never enforce
    the current rules, so start enforcing them now, by emitting a warning
    if non-zero values are detected.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 1783b38cf4c0..51ef97274b52 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -115,6 +115,11 @@ void __init early_print(const char *str, ...)
 	printk("%s", buf);
 }
 
+/*
+ * The recorded values of x0 .. x3 upon kernel entry.
+ */
+u64 __cacheline_aligned boot_args[4];
+
 void __init smp_setup_processor_id(void)
 {
 	u64 mpidr = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
@@ -412,6 +417,12 @@ void __init setup_arch(char **cmdline_p)
 	conswitchp = &dummy_con;
 #endif
 #endif
+	if (boot_args[1] || boot_args[2] || boot_args[3]) {
+		pr_err("WARNING: x1-x3 nonzero in violation of boot protocol:\n"
+			"\tx1: %016llx\n\tx2: %016llx\n\tx3: %016llx\n"
+			"This indicates a broken bootloader or old kernel\n",
+			boot_args[1], boot_args[2], boot_args[3]);
+	}
 }
 
 static int __init arm64_device_init(void)

commit a44ef51799109dccba751240e84ca2da937a88ed
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Wed Mar 4 11:49:32 2015 +0100

    arm64: remove processor_id
    
    The global processor_id is assigned the MIDR_EL1 value of the boot
    CPU in the early init code, but is never referenced afterwards.
    
    As the relevance of the MIDR_EL1 value of the boot CPU is debatable
    anyway, especially under big.LITTLE, let's remove it before anyone
    starts using it.
    
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 3852405d70b5..1783b38cf4c0 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -63,9 +63,6 @@
 #include <asm/efi.h>
 #include <asm/virt.h>
 
-unsigned int processor_id;
-EXPORT_SYMBOL(processor_id);
-
 unsigned long elf_hwcap __read_mostly;
 EXPORT_SYMBOL_GPL(elf_hwcap);
 

commit a591ede4cd1cac02d3398a9ad332bd0bba460efe
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Mar 18 14:55:20 2015 +0000

    arm64: Get rid of struct cpu_table
    
    struct cpu_table is an artifact left from the (very) early days of
    the arm64 port, and its only real use is to allow the most beautiful
    "AArch64 Processor" string to be displayed at boot time.
    
    Really? Yes, really.
    
    Let's get rid of it. In order to avoid another BogoMips-gate, the
    aforementioned string is preserved.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 14808947bf46..3852405d70b5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -50,7 +50,6 @@
 #include <asm/cpu.h>
 #include <asm/cputype.h>
 #include <asm/elf.h>
-#include <asm/cputable.h>
 #include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
 #include <asm/sections.h>
@@ -84,7 +83,6 @@ unsigned int compat_elf_hwcap2 __read_mostly;
 
 DECLARE_BITMAP(cpu_hwcaps, ARM64_NCAPS);
 
-static const char *cpu_name;
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -234,22 +232,12 @@ void __init up_late_init(void)
 
 static void __init setup_processor(void)
 {
-	struct cpu_info *cpu_info;
 	u64 features, block;
 	u32 cwg;
 	int cls;
 
-	cpu_info = lookup_processor_type(read_cpuid_id());
-	if (!cpu_info) {
-		printk("CPU configuration botched (ID %08x), unable to continue.\n",
-		       read_cpuid_id());
-		while (1);
-	}
-
-	cpu_name = cpu_info->cpu_name;
-
-	printk("CPU: %s [%08x] revision %d\n",
-	       cpu_name, read_cpuid_id(), read_cpuid_id() & 15);
+	printk("CPU: AArch64 Processor [%08x] revision %d\n",
+	       read_cpuid_id(), read_cpuid_id() & 15);
 
 	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;

commit 667f3fd3950c123fd62d3b15d9db80926e75f1f0
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Mar 13 16:14:37 2015 +0000

    arm64: log CPU boot modes
    
    We currently don't log the boot mode for arm64 as we do for arm, and
    without KVM the user is provided with no indication as to which mode(s)
    CPUs were booted in, which can seriously hinder debugging in some cases.
    
    Add logging to the boot path once all CPUs are up. Where CPUs are
    mismatched in violation of the boot protocol, WARN and set a taint (as
    we do for CPU other CPU feature mismatches) given that the
    firmware/bootloader is buggy and should be fixed.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 781f4697dc26..14808947bf46 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -62,6 +62,7 @@
 #include <asm/memblock.h>
 #include <asm/psci.h>
 #include <asm/efi.h>
+#include <asm/virt.h>
 
 unsigned int processor_id;
 EXPORT_SYMBOL(processor_id);
@@ -207,8 +208,20 @@ static void __init smp_build_mpidr_hash(void)
 }
 #endif
 
+static void __init hyp_mode_check(void)
+{
+	if (is_hyp_mode_available())
+		pr_info("CPU: All CPU(s) started at EL2\n");
+	else if (is_hyp_mode_mismatched())
+		WARN_TAINT(1, TAINT_CPU_OUT_OF_SPEC,
+			   "CPU: CPUs started in inconsistent modes");
+	else
+		pr_info("CPU: All CPU(s) started at EL1\n");
+}
+
 void __init do_post_cpus_up_work(void)
 {
+	hyp_mode_check();
 	apply_alternatives_all();
 }
 

commit 137650aad96c9594683445e41afa8ac5a2097520
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Mar 13 16:14:34 2015 +0000

    arm64: apply alternatives for !SMP kernels
    
    Currently we only perform alternative patching for kernels built with
    CONFIG_SMP, as we call apply_alternatives_all() in smp.c, which is only
    built for CONFIG_SMP. Thus !SMP kernels may not have necessary
    alternatives patched in.
    
    This patch ensures that we call apply_alternatives_all() once all CPUs
    are booted, even for !SMP kernels, by having the smp_init_cpus() stub
    call this for !SMP kernels via up_late_init. A new wrapper,
    do_post_cpus_up_work, is added so we can hook other calls here later
    (e.g. boot mode logging).
    
    Cc: Andre Przywara <andre.przywara@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Fixes: e039ee4ee3fcf174 ("arm64: add alternative runtime patching")
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index e8420f635bd4..781f4697dc26 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -207,6 +207,18 @@ static void __init smp_build_mpidr_hash(void)
 }
 #endif
 
+void __init do_post_cpus_up_work(void)
+{
+	apply_alternatives_all();
+}
+
+#ifdef CONFIG_UP_LATE_INIT
+void __init up_late_init(void)
+{
+	do_post_cpus_up_work();
+}
+#endif /* CONFIG_UP_LATE_INIT */
+
 static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;

commit 78d51e0b8b57728099a3da74f4a10b6f8c71b764
Author: Robin Murphy <Robin.Murphy@arm.com>
Date:   Mon Jan 12 20:48:54 2015 +0000

    arm64: implement generic IOMMU configuration
    
    Add the necessary call to of_iommu_init.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index bb10903887d4..e8420f635bd4 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -40,6 +40,7 @@
 #include <linux/fs.h>
 #include <linux/proc_fs.h>
 #include <linux/memblock.h>
+#include <linux/of_iommu.h>
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
@@ -405,6 +406,7 @@ void __init setup_arch(char **cmdline_p)
 
 static int __init arm64_device_init(void)
 {
+	of_iommu_init();
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 	return 0;
 }

commit 60305db9884515ca063474e262b454f6da04e4e2
Author: Ard Biesheuvel <ard.biesheuvel-QSEj5FYQhm4dnm+yROfE0A@public.gmane.org>
Date:   Thu Jan 22 10:01:40 2015 +0000

    arm64/efi: move virtmap init to early initcall
    
    Now that the create_mapping() code in mm/mmu.c is able to support
    setting up kernel page tables at initcall time, we can move the whole
    virtmap creation to arm64_enable_runtime_services() instead of having
    a distinct stage during early boot. This also allows us to drop the
    arm64-specific EFI_VIRTMAP flag.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel-QSEj5FYQhm4dnm+yROfE0A@public.gmane.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 207413fe08a0..bb10903887d4 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -382,7 +382,6 @@ void __init setup_arch(char **cmdline_p)
 	paging_init();
 	request_standard_resources();
 
-	efi_virtmap_init();
 	early_ioremap_reset();
 
 	unflatten_device_tree();

commit 6083fe74b7bfffc2c7be8c711596608bda0cda6e
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Jan 15 16:42:14 2015 +0000

    arm64: respect mem= for EFI
    
    When booting with EFI, we acquire the EFI memory map after parsing the
    early params. This unfortuantely renders the option useless as we call
    memblock_enforce_memory_limit (which uses memblock_remove_range behind
    the scenes) before we've added any memblocks. We end up removing
    nothing, then adding all of memory later when efi_init calls
    reserve_regions.
    
    Instead, we can log the limit and apply this later when we do the rest
    of the memblock work in memblock_init, which should work regardless of
    the presence of EFI. At the same time we may as well move the early
    parameter into arm64's mm/init.c, close to arm64_memblock_init.
    
    Any memory which must be mapped (e.g. for use by EFI runtime services)
    must be mapped explicitly reather than relying on the linear mapping,
    which may be truncated as a result of a mem= option passed on the kernel
    command line.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Tested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Leif Lindholm <leif.lindholm@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 199d1b7809d7..207413fe08a0 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -322,25 +322,6 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 	dump_stack_set_arch_desc("%s (DT)", of_flat_dt_get_machine_name());
 }
 
-/*
- * Limit the memory size that was specified via FDT.
- */
-static int __init early_mem(char *p)
-{
-	phys_addr_t limit;
-
-	if (!p)
-		return 1;
-
-	limit = memparse(p, &p) & PAGE_MASK;
-	pr_notice("Memory limited to %lldMB\n", limit >> 20);
-
-	memblock_enforce_memory_limit(limit);
-
-	return 0;
-}
-early_param("mem", early_mem);
-
 static void __init request_standard_resources(void)
 {
 	struct memblock_region *region;

commit 9679be103108926cfe9e6fd2f6829cefa77e47b0
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 16:41:38 2014 +0200

    arm64/efi: remove idmap manipulations from UEFI code
    
    Now that we have moved the call to SetVirtualAddressMap() to the stub,
    UEFI has no use for the ID map, so we can drop the code that installs
    ID mappings for UEFI memory regions.
    
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index beac8188fdbd..199d1b7809d7 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -402,7 +402,6 @@ void __init setup_arch(char **cmdline_p)
 	request_standard_resources();
 
 	efi_virtmap_init();
-	efi_idmap_init();
 	early_ioremap_reset();
 
 	unflatten_device_tree();

commit f3cdfd239da56a4cea75a2920dc326f0f45f67e3
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Oct 20 16:27:26 2014 +0200

    arm64/efi: move SetVirtualAddressMap() to UEFI stub
    
    In order to support kexec, the kernel needs to be able to deal with the
    state of the UEFI firmware after SetVirtualAddressMap() has been called.
    To avoid having separate code paths for non-kexec and kexec, let's move
    the call to SetVirtualAddressMap() to the stub: this will guarantee us
    that it will only be called once (since the stub is not executed during
    kexec), and ensures that the UEFI state is identical between kexec and
    normal boot.
    
    This implies that the layout of the virtual mapping needs to be created
    by the stub as well. All regions are rounded up to a naturally aligned
    multiple of 64 KB (for compatibility with 64k pages kernels) and recorded
    in the UEFI memory map. The kernel proper reads those values and installs
    the mappings in a dedicated set of page tables that are swapped in during
    UEFI Runtime Services calls.
    
    Acked-by: Leif Lindholm <leif.lindholm@linaro.org>
    Acked-by: Matt Fleming <matt.fleming@intel.com>
    Tested-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 20fe2932ad0c..beac8188fdbd 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -401,6 +401,7 @@ void __init setup_arch(char **cmdline_p)
 	paging_init();
 	request_standard_resources();
 
+	efi_virtmap_init();
 	efi_idmap_init();
 	early_ioremap_reset();
 

commit 0e63ea48b4d8035dd0e91a3fa6fb79458b47adfb
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Jan 8 09:54:58 2015 +0000

    arm64/efi: add missing call to early_ioremap_reset()
    
    The early ioremap support introduced by patch bf4b558eba92
    ("arm64: add early_ioremap support") failed to add a call to
    early_ioremap_reset() at an appropriate time. Without this call,
    invocations of early_ioremap etc. that are done too late will go
    unnoticed and may cause corruption.
    
    This is exactly what happened when the first user of this feature
    was added in patch f84d02755f5a ("arm64: add EFI runtime services").
    The early mapping of the EFI memory map is unmapped during an early
    initcall, at which time the early ioremap support is long gone.
    
    Fix by adding the missing call to early_ioremap_reset() to
    setup_arch(), and move the offending early_memunmap() to right after
    the point where the early mapping of the EFI memory map is last used.
    
    Fixes: f84d02755f5a ("arm64: add EFI runtime services")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b80991166754..20fe2932ad0c 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -402,6 +402,7 @@ void __init setup_arch(char **cmdline_p)
 	request_standard_resources();
 
 	efi_idmap_init();
+	early_ioremap_reset();
 
 	unflatten_device_tree();
 

commit 06f9eb884be81431d54d7d37390043e3b5b7f14a
Author: Fabio Estevam <fabio.estevam@freescale.com>
Date:   Thu Dec 4 01:17:01 2014 +0000

    arm64: Provide a namespace to NCAPS
    
    Building arm64.allmodconfig leads to the following warning:
    
    usb/gadget/function/f_ncm.c:203:0: warning: "NCAPS" redefined
     #define NCAPS (USB_CDC_NCM_NCAP_ETH_FILTER | USB_CDC_NCM_NCAP_CRC_MODE)
     ^
    In file included from /home/build/work/batch/arch/arm64/include/asm/io.h:32:0,
                     from /home/build/work/batch/include/linux/clocksource.h:19,
                     from /home/build/work/batch/include/clocksource/arm_arch_timer.h:19,
                     from /home/build/work/batch/arch/arm64/include/asm/arch_timer.h:27,
                     from /home/build/work/batch/arch/arm64/include/asm/timex.h:19,
                     from /home/build/work/batch/include/linux/timex.h:65,
                     from /home/build/work/batch/include/linux/sched.h:19,
                     from /home/build/work/batch/arch/arm64/include/asm/compat.h:25,
                     from /home/build/work/batch/arch/arm64/include/asm/stat.h:23,
                     from /home/build/work/batch/include/linux/stat.h:5,
                     from /home/build/work/batch/include/linux/module.h:10,
                     from /home/build/work/batch/drivers/usb/gadget/function/f_ncm.c:19:
    arch/arm64/include/asm/cpufeature.h:27:0: note: this is the location of the previous definition
     #define NCAPS     2
    
    So add a ARM64 prefix to avoid such problem.
    
    Reported-by: Olof's autobuilder <build@lixom.net>
    Signed-off-by: Fabio Estevam <fabio.estevam@freescale.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 1de0e8a895ee..b80991166754 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -80,7 +80,7 @@ unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
 unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
-DECLARE_BITMAP(cpu_hwcaps, NCAPS);
+DECLARE_BITMAP(cpu_hwcaps, ARM64_NCAPS);
 
 static const char *cpu_name;
 phys_addr_t __fdt_pointer __initdata;

commit af86e5974d3069bd26ebcf7c046c6e59726acaaa
Author: Laura Abbott <lauraa@codeaurora.org>
Date:   Fri Nov 21 21:50:42 2014 +0000

    arm64: Factor out fixmap initialization from ioremap
    
    The fixmap API was originally added for arm64 for
    early_ioremap purposes. It can be used for other purposes too
    so move the initialization from ioremap to somewhere more
    generic. This makes it obvious where the fixmap is being set
    up and allows for a cleaner implementation of __set_fixmap.
    
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Laura Abbott <lauraa@codeaurora.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index c8629eb07ba6..1de0e8a895ee 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -384,6 +384,7 @@ void __init setup_arch(char **cmdline_p)
 
 	*cmdline_p = boot_command_line;
 
+	early_fixmap_init();
 	early_ioremap_init();
 
 	parse_early_param();

commit 930da09f5e50dd22fb0a8600388da8677d62d671
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Fri Nov 14 15:54:07 2014 +0000

    arm64: add cpu_capabilities bitmap
    
    For taking note if at least one CPU in the system needs a bug
    workaround or would benefit from a code optimization, we create a new
    bitmap to hold (artificial) feature bits.
    Since elf_hwcap is part of the userland ABI, we keep it alone and
    introduce a new data structure for that (along with some accessors).
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 2e17bd3806c8..c8629eb07ba6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -50,6 +50,7 @@
 #include <asm/cputype.h>
 #include <asm/elf.h>
 #include <asm/cputable.h>
+#include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
@@ -79,6 +80,8 @@ unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
 unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
+DECLARE_BITMAP(cpu_hwcaps, NCAPS);
+
 static const char *cpu_name;
 phys_addr_t __fdt_pointer __initdata;
 

commit 7d57511d2dba03a8046c8b428dd9192a4bfc1e73
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Nov 17 10:37:40 2014 +0000

    arm64: Add COMPAT_HWCAP_LPAE
    
    Commit a469abd0f868 (ARM: elf: add new hwcap for identifying atomic
    ldrd/strd instructions) introduces HWCAP_ELF for 32-bit ARM
    applications. As LPAE is always present on arm64, report the
    corresponding compat HWCAP to user space.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: <stable@vger.kernel.org> # 3.11+
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 831c97fe1ae9..2e17bd3806c8 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -73,7 +73,8 @@ EXPORT_SYMBOL_GPL(elf_hwcap);
 				 COMPAT_HWCAP_FAST_MULT|COMPAT_HWCAP_EDSP|\
 				 COMPAT_HWCAP_TLS|COMPAT_HWCAP_VFP|\
 				 COMPAT_HWCAP_VFPv3|COMPAT_HWCAP_VFPv4|\
-				 COMPAT_HWCAP_NEON|COMPAT_HWCAP_IDIV)
+				 COMPAT_HWCAP_NEON|COMPAT_HWCAP_IDIV|\
+				 COMPAT_HWCAP_LPAE)
 unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
 unsigned int compat_elf_hwcap2 __read_mostly;
 #endif

commit 44b82b7700d05a52cd983799d3ecde1a976b3bed
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Oct 24 14:56:40 2014 +0100

    arm64: Fix up /proc/cpuinfo
    
    Commit d7a49086f263164a (arm64: cpuinfo: print info for all CPUs)
    attempted to clean up /proc/cpuinfo, but due to concerns regarding
    further changes was reverted in commit 5e39977edf6500fd (Revert "arm64:
    cpuinfo: print info for all CPUs").
    
    There are two major issues with the arm64 /proc/cpuinfo format
    currently:
    
    * The "Features" line describes (only) the 64-bit hwcaps, which is
      problematic for some 32-bit applications which attempt to parse it. As
      the same names are used for analogous ISA features (e.g. aes) despite
      these generally being architecturally unrelated, it is not possible to
      simply append the 64-bit and 32-bit hwcaps in a manner that might not
      be misleading to some applications.
    
      Various potential solutions have appeared in vendor kernels. Typically
      the format of the Features line varies depending on whether the task
      is 32-bit.
    
    * Information is only printed regarding a single CPU. This does not
      match the ARM format, and does not provide sufficient information in
      big.LITTLE systems where CPUs are heterogeneous. The CPU information
      printed is queried from the current CPU's registers, which is racy
      w.r.t. cross-cpu migration.
    
    This patch attempts to solve these issues. The following changes are
    made:
    
    * When a task with a LINUX32 personality attempts to read /proc/cpuinfo,
      the "Features" line contains the decoded 32-bit hwcaps, as with the
      arm port. Otherwise, the decoded 64-bit hwcaps are shown. This aligns
      with the behaviour of COMPAT_UTS_MACHINE and COMPAT_ELF_PLATFORM. In
      the absense of compat support, the Features line is empty.
    
      The set of hwcaps injected into a task's auxval are unaffected.
    
    * Properties are printed per-cpu, as with the ARM port. The per-cpu
      information is queried from pre-recorded cpu information (as used by
      the sanity checks).
    
    * As with the previous attempt at fixing up /proc/cpuinfo, the hardware
      field is removed. The only users so far are 32-bit applications tied
      to particular boards, so no portable applications should be affected,
      and this should prevent future tying to particular boards.
    
    The following differences remain:
    
    * No model_name is printed, as this cannot be queried from the hardware
      and cannot be provided in a stable fashion. Use of the CPU
      {implementor,variant,part,revision} fields is sufficient to identify a
      CPU and is portable across arm and arm64.
    
    * The following system-wide properties are not provided, as they are not
      possible to provide generally. Programs relying on these are already
      tied to particular (32-bit only) boards:
      - Hardware
      - Revision
      - Serial
    
    No software has yet been identified for which these remaining
    differences are problematic.
    
    Cc: Greg Hackmann <ghackmann@google.com>
    Cc: Ian Campbell <ijc@hellion.org.uk>
    Cc: Serban Constantinescu <serban.constantinescu@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: cross-distro@lists.linaro.org
    Cc: linux-api@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-kernel@vger.kernel.org
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index c73714b6aa96..831c97fe1ae9 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -43,6 +43,7 @@
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
+#include <linux/personality.h>
 
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
@@ -78,7 +79,6 @@ unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
 static const char *cpu_name;
-static const char *machine_name;
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -315,8 +315,7 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 			cpu_relax();
 	}
 
-	machine_name = of_flat_dt_get_machine_name();
-	dump_stack_set_arch_desc("%s (DT)", machine_name);
+	dump_stack_set_arch_desc("%s (DT)", of_flat_dt_get_machine_name());
 }
 
 /*
@@ -451,14 +450,50 @@ static const char *hwcap_str[] = {
 	NULL
 };
 
+#ifdef CONFIG_COMPAT
+static const char *compat_hwcap_str[] = {
+	"swp",
+	"half",
+	"thumb",
+	"26bit",
+	"fastmult",
+	"fpa",
+	"vfp",
+	"edsp",
+	"java",
+	"iwmmxt",
+	"crunch",
+	"thumbee",
+	"neon",
+	"vfpv3",
+	"vfpv3d16",
+	"tls",
+	"vfpv4",
+	"idiva",
+	"idivt",
+	"vfpd32",
+	"lpae",
+	"evtstrm"
+};
+
+static const char *compat_hwcap2_str[] = {
+	"aes",
+	"pmull",
+	"sha1",
+	"sha2",
+	"crc32",
+	NULL
+};
+#endif /* CONFIG_COMPAT */
+
 static int c_show(struct seq_file *m, void *v)
 {
-	int i;
-
-	seq_printf(m, "Processor\t: %s rev %d (%s)\n",
-		   cpu_name, read_cpuid_id() & 15, ELF_PLATFORM);
+	int i, j;
 
 	for_each_online_cpu(i) {
+		struct cpuinfo_arm64 *cpuinfo = &per_cpu(cpu_data, i);
+		u32 midr = cpuinfo->reg_midr;
+
 		/*
 		 * glibc reads /proc/cpuinfo to determine the number of
 		 * online processors, looking for lines beginning with
@@ -467,24 +502,38 @@ static int c_show(struct seq_file *m, void *v)
 #ifdef CONFIG_SMP
 		seq_printf(m, "processor\t: %d\n", i);
 #endif
-	}
-
-	/* dump out the processor features */
-	seq_puts(m, "Features\t: ");
-
-	for (i = 0; hwcap_str[i]; i++)
-		if (elf_hwcap & (1 << i))
-			seq_printf(m, "%s ", hwcap_str[i]);
-
-	seq_printf(m, "\nCPU implementer\t: 0x%02x\n", read_cpuid_id() >> 24);
-	seq_printf(m, "CPU architecture: AArch64\n");
-	seq_printf(m, "CPU variant\t: 0x%x\n", (read_cpuid_id() >> 20) & 15);
-	seq_printf(m, "CPU part\t: 0x%03x\n", (read_cpuid_id() >> 4) & 0xfff);
-	seq_printf(m, "CPU revision\t: %d\n", read_cpuid_id() & 15);
 
-	seq_puts(m, "\n");
-
-	seq_printf(m, "Hardware\t: %s\n", machine_name);
+		/*
+		 * Dump out the common processor features in a single line.
+		 * Userspace should read the hwcaps with getauxval(AT_HWCAP)
+		 * rather than attempting to parse this, but there's a body of
+		 * software which does already (at least for 32-bit).
+		 */
+		seq_puts(m, "Features\t:");
+		if (personality(current->personality) == PER_LINUX32) {
+#ifdef CONFIG_COMPAT
+			for (j = 0; compat_hwcap_str[j]; j++)
+				if (compat_elf_hwcap & (1 << j))
+					seq_printf(m, " %s", compat_hwcap_str[j]);
+
+			for (j = 0; compat_hwcap2_str[j]; j++)
+				if (compat_elf_hwcap2 & (1 << j))
+					seq_printf(m, " %s", compat_hwcap2_str[j]);
+#endif /* CONFIG_COMPAT */
+		} else {
+			for (j = 0; hwcap_str[j]; j++)
+				if (elf_hwcap & (1 << j))
+					seq_printf(m, " %s", hwcap_str[j]);
+		}
+		seq_puts(m, "\n");
+
+		seq_printf(m, "CPU implementer\t: 0x%02x\n",
+			   MIDR_IMPLEMENTOR(midr));
+		seq_printf(m, "CPU architecture: 8\n");
+		seq_printf(m, "CPU variant\t: 0x%x\n", MIDR_VARIANT(midr));
+		seq_printf(m, "CPU part\t: 0x%03x\n", MIDR_PARTNUM(midr));
+		seq_printf(m, "CPU revision\t: %d\n\n", MIDR_REVISION(midr));
+	}
 
 	return 0;
 }

commit 80708677fab44a1489a089e162455dfb4dd722cd
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Nov 4 10:50:16 2014 +0000

    arm64: log physical ID of boot CPU
    
    In certain debugging scenarios it's useful to know the physical ID (i.e.
    the MPIDR_EL1.Aff* fields) of the boot CPU, but we don't currently log
    this as we do for 32-bit ARM kernels.
    
    This patch makes the kernel log the physical ID of the boot CPU early in
    the boot process. The CPU logical map initialisation is folded in to
    smp_setup_processor_id (which contrary to its name is also called by UP
    kernels). This is called before setup_arch, so should not adversely
    affect existing cpu_logical_map users.
    
    Acked-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Lorenzo Pieralisis <lorenzo.pieralisi@arm.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index cbeaa2f3844b..c73714b6aa96 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -116,12 +116,16 @@ void __init early_print(const char *str, ...)
 
 void __init smp_setup_processor_id(void)
 {
+	u64 mpidr = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
+	cpu_logical_map(0) = mpidr;
+
 	/*
 	 * clear __my_cpu_offset on boot CPU to avoid hang caused by
 	 * using percpu variable early, for example, lockdep will
 	 * access percpu variable inside lock_release
 	 */
 	set_my_cpu_offset(0);
+	pr_info("Booting Linux on physical CPU 0x%lx\n", (unsigned long)mpidr);
 }
 
 bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
@@ -399,7 +403,6 @@ void __init setup_arch(char **cmdline_p)
 
 	psci_init();
 
-	cpu_logical_map(0) = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
 	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
 	smp_init_cpus();

commit d8c6d8b877cb2a216e933ce11954632a9daeb362
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Tue Oct 28 12:24:20 2014 +0000

    arm64/dt: add machine name to kernel call stack dump output
    
    This installs the machine name as recorded by setup_machine_fdt()
    as dump stack arch description. This results in the string to be
    included in call stack dumps, as is shown here:
    
      ...
      Bad mode in Synchronous Abort handler detected, code 0x84000005
      CPU: 0 PID: 1 Comm: swapper/0 Not tainted 3.18.0-rc2+ #548
    > Hardware name: linux,dummy-virt (DT)
      task: ffffffc07c870000 ti: ffffffc07c878000 task.ti: ffffffc07c878000
      PC is at 0x0
      ...
    
    Note that systems that support DMI/SMBIOS may override this later.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 2437196cc5d4..cbeaa2f3844b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -312,6 +312,7 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 	}
 
 	machine_name = of_flat_dt_get_machine_name();
+	dump_stack_set_arch_desc("%s (DT)", machine_name);
 }
 
 /*

commit 7a9c43bed891d1f8d639c69893ee194f5700d0b2
Author: Jon Masters <jcm@redhat.com>
Date:   Tue Aug 26 21:23:38 2014 +0100

    setup: Move unmask of async interrupts after possible earlycon setup
    
    The kernel wants to enable reporting of asynchronous interrupts (i.e.
    System Errors) as early as possible. But if this happens too early then
    any pending System Error on initial entry into the kernel may never be
    reported where a user can see it. This situation will occur if the kernel
    is configured with CONFIG_PANIC_ON_OOPS set and (default or command line)
    enabled, in which case the kernel will panic as intended, however the
    associated logging messages indicating this failure condition will remain
    only in the kernel ring buffer and never be flushed out to the (not yet
    configured) console. Therefore, this patch moves the enabling of
    asynchronous interrupts during early setup to as early as reasonable,
    but after parsing any possible earlycon parameters setting up earlycon.
    
    Signed-off-by: Jon Masters <jcm@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index edb146d01857..2437196cc5d4 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -365,11 +365,6 @@ u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
 {
-	/*
-	 * Unmask asynchronous aborts early to catch possible system errors.
-	 */
-	local_async_enable();
-
 	setup_processor();
 
 	setup_machine_fdt(__fdt_pointer);
@@ -385,6 +380,12 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+	/*
+	 *  Unmask asynchronous aborts after bringing up possible earlycon.
+	 * (Report possible System Errors once we can report this occurred)
+	 */
+	local_async_enable();
+
 	efi_init();
 	arm64_memblock_init();
 

commit 5e39977edf6500fd12f169e6c458d33b0ef62feb
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Sep 1 15:47:19 2014 +0100

    Revert "arm64: cpuinfo: print info for all CPUs"
    
    It turns out that vendors are relying on the format of /proc/cpuinfo,
    and we've even spotted out-of-tree hacks attempting to make it look
    identical to the format used by arch/arm/. That means we can't afford to
    churn this interface in mainline, so revert the recent reformatting of
    the file for arm64 pending discussions on the list to find out what
    people actually want.
    
    This reverts commit d7a49086f263164a2c4c178eb76412d48cd671d7.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f6f0ccf35ae6..edb146d01857 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -78,6 +78,7 @@ unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
 static const char *cpu_name;
+static const char *machine_name;
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -309,6 +310,8 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 		while (true)
 			cpu_relax();
 	}
+
+	machine_name = of_flat_dt_get_machine_name();
 }
 
 /*
@@ -447,21 +450,10 @@ static int c_show(struct seq_file *m, void *v)
 {
 	int i;
 
-	/*
-	 * Dump out the common processor features in a single line. Userspace
-	 * should read the hwcaps with getauxval(AT_HWCAP) rather than
-	 * attempting to parse this.
-	 */
-	seq_puts(m, "features\t:");
-	for (i = 0; hwcap_str[i]; i++)
-		if (elf_hwcap & (1 << i))
-			seq_printf(m, " %s", hwcap_str[i]);
-	seq_puts(m, "\n\n");
+	seq_printf(m, "Processor\t: %s rev %d (%s)\n",
+		   cpu_name, read_cpuid_id() & 15, ELF_PLATFORM);
 
 	for_each_online_cpu(i) {
-		struct cpuinfo_arm64 *cpuinfo = &per_cpu(cpu_data, i);
-		u32 midr = cpuinfo->reg_midr;
-
 		/*
 		 * glibc reads /proc/cpuinfo to determine the number of
 		 * online processors, looking for lines beginning with
@@ -470,13 +462,25 @@ static int c_show(struct seq_file *m, void *v)
 #ifdef CONFIG_SMP
 		seq_printf(m, "processor\t: %d\n", i);
 #endif
-		seq_printf(m, "implementer\t: 0x%02x\n",
-			   MIDR_IMPLEMENTOR(midr));
-		seq_printf(m, "variant\t\t: 0x%x\n", MIDR_VARIANT(midr));
-		seq_printf(m, "partnum\t\t: 0x%03x\n", MIDR_PARTNUM(midr));
-		seq_printf(m, "revision\t: 0x%x\n\n", MIDR_REVISION(midr));
 	}
 
+	/* dump out the processor features */
+	seq_puts(m, "Features\t: ");
+
+	for (i = 0; hwcap_str[i]; i++)
+		if (elf_hwcap & (1 << i))
+			seq_printf(m, "%s ", hwcap_str[i]);
+
+	seq_printf(m, "\nCPU implementer\t: 0x%02x\n", read_cpuid_id() >> 24);
+	seq_printf(m, "CPU architecture: AArch64\n");
+	seq_printf(m, "CPU variant\t: 0x%x\n", (read_cpuid_id() >> 20) & 15);
+	seq_printf(m, "CPU part\t: 0x%03x\n", (read_cpuid_id() >> 4) & 0xfff);
+	seq_printf(m, "CPU revision\t: %d\n", read_cpuid_id() & 15);
+
+	seq_puts(m, "\n");
+
+	seq_printf(m, "Hardware\t: %s\n", machine_name);
+
 	return 0;
 }
 

commit 94156675847c14a9b16e91b035da32e35e98ef79
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jul 31 14:00:03 2014 +0100

    Revert "arm64: dmi: Add SMBIOS/DMI support"
    
    This reverts commit a28e3f4b90543f7c249a956e3ca518e243a04618.
    
    Ard and Yi Li report that this patch is broken by design, so revert it
    and let them sort it out for 3.18 instead.
    
    Reported-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 35339a0e1592..f6f0ccf35ae6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -43,7 +43,6 @@
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
-#include <linux/dmi.h>
 
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
@@ -414,7 +413,6 @@ void __init setup_arch(char **cmdline_p)
 static int __init arm64_device_init(void)
 {
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
-	dmi_scan_machine();
 	return 0;
 }
 arch_initcall_sync(arm64_device_init);

commit a28e3f4b90543f7c249a956e3ca518e243a04618
Author: Yi Li <yi.li@linaro.org>
Date:   Fri Jul 11 12:46:50 2014 +0100

    arm64: dmi: Add SMBIOS/DMI support
    
    SMbios is important for server hardware vendors. It implements a spec for
    providing descriptive information about the platform. Things like serial
    numbers, physical layout of the ports, build configuration data, and the like.
    
    This has been tested by dmidecode and lshw tools.
    
    Signed-off-by: Yi Li <yi.li@linaro.org>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index f6f0ccf35ae6..35339a0e1592 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -43,6 +43,7 @@
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
+#include <linux/dmi.h>
 
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
@@ -413,6 +414,7 @@ void __init setup_arch(char **cmdline_p)
 static int __init arm64_device_init(void)
 {
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
+	dmi_scan_machine();
 	return 0;
 }
 arch_initcall_sync(arm64_device_init);

commit d7a49086f263164a2c4c178eb76412d48cd671d7
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Fri Jul 18 14:57:38 2014 +0100

    arm64: cpuinfo: print info for all CPUs
    
    Currently reading /proc/cpuinfo will result in information being read
    out of the MIDR_EL1 of the current CPU, and the information is not
    associated with any particular logical CPU number.
    
    This is problematic for systems with heterogeneous CPUs (i.e.
    big.LITTLE) where MIDR fields will vary across CPUs, and the output will
    differ depending on the executing CPU.
    
    This patch reorganises the code responsible for /proc/cpuinfo to print
    information per-cpu. In the process, we perform several cleanups:
    
    * Property names are coerced to lower-case (to match "processor" as per
      glibc's expectations).
    * Property names are simplified and made to match the MIDR field names.
    * Revision is changed to hex as with every other field.
    * The meaningless Architecture property is removed.
    * The ripe-for-abuse Machine field is removed.
    
    The features field (a human-readable representation of the hwcaps)
    remains printed once, as this is expected to remain in use as the
    globally support CPU features. To enable the possibility of the addition
    of per-cpu HW feature information later, this is printed before any
    CPU-specific information.
    
    Comments are added to guide userspace developers in the right direction
    (using the hwcaps provided in auxval). Hopefully where userspace
    applications parse /proc/cpuinfo rather than using the readily available
    hwcaps, they limit themselves to reading said first line.
    
    If CPU features differ from each other, the previously installed sanity
    checks will give us some advance notice with warnings and
    TAINT_CPU_OUT_OF_SPEC. If we are lucky, we will never see such systems.
    Rework will be required in many places to support such systems anyway.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Marcus Shawcroft <marcus.shawcroft@arm.com>
    Cc: Peter Maydell <peter.maydell@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    [catalin.marinas@arm.com: remove machine_name as it is no longer reported]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index edb146d01857..f6f0ccf35ae6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -78,7 +78,6 @@ unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
 static const char *cpu_name;
-static const char *machine_name;
 phys_addr_t __fdt_pointer __initdata;
 
 /*
@@ -310,8 +309,6 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 		while (true)
 			cpu_relax();
 	}
-
-	machine_name = of_flat_dt_get_machine_name();
 }
 
 /*
@@ -450,10 +447,21 @@ static int c_show(struct seq_file *m, void *v)
 {
 	int i;
 
-	seq_printf(m, "Processor\t: %s rev %d (%s)\n",
-		   cpu_name, read_cpuid_id() & 15, ELF_PLATFORM);
+	/*
+	 * Dump out the common processor features in a single line. Userspace
+	 * should read the hwcaps with getauxval(AT_HWCAP) rather than
+	 * attempting to parse this.
+	 */
+	seq_puts(m, "features\t:");
+	for (i = 0; hwcap_str[i]; i++)
+		if (elf_hwcap & (1 << i))
+			seq_printf(m, " %s", hwcap_str[i]);
+	seq_puts(m, "\n\n");
 
 	for_each_online_cpu(i) {
+		struct cpuinfo_arm64 *cpuinfo = &per_cpu(cpu_data, i);
+		u32 midr = cpuinfo->reg_midr;
+
 		/*
 		 * glibc reads /proc/cpuinfo to determine the number of
 		 * online processors, looking for lines beginning with
@@ -462,25 +470,13 @@ static int c_show(struct seq_file *m, void *v)
 #ifdef CONFIG_SMP
 		seq_printf(m, "processor\t: %d\n", i);
 #endif
+		seq_printf(m, "implementer\t: 0x%02x\n",
+			   MIDR_IMPLEMENTOR(midr));
+		seq_printf(m, "variant\t\t: 0x%x\n", MIDR_VARIANT(midr));
+		seq_printf(m, "partnum\t\t: 0x%03x\n", MIDR_PARTNUM(midr));
+		seq_printf(m, "revision\t: 0x%x\n\n", MIDR_REVISION(midr));
 	}
 
-	/* dump out the processor features */
-	seq_puts(m, "Features\t: ");
-
-	for (i = 0; hwcap_str[i]; i++)
-		if (elf_hwcap & (1 << i))
-			seq_printf(m, "%s ", hwcap_str[i]);
-
-	seq_printf(m, "\nCPU implementer\t: 0x%02x\n", read_cpuid_id() >> 24);
-	seq_printf(m, "CPU architecture: AArch64\n");
-	seq_printf(m, "CPU variant\t: 0x%x\n", (read_cpuid_id() >> 20) & 15);
-	seq_printf(m, "CPU part\t: 0x%03x\n", (read_cpuid_id() >> 4) & 0xfff);
-	seq_printf(m, "CPU revision\t: %d\n", read_cpuid_id() & 15);
-
-	seq_puts(m, "\n");
-
-	seq_printf(m, "Hardware\t: %s\n", machine_name);
-
 	return 0;
 }
 

commit df857416a13734ed9356f6e4f0152d55e4fb748a
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jul 16 16:32:44 2014 +0100

    arm64: cpuinfo: record cpu system register values
    
    Several kernel subsystems need to know details about CPU system register
    values, sometimes for CPUs other than that they are executing on. Rather
    than hard-coding system register accesses and cross-calls for these
    cases, this patch adds logic to record various system register values at
    boot-time. This may be used for feature reporting, firmware bug
    detection, etc.
    
    Separate hooks are added for the boot and hotplug paths to enable
    one-time intialisation and cold/warm boot value mismatch detection in
    later patches.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 46d1125571f6..edb146d01857 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -45,6 +45,7 @@
 #include <linux/efi.h>
 
 #include <asm/fixmap.h>
+#include <asm/cpu.h>
 #include <asm/cputype.h>
 #include <asm/elf.h>
 #include <asm/cputable.h>
@@ -219,6 +220,8 @@ static void __init setup_processor(void)
 	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;
 
+	cpuinfo_store_boot_cpu();
+
 	/*
 	 * Check for sane CTR_EL0.CWG value.
 	 */
@@ -417,14 +420,12 @@ static int __init arm64_device_init(void)
 }
 arch_initcall_sync(arm64_device_init);
 
-static DEFINE_PER_CPU(struct cpu, cpu_data);
-
 static int __init topology_init(void)
 {
 	int i;
 
 	for_each_possible_cpu(i) {
-		struct cpu *cpu = &per_cpu(cpu_data, i);
+		struct cpu *cpu = &per_cpu(cpu_data.cpu, i);
 		cpu->hotpluggable = 1;
 		register_cpu(cpu, i);
 	}

commit cc07aabc53978ae09a1d539237189f7c9841060a
Merge: 9e47aaef0bd3 9358d755bd5c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 6 10:43:28 2014 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux into next
    
    Pull arm64 updates from Catalin Marinas:
     - Optimised assembly string/memory routines (based on the AArch64
       Cortex Strings library contributed to glibc but re-licensed under
       GPLv2)
     - Optimised crypto algorithms making use of the ARMv8 crypto extensions
       (together with kernel API for using FPSIMD instructions in interrupt
       context)
     - Ftrace support
     - CPU topology parsing from DT
     - ESR_EL1 (Exception Syndrome Register) exposed to user space signal
       handlers for SIGSEGV/SIGBUS (useful to emulation tools like Qemu)
     - 1GB section linear mapping if applicable
     - Barriers usage clean-up
     - Default pgprot clean-up
    
    Conflicts as per Catalin.
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (57 commits)
      arm64: kernel: initialize broadcast hrtimer based clock event device
      arm64: ftrace: Add system call tracepoint
      arm64: ftrace: Add CALLER_ADDRx macros
      arm64: ftrace: Add dynamic ftrace support
      arm64: Add ftrace support
      ftrace: Add arm64 support to recordmcount
      arm64: Add 'notrace' attribute to unwind_frame() for ftrace
      arm64: add __ASSEMBLY__ in asm/insn.h
      arm64: Fix linker script entry point
      arm64: lib: Implement optimized string length routines
      arm64: lib: Implement optimized string compare routines
      arm64: lib: Implement optimized memcmp routine
      arm64: lib: Implement optimized memset routine
      arm64: lib: Implement optimized memmove routine
      arm64: lib: Implement optimized memcpy routine
      arm64: defconfig: enable a few more common/useful options in defconfig
      ftrace: Make CALLER_ADDRx macros more generic
      arm64: Fix deadlock scenario with smp_send_stop()
      arm64: Fix machine_shutdown() definition
      arm64: Support arch_irq_work_raise() via self IPIs
      ...

commit c3c55a07203947f72afa50a3218460b27307c47d
Merge: 046f153343e3 74bcc2499291
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 5 13:15:32 2014 -0700

    Merge branch 'arm64-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip into next
    
    Pull ARM64 EFI update from Peter Anvin:
     "By agreement with the ARM64 EFI maintainers, we have agreed to make
      -tip the upstream for all EFI patches.  That is why this patchset
      comes from me :)
    
      This patchset enables EFI stub support for ARM64, like we already have
      on x86"
    
    * 'arm64-efi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      arm64: efi: only attempt efi map setup if booting via EFI
      efi/arm64: ignore dtb= when UEFI SecureBoot is enabled
      doc: arm64: add description of EFI stub support
      arm64: efi: add EFI stub
      doc: arm: add UEFI support documentation
      arm64: add EFI runtime services
      efi: Add shared FDT related functions for ARM/ARM64
      arm64: Add function to create identity mappings
      efi: add helper function to get UEFI params from FDT
      doc: efi-stub.txt updates for ARM
      lib: add fdt_empty_tree.c

commit a501e32430d4232012ab708b8f0ce841f29e0f02
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Apr 3 15:57:15 2014 +0100

    arm64: Clean up the default pgprot setting
    
    The primary aim of this patchset is to remove the pgprot_default and
    prot_sect_default global variables and rely strictly on predefined
    values. The original goal was to be able to run SMP kernels on UP
    hardware by not setting the Shareability bit. However, it is unlikely to
    see UP ARMv8 hardware and even if we do, the Shareability bit is no
    longer assumed to disable cacheable accesses.
    
    A side effect is that the device mappings now have the Shareability
    attribute set. The hardware, however, should ignore it since Device
    accesses are always Outer Shareable.
    
    Following the removal of the two global variables, there is some PROT_*
    macro reshuffling and cleanup, including the __PAGE_* macros (replaced
    by PAGE_*).
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 5b9e046d580e..7450c5802c3f 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -376,7 +376,6 @@ void __init setup_arch(char **cmdline_p)
 
 	*cmdline_p = boot_command_line;
 
-	init_mem_pgprot();
 	early_ioremap_init();
 
 	parse_early_param();

commit a41dc0e841523efe1df7fa5ad48b5e9027a921df
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Apr 3 17:48:54 2014 +0100

    arm64: Implement cache_line_size() based on CTR_EL0.CWG
    
    The hardware provides the maximum cache line size in the system via the
    CTR_EL0.CWG bits. This patch implements the cache_line_size() function
    to read such information, together with a sanity check if the statically
    defined L1_CACHE_BYTES is smaller than the hardware value.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7ec784653b29..5b9e046d580e 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -25,6 +25,7 @@
 #include <linux/utsname.h>
 #include <linux/initrd.h>
 #include <linux/console.h>
+#include <linux/cache.h>
 #include <linux/bootmem.h>
 #include <linux/seq_file.h>
 #include <linux/screen_info.h>
@@ -198,6 +199,8 @@ static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;
 	u64 features, block;
+	u32 cwg;
+	int cls;
 
 	cpu_info = lookup_processor_type(read_cpuid_id());
 	if (!cpu_info) {
@@ -214,6 +217,18 @@ static void __init setup_processor(void)
 	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;
 
+	/*
+	 * Check for sane CTR_EL0.CWG value.
+	 */
+	cwg = cache_type_cwg();
+	cls = cache_line_size();
+	if (!cwg)
+		pr_warn("No Cache Writeback Granule information, assuming cache line size %d\n",
+			cls);
+	if (L1_CACHE_BYTES < cls)
+		pr_warn("L1_CACHE_BYTES smaller than the Cache Writeback Granule (%d < %d)\n",
+			L1_CACHE_BYTES, cls);
+
 	/*
 	 * ID_AA64ISAR0_EL1 contains 4-bit wide signed feature blocks.
 	 * The blocks we test below represent incremental functionality

commit 6ecba8eb51b7d23fda66388a5420be7d8688b186
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Apr 25 15:31:45 2014 +0100

    arm64: Use bus notifiers to set per-device coherent DMA ops
    
    Recently, the default DMA ops have been changed to non-coherent for
    alignment with 32-bit ARM platforms (and DT files). This patch adds bus
    notifiers to be able to set the coherent DMA ops (with no cache
    maintenance) for devices explicitly marked as coherent via the
    "dma-coherent" DT property.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 93e7df8968fe..7ec784653b29 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -396,7 +396,7 @@ static int __init arm64_device_init(void)
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 	return 0;
 }
-arch_initcall(arm64_device_init);
+arch_initcall_sync(arm64_device_init);
 
 static DEFINE_PER_CPU(struct cpu, cpu_data);
 

commit f84d02755f5a9f3b88e8d15d6384da25ad6dcf5e
Author: Mark Salter <msalter@redhat.com>
Date:   Tue Apr 15 21:59:30 2014 -0400

    arm64: add EFI runtime services
    
    This patch adds EFI runtime support for arm64. This runtime support allows
    the kernel to access various EFI runtime services provided by EFI firmware.
    Things like reboot, real time clock, EFI boot variables, and others.
    
    This functionality is supported for little endian kernels only. The UEFI
    firmware standard specifies that the firmware be little endian. A future
    patch is expected to add support for big endian kernels running with
    little endian firmware.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    [ Remove unnecessary cache/tlb maintenance. ]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Leif Lindholm <leif.lindholm@linaro.org>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 720853f70b6b..0a14aaffc834 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -41,6 +41,7 @@
 #include <linux/memblock.h>
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
+#include <linux/efi.h>
 
 #include <asm/fixmap.h>
 #include <asm/cputype.h>
@@ -55,6 +56,7 @@
 #include <asm/traps.h>
 #include <asm/memblock.h>
 #include <asm/psci.h>
+#include <asm/efi.h>
 
 unsigned int processor_id;
 EXPORT_SYMBOL(processor_id);
@@ -366,11 +368,14 @@ void __init setup_arch(char **cmdline_p)
 
 	parse_early_param();
 
+	efi_init();
 	arm64_memblock_init();
 
 	paging_init();
 	request_standard_resources();
 
+	efi_idmap_init();
+
 	unflatten_device_tree();
 
 	psci_init();

commit bc3ee18a7a57243721ecfd879319e3d2e882f289
Author: Chanho Min <chanho.min@lge.com>
Date:   Mon Apr 14 08:38:53 2014 +0100

    arm64: init: Move of_clk_init to time_init
    
    Clock providers should be initialized before clocksource_of_init.
    If not, Clock source initialization can be fail to get the clock.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Chanho Min <chanho.min@lge.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 720853f70b6b..93e7df8968fe 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -393,7 +393,6 @@ void __init setup_arch(char **cmdline_p)
 
 static int __init arm64_device_init(void)
 {
-	of_clk_init(NULL);
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 	return 0;
 }

commit bf4b558eba920a38f91beb5ee62a8ce2628c92f7
Author: Mark Salter <msalter@redhat.com>
Date:   Mon Apr 7 15:39:52 2014 -0700

    arm64: add early_ioremap support
    
    Add support for early IO or memory mappings which are needed before the
    normal ioremap() is usable.  This also adds fixmap support for permanent
    fixed mappings such as that used by the earlyprintk device register
    region.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 20830d1afbb6..720853f70b6b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -42,6 +42,7 @@
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 
+#include <asm/fixmap.h>
 #include <asm/cputype.h>
 #include <asm/elf.h>
 #include <asm/cputable.h>
@@ -361,6 +362,7 @@ void __init setup_arch(char **cmdline_p)
 	*cmdline_p = boot_command_line;
 
 	init_mem_pgprot();
+	early_ioremap_init();
 
 	parse_early_param();
 

commit 0bf757c73d6612d3d279de3f61b35062aa9c8b1d
Author: Mark Salter <msalter@redhat.com>
Date:   Mon Apr 7 15:39:51 2014 -0700

    arm64: initialize pgprot info earlier in boot
    
    Presently, paging_init() calls init_mem_pgprot() to initialize pgprot
    values used by macros such as PAGE_KERNEL, PAGE_KERNEL_EXEC, etc.
    
    The new fixmap and early_ioremap support also needs to use these macros
    before paging_init() is called.  This patch moves the init_mem_pgprot()
    call out of paging_init() and into setup_arch() so that pgprot_default
    gets initialized in time for fixmap and early_ioremap.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Borislav Petkov <borislav.petkov@amd.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 67da30741a1b..20830d1afbb6 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -360,6 +360,8 @@ void __init setup_arch(char **cmdline_p)
 
 	*cmdline_p = boot_command_line;
 
+	init_mem_pgprot();
+
 	parse_early_param();
 
 	arm64_memblock_init();

commit 4cf761cdccc3b050f768f25dc36342cdfec4efdd
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Mar 3 07:34:46 2014 +0000

    arm64: advertise ARMv8 extensions to 32-bit compat ELF binaries
    
    This adds support for advertising the presence of ARMv8 Crypto
    Extensions in the Aarch32 execution state to 32-bit ELF binaries
    running in 32-bit compat mode under the arm64 kernel.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 349c49260f09..67da30741a1b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -243,6 +243,38 @@ static void __init setup_processor(void)
 	block = (features >> 16) & 0xf;
 	if (block && !(block & 0x8))
 		elf_hwcap |= HWCAP_CRC32;
+
+#ifdef CONFIG_COMPAT
+	/*
+	 * ID_ISAR5_EL1 carries similar information as above, but pertaining to
+	 * the Aarch32 32-bit execution state.
+	 */
+	features = read_cpuid(ID_ISAR5_EL1);
+	block = (features >> 4) & 0xf;
+	if (!(block & 0x8)) {
+		switch (block) {
+		default:
+		case 2:
+			compat_elf_hwcap2 |= COMPAT_HWCAP2_PMULL;
+		case 1:
+			compat_elf_hwcap2 |= COMPAT_HWCAP2_AES;
+		case 0:
+			break;
+		}
+	}
+
+	block = (features >> 8) & 0xf;
+	if (block && !(block & 0x8))
+		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA1;
+
+	block = (features >> 12) & 0xf;
+	if (block && !(block & 0x8))
+		compat_elf_hwcap2 |= COMPAT_HWCAP2_SHA2;
+
+	block = (features >> 16) & 0xf;
+	if (block && !(block & 0x8))
+		compat_elf_hwcap2 |= COMPAT_HWCAP2_CRC32;
+#endif
 }
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)

commit 28964d32d495a0753986d464c48c8e1ae73699be
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Mon Mar 3 07:34:45 2014 +0000

    arm64: add AT_HWCAP2 support for 32-bit compat
    
    Add support for the ELF auxv entry AT_HWCAP2 when running 32-bit
    ELF binaries in compat mode.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index c8e9effe52e1..349c49260f09 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -69,6 +69,7 @@ EXPORT_SYMBOL_GPL(elf_hwcap);
 				 COMPAT_HWCAP_VFPv3|COMPAT_HWCAP_VFPv4|\
 				 COMPAT_HWCAP_NEON|COMPAT_HWCAP_IDIV)
 unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
+unsigned int compat_elf_hwcap2 __read_mostly;
 #endif
 
 static const char *cpu_name;

commit 0a5be743e8c3c3230600fbc0cf923fb5dbefd579
Merge: 6ac2104debc2 1307220d7bb7
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Dec 19 17:57:51 2013 +0000

    Merge tag 'arm64-suspend' of git://linux-arm.org/linux-2.6-lp into upstream
    
    * tag 'arm64-suspend' of git://linux-arm.org/linux-2.6-lp:
      arm64: add CPU power management menu/entries
      arm64: kernel: add PM build infrastructure
      arm64: kernel: add CPU idle call
      arm64: enable generic clockevent broadcast
      arm64: kernel: implement HW breakpoints CPU PM notifier
      arm64: kernel: refactor code to install/uninstall breakpoints
      arm: kvm: implement CPU PM notifier
      arm64: kernel: implement fpsimd CPU PM notifier
      arm64: kernel: cpu_{suspend/resume} implementation
      arm64: kernel: suspend/resume registers save/restore
      arm64: kernel: build MPIDR_EL1 hash function data structure
      arm64: kernel: add MPIDR_EL1 accessors macros
    
    Conflicts:
            arch/arm64/Kconfig

commit 4bff28ccda2b7a3fbdf8e80aef7a599284681dc6
Author: Steve Capper <steve.capper@linaro.org>
Date:   Mon Dec 16 21:04:36 2013 +0000

    arm64: Add hwcaps for crypto and CRC32 extensions.
    
    Advertise the optional cryptographic and CRC32 instructions to
    user space where present. Several hwcap bits [3-7] are allocated.
    
    Signed-off-by: Steve Capper <steve.capper@linaro.org>
    [bit 2 is taken now so use bits 3-7 instead]
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 82d65bb536b2..bb33fff09ba2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -126,6 +126,7 @@ bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
 static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;
+	u64 features, block;
 
 	cpu_info = lookup_processor_type(read_cpuid_id());
 	if (!cpu_info) {
@@ -141,6 +142,37 @@ static void __init setup_processor(void)
 
 	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;
+
+	/*
+	 * ID_AA64ISAR0_EL1 contains 4-bit wide signed feature blocks.
+	 * The blocks we test below represent incremental functionality
+	 * for non-negative values. Negative values are reserved.
+	 */
+	features = read_cpuid(ID_AA64ISAR0_EL1);
+	block = (features >> 4) & 0xf;
+	if (!(block & 0x8)) {
+		switch (block) {
+		default:
+		case 2:
+			elf_hwcap |= HWCAP_PMULL;
+		case 1:
+			elf_hwcap |= HWCAP_AES;
+		case 0:
+			break;
+		}
+	}
+
+	block = (features >> 8) & 0xf;
+	if (block && !(block & 0x8))
+		elf_hwcap |= HWCAP_SHA1;
+
+	block = (features >> 12) & 0xf;
+	if (block && !(block & 0x8))
+		elf_hwcap |= HWCAP_SHA2;
+
+	block = (features >> 16) & 0xf;
+	if (block && !(block & 0x8))
+		elf_hwcap |= HWCAP_CRC32;
 }
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
@@ -280,6 +312,11 @@ static const char *hwcap_str[] = {
 	"fp",
 	"asimd",
 	"evtstrm",
+	"aes",
+	"pmull",
+	"sha1",
+	"sha2",
+	"crc32",
 	NULL
 };
 

commit 81cac699440fc3707fd80f16bf34a7e506d41487
Author: Liviu Dudau <Liviu.Dudau@arm.com>
Date:   Tue Dec 17 18:19:46 2013 +0000

    arm64: Remove outdated comment
    
    Code referenced in the comment has moved to arch/arm64/kernel/cputable.c
    
    Signed-off-by: Liviu Dudau <Liviu.Dudau@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 97d90840a7fd..82d65bb536b2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -127,11 +127,6 @@ static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;
 
-	/*
-	 * locate processor in the list of supported processor
-	 * types.  The linker builds this table for us from the
-	 * entries in arch/arm/mm/proc.S
-	 */
 	cpu_info = lookup_processor_type(read_cpuid_id());
 	if (!cpu_info) {
 		printk("CPU configuration botched (ID %08x), unable to continue.\n",

commit 7158627686f02319c50c8d9d78f75d4c8d126ff2
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Nov 5 18:10:47 2013 +0000

    arm64: percpu: implement optimised pcpu access using tpidr_el1
    
    This patch implements optimised percpu variable accesses using the
    el1 r/w thread register (tpidr_el1) along the same lines as arch/arm/.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index bd9bbd0e44ed..97d90840a7fd 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -108,6 +108,16 @@ void __init early_print(const char *str, ...)
 	printk("%s", buf);
 }
 
+void __init smp_setup_processor_id(void)
+{
+	/*
+	 * clear __my_cpu_offset on boot CPU to avoid hang caused by
+	 * using percpu variable early, for example, lockdep will
+	 * access percpu variable inside lock_release
+	 */
+	set_my_cpu_offset(0);
+}
+
 bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
 {
 	return phys_id == cpu_logical_map(cpu);

commit 976d7d3f79a997b223f2ed8eabef7e12e469b5cf
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Thu May 16 10:32:09 2013 +0100

    arm64: kernel: build MPIDR_EL1 hash function data structure
    
    On ARM64 SMP systems, cores are identified by their MPIDR_EL1 register.
    The MPIDR_EL1 guidelines in the ARM ARM do not provide strict enforcement of
    MPIDR_EL1 layout, only recommendations that, if followed, split the MPIDR_EL1
    on ARM 64 bit platforms in four affinity levels. In multi-cluster
    systems like big.LITTLE, if the affinity guidelines are followed, the
    MPIDR_EL1 can not be considered a linear index. This means that the
    association between logical CPU in the kernel and the HW CPU identifier
    becomes somewhat more complicated requiring methods like hashing to
    associate a given MPIDR_EL1 to a CPU logical index, in order for the look-up
    to be carried out in an efficient and scalable way.
    
    This patch provides a function in the kernel that starting from the
    cpu_logical_map, implement collision-free hashing of MPIDR_EL1 values by
    checking all significative bits of MPIDR_EL1 affinity level bitfields.
    The hashing can then be carried out through bits shifting and ORing; the
    resulting hash algorithm is a collision-free though not minimal hash that can
    be executed with few assembly instructions. The mpidr_el1 is filtered through a
    mpidr mask that is built by checking all bits that toggle in the set of
    MPIDR_EL1s corresponding to possible CPUs. Bits that do not toggle do not
    carry information so they do not contribute to the resulting hash.
    
    Pseudo code:
    
    /* check all bits that toggle, so they are required */
    for (i = 1, mpidr_el1_mask = 0; i < num_possible_cpus(); i++)
            mpidr_el1_mask |= (cpu_logical_map(i) ^ cpu_logical_map(0));
    
    /*
     * Build shifts to be applied to aff0, aff1, aff2, aff3 values to hash the
     * mpidr_el1
     * fls() returns the last bit set in a word, 0 if none
     * ffs() returns the first bit set in a word, 0 if none
     */
    fs0 = mpidr_el1_mask[7:0] ? ffs(mpidr_el1_mask[7:0]) - 1 : 0;
    fs1 = mpidr_el1_mask[15:8] ? ffs(mpidr_el1_mask[15:8]) - 1 : 0;
    fs2 = mpidr_el1_mask[23:16] ? ffs(mpidr_el1_mask[23:16]) - 1 : 0;
    fs3 = mpidr_el1_mask[39:32] ? ffs(mpidr_el1_mask[39:32]) - 1 : 0;
    ls0 = fls(mpidr_el1_mask[7:0]);
    ls1 = fls(mpidr_el1_mask[15:8]);
    ls2 = fls(mpidr_el1_mask[23:16]);
    ls3 = fls(mpidr_el1_mask[39:32]);
    bits0 = ls0 - fs0;
    bits1 = ls1 - fs1;
    bits2 = ls2 - fs2;
    bits3 = ls3 - fs3;
    aff0_shift = fs0;
    aff1_shift = 8 + fs1 - bits0;
    aff2_shift = 16 + fs2 - (bits0 + bits1);
    aff3_shift = 32 + fs3 - (bits0 + bits1 + bits2);
    u32 hash(u64 mpidr_el1) {
            u32 l[4];
            u64 mpidr_el1_masked = mpidr_el1 & mpidr_el1_mask;
            l[0] = mpidr_el1_masked & 0xff;
            l[1] = mpidr_el1_masked & 0xff00;
            l[2] = mpidr_el1_masked & 0xff0000;
            l[3] = mpidr_el1_masked & 0xff00000000;
            return (l[0] >> aff0_shift | l[1] >> aff1_shift | l[2] >> aff2_shift |
                    l[3] >> aff3_shift);
    }
    
    The hashing algorithm relies on the inherent properties set in the ARM ARM
    recommendations for the MPIDR_EL1. Exotic configurations, where for instance
    the MPIDR_EL1 values at a given affinity level have large holes, can end up
    requiring big hash tables since the compression of values that can be achieved
    through shifting is somewhat crippled when holes are present. Kernel warns if
    the number of buckets of the resulting hash table exceeds the number of
    possible CPUs by a factor of 4, which is a symptom of a very sparse HW
    MPIDR_EL1 configuration.
    
    The hash algorithm is quite simple and can easily be implemented in assembly
    code, to be used in code paths where the kernel virtual address space is
    not set-up (ie cpu_resume) and instruction and data fetches are strongly
    ordered so code must be compact and must carry out few data accesses.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index bd9bbd0e44ed..87ddfce35cb5 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -113,6 +113,75 @@ bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
 	return phys_id == cpu_logical_map(cpu);
 }
 
+struct mpidr_hash mpidr_hash;
+#ifdef CONFIG_SMP
+/**
+ * smp_build_mpidr_hash - Pre-compute shifts required at each affinity
+ *			  level in order to build a linear index from an
+ *			  MPIDR value. Resulting algorithm is a collision
+ *			  free hash carried out through shifting and ORing
+ */
+static void __init smp_build_mpidr_hash(void)
+{
+	u32 i, affinity, fs[4], bits[4], ls;
+	u64 mask = 0;
+	/*
+	 * Pre-scan the list of MPIDRS and filter out bits that do
+	 * not contribute to affinity levels, ie they never toggle.
+	 */
+	for_each_possible_cpu(i)
+		mask |= (cpu_logical_map(i) ^ cpu_logical_map(0));
+	pr_debug("mask of set bits %#llx\n", mask);
+	/*
+	 * Find and stash the last and first bit set at all affinity levels to
+	 * check how many bits are required to represent them.
+	 */
+	for (i = 0; i < 4; i++) {
+		affinity = MPIDR_AFFINITY_LEVEL(mask, i);
+		/*
+		 * Find the MSB bit and LSB bits position
+		 * to determine how many bits are required
+		 * to express the affinity level.
+		 */
+		ls = fls(affinity);
+		fs[i] = affinity ? ffs(affinity) - 1 : 0;
+		bits[i] = ls - fs[i];
+	}
+	/*
+	 * An index can be created from the MPIDR_EL1 by isolating the
+	 * significant bits at each affinity level and by shifting
+	 * them in order to compress the 32 bits values space to a
+	 * compressed set of values. This is equivalent to hashing
+	 * the MPIDR_EL1 through shifting and ORing. It is a collision free
+	 * hash though not minimal since some levels might contain a number
+	 * of CPUs that is not an exact power of 2 and their bit
+	 * representation might contain holes, eg MPIDR_EL1[7:0] = {0x2, 0x80}.
+	 */
+	mpidr_hash.shift_aff[0] = MPIDR_LEVEL_SHIFT(0) + fs[0];
+	mpidr_hash.shift_aff[1] = MPIDR_LEVEL_SHIFT(1) + fs[1] - bits[0];
+	mpidr_hash.shift_aff[2] = MPIDR_LEVEL_SHIFT(2) + fs[2] -
+						(bits[1] + bits[0]);
+	mpidr_hash.shift_aff[3] = MPIDR_LEVEL_SHIFT(3) +
+				  fs[3] - (bits[2] + bits[1] + bits[0]);
+	mpidr_hash.mask = mask;
+	mpidr_hash.bits = bits[3] + bits[2] + bits[1] + bits[0];
+	pr_debug("MPIDR hash: aff0[%u] aff1[%u] aff2[%u] aff3[%u] mask[%#llx] bits[%u]\n",
+		mpidr_hash.shift_aff[0],
+		mpidr_hash.shift_aff[1],
+		mpidr_hash.shift_aff[2],
+		mpidr_hash.shift_aff[3],
+		mpidr_hash.mask,
+		mpidr_hash.bits);
+	/*
+	 * 4x is an arbitrary value used to warn on a hash table much bigger
+	 * than expected on most systems.
+	 */
+	if (mpidr_hash_size() > 4 * num_possible_cpus())
+		pr_warn("Large number of MPIDR hash buckets detected\n");
+	__flush_dcache_area(&mpidr_hash, sizeof(struct mpidr_hash));
+}
+#endif
+
 static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;
@@ -236,6 +305,7 @@ void __init setup_arch(char **cmdline_p)
 	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
 	smp_init_cpus();
+	smp_build_mpidr_hash();
 #endif
 
 #ifdef CONFIG_VT

commit b3bf6aa7e79117419f7eddccf0b7af4382d823c3
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Nov 21 14:46:17 2013 +0000

    arm64: Unmask asynchronous aborts when in kernel mode
    
    The asynchronous aborts are generally fatal for the kernel but they can
    be masked via the pstate A bit. If a system error happens while in
    kernel mode, it won't be visible until returning to user space. This
    patch enables this kind of abort early to help identifying the cause.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 0bc5e4cbc017..bd9bbd0e44ed 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -205,6 +205,11 @@ u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
 
 void __init setup_arch(char **cmdline_p)
 {
+	/*
+	 * Unmask asynchronous aborts early to catch possible system errors.
+	 */
+	local_async_enable();
+
 	setup_processor();
 
 	setup_machine_fdt(__fdt_pointer);

commit 10d0c9705e80bbd3d587c5fad24599aabaca6688
Merge: 85b656cf1560 c11eede69b6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 16:52:17 2013 +0900

    Merge tag 'devicetree-for-3.13' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux
    
    Pull devicetree updates from Rob Herring:
     "DeviceTree updates for 3.13.  This is a bit larger pull request than
      usual for this cycle with lots of clean-up.
    
       - Cross arch clean-up and consolidation of early DT scanning code.
       - Clean-up and removal of arch prom.h headers.  Makes arch specific
         prom.h optional on all but Sparc.
       - Addition of interrupts-extended property for devices connected to
         multiple interrupt controllers.
       - Refactoring of DT interrupt parsing code in preparation for
         deferred probe of interrupts.
       - ARM cpu and cpu topology bindings documentation.
       - Various DT vendor binding documentation updates"
    
    * tag 'devicetree-for-3.13' of git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux: (82 commits)
      powerpc: add missing explicit OF includes for ppc
      dt/irq: add empty of_irq_count for !OF_IRQ
      dt: disable self-tests for !OF_IRQ
      of: irq: Fix interrupt-map entry matching
      MIPS: Netlogic: replace early_init_devtree() call
      of: Add Panasonic Corporation vendor prefix
      of: Add Chunghwa Picture Tubes Ltd. vendor prefix
      of: Add AU Optronics Corporation vendor prefix
      of/irq: Fix potential buffer overflow
      of/irq: Fix bug in interrupt parsing refactor.
      of: set dma_mask to point to coherent_dma_mask
      of: add vendor prefix for PHYTEC Messtechnik GmbH
      DT: sort vendor-prefixes.txt
      of: Add vendor prefix for Cadence
      of: Add empty for_each_available_child_of_node() macro definition
      arm/versatile: Fix versatile irq specifications.
      of/irq: create interrupts-extended property
      microblaze/pci: Drop PowerPC-ism from irq parsing
      of/irq: Create of_irq_parse_and_map_pci() to consolidate arch code.
      of/irq: Use irq_of_parse_and_map()
      ...

commit 87093826aa0172d9135ca1f301c4298a258ceee6
Merge: 39cf275a1a18 ee5872befc93
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 10:36:00 2013 +0900

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer changes from Ingo Molnar:
     "Main changes in this cycle were:
    
       - Updated full dynticks support.
    
       - Event stream support for architected (ARM) timers.
    
       - ARM clocksource driver updates.
    
       - Move arm64 to using the generic sched_clock framework & resulting
         cleanup in the generic sched_clock code.
    
       - Misc fixes and cleanups"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (50 commits)
      x86/time: Honor ACPI FADT flag indicating absence of a CMOS RTC
      clocksource: sun4i: remove IRQF_DISABLED
      clocksource: sun4i: Report the minimum tick that we can program
      clocksource: sun4i: Select CLKSRC_MMIO
      clocksource: Provide timekeeping for efm32 SoCs
      clocksource: em_sti: convert to clk_prepare/unprepare
      time: Fix signedness bug in sysfs_get_uname() and its callers
      timekeeping: Fix some trivial typos in comments
      alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
      clocksource: arch_timer: Do not register arch_sys_counter twice
      timer stats: Add a 'Collection: active/inactive' line to timer usage statistics
      sched_clock: Remove sched_clock_func() hook
      arch_timer: Move to generic sched_clock framework
      clocksource: tcb_clksrc: Remove IRQF_DISABLED
      clocksource: tcb_clksrc: Improve driver robustness
      clocksource: tcb_clksrc: Replace clk_enable/disable with clk_prepare_enable/disable_unprepare
      clocksource: arm_arch_timer: Use clocksource for suspend timekeeping
      clocksource: dw_apb_timer_of: Mark a few more functions as __init
      clocksource: Put nodes passed to CLOCKSOURCE_OF_DECLARE callbacks centrally
      arm: zynq: Enable arm_global_timer
      ...

commit 6e15d0e04bfeaa5662a289ee915273307326e45a
Author: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
Date:   Mon Oct 21 13:29:42 2013 +0100

    ARM64: DT: define ARM64 specific arch_match_cpu_phys_id
    
    OF/DT core library provides architecture specific hook to match the
    logical cpu index with the corresponding physical identifier.
    
    On ARM64, the MPIDR_EL1 contains specific bitfields(MPIDR_EL1.Aff{3..0})
    which uniquely identify a CPU, in addition to some non-identifying
    information and reserved bits. The ARM cpu binding defines the 'reg'
    property to only contain the affinity bits, and any cpu nodes with other
    bits set in their 'reg' entry are skipped.
    
    This patch overrides the weak definition of arch_match_cpu_phys_id
    with ARM64 specific version using MPIDR_EL1.Aff{3..0} as cpu physical
    identifiers.
    
    Signed-off-by: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index fa6faf564da2..9cf30f49610d 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -98,6 +98,11 @@ void __init early_print(const char *str, ...)
 	printk("%s", buf);
 }
 
+bool arch_match_cpu_phys_id(int cpu, u64 phys_id)
+{
+	return phys_id == cpu_logical_map(cpu);
+}
+
 static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;

commit 94ed1f2cb5d46533f10262b1b760db7dbec9cf10
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Oct 11 14:52:11 2013 +0100

    arm64: setup: report ELF_PLATFORM as the machine for utsname
    
    uname -m reports the machine field from the current utsname, which should
    reflect the endianness of the system.
    
    This patch reports ELF_PLATFORM for the field, so that everything appears
    consistent from userspace.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index b65c132fac30..fa6faf564da2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -119,7 +119,7 @@ static void __init setup_processor(void)
 	printk("CPU: %s [%08x] revision %d\n",
 	       cpu_name, read_cpuid_id(), read_cpuid_id() & 15);
 
-	sprintf(init_utsname()->machine, "aarch64");
+	sprintf(init_utsname()->machine, ELF_PLATFORM);
 	elf_hwcap = 0;
 }
 

commit e8765b265a69c83504afc6901d6e137b1811d1f0
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Oct 24 20:30:17 2013 +0100

    arm64: read enable-method for CPU0
    
    With the advent of CPU_HOTPLUG, the enable-method property for CPU0 may
    tells us something useful (i.e. how to hotplug it back on), so we must
    read it along with all the enable-method for all the other CPUs.  Even
    on UP the enable-method may tell us useful information (e.g. if a core
    has some mechanism that might be usable for cpuidle), so we should
    always read it.
    
    This patch factors out the reading of the enable method, and ensures
    that CPU0's enable method is read regardless of whether the kernel is
    built with SMP support.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 055cfb80e05c..b65c132fac30 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -45,6 +45,7 @@
 #include <asm/cputype.h>
 #include <asm/elf.h>
 #include <asm/cputable.h>
+#include <asm/cpu_ops.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
 #include <asm/smp_plat.h>
@@ -264,6 +265,7 @@ void __init setup_arch(char **cmdline_p)
 	psci_init();
 
 	cpu_logical_map(0) = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
+	cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
 	smp_init_cpus();
 #endif

commit f2b99bccae87de82a5d03838abe85d604ee7e525
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Tue Aug 27 21:44:37 2013 -0500

    arm64: use common of_flat_dt_get_machine_name
    
    Convert arm64 to use the common of_flat_dt_get_machine_name function.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7feb0c97d0dd..a4ed2d3e4de9 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -124,8 +124,6 @@ static void __init setup_processor(void)
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
-	unsigned long dt_root;
-
 	if (!dt_phys || !early_init_dt_scan(phys_to_virt(dt_phys))) {
 		early_print("\n"
 			"Error: invalid device tree blob at physical address 0x%p (virtual address 0x%p)\n"
@@ -137,14 +135,7 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 			cpu_relax();
 	}
 
-	dt_root = of_get_flat_dt_root();
-
-	machine_name = of_get_flat_dt_prop(dt_root, "model", NULL);
-	if (!machine_name)
-		machine_name = of_get_flat_dt_prop(dt_root, "compatible", NULL);
-	if (!machine_name)
-		machine_name = "<unknown>";
-	pr_info("Machine: %s\n", machine_name);
+	machine_name = of_flat_dt_get_machine_name();
 }
 
 /*

commit 068f6310b965d67d57f89ebf4c539e5933754366
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Tue Sep 24 22:20:01 2013 -0500

    of: create default early_init_dt_add_memory_arch
    
    Create a weak version of early_init_dt_add_memory_arch which uses
    memblock. This will unify all architectures except ones with custom
    memory bank structs.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Jonas Bonn <jonas@southpole.se>
    Acked-by: Grant Likely <grant.likely@linaro.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: microblaze-uclinux@itee.uq.edu.au
    Cc: linux@lists.openrisc.net
    Cc: devicetree@vger.kernel.org

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4a5f6243ade2..7feb0c97d0dd 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -147,24 +147,6 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 	pr_info("Machine: %s\n", machine_name);
 }
 
-void __init early_init_dt_add_memory_arch(u64 base, u64 size)
-{
-	base &= PAGE_MASK;
-	size &= PAGE_MASK;
-	if (base + size < PHYS_OFFSET) {
-		pr_warning("Ignoring memory block 0x%llx - 0x%llx\n",
-			   base, base + size);
-		return;
-	}
-	if (base < PHYS_OFFSET) {
-		pr_warning("Ignoring memory range 0x%llx - 0x%llx\n",
-			   base, PHYS_OFFSET);
-		size -= PHYS_OFFSET - base;
-		base = PHYS_OFFSET;
-	}
-	memblock_add(base, size);
-}
-
 /*
  * Limit the memory size that was specified via FDT.
  */

commit d5189cc57b1d231b6dc745de6b68881901d0c5c4
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Mon Aug 26 10:14:32 2013 -0500

    arm64: use early_init_dt_scan
    
    Convert arm64 to use new early_init_dt_scan function.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 055cfb80e05c..4a5f6243ade2 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -124,37 +124,19 @@ static void __init setup_processor(void)
 
 static void __init setup_machine_fdt(phys_addr_t dt_phys)
 {
-	struct boot_param_header *devtree;
 	unsigned long dt_root;
 
-	/* Check we have a non-NULL DT pointer */
-	if (!dt_phys) {
-		early_print("\n"
-			"Error: NULL or invalid device tree blob\n"
-			"The dtb must be 8-byte aligned and passed in the first 512MB of memory\n"
-			"\nPlease check your bootloader.\n");
-
-		while (true)
-			cpu_relax();
-
-	}
-
-	devtree = phys_to_virt(dt_phys);
-
-	/* Check device tree validity */
-	if (be32_to_cpu(devtree->magic) != OF_DT_HEADER) {
+	if (!dt_phys || !early_init_dt_scan(phys_to_virt(dt_phys))) {
 		early_print("\n"
 			"Error: invalid device tree blob at physical address 0x%p (virtual address 0x%p)\n"
-			"Expected 0x%x, found 0x%x\n"
+			"The dtb must be 8-byte aligned and passed in the first 512MB of memory\n"
 			"\nPlease check your bootloader.\n",
-			dt_phys, devtree, OF_DT_HEADER,
-			be32_to_cpu(devtree->magic));
+			dt_phys, phys_to_virt(dt_phys));
 
 		while (true)
 			cpu_relax();
 	}
 
-	initial_boot_params = devtree;
 	dt_root = of_get_flat_dt_root();
 
 	machine_name = of_get_flat_dt_prop(dt_root, "model", NULL);
@@ -163,13 +145,6 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 	if (!machine_name)
 		machine_name = "<unknown>";
 	pr_info("Machine: %s\n", machine_name);
-
-	/* Retrieve various information from the /chosen node */
-	of_scan_flat_dt(early_init_dt_scan_chosen, boot_command_line);
-	/* Initialize {size,address}-cells info */
-	of_scan_flat_dt(early_init_dt_scan_root, NULL);
-	/* Setup memory, calling early_init_dt_add_memory_arch */
-	of_scan_flat_dt(early_init_dt_scan_memory, NULL);
 }
 
 void __init early_init_dt_add_memory_arch(u64 base, u64 size)

commit 46efe547aca8498d51b64460c02366ae4032ca32
Author: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
Date:   Tue Aug 13 15:57:53 2013 +0100

    ARM64: arch_timer: add support to configure and enable event stream
    
    This patch adds support for configuring the event stream frequency
    and enabling it.
    
    It also adds the hwcaps as well as compat-specific definitions to
    the user to detect this event stream feature.
    
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 055cfb80e05c..d355b7b9710b 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -60,6 +60,16 @@ EXPORT_SYMBOL(processor_id);
 unsigned long elf_hwcap __read_mostly;
 EXPORT_SYMBOL_GPL(elf_hwcap);
 
+#ifdef CONFIG_COMPAT
+#define COMPAT_ELF_HWCAP_DEFAULT	\
+				(COMPAT_HWCAP_HALF|COMPAT_HWCAP_THUMB|\
+				 COMPAT_HWCAP_FAST_MULT|COMPAT_HWCAP_EDSP|\
+				 COMPAT_HWCAP_TLS|COMPAT_HWCAP_VFP|\
+				 COMPAT_HWCAP_VFPv3|COMPAT_HWCAP_VFPv4|\
+				 COMPAT_HWCAP_NEON|COMPAT_HWCAP_IDIV)
+unsigned int compat_elf_hwcap __read_mostly = COMPAT_ELF_HWCAP_DEFAULT;
+#endif
+
 static const char *cpu_name;
 static const char *machine_name;
 phys_addr_t __fdt_pointer __initdata;
@@ -304,6 +314,7 @@ subsys_initcall(topology_init);
 static const char *hwcap_str[] = {
 	"fp",
 	"asimd",
+	"evtstrm",
 	NULL
 };
 

commit 25804e6a96681d5d2142058948e218999e4f547c
Author: Steve Capper <Steve.Capper@arm.com>
Date:   Wed Sep 18 16:14:28 2013 +0100

    arm64: Widen hwcap to be 64 bit
    
    Under arm64 elf_hwcap is a 32 bit quantity, but it is stored in
    a 64 bit auxiliary ELF field and glibc reads hwcap as 64 bit.
    
    This patch widens elf_hwcap to be 64 bit.
    
    Signed-off-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 12ad8f3d0cfd..055cfb80e05c 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -57,7 +57,7 @@
 unsigned int processor_id;
 EXPORT_SYMBOL(processor_id);
 
-unsigned int elf_hwcap __read_mostly;
+unsigned long elf_hwcap __read_mostly;
 EXPORT_SYMBOL_GPL(elf_hwcap);
 
 static const char *cpu_name;

commit 31f7c3a688f75bceaf2fd009efc489659ad6aa61
Merge: ec5b103ecfde 2bc552df76d8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 10 13:53:52 2013 -0700

    Merge tag 'devicetree-for-linus' of git://git.secretlab.ca/git/linux
    
    Pull device tree core updates from Grant Likely:
     "Generally minor changes.  A bunch of bug fixes, particularly for
      initialization and some refactoring.  Most notable change if feeding
      the entire flattened tree into the random pool at boot.  May not be
      significant, but shouldn't hurt either"
    
    Tim Bird questions whether the boot time cost of the random feeding may
    be noticeable.  And "add_device_randomness()" is definitely not some
    speed deamon of a function.
    
    * tag 'devicetree-for-linus' of git://git.secretlab.ca/git/linux:
      of/platform: add error reporting to of_amba_device_create()
      irq/of: Fix comment typo for irq_of_parse_and_map
      of: Feed entire flattened device tree into the random pool
      of/fdt: Clean up casting in unflattening path
      of/fdt: Remove duplicate memory clearing on FDT unflattening
      gpio: implement gpio-ranges binding document fix
      of: call __of_parse_phandle_with_args from of_parse_phandle
      of: introduce of_parse_phandle_with_fixed_args
      of: move of_parse_phandle()
      of: move documentation of of_parse_phandle_with_args
      of: Fix missing memory initialization on FDT unflattening
      of: consolidate definition of early_init_dt_alloc_memory_arch()
      of: Make of_get_phy_mode() return int i.s.o. const int
      include: dt-binding: input: create a DT header defining key codes.
      of/platform: Staticize of_platform_device_create_pdata()
      of: Specify initrd location using 64-bit
      dt: Typo fix
      OF: make of_property_for_each_{u32|string}() use parameters if OF is not enabled

commit 326b16db9f69fd0d279be873c6c00f88c0a4aad5
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Aug 30 18:06:48 2013 +0100

    arm64: delay: don't bother reporting bogomips in /proc/cpuinfo
    
    We always use a timer-backed delay loop for arm64, so don't bother
    reporting a bogomips value which appears to confuse some people.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index add6ea616843..bca4c1c2052a 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -328,9 +328,6 @@ static int c_show(struct seq_file *m, void *v)
 #ifdef CONFIG_SMP
 		seq_printf(m, "processor\t: %d\n", i);
 #endif
-		seq_printf(m, "BogoMIPS\t: %lu.%02lu\n\n",
-			   loops_per_jiffy / (500000UL/HZ),
-			   loops_per_jiffy / (5000UL/HZ) % 100);
 	}
 
 	/* dump out the processor features */

commit a1727da599ad030ccaf4073473fd235c8ee28219
Author: Grant Likely <grant.likely@linaro.org>
Date:   Wed Aug 28 21:18:32 2013 +0100

    of: consolidate definition of early_init_dt_alloc_memory_arch()
    
    Most architectures use the same implementation. Collapse the common ones
    into a single weak function that can be overridden.
    
    Signed-off-by: Grant Likely <grant.likely@linaro.org>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index add6ea616843..0f9856a2afa4 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -190,11 +190,6 @@ void __init early_init_dt_add_memory_arch(u64 base, u64 size)
 	memblock_add(base, size);
 }
 
-void * __init early_init_dt_alloc_memory_arch(u64 size, u64 align)
-{
-	return __va(memblock_alloc(size, align));
-}
-
 /*
  * Limit the memory size that was specified via FDT.
  */

commit c560ecfe9617c629ad09b07edb7523c87b2c9619
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue May 14 10:51:18 2013 +0100

    arm64: Invoke the of_platform_populate() at arch_initcall() level
    
    The of_platform_populate() is currently invoked at device_initcall()
    level. There are however drivers that use platform_driver_probe()
    directly and they need the devices to be populated. This patch makes the
    of_platform_populate() and arch_initcall().
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Reported-by: Benoit Lecardonnel <Benoit.Lecardonnel@synopsys.com>
    Tested-by: Benoit Lecardonnel <Benoit.Lecardonnel@synopsys.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 6a9a53292590..add6ea616843 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -282,12 +282,13 @@ void __init setup_arch(char **cmdline_p)
 #endif
 }
 
-static int __init arm64_of_clk_init(void)
+static int __init arm64_device_init(void)
 {
 	of_clk_init(NULL);
+	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 	return 0;
 }
-arch_initcall(arm64_of_clk_init);
+arch_initcall(arm64_device_init);
 
 static DEFINE_PER_CPU(struct cpu, cpu_data);
 
@@ -305,13 +306,6 @@ static int __init topology_init(void)
 }
 subsys_initcall(topology_init);
 
-static int __init arm64_device_probe(void)
-{
-	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
-	return 0;
-}
-device_initcall(arm64_device_probe);
-
 static const char *hwcap_str[] = {
 	"fp",
 	"asimd",

commit 4c7aa0021356ee91b96cea51b8b7fadebaba489e
Author: Javi Merino <javi.merino@arm.com>
Date:   Wed Aug 29 09:47:19 2012 +0100

    arm64: kernel: initialise cpu_logical_map from the DT
    
    When booting the kernel, the cpu logical id map must be initialised
    using device tree data passed by FW or through an embedded blob.
    
    This patch parses the reg property in device tree "cpu" nodes,
    retrieves the corresponding CPUs hardware identifiers (MPIDR) and
    initialises the cpu logical map accordingly.
    
    The device tree HW identifiers are considered valid if all CPU nodes
    contain a "reg" property, there are no duplicate "reg" entries and the
    DT defines a CPU node whose "reg" property defines affinity levels
    that matches those of the boot CPU.
    
    The primary CPU is assigned cpu logical number 0 to keep the current
    convention valid.
    
    Based on a0ae02405076ac32bd17ece976e914b5b6075bb0 (ARM: kernel: add
    device tree init map function).
    
    Signed-off-by: Javi Merino <javi.merino@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 9c023d714f44..6a9a53292590 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -47,6 +47,7 @@
 #include <asm/cputable.h>
 #include <asm/sections.h>
 #include <asm/setup.h>
+#include <asm/smp_plat.h>
 #include <asm/cacheflush.h>
 #include <asm/tlbflush.h>
 #include <asm/traps.h>
@@ -241,6 +242,8 @@ static void __init request_standard_resources(void)
 	}
 }
 
+u64 __cpu_logical_map[NR_CPUS] = { [0 ... NR_CPUS-1] = INVALID_HWID };
+
 void __init setup_arch(char **cmdline_p)
 {
 	setup_processor();
@@ -265,6 +268,7 @@ void __init setup_arch(char **cmdline_p)
 
 	psci_init();
 
+	cpu_logical_map(0) = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
 #ifdef CONFIG_SMP
 	smp_init_cpus();
 #endif

commit de79a64d61ed3f7ccec9f9661fab2f3e97256243
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Feb 8 12:18:15 2013 +0000

    arm64: Initialise the clocks described via DT
    
    This patch adds an arch_initcall() for the of_clk_init() clock
    initialisation.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 113db863f832..9c023d714f44 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -32,6 +32,7 @@
 #include <linux/kexec.h>
 #include <linux/crash_dump.h>
 #include <linux/root_dev.h>
+#include <linux/clk-provider.h>
 #include <linux/cpu.h>
 #include <linux/interrupt.h>
 #include <linux/smp.h>
@@ -277,6 +278,13 @@ void __init setup_arch(char **cmdline_p)
 #endif
 }
 
+static int __init arm64_of_clk_init(void)
+{
+	of_clk_init(NULL);
+	return 0;
+}
+arch_initcall(arm64_of_clk_init);
+
 static DEFINE_PER_CPU(struct cpu, cpu_data);
 
 static int __init topology_init(void)

commit e790f1deb26a2e23f05dee0b9a5d4f764c3d7ea7
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Dec 18 17:53:14 2012 +0000

    arm64: psci: add support for PSCI invocations from the kernel
    
    This patch adds support for the Power State Coordination Interface
    defined by ARM, allowing Linux to request CPU-centric power-management
    operations from firmware implementing the PSCI protocol.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    [Marc: s/u32/u64/ in the relevant spots, and switch from an initcall
     to an simpler init function]
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 894c1e5ed609..113db863f832 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -50,6 +50,7 @@
 #include <asm/tlbflush.h>
 #include <asm/traps.h>
 #include <asm/memblock.h>
+#include <asm/psci.h>
 
 unsigned int processor_id;
 EXPORT_SYMBOL(processor_id);
@@ -261,6 +262,8 @@ void __init setup_arch(char **cmdline_p)
 
 	unflatten_device_tree();
 
+	psci_init();
+
 #ifdef CONFIG_SMP
 	smp_init_cpus();
 #endif

commit d6bafb9b821a3a5ddeb600a9fd015085760d818e
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Dec 7 17:47:17 2012 +0000

    arm64: Populate the platform devices
    
    This patch add a device_initcall() to populate the platform devices
    (of_default_bus_match_table). This allows SoC implementations that do
    not require earlier initcalls to avoid any platform-specific code under
    arch/arm64.
    
    GIC and generic timer initialisation is done via FDT and CPU notifiers
    independently of the SoC code.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 7665a9bfdb1e..894c1e5ed609 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -39,6 +39,7 @@
 #include <linux/proc_fs.h>
 #include <linux/memblock.h>
 #include <linux/of_fdt.h>
+#include <linux/of_platform.h>
 
 #include <asm/cputype.h>
 #include <asm/elf.h>
@@ -289,6 +290,13 @@ static int __init topology_init(void)
 }
 subsys_initcall(topology_init);
 
+static int __init arm64_device_probe(void)
+{
+	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
+	return 0;
+}
+device_initcall(arm64_device_probe);
+
 static const char *hwcap_str[] = {
 	"fp",
 	"asimd",

commit f71a1a42667f576ec736bb1200eba2118fee3a22
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue Oct 16 12:00:29 2012 +0100

    arm64: Ignore memory blocks below PHYS_OFFSET
    
    According to Documentation/arm64/booting.txt, the kernel image must be
    loaded at a pre-defined offset from the start of RAM so that the kernel
    can calculate PHYS_OFFSET based on this address. If the DT contains
    memory blocks below this PHYS_OFFSET, report them and ignore the
    corresponding memory range.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 48ffb9fb3fe3..7665a9bfdb1e 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -170,7 +170,19 @@ static void __init setup_machine_fdt(phys_addr_t dt_phys)
 
 void __init early_init_dt_add_memory_arch(u64 base, u64 size)
 {
+	base &= PAGE_MASK;
 	size &= PAGE_MASK;
+	if (base + size < PHYS_OFFSET) {
+		pr_warning("Ignoring memory block 0x%llx - 0x%llx\n",
+			   base, base + size);
+		return;
+	}
+	if (base < PHYS_OFFSET) {
+		pr_warning("Ignoring memory range 0x%llx - 0x%llx\n",
+			   base, PHYS_OFFSET);
+		size -= PHYS_OFFSET - base;
+		base = PHYS_OFFSET;
+	}
 	memblock_add(base, size);
 }
 

commit 9703d9d7f77ce129621f7d80a844822e2daa7008
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Mar 5 11:49:27 2012 +0000

    arm64: Kernel booting and initialisation
    
    The patch adds the kernel booting and the initial setup code.
    Documentation/arm64/booting.txt describes the booting protocol on the
    AArch64 Linux kernel. This is subject to change following the work on
    boot standardisation, ACPI.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
new file mode 100644
index 000000000000..48ffb9fb3fe3
--- /dev/null
+++ b/arch/arm64/kernel/setup.c
@@ -0,0 +1,347 @@
+/*
+ * Based on arch/arm/kernel/setup.c
+ *
+ * Copyright (C) 1995-2001 Russell King
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/export.h>
+#include <linux/kernel.h>
+#include <linux/stddef.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/utsname.h>
+#include <linux/initrd.h>
+#include <linux/console.h>
+#include <linux/bootmem.h>
+#include <linux/seq_file.h>
+#include <linux/screen_info.h>
+#include <linux/init.h>
+#include <linux/kexec.h>
+#include <linux/crash_dump.h>
+#include <linux/root_dev.h>
+#include <linux/cpu.h>
+#include <linux/interrupt.h>
+#include <linux/smp.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/memblock.h>
+#include <linux/of_fdt.h>
+
+#include <asm/cputype.h>
+#include <asm/elf.h>
+#include <asm/cputable.h>
+#include <asm/sections.h>
+#include <asm/setup.h>
+#include <asm/cacheflush.h>
+#include <asm/tlbflush.h>
+#include <asm/traps.h>
+#include <asm/memblock.h>
+
+unsigned int processor_id;
+EXPORT_SYMBOL(processor_id);
+
+unsigned int elf_hwcap __read_mostly;
+EXPORT_SYMBOL_GPL(elf_hwcap);
+
+static const char *cpu_name;
+static const char *machine_name;
+phys_addr_t __fdt_pointer __initdata;
+
+/*
+ * Standard memory resources
+ */
+static struct resource mem_res[] = {
+	{
+		.name = "Kernel code",
+		.start = 0,
+		.end = 0,
+		.flags = IORESOURCE_MEM
+	},
+	{
+		.name = "Kernel data",
+		.start = 0,
+		.end = 0,
+		.flags = IORESOURCE_MEM
+	}
+};
+
+#define kernel_code mem_res[0]
+#define kernel_data mem_res[1]
+
+void __init early_print(const char *str, ...)
+{
+	char buf[256];
+	va_list ap;
+
+	va_start(ap, str);
+	vsnprintf(buf, sizeof(buf), str, ap);
+	va_end(ap);
+
+	printk("%s", buf);
+}
+
+static void __init setup_processor(void)
+{
+	struct cpu_info *cpu_info;
+
+	/*
+	 * locate processor in the list of supported processor
+	 * types.  The linker builds this table for us from the
+	 * entries in arch/arm/mm/proc.S
+	 */
+	cpu_info = lookup_processor_type(read_cpuid_id());
+	if (!cpu_info) {
+		printk("CPU configuration botched (ID %08x), unable to continue.\n",
+		       read_cpuid_id());
+		while (1);
+	}
+
+	cpu_name = cpu_info->cpu_name;
+
+	printk("CPU: %s [%08x] revision %d\n",
+	       cpu_name, read_cpuid_id(), read_cpuid_id() & 15);
+
+	sprintf(init_utsname()->machine, "aarch64");
+	elf_hwcap = 0;
+}
+
+static void __init setup_machine_fdt(phys_addr_t dt_phys)
+{
+	struct boot_param_header *devtree;
+	unsigned long dt_root;
+
+	/* Check we have a non-NULL DT pointer */
+	if (!dt_phys) {
+		early_print("\n"
+			"Error: NULL or invalid device tree blob\n"
+			"The dtb must be 8-byte aligned and passed in the first 512MB of memory\n"
+			"\nPlease check your bootloader.\n");
+
+		while (true)
+			cpu_relax();
+
+	}
+
+	devtree = phys_to_virt(dt_phys);
+
+	/* Check device tree validity */
+	if (be32_to_cpu(devtree->magic) != OF_DT_HEADER) {
+		early_print("\n"
+			"Error: invalid device tree blob at physical address 0x%p (virtual address 0x%p)\n"
+			"Expected 0x%x, found 0x%x\n"
+			"\nPlease check your bootloader.\n",
+			dt_phys, devtree, OF_DT_HEADER,
+			be32_to_cpu(devtree->magic));
+
+		while (true)
+			cpu_relax();
+	}
+
+	initial_boot_params = devtree;
+	dt_root = of_get_flat_dt_root();
+
+	machine_name = of_get_flat_dt_prop(dt_root, "model", NULL);
+	if (!machine_name)
+		machine_name = of_get_flat_dt_prop(dt_root, "compatible", NULL);
+	if (!machine_name)
+		machine_name = "<unknown>";
+	pr_info("Machine: %s\n", machine_name);
+
+	/* Retrieve various information from the /chosen node */
+	of_scan_flat_dt(early_init_dt_scan_chosen, boot_command_line);
+	/* Initialize {size,address}-cells info */
+	of_scan_flat_dt(early_init_dt_scan_root, NULL);
+	/* Setup memory, calling early_init_dt_add_memory_arch */
+	of_scan_flat_dt(early_init_dt_scan_memory, NULL);
+}
+
+void __init early_init_dt_add_memory_arch(u64 base, u64 size)
+{
+	size &= PAGE_MASK;
+	memblock_add(base, size);
+}
+
+void * __init early_init_dt_alloc_memory_arch(u64 size, u64 align)
+{
+	return __va(memblock_alloc(size, align));
+}
+
+/*
+ * Limit the memory size that was specified via FDT.
+ */
+static int __init early_mem(char *p)
+{
+	phys_addr_t limit;
+
+	if (!p)
+		return 1;
+
+	limit = memparse(p, &p) & PAGE_MASK;
+	pr_notice("Memory limited to %lldMB\n", limit >> 20);
+
+	memblock_enforce_memory_limit(limit);
+
+	return 0;
+}
+early_param("mem", early_mem);
+
+static void __init request_standard_resources(void)
+{
+	struct memblock_region *region;
+	struct resource *res;
+
+	kernel_code.start   = virt_to_phys(_text);
+	kernel_code.end     = virt_to_phys(_etext - 1);
+	kernel_data.start   = virt_to_phys(_sdata);
+	kernel_data.end     = virt_to_phys(_end - 1);
+
+	for_each_memblock(memory, region) {
+		res = alloc_bootmem_low(sizeof(*res));
+		res->name  = "System RAM";
+		res->start = __pfn_to_phys(memblock_region_memory_base_pfn(region));
+		res->end = __pfn_to_phys(memblock_region_memory_end_pfn(region)) - 1;
+		res->flags = IORESOURCE_MEM | IORESOURCE_BUSY;
+
+		request_resource(&iomem_resource, res);
+
+		if (kernel_code.start >= res->start &&
+		    kernel_code.end <= res->end)
+			request_resource(res, &kernel_code);
+		if (kernel_data.start >= res->start &&
+		    kernel_data.end <= res->end)
+			request_resource(res, &kernel_data);
+	}
+}
+
+void __init setup_arch(char **cmdline_p)
+{
+	setup_processor();
+
+	setup_machine_fdt(__fdt_pointer);
+
+	init_mm.start_code = (unsigned long) _text;
+	init_mm.end_code   = (unsigned long) _etext;
+	init_mm.end_data   = (unsigned long) _edata;
+	init_mm.brk	   = (unsigned long) _end;
+
+	*cmdline_p = boot_command_line;
+
+	parse_early_param();
+
+	arm64_memblock_init();
+
+	paging_init();
+	request_standard_resources();
+
+	unflatten_device_tree();
+
+#ifdef CONFIG_SMP
+	smp_init_cpus();
+#endif
+
+#ifdef CONFIG_VT
+#if defined(CONFIG_VGA_CONSOLE)
+	conswitchp = &vga_con;
+#elif defined(CONFIG_DUMMY_CONSOLE)
+	conswitchp = &dummy_con;
+#endif
+#endif
+}
+
+static DEFINE_PER_CPU(struct cpu, cpu_data);
+
+static int __init topology_init(void)
+{
+	int i;
+
+	for_each_possible_cpu(i) {
+		struct cpu *cpu = &per_cpu(cpu_data, i);
+		cpu->hotpluggable = 1;
+		register_cpu(cpu, i);
+	}
+
+	return 0;
+}
+subsys_initcall(topology_init);
+
+static const char *hwcap_str[] = {
+	"fp",
+	"asimd",
+	NULL
+};
+
+static int c_show(struct seq_file *m, void *v)
+{
+	int i;
+
+	seq_printf(m, "Processor\t: %s rev %d (%s)\n",
+		   cpu_name, read_cpuid_id() & 15, ELF_PLATFORM);
+
+	for_each_online_cpu(i) {
+		/*
+		 * glibc reads /proc/cpuinfo to determine the number of
+		 * online processors, looking for lines beginning with
+		 * "processor".  Give glibc what it expects.
+		 */
+#ifdef CONFIG_SMP
+		seq_printf(m, "processor\t: %d\n", i);
+#endif
+		seq_printf(m, "BogoMIPS\t: %lu.%02lu\n\n",
+			   loops_per_jiffy / (500000UL/HZ),
+			   loops_per_jiffy / (5000UL/HZ) % 100);
+	}
+
+	/* dump out the processor features */
+	seq_puts(m, "Features\t: ");
+
+	for (i = 0; hwcap_str[i]; i++)
+		if (elf_hwcap & (1 << i))
+			seq_printf(m, "%s ", hwcap_str[i]);
+
+	seq_printf(m, "\nCPU implementer\t: 0x%02x\n", read_cpuid_id() >> 24);
+	seq_printf(m, "CPU architecture: AArch64\n");
+	seq_printf(m, "CPU variant\t: 0x%x\n", (read_cpuid_id() >> 20) & 15);
+	seq_printf(m, "CPU part\t: 0x%03x\n", (read_cpuid_id() >> 4) & 0xfff);
+	seq_printf(m, "CPU revision\t: %d\n", read_cpuid_id() & 15);
+
+	seq_puts(m, "\n");
+
+	seq_printf(m, "Hardware\t: %s\n", machine_name);
+
+	return 0;
+}
+
+static void *c_start(struct seq_file *m, loff_t *pos)
+{
+	return *pos < 1 ? (void *)1 : NULL;
+}
+
+static void *c_next(struct seq_file *m, void *v, loff_t *pos)
+{
+	++*pos;
+	return NULL;
+}
+
+static void c_stop(struct seq_file *m, void *v)
+{
+}
+
+const struct seq_operations cpuinfo_op = {
+	.start	= c_start,
+	.next	= c_next,
+	.stop	= c_stop,
+	.show	= c_show
+};
