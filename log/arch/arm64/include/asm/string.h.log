commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 03a6c256b7ec..b31e8e87a0db 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -1,17 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright (C) 2013 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __ASM_STRING_H
 #define __ASM_STRING_H

commit 19a2ca0fb560fd7be7b5293c6b652c6d6078dcde
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Fri Oct 26 15:02:30 2018 -0700

    arm64: lib: use C string functions with KASAN enabled
    
    ARM64 has asm implementation of memchr(), memcmp(), str[r]chr(),
    str[n]cmp(), str[n]len().  KASAN don't see memory accesses in asm code,
    thus it can potentially miss many bugs.
    
    Ifdef out __HAVE_ARCH_* defines of these functions when KASAN is enabled,
    so the generic implementations from lib/string.c will be used.
    
    We can't just remove the asm functions because efistub uses them.  And we
    can't have two non-weak functions either, so declare the asm functions as
    weak.
    
    Link: http://lkml.kernel.org/r/20180920135631.23833-2-aryabinin@virtuozzo.com
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reported-by: Kyeongdon Kim <kyeongdon.kim@lge.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index dd95d33a5bd5..03a6c256b7ec 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -16,6 +16,7 @@
 #ifndef __ASM_STRING_H
 #define __ASM_STRING_H
 
+#ifndef CONFIG_KASAN
 #define __HAVE_ARCH_STRRCHR
 extern char *strrchr(const char *, int c);
 
@@ -34,6 +35,13 @@ extern __kernel_size_t strlen(const char *);
 #define __HAVE_ARCH_STRNLEN
 extern __kernel_size_t strnlen(const char *, __kernel_size_t);
 
+#define __HAVE_ARCH_MEMCMP
+extern int memcmp(const void *, const void *, size_t);
+
+#define __HAVE_ARCH_MEMCHR
+extern void *memchr(const void *, int, __kernel_size_t);
+#endif
+
 #define __HAVE_ARCH_MEMCPY
 extern void *memcpy(void *, const void *, __kernel_size_t);
 extern void *__memcpy(void *, const void *, __kernel_size_t);
@@ -42,16 +50,10 @@ extern void *__memcpy(void *, const void *, __kernel_size_t);
 extern void *memmove(void *, const void *, __kernel_size_t);
 extern void *__memmove(void *, const void *, __kernel_size_t);
 
-#define __HAVE_ARCH_MEMCHR
-extern void *memchr(const void *, int, __kernel_size_t);
-
 #define __HAVE_ARCH_MEMSET
 extern void *memset(void *, int, __kernel_size_t);
 extern void *__memset(void *, int, __kernel_size_t);
 
-#define __HAVE_ARCH_MEMCMP
-extern int memcmp(const void *, const void *, size_t);
-
 #ifdef CONFIG_ARCH_HAS_UACCESS_FLUSHCACHE
 #define __HAVE_ARCH_MEMCPY_FLUSHCACHE
 void memcpy_flushcache(void *dst, const void *src, size_t cnt);

commit 5d7bdeb1eeb250222304cb7b8126892cc47980a8
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Tue Jul 25 11:55:43 2017 +0100

    arm64: uaccess: Implement *_flushcache variants
    
    Implement the set of copy functions with guarantees of a clean cache
    upon completion necessary to support the pmem driver.
    
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index d0aa42907569..dd95d33a5bd5 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -52,6 +52,10 @@ extern void *__memset(void *, int, __kernel_size_t);
 #define __HAVE_ARCH_MEMCMP
 extern int memcmp(const void *, const void *, size_t);
 
+#ifdef CONFIG_ARCH_HAS_UACCESS_FLUSHCACHE
+#define __HAVE_ARCH_MEMCPY_FLUSHCACHE
+void memcpy_flushcache(void *dst, const void *src, size_t cnt);
+#endif
 
 #if defined(CONFIG_KASAN) && !defined(__SANITIZE_ADDRESS__)
 

commit 6974f0c4555e285ab217cee58b6e874f776ff409
Author: Daniel Micay <danielmicay@gmail.com>
Date:   Wed Jul 12 14:36:10 2017 -0700

    include/linux/string.h: add the option of fortified string.h functions
    
    This adds support for compiling with a rough equivalent to the glibc
    _FORTIFY_SOURCE=1 feature, providing compile-time and runtime buffer
    overflow checks for string.h functions when the compiler determines the
    size of the source or destination buffer at compile-time.  Unlike glibc,
    it covers buffer reads in addition to writes.
    
    GNU C __builtin_*_chk intrinsics are avoided because they would force a
    much more complex implementation.  They aren't designed to detect read
    overflows and offer no real benefit when using an implementation based
    on inline checks.  Inline checks don't add up to much code size and
    allow full use of the regular string intrinsics while avoiding the need
    for a bunch of _chk functions and per-arch assembly to avoid wrapper
    overhead.
    
    This detects various overflows at compile-time in various drivers and
    some non-x86 core kernel code.  There will likely be issues caught in
    regular use at runtime too.
    
    Future improvements left out of initial implementation for simplicity,
    as it's all quite optional and can be done incrementally:
    
    * Some of the fortified string functions (strncpy, strcat), don't yet
      place a limit on reads from the source based on __builtin_object_size of
      the source buffer.
    
    * Extending coverage to more string functions like strlcat.
    
    * It should be possible to optionally use __builtin_object_size(x, 1) for
      some functions (C strings) to detect intra-object overflows (like
      glibc's _FORTIFY_SOURCE=2), but for now this takes the conservative
      approach to avoid likely compatibility issues.
    
    * The compile-time checks should be made available via a separate config
      option which can be enabled by default (or always enabled) once enough
      time has passed to get the issues it catches fixed.
    
    Kees said:
     "This is great to have. While it was out-of-tree code, it would have
      blocked at least CVE-2016-3858 from being exploitable (improper size
      argument to strlcpy()). I've sent a number of fixes for
      out-of-bounds-reads that this detected upstream already"
    
    [arnd@arndb.de: x86: fix fortified memcpy]
      Link: http://lkml.kernel.org/r/20170627150047.660360-1-arnd@arndb.de
    [keescook@chromium.org: avoid panic() in favor of BUG()]
      Link: http://lkml.kernel.org/r/20170626235122.GA25261@beast
    [keescook@chromium.org: move from -mm, add ARCH_HAS_FORTIFY_SOURCE, tweak Kconfig help]
    Link: http://lkml.kernel.org/r/20170526095404.20439-1-danielmicay@gmail.com
    Link: http://lkml.kernel.org/r/1497903987-21002-8-git-send-email-keescook@chromium.org
    Signed-off-by: Daniel Micay <danielmicay@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Daniel Axtens <dja@axtens.net>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 2eb714c4639f..d0aa42907569 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -63,6 +63,11 @@ extern int memcmp(const void *, const void *, size_t);
 #define memcpy(dst, src, len) __memcpy(dst, src, len)
 #define memmove(dst, src, len) __memmove(dst, src, len)
 #define memset(s, c, n) __memset(s, c, n)
+
+#ifndef __NO_FORTIFY
+#define __NO_FORTIFY /* FORTIFY_SOURCE uses __builtin_memcpy, etc. */
+#endif
+
 #endif
 
 #endif

commit 39d114ddc68223022c12ae3a1573912bc4b585e5
Author: Andrey Ryabinin <ryabinin.a.a@gmail.com>
Date:   Mon Oct 12 18:52:58 2015 +0300

    arm64: add KASAN support
    
    This patch adds arch specific code for kernel address sanitizer
    (see Documentation/kasan.txt).
    
    1/8 of kernel addresses reserved for shadow memory. There was no
    big enough hole for this, so virtual addresses for shadow were
    stolen from vmalloc area.
    
    At early boot stage the whole shadow region populated with just
    one physical page (kasan_zero_page). Later, this page reused
    as readonly zero shadow for some memory that KASan currently
    don't track (vmalloc).
    After mapping the physical memory, pages for shadow memory are
    allocated and mapped.
    
    Functions like memset/memmove/memcpy do a lot of memory accesses.
    If bad pointer passed to one of these function it is important
    to catch this. Compiler's instrumentation cannot do this since
    these functions are written in assembly.
    KASan replaces memory functions with manually instrumented variants.
    Original functions declared as weak symbols so strong definitions
    in mm/kasan/kasan.c could replace them. Original functions have aliases
    with '__' prefix in name, so we could call non-instrumented variant
    if needed.
    Some files built without kasan instrumentation (e.g. mm/slub.c).
    Original mem* function replaced (via #define) with prefixed variants
    to disable memory access checks for such files.
    
    Signed-off-by: Andrey Ryabinin <ryabinin.a.a@gmail.com>
    Tested-by: Linus Walleij <linus.walleij@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 64d2d4884a9d..2eb714c4639f 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -36,17 +36,33 @@ extern __kernel_size_t strnlen(const char *, __kernel_size_t);
 
 #define __HAVE_ARCH_MEMCPY
 extern void *memcpy(void *, const void *, __kernel_size_t);
+extern void *__memcpy(void *, const void *, __kernel_size_t);
 
 #define __HAVE_ARCH_MEMMOVE
 extern void *memmove(void *, const void *, __kernel_size_t);
+extern void *__memmove(void *, const void *, __kernel_size_t);
 
 #define __HAVE_ARCH_MEMCHR
 extern void *memchr(const void *, int, __kernel_size_t);
 
 #define __HAVE_ARCH_MEMSET
 extern void *memset(void *, int, __kernel_size_t);
+extern void *__memset(void *, int, __kernel_size_t);
 
 #define __HAVE_ARCH_MEMCMP
 extern int memcmp(const void *, const void *, size_t);
 
+
+#if defined(CONFIG_KASAN) && !defined(__SANITIZE_ADDRESS__)
+
+/*
+ * For files that are not instrumented (e.g. mm/slub.c) we
+ * should use not instrumented version of mem* functions.
+ */
+
+#define memcpy(dst, src, len) __memcpy(dst, src, len)
+#define memmove(dst, src, len) __memmove(dst, src, len)
+#define memset(s, c, n) __memset(s, c, n)
+#endif
+
 #endif

commit 0a42cb0a6fa64cb17db11164a1ad3511b43acefe
Author: zhichang.yuan <zhichang.yuan@linaro.org>
Date:   Mon Apr 28 13:11:34 2014 +0800

    arm64: lib: Implement optimized string length routines
    
    This patch, based on Linaro's Cortex Strings library, adds
    an assembly optimized strlen() and strnlen() functions.
    
    Signed-off-by: Zhichang Yuan <zhichang.yuan@linaro.org>
    Signed-off-by: Deepak Saxena <dsaxena@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 6133f4970027..64d2d4884a9d 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -28,6 +28,12 @@ extern int strcmp(const char *, const char *);
 #define __HAVE_ARCH_STRNCMP
 extern int strncmp(const char *, const char *, __kernel_size_t);
 
+#define __HAVE_ARCH_STRLEN
+extern __kernel_size_t strlen(const char *);
+
+#define __HAVE_ARCH_STRNLEN
+extern __kernel_size_t strnlen(const char *, __kernel_size_t);
+
 #define __HAVE_ARCH_MEMCPY
 extern void *memcpy(void *, const void *, __kernel_size_t);
 

commit 192c4d902f19b66902d7aacc19e9b169bebfb2e5
Author: zhichang.yuan <zhichang.yuan@linaro.org>
Date:   Mon Apr 28 13:11:33 2014 +0800

    arm64: lib: Implement optimized string compare routines
    
    This patch, based on Linaro's Cortex Strings library, adds
    an assembly optimized strcmp() and strncmp() functions.
    
    Signed-off-by: Zhichang Yuan <zhichang.yuan@linaro.org>
    Signed-off-by: Deepak Saxena <dsaxena@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 3a43305cda71..6133f4970027 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -22,6 +22,12 @@ extern char *strrchr(const char *, int c);
 #define __HAVE_ARCH_STRCHR
 extern char *strchr(const char *, int c);
 
+#define __HAVE_ARCH_STRCMP
+extern int strcmp(const char *, const char *);
+
+#define __HAVE_ARCH_STRNCMP
+extern int strncmp(const char *, const char *, __kernel_size_t);
+
 #define __HAVE_ARCH_MEMCPY
 extern void *memcpy(void *, const void *, __kernel_size_t);
 

commit d875c9b3724083cd2629cd8507e424cd3716cd28
Author: zhichang.yuan <zhichang.yuan@linaro.org>
Date:   Mon Apr 28 06:11:32 2014 +0100

    arm64: lib: Implement optimized memcmp routine
    
    This patch, based on Linaro's Cortex Strings library, adds
    an assembly optimized memcmp() function.
    
    Signed-off-by: Zhichang Yuan <zhichang.yuan@linaro.org>
    Signed-off-by: Deepak Saxena <dsaxena@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 3ee8b303d9a9..3a43305cda71 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -34,4 +34,7 @@ extern void *memchr(const void *, int, __kernel_size_t);
 #define __HAVE_ARCH_MEMSET
 extern void *memset(void *, int, __kernel_size_t);
 
+#define __HAVE_ARCH_MEMCMP
+extern int memcmp(const void *, const void *, size_t);
+
 #endif

commit 2b8cac814cd5a0a305d62dcd1d589faccb705a4d
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Mar 21 16:23:43 2013 +0000

    arm64: klib: Optimised string functions
    
    This patch introduces AArch64-specific string functions (strchr,
    strrchr).
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index be8a644f306a..3ee8b303d9a9 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -16,6 +16,12 @@
 #ifndef __ASM_STRING_H
 #define __ASM_STRING_H
 
+#define __HAVE_ARCH_STRRCHR
+extern char *strrchr(const char *, int c);
+
+#define __HAVE_ARCH_STRCHR
+extern char *strchr(const char *, int c);
+
 #define __HAVE_ARCH_MEMCPY
 extern void *memcpy(void *, const void *, __kernel_size_t);
 

commit 4a8992271c843cb5bcd3321bf6a02eb251280b1d
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Mar 21 16:16:43 2013 +0000

    arm64: klib: Optimised memory functions
    
    This patch introduces AArch64-specific memory functions (memcpy,
    memmove, memchr, memset). These functions are not optimised for any CPU
    implementation but can be used as a starting point once hardware is
    available.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
new file mode 100644
index 000000000000..be8a644f306a
--- /dev/null
+++ b/arch/arm64/include/asm/string.h
@@ -0,0 +1,31 @@
+/*
+ * Copyright (C) 2013 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __ASM_STRING_H
+#define __ASM_STRING_H
+
+#define __HAVE_ARCH_MEMCPY
+extern void *memcpy(void *, const void *, __kernel_size_t);
+
+#define __HAVE_ARCH_MEMMOVE
+extern void *memmove(void *, const void *, __kernel_size_t);
+
+#define __HAVE_ARCH_MEMCHR
+extern void *memchr(const void *, int, __kernel_size_t);
+
+#define __HAVE_ARCH_MEMSET
+extern void *memset(void *, int, __kernel_size_t);
+
+#endif
