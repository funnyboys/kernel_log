commit d9d7d84d9906e1bc886c5e0fc66aaad26008264b
Author: Marc Zyngier <maz@kernel.org>
Date:   Tue Apr 21 18:32:02 2020 +0100

    KVM: arm64: Parametrize exception entry with a target EL
    
    We currently assume that an exception is delivered to EL1, always.
    Once we emulate EL2, this no longer will be the case. To prepare
    for this, add a target_mode parameter.
    
    While we're at it, merge the computing of the target PC and PSTATE in
    a single function that updates both PC and CPSR after saving their
    previous values in the corresponding ELR/SPSR. This ensures that they
    are updated in the correct order (a pretty common source of bugs...).
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Marc Zyngier <maz@kernel.org>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index bf57308fcd63..953b6a1ce549 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -35,6 +35,7 @@
 #define GIC_PRIO_PSR_I_SET		(1 << 4)
 
 /* Additional SPSR bits not exposed in the UABI */
+#define PSR_MODE_THREAD_BIT	(1 << 0)
 #define PSR_IL_BIT		(1 << 20)
 
 /* AArch32-specific ptrace requests */

commit 3c2483f15499b877ccb53250d88addb8c91da147
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jan 8 13:43:23 2020 +0000

    KVM: arm/arm64: Correct CPSR on exception entry
    
    When KVM injects an exception into a guest, it generates the CPSR value
    from scratch, configuring CPSR.{M,A,I,T,E}, and setting all other
    bits to zero.
    
    This isn't correct, as the architecture specifies that some CPSR bits
    are (conditionally) cleared or set upon an exception, and others are
    unchanged from the original context.
    
    This patch adds logic to match the architectural behaviour. To make this
    simple to follow/audit/extend, documentation references are provided,
    and bits are configured in order of their layout in SPSR_EL2. This
    layout can be seen in the diagram on ARM DDI 0487E.a page C5-426.
    
    Note that this code is used by both arm and arm64, and is intended to
    fuction with the SPSR_EL2 and SPSR_HYP layouts.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Marc Zyngier <maz@kernel.org>
    Reviewed-by: Alexandru Elisei <alexandru.elisei@arm.com>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20200108134324.46500-3-mark.rutland@arm.com

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index fbebb411ae20..bf57308fcd63 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -62,6 +62,7 @@
 #define PSR_AA32_I_BIT		0x00000080
 #define PSR_AA32_A_BIT		0x00000100
 #define PSR_AA32_E_BIT		0x00000200
+#define PSR_AA32_PAN_BIT	0x00400000
 #define PSR_AA32_SSBS_BIT	0x00800000
 #define PSR_AA32_DIT_BIT	0x01000000
 #define PSR_AA32_Q_BIT		0x08000000

commit 42d038c4fb00f1ec1a4c4616784da4561385b628
Author: Leo Yan <leo.yan@linaro.org>
Date:   Tue Aug 6 18:00:14 2019 +0800

    arm64: Add support for function error injection
    
    Inspired by the commit 7cd01b08d35f ("powerpc: Add support for function
    error injection"), this patch supports function error injection for
    Arm64.
    
    This patch mainly support two functions: one is regs_set_return_value()
    which is used to overwrite the return value; the another function is
    override_function_with_return() which is to override the probed
    function returning and jump to its caller.
    
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Leo Yan <leo.yan@linaro.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 1dcf63a9ac1f..fbebb411ae20 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -301,6 +301,11 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 	return regs->regs[0];
 }
 
+static inline void regs_set_return_value(struct pt_regs *regs, unsigned long rc)
+{
+	regs->regs[0] = rc;
+}
+
 /**
  * regs_get_kernel_argument() - get Nth function argument in kernel
  * @regs:	pt_regs of that context

commit 677379bc9139ac24b310a281fcb21a2f04288353
Author: Julien Thierry <julien.thierry.kdev@gmail.com>
Date:   Mon Jul 29 15:57:46 2019 +0100

    arm64: Lower priority mask for GIC_PRIO_IRQON
    
    On a system with two security states, if SCR_EL3.FIQ is cleared,
    non-secure IRQ priorities get shifted to fit the secure view but
    priority masks aren't.
    
    On such system, it turns out that GIC_PRIO_IRQON masks the priority of
    normal interrupts, which obviously ends up in a hang.
    
    Increase GIC_PRIO_IRQON value (i.e. lower priority) to make sure
    interrupts are not blocked by it.
    
    Cc: Oleg Nesterov <oleg@redhat.com>
    Fixes: bd82d4bd21880b7c ("arm64: Fix incorrect irqflag restore for priority masking")
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry.kdev@gmail.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    [will: fixed Fixes: tag]
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b1dd039023ef..1dcf63a9ac1f 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -30,7 +30,7 @@
  * in the  the priority mask, it indicates that PSR.I should be set and
  * interrupt disabling temporarily does not rely on IRQ priorities.
  */
-#define GIC_PRIO_IRQON			0xc0
+#define GIC_PRIO_IRQON			0xe0
 #define GIC_PRIO_IRQOFF			(GIC_PRIO_IRQON & ~0x80)
 #define GIC_PRIO_PSR_I_SET		(1 << 4)
 

commit 5f26f1143678d0fed8115afdcc0de99ee7cc9675
Merge: aabfea8dc91c 7f3a8dff1219
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 12 15:41:33 2019 -0700

    Merge tag 'asm-generic-5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic
    
    Pull asm-generic updates from Arnd Bergmann:
     "The asm-generic changes for 5.3 consist of a cleanup series to remove
      ptrace.h from Christoph Hellwig, who explains:
    
        'asm-generic/ptrace.h is a little weird in that it doesn't actually
         implement any functionality, but it provided multiple layers of
         macros that just implement trivial inline functions. We implement
         those directly in the few architectures and be off with a much
         simpler design.'
    
      at https://lore.kernel.org/lkml/20190624054728.30966-1-hch@lst.de/"
    
    * tag 'asm-generic-5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic:
      asm-generic: remove ptrace.h
      x86: don't use asm-generic/ptrace.h
      sh: don't use asm-generic/ptrace.h
      powerpc: don't use asm-generic/ptrace.h
      arm64: don't use asm-generic/ptrace.h

commit dfd437a257924484b144ee750e60affc95562c6d
Merge: 0ecfebd2b524 0c61efd322b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 09:54:55 2019 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - arm64 support for syscall emulation via PTRACE_SYSEMU{,_SINGLESTEP}
    
     - Wire up VM_FLUSH_RESET_PERMS for arm64, allowing the core code to
       manage the permissions of executable vmalloc regions more strictly
    
     - Slight performance improvement by keeping softirqs enabled while
       touching the FPSIMD/SVE state (kernel_neon_begin/end)
    
     - Expose a couple of ARMv8.5 features to user (HWCAP): CondM (new
       XAFLAG and AXFLAG instructions for floating point comparison flags
       manipulation) and FRINT (rounding floating point numbers to integers)
    
     - Re-instate ARM64_PSEUDO_NMI support which was previously marked as
       BROKEN due to some bugs (now fixed)
    
     - Improve parking of stopped CPUs and implement an arm64-specific
       panic_smp_self_stop() to avoid warning on not being able to stop
       secondary CPUs during panic
    
     - perf: enable the ARM Statistical Profiling Extensions (SPE) on ACPI
       platforms
    
     - perf: DDR performance monitor support for iMX8QXP
    
     - cache_line_size() can now be set from DT or ACPI/PPTT if provided to
       cope with a system cache info not exposed via the CPUID registers
    
     - Avoid warning on hardware cache line size greater than
       ARCH_DMA_MINALIGN if the system is fully coherent
    
     - arm64 do_page_fault() and hugetlb cleanups
    
     - Refactor set_pte_at() to avoid redundant READ_ONCE(*ptep)
    
     - Ignore ACPI 5.1 FADTs reported as 5.0 (infer from the
       'arm_boot_flags' introduced in 5.1)
    
     - CONFIG_RANDOMIZE_BASE now enabled in defconfig
    
     - Allow the selection of ARM64_MODULE_PLTS, currently only done via
       RANDOMIZE_BASE (and an erratum workaround), allowing modules to spill
       over into the vmalloc area
    
     - Make ZONE_DMA32 configurable
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (54 commits)
      perf: arm_spe: Enable ACPI/Platform automatic module loading
      arm_pmu: acpi: spe: Add initial MADT/SPE probing
      ACPI/PPTT: Add function to return ACPI 6.3 Identical tokens
      ACPI/PPTT: Modify node flag detection to find last IDENTICAL
      x86/entry: Simplify _TIF_SYSCALL_EMU handling
      arm64: rename dump_instr as dump_kernel_instr
      arm64/mm: Drop [PTE|PMD]_TYPE_FAULT
      arm64: Implement panic_smp_self_stop()
      arm64: Improve parking of stopped CPUs
      arm64: Expose FRINT capabilities to userspace
      arm64: Expose ARMv8.5 CondM capability to userspace
      arm64: defconfig: enable CONFIG_RANDOMIZE_BASE
      arm64: ARM64_MODULES_PLTS must depend on MODULES
      arm64: bpf: do not allocate executable memory
      arm64/kprobes: set VM_FLUSH_RESET_PERMS on kprobe instruction pages
      arm64/mm: wire up CONFIG_ARCH_HAS_SET_DIRECT_MAP
      arm64: module: create module allocations without exec permissions
      arm64: Allow user selection of ARM64_MODULE_PLTS
      acpi/arm64: ignore 5.1 FADTs that are reported as 5.0
      arm64: Allow selecting Pseudo-NMI again
      ...

commit 56a5d00328e1d859b743e14b6e2ca76d47ba6e5d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 24 07:47:24 2019 +0200

    arm64: don't use asm-generic/ptrace.h
    
    Doing the indirection through macros for the regs accessors just
    makes them harder to read, so implement the helpers directly.
    
    Note that only the helpers actually used are implemented now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b2de32939ada..584261e00619 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -228,11 +228,12 @@ static inline void forget_syscall(struct pt_regs *regs)
 #define fast_interrupts_enabled(regs) \
 	(!((regs)->pstate & PSR_F_BIT))
 
-#define GET_USP(regs) \
-	(!compat_user_mode(regs) ? (regs)->sp : (regs)->compat_sp)
-
-#define SET_USP(ptregs, value) \
-	(!compat_user_mode(regs) ? ((regs)->sp = value) : ((regs)->compat_sp = value))
+static inline unsigned long user_stack_pointer(struct pt_regs *regs)
+{
+	if (compat_user_mode(regs))
+		return regs->compat_sp;
+	return regs->sp;
+}
 
 extern int regs_query_register_offset(const char *name);
 extern unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
@@ -331,13 +332,20 @@ static inline unsigned long regs_get_kernel_argument(struct pt_regs *regs,
 struct task_struct;
 int valid_user_regs(struct user_pt_regs *regs, struct task_struct *task);
 
-#define GET_IP(regs)		((unsigned long)(regs)->pc)
-#define SET_IP(regs, value)	((regs)->pc = ((u64) (value)))
-
-#define GET_FP(ptregs)		((unsigned long)(ptregs)->regs[29])
-#define SET_FP(ptregs, value)	((ptregs)->regs[29] = ((u64) (value)))
+static inline unsigned long instruction_pointer(struct pt_regs *regs)
+{
+	return regs->pc;
+}
+static inline void instruction_pointer_set(struct pt_regs *regs,
+		unsigned long val)
+{
+	regs->pc = val;
+}
 
-#include <asm-generic/ptrace.h>
+static inline unsigned long frame_pointer(struct pt_regs *regs)
+{
+	return regs->regs[29];
+}
 
 #define procedure_link_pointer(regs)	((regs)->regs[30])
 
@@ -347,7 +355,6 @@ static inline void procedure_link_pointer_set(struct pt_regs *regs,
 	procedure_link_pointer(regs) = val;
 }
 
-#undef profile_pc
 extern unsigned long profile_pc(struct pt_regs *regs);
 
 #endif /* __ASSEMBLY__ */

commit bd82d4bd21880b7c4d5f5756be435095d6ae07b5
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Tue Jun 11 10:38:10 2019 +0100

    arm64: Fix incorrect irqflag restore for priority masking
    
    When using IRQ priority masking to disable interrupts, in order to deal
    with the PSR.I state, local_irq_save() would convert the I bit into a
    PMR value (GIC_PRIO_IRQOFF). This resulted in local_irq_restore()
    potentially modifying the value of PMR in undesired location due to the
    state of PSR.I upon flag saving [1].
    
    In an attempt to solve this issue in a less hackish manner, introduce
    a bit (GIC_PRIO_IGNORE_PMR) for the PMR values that can represent
    whether PSR.I is being used to disable interrupts, in which case it
    takes precedence of the status of interrupt masking via PMR.
    
    GIC_PRIO_PSR_I_SET is chosen such that (<pmr_value> |
    GIC_PRIO_PSR_I_SET) does not mask more interrupts than <pmr_value> as
    some sections (e.g. arch_cpu_idle(), interrupt acknowledge path)
    requires PMR not to mask interrupts that could be signaled to the
    CPU when using only PSR.I.
    
    [1] https://www.spinics.net/lists/arm-kernel/msg716956.html
    
    Fixes: 4a503217ce37 ("arm64: irqflags: Use ICC_PMR_EL1 for interrupt masking")
    Cc: <stable@vger.kernel.org> # 5.1.x-
    Reported-by: Zenghui Yu <yuzenghui@huawei.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Wei Li <liwei391@huawei.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Christoffer Dall <christoffer.dall@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Suzuki K Pouloze <suzuki.poulose@arm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b2de32939ada..da2242248466 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -35,9 +35,15 @@
  * means masking more IRQs (or at least that the same IRQs remain masked).
  *
  * To mask interrupts, we clear the most significant bit of PMR.
+ *
+ * Some code sections either automatically switch back to PSR.I or explicitly
+ * require to not use priority masking. If bit GIC_PRIO_PSR_I_SET is included
+ * in the  the priority mask, it indicates that PSR.I should be set and
+ * interrupt disabling temporarily does not rely on IRQ priorities.
  */
-#define GIC_PRIO_IRQON		0xf0
-#define GIC_PRIO_IRQOFF		(GIC_PRIO_IRQON & ~0x80)
+#define GIC_PRIO_IRQON			0xc0
+#define GIC_PRIO_IRQOFF			(GIC_PRIO_IRQON & ~0x80)
+#define GIC_PRIO_PSR_I_SET		(1 << 4)
 
 /* Additional SPSR bits not exposed in the UABI */
 #define PSR_IL_BIT		(1 << 20)

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b2de32939ada..dad858b6adc6 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -1,20 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Based on arch/arm/include/asm/ptrace.h
  *
  * Copyright (C) 1996-2003 Russell King
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __ASM_PTRACE_H
 #define __ASM_PTRACE_H

commit a823c35ff2eda73046cc1847326071de350fceda
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Fri Apr 12 23:22:01 2019 +0900

    arm64: ptrace: Add function argument access API
    
    Add regs_get_argument() which returns N th argument of the function
    call. On arm64, it supports up to 8th argument.
    Note that this chooses most probably assignment, in some case
    it can be incorrect (e.g. passing data structure or floating
    point etc.)
    
    This enables ftrace kprobe events to access kernel function
    arguments via $argN syntax.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    [will: tidied up the comment a bit]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index ec60174c8c18..b2de32939ada 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -305,6 +305,28 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 	return regs->regs[0];
 }
 
+/**
+ * regs_get_kernel_argument() - get Nth function argument in kernel
+ * @regs:	pt_regs of that context
+ * @n:		function argument number (start from 0)
+ *
+ * regs_get_argument() returns @n th argument of the function call.
+ *
+ * Note that this chooses the most likely register mapping. In very rare
+ * cases this may not return correct data, for example, if one of the
+ * function parameters is 16 bytes or bigger. In such cases, we cannot
+ * get access the parameter correctly and the register assignment of
+ * subsequent parameters will be shifted.
+ */
+static inline unsigned long regs_get_kernel_argument(struct pt_regs *regs,
+						     unsigned int n)
+{
+#define NR_REG_ARGUMENTS 8
+	if (n < NR_REG_ARGUMENTS)
+		return pt_regs_read_reg(regs, n);
+	return 0;
+}
+
 /* We must avoid circular header include via sched.h */
 struct task_struct;
 int valid_user_regs(struct user_pt_regs *regs, struct task_struct *task);

commit 133d05186325ce04494ea6488a6b86e50a446c12
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:58:46 2019 +0000

    arm64: Make PMR part of task context
    
    In order to replace PSR.I interrupt disabling/enabling with ICC_PMR_EL1
    interrupt masking, ICC_PMR_EL1 needs to be saved/restored when
    taking/returning from an exception. This mimics the way hardware saves
    and restores PSR.I bit in spsr_el1 for exceptions and ERET.
    
    Add PMR to the registers to save in the pt_regs struct upon kernel entry,
    and restore it before ERET. Also, initialize it to a sane value when
    creating new tasks.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 8b131bc8984d..ec60174c8c18 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -19,6 +19,8 @@
 #ifndef __ASM_PTRACE_H
 #define __ASM_PTRACE_H
 
+#include <asm/cpufeature.h>
+
 #include <uapi/asm/ptrace.h>
 
 /* Current Exception Level values, as contained in CurrentEL */
@@ -179,7 +181,8 @@ struct pt_regs {
 #endif
 
 	u64 orig_addr_limit;
-	u64 unused;	// maintain 16 byte alignment
+	/* Only valid when ARM64_HAS_IRQ_PRIO_MASKING is enabled. */
+	u64 pmr_save;
 	u64 stackframe[2];
 };
 
@@ -214,8 +217,13 @@ static inline void forget_syscall(struct pt_regs *regs)
 #define processor_mode(regs) \
 	((regs)->pstate & PSR_MODE_MASK)
 
-#define interrupts_enabled(regs) \
-	(!((regs)->pstate & PSR_I_BIT))
+#define irqs_priority_unmasked(regs)					\
+	(system_uses_irq_prio_masking() ?				\
+		(regs)->pmr_save == GIC_PRIO_IRQON :			\
+		true)
+
+#define interrupts_enabled(regs)			\
+	(!((regs)->pstate & PSR_I_BIT) && irqs_priority_unmasked(regs))
 
 #define fast_interrupts_enabled(regs) \
 	(!((regs)->pstate & PSR_F_BIT))

commit cdbc81ddef43c8fdcbd3a26e1a7530c70b629cfc
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:58:45 2019 +0000

    arm64: ptrace: Provide definitions for PMR values
    
    Introduce fixed values for PMR that are going to be used to mask and
    unmask interrupts by priority.
    
    The current priority given to GIC interrupts is 0xa0, so clearing PMR's
    most significant bit is enough to mask interrupts.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Suggested-by: Daniel Thompson <daniel.thompson@linaro.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index fce22c4b2f73..8b131bc8984d 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -25,6 +25,18 @@
 #define CurrentEL_EL1		(1 << 2)
 #define CurrentEL_EL2		(2 << 2)
 
+/*
+ * PMR values used to mask/unmask interrupts.
+ *
+ * GIC priority masking works as follows: if an IRQ's priority is a higher value
+ * than the value held in PMR, that IRQ is masked. Lowering the value of PMR
+ * means masking more IRQs (or at least that the same IRQs remain masked).
+ *
+ * To mask interrupts, we clear the most significant bit of PMR.
+ */
+#define GIC_PRIO_IRQON		0xf0
+#define GIC_PRIO_IRQOFF		(GIC_PRIO_IRQON & ~0x80)
+
 /* Additional SPSR bits not exposed in the UABI */
 #define PSR_IL_BIT		(1 << 20)
 

commit 0d1e8b8d2bcd3150d51754d8d0fdbf44dc88b0d3
Merge: 83c4087ce468 22a7cdcae6a4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 17:57:35 2018 -0700

    Merge tag 'kvm-4.20-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Radim Krčmář:
     "ARM:
       - Improved guest IPA space support (32 to 52 bits)
    
       - RAS event delivery for 32bit
    
       - PMU fixes
    
       - Guest entry hardening
    
       - Various cleanups
    
       - Port of dirty_log_test selftest
    
      PPC:
       - Nested HV KVM support for radix guests on POWER9. The performance
         is much better than with PR KVM. Migration and arbitrary level of
         nesting is supported.
    
       - Disable nested HV-KVM on early POWER9 chips that need a particular
         hardware bug workaround
    
       - One VM per core mode to prevent potential data leaks
    
       - PCI pass-through optimization
    
       - merge ppc-kvm topic branch and kvm-ppc-fixes to get a better base
    
      s390:
       - Initial version of AP crypto virtualization via vfio-mdev
    
       - Improvement for vfio-ap
    
       - Set the host program identifier
    
       - Optimize page table locking
    
      x86:
       - Enable nested virtualization by default
    
       - Implement Hyper-V IPI hypercalls
    
       - Improve #PF and #DB handling
    
       - Allow guests to use Enlightened VMCS
    
       - Add migration selftests for VMCS and Enlightened VMCS
    
       - Allow coalesced PIO accesses
    
       - Add an option to perform nested VMCS host state consistency check
         through hardware
    
       - Automatic tuning of lapic_timer_advance_ns
    
       - Many fixes, minor improvements, and cleanups"
    
    * tag 'kvm-4.20-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (204 commits)
      KVM/nVMX: Do not validate that posted_intr_desc_addr is page aligned
      Revert "kvm: x86: optimize dr6 restore"
      KVM: PPC: Optimize clearing TCEs for sparse tables
      x86/kvm/nVMX: tweak shadow fields
      selftests/kvm: add missing executables to .gitignore
      KVM: arm64: Safety check PSTATE when entering guest and handle IL
      KVM: PPC: Book3S HV: Don't use streamlined entry path on early POWER9 chips
      arm/arm64: KVM: Enable 32 bits kvm vcpu events support
      arm/arm64: KVM: Rename function kvm_arch_dev_ioctl_check_extension()
      KVM: arm64: Fix caching of host MDCR_EL2 value
      KVM: VMX: enable nested virtualization by default
      KVM/x86: Use 32bit xor to clear registers in svm.c
      kvm: x86: Introduce KVM_CAP_EXCEPTION_PAYLOAD
      kvm: vmx: Defer setting of DR6 until #DB delivery
      kvm: x86: Defer setting of CR2 until #PF delivery
      kvm: x86: Add payload operands to kvm_multiple_exception
      kvm: x86: Add exception payload fields to kvm_vcpu_events
      kvm: x86: Add has_payload and payload to kvm_queued_exception
      KVM: Documentation: Fix omission in struct kvm_vcpu_events
      KVM: selftests: add Enlightened VMCS test
      ...

commit e4e11cc0f81ee7be17d6f6fb96128a6d51c0e838
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Wed Oct 17 20:21:16 2018 +0200

    KVM: arm64: Safety check PSTATE when entering guest and handle IL
    
    This commit adds a paranoid check when entering the guest to make sure
    we don't attempt running guest code in an equally or more privilged mode
    than the hypervisor.  We also catch other accidental programming of the
    SPSR_EL2 which results in an illegal exception return and report this
    safely back to the user.
    
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 177b851ca6d9..ff35ac1258eb 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -25,6 +25,9 @@
 #define CurrentEL_EL1		(1 << 2)
 #define CurrentEL_EL2		(2 << 2)
 
+/* Additional SPSR bits not exposed in the UABI */
+#define PSR_IL_BIT		(1 << 20)
+
 /* AArch32-specific ptrace requests */
 #define COMPAT_PTRACE_GETREGS		12
 #define COMPAT_PTRACE_SETREGS		13

commit 8f04e8e6e29c93421a95b61cad62e3918425eac7
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Aug 7 13:47:06 2018 +0100

    arm64: ssbd: Add support for PSTATE.SSBS rather than trapping to EL3
    
    On CPUs with support for PSTATE.SSBS, the kernel can toggle the SSBD
    state without needing to call into firmware.
    
    This patch hooks into the existing SSBD infrastructure so that SSBS is
    used on CPUs that support it, but it's all made horribly complicated by
    the very real possibility of big/little systems that don't uniformly
    provide the new capability.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 177b851ca6d9..6bc43889d11e 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -50,6 +50,7 @@
 #define PSR_AA32_I_BIT		0x00000080
 #define PSR_AA32_A_BIT		0x00000100
 #define PSR_AA32_E_BIT		0x00000200
+#define PSR_AA32_SSBS_BIT	0x00800000
 #define PSR_AA32_DIT_BIT	0x01000000
 #define PSR_AA32_Q_BIT		0x08000000
 #define PSR_AA32_V_BIT		0x10000000

commit 7373fed2f258e640031387616a2275a6fc0d7231
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Jul 5 15:16:54 2018 +0100

    arm64: remove unused COMPAT_PSR definitions
    
    Now that users have been migrated to PSR_AA32, kill the unused
    COMPAT_PSR definitions.
    
    The only difference we need a definition for is COMPAT_PSR_DIT_BIT,
    which differs from PSR_AA32_DIT_BIT.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index d55237eb89bb..177b851ca6d9 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -66,35 +66,7 @@
 #endif
 
 /* AArch32 CPSR bits, as seen in AArch32 */
-#define COMPAT_PSR_MODE_MASK	0x0000001f
-#define COMPAT_PSR_MODE_USR	0x00000010
-#define COMPAT_PSR_MODE_FIQ	0x00000011
-#define COMPAT_PSR_MODE_IRQ	0x00000012
-#define COMPAT_PSR_MODE_SVC	0x00000013
-#define COMPAT_PSR_MODE_ABT	0x00000017
-#define COMPAT_PSR_MODE_HYP	0x0000001a
-#define COMPAT_PSR_MODE_UND	0x0000001b
-#define COMPAT_PSR_MODE_SYS	0x0000001f
-#define COMPAT_PSR_T_BIT	0x00000020
-#define COMPAT_PSR_F_BIT	0x00000040
-#define COMPAT_PSR_I_BIT	0x00000080
-#define COMPAT_PSR_A_BIT	0x00000100
-#define COMPAT_PSR_E_BIT	0x00000200
 #define COMPAT_PSR_DIT_BIT	0x00200000
-#define COMPAT_PSR_J_BIT	0x01000000
-#define COMPAT_PSR_Q_BIT	0x08000000
-#define COMPAT_PSR_V_BIT	0x10000000
-#define COMPAT_PSR_C_BIT	0x20000000
-#define COMPAT_PSR_Z_BIT	0x40000000
-#define COMPAT_PSR_N_BIT	0x80000000
-#define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
-#define COMPAT_PSR_GE_MASK	0x000f0000
-
-#ifdef CONFIG_CPU_BIG_ENDIAN
-#define COMPAT_PSR_ENDSTATE	COMPAT_PSR_E_BIT
-#else
-#define COMPAT_PSR_ENDSTATE	0
-#endif
 
 /*
  * These are 'magic' values for PTRACE_PEEKUSR that return info about where a

commit d64567f67835736d65086e9bfc41a19b2863c32e
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Jul 5 15:16:52 2018 +0100

    arm64: use PSR_AA32 definitions
    
    Some code cares about the SPSR_ELx format for exceptions taken from
    AArch32 to inspect or manipulate the SPSR_ELx value, which is already in
    the SPSR_ELx format, and not in the AArch32 PSR format.
    
    To separate these from cases where we care about the AArch32 PSR format,
    migrate these cases to use the PSR_AA32_* definitions rather than
    COMPAT_PSR_*.
    
    There should be no functional change as a result of this patch.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 1b2a253de6a1..d55237eb89bb 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -211,7 +211,7 @@ static inline void forget_syscall(struct pt_regs *regs)
 
 #ifdef CONFIG_COMPAT
 #define compat_thumb_mode(regs) \
-	(((regs)->pstate & COMPAT_PSR_T_BIT))
+	(((regs)->pstate & PSR_AA32_T_BIT))
 #else
 #define compat_thumb_mode(regs) (0)
 #endif

commit 25086263425641c74123f9387426c23072b299ea
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Jul 5 15:16:48 2018 +0100

    arm64: add PSR_AA32_* definitions
    
    The AArch32 CPSR/SPSR format is *almost* identical to the AArch64
    SPSR_ELx format for exceptions taken from AArch32, but the two have
    diverged with the addition of DIT, and we need to treat the two as
    logically distinct.
    
    This patch adds new definitions for the SPSR_ELx format for exceptions
    taken from AArch32, with a consistent PSR_AA32_ prefix. The existing
    COMPAT_PSR_ definitions will be used for the PSR format as seen from
    AArch32.
    
    Definitions of DIT are provided for both, and inline functions are
    provided to map between the two formats. Note that for SPSR_ELx, the
    (RES0) J bit has been re-allocated as the DIT bit.
    
    Once users of the COMPAT_PSR definitions have been migrated over to the
    PSR_AA32 definitions, the (majority of) the former will be removed, so
    no efforts is made to avoid duplication until then.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christoffer Dall <christoffer.dall@arm.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Suzuki Poulose <suzuki.poulose@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 6069d66e0bc2..1b2a253de6a1 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -35,7 +35,37 @@
 #define COMPAT_PTRACE_GETHBPREGS	29
 #define COMPAT_PTRACE_SETHBPREGS	30
 
-/* AArch32 CPSR bits */
+/* SPSR_ELx bits for exceptions taken from AArch32 */
+#define PSR_AA32_MODE_MASK	0x0000001f
+#define PSR_AA32_MODE_USR	0x00000010
+#define PSR_AA32_MODE_FIQ	0x00000011
+#define PSR_AA32_MODE_IRQ	0x00000012
+#define PSR_AA32_MODE_SVC	0x00000013
+#define PSR_AA32_MODE_ABT	0x00000017
+#define PSR_AA32_MODE_HYP	0x0000001a
+#define PSR_AA32_MODE_UND	0x0000001b
+#define PSR_AA32_MODE_SYS	0x0000001f
+#define PSR_AA32_T_BIT		0x00000020
+#define PSR_AA32_F_BIT		0x00000040
+#define PSR_AA32_I_BIT		0x00000080
+#define PSR_AA32_A_BIT		0x00000100
+#define PSR_AA32_E_BIT		0x00000200
+#define PSR_AA32_DIT_BIT	0x01000000
+#define PSR_AA32_Q_BIT		0x08000000
+#define PSR_AA32_V_BIT		0x10000000
+#define PSR_AA32_C_BIT		0x20000000
+#define PSR_AA32_Z_BIT		0x40000000
+#define PSR_AA32_N_BIT		0x80000000
+#define PSR_AA32_IT_MASK	0x0600fc00	/* If-Then execution state mask */
+#define PSR_AA32_GE_MASK	0x000f0000
+
+#ifdef CONFIG_CPU_BIG_ENDIAN
+#define PSR_AA32_ENDSTATE	PSR_AA32_E_BIT
+#else
+#define PSR_AA32_ENDSTATE	0
+#endif
+
+/* AArch32 CPSR bits, as seen in AArch32 */
 #define COMPAT_PSR_MODE_MASK	0x0000001f
 #define COMPAT_PSR_MODE_USR	0x00000010
 #define COMPAT_PSR_MODE_FIQ	0x00000011
@@ -50,6 +80,7 @@
 #define COMPAT_PSR_I_BIT	0x00000080
 #define COMPAT_PSR_A_BIT	0x00000100
 #define COMPAT_PSR_E_BIT	0x00000200
+#define COMPAT_PSR_DIT_BIT	0x00200000
 #define COMPAT_PSR_J_BIT	0x01000000
 #define COMPAT_PSR_Q_BIT	0x08000000
 #define COMPAT_PSR_V_BIT	0x10000000
@@ -111,6 +142,30 @@
 #define compat_sp_fiq	regs[29]
 #define compat_lr_fiq	regs[30]
 
+static inline unsigned long compat_psr_to_pstate(const unsigned long psr)
+{
+	unsigned long pstate;
+
+	pstate = psr & ~COMPAT_PSR_DIT_BIT;
+
+	if (psr & COMPAT_PSR_DIT_BIT)
+		pstate |= PSR_AA32_DIT_BIT;
+
+	return pstate;
+}
+
+static inline unsigned long pstate_to_compat_psr(const unsigned long pstate)
+{
+	unsigned long psr;
+
+	psr = pstate & ~PSR_AA32_DIT_BIT;
+
+	if (pstate & PSR_AA32_DIT_BIT)
+		psr |= COMPAT_PSR_DIT_BIT;
+
+	return psr;
+}
+
 /*
  * This struct defines the way the registers are stored on the stack during an
  * exception. Note that sizeof(struct pt_regs) has to be a multiple of 16 (for

commit 0553896787353e2526078064ff1cf21ff7bc34ce
Merge: 739586951b8a 31e43ad3b74a
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Wed Aug 9 15:37:49 2017 +0100

    Merge branch 'arm64/exception-stack' of git://git.kernel.org/pub/scm/linux/kernel/git/mark/linux into for-next/core
    
    * 'arm64/exception-stack' of git://git.kernel.org/pub/scm/linux/kernel/git/mark/linux:
      arm64: unwind: remove sp from struct stackframe
      arm64: unwind: reference pt_regs via embedded stack frame
      arm64: unwind: disregard frame.sp when validating frame pointer
      arm64: unwind: avoid percpu indirection for irq stack
      arm64: move non-entry code out of .entry.text
      arm64: consistently use bl for C exception entry
      arm64: Add ASM_BUG()

commit 7326749801396105aef0ed9229df746ac9e24300
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sat Jul 22 18:45:33 2017 +0100

    arm64: unwind: reference pt_regs via embedded stack frame
    
    As it turns out, the unwind code is slightly broken, and probably has
    been for a while. The problem is in the dumping of the exception stack,
    which is intended to dump the contents of the pt_regs struct at each
    level in the call stack where an exception was taken and routed to a
    routine marked as __exception (which means its stack frame is right
    below the pt_regs struct on the stack).
    
    'Right below the pt_regs struct' is ill defined, though: the unwind
    code assigns 'frame pointer + 0x10' to the .sp member of the stackframe
    struct at each level, and dump_backtrace() happily dereferences that as
    the pt_regs pointer when encountering an __exception routine. However,
    the actual size of the stack frame created by this routine (which could
    be one of many __exception routines we have in the kernel) is not known,
    and so frame.sp is pretty useless to figure out where struct pt_regs
    really is.
    
    So it seems the only way to ensure that we can find our struct pt_regs
    when walking the stack frames is to put it at a known fixed offset of
    the stack frame pointer that is passed to such __exception routines.
    The simplest way to do that is to put it inside pt_regs itself, which is
    the main change implemented by this patch. As a bonus, doing this allows
    us to get rid of a fair amount of cruft related to walking from one stack
    to the other, which is especially nice since we intend to introduce yet
    another stack for overflow handling once we add support for vmapped
    stacks. It also fixes an inconsistency where we only add a stack frame
    pointing to ELR_EL1 if we are executing from the IRQ stack but not when
    we are executing from the task stack.
    
    To consistly identify exceptions regs even in the presence of exceptions
    taken from entry code, we must check whether the next frame was created
    by entry text, rather than whether the current frame was crated by
    exception text.
    
    To avoid backtracing using PCs that fall in the idmap, or are controlled
    by userspace, we must explcitly zero the FP and LR in startup paths, and
    must ensure that the frame embedded in pt_regs is zeroed upon entry from
    EL0. To avoid these NULL entries showin in the backtrace, unwind_frame()
    is updated to avoid them.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    [Mark: compare current frame against .entry.text, avoid bogus PCs]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 11403fdd0a50..ee72aa979078 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -119,6 +119,7 @@ struct pt_regs {
 	u64 syscallno;
 	u64 orig_addr_limit;
 	u64 unused;	// maintain 16 byte alignment
+	u64 stackframe[2];
 };
 
 #define MAX_REG_OFFSET offsetof(struct pt_regs, pstate)

commit 17c28958600928109049a3bcc814b0d5bfb1ff3a
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Aug 1 15:35:54 2017 +0100

    arm64: Abstract syscallno manipulation
    
    The -1 "no syscall" value is written in various ways, shared with
    the user ABI in some places, and generally obscure.
    
    This patch attempts to make things a little more consistent and
    readable by replacing all these uses with a single #define.  A
    couple of symbolic helpers are provided to clarify the intent
    further.
    
    Because the in-syscall check in do_signal() is changed from >= 0 to
    != NO_SYSCALL by this patch, different behaviour may be observable
    if syscallno is set to values less than -1 by a tracer.  However,
    this is not different from the behaviour that is already observable
    if a tracer sets syscallno to a value >= __NR_(compat_)syscalls.
    
    It appears that this can cause spurious syscall restarting, but
    that is not a new behaviour either, and does not appear harmful.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 21c87dc240e1..4f64373b84fd 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -72,8 +72,19 @@
 #define COMPAT_PT_TEXT_ADDR		0x10000
 #define COMPAT_PT_DATA_ADDR		0x10004
 #define COMPAT_PT_TEXT_END_ADDR		0x10008
+
+/*
+ * If pt_regs.syscallno == NO_SYSCALL, then the thread is not executing
+ * a syscall -- i.e., its most recent entry into the kernel from
+ * userspace was not via SVC, or otherwise a tracer cancelled the syscall.
+ *
+ * This must have the value -1, for ABI compatibility with ptrace etc.
+ */
+#define NO_SYSCALL (-1)
+
 #ifndef __ASSEMBLY__
 #include <linux/bug.h>
+#include <linux/types.h>
 
 /* sizeof(struct user) for AArch32 */
 #define COMPAT_USER_SZ	296
@@ -128,6 +139,16 @@ struct pt_regs {
 	u64 unused;	// maintain 16 byte alignment
 };
 
+static inline bool in_syscall(struct pt_regs const *regs)
+{
+	return regs->syscallno != NO_SYSCALL;
+}
+
+static inline void forget_syscall(struct pt_regs *regs)
+{
+	regs->syscallno = NO_SYSCALL;
+}
+
 #define MAX_REG_OFFSET offsetof(struct pt_regs, pstate)
 
 #define arch_has_single_step()	(1)

commit 35d0e6fb4d219d64ab3b7cffef7a11a0662140f5
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Aug 1 15:35:53 2017 +0100

    arm64: syscallno is secretly an int, make it official
    
    The upper 32 bits of the syscallno field in thread_struct are
    handled inconsistently, being sometimes zero extended and sometimes
    sign-extended.  In fact, only the lower 32 bits seem to have any
    real significance for the behaviour of the code: it's been OK to
    handle the upper bits inconsistently because they don't matter.
    
    Currently, the only place I can find where those bits are
    significant is in calling trace_sys_enter(), which may be
    unintentional: for example, if a compat tracer attempts to cancel a
    syscall by passing -1 to (COMPAT_)PTRACE_SET_SYSCALL at the
    syscall-enter-stop, it will be traced as syscall 4294967295
    rather than -1 as might be expected (and as occurs for a native
    tracer doing the same thing).  Elsewhere, reads of syscallno cast
    it to an int or truncate it.
    
    There's also a conspicuous amount of code and casting to bodge
    around the fact that although semantically an int, syscallno is
    stored as a u64.
    
    Let's not pretend any more.
    
    In order to preserve the stp x instruction that stores the syscall
    number in entry.S, this patch special-cases the layout of struct
    pt_regs for big endian so that the newly 32-bit syscallno field
    maps onto the low bits of the stored value.  This is not beautiful,
    but benchmarking of the getpid syscall on Juno suggests indicates a
    minor slowdown if the stp is split into an stp x and stp w.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 11403fdd0a50..21c87dc240e1 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -116,7 +116,14 @@ struct pt_regs {
 		};
 	};
 	u64 orig_x0;
-	u64 syscallno;
+#ifdef __AARCH64EB__
+	u32 unused2;
+	s32 syscallno;
+#else
+	s32 syscallno;
+	u32 unused2;
+#endif
+
 	u64 orig_addr_limit;
 	u64 unused;	// maintain 16 byte alignment
 };

commit 6c23e2ff7013be2c4bbcb7b9b3cc27c763348223
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Feb 9 15:19:18 2017 +0000

    arm64: ptrace: add XZR-safe regs accessors
    
    In A64, XZR and the SP share the same encoding (31), and whether an
    instruction accesses XZR or SP for a particular register parameter
    depends on the definition of the instruction.
    
    We store the SP in pt_regs::regs[31], and thus when emulating
    instructions, we must be careful to not erroneously read from or write
    back to the saved SP. Unfortunately, we often fail to be this careful.
    
    In all cases, instructions using a transfer register parameter Xt use
    this to refer to XZR rather than SP. This patch adds helpers so that we
    can more easily and consistently handle these cases.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 513daf050e84..11403fdd0a50 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -194,6 +194,26 @@ static inline u64 regs_get_register(struct pt_regs *regs, unsigned int offset)
 	return val;
 }
 
+/*
+ * Read a register given an architectural register index r.
+ * This handles the common case where 31 means XZR, not SP.
+ */
+static inline unsigned long pt_regs_read_reg(const struct pt_regs *regs, int r)
+{
+	return (r == 31) ? 0 : regs->regs[r];
+}
+
+/*
+ * Write a register given an architectural register index r.
+ * This handles the common case where 31 means XZR, not SP.
+ */
+static inline void pt_regs_write_reg(struct pt_regs *regs, int r,
+				     unsigned long val)
+{
+	if (r != 31)
+		regs->regs[r] = val;
+}
+
 /* Valid only for Kernel mode traps. */
 static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
 {

commit 9842ceae9fa8deae141533d52a6ead7666962c09
Author: Pratyush Anand <panand@redhat.com>
Date:   Wed Nov 2 14:40:46 2016 +0530

    arm64: Add uprobe support
    
    This patch adds support for uprobe on ARM64 architecture.
    
    Unit tests for following have been done so far and they have been found
    working
        1. Step-able instructions, like sub, ldr, add etc.
        2. Simulation-able like ret, cbnz, cbz etc.
        3. uretprobe
        4. Reject-able instructions like sev, wfe etc.
        5. trapped and abort xol path
        6. probe at unaligned user address.
        7. longjump test cases
    
    Currently it does not support aarch32 instruction probing.
    
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index ada08b5b036d..513daf050e84 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -217,6 +217,14 @@ int valid_user_regs(struct user_pt_regs *regs, struct task_struct *task);
 
 #include <asm-generic/ptrace.h>
 
+#define procedure_link_pointer(regs)	((regs)->regs[30])
+
+static inline void procedure_link_pointer_set(struct pt_regs *regs,
+					   unsigned long val)
+{
+	procedure_link_pointer(regs) = val;
+}
+
 #undef profile_pc
 extern unsigned long profile_pc(struct pt_regs *regs);
 

commit e831101a73fbc8339ef1d1909dad3ef64f089e70
Merge: f9abf53af4c7 fd6380b75065
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 11:16:05 2016 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - Kexec support for arm64
    
     - Kprobes support
    
     - Expose MIDR_EL1 and REVIDR_EL1 CPU identification registers to sysfs
    
     - Trapping of user space cache maintenance operations and emulation in
       the kernel (CPU errata workaround)
    
     - Clean-up of the early page tables creation (kernel linear mapping,
       EFI run-time maps) to avoid splitting larger blocks (e.g.  pmds) into
       smaller ones (e.g.  ptes)
    
     - VDSO support for CLOCK_MONOTONIC_RAW in clock_gettime()
    
     - ARCH_HAS_KCOV enabled for arm64
    
     - Optimise IP checksum helpers
    
     - SWIOTLB optimisation to only allocate/initialise the buffer if the
       available RAM is beyond the 32-bit mask
    
     - Properly handle the "nosmp" command line argument
    
     - Fix for the initialisation of the CPU debug state during early boot
    
     - vdso-offsets.h build dependency workaround
    
     - Build fix when RANDOMIZE_BASE is enabled with MODULES off
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (64 commits)
      arm64: arm: Fix-up the removal of the arm64 regs_query_register_name() prototype
      arm64: Only select ARM64_MODULE_PLTS if MODULES=y
      arm64: mm: run pgtable_page_ctor() on non-swapper translation table pages
      arm64: mm: make create_mapping_late() non-allocating
      arm64: Honor nosmp kernel command line option
      arm64: Fix incorrect per-cpu usage for boot CPU
      arm64: kprobes: Add KASAN instrumentation around stack accesses
      arm64: kprobes: Cleanup jprobe_return
      arm64: kprobes: Fix overflow when saving stack
      arm64: kprobes: WARN if attempting to step with PSTATE.D=1
      arm64: debug: remove unused local_dbg_{enable, disable} macros
      arm64: debug: remove redundant spsr manipulation
      arm64: debug: unmask PSTATE.D earlier
      arm64: localise Image objcopy flags
      arm64: ptrace: remove extra define for CPSR's E bit
      kprobes: Add arm64 case in kprobe example module
      arm64: Add kernel return probes support (kretprobes)
      arm64: Add trampoline code for kretprobes
      arm64: kprobes instruction simulation support
      arm64: Treat all entry code as non-kprobe-able
      ...

commit fd6380b75065fd2ff51b5f7cbbe6be77d71ea9c7
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Wed Jul 27 08:11:10 2016 +0100

    arm64: arm: Fix-up the removal of the arm64 regs_query_register_name() prototype
    
    Commit 0a8ea52c3eb1 ("arm64: Add HAVE_REGS_AND_STACK_ACCESS_API
    feature") inadvertently removed the arch/arm prototype instead of the
    arm64 one introduced by the original patch. There should not be any
    bisection issues since this function is not called from anywhere else
    (it could as well be removed from arch/arm at some point).
    
    Fixes: 0a8ea52c3eb1 ("arm64: Add HAVE_REGS_AND_STACK_ACCESS_API feature")
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 3fd15fdf4181..8fbac706b906 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -153,7 +153,6 @@ struct pt_regs {
 	(!compat_user_mode(regs) ? ((regs)->sp = value) : ((regs)->compat_sp = value))
 
 extern int regs_query_register_offset(const char *name);
-extern const char *regs_query_register_name(unsigned int offset);
 extern unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
 					       unsigned int n);
 

commit a95b0644b38c16c40b753224671b919b9af0b73c
Merge: e75118a7b581 f7e35c5ba432
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Jul 21 18:20:41 2016 +0100

    Merge branch 'for-next/kprobes' into for-next/core
    
    * kprobes:
      arm64: kprobes: Add KASAN instrumentation around stack accesses
      arm64: kprobes: Cleanup jprobe_return
      arm64: kprobes: Fix overflow when saving stack
      arm64: kprobes: WARN if attempting to step with PSTATE.D=1
      kprobes: Add arm64 case in kprobe example module
      arm64: Add kernel return probes support (kretprobes)
      arm64: Add trampoline code for kretprobes
      arm64: kprobes instruction simulation support
      arm64: Treat all entry code as non-kprobe-able
      arm64: Blacklist non-kprobe-able symbol
      arm64: Kprobes with single stepping support
      arm64: add conditional instruction simulation support
      arm64: Add more test functions to insn.c
      arm64: Add HAVE_REGS_AND_STACK_ACCESS_API feature

commit 9df53ff2bb89bd9c60e655baaf78251c49c72578
Author: Vladimir Murzin <vladimir.murzin@arm.com>
Date:   Mon Jul 18 11:20:54 2016 +0100

    arm64: ptrace: remove extra define for CPSR's E bit
    
    ...and do not confuse source navigation tools ;)
    
    Signed-off-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index a307eb6e7fa8..10e6f1d7269c 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -46,7 +46,6 @@
 #define COMPAT_PSR_MODE_UND	0x0000001b
 #define COMPAT_PSR_MODE_SYS	0x0000001f
 #define COMPAT_PSR_T_BIT	0x00000020
-#define COMPAT_PSR_E_BIT	0x00000200
 #define COMPAT_PSR_F_BIT	0x00000040
 #define COMPAT_PSR_I_BIT	0x00000080
 #define COMPAT_PSR_A_BIT	0x00000100

commit 2dd0e8d2d2a157dbc83295a78336c2217110f2f8
Author: Sandeepa Prabhu <sandeepa.s.prabhu@gmail.com>
Date:   Fri Jul 8 12:35:48 2016 -0400

    arm64: Kprobes with single stepping support
    
    Add support for basic kernel probes(kprobes) and jump probes
    (jprobes) for ARM64.
    
    Kprobes utilizes software breakpoint and single step debug
    exceptions supported on ARM v8.
    
    A software breakpoint is placed at the probe address to trap the
    kernel execution into the kprobe handler.
    
    ARM v8 supports enabling single stepping before the break exception
    return (ERET), with next PC in exception return address (ELR_EL1). The
    kprobe handler prepares an executable memory slot for out-of-line
    execution with a copy of the original instruction being probed, and
    enables single stepping. The PC is set to the out-of-line slot address
    before the ERET. With this scheme, the instruction is executed with the
    exact same register context except for the PC (and DAIF) registers.
    
    Debug mask (PSTATE.D) is enabled only when single stepping a recursive
    kprobe, e.g.: during kprobes reenter so that probed instruction can be
    single stepped within the kprobe handler -exception- context.
    The recursion depth of kprobe is always 2, i.e. upon probe re-entry,
    any further re-entry is prevented by not calling handlers and the case
    counted as a missed kprobe).
    
    Single stepping from the x-o-l slot has a drawback for PC-relative accesses
    like branching and symbolic literals access as the offset from the new PC
    (slot address) may not be ensured to fit in the immediate value of
    the opcode. Such instructions need simulation, so reject
    probing them.
    
    Instructions generating exceptions or cpu mode change are rejected
    for probing.
    
    Exclusive load/store instructions are rejected too.  Additionally, the
    code is checked to see if it is inside an exclusive load/store sequence
    (code from Pratyush).
    
    System instructions are mostly enabled for stepping, except MSR/MRS
    accesses to "DAIF" flags in PSTATE, which are not safe for
    probing.
    
    This also changes arch/arm64/include/asm/ptrace.h to use
    include/asm-generic/ptrace.h.
    
    Thanks to Steve Capper and Pratyush Anand for several suggested
    Changes.
    
    Signed-off-by: Sandeepa Prabhu <sandeepa.s.prabhu@gmail.com>
    Signed-off-by: David A. Long <dave.long@linaro.org>
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 941e12d235be..baf938135986 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -147,9 +147,12 @@ struct pt_regs {
 #define fast_interrupts_enabled(regs) \
 	(!((regs)->pstate & PSR_F_BIT))
 
-#define user_stack_pointer(regs) \
+#define GET_USP(regs) \
 	(!compat_user_mode(regs) ? (regs)->sp : (regs)->compat_sp)
 
+#define SET_USP(ptregs, value) \
+	(!compat_user_mode(regs) ? ((regs)->sp = value) : ((regs)->compat_sp = value))
+
 extern int regs_query_register_offset(const char *name);
 extern const char *regs_query_register_name(unsigned int offset);
 extern unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
@@ -206,8 +209,15 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 struct task_struct;
 int valid_user_regs(struct user_pt_regs *regs, struct task_struct *task);
 
-#define instruction_pointer(regs)	((unsigned long)(regs)->pc)
+#define GET_IP(regs)		((unsigned long)(regs)->pc)
+#define SET_IP(regs, value)	((regs)->pc = ((u64) (value)))
+
+#define GET_FP(ptregs)		((unsigned long)(ptregs)->regs[29])
+#define SET_FP(ptregs, value)	((ptregs)->regs[29] = ((u64) (value)))
+
+#include <asm-generic/ptrace.h>
 
+#undef profile_pc
 extern unsigned long profile_pc(struct pt_regs *regs);
 
 #endif /* __ASSEMBLY__ */

commit 0a8ea52c3eb157dd65e224fc95b7c9c99fcba9f7
Author: David A. Long <dave.long@linaro.org>
Date:   Fri Jul 8 12:35:45 2016 -0400

    arm64: Add HAVE_REGS_AND_STACK_ACCESS_API feature
    
    Add HAVE_REGS_AND_STACK_ACCESS_API feature for arm64, including supporting
    functions and defines.
    
    Signed-off-by: David A. Long <dave.long@linaro.org>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    [catalin.marinas@arm.com: Remove unused functions]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index a307eb6e7fa8..941e12d235be 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -74,6 +74,7 @@
 #define COMPAT_PT_DATA_ADDR		0x10004
 #define COMPAT_PT_TEXT_END_ADDR		0x10008
 #ifndef __ASSEMBLY__
+#include <linux/bug.h>
 
 /* sizeof(struct user) for AArch32 */
 #define COMPAT_USER_SZ	296
@@ -119,6 +120,8 @@ struct pt_regs {
 	u64 syscallno;
 };
 
+#define MAX_REG_OFFSET offsetof(struct pt_regs, pstate)
+
 #define arch_has_single_step()	(1)
 
 #ifdef CONFIG_COMPAT
@@ -147,6 +150,53 @@ struct pt_regs {
 #define user_stack_pointer(regs) \
 	(!compat_user_mode(regs) ? (regs)->sp : (regs)->compat_sp)
 
+extern int regs_query_register_offset(const char *name);
+extern const char *regs_query_register_name(unsigned int offset);
+extern unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs,
+					       unsigned int n);
+
+/**
+ * regs_get_register() - get register value from its offset
+ * @regs:	pt_regs from which register value is gotten
+ * @offset:	offset of the register.
+ *
+ * regs_get_register returns the value of a register whose offset from @regs.
+ * The @offset is the offset of the register in struct pt_regs.
+ * If @offset is bigger than MAX_REG_OFFSET, this returns 0.
+ */
+static inline u64 regs_get_register(struct pt_regs *regs, unsigned int offset)
+{
+	u64 val = 0;
+
+	WARN_ON(offset & 7);
+
+	offset >>= 3;
+	switch (offset) {
+	case 0 ... 30:
+		val = regs->regs[offset];
+		break;
+	case offsetof(struct pt_regs, sp) >> 3:
+		val = regs->sp;
+		break;
+	case offsetof(struct pt_regs, pc) >> 3:
+		val = regs->pc;
+		break;
+	case offsetof(struct pt_regs, pstate) >> 3:
+		val = regs->pstate;
+		break;
+	default:
+		val = 0;
+	}
+
+	return val;
+}
+
+/* Valid only for Kernel mode traps. */
+static inline unsigned long kernel_stack_pointer(struct pt_regs *regs)
+{
+	return regs->sp;
+}
+
 static inline unsigned long regs_return_value(struct pt_regs *regs)
 {
 	return regs->regs[0];

commit e19a6ee2460bdd0d0055a6029383422773f9999a
Author: James Morse <james.morse@arm.com>
Date:   Mon Jun 20 18:28:01 2016 +0100

    arm64: kernel: Save and restore UAO and addr_limit on exception entry
    
    If we take an exception while at EL1, the exception handler inherits
    the original context's addr_limit and PSTATE.UAO values. To be consistent
    always reset addr_limit and PSTATE.UAO on (re-)entry to EL1. This
    prevents accidental re-use of the original context's addr_limit.
    
    Based on a similar patch for arm from Russell King.
    
    Cc: <stable@vger.kernel.org> # 4.6-
    Acked-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index a307eb6e7fa8..7f94755089e2 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -117,6 +117,8 @@ struct pt_regs {
 	};
 	u64 orig_x0;
 	u64 syscallno;
+	u64 orig_addr_limit;
+	u64 unused;	// maintain 16 byte alignment
 };
 
 #define arch_has_single_step()	(1)

commit dbd4d7ca563fd0a8949718d35ce197e5642d5d9d
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Mar 1 14:18:50 2016 +0000

    arm64: Rework valid_user_regs
    
    We validate pstate using PSR_MODE32_BIT, which is part of the
    user-provided pstate (and cannot be trusted). Also, we conflate
    validation of AArch32 and AArch64 pstate values, making the code
    difficult to reason about.
    
    Instead, validate the pstate value based on the associated task. The
    task may or may not be current (e.g. when using ptrace), so this must be
    passed explicitly by callers. To avoid circular header dependencies via
    sched.h, is_compat_task is pulled out of asm/ptrace.h.
    
    To make the code possible to reason about, the AArch64 and AArch32
    validation is split into separate functions. Software must respect the
    RES0 policy for SPSR bits, and thus the kernel mirrors the hardware
    policy (RAZ/WI) for bits as-yet unallocated. When these acquire an
    architected meaning writes may be permitted (potentially with additional
    validation).
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Dave Martin <dave.martin@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Peter Maydell <peter.maydell@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index e9e5467e0bf4..a307eb6e7fa8 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -58,6 +58,7 @@
 #define COMPAT_PSR_Z_BIT	0x40000000
 #define COMPAT_PSR_N_BIT	0x80000000
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
+#define COMPAT_PSR_GE_MASK	0x000f0000
 
 #ifdef CONFIG_CPU_BIG_ENDIAN
 #define COMPAT_PSR_ENDSTATE	COMPAT_PSR_E_BIT
@@ -151,35 +152,9 @@ static inline unsigned long regs_return_value(struct pt_regs *regs)
 	return regs->regs[0];
 }
 
-/*
- * Are the current registers suitable for user mode? (used to maintain
- * security in signal handlers)
- */
-static inline int valid_user_regs(struct user_pt_regs *regs)
-{
-	if (user_mode(regs) && (regs->pstate & PSR_I_BIT) == 0) {
-		regs->pstate &= ~(PSR_F_BIT | PSR_A_BIT);
-
-		/* The T bit is reserved for AArch64 */
-		if (!(regs->pstate & PSR_MODE32_BIT))
-			regs->pstate &= ~COMPAT_PSR_T_BIT;
-
-		return 1;
-	}
-
-	/*
-	 * Force PSR to something logical...
-	 */
-	regs->pstate &= PSR_f | PSR_s | (PSR_x & ~PSR_A_BIT) | \
-			COMPAT_PSR_T_BIT | PSR_MODE32_BIT;
-
-	if (!(regs->pstate & PSR_MODE32_BIT)) {
-		regs->pstate &= ~COMPAT_PSR_T_BIT;
-		regs->pstate |= PSR_MODE_EL0t;
-	}
-
-	return 0;
-}
+/* We must avoid circular header include via sched.h */
+struct task_struct;
+int valid_user_regs(struct user_pt_regs *regs, struct task_struct *task);
 
 #define instruction_pointer(regs)	((unsigned long)(regs)->pc)
 

commit 5accd17d0eb523350c9ef754d655e379c9bb93b3
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Oct 22 15:41:52 2015 +0100

    arm64: Fix compat register mappings
    
    For reasons not entirely apparent, but now enshrined in history, the
    architectural mapping of AArch32 banked registers to AArch64 registers
    actually orders SP_<mode> and LR_<mode> backwards compared to the
    intuitive r13/r14 order, for all modes except FIQ.
    
    Fix the compat_<reg>_<mode> macros accordingly, in the hope of avoiding
    subtle bugs with KVM and AArch32 guests.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 536274ed292e..e9e5467e0bf4 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -83,14 +83,14 @@
 #define compat_sp	regs[13]
 #define compat_lr	regs[14]
 #define compat_sp_hyp	regs[15]
-#define compat_sp_irq	regs[16]
-#define compat_lr_irq	regs[17]
-#define compat_sp_svc	regs[18]
-#define compat_lr_svc	regs[19]
-#define compat_sp_abt	regs[20]
-#define compat_lr_abt	regs[21]
-#define compat_sp_und	regs[22]
-#define compat_lr_und	regs[23]
+#define compat_lr_irq	regs[16]
+#define compat_sp_irq	regs[17]
+#define compat_lr_svc	regs[18]
+#define compat_sp_svc	regs[19]
+#define compat_lr_abt	regs[20]
+#define compat_sp_abt	regs[21]
+#define compat_lr_und	regs[22]
+#define compat_sp_und	regs[23]
 #define compat_r8_fiq	regs[24]
 #define compat_r9_fiq	regs[25]
 #define compat_r10_fiq	regs[26]

commit 4b3dc9679cf779339d9049800803dfc3c83433d1
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri May 29 18:28:44 2015 +0100

    arm64: force CONFIG_SMP=y and remove redundant #ifdefs
    
    Nobody seems to be producing !SMP systems anymore, so this is just
    becoming a source of kernel bugs, particularly if people want to use
    coherent DMA with non-shared pages.
    
    This patch forces CONFIG_SMP=y for arm64, removing a modest amount of
    code in the process.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index d6dd9fdbc3be..536274ed292e 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -183,11 +183,7 @@ static inline int valid_user_regs(struct user_pt_regs *regs)
 
 #define instruction_pointer(regs)	((unsigned long)(regs)->pc)
 
-#ifdef CONFIG_SMP
 extern unsigned long profile_pc(struct pt_regs *regs);
-#else
-#define profile_pc(regs) instruction_pointer(regs)
-#endif
 
 #endif /* __ASSEMBLY__ */
 #endif

commit 2d888f48e056119495847a269a435d5c3d9df349
Author: Suzuki K. Poulose <suzuki.poulose@arm.com>
Date:   Wed Jan 21 12:43:11 2015 +0000

    arm64: Emulate SETEND for AArch32 tasks
    
    Emulate deprecated 'setend' instruction for AArch32 bit tasks.
    
            setend [le/be] - Sets the endianness of EL0
    
    On systems with CPUs which support mixed endian at EL0, the hardware
    support for the instruction can be enabled by setting the SCTLR_EL1.SED
    bit. Like the other emulated instructions it is controlled by an entry in
    /proc/sys/abi/. For more information see :
            Documentation/arm64/legacy_instructions.txt
    
    The instruction is emulated by setting/clearing the SPSR_EL1.E bit, which
    will be reflected in the PSTATE.E in AArch32 context.
    
    This patch also restores the native endianness for the execution of signal
    handlers, since the process could have changed the endianness.
    
    Note: All CPUs on the system must have mixed endian support at EL0. Once the
    handler is registered, hotplugging a CPU which doesn't support mixed endian,
    could lead to unexpected results/behavior in applications.
    
    Signed-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Punit Agrawal <punit.agrawal@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 41ed9e13795e..d6dd9fdbc3be 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -58,6 +58,13 @@
 #define COMPAT_PSR_Z_BIT	0x40000000
 #define COMPAT_PSR_N_BIT	0x80000000
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
+
+#ifdef CONFIG_CPU_BIG_ENDIAN
+#define COMPAT_PSR_ENDSTATE	COMPAT_PSR_E_BIT
+#else
+#define COMPAT_PSR_ENDSTATE	0
+#endif
+
 /*
  * These are 'magic' values for PTRACE_PEEKUSR that return info about where a
  * process is located in memory.

commit 2520d039728b2a3c5ae7f79fe2a0e9d182855b12
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Fri Aug 29 16:08:02 2014 +0100

    arm64: Add brackets around user_stack_pointer()
    
    Commit 5f888a1d33 (ARM64: perf: support dwarf unwinding in compat mode)
    changes user_stack_pointer() to return the compat SP for 32-bit tasks
    but without brackets around the whole definition, with possible issues
    on the call sites (noticed with a subsequent fix for KSTK_ESP).
    
    Fixes: 5f888a1d33c4 (ARM64: perf: support dwarf unwinding in compat mode)
    Reported-by: Sudeep Holla <sudeep.holla@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 501000fadb6f..41ed9e13795e 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -137,7 +137,7 @@ struct pt_regs {
 	(!((regs)->pstate & PSR_F_BIT))
 
 #define user_stack_pointer(regs) \
-	(!compat_user_mode(regs)) ? ((regs)->sp) : ((regs)->compat_sp)
+	(!compat_user_mode(regs) ? (regs)->sp : (regs)->compat_sp)
 
 static inline unsigned long regs_return_value(struct pt_regs *regs)
 {

commit 974c8e450b9327a03453a4a450a2030b1bd42b5f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Jun 6 14:16:21 2014 +0100

    arm64: fix el2_setup check of CurrentEL
    
    The CurrentEL system register reports the Current Exception Level
    of the CPU. It doesn't say anything about the stack handling, and
    yet we compare it to PSR_MODE_EL2t and PSR_MODE_EL2h.
    
    It works by chance because PSR_MODE_EL2t happens to match the right
    bits, but that's otherwise a very bad idea. Just check for the EL
    value instead.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    [catalin.marinas@arm.com: fixed arch/arm64/kernel/efi-entry.S]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index a429b5940be2..501000fadb6f 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -21,6 +21,10 @@
 
 #include <uapi/asm/ptrace.h>
 
+/* Current Exception Level values, as contained in CurrentEL */
+#define CurrentEL_EL1		(1 << 2)
+#define CurrentEL_EL2		(2 << 2)
+
 /* AArch32-specific ptrace requests */
 #define COMPAT_PTRACE_GETREGS		12
 #define COMPAT_PTRACE_SETREGS		13

commit d34a3ebd8d25cf691a94fae66a957a480cf46430
Author: AKASHI Takahiro <takahiro.akashi@linaro.org>
Date:   Wed Apr 30 10:51:31 2014 +0100

    arm64: Add regs_return_value() in syscall.h
    
    This macro, regs_return_value, is used mainly for audit to record system
    call's results, but may also be used in test_kprobes.c.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Richard Guy Briggs <rgb@redhat.com>
    Signed-off-by: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index c7ba261dd4b3..a429b5940be2 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -135,6 +135,11 @@ struct pt_regs {
 #define user_stack_pointer(regs) \
 	(!compat_user_mode(regs)) ? ((regs)->sp) : ((regs)->compat_sp)
 
+static inline unsigned long regs_return_value(struct pt_regs *regs)
+{
+	return regs->regs[0];
+}
+
 /*
  * Are the current registers suitable for user mode? (used to maintain
  * security in signal handlers)

commit 5f888a1d33c48900012e6b4c18296ce7c715dc6c
Author: Jean Pihet <jean.pihet@linaro.org>
Date:   Mon Feb 3 19:18:29 2014 +0100

    ARM64: perf: support dwarf unwinding in compat mode
    
    Add support for unwinding using the dwarf information in compat
    mode. Using the correct user stack pointer allows perf to record
    the frames correctly in the native and compat modes.
    
    Note that although the dwarf frame unwinding works ok using
    libunwind in native mode (on ARMv7 & ARMv8), some changes are
    required to the libunwind code for the compat mode. Those changes
    are posted separately on the libunwind mailing list.
    
    Tested on ARMv8 platform with v8 and compat v7 binaries, the latter
    are statically built.
    
    Signed-off-by: Jean Pihet <jean.pihet@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 35ff2f9de072..c7ba261dd4b3 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -133,7 +133,7 @@ struct pt_regs {
 	(!((regs)->pstate & PSR_F_BIT))
 
 #define user_stack_pointer(regs) \
-	((regs)->sp)
+	(!compat_user_mode(regs)) ? ((regs)->sp) : ((regs)->compat_sp)
 
 /*
  * Are the current registers suitable for user mode? (used to maintain

commit 2ee0d7fd36a3f87bc5b29b1ec54ad6728deedb41
Author: Jean Pihet <jean.pihet@linaro.org>
Date:   Mon Feb 3 19:18:27 2014 +0100

    ARM64: perf: add support for perf registers API
    
    This patch implements the functions required for the perf registers API,
    allowing the perf tool to interface kernel register dumps with libunwind
    in order to provide userspace backtracing.
    Compat mode is also supported.
    
    Only the general purpose user space registers are exported, i.e.:
     PERF_REG_ARM_X0,
     ...
     PERF_REG_ARM_X28,
     PERF_REG_ARM_FP,
     PERF_REG_ARM_LR,
     PERF_REG_ARM_SP,
     PERF_REG_ARM_PC
    and not the PERF_REG_ARM_V* registers.
    
    Signed-off-by: Jean Pihet <jean.pihet@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 5233966fba3d..35ff2f9de072 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -68,6 +68,7 @@
 
 /* Architecturally defined mapping between AArch32 and AArch64 registers */
 #define compat_usr(x)	regs[(x)]
+#define compat_fp	regs[11]
 #define compat_sp	regs[13]
 #define compat_lr	regs[14]
 #define compat_sp_hyp	regs[15]

commit 58dcc204f18af2821f683b235bb376f9db2557f5
Author: Vijaya Kumar K <Vijaya.Kumar@caviumnetworks.com>
Date:   Tue Jan 28 16:50:21 2014 +0530

    misc: debug: remove compilation warnings
    
    typecast instruction_pointer macro to unsigned long to
    resolve following compiler warnings like
    warning: format '%lx' expects argument of type 'long unsigned int',
    but argument 2 has type 'u64' [-Wformat]
    
    Signed-off-by: Vijaya Kumar K <Vijaya.Kumar@caviumnetworks.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 0e7fa4963735..5233966fba3d 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -164,7 +164,7 @@ static inline int valid_user_regs(struct user_pt_regs *regs)
 	return 0;
 }
 
-#define instruction_pointer(regs)	(regs)->pc
+#define instruction_pointer(regs)	((unsigned long)(regs)->pc)
 
 #ifdef CONFIG_SMP
 extern unsigned long profile_pc(struct pt_regs *regs);

commit a795a38eb91cf72c4a05e72a9c84e317ee179a48
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Oct 11 14:52:12 2013 +0100

    arm64: compat: add support for big-endian (BE8) AArch32 binaries
    
    This patch adds support for BE8 AArch32 tasks to the compat layer.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 0dacbbf9458b..0e7fa4963735 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -42,6 +42,7 @@
 #define COMPAT_PSR_MODE_UND	0x0000001b
 #define COMPAT_PSR_MODE_SYS	0x0000001f
 #define COMPAT_PSR_T_BIT	0x00000020
+#define COMPAT_PSR_E_BIT	0x00000200
 #define COMPAT_PSR_F_BIT	0x00000040
 #define COMPAT_PSR_I_BIT	0x00000080
 #define COMPAT_PSR_A_BIT	0x00000100

commit 1442b6ed249d2b3d2cfcf45b65ac64393495c96c
Author: Will Deacon <will.deacon@arm.com>
Date:   Sat Mar 16 08:48:13 2013 +0000

    arm64: debug: consolidate software breakpoint handlers
    
    The software breakpoint handlers are hooked in directly from ptrace,
    which makes it difficult to add additional handlers for things like
    kprobes and kgdb.
    
    This patch moves the handling code into debug-monitors.c, where we can
    dispatch to different debug subsystems more easily.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 41a71ee4c3df..0dacbbf9458b 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -171,7 +171,5 @@ extern unsigned long profile_pc(struct pt_regs *regs);
 #define profile_pc(regs) instruction_pointer(regs)
 #endif
 
-extern int aarch32_break_trap(struct pt_regs *regs);
-
 #endif /* __ASSEMBLY__ */
 #endif

commit 10a3cc2f764038e388d6fc3510142ae7d23fb2d9
Author: Marc Zyngier <Marc.Zyngier@arm.com>
Date:   Wed Jan 23 16:59:32 2013 +0000

    arm64: add COMPAT_PSR_*_BIT flags
    
    In order to mess with the processor state when running 32bit
    guests, define all the AArch32 PSR flags.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 4ce845f8ee1c..41a71ee4c3df 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -42,6 +42,16 @@
 #define COMPAT_PSR_MODE_UND	0x0000001b
 #define COMPAT_PSR_MODE_SYS	0x0000001f
 #define COMPAT_PSR_T_BIT	0x00000020
+#define COMPAT_PSR_F_BIT	0x00000040
+#define COMPAT_PSR_I_BIT	0x00000080
+#define COMPAT_PSR_A_BIT	0x00000100
+#define COMPAT_PSR_E_BIT	0x00000200
+#define COMPAT_PSR_J_BIT	0x01000000
+#define COMPAT_PSR_Q_BIT	0x08000000
+#define COMPAT_PSR_V_BIT	0x10000000
+#define COMPAT_PSR_C_BIT	0x20000000
+#define COMPAT_PSR_Z_BIT	0x40000000
+#define COMPAT_PSR_N_BIT	0x80000000
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
 /*
  * These are 'magic' values for PTRACE_PEEKUSR that return info about where a

commit 9ec218b8f5a22bf909b8c016b2abd75763f94acb
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Thu Oct 4 16:28:52 2012 +0100

    arm64: add AArch32 execution modes to ptrace.h
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index de68a5aa60c3..4ce845f8ee1c 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -30,7 +30,17 @@
 #define COMPAT_PTRACE_SETVFPREGS	28
 #define COMPAT_PTRACE_GETHBPREGS	29
 #define COMPAT_PTRACE_SETHBPREGS	30
+
+/* AArch32 CPSR bits */
+#define COMPAT_PSR_MODE_MASK	0x0000001f
 #define COMPAT_PSR_MODE_USR	0x00000010
+#define COMPAT_PSR_MODE_FIQ	0x00000011
+#define COMPAT_PSR_MODE_IRQ	0x00000012
+#define COMPAT_PSR_MODE_SVC	0x00000013
+#define COMPAT_PSR_MODE_ABT	0x00000017
+#define COMPAT_PSR_MODE_HYP	0x0000001a
+#define COMPAT_PSR_MODE_UND	0x0000001b
+#define COMPAT_PSR_MODE_SYS	0x0000001f
 #define COMPAT_PSR_T_BIT	0x00000020
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
 /*

commit 88483ec647c314dedbe157e567c3d24c683cc90f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Oct 3 15:54:09 2012 +0100

    arm64: expand register mapping between AArch32 and AArch64
    
    The general purpose registers in AArch32 are mapped in an
    architecturally defined manner into the AArch64 registers.
    
    It allows the AArch32 registers of an application or a virtual
    machine to be inspected by the OS or an hypervisor.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b04d3404f0d1..de68a5aa60c3 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -44,10 +44,27 @@
 
 /* sizeof(struct user) for AArch32 */
 #define COMPAT_USER_SZ	296
-/* AArch32 uses x13 as the stack pointer... */
+
+/* Architecturally defined mapping between AArch32 and AArch64 registers */
+#define compat_usr(x)	regs[(x)]
 #define compat_sp	regs[13]
-/* ... and x14 as the link register. */
 #define compat_lr	regs[14]
+#define compat_sp_hyp	regs[15]
+#define compat_sp_irq	regs[16]
+#define compat_lr_irq	regs[17]
+#define compat_sp_svc	regs[18]
+#define compat_lr_svc	regs[19]
+#define compat_sp_abt	regs[20]
+#define compat_lr_abt	regs[21]
+#define compat_sp_und	regs[22]
+#define compat_lr_und	regs[23]
+#define compat_r8_fiq	regs[24]
+#define compat_r9_fiq	regs[25]
+#define compat_r10_fiq	regs[26]
+#define compat_r11_fiq	regs[27]
+#define compat_r12_fiq	regs[28]
+#define compat_sp_fiq	regs[29]
+#define compat_lr_fiq	regs[30]
 
 /*
  * This struct defines the way the registers are stored on the stack during an

commit 4262a727621ceadfb38cb90a69804b6ee6be746e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 11 11:05:13 2012 +0100

    UAPI: (Scripted) Disintegrate arch/arm64/include/asm
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index fc2772a27c78..b04d3404f0d1 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -19,11 +19,8 @@
 #ifndef __ASM_PTRACE_H
 #define __ASM_PTRACE_H
 
-#include <linux/types.h>
+#include <uapi/asm/ptrace.h>
 
-#include <asm/hwcap.h>
-
-#ifdef __KERNEL__
 /* AArch32-specific ptrace requests */
 #define COMPAT_PTRACE_GETREGS		12
 #define COMPAT_PTRACE_SETREGS		13
@@ -33,48 +30,9 @@
 #define COMPAT_PTRACE_SETVFPREGS	28
 #define COMPAT_PTRACE_GETHBPREGS	29
 #define COMPAT_PTRACE_SETHBPREGS	30
-#endif
-
-/*
- * PSR bits
- */
-#define PSR_MODE_EL0t	0x00000000
-#define PSR_MODE_EL1t	0x00000004
-#define PSR_MODE_EL1h	0x00000005
-#define PSR_MODE_EL2t	0x00000008
-#define PSR_MODE_EL2h	0x00000009
-#define PSR_MODE_EL3t	0x0000000c
-#define PSR_MODE_EL3h	0x0000000d
-#define PSR_MODE_MASK	0x0000000f
-
-/* AArch32 CPSR bits */
-#define PSR_MODE32_BIT		0x00000010
-#ifdef __KERNEL__
 #define COMPAT_PSR_MODE_USR	0x00000010
 #define COMPAT_PSR_T_BIT	0x00000020
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
-#endif
-
-/* AArch64 SPSR bits */
-#define PSR_F_BIT	0x00000040
-#define PSR_I_BIT	0x00000080
-#define PSR_A_BIT	0x00000100
-#define PSR_D_BIT	0x00000200
-#define PSR_Q_BIT	0x08000000
-#define PSR_V_BIT	0x10000000
-#define PSR_C_BIT	0x20000000
-#define PSR_Z_BIT	0x40000000
-#define PSR_N_BIT	0x80000000
-
-/*
- * Groups of PSR bits
- */
-#define PSR_f		0xff000000	/* Flags		*/
-#define PSR_s		0x00ff0000	/* Status		*/
-#define PSR_x		0x0000ff00	/* Extension		*/
-#define PSR_c		0x000000ff	/* Control		*/
-
-#ifdef __KERNEL__
 /*
  * These are 'magic' values for PTRACE_PEEKUSR that return info about where a
  * process is located in memory.
@@ -82,36 +40,8 @@
 #define COMPAT_PT_TEXT_ADDR		0x10000
 #define COMPAT_PT_DATA_ADDR		0x10004
 #define COMPAT_PT_TEXT_END_ADDR		0x10008
-#endif
-
 #ifndef __ASSEMBLY__
 
-/*
- * User structures for general purpose, floating point and debug registers.
- */
-struct user_pt_regs {
-	__u64		regs[31];
-	__u64		sp;
-	__u64		pc;
-	__u64		pstate;
-};
-
-struct user_fpsimd_state {
-	__uint128_t	vregs[32];
-	__u32		fpsr;
-	__u32		fpcr;
-};
-
-struct user_hwdebug_state {
-	__u32		dbg_info;
-	struct {
-		__u64	addr;
-		__u32	ctrl;
-	}		dbg_regs[16];
-};
-
-#ifdef __KERNEL__
-
 /* sizeof(struct user) for AArch32 */
 #define COMPAT_USER_SZ	296
 /* AArch32 uses x13 as the stack pointer... */
@@ -206,8 +136,5 @@ extern unsigned long profile_pc(struct pt_regs *regs);
 
 extern int aarch32_break_trap(struct pt_regs *regs);
 
-#endif /* __KERNEL__ */
-
 #endif /* __ASSEMBLY__ */
-
 #endif

commit 7606c37d4a447ea3b0efb2165d3ccf516b7d8696
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Wed Oct 10 15:50:03 2012 +0100

    arm64: Do not export the compat-specific definitions to the user
    
    This patch adds #ifdef __KERNEL__ guards around the COMPAT_* definitions
    to avoid exporting them to user. AArch32 user requiring the kernel
    headers must use those generated with ARCH=arm.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index 0fa5d6c9ef76..fc2772a27c78 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -23,6 +23,7 @@
 
 #include <asm/hwcap.h>
 
+#ifdef __KERNEL__
 /* AArch32-specific ptrace requests */
 #define COMPAT_PTRACE_GETREGS		12
 #define COMPAT_PTRACE_SETREGS		13
@@ -32,6 +33,7 @@
 #define COMPAT_PTRACE_SETVFPREGS	28
 #define COMPAT_PTRACE_GETHBPREGS	29
 #define COMPAT_PTRACE_SETHBPREGS	30
+#endif
 
 /*
  * PSR bits
@@ -47,9 +49,11 @@
 
 /* AArch32 CPSR bits */
 #define PSR_MODE32_BIT		0x00000010
+#ifdef __KERNEL__
 #define COMPAT_PSR_MODE_USR	0x00000010
 #define COMPAT_PSR_T_BIT	0x00000020
 #define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
+#endif
 
 /* AArch64 SPSR bits */
 #define PSR_F_BIT	0x00000040
@@ -70,13 +74,15 @@
 #define PSR_x		0x0000ff00	/* Extension		*/
 #define PSR_c		0x000000ff	/* Control		*/
 
+#ifdef __KERNEL__
 /*
  * These are 'magic' values for PTRACE_PEEKUSR that return info about where a
  * process is located in memory.
  */
-#define PT_TEXT_ADDR		0x10000
-#define PT_DATA_ADDR		0x10004
-#define PT_TEXT_END_ADDR	0x10008
+#define COMPAT_PT_TEXT_ADDR		0x10000
+#define COMPAT_PT_DATA_ADDR		0x10004
+#define COMPAT_PT_TEXT_END_ADDR		0x10008
+#endif
 
 #ifndef __ASSEMBLY__
 

commit 27aa55c5e5123fa8b8ad0156559d34d7edff58ca
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Sep 27 11:38:12 2012 +0100

    arm64: ptrace: remove obsolete ptrace request numbers from user headers
    
    The use of regsets has removed the need for many private ptrace requests,
    so remove the corresponding definitions from the user-visible ptrace.h
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
index b0a2e1f441fb..0fa5d6c9ef76 100644
--- a/arch/arm64/include/asm/ptrace.h
+++ b/arch/arm64/include/asm/ptrace.h
@@ -23,20 +23,15 @@
 
 #include <asm/hwcap.h>
 
-#define PTRACE_GETREGS		12
-#define PTRACE_SETREGS		13
-#define PTRACE_GETFPSIMDREGS	14
-#define PTRACE_SETFPSIMDREGS	15
-/* PTRACE_ATTACH is 16 */
-/* PTRACE_DETACH is 17 */
-#define PTRACE_GET_THREAD_AREA	22
-#define PTRACE_SET_SYSCALL	23
-#define PTRACE_GETHBPREGS	29
-#define PTRACE_SETHBPREGS	30
-
 /* AArch32-specific ptrace requests */
+#define COMPAT_PTRACE_GETREGS		12
+#define COMPAT_PTRACE_SETREGS		13
+#define COMPAT_PTRACE_GET_THREAD_AREA	22
+#define COMPAT_PTRACE_SET_SYSCALL	23
 #define COMPAT_PTRACE_GETVFPREGS	27
 #define COMPAT_PTRACE_SETVFPREGS	28
+#define COMPAT_PTRACE_GETHBPREGS	29
+#define COMPAT_PTRACE_SETHBPREGS	30
 
 /*
  * PSR bits

commit 60ffc30d5652810dd34ea2eec41504222f5d5791
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Mar 5 11:49:27 2012 +0000

    arm64: Exception handling
    
    The patch contains the exception entry code (kernel/entry.S), pt_regs
    structure and related accessors, undefined instruction trapping and
    stack tracing.
    
    AArch64 Linux kernel (including kernel threads) runs in EL1 mode using
    the SP1 stack. The vectors don't have a fixed address, only alignment
    (2^11) requirements.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/include/asm/ptrace.h b/arch/arm64/include/asm/ptrace.h
new file mode 100644
index 000000000000..b0a2e1f441fb
--- /dev/null
+++ b/arch/arm64/include/asm/ptrace.h
@@ -0,0 +1,212 @@
+/*
+ * Based on arch/arm/include/asm/ptrace.h
+ *
+ * Copyright (C) 1996-2003 Russell King
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __ASM_PTRACE_H
+#define __ASM_PTRACE_H
+
+#include <linux/types.h>
+
+#include <asm/hwcap.h>
+
+#define PTRACE_GETREGS		12
+#define PTRACE_SETREGS		13
+#define PTRACE_GETFPSIMDREGS	14
+#define PTRACE_SETFPSIMDREGS	15
+/* PTRACE_ATTACH is 16 */
+/* PTRACE_DETACH is 17 */
+#define PTRACE_GET_THREAD_AREA	22
+#define PTRACE_SET_SYSCALL	23
+#define PTRACE_GETHBPREGS	29
+#define PTRACE_SETHBPREGS	30
+
+/* AArch32-specific ptrace requests */
+#define COMPAT_PTRACE_GETVFPREGS	27
+#define COMPAT_PTRACE_SETVFPREGS	28
+
+/*
+ * PSR bits
+ */
+#define PSR_MODE_EL0t	0x00000000
+#define PSR_MODE_EL1t	0x00000004
+#define PSR_MODE_EL1h	0x00000005
+#define PSR_MODE_EL2t	0x00000008
+#define PSR_MODE_EL2h	0x00000009
+#define PSR_MODE_EL3t	0x0000000c
+#define PSR_MODE_EL3h	0x0000000d
+#define PSR_MODE_MASK	0x0000000f
+
+/* AArch32 CPSR bits */
+#define PSR_MODE32_BIT		0x00000010
+#define COMPAT_PSR_MODE_USR	0x00000010
+#define COMPAT_PSR_T_BIT	0x00000020
+#define COMPAT_PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
+
+/* AArch64 SPSR bits */
+#define PSR_F_BIT	0x00000040
+#define PSR_I_BIT	0x00000080
+#define PSR_A_BIT	0x00000100
+#define PSR_D_BIT	0x00000200
+#define PSR_Q_BIT	0x08000000
+#define PSR_V_BIT	0x10000000
+#define PSR_C_BIT	0x20000000
+#define PSR_Z_BIT	0x40000000
+#define PSR_N_BIT	0x80000000
+
+/*
+ * Groups of PSR bits
+ */
+#define PSR_f		0xff000000	/* Flags		*/
+#define PSR_s		0x00ff0000	/* Status		*/
+#define PSR_x		0x0000ff00	/* Extension		*/
+#define PSR_c		0x000000ff	/* Control		*/
+
+/*
+ * These are 'magic' values for PTRACE_PEEKUSR that return info about where a
+ * process is located in memory.
+ */
+#define PT_TEXT_ADDR		0x10000
+#define PT_DATA_ADDR		0x10004
+#define PT_TEXT_END_ADDR	0x10008
+
+#ifndef __ASSEMBLY__
+
+/*
+ * User structures for general purpose, floating point and debug registers.
+ */
+struct user_pt_regs {
+	__u64		regs[31];
+	__u64		sp;
+	__u64		pc;
+	__u64		pstate;
+};
+
+struct user_fpsimd_state {
+	__uint128_t	vregs[32];
+	__u32		fpsr;
+	__u32		fpcr;
+};
+
+struct user_hwdebug_state {
+	__u32		dbg_info;
+	struct {
+		__u64	addr;
+		__u32	ctrl;
+	}		dbg_regs[16];
+};
+
+#ifdef __KERNEL__
+
+/* sizeof(struct user) for AArch32 */
+#define COMPAT_USER_SZ	296
+/* AArch32 uses x13 as the stack pointer... */
+#define compat_sp	regs[13]
+/* ... and x14 as the link register. */
+#define compat_lr	regs[14]
+
+/*
+ * This struct defines the way the registers are stored on the stack during an
+ * exception. Note that sizeof(struct pt_regs) has to be a multiple of 16 (for
+ * stack alignment). struct user_pt_regs must form a prefix of struct pt_regs.
+ */
+struct pt_regs {
+	union {
+		struct user_pt_regs user_regs;
+		struct {
+			u64 regs[31];
+			u64 sp;
+			u64 pc;
+			u64 pstate;
+		};
+	};
+	u64 orig_x0;
+	u64 syscallno;
+};
+
+#define arch_has_single_step()	(1)
+
+#ifdef CONFIG_COMPAT
+#define compat_thumb_mode(regs) \
+	(((regs)->pstate & COMPAT_PSR_T_BIT))
+#else
+#define compat_thumb_mode(regs) (0)
+#endif
+
+#define user_mode(regs)	\
+	(((regs)->pstate & PSR_MODE_MASK) == PSR_MODE_EL0t)
+
+#define compat_user_mode(regs)	\
+	(((regs)->pstate & (PSR_MODE32_BIT | PSR_MODE_MASK)) == \
+	 (PSR_MODE32_BIT | PSR_MODE_EL0t))
+
+#define processor_mode(regs) \
+	((regs)->pstate & PSR_MODE_MASK)
+
+#define interrupts_enabled(regs) \
+	(!((regs)->pstate & PSR_I_BIT))
+
+#define fast_interrupts_enabled(regs) \
+	(!((regs)->pstate & PSR_F_BIT))
+
+#define user_stack_pointer(regs) \
+	((regs)->sp)
+
+/*
+ * Are the current registers suitable for user mode? (used to maintain
+ * security in signal handlers)
+ */
+static inline int valid_user_regs(struct user_pt_regs *regs)
+{
+	if (user_mode(regs) && (regs->pstate & PSR_I_BIT) == 0) {
+		regs->pstate &= ~(PSR_F_BIT | PSR_A_BIT);
+
+		/* The T bit is reserved for AArch64 */
+		if (!(regs->pstate & PSR_MODE32_BIT))
+			regs->pstate &= ~COMPAT_PSR_T_BIT;
+
+		return 1;
+	}
+
+	/*
+	 * Force PSR to something logical...
+	 */
+	regs->pstate &= PSR_f | PSR_s | (PSR_x & ~PSR_A_BIT) | \
+			COMPAT_PSR_T_BIT | PSR_MODE32_BIT;
+
+	if (!(regs->pstate & PSR_MODE32_BIT)) {
+		regs->pstate &= ~COMPAT_PSR_T_BIT;
+		regs->pstate |= PSR_MODE_EL0t;
+	}
+
+	return 0;
+}
+
+#define instruction_pointer(regs)	(regs)->pc
+
+#ifdef CONFIG_SMP
+extern unsigned long profile_pc(struct pt_regs *regs);
+#else
+#define profile_pc(regs) instruction_pointer(regs)
+#endif
+
+extern int aarch32_break_trap(struct pt_regs *regs);
+
+#endif /* __KERNEL__ */
+
+#endif /* __ASSEMBLY__ */
+
+#endif
