commit b6e43c0e3129ffe87e65c85f20fcbdf0eb86fba0
Author: James Morse <james.morse@arm.com>
Date:   Fri Oct 25 17:42:10 2019 +0100

    arm64: remove __exception annotations
    
    Since commit 732674980139 ("arm64: unwind: reference pt_regs via embedded
    stack frame") arm64 has not used the __exception annotation to dump
    the pt_regs during stack tracing. in_exception_text() has no callers.
    
    This annotation is only used to blacklist kprobes, it means the same as
    __kprobes.
    
    Section annotations like this require the functions to be grouped
    together between the start/end markers, and placed according to
    the linker script. For kprobes we also have NOKPROBE_SYMBOL() which
    logs the symbol address in a section that kprobes parses and
    blacklists at boot.
    
    Using NOKPROBE_SYMBOL() instead lets kprobes publish the list of
    blacklisted symbols, and saves us from having an arm64 specific
    spelling of __kprobes.
    
    do_debug_exception() already has a NOKPROBE_SYMBOL() annotation.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 59690613ac31..cee5928e1b7d 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -42,16 +42,6 @@ static inline int __in_irqentry_text(unsigned long ptr)
 	       ptr < (unsigned long)&__irqentry_text_end;
 }
 
-static inline int in_exception_text(unsigned long ptr)
-{
-	int in;
-
-	in = ptr >= (unsigned long)&__exception_text_start &&
-	     ptr < (unsigned long)&__exception_text_end;
-
-	return in ? : __in_irqentry_text(ptr);
-}
-
 static inline int in_entry_text(unsigned long ptr)
 {
 	return ptr >= (unsigned long)&__entry_text_start &&

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index f9c1aa6167d2..59690613ac31 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -1,19 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Based on arch/arm/include/asm/traps.h
  *
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __ASM_TRAP_H
 #define __ASM_TRAP_H

commit f3a900b34101bb8df10b83f326b3af796c101a05
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Sep 22 10:52:41 2018 +0200

    signal/arm64: Add and use arm64_force_sig_ptrace_errno_trap
    
    Add arm64_force_sig_ptrace_errno_trap for consistency with
    arm64_force_sig_fault and use it where appropriate.
    
    This adds the show_signal logic to the force_sig_errno_trap case,
    where it was apparently overlooked earlier.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index d32b8bd440af..f9c1aa6167d2 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -39,6 +39,7 @@ void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
 void arm64_force_sig_fault(int signo, int code, void __user *addr, const char *str);
 void arm64_force_sig_mceerr(int code, void __user *addr, short lsb, const char *str);
+void arm64_force_sig_ptrace_errno_trap(int errno, void __user *addr, const char *str);
 
 /*
  * Move regs->pc to next instruction and do necessary setup before it

commit 009f608ab20a25d01a07e9e75e7d246e81252eb8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Sep 22 10:43:01 2018 +0200

    signal/arm64: Remove arm64_force_sig_info
    
    The function has no more callers so remove it.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 193f0b0e8ee3..d32b8bd440af 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -39,7 +39,6 @@ void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
 void arm64_force_sig_fault(int signo, int code, void __user *addr, const char *str);
 void arm64_force_sig_mceerr(int code, void __user *addr, short lsb, const char *str);
-void arm64_force_sig_info(struct siginfo *info, const char *str);
 
 /*
  * Move regs->pc to next instruction and do necessary setup before it

commit b4d5557caa07a01796ca8a2d756eeaa5308f6876
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Sep 22 10:37:15 2018 +0200

    signal/arm64: Add and use arm64_force_sig_mceerr as appropriate
    
    Add arm64_force_sig_mceerr for consistency with arm64_force_sig_fault,
    and use it in the one location that can take advantage of it.
    
    This removes the fiddly filling out of siginfo before sending a signal
    reporting an memory error to userspace.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 08e99901edbc..193f0b0e8ee3 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -38,6 +38,7 @@ void unregister_undef_hook(struct undef_hook *hook);
 void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
 void arm64_force_sig_fault(int signo, int code, void __user *addr, const char *str);
+void arm64_force_sig_mceerr(int code, void __user *addr, short lsb, const char *str);
 void arm64_force_sig_info(struct siginfo *info, const char *str);
 
 /*

commit feca355b3d8eba3a2cbca63c97a59a14681983f7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Sep 22 10:26:57 2018 +0200

    signal/arm64: Add and use arm64_force_sig_fault where appropriate
    
    Wrap force_sig_fault with a helper that calls arm64_show_signal
    and call arm64_force_sig_fault where appropraite.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index cd3a2ca9c179..08e99901edbc 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -37,6 +37,7 @@ void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
 void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
+void arm64_force_sig_fault(int signo, int code, void __user *addr, const char *str);
 void arm64_force_sig_info(struct siginfo *info, const char *str);
 
 /*

commit 24b8f79dd8e036da618d158b4c0295208d478c5c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Sep 22 00:38:41 2018 +0200

    signal/arm64: Remove unneeded tsk parameter from arm64_force_sig_info
    
    Every caller passes in current for tsk so there is no need to pass
    tsk.  Instead make tsk a local variable initialized to current.
    
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Tested-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index c320f3bf6c57..cd3a2ca9c179 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -37,8 +37,7 @@ void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
 void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
-void arm64_force_sig_info(struct siginfo *info, const char *str,
-			  struct task_struct *tsk);
+void arm64_force_sig_info(struct siginfo *info, const char *str);
 
 /*
  * Move regs->pc to next instruction and do necessary setup before it

commit a1ece8216c41c9dbb4040f7b8b3fbcd17662c665
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 20 13:46:05 2018 +0000

    arm64: Introduce arm64_force_sig_info and hook up in arm64_notify_die
    
    In preparation for consolidating our handling of printing unhandled
    signals, introduce a wrapper around force_sig_info which can act as
    the canonical place for dealing with show_unhandled_signals.
    
    Initially, we just hook this up to arm64_notify_die.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 1ee63dc38579..c320f3bf6c57 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -37,6 +37,8 @@ void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
 void force_signal_inject(int signal, int code, unsigned long address);
 void arm64_notify_segfault(unsigned long addr);
+void arm64_force_sig_info(struct siginfo *info, const char *str,
+			  struct task_struct *tsk);
 
 /*
  * Move regs->pc to next instruction and do necessary setup before it

commit 2c9120f3a86a809518ece1787d76ae07dd01e01b
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 20 14:16:29 2018 +0000

    arm64: signal: Make force_signal_inject more robust
    
    force_signal_inject is a little flakey:
    
      * It only knows about SIGILL and SIGSEGV, so can potentially deliver
        other signals based on a partially initialised siginfo_t
    
      * It sets si_addr to point at the PC for SIGSEGV
    
      * It always operates on current, so doesn't need the regs argument
    
    This patch fixes these issues by always assigning the si_addr field to
    the address parameter of the function and updates the callers (including
    those that indirectly call via arm64_notify_segfault) accordingly.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 178e338d2889..1ee63dc38579 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -35,10 +35,8 @@ struct undef_hook {
 
 void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
-void force_signal_inject(int signal, int code, struct pt_regs *regs,
-			 unsigned long address);
-
-void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
+void force_signal_inject(int signal, int code, unsigned long address);
+void arm64_notify_segfault(unsigned long addr);
 
 /*
  * Move regs->pc to next instruction and do necessary setup before it

commit 6bf0dcfd713563bd2e13ceb53217305c28a8aa5f
Author: James Morse <james.morse@arm.com>
Date:   Mon Jan 15 19:38:57 2018 +0000

    arm64: kernel: Survive corrected RAS errors notified by SError
    
    Prior to v8.2, SError is an uncontainable fatal exception. The v8.2 RAS
    extensions use SError to notify software about RAS errors, these can be
    contained by the Error Syncronization Barrier.
    
    An ACPI system with firmware-first may use SError as its 'SEI'
    notification. Future patches may add code to 'claim' this SError as a
    notification.
    
    Other systems can distinguish these RAS errors from the SError ESR and
    use the AET bits and additional data from RAS-Error registers to handle
    the error. Future patches may add this kernel-first handling.
    
    Without support for either of these we will panic(), even if we received
    a corrected error. Add code to decode the severity of RAS errors. We can
    safely ignore contained errors where the CPU can continue to make
    progress. For all other errors we continue to panic().
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 1696f9de9359..178e338d2889 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -19,6 +19,7 @@
 #define __ASM_TRAP_H
 
 #include <linux/list.h>
+#include <asm/esr.h>
 #include <asm/sections.h>
 
 struct pt_regs;
@@ -66,4 +67,57 @@ static inline int in_entry_text(unsigned long ptr)
 	return ptr >= (unsigned long)&__entry_text_start &&
 	       ptr < (unsigned long)&__entry_text_end;
 }
+
+/*
+ * CPUs with the RAS extensions have an Implementation-Defined-Syndrome bit
+ * to indicate whether this ESR has a RAS encoding. CPUs without this feature
+ * have a ISS-Valid bit in the same position.
+ * If this bit is set, we know its not a RAS SError.
+ * If its clear, we need to know if the CPU supports RAS. Uncategorized RAS
+ * errors share the same encoding as an all-zeros encoding from a CPU that
+ * doesn't support RAS.
+ */
+static inline bool arm64_is_ras_serror(u32 esr)
+{
+	WARN_ON(preemptible());
+
+	if (esr & ESR_ELx_IDS)
+		return false;
+
+	if (this_cpu_has_cap(ARM64_HAS_RAS_EXTN))
+		return true;
+	else
+		return false;
+}
+
+/*
+ * Return the AET bits from a RAS SError's ESR.
+ *
+ * It is implementation defined whether Uncategorized errors are containable.
+ * We treat them as Uncontainable.
+ * Non-RAS SError's are reported as Uncontained/Uncategorized.
+ */
+static inline u32 arm64_ras_serror_get_severity(u32 esr)
+{
+	u32 aet = esr & ESR_ELx_AET;
+
+	if (!arm64_is_ras_serror(esr)) {
+		/* Not a RAS error, we can't interpret the ESR. */
+		return ESR_ELx_AET_UC;
+	}
+
+	/*
+	 * AET is RES0 if 'the value returned in the DFSC field is not
+	 * [ESR_ELx_FSC_SERROR]'
+	 */
+	if ((esr & ESR_ELx_FSC) != ESR_ELx_FSC_SERROR) {
+		/* No severity information : Uncategorized */
+		return ESR_ELx_AET_UC;
+	}
+
+	return aet;
+}
+
+bool arm64_is_fatal_ras_serror(struct pt_regs *regs, unsigned int esr);
+void __noreturn arm64_serror_panic(struct pt_regs *regs, u32 esr);
 #endif

commit bc0ee476036478a85beeed51f0d94c8729fd0544
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Tue Oct 31 15:51:05 2017 +0000

    arm64/sve: Core task context handling
    
    This patch adds the core support for switching and managing the SVE
    architectural state of user tasks.
    
    Calls to the existing FPSIMD low-level save/restore functions are
    factored out as new functions task_fpsimd_{save,load}(), since SVE
    now dynamically may or may not need to be handled at these points
    depending on the kernel configuration, hardware features discovered
    at boot, and the runtime state of the task.  To make these
    decisions as fast as possible, const cpucaps are used where
    feasible, via the system_supports_sve() helper.
    
    The SVE registers are only tracked for threads that have explicitly
    used SVE, indicated by the new thread flag TIF_SVE.  Otherwise, the
    FPSIMD view of the architectural state is stored in
    thread.fpsimd_state as usual.
    
    When in use, the SVE registers are not stored directly in
    thread_struct due to their potentially large and variable size.
    Because the task_struct slab allocator must be configured very
    early during kernel boot, it is also tricky to configure it
    correctly to match the maximum vector length provided by the
    hardware, since this depends on examining secondary CPUs as well as
    the primary.  Instead, a pointer sve_state in thread_struct points
    to a dynamically allocated buffer containing the SVE register data,
    and code is added to allocate and free this buffer at appropriate
    times.
    
    TIF_SVE is set when taking an SVE access trap from userspace, if
    suitable hardware support has been detected.  This enables SVE for
    the thread: a subsequent return to userspace will disable the trap
    accordingly.  If such a trap is taken without sufficient system-
    wide hardware support, SIGILL is sent to the thread instead as if
    an undefined instruction had been executed: this may happen if
    userspace tries to use SVE in a system where not all CPUs support
    it for example.
    
    The kernel will clear TIF_SVE and disable SVE for the thread
    whenever an explicit syscall is made by userspace.  For backwards
    compatibility reasons and conformance with the spirit of the base
    AArch64 procedure call standard, the subset of the SVE register
    state that aliases the FPSIMD registers is still preserved across a
    syscall even if this happens.  The remainder of the SVE register
    state logically becomes zero at syscall entry, though the actual
    zeroing work is currently deferred until the thread next tries to
    use SVE, causing another trap to the kernel.  This implementation
    is suboptimal: in the future, the fastpath case may be optimised
    to zero the registers in-place and leave SVE enabled for the task,
    where beneficial.
    
    TIF_SVE is also cleared in the following slowpath cases, which are
    taken as reasonable hints that the task may no longer use SVE:
     * exec
     * fork and clone
    
    Code is added to sync data between thread.fpsimd_state and
    thread.sve_state whenever enabling/disabling SVE, in a manner
    consistent with the SVE architectural programmer's model.
    
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Alex Bennée <alex.bennee@linaro.org>
    [will: added #include to fix allnoconfig build]
    [will: use enable_daif in do_sve_acc]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 45e3da34bdc4..1696f9de9359 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -34,6 +34,8 @@ struct undef_hook {
 
 void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
+void force_signal_inject(int signal, int code, struct pt_regs *regs,
+			 unsigned long address);
 
 void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
 

commit 6436beeee5721a8e906e9eabf866f12d04470437
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Wed Oct 25 10:04:33 2017 +0100

    arm64: Fix single stepping in kernel traps
    
    Software Step exception is missing after stepping a trapped instruction.
    
    Ensure SPSR.SS gets set to 0 after emulating/skipping a trapped instruction
    before doing ERET.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Alex Bennée <alex.bennee@linaro.org>
    [will: replaced AARCH32_INSN_SIZE with 4]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index d131501c6222..45e3da34bdc4 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -37,6 +37,12 @@ void unregister_undef_hook(struct undef_hook *hook);
 
 void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
 
+/*
+ * Move regs->pc to next instruction and do necessary setup before it
+ * is executed.
+ */
+void arm64_skip_faulting_instruction(struct pt_regs *regs, unsigned long size);
+
 static inline int __in_irqentry_text(unsigned long ptr)
 {
 	return ptr >= (unsigned long)&__irqentry_text_start &&

commit 04759194dc447ff0b9ef35bc641ce3bb076c2930
Merge: 9e85ae6af6e9 d1be5c99a034
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 5 09:53:37 2017 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - VMAP_STACK support, allowing the kernel stacks to be allocated in the
       vmalloc space with a guard page for trapping stack overflows. One of
       the patches introduces THREAD_ALIGN and changes the generic
       alloc_thread_stack_node() to use this instead of THREAD_SIZE (no
       functional change for other architectures)
    
     - Contiguous PTE hugetlb support re-enabled (after being reverted a
       couple of times). We now have the semantics agreed in the generic mm
       layer together with API improvements so that the architecture code
       can detect between contiguous and non-contiguous huge PTEs
    
     - Initial support for persistent memory on ARM: DC CVAP instruction
       exposed to user space (HWCAP) and the in-kernel pmem API implemented
    
     - raid6 improvements for arm64: faster algorithm for the delta syndrome
       and implementation of the recovery routines using Neon
    
     - FP/SIMD refactoring and removal of support for Neon in interrupt
       context. This is in preparation for full SVE support
    
     - PTE accessors converted from inline asm to cmpxchg so that we can use
       LSE atomics if available (ARMv8.1)
    
     - Perf support for Cortex-A35 and A73
    
     - Non-urgent fixes and cleanups
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (75 commits)
      arm64: cleanup {COMPAT_,}SET_PERSONALITY() macro
      arm64: introduce separated bits for mm_context_t flags
      arm64: hugetlb: Cleanup setup_hugepagesz
      arm64: Re-enable support for contiguous hugepages
      arm64: hugetlb: Override set_huge_swap_pte_at() to support contiguous hugepages
      arm64: hugetlb: Override huge_pte_clear() to support contiguous hugepages
      arm64: hugetlb: Handle swap entries in huge_pte_offset() for contiguous hugepages
      arm64: hugetlb: Add break-before-make logic for contiguous entries
      arm64: hugetlb: Spring clean huge pte accessors
      arm64: hugetlb: Introduce pte_pgprot helper
      arm64: hugetlb: set_huge_pte_at Add WARN_ON on !pte_present
      arm64: kexec: have own crash_smp_send_stop() for crash dump for nonpanic cores
      arm64: dma-mapping: Mark atomic_pool as __ro_after_init
      arm64: dma-mapping: Do not pass data to gen_pool_set_algo()
      arm64: Remove the !CONFIG_ARM64_HW_AFDBM alternative code paths
      arm64: Ignore hardware dirty bit updates in ptep_set_wrprotect()
      arm64: Move PTE_RDONLY bit handling out of set_pte_at()
      kvm: arm64: Convert kvm_set_s2pte_readonly() from inline asm to cmpxchg()
      arm64: Convert pte handling from inline asm to using (cmp)xchg
      arm64: neon/efi: Make EFI fpsimd save/restore variables static
      ...

commit 229a71860547ec856b156179a9c6bef2de426f66
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Thu Aug 3 11:38:21 2017 +0900

    irq: Make the irqentry text section unconditional
    
    Generate irqentry and softirqentry text sections without
    any Kconfig dependencies. This will add extra sections, but
    there should be no performace impact.
    
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David S . Miller <davem@davemloft.net>
    Cc: Francis Deslauriers <francis.deslauriers@efficios.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-cris-kernel@axis.com
    Cc: mathieu.desnoyers@efficios.com
    Link: http://lkml.kernel.org/r/150172789110.27216.3955739126693102122.stgit@devbox
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 02e9035b0685..47a9066f7c86 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -37,18 +37,11 @@ void unregister_undef_hook(struct undef_hook *hook);
 
 void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
 
-#ifdef CONFIG_FUNCTION_GRAPH_TRACER
 static inline int __in_irqentry_text(unsigned long ptr)
 {
 	return ptr >= (unsigned long)&__irqentry_text_start &&
 	       ptr < (unsigned long)&__irqentry_text_end;
 }
-#else
-static inline int __in_irqentry_text(unsigned long ptr)
-{
-	return 0;
-}
-#endif
 
 static inline int in_exception_text(unsigned long ptr)
 {

commit 7326749801396105aef0ed9229df746ac9e24300
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Sat Jul 22 18:45:33 2017 +0100

    arm64: unwind: reference pt_regs via embedded stack frame
    
    As it turns out, the unwind code is slightly broken, and probably has
    been for a while. The problem is in the dumping of the exception stack,
    which is intended to dump the contents of the pt_regs struct at each
    level in the call stack where an exception was taken and routed to a
    routine marked as __exception (which means its stack frame is right
    below the pt_regs struct on the stack).
    
    'Right below the pt_regs struct' is ill defined, though: the unwind
    code assigns 'frame pointer + 0x10' to the .sp member of the stackframe
    struct at each level, and dump_backtrace() happily dereferences that as
    the pt_regs pointer when encountering an __exception routine. However,
    the actual size of the stack frame created by this routine (which could
    be one of many __exception routines we have in the kernel) is not known,
    and so frame.sp is pretty useless to figure out where struct pt_regs
    really is.
    
    So it seems the only way to ensure that we can find our struct pt_regs
    when walking the stack frames is to put it at a known fixed offset of
    the stack frame pointer that is passed to such __exception routines.
    The simplest way to do that is to put it inside pt_regs itself, which is
    the main change implemented by this patch. As a bonus, doing this allows
    us to get rid of a fair amount of cruft related to walking from one stack
    to the other, which is especially nice since we intend to introduce yet
    another stack for overflow handling once we add support for vmapped
    stacks. It also fixes an inconsistency where we only add a stack frame
    pointing to ELR_EL1 if we are executing from the IRQ stack but not when
    we are executing from the task stack.
    
    To consistly identify exceptions regs even in the presence of exceptions
    taken from entry code, we must check whether the next frame was created
    by entry text, rather than whether the current frame was crated by
    exception text.
    
    To avoid backtracing using PCs that fall in the idmap, or are controlled
    by userspace, we must explcitly zero the FP and LR in startup paths, and
    must ensure that the frame embedded in pt_regs is zeroed upon entry from
    EL0. To avoid these NULL entries showin in the backtrace, unwind_frame()
    is updated to avoid them.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    [Mark: compare current frame against .entry.text, avoid bogus PCs]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 02e9035b0685..41361684580d 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -60,4 +60,9 @@ static inline int in_exception_text(unsigned long ptr)
 	return in ? : __in_irqentry_text(ptr);
 }
 
+static inline int in_entry_text(unsigned long ptr)
+{
+	return ptr >= (unsigned long)&__entry_text_start &&
+	       ptr < (unsigned long)&__entry_text_end;
+}
 #endif

commit ee78fdc71db1ce9a437b9ca17e31063996b71ec1
Author: James Morse <james.morse@arm.com>
Date:   Wed Aug 24 18:27:28 2016 +0100

    arm64: Create sections.h
    
    Each time new section markers are added, kernel/vmlinux.ld.S is updated,
    and new extern char __start_foo[] definitions are scattered through the
    tree.
    
    Create asm/include/sections.h to collect these definitions (and include
    the existing asm-generic version).
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 9cd03f3e812f..02e9035b0685 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -19,6 +19,7 @@
 #define __ASM_TRAP_H
 
 #include <linux/list.h>
+#include <asm/sections.h>
 
 struct pt_regs;
 
@@ -39,9 +40,6 @@ void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 static inline int __in_irqentry_text(unsigned long ptr)
 {
-	extern char __irqentry_text_start[];
-	extern char __irqentry_text_end[];
-
 	return ptr >= (unsigned long)&__irqentry_text_start &&
 	       ptr < (unsigned long)&__irqentry_text_end;
 }
@@ -54,8 +52,6 @@ static inline int __in_irqentry_text(unsigned long ptr)
 
 static inline int in_exception_text(unsigned long ptr)
 {
-	extern char __exception_text_start[];
-	extern char __exception_text_end[];
 	int in;
 
 	in = ptr >= (unsigned long)&__exception_text_start &&

commit 390bf1773c7eba3b45df62ae82b3d2be911185b7
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Tue Jun 28 18:07:31 2016 +0100

    arm64: consolidate signal injection on emulation errors
    
    The code for injecting a signal into userland if a trapped instruction
    fails emulation due to a _userland_ error (like an illegal address)
    will be used more often with the next patch.
    Factor out the core functionality into a separate function and use
    that both for the existing trap handler and for the deprecated
    instructions emulation.
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    [catalin.marinas@arm.com: s/set_segfault/arm64_notify_segfault/]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 0cc2f29bf9da..9cd03f3e812f 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -34,6 +34,8 @@ struct undef_hook {
 void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
 
+void arm64_notify_segfault(struct pt_regs *regs, unsigned long addr);
+
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 static inline int __in_irqentry_text(unsigned long ptr)
 {

commit 9a5ad7d0e3e1c6c0c11df89fbc5376f8aaf7a90f
Author: Jungseok Lee <jungseoklee85@gmail.com>
Date:   Wed Aug 12 15:16:19 2015 +0100

    arm64: Add __exception_irq_entry definition for function graph
    
    The gic_handle_irq() is defined with __exception_irq_entry attribute.
    A single remaining work is to add its definition as ARM did. Below
    shows how function graph data is changed with these hunks.
    
    A prologue of an interrupt handler is drawn as follows.
    
    - current status
    
     0)   0.208 us    |  cpuidle_not_available();
     0)               |  default_idle_call() {
     0)               |    arch_cpu_idle() {
     0)               |      __handle_domain_irq() {
     0)               |        irq_enter() {
     0)   0.313 us    |          rcu_irq_enter();
     0)   0.261 us    |          __local_bh_disable_ip();
    
    - with this change
    
     0)   0.625 us    |  cpuidle_not_available();
     0)               |  default_idle_call() {
     0)               |    arch_cpu_idle() {
     0)   ==========> |
     0)               |      gic_handle_irq() {
     0)               |        __handle_domain_irq() {
     0)               |          irq_enter() {
     0)   0.885 us    |            rcu_irq_enter();
     0)   0.781 us    |            __local_bh_disable_ip();
    
    An epilogue of an interrupt handler is recorded as follows.
    
    - current status
    
     0)   0.261 us    |          idle_cpu();
     0)               |          rcu_irq_exit() {
     0)   0.521 us    |            rcu_eqs_enter_common.isra.46();
     0)   2.552 us    |          }
     0) ! 322.448 us  |        }
     0) ! 583.437 us  |      }
     0) # 1656.041 us |    }
     0) # 1658.073 us |  }
    
    - with this change
    
     0)   0.677 us    |            idle_cpu();
     0)               |            rcu_irq_exit() {
     0)   1.770 us    |              rcu_eqs_enter_common.isra.46();
     0)   7.968 us    |            }
     0) # 1803.541 us |          }
     0) # 2626.667 us |        }
     0) # 2632.969 us |      }
     0)   <========== |
     0) # 14425.00 us |    }
     0) # 14430.98 us |  }
    
    Cc: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Rabin Vincent <rabin@rab.in>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Jungseok Lee <jungseoklee85@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 232e4ba5d314..0cc2f29bf9da 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -34,13 +34,32 @@ struct undef_hook {
 void register_undef_hook(struct undef_hook *hook);
 void unregister_undef_hook(struct undef_hook *hook);
 
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+static inline int __in_irqentry_text(unsigned long ptr)
+{
+	extern char __irqentry_text_start[];
+	extern char __irqentry_text_end[];
+
+	return ptr >= (unsigned long)&__irqentry_text_start &&
+	       ptr < (unsigned long)&__irqentry_text_end;
+}
+#else
+static inline int __in_irqentry_text(unsigned long ptr)
+{
+	return 0;
+}
+#endif
+
 static inline int in_exception_text(unsigned long ptr)
 {
 	extern char __exception_text_start[];
 	extern char __exception_text_end[];
+	int in;
+
+	in = ptr >= (unsigned long)&__exception_text_start &&
+	     ptr < (unsigned long)&__exception_text_end;
 
-	return ptr >= (unsigned long)&__exception_text_start &&
-	       ptr < (unsigned long)&__exception_text_end;
+	return in ? : __in_irqentry_text(ptr);
 }
 
 #endif

commit 9b79f52d1a702dd5b160f9d2ee0199c3122809bb
Author: Punit Agrawal <punit.agrawal@arm.com>
Date:   Tue Nov 18 11:41:22 2014 +0000

    arm64: Add support for hooks to handle undefined instructions
    
    Add support to register hooks for undefined instructions. The handlers
    will be called when the undefined instruction and the processor state
    (as contained in pstate) match criteria used at registration.
    
    Signed-off-by: Punit Agrawal <punit.agrawal@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
index 10ca8ff93cc2..232e4ba5d314 100644
--- a/arch/arm64/include/asm/traps.h
+++ b/arch/arm64/include/asm/traps.h
@@ -18,6 +18,22 @@
 #ifndef __ASM_TRAP_H
 #define __ASM_TRAP_H
 
+#include <linux/list.h>
+
+struct pt_regs;
+
+struct undef_hook {
+	struct list_head node;
+	u32 instr_mask;
+	u32 instr_val;
+	u64 pstate_mask;
+	u64 pstate_val;
+	int (*fn)(struct pt_regs *regs, u32 instr);
+};
+
+void register_undef_hook(struct undef_hook *hook);
+void unregister_undef_hook(struct undef_hook *hook);
+
 static inline int in_exception_text(unsigned long ptr)
 {
 	extern char __exception_text_start[];

commit 60ffc30d5652810dd34ea2eec41504222f5d5791
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Mar 5 11:49:27 2012 +0000

    arm64: Exception handling
    
    The patch contains the exception entry code (kernel/entry.S), pt_regs
    structure and related accessors, undefined instruction trapping and
    stack tracing.
    
    AArch64 Linux kernel (including kernel threads) runs in EL1 mode using
    the SP1 stack. The vectors don't have a fixed address, only alignment
    (2^11) requirements.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arm64/include/asm/traps.h b/arch/arm64/include/asm/traps.h
new file mode 100644
index 000000000000..10ca8ff93cc2
--- /dev/null
+++ b/arch/arm64/include/asm/traps.h
@@ -0,0 +1,30 @@
+/*
+ * Based on arch/arm/include/asm/traps.h
+ *
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __ASM_TRAP_H
+#define __ASM_TRAP_H
+
+static inline int in_exception_text(unsigned long ptr)
+{
+	extern char __exception_text_start[];
+	extern char __exception_text_end[];
+
+	return ptr >= (unsigned long)&__exception_text_start &&
+	       ptr < (unsigned long)&__exception_text_end;
+}
+
+#endif
