commit f226650494c6aa87526d12135b7de8b8c074f3de
Author: Marc Zyngier <maz@kernel.org>
Date:   Wed Oct 2 10:06:12 2019 +0100

    arm64: Relax ICC_PMR_EL1 accesses when ICC_CTLR_EL1.PMHE is clear
    
    The GICv3 architecture specification is incredibly misleading when it
    comes to PMR and the requirement for a DSB. It turns out that this DSB
    is only required if the CPU interface sends an Upstream Control
    message to the redistributor in order to update the RD's view of PMR.
    
    This message is only sent when ICC_CTLR_EL1.PMHE is set, which isn't
    the case in Linux. It can still be set from EL3, so some special care
    is required. But the upshot is that in the (hopefuly large) majority
    of the cases, we can drop the DSB altogether.
    
    This relies on a new static key being set if the boot CPU has PMHE
    set. The drawback is that this static key has to be exported to
    modules.
    
    Cc: Will Deacon <will@kernel.org>
    Cc: James Morse <james.morse@arm.com>
    Cc: Julien Thierry <julien.thierry.kdev@gmail.com>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Marc Zyngier <maz@kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 1a59f0ed1ae3..aa4b6521ef14 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -6,6 +6,7 @@
 #define __ASM_IRQFLAGS_H
 
 #include <asm/alternative.h>
+#include <asm/barrier.h>
 #include <asm/ptrace.h>
 #include <asm/sysreg.h>
 
@@ -34,14 +35,14 @@ static inline void arch_local_irq_enable(void)
 	}
 
 	asm volatile(ALTERNATIVE(
-		"msr	daifclr, #2		// arch_local_irq_enable\n"
-		"nop",
-		__msr_s(SYS_ICC_PMR_EL1, "%0")
-		"dsb	sy",
+		"msr	daifclr, #2		// arch_local_irq_enable",
+		__msr_s(SYS_ICC_PMR_EL1, "%0"),
 		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
 		: "r" ((unsigned long) GIC_PRIO_IRQON)
 		: "memory");
+
+	pmr_sync();
 }
 
 static inline void arch_local_irq_disable(void)
@@ -116,14 +117,14 @@ static inline unsigned long arch_local_irq_save(void)
 static inline void arch_local_irq_restore(unsigned long flags)
 {
 	asm volatile(ALTERNATIVE(
-			"msr	daif, %0\n"
-			"nop",
-			__msr_s(SYS_ICC_PMR_EL1, "%0")
-			"dsb	sy",
-			ARM64_HAS_IRQ_PRIO_MASKING)
+		"msr	daif, %0",
+		__msr_s(SYS_ICC_PMR_EL1, "%0"),
+		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
 		: "r" (flags)
 		: "memory");
+
+	pmr_sync();
 }
 
 #endif /* __ASM_IRQFLAGS_H */

commit b907b80d7ae7b2b65ef9f534f3e9a32ce6a4b539
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Jul 8 17:36:40 2019 +0100

    arm64: remove pointless __KERNEL__ guards
    
    For a number of years, UAPI headers have been split from kernel-internal
    headers. The latter are never exposed to userspace, and always built
    with __KERNEL__ defined.
    
    Most headers under arch/arm64 don't have __KERNEL__ guards, but there
    are a few stragglers lying around. To make things more consistent, and
    to set a good example going forward, let's remove these redundant
    __KERNEL__ guards.
    
    In a couple of cases, a trailing #endif lacked a comment describing its
    corresponding #if or #ifdef, so these are fixes up at the same time.
    
    Guards in auto-generated crypto code are left as-is, as these guards are
    generated by scripting imported from the upstream openssl project
    scripts. Guards in UAPI headers are left as-is, as these can be included
    by userspace or the kernel.
    
    There should be no functional change as a result of this patch.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 7872f260c9ee..1a59f0ed1ae3 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -5,8 +5,6 @@
 #ifndef __ASM_IRQFLAGS_H
 #define __ASM_IRQFLAGS_H
 
-#ifdef __KERNEL__
-
 #include <asm/alternative.h>
 #include <asm/ptrace.h>
 #include <asm/sysreg.h>
@@ -128,5 +126,4 @@ static inline void arch_local_irq_restore(unsigned long flags)
 		: "memory");
 }
 
-#endif
-#endif
+#endif /* __ASM_IRQFLAGS_H */

commit dfd437a257924484b144ee750e60affc95562c6d
Merge: 0ecfebd2b524 0c61efd322b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 09:54:55 2019 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - arm64 support for syscall emulation via PTRACE_SYSEMU{,_SINGLESTEP}
    
     - Wire up VM_FLUSH_RESET_PERMS for arm64, allowing the core code to
       manage the permissions of executable vmalloc regions more strictly
    
     - Slight performance improvement by keeping softirqs enabled while
       touching the FPSIMD/SVE state (kernel_neon_begin/end)
    
     - Expose a couple of ARMv8.5 features to user (HWCAP): CondM (new
       XAFLAG and AXFLAG instructions for floating point comparison flags
       manipulation) and FRINT (rounding floating point numbers to integers)
    
     - Re-instate ARM64_PSEUDO_NMI support which was previously marked as
       BROKEN due to some bugs (now fixed)
    
     - Improve parking of stopped CPUs and implement an arm64-specific
       panic_smp_self_stop() to avoid warning on not being able to stop
       secondary CPUs during panic
    
     - perf: enable the ARM Statistical Profiling Extensions (SPE) on ACPI
       platforms
    
     - perf: DDR performance monitor support for iMX8QXP
    
     - cache_line_size() can now be set from DT or ACPI/PPTT if provided to
       cope with a system cache info not exposed via the CPUID registers
    
     - Avoid warning on hardware cache line size greater than
       ARCH_DMA_MINALIGN if the system is fully coherent
    
     - arm64 do_page_fault() and hugetlb cleanups
    
     - Refactor set_pte_at() to avoid redundant READ_ONCE(*ptep)
    
     - Ignore ACPI 5.1 FADTs reported as 5.0 (infer from the
       'arm_boot_flags' introduced in 5.1)
    
     - CONFIG_RANDOMIZE_BASE now enabled in defconfig
    
     - Allow the selection of ARM64_MODULE_PLTS, currently only done via
       RANDOMIZE_BASE (and an erratum workaround), allowing modules to spill
       over into the vmalloc area
    
     - Make ZONE_DMA32 configurable
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (54 commits)
      perf: arm_spe: Enable ACPI/Platform automatic module loading
      arm_pmu: acpi: spe: Add initial MADT/SPE probing
      ACPI/PPTT: Add function to return ACPI 6.3 Identical tokens
      ACPI/PPTT: Modify node flag detection to find last IDENTICAL
      x86/entry: Simplify _TIF_SYSCALL_EMU handling
      arm64: rename dump_instr as dump_kernel_instr
      arm64/mm: Drop [PTE|PMD]_TYPE_FAULT
      arm64: Implement panic_smp_self_stop()
      arm64: Improve parking of stopped CPUs
      arm64: Expose FRINT capabilities to userspace
      arm64: Expose ARMv8.5 CondM capability to userspace
      arm64: defconfig: enable CONFIG_RANDOMIZE_BASE
      arm64: ARM64_MODULES_PLTS must depend on MODULES
      arm64: bpf: do not allocate executable memory
      arm64/kprobes: set VM_FLUSH_RESET_PERMS on kprobe instruction pages
      arm64/mm: wire up CONFIG_ARCH_HAS_SET_DIRECT_MAP
      arm64: module: create module allocations without exec permissions
      arm64: Allow user selection of ARM64_MODULE_PLTS
      acpi/arm64: ignore 5.1 FADTs that are reported as 5.0
      arm64: Allow selecting Pseudo-NMI again
      ...

commit 48ce8f80f5901f1f031b00be66d659d39f33b0a1
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Tue Jun 11 10:38:11 2019 +0100

    arm64: irqflags: Introduce explicit debugging for IRQ priorities
    
    Using IRQ priority masking to enable/disable interrupts is a bit
    sensitive as it requires to deal with both ICC_PMR_EL1 and PSR.I.
    
    Introduce some validity checks to both highlight the states in which
    functions dealing with IRQ enabling/disabling can (not) be called, and
    bark a warning when called in an unexpected state.
    
    Since these checks are done on hotpaths, introduce a build option to
    choose whether to do the checking.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index a1372722f12e..cac2d2a3c24e 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -40,6 +40,12 @@
  */
 static inline void arch_local_irq_enable(void)
 {
+	if (system_has_prio_mask_debugging()) {
+		u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
+
+		WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
+	}
+
 	asm volatile(ALTERNATIVE(
 		"msr	daifclr, #2		// arch_local_irq_enable\n"
 		"nop",
@@ -53,6 +59,12 @@ static inline void arch_local_irq_enable(void)
 
 static inline void arch_local_irq_disable(void)
 {
+	if (system_has_prio_mask_debugging()) {
+		u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
+
+		WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
+	}
+
 	asm volatile(ALTERNATIVE(
 		"msr	daifset, #2		// arch_local_irq_disable",
 		__msr_s(SYS_ICC_PMR_EL1, "%0"),

commit bd82d4bd21880b7c4d5f5756be435095d6ae07b5
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Tue Jun 11 10:38:10 2019 +0100

    arm64: Fix incorrect irqflag restore for priority masking
    
    When using IRQ priority masking to disable interrupts, in order to deal
    with the PSR.I state, local_irq_save() would convert the I bit into a
    PMR value (GIC_PRIO_IRQOFF). This resulted in local_irq_restore()
    potentially modifying the value of PMR in undesired location due to the
    state of PSR.I upon flag saving [1].
    
    In an attempt to solve this issue in a less hackish manner, introduce
    a bit (GIC_PRIO_IGNORE_PMR) for the PMR values that can represent
    whether PSR.I is being used to disable interrupts, in which case it
    takes precedence of the status of interrupt masking via PMR.
    
    GIC_PRIO_PSR_I_SET is chosen such that (<pmr_value> |
    GIC_PRIO_PSR_I_SET) does not mask more interrupts than <pmr_value> as
    some sections (e.g. arch_cpu_idle(), interrupt acknowledge path)
    requires PMR not to mask interrupts that could be signaled to the
    CPU when using only PSR.I.
    
    [1] https://www.spinics.net/lists/arm-kernel/msg716956.html
    
    Fixes: 4a503217ce37 ("arm64: irqflags: Use ICC_PMR_EL1 for interrupt masking")
    Cc: <stable@vger.kernel.org> # 5.1.x-
    Reported-by: Zenghui Yu <yuzenghui@huawei.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Wei Li <liwei391@huawei.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Christoffer Dall <christoffer.dall@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Suzuki K Pouloze <suzuki.poulose@arm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index fbe1aba6ffb3..a1372722f12e 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -67,43 +67,46 @@ static inline void arch_local_irq_disable(void)
  */
 static inline unsigned long arch_local_save_flags(void)
 {
-	unsigned long daif_bits;
 	unsigned long flags;
 
-	daif_bits = read_sysreg(daif);
-
-	/*
-	 * The asm is logically equivalent to:
-	 *
-	 * if (system_uses_irq_prio_masking())
-	 *	flags = (daif_bits & PSR_I_BIT) ?
-	 *			GIC_PRIO_IRQOFF :
-	 *			read_sysreg_s(SYS_ICC_PMR_EL1);
-	 * else
-	 *	flags = daif_bits;
-	 */
 	asm volatile(ALTERNATIVE(
-			"mov	%0, %1\n"
-			"nop\n"
-			"nop",
-			__mrs_s("%0", SYS_ICC_PMR_EL1)
-			"ands	%1, %1, " __stringify(PSR_I_BIT) "\n"
-			"csel	%0, %0, %2, eq",
-			ARM64_HAS_IRQ_PRIO_MASKING)
-		: "=&r" (flags), "+r" (daif_bits)
-		: "r" ((unsigned long) GIC_PRIO_IRQOFF)
-		: "cc", "memory");
+		"mrs	%0, daif",
+		__mrs_s("%0", SYS_ICC_PMR_EL1),
+		ARM64_HAS_IRQ_PRIO_MASKING)
+		: "=&r" (flags)
+		:
+		: "memory");
 
 	return flags;
 }
 
+static inline int arch_irqs_disabled_flags(unsigned long flags)
+{
+	int res;
+
+	asm volatile(ALTERNATIVE(
+		"and	%w0, %w1, #" __stringify(PSR_I_BIT),
+		"eor	%w0, %w1, #" __stringify(GIC_PRIO_IRQON),
+		ARM64_HAS_IRQ_PRIO_MASKING)
+		: "=&r" (res)
+		: "r" ((int) flags)
+		: "memory");
+
+	return res;
+}
+
 static inline unsigned long arch_local_irq_save(void)
 {
 	unsigned long flags;
 
 	flags = arch_local_save_flags();
 
-	arch_local_irq_disable();
+	/*
+	 * There are too many states with IRQs disabled, just keep the current
+	 * state if interrupts are already disabled/masked.
+	 */
+	if (!arch_irqs_disabled_flags(flags))
+		arch_local_irq_disable();
 
 	return flags;
 }
@@ -124,21 +127,5 @@ static inline void arch_local_irq_restore(unsigned long flags)
 		: "memory");
 }
 
-static inline int arch_irqs_disabled_flags(unsigned long flags)
-{
-	int res;
-
-	asm volatile(ALTERNATIVE(
-			"and	%w0, %w1, #" __stringify(PSR_I_BIT) "\n"
-			"nop",
-			"cmp	%w1, #" __stringify(GIC_PRIO_IRQOFF) "\n"
-			"cset	%w0, ls",
-			ARM64_HAS_IRQ_PRIO_MASKING)
-		: "=&r" (res)
-		: "r" ((int) flags)
-		: "cc", "memory");
-
-	return res;
-}
 #endif
 #endif

commit f57065782f245ca96f1472209a485073bbc11247
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Tue Jun 11 10:38:08 2019 +0100

    arm64: irqflags: Add condition flags to inline asm clobber list
    
    Some of the inline assembly instruction use the condition flags and need
    to include "cc" in the clobber list.
    
    Fixes: 4a503217ce37 ("arm64: irqflags: Use ICC_PMR_EL1 for interrupt masking")
    Cc: <stable@vger.kernel.org> # 5.1.x-
    Suggested-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 9c93152c9af7..fbe1aba6ffb3 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -92,7 +92,7 @@ static inline unsigned long arch_local_save_flags(void)
 			ARM64_HAS_IRQ_PRIO_MASKING)
 		: "=&r" (flags), "+r" (daif_bits)
 		: "r" ((unsigned long) GIC_PRIO_IRQOFF)
-		: "memory");
+		: "cc", "memory");
 
 	return flags;
 }
@@ -136,7 +136,7 @@ static inline int arch_irqs_disabled_flags(unsigned long flags)
 			ARM64_HAS_IRQ_PRIO_MASKING)
 		: "=&r" (res)
 		: "r" ((int) flags)
-		: "memory");
+		: "cc", "memory");
 
 	return res;
 }

commit 19c36b185a1d13f79f3a382e08695a2633155e5a
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Tue Jun 11 10:38:07 2019 +0100

    arm64: irqflags: Pass flags as readonly operand to restore instruction
    
    Flags are only read by the instructions doing the irqflags restore
    operation. Pass the operand as read only to the asm inline instead of
    read-write.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Mark Rutland <mark.rutland@ar.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 629963189085..9c93152c9af7 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -119,8 +119,8 @@ static inline void arch_local_irq_restore(unsigned long flags)
 			__msr_s(SYS_ICC_PMR_EL1, "%0")
 			"dsb	sy",
 			ARM64_HAS_IRQ_PRIO_MASKING)
-		: "+r" (flags)
 		:
+		: "r" (flags)
 		: "memory");
 }
 

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 629963189085..66853fde60f9 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -1,17 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright (C) 2012 ARM Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __ASM_IRQFLAGS_H
 #define __ASM_IRQFLAGS_H

commit be604c616ca71cbf5c860d0cfa4595128ab74189
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Apr 24 09:55:37 2019 -0700

    arm64: sysreg: Make mrs_s and msr_s macros work with Clang and LTO
    
    Clang's integrated assembler does not allow assembly macros defined
    in one inline asm block using the .macro directive to be used across
    separate asm blocks. LLVM developers consider this a feature and not a
    bug, recommending code refactoring:
    
      https://bugs.llvm.org/show_bug.cgi?id=19749
    
    As binutils doesn't allow macros to be redefined, this change uses
    UNDEFINE_MRS_S and UNDEFINE_MSR_S to define corresponding macros
    in-place and workaround gcc and clang limitations on redefining macros
    across different assembler blocks.
    
    Specifically, the current state after preprocessing looks like this:
    
    asm volatile(".macro mXX_s ... .endm");
    void f()
    {
            asm volatile("mXX_s a, b");
    }
    
    With GCC, it gives macro redefinition error because sysreg.h is included
    in multiple source files, and assembler code for all of them is later
    combined for LTO (I've seen an intermediate file with hundreds of
    identical definitions).
    
    With clang, it gives macro undefined error because clang doesn't allow
    sharing macros between inline asm statements.
    
    I also seem to remember catching another sort of undefined error with
    GCC due to reordering of macro definition asm statement and generated
    asm code for function that uses the macro.
    
    The solution with defining and undefining for each use, while certainly
    not elegant, satisfies both GCC and clang, LTO and non-LTO.
    
    Co-developed-by: Alex Matveev <alxmtvv@gmail.com>
    Co-developed-by: Yury Norov <ynorov@caviumnetworks.com>
    Co-developed-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 43d8366c1e87..629963189085 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -43,7 +43,7 @@ static inline void arch_local_irq_enable(void)
 	asm volatile(ALTERNATIVE(
 		"msr	daifclr, #2		// arch_local_irq_enable\n"
 		"nop",
-		"msr_s  " __stringify(SYS_ICC_PMR_EL1) ",%0\n"
+		__msr_s(SYS_ICC_PMR_EL1, "%0")
 		"dsb	sy",
 		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
@@ -55,7 +55,7 @@ static inline void arch_local_irq_disable(void)
 {
 	asm volatile(ALTERNATIVE(
 		"msr	daifset, #2		// arch_local_irq_disable",
-		"msr_s  " __stringify(SYS_ICC_PMR_EL1) ", %0",
+		__msr_s(SYS_ICC_PMR_EL1, "%0"),
 		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
 		: "r" ((unsigned long) GIC_PRIO_IRQOFF)
@@ -86,7 +86,7 @@ static inline unsigned long arch_local_save_flags(void)
 			"mov	%0, %1\n"
 			"nop\n"
 			"nop",
-			"mrs_s	%0, " __stringify(SYS_ICC_PMR_EL1) "\n"
+			__mrs_s("%0", SYS_ICC_PMR_EL1)
 			"ands	%1, %1, " __stringify(PSR_I_BIT) "\n"
 			"csel	%0, %0, %2, eq",
 			ARM64_HAS_IRQ_PRIO_MASKING)
@@ -116,7 +116,7 @@ static inline void arch_local_irq_restore(unsigned long flags)
 	asm volatile(ALTERNATIVE(
 			"msr	daif, %0\n"
 			"nop",
-			"msr_s	" __stringify(SYS_ICC_PMR_EL1) ", %0\n"
+			__msr_s(SYS_ICC_PMR_EL1, "%0")
 			"dsb	sy",
 			ARM64_HAS_IRQ_PRIO_MASKING)
 		: "+r" (flags)

commit a80554fc36ba41d96af8e72fb54cd5d490e06c54
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Fri Feb 8 09:36:48 2019 +0000

    arm64: irqflags: Fix clang build warnings
    
    Clang complains when passing asm operands that are smaller than the
    registers they are mapped to:
    
    arch/arm64/include/asm/irqflags.h:50:10: warning: value size does not
            match register size specified by the constraint and modifier
            [-Wasm-operand-widths]
                    : "r" (GIC_PRIO_IRQON)
    
    Fix it by casting the affected input operands to a type of the correct
    size.
    
    Reported-by: Nathan Chancellor <natechancellor@gmail.com>
    Tested-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index d4597b2c5729..43d8366c1e87 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -47,7 +47,7 @@ static inline void arch_local_irq_enable(void)
 		"dsb	sy",
 		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
-		: "r" (GIC_PRIO_IRQON)
+		: "r" ((unsigned long) GIC_PRIO_IRQON)
 		: "memory");
 }
 
@@ -58,7 +58,7 @@ static inline void arch_local_irq_disable(void)
 		"msr_s  " __stringify(SYS_ICC_PMR_EL1) ", %0",
 		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
-		: "r" (GIC_PRIO_IRQOFF)
+		: "r" ((unsigned long) GIC_PRIO_IRQOFF)
 		: "memory");
 }
 
@@ -91,7 +91,7 @@ static inline unsigned long arch_local_save_flags(void)
 			"csel	%0, %0, %2, eq",
 			ARM64_HAS_IRQ_PRIO_MASKING)
 		: "=&r" (flags), "+r" (daif_bits)
-		: "r" (GIC_PRIO_IRQOFF)
+		: "r" ((unsigned long) GIC_PRIO_IRQOFF)
 		: "memory");
 
 	return flags;

commit 4a503217ce37e1f4f3d9b681bbcbbac103776bf1
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:58:50 2019 +0000

    arm64: irqflags: Use ICC_PMR_EL1 for interrupt masking
    
    Instead disabling interrupts by setting the PSR.I bit, use a priority
    higher than the one used for interrupts to mask them via PMR.
    
    When using PMR to disable interrupts, the value of PMR will be used
    instead of PSR.[DAIF] for the irqflags.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Suggested-by: Daniel Thompson <daniel.thompson@linaro.org>
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 24692edf1a69..d4597b2c5729 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -18,7 +18,9 @@
 
 #ifdef __KERNEL__
 
+#include <asm/alternative.h>
 #include <asm/ptrace.h>
+#include <asm/sysreg.h>
 
 /*
  * Aarch64 has flags for masking: Debug, Asynchronous (serror), Interrupts and
@@ -36,33 +38,27 @@
 /*
  * CPU interrupt mask handling.
  */
-static inline unsigned long arch_local_irq_save(void)
-{
-	unsigned long flags;
-	asm volatile(
-		"mrs	%0, daif		// arch_local_irq_save\n"
-		"msr	daifset, #2"
-		: "=r" (flags)
-		:
-		: "memory");
-	return flags;
-}
-
 static inline void arch_local_irq_enable(void)
 {
-	asm volatile(
-		"msr	daifclr, #2		// arch_local_irq_enable"
-		:
+	asm volatile(ALTERNATIVE(
+		"msr	daifclr, #2		// arch_local_irq_enable\n"
+		"nop",
+		"msr_s  " __stringify(SYS_ICC_PMR_EL1) ",%0\n"
+		"dsb	sy",
+		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
+		: "r" (GIC_PRIO_IRQON)
 		: "memory");
 }
 
 static inline void arch_local_irq_disable(void)
 {
-	asm volatile(
-		"msr	daifset, #2		// arch_local_irq_disable"
-		:
+	asm volatile(ALTERNATIVE(
+		"msr	daifset, #2		// arch_local_irq_disable",
+		"msr_s  " __stringify(SYS_ICC_PMR_EL1) ", %0",
+		ARM64_HAS_IRQ_PRIO_MASKING)
 		:
+		: "r" (GIC_PRIO_IRQOFF)
 		: "memory");
 }
 
@@ -71,12 +67,44 @@ static inline void arch_local_irq_disable(void)
  */
 static inline unsigned long arch_local_save_flags(void)
 {
+	unsigned long daif_bits;
 	unsigned long flags;
-	asm volatile(
-		"mrs	%0, daif		// arch_local_save_flags"
-		: "=r" (flags)
-		:
+
+	daif_bits = read_sysreg(daif);
+
+	/*
+	 * The asm is logically equivalent to:
+	 *
+	 * if (system_uses_irq_prio_masking())
+	 *	flags = (daif_bits & PSR_I_BIT) ?
+	 *			GIC_PRIO_IRQOFF :
+	 *			read_sysreg_s(SYS_ICC_PMR_EL1);
+	 * else
+	 *	flags = daif_bits;
+	 */
+	asm volatile(ALTERNATIVE(
+			"mov	%0, %1\n"
+			"nop\n"
+			"nop",
+			"mrs_s	%0, " __stringify(SYS_ICC_PMR_EL1) "\n"
+			"ands	%1, %1, " __stringify(PSR_I_BIT) "\n"
+			"csel	%0, %0, %2, eq",
+			ARM64_HAS_IRQ_PRIO_MASKING)
+		: "=&r" (flags), "+r" (daif_bits)
+		: "r" (GIC_PRIO_IRQOFF)
 		: "memory");
+
+	return flags;
+}
+
+static inline unsigned long arch_local_irq_save(void)
+{
+	unsigned long flags;
+
+	flags = arch_local_save_flags();
+
+	arch_local_irq_disable();
+
 	return flags;
 }
 
@@ -85,16 +113,32 @@ static inline unsigned long arch_local_save_flags(void)
  */
 static inline void arch_local_irq_restore(unsigned long flags)
 {
-	asm volatile(
-		"msr	daif, %0		// arch_local_irq_restore"
-	:
-	: "r" (flags)
-	: "memory");
+	asm volatile(ALTERNATIVE(
+			"msr	daif, %0\n"
+			"nop",
+			"msr_s	" __stringify(SYS_ICC_PMR_EL1) ", %0\n"
+			"dsb	sy",
+			ARM64_HAS_IRQ_PRIO_MASKING)
+		: "+r" (flags)
+		:
+		: "memory");
 }
 
 static inline int arch_irqs_disabled_flags(unsigned long flags)
 {
-	return flags & PSR_I_BIT;
+	int res;
+
+	asm volatile(ALTERNATIVE(
+			"and	%w0, %w1, #" __stringify(PSR_I_BIT) "\n"
+			"nop",
+			"cmp	%w1, #" __stringify(GIC_PRIO_IRQOFF) "\n"
+			"cset	%w0, ls",
+			ARM64_HAS_IRQ_PRIO_MASKING)
+		: "=&r" (res)
+		: "r" ((int) flags)
+		: "memory");
+
+	return res;
 }
 #endif
 #endif

commit 41bd5b5d22b77c7300df2a2fa5397cbe785189b4
Author: James Morse <james.morse@arm.com>
Date:   Thu Nov 2 12:12:36 2017 +0000

    arm64: Move the async/fiq helpers to explicitly set process context flags
    
    Remove the local_{async,fiq}_{en,dis}able macros as they don't respect
    our newly defined order and are only used to set the flags for process
    context when we bring CPUs online.
    
    Add a helper to do this. The IRQ flag varies as we want it masked on
    the boot CPU until we are ready to handle interrupts.
    The boot CPU unmasks SError during early boot once it can print an error
    message. If we can print an error message about SError, we can do the
    same for FIQ. Debug exceptions are already enabled by __cpu_setup(),
    which has also configured MDSCR_EL1 to disable MDE and KDE.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 9ecdca7011f0..24692edf1a69 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -66,12 +66,6 @@ static inline void arch_local_irq_disable(void)
 		: "memory");
 }
 
-#define local_fiq_enable()	asm("msr	daifclr, #1" : : : "memory")
-#define local_fiq_disable()	asm("msr	daifset, #1" : : : "memory")
-
-#define local_async_enable()	asm("msr	daifclr, #4" : : : "memory")
-#define local_async_disable()	asm("msr	daifset, #4" : : : "memory")
-
 /*
  * Save the current interrupt enable state.
  */

commit 65be7a1b799f11ff16f4c154ba4cf82eeb722ec7
Author: James Morse <james.morse@arm.com>
Date:   Thu Nov 2 12:12:35 2017 +0000

    arm64: introduce an order for exceptions
    
    Currently SError is always masked in the kernel. To support RAS exceptions
    using SError on hardware with the v8.2 RAS Extensions we need to unmask
    SError as much as possible.
    
    Let's define an order for masking and unmasking exceptions. 'dai' is
    memorable and effectively what we have today.
    
    Disabling debug exceptions should cause all other exceptions to be masked.
    Masking SError should mask irq, but not disable debug exceptions.
    Masking irqs has no side effects for other flags. Keeping to this order
    makes it easier for entry.S to know which exceptions should be unmasked.
    
    FIQ is never expected, but we mask it when we mask debug exceptions, and
    unmask it at all other times.
    
    Given masking debug exceptions masks everything, we don't need macros
    to save/restore that bit independently. Remove them and switch the last
    caller over to use the daif calls.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 8c581281fa12..9ecdca7011f0 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -20,6 +20,19 @@
 
 #include <asm/ptrace.h>
 
+/*
+ * Aarch64 has flags for masking: Debug, Asynchronous (serror), Interrupts and
+ * FIQ exceptions, in the 'daif' register. We mask and unmask them in 'dai'
+ * order:
+ * Masking debug exceptions causes all other exceptions to be masked too/
+ * Masking SError masks irq, but not debug exceptions. Masking irqs has no
+ * side effects for other flags. Keeping to this order makes it easier for
+ * entry.S to know which exceptions should be unmasked.
+ *
+ * FIQ is never expected, but we mask it when we disable debug exceptions, and
+ * unmask it at all other times.
+ */
+
 /*
  * CPU interrupt mask handling.
  */
@@ -89,26 +102,5 @@ static inline int arch_irqs_disabled_flags(unsigned long flags)
 {
 	return flags & PSR_I_BIT;
 }
-
-/*
- * save and restore debug state
- */
-#define local_dbg_save(flags)						\
-	do {								\
-		typecheck(unsigned long, flags);			\
-		asm volatile(						\
-		"mrs    %0, daif		// local_dbg_save\n"	\
-		"msr    daifset, #8"					\
-		: "=r" (flags) : : "memory");				\
-	} while (0)
-
-#define local_dbg_restore(flags)					\
-	do {								\
-		typecheck(unsigned long, flags);			\
-		asm volatile(						\
-		"msr    daif, %0		// local_dbg_restore\n"	\
-		: : "r" (flags) : "memory");				\
-	} while (0)
-
 #endif
 #endif

commit 2572214170fb95370be21915c0397f4b6a27e7e3
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Jul 19 15:07:40 2016 +0100

    arm64: debug: remove unused local_dbg_{enable, disable} macros
    
    The debug enable/disable macros are not used anywhere in the kernel, so
    remove them from irqflags.h
    
    Reported-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index 11cc941bd107..8c581281fa12 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -110,8 +110,5 @@ static inline int arch_irqs_disabled_flags(unsigned long flags)
 		: : "r" (flags) : "memory");				\
 	} while (0)
 
-#define local_dbg_enable()	asm("msr	daifclr, #8" : : : "memory")
-#define local_dbg_disable()	asm("msr	daifset, #8" : : : "memory")
-
 #endif
 #endif

commit c7db4ff5d2b459a579d348532a92fd5885520ce6
Author: Vijaya Kumar K <Vijaya.Kumar@caviumnetworks.com>
Date:   Tue Jan 28 11:20:17 2014 +0000

    arm64: Add macros to manage processor debug state
    
    Add macros to enable and disable to manage PSTATE.D
    for debugging. The macros local_dbg_save and local_dbg_restore
    are moved to irqflags.h file
    
    KGDB boot tests fail because of PSTATE.D is masked.
    unmask it for debugging support
    
    Signed-off-by: Vijaya Kumar K <Vijaya.Kumar@caviumnetworks.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index b2fcfbc51ecc..11cc941bd107 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -90,5 +90,28 @@ static inline int arch_irqs_disabled_flags(unsigned long flags)
 	return flags & PSR_I_BIT;
 }
 
+/*
+ * save and restore debug state
+ */
+#define local_dbg_save(flags)						\
+	do {								\
+		typecheck(unsigned long, flags);			\
+		asm volatile(						\
+		"mrs    %0, daif		// local_dbg_save\n"	\
+		"msr    daifset, #8"					\
+		: "=r" (flags) : : "memory");				\
+	} while (0)
+
+#define local_dbg_restore(flags)					\
+	do {								\
+		typecheck(unsigned long, flags);			\
+		asm volatile(						\
+		"msr    daif, %0		// local_dbg_restore\n"	\
+		: : "r" (flags) : "memory");				\
+	} while (0)
+
+#define local_dbg_enable()	asm("msr	daifclr, #8" : : : "memory")
+#define local_dbg_disable()	asm("msr	daifset, #8" : : : "memory")
+
 #endif
 #endif

commit b3bf6aa7e79117419f7eddccf0b7af4382d823c3
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Nov 21 14:46:17 2013 +0000

    arm64: Unmask asynchronous aborts when in kernel mode
    
    The asynchronous aborts are generally fatal for the kernel but they can
    be masked via the pstate A bit. If a system error happens while in
    kernel mode, it won't be visible until returning to user space. This
    patch enables this kind of abort early to help identifying the cause.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
index aa11943b8502..b2fcfbc51ecc 100644
--- a/arch/arm64/include/asm/irqflags.h
+++ b/arch/arm64/include/asm/irqflags.h
@@ -56,6 +56,9 @@ static inline void arch_local_irq_disable(void)
 #define local_fiq_enable()	asm("msr	daifclr, #1" : : : "memory")
 #define local_fiq_disable()	asm("msr	daifset, #1" : : : "memory")
 
+#define local_async_enable()	asm("msr	daifclr, #4" : : : "memory")
+#define local_async_disable()	asm("msr	daifset, #4" : : : "memory")
+
 /*
  * Save the current interrupt enable state.
  */

commit fb9bd7d6df81ddf1e7ab6648ac89ddbe0625b26b
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Mar 5 11:49:29 2012 +0000

    arm64: IRQ handling
    
    This patch adds the support for IRQ handling. The actual interrupt
    controller will be part of a separate patch (going into
    drivers/irqchip/).
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm64/include/asm/irqflags.h b/arch/arm64/include/asm/irqflags.h
new file mode 100644
index 000000000000..aa11943b8502
--- /dev/null
+++ b/arch/arm64/include/asm/irqflags.h
@@ -0,0 +1,91 @@
+/*
+ * Copyright (C) 2012 ARM Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __ASM_IRQFLAGS_H
+#define __ASM_IRQFLAGS_H
+
+#ifdef __KERNEL__
+
+#include <asm/ptrace.h>
+
+/*
+ * CPU interrupt mask handling.
+ */
+static inline unsigned long arch_local_irq_save(void)
+{
+	unsigned long flags;
+	asm volatile(
+		"mrs	%0, daif		// arch_local_irq_save\n"
+		"msr	daifset, #2"
+		: "=r" (flags)
+		:
+		: "memory");
+	return flags;
+}
+
+static inline void arch_local_irq_enable(void)
+{
+	asm volatile(
+		"msr	daifclr, #2		// arch_local_irq_enable"
+		:
+		:
+		: "memory");
+}
+
+static inline void arch_local_irq_disable(void)
+{
+	asm volatile(
+		"msr	daifset, #2		// arch_local_irq_disable"
+		:
+		:
+		: "memory");
+}
+
+#define local_fiq_enable()	asm("msr	daifclr, #1" : : : "memory")
+#define local_fiq_disable()	asm("msr	daifset, #1" : : : "memory")
+
+/*
+ * Save the current interrupt enable state.
+ */
+static inline unsigned long arch_local_save_flags(void)
+{
+	unsigned long flags;
+	asm volatile(
+		"mrs	%0, daif		// arch_local_save_flags"
+		: "=r" (flags)
+		:
+		: "memory");
+	return flags;
+}
+
+/*
+ * restore saved IRQ state
+ */
+static inline void arch_local_irq_restore(unsigned long flags)
+{
+	asm volatile(
+		"msr	daif, %0		// arch_local_irq_restore"
+	:
+	: "r" (flags)
+	: "memory");
+}
+
+static inline int arch_irqs_disabled_flags(unsigned long flags)
+{
+	return flags & PSR_I_BIT;
+}
+
+#endif
+#endif
