commit f7b93d42945cc71e1346dd5ae07c59061d56745e
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Tue Jun 30 10:19:21 2020 +0200

    arm64/alternatives: use subsections for replacement sequences
    
    When building very large kernels, the logic that emits replacement
    sequences for alternatives fails when relative branches are present
    in the code that is emitted into the .altinstr_replacement section
    and patched in at the original site and fixed up. The reason is that
    the linker will insert veneers if relative branches go out of range,
    and due to the relative distance of the .altinstr_replacement from
    the .text section where its branch targets usually live, veneers
    may be emitted at the end of the .altinstr_replacement section, with
    the relative branches in the sequence pointed at the veneers instead
    of the actual target.
    
    The alternatives patching logic will attempt to fix up the branch to
    point to its original target, which will be the veneer in this case,
    but given that the patch site is likely to be far away as well, it
    will be out of range and so patching will fail. There are other cases
    where these veneers are problematic, e.g., when the target of the
    branch is in .text while the patch site is in .init.text, in which
    case putting the replacement sequence inside .text may not help either.
    
    So let's use subsections to emit the replacement code as closely as
    possible to the patch site, to ensure that veneers are only likely to
    be emitted if they are required at the patch site as well, in which
    case they will be in range for the replacement sequence both before
    and after it is transported to the patch site.
    
    This will prevent alternative sequences in non-init code from being
    released from memory after boot, but this is tolerable given that the
    entire section is only 512 KB on an allyesconfig build (which weighs in
    at 500+ MB for the entire Image). Also, note that modules today carry
    the replacement sequences in non-init sections as well, and any of
    those that target init code will be emitted into init sections after
    this change.
    
    This fixes an early crash when booting an allyesconfig kernel on a
    system where any of the alternatives sequences containing relative
    branches are activated at boot (e.g., ARM64_HAS_PAN on TX2)
    
    Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Andre Przywara <andre.przywara@arm.com>
    Cc: Dave P Martin <dave.martin@arm.com>
    Link: https://lore.kernel.org/r/20200630081921.13443-1-ardb@kernel.org
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 5e5dc05d63a0..12f0eb56a1cc 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -73,11 +73,11 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 	".pushsection .altinstructions,\"a\"\n"				\
 	ALTINSTR_ENTRY(feature)						\
 	".popsection\n"							\
-	".pushsection .altinstr_replacement, \"a\"\n"			\
+	".subsection 1\n"						\
 	"663:\n\t"							\
 	newinstr "\n"							\
 	"664:\n\t"							\
-	".popsection\n\t"						\
+	".previous\n\t"							\
 	".org	. - (664b-663b) + (662b-661b)\n\t"			\
 	".org	. - (662b-661b) + (664b-663b)\n"			\
 	".endif\n"
@@ -117,9 +117,9 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 662:	.pushsection .altinstructions, "a"
 	altinstruction_entry 661b, 663f, \cap, 662b-661b, 664f-663f
 	.popsection
-	.pushsection .altinstr_replacement, "ax"
+	.subsection 1
 663:	\insn2
-664:	.popsection
+664:	.previous
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)
 	.endif
@@ -160,7 +160,7 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 	.pushsection .altinstructions, "a"
 	altinstruction_entry 663f, 661f, \cap, 664f-663f, 662f-661f
 	.popsection
-	.pushsection .altinstr_replacement, "ax"
+	.subsection 1
 	.align 2	/* So GAS knows label 661 is suitably aligned */
 661:
 .endm
@@ -179,9 +179,9 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 .macro alternative_else
 662:
 	.if .Lasm_alt_mode==0
-	.pushsection .altinstr_replacement, "ax"
+	.subsection 1
 	.else
-	.popsection
+	.previous
 	.endif
 663:
 .endm
@@ -192,7 +192,7 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 .macro alternative_endif
 664:
 	.if .Lasm_alt_mode==0
-	.popsection
+	.previous
 	.endif
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)

commit 6f5459da2b8736720afdbd67c4bd2d1edba7d0e3
Author: Ilie Halip <ilie.halip@gmail.com>
Date:   Thu Mar 19 23:45:28 2020 +0200

    arm64: alternative: fix build with clang integrated assembler
    
    Building an arm64 defconfig with clang's integrated assembler, this error
    occurs:
        <instantiation>:2:2: error: unrecognized instruction mnemonic
         _ASM_EXTABLE 9999b, 9f
         ^
        arch/arm64/mm/cache.S:50:1: note: while in macro instantiation
        user_alt 9f, "dc cvau, x4", "dc civac, x4", 0
        ^
    
    While GNU as seems fine with case-sensitive macro instantiations, clang
    doesn't, so use the actual macro name (_asm_extable) as in the rest of
    the file.
    
    Also checked that the generated assembly matches the GCC output.
    
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Tested-by: Nick Desaulniers <ndesaulniers@google.com>
    Fixes: 290622efc76e ("arm64: fix "dc cvau" cache operation on errata-affected core")
    Link: https://github.com/ClangBuiltLinux/linux/issues/924
    Signed-off-by: Ilie Halip <ilie.halip@gmail.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 324e7d5ab37e..5e5dc05d63a0 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -221,7 +221,7 @@ alternative_endif
 
 .macro user_alt, label, oldinstr, newinstr, cond
 9999:	alternative_insn "\oldinstr", "\newinstr", \cond
-	_ASM_EXTABLE 9999b, \label
+	_asm_extable 9999b, \label
 .endm
 
 /*

commit c54f90c2627cc316d365e3073614731e17dbc631
Author: Sami Tolvanen <samitolvanen@google.com>
Date:   Thu Oct 31 12:46:52 2019 -0700

    arm64: fix alternatives with LLVM's integrated assembler
    
    LLVM's integrated assembler fails with the following error when
    building KVM:
    
      <inline asm>:12:6: error: expected absolute expression
       .if kvm_update_va_mask == 0
           ^
      <inline asm>:21:6: error: expected absolute expression
       .if kvm_update_va_mask == 0
           ^
      <inline asm>:24:2: error: unrecognized instruction mnemonic
              NOT_AN_INSTRUCTION
              ^
      LLVM ERROR: Error parsing inline asm
    
    These errors come from ALTERNATIVE_CB and __ALTERNATIVE_CFG,
    which test for the existence of the callback parameter in inline
    assembly using the following expression:
    
      " .if " __stringify(cb) " == 0\n"
    
    This works with GNU as, but isn't supported by LLVM. This change
    splits __ALTERNATIVE_CFG and ALTINSTR_ENTRY into separate macros
    to fix the LLVM build.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/472
    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>
    Tested-by: Nick Desaulniers <ndesaulniers@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index b9f8d787eea9..324e7d5ab37e 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -35,13 +35,16 @@ void apply_alternatives_module(void *start, size_t length);
 static inline void apply_alternatives_module(void *start, size_t length) { }
 #endif
 
-#define ALTINSTR_ENTRY(feature,cb)					      \
+#define ALTINSTR_ENTRY(feature)					              \
 	" .word 661b - .\n"				/* label           */ \
-	" .if " __stringify(cb) " == 0\n"				      \
 	" .word 663f - .\n"				/* new instruction */ \
-	" .else\n"							      \
+	" .hword " __stringify(feature) "\n"		/* feature bit     */ \
+	" .byte 662b-661b\n"				/* source len      */ \
+	" .byte 664f-663f\n"				/* replacement len */
+
+#define ALTINSTR_ENTRY_CB(feature, cb)					      \
+	" .word 661b - .\n"				/* label           */ \
 	" .word " __stringify(cb) "- .\n"		/* callback */	      \
-	" .endif\n"							      \
 	" .hword " __stringify(feature) "\n"		/* feature bit     */ \
 	" .byte 662b-661b\n"				/* source len      */ \
 	" .byte 664f-663f\n"				/* replacement len */
@@ -62,15 +65,14 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
  *
  * Alternatives with callbacks do not generate replacement instructions.
  */
-#define __ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg_enabled, cb)	\
+#define __ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg_enabled)	\
 	".if "__stringify(cfg_enabled)" == 1\n"				\
 	"661:\n\t"							\
 	oldinstr "\n"							\
 	"662:\n"							\
 	".pushsection .altinstructions,\"a\"\n"				\
-	ALTINSTR_ENTRY(feature,cb)					\
+	ALTINSTR_ENTRY(feature)						\
 	".popsection\n"							\
-	" .if " __stringify(cb) " == 0\n"				\
 	".pushsection .altinstr_replacement, \"a\"\n"			\
 	"663:\n\t"							\
 	newinstr "\n"							\
@@ -78,17 +80,25 @@ static inline void apply_alternatives_module(void *start, size_t length) { }
 	".popsection\n\t"						\
 	".org	. - (664b-663b) + (662b-661b)\n\t"			\
 	".org	. - (662b-661b) + (664b-663b)\n"			\
-	".else\n\t"							\
+	".endif\n"
+
+#define __ALTERNATIVE_CFG_CB(oldinstr, feature, cfg_enabled, cb)	\
+	".if "__stringify(cfg_enabled)" == 1\n"				\
+	"661:\n\t"							\
+	oldinstr "\n"							\
+	"662:\n"							\
+	".pushsection .altinstructions,\"a\"\n"				\
+	ALTINSTR_ENTRY_CB(feature, cb)					\
+	".popsection\n"							\
 	"663:\n\t"							\
 	"664:\n\t"							\
-	".endif\n"							\
 	".endif\n"
 
 #define _ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg, ...)	\
-	__ALTERNATIVE_CFG(oldinstr, newinstr, feature, IS_ENABLED(cfg), 0)
+	__ALTERNATIVE_CFG(oldinstr, newinstr, feature, IS_ENABLED(cfg))
 
 #define ALTERNATIVE_CB(oldinstr, cb) \
-	__ALTERNATIVE_CFG(oldinstr, "NOT_AN_INSTRUCTION", ARM64_CB_PATCH, 1, cb)
+	__ALTERNATIVE_CFG_CB(oldinstr, ARM64_CB_PATCH, 1, cb)
 #else
 
 #include <asm/assembler.h>

commit 0ceb0d56905e3d141fae77e5936d00eee9233473
Author: Daniel Thompson <daniel.thompson@linaro.org>
Date:   Thu Jan 31 14:58:53 2019 +0000

    arm64: alternative: Apply alternatives early in boot process
    
    Currently alternatives are applied very late in the boot process (and
    a long time after we enable scheduling). Some alternative sequences,
    such as those that alter the way CPU context is stored, must be applied
    much earlier in the boot sequence.
    
    Introduce apply_boot_alternatives() to allow some alternatives to be
    applied immediately after we detect the CPU features of the boot CPU.
    
    Signed-off-by: Daniel Thompson <daniel.thompson@linaro.org>
    [julien.thierry@arm.com: rename to fit new cpufeature framework better,
                             apply BOOT_SCOPE feature early in boot]
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Christoffer Dall <christoffer.dall@arm.com>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 9806a2357e70..b9f8d787eea9 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -25,6 +25,7 @@ struct alt_instr {
 typedef void (*alternative_cb_t)(struct alt_instr *alt,
 				 __le32 *origptr, __le32 *updptr, int nr_inst);
 
+void __init apply_boot_alternatives(void);
 void __init apply_alternatives_all(void);
 bool alternative_is_applied(u16 cpufeature);
 

commit e9ab7a2e333615497b3fc426c379c330230c2b50
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:58:52 2019 +0000

    arm64: alternative: Allow alternative status checking per cpufeature
    
    In preparation for the application of alternatives at different points
    during the boot process, provide the possibility to check whether
    alternatives for a feature of interest was already applied instead of
    having a global boolean for all alternatives.
    
    Make VHE enablement code check for the VHE feature instead of considering
    all alternatives.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: Marc Zyngier <Marc.Zyngier@arm.com>
    Cc: Christoffer Dall <Christoffer.Dall@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 4b650ec1d7dd..9806a2357e70 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -14,8 +14,6 @@
 #include <linux/stddef.h>
 #include <linux/stringify.h>
 
-extern int alternatives_applied;
-
 struct alt_instr {
 	s32 orig_offset;	/* offset to original instruction */
 	s32 alt_offset;		/* offset to replacement instruction */
@@ -28,6 +26,7 @@ typedef void (*alternative_cb_t)(struct alt_instr *alt,
 				 __le32 *origptr, __le32 *updptr, int nr_inst);
 
 void __init apply_alternatives_all(void);
+bool alternative_is_applied(u16 cpufeature);
 
 #ifdef CONFIG_MODULES
 void apply_alternatives_module(void *start, size_t length);

commit 429388682dc266e7a693f9c27e3aabd341d55343
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Jun 22 09:31:15 2018 +0100

    arm64: Avoid flush_icache_range() in alternatives patching code
    
    The implementation of flush_icache_range() includes instruction sequences
    which are themselves patched at runtime, so it is not safe to call from
    the patching framework.
    
    This patch reworks the alternatives cache-flushing code so that it rolls
    its own internal D-cache maintenance using DC CIVAC before invalidating
    the entire I-cache after all alternatives have been applied at boot.
    Modules don't cause any issues, since flush_icache_range() is safe to
    call by the time they are loaded.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Reported-by: Rohit Khanna <rokhanna@nvidia.com>
    Cc: Alexander Van Brunt <avanbrunt@nvidia.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index a91933b1e2e6..4b650ec1d7dd 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -28,7 +28,12 @@ typedef void (*alternative_cb_t)(struct alt_instr *alt,
 				 __le32 *origptr, __le32 *updptr, int nr_inst);
 
 void __init apply_alternatives_all(void);
-void apply_alternatives(void *start, size_t length);
+
+#ifdef CONFIG_MODULES
+void apply_alternatives_module(void *start, size_t length);
+#else
+static inline void apply_alternatives_module(void *start, size_t length) { }
+#endif
 
 #define ALTINSTR_ENTRY(feature,cb)					      \
 	" .word 661b - .\n"				/* label           */ \

commit dea5e2a4c5bcf196f879a66cebdcca07793e8ba4
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Sun Dec 3 12:02:14 2017 +0000

    arm64: alternatives: Add dynamic patching feature
    
    We've so far relied on a patching infrastructure that only gave us
    a single alternative, without any way to provide a range of potential
    replacement instructions. For a single feature, this is an all or
    nothing thing.
    
    It would be interesting to have a more flexible grained way of patching
    the kernel though, where we could dynamically tune the code that gets
    injected.
    
    In order to achive this, let's introduce a new form of dynamic patching,
    assiciating a callback to a patching site. This callback gets source and
    target locations of the patching request, as well as the number of
    instructions to be patched.
    
    Dynamic patching is declared with the new ALTERNATIVE_CB and alternative_cb
    directives:
    
            asm volatile(ALTERNATIVE_CB("mov %0, #0\n", callback)
                         : "r" (v));
    or
            alternative_cb callback
                    mov     x0, #0
            alternative_cb_end
    
    where callback is the C function computing the alternative.
    
    Reviewed-by: Christoffer Dall <christoffer.dall@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 669028172fd6..a91933b1e2e6 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -5,6 +5,8 @@
 #include <asm/cpucaps.h>
 #include <asm/insn.h>
 
+#define ARM64_CB_PATCH ARM64_NCAPS
+
 #ifndef __ASSEMBLY__
 
 #include <linux/init.h>
@@ -22,12 +24,19 @@ struct alt_instr {
 	u8  alt_len;		/* size of new instruction(s), <= orig_len */
 };
 
+typedef void (*alternative_cb_t)(struct alt_instr *alt,
+				 __le32 *origptr, __le32 *updptr, int nr_inst);
+
 void __init apply_alternatives_all(void);
 void apply_alternatives(void *start, size_t length);
 
-#define ALTINSTR_ENTRY(feature)						      \
+#define ALTINSTR_ENTRY(feature,cb)					      \
 	" .word 661b - .\n"				/* label           */ \
+	" .if " __stringify(cb) " == 0\n"				      \
 	" .word 663f - .\n"				/* new instruction */ \
+	" .else\n"							      \
+	" .word " __stringify(cb) "- .\n"		/* callback */	      \
+	" .endif\n"							      \
 	" .hword " __stringify(feature) "\n"		/* feature bit     */ \
 	" .byte 662b-661b\n"				/* source len      */ \
 	" .byte 664f-663f\n"				/* replacement len */
@@ -45,15 +54,18 @@ void apply_alternatives(void *start, size_t length);
  * but most assemblers die if insn1 or insn2 have a .inst. This should
  * be fixed in a binutils release posterior to 2.25.51.0.2 (anything
  * containing commit 4e4d08cf7399b606 or c1baaddf8861).
+ *
+ * Alternatives with callbacks do not generate replacement instructions.
  */
-#define __ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg_enabled)	\
+#define __ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg_enabled, cb)	\
 	".if "__stringify(cfg_enabled)" == 1\n"				\
 	"661:\n\t"							\
 	oldinstr "\n"							\
 	"662:\n"							\
 	".pushsection .altinstructions,\"a\"\n"				\
-	ALTINSTR_ENTRY(feature)						\
+	ALTINSTR_ENTRY(feature,cb)					\
 	".popsection\n"							\
+	" .if " __stringify(cb) " == 0\n"				\
 	".pushsection .altinstr_replacement, \"a\"\n"			\
 	"663:\n\t"							\
 	newinstr "\n"							\
@@ -61,11 +73,17 @@ void apply_alternatives(void *start, size_t length);
 	".popsection\n\t"						\
 	".org	. - (664b-663b) + (662b-661b)\n\t"			\
 	".org	. - (662b-661b) + (664b-663b)\n"			\
+	".else\n\t"							\
+	"663:\n\t"							\
+	"664:\n\t"							\
+	".endif\n"							\
 	".endif\n"
 
 #define _ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg, ...)	\
-	__ALTERNATIVE_CFG(oldinstr, newinstr, feature, IS_ENABLED(cfg))
+	__ALTERNATIVE_CFG(oldinstr, newinstr, feature, IS_ENABLED(cfg), 0)
 
+#define ALTERNATIVE_CB(oldinstr, cb) \
+	__ALTERNATIVE_CFG(oldinstr, "NOT_AN_INSTRUCTION", ARM64_CB_PATCH, 1, cb)
 #else
 
 #include <asm/assembler.h>
@@ -132,6 +150,14 @@ void apply_alternatives(void *start, size_t length);
 661:
 .endm
 
+.macro alternative_cb cb
+	.set .Lasm_alt_mode, 0
+	.pushsection .altinstructions, "a"
+	altinstruction_entry 661f, \cb, ARM64_CB_PATCH, 662f-661f, 0
+	.popsection
+661:
+.endm
+
 /*
  * Provide the other half of the alternative code sequence.
  */
@@ -157,6 +183,13 @@ void apply_alternatives(void *start, size_t length);
 	.org	. - (662b-661b) + (664b-663b)
 .endm
 
+/*
+ * Callback-based alternative epilogue
+ */
+.macro alternative_cb_end
+662:
+.endm
+
 /*
  * Provides a trivial alternative or default sequence consisting solely
  * of NOPs. The number of NOPs is chosen automatically to match the

commit 6d99b68933fbcf51f84fcbba49246ce1209ec193
Author: James Morse <james.morse@arm.com>
Date:   Mon Jan 8 15:38:06 2018 +0000

    arm64: alternatives: use tpidr_el2 on VHE hosts
    
    Now that KVM uses tpidr_el2 in the same way as Linux's cpu_offset in
    tpidr_el1, merge the two. This saves KVM from save/restoring tpidr_el1
    on VHE hosts, and allows future code to blindly access per-cpu variables
    without triggering world-switch.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Christoffer Dall <cdall@linaro.org>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 4a85c6952a22..669028172fd6 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -12,6 +12,8 @@
 #include <linux/stddef.h>
 #include <linux/stringify.h>
 
+extern int alternatives_applied;
+
 struct alt_instr {
 	s32 orig_offset;	/* offset to original instruction */
 	s32 alt_offset;		/* offset to replacement instruction */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 6e1cb8c5af4d..4a85c6952a22 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __ASM_ALTERNATIVE_H
 #define __ASM_ALTERNATIVE_H
 

commit 272d01bd790fdf3f1b16372fe28136e27756756f
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Thu Nov 3 18:34:34 2016 +0000

    arm64: Fix circular include of asm/lse.h through linux/jump_label.h
    
    Commit efd9e03facd0 ("arm64: Use static keys for CPU features")
    introduced support for static keys in asm/cpufeature.h, including
    linux/jump_label.h. When CC_HAVE_ASM_GOTO is not defined, this causes a
    circular dependency via linux/atomic.h, asm/lse.h and asm/cpufeature.h.
    
    This patch moves the capability macros out out of asm/cpufeature.h into
    a separate asm/cpucaps.h and modifies some of the #includes accordingly.
    
    Fixes: efd9e03facd0 ("arm64: Use static keys for CPU features")
    Reported-by: Artem Savkov <asavkov@redhat.com>
    Tested-by: Artem Savkov <asavkov@redhat.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 39feb85a6931..6e1cb8c5af4d 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -1,7 +1,7 @@
 #ifndef __ASM_ALTERNATIVE_H
 #define __ASM_ALTERNATIVE_H
 
-#include <asm/cpufeature.h>
+#include <asm/cpucaps.h>
 #include <asm/insn.h>
 
 #ifndef __ASSEMBLY__

commit 97139d4a6f26445de47b378cddd5192c0278f863
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Tue Oct 11 13:55:58 2016 -0700

    treewide: remove redundant #include <linux/kconfig.h>
    
    Kernel source files need not include <linux/kconfig.h> explicitly
    because the top Makefile forces to include it with:
    
      -include $(srctree)/include/linux/kconfig.h
    
    This commit removes explicit includes except the following:
    
      * arch/s390/include/asm/facilities_src.h
      * tools/testing/radix-tree/linux/kernel.h
    
    These two are used for host programs.
    
    Link: http://lkml.kernel.org/r/1473656164-11929-1-git-send-email-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 55101bd86b98..39feb85a6931 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -7,7 +7,6 @@
 #ifndef __ASSEMBLY__
 
 #include <linux/init.h>
-#include <linux/kconfig.h>
 #include <linux/types.h>
 #include <linux/stddef.h>
 #include <linux/stringify.h>

commit 792d47379f4d4c76692f1795f33d38582f8907fa
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Sep 7 11:07:08 2016 +0100

    arm64: alternative: add auto-nop infrastructure
    
    In some cases, one side of an alternative sequence is simply a number of
    NOPs used to balance the other side. Keeping track of this manually is
    tedious, and the presence of large chains of NOPs makes the code more
    painful to read than necessary.
    
    To ameliorate matters, this patch adds a new alternative_else_nop_endif,
    which automatically balances an alternative sequence with a trivial NOP
    sled.
    
    In many cases, we would like a NOP-sled in the default case, and
    instructions patched in in the presence of a feature. To enable the NOPs
    to be generated automatically for this case, this patch also adds a new
    alternative_if, and updates alternative_else and alternative_endif to
    work with either alternative_if or alternative_endif.
    
    Cc: Andre Przywara <andre.przywara@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Dave Martin <dave.martin@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    [will: use new nops macro to generate nop sequences]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 8746ff6abd77..55101bd86b98 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -2,6 +2,7 @@
 #define __ASM_ALTERNATIVE_H
 
 #include <asm/cpufeature.h>
+#include <asm/insn.h>
 
 #ifndef __ASSEMBLY__
 
@@ -90,34 +91,55 @@ void apply_alternatives(void *start, size_t length);
 .endm
 
 /*
- * Begin an alternative code sequence.
+ * Alternative sequences
+ *
+ * The code for the case where the capability is not present will be
+ * assembled and linked as normal. There are no restrictions on this
+ * code.
+ *
+ * The code for the case where the capability is present will be
+ * assembled into a special section to be used for dynamic patching.
+ * Code for that case must:
+ *
+ * 1. Be exactly the same length (in bytes) as the default code
+ *    sequence.
  *
- * The code that follows this macro will be assembled and linked as
- * normal. There are no restrictions on this code.
+ * 2. Not contain a branch target that is used outside of the
+ *    alternative sequence it is defined in (branches into an
+ *    alternative sequence are not fixed up).
+ */
+
+/*
+ * Begin an alternative code sequence.
  */
 .macro alternative_if_not cap
+	.set .Lasm_alt_mode, 0
 	.pushsection .altinstructions, "a"
 	altinstruction_entry 661f, 663f, \cap, 662f-661f, 664f-663f
 	.popsection
 661:
 .endm
 
+.macro alternative_if cap
+	.set .Lasm_alt_mode, 1
+	.pushsection .altinstructions, "a"
+	altinstruction_entry 663f, 661f, \cap, 664f-663f, 662f-661f
+	.popsection
+	.pushsection .altinstr_replacement, "ax"
+	.align 2	/* So GAS knows label 661 is suitably aligned */
+661:
+.endm
+
 /*
- * Provide the alternative code sequence.
- *
- * The code that follows this macro is assembled into a special
- * section to be used for dynamic patching. Code that follows this
- * macro must:
- *
- * 1. Be exactly the same length (in bytes) as the default code
- *    sequence.
- *
- * 2. Not contain a branch target that is used outside of the
- *    alternative sequence it is defined in (branches into an
- *    alternative sequence are not fixed up).
+ * Provide the other half of the alternative code sequence.
  */
 .macro alternative_else
-662:	.pushsection .altinstr_replacement, "ax"
+662:
+	.if .Lasm_alt_mode==0
+	.pushsection .altinstr_replacement, "ax"
+	.else
+	.popsection
+	.endif
 663:
 .endm
 
@@ -125,11 +147,25 @@ void apply_alternatives(void *start, size_t length);
  * Complete an alternative code sequence.
  */
 .macro alternative_endif
-664:	.popsection
+664:
+	.if .Lasm_alt_mode==0
+	.popsection
+	.endif
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)
 .endm
 
+/*
+ * Provides a trivial alternative or default sequence consisting solely
+ * of NOPs. The number of NOPs is chosen automatically to match the
+ * previous case.
+ */
+.macro alternative_else_nop_endif
+alternative_else
+	nops	(662b-661b) / AARCH64_INSN_SIZE
+alternative_endif
+.endm
+
 #define _ALTERNATIVE_CFG(insn1, insn2, cap, cfg, ...)	\
 	alternative_insn insn1, insn2, cap, IS_ENABLED(cfg)
 

commit 290622efc76ece22ef76a30bf117755891ab27f6
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Tue Jun 28 18:07:28 2016 +0100

    arm64: fix "dc cvau" cache operation on errata-affected core
    
    The ARM errata 819472, 826319, 827319 and 824069 for affected
    Cortex-A53 cores demand to promote "dc cvau" instructions to
    "dc civac" as well.
    Attribute the usage of the instruction in __flush_cache_user_range
    to also be covered by our alternative patching efforts.
    For that we introduce an assembly macro which both deals with
    alternatives while still tagging the instructions as USER.
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 7288071195e1..8746ff6abd77 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -133,6 +133,10 @@ void apply_alternatives(void *start, size_t length);
 #define _ALTERNATIVE_CFG(insn1, insn2, cap, cfg, ...)	\
 	alternative_insn insn1, insn2, cap, IS_ENABLED(cfg)
 
+.macro user_alt, label, oldinstr, newinstr, cond
+9999:	alternative_insn "\oldinstr", "\newinstr", \cond
+	_ASM_EXTABLE 9999b, \label
+.endm
 
 /*
  * Generate the assembly for UAO alternatives with exception table entries.

commit b82bfa4793cd0f8fde49b85e0ad66906682e7447
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Tue Jun 28 18:07:27 2016 +0100

    Revert "arm64: alternatives: add enable parameter to conditional asm macros"
    
    Commit 77ee306c0aea9 ("arm64: alternatives: add enable parameter to
    conditional asm macros") extended the alternative assembly macros.
    Unfortunately this does not really work as one would expect, as the
    enable parameter in fact correctly protects the alternative section
    magic, but not the actual code sequences.
    This results in having both the original instruction(s) _and_  the
    alternative ones, if enable if false.
    Since there is no user of this macros anyway, just revert it.
    
    This reverts commit 77ee306c0aea9a219daec256ad25982944affef8.
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index beccbdefa106..7288071195e1 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -95,13 +95,11 @@ void apply_alternatives(void *start, size_t length);
  * The code that follows this macro will be assembled and linked as
  * normal. There are no restrictions on this code.
  */
-.macro alternative_if_not cap, enable = 1
-	.if \enable
+.macro alternative_if_not cap
 	.pushsection .altinstructions, "a"
 	altinstruction_entry 661f, 663f, \cap, 662f-661f, 664f-663f
 	.popsection
 661:
-	.endif
 .endm
 
 /*
@@ -118,22 +116,18 @@ void apply_alternatives(void *start, size_t length);
  *    alternative sequence it is defined in (branches into an
  *    alternative sequence are not fixed up).
  */
-.macro alternative_else, enable = 1
-	.if \enable
+.macro alternative_else
 662:	.pushsection .altinstr_replacement, "ax"
 663:
-	.endif
 .endm
 
 /*
  * Complete an alternative code sequence.
  */
-.macro alternative_endif, enable = 1
-	.if \enable
+.macro alternative_endif
 664:	.popsection
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)
-	.endif
 .endm
 
 #define _ALTERNATIVE_CFG(insn1, insn2, cap, cfg, ...)	\

commit 6c94f27ac847ff8ef15b3da5b200574923bd6287
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Fri Jan 1 15:02:12 2016 +0100

    arm64: switch to relative exception tables
    
    Instead of using absolute addresses for both the exception location
    and the fixup, use offsets relative to the exception table entry values.
    Not only does this cut the size of the exception table in half, it is
    also a prerequisite for KASLR, since absolute exception table entries
    are subject to dynamic relocation, which is incompatible with the sorting
    of the exception table that occurs at build time.
    
    This patch also introduces the _ASM_EXTABLE preprocessor macro (which
    exists on x86 as well) and its _asm_extable assembly counterpart, as
    shorthands to emit exception table entries.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index a9fc24ec1aa9..beccbdefa106 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -157,11 +157,8 @@ void apply_alternatives(void *start, size_t length);
 			add	\addr, \addr, \post_inc;
 		alternative_endif
 
-		.section __ex_table,"a";
-		.align	3;
-		.quad	8888b,\l;
-		.quad	8889b,\l;
-		.previous;
+		_asm_extable	8888b,\l;
+		_asm_extable	8889b,\l;
 	.endm
 
 	.macro uao_stp l, reg1, reg2, addr, post_inc
@@ -175,11 +172,8 @@ void apply_alternatives(void *start, size_t length);
 			add	\addr, \addr, \post_inc;
 		alternative_endif
 
-		.section __ex_table,"a";
-		.align	3;
-		.quad	8888b,\l;
-		.quad	8889b,\l;
-		.previous
+		_asm_extable	8888b,\l;
+		_asm_extable	8889b,\l;
 	.endm
 
 	.macro uao_user_alternative l, inst, alt_inst, reg, addr, post_inc
@@ -191,10 +185,7 @@ void apply_alternatives(void *start, size_t length);
 			add		\addr, \addr, \post_inc;
 		alternative_endif
 
-		.section __ex_table,"a";
-		.align	3;
-		.quad	8888b,\l;
-		.previous
+		_asm_extable	8888b,\l;
 	.endm
 #else
 	.macro uao_ldp l, reg1, reg2, addr, post_inc

commit 57f4959bad0a154aeca125b7d38d1d9471a12422
Author: James Morse <james.morse@arm.com>
Date:   Fri Feb 5 14:58:48 2016 +0000

    arm64: kernel: Add support for User Access Override
    
    'User Access Override' is a new ARMv8.2 feature which allows the
    unprivileged load and store instructions to be overridden to behave in
    the normal way.
    
    This patch converts {get,put}_user() and friends to use ldtr*/sttr*
    instructions - so that they can only access EL0 memory, then enables
    UAO when fs==KERNEL_DS so that these functions can access kernel memory.
    
    This allows user space's read/write permissions to be checked against the
    page tables, instead of testing addr<USER_DS, then using the kernel's
    read/write permissions.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    [catalin.marinas@arm.com: move uao_thread_switch() above dsb()]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index e4962f04201e..a9fc24ec1aa9 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -1,6 +1,8 @@
 #ifndef __ASM_ALTERNATIVE_H
 #define __ASM_ALTERNATIVE_H
 
+#include <asm/cpufeature.h>
+
 #ifndef __ASSEMBLY__
 
 #include <linux/init.h>
@@ -63,6 +65,8 @@ void apply_alternatives(void *start, size_t length);
 
 #else
 
+#include <asm/assembler.h>
+
 .macro altinstruction_entry orig_offset alt_offset feature orig_len alt_len
 	.word \orig_offset - .
 	.word \alt_offset - .
@@ -136,6 +140,74 @@ void apply_alternatives(void *start, size_t length);
 	alternative_insn insn1, insn2, cap, IS_ENABLED(cfg)
 
 
+/*
+ * Generate the assembly for UAO alternatives with exception table entries.
+ * This is complicated as there is no post-increment or pair versions of the
+ * unprivileged instructions, and USER() only works for single instructions.
+ */
+#ifdef CONFIG_ARM64_UAO
+	.macro uao_ldp l, reg1, reg2, addr, post_inc
+		alternative_if_not ARM64_HAS_UAO
+8888:			ldp	\reg1, \reg2, [\addr], \post_inc;
+8889:			nop;
+			nop;
+		alternative_else
+			ldtr	\reg1, [\addr];
+			ldtr	\reg2, [\addr, #8];
+			add	\addr, \addr, \post_inc;
+		alternative_endif
+
+		.section __ex_table,"a";
+		.align	3;
+		.quad	8888b,\l;
+		.quad	8889b,\l;
+		.previous;
+	.endm
+
+	.macro uao_stp l, reg1, reg2, addr, post_inc
+		alternative_if_not ARM64_HAS_UAO
+8888:			stp	\reg1, \reg2, [\addr], \post_inc;
+8889:			nop;
+			nop;
+		alternative_else
+			sttr	\reg1, [\addr];
+			sttr	\reg2, [\addr, #8];
+			add	\addr, \addr, \post_inc;
+		alternative_endif
+
+		.section __ex_table,"a";
+		.align	3;
+		.quad	8888b,\l;
+		.quad	8889b,\l;
+		.previous
+	.endm
+
+	.macro uao_user_alternative l, inst, alt_inst, reg, addr, post_inc
+		alternative_if_not ARM64_HAS_UAO
+8888:			\inst	\reg, [\addr], \post_inc;
+			nop;
+		alternative_else
+			\alt_inst	\reg, [\addr];
+			add		\addr, \addr, \post_inc;
+		alternative_endif
+
+		.section __ex_table,"a";
+		.align	3;
+		.quad	8888b,\l;
+		.previous
+	.endm
+#else
+	.macro uao_ldp l, reg1, reg2, addr, post_inc
+		USER(\l, ldp \reg1, \reg2, [\addr], \post_inc)
+	.endm
+	.macro uao_stp l, reg1, reg2, addr, post_inc
+		USER(\l, stp \reg1, \reg2, [\addr], \post_inc)
+	.endm
+	.macro uao_user_alternative l, inst, alt_inst, reg, addr, post_inc
+		USER(\l, \inst \reg, [\addr], \post_inc)
+	.endm
+#endif
+
 #endif  /*  __ASSEMBLY__  */
 
 /*

commit 9aa4ec1571da62366cfddc20f3b923609604fe63
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Dec 9 12:44:38 2015 +0000

    arm64: mm: fold alternatives into .init
    
    Currently we treat the alternatives separately from other data that's
    only used during initialisation, using separate .altinstructions and
    .altinstr_replacement linker sections. These are freed for general
    allocation separately from .init*. This is problematic as:
    
    * We do not remove execute permissions, as we do for .init, leaving the
      memory executable.
    
    * We pad between them, making the kernel Image bianry up to PAGE_SIZE
      bytes larger than necessary.
    
    This patch moves the two sections into the contiguous region used for
    .init*. This saves some memory, ensures that we remove execute
    permissions, and allows us to remove some code made redundant by this
    reorganisation.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Andre Przywara <andre.przywara@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Jeremy Linton <jeremy.linton@arm.com>
    Cc: Laura Abbott <labbott@fedoraproject.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index d56ec0715157..e4962f04201e 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -19,7 +19,6 @@ struct alt_instr {
 
 void __init apply_alternatives_all(void);
 void apply_alternatives(void *start, size_t length);
-void free_alternatives_memory(void);
 
 #define ALTINSTR_ENTRY(feature)						      \
 	" .word 661b - .\n"				/* label           */ \

commit ef5e724b25c9f90b7683bb2d45833ebac0989dcb
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Jul 28 19:07:28 2015 +0100

    arm64: alternative: put secondary CPUs into polling loop during patch
    
    When patching the kernel text with alternatives, we may end up patching
    parts of the stop_machine state machine (e.g. atomic_dec_and_test in
    ack_state) and consequently corrupt the instruction stream of any
    secondary CPUs.
    
    This patch passes the cpu_online_mask to stop_machine, forcing all of
    the CPUs into our own callback which can place the secondary cores into
    a dumb (but safe!) polling loop whilst the patching is carried out.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index b474e9106bc2..d56ec0715157 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -3,6 +3,7 @@
 
 #ifndef __ASSEMBLY__
 
+#include <linux/init.h>
 #include <linux/kconfig.h>
 #include <linux/types.h>
 #include <linux/stddef.h>
@@ -16,7 +17,7 @@ struct alt_instr {
 	u8  alt_len;		/* size of new instruction(s), <= orig_len */
 };
 
-void apply_alternatives_all(void);
+void __init apply_alternatives_all(void);
 void apply_alternatives(void *start, size_t length);
 void free_alternatives_memory(void);
 

commit 77ee306c0aea9a219daec256ad25982944affef8
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jul 23 13:51:46 2015 +0100

    arm64: alternatives: add enable parameter to conditional asm macros
    
    There are cases where we want to compile out both versions of an
    alternative code block, so add an enable parameter to the new conditional
    alternative assembly macros in the same way as alternative_insn.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 20367882226c..b474e9106bc2 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -91,11 +91,13 @@ void free_alternatives_memory(void);
  * The code that follows this macro will be assembled and linked as
  * normal. There are no restrictions on this code.
  */
-.macro alternative_if_not cap
+.macro alternative_if_not cap, enable = 1
+	.if \enable
 	.pushsection .altinstructions, "a"
 	altinstruction_entry 661f, 663f, \cap, 662f-661f, 664f-663f
 	.popsection
 661:
+	.endif
 .endm
 
 /*
@@ -112,18 +114,22 @@ void free_alternatives_memory(void);
  *    alternative sequence it is defined in (branches into an
  *    alternative sequence are not fixed up).
  */
-.macro alternative_else
+.macro alternative_else, enable = 1
+	.if \enable
 662:	.pushsection .altinstr_replacement, "ax"
 663:
+	.endif
 .endm
 
 /*
  * Complete an alternative code sequence.
  */
-.macro alternative_endif
+.macro alternative_endif, enable = 1
+	.if \enable
 664:	.popsection
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)
+	.endif
 .endm
 
 #define _ALTERNATIVE_CFG(insn1, insn2, cap, cfg, ...)	\

commit 91a5cefa2f98bdd3404c2fba57048c4fa225cc37
Author: James Morse <james.morse@arm.com>
Date:   Tue Jul 21 13:23:30 2015 +0100

    arm64: kernel: Add optional CONFIG_ parameter to ALTERNATIVE()
    
    Some uses of ALTERNATIVE() may depend on a feature that is disabled at
    compile time by a Kconfig option. In this case the unused alternative
    instructions waste space, and if the original instruction is a nop, it
    wastes time and space.
    
    This patch adds an optional 'config' option to ALTERNATIVE() and
    alternative_insn that allows the compiler to remove both the original
    and alternative instructions if the config option is not defined.
    
    Suggested-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index e86681ad0931..20367882226c 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -3,6 +3,7 @@
 
 #ifndef __ASSEMBLY__
 
+#include <linux/kconfig.h>
 #include <linux/types.h>
 #include <linux/stddef.h>
 #include <linux/stringify.h>
@@ -40,7 +41,8 @@ void free_alternatives_memory(void);
  * be fixed in a binutils release posterior to 2.25.51.0.2 (anything
  * containing commit 4e4d08cf7399b606 or c1baaddf8861).
  */
-#define ALTERNATIVE(oldinstr, newinstr, feature)			\
+#define __ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg_enabled)	\
+	".if "__stringify(cfg_enabled)" == 1\n"				\
 	"661:\n\t"							\
 	oldinstr "\n"							\
 	"662:\n"							\
@@ -53,7 +55,11 @@ void free_alternatives_memory(void);
 	"664:\n\t"							\
 	".popsection\n\t"						\
 	".org	. - (664b-663b) + (662b-661b)\n\t"			\
-	".org	. - (662b-661b) + (664b-663b)\n"
+	".org	. - (662b-661b) + (664b-663b)\n"			\
+	".endif\n"
+
+#define _ALTERNATIVE_CFG(oldinstr, newinstr, feature, cfg, ...)	\
+	__ALTERNATIVE_CFG(oldinstr, newinstr, feature, IS_ENABLED(cfg))
 
 #else
 
@@ -65,7 +71,8 @@ void free_alternatives_memory(void);
 	.byte \alt_len
 .endm
 
-.macro alternative_insn insn1 insn2 cap
+.macro alternative_insn insn1, insn2, cap, enable = 1
+	.if \enable
 661:	\insn1
 662:	.pushsection .altinstructions, "a"
 	altinstruction_entry 661b, 663f, \cap, 662b-661b, 664f-663f
@@ -75,6 +82,7 @@ void free_alternatives_memory(void);
 664:	.popsection
 	.org	. - (664b-663b) + (662b-661b)
 	.org	. - (662b-661b) + (664b-663b)
+	.endif
 .endm
 
 /*
@@ -118,6 +126,20 @@ void free_alternatives_memory(void);
 	.org	. - (662b-661b) + (664b-663b)
 .endm
 
+#define _ALTERNATIVE_CFG(insn1, insn2, cap, cfg, ...)	\
+	alternative_insn insn1, insn2, cap, IS_ENABLED(cfg)
+
+
 #endif  /*  __ASSEMBLY__  */
 
+/*
+ * Usage: asm(ALTERNATIVE(oldinstr, newinstr, feature));
+ *
+ * Usage: asm(ALTERNATIVE(oldinstr, newinstr, feature, CONFIG_FOO));
+ * N.B. If CONFIG_FOO is specified, but not selected, the whole block
+ *      will be omitted, including oldinstr.
+ */
+#define ALTERNATIVE(oldinstr, newinstr, ...)   \
+	_ALTERNATIVE_CFG(oldinstr, newinstr, __VA_ARGS__, 1)
+
 #endif /* __ASM_ALTERNATIVE_H */

commit 63e40815f02584ba8174e0f6af40924b2b335cae
Author: Daniel Thompson <daniel.thompson@linaro.org>
Date:   Wed Jul 22 12:21:01 2015 +0100

    arm64: alternative: Provide if/else/endif assembler macros
    
    The existing alternative_insn macro has some limitations that make it
    hard to work with. In particular the fact it takes instructions from it
    own macro arguments means it doesn't play very nicely with C pre-processor
    macros because the macro arguments look like a string to the C
    pre-processor. Workarounds are (probably) possible but things start to
    look ugly.
    
    Introduce an alternative set of macros that allows instructions to be
    presented to the assembler as normal and switch everything over to the
    new macros.
    
    Signed-off-by: Daniel Thompson <daniel.thompson@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index c385a0c4057f..e86681ad0931 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -77,6 +77,47 @@ void free_alternatives_memory(void);
 	.org	. - (662b-661b) + (664b-663b)
 .endm
 
+/*
+ * Begin an alternative code sequence.
+ *
+ * The code that follows this macro will be assembled and linked as
+ * normal. There are no restrictions on this code.
+ */
+.macro alternative_if_not cap
+	.pushsection .altinstructions, "a"
+	altinstruction_entry 661f, 663f, \cap, 662f-661f, 664f-663f
+	.popsection
+661:
+.endm
+
+/*
+ * Provide the alternative code sequence.
+ *
+ * The code that follows this macro is assembled into a special
+ * section to be used for dynamic patching. Code that follows this
+ * macro must:
+ *
+ * 1. Be exactly the same length (in bytes) as the default code
+ *    sequence.
+ *
+ * 2. Not contain a branch target that is used outside of the
+ *    alternative sequence it is defined in (branches into an
+ *    alternative sequence are not fixed up).
+ */
+.macro alternative_else
+662:	.pushsection .altinstr_replacement, "ax"
+663:
+.endm
+
+/*
+ * Complete an alternative code sequence.
+ */
+.macro alternative_endif
+664:	.popsection
+	.org	. - (664b-663b) + (662b-661b)
+	.org	. - (662b-661b) + (664b-663b)
+.endm
+
 #endif  /*  __ASSEMBLY__  */
 
 #endif /* __ASM_ALTERNATIVE_H */

commit eb7c11ee3c5ce6c45ac28a5015a8e60ed458b412
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Jun 1 10:47:42 2015 +0100

    arm64: alternative: Work around .inst assembler bugs
    
    AArch64 toolchains suffer from the following bug:
    
    $ cat blah.S
    1:
            .inst   0x01020304
            .if ((. - 1b) != 4)
                    .error  "blah"
            .endif
    $ aarch64-linux-gnu-gcc -c blah.S
    blah.S: Assembler messages:
    blah.S:3: Error: non-constant expression in ".if" statement
    
    which precludes the use of msr_s and co as part of alternatives.
    
    We workaround this issue by not directly testing the labels
    themselves, but by moving the current output pointer by a value
    that should always be zero. If this value is not null, then
    we will trigger a backward move, which is expclicitely forbidden.
    This triggers the error we're after:
    
      AS      arch/arm64/kvm/hyp.o
    arch/arm64/kvm/hyp.S: Assembler messages:
    arch/arm64/kvm/hyp.S:1377: Error: attempt to move .org backwards
    scripts/Makefile.build:294: recipe for target 'arch/arm64/kvm/hyp.o' failed
    make[1]: *** [arch/arm64/kvm/hyp.o] Error 1
    Makefile:946: recipe for target 'arch/arm64/kvm' failed
    
    Not pretty, but at least works on the current toolchains.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index 265b13ea02ee..c385a0c4057f 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -26,7 +26,20 @@ void free_alternatives_memory(void);
 	" .byte 662b-661b\n"				/* source len      */ \
 	" .byte 664f-663f\n"				/* replacement len */
 
-/* alternative assembly primitive: */
+/*
+ * alternative assembly primitive:
+ *
+ * If any of these .org directive fail, it means that insn1 and insn2
+ * don't have the same length. This used to be written as
+ *
+ * .if ((664b-663b) != (662b-661b))
+ * 	.error "Alternatives instruction length mismatch"
+ * .endif
+ *
+ * but most assemblers die if insn1 or insn2 have a .inst. This should
+ * be fixed in a binutils release posterior to 2.25.51.0.2 (anything
+ * containing commit 4e4d08cf7399b606 or c1baaddf8861).
+ */
 #define ALTERNATIVE(oldinstr, newinstr, feature)			\
 	"661:\n\t"							\
 	oldinstr "\n"							\
@@ -39,9 +52,8 @@ void free_alternatives_memory(void);
 	newinstr "\n"							\
 	"664:\n\t"							\
 	".popsection\n\t"						\
-	".if ((664b-663b) != (662b-661b))\n\t"				\
-	"	.error \"Alternatives instruction length mismatch\"\n\t"\
-	".endif\n"
+	".org	. - (664b-663b) + (662b-661b)\n\t"			\
+	".org	. - (662b-661b) + (664b-663b)\n"
 
 #else
 
@@ -61,9 +73,8 @@ void free_alternatives_memory(void);
 	.pushsection .altinstr_replacement, "ax"
 663:	\insn2
 664:	.popsection
-	.if ((664b-663b) != (662b-661b))
-		.error "Alternatives instruction length mismatch"
-	.endif
+	.org	. - (664b-663b) + (662b-661b)
+	.org	. - (662b-661b) + (664b-663b)
 .endm
 
 #endif  /*  __ASSEMBLY__  */

commit 8d883b23aed73cad844ba48051c7e96eddf0f51c
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Jun 1 10:47:41 2015 +0100

    arm64: alternative: Merge alternative-asm.h into alternative.h
    
    asm/alternative-asm.h and asm/alternative.h are extremely similar,
    and really deserve to live in the same file (as this makes further
    modufications a bit easier).
    
    Fold the content of alternative-asm.h into alternative.h, and
    update the few users.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index d261f01e2bae..265b13ea02ee 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -1,6 +1,8 @@
 #ifndef __ASM_ALTERNATIVE_H
 #define __ASM_ALTERNATIVE_H
 
+#ifndef __ASSEMBLY__
+
 #include <linux/types.h>
 #include <linux/stddef.h>
 #include <linux/stringify.h>
@@ -41,4 +43,29 @@ void free_alternatives_memory(void);
 	"	.error \"Alternatives instruction length mismatch\"\n\t"\
 	".endif\n"
 
+#else
+
+.macro altinstruction_entry orig_offset alt_offset feature orig_len alt_len
+	.word \orig_offset - .
+	.word \alt_offset - .
+	.hword \feature
+	.byte \orig_len
+	.byte \alt_len
+.endm
+
+.macro alternative_insn insn1 insn2 cap
+661:	\insn1
+662:	.pushsection .altinstructions, "a"
+	altinstruction_entry 661b, 663f, \cap, 662b-661b, 664f-663f
+	.popsection
+	.pushsection .altinstr_replacement, "ax"
+663:	\insn2
+664:	.popsection
+	.if ((664b-663b) != (662b-661b))
+		.error "Alternatives instruction length mismatch"
+	.endif
+.endm
+
+#endif  /*  __ASSEMBLY__  */
+
 #endif /* __ASM_ALTERNATIVE_H */

commit 932ded4b0b9bf111fbf9d176ec12152a0d29b0fd
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Fri Nov 28 13:40:45 2014 +0000

    arm64: add module support for alternatives fixups
    
    Currently the kernel patches all necessary instructions once at boot
    time, so modules are not covered by this.
    Change the apply_alternatives() function to take a beginning and an
    end pointer and introduce a new variant (apply_alternatives_all()) to
    cover the existing use case for the static kernel image section.
    Add a module_finalize() function to arm64 to check for an
    alternatives section in a module and patch only the instructions from
    that specific area.
    Since that module code is not touched before the module
    initialization has ended, we don't need to halt the machine before
    doing the patching in the module's code.
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
index f6d206e7f9e9..d261f01e2bae 100644
--- a/arch/arm64/include/asm/alternative.h
+++ b/arch/arm64/include/asm/alternative.h
@@ -13,7 +13,8 @@ struct alt_instr {
 	u8  alt_len;		/* size of new instruction(s), <= orig_len */
 };
 
-void apply_alternatives(void);
+void apply_alternatives_all(void);
+void apply_alternatives(void *start, size_t length);
 void free_alternatives_memory(void);
 
 #define ALTINSTR_ENTRY(feature)						      \

commit e039ee4ee3fcf174736f2cb0a2eed6cb908348a6
Author: Andre Przywara <andre.przywara@arm.com>
Date:   Fri Nov 14 15:54:08 2014 +0000

    arm64: add alternative runtime patching
    
    With a blatant copy of some x86 bits we introduce the alternative
    runtime patching "framework" to arm64.
    This is quite basic for now and we only provide the functions we need
    at this time.
    This is connected to the newly introduced feature bits.
    
    Signed-off-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/alternative.h b/arch/arm64/include/asm/alternative.h
new file mode 100644
index 000000000000..f6d206e7f9e9
--- /dev/null
+++ b/arch/arm64/include/asm/alternative.h
@@ -0,0 +1,43 @@
+#ifndef __ASM_ALTERNATIVE_H
+#define __ASM_ALTERNATIVE_H
+
+#include <linux/types.h>
+#include <linux/stddef.h>
+#include <linux/stringify.h>
+
+struct alt_instr {
+	s32 orig_offset;	/* offset to original instruction */
+	s32 alt_offset;		/* offset to replacement instruction */
+	u16 cpufeature;		/* cpufeature bit set for replacement */
+	u8  orig_len;		/* size of original instruction(s) */
+	u8  alt_len;		/* size of new instruction(s), <= orig_len */
+};
+
+void apply_alternatives(void);
+void free_alternatives_memory(void);
+
+#define ALTINSTR_ENTRY(feature)						      \
+	" .word 661b - .\n"				/* label           */ \
+	" .word 663f - .\n"				/* new instruction */ \
+	" .hword " __stringify(feature) "\n"		/* feature bit     */ \
+	" .byte 662b-661b\n"				/* source len      */ \
+	" .byte 664f-663f\n"				/* replacement len */
+
+/* alternative assembly primitive: */
+#define ALTERNATIVE(oldinstr, newinstr, feature)			\
+	"661:\n\t"							\
+	oldinstr "\n"							\
+	"662:\n"							\
+	".pushsection .altinstructions,\"a\"\n"				\
+	ALTINSTR_ENTRY(feature)						\
+	".popsection\n"							\
+	".pushsection .altinstr_replacement, \"a\"\n"			\
+	"663:\n\t"							\
+	newinstr "\n"							\
+	"664:\n\t"							\
+	".popsection\n\t"						\
+	".if ((664b-663b) != (662b-661b))\n\t"				\
+	"	.error \"Alternatives instruction length mismatch\"\n\t"\
+	".endif\n"
+
+#endif /* __ASM_ALTERNATIVE_H */
