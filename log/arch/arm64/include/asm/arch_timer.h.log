commit c1fbec4ac0d701f350a581941d35643d5a9cd184
Author: Marc Zyngier <maz@kernel.org>
Date:   Mon Jul 6 17:38:00 2020 +0100

    arm64: arch_timer: Allow an workaround descriptor to disable compat vdso
    
    As we are about to disable the vdso for compat tasks in some circumstances,
    let's allow a workaround descriptor to express exactly that.
    
    Signed-off-by: Marc Zyngier <maz@kernel.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20200706163802.1836732-3-maz@kernel.org
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 7ae54d7d333a..9f0ec21d6327 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -58,6 +58,7 @@ struct arch_timer_erratum_workaround {
 	u64 (*read_cntvct_el0)(void);
 	int (*set_next_event_phys)(unsigned long, struct clock_event_device *);
 	int (*set_next_event_virt)(unsigned long, struct clock_event_device *);
+	bool disable_compat_vdso;
 };
 
 DECLARE_PER_CPU(const struct arch_timer_erratum_workaround *,

commit 341924049558e5f7c1a148a2c461a417933d35d9
Merge: 516337048fa4 4a8f81b8c053
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 3 10:50:21 2019 +0200

    Merge branch 'timers/vdso' into timers/core
    
    so the hyper-v clocksource update can be applied.

commit 5a354412567d7de81d69b6ac61c3b7fcebbe497e
Author: Andrew Murray <andrew.murray@arm.com>
Date:   Thu Jun 13 13:51:02 2019 +0100

    clocksource/drivers/arm_arch_timer: Extract elf_hwcap use to arch-helper
    
    Different mechanisms are used to test and set elf_hwcaps between ARM
    and ARM64, this results in the use of ifdeferry in this file when
    setting/testing for the EVTSTRM hwcap.
    
    Let's improve readability by extracting this to an arch helper.
    
    Signed-off-by: Andrew Murray <andrew.murray@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 50b3ab7ded4f..a847a3ee6cab 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -20,6 +20,7 @@
 #define __ASM_ARCH_TIMER_H
 
 #include <asm/barrier.h>
+#include <asm/hwcap.h>
 #include <asm/sysreg.h>
 
 #include <linux/bug.h>
@@ -240,4 +241,16 @@ static inline int arch_timer_arch_init(void)
 	return 0;
 }
 
+static inline void arch_timer_set_evtstrm_feature(void)
+{
+	cpu_set_named_feature(EVTSTRM);
+#ifdef CONFIG_COMPAT
+	compat_elf_hwcap |= COMPAT_HWCAP_EVTSTRM;
+#endif
+}
+
+static inline bool arch_timer_have_evtstrm_feature(void)
+{
+	return cpu_have_named_feature(EVTSTRM);
+}
 #endif

commit caab277b1de0a22b675c4c95fc7b285ec2eb5bf5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 3 07:44:50 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 234
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not see http www gnu org
      licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 503 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190602204653.811534538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 50b3ab7ded4f..6756178c27db 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -1,20 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * arch/arm64/include/asm/arch_timer.h
  *
  * Copyright (C) 2012 ARM Ltd.
  * Author: Marc Zyngier <marc.zyngier@arm.com>
- *
- * This program is free software: you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #ifndef __ASM_ARCH_TIMER_H
 #define __ASM_ARCH_TIMER_H

commit f31e98bfae1c8792701ef03acd47344866cb2e14
Author: Anders Roxell <anders.roxell@linaro.org>
Date:   Mon Jun 3 11:14:02 2019 +0200

    arm64: arch_timer: mark functions as __always_inline
    
    If CONFIG_FUNCTION_GRAPH_TRACER is enabled function
    arch_counter_get_cntvct() is marked as notrace. However, function
    __arch_counter_get_cntvct is marked as inline. If
    CONFIG_OPTIMIZE_INLINING is set that will make the two functions
    tracable which they shouldn't.
    
    Rework so that functions __arch_counter_get_* are marked with
    __always_inline so they will be inlined even if CONFIG_OPTIMIZE_INLINING
    is turned on.
    
    Fixes: 0ea415390cd3 ("clocksource/arm_arch_timer: Use arch_timer_read_counter to access stable counters")
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Anders Roxell <anders.roxell@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index b7bca1ae09e6..50b3ab7ded4f 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -193,7 +193,7 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	: "=r" (tmp) : "r" (_val));					\
 } while (0)
 
-static inline u64 __arch_counter_get_cntpct_stable(void)
+static __always_inline u64 __arch_counter_get_cntpct_stable(void)
 {
 	u64 cnt;
 
@@ -203,7 +203,7 @@ static inline u64 __arch_counter_get_cntpct_stable(void)
 	return cnt;
 }
 
-static inline u64 __arch_counter_get_cntpct(void)
+static __always_inline u64 __arch_counter_get_cntpct(void)
 {
 	u64 cnt;
 
@@ -213,7 +213,7 @@ static inline u64 __arch_counter_get_cntpct(void)
 	return cnt;
 }
 
-static inline u64 __arch_counter_get_cntvct_stable(void)
+static __always_inline u64 __arch_counter_get_cntvct_stable(void)
 {
 	u64 cnt;
 
@@ -223,7 +223,7 @@ static inline u64 __arch_counter_get_cntvct_stable(void)
 	return cnt;
 }
 
-static inline u64 __arch_counter_get_cntvct(void)
+static __always_inline u64 __arch_counter_get_cntvct(void)
 {
 	u64 cnt;
 

commit 24cf262da1ad303fc940c798aab0bd1bd50e3fc2
Merge: 50abbe19623e 0ea415390cd3
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed May 1 15:45:36 2019 +0100

    Merge branch 'for-next/timers' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux into for-next/core
    
    Conflicts:
            arch/arm64/Kconfig
            arch/arm64/include/asm/arch_timer.h

commit 0ea415390cd345b7d09e8c9ebd4b68adfe873043
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Apr 8 16:49:07 2019 +0100

    clocksource/arm_arch_timer: Use arch_timer_read_counter to access stable counters
    
    Instead of always going via arch_counter_get_cntvct_stable to access the
    counter workaround, let's have arch_timer_read_counter point to the
    right method.
    
    For that, we need to track whether any CPU in the system has a
    workaround for the counter. This is done by having an atomic variable
    tracking this.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 5502ea049b63..48b2100f4aaa 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -174,18 +174,30 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	isb();
 }
 
-static inline u64 arch_counter_get_cntpct(void)
+static inline u64 __arch_counter_get_cntpct_stable(void)
 {
 	isb();
 	return arch_timer_reg_read_stable(cntpct_el0);
 }
 
-static inline u64 arch_counter_get_cntvct(void)
+static inline u64 __arch_counter_get_cntpct(void)
+{
+	isb();
+	return read_sysreg(cntpct_el0);
+}
+
+static inline u64 __arch_counter_get_cntvct_stable(void)
 {
 	isb();
 	return arch_timer_reg_read_stable(cntvct_el0);
 }
 
+static inline u64 __arch_counter_get_cntvct(void)
+{
+	isb();
+	return read_sysreg(cntvct_el0);
+}
+
 static inline int arch_timer_arch_init(void)
 {
 	return 0;

commit a862fc2254bdbcee3b5da4f730984e5d8393a2f1
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Apr 8 16:49:06 2019 +0100

    clocksource/arm_arch_timer: Remove use of workaround static key
    
    The use of a static key in a hotplug path has proved to be a real
    nightmare, and makes it impossible to have scream-free lockdep
    kernel.
    
    Let's remove the static key altogether, and focus on something saner.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 4a06d46def7e..5502ea049b63 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -45,13 +45,9 @@
 		(__wa && __wa->h) ? __wa->h : arch_timer_##h;		\
 	})
 
-extern struct static_key_false arch_timer_read_ool_enabled;
-#define needs_unstable_timer_counter_workaround() \
-	static_branch_unlikely(&arch_timer_read_ool_enabled)
 #else
 #define has_erratum_handler(h)			   false
 #define erratum_handler(h)			   (arch_timer_##h)
-#define needs_unstable_timer_counter_workaround()  false
 #endif
 
 enum arch_timer_erratum_match_type {

commit 57f27666f91a85431492b092f5db53ecab1a0739
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Apr 8 16:49:05 2019 +0100

    clocksource/arm_arch_timer: Drop use of static key in arch_timer_reg_read_stable
    
    Let's start with the removal of the arch_timer_read_ool_enabled
    static key in arch_timer_reg_read_stable. It is not a fast path,
    and we can simplify things a bit.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index c3762ffcc933..4a06d46def7e 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -77,23 +77,37 @@ struct arch_timer_erratum_workaround {
 DECLARE_PER_CPU(const struct arch_timer_erratum_workaround *,
 		timer_unstable_counter_workaround);
 
+/* inline sysreg accessors that make erratum_handler() work */
+static inline notrace u32 arch_timer_read_cntp_tval_el0(void)
+{
+	return read_sysreg(cntp_tval_el0);
+}
+
+static inline notrace u32 arch_timer_read_cntv_tval_el0(void)
+{
+	return read_sysreg(cntv_tval_el0);
+}
+
+static inline notrace u64 arch_timer_read_cntpct_el0(void)
+{
+	return read_sysreg(cntpct_el0);
+}
+
+static inline notrace u64 arch_timer_read_cntvct_el0(void)
+{
+	return read_sysreg(cntvct_el0);
+}
+
 #define arch_timer_reg_read_stable(reg)					\
-({									\
-	u64 _val;							\
-	if (needs_unstable_timer_counter_workaround()) {		\
-		const struct arch_timer_erratum_workaround *wa;		\
+	({								\
+		u64 _val;						\
+									\
 		preempt_disable_notrace();				\
-		wa = __this_cpu_read(timer_unstable_counter_workaround); \
-		if (wa && wa->read_##reg)				\
-			_val = wa->read_##reg();			\
-		else							\
-			_val = read_sysreg(reg);			\
+		_val = erratum_handler(read_ ## reg)();			\
 		preempt_enable_notrace();				\
-	} else {							\
-		_val = read_sysreg(reg);				\
-	}								\
-	_val;								\
-})
+									\
+		_val;							\
+	})
 
 /*
  * These register accessors are marked inline so the compiler can

commit 5ef19a161cfa88a59508979e2f39d3d092c1d5c0
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Apr 8 16:49:04 2019 +0100

    clocksource/arm_arch_timer: Direcly assign set_next_event workaround
    
    When a given timer is affected by an erratum and requires an
    alternative implementation of set_next_event, we do a rather
    complicated dance to detect and call the workaround on each
    set_next_event call.
    
    This is clearly idiotic, as we can perfectly detect whether
    this CPU requires a workaround while setting up the clock event
    device.
    
    This only requires the CPU-specific detection to be done a bit
    earlier, and we can then safely override the set_next_event pointer
    if we have a workaround associated to that CPU.
    
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by; Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index f2a234d6516c..c3762ffcc933 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -31,10 +31,26 @@
 #include <clocksource/arm_arch_timer.h>
 
 #if IS_ENABLED(CONFIG_ARM_ARCH_TIMER_OOL_WORKAROUND)
+#define has_erratum_handler(h)						\
+	({								\
+		const struct arch_timer_erratum_workaround *__wa;	\
+		__wa = __this_cpu_read(timer_unstable_counter_workaround); \
+		(__wa && __wa->h);					\
+	})
+
+#define erratum_handler(h)						\
+	({								\
+		const struct arch_timer_erratum_workaround *__wa;	\
+		__wa = __this_cpu_read(timer_unstable_counter_workaround); \
+		(__wa && __wa->h) ? __wa->h : arch_timer_##h;		\
+	})
+
 extern struct static_key_false arch_timer_read_ool_enabled;
 #define needs_unstable_timer_counter_workaround() \
 	static_branch_unlikely(&arch_timer_read_ool_enabled)
 #else
+#define has_erratum_handler(h)			   false
+#define erratum_handler(h)			   (arch_timer_##h)
 #define needs_unstable_timer_counter_workaround()  false
 #endif
 

commit 75a19a0202db21638a1c2b424afb867e1f9a2376
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Apr 29 17:26:22 2019 +0100

    arm64: arch_timer: Ensure counter register reads occur with seqlock held
    
    When executing clock_gettime(), either in the vDSO or via a system call,
    we need to ensure that the read of the counter register occurs within
    the seqlock reader critical section. This ensures that updates to the
    clocksource parameters (e.g. the multiplier) are consistent with the
    counter value and therefore avoids the situation where time appears to
    go backwards across multiple reads.
    
    Extend the vDSO logic so that the seqlock critical section covers the
    read of the counter register as well as accesses to the data page. Since
    reads of the counter system registers are not ordered by memory barrier
    instructions, introduce dependency ordering from the counter read to a
    subsequent memory access so that the seqlock memory barriers apply to
    the counter access in both the vDSO and the system call paths.
    
    Cc: <stable@vger.kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/linux-arm-kernel/alpine.DEB.2.21.1902081950260.1662@nanos.tec.linutronix.de/
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index f2a234d6516c..93e07512b4b6 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -148,18 +148,47 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	isb();
 }
 
+/*
+ * Ensure that reads of the counter are treated the same as memory reads
+ * for the purposes of ordering by subsequent memory barriers.
+ *
+ * This insanity brought to you by speculative system register reads,
+ * out-of-order memory accesses, sequence locks and Thomas Gleixner.
+ *
+ * http://lists.infradead.org/pipermail/linux-arm-kernel/2019-February/631195.html
+ */
+#define arch_counter_enforce_ordering(val) do {				\
+	u64 tmp, _val = (val);						\
+									\
+	asm volatile(							\
+	"	eor	%0, %1, %1\n"					\
+	"	add	%0, sp, %0\n"					\
+	"	ldr	xzr, [%0]"					\
+	: "=r" (tmp) : "r" (_val));					\
+} while (0)
+
 static inline u64 arch_counter_get_cntpct(void)
 {
+	u64 cnt;
+
 	isb();
-	return arch_timer_reg_read_stable(cntpct_el0);
+	cnt = arch_timer_reg_read_stable(cntpct_el0);
+	arch_counter_enforce_ordering(cnt);
+	return cnt;
 }
 
 static inline u64 arch_counter_get_cntvct(void)
 {
+	u64 cnt;
+
 	isb();
-	return arch_timer_reg_read_stable(cntvct_el0);
+	cnt = arch_timer_reg_read_stable(cntvct_el0);
+	arch_counter_enforce_ordering(cnt);
+	return cnt;
 }
 
+#undef arch_counter_enforce_ordering
+
 static inline int arch_timer_arch_init(void)
 {
 	return 0;

commit 974aa5630b318938273d7efe7a2cf031c7b927db
Merge: 441692aafc17 a6014f1ab708
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 16 13:00:24 2017 -0800

    Merge tag 'kvm-4.15-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Radim Krčmář:
     "First batch of KVM changes for 4.15
    
      Common:
       - Python 3 support in kvm_stat
       - Accounting of slabs to kmemcg
    
      ARM:
       - Optimized arch timer handling for KVM/ARM
       - Improvements to the VGIC ITS code and introduction of an ITS reset
         ioctl
       - Unification of the 32-bit fault injection logic
       - More exact external abort matching logic
    
      PPC:
       - Support for running hashed page table (HPT) MMU mode on a host that
         is using the radix MMU mode; single threaded mode on POWER 9 is
         added as a pre-requisite
       - Resolution of merge conflicts with the last second 4.14 HPT fixes
       - Fixes and cleanups
    
      s390:
       - Some initial preparation patches for exitless interrupts and crypto
       - New capability for AIS migration
       - Fixes
    
      x86:
       - Improved emulation of LAPIC timer mode changes, MCi_STATUS MSRs,
         and after-reset state
       - Refined dependencies for VMX features
       - Fixes for nested SMI injection
       - A lot of cleanups"
    
    * tag 'kvm-4.15-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (89 commits)
      KVM: s390: provide a capability for AIS state migration
      KVM: s390: clear_io_irq() requests are not expected for adapter interrupts
      KVM: s390: abstract conversion between isc and enum irq_types
      KVM: s390: vsie: use common code functions for pinning
      KVM: s390: SIE considerations for AP Queue virtualization
      KVM: s390: document memory ordering for kvm_s390_vcpu_wakeup
      KVM: PPC: Book3S HV: Cosmetic post-merge cleanups
      KVM: arm/arm64: fix the incompatible matching for external abort
      KVM: arm/arm64: Unify 32bit fault injection
      KVM: arm/arm64: vgic-its: Implement KVM_DEV_ARM_ITS_CTRL_RESET
      KVM: arm/arm64: Document KVM_DEV_ARM_ITS_CTRL_RESET
      KVM: arm/arm64: vgic-its: Free caches when GITS_BASER Valid bit is cleared
      KVM: arm/arm64: vgic-its: New helper functions to free the caches
      KVM: arm/arm64: vgic-its: Remove kvm_its_unmap_device
      arm/arm64: KVM: Load the timer state when enabling the timer
      KVM: arm/arm64: Rework kvm_timer_should_fire
      KVM: arm/arm64: Get rid of kvm_timer_flush_hwstate
      KVM: arm/arm64: Avoid phys timer emulation in vcpu entry/exit
      KVM: arm/arm64: Move phys_timer_emulate function
      KVM: arm/arm64: Use kvm_arm_timer_set/get_reg for guest register traps
      ...

commit f2e600c149fda3453344f89c7e9353fe278ebd32
Author: Christoffer Dall <christoffer.dall@linaro.org>
Date:   Wed Oct 18 13:06:25 2017 +0200

    arm64: Implement arch_counter_get_cntpct to read the physical counter
    
    As we are about to use the physical counter on arm64 systems that have
    KVM support, implement arch_counter_get_cntpct() and the associated
    errata workaround functionality for stable timer reads.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@linaro.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index a652ce0a5cb2..04275de614db 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -52,6 +52,7 @@ struct arch_timer_erratum_workaround {
 	const char *desc;
 	u32 (*read_cntp_tval_el0)(void);
 	u32 (*read_cntv_tval_el0)(void);
+	u64 (*read_cntpct_el0)(void);
 	u64 (*read_cntvct_el0)(void);
 	int (*set_next_event_phys)(unsigned long, struct clock_event_device *);
 	int (*set_next_event_virt)(unsigned long, struct clock_event_device *);
@@ -148,11 +149,8 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 
 static inline u64 arch_counter_get_cntpct(void)
 {
-	/*
-	 * AArch64 kernel and user space mandate the use of CNTVCT.
-	 */
-	BUG();
-	return 0;
+	isb();
+	return arch_timer_reg_read_stable(cntpct_el0);
 }
 
 static inline u64 arch_counter_get_cntvct(void)

commit ec5c8e429d07737ee94ee1fd2ae5029547484194
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Fri Oct 13 14:32:55 2017 +0100

    arm_arch_timer: Expose event stream status
    
    The arch timer configuration for a CPU might get reset after suspending
    said CPU.
    
    In order to reliably use the event stream in the kernel (e.g. for delays),
    we keep track of the state where we can safely consider the event stream as
    properly configured. After writing to cntkctl, we issue an ISB to ensure
    that subsequent delay loops can rely on the event stream being enabled.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index a652ce0a5cb2..bdedd8f748d1 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -144,6 +144,7 @@ static inline u32 arch_timer_get_cntkctl(void)
 static inline void arch_timer_set_cntkctl(u32 cntkctl)
 {
 	write_sysreg(cntkctl, cntkctl_el1);
+	isb();
 }
 
 static inline u64 arch_counter_get_cntpct(void)

commit adb4f11e0a8f4e29900adb2b7af28b6bbd5c1fa4
Author: Ding Tianhong <dingtianhong@huawei.com>
Date:   Thu Aug 10 10:52:45 2017 +0800

    clocksource/drivers/arm_arch_timer: Avoid infinite recursion when ftrace is enabled
    
    On platforms with an arch timer erratum workaround, it's possible for
    arch_timer_reg_read_stable() to recurse into itself when certain
    tracing options are enabled, leading to stack overflows and related
    problems.
    
    For example, when PREEMPT_TRACER and FUNCTION_GRAPH_TRACER are
    selected, it's possible to trigger this with:
    
    $ mount -t debugfs nodev /sys/kernel/debug/
    $ echo function_graph > /sys/kernel/debug/tracing/current_tracer
    
    The problem is that in such cases, preempt_disable() instrumentation
    attempts to acquire a timestamp via trace_clock(), resulting in a call
    back to arch_timer_reg_read_stable(), and hence recursion.
    
    This patch changes arch_timer_reg_read_stable() to use
    preempt_{disable,enable}_notrace(), which avoids this.
    
    This problem is similar to the fixed by upstream commit 96b3d28bf4
    ("sched/clock: Prevent tracing recursion in sched_clock_cpu()").
    
    Fixes: 6acc71ccac71 ("arm64: arch_timer: Allows a CPU-specific erratum to only affect a subset of CPUs")
    Signed-off-by: Ding Tianhong <dingtianhong@huawei.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 74d08e44a651..a652ce0a5cb2 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -65,13 +65,13 @@ DECLARE_PER_CPU(const struct arch_timer_erratum_workaround *,
 	u64 _val;							\
 	if (needs_unstable_timer_counter_workaround()) {		\
 		const struct arch_timer_erratum_workaround *wa;		\
-		preempt_disable();					\
+		preempt_disable_notrace();				\
 		wa = __this_cpu_read(timer_unstable_counter_workaround); \
 		if (wa && wa->read_##reg)				\
 			_val = wa->read_##reg();			\
 		else							\
 			_val = read_sysreg(reg);			\
-		preempt_enable();					\
+		preempt_enable_notrace();				\
 	} else {							\
 		_val = read_sysreg(reg);				\
 	}								\

commit 5a38bcac1f2f0bd0d24700690e36a277ffd0396d
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Tue Feb 21 14:37:30 2017 +0000

    arm64: arch_timer: Allow erratum matching with ACPI OEM information
    
    Just as we're able to identify a broken platform using some DT
    information, let's enable a way to spot the offenders with ACPI.
    
    The difference is that we can only match on some OEM info instead
    of implementation-specific properties. So in order to avoid the
    insane multiplication of errata structures, we allow an array
    of OEM descriptions to be attached to an erratum structure.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: dann frazier <dann.frazier@canonical.com>
    Tested-by: Hanjun Guo <hanjun.guo@linaro.org>
    Reviewed-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 6bd1a9a1573a..74d08e44a651 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -41,6 +41,7 @@ extern struct static_key_false arch_timer_read_ool_enabled;
 enum arch_timer_erratum_match_type {
 	ate_match_dt,
 	ate_match_local_cap_id,
+	ate_match_acpi_oem_info,
 };
 
 struct clock_event_device;

commit 6acc71ccac7187fc0ef85f10bd09c2058f21fab5
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Feb 20 18:34:48 2017 +0000

    arm64: arch_timer: Allows a CPU-specific erratum to only affect a subset of CPUs
    
    Instead of applying a CPU-specific workaround to all CPUs in the system,
    allow it to only affect a subset of them (typical big-little case).
    
    This is done by turning the erratum pointer into a per-CPU variable.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 01917b4c65ca..6bd1a9a1573a 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -25,6 +25,7 @@
 #include <linux/bug.h>
 #include <linux/init.h>
 #include <linux/jump_label.h>
+#include <linux/smp.h>
 #include <linux/types.h>
 
 #include <clocksource/arm_arch_timer.h>
@@ -55,17 +56,25 @@ struct arch_timer_erratum_workaround {
 	int (*set_next_event_virt)(unsigned long, struct clock_event_device *);
 };
 
-extern const struct arch_timer_erratum_workaround *timer_unstable_counter_workaround;
-
-#define arch_timer_reg_read_stable(reg) 		\
-({							\
-	u64 _val;					\
-	if (needs_unstable_timer_counter_workaround() &&		\
-	    timer_unstable_counter_workaround->read_##reg)		\
-		_val = timer_unstable_counter_workaround->read_##reg();	\
-	else						\
-		_val = read_sysreg(reg);		\
-	_val;						\
+DECLARE_PER_CPU(const struct arch_timer_erratum_workaround *,
+		timer_unstable_counter_workaround);
+
+#define arch_timer_reg_read_stable(reg)					\
+({									\
+	u64 _val;							\
+	if (needs_unstable_timer_counter_workaround()) {		\
+		const struct arch_timer_erratum_workaround *wa;		\
+		preempt_disable();					\
+		wa = __this_cpu_read(timer_unstable_counter_workaround); \
+		if (wa && wa->read_##reg)				\
+			_val = wa->read_##reg();			\
+		else							\
+			_val = read_sysreg(reg);			\
+		preempt_enable();					\
+	} else {							\
+		_val = read_sysreg(reg);				\
+	}								\
+	_val;								\
 })
 
 /*

commit 8c64621bf9501902a3086a5e38135344b3161128
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Jan 27 10:34:13 2017 +0000

    arm64: arch_timer: Make workaround methods optional
    
    Not all errata need to workaround all access types. Allow them to
    be optional.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index cc1e08127fb4..01917b4c65ca 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -60,8 +60,9 @@ extern const struct arch_timer_erratum_workaround *timer_unstable_counter_workar
 #define arch_timer_reg_read_stable(reg) 		\
 ({							\
 	u64 _val;					\
-	if (needs_unstable_timer_counter_workaround())		\
-		_val = timer_unstable_counter_workaround->read_##reg();\
+	if (needs_unstable_timer_counter_workaround() &&		\
+	    timer_unstable_counter_workaround->read_##reg)		\
+		_val = timer_unstable_counter_workaround->read_##reg();	\
 	else						\
 		_val = read_sysreg(reg);		\
 	_val;						\

commit 01d3e3ff26080040cb02ec4989a0da36d069f1e9
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Jan 27 10:27:09 2017 +0000

    arm64: arch_timer: Rework the set_next_event workarounds
    
    The way we work around errata affecting set_next_event is not very
    nice, at it imposes this workaround on errata that do not need it.
    
    Add new workaround hooks and let the existing workarounds use them.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 1b0d7e994e0c..cc1e08127fb4 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -42,6 +42,8 @@ enum arch_timer_erratum_match_type {
 	ate_match_local_cap_id,
 };
 
+struct clock_event_device;
+
 struct arch_timer_erratum_workaround {
 	enum arch_timer_erratum_match_type match_type;
 	const void *id;
@@ -49,6 +51,8 @@ struct arch_timer_erratum_workaround {
 	u32 (*read_cntp_tval_el0)(void);
 	u32 (*read_cntv_tval_el0)(void);
 	u64 (*read_cntvct_el0)(void);
+	int (*set_next_event_phys)(unsigned long, struct clock_event_device *);
+	int (*set_next_event_virt)(unsigned long, struct clock_event_device *);
 };
 
 extern const struct arch_timer_erratum_workaround *timer_unstable_counter_workaround;

commit 0064030c6fd4ca6cfab42de037b2a89445beeead
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Mar 20 16:47:59 2017 +0000

    arm64: arch_timer: Add erratum handler for CPU-specific capability
    
    Should we ever have a workaround for an erratum that is detected using
    a capability and affecting a particular CPU, it'd be nice to have
    a way to probe them directly.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 5cd964e90d11..1b0d7e994e0c 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -39,6 +39,7 @@ extern struct static_key_false arch_timer_read_ool_enabled;
 
 enum arch_timer_erratum_match_type {
 	ate_match_dt,
+	ate_match_local_cap_id,
 };
 
 struct arch_timer_erratum_workaround {

commit 651bb2e9dca6e6dbad3fba5f6e6086a23575b8b5
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Thu Jan 19 17:20:59 2017 +0000

    arm64: arch_timer: Add infrastructure for multiple erratum detection methods
    
    We're currently stuck with DT when it comes to handling errata, which
    is pretty restrictive. In order to make things more flexible, let's
    introduce an infrastructure that could support alternative discovery
    methods. No change in functionality.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Hanjun Guo <hanjun.guo@linaro.org>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index b4b34004a21e..5cd964e90d11 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -37,9 +37,14 @@ extern struct static_key_false arch_timer_read_ool_enabled;
 #define needs_unstable_timer_counter_workaround()  false
 #endif
 
+enum arch_timer_erratum_match_type {
+	ate_match_dt,
+};
 
 struct arch_timer_erratum_workaround {
-	const char *id;		/* Indicate the Erratum ID */
+	enum arch_timer_erratum_match_type match_type;
+	const void *id;
+	const char *desc;
 	u32 (*read_cntp_tval_el0)(void);
 	u32 (*read_cntv_tval_el0)(void);
 	u64 (*read_cntvct_el0)(void);

commit 16d10ef29f25aba923779234bb93a451b14d20e6
Author: Ding Tianhong <dingtianhong@huawei.com>
Date:   Mon Feb 6 16:47:41 2017 +0000

    clocksource/drivers/arm_arch_timer: Introduce generic errata handling infrastructure
    
    Currently we have code inline in the arch timer probe path to cater for
    Freescale erratum A-008585, complete with ifdeffery. This is a little
    ugly, and will get worse as we try to add more errata handling.
    
    This patch refactors the handling of Freescale erratum A-008585. Now the
    erratum is described in a generic arch_timer_erratum_workaround
    structure, and the probe path can iterate over these to detect errata
    and enable workarounds.
    
    This will simplify the addition and maintenance of code handling
    Hisilicon erratum 161010101.
    
    Signed-off-by: Ding Tianhong <dingtianhong@huawei.com>
    [Mark: split patch, correct Kconfig, reword commit message]
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index eaa5bbe3fa87..b4b34004a21e 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -29,41 +29,29 @@
 
 #include <clocksource/arm_arch_timer.h>
 
-#if IS_ENABLED(CONFIG_FSL_ERRATUM_A008585)
+#if IS_ENABLED(CONFIG_ARM_ARCH_TIMER_OOL_WORKAROUND)
 extern struct static_key_false arch_timer_read_ool_enabled;
-#define needs_fsl_a008585_workaround() \
+#define needs_unstable_timer_counter_workaround() \
 	static_branch_unlikely(&arch_timer_read_ool_enabled)
 #else
-#define needs_fsl_a008585_workaround()  false
+#define needs_unstable_timer_counter_workaround()  false
 #endif
 
-u32 __fsl_a008585_read_cntp_tval_el0(void);
-u32 __fsl_a008585_read_cntv_tval_el0(void);
-u64 __fsl_a008585_read_cntvct_el0(void);
 
-/*
- * The number of retries is an arbitrary value well beyond the highest number
- * of iterations the loop has been observed to take.
- */
-#define __fsl_a008585_read_reg(reg) ({			\
-	u64 _old, _new;					\
-	int _retries = 200;				\
-							\
-	do {						\
-		_old = read_sysreg(reg);		\
-		_new = read_sysreg(reg);		\
-		_retries--;				\
-	} while (unlikely(_old != _new) && _retries);	\
-							\
-	WARN_ON_ONCE(!_retries);			\
-	_new;						\
-})
+struct arch_timer_erratum_workaround {
+	const char *id;		/* Indicate the Erratum ID */
+	u32 (*read_cntp_tval_el0)(void);
+	u32 (*read_cntv_tval_el0)(void);
+	u64 (*read_cntvct_el0)(void);
+};
+
+extern const struct arch_timer_erratum_workaround *timer_unstable_counter_workaround;
 
 #define arch_timer_reg_read_stable(reg) 		\
 ({							\
 	u64 _val;					\
-	if (needs_fsl_a008585_workaround())		\
-		_val = __fsl_a008585_read_##reg();	\
+	if (needs_unstable_timer_counter_workaround())		\
+		_val = timer_unstable_counter_workaround->read_##reg();\
 	else						\
 		_val = read_sysreg(reg);		\
 	_val;						\

commit f6dc1576cd517440313c9551b6ffa3d7e389c7c7
Author: Scott Wood <oss@buserror.net>
Date:   Thu Sep 22 03:35:17 2016 -0500

    arm64: arch_timer: Work around QorIQ Erratum A-008585
    
    Erratum A-008585 says that the ARM generic timer counter "has the
    potential to contain an erroneous value for a small number of core
    clock cycles every time the timer value changes".  Accesses to TVAL
    (both read and write) are also affected due to the implicit counter
    read.  Accesses to CVAL are not affected.
    
    The workaround is to reread TVAL and count registers until successive
    reads return the same value.  Writes to TVAL are replaced with an
    equivalent write to CVAL.
    
    The workaround is to reread TVAL and count registers until successive reads
    return the same value, and when writing TVAL to retry until counter
    reads before and after the write return the same value.
    
    The workaround is enabled if the fsl,erratum-a008585 property is found in
    the timer node in the device tree.  This can be overridden with the
    clocksource.arm_arch_timer.fsl-a008585 boot parameter, which allows KVM
    users to enable the workaround until a mechanism is implemented to
    automatically communicate this information.
    
    This erratum can be found on LS1043A and LS2080A.
    
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Scott Wood <oss@buserror.net>
    [will: renamed read macro to reflect that it's not usually unstable]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 7ff386c15539..eaa5bbe3fa87 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -24,10 +24,51 @@
 
 #include <linux/bug.h>
 #include <linux/init.h>
+#include <linux/jump_label.h>
 #include <linux/types.h>
 
 #include <clocksource/arm_arch_timer.h>
 
+#if IS_ENABLED(CONFIG_FSL_ERRATUM_A008585)
+extern struct static_key_false arch_timer_read_ool_enabled;
+#define needs_fsl_a008585_workaround() \
+	static_branch_unlikely(&arch_timer_read_ool_enabled)
+#else
+#define needs_fsl_a008585_workaround()  false
+#endif
+
+u32 __fsl_a008585_read_cntp_tval_el0(void);
+u32 __fsl_a008585_read_cntv_tval_el0(void);
+u64 __fsl_a008585_read_cntvct_el0(void);
+
+/*
+ * The number of retries is an arbitrary value well beyond the highest number
+ * of iterations the loop has been observed to take.
+ */
+#define __fsl_a008585_read_reg(reg) ({			\
+	u64 _old, _new;					\
+	int _retries = 200;				\
+							\
+	do {						\
+		_old = read_sysreg(reg);		\
+		_new = read_sysreg(reg);		\
+		_retries--;				\
+	} while (unlikely(_old != _new) && _retries);	\
+							\
+	WARN_ON_ONCE(!_retries);			\
+	_new;						\
+})
+
+#define arch_timer_reg_read_stable(reg) 		\
+({							\
+	u64 _val;					\
+	if (needs_fsl_a008585_workaround())		\
+		_val = __fsl_a008585_read_##reg();	\
+	else						\
+		_val = read_sysreg(reg);		\
+	_val;						\
+})
+
 /*
  * These register accessors are marked inline so the compiler can
  * nicely work out which register we want, and chuck away the rest of
@@ -67,14 +108,14 @@ u32 arch_timer_reg_read_cp15(int access, enum arch_timer_reg reg)
 		case ARCH_TIMER_REG_CTRL:
 			return read_sysreg(cntp_ctl_el0);
 		case ARCH_TIMER_REG_TVAL:
-			return read_sysreg(cntp_tval_el0);
+			return arch_timer_reg_read_stable(cntp_tval_el0);
 		}
 	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
 		switch (reg) {
 		case ARCH_TIMER_REG_CTRL:
 			return read_sysreg(cntv_ctl_el0);
 		case ARCH_TIMER_REG_TVAL:
-			return read_sysreg(cntv_tval_el0);
+			return arch_timer_reg_read_stable(cntv_tval_el0);
 		}
 	}
 
@@ -108,7 +149,7 @@ static inline u64 arch_counter_get_cntpct(void)
 static inline u64 arch_counter_get_cntvct(void)
 {
 	isb();
-	return read_sysreg(cntvct_el0);
+	return arch_timer_reg_read_stable(cntvct_el0);
 }
 
 static inline int arch_timer_arch_init(void)

commit cd5f22d7967f613c49288256ce95b07eb910e2a9
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Thu Sep 8 13:55:35 2016 +0100

    arm64: arch_timer: simplify accessors
    
    A while back we added {read,write}_sysreg accessors to handle accesses
    to system registers, without the usual boilerplate asm volatile,
    temporary variable, etc.
    
    This patch makes use of these in the arm64 arch timer accessors to make
    the code shorter and clearer.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index fbe0ca31a99c..7ff386c15539 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -20,6 +20,7 @@
 #define __ASM_ARCH_TIMER_H
 
 #include <asm/barrier.h>
+#include <asm/sysreg.h>
 
 #include <linux/bug.h>
 #include <linux/init.h>
@@ -38,19 +39,19 @@ void arch_timer_reg_write_cp15(int access, enum arch_timer_reg reg, u32 val)
 	if (access == ARCH_TIMER_PHYS_ACCESS) {
 		switch (reg) {
 		case ARCH_TIMER_REG_CTRL:
-			asm volatile("msr cntp_ctl_el0,  %0" : : "r" (val));
+			write_sysreg(val, cntp_ctl_el0);
 			break;
 		case ARCH_TIMER_REG_TVAL:
-			asm volatile("msr cntp_tval_el0, %0" : : "r" (val));
+			write_sysreg(val, cntp_tval_el0);
 			break;
 		}
 	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
 		switch (reg) {
 		case ARCH_TIMER_REG_CTRL:
-			asm volatile("msr cntv_ctl_el0,  %0" : : "r" (val));
+			write_sysreg(val, cntv_ctl_el0);
 			break;
 		case ARCH_TIMER_REG_TVAL:
-			asm volatile("msr cntv_tval_el0, %0" : : "r" (val));
+			write_sysreg(val, cntv_tval_el0);
 			break;
 		}
 	}
@@ -61,48 +62,38 @@ void arch_timer_reg_write_cp15(int access, enum arch_timer_reg reg, u32 val)
 static __always_inline
 u32 arch_timer_reg_read_cp15(int access, enum arch_timer_reg reg)
 {
-	u32 val;
-
 	if (access == ARCH_TIMER_PHYS_ACCESS) {
 		switch (reg) {
 		case ARCH_TIMER_REG_CTRL:
-			asm volatile("mrs %0,  cntp_ctl_el0" : "=r" (val));
-			break;
+			return read_sysreg(cntp_ctl_el0);
 		case ARCH_TIMER_REG_TVAL:
-			asm volatile("mrs %0, cntp_tval_el0" : "=r" (val));
-			break;
+			return read_sysreg(cntp_tval_el0);
 		}
 	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
 		switch (reg) {
 		case ARCH_TIMER_REG_CTRL:
-			asm volatile("mrs %0,  cntv_ctl_el0" : "=r" (val));
-			break;
+			return read_sysreg(cntv_ctl_el0);
 		case ARCH_TIMER_REG_TVAL:
-			asm volatile("mrs %0, cntv_tval_el0" : "=r" (val));
-			break;
+			return read_sysreg(cntv_tval_el0);
 		}
 	}
 
-	return val;
+	BUG();
 }
 
 static inline u32 arch_timer_get_cntfrq(void)
 {
-	u32 val;
-	asm volatile("mrs %0,   cntfrq_el0" : "=r" (val));
-	return val;
+	return read_sysreg(cntfrq_el0);
 }
 
 static inline u32 arch_timer_get_cntkctl(void)
 {
-	u32 cntkctl;
-	asm volatile("mrs	%0, cntkctl_el1" : "=r" (cntkctl));
-	return cntkctl;
+	return read_sysreg(cntkctl_el1);
 }
 
 static inline void arch_timer_set_cntkctl(u32 cntkctl)
 {
-	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
+	write_sysreg(cntkctl, cntkctl_el1);
 }
 
 static inline u64 arch_counter_get_cntpct(void)
@@ -116,12 +107,8 @@ static inline u64 arch_counter_get_cntpct(void)
 
 static inline u64 arch_counter_get_cntvct(void)
 {
-	u64 cval;
-
 	isb();
-	asm volatile("mrs %0, cntvct_el0" : "=r" (cval));
-
-	return cval;
+	return read_sysreg(cntvct_el0);
 }
 
 static inline int arch_timer_arch_init(void)

commit 082471a8efe1a91d4e44abec202d9e3067dcec91
Author: Paul Walmsley <pwalmsley@nvidia.com>
Date:   Mon Jan 5 17:38:41 2015 -0700

    arm64: fix missing linux/bug.h include in asm/arch_timer.h
    
    On next-20150105, defconfig compilation breaks with:
    
    ./arch/arm64/include/asm/arch_timer.h:112:2: error: implicit declaration of function ‘BUG’ [-Werror=implicit-function-declaration]
    
    Fix by including linux/bug.h, where the BUG macro is defined.
    
    This second version incorporates a comment from Mark Rutland
    <mark.rutland@arm.com> to keep the includes in alphabetical order
    by filename.
    
    Signed-off-by: Paul Walmsley <paul@pwsan.com>
    Cc: Paul Walmsley <pwalmsley@nvidia.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index b1fa4e614718..fbe0ca31a99c 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -21,6 +21,7 @@
 
 #include <asm/barrier.h>
 
+#include <linux/bug.h>
 #include <linux/init.h>
 #include <linux/types.h>
 

commit 0b46b8a718c6e90910a1b1b0fe797be3c167e186
Author: Sonny Rao <sonnyrao@chromium.org>
Date:   Sun Nov 23 23:02:44 2014 -0800

    clocksource: arch_timer: Fix code to use physical timers when requested
    
    This is a bug fix for using physical arch timers when
    the arch_timer_use_virtual boolean is false.  It restores the
    arch_counter_get_cntpct() function after removal in
    
    0d651e4e "clocksource: arch_timer: use virtual counters"
    
    We need this on certain ARMv7 systems which are architected like this:
    
    * The firmware doesn't know and doesn't care about hypervisor mode and
      we don't want to add the complexity of hypervisor there.
    
    * The firmware isn't involved in SMP bringup or resume.
    
    * The ARCH timer come up with an uninitialized offset between the
      virtual and physical counters.  Each core gets a different random
      offset.
    
    * The device boots in "Secure SVC" mode.
    
    * Nothing has touched the reset value of CNTHCTL.PL1PCEN or
      CNTHCTL.PL1PCTEN (both default to 1 at reset)
    
    One example of such as system is RK3288 where it is much simpler to
    use the physical counter since there's nobody managing the offset and
    each time a core goes down and comes back up it will get reinitialized
    to some other random value.
    
    Fixes: 0d651e4e65e9 ("clocksource: arch_timer: use virtual counters")
    Cc: stable@vger.kernel.org
    Signed-off-by: Sonny Rao <sonnyrao@chromium.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Olof Johansson <olof@lixom.net>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index f19097134b02..b1fa4e614718 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -104,6 +104,15 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
 }
 
+static inline u64 arch_counter_get_cntpct(void)
+{
+	/*
+	 * AArch64 kernel and user space mandate the use of CNTVCT.
+	 */
+	BUG();
+	return 0;
+}
+
 static inline u64 arch_counter_get_cntvct(void)
 {
 	u64 cval;

commit e1ce5c7adc735ce96a35806ca32ceb78e607a283
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Mon Sep 29 01:50:06 2014 +0200

    clocksource: arm_arch_timer: Consolidate arch_timer_evtstrm_enable
    
    The arch_timer_evtstrm_enable hooks in arm and arm64 are substantially
    similar, the only difference being a CONFIG_COMPAT-conditional section
    which is relevant only for arm64.  Copy the arm64 version to the
    driver, removing the arch-specific hooks.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 49e94c677e7a..f19097134b02 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -104,20 +104,6 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
 }
 
-static inline void arch_timer_evtstrm_enable(int divider)
-{
-	u32 cntkctl = arch_timer_get_cntkctl();
-	cntkctl &= ~ARCH_TIMER_EVT_TRIGGER_MASK;
-	/* Set the divider and enable virtual event stream */
-	cntkctl |= (divider << ARCH_TIMER_EVT_TRIGGER_SHIFT)
-			| ARCH_TIMER_VIRT_EVT_EN;
-	arch_timer_set_cntkctl(cntkctl);
-	elf_hwcap |= HWCAP_EVTSTRM;
-#ifdef CONFIG_COMPAT
-	compat_elf_hwcap |= COMPAT_HWCAP_EVTSTRM;
-#endif
-}
-
 static inline u64 arch_counter_get_cntvct(void)
 {
 	u64 cval;

commit 8b8dde00347ef409b29abd97e5833ffdb4ed7508
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Mon Sep 29 01:50:06 2014 +0200

    clocksource: arm_arch_timer: Enable counter access for 32-bit ARM
    
    The only difference between arm and arm64's implementations of
    arch_counter_set_user_access is that 32-bit ARM does not enable user
    access to the virtual counter.  We want to enable this access for the
    32-bit ARM VDSO, so copy the arm64 version to the driver itself, and
    remove the arch-specific implementations.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 9400596a0f39..49e94c677e7a 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -104,23 +104,6 @@ static inline void arch_timer_set_cntkctl(u32 cntkctl)
 	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
 }
 
-static inline void arch_counter_set_user_access(void)
-{
-	u32 cntkctl = arch_timer_get_cntkctl();
-
-	/* Disable user access to the timers and the physical counter */
-	/* Also disable virtual event stream */
-	cntkctl &= ~(ARCH_TIMER_USR_PT_ACCESS_EN
-			| ARCH_TIMER_USR_VT_ACCESS_EN
-			| ARCH_TIMER_VIRT_EVT_EN
-			| ARCH_TIMER_USR_PCT_ACCESS_EN);
-
-	/* Enable user access to the virtual counter */
-	cntkctl |= ARCH_TIMER_USR_VCT_ACCESS_EN;
-
-	arch_timer_set_cntkctl(cntkctl);
-}
-
 static inline void arch_timer_evtstrm_enable(int divider)
 {
 	u32 cntkctl = arch_timer_get_cntkctl();

commit 46efe547aca8498d51b64460c02366ae4032ca32
Author: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
Date:   Tue Aug 13 15:57:53 2013 +0100

    ARM64: arch_timer: add support to configure and enable event stream
    
    This patch adds support for configuring the event stream frequency
    and enabling it.
    
    It also adds the hwcaps as well as compat-specific definitions to
    the user to detect this event stream feature.
    
    Cc: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 2b9722f42729..9400596a0f39 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -92,21 +92,47 @@ static inline u32 arch_timer_get_cntfrq(void)
 	return val;
 }
 
-static inline void arch_counter_set_user_access(void)
+static inline u32 arch_timer_get_cntkctl(void)
 {
 	u32 cntkctl;
-
 	asm volatile("mrs	%0, cntkctl_el1" : "=r" (cntkctl));
+	return cntkctl;
+}
+
+static inline void arch_timer_set_cntkctl(u32 cntkctl)
+{
+	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
+}
+
+static inline void arch_counter_set_user_access(void)
+{
+	u32 cntkctl = arch_timer_get_cntkctl();
 
 	/* Disable user access to the timers and the physical counter */
+	/* Also disable virtual event stream */
 	cntkctl &= ~(ARCH_TIMER_USR_PT_ACCESS_EN
 			| ARCH_TIMER_USR_VT_ACCESS_EN
+			| ARCH_TIMER_VIRT_EVT_EN
 			| ARCH_TIMER_USR_PCT_ACCESS_EN);
 
 	/* Enable user access to the virtual counter */
 	cntkctl |= ARCH_TIMER_USR_VCT_ACCESS_EN;
 
-	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
+	arch_timer_set_cntkctl(cntkctl);
+}
+
+static inline void arch_timer_evtstrm_enable(int divider)
+{
+	u32 cntkctl = arch_timer_get_cntkctl();
+	cntkctl &= ~ARCH_TIMER_EVT_TRIGGER_MASK;
+	/* Set the divider and enable virtual event stream */
+	cntkctl |= (divider << ARCH_TIMER_EVT_TRIGGER_SHIFT)
+			| ARCH_TIMER_VIRT_EVT_EN;
+	arch_timer_set_cntkctl(cntkctl);
+	elf_hwcap |= HWCAP_EVTSTRM;
+#ifdef CONFIG_COMPAT
+	compat_elf_hwcap |= COMPAT_HWCAP_EVTSTRM;
+#endif
 }
 
 static inline u64 arch_counter_get_cntvct(void)

commit 28061758dc83df445a05af347b5ce55ccd968c03
Author: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>
Date:   Tue Aug 13 13:43:26 2013 +0100

    ARM/ARM64: arch_timer: add macros for bits in control register
    
    Add macros to describe the bitfields in the ARM architected timer
    control register to make code easy to understand.
    
    Reviewed-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Reviewed-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index c9f1d2816c2b..2b9722f42729 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -96,12 +96,16 @@ static inline void arch_counter_set_user_access(void)
 {
 	u32 cntkctl;
 
-	/* Disable user access to the timers and the physical counter. */
 	asm volatile("mrs	%0, cntkctl_el1" : "=r" (cntkctl));
-	cntkctl &= ~((3 << 8) | (1 << 0));
 
-	/* Enable user access to the virtual counter and frequency. */
-	cntkctl |= (1 << 1);
+	/* Disable user access to the timers and the physical counter */
+	cntkctl &= ~(ARCH_TIMER_USR_PT_ACCESS_EN
+			| ARCH_TIMER_USR_VT_ACCESS_EN
+			| ARCH_TIMER_USR_PCT_ACCESS_EN);
+
+	/* Enable user access to the virtual counter */
+	cntkctl |= ARCH_TIMER_USR_VCT_ACCESS_EN;
+
 	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
 }
 

commit cfb6d656d569510ac9239583ce09e4c92ad54719
Merge: fac778a2b8d6 220069945b29
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Aug 21 14:59:23 2013 +0200

    Merge branch 'timers/clockevents-next' of git://git.linaro.org/people/dlezcano/clockevents into timers/core
    
    * Support for memory mapped arch_timers
    * Trivial fixes to the moxart timer code
    * Documentation updates
    
    Trivial conflicts in drivers/clocksource/arm_arch_timer.c. Fixed up
    the newly added __cpuinit annotations as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 60faddf6eb3aba16068032bdcf35e18ace4bfb21
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Thu Jul 18 16:59:31 2013 -0700

    clocksource: arch_timer: Push the read/write wrappers deeper
    
    We're going to introduce support to read and write the memory
    mapped timer registers in the next patch, so push the cp15
    read/write functions one level deeper. This simplifies the next
    patch and makes it clearer what's going on.
    
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Marc Zyngier <Marc.Zyngier@arm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index dbca77168e81..7181e777c2c5 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -32,7 +32,7 @@
  * the code.
  */
 static __always_inline
-void arch_timer_reg_write(int access, enum arch_timer_reg reg, u32 val)
+void arch_timer_reg_write_cp15(int access, enum arch_timer_reg reg, u32 val)
 {
 	if (access == ARCH_TIMER_PHYS_ACCESS) {
 		switch (reg) {
@@ -58,7 +58,7 @@ void arch_timer_reg_write(int access, enum arch_timer_reg reg, u32 val)
 }
 
 static __always_inline
-u32 arch_timer_reg_read(int access, enum arch_timer_reg reg)
+u32 arch_timer_reg_read_cp15(int access, enum arch_timer_reg reg)
 {
 	u32 val;
 

commit e09f3cc0184d6b5c3816f921b7ffb67623e5e834
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Thu Jul 18 16:59:28 2013 -0700

    clocksource: arch_timer: Make register accessors less error-prone
    
    Using an enum for the register we wish to access allows newer
    compilers to determine if we've forgotten a case in our switch
    statement. This allows us to remove the BUILD_BUG() instances in
    the arm64 port, avoiding problems where optimizations may not
    happen.
    
    To try and force better code generation we're currently marking
    the accessor functions as inline, but newer compilers can ignore
    the inline keyword unless it's marked __always_inline. Luckily on
    arm and arm64 inline is __always_inline, but let's make
    everything __always_inline to be explicit.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Marc Zyngier <Marc.Zyngier@arm.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index d56ed11ba9a3..dbca77168e81 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -26,7 +26,13 @@
 
 #include <clocksource/arm_arch_timer.h>
 
-static inline void arch_timer_reg_write(int access, int reg, u32 val)
+/*
+ * These register accessors are marked inline so the compiler can
+ * nicely work out which register we want, and chuck away the rest of
+ * the code.
+ */
+static __always_inline
+void arch_timer_reg_write(int access, enum arch_timer_reg reg, u32 val)
 {
 	if (access == ARCH_TIMER_PHYS_ACCESS) {
 		switch (reg) {
@@ -36,8 +42,6 @@ static inline void arch_timer_reg_write(int access, int reg, u32 val)
 		case ARCH_TIMER_REG_TVAL:
 			asm volatile("msr cntp_tval_el0, %0" : : "r" (val));
 			break;
-		default:
-			BUILD_BUG();
 		}
 	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
 		switch (reg) {
@@ -47,17 +51,14 @@ static inline void arch_timer_reg_write(int access, int reg, u32 val)
 		case ARCH_TIMER_REG_TVAL:
 			asm volatile("msr cntv_tval_el0, %0" : : "r" (val));
 			break;
-		default:
-			BUILD_BUG();
 		}
-	} else {
-		BUILD_BUG();
 	}
 
 	isb();
 }
 
-static inline u32 arch_timer_reg_read(int access, int reg)
+static __always_inline
+u32 arch_timer_reg_read(int access, enum arch_timer_reg reg)
 {
 	u32 val;
 
@@ -69,8 +70,6 @@ static inline u32 arch_timer_reg_read(int access, int reg)
 		case ARCH_TIMER_REG_TVAL:
 			asm volatile("mrs %0, cntp_tval_el0" : "=r" (val));
 			break;
-		default:
-			BUILD_BUG();
 		}
 	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
 		switch (reg) {
@@ -80,11 +79,7 @@ static inline u32 arch_timer_reg_read(int access, int reg)
 		case ARCH_TIMER_REG_TVAL:
 			asm volatile("mrs %0, cntv_tval_el0" : "=r" (val));
 			break;
-		default:
-			BUILD_BUG();
 		}
-	} else {
-		BUILD_BUG();
 	}
 
 	return val;

commit b8c6453aaf142620c2e1a4c2da24bbb10cb424bf
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Jun 18 10:18:31 2013 -0400

    arm64: delete __cpuinit usage from all users
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    are flagged as __cpuinit  -- so if we remove the __cpuinit from
    arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    content into no-ops as early as possible, since that will get rid
    of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the arch/arm64 uses of the __cpuinit macros from
    all C files.  Currently arm64 does not have any __CPUINIT used in
    assembly files.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index d56ed11ba9a3..98abd476992d 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -97,7 +97,7 @@ static inline u32 arch_timer_get_cntfrq(void)
 	return val;
 }
 
-static inline void __cpuinit arch_counter_set_user_access(void)
+static inline void arch_counter_set_user_access(void)
 {
 	u32 cntkctl;
 

commit 0d651e4e65e96989f72236bf83bd4c6e55eb6ce4
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Wed Jan 30 17:51:26 2013 +0000

    clocksource: arch_timer: use virtual counters
    
    Switching between reading the virtual or physical counters is
    problematic, as some core code wants a view of time before we're fully
    set up. Using a function pointer and switching the source after the
    first read can make time appear to go backwards, and having a check in
    the read function is an unfortunate block on what we want to be a fast
    path.
    
    Instead, this patch makes us always use the virtual counters. If we're a
    guest, or don't have hyp mode, we'll use the virtual timers, and as such
    don't care about CNTVOFF as long as it doesn't change in such a way as
    to make time appear to travel backwards. As the guest will use the
    virtual timers, a (potential) KVM host must use the physical timers
    (which can wake up the host even if they fire while a guest is
    executing), and hence a host must have CNTVOFF set to zero so as to have
    a consistent view of time between the physical timers and virtual
    counters.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Rob Herring <rob.herring@calxeda.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index bf6ab242f047..d56ed11ba9a3 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -110,16 +110,6 @@ static inline void __cpuinit arch_counter_set_user_access(void)
 	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
 }
 
-static inline u64 arch_counter_get_cntpct(void)
-{
-	u64 cval;
-
-	isb();
-	asm volatile("mrs %0, cntpct_el0" : "=r" (cval));
-
-	return cval;
-}
-
 static inline u64 arch_counter_get_cntvct(void)
 {
 	u64 cval;

commit 0583fe478a7d93be2c814b7e50d6e81c287edfe8
Author: Rob Herring <rob.herring@calxeda.com>
Date:   Wed Apr 10 18:27:51 2013 -0500

    ARM: convert arm/arm64 arch timer to use CLKSRC_OF init
    
    This converts arm and arm64 to use CLKSRC_OF DT based initialization for
    the arch timer. A new function arch_timer_arch_init is added to allow for
    arch specific setup.
    
    This has a side effect of enabling sched_clock on omap5 and exynos5. There
    should not be any reason not to use the arch timers for sched_clock.
    
    Signed-off-by: Rob Herring <rob.herring@calxeda.com>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Simon Horman <horms@verge.net.au>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-samsung-soc@vger.kernel.org
    Cc: linux-omap@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
index 91e2a6a6fcd4..bf6ab242f047 100644
--- a/arch/arm64/include/asm/arch_timer.h
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -130,4 +130,9 @@ static inline u64 arch_counter_get_cntvct(void)
 	return cval;
 }
 
+static inline int arch_timer_arch_init(void)
+{
+	return 0;
+}
+
 #endif

commit 1aee5d7a8120cbe3eca9180ef9276d75a4f51dd2
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Tue Nov 20 10:06:00 2012 +0000

    arm64: move from arm_generic to arm_arch_timer
    
    The arch_timer driver supports a superset of the functionality of the
    arm_generic driver, and is not tied to a particular arch.
    
    This patch moves arm64 to use the arch_timer driver, gaining additional
    functionality in doing so, and removes the (now unused) arm_generic
    driver. Timer-related hooks specific to arm64 are moved into
    arch/arm64/kernel/time.c.
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>

diff --git a/arch/arm64/include/asm/arch_timer.h b/arch/arm64/include/asm/arch_timer.h
new file mode 100644
index 000000000000..91e2a6a6fcd4
--- /dev/null
+++ b/arch/arm64/include/asm/arch_timer.h
@@ -0,0 +1,133 @@
+/*
+ * arch/arm64/include/asm/arch_timer.h
+ *
+ * Copyright (C) 2012 ARM Ltd.
+ * Author: Marc Zyngier <marc.zyngier@arm.com>
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __ASM_ARCH_TIMER_H
+#define __ASM_ARCH_TIMER_H
+
+#include <asm/barrier.h>
+
+#include <linux/init.h>
+#include <linux/types.h>
+
+#include <clocksource/arm_arch_timer.h>
+
+static inline void arch_timer_reg_write(int access, int reg, u32 val)
+{
+	if (access == ARCH_TIMER_PHYS_ACCESS) {
+		switch (reg) {
+		case ARCH_TIMER_REG_CTRL:
+			asm volatile("msr cntp_ctl_el0,  %0" : : "r" (val));
+			break;
+		case ARCH_TIMER_REG_TVAL:
+			asm volatile("msr cntp_tval_el0, %0" : : "r" (val));
+			break;
+		default:
+			BUILD_BUG();
+		}
+	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
+		switch (reg) {
+		case ARCH_TIMER_REG_CTRL:
+			asm volatile("msr cntv_ctl_el0,  %0" : : "r" (val));
+			break;
+		case ARCH_TIMER_REG_TVAL:
+			asm volatile("msr cntv_tval_el0, %0" : : "r" (val));
+			break;
+		default:
+			BUILD_BUG();
+		}
+	} else {
+		BUILD_BUG();
+	}
+
+	isb();
+}
+
+static inline u32 arch_timer_reg_read(int access, int reg)
+{
+	u32 val;
+
+	if (access == ARCH_TIMER_PHYS_ACCESS) {
+		switch (reg) {
+		case ARCH_TIMER_REG_CTRL:
+			asm volatile("mrs %0,  cntp_ctl_el0" : "=r" (val));
+			break;
+		case ARCH_TIMER_REG_TVAL:
+			asm volatile("mrs %0, cntp_tval_el0" : "=r" (val));
+			break;
+		default:
+			BUILD_BUG();
+		}
+	} else if (access == ARCH_TIMER_VIRT_ACCESS) {
+		switch (reg) {
+		case ARCH_TIMER_REG_CTRL:
+			asm volatile("mrs %0,  cntv_ctl_el0" : "=r" (val));
+			break;
+		case ARCH_TIMER_REG_TVAL:
+			asm volatile("mrs %0, cntv_tval_el0" : "=r" (val));
+			break;
+		default:
+			BUILD_BUG();
+		}
+	} else {
+		BUILD_BUG();
+	}
+
+	return val;
+}
+
+static inline u32 arch_timer_get_cntfrq(void)
+{
+	u32 val;
+	asm volatile("mrs %0,   cntfrq_el0" : "=r" (val));
+	return val;
+}
+
+static inline void __cpuinit arch_counter_set_user_access(void)
+{
+	u32 cntkctl;
+
+	/* Disable user access to the timers and the physical counter. */
+	asm volatile("mrs	%0, cntkctl_el1" : "=r" (cntkctl));
+	cntkctl &= ~((3 << 8) | (1 << 0));
+
+	/* Enable user access to the virtual counter and frequency. */
+	cntkctl |= (1 << 1);
+	asm volatile("msr	cntkctl_el1, %0" : : "r" (cntkctl));
+}
+
+static inline u64 arch_counter_get_cntpct(void)
+{
+	u64 cval;
+
+	isb();
+	asm volatile("mrs %0, cntpct_el0" : "=r" (cval));
+
+	return cval;
+}
+
+static inline u64 arch_counter_get_cntvct(void)
+{
+	u64 cval;
+
+	isb();
+	asm volatile("mrs %0, cntvct_el0" : "=r" (cval));
+
+	return cval;
+}
+
+#endif
