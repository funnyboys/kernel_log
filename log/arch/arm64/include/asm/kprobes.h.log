commit 1802d0beecafe581ad584634ba92f8a471d8a63a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:21 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 174
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 655 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070034.575739538@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index 21721fbf44e7..97e511d645a2 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -1,16 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * arch/arm64/include/asm/kprobes.h
  *
  * Copyright (C) 2013 Linaro Limited
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
  */
 
 #ifndef _ARM_KPROBES_H

commit a22d570aee77ae626e4d3532478ae8058a24bdb3
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Feb 26 14:35:00 2019 +0000

    arm64: kprobes: Avoid calling kprobes debug handlers explicitly
    
    Kprobes bypasses our debug hook registration code so that it doesn't
    get tangled up with recursive debug exceptions from things like lockdep:
    
      http://lists.infradead.org/pipermail/linux-arm-kernel/2015-February/324385.html
    
    However, since then, (a) the hook list has become RCU protected and (b)
    the kprobes hooks were found not to filter out exceptions from userspace
    correctly. On top of that, the step handler is invoked directly from
    single_step_handler(), which *does* use the debug hook list, so it's
    clearly not the end of the world.
    
    For now, have kprobes use the debug hook registration API like everybody
    else. We can revisit this in the future if this is found to limit
    coverage significantly.
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index d5a44cf859e9..21721fbf44e7 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -54,8 +54,6 @@ void arch_remove_kprobe(struct kprobe *);
 int kprobe_fault_handler(struct pt_regs *regs, unsigned int fsr);
 int kprobe_exceptions_notify(struct notifier_block *self,
 			     unsigned long val, void *data);
-int kprobe_breakpoint_handler(struct pt_regs *regs, unsigned int esr);
-int kprobe_single_step_handler(struct pt_regs *regs, unsigned int esr);
 void kretprobe_trampoline(void);
 void __kprobes *trampoline_probe_handler(struct pt_regs *regs);
 

commit 2efb75cd712d8311a2d0c1ba041ded191398bca7
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Wed Jun 20 01:07:03 2018 +0900

    arm64/kprobes: Remove jprobe implementation
    
    Remove arch dependent setjump/longjump functions
    and unused fields in kprobe_ctlblk for jprobes
    from arch/arm64.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Link: https://lore.kernel.org/lkml/152942442318.15209.17767976282305601884.stgit@devbox
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index 6deb8d726041..d5a44cf859e9 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -48,7 +48,6 @@ struct kprobe_ctlblk {
 	unsigned long saved_irqflag;
 	struct prev_kprobe prev_kprobe;
 	struct kprobe_step_ctx ss_ctx;
-	struct pt_regs jprobe_saved_regs;
 };
 
 void arch_remove_kprobe(struct kprobe *);

commit 7d134b2ce639448199052fd573a324f7e7cd5ed8
Author: Luis R. Rodriguez <mcgrof@kernel.org>
Date:   Mon Feb 27 14:26:56 2017 -0800

    kprobes: move kprobe declarations to asm-generic/kprobes.h
    
    Often all is needed is these small helpers, instead of compiler.h or a
    full kprobes.h.  This is important for asm helpers, in fact even some
    asm/kprobes.h make use of these helpers...  instead just keep a generic
    asm file with helpers useful for asm code with the least amount of
    clutter as possible.
    
    Likewise we need now to also address what to do about this file for both
    when architectures have CONFIG_HAVE_KPROBES, and when they do not.  Then
    for when architectures have CONFIG_HAVE_KPROBES but have disabled
    CONFIG_KPROBES.
    
    Right now most asm/kprobes.h do not have guards against CONFIG_KPROBES,
    this means most architecture code cannot include asm/kprobes.h safely.
    Correct this and add guards for architectures missing them.
    Additionally provide architectures that not have kprobes support with
    the default asm-generic solution.  This lets us force asm/kprobes.h on
    the header include/linux/kprobes.h always, but most importantly we can
    now safely include just asm/kprobes.h on architecture code without
    bringing the full kitchen sink of header files.
    
    Two architectures already provided a guard against CONFIG_KPROBES on its
    kprobes.h: sh, arch.  The rest of the architectures needed gaurds added.
    We avoid including any not-needed headers on asm/kprobes.h unless
    kprobes have been enabled.
    
    In a subsequent atomic change we can try now to remove compiler.h from
    include/linux/kprobes.h.
    
    During this sweep I've also identified a few architectures defining a
    common macro needed for both kprobes and ftrace, that of the definition
    of the breakput instruction up.  Some refer to this as
    BREAKPOINT_INSTRUCTION.  This must be kept outside of the #ifdef
    CONFIG_KPROBES guard.
    
    [mcgrof@kernel.org: fix arm64 build]
      Link: http://lkml.kernel.org/r/CAB=NE6X1WMByuARS4mZ1g9+W=LuVBnMDnh_5zyN0CLADaVh=Jw@mail.gmail.com
    [sfr@canb.auug.org.au: fixup for kprobes declarations moving]
      Link: http://lkml.kernel.org/r/20170214165933.13ebd4f4@canb.auug.org.au
    Link: http://lkml.kernel.org/r/20170203233139.32682-1-mcgrof@kernel.org
    Signed-off-by: Luis R. Rodriguez <mcgrof@kernel.org>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index 1737aecfcc5e..6deb8d726041 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -16,6 +16,9 @@
 #ifndef _ARM_KPROBES_H
 #define _ARM_KPROBES_H
 
+#include <asm-generic/kprobes.h>
+
+#ifdef CONFIG_KPROBES
 #include <linux/types.h>
 #include <linux/ptrace.h>
 #include <linux/percpu.h>
@@ -57,4 +60,5 @@ int kprobe_single_step_handler(struct pt_regs *regs, unsigned int esr);
 void kretprobe_trampoline(void);
 void __kprobes *trampoline_probe_handler(struct pt_regs *regs);
 
+#endif /* CONFIG_KPROBES */
 #endif /* _ARM_KPROBES_H */

commit ad05711cec12131e1277ce749a99d08ecf233aa7
Author: David A. Long <dave.long@linaro.org>
Date:   Wed Aug 10 16:44:51 2016 -0400

    arm64: Remove stack duplicating code from jprobes
    
    Because the arm64 calling standard allows stacked function arguments to be
    anywhere in the stack frame, do not attempt to duplicate the stack frame for
    jprobes handler functions.
    
    Documentation changes to describe this issue have been broken out into a
    separate patch in order to simultaneously address them in other
    architecture(s).
    
    Signed-off-by: David A. Long <dave.long@linaro.org>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index 61b49150dfa3..1737aecfcc5e 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -22,7 +22,6 @@
 
 #define __ARCH_WANT_KPROBES_INSN_SLOT
 #define MAX_INSN_SIZE			1
-#define MAX_STACK_SIZE			128
 
 #define flush_insn_slot(p)		do { } while (0)
 #define kretprobe_blacklist_size	0
@@ -47,7 +46,6 @@ struct kprobe_ctlblk {
 	struct prev_kprobe prev_kprobe;
 	struct kprobe_step_ctx ss_ctx;
 	struct pt_regs jprobe_saved_regs;
-	char jprobes_stack[MAX_STACK_SIZE];
 };
 
 void arch_remove_kprobe(struct kprobe *);

commit da6a91252ad98d49b49e83b76c1f032cdf6e5258
Author: William Cohen <wcohen@redhat.com>
Date:   Fri Jul 8 12:35:52 2016 -0400

    arm64: Add trampoline code for kretprobes
    
    The trampoline code is used by kretprobes to capture a return from a probed
    function.  This is done by saving the registers, calling the handler, and
    restoring the registers. The code then returns to the original saved caller
    return address. It is necessary to do this directly instead of using a
    software breakpoint because the code used in processing that breakpoint
    could itself be kprobe'd and cause a problematic reentry into the debug
    exception handler.
    
    Signed-off-by: William Cohen <wcohen@redhat.com>
    Signed-off-by: David A. Long <dave.long@linaro.org>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    [catalin.marinas@arm.com: removed unnecessary masking of the PSTATE bits]
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
index 79c9511612b5..61b49150dfa3 100644
--- a/arch/arm64/include/asm/kprobes.h
+++ b/arch/arm64/include/asm/kprobes.h
@@ -56,5 +56,7 @@ int kprobe_exceptions_notify(struct notifier_block *self,
 			     unsigned long val, void *data);
 int kprobe_breakpoint_handler(struct pt_regs *regs, unsigned int esr);
 int kprobe_single_step_handler(struct pt_regs *regs, unsigned int esr);
+void kretprobe_trampoline(void);
+void __kprobes *trampoline_probe_handler(struct pt_regs *regs);
 
 #endif /* _ARM_KPROBES_H */

commit 2dd0e8d2d2a157dbc83295a78336c2217110f2f8
Author: Sandeepa Prabhu <sandeepa.s.prabhu@gmail.com>
Date:   Fri Jul 8 12:35:48 2016 -0400

    arm64: Kprobes with single stepping support
    
    Add support for basic kernel probes(kprobes) and jump probes
    (jprobes) for ARM64.
    
    Kprobes utilizes software breakpoint and single step debug
    exceptions supported on ARM v8.
    
    A software breakpoint is placed at the probe address to trap the
    kernel execution into the kprobe handler.
    
    ARM v8 supports enabling single stepping before the break exception
    return (ERET), with next PC in exception return address (ELR_EL1). The
    kprobe handler prepares an executable memory slot for out-of-line
    execution with a copy of the original instruction being probed, and
    enables single stepping. The PC is set to the out-of-line slot address
    before the ERET. With this scheme, the instruction is executed with the
    exact same register context except for the PC (and DAIF) registers.
    
    Debug mask (PSTATE.D) is enabled only when single stepping a recursive
    kprobe, e.g.: during kprobes reenter so that probed instruction can be
    single stepped within the kprobe handler -exception- context.
    The recursion depth of kprobe is always 2, i.e. upon probe re-entry,
    any further re-entry is prevented by not calling handlers and the case
    counted as a missed kprobe).
    
    Single stepping from the x-o-l slot has a drawback for PC-relative accesses
    like branching and symbolic literals access as the offset from the new PC
    (slot address) may not be ensured to fit in the immediate value of
    the opcode. Such instructions need simulation, so reject
    probing them.
    
    Instructions generating exceptions or cpu mode change are rejected
    for probing.
    
    Exclusive load/store instructions are rejected too.  Additionally, the
    code is checked to see if it is inside an exclusive load/store sequence
    (code from Pratyush).
    
    System instructions are mostly enabled for stepping, except MSR/MRS
    accesses to "DAIF" flags in PSTATE, which are not safe for
    probing.
    
    This also changes arch/arm64/include/asm/ptrace.h to use
    include/asm-generic/ptrace.h.
    
    Thanks to Steve Capper and Pratyush Anand for several suggested
    Changes.
    
    Signed-off-by: Sandeepa Prabhu <sandeepa.s.prabhu@gmail.com>
    Signed-off-by: David A. Long <dave.long@linaro.org>
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/kprobes.h b/arch/arm64/include/asm/kprobes.h
new file mode 100644
index 000000000000..79c9511612b5
--- /dev/null
+++ b/arch/arm64/include/asm/kprobes.h
@@ -0,0 +1,60 @@
+/*
+ * arch/arm64/include/asm/kprobes.h
+ *
+ * Copyright (C) 2013 Linaro Limited
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ */
+
+#ifndef _ARM_KPROBES_H
+#define _ARM_KPROBES_H
+
+#include <linux/types.h>
+#include <linux/ptrace.h>
+#include <linux/percpu.h>
+
+#define __ARCH_WANT_KPROBES_INSN_SLOT
+#define MAX_INSN_SIZE			1
+#define MAX_STACK_SIZE			128
+
+#define flush_insn_slot(p)		do { } while (0)
+#define kretprobe_blacklist_size	0
+
+#include <asm/probes.h>
+
+struct prev_kprobe {
+	struct kprobe *kp;
+	unsigned int status;
+};
+
+/* Single step context for kprobe */
+struct kprobe_step_ctx {
+	unsigned long ss_pending;
+	unsigned long match_addr;
+};
+
+/* per-cpu kprobe control block */
+struct kprobe_ctlblk {
+	unsigned int kprobe_status;
+	unsigned long saved_irqflag;
+	struct prev_kprobe prev_kprobe;
+	struct kprobe_step_ctx ss_ctx;
+	struct pt_regs jprobe_saved_regs;
+	char jprobes_stack[MAX_STACK_SIZE];
+};
+
+void arch_remove_kprobe(struct kprobe *);
+int kprobe_fault_handler(struct pt_regs *regs, unsigned int fsr);
+int kprobe_exceptions_notify(struct notifier_block *self,
+			     unsigned long val, void *data);
+int kprobe_breakpoint_handler(struct pt_regs *regs, unsigned int esr);
+int kprobe_single_step_handler(struct pt_regs *regs, unsigned int esr);
+
+#endif /* _ARM_KPROBES_H */
