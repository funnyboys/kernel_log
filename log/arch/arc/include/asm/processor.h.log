commit 7321e2ea0d6aece516a9c0827028ecda2ccaeae9
Author: Eugeniy Paltsev <Eugeniy.Paltsev@synopsys.com>
Date:   Thu Mar 5 23:02:51 2020 +0300

    ARC: add support for DSP-enabled userspace applications
    
    To be able to run DSP-enabled userspace applications we need to
    save and restore following DSP-related registers:
    At IRQ/exception entry/exit:
     * DSP_CTRL (save it and reset to value suitable for kernel)
     * ACC0_LO, ACC0_HI (we already save them as r58, r59 pair)
    At context switch:
     * ACC0_GLO, ACC0_GHI
     * DSP_BFLY0, DSP_FFT_CTRL
    
    Reviewed-by: Vineet Gupta <vgupta@synopsys.com>
    Signed-off-by: Eugeniy Paltsev <Eugeniy.Paltsev@synopsys.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index ec532d1e0725..0fcea5bad343 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -14,6 +14,7 @@
 #ifndef __ASSEMBLY__
 
 #include <asm/ptrace.h>
+#include <asm/dsp.h>
 #include <asm/fpu.h>
 
 #ifdef CONFIG_ARC_PLAT_EZNPS
@@ -31,6 +32,9 @@ struct thread_struct {
 	unsigned long ksp;	/* kernel mode stack pointer */
 	unsigned long callee_reg;	/* pointer to callee regs */
 	unsigned long fault_address;	/* dbls as brkpt holder as well */
+#ifdef CONFIG_ARC_DSP_SAVE_RESTORE_REGS
+	struct dsp_callee_regs dsp;
+#endif
 #ifdef CONFIG_ARC_FPU_SAVE_RESTORE
 	struct arc_fpu fpu;
 #endif

commit f05523aa7a1e63bfada5e222c0a57e02dbd4fcfa
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Jan 17 16:00:41 2020 -0800

    ARC: fpu: declutter code, move bits out into fpu.h
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 706edeaa5583..ec532d1e0725 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -14,15 +14,7 @@
 #ifndef __ASSEMBLY__
 
 #include <asm/ptrace.h>
-
-#ifdef CONFIG_ARC_FPU_SAVE_RESTORE
-/* These DPFP regs need to be saved/restored across ctx-sw */
-struct arc_fpu {
-	struct {
-		unsigned int l, h;
-	} aux_dpfp[2];
-};
-#endif
+#include <asm/fpu.h>
 
 #ifdef CONFIG_ARC_PLAT_EZNPS
 struct eznps_dp {

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 10346d6cf926..706edeaa5583 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -1,10 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
  * vineetg: March 2009
  *  -Implemented task_pt_regs( )
  *

commit de0d22e50cd3d57277f073ccf65d57aa519d6888
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Tue Oct 30 15:04:47 2018 -0700

    treewide: remove current_text_addr
    
    Prefer _THIS_IP_ defined in linux/kernel.h.
    
    Most definitions of current_text_addr were the same as _THIS_IP_, but
    a few archs had inline assembly instead.
    
    This patch removes the final call site of current_text_addr, making all
    of the definitions dead code.
    
    [akpm@linux-foundation.org: fix arch/csky/include/asm/processor.h]
    Link: http://lkml.kernel.org/r/20180911182413.180715-1-ndesaulniers@google.com
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 8ee41e988169..10346d6cf926 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -98,14 +98,6 @@ extern void start_thread(struct pt_regs * regs, unsigned long pc,
 
 extern unsigned int get_wchan(struct task_struct *p);
 
-/*
- * Default implementation of macro that returns current
- * instruction pointer ("program counter").
- * Should the PC register be read instead ? This macro does not seem to
- * be used in many places so this wont be all that bad.
- */
-#define current_text_addr() ({ __label__ _l; _l: &&_l; })
-
 #endif /* !__ASSEMBLY__ */
 
 /*

commit c17c02040bf0d186cebd3e66ff349f955575bf38
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Fri Sep 22 09:42:42 2017 +0200

    arch: remove unused *_segments() macros/functions
    
    Some architectures define the no-op macros/functions copy_segments,
    release_segments and forget_segments. These are used nowhere in the
    tree, so removed them.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>   [for arch/arc]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index d400a2161935..8ee41e988169 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -78,9 +78,6 @@ struct task_struct;
 
 #endif
 
-#define copy_segments(tsk, mm)      do { } while (0)
-#define release_segments(mm)        do { } while (0)
-
 #define KSTK_EIP(tsk)   (task_pt_regs(tsk)->ret)
 #define KSTK_ESP(tsk)   (task_pt_regs(tsk)->sp)
 

commit 5b2189ab6ee0717babac912f779dcd440e942173
Author: Noam Camus <noamc@ezchip.com>
Date:   Thu Jun 15 11:43:59 2017 +0300

    ARC: [plat-eznps] handle extra aux regs #1: save/restore on context switch
    
    save EFLAGS, and GPA1 auxiliary registers during context switch,
    since they may be changed by the new task in kernel mode, while using atomic
    ops e.g. cmpxchg.
    
    Signed-off-by: Noam Camus <noamc@ezchip.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 4104a0839214..d400a2161935 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -27,6 +27,13 @@ struct arc_fpu {
 };
 #endif
 
+#ifdef CONFIG_ARC_PLAT_EZNPS
+struct eznps_dp {
+	unsigned int eflags;
+	unsigned int gpa1;
+};
+#endif
+
 /* Arch specific stuff which needs to be saved per task.
  * However these items are not so important so as to earn a place in
  * struct thread_info
@@ -38,6 +45,9 @@ struct thread_struct {
 #ifdef CONFIG_ARC_FPU_SAVE_RESTORE
 	struct arc_fpu fpu;
 #endif
+#ifdef CONFIG_ARC_PLAT_EZNPS
+	struct eznps_dp dp;
+#endif
 };
 
 #define INIT_THREAD  {                          \

commit 6474924e2b5ddb0030c355558966adcbe3b49022
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Wed Jun 28 15:30:02 2017 +0200

    arch: remove unused macro/function thread_saved_pc()
    
    The only user of thread_saved_pc() in non-arch-specific code was removed
    in commit 8243d5597793 ("sched/core: Remove pointless printout in
    sched_show_task()").  Remove the implementations as well.
    
    Some architectures use thread_saved_pc() in their arch-specific code.
    Leave their thread_saved_pc() intact.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 6e1242da0159..4104a0839214 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -86,8 +86,6 @@ struct task_struct;
 #define TSK_K_BLINK(tsk)	TSK_K_REG(tsk, 4)
 #define TSK_K_FP(tsk)		TSK_K_REG(tsk, 0)
 
-#define thread_saved_pc(tsk)	TSK_K_BLINK(tsk)
-
 extern void start_thread(struct pt_regs * regs, unsigned long pc,
 			 unsigned long usp);
 

commit 6d0d287891a022ebba572327cbd70b5de69a63a2
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Wed Nov 16 13:23:05 2016 +0100

    locking/core: Provide common cpu_relax_yield() definition
    
    No need to duplicate the same define everywhere. Since
    the only user is stop-machine and the only provider is
    s390, we can use a default implementation of cpu_relax_yield()
    in sched.h.
    
    Suggested-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-s390 <linux-s390@vger.kernel.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: sparclinux@vger.kernel.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1479298985-191589-1-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index d102a49ad8c5..6e1242da0159 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -60,15 +60,12 @@ struct task_struct;
 #ifndef CONFIG_EZNPS_MTM_EXT
 
 #define cpu_relax()		barrier()
-#define cpu_relax_yield()	cpu_relax()
 
 #else
 
 #define cpu_relax()     \
 	__asm__ __volatile__ (".word %0" : : "i"(CTOP_INST_SCHD_RW) : "memory")
 
-#define cpu_relax_yield()	cpu_relax()
-
 #endif
 
 #define copy_segments(tsk, mm)      do { } while (0)

commit 5bd0b85ba8bb9de6f61f33f3752fc85f4c87fc22
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:15 2016 +0200

    locking/core, arch: Remove cpu_relax_lowlatency()
    
    As there are no users left, we can remove cpu_relax_lowlatency()
    implementations from every architecture.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Cc: <linux-arch@vger.kernel.org>
    Link: http://lkml.kernel.org/r/1477386195-32736-6-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 6c158d576355..d102a49ad8c5 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -61,7 +61,6 @@ struct task_struct;
 
 #define cpu_relax()		barrier()
 #define cpu_relax_yield()	cpu_relax()
-#define cpu_relax_lowlatency()	cpu_relax()
 
 #else
 
@@ -69,7 +68,6 @@ struct task_struct;
 	__asm__ __volatile__ (".word %0" : : "i"(CTOP_INST_SCHD_RW) : "memory")
 
 #define cpu_relax_yield()	cpu_relax()
-#define cpu_relax_lowlatency()	barrier()
 
 #endif
 

commit 79ab11cdb90d8536817ab7357ecb6b1ff76be26c
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:11 2016 +0200

    locking/core: Introduce cpu_relax_yield()
    
    For spinning loops people do often use barrier() or cpu_relax().
    For most architectures cpu_relax and barrier are the same, but on
    some architectures cpu_relax can add some latency.
    For example on power,sparc64 and arc, cpu_relax can shift the CPU
    towards other hardware threads in an SMT environment.
    On s390 cpu_relax does even more, it uses an hypercall to the
    hypervisor to give up the timeslice.
    In contrast to the SMT yielding this can result in larger latencies.
    In some places this latency is unwanted, so another variant
    "cpu_relax_lowlatency" was introduced. Before this is used in more
    and more places, lets revert the logic and provide a cpu_relax_yield
    that can be called in places where yielding is more important than
    latency. By default this is the same as cpu_relax on all architectures.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1477386195-32736-2-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 16b630fbeb6a..6c158d576355 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -60,6 +60,7 @@ struct task_struct;
 #ifndef CONFIG_EZNPS_MTM_EXT
 
 #define cpu_relax()		barrier()
+#define cpu_relax_yield()	cpu_relax()
 #define cpu_relax_lowlatency()	cpu_relax()
 
 #else
@@ -67,6 +68,7 @@ struct task_struct;
 #define cpu_relax()     \
 	__asm__ __volatile__ (".word %0" : : "i"(CTOP_INST_SCHD_RW) : "memory")
 
+#define cpu_relax_yield()	cpu_relax()
 #define cpu_relax_lowlatency()	barrier()
 
 #endif

commit 2547476a5e4061f6addb88d5fc837d3a950f54c4
Author: Andrea Gelmini <andrea.gelmini@gelma.net>
Date:   Sat May 21 13:45:35 2016 +0200

    Fix typos
    
    Signed-off-by: Andrea Gelmini <andrea.gelmini@gelma.net>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index f9048994b22f..16b630fbeb6a 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -78,7 +78,7 @@ struct task_struct;
 #define KSTK_ESP(tsk)   (task_pt_regs(tsk)->sp)
 
 /*
- * Where abouts of Task's sp, fp, blink when it was last seen in kernel mode.
+ * Where about of Task's sp, fp, blink when it was last seen in kernel mode.
  * Look in process.c for details of kernel stack layout
  */
 #define TSK_K_ESP(tsk)		(tsk->thread.ksp)

commit 46c3e6b8768643d9bc7325324d17e37781b7bbf8
Author: Tal Zilcer <talz@ezchip.com>
Date:   Mon Mar 9 16:58:39 2015 +0200

    ARC: [plat-eznps] Use dedicated cpu_relax()
    
    Since the CTOP is SMT hardware multi-threaded, we need to hint
    the HW that now will be a very good time to do a hardware
    thread context switching. This is done by issuing the schd.rw
    instruction (binary coded here so as to not require specific
    revision of GCC to build the kernel).
    sched.rw means that Thread becomes eligible for execution by
    the threads scheduler after all pending read/write
    transactions were completed.
    
    Implementing cpu_relax_lowlatency() with barrier()
    Since with current semantics of cpu_relax() it may take a
    while till yielded CPU will get back.
    
    Signed-off-by: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 194a09fce198..f9048994b22f 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -57,9 +57,19 @@ struct task_struct;
  * A lot of busy-wait loops in SMP are based off of non-volatile data otherwise
  * get optimised away by gcc
  */
-#define cpu_relax()	__asm__ __volatile__ ("" : : : "memory")
+#ifndef CONFIG_EZNPS_MTM_EXT
 
-#define cpu_relax_lowlatency() cpu_relax()
+#define cpu_relax()		barrier()
+#define cpu_relax_lowlatency()	cpu_relax()
+
+#else
+
+#define cpu_relax()     \
+	__asm__ __volatile__ (".word %0" : : "i"(CTOP_INST_SCHD_RW) : "memory")
+
+#define cpu_relax_lowlatency()	barrier()
+
+#endif
 
 #define copy_segments(tsk, mm)      do { } while (0)
 #define release_segments(mm)        do { } while (0)

commit 8bcf2c48f32e22f923b69f779c95b1348308d5b1
Author: Noam Camus <noamc@ezchip.com>
Date:   Sun Dec 6 15:40:55 2015 +0200

    ARC: [plat-eznps] Use dedicated user stack top
    
    NPS use special mapping right below TASK_SIZE.
    Hence we need to lower STACK_TOP so that user stack won't
    overlap NPS special mapping.
    
    Signed-off-by: Noam Camus <noamc@ezchip.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index d0a9211ec769..194a09fce198 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -121,7 +121,25 @@ extern unsigned int get_wchan(struct task_struct *p);
 
 #define USER_KERNEL_GUTTER    (VMALLOC_START - TASK_SIZE)
 
+#ifdef CONFIG_ARC_PLAT_EZNPS
+/* NPS architecture defines special window of 129M in user address space for
+ * special memory areas, when accessing this window the MMU do not use TLB.
+ * Instead MMU direct the access to:
+ * 0x57f00000:0x57ffffff -- 1M of closely coupled memory (aka CMEM)
+ * 0x58000000:0x5fffffff -- 16 huge pages, 8M each, with fixed map (aka FMTs)
+ *
+ * CMEM - is the fastest memory we got and its size is 16K.
+ * FMT  - is used to map either to internal/external memory.
+ * Internal memory is the second fast memory and its size is 16M
+ * External memory is the biggest memory (16G) and also the slowest.
+ *
+ * STACK_TOP need to be PMD align (21bit) that is why we supply 0x57e00000.
+ */
+#define STACK_TOP       0x57e00000
+#else
 #define STACK_TOP       TASK_SIZE
+#endif
+
 #define STACK_TOP_MAX   STACK_TOP
 
 /* This decides where the kernel will search for a free chunk of vm

commit 15ca68a993d10767c37793e6a0a780b0a7e395dd
Author: Noam Camus <noamc@ezchip.com>
Date:   Sun Sep 7 22:52:33 2014 +0300

    ARC: Make vmalloc size configurable
    
    On ARC, lower 2G of address space is translated and used for
     - user vaddr space (region 0 to 5)
     - unused kernel-user gutter (region 6)
     - kernel vaddr space (region 7)
    
    where each region simply represents 256MB of address space.
    
    The kernel vaddr space of 256MB is used to implement vmalloc, modules
    So far this was enough, but not on EZChip system with 4K CPUs (given
    that per cpu mechanism uses vmalloc for allocating chunks)
    
    So allow VMALLOC_SIZE to be configurable by expanding down into the unused
    kernel-user gutter region which at default 256M was excessive anyways.
    
    Also use _BITUL() to fix a build error since PGDIR_SIZE cannot use "1UL"
    as called from assembly code in mm/tlbex.S
    
    Signed-off-by: Noam Camus <noamc@ezchip.com>
    [vgupta: rewrote changelog, debugged bootup crash due to int vs. hex]
    Acked-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 1d694c1ef6d6..d0a9211ec769 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -97,7 +97,7 @@ extern unsigned int get_wchan(struct task_struct *p);
 #endif /* !__ASSEMBLY__ */
 
 /*
- * System Memory Map on ARC
+ * Default System Memory Map on ARC
  *
  * ---------------------------- (lower 2G, Translated) -------------------------
  * 0x0000_0000		0x5FFF_FFFF	(user vaddr: TASK_SIZE)
@@ -109,18 +109,17 @@ extern unsigned int get_wchan(struct task_struct *p);
  * 0xC000_0000		0xFFFF_FFFF	(peripheral uncached space)
  * -----------------------------------------------------------------------------
  */
-#define VMALLOC_START	0x70000000
 
-/*
- * 1 PGDIR_SIZE each for fixmap/pkmap, 2 PGDIR_SIZE gutter
- * See asm/highmem.h for details
- */
-#define VMALLOC_SIZE	(PAGE_OFFSET - VMALLOC_START - PGDIR_SIZE * 4)
-#define VMALLOC_END	(VMALLOC_START + VMALLOC_SIZE)
+#define TASK_SIZE	0x60000000
 
-#define USER_KERNEL_GUTTER    0x10000000
+#define VMALLOC_START	(PAGE_OFFSET - (CONFIG_ARC_KVADDR_SIZE << 20))
+
+/* 1 PGDIR_SIZE each for fixmap/pkmap, 2 PGDIR_SIZE gutter (see asm/highmem.h) */
+#define VMALLOC_SIZE	((CONFIG_ARC_KVADDR_SIZE << 20) - PGDIR_SIZE * 4)
+
+#define VMALLOC_END	(VMALLOC_START + VMALLOC_SIZE)
 
-#define TASK_SIZE	(VMALLOC_START - USER_KERNEL_GUTTER)
+#define USER_KERNEL_GUTTER    (VMALLOC_START - TASK_SIZE)
 
 #define STACK_TOP       TASK_SIZE
 #define STACK_TOP_MAX   STACK_TOP

commit 1cfc05cbe2c9757c6cc36804df96e3ed28e940a1
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Mon Nov 9 17:48:34 2015 +0530

    ARC: cpu_relax() to be compiler barrier even for UP
    
    cpu_relax() on ARC has been barrier only for SMP (and no-op for UP). Per
    recent discussions, it is safer to make it a compiler barrier
    unconditionally.
    
    Link: http://lkml.kernel.org/r/53A7D3AA.9020100@synopsys.com
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 44545354e9e8..1d694c1ef6d6 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -57,11 +57,7 @@ struct task_struct;
  * A lot of busy-wait loops in SMP are based off of non-volatile data otherwise
  * get optimised away by gcc
  */
-#ifdef CONFIG_SMP
 #define cpu_relax()	__asm__ __volatile__ ("" : : : "memory")
-#else
-#define cpu_relax()	do { } while (0)
-#endif
 
 #define cpu_relax_lowlatency() cpu_relax()
 

commit 45890f6d34e70d9dd194bd1729eba3ff72cabf78
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Mon Mar 9 18:53:49 2015 +0530

    ARC: mm: HIGHMEM: kmap API implementation
    
    Implement kmap* API for ARC.
    
    This enables
     - permanent kernel maps (pkmaps): :kmap() API
     - fixmap : kmap_atomic()
    
    We use a very simple/uniform approach for both (unlike some of the other
    arches). So fixmap doesn't use the customary compile time address stuff.
    The important semantic is sleep'ability (pkmap) vs. not (fixmap) which
    the API guarantees.
    
    Note that this patch only enables highmem for subsequent PAE40 support
    as there is no real highmem for ARC in pure 32-bit paradigm as explained
    below.
    
    ARC has 2:2 address split of the 32-bit address space with lower half
    being translated (virtual) while upper half unstranslated
    (0x8000_0000 to 0xFFFF_FFFF). kernel itself is linked at base of
    unstranslated space (i.e. 0x8000_0000 onwards), which is mapped to say
    DDR 0x0 by external Bus Glue logic (outside the core). So kernel can
    potentially access 1.75G worth of memory directly w/o need for highmem.
    (the top 256M is taken by uncached peripheral space from 0xF000_0000 to
    0xFFFF_FFFF)
    
    In PAE40, hardware can address memory beyond 4G (0x1_0000_0000) while
    the logical/virtual addresses remain 32-bits. Thus highmem is required
    for kernel proper to be able to access these pages for it's own purposes
    (user space is agnostic to this anyways).
    
    Signed-off-by: Alexey Brodkin <abrodkin@synopsys.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index ee682d8e0213..44545354e9e8 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -114,7 +114,12 @@ extern unsigned int get_wchan(struct task_struct *p);
  * -----------------------------------------------------------------------------
  */
 #define VMALLOC_START	0x70000000
-#define VMALLOC_SIZE	(PAGE_OFFSET - VMALLOC_START)
+
+/*
+ * 1 PGDIR_SIZE each for fixmap/pkmap, 2 PGDIR_SIZE gutter
+ * See asm/highmem.h for details
+ */
+#define VMALLOC_SIZE	(PAGE_OFFSET - VMALLOC_START - PGDIR_SIZE * 4)
 #define VMALLOC_END	(VMALLOC_START + VMALLOC_SIZE)
 
 #define USER_KERNEL_GUTTER    0x10000000

commit 4db27dca607aed14a852b21db02ddb530551c5eb
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Thu Mar 5 14:46:20 2015 +0530

    ARC: mm: document system mem map clearly
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 649e4398ed8e..ee682d8e0213 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -100,29 +100,26 @@ extern unsigned int get_wchan(struct task_struct *p);
 
 #endif /* !__ASSEMBLY__ */
 
-/* Kernels Virtual memory area.
- * Unlike other architectures(MIPS, sh, cris ) ARC 700 does not have a
- * "kernel translated" region (like KSEG2 in MIPS). So we use a upper part
- * of the translated bottom 2GB for kernel virtual memory and protect
- * these pages from user accesses by disabling Ru, Eu and Wu.
+/*
+ * System Memory Map on ARC
+ *
+ * ---------------------------- (lower 2G, Translated) -------------------------
+ * 0x0000_0000		0x5FFF_FFFF	(user vaddr: TASK_SIZE)
+ * 0x6000_0000		0x6FFF_FFFF	(reserved gutter between U/K)
+ * 0x7000_0000		0x7FFF_FFFF	(kvaddr: vmalloc/modules/pkmap..)
+ *
+ * PAGE_OFFSET ---------------- (Upper 2G, Untranslated) -----------------------
+ * 0x8000_0000		0xBFFF_FFFF	(kernel direct mapped)
+ * 0xC000_0000		0xFFFF_FFFF	(peripheral uncached space)
+ * -----------------------------------------------------------------------------
  */
-#define VMALLOC_SIZE	(0x10000000)	/* 256M */
-#define VMALLOC_START	(PAGE_OFFSET - VMALLOC_SIZE)
-#define VMALLOC_END	(PAGE_OFFSET)
+#define VMALLOC_START	0x70000000
+#define VMALLOC_SIZE	(PAGE_OFFSET - VMALLOC_START)
+#define VMALLOC_END	(VMALLOC_START + VMALLOC_SIZE)
 
-/* Most of the architectures seem to be keeping some kind of padding between
- * userspace TASK_SIZE and PAGE_OFFSET. i.e TASK_SIZE != PAGE_OFFSET.
- */
 #define USER_KERNEL_GUTTER    0x10000000
 
-/* User address space:
- * On ARC700, CPU allows the entire lower half of 32 bit address space to be
- * translated. Thus potentially 2G (0:0x7FFF_FFFF) could be User vaddr space.
- * However we steal 256M for kernel addr (0x7000_0000:0x7FFF_FFFF) and another
- * 256M (0x6000_0000:0x6FFF_FFFF) is gutter between user/kernel spaces
- * Thus total User vaddr space is (0:0x5FFF_FFFF)
- */
-#define TASK_SIZE	(PAGE_OFFSET - VMALLOC_SIZE - USER_KERNEL_GUTTER)
+#define TASK_SIZE	(VMALLOC_START - USER_KERNEL_GUTTER)
 
 #define STACK_TOP       TASK_SIZE
 #define STACK_TOP_MAX   STACK_TOP

commit 1269f4d5c9022ddd53d62e9bfa89b2af08c934ea
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Sat Apr 25 10:40:52 2015 +0530

    ARC: fix warning in sched due to thread_saved_pc()
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 52312cb5dbe2..649e4398ed8e 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -77,7 +77,7 @@ struct task_struct;
  */
 #define TSK_K_ESP(tsk)		(tsk->thread.ksp)
 
-#define TSK_K_REG(tsk, off)	(*((unsigned int *)(TSK_K_ESP(tsk) + \
+#define TSK_K_REG(tsk, off)	(*((unsigned long *)(TSK_K_ESP(tsk) + \
 					sizeof(struct callee_regs) + off)))
 
 #define TSK_K_BLINK(tsk)	TSK_K_REG(tsk, 4)

commit 3240dd57e533da94998029af6e17008a1806c665
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Feb 27 10:59:31 2015 +0530

    ARC: Fix thread_saved_pc()
    
    The old implementation assumed that SP at the time of __switch_to() is
    right above pt_regs which is almost certainly not the case as there will
    be some stack build up between entry into kernel and leading up to
    __switch_to
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 88398caa3989..52312cb5dbe2 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -47,9 +47,6 @@ struct thread_struct {
 /* Forward declaration, a strange C thing */
 struct task_struct;
 
-/* Return saved PC of a blocked thread  */
-unsigned long thread_saved_pc(struct task_struct *t);
-
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_SIZE + (void *)task_stack_page(p)) - 1)
 
@@ -86,6 +83,8 @@ unsigned long thread_saved_pc(struct task_struct *t);
 #define TSK_K_BLINK(tsk)	TSK_K_REG(tsk, 4)
 #define TSK_K_FP(tsk)		TSK_K_REG(tsk, 0)
 
+#define thread_saved_pc(tsk)	TSK_K_BLINK(tsk)
+
 extern void start_thread(struct pt_regs * regs, unsigned long pc,
 			 unsigned long usp);
 

commit 13648b0118a24f4fc76c34e6c7b6ccf447e46a2a
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Feb 27 10:39:17 2015 +0530

    ARC: Fix KSTK_ESP()
    
    /proc/<pid>/maps currently don't annotate stack vma with "[stack]"
    This is because KSTK_ESP ie expected to return usermode SP of tsk while
    currently it returns the kernel mode SP of a sleeping tsk.
    
    While the fix is trivial, we also need to adjust the ARC kernel stack
    unwinder to not use KSTK_SP and friends any more.
    
    Cc: <stable@vger.kernel.org>
    Reported-and-suggested-by: Alexey Brodkin <abrodkin@synopsys.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 4e547296831d..88398caa3989 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -72,18 +72,19 @@ unsigned long thread_saved_pc(struct task_struct *t);
 #define release_segments(mm)        do { } while (0)
 
 #define KSTK_EIP(tsk)   (task_pt_regs(tsk)->ret)
+#define KSTK_ESP(tsk)   (task_pt_regs(tsk)->sp)
 
 /*
  * Where abouts of Task's sp, fp, blink when it was last seen in kernel mode.
  * Look in process.c for details of kernel stack layout
  */
-#define KSTK_ESP(tsk)   (tsk->thread.ksp)
+#define TSK_K_ESP(tsk)		(tsk->thread.ksp)
 
-#define KSTK_REG(tsk, off)	(*((unsigned int *)(KSTK_ESP(tsk) + \
+#define TSK_K_REG(tsk, off)	(*((unsigned int *)(TSK_K_ESP(tsk) + \
 					sizeof(struct callee_regs) + off)))
 
-#define KSTK_BLINK(tsk) KSTK_REG(tsk, 4)
-#define KSTK_FP(tsk)    KSTK_REG(tsk, 0)
+#define TSK_K_BLINK(tsk)	TSK_K_REG(tsk, 4)
+#define TSK_K_FP(tsk)		TSK_K_REG(tsk, 0)
 
 extern void start_thread(struct pt_regs * regs, unsigned long pc,
 			 unsigned long usp);

commit 7bf6df575fd628fd7ec737789ae8bcb7081d77de
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Mon Jan 5 15:24:18 2015 +0100

    arc: Remove unused prepare_to_copy()
    
    prepare_to_copy() was removed from all architectures supported at that
    time in commit 55ccf3fe3f9a ("fork: move the real prepare_to_copy()
    users to arch_dup_task_struct()"). Remove it from arc as well.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 210fe97464c3..4e547296831d 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -56,9 +56,6 @@ unsigned long thread_saved_pc(struct task_struct *t);
 /* Free all resources held by a thread */
 #define release_thread(thread) do { } while (0)
 
-/* Prepare to copy thread state - unlazy all lazy status */
-#define prepare_to_copy(tsk)    do { } while (0)
-
 /*
  * A lot of busy-wait loops in SMP are based off of non-volatile data otherwise
  * get optimised away by gcc

commit 52e9bae93802bd29c33be11e9e758ad7daac805f
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Sat Sep 27 12:53:41 2014 +0530

    ARC: unbork FPU save/restore
    
    Fixes: 2ab402dfd65d15a4b2 "ARC: make start_thread() out-of-line"
    CC: <stable@vger.kernel.org>  #3.16
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 08fbe2e9d4cc..210fe97464c3 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -18,6 +18,15 @@
 
 #include <asm/ptrace.h>
 
+#ifdef CONFIG_ARC_FPU_SAVE_RESTORE
+/* These DPFP regs need to be saved/restored across ctx-sw */
+struct arc_fpu {
+	struct {
+		unsigned int l, h;
+	} aux_dpfp[2];
+};
+#endif
+
 /* Arch specific stuff which needs to be saved per task.
  * However these items are not so important so as to earn a place in
  * struct thread_info

commit be64c997d96dd29029ed40d9df9cbf80fa1c7ed4
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Sat Sep 27 12:49:11 2014 +0530

    ARC: remove extraneous __KERNEL__ guards
    
    Verified by doing make headers_install as none of these files are
    exported to userspace

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 82588f3ba77f..08fbe2e9d4cc 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -14,8 +14,6 @@
 #ifndef __ASM_ARC_PROCESSOR_H
 #define __ASM_ARC_PROCESSOR_H
 
-#ifdef __KERNEL__
-
 #ifndef __ASSEMBLY__
 
 #include <asm/ptrace.h>
@@ -128,6 +126,4 @@ extern unsigned int get_wchan(struct task_struct *p);
  */
 #define TASK_UNMAPPED_BASE      (TASK_SIZE / 3)
 
-#endif /* __KERNEL__ */
-
 #endif /* __ASM_ARC_PROCESSOR_H */

commit 3a6bfbc91df04b081a44d419e0260bad54abddf7
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Sun Jun 29 15:09:33 2014 -0700

    arch, locking: Ciao arch_mutex_cpu_relax()
    
    The arch_mutex_cpu_relax() function, introduced by 34b133f, is
    hacky and ugly. It was added a few years ago to address the fact
    that common cpu_relax() calls include yielding on s390, and thus
    impact the optimistic spinning functionality of mutexes. Nowadays
    we use this function well beyond mutexes: rwsem, qrwlock, mcs and
    lockref. Since the macro that defines the call is in the mutex header,
    any users must include mutex.h and the naming is misleading as well.
    
    This patch (i) renames the call to cpu_relax_lowlatency  ("relax, but
    only if you can do it with very low latency") and (ii) defines it in
    each arch's asm/processor.h local header, just like for regular cpu_relax
    functions. On all archs, except s390, cpu_relax_lowlatency is simply cpu_relax,
    and thus we can take it out of mutex.h. While this can seem redundant,
    I believe it is a good choice as it allows us to move out arch specific
    logic from generic locking primitives and enables future(?) archs to
    transparently define it, similarly to System Z.
    
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Bharat Bhushan <r65777@freescale.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Joseph Myers <joseph@codesourcery.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Qais Yousef <qais.yousef@imgtec.com>
    Cc: Qiaowei Ren <qiaowei.ren@intel.com>
    Cc: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: Stratos Karafotis <stratosk@semaphore.gr>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Vineet Gupta <Vineet.Gupta1@synopsys.com>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Wolfram Sang <wsa@the-dreams.de>
    Cc: adi-buildroot-devel@lists.sourceforge.net
    Cc: linux390@de.ibm.com
    Cc: linux-alpha@vger.kernel.org
    Cc: linux-am33-list@redhat.com
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: linux-cris-kernel@axis.com
    Cc: linux-hexagon@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux@lists.openrisc.net
    Cc: linux-m32r-ja@ml.linux-m32r.org
    Cc: linux-m32r@ml.linux-m32r.org
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: linux-metag@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: linux-xtensa@linux-xtensa.org
    Cc: sparclinux@vger.kernel.org
    Link: http://lkml.kernel.org/r/1404079773.2619.4.camel@buesod1.americas.hpqcorp.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index d99f9b37cd15..82588f3ba77f 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -62,6 +62,8 @@ unsigned long thread_saved_pc(struct task_struct *t);
 #define cpu_relax()	do { } while (0)
 #endif
 
+#define cpu_relax_lowlatency() cpu_relax()
+
 #define copy_segments(tsk, mm)      do { } while (0)
 #define release_segments(mm)        do { } while (0)
 

commit 2ab402dfd65d15a4b25a8756272ababe3ef76884
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Apr 18 12:19:59 2014 +0530

    ARC: make start_thread() out-of-line
    
    Helps move out ISA specific bits from a arch exported header
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 15334ab66b56..d99f9b37cd15 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -18,7 +18,6 @@
 
 #ifndef __ASSEMBLY__
 
-#include <asm/arcregs.h>	/* for STATUS_E1_MASK et all */
 #include <asm/ptrace.h>
 
 /* Arch specific stuff which needs to be saved per task.
@@ -41,15 +40,13 @@ struct thread_struct {
 /* Forward declaration, a strange C thing */
 struct task_struct;
 
-/*
- * Return saved PC of a blocked thread.
- */
+/* Return saved PC of a blocked thread  */
 unsigned long thread_saved_pc(struct task_struct *t);
 
 #define task_pt_regs(p) \
 	((struct pt_regs *)(THREAD_SIZE + (void *)task_stack_page(p)) - 1)
 
-/* Free all resources held by a thread. */
+/* Free all resources held by a thread */
 #define release_thread(thread) do { } while (0)
 
 /* Prepare to copy thread state - unlazy all lazy status */
@@ -82,26 +79,8 @@ unsigned long thread_saved_pc(struct task_struct *t);
 #define KSTK_BLINK(tsk) KSTK_REG(tsk, 4)
 #define KSTK_FP(tsk)    KSTK_REG(tsk, 0)
 
-/*
- * Do necessary setup to start up a newly executed thread.
- *
- * E1,E2 so that Interrupts are enabled in user mode
- * L set, so Loop inhibited to begin with
- * lp_start and lp_end seeded with bogus non-zero values so to easily catch
- * the ARC700 sr to lp_start hardware bug
- */
-#define start_thread(_regs, _pc, _usp)				\
-do {								\
-	set_fs(USER_DS); /* reads from user space */		\
-	(_regs)->ret = (_pc);					\
-	/* Interrupts enabled in User Mode */			\
-	(_regs)->status32 = STATUS_U_MASK | STATUS_L_MASK	\
-		| STATUS_E1_MASK | STATUS_E2_MASK;		\
-	(_regs)->sp = (_usp);					\
-	/* bogus seed values for debugging */			\
-	(_regs)->lp_start = 0x10;				\
-	(_regs)->lp_end = 0x80;					\
-} while (0)
+extern void start_thread(struct pt_regs * regs, unsigned long pc,
+			 unsigned long usp);
 
 extern unsigned int get_wchan(struct task_struct *p);
 

commit 38a9ff6d247cf9afcbe55ea245b650b8955029fd
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Wed Jun 12 15:13:40 2013 +0530

    ARC: Remove explicit passing around of ECR
    
    With ECR now part of pt_regs
    
    * No need to propagate from lowest asm handlers as arg
    * No need to save it in tsk->thread.cause_code
    * Avoid bit chopping to access the bit-fields
    
    More code consolidation, cleanup
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index b0b5d2d9b3d3..15334ab66b56 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -29,7 +29,6 @@ struct thread_struct {
 	unsigned long ksp;	/* kernel mode stack pointer */
 	unsigned long callee_reg;	/* pointer to callee regs */
 	unsigned long fault_address;	/* dbls as brkpt holder as well */
-	unsigned long cause_code;	/* Exception Cause Code (ECR) */
 #ifdef CONFIG_ARC_FPU_SAVE_RESTORE
 	struct arc_fpu fpu;
 #endif

commit 359105bdb06f8421fd8e69ae47fd052e398b6778
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Tue May 28 13:50:41 2013 +0530

    ARC: pt_regs update #4: r25 saved/restored unconditionally
    
    (This is a VERY IMP change for low level interrupt/exception handling)
    
    -----------------------------------------------------------------------
    WHAT
    -----------------------------------------------------------------------
    * User 25 now saved in pt_regs->user_r25 (vs. tsk->thread_info.user_r25)
    
    * This allows Low level interrupt code to unconditionally save r25
      (vs. the prev version which would only do it for U->K transition).
      Ofcourse for nested interrupts, only the pt_regs->user_r25 of
      bottom-most frame is useful.
    
    * simplifies the interrupt prologue/epilogue
    
    * Needed for ARCv2 ISA code and done here to keep design similar with
      ARCompact event handling
    
    -----------------------------------------------------------------------
    WHY
    -------------------------------------------------------------------------
    With CONFIG_ARC_CURR_IN_REG, r25 is used to cache "current" task pointer
    in kernel mode. So when entering kernel mode from User Mode
    - user r25 is specially safe-kept (it being a callee reg is NOT part of
      pt_regs which are saved by default on each interrupt/trap/exception)
    - r25 loaded with current task pointer.
    
    Further, if interrupt was taken in kernel mode, this is skipped since we
    know that r25 already has valid "current" pointer.
    
    With 2 level of interrupts in ARCompact ISA, detecting this is difficult
    but still possible, since we could be in kernel mode but r25 not already saved
    (in fact the stack itself might not have been switched).
    
    A. User mode
    B. L1 IRQ taken
    C. L2 IRQ taken (while on 1st line of L1 ISR)
    
    So in #C, although in kernel mode, r25 not saved (infact SP not
    switched at all)
    
    Given that ARcompact has manual stack switching, we could use a bit of
    trickey - The low level code would make sure that SP is only set to kernel
    mode value at the very end (after saving r25). So a non kernel mode SP,
    even if in kernel mode, meant r25 was NOT saved.
    
    The same paradigm won't work in ARCv2 ISA since SP is auto-switched so
    it's setting can't be delayed/constrained.
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 8c77e623c4e5..b0b5d2d9b3d3 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -30,9 +30,6 @@ struct thread_struct {
 	unsigned long callee_reg;	/* pointer to callee regs */
 	unsigned long fault_address;	/* dbls as brkpt holder as well */
 	unsigned long cause_code;	/* Exception Cause Code (ECR) */
-#ifdef CONFIG_ARC_CURR_IN_REG
-	unsigned long user_r25;
-#endif
 #ifdef CONFIG_ARC_FPU_SAVE_RESTORE
 	struct arc_fpu fpu;
 #endif

commit 16f9afe651e8197fb7ce6df0990d8e2ad779e1af
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Mon May 27 21:43:41 2013 +0530

    ARC: pt_regs update #3: Remove unused gutter at start of callee_regs
    
    This is trickier than prev two:
    
    * context switching code saves kernel mode callee regs in the format of
      struct callee_regs thus needs adjustment. This also reduces the height
      of topmost kernel stack frame by 1 word.
    
    * Since kernel stack unwinder is sensitive to height of topmost kernel
      stack frame, that needs a word of adjustment too.
    
    ptrace needs a bit of updating since pt_regs now diverges from
    user_regs_struct.
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 81efbcae3839..8c77e623c4e5 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -19,6 +19,7 @@
 #ifndef __ASSEMBLY__
 
 #include <asm/arcregs.h>	/* for STATUS_E1_MASK et all */
+#include <asm/ptrace.h>
 
 /* Arch specific stuff which needs to be saved per task.
  * However these items are not so important so as to earn a place in
@@ -75,11 +76,15 @@ unsigned long thread_saved_pc(struct task_struct *t);
 
 /*
  * Where abouts of Task's sp, fp, blink when it was last seen in kernel mode.
- * These can't be derived from pt_regs as that would give correp user-mode val
+ * Look in process.c for details of kernel stack layout
  */
 #define KSTK_ESP(tsk)   (tsk->thread.ksp)
-#define KSTK_BLINK(tsk) (*((unsigned int *)((KSTK_ESP(tsk)) + (13+1+1)*4)))
-#define KSTK_FP(tsk)    (*((unsigned int *)((KSTK_ESP(tsk)) + (13+1)*4)))
+
+#define KSTK_REG(tsk, off)	(*((unsigned int *)(KSTK_ESP(tsk) + \
+					sizeof(struct callee_regs) + off)))
+
+#define KSTK_BLINK(tsk) KSTK_REG(tsk, 4)
+#define KSTK_FP(tsk)    KSTK_REG(tsk, 0)
 
 /*
  * Do necessary setup to start up a newly executed thread.

commit 283237a04fd332bddc2ac298e6ad7d23a1fc4b99
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Tue May 28 09:34:45 2013 +0530

    ARC: pt_regs update #1: Align pt_regs end with end of kernel stack page
    
    Historically, pt_regs would end at offset of 1 word from end of stack
    page.
    
            -----------------  -> START of page (task->stack)
            |               |
            | thread_info   |
            -----------------
            |               |
       ^    ~               ~
       |    ~               ~
       |    |               |
       |    |               | <---- pt_regs used to END here
            -----------------
            | 1 word GUTTER |
            ----------------- -> End of page (START of kernel stack)
    
    This required special "one-off" considerations in low level code.
    
    The root cause is very likely assumption of "empty" SP by the original
    ARC kernel hackers, despite ARC700 always been "full" SP.
    
    So finally RIP one word gutter !
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 5f26b2c1cba0..81efbcae3839 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -50,7 +50,7 @@ struct task_struct;
 unsigned long thread_saved_pc(struct task_struct *t);
 
 #define task_pt_regs(p) \
-	((struct pt_regs *)(THREAD_SIZE - 4 + (void *)task_stack_page(p)) - 1)
+	((struct pt_regs *)(THREAD_SIZE + (void *)task_stack_page(p)) - 1)
 
 /* Free all resources held by a thread. */
 #define release_thread(thread) do { } while (0)

commit 41195d236e84458bebd4fdc218610a92231ac791
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Jan 18 15:12:23 2013 +0530

    ARC: SMP support
    
    ARC common code to enable a SMP system + ISS provided SMP extensions.
    
    ARC700 natively lacks SMP support, hence some of the core features are
    are only enabled if SoCs have the necessary h/w pixie-dust. This
    includes:
    -Inter Processor Interrupts (IPI)
    -Cache coherency
    -load-locked/store-conditional
    ...
    
    The low level exception handling would be completely broken in SMP
    because we don't have hardware assisted stack switching. Thus a fair bit
    of this code is repurposing the MMU_SCRATCH reg for event handler
    prologues to keep them re-entrant.
    
    Many thanks to Rajeshwar Ranga for his initial "major" contributions to
    SMP Port (back in 2008), and to Noam Camus and Gilad Ben-Yossef for help
    with resurrecting that in 3.2 kernel (2012).
    
    Note that this platform code is again singleton design pattern - so
    multiple SMP platforms won't build at the moment - this deficiency is
    addressed in subsequent patches within this series.
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Rajeshwar Ranga <rajeshwar.ranga@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Gilad Ben-Yossef <gilad@benyossef.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index b7b155610067..5f26b2c1cba0 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -58,7 +58,15 @@ unsigned long thread_saved_pc(struct task_struct *t);
 /* Prepare to copy thread state - unlazy all lazy status */
 #define prepare_to_copy(tsk)    do { } while (0)
 
+/*
+ * A lot of busy-wait loops in SMP are based off of non-volatile data otherwise
+ * get optimised away by gcc
+ */
+#ifdef CONFIG_SMP
+#define cpu_relax()	__asm__ __volatile__ ("" : : : "memory")
+#else
 #define cpu_relax()	do { } while (0)
+#endif
 
 #define copy_segments(tsk, mm)      do { } while (0)
 #define release_segments(mm)        do { } while (0)

commit 080c37473eb671a037b3e9a315303851f0675be5
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Mon Feb 11 19:52:57 2013 +0530

    ARC: [optim] Cache "current" in Register r25
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index 860252ec3fa7..b7b155610067 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -29,6 +29,9 @@ struct thread_struct {
 	unsigned long callee_reg;	/* pointer to callee regs */
 	unsigned long fault_address;	/* dbls as brkpt holder as well */
 	unsigned long cause_code;	/* Exception Cause Code (ECR) */
+#ifdef CONFIG_ARC_CURR_IN_REG
+	unsigned long user_r25;
+#endif
 #ifdef CONFIG_ARC_FPU_SAVE_RESTORE
 	struct arc_fpu fpu;
 #endif

commit bf90e1eab682dcb79b7765989fb65835ce9d6165
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Jan 18 15:12:18 2013 +0530

    ARC: Process-creation/scheduling/idle-loop
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
index bf88cfbc9128..860252ec3fa7 100644
--- a/arch/arc/include/asm/processor.h
+++ b/arch/arc/include/asm/processor.h
@@ -29,6 +29,9 @@ struct thread_struct {
 	unsigned long callee_reg;	/* pointer to callee regs */
 	unsigned long fault_address;	/* dbls as brkpt holder as well */
 	unsigned long cause_code;	/* Exception Cause Code (ECR) */
+#ifdef CONFIG_ARC_FPU_SAVE_RESTORE
+	struct arc_fpu fpu;
+#endif
 };
 
 #define INIT_THREAD  {                          \
@@ -54,12 +57,6 @@ unsigned long thread_saved_pc(struct task_struct *t);
 
 #define cpu_relax()	do { } while (0)
 
-/*
- * Create a new kernel thread
- */
-
-extern int kernel_thread(int (*fn) (void *), void *arg, unsigned long flags);
-
 #define copy_segments(tsk, mm)      do { } while (0)
 #define release_segments(mm)        do { } while (0)
 

commit 3be80aaef861a60b85a9323462ebb5f623774f7a
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Jan 18 15:12:17 2013 +0530

    ARC: Fundamental ARCH data-types/defines
    
    * L1_CACHE_SHIFT
    * PAGE_SIZE, PAGE_OFFSET
    * struct pt_regs, struct user_regs_struct
    * struct thread_struct, cpu_relax(), task_pt_regs(), start_thread(), ...
    * struct thread_info, THREAD_SIZE, INIT_THREAD_INFO(), TIF_*, ...
    * BUG()
    * ELF_*
    * Elf_*
    
    To disallow user-space visibility into some of the core kernel data-types
    such as struct pt_regs, #ifdef __KERNEL__ which also makes the UAPI header
    spit (further patch in the series) to NOT export it to asm/uapi/ptrace.h
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Jonas Bonn <jonas.bonn@gmail.com>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/arc/include/asm/processor.h b/arch/arc/include/asm/processor.h
new file mode 100644
index 000000000000..bf88cfbc9128
--- /dev/null
+++ b/arch/arc/include/asm/processor.h
@@ -0,0 +1,143 @@
+/*
+ * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * vineetg: March 2009
+ *  -Implemented task_pt_regs( )
+ *
+ * Amit Bhor, Sameer Dhavale, Ashwin Chaugule: Codito Technologies 2004
+ */
+
+#ifndef __ASM_ARC_PROCESSOR_H
+#define __ASM_ARC_PROCESSOR_H
+
+#ifdef __KERNEL__
+
+#ifndef __ASSEMBLY__
+
+#include <asm/arcregs.h>	/* for STATUS_E1_MASK et all */
+
+/* Arch specific stuff which needs to be saved per task.
+ * However these items are not so important so as to earn a place in
+ * struct thread_info
+ */
+struct thread_struct {
+	unsigned long ksp;	/* kernel mode stack pointer */
+	unsigned long callee_reg;	/* pointer to callee regs */
+	unsigned long fault_address;	/* dbls as brkpt holder as well */
+	unsigned long cause_code;	/* Exception Cause Code (ECR) */
+};
+
+#define INIT_THREAD  {                          \
+	.ksp = sizeof(init_stack) + (unsigned long) init_stack, \
+}
+
+/* Forward declaration, a strange C thing */
+struct task_struct;
+
+/*
+ * Return saved PC of a blocked thread.
+ */
+unsigned long thread_saved_pc(struct task_struct *t);
+
+#define task_pt_regs(p) \
+	((struct pt_regs *)(THREAD_SIZE - 4 + (void *)task_stack_page(p)) - 1)
+
+/* Free all resources held by a thread. */
+#define release_thread(thread) do { } while (0)
+
+/* Prepare to copy thread state - unlazy all lazy status */
+#define prepare_to_copy(tsk)    do { } while (0)
+
+#define cpu_relax()	do { } while (0)
+
+/*
+ * Create a new kernel thread
+ */
+
+extern int kernel_thread(int (*fn) (void *), void *arg, unsigned long flags);
+
+#define copy_segments(tsk, mm)      do { } while (0)
+#define release_segments(mm)        do { } while (0)
+
+#define KSTK_EIP(tsk)   (task_pt_regs(tsk)->ret)
+
+/*
+ * Where abouts of Task's sp, fp, blink when it was last seen in kernel mode.
+ * These can't be derived from pt_regs as that would give correp user-mode val
+ */
+#define KSTK_ESP(tsk)   (tsk->thread.ksp)
+#define KSTK_BLINK(tsk) (*((unsigned int *)((KSTK_ESP(tsk)) + (13+1+1)*4)))
+#define KSTK_FP(tsk)    (*((unsigned int *)((KSTK_ESP(tsk)) + (13+1)*4)))
+
+/*
+ * Do necessary setup to start up a newly executed thread.
+ *
+ * E1,E2 so that Interrupts are enabled in user mode
+ * L set, so Loop inhibited to begin with
+ * lp_start and lp_end seeded with bogus non-zero values so to easily catch
+ * the ARC700 sr to lp_start hardware bug
+ */
+#define start_thread(_regs, _pc, _usp)				\
+do {								\
+	set_fs(USER_DS); /* reads from user space */		\
+	(_regs)->ret = (_pc);					\
+	/* Interrupts enabled in User Mode */			\
+	(_regs)->status32 = STATUS_U_MASK | STATUS_L_MASK	\
+		| STATUS_E1_MASK | STATUS_E2_MASK;		\
+	(_regs)->sp = (_usp);					\
+	/* bogus seed values for debugging */			\
+	(_regs)->lp_start = 0x10;				\
+	(_regs)->lp_end = 0x80;					\
+} while (0)
+
+extern unsigned int get_wchan(struct task_struct *p);
+
+/*
+ * Default implementation of macro that returns current
+ * instruction pointer ("program counter").
+ * Should the PC register be read instead ? This macro does not seem to
+ * be used in many places so this wont be all that bad.
+ */
+#define current_text_addr() ({ __label__ _l; _l: &&_l; })
+
+#endif /* !__ASSEMBLY__ */
+
+/* Kernels Virtual memory area.
+ * Unlike other architectures(MIPS, sh, cris ) ARC 700 does not have a
+ * "kernel translated" region (like KSEG2 in MIPS). So we use a upper part
+ * of the translated bottom 2GB for kernel virtual memory and protect
+ * these pages from user accesses by disabling Ru, Eu and Wu.
+ */
+#define VMALLOC_SIZE	(0x10000000)	/* 256M */
+#define VMALLOC_START	(PAGE_OFFSET - VMALLOC_SIZE)
+#define VMALLOC_END	(PAGE_OFFSET)
+
+/* Most of the architectures seem to be keeping some kind of padding between
+ * userspace TASK_SIZE and PAGE_OFFSET. i.e TASK_SIZE != PAGE_OFFSET.
+ */
+#define USER_KERNEL_GUTTER    0x10000000
+
+/* User address space:
+ * On ARC700, CPU allows the entire lower half of 32 bit address space to be
+ * translated. Thus potentially 2G (0:0x7FFF_FFFF) could be User vaddr space.
+ * However we steal 256M for kernel addr (0x7000_0000:0x7FFF_FFFF) and another
+ * 256M (0x6000_0000:0x6FFF_FFFF) is gutter between user/kernel spaces
+ * Thus total User vaddr space is (0:0x5FFF_FFFF)
+ */
+#define TASK_SIZE	(PAGE_OFFSET - VMALLOC_SIZE - USER_KERNEL_GUTTER)
+
+#define STACK_TOP       TASK_SIZE
+#define STACK_TOP_MAX   STACK_TOP
+
+/* This decides where the kernel will search for a free chunk of vm
+ * space during mmap's.
+ */
+#define TASK_UNMAPPED_BASE      (TASK_SIZE / 3)
+
+#endif /* __KERNEL__ */
+
+#endif /* __ASM_ARC_PROCESSOR_H */
