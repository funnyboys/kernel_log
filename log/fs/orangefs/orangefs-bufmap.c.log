commit 0df556457748d160013e88202c11712c16a83b0c
Author: John Hubbard <jhubbard@nvidia.com>
Date:   Fri May 22 20:59:09 2020 -0700

    orangefs: convert get_user_pages() --> pin_user_pages()
    
    This code was using get_user_pages*(), in a "Case 1" scenario
    (Direct IO), using the categorization from [1]. That means that it's
    time to convert the get_user_pages*() + put_page() calls to
    pin_user_pages*() + unpin_user_pages() calls.
    
    There is some helpful background in [2]: basically, this is a small
    part of fixing a long-standing disconnect between pinning pages, and
    file systems' use of those pages.
    
    [1] Documentation/core-api/pin_user_pages.rst
    
    [2] "Explicit pinning of user-space pages":
        https://lwn.net/Articles/807108/
    
    Cc: Mike Marshall <hubcap@omnibond.com>
    Cc: Martin Brandenburg <martin@omnibond.com>
    Cc: devel@lists.orangefs.org
    Cc: linux-fsdevel@vger.kernel.org
    Signed-off-by: John Hubbard <jhubbard@nvidia.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 2bb916d68576..538e839590ef 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -168,10 +168,7 @@ static DEFINE_SPINLOCK(orangefs_bufmap_lock);
 static void
 orangefs_bufmap_unmap(struct orangefs_bufmap *bufmap)
 {
-	int i;
-
-	for (i = 0; i < bufmap->page_count; i++)
-		put_page(bufmap->page_array[i]);
+	unpin_user_pages(bufmap->page_array, bufmap->page_count);
 }
 
 static void
@@ -268,7 +265,7 @@ orangefs_bufmap_map(struct orangefs_bufmap *bufmap,
 	int offset = 0, ret, i;
 
 	/* map the pages */
-	ret = get_user_pages_fast((unsigned long)user_desc->ptr,
+	ret = pin_user_pages_fast((unsigned long)user_desc->ptr,
 			     bufmap->page_count, FOLL_WRITE, bufmap->page_array);
 
 	if (ret < 0)
@@ -280,7 +277,7 @@ orangefs_bufmap_map(struct orangefs_bufmap *bufmap,
 
 		for (i = 0; i < ret; i++) {
 			SetPageError(bufmap->page_array[i]);
-			put_page(bufmap->page_array[i]);
+			unpin_user_page(bufmap->page_array[i]);
 		}
 		return -ENOMEM;
 	}

commit 73b0140bf0fe9df90fb267c00673c4b9bf285430
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Mon May 13 17:17:11 2019 -0700

    mm/gup: change GUP fast to use flags rather than a write 'bool'
    
    To facilitate additional options to get_user_pages_fast() change the
    singular write parameter to be gup_flags.
    
    This patch does not change any functionality.  New functionality will
    follow in subsequent patches.
    
    Some of the get_user_pages_fast() call sites were unchanged because they
    already passed FOLL_WRITE or 0 for the write parameter.
    
    NOTE: It was suggested to change the ordering of the get_user_pages_fast()
    arguments to ensure that callers were converted.  This breaks the current
    GUP call site convention of having the returned pages be the final
    parameter.  So the suggestion was rejected.
    
    Link: http://lkml.kernel.org/r/20190328084422.29911-4-ira.weiny@intel.com
    Link: http://lkml.kernel.org/r/20190317183438.2057-4-ira.weiny@intel.com
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Mike Marshall <hubcap@omnibond.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index d4811f981608..2bb916d68576 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -269,7 +269,7 @@ orangefs_bufmap_map(struct orangefs_bufmap *bufmap,
 
 	/* map the pages */
 	ret = get_user_pages_fast((unsigned long)user_desc->ptr,
-			     bufmap->page_count, 1, bufmap->page_array);
+			     bufmap->page_count, FOLL_WRITE, bufmap->page_array);
 
 	if (ret < 0)
 		return ret;

commit dd59a6475c4cf69afac2ade01ab732b7825a2a45
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Mon Mar 25 18:59:29 2019 -0400

    orangefs: copy Orangefs-sized blocks into the pagecache if possible.
    
    ->readpage looks in file->private_data to try and find out how the
    userspace program set "count" in read(2) or with "dd bs=" or whatever.
    
    ->readpage uses "count" and inode->i_size to calculate how much
    data Orangefs should deposit in the Orangefs shared buffer, and
    remembers which slot the data is in.
    
    After copying data from the Orangefs shared buffer slot into
    "the page", readpage tries to increment through the pagecache index
    and fill as many pages as it can from the extra data in the shared
    buffer. Hopefully these extra pages will soon be needed by the vfs,
    and they'll be in the pagecache already.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 443bcd8c3c19..d4811f981608 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -538,3 +538,16 @@ int orangefs_bufmap_copy_to_iovec(struct iov_iter *iter,
 	}
 	return 0;
 }
+
+void orangefs_bufmap_page_fill(void *page_to,
+				int buffer_index,
+				int slot_index)
+{
+	struct orangefs_bufmap_desc *from;
+	void *page_from;
+
+	from = &__orangefs_bufmap->desc_array[buffer_index];
+	page_from = kmap_atomic(from->page_array[slot_index]);
+	memcpy(page_to, page_from, PAGE_SIZE);
+	kunmap_atomic(page_from);
+}

commit 08d405c8b845a4b871fa3606c9ebe0d0f3b74614
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Thu Jan 3 15:28:58 2019 -0800

    fs/: remove caller signal_pending branch predictions
    
    This is already done for us internally by the signal machinery.
    
    [akpm@linux-foundation.org: fix fs/buffer.c]
    Link: http://lkml.kernel.org/r/20181116002713.8474-7-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dave@stgolabs.net>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index c4e98c9c1621..443bcd8c3c19 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -105,7 +105,7 @@ static int wait_for_free(struct slot_map *m)
 			left = t;
 		else
 			left = t + (left - n);
-		if (unlikely(signal_pending(current)))
+		if (signal_pending(current))
 			left = -EINTR;
 	} while (left > 0);
 

commit 8a6080f574b172f4d0916f69c52d3a157d355f9c
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Jun 1 13:18:26 2018 -0400

    orangefs: remove unused function orangefs_get_bufmap_init
    
    get_bufmap_init is used in the out-of-tree module, but was left in
    the upstream version as an oversight. Tip-of-the-hat to sparse and Al Viro.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index c4699a164f76..c4e98c9c1621 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -215,20 +215,6 @@ int orangefs_bufmap_shift_query(void)
 static DECLARE_WAIT_QUEUE_HEAD(bufmap_waitq);
 static DECLARE_WAIT_QUEUE_HEAD(readdir_waitq);
 
-/*
- * orangefs_get_bufmap_init
- *
- * If bufmap_init is 1, then the shared memory system, including the
- * buffer_index_array, is available.  Otherwise, it is not.
- *
- * returns the value of bufmap_init
- */
-int orangefs_get_bufmap_init(void)
-{
-	return __orangefs_bufmap ? 1 : 0;
-}
-
-
 static struct orangefs_bufmap *
 orangefs_bufmap_alloc(struct ORANGEFS_dev_map_desc *user_desc)
 {

commit 817e9b4d9e660761e1e613aa294bf77d2e7c7310
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Jun 1 12:19:45 2018 -0400

    orangefs: specify user pointers when using dev_map_desc and bufmap
    
    Sparse lead me to the dev_map_desc one and Al Viro lead me to the bufmap
    one.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index e3302f8d6429..c4699a164f76 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -138,7 +138,7 @@ static int get(struct slot_map *m)
 
 /* used to describe mapped buffers */
 struct orangefs_bufmap_desc {
-	void *uaddr;			/* user space address pointer */
+	void __user *uaddr;		/* user space address pointer */
 	struct page **page_array;	/* array of mapped pages */
 	int array_count;		/* size of above arrays */
 	struct list_head list_link;

commit 95f5f88f8900c09eb534c8cb42d75ff3cf7ea96c
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri May 11 17:11:48 2018 -0400

    orangefs: formatting cleanups
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 4f927023d095..e3302f8d6429 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -184,7 +184,7 @@ orangefs_bufmap_free(struct orangefs_bufmap *bufmap)
 }
 
 /*
- * XXX: Can the size and shift change while the caller gives up the 
+ * XXX: Can the size and shift change while the caller gives up the
  * XXX: lock between calling this and doing something useful?
  */
 
@@ -496,7 +496,7 @@ void orangefs_readdir_index_put(int buffer_index)
 }
 
 /*
- * we've been handed an iovec, we need to copy it to 
+ * we've been handed an iovec, we need to copy it to
  * the shared memory descriptor at "buffer_index".
  */
 int orangefs_bufmap_copy_from_iovec(struct iov_iter *iter,

commit c2676ef801f50cc759d205a89adbf733c798d052
Author: David Reynolds <david@omnibond.com>
Date:   Thu Mar 8 18:54:12 2018 -0500

    orangefs: bug fix for a race condition when getting a slot
    
    When a slot becomes free, call wake_up_locked regardless of the number
    of slots available.
    
    Without this patch, wake_up_locked is only called when going from no
    free slots to one. This means that there is a chance a waiting task
    will not be woken up. In many cases, the system will bounce between 0
    and 1 free slots, and the waiting tasks will be woken up. But if there
    is still a waiting task and another slot becomes available before the
    number of free slots reaches zero, that waiting task may never be woken
    up since the number of free slots may never reach zero again.
    
    The bug behavior is easy to reproduce with the following script,
    where /mnt/orangefs is an OrangeFS file system.
    
    for i in {1..100}; do
            for j in {1..20}; do
                    dd if=/dev/zero of=/mnt/orangefs/tmp$j bs=32768 count=32 &
            done
            wait
    done
    
    Signed-off-by: David Reynolds <david@omnibond.com>
    Reviewed-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 59f444dced9b..4f927023d095 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -71,9 +71,9 @@ static void put(struct slot_map *m, int slot)
 	spin_lock(&m->q.lock);
 	__clear_bit(slot, m->map);
 	v = ++m->c;
-	if (unlikely(v == 1))	/* no free slots -> one free slot */
+	if (v > 0)
 		wake_up_locked(&m->q);
-	else if (unlikely(v == -1))	/* finished dying */
+	if (unlikely(v == -1))     /* finished dying */
 		wake_up_all_locked(&m->q);
 	spin_unlock(&m->q.lock);
 }

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 7ef473f3d642..59f444dced9b 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * (C) 2001 Clemson University and The University of Chicago
  *

commit 07a258531c7550f8bb481dfe2ec12bb876224487
Author: Markus Elfring <elfring@users.sourceforge.net>
Date:   Thu Aug 17 21:00:07 2017 +0200

    orangefs: Delete error messages for a failed memory allocation in five functions
    
    Omit an extra message for a memory allocation failure in these functions.
    
    This issue was detected by using the Coccinelle software.
    
    Signed-off-by: Markus Elfring <elfring@users.sourceforge.net>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 038d67545d9f..7ef473f3d642 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -244,20 +244,14 @@ orangefs_bufmap_alloc(struct ORANGEFS_dev_map_desc *user_desc)
 
 	bufmap->buffer_index_array =
 		kzalloc(DIV_ROUND_UP(bufmap->desc_count, BITS_PER_LONG), GFP_KERNEL);
-	if (!bufmap->buffer_index_array) {
-		gossip_err("orangefs: could not allocate %d buffer indices\n",
-				bufmap->desc_count);
+	if (!bufmap->buffer_index_array)
 		goto out_free_bufmap;
-	}
 
 	bufmap->desc_array =
 		kcalloc(bufmap->desc_count, sizeof(struct orangefs_bufmap_desc),
 			GFP_KERNEL);
-	if (!bufmap->desc_array) {
-		gossip_err("orangefs: could not allocate %d descriptors\n",
-				bufmap->desc_count);
+	if (!bufmap->desc_array)
 		goto out_free_index_array;
-	}
 
 	bufmap->page_count = bufmap->total_size / PAGE_SIZE;
 

commit 2055da97389a605c8a00d163d40903afbe413921
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Jun 20 12:06:46 2017 +0200

    sched/wait: Disambiguate wq_entry->task_list and wq_head->task_list naming
    
    So I've noticed a number of instances where it was not obvious from the
    code whether ->task_list was for a wait-queue head or a wait-queue entry.
    
    Furthermore, there's a number of wait-queue users where the lists are
    not for 'tasks' but other entities (poll tables, etc.), in which case
    the 'task_list' name is actively confusing.
    
    To clear this all up, name the wait-queue head and entry list structure
    fields unambiguously:
    
            struct wait_queue_head::task_list       => ::head
            struct wait_queue_entry::task_list      => ::entry
    
    For example, this code:
    
            rqw->wait.task_list.next != &wait->task_list
    
    ... is was pretty unclear (to me) what it's doing, while now it's written this way:
    
            rqw->wait.head.next != &wait->entry
    
    ... which makes it pretty clear that we are iterating a list until we see the head.
    
    Other examples are:
    
            list_for_each_entry_safe(pos, next, &x->task_list, task_list) {
            list_for_each_entry(wq, &fence->wait.task_list, task_list) {
    
    ... where it's unclear (to me) what we are iterating, and during review it's
    hard to tell whether it's trying to walk a wait-queue entry (which would be
    a bug), while now it's written as:
    
            list_for_each_entry_safe(pos, next, &x->head, entry) {
            list_for_each_entry(wq, &fence->wait.head, entry) {
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 9e37b7028ea4..038d67545d9f 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -46,7 +46,7 @@ static void run_down(struct slot_map *m)
 	spin_lock(&m->q.lock);
 	if (m->c != -1) {
 		for (;;) {
-			if (likely(list_empty(&wait.task_list)))
+			if (likely(list_empty(&wait.entry)))
 				__add_wait_queue_entry_tail(&m->q, &wait);
 			set_current_state(TASK_UNINTERRUPTIBLE);
 
@@ -84,7 +84,7 @@ static int wait_for_free(struct slot_map *m)
 
 	do {
 		long n = left, t;
-		if (likely(list_empty(&wait.task_list)))
+		if (likely(list_empty(&wait.entry)))
 			__add_wait_queue_entry_tail_exclusive(&m->q, &wait);
 		set_current_state(TASK_INTERRUPTIBLE);
 
@@ -108,8 +108,8 @@ static int wait_for_free(struct slot_map *m)
 			left = -EINTR;
 	} while (left > 0);
 
-	if (!list_empty(&wait.task_list))
-		list_del(&wait.task_list);
+	if (!list_empty(&wait.entry))
+		list_del(&wait.entry);
 	else if (left <= 0 && waitqueue_active(&m->q))
 		__wake_up_locked_key(&m->q, TASK_INTERRUPTIBLE, NULL);
 	__set_current_state(TASK_RUNNING);

commit ac6424b981bce1c4bc55675c6ce11bfe1bbfa64f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Jun 20 12:06:13 2017 +0200

    sched/wait: Rename wait_queue_t => wait_queue_entry_t
    
    Rename:
    
            wait_queue_t            =>      wait_queue_entry_t
    
    'wait_queue_t' was always a slight misnomer: its name implies that it's a "queue",
    but in reality it's a queue *entry*. The 'real' queue is the wait queue head,
    which had to carry the name.
    
    Start sorting this out by renaming it to 'wait_queue_entry_t'.
    
    This also allows the real structure name 'struct __wait_queue' to
    lose its double underscore and become 'struct wait_queue_entry',
    which is the more canonical nomenclature for such data types.
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 83b506020718..9e37b7028ea4 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -47,7 +47,7 @@ static void run_down(struct slot_map *m)
 	if (m->c != -1) {
 		for (;;) {
 			if (likely(list_empty(&wait.task_list)))
-				__add_wait_queue_tail(&m->q, &wait);
+				__add_wait_queue_entry_tail(&m->q, &wait);
 			set_current_state(TASK_UNINTERRUPTIBLE);
 
 			if (m->c == -1)
@@ -85,7 +85,7 @@ static int wait_for_free(struct slot_map *m)
 	do {
 		long n = left, t;
 		if (likely(list_empty(&wait.task_list)))
-			__add_wait_queue_tail_exclusive(&m->q, &wait);
+			__add_wait_queue_entry_tail_exclusive(&m->q, &wait);
 		set_current_state(TASK_INTERRUPTIBLE);
 
 		if (m->c > 0)

commit 890559e34eac1fb90a4b5916d4a1387376a05d51
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 13 03:10:18 2017 -0400

    orangefs_bufmap_copy_from_iovec(): fix EFAULT handling
    
    short copy here should mean instant EFAULT, not "move to the
    next page and hope it fails there, this time with nothing
    copied"
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 6333cbbdfef7..83b506020718 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -521,13 +521,11 @@ int orangefs_bufmap_copy_from_iovec(struct iov_iter *iter,
 		size_t n = size;
 		if (n > PAGE_SIZE)
 			n = PAGE_SIZE;
-		n = copy_page_from_iter(page, 0, n, iter);
-		if (!n)
+		if (copy_page_from_iter(page, 0, n, iter) != n)
 			return -EFAULT;
 		size -= n;
 	}
 	return 0;
-
 }
 
 /*

commit eb82fbcf82965c18da11ada92b82f1400b36e0ad
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Sat Jan 21 08:04:45 2017 +0300

    orangefs: silence harmless integer overflow warning
    
    The issue here is that in orangefs_bufmap_alloc() we do:
    
            bufmap->buffer_index_array =
                    kzalloc(DIV_ROUND_UP(bufmap->desc_count, BITS_PER_LONG), GFP_KERNEL);
    
    If we choose a bufmap->desc_count like -31 then it means the
    DIV_ROUND_UP ends up having an integer overflow.   The result is that
    kzalloc() returns the ZERO_SIZE_PTR and there is a static checker
    warning.
    
    But this bug is harmless because on the next lines we use ->desc_count
    to do a kcalloc().  That has integer overflow checking built in so the
    kcalloc() fails and we return an error code.
    
    Anyway, it doesn't make sense to talk about negative sizes and blocking
    them silences the static checker warning.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 75375e90a63f..6333cbbdfef7 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -344,6 +344,11 @@ int orangefs_bufmap_initialize(struct ORANGEFS_dev_map_desc *user_desc)
 		     user_desc->size,
 		     user_desc->count);
 
+	if (user_desc->total_size < 0 ||
+	    user_desc->size < 0 ||
+	    user_desc->count < 0)
+		goto out;
+
 	/*
 	 * sanity check alignment and size of buffer that caller wants to
 	 * work with

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 1f8acc9f9a88..75375e90a63f 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -170,7 +170,7 @@ orangefs_bufmap_unmap(struct orangefs_bufmap *bufmap)
 	int i;
 
 	for (i = 0; i < bufmap->page_count; i++)
-		page_cache_release(bufmap->page_array[i]);
+		put_page(bufmap->page_array[i]);
 }
 
 static void
@@ -299,7 +299,7 @@ orangefs_bufmap_map(struct orangefs_bufmap *bufmap,
 
 		for (i = 0; i < ret; i++) {
 			SetPageError(bufmap->page_array[i]);
-			page_cache_release(bufmap->page_array[i]);
+			put_page(bufmap->page_array[i]);
 		}
 		return -ENOMEM;
 	}

commit b8a99a8f9f0aebf2a75bb0d9280bff7e7ac9b57e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Feb 16 20:10:26 2016 -0500

    orangefs: saner calling conventions for getting a slot
    
    just have it return the slot number or -E... - the caller checks
    the sign anyway
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 97689c6cab17..1f8acc9f9a88 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -455,17 +455,11 @@ void orangefs_bufmap_run_down(void)
  * gets a free mapped buffer descriptor, will sleep until one becomes
  * available if necessary
  *
- * returns 0 on success, -errno on failure
+ * returns slot on success, -errno on failure
  */
-int orangefs_bufmap_get(struct orangefs_bufmap **mapp, int *buffer_index)
+int orangefs_bufmap_get(void)
 {
-	int ret = get(&rw_map);
-	if (ret >= 0) {
-		*mapp = __orangefs_bufmap;
-		*buffer_index = ret;
-		ret = 0;
-	}
-	return ret;
+	return get(&rw_map);
 }
 
 /*
@@ -489,17 +483,11 @@ void orangefs_bufmap_put(int buffer_index)
  * we could do that at a later point of time. Regardless, these
  * indices are used by the client-core.
  *
- * returns 0 on success, -errno on failure
+ * returns slot on success, -errno on failure
  */
-int orangefs_readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
+int orangefs_readdir_index_get(void)
 {
-	int ret = get(&readdir_map);
-	if (ret >= 0) {
-		*mapp = __orangefs_bufmap;
-		*buffer_index = ret;
-		ret = 0;
-	}
-	return ret;
+	return get(&readdir_map);
 }
 
 void orangefs_readdir_index_put(int buffer_index)

commit bf6bf606e545cb31c29499b354c13b2621acd649
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Feb 16 20:06:19 2016 -0500

    orangefs_copy_{to,from}_bufmap(): don't pass bufmap pointer
    
    it's always __orangefs_bufmap
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 44d437dbfce0..97689c6cab17 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -511,19 +511,18 @@ void orangefs_readdir_index_put(int buffer_index)
  * we've been handed an iovec, we need to copy it to 
  * the shared memory descriptor at "buffer_index".
  */
-int orangefs_bufmap_copy_from_iovec(struct orangefs_bufmap *bufmap,
-				struct iov_iter *iter,
+int orangefs_bufmap_copy_from_iovec(struct iov_iter *iter,
 				int buffer_index,
 				size_t size)
 {
-	struct orangefs_bufmap_desc *to = &bufmap->desc_array[buffer_index];
+	struct orangefs_bufmap_desc *to;
 	int i;
 
 	gossip_debug(GOSSIP_BUFMAP_DEBUG,
 		     "%s: buffer_index:%d: size:%zu:\n",
 		     __func__, buffer_index, size);
 
-
+	to = &__orangefs_bufmap->desc_array[buffer_index];
 	for (i = 0; size; i++) {
 		struct page *page = to->page_array[i];
 		size_t n = size;
@@ -542,14 +541,14 @@ int orangefs_bufmap_copy_from_iovec(struct orangefs_bufmap *bufmap,
  * we've been handed an iovec, we need to fill it from
  * the shared memory descriptor at "buffer_index".
  */
-int orangefs_bufmap_copy_to_iovec(struct orangefs_bufmap *bufmap,
-				    struct iov_iter *iter,
+int orangefs_bufmap_copy_to_iovec(struct iov_iter *iter,
 				    int buffer_index,
 				    size_t size)
 {
-	struct orangefs_bufmap_desc *from = &bufmap->desc_array[buffer_index];
+	struct orangefs_bufmap_desc *from;
 	int i;
 
+	from = &__orangefs_bufmap->desc_array[buffer_index];
 	gossip_debug(GOSSIP_BUFMAP_DEBUG,
 		     "%s: buffer_index:%d: size:%zu:\n",
 		     __func__, buffer_index, size);

commit 82d37f19ff885ece97b8a072182e39c9dc4ead7d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 21:04:51 2016 -0500

    orangefs_readdir_index_put(): get rid of bufmap argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 96faf4ee6529..44d437dbfce0 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -502,7 +502,7 @@ int orangefs_readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
 	return ret;
 }
 
-void orangefs_readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
+void orangefs_readdir_index_put(int buffer_index)
 {
 	put(&readdir_map, buffer_index);
 }

commit ea2c9c9f6574e835cbc903c94b82b5a34a334866
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 21:01:21 2016 -0500

    orangefs: bufmap rewrite
    
    new waiting-for-slot logics:
            * make request for slot wait for bufmap to be set up if it
    comes before it's installed *OR* while it's running down
            * make closing control device wait for all slots to be freed
            * waiting itself rewritten to (open-coded) analogues of wait_event_...
    primitives - we would need wait_event_locked() and, pardon an obscenely
    long name, wait_event_interruptible_exclusive_timeout_locked().
            * we never wait for more than slot_timeout_secs in total and,
    if during the wait the daemon goes away, we only allow
    ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS for it to come back.
            * (cosmetical) bitmap is used instead of an array of zeroes and ones
            * old (and only reached if we are about to corrupt memory) waiting
    for daemon restart in service_operation() removed.
    
    [Martin's fixes folded]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index cd484665bf72..96faf4ee6529 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -7,7 +7,133 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
-DECLARE_WAIT_QUEUE_HEAD(orangefs_bufmap_init_waitq);
+struct slot_map {
+	int c;
+	wait_queue_head_t q;
+	int count;
+	unsigned long *map;
+};
+
+static struct slot_map rw_map = {
+	.c = -1,
+	.q = __WAIT_QUEUE_HEAD_INITIALIZER(rw_map.q)
+};
+static struct slot_map readdir_map = {
+	.c = -1,
+	.q = __WAIT_QUEUE_HEAD_INITIALIZER(readdir_map.q)
+};
+
+
+static void install(struct slot_map *m, int count, unsigned long *map)
+{
+	spin_lock(&m->q.lock);
+	m->c = m->count = count;
+	m->map = map;
+	wake_up_all_locked(&m->q);
+	spin_unlock(&m->q.lock);
+}
+
+static void mark_killed(struct slot_map *m)
+{
+	spin_lock(&m->q.lock);
+	m->c -= m->count + 1;
+	spin_unlock(&m->q.lock);
+}
+
+static void run_down(struct slot_map *m)
+{
+	DEFINE_WAIT(wait);
+	spin_lock(&m->q.lock);
+	if (m->c != -1) {
+		for (;;) {
+			if (likely(list_empty(&wait.task_list)))
+				__add_wait_queue_tail(&m->q, &wait);
+			set_current_state(TASK_UNINTERRUPTIBLE);
+
+			if (m->c == -1)
+				break;
+
+			spin_unlock(&m->q.lock);
+			schedule();
+			spin_lock(&m->q.lock);
+		}
+		__remove_wait_queue(&m->q, &wait);
+		__set_current_state(TASK_RUNNING);
+	}
+	m->map = NULL;
+	spin_unlock(&m->q.lock);
+}
+
+static void put(struct slot_map *m, int slot)
+{
+	int v;
+	spin_lock(&m->q.lock);
+	__clear_bit(slot, m->map);
+	v = ++m->c;
+	if (unlikely(v == 1))	/* no free slots -> one free slot */
+		wake_up_locked(&m->q);
+	else if (unlikely(v == -1))	/* finished dying */
+		wake_up_all_locked(&m->q);
+	spin_unlock(&m->q.lock);
+}
+
+static int wait_for_free(struct slot_map *m)
+{
+	long left = slot_timeout_secs * HZ;
+	DEFINE_WAIT(wait);
+
+	do {
+		long n = left, t;
+		if (likely(list_empty(&wait.task_list)))
+			__add_wait_queue_tail_exclusive(&m->q, &wait);
+		set_current_state(TASK_INTERRUPTIBLE);
+
+		if (m->c > 0)
+			break;
+
+		if (m->c < 0) {
+			/* we are waiting for map to be installed */
+			/* it would better be there soon, or we go away */
+			if (n > ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS * HZ)
+				n = ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS * HZ;
+		}
+		spin_unlock(&m->q.lock);
+		t = schedule_timeout(n);
+		spin_lock(&m->q.lock);
+		if (unlikely(!t) && n != left && m->c < 0)
+			left = t;
+		else
+			left = t + (left - n);
+		if (unlikely(signal_pending(current)))
+			left = -EINTR;
+	} while (left > 0);
+
+	if (!list_empty(&wait.task_list))
+		list_del(&wait.task_list);
+	else if (left <= 0 && waitqueue_active(&m->q))
+		__wake_up_locked_key(&m->q, TASK_INTERRUPTIBLE, NULL);
+	__set_current_state(TASK_RUNNING);
+
+	if (likely(left > 0))
+		return 0;
+
+	return left < 0 ? -EINTR : -ETIMEDOUT;
+}
+
+static int get(struct slot_map *m)
+{
+	int res = 0;
+	spin_lock(&m->q.lock);
+	if (unlikely(m->c <= 0))
+		res = wait_for_free(m);
+	if (likely(!res)) {
+		m->c--;
+		res = find_first_zero_bit(m->map, m->count);
+		__set_bit(res, m->map);
+	}
+	spin_unlock(&m->q.lock);
+	return res;
+}
 
 /* used to describe mapped buffers */
 struct orangefs_bufmap_desc {
@@ -18,8 +144,6 @@ struct orangefs_bufmap_desc {
 };
 
 static struct orangefs_bufmap {
-	atomic_t refcnt;
-
 	int desc_size;
 	int desc_shift;
 	int desc_count;
@@ -30,12 +154,12 @@ static struct orangefs_bufmap {
 	struct orangefs_bufmap_desc *desc_array;
 
 	/* array to track usage of buffer descriptors */
-	int *buffer_index_array;
-	spinlock_t buffer_index_lock;
+	unsigned long *buffer_index_array;
 
 	/* array to track usage of buffer descriptors for readdir */
-	int readdir_index_array[ORANGEFS_READDIR_DEFAULT_DESC_COUNT];
-	spinlock_t readdir_index_lock;
+#define N DIV_ROUND_UP(ORANGEFS_READDIR_DEFAULT_DESC_COUNT, BITS_PER_LONG)
+	unsigned long readdir_index_array[N];
+#undef N
 } *__orangefs_bufmap;
 
 static DEFINE_SPINLOCK(orangefs_bufmap_lock);
@@ -58,30 +182,6 @@ orangefs_bufmap_free(struct orangefs_bufmap *bufmap)
 	kfree(bufmap);
 }
 
-static struct orangefs_bufmap *orangefs_bufmap_ref(void)
-{
-	struct orangefs_bufmap *bufmap = NULL;
-
-	spin_lock(&orangefs_bufmap_lock);
-	if (__orangefs_bufmap) {
-		bufmap = __orangefs_bufmap;
-		atomic_inc(&bufmap->refcnt);
-	}
-	spin_unlock(&orangefs_bufmap_lock);
-	return bufmap;
-}
-
-static void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
-{
-	if (atomic_dec_and_lock(&bufmap->refcnt, &orangefs_bufmap_lock)) {
-		__orangefs_bufmap = NULL;
-		spin_unlock(&orangefs_bufmap_lock);
-
-		orangefs_bufmap_unmap(bufmap);
-		orangefs_bufmap_free(bufmap);
-	}
-}
-
 /*
  * XXX: Can the size and shift change while the caller gives up the 
  * XXX: lock between calling this and doing something useful?
@@ -137,21 +237,18 @@ orangefs_bufmap_alloc(struct ORANGEFS_dev_map_desc *user_desc)
 	if (!bufmap)
 		goto out;
 
-	atomic_set(&bufmap->refcnt, 1);
 	bufmap->total_size = user_desc->total_size;
 	bufmap->desc_count = user_desc->count;
 	bufmap->desc_size = user_desc->size;
 	bufmap->desc_shift = ilog2(bufmap->desc_size);
 
-	spin_lock_init(&bufmap->buffer_index_lock);
 	bufmap->buffer_index_array =
-		kcalloc(bufmap->desc_count, sizeof(int), GFP_KERNEL);
+		kzalloc(DIV_ROUND_UP(bufmap->desc_count, BITS_PER_LONG), GFP_KERNEL);
 	if (!bufmap->buffer_index_array) {
 		gossip_err("orangefs: could not allocate %d buffer indices\n",
 				bufmap->desc_count);
 		goto out_free_bufmap;
 	}
-	spin_lock_init(&bufmap->readdir_index_lock);
 
 	bufmap->desc_array =
 		kcalloc(bufmap->desc_count, sizeof(struct orangefs_bufmap_desc),
@@ -294,24 +391,18 @@ int orangefs_bufmap_initialize(struct ORANGEFS_dev_map_desc *user_desc)
 	if (__orangefs_bufmap) {
 		spin_unlock(&orangefs_bufmap_lock);
 		gossip_err("orangefs: error: bufmap already initialized.\n");
-		ret = -EALREADY;
+		ret = -EINVAL;
 		goto out_unmap_bufmap;
 	}
 	__orangefs_bufmap = bufmap;
+	install(&rw_map,
+		bufmap->desc_count,
+		bufmap->buffer_index_array);
+	install(&readdir_map,
+		ORANGEFS_READDIR_DEFAULT_DESC_COUNT,
+		bufmap->readdir_index_array);
 	spin_unlock(&orangefs_bufmap_lock);
 
-	/*
-	 * If there are operations in orangefs_bufmap_init_waitq, wake them up.
-	 * This scenario occurs when the client-core is restarted and I/O
-	 * requests in the in-progress or waiting tables are restarted.  I/O
-	 * requests cannot be restarted until the shared memory system is
-	 * completely re-initialized, so we put the I/O requests in this
-	 * waitq until initialization has completed.  NOTE:  the I/O requests
-	 * are also on a timer, so they don't wait forever just in case the
-	 * client-core doesn't come back up.
-	 */
-	wake_up_interruptible(&orangefs_bufmap_init_waitq);
-
 	gossip_debug(GOSSIP_BUFMAP_DEBUG,
 		     "orangefs_bufmap_initialize: exiting normally\n");
 	return 0;
@@ -334,91 +425,28 @@ int orangefs_bufmap_initialize(struct ORANGEFS_dev_map_desc *user_desc)
  */
 void orangefs_bufmap_finalize(void)
 {
+	struct orangefs_bufmap *bufmap = __orangefs_bufmap;
+	if (!bufmap)
+		return;
 	gossip_debug(GOSSIP_BUFMAP_DEBUG, "orangefs_bufmap_finalize: called\n");
-	BUG_ON(!__orangefs_bufmap);
-	orangefs_bufmap_unref(__orangefs_bufmap);
+	mark_killed(&rw_map);
+	mark_killed(&readdir_map);
 	gossip_debug(GOSSIP_BUFMAP_DEBUG,
 		     "orangefs_bufmap_finalize: exiting normally\n");
 }
 
-struct slot_args {
-	int slot_count;
-	int *slot_array;
-	spinlock_t *slot_lock;
-	wait_queue_head_t *slot_wq;
-};
-
-static int wait_for_a_slot(struct slot_args *slargs, int *buffer_index)
+void orangefs_bufmap_run_down(void)
 {
-	int ret = -1;
-	int i = 0;
-	DEFINE_WAIT(wait_entry);
-
-	while (1) {
-		/*
-		 * check for available desc, slot_lock is the appropriate
-		 * index_lock
-		 */
-		spin_lock(slargs->slot_lock);
-		prepare_to_wait_exclusive(slargs->slot_wq,
-					  &wait_entry,
-					  TASK_INTERRUPTIBLE);
-		for (i = 0; i < slargs->slot_count; i++)
-			if (slargs->slot_array[i] == 0) {
-				slargs->slot_array[i] = 1;
-				*buffer_index = i;
-				ret = 0;
-				break;
-			}
-		spin_unlock(slargs->slot_lock);
-
-		/* if we acquired a buffer, then break out of while */
-		if (ret == 0)
-			break;
-
-		if (!signal_pending(current)) {
-			gossip_debug(GOSSIP_BUFMAP_DEBUG,
-				     "[BUFMAP]: waiting %d "
-				     "seconds for a slot\n",
-				     slot_timeout_secs);
-			if (!schedule_timeout(slot_timeout_secs * HZ)) {
-				gossip_debug(GOSSIP_BUFMAP_DEBUG,
-					     "*** wait_for_a_slot timed out\n");
-				ret = -ETIMEDOUT;
-				break;
-			}
-			gossip_debug(GOSSIP_BUFMAP_DEBUG,
-			  "[BUFMAP]: woken up by a slot becoming available.\n");
-			continue;
-		}
-
-		gossip_debug(GOSSIP_BUFMAP_DEBUG, "orangefs: %s interrupted.\n",
-			     __func__);
-		ret = -EINTR;
-		break;
-	}
-
-	spin_lock(slargs->slot_lock);
-	finish_wait(slargs->slot_wq, &wait_entry);
-	spin_unlock(slargs->slot_lock);
-	return ret;
-}
-
-static void put_back_slot(struct slot_args *slargs, int buffer_index)
-{
-	/* slot_lock is the appropriate index_lock */
-	spin_lock(slargs->slot_lock);
-	if (buffer_index < 0 || buffer_index >= slargs->slot_count) {
-		spin_unlock(slargs->slot_lock);
+	struct orangefs_bufmap *bufmap = __orangefs_bufmap;
+	if (!bufmap)
 		return;
-	}
-
-	/* put the desc back on the queue */
-	slargs->slot_array[buffer_index] = 0;
-	spin_unlock(slargs->slot_lock);
-
-	/* wake up anyone who may be sleeping on the queue */
-	wake_up_interruptible(slargs->slot_wq);
+	run_down(&rw_map);
+	run_down(&readdir_map);
+	spin_lock(&orangefs_bufmap_lock);
+	__orangefs_bufmap = NULL;
+	spin_unlock(&orangefs_bufmap_lock);
+	orangefs_bufmap_unmap(bufmap);
+	orangefs_bufmap_free(bufmap);
 }
 
 /*
@@ -431,23 +459,12 @@ static void put_back_slot(struct slot_args *slargs, int buffer_index)
  */
 int orangefs_bufmap_get(struct orangefs_bufmap **mapp, int *buffer_index)
 {
-	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
-	struct slot_args slargs;
-	int ret;
-
-	if (!bufmap) {
-		gossip_err("orangefs: please confirm that pvfs2-client daemon is running.\n");
-		return -EIO;
+	int ret = get(&rw_map);
+	if (ret >= 0) {
+		*mapp = __orangefs_bufmap;
+		*buffer_index = ret;
+		ret = 0;
 	}
-
-	slargs.slot_count = bufmap->desc_count;
-	slargs.slot_array = bufmap->buffer_index_array;
-	slargs.slot_lock = &bufmap->buffer_index_lock;
-	slargs.slot_wq = &bufmap_waitq;
-	ret = wait_for_a_slot(&slargs, buffer_index);
-	if (ret)
-		orangefs_bufmap_unref(bufmap);
-	*mapp = bufmap;
 	return ret;
 }
 
@@ -460,15 +477,7 @@ int orangefs_bufmap_get(struct orangefs_bufmap **mapp, int *buffer_index)
  */
 void orangefs_bufmap_put(int buffer_index)
 {
-	struct slot_args slargs;
-	struct orangefs_bufmap *bufmap = __orangefs_bufmap;
-
-	slargs.slot_count = bufmap->desc_count;
-	slargs.slot_array = bufmap->buffer_index_array;
-	slargs.slot_lock = &bufmap->buffer_index_lock;
-	slargs.slot_wq = &bufmap_waitq;
-	put_back_slot(&slargs, buffer_index);
-	orangefs_bufmap_unref(bufmap);
+	put(&rw_map, buffer_index);
 }
 
 /*
@@ -484,36 +493,18 @@ void orangefs_bufmap_put(int buffer_index)
  */
 int orangefs_readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
 {
-	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
-	struct slot_args slargs;
-	int ret;
-
-	if (!bufmap) {
-		gossip_err("orangefs: please confirm that pvfs2-client daemon is running.\n");
-		return -EIO;
+	int ret = get(&readdir_map);
+	if (ret >= 0) {
+		*mapp = __orangefs_bufmap;
+		*buffer_index = ret;
+		ret = 0;
 	}
-
-	slargs.slot_count = ORANGEFS_READDIR_DEFAULT_DESC_COUNT;
-	slargs.slot_array = bufmap->readdir_index_array;
-	slargs.slot_lock = &bufmap->readdir_index_lock;
-	slargs.slot_wq = &readdir_waitq;
-	ret = wait_for_a_slot(&slargs, buffer_index);
-	if (ret)
-		orangefs_bufmap_unref(bufmap);
-	*mapp = bufmap;
 	return ret;
 }
 
 void orangefs_readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
 {
-	struct slot_args slargs;
-
-	slargs.slot_count = ORANGEFS_READDIR_DEFAULT_DESC_COUNT;
-	slargs.slot_array = bufmap->readdir_index_array;
-	slargs.slot_lock = &bufmap->readdir_index_lock;
-	slargs.slot_wq = &readdir_waitq;
-	put_back_slot(&slargs, buffer_index);
-	orangefs_bufmap_unref(bufmap);
+	put(&readdir_map, buffer_index);
 }
 
 /*

commit 178041848a6e7072cc6ebc1c6c7763e33f564722
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 11:16:37 2016 -0500

    orangefs_bufmap_..._query(): don't bother with refcounts
    
    ... just hold the spinlock while fetching the field in question.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 1819dee58433..cd484665bf72 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -91,11 +91,11 @@ int orangefs_bufmap_size_query(void)
 {
 	struct orangefs_bufmap *bufmap;
 	int size = 0;
-	bufmap = orangefs_bufmap_ref();
-	if (bufmap) {
+	spin_lock(&orangefs_bufmap_lock);
+	bufmap = __orangefs_bufmap;
+	if (bufmap)
 		size = bufmap->desc_size;
-		orangefs_bufmap_unref(bufmap);
-	}
+	spin_unlock(&orangefs_bufmap_lock);
 	return size;
 }
 
@@ -103,11 +103,11 @@ int orangefs_bufmap_shift_query(void)
 {
 	struct orangefs_bufmap *bufmap;
 	int shift = 0;
-	bufmap = orangefs_bufmap_ref();
-	if (bufmap) {
+	spin_lock(&orangefs_bufmap_lock);
+	bufmap = __orangefs_bufmap;
+	if (bufmap)
 		shift = bufmap->desc_shift;
-		orangefs_bufmap_unref(bufmap);
-	}
+	spin_unlock(&orangefs_bufmap_lock);
 	return shift;
 }
 

commit 1357d06d49d1f87af48ab768d34af55bff18b0c3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Feb 11 21:34:52 2016 -0500

    get rid of bufmap argument of orangefs_bufmap_put()
    
    it's always equal to __orangefs_bufmap and the latter can't change
    until we are done
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index c60019de1fd8..1819dee58433 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -458,9 +458,10 @@ int orangefs_bufmap_get(struct orangefs_bufmap **mapp, int *buffer_index)
  *
  * no return value
  */
-void orangefs_bufmap_put(struct orangefs_bufmap *bufmap, int buffer_index)
+void orangefs_bufmap_put(int buffer_index)
 {
 	struct slot_args slargs;
+	struct orangefs_bufmap *bufmap = __orangefs_bufmap;
 
 	slargs.slot_count = bufmap->desc_count;
 	slargs.slot_array = bufmap->buffer_index_array;

commit 727cbfea623b78d46ce8e0f8c931b5189f3fe2e0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 23 13:17:55 2016 -0500

    orangefs: get rid of MSECS_TO_JIFFIES
    
    All timeouts are in _seconds_, so all calls are of form
    MSECS_TO_JIFFIES(n * 1000), which is a convoluted way to
    spell n * HZ.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 15baecb8094d..c60019de1fd8 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -377,13 +377,11 @@ static int wait_for_a_slot(struct slot_args *slargs, int *buffer_index)
 			break;
 
 		if (!signal_pending(current)) {
-			int timeout =
-			    MSECS_TO_JIFFIES(1000 * slot_timeout_secs);
 			gossip_debug(GOSSIP_BUFMAP_DEBUG,
 				     "[BUFMAP]: waiting %d "
 				     "seconds for a slot\n",
 				     slot_timeout_secs);
-			if (!schedule_timeout(timeout)) {
+			if (!schedule_timeout(slot_timeout_secs * HZ)) {
 				gossip_debug(GOSSIP_BUFMAP_DEBUG,
 					     "*** wait_for_a_slot timed out\n");
 				ret = -ETIMEDOUT;

commit 7d2214858f137ff5fe20d0fdc2823c12b4b54f46
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Mon Jan 4 15:05:28 2016 -0500

    orangefs: Fix some more global namespace pollution.
    
    This only changes the names of things, so there is no functional change.
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 888aa28136ee..15baecb8094d 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -115,14 +115,14 @@ static DECLARE_WAIT_QUEUE_HEAD(bufmap_waitq);
 static DECLARE_WAIT_QUEUE_HEAD(readdir_waitq);
 
 /*
- * get_bufmap_init
+ * orangefs_get_bufmap_init
  *
  * If bufmap_init is 1, then the shared memory system, including the
  * buffer_index_array, is available.  Otherwise, it is not.
  *
  * returns the value of bufmap_init
  */
-int get_bufmap_init(void)
+int orangefs_get_bufmap_init(void)
 {
 	return __orangefs_bufmap ? 1 : 0;
 }
@@ -473,7 +473,7 @@ void orangefs_bufmap_put(struct orangefs_bufmap *bufmap, int buffer_index)
 }
 
 /*
- * readdir_index_get()
+ * orangefs_readdir_index_get()
  *
  * gets a free descriptor, will sleep until one becomes
  * available if necessary.
@@ -483,7 +483,7 @@ void orangefs_bufmap_put(struct orangefs_bufmap *bufmap, int buffer_index)
  *
  * returns 0 on success, -errno on failure
  */
-int readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
+int orangefs_readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
 {
 	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
 	struct slot_args slargs;
@@ -505,7 +505,7 @@ int readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
 	return ret;
 }
 
-void readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
+void orangefs_readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
 {
 	struct slot_args slargs;
 

commit b09d10df5a39b17ec12ecc0dc230a4d71c8a9996
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Tue Dec 15 14:54:27 2015 -0500

    orangefs: Do not unref if there is no bufmap.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index cf3ffb57334b..888aa28136ee 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -82,21 +82,32 @@ static void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
 	}
 }
 
+/*
+ * XXX: Can the size and shift change while the caller gives up the 
+ * XXX: lock between calling this and doing something useful?
+ */
+
 int orangefs_bufmap_size_query(void)
 {
-	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
-	int size = bufmap ? bufmap->desc_size : 0;
-
-	orangefs_bufmap_unref(bufmap);
+	struct orangefs_bufmap *bufmap;
+	int size = 0;
+	bufmap = orangefs_bufmap_ref();
+	if (bufmap) {
+		size = bufmap->desc_size;
+		orangefs_bufmap_unref(bufmap);
+	}
 	return size;
 }
 
 int orangefs_bufmap_shift_query(void)
 {
-	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
-	int shift = bufmap ? bufmap->desc_shift : 0;
-
-	orangefs_bufmap_unref(bufmap);
+	struct orangefs_bufmap *bufmap;
+	int shift = 0;
+	bufmap = orangefs_bufmap_ref();
+	if (bufmap) {
+		shift = bufmap->desc_shift;
+		orangefs_bufmap_unref(bufmap);
+	}
 	return shift;
 }
 

commit 765a75b34a9d72aca875d85d4dc40945afd2939e
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Tue Dec 15 14:48:17 2015 -0500

    orangefs: Remove useless inline qualifier from bufmap functions.
    
    All callers were outside of the file these functions were declared in,
    so nothing was ever inlined anyway.
    
    Further this happens before I/O and any speedup by not having to do a
    call will be dwarfed by the time it takes to talk to the server.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index bf8470060c74..cf3ffb57334b 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -82,7 +82,7 @@ static void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
 	}
 }
 
-inline int orangefs_bufmap_size_query(void)
+int orangefs_bufmap_size_query(void)
 {
 	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
 	int size = bufmap ? bufmap->desc_size : 0;
@@ -91,7 +91,7 @@ inline int orangefs_bufmap_size_query(void)
 	return size;
 }
 
-inline int orangefs_bufmap_shift_query(void)
+int orangefs_bufmap_shift_query(void)
 {
 	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
 	int shift = bufmap ? bufmap->desc_shift : 0;

commit bf89f584329c79909ea01c99aeac59ec20b3f524
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Tue Dec 15 14:45:12 2015 -0500

    orangefs: Change visibility of several bufmap helpers to static.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index 863c6fc8e192..bf8470060c74 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -9,6 +9,14 @@
 
 DECLARE_WAIT_QUEUE_HEAD(orangefs_bufmap_init_waitq);
 
+/* used to describe mapped buffers */
+struct orangefs_bufmap_desc {
+	void *uaddr;			/* user space address pointer */
+	struct page **page_array;	/* array of mapped pages */
+	int array_count;		/* size of above arrays */
+	struct list_head list_link;
+};
+
 static struct orangefs_bufmap {
 	atomic_t refcnt;
 
@@ -50,7 +58,7 @@ orangefs_bufmap_free(struct orangefs_bufmap *bufmap)
 	kfree(bufmap);
 }
 
-struct orangefs_bufmap *orangefs_bufmap_ref(void)
+static struct orangefs_bufmap *orangefs_bufmap_ref(void)
 {
 	struct orangefs_bufmap *bufmap = NULL;
 
@@ -63,7 +71,7 @@ struct orangefs_bufmap *orangefs_bufmap_ref(void)
 	return bufmap;
 }
 
-void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
+static void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
 {
 	if (atomic_dec_and_lock(&bufmap->refcnt, &orangefs_bufmap_lock)) {
 		__orangefs_bufmap = NULL;

commit ce6c414e17be602a84b1b34915468f8301ed14a0
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Mon Dec 14 14:54:46 2015 -0500

    Orangefs: Don't wait the old-fashioned way.
    
    Get rid of add_wait_queue, set_current_state, etc, and use the
    wait_event() model.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index f7cd18a2a73b..863c6fc8e192 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -333,19 +333,17 @@ static int wait_for_a_slot(struct slot_args *slargs, int *buffer_index)
 {
 	int ret = -1;
 	int i = 0;
-	DECLARE_WAITQUEUE(my_wait, current);
-
-
-	add_wait_queue_exclusive(slargs->slot_wq, &my_wait);
+	DEFINE_WAIT(wait_entry);
 
 	while (1) {
-		set_current_state(TASK_INTERRUPTIBLE);
-
 		/*
 		 * check for available desc, slot_lock is the appropriate
 		 * index_lock
 		 */
 		spin_lock(slargs->slot_lock);
+		prepare_to_wait_exclusive(slargs->slot_wq,
+					  &wait_entry,
+					  TASK_INTERRUPTIBLE);
 		for (i = 0; i < slargs->slot_count; i++)
 			if (slargs->slot_array[i] == 0) {
 				slargs->slot_array[i] = 1;
@@ -383,8 +381,9 @@ static int wait_for_a_slot(struct slot_args *slargs, int *buffer_index)
 		break;
 	}
 
-	set_current_state(TASK_RUNNING);
-	remove_wait_queue(slargs->slot_wq, &my_wait);
+	spin_lock(slargs->slot_lock);
+	finish_wait(slargs->slot_wq, &wait_entry);
+	spin_unlock(slargs->slot_lock);
 	return ret;
 }
 

commit b5e376ea8b20d5d0b48871d2c05916d69da4e604
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Dec 11 10:50:42 2015 -0500

    Orangefs: improve comments
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
index c5368d852ee2..f7cd18a2a73b 100644
--- a/fs/orangefs/orangefs-bufmap.c
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -499,6 +499,10 @@ void readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
 	orangefs_bufmap_unref(bufmap);
 }
 
+/*
+ * we've been handed an iovec, we need to copy it to 
+ * the shared memory descriptor at "buffer_index".
+ */
 int orangefs_bufmap_copy_from_iovec(struct orangefs_bufmap *bufmap,
 				struct iov_iter *iter,
 				int buffer_index,
@@ -527,9 +531,8 @@ int orangefs_bufmap_copy_from_iovec(struct orangefs_bufmap *bufmap,
 }
 
 /*
- * Iterate through the array of pages containing the bytes from
- * a file being read.
- *
+ * we've been handed an iovec, we need to fill it from
+ * the shared memory descriptor at "buffer_index".
  */
 int orangefs_bufmap_copy_to_iovec(struct orangefs_bufmap *bufmap,
 				    struct iov_iter *iter,

commit 575e946125f70c41c2042f10172842c5cab9a09a
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Dec 4 12:56:14 2015 -0500

    Orangefs: change pvfs2 filenames to orangefs
    
    Also changed references within source files that referred to
    header files whose names had changed.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/orangefs-bufmap.c b/fs/orangefs/orangefs-bufmap.c
new file mode 100644
index 000000000000..c5368d852ee2
--- /dev/null
+++ b/fs/orangefs/orangefs-bufmap.c
@@ -0,0 +1,558 @@
+/*
+ * (C) 2001 Clemson University and The University of Chicago
+ *
+ * See COPYING in top-level directory.
+ */
+#include "protocol.h"
+#include "orangefs-kernel.h"
+#include "orangefs-bufmap.h"
+
+DECLARE_WAIT_QUEUE_HEAD(orangefs_bufmap_init_waitq);
+
+static struct orangefs_bufmap {
+	atomic_t refcnt;
+
+	int desc_size;
+	int desc_shift;
+	int desc_count;
+	int total_size;
+	int page_count;
+
+	struct page **page_array;
+	struct orangefs_bufmap_desc *desc_array;
+
+	/* array to track usage of buffer descriptors */
+	int *buffer_index_array;
+	spinlock_t buffer_index_lock;
+
+	/* array to track usage of buffer descriptors for readdir */
+	int readdir_index_array[ORANGEFS_READDIR_DEFAULT_DESC_COUNT];
+	spinlock_t readdir_index_lock;
+} *__orangefs_bufmap;
+
+static DEFINE_SPINLOCK(orangefs_bufmap_lock);
+
+static void
+orangefs_bufmap_unmap(struct orangefs_bufmap *bufmap)
+{
+	int i;
+
+	for (i = 0; i < bufmap->page_count; i++)
+		page_cache_release(bufmap->page_array[i]);
+}
+
+static void
+orangefs_bufmap_free(struct orangefs_bufmap *bufmap)
+{
+	kfree(bufmap->page_array);
+	kfree(bufmap->desc_array);
+	kfree(bufmap->buffer_index_array);
+	kfree(bufmap);
+}
+
+struct orangefs_bufmap *orangefs_bufmap_ref(void)
+{
+	struct orangefs_bufmap *bufmap = NULL;
+
+	spin_lock(&orangefs_bufmap_lock);
+	if (__orangefs_bufmap) {
+		bufmap = __orangefs_bufmap;
+		atomic_inc(&bufmap->refcnt);
+	}
+	spin_unlock(&orangefs_bufmap_lock);
+	return bufmap;
+}
+
+void orangefs_bufmap_unref(struct orangefs_bufmap *bufmap)
+{
+	if (atomic_dec_and_lock(&bufmap->refcnt, &orangefs_bufmap_lock)) {
+		__orangefs_bufmap = NULL;
+		spin_unlock(&orangefs_bufmap_lock);
+
+		orangefs_bufmap_unmap(bufmap);
+		orangefs_bufmap_free(bufmap);
+	}
+}
+
+inline int orangefs_bufmap_size_query(void)
+{
+	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
+	int size = bufmap ? bufmap->desc_size : 0;
+
+	orangefs_bufmap_unref(bufmap);
+	return size;
+}
+
+inline int orangefs_bufmap_shift_query(void)
+{
+	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
+	int shift = bufmap ? bufmap->desc_shift : 0;
+
+	orangefs_bufmap_unref(bufmap);
+	return shift;
+}
+
+static DECLARE_WAIT_QUEUE_HEAD(bufmap_waitq);
+static DECLARE_WAIT_QUEUE_HEAD(readdir_waitq);
+
+/*
+ * get_bufmap_init
+ *
+ * If bufmap_init is 1, then the shared memory system, including the
+ * buffer_index_array, is available.  Otherwise, it is not.
+ *
+ * returns the value of bufmap_init
+ */
+int get_bufmap_init(void)
+{
+	return __orangefs_bufmap ? 1 : 0;
+}
+
+
+static struct orangefs_bufmap *
+orangefs_bufmap_alloc(struct ORANGEFS_dev_map_desc *user_desc)
+{
+	struct orangefs_bufmap *bufmap;
+
+	bufmap = kzalloc(sizeof(*bufmap), GFP_KERNEL);
+	if (!bufmap)
+		goto out;
+
+	atomic_set(&bufmap->refcnt, 1);
+	bufmap->total_size = user_desc->total_size;
+	bufmap->desc_count = user_desc->count;
+	bufmap->desc_size = user_desc->size;
+	bufmap->desc_shift = ilog2(bufmap->desc_size);
+
+	spin_lock_init(&bufmap->buffer_index_lock);
+	bufmap->buffer_index_array =
+		kcalloc(bufmap->desc_count, sizeof(int), GFP_KERNEL);
+	if (!bufmap->buffer_index_array) {
+		gossip_err("orangefs: could not allocate %d buffer indices\n",
+				bufmap->desc_count);
+		goto out_free_bufmap;
+	}
+	spin_lock_init(&bufmap->readdir_index_lock);
+
+	bufmap->desc_array =
+		kcalloc(bufmap->desc_count, sizeof(struct orangefs_bufmap_desc),
+			GFP_KERNEL);
+	if (!bufmap->desc_array) {
+		gossip_err("orangefs: could not allocate %d descriptors\n",
+				bufmap->desc_count);
+		goto out_free_index_array;
+	}
+
+	bufmap->page_count = bufmap->total_size / PAGE_SIZE;
+
+	/* allocate storage to track our page mappings */
+	bufmap->page_array =
+		kcalloc(bufmap->page_count, sizeof(struct page *), GFP_KERNEL);
+	if (!bufmap->page_array)
+		goto out_free_desc_array;
+
+	return bufmap;
+
+out_free_desc_array:
+	kfree(bufmap->desc_array);
+out_free_index_array:
+	kfree(bufmap->buffer_index_array);
+out_free_bufmap:
+	kfree(bufmap);
+out:
+	return NULL;
+}
+
+static int
+orangefs_bufmap_map(struct orangefs_bufmap *bufmap,
+		struct ORANGEFS_dev_map_desc *user_desc)
+{
+	int pages_per_desc = bufmap->desc_size / PAGE_SIZE;
+	int offset = 0, ret, i;
+
+	/* map the pages */
+	ret = get_user_pages_fast((unsigned long)user_desc->ptr,
+			     bufmap->page_count, 1, bufmap->page_array);
+
+	if (ret < 0)
+		return ret;
+
+	if (ret != bufmap->page_count) {
+		gossip_err("orangefs error: asked for %d pages, only got %d.\n",
+				bufmap->page_count, ret);
+
+		for (i = 0; i < ret; i++) {
+			SetPageError(bufmap->page_array[i]);
+			page_cache_release(bufmap->page_array[i]);
+		}
+		return -ENOMEM;
+	}
+
+	/*
+	 * ideally we want to get kernel space pointers for each page, but
+	 * we can't kmap that many pages at once if highmem is being used.
+	 * so instead, we just kmap/kunmap the page address each time the
+	 * kaddr is needed.
+	 */
+	for (i = 0; i < bufmap->page_count; i++)
+		flush_dcache_page(bufmap->page_array[i]);
+
+	/* build a list of available descriptors */
+	for (offset = 0, i = 0; i < bufmap->desc_count; i++) {
+		bufmap->desc_array[i].page_array = &bufmap->page_array[offset];
+		bufmap->desc_array[i].array_count = pages_per_desc;
+		bufmap->desc_array[i].uaddr =
+		    (user_desc->ptr + (i * pages_per_desc * PAGE_SIZE));
+		offset += pages_per_desc;
+	}
+
+	return 0;
+}
+
+/*
+ * orangefs_bufmap_initialize()
+ *
+ * initializes the mapped buffer interface
+ *
+ * returns 0 on success, -errno on failure
+ */
+int orangefs_bufmap_initialize(struct ORANGEFS_dev_map_desc *user_desc)
+{
+	struct orangefs_bufmap *bufmap;
+	int ret = -EINVAL;
+
+	gossip_debug(GOSSIP_BUFMAP_DEBUG,
+		     "orangefs_bufmap_initialize: called (ptr ("
+		     "%p) sz (%d) cnt(%d).\n",
+		     user_desc->ptr,
+		     user_desc->size,
+		     user_desc->count);
+
+	/*
+	 * sanity check alignment and size of buffer that caller wants to
+	 * work with
+	 */
+	if (PAGE_ALIGN((unsigned long)user_desc->ptr) !=
+	    (unsigned long)user_desc->ptr) {
+		gossip_err("orangefs error: memory alignment (front). %p\n",
+			   user_desc->ptr);
+		goto out;
+	}
+
+	if (PAGE_ALIGN(((unsigned long)user_desc->ptr + user_desc->total_size))
+	    != (unsigned long)(user_desc->ptr + user_desc->total_size)) {
+		gossip_err("orangefs error: memory alignment (back).(%p + %d)\n",
+			   user_desc->ptr,
+			   user_desc->total_size);
+		goto out;
+	}
+
+	if (user_desc->total_size != (user_desc->size * user_desc->count)) {
+		gossip_err("orangefs error: user provided an oddly sized buffer: (%d, %d, %d)\n",
+			   user_desc->total_size,
+			   user_desc->size,
+			   user_desc->count);
+		goto out;
+	}
+
+	if ((user_desc->size % PAGE_SIZE) != 0) {
+		gossip_err("orangefs error: bufmap size not page size divisible (%d).\n",
+			   user_desc->size);
+		goto out;
+	}
+
+	ret = -ENOMEM;
+	bufmap = orangefs_bufmap_alloc(user_desc);
+	if (!bufmap)
+		goto out;
+
+	ret = orangefs_bufmap_map(bufmap, user_desc);
+	if (ret)
+		goto out_free_bufmap;
+
+
+	spin_lock(&orangefs_bufmap_lock);
+	if (__orangefs_bufmap) {
+		spin_unlock(&orangefs_bufmap_lock);
+		gossip_err("orangefs: error: bufmap already initialized.\n");
+		ret = -EALREADY;
+		goto out_unmap_bufmap;
+	}
+	__orangefs_bufmap = bufmap;
+	spin_unlock(&orangefs_bufmap_lock);
+
+	/*
+	 * If there are operations in orangefs_bufmap_init_waitq, wake them up.
+	 * This scenario occurs when the client-core is restarted and I/O
+	 * requests in the in-progress or waiting tables are restarted.  I/O
+	 * requests cannot be restarted until the shared memory system is
+	 * completely re-initialized, so we put the I/O requests in this
+	 * waitq until initialization has completed.  NOTE:  the I/O requests
+	 * are also on a timer, so they don't wait forever just in case the
+	 * client-core doesn't come back up.
+	 */
+	wake_up_interruptible(&orangefs_bufmap_init_waitq);
+
+	gossip_debug(GOSSIP_BUFMAP_DEBUG,
+		     "orangefs_bufmap_initialize: exiting normally\n");
+	return 0;
+
+out_unmap_bufmap:
+	orangefs_bufmap_unmap(bufmap);
+out_free_bufmap:
+	orangefs_bufmap_free(bufmap);
+out:
+	return ret;
+}
+
+/*
+ * orangefs_bufmap_finalize()
+ *
+ * shuts down the mapped buffer interface and releases any resources
+ * associated with it
+ *
+ * no return value
+ */
+void orangefs_bufmap_finalize(void)
+{
+	gossip_debug(GOSSIP_BUFMAP_DEBUG, "orangefs_bufmap_finalize: called\n");
+	BUG_ON(!__orangefs_bufmap);
+	orangefs_bufmap_unref(__orangefs_bufmap);
+	gossip_debug(GOSSIP_BUFMAP_DEBUG,
+		     "orangefs_bufmap_finalize: exiting normally\n");
+}
+
+struct slot_args {
+	int slot_count;
+	int *slot_array;
+	spinlock_t *slot_lock;
+	wait_queue_head_t *slot_wq;
+};
+
+static int wait_for_a_slot(struct slot_args *slargs, int *buffer_index)
+{
+	int ret = -1;
+	int i = 0;
+	DECLARE_WAITQUEUE(my_wait, current);
+
+
+	add_wait_queue_exclusive(slargs->slot_wq, &my_wait);
+
+	while (1) {
+		set_current_state(TASK_INTERRUPTIBLE);
+
+		/*
+		 * check for available desc, slot_lock is the appropriate
+		 * index_lock
+		 */
+		spin_lock(slargs->slot_lock);
+		for (i = 0; i < slargs->slot_count; i++)
+			if (slargs->slot_array[i] == 0) {
+				slargs->slot_array[i] = 1;
+				*buffer_index = i;
+				ret = 0;
+				break;
+			}
+		spin_unlock(slargs->slot_lock);
+
+		/* if we acquired a buffer, then break out of while */
+		if (ret == 0)
+			break;
+
+		if (!signal_pending(current)) {
+			int timeout =
+			    MSECS_TO_JIFFIES(1000 * slot_timeout_secs);
+			gossip_debug(GOSSIP_BUFMAP_DEBUG,
+				     "[BUFMAP]: waiting %d "
+				     "seconds for a slot\n",
+				     slot_timeout_secs);
+			if (!schedule_timeout(timeout)) {
+				gossip_debug(GOSSIP_BUFMAP_DEBUG,
+					     "*** wait_for_a_slot timed out\n");
+				ret = -ETIMEDOUT;
+				break;
+			}
+			gossip_debug(GOSSIP_BUFMAP_DEBUG,
+			  "[BUFMAP]: woken up by a slot becoming available.\n");
+			continue;
+		}
+
+		gossip_debug(GOSSIP_BUFMAP_DEBUG, "orangefs: %s interrupted.\n",
+			     __func__);
+		ret = -EINTR;
+		break;
+	}
+
+	set_current_state(TASK_RUNNING);
+	remove_wait_queue(slargs->slot_wq, &my_wait);
+	return ret;
+}
+
+static void put_back_slot(struct slot_args *slargs, int buffer_index)
+{
+	/* slot_lock is the appropriate index_lock */
+	spin_lock(slargs->slot_lock);
+	if (buffer_index < 0 || buffer_index >= slargs->slot_count) {
+		spin_unlock(slargs->slot_lock);
+		return;
+	}
+
+	/* put the desc back on the queue */
+	slargs->slot_array[buffer_index] = 0;
+	spin_unlock(slargs->slot_lock);
+
+	/* wake up anyone who may be sleeping on the queue */
+	wake_up_interruptible(slargs->slot_wq);
+}
+
+/*
+ * orangefs_bufmap_get()
+ *
+ * gets a free mapped buffer descriptor, will sleep until one becomes
+ * available if necessary
+ *
+ * returns 0 on success, -errno on failure
+ */
+int orangefs_bufmap_get(struct orangefs_bufmap **mapp, int *buffer_index)
+{
+	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
+	struct slot_args slargs;
+	int ret;
+
+	if (!bufmap) {
+		gossip_err("orangefs: please confirm that pvfs2-client daemon is running.\n");
+		return -EIO;
+	}
+
+	slargs.slot_count = bufmap->desc_count;
+	slargs.slot_array = bufmap->buffer_index_array;
+	slargs.slot_lock = &bufmap->buffer_index_lock;
+	slargs.slot_wq = &bufmap_waitq;
+	ret = wait_for_a_slot(&slargs, buffer_index);
+	if (ret)
+		orangefs_bufmap_unref(bufmap);
+	*mapp = bufmap;
+	return ret;
+}
+
+/*
+ * orangefs_bufmap_put()
+ *
+ * returns a mapped buffer descriptor to the collection
+ *
+ * no return value
+ */
+void orangefs_bufmap_put(struct orangefs_bufmap *bufmap, int buffer_index)
+{
+	struct slot_args slargs;
+
+	slargs.slot_count = bufmap->desc_count;
+	slargs.slot_array = bufmap->buffer_index_array;
+	slargs.slot_lock = &bufmap->buffer_index_lock;
+	slargs.slot_wq = &bufmap_waitq;
+	put_back_slot(&slargs, buffer_index);
+	orangefs_bufmap_unref(bufmap);
+}
+
+/*
+ * readdir_index_get()
+ *
+ * gets a free descriptor, will sleep until one becomes
+ * available if necessary.
+ * Although the readdir buffers are not mapped into kernel space
+ * we could do that at a later point of time. Regardless, these
+ * indices are used by the client-core.
+ *
+ * returns 0 on success, -errno on failure
+ */
+int readdir_index_get(struct orangefs_bufmap **mapp, int *buffer_index)
+{
+	struct orangefs_bufmap *bufmap = orangefs_bufmap_ref();
+	struct slot_args slargs;
+	int ret;
+
+	if (!bufmap) {
+		gossip_err("orangefs: please confirm that pvfs2-client daemon is running.\n");
+		return -EIO;
+	}
+
+	slargs.slot_count = ORANGEFS_READDIR_DEFAULT_DESC_COUNT;
+	slargs.slot_array = bufmap->readdir_index_array;
+	slargs.slot_lock = &bufmap->readdir_index_lock;
+	slargs.slot_wq = &readdir_waitq;
+	ret = wait_for_a_slot(&slargs, buffer_index);
+	if (ret)
+		orangefs_bufmap_unref(bufmap);
+	*mapp = bufmap;
+	return ret;
+}
+
+void readdir_index_put(struct orangefs_bufmap *bufmap, int buffer_index)
+{
+	struct slot_args slargs;
+
+	slargs.slot_count = ORANGEFS_READDIR_DEFAULT_DESC_COUNT;
+	slargs.slot_array = bufmap->readdir_index_array;
+	slargs.slot_lock = &bufmap->readdir_index_lock;
+	slargs.slot_wq = &readdir_waitq;
+	put_back_slot(&slargs, buffer_index);
+	orangefs_bufmap_unref(bufmap);
+}
+
+int orangefs_bufmap_copy_from_iovec(struct orangefs_bufmap *bufmap,
+				struct iov_iter *iter,
+				int buffer_index,
+				size_t size)
+{
+	struct orangefs_bufmap_desc *to = &bufmap->desc_array[buffer_index];
+	int i;
+
+	gossip_debug(GOSSIP_BUFMAP_DEBUG,
+		     "%s: buffer_index:%d: size:%zu:\n",
+		     __func__, buffer_index, size);
+
+
+	for (i = 0; size; i++) {
+		struct page *page = to->page_array[i];
+		size_t n = size;
+		if (n > PAGE_SIZE)
+			n = PAGE_SIZE;
+		n = copy_page_from_iter(page, 0, n, iter);
+		if (!n)
+			return -EFAULT;
+		size -= n;
+	}
+	return 0;
+
+}
+
+/*
+ * Iterate through the array of pages containing the bytes from
+ * a file being read.
+ *
+ */
+int orangefs_bufmap_copy_to_iovec(struct orangefs_bufmap *bufmap,
+				    struct iov_iter *iter,
+				    int buffer_index,
+				    size_t size)
+{
+	struct orangefs_bufmap_desc *from = &bufmap->desc_array[buffer_index];
+	int i;
+
+	gossip_debug(GOSSIP_BUFMAP_DEBUG,
+		     "%s: buffer_index:%d: size:%zu:\n",
+		     __func__, buffer_index, size);
+
+
+	for (i = 0; size; i++) {
+		struct page *page = from->page_array[i];
+		size_t n = size;
+		if (n > PAGE_SIZE)
+			n = PAGE_SIZE;
+		n = copy_page_to_iter(page, 0, n, iter);
+		if (!n)
+			return -EFAULT;
+		size -= n;
+	}
+	return 0;
+}
