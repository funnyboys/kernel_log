commit 0dcac0f7812b2c09ed018a5eba91448a37f1b71b
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Thu Feb 15 19:38:01 2018 +0000

    orangefs: service ops done for writeback are not killable
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 0729d2645d6a..beafc33d57be 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -19,7 +19,7 @@
 
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 		long timeout,
-		bool interruptible)
+		int flags)
 			__acquires(op->lock);
 static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 	__releases(op->lock);
@@ -143,9 +143,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	if (!(flags & ORANGEFS_OP_NO_MUTEX))
 		mutex_unlock(&orangefs_request_mutex);
 
-	ret = wait_for_matching_downcall(op, timeout,
-					 flags & ORANGEFS_OP_INTERRUPTIBLE);
-
+	ret = wait_for_matching_downcall(op, timeout, flags);
 	gossip_debug(GOSSIP_WAIT_DEBUG,
 		     "%s: wait_for_matching_downcall returned %d for %p\n",
 		     __func__,
@@ -319,10 +317,12 @@ static void
  */
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 		long timeout,
-		bool interruptible)
+		int flags)
 			__acquires(op->lock)
 {
 	long n;
+	int writeback = flags & ORANGEFS_OP_WRITEBACK,
+	    interruptible = flags & ORANGEFS_OP_INTERRUPTIBLE;
 
 	/*
 	 * There's a "schedule_timeout" inside of these wait
@@ -330,10 +330,12 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 	 * user process that needs something done and is being
 	 * manipulated by the client-core process.
 	 */
-	if (interruptible)
+	if (writeback)
+		n = wait_for_completion_io_timeout(&op->waitq, timeout);
+	else if (!writeback && interruptible)
 		n = wait_for_completion_interruptible_timeout(&op->waitq,
-							      timeout);
-	else
+								      timeout);
+	else /* !writeback && !interruptible but compiler complains */
 		n = wait_for_completion_killable_timeout(&op->waitq, timeout);
 
 	spin_lock(&op->lock);

commit b1116bc03c00255b7e5feaed561e8bb2fc38c0f8
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Jun 1 14:17:23 2018 -0400

    orangefs: use sparse annotations for holding locks across function calls.
    
    Sparse complained and Al Viro knew what to do...
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 0577d6dba8c8..0729d2645d6a 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -17,8 +17,12 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
-static int wait_for_matching_downcall(struct orangefs_kernel_op_s *, long, bool);
-static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *);
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
+		long timeout,
+		bool interruptible)
+			__acquires(op->lock);
+static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
+	__releases(op->lock);
 
 /*
  * What we do in this function is to walk the list of operations that are
@@ -246,6 +250,7 @@ bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
  */
 static void
 	orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
+		__releases(op->lock)
 {
 	/*
 	 * handle interrupted cases depending on what state we were in when
@@ -313,8 +318,9 @@ static void
  * Returns with op->lock taken.
  */
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
-				      long timeout,
-				      bool interruptible)
+		long timeout,
+		bool interruptible)
+			__acquires(op->lock)
 {
 	long n;
 

commit 0afc0decf247f65b7aba666a76a0a68adf4bc435
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Mon Jan 22 15:44:51 2018 -0500

    orangefs: use list_for_each_entry_safe in purge_waiting_ops
    
    set_op_state_purged can delete the op.
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 835c6e148afc..0577d6dba8c8 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -29,10 +29,10 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
  */
 void purge_waiting_ops(void)
 {
-	struct orangefs_kernel_op_s *op;
+	struct orangefs_kernel_op_s *op, *tmp;
 
 	spin_lock(&orangefs_request_list_lock);
-	list_for_each_entry(op, &orangefs_request_list, list) {
+	list_for_each_entry_safe(op, tmp, &orangefs_request_list, list) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "pvfs2-client-core: purging op tag %llu %s\n",
 			     llu(op->tag),

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 61e2ca7fec55..835c6e148afc 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * (C) 2001 Clemson University and The University of Chicago
  * (C) 2011 Omnibond Systems

commit b5a9d61eebdd0016ccb383b25a5c3d04977a6549
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Tue Apr 25 15:38:07 2017 -0400

    orangefs: do not wait for timeout if umounting
    
    When the computer is turned off, all the processes are killed and then
    all the filesystems are umounted.  OrangeFS should not wait for the
    userspace daemon to come back in that case.
    
    This only works for plain umount(2).  To actually take advantage of this
    interactively, `umount -f' is needed; otherwise umount will issue a
    statfs first, which will wait for the userspace daemon to come back.
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index abcfa3fa9992..61e2ca7fec55 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -124,7 +124,14 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "%s:client core is NOT in service.\n",
 			     __func__);
-		timeout = op_timeout_secs * HZ;
+		/*
+		 * Don't wait for the userspace component to return if
+		 * the filesystem is being umounted anyway.
+		 */
+		if (op->upcall.type == ORANGEFS_VFS_OP_FS_UMOUNT)
+			timeout = 0;
+		else
+			timeout = op_timeout_secs * HZ;
 	}
 	spin_unlock(&orangefs_request_list_lock);
 

commit 1d503617884ed43af1c03685e73ce23f155d3fa4
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Tue Aug 16 11:38:14 2016 -0400

    orangefs: rename most remaining global variables
    
    Only op_timeout_secs, slot_timeout_secs, and hash_table_size are left
    because they are exposed as module parameters. All other global
    variables have the orangefs_ prefix.
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 31635bc303fe..abcfa3fa9992 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -87,9 +87,9 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	 */
 	if (!(flags & ORANGEFS_OP_NO_MUTEX)) {
 		if (flags & ORANGEFS_OP_INTERRUPTIBLE)
-			ret = mutex_lock_interruptible(&request_mutex);
+			ret = mutex_lock_interruptible(&orangefs_request_mutex);
 		else
-			ret = mutex_lock_killable(&request_mutex);
+			ret = mutex_lock_killable(&orangefs_request_mutex);
 		/*
 		 * check to see if we were interrupted while waiting for
 		 * mutex
@@ -129,7 +129,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	spin_unlock(&orangefs_request_list_lock);
 
 	if (!(flags & ORANGEFS_OP_NO_MUTEX))
-		mutex_unlock(&request_mutex);
+		mutex_unlock(&orangefs_request_mutex);
 
 	ret = wait_for_matching_downcall(op, timeout,
 					 flags & ORANGEFS_OP_INTERRUPTIBLE);
@@ -272,9 +272,9 @@ static void
 	} else if (op_state_in_progress(op)) {
 		/* op must be removed from the in progress htable */
 		spin_unlock(&op->lock);
-		spin_lock(&htable_ops_in_progress_lock);
+		spin_lock(&orangefs_htable_ops_in_progress_lock);
 		list_del_init(&op->list);
-		spin_unlock(&htable_ops_in_progress_lock);
+		spin_unlock(&orangefs_htable_ops_in_progress_lock);
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "Interrupted: Removed op %p"
 			     " from htable_ops_in_progress\n",

commit 9d9e7ba9ee8f304c4608f3c81aa5e7fb3bddd251
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Thu Mar 3 13:46:48 2016 -0500

    Orangefs: improve gossip statements
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index edfd921cf6ec..31635bc303fe 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -37,6 +37,12 @@ void purge_waiting_ops(void)
 			     llu(op->tag),
 			     get_opname_string(op));
 		set_op_state_purged(op);
+		gossip_debug(GOSSIP_DEV_DEBUG,
+			     "%s: op:%s: op_state:%d: process:%s:\n",
+			     __func__,
+			     get_opname_string(op),
+			     op->op_state,
+			     current->comm);
 	}
 	spin_unlock(&orangefs_request_list_lock);
 }
@@ -101,6 +107,12 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	spin_lock(&orangefs_request_list_lock);
 	spin_lock(&op->lock);
 	set_op_state_waiting(op);
+	gossip_debug(GOSSIP_DEV_DEBUG,
+		     "%s: op:%s: op_state:%d: process:%s:\n",
+		     __func__,
+		     get_opname_string(op),
+		     op->op_state,
+		     current->comm);
 	/* add high priority remount op to the front of the line. */
 	if (flags & ORANGEFS_OP_PRIORITY)
 		list_add(&op->list, &orangefs_request_list);
@@ -173,7 +185,8 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 out:
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "orangefs: service_operation %s returning: %d for %p.\n",
+		     "%s: %s returning: %d for %p.\n",
+		     __func__,
 		     op_name,
 		     ret,
 		     op);
@@ -204,6 +217,12 @@ bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
 	}
 	spin_lock(&op->lock);
 	set_op_state_waiting(op);
+	gossip_debug(GOSSIP_DEV_DEBUG,
+		     "%s: op:%s: op_state:%d: process:%s:\n",
+		     __func__,
+		     get_opname_string(op),
+		     op->op_state,
+		     current->comm);
 	list_add(&op->list, &orangefs_request_list);
 	spin_unlock(&op->lock);
 	spin_unlock(&orangefs_request_list_lock);
@@ -310,9 +329,7 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 
 	if (unlikely(n < 0)) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "*** %s:"
-			     " operation interrupted by a signal (tag "
-			     "%llu, op %p)\n",
+			     "%s: operation interrupted, tag %llu, %p\n",
 			     __func__,
 			     llu(op->tag),
 			     op);
@@ -320,9 +337,7 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 	}
 	if (op_state_purged(op)) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "*** %s:"
-			     " operation purged (tag "
-			     "%llu, %p, att %d)\n",
+			     "%s: operation purged, tag %llu, %p, %d\n",
 			     __func__,
 			     llu(op->tag),
 			     op,
@@ -333,9 +348,7 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 	}
 	/* must have timed out, then... */
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "*** %s:"
-		     " operation timed out (tag"
-		     " %llu, %p, att %d)\n",
+		     "%s: operation timed out, tag %llu, %p, %d)\n",
 		     __func__,
 		     llu(op->tag),
 		     op,

commit ca9f518eadeb7edd8e438a6542d3caec9bc3bb74
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Feb 26 10:21:12 2016 -0500

    Orangefs: code sanitation.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 1eadf69cc919..edfd921cf6ec 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -75,7 +75,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 	/*
 	 * If ORANGEFS_OP_NO_MUTEX was set in flags, we need to avoid
-	 * aquiring the request_mutex because we're servicing a
+	 * acquiring the request_mutex because we're servicing a
 	 * high priority remount operation and the request_mutex is
 	 * already taken.
 	 */
@@ -91,7 +91,8 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		if (ret < 0) {
 			op->downcall.status = ret;
 			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "orangefs: service_operation interrupted.\n");
+				     "%s: service_operation interrupted.\n",
+				     __func__);
 			return ret;
 		}
 	}
@@ -127,9 +128,9 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		     ret,
 		     op);
 
+	/* got matching downcall; make sure status is in errno format */
 	if (!ret) {
 		spin_unlock(&op->lock);
-		/* got matching downcall; make sure status is in errno format */
 		op->downcall.status =
 		    orangefs_normalize_to_errno(op->downcall.status);
 		ret = op->downcall.status;
@@ -144,8 +145,8 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	}
 
 	/*
-	 * remove waiting ops from the request list or
-	 * remove in-progress ops from the in-progress list.
+	 * remove a waiting op from the request list or
+	 * remove an in-progress op from the in-progress list.
 	 */
 	orangefs_clean_up_interrupted_operation(op);
 
@@ -179,6 +180,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	return ret;
 }
 
+/* This can get called on an I/O op if it had a bad service_operation. */
 bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
 {
 	u64 tag = op->tag;
@@ -206,23 +208,31 @@ bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
 	spin_unlock(&op->lock);
 	spin_unlock(&orangefs_request_list_lock);
 
-	gossip_debug(GOSSIP_UTILS_DEBUG,
+	gossip_debug(GOSSIP_WAIT_DEBUG,
 		     "Attempting ORANGEFS operation cancellation of tag %llu\n",
 		     llu(tag));
 	return true;
 }
 
-static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
+/*
+ * Change an op to the "given up" state and remove it from its list.
+ */
+static void
+	orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*
 	 * handle interrupted cases depending on what state we were in when
-	 * the interruption is detected.  there is a coarse grained lock
-	 * across the operation.
+	 * the interruption is detected.
 	 *
 	 * Called with op->lock held.
 	 */
+
+	/*
+	 * List manipulation code elsewhere will ignore ops that
+	 * have been given up upon.
+	 */
 	op->op_state |= OP_VFS_STATE_GIVEN_UP;
-	/* from that point on it can't be moved by anybody else */
+
 	if (list_empty(&op->list)) {
 		/* caught copying to/from daemon */
 		BUG_ON(op_state_serviced(op));
@@ -259,12 +269,12 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 }
 
 /*
- * sleeps on waitqueue waiting for matching downcall.
- * if client-core finishes servicing, then we are good to go.
+ * Sleeps on waitqueue waiting for matching downcall.
+ * If client-core finishes servicing, then we are good to go.
  * else if client-core exits, we get woken up here, and retry with a timeout
  *
- * Post when this call returns to the caller, the specified op will no
- * longer be on any list or htable.
+ * When this call returns to the caller, the specified op will no
+ * longer be in either the in_progress hash table or on the request list.
  *
  * Returns 0 on success and -errno on failure
  * Errors are:
@@ -281,6 +291,12 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 {
 	long n;
 
+	/*
+	 * There's a "schedule_timeout" inside of these wait
+	 * primitives, during which the op is out of the hands of the
+	 * user process that needs something done and is being
+	 * manipulated by the client-core process.
+	 */
 	if (interruptible)
 		n = wait_for_completion_interruptible_timeout(&op->waitq,
 							      timeout);

commit adcf34a2893386c99e80feee36e30a782b3815e7
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Wed Feb 24 16:54:27 2016 -0500

    Orangefs: code sanitation
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 3f9e43066444..1eadf69cc919 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -56,7 +56,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		      int flags)
 {
 	long timeout = MAX_SCHEDULE_TIMEOUT;
-	/* flags to modify behavior */
 	int ret = 0;
 
 	DEFINE_WAIT(wait_entry);
@@ -74,14 +73,20 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		     current->comm,
 		     current->pid);
 
-	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE)) {
+	/*
+	 * If ORANGEFS_OP_NO_MUTEX was set in flags, we need to avoid
+	 * aquiring the request_mutex because we're servicing a
+	 * high priority remount operation and the request_mutex is
+	 * already taken.
+	 */
+	if (!(flags & ORANGEFS_OP_NO_MUTEX)) {
 		if (flags & ORANGEFS_OP_INTERRUPTIBLE)
 			ret = mutex_lock_interruptible(&request_mutex);
 		else
 			ret = mutex_lock_killable(&request_mutex);
 		/*
 		 * check to see if we were interrupted while waiting for
-		 * semaphore
+		 * mutex
 		 */
 		if (ret < 0) {
 			op->downcall.status = ret;
@@ -95,6 +100,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	spin_lock(&orangefs_request_list_lock);
 	spin_lock(&op->lock);
 	set_op_state_waiting(op);
+	/* add high priority remount op to the front of the line. */
 	if (flags & ORANGEFS_OP_PRIORITY)
 		list_add(&op->list, &orangefs_request_list);
 	else
@@ -109,7 +115,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	}
 	spin_unlock(&orangefs_request_list_lock);
 
-	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE))
+	if (!(flags & ORANGEFS_OP_NO_MUTEX))
 		mutex_unlock(&request_mutex);
 
 	ret = wait_for_matching_downcall(op, timeout,
@@ -132,10 +138,17 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 	/* failed to get matching downcall */
 	if (ret == -ETIMEDOUT) {
-		gossip_err("orangefs: %s -- wait timed out; aborting attempt.\n",
+		gossip_err("%s: %s -- wait timed out; aborting attempt.\n",
+			   __func__,
 			   op_name);
 	}
+
+	/*
+	 * remove waiting ops from the request list or
+	 * remove in-progress ops from the in-progress list.
+	 */
 	orangefs_clean_up_interrupted_operation(op);
+
 	op->downcall.status = ret;
 	/* retry if operation has not been serviced and if requested */
 	if (ret == -EAGAIN) {
@@ -148,11 +161,12 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			     op_name,
 			     op->attempts);
 
+		/*
+		 * io ops (ops that use the shared memory buffer) have
+		 * to be returned to their caller for a retry. Other ops
+		 * can just be recycled here.
+		 */
 		if (!op->uses_shared_memory)
-			/*
-			 * this operation doesn't use the shared memory
-			 * system
-			 */
 			goto retry_servicing;
 	}
 
@@ -268,7 +282,8 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 	long n;
 
 	if (interruptible)
-		n = wait_for_completion_interruptible_timeout(&op->waitq, timeout);
+		n = wait_for_completion_interruptible_timeout(&op->waitq,
+							      timeout);
 	else
 		n = wait_for_completion_killable_timeout(&op->waitq, timeout);
 

commit 05a50a5be897004b6c1399645256bcf2e768b4ef
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Feb 18 18:59:44 2016 -0500

    orangefs: have ..._clean_interrupted_...() wait for copy to/from daemon
    
    * turn all those list_del(&op->list) into list_del_init()
    * don't pick ops that are already given up in control device
      ->read()/->write_iter().
    * have orangefs_clean_interrupted_operation() notice if op is currently
      being copied to/from daemon (by said ->read()/->write_iter()) and
      wait for that to finish.
    * when we are done copying to/from daemon and find that it had been
      given up while we were doing that, wake the waiting ..._clean_interrupted_...
    
    As the result, we are guaranteed that orangefs_clean_interrupted_operation(op)
    doesn't return until nobody else can see op.  Moreover, we don't need to play
    with op refcounts anymore.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index d980240b0fa7..3f9e43066444 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -208,15 +208,20 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 	 * Called with op->lock held.
 	 */
 	op->op_state |= OP_VFS_STATE_GIVEN_UP;
-
-	if (op_state_waiting(op)) {
+	/* from that point on it can't be moved by anybody else */
+	if (list_empty(&op->list)) {
+		/* caught copying to/from daemon */
+		BUG_ON(op_state_serviced(op));
+		spin_unlock(&op->lock);
+		wait_for_completion(&op->waitq);
+	} else if (op_state_waiting(op)) {
 		/*
 		 * upcall hasn't been read; remove op from upcall request
 		 * list.
 		 */
 		spin_unlock(&op->lock);
 		spin_lock(&orangefs_request_list_lock);
-		list_del(&op->list);
+		list_del_init(&op->list);
 		spin_unlock(&orangefs_request_list_lock);
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "Interrupted: Removed op %p from request_list\n",
@@ -225,23 +230,16 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 		/* op must be removed from the in progress htable */
 		spin_unlock(&op->lock);
 		spin_lock(&htable_ops_in_progress_lock);
-		list_del(&op->list);
+		list_del_init(&op->list);
 		spin_unlock(&htable_ops_in_progress_lock);
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "Interrupted: Removed op %p"
 			     " from htable_ops_in_progress\n",
 			     op);
-	} else if (!op_state_serviced(op)) {
+	} else {
 		spin_unlock(&op->lock);
 		gossip_err("interrupted operation is in a weird state 0x%x\n",
 			   op->op_state);
-	} else {
-		/*
-		 * It is not intended for execution to flow here,
-		 * but having this unlock here makes sparse happy.
-		 */
-		gossip_err("%s: can't get here.\n", __func__);
-		spin_unlock(&op->lock);
 	}
 	reinit_completion(&op->waitq);
 }

commit ddb84da38d0f050ff3582d5bb5e70cc7f2c6ef18
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Tue Feb 16 17:10:28 2016 -0500

    Orangefs: remove vestigial ASYNC code
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 2c47f159d1d8..d980240b0fa7 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -112,13 +112,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE))
 		mutex_unlock(&request_mutex);
 
-	/*
-	 * If we are asked to service an asynchronous operation from
-	 * VFS perspective, we are done.
-	 */
-	if (flags & ORANGEFS_OP_ASYNC)
-		return 0;
-
 	ret = wait_for_matching_downcall(op, timeout,
 					 flags & ORANGEFS_OP_INTERRUPTIBLE);
 

commit 5253487e0445d7bc9b7488e78aa3d65d4bbb158e
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Tue Feb 16 17:09:09 2016 -0500

    Orangefs: make some gossip statements more helpful.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 36eedd6a8335..2c47f159d1d8 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -67,11 +67,10 @@ int service_operation(struct orangefs_kernel_op_s *op,
 retry_servicing:
 	op->downcall.status = 0;
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "orangefs: service_operation: %s %p\n",
+		     "%s: %s op:%p: process:%s: pid:%d:\n",
+		     __func__,
 		     op_name,
-		     op);
-	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "orangefs: operation posted by process: %s, pid: %i\n",
+		     op,
 		     current->comm,
 		     current->pid);
 
@@ -122,6 +121,13 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 	ret = wait_for_matching_downcall(op, timeout,
 					 flags & ORANGEFS_OP_INTERRUPTIBLE);
+
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "%s: wait_for_matching_downcall returned %d for %p\n",
+		     __func__,
+		     ret,
+		     op);
+
 	if (!ret) {
 		spin_unlock(&op->lock);
 		/* got matching downcall; make sure status is in errno format */

commit ea2c9c9f6574e835cbc903c94b82b5a34a334866
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 21:01:21 2016 -0500

    orangefs: bufmap rewrite
    
    new waiting-for-slot logics:
            * make request for slot wait for bufmap to be set up if it
    comes before it's installed *OR* while it's running down
            * make closing control device wait for all slots to be freed
            * waiting itself rewritten to (open-coded) analogues of wait_event_...
    primitives - we would need wait_event_locked() and, pardon an obscenely
    long name, wait_event_interruptible_exclusive_timeout_locked().
            * we never wait for more than slot_timeout_secs in total and,
    if during the wait the daemon goes away, we only allow
    ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS for it to come back.
            * (cosmetical) bitmap is used instead of an array of zeroes and ones
            * old (and only reached if we are about to corrupt memory) waiting
    for daemon restart in service_operation() removed.
    
    [Martin's fixes folded]
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 378cdcf43252..36eedd6a8335 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -155,67 +155,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			 * system
 			 */
 			goto retry_servicing;
-
-		/* op uses shared memory */
-		if (orangefs_get_bufmap_init() == 0) {
-			WARN_ON(1);
-			/*
-			 * This operation uses the shared memory system AND
-			 * the system is not yet ready. This situation occurs
-			 * when the client-core is restarted AND there were
-			 * operations waiting to be processed or were already
-			 * in process.
-			 */
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "uses_shared_memory is true.\n");
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "Client core in-service status(%d).\n",
-				     is_daemon_in_service());
-			gossip_debug(GOSSIP_WAIT_DEBUG, "bufmap_init:%d.\n",
-				     orangefs_get_bufmap_init());
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "operation's status is 0x%0x.\n",
-				     op->op_state);
-
-			/*
-			 * let process sleep for a few seconds so shared
-			 * memory system can be initialized.
-			 */
-			prepare_to_wait(&orangefs_bufmap_init_waitq,
-					&wait_entry,
-					TASK_INTERRUPTIBLE);
-
-			/*
-			 * Wait for orangefs_bufmap_initialize() to wake me up
-			 * within the allotted time.
-			 */
-			ret = schedule_timeout(
-				ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS * HZ);
-
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "Value returned from schedule_timeout:"
-				     "%d.\n",
-				     ret);
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "Is shared memory available? (%d).\n",
-				     orangefs_get_bufmap_init());
-
-			finish_wait(&orangefs_bufmap_init_waitq, &wait_entry);
-
-			if (orangefs_get_bufmap_init() == 0) {
-				gossip_err("%s:The shared memory system has not started in %d seconds after the client core restarted.  Aborting user's request(%s).\n",
-					   __func__,
-					   ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS,
-					   get_opname_string(op));
-				return -EIO;
-			}
-
-			/*
-			 * Return to the calling function and re-populate a
-			 * shared memory buffer.
-			 */
-			return -EAGAIN;
-		}
 	}
 
 out:

commit 05b39a8b5cecaaf356497ee7df2f8acbc59eb2ee
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 11:04:19 2016 -0500

    orangefs: lift handling of timeouts and attempts count to service_operation()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 86b4b1fc0b14..378cdcf43252 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -16,7 +16,7 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
-static int wait_for_matching_downcall(struct orangefs_kernel_op_s *, bool);
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *, long, bool);
 static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *);
 
 /*
@@ -55,6 +55,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		      const char *op_name,
 		      int flags)
 {
+	long timeout = MAX_SCHEDULE_TIMEOUT;
 	/* flags to modify behavior */
 	int ret = 0;
 
@@ -102,15 +103,10 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	spin_unlock(&op->lock);
 	wake_up_interruptible(&orangefs_request_list_waitq);
 	if (!__is_daemon_in_service()) {
-		/*
-		 * By incrementing the per-operation attempt counter, we
-		 * directly go into the timeout logic while waiting for
-		 * the matching downcall to be read
-		 */
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "%s:client core is NOT in service.\n",
 			     __func__);
-		op->attempts++;
+		timeout = op_timeout_secs * HZ;
 	}
 	spin_unlock(&orangefs_request_list_lock);
 
@@ -124,33 +120,34 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	if (flags & ORANGEFS_OP_ASYNC)
 		return 0;
 
-	ret = wait_for_matching_downcall(op, flags & ORANGEFS_OP_INTERRUPTIBLE);
-
-	if (ret < 0) {
-		/* failed to get matching downcall */
-		if (ret == -ETIMEDOUT) {
-			gossip_err("orangefs: %s -- wait timed out; aborting attempt.\n",
-				   op_name);
-		}
-		orangefs_clean_up_interrupted_operation(op);
-		op->downcall.status = ret;
-	} else {
+	ret = wait_for_matching_downcall(op, timeout,
+					 flags & ORANGEFS_OP_INTERRUPTIBLE);
+	if (!ret) {
 		spin_unlock(&op->lock);
 		/* got matching downcall; make sure status is in errno format */
 		op->downcall.status =
 		    orangefs_normalize_to_errno(op->downcall.status);
 		ret = op->downcall.status;
+		goto out;
 	}
 
-	BUG_ON(ret != op->downcall.status);
+	/* failed to get matching downcall */
+	if (ret == -ETIMEDOUT) {
+		gossip_err("orangefs: %s -- wait timed out; aborting attempt.\n",
+			   op_name);
+	}
+	orangefs_clean_up_interrupted_operation(op);
+	op->downcall.status = ret;
 	/* retry if operation has not been serviced and if requested */
-	if (!op_state_serviced(op) && op->downcall.status == -EAGAIN) {
+	if (ret == -EAGAIN) {
+		op->attempts++;
+		timeout = op_timeout_secs * HZ;
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "orangefs: tag %llu (%s)"
 			     " -- operation to be retried (%d attempt)\n",
 			     llu(op->tag),
 			     op_name,
-			     op->attempts + 1);
+			     op->attempts);
 
 		if (!op->uses_shared_memory)
 			/*
@@ -221,6 +218,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		}
 	}
 
+out:
 	gossip_debug(GOSSIP_WAIT_DEBUG,
 		     "orangefs: service_operation %s returning: %d for %p.\n",
 		     op_name,
@@ -328,11 +326,10 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
  * Returns with op->lock taken.
  */
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
+				      long timeout,
 				      bool interruptible)
 {
-	long timeout, n;
-
-	timeout = op->attempts ? op_timeout_secs * HZ : MAX_SCHEDULE_TIMEOUT;
+	long n;
 
 	if (interruptible)
 		n = wait_for_completion_interruptible_timeout(&op->waitq, timeout);
@@ -354,7 +351,6 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
 			     op);
 		return -EINTR;
 	}
-	op->attempts++;
 	if (op_state_purged(op)) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "*** %s:"

commit c72f15b7d9b3cc744f066776dd0e61e6ab25e7d2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 10:49:24 2016 -0500

    service_operation(): don't block signals, just use ..._killable
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 6cae77400a5b..86b4b1fc0b14 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -16,7 +16,7 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
-static int wait_for_matching_downcall(struct orangefs_kernel_op_s *);
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *, bool);
 static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *);
 
 /*
@@ -56,7 +56,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		      int flags)
 {
 	/* flags to modify behavior */
-	sigset_t orig_sigset;
 	int ret = 0;
 
 	DEFINE_WAIT(wait_entry);
@@ -75,19 +74,16 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		     current->comm,
 		     current->pid);
 
-	/* mask out signals if this operation is not to be interrupted */
-	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-		orangefs_block_signals(&orig_sigset);
-
 	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE)) {
-		ret = mutex_lock_interruptible(&request_mutex);
+		if (flags & ORANGEFS_OP_INTERRUPTIBLE)
+			ret = mutex_lock_interruptible(&request_mutex);
+		else
+			ret = mutex_lock_killable(&request_mutex);
 		/*
 		 * check to see if we were interrupted while waiting for
 		 * semaphore
 		 */
 		if (ret < 0) {
-			if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-				orangefs_set_signals(&orig_sigset);
 			op->downcall.status = ret;
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "orangefs: service_operation interrupted.\n");
@@ -128,7 +124,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	if (flags & ORANGEFS_OP_ASYNC)
 		return 0;
 
-	ret = wait_for_matching_downcall(op);
+	ret = wait_for_matching_downcall(op, flags & ORANGEFS_OP_INTERRUPTIBLE);
 
 	if (ret < 0) {
 		/* failed to get matching downcall */
@@ -146,9 +142,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		ret = op->downcall.status;
 	}
 
-	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-		orangefs_set_signals(&orig_sigset);
-
 	BUG_ON(ret != op->downcall.status);
 	/* retry if operation has not been serviced and if requested */
 	if (!op_state_serviced(op) && op->downcall.status == -EAGAIN) {
@@ -334,12 +327,18 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
  *
  * Returns with op->lock taken.
  */
-static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op,
+				      bool interruptible)
 {
 	long timeout, n;
 
 	timeout = op->attempts ? op_timeout_secs * HZ : MAX_SCHEDULE_TIMEOUT;
-	n = wait_for_completion_interruptible_timeout(&op->waitq, timeout);
+
+	if (interruptible)
+		n = wait_for_completion_interruptible_timeout(&op->waitq, timeout);
+	else
+		n = wait_for_completion_killable_timeout(&op->waitq, timeout);
+
 	spin_lock(&op->lock);
 
 	if (op_state_serviced(op))

commit 98815ade9eaca3c4729710129a651aa0b43d007a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 10:38:23 2016 -0500

    orangefs: sanitize handling of request list
    
    * checking that daemon is running (to decide whether we want to limit
    the timeout) should be done *after* the damn thing is included into
    the list; doing that before means that if the daemon gets shut down
    in between, we'll end up waiting indefinitely (== up to kill -9).
    
    * cancels should go into the head of the queue - the sooner they
    are picked, the less work daemon has to do and the sooner we get to
    free the slot held by aborted operation.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 89622717a06d..6cae77400a5b 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -41,37 +41,6 @@ void purge_waiting_ops(void)
 	spin_unlock(&orangefs_request_list_lock);
 }
 
-static inline void
-__add_op_to_request_list(struct orangefs_kernel_op_s *op)
-{
-	spin_lock(&op->lock);
-	set_op_state_waiting(op);
-	list_add_tail(&op->list, &orangefs_request_list);
-	spin_unlock(&op->lock);
-	wake_up_interruptible(&orangefs_request_list_waitq);
-}
-
-static inline void
-add_op_to_request_list(struct orangefs_kernel_op_s *op)
-{
-	spin_lock(&orangefs_request_list_lock);
-	__add_op_to_request_list(op);
-	spin_unlock(&orangefs_request_list_lock);
-}
-
-static inline
-void add_priority_op_to_request_list(struct orangefs_kernel_op_s *op)
-{
-	spin_lock(&orangefs_request_list_lock);
-	spin_lock(&op->lock);
-	set_op_state_waiting(op);
-
-	list_add(&op->list, &orangefs_request_list);
-	spin_unlock(&orangefs_request_list_lock);
-	spin_unlock(&op->lock);
-	wake_up_interruptible(&orangefs_request_list_waitq);
-}
-
 /*
  * submits a ORANGEFS operation and waits for it to complete
  *
@@ -126,32 +95,28 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		}
 	}
 
-	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "%s:About to call is_daemon_in_service().\n",
-		     __func__);
-
-	if (is_daemon_in_service() < 0) {
+	/* queue up the operation */
+	spin_lock(&orangefs_request_list_lock);
+	spin_lock(&op->lock);
+	set_op_state_waiting(op);
+	if (flags & ORANGEFS_OP_PRIORITY)
+		list_add(&op->list, &orangefs_request_list);
+	else
+		list_add_tail(&op->list, &orangefs_request_list);
+	spin_unlock(&op->lock);
+	wake_up_interruptible(&orangefs_request_list_waitq);
+	if (!__is_daemon_in_service()) {
 		/*
 		 * By incrementing the per-operation attempt counter, we
 		 * directly go into the timeout logic while waiting for
 		 * the matching downcall to be read
 		 */
 		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:client core is NOT in service(%d).\n",
-			     __func__,
-			     is_daemon_in_service());
-		op->attempts++;
-	}
-
-	/* queue up the operation */
-	if (flags & ORANGEFS_OP_PRIORITY) {
-		add_priority_op_to_request_list(op);
-	} else {
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:About to call add_op_to_request_list().\n",
+			     "%s:client core is NOT in service.\n",
 			     __func__);
-		add_op_to_request_list(op);
+		op->attempts++;
 	}
+	spin_unlock(&orangefs_request_list_lock);
 
 	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE))
 		mutex_unlock(&request_mutex);
@@ -292,7 +257,10 @@ bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
 		spin_unlock(&orangefs_request_list_lock);
 		return false;
 	}
-	__add_op_to_request_list(op);
+	spin_lock(&op->lock);
+	set_op_state_waiting(op);
+	list_add(&op->list, &orangefs_request_list);
+	spin_unlock(&op->lock);
 	spin_unlock(&orangefs_request_list_lock);
 
 	gossip_debug(GOSSIP_UTILS_DEBUG,

commit d2d87a3b6df3088a991e277d42cd6a549ff2bc66
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Feb 13 10:15:22 2016 -0500

    orangefs: get rid of loop in wait_for_matching_downcall()
    
    turn op->waitq into struct completion...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 3ea1665efdf0..89622717a06d 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -17,6 +17,7 @@
 #include "orangefs-bufmap.h"
 
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *);
+static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *);
 
 /*
  * What we do in this function is to walk the list of operations that are
@@ -170,8 +171,10 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			gossip_err("orangefs: %s -- wait timed out; aborting attempt.\n",
 				   op_name);
 		}
+		orangefs_clean_up_interrupted_operation(op);
 		op->downcall.status = ret;
 	} else {
+		spin_unlock(&op->lock);
 		/* got matching downcall; make sure status is in errno format */
 		op->downcall.status =
 		    orangefs_normalize_to_errno(op->downcall.status);
@@ -343,6 +346,7 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 		gossip_err("%s: can't get here.\n", __func__);
 		spin_unlock(&op->lock);
 	}
+	reinit_completion(&op->waitq);
 }
 
 /*
@@ -359,95 +363,52 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
  * EINTR/EIO/ETIMEDOUT indicating we are done trying to service this
  * operation since client-core seems to be exiting too often
  * or if we were interrupted.
+ *
+ * Returns with op->lock taken.
  */
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 {
-	int ret = -EINVAL;
-	DEFINE_WAIT(wait_entry);
+	long timeout, n;
 
-	while (1) {
-		spin_lock(&op->lock);
-		prepare_to_wait(&op->waitq, &wait_entry, TASK_INTERRUPTIBLE);
-		if (op_state_serviced(op)) {
-			spin_unlock(&op->lock);
-			ret = 0;
-			break;
-		}
+	timeout = op->attempts ? op_timeout_secs * HZ : MAX_SCHEDULE_TIMEOUT;
+	n = wait_for_completion_interruptible_timeout(&op->waitq, timeout);
+	spin_lock(&op->lock);
 
-		if (unlikely(signal_pending(current))) {
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "*** %s:"
-				     " operation interrupted by a signal (tag "
-				     "%llu, op %p)\n",
-				     __func__,
-				     llu(op->tag),
-				     op);
-			orangefs_clean_up_interrupted_operation(op);
-			ret = -EINTR;
-			break;
-		}
+	if (op_state_serviced(op))
+		return 0;
 
-		/*
-		 * if this was our first attempt and client-core
-		 * has not purged our operation, we are happy to
-		 * simply wait
-		 */
-		if (op->attempts == 0 && !op_state_purged(op)) {
-			spin_unlock(&op->lock);
-			schedule();
-		} else {
-			spin_unlock(&op->lock);
-			/*
-			 * subsequent attempts, we retry exactly once
-			 * with timeouts
-			 */
-			if (!schedule_timeout(op_timeout_secs * HZ)) {
-				gossip_debug(GOSSIP_WAIT_DEBUG,
-					     "*** %s:"
-					     " operation timed out (tag"
-					     " %llu, %p, att %d)\n",
-					     __func__,
-					     llu(op->tag),
-					     op,
-					     op->attempts);
-				ret = -ETIMEDOUT;
-				spin_lock(&op->lock);
-				orangefs_clean_up_interrupted_operation(op);
-				break;
-			}
-		}
-		spin_lock(&op->lock);
-		op->attempts++;
-		/*
-		 * if the operation was purged in the meantime, it
-		 * is better to requeue it afresh but ensure that
-		 * we have not been purged repeatedly. This could
-		 * happen if client-core crashes when an op
-		 * is being serviced, so we requeue the op, client
-		 * core crashes again so we requeue the op, client
-		 * core starts, and so on...
-		 */
-		if (op_state_purged(op)) {
-			ret = (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
-				 -EAGAIN :
-				 -EIO;
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "*** %s:"
-				     " operation purged (tag "
-				     "%llu, %p, att %d)\n",
-				     __func__,
-				     llu(op->tag),
-				     op,
-				     op->attempts);
-			orangefs_clean_up_interrupted_operation(op);
-			break;
-		}
-		spin_unlock(&op->lock);
+	if (unlikely(n < 0)) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "*** %s:"
+			     " operation interrupted by a signal (tag "
+			     "%llu, op %p)\n",
+			     __func__,
+			     llu(op->tag),
+			     op);
+		return -EINTR;
 	}
-
-	spin_lock(&op->lock);
-	finish_wait(&op->waitq, &wait_entry);
-	spin_unlock(&op->lock);
-
-	return ret;
+	op->attempts++;
+	if (op_state_purged(op)) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "*** %s:"
+			     " operation purged (tag "
+			     "%llu, %p, att %d)\n",
+			     __func__,
+			     llu(op->tag),
+			     op,
+			     op->attempts);
+		return (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
+			 -EAGAIN :
+			 -EIO;
+	}
+	/* must have timed out, then... */
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "*** %s:"
+		     " operation timed out (tag"
+		     " %llu, %p, att %d)\n",
+		     __func__,
+		     llu(op->tag),
+		     op,
+		     op->attempts);
+	return -ETIMEDOUT;
 }

commit 78699e29fd784a4613d254a22627f336c55c4a76
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Feb 11 23:07:19 2016 -0500

    orangefs: delay freeing slot until cancel completes
    
    Make cancels reuse the aborted read/write op, to make sure they do not
    fail on lack of memory.
    
    Don't issue a cancel unless the daemon has seen our read/write, has not
    replied and isn't being shut down.
    
    If cancel *is* issued, don't wait for it to complete; stash the slot
    in there and just have it freed when cancel is finally replied to or
    purged (and delay dropping the reference until then, obviously).
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 191d886ccc57..3ea1665efdf0 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -16,7 +16,6 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
-static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *);
 static int wait_for_matching_downcall(struct orangefs_kernel_op_s *);
 
 /*
@@ -36,25 +35,29 @@ void purge_waiting_ops(void)
 			     "pvfs2-client-core: purging op tag %llu %s\n",
 			     llu(op->tag),
 			     get_opname_string(op));
-		spin_lock(&op->lock);
 		set_op_state_purged(op);
-		spin_unlock(&op->lock);
 	}
 	spin_unlock(&orangefs_request_list_lock);
 }
 
 static inline void
-add_op_to_request_list(struct orangefs_kernel_op_s *op)
+__add_op_to_request_list(struct orangefs_kernel_op_s *op)
 {
-	spin_lock(&orangefs_request_list_lock);
 	spin_lock(&op->lock);
 	set_op_state_waiting(op);
 	list_add_tail(&op->list, &orangefs_request_list);
-	spin_unlock(&orangefs_request_list_lock);
 	spin_unlock(&op->lock);
 	wake_up_interruptible(&orangefs_request_list_waitq);
 }
 
+static inline void
+add_op_to_request_list(struct orangefs_kernel_op_s *op)
+{
+	spin_lock(&orangefs_request_list_lock);
+	__add_op_to_request_list(op);
+	spin_unlock(&orangefs_request_list_lock);
+}
+
 static inline
 void add_priority_op_to_request_list(struct orangefs_kernel_op_s *op)
 {
@@ -159,15 +162,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	if (flags & ORANGEFS_OP_ASYNC)
 		return 0;
 
-	if (flags & ORANGEFS_OP_CANCELLATION) {
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:"
-			     "About to call wait_for_cancellation_downcall.\n",
-			     __func__);
-		ret = wait_for_cancellation_downcall(op);
-	} else {
-		ret = wait_for_matching_downcall(op);
-	}
+	ret = wait_for_matching_downcall(op);
 
 	if (ret < 0) {
 		/* failed to get matching downcall */
@@ -273,6 +268,36 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	return ret;
 }
 
+bool orangefs_cancel_op_in_progress(struct orangefs_kernel_op_s *op)
+{
+	u64 tag = op->tag;
+	if (!op_state_in_progress(op))
+		return false;
+
+	op->slot_to_free = op->upcall.req.io.buf_index;
+	memset(&op->upcall, 0, sizeof(op->upcall));
+	memset(&op->downcall, 0, sizeof(op->downcall));
+	op->upcall.type = ORANGEFS_VFS_OP_CANCEL;
+	op->upcall.req.cancel.op_tag = tag;
+	op->downcall.type = ORANGEFS_VFS_OP_INVALID;
+	op->downcall.status = -1;
+	orangefs_new_tag(op);
+
+	spin_lock(&orangefs_request_list_lock);
+	/* orangefs_request_list_lock is enough of a barrier here */
+	if (!__is_daemon_in_service()) {
+		spin_unlock(&orangefs_request_list_lock);
+		return false;
+	}
+	__add_op_to_request_list(op);
+	spin_unlock(&orangefs_request_list_lock);
+
+	gossip_debug(GOSSIP_UTILS_DEBUG,
+		     "Attempting ORANGEFS operation cancellation of tag %llu\n",
+		     llu(tag));
+	return true;
+}
+
 static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*
@@ -426,81 +451,3 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 
 	return ret;
 }
-
-/*
- * similar to wait_for_matching_downcall(), but used in the special case
- * of I/O cancellations.
- *
- * Note we need a special wait function because if this is called we already
- *      know that a signal is pending in current and need to service the
- *      cancellation upcall anyway.  the only way to exit this is to either
- *      timeout or have the cancellation be serviced properly.
- */
-static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
-{
-	int ret = -EINVAL;
-	DEFINE_WAIT(wait_entry);
-
-	while (1) {
-		spin_lock(&op->lock);
-		prepare_to_wait(&op->waitq, &wait_entry, TASK_INTERRUPTIBLE);
-		if (op_state_serviced(op)) {
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "%s:op-state is SERVICED.\n",
-				     __func__);
-			spin_unlock(&op->lock);
-			ret = 0;
-			break;
-		}
-
-		if (signal_pending(current)) {
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "%s:operation interrupted by a signal (tag"
-				     " %llu, op %p)\n",
-				     __func__,
-				     llu(op->tag),
-				     op);
-			orangefs_clean_up_interrupted_operation(op);
-			ret = -EINTR;
-			break;
-		}
-
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:About to call schedule_timeout.\n",
-			     __func__);
-		spin_unlock(&op->lock);
-		ret = schedule_timeout(op_timeout_secs * HZ);
-
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:Value returned from schedule_timeout(%d).\n",
-			     __func__,
-			     ret);
-		if (!ret) {
-			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "%s:*** operation timed out: %p\n",
-				     __func__,
-				     op);
-			spin_lock(&op->lock);
-			orangefs_clean_up_interrupted_operation(op);
-			ret = -ETIMEDOUT;
-			break;
-		}
-
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s:Breaking out of loop, regardless of value returned by schedule_timeout.\n",
-			     __func__);
-		ret = -ETIMEDOUT;
-		break;
-	}
-
-	spin_lock(&op->lock);
-	finish_wait(&op->waitq, &wait_entry);
-	spin_unlock(&op->lock);
-
-	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "%s:returning ret(%d)\n",
-		     __func__,
-		     ret);
-
-	return ret;
-}

commit 6ebcc3fcdac1f70078a02ab11f2aa5a88a4fdaee
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Thu Feb 4 16:28:31 2016 -0500

    Orangefs: added a couple of WARN_ONs, perhaps just temporarily.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index cdbf57bef3eb..191d886ccc57 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -205,6 +205,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 		/* op uses shared memory */
 		if (orangefs_get_bufmap_init() == 0) {
+			WARN_ON(1);
 			/*
 			 * This operation uses the shared memory system AND
 			 * the system is not yet ready. This situation occurs

commit 727cbfea623b78d46ce8e0f8c931b5189f3fe2e0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 23 13:17:55 2016 -0500

    orangefs: get rid of MSECS_TO_JIFFIES
    
    All timeouts are in _seconds_, so all calls are of form
    MSECS_TO_JIFFIES(n * 1000), which is a convoluted way to
    spell n * HZ.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 699ffd8b2a51..cdbf57bef3eb 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -235,8 +235,8 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			 * Wait for orangefs_bufmap_initialize() to wake me up
 			 * within the allotted time.
 			 */
-			ret = schedule_timeout(MSECS_TO_JIFFIES
-				(1000 * ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS));
+			ret = schedule_timeout(
+				ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS * HZ);
 
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "Value returned from schedule_timeout:"
@@ -375,8 +375,7 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 			 * subsequent attempts, we retry exactly once
 			 * with timeouts
 			 */
-			if (!schedule_timeout(MSECS_TO_JIFFIES
-			      (1000 * op_timeout_secs))) {
+			if (!schedule_timeout(op_timeout_secs * HZ)) {
 				gossip_debug(GOSSIP_WAIT_DEBUG,
 					     "*** %s:"
 					     " operation timed out (tag"
@@ -469,8 +468,7 @@ static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 			     "%s:About to call schedule_timeout.\n",
 			     __func__);
 		spin_unlock(&op->lock);
-		ret =
-		    schedule_timeout(MSECS_TO_JIFFIES(1000 * op_timeout_secs));
+		ret = schedule_timeout(op_timeout_secs * HZ);
 
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "%s:Value returned from schedule_timeout(%d).\n",

commit eab9b38939fae1b7731570478718a5d1b2f28ea9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 23 13:09:05 2016 -0500

    orangefs_clean_up_interrupted_operation: call with op->lock held
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 8c07a070e2b6..699ffd8b2a51 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -279,35 +279,8 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 	 * the interruption is detected.  there is a coarse grained lock
 	 * across the operation.
 	 *
-	 * NOTE: be sure not to reverse lock ordering by locking an op lock
-	 * while holding the request_list lock.  Here, we first lock the op
-	 * and then lock the appropriate list.
+	 * Called with op->lock held.
 	 */
-	if (!op) {
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			    "%s: op is null, ignoring\n",
-			     __func__);
-		return;
-	}
-
-	/*
-	 * one more sanity check, make sure it's in one of the possible states
-	 * or don't try to cancel it
-	 */
-	if (!(op_state_waiting(op) ||
-	      op_state_in_progress(op) ||
-	      op_state_serviced(op) ||
-	      op_state_purged(op))) {
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "%s: op %p not in a valid state (%0x), "
-			     "ignoring\n",
-			     __func__,
-			     op,
-			     op->op_state);
-		return;
-	}
-
-	spin_lock(&op->lock);
 	op->op_state |= OP_VFS_STATE_GIVEN_UP;
 
 	if (op_state_waiting(op)) {
@@ -374,7 +347,6 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 			ret = 0;
 			break;
 		}
-		spin_unlock(&op->lock);
 
 		if (unlikely(signal_pending(current))) {
 			gossip_debug(GOSSIP_WAIT_DEBUG,
@@ -394,7 +366,6 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 		 * has not purged our operation, we are happy to
 		 * simply wait
 		 */
-		spin_lock(&op->lock);
 		if (op->attempts == 0 && !op_state_purged(op)) {
 			spin_unlock(&op->lock);
 			schedule();
@@ -415,6 +386,7 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 					     op,
 					     op->attempts);
 				ret = -ETIMEDOUT;
+				spin_lock(&op->lock);
 				orangefs_clean_up_interrupted_operation(op);
 				break;
 			}
@@ -434,7 +406,6 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 			ret = (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
 				 -EAGAIN :
 				 -EIO;
-			spin_unlock(&op->lock);
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "*** %s:"
 				     " operation purged (tag "
@@ -481,7 +452,6 @@ static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 			ret = 0;
 			break;
 		}
-		spin_unlock(&op->lock);
 
 		if (signal_pending(current)) {
 			gossip_debug(GOSSIP_WAIT_DEBUG,
@@ -498,6 +468,7 @@ static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "%s:About to call schedule_timeout.\n",
 			     __func__);
+		spin_unlock(&op->lock);
 		ret =
 		    schedule_timeout(MSECS_TO_JIFFIES(1000 * op_timeout_secs));
 
@@ -510,6 +481,7 @@ static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 				     "%s:*** operation timed out: %p\n",
 				     __func__,
 				     op);
+			spin_lock(&op->lock);
 			orangefs_clean_up_interrupted_operation(op);
 			ret = -ETIMEDOUT;
 			break;

commit 70c6ea26ff2d2df420d573f8f0f22853336c0b56
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 23 13:04:19 2016 -0500

    orangefs: reduce nesting in wait_for_matching_downcall()
    
    reorder if branches...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index b8a2fcbcce64..8c07a070e2b6 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -376,79 +376,77 @@ static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 		}
 		spin_unlock(&op->lock);
 
-		if (!signal_pending(current)) {
-			/*
-			 * if this was our first attempt and client-core
-			 * has not purged our operation, we are happy to
-			 * simply wait
-			 */
-			spin_lock(&op->lock);
-			if (op->attempts == 0 && !op_state_purged(op)) {
-				spin_unlock(&op->lock);
-				schedule();
-			} else {
-				spin_unlock(&op->lock);
-				/*
-				 * subsequent attempts, we retry exactly once
-				 * with timeouts
-				 */
-				if (!schedule_timeout(MSECS_TO_JIFFIES
-				      (1000 * op_timeout_secs))) {
-					gossip_debug(GOSSIP_WAIT_DEBUG,
-						     "*** %s:"
-						     " operation timed out (tag"
-						     " %llu, %p, att %d)\n",
-						     __func__,
-						     llu(op->tag),
-						     op,
-						     op->attempts);
-					ret = -ETIMEDOUT;
-					orangefs_clean_up_interrupted_operation
-					    (op);
-					break;
-				}
-			}
-			spin_lock(&op->lock);
-			op->attempts++;
+		if (unlikely(signal_pending(current))) {
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "*** %s:"
+				     " operation interrupted by a signal (tag "
+				     "%llu, op %p)\n",
+				     __func__,
+				     llu(op->tag),
+				     op);
+			orangefs_clean_up_interrupted_operation(op);
+			ret = -EINTR;
+			break;
+		}
+
+		/*
+		 * if this was our first attempt and client-core
+		 * has not purged our operation, we are happy to
+		 * simply wait
+		 */
+		spin_lock(&op->lock);
+		if (op->attempts == 0 && !op_state_purged(op)) {
+			spin_unlock(&op->lock);
+			schedule();
+		} else {
+			spin_unlock(&op->lock);
 			/*
-			 * if the operation was purged in the meantime, it
-			 * is better to requeue it afresh but ensure that
-			 * we have not been purged repeatedly. This could
-			 * happen if client-core crashes when an op
-			 * is being serviced, so we requeue the op, client
-			 * core crashes again so we requeue the op, client
-			 * core starts, and so on...
+			 * subsequent attempts, we retry exactly once
+			 * with timeouts
 			 */
-			if (op_state_purged(op)) {
-				ret = (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
-					 -EAGAIN :
-					 -EIO;
-				spin_unlock(&op->lock);
+			if (!schedule_timeout(MSECS_TO_JIFFIES
+			      (1000 * op_timeout_secs))) {
 				gossip_debug(GOSSIP_WAIT_DEBUG,
 					     "*** %s:"
-					     " operation purged (tag "
-					     "%llu, %p, att %d)\n",
+					     " operation timed out (tag"
+					     " %llu, %p, att %d)\n",
 					     __func__,
 					     llu(op->tag),
 					     op,
 					     op->attempts);
+				ret = -ETIMEDOUT;
 				orangefs_clean_up_interrupted_operation(op);
 				break;
 			}
+		}
+		spin_lock(&op->lock);
+		op->attempts++;
+		/*
+		 * if the operation was purged in the meantime, it
+		 * is better to requeue it afresh but ensure that
+		 * we have not been purged repeatedly. This could
+		 * happen if client-core crashes when an op
+		 * is being serviced, so we requeue the op, client
+		 * core crashes again so we requeue the op, client
+		 * core starts, and so on...
+		 */
+		if (op_state_purged(op)) {
+			ret = (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
+				 -EAGAIN :
+				 -EIO;
 			spin_unlock(&op->lock);
-			continue;
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "*** %s:"
+				     " operation purged (tag "
+				     "%llu, %p, att %d)\n",
+				     __func__,
+				     llu(op->tag),
+				     op,
+				     op->attempts);
+			orangefs_clean_up_interrupted_operation(op);
+			break;
 		}
-
-		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "*** %s:"
-			     " operation interrupted by a signal (tag "
-			     "%llu, op %p)\n",
-			     __func__,
-			     llu(op->tag),
-			     op);
-		orangefs_clean_up_interrupted_operation(op);
-		ret = -EINTR;
-		break;
+		spin_unlock(&op->lock);
 	}
 
 	spin_lock(&op->lock);

commit e1056a9cc35c878b6615d0fc84d3f338c89a38fa
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jan 23 12:26:56 2016 -0500

    orangefs: remove cargo-culting spin_lock_irqsave() in service_operation()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 2e9468f57981..b8a2fcbcce64 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -86,9 +86,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	sigset_t orig_sigset;
 	int ret = 0;
 
-	/* irqflags and wait_entry are only used IF the client-core aborts */
-	unsigned long irqflags;
-
 	DEFINE_WAIT(wait_entry);
 
 	op->upcall.tgid = current->tgid;
@@ -230,11 +227,9 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			 * let process sleep for a few seconds so shared
 			 * memory system can be initialized.
 			 */
-			spin_lock_irqsave(&op->lock, irqflags);
 			prepare_to_wait(&orangefs_bufmap_init_waitq,
 					&wait_entry,
 					TASK_INTERRUPTIBLE);
-			spin_unlock_irqrestore(&op->lock, irqflags);
 
 			/*
 			 * Wait for orangefs_bufmap_initialize() to wake me up
@@ -251,9 +246,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 				     "Is shared memory available? (%d).\n",
 				     orangefs_get_bufmap_init());
 
-			spin_lock_irqsave(&op->lock, irqflags);
 			finish_wait(&orangefs_bufmap_init_waitq, &wait_entry);
-			spin_unlock_irqrestore(&op->lock, irqflags);
 
 			if (orangefs_get_bufmap_init() == 0) {
 				gossip_err("%s:The shared memory system has not started in %d seconds after the client core restarted.  Aborting user's request(%s).\n",

commit ed42fe059389daa35a2aa10ec832e9f8d0a9e59e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 22 19:47:47 2016 -0500

    orangefs: hopefully saner op refcounting and locking
    
    * create with refcount 1
    * make op_release() decrement and free if zero (i.e. old put_op()
      has become that).
    * mark when submitter has given up waiting; from that point nobody
      else can move between the lists, change state, etc.
    * have daemon read/write_iter grab a reference when picking op
      and *always* give it up in the end
    * don't put into hash until we know it's been successfully passed to
      daemon
    
    * move op->lock _lower_ than htab_in_progress_lock (and make sure
      to take it in purge_inprogress_ops())
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index a257891dd3ea..2e9468f57981 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -279,25 +279,6 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	return ret;
 }
 
-static inline void remove_op_from_request_list(struct orangefs_kernel_op_s *op)
-{
-	struct list_head *tmp = NULL;
-	struct list_head *tmp_safe = NULL;
-	struct orangefs_kernel_op_s *tmp_op = NULL;
-
-	spin_lock(&orangefs_request_list_lock);
-	list_for_each_safe(tmp, tmp_safe, &orangefs_request_list) {
-		tmp_op = list_entry(tmp,
-				    struct orangefs_kernel_op_s,
-				    list);
-		if (tmp_op && (tmp_op == op)) {
-			list_del(&tmp_op->list);
-			break;
-		}
-	}
-	spin_unlock(&orangefs_request_list_lock);
-}
-
 static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*
@@ -334,6 +315,7 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 	}
 
 	spin_lock(&op->lock);
+	op->op_state |= OP_VFS_STATE_GIVEN_UP;
 
 	if (op_state_waiting(op)) {
 		/*
@@ -341,7 +323,9 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
 		 * list.
 		 */
 		spin_unlock(&op->lock);
-		remove_op_from_request_list(op);
+		spin_lock(&orangefs_request_list_lock);
+		list_del(&op->list);
+		spin_unlock(&orangefs_request_list_lock);
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "Interrupted: Removed op %p from request_list\n",
 			     op);

commit ade3d78104e08809569acef37dc905066d320726
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jan 21 22:58:58 2016 -0500

    orangefs: make wait_for_...downcall() static
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 641de05fa739..a257891dd3ea 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -16,6 +16,9 @@
 #include "orangefs-kernel.h"
 #include "orangefs-bufmap.h"
 
+static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *);
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *);
+
 /*
  * What we do in this function is to walk the list of operations that are
  * present in the request queue and mark them as purged.

commit 831d0949799be75ed84c1c6a4541ebcd74edba6c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jan 21 23:17:37 2016 -0500

    orangefs: move wakeups into set_op_state_{serviced,purged}()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 0b04f4197526..641de05fa739 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -36,7 +36,6 @@ void purge_waiting_ops(void)
 		spin_lock(&op->lock);
 		set_op_state_purged(op);
 		spin_unlock(&op->lock);
-		wake_up_interruptible(&op->waitq);
 	}
 	spin_unlock(&orangefs_request_list_lock);
 }

commit b7ae37b09e069a5d8d604caabd6675456a0d89fc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jan 21 22:58:58 2016 -0500

    orangefs: make wait_for_...downcall() static
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index bc86f16c2037..0b04f4197526 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -382,7 +382,7 @@ static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s
  * operation since client-core seems to be exiting too often
  * or if we were interrupted.
  */
-int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
+static int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
 	DEFINE_WAIT(wait_entry);
@@ -488,7 +488,7 @@ int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
  *      cancellation upcall anyway.  the only way to exit this is to either
  *      timeout or have the cancellation be serviced properly.
  */
-int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
+static int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
 	DEFINE_WAIT(wait_entry);

commit e07db0a2c2e910d6619bfff962d73bd9c886c604
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Jan 21 22:21:41 2016 -0500

    make orangefs_clean_up_interrupted_operation() static
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 4730baf686b2..bc86f16c2037 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -296,7 +296,7 @@ static inline void remove_op_from_request_list(struct orangefs_kernel_op_s *op)
 	spin_unlock(&orangefs_request_list_lock);
 }
 
-void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
+static void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*
 	 * handle interrupted cases depending on what state we were in when

commit fc916da52dde736605137c7d528e2cdec7f81bca
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jan 19 12:26:13 2016 -0500

    orangefs: get rid of <censored> macros
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 751c3c640a52..4730baf686b2 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -41,6 +41,31 @@ void purge_waiting_ops(void)
 	spin_unlock(&orangefs_request_list_lock);
 }
 
+static inline void
+add_op_to_request_list(struct orangefs_kernel_op_s *op)
+{
+	spin_lock(&orangefs_request_list_lock);
+	spin_lock(&op->lock);
+	set_op_state_waiting(op);
+	list_add_tail(&op->list, &orangefs_request_list);
+	spin_unlock(&orangefs_request_list_lock);
+	spin_unlock(&op->lock);
+	wake_up_interruptible(&orangefs_request_list_waitq);
+}
+
+static inline
+void add_priority_op_to_request_list(struct orangefs_kernel_op_s *op)
+{
+	spin_lock(&orangefs_request_list_lock);
+	spin_lock(&op->lock);
+	set_op_state_waiting(op);
+
+	list_add(&op->list, &orangefs_request_list);
+	spin_unlock(&orangefs_request_list_lock);
+	spin_unlock(&op->lock);
+	wake_up_interruptible(&orangefs_request_list_waitq);
+}
+
 /*
  * submits a ORANGEFS operation and waits for it to complete
  *
@@ -252,6 +277,25 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	return ret;
 }
 
+static inline void remove_op_from_request_list(struct orangefs_kernel_op_s *op)
+{
+	struct list_head *tmp = NULL;
+	struct list_head *tmp_safe = NULL;
+	struct orangefs_kernel_op_s *tmp_op = NULL;
+
+	spin_lock(&orangefs_request_list_lock);
+	list_for_each_safe(tmp, tmp_safe, &orangefs_request_list) {
+		tmp_op = list_entry(tmp,
+				    struct orangefs_kernel_op_s,
+				    list);
+		if (tmp_op && (tmp_op == op)) {
+			list_del(&tmp_op->list);
+			break;
+		}
+	}
+	spin_unlock(&orangefs_request_list_lock);
+}
+
 void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*

commit 7d2214858f137ff5fe20d0fdc2823c12b4b54f46
Author: Martin Brandenburg <martin@omnibond.com>
Date:   Mon Jan 4 15:05:28 2016 -0500

    orangefs: Fix some more global namespace pollution.
    
    This only changes the names of things, so there is no functional change.
    
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index e1415e3882ba..751c3c640a52 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -180,7 +180,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			goto retry_servicing;
 
 		/* op uses shared memory */
-		if (get_bufmap_init() == 0) {
+		if (orangefs_get_bufmap_init() == 0) {
 			/*
 			 * This operation uses the shared memory system AND
 			 * the system is not yet ready. This situation occurs
@@ -194,7 +194,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 				     "Client core in-service status(%d).\n",
 				     is_daemon_in_service());
 			gossip_debug(GOSSIP_WAIT_DEBUG, "bufmap_init:%d.\n",
-				     get_bufmap_init());
+				     orangefs_get_bufmap_init());
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "operation's status is 0x%0x.\n",
 				     op->op_state);
@@ -222,13 +222,13 @@ int service_operation(struct orangefs_kernel_op_s *op,
 				     ret);
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "Is shared memory available? (%d).\n",
-				     get_bufmap_init());
+				     orangefs_get_bufmap_init());
 
 			spin_lock_irqsave(&op->lock, irqflags);
 			finish_wait(&orangefs_bufmap_init_waitq, &wait_entry);
 			spin_unlock_irqrestore(&op->lock, irqflags);
 
-			if (get_bufmap_init() == 0) {
+			if (orangefs_get_bufmap_init() == 0) {
 				gossip_err("%s:The shared memory system has not started in %d seconds after the client core restarted.  Aborting user's request(%s).\n",
 					   __func__,
 					   ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS,

commit c146c0b87f7cef247744a649f8c1d794d18bfcb7
Author: Richard Weinberger <richard@nod.at>
Date:   Sat Jan 2 23:04:47 2016 +0100

    orangefs: Don't pollute global namespace
    
    Prefix public functions with "orangefs_" do don't
    pollute the global namespace.
    
    This fixes a build issue on UML which also has block_signals().
    
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 856a4b48fe23..e1415e3882ba 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -80,7 +80,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 
 	/* mask out signals if this operation is not to be interrupted */
 	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-		block_signals(&orig_sigset);
+		orangefs_block_signals(&orig_sigset);
 
 	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE)) {
 		ret = mutex_lock_interruptible(&request_mutex);
@@ -90,7 +90,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 		 */
 		if (ret < 0) {
 			if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-				set_signals(&orig_sigset);
+				orangefs_set_signals(&orig_sigset);
 			op->downcall.status = ret;
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "orangefs: service_operation interrupted.\n");
@@ -160,7 +160,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	}
 
 	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
-		set_signals(&orig_sigset);
+		orangefs_set_signals(&orig_sigset);
 
 	BUG_ON(ret != op->downcall.status);
 	/* retry if operation has not been serviced and if requested */

commit ce6c414e17be602a84b1b34915468f8301ed14a0
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Mon Dec 14 14:54:46 2015 -0500

    Orangefs: Don't wait the old-fashioned way.
    
    Get rid of add_wait_queue, set_current_state, etc, and use the
    wait_event() model.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index c731cbdd5fbd..856a4b48fe23 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -62,7 +62,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 	/* irqflags and wait_entry are only used IF the client-core aborts */
 	unsigned long irqflags;
 
-	DECLARE_WAITQUEUE(wait_entry, current);
+	DEFINE_WAIT(wait_entry);
 
 	op->upcall.tgid = current->tgid;
 	op->upcall.pid = current->pid;
@@ -204,11 +204,11 @@ int service_operation(struct orangefs_kernel_op_s *op,
 			 * memory system can be initialized.
 			 */
 			spin_lock_irqsave(&op->lock, irqflags);
-			add_wait_queue(&orangefs_bufmap_init_waitq, &wait_entry);
+			prepare_to_wait(&orangefs_bufmap_init_waitq,
+					&wait_entry,
+					TASK_INTERRUPTIBLE);
 			spin_unlock_irqrestore(&op->lock, irqflags);
 
-			set_current_state(TASK_INTERRUPTIBLE);
-
 			/*
 			 * Wait for orangefs_bufmap_initialize() to wake me up
 			 * within the allotted time.
@@ -225,8 +225,7 @@ int service_operation(struct orangefs_kernel_op_s *op,
 				     get_bufmap_init());
 
 			spin_lock_irqsave(&op->lock, irqflags);
-			remove_wait_queue(&orangefs_bufmap_init_waitq,
-					  &wait_entry);
+			finish_wait(&orangefs_bufmap_init_waitq, &wait_entry);
 			spin_unlock_irqrestore(&op->lock, irqflags);
 
 			if (get_bufmap_init() == 0) {
@@ -342,16 +341,11 @@ void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
-	DECLARE_WAITQUEUE(wait_entry, current);
-
-	spin_lock(&op->lock);
-	add_wait_queue(&op->waitq, &wait_entry);
-	spin_unlock(&op->lock);
+	DEFINE_WAIT(wait_entry);
 
 	while (1) {
-		set_current_state(TASK_INTERRUPTIBLE);
-
 		spin_lock(&op->lock);
+		prepare_to_wait(&op->waitq, &wait_entry, TASK_INTERRUPTIBLE);
 		if (op_state_serviced(op)) {
 			spin_unlock(&op->lock);
 			ret = 0;
@@ -434,10 +428,8 @@ int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 		break;
 	}
 
-	set_current_state(TASK_RUNNING);
-
 	spin_lock(&op->lock);
-	remove_wait_queue(&op->waitq, &wait_entry);
+	finish_wait(&op->waitq, &wait_entry);
 	spin_unlock(&op->lock);
 
 	return ret;
@@ -455,16 +447,11 @@ int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
-	DECLARE_WAITQUEUE(wait_entry, current);
-
-	spin_lock(&op->lock);
-	add_wait_queue(&op->waitq, &wait_entry);
-	spin_unlock(&op->lock);
+	DEFINE_WAIT(wait_entry);
 
 	while (1) {
-		set_current_state(TASK_INTERRUPTIBLE);
-
 		spin_lock(&op->lock);
+		prepare_to_wait(&op->waitq, &wait_entry, TASK_INTERRUPTIBLE);
 		if (op_state_serviced(op)) {
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "%s:op-state is SERVICED.\n",
@@ -514,10 +501,8 @@ int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 		break;
 	}
 
-	set_current_state(TASK_RUNNING);
-
 	spin_lock(&op->lock);
-	remove_wait_queue(&op->waitq, &wait_entry);
+	finish_wait(&op->waitq, &wait_entry);
 	spin_unlock(&op->lock);
 
 	gossip_debug(GOSSIP_WAIT_DEBUG,

commit 575e946125f70c41c2042f10172842c5cab9a09a
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Dec 4 12:56:14 2015 -0500

    Orangefs: change pvfs2 filenames to orangefs
    
    Also changed references within source files that referred to
    header files whose names had changed.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index cfc8dc59c4eb..c731cbdd5fbd 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -13,8 +13,8 @@
  */
 
 #include "protocol.h"
-#include "pvfs2-kernel.h"
-#include "pvfs2-bufmap.h"
+#include "orangefs-kernel.h"
+#include "orangefs-bufmap.h"
 
 /*
  * What we do in this function is to walk the list of operations that are

commit 8bb8aefd5afb54a25a002feb4ec70011812d06a0
Author: Yi Liu <yi9@clemson.edu>
Date:   Tue Nov 24 15:12:14 2015 -0500

    OrangeFS: Change almost all instances of the string PVFS2 to OrangeFS.
    
    OrangeFS was formerly known as PVFS2 and retains the name in many places.
    
    I leave the device /dev/pvfs2-req since this affects userspace.
    
    I leave the filesystem type pvfs2 since this affects userspace. Further
    the OrangeFS sysint library reads fstab for an entry of type pvfs2
    independently of kernel mounts.
    
    I leave extended attribute keys user.pvfs2 and system.pvfs2 as the
    sysint library understands these.
    
    I leave references to userspace binaries still named pvfs2.
    
    I leave the filenames.
    
    Signed-off-by: Yi Liu <yi9@clemson.edu>
    [martin@omnibond.com: clairify above constraints and merge]
    Signed-off-by: Martin Brandenburg <martin@omnibond.com>
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index d7b0eba043ab..cfc8dc59c4eb 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -25,10 +25,10 @@
  */
 void purge_waiting_ops(void)
 {
-	struct pvfs2_kernel_op_s *op;
+	struct orangefs_kernel_op_s *op;
 
-	spin_lock(&pvfs2_request_list_lock);
-	list_for_each_entry(op, &pvfs2_request_list, list) {
+	spin_lock(&orangefs_request_list_lock);
+	list_for_each_entry(op, &orangefs_request_list, list) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "pvfs2-client-core: purging op tag %llu %s\n",
 			     llu(op->tag),
@@ -38,11 +38,11 @@ void purge_waiting_ops(void)
 		spin_unlock(&op->lock);
 		wake_up_interruptible(&op->waitq);
 	}
-	spin_unlock(&pvfs2_request_list_lock);
+	spin_unlock(&orangefs_request_list_lock);
 }
 
 /*
- * submits a PVFS2 operation and waits for it to complete
+ * submits a ORANGEFS operation and waits for it to complete
  *
  * Note op->downcall.status will contain the status of the operation (in
  * errno format), whether provided by pvfs2-client or a result of failure to
@@ -51,7 +51,7 @@ void purge_waiting_ops(void)
  *
  * Returns contents of op->downcall.status for convenience
  */
-int service_operation(struct pvfs2_kernel_op_s *op,
+int service_operation(struct orangefs_kernel_op_s *op,
 		      const char *op_name,
 		      int flags)
 {
@@ -70,30 +70,30 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 retry_servicing:
 	op->downcall.status = 0;
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "pvfs2: service_operation: %s %p\n",
+		     "orangefs: service_operation: %s %p\n",
 		     op_name,
 		     op);
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "pvfs2: operation posted by process: %s, pid: %i\n",
+		     "orangefs: operation posted by process: %s, pid: %i\n",
 		     current->comm,
 		     current->pid);
 
 	/* mask out signals if this operation is not to be interrupted */
-	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
 		block_signals(&orig_sigset);
 
-	if (!(flags & PVFS2_OP_NO_SEMAPHORE)) {
+	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE)) {
 		ret = mutex_lock_interruptible(&request_mutex);
 		/*
 		 * check to see if we were interrupted while waiting for
 		 * semaphore
 		 */
 		if (ret < 0) {
-			if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+			if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
 				set_signals(&orig_sigset);
 			op->downcall.status = ret;
 			gossip_debug(GOSSIP_WAIT_DEBUG,
-				     "pvfs2: service_operation interrupted.\n");
+				     "orangefs: service_operation interrupted.\n");
 			return ret;
 		}
 	}
@@ -116,7 +116,7 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 	}
 
 	/* queue up the operation */
-	if (flags & PVFS2_OP_PRIORITY) {
+	if (flags & ORANGEFS_OP_PRIORITY) {
 		add_priority_op_to_request_list(op);
 	} else {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
@@ -125,17 +125,17 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 		add_op_to_request_list(op);
 	}
 
-	if (!(flags & PVFS2_OP_NO_SEMAPHORE))
+	if (!(flags & ORANGEFS_OP_NO_SEMAPHORE))
 		mutex_unlock(&request_mutex);
 
 	/*
 	 * If we are asked to service an asynchronous operation from
 	 * VFS perspective, we are done.
 	 */
-	if (flags & PVFS2_OP_ASYNC)
+	if (flags & ORANGEFS_OP_ASYNC)
 		return 0;
 
-	if (flags & PVFS2_OP_CANCELLATION) {
+	if (flags & ORANGEFS_OP_CANCELLATION) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
 			     "%s:"
 			     "About to call wait_for_cancellation_downcall.\n",
@@ -148,25 +148,25 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 	if (ret < 0) {
 		/* failed to get matching downcall */
 		if (ret == -ETIMEDOUT) {
-			gossip_err("pvfs2: %s -- wait timed out; aborting attempt.\n",
+			gossip_err("orangefs: %s -- wait timed out; aborting attempt.\n",
 				   op_name);
 		}
 		op->downcall.status = ret;
 	} else {
 		/* got matching downcall; make sure status is in errno format */
 		op->downcall.status =
-		    pvfs2_normalize_to_errno(op->downcall.status);
+		    orangefs_normalize_to_errno(op->downcall.status);
 		ret = op->downcall.status;
 	}
 
-	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+	if (!(flags & ORANGEFS_OP_INTERRUPTIBLE))
 		set_signals(&orig_sigset);
 
 	BUG_ON(ret != op->downcall.status);
 	/* retry if operation has not been serviced and if requested */
 	if (!op_state_serviced(op) && op->downcall.status == -EAGAIN) {
 		gossip_debug(GOSSIP_WAIT_DEBUG,
-			     "pvfs2: tag %llu (%s)"
+			     "orangefs: tag %llu (%s)"
 			     " -- operation to be retried (%d attempt)\n",
 			     llu(op->tag),
 			     op_name,
@@ -204,17 +204,17 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 			 * memory system can be initialized.
 			 */
 			spin_lock_irqsave(&op->lock, irqflags);
-			add_wait_queue(&pvfs2_bufmap_init_waitq, &wait_entry);
+			add_wait_queue(&orangefs_bufmap_init_waitq, &wait_entry);
 			spin_unlock_irqrestore(&op->lock, irqflags);
 
 			set_current_state(TASK_INTERRUPTIBLE);
 
 			/*
-			 * Wait for pvfs_bufmap_initialize() to wake me up
+			 * Wait for orangefs_bufmap_initialize() to wake me up
 			 * within the allotted time.
 			 */
 			ret = schedule_timeout(MSECS_TO_JIFFIES
-				(1000 * PVFS2_BUFMAP_WAIT_TIMEOUT_SECS));
+				(1000 * ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS));
 
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "Value returned from schedule_timeout:"
@@ -225,14 +225,14 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 				     get_bufmap_init());
 
 			spin_lock_irqsave(&op->lock, irqflags);
-			remove_wait_queue(&pvfs2_bufmap_init_waitq,
+			remove_wait_queue(&orangefs_bufmap_init_waitq,
 					  &wait_entry);
 			spin_unlock_irqrestore(&op->lock, irqflags);
 
 			if (get_bufmap_init() == 0) {
 				gossip_err("%s:The shared memory system has not started in %d seconds after the client core restarted.  Aborting user's request(%s).\n",
 					   __func__,
-					   PVFS2_BUFMAP_WAIT_TIMEOUT_SECS,
+					   ORANGEFS_BUFMAP_WAIT_TIMEOUT_SECS,
 					   get_opname_string(op));
 				return -EIO;
 			}
@@ -246,14 +246,14 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 	}
 
 	gossip_debug(GOSSIP_WAIT_DEBUG,
-		     "pvfs2: service_operation %s returning: %d for %p.\n",
+		     "orangefs: service_operation %s returning: %d for %p.\n",
 		     op_name,
 		     ret,
 		     op);
 	return ret;
 }
 
-void pvfs2_clean_up_interrupted_operation(struct pvfs2_kernel_op_s *op)
+void orangefs_clean_up_interrupted_operation(struct orangefs_kernel_op_s *op)
 {
 	/*
 	 * handle interrupted cases depending on what state we were in when
@@ -339,7 +339,7 @@ void pvfs2_clean_up_interrupted_operation(struct pvfs2_kernel_op_s *op)
  * operation since client-core seems to be exiting too often
  * or if we were interrupted.
  */
-int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
+int wait_for_matching_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
 	DECLARE_WAITQUEUE(wait_entry, current);
@@ -386,7 +386,7 @@ int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
 						     op,
 						     op->attempts);
 					ret = -ETIMEDOUT;
-					pvfs2_clean_up_interrupted_operation
+					orangefs_clean_up_interrupted_operation
 					    (op);
 					break;
 				}
@@ -403,7 +403,7 @@ int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
 			 * core starts, and so on...
 			 */
 			if (op_state_purged(op)) {
-				ret = (op->attempts < PVFS2_PURGE_RETRY_COUNT) ?
+				ret = (op->attempts < ORANGEFS_PURGE_RETRY_COUNT) ?
 					 -EAGAIN :
 					 -EIO;
 				spin_unlock(&op->lock);
@@ -415,7 +415,7 @@ int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
 					     llu(op->tag),
 					     op,
 					     op->attempts);
-				pvfs2_clean_up_interrupted_operation(op);
+				orangefs_clean_up_interrupted_operation(op);
 				break;
 			}
 			spin_unlock(&op->lock);
@@ -429,7 +429,7 @@ int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
 			     __func__,
 			     llu(op->tag),
 			     op);
-		pvfs2_clean_up_interrupted_operation(op);
+		orangefs_clean_up_interrupted_operation(op);
 		ret = -EINTR;
 		break;
 	}
@@ -452,7 +452,7 @@ int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
  *      cancellation upcall anyway.  the only way to exit this is to either
  *      timeout or have the cancellation be serviced properly.
  */
-int wait_for_cancellation_downcall(struct pvfs2_kernel_op_s *op)
+int wait_for_cancellation_downcall(struct orangefs_kernel_op_s *op)
 {
 	int ret = -EINVAL;
 	DECLARE_WAITQUEUE(wait_entry, current);
@@ -482,7 +482,7 @@ int wait_for_cancellation_downcall(struct pvfs2_kernel_op_s *op)
 				     __func__,
 				     llu(op->tag),
 				     op);
-			pvfs2_clean_up_interrupted_operation(op);
+			orangefs_clean_up_interrupted_operation(op);
 			ret = -EINTR;
 			break;
 		}
@@ -502,7 +502,7 @@ int wait_for_cancellation_downcall(struct pvfs2_kernel_op_s *op)
 				     "%s:*** operation timed out: %p\n",
 				     __func__,
 				     op);
-			pvfs2_clean_up_interrupted_operation(op);
+			orangefs_clean_up_interrupted_operation(op);
 			ret = -ETIMEDOUT;
 			break;
 		}

commit 8c3905adea92c79e32b02120c724dfd4cf84dd85
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Tue Sep 29 12:07:46 2015 -0400

    Orangefs: update signal blocking code before Oleg sees it.
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index ad79e534dc8e..d7b0eba043ab 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -80,7 +80,7 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 
 	/* mask out signals if this operation is not to be interrupted */
 	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
-		mask_blocked_signals(&orig_sigset);
+		block_signals(&orig_sigset);
 
 	if (!(flags & PVFS2_OP_NO_SEMAPHORE)) {
 		ret = mutex_lock_interruptible(&request_mutex);
@@ -90,7 +90,7 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 		 */
 		if (ret < 0) {
 			if (!(flags & PVFS2_OP_INTERRUPTIBLE))
-				unmask_blocked_signals(&orig_sigset);
+				set_signals(&orig_sigset);
 			op->downcall.status = ret;
 			gossip_debug(GOSSIP_WAIT_DEBUG,
 				     "pvfs2: service_operation interrupted.\n");
@@ -160,7 +160,7 @@ int service_operation(struct pvfs2_kernel_op_s *op,
 	}
 
 	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
-		unmask_blocked_signals(&orig_sigset);
+		set_signals(&orig_sigset);
 
 	BUG_ON(ret != op->downcall.status);
 	/* retry if operation has not been serviced and if requested */

commit 84d02150dea7571dc32176e35d65eecde82631a9
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Tue Jul 28 13:27:51 2015 -0400

    Orangefs: sooth most sparse complaints
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
index 9b32286a7dc4..ad79e534dc8e 100644
--- a/fs/orangefs/waitqueue.c
+++ b/fs/orangefs/waitqueue.c
@@ -314,6 +314,13 @@ void pvfs2_clean_up_interrupted_operation(struct pvfs2_kernel_op_s *op)
 		spin_unlock(&op->lock);
 		gossip_err("interrupted operation is in a weird state 0x%x\n",
 			   op->op_state);
+	} else {
+		/*
+		 * It is not intended for execution to flow here,
+		 * but having this unlock here makes sparse happy.
+		 */
+		gossip_err("%s: can't get here.\n", __func__);
+		spin_unlock(&op->lock);
 	}
 }
 

commit 1182fca3bc00441d5b2dee2f0548a3b7f978f9e7
Author: Mike Marshall <hubcap@omnibond.com>
Date:   Fri Jul 17 10:38:15 2015 -0400

    Orangefs: kernel client part 5
    
    Signed-off-by: Mike Marshall <hubcap@omnibond.com>

diff --git a/fs/orangefs/waitqueue.c b/fs/orangefs/waitqueue.c
new file mode 100644
index 000000000000..9b32286a7dc4
--- /dev/null
+++ b/fs/orangefs/waitqueue.c
@@ -0,0 +1,522 @@
+/*
+ * (C) 2001 Clemson University and The University of Chicago
+ * (C) 2011 Omnibond Systems
+ *
+ * Changes by Acxiom Corporation to implement generic service_operation()
+ * function, Copyright Acxiom Corporation, 2005.
+ *
+ * See COPYING in top-level directory.
+ */
+
+/*
+ *  In-kernel waitqueue operations.
+ */
+
+#include "protocol.h"
+#include "pvfs2-kernel.h"
+#include "pvfs2-bufmap.h"
+
+/*
+ * What we do in this function is to walk the list of operations that are
+ * present in the request queue and mark them as purged.
+ * NOTE: This is called from the device close after client-core has
+ * guaranteed that no new operations could appear on the list since the
+ * client-core is anyway going to exit.
+ */
+void purge_waiting_ops(void)
+{
+	struct pvfs2_kernel_op_s *op;
+
+	spin_lock(&pvfs2_request_list_lock);
+	list_for_each_entry(op, &pvfs2_request_list, list) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "pvfs2-client-core: purging op tag %llu %s\n",
+			     llu(op->tag),
+			     get_opname_string(op));
+		spin_lock(&op->lock);
+		set_op_state_purged(op);
+		spin_unlock(&op->lock);
+		wake_up_interruptible(&op->waitq);
+	}
+	spin_unlock(&pvfs2_request_list_lock);
+}
+
+/*
+ * submits a PVFS2 operation and waits for it to complete
+ *
+ * Note op->downcall.status will contain the status of the operation (in
+ * errno format), whether provided by pvfs2-client or a result of failure to
+ * service the operation.  If the caller wishes to distinguish, then
+ * op->state can be checked to see if it was serviced or not.
+ *
+ * Returns contents of op->downcall.status for convenience
+ */
+int service_operation(struct pvfs2_kernel_op_s *op,
+		      const char *op_name,
+		      int flags)
+{
+	/* flags to modify behavior */
+	sigset_t orig_sigset;
+	int ret = 0;
+
+	/* irqflags and wait_entry are only used IF the client-core aborts */
+	unsigned long irqflags;
+
+	DECLARE_WAITQUEUE(wait_entry, current);
+
+	op->upcall.tgid = current->tgid;
+	op->upcall.pid = current->pid;
+
+retry_servicing:
+	op->downcall.status = 0;
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "pvfs2: service_operation: %s %p\n",
+		     op_name,
+		     op);
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "pvfs2: operation posted by process: %s, pid: %i\n",
+		     current->comm,
+		     current->pid);
+
+	/* mask out signals if this operation is not to be interrupted */
+	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+		mask_blocked_signals(&orig_sigset);
+
+	if (!(flags & PVFS2_OP_NO_SEMAPHORE)) {
+		ret = mutex_lock_interruptible(&request_mutex);
+		/*
+		 * check to see if we were interrupted while waiting for
+		 * semaphore
+		 */
+		if (ret < 0) {
+			if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+				unmask_blocked_signals(&orig_sigset);
+			op->downcall.status = ret;
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "pvfs2: service_operation interrupted.\n");
+			return ret;
+		}
+	}
+
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "%s:About to call is_daemon_in_service().\n",
+		     __func__);
+
+	if (is_daemon_in_service() < 0) {
+		/*
+		 * By incrementing the per-operation attempt counter, we
+		 * directly go into the timeout logic while waiting for
+		 * the matching downcall to be read
+		 */
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:client core is NOT in service(%d).\n",
+			     __func__,
+			     is_daemon_in_service());
+		op->attempts++;
+	}
+
+	/* queue up the operation */
+	if (flags & PVFS2_OP_PRIORITY) {
+		add_priority_op_to_request_list(op);
+	} else {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:About to call add_op_to_request_list().\n",
+			     __func__);
+		add_op_to_request_list(op);
+	}
+
+	if (!(flags & PVFS2_OP_NO_SEMAPHORE))
+		mutex_unlock(&request_mutex);
+
+	/*
+	 * If we are asked to service an asynchronous operation from
+	 * VFS perspective, we are done.
+	 */
+	if (flags & PVFS2_OP_ASYNC)
+		return 0;
+
+	if (flags & PVFS2_OP_CANCELLATION) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:"
+			     "About to call wait_for_cancellation_downcall.\n",
+			     __func__);
+		ret = wait_for_cancellation_downcall(op);
+	} else {
+		ret = wait_for_matching_downcall(op);
+	}
+
+	if (ret < 0) {
+		/* failed to get matching downcall */
+		if (ret == -ETIMEDOUT) {
+			gossip_err("pvfs2: %s -- wait timed out; aborting attempt.\n",
+				   op_name);
+		}
+		op->downcall.status = ret;
+	} else {
+		/* got matching downcall; make sure status is in errno format */
+		op->downcall.status =
+		    pvfs2_normalize_to_errno(op->downcall.status);
+		ret = op->downcall.status;
+	}
+
+	if (!(flags & PVFS2_OP_INTERRUPTIBLE))
+		unmask_blocked_signals(&orig_sigset);
+
+	BUG_ON(ret != op->downcall.status);
+	/* retry if operation has not been serviced and if requested */
+	if (!op_state_serviced(op) && op->downcall.status == -EAGAIN) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "pvfs2: tag %llu (%s)"
+			     " -- operation to be retried (%d attempt)\n",
+			     llu(op->tag),
+			     op_name,
+			     op->attempts + 1);
+
+		if (!op->uses_shared_memory)
+			/*
+			 * this operation doesn't use the shared memory
+			 * system
+			 */
+			goto retry_servicing;
+
+		/* op uses shared memory */
+		if (get_bufmap_init() == 0) {
+			/*
+			 * This operation uses the shared memory system AND
+			 * the system is not yet ready. This situation occurs
+			 * when the client-core is restarted AND there were
+			 * operations waiting to be processed or were already
+			 * in process.
+			 */
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "uses_shared_memory is true.\n");
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "Client core in-service status(%d).\n",
+				     is_daemon_in_service());
+			gossip_debug(GOSSIP_WAIT_DEBUG, "bufmap_init:%d.\n",
+				     get_bufmap_init());
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "operation's status is 0x%0x.\n",
+				     op->op_state);
+
+			/*
+			 * let process sleep for a few seconds so shared
+			 * memory system can be initialized.
+			 */
+			spin_lock_irqsave(&op->lock, irqflags);
+			add_wait_queue(&pvfs2_bufmap_init_waitq, &wait_entry);
+			spin_unlock_irqrestore(&op->lock, irqflags);
+
+			set_current_state(TASK_INTERRUPTIBLE);
+
+			/*
+			 * Wait for pvfs_bufmap_initialize() to wake me up
+			 * within the allotted time.
+			 */
+			ret = schedule_timeout(MSECS_TO_JIFFIES
+				(1000 * PVFS2_BUFMAP_WAIT_TIMEOUT_SECS));
+
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "Value returned from schedule_timeout:"
+				     "%d.\n",
+				     ret);
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "Is shared memory available? (%d).\n",
+				     get_bufmap_init());
+
+			spin_lock_irqsave(&op->lock, irqflags);
+			remove_wait_queue(&pvfs2_bufmap_init_waitq,
+					  &wait_entry);
+			spin_unlock_irqrestore(&op->lock, irqflags);
+
+			if (get_bufmap_init() == 0) {
+				gossip_err("%s:The shared memory system has not started in %d seconds after the client core restarted.  Aborting user's request(%s).\n",
+					   __func__,
+					   PVFS2_BUFMAP_WAIT_TIMEOUT_SECS,
+					   get_opname_string(op));
+				return -EIO;
+			}
+
+			/*
+			 * Return to the calling function and re-populate a
+			 * shared memory buffer.
+			 */
+			return -EAGAIN;
+		}
+	}
+
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "pvfs2: service_operation %s returning: %d for %p.\n",
+		     op_name,
+		     ret,
+		     op);
+	return ret;
+}
+
+void pvfs2_clean_up_interrupted_operation(struct pvfs2_kernel_op_s *op)
+{
+	/*
+	 * handle interrupted cases depending on what state we were in when
+	 * the interruption is detected.  there is a coarse grained lock
+	 * across the operation.
+	 *
+	 * NOTE: be sure not to reverse lock ordering by locking an op lock
+	 * while holding the request_list lock.  Here, we first lock the op
+	 * and then lock the appropriate list.
+	 */
+	if (!op) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			    "%s: op is null, ignoring\n",
+			     __func__);
+		return;
+	}
+
+	/*
+	 * one more sanity check, make sure it's in one of the possible states
+	 * or don't try to cancel it
+	 */
+	if (!(op_state_waiting(op) ||
+	      op_state_in_progress(op) ||
+	      op_state_serviced(op) ||
+	      op_state_purged(op))) {
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s: op %p not in a valid state (%0x), "
+			     "ignoring\n",
+			     __func__,
+			     op,
+			     op->op_state);
+		return;
+	}
+
+	spin_lock(&op->lock);
+
+	if (op_state_waiting(op)) {
+		/*
+		 * upcall hasn't been read; remove op from upcall request
+		 * list.
+		 */
+		spin_unlock(&op->lock);
+		remove_op_from_request_list(op);
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "Interrupted: Removed op %p from request_list\n",
+			     op);
+	} else if (op_state_in_progress(op)) {
+		/* op must be removed from the in progress htable */
+		spin_unlock(&op->lock);
+		spin_lock(&htable_ops_in_progress_lock);
+		list_del(&op->list);
+		spin_unlock(&htable_ops_in_progress_lock);
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "Interrupted: Removed op %p"
+			     " from htable_ops_in_progress\n",
+			     op);
+	} else if (!op_state_serviced(op)) {
+		spin_unlock(&op->lock);
+		gossip_err("interrupted operation is in a weird state 0x%x\n",
+			   op->op_state);
+	}
+}
+
+/*
+ * sleeps on waitqueue waiting for matching downcall.
+ * if client-core finishes servicing, then we are good to go.
+ * else if client-core exits, we get woken up here, and retry with a timeout
+ *
+ * Post when this call returns to the caller, the specified op will no
+ * longer be on any list or htable.
+ *
+ * Returns 0 on success and -errno on failure
+ * Errors are:
+ * EAGAIN in case we want the caller to requeue and try again..
+ * EINTR/EIO/ETIMEDOUT indicating we are done trying to service this
+ * operation since client-core seems to be exiting too often
+ * or if we were interrupted.
+ */
+int wait_for_matching_downcall(struct pvfs2_kernel_op_s *op)
+{
+	int ret = -EINVAL;
+	DECLARE_WAITQUEUE(wait_entry, current);
+
+	spin_lock(&op->lock);
+	add_wait_queue(&op->waitq, &wait_entry);
+	spin_unlock(&op->lock);
+
+	while (1) {
+		set_current_state(TASK_INTERRUPTIBLE);
+
+		spin_lock(&op->lock);
+		if (op_state_serviced(op)) {
+			spin_unlock(&op->lock);
+			ret = 0;
+			break;
+		}
+		spin_unlock(&op->lock);
+
+		if (!signal_pending(current)) {
+			/*
+			 * if this was our first attempt and client-core
+			 * has not purged our operation, we are happy to
+			 * simply wait
+			 */
+			spin_lock(&op->lock);
+			if (op->attempts == 0 && !op_state_purged(op)) {
+				spin_unlock(&op->lock);
+				schedule();
+			} else {
+				spin_unlock(&op->lock);
+				/*
+				 * subsequent attempts, we retry exactly once
+				 * with timeouts
+				 */
+				if (!schedule_timeout(MSECS_TO_JIFFIES
+				      (1000 * op_timeout_secs))) {
+					gossip_debug(GOSSIP_WAIT_DEBUG,
+						     "*** %s:"
+						     " operation timed out (tag"
+						     " %llu, %p, att %d)\n",
+						     __func__,
+						     llu(op->tag),
+						     op,
+						     op->attempts);
+					ret = -ETIMEDOUT;
+					pvfs2_clean_up_interrupted_operation
+					    (op);
+					break;
+				}
+			}
+			spin_lock(&op->lock);
+			op->attempts++;
+			/*
+			 * if the operation was purged in the meantime, it
+			 * is better to requeue it afresh but ensure that
+			 * we have not been purged repeatedly. This could
+			 * happen if client-core crashes when an op
+			 * is being serviced, so we requeue the op, client
+			 * core crashes again so we requeue the op, client
+			 * core starts, and so on...
+			 */
+			if (op_state_purged(op)) {
+				ret = (op->attempts < PVFS2_PURGE_RETRY_COUNT) ?
+					 -EAGAIN :
+					 -EIO;
+				spin_unlock(&op->lock);
+				gossip_debug(GOSSIP_WAIT_DEBUG,
+					     "*** %s:"
+					     " operation purged (tag "
+					     "%llu, %p, att %d)\n",
+					     __func__,
+					     llu(op->tag),
+					     op,
+					     op->attempts);
+				pvfs2_clean_up_interrupted_operation(op);
+				break;
+			}
+			spin_unlock(&op->lock);
+			continue;
+		}
+
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "*** %s:"
+			     " operation interrupted by a signal (tag "
+			     "%llu, op %p)\n",
+			     __func__,
+			     llu(op->tag),
+			     op);
+		pvfs2_clean_up_interrupted_operation(op);
+		ret = -EINTR;
+		break;
+	}
+
+	set_current_state(TASK_RUNNING);
+
+	spin_lock(&op->lock);
+	remove_wait_queue(&op->waitq, &wait_entry);
+	spin_unlock(&op->lock);
+
+	return ret;
+}
+
+/*
+ * similar to wait_for_matching_downcall(), but used in the special case
+ * of I/O cancellations.
+ *
+ * Note we need a special wait function because if this is called we already
+ *      know that a signal is pending in current and need to service the
+ *      cancellation upcall anyway.  the only way to exit this is to either
+ *      timeout or have the cancellation be serviced properly.
+ */
+int wait_for_cancellation_downcall(struct pvfs2_kernel_op_s *op)
+{
+	int ret = -EINVAL;
+	DECLARE_WAITQUEUE(wait_entry, current);
+
+	spin_lock(&op->lock);
+	add_wait_queue(&op->waitq, &wait_entry);
+	spin_unlock(&op->lock);
+
+	while (1) {
+		set_current_state(TASK_INTERRUPTIBLE);
+
+		spin_lock(&op->lock);
+		if (op_state_serviced(op)) {
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "%s:op-state is SERVICED.\n",
+				     __func__);
+			spin_unlock(&op->lock);
+			ret = 0;
+			break;
+		}
+		spin_unlock(&op->lock);
+
+		if (signal_pending(current)) {
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "%s:operation interrupted by a signal (tag"
+				     " %llu, op %p)\n",
+				     __func__,
+				     llu(op->tag),
+				     op);
+			pvfs2_clean_up_interrupted_operation(op);
+			ret = -EINTR;
+			break;
+		}
+
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:About to call schedule_timeout.\n",
+			     __func__);
+		ret =
+		    schedule_timeout(MSECS_TO_JIFFIES(1000 * op_timeout_secs));
+
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:Value returned from schedule_timeout(%d).\n",
+			     __func__,
+			     ret);
+		if (!ret) {
+			gossip_debug(GOSSIP_WAIT_DEBUG,
+				     "%s:*** operation timed out: %p\n",
+				     __func__,
+				     op);
+			pvfs2_clean_up_interrupted_operation(op);
+			ret = -ETIMEDOUT;
+			break;
+		}
+
+		gossip_debug(GOSSIP_WAIT_DEBUG,
+			     "%s:Breaking out of loop, regardless of value returned by schedule_timeout.\n",
+			     __func__);
+		ret = -ETIMEDOUT;
+		break;
+	}
+
+	set_current_state(TASK_RUNNING);
+
+	spin_lock(&op->lock);
+	remove_wait_queue(&op->waitq, &wait_entry);
+	spin_unlock(&op->lock);
+
+	gossip_debug(GOSSIP_WAIT_DEBUG,
+		     "%s:returning ret(%d)\n",
+		     __func__,
+		     ret);
+
+	return ret;
+}
