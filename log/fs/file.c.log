commit 4e89b7210403fa4a8acafe7c602b6212b7af6c3b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue May 19 17:48:52 2020 -0400

    fix multiplication overflow in copy_fdtable()
    
    cpy and set really should be size_t; we won't get an overflow on that,
    since sysctl_nr_open can't be set above ~(size_t)0 / sizeof(void *),
    so nr that would've managed to overflow size_t on that multiplication
    won't get anywhere near copy_fdtable() - we'll fail with EMFILE
    before that.
    
    Cc: stable@kernel.org # v2.6.25+
    Fixes: 9cfe015aa424 (get rid of NR_OPEN and introduce a sysctl_nr_open)
    Reported-by: Thiago Macieira <thiago.macieira@intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index c8a4e4c86e55..abb8b7081d7a 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -70,7 +70,7 @@ static void copy_fd_bitmaps(struct fdtable *nfdt, struct fdtable *ofdt,
  */
 static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 {
-	unsigned int cpy, set;
+	size_t cpy, set;
 
 	BUG_ON(nfdt->max_fds < ofdt->max_fds);
 

commit 4022e7af86be2dd62975dedb6b7ea551d108695e
Author: Jens Axboe <axboe@kernel.dk>
Date:   Thu Mar 19 19:23:18 2020 -0600

    io_uring: make sure openat/openat2 honor rlimit nofile
    
    Dmitry reports that a test case shows that io_uring isn't honoring a
    modified rlimit nofile setting. get_unused_fd_flags() checks the task
    signal->rlimi[] for the limits. As this isn't easily inheritable,
    provide a __get_unused_fd_flags() that takes the value instead. Then we
    can grab it when the request is prepared (from the original task), and
    pass that in when we do the async part part of the open.
    
    Reported-by: Dmitry Kadashev <dkadashev@gmail.com>
    Tested-by: Dmitry Kadashev <dkadashev@gmail.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/file.c b/fs/file.c
index a364e1a9b7e8..c8a4e4c86e55 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -540,9 +540,14 @@ static int alloc_fd(unsigned start, unsigned flags)
 	return __alloc_fd(current->files, start, rlimit(RLIMIT_NOFILE), flags);
 }
 
+int __get_unused_fd_flags(unsigned flags, unsigned long nofile)
+{
+	return __alloc_fd(current->files, 0, nofile, flags);
+}
+
 int get_unused_fd_flags(unsigned flags)
 {
-	return __alloc_fd(current->files, 0, rlimit(RLIMIT_NOFILE), flags);
+	return __get_unused_fd_flags(flags, rlimit(RLIMIT_NOFILE));
 }
 EXPORT_SYMBOL(get_unused_fd_flags);
 

commit 83fa805bcbfc53ae82eedd65132794ae324798e5
Merge: 896f8d23d0cb 8d19f1c8e193
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 29 19:38:34 2020 -0800

    Merge tag 'threads-v5.6' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull thread management updates from Christian Brauner:
     "Sargun Dhillon over the last cycle has worked on the pidfd_getfd()
      syscall.
    
      This syscall allows for the retrieval of file descriptors of a process
      based on its pidfd. A task needs to have ptrace_may_access()
      permissions with PTRACE_MODE_ATTACH_REALCREDS (suggested by Oleg and
      Andy) on the target.
    
      One of the main use-cases is in combination with seccomp's user
      notification feature. As a reminder, seccomp's user notification
      feature was made available in v5.0. It allows a task to retrieve a
      file descriptor for its seccomp filter. The file descriptor is usually
      handed of to a more privileged supervising process. The supervisor can
      then listen for syscall events caught by the seccomp filter of the
      supervisee and perform actions in lieu of the supervisee, usually
      emulating syscalls. pidfd_getfd() is needed to expand its uses.
    
      There are currently two major users that wait on pidfd_getfd() and one
      future user:
    
       - Netflix, Sargun said, is working on a service mesh where users
         should be able to connect to a dns-based VIP. When a user connects
         to e.g. 1.2.3.4:80 that runs e.g. service "foo" they will be
         redirected to an envoy process. This service mesh uses seccomp user
         notifications and pidfd to intercept all connect calls and instead
         of connecting them to 1.2.3.4:80 connects them to e.g.
         127.0.0.1:8080.
    
       - LXD uses the seccomp notifier heavily to intercept and emulate
         mknod() and mount() syscalls for unprivileged containers/processes.
         With pidfd_getfd() more uses-cases e.g. bridging socket connections
         will be possible.
    
       - The patchset has also seen some interest from the browser corner.
         Right now, Firefox is using a SECCOMP_RET_TRAP sandbox managed by a
         broker process. In the future glibc will start blocking all signals
         during dlopen() rendering this type of sandbox impossible. Hence,
         in the future Firefox will switch to a seccomp-user-nofication
         based sandbox which also makes use of file descriptor retrieval.
         The thread for this can be found at
         https://sourceware.org/ml/libc-alpha/2019-12/msg00079.html
    
      With pidfd_getfd() it is e.g. possible to bridge socket connections
      for the supervisee (binding to a privileged port) and taking actions
      on file descriptors on behalf of the supervisee in general.
    
      Sargun's first version was using an ioctl on pidfds but various people
      pushed for it to be a proper syscall which he duely implemented as
      well over various review cycles. Selftests are of course included.
      I've also added instructions how to deal with merge conflicts below.
    
      There's also a small fix coming from the kernel mentee project to
      correctly annotate struct sighand_struct with __rcu to fix various
      sparse warnings. We've received a few more such fixes and even though
      they are mostly trivial I've decided to postpone them until after -rc1
      since they came in rather late and I don't want to risk introducing
      build warnings.
    
      Finally, there's a new prctl() command PR_{G,S}ET_IO_FLUSHER which is
      needed to avoid allocation recursions triggerable by storage drivers
      that have userspace parts that run in the IO path (e.g. dm-multipath,
      iscsi, etc). These allocation recursions deadlock the device.
    
      The new prctl() allows such privileged userspace components to avoid
      allocation recursions by setting the PF_MEMALLOC_NOIO and
      PF_LESS_THROTTLE flags. The patch carries the necessary acks from the
      relevant maintainers and is routed here as part of prctl()
      thread-management."
    
    * tag 'threads-v5.6' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      prctl: PR_{G,S}ET_IO_FLUSHER to support controlling memory reclaim
      sched.h: Annotate sighand_struct with __rcu
      test: Add test for pidfd getfd
      arch: wire up pidfd_getfd syscall
      pid: Implement pidfd_getfd syscall
      vfs, fdtable: Add fget_task helper

commit 6e802a4ba056a6f2f51ac9d54eead3ed6f9829a2
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Dec 11 14:10:35 2019 -0700

    fs: move filp_close() outside of __close_fd_get_file()
    
    Just one caller of this, and just use filp_close() there manually.
    This is important to allow async close/removal of the fd.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/file.c b/fs/file.c
index 3da91a112bab..fb7081bfac2b 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -642,7 +642,9 @@ int __close_fd(struct files_struct *files, unsigned fd)
 EXPORT_SYMBOL(__close_fd); /* for ksys_close() */
 
 /*
- * variant of __close_fd that gets a ref on the file for later fput
+ * variant of __close_fd that gets a ref on the file for later fput.
+ * The caller must ensure that filp_close() called on the file, and then
+ * an fput().
  */
 int __close_fd_get_file(unsigned int fd, struct file **res)
 {
@@ -662,7 +664,7 @@ int __close_fd_get_file(unsigned int fd, struct file **res)
 	spin_unlock(&files->file_lock);
 	get_file(file);
 	*res = file;
-	return filp_close(file, files);
+	return 0;
 
 out_unlock:
 	spin_unlock(&files->file_lock);

commit 5e876fb43dbf24c941a323139752bcb2f0a80da0
Author: Sargun Dhillon <sargun@sargun.me>
Date:   Tue Jan 7 09:59:24 2020 -0800

    vfs, fdtable: Add fget_task helper
    
    This introduces a function which can be used to fetch a file, given an
    arbitrary task. As long as the user holds a reference (refcnt) to the
    task_struct it is safe to call, and will either return NULL on failure,
    or a pointer to the file, with a refcnt.
    
    This patch is based on Oleg Nesterov's (cf. [1]) patch from September
    2018.
    
    [1]: Link: https://lore.kernel.org/r/20180915160423.GA31461@redhat.com
    
    Signed-off-by: Sargun Dhillon <sargun@sargun.me>
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Link: https://lore.kernel.org/r/20200107175927.4558-2-sargun@sargun.me
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/fs/file.c b/fs/file.c
index 3da91a112bab..d044a32c030e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -706,9 +706,9 @@ void do_close_on_exec(struct files_struct *files)
 	spin_unlock(&files->file_lock);
 }
 
-static struct file *__fget(unsigned int fd, fmode_t mask, unsigned int refs)
+static struct file *__fget_files(struct files_struct *files, unsigned int fd,
+				 fmode_t mask, unsigned int refs)
 {
-	struct files_struct *files = current->files;
 	struct file *file;
 
 	rcu_read_lock();
@@ -729,6 +729,12 @@ static struct file *__fget(unsigned int fd, fmode_t mask, unsigned int refs)
 	return file;
 }
 
+static inline struct file *__fget(unsigned int fd, fmode_t mask,
+				  unsigned int refs)
+{
+	return __fget_files(current->files, fd, mask, refs);
+}
+
 struct file *fget_many(unsigned int fd, unsigned int refs)
 {
 	return __fget(fd, FMODE_PATH, refs);
@@ -746,6 +752,18 @@ struct file *fget_raw(unsigned int fd)
 }
 EXPORT_SYMBOL(fget_raw);
 
+struct file *fget_task(struct task_struct *task, unsigned int fd)
+{
+	struct file *file = NULL;
+
+	task_lock(task);
+	if (task->files)
+		file = __fget_files(task->files, fd, 0, 1);
+	task_unlock(task);
+
+	return file;
+}
+
 /*
  * Lightweight file lookup - no refcnt increment if fd table isn't shared.
  *

commit 74f1a299107b9e1a563831a4ba85f769ab577164
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Wed Jan 1 20:05:03 2020 +0100

    Revert "fs: remove ksys_dup()"
    
    This reverts commit 8243186f0cc7 ("fs: remove ksys_dup()") and the
    subsequent fix for it in commit 2d3145f8d280 ("early init: fix error
    handling when opening /dev/console").
    
    Trying to use filp_open() and f_dupfd() instead of pseudo-syscalls
    caused more trouble than what is worth it: it requires accessing vfs
    internals and it turns out there were other bugs in it too.
    
    In particular, the file reference counting was wrong - because unlike
    the original "open+2*dup" sequence it used "filp_open+3*f_dupfd" and
    thus had an extra leaked file reference.
    
    That in turn then caused odd problems with Androidx86 long after boot
    becaue of how the extra reference to the console kept the session active
    even after all file descriptors had been closed.
    
    Reported-by: youling 257 <youling257@gmail.com>
    Cc: Arvind Sankar <nivedita@alum.mit.edu>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 2f4fcf985079..3da91a112bab 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -960,7 +960,7 @@ SYSCALL_DEFINE2(dup2, unsigned int, oldfd, unsigned int, newfd)
 	return ksys_dup3(oldfd, newfd, 0);
 }
 
-SYSCALL_DEFINE1(dup, unsigned int, fildes)
+int ksys_dup(unsigned int fildes)
 {
 	int ret = -EBADF;
 	struct file *file = fget_raw(fildes);
@@ -975,6 +975,11 @@ SYSCALL_DEFINE1(dup, unsigned int, fildes)
 	return ret;
 }
 
+SYSCALL_DEFINE1(dup, unsigned int, fildes)
+{
+	return ksys_dup(fildes);
+}
+
 int f_dupfd(unsigned int from, struct file *file, unsigned flags)
 {
 	int err;

commit 8243186f0cc7c57cf9d6a110cd7315c44e3e0be8
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Tue Oct 23 16:24:09 2018 +0200

    fs: remove ksys_dup()
    
    ksys_dup() is used only at one place in the kernel, namely to duplicate
    fd 0 of /dev/console to stdout and stderr. The same functionality can be
    achieved by using functions already available within the kernel namespace.
    
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/fs/file.c b/fs/file.c
index 3da91a112bab..2f4fcf985079 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -960,7 +960,7 @@ SYSCALL_DEFINE2(dup2, unsigned int, oldfd, unsigned int, newfd)
 	return ksys_dup3(oldfd, newfd, 0);
 }
 
-int ksys_dup(unsigned int fildes)
+SYSCALL_DEFINE1(dup, unsigned int, fildes)
 {
 	int ret = -EBADF;
 	struct file *file = fget_raw(fildes);
@@ -975,11 +975,6 @@ int ksys_dup(unsigned int fildes)
 	return ret;
 }
 
-SYSCALL_DEFINE1(dup, unsigned int, fildes)
-{
-	return ksys_dup(fildes);
-}
-
 int f_dupfd(unsigned int from, struct file *file, unsigned flags)
 {
 	int err;

commit 2be7d348fe924f0c5583c6a805bd42cecda93104
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 26 11:34:06 2019 -0800

    Revert "vfs: properly and reliably lock f_pos in fdget_pos()"
    
    This reverts commit 0be0ee71816b2b6725e2b4f32ad6726c9d729777.
    
    I was hoping it would be benign to switch over entirely to FMODE_STREAM,
    and we'd have just a couple of small fixups we'd need, but it looks like
    we're not quite there yet.
    
    While it worked fine on both my desktop and laptop, they are fairly
    similar in other respects, and run mostly the same loads.  Kenneth
    Crudup reports that it seems to break both his vmware installation and
    the KDE upower service.  In both cases apparently leading to timeouts
    due to waitinmg for the f_pos lock.
    
    There are a number of character devices in particular that definitely
    want stream-like behavior, but that currently don't get marked as
    streams, and as a result get the exclusion between concurrent
    read()/write() on the same file descriptor.  Which doesn't work well for
    them.
    
    The most obvious example if this is /dev/console and /dev/tty, which use
    console_fops and tty_fops respectively (and ptmx_fops for the pty master
    side).  It may be that it's just this that causes problems, but we
    clearly weren't ready yet.
    
    Because there's a number of other likely common cases that don't have
    llseek implementations and would seem to act as stream devices:
    
      /dev/fuse             (fuse_dev_operations)
      /dev/mcelog           (mce_chrdev_ops)
      /dev/mei0             (mei_fops)
      /dev/net/tun          (tun_fops)
      /dev/nvme0            (nvme_dev_fops)
      /dev/tpm0             (tpm_fops)
      /proc/self/ns/mnt     (ns_file_operations)
      /dev/snd/pcm*         (snd_pcm_f_ops[])
    
    and while some of these could be trivially automatically detected by the
    vfs layer when the character device is opened by just noticing that they
    have no read or write operations either, it often isn't that obvious.
    
    Some character devices most definitely do use the file position, even if
    they don't allow seeking: the firmware update code, for example, uses
    simple_read_from_buffer() that does use f_pos, but doesn't allow seeking
    back and forth.
    
    We'll revisit this when there's a better way to detect the problem and
    fix it (possibly with a coccinelle script to do more of the FMODE_STREAM
    annotations).
    
    Reported-by: Kenneth R. Crudup <kenny@panix.com>
    Cc: Kirill Smelkov <kirr@nexedi.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index b241ea7f1aa4..3da91a112bab 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -795,7 +795,7 @@ unsigned long __fdget_pos(unsigned int fd)
 	unsigned long v = __fdget(fd);
 	struct file *file = (struct file *)(v & ~3);
 
-	if (file && !(file->f_mode & FMODE_STREAM)) {
+	if (file && (file->f_mode & FMODE_ATOMIC_POS)) {
 		if (file_count(file) > 1) {
 			v |= FDPUT_POS_UNLOCK;
 			mutex_lock(&file->f_pos_lock);

commit 0be0ee71816b2b6725e2b4f32ad6726c9d729777
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 11 15:51:03 2019 -0800

    vfs: properly and reliably lock f_pos in fdget_pos()
    
    fdget_pos() is used by file operations that will read and update f_pos:
    things like "read()", "write()" and "lseek()" (but not, for example,
    "pread()/pwrite" that get their file positions elsewhere).
    
    However, it had two separate escape clauses for this, because not
    everybody wants or needs serialization of the file position.
    
    The first and most obvious case is the "file descriptor doesn't have a
    position at all", ie a stream-like file.  Except we didn't actually use
    FMODE_STREAM, but instead used FMODE_ATOMIC_POS.  The reason for that
    was that FMODE_STREAM didn't exist back in the days, but also that we
    didn't want to mark all the special cases, so we only marked the ones
    that _required_ position atomicity according to POSIX - regular files
    and directories.
    
    The case one was intentionally lazy, but now that we _do_ have
    FMODE_STREAM we could and should just use it.  With the change to use
    FMODE_STREAM, there are no remaining uses for FMODE_ATOMIC_POS, and all
    the code to set it is deleted.
    
    Any cases where we don't want the serialization because the driver (or
    subsystem) doesn't use the file position should just be updated to do
    "stream_open()".  We've done that for all the obvious and common
    situations, we may need a few more.  Quoting Kirill Smelkov in the
    original FMODE_STREAM thread (see link below for full email):
    
     "And I appreciate if people could help at least somehow with "getting
      rid of mixed case entirely" (i.e. always lock f_pos_lock on
      !FMODE_STREAM), because this transition starts to diverge from my
      particular use-case too far. To me it makes sense to do that
      transition as follows:
    
       - convert nonseekable_open -> stream_open via stream_open.cocci;
       - audit other nonseekable_open calls and convert left users that
         truly don't depend on position to stream_open;
       - extend stream_open.cocci to analyze alloc_file_pseudo as well (this
         will cover pipes and sockets), or maybe convert pipes and sockets
         to FMODE_STREAM manually;
       - extend stream_open.cocci to analyze file_operations that use
         no_llseek or noop_llseek, but do not use nonseekable_open or
         alloc_file_pseudo. This might find files that have stream semantic
         but are opened differently;
       - extend stream_open.cocci to analyze file_operations whose
         .read/.write do not use ppos at all (independently of how file was
         opened);
       - ...
       - after that remove FMODE_ATOMIC_POS and always take f_pos_lock if
         !FMODE_STREAM;
       - gather bug reports for deadlocked read/write and convert missed
         cases to FMODE_STREAM, probably extending stream_open.cocci along
         the road to catch similar cases
    
      i.e. always take f_pos_lock unless a file is explicitly marked as
      being stream, and try to find and cover all files that are streams"
    
    We have not done the "extend stream_open.cocci to analyze
    alloc_file_pseudo" as well, but the previous commit did manually handle
    the case of pipes and sockets.
    
    The other case where we can avoid locking f_pos is the "this file
    descriptor only has a single user and it is us, and thus there is no
    need to lock it".
    
    The second test was correct, although a bit subtle and worth just
    re-iterating here.  There are two kinds of other sources of references
    to the same file descriptor: file descriptors that have been explicitly
    shared across fork() or with dup(), and file tables having elevated
    reference counts due to threading (or explicit file sharing with
    clone()).
    
    The first case would have incremented the file count explicitly, and in
    the second case the previous __fdget() would have incremented it for us
    and set the FDPUT_FPUT flag.
    
    But in both cases the file count would be greater than one, so the
    "file_count(file) > 1" test catches both situations.  Also note that if
    file_count is 1, that also means that no other thread can have access to
    the file table, so there also cannot be races with concurrent calls to
    dup()/fork()/clone() that would increment the file count any other way.
    
    Link: https://lore.kernel.org/linux-fsdevel/20190413184404.GA13490@deco.navytux.spb.ru
    Cc: Kirill Smelkov <kirr@nexedi.com>
    Cc: Eic Dumazet <edumazet@google.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: Marco Elver <elver@google.com>
    Cc: Andrea Parri <parri.andrea@gmail.com>
    Cc: Paul McKenney <paulmck@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 3da91a112bab..b241ea7f1aa4 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -795,7 +795,7 @@ unsigned long __fdget_pos(unsigned int fd)
 	unsigned long v = __fdget(fd);
 	struct file *file = (struct file *)(v & ~3);
 
-	if (file && (file->f_mode & FMODE_ATOMIC_POS)) {
+	if (file && !(file->f_mode & FMODE_STREAM)) {
 		if (file_count(file) > 1) {
 			v |= FDPUT_POS_UNLOCK;
 			mutex_lock(&file->f_pos_lock);

commit 38e7571c07be01f9f19b355a9306a4e3d5cb0f5b
Merge: 80201fe175cb 21b4aa5d20fd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 8 14:48:40 2019 -0800

    Merge tag 'io_uring-2019-03-06' of git://git.kernel.dk/linux-block
    
    Pull io_uring IO interface from Jens Axboe:
     "Second attempt at adding the io_uring interface.
    
      Since the first one, we've added basic unit testing of the three
      system calls, that resides in liburing like the other unit tests that
      we have so far. It'll take a while to get full coverage of it, but
      we're working towards it. I've also added two basic test programs to
      tools/io_uring. One uses the raw interface and has support for all the
      various features that io_uring supports outside of standard IO, like
      fixed files, fixed IO buffers, and polled IO. The other uses the
      liburing API, and is a simplified version of cp(1).
    
      This adds support for a new IO interface, io_uring.
    
      io_uring allows an application to communicate with the kernel through
      two rings, the submission queue (SQ) and completion queue (CQ) ring.
      This allows for very efficient handling of IOs, see the v5 posting for
      some basic numbers:
    
        https://lore.kernel.org/linux-block/20190116175003.17880-1-axboe@kernel.dk/
    
      Outside of just efficiency, the interface is also flexible and
      extendable, and allows for future use cases like the upcoming NVMe
      key-value store API, networked IO, and so on. It also supports async
      buffered IO, something that we've always failed to support in the
      kernel.
    
      Outside of basic IO features, it supports async polled IO as well.
      This particular feature has already been tested at Facebook months ago
      for flash storage boxes, with 25-33% improvements. It makes polled IO
      actually useful for real world use cases, where even basic flash sees
      a nice win in terms of efficiency, latency, and performance. These
      boxes were IOPS bound before, now they are not.
    
      This series adds three new system calls. One for setting up an
      io_uring instance (io_uring_setup(2)), one for submitting/completing
      IO (io_uring_enter(2)), and one for aux functions like registrating
      file sets, buffers, etc (io_uring_register(2)). Through the help of
      Arnd, I've coordinated the syscall numbers so merge on that front
      should be painless.
    
      Jon did a writeup of the interface a while back, which (except for
      minor details that have been tweaked) is still accurate. Find that
      here:
    
        https://lwn.net/Articles/776703/
    
      Huge thanks to Al Viro for helping getting the reference cycle code
      correct, and to Jann Horn for his extensive reviews focused on both
      security and bugs in general.
    
      There's a userspace library that provides basic functionality for
      applications that don't need or want to care about how to fiddle with
      the rings directly. It has helpers to allow applications to easily set
      up an io_uring instance, and submit/complete IO through it without
      knowing about the intricacies of the rings. It also includes man pages
      (thanks to Jeff Moyer), and will continue to grow support helper
      functions and features as time progresses. Find it here:
    
        git://git.kernel.dk/liburing
    
      Fio has full support for the raw interface, both in the form of an IO
      engine (io_uring), but also with a small test application (t/io_uring)
      that can exercise and benchmark the interface"
    
    * tag 'io_uring-2019-03-06' of git://git.kernel.dk/linux-block:
      io_uring: add a few test tools
      io_uring: allow workqueue item to handle multiple buffered requests
      io_uring: add support for IORING_OP_POLL
      io_uring: add io_kiocb ref count
      io_uring: add submission polling
      io_uring: add file set registration
      net: split out functions related to registering inflight socket files
      io_uring: add support for pre-mapped user IO buffers
      block: implement bio helper to add iter bvec pages to bio
      io_uring: batch io_kiocb allocation
      io_uring: use fget/fput_many() for file references
      fs: add fget_many() and fput_many()
      io_uring: support for IO polling
      io_uring: add fsync support
      Add io_uring IO interface

commit 5704a06810682683355624923547b41540e2801a
Author: Shuriyc Chu <sureeju@gmail.com>
Date:   Tue Mar 5 15:41:56 2019 -0800

    fs/file.c: initialize init_files.resize_wait
    
    (Taken from https://bugzilla.kernel.org/show_bug.cgi?id=200647)
    
    'get_unused_fd_flags' in kthread cause kernel crash.  It works fine on
    4.1, but causes crash after get 64 fds.  It also cause crash on
    ubuntu1404/1604/1804, centos7.5, and the crash messages are almost the
    same.
    
    The crash message on centos7.5 shows below:
    
      start fd 61
      start fd 62
      start fd 63
      BUG: unable to handle kernel NULL pointer dereference at           (null)
      IP: __wake_up_common+0x2e/0x90
      PGD 0
      Oops: 0000 [#1] SMP
      Modules linked in: test(OE) xt_CHECKSUM iptable_mangle ipt_MASQUERADE nf_nat_masquerade_ipv4 iptable_nat nf_nat_ipv4 nf_nat nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ipt_REJECT nf_reject_ipv4 tun bridge stp llc ebtable_filter ebtables ip6table_filter ip6_tables iptable_filter devlink sunrpc kvm_intel kvm irqbypass crc32_pclmul ghash_clmulni_intel aesni_intel lrw gf128mul glue_helper ablk_helper cryptd sg ppdev pcspkr virtio_balloon parport_pc parport i2c_piix4 joydev ip_tables xfs libcrc32c sr_mod cdrom sd_mod crc_t10dif crct10dif_generic ata_generic pata_acpi virtio_scsi virtio_console virtio_net cirrus drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops ttm crct10dif_pclmul crct10dif_common crc32c_intel drm ata_piix serio_raw libata virtio_pci virtio_ring i2c_core
       virtio floppy dm_mirror dm_region_hash dm_log dm_mod
      CPU: 2 PID: 1820 Comm: test_fd Kdump: loaded Tainted: G           OE  ------------   3.10.0-862.3.3.el7.x86_64 #1
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
      task: ffff8e92b9431fa0 ti: ffff8e94247a0000 task.ti: ffff8e94247a0000
      RIP: 0010:__wake_up_common+0x2e/0x90
      RSP: 0018:ffff8e94247a2d18  EFLAGS: 00010086
      RAX: 0000000000000000 RBX: ffffffff9d09daa0 RCX: 0000000000000000
      RDX: 0000000000000000 RSI: 0000000000000003 RDI: ffffffff9d09daa0
      RBP: ffff8e94247a2d50 R08: 0000000000000000 R09: ffff8e92b95dfda8
      R10: 0000000000000000 R11: 0000000000000000 R12: ffffffff9d09daa8
      R13: 0000000000000003 R14: 0000000000000000 R15: 0000000000000003
      FS:  0000000000000000(0000) GS:ffff8e9434e80000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      CR2: 0000000000000000 CR3: 000000017c686000 CR4: 00000000000207e0
      Call Trace:
        __wake_up+0x39/0x50
        expand_files+0x131/0x250
        __alloc_fd+0x47/0x170
        get_unused_fd_flags+0x30/0x40
        test_fd+0x12a/0x1c0 [test]
        kthread+0xd1/0xe0
        ret_from_fork_nospec_begin+0x21/0x21
      Code: 66 90 55 48 89 e5 41 57 41 89 f7 41 56 41 89 ce 41 55 41 54 49 89 fc 49 83 c4 08 53 48 83 ec 10 48 8b 47 08 89 55 cc 4c 89 45 d0 <48> 8b 08 49 39 c4 48 8d 78 e8 4c 8d 69 e8 75 08 eb 3b 4c 89 ef
      RIP   __wake_up_common+0x2e/0x90
       RSP <ffff8e94247a2d18>
      CR2: 0000000000000000
    
    This issue exists since CentOS 7.5 3.10.0-862 and CentOS 7.4
    (3.10.0-693.21.1 ) is ok.  Root cause: the item 'resize_wait' is not
    initialized before being used.
    
    Reported-by: Richard Zhang <zhang.zijian@h3c.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 3209ee271c41..a10487aa0a84 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -457,6 +457,7 @@ struct files_struct init_files = {
 		.full_fds_bits	= init_files.full_fds_bits_init,
 	},
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_files.file_lock),
+	.resize_wait	= __WAIT_QUEUE_HEAD_INITIALIZER(init_files.resize_wait),
 };
 
 static unsigned int find_next_fd(struct fdtable *fdt, unsigned int start)

commit 091141a42e15fe47ada737f3996b317072afcefb
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Nov 21 10:32:39 2018 -0700

    fs: add fget_many() and fput_many()
    
    Some uses cases repeatedly get and put references to the same file, but
    the only exposed interface is doing these one at the time. As each of
    these entail an atomic inc or dec on a shared structure, that cost can
    add up.
    
    Add fget_many(), which works just like fget(), except it takes an
    argument for how many references to get on the file. Ditto fput_many(),
    which can drop an arbitrary number of references to a file.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/file.c b/fs/file.c
index 3209ee271c41..97df385d6ab0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -705,7 +705,7 @@ void do_close_on_exec(struct files_struct *files)
 	spin_unlock(&files->file_lock);
 }
 
-static struct file *__fget(unsigned int fd, fmode_t mask)
+static struct file *__fget(unsigned int fd, fmode_t mask, unsigned int refs)
 {
 	struct files_struct *files = current->files;
 	struct file *file;
@@ -720,7 +720,7 @@ static struct file *__fget(unsigned int fd, fmode_t mask)
 		 */
 		if (file->f_mode & mask)
 			file = NULL;
-		else if (!get_file_rcu(file))
+		else if (!get_file_rcu_many(file, refs))
 			goto loop;
 	}
 	rcu_read_unlock();
@@ -728,15 +728,20 @@ static struct file *__fget(unsigned int fd, fmode_t mask)
 	return file;
 }
 
+struct file *fget_many(unsigned int fd, unsigned int refs)
+{
+	return __fget(fd, FMODE_PATH, refs);
+}
+
 struct file *fget(unsigned int fd)
 {
-	return __fget(fd, FMODE_PATH);
+	return __fget(fd, FMODE_PATH, 1);
 }
 EXPORT_SYMBOL(fget);
 
 struct file *fget_raw(unsigned int fd)
 {
-	return __fget(fd, 0);
+	return __fget(fd, 0, 1);
 }
 EXPORT_SYMBOL(fget_raw);
 
@@ -767,7 +772,7 @@ static unsigned long __fget_light(unsigned int fd, fmode_t mask)
 			return 0;
 		return (unsigned long)file;
 	} else {
-		file = __fget(fd, mask);
+		file = __fget(fd, mask, 1);
 		if (!file)
 			return 0;
 		return FDPUT_FPUT | (unsigned long)file;

commit 457fa3469a65a524be04412f5cd497fa3b11c9fd
Merge: b07039b79c9e fbc4904c2877
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 28 20:54:57 2018 -0800

    Merge tag 'char-misc-4.21-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc
    
    Pull char/misc driver updates from Greg KH:
     "Here is the big set of char and misc driver patches for 4.21-rc1.
    
      Lots of different types of driver things in here, as this tree seems
      to be the "collection of various driver subsystems not big enough to
      have their own git tree" lately.
    
      Anyway, some highlights of the changes in here:
    
       - binderfs: is it a rule that all driver subsystems will eventually
         grow to have their own filesystem? Binder now has one to handle the
         use of it in containerized systems.
    
         This was discussed at the Plumbers conference a few months ago and
         knocked into mergable shape very fast by Christian Brauner. Who
         also has signed up to be another binder maintainer, showing a
         distinct lack of good judgement :)
    
       - binder updates and fixes
    
       - mei driver updates
    
       - fpga driver updates and additions
    
       - thunderbolt driver updates
    
       - soundwire driver updates
    
       - extcon driver updates
    
       - nvmem driver updates
    
       - hyper-v driver updates
    
       - coresight driver updates
    
       - pvpanic driver additions and reworking for more device support
    
       - lp driver updates. Yes really, it's _finally_ moved to the proper
         parallal port driver model, something I never thought I would see
         happen. Good stuff.
    
       - other tiny driver updates and fixes.
    
      All of these have been in linux-next for a while with no reported
      issues"
    
    * tag 'char-misc-4.21-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc: (116 commits)
      MAINTAINERS: add another Android binder maintainer
      intel_th: msu: Fix an off-by-one in attribute store
      stm class: Add a reference to the SyS-T document
      stm class: Fix a module refcount leak in policy creation error path
      char: lp: use new parport device model
      char: lp: properly count the lp devices
      char: lp: use first unused lp number while registering
      char: lp: detach the device when parallel port is removed
      char: lp: introduce list to save port number
      bus: qcom: remove duplicated include from qcom-ebi2.c
      VMCI: Use memdup_user() rather than duplicating its implementation
      char/rtc: Use of_node_name_eq for node name comparisons
      misc: mic: fix a DMA pool free failure
      ptp: fix an IS_ERR() vs NULL check
      genwqe: Fix size check
      binder: implement binderfs
      binder: fix use-after-free due to ksys_close() during fdget()
      bus: fsl-mc: remove duplicated include files
      bus: fsl-mc: explicitly define the fsl_mc_command endianness
      misc: ti-st: make array read_ver_cmd static, shrinks object size
      ...

commit 80cd795630d6526ba729a089a435bf74a57af927
Author: Todd Kjos <tkjos@android.com>
Date:   Fri Dec 14 15:58:21 2018 -0800

    binder: fix use-after-free due to ksys_close() during fdget()
    
    44d8047f1d8 ("binder: use standard functions to allocate fds")
    exposed a pre-existing issue in the binder driver.
    
    fdget() is used in ksys_ioctl() as a performance optimization.
    One of the rules associated with fdget() is that ksys_close() must
    not be called between the fdget() and the fdput(). There is a case
    where this requirement is not met in the binder driver which results
    in the reference count dropping to 0 when the device is still in
    use. This can result in use-after-free or other issues.
    
    If userpace has passed a file-descriptor for the binder driver using
    a BINDER_TYPE_FDA object, then kys_close() is called on it when
    handling a binder_ioctl(BC_FREE_BUFFER) command. This violates
    the assumptions for using fdget().
    
    The problem is fixed by deferring the close using task_work_add(). A
    new variant of __close_fd() was created that returns a struct file
    with a reference. The fput() is deferred instead of using ksys_close().
    
    Fixes: 44d8047f1d87a ("binder: use standard functions to allocate fds")
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Todd Kjos <tkjos@google.com>
    Cc: stable <stable@vger.kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/file.c b/fs/file.c
index 7ffd6e9d103d..8d059d8973e9 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -640,6 +640,35 @@ int __close_fd(struct files_struct *files, unsigned fd)
 }
 EXPORT_SYMBOL(__close_fd); /* for ksys_close() */
 
+/*
+ * variant of __close_fd that gets a ref on the file for later fput
+ */
+int __close_fd_get_file(unsigned int fd, struct file **res)
+{
+	struct files_struct *files = current->files;
+	struct file *file;
+	struct fdtable *fdt;
+
+	spin_lock(&files->file_lock);
+	fdt = files_fdtable(files);
+	if (fd >= fdt->max_fds)
+		goto out_unlock;
+	file = fdt->fd[fd];
+	if (!file)
+		goto out_unlock;
+	rcu_assign_pointer(fdt->fd[fd], NULL);
+	__put_unused_fd(files, fd);
+	spin_unlock(&files->file_lock);
+	get_file(file);
+	*res = file;
+	return filp_close(file, files);
+
+out_unlock:
+	spin_unlock(&files->file_lock);
+	*res = NULL;
+	return -ENOENT;
+}
+
 void do_close_on_exec(struct files_struct *files)
 {
 	unsigned i;

commit c93ffc15cceb057924410f9178e679120ee12353
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Nov 5 17:31:31 2018 -0800

    fs/file: Replace synchronize_sched() with synchronize_rcu()
    
    Now that synchronize_rcu() waits for preempt-disable regions of code
    as well as RCU read-side critical sections, synchronize_sched() can be
    replaced by synchronize_rcu().  This commit therefore makes this change.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: <linux-fsdevel@vger.kernel.org>

diff --git a/fs/file.c b/fs/file.c
index 7ffd6e9d103d..50304c7525ea 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -158,7 +158,7 @@ static int expand_fdtable(struct files_struct *files, unsigned int nr)
 	 * or have finished their rcu_read_lock_sched() section.
 	 */
 	if (atomic_read(&files->count) > 1)
-		synchronize_sched();
+		synchronize_rcu();
 
 	spin_lock(&files->file_lock);
 	if (!new_fdt)

commit 2ca2a09d6215fd9621aa3e2db7cc9428a61f2911
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sun Mar 11 11:34:55 2018 +0100

    fs: add ksys_close() wrapper; remove in-kernel calls to sys_close()
    
    Using the ksys_close() wrapper allows us to get rid of in-kernel calls
    to the sys_close() syscall. The ksys_ prefix denotes that this function
    is meant as a drop-in replacement for the syscall. In particular, it
    uses the same calling convention as sys_close(), with one subtle
    difference:
    
    The few places which checked the return value did not care about the return
    value re-writing in sys_close(), so simply use a wrapper around
    __close_fd().
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/fs/file.c b/fs/file.c
index d304004f0b65..7ffd6e9d103d 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -638,6 +638,7 @@ int __close_fd(struct files_struct *files, unsigned fd)
 	spin_unlock(&files->file_lock);
 	return -EBADF;
 }
+EXPORT_SYMBOL(__close_fd); /* for ksys_close() */
 
 void do_close_on_exec(struct files_struct *files)
 {

commit c7248321a3d42ffba78db0dde88d1c49ca1c045f
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sun Mar 11 11:34:40 2018 +0100

    fs: add ksys_dup{,3}() helper; remove in-kernel calls to sys_dup{,3}()
    
    Using ksys_dup() and ksys_dup3() as helper functions allows us to
    avoid the in-kernel calls to the sys_dup() and sys_dup3() syscalls.
    The ksys_ prefix denotes that these functions are meant as a drop-in
    replacement for the syscalls. In particular, they use the same
    calling convention as sys_dup{,3}().
    
    In the near future, the fs-external callers of ksys_dup{,3}() should be
    converted to call do_dup2() directly. Then, ksys_dup{,3}() can be moved
    within sys_dup{,3}() again.
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/fs/file.c b/fs/file.c
index 42f0db4bd0fb..d304004f0b65 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -870,7 +870,7 @@ int replace_fd(unsigned fd, struct file *file, unsigned flags)
 	return err;
 }
 
-SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
+static int ksys_dup3(unsigned int oldfd, unsigned int newfd, int flags)
 {
 	int err = -EBADF;
 	struct file *file;
@@ -904,6 +904,11 @@ SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
 	return err;
 }
 
+SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
+{
+	return ksys_dup3(oldfd, newfd, flags);
+}
+
 SYSCALL_DEFINE2(dup2, unsigned int, oldfd, unsigned int, newfd)
 {
 	if (unlikely(newfd == oldfd)) { /* corner case */
@@ -916,10 +921,10 @@ SYSCALL_DEFINE2(dup2, unsigned int, oldfd, unsigned int, newfd)
 		rcu_read_unlock();
 		return retval;
 	}
-	return sys_dup3(oldfd, newfd, 0);
+	return ksys_dup3(oldfd, newfd, 0);
 }
 
-SYSCALL_DEFINE1(dup, unsigned int, fildes)
+int ksys_dup(unsigned int fildes)
 {
 	int ret = -EBADF;
 	struct file *file = fget_raw(fildes);
@@ -934,6 +939,11 @@ SYSCALL_DEFINE1(dup, unsigned int, fildes)
 	return ret;
 }
 
+SYSCALL_DEFINE1(dup, unsigned int, fildes)
+{
+	return ksys_dup(fildes);
+}
+
 int f_dupfd(unsigned int from, struct file *file, unsigned flags)
 {
 	int err;

commit 19e7b5f99474107e8d0b4b3e4652fa19ddb87efc
Merge: 26064ea409b4 ce4c253573ad
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 09:25:20 2018 -0800

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc vfs updates from Al Viro:
     "All kinds of misc stuff, without any unifying topic, from various
      people.
    
      Neil's d_anon patch, several bugfixes, introduction of kvmalloc
      analogue of kmemdup_user(), extending bitfield.h to deal with
      fixed-endians, assorted cleanups all over the place..."
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (28 commits)
      alpha: osf_sys.c: use timespec64 where appropriate
      alpha: osf_sys.c: fix put_tv32 regression
      jffs2: Fix use-after-free bug in jffs2_iget()'s error handling path
      dcache: delete unused d_hash_mask
      dcache: subtract d_hash_shift from 32 in advance
      fs/buffer.c: fold init_buffer() into init_page_buffers()
      fs: fold __inode_permission() into inode_permission()
      fs: add RWF_APPEND
      sctp: use vmemdup_user() rather than badly open-coding memdup_user()
      snd_ctl_elem_init_enum_names(): switch to vmemdup_user()
      replace_user_tlv(): switch to vmemdup_user()
      new primitive: vmemdup_user()
      memdup_user(): switch to GFP_USER
      eventfd: fold eventfd_ctx_get() into eventfd_ctx_fileget()
      eventfd: fold eventfd_ctx_read() into eventfd_read()
      eventfd: convert to use anon_inode_getfd()
      nfs4file: get rid of pointless include of btrfs.h
      uvc_v4l2: clean copyin/copyout up
      vme_user: don't use __copy_..._user()
      usx2y: don't bother with memdup_user() for 16-byte structure
      ...

commit d6b4dcf5c580470ed553052206836adfaa2052fc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 5 09:41:03 2017 -0500

    fs/file.c: trim includes
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 3b080834b870..bb2d251e19c1 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -11,18 +11,13 @@
 #include <linux/export.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
-#include <linux/mmzone.h>
-#include <linux/time.h>
 #include <linux/sched/signal.h>
 #include <linux/slab.h>
-#include <linux/vmalloc.h>
 #include <linux/file.h>
 #include <linux/fdtable.h>
 #include <linux/bitops.h>
-#include <linux/interrupt.h>
 #include <linux/spinlock.h>
 #include <linux/rcupdate.h>
-#include <linux/workqueue.h>
 
 unsigned int sysctl_nr_open __read_mostly = 1024*1024;
 unsigned int sysctl_nr_open_min = BITS_PER_LONG;

commit 388a4c88064e7e62602b4d92ca127f0b0c9b305a
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Oct 24 08:39:34 2017 -0700

    fs: Eliminate cond_resched_rcu_qs() in favor of cond_resched()
    
    Now that cond_resched() also provides RCU quiescent states when
    needed, it can be used in place of cond_resched_rcu_qs().  This
    commit therefore makes this change.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: <linux-fsdevel@vger.kernel.org>

diff --git a/fs/file.c b/fs/file.c
index 3b080834b870..fc0eeb812e2c 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -391,7 +391,7 @@ static struct fdtable *close_files(struct files_struct * files)
 				struct file * file = xchg(&fdt->fd[i], NULL);
 				if (file) {
 					filp_close(file, files);
-					cond_resched_rcu_qs();
+					cond_resched();
 				}
 			}
 			i++;

commit ca5b857cb0f42986520abd9dbb0c2508067342b2
Merge: a0e136e5da98 c02b1a9b41c2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 12:54:01 2017 -0800

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc vfs updates from Al Viro:
     "Assorted stuff, really no common topic here"
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      vfs: grab the lock instead of blocking in __fd_install during resizing
      vfs: stop clearing close on exec when closing a fd
      include/linux/fs.h: fix comment about struct address_space
      fs: make fiemap work from compat_ioctl
      coda: fix 'kernel memory exposure attempt' in fsync
      pstore: remove unneeded unlikely()
      vfs: remove unneeded unlikely()
      stubs for mount_bdev() and kill_block_super() in !CONFIG_BLOCK case
      make vfs_ustat() static
      do_handle_open() should be static
      elf_fdpic: fix unused variable warning
      fold destroy_super() into __put_super()
      new helper: destroy_unused_super()
      fix address space warnings in ipc/
      acct.h: get rid of detritus

commit c02b1a9b41c2e728289f96850580a3651e0a8b5f
Author: Mateusz Guzik <mguzik@redhat.com>
Date:   Tue Oct 3 12:58:15 2017 +0200

    vfs: grab the lock instead of blocking in __fd_install during resizing
    
    Explicit locking in the fallback case provides a safe state of the
    table. Getting rid of blocking semantics makes __fd_install usable
    again in non-sleepable contexts, which easies backporting efforts.
    
    There is a side effect of slightly nicer assembly for the common case
    as might_sleep can now be removed.
    
    Signed-off-by: Mateusz Guzik <mguzik@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 9d047bd046b0..4115503bb575 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -592,13 +592,16 @@ void __fd_install(struct files_struct *files, unsigned int fd,
 {
 	struct fdtable *fdt;
 
-	might_sleep();
 	rcu_read_lock_sched();
 
-	while (unlikely(files->resize_in_progress)) {
+	if (unlikely(files->resize_in_progress)) {
 		rcu_read_unlock_sched();
-		wait_event(files->resize_wait, !files->resize_in_progress);
-		rcu_read_lock_sched();
+		spin_lock(&files->file_lock);
+		fdt = files_fdtable(files);
+		BUG_ON(fdt->fd[fd] != NULL);
+		rcu_assign_pointer(fdt->fd[fd], file);
+		spin_unlock(&files->file_lock);
+		return;
 	}
 	/* coupled with smp_wmb() in expand_fdtable() */
 	smp_rmb();

commit 5297908270549b734c7c2556745e2385b6d4941d
Author: Mateusz Guzik <mguzik@redhat.com>
Date:   Tue Oct 3 12:58:14 2017 +0200

    vfs: stop clearing close on exec when closing a fd
    
    Codepaths allocating a fd always make sure the bit is set/unset
    depending on flags, thus clearing on close is redundant.
    
    Signed-off-by: Mateusz Guzik <mguzik@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 1fc7fbbb4510..9d047bd046b0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -631,7 +631,6 @@ int __close_fd(struct files_struct *files, unsigned fd)
 	if (!file)
 		goto out_unlock;
 	rcu_assign_pointer(fdt->fd[fd], NULL);
-	__clear_close_on_exec(fd, fdt);
 	__put_unused_fd(files, fd);
 	spin_unlock(&files->file_lock);
 	return filp_close(file, files);

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/file.c b/fs/file.c
index 1fc7fbbb4510..4eecbf4244a5 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/fs/file.c
  *

commit c823bd9244337aef3699c546eb521c71fd60012e
Author: Michal Hocko <mhocko@suse.com>
Date:   Thu Jul 6 15:36:19 2017 -0700

    fs/file.c: replace alloc_fdmem() with kvmalloc() alternative
    
    There is no real reason to duplicate kvmalloc* helpers so drop
    alloc_fdmem and replace it with the appropriate library function.
    
    Link: http://lkml.kernel.org/r/20170531155145.17111-2-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 1c2972e3a405..1fc7fbbb4510 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -30,21 +30,6 @@ unsigned int sysctl_nr_open_min = BITS_PER_LONG;
 unsigned int sysctl_nr_open_max =
 	__const_min(INT_MAX, ~(size_t)0/sizeof(void *)) & -BITS_PER_LONG;
 
-static void *alloc_fdmem(size_t size)
-{
-	/*
-	 * Very large allocations can stress page reclaim, so fall back to
-	 * vmalloc() if the allocation size will be considered "large" by the VM.
-	 */
-	if (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {
-		void *data = kmalloc(size, GFP_KERNEL_ACCOUNT |
-				     __GFP_NOWARN | __GFP_NORETRY);
-		if (data != NULL)
-			return data;
-	}
-	return __vmalloc(size, GFP_KERNEL_ACCOUNT, PAGE_KERNEL);
-}
-
 static void __free_fdtable(struct fdtable *fdt)
 {
 	kvfree(fdt->fd);
@@ -131,13 +116,14 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	if (!fdt)
 		goto out;
 	fdt->max_fds = nr;
-	data = alloc_fdmem(nr * sizeof(struct file *));
+	data = kvmalloc_array(nr, sizeof(struct file *), GFP_KERNEL_ACCOUNT);
 	if (!data)
 		goto out_fdt;
 	fdt->fd = data;
 
-	data = alloc_fdmem(max_t(size_t,
-				 2 * nr / BITS_PER_BYTE + BITBIT_SIZE(nr), L1_CACHE_BYTES));
+	data = kvmalloc(max_t(size_t,
+				 2 * nr / BITS_PER_BYTE + BITBIT_SIZE(nr), L1_CACHE_BYTES),
+				 GFP_KERNEL_ACCOUNT);
 	if (!data)
 		goto out_arr;
 	fdt->open_fds = data;

commit 19809c2da28aee5860ad9a2eff760730a0710df0
Author: Michal Hocko <mhocko@suse.com>
Date:   Mon May 8 15:57:44 2017 -0700

    mm, vmalloc: use __GFP_HIGHMEM implicitly
    
    __vmalloc* allows users to provide gfp flags for the underlying
    allocation.  This API is quite popular
    
      $ git grep "=[[:space:]]__vmalloc\|return[[:space:]]*__vmalloc" | wc -l
      77
    
    The only problem is that many people are not aware that they really want
    to give __GFP_HIGHMEM along with other flags because there is really no
    reason to consume precious lowmemory on CONFIG_HIGHMEM systems for pages
    which are mapped to the kernel vmalloc space.  About half of users don't
    use this flag, though.  This signals that we make the API unnecessarily
    too complex.
    
    This patch simply uses __GFP_HIGHMEM implicitly when allocating pages to
    be mapped to the vmalloc space.  Current users which add __GFP_HIGHMEM
    are simplified and drop the flag.
    
    Link: http://lkml.kernel.org/r/20170307141020.29107-1-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Reviewed-by: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Cristopher Lameter <cl@linux.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index ad6f094f2eff..1c2972e3a405 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -42,7 +42,7 @@ static void *alloc_fdmem(size_t size)
 		if (data != NULL)
 			return data;
 	}
-	return __vmalloc(size, GFP_KERNEL_ACCOUNT | __GFP_HIGHMEM, PAGE_KERNEL);
+	return __vmalloc(size, GFP_KERNEL_ACCOUNT, PAGE_KERNEL);
 }
 
 static void __free_fdtable(struct fdtable *fdt)

commit 3f07c0144132e4f59d88055ac8ff3e691a5fa2b8
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/signal.h>
    
    We are going to split <linux/sched/signal.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/signal.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/file.c b/fs/file.c
index 69d6990e3021..ad6f094f2eff 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -12,7 +12,7 @@
 #include <linux/mm.h>
 #include <linux/mmzone.h>
 #include <linux/time.h>
-#include <linux/sched.h>
+#include <linux/sched/signal.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/file.h>

commit 9b80a184eaadc117f27faad522008f31d571621b
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Fri Sep 2 00:38:52 2016 +0300

    fs/file: more unsigned file descriptors
    
    Propagate unsignedness for grand total of 149 bytes:
    
            $ ./scripts/bloat-o-meter ../vmlinux-000 ../obj/vmlinux
            add/remove: 0/0 grow/shrink: 0/10 up/down: 0/-149 (-149)
            function                                     old     new   delta
            set_close_on_exec                             99      98      -1
            put_files_struct                             201     200      -1
            get_close_on_exec                             59      58      -1
            do_prlimit                                   498     497      -1
            do_execveat_common.isra                     1662    1661      -1
            __close_fd                                   178     173      -5
            do_dup2                                      219     204     -15
            seq_show                                     685     660     -25
            __alloc_fd                                   384     357     -27
            dup_fd                                       718     646     -72
    
    It mostly comes from converting "unsigned int" to "long" for bit operations.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 6b1acdfe59da..69d6990e3021 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -23,12 +23,12 @@
 #include <linux/rcupdate.h>
 #include <linux/workqueue.h>
 
-int sysctl_nr_open __read_mostly = 1024*1024;
-int sysctl_nr_open_min = BITS_PER_LONG;
+unsigned int sysctl_nr_open __read_mostly = 1024*1024;
+unsigned int sysctl_nr_open_min = BITS_PER_LONG;
 /* our min() is unusable in constant expressions ;-/ */
 #define __const_min(x, y) ((x) < (y) ? (x) : (y))
-int sysctl_nr_open_max = __const_min(INT_MAX, ~(size_t)0/sizeof(void *)) &
-			 -BITS_PER_LONG;
+unsigned int sysctl_nr_open_max =
+	__const_min(INT_MAX, ~(size_t)0/sizeof(void *)) & -BITS_PER_LONG;
 
 static void *alloc_fdmem(size_t size)
 {
@@ -163,7 +163,7 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
  * Return <0 error code on error; 1 on successful completion.
  * The files->file_lock should be held on entry, and will be held on exit.
  */
-static int expand_fdtable(struct files_struct *files, int nr)
+static int expand_fdtable(struct files_struct *files, unsigned int nr)
 	__releases(files->file_lock)
 	__acquires(files->file_lock)
 {
@@ -208,7 +208,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
  * expanded and execution may have blocked.
  * The files->file_lock should be held on entry, and will be held on exit.
  */
-static int expand_files(struct files_struct *files, int nr)
+static int expand_files(struct files_struct *files, unsigned int nr)
 	__releases(files->file_lock)
 	__acquires(files->file_lock)
 {
@@ -243,12 +243,12 @@ static int expand_files(struct files_struct *files, int nr)
 	return expanded;
 }
 
-static inline void __set_close_on_exec(int fd, struct fdtable *fdt)
+static inline void __set_close_on_exec(unsigned int fd, struct fdtable *fdt)
 {
 	__set_bit(fd, fdt->close_on_exec);
 }
 
-static inline void __clear_close_on_exec(int fd, struct fdtable *fdt)
+static inline void __clear_close_on_exec(unsigned int fd, struct fdtable *fdt)
 {
 	if (test_bit(fd, fdt->close_on_exec))
 		__clear_bit(fd, fdt->close_on_exec);
@@ -268,10 +268,10 @@ static inline void __clear_open_fd(unsigned int fd, struct fdtable *fdt)
 	__clear_bit(fd / BITS_PER_LONG, fdt->full_fds_bits);
 }
 
-static int count_open_files(struct fdtable *fdt)
+static unsigned int count_open_files(struct fdtable *fdt)
 {
-	int size = fdt->max_fds;
-	int i;
+	unsigned int size = fdt->max_fds;
+	unsigned int i;
 
 	/* Find the last open fd */
 	for (i = size / BITS_PER_LONG; i > 0; ) {
@@ -291,7 +291,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 {
 	struct files_struct *newf;
 	struct file **old_fds, **new_fds;
-	int open_files, i;
+	unsigned int open_files, i;
 	struct fdtable *old_fdt, *new_fdt;
 
 	*errorp = -ENOMEM;
@@ -391,7 +391,7 @@ static struct fdtable *close_files(struct files_struct * files)
 	 * files structure.
 	 */
 	struct fdtable *fdt = rcu_dereference_raw(files->fdt);
-	int i, j = 0;
+	unsigned int i, j = 0;
 
 	for (;;) {
 		unsigned long set;
@@ -477,11 +477,11 @@ struct files_struct init_files = {
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_files.file_lock),
 };
 
-static unsigned long find_next_fd(struct fdtable *fdt, unsigned long start)
+static unsigned int find_next_fd(struct fdtable *fdt, unsigned int start)
 {
-	unsigned long maxfd = fdt->max_fds;
-	unsigned long maxbit = maxfd / BITS_PER_LONG;
-	unsigned long bitbit = start / BITS_PER_LONG;
+	unsigned int maxfd = fdt->max_fds;
+	unsigned int maxbit = maxfd / BITS_PER_LONG;
+	unsigned int bitbit = start / BITS_PER_LONG;
 
 	bitbit = find_next_zero_bit(fdt->full_fds_bits, maxbit, bitbit) * BITS_PER_LONG;
 	if (bitbit > maxfd)

commit 63b6df14134ddd048984c8afadb46e721815bfc6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 20 17:08:21 2016 -0400

    give readdir(2)/getdents(2)/etc. uniform exclusion with lseek()
    
    same as read() on regular files has, and for the same reason.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 1fbc5c0555a9..6b1acdfe59da 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -784,6 +784,11 @@ unsigned long __fdget_pos(unsigned int fd)
 	return v;
 }
 
+void __f_unlock_pos(struct file *f)
+{
+	mutex_unlock(&f->f_pos_lock);
+}
+
 /*
  * We only lock f_pos if we have threads or if the file might be
  * shared with another process. In both cases we'll have an elevated

commit 5d097056c9a017a3b720849efb5432f37acabbac
Author: Vladimir Davydov <vdavydov@virtuozzo.com>
Date:   Thu Jan 14 15:18:21 2016 -0800

    kmemcg: account certain kmem allocations to memcg
    
    Mark those kmem allocations that are known to be easily triggered from
    userspace as __GFP_ACCOUNT/SLAB_ACCOUNT, which makes them accounted to
    memcg.  For the list, see below:
    
     - threadinfo
     - task_struct
     - task_delay_info
     - pid
     - cred
     - mm_struct
     - vm_area_struct and vm_region (nommu)
     - anon_vma and anon_vma_chain
     - signal_struct
     - sighand_struct
     - fs_struct
     - files_struct
     - fdtable and fdtable->full_fds_bits
     - dentry and external_name
     - inode for all filesystems. This is the most tedious part, because
       most filesystems overwrite the alloc_inode method.
    
    The list is far from complete, so feel free to add more objects.
    Nevertheless, it should be close to "account everything" approach and
    keep most workloads within bounds.  Malevolent users will be able to
    breach the limit, but this was possible even with the former "account
    everything" approach (simply because it did not account everything in
    fact).
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Vladimir Davydov <vdavydov@virtuozzo.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 1aed0add16a2..1fbc5c0555a9 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -37,11 +37,12 @@ static void *alloc_fdmem(size_t size)
 	 * vmalloc() if the allocation size will be considered "large" by the VM.
 	 */
 	if (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {
-		void *data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN|__GFP_NORETRY);
+		void *data = kmalloc(size, GFP_KERNEL_ACCOUNT |
+				     __GFP_NOWARN | __GFP_NORETRY);
 		if (data != NULL)
 			return data;
 	}
-	return vmalloc(size);
+	return __vmalloc(size, GFP_KERNEL_ACCOUNT | __GFP_HIGHMEM, PAGE_KERNEL);
 }
 
 static void __free_fdtable(struct fdtable *fdt)
@@ -126,7 +127,7 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	if (unlikely(nr > sysctl_nr_open))
 		nr = ((sysctl_nr_open - 1) | (BITS_PER_LONG - 1)) + 1;
 
-	fdt = kmalloc(sizeof(struct fdtable), GFP_KERNEL);
+	fdt = kmalloc(sizeof(struct fdtable), GFP_KERNEL_ACCOUNT);
 	if (!fdt)
 		goto out;
 	fdt->max_fds = nr;

commit 752343be63d90c84d275f046e43371febe217863
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Thu Oct 29 12:01:41 2015 +0100

    fs/file.c: __const_max is actually __const_min :-)
    
    7f4b36f9bb930 "get rid of files_defer_init()" inexplicably changed a
    min() to a __const_max() - but the __const_max macro actually gives
    the minimum... So no functional change, just less confusing naming.
    
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 39f8f15921da..1aed0add16a2 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -25,9 +25,9 @@
 
 int sysctl_nr_open __read_mostly = 1024*1024;
 int sysctl_nr_open_min = BITS_PER_LONG;
-/* our max() is unusable in constant expressions ;-/ */
-#define __const_max(x, y) ((x) < (y) ? (x) : (y))
-int sysctl_nr_open_max = __const_max(INT_MAX, ~(size_t)0/sizeof(void *)) &
+/* our min() is unusable in constant expressions ;-/ */
+#define __const_min(x, y) ((x) < (y) ? (x) : (y))
+int sysctl_nr_open_max = __const_min(INT_MAX, ~(size_t)0/sizeof(void *)) &
 			 -BITS_PER_LONG;
 
 static void *alloc_fdmem(size_t size)

commit ea5c58e70c3a148ada0d3061a8f529589bb766ba
Author: Eric Biggers <ebiggers3@gmail.com>
Date:   Fri Nov 6 00:32:04 2015 -0600

    vfs: clear remainder of 'full_fds_bits' in dup_fd()
    
    This fixes a bug from commit f3f86e33dc3d ("vfs: Fix pathological
    performance case for __alloc_fd()").
    
    v2: refactor to share fd bitmap copying code
    Signed-off-by: Eric Biggers <ebiggers3@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index c6986dce0334..39f8f15921da 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -60,8 +60,31 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 #define BITBIT_SIZE(nr)	(BITBIT_NR(nr) * sizeof(long))
 
 /*
- * Expand the fdset in the files_struct.  Called with the files spinlock
- * held for write.
+ * Copy 'count' fd bits from the old table to the new table and clear the extra
+ * space if any.  This does not copy the file pointers.  Called with the files
+ * spinlock held for write.
+ */
+static void copy_fd_bitmaps(struct fdtable *nfdt, struct fdtable *ofdt,
+			    unsigned int count)
+{
+	unsigned int cpy, set;
+
+	cpy = count / BITS_PER_BYTE;
+	set = (nfdt->max_fds - count) / BITS_PER_BYTE;
+	memcpy(nfdt->open_fds, ofdt->open_fds, cpy);
+	memset((char *)nfdt->open_fds + cpy, 0, set);
+	memcpy(nfdt->close_on_exec, ofdt->close_on_exec, cpy);
+	memset((char *)nfdt->close_on_exec + cpy, 0, set);
+
+	cpy = BITBIT_SIZE(count);
+	set = BITBIT_SIZE(nfdt->max_fds) - cpy;
+	memcpy(nfdt->full_fds_bits, ofdt->full_fds_bits, cpy);
+	memset((char *)nfdt->full_fds_bits + cpy, 0, set);
+}
+
+/*
+ * Copy all file descriptors from the old table to the new, expanded table and
+ * clear the extra space.  Called with the files spinlock held for write.
  */
 static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 {
@@ -72,19 +95,9 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 	cpy = ofdt->max_fds * sizeof(struct file *);
 	set = (nfdt->max_fds - ofdt->max_fds) * sizeof(struct file *);
 	memcpy(nfdt->fd, ofdt->fd, cpy);
-	memset((char *)(nfdt->fd) + cpy, 0, set);
+	memset((char *)nfdt->fd + cpy, 0, set);
 
-	cpy = ofdt->max_fds / BITS_PER_BYTE;
-	set = (nfdt->max_fds - ofdt->max_fds) / BITS_PER_BYTE;
-	memcpy(nfdt->open_fds, ofdt->open_fds, cpy);
-	memset((char *)(nfdt->open_fds) + cpy, 0, set);
-	memcpy(nfdt->close_on_exec, ofdt->close_on_exec, cpy);
-	memset((char *)(nfdt->close_on_exec) + cpy, 0, set);
-
-	cpy = BITBIT_SIZE(ofdt->max_fds);
-	set = BITBIT_SIZE(nfdt->max_fds) - cpy;
-	memcpy(nfdt->full_fds_bits, ofdt->full_fds_bits, cpy);
-	memset(cpy+(char *)nfdt->full_fds_bits, 0, set);
+	copy_fd_bitmaps(nfdt, ofdt, ofdt->max_fds);
 }
 
 static struct fdtable * alloc_fdtable(unsigned int nr)
@@ -277,7 +290,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 {
 	struct files_struct *newf;
 	struct file **old_fds, **new_fds;
-	int open_files, size, i;
+	int open_files, i;
 	struct fdtable *old_fdt, *new_fdt;
 
 	*errorp = -ENOMEM;
@@ -334,13 +347,11 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 		open_files = count_open_files(old_fdt);
 	}
 
+	copy_fd_bitmaps(new_fdt, old_fdt, open_files);
+
 	old_fds = old_fdt->fd;
 	new_fds = new_fdt->fd;
 
-	memcpy(new_fdt->open_fds, old_fdt->open_fds, open_files / 8);
-	memcpy(new_fdt->close_on_exec, old_fdt->close_on_exec, open_files / 8);
-	memcpy(new_fdt->full_fds_bits, old_fdt->full_fds_bits, BITBIT_SIZE(open_files));
-
 	for (i = open_files; i != 0; i--) {
 		struct file *f = *old_fds++;
 		if (f) {
@@ -358,19 +369,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	}
 	spin_unlock(&oldf->file_lock);
 
-	/* compute the remainder to be cleared */
-	size = (new_fdt->max_fds - open_files) * sizeof(struct file *);
-
-	/* This is long word aligned thus could use a optimized version */
-	memset(new_fds, 0, size);
-
-	if (new_fdt->max_fds > open_files) {
-		int left = (new_fdt->max_fds - open_files) / 8;
-		int start = open_files / BITS_PER_LONG;
-
-		memset(&new_fdt->open_fds[start], 0, left);
-		memset(&new_fdt->close_on_exec[start], 0, left);
-	}
+	/* clear the remainder */
+	memset(new_fds, 0, (new_fdt->max_fds - open_files) * sizeof(struct file *));
 
 	rcu_assign_pointer(newf->fdt, new_fdt);
 

commit fc90888d07b8e17eec49c04bdb26344fdea96c3b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 31 16:06:40 2015 -0700

    vfs: conditionally clear close-on-exec flag
    
    We clear the close-on-exec flag when opening and closing files, and the
    bit was almost always already clear before.  Avoid dirtying the
    cacheline if the clearning isn't necessary.  That avoids unnecessary
    cacheline dirtying and bouncing in multi-socket environments.
    
    Eric Dumazet has a file descriptor benchmark that goes 4% faster from
    this on his two-socket machine.  It's probably partly superlinear
    improvement due to getting slightly less spinlock contention on the
    file_lock spinlock due to less work in the critical section.
    
    Tested-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 6f6eb2b03af5..c6986dce0334 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -236,7 +236,8 @@ static inline void __set_close_on_exec(int fd, struct fdtable *fdt)
 
 static inline void __clear_close_on_exec(int fd, struct fdtable *fdt)
 {
-	__clear_bit(fd, fdt->close_on_exec);
+	if (test_bit(fd, fdt->close_on_exec))
+		__clear_bit(fd, fdt->close_on_exec);
 }
 
 static inline void __set_open_fd(unsigned int fd, struct fdtable *fdt)

commit f3f86e33dc3da437fa4f204588ce7c78ea756982
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 30 16:53:57 2015 -0700

    vfs: Fix pathological performance case for __alloc_fd()
    
    Al Viro points out that:
    > >     * [Linux-specific aside] our __alloc_fd() can degrade quite badly
    > > with some use patterns.  The cacheline pingpong in the bitmap is probably
    > > inevitable, unless we accept considerably heavier memory footprint,
    > > but we also have a case when alloc_fd() takes O(n) and it's _not_ hard
    > > to trigger - close(3);open(...); will have the next open() after that
    > > scanning the entire in-use bitmap.
    
    And Eric Dumazet has a somewhat realistic multithreaded microbenchmark
    that opens and closes a lot of sockets with minimal work per socket.
    
    This patch largely fixes it.  We keep a 2nd-level bitmap of the open
    file bitmaps, showing which words are already full.  So then we can
    traverse that second-level bitmap to efficiently skip already allocated
    file descriptors.
    
    On his benchmark, this improves performance by up to an order of
    magnitude, by avoiding the excessive open file bitmap scanning.
    
    Tested-and-acked-by: Eric Dumazet <edumazet@google.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 6c672ad329e9..6f6eb2b03af5 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -56,6 +56,9 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	__free_fdtable(container_of(rcu, struct fdtable, rcu));
 }
 
+#define BITBIT_NR(nr)	BITS_TO_LONGS(BITS_TO_LONGS(nr))
+#define BITBIT_SIZE(nr)	(BITBIT_NR(nr) * sizeof(long))
+
 /*
  * Expand the fdset in the files_struct.  Called with the files spinlock
  * held for write.
@@ -77,6 +80,11 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 	memset((char *)(nfdt->open_fds) + cpy, 0, set);
 	memcpy(nfdt->close_on_exec, ofdt->close_on_exec, cpy);
 	memset((char *)(nfdt->close_on_exec) + cpy, 0, set);
+
+	cpy = BITBIT_SIZE(ofdt->max_fds);
+	set = BITBIT_SIZE(nfdt->max_fds) - cpy;
+	memcpy(nfdt->full_fds_bits, ofdt->full_fds_bits, cpy);
+	memset(cpy+(char *)nfdt->full_fds_bits, 0, set);
 }
 
 static struct fdtable * alloc_fdtable(unsigned int nr)
@@ -115,12 +123,14 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	fdt->fd = data;
 
 	data = alloc_fdmem(max_t(size_t,
-				 2 * nr / BITS_PER_BYTE, L1_CACHE_BYTES));
+				 2 * nr / BITS_PER_BYTE + BITBIT_SIZE(nr), L1_CACHE_BYTES));
 	if (!data)
 		goto out_arr;
 	fdt->open_fds = data;
 	data += nr / BITS_PER_BYTE;
 	fdt->close_on_exec = data;
+	data += nr / BITS_PER_BYTE;
+	fdt->full_fds_bits = data;
 
 	return fdt;
 
@@ -229,14 +239,18 @@ static inline void __clear_close_on_exec(int fd, struct fdtable *fdt)
 	__clear_bit(fd, fdt->close_on_exec);
 }
 
-static inline void __set_open_fd(int fd, struct fdtable *fdt)
+static inline void __set_open_fd(unsigned int fd, struct fdtable *fdt)
 {
 	__set_bit(fd, fdt->open_fds);
+	fd /= BITS_PER_LONG;
+	if (!~fdt->open_fds[fd])
+		__set_bit(fd, fdt->full_fds_bits);
 }
 
-static inline void __clear_open_fd(int fd, struct fdtable *fdt)
+static inline void __clear_open_fd(unsigned int fd, struct fdtable *fdt)
 {
 	__clear_bit(fd, fdt->open_fds);
+	__clear_bit(fd / BITS_PER_LONG, fdt->full_fds_bits);
 }
 
 static int count_open_files(struct fdtable *fdt)
@@ -280,6 +294,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	new_fdt->max_fds = NR_OPEN_DEFAULT;
 	new_fdt->close_on_exec = newf->close_on_exec_init;
 	new_fdt->open_fds = newf->open_fds_init;
+	new_fdt->full_fds_bits = newf->full_fds_bits_init;
 	new_fdt->fd = &newf->fd_array[0];
 
 	spin_lock(&oldf->file_lock);
@@ -323,6 +338,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 
 	memcpy(new_fdt->open_fds, old_fdt->open_fds, open_files / 8);
 	memcpy(new_fdt->close_on_exec, old_fdt->close_on_exec, open_files / 8);
+	memcpy(new_fdt->full_fds_bits, old_fdt->full_fds_bits, BITBIT_SIZE(open_files));
 
 	for (i = open_files; i != 0; i--) {
 		struct file *f = *old_fds++;
@@ -454,10 +470,25 @@ struct files_struct init_files = {
 		.fd		= &init_files.fd_array[0],
 		.close_on_exec	= init_files.close_on_exec_init,
 		.open_fds	= init_files.open_fds_init,
+		.full_fds_bits	= init_files.full_fds_bits_init,
 	},
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_files.file_lock),
 };
 
+static unsigned long find_next_fd(struct fdtable *fdt, unsigned long start)
+{
+	unsigned long maxfd = fdt->max_fds;
+	unsigned long maxbit = maxfd / BITS_PER_LONG;
+	unsigned long bitbit = start / BITS_PER_LONG;
+
+	bitbit = find_next_zero_bit(fdt->full_fds_bits, maxbit, bitbit) * BITS_PER_LONG;
+	if (bitbit > maxfd)
+		return maxfd;
+	if (bitbit > start)
+		start = bitbit;
+	return find_next_zero_bit(fdt->open_fds, maxfd, start);
+}
+
 /*
  * allocate a file descriptor, mark it busy.
  */
@@ -476,7 +507,7 @@ int __alloc_fd(struct files_struct *files,
 		fd = files->next_fd;
 
 	if (fd < fdt->max_fds)
-		fd = find_next_zero_bit(fdt->open_fds, fdt->max_fds, fd);
+		fd = find_next_fd(fdt, fd);
 
 	/*
 	 * N.B. For clone tasks sharing a files structure, this test

commit 5ba97d2832f87943c43bb69cb1ef86dbc59df5bc
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jun 29 17:10:30 2015 +0200

    fs/file.c: __fget() and dup2() atomicity rules
    
    __fget() does lockless fetch of pointer from the descriptor
    table, attempts to grab a reference and treats "it was already
    zero" as "it's already gone from the table, we just hadn't
    seen the store, let's fail".  Unfortunately, that breaks the
    atomicity of dup2() - __fget() might see the old pointer,
    notice that it's been already dropped and treat that as
    "it's closed".  What we should be getting is either the
    old file or new one, depending whether we come before or after
    dup2().
    
    Dmitry had following test failing sometimes :
    
    int fd;
    void *Thread(void *x) {
      char buf;
      int n = read(fd, &buf, 1);
      if (n != 1)
        exit(printf("read failed: n=%d errno=%d\n", n, errno));
      return 0;
    }
    
    int main()
    {
      fd = open("/dev/urandom", O_RDONLY);
      int fd2 = open("/dev/urandom", O_RDONLY);
      if (fd == -1 || fd2 == -1)
        exit(printf("open failed\n"));
      pthread_t th;
      pthread_create(&th, 0, Thread, 0);
      if (dup2(fd2, fd) == -1)
        exit(printf("dup2 failed\n"));
      pthread_join(th, 0);
      if (close(fd) == -1)
        exit(printf("close failed\n"));
      if (close(fd2) == -1)
        exit(printf("close failed\n"));
      printf("DONE\n");
      return 0;
    }
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 3d2eb4c542a4..6c672ad329e9 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -664,11 +664,17 @@ static struct file *__fget(unsigned int fd, fmode_t mask)
 	struct file *file;
 
 	rcu_read_lock();
+loop:
 	file = fcheck_files(files, fd);
 	if (file) {
-		/* File object ref couldn't be taken */
-		if ((file->f_mode & mask) || !get_file_rcu(file))
+		/* File object ref couldn't be taken.
+		 * dup2() atomicity guarantee is the reason
+		 * we loop to catch the new file (or NULL pointer)
+		 */
+		if (file->f_mode & mask)
 			file = NULL;
+		else if (!get_file_rcu(file))
+			goto loop;
 	}
 	rcu_read_unlock();
 

commit 8a81252b774b53e628a8a0fe18e2b8fc236d92cc
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Jun 30 15:54:08 2015 +0200

    fs/file.c: don't acquire files->file_lock in fd_install()
    
    Mateusz Guzik reported :
    
     Currently obtaining a new file descriptor results in locking fdtable
     twice - once in order to reserve a slot and second time to fill it.
    
    Holding the spinlock in __fd_install() is needed in case a resize is
    done, or to prevent a resize.
    
    Mateusz provided an RFC patch and a micro benchmark :
      http://people.redhat.com/~mguzik/pipebench.c
    
    A resize is an unlikely operation in a process lifetime,
    as table size is at least doubled at every resize.
    
    We can use RCU instead of the spinlock.
    
    __fd_install() must wait if a resize is in progress.
    
    The resize must block new __fd_install() callers from starting,
    and wait that ongoing install are finished (synchronize_sched())
    
    resize should be attempted by a single thread to not waste resources.
    
    rcu_sched variant is used, as __fd_install() and expand_fdtable() run
    from process context.
    
    It gives us a ~30% speedup using pipebench on a dual Intel(R) Xeon(R)
    CPU E5-2696 v2 @ 2.50GHz
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Mateusz Guzik <mguzik@redhat.com>
    Acked-by: Mateusz Guzik <mguzik@redhat.com>
    Tested-by: Mateusz Guzik <mguzik@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 93c5f89c248b..3d2eb4c542a4 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -147,6 +147,13 @@ static int expand_fdtable(struct files_struct *files, int nr)
 
 	spin_unlock(&files->file_lock);
 	new_fdt = alloc_fdtable(nr);
+
+	/* make sure all __fd_install() have seen resize_in_progress
+	 * or have finished their rcu_read_lock_sched() section.
+	 */
+	if (atomic_read(&files->count) > 1)
+		synchronize_sched();
+
 	spin_lock(&files->file_lock);
 	if (!new_fdt)
 		return -ENOMEM;
@@ -158,21 +165,14 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		__free_fdtable(new_fdt);
 		return -EMFILE;
 	}
-	/*
-	 * Check again since another task may have expanded the fd table while
-	 * we dropped the lock
-	 */
 	cur_fdt = files_fdtable(files);
-	if (nr >= cur_fdt->max_fds) {
-		/* Continue as planned */
-		copy_fdtable(new_fdt, cur_fdt);
-		rcu_assign_pointer(files->fdt, new_fdt);
-		if (cur_fdt != &files->fdtab)
-			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
-	} else {
-		/* Somebody else expanded, so undo our attempt */
-		__free_fdtable(new_fdt);
-	}
+	BUG_ON(nr < cur_fdt->max_fds);
+	copy_fdtable(new_fdt, cur_fdt);
+	rcu_assign_pointer(files->fdt, new_fdt);
+	if (cur_fdt != &files->fdtab)
+		call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
+	/* coupled with smp_rmb() in __fd_install() */
+	smp_wmb();
 	return 1;
 }
 
@@ -185,21 +185,38 @@ static int expand_fdtable(struct files_struct *files, int nr)
  * The files->file_lock should be held on entry, and will be held on exit.
  */
 static int expand_files(struct files_struct *files, int nr)
+	__releases(files->file_lock)
+	__acquires(files->file_lock)
 {
 	struct fdtable *fdt;
+	int expanded = 0;
 
+repeat:
 	fdt = files_fdtable(files);
 
 	/* Do we need to expand? */
 	if (nr < fdt->max_fds)
-		return 0;
+		return expanded;
 
 	/* Can we expand? */
 	if (nr >= sysctl_nr_open)
 		return -EMFILE;
 
+	if (unlikely(files->resize_in_progress)) {
+		spin_unlock(&files->file_lock);
+		expanded = 1;
+		wait_event(files->resize_wait, !files->resize_in_progress);
+		spin_lock(&files->file_lock);
+		goto repeat;
+	}
+
 	/* All good, so we try */
-	return expand_fdtable(files, nr);
+	files->resize_in_progress = true;
+	expanded = expand_fdtable(files, nr);
+	files->resize_in_progress = false;
+
+	wake_up_all(&files->resize_wait);
+	return expanded;
 }
 
 static inline void __set_close_on_exec(int fd, struct fdtable *fdt)
@@ -256,6 +273,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	atomic_set(&newf->count, 1);
 
 	spin_lock_init(&newf->file_lock);
+	newf->resize_in_progress = false;
+	init_waitqueue_head(&newf->resize_wait);
 	newf->next_fd = 0;
 	new_fdt = &newf->fdtab;
 	new_fdt->max_fds = NR_OPEN_DEFAULT;
@@ -553,11 +572,21 @@ void __fd_install(struct files_struct *files, unsigned int fd,
 		struct file *file)
 {
 	struct fdtable *fdt;
-	spin_lock(&files->file_lock);
-	fdt = files_fdtable(files);
+
+	might_sleep();
+	rcu_read_lock_sched();
+
+	while (unlikely(files->resize_in_progress)) {
+		rcu_read_unlock_sched();
+		wait_event(files->resize_wait, !files->resize_in_progress);
+		rcu_read_lock_sched();
+	}
+	/* coupled with smp_wmb() in expand_fdtable() */
+	smp_rmb();
+	fdt = rcu_dereference_sched(files->fdt);
 	BUG_ON(fdt->fd[fd] != NULL);
 	rcu_assign_pointer(fdt->fd[fd], file);
-	spin_unlock(&files->file_lock);
+	rcu_read_unlock_sched();
 }
 
 void fd_install(unsigned int fd, struct file *file)

commit 90f31d0ea88880f780574f3d0bb1a227c4c66ca3
Author: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
Date:   Thu Apr 16 12:47:56 2015 -0700

    mm: rcu-protected get_mm_exe_file()
    
    This patch removes mm->mmap_sem from mm->exe_file read side.
    Also it kills dup_mm_exe_file() and moves exe_file duplication into
    dup_mmap() where both mmap_sems are locked.
    
    [akpm@linux-foundation.org: fix comment typo]
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index ee738ea028fa..93c5f89c248b 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -638,8 +638,7 @@ static struct file *__fget(unsigned int fd, fmode_t mask)
 	file = fcheck_files(files, fd);
 	if (file) {
 		/* File object ref couldn't be taken */
-		if ((file->f_mode & mask) ||
-		    !atomic_long_inc_not_zero(&file->f_count))
+		if ((file->f_mode & mask) || !get_file_rcu(file))
 			file = NULL;
 	}
 	rcu_read_unlock();

commit 8d10a035829cacbd84bf35610870c35e566d1242
Author: Yann Droneaud <ydroneaud@opteya.com>
Date:   Wed Dec 10 15:45:44 2014 -0800

    fs/file.c: replace get_unused_fd() with get_unused_fd_flags(0)
    
    This patch replaces calls to get_unused_fd() with equivalent call to
    get_unused_fd_flags(0) to preserve current behavor for existing code.
    
    In a further patch, get_unused_fd() will be removed so that new code
    start using get_unused_fd_flags(), with the hope O_CLOEXEC could be
    used, either by default or choosen by userspace.
    
    Signed-off-by: Yann Droneaud <ydroneaud@opteya.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index ab3eb6a88239..ee738ea028fa 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -869,7 +869,7 @@ SYSCALL_DEFINE1(dup, unsigned int, fildes)
 	struct file *file = fget_raw(fildes);
 
 	if (file) {
-		ret = get_unused_fd();
+		ret = get_unused_fd_flags(0);
 		if (ret >= 0)
 			fd_install(ret, file);
 		else

commit d6dd50e07c5bec00db2005969b1a01f8ca3d25ef
Merge: 5ff0b9e1a1da fd19bda49120
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 13 15:44:12 2014 +0200

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - changes related to No-CBs CPUs and NO_HZ_FULL
    
       - RCU-tasks implementation
    
       - torture-test updates
    
       - miscellaneous fixes
    
       - locktorture updates
    
       - RCU documentation updates"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (81 commits)
      workqueue: Use cond_resched_rcu_qs macro
      workqueue: Add quiescent state between work items
      locktorture: Cleanup header usage
      locktorture: Cannot hold read and write lock
      locktorture: Fix __acquire annotation for spinlock irq
      locktorture: Support rwlocks
      rcu: Eliminate deadlock between CPU hotplug and expedited grace periods
      locktorture: Document boot/module parameters
      rcutorture: Rename rcutorture_runnable parameter
      locktorture: Add test scenario for rwsem_lock
      locktorture: Add test scenario for mutex_lock
      locktorture: Make torture scripting account for new _runnable name
      locktorture: Introduce torture context
      locktorture: Support rwsems
      locktorture: Add infrastructure for torturing read locks
      torture: Address race in module cleanup
      locktorture: Make statistics generic
      locktorture: Teach about lock debugging
      locktorture: Support mutexes
      locktorture: Add documentation
      ...

commit e983094d6dce524f3890edfec44b7ca6dbfa1183
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 31 14:12:09 2014 -0400

    missing annotation in fs/file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 66923fe3176e..f3b2c206c18d 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -750,6 +750,7 @@ bool get_close_on_exec(unsigned int fd)
 
 static int do_dup2(struct files_struct *files,
 	struct file *file, unsigned fd, unsigned flags)
+__releases(&files->file_lock)
 {
 	struct file *tofree;
 	struct fdtable *fdt;

commit bde6c3aa993066acb0d6ce32ecabe03b9d5df92d
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jul 1 11:26:57 2014 -0700

    rcu: Provide cond_resched_rcu_qs() to force quiescent states in long loops
    
    RCU-tasks requires the occasional voluntary context switch
    from CPU-bound in-kernel tasks.  In some cases, this requires
    instrumenting cond_resched().  However, there is some reluctance
    to countenance unconditionally instrumenting cond_resched() (see
    http://lwn.net/Articles/603252/), so this commit creates a separate
    cond_resched_rcu_qs() that may be used in place of cond_resched() in
    locations prone to long-duration in-kernel looping.
    
    This commit currently instruments only RCU-tasks.  Future possibilities
    include also instrumenting RCU, RCU-bh, and RCU-sched in order to reduce
    IPI usage.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/fs/file.c b/fs/file.c
index 66923fe3176e..1cafc4c9275b 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -367,7 +367,7 @@ static struct fdtable *close_files(struct files_struct * files)
 				struct file * file = xchg(&fdt->fd[i], NULL);
 				if (file) {
 					filp_close(file, files);
-					cond_resched();
+					cond_resched_rcu_qs();
 				}
 			}
 			i++;

commit f6c0a1920e0180175bd5e8e4aff8ea5556f1895d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Apr 23 10:18:46 2014 -0400

    fs/file.c: don't open-code kvfree()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 8f294cfac697..66923fe3176e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -44,15 +44,10 @@ static void *alloc_fdmem(size_t size)
 	return vmalloc(size);
 }
 
-static void free_fdmem(void *ptr)
-{
-	is_vmalloc_addr(ptr) ? vfree(ptr) : kfree(ptr);
-}
-
 static void __free_fdtable(struct fdtable *fdt)
 {
-	free_fdmem(fdt->fd);
-	free_fdmem(fdt->open_fds);
+	kvfree(fdt->fd);
+	kvfree(fdt->open_fds);
 	kfree(fdt);
 }
 
@@ -130,7 +125,7 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	return fdt;
 
 out_arr:
-	free_fdmem(fdt->fd);
+	kvfree(fdt->fd);
 out_fdt:
 	kfree(fdt);
 out:

commit 5166701b368caea89d57b14bf41cf39e819dad51
Merge: 0a7418f5f569 a786c06d9f27
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 12 14:49:50 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "The first vfs pile, with deep apologies for being very late in this
      window.
    
      Assorted cleanups and fixes, plus a large preparatory part of iov_iter
      work.  There's a lot more of that, but it'll probably go into the next
      merge window - it *does* shape up nicely, removes a lot of
      boilerplate, gets rid of locking inconsistencie between aio_write and
      splice_write and I hope to get Kent's direct-io rewrite merged into
      the same queue, but some of the stuff after this point is having
      (mostly trivial) conflicts with the things already merged into
      mainline and with some I want more testing.
    
      This one passes LTP and xfstests without regressions, in addition to
      usual beating.  BTW, readahead02 in ltp syscalls testsuite has started
      giving failures since "mm/readahead.c: fix readahead failure for
      memoryless NUMA nodes and limit readahead pages" - might be a false
      positive, might be a real regression..."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (63 commits)
      missing bits of "splice: fix racy pipe->buffers uses"
      cifs: fix the race in cifs_writev()
      ceph_sync_{,direct_}write: fix an oops on ceph_osdc_new_request() failure
      kill generic_file_buffered_write()
      ocfs2_file_aio_write(): switch to generic_perform_write()
      ceph_aio_write(): switch to generic_perform_write()
      xfs_file_buffered_aio_write(): switch to generic_perform_write()
      export generic_perform_write(), start getting rid of generic_file_buffer_write()
      generic_file_direct_write(): get rid of ppos argument
      btrfs_file_aio_write(): get rid of ppos
      kill the 5th argument of generic_file_buffered_write()
      kill the 4th argument of __generic_file_aio_write()
      lustre: don't open-code kernel_recvmsg()
      ocfs2: don't open-code kernel_recvmsg()
      drbd: don't open-code kernel_recvmsg()
      constify blk_rq_map_user_iov() and friends
      lustre: switch to kernel_sendmsg()
      ocfs2: don't open-code kernel_sendmsg()
      take iov_iter stuff to mm/iov_iter.c
      process_vm_access: tidy up a bit
      ...

commit 7f4b36f9bb930b3b2105a9a2cb0121fa7028c432
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Mar 14 12:45:29 2014 -0400

    get rid of files_defer_init()
    
    the only thing it's doing these days is calculation of
    upper limit for fs.nr_open sysctl and that can be done
    statically
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index eb56a13dab3e..682103b95f8f 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -25,7 +25,10 @@
 
 int sysctl_nr_open __read_mostly = 1024*1024;
 int sysctl_nr_open_min = BITS_PER_LONG;
-int sysctl_nr_open_max = 1024 * 1024; /* raised later */
+/* our max() is unusable in constant expressions ;-/ */
+#define __const_max(x, y) ((x) < (y) ? (x) : (y))
+int sysctl_nr_open_max = __const_max(INT_MAX, ~(size_t)0/sizeof(void *)) &
+			 -BITS_PER_LONG;
 
 static void *alloc_fdmem(size_t size)
 {
@@ -429,12 +432,6 @@ void exit_files(struct task_struct *tsk)
 	}
 }
 
-void __init files_defer_init(void)
-{
-	sysctl_nr_open_max = min((size_t)INT_MAX, ~(size_t)0/sizeof(void *)) &
-			     -BITS_PER_LONG;
-}
-
 struct files_struct init_files = {
 	.count		= ATOMIC_INIT(1),
 	.fdt		= &init_files.fdtab,

commit b3fd4ea9df2d5c39cd6ce08faf965ed669eb3b56
Merge: 462bf234a82a 7de700e6806c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 31 11:05:24 2014 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "Main changes:
    
       - Torture-test changes, including refactoring of rcutorture and
         introduction of a vestigial locktorture.
    
       - Real-time latency fixes.
    
       - Documentation updates.
    
       - Miscellaneous fixes"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (77 commits)
      rcu: Provide grace-period piggybacking API
      rcu: Ensure kernel/rcu/rcu.h can be sourced/used stand-alone
      rcu: Fix sparse warning for rcu_expedited from kernel/ksysfs.c
      notifier: Substitute rcu_access_pointer() for rcu_dereference_raw()
      Documentation/memory-barriers.txt: Clarify release/acquire ordering
      rcutorture: Save kvm.sh output to log
      rcutorture: Add a lock_busted to test the test
      rcutorture: Place kvm-test-1-run.sh output into res directory
      rcutorture: Rename TREE_RCU-Kconfig.txt
      locktorture: Add kvm-recheck.sh plug-in for locktorture
      rcutorture: Gracefully handle NULL cleanup hooks
      locktorture: Add vestigial locktorture configuration
      rcutorture: Introduce "rcu" directory level underneath configs
      rcutorture: Rename kvm-test-1-rcu.sh
      rcutorture: Remove RCU dependencies from ver_functions.sh API
      rcutorture: Create CFcommon file for common Kconfig parameters
      rcutorture: Create config files for scripted test-the-test testing
      rcutorture: Add an rcu_busted to test the test
      locktorture: Add a lock-torture kernel module
      rcutorture: Abstract kvm-recheck.sh
      ...

commit 99aea68134f3c2a27b4d463c91cfa298c3efaccf
Author: Eric Biggers <ebiggers3@gmail.com>
Date:   Sun Mar 16 15:47:48 2014 -0500

    vfs: Don't let __fdget_pos() get FMODE_PATH files
    
    Commit bd2a31d522344 ("get rid of fget_light()") introduced the
    __fdget_pos() function, which returns the resulting file pointer and
    fdput flags combined in an 'unsigned long'.  However, it also changed the
    behavior to return files with FMODE_PATH set, which shouldn't happen
    because read(), write(), lseek(), etc. aren't allowed on such files.
    This commit restores the old behavior.
    
    This regression actually had no effect on read() and write() since
    FMODE_READ and FMODE_WRITE are not set on file descriptors opened with
    O_PATH, but it did cause lseek() on a file descriptor opened with O_PATH
    to fail with ESPIPE rather than EBADF.
    
    Signed-off-by: Eric Biggers <ebiggers3@gmail.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 60a45e9f5323..eb56a13dab3e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -713,27 +713,16 @@ unsigned long __fdget_raw(unsigned int fd)
 
 unsigned long __fdget_pos(unsigned int fd)
 {
-	struct files_struct *files = current->files;
-	struct file *file;
-	unsigned long v;
-
-	if (atomic_read(&files->count) == 1) {
-		file = __fcheck_files(files, fd);
-		v = 0;
-	} else {
-		file = __fget(fd, 0);
-		v = FDPUT_FPUT;
-	}
-	if (!file)
-		return 0;
+	unsigned long v = __fdget(fd);
+	struct file *file = (struct file *)(v & ~3);
 
-	if (file->f_mode & FMODE_ATOMIC_POS) {
+	if (file && (file->f_mode & FMODE_ATOMIC_POS)) {
 		if (file_count(file) > 1) {
 			v |= FDPUT_POS_UNLOCK;
 			mutex_lock(&file->f_pos_lock);
 		}
 	}
-	return v | (unsigned long)file;
+	return v;
 }
 
 /*

commit bd2a31d522344b3ac2fb680bd2366e77a9bd8209
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 4 14:54:22 2014 -0500

    get rid of fget_light()
    
    instead of returning the flags by reference, we can just have the
    low-level primitive return those in lower bits of unsigned long,
    with struct file * derived from the rest.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index db25c2bdfe46..60a45e9f5323 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -683,35 +683,65 @@ EXPORT_SYMBOL(fget_raw);
  * The fput_needed flag returned by fget_light should be passed to the
  * corresponding fput_light.
  */
-struct file *__fget_light(unsigned int fd, fmode_t mask, int *fput_needed)
+static unsigned long __fget_light(unsigned int fd, fmode_t mask)
 {
 	struct files_struct *files = current->files;
 	struct file *file;
 
-	*fput_needed = 0;
 	if (atomic_read(&files->count) == 1) {
 		file = __fcheck_files(files, fd);
-		if (file && (file->f_mode & mask))
-			file = NULL;
+		if (!file || unlikely(file->f_mode & mask))
+			return 0;
+		return (unsigned long)file;
 	} else {
 		file = __fget(fd, mask);
-		if (file)
-			*fput_needed = 1;
+		if (!file)
+			return 0;
+		return FDPUT_FPUT | (unsigned long)file;
 	}
-
-	return file;
 }
-struct file *fget_light(unsigned int fd, int *fput_needed)
+unsigned long __fdget(unsigned int fd)
 {
-	return __fget_light(fd, FMODE_PATH, fput_needed);
+	return __fget_light(fd, FMODE_PATH);
 }
-EXPORT_SYMBOL(fget_light);
+EXPORT_SYMBOL(__fdget);
 
-struct file *fget_raw_light(unsigned int fd, int *fput_needed)
+unsigned long __fdget_raw(unsigned int fd)
 {
-	return __fget_light(fd, 0, fput_needed);
+	return __fget_light(fd, 0);
+}
+
+unsigned long __fdget_pos(unsigned int fd)
+{
+	struct files_struct *files = current->files;
+	struct file *file;
+	unsigned long v;
+
+	if (atomic_read(&files->count) == 1) {
+		file = __fcheck_files(files, fd);
+		v = 0;
+	} else {
+		file = __fget(fd, 0);
+		v = FDPUT_FPUT;
+	}
+	if (!file)
+		return 0;
+
+	if (file->f_mode & FMODE_ATOMIC_POS) {
+		if (file_count(file) > 1) {
+			v |= FDPUT_POS_UNLOCK;
+			mutex_lock(&file->f_pos_lock);
+		}
+	}
+	return v | (unsigned long)file;
 }
 
+/*
+ * We only lock f_pos if we have threads or if the file might be
+ * shared with another process. In both cases we'll have an elevated
+ * file count (done either by fdget() or by fork()).
+ */
+
 void set_close_on_exec(unsigned int fd, int flag)
 {
 	struct files_struct *files = current->files;

commit add1f0995454374d90c9d6b2c420d2fba3d0a4e3
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Feb 12 12:51:09 2014 -0800

    fs: Substitute rcu_access_pointer() for rcu_dereference_raw()
    
    (Trivial patch.)
    
    If the code is looking at the RCU-protected pointer itself, but not
    dereferencing it, the rcu_dereference() functions can be downgraded to
    rcu_access_pointer().  This commit makes this downgrade in __alloc_fd(),
    which simply compares the RCU-protected pointer against NULL with no
    dereferencing.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: linux-fsdevel@vger.kernel.org
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/fs/file.c b/fs/file.c
index db25c2bdfe46..18f7d27855c4 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -497,7 +497,7 @@ int __alloc_fd(struct files_struct *files,
 	error = fd;
 #if 1
 	/* Sanity check */
-	if (rcu_dereference_raw(fdt->fd[fd]) != NULL) {
+	if (rcu_access_pointer(fdt->fd[fd]) != NULL) {
 		printk(KERN_WARNING "alloc_fd: slot %d not NULL!\n", fd);
 		rcu_assign_pointer(fdt->fd[fd], NULL);
 	}

commit 96c7a2ff21501691587e1ae969b83cbec8b78e08
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Feb 10 14:25:41 2014 -0800

    fs/file.c:fdtable: avoid triggering OOMs from alloc_fdmem
    
    Recently due to a spike in connections per second memcached on 3
    separate boxes triggered the OOM killer from accept.  At the time the
    OOM killer was triggered there was 4GB out of 36GB free in zone 1.  The
    problem was that alloc_fdtable was allocating an order 3 page (32KiB) to
    hold a bitmap, and there was sufficient fragmentation that the largest
    page available was 8KiB.
    
    I find the logic that PAGE_ALLOC_COSTLY_ORDER can't fail pretty dubious
    but I do agree that order 3 allocations are very likely to succeed.
    
    There are always pathologies where order > 0 allocations can fail when
    there are copious amounts of free memory available.  Using the pigeon
    hole principle it is easy to show that it requires 1 page more than 50%
    of the pages being free to guarantee an order 1 (8KiB) allocation will
    succeed, 1 page more than 75% of the pages being free to guarantee an
    order 2 (16KiB) allocation will succeed and 1 page more than 87.5% of
    the pages being free to guarantee an order 3 allocate will succeed.
    
    A server churning memory with a lot of small requests and replies like
    memcached is a common case that if anything can will skew the odds
    against large pages being available.
    
    Therefore let's not give external applications a practical way to kill
    linux server applications, and specify __GFP_NORETRY to the kmalloc in
    alloc_fdmem.  Unless I am misreading the code and by the time the code
    reaches should_alloc_retry in __alloc_pages_slowpath (where
    __GFP_NORETRY becomes signification).  We have already tried everything
    reasonable to allocate a page and the only thing left to do is wait.  So
    not waiting and falling back to vmalloc immediately seems like the
    reasonable thing to do even if there wasn't a chance of triggering the
    OOM killer.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Cong Wang <cwang@twopensource.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 771578b33fb6..db25c2bdfe46 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -34,7 +34,7 @@ static void *alloc_fdmem(size_t size)
 	 * vmalloc() if the allocation size will be considered "large" by the VM.
 	 */
 	if (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {
-		void *data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN);
+		void *data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN|__GFP_NORETRY);
 		if (data != NULL)
 			return data;
 	}

commit e6ff9a9fa4e05c1c03dec63cdc6a87d6dea02755
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 13 16:49:06 2014 +0100

    fs: __fget_light() can use __fget() in slow path
    
    The slow path in __fget_light() can use __fget() to avoid the
    code duplication. Saves 232 bytes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 50c1208f6450..771578b33fb6 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -694,17 +694,9 @@ struct file *__fget_light(unsigned int fd, fmode_t mask, int *fput_needed)
 		if (file && (file->f_mode & mask))
 			file = NULL;
 	} else {
-		rcu_read_lock();
-		file = fcheck_files(files, fd);
-		if (file) {
-			if (!(file->f_mode & mask) &&
-			    atomic_long_inc_not_zero(&file->f_count))
-				*fput_needed = 1;
-			else
-				/* Didn't get the reference, someone's freed */
-				file = NULL;
-		}
-		rcu_read_unlock();
+		file = __fget(fd, mask);
+		if (file)
+			*fput_needed = 1;
 	}
 
 	return file;

commit ad46183445043b562856c60b74db664668fb364b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 13 16:48:40 2014 +0100

    fs: factor out common code in fget_light() and fget_raw_light()
    
    Apart from FMODE_PATH check fget_light() and fget_raw_light() are
    identical, shift the code into the new helper, __fget_light(fd, mask).
    Saves 208 bytes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 4ed58a32575e..50c1208f6450 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -683,21 +683,21 @@ EXPORT_SYMBOL(fget_raw);
  * The fput_needed flag returned by fget_light should be passed to the
  * corresponding fput_light.
  */
-struct file *fget_light(unsigned int fd, int *fput_needed)
+struct file *__fget_light(unsigned int fd, fmode_t mask, int *fput_needed)
 {
-	struct file *file;
 	struct files_struct *files = current->files;
+	struct file *file;
 
 	*fput_needed = 0;
 	if (atomic_read(&files->count) == 1) {
 		file = __fcheck_files(files, fd);
-		if (file && (file->f_mode & FMODE_PATH))
+		if (file && (file->f_mode & mask))
 			file = NULL;
 	} else {
 		rcu_read_lock();
 		file = fcheck_files(files, fd);
 		if (file) {
-			if (!(file->f_mode & FMODE_PATH) &&
+			if (!(file->f_mode & mask) &&
 			    atomic_long_inc_not_zero(&file->f_count))
 				*fput_needed = 1;
 			else
@@ -709,30 +709,15 @@ struct file *fget_light(unsigned int fd, int *fput_needed)
 
 	return file;
 }
+struct file *fget_light(unsigned int fd, int *fput_needed)
+{
+	return __fget_light(fd, FMODE_PATH, fput_needed);
+}
 EXPORT_SYMBOL(fget_light);
 
 struct file *fget_raw_light(unsigned int fd, int *fput_needed)
 {
-	struct file *file;
-	struct files_struct *files = current->files;
-
-	*fput_needed = 0;
-	if (atomic_read(&files->count) == 1) {
-		file = __fcheck_files(files, fd);
-	} else {
-		rcu_read_lock();
-		file = fcheck_files(files, fd);
-		if (file) {
-			if (atomic_long_inc_not_zero(&file->f_count))
-				*fput_needed = 1;
-			else
-				/* Didn't get the reference, someone's freed */
-				file = NULL;
-		}
-		rcu_read_unlock();
-	}
-
-	return file;
+	return __fget_light(fd, 0, fput_needed);
 }
 
 void set_close_on_exec(unsigned int fd, int flag)

commit 1deb46e2562561255c34075825fd00f22a858bb3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 13 16:48:19 2014 +0100

    fs: factor out common code in fget() and fget_raw()
    
    Apart from FMODE_PATH check fget() and fget_raw() are identical,
    shift the code into the new simple helper, __fget(fd, mask). Saves
    160 bytes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index d34e59e51743..4ed58a32575e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -637,16 +637,16 @@ void do_close_on_exec(struct files_struct *files)
 	spin_unlock(&files->file_lock);
 }
 
-struct file *fget(unsigned int fd)
+static struct file *__fget(unsigned int fd, fmode_t mask)
 {
-	struct file *file;
 	struct files_struct *files = current->files;
+	struct file *file;
 
 	rcu_read_lock();
 	file = fcheck_files(files, fd);
 	if (file) {
 		/* File object ref couldn't be taken */
-		if (file->f_mode & FMODE_PATH ||
+		if ((file->f_mode & mask) ||
 		    !atomic_long_inc_not_zero(&file->f_count))
 			file = NULL;
 	}
@@ -655,25 +655,16 @@ struct file *fget(unsigned int fd)
 	return file;
 }
 
+struct file *fget(unsigned int fd)
+{
+	return __fget(fd, FMODE_PATH);
+}
 EXPORT_SYMBOL(fget);
 
 struct file *fget_raw(unsigned int fd)
 {
-	struct file *file;
-	struct files_struct *files = current->files;
-
-	rcu_read_lock();
-	file = fcheck_files(files, fd);
-	if (file) {
-		/* File object ref couldn't be taken */
-		if (!atomic_long_inc_not_zero(&file->f_count))
-			file = NULL;
-	}
-	rcu_read_unlock();
-
-	return file;
+	return __fget(fd, 0);
 }
-
 EXPORT_SYMBOL(fget_raw);
 
 /*

commit ce08b62d18b3f97cd4e5a39bd5898872b9201875
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Jan 11 19:19:53 2014 +0100

    change close_files() to use rcu_dereference_raw(files->fdt)
    
    put_files_struct() and close_files() do rcu_read_lock() to make
    rcu_dereference_check_fdtable() happy.
    
    This looks a bit ugly, files_fdtable() just reads the pointer,
    we can simply use rcu_dereference_raw() to avoid the warning.
    
    The patch also changes close_files() to return fdt, this avoids
    another rcu_read_lock()/files_fdtable() in put_files_struct().
    
    I think close_files() needs more cleanups:
    
            - we do not need xchg() exactly because we are the last
              user of this files_struct
    
            - "if (file)" should be turned into WARN_ON(!file)
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 957cbc09b0db..d34e59e51743 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -348,21 +348,16 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	return NULL;
 }
 
-static void close_files(struct files_struct * files)
+static struct fdtable *close_files(struct files_struct * files)
 {
-	int i, j;
-	struct fdtable *fdt;
-
-	j = 0;
-
 	/*
 	 * It is safe to dereference the fd table without RCU or
 	 * ->file_lock because this is the last reference to the
-	 * files structure.  But use RCU to shut RCU-lockdep up.
+	 * files structure.
 	 */
-	rcu_read_lock();
-	fdt = files_fdtable(files);
-	rcu_read_unlock();
+	struct fdtable *fdt = rcu_dereference_raw(files->fdt);
+	int i, j = 0;
+
 	for (;;) {
 		unsigned long set;
 		i = j * BITS_PER_LONG;
@@ -381,6 +376,8 @@ static void close_files(struct files_struct * files)
 			set >>= 1;
 		}
 	}
+
+	return fdt;
 }
 
 struct files_struct *get_files_struct(struct task_struct *task)
@@ -398,14 +395,9 @@ struct files_struct *get_files_struct(struct task_struct *task)
 
 void put_files_struct(struct files_struct *files)
 {
-	struct fdtable *fdt;
-
 	if (atomic_dec_and_test(&files->count)) {
-		close_files(files);
-		/* not really needed, since nobody can see us */
-		rcu_read_lock();
-		fdt = files_fdtable(files);
-		rcu_read_unlock();
+		struct fdtable *fdt = close_files(files);
+
 		/* free the arrays if they are not embedded */
 		if (fdt != &files->fdtab)
 			__free_fdtable(fdt);

commit a8d4b8345e0ee48b732126d980efaf0dc373e2b0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Jan 11 19:19:32 2014 +0100

    introduce __fcheck_files() to fix rcu_dereference_check_fdtable(), kill rcu_my_thread_group_empty()
    
    rcu_dereference_check_fdtable() looks very wrong,
    
    1. rcu_my_thread_group_empty() was added by 844b9a8707f1 "vfs: fix
       RCU-lockdep false positive due to /proc" but it doesn't really
       fix the problem. A CLONE_THREAD (without CLONE_FILES) task can
       hit the same race with get_files_struct().
    
       And otoh rcu_my_thread_group_empty() can suppress the correct
       warning if the caller is the CLONE_FILES (without CLONE_THREAD)
       task.
    
    2. files->count == 1 check is not really right too. Even if this
       files_struct is not shared it is not safe to access it lockless
       unless the caller is the owner.
    
       Otoh, this check is sub-optimal. files->count == 0 always means
       it is safe to use it lockless even if files != current->files,
       but put_files_struct() has to take rcu_read_lock(). See the next
       patch.
    
    This patch removes the buggy checks and turns fcheck_files() into
    __fcheck_files() which uses rcu_dereference_raw(), the "unshared"
    callers, fget_light() and fget_raw_light(), can use it to avoid
    the warning from RCU-lockdep.
    
    fcheck_files() is trivially reimplemented as rcu_lockdep_assert()
    plus __fcheck_files().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 4a78f981557a..957cbc09b0db 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -707,7 +707,7 @@ struct file *fget_light(unsigned int fd, int *fput_needed)
 
 	*fput_needed = 0;
 	if (atomic_read(&files->count) == 1) {
-		file = fcheck_files(files, fd);
+		file = __fcheck_files(files, fd);
 		if (file && (file->f_mode & FMODE_PATH))
 			file = NULL;
 	} else {
@@ -735,7 +735,7 @@ struct file *fget_raw_light(unsigned int fd, int *fput_needed)
 
 	*fput_needed = 0;
 	if (atomic_read(&files->count) == 1) {
-		file = fcheck_files(files, fd);
+		file = __fcheck_files(files, fd);
 	} else {
 		rcu_read_lock();
 		file = fcheck_files(files, fd);

commit ac3e3c5b1164397656df81b9e9ab4991184d3236
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Apr 28 21:42:33 2013 -0400

    don't bother with deferred freeing of fdtables
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 3906d9577a18..4a78f981557a 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -23,24 +23,10 @@
 #include <linux/rcupdate.h>
 #include <linux/workqueue.h>
 
-struct fdtable_defer {
-	spinlock_t lock;
-	struct work_struct wq;
-	struct fdtable *next;
-};
-
 int sysctl_nr_open __read_mostly = 1024*1024;
 int sysctl_nr_open_min = BITS_PER_LONG;
 int sysctl_nr_open_max = 1024 * 1024; /* raised later */
 
-/*
- * We use this list to defer free fdtables that have vmalloced
- * sets/arrays. By keeping a per-cpu list, we avoid having to embed
- * the work_struct in fdtable itself which avoids a 64 byte (i386) increase in
- * this per-task structure.
- */
-static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
-
 static void *alloc_fdmem(size_t size)
 {
 	/*
@@ -67,46 +53,9 @@ static void __free_fdtable(struct fdtable *fdt)
 	kfree(fdt);
 }
 
-static void free_fdtable_work(struct work_struct *work)
-{
-	struct fdtable_defer *f =
-		container_of(work, struct fdtable_defer, wq);
-	struct fdtable *fdt;
-
-	spin_lock_bh(&f->lock);
-	fdt = f->next;
-	f->next = NULL;
-	spin_unlock_bh(&f->lock);
-	while(fdt) {
-		struct fdtable *next = fdt->next;
-
-		__free_fdtable(fdt);
-		fdt = next;
-	}
-}
-
 static void free_fdtable_rcu(struct rcu_head *rcu)
 {
-	struct fdtable *fdt = container_of(rcu, struct fdtable, rcu);
-	struct fdtable_defer *fddef;
-
-	BUG_ON(!fdt);
-	BUG_ON(fdt->max_fds <= NR_OPEN_DEFAULT);
-
-	if (!is_vmalloc_addr(fdt->fd) && !is_vmalloc_addr(fdt->open_fds)) {
-		kfree(fdt->fd);
-		kfree(fdt->open_fds);
-		kfree(fdt);
-	} else {
-		fddef = &get_cpu_var(fdtable_defer_list);
-		spin_lock(&fddef->lock);
-		fdt->next = fddef->next;
-		fddef->next = fdt;
-		/* vmallocs are handled from the workqueue context */
-		schedule_work(&fddef->wq);
-		spin_unlock(&fddef->lock);
-		put_cpu_var(fdtable_defer_list);
-	}
+	__free_fdtable(container_of(rcu, struct fdtable, rcu));
 }
 
 /*
@@ -174,7 +123,6 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	fdt->open_fds = data;
 	data += nr / BITS_PER_BYTE;
 	fdt->close_on_exec = data;
-	fdt->next = NULL;
 
 	return fdt;
 
@@ -221,7 +169,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		/* Continue as planned */
 		copy_fdtable(new_fdt, cur_fdt);
 		rcu_assign_pointer(files->fdt, new_fdt);
-		if (cur_fdt->max_fds > NR_OPEN_DEFAULT)
+		if (cur_fdt != &files->fdtab)
 			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
@@ -316,7 +264,6 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	new_fdt->close_on_exec = newf->close_on_exec_init;
 	new_fdt->open_fds = newf->open_fds_init;
 	new_fdt->fd = &newf->fd_array[0];
-	new_fdt->next = NULL;
 
 	spin_lock(&oldf->file_lock);
 	old_fdt = files_fdtable(oldf);
@@ -490,19 +437,8 @@ void exit_files(struct task_struct *tsk)
 	}
 }
 
-static void fdtable_defer_list_init(int cpu)
-{
-	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);
-	spin_lock_init(&fddef->lock);
-	INIT_WORK(&fddef->wq, free_fdtable_work);
-	fddef->next = NULL;
-}
-
 void __init files_defer_init(void)
 {
-	int i;
-	for_each_possible_cpu(i)
-		fdtable_defer_list_init(i);
 	sysctl_nr_open_max = min((size_t)INT_MAX, ~(size_t)0/sizeof(void *)) &
 			     -BITS_PER_LONG;
 }

commit eece09ec213e93333010bf4c6bb9175b32229c54
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 17 21:25:03 2011 +0200

    locking: Various static lock initializer fixes
    
    The static lock initializers want to be fed the proper name of the
    lock and not some random string. In mainline random strings are
    obfuscating the readability of debug output, but for RT they prevent
    the spinlock substitution. Fix it up.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/fs/file.c b/fs/file.c
index 2b3570b7caeb..3906d9577a18 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -516,7 +516,7 @@ struct files_struct init_files = {
 		.close_on_exec	= init_files.close_on_exec_init,
 		.open_fds	= init_files.open_fds_init,
 	},
-	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
+	.file_lock	= __SPIN_LOCK_UNLOCKED(init_files.file_lock),
 };
 
 /*

commit 6ae141718e3f9c7e2c620e999c86612a7f415bb1
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Dec 21 15:16:45 2012 -0800

    misc: remove __dev* attributes.
    
    CONFIG_HOTPLUG is going away as an option.  As a result, the __dev*
    markings need to be removed.
    
    This change removes the last of the __dev* markings from the kernel from
    a variety of different, tiny, places.
    
    Based on patches originally written by Bill Pemberton, but redone by me
    in order to handle some of the coding style issues better, by hand.
    
    Cc: Bill Pemberton <wfp5p@virginia.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/file.c b/fs/file.c
index 15cb8618e95d..2b3570b7caeb 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -490,7 +490,7 @@ void exit_files(struct task_struct *tsk)
 	}
 }
 
-static void __devinit fdtable_defer_list_init(int cpu)
+static void fdtable_defer_list_init(int cpu)
 {
 	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);
 	spin_lock_init(&fddef->lock);

commit 9977d9b379cb77e0f67bd6f4563618106e58e11d
Merge: cf4af0122157 541880d9a2c7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 12 12:22:13 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull big execve/kernel_thread/fork unification series from Al Viro:
     "All architectures are converted to new model.  Quite a bit of that
      stuff is actually shared with architecture trees; in such cases it's
      literally shared branch pulled by both, not a cherry-pick.
    
      A lot of ugliness and black magic is gone (-3KLoC total in this one):
    
       - kernel_thread()/kernel_execve()/sys_execve() redesign.
    
         We don't do syscalls from kernel anymore for either kernel_thread()
         or kernel_execve():
    
         kernel_thread() is essentially clone(2) with callback run before we
         return to userland, the callbacks either never return or do
         successful do_execve() before returning.
    
         kernel_execve() is a wrapper for do_execve() - it doesn't need to
         do transition to user mode anymore.
    
         As a result kernel_thread() and kernel_execve() are
         arch-independent now - they live in kernel/fork.c and fs/exec.c
         resp.  sys_execve() is also in fs/exec.c and it's completely
         architecture-independent.
    
       - daemonize() is gone, along with its parts in fs/*.c
    
       - struct pt_regs * is no longer passed to do_fork/copy_process/
         copy_thread/do_execve/search_binary_handler/->load_binary/do_coredump.
    
       - sys_fork()/sys_vfork()/sys_clone() unified; some architectures
         still need wrappers (ones with callee-saved registers not saved in
         pt_regs on syscall entry), but the main part of those suckers is in
         kernel/fork.c now."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (113 commits)
      do_coredump(): get rid of pt_regs argument
      print_fatal_signal(): get rid of pt_regs argument
      ptrace_signal(): get rid of unused arguments
      get rid of ptrace_signal_deliver() arguments
      new helper: signal_pt_regs()
      unify default ptrace_signal_deliver
      flagday: kill pt_regs argument of do_fork()
      death to idle_regs()
      don't pass regs to copy_process()
      flagday: don't pass regs to copy_thread()
      bfin: switch to generic vfork, get rid of pointless wrappers
      xtensa: switch to generic clone()
      openrisc: switch to use of generic fork and clone
      unicore32: switch to generic clone(2)
      score: switch to generic fork/vfork/clone
      c6x: sanitize copy_thread(), get rid of clone(2) wrapper, switch to generic clone()
      take sys_fork/sys_vfork/sys_clone prototypes to linux/syscalls.h
      mn10300: switch to generic fork/vfork/clone
      h8300: switch to generic fork/vfork/clone
      tile: switch to generic clone()
      ...
    
    Conflicts:
            arch/microblaze/include/asm/Kbuild

commit a77cfcb429ed98845a4e4df72473b8f37acd890b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Nov 29 22:57:33 2012 -0500

    fix off-by-one in argument passed by iterate_fd() to callbacks
    
    Noticed by Pavel Roskin; the thing in his patch I disagree with
    was compensating for that shite in callbacks instead of fixing
    it once in the iterator itself.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 7cb71b992603..eff23162485f 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -994,16 +994,18 @@ int iterate_fd(struct files_struct *files, unsigned n,
 		const void *p)
 {
 	struct fdtable *fdt;
-	struct file *file;
 	int res = 0;
 	if (!files)
 		return 0;
 	spin_lock(&files->file_lock);
-	fdt = files_fdtable(files);
-	while (!res && n < fdt->max_fds) {
-		file = rcu_dereference_check_fdtable(files, fdt->fd[n++]);
-		if (file)
-			res = f(p, file, n);
+	for (fdt = files_fdtable(files); n < fdt->max_fds; n++) {
+		struct file *file;
+		file = rcu_dereference_check_fdtable(files, fdt->fd[n]);
+		if (!file)
+			continue;
+		res = f(p, file, n);
+		if (res)
+			break;
 	}
 	spin_unlock(&files->file_lock);
 	return res;

commit c4144670fd9b34d6eae22c9f83751745898e8243
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Oct 2 16:34:38 2012 -0400

    kill daemonize()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 7cb71b992603..7272a1c5831d 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -519,12 +519,6 @@ struct files_struct init_files = {
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
 };
 
-void daemonize_descriptors(void)
-{
-	atomic_inc(&init_files.count);
-	reset_files_struct(&init_files);
-}
-
 /*
  * allocate a file descriptor, mark it busy.
  */

commit 8d938105e432fe0e9f5163147e9c113190bd9d32
Merge: aa7202c25143 5a8477660d9d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 18 09:13:48 2012 -1000

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc VFS fixes from Al Viro:
     "Remove a bogus BUG_ON() that can trigger spuriously + alpha bits of
      do_mount() constification I'd missed during the merge window."
    
    This pull request came in a week ago, I missed it for some reason.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      kill bogus BUG_ON() in do_close_on_exec()
      missing const in alpha callers of do_mount()

commit 5a8477660d9ddc090203736d7271137265cb25bb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 12 01:19:02 2012 -0500

    kill bogus BUG_ON() in do_close_on_exec()
    
    It can be legitimately triggered via procfs access.  Now, at least
    2 of 3 of get_files_struct() callers in procfs are useless, but
    when and if we get rid of those we can always add WARN_ON() here.
    BUG_ON() at that spot is simply wrong.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index d3b5fa80b71b..331e7d24d9d3 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -685,7 +685,6 @@ void do_close_on_exec(struct files_struct *files)
 	struct fdtable *fdt;
 
 	/* exec unshares first */
-	BUG_ON(atomic_read(&files->count) != 1);
 	spin_lock(&files->file_lock);
 	for (i = 0; ; i++) {
 		unsigned long set;

commit 08f05c49749ee655bef921d12160960a273aad47
Author: Al Viro <viro@ZenIV.linux.org.uk>
Date:   Wed Oct 31 03:37:48 2012 +0000

    Return the right error value when dup[23]() newfd argument is too large
    
    Jack Lin reports that the error return from dup3() for the RLIMIT_NOFILE
    case changed incorrectly after 3.6.
    
    The culprit is commit f33ff9927f42 ("take rlimit check to callers of
    expand_files()") which when it moved the "return -EMFILE" out to the
    caller, didn't notice that the dup3() had special code to turn the
    EMFILE return into EBADF.
    
    The replace_fd() helper that got added later then inherited the bug too.
    
    Reported-by: Jack Lin <linliangjie@huawei.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    [ Noted more bugs, wrote proper changelog, fixed up typos - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index d3b5fa80b71b..708d997a7748 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -900,7 +900,7 @@ int replace_fd(unsigned fd, struct file *file, unsigned flags)
 		return __close_fd(files, fd);
 
 	if (fd >= rlimit(RLIMIT_NOFILE))
-		return -EMFILE;
+		return -EBADF;
 
 	spin_lock(&files->file_lock);
 	err = expand_files(files, fd);
@@ -926,7 +926,7 @@ SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
 		return -EINVAL;
 
 	if (newfd >= rlimit(RLIMIT_NOFILE))
-		return -EMFILE;
+		return -EBADF;
 
 	spin_lock(&files->file_lock);
 	err = expand_files(files, newfd);

commit aed976475bff939672b0e21595839c445dcec0fa
Author: Richard W.M. Jones <rjones@redhat.com>
Date:   Tue Oct 9 15:27:43 2012 +0100

    dup3: Return an error when oldfd == newfd.
    
    I have tested the attached patch to fix the dup3 regression.
    
    Rich.
    
    From 0944e30e12dec6544b3602626b60ff412375c78f Mon Sep 17 00:00:00 2001
    From: "Richard W.M. Jones" <rjones@redhat.com>
    Date: Tue, 9 Oct 2012 14:42:45 +0100
    Subject: [PATCH] dup3: Return an error when oldfd == newfd.
    
    The following commit:
    
      commit fe17f22d7fd0e344ef6447238f799bb49f670c6f
      Author: Al Viro <viro@zeniv.linux.org.uk>
      Date:   Tue Aug 21 11:48:11 2012 -0400
    
        take purely descriptor-related stuff from fcntl.c to file.c
    
    was supposed to be just code motion, but it dropped the following two
    lines:
    
      if (unlikely(oldfd == newfd))
              return -EINVAL;
    
    from the dup3 system call.  dup3 is not specified by POSIX, so Linux
    can do what it likes.  However the POSIX proposal for dup3 [1] states
    that it should return an error if oldfd == newfd.
    
    [1] http://austingroupbugs.net/view.php?id=411
    
    Signed-off-by: Richard W.M. Jones <rjones@redhat.com>
    Tested-by: Richard W.M. Jones <rjones@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 0f1bda4bebfa..d3b5fa80b71b 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -922,6 +922,9 @@ SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
 	if ((flags & ~O_CLOEXEC) != 0)
 		return -EINVAL;
 
+	if (unlikely(oldfd == newfd))
+		return -EINVAL;
+
 	if (newfd >= rlimit(RLIMIT_NOFILE))
 		return -EMFILE;
 

commit 4557c669ef9801d96cf663331cdd1dcb8fa9c2f1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 28 10:19:41 2012 -0400

    export fget_light
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 15750b80e3ce..0f1bda4bebfa 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -797,6 +797,7 @@ struct file *fget_light(unsigned int fd, int *fput_needed)
 
 	return file;
 }
+EXPORT_SYMBOL(fget_light);
 
 struct file *fget_raw_light(unsigned int fd, int *fput_needed)
 {

commit 864bdb3b6cbd9911222543fef1cfe36f88183f44
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 22 18:42:10 2012 -0400

    new helper: daemonize_descriptors()
    
    descriptor-related parts of daemonize, done right.  As the
    result we simplify the locking rules for ->files - we
    hold task_lock in *all* cases when we modify ->files.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index e6e418122587..15750b80e3ce 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -519,6 +519,12 @@ struct files_struct init_files = {
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
 };
 
+void daemonize_descriptors(void)
+{
+	atomic_inc(&init_files.count);
+	reset_files_struct(&init_files);
+}
+
 /*
  * allocate a file descriptor, mark it busy.
  */

commit c3c073f808b22dfae15ef8412b6f7b998644139a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 22:32:06 2012 -0400

    new helper: iterate_fd()
    
    iterates through the opened files in given descriptor table,
    calling a supplied function; we stop once non-zero is returned.
    Callback gets struct file *, descriptor number and const void *
    argument passed to iterator.  It is called with files->file_lock
    held, so it is not allowed to block.
    
    tty_io, netprio_cgroup and selinux flush_unauthorized_files()
    converted to its use.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 967bd0dadbe5..e6e418122587 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -979,3 +979,24 @@ int f_dupfd(unsigned int from, struct file *file, unsigned flags)
 	}
 	return err;
 }
+
+int iterate_fd(struct files_struct *files, unsigned n,
+		int (*f)(const void *, struct file *, unsigned),
+		const void *p)
+{
+	struct fdtable *fdt;
+	struct file *file;
+	int res = 0;
+	if (!files)
+		return 0;
+	spin_lock(&files->file_lock);
+	fdt = files_fdtable(files);
+	while (!res && n < fdt->max_fds) {
+		file = rcu_dereference_check_fdtable(files, fdt->fd[n++]);
+		if (file)
+			res = f(p, file, n);
+	}
+	spin_unlock(&files->file_lock);
+	return res;
+}
+EXPORT_SYMBOL(iterate_fd);

commit ad47bd7252bf402fe7dba92f5240b5ed16832ae7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 20:11:34 2012 -0400

    make expand_files() and alloc_fd() static
    
    no callers outside of fs/file.c left
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 40ddef9fe041..967bd0dadbe5 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -238,7 +238,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
  * expanded and execution may have blocked.
  * The files->file_lock should be held on entry, and will be held on exit.
  */
-int expand_files(struct files_struct *files, int nr)
+static int expand_files(struct files_struct *files, int nr)
 {
 	struct fdtable *fdt;
 
@@ -580,7 +580,7 @@ int __alloc_fd(struct files_struct *files,
 	return error;
 }
 
-int alloc_fd(unsigned start, unsigned flags)
+static int alloc_fd(unsigned start, unsigned flags)
 {
 	return __alloc_fd(current->files, start, rlimit(RLIMIT_NOFILE), flags);
 }

commit b8318b01a8f7f760ae3ecae052ccc7fc123d9508
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 20:09:42 2012 -0400

    take __{set,clear}_{open_fd,close_on_exec}() into fs/file.c
    
    nobody uses those outside anymore.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index a7bbe0324478..40ddef9fe041 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -256,6 +256,26 @@ int expand_files(struct files_struct *files, int nr)
 	return expand_fdtable(files, nr);
 }
 
+static inline void __set_close_on_exec(int fd, struct fdtable *fdt)
+{
+	__set_bit(fd, fdt->close_on_exec);
+}
+
+static inline void __clear_close_on_exec(int fd, struct fdtable *fdt)
+{
+	__clear_bit(fd, fdt->close_on_exec);
+}
+
+static inline void __set_open_fd(int fd, struct fdtable *fdt)
+{
+	__set_bit(fd, fdt->open_fds);
+}
+
+static inline void __clear_open_fd(int fd, struct fdtable *fdt)
+{
+	__clear_bit(fd, fdt->open_fds);
+}
+
 static int count_open_files(struct fdtable *fdt)
 {
 	int size = fdt->max_fds;

commit 8280d16172243702ed43432f826ca6130edb4086
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 12:11:46 2012 -0400

    new helper: replace_fd()
    
    analog of dup2(), except that it takes struct file * as source.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 7f29544755d0..a7bbe0324478 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -821,29 +821,12 @@ bool get_close_on_exec(unsigned int fd)
 	return res;
 }
 
-SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
+static int do_dup2(struct files_struct *files,
+	struct file *file, unsigned fd, unsigned flags)
 {
-	int err = -EBADF;
-	struct file * file, *tofree;
-	struct files_struct * files = current->files;
+	struct file *tofree;
 	struct fdtable *fdt;
 
-	if ((flags & ~O_CLOEXEC) != 0)
-		return -EINVAL;
-
-	if (newfd >= rlimit(RLIMIT_NOFILE))
-		return -EMFILE;
-
-	spin_lock(&files->file_lock);
-	err = expand_files(files, newfd);
-	file = fcheck(oldfd);
-	if (unlikely(!file))
-		goto Ebadf;
-	if (unlikely(err < 0)) {
-		if (err == -EMFILE)
-			goto Ebadf;
-		goto out_unlock;
-	}
 	/*
 	 * We need to detect attempts to do dup2() over allocated but still
 	 * not finished descriptor.  NB: OpenBSD avoids that at the price of
@@ -858,24 +841,74 @@ SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
 	 * scope of POSIX or SUS, since neither considers shared descriptor
 	 * tables and this condition does not arise without those.
 	 */
-	err = -EBUSY;
 	fdt = files_fdtable(files);
-	tofree = fdt->fd[newfd];
-	if (!tofree && fd_is_open(newfd, fdt))
-		goto out_unlock;
+	tofree = fdt->fd[fd];
+	if (!tofree && fd_is_open(fd, fdt))
+		goto Ebusy;
 	get_file(file);
-	rcu_assign_pointer(fdt->fd[newfd], file);
-	__set_open_fd(newfd, fdt);
+	rcu_assign_pointer(fdt->fd[fd], file);
+	__set_open_fd(fd, fdt);
 	if (flags & O_CLOEXEC)
-		__set_close_on_exec(newfd, fdt);
+		__set_close_on_exec(fd, fdt);
 	else
-		__clear_close_on_exec(newfd, fdt);
+		__clear_close_on_exec(fd, fdt);
 	spin_unlock(&files->file_lock);
 
 	if (tofree)
 		filp_close(tofree, files);
 
-	return newfd;
+	return fd;
+
+Ebusy:
+	spin_unlock(&files->file_lock);
+	return -EBUSY;
+}
+
+int replace_fd(unsigned fd, struct file *file, unsigned flags)
+{
+	int err;
+	struct files_struct *files = current->files;
+
+	if (!file)
+		return __close_fd(files, fd);
+
+	if (fd >= rlimit(RLIMIT_NOFILE))
+		return -EMFILE;
+
+	spin_lock(&files->file_lock);
+	err = expand_files(files, fd);
+	if (unlikely(err < 0))
+		goto out_unlock;
+	return do_dup2(files, file, fd, flags);
+
+out_unlock:
+	spin_unlock(&files->file_lock);
+	return err;
+}
+
+SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
+{
+	int err = -EBADF;
+	struct file *file;
+	struct files_struct *files = current->files;
+
+	if ((flags & ~O_CLOEXEC) != 0)
+		return -EINVAL;
+
+	if (newfd >= rlimit(RLIMIT_NOFILE))
+		return -EMFILE;
+
+	spin_lock(&files->file_lock);
+	err = expand_files(files, newfd);
+	file = fcheck(oldfd);
+	if (unlikely(!file))
+		goto Ebadf;
+	if (unlikely(err < 0)) {
+		if (err == -EMFILE)
+			goto Ebadf;
+		goto out_unlock;
+	}
+	return do_dup2(files, file, newfd, flags);
 
 Ebadf:
 	err = -EBADF;

commit fe17f22d7fd0e344ef6447238f799bb49f670c6f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 11:48:11 2012 -0400

    take purely descriptor-related stuff from fcntl.c to file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 92197dd9fdc8..7f29544755d0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -6,6 +6,7 @@
  *  Manage the dynamic fd arrays in the process files_struct.
  */
 
+#include <linux/syscalls.h>
 #include <linux/export.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
@@ -794,3 +795,134 @@ struct file *fget_raw_light(unsigned int fd, int *fput_needed)
 
 	return file;
 }
+
+void set_close_on_exec(unsigned int fd, int flag)
+{
+	struct files_struct *files = current->files;
+	struct fdtable *fdt;
+	spin_lock(&files->file_lock);
+	fdt = files_fdtable(files);
+	if (flag)
+		__set_close_on_exec(fd, fdt);
+	else
+		__clear_close_on_exec(fd, fdt);
+	spin_unlock(&files->file_lock);
+}
+
+bool get_close_on_exec(unsigned int fd)
+{
+	struct files_struct *files = current->files;
+	struct fdtable *fdt;
+	bool res;
+	rcu_read_lock();
+	fdt = files_fdtable(files);
+	res = close_on_exec(fd, fdt);
+	rcu_read_unlock();
+	return res;
+}
+
+SYSCALL_DEFINE3(dup3, unsigned int, oldfd, unsigned int, newfd, int, flags)
+{
+	int err = -EBADF;
+	struct file * file, *tofree;
+	struct files_struct * files = current->files;
+	struct fdtable *fdt;
+
+	if ((flags & ~O_CLOEXEC) != 0)
+		return -EINVAL;
+
+	if (newfd >= rlimit(RLIMIT_NOFILE))
+		return -EMFILE;
+
+	spin_lock(&files->file_lock);
+	err = expand_files(files, newfd);
+	file = fcheck(oldfd);
+	if (unlikely(!file))
+		goto Ebadf;
+	if (unlikely(err < 0)) {
+		if (err == -EMFILE)
+			goto Ebadf;
+		goto out_unlock;
+	}
+	/*
+	 * We need to detect attempts to do dup2() over allocated but still
+	 * not finished descriptor.  NB: OpenBSD avoids that at the price of
+	 * extra work in their equivalent of fget() - they insert struct
+	 * file immediately after grabbing descriptor, mark it larval if
+	 * more work (e.g. actual opening) is needed and make sure that
+	 * fget() treats larval files as absent.  Potentially interesting,
+	 * but while extra work in fget() is trivial, locking implications
+	 * and amount of surgery on open()-related paths in VFS are not.
+	 * FreeBSD fails with -EBADF in the same situation, NetBSD "solution"
+	 * deadlocks in rather amusing ways, AFAICS.  All of that is out of
+	 * scope of POSIX or SUS, since neither considers shared descriptor
+	 * tables and this condition does not arise without those.
+	 */
+	err = -EBUSY;
+	fdt = files_fdtable(files);
+	tofree = fdt->fd[newfd];
+	if (!tofree && fd_is_open(newfd, fdt))
+		goto out_unlock;
+	get_file(file);
+	rcu_assign_pointer(fdt->fd[newfd], file);
+	__set_open_fd(newfd, fdt);
+	if (flags & O_CLOEXEC)
+		__set_close_on_exec(newfd, fdt);
+	else
+		__clear_close_on_exec(newfd, fdt);
+	spin_unlock(&files->file_lock);
+
+	if (tofree)
+		filp_close(tofree, files);
+
+	return newfd;
+
+Ebadf:
+	err = -EBADF;
+out_unlock:
+	spin_unlock(&files->file_lock);
+	return err;
+}
+
+SYSCALL_DEFINE2(dup2, unsigned int, oldfd, unsigned int, newfd)
+{
+	if (unlikely(newfd == oldfd)) { /* corner case */
+		struct files_struct *files = current->files;
+		int retval = oldfd;
+
+		rcu_read_lock();
+		if (!fcheck_files(files, oldfd))
+			retval = -EBADF;
+		rcu_read_unlock();
+		return retval;
+	}
+	return sys_dup3(oldfd, newfd, 0);
+}
+
+SYSCALL_DEFINE1(dup, unsigned int, fildes)
+{
+	int ret = -EBADF;
+	struct file *file = fget_raw(fildes);
+
+	if (file) {
+		ret = get_unused_fd();
+		if (ret >= 0)
+			fd_install(ret, file);
+		else
+			fput(file);
+	}
+	return ret;
+}
+
+int f_dupfd(unsigned int from, struct file *file, unsigned flags)
+{
+	int err;
+	if (from >= rlimit(RLIMIT_NOFILE))
+		return -EINVAL;
+	err = alloc_fd(from, flags);
+	if (err >= 0) {
+		get_file(file);
+		fd_install(err, file);
+	}
+	return err;
+}

commit 6a6d27de340c89c5323565b49f7851362619925d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 21 09:56:33 2012 -0400

    take close-on-exec logics to fs/file.c, clean it up a bit
    
    ... and add cond_resched() there, while we are at it.  We can
    get large latencies as is...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index fd4694e688ab..92197dd9fdc8 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -652,6 +652,43 @@ int __close_fd(struct files_struct *files, unsigned fd)
 	return -EBADF;
 }
 
+void do_close_on_exec(struct files_struct *files)
+{
+	unsigned i;
+	struct fdtable *fdt;
+
+	/* exec unshares first */
+	BUG_ON(atomic_read(&files->count) != 1);
+	spin_lock(&files->file_lock);
+	for (i = 0; ; i++) {
+		unsigned long set;
+		unsigned fd = i * BITS_PER_LONG;
+		fdt = files_fdtable(files);
+		if (fd >= fdt->max_fds)
+			break;
+		set = fdt->close_on_exec[i];
+		if (!set)
+			continue;
+		fdt->close_on_exec[i] = 0;
+		for ( ; set ; fd++, set >>= 1) {
+			struct file *file;
+			if (!(set & 1))
+				continue;
+			file = fdt->fd[fd];
+			if (!file)
+				continue;
+			rcu_assign_pointer(fdt->fd[fd], NULL);
+			__put_unused_fd(files, fd);
+			spin_unlock(&files->file_lock);
+			filp_close(file, files);
+			cond_resched();
+			spin_lock(&files->file_lock);
+		}
+
+	}
+	spin_unlock(&files->file_lock);
+}
+
 struct file *fget(unsigned int fd)
 {
 	struct file *file;

commit 483ce1d4b8c3b82bc9c9a1dd9dbc44f50b3aaf5a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 19 12:04:24 2012 -0400

    take descriptor-related part of close() to file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 6eef55ce30c9..fd4694e688ab 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -626,6 +626,32 @@ void fd_install(unsigned int fd, struct file *file)
 
 EXPORT_SYMBOL(fd_install);
 
+/*
+ * The same warnings as for __alloc_fd()/__fd_install() apply here...
+ */
+int __close_fd(struct files_struct *files, unsigned fd)
+{
+	struct file *file;
+	struct fdtable *fdt;
+
+	spin_lock(&files->file_lock);
+	fdt = files_fdtable(files);
+	if (fd >= fdt->max_fds)
+		goto out_unlock;
+	file = fdt->fd[fd];
+	if (!file)
+		goto out_unlock;
+	rcu_assign_pointer(fdt->fd[fd], NULL);
+	__clear_close_on_exec(fd, fdt);
+	__put_unused_fd(files, fd);
+	spin_unlock(&files->file_lock);
+	return filp_close(file, files);
+
+out_unlock:
+	spin_unlock(&files->file_lock);
+	return -EBADF;
+}
+
 struct file *fget(unsigned int fd)
 {
 	struct file *file;

commit 0ee8cdfe6af052deb56dccd54838a1eb32fb4ca2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 21:12:10 2012 -0400

    take fget() and friends to fs/file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 0d1bf0515111..6eef55ce30c9 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -625,3 +625,109 @@ void fd_install(unsigned int fd, struct file *file)
 }
 
 EXPORT_SYMBOL(fd_install);
+
+struct file *fget(unsigned int fd)
+{
+	struct file *file;
+	struct files_struct *files = current->files;
+
+	rcu_read_lock();
+	file = fcheck_files(files, fd);
+	if (file) {
+		/* File object ref couldn't be taken */
+		if (file->f_mode & FMODE_PATH ||
+		    !atomic_long_inc_not_zero(&file->f_count))
+			file = NULL;
+	}
+	rcu_read_unlock();
+
+	return file;
+}
+
+EXPORT_SYMBOL(fget);
+
+struct file *fget_raw(unsigned int fd)
+{
+	struct file *file;
+	struct files_struct *files = current->files;
+
+	rcu_read_lock();
+	file = fcheck_files(files, fd);
+	if (file) {
+		/* File object ref couldn't be taken */
+		if (!atomic_long_inc_not_zero(&file->f_count))
+			file = NULL;
+	}
+	rcu_read_unlock();
+
+	return file;
+}
+
+EXPORT_SYMBOL(fget_raw);
+
+/*
+ * Lightweight file lookup - no refcnt increment if fd table isn't shared.
+ *
+ * You can use this instead of fget if you satisfy all of the following
+ * conditions:
+ * 1) You must call fput_light before exiting the syscall and returning control
+ *    to userspace (i.e. you cannot remember the returned struct file * after
+ *    returning to userspace).
+ * 2) You must not call filp_close on the returned struct file * in between
+ *    calls to fget_light and fput_light.
+ * 3) You must not clone the current task in between the calls to fget_light
+ *    and fput_light.
+ *
+ * The fput_needed flag returned by fget_light should be passed to the
+ * corresponding fput_light.
+ */
+struct file *fget_light(unsigned int fd, int *fput_needed)
+{
+	struct file *file;
+	struct files_struct *files = current->files;
+
+	*fput_needed = 0;
+	if (atomic_read(&files->count) == 1) {
+		file = fcheck_files(files, fd);
+		if (file && (file->f_mode & FMODE_PATH))
+			file = NULL;
+	} else {
+		rcu_read_lock();
+		file = fcheck_files(files, fd);
+		if (file) {
+			if (!(file->f_mode & FMODE_PATH) &&
+			    atomic_long_inc_not_zero(&file->f_count))
+				*fput_needed = 1;
+			else
+				/* Didn't get the reference, someone's freed */
+				file = NULL;
+		}
+		rcu_read_unlock();
+	}
+
+	return file;
+}
+
+struct file *fget_raw_light(unsigned int fd, int *fput_needed)
+{
+	struct file *file;
+	struct files_struct *files = current->files;
+
+	*fput_needed = 0;
+	if (atomic_read(&files->count) == 1) {
+		file = fcheck_files(files, fd);
+	} else {
+		rcu_read_lock();
+		file = fcheck_files(files, fd);
+		if (file) {
+			if (atomic_long_inc_not_zero(&file->f_count))
+				*fput_needed = 1;
+			else
+				/* Didn't get the reference, someone's freed */
+				file = NULL;
+		}
+		rcu_read_unlock();
+	}
+
+	return file;
+}

commit f869e8a7f753e3fd43d6483e796774776f645edb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 21:06:33 2012 -0400

    expose a low-level variant of fd_install() for binder
    
    Similar situation to that of __alloc_fd(); do not use unless you
    really have to.  You should not touch any descriptor table other
    than your own; it's a sure sign of a really bad API design.
    
    As with __alloc_fd(), you *must* use a first-class reference to
    struct files_struct; something obtained by get_files_struct(some task)
    (let alone direct task->files) will not do.  It must be either
    current->files, or obtained by get_files_struct(current) by the
    owner of that sucker and given to you.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 78cf88f2a0e8..0d1bf0515111 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -599,11 +599,18 @@ EXPORT_SYMBOL(put_unused_fd);
  *
  * It should never happen - if we allow dup2() do it, _really_ bad things
  * will follow.
+ *
+ * NOTE: __fd_install() variant is really, really low-level; don't
+ * use it unless you are forced to by truly lousy API shoved down
+ * your throat.  'files' *MUST* be either current->files or obtained
+ * by get_files_struct(current) done by whoever had given it to you,
+ * or really bad things will happen.  Normally you want to use
+ * fd_install() instead.
  */
 
-void fd_install(unsigned int fd, struct file *file)
+void __fd_install(struct files_struct *files, unsigned int fd,
+		struct file *file)
 {
-	struct files_struct *files = current->files;
 	struct fdtable *fdt;
 	spin_lock(&files->file_lock);
 	fdt = files_fdtable(files);
@@ -612,4 +619,9 @@ void fd_install(unsigned int fd, struct file *file)
 	spin_unlock(&files->file_lock);
 }
 
+void fd_install(unsigned int fd, struct file *file)
+{
+	__fd_install(current->files, fd, file);
+}
+
 EXPORT_SYMBOL(fd_install);

commit 56007cae94f349387c088e738c7dcb6bc513063b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 21:03:26 2012 -0400

    move put_unused_fd() and fd_install() to fs/file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 4ce4a0fcf320..78cf88f2a0e8 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -569,3 +569,47 @@ int get_unused_fd_flags(unsigned flags)
 	return __alloc_fd(current->files, 0, rlimit(RLIMIT_NOFILE), flags);
 }
 EXPORT_SYMBOL(get_unused_fd_flags);
+
+static void __put_unused_fd(struct files_struct *files, unsigned int fd)
+{
+	struct fdtable *fdt = files_fdtable(files);
+	__clear_open_fd(fd, fdt);
+	if (fd < files->next_fd)
+		files->next_fd = fd;
+}
+
+void put_unused_fd(unsigned int fd)
+{
+	struct files_struct *files = current->files;
+	spin_lock(&files->file_lock);
+	__put_unused_fd(files, fd);
+	spin_unlock(&files->file_lock);
+}
+
+EXPORT_SYMBOL(put_unused_fd);
+
+/*
+ * Install a file pointer in the fd array.
+ *
+ * The VFS is full of places where we drop the files lock between
+ * setting the open_fds bitmap and installing the file in the file
+ * array.  At any such point, we are vulnerable to a dup2() race
+ * installing a file in the array before us.  We need to detect this and
+ * fput() the struct file we are about to overwrite in this case.
+ *
+ * It should never happen - if we allow dup2() do it, _really_ bad things
+ * will follow.
+ */
+
+void fd_install(unsigned int fd, struct file *file)
+{
+	struct files_struct *files = current->files;
+	struct fdtable *fdt;
+	spin_lock(&files->file_lock);
+	fdt = files_fdtable(files);
+	BUG_ON(fdt->fd[fd] != NULL);
+	rcu_assign_pointer(fdt->fd[fd], file);
+	spin_unlock(&files->file_lock);
+}
+
+EXPORT_SYMBOL(fd_install);

commit 1983e781da2f7f77906f4ccc2c3dc279cd61d1ff
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 20:06:36 2012 -0400

    trim free_fdtable_rcu()
    
    embedded case isn't hit anymore
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 533fa5d56a5f..4ce4a0fcf320 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -90,16 +90,8 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	struct fdtable_defer *fddef;
 
 	BUG_ON(!fdt);
+	BUG_ON(fdt->max_fds <= NR_OPEN_DEFAULT);
 
-	if (fdt->max_fds <= NR_OPEN_DEFAULT) {
-		/*
-		 * This fdtable is embedded in the files structure and that
-		 * structure itself is getting destroyed.
-		 */
-		kmem_cache_free(files_cachep,
-				container_of(fdt, struct files_struct, fdtab));
-		return;
-	}
 	if (!is_vmalloc_addr(fdt->fd) && !is_vmalloc_addr(fdt->open_fds)) {
 		kfree(fdt->fd);
 		kfree(fdt->open_fds);
@@ -116,11 +108,6 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	}
 }
 
-static inline void free_fdtable(struct fdtable *fdt)
-{
-	call_rcu(&fdt->rcu, free_fdtable_rcu);
-}
-
 /*
  * Expand the fdset in the files_struct.  Called with the files spinlock
  * held for write.
@@ -234,7 +221,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		copy_fdtable(new_fdt, cur_fdt);
 		rcu_assign_pointer(files->fdt, new_fdt);
 		if (cur_fdt->max_fds > NR_OPEN_DEFAULT)
-			free_fdtable(cur_fdt);
+			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
 		__free_fdtable(new_fdt);

commit b9e02af0ae0783894abb576fbab45ec29aa8e7fc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 20:00:58 2012 -0400

    don't bother with call_rcu() in put_files_struct()
    
    At that point nobody can see us anyway; everything that
    looks at files_fdtable(files) is separated from the
    guts of put_files_struct(files) - either since files is
    current->files or because we fetched it under task_lock()
    and hadn't dropped that yet, or because we'd bumped
    files->count while holding task_lock()...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 0be423cadb26..533fa5d56a5f 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -447,18 +447,14 @@ void put_files_struct(struct files_struct *files)
 
 	if (atomic_dec_and_test(&files->count)) {
 		close_files(files);
-		/*
-		 * Free the fd and fdset arrays if we expanded them.
-		 * If the fdtable was embedded, pass files for freeing
-		 * at the end of the RCU grace period. Otherwise,
-		 * you can free files immediately.
-		 */
+		/* not really needed, since nobody can see us */
 		rcu_read_lock();
 		fdt = files_fdtable(files);
-		if (fdt != &files->fdtab)
-			kmem_cache_free(files_cachep, files);
-		free_fdtable(fdt);
 		rcu_read_unlock();
+		/* free the arrays if they are not embedded */
+		if (fdt != &files->fdtab)
+			__free_fdtable(fdt);
+		kmem_cache_free(files_cachep, files);
 	}
 }
 

commit 7cf4dc3c8dbfdfde163d4636f621cf99a1f63bfb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Aug 15 19:56:12 2012 -0400

    move files_struct-related bits from kernel/exit.c to fs/file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index a3a0705f8f51..0be423cadb26 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -84,7 +84,7 @@ static void free_fdtable_work(struct work_struct *work)
 	}
 }
 
-void free_fdtable_rcu(struct rcu_head *rcu)
+static void free_fdtable_rcu(struct rcu_head *rcu)
 {
 	struct fdtable *fdt = container_of(rcu, struct fdtable, rcu);
 	struct fdtable_defer *fddef;
@@ -116,6 +116,11 @@ void free_fdtable_rcu(struct rcu_head *rcu)
 	}
 }
 
+static inline void free_fdtable(struct fdtable *fdt)
+{
+	call_rcu(&fdt->rcu, free_fdtable_rcu);
+}
+
 /*
  * Expand the fdset in the files_struct.  Called with the files spinlock
  * held for write.
@@ -388,6 +393,99 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	return NULL;
 }
 
+static void close_files(struct files_struct * files)
+{
+	int i, j;
+	struct fdtable *fdt;
+
+	j = 0;
+
+	/*
+	 * It is safe to dereference the fd table without RCU or
+	 * ->file_lock because this is the last reference to the
+	 * files structure.  But use RCU to shut RCU-lockdep up.
+	 */
+	rcu_read_lock();
+	fdt = files_fdtable(files);
+	rcu_read_unlock();
+	for (;;) {
+		unsigned long set;
+		i = j * BITS_PER_LONG;
+		if (i >= fdt->max_fds)
+			break;
+		set = fdt->open_fds[j++];
+		while (set) {
+			if (set & 1) {
+				struct file * file = xchg(&fdt->fd[i], NULL);
+				if (file) {
+					filp_close(file, files);
+					cond_resched();
+				}
+			}
+			i++;
+			set >>= 1;
+		}
+	}
+}
+
+struct files_struct *get_files_struct(struct task_struct *task)
+{
+	struct files_struct *files;
+
+	task_lock(task);
+	files = task->files;
+	if (files)
+		atomic_inc(&files->count);
+	task_unlock(task);
+
+	return files;
+}
+
+void put_files_struct(struct files_struct *files)
+{
+	struct fdtable *fdt;
+
+	if (atomic_dec_and_test(&files->count)) {
+		close_files(files);
+		/*
+		 * Free the fd and fdset arrays if we expanded them.
+		 * If the fdtable was embedded, pass files for freeing
+		 * at the end of the RCU grace period. Otherwise,
+		 * you can free files immediately.
+		 */
+		rcu_read_lock();
+		fdt = files_fdtable(files);
+		if (fdt != &files->fdtab)
+			kmem_cache_free(files_cachep, files);
+		free_fdtable(fdt);
+		rcu_read_unlock();
+	}
+}
+
+void reset_files_struct(struct files_struct *files)
+{
+	struct task_struct *tsk = current;
+	struct files_struct *old;
+
+	old = tsk->files;
+	task_lock(tsk);
+	tsk->files = files;
+	task_unlock(tsk);
+	put_files_struct(old);
+}
+
+void exit_files(struct task_struct *tsk)
+{
+	struct files_struct * files = tsk->files;
+
+	if (files) {
+		task_lock(tsk);
+		tsk->files = NULL;
+		task_unlock(tsk);
+		put_files_struct(files);
+	}
+}
+
 static void __devinit fdtable_defer_list_init(int cpu)
 {
 	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);

commit dcfadfa4ec5a12404a99ad6426871a6b03a62b37
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 12 17:27:30 2012 -0400

    new helper: __alloc_fd()
    
    Essentially, alloc_fd() in a files_struct we own a reference to.
    Most of the time wanting to use it is a sign of lousy API
    design (such as android/binder).  It's *not* a general-purpose
    interface; better that than open-coding its guts, but again,
    playing with other process' descriptor table is a sign of bad
    design.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 08922af4a62c..a3a0705f8f51 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -420,11 +420,10 @@ struct files_struct init_files = {
 /*
  * allocate a file descriptor, mark it busy.
  */
-int alloc_fd(unsigned start, unsigned flags)
+int __alloc_fd(struct files_struct *files,
+	       unsigned start, unsigned end, unsigned flags)
 {
-	struct files_struct *files = current->files;
 	unsigned int fd;
-	unsigned end = rlimit(RLIMIT_NOFILE);
 	int error;
 	struct fdtable *fdt;
 
@@ -479,8 +478,13 @@ int alloc_fd(unsigned start, unsigned flags)
 	return error;
 }
 
+int alloc_fd(unsigned start, unsigned flags)
+{
+	return __alloc_fd(current->files, start, rlimit(RLIMIT_NOFILE), flags);
+}
+
 int get_unused_fd_flags(unsigned flags)
 {
-	return alloc_fd(0, flags);
+	return __alloc_fd(current->files, 0, rlimit(RLIMIT_NOFILE), flags);
 }
 EXPORT_SYMBOL(get_unused_fd_flags);

commit f33ff9927f42045116d738ee47ff7bc59f739bd7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 12 16:17:59 2012 -0400

    take rlimit check to callers of expand_files()
    
    ... except for one in android, where the check is different
    and already done in caller.  No need to recalculate rlimit
    many times in alloc_fd() either.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 5b46e9970a7a..08922af4a62c 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -251,13 +251,6 @@ int expand_files(struct files_struct *files, int nr)
 
 	fdt = files_fdtable(files);
 
-	/*
-	 * N.B. For clone tasks sharing a files structure, this test
-	 * will limit the total number of files that can be opened.
-	 */
-	if (nr >= rlimit(RLIMIT_NOFILE))
-		return -EMFILE;
-
 	/* Do we need to expand? */
 	if (nr < fdt->max_fds)
 		return 0;
@@ -431,6 +424,7 @@ int alloc_fd(unsigned start, unsigned flags)
 {
 	struct files_struct *files = current->files;
 	unsigned int fd;
+	unsigned end = rlimit(RLIMIT_NOFILE);
 	int error;
 	struct fdtable *fdt;
 
@@ -444,6 +438,14 @@ int alloc_fd(unsigned start, unsigned flags)
 	if (fd < fdt->max_fds)
 		fd = find_next_zero_bit(fdt->open_fds, fdt->max_fds, fd);
 
+	/*
+	 * N.B. For clone tasks sharing a files structure, this test
+	 * will limit the total number of files that can be opened.
+	 */
+	error = -EMFILE;
+	if (fd >= end)
+		goto out;
+
 	error = expand_files(files, fd);
 	if (error < 0)
 		goto out;

commit 1a7bd2265fc57f29400d57f66275cc5918e30aa6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 12 17:18:05 2012 -0400

    make get_unused_fd_flags() a function
    
    ... and get_unused_fd() a macro around it
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index ba3f6053025c..5b46e9970a7a 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -477,8 +477,8 @@ int alloc_fd(unsigned start, unsigned flags)
 	return error;
 }
 
-int get_unused_fd(void)
+int get_unused_fd_flags(unsigned flags)
 {
-	return alloc_fd(0, 0);
+	return alloc_fd(0, flags);
 }
-EXPORT_SYMBOL(get_unused_fd);
+EXPORT_SYMBOL(get_unused_fd_flags);

commit a591afc01d9e48affbacb365558a31e53c85af45
Merge: 820d41cf0cd0 31796ac4e8f0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 18:12:23 2012 -0700

    Merge branch 'x86-x32-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x32 support for x86-64 from Ingo Molnar:
     "This tree introduces the X32 binary format and execution mode for x86:
      32-bit data space binaries using 64-bit instructions and 64-bit kernel
      syscalls.
    
      This allows applications whose working set fits into a 32 bits address
      space to make use of 64-bit instructions while using a 32-bit address
      space with shorter pointers, more compressed data structures, etc."
    
    Fix up trivial context conflicts in arch/x86/{Kconfig,vdso/vma.c}
    
    * 'x86-x32-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (71 commits)
      x32: Fix alignment fail in struct compat_siginfo
      x32: Fix stupid ia32/x32 inversion in the siginfo format
      x32: Add ptrace for x32
      x32: Switch to a 64-bit clock_t
      x32: Provide separate is_ia32_task() and is_x32_task() predicates
      x86, mtrr: Use explicit sizing and padding for the 64-bit ioctls
      x86/x32: Fix the binutils auto-detect
      x32: Warn and disable rather than error if binutils too old
      x32: Only clear TIF_X32 flag once
      x32: Make sure TS_COMPAT is cleared for x32 tasks
      fs: Remove missed ->fds_bits from cessation use of fd_set structs internally
      fs: Fix close_on_exec pointer in alloc_fdtable
      x32: Drop non-__vdso weak symbols from the x32 VDSO
      x32: Fix coding style violations in the x32 VDSO code
      x32: Add x32 VDSO support
      x32: Allow x32 to be configured
      x32: If configured, add x32 system calls to system call tables
      x32: Handle process creation
      x32: Signal-related system calls
      x86: Add #ifdef CONFIG_COMPAT to <asm/sys_ia32.h>
      ...

commit 630d9c47274aa89bfa77fe6556d7818bdcb12992
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Nov 16 23:57:37 2011 -0500

    fs: reduce the use of module.h wherever possible
    
    For files only using THIS_MODULE and/or EXPORT_SYMBOL, map
    them onto including export.h -- or if the file isn't even
    using those, then just delete the include.  Fix up any implicit
    include dependencies that were being masked by module.h along
    the way.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/fs/file.c b/fs/file.c
index 4c6992d8f3ba..3c426de7203a 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -6,7 +6,7 @@
  *  Manage the dynamic fd arrays in the process files_struct.
  */
 
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
 #include <linux/mmzone.h>

commit f044db4cb4bf16893812d35b5fbeaaf3e30c9215
Author: Bobby Powers <bobbypowers@gmail.com>
Date:   Wed Feb 22 00:29:47 2012 -0500

    fs: Fix close_on_exec pointer in alloc_fdtable
    
    alloc_fdtable allocates space for the open_fds and close_on_exec
    bitfields together, as 2 * nr / BITS_PER_BYTE.  close_on_exec needs to
    point to open_fds + nr / BITS_PER_BYTE, not open_fds + nr /
    BITS_PER_LONG, as introducted in 1fd36adc: Replace the fd_sets in
    struct fdtable with an array of unsigned longs.
    
    Signed-off-by: Bobby Powers <bobbypowers@gmail.com>
    Link: http://lkml.kernel.org/r/1329888587-3087-1-git-send-email-bobbypowers@gmail.com
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>

diff --git a/fs/file.c b/fs/file.c
index 2d479dd8484e..171f6b41b4cd 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -179,7 +179,7 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	if (!data)
 		goto out_arr;
 	fdt->open_fds = data;
-	data += nr / BITS_PER_LONG;
+	data += nr / BITS_PER_BYTE;
 	fdt->close_on_exec = data;
 	fdt->next = NULL;
 

commit 1fd36adcd98c14d2fd97f545293c488775cb2823
Author: David Howells <dhowells@redhat.com>
Date:   Thu Feb 16 17:49:54 2012 +0000

    Replace the fd_sets in struct fdtable with an array of unsigned longs
    
    Replace the fd_sets in struct fdtable with an array of unsigned longs and then
    use the standard non-atomic bit operations rather than the FD_* macros.
    
    This:
    
     (1) Removes the abuses of struct fd_set:
    
         (a) Since we don't want to allocate a full fd_set the vast majority of the
             time, we actually, in effect, just allocate a just-big-enough array of
             unsigned longs and cast it to an fd_set type - so why bother with the
             fd_set at all?
    
         (b) Some places outside of the core fdtable handling code (such as
             SELinux) want to look inside the array of unsigned longs hidden inside
             the fd_set struct for more efficient iteration over the entire set.
    
     (2) Eliminates the use of FD_*() macros in the kernel completely.
    
     (3) Permits the __FD_*() macros to be deleted entirely where not exposed to
         userspace.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Link: http://lkml.kernel.org/r/20120216174954.23314.48147.stgit@warthog.procyon.org.uk
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 114fea0a2cec..2d479dd8484e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -40,7 +40,7 @@ int sysctl_nr_open_max = 1024 * 1024; /* raised later */
  */
 static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
 
-static void *alloc_fdmem(unsigned int size)
+static void *alloc_fdmem(size_t size)
 {
 	/*
 	 * Very large allocations can stress page reclaim, so fall back to
@@ -142,7 +142,7 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 static struct fdtable * alloc_fdtable(unsigned int nr)
 {
 	struct fdtable *fdt;
-	char *data;
+	void *data;
 
 	/*
 	 * Figure out how many fds we actually want to support in this fdtable.
@@ -172,14 +172,15 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	data = alloc_fdmem(nr * sizeof(struct file *));
 	if (!data)
 		goto out_fdt;
-	fdt->fd = (struct file **)data;
-	data = alloc_fdmem(max_t(unsigned int,
+	fdt->fd = data;
+
+	data = alloc_fdmem(max_t(size_t,
 				 2 * nr / BITS_PER_BYTE, L1_CACHE_BYTES));
 	if (!data)
 		goto out_arr;
-	fdt->open_fds = (fd_set *)data;
-	data += nr / BITS_PER_BYTE;
-	fdt->close_on_exec = (fd_set *)data;
+	fdt->open_fds = data;
+	data += nr / BITS_PER_LONG;
+	fdt->close_on_exec = data;
 	fdt->next = NULL;
 
 	return fdt;
@@ -275,11 +276,11 @@ static int count_open_files(struct fdtable *fdt)
 	int i;
 
 	/* Find the last open fd */
-	for (i = size/(8*sizeof(long)); i > 0; ) {
-		if (fdt->open_fds->fds_bits[--i])
+	for (i = size / BITS_PER_LONG; i > 0; ) {
+		if (fdt->open_fds[--i])
 			break;
 	}
-	i = (i+1) * 8 * sizeof(long);
+	i = (i + 1) * BITS_PER_LONG;
 	return i;
 }
 
@@ -306,8 +307,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	newf->next_fd = 0;
 	new_fdt = &newf->fdtab;
 	new_fdt->max_fds = NR_OPEN_DEFAULT;
-	new_fdt->close_on_exec = (fd_set *)&newf->close_on_exec_init;
-	new_fdt->open_fds = (fd_set *)&newf->open_fds_init;
+	new_fdt->close_on_exec = newf->close_on_exec_init;
+	new_fdt->open_fds = newf->open_fds_init;
 	new_fdt->fd = &newf->fd_array[0];
 	new_fdt->next = NULL;
 
@@ -350,10 +351,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	old_fds = old_fdt->fd;
 	new_fds = new_fdt->fd;
 
-	memcpy(new_fdt->open_fds->fds_bits,
-		old_fdt->open_fds->fds_bits, open_files/8);
-	memcpy(new_fdt->close_on_exec->fds_bits,
-		old_fdt->close_on_exec->fds_bits, open_files/8);
+	memcpy(new_fdt->open_fds, old_fdt->open_fds, open_files / 8);
+	memcpy(new_fdt->close_on_exec, old_fdt->close_on_exec, open_files / 8);
 
 	for (i = open_files; i != 0; i--) {
 		struct file *f = *old_fds++;
@@ -379,11 +378,11 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	memset(new_fds, 0, size);
 
 	if (new_fdt->max_fds > open_files) {
-		int left = (new_fdt->max_fds-open_files)/8;
-		int start = open_files / (8 * sizeof(unsigned long));
+		int left = (new_fdt->max_fds - open_files) / 8;
+		int start = open_files / BITS_PER_LONG;
 
-		memset(&new_fdt->open_fds->fds_bits[start], 0, left);
-		memset(&new_fdt->close_on_exec->fds_bits[start], 0, left);
+		memset(&new_fdt->open_fds[start], 0, left);
+		memset(&new_fdt->close_on_exec[start], 0, left);
 	}
 
 	rcu_assign_pointer(newf->fdt, new_fdt);
@@ -419,8 +418,8 @@ struct files_struct init_files = {
 	.fdtab		= {
 		.max_fds	= NR_OPEN_DEFAULT,
 		.fd		= &init_files.fd_array[0],
-		.close_on_exec	= (fd_set *)&init_files.close_on_exec_init,
-		.open_fds	= (fd_set *)&init_files.open_fds_init,
+		.close_on_exec	= init_files.close_on_exec_init,
+		.open_fds	= init_files.open_fds_init,
 	},
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
 };
@@ -443,8 +442,7 @@ int alloc_fd(unsigned start, unsigned flags)
 		fd = files->next_fd;
 
 	if (fd < fdt->max_fds)
-		fd = find_next_zero_bit(fdt->open_fds->fds_bits,
-					   fdt->max_fds, fd);
+		fd = find_next_zero_bit(fdt->open_fds, fdt->max_fds, fd);
 
 	error = expand_files(files, fd);
 	if (error < 0)

commit 1dce27c5aa6770e9d195f2bb7db1db3d4dde5591
Author: David Howells <dhowells@redhat.com>
Date:   Thu Feb 16 17:49:42 2012 +0000

    Wrap accesses to the fd_sets in struct fdtable
    
    Wrap accesses to the fd_sets in struct fdtable (for recording open files and
    close-on-exec flags) so that we can move away from using fd_sets since we
    abuse the fd_set structs by not allocating the full-sized structure under
    normal circumstances and by non-core code looking at the internals of the
    fd_sets.
    
    The first abuse means that use of FD_ZERO() on these fd_sets is not permitted,
    since that cannot be told about their abnormal lengths.
    
    This introduces six wrapper functions for setting, clearing and testing
    close-on-exec flags and fd-is-open flags:
    
            void __set_close_on_exec(int fd, struct fdtable *fdt);
            void __clear_close_on_exec(int fd, struct fdtable *fdt);
            bool close_on_exec(int fd, const struct fdtable *fdt);
            void __set_open_fd(int fd, struct fdtable *fdt);
            void __clear_open_fd(int fd, struct fdtable *fdt);
            bool fd_is_open(int fd, const struct fdtable *fdt);
    
    Note that I've prepended '__' to the names of the set/clear functions because
    they require the caller to hold a lock to use them.
    
    Note also that I haven't added wrappers for looking behind the scenes at the
    the array.  Possibly that should exist too.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Link: http://lkml.kernel.org/r/20120216174942.23314.1364.stgit@warthog.procyon.org.uk
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 4c6992d8f3ba..114fea0a2cec 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -366,7 +366,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 			 * is partway through open().  So make sure that this
 			 * fd is available to the new process.
 			 */
-			FD_CLR(open_files - i, new_fdt->open_fds);
+			__clear_open_fd(open_files - i, new_fdt);
 		}
 		rcu_assign_pointer(*new_fds++, f);
 	}
@@ -460,11 +460,11 @@ int alloc_fd(unsigned start, unsigned flags)
 	if (start <= files->next_fd)
 		files->next_fd = fd + 1;
 
-	FD_SET(fd, fdt->open_fds);
+	__set_open_fd(fd, fdt);
 	if (flags & O_CLOEXEC)
-		FD_SET(fd, fdt->close_on_exec);
+		__set_close_on_exec(fd, fdt);
 	else
-		FD_CLR(fd, fdt->close_on_exec);
+		__clear_close_on_exec(fd, fdt);
 	error = fd;
 #if 1
 	/* Sanity check */

commit 6d4831c283530a5f2c6bd8172c13efa236eb149d
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Wed Apr 27 15:26:41 2011 -0700

    vfs: avoid large kmalloc()s for the fdtable
    
    Azurit reports large increases in system time after 2.6.36 when running
    Apache.  It was bisected down to a892e2d7dcdfa6c76e6 ("vfs: use kmalloc()
    to allocate fdmem if possible").
    
    That patch caused the vfs to use kmalloc() for very large allocations and
    this is causing excessive work (and presumably excessive reclaim) within
    the page allocator.
    
    Fix it by falling back to vmalloc() earlier - when the allocation attempt
    would have been considered "costly" by reclaim.
    
    Reported-by: azurIt <azurit@pobox.sk>
    Tested-by: azurIt <azurit@pobox.sk>
    Acked-by: Changli Gao <xiaosuo@gmail.com>
    Cc: Americo Wang <xiyou.wangcong@gmail.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 0be344755c02..4c6992d8f3ba 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -9,6 +9,7 @@
 #include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
+#include <linux/mmzone.h>
 #include <linux/time.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
@@ -39,14 +40,17 @@ int sysctl_nr_open_max = 1024 * 1024; /* raised later */
  */
 static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
 
-static inline void *alloc_fdmem(unsigned int size)
+static void *alloc_fdmem(unsigned int size)
 {
-	void *data;
-
-	data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN);
-	if (data != NULL)
-		return data;
-
+	/*
+	 * Very large allocations can stress page reclaim, so fall back to
+	 * vmalloc() if the allocation size will be considered "large" by the VM.
+	 */
+	if (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {
+		void *data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN);
+		if (data != NULL)
+			return data;
+	}
 	return vmalloc(size);
 }
 

commit a892e2d7dcdfa6c76e60c50a8c7385c65587a2a6
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Tue Aug 10 18:01:35 2010 -0700

    vfs: use kmalloc() to allocate fdmem if possible
    
    Use kmalloc() to allocate fdmem if possible.
    
    vmalloc() is used as a fallback solution for fdmem allocation.  A new
    helper function __free_fdtable() is introduced to reduce the lines of
    code.
    
    A potential bug, vfree() a memory allocated by kmalloc(), is fixed.
    
    [akpm@linux-foundation.org: use __GFP_NOWARN, uninline alloc_fdmem() and free_fdmem()]
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index cccaead962c2..0be344755c02 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -39,28 +39,27 @@ int sysctl_nr_open_max = 1024 * 1024; /* raised later */
  */
 static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
 
-static inline void * alloc_fdmem(unsigned int size)
+static inline void *alloc_fdmem(unsigned int size)
 {
-	if (size <= PAGE_SIZE)
-		return kmalloc(size, GFP_KERNEL);
-	else
-		return vmalloc(size);
+	void *data;
+
+	data = kmalloc(size, GFP_KERNEL|__GFP_NOWARN);
+	if (data != NULL)
+		return data;
+
+	return vmalloc(size);
 }
 
-static inline void free_fdarr(struct fdtable *fdt)
+static void free_fdmem(void *ptr)
 {
-	if (fdt->max_fds <= (PAGE_SIZE / sizeof(struct file *)))
-		kfree(fdt->fd);
-	else
-		vfree(fdt->fd);
+	is_vmalloc_addr(ptr) ? vfree(ptr) : kfree(ptr);
 }
 
-static inline void free_fdset(struct fdtable *fdt)
+static void __free_fdtable(struct fdtable *fdt)
 {
-	if (fdt->max_fds <= (PAGE_SIZE * BITS_PER_BYTE / 2))
-		kfree(fdt->open_fds);
-	else
-		vfree(fdt->open_fds);
+	free_fdmem(fdt->fd);
+	free_fdmem(fdt->open_fds);
+	kfree(fdt);
 }
 
 static void free_fdtable_work(struct work_struct *work)
@@ -75,9 +74,8 @@ static void free_fdtable_work(struct work_struct *work)
 	spin_unlock_bh(&f->lock);
 	while(fdt) {
 		struct fdtable *next = fdt->next;
-		vfree(fdt->fd);
-		free_fdset(fdt);
-		kfree(fdt);
+
+		__free_fdtable(fdt);
 		fdt = next;
 	}
 }
@@ -98,7 +96,7 @@ void free_fdtable_rcu(struct rcu_head *rcu)
 				container_of(fdt, struct files_struct, fdtab));
 		return;
 	}
-	if (fdt->max_fds <= (PAGE_SIZE / sizeof(struct file *))) {
+	if (!is_vmalloc_addr(fdt->fd) && !is_vmalloc_addr(fdt->open_fds)) {
 		kfree(fdt->fd);
 		kfree(fdt->open_fds);
 		kfree(fdt);
@@ -183,7 +181,7 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	return fdt;
 
 out_arr:
-	free_fdarr(fdt);
+	free_fdmem(fdt->fd);
 out_fdt:
 	kfree(fdt);
 out:
@@ -213,9 +211,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 	 * caller and alloc_fdtable().  Cheaper to catch it here...
 	 */
 	if (unlikely(new_fdt->max_fds <= nr)) {
-		free_fdarr(new_fdt);
-		free_fdset(new_fdt);
-		kfree(new_fdt);
+		__free_fdtable(new_fdt);
 		return -EMFILE;
 	}
 	/*
@@ -231,9 +227,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 			free_fdtable(cur_fdt);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
-		free_fdarr(new_fdt);
-		free_fdset(new_fdt);
-		kfree(new_fdt);
+		__free_fdtable(new_fdt);
 	}
 	return 1;
 }
@@ -323,11 +317,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	while (unlikely(open_files > new_fdt->max_fds)) {
 		spin_unlock(&oldf->file_lock);
 
-		if (new_fdt != &newf->fdtab) {
-			free_fdarr(new_fdt);
-			free_fdset(new_fdt);
-			kfree(new_fdt);
-		}
+		if (new_fdt != &newf->fdtab)
+			__free_fdtable(new_fdt);
 
 		new_fdt = alloc_fdtable(open_files - 1);
 		if (!new_fdt) {
@@ -337,9 +328,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 
 		/* beyond sysctl_nr_open; nothing to do */
 		if (unlikely(new_fdt->max_fds < open_files)) {
-			free_fdarr(new_fdt);
-			free_fdset(new_fdt);
-			kfree(new_fdt);
+			__free_fdtable(new_fdt);
 			*errorp = -EMFILE;
 			goto out_release;
 		}

commit b97181f24212f4c29197890ce1b2b9100bcc184d
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 10 17:09:25 2010 -0700

    fs: remove all rcu head initializations, except on_stack initializations
    
    Remove all rcu head inits. We don't care about the RCU head state before passing
    it to call_rcu() anyway. Only leave the "on_stack" variants so debugobjects can
    keep track of objects on stack.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andries Brouwer <aeb@cwi.nl>

diff --git a/fs/file.c b/fs/file.c
index 34bb7f71d994..cccaead962c2 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -178,7 +178,6 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	fdt->open_fds = (fd_set *)data;
 	data += nr / BITS_PER_BYTE;
 	fdt->close_on_exec = (fd_set *)data;
-	INIT_RCU_HEAD(&fdt->rcu);
 	fdt->next = NULL;
 
 	return fdt;
@@ -312,7 +311,6 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	new_fdt->close_on_exec = (fd_set *)&newf->close_on_exec_init;
 	new_fdt->open_fds = (fd_set *)&newf->open_fds_init;
 	new_fdt->fd = &newf->fd_array[0];
-	INIT_RCU_HEAD(&new_fdt->rcu);
 	new_fdt->next = NULL;
 
 	spin_lock(&oldf->file_lock);
@@ -430,7 +428,6 @@ struct files_struct init_files = {
 		.fd		= &init_files.fd_array[0],
 		.close_on_exec	= (fd_set *)&init_files.close_on_exec_init,
 		.open_fds	= (fd_set *)&init_files.open_fds_init,
-		.rcu		= RCU_HEAD_INIT,
 	},
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
 };

commit d554ed895dc8f293cc712c71f14b101ace82579a
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Fri Mar 5 13:42:42 2010 -0800

    fs: use rlimit helpers
    
    Make sure compiler won't do weird things with limits.  E.g.  fetching them
    twice may return 2 different values after writable limits are implemented.
    
    I.e.  either use rlimit helpers added in commit 3e10e716abf3 ("resource:
    add helpers for fetching rlimits") or ACCESS_ONCE if not applicable.
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index 38039af67663..34bb7f71d994 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -257,7 +257,7 @@ int expand_files(struct files_struct *files, int nr)
 	 * N.B. For clone tasks sharing a files structure, this test
 	 * will limit the total number of files that can be opened.
 	 */
-	if (nr >= current->signal->rlim[RLIMIT_NOFILE].rlim_cur)
+	if (nr >= rlimit(RLIMIT_NOFILE))
 		return -EMFILE;
 
 	/* Do we need to expand? */

commit 7dc52157982ab771f40e3c0b7dc55b954c3c2d19
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 22 17:04:52 2010 -0800

    vfs: Apply lockdep-based checking to rcu_dereference() uses
    
    Add lockdep-ified RCU primitives to alloc_fd(), files_fdtable()
    and fcheck_files().
    
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    LKML-Reference: <1266887105-1528-8-git-send-email-paulmck@linux.vnet.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/file.c b/fs/file.c
index 87e129030ab1..38039af67663 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -478,7 +478,7 @@ int alloc_fd(unsigned start, unsigned flags)
 	error = fd;
 #if 1
 	/* Sanity check */
-	if (rcu_dereference(fdt->fd[fd]) != NULL) {
+	if (rcu_dereference_raw(fdt->fd[fd]) != NULL) {
 		printk(KERN_WARNING "alloc_fd: slot %d not NULL!\n", fd);
 		rcu_assign_pointer(fdt->fd[fd], NULL);
 	}

commit d43c36dc6b357fa1806800f18aa30123c747a6d1
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Wed Oct 7 17:09:06 2009 +0400

    headers: remove sched.h from interrupt.h
    
    After m68k's task_thread_info() doesn't refer to current,
    it's possible to remove sched.h from interrupt.h and not break m68k!
    Many thanks to Heiko Carstens for allowing this.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>

diff --git a/fs/file.c b/fs/file.c
index f313314f996f..87e129030ab1 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -10,6 +10,7 @@
 #include <linux/fs.h>
 #include <linux/mm.h>
 #include <linux/time.h>
+#include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/file.h>

commit 1027abe8827b47f7e9c4ed6514fde3d44f79963c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jul 30 04:13:04 2008 -0400

    [PATCH] merge locate_fd() and get_unused_fd()
    
            New primitive: alloc_fd(start, flags).  get_unused_fd() and
    get_unused_fd_flags() become wrappers on top of it.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index d8773b19fe47..f313314f996f 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -6,6 +6,7 @@
  *  Manage the dynamic fd arrays in the process files_struct.
  */
 
+#include <linux/module.h>
 #include <linux/fs.h>
 #include <linux/mm.h>
 #include <linux/time.h>
@@ -432,3 +433,63 @@ struct files_struct init_files = {
 	},
 	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
 };
+
+/*
+ * allocate a file descriptor, mark it busy.
+ */
+int alloc_fd(unsigned start, unsigned flags)
+{
+	struct files_struct *files = current->files;
+	unsigned int fd;
+	int error;
+	struct fdtable *fdt;
+
+	spin_lock(&files->file_lock);
+repeat:
+	fdt = files_fdtable(files);
+	fd = start;
+	if (fd < files->next_fd)
+		fd = files->next_fd;
+
+	if (fd < fdt->max_fds)
+		fd = find_next_zero_bit(fdt->open_fds->fds_bits,
+					   fdt->max_fds, fd);
+
+	error = expand_files(files, fd);
+	if (error < 0)
+		goto out;
+
+	/*
+	 * If we needed to expand the fs array we
+	 * might have blocked - try again.
+	 */
+	if (error)
+		goto repeat;
+
+	if (start <= files->next_fd)
+		files->next_fd = fd + 1;
+
+	FD_SET(fd, fdt->open_fds);
+	if (flags & O_CLOEXEC)
+		FD_SET(fd, fdt->close_on_exec);
+	else
+		FD_CLR(fd, fdt->close_on_exec);
+	error = fd;
+#if 1
+	/* Sanity check */
+	if (rcu_dereference(fdt->fd[fd]) != NULL) {
+		printk(KERN_WARNING "alloc_fd: slot %d not NULL!\n", fd);
+		rcu_assign_pointer(fdt->fd[fd], NULL);
+	}
+#endif
+
+out:
+	spin_unlock(&files->file_lock);
+	return error;
+}
+
+int get_unused_fd(void)
+{
+	return alloc_fd(0, 0);
+}
+EXPORT_SYMBOL(get_unused_fd);

commit 4e1e018ecc6f7bfd10fc75b3ff9715cc8164e0a2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 26 16:01:20 2008 -0400

    [PATCH] fix RLIM_NOFILE handling
    
    * dup2() should return -EBADF on exceeded sysctl_nr_open
    * dup() should *not* return -EINVAL even if you have rlimit set to 0;
      it should get -EMFILE instead.
    
    Check for orig_start exceeding rlimit taken to sys_fcntl().
    Failing expand_files() in dup{2,3}() now gets -EMFILE remapped to -EBADF.
    Consequently, remaining checks for rlimit are taken to expand_files().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 7b3887e054d0..d8773b19fe47 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -250,9 +250,18 @@ int expand_files(struct files_struct *files, int nr)
 	struct fdtable *fdt;
 
 	fdt = files_fdtable(files);
+
+	/*
+	 * N.B. For clone tasks sharing a files structure, this test
+	 * will limit the total number of files that can be opened.
+	 */
+	if (nr >= current->signal->rlim[RLIMIT_NOFILE].rlim_cur)
+		return -EMFILE;
+
 	/* Do we need to expand? */
 	if (nr < fdt->max_fds)
 		return 0;
+
 	/* Can we expand? */
 	if (nr >= sysctl_nr_open)
 		return -EMFILE;

commit eceea0b3df05ed262ae32e0c6340cc7a3626632d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat May 10 10:08:32 2008 -0400

    [PATCH] avoid multiplication overflows and signedness issues for max_fds
    
    Limit sysctl_nr_open - we don't want ->max_fds to exceed MAX_INT and
    we don't want size calculation for ->fd[] to overflow.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 0f705c7cfefe..7b3887e054d0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -26,6 +26,8 @@ struct fdtable_defer {
 };
 
 int sysctl_nr_open __read_mostly = 1024*1024;
+int sysctl_nr_open_min = BITS_PER_LONG;
+int sysctl_nr_open_max = 1024 * 1024; /* raised later */
 
 /*
  * We use this list to defer free fdtables that have vmalloced
@@ -405,6 +407,8 @@ void __init files_defer_init(void)
 	int i;
 	for_each_possible_cpu(i)
 		fdtable_defer_list_init(i);
+	sysctl_nr_open_max = min((size_t)INT_MAX, ~(size_t)0/sizeof(void *)) &
+			     -BITS_PER_LONG;
 }
 
 struct files_struct init_files = {

commit adbecb128cd2cc5d14b0ebef6d020ced0efd0ec6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 8 21:19:42 2008 -0400

    [PATCH] dup_fd() part 4 - race fix
    
    Parent _can_ be a clone task, contrary to the comment.  Moreover,
    more files could be opened while we allocate a copy, in which case
    we end up copying only part into new descriptor table.  Since what
    we get _is_ affected by all changes in the old range, we can get
    rather weird effects - e.g.
            dup2(0, 1024); close(0);
    in parallel with fork() resulting in child that sees the effect of
    close(), but not that of dup2() done just before that close().
    
    What we need is to recalculate the open_count after having reacquired
    ->file_lock and if external fdtable we'd just allocated is too small for
    it, free the sucker and redo allocation.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 689d2b6947e3..0f705c7cfefe 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -308,11 +308,16 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 
 	/*
 	 * Check whether we need to allocate a larger fd array and fd set.
-	 * Note: we're not a clone task, so the open count won't change.
 	 */
-	if (open_files > new_fdt->max_fds) {
+	while (unlikely(open_files > new_fdt->max_fds)) {
 		spin_unlock(&oldf->file_lock);
 
+		if (new_fdt != &newf->fdtab) {
+			free_fdarr(new_fdt);
+			free_fdset(new_fdt);
+			kfree(new_fdt);
+		}
+
 		new_fdt = alloc_fdtable(open_files - 1);
 		if (!new_fdt) {
 			*errorp = -ENOMEM;
@@ -335,6 +340,7 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 		 */
 		spin_lock(&oldf->file_lock);
 		old_fdt = files_fdtable(oldf);
+		open_files = count_open_files(old_fdt);
 	}
 
 	old_fds = old_fdt->fd;

commit afbec7fff4928c273a1f1bb14dfdfdf62688a193
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 8 21:11:17 2008 -0400

    [PATCH] dup_fd() - part 3
    
    merge alloc_files() into dup_fd(), leave setting newf->fdt until the end
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 6491b2b5bc38..689d2b6947e3 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -273,31 +273,6 @@ static int count_open_files(struct fdtable *fdt)
 	return i;
 }
 
-static struct files_struct *alloc_files(void)
-{
-	struct files_struct *newf;
-	struct fdtable *fdt;
-
-	newf = kmem_cache_alloc(files_cachep, GFP_KERNEL);
-	if (!newf)
-		goto out;
-
-	atomic_set(&newf->count, 1);
-
-	spin_lock_init(&newf->file_lock);
-	newf->next_fd = 0;
-	fdt = &newf->fdtab;
-	fdt->max_fds = NR_OPEN_DEFAULT;
-	fdt->close_on_exec = (fd_set *)&newf->close_on_exec_init;
-	fdt->open_fds = (fd_set *)&newf->open_fds_init;
-	fdt->fd = &newf->fd_array[0];
-	INIT_RCU_HEAD(&fdt->rcu);
-	fdt->next = NULL;
-	rcu_assign_pointer(newf->fdt, fdt);
-out:
-	return newf;
-}
-
 /*
  * Allocate a new files structure and copy contents from the
  * passed in files structure.
@@ -311,13 +286,24 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	struct fdtable *old_fdt, *new_fdt;
 
 	*errorp = -ENOMEM;
-	newf = alloc_files();
+	newf = kmem_cache_alloc(files_cachep, GFP_KERNEL);
 	if (!newf)
 		goto out;
 
+	atomic_set(&newf->count, 1);
+
+	spin_lock_init(&newf->file_lock);
+	newf->next_fd = 0;
+	new_fdt = &newf->fdtab;
+	new_fdt->max_fds = NR_OPEN_DEFAULT;
+	new_fdt->close_on_exec = (fd_set *)&newf->close_on_exec_init;
+	new_fdt->open_fds = (fd_set *)&newf->open_fds_init;
+	new_fdt->fd = &newf->fd_array[0];
+	INIT_RCU_HEAD(&new_fdt->rcu);
+	new_fdt->next = NULL;
+
 	spin_lock(&oldf->file_lock);
 	old_fdt = files_fdtable(oldf);
-	new_fdt = files_fdtable(newf);
 	open_files = count_open_files(old_fdt);
 
 	/*
@@ -341,7 +327,6 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 			*errorp = -EMFILE;
 			goto out_release;
 		}
-		rcu_assign_pointer(files->fdt, new_fdt);
 
 		/*
 		 * Reacquire the oldf lock and a pointer to its fd table
@@ -391,6 +376,8 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 		memset(&new_fdt->close_on_exec->fds_bits[start], 0, left);
 	}
 
+	rcu_assign_pointer(newf->fdt, new_fdt);
+
 	return newf;
 
 out_release:

commit 9dec3c4d306b09b31331e475e895bb9674e16d81
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 8 21:02:45 2008 -0400

    [PATCH] dup_fd() part 2
    
    use alloc_fdtable() instead of expand_files(), get rid of pointless
    grabbing newf->file_lock, kill magic in copy_fdtable() that used to
    be there only to skip copying when called from dup_fd().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 7dbadaaf00f0..6491b2b5bc38 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -119,8 +119,6 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 	unsigned int cpy, set;
 
 	BUG_ON(nfdt->max_fds < ofdt->max_fds);
-	if (ofdt->max_fds == 0)
-		return;
 
 	cpy = ofdt->max_fds * sizeof(struct file *);
 	set = (nfdt->max_fds - ofdt->max_fds) * sizeof(struct file *);
@@ -327,14 +325,24 @@ struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
 	 * Note: we're not a clone task, so the open count won't change.
 	 */
 	if (open_files > new_fdt->max_fds) {
-		new_fdt->max_fds = 0;
 		spin_unlock(&oldf->file_lock);
-		spin_lock(&newf->file_lock);
-		*errorp = expand_files(newf, open_files-1);
-		spin_unlock(&newf->file_lock);
-		if (*errorp < 0)
+
+		new_fdt = alloc_fdtable(open_files - 1);
+		if (!new_fdt) {
+			*errorp = -ENOMEM;
+			goto out_release;
+		}
+
+		/* beyond sysctl_nr_open; nothing to do */
+		if (unlikely(new_fdt->max_fds < open_files)) {
+			free_fdarr(new_fdt);
+			free_fdset(new_fdt);
+			kfree(new_fdt);
+			*errorp = -EMFILE;
 			goto out_release;
-		new_fdt = files_fdtable(newf);
+		}
+		rcu_assign_pointer(files->fdt, new_fdt);
+
 		/*
 		 * Reacquire the oldf lock and a pointer to its fd table
 		 * who knows it may have a new bigger fd table. We need

commit 02afc6267f6d55d47aba9fcafdbd1b7230d2294a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 8 19:42:56 2008 -0400

    [PATCH] dup_fd() fixes, part 1
    
    Move the sucker to fs/file.c in preparation to the rest
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 754cd05b06af..7dbadaaf00f0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -261,6 +261,136 @@ int expand_files(struct files_struct *files, int nr)
 	return expand_fdtable(files, nr);
 }
 
+static int count_open_files(struct fdtable *fdt)
+{
+	int size = fdt->max_fds;
+	int i;
+
+	/* Find the last open fd */
+	for (i = size/(8*sizeof(long)); i > 0; ) {
+		if (fdt->open_fds->fds_bits[--i])
+			break;
+	}
+	i = (i+1) * 8 * sizeof(long);
+	return i;
+}
+
+static struct files_struct *alloc_files(void)
+{
+	struct files_struct *newf;
+	struct fdtable *fdt;
+
+	newf = kmem_cache_alloc(files_cachep, GFP_KERNEL);
+	if (!newf)
+		goto out;
+
+	atomic_set(&newf->count, 1);
+
+	spin_lock_init(&newf->file_lock);
+	newf->next_fd = 0;
+	fdt = &newf->fdtab;
+	fdt->max_fds = NR_OPEN_DEFAULT;
+	fdt->close_on_exec = (fd_set *)&newf->close_on_exec_init;
+	fdt->open_fds = (fd_set *)&newf->open_fds_init;
+	fdt->fd = &newf->fd_array[0];
+	INIT_RCU_HEAD(&fdt->rcu);
+	fdt->next = NULL;
+	rcu_assign_pointer(newf->fdt, fdt);
+out:
+	return newf;
+}
+
+/*
+ * Allocate a new files structure and copy contents from the
+ * passed in files structure.
+ * errorp will be valid only when the returned files_struct is NULL.
+ */
+struct files_struct *dup_fd(struct files_struct *oldf, int *errorp)
+{
+	struct files_struct *newf;
+	struct file **old_fds, **new_fds;
+	int open_files, size, i;
+	struct fdtable *old_fdt, *new_fdt;
+
+	*errorp = -ENOMEM;
+	newf = alloc_files();
+	if (!newf)
+		goto out;
+
+	spin_lock(&oldf->file_lock);
+	old_fdt = files_fdtable(oldf);
+	new_fdt = files_fdtable(newf);
+	open_files = count_open_files(old_fdt);
+
+	/*
+	 * Check whether we need to allocate a larger fd array and fd set.
+	 * Note: we're not a clone task, so the open count won't change.
+	 */
+	if (open_files > new_fdt->max_fds) {
+		new_fdt->max_fds = 0;
+		spin_unlock(&oldf->file_lock);
+		spin_lock(&newf->file_lock);
+		*errorp = expand_files(newf, open_files-1);
+		spin_unlock(&newf->file_lock);
+		if (*errorp < 0)
+			goto out_release;
+		new_fdt = files_fdtable(newf);
+		/*
+		 * Reacquire the oldf lock and a pointer to its fd table
+		 * who knows it may have a new bigger fd table. We need
+		 * the latest pointer.
+		 */
+		spin_lock(&oldf->file_lock);
+		old_fdt = files_fdtable(oldf);
+	}
+
+	old_fds = old_fdt->fd;
+	new_fds = new_fdt->fd;
+
+	memcpy(new_fdt->open_fds->fds_bits,
+		old_fdt->open_fds->fds_bits, open_files/8);
+	memcpy(new_fdt->close_on_exec->fds_bits,
+		old_fdt->close_on_exec->fds_bits, open_files/8);
+
+	for (i = open_files; i != 0; i--) {
+		struct file *f = *old_fds++;
+		if (f) {
+			get_file(f);
+		} else {
+			/*
+			 * The fd may be claimed in the fd bitmap but not yet
+			 * instantiated in the files array if a sibling thread
+			 * is partway through open().  So make sure that this
+			 * fd is available to the new process.
+			 */
+			FD_CLR(open_files - i, new_fdt->open_fds);
+		}
+		rcu_assign_pointer(*new_fds++, f);
+	}
+	spin_unlock(&oldf->file_lock);
+
+	/* compute the remainder to be cleared */
+	size = (new_fdt->max_fds - open_files) * sizeof(struct file *);
+
+	/* This is long word aligned thus could use a optimized version */
+	memset(new_fds, 0, size);
+
+	if (new_fdt->max_fds > open_files) {
+		int left = (new_fdt->max_fds-open_files)/8;
+		int start = open_files / (8 * sizeof(unsigned long));
+
+		memset(&new_fdt->open_fds->fds_bits[start], 0, left);
+		memset(&new_fdt->close_on_exec->fds_bits[start], 0, left);
+	}
+
+	return newf;
+
+out_release:
+	kmem_cache_free(files_cachep, newf);
+out:
+	return NULL;
+}
+
 static void __devinit fdtable_defer_list_init(int cpu)
 {
 	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);

commit f52111b1546943545e67573c4dde1c7613ca33d3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 8 18:19:16 2008 -0400

    [PATCH] take init_files to fs/file.c
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 4c6f0ea12c41..754cd05b06af 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -275,3 +275,16 @@ void __init files_defer_init(void)
 	for_each_possible_cpu(i)
 		fdtable_defer_list_init(i);
 }
+
+struct files_struct init_files = {
+	.count		= ATOMIC_INIT(1),
+	.fdt		= &init_files.fdtab,
+	.fdtab		= {
+		.max_fds	= NR_OPEN_DEFAULT,
+		.fd		= &init_files.fd_array[0],
+		.close_on_exec	= (fd_set *)&init_files.close_on_exec_init,
+		.open_fds	= (fd_set *)&init_files.open_fds_init,
+		.rcu		= RCU_HEAD_INIT,
+	},
+	.file_lock	= __SPIN_LOCK_UNLOCKED(init_task.file_lock),
+};

commit 5c598b3428c372a1209597cee99a70da20625876
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Apr 27 20:04:15 2008 -0400

    [PATCH] fix sysctl_nr_open bugs
    
    * if luser with root sets it to something that is not a multiple of
      BITS_PER_LONG, the system is screwed.
    * if it gets decreased at the wrong time, we can get expand_files()
      returning success and _not_ increasing the size of table as asked.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index f6fbcb49faf7..4c6f0ea12c41 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -150,8 +150,16 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	nr /= (1024 / sizeof(struct file *));
 	nr = roundup_pow_of_two(nr + 1);
 	nr *= (1024 / sizeof(struct file *));
-	if (nr > sysctl_nr_open)
-		nr = sysctl_nr_open;
+	/*
+	 * Note that this can drive nr *below* what we had passed if sysctl_nr_open
+	 * had been set lower between the check in expand_files() and here.  Deal
+	 * with that in caller, it's cheaper that way.
+	 *
+	 * We make sure that nr remains a multiple of BITS_PER_LONG - otherwise
+	 * bitmaps handling below becomes unpleasant, to put it mildly...
+	 */
+	if (unlikely(nr > sysctl_nr_open))
+		nr = ((sysctl_nr_open - 1) | (BITS_PER_LONG - 1)) + 1;
 
 	fdt = kmalloc(sizeof(struct fdtable), GFP_KERNEL);
 	if (!fdt)
@@ -199,6 +207,16 @@ static int expand_fdtable(struct files_struct *files, int nr)
 	spin_lock(&files->file_lock);
 	if (!new_fdt)
 		return -ENOMEM;
+	/*
+	 * extremely unlikely race - sysctl_nr_open decreased between the check in
+	 * caller and alloc_fdtable().  Cheaper to catch it here...
+	 */
+	if (unlikely(new_fdt->max_fds <= nr)) {
+		free_fdarr(new_fdt);
+		free_fdset(new_fdt);
+		kfree(new_fdt);
+		return -EMFILE;
+	}
 	/*
 	 * Check again since another task may have expanded the fd table while
 	 * we dropped the lock

commit 9f3acc3140444a900ab280de942291959f0f615d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 24 07:44:08 2008 -0400

    [PATCH] split linux/file.h
    
    Initial splitoff of the low-level stuff; taken to fdtable.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/file.c b/fs/file.c
index 5110acb1c9ef..f6fbcb49faf7 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -12,6 +12,7 @@
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/file.h>
+#include <linux/fdtable.h>
 #include <linux/bitops.h>
 #include <linux/interrupt.h>
 #include <linux/spinlock.h>

commit 9cfe015aa424b3c003baba3841a60dd9b5ad319b
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Wed Feb 6 01:37:16 2008 -0800

    get rid of NR_OPEN and introduce a sysctl_nr_open
    
    NR_OPEN (historically set to 1024*1024) actually forbids processes to open
    more than 1024*1024 handles.
    
    Unfortunatly some production servers hit the not so 'ridiculously high
    value' of 1024*1024 file descriptors per process.
    
    Changing NR_OPEN is not considered safe because of vmalloc space potential
    exhaust.
    
    This patch introduces a new sysctl (/proc/sys/fs/nr_open) wich defaults to
    1024*1024, so that admins can decide to change this limit if their workload
    needs it.
    
    [akpm@linux-foundation.org: export it for sparc64]
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/file.c b/fs/file.c
index c5575de01113..5110acb1c9ef 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -24,6 +24,8 @@ struct fdtable_defer {
 	struct fdtable *next;
 };
 
+int sysctl_nr_open __read_mostly = 1024*1024;
+
 /*
  * We use this list to defer free fdtables that have vmalloced
  * sets/arrays. By keeping a per-cpu list, we avoid having to embed
@@ -147,8 +149,8 @@ static struct fdtable * alloc_fdtable(unsigned int nr)
 	nr /= (1024 / sizeof(struct file *));
 	nr = roundup_pow_of_two(nr + 1);
 	nr *= (1024 / sizeof(struct file *));
-	if (nr > NR_OPEN)
-		nr = NR_OPEN;
+	if (nr > sysctl_nr_open)
+		nr = sysctl_nr_open;
 
 	fdt = kmalloc(sizeof(struct fdtable), GFP_KERNEL);
 	if (!fdt)
@@ -233,7 +235,7 @@ int expand_files(struct files_struct *files, int nr)
 	if (nr < fdt->max_fds)
 		return 0;
 	/* Can we expand? */
-	if (nr >= NR_OPEN)
+	if (nr >= sysctl_nr_open)
 		return -EMFILE;
 
 	/* All good, so we try */

commit 01b2d93ca4c495f056471189ac6c4e6ac4cbbccb
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Fri Dec 22 01:10:43 2006 -0800

    [PATCH] fdtable: Provide free_fdtable() wrapper
    
    Christoph Hellwig has expressed concerns that the recent fdtable changes
    expose the details of the RCU methodology used to release no-longer-used
    fdtable structures to the rest of the kernel.  The trivial patch below
    addresses these concerns by introducing the appropriate free_fdtable()
    calls, which simply wrap the release RCU usage.  Since free_fdtable() is a
    one-liner, it makes sense to promote it to an inline helper.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 857fa49e984c..c5575de01113 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -206,7 +206,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		copy_fdtable(new_fdt, cur_fdt);
 		rcu_assign_pointer(files->fdt, new_fdt);
 		if (cur_fdt->max_fds > NR_OPEN_DEFAULT)
-			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
+			free_fdtable(cur_fdt);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
 		free_fdarr(new_fdt);

commit 5466b456ed6748e0bfe02831e570004d4c04c1d7
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Sun Dec 10 02:21:22 2006 -0800

    [PATCH] fdtable: Implement new pagesize-based fdtable allocator
    
    This patch provides an improved fdtable allocation scheme, useful for
    expanding fdtable file descriptor entries.  The main focus is on the fdarray,
    as its memory usage grows 128 times faster than that of an fdset.
    
    The allocation algorithm sizes the fdarray in such a way that its memory usage
    increases in easy page-sized chunks. The overall algorithm expands the allowed
    size in powers of two, in order to amortize the cost of invoking vmalloc() for
    larger allocation sizes. Namely, the following sizes for the fdarray are
    considered, and the smallest that accommodates the requested fd count is
    chosen:
    
        pagesize / 4
        pagesize / 2
        pagesize      <- memory allocator switch point
        pagesize * 2
        pagesize * 4
        ...etc...
    
    Unlike the current implementation, this allocation scheme does not require a
    loop to compute the optimal fdarray size, and can be done in efficient
    straightline code.
    
    Furthermore, since the fdarray overflows the pagesize boundary long before any
    of the fdsets do, it makes sense to optimize run-time by allocating both
    fdsets in a single swoop.  Even together, they will still be, by far, smaller
    than the fdarray.  The fdtable->open_fds is now used as the anchor for the
    fdset memory allocation.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 17e6a55521e2..857fa49e984c 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -32,46 +32,28 @@ struct fdtable_defer {
  */
 static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
 
-
-/*
- * Allocate an fd array, using kmalloc or vmalloc.
- * Note: the array isn't cleared at allocation time.
- */
-struct file ** alloc_fd_array(int num)
+static inline void * alloc_fdmem(unsigned int size)
 {
-	struct file **new_fds;
-	int size = num * sizeof(struct file *);
-
 	if (size <= PAGE_SIZE)
-		new_fds = (struct file **) kmalloc(size, GFP_KERNEL);
-	else 
-		new_fds = (struct file **) vmalloc(size);
-	return new_fds;
+		return kmalloc(size, GFP_KERNEL);
+	else
+		return vmalloc(size);
 }
 
-void free_fd_array(struct file **array, int num)
+static inline void free_fdarr(struct fdtable *fdt)
 {
-	int size = num * sizeof(struct file *);
-
-	if (!array) {
-		printk (KERN_ERR "free_fd_array: array = 0 (num = %d)\n", num);
-		return;
-	}
-
-	if (num <= NR_OPEN_DEFAULT) /* Don't free the embedded fd array! */
-		return;
-	else if (size <= PAGE_SIZE)
-		kfree(array);
+	if (fdt->max_fds <= (PAGE_SIZE / sizeof(struct file *)))
+		kfree(fdt->fd);
 	else
-		vfree(array);
+		vfree(fdt->fd);
 }
 
-static void __free_fdtable(struct fdtable *fdt)
+static inline void free_fdset(struct fdtable *fdt)
 {
-	free_fdset(fdt->open_fds, fdt->max_fds);
-	free_fdset(fdt->close_on_exec, fdt->max_fds);
-	free_fd_array(fdt->fd, fdt->max_fds);
-	kfree(fdt);
+	if (fdt->max_fds <= (PAGE_SIZE * BITS_PER_BYTE / 2))
+		kfree(fdt->open_fds);
+	else
+		vfree(fdt->open_fds);
 }
 
 static void free_fdtable_work(struct work_struct *work)
@@ -86,7 +68,9 @@ static void free_fdtable_work(struct work_struct *work)
 	spin_unlock_bh(&f->lock);
 	while(fdt) {
 		struct fdtable *next = fdt->next;
-		__free_fdtable(fdt);
+		vfree(fdt->fd);
+		free_fdset(fdt);
+		kfree(fdt);
 		fdt = next;
 	}
 }
@@ -94,12 +78,9 @@ static void free_fdtable_work(struct work_struct *work)
 void free_fdtable_rcu(struct rcu_head *rcu)
 {
 	struct fdtable *fdt = container_of(rcu, struct fdtable, rcu);
-	int fdset_size, fdarray_size;
 	struct fdtable_defer *fddef;
 
 	BUG_ON(!fdt);
-	fdset_size = fdt->max_fds / 8;
-	fdarray_size = fdt->max_fds * sizeof(struct file *);
 
 	if (fdt->max_fds <= NR_OPEN_DEFAULT) {
 		/*
@@ -110,10 +91,9 @@ void free_fdtable_rcu(struct rcu_head *rcu)
 				container_of(fdt, struct files_struct, fdtab));
 		return;
 	}
-	if (fdset_size <= PAGE_SIZE && fdarray_size <= PAGE_SIZE) {
-		kfree(fdt->open_fds);
-		kfree(fdt->close_on_exec);
+	if (fdt->max_fds <= (PAGE_SIZE / sizeof(struct file *))) {
 		kfree(fdt->fd);
+		kfree(fdt->open_fds);
 		kfree(fdt);
 	} else {
 		fddef = &get_cpu_var(fdtable_defer_list);
@@ -131,116 +111,70 @@ void free_fdtable_rcu(struct rcu_head *rcu)
  * Expand the fdset in the files_struct.  Called with the files spinlock
  * held for write.
  */
-static void copy_fdtable(struct fdtable *nfdt, struct fdtable *fdt)
+static void copy_fdtable(struct fdtable *nfdt, struct fdtable *ofdt)
 {
-	int i;
-	int count;
-
-	BUG_ON(nfdt->max_fds < fdt->max_fds);
-	/* Copy the existing tables and install the new pointers */
-
-	i = fdt->max_fds / (sizeof(unsigned long) * 8);
-	count = (nfdt->max_fds - fdt->max_fds) / 8;
-
-	/*
-	 * Don't copy the entire array if the current fdset is
-	 * not yet initialised.
-	 */
-	if (i) {
-		memcpy (nfdt->open_fds, fdt->open_fds,
-						fdt->max_fds/8);
-		memcpy (nfdt->close_on_exec, fdt->close_on_exec,
-						fdt->max_fds/8);
-		memset (&nfdt->open_fds->fds_bits[i], 0, count);
-		memset (&nfdt->close_on_exec->fds_bits[i], 0, count);
-	}
+	unsigned int cpy, set;
 
-	/* Don't copy/clear the array if we are creating a new
-	   fd array for fork() */
-	if (fdt->max_fds) {
-		memcpy(nfdt->fd, fdt->fd,
-			fdt->max_fds * sizeof(struct file *));
-		/* clear the remainder of the array */
-		memset(&nfdt->fd[fdt->max_fds], 0,
-		       (nfdt->max_fds - fdt->max_fds) *
-					sizeof(struct file *));
-	}
-}
-
-/*
- * Allocate an fdset array, using kmalloc or vmalloc.
- * Note: the array isn't cleared at allocation time.
- */
-fd_set * alloc_fdset(int num)
-{
-	fd_set *new_fdset;
-	int size = num / 8;
-
-	if (size <= PAGE_SIZE)
-		new_fdset = (fd_set *) kmalloc(size, GFP_KERNEL);
-	else
-		new_fdset = (fd_set *) vmalloc(size);
-	return new_fdset;
-}
-
-void free_fdset(fd_set *array, int num)
-{
-	if (num <= NR_OPEN_DEFAULT) /* Don't free an embedded fdset */
+	BUG_ON(nfdt->max_fds < ofdt->max_fds);
+	if (ofdt->max_fds == 0)
 		return;
-	else if (num <= 8 * PAGE_SIZE)
-		kfree(array);
-	else
-		vfree(array);
+
+	cpy = ofdt->max_fds * sizeof(struct file *);
+	set = (nfdt->max_fds - ofdt->max_fds) * sizeof(struct file *);
+	memcpy(nfdt->fd, ofdt->fd, cpy);
+	memset((char *)(nfdt->fd) + cpy, 0, set);
+
+	cpy = ofdt->max_fds / BITS_PER_BYTE;
+	set = (nfdt->max_fds - ofdt->max_fds) / BITS_PER_BYTE;
+	memcpy(nfdt->open_fds, ofdt->open_fds, cpy);
+	memset((char *)(nfdt->open_fds) + cpy, 0, set);
+	memcpy(nfdt->close_on_exec, ofdt->close_on_exec, cpy);
+	memset((char *)(nfdt->close_on_exec) + cpy, 0, set);
 }
 
-static struct fdtable *alloc_fdtable(int nr)
+static struct fdtable * alloc_fdtable(unsigned int nr)
 {
-	struct fdtable *fdt = NULL;
-	int nfds = 0;
-  	fd_set *new_openset = NULL, *new_execset = NULL;
-	struct file **new_fds;
-
-	fdt = kzalloc(sizeof(*fdt), GFP_KERNEL);
-	if (!fdt)
-  		goto out;
+	struct fdtable *fdt;
+	char *data;
 
-	nfds = NR_OPEN_DEFAULT;
 	/*
-	 * Expand to the max in easy steps, and keep expanding it until
-	 * we have enough for the requested fd array size.
+	 * Figure out how many fds we actually want to support in this fdtable.
+	 * Allocation steps are keyed to the size of the fdarray, since it
+	 * grows far faster than any of the other dynamic data. We try to fit
+	 * the fdarray into comfortable page-tuned chunks: starting at 1024B
+	 * and growing in powers of two from there on.
 	 */
-	do {
-#if NR_OPEN_DEFAULT < 256
-		if (nfds < 256)
-			nfds = 256;
-		else
-#endif
-		if (nfds < (PAGE_SIZE / sizeof(struct file *)))
-			nfds = PAGE_SIZE / sizeof(struct file *);
-		else {
-			nfds = nfds * 2;
-			if (nfds > NR_OPEN)
-				nfds = NR_OPEN;
-  		}
-	} while (nfds <= nr);
-
-  	new_openset = alloc_fdset(nfds);
-  	new_execset = alloc_fdset(nfds);
-  	if (!new_openset || !new_execset)
-  		goto out;
-	fdt->open_fds = new_openset;
-	fdt->close_on_exec = new_execset;
+	nr /= (1024 / sizeof(struct file *));
+	nr = roundup_pow_of_two(nr + 1);
+	nr *= (1024 / sizeof(struct file *));
+	if (nr > NR_OPEN)
+		nr = NR_OPEN;
 
-	new_fds = alloc_fd_array(nfds);
-	if (!new_fds)
+	fdt = kmalloc(sizeof(struct fdtable), GFP_KERNEL);
+	if (!fdt)
 		goto out;
-	fdt->fd = new_fds;
-	fdt->max_fds = nfds;
+	fdt->max_fds = nr;
+	data = alloc_fdmem(nr * sizeof(struct file *));
+	if (!data)
+		goto out_fdt;
+	fdt->fd = (struct file **)data;
+	data = alloc_fdmem(max_t(unsigned int,
+				 2 * nr / BITS_PER_BYTE, L1_CACHE_BYTES));
+	if (!data)
+		goto out_arr;
+	fdt->open_fds = (fd_set *)data;
+	data += nr / BITS_PER_BYTE;
+	fdt->close_on_exec = (fd_set *)data;
+	INIT_RCU_HEAD(&fdt->rcu);
+	fdt->next = NULL;
+
 	return fdt;
-out:
-	free_fdset(new_openset, nfds);
-	free_fdset(new_execset, nfds);
+
+out_arr:
+	free_fdarr(fdt);
+out_fdt:
 	kfree(fdt);
+out:
 	return NULL;
 }
 
@@ -275,7 +209,9 @@ static int expand_fdtable(struct files_struct *files, int nr)
 			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
-		__free_fdtable(new_fdt);
+		free_fdarr(new_fdt);
+		free_fdset(new_fdt);
+		kfree(new_fdt);
 	}
 	return 1;
 }

commit 4fd45812cbe875a620c86a096a5d46c742694b7e
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Sun Dec 10 02:21:17 2006 -0800

    [PATCH] fdtable: Remove the free_files field
    
    An fdtable can either be embedded inside a files_struct or standalone (after
    being expanded).  When an fdtable is being discarded after all RCU references
    to it have expired, we must either free it directly, in the standalone case,
    or free the files_struct it is contained within, in the embedded case.
    
    Currently the free_files field controls this behavior, but we can get rid of
    it entirely, as all the necessary information is already recorded.  We can
    distinguish embedded and standalone fdtables using max_fds, and if it is
    embedded we can divine the relevant files_struct using container_of().
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index fb3d2038dc21..17e6a55521e2 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -91,7 +91,7 @@ static void free_fdtable_work(struct work_struct *work)
 	}
 }
 
-static void free_fdtable_rcu(struct rcu_head *rcu)
+void free_fdtable_rcu(struct rcu_head *rcu)
 {
 	struct fdtable *fdt = container_of(rcu, struct fdtable, rcu);
 	int fdset_size, fdarray_size;
@@ -101,20 +101,15 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	fdset_size = fdt->max_fds / 8;
 	fdarray_size = fdt->max_fds * sizeof(struct file *);
 
-	if (fdt->free_files) {
+	if (fdt->max_fds <= NR_OPEN_DEFAULT) {
 		/*
-		 * The this fdtable was embedded in the files structure
-		 * and the files structure itself was getting destroyed.
-		 * It is now safe to free the files structure.
+		 * This fdtable is embedded in the files structure and that
+		 * structure itself is getting destroyed.
 		 */
-		kmem_cache_free(files_cachep, fdt->free_files);
+		kmem_cache_free(files_cachep,
+				container_of(fdt, struct files_struct, fdtab));
 		return;
 	}
-	if (fdt->max_fds <= NR_OPEN_DEFAULT)
-		/*
-		 * The fdtable was embedded
-		 */
-		return;
 	if (fdset_size <= PAGE_SIZE && fdarray_size <= PAGE_SIZE) {
 		kfree(fdt->open_fds);
 		kfree(fdt->close_on_exec);
@@ -132,12 +127,6 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	}
 }
 
-void free_fdtable(struct fdtable *fdt)
-{
-	if (fdt->free_files || fdt->max_fds > NR_OPEN_DEFAULT)
-		call_rcu(&fdt->rcu, free_fdtable_rcu);
-}
-
 /*
  * Expand the fdset in the files_struct.  Called with the files spinlock
  * held for write.
@@ -247,7 +236,6 @@ static struct fdtable *alloc_fdtable(int nr)
 		goto out;
 	fdt->fd = new_fds;
 	fdt->max_fds = nfds;
-	fdt->free_files = NULL;
 	return fdt;
 out:
 	free_fdset(new_openset, nfds);
@@ -283,7 +271,8 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		/* Continue as planned */
 		copy_fdtable(new_fdt, cur_fdt);
 		rcu_assign_pointer(files->fdt, new_fdt);
-		free_fdtable(cur_fdt);
+		if (cur_fdt->max_fds > NR_OPEN_DEFAULT)
+			call_rcu(&cur_fdt->rcu, free_fdtable_rcu);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
 		__free_fdtable(new_fdt);

commit bbea9f69668a3d0cf9feba15a724cd02896f8675
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Sun Dec 10 02:21:12 2006 -0800

    [PATCH] fdtable: Make fdarray and fdsets equal in size
    
    Currently, each fdtable supports three dynamically-sized arrays of data: the
    fdarray and two fdsets.  The code allows the number of fds supported by the
    fdarray (fdtable->max_fds) to differ from the number of fds supported by each
    of the fdsets (fdtable->max_fdset).
    
    In practice, it is wasteful for these two sizes to differ: whenever we hit a
    limit on the smaller-capacity structure, we will reallocate the entire fdtable
    and all the dynamic arrays within it, so any delta in the memory used by the
    larger-capacity structure will never be touched at all.
    
    Rather than hogging this excess, we shouldn't even allocate it in the first
    place, and keep the capacities of the fdarray and the fdsets equal.  This
    patch removes fdtable->max_fdset.  As an added bonus, most of the supporting
    code becomes simpler.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 51aef675470f..fb3d2038dc21 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -68,8 +68,8 @@ void free_fd_array(struct file **array, int num)
 
 static void __free_fdtable(struct fdtable *fdt)
 {
-	free_fdset(fdt->open_fds, fdt->max_fdset);
-	free_fdset(fdt->close_on_exec, fdt->max_fdset);
+	free_fdset(fdt->open_fds, fdt->max_fds);
+	free_fdset(fdt->close_on_exec, fdt->max_fds);
 	free_fd_array(fdt->fd, fdt->max_fds);
 	kfree(fdt);
 }
@@ -98,7 +98,7 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 	struct fdtable_defer *fddef;
 
 	BUG_ON(!fdt);
-	fdset_size = fdt->max_fdset / 8;
+	fdset_size = fdt->max_fds / 8;
 	fdarray_size = fdt->max_fds * sizeof(struct file *);
 
 	if (fdt->free_files) {
@@ -110,13 +110,11 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 		kmem_cache_free(files_cachep, fdt->free_files);
 		return;
 	}
-	if (fdt->max_fdset <= EMBEDDED_FD_SET_SIZE &&
-		fdt->max_fds <= NR_OPEN_DEFAULT) {
+	if (fdt->max_fds <= NR_OPEN_DEFAULT)
 		/*
 		 * The fdtable was embedded
 		 */
 		return;
-	}
 	if (fdset_size <= PAGE_SIZE && fdarray_size <= PAGE_SIZE) {
 		kfree(fdt->open_fds);
 		kfree(fdt->close_on_exec);
@@ -136,9 +134,7 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 
 void free_fdtable(struct fdtable *fdt)
 {
-	if (fdt->free_files ||
-		fdt->max_fdset > EMBEDDED_FD_SET_SIZE ||
-		fdt->max_fds > NR_OPEN_DEFAULT)
+	if (fdt->free_files || fdt->max_fds > NR_OPEN_DEFAULT)
 		call_rcu(&fdt->rcu, free_fdtable_rcu);
 }
 
@@ -151,12 +147,11 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *fdt)
 	int i;
 	int count;
 
-	BUG_ON(nfdt->max_fdset < fdt->max_fdset);
 	BUG_ON(nfdt->max_fds < fdt->max_fds);
 	/* Copy the existing tables and install the new pointers */
 
-	i = fdt->max_fdset / (sizeof(unsigned long) * 8);
-	count = (nfdt->max_fdset - fdt->max_fdset) / 8;
+	i = fdt->max_fds / (sizeof(unsigned long) * 8);
+	count = (nfdt->max_fds - fdt->max_fds) / 8;
 
 	/*
 	 * Don't copy the entire array if the current fdset is
@@ -164,9 +159,9 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *fdt)
 	 */
 	if (i) {
 		memcpy (nfdt->open_fds, fdt->open_fds,
-						fdt->max_fdset/8);
+						fdt->max_fds/8);
 		memcpy (nfdt->close_on_exec, fdt->close_on_exec,
-						fdt->max_fdset/8);
+						fdt->max_fds/8);
 		memset (&nfdt->open_fds->fds_bits[i], 0, count);
 		memset (&nfdt->close_on_exec->fds_bits[i], 0, count);
 	}
@@ -201,7 +196,7 @@ fd_set * alloc_fdset(int num)
 
 void free_fdset(fd_set *array, int num)
 {
-	if (num <= EMBEDDED_FD_SET_SIZE) /* Don't free an embedded fdset */
+	if (num <= NR_OPEN_DEFAULT) /* Don't free an embedded fdset */
 		return;
 	else if (num <= 8 * PAGE_SIZE)
 		kfree(array);
@@ -220,18 +215,6 @@ static struct fdtable *alloc_fdtable(int nr)
 	if (!fdt)
   		goto out;
 
-	nfds = max_t(int, 8 * L1_CACHE_BYTES, roundup_pow_of_two(nr + 1));
-	if (nfds > NR_OPEN)
-		nfds = NR_OPEN;
-
-  	new_openset = alloc_fdset(nfds);
-  	new_execset = alloc_fdset(nfds);
-  	if (!new_openset || !new_execset)
-  		goto out;
-	fdt->open_fds = new_openset;
-	fdt->close_on_exec = new_execset;
-	fdt->max_fdset = nfds;
-
 	nfds = NR_OPEN_DEFAULT;
 	/*
 	 * Expand to the max in easy steps, and keep expanding it until
@@ -251,15 +234,21 @@ static struct fdtable *alloc_fdtable(int nr)
 				nfds = NR_OPEN;
   		}
 	} while (nfds <= nr);
+
+  	new_openset = alloc_fdset(nfds);
+  	new_execset = alloc_fdset(nfds);
+  	if (!new_openset || !new_execset)
+  		goto out;
+	fdt->open_fds = new_openset;
+	fdt->close_on_exec = new_execset;
+
 	new_fds = alloc_fd_array(nfds);
 	if (!new_fds)
-		goto out2;
+		goto out;
 	fdt->fd = new_fds;
 	fdt->max_fds = nfds;
 	fdt->free_files = NULL;
 	return fdt;
-out2:
-	nfds = fdt->max_fdset;
 out:
 	free_fdset(new_openset, nfds);
 	free_fdset(new_execset, nfds);
@@ -290,7 +279,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 	 * we dropped the lock
 	 */
 	cur_fdt = files_fdtable(files);
-	if (nr >= cur_fdt->max_fds || nr >= cur_fdt->max_fdset) {
+	if (nr >= cur_fdt->max_fds) {
 		/* Continue as planned */
 		copy_fdtable(new_fdt, cur_fdt);
 		rcu_assign_pointer(files->fdt, new_fdt);
@@ -316,11 +305,10 @@ int expand_files(struct files_struct *files, int nr)
 
 	fdt = files_fdtable(files);
 	/* Do we need to expand? */
-	if (nr < fdt->max_fdset && nr < fdt->max_fds)
+	if (nr < fdt->max_fds)
 		return 0;
 	/* Can we expand? */
-	if (fdt->max_fdset >= NR_OPEN || fdt->max_fds >= NR_OPEN ||
-	    nr >= NR_OPEN)
+	if (nr >= NR_OPEN)
 		return -EMFILE;
 
 	/* All good, so we try */

commit 593be07ae8f6f4a1b1b98813fabb155328f8bc0c
Author: Tejun Heo <htejun@gmail.com>
Date:   Wed Dec 6 20:36:01 2006 -0800

    [PATCH] file: kill unnecessary timer in fdtable_defer
    
    free_fdtable_rc() schedules timer to reschedule fddef->wq if
    schedule_work() on it returns 0.  However, schedule_work() guarantees that
    the target work is executed at least once after the scheduling regardless
    of its return value.  0 return simply means that the work was already
    pending and thus no further action was required.
    
    Another problem is that it used contant '5' as @expires argument to
    mod_timer().
    
    Kill unnecessary fddef->timer.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Cc: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 3787e82f54c1..51aef675470f 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -21,7 +21,6 @@
 struct fdtable_defer {
 	spinlock_t lock;
 	struct work_struct wq;
-	struct timer_list timer;
 	struct fdtable *next;
 };
 
@@ -75,22 +74,6 @@ static void __free_fdtable(struct fdtable *fdt)
 	kfree(fdt);
 }
 
-static void fdtable_timer(unsigned long data)
-{
-	struct fdtable_defer *fddef = (struct fdtable_defer *)data;
-
-	spin_lock(&fddef->lock);
-	/*
-	 * If someone already emptied the queue return.
-	 */
-	if (!fddef->next)
-		goto out;
-	if (!schedule_work(&fddef->wq))
-		mod_timer(&fddef->timer, 5);
-out:
-	spin_unlock(&fddef->lock);
-}
-
 static void free_fdtable_work(struct work_struct *work)
 {
 	struct fdtable_defer *f =
@@ -144,13 +127,8 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 		spin_lock(&fddef->lock);
 		fdt->next = fddef->next;
 		fddef->next = fdt;
-		/*
-		 * vmallocs are handled from the workqueue context.
-		 * If the per-cpu workqueue is running, then we
-		 * defer work scheduling through a timer.
-		 */
-		if (!schedule_work(&fddef->wq))
-			mod_timer(&fddef->timer, 5);
+		/* vmallocs are handled from the workqueue context */
+		schedule_work(&fddef->wq);
 		spin_unlock(&fddef->lock);
 		put_cpu_var(fdtable_defer_list);
 	}
@@ -354,9 +332,6 @@ static void __devinit fdtable_defer_list_init(int cpu)
 	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);
 	spin_lock_init(&fddef->lock);
 	INIT_WORK(&fddef->wq, free_fdtable_work);
-	init_timer(&fddef->timer);
-	fddef->timer.data = (unsigned long)fddef;
-	fddef->timer.function = fdtable_timer;
 	fddef->next = NULL;
 }
 

commit 65f27f38446e1976cc98fd3004b110fedcddd189
Author: David Howells <dhowells@redhat.com>
Date:   Wed Nov 22 14:55:48 2006 +0000

    WorkStruct: Pass the work_struct pointer instead of context data
    
    Pass the work_struct pointer to the work function rather than context data.
    The work function can use container_of() to work out the data.
    
    For the cases where the container of the work_struct may go away the moment the
    pending bit is cleared, it is made possible to defer the release of the
    structure by deferring the clearing of the pending bit.
    
    To make this work, an extra flag is introduced into the management side of the
    work_struct.  This governs auto-release of the structure upon execution.
    
    Ordinarily, the work queue executor would release the work_struct for further
    scheduling or deallocation by clearing the pending bit prior to jumping to the
    work function.  This means that, unless the driver makes some guarantee itself
    that the work_struct won't go away, the work function may not access anything
    else in the work_struct or its container lest they be deallocated..  This is a
    problem if the auxiliary data is taken away (as done by the last patch).
    
    However, if the pending bit is *not* cleared before jumping to the work
    function, then the work function *may* access the work_struct and its container
    with no problems.  But then the work function must itself release the
    work_struct by calling work_release().
    
    In most cases, automatic release is fine, so this is the default.  Special
    initiators exist for the non-auto-release case (ending in _NAR).
    
    
    Signed-Off-By: David Howells <dhowells@redhat.com>

diff --git a/fs/file.c b/fs/file.c
index 8e81775c5dc8..3787e82f54c1 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -91,8 +91,10 @@ static void fdtable_timer(unsigned long data)
 	spin_unlock(&fddef->lock);
 }
 
-static void free_fdtable_work(struct fdtable_defer *f)
+static void free_fdtable_work(struct work_struct *work)
 {
+	struct fdtable_defer *f =
+		container_of(work, struct fdtable_defer, wq);
 	struct fdtable *fdt;
 
 	spin_lock_bh(&f->lock);
@@ -351,7 +353,7 @@ static void __devinit fdtable_defer_list_init(int cpu)
 {
 	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);
 	spin_lock_init(&fddef->lock);
-	INIT_WORK(&fddef->wq, (void (*)(void *))free_fdtable_work, fddef);
+	INIT_WORK(&fddef->wq, free_fdtable_work);
 	init_timer(&fddef->timer);
 	fddef->timer.data = (unsigned long)fddef;
 	fddef->timer.function = fdtable_timer;

commit 327dcaadc0bc08ad081aa8e36b6ec7ad7aa45e30
Author: Andrew Morton <akpm@osdl.org>
Date:   Fri Sep 29 02:01:44 2006 -0700

    [PATCH] expand_fdtable(): remove pointless unlock+lock
    
    This unlock/lock on a super-unlikely path isn't worth the kernel text.
    
    Cc: Vadim Lobanov <vlobanov@speakeasy.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 2a991ac8e562..8e81775c5dc8 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -317,9 +317,7 @@ static int expand_fdtable(struct files_struct *files, int nr)
 		free_fdtable(cur_fdt);
 	} else {
 		/* Somebody else expanded, so undo our attempt */
-		spin_unlock(&files->file_lock);
 		__free_fdtable(new_fdt);
-		spin_lock(&files->file_lock);
 	}
 	return 1;
 }

commit 74d392aaabfc890cc1f0e80fc5ff13e5d3bcf4c9
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Fri Sep 29 02:01:43 2006 -0700

    [PATCH] Clean up expand_fdtable() and expand_files()
    
    Perform a code cleanup against the expand_fdtable() and expand_files()
    functions inside fs/file.c.  It aims to make the flow of code within these
    functions simpler and easier to understand, via added comments and modest
    refactoring.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 8d3bfca7714b..2a991ac8e562 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -288,71 +288,65 @@ static struct fdtable *alloc_fdtable(int nr)
 }
 
 /*
- * Expands the file descriptor table - it will allocate a new fdtable and
- * both fd array and fdset. It is expected to be called with the
- * files_lock held.
+ * Expand the file descriptor table.
+ * This function will allocate a new fdtable and both fd array and fdset, of
+ * the given size.
+ * Return <0 error code on error; 1 on successful completion.
+ * The files->file_lock should be held on entry, and will be held on exit.
  */
 static int expand_fdtable(struct files_struct *files, int nr)
 	__releases(files->file_lock)
 	__acquires(files->file_lock)
 {
-	int error = 0;
-	struct fdtable *fdt;
-	struct fdtable *nfdt = NULL;
+	struct fdtable *new_fdt, *cur_fdt;
 
 	spin_unlock(&files->file_lock);
-	nfdt = alloc_fdtable(nr);
-	if (!nfdt) {
-		error = -ENOMEM;
-		spin_lock(&files->file_lock);
-		goto out;
-	}
-
+	new_fdt = alloc_fdtable(nr);
 	spin_lock(&files->file_lock);
-	fdt = files_fdtable(files);
+	if (!new_fdt)
+		return -ENOMEM;
 	/*
-	 * Check again since another task may have expanded the
-	 * fd table while we dropped the lock
+	 * Check again since another task may have expanded the fd table while
+	 * we dropped the lock
 	 */
-	if (nr >= fdt->max_fds || nr >= fdt->max_fdset) {
-		copy_fdtable(nfdt, fdt);
+	cur_fdt = files_fdtable(files);
+	if (nr >= cur_fdt->max_fds || nr >= cur_fdt->max_fdset) {
+		/* Continue as planned */
+		copy_fdtable(new_fdt, cur_fdt);
+		rcu_assign_pointer(files->fdt, new_fdt);
+		free_fdtable(cur_fdt);
 	} else {
-		/* Somebody expanded while we dropped file_lock */
+		/* Somebody else expanded, so undo our attempt */
 		spin_unlock(&files->file_lock);
-		__free_fdtable(nfdt);
+		__free_fdtable(new_fdt);
 		spin_lock(&files->file_lock);
-		goto out;
 	}
-	rcu_assign_pointer(files->fdt, nfdt);
-	free_fdtable(fdt);
-out:
-	return error;
+	return 1;
 }
 
 /*
  * Expand files.
- * Return <0 on error; 0 nothing done; 1 files expanded, we may have blocked.
- * Should be called with the files->file_lock spinlock held for write.
+ * This function will expand the file structures, if the requested size exceeds
+ * the current capacity and there is room for expansion.
+ * Return <0 error code on error; 0 when nothing done; 1 when files were
+ * expanded and execution may have blocked.
+ * The files->file_lock should be held on entry, and will be held on exit.
  */
 int expand_files(struct files_struct *files, int nr)
 {
-	int err, expand = 0;
 	struct fdtable *fdt;
 
 	fdt = files_fdtable(files);
-	if (nr >= fdt->max_fdset || nr >= fdt->max_fds) {
-		if (fdt->max_fdset >= NR_OPEN ||
-			fdt->max_fds >= NR_OPEN || nr >= NR_OPEN) {
-			err = -EMFILE;
-			goto out;
-		}
-		expand = 1;
-		if ((err = expand_fdtable(files, nr)))
-			goto out;
-	}
-	err = expand;
-out:
-	return err;
+	/* Do we need to expand? */
+	if (nr < fdt->max_fdset && nr < fdt->max_fds)
+		return 0;
+	/* Can we expand? */
+	if (fdt->max_fdset >= NR_OPEN || fdt->max_fds >= NR_OPEN ||
+	    nr >= NR_OPEN)
+		return -EMFILE;
+
+	/* All good, so we try */
+	return expand_fdtable(files, nr);
 }
 
 static void __devinit fdtable_defer_list_init(int cpu)

commit 8b0e330b7720a206339887044fa275bf537a5264
Author: Andrew Morton <akpm@osdl.org>
Date:   Wed Sep 27 01:51:02 2006 -0700

    [PATCH] alloc_fdtable() cleanup
    
    free_fdset(NULL, ...) is legal.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index b3c6b82e6a9d..8d3bfca7714b 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -281,10 +281,8 @@ static struct fdtable *alloc_fdtable(int nr)
 out2:
 	nfds = fdt->max_fdset;
 out:
-  	if (new_openset)
-  		free_fdset(new_openset, nfds);
-  	if (new_execset)
-  		free_fdset(new_execset, nfds);
+	free_fdset(new_openset, nfds);
+	free_fdset(new_execset, nfds);
 	kfree(fdt);
 	return NULL;
 }

commit a29b0b74e73b66674d20a170e463fe9032f2272a
Author: Andrew Morton <akpm@osdl.org>
Date:   Wed Jul 12 09:03:08 2006 -0700

    [PATCH] alloc_fdtable() expansion fix
    
    We're supposed to go the next power of two if nfds==nr.
    
    Of `nr', not of `nfsd'.
    
    Spotted by Rene Scharfe <rene.scharfe@lsrfire.ath.cx>
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index c8f1b0af8e00..b3c6b82e6a9d 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -240,7 +240,7 @@ static struct fdtable *alloc_fdtable(int nr)
 	if (!fdt)
   		goto out;
 
-	nfds = max_t(int, 8 * L1_CACHE_BYTES, roundup_pow_of_two(nfds));
+	nfds = max_t(int, 8 * L1_CACHE_BYTES, roundup_pow_of_two(nr + 1));
 	if (nfds > NR_OPEN)
 		nfds = NR_OPEN;
 

commit d579091b4385e9386e244622d593fe064aa8e8e7
Author: Kirill Korotaev <dev@openvz.org>
Date:   Wed Jul 12 09:03:05 2006 -0700

    [PATCH] fix fdset leakage
    
    When found, it is obvious.  nfds calculated when allocating fdsets is
    rewritten by calculation of size of fdtable, and when we are unlucky, we
    try to free fdsets of wrong size.
    
    Found due to OpenVZ resource management (User Beancounters).
    
    Signed-off-by: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: Kirill Korotaev <dev@openvz.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 3f356086061d..c8f1b0af8e00 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -273,11 +273,13 @@ static struct fdtable *alloc_fdtable(int nr)
 	} while (nfds <= nr);
 	new_fds = alloc_fd_array(nfds);
 	if (!new_fds)
-		goto out;
+		goto out2;
 	fdt->fd = new_fds;
 	fdt->max_fds = nfds;
 	fdt->free_files = NULL;
 	return fdt;
+out2:
+	nfds = fdt->max_fdset;
 out:
   	if (new_openset)
   		free_fdset(new_openset, nfds);

commit 92eb7a2f28d551acedeb5752263267a64b1f5ddf
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Jul 10 04:45:31 2006 -0700

    [PATCH] fix weird logic in alloc_fdtable()
    
    There's a fairly obvious infinite loop in there.
    
    Also, use roundup_pow_of_two() rather than open-coding stuff.
    
    Cc: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 55f4e7022563..3f356086061d 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -240,13 +240,9 @@ static struct fdtable *alloc_fdtable(int nr)
 	if (!fdt)
   		goto out;
 
-	nfds = 8 * L1_CACHE_BYTES;
-  	/* Expand to the max in easy steps */
-  	while (nfds <= nr) {
-		nfds = nfds * 2;
-		if (nfds > NR_OPEN)
-			nfds = NR_OPEN;
-	}
+	nfds = max_t(int, 8 * L1_CACHE_BYTES, roundup_pow_of_two(nfds));
+	if (nfds > NR_OPEN)
+		nfds = NR_OPEN;
 
   	new_openset = alloc_fdset(nfds);
   	new_execset = alloc_fdset(nfds);

commit 0a945022778f100115d0cb6234eb28fc1b15ccaf
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Tue Mar 28 01:56:37 2006 -0800

    [PATCH] for_each_possible_cpu: fixes for generic part
    
    replaces for_each_cpu with for_each_possible_cpu().
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index bbc743314730..55f4e7022563 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -373,6 +373,6 @@ static void __devinit fdtable_defer_list_init(int cpu)
 void __init files_defer_init(void)
 {
 	int i;
-	for_each_cpu(i)
+	for_each_possible_cpu(i)
 		fdtable_defer_list_init(i);
 }

commit 0c9e63fd38a2fb2181668a0cdd622a3c23cfd567
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Thu Mar 23 03:00:12 2006 -0800

    [PATCH] Shrinks sizeof(files_struct) and better layout
    
    1) Reduce the size of (struct fdtable) to exactly 64 bytes on 32bits
       platforms, lowering kmalloc() allocated space by 50%.
    
    2) Reduce the size of (files_struct), using a special 32 bits (or
       64bits) embedded_fd_set, instead of a 1024 bits fd_set for the
       close_on_exec_init and open_fds_init fields.  This save some ram (248
       bytes per task) as most tasks dont open more than 32 files.  D-Cache
       footprint for such tasks is also reduced to the minimum.
    
    3) Reduce size of allocated fdset.  Currently two full pages are
       allocated, that is 32768 bits on x86 for example, and way too much.  The
       minimum is now L1_CACHE_BYTES.
    
    UP and SMP should benefit from this patch, because most tasks will touch
    only one cache line when open()/close() stdin/stdout/stderr (0/1/2),
    (next_fd, close_on_exec_init, open_fds_init, fd_array[0 ..  2] being in the
    same cache line)
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index cea7cbea11d0..bbc743314730 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -125,7 +125,8 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 		kmem_cache_free(files_cachep, fdt->free_files);
 		return;
 	}
-	if (fdt->max_fdset <= __FD_SETSIZE && fdt->max_fds <= NR_OPEN_DEFAULT) {
+	if (fdt->max_fdset <= EMBEDDED_FD_SET_SIZE &&
+		fdt->max_fds <= NR_OPEN_DEFAULT) {
 		/*
 		 * The fdtable was embedded
 		 */
@@ -155,8 +156,9 @@ static void free_fdtable_rcu(struct rcu_head *rcu)
 
 void free_fdtable(struct fdtable *fdt)
 {
-	if (fdt->free_files || fdt->max_fdset > __FD_SETSIZE ||
-					fdt->max_fds > NR_OPEN_DEFAULT)
+	if (fdt->free_files ||
+		fdt->max_fdset > EMBEDDED_FD_SET_SIZE ||
+		fdt->max_fds > NR_OPEN_DEFAULT)
 		call_rcu(&fdt->rcu, free_fdtable_rcu);
 }
 
@@ -199,7 +201,6 @@ static void copy_fdtable(struct fdtable *nfdt, struct fdtable *fdt)
 		       (nfdt->max_fds - fdt->max_fds) *
 					sizeof(struct file *));
 	}
-	nfdt->next_fd = fdt->next_fd;
 }
 
 /*
@@ -220,11 +221,9 @@ fd_set * alloc_fdset(int num)
 
 void free_fdset(fd_set *array, int num)
 {
-	int size = num / 8;
-
-	if (num <= __FD_SETSIZE) /* Don't free an embedded fdset */
+	if (num <= EMBEDDED_FD_SET_SIZE) /* Don't free an embedded fdset */
 		return;
-	else if (size <= PAGE_SIZE)
+	else if (num <= 8 * PAGE_SIZE)
 		kfree(array);
 	else
 		vfree(array);
@@ -237,22 +236,17 @@ static struct fdtable *alloc_fdtable(int nr)
   	fd_set *new_openset = NULL, *new_execset = NULL;
 	struct file **new_fds;
 
-	fdt = kmalloc(sizeof(*fdt), GFP_KERNEL);
+	fdt = kzalloc(sizeof(*fdt), GFP_KERNEL);
 	if (!fdt)
   		goto out;
-	memset(fdt, 0, sizeof(*fdt));
 
-	nfds = __FD_SETSIZE;
+	nfds = 8 * L1_CACHE_BYTES;
   	/* Expand to the max in easy steps */
-  	do {
-		if (nfds < (PAGE_SIZE * 8))
-			nfds = PAGE_SIZE * 8;
-		else {
-			nfds = nfds * 2;
-			if (nfds > NR_OPEN)
-				nfds = NR_OPEN;
-		}
-	} while (nfds <= nr);
+  	while (nfds <= nr) {
+		nfds = nfds * 2;
+		if (nfds > NR_OPEN)
+			nfds = NR_OPEN;
+	}
 
   	new_openset = alloc_fdset(nfds);
   	new_execset = alloc_fdset(nfds);

commit 88a2a4ac6b671a4b0dd5d2d762418904c05f4104
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sat Feb 4 23:27:36 2006 -0800

    [PATCH] percpu data: only iterate over possible CPUs
    
    percpu_data blindly allocates bootmem memory to store NR_CPUS instances of
    cpudata, instead of allocating memory only for possible cpus.
    
    As a preparation for changing that, we need to convert various 0 -> NR_CPUS
    loops to use for_each_cpu().
    
    (The above only applies to users of asm-generic/percpu.h.  powerpc has gone it
    alone and is presently only allocating memory for present CPUs, so it's
    currently corrupting memory).
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Jens Axboe <axboe@suse.de>
    Cc: Anton Blanchard <anton@samba.org>
    Acked-by: William Irwin <wli@holomorphy.com>
    Cc: Andi Kleen <ak@muc.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index fd066b261c75..cea7cbea11d0 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -379,7 +379,6 @@ static void __devinit fdtable_defer_list_init(int cpu)
 void __init files_defer_init(void)
 {
 	int i;
-	/* Really early - can't use for_each_cpu */
-	for (i = 0; i < NR_CPUS; i++)
+	for_each_cpu(i)
 		fdtable_defer_list_init(i);
 }

commit 0b175a7e68c2f51555820efb0a01681e3419c1bc
Author: Dipankar Sarma <dipankar@in.ibm.com>
Date:   Thu Sep 15 00:48:42 2005 +0530

    [PATCH] Fix the fdtable freeing in the case of vmalloced fdset/arrays
    
    Noted by David Miller:
    
      "The bug is that free_fd_array() takes a "num" argument, but when
       calling it from __free_fdtable() we're instead passing in the size in
       bytes (ie.  "num * sizeof(struct file *)")."
    
    Yes it is a bug. I think I messed it up while merging newer
    changes with an older version where I was using size in bytes
    to optimize.
    
    Signed-off-by: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 2127a7b9dc3a..fd066b261c75 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -69,13 +69,9 @@ void free_fd_array(struct file **array, int num)
 
 static void __free_fdtable(struct fdtable *fdt)
 {
-	int fdset_size, fdarray_size;
-
-	fdset_size = fdt->max_fdset / 8;
-	fdarray_size = fdt->max_fds * sizeof(struct file *);
-	free_fdset(fdt->open_fds, fdset_size);
-	free_fdset(fdt->close_on_exec, fdset_size);
-	free_fd_array(fdt->fd, fdarray_size);
+	free_fdset(fdt->open_fds, fdt->max_fdset);
+	free_fdset(fdt->close_on_exec, fdt->max_fdset);
+	free_fd_array(fdt->fd, fdt->max_fds);
 	kfree(fdt);
 }
 

commit ab2af1f5005069321c5d130f09cce577b03f43ef
Author: Dipankar Sarma <dipankar@in.ibm.com>
Date:   Fri Sep 9 13:04:13 2005 -0700

    [PATCH] files: files struct with RCU
    
    Patch to eliminate struct files_struct.file_lock spinlock on the reader side
    and use rcu refcounting rcuref_xxx api for the f_count refcounter.  The
    updates to the fdtable are done by allocating a new fdtable structure and
    setting files->fdt to point to the new structure.  The fdtable structure is
    protected by RCU thereby allowing lock-free lookup.  For fd arrays/sets that
    are vmalloced, we use keventd to free them since RCU callbacks can't sleep.  A
    global list of fdtable to be freed is not scalable, so we use a per-cpu list.
    If keventd is already handling the current cpu's work, we use a timer to defer
    queueing of that work.
    
    Since the last publication, this patch has been re-written to avoid using
    explicit memory barriers and use rcu_assign_pointer(), rcu_dereference()
    premitives instead.  This required that the fd information is kept in a
    separate structure (fdtable) and updated atomically.
    
    Signed-off-by: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index f5926ce73f37..2127a7b9dc3a 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -13,6 +13,25 @@
 #include <linux/vmalloc.h>
 #include <linux/file.h>
 #include <linux/bitops.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/rcupdate.h>
+#include <linux/workqueue.h>
+
+struct fdtable_defer {
+	spinlock_t lock;
+	struct work_struct wq;
+	struct timer_list timer;
+	struct fdtable *next;
+};
+
+/*
+ * We use this list to defer free fdtables that have vmalloced
+ * sets/arrays. By keeping a per-cpu list, we avoid having to embed
+ * the work_struct in fdtable itself which avoids a 64 byte (i386) increase in
+ * this per-task structure.
+ */
+static DEFINE_PER_CPU(struct fdtable_defer, fdtable_defer_list);
 
 
 /*
@@ -48,85 +67,143 @@ void free_fd_array(struct file **array, int num)
 		vfree(array);
 }
 
-/*
- * Expand the fd array in the files_struct.  Called with the files
- * spinlock held for write.
- */
-
-static int expand_fd_array(struct files_struct *files, int nr)
-	__releases(files->file_lock)
-	__acquires(files->file_lock)
+static void __free_fdtable(struct fdtable *fdt)
 {
-	struct file **new_fds;
-	int error, nfds;
-	struct fdtable *fdt;
+	int fdset_size, fdarray_size;
 
-	
-	error = -EMFILE;
-	fdt = files_fdtable(files);
-	if (fdt->max_fds >= NR_OPEN || nr >= NR_OPEN)
-		goto out;
+	fdset_size = fdt->max_fdset / 8;
+	fdarray_size = fdt->max_fds * sizeof(struct file *);
+	free_fdset(fdt->open_fds, fdset_size);
+	free_fdset(fdt->close_on_exec, fdset_size);
+	free_fd_array(fdt->fd, fdarray_size);
+	kfree(fdt);
+}
 
-	nfds = fdt->max_fds;
-	spin_unlock(&files->file_lock);
+static void fdtable_timer(unsigned long data)
+{
+	struct fdtable_defer *fddef = (struct fdtable_defer *)data;
 
-	/* 
-	 * Expand to the max in easy steps, and keep expanding it until
-	 * we have enough for the requested fd array size. 
+	spin_lock(&fddef->lock);
+	/*
+	 * If someone already emptied the queue return.
 	 */
+	if (!fddef->next)
+		goto out;
+	if (!schedule_work(&fddef->wq))
+		mod_timer(&fddef->timer, 5);
+out:
+	spin_unlock(&fddef->lock);
+}
 
-	do {
-#if NR_OPEN_DEFAULT < 256
-		if (nfds < 256)
-			nfds = 256;
-		else 
-#endif
-		if (nfds < (PAGE_SIZE / sizeof(struct file *)))
-			nfds = PAGE_SIZE / sizeof(struct file *);
-		else {
-			nfds = nfds * 2;
-			if (nfds > NR_OPEN)
-				nfds = NR_OPEN;
-		}
-	} while (nfds <= nr);
+static void free_fdtable_work(struct fdtable_defer *f)
+{
+	struct fdtable *fdt;
 
-	error = -ENOMEM;
-	new_fds = alloc_fd_array(nfds);
-	spin_lock(&files->file_lock);
-	if (!new_fds)
-		goto out;
+	spin_lock_bh(&f->lock);
+	fdt = f->next;
+	f->next = NULL;
+	spin_unlock_bh(&f->lock);
+	while(fdt) {
+		struct fdtable *next = fdt->next;
+		__free_fdtable(fdt);
+		fdt = next;
+	}
+}
 
-	/* Copy the existing array and install the new pointer */
-	fdt = files_fdtable(files);
+static void free_fdtable_rcu(struct rcu_head *rcu)
+{
+	struct fdtable *fdt = container_of(rcu, struct fdtable, rcu);
+	int fdset_size, fdarray_size;
+	struct fdtable_defer *fddef;
 
-	if (nfds > fdt->max_fds) {
-		struct file **old_fds;
-		int i;
-		
-		old_fds = xchg(&fdt->fd, new_fds);
-		i = xchg(&fdt->max_fds, nfds);
-
-		/* Don't copy/clear the array if we are creating a new
-		   fd array for fork() */
-		if (i) {
-			memcpy(new_fds, old_fds, i * sizeof(struct file *));
-			/* clear the remainder of the array */
-			memset(&new_fds[i], 0,
-			       (nfds-i) * sizeof(struct file *)); 
-
-			spin_unlock(&files->file_lock);
-			free_fd_array(old_fds, i);
-			spin_lock(&files->file_lock);
-		}
+	BUG_ON(!fdt);
+	fdset_size = fdt->max_fdset / 8;
+	fdarray_size = fdt->max_fds * sizeof(struct file *);
+
+	if (fdt->free_files) {
+		/*
+		 * The this fdtable was embedded in the files structure
+		 * and the files structure itself was getting destroyed.
+		 * It is now safe to free the files structure.
+		 */
+		kmem_cache_free(files_cachep, fdt->free_files);
+		return;
+	}
+	if (fdt->max_fdset <= __FD_SETSIZE && fdt->max_fds <= NR_OPEN_DEFAULT) {
+		/*
+		 * The fdtable was embedded
+		 */
+		return;
+	}
+	if (fdset_size <= PAGE_SIZE && fdarray_size <= PAGE_SIZE) {
+		kfree(fdt->open_fds);
+		kfree(fdt->close_on_exec);
+		kfree(fdt->fd);
+		kfree(fdt);
 	} else {
-		/* Somebody expanded the array while we slept ... */
-		spin_unlock(&files->file_lock);
-		free_fd_array(new_fds, nfds);
-		spin_lock(&files->file_lock);
+		fddef = &get_cpu_var(fdtable_defer_list);
+		spin_lock(&fddef->lock);
+		fdt->next = fddef->next;
+		fddef->next = fdt;
+		/*
+		 * vmallocs are handled from the workqueue context.
+		 * If the per-cpu workqueue is running, then we
+		 * defer work scheduling through a timer.
+		 */
+		if (!schedule_work(&fddef->wq))
+			mod_timer(&fddef->timer, 5);
+		spin_unlock(&fddef->lock);
+		put_cpu_var(fdtable_defer_list);
 	}
-	error = 0;
-out:
-	return error;
+}
+
+void free_fdtable(struct fdtable *fdt)
+{
+	if (fdt->free_files || fdt->max_fdset > __FD_SETSIZE ||
+					fdt->max_fds > NR_OPEN_DEFAULT)
+		call_rcu(&fdt->rcu, free_fdtable_rcu);
+}
+
+/*
+ * Expand the fdset in the files_struct.  Called with the files spinlock
+ * held for write.
+ */
+static void copy_fdtable(struct fdtable *nfdt, struct fdtable *fdt)
+{
+	int i;
+	int count;
+
+	BUG_ON(nfdt->max_fdset < fdt->max_fdset);
+	BUG_ON(nfdt->max_fds < fdt->max_fds);
+	/* Copy the existing tables and install the new pointers */
+
+	i = fdt->max_fdset / (sizeof(unsigned long) * 8);
+	count = (nfdt->max_fdset - fdt->max_fdset) / 8;
+
+	/*
+	 * Don't copy the entire array if the current fdset is
+	 * not yet initialised.
+	 */
+	if (i) {
+		memcpy (nfdt->open_fds, fdt->open_fds,
+						fdt->max_fdset/8);
+		memcpy (nfdt->close_on_exec, fdt->close_on_exec,
+						fdt->max_fdset/8);
+		memset (&nfdt->open_fds->fds_bits[i], 0, count);
+		memset (&nfdt->close_on_exec->fds_bits[i], 0, count);
+	}
+
+	/* Don't copy/clear the array if we are creating a new
+	   fd array for fork() */
+	if (fdt->max_fds) {
+		memcpy(nfdt->fd, fdt->fd,
+			fdt->max_fds * sizeof(struct file *));
+		/* clear the remainder of the array */
+		memset(&nfdt->fd[fdt->max_fds], 0,
+		       (nfdt->max_fds - fdt->max_fds) *
+					sizeof(struct file *));
+	}
+	nfdt->next_fd = fdt->next_fd;
 }
 
 /*
@@ -157,28 +234,21 @@ void free_fdset(fd_set *array, int num)
 		vfree(array);
 }
 
-/*
- * Expand the fdset in the files_struct.  Called with the files spinlock
- * held for write.
- */
-static int expand_fdset(struct files_struct *files, int nr)
-	__releases(file->file_lock)
-	__acquires(file->file_lock)
+static struct fdtable *alloc_fdtable(int nr)
 {
-	fd_set *new_openset = NULL, *new_execset = NULL;
-	int error, nfds = 0;
-	struct fdtable *fdt;
-
-	error = -EMFILE;
-	fdt = files_fdtable(files);
-	if (fdt->max_fdset >= NR_OPEN || nr >= NR_OPEN)
-		goto out;
+	struct fdtable *fdt = NULL;
+	int nfds = 0;
+  	fd_set *new_openset = NULL, *new_execset = NULL;
+	struct file **new_fds;
 
-	nfds = fdt->max_fdset;
-	spin_unlock(&files->file_lock);
+	fdt = kmalloc(sizeof(*fdt), GFP_KERNEL);
+	if (!fdt)
+  		goto out;
+	memset(fdt, 0, sizeof(*fdt));
 
-	/* Expand to the max in easy steps */
-	do {
+	nfds = __FD_SETSIZE;
+  	/* Expand to the max in easy steps */
+  	do {
 		if (nfds < (PAGE_SIZE * 8))
 			nfds = PAGE_SIZE * 8;
 		else {
@@ -188,50 +258,88 @@ static int expand_fdset(struct files_struct *files, int nr)
 		}
 	} while (nfds <= nr);
 
-	error = -ENOMEM;
-	new_openset = alloc_fdset(nfds);
-	new_execset = alloc_fdset(nfds);
-	spin_lock(&files->file_lock);
-	if (!new_openset || !new_execset)
+  	new_openset = alloc_fdset(nfds);
+  	new_execset = alloc_fdset(nfds);
+  	if (!new_openset || !new_execset)
+  		goto out;
+	fdt->open_fds = new_openset;
+	fdt->close_on_exec = new_execset;
+	fdt->max_fdset = nfds;
+
+	nfds = NR_OPEN_DEFAULT;
+	/*
+	 * Expand to the max in easy steps, and keep expanding it until
+	 * we have enough for the requested fd array size.
+	 */
+	do {
+#if NR_OPEN_DEFAULT < 256
+		if (nfds < 256)
+			nfds = 256;
+		else
+#endif
+		if (nfds < (PAGE_SIZE / sizeof(struct file *)))
+			nfds = PAGE_SIZE / sizeof(struct file *);
+		else {
+			nfds = nfds * 2;
+			if (nfds > NR_OPEN)
+				nfds = NR_OPEN;
+  		}
+	} while (nfds <= nr);
+	new_fds = alloc_fd_array(nfds);
+	if (!new_fds)
 		goto out;
+	fdt->fd = new_fds;
+	fdt->max_fds = nfds;
+	fdt->free_files = NULL;
+	return fdt;
+out:
+  	if (new_openset)
+  		free_fdset(new_openset, nfds);
+  	if (new_execset)
+  		free_fdset(new_execset, nfds);
+	kfree(fdt);
+	return NULL;
+}
 
-	error = 0;
-	
-	/* Copy the existing tables and install the new pointers */
+/*
+ * Expands the file descriptor table - it will allocate a new fdtable and
+ * both fd array and fdset. It is expected to be called with the
+ * files_lock held.
+ */
+static int expand_fdtable(struct files_struct *files, int nr)
+	__releases(files->file_lock)
+	__acquires(files->file_lock)
+{
+	int error = 0;
+	struct fdtable *fdt;
+	struct fdtable *nfdt = NULL;
+
+	spin_unlock(&files->file_lock);
+	nfdt = alloc_fdtable(nr);
+	if (!nfdt) {
+		error = -ENOMEM;
+		spin_lock(&files->file_lock);
+		goto out;
+	}
+
+	spin_lock(&files->file_lock);
 	fdt = files_fdtable(files);
-	if (nfds > fdt->max_fdset) {
-		int i = fdt->max_fdset / (sizeof(unsigned long) * 8);
-		int count = (nfds - fdt->max_fdset) / 8;
-		
-		/* 
-		 * Don't copy the entire array if the current fdset is
-		 * not yet initialised.  
-		 */
-		if (i) {
-			memcpy (new_openset, fdt->open_fds, fdt->max_fdset/8);
-			memcpy (new_execset, fdt->close_on_exec, fdt->max_fdset/8);
-			memset (&new_openset->fds_bits[i], 0, count);
-			memset (&new_execset->fds_bits[i], 0, count);
-		}
-		
-		nfds = xchg(&fdt->max_fdset, nfds);
-		new_openset = xchg(&fdt->open_fds, new_openset);
-		new_execset = xchg(&fdt->close_on_exec, new_execset);
+	/*
+	 * Check again since another task may have expanded the
+	 * fd table while we dropped the lock
+	 */
+	if (nr >= fdt->max_fds || nr >= fdt->max_fdset) {
+		copy_fdtable(nfdt, fdt);
+	} else {
+		/* Somebody expanded while we dropped file_lock */
 		spin_unlock(&files->file_lock);
-		free_fdset (new_openset, nfds);
-		free_fdset (new_execset, nfds);
+		__free_fdtable(nfdt);
 		spin_lock(&files->file_lock);
-		return 0;
-	} 
-	/* Somebody expanded the array while we slept ... */
-
+		goto out;
+	}
+	rcu_assign_pointer(files->fdt, nfdt);
+	free_fdtable(fdt);
 out:
-	spin_unlock(&files->file_lock);
-	if (new_openset)
-		free_fdset(new_openset, nfds);
-	if (new_execset)
-		free_fdset(new_execset, nfds);
-	spin_lock(&files->file_lock);
 	return error;
 }
 
@@ -246,17 +354,36 @@ int expand_files(struct files_struct *files, int nr)
 	struct fdtable *fdt;
 
 	fdt = files_fdtable(files);
-	if (nr >= fdt->max_fdset) {
-		expand = 1;
-		if ((err = expand_fdset(files, nr)))
+	if (nr >= fdt->max_fdset || nr >= fdt->max_fds) {
+		if (fdt->max_fdset >= NR_OPEN ||
+			fdt->max_fds >= NR_OPEN || nr >= NR_OPEN) {
+			err = -EMFILE;
 			goto out;
-	}
-	if (nr >= fdt->max_fds) {
+		}
 		expand = 1;
-		if ((err = expand_fd_array(files, nr)))
+		if ((err = expand_fdtable(files, nr)))
 			goto out;
 	}
 	err = expand;
 out:
 	return err;
 }
+
+static void __devinit fdtable_defer_list_init(int cpu)
+{
+	struct fdtable_defer *fddef = &per_cpu(fdtable_defer_list, cpu);
+	spin_lock_init(&fddef->lock);
+	INIT_WORK(&fddef->wq, (void (*)(void *))free_fdtable_work, fddef);
+	init_timer(&fddef->timer);
+	fddef->timer.data = (unsigned long)fddef;
+	fddef->timer.function = fdtable_timer;
+	fddef->next = NULL;
+}
+
+void __init files_defer_init(void)
+{
+	int i;
+	/* Really early - can't use for_each_cpu */
+	for (i = 0; i < NR_CPUS; i++)
+		fdtable_defer_list_init(i);
+}

commit badf16621c1f9d1ac753be056fce11b43d6e0be5
Author: Dipankar Sarma <dipankar@in.ibm.com>
Date:   Fri Sep 9 13:04:10 2005 -0700

    [PATCH] files: break up files struct
    
    In order for the RCU to work, the file table array, sets and their sizes must
    be updated atomically.  Instead of ensuring this through too many memory
    barriers, we put the arrays and their sizes in a separate structure.  This
    patch takes the first step of putting the file table elements in a separate
    structure fdtable that is embedded withing files_struct.  It also changes all
    the users to refer to the file table using files_fdtable() macro.  Subsequent
    applciation of RCU becomes easier after this.
    
    Signed-off-by: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-Off-By: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/file.c b/fs/file.c
index 92b5f25985d2..f5926ce73f37 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -59,13 +59,15 @@ static int expand_fd_array(struct files_struct *files, int nr)
 {
 	struct file **new_fds;
 	int error, nfds;
+	struct fdtable *fdt;
 
 	
 	error = -EMFILE;
-	if (files->max_fds >= NR_OPEN || nr >= NR_OPEN)
+	fdt = files_fdtable(files);
+	if (fdt->max_fds >= NR_OPEN || nr >= NR_OPEN)
 		goto out;
 
-	nfds = files->max_fds;
+	nfds = fdt->max_fds;
 	spin_unlock(&files->file_lock);
 
 	/* 
@@ -95,13 +97,14 @@ static int expand_fd_array(struct files_struct *files, int nr)
 		goto out;
 
 	/* Copy the existing array and install the new pointer */
+	fdt = files_fdtable(files);
 
-	if (nfds > files->max_fds) {
+	if (nfds > fdt->max_fds) {
 		struct file **old_fds;
 		int i;
 		
-		old_fds = xchg(&files->fd, new_fds);
-		i = xchg(&files->max_fds, nfds);
+		old_fds = xchg(&fdt->fd, new_fds);
+		i = xchg(&fdt->max_fds, nfds);
 
 		/* Don't copy/clear the array if we are creating a new
 		   fd array for fork() */
@@ -164,12 +167,14 @@ static int expand_fdset(struct files_struct *files, int nr)
 {
 	fd_set *new_openset = NULL, *new_execset = NULL;
 	int error, nfds = 0;
+	struct fdtable *fdt;
 
 	error = -EMFILE;
-	if (files->max_fdset >= NR_OPEN || nr >= NR_OPEN)
+	fdt = files_fdtable(files);
+	if (fdt->max_fdset >= NR_OPEN || nr >= NR_OPEN)
 		goto out;
 
-	nfds = files->max_fdset;
+	nfds = fdt->max_fdset;
 	spin_unlock(&files->file_lock);
 
 	/* Expand to the max in easy steps */
@@ -193,24 +198,25 @@ static int expand_fdset(struct files_struct *files, int nr)
 	error = 0;
 	
 	/* Copy the existing tables and install the new pointers */
-	if (nfds > files->max_fdset) {
-		int i = files->max_fdset / (sizeof(unsigned long) * 8);
-		int count = (nfds - files->max_fdset) / 8;
+	fdt = files_fdtable(files);
+	if (nfds > fdt->max_fdset) {
+		int i = fdt->max_fdset / (sizeof(unsigned long) * 8);
+		int count = (nfds - fdt->max_fdset) / 8;
 		
 		/* 
 		 * Don't copy the entire array if the current fdset is
 		 * not yet initialised.  
 		 */
 		if (i) {
-			memcpy (new_openset, files->open_fds, files->max_fdset/8);
-			memcpy (new_execset, files->close_on_exec, files->max_fdset/8);
+			memcpy (new_openset, fdt->open_fds, fdt->max_fdset/8);
+			memcpy (new_execset, fdt->close_on_exec, fdt->max_fdset/8);
 			memset (&new_openset->fds_bits[i], 0, count);
 			memset (&new_execset->fds_bits[i], 0, count);
 		}
 		
-		nfds = xchg(&files->max_fdset, nfds);
-		new_openset = xchg(&files->open_fds, new_openset);
-		new_execset = xchg(&files->close_on_exec, new_execset);
+		nfds = xchg(&fdt->max_fdset, nfds);
+		new_openset = xchg(&fdt->open_fds, new_openset);
+		new_execset = xchg(&fdt->close_on_exec, new_execset);
 		spin_unlock(&files->file_lock);
 		free_fdset (new_openset, nfds);
 		free_fdset (new_execset, nfds);
@@ -237,13 +243,15 @@ static int expand_fdset(struct files_struct *files, int nr)
 int expand_files(struct files_struct *files, int nr)
 {
 	int err, expand = 0;
+	struct fdtable *fdt;
 
-	if (nr >= files->max_fdset) {
+	fdt = files_fdtable(files);
+	if (nr >= fdt->max_fdset) {
 		expand = 1;
 		if ((err = expand_fdset(files, nr)))
 			goto out;
 	}
-	if (nr >= files->max_fds) {
+	if (nr >= fdt->max_fds) {
 		expand = 1;
 		if ((err = expand_fd_array(files, nr)))
 			goto out;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/file.c b/fs/file.c
new file mode 100644
index 000000000000..92b5f25985d2
--- /dev/null
+++ b/fs/file.c
@@ -0,0 +1,254 @@
+/*
+ *  linux/fs/file.c
+ *
+ *  Copyright (C) 1998-1999, Stephen Tweedie and Bill Hawes
+ *
+ *  Manage the dynamic fd arrays in the process files_struct.
+ */
+
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/time.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/file.h>
+#include <linux/bitops.h>
+
+
+/*
+ * Allocate an fd array, using kmalloc or vmalloc.
+ * Note: the array isn't cleared at allocation time.
+ */
+struct file ** alloc_fd_array(int num)
+{
+	struct file **new_fds;
+	int size = num * sizeof(struct file *);
+
+	if (size <= PAGE_SIZE)
+		new_fds = (struct file **) kmalloc(size, GFP_KERNEL);
+	else 
+		new_fds = (struct file **) vmalloc(size);
+	return new_fds;
+}
+
+void free_fd_array(struct file **array, int num)
+{
+	int size = num * sizeof(struct file *);
+
+	if (!array) {
+		printk (KERN_ERR "free_fd_array: array = 0 (num = %d)\n", num);
+		return;
+	}
+
+	if (num <= NR_OPEN_DEFAULT) /* Don't free the embedded fd array! */
+		return;
+	else if (size <= PAGE_SIZE)
+		kfree(array);
+	else
+		vfree(array);
+}
+
+/*
+ * Expand the fd array in the files_struct.  Called with the files
+ * spinlock held for write.
+ */
+
+static int expand_fd_array(struct files_struct *files, int nr)
+	__releases(files->file_lock)
+	__acquires(files->file_lock)
+{
+	struct file **new_fds;
+	int error, nfds;
+
+	
+	error = -EMFILE;
+	if (files->max_fds >= NR_OPEN || nr >= NR_OPEN)
+		goto out;
+
+	nfds = files->max_fds;
+	spin_unlock(&files->file_lock);
+
+	/* 
+	 * Expand to the max in easy steps, and keep expanding it until
+	 * we have enough for the requested fd array size. 
+	 */
+
+	do {
+#if NR_OPEN_DEFAULT < 256
+		if (nfds < 256)
+			nfds = 256;
+		else 
+#endif
+		if (nfds < (PAGE_SIZE / sizeof(struct file *)))
+			nfds = PAGE_SIZE / sizeof(struct file *);
+		else {
+			nfds = nfds * 2;
+			if (nfds > NR_OPEN)
+				nfds = NR_OPEN;
+		}
+	} while (nfds <= nr);
+
+	error = -ENOMEM;
+	new_fds = alloc_fd_array(nfds);
+	spin_lock(&files->file_lock);
+	if (!new_fds)
+		goto out;
+
+	/* Copy the existing array and install the new pointer */
+
+	if (nfds > files->max_fds) {
+		struct file **old_fds;
+		int i;
+		
+		old_fds = xchg(&files->fd, new_fds);
+		i = xchg(&files->max_fds, nfds);
+
+		/* Don't copy/clear the array if we are creating a new
+		   fd array for fork() */
+		if (i) {
+			memcpy(new_fds, old_fds, i * sizeof(struct file *));
+			/* clear the remainder of the array */
+			memset(&new_fds[i], 0,
+			       (nfds-i) * sizeof(struct file *)); 
+
+			spin_unlock(&files->file_lock);
+			free_fd_array(old_fds, i);
+			spin_lock(&files->file_lock);
+		}
+	} else {
+		/* Somebody expanded the array while we slept ... */
+		spin_unlock(&files->file_lock);
+		free_fd_array(new_fds, nfds);
+		spin_lock(&files->file_lock);
+	}
+	error = 0;
+out:
+	return error;
+}
+
+/*
+ * Allocate an fdset array, using kmalloc or vmalloc.
+ * Note: the array isn't cleared at allocation time.
+ */
+fd_set * alloc_fdset(int num)
+{
+	fd_set *new_fdset;
+	int size = num / 8;
+
+	if (size <= PAGE_SIZE)
+		new_fdset = (fd_set *) kmalloc(size, GFP_KERNEL);
+	else
+		new_fdset = (fd_set *) vmalloc(size);
+	return new_fdset;
+}
+
+void free_fdset(fd_set *array, int num)
+{
+	int size = num / 8;
+
+	if (num <= __FD_SETSIZE) /* Don't free an embedded fdset */
+		return;
+	else if (size <= PAGE_SIZE)
+		kfree(array);
+	else
+		vfree(array);
+}
+
+/*
+ * Expand the fdset in the files_struct.  Called with the files spinlock
+ * held for write.
+ */
+static int expand_fdset(struct files_struct *files, int nr)
+	__releases(file->file_lock)
+	__acquires(file->file_lock)
+{
+	fd_set *new_openset = NULL, *new_execset = NULL;
+	int error, nfds = 0;
+
+	error = -EMFILE;
+	if (files->max_fdset >= NR_OPEN || nr >= NR_OPEN)
+		goto out;
+
+	nfds = files->max_fdset;
+	spin_unlock(&files->file_lock);
+
+	/* Expand to the max in easy steps */
+	do {
+		if (nfds < (PAGE_SIZE * 8))
+			nfds = PAGE_SIZE * 8;
+		else {
+			nfds = nfds * 2;
+			if (nfds > NR_OPEN)
+				nfds = NR_OPEN;
+		}
+	} while (nfds <= nr);
+
+	error = -ENOMEM;
+	new_openset = alloc_fdset(nfds);
+	new_execset = alloc_fdset(nfds);
+	spin_lock(&files->file_lock);
+	if (!new_openset || !new_execset)
+		goto out;
+
+	error = 0;
+	
+	/* Copy the existing tables and install the new pointers */
+	if (nfds > files->max_fdset) {
+		int i = files->max_fdset / (sizeof(unsigned long) * 8);
+		int count = (nfds - files->max_fdset) / 8;
+		
+		/* 
+		 * Don't copy the entire array if the current fdset is
+		 * not yet initialised.  
+		 */
+		if (i) {
+			memcpy (new_openset, files->open_fds, files->max_fdset/8);
+			memcpy (new_execset, files->close_on_exec, files->max_fdset/8);
+			memset (&new_openset->fds_bits[i], 0, count);
+			memset (&new_execset->fds_bits[i], 0, count);
+		}
+		
+		nfds = xchg(&files->max_fdset, nfds);
+		new_openset = xchg(&files->open_fds, new_openset);
+		new_execset = xchg(&files->close_on_exec, new_execset);
+		spin_unlock(&files->file_lock);
+		free_fdset (new_openset, nfds);
+		free_fdset (new_execset, nfds);
+		spin_lock(&files->file_lock);
+		return 0;
+	} 
+	/* Somebody expanded the array while we slept ... */
+
+out:
+	spin_unlock(&files->file_lock);
+	if (new_openset)
+		free_fdset(new_openset, nfds);
+	if (new_execset)
+		free_fdset(new_execset, nfds);
+	spin_lock(&files->file_lock);
+	return error;
+}
+
+/*
+ * Expand files.
+ * Return <0 on error; 0 nothing done; 1 files expanded, we may have blocked.
+ * Should be called with the files->file_lock spinlock held for write.
+ */
+int expand_files(struct files_struct *files, int nr)
+{
+	int err, expand = 0;
+
+	if (nr >= files->max_fdset) {
+		expand = 1;
+		if ((err = expand_fdset(files, nr)))
+			goto out;
+	}
+	if (nr >= files->max_fds) {
+		expand = 1;
+		if ((err = expand_fd_array(files, nr)))
+			goto out;
+	}
+	err = expand;
+out:
+	return err;
+}
