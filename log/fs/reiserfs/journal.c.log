commit ea3edd4dc23027083fbb4a73b65114d08fe73a76
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Mar 24 08:25:11 2020 +0100

    block: remove __bdevname
    
    There is no good reason for __bdevname to exist.  Just open code
    printing the string in the callers.  For three of them the format
    string can be trivially merged into existing printk statements,
    and in init/do_mounts.c we can at least do the scnprintf once at
    the start of the function, and unconditional of CONFIG_BLOCK to
    make the output for tiny configfs a little more helpful.
    
    Acked-by: Theodore Ts'o <tytso@mit.edu> # for ext4
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 072156c4f895..5c766330e493 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2599,7 +2599,6 @@ static int journal_init_dev(struct super_block *super,
 	int result;
 	dev_t jdev;
 	fmode_t blkdev_mode = FMODE_READ | FMODE_WRITE | FMODE_EXCL;
-	char b[BDEVNAME_SIZE];
 
 	result = 0;
 
@@ -2621,8 +2620,8 @@ static int journal_init_dev(struct super_block *super,
 			result = PTR_ERR(journal->j_dev_bd);
 			journal->j_dev_bd = NULL;
 			reiserfs_warning(super, "sh-458",
-					 "cannot init journal device '%s': %i",
-					 __bdevname(jdev, b), result);
+					 "cannot init journal device unknown-block(%u,%u): %i",
+					 MAJOR(jdev), MINOR(jdev), result);
 			return result;
 		} else if (jdev != super->s_dev)
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);

commit 154a4dcfc95f9dfcb2fda3ddf24c0602060d1120
Author: Alex Shi <alex.shi@linux.alibaba.com>
Date:   Tue Jan 21 18:25:38 2020 +0800

    fs/reiserfs: remove unused macros
    
    these macros are never used from introduced. better to
    remove them.
    
    Link: https://lore.kernel.org/r/1579602338-57079-1-git-send-email-alex.shi@linux.alibaba.com
    Signed-off-by: Alex Shi <alex.shi@linux.alibaba.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Bharath Vedartham <linux.bhar@gmail.com>
    Cc: Hariprasad Kelam <hariprasad.kelam@gmail.com>
    Cc: Jason Yan <yanaijie@huawei.com>
    Cc: zhengbin <zhengbin13@huawei.com>
    Cc: Jia-Ju Bai <baijiaju1990@gmail.com>
    Cc: reiserfs-devel@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4b3e3e73b512..072156c4f895 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -56,8 +56,6 @@
 /* gets a struct reiserfs_journal_list * from a list head */
 #define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
                                j_list))
-#define JOURNAL_WORK_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
-                               j_working_list))
 
 /* must be correct to keep the desc and commit structs at 4k */
 #define JOURNAL_TRANS_HALF 1018

commit 3e9fd5a48cb7b0ef93be097c2c1066738d37f5b7
Author: Jason Yan <yanaijie@huawei.com>
Date:   Wed Sep 25 16:47:19 2019 -0700

    fs/reiserfs/journal.c: remove set but not used variable
    
    Fix the following gcc warning:
    
    fs/reiserfs/journal.c: In function flush_used_journal_lists:
    fs/reiserfs/journal.c:1791:6: warning: variable ret set but not used
    [-Wunused-but-set-variable]
    
    Link: http://lkml.kernel.org/r/20190827032932.46622-1-yanaijie@huawei.com
    Signed-off-by: Jason Yan <yanaijie@huawei.com>
    Cc: zhengbin <zhengbin13@huawei.com>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 75d9d52d489f..4b3e3e73b512 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1788,7 +1788,6 @@ static int flush_used_journal_lists(struct super_block *s,
 {
 	unsigned long len = 0;
 	unsigned long cur_len;
-	int ret;
 	int i;
 	int limit = 256;
 	struct reiserfs_journal_list *tjl;
@@ -1825,9 +1824,9 @@ static int flush_used_journal_lists(struct super_block *s,
 	 * transactions, but only bother if we've actually spanned
 	 * across multiple lists
 	 */
-	if (flush_jl != jl) {
-		ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
-	}
+	if (flush_jl != jl)
+		kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
+
 	flush_journal_list(s, flush_jl, 1);
 	put_journal_list(s, flush_jl);
 	put_journal_list(s, jl);

commit 6e9ca45f77bc944d44face28059ab4db02e280fa
Author: zhengbin <zhengbin13@huawei.com>
Date:   Wed Sep 25 16:46:58 2019 -0700

    fs/reiserfs/journal.c: remove set but not used variables
    
    Fixes gcc '-Wunused-but-set-variable' warning:
    
    fs/reiserfs/journal.c: In function flush_older_commits:
    fs/reiserfs/journal.c:894:15: warning: variable first_trans_id set but not used [-Wunused-but-set-variable]
    fs/reiserfs/journal.c: In function flush_journal_list:
    fs/reiserfs/journal.c:1354:38: warning: variable last set but not used [-Wunused-but-set-variable]
    fs/reiserfs/journal.c: In function do_journal_release:
    fs/reiserfs/journal.c:1916:6: warning: variable flushed set but not used [-Wunused-but-set-variable]
    fs/reiserfs/journal.c: In function do_journal_end:
    fs/reiserfs/journal.c:3993:6: warning: variable old_start set but not used [-Wunused-but-set-variable]
    
    Link: http://lkml.kernel.org/r/1566379929-118398-2-git-send-email-zhengbin13@huawei.com
    Signed-off-by: zhengbin <zhengbin13@huawei.com>
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 11155b8513db..75d9d52d489f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -891,7 +891,6 @@ static int flush_older_commits(struct super_block *s,
 	struct list_head *entry;
 	unsigned int trans_id = jl->j_trans_id;
 	unsigned int other_trans_id;
-	unsigned int first_trans_id;
 
 find_first:
 	/*
@@ -914,8 +913,6 @@ static int flush_older_commits(struct super_block *s,
 		return 0;
 	}
 
-	first_trans_id = first_jl->j_trans_id;
-
 	entry = &first_jl->j_list;
 	while (1) {
 		other_jl = JOURNAL_LIST_ENTRY(entry);
@@ -1351,7 +1348,7 @@ static int flush_journal_list(struct super_block *s,
 			      struct reiserfs_journal_list *jl, int flushall)
 {
 	struct reiserfs_journal_list *pjl;
-	struct reiserfs_journal_cnode *cn, *last;
+	struct reiserfs_journal_cnode *cn;
 	int count;
 	int was_jwait = 0;
 	int was_dirty = 0;
@@ -1509,7 +1506,6 @@ static int flush_journal_list(struct super_block *s,
 					 b_blocknr, __func__);
 		}
 free_cnode:
-		last = cn;
 		cn = cn->next;
 		if (saved_bh) {
 			/*
@@ -1911,7 +1907,6 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 			      struct super_block *sb, int error)
 {
 	struct reiserfs_transaction_handle myth;
-	int flushed = 0;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	/*
@@ -1933,7 +1928,6 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 						     1);
 			journal_mark_dirty(&myth, SB_BUFFER_WITH_SB(sb));
 			do_journal_end(&myth, FLUSH_ALL);
-			flushed = 1;
 		}
 	}
 
@@ -3987,7 +3981,6 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	struct buffer_head *c_bh;	/* commit bh */
 	struct buffer_head *d_bh;	/* desc bh */
 	int cur_write_start = 0;	/* start index of current log write */
-	int old_start;
 	int i;
 	int flush;
 	int wait_on_commit;
@@ -4244,7 +4237,6 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	journal->j_num_work_lists++;
 
 	/* reset journal values for the next transaction */
-	old_start = journal->j_start;
 	journal->j_start =
 	    (journal->j_start + journal->j_len +
 	     2) % SB_ONDISK_JOURNAL_SIZE(sb);

commit d256085be12dc3b24e7b19c357e975a37dbff509
Author: Jia-Ju Bai <baijiaju1990@gmail.com>
Date:   Wed Sep 25 16:46:55 2019 -0700

    fs: reiserfs: remove unnecessary check of bh in remove_from_transaction()
    
    On lines 3430-3434, bh has been assured to be non-null:
        cn = get_journal_hash_dev(sb, journal->j_hash_table, blocknr);
        if (!cn || !cn->bh) {
            return ret;
        }
        bh = cn->bh;
    
    Thus, the check of bh on line 3447 is unnecessary and can be removed.
    Thank Andrew Morton for good advice.
    
    Link: http://lkml.kernel.org/r/20190727084019.11307-1-baijiaju1990@gmail.com
    Signed-off-by: Jia-Ju Bai <baijiaju1990@gmail.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Hariprasad Kelam <hariprasad.kelam@gmail.com>
    Cc: Bharath Vedartham <linux.bhar@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4517a1394c6f..11155b8513db 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -3444,9 +3444,8 @@ static int remove_from_transaction(struct super_block *sb,
 	if (cn == journal->j_last) {
 		journal->j_last = cn->prev;
 	}
-	if (bh)
-		remove_journal_hash(sb, journal->j_hash_table, NULL,
-				    bh->b_blocknr, 0);
+	remove_journal_hash(sb, journal->j_hash_table, NULL,
+			    bh->b_blocknr, 0);
 	clear_buffer_journaled(bh);	/* don't log this one */
 
 	if (!already_cleaned) {

commit dc0dde61f17d4e83776e7c5d8b81787436447346
Author: Hariprasad Kelam <hariprasad.kelam@gmail.com>
Date:   Tue Jul 16 16:29:21 2019 -0700

    fs/reiserfs/journal.c: change return type of dirty_one_transaction
    
    Change return type of dirty_one_transaction from int to void.  As this
    function always return success.
    
    Fixes below issue reported by coccicheck:
    
      fs/reiserfs/journal.c:1690:5-8: Unneeded variable: "ret".  Return "0" on line 1719
    
    Link: http://lkml.kernel.org/r/20190702175430.GA5882@hari-Inspiron-1545
    Signed-off-by: Hariprasad Kelam <hariprasad.kelam@gmail.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Bharath Vedartham <linux.bhar@gmail.com>
    Cc: Hariprasad Kelam <hariprasad.kelam@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 36346dc4cec0..4517a1394c6f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -94,7 +94,7 @@ static int journal_join(struct reiserfs_transaction_handle *th,
 			struct super_block *sb);
 static void release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal);
-static int dirty_one_transaction(struct super_block *s,
+static void dirty_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl);
 static void flush_async_commits(struct work_struct *work);
 static void queue_log_writer(struct super_block *s);
@@ -1682,12 +1682,11 @@ static int write_one_transaction(struct super_block *s,
 }
 
 /* used by flush_commit_list */
-static int dirty_one_transaction(struct super_block *s,
+static void dirty_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl)
 {
 	struct reiserfs_journal_cnode *cn;
 	struct reiserfs_journal_list *pjl;
-	int ret = 0;
 
 	jl->j_state |= LIST_DIRTY;
 	cn = jl->j_realblock;
@@ -1716,7 +1715,6 @@ static int dirty_one_transaction(struct super_block *s,
 		}
 		cn = cn->next;
 	}
-	return ret;
 }
 
 static int kupdate_transactions(struct super_block *s,

commit 5d552ad79630d41ca065457e22a20ae2db5b2441
Author: Bharath Vedartham <linux.bhar@gmail.com>
Date:   Sun Apr 14 16:54:38 2019 +0530

    fs/reiserfs/journal.c: Make remove_journal_hash static
    
    This fixes the -WDecl sparse warning in journal.c. Function was declared
    as static void but the definition was void.
    
    Signed-off-by: Bharath Vedartham <linux.bhar@gmail.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 8a76f9d14bc6..36346dc4cec0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1844,7 +1844,7 @@ static int flush_used_journal_lists(struct super_block *s,
  * removes any nodes in table with name block and dev as bh.
  * only touchs the hnext and hprev pointers.
  */
-void remove_journal_hash(struct super_block *sb,
+static void remove_journal_hash(struct super_block *sb,
 			 struct reiserfs_journal_cnode **table,
 			 struct reiserfs_journal_list *jl,
 			 unsigned long block, int remove_freed)

commit 34d082604a7c8856051ff441fef0e22d93afd848
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Aug 21 21:59:26 2018 -0700

    reiserfs: use monotonic time for j_trans_start_time
    
    Using CLOCK_REALTIME time_t timestamps breaks on 32-bit systems in 2038,
    and gives surprising results with a concurrent settimeofday().
    
    This changes the reiserfs journal timestamps to use ktime_get_seconds()
    instead, which makes it use a 64-bit CLOCK_MONOTONIC stamp.
    
    In the procfs output, the monotonic timestamp needs to be converted back
    to CLOCK_REALTIME to keep the existing ABI.
    
    Link: http://lkml.kernel.org/r/20180620142522.27639-2-arnd@arndb.de
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 52eb5d293a34..8a76f9d14bc6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2381,7 +2381,7 @@ static int journal_read(struct super_block *sb)
 	struct reiserfs_journal_desc *desc;
 	unsigned int oldest_trans_id = 0;
 	unsigned int oldest_invalid_trans_id = 0;
-	time_t start;
+	time64_t start;
 	unsigned long oldest_start = 0;
 	unsigned long cur_dblock = 0;
 	unsigned long newest_mount_id = 9;
@@ -2395,7 +2395,7 @@ static int journal_read(struct super_block *sb)
 	cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(sb);
 	reiserfs_info(sb, "checking transaction log (%pg)\n",
 		      journal->j_dev_bd);
-	start = get_seconds();
+	start = ktime_get_seconds();
 
 	/*
 	 * step 1, read in the journal header block.  Check the transaction
@@ -2556,7 +2556,7 @@ static int journal_read(struct super_block *sb)
 	if (replay_count > 0) {
 		reiserfs_info(sb,
 			      "replayed %d transactions in %lu seconds\n",
-			      replay_count, get_seconds() - start);
+			      replay_count, ktime_get_seconds() - start);
 	}
 	/* needed to satisfy the locking in _update_journal_header_block */
 	reiserfs_write_lock(sb);
@@ -2914,7 +2914,7 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 				   int new_alloc)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(th->t_super);
-	time_t now = get_seconds();
+	time64_t now = ktime_get_seconds();
 	/* cannot restart while nested */
 	BUG_ON(!th->t_trans_id);
 	if (th->t_refcount > 1)
@@ -3023,7 +3023,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 			      struct super_block *sb, unsigned long nblocks,
 			      int join)
 {
-	time_t now = get_seconds();
+	time64_t now = ktime_get_seconds();
 	unsigned int old_trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_transaction_handle myth;
@@ -3056,7 +3056,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 		PROC_INFO_INC(sb, journal.journal_relock_writers);
 		goto relock;
 	}
-	now = get_seconds();
+	now = ktime_get_seconds();
 
 	/*
 	 * if there is no room in the journal OR
@@ -3119,7 +3119,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	}
 	/* we are the first writer, set trans_id */
 	if (journal->j_trans_start_time == 0) {
-		journal->j_trans_start_time = get_seconds();
+		journal->j_trans_start_time = ktime_get_seconds();
 	}
 	atomic_inc(&journal->j_wcount);
 	journal->j_len_alloc += nblocks;
@@ -3559,11 +3559,11 @@ static void flush_async_commits(struct work_struct *work)
  */
 void reiserfs_flush_old_commits(struct super_block *sb)
 {
-	time_t now;
+	time64_t now;
 	struct reiserfs_transaction_handle th;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
-	now = get_seconds();
+	now = ktime_get_seconds();
 	/*
 	 * safety check so we don't flush while we are replaying the log during
 	 * mount
@@ -3613,7 +3613,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 {
 
-	time_t now;
+	time64_t now;
 	int flush = flags & FLUSH_ALL;
 	int commit_now = flags & COMMIT_NOW;
 	int wait_on_commit = flags & WAIT;
@@ -3694,7 +3694,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	}
 
 	/* deal with old transactions where we are the last writers */
-	now = get_seconds();
+	now = ktime_get_seconds();
 	if ((now - journal->j_trans_start_time) > journal->j_max_trans_age) {
 		commit_now = 1;
 		journal->j_next_async_flush = 1;

commit fad953ce0b22cfd352a9a90b070c34b8791e6868
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 14:27:37 2018 -0700

    treewide: Use array_size() in vzalloc()
    
    The vzalloc() function has no 2-factor argument form, so multiplication
    factors need to be wrapped in array_size(). This patch replaces cases of:
    
            vzalloc(a * b)
    
    with:
            vzalloc(array_size(a, b))
    
    as well as handling cases of:
    
            vzalloc(a * b * c)
    
    with:
    
            vzalloc(array3_size(a, b, c))
    
    This does, however, attempt to ignore constant size factors like:
    
            vzalloc(4 * 1024)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      vzalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      vzalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      vzalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      vzalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT_ID)
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT_ID
    +       array_size(COUNT_ID, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT_CONST)
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT_CONST
    +       array_size(COUNT_CONST, sizeof(THING))
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
      vzalloc(
    -       SIZE * COUNT
    +       array_size(COUNT, SIZE)
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      vzalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      vzalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      vzalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      vzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      vzalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      vzalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      vzalloc(C1 * C2 * C3, ...)
    |
      vzalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants.
    @@
    expression E1, E2;
    constant C1, C2;
    @@
    
    (
      vzalloc(C1 * C2, ...)
    |
      vzalloc(
    -       E1 * E2
    +       array_size(E1, E2)
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 358ee2a1ce1a..52eb5d293a34 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -350,7 +350,8 @@ static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 	if (num_cnodes <= 0) {
 		return NULL;
 	}
-	head = vzalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode));
+	head = vzalloc(array_size(num_cnodes,
+				  sizeof(struct reiserfs_journal_cnode)));
 	if (!head) {
 		return NULL;
 	}

commit 6da2ec56059c3c7a7e5f729e6349e74ace1e5c57
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 13:55:00 2018 -0700

    treewide: kmalloc() -> kmalloc_array()
    
    The kmalloc() function has a 2-factor argument form, kmalloc_array(). This
    patch replaces cases of:
    
            kmalloc(a * b, gfp)
    
    with:
            kmalloc_array(a * b, gfp)
    
    as well as handling cases of:
    
            kmalloc(a * b * c, gfp)
    
    with:
    
            kmalloc(array3_size(a, b, c), gfp)
    
    as it's slightly less ugly than:
    
            kmalloc_array(array_size(a, b), c, gfp)
    
    This does, however, attempt to ignore constant size factors like:
    
            kmalloc(4 * 1024, gfp)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The tools/ directory was manually excluded, since it has its own
    implementation of kmalloc().
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      kmalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      kmalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      kmalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      kmalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (COUNT_ID)
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * COUNT_ID
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * COUNT_CONST
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (COUNT_ID)
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * COUNT_ID
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * COUNT_CONST
    +       COUNT_CONST, sizeof(THING)
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
    - kmalloc
    + kmalloc_array
      (
    -       SIZE * COUNT
    +       COUNT, SIZE
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      kmalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kmalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      kmalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kmalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      kmalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      kmalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kmalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products,
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      kmalloc(C1 * C2 * C3, ...)
    |
      kmalloc(
    -       (E1) * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       (E1) * (E2) * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       (E1) * (E2) * (E3)
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kmalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants,
    // keeping sizeof() as the second factor argument.
    @@
    expression THING, E1, E2;
    type TYPE;
    constant C1, C2, C3;
    @@
    
    (
      kmalloc(sizeof(THING) * C2, ...)
    |
      kmalloc(sizeof(TYPE) * C2, ...)
    |
      kmalloc(C1 * C2 * C3, ...)
    |
      kmalloc(C1 * C2, ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * (E2)
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(TYPE) * E2
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * (E2)
    +       E2, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       sizeof(THING) * E2
    +       E2, sizeof(THING)
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       (E1) * E2
    +       E1, E2
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       (E1) * (E2)
    +       E1, E2
      , ...)
    |
    - kmalloc
    + kmalloc_array
      (
    -       E1 * E2
    +       E1, E2
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 23148c3ed675..358ee2a1ce1a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2192,10 +2192,12 @@ static int journal_read_transaction(struct super_block *sb,
 	 * now we know we've got a good transaction, and it was
 	 * inside the valid time ranges
 	 */
-	log_blocks = kmalloc(get_desc_trans_len(desc) *
-			     sizeof(struct buffer_head *), GFP_NOFS);
-	real_blocks = kmalloc(get_desc_trans_len(desc) *
-			      sizeof(struct buffer_head *), GFP_NOFS);
+	log_blocks = kmalloc_array(get_desc_trans_len(desc),
+				   sizeof(struct buffer_head *),
+				   GFP_NOFS);
+	real_blocks = kmalloc_array(get_desc_trans_len(desc),
+				    sizeof(struct buffer_head *),
+				    GFP_NOFS);
 	if (!log_blocks || !real_blocks) {
 		brelse(c_bh);
 		brelse(d_bh);

commit 9ad553abe66f8be3f4755e9fa0a6ba137ce76341
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Tue Apr 10 16:34:41 2018 -0700

    fs/reiserfs/journal.c: add missing resierfs_warning() arg
    
    One use of the reiserfs_warning() macro in journal_init_dev() is missing
    a parameter, causing the following warning:
    
      REISERFS warning (device loop0): journal_init_dev: Cannot open '%s': %i journal_init_dev:
    
    This also causes a WARN_ONCE() warning in the vsprintf code, and then a
    panic if panic_on_warn is set.
    
      Please remove unsupported %/ in format string
      WARNING: CPU: 1 PID: 4480 at lib/vsprintf.c:2138 format_decode+0x77f/0x830 lib/vsprintf.c:2138
      Kernel panic - not syncing: panic_on_warn set ...
    
    Just add another string argument to the macro invocation.
    
    Addresses https://syzkaller.appspot.com/bug?id=0627d4551fdc39bf1ef5d82cd9eef587047f7718
    
    Link: http://lkml.kernel.org/r/d678ebe1-6f54-8090-df4c-b9affad62293@infradead.org
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Reported-by: <syzbot+6bd77b88c1977c03f584@syzkaller.appspotmail.com>
    Tested-by: Randy Dunlap <rdunlap@infradead.org>
    Acked-by: Jeff Mahoney <jeffm@suse.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Jan Kara <jack@suse.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 70057359fbaf..23148c3ed675 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2643,7 +2643,7 @@ static int journal_init_dev(struct super_block *super,
 	if (IS_ERR(journal->j_dev_bd)) {
 		result = PTR_ERR(journal->j_dev_bd);
 		journal->j_dev_bd = NULL;
-		reiserfs_warning(super,
+		reiserfs_warning(super, "sh-457",
 				 "journal_init_dev: Cannot open '%s': %i",
 				 jdev_name, result);
 		return result;

commit 1751e8a6cb935e555fcdbcb9ab4f0446e322ca3e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 27 13:05:09 2017 -0800

    Rename superblock flags (MS_xyz -> SB_xyz)
    
    This is a pure automated search-and-replace of the internal kernel
    superblock flags.
    
    The s_flags are now called SB_*, with the names and the values for the
    moment mirroring the MS_* flags that they're equivalent to.
    
    Note how the MS_xyz flags are the ones passed to the mount system call,
    while the SB_xyz flags are what we then use in sb->s_flags.
    
    The script to do this was:
    
        # places to look in; re security/*: it generally should *not* be
        # touched (that stuff parses mount(2) arguments directly), but
        # there are two places where we really deal with superblock flags.
        FILES="drivers/mtd drivers/staging/lustre fs ipc mm \
                include/linux/fs.h include/uapi/linux/bfs_fs.h \
                security/apparmor/apparmorfs.c security/apparmor/include/lib.h"
        # the list of MS_... constants
        SYMS="RDONLY NOSUID NODEV NOEXEC SYNCHRONOUS REMOUNT MANDLOCK \
              DIRSYNC NOATIME NODIRATIME BIND MOVE REC VERBOSE SILENT \
              POSIXACL UNBINDABLE PRIVATE SLAVE SHARED RELATIME KERNMOUNT \
              I_VERSION STRICTATIME LAZYTIME SUBMOUNT NOREMOTELOCK NOSEC BORN \
              ACTIVE NOUSER"
    
        SED_PROG=
        for i in $SYMS; do SED_PROG="$SED_PROG -e s/MS_$i/SB_$i/g"; done
    
        # we want files that contain at least one of MS_...,
        # with fs/namespace.c and fs/pnode.c excluded.
        L=$(for i in $SYMS; do git grep -w -l MS_$i $FILES; done| sort|uniq|grep -v '^fs/namespace.c'|grep -v '^fs/pnode.c')
    
        for f in $L; do sed -i $f $SED_PROG; done
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 69ff280bdfe8..70057359fbaf 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1960,7 +1960,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	/*
 	 * Cancel flushing of old commits. Note that neither of these works
 	 * will be requeued because superblock is being shutdown and doesn't
-	 * have MS_ACTIVE set.
+	 * have SB_ACTIVE set.
 	 */
 	reiserfs_cancel_old_flush(sb);
 	/* wait for all commits to finish */
@@ -4302,7 +4302,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 		 * Avoid queueing work when sb is being shut down. Transaction
 		 * will be flushed on journal shutdown.
 		 */
-		if (sb->s_flags & MS_ACTIVE)
+		if (sb->s_flags & SB_ACTIVE)
 			queue_delayed_work(REISERFS_SB(sb)->commit_wq,
 					   &journal->j_work, HZ / 10);
 	}
@@ -4393,7 +4393,7 @@ void reiserfs_abort_journal(struct super_block *sb, int errno)
 	if (!journal->j_errno)
 		journal->j_errno = errno;
 
-	sb->s_flags |= MS_RDONLY;
+	sb->s_flags |= SB_RDONLY;
 	set_bit(J_ABORTED, &journal->j_state);
 
 #ifdef CONFIG_REISERFS_CHECK

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index f59c667df15b..69ff280bdfe8 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Write ahead logging implementation copyright Chris Mason 2000
  *

commit 0f0d12728e56c94d3289c6831243b6faeae8a19d
Merge: 581bfce969cb e462ec50cb5f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 18:54:01 2017 -0700

    Merge branch 'work.mount' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull mount flag updates from Al Viro:
     "Another chunk of fmount preparations from dhowells; only trivial
      conflicts for that part. It separates MS_... bits (very grotty
      mount(2) ABI) from the struct super_block ->s_flags (kernel-internal,
      only a small subset of MS_... stuff).
    
      This does *not* convert the filesystems to new constants; only the
      infrastructure is done here. The next step in that series is where the
      conflicts would be; that's the conversion of filesystems. It's purely
      mechanical and it's better done after the merge, so if you could run
      something like
    
            list=$(for i in MS_RDONLY MS_NOSUID MS_NODEV MS_NOEXEC MS_SYNCHRONOUS MS_MANDLOCK MS_DIRSYNC MS_NOATIME MS_NODIRATIME MS_SILENT MS_POSIXACL MS_KERNMOUNT MS_I_VERSION MS_LAZYTIME; do git grep -l $i fs drivers/staging/lustre drivers/mtd ipc mm include/linux; done|sort|uniq|grep -v '^fs/namespace.c$')
    
            sed -i -e 's/\<MS_RDONLY\>/SB_RDONLY/g' \
                    -e 's/\<MS_NOSUID\>/SB_NOSUID/g' \
                    -e 's/\<MS_NODEV\>/SB_NODEV/g' \
                    -e 's/\<MS_NOEXEC\>/SB_NOEXEC/g' \
                    -e 's/\<MS_SYNCHRONOUS\>/SB_SYNCHRONOUS/g' \
                    -e 's/\<MS_MANDLOCK\>/SB_MANDLOCK/g' \
                    -e 's/\<MS_DIRSYNC\>/SB_DIRSYNC/g' \
                    -e 's/\<MS_NOATIME\>/SB_NOATIME/g' \
                    -e 's/\<MS_NODIRATIME\>/SB_NODIRATIME/g' \
                    -e 's/\<MS_SILENT\>/SB_SILENT/g' \
                    -e 's/\<MS_POSIXACL\>/SB_POSIXACL/g' \
                    -e 's/\<MS_KERNMOUNT\>/SB_KERNMOUNT/g' \
                    -e 's/\<MS_I_VERSION\>/SB_I_VERSION/g' \
                    -e 's/\<MS_LAZYTIME\>/SB_LAZYTIME/g' \
                    $list
    
      and commit it with something along the lines of 'convert filesystems
      away from use of MS_... constants' as commit message, it would save a
      quite a bit of headache next cycle"
    
    * 'work.mount' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      VFS: Differentiate mount flags (MS_*) from internal superblock flags
      VFS: Convert sb->s_flags & MS_RDONLY to sb_rdonly(sb)
      vfs: Add sb_rdonly(sb) to query the MS_RDONLY flag on s_flags

commit 65f2b26339927a37570ffa42a8fcc8764fef06f7
Author: Colin Ian King <colin.king@canonical.com>
Date:   Wed Aug 16 09:06:20 2017 +0100

    reiserfs: fix spelling mistake: "tranasction" -> "transaction"
    
    Trivial fix to spelling mistake in reiserfs_warning message
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a11d773e5ff3..0c882a0e2a6e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1481,7 +1481,7 @@ static int flush_journal_list(struct super_block *s,
 		if ((!was_jwait) && !buffer_locked(saved_bh)) {
 			reiserfs_warning(s, "journal-813",
 					 "BAD! buffer %llu %cdirty %cjwait, "
-					 "not in a newer tranasction",
+					 "not in a newer transaction",
 					 (unsigned long long)saved_bh->
 					 b_blocknr, was_dirty ? ' ' : '!',
 					 was_jwait ? ' ' : '!');

commit bc98a42c1f7d0f886c0c1b75a92a004976a46d9f
Author: David Howells <dhowells@redhat.com>
Date:   Mon Jul 17 08:45:34 2017 +0100

    VFS: Convert sb->s_flags & MS_RDONLY to sb_rdonly(sb)
    
    Firstly by applying the following with coccinelle's spatch:
    
            @@ expression SB; @@
            -SB->s_flags & MS_RDONLY
            +sb_rdonly(SB)
    
    to effect the conversion to sb_rdonly(sb), then by applying:
    
            @@ expression A, SB; @@
            (
            -(!sb_rdonly(SB)) && A
            +!sb_rdonly(SB) && A
            |
            -A != (sb_rdonly(SB))
            +A != sb_rdonly(SB)
            |
            -A == (sb_rdonly(SB))
            +A == sb_rdonly(SB)
            |
            -!(sb_rdonly(SB))
            +!sb_rdonly(SB)
            |
            -A && (sb_rdonly(SB))
            +A && sb_rdonly(SB)
            |
            -A || (sb_rdonly(SB))
            +A || sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) != A
            +sb_rdonly(SB) != A
            |
            -(sb_rdonly(SB)) == A
            +sb_rdonly(SB) == A
            |
            -(sb_rdonly(SB)) && A
            +sb_rdonly(SB) && A
            |
            -(sb_rdonly(SB)) || A
            +sb_rdonly(SB) || A
            )
    
            @@ expression A, B, SB; @@
            (
            -(sb_rdonly(SB)) ? 1 : 0
            +sb_rdonly(SB)
            |
            -(sb_rdonly(SB)) ? A : B
            +sb_rdonly(SB) ? A : B
            )
    
    to remove left over excess bracketage and finally by applying:
    
            @@ expression A, SB; @@
            (
            -(A & MS_RDONLY) != sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) != sb_rdonly(SB)
            |
            -(A & MS_RDONLY) == sb_rdonly(SB)
            +(bool)(A & MS_RDONLY) == sb_rdonly(SB)
            )
    
    to make comparisons against the result of sb_rdonly() (which is a bool)
    work correctly.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a11d773e5ff3..e47da919f443 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1918,7 +1918,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	 * we only want to flush out transactions if we were
 	 * called with error == 0
 	 */
-	if (!error && !(sb->s_flags & MS_RDONLY)) {
+	if (!error && !sb_rdonly(sb)) {
 		/* end the current trans */
 		BUG_ON(!th->t_trans_id);
 		do_journal_end(th, FLUSH_ALL);

commit ac6424b981bce1c4bc55675c6ce11bfe1bbfa64f
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Jun 20 12:06:13 2017 +0200

    sched/wait: Rename wait_queue_t => wait_queue_entry_t
    
    Rename:
    
            wait_queue_t            =>      wait_queue_entry_t
    
    'wait_queue_t' was always a slight misnomer: its name implies that it's a "queue",
    but in reality it's a queue *entry*. The 'real' queue is the wait queue head,
    which had to carry the name.
    
    Start sorting this out by renaming it to 'wait_queue_entry_t'.
    
    This also allows the real structure name 'struct __wait_queue' to
    lose its double underscore and become 'struct wait_queue_entry',
    which is the more canonical nomenclature for such data types.
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 39bb1e838d8d..a11d773e5ff3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2956,7 +2956,7 @@ void reiserfs_wait_on_write_block(struct super_block *s)
 
 static void queue_log_writer(struct super_block *s)
 {
-	wait_queue_t wait;
+	wait_queue_entry_t wait;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	set_bit(J_WRITERS_QUEUED, &journal->j_state);
 

commit d8747d642ec4ce96adf17ae35652a5e4015cfe02
Author: Jan Kara <jack@suse.cz>
Date:   Tue May 2 13:16:18 2017 +0200

    reiserfs: Make flush bios explicitely sync
    
    Commit b685d3d65ac7 "block: treat REQ_FUA and REQ_PREFLUSH as
    synchronous" removed REQ_SYNC flag from WRITE_{FUA|PREFLUSH|...}
    definitions.  generic_make_request_checks() however strips REQ_FUA and
    REQ_PREFLUSH flags from a bio when the storage doesn't report volatile
    write cache and thus write effectively becomes asynchronous which can
    lead to performance regressions
    
    Fix the problem by making sure all bios which are synchronous are
    properly marked with REQ_SYNC.
    
    Fixes: b685d3d65ac791406e0dfd8779cc9b3707fea5a3
    CC: reiserfs-devel@vger.kernel.org
    CC: stable@vger.kernel.org
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index da01f497180a..39bb1e838d8d 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1112,7 +1112,7 @@ static int flush_commit_list(struct super_block *s,
 		depth = reiserfs_write_unlock_nested(s);
 		if (reiserfs_barrier_flush(s))
 			__sync_dirty_buffer(jl->j_commit_bh,
-					REQ_PREFLUSH | REQ_FUA);
+					REQ_SYNC | REQ_PREFLUSH | REQ_FUA);
 		else
 			sync_dirty_buffer(jl->j_commit_bh);
 		reiserfs_write_lock_nested(s, depth);
@@ -1271,7 +1271,7 @@ static int _update_journal_header_block(struct super_block *sb,
 
 		if (reiserfs_barrier_flush(sb))
 			__sync_dirty_buffer(journal->j_header_bh,
-					REQ_PREFLUSH | REQ_FUA);
+					REQ_SYNC | REQ_PREFLUSH | REQ_FUA);
 		else
 			sync_dirty_buffer(journal->j_header_bh);
 

commit 71b0576bdb862e964a82c73327cdd1a249c53e67
Author: Jan Kara <jack@suse.cz>
Date:   Wed Apr 5 14:09:48 2017 +0200

    reiserfs: Make cancel_old_flush() reliable
    
    Currently canceling of delayed work that flushes old data using
    cancel_old_flush() does not prevent work from being requeued. Thus
    in theory new work can be queued after cancel_old_flush() from
    reiserfs_freeze() has run. This will become larger problem once
    flush_old_commits() can requeue the work itself.
    
    Fix the problem by recording in sbi->work_queue that flushing work is
    canceled and should not be requeued.
    
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index aa40c242f1db..da01f497180a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1961,7 +1961,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	 * will be requeued because superblock is being shutdown and doesn't
 	 * have MS_ACTIVE set.
 	 */
-	cancel_delayed_work_sync(&REISERFS_SB(sb)->old_work);
+	reiserfs_cancel_old_flush(sb);
 	/* wait for all commits to finish */
 	cancel_delayed_work_sync(&SB_JOURNAL(sb)->j_work);
 

commit 70fd76140a6cb63262bd47b68d57b42e889c10ee
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 07:40:10 2016 -0600

    block,fs: use REQ_* flags directly
    
    Remove the WRITE_* and READ_SYNC wrappers, and just use the flags
    directly.  Where applicable this also drops usage of the
    bio_set_op_attrs wrapper.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index bc2dde2423c2..aa40c242f1db 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1111,7 +1111,8 @@ static int flush_commit_list(struct super_block *s,
 		mark_buffer_dirty(jl->j_commit_bh) ;
 		depth = reiserfs_write_unlock_nested(s);
 		if (reiserfs_barrier_flush(s))
-			__sync_dirty_buffer(jl->j_commit_bh, WRITE_FLUSH_FUA);
+			__sync_dirty_buffer(jl->j_commit_bh,
+					REQ_PREFLUSH | REQ_FUA);
 		else
 			sync_dirty_buffer(jl->j_commit_bh);
 		reiserfs_write_lock_nested(s, depth);
@@ -1269,7 +1270,8 @@ static int _update_journal_header_block(struct super_block *sb,
 		depth = reiserfs_write_unlock_nested(sb);
 
 		if (reiserfs_barrier_flush(sb))
-			__sync_dirty_buffer(journal->j_header_bh, WRITE_FLUSH_FUA);
+			__sync_dirty_buffer(journal->j_header_bh,
+					REQ_PREFLUSH | REQ_FUA);
 		else
 			sync_dirty_buffer(journal->j_header_bh);
 

commit dfec8a14fc9043039e3c04807caf39dc71102816
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:44 2016 -0500

    fs: have ll_rw_block users pass in op and flags separately
    
    This has ll_rw_block users pass in the operation and flags separately,
    so ll_rw_block can setup the bio op and bi_rw flags on the bio that
    is submitted.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 6945e719bdab..bc2dde2423c2 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -870,7 +870,7 @@ static int write_ordered_buffers(spinlock_t * lock,
 		 */
 		if (buffer_dirty(bh) && unlikely(bh->b_page->mapping == NULL)) {
 			spin_unlock(lock);
-			ll_rw_block(WRITE, 1, &bh);
+			ll_rw_block(REQ_OP_WRITE, 0, 1, &bh);
 			spin_lock(lock);
 		}
 		put_bh(bh);
@@ -1057,7 +1057,7 @@ static int flush_commit_list(struct super_block *s,
 		if (tbh) {
 			if (buffer_dirty(tbh)) {
 		            depth = reiserfs_write_unlock_nested(s);
-			    ll_rw_block(WRITE, 1, &tbh);
+			    ll_rw_block(REQ_OP_WRITE, 0, 1, &tbh);
 			    reiserfs_write_lock_nested(s, depth);
 			}
 			put_bh(tbh) ;
@@ -2244,7 +2244,7 @@ static int journal_read_transaction(struct super_block *sb,
 		}
 	}
 	/* read in the log blocks, memcpy to the corresponding real block */
-	ll_rw_block(READ, get_desc_trans_len(desc), log_blocks);
+	ll_rw_block(REQ_OP_READ, 0, get_desc_trans_len(desc), log_blocks);
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 
 		wait_on_buffer(log_blocks[i]);
@@ -2346,7 +2346,7 @@ static struct buffer_head *reiserfs_breada(struct block_device *dev,
 		} else
 			bhlist[j++] = bh;
 	}
-	ll_rw_block(READ, j, bhlist);
+	ll_rw_block(REQ_OP_READ, 0, j, bhlist);
 	for (i = 1; i < j; i++)
 		brelse(bhlist[i]);
 	bh = bhlist[0];

commit 2a222ca992c35aee1e83af428f3dd26a3f5d5d94
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:43 2016 -0500

    fs: have submit_bh users pass in op and flags separately
    
    This has submit_bh users pass in the operation and flags separately,
    so submit_bh_wbc can setup the bio op and bi_rw flags on the bio that
    is submitted.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 2ace90e981f0..6945e719bdab 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -652,7 +652,7 @@ static void submit_logged_buffer(struct buffer_head *bh)
 		BUG();
 	if (!buffer_uptodate(bh))
 		BUG();
-	submit_bh(WRITE, bh);
+	submit_bh(REQ_OP_WRITE, 0, bh);
 }
 
 static void submit_ordered_buffer(struct buffer_head *bh)
@@ -662,7 +662,7 @@ static void submit_ordered_buffer(struct buffer_head *bh)
 	clear_buffer_dirty(bh);
 	if (!buffer_uptodate(bh))
 		BUG();
-	submit_bh(WRITE, bh);
+	submit_bh(REQ_OP_WRITE, 0, bh);
 }
 
 #define CHUNK_SIZE 32
@@ -2269,7 +2269,7 @@ static int journal_read_transaction(struct super_block *sb,
 	/* flush out the real blocks */
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		set_buffer_dirty(real_blocks[i]);
-		write_dirty_buffer(real_blocks[i], WRITE);
+		write_dirty_buffer(real_blocks[i], 0);
 	}
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(real_blocks[i]);

commit ea1754a084760e68886f5b725c8eaada9cc57155
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:48 2016 +0300

    mm, fs: remove remaining PAGE_CACHE_* and page_cache_{get,release} usage
    
    Mostly direct substitution with occasional adjustment or removing
    outdated comments.
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 8c6487238bb3..2ace90e981f0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -599,7 +599,7 @@ static int journal_list_still_alive(struct super_block *s,
  * This does a check to see if the buffer belongs to one of these
  * lost pages before doing the final put_bh.  If page->mapping was
  * null, it tries to free buffers on the page, which should make the
- * final page_cache_release drop the page from the lru.
+ * final put_page drop the page from the lru.
  */
 static void release_buffer_page(struct buffer_head *bh)
 {

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 44c2bdced1c8..8c6487238bb3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -605,12 +605,12 @@ static void release_buffer_page(struct buffer_head *bh)
 {
 	struct page *page = bh->b_page;
 	if (!page->mapping && trylock_page(page)) {
-		page_cache_get(page);
+		get_page(page);
 		put_bh(bh);
 		if (!page->mapping)
 			try_to_free_buffers(page);
 		unlock_page(page);
-		page_cache_release(page);
+		put_page(page);
 	} else {
 		put_bh(bh);
 	}

commit a1c6f05733c27ba7067c06c095f49e8732a5ae17
Author: Dmitry Monakhov <dmonakhov@openvz.org>
Date:   Mon Apr 13 16:31:37 2015 +0400

    fs: use block_device name vsprintf helper
    
    Signed-off-by: Dmitry Monakhov <dmonakhov@openvz.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 9d6486d416a3..44c2bdced1c8 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -618,12 +618,10 @@ static void release_buffer_page(struct buffer_head *bh)
 
 static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate)
 {
-	char b[BDEVNAME_SIZE];
-
 	if (buffer_journaled(bh)) {
 		reiserfs_warning(NULL, "clm-2084",
-				 "pinned buffer %lu:%s sent to disk",
-				 bh->b_blocknr, bdevname(bh->b_bdev, b));
+				 "pinned buffer %lu:%pg sent to disk",
+				 bh->b_blocknr, bh->b_bdev);
 	}
 	if (uptodate)
 		set_buffer_uptodate(bh);
@@ -2387,11 +2385,10 @@ static int journal_read(struct super_block *sb)
 	int replay_count = 0;
 	int continue_replay = 1;
 	int ret;
-	char b[BDEVNAME_SIZE];
 
 	cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(sb);
-	reiserfs_info(sb, "checking transaction log (%s)\n",
-		      bdevname(journal->j_dev_bd, b));
+	reiserfs_info(sb, "checking transaction log (%pg)\n",
+		      journal->j_dev_bd);
 	start = get_seconds();
 
 	/*
@@ -2651,8 +2648,8 @@ static int journal_init_dev(struct super_block *super,
 
 	set_blocksize(journal->j_dev_bd, super->s_blocksize);
 	reiserfs_info(super,
-		      "journal_init_dev: journal device: %s\n",
-		      bdevname(journal->j_dev_bd, b));
+		      "journal_init_dev: journal device: %pg\n",
+		      journal->j_dev_bd);
 	return 0;
 }
 
@@ -2724,7 +2721,6 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	struct reiserfs_journal_header *jh;
 	struct reiserfs_journal *journal;
 	struct reiserfs_journal_list *jl;
-	char b[BDEVNAME_SIZE];
 	int ret;
 
 	journal = SB_JOURNAL(sb) = vzalloc(sizeof(struct reiserfs_journal));
@@ -2794,10 +2790,10 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	    && (le32_to_cpu(jh->jh_journal.jp_journal_magic) !=
 		sb_jp_journal_magic(rs))) {
 		reiserfs_warning(sb, "sh-460",
-				 "journal header magic %x (device %s) does "
+				 "journal header magic %x (device %pg) does "
 				 "not match to magic found in super block %x",
 				 jh->jh_journal.jp_journal_magic,
-				 bdevname(journal->j_dev_bd, b),
+				 journal->j_dev_bd,
 				 sb_jp_journal_magic(rs));
 		brelse(bhjh);
 		goto free_and_return;
@@ -2818,10 +2814,10 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 		journal->j_max_trans_age = commit_max_age;
 	}
 
-	reiserfs_info(sb, "journal params: device %s, size %u, "
+	reiserfs_info(sb, "journal params: device %pg, size %u, "
 		      "journal first block %u, max trans len %u, max batch %u, "
 		      "max commit age %u, max trans age %u\n",
-		      bdevname(journal->j_dev_bd, b),
+		      journal->j_dev_bd,
 		      SB_ONDISK_JOURNAL_SIZE(sb),
 		      SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 		      journal->j_trans_max,

commit 6774def6422f6eac53f1828c317bf3b08a8f5a60
Author: Masanari Iida <standby24x7@gmail.com>
Date:   Wed Nov 5 22:26:48 2014 +0900

    treewide: fix typo in printk and Kconfig
    
    This patch fix spelling typo in printk and Kconfig within
    various part of kernel sources.
    
    Signed-off-by: Masanari Iida <standby24x7@gmail.com>
    Acked-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index d571e173a990..9d6486d416a3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2772,7 +2772,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 
 	if (journal_init_dev(sb, journal, j_dev_name) != 0) {
 		reiserfs_warning(sb, "sh-462",
-				 "unable to initialize jornal device");
+				 "unable to initialize journal device");
 		goto free_and_return;
 	}
 

commit 54cc6cea73bb5ddf0362a70ef58816898bfb7f87
Author: Fabian Frederick <fabf@skynet.be>
Date:   Mon Oct 13 15:53:29 2014 -0700

    fs/reiserfs/journal.c: fix sparse context imbalance warning
    
    Merge conditional unlock/lock in the same condition to avoid sparse
    warning:
    
      fs/reiserfs/journal.c:703:36: warning: context imbalance in 'add_to_chunk' - unexpected unlock
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a88b1b3e7db3..d571e173a990 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -699,11 +699,13 @@ static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
 	chunk->bh[chunk->nr++] = bh;
 	if (chunk->nr >= CHUNK_SIZE) {
 		ret = 1;
-		if (lock)
+		if (lock) {
 			spin_unlock(lock);
-		fn(chunk);
-		if (lock)
+			fn(chunk);
 			spin_lock(lock);
+		} else {
+			fn(chunk);
+		}
 	}
 	return ret;
 }

commit 01777836c87081e4f68c4a43c9abe6114805f91e
Author: Jan Kara <jack@suse.cz>
Date:   Wed Aug 6 19:43:56 2014 +0200

    reiserfs: Fix use after free in journal teardown
    
    If do_journal_release() races with do_journal_end() which requeues
    delayed works for transaction flushing, we can leave work items for
    flushing outstanding transactions queued while freeing them. That
    results in use after free and possible crash in run_timers_softirq().
    
    Fix the problem by not requeueing works if superblock is being shut down
    (MS_ACTIVE not set) and using cancel_delayed_work_sync() in
    do_journal_release().
    
    CC: stable@vger.kernel.org
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e8870de4627e..a88b1b3e7db3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1947,8 +1947,6 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 		}
 	}
 
-	/* wait for all commits to finish */
-	cancel_delayed_work(&SB_JOURNAL(sb)->j_work);
 
 	/*
 	 * We must release the write lock here because
@@ -1956,8 +1954,14 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	 */
 	reiserfs_write_unlock(sb);
 
+	/*
+	 * Cancel flushing of old commits. Note that neither of these works
+	 * will be requeued because superblock is being shutdown and doesn't
+	 * have MS_ACTIVE set.
+	 */
 	cancel_delayed_work_sync(&REISERFS_SB(sb)->old_work);
-	flush_workqueue(REISERFS_SB(sb)->commit_wq);
+	/* wait for all commits to finish */
+	cancel_delayed_work_sync(&SB_JOURNAL(sb)->j_work);
 
 	free_journal_ram(sb);
 
@@ -4292,9 +4296,15 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	if (flush) {
 		flush_commit_list(sb, jl, 1);
 		flush_journal_list(sb, jl, 1);
-	} else if (!(jl->j_state & LIST_COMMIT_PENDING))
-		queue_delayed_work(REISERFS_SB(sb)->commit_wq,
-				   &journal->j_work, HZ / 10);
+	} else if (!(jl->j_state & LIST_COMMIT_PENDING)) {
+		/*
+		 * Avoid queueing work when sb is being shut down. Transaction
+		 * will be flushed on journal shutdown.
+		 */
+		if (sb->s_flags & MS_ACTIVE)
+			queue_delayed_work(REISERFS_SB(sb)->commit_wq,
+					   &journal->j_work, HZ / 10);
+	}
 
 	/*
 	 * if the next transaction has any chance of wrapping, flush

commit a228bf8f0a3e5f1406edbd61f7400e87e23af5f7
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:42 2014 -0400

    reiserfs: cleanup, remove unnecessary parens
    
    The reiserfs code is littered with extra parens in places where the authors
    may not have been certain about precedence of & vs ->. This patch cleans them
    out.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 75b0285dc27a..e8870de4627e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1016,9 +1016,9 @@ static int flush_commit_list(struct super_block *s,
 	BUG_ON(jl->j_trans_id == 0);
 
 	/* this commit is done, exit */
-	if (atomic_read(&(jl->j_commit_left)) <= 0) {
+	if (atomic_read(&jl->j_commit_left) <= 0) {
 		if (flushall) {
-			atomic_set(&(jl->j_older_commits_done), 1);
+			atomic_set(&jl->j_older_commits_done, 1);
 		}
 		mutex_unlock(&jl->j_commit_mutex);
 		goto put_jl;
@@ -1094,10 +1094,10 @@ static int flush_commit_list(struct super_block *s,
 		put_bh(tbh);
 		/* once due to original getblk in do_journal_end */
 		put_bh(tbh);
-		atomic_dec(&(jl->j_commit_left));
+		atomic_dec(&jl->j_commit_left);
 	}
 
-	BUG_ON(atomic_read(&(jl->j_commit_left)) != 1);
+	BUG_ON(atomic_read(&jl->j_commit_left) != 1);
 
 	/*
 	 * If there was a write error in the journal - we can't commit
@@ -1147,10 +1147,10 @@ static int flush_commit_list(struct super_block *s,
 	/* mark the metadata dirty */
 	if (!retval)
 		dirty_one_transaction(s, jl);
-	atomic_dec(&(jl->j_commit_left));
+	atomic_dec(&jl->j_commit_left);
 
 	if (flushall) {
-		atomic_set(&(jl->j_older_commits_done), 1);
+		atomic_set(&jl->j_older_commits_done, 1);
 	}
 	mutex_unlock(&jl->j_commit_mutex);
 put_jl:
@@ -1379,8 +1379,8 @@ static int flush_journal_list(struct super_block *s,
 	}
 
 	/* if all the work is already done, get out of here */
-	if (atomic_read(&(jl->j_nonzerolen)) <= 0 &&
-	    atomic_read(&(jl->j_commit_left)) <= 0) {
+	if (atomic_read(&jl->j_nonzerolen) <= 0 &&
+	    atomic_read(&jl->j_commit_left) <= 0) {
 		goto flush_older_and_return;
 	}
 
@@ -1395,8 +1395,8 @@ static int flush_journal_list(struct super_block *s,
 		BUG();
 
 	/* are we done now? */
-	if (atomic_read(&(jl->j_nonzerolen)) <= 0 &&
-	    atomic_read(&(jl->j_commit_left)) <= 0) {
+	if (atomic_read(&jl->j_nonzerolen) <= 0 &&
+	    atomic_read(&jl->j_commit_left) <= 0) {
 		goto flush_older_and_return;
 	}
 
@@ -1404,7 +1404,7 @@ static int flush_journal_list(struct super_block *s,
 	 * loop through each cnode, see if we need to write it,
 	 * or wait on a more recent transaction, or just ignore it
 	 */
-	if (atomic_read(&(journal->j_wcount)) != 0) {
+	if (atomic_read(&journal->j_wcount) != 0) {
 		reiserfs_panic(s, "journal-844", "journal list is flushing, "
 			       "wcount is not 0");
 	}
@@ -1513,7 +1513,7 @@ static int flush_journal_list(struct super_block *s,
 			 * taking the buffer head away
 			 */
 			put_bh(saved_bh);
-			if (atomic_read(&(saved_bh->b_count)) < 0) {
+			if (atomic_read(&saved_bh->b_count) < 0) {
 				reiserfs_warning(s, "journal-945",
 						 "saved_bh->b_count < 0");
 			}
@@ -1614,7 +1614,7 @@ static int flush_journal_list(struct super_block *s,
 	 * help find code using dead lists later on
 	 */
 	jl->j_len = 0;
-	atomic_set(&(jl->j_nonzerolen), 0);
+	atomic_set(&jl->j_nonzerolen, 0);
 	jl->j_start = 0;
 	jl->j_realblock = NULL;
 	jl->j_commit_bh = NULL;
@@ -1873,7 +1873,7 @@ void remove_journal_hash(struct super_block *sb,
 			 * dec the nonzerolen
 			 */
 			if (cur->bh && cur->jlist)
-				atomic_dec(&(cur->jlist->j_nonzerolen));
+				atomic_dec(&cur->jlist->j_nonzerolen);
 			cur->bh = NULL;
 			cur->jlist = NULL;
 		}
@@ -2836,20 +2836,20 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	journal->j_start = 0;
 	journal->j_len = 0;
 	journal->j_len_alloc = 0;
-	atomic_set(&(journal->j_wcount), 0);
-	atomic_set(&(journal->j_async_throttle), 0);
+	atomic_set(&journal->j_wcount, 0);
+	atomic_set(&journal->j_async_throttle, 0);
 	journal->j_bcount = 0;
 	journal->j_trans_start_time = 0;
 	journal->j_last = NULL;
 	journal->j_first = NULL;
-	init_waitqueue_head(&(journal->j_join_wait));
+	init_waitqueue_head(&journal->j_join_wait);
 	mutex_init(&journal->j_mutex);
 	mutex_init(&journal->j_flush_mutex);
 
 	journal->j_trans_id = 10;
 	journal->j_mount_id = 10;
 	journal->j_state = 0;
-	atomic_set(&(journal->j_jlock), 0);
+	atomic_set(&journal->j_jlock, 0);
 	journal->j_cnode_free_list = allocate_cnodes(num_cnodes);
 	journal->j_cnode_free_orig = journal->j_cnode_free_list;
 	journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0;
@@ -2913,7 +2913,7 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 		return 0;
 	if (journal->j_must_wait > 0 ||
 	    (journal->j_len_alloc + new_alloc) >= journal->j_max_batch ||
-	    atomic_read(&(journal->j_jlock)) ||
+	    atomic_read(&journal->j_jlock) ||
 	    (now - journal->j_trans_start_time) > journal->j_max_trans_age ||
 	    journal->j_cnode_free < (journal->j_trans_max * 3)) {
 		return 1;
@@ -3113,7 +3113,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	if (journal->j_trans_start_time == 0) {
 		journal->j_trans_start_time = get_seconds();
 	}
-	atomic_inc(&(journal->j_wcount));
+	atomic_inc(&journal->j_wcount);
 	journal->j_len_alloc += nblocks;
 	th->t_blocks_logged = 0;
 	th->t_blocks_allocated = nblocks;
@@ -3306,10 +3306,10 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 				 buffer_journal_dirty(bh) ? ' ' : '!');
 	}
 
-	if (atomic_read(&(journal->j_wcount)) <= 0) {
+	if (atomic_read(&journal->j_wcount) <= 0) {
 		reiserfs_warning(sb, "journal-1409",
 				 "returning because j_wcount was %d",
-				 atomic_read(&(journal->j_wcount)));
+				 atomic_read(&journal->j_wcount));
 		return 1;
 	}
 	/*
@@ -3448,7 +3448,7 @@ static int remove_from_transaction(struct super_block *sb,
 		clear_buffer_dirty(bh);
 		clear_buffer_journal_test(bh);
 		put_bh(bh);
-		if (atomic_read(&(bh->b_count)) < 0) {
+		if (atomic_read(&bh->b_count) < 0) {
 			reiserfs_warning(sb, "journal-1752",
 					 "b_count < 0");
 		}
@@ -3497,7 +3497,7 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 	cur = cn->hnext;
 	while (cur && can_dirty) {
 		if (cur->jlist && cur->jlist->j_len > 0 &&
-		    atomic_read(&(cur->jlist->j_commit_left)) > 0 && cur->bh &&
+		    atomic_read(&cur->jlist->j_commit_left) > 0 && cur->bh &&
 		    cur->blocknr && cur->sb == sb && cur->blocknr == blocknr) {
 			can_dirty = 0;
 		}
@@ -3623,8 +3623,8 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 
 	journal->j_len_alloc -= (th->t_blocks_allocated - th->t_blocks_logged);
 	/* <= 0 is allowed.  unmounting might not call begin */
-	if (atomic_read(&(journal->j_wcount)) > 0)
-		atomic_dec(&(journal->j_wcount));
+	if (atomic_read(&journal->j_wcount) > 0)
+		atomic_dec(&journal->j_wcount);
 
 	/*
 	 * BUG, deal with case where j_len is 0, but people previously
@@ -3642,7 +3642,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	 * because the rest of journal end was already done for this
 	 * transaction.
 	 */
-	if (atomic_read(&(journal->j_wcount)) > 0) {
+	if (atomic_read(&journal->j_wcount) > 0) {
 		if (flush || commit_now) {
 			unsigned trans_id;
 
@@ -3650,7 +3650,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 			trans_id = jl->j_trans_id;
 			if (wait_on_commit)
 				jl->j_state |= LIST_COMMIT_PENDING;
-			atomic_set(&(journal->j_jlock), 1);
+			atomic_set(&journal->j_jlock, 1);
 			if (flush) {
 				journal->j_next_full_flush = 1;
 			}
@@ -3666,7 +3666,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 				} else {
 					lock_journal(sb);
 					if (journal->j_trans_id == trans_id) {
-						atomic_set(&(journal->j_jlock),
+						atomic_set(&journal->j_jlock,
 							   1);
 					}
 					unlock_journal(sb);
@@ -3693,7 +3693,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	}
 	/* don't batch when someone is waiting on j_join_wait */
 	/* don't batch when syncing the commit or flushing the whole trans */
-	if (!(journal->j_must_wait > 0) && !(atomic_read(&(journal->j_jlock)))
+	if (!(journal->j_must_wait > 0) && !(atomic_read(&journal->j_jlock))
 	    && !flush && !commit_now && (journal->j_len < journal->j_max_batch)
 	    && journal->j_len_alloc < journal->j_max_batch
 	    && journal->j_cnode_free > (journal->j_trans_max * 3)) {
@@ -3792,7 +3792,7 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 						cleaned = 1;
 						put_bh(cn->bh);
 						if (atomic_read
-						    (&(cn->bh->b_count)) < 0) {
+						    (&cn->bh->b_count) < 0) {
 							reiserfs_warning(sb,
 								 "journal-2138",
 								 "cn->bh->b_count < 0");
@@ -3803,9 +3803,8 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 					 * we MUST dec nonzerolen
 					 */
 					if (cn->jlist) {
-						atomic_dec(&
-							   (cn->jlist->
-							    j_nonzerolen));
+						atomic_dec(&cn->jlist->
+							   j_nonzerolen);
 					}
 					cn->bh = NULL;
 				}
@@ -4244,7 +4243,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	journal->j_start =
 	    (journal->j_start + journal->j_len +
 	     2) % SB_ONDISK_JOURNAL_SIZE(sb);
-	atomic_set(&(journal->j_wcount), 0);
+	atomic_set(&journal->j_wcount, 0);
 	journal->j_bcount = 0;
 	journal->j_last = NULL;
 	journal->j_first = NULL;
@@ -4349,11 +4348,11 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 			       "could not get a list bitmap");
 	}
 
-	atomic_set(&(journal->j_jlock), 0);
+	atomic_set(&journal->j_jlock, 0);
 	unlock_journal(sb);
 	/* wake up any body waiting to join. */
 	clear_bit(J_WRITERS_QUEUED, &journal->j_state);
-	wake_up(&(journal->j_join_wait));
+	wake_up(&journal->j_join_wait);
 
 	if (!flush && wait_on_commit &&
 	    journal_list_still_alive(sb, commit_trans_id)) {

commit cf776a7a4dafa330dd371a6a301ddf9e38747d93
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:41 2014 -0400

    reiserfs: cleanup, remove leading whitespace from labels
    
    This patch moves reiserfs closer to adhering to the style rules by
    removing leading whitespace from labels.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b0ceee401a26..75b0285dc27a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -160,7 +160,7 @@ static struct reiserfs_bitmap_node *get_bitmap_node(struct super_block *sb)
 	struct list_head *entry = journal->j_bitmap_nodes.next;
 
 	journal->j_used_bitmap_nodes++;
-      repeat:
+repeat:
 
 	if (entry != &journal->j_bitmap_nodes) {
 		bn = list_entry(entry, struct reiserfs_bitmap_node, list);
@@ -757,7 +757,7 @@ static inline int __add_jh(struct reiserfs_journal *j, struct buffer_head *bh,
 		jh = bh->b_private;
 		list_del_init(&jh->list);
 	} else {
-	      no_jh:
+no_jh:
 		get_bh(bh);
 		jh = alloc_jh();
 		spin_lock(&j->j_dirty_buffers_lock);
@@ -836,7 +836,7 @@ static int write_ordered_buffers(spinlock_t * lock,
 			reiserfs_free_jh(bh);
 			unlock_buffer(bh);
 		}
-	      loop_next:
+loop_next:
 		put_bh(bh);
 		cond_resched_lock(lock);
 	}
@@ -891,7 +891,7 @@ static int flush_older_commits(struct super_block *s,
 	unsigned int other_trans_id;
 	unsigned int first_trans_id;
 
-      find_first:
+find_first:
 	/*
 	 * first we walk backwards to find the oldest uncommitted transation
 	 */
@@ -1153,7 +1153,7 @@ static int flush_commit_list(struct super_block *s,
 		atomic_set(&(jl->j_older_commits_done), 1);
 	}
 	mutex_unlock(&jl->j_commit_mutex);
-      put_jl:
+put_jl:
 	put_journal_list(s, jl);
 
 	if (retval)
@@ -1306,7 +1306,7 @@ static int flush_older_journal_lists(struct super_block *sb,
 	 * we know we are the only ones flushing things, no extra race
 	 * protection is required.
 	 */
-      restart:
+restart:
 	entry = journal->j_journal_list.next;
 	/* Did we wrap? */
 	if (entry == &journal->j_journal_list)
@@ -1504,7 +1504,7 @@ static int flush_journal_list(struct super_block *s,
 					 (unsigned long long)saved_bh->
 					 b_blocknr, __func__);
 		}
-	      free_cnode:
+free_cnode:
 		last = cn;
 		cn = cn->next;
 		if (saved_bh) {
@@ -1564,7 +1564,7 @@ static int flush_journal_list(struct super_block *s,
 		reiserfs_abort(s, -EIO,
 			       "Write error while pushing transaction to disk in %s",
 			       __func__);
-      flush_older_and_return:
+flush_older_and_return:
 
 	/*
 	 * before we can update the journal header block, we _must_ flush all
@@ -1670,7 +1670,7 @@ static int write_one_transaction(struct super_block *s,
 			}
 			put_bh(tmp_bh);
 		}
-	      next:
+next:
 		cn = cn->next;
 		cond_resched();
 	}
@@ -1770,7 +1770,7 @@ static int kupdate_transactions(struct super_block *s,
 		write_chunk(&chunk);
 	}
 
-      done:
+done:
 	mutex_unlock(&journal->j_flush_mutex);
 	return ret;
 }
@@ -2229,7 +2229,7 @@ static int journal_read_transaction(struct super_block *sb,
 			reiserfs_warning(sb, "journal-1204",
 					 "REPLAY FAILURE fsck required! "
 					 "Trying to replay onto a log block");
-		      abort_replay:
+abort_replay:
 			brelse_array(log_blocks, i);
 			brelse_array(real_blocks, i);
 			brelse(c_bh);
@@ -2491,7 +2491,7 @@ static int journal_read(struct super_block *sb)
 		brelse(d_bh);
 	}
 
-      start_log_replay:
+start_log_replay:
 	cur_dblock = oldest_start;
 	if (oldest_trans_id) {
 		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
@@ -2892,7 +2892,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
 	journal->j_work_sb = sb;
 	return 0;
-      free_and_return:
+free_and_return:
 	free_journal_ram(sb);
 	return 1;
 }
@@ -3031,7 +3031,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	th->t_refcount = 1;
 	th->t_super = sb;
 
-      relock:
+relock:
 	lock_journal(sb);
 	if (join != JBEGIN_ABORT && reiserfs_is_journal_aborted(journal)) {
 		unlock_journal(sb);
@@ -3122,7 +3122,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	INIT_LIST_HEAD(&th->t_list);
 	return 0;
 
-      out_fail:
+out_fail:
 	memset(th, 0, sizeof(*th));
 	/*
 	 * Re-set th->t_super, so we can properly keep track of how many
@@ -3876,7 +3876,7 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 		 * the inode still exists.  We know the list is still around
 		 * if we've got a larger transaction id than the oldest list
 		 */
-	      flush_commit_only:
+flush_commit_only:
 		if (journal_list_still_alive(inode->i_sb, id)) {
 			/*
 			 * we only set ret to 1 when we know for sure
@@ -4302,7 +4302,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	 * transactions that might get overwritten.  If any journal lists
 	 * are very old flush them as well.
 	 */
-      first_jl:
+first_jl:
 	list_for_each_safe(entry, safe, &journal->j_journal_list) {
 		temp_jl = JOURNAL_LIST_ENTRY(entry);
 		if (journal->j_start <= temp_jl->j_start) {
@@ -4359,7 +4359,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	    journal_list_still_alive(sb, commit_trans_id)) {
 		flush_commit_list(sb, jl, 1);
 	}
-      out:
+out:
 	reiserfs_check_lock_depth(sb, "journal end2");
 
 	memset(th, 0, sizeof(*th));

commit b491dd1769f11c2cd07278c1e285a63ccb1918ae
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:40 2014 -0400

    reiserfs: cleanup, remove blocks arg from journal_join
    
    journal_join is always called with a block count of 1. Let's just get
    rid of the argument.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 688c7d2f0fc5..b0ceee401a26 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -90,7 +90,7 @@ static int flush_commit_list(struct super_block *s,
 			     struct reiserfs_journal_list *jl, int flushall);
 static int can_dirty(struct reiserfs_journal_cnode *cn);
 static int journal_join(struct reiserfs_transaction_handle *th,
-			struct super_block *sb, unsigned long nblocks);
+			struct super_block *sb);
 static void release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal);
 static int dirty_one_transaction(struct super_block *s,
@@ -1925,7 +1925,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 		 * make sure something gets logged to force
 		 * our way into the flush code
 		 */
-		if (!journal_join(&myth, sb, 1)) {
+		if (!journal_join(&myth, sb)) {
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);
@@ -1938,7 +1938,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	/* this also catches errors during the do_journal_end above */
 	if (!error && reiserfs_is_journal_aborted(journal)) {
 		memset(&myth, 0, sizeof(myth));
-		if (!journal_join_abort(&myth, sb, 1)) {
+		if (!journal_join_abort(&myth, sb)) {
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);
@@ -3092,7 +3092,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 			}
 			goto relock;
 		}
-		retval = journal_join(&myth, sb, 1);
+		retval = journal_join(&myth, sb);
 		if (retval)
 			goto out_fail;
 
@@ -3181,7 +3181,7 @@ int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
 }
 
 static int journal_join(struct reiserfs_transaction_handle *th,
-			struct super_block *sb, unsigned long nblocks)
+			struct super_block *sb)
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
@@ -3191,11 +3191,11 @@ static int journal_join(struct reiserfs_transaction_handle *th,
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
-	return do_journal_begin_r(th, sb, nblocks, JBEGIN_JOIN);
+	return do_journal_begin_r(th, sb, 1, JBEGIN_JOIN);
 }
 
 int journal_join_abort(struct reiserfs_transaction_handle *th,
-		       struct super_block *sb, unsigned long nblocks)
+		       struct super_block *sb)
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
@@ -3205,7 +3205,7 @@ int journal_join_abort(struct reiserfs_transaction_handle *th,
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
-	return do_journal_begin_r(th, sb, nblocks, JBEGIN_ABORT);
+	return do_journal_begin_r(th, sb, 1, JBEGIN_ABORT);
 }
 
 int journal_begin(struct reiserfs_transaction_handle *th,
@@ -3571,7 +3571,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 	    journal->j_trans_start_time > 0 &&
 	    journal->j_len > 0 &&
 	    (now - journal->j_trans_start_time) > journal->j_max_trans_age) {
-		if (!journal_join(&th, sb, 1)) {
+		if (!journal_join(&th, sb)) {
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);

commit 09f1b80ba8c967b6e17c0516e95578d5da18115f
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:39 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_mark_dirty
    
    journal_mark_dirty doesn't need a separate sb argument; It's provided
    by the transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 5b4ccd5f642e..688c7d2f0fc5 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1929,8 +1929,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&myth, sb,
-					   SB_BUFFER_WITH_SB(sb));
+			journal_mark_dirty(&myth, SB_BUFFER_WITH_SB(sb));
 			do_journal_end(&myth, FLUSH_ALL);
 			flushed = 1;
 		}
@@ -1943,8 +1942,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&myth, sb,
-					   SB_BUFFER_WITH_SB(sb));
+			journal_mark_dirty(&myth, SB_BUFFER_WITH_SB(sb));
 			do_journal_end(&myth, FLUSH_ALL);
 		}
 	}
@@ -3268,8 +3266,9 @@ int journal_begin(struct reiserfs_transaction_handle *th,
  * if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
  */
 int journal_mark_dirty(struct reiserfs_transaction_handle *th,
-		       struct super_block *sb, struct buffer_head *bh)
+		       struct buffer_head *bh)
 {
+	struct super_block *sb = th->t_super;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn = NULL;
 	int count_already_incd = 0;
@@ -3522,7 +3521,7 @@ int journal_end_sync(struct reiserfs_transaction_handle *th)
 	if (journal->j_len == 0) {
 		reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 					     1);
-		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
+		journal_mark_dirty(th, SB_BUFFER_WITH_SB(sb));
 	}
 	return do_journal_end(th, COMMIT_NOW | WAIT);
 }
@@ -3576,8 +3575,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&th, sb,
-					   SB_BUFFER_WITH_SB(sb));
+			journal_mark_dirty(&th, SB_BUFFER_WITH_SB(sb));
 
 			/*
 			 * we're only being called from kreiserfsd, it makes
@@ -3863,7 +3861,7 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 		if (journal->j_trans_id != id) {
 			reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb));
+			journal_mark_dirty(&th, SB_BUFFER_WITH_SB(sb));
 			ret = journal_end(&th);
 			goto flush_commit_only;
 		}
@@ -4014,7 +4012,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 	if (journal->j_len == 0) {
 		reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 					     1);
-		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
+		journal_mark_dirty(th, SB_BUFFER_WITH_SB(sb));
 	}
 
 	lock_journal(sb);

commit 58d854265c4c7d9792ecb5aa5ef67ba79b1a4c12
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:38 2014 -0400

    reiserfs: cleanup, remove sb argument from journal_end
    
    journal_end doesn't need a separate sb argument; it's provided by the
    transaction handle.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a2f80d6c4f7e..5b4ccd5f642e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -83,8 +83,7 @@
 #define COMMIT_NOW  2		/* end and commit this transaction */
 #define WAIT        4		/* wait for the log blocks to hit the disk */
 
-static int do_journal_end(struct reiserfs_transaction_handle *,
-			  struct super_block *, int flags);
+static int do_journal_end(struct reiserfs_transaction_handle *, int flags);
 static int flush_journal_list(struct super_block *s,
 			      struct reiserfs_journal_list *jl, int flushall);
 static int flush_commit_list(struct super_block *s,
@@ -1920,7 +1919,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	if (!error && !(sb->s_flags & MS_RDONLY)) {
 		/* end the current trans */
 		BUG_ON(!th->t_trans_id);
-		do_journal_end(th, sb, FLUSH_ALL);
+		do_journal_end(th, FLUSH_ALL);
 
 		/*
 		 * make sure something gets logged to force
@@ -1932,7 +1931,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 						     1);
 			journal_mark_dirty(&myth, sb,
 					   SB_BUFFER_WITH_SB(sb));
-			do_journal_end(&myth, sb, FLUSH_ALL);
+			do_journal_end(&myth, FLUSH_ALL);
 			flushed = 1;
 		}
 	}
@@ -1946,7 +1945,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 						     1);
 			journal_mark_dirty(&myth, sb,
 					   SB_BUFFER_WITH_SB(sb));
-			do_journal_end(&myth, sb, FLUSH_ALL);
+			do_journal_end(&myth, FLUSH_ALL);
 		}
 	}
 
@@ -3101,9 +3100,9 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 
 		/* someone might have ended the transaction while we joined */
 		if (old_trans_id != journal->j_trans_id) {
-			retval = do_journal_end(&myth, sb, 0);
+			retval = do_journal_end(&myth, 0);
 		} else {
-			retval = do_journal_end(&myth, sb, COMMIT_NOW);
+			retval = do_journal_end(&myth, COMMIT_NOW);
 		}
 
 		if (retval)
@@ -3173,7 +3172,7 @@ int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
 	struct super_block *s = th->t_super;
 	int ret = 0;
 	if (th->t_trans_id)
-		ret = journal_end(th, th->t_super);
+		ret = journal_end(th);
 	else
 		ret = -EIO;
 	if (th->t_refcount == 0) {
@@ -3374,8 +3373,9 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	return 0;
 }
 
-int journal_end(struct reiserfs_transaction_handle *th, struct super_block *sb)
+int journal_end(struct reiserfs_transaction_handle *th)
 {
+	struct super_block *sb = th->t_super;
 	if (!current->journal_info && th->t_refcount > 1)
 		reiserfs_warning(sb, "REISER-NESTING",
 				 "th NULL, refcount %d", th->t_refcount);
@@ -3402,7 +3402,7 @@ int journal_end(struct reiserfs_transaction_handle *th, struct super_block *sb)
 		}
 		return 0;
 	} else {
-		return do_journal_end(th, sb, 0);
+		return do_journal_end(th, 0);
 	}
 }
 
@@ -3511,9 +3511,9 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
  * syncs the commit blocks, but does not force the real buffers to disk
  * will wait until the current transaction is done/committed before returning
  */
-int journal_end_sync(struct reiserfs_transaction_handle *th,
-		     struct super_block *sb)
+int journal_end_sync(struct reiserfs_transaction_handle *th)
 {
+	struct super_block *sb = th->t_super;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	BUG_ON(!th->t_trans_id);
@@ -3524,7 +3524,7 @@ int journal_end_sync(struct reiserfs_transaction_handle *th,
 					     1);
 		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
 	}
-	return do_journal_end(th, sb, COMMIT_NOW | WAIT);
+	return do_journal_end(th, COMMIT_NOW | WAIT);
 }
 
 /* writeback the pending async commits to disk */
@@ -3584,7 +3584,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 			 * no sense to do an async commit so that kreiserfsd
 			 * can do it later
 			 */
-			do_journal_end(&th, sb, COMMIT_NOW | WAIT);
+			do_journal_end(&th, COMMIT_NOW | WAIT);
 		}
 	}
 }
@@ -3604,8 +3604,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
  * Note, we can't allow the journal_end to proceed while there are still
  * writers in the log.
  */
-static int check_journal_end(struct reiserfs_transaction_handle *th,
-			     struct super_block *sb, int flags)
+static int check_journal_end(struct reiserfs_transaction_handle *th, int flags)
 {
 
 	time_t now;
@@ -3613,6 +3612,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	int commit_now = flags & COMMIT_NOW;
 	int wait_on_commit = flags & WAIT;
 	struct reiserfs_journal_list *jl;
+	struct super_block *sb = th->t_super;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	BUG_ON(!th->t_trans_id);
@@ -3864,11 +3864,11 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 			reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 						     1);
 			journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb));
-			ret = journal_end(&th, sb);
+			ret = journal_end(&th);
 			goto flush_commit_only;
 		}
 
-		ret = journal_end_sync(&th, sb);
+		ret = journal_end_sync(&th);
 		if (!ret)
 			ret = 1;
 
@@ -3974,9 +3974,9 @@ int reiserfs_prepare_for_journal(struct super_block *sb,
  * If the journal is aborted, we just clean up. Things like flushing
  * journal lists, etc just won't happen.
  */
-static int do_journal_end(struct reiserfs_transaction_handle *th,
-			  struct super_block *sb, int flags)
+static int do_journal_end(struct reiserfs_transaction_handle *th, int flags)
 {
+	struct super_block *sb = th->t_super;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn, *next, *jl_cn;
 	struct reiserfs_journal_cnode *last_cn = NULL;
@@ -3998,6 +3998,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 
 	BUG_ON(th->t_refcount > 1);
 	BUG_ON(!th->t_trans_id);
+	BUG_ON(!th->t_super);
 
 	/*
 	 * protect flush_older_commits from doing mistakes if the
@@ -4031,7 +4032,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * not return 1 it tells us if we should continue with the
 	 * journal_end, or just return
 	 */
-	if (!check_journal_end(th, sb, flags)) {
+	if (!check_journal_end(th, flags)) {
 		reiserfs_schedule_old_flush(sb);
 		wake_queued_writers(sb);
 		reiserfs_async_progress_wait(sb);

commit 706a5323384d9ae973a72005b73987d39e009019
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:37 2014 -0400

    reiserfs: cleanup, remove nblocks argument from journal_end
    
    journal_end takes a block count argument but doesn't actually use it
    for anything. We can remove it.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 48f03e5d16ef..a2f80d6c4f7e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -84,8 +84,7 @@
 #define WAIT        4		/* wait for the log blocks to hit the disk */
 
 static int do_journal_end(struct reiserfs_transaction_handle *,
-			  struct super_block *, unsigned long nblocks,
-			  int flags);
+			  struct super_block *, int flags);
 static int flush_journal_list(struct super_block *s,
 			      struct reiserfs_journal_list *jl, int flushall);
 static int flush_commit_list(struct super_block *s,
@@ -1921,7 +1920,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	if (!error && !(sb->s_flags & MS_RDONLY)) {
 		/* end the current trans */
 		BUG_ON(!th->t_trans_id);
-		do_journal_end(th, sb, 10, FLUSH_ALL);
+		do_journal_end(th, sb, FLUSH_ALL);
 
 		/*
 		 * make sure something gets logged to force
@@ -1933,7 +1932,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 						     1);
 			journal_mark_dirty(&myth, sb,
 					   SB_BUFFER_WITH_SB(sb));
-			do_journal_end(&myth, sb, 1, FLUSH_ALL);
+			do_journal_end(&myth, sb, FLUSH_ALL);
 			flushed = 1;
 		}
 	}
@@ -1947,7 +1946,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 						     1);
 			journal_mark_dirty(&myth, sb,
 					   SB_BUFFER_WITH_SB(sb));
-			do_journal_end(&myth, sb, 1, FLUSH_ALL);
+			do_journal_end(&myth, sb, FLUSH_ALL);
 		}
 	}
 
@@ -3102,9 +3101,9 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 
 		/* someone might have ended the transaction while we joined */
 		if (old_trans_id != journal->j_trans_id) {
-			retval = do_journal_end(&myth, sb, 1, 0);
+			retval = do_journal_end(&myth, sb, 0);
 		} else {
-			retval = do_journal_end(&myth, sb, 1, COMMIT_NOW);
+			retval = do_journal_end(&myth, sb, COMMIT_NOW);
 		}
 
 		if (retval)
@@ -3174,7 +3173,7 @@ int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
 	struct super_block *s = th->t_super;
 	int ret = 0;
 	if (th->t_trans_id)
-		ret = journal_end(th, th->t_super, th->t_blocks_allocated);
+		ret = journal_end(th, th->t_super);
 	else
 		ret = -EIO;
 	if (th->t_refcount == 0) {
@@ -3375,8 +3374,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	return 0;
 }
 
-int journal_end(struct reiserfs_transaction_handle *th,
-		struct super_block *sb, unsigned long nblocks)
+int journal_end(struct reiserfs_transaction_handle *th, struct super_block *sb)
 {
 	if (!current->journal_info && th->t_refcount > 1)
 		reiserfs_warning(sb, "REISER-NESTING",
@@ -3404,7 +3402,7 @@ int journal_end(struct reiserfs_transaction_handle *th,
 		}
 		return 0;
 	} else {
-		return do_journal_end(th, sb, nblocks, 0);
+		return do_journal_end(th, sb, 0);
 	}
 }
 
@@ -3514,7 +3512,7 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
  * will wait until the current transaction is done/committed before returning
  */
 int journal_end_sync(struct reiserfs_transaction_handle *th,
-		     struct super_block *sb, unsigned long nblocks)
+		     struct super_block *sb)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
@@ -3526,7 +3524,7 @@ int journal_end_sync(struct reiserfs_transaction_handle *th,
 					     1);
 		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
 	}
-	return do_journal_end(th, sb, nblocks, COMMIT_NOW | WAIT);
+	return do_journal_end(th, sb, COMMIT_NOW | WAIT);
 }
 
 /* writeback the pending async commits to disk */
@@ -3586,7 +3584,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 			 * no sense to do an async commit so that kreiserfsd
 			 * can do it later
 			 */
-			do_journal_end(&th, sb, 1, COMMIT_NOW | WAIT);
+			do_journal_end(&th, sb, COMMIT_NOW | WAIT);
 		}
 	}
 }
@@ -3607,8 +3605,7 @@ void reiserfs_flush_old_commits(struct super_block *sb)
  * writers in the log.
  */
 static int check_journal_end(struct reiserfs_transaction_handle *th,
-			     struct super_block *sb, unsigned long nblocks,
-			     int flags)
+			     struct super_block *sb, int flags)
 {
 
 	time_t now;
@@ -3867,11 +3864,11 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 			reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 						     1);
 			journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb));
-			ret = journal_end(&th, sb, 1);
+			ret = journal_end(&th, sb);
 			goto flush_commit_only;
 		}
 
-		ret = journal_end_sync(&th, sb, 1);
+		ret = journal_end_sync(&th, sb);
 		if (!ret)
 			ret = 1;
 
@@ -3978,8 +3975,7 @@ int reiserfs_prepare_for_journal(struct super_block *sb,
  * journal lists, etc just won't happen.
  */
 static int do_journal_end(struct reiserfs_transaction_handle *th,
-			  struct super_block *sb, unsigned long nblocks,
-			  int flags)
+			  struct super_block *sb, int flags)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn, *next, *jl_cn;
@@ -4035,7 +4031,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * not return 1 it tells us if we should continue with the
 	 * journal_end, or just return
 	 */
-	if (!check_journal_end(th, sb, nblocks, flags)) {
+	if (!check_journal_end(th, sb, flags)) {
 		reiserfs_schedule_old_flush(sb);
 		wake_queued_writers(sb);
 		reiserfs_async_progress_wait(sb);

commit 098297b27d23ad9d0fc302e3417474d9342c6c14
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:36 2014 -0400

    reiserfs: cleanup, reformat comments to normal kernel style
    
    This patch reformats comments in the reiserfs code to fit in 80 columns and
    to follow the style rules.
    
    There is no functional change but it helps make my eyes bleed less.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 225921126455..48f03e5d16ef 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1,38 +1,38 @@
 /*
-** Write ahead logging implementation copyright Chris Mason 2000
-**
-** The background commits make this code very interrelated, and
-** overly complex.  I need to rethink things a bit....The major players:
-**
-** journal_begin -- call with the number of blocks you expect to log.
-**                  If the current transaction is too
-** 		    old, it will block until the current transaction is
-** 		    finished, and then start a new one.
-**		    Usually, your transaction will get joined in with
-**                  previous ones for speed.
-**
-** journal_join  -- same as journal_begin, but won't block on the current
-**                  transaction regardless of age.  Don't ever call
-**                  this.  Ever.  There are only two places it should be
-**                  called from, and they are both inside this file.
-**
-** journal_mark_dirty -- adds blocks into this transaction.  clears any flags
-**                       that might make them get sent to disk
-**                       and then marks them BH_JDirty.  Puts the buffer head
-**                       into the current transaction hash.
-**
-** journal_end -- if the current transaction is batchable, it does nothing
-**                   otherwise, it could do an async/synchronous commit, or
-**                   a full flush of all log and real blocks in the
-**                   transaction.
-**
-** flush_old_commits -- if the current transaction is too old, it is ended and
-**                      commit blocks are sent to disk.  Forces commit blocks
-**                      to disk for all backgrounded commits that have been
-**                      around too long.
-**		     -- Note, if you call this as an immediate flush from
-**		        from within kupdate, it will ignore the immediate flag
-*/
+ * Write ahead logging implementation copyright Chris Mason 2000
+ *
+ * The background commits make this code very interrelated, and
+ * overly complex.  I need to rethink things a bit....The major players:
+ *
+ * journal_begin -- call with the number of blocks you expect to log.
+ *                  If the current transaction is too
+ *		    old, it will block until the current transaction is
+ *		    finished, and then start a new one.
+ *		    Usually, your transaction will get joined in with
+ *                  previous ones for speed.
+ *
+ * journal_join  -- same as journal_begin, but won't block on the current
+ *                  transaction regardless of age.  Don't ever call
+ *                  this.  Ever.  There are only two places it should be
+ *                  called from, and they are both inside this file.
+ *
+ * journal_mark_dirty -- adds blocks into this transaction.  clears any flags
+ *                       that might make them get sent to disk
+ *                       and then marks them BH_JDirty.  Puts the buffer head
+ *                       into the current transaction hash.
+ *
+ * journal_end -- if the current transaction is batchable, it does nothing
+ *                   otherwise, it could do an async/synchronous commit, or
+ *                   a full flush of all log and real blocks in the
+ *                   transaction.
+ *
+ * flush_old_commits -- if the current transaction is too old, it is ended and
+ *                      commit blocks are sent to disk.  Forces commit blocks
+ *                      to disk for all backgrounded commits that have been
+ *                      around too long.
+ *		     -- Note, if you call this as an immediate flush from
+ *		        from within kupdate, it will ignore the immediate flag
+ */
 
 #include <linux/time.h>
 #include <linux/semaphore.h>
@@ -58,16 +58,19 @@
 #define JOURNAL_WORK_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
                                j_working_list))
 
-#define JOURNAL_TRANS_HALF 1018	/* must be correct to keep the desc and commit
-				   structs at 4k */
+/* must be correct to keep the desc and commit structs at 4k */
+#define JOURNAL_TRANS_HALF 1018
 #define BUFNR 64		/*read ahead */
 
 /* cnode stat bits.  Move these into reiserfs_fs.h */
 
-#define BLOCK_FREED 2		/* this block was freed, and can't be written.  */
-#define BLOCK_FREED_HOLDER 3	/* this block was freed during this transaction, and can't be written */
+/* this block was freed, and can't be written.  */
+#define BLOCK_FREED 2
+/* this block was freed during this transaction, and can't be written */
+#define BLOCK_FREED_HOLDER 3
 
-#define BLOCK_NEEDS_FLUSH 4	/* used in flush_journal_list */
+/* used in flush_journal_list */
+#define BLOCK_NEEDS_FLUSH 4
 #define BLOCK_DIRTIED 5
 
 /* journal list state bits */
@@ -100,8 +103,10 @@ static void queue_log_writer(struct super_block *s);
 /* values for join in do_journal_begin_r */
 enum {
 	JBEGIN_REG = 0,		/* regular journal begin */
-	JBEGIN_JOIN = 1,	/* join the running transaction if at all possible */
-	JBEGIN_ABORT = 2,	/* called from cleanup code, ignores aborted flag */
+	/* join the running transaction if at all possible */
+	JBEGIN_JOIN = 1,
+	/* called from cleanup code, ignores aborted flag */
+	JBEGIN_ABORT = 2,
 };
 
 static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
@@ -116,10 +121,11 @@ static void init_journal_hash(struct super_block *sb)
 }
 
 /*
-** clears BH_Dirty and sticks the buffer on the clean list.  Called because I can't allow refile_buffer to
-** make schedule happen after I've freed a block.  Look at remove_from_transaction and journal_mark_freed for
-** more details.
-*/
+ * clears BH_Dirty and sticks the buffer on the clean list.  Called because
+ * I can't allow refile_buffer to make schedule happen after I've freed a
+ * block.  Look at remove_from_transaction and journal_mark_freed for
+ * more details.
+ */
 static int reiserfs_clean_and_file_buffer(struct buffer_head *bh)
 {
 	if (bh) {
@@ -197,7 +203,8 @@ static void allocate_bitmap_nodes(struct super_block *sb)
 			list_add(&bn->list, &journal->j_bitmap_nodes);
 			journal->j_free_bitmap_nodes++;
 		} else {
-			break;	/* this is ok, we'll try again when more are needed */
+			/* this is ok, we'll try again when more are needed */
+			break;
 		}
 	}
 }
@@ -232,8 +239,8 @@ static void cleanup_bitmap_list(struct super_block *sb,
 }
 
 /*
-** only call this on FS unmount.
-*/
+ * only call this on FS unmount.
+ */
 static int free_list_bitmaps(struct super_block *sb,
 			     struct reiserfs_list_bitmap *jb_array)
 {
@@ -268,9 +275,9 @@ static int free_bitmap_nodes(struct super_block *sb)
 }
 
 /*
-** get memory for JOURNAL_NUM_BITMAPS worth of bitmaps.
-** jb_array is the array to be filled in.
-*/
+ * get memory for JOURNAL_NUM_BITMAPS worth of bitmaps.
+ * jb_array is the array to be filled in.
+ */
 int reiserfs_allocate_list_bitmaps(struct super_block *sb,
 				   struct reiserfs_list_bitmap *jb_array,
 				   unsigned int bmap_nr)
@@ -299,9 +306,9 @@ int reiserfs_allocate_list_bitmaps(struct super_block *sb,
 }
 
 /*
-** find an available list bitmap.  If you can't find one, flush a commit list
-** and try again
-*/
+ * find an available list bitmap.  If you can't find one, flush a commit list
+ * and try again
+ */
 static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *sb,
 						    struct reiserfs_journal_list
 						    *jl)
@@ -325,18 +332,18 @@ static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *sb,
 			break;
 		}
 	}
-	if (jb->journal_list) {	/* double check to make sure if flushed correctly */
+	/* double check to make sure if flushed correctly */
+	if (jb->journal_list)
 		return NULL;
-	}
 	jb->journal_list = jl;
 	return jb;
 }
 
 /*
-** allocates a new chunk of X nodes, and links them all together as a list.
-** Uses the cnode->next and cnode->prev pointers
-** returns NULL on failure
-*/
+ * allocates a new chunk of X nodes, and links them all together as a list.
+ * Uses the cnode->next and cnode->prev pointers
+ * returns NULL on failure
+ */
 static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 {
 	struct reiserfs_journal_cnode *head;
@@ -358,9 +365,7 @@ static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 	return head;
 }
 
-/*
-** pulls a cnode off the free list, or returns NULL on failure
-*/
+/* pulls a cnode off the free list, or returns NULL on failure */
 static struct reiserfs_journal_cnode *get_cnode(struct super_block *sb)
 {
 	struct reiserfs_journal_cnode *cn;
@@ -386,8 +391,8 @@ static struct reiserfs_journal_cnode *get_cnode(struct super_block *sb)
 }
 
 /*
-** returns a cnode to the free list
-*/
+ * returns a cnode to the free list
+ */
 static void free_cnode(struct super_block *sb,
 		       struct reiserfs_journal_cnode *cn)
 {
@@ -412,7 +417,10 @@ static void clear_prepared_bits(struct buffer_head *bh)
 	clear_buffer_journal_restore_dirty(bh);
 }
 
-/* return a cnode with same dev, block number and size in table, or null if not found */
+/*
+ * return a cnode with same dev, block number and size in table,
+ * or null if not found
+ */
 static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
 								  super_block
 								  *sb,
@@ -432,23 +440,24 @@ static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
 }
 
 /*
-** this actually means 'can this block be reallocated yet?'.  If you set search_all, a block can only be allocated
-** if it is not in the current transaction, was not freed by the current transaction, and has no chance of ever
-** being overwritten by a replay after crashing.
-**
-** If you don't set search_all, a block can only be allocated if it is not in the current transaction.  Since deleting
-** a block removes it from the current transaction, this case should never happen.  If you don't set search_all, make
-** sure you never write the block without logging it.
-**
-** next_zero_bit is a suggestion about the next block to try for find_forward.
-** when bl is rejected because it is set in a journal list bitmap, we search
-** for the next zero bit in the bitmap that rejected bl.  Then, we return that
-** through next_zero_bit for find_forward to try.
-**
-** Just because we return something in next_zero_bit does not mean we won't
-** reject it on the next call to reiserfs_in_journal
-**
-*/
+ * this actually means 'can this block be reallocated yet?'.  If you set
+ * search_all, a block can only be allocated if it is not in the current
+ * transaction, was not freed by the current transaction, and has no chance
+ * of ever being overwritten by a replay after crashing.
+ *
+ * If you don't set search_all, a block can only be allocated if it is not
+ * in the current transaction.  Since deleting a block removes it from the
+ * current transaction, this case should never happen.  If you don't set
+ * search_all, make sure you never write the block without logging it.
+ *
+ * next_zero_bit is a suggestion about the next block to try for find_forward.
+ * when bl is rejected because it is set in a journal list bitmap, we search
+ * for the next zero bit in the bitmap that rejected bl.  Then, we return
+ * that through next_zero_bit for find_forward to try.
+ *
+ * Just because we return something in next_zero_bit does not mean we won't
+ * reject it on the next call to reiserfs_in_journal
+ */
 int reiserfs_in_journal(struct super_block *sb,
 			unsigned int bmap_nr, int bit_nr, int search_all,
 			b_blocknr_t * next_zero_bit)
@@ -462,9 +471,11 @@ int reiserfs_in_journal(struct super_block *sb,
 	*next_zero_bit = 0;	/* always start this at zero. */
 
 	PROC_INFO_INC(sb, journal.in_journal);
-	/* If we aren't doing a search_all, this is a metablock, and it will be logged before use.
-	 ** if we crash before the transaction that freed it commits,  this transaction won't
-	 ** have committed either, and the block will never be written
+	/*
+	 * If we aren't doing a search_all, this is a metablock, and it
+	 * will be logged before use.  if we crash before the transaction
+	 * that freed it commits,  this transaction won't have committed
+	 * either, and the block will never be written
 	 */
 	if (search_all) {
 		for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
@@ -504,8 +515,7 @@ int reiserfs_in_journal(struct super_block *sb,
 	return 0;
 }
 
-/* insert cn into table
-*/
+/* insert cn into table */
 static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 				       struct reiserfs_journal_cnode *cn)
 {
@@ -551,10 +561,10 @@ static inline void put_journal_list(struct super_block *s,
 }
 
 /*
-** this used to be much more involved, and I'm keeping it just in case things get ugly again.
-** it gets called by flush_commit_list, and cleans up any data stored about blocks freed during a
-** transaction.
-*/
+ * this used to be much more involved, and I'm keeping it just in case
+ * things get ugly again.  it gets called by flush_commit_list, and
+ * cleans up any data stored about blocks freed during a transaction.
+ */
 static void cleanup_freed_for_journal_list(struct super_block *sb,
 					   struct reiserfs_journal_list *jl)
 {
@@ -753,7 +763,8 @@ static inline int __add_jh(struct reiserfs_journal *j, struct buffer_head *bh,
 		get_bh(bh);
 		jh = alloc_jh();
 		spin_lock(&j->j_dirty_buffers_lock);
-		/* buffer must be locked for __add_jh, should be able to have
+		/*
+		 * buffer must be locked for __add_jh, should be able to have
 		 * two adds at the same time
 		 */
 		BUG_ON(bh->b_private);
@@ -811,7 +822,8 @@ static int write_ordered_buffers(spinlock_t * lock,
 			spin_lock(lock);
 			goto loop_next;
 		}
-		/* in theory, dirty non-uptodate buffers should never get here,
+		/*
+		 * in theory, dirty non-uptodate buffers should never get here,
 		 * but the upper layer io error paths still have a few quirks.
 		 * Handle them here as gracefully as we can
 		 */
@@ -849,13 +861,14 @@ static int write_ordered_buffers(spinlock_t * lock,
 		if (!buffer_uptodate(bh)) {
 			ret = -EIO;
 		}
-		/* ugly interaction with invalidatepage here.
-		 * reiserfs_invalidate_page will pin any buffer that has a valid
-		 * journal head from an older transaction.  If someone else sets
-		 * our buffer dirty after we write it in the first loop, and
-		 * then someone truncates the page away, nobody will ever write
-		 * the buffer. We're safe if we write the page one last time
-		 * after freeing the journal header.
+		/*
+		 * ugly interaction with invalidatepage here.
+		 * reiserfs_invalidate_page will pin any buffer that has a
+		 * valid journal head from an older transaction.  If someone
+		 * else sets our buffer dirty after we write it in the first
+		 * loop, and then someone truncates the page away, nobody
+		 * will ever write the buffer. We're safe if we write the
+		 * page one last time after freeing the journal header.
 		 */
 		if (buffer_dirty(bh) && unlikely(bh->b_page->mapping == NULL)) {
 			spin_unlock(lock);
@@ -916,9 +929,11 @@ static int flush_older_commits(struct super_block *s,
 				if (!journal_list_still_alive(s, trans_id))
 					return 1;
 
-				/* the one we just flushed is gone, this means all
-				 * older lists are also gone, so first_jl is no longer
-				 * valid either.  Go back to the beginning.
+				/*
+				 * the one we just flushed is gone, this means
+				 * all older lists are also gone, so first_jl
+				 * is no longer valid either.  Go back to the
+				 * beginning.
 				 */
 				if (!journal_list_still_alive
 				    (s, other_trans_id)) {
@@ -951,12 +966,12 @@ static int reiserfs_async_progress_wait(struct super_block *s)
 }
 
 /*
-** if this journal list still has commit blocks unflushed, send them to disk.
-**
-** log areas must be flushed in order (transaction 2 can't commit before transaction 1)
-** Before the commit block can by written, every other log block must be safely on disk
-**
-*/
+ * if this journal list still has commit blocks unflushed, send them to disk.
+ *
+ * log areas must be flushed in order (transaction 2 can't commit before
+ * transaction 1) Before the commit block can by written, every other log
+ * block must be safely on disk
+ */
 static int flush_commit_list(struct super_block *s,
 			     struct reiserfs_journal_list *jl, int flushall)
 {
@@ -975,8 +990,9 @@ static int flush_commit_list(struct super_block *s,
 		return 0;
 	}
 
-	/* before we can put our commit blocks on disk, we have to make sure everyone older than
-	 ** us is on disk too
+	/*
+	 * before we can put our commit blocks on disk, we have to make
+	 * sure everyone older than us is on disk too
 	 */
 	BUG_ON(jl->j_len <= 0);
 	BUG_ON(trans_id == journal->j_trans_id);
@@ -984,7 +1000,10 @@ static int flush_commit_list(struct super_block *s,
 	get_journal_list(jl);
 	if (flushall) {
 		if (flush_older_commits(s, jl) == 1) {
-			/* list disappeared during flush_older_commits.  return */
+			/*
+			 * list disappeared during flush_older_commits.
+			 * return
+			 */
 			goto put_jl;
 		}
 	}
@@ -1056,9 +1075,10 @@ static int flush_commit_list(struct super_block *s,
 		depth = reiserfs_write_unlock_nested(s);
 		__wait_on_buffer(tbh);
 		reiserfs_write_lock_nested(s, depth);
-		// since we're using ll_rw_blk above, it might have skipped over
-		// a locked buffer.  Double check here
-		//
+		/*
+		 * since we're using ll_rw_blk above, it might have skipped
+		 * over a locked buffer.  Double check here
+		 */
 		/* redundant, sync_dirty_buffer() checks */
 		if (buffer_dirty(tbh)) {
 			depth = reiserfs_write_unlock_nested(s);
@@ -1072,17 +1092,21 @@ static int flush_commit_list(struct super_block *s,
 #endif
 			retval = -EIO;
 		}
-		put_bh(tbh);	/* once for journal_find_get_block */
-		put_bh(tbh);	/* once due to original getblk in do_journal_end */
+		/* once for journal_find_get_block */
+		put_bh(tbh);
+		/* once due to original getblk in do_journal_end */
+		put_bh(tbh);
 		atomic_dec(&(jl->j_commit_left));
 	}
 
 	BUG_ON(atomic_read(&(jl->j_commit_left)) != 1);
 
-	/* If there was a write error in the journal - we can't commit
+	/*
+	 * If there was a write error in the journal - we can't commit
 	 * this transaction - it will be invalid and, if successful,
 	 * will just end up propagating the write error out to
-	 * the file system. */
+	 * the file system.
+	 */
 	if (likely(!retval && !reiserfs_is_journal_aborted (journal))) {
 		if (buffer_dirty(jl->j_commit_bh))
 			BUG();
@@ -1095,9 +1119,11 @@ static int flush_commit_list(struct super_block *s,
 		reiserfs_write_lock_nested(s, depth);
 	}
 
-	/* If there was a write error in the journal - we can't commit this
+	/*
+	 * If there was a write error in the journal - we can't commit this
 	 * transaction - it will be invalid and, if successful, will just end
-	 * up propagating the write error out to the filesystem. */
+	 * up propagating the write error out to the filesystem.
+	 */
 	if (unlikely(!buffer_uptodate(jl->j_commit_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
 		reiserfs_warning(s, "journal-615", "buffer write failed");
@@ -1112,7 +1138,10 @@ static int flush_commit_list(struct super_block *s,
 	}
 	journal->j_last_commit_id = jl->j_trans_id;
 
-	/* now, every commit block is on the disk.  It is safe to allow blocks freed during this transaction to be reallocated */
+	/*
+	 * now, every commit block is on the disk.  It is safe to allow
+	 * blocks freed during this transaction to be reallocated
+	 */
 	cleanup_freed_for_journal_list(s, jl);
 
 	retval = retval ? retval : journal->j_errno;
@@ -1136,9 +1165,9 @@ static int flush_commit_list(struct super_block *s,
 }
 
 /*
-** flush_journal_list frequently needs to find a newer transaction for a given block.  This does that, or
-** returns NULL if it can't find anything
-*/
+ * flush_journal_list frequently needs to find a newer transaction for a
+ * given block.  This does that, or returns NULL if it can't find anything
+ */
 static struct reiserfs_journal_list *find_newer_jl_for_cn(struct
 							  reiserfs_journal_cnode
 							  *cn)
@@ -1162,10 +1191,11 @@ static void remove_journal_hash(struct super_block *,
 				int);
 
 /*
-** once all the real blocks have been flushed, it is safe to remove them from the
-** journal list for this transaction.  Aside from freeing the cnode, this also allows the
-** block to be reallocated for data blocks if it had been deleted.
-*/
+ * once all the real blocks have been flushed, it is safe to remove them
+ * from the journal list for this transaction.  Aside from freeing the
+ * cnode, this also allows the block to be reallocated for data blocks
+ * if it had been deleted.
+ */
 static void remove_all_from_journal_list(struct super_block *sb,
 					 struct reiserfs_journal_list *jl,
 					 int debug)
@@ -1174,8 +1204,9 @@ static void remove_all_from_journal_list(struct super_block *sb,
 	struct reiserfs_journal_cnode *cn, *last;
 	cn = jl->j_realblock;
 
-	/* which is better, to lock once around the whole loop, or
-	 ** to lock for each call to remove_journal_hash?
+	/*
+	 * which is better, to lock once around the whole loop, or
+	 * to lock for each call to remove_journal_hash?
 	 */
 	while (cn) {
 		if (cn->blocknr != 0) {
@@ -1197,12 +1228,13 @@ static void remove_all_from_journal_list(struct super_block *sb,
 }
 
 /*
-** if this timestamp is greater than the timestamp we wrote last to the header block, write it to the header block.
-** once this is done, I can safely say the log area for this transaction won't ever be replayed, and I can start
-** releasing blocks in this transaction for reuse as data blocks.
-** called by flush_journal_list, before it calls remove_all_from_journal_list
-**
-*/
+ * if this timestamp is greater than the timestamp we wrote last to the
+ * header block, write it to the header block.  once this is done, I can
+ * safely say the log area for this transaction won't ever be replayed,
+ * and I can start releasing blocks in this transaction for reuse as data
+ * blocks.  called by flush_journal_list, before it calls
+ * remove_all_from_journal_list
+ */
 static int _update_journal_header_block(struct super_block *sb,
 					unsigned long offset,
 					unsigned int trans_id)
@@ -1272,7 +1304,8 @@ static int flush_older_journal_lists(struct super_block *sb,
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned int trans_id = jl->j_trans_id;
 
-	/* we know we are the only ones flushing things, no extra race
+	/*
+	 * we know we are the only ones flushing things, no extra race
 	 * protection is required.
 	 */
       restart:
@@ -1302,15 +1335,16 @@ static void del_from_work_list(struct super_block *s,
 	}
 }
 
-/* flush a journal list, both commit and real blocks
-**
-** always set flushall to 1, unless you are calling from inside
-** flush_journal_list
-**
-** IMPORTANT.  This can only be called while there are no journal writers,
-** and the journal is locked.  That means it can only be called from
-** do_journal_end, or by journal_release
-*/
+/*
+ * flush a journal list, both commit and real blocks
+ *
+ * always set flushall to 1, unless you are calling from inside
+ * flush_journal_list
+ *
+ * IMPORTANT.  This can only be called while there are no journal writers,
+ * and the journal is locked.  That means it can only be called from
+ * do_journal_end, or by journal_release
+ */
 static int flush_journal_list(struct super_block *s,
 			      struct reiserfs_journal_list *jl, int flushall)
 {
@@ -1352,8 +1386,9 @@ static int flush_journal_list(struct super_block *s,
 		goto flush_older_and_return;
 	}
 
-	/* start by putting the commit list on disk.  This will also flush
-	 ** the commit lists of any olders transactions
+	/*
+	 * start by putting the commit list on disk.  This will also flush
+	 * the commit lists of any olders transactions
 	 */
 	flush_commit_list(s, jl, 1);
 
@@ -1367,8 +1402,9 @@ static int flush_journal_list(struct super_block *s,
 		goto flush_older_and_return;
 	}
 
-	/* loop through each cnode, see if we need to write it,
-	 ** or wait on a more recent transaction, or just ignore it
+	/*
+	 * loop through each cnode, see if we need to write it,
+	 * or wait on a more recent transaction, or just ignore it
 	 */
 	if (atomic_read(&(journal->j_wcount)) != 0) {
 		reiserfs_panic(s, "journal-844", "journal list is flushing, "
@@ -1384,20 +1420,25 @@ static int flush_journal_list(struct super_block *s,
 			goto free_cnode;
 		}
 
-		/* This transaction failed commit. Don't write out to the disk */
+		/*
+		 * This transaction failed commit.
+		 * Don't write out to the disk
+		 */
 		if (!(jl->j_state & LIST_DIRTY))
 			goto free_cnode;
 
 		pjl = find_newer_jl_for_cn(cn);
-		/* the order is important here.  We check pjl to make sure we
-		 ** don't clear BH_JDirty_wait if we aren't the one writing this
-		 ** block to disk
+		/*
+		 * the order is important here.  We check pjl to make sure we
+		 * don't clear BH_JDirty_wait if we aren't the one writing this
+		 * block to disk
 		 */
 		if (!pjl && cn->bh) {
 			saved_bh = cn->bh;
 
-			/* we do this to make sure nobody releases the buffer while
-			 ** we are working with it
+			/*
+			 * we do this to make sure nobody releases the
+			 * buffer while we are working with it
 			 */
 			get_bh(saved_bh);
 
@@ -1406,13 +1447,17 @@ static int flush_journal_list(struct super_block *s,
 				was_jwait = 1;
 				was_dirty = 1;
 			} else if (can_dirty(cn)) {
-				/* everything with !pjl && jwait should be writable */
+				/*
+				 * everything with !pjl && jwait
+				 * should be writable
+				 */
 				BUG();
 			}
 		}
 
-		/* if someone has this block in a newer transaction, just make
-		 ** sure they are committed, and don't try writing it to disk
+		/*
+		 * if someone has this block in a newer transaction, just make
+		 * sure they are committed, and don't try writing it to disk
 		 */
 		if (pjl) {
 			if (atomic_read(&pjl->j_commit_left))
@@ -1420,16 +1465,18 @@ static int flush_journal_list(struct super_block *s,
 			goto free_cnode;
 		}
 
-		/* bh == NULL when the block got to disk on its own, OR,
-		 ** the block got freed in a future transaction
+		/*
+		 * bh == NULL when the block got to disk on its own, OR,
+		 * the block got freed in a future transaction
 		 */
 		if (saved_bh == NULL) {
 			goto free_cnode;
 		}
 
-		/* this should never happen.  kupdate_one_transaction has this list
-		 ** locked while it works, so we should never see a buffer here that
-		 ** is not marked JDirty_wait
+		/*
+		 * this should never happen.  kupdate_one_transaction has
+		 * this list locked while it works, so we should never see a
+		 * buffer here that is not marked JDirty_wait
 		 */
 		if ((!was_jwait) && !buffer_locked(saved_bh)) {
 			reiserfs_warning(s, "journal-813",
@@ -1440,7 +1487,10 @@ static int flush_journal_list(struct super_block *s,
 					 was_jwait ? ' ' : '!');
 		}
 		if (was_dirty) {
-			/* we inc again because saved_bh gets decremented at free_cnode */
+			/*
+			 * we inc again because saved_bh gets decremented
+			 * at free_cnode
+			 */
 			get_bh(saved_bh);
 			set_bit(BLOCK_NEEDS_FLUSH, &cn->state);
 			lock_buffer(saved_bh);
@@ -1460,7 +1510,10 @@ static int flush_journal_list(struct super_block *s,
 		last = cn;
 		cn = cn->next;
 		if (saved_bh) {
-			/* we incremented this to keep others from taking the buffer head away */
+			/*
+			 * we incremented this to keep others from
+			 * taking the buffer head away
+			 */
 			put_bh(saved_bh);
 			if (atomic_read(&(saved_bh->b_count)) < 0) {
 				reiserfs_warning(s, "journal-945",
@@ -1492,8 +1545,10 @@ static int flush_journal_list(struct super_block *s,
 #endif
 					err = -EIO;
 				}
-				/* note, we must clear the JDirty_wait bit after the up to date
-				 ** check, otherwise we race against our flushpage routine
+				/*
+				 * note, we must clear the JDirty_wait bit
+				 * after the up to date check, otherwise we
+				 * race against our flushpage routine
 				 */
 				BUG_ON(!test_clear_buffer_journal_dirty
 				       (cn->bh));
@@ -1513,23 +1568,25 @@ static int flush_journal_list(struct super_block *s,
 			       __func__);
       flush_older_and_return:
 
-	/* before we can update the journal header block, we _must_ flush all
-	 ** real blocks from all older transactions to disk.  This is because
-	 ** once the header block is updated, this transaction will not be
-	 ** replayed after a crash
+	/*
+	 * before we can update the journal header block, we _must_ flush all
+	 * real blocks from all older transactions to disk.  This is because
+	 * once the header block is updated, this transaction will not be
+	 * replayed after a crash
 	 */
 	if (flushall) {
 		flush_older_journal_lists(s, jl);
 	}
 
 	err = journal->j_errno;
-	/* before we can remove everything from the hash tables for this
-	 ** transaction, we must make sure it can never be replayed
-	 **
-	 ** since we are only called from do_journal_end, we know for sure there
-	 ** are no allocations going on while we are flushing journal lists.  So,
-	 ** we only need to update the journal header block for the last list
-	 ** being flushed
+	/*
+	 * before we can remove everything from the hash tables for this
+	 * transaction, we must make sure it can never be replayed
+	 *
+	 * since we are only called from do_journal_end, we know for sure there
+	 * are no allocations going on while we are flushing journal lists.  So,
+	 * we only need to update the journal header block for the last list
+	 * being flushed
 	 */
 	if (!err && flushall) {
 		err =
@@ -1554,7 +1611,8 @@ static int flush_journal_list(struct super_block *s,
 	}
 	journal->j_last_flush_id = jl->j_trans_id;
 
-	/* not strictly required since we are freeing the list, but it should
+	/*
+	 * not strictly required since we are freeing the list, but it should
 	 * help find code using dead lists later on
 	 */
 	jl->j_len = 0;
@@ -1585,15 +1643,17 @@ static int write_one_transaction(struct super_block *s,
 
 	cn = jl->j_realblock;
 	while (cn) {
-		/* if the blocknr == 0, this has been cleared from the hash,
-		 ** skip it
+		/*
+		 * if the blocknr == 0, this has been cleared from the hash,
+		 * skip it
 		 */
 		if (cn->blocknr == 0) {
 			goto next;
 		}
 		if (cn->bh && can_dirty(cn) && buffer_dirty(cn->bh)) {
 			struct buffer_head *tmp_bh;
-			/* we can race against journal_mark_freed when we try
+			/*
+			 * we can race against journal_mark_freed when we try
 			 * to lock_buffer(cn->bh), so we have to inc the buffer
 			 * count, and recheck things after locking
 			 */
@@ -1630,15 +1690,17 @@ static int dirty_one_transaction(struct super_block *s,
 	jl->j_state |= LIST_DIRTY;
 	cn = jl->j_realblock;
 	while (cn) {
-		/* look for a more recent transaction that logged this
-		 ** buffer.  Only the most recent transaction with a buffer in
-		 ** it is allowed to send that buffer to disk
+		/*
+		 * look for a more recent transaction that logged this
+		 * buffer.  Only the most recent transaction with a buffer in
+		 * it is allowed to send that buffer to disk
 		 */
 		pjl = find_newer_jl_for_cn(cn);
 		if (!pjl && cn->blocknr && cn->bh
 		    && buffer_journal_dirty(cn->bh)) {
 			BUG_ON(!can_dirty(cn));
-			/* if the buffer is prepared, it will either be logged
+			/*
+			 * if the buffer is prepared, it will either be logged
 			 * or restored.  If restored, we need to make sure
 			 * it actually gets marked dirty
 			 */
@@ -1675,7 +1737,8 @@ static int kupdate_transactions(struct super_block *s,
 		goto done;
 	}
 
-	/* we've got j_flush_mutex held, nobody is going to delete any
+	/*
+	 * we've got j_flush_mutex held, nobody is going to delete any
 	 * of these lists out from underneath us
 	 */
 	while ((num_trans && transactions_flushed < num_trans) ||
@@ -1714,15 +1777,16 @@ static int kupdate_transactions(struct super_block *s,
 	return ret;
 }
 
-/* for o_sync and fsync heavy applications, they tend to use
-** all the journa list slots with tiny transactions.  These
-** trigger lots and lots of calls to update the header block, which
-** adds seeks and slows things down.
-**
-** This function tries to clear out a large chunk of the journal lists
-** at once, which makes everything faster since only the newest journal
-** list updates the header block
-*/
+/*
+ * for o_sync and fsync heavy applications, they tend to use
+ * all the journa list slots with tiny transactions.  These
+ * trigger lots and lots of calls to update the header block, which
+ * adds seeks and slows things down.
+ *
+ * This function tries to clear out a large chunk of the journal lists
+ * at once, which makes everything faster since only the newest journal
+ * list updates the header block
+ */
 static int flush_used_journal_lists(struct super_block *s,
 				    struct reiserfs_journal_list *jl)
 {
@@ -1759,9 +1823,11 @@ static int flush_used_journal_lists(struct super_block *s,
 	}
 	get_journal_list(jl);
 	get_journal_list(flush_jl);
-	/* try to find a group of blocks we can flush across all the
-	 ** transactions, but only bother if we've actually spanned
-	 ** across multiple lists
+
+	/*
+	 * try to find a group of blocks we can flush across all the
+	 * transactions, but only bother if we've actually spanned
+	 * across multiple lists
 	 */
 	if (flush_jl != jl) {
 		ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
@@ -1773,9 +1839,9 @@ static int flush_used_journal_lists(struct super_block *s,
 }
 
 /*
-** removes any nodes in table with name block and dev as bh.
-** only touchs the hnext and hprev pointers.
-*/
+ * removes any nodes in table with name block and dev as bh.
+ * only touchs the hnext and hprev pointers.
+ */
 void remove_journal_hash(struct super_block *sb,
 			 struct reiserfs_journal_cnode **table,
 			 struct reiserfs_journal_list *jl,
@@ -1804,7 +1870,11 @@ void remove_journal_hash(struct super_block *sb,
 			cur->blocknr = 0;
 			cur->sb = NULL;
 			cur->state = 0;
-			if (cur->bh && cur->jlist)	/* anybody who clears the cur->bh will also dec the nonzerolen */
+			/*
+			 * anybody who clears the cur->bh will also
+			 * dec the nonzerolen
+			 */
+			if (cur->bh && cur->jlist)
 				atomic_dec(&(cur->jlist->j_nonzerolen));
 			cur->bh = NULL;
 			cur->jlist = NULL;
@@ -1825,17 +1895,18 @@ static void free_journal_ram(struct super_block *sb)
 	if (journal->j_header_bh) {
 		brelse(journal->j_header_bh);
 	}
-	/* j_header_bh is on the journal dev, make sure not to release the journal
-	 * dev until we brelse j_header_bh
+	/*
+	 * j_header_bh is on the journal dev, make sure
+	 * not to release the journal dev until we brelse j_header_bh
 	 */
 	release_journal_dev(sb, journal);
 	vfree(journal);
 }
 
 /*
-** call on unmount.  Only set error to 1 if you haven't made your way out
-** of read_super() yet.  Any other caller must keep error at 0.
-*/
+ * call on unmount.  Only set error to 1 if you haven't made your way out
+ * of read_super() yet.  Any other caller must keep error at 0.
+ */
 static int do_journal_release(struct reiserfs_transaction_handle *th,
 			      struct super_block *sb, int error)
 {
@@ -1843,14 +1914,19 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	int flushed = 0;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
-	/* we only want to flush out transactions if we were called with error == 0
+	/*
+	 * we only want to flush out transactions if we were
+	 * called with error == 0
 	 */
 	if (!error && !(sb->s_flags & MS_RDONLY)) {
 		/* end the current trans */
 		BUG_ON(!th->t_trans_id);
 		do_journal_end(th, sb, 10, FLUSH_ALL);
 
-		/* make sure something gets logged to force our way into the flush code */
+		/*
+		 * make sure something gets logged to force
+		 * our way into the flush code
+		 */
 		if (!journal_join(&myth, sb, 1)) {
 			reiserfs_prepare_for_journal(sb,
 						     SB_BUFFER_WITH_SB(sb),
@@ -1894,25 +1970,24 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	return 0;
 }
 
-/*
-** call on unmount.  flush all journal trans, release all alloc'd ram
-*/
+/* * call on unmount.  flush all journal trans, release all alloc'd ram */
 int journal_release(struct reiserfs_transaction_handle *th,
 		    struct super_block *sb)
 {
 	return do_journal_release(th, sb, 0);
 }
 
-/*
-** only call from an error condition inside reiserfs_read_super!
-*/
+/* only call from an error condition inside reiserfs_read_super!  */
 int journal_release_error(struct reiserfs_transaction_handle *th,
 			  struct super_block *sb)
 {
 	return do_journal_release(th, sb, 1);
 }
 
-/* compares description block with commit block.  returns 1 if they differ, 0 if they are the same */
+/*
+ * compares description block with commit block.
+ * returns 1 if they differ, 0 if they are the same
+ */
 static int journal_compare_desc_commit(struct super_block *sb,
 				       struct reiserfs_journal_desc *desc,
 				       struct reiserfs_journal_commit *commit)
@@ -1926,11 +2001,12 @@ static int journal_compare_desc_commit(struct super_block *sb,
 	return 0;
 }
 
-/* returns 0 if it did not find a description block
-** returns -1 if it found a corrupt commit block
-** returns 1 if both desc and commit were valid
-** NOTE: only called during fs mount
-*/
+/*
+ * returns 0 if it did not find a description block
+ * returns -1 if it found a corrupt commit block
+ * returns 1 if both desc and commit were valid
+ * NOTE: only called during fs mount
+ */
 static int journal_transaction_is_valid(struct super_block *sb,
 					struct buffer_head *d_bh,
 					unsigned int *oldest_invalid_trans_id,
@@ -1976,7 +2052,10 @@ static int journal_transaction_is_valid(struct super_block *sb,
 		}
 		offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(sb);
 
-		/* ok, we have a journal description block, lets see if the transaction was valid */
+		/*
+		 * ok, we have a journal description block,
+		 * let's see if the transaction was valid
+		 */
 		c_bh =
 		    journal_bread(sb,
 				  SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
@@ -2028,11 +2107,11 @@ static void brelse_array(struct buffer_head **heads, int num)
 }
 
 /*
-** given the start, and values for the oldest acceptable transactions,
-** this either reads in a replays a transaction, or returns because the
-** transaction is invalid, or too old.
-** NOTE: only called during fs mount
-*/
+ * given the start, and values for the oldest acceptable transactions,
+ * this either reads in a replays a transaction, or returns because the
+ * transaction is invalid, or too old.
+ * NOTE: only called during fs mount
+ */
 static int journal_read_transaction(struct super_block *sb,
 				    unsigned long cur_dblock,
 				    unsigned long oldest_start,
@@ -2106,7 +2185,10 @@ static int journal_read_transaction(struct super_block *sb,
 	}
 
 	trans_id = get_desc_trans_id(desc);
-	/* now we know we've got a good transaction, and it was inside the valid time ranges */
+	/*
+	 * now we know we've got a good transaction, and it was
+	 * inside the valid time ranges
+	 */
 	log_blocks = kmalloc(get_desc_trans_len(desc) *
 			     sizeof(struct buffer_head *), GFP_NOFS);
 	real_blocks = kmalloc(get_desc_trans_len(desc) *
@@ -2213,7 +2295,10 @@ static int journal_read_transaction(struct super_block *sb,
 		       "journal-1095: setting journal " "start to offset %ld",
 		       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(sb));
 
-	/* init starting values for the first transaction, in case this is the last transaction to be replayed. */
+	/*
+	 * init starting values for the first transaction, in case
+	 * this is the last transaction to be replayed.
+	 */
 	journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(sb);
 	journal->j_last_flush_trans_id = trans_id;
 	journal->j_trans_id = trans_id + 1;
@@ -2227,12 +2312,14 @@ static int journal_read_transaction(struct super_block *sb,
 	return 0;
 }
 
-/* This function reads blocks starting from block and to max_block of bufsize
-   size (but no more than BUFNR blocks at a time). This proved to improve
-   mounting speed on self-rebuilding raid5 arrays at least.
-   Right now it is only used from journal code. But later we might use it
-   from other places.
-   Note: Do not use journal_getblk/sb_getblk functions here! */
+/*
+ * This function reads blocks starting from block and to max_block of bufsize
+ * size (but no more than BUFNR blocks at a time). This proved to improve
+ * mounting speed on self-rebuilding raid5 arrays at least.
+ * Right now it is only used from journal code. But later we might use it
+ * from other places.
+ * Note: Do not use journal_getblk/sb_getblk functions here!
+ */
 static struct buffer_head *reiserfs_breada(struct block_device *dev,
 					   b_blocknr_t block, int bufsize,
 					   b_blocknr_t max_block)
@@ -2271,15 +2358,17 @@ static struct buffer_head *reiserfs_breada(struct block_device *dev,
 }
 
 /*
-** read and replay the log
-** on a clean unmount, the journal header's next unflushed pointer will
-** be to an invalid transaction.  This tests that before finding all the
-** transactions in the log, which makes normal mount times fast.
-** After a crash, this starts with the next unflushed transaction, and
-** replays until it finds one too old, or invalid.
-** On exit, it sets things up so the first transaction will work correctly.
-** NOTE: only called during fs mount
-*/
+ * read and replay the log
+ * on a clean unmount, the journal header's next unflushed pointer will be
+ * to an invalid transaction.  This tests that before finding all the
+ * transactions in the log, which makes normal mount times fast.
+ *
+ * After a crash, this starts with the next unflushed transaction, and
+ * replays until it finds one too old, or invalid.
+ *
+ * On exit, it sets things up so the first transaction will work correctly.
+ * NOTE: only called during fs mount
+ */
 static int journal_read(struct super_block *sb)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
@@ -2303,9 +2392,10 @@ static int journal_read(struct super_block *sb)
 		      bdevname(journal->j_dev_bd, b));
 	start = get_seconds();
 
-	/* step 1, read in the journal header block.  Check the transaction it says
-	 ** is the first unflushed, and if that transaction is not valid,
-	 ** replay is done
+	/*
+	 * step 1, read in the journal header block.  Check the transaction
+	 * it says is the first unflushed, and if that transaction is not
+	 * valid, replay is done
 	 */
 	journal->j_header_bh = journal_bread(sb,
 					     SB_ONDISK_JOURNAL_1st_BLOCK(sb)
@@ -2329,9 +2419,10 @@ static int journal_read(struct super_block *sb)
 			       le32_to_cpu(jh->j_last_flush_trans_id));
 		valid_journal_header = 1;
 
-		/* now, we try to read the first unflushed offset.  If it is not valid,
-		 ** there is nothing more we can do, and it makes no sense to read
-		 ** through the whole log.
+		/*
+		 * now, we try to read the first unflushed offset.  If it
+		 * is not valid, there is nothing more we can do, and it
+		 * makes no sense to read through the whole log.
 		 */
 		d_bh =
 		    journal_bread(sb,
@@ -2345,15 +2436,19 @@ static int journal_read(struct super_block *sb)
 		goto start_log_replay;
 	}
 
-	/* ok, there are transactions that need to be replayed.  start with the first log block, find
-	 ** all the valid transactions, and pick out the oldest.
+	/*
+	 * ok, there are transactions that need to be replayed.  start
+	 * with the first log block, find all the valid transactions, and
+	 * pick out the oldest.
 	 */
 	while (continue_replay
 	       && cur_dblock <
 	       (SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 		SB_ONDISK_JOURNAL_SIZE(sb))) {
-		/* Note that it is required for blocksize of primary fs device and journal
-		   device to be the same */
+		/*
+		 * Note that it is required for blocksize of primary fs
+		 * device and journal device to be the same
+		 */
 		d_bh =
 		    reiserfs_breada(journal->j_dev_bd, cur_dblock,
 				    sb->s_blocksize,
@@ -2431,9 +2526,11 @@ static int journal_read(struct super_block *sb)
 		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal-1225: No valid " "transactions found");
 	}
-	/* j_start does not get set correctly if we don't replay any transactions.
-	 ** if we had a valid journal_header, set j_start to the first unflushed transaction value,
-	 ** copy the trans_id from the header
+	/*
+	 * j_start does not get set correctly if we don't replay any
+	 * transactions.  if we had a valid journal_header, set j_start
+	 * to the first unflushed transaction value, copy the trans_id
+	 * from the header
 	 */
 	if (valid_journal_header && replay_count == 0) {
 		journal->j_start = le32_to_cpu(jh->j_first_unflushed_offset);
@@ -2462,8 +2559,9 @@ static int journal_read(struct super_block *sb)
 	    _update_journal_header_block(sb, journal->j_start,
 					 journal->j_last_flush_trans_id)) {
 		reiserfs_write_unlock(sb);
-		/* replay failed, caller must call free_journal_ram and abort
-		 ** the mount
+		/*
+		 * replay failed, caller must call free_journal_ram and abort
+		 * the mount
 		 */
 		return -1;
 	}
@@ -2556,7 +2654,7 @@ static int journal_init_dev(struct super_block *super,
 	return 0;
 }
 
-/**
+/*
  * When creating/tuning a file system user can assign some
  * journal params within boundaries which depend on the ratio
  * blocksize/standard_blocksize.
@@ -2574,8 +2672,7 @@ static int check_advise_trans_params(struct super_block *sb,
 				     struct reiserfs_journal *journal)
 {
         if (journal->j_trans_max) {
-	        /* Non-default journal params.
-		   Do sanity check for them. */
+		/* Non-default journal params.  Do sanity check for them. */
 	        int ratio = 1;
 		if (sb->s_blocksize < REISERFS_STANDARD_BLKSIZE)
 		        ratio = REISERFS_STANDARD_BLKSIZE / sb->s_blocksize;
@@ -2597,10 +2694,12 @@ static int check_advise_trans_params(struct super_block *sb,
 			return 1;
 		}
 	} else {
-		/* Default journal params.
-                   The file system was created by old version
-		   of mkreiserfs, so some fields contain zeros,
-		   and we need to advise proper values for them */
+		/*
+		 * Default journal params.
+		 * The file system was created by old version
+		 * of mkreiserfs, so some fields contain zeros,
+		 * and we need to advise proper values for them
+		 */
 		if (sb->s_blocksize != REISERFS_STANDARD_BLKSIZE) {
 			reiserfs_warning(sb, "sh-464", "bad blocksize (%u)",
 					 sb->s_blocksize);
@@ -2613,9 +2712,7 @@ static int check_advise_trans_params(struct super_block *sb,
 	return 0;
 }
 
-/*
-** must be called once on fs mount.  calls journal_read for you
-*/
+/* must be called once on fs mount.  calls journal_read for you */
 int journal_init(struct super_block *sb, const char *j_dev_name,
 		 int old_format, unsigned int commit_max_age)
 {
@@ -2654,8 +2751,10 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 						 REISERFS_DISK_OFFSET_IN_BYTES /
 						 sb->s_blocksize + 2);
 
-	/* Sanity check to see is the standard journal fitting within first bitmap
-	   (actual for small blocksizes) */
+	/*
+	 * Sanity check to see is the standard journal fitting
+	 * within first bitmap (actual for small blocksizes)
+	 */
 	if (!SB_ONDISK_JOURNAL_DEVICE(sb) &&
 	    (SB_JOURNAL_1st_RESERVED_BLOCK(sb) +
 	     SB_ONDISK_JOURNAL_SIZE(sb) > sb->s_blocksize * 8)) {
@@ -2803,10 +2902,10 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 }
 
 /*
-** test for a polite end of the current transaction.  Used by file_write, and should
-** be used by delete to make sure they don't write more than can fit inside a single
-** transaction
-*/
+ * test for a polite end of the current transaction.  Used by file_write,
+ * and should be used by delete to make sure they don't write more than
+ * can fit inside a single transaction
+ */
 int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 				   int new_alloc)
 {
@@ -2829,8 +2928,7 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 	return 0;
 }
 
-/* this must be called inside a transaction
-*/
+/* this must be called inside a transaction */
 void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(th->t_super);
@@ -2840,8 +2938,7 @@ void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
 	return;
 }
 
-/* this must be called without a transaction started
-*/
+/* this must be called without a transaction started */
 void reiserfs_allow_writes(struct super_block *s)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
@@ -2849,8 +2946,7 @@ void reiserfs_allow_writes(struct super_block *s)
 	wake_up(&journal->j_join_wait);
 }
 
-/* this must be called without a transaction started
-*/
+/* this must be called without a transaction started */
 void reiserfs_wait_on_write_block(struct super_block *s)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
@@ -2912,11 +3008,12 @@ static void let_transaction_grow(struct super_block *sb, unsigned int trans_id)
 	}
 }
 
-/* join == true if you must join an existing transaction.
-** join == false if you can deal with waiting for others to finish
-**
-** this will block until the transaction is joinable.  send the number of blocks you
-** expect to use in nblocks.
+/*
+ * join == true if you must join an existing transaction.
+ * join == false if you can deal with waiting for others to finish
+ *
+ * this will block until the transaction is joinable.  send the number of
+ * blocks you expect to use in nblocks.
 */
 static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 			      struct super_block *sb, unsigned long nblocks,
@@ -2957,9 +3054,11 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	}
 	now = get_seconds();
 
-	/* if there is no room in the journal OR
-	 ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning
-	 ** we don't sleep if there aren't other writers
+	/*
+	 * if there is no room in the journal OR
+	 * if this transaction is too old, and we weren't called joinable,
+	 * wait for it to finish before beginning we don't sleep if there
+	 * aren't other writers
 	 */
 
 	if ((!join && journal->j_must_wait > 0) ||
@@ -2973,7 +3072,8 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	    || (!join && journal->j_cnode_free < (journal->j_trans_max * 3))) {
 
 		old_trans_id = journal->j_trans_id;
-		unlock_journal(sb);	/* allow others to finish this transaction */
+		/* allow others to finish this transaction */
+		unlock_journal(sb);
 
 		if (!join && (journal->j_len_alloc + nblocks + 2) >=
 		    journal->j_max_batch &&
@@ -2985,8 +3085,9 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 				goto relock;
 			}
 		}
-		/* don't mess with joining the transaction if all we have to do is
-		 * wait for someone else to do a commit
+		/*
+		 * don't mess with joining the transaction if all we
+		 * have to do is wait for someone else to do a commit
 		 */
 		if (atomic_read(&journal->j_jlock)) {
 			while (journal->j_trans_id == old_trans_id &&
@@ -3027,9 +3128,11 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 
       out_fail:
 	memset(th, 0, sizeof(*th));
-	/* Re-set th->t_super, so we can properly keep track of how many
+	/*
+	 * Re-set th->t_super, so we can properly keep track of how many
 	 * persistent transactions there are. We need to do this so if this
-	 * call is part of a failed restart_transaction, we can free it later */
+	 * call is part of a failed restart_transaction, we can free it later
+	 */
 	th->t_super = sb;
 	return retval;
 }
@@ -3042,14 +3145,15 @@ struct reiserfs_transaction_handle *reiserfs_persistent_transaction(struct
 	int ret;
 	struct reiserfs_transaction_handle *th;
 
-	/* if we're nesting into an existing transaction.  It will be
-	 ** persistent on its own
+	/*
+	 * if we're nesting into an existing transaction.  It will be
+	 * persistent on its own
 	 */
 	if (reiserfs_transaction_running(s)) {
 		th = current->journal_info;
 		th->t_refcount++;
 		BUG_ON(th->t_refcount < 2);
-		
+
 		return th;
 	}
 	th = kmalloc(sizeof(struct reiserfs_transaction_handle), GFP_NOFS);
@@ -3085,8 +3189,9 @@ static int journal_join(struct reiserfs_transaction_handle *th,
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
-	/* this keeps do_journal_end from NULLing out the current->journal_info
-	 ** pointer
+	/*
+	 * this keeps do_journal_end from NULLing out the
+	 * current->journal_info pointer
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
@@ -3098,8 +3203,9 @@ int journal_join_abort(struct reiserfs_transaction_handle *th,
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
-	/* this keeps do_journal_end from NULLing out the current->journal_info
-	 ** pointer
+	/*
+	 * this keeps do_journal_end from NULLing out the
+	 * current->journal_info pointer
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
@@ -3125,9 +3231,10 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 						 "journal_info != 0");
 			return 0;
 		} else {
-			/* we've ended up with a handle from a different filesystem.
-			 ** save it and restore on journal_end.  This should never
-			 ** really happen...
+			/*
+			 * we've ended up with a handle from a different
+			 * filesystem.  save it and restore on journal_end.
+			 * This should never really happen...
 			 */
 			reiserfs_warning(sb, "clm-2100",
 					 "nesting info a different FS");
@@ -3140,9 +3247,10 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 	ret = do_journal_begin_r(th, sb, nblocks, JBEGIN_REG);
 	BUG_ON(current->journal_info != th);
 
-	/* I guess this boils down to being the reciprocal of clm-2100 above.
-	 * If do_journal_begin_r fails, we need to put it back, since journal_end
-	 * won't be called to do it. */
+	/*
+	 * I guess this boils down to being the reciprocal of clm-2100 above.
+	 * If do_journal_begin_r fails, we need to put it back, since
+	 * journal_end won't be called to do it. */
 	if (ret)
 		current->journal_info = th->t_handle_save;
 	else
@@ -3152,14 +3260,15 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 }
 
 /*
-** puts bh into the current transaction.  If it was already there, reorders removes the
-** old pointers from the hash, and puts new ones in (to make sure replay happen in the right order).
-**
-** if it was dirty, cleans and files onto the clean list.  I can't let it be dirty again until the
-** transaction is committed.
-**
-** if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
-*/
+ * puts bh into the current transaction.  If it was already there, reorders
+ * removes the old pointers from the hash, and puts new ones in (to make
+ * sure replay happen in the right order).
+ *
+ * if it was dirty, cleans and files onto the clean list.  I can't let it
+ * be dirty again until the transaction is committed.
+ *
+ * if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
+ */
 int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 		       struct super_block *sb, struct buffer_head *bh)
 {
@@ -3184,9 +3293,10 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 		return 0;
 	}
 
-	/* this must be turned into a panic instead of a warning.  We can't allow
-	 ** a dirty or journal_dirty or locked buffer to be logged, as some changes
-	 ** could get to disk too early.  NOT GOOD.
+	/*
+	 * this must be turned into a panic instead of a warning.  We can't
+	 * allow a dirty or journal_dirty or locked buffer to be logged, as
+	 * some changes could get to disk too early.  NOT GOOD.
 	 */
 	if (!prepared || buffer_dirty(bh)) {
 		reiserfs_warning(sb, "journal-1777",
@@ -3205,8 +3315,10 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 				 atomic_read(&(journal->j_wcount)));
 		return 1;
 	}
-	/* this error means I've screwed up, and we've overflowed the transaction.
-	 ** Nothing can be done here, except make the FS readonly or panic.
+	/*
+	 * this error means I've screwed up, and we've overflowed
+	 * the transaction.  Nothing can be done here, except make the
+	 * FS readonly or panic.
 	 */
 	if (journal->j_len >= journal->j_trans_max) {
 		reiserfs_panic(th->t_super, "journal-1413",
@@ -3280,8 +3392,9 @@ int journal_end(struct reiserfs_transaction_handle *th,
 		struct reiserfs_transaction_handle *cur_th =
 		    current->journal_info;
 
-		/* we aren't allowed to close a nested transaction on a different
-		 ** filesystem from the one in the task struct
+		/*
+		 * we aren't allowed to close a nested transaction on a
+		 * different filesystem from the one in the task struct
 		 */
 		BUG_ON(cur_th->t_super != th->t_super);
 
@@ -3295,13 +3408,14 @@ int journal_end(struct reiserfs_transaction_handle *th,
 	}
 }
 
-/* removes from the current transaction, relsing and descrementing any counters.
-** also files the removed buffer directly onto the clean list
-**
-** called by journal_mark_freed when a block has been deleted
-**
-** returns 1 if it cleaned and relsed the buffer. 0 otherwise
-*/
+/*
+ * removes from the current transaction, relsing and descrementing any counters.
+ * also files the removed buffer directly onto the clean list
+ *
+ * called by journal_mark_freed when a block has been deleted
+ *
+ * returns 1 if it cleaned and relsed the buffer. 0 otherwise
+ */
 static int remove_from_transaction(struct super_block *sb,
 				   b_blocknr_t blocknr, int already_cleaned)
 {
@@ -3350,15 +3464,16 @@ static int remove_from_transaction(struct super_block *sb,
 }
 
 /*
-** for any cnode in a journal list, it can only be dirtied of all the
-** transactions that include it are committed to disk.
-** this checks through each transaction, and returns 1 if you are allowed to dirty,
-** and 0 if you aren't
-**
-** it is called by dirty_journal_list, which is called after flush_commit_list has gotten all the log
-** blocks for a given transaction on disk
-**
-*/
+ * for any cnode in a journal list, it can only be dirtied of all the
+ * transactions that include it are committed to disk.
+ * this checks through each transaction, and returns 1 if you are allowed
+ * to dirty, and 0 if you aren't
+ *
+ * it is called by dirty_journal_list, which is called after
+ * flush_commit_list has gotten all the log blocks for a given
+ * transaction on disk
+ *
+ */
 static int can_dirty(struct reiserfs_journal_cnode *cn)
 {
 	struct super_block *sb = cn->sb;
@@ -3366,9 +3481,10 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 	struct reiserfs_journal_cnode *cur = cn->hprev;
 	int can_dirty = 1;
 
-	/* first test hprev.  These are all newer than cn, so any node here
-	 ** with the same block number and dev means this node can't be sent
-	 ** to disk right now.
+	/*
+	 * first test hprev.  These are all newer than cn, so any node here
+	 * with the same block number and dev means this node can't be sent
+	 * to disk right now.
 	 */
 	while (cur && can_dirty) {
 		if (cur->jlist && cur->bh && cur->blocknr && cur->sb == sb &&
@@ -3377,8 +3493,9 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 		}
 		cur = cur->hprev;
 	}
-	/* then test hnext.  These are all older than cn.  As long as they
-	 ** are committed to the log, it is safe to write cn to disk
+	/*
+	 * then test hnext.  These are all older than cn.  As long as they
+	 * are committed to the log, it is safe to write cn to disk
 	 */
 	cur = cn->hnext;
 	while (cur && can_dirty) {
@@ -3392,9 +3509,10 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 	return can_dirty;
 }
 
-/* syncs the commit blocks, but does not force the real buffers to disk
-** will wait until the current transaction is done/committed before returning
-*/
+/*
+ * syncs the commit blocks, but does not force the real buffers to disk
+ * will wait until the current transaction is done/committed before returning
+ */
 int journal_end_sync(struct reiserfs_transaction_handle *th,
 		     struct super_block *sb, unsigned long nblocks)
 {
@@ -3411,9 +3529,7 @@ int journal_end_sync(struct reiserfs_transaction_handle *th,
 	return do_journal_end(th, sb, nblocks, COMMIT_NOW | WAIT);
 }
 
-/*
-** writeback the pending async commits to disk
-*/
+/* writeback the pending async commits to disk */
 static void flush_async_commits(struct work_struct *work)
 {
 	struct reiserfs_journal *journal =
@@ -3433,9 +3549,9 @@ static void flush_async_commits(struct work_struct *work)
 }
 
 /*
-** flushes any old transactions to disk
-** ends the current transaction if it is too old
-*/
+ * flushes any old transactions to disk
+ * ends the current transaction if it is too old
+ */
 void reiserfs_flush_old_commits(struct super_block *sb)
 {
 	time_t now;
@@ -3443,13 +3559,15 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	now = get_seconds();
-	/* safety check so we don't flush while we are replaying the log during
+	/*
+	 * safety check so we don't flush while we are replaying the log during
 	 * mount
 	 */
 	if (list_empty(&journal->j_journal_list))
 		return;
 
-	/* check the current transaction.  If there are no writers, and it is
+	/*
+	 * check the current transaction.  If there are no writers, and it is
 	 * too old, finish it, and force the commit blocks to disk
 	 */
 	if (atomic_read(&journal->j_wcount) <= 0 &&
@@ -3463,8 +3581,10 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 			journal_mark_dirty(&th, sb,
 					   SB_BUFFER_WITH_SB(sb));
 
-			/* we're only being called from kreiserfsd, it makes no sense to do
-			 ** an async commit so that kreiserfsd can do it later
+			/*
+			 * we're only being called from kreiserfsd, it makes
+			 * no sense to do an async commit so that kreiserfsd
+			 * can do it later
 			 */
 			do_journal_end(&th, sb, 1, COMMIT_NOW | WAIT);
 		}
@@ -3472,16 +3592,20 @@ void reiserfs_flush_old_commits(struct super_block *sb)
 }
 
 /*
-** returns 0 if do_journal_end should return right away, returns 1 if do_journal_end should finish the commit
-**
-** if the current transaction is too old, but still has writers, this will wait on j_join_wait until all
-** the writers are done.  By the time it wakes up, the transaction it was called has already ended, so it just
-** flushes the commit list and returns 0.
-**
-** Won't batch when flush or commit_now is set.  Also won't batch when others are waiting on j_join_wait.
-**
-** Note, we can't allow the journal_end to proceed while there are still writers in the log.
-*/
+ * returns 0 if do_journal_end should return right away, returns 1 if
+ * do_journal_end should finish the commit
+ *
+ * if the current transaction is too old, but still has writers, this will
+ * wait on j_join_wait until all the writers are done.  By the time it
+ * wakes up, the transaction it was called has already ended, so it just
+ * flushes the commit list and returns 0.
+ *
+ * Won't batch when flush or commit_now is set.  Also won't batch when
+ * others are waiting on j_join_wait.
+ *
+ * Note, we can't allow the journal_end to proceed while there are still
+ * writers in the log.
+ */
 static int check_journal_end(struct reiserfs_transaction_handle *th,
 			     struct super_block *sb, unsigned long nblocks,
 			     int flags)
@@ -3503,21 +3627,25 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	}
 
 	journal->j_len_alloc -= (th->t_blocks_allocated - th->t_blocks_logged);
-	if (atomic_read(&(journal->j_wcount)) > 0) {	/* <= 0 is allowed.  unmounting might not call begin */
+	/* <= 0 is allowed.  unmounting might not call begin */
+	if (atomic_read(&(journal->j_wcount)) > 0)
 		atomic_dec(&(journal->j_wcount));
-	}
 
-	/* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released
-	 ** will be dealt with by next transaction that actually writes something, but should be taken
-	 ** care of in this trans
+	/*
+	 * BUG, deal with case where j_len is 0, but people previously
+	 * freed blocks need to be released will be dealt with by next
+	 * transaction that actually writes something, but should be taken
+	 * care of in this trans
 	 */
 	BUG_ON(journal->j_len == 0);
 
-	/* if wcount > 0, and we are called to with flush or commit_now,
-	 ** we wait on j_join_wait.  We will wake up when the last writer has
-	 ** finished the transaction, and started it on its way to the disk.
-	 ** Then, we flush the commit or journal list, and just return 0
-	 ** because the rest of journal end was already done for this transaction.
+	/*
+	 * if wcount > 0, and we are called to with flush or commit_now,
+	 * we wait on j_join_wait.  We will wake up when the last writer has
+	 * finished the transaction, and started it on its way to the disk.
+	 * Then, we flush the commit or journal list, and just return 0
+	 * because the rest of journal end was already done for this
+	 * transaction.
 	 */
 	if (atomic_read(&(journal->j_wcount)) > 0) {
 		if (flush || commit_now) {
@@ -3533,7 +3661,10 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 			}
 			unlock_journal(sb);
 
-			/* sleep while the current transaction is still j_jlocked */
+			/*
+			 * sleep while the current transaction is
+			 * still j_jlocked
+			 */
 			while (journal->j_trans_id == trans_id) {
 				if (atomic_read(&journal->j_jlock)) {
 					queue_log_writer(sb);
@@ -3547,7 +3678,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 				}
 			}
 			BUG_ON(journal->j_trans_id == trans_id);
-			
+
 			if (commit_now
 			    && journal_list_still_alive(sb, trans_id)
 			    && wait_on_commit) {
@@ -3585,19 +3716,22 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 }
 
 /*
-** Does all the work that makes deleting blocks safe.
-** when deleting a block mark BH_JNew, just remove it from the current transaction, clean it's buffer_head and move on.
-**
-** otherwise:
-** set a bit for the block in the journal bitmap.  That will prevent it from being allocated for unformatted nodes
-** before this transaction has finished.
-**
-** mark any cnodes for this block as BLOCK_FREED, and clear their bh pointers.  That will prevent any old transactions with
-** this block from trying to flush to the real location.  Since we aren't removing the cnode from the journal_list_hash,
-** the block can't be reallocated yet.
-**
-** Then remove it from the current transaction, decrementing any counters and filing it on the clean list.
-*/
+ * Does all the work that makes deleting blocks safe.
+ * when deleting a block mark BH_JNew, just remove it from the current
+ * transaction, clean it's buffer_head and move on.
+ *
+ * otherwise:
+ * set a bit for the block in the journal bitmap.  That will prevent it from
+ * being allocated for unformatted nodes before this transaction has finished.
+ *
+ * mark any cnodes for this block as BLOCK_FREED, and clear their bh pointers.
+ * That will prevent any old transactions with this block from trying to flush
+ * to the real location.  Since we aren't removing the cnode from the
+ * journal_list_hash, *the block can't be reallocated yet.
+ *
+ * Then remove it from the current transaction, decrementing any counters and
+ * filing it on the clean list.
+ */
 int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		       struct super_block *sb, b_blocknr_t blocknr)
 {
@@ -3620,7 +3754,10 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		reiserfs_clean_and_file_buffer(bh);
 		cleaned = remove_from_transaction(sb, blocknr, cleaned);
 	} else {
-		/* set the bit for this block in the journal bitmap for this transaction */
+		/*
+		 * set the bit for this block in the journal bitmap
+		 * for this transaction
+		 */
 		jb = journal->j_current_jl->j_list_bitmap;
 		if (!jb) {
 			reiserfs_panic(sb, "journal-1702",
@@ -3636,17 +3773,22 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		}
 		cleaned = remove_from_transaction(sb, blocknr, cleaned);
 
-		/* find all older transactions with this block, make sure they don't try to write it out */
+		/*
+		 * find all older transactions with this block,
+		 * make sure they don't try to write it out
+		 */
 		cn = get_journal_hash_dev(sb, journal->j_list_hash_table,
 					  blocknr);
 		while (cn) {
 			if (sb == cn->sb && blocknr == cn->blocknr) {
 				set_bit(BLOCK_FREED, &cn->state);
 				if (cn->bh) {
+					/*
+					 * remove_from_transaction will brelse
+					 * the buffer if it was in the current
+					 * trans
+					 */
 					if (!cleaned) {
-						/* remove_from_transaction will brelse the buffer if it was 
-						 ** in the current trans
-						 */
 						clear_buffer_journal_dirty(cn->
 									   bh);
 						clear_buffer_dirty(cn->bh);
@@ -3661,7 +3803,11 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 								 "cn->bh->b_count < 0");
 						}
 					}
-					if (cn->jlist) {	/* since we are clearing the bh, we MUST dec nonzerolen */
+					/*
+					 * since we are clearing the bh,
+					 * we MUST dec nonzerolen
+					 */
+					if (cn->jlist) {
 						atomic_dec(&
 							   (cn->jlist->
 							    j_nonzerolen));
@@ -3697,10 +3843,16 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	int ret = 0;
 
-	/* is it from the current transaction, or from an unknown transaction? */
+	/*
+	 * is it from the current transaction,
+	 * or from an unknown transaction?
+	 */
 	if (id == journal->j_trans_id) {
 		jl = journal->j_current_jl;
-		/* try to let other writers come in and grow this transaction */
+		/*
+		 * try to let other writers come in and
+		 * grow this transaction
+		 */
 		let_transaction_grow(sb, id);
 		if (journal->j_trans_id != id) {
 			goto flush_commit_only;
@@ -3724,7 +3876,8 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 			ret = 1;
 
 	} else {
-		/* this gets tricky, we have to make sure the journal list in
+		/*
+		 * this gets tricky, we have to make sure the journal list in
 		 * the inode still exists.  We know the list is still around
 		 * if we've got a larger transaction id than the oldest list
 		 */
@@ -3751,7 +3904,8 @@ int reiserfs_commit_for_inode(struct inode *inode)
 	unsigned int id = REISERFS_I(inode)->i_trans_id;
 	struct reiserfs_journal_list *jl = REISERFS_I(inode)->i_jl;
 
-	/* for the whole inode, assume unset id means it was
+	/*
+	 * for the whole inode, assume unset id means it was
 	 * changed in the current transaction.  More conservative
 	 */
 	if (!id || !jl) {
@@ -3789,12 +3943,11 @@ void reiserfs_restore_prepared_buffer(struct super_block *sb,
 
 extern struct tree_balance *cur_tb;
 /*
-** before we can change a metadata block, we have to make sure it won't
-** be written to disk while we are altering it.  So, we must:
-** clean it
-** wait on it.
-**
-*/
+ * before we can change a metadata block, we have to make sure it won't
+ * be written to disk while we are altering it.  So, we must:
+ * clean it
+ * wait on it.
+ */
 int reiserfs_prepare_for_journal(struct super_block *sb,
 				 struct buffer_head *bh, int wait)
 {
@@ -3815,15 +3968,15 @@ int reiserfs_prepare_for_journal(struct super_block *sb,
 }
 
 /*
-** long and ugly.  If flush, will not return until all commit
-** blocks and all real buffers in the trans are on disk.
-** If no_async, won't return until all commit blocks are on disk.
-**
-** keep reading, there are comments as you go along
-**
-** If the journal is aborted, we just clean up. Things like flushing
-** journal lists, etc just won't happen.
-*/
+ * long and ugly.  If flush, will not return until all commit
+ * blocks and all real buffers in the trans are on disk.
+ * If no_async, won't return until all commit blocks are on disk.
+ *
+ * keep reading, there are comments as you go along
+ *
+ * If the journal is aborted, we just clean up. Things like flushing
+ * journal lists, etc just won't happen.
+ */
 static int do_journal_end(struct reiserfs_transaction_handle *th,
 			  struct super_block *sb, unsigned long nblocks,
 			  int flags)
@@ -3850,8 +4003,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	BUG_ON(th->t_refcount > 1);
 	BUG_ON(!th->t_trans_id);
 
-	/* protect flush_older_commits from doing mistakes if the
-           transaction ID counter gets overflowed.  */
+	/*
+	 * protect flush_older_commits from doing mistakes if the
+	 * transaction ID counter gets overflowed.
+	 */
 	if (th->t_trans_id == ~0U)
 		flags |= FLUSH_ALL | COMMIT_NOW | WAIT;
 	flush = flags & FLUSH_ALL;
@@ -3875,8 +4030,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		wait_on_commit = 1;
 	}
 
-	/* check_journal_end locks the journal, and unlocks if it does not return 1
-	 ** it tells us if we should continue with the journal_end, or just return
+	/*
+	 * check_journal_end locks the journal, and unlocks if it does
+	 * not return 1 it tells us if we should continue with the
+	 * journal_end, or just return
 	 */
 	if (!check_journal_end(th, sb, nblocks, flags)) {
 		reiserfs_schedule_old_flush(sb);
@@ -3891,19 +4048,23 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	}
 
 	/*
-	 ** j must wait means we have to flush the log blocks, and the real blocks for
-	 ** this transaction
+	 * j must wait means we have to flush the log blocks, and the
+	 * real blocks for this transaction
 	 */
 	if (journal->j_must_wait > 0) {
 		flush = 1;
 	}
 #ifdef REISERFS_PREALLOCATE
-	/* quota ops might need to nest, setup the journal_info pointer for them
-	 * and raise the refcount so that it is > 0. */
+	/*
+	 * quota ops might need to nest, setup the journal_info pointer
+	 * for them and raise the refcount so that it is > 0.
+	 */
 	current->journal_info = th;
 	th->t_refcount++;
-	reiserfs_discard_all_prealloc(th);	/* it should not involve new blocks into
-						 * the transaction */
+
+	/* it should not involve new blocks into the transaction */
+	reiserfs_discard_all_prealloc(th);
+
 	th->t_refcount--;
 	current->journal_info = th->t_handle_save;
 #endif
@@ -3919,7 +4080,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	memcpy(get_journal_desc_magic(d_bh), JOURNAL_DESC_MAGIC, 8);
 	set_desc_trans_id(desc, journal->j_trans_id);
 
-	/* setup commit block.  Don't write (keep it clean too) this one until after everyone else is written */
+	/*
+	 * setup commit block.  Don't write (keep it clean too) this one
+	 * until after everyone else is written
+	 */
 	c_bh = journal_getblk(sb, SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 			      ((journal->j_start + journal->j_len +
 				1) % SB_ONDISK_JOURNAL_SIZE(sb)));
@@ -3931,7 +4095,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	/* init this journal list */
 	jl = journal->j_current_jl;
 
-	/* we lock the commit before doing anything because
+	/*
+	 * we lock the commit before doing anything because
 	 * we want to make sure nobody tries to run flush_commit_list until
 	 * the new transaction is fully setup, and we've already flushed the
 	 * ordered bh list
@@ -3951,9 +4116,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	atomic_set(&jl->j_commit_left, journal->j_len + 2);
 	jl->j_realblock = NULL;
 
-	/* The ENTIRE FOR LOOP MUST not cause schedule to occur.
-	 **  for each real block, add it to the journal list hash,
-	 ** copy into real block index array in the commit or desc block
+	/*
+	 * The ENTIRE FOR LOOP MUST not cause schedule to occur.
+	 * for each real block, add it to the journal list hash,
+	 * copy into real block index array in the commit or desc block
 	 */
 	trans_half = journal_trans_half(sb->s_blocksize);
 	for (i = 0, cn = journal->j_first; cn; cn = cn->next, i++) {
@@ -3972,9 +4138,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 				last_cn->next = jl_cn;
 			}
 			last_cn = jl_cn;
-			/* make sure the block we are trying to log is not a block
-			   of journal or reserved area */
-
+			/*
+			 * make sure the block we are trying to log
+			 * is not a block of journal or reserved area
+			 */
 			if (is_block_in_log_or_reserved_area
 			    (sb, cn->bh->b_blocknr)) {
 				reiserfs_panic(sb, "journal-2332",
@@ -4004,19 +4171,26 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	set_desc_trans_id(desc, journal->j_trans_id);
 	set_commit_trans_len(commit, journal->j_len);
 
-	/* special check in case all buffers in the journal were marked for not logging */
+	/*
+	 * special check in case all buffers in the journal
+	 * were marked for not logging
+	 */
 	BUG_ON(journal->j_len == 0);
 
-	/* we're about to dirty all the log blocks, mark the description block
+	/*
+	 * we're about to dirty all the log blocks, mark the description block
 	 * dirty now too.  Don't mark the commit block dirty until all the
 	 * others are on disk
 	 */
 	mark_buffer_dirty(d_bh);
 
-	/* first data block is j_start + 1, so add one to cur_write_start wherever you use it */
+	/*
+	 * first data block is j_start + 1, so add one to
+	 * cur_write_start wherever you use it
+	 */
 	cur_write_start = journal->j_start;
 	cn = journal->j_first;
-	jindex = 1;		/* start at one so we don't get the desc again */
+	jindex = 1;	/* start at one so we don't get the desc again */
 	while (cn) {
 		clear_buffer_journal_new(cn->bh);
 		/* copy all the real blocks into log area.  dirty log blocks */
@@ -4042,7 +4216,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			set_buffer_journal_dirty(cn->bh);
 			clear_buffer_journaled(cn->bh);
 		} else {
-			/* JDirty cleared sometime during transaction.  don't log this one */
+			/*
+			 * JDirty cleared sometime during transaction.
+			 * don't log this one
+			 */
 			reiserfs_warning(sb, "journal-2048",
 					 "BAD, buffer in journal hash, "
 					 "but not JDirty!");
@@ -4054,9 +4231,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		reiserfs_cond_resched(sb);
 	}
 
-	/* we are done  with both the c_bh and d_bh, but
-	 ** c_bh must be written after all other commit blocks,
-	 ** so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
+	/*
+	 * we are done with both the c_bh and d_bh, but
+	 * c_bh must be written after all other commit blocks,
+	 * so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
 	 */
 
 	journal->j_current_jl = alloc_journal_list(sb);
@@ -4087,15 +4265,18 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	journal->j_next_async_flush = 0;
 	init_journal_hash(sb);
 
-	// make sure reiserfs_add_jh sees the new current_jl before we
-	// write out the tails
+	/*
+	 * make sure reiserfs_add_jh sees the new current_jl before we
+	 * write out the tails
+	 */
 	smp_mb();
 
-	/* tail conversion targets have to hit the disk before we end the
+	/*
+	 * tail conversion targets have to hit the disk before we end the
 	 * transaction.  Otherwise a later transaction might repack the tail
-	 * before this transaction commits, leaving the data block unflushed and
-	 * clean, if we crash before the later transaction commits, the data block
-	 * is lost.
+	 * before this transaction commits, leaving the data block unflushed
+	 * and clean, if we crash before the later transaction commits, the
+	 * data block is lost.
 	 */
 	if (!list_empty(&jl->j_tail_bh_list)) {
 		depth = reiserfs_write_unlock_nested(sb);
@@ -4106,12 +4287,13 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	BUG_ON(!list_empty(&jl->j_tail_bh_list));
 	mutex_unlock(&jl->j_commit_mutex);
 
-	/* honor the flush wishes from the caller, simple commits can
-	 ** be done outside the journal lock, they are done below
-	 **
-	 ** if we don't flush the commit list right now, we put it into
-	 ** the work queue so the people waiting on the async progress work
-	 ** queue don't wait for this proc to flush journal lists and such.
+	/*
+	 * honor the flush wishes from the caller, simple commits can
+	 * be done outside the journal lock, they are done below
+	 *
+	 * if we don't flush the commit list right now, we put it into
+	 * the work queue so the people waiting on the async progress work
+	 * queue don't wait for this proc to flush journal lists and such.
 	 */
 	if (flush) {
 		flush_commit_list(sb, jl, 1);
@@ -4120,9 +4302,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		queue_delayed_work(REISERFS_SB(sb)->commit_wq,
 				   &journal->j_work, HZ / 10);
 
-	/* if the next transaction has any chance of wrapping, flush
-	 ** transactions that might get overwritten.  If any journal lists are very
-	 ** old flush them as well.
+	/*
+	 * if the next transaction has any chance of wrapping, flush
+	 * transactions that might get overwritten.  If any journal lists
+	 * are very old flush them as well.
 	 */
       first_jl:
 	list_for_each_safe(entry, safe, &journal->j_journal_list) {
@@ -4135,8 +4318,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			} else if ((journal->j_start +
 				    journal->j_trans_max + 1) <
 				   SB_ONDISK_JOURNAL_SIZE(sb)) {
-				/* if we don't cross into the next transaction and we don't
-				 * wrap, there is no way we can overlap any later transactions
+				/*
+				 * if we don't cross into the next
+				 * transaction and we don't wrap, there is
+				 * no way we can overlap any later transactions
 				 * break now
 				 */
 				break;
@@ -4150,10 +4335,12 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 				flush_used_journal_lists(sb, temp_jl);
 				goto first_jl;
 			} else {
-				/* we don't overlap anything from out start to the end of the
-				 * log, and our wrapped portion doesn't overlap anything at
-				 * the start of the log.  We can break
-				 */
+				/*
+				* we don't overlap anything from out start
+				* to the end of the log, and our wrapped
+				* portion doesn't overlap anything at
+				* the start of the log.  We can break
+				*/
 				break;
 			}
 		}
@@ -4181,9 +4368,11 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	reiserfs_check_lock_depth(sb, "journal end2");
 
 	memset(th, 0, sizeof(*th));
-	/* Re-set th->t_super, so we can properly keep track of how many
+	/*
+	 * Re-set th->t_super, so we can properly keep track of how many
 	 * persistent transactions there are. We need to do this so if this
-	 * call is part of a failed restart_transaction, we can free it later */
+	 * call is part of a failed restart_transaction, we can free it later
+	 */
 	th->t_super = sb;
 
 	return journal->j_errno;

commit 797d9016ceca69879bb273218810fa0beef46aac
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Apr 23 10:00:34 2014 -0400

    reiserfs: use per-fs commit workqueues
    
    The reiserfs write lock hasn't been the BKL for some time. There's no
    need to have different file systems queued up on the same workqueue.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index fd777032c2ba..225921126455 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -58,13 +58,6 @@
 #define JOURNAL_WORK_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
                                j_working_list))
 
-/* the number of mounted filesystems.  This is used to decide when to
-** start and kill the commit workqueue
-*/
-static int reiserfs_mounted_fs_count;
-
-static struct workqueue_struct *commit_wq;
-
 #define JOURNAL_TRANS_HALF 1018	/* must be correct to keep the desc and commit
 				   structs at 4k */
 #define BUFNR 64		/*read ahead */
@@ -1882,7 +1875,6 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 		}
 	}
 
-	reiserfs_mounted_fs_count--;
 	/* wait for all commits to finish */
 	cancel_delayed_work(&SB_JOURNAL(sb)->j_work);
 
@@ -1893,12 +1885,7 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	reiserfs_write_unlock(sb);
 
 	cancel_delayed_work_sync(&REISERFS_SB(sb)->old_work);
-	flush_workqueue(commit_wq);
-
-	if (!reiserfs_mounted_fs_count) {
-		destroy_workqueue(commit_wq);
-		commit_wq = NULL;
-	}
+	flush_workqueue(REISERFS_SB(sb)->commit_wq);
 
 	free_journal_ram(sb);
 
@@ -2807,10 +2794,6 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 		goto free_and_return;
 	}
 
-	reiserfs_mounted_fs_count++;
-	if (reiserfs_mounted_fs_count <= 1)
-		commit_wq = alloc_workqueue("reiserfs", WQ_MEM_RECLAIM, 0);
-
 	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
 	journal->j_work_sb = sb;
 	return 0;
@@ -4134,7 +4117,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		flush_commit_list(sb, jl, 1);
 		flush_journal_list(sb, jl, 1);
 	} else if (!(jl->j_state & LIST_COMMIT_PENDING))
-		queue_delayed_work(commit_wq, &journal->j_work, HZ / 10);
+		queue_delayed_work(REISERFS_SB(sb)->commit_wq,
+				   &journal->j_work, HZ / 10);
 
 	/* if the next transaction has any chance of wrapping, flush
 	 ** transactions that might get overwritten.  If any journal lists are very

commit 721a769c034204e8e5f6ca4ecbff249e0225333b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Sep 23 16:50:42 2013 -0400

    reiserfs: fix race with flush_used_journal_lists and flush_journal_list
    
    There are two locks involved in managing the journal lists. The general
    reiserfs_write_lock and the journal->j_flush_mutex.
    
    While flush_journal_list is sleeping to acquire the j_flush_mutex or to
    submit a block for write, it will drop the write lock. This allows
    another thread to acquire the write lock and ultimately call
    flush_used_journal_lists to traverse the list of journal lists and
    select one for flushing. It can select the journal_list that has just
    had flush_journal_list called on it in the original thread and call it
    again with the same journal_list.
    
    The second thread then drops the write lock to acquire j_flush_mutex and
    the first thread reacquires it and continues execution and eventually
    clears and frees the journal list before dropping j_flush_mutex and
    returning.
    
    The second thread acquires j_flush_mutex and ends up operating on a
    journal_list that has already been released. If the memory hasn't
    been reused, we'll soon after hit a BUG_ON because the transaction id
    has already been cleared. If it's been reused, we'll crash in other
    fun ways.
    
    Since flush_journal_list will synchronize on j_flush_mutex, we can fix
    the race by taking a proper reference in flush_used_journal_lists
    and checking to see if it's still valid after the mutex is taken. It's
    safe to iterate the list of journal lists and pick a list with
    just the write lock as long as a reference is taken on the journal list
    before we drop the lock. We already have code to handle whether a
    transaction has been flushed already so we can use that to handle the
    race and get rid of the trans_id BUG_ON.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 7a37473b44dd..fd777032c2ba 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1338,7 +1338,6 @@ static int flush_journal_list(struct super_block *s,
 		reiserfs_warning(s, "clm-2048", "called with wcount %d",
 				 atomic_read(&journal->j_wcount));
 	}
-	BUG_ON(jl->j_trans_id == 0);
 
 	/* if flushall == 0, the lock is already held */
 	if (flushall) {
@@ -1765,6 +1764,8 @@ static int flush_used_journal_lists(struct super_block *s,
 			break;
 		tjl = JOURNAL_LIST_ENTRY(tjl->j_list.next);
 	}
+	get_journal_list(jl);
+	get_journal_list(flush_jl);
 	/* try to find a group of blocks we can flush across all the
 	 ** transactions, but only bother if we've actually spanned
 	 ** across multiple lists
@@ -1773,6 +1774,8 @@ static int flush_used_journal_lists(struct super_block *s,
 		ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
 	}
 	flush_journal_list(s, flush_jl, 1);
+	put_journal_list(s, flush_jl);
+	put_journal_list(s, jl);
 	return 0;
 }
 

commit 7bc9cc07ee5bbac58bab88e8a5d6e32785f8fd32
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Sep 23 16:50:28 2013 -0400

    reiserfs: remove useless flush_old_journal_lists
    
    Commit a3172027 introduced test_transaction as a requirement for
    flushing old lists -- but it can never return 1 unless the transaction
    has already been flushed.
    
    As a result, we have a routine that iterates the j_realblocks list but
    doesn't actually do anything. Since it's been this way since 2006 and
    the latency numbers were what Chris expected, let's just rip it out.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Jan Kara <jack@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 73feacc49b2e..7a37473b44dd 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1163,21 +1163,6 @@ static struct reiserfs_journal_list *find_newer_jl_for_cn(struct
 	return NULL;
 }
 
-static int newer_jl_done(struct reiserfs_journal_cnode *cn)
-{
-	struct super_block *sb = cn->sb;
-	b_blocknr_t blocknr = cn->blocknr;
-
-	cn = cn->hprev;
-	while (cn) {
-		if (cn->sb == sb && cn->blocknr == blocknr && cn->jlist &&
-		    atomic_read(&cn->jlist->j_commit_left) != 0)
-				    return 0;
-		cn = cn->hprev;
-	}
-	return 1;
-}
-
 static void remove_journal_hash(struct super_block *,
 				struct reiserfs_journal_cnode **,
 				struct reiserfs_journal_list *, unsigned long,
@@ -1593,31 +1578,6 @@ static int flush_journal_list(struct super_block *s,
 	return err;
 }
 
-static int test_transaction(struct super_block *s,
-                            struct reiserfs_journal_list *jl)
-{
-	struct reiserfs_journal_cnode *cn;
-
-	if (jl->j_len == 0 || atomic_read(&jl->j_nonzerolen) == 0)
-		return 1;
-
-	cn = jl->j_realblock;
-	while (cn) {
-		/* if the blocknr == 0, this has been cleared from the hash,
-		 ** skip it
-		 */
-		if (cn->blocknr == 0) {
-			goto next;
-		}
-		if (cn->bh && !newer_jl_done(cn))
-			return 0;
-	      next:
-		cn = cn->next;
-		cond_resched();
-	}
-	return 0;
-}
-
 static int write_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl,
 				 struct buffer_chunk *chunk)
@@ -3868,27 +3828,6 @@ int reiserfs_prepare_for_journal(struct super_block *sb,
 	return 1;
 }
 
-static void flush_old_journal_lists(struct super_block *s)
-{
-	struct reiserfs_journal *journal = SB_JOURNAL(s);
-	struct reiserfs_journal_list *jl;
-	struct list_head *entry;
-	time_t now = get_seconds();
-
-	while (!list_empty(&journal->j_journal_list)) {
-		entry = journal->j_journal_list.next;
-		jl = JOURNAL_LIST_ENTRY(entry);
-		/* this check should always be run, to send old lists to disk */
-		if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4)) &&
-		    atomic_read(&jl->j_commit_left) == 0 &&
-		    test_transaction(s, jl)) {
-			flush_used_journal_lists(s, jl);
-		} else {
-			break;
-		}
-	}
-}
-
 /*
 ** long and ugly.  If flush, will not return until all commit
 ** blocks and all real buffers in the trans are on disk.
@@ -4232,7 +4171,6 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			}
 		}
 	}
-	flush_old_journal_lists(sb);
 
 	journal->j_current_jl->j_list_bitmap =
 	    get_list_bitmap(sb, journal->j_current_jl);

commit 278f6679f454bf185a07d9a4ca355b153482d17a
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Aug 8 17:34:46 2013 -0400

    reiserfs: locking, handle nested locks properly
    
    The reiserfs write lock replaced the BKL and uses similar semantics.
    
    Frederic's locking code makes a distinction between when the lock is nested
    and when it's being acquired/released, but I don't think that's the right
    distinction to make.
    
    The right distinction is between the lock being released at end-of-use and
    the lock being released for a schedule. The unlock should return the depth
    and the lock should restore it, rather than the other way around as it is now.
    
    This patch implements that and adds a number of places where the lock
    should be dropped.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 742fdd4c209a..73feacc49b2e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -947,9 +947,11 @@ static int reiserfs_async_progress_wait(struct super_block *s)
 	struct reiserfs_journal *j = SB_JOURNAL(s);
 
 	if (atomic_read(&j->j_async_throttle)) {
-		reiserfs_write_unlock(s);
+		int depth;
+
+		depth = reiserfs_write_unlock_nested(s);
 		congestion_wait(BLK_RW_ASYNC, HZ / 10);
-		reiserfs_write_lock(s);
+		reiserfs_write_lock_nested(s, depth);
 	}
 
 	return 0;
@@ -972,6 +974,7 @@ static int flush_commit_list(struct super_block *s,
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	int retval = 0;
 	int write_len;
+	int depth;
 
 	reiserfs_check_lock_depth(s, "flush_commit_list");
 
@@ -1018,12 +1021,12 @@ static int flush_commit_list(struct super_block *s,
 		 * We might sleep in numerous places inside
 		 * write_ordered_buffers. Relax the write lock.
 		 */
-		reiserfs_write_unlock(s);
+		depth = reiserfs_write_unlock_nested(s);
 		ret = write_ordered_buffers(&journal->j_dirty_buffers_lock,
 					    journal, jl, &jl->j_bh_list);
 		if (ret < 0 && retval == 0)
 			retval = ret;
-		reiserfs_write_lock(s);
+		reiserfs_write_lock_nested(s, depth);
 	}
 	BUG_ON(!list_empty(&jl->j_bh_list));
 	/*
@@ -1043,9 +1046,9 @@ static int flush_commit_list(struct super_block *s,
 		tbh = journal_find_get_block(s, bn);
 		if (tbh) {
 			if (buffer_dirty(tbh)) {
-		            reiserfs_write_unlock(s);
+		            depth = reiserfs_write_unlock_nested(s);
 			    ll_rw_block(WRITE, 1, &tbh);
-			    reiserfs_write_lock(s);
+			    reiserfs_write_lock_nested(s, depth);
 			}
 			put_bh(tbh) ;
 		}
@@ -1057,17 +1060,17 @@ static int flush_commit_list(struct super_block *s,
 		    (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s);
 		tbh = journal_find_get_block(s, bn);
 
-		reiserfs_write_unlock(s);
-		wait_on_buffer(tbh);
-		reiserfs_write_lock(s);
+		depth = reiserfs_write_unlock_nested(s);
+		__wait_on_buffer(tbh);
+		reiserfs_write_lock_nested(s, depth);
 		// since we're using ll_rw_blk above, it might have skipped over
 		// a locked buffer.  Double check here
 		//
 		/* redundant, sync_dirty_buffer() checks */
 		if (buffer_dirty(tbh)) {
-			reiserfs_write_unlock(s);
+			depth = reiserfs_write_unlock_nested(s);
 			sync_dirty_buffer(tbh);
-			reiserfs_write_lock(s);
+			reiserfs_write_lock_nested(s, depth);
 		}
 		if (unlikely(!buffer_uptodate(tbh))) {
 #ifdef CONFIG_REISERFS_CHECK
@@ -1091,12 +1094,12 @@ static int flush_commit_list(struct super_block *s,
 		if (buffer_dirty(jl->j_commit_bh))
 			BUG();
 		mark_buffer_dirty(jl->j_commit_bh) ;
-		reiserfs_write_unlock(s);
+		depth = reiserfs_write_unlock_nested(s);
 		if (reiserfs_barrier_flush(s))
 			__sync_dirty_buffer(jl->j_commit_bh, WRITE_FLUSH_FUA);
 		else
 			sync_dirty_buffer(jl->j_commit_bh);
-		reiserfs_write_lock(s);
+		reiserfs_write_lock_nested(s, depth);
 	}
 
 	/* If there was a write error in the journal - we can't commit this
@@ -1228,15 +1231,16 @@ static int _update_journal_header_block(struct super_block *sb,
 {
 	struct reiserfs_journal_header *jh;
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	int depth;
 
 	if (reiserfs_is_journal_aborted(journal))
 		return -EIO;
 
 	if (trans_id >= journal->j_last_flush_trans_id) {
 		if (buffer_locked((journal->j_header_bh))) {
-			reiserfs_write_unlock(sb);
-			wait_on_buffer((journal->j_header_bh));
-			reiserfs_write_lock(sb);
+			depth = reiserfs_write_unlock_nested(sb);
+			__wait_on_buffer(journal->j_header_bh);
+			reiserfs_write_lock_nested(sb, depth);
 			if (unlikely(!buffer_uptodate(journal->j_header_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
 				reiserfs_warning(sb, "journal-699",
@@ -1254,14 +1258,14 @@ static int _update_journal_header_block(struct super_block *sb,
 		jh->j_mount_id = cpu_to_le32(journal->j_mount_id);
 
 		set_buffer_dirty(journal->j_header_bh);
-		reiserfs_write_unlock(sb);
+		depth = reiserfs_write_unlock_nested(sb);
 
 		if (reiserfs_barrier_flush(sb))
 			__sync_dirty_buffer(journal->j_header_bh, WRITE_FLUSH_FUA);
 		else
 			sync_dirty_buffer(journal->j_header_bh);
 
-		reiserfs_write_lock(sb);
+		reiserfs_write_lock_nested(sb, depth);
 		if (!buffer_uptodate(journal->j_header_bh)) {
 			reiserfs_warning(sb, "journal-837",
 					 "IO error during journal replay");
@@ -1341,6 +1345,7 @@ static int flush_journal_list(struct super_block *s,
 	unsigned long j_len_saved = jl->j_len;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	int err = 0;
+	int depth;
 
 	BUG_ON(j_len_saved <= 0);
 
@@ -1495,9 +1500,9 @@ static int flush_journal_list(struct super_block *s,
 						       "cn->bh is NULL");
 				}
 
-				reiserfs_write_unlock(s);
-				wait_on_buffer(cn->bh);
-				reiserfs_write_lock(s);
+				depth = reiserfs_write_unlock_nested(s);
+				__wait_on_buffer(cn->bh);
+				reiserfs_write_lock_nested(s, depth);
 
 				if (!cn->bh) {
 					reiserfs_panic(s, "journal-1012",
@@ -1974,6 +1979,7 @@ static int journal_compare_desc_commit(struct super_block *sb,
 /* returns 0 if it did not find a description block
 ** returns -1 if it found a corrupt commit block
 ** returns 1 if both desc and commit were valid
+** NOTE: only called during fs mount
 */
 static int journal_transaction_is_valid(struct super_block *sb,
 					struct buffer_head *d_bh,
@@ -2073,8 +2079,9 @@ static void brelse_array(struct buffer_head **heads, int num)
 
 /*
 ** given the start, and values for the oldest acceptable transactions,
-** this either reads in a replays a transaction, or returns because the transaction
-** is invalid, or too old.
+** this either reads in a replays a transaction, or returns because the
+** transaction is invalid, or too old.
+** NOTE: only called during fs mount
 */
 static int journal_read_transaction(struct super_block *sb,
 				    unsigned long cur_dblock,
@@ -2208,10 +2215,7 @@ static int journal_read_transaction(struct super_block *sb,
 	ll_rw_block(READ, get_desc_trans_len(desc), log_blocks);
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 
-		reiserfs_write_unlock(sb);
 		wait_on_buffer(log_blocks[i]);
-		reiserfs_write_lock(sb);
-
 		if (!buffer_uptodate(log_blocks[i])) {
 			reiserfs_warning(sb, "journal-1212",
 					 "REPLAY FAILURE fsck required! "
@@ -2318,12 +2322,13 @@ static struct buffer_head *reiserfs_breada(struct block_device *dev,
 
 /*
 ** read and replay the log
-** on a clean unmount, the journal header's next unflushed pointer will be to an invalid
-** transaction.  This tests that before finding all the transactions in the log, which makes normal mount times fast.
-**
-** After a crash, this starts with the next unflushed transaction, and replays until it finds one too old, or invalid.
-**
+** on a clean unmount, the journal header's next unflushed pointer will
+** be to an invalid transaction.  This tests that before finding all the
+** transactions in the log, which makes normal mount times fast.
+** After a crash, this starts with the next unflushed transaction, and
+** replays until it finds one too old, or invalid.
 ** On exit, it sets things up so the first transaction will work correctly.
+** NOTE: only called during fs mount
 */
 static int journal_read(struct super_block *sb)
 {
@@ -2501,14 +2506,18 @@ static int journal_read(struct super_block *sb)
 			      "replayed %d transactions in %lu seconds\n",
 			      replay_count, get_seconds() - start);
 	}
+	/* needed to satisfy the locking in _update_journal_header_block */
+	reiserfs_write_lock(sb);
 	if (!bdev_read_only(sb->s_bdev) &&
 	    _update_journal_header_block(sb, journal->j_start,
 					 journal->j_last_flush_trans_id)) {
+		reiserfs_write_unlock(sb);
 		/* replay failed, caller must call free_journal_ram and abort
 		 ** the mount
 		 */
 		return -1;
 	}
+	reiserfs_write_unlock(sb);
 	return 0;
 }
 
@@ -2828,13 +2837,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 		goto free_and_return;
 	}
 
-	/*
-	 * Journal_read needs to be inspected in order to push down
-	 * the lock further inside (or even remove it).
-	 */
-	reiserfs_write_lock(sb);
 	ret = journal_read(sb);
-	reiserfs_write_unlock(sb);
 	if (ret < 0) {
 		reiserfs_warning(sb, "reiserfs-2006",
 				 "Replay Failure, unable to mount");
@@ -2923,9 +2926,9 @@ static void queue_log_writer(struct super_block *s)
 	add_wait_queue(&journal->j_join_wait, &wait);
 	set_current_state(TASK_UNINTERRUPTIBLE);
 	if (test_bit(J_WRITERS_QUEUED, &journal->j_state)) {
-		reiserfs_write_unlock(s);
+		int depth = reiserfs_write_unlock_nested(s);
 		schedule();
-		reiserfs_write_lock(s);
+		reiserfs_write_lock_nested(s, depth);
 	}
 	__set_current_state(TASK_RUNNING);
 	remove_wait_queue(&journal->j_join_wait, &wait);
@@ -2943,9 +2946,12 @@ static void let_transaction_grow(struct super_block *sb, unsigned int trans_id)
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned long bcount = journal->j_bcount;
 	while (1) {
-		reiserfs_write_unlock(sb);
+		int depth;
+
+		depth = reiserfs_write_unlock_nested(sb);
 		schedule_timeout_uninterruptible(1);
-		reiserfs_write_lock(sb);
+		reiserfs_write_lock_nested(sb, depth);
+
 		journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
 		while ((atomic_read(&journal->j_wcount) > 0 ||
 			atomic_read(&journal->j_jlock)) &&
@@ -2976,6 +2982,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	struct reiserfs_transaction_handle myth;
 	int sched_count = 0;
 	int retval;
+	int depth;
 
 	reiserfs_check_lock_depth(sb, "journal_begin");
 	BUG_ON(nblocks > journal->j_trans_max);
@@ -2996,9 +3003,9 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 
 	if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
 		unlock_journal(sb);
-		reiserfs_write_unlock(sb);
+		depth = reiserfs_write_unlock_nested(sb);
 		reiserfs_wait_on_write_block(sb);
-		reiserfs_write_lock(sb);
+		reiserfs_write_lock_nested(sb, depth);
 		PROC_INFO_INC(sb, journal.journal_relock_writers);
 		goto relock;
 	}
@@ -3821,6 +3828,7 @@ void reiserfs_restore_prepared_buffer(struct super_block *sb,
 	if (test_clear_buffer_journal_restore_dirty(bh) &&
 	    buffer_journal_dirty(bh)) {
 		struct reiserfs_journal_cnode *cn;
+		reiserfs_write_lock(sb);
 		cn = get_journal_hash_dev(sb,
 					  journal->j_list_hash_table,
 					  bh->b_blocknr);
@@ -3828,6 +3836,7 @@ void reiserfs_restore_prepared_buffer(struct super_block *sb,
 			set_buffer_journal_test(bh);
 			mark_buffer_dirty(bh);
 		}
+		reiserfs_write_unlock(sb);
 	}
 	clear_buffer_journal_prepared(bh);
 }
@@ -3911,6 +3920,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	unsigned long jindex;
 	unsigned int commit_trans_id;
 	int trans_half;
+	int depth;
 
 	BUG_ON(th->t_refcount > 1);
 	BUG_ON(!th->t_trans_id);
@@ -4116,9 +4126,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		next = cn->next;
 		free_cnode(sb, cn);
 		cn = next;
-		reiserfs_write_unlock(sb);
-		cond_resched();
-		reiserfs_write_lock(sb);
+		reiserfs_cond_resched(sb);
 	}
 
 	/* we are done  with both the c_bh and d_bh, but
@@ -4165,10 +4173,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * is lost.
 	 */
 	if (!list_empty(&jl->j_tail_bh_list)) {
-		reiserfs_write_unlock(sb);
+		depth = reiserfs_write_unlock_nested(sb);
 		write_ordered_buffers(&journal->j_dirty_buffers_lock,
 				      journal, jl, &jl->j_tail_bh_list);
-		reiserfs_write_lock(sb);
+		reiserfs_write_lock_nested(sb, depth);
 	}
 	BUG_ON(!list_empty(&jl->j_tail_bh_list));
 	mutex_unlock(&jl->j_commit_mutex);

commit 4385bab128911df14ab25f0b5ae1a48d7b53dd94
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun May 5 22:11:03 2013 -0400

    make blkdev_put() return void
    
    same story as with the previous patches - note that return
    value of blkdev_close() is lost, since there's nowhere the
    caller (__fput()) could return it to.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index afcadcc03e8a..742fdd4c209a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -97,7 +97,7 @@ static int flush_commit_list(struct super_block *s,
 static int can_dirty(struct reiserfs_journal_cnode *cn);
 static int journal_join(struct reiserfs_transaction_handle *th,
 			struct super_block *sb, unsigned long nblocks);
-static int release_journal_dev(struct super_block *super,
+static void release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal);
 static int dirty_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl);
@@ -2532,23 +2532,13 @@ static void journal_list_init(struct super_block *sb)
 	SB_JOURNAL(sb)->j_current_jl = alloc_journal_list(sb);
 }
 
-static int release_journal_dev(struct super_block *super,
+static void release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal)
 {
-	int result;
-
-	result = 0;
-
 	if (journal->j_dev_bd != NULL) {
-		result = blkdev_put(journal->j_dev_bd, journal->j_dev_mode);
+		blkdev_put(journal->j_dev_bd, journal->j_dev_mode);
 		journal->j_dev_bd = NULL;
 	}
-
-	if (result != 0) {
-		reiserfs_warning(super, "sh-457",
-				 "Cannot release journal device: %i", result);
-	}
-	return result;
 }
 
 static int journal_init_dev(struct super_block *super,

commit 033369d1af1264abc23bea2e174aa47cdd212f6f
Author: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
Date:   Fri Jun 1 17:18:08 2012 +0300

    reiserfs: get rid of resierfs_sync_super
    
    This patch stops reiserfs using the VFS 'write_super()' method along with the
    s_dirt flag, because they are on their way out.
    
    The whole "superblock write-out" VFS infrastructure is served by the
    'sync_supers()' kernel thread, which wakes up every 5 (by default) seconds and
    writes out all dirty superblock using the '->write_super()' call-back.  But the
    problem with this thread is that it wastes power by waking up the system every
    5 seconds, even if there are no diry superblocks, or there are no client
    file-systems which would need this (e.g., btrfs does not use
    '->write_super()'). So we want to kill it completely and thus, we need to make
    file-systems to stop using the '->write_super()' VFS service, and then remove
    it together with the kernel thread.
    
    Signed-off-by: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e5e06dd8562f..afcadcc03e8a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1923,6 +1923,8 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	 * the workqueue job (flush_async_commit) needs this lock
 	 */
 	reiserfs_write_unlock(sb);
+
+	cancel_delayed_work_sync(&REISERFS_SB(sb)->old_work);
 	flush_workqueue(commit_wq);
 
 	if (!reiserfs_mounted_fs_count) {
@@ -3314,7 +3316,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 		journal->j_first = cn;
 		journal->j_last = cn;
 	}
-	sb->s_dirt = 1;
+	reiserfs_schedule_old_flush(sb);
 	return 0;
 }
 
@@ -3952,7 +3954,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 ** it tells us if we should continue with the journal_end, or just return
 	 */
 	if (!check_journal_end(th, sb, nblocks, flags)) {
-		sb->s_dirt = 1;
+		reiserfs_schedule_old_flush(sb);
 		wake_queued_writers(sb);
 		reiserfs_async_progress_wait(sb);
 		goto out;

commit 5c5fd81962271d4ee2984837fef4ec37e689aa41
Author: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
Date:   Fri Jun 1 17:18:07 2012 +0300

    reiserfs: mark the superblock as dirty a bit later
    
    The 'journal_mark_dirty()' function currently first marks the superblock as
    dirty by setting 's_dirt' to 1, then does various sanity checks and returns,
    then actuall does all the magic with the journal.
    
    This is not an ideal order, though. It makes more sense to first do all the
    checks, then do all the internal stuff, and at the end notify the VFS that the
    superblock is now dirty.
    
    This patch moves the 's_dirt = 1' assignment from the very beginning of this
    function to the very end.
    
    Signed-off-by: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 68aea62ea61d..e5e06dd8562f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -3231,8 +3231,6 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 			       th->t_trans_id, journal->j_trans_id);
 	}
 
-	sb->s_dirt = 1;
-
 	prepared = test_clear_buffer_journal_prepared(bh);
 	clear_buffer_journal_restore_dirty(bh);
 	/* already in this transaction, we are done */
@@ -3316,6 +3314,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 		journal->j_first = cn;
 		journal->j_last = cn;
 	}
+	sb->s_dirt = 1;
 	return 0;
 }
 

commit 25729b0e94c2103a8d726eda843136a3775366cf
Author: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
Date:   Fri Jun 1 17:18:05 2012 +0300

    reiserfs: clean-up function return type
    
    Turn 'reiserfs_flush_old_commits()' into a void function because the callers
    do not cares about what it returns anyway.
    
    We are going to remove the 'sb->s_dirt' field completely and this patch is a
    small step towards this direction.
    
    Signed-off-by: Artem Bityutskiy <artem.bityutskiy@linux.intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b1a08573fe14..68aea62ea61d 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -3492,7 +3492,7 @@ static void flush_async_commits(struct work_struct *work)
 ** flushes any old transactions to disk
 ** ends the current transaction if it is too old
 */
-int reiserfs_flush_old_commits(struct super_block *sb)
+void reiserfs_flush_old_commits(struct super_block *sb)
 {
 	time_t now;
 	struct reiserfs_transaction_handle th;
@@ -3502,9 +3502,8 @@ int reiserfs_flush_old_commits(struct super_block *sb)
 	/* safety check so we don't flush while we are replaying the log during
 	 * mount
 	 */
-	if (list_empty(&journal->j_journal_list)) {
-		return 0;
-	}
+	if (list_empty(&journal->j_journal_list))
+		return;
 
 	/* check the current transaction.  If there are no writers, and it is
 	 * too old, finish it, and force the commit blocks to disk
@@ -3526,7 +3525,6 @@ int reiserfs_flush_old_commits(struct super_block *sb)
 			do_journal_end(&th, sb, 1, COMMIT_NOW | WAIT);
 		}
 	}
-	return sb->s_dirt;
 }
 
 /*

commit 9ffc93f203c18a70623f21950f1dd473c9ec48cd
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Remove all #inclusions of asm/system.h
    
    Remove all #inclusions of asm/system.h preparatory to splitting and killing
    it.  Performed with the following command:
    
    perl -p -i -e 's!^#\s*include\s*<asm/system[.]h>.*\n!!' `grep -Irl '^#\s*include\s*<asm/system[.]h>' *`
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index cf9f4de00a95..b1a08573fe14 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -51,7 +51,6 @@
 #include <linux/uaccess.h>
 #include <linux/slab.h>
 
-#include <asm/system.h>
 
 /* gets a struct reiserfs_journal_list * from a list head */
 #define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \

commit f466c6fdb3b1f043ff1977a8d2a1d0cd4dc164fa
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 17 01:16:43 2012 -0400

    move private bits of reiserfs_fs.h to fs/reiserfs/reiserfs.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c3cf54fd4de3..cf9f4de00a95 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -37,7 +37,7 @@
 #include <linux/time.h>
 #include <linux/semaphore.h>
 #include <linux/vmalloc.h>
-#include <linux/reiserfs_fs.h>
+#include "reiserfs.h"
 #include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/fcntl.h>

commit 37c69b98d0dca54d9eb72226bbf2e211aaaf126e
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 10 15:11:09 2012 -0800

    reiserfs: don't lock journal_init()
    
    journal_init() doesn't need the lock since no operation on the filesystem
    is involved there.  journal_read() and get_list_bitmap() have yet to be
    reviewed carefully though before removing the lock there.  Just keep the
    it around these two calls for safety.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index cce8e8710df2..c3cf54fd4de3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2678,16 +2678,10 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	char b[BDEVNAME_SIZE];
 	int ret;
 
-	/*
-	 * Unlock here to avoid various RECLAIM-FS-ON <-> IN-RECLAIM-FS
-	 * dependency inversion warnings.
-	 */
-	reiserfs_write_unlock(sb);
 	journal = SB_JOURNAL(sb) = vzalloc(sizeof(struct reiserfs_journal));
 	if (!journal) {
 		reiserfs_warning(sb, "journal-1256",
 				 "unable to get memory for journal structure");
-		reiserfs_write_lock(sb);
 		return 1;
 	}
 	INIT_LIST_HEAD(&journal->j_bitmap_nodes);
@@ -2695,10 +2689,8 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	INIT_LIST_HEAD(&journal->j_working_list);
 	INIT_LIST_HEAD(&journal->j_journal_list);
 	journal->j_persistent_trans = 0;
-	ret = reiserfs_allocate_list_bitmaps(sb, journal->j_list_bitmap,
-					   reiserfs_bmap_count(sb));
-	reiserfs_write_lock(sb);
-	if (ret)
+	if (reiserfs_allocate_list_bitmaps(sb, journal->j_list_bitmap,
+					   reiserfs_bmap_count(sb)))
 		goto free_and_return;
 
 	allocate_bitmap_nodes(sb);
@@ -2727,27 +2719,11 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 		goto free_and_return;
 	}
 
-	/*
-	 * We need to unlock here to avoid creating the following
-	 * dependency:
-	 * reiserfs_lock -> sysfs_mutex
-	 * Because the reiserfs mmap path creates the following dependency:
-	 * mm->mmap -> reiserfs_lock, hence we have
-	 * mm->mmap -> reiserfs_lock ->sysfs_mutex
-	 * This would ends up in a circular dependency with sysfs readdir path
-	 * which does sysfs_mutex -> mm->mmap_sem
-	 * This is fine because the reiserfs lock is useless in mount path,
-	 * at least until we call journal_begin. We keep it for paranoid
-	 * reasons.
-	 */
-	reiserfs_write_unlock(sb);
 	if (journal_init_dev(sb, journal, j_dev_name) != 0) {
-		reiserfs_write_lock(sb);
 		reiserfs_warning(sb, "sh-462",
 				 "unable to initialize jornal device");
 		goto free_and_return;
 	}
-	reiserfs_write_lock(sb);
 
 	rs = SB_DISK_SUPER_BLOCK(sb);
 
@@ -2829,9 +2805,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	journal->j_mount_id = 10;
 	journal->j_state = 0;
 	atomic_set(&(journal->j_jlock), 0);
-	reiserfs_write_unlock(sb);
 	journal->j_cnode_free_list = allocate_cnodes(num_cnodes);
-	reiserfs_write_lock(sb);
 	journal->j_cnode_free_orig = journal->j_cnode_free_list;
 	journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0;
 	journal->j_cnode_used = 0;
@@ -2848,24 +2822,37 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 
 	init_journal_hash(sb);
 	jl = journal->j_current_jl;
+
+	/*
+	 * get_list_bitmap() may call flush_commit_list() which
+	 * requires the lock. Calling flush_commit_list() shouldn't happen
+	 * this early but I like to be paranoid.
+	 */
+	reiserfs_write_lock(sb);
 	jl->j_list_bitmap = get_list_bitmap(sb, jl);
+	reiserfs_write_unlock(sb);
 	if (!jl->j_list_bitmap) {
 		reiserfs_warning(sb, "journal-2005",
 				 "get_list_bitmap failed for journal list 0");
 		goto free_and_return;
 	}
-	if (journal_read(sb) < 0) {
+
+	/*
+	 * Journal_read needs to be inspected in order to push down
+	 * the lock further inside (or even remove it).
+	 */
+	reiserfs_write_lock(sb);
+	ret = journal_read(sb);
+	reiserfs_write_unlock(sb);
+	if (ret < 0) {
 		reiserfs_warning(sb, "reiserfs-2006",
 				 "Replay Failure, unable to mount");
 		goto free_and_return;
 	}
 
 	reiserfs_mounted_fs_count++;
-	if (reiserfs_mounted_fs_count <= 1) {
-		reiserfs_write_unlock(sb);
+	if (reiserfs_mounted_fs_count <= 1)
 		commit_wq = alloc_workqueue("reiserfs", WQ_MEM_RECLAIM, 0);
-		reiserfs_write_lock(sb);
-	}
 
 	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
 	journal->j_work_sb = sb;

commit b18c1c6e0c90cbcd38ba879bd63a44c94e4f7301
Author: Davidlohr Bueso <dave@gnu.org>
Date:   Tue Jan 10 15:11:05 2012 -0800

    reiserfs: delete comments referring to the BKL
    
    Signed-off-by: Davidlohr Bueso <dave@gnu.org>
    Cc: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index eb711060a6f2..cce8e8710df2 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2896,14 +2896,13 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 	    journal->j_cnode_free < (journal->j_trans_max * 3)) {
 		return 1;
 	}
-	/* protected by the BKL here */
+
 	journal->j_len_alloc += new_alloc;
 	th->t_blocks_allocated += new_alloc ;
 	return 0;
 }
 
-/* this must be called inside a transaction, and requires the
-** kernel_lock to be held
+/* this must be called inside a transaction
 */
 void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
 {
@@ -2914,8 +2913,7 @@ void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
 	return;
 }
 
-/* this must be called without a transaction started, and does not
-** require BKL
+/* this must be called without a transaction started
 */
 void reiserfs_allow_writes(struct super_block *s)
 {
@@ -2924,8 +2922,7 @@ void reiserfs_allow_writes(struct super_block *s)
 	wake_up(&journal->j_join_wait);
 }
 
-/* this must be called without a transaction started, and does not
-** require BKL
+/* this must be called without a transaction started
 */
 void reiserfs_wait_on_write_block(struct super_block *s)
 {

commit 558feb0818374d657fbc1ea03776ee20f204b3a6
Author: Joe Perches <joe@perches.com>
Date:   Sat May 28 10:36:33 2011 -0700

    fs: Convert vmalloc/memset to vzalloc
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-by: Alex Elder <aelder@sgi.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a159ba5a35e7..eb711060a6f2 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -291,14 +291,13 @@ int reiserfs_allocate_list_bitmaps(struct super_block *sb,
 	for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
 		jb = jb_array + i;
 		jb->journal_list = NULL;
-		jb->bitmaps = vmalloc(mem);
+		jb->bitmaps = vzalloc(mem);
 		if (!jb->bitmaps) {
 			reiserfs_warning(sb, "clm-2000", "unable to "
 					 "allocate bitmaps for journal lists");
 			failed = 1;
 			break;
 		}
-		memset(jb->bitmaps, 0, mem);
 	}
 	if (failed) {
 		free_list_bitmaps(sb, jb_array);
@@ -353,11 +352,10 @@ static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 	if (num_cnodes <= 0) {
 		return NULL;
 	}
-	head = vmalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode));
+	head = vzalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode));
 	if (!head) {
 		return NULL;
 	}
-	memset(head, 0, num_cnodes * sizeof(struct reiserfs_journal_cnode));
 	head[0].prev = NULL;
 	head[0].next = head + 1;
 	for (i = 1; i < num_cnodes; i++) {
@@ -2685,14 +2683,13 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	 * dependency inversion warnings.
 	 */
 	reiserfs_write_unlock(sb);
-	journal = SB_JOURNAL(sb) = vmalloc(sizeof(struct reiserfs_journal));
+	journal = SB_JOURNAL(sb) = vzalloc(sizeof(struct reiserfs_journal));
 	if (!journal) {
 		reiserfs_warning(sb, "journal-1256",
 				 "unable to get memory for journal structure");
 		reiserfs_write_lock(sb);
 		return 1;
 	}
-	memset(journal, 0, sizeof(struct reiserfs_journal));
 	INIT_LIST_HEAD(&journal->j_bitmap_nodes);
 	INIT_LIST_HEAD(&journal->j_prealloc_list);
 	INIT_LIST_HEAD(&journal->j_working_list);

commit 4aede84b33d6beb401136a3deca0651ae07c5e99
Author: Justin TerAvest <teravest@google.com>
Date:   Tue Jul 12 08:31:45 2011 +0200

    fixlet: Remove fs_excl from struct task.
    
    fs_excl is a poor man's priority inheritance for filesystems to hint to
    the block layer that an operation is important. It was never clearly
    specified, not widely adopted, and will not prevent starvation in many
    cases (like across cgroups).
    
    fs_excl was introduced with the time sliced CFQ IO scheduler, to
    indicate when a process held FS exclusive resources and thus needed
    a boost.
    
    It doesn't cover all file systems, and it was never fully complete.
    Lets kill it.
    
    Signed-off-by: Justin TerAvest <teravest@google.com>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c5e82ece7c6c..a159ba5a35e7 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -678,23 +678,19 @@ struct buffer_chunk {
 static void write_chunk(struct buffer_chunk *chunk)
 {
 	int i;
-	get_fs_excl();
 	for (i = 0; i < chunk->nr; i++) {
 		submit_logged_buffer(chunk->bh[i]);
 	}
 	chunk->nr = 0;
-	put_fs_excl();
 }
 
 static void write_ordered_chunk(struct buffer_chunk *chunk)
 {
 	int i;
-	get_fs_excl();
 	for (i = 0; i < chunk->nr; i++) {
 		submit_ordered_buffer(chunk->bh[i]);
 	}
 	chunk->nr = 0;
-	put_fs_excl();
 }
 
 static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
@@ -986,8 +982,6 @@ static int flush_commit_list(struct super_block *s,
 		return 0;
 	}
 
-	get_fs_excl();
-
 	/* before we can put our commit blocks on disk, we have to make sure everyone older than
 	 ** us is on disk too
 	 */
@@ -1145,7 +1139,6 @@ static int flush_commit_list(struct super_block *s,
 	if (retval)
 		reiserfs_abort(s, retval, "Journal write error in %s",
 			       __func__);
-	put_fs_excl();
 	return retval;
 }
 
@@ -1374,8 +1367,6 @@ static int flush_journal_list(struct super_block *s,
 		return 0;
 	}
 
-	get_fs_excl();
-
 	/* if all the work is already done, get out of here */
 	if (atomic_read(&(jl->j_nonzerolen)) <= 0 &&
 	    atomic_read(&(jl->j_commit_left)) <= 0) {
@@ -1597,7 +1588,6 @@ static int flush_journal_list(struct super_block *s,
 	put_journal_list(s, jl);
 	if (flushall)
 		mutex_unlock(&journal->j_flush_mutex);
-	put_fs_excl();
 	return err;
 }
 
@@ -3108,7 +3098,6 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	th->t_trans_id = journal->j_trans_id;
 	unlock_journal(sb);
 	INIT_LIST_HEAD(&th->t_list);
-	get_fs_excl();
 	return 0;
 
       out_fail:
@@ -3964,7 +3953,6 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	flush = flags & FLUSH_ALL;
 	wait_on_commit = flags & WAIT;
 
-	put_fs_excl();
 	current->journal_info = th->t_handle_save;
 	reiserfs_check_lock_depth(sb, "journal end");
 	if (journal->j_len == 0) {
@@ -4316,4 +4304,3 @@ void reiserfs_abort_journal(struct super_block *sb, int errno)
 	dump_stack();
 #endif
 }
-

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c77514bd5776..c5e82ece7c6c 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1,7 +1,7 @@
 /*
 ** Write ahead logging implementation copyright Chris Mason 2000
 **
-** The background commits make this code very interelated, and
+** The background commits make this code very interrelated, and
 ** overly complex.  I need to rethink things a bit....The major players:
 **
 ** journal_begin -- call with the number of blocks you expect to log.
@@ -2725,7 +2725,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 						 REISERFS_DISK_OFFSET_IN_BYTES /
 						 sb->s_blocksize + 2);
 
-	/* Sanity check to see is the standard journal fitting withing first bitmap
+	/* Sanity check to see is the standard journal fitting within first bitmap
 	   (actual for small blocksizes) */
 	if (!SB_ONDISK_JOURNAL_DEVICE(sb) &&
 	    (SB_JOURNAL_1st_RESERVED_BLOCK(sb) +

commit 28aadf51693f56c41326ebbc795318a49011b12d
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 1 11:42:42 2011 +0100

    reiserfs: make commit_wq use the default concurrency level
    
    The maximum number of concurrent work items queued on commit_wq is
    bound by the number of active journals.  Convert to alloc_workqueue()
    and use the default concurrency level so that they can be processed in
    parallel.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: reiserfs-devel@vger.kernel.org

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 3eea859e6990..c77514bd5776 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2876,7 +2876,7 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	reiserfs_mounted_fs_count++;
 	if (reiserfs_mounted_fs_count <= 1) {
 		reiserfs_write_unlock(sb);
-		commit_wq = create_workqueue("reiserfs");
+		commit_wq = alloc_workqueue("reiserfs", WQ_MEM_RECLAIM, 0);
 		reiserfs_write_lock(sb);
 	}
 

commit 275220f0fcff1adf28a717076e00f575edf05fda
Merge: fe3c560b8a22 81c5e2ae33c4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 13 10:45:01 2011 -0800

    Merge branch 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block: (43 commits)
      block: ensure that completion error gets properly traced
      blktrace: add missing probe argument to block_bio_complete
      block cfq: don't use atomic_t for cfq_group
      block cfq: don't use atomic_t for cfq_queue
      block: trace event block fix unassigned field
      block: add internal hd part table references
      block: fix accounting bug on cross partition merges
      kref: add kref_test_and_get
      bio-integrity: mark kintegrityd_wq highpri and CPU intensive
      block: make kblockd_workqueue smarter
      Revert "sd: implement sd_check_events()"
      block: Clean up exit_io_context() source code.
      Fix compile warnings due to missing removal of a 'ret' variable
      fs/block: type signature of major_to_index(int) to major_to_index(unsigned)
      block: convert !IS_ERR(p) && p to !IS_ERR_NOR_NULL(p)
      cfq-iosched: don't check cfqg in choose_service_tree()
      fs/splice: Pull buf->ops->confirm() from splice_from_pipe actors
      cdrom: export cdrom_check_events()
      sd: implement sd_check_events()
      sr: implement sr_check_events()
      ...

commit 451a3c24b0135bce54542009b5fde43846c7cf67
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Nov 17 16:26:55 2010 +0100

    BKL: remove extraneous #include <smp_lock.h>
    
    The big kernel lock has been removed from all these files at some point,
    leaving only the #include.
    
    Remove this too as a cleanup.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 076c8b194682..d31bce1a9f90 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -43,7 +43,6 @@
 #include <linux/fcntl.h>
 #include <linux/stat.h>
 #include <linux/string.h>
-#include <linux/smp_lock.h>
 #include <linux/buffer_head.h>
 #include <linux/workqueue.h>
 #include <linux/writeback.h>

commit d4d77629953eabd3c14f6fa5746f6b28babfc55f
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:18 2010 +0100

    block: clean up blkdev_get() wrappers and their users
    
    After recent blkdev_get() modifications, open_by_devnum() and
    open_bdev_exclusive() are simple wrappers around blkdev_get().
    Replace them with blkdev_get_by_dev() and blkdev_get_by_path().
    
    blkdev_get_by_dev() is identical to open_by_devnum().
    blkdev_get_by_path() is slightly different in that it doesn't
    automatically add %FMODE_EXCL to @mode.
    
    All users are converted.  Most conversions are mechanical and don't
    introduce any behavior difference.  There are several exceptions.
    
    * btrfs now sets FMODE_EXCL in btrfs_device->mode, so there's no
      reason to OR it explicitly on blkdev_put().
    
    * gfs2, nilfs2 and the generic mount_bdev() now set FMODE_EXCL in
      sb->s_mode.
    
    * With the above changes, sb->s_mode now always should contain
      FMODE_EXCL.  WARN_ON_ONCE() added to kill_block_super() to detect
      errors.
    
    The new blkdev_get_*() functions are with proper docbook comments.
    While at it, add function description to blkdev_get() too.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Joern Engel <joern@lazybastard.org>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: reiserfs-devel@vger.kernel.org
    Cc: xfs-masters@oss.sgi.com
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b488136f5ace..e2fce519c0f2 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2585,7 +2585,8 @@ static int journal_init_dev(struct super_block *super,
 	if ((!jdev_name || !jdev_name[0])) {
 		if (jdev == super->s_dev)
 			blkdev_mode &= ~FMODE_EXCL;
-		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode, journal);
+		journal->j_dev_bd = blkdev_get_by_dev(jdev, blkdev_mode,
+						      journal);
 		journal->j_dev_mode = blkdev_mode;
 		if (IS_ERR(journal->j_dev_bd)) {
 			result = PTR_ERR(journal->j_dev_bd);
@@ -2601,8 +2602,7 @@ static int journal_init_dev(struct super_block *super,
 	}
 
 	journal->j_dev_mode = blkdev_mode;
-	journal->j_dev_bd = open_bdev_exclusive(jdev_name,
-						blkdev_mode, journal);
+	journal->j_dev_bd = blkdev_get_by_path(jdev_name, blkdev_mode, journal);
 	if (IS_ERR(journal->j_dev_bd)) {
 		result = PTR_ERR(journal->j_dev_bd);
 		journal->j_dev_bd = NULL;

commit e525fd89d380c4a94c0d63913a1dd1a593ed25e7
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Nov 13 11:55:17 2010 +0100

    block: make blkdev_get/put() handle exclusive access
    
    Over time, block layer has accumulated a set of APIs dealing with bdev
    open, close, claim and release.
    
    * blkdev_get/put() are the primary open and close functions.
    
    * bd_claim/release() deal with exclusive open.
    
    * open/close_bdev_exclusive() are combination of open and claim and
      the other way around, respectively.
    
    * bd_link/unlink_disk_holder() to create and remove holder/slave
      symlinks.
    
    * open_by_devnum() wraps bdget() + blkdev_get().
    
    The interface is a bit confusing and the decoupling of open and claim
    makes it impossible to properly guarantee exclusive access as
    in-kernel open + claim sequence can disturb the existing exclusive
    open even before the block layer knows the current open if for another
    exclusive access.  Reorganize the interface such that,
    
    * blkdev_get() is extended to include exclusive access management.
      @holder argument is added and, if is @FMODE_EXCL specified, it will
      gain exclusive access atomically w.r.t. other exclusive accesses.
    
    * blkdev_put() is similarly extended.  It now takes @mode argument and
      if @FMODE_EXCL is set, it releases an exclusive access.  Also, when
      the last exclusive claim is released, the holder/slave symlinks are
      removed automatically.
    
    * bd_claim/release() and close_bdev_exclusive() are no longer
      necessary and either made static or removed.
    
    * bd_link_disk_holder() remains the same but bd_unlink_disk_holder()
      is no longer necessary and removed.
    
    * open_bdev_exclusive() becomes a simple wrapper around lookup_bdev()
      and blkdev_get().  It also has an unexpected extra bdev_read_only()
      test which probably should be moved into blkdev_get().
    
    * open_by_devnum() is modified to take @holder argument and pass it to
      blkdev_get().
    
    Most of bdev open/close operations are unified into blkdev_get/put()
    and most exclusive accesses are tested atomically at the open time (as
    it should).  This cleans up code and removes some, both valid and
    invalid, but unnecessary all the same, corner cases.
    
    open_bdev_exclusive() and open_by_devnum() can use further cleanup -
    rename to blkdev_get_by_path() and blkdev_get_by_devt() and drop
    special features.  Well, let's leave them for another day.
    
    Most conversions are straight-forward.  drbd conversion is a bit more
    involved as there was some reordering, but the logic should stay the
    same.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Neil Brown <neilb@suse.de>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Peter Osterlund <petero2@telia.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <joel.becker@oracle.com>
    Cc: Alex Elder <aelder@sgi.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: dm-devel@redhat.com
    Cc: drbd-dev@lists.linbit.com
    Cc: Leo Chen <leochen@broadcom.com>
    Cc: Scott Branden <sbranden@broadcom.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Cc: Joern Engel <joern@logfs.org>
    Cc: reiserfs-devel@vger.kernel.org
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 076c8b194682..b488136f5ace 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2552,8 +2552,6 @@ static int release_journal_dev(struct super_block *super,
 	result = 0;
 
 	if (journal->j_dev_bd != NULL) {
-		if (journal->j_dev_bd->bd_dev != super->s_dev)
-			bd_release(journal->j_dev_bd);
 		result = blkdev_put(journal->j_dev_bd, journal->j_dev_mode);
 		journal->j_dev_bd = NULL;
 	}
@@ -2571,7 +2569,7 @@ static int journal_init_dev(struct super_block *super,
 {
 	int result;
 	dev_t jdev;
-	fmode_t blkdev_mode = FMODE_READ | FMODE_WRITE;
+	fmode_t blkdev_mode = FMODE_READ | FMODE_WRITE | FMODE_EXCL;
 	char b[BDEVNAME_SIZE];
 
 	result = 0;
@@ -2585,7 +2583,9 @@ static int journal_init_dev(struct super_block *super,
 
 	/* there is no "jdev" option and journal is on separate device */
 	if ((!jdev_name || !jdev_name[0])) {
-		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode);
+		if (jdev == super->s_dev)
+			blkdev_mode &= ~FMODE_EXCL;
+		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode, journal);
 		journal->j_dev_mode = blkdev_mode;
 		if (IS_ERR(journal->j_dev_bd)) {
 			result = PTR_ERR(journal->j_dev_bd);
@@ -2594,15 +2594,8 @@ static int journal_init_dev(struct super_block *super,
 					 "cannot init journal device '%s': %i",
 					 __bdevname(jdev, b), result);
 			return result;
-		} else if (jdev != super->s_dev) {
-			result = bd_claim(journal->j_dev_bd, journal);
-			if (result) {
-				blkdev_put(journal->j_dev_bd, blkdev_mode);
-				return result;
-			}
-
+		} else if (jdev != super->s_dev)
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);
-		}
 
 		return 0;
 	}

commit 7cd33ad23ec41d685902159be8b2c6552fab8bd0
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Aug 18 05:29:14 2010 -0400

    reiserfs: replace barriers with explicit flush / FUA usage
    
    Switch to the WRITE_FLUSH_FUA flag for log writes and remove the EOPNOTSUPP
    detection for barriers.  Note that reiserfs had a fairly different code
    path for barriers before as it wa the only filesystem actually making use
    of them.  The new code always uses the old non-barrier codepath and just
    sets the WRITE_FLUSH_FUA explicitly for the journal commits.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Jan Kara <jack@suse.cz>
    Acked-by: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 812e2c05aa29..076c8b194682 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -138,13 +138,6 @@ static int reiserfs_clean_and_file_buffer(struct buffer_head *bh)
 	return 0;
 }
 
-static void disable_barrier(struct super_block *s)
-{
-	REISERFS_SB(s)->s_mount_opt &= ~(1 << REISERFS_BARRIER_FLUSH);
-	printk("reiserfs: disabling flush barriers on %s\n",
-	       reiserfs_bdevname(s));
-}
-
 static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
 							 *sb)
 {
@@ -677,30 +670,6 @@ static void submit_ordered_buffer(struct buffer_head *bh)
 	submit_bh(WRITE, bh);
 }
 
-static int submit_barrier_buffer(struct buffer_head *bh)
-{
-	get_bh(bh);
-	bh->b_end_io = reiserfs_end_ordered_io;
-	clear_buffer_dirty(bh);
-	if (!buffer_uptodate(bh))
-		BUG();
-	return submit_bh(WRITE_BARRIER, bh);
-}
-
-static void check_barrier_completion(struct super_block *s,
-				     struct buffer_head *bh)
-{
-	if (buffer_eopnotsupp(bh)) {
-		clear_buffer_eopnotsupp(bh);
-		disable_barrier(s);
-		set_buffer_uptodate(bh);
-		set_buffer_dirty(bh);
-		reiserfs_write_unlock(s);
-		sync_dirty_buffer(bh);
-		reiserfs_write_lock(s);
-	}
-}
-
 #define CHUNK_SIZE 32
 struct buffer_chunk {
 	struct buffer_head *bh[CHUNK_SIZE];
@@ -1009,7 +978,6 @@ static int flush_commit_list(struct super_block *s,
 	struct buffer_head *tbh = NULL;
 	unsigned int trans_id = jl->j_trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
-	int barrier = 0;
 	int retval = 0;
 	int write_len;
 
@@ -1094,24 +1062,6 @@ static int flush_commit_list(struct super_block *s,
 	}
 	atomic_dec(&journal->j_async_throttle);
 
-	/* We're skipping the commit if there's an error */
-	if (retval || reiserfs_is_journal_aborted(journal))
-		barrier = 0;
-
-	/* wait on everything written so far before writing the commit
-	 * if we are in barrier mode, send the commit down now
-	 */
-	barrier = reiserfs_barrier_flush(s);
-	if (barrier) {
-		int ret;
-		lock_buffer(jl->j_commit_bh);
-		ret = submit_barrier_buffer(jl->j_commit_bh);
-		if (ret == -EOPNOTSUPP) {
-			set_buffer_uptodate(jl->j_commit_bh);
-			disable_barrier(s);
-			barrier = 0;
-		}
-	}
 	for (i = 0; i < (jl->j_len + 1); i++) {
 		bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) +
 		    (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s);
@@ -1143,27 +1093,22 @@ static int flush_commit_list(struct super_block *s,
 
 	BUG_ON(atomic_read(&(jl->j_commit_left)) != 1);
 
-	if (!barrier) {
-		/* If there was a write error in the journal - we can't commit
-		 * this transaction - it will be invalid and, if successful,
-		 * will just end up propagating the write error out to
-		 * the file system. */
-		if (likely(!retval && !reiserfs_is_journal_aborted (journal))) {
-			if (buffer_dirty(jl->j_commit_bh))
-				BUG();
-			mark_buffer_dirty(jl->j_commit_bh) ;
-			reiserfs_write_unlock(s);
-			sync_dirty_buffer(jl->j_commit_bh) ;
-			reiserfs_write_lock(s);
-		}
-	} else {
+	/* If there was a write error in the journal - we can't commit
+	 * this transaction - it will be invalid and, if successful,
+	 * will just end up propagating the write error out to
+	 * the file system. */
+	if (likely(!retval && !reiserfs_is_journal_aborted (journal))) {
+		if (buffer_dirty(jl->j_commit_bh))
+			BUG();
+		mark_buffer_dirty(jl->j_commit_bh) ;
 		reiserfs_write_unlock(s);
-		wait_on_buffer(jl->j_commit_bh);
+		if (reiserfs_barrier_flush(s))
+			__sync_dirty_buffer(jl->j_commit_bh, WRITE_FLUSH_FUA);
+		else
+			sync_dirty_buffer(jl->j_commit_bh);
 		reiserfs_write_lock(s);
 	}
 
-	check_barrier_completion(s, jl->j_commit_bh);
-
 	/* If there was a write error in the journal - we can't commit this
 	 * transaction - it will be invalid and, if successful, will just end
 	 * up propagating the write error out to the filesystem. */
@@ -1319,26 +1264,15 @@ static int _update_journal_header_block(struct super_block *sb,
 		jh->j_first_unflushed_offset = cpu_to_le32(offset);
 		jh->j_mount_id = cpu_to_le32(journal->j_mount_id);
 
-		if (reiserfs_barrier_flush(sb)) {
-			int ret;
-			lock_buffer(journal->j_header_bh);
-			ret = submit_barrier_buffer(journal->j_header_bh);
-			if (ret == -EOPNOTSUPP) {
-				set_buffer_uptodate(journal->j_header_bh);
-				disable_barrier(sb);
-				goto sync;
-			}
-			reiserfs_write_unlock(sb);
-			wait_on_buffer(journal->j_header_bh);
-			reiserfs_write_lock(sb);
-			check_barrier_completion(sb, journal->j_header_bh);
-		} else {
-		      sync:
-			set_buffer_dirty(journal->j_header_bh);
-			reiserfs_write_unlock(sb);
+		set_buffer_dirty(journal->j_header_bh);
+		reiserfs_write_unlock(sb);
+
+		if (reiserfs_barrier_flush(sb))
+			__sync_dirty_buffer(journal->j_header_bh, WRITE_FLUSH_FUA);
+		else
 			sync_dirty_buffer(journal->j_header_bh);
-			reiserfs_write_lock(sb);
-		}
+
+		reiserfs_write_lock(sb);
 		if (!buffer_uptodate(journal->j_header_bh)) {
 			reiserfs_warning(sb, "journal-837",
 					 "IO error during journal replay");

commit 9cb569d601e0b93e01c20a22872270ec663b75f6
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 11 17:06:24 2010 +0200

    remove SWRITE* I/O types
    
    These flags aren't real I/O types, but tell ll_rw_block to always
    lock the buffer instead of giving up on a failed trylock.
    
    Instead add a new write_dirty_buffer helper that implements this semantic
    and use it from the existing SWRITE* callers.  Note that the ll_rw_block
    code had a bug where it didn't promote WRITE_SYNC_PLUG properly, which
    this patch fixes.
    
    In the ufs code clean up the helper that used to call ll_rw_block
    to mirror sync_dirty_buffer, which is the function it implements for
    compound buffers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 1ec952b1f036..812e2c05aa29 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2311,7 +2311,7 @@ static int journal_read_transaction(struct super_block *sb,
 	/* flush out the real blocks */
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		set_buffer_dirty(real_blocks[i]);
-		ll_rw_block(SWRITE, 1, real_blocks + i);
+		write_dirty_buffer(real_blocks[i], WRITE);
 	}
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(real_blocks[i]);

commit b3397ad544172fb34ddcff5b04704b6c80838289
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Tue Aug 10 18:02:48 2010 -0700

    reiserfs: remove unused local `wait'
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 19fbc810e8e7..1ec952b1f036 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -983,7 +983,6 @@ static int flush_older_commits(struct super_block *s,
 
 static int reiserfs_async_progress_wait(struct super_block *s)
 {
-	DEFINE_WAIT(wait);
 	struct reiserfs_journal *j = SB_JOURNAL(s);
 
 	if (atomic_read(&j->j_async_throttle)) {

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index f3de5e8a2ae8..19fbc810e8e7 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -50,6 +50,7 @@
 #include <linux/blkdev.h>
 #include <linux/backing-dev.h>
 #include <linux/uaccess.h>
+#include <linux/slab.h>
 
 #include <asm/system.h>
 

commit 3f8b5ee33293d43ca360771b535dfae8c57259dc
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Mar 23 13:35:39 2010 -0700

    reiserfs: properly honor read-only devices
    
    The reiserfs journal behaves inconsistently when determining whether to
    allow a mount of a read-only device.
    
    This is due to the use of the continue_replay variable to short circuit
    the journal scanning.  If it's set, it's assumed that there are
    transactions to replay, but there may not be.  If it's unset, it's assumed
    that there aren't any, and that may not be the case either.
    
    I've observed two failure cases:
    1) Where a clean file system on a read-only device refuses to mount
    2) Where a clean file system on a read-only device passes the
       optimization and then tries writing the journal header to update
       the latest mount id.
    
    The former is easily observable by using a freshly created file system on
    a read-only loopback device.
    
    This patch moves the check into journal_read_transaction, where it can
    bail out before it's about to replay a transaction.  That way it can go
    through and skip transactions where appropriate, yet still refuse to mount
    a file system with outstanding transactions.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ba98546fabbd..f3de5e8a2ae8 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2217,6 +2217,15 @@ static int journal_read_transaction(struct super_block *sb,
 		brelse(d_bh);
 		return 1;
 	}
+
+	if (bdev_read_only(sb->s_bdev)) {
+		reiserfs_warning(sb, "clm-2076",
+				 "device is readonly, unable to replay log");
+		brelse(c_bh);
+		brelse(d_bh);
+		return -EROFS;
+	}
+
 	trans_id = get_desc_trans_id(desc);
 	/* now we know we've got a good transaction, and it was inside the valid time ranges */
 	log_blocks = kmalloc(get_desc_trans_len(desc) *
@@ -2459,12 +2468,6 @@ static int journal_read(struct super_block *sb)
 		goto start_log_replay;
 	}
 
-	if (continue_replay && bdev_read_only(sb->s_bdev)) {
-		reiserfs_warning(sb, "clm-2076",
-				 "device is readonly, unable to replay log");
-		return -1;
-	}
-
 	/* ok, there are transactions that need to be replayed.  start with the first log block, find
 	 ** all the valid transactions, and pick out the oldest.
 	 */

commit bbec919150037b8a2e58e32d3ba642ba3b6582a5
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 28 13:43:50 2010 +0100

    reiserfs: Fix vmalloc call under reiserfs lock
    
    Vmalloc is called to allocate journal->j_cnode_free_list but
    we hold the reiserfs lock at this time, which raises a
    {RECLAIM_FS-ON-W} -> {IN-RECLAIM_FS-W} lock inversion.
    
    Just drop the reiserfs lock at this time, as it's not even
    needed but kept for paranoid reasons.
    
    This fixes:
    
    [ INFO: inconsistent lock state ]
    2.6.33-rc5 #1
    ---------------------------------
    inconsistent {RECLAIM_FS-ON-W} -> {IN-RECLAIM_FS-W} usage.
    kswapd0/313 [HC0[0]:SC0[0]:HE1:SE1] takes:
     (&REISERFS_SB(s)->lock){+.+.?.}, at: [<c11118c8>]
    reiserfs_write_lock_once+0x28/0x50
    {RECLAIM_FS-ON-W} state was registered at:
      [<c104ee32>] mark_held_locks+0x62/0x90
      [<c104eefa>] lockdep_trace_alloc+0x9a/0xc0
      [<c108f7b6>] kmem_cache_alloc+0x26/0xf0
      [<c108621c>] __get_vm_area_node+0x6c/0xf0
      [<c108690e>] __vmalloc_node+0x7e/0xa0
      [<c1086aab>] vmalloc+0x2b/0x30
      [<c110e1fb>] journal_init+0x6cb/0xa10
      [<c10f90a2>] reiserfs_fill_super+0x342/0xb80
      [<c1095665>] get_sb_bdev+0x145/0x180
      [<c10f68e1>] get_super_block+0x21/0x30
      [<c1094520>] vfs_kern_mount+0x40/0xd0
      [<c1094609>] do_kern_mount+0x39/0xd0
      [<c10aaa97>] do_mount+0x2c7/0x6d0
      [<c10aaf06>] sys_mount+0x66/0xa0
      [<c16198a7>] mount_block_root+0xc4/0x245
      [<c1619a81>] mount_root+0x59/0x5f
      [<c1619b98>] prepare_namespace+0x111/0x14b
      [<c1619269>] kernel_init+0xcf/0xdb
      [<c100303a>] kernel_thread_helper+0x6/0x1c
    irq event stamp: 63236801
    hardirqs last  enabled at (63236801): [<c134e7fa>]
    __mutex_unlock_slowpath+0x9a/0x120
    hardirqs last disabled at (63236800): [<c134e799>]
    __mutex_unlock_slowpath+0x39/0x120
    softirqs last  enabled at (63218800): [<c102f451>] __do_softirq+0xc1/0x110
    softirqs last disabled at (63218789): [<c102f4ed>] do_softirq+0x4d/0x60
    
    other info that might help us debug this:
    2 locks held by kswapd0/313:
     #0:  (shrinker_rwsem){++++..}, at: [<c1074bb4>] shrink_slab+0x24/0x170
     #1:  (&type->s_umount_key#19){++++..}, at: [<c10a2edd>]
    shrink_dcache_memory+0xfd/0x1a0
    
    stack backtrace:
    Pid: 313, comm: kswapd0 Not tainted 2.6.33-rc5 #1
    Call Trace:
     [<c134db2c>] ? printk+0x18/0x1c
     [<c104e7ef>] print_usage_bug+0x15f/0x1a0
     [<c104ebcf>] mark_lock+0x39f/0x5a0
     [<c104d66b>] ? trace_hardirqs_off+0xb/0x10
     [<c1052c50>] ? check_usage_forwards+0x0/0xf0
     [<c1050c24>] __lock_acquire+0x214/0xa70
     [<c10438c5>] ? sched_clock_cpu+0x95/0x110
     [<c10514fa>] lock_acquire+0x7a/0xa0
     [<c11118c8>] ? reiserfs_write_lock_once+0x28/0x50
     [<c134f03f>] mutex_lock_nested+0x5f/0x2b0
     [<c11118c8>] ? reiserfs_write_lock_once+0x28/0x50
     [<c11118c8>] ? reiserfs_write_lock_once+0x28/0x50
     [<c11118c8>] reiserfs_write_lock_once+0x28/0x50
     [<c10f05b0>] reiserfs_delete_inode+0x50/0x140
     [<c10a653f>] ? generic_delete_inode+0x5f/0x150
     [<c10f0560>] ? reiserfs_delete_inode+0x0/0x140
     [<c10a657c>] generic_delete_inode+0x9c/0x150
     [<c10a666d>] generic_drop_inode+0x3d/0x60
     [<c10a5597>] iput+0x47/0x50
     [<c10a2a4f>] dentry_iput+0x6f/0xf0
     [<c10a2af4>] d_kill+0x24/0x50
     [<c10a2d3d>] __shrink_dcache_sb+0x21d/0x2b0
     [<c10a2f0f>] shrink_dcache_memory+0x12f/0x1a0
     [<c1074c9e>] shrink_slab+0x10e/0x170
     [<c1075177>] kswapd+0x477/0x6a0
     [<c1072d10>] ? isolate_pages_global+0x0/0x1b0
     [<c103e160>] ? autoremove_wake_function+0x0/0x40
     [<c1074d00>] ? kswapd+0x0/0x6a0
     [<c103de6c>] kthread+0x6c/0x80
     [<c103de00>] ? kthread+0x0/0x80
     [<c100303a>] kernel_thread_helper+0x6/0x1c
    
    Reported-by: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Christian Kujau <lists@nerdbynature.de>
    Cc: Chris Mason <chris.mason@oracle.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 83ac4d3b3cb0..ba98546fabbd 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2913,7 +2913,9 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	journal->j_mount_id = 10;
 	journal->j_state = 0;
 	atomic_set(&(journal->j_jlock), 0);
+	reiserfs_write_unlock(sb);
 	journal->j_cnode_free_list = allocate_cnodes(num_cnodes);
+	reiserfs_write_lock(sb);
 	journal->j_cnode_free_orig = journal->j_cnode_free_list;
 	journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0;
 	journal->j_cnode_used = 0;

commit 0523676d3f3aa7edeea63cc3a1bc4dc612380a26
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Dec 30 05:56:08 2009 +0100

    reiserfs: Relax reiserfs lock while freeing the journal
    
    Keeping the reiserfs lock while freeing the journal on
    umount path triggers a lock inversion between bdev->bd_mutex
    and the reiserfs lock.
    
    We don't need the reiserfs lock at this stage. The filesystem
    is not usable anymore, and there are no more pending commits,
    everything got flushed (even this operation was done in parallel
    and didn't required the reiserfs lock from the current process).
    
    This fixes the following lockdep report:
    
    =======================================================
    [ INFO: possible circular locking dependency detected ]
    2.6.32-atom #172
    -------------------------------------------------------
    umount/3904 is trying to acquire lock:
     (&bdev->bd_mutex){+.+.+.}, at: [<c10de2c2>] __blkdev_put+0x22/0x160
    
    but task is already holding lock:
     (&REISERFS_SB(s)->lock){+.+.+.}, at: [<c1143279>] reiserfs_write_lock+0x29/0x40
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #3 (&REISERFS_SB(s)->lock){+.+.+.}:
           [<c105ea7f>] __lock_acquire+0x11ff/0x19e0
           [<c105f2c8>] lock_acquire+0x68/0x90
           [<c140199b>] mutex_lock_nested+0x5b/0x340
           [<c1143229>] reiserfs_write_lock_once+0x29/0x50
           [<c111c485>] reiserfs_get_block+0x85/0x1620
           [<c10e1040>] do_mpage_readpage+0x1f0/0x6d0
           [<c10e1640>] mpage_readpages+0xc0/0x100
           [<c1119b89>] reiserfs_readpages+0x19/0x20
           [<c108f1ec>] __do_page_cache_readahead+0x1bc/0x260
           [<c108f2b8>] ra_submit+0x28/0x40
           [<c1087e3e>] filemap_fault+0x40e/0x420
           [<c109b5fd>] __do_fault+0x3d/0x430
           [<c109d47e>] handle_mm_fault+0x12e/0x790
           [<c1022a65>] do_page_fault+0x135/0x330
           [<c1403663>] error_code+0x6b/0x70
           [<c10ef9ca>] load_elf_binary+0x82a/0x1a10
           [<c10ba130>] search_binary_handler+0x90/0x1d0
           [<c10bb70f>] do_execve+0x1df/0x250
           [<c1001746>] sys_execve+0x46/0x70
           [<c1002fa5>] syscall_call+0x7/0xb
    
    -> #2 (&mm->mmap_sem){++++++}:
           [<c105ea7f>] __lock_acquire+0x11ff/0x19e0
           [<c105f2c8>] lock_acquire+0x68/0x90
           [<c109b1ab>] might_fault+0x8b/0xb0
           [<c11b8f52>] copy_to_user+0x32/0x70
           [<c10c3b94>] filldir64+0xa4/0xf0
           [<c1109116>] sysfs_readdir+0x116/0x210
           [<c10c3e1d>] vfs_readdir+0x8d/0xb0
           [<c10c3ea9>] sys_getdents64+0x69/0xb0
           [<c1002ec4>] sysenter_do_call+0x12/0x32
    
    -> #1 (sysfs_mutex){+.+.+.}:
           [<c105ea7f>] __lock_acquire+0x11ff/0x19e0
           [<c105f2c8>] lock_acquire+0x68/0x90
           [<c140199b>] mutex_lock_nested+0x5b/0x340
           [<c110951c>] sysfs_addrm_start+0x2c/0xb0
           [<c1109aa0>] create_dir+0x40/0x90
           [<c1109b1b>] sysfs_create_dir+0x2b/0x50
           [<c11b2352>] kobject_add_internal+0xc2/0x1b0
           [<c11b2531>] kobject_add_varg+0x31/0x50
           [<c11b25ac>] kobject_add+0x2c/0x60
           [<c1258294>] device_add+0x94/0x560
           [<c11036ea>] add_partition+0x18a/0x2a0
           [<c110418a>] rescan_partitions+0x33a/0x450
           [<c10de5bf>] __blkdev_get+0x12f/0x2d0
           [<c10de76a>] blkdev_get+0xa/0x10
           [<c11034b8>] register_disk+0x108/0x130
           [<c11a87a9>] add_disk+0xd9/0x130
           [<c12998e5>] sd_probe_async+0x105/0x1d0
           [<c10528af>] async_thread+0xcf/0x230
           [<c104bfd4>] kthread+0x74/0x80
           [<c1003aab>] kernel_thread_helper+0x7/0x3c
    
    -> #0 (&bdev->bd_mutex){+.+.+.}:
           [<c105f176>] __lock_acquire+0x18f6/0x19e0
           [<c105f2c8>] lock_acquire+0x68/0x90
           [<c140199b>] mutex_lock_nested+0x5b/0x340
           [<c10de2c2>] __blkdev_put+0x22/0x160
           [<c10de40a>] blkdev_put+0xa/0x10
           [<c113ce22>] free_journal_ram+0xd2/0x130
           [<c113ea18>] do_journal_release+0x98/0x190
           [<c113eb2a>] journal_release+0xa/0x10
           [<c1128eb6>] reiserfs_put_super+0x36/0x130
           [<c10b776f>] generic_shutdown_super+0x4f/0xe0
           [<c10b7825>] kill_block_super+0x25/0x40
           [<c11255df>] reiserfs_kill_sb+0x7f/0x90
           [<c10b7f4a>] deactivate_super+0x7a/0x90
           [<c10cccd8>] mntput_no_expire+0x98/0xd0
           [<c10ccfcc>] sys_umount+0x4c/0x310
           [<c10cd2a9>] sys_oldumount+0x19/0x20
           [<c1002ec4>] sysenter_do_call+0x12/0x32
    
    other info that might help us debug this:
    
    2 locks held by umount/3904:
     #0:  (&type->s_umount_key#30){+++++.}, at: [<c10b7f45>] deactivate_super+0x75/0x90
     #1:  (&REISERFS_SB(s)->lock){+.+.+.}, at: [<c1143279>] reiserfs_write_lock+0x29/0x40
    
    stack backtrace:
    Pid: 3904, comm: umount Not tainted 2.6.32-atom #172
    Call Trace:
     [<c13ff903>] ? printk+0x18/0x1a
     [<c105d33a>] print_circular_bug+0xca/0xd0
     [<c105f176>] __lock_acquire+0x18f6/0x19e0
     [<c108b66f>] ? free_pcppages_bulk+0x1f/0x250
     [<c105f2c8>] lock_acquire+0x68/0x90
     [<c10de2c2>] ? __blkdev_put+0x22/0x160
     [<c10de2c2>] ? __blkdev_put+0x22/0x160
     [<c140199b>] mutex_lock_nested+0x5b/0x340
     [<c10de2c2>] ? __blkdev_put+0x22/0x160
     [<c105c932>] ? mark_held_locks+0x62/0x80
     [<c10afe12>] ? kfree+0x92/0xd0
     [<c10de2c2>] __blkdev_put+0x22/0x160
     [<c105cc3b>] ? trace_hardirqs_on+0xb/0x10
     [<c10de40a>] blkdev_put+0xa/0x10
     [<c113ce22>] free_journal_ram+0xd2/0x130
     [<c113ea18>] do_journal_release+0x98/0x190
     [<c113eb2a>] journal_release+0xa/0x10
     [<c1128eb6>] reiserfs_put_super+0x36/0x130
     [<c1050596>] ? up_write+0x16/0x30
     [<c10b776f>] generic_shutdown_super+0x4f/0xe0
     [<c10b7825>] kill_block_super+0x25/0x40
     [<c10f41e0>] ? vfs_quota_off+0x0/0x20
     [<c11255df>] reiserfs_kill_sb+0x7f/0x90
     [<c10b7f4a>] deactivate_super+0x7a/0x90
     [<c10cccd8>] mntput_no_expire+0x98/0xd0
     [<c10ccfcc>] sys_umount+0x4c/0x310
     [<c10cd2a9>] sys_oldumount+0x19/0x20
     [<c1002ec4>] sysenter_do_call+0x12/0x32
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a059879667b1..83ac4d3b3cb0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2009,10 +2009,11 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 		destroy_workqueue(commit_wq);
 		commit_wq = NULL;
 	}
-	reiserfs_write_lock(sb);
 
 	free_journal_ram(sb);
 
+	reiserfs_write_lock(sb);
+
 	return 0;
 }
 

commit 98ea3f50bcc97689cc0e1fa3b6733f03aeb8fef4
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Dec 29 21:51:15 2009 +0100

    reiserfs: Fix remaining in-reclaim-fs <-> reclaim-fs-on locking inversion
    
    Commit 500f5a0bf5f0624dae34307010e240ec090e4cde
    (reiserfs: Fix possible recursive lock) fixed a vmalloc under reiserfs
    lock that triggered a lockdep warning because of a
    IN-FS-RECLAIM <-> RECLAIM-FS-ON locking dependency inversion.
    
    But this patch has ommitted another vmalloc call in the same path
    that allocates the journal. Relax the lock for this one too.
    
    Reported-by: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 2f8a7e7b8dab..a059879667b1 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2758,11 +2758,18 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	struct reiserfs_journal *journal;
 	struct reiserfs_journal_list *jl;
 	char b[BDEVNAME_SIZE];
+	int ret;
 
+	/*
+	 * Unlock here to avoid various RECLAIM-FS-ON <-> IN-RECLAIM-FS
+	 * dependency inversion warnings.
+	 */
+	reiserfs_write_unlock(sb);
 	journal = SB_JOURNAL(sb) = vmalloc(sizeof(struct reiserfs_journal));
 	if (!journal) {
 		reiserfs_warning(sb, "journal-1256",
 				 "unable to get memory for journal structure");
+		reiserfs_write_lock(sb);
 		return 1;
 	}
 	memset(journal, 0, sizeof(struct reiserfs_journal));
@@ -2771,10 +2778,12 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	INIT_LIST_HEAD(&journal->j_working_list);
 	INIT_LIST_HEAD(&journal->j_journal_list);
 	journal->j_persistent_trans = 0;
-	if (reiserfs_allocate_list_bitmaps(sb,
-					   journal->j_list_bitmap,
-					   reiserfs_bmap_count(sb)))
+	ret = reiserfs_allocate_list_bitmaps(sb, journal->j_list_bitmap,
+					   reiserfs_bmap_count(sb));
+	reiserfs_write_lock(sb);
+	if (ret)
 		goto free_and_return;
+
 	allocate_bitmap_nodes(sb);
 
 	/* reserved for journal area support */

commit 48f6ba5e691948caba2e7bc362153fb28e4f1e09
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Oct 5 16:31:37 2009 +0200

    kill-the-bkl/reiserfs: fix reiserfs lock to cpu_add_remove_lock dependency
    
    While creating the reiserfs workqueue during the journal
    initialization, we are holding the reiserfs lock, but
    create_workqueue() also holds the cpu_add_remove_lock, creating
    then the following dependency:
    
    - reiserfs lock -> cpu_add_remove_lock
    
    But we also have the following existing dependencies:
    
    - mm->mmap_sem -> reiserfs lock
    - cpu_add_remove_lock -> cpu_hotplug.lock -> slub_lock -> sysfs_mutex
    
    The merged dependency chain then becomes:
    
    - mm->mmap_sem -> reiserfs lock -> cpu_add_remove_lock ->
            cpu_hotplug.lock -> slub_lock -> sysfs_mutex
    
    But when we fill a dir entry in sysfs_readir(), we are holding the
    sysfs_mutex and we also might fault while copying the directory entry
    to the user, leading to the following dependency:
    
    - sysfs_mutex -> mm->mmap_sem
    
    The end result is then a lock inversion between sysfs_mutex and
    mm->mmap_sem, as reported in the following lockdep warning:
    
    [ INFO: possible circular locking dependency detected ]
    2.6.31-07095-g25a3912 #4
    -------------------------------------------------------
    udevadm/790 is trying to acquire lock:
     (&mm->mmap_sem){++++++}, at: [<c1098942>] might_fault+0x72/0xc0
    
    but task is already holding lock:
     (sysfs_mutex){+.+.+.}, at: [<c110813c>] sysfs_readdir+0x7c/0x260
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #5 (sysfs_mutex){+.+.+.}:
          [...]
    
    -> #4 (slub_lock){+++++.}:
          [...]
    
    -> #3 (cpu_hotplug.lock){+.+.+.}:
          [...]
    
    -> #2 (cpu_add_remove_lock){+.+.+.}:
          [...]
    
    -> #1 (&REISERFS_SB(s)->lock){+.+.+.}:
          [...]
    
    -> #0 (&mm->mmap_sem){++++++}:
          [...]
    
    This can be fixed by relaxing the reiserfs lock while creating the
    workqueue.
    This is fine to relax the lock here, we just keep it around to pass
    through reiserfs lock checks and for paranoid reasons.
    
    Reported-by: Alexander Beregalov <a.beregalov@gmail.com>
    Tested-by: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Cc: Laurent Riffard <laurent.riffard@free.fr>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 04e3c42a085f..2f8a7e7b8dab 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2933,8 +2933,11 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 	}
 
 	reiserfs_mounted_fs_count++;
-	if (reiserfs_mounted_fs_count <= 1)
+	if (reiserfs_mounted_fs_count <= 1) {
+		reiserfs_write_unlock(sb);
 		commit_wq = create_workqueue("reiserfs");
+		reiserfs_write_lock(sb);
+	}
 
 	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
 	journal->j_work_sb = sb;

commit 193be0ee17dd7ea309ddab1093da17e5924d7f36
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Sep 17 05:31:37 2009 +0200

    kill-the-bkl/reiserfs: Fix induced mm->mmap_sem to sysfs_mutex dependency
    
    Alexander Beregalov reported the following warning:
    
            =======================================================
            [ INFO: possible circular locking dependency detected ]
            2.6.31-03149-gdcc030a #1
            -------------------------------------------------------
            udevadm/716 is trying to acquire lock:
             (&mm->mmap_sem){++++++}, at: [<c107249a>] might_fault+0x4a/0xa0
    
            but task is already holding lock:
             (sysfs_mutex){+.+.+.}, at: [<c10cb9aa>] sysfs_readdir+0x5a/0x200
    
            which lock already depends on the new lock.
    
            the existing dependency chain (in reverse order) is:
    
            -> #3 (sysfs_mutex){+.+.+.}:
                   [...]
    
            -> #2 (&bdev->bd_mutex){+.+.+.}:
                   [...]
    
            -> #1 (&REISERFS_SB(s)->lock){+.+.+.}:
                   [...]
    
            -> #0 (&mm->mmap_sem){++++++}:
                   [...]
    
    On reiserfs mount path, we take the reiserfs lock and while
    initializing the journal, we open the device, taking the
    bdev->bd_mutex. Then rescan_partition() may signal the change
    to sysfs.
    
    We have then the following dependency:
    
            reiserfs_lock -> bd_mutex -> sysfs_mutex
    
    Later, while entering reiserfs_readpage() after a pagefault in an
    mmaped reiserfs file, we are holding the mm->mmap_sem, and we are going
    to take the reiserfs lock too.
    We have then the following dependency:
    
            mm->mmap_sem -> reiserfs_lock
    
    which, expanded with the previous dependency gives us:
    
            mm->mmap_sem -> reiserfs_lock -> bd_mutex -> sysfs_mutex
    
    Now while entering the sysfs readdir path, we are holding the
    sysfs_mutex. And when we copy a directory entry to the user buffer, we
    might fault and then take the mm->mmap_sem lock. Which leads to the
    circular locking dependency reported.
    
    We can fix that by relaxing the reiserfs lock during the call to
    journal_init_dev(), which is the place where we open the mounted
    device.
    
    This is fine to relax the lock here because we are in the begining of
    the reiserfs mount path and there is nothing to protect at this time,
    the journal is not intialized.
    We just keep this lock around for paranoid reasons.
    
    Reported-by: Alexander Beregalov <a.beregalov@gmail.com>
    Tested-by: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Cc: Laurent Riffard <laurent.riffard@free.fr>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index d23d6d7a45a6..04e3c42a085f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2801,11 +2801,27 @@ int journal_init(struct super_block *sb, const char *j_dev_name,
 		goto free_and_return;
 	}
 
+	/*
+	 * We need to unlock here to avoid creating the following
+	 * dependency:
+	 * reiserfs_lock -> sysfs_mutex
+	 * Because the reiserfs mmap path creates the following dependency:
+	 * mm->mmap -> reiserfs_lock, hence we have
+	 * mm->mmap -> reiserfs_lock ->sysfs_mutex
+	 * This would ends up in a circular dependency with sysfs readdir path
+	 * which does sysfs_mutex -> mm->mmap_sem
+	 * This is fine because the reiserfs lock is useless in mount path,
+	 * at least until we call journal_begin. We keep it for paranoid
+	 * reasons.
+	 */
+	reiserfs_write_unlock(sb);
 	if (journal_init_dev(sb, journal, j_dev_name) != 0) {
+		reiserfs_write_lock(sb);
 		reiserfs_warning(sb, "sh-462",
 				 "unable to initialize jornal device");
 		goto free_and_return;
 	}
+	reiserfs_write_lock(sb);
 
 	rs = SB_DISK_SUPER_BLOCK(sb);
 

commit c72e05756b900b3be24cd73a16de52bab80984c0
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat May 16 18:12:08 2009 +0200

    kill-the-bkl/reiserfs: acquire the inode mutex safely
    
    While searching a pathname, an inode mutex can be acquired
    in do_lookup() which calls reiserfs_lookup() which in turn
    acquires the write lock.
    
    On the other side reiserfs_fill_super() can acquire the write_lock
    and then call reiserfs_lookup_privroot() which can acquire an
    inode mutex (the root of the mount point).
    
    So we theoretically risk an AB - BA lock inversion that could lead
    to a deadlock.
    
    As for other lock dependencies found since the bkl to mutex
    conversion, the fix is to use reiserfs_mutex_lock_safe() which
    drops the lock dependency to the write lock.
    
    [ Impact: fix a possible deadlock with reiserfs ]
    
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e9a972bd0323..d23d6d7a45a6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -537,40 +537,6 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 	journal_hash(table, cn->sb, cn->blocknr) = cn;
 }
 
-/*
- * Several mutexes depend on the write lock.
- * However sometimes we want to relax the write lock while we hold
- * these mutexes, according to the release/reacquire on schedule()
- * properties of the Bkl that were used.
- * Reiserfs performances and locking were based on this scheme.
- * Now that the write lock is a mutex and not the bkl anymore, doing so
- * may result in a deadlock:
- *
- * A acquire write_lock
- * A acquire j_commit_mutex
- * A release write_lock and wait for something
- * B acquire write_lock
- * B can't acquire j_commit_mutex and sleep
- * A can't acquire write lock anymore
- * deadlock
- *
- * What we do here is avoiding such deadlock by playing the same game
- * than the Bkl: if we can't acquire a mutex that depends on the write lock,
- * we release the write lock, wait a bit and then retry.
- *
- * The mutexes concerned by this hack are:
- * - The commit mutex of a journal list
- * - The flush mutex
- * - The journal lock
- */
-static inline void reiserfs_mutex_lock_safe(struct mutex *m,
-			       struct super_block *s)
-{
-	reiserfs_write_unlock(s);
-	mutex_lock(m);
-	reiserfs_write_lock(s);
-}
-
 /* lock the current transaction */
 static inline void lock_journal(struct super_block *sb)
 {

commit c63e3c0b2498adec921b06c670d12c8c74b85538
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri May 8 20:01:09 2009 +0200

    kill-the-bkl/reiserfs: use mutex_lock in reiserfs_mutex_lock_safe
    
    reiserfs_mutex_lock_safe() is a hack to avoid any dependency between
    an internal reiserfs mutex and the write lock, it has been proposed
    to follow the old bkl logic.
    
    The code does the following:
    
    while (!mutex_trylock(m)) {
            reiserfs_write_unlock(s);
            schedule();
            reiserfs_write_lock(s);
    }
    
    It then imitate the implicit behaviour of the lock when it was
    a Bkl and hadn't such dependency:
    
    mutex_lock(m) {
            if (fastpath)
                    let's go
            else {
                    wait_for_mutex() {
                            schedule() {
                                    unlock_kernel()
                                    reacquire_lock_kernel()
                            }
                    }
            }
    }
    
    The problem is that by using such explicit schedule(), we don't
    benefit of the adaptive mutex spinning on owner.
    
    The logic in use now is:
    
    reiserfs_write_unlock(s);
    mutex_lock(m); // -> possible adaptive spinning
    reiserfs_write_lock(s);
    
    [ Impact: restore the use of adaptive spinning mutexes in reiserfs ]
    
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ffb7f50abc2f..e9a972bd0323 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -566,11 +566,9 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 static inline void reiserfs_mutex_lock_safe(struct mutex *m,
 			       struct super_block *s)
 {
-	while (!mutex_trylock(m)) {
-		reiserfs_write_unlock(s);
-		schedule();
-		reiserfs_write_lock(s);
-	}
+	reiserfs_write_unlock(s);
+	mutex_lock(m);
+	reiserfs_write_lock(s);
 }
 
 /* lock the current transaction */

commit 6e3647acb4f200add1d8e0203514f7ac925ae463
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri May 1 02:27:39 2009 +0200

    kill-the-BKL/reiserfs: release the write lock on flush_commit_list()
    
    flush_commit_list() uses ll_rw_block() to commit the pending log blocks.
    ll_rw_block() might sleep, and the bkl was released at this point. Then
    we can also relax the write lock at this point.
    
    [ Impact: release the reiserfs write lock when it is not needed ]
    
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 5cd600baf8cf..ffb7f50abc2f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1120,8 +1120,11 @@ static int flush_commit_list(struct super_block *s,
 		    SB_ONDISK_JOURNAL_SIZE(s);
 		tbh = journal_find_get_block(s, bn);
 		if (tbh) {
-			if (buffer_dirty(tbh))
-			    ll_rw_block(WRITE, 1, &tbh) ;
+			if (buffer_dirty(tbh)) {
+		            reiserfs_write_unlock(s);
+			    ll_rw_block(WRITE, 1, &tbh);
+			    reiserfs_write_lock(s);
+			}
 			put_bh(tbh) ;
 		}
 	}

commit e6950a4da33fa84ef4402d29e2331cd5e5df9cb8
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Apr 30 23:04:32 2009 +0200

    kill-the-BKL/reiserfs: release the write lock before rescheduling on do_journal_end()
    
    When do_journal_end() copies data to the journal blocks buffers in memory,
    it reschedules if needed between each block copied and dirtyfied.
    
    We can also release the write lock at this rescheduling stage,
    like did the bkl implicitly.
    
    [ Impact: release the reiserfs write lock when it is not needed ]
    
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Alexander Beregalov <a.beregalov@gmail.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 0ba98ca367c7..5cd600baf8cf 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -4232,7 +4232,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		next = cn->next;
 		free_cnode(sb, cn);
 		cn = next;
+		reiserfs_write_unlock(sb);
 		cond_resched();
+		reiserfs_write_lock(sb);
 	}
 
 	/* we are done  with both the c_bh and d_bh, but

commit a412f9efdd6424bf4bf28c8e8c92060b5e975482
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Apr 14 00:10:35 2009 +0200

    reiserfs, kill-the-BKL: fix unsafe j_flush_mutex lock
    
    Impact: fix a deadlock
    
    The j_flush_mutex is acquired safely in journal.c:
    if we can't take it, we free the reiserfs per superblock lock
    and wait a bit.
    
    But we have a remaining place in kupdate_transactions() where
    j_flush_mutex is still acquired traditionnaly. Thus the following
    scenario (warned by lockdep) can happen:
    
    A                                               B
    
    mutex_lock(&write_lock)                 mutex_lock(&write_lock)
            mutex_lock(&j_flush_mutex)      mutex_lock(&j_flush_mutex) //block
            mutex_unlock(&write_lock)
            sleep...
            mutex_lock(&write_lock) //deadlock
    
    Fix this by using reiserfs_mutex_lock_safe() in kupdate_transactions().
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Alessio Igor Bogani <abogani@texware.it>
    Cc: Jeff Mahoney <jeffm@suse.com>
    LKML-Reference: <1239660635-12940-1-git-send-email-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 438c71f0bc91..0ba98ca367c7 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1826,7 +1826,7 @@ static int kupdate_transactions(struct super_block *s,
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	chunk.nr = 0;
 
-	mutex_lock(&journal->j_flush_mutex);
+	reiserfs_mutex_lock_safe(&journal->j_flush_mutex, s);
 	if (!journal_list_still_alive(s, orig_trans_id)) {
 		goto done;
 	}

commit 8ebc423238341b52912c7295b045a32477b33f09
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Apr 7 04:19:49 2009 +0200

    reiserfs: kill-the-BKL
    
    This patch is an attempt to remove the Bkl based locking scheme from
    reiserfs and is intended.
    
    It is a bit inspired from an old attempt by Peter Zijlstra:
    
       http://lkml.indiana.edu/hypermail/linux/kernel/0704.2/2174.html
    
    The bkl is heavily used in this filesystem to prevent from
    concurrent write accesses on the filesystem.
    
    Reiserfs makes a deep use of the specific properties of the Bkl:
    
    - It can be acqquired recursively by a same task
    - It is released on the schedule() calls and reacquired when schedule() returns
    
    The two properties above are a roadmap for the reiserfs write locking so it's
    very hard to simply replace it with a common mutex.
    
    - We need a recursive-able locking unless we want to restructure several blocks
      of the code.
    - We need to identify the sites where the bkl was implictly relaxed
      (schedule, wait, sync, etc...) so that we can in turn release and
      reacquire our new lock explicitly.
      Such implicit releases of the lock are often required to let other
      resources producer/consumer do their job or we can suffer unexpected
      starvations or deadlocks.
    
    So the new lock that replaces the bkl here is a per superblock mutex with a
    specific property: it can be acquired recursively by a same task, like the
    bkl.
    
    For such purpose, we integrate a lock owner and a lock depth field on the
    superblock information structure.
    
    The first axis on this patch is to turn reiserfs_write_(un)lock() function
    into a wrapper to manage this mutex. Also some explicit calls to
    lock_kernel() have been converted to reiserfs_write_lock() helpers.
    
    The second axis is to find the important blocking sites (schedule...(),
    wait_on_buffer(), sync_dirty_buffer(), etc...) and then apply an explicit
    release of the write lock on these locations before blocking. Then we can
    safely wait for those who can give us resources or those who need some.
    Typically this is a fight between the current writer, the reiserfs workqueue
    (aka the async commiter) and the pdflush threads.
    
    The third axis is a consequence of the second. The write lock is usually
    on top of a lock dependency chain which can include the journal lock, the
    flush lock or the commit lock. So it's dangerous to release and trying to
    reacquire the write lock while we still hold other locks.
    
    This is fine with the bkl:
    
          T1                       T2
    
    lock_kernel()
        mutex_lock(A)
        unlock_kernel()
        // do something
                                lock_kernel()
                                    mutex_lock(A) -> already locked by T1
                                    schedule() (and then unlock_kernel())
        lock_kernel()
        mutex_unlock(A)
        ....
    
    This is not fine with a mutex:
    
          T1                       T2
    
    mutex_lock(write)
        mutex_lock(A)
        mutex_unlock(write)
        // do something
                               mutex_lock(write)
                                  mutex_lock(A) -> already locked by T1
                                  schedule()
    
        mutex_lock(write) -> already locked by T2
        deadlock
    
    The solution in this patch is to provide a helper which releases the write
    lock and sleep a bit if we can't lock a mutex that depend on it. It's another
    simulation of the bkl behaviour.
    
    The last axis is to locate the fs callbacks that are called with the bkl held,
    according to Documentation/filesystem/Locking.
    
    Those are:
    
    - reiserfs_remount
    - reiserfs_fill_super
    - reiserfs_put_super
    
    Reiserfs didn't need to explicitly lock because of the context of these callbacks.
    But now we must take care of that with the new locking.
    
    After this patch, reiserfs suffers from a slight performance regression (for now).
    On UP, a high volume write with dd reports an average of 27 MB/s instead
    of 30 MB/s without the patch applied.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Bron Gondwana <brong@fastmail.fm>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    LKML-Reference: <1239070789-13354-1-git-send-email-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 90622200b39c..438c71f0bc91 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -429,21 +429,6 @@ static void clear_prepared_bits(struct buffer_head *bh)
 	clear_buffer_journal_restore_dirty(bh);
 }
 
-/* utility function to force a BUG if it is called without the big
-** kernel lock held.  caller is the string printed just before calling BUG()
-*/
-void reiserfs_check_lock_depth(struct super_block *sb, char *caller)
-{
-#ifdef CONFIG_SMP
-	if (current->lock_depth < 0) {
-		reiserfs_panic(sb, "journal-1", "%s called without kernel "
-			       "lock held", caller);
-	}
-#else
-	;
-#endif
-}
-
 /* return a cnode with same dev, block number and size in table, or null if not found */
 static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
 								  super_block
@@ -552,11 +537,48 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 	journal_hash(table, cn->sb, cn->blocknr) = cn;
 }
 
+/*
+ * Several mutexes depend on the write lock.
+ * However sometimes we want to relax the write lock while we hold
+ * these mutexes, according to the release/reacquire on schedule()
+ * properties of the Bkl that were used.
+ * Reiserfs performances and locking were based on this scheme.
+ * Now that the write lock is a mutex and not the bkl anymore, doing so
+ * may result in a deadlock:
+ *
+ * A acquire write_lock
+ * A acquire j_commit_mutex
+ * A release write_lock and wait for something
+ * B acquire write_lock
+ * B can't acquire j_commit_mutex and sleep
+ * A can't acquire write lock anymore
+ * deadlock
+ *
+ * What we do here is avoiding such deadlock by playing the same game
+ * than the Bkl: if we can't acquire a mutex that depends on the write lock,
+ * we release the write lock, wait a bit and then retry.
+ *
+ * The mutexes concerned by this hack are:
+ * - The commit mutex of a journal list
+ * - The flush mutex
+ * - The journal lock
+ */
+static inline void reiserfs_mutex_lock_safe(struct mutex *m,
+			       struct super_block *s)
+{
+	while (!mutex_trylock(m)) {
+		reiserfs_write_unlock(s);
+		schedule();
+		reiserfs_write_lock(s);
+	}
+}
+
 /* lock the current transaction */
 static inline void lock_journal(struct super_block *sb)
 {
 	PROC_INFO_INC(sb, journal.lock_journal);
-	mutex_lock(&SB_JOURNAL(sb)->j_mutex);
+
+	reiserfs_mutex_lock_safe(&SB_JOURNAL(sb)->j_mutex, sb);
 }
 
 /* unlock the current transaction */
@@ -708,7 +730,9 @@ static void check_barrier_completion(struct super_block *s,
 		disable_barrier(s);
 		set_buffer_uptodate(bh);
 		set_buffer_dirty(bh);
+		reiserfs_write_unlock(s);
 		sync_dirty_buffer(bh);
+		reiserfs_write_lock(s);
 	}
 }
 
@@ -996,8 +1020,13 @@ static int reiserfs_async_progress_wait(struct super_block *s)
 {
 	DEFINE_WAIT(wait);
 	struct reiserfs_journal *j = SB_JOURNAL(s);
-	if (atomic_read(&j->j_async_throttle))
+
+	if (atomic_read(&j->j_async_throttle)) {
+		reiserfs_write_unlock(s);
 		congestion_wait(BLK_RW_ASYNC, HZ / 10);
+		reiserfs_write_lock(s);
+	}
+
 	return 0;
 }
 
@@ -1043,7 +1072,8 @@ static int flush_commit_list(struct super_block *s,
 	}
 
 	/* make sure nobody is trying to flush this one at the same time */
-	mutex_lock(&jl->j_commit_mutex);
+	reiserfs_mutex_lock_safe(&jl->j_commit_mutex, s);
+
 	if (!journal_list_still_alive(s, trans_id)) {
 		mutex_unlock(&jl->j_commit_mutex);
 		goto put_jl;
@@ -1061,12 +1091,17 @@ static int flush_commit_list(struct super_block *s,
 
 	if (!list_empty(&jl->j_bh_list)) {
 		int ret;
-		unlock_kernel();
+
+		/*
+		 * We might sleep in numerous places inside
+		 * write_ordered_buffers. Relax the write lock.
+		 */
+		reiserfs_write_unlock(s);
 		ret = write_ordered_buffers(&journal->j_dirty_buffers_lock,
 					    journal, jl, &jl->j_bh_list);
 		if (ret < 0 && retval == 0)
 			retval = ret;
-		lock_kernel();
+		reiserfs_write_lock(s);
 	}
 	BUG_ON(!list_empty(&jl->j_bh_list));
 	/*
@@ -1114,12 +1149,19 @@ static int flush_commit_list(struct super_block *s,
 		bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) +
 		    (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s);
 		tbh = journal_find_get_block(s, bn);
+
+		reiserfs_write_unlock(s);
 		wait_on_buffer(tbh);
+		reiserfs_write_lock(s);
 		// since we're using ll_rw_blk above, it might have skipped over
 		// a locked buffer.  Double check here
 		//
-		if (buffer_dirty(tbh))	/* redundant, sync_dirty_buffer() checks */
+		/* redundant, sync_dirty_buffer() checks */
+		if (buffer_dirty(tbh)) {
+			reiserfs_write_unlock(s);
 			sync_dirty_buffer(tbh);
+			reiserfs_write_lock(s);
+		}
 		if (unlikely(!buffer_uptodate(tbh))) {
 #ifdef CONFIG_REISERFS_CHECK
 			reiserfs_warning(s, "journal-601",
@@ -1143,10 +1185,15 @@ static int flush_commit_list(struct super_block *s,
 			if (buffer_dirty(jl->j_commit_bh))
 				BUG();
 			mark_buffer_dirty(jl->j_commit_bh) ;
+			reiserfs_write_unlock(s);
 			sync_dirty_buffer(jl->j_commit_bh) ;
+			reiserfs_write_lock(s);
 		}
-	} else
+	} else {
+		reiserfs_write_unlock(s);
 		wait_on_buffer(jl->j_commit_bh);
+		reiserfs_write_lock(s);
+	}
 
 	check_barrier_completion(s, jl->j_commit_bh);
 
@@ -1286,7 +1333,9 @@ static int _update_journal_header_block(struct super_block *sb,
 
 	if (trans_id >= journal->j_last_flush_trans_id) {
 		if (buffer_locked((journal->j_header_bh))) {
+			reiserfs_write_unlock(sb);
 			wait_on_buffer((journal->j_header_bh));
+			reiserfs_write_lock(sb);
 			if (unlikely(!buffer_uptodate(journal->j_header_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
 				reiserfs_warning(sb, "journal-699",
@@ -1312,12 +1361,16 @@ static int _update_journal_header_block(struct super_block *sb,
 				disable_barrier(sb);
 				goto sync;
 			}
+			reiserfs_write_unlock(sb);
 			wait_on_buffer(journal->j_header_bh);
+			reiserfs_write_lock(sb);
 			check_barrier_completion(sb, journal->j_header_bh);
 		} else {
 		      sync:
 			set_buffer_dirty(journal->j_header_bh);
+			reiserfs_write_unlock(sb);
 			sync_dirty_buffer(journal->j_header_bh);
+			reiserfs_write_lock(sb);
 		}
 		if (!buffer_uptodate(journal->j_header_bh)) {
 			reiserfs_warning(sb, "journal-837",
@@ -1409,7 +1462,7 @@ static int flush_journal_list(struct super_block *s,
 
 	/* if flushall == 0, the lock is already held */
 	if (flushall) {
-		mutex_lock(&journal->j_flush_mutex);
+		reiserfs_mutex_lock_safe(&journal->j_flush_mutex, s);
 	} else if (mutex_trylock(&journal->j_flush_mutex)) {
 		BUG();
 	}
@@ -1553,7 +1606,11 @@ static int flush_journal_list(struct super_block *s,
 					reiserfs_panic(s, "journal-1011",
 						       "cn->bh is NULL");
 				}
+
+				reiserfs_write_unlock(s);
 				wait_on_buffer(cn->bh);
+				reiserfs_write_lock(s);
+
 				if (!cn->bh) {
 					reiserfs_panic(s, "journal-1012",
 						       "cn->bh is NULL");
@@ -1973,11 +2030,19 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	reiserfs_mounted_fs_count--;
 	/* wait for all commits to finish */
 	cancel_delayed_work(&SB_JOURNAL(sb)->j_work);
+
+	/*
+	 * We must release the write lock here because
+	 * the workqueue job (flush_async_commit) needs this lock
+	 */
+	reiserfs_write_unlock(sb);
 	flush_workqueue(commit_wq);
+
 	if (!reiserfs_mounted_fs_count) {
 		destroy_workqueue(commit_wq);
 		commit_wq = NULL;
 	}
+	reiserfs_write_lock(sb);
 
 	free_journal_ram(sb);
 
@@ -2243,7 +2308,11 @@ static int journal_read_transaction(struct super_block *sb,
 	/* read in the log blocks, memcpy to the corresponding real block */
 	ll_rw_block(READ, get_desc_trans_len(desc), log_blocks);
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
+
+		reiserfs_write_unlock(sb);
 		wait_on_buffer(log_blocks[i]);
+		reiserfs_write_lock(sb);
+
 		if (!buffer_uptodate(log_blocks[i])) {
 			reiserfs_warning(sb, "journal-1212",
 					 "REPLAY FAILURE fsck required! "
@@ -2964,8 +3033,11 @@ static void queue_log_writer(struct super_block *s)
 	init_waitqueue_entry(&wait, current);
 	add_wait_queue(&journal->j_join_wait, &wait);
 	set_current_state(TASK_UNINTERRUPTIBLE);
-	if (test_bit(J_WRITERS_QUEUED, &journal->j_state))
+	if (test_bit(J_WRITERS_QUEUED, &journal->j_state)) {
+		reiserfs_write_unlock(s);
 		schedule();
+		reiserfs_write_lock(s);
+	}
 	__set_current_state(TASK_RUNNING);
 	remove_wait_queue(&journal->j_join_wait, &wait);
 }
@@ -2982,7 +3054,9 @@ static void let_transaction_grow(struct super_block *sb, unsigned int trans_id)
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned long bcount = journal->j_bcount;
 	while (1) {
+		reiserfs_write_unlock(sb);
 		schedule_timeout_uninterruptible(1);
+		reiserfs_write_lock(sb);
 		journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
 		while ((atomic_read(&journal->j_wcount) > 0 ||
 			atomic_read(&journal->j_jlock)) &&
@@ -3033,7 +3107,9 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 
 	if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
 		unlock_journal(sb);
+		reiserfs_write_unlock(sb);
 		reiserfs_wait_on_write_block(sb);
+		reiserfs_write_lock(sb);
 		PROC_INFO_INC(sb, journal.journal_relock_writers);
 		goto relock;
 	}
@@ -3506,14 +3582,14 @@ static void flush_async_commits(struct work_struct *work)
 	struct reiserfs_journal_list *jl;
 	struct list_head *entry;
 
-	lock_kernel();
+	reiserfs_write_lock(sb);
 	if (!list_empty(&journal->j_journal_list)) {
 		/* last entry is the youngest, commit it and you get everything */
 		entry = journal->j_journal_list.prev;
 		jl = JOURNAL_LIST_ENTRY(entry);
 		flush_commit_list(sb, jl, 1);
 	}
-	unlock_kernel();
+	reiserfs_write_unlock(sb);
 }
 
 /*
@@ -4041,7 +4117,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * the new transaction is fully setup, and we've already flushed the
 	 * ordered bh list
 	 */
-	mutex_lock(&jl->j_commit_mutex);
+	reiserfs_mutex_lock_safe(&jl->j_commit_mutex, sb);
 
 	/* save the transaction id in case we need to commit it later */
 	commit_trans_id = jl->j_trans_id;
@@ -4203,10 +4279,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * is lost.
 	 */
 	if (!list_empty(&jl->j_tail_bh_list)) {
-		unlock_kernel();
+		reiserfs_write_unlock(sb);
 		write_ordered_buffers(&journal->j_dirty_buffers_lock,
 				      journal, jl, &jl->j_tail_bh_list);
-		lock_kernel();
+		reiserfs_write_lock(sb);
 	}
 	BUG_ON(!list_empty(&jl->j_tail_bh_list));
 	mutex_unlock(&jl->j_commit_mutex);

commit 8aa7e847d834ed937a9ad37a0f2ad5b8584c1ab0
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Thu Jul 9 14:52:32 2009 +0200

    Fix congestion_wait() sync/async vs read/write confusion
    
    Commit 1faa16d22877f4839bd433547d770c676d1d964c accidentally broke
    the bdi congestion wait queue logic, causing us to wait on congestion
    for WRITE (== 1) when we really wanted BLK_RW_ASYNC (== 0) instead.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 77f5bb746bf0..90622200b39c 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -997,7 +997,7 @@ static int reiserfs_async_progress_wait(struct super_block *s)
 	DEFINE_WAIT(wait);
 	struct reiserfs_journal *j = SB_JOURNAL(s);
 	if (atomic_read(&j->j_async_throttle))
-		congestion_wait(WRITE, HZ / 10);
+		congestion_wait(BLK_RW_ASYNC, HZ / 10);
 	return 0;
 }
 

commit a9dd364358fbdc68faee5d20c2d648c320dc3cf0
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:45 2009 -0400

    reiserfs: rename p_s_sb to sb
    
    This patch is a simple s/p_s_sb/sb/g to the reiserfs code.  This is the
    first in a series of patches to rip out some of the awful variable
    naming in reiserfs.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4f787462becc..77f5bb746bf0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -97,7 +97,7 @@ static int flush_commit_list(struct super_block *s,
 			     struct reiserfs_journal_list *jl, int flushall);
 static int can_dirty(struct reiserfs_journal_cnode *cn);
 static int journal_join(struct reiserfs_transaction_handle *th,
-			struct super_block *p_s_sb, unsigned long nblocks);
+			struct super_block *sb, unsigned long nblocks);
 static int release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal);
 static int dirty_one_transaction(struct super_block *s,
@@ -113,12 +113,12 @@ enum {
 };
 
 static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
-			      struct super_block *p_s_sb,
+			      struct super_block *sb,
 			      unsigned long nblocks, int join);
 
-static void init_journal_hash(struct super_block *p_s_sb)
+static void init_journal_hash(struct super_block *sb)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	memset(journal->j_hash_table, 0,
 	       JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *));
 }
@@ -145,7 +145,7 @@ static void disable_barrier(struct super_block *s)
 }
 
 static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
-							 *p_s_sb)
+							 *sb)
 {
 	struct reiserfs_bitmap_node *bn;
 	static int id;
@@ -154,7 +154,7 @@ static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
 	if (!bn) {
 		return NULL;
 	}
-	bn->data = kzalloc(p_s_sb->s_blocksize, GFP_NOFS);
+	bn->data = kzalloc(sb->s_blocksize, GFP_NOFS);
 	if (!bn->data) {
 		kfree(bn);
 		return NULL;
@@ -164,9 +164,9 @@ static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
 	return bn;
 }
 
-static struct reiserfs_bitmap_node *get_bitmap_node(struct super_block *p_s_sb)
+static struct reiserfs_bitmap_node *get_bitmap_node(struct super_block *sb)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_bitmap_node *bn = NULL;
 	struct list_head *entry = journal->j_bitmap_nodes.next;
 
@@ -176,21 +176,21 @@ static struct reiserfs_bitmap_node *get_bitmap_node(struct super_block *p_s_sb)
 	if (entry != &journal->j_bitmap_nodes) {
 		bn = list_entry(entry, struct reiserfs_bitmap_node, list);
 		list_del(entry);
-		memset(bn->data, 0, p_s_sb->s_blocksize);
+		memset(bn->data, 0, sb->s_blocksize);
 		journal->j_free_bitmap_nodes--;
 		return bn;
 	}
-	bn = allocate_bitmap_node(p_s_sb);
+	bn = allocate_bitmap_node(sb);
 	if (!bn) {
 		yield();
 		goto repeat;
 	}
 	return bn;
 }
-static inline void free_bitmap_node(struct super_block *p_s_sb,
+static inline void free_bitmap_node(struct super_block *sb,
 				    struct reiserfs_bitmap_node *bn)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	journal->j_used_bitmap_nodes--;
 	if (journal->j_free_bitmap_nodes > REISERFS_MAX_BITMAP_NODES) {
 		kfree(bn->data);
@@ -201,13 +201,13 @@ static inline void free_bitmap_node(struct super_block *p_s_sb,
 	}
 }
 
-static void allocate_bitmap_nodes(struct super_block *p_s_sb)
+static void allocate_bitmap_nodes(struct super_block *sb)
 {
 	int i;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_bitmap_node *bn = NULL;
 	for (i = 0; i < REISERFS_MIN_BITMAP_NODES; i++) {
-		bn = allocate_bitmap_node(p_s_sb);
+		bn = allocate_bitmap_node(sb);
 		if (bn) {
 			list_add(&bn->list, &journal->j_bitmap_nodes);
 			journal->j_free_bitmap_nodes++;
@@ -217,30 +217,30 @@ static void allocate_bitmap_nodes(struct super_block *p_s_sb)
 	}
 }
 
-static int set_bit_in_list_bitmap(struct super_block *p_s_sb,
+static int set_bit_in_list_bitmap(struct super_block *sb,
 				  b_blocknr_t block,
 				  struct reiserfs_list_bitmap *jb)
 {
-	unsigned int bmap_nr = block / (p_s_sb->s_blocksize << 3);
-	unsigned int bit_nr = block % (p_s_sb->s_blocksize << 3);
+	unsigned int bmap_nr = block / (sb->s_blocksize << 3);
+	unsigned int bit_nr = block % (sb->s_blocksize << 3);
 
 	if (!jb->bitmaps[bmap_nr]) {
-		jb->bitmaps[bmap_nr] = get_bitmap_node(p_s_sb);
+		jb->bitmaps[bmap_nr] = get_bitmap_node(sb);
 	}
 	set_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data);
 	return 0;
 }
 
-static void cleanup_bitmap_list(struct super_block *p_s_sb,
+static void cleanup_bitmap_list(struct super_block *sb,
 				struct reiserfs_list_bitmap *jb)
 {
 	int i;
 	if (jb->bitmaps == NULL)
 		return;
 
-	for (i = 0; i < reiserfs_bmap_count(p_s_sb); i++) {
+	for (i = 0; i < reiserfs_bmap_count(sb); i++) {
 		if (jb->bitmaps[i]) {
-			free_bitmap_node(p_s_sb, jb->bitmaps[i]);
+			free_bitmap_node(sb, jb->bitmaps[i]);
 			jb->bitmaps[i] = NULL;
 		}
 	}
@@ -249,7 +249,7 @@ static void cleanup_bitmap_list(struct super_block *p_s_sb,
 /*
 ** only call this on FS unmount.
 */
-static int free_list_bitmaps(struct super_block *p_s_sb,
+static int free_list_bitmaps(struct super_block *sb,
 			     struct reiserfs_list_bitmap *jb_array)
 {
 	int i;
@@ -257,16 +257,16 @@ static int free_list_bitmaps(struct super_block *p_s_sb,
 	for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
 		jb = jb_array + i;
 		jb->journal_list = NULL;
-		cleanup_bitmap_list(p_s_sb, jb);
+		cleanup_bitmap_list(sb, jb);
 		vfree(jb->bitmaps);
 		jb->bitmaps = NULL;
 	}
 	return 0;
 }
 
-static int free_bitmap_nodes(struct super_block *p_s_sb)
+static int free_bitmap_nodes(struct super_block *sb)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct list_head *next = journal->j_bitmap_nodes.next;
 	struct reiserfs_bitmap_node *bn;
 
@@ -286,7 +286,7 @@ static int free_bitmap_nodes(struct super_block *p_s_sb)
 ** get memory for JOURNAL_NUM_BITMAPS worth of bitmaps.
 ** jb_array is the array to be filled in.
 */
-int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
+int reiserfs_allocate_list_bitmaps(struct super_block *sb,
 				   struct reiserfs_list_bitmap *jb_array,
 				   unsigned int bmap_nr)
 {
@@ -300,7 +300,7 @@ int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 		jb->journal_list = NULL;
 		jb->bitmaps = vmalloc(mem);
 		if (!jb->bitmaps) {
-			reiserfs_warning(p_s_sb, "clm-2000", "unable to "
+			reiserfs_warning(sb, "clm-2000", "unable to "
 					 "allocate bitmaps for journal lists");
 			failed = 1;
 			break;
@@ -308,7 +308,7 @@ int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 		memset(jb->bitmaps, 0, mem);
 	}
 	if (failed) {
-		free_list_bitmaps(p_s_sb, jb_array);
+		free_list_bitmaps(sb, jb_array);
 		return -1;
 	}
 	return 0;
@@ -318,12 +318,12 @@ int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 ** find an available list bitmap.  If you can't find one, flush a commit list
 ** and try again
 */
-static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *p_s_sb,
+static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *sb,
 						    struct reiserfs_journal_list
 						    *jl)
 {
 	int i, j;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_list_bitmap *jb = NULL;
 
 	for (j = 0; j < (JOURNAL_NUM_BITMAPS * 3); j++) {
@@ -331,7 +331,7 @@ static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *p_s_sb,
 		journal->j_list_bitmap_index = (i + 1) % JOURNAL_NUM_BITMAPS;
 		jb = journal->j_list_bitmap + i;
 		if (journal->j_list_bitmap[i].journal_list) {
-			flush_commit_list(p_s_sb,
+			flush_commit_list(sb,
 					  journal->j_list_bitmap[i].
 					  journal_list, 1);
 			if (!journal->j_list_bitmap[i].journal_list) {
@@ -378,12 +378,12 @@ static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 /*
 ** pulls a cnode off the free list, or returns NULL on failure
 */
-static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb)
+static struct reiserfs_journal_cnode *get_cnode(struct super_block *sb)
 {
 	struct reiserfs_journal_cnode *cn;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
-	reiserfs_check_lock_depth(p_s_sb, "get_cnode");
+	reiserfs_check_lock_depth(sb, "get_cnode");
 
 	if (journal->j_cnode_free <= 0) {
 		return NULL;
@@ -405,12 +405,12 @@ static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb)
 /*
 ** returns a cnode to the free list
 */
-static void free_cnode(struct super_block *p_s_sb,
+static void free_cnode(struct super_block *sb,
 		       struct reiserfs_journal_cnode *cn)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
-	reiserfs_check_lock_depth(p_s_sb, "free_cnode");
+	reiserfs_check_lock_depth(sb, "free_cnode");
 
 	journal->j_cnode_used--;
 	journal->j_cnode_free++;
@@ -481,11 +481,11 @@ static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
 ** reject it on the next call to reiserfs_in_journal
 **
 */
-int reiserfs_in_journal(struct super_block *p_s_sb,
+int reiserfs_in_journal(struct super_block *sb,
 			unsigned int bmap_nr, int bit_nr, int search_all,
 			b_blocknr_t * next_zero_bit)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn;
 	struct reiserfs_list_bitmap *jb;
 	int i;
@@ -493,14 +493,14 @@ int reiserfs_in_journal(struct super_block *p_s_sb,
 
 	*next_zero_bit = 0;	/* always start this at zero. */
 
-	PROC_INFO_INC(p_s_sb, journal.in_journal);
+	PROC_INFO_INC(sb, journal.in_journal);
 	/* If we aren't doing a search_all, this is a metablock, and it will be logged before use.
 	 ** if we crash before the transaction that freed it commits,  this transaction won't
 	 ** have committed either, and the block will never be written
 	 */
 	if (search_all) {
 		for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
-			PROC_INFO_INC(p_s_sb, journal.in_journal_bitmap);
+			PROC_INFO_INC(sb, journal.in_journal_bitmap);
 			jb = journal->j_list_bitmap + i;
 			if (jb->journal_list && jb->bitmaps[bmap_nr] &&
 			    test_bit(bit_nr,
@@ -510,28 +510,28 @@ int reiserfs_in_journal(struct super_block *p_s_sb,
 				    find_next_zero_bit((unsigned long *)
 						       (jb->bitmaps[bmap_nr]->
 							data),
-						       p_s_sb->s_blocksize << 3,
+						       sb->s_blocksize << 3,
 						       bit_nr + 1);
 				return 1;
 			}
 		}
 	}
 
-	bl = bmap_nr * (p_s_sb->s_blocksize << 3) + bit_nr;
+	bl = bmap_nr * (sb->s_blocksize << 3) + bit_nr;
 	/* is it in any old transactions? */
 	if (search_all
 	    && (cn =
-		get_journal_hash_dev(p_s_sb, journal->j_list_hash_table, bl))) {
+		get_journal_hash_dev(sb, journal->j_list_hash_table, bl))) {
 		return 1;
 	}
 
 	/* is it in the current transaction.  This should never happen */
-	if ((cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, bl))) {
+	if ((cn = get_journal_hash_dev(sb, journal->j_hash_table, bl))) {
 		BUG();
 		return 1;
 	}
 
-	PROC_INFO_INC(p_s_sb, journal.in_journal_reusable);
+	PROC_INFO_INC(sb, journal.in_journal_reusable);
 	/* safe for reuse */
 	return 0;
 }
@@ -553,16 +553,16 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 }
 
 /* lock the current transaction */
-static inline void lock_journal(struct super_block *p_s_sb)
+static inline void lock_journal(struct super_block *sb)
 {
-	PROC_INFO_INC(p_s_sb, journal.lock_journal);
-	mutex_lock(&SB_JOURNAL(p_s_sb)->j_mutex);
+	PROC_INFO_INC(sb, journal.lock_journal);
+	mutex_lock(&SB_JOURNAL(sb)->j_mutex);
 }
 
 /* unlock the current transaction */
-static inline void unlock_journal(struct super_block *p_s_sb)
+static inline void unlock_journal(struct super_block *sb)
 {
-	mutex_unlock(&SB_JOURNAL(p_s_sb)->j_mutex);
+	mutex_unlock(&SB_JOURNAL(sb)->j_mutex);
 }
 
 static inline void get_journal_list(struct reiserfs_journal_list *jl)
@@ -586,13 +586,13 @@ static inline void put_journal_list(struct super_block *s,
 ** it gets called by flush_commit_list, and cleans up any data stored about blocks freed during a
 ** transaction.
 */
-static void cleanup_freed_for_journal_list(struct super_block *p_s_sb,
+static void cleanup_freed_for_journal_list(struct super_block *sb,
 					   struct reiserfs_journal_list *jl)
 {
 
 	struct reiserfs_list_bitmap *jb = jl->j_list_bitmap;
 	if (jb) {
-		cleanup_bitmap_list(p_s_sb, jb);
+		cleanup_bitmap_list(sb, jb);
 	}
 	jl->j_list_bitmap->journal_list = NULL;
 	jl->j_list_bitmap = NULL;
@@ -1237,11 +1237,11 @@ static void remove_journal_hash(struct super_block *,
 ** journal list for this transaction.  Aside from freeing the cnode, this also allows the
 ** block to be reallocated for data blocks if it had been deleted.
 */
-static void remove_all_from_journal_list(struct super_block *p_s_sb,
+static void remove_all_from_journal_list(struct super_block *sb,
 					 struct reiserfs_journal_list *jl,
 					 int debug)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn, *last;
 	cn = jl->j_realblock;
 
@@ -1251,18 +1251,18 @@ static void remove_all_from_journal_list(struct super_block *p_s_sb,
 	while (cn) {
 		if (cn->blocknr != 0) {
 			if (debug) {
-				reiserfs_warning(p_s_sb, "reiserfs-2201",
+				reiserfs_warning(sb, "reiserfs-2201",
 						 "block %u, bh is %d, state %ld",
 						 cn->blocknr, cn->bh ? 1 : 0,
 						 cn->state);
 			}
 			cn->state = 0;
-			remove_journal_hash(p_s_sb, journal->j_list_hash_table,
+			remove_journal_hash(sb, journal->j_list_hash_table,
 					    jl, cn->blocknr, 1);
 		}
 		last = cn;
 		cn = cn->next;
-		free_cnode(p_s_sb, last);
+		free_cnode(sb, last);
 	}
 	jl->j_realblock = NULL;
 }
@@ -1274,12 +1274,12 @@ static void remove_all_from_journal_list(struct super_block *p_s_sb,
 ** called by flush_journal_list, before it calls remove_all_from_journal_list
 **
 */
-static int _update_journal_header_block(struct super_block *p_s_sb,
+static int _update_journal_header_block(struct super_block *sb,
 					unsigned long offset,
 					unsigned int trans_id)
 {
 	struct reiserfs_journal_header *jh;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	if (reiserfs_is_journal_aborted(journal))
 		return -EIO;
@@ -1289,7 +1289,7 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 			wait_on_buffer((journal->j_header_bh));
 			if (unlikely(!buffer_uptodate(journal->j_header_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-				reiserfs_warning(p_s_sb, "journal-699",
+				reiserfs_warning(sb, "journal-699",
 						 "buffer write failed");
 #endif
 				return -EIO;
@@ -1303,24 +1303,24 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 		jh->j_first_unflushed_offset = cpu_to_le32(offset);
 		jh->j_mount_id = cpu_to_le32(journal->j_mount_id);
 
-		if (reiserfs_barrier_flush(p_s_sb)) {
+		if (reiserfs_barrier_flush(sb)) {
 			int ret;
 			lock_buffer(journal->j_header_bh);
 			ret = submit_barrier_buffer(journal->j_header_bh);
 			if (ret == -EOPNOTSUPP) {
 				set_buffer_uptodate(journal->j_header_bh);
-				disable_barrier(p_s_sb);
+				disable_barrier(sb);
 				goto sync;
 			}
 			wait_on_buffer(journal->j_header_bh);
-			check_barrier_completion(p_s_sb, journal->j_header_bh);
+			check_barrier_completion(sb, journal->j_header_bh);
 		} else {
 		      sync:
 			set_buffer_dirty(journal->j_header_bh);
 			sync_dirty_buffer(journal->j_header_bh);
 		}
 		if (!buffer_uptodate(journal->j_header_bh)) {
-			reiserfs_warning(p_s_sb, "journal-837",
+			reiserfs_warning(sb, "journal-837",
 					 "IO error during journal replay");
 			return -EIO;
 		}
@@ -1328,23 +1328,23 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 	return 0;
 }
 
-static int update_journal_header_block(struct super_block *p_s_sb,
+static int update_journal_header_block(struct super_block *sb,
 				       unsigned long offset,
 				       unsigned int trans_id)
 {
-	return _update_journal_header_block(p_s_sb, offset, trans_id);
+	return _update_journal_header_block(sb, offset, trans_id);
 }
 
 /*
 ** flush any and all journal lists older than you are
 ** can only be called from flush_journal_list
 */
-static int flush_older_journal_lists(struct super_block *p_s_sb,
+static int flush_older_journal_lists(struct super_block *sb,
 				     struct reiserfs_journal_list *jl)
 {
 	struct list_head *entry;
 	struct reiserfs_journal_list *other_jl;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned int trans_id = jl->j_trans_id;
 
 	/* we know we are the only ones flushing things, no extra race
@@ -1359,7 +1359,7 @@ static int flush_older_journal_lists(struct super_block *p_s_sb,
 	if (other_jl->j_trans_id < trans_id) {
 		BUG_ON(other_jl->j_refcount <= 0);
 		/* do not flush all */
-		flush_journal_list(p_s_sb, other_jl, 0);
+		flush_journal_list(sb, other_jl, 0);
 
 		/* other_jl is now deleted from the list */
 		goto restart;
@@ -1908,22 +1908,22 @@ void remove_journal_hash(struct super_block *sb,
 	}
 }
 
-static void free_journal_ram(struct super_block *p_s_sb)
+static void free_journal_ram(struct super_block *sb)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	kfree(journal->j_current_jl);
 	journal->j_num_lists--;
 
 	vfree(journal->j_cnode_free_orig);
-	free_list_bitmaps(p_s_sb, journal->j_list_bitmap);
-	free_bitmap_nodes(p_s_sb);	/* must be after free_list_bitmaps */
+	free_list_bitmaps(sb, journal->j_list_bitmap);
+	free_bitmap_nodes(sb);	/* must be after free_list_bitmaps */
 	if (journal->j_header_bh) {
 		brelse(journal->j_header_bh);
 	}
 	/* j_header_bh is on the journal dev, make sure not to release the journal
 	 * dev until we brelse j_header_bh
 	 */
-	release_journal_dev(p_s_sb, journal);
+	release_journal_dev(sb, journal);
 	vfree(journal);
 }
 
@@ -1932,27 +1932,27 @@ static void free_journal_ram(struct super_block *p_s_sb)
 ** of read_super() yet.  Any other caller must keep error at 0.
 */
 static int do_journal_release(struct reiserfs_transaction_handle *th,
-			      struct super_block *p_s_sb, int error)
+			      struct super_block *sb, int error)
 {
 	struct reiserfs_transaction_handle myth;
 	int flushed = 0;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	/* we only want to flush out transactions if we were called with error == 0
 	 */
-	if (!error && !(p_s_sb->s_flags & MS_RDONLY)) {
+	if (!error && !(sb->s_flags & MS_RDONLY)) {
 		/* end the current trans */
 		BUG_ON(!th->t_trans_id);
-		do_journal_end(th, p_s_sb, 10, FLUSH_ALL);
+		do_journal_end(th, sb, 10, FLUSH_ALL);
 
 		/* make sure something gets logged to force our way into the flush code */
-		if (!journal_join(&myth, p_s_sb, 1)) {
-			reiserfs_prepare_for_journal(p_s_sb,
-						     SB_BUFFER_WITH_SB(p_s_sb),
+		if (!journal_join(&myth, sb, 1)) {
+			reiserfs_prepare_for_journal(sb,
+						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&myth, p_s_sb,
-					   SB_BUFFER_WITH_SB(p_s_sb));
-			do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL);
+			journal_mark_dirty(&myth, sb,
+					   SB_BUFFER_WITH_SB(sb));
+			do_journal_end(&myth, sb, 1, FLUSH_ALL);
 			flushed = 1;
 		}
 	}
@@ -1960,26 +1960,26 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 	/* this also catches errors during the do_journal_end above */
 	if (!error && reiserfs_is_journal_aborted(journal)) {
 		memset(&myth, 0, sizeof(myth));
-		if (!journal_join_abort(&myth, p_s_sb, 1)) {
-			reiserfs_prepare_for_journal(p_s_sb,
-						     SB_BUFFER_WITH_SB(p_s_sb),
+		if (!journal_join_abort(&myth, sb, 1)) {
+			reiserfs_prepare_for_journal(sb,
+						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&myth, p_s_sb,
-					   SB_BUFFER_WITH_SB(p_s_sb));
-			do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL);
+			journal_mark_dirty(&myth, sb,
+					   SB_BUFFER_WITH_SB(sb));
+			do_journal_end(&myth, sb, 1, FLUSH_ALL);
 		}
 	}
 
 	reiserfs_mounted_fs_count--;
 	/* wait for all commits to finish */
-	cancel_delayed_work(&SB_JOURNAL(p_s_sb)->j_work);
+	cancel_delayed_work(&SB_JOURNAL(sb)->j_work);
 	flush_workqueue(commit_wq);
 	if (!reiserfs_mounted_fs_count) {
 		destroy_workqueue(commit_wq);
 		commit_wq = NULL;
 	}
 
-	free_journal_ram(p_s_sb);
+	free_journal_ram(sb);
 
 	return 0;
 }
@@ -1988,28 +1988,28 @@ static int do_journal_release(struct reiserfs_transaction_handle *th,
 ** call on unmount.  flush all journal trans, release all alloc'd ram
 */
 int journal_release(struct reiserfs_transaction_handle *th,
-		    struct super_block *p_s_sb)
+		    struct super_block *sb)
 {
-	return do_journal_release(th, p_s_sb, 0);
+	return do_journal_release(th, sb, 0);
 }
 
 /*
 ** only call from an error condition inside reiserfs_read_super!
 */
 int journal_release_error(struct reiserfs_transaction_handle *th,
-			  struct super_block *p_s_sb)
+			  struct super_block *sb)
 {
-	return do_journal_release(th, p_s_sb, 1);
+	return do_journal_release(th, sb, 1);
 }
 
 /* compares description block with commit block.  returns 1 if they differ, 0 if they are the same */
-static int journal_compare_desc_commit(struct super_block *p_s_sb,
+static int journal_compare_desc_commit(struct super_block *sb,
 				       struct reiserfs_journal_desc *desc,
 				       struct reiserfs_journal_commit *commit)
 {
 	if (get_commit_trans_id(commit) != get_desc_trans_id(desc) ||
 	    get_commit_trans_len(commit) != get_desc_trans_len(desc) ||
-	    get_commit_trans_len(commit) > SB_JOURNAL(p_s_sb)->j_trans_max ||
+	    get_commit_trans_len(commit) > SB_JOURNAL(sb)->j_trans_max ||
 	    get_commit_trans_len(commit) <= 0) {
 		return 1;
 	}
@@ -2020,7 +2020,7 @@ static int journal_compare_desc_commit(struct super_block *p_s_sb,
 ** returns -1 if it found a corrupt commit block
 ** returns 1 if both desc and commit were valid
 */
-static int journal_transaction_is_valid(struct super_block *p_s_sb,
+static int journal_transaction_is_valid(struct super_block *sb,
 					struct buffer_head *d_bh,
 					unsigned int *oldest_invalid_trans_id,
 					unsigned long *newest_mount_id)
@@ -2038,7 +2038,7 @@ static int journal_transaction_is_valid(struct super_block *p_s_sb,
 	    && !memcmp(get_journal_desc_magic(d_bh), JOURNAL_DESC_MAGIC, 8)) {
 		if (oldest_invalid_trans_id && *oldest_invalid_trans_id
 		    && get_desc_trans_id(desc) > *oldest_invalid_trans_id) {
-			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 				       "journal-986: transaction "
 				       "is valid returning because trans_id %d is greater than "
 				       "oldest_invalid %lu",
@@ -2048,7 +2048,7 @@ static int journal_transaction_is_valid(struct super_block *p_s_sb,
 		}
 		if (newest_mount_id
 		    && *newest_mount_id > get_desc_mount_id(desc)) {
-			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 				       "journal-1087: transaction "
 				       "is valid returning because mount_id %d is less than "
 				       "newest_mount_id %lu",
@@ -2056,37 +2056,37 @@ static int journal_transaction_is_valid(struct super_block *p_s_sb,
 				       *newest_mount_id);
 			return -1;
 		}
-		if (get_desc_trans_len(desc) > SB_JOURNAL(p_s_sb)->j_trans_max) {
-			reiserfs_warning(p_s_sb, "journal-2018",
+		if (get_desc_trans_len(desc) > SB_JOURNAL(sb)->j_trans_max) {
+			reiserfs_warning(sb, "journal-2018",
 					 "Bad transaction length %d "
 					 "encountered, ignoring transaction",
 					 get_desc_trans_len(desc));
 			return -1;
 		}
-		offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+		offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(sb);
 
 		/* ok, we have a journal description block, lets see if the transaction was valid */
 		c_bh =
-		    journal_bread(p_s_sb,
-				  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		    journal_bread(sb,
+				  SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 				  ((offset + get_desc_trans_len(desc) +
-				    1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+				    1) % SB_ONDISK_JOURNAL_SIZE(sb)));
 		if (!c_bh)
 			return 0;
 		commit = (struct reiserfs_journal_commit *)c_bh->b_data;
-		if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
-			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		if (journal_compare_desc_commit(sb, desc, commit)) {
+			reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 				       "journal_transaction_is_valid, commit offset %ld had bad "
 				       "time %d or length %d",
 				       c_bh->b_blocknr -
-				       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+				       SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 				       get_commit_trans_id(commit),
 				       get_commit_trans_len(commit));
 			brelse(c_bh);
 			if (oldest_invalid_trans_id) {
 				*oldest_invalid_trans_id =
 				    get_desc_trans_id(desc);
-				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 					       "journal-1004: "
 					       "transaction_is_valid setting oldest invalid trans_id "
 					       "to %d",
@@ -2095,11 +2095,11 @@ static int journal_transaction_is_valid(struct super_block *p_s_sb,
 			return -1;
 		}
 		brelse(c_bh);
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal-1006: found valid "
 			       "transaction start offset %llu, len %d id %d",
 			       d_bh->b_blocknr -
-			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 			       get_desc_trans_len(desc),
 			       get_desc_trans_id(desc));
 		return 1;
@@ -2121,13 +2121,13 @@ static void brelse_array(struct buffer_head **heads, int num)
 ** this either reads in a replays a transaction, or returns because the transaction
 ** is invalid, or too old.
 */
-static int journal_read_transaction(struct super_block *p_s_sb,
+static int journal_read_transaction(struct super_block *sb,
 				    unsigned long cur_dblock,
 				    unsigned long oldest_start,
 				    unsigned int oldest_trans_id,
 				    unsigned long newest_mount_id)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_desc *desc;
 	struct reiserfs_journal_commit *commit;
 	unsigned int trans_id = 0;
@@ -2139,45 +2139,45 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	int i;
 	int trans_half;
 
-	d_bh = journal_bread(p_s_sb, cur_dblock);
+	d_bh = journal_bread(sb, cur_dblock);
 	if (!d_bh)
 		return 1;
 	desc = (struct reiserfs_journal_desc *)d_bh->b_data;
-	trans_offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1037: "
+	trans_offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(sb);
+	reiserfs_debug(sb, REISERFS_DEBUG_CODE, "journal-1037: "
 		       "journal_read_transaction, offset %llu, len %d mount_id %d",
-		       d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		       d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 		       get_desc_trans_len(desc), get_desc_mount_id(desc));
 	if (get_desc_trans_id(desc) < oldest_trans_id) {
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1039: "
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE, "journal-1039: "
 			       "journal_read_trans skipping because %lu is too old",
 			       cur_dblock -
-			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb));
+			       SB_ONDISK_JOURNAL_1st_BLOCK(sb));
 		brelse(d_bh);
 		return 1;
 	}
 	if (get_desc_mount_id(desc) != newest_mount_id) {
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1146: "
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE, "journal-1146: "
 			       "journal_read_trans skipping because %d is != "
 			       "newest_mount_id %lu", get_desc_mount_id(desc),
 			       newest_mount_id);
 		brelse(d_bh);
 		return 1;
 	}
-	c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+	c_bh = journal_bread(sb, SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 			     ((trans_offset + get_desc_trans_len(desc) + 1) %
-			      SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+			      SB_ONDISK_JOURNAL_SIZE(sb)));
 	if (!c_bh) {
 		brelse(d_bh);
 		return 1;
 	}
 	commit = (struct reiserfs_journal_commit *)c_bh->b_data;
-	if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+	if (journal_compare_desc_commit(sb, desc, commit)) {
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal_read_transaction, "
 			       "commit offset %llu had bad time %d or length %d",
 			       c_bh->b_blocknr -
-			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 			       get_commit_trans_id(commit),
 			       get_commit_trans_len(commit));
 		brelse(c_bh);
@@ -2195,30 +2195,30 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 		brelse(d_bh);
 		kfree(log_blocks);
 		kfree(real_blocks);
-		reiserfs_warning(p_s_sb, "journal-1169",
+		reiserfs_warning(sb, "journal-1169",
 				 "kmalloc failed, unable to mount FS");
 		return -1;
 	}
 	/* get all the buffer heads */
-	trans_half = journal_trans_half(p_s_sb->s_blocksize);
+	trans_half = journal_trans_half(sb->s_blocksize);
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		log_blocks[i] =
-		    journal_getblk(p_s_sb,
-				   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		    journal_getblk(sb,
+				   SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 				   (trans_offset + 1 +
-				    i) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+				    i) % SB_ONDISK_JOURNAL_SIZE(sb));
 		if (i < trans_half) {
 			real_blocks[i] =
-			    sb_getblk(p_s_sb,
+			    sb_getblk(sb,
 				      le32_to_cpu(desc->j_realblock[i]));
 		} else {
 			real_blocks[i] =
-			    sb_getblk(p_s_sb,
+			    sb_getblk(sb,
 				      le32_to_cpu(commit->
 						  j_realblock[i - trans_half]));
 		}
-		if (real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(p_s_sb)) {
-			reiserfs_warning(p_s_sb, "journal-1207",
+		if (real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(sb)) {
+			reiserfs_warning(sb, "journal-1207",
 					 "REPLAY FAILURE fsck required! "
 					 "Block to replay is outside of "
 					 "filesystem");
@@ -2226,8 +2226,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 		}
 		/* make sure we don't try to replay onto log or reserved area */
 		if (is_block_in_log_or_reserved_area
-		    (p_s_sb, real_blocks[i]->b_blocknr)) {
-			reiserfs_warning(p_s_sb, "journal-1204",
+		    (sb, real_blocks[i]->b_blocknr)) {
+			reiserfs_warning(sb, "journal-1204",
 					 "REPLAY FAILURE fsck required! "
 					 "Trying to replay onto a log block");
 		      abort_replay:
@@ -2245,7 +2245,7 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(log_blocks[i]);
 		if (!buffer_uptodate(log_blocks[i])) {
-			reiserfs_warning(p_s_sb, "journal-1212",
+			reiserfs_warning(sb, "journal-1212",
 					 "REPLAY FAILURE fsck required! "
 					 "buffer write failed");
 			brelse_array(log_blocks + i,
@@ -2270,7 +2270,7 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(real_blocks[i]);
 		if (!buffer_uptodate(real_blocks[i])) {
-			reiserfs_warning(p_s_sb, "journal-1226",
+			reiserfs_warning(sb, "journal-1226",
 					 "REPLAY FAILURE, fsck required! "
 					 "buffer write failed");
 			brelse_array(real_blocks + i,
@@ -2284,15 +2284,15 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 		brelse(real_blocks[i]);
 	}
 	cur_dblock =
-	    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+	    SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 	    ((trans_offset + get_desc_trans_len(desc) +
-	      2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+	      2) % SB_ONDISK_JOURNAL_SIZE(sb));
+	reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 		       "journal-1095: setting journal " "start to offset %ld",
-		       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb));
+		       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(sb));
 
 	/* init starting values for the first transaction, in case this is the last transaction to be replayed. */
-	journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+	journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(sb);
 	journal->j_last_flush_trans_id = trans_id;
 	journal->j_trans_id = trans_id + 1;
 	/* check for trans_id overflow */
@@ -2357,9 +2357,9 @@ static struct buffer_head *reiserfs_breada(struct block_device *dev,
 **
 ** On exit, it sets things up so the first transaction will work correctly.
 */
-static int journal_read(struct super_block *p_s_sb)
+static int journal_read(struct super_block *sb)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_desc *desc;
 	unsigned int oldest_trans_id = 0;
 	unsigned int oldest_invalid_trans_id = 0;
@@ -2375,8 +2375,8 @@ static int journal_read(struct super_block *p_s_sb)
 	int ret;
 	char b[BDEVNAME_SIZE];
 
-	cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
-	reiserfs_info(p_s_sb, "checking transaction log (%s)\n",
+	cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(sb);
+	reiserfs_info(sb, "checking transaction log (%s)\n",
 		      bdevname(journal->j_dev_bd, b));
 	start = get_seconds();
 
@@ -2384,22 +2384,22 @@ static int journal_read(struct super_block *p_s_sb)
 	 ** is the first unflushed, and if that transaction is not valid,
 	 ** replay is done
 	 */
-	journal->j_header_bh = journal_bread(p_s_sb,
-					     SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)
-					     + SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+	journal->j_header_bh = journal_bread(sb,
+					     SB_ONDISK_JOURNAL_1st_BLOCK(sb)
+					     + SB_ONDISK_JOURNAL_SIZE(sb));
 	if (!journal->j_header_bh) {
 		return 1;
 	}
 	jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data);
 	if (le32_to_cpu(jh->j_first_unflushed_offset) <
-	    SB_ONDISK_JOURNAL_SIZE(p_s_sb)
+	    SB_ONDISK_JOURNAL_SIZE(sb)
 	    && le32_to_cpu(jh->j_last_flush_trans_id) > 0) {
 		oldest_start =
-		    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		    SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 		    le32_to_cpu(jh->j_first_unflushed_offset);
 		oldest_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
 		newest_mount_id = le32_to_cpu(jh->j_mount_id);
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal-1153: found in "
 			       "header: first_unflushed_offset %d, last_flushed_trans_id "
 			       "%lu", le32_to_cpu(jh->j_first_unflushed_offset),
@@ -2411,10 +2411,10 @@ static int journal_read(struct super_block *p_s_sb)
 		 ** through the whole log.
 		 */
 		d_bh =
-		    journal_bread(p_s_sb,
-				  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		    journal_bread(sb,
+				  SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 				  le32_to_cpu(jh->j_first_unflushed_offset));
-		ret = journal_transaction_is_valid(p_s_sb, d_bh, NULL, NULL);
+		ret = journal_transaction_is_valid(sb, d_bh, NULL, NULL);
 		if (!ret) {
 			continue_replay = 0;
 		}
@@ -2422,8 +2422,8 @@ static int journal_read(struct super_block *p_s_sb)
 		goto start_log_replay;
 	}
 
-	if (continue_replay && bdev_read_only(p_s_sb->s_bdev)) {
-		reiserfs_warning(p_s_sb, "clm-2076",
+	if (continue_replay && bdev_read_only(sb->s_bdev)) {
+		reiserfs_warning(sb, "clm-2076",
 				 "device is readonly, unable to replay log");
 		return -1;
 	}
@@ -2433,17 +2433,17 @@ static int journal_read(struct super_block *p_s_sb)
 	 */
 	while (continue_replay
 	       && cur_dblock <
-	       (SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
-		SB_ONDISK_JOURNAL_SIZE(p_s_sb))) {
+	       (SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
+		SB_ONDISK_JOURNAL_SIZE(sb))) {
 		/* Note that it is required for blocksize of primary fs device and journal
 		   device to be the same */
 		d_bh =
 		    reiserfs_breada(journal->j_dev_bd, cur_dblock,
-				    p_s_sb->s_blocksize,
-				    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
-				    SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+				    sb->s_blocksize,
+				    SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
+				    SB_ONDISK_JOURNAL_SIZE(sb));
 		ret =
-		    journal_transaction_is_valid(p_s_sb, d_bh,
+		    journal_transaction_is_valid(sb, d_bh,
 						 &oldest_invalid_trans_id,
 						 &newest_mount_id);
 		if (ret == 1) {
@@ -2452,26 +2452,26 @@ static int journal_read(struct super_block *p_s_sb)
 				oldest_trans_id = get_desc_trans_id(desc);
 				oldest_start = d_bh->b_blocknr;
 				newest_mount_id = get_desc_mount_id(desc);
-				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 					       "journal-1179: Setting "
 					       "oldest_start to offset %llu, trans_id %lu",
 					       oldest_start -
 					       SB_ONDISK_JOURNAL_1st_BLOCK
-					       (p_s_sb), oldest_trans_id);
+					       (sb), oldest_trans_id);
 			} else if (oldest_trans_id > get_desc_trans_id(desc)) {
 				/* one we just read was older */
 				oldest_trans_id = get_desc_trans_id(desc);
 				oldest_start = d_bh->b_blocknr;
-				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 					       "journal-1180: Resetting "
 					       "oldest_start to offset %lu, trans_id %lu",
 					       oldest_start -
 					       SB_ONDISK_JOURNAL_1st_BLOCK
-					       (p_s_sb), oldest_trans_id);
+					       (sb), oldest_trans_id);
 			}
 			if (newest_mount_id < get_desc_mount_id(desc)) {
 				newest_mount_id = get_desc_mount_id(desc);
-				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 					       "journal-1299: Setting "
 					       "newest_mount_id to %d",
 					       get_desc_mount_id(desc));
@@ -2486,17 +2486,17 @@ static int journal_read(struct super_block *p_s_sb)
       start_log_replay:
 	cur_dblock = oldest_start;
 	if (oldest_trans_id) {
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal-1206: Starting replay "
 			       "from offset %llu, trans_id %lu",
-			       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 			       oldest_trans_id);
 
 	}
 	replay_count = 0;
 	while (continue_replay && oldest_trans_id > 0) {
 		ret =
-		    journal_read_transaction(p_s_sb, cur_dblock, oldest_start,
+		    journal_read_transaction(sb, cur_dblock, oldest_start,
 					     oldest_trans_id, newest_mount_id);
 		if (ret < 0) {
 			return ret;
@@ -2504,14 +2504,14 @@ static int journal_read(struct super_block *p_s_sb)
 			break;
 		}
 		cur_dblock =
-		    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start;
+		    SB_ONDISK_JOURNAL_1st_BLOCK(sb) + journal->j_start;
 		replay_count++;
 		if (cur_dblock == oldest_start)
 			break;
 	}
 
 	if (oldest_trans_id == 0) {
-		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		reiserfs_debug(sb, REISERFS_DEBUG_CODE,
 			       "journal-1225: No valid " "transactions found");
 	}
 	/* j_start does not get set correctly if we don't replay any transactions.
@@ -2531,16 +2531,16 @@ static int journal_read(struct super_block *p_s_sb)
 	} else {
 		journal->j_mount_id = newest_mount_id + 1;
 	}
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
+	reiserfs_debug(sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
 		       "newest_mount_id to %lu", journal->j_mount_id);
 	journal->j_first_unflushed_offset = journal->j_start;
 	if (replay_count > 0) {
-		reiserfs_info(p_s_sb,
+		reiserfs_info(sb,
 			      "replayed %d transactions in %lu seconds\n",
 			      replay_count, get_seconds() - start);
 	}
-	if (!bdev_read_only(p_s_sb->s_bdev) &&
-	    _update_journal_header_block(p_s_sb, journal->j_start,
+	if (!bdev_read_only(sb->s_bdev) &&
+	    _update_journal_header_block(sb, journal->j_start,
 					 journal->j_last_flush_trans_id)) {
 		/* replay failed, caller must call free_journal_ram and abort
 		 ** the mount
@@ -2565,9 +2565,9 @@ static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
 	return jl;
 }
 
-static void journal_list_init(struct super_block *p_s_sb)
+static void journal_list_init(struct super_block *sb)
 {
-	SB_JOURNAL(p_s_sb)->j_current_jl = alloc_journal_list(p_s_sb);
+	SB_JOURNAL(sb)->j_current_jl = alloc_journal_list(sb);
 }
 
 static int release_journal_dev(struct super_block *super,
@@ -2666,28 +2666,28 @@ static int journal_init_dev(struct super_block *super,
  */
 #define REISERFS_STANDARD_BLKSIZE (4096)
 
-static int check_advise_trans_params(struct super_block *p_s_sb,
+static int check_advise_trans_params(struct super_block *sb,
 				     struct reiserfs_journal *journal)
 {
         if (journal->j_trans_max) {
 	        /* Non-default journal params.
 		   Do sanity check for them. */
 	        int ratio = 1;
-		if (p_s_sb->s_blocksize < REISERFS_STANDARD_BLKSIZE)
-		        ratio = REISERFS_STANDARD_BLKSIZE / p_s_sb->s_blocksize;
+		if (sb->s_blocksize < REISERFS_STANDARD_BLKSIZE)
+		        ratio = REISERFS_STANDARD_BLKSIZE / sb->s_blocksize;
 
 		if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio ||
 		    journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio ||
-		    SB_ONDISK_JOURNAL_SIZE(p_s_sb) / journal->j_trans_max <
+		    SB_ONDISK_JOURNAL_SIZE(sb) / journal->j_trans_max <
 		    JOURNAL_MIN_RATIO) {
-			reiserfs_warning(p_s_sb, "sh-462",
+			reiserfs_warning(sb, "sh-462",
 					 "bad transaction max size (%u). "
 					 "FSCK?", journal->j_trans_max);
 			return 1;
 		}
 		if (journal->j_max_batch != (journal->j_trans_max) *
 		        JOURNAL_MAX_BATCH_DEFAULT/JOURNAL_TRANS_MAX_DEFAULT) {
-			reiserfs_warning(p_s_sb, "sh-463",
+			reiserfs_warning(sb, "sh-463",
 					 "bad transaction max batch (%u). "
 					 "FSCK?", journal->j_max_batch);
 			return 1;
@@ -2697,9 +2697,9 @@ static int check_advise_trans_params(struct super_block *p_s_sb,
                    The file system was created by old version
 		   of mkreiserfs, so some fields contain zeros,
 		   and we need to advise proper values for them */
-		if (p_s_sb->s_blocksize != REISERFS_STANDARD_BLKSIZE) {
-			reiserfs_warning(p_s_sb, "sh-464", "bad blocksize (%u)",
-					 p_s_sb->s_blocksize);
+		if (sb->s_blocksize != REISERFS_STANDARD_BLKSIZE) {
+			reiserfs_warning(sb, "sh-464", "bad blocksize (%u)",
+					 sb->s_blocksize);
 			return 1;
 		}
 		journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT;
@@ -2712,10 +2712,10 @@ static int check_advise_trans_params(struct super_block *p_s_sb,
 /*
 ** must be called once on fs mount.  calls journal_read for you
 */
-int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
+int journal_init(struct super_block *sb, const char *j_dev_name,
 		 int old_format, unsigned int commit_max_age)
 {
-	int num_cnodes = SB_ONDISK_JOURNAL_SIZE(p_s_sb) * 2;
+	int num_cnodes = SB_ONDISK_JOURNAL_SIZE(sb) * 2;
 	struct buffer_head *bhjh;
 	struct reiserfs_super_block *rs;
 	struct reiserfs_journal_header *jh;
@@ -2723,9 +2723,9 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	struct reiserfs_journal_list *jl;
 	char b[BDEVNAME_SIZE];
 
-	journal = SB_JOURNAL(p_s_sb) = vmalloc(sizeof(struct reiserfs_journal));
+	journal = SB_JOURNAL(sb) = vmalloc(sizeof(struct reiserfs_journal));
 	if (!journal) {
-		reiserfs_warning(p_s_sb, "journal-1256",
+		reiserfs_warning(sb, "journal-1256",
 				 "unable to get memory for journal structure");
 		return 1;
 	}
@@ -2735,50 +2735,50 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	INIT_LIST_HEAD(&journal->j_working_list);
 	INIT_LIST_HEAD(&journal->j_journal_list);
 	journal->j_persistent_trans = 0;
-	if (reiserfs_allocate_list_bitmaps(p_s_sb,
+	if (reiserfs_allocate_list_bitmaps(sb,
 					   journal->j_list_bitmap,
-					   reiserfs_bmap_count(p_s_sb)))
+					   reiserfs_bmap_count(sb)))
 		goto free_and_return;
-	allocate_bitmap_nodes(p_s_sb);
+	allocate_bitmap_nodes(sb);
 
 	/* reserved for journal area support */
-	SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) = (old_format ?
+	SB_JOURNAL_1st_RESERVED_BLOCK(sb) = (old_format ?
 						 REISERFS_OLD_DISK_OFFSET_IN_BYTES
-						 / p_s_sb->s_blocksize +
-						 reiserfs_bmap_count(p_s_sb) +
+						 / sb->s_blocksize +
+						 reiserfs_bmap_count(sb) +
 						 1 :
 						 REISERFS_DISK_OFFSET_IN_BYTES /
-						 p_s_sb->s_blocksize + 2);
+						 sb->s_blocksize + 2);
 
 	/* Sanity check to see is the standard journal fitting withing first bitmap
 	   (actual for small blocksizes) */
-	if (!SB_ONDISK_JOURNAL_DEVICE(p_s_sb) &&
-	    (SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) +
-	     SB_ONDISK_JOURNAL_SIZE(p_s_sb) > p_s_sb->s_blocksize * 8)) {
-		reiserfs_warning(p_s_sb, "journal-1393",
+	if (!SB_ONDISK_JOURNAL_DEVICE(sb) &&
+	    (SB_JOURNAL_1st_RESERVED_BLOCK(sb) +
+	     SB_ONDISK_JOURNAL_SIZE(sb) > sb->s_blocksize * 8)) {
+		reiserfs_warning(sb, "journal-1393",
 				 "journal does not fit for area addressed "
 				 "by first of bitmap blocks. It starts at "
 				 "%u and its size is %u. Block size %ld",
-				 SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb),
-				 SB_ONDISK_JOURNAL_SIZE(p_s_sb),
-				 p_s_sb->s_blocksize);
+				 SB_JOURNAL_1st_RESERVED_BLOCK(sb),
+				 SB_ONDISK_JOURNAL_SIZE(sb),
+				 sb->s_blocksize);
 		goto free_and_return;
 	}
 
-	if (journal_init_dev(p_s_sb, journal, j_dev_name) != 0) {
-		reiserfs_warning(p_s_sb, "sh-462",
+	if (journal_init_dev(sb, journal, j_dev_name) != 0) {
+		reiserfs_warning(sb, "sh-462",
 				 "unable to initialize jornal device");
 		goto free_and_return;
 	}
 
-	rs = SB_DISK_SUPER_BLOCK(p_s_sb);
+	rs = SB_DISK_SUPER_BLOCK(sb);
 
 	/* read journal header */
-	bhjh = journal_bread(p_s_sb,
-			     SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
-			     SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+	bhjh = journal_bread(sb,
+			     SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
+			     SB_ONDISK_JOURNAL_SIZE(sb));
 	if (!bhjh) {
-		reiserfs_warning(p_s_sb, "sh-459",
+		reiserfs_warning(sb, "sh-459",
 				 "unable to read journal header");
 		goto free_and_return;
 	}
@@ -2788,7 +2788,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	if (is_reiserfs_jr(rs)
 	    && (le32_to_cpu(jh->jh_journal.jp_journal_magic) !=
 		sb_jp_journal_magic(rs))) {
-		reiserfs_warning(p_s_sb, "sh-460",
+		reiserfs_warning(sb, "sh-460",
 				 "journal header magic %x (device %s) does "
 				 "not match to magic found in super block %x",
 				 jh->jh_journal.jp_journal_magic,
@@ -2804,7 +2804,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	    le32_to_cpu(jh->jh_journal.jp_journal_max_commit_age);
 	journal->j_max_trans_age = JOURNAL_MAX_TRANS_AGE;
 
-	if (check_advise_trans_params(p_s_sb, journal) != 0)
+	if (check_advise_trans_params(sb, journal) != 0)
 	        goto free_and_return;
 	journal->j_default_max_commit_age = journal->j_max_commit_age;
 
@@ -2813,12 +2813,12 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 		journal->j_max_trans_age = commit_max_age;
 	}
 
-	reiserfs_info(p_s_sb, "journal params: device %s, size %u, "
+	reiserfs_info(sb, "journal params: device %s, size %u, "
 		      "journal first block %u, max trans len %u, max batch %u, "
 		      "max commit age %u, max trans age %u\n",
 		      bdevname(journal->j_dev_bd, b),
-		      SB_ONDISK_JOURNAL_SIZE(p_s_sb),
-		      SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		      SB_ONDISK_JOURNAL_SIZE(sb),
+		      SB_ONDISK_JOURNAL_1st_BLOCK(sb),
 		      journal->j_trans_max,
 		      journal->j_max_batch,
 		      journal->j_max_commit_age, journal->j_max_trans_age);
@@ -2826,7 +2826,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	brelse(bhjh);
 
 	journal->j_list_bitmap_index = 0;
-	journal_list_init(p_s_sb);
+	journal_list_init(sb);
 
 	memset(journal->j_list_hash_table, 0,
 	       JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *));
@@ -2858,7 +2858,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_must_wait = 0;
 
 	if (journal->j_cnode_free == 0) {
-		reiserfs_warning(p_s_sb, "journal-2004", "Journal cnode memory "
+		reiserfs_warning(sb, "journal-2004", "Journal cnode memory "
 		                 "allocation failed (%ld bytes). Journal is "
 		                 "too large for available memory. Usually "
 		                 "this is due to a journal that is too large.",
@@ -2866,16 +2866,16 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
         	goto free_and_return;
 	}
 
-	init_journal_hash(p_s_sb);
+	init_journal_hash(sb);
 	jl = journal->j_current_jl;
-	jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);
+	jl->j_list_bitmap = get_list_bitmap(sb, jl);
 	if (!jl->j_list_bitmap) {
-		reiserfs_warning(p_s_sb, "journal-2005",
+		reiserfs_warning(sb, "journal-2005",
 				 "get_list_bitmap failed for journal list 0");
 		goto free_and_return;
 	}
-	if (journal_read(p_s_sb) < 0) {
-		reiserfs_warning(p_s_sb, "reiserfs-2006",
+	if (journal_read(sb) < 0) {
+		reiserfs_warning(sb, "reiserfs-2006",
 				 "Replay Failure, unable to mount");
 		goto free_and_return;
 	}
@@ -2885,10 +2885,10 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 		commit_wq = create_workqueue("reiserfs");
 
 	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
-	journal->j_work_sb = p_s_sb;
+	journal->j_work_sb = sb;
 	return 0;
       free_and_return:
-	free_journal_ram(p_s_sb);
+	free_journal_ram(sb);
 	return 1;
 }
 
@@ -3004,37 +3004,37 @@ static void let_transaction_grow(struct super_block *sb, unsigned int trans_id)
 ** expect to use in nblocks.
 */
 static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
-			      struct super_block *p_s_sb, unsigned long nblocks,
+			      struct super_block *sb, unsigned long nblocks,
 			      int join)
 {
 	time_t now = get_seconds();
 	unsigned int old_trans_id;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_transaction_handle myth;
 	int sched_count = 0;
 	int retval;
 
-	reiserfs_check_lock_depth(p_s_sb, "journal_begin");
+	reiserfs_check_lock_depth(sb, "journal_begin");
 	BUG_ON(nblocks > journal->j_trans_max);
 
-	PROC_INFO_INC(p_s_sb, journal.journal_being);
+	PROC_INFO_INC(sb, journal.journal_being);
 	/* set here for journal_join */
 	th->t_refcount = 1;
-	th->t_super = p_s_sb;
+	th->t_super = sb;
 
       relock:
-	lock_journal(p_s_sb);
+	lock_journal(sb);
 	if (join != JBEGIN_ABORT && reiserfs_is_journal_aborted(journal)) {
-		unlock_journal(p_s_sb);
+		unlock_journal(sb);
 		retval = journal->j_errno;
 		goto out_fail;
 	}
 	journal->j_bcount++;
 
 	if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
-		unlock_journal(p_s_sb);
-		reiserfs_wait_on_write_block(p_s_sb);
-		PROC_INFO_INC(p_s_sb, journal.journal_relock_writers);
+		unlock_journal(sb);
+		reiserfs_wait_on_write_block(sb);
+		PROC_INFO_INC(sb, journal.journal_relock_writers);
 		goto relock;
 	}
 	now = get_seconds();
@@ -3055,7 +3055,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	    || (!join && journal->j_cnode_free < (journal->j_trans_max * 3))) {
 
 		old_trans_id = journal->j_trans_id;
-		unlock_journal(p_s_sb);	/* allow others to finish this transaction */
+		unlock_journal(sb);	/* allow others to finish this transaction */
 
 		if (!join && (journal->j_len_alloc + nblocks + 2) >=
 		    journal->j_max_batch &&
@@ -3063,7 +3063,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 		    (journal->j_len_alloc * 75)) {
 			if (atomic_read(&journal->j_wcount) > 10) {
 				sched_count++;
-				queue_log_writer(p_s_sb);
+				queue_log_writer(sb);
 				goto relock;
 			}
 		}
@@ -3073,25 +3073,25 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 		if (atomic_read(&journal->j_jlock)) {
 			while (journal->j_trans_id == old_trans_id &&
 			       atomic_read(&journal->j_jlock)) {
-				queue_log_writer(p_s_sb);
+				queue_log_writer(sb);
 			}
 			goto relock;
 		}
-		retval = journal_join(&myth, p_s_sb, 1);
+		retval = journal_join(&myth, sb, 1);
 		if (retval)
 			goto out_fail;
 
 		/* someone might have ended the transaction while we joined */
 		if (old_trans_id != journal->j_trans_id) {
-			retval = do_journal_end(&myth, p_s_sb, 1, 0);
+			retval = do_journal_end(&myth, sb, 1, 0);
 		} else {
-			retval = do_journal_end(&myth, p_s_sb, 1, COMMIT_NOW);
+			retval = do_journal_end(&myth, sb, 1, COMMIT_NOW);
 		}
 
 		if (retval)
 			goto out_fail;
 
-		PROC_INFO_INC(p_s_sb, journal.journal_relock_wcount);
+		PROC_INFO_INC(sb, journal.journal_relock_wcount);
 		goto relock;
 	}
 	/* we are the first writer, set trans_id */
@@ -3103,7 +3103,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	th->t_blocks_logged = 0;
 	th->t_blocks_allocated = nblocks;
 	th->t_trans_id = journal->j_trans_id;
-	unlock_journal(p_s_sb);
+	unlock_journal(sb);
 	INIT_LIST_HEAD(&th->t_list);
 	get_fs_excl();
 	return 0;
@@ -3113,7 +3113,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	/* Re-set th->t_super, so we can properly keep track of how many
 	 * persistent transactions there are. We need to do this so if this
 	 * call is part of a failed restart_transaction, we can free it later */
-	th->t_super = p_s_sb;
+	th->t_super = sb;
 	return retval;
 }
 
@@ -3164,7 +3164,7 @@ int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
 }
 
 static int journal_join(struct reiserfs_transaction_handle *th,
-			struct super_block *p_s_sb, unsigned long nblocks)
+			struct super_block *sb, unsigned long nblocks)
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
@@ -3173,11 +3173,11 @@ static int journal_join(struct reiserfs_transaction_handle *th,
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
-	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_JOIN);
+	return do_journal_begin_r(th, sb, nblocks, JBEGIN_JOIN);
 }
 
 int journal_join_abort(struct reiserfs_transaction_handle *th,
-		       struct super_block *p_s_sb, unsigned long nblocks)
+		       struct super_block *sb, unsigned long nblocks)
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 
@@ -3186,11 +3186,11 @@ int journal_join_abort(struct reiserfs_transaction_handle *th,
 	 */
 	th->t_handle_save = cur_th;
 	BUG_ON(cur_th && cur_th->t_refcount > 1);
-	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_ABORT);
+	return do_journal_begin_r(th, sb, nblocks, JBEGIN_ABORT);
 }
 
 int journal_begin(struct reiserfs_transaction_handle *th,
-		  struct super_block *p_s_sb, unsigned long nblocks)
+		  struct super_block *sb, unsigned long nblocks)
 {
 	struct reiserfs_transaction_handle *cur_th = current->journal_info;
 	int ret;
@@ -3198,12 +3198,12 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 	th->t_handle_save = NULL;
 	if (cur_th) {
 		/* we are nesting into the current transaction */
-		if (cur_th->t_super == p_s_sb) {
+		if (cur_th->t_super == sb) {
 			BUG_ON(!cur_th->t_refcount);
 			cur_th->t_refcount++;
 			memcpy(th, cur_th, sizeof(*th));
 			if (th->t_refcount <= 1)
-				reiserfs_warning(p_s_sb, "reiserfs-2005",
+				reiserfs_warning(sb, "reiserfs-2005",
 						 "BAD: refcount <= 1, but "
 						 "journal_info != 0");
 			return 0;
@@ -3212,7 +3212,7 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 			 ** save it and restore on journal_end.  This should never
 			 ** really happen...
 			 */
-			reiserfs_warning(p_s_sb, "clm-2100",
+			reiserfs_warning(sb, "clm-2100",
 					 "nesting info a different FS");
 			th->t_handle_save = current->journal_info;
 			current->journal_info = th;
@@ -3220,7 +3220,7 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 	} else {
 		current->journal_info = th;
 	}
-	ret = do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_REG);
+	ret = do_journal_begin_r(th, sb, nblocks, JBEGIN_REG);
 	BUG_ON(current->journal_info != th);
 
 	/* I guess this boils down to being the reciprocal of clm-2100 above.
@@ -3244,28 +3244,28 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 ** if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
 */
 int journal_mark_dirty(struct reiserfs_transaction_handle *th,
-		       struct super_block *p_s_sb, struct buffer_head *bh)
+		       struct super_block *sb, struct buffer_head *bh)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn = NULL;
 	int count_already_incd = 0;
 	int prepared = 0;
 	BUG_ON(!th->t_trans_id);
 
-	PROC_INFO_INC(p_s_sb, journal.mark_dirty);
+	PROC_INFO_INC(sb, journal.mark_dirty);
 	if (th->t_trans_id != journal->j_trans_id) {
 		reiserfs_panic(th->t_super, "journal-1577",
 			       "handle trans id %ld != current trans id %ld",
 			       th->t_trans_id, journal->j_trans_id);
 	}
 
-	p_s_sb->s_dirt = 1;
+	sb->s_dirt = 1;
 
 	prepared = test_clear_buffer_journal_prepared(bh);
 	clear_buffer_journal_restore_dirty(bh);
 	/* already in this transaction, we are done */
 	if (buffer_journaled(bh)) {
-		PROC_INFO_INC(p_s_sb, journal.mark_dirty_already);
+		PROC_INFO_INC(sb, journal.mark_dirty_already);
 		return 0;
 	}
 
@@ -3274,7 +3274,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	 ** could get to disk too early.  NOT GOOD.
 	 */
 	if (!prepared || buffer_dirty(bh)) {
-		reiserfs_warning(p_s_sb, "journal-1777",
+		reiserfs_warning(sb, "journal-1777",
 				 "buffer %llu bad state "
 				 "%cPREPARED %cLOCKED %cDIRTY %cJDIRTY_WAIT",
 				 (unsigned long long)bh->b_blocknr,
@@ -3285,7 +3285,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	}
 
 	if (atomic_read(&(journal->j_wcount)) <= 0) {
-		reiserfs_warning(p_s_sb, "journal-1409",
+		reiserfs_warning(sb, "journal-1409",
 				 "returning because j_wcount was %d",
 				 atomic_read(&(journal->j_wcount)));
 		return 1;
@@ -3301,7 +3301,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 
 	if (buffer_journal_dirty(bh)) {
 		count_already_incd = 1;
-		PROC_INFO_INC(p_s_sb, journal.mark_dirty_notjournal);
+		PROC_INFO_INC(sb, journal.mark_dirty_notjournal);
 		clear_buffer_journal_dirty(bh);
 	}
 
@@ -3313,10 +3313,9 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 
 	/* now put this guy on the end */
 	if (!cn) {
-		cn = get_cnode(p_s_sb);
+		cn = get_cnode(sb);
 		if (!cn) {
-			reiserfs_panic(p_s_sb, "journal-4",
-				       "get_cnode failed!");
+			reiserfs_panic(sb, "journal-4", "get_cnode failed!");
 		}
 
 		if (th->t_blocks_logged == th->t_blocks_allocated) {
@@ -3328,7 +3327,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 
 		cn->bh = bh;
 		cn->blocknr = bh->b_blocknr;
-		cn->sb = p_s_sb;
+		cn->sb = sb;
 		cn->jlist = NULL;
 		insert_journal_hash(journal->j_hash_table, cn);
 		if (!count_already_incd) {
@@ -3349,10 +3348,10 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 }
 
 int journal_end(struct reiserfs_transaction_handle *th,
-		struct super_block *p_s_sb, unsigned long nblocks)
+		struct super_block *sb, unsigned long nblocks)
 {
 	if (!current->journal_info && th->t_refcount > 1)
-		reiserfs_warning(p_s_sb, "REISER-NESTING",
+		reiserfs_warning(sb, "REISER-NESTING",
 				 "th NULL, refcount %d", th->t_refcount);
 
 	if (!th->t_trans_id) {
@@ -3376,7 +3375,7 @@ int journal_end(struct reiserfs_transaction_handle *th,
 		}
 		return 0;
 	} else {
-		return do_journal_end(th, p_s_sb, nblocks, 0);
+		return do_journal_end(th, sb, nblocks, 0);
 	}
 }
 
@@ -3387,15 +3386,15 @@ int journal_end(struct reiserfs_transaction_handle *th,
 **
 ** returns 1 if it cleaned and relsed the buffer. 0 otherwise
 */
-static int remove_from_transaction(struct super_block *p_s_sb,
+static int remove_from_transaction(struct super_block *sb,
 				   b_blocknr_t blocknr, int already_cleaned)
 {
 	struct buffer_head *bh;
 	struct reiserfs_journal_cnode *cn;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	int ret = 0;
 
-	cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
+	cn = get_journal_hash_dev(sb, journal->j_hash_table, blocknr);
 	if (!cn || !cn->bh) {
 		return ret;
 	}
@@ -3413,7 +3412,7 @@ static int remove_from_transaction(struct super_block *p_s_sb,
 		journal->j_last = cn->prev;
 	}
 	if (bh)
-		remove_journal_hash(p_s_sb, journal->j_hash_table, NULL,
+		remove_journal_hash(sb, journal->j_hash_table, NULL,
 				    bh->b_blocknr, 0);
 	clear_buffer_journaled(bh);	/* don't log this one */
 
@@ -3423,14 +3422,14 @@ static int remove_from_transaction(struct super_block *p_s_sb,
 		clear_buffer_journal_test(bh);
 		put_bh(bh);
 		if (atomic_read(&(bh->b_count)) < 0) {
-			reiserfs_warning(p_s_sb, "journal-1752",
+			reiserfs_warning(sb, "journal-1752",
 					 "b_count < 0");
 		}
 		ret = 1;
 	}
 	journal->j_len--;
 	journal->j_len_alloc--;
-	free_cnode(p_s_sb, cn);
+	free_cnode(sb, cn);
 	return ret;
 }
 
@@ -3481,19 +3480,19 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 ** will wait until the current transaction is done/committed before returning
 */
 int journal_end_sync(struct reiserfs_transaction_handle *th,
-		     struct super_block *p_s_sb, unsigned long nblocks)
+		     struct super_block *sb, unsigned long nblocks)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	BUG_ON(!th->t_trans_id);
 	/* you can sync while nested, very, very bad */
 	BUG_ON(th->t_refcount > 1);
 	if (journal->j_len == 0) {
-		reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb),
+		reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 					     1);
-		journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb));
+		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
 	}
-	return do_journal_end(th, p_s_sb, nblocks, COMMIT_NOW | WAIT);
+	return do_journal_end(th, sb, nblocks, COMMIT_NOW | WAIT);
 }
 
 /*
@@ -3503,7 +3502,7 @@ static void flush_async_commits(struct work_struct *work)
 {
 	struct reiserfs_journal *journal =
 		container_of(work, struct reiserfs_journal, j_work.work);
-	struct super_block *p_s_sb = journal->j_work_sb;
+	struct super_block *sb = journal->j_work_sb;
 	struct reiserfs_journal_list *jl;
 	struct list_head *entry;
 
@@ -3512,7 +3511,7 @@ static void flush_async_commits(struct work_struct *work)
 		/* last entry is the youngest, commit it and you get everything */
 		entry = journal->j_journal_list.prev;
 		jl = JOURNAL_LIST_ENTRY(entry);
-		flush_commit_list(p_s_sb, jl, 1);
+		flush_commit_list(sb, jl, 1);
 	}
 	unlock_kernel();
 }
@@ -3521,11 +3520,11 @@ static void flush_async_commits(struct work_struct *work)
 ** flushes any old transactions to disk
 ** ends the current transaction if it is too old
 */
-int reiserfs_flush_old_commits(struct super_block *p_s_sb)
+int reiserfs_flush_old_commits(struct super_block *sb)
 {
 	time_t now;
 	struct reiserfs_transaction_handle th;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	now = get_seconds();
 	/* safety check so we don't flush while we are replaying the log during
@@ -3542,20 +3541,20 @@ int reiserfs_flush_old_commits(struct super_block *p_s_sb)
 	    journal->j_trans_start_time > 0 &&
 	    journal->j_len > 0 &&
 	    (now - journal->j_trans_start_time) > journal->j_max_trans_age) {
-		if (!journal_join(&th, p_s_sb, 1)) {
-			reiserfs_prepare_for_journal(p_s_sb,
-						     SB_BUFFER_WITH_SB(p_s_sb),
+		if (!journal_join(&th, sb, 1)) {
+			reiserfs_prepare_for_journal(sb,
+						     SB_BUFFER_WITH_SB(sb),
 						     1);
-			journal_mark_dirty(&th, p_s_sb,
-					   SB_BUFFER_WITH_SB(p_s_sb));
+			journal_mark_dirty(&th, sb,
+					   SB_BUFFER_WITH_SB(sb));
 
 			/* we're only being called from kreiserfsd, it makes no sense to do
 			 ** an async commit so that kreiserfsd can do it later
 			 */
-			do_journal_end(&th, p_s_sb, 1, COMMIT_NOW | WAIT);
+			do_journal_end(&th, sb, 1, COMMIT_NOW | WAIT);
 		}
 	}
-	return p_s_sb->s_dirt;
+	return sb->s_dirt;
 }
 
 /*
@@ -3570,7 +3569,7 @@ int reiserfs_flush_old_commits(struct super_block *p_s_sb)
 ** Note, we can't allow the journal_end to proceed while there are still writers in the log.
 */
 static int check_journal_end(struct reiserfs_transaction_handle *th,
-			     struct super_block *p_s_sb, unsigned long nblocks,
+			     struct super_block *sb, unsigned long nblocks,
 			     int flags)
 {
 
@@ -3579,7 +3578,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	int commit_now = flags & COMMIT_NOW;
 	int wait_on_commit = flags & WAIT;
 	struct reiserfs_journal_list *jl;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 
 	BUG_ON(!th->t_trans_id);
 
@@ -3618,31 +3617,31 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 			if (flush) {
 				journal->j_next_full_flush = 1;
 			}
-			unlock_journal(p_s_sb);
+			unlock_journal(sb);
 
 			/* sleep while the current transaction is still j_jlocked */
 			while (journal->j_trans_id == trans_id) {
 				if (atomic_read(&journal->j_jlock)) {
-					queue_log_writer(p_s_sb);
+					queue_log_writer(sb);
 				} else {
-					lock_journal(p_s_sb);
+					lock_journal(sb);
 					if (journal->j_trans_id == trans_id) {
 						atomic_set(&(journal->j_jlock),
 							   1);
 					}
-					unlock_journal(p_s_sb);
+					unlock_journal(sb);
 				}
 			}
 			BUG_ON(journal->j_trans_id == trans_id);
 			
 			if (commit_now
-			    && journal_list_still_alive(p_s_sb, trans_id)
+			    && journal_list_still_alive(sb, trans_id)
 			    && wait_on_commit) {
-				flush_commit_list(p_s_sb, jl, 1);
+				flush_commit_list(sb, jl, 1);
 			}
 			return 0;
 		}
-		unlock_journal(p_s_sb);
+		unlock_journal(sb);
 		return 0;
 	}
 
@@ -3659,12 +3658,12 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	    && journal->j_len_alloc < journal->j_max_batch
 	    && journal->j_cnode_free > (journal->j_trans_max * 3)) {
 		journal->j_bcount++;
-		unlock_journal(p_s_sb);
+		unlock_journal(sb);
 		return 0;
 	}
 
-	if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
-		reiserfs_panic(p_s_sb, "journal-003",
+	if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(sb)) {
+		reiserfs_panic(sb, "journal-003",
 			       "j_start (%ld) is too high",
 			       journal->j_start);
 	}
@@ -3686,16 +3685,16 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 ** Then remove it from the current transaction, decrementing any counters and filing it on the clean list.
 */
 int journal_mark_freed(struct reiserfs_transaction_handle *th,
-		       struct super_block *p_s_sb, b_blocknr_t blocknr)
+		       struct super_block *sb, b_blocknr_t blocknr)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn = NULL;
 	struct buffer_head *bh = NULL;
 	struct reiserfs_list_bitmap *jb = NULL;
 	int cleaned = 0;
 	BUG_ON(!th->t_trans_id);
 
-	cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
+	cn = get_journal_hash_dev(sb, journal->j_hash_table, blocknr);
 	if (cn && cn->bh) {
 		bh = cn->bh;
 		get_bh(bh);
@@ -3705,15 +3704,15 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		clear_buffer_journal_new(bh);
 		clear_prepared_bits(bh);
 		reiserfs_clean_and_file_buffer(bh);
-		cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned);
+		cleaned = remove_from_transaction(sb, blocknr, cleaned);
 	} else {
 		/* set the bit for this block in the journal bitmap for this transaction */
 		jb = journal->j_current_jl->j_list_bitmap;
 		if (!jb) {
-			reiserfs_panic(p_s_sb, "journal-1702",
+			reiserfs_panic(sb, "journal-1702",
 				       "journal_list_bitmap is NULL");
 		}
-		set_bit_in_list_bitmap(p_s_sb, blocknr, jb);
+		set_bit_in_list_bitmap(sb, blocknr, jb);
 
 		/* Note, the entire while loop is not allowed to schedule.  */
 
@@ -3721,13 +3720,13 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 			clear_prepared_bits(bh);
 			reiserfs_clean_and_file_buffer(bh);
 		}
-		cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned);
+		cleaned = remove_from_transaction(sb, blocknr, cleaned);
 
 		/* find all older transactions with this block, make sure they don't try to write it out */
-		cn = get_journal_hash_dev(p_s_sb, journal->j_list_hash_table,
+		cn = get_journal_hash_dev(sb, journal->j_list_hash_table,
 					  blocknr);
 		while (cn) {
-			if (p_s_sb == cn->sb && blocknr == cn->blocknr) {
+			if (sb == cn->sb && blocknr == cn->blocknr) {
 				set_bit(BLOCK_FREED, &cn->state);
 				if (cn->bh) {
 					if (!cleaned) {
@@ -3743,7 +3742,7 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 						put_bh(cn->bh);
 						if (atomic_read
 						    (&(cn->bh->b_count)) < 0) {
-							reiserfs_warning(p_s_sb,
+							reiserfs_warning(sb,
 								 "journal-2138",
 								 "cn->bh->b_count < 0");
 						}
@@ -3850,18 +3849,18 @@ int reiserfs_commit_for_inode(struct inode *inode)
 	return __commit_trans_jl(inode, id, jl);
 }
 
-void reiserfs_restore_prepared_buffer(struct super_block *p_s_sb,
+void reiserfs_restore_prepared_buffer(struct super_block *sb,
 				      struct buffer_head *bh)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-	PROC_INFO_INC(p_s_sb, journal.restore_prepared);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	PROC_INFO_INC(sb, journal.restore_prepared);
 	if (!bh) {
 		return;
 	}
 	if (test_clear_buffer_journal_restore_dirty(bh) &&
 	    buffer_journal_dirty(bh)) {
 		struct reiserfs_journal_cnode *cn;
-		cn = get_journal_hash_dev(p_s_sb,
+		cn = get_journal_hash_dev(sb,
 					  journal->j_list_hash_table,
 					  bh->b_blocknr);
 		if (cn && can_dirty(cn)) {
@@ -3880,10 +3879,10 @@ extern struct tree_balance *cur_tb;
 ** wait on it.
 **
 */
-int reiserfs_prepare_for_journal(struct super_block *p_s_sb,
+int reiserfs_prepare_for_journal(struct super_block *sb,
 				 struct buffer_head *bh, int wait)
 {
-	PROC_INFO_INC(p_s_sb, journal.prepare);
+	PROC_INFO_INC(sb, journal.prepare);
 
 	if (!trylock_buffer(bh)) {
 		if (!wait)
@@ -3931,10 +3930,10 @@ static void flush_old_journal_lists(struct super_block *s)
 ** journal lists, etc just won't happen.
 */
 static int do_journal_end(struct reiserfs_transaction_handle *th,
-			  struct super_block *p_s_sb, unsigned long nblocks,
+			  struct super_block *sb, unsigned long nblocks,
 			  int flags)
 {
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	struct reiserfs_journal_cnode *cn, *next, *jl_cn;
 	struct reiserfs_journal_cnode *last_cn = NULL;
 	struct reiserfs_journal_desc *desc;
@@ -3964,14 +3963,14 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 
 	put_fs_excl();
 	current->journal_info = th->t_handle_save;
-	reiserfs_check_lock_depth(p_s_sb, "journal end");
+	reiserfs_check_lock_depth(sb, "journal end");
 	if (journal->j_len == 0) {
-		reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb),
+		reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
 					     1);
-		journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb));
+		journal_mark_dirty(th, sb, SB_BUFFER_WITH_SB(sb));
 	}
 
-	lock_journal(p_s_sb);
+	lock_journal(sb);
 	if (journal->j_next_full_flush) {
 		flags |= FLUSH_ALL;
 		flush = 1;
@@ -3984,10 +3983,10 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	/* check_journal_end locks the journal, and unlocks if it does not return 1
 	 ** it tells us if we should continue with the journal_end, or just return
 	 */
-	if (!check_journal_end(th, p_s_sb, nblocks, flags)) {
-		p_s_sb->s_dirt = 1;
-		wake_queued_writers(p_s_sb);
-		reiserfs_async_progress_wait(p_s_sb);
+	if (!check_journal_end(th, sb, nblocks, flags)) {
+		sb->s_dirt = 1;
+		wake_queued_writers(sb);
+		reiserfs_async_progress_wait(sb);
 		goto out;
 	}
 
@@ -4016,8 +4015,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 
 	/* setup description block */
 	d_bh =
-	    journal_getblk(p_s_sb,
-			   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+	    journal_getblk(sb,
+			   SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 			   journal->j_start);
 	set_buffer_uptodate(d_bh);
 	desc = (struct reiserfs_journal_desc *)(d_bh)->b_data;
@@ -4026,9 +4025,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	set_desc_trans_id(desc, journal->j_trans_id);
 
 	/* setup commit block.  Don't write (keep it clean too) this one until after everyone else is written */
-	c_bh = journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+	c_bh = journal_getblk(sb, SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 			      ((journal->j_start + journal->j_len +
-				1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+				1) % SB_ONDISK_JOURNAL_SIZE(sb)));
 	commit = (struct reiserfs_journal_commit *)c_bh->b_data;
 	memset(c_bh->b_data, 0, c_bh->b_size);
 	set_commit_trans_id(commit, journal->j_trans_id);
@@ -4061,12 +4060,12 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 **  for each real block, add it to the journal list hash,
 	 ** copy into real block index array in the commit or desc block
 	 */
-	trans_half = journal_trans_half(p_s_sb->s_blocksize);
+	trans_half = journal_trans_half(sb->s_blocksize);
 	for (i = 0, cn = journal->j_first; cn; cn = cn->next, i++) {
 		if (buffer_journaled(cn->bh)) {
-			jl_cn = get_cnode(p_s_sb);
+			jl_cn = get_cnode(sb);
 			if (!jl_cn) {
-				reiserfs_panic(p_s_sb, "journal-1676",
+				reiserfs_panic(sb, "journal-1676",
 					       "get_cnode returned NULL");
 			}
 			if (i == 0) {
@@ -4082,15 +4081,15 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			   of journal or reserved area */
 
 			if (is_block_in_log_or_reserved_area
-			    (p_s_sb, cn->bh->b_blocknr)) {
-				reiserfs_panic(p_s_sb, "journal-2332",
+			    (sb, cn->bh->b_blocknr)) {
+				reiserfs_panic(sb, "journal-2332",
 					       "Trying to log block %lu, "
 					       "which is a log block",
 					       cn->bh->b_blocknr);
 			}
 			jl_cn->blocknr = cn->bh->b_blocknr;
 			jl_cn->state = 0;
-			jl_cn->sb = p_s_sb;
+			jl_cn->sb = sb;
 			jl_cn->bh = cn->bh;
 			jl_cn->jlist = jl;
 			insert_journal_hash(journal->j_list_hash_table, jl_cn);
@@ -4131,11 +4130,11 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			char *addr;
 			struct page *page;
 			tmp_bh =
-			    journal_getblk(p_s_sb,
-					   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+			    journal_getblk(sb,
+					   SB_ONDISK_JOURNAL_1st_BLOCK(sb) +
 					   ((cur_write_start +
 					     jindex) %
-					    SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+					    SB_ONDISK_JOURNAL_SIZE(sb)));
 			set_buffer_uptodate(tmp_bh);
 			page = cn->bh->b_page;
 			addr = kmap(page);
@@ -4149,13 +4148,13 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			clear_buffer_journaled(cn->bh);
 		} else {
 			/* JDirty cleared sometime during transaction.  don't log this one */
-			reiserfs_warning(p_s_sb, "journal-2048",
+			reiserfs_warning(sb, "journal-2048",
 					 "BAD, buffer in journal hash, "
 					 "but not JDirty!");
 			brelse(cn->bh);
 		}
 		next = cn->next;
-		free_cnode(p_s_sb, cn);
+		free_cnode(sb, cn);
 		cn = next;
 		cond_resched();
 	}
@@ -4165,7 +4164,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 ** so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
 	 */
 
-	journal->j_current_jl = alloc_journal_list(p_s_sb);
+	journal->j_current_jl = alloc_journal_list(sb);
 
 	/* now it is safe to insert this transaction on the main list */
 	list_add_tail(&jl->j_list, &journal->j_journal_list);
@@ -4176,7 +4175,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	old_start = journal->j_start;
 	journal->j_start =
 	    (journal->j_start + journal->j_len +
-	     2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb);
+	     2) % SB_ONDISK_JOURNAL_SIZE(sb);
 	atomic_set(&(journal->j_wcount), 0);
 	journal->j_bcount = 0;
 	journal->j_last = NULL;
@@ -4191,7 +4190,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	journal->j_len_alloc = 0;
 	journal->j_next_full_flush = 0;
 	journal->j_next_async_flush = 0;
-	init_journal_hash(p_s_sb);
+	init_journal_hash(sb);
 
 	// make sure reiserfs_add_jh sees the new current_jl before we
 	// write out the tails
@@ -4220,8 +4219,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 ** queue don't wait for this proc to flush journal lists and such.
 	 */
 	if (flush) {
-		flush_commit_list(p_s_sb, jl, 1);
-		flush_journal_list(p_s_sb, jl, 1);
+		flush_commit_list(sb, jl, 1);
+		flush_journal_list(sb, jl, 1);
 	} else if (!(jl->j_state & LIST_COMMIT_PENDING))
 		queue_delayed_work(commit_wq, &journal->j_work, HZ / 10);
 
@@ -4235,11 +4234,11 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		if (journal->j_start <= temp_jl->j_start) {
 			if ((journal->j_start + journal->j_trans_max + 1) >=
 			    temp_jl->j_start) {
-				flush_used_journal_lists(p_s_sb, temp_jl);
+				flush_used_journal_lists(sb, temp_jl);
 				goto first_jl;
 			} else if ((journal->j_start +
 				    journal->j_trans_max + 1) <
-				   SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+				   SB_ONDISK_JOURNAL_SIZE(sb)) {
 				/* if we don't cross into the next transaction and we don't
 				 * wrap, there is no way we can overlap any later transactions
 				 * break now
@@ -4248,11 +4247,11 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			}
 		} else if ((journal->j_start +
 			    journal->j_trans_max + 1) >
-			   SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+			   SB_ONDISK_JOURNAL_SIZE(sb)) {
 			if (((journal->j_start + journal->j_trans_max + 1) %
-			     SB_ONDISK_JOURNAL_SIZE(p_s_sb)) >=
+			     SB_ONDISK_JOURNAL_SIZE(sb)) >=
 			    temp_jl->j_start) {
-				flush_used_journal_lists(p_s_sb, temp_jl);
+				flush_used_journal_lists(sb, temp_jl);
 				goto first_jl;
 			} else {
 				/* we don't overlap anything from out start to the end of the
@@ -4263,34 +4262,34 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			}
 		}
 	}
-	flush_old_journal_lists(p_s_sb);
+	flush_old_journal_lists(sb);
 
 	journal->j_current_jl->j_list_bitmap =
-	    get_list_bitmap(p_s_sb, journal->j_current_jl);
+	    get_list_bitmap(sb, journal->j_current_jl);
 
 	if (!(journal->j_current_jl->j_list_bitmap)) {
-		reiserfs_panic(p_s_sb, "journal-1996",
+		reiserfs_panic(sb, "journal-1996",
 			       "could not get a list bitmap");
 	}
 
 	atomic_set(&(journal->j_jlock), 0);
-	unlock_journal(p_s_sb);
+	unlock_journal(sb);
 	/* wake up any body waiting to join. */
 	clear_bit(J_WRITERS_QUEUED, &journal->j_state);
 	wake_up(&(journal->j_join_wait));
 
 	if (!flush && wait_on_commit &&
-	    journal_list_still_alive(p_s_sb, commit_trans_id)) {
-		flush_commit_list(p_s_sb, jl, 1);
+	    journal_list_still_alive(sb, commit_trans_id)) {
+		flush_commit_list(sb, jl, 1);
 	}
       out:
-	reiserfs_check_lock_depth(p_s_sb, "journal end2");
+	reiserfs_check_lock_depth(sb, "journal end2");
 
 	memset(th, 0, sizeof(*th));
 	/* Re-set th->t_super, so we can properly keep track of how many
 	 * persistent transactions there are. We need to do this so if this
 	 * call is part of a failed restart_transaction, we can free it later */
-	th->t_super = p_s_sb;
+	th->t_super = sb;
 
 	return journal->j_errno;
 }

commit 0222e6571c332563a48d4cf5487b67feabe60b5e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:44 2009 -0400

    reiserfs: strip trailing whitespace
    
    This patch strips trailing whitespace from the reiserfs code.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index db91754cfb83..4f787462becc 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1,36 +1,36 @@
 /*
 ** Write ahead logging implementation copyright Chris Mason 2000
 **
-** The background commits make this code very interelated, and 
+** The background commits make this code very interelated, and
 ** overly complex.  I need to rethink things a bit....The major players:
 **
-** journal_begin -- call with the number of blocks you expect to log.  
+** journal_begin -- call with the number of blocks you expect to log.
 **                  If the current transaction is too
-** 		    old, it will block until the current transaction is 
+** 		    old, it will block until the current transaction is
 ** 		    finished, and then start a new one.
-**		    Usually, your transaction will get joined in with 
+**		    Usually, your transaction will get joined in with
 **                  previous ones for speed.
 **
-** journal_join  -- same as journal_begin, but won't block on the current 
+** journal_join  -- same as journal_begin, but won't block on the current
 **                  transaction regardless of age.  Don't ever call
-**                  this.  Ever.  There are only two places it should be 
+**                  this.  Ever.  There are only two places it should be
 **                  called from, and they are both inside this file.
 **
-** journal_mark_dirty -- adds blocks into this transaction.  clears any flags 
+** journal_mark_dirty -- adds blocks into this transaction.  clears any flags
 **                       that might make them get sent to disk
-**                       and then marks them BH_JDirty.  Puts the buffer head 
-**                       into the current transaction hash.  
+**                       and then marks them BH_JDirty.  Puts the buffer head
+**                       into the current transaction hash.
 **
 ** journal_end -- if the current transaction is batchable, it does nothing
 **                   otherwise, it could do an async/synchronous commit, or
-**                   a full flush of all log and real blocks in the 
+**                   a full flush of all log and real blocks in the
 **                   transaction.
 **
-** flush_old_commits -- if the current transaction is too old, it is ended and 
-**                      commit blocks are sent to disk.  Forces commit blocks 
-**                      to disk for all backgrounded commits that have been 
+** flush_old_commits -- if the current transaction is too old, it is ended and
+**                      commit blocks are sent to disk.  Forces commit blocks
+**                      to disk for all backgrounded commits that have been
 **                      around too long.
-**		     -- Note, if you call this as an immediate flush from 
+**		     -- Note, if you call this as an immediate flush from
 **		        from within kupdate, it will ignore the immediate flag
 */
 
@@ -212,7 +212,7 @@ static void allocate_bitmap_nodes(struct super_block *p_s_sb)
 			list_add(&bn->list, &journal->j_bitmap_nodes);
 			journal->j_free_bitmap_nodes++;
 		} else {
-			break;	// this is ok, we'll try again when more are needed 
+			break;	/* this is ok, we'll try again when more are needed */
 		}
 	}
 }
@@ -283,7 +283,7 @@ static int free_bitmap_nodes(struct super_block *p_s_sb)
 }
 
 /*
-** get memory for JOURNAL_NUM_BITMAPS worth of bitmaps. 
+** get memory for JOURNAL_NUM_BITMAPS worth of bitmaps.
 ** jb_array is the array to be filled in.
 */
 int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
@@ -315,7 +315,7 @@ int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 }
 
 /*
-** find an available list bitmap.  If you can't find one, flush a commit list 
+** find an available list bitmap.  If you can't find one, flush a commit list
 ** and try again
 */
 static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *p_s_sb,
@@ -348,7 +348,7 @@ static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *p_s_sb,
 	return jb;
 }
 
-/* 
+/*
 ** allocates a new chunk of X nodes, and links them all together as a list.
 ** Uses the cnode->next and cnode->prev pointers
 ** returns NULL on failure
@@ -376,7 +376,7 @@ static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
 }
 
 /*
-** pulls a cnode off the free list, or returns NULL on failure 
+** pulls a cnode off the free list, or returns NULL on failure
 */
 static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb)
 {
@@ -403,7 +403,7 @@ static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb)
 }
 
 /*
-** returns a cnode to the free list 
+** returns a cnode to the free list
 */
 static void free_cnode(struct super_block *p_s_sb,
 		       struct reiserfs_journal_cnode *cn)
@@ -1192,8 +1192,8 @@ static int flush_commit_list(struct super_block *s,
 }
 
 /*
-** flush_journal_list frequently needs to find a newer transaction for a given block.  This does that, or 
-** returns NULL if it can't find anything 
+** flush_journal_list frequently needs to find a newer transaction for a given block.  This does that, or
+** returns NULL if it can't find anything
 */
 static struct reiserfs_journal_list *find_newer_jl_for_cn(struct
 							  reiserfs_journal_cnode
@@ -1335,8 +1335,8 @@ static int update_journal_header_block(struct super_block *p_s_sb,
 	return _update_journal_header_block(p_s_sb, offset, trans_id);
 }
 
-/* 
-** flush any and all journal lists older than you are 
+/*
+** flush any and all journal lists older than you are
 ** can only be called from flush_journal_list
 */
 static int flush_older_journal_lists(struct super_block *p_s_sb,
@@ -1382,8 +1382,8 @@ static void del_from_work_list(struct super_block *s,
 ** always set flushall to 1, unless you are calling from inside
 ** flush_journal_list
 **
-** IMPORTANT.  This can only be called while there are no journal writers, 
-** and the journal is locked.  That means it can only be called from 
+** IMPORTANT.  This can only be called while there are no journal writers,
+** and the journal is locked.  That means it can only be called from
 ** do_journal_end, or by journal_release
 */
 static int flush_journal_list(struct super_block *s,
@@ -1429,7 +1429,7 @@ static int flush_journal_list(struct super_block *s,
 		goto flush_older_and_return;
 	}
 
-	/* start by putting the commit list on disk.  This will also flush 
+	/* start by putting the commit list on disk.  This will also flush
 	 ** the commit lists of any olders transactions
 	 */
 	flush_commit_list(s, jl, 1);
@@ -1444,8 +1444,8 @@ static int flush_journal_list(struct super_block *s,
 		goto flush_older_and_return;
 	}
 
-	/* loop through each cnode, see if we need to write it, 
-	 ** or wait on a more recent transaction, or just ignore it 
+	/* loop through each cnode, see if we need to write it,
+	 ** or wait on a more recent transaction, or just ignore it
 	 */
 	if (atomic_read(&(journal->j_wcount)) != 0) {
 		reiserfs_panic(s, "journal-844", "journal list is flushing, "
@@ -1473,8 +1473,8 @@ static int flush_journal_list(struct super_block *s,
 		if (!pjl && cn->bh) {
 			saved_bh = cn->bh;
 
-			/* we do this to make sure nobody releases the buffer while 
-			 ** we are working with it 
+			/* we do this to make sure nobody releases the buffer while
+			 ** we are working with it
 			 */
 			get_bh(saved_bh);
 
@@ -1497,8 +1497,8 @@ static int flush_journal_list(struct super_block *s,
 			goto free_cnode;
 		}
 
-		/* bh == NULL when the block got to disk on its own, OR, 
-		 ** the block got freed in a future transaction 
+		/* bh == NULL when the block got to disk on its own, OR,
+		 ** the block got freed in a future transaction
 		 */
 		if (saved_bh == NULL) {
 			goto free_cnode;
@@ -1586,7 +1586,7 @@ static int flush_journal_list(struct super_block *s,
 			       __func__);
       flush_older_and_return:
 
-	/* before we can update the journal header block, we _must_ flush all 
+	/* before we can update the journal header block, we _must_ flush all
 	 ** real blocks from all older transactions to disk.  This is because
 	 ** once the header block is updated, this transaction will not be
 	 ** replayed after a crash
@@ -1596,7 +1596,7 @@ static int flush_journal_list(struct super_block *s,
 	}
 
 	err = journal->j_errno;
-	/* before we can remove everything from the hash tables for this 
+	/* before we can remove everything from the hash tables for this
 	 ** transaction, we must make sure it can never be replayed
 	 **
 	 ** since we are only called from do_journal_end, we know for sure there
@@ -2016,9 +2016,9 @@ static int journal_compare_desc_commit(struct super_block *p_s_sb,
 	return 0;
 }
 
-/* returns 0 if it did not find a description block  
+/* returns 0 if it did not find a description block
 ** returns -1 if it found a corrupt commit block
-** returns 1 if both desc and commit were valid 
+** returns 1 if both desc and commit were valid
 */
 static int journal_transaction_is_valid(struct super_block *p_s_sb,
 					struct buffer_head *d_bh,
@@ -2380,8 +2380,8 @@ static int journal_read(struct super_block *p_s_sb)
 		      bdevname(journal->j_dev_bd, b));
 	start = get_seconds();
 
-	/* step 1, read in the journal header block.  Check the transaction it says 
-	 ** is the first unflushed, and if that transaction is not valid, 
+	/* step 1, read in the journal header block.  Check the transaction it says
+	 ** is the first unflushed, and if that transaction is not valid,
 	 ** replay is done
 	 */
 	journal->j_header_bh = journal_bread(p_s_sb,
@@ -2406,8 +2406,8 @@ static int journal_read(struct super_block *p_s_sb)
 			       le32_to_cpu(jh->j_last_flush_trans_id));
 		valid_journal_header = 1;
 
-		/* now, we try to read the first unflushed offset.  If it is not valid, 
-		 ** there is nothing more we can do, and it makes no sense to read 
+		/* now, we try to read the first unflushed offset.  If it is not valid,
+		 ** there is nothing more we can do, and it makes no sense to read
 		 ** through the whole log.
 		 */
 		d_bh =
@@ -2919,7 +2919,7 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 	return 0;
 }
 
-/* this must be called inside a transaction, and requires the 
+/* this must be called inside a transaction, and requires the
 ** kernel_lock to be held
 */
 void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
@@ -3040,7 +3040,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	now = get_seconds();
 
 	/* if there is no room in the journal OR
-	 ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning 
+	 ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning
 	 ** we don't sleep if there aren't other writers
 	 */
 
@@ -3240,7 +3240,7 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 **
 ** if it was dirty, cleans and files onto the clean list.  I can't let it be dirty again until the
 ** transaction is committed.
-** 
+**
 ** if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
 */
 int journal_mark_dirty(struct reiserfs_transaction_handle *th,
@@ -3290,7 +3290,7 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 				 atomic_read(&(journal->j_wcount)));
 		return 1;
 	}
-	/* this error means I've screwed up, and we've overflowed the transaction.  
+	/* this error means I've screwed up, and we've overflowed the transaction.
 	 ** Nothing can be done here, except make the FS readonly or panic.
 	 */
 	if (journal->j_len >= journal->j_trans_max) {
@@ -3380,7 +3380,7 @@ int journal_end(struct reiserfs_transaction_handle *th,
 	}
 }
 
-/* removes from the current transaction, relsing and descrementing any counters.  
+/* removes from the current transaction, relsing and descrementing any counters.
 ** also files the removed buffer directly onto the clean list
 **
 ** called by journal_mark_freed when a block has been deleted
@@ -3478,7 +3478,7 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 }
 
 /* syncs the commit blocks, but does not force the real buffers to disk
-** will wait until the current transaction is done/committed before returning 
+** will wait until the current transaction is done/committed before returning
 */
 int journal_end_sync(struct reiserfs_transaction_handle *th,
 		     struct super_block *p_s_sb, unsigned long nblocks)
@@ -3560,13 +3560,13 @@ int reiserfs_flush_old_commits(struct super_block *p_s_sb)
 
 /*
 ** returns 0 if do_journal_end should return right away, returns 1 if do_journal_end should finish the commit
-** 
-** if the current transaction is too old, but still has writers, this will wait on j_join_wait until all 
+**
+** if the current transaction is too old, but still has writers, this will wait on j_join_wait until all
 ** the writers are done.  By the time it wakes up, the transaction it was called has already ended, so it just
 ** flushes the commit list and returns 0.
 **
 ** Won't batch when flush or commit_now is set.  Also won't batch when others are waiting on j_join_wait.
-** 
+**
 ** Note, we can't allow the journal_end to proceed while there are still writers in the log.
 */
 static int check_journal_end(struct reiserfs_transaction_handle *th,
@@ -3594,7 +3594,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 		atomic_dec(&(journal->j_wcount));
 	}
 
-	/* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released 
+	/* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released
 	 ** will be dealt with by next transaction that actually writes something, but should be taken
 	 ** care of in this trans
 	 */
@@ -3603,7 +3603,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	/* if wcount > 0, and we are called to with flush or commit_now,
 	 ** we wait on j_join_wait.  We will wake up when the last writer has
 	 ** finished the transaction, and started it on its way to the disk.
-	 ** Then, we flush the commit or journal list, and just return 0 
+	 ** Then, we flush the commit or journal list, and just return 0
 	 ** because the rest of journal end was already done for this transaction.
 	 */
 	if (atomic_read(&(journal->j_wcount)) > 0) {
@@ -3674,7 +3674,7 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 /*
 ** Does all the work that makes deleting blocks safe.
 ** when deleting a block mark BH_JNew, just remove it from the current transaction, clean it's buffer_head and move on.
-** 
+**
 ** otherwise:
 ** set a bit for the block in the journal bitmap.  That will prevent it from being allocated for unformatted nodes
 ** before this transaction has finished.
@@ -3878,7 +3878,7 @@ extern struct tree_balance *cur_tb;
 ** be written to disk while we are altering it.  So, we must:
 ** clean it
 ** wait on it.
-** 
+**
 */
 int reiserfs_prepare_for_journal(struct super_block *p_s_sb,
 				 struct buffer_head *bh, int wait)
@@ -3920,7 +3920,7 @@ static void flush_old_journal_lists(struct super_block *s)
 	}
 }
 
-/* 
+/*
 ** long and ugly.  If flush, will not return until all commit
 ** blocks and all real buffers in the trans are on disk.
 ** If no_async, won't return until all commit blocks are on disk.
@@ -3981,7 +3981,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		wait_on_commit = 1;
 	}
 
-	/* check_journal_end locks the journal, and unlocks if it does not return 1 
+	/* check_journal_end locks the journal, and unlocks if it does not return 1
 	 ** it tells us if we should continue with the journal_end, or just return
 	 */
 	if (!check_journal_end(th, p_s_sb, nblocks, flags)) {
@@ -4078,7 +4078,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 				last_cn->next = jl_cn;
 			}
 			last_cn = jl_cn;
-			/* make sure the block we are trying to log is not a block 
+			/* make sure the block we are trying to log is not a block
 			   of journal or reserved area */
 
 			if (is_block_in_log_or_reserved_area
@@ -4225,9 +4225,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	} else if (!(jl->j_state & LIST_COMMIT_PENDING))
 		queue_delayed_work(commit_wq, &journal->j_work, HZ / 10);
 
-	/* if the next transaction has any chance of wrapping, flush 
-	 ** transactions that might get overwritten.  If any journal lists are very 
-	 ** old flush them as well.  
+	/* if the next transaction has any chance of wrapping, flush
+	 ** transactions that might get overwritten.  If any journal lists are very
+	 ** old flush them as well.
 	 */
       first_jl:
 	list_for_each_safe(entry, safe, &journal->j_journal_list) {

commit 32e8b1062915d00d07d3b88a95174648e369b6a3
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:26 2009 -0400

    reiserfs: rearrange journal abort
    
    This patch kills off reiserfs_journal_abort as it is never called, and
    combines __reiserfs_journal_abort_{soft,hard} into one function called
    reiserfs_abort_journal, which performs the same work. It is silent
    as opposed to the old version, since the message was always issued
    after a regular 'abort' message.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 774f3ba37409..db91754cfb83 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -4295,14 +4295,15 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	return journal->j_errno;
 }
 
-static void __reiserfs_journal_abort_hard(struct super_block *sb)
+/* Send the file system read only and refuse new transactions */
+void reiserfs_abort_journal(struct super_block *sb, int errno)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	if (test_bit(J_ABORTED, &journal->j_state))
 		return;
 
-	printk(KERN_CRIT "REISERFS: Aborting journal for filesystem on %s\n",
-	       reiserfs_bdevname(sb));
+	if (!journal->j_errno)
+		journal->j_errno = errno;
 
 	sb->s_flags |= MS_RDONLY;
 	set_bit(J_ABORTED, &journal->j_state);
@@ -4312,19 +4313,3 @@ static void __reiserfs_journal_abort_hard(struct super_block *sb)
 #endif
 }
 
-static void __reiserfs_journal_abort_soft(struct super_block *sb, int errno)
-{
-	struct reiserfs_journal *journal = SB_JOURNAL(sb);
-	if (test_bit(J_ABORTED, &journal->j_state))
-		return;
-
-	if (!journal->j_errno)
-		journal->j_errno = errno;
-
-	__reiserfs_journal_abort_hard(sb);
-}
-
-void reiserfs_journal_abort(struct super_block *sb, int errno)
-{
-	__reiserfs_journal_abort_soft(sb, errno);
-}

commit c3a9c2109f84882b9b3178f6b1838d550d3df0ec
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:25 2009 -0400

    reiserfs: rework reiserfs_panic
    
    ReiserFS panics can be somewhat inconsistent.
    In some cases:
     * a unique identifier may be associated with it
     * the function name may be included
     * the device may be printed separately
    
    This patch aims to make warnings more consistent. reiserfs_warning() prints
    the device name, so printing it a second time is not required. The function
    name for a warning is always helpful in debugging, so it is now automatically
    inserted into the output. Hans has stated that every warning should have
    a unique identifier. Some cases lack them, others really shouldn't have them.
    reiserfs_warning() now expects an id associated with each message. In the
    rare case where one isn't needed, "" will suffice.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 88a031fafd07..774f3ba37409 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -436,8 +436,8 @@ void reiserfs_check_lock_depth(struct super_block *sb, char *caller)
 {
 #ifdef CONFIG_SMP
 	if (current->lock_depth < 0) {
-		reiserfs_panic(sb, "%s called without kernel lock held",
-			       caller);
+		reiserfs_panic(sb, "journal-1", "%s called without kernel "
+			       "lock held", caller);
 	}
 #else
 	;
@@ -574,7 +574,7 @@ static inline void put_journal_list(struct super_block *s,
 				    struct reiserfs_journal_list *jl)
 {
 	if (jl->j_refcount < 1) {
-		reiserfs_panic(s, "trans id %u, refcount at %d",
+		reiserfs_panic(s, "journal-2", "trans id %u, refcount at %d",
 			       jl->j_trans_id, jl->j_refcount);
 	}
 	if (--jl->j_refcount == 0)
@@ -1416,8 +1416,7 @@ static int flush_journal_list(struct super_block *s,
 
 	count = 0;
 	if (j_len_saved > journal->j_trans_max) {
-		reiserfs_panic(s,
-			       "journal-715: flush_journal_list, length is %lu, trans id %lu\n",
+		reiserfs_panic(s, "journal-715", "length is %lu, trans id %lu",
 			       j_len_saved, jl->j_trans_id);
 		return 0;
 	}
@@ -1449,8 +1448,8 @@ static int flush_journal_list(struct super_block *s,
 	 ** or wait on a more recent transaction, or just ignore it 
 	 */
 	if (atomic_read(&(journal->j_wcount)) != 0) {
-		reiserfs_panic(s,
-			       "journal-844: panic journal list is flushing, wcount is not 0\n");
+		reiserfs_panic(s, "journal-844", "journal list is flushing, "
+			       "wcount is not 0");
 	}
 	cn = jl->j_realblock;
 	while (cn) {
@@ -1551,13 +1550,13 @@ static int flush_journal_list(struct super_block *s,
 		while (cn) {
 			if (test_bit(BLOCK_NEEDS_FLUSH, &cn->state)) {
 				if (!cn->bh) {
-					reiserfs_panic(s,
-						       "journal-1011: cn->bh is NULL\n");
+					reiserfs_panic(s, "journal-1011",
+						       "cn->bh is NULL");
 				}
 				wait_on_buffer(cn->bh);
 				if (!cn->bh) {
-					reiserfs_panic(s,
-						       "journal-1012: cn->bh is NULL\n");
+					reiserfs_panic(s, "journal-1012",
+						       "cn->bh is NULL");
 				}
 				if (unlikely(!buffer_uptodate(cn->bh))) {
 #ifdef CONFIG_REISERFS_CHECK
@@ -3255,8 +3254,8 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 
 	PROC_INFO_INC(p_s_sb, journal.mark_dirty);
 	if (th->t_trans_id != journal->j_trans_id) {
-		reiserfs_panic(th->t_super,
-			       "journal-1577: handle trans id %ld != current trans id %ld\n",
+		reiserfs_panic(th->t_super, "journal-1577",
+			       "handle trans id %ld != current trans id %ld",
 			       th->t_trans_id, journal->j_trans_id);
 	}
 
@@ -3295,8 +3294,8 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	 ** Nothing can be done here, except make the FS readonly or panic.
 	 */
 	if (journal->j_len >= journal->j_trans_max) {
-		reiserfs_panic(th->t_super,
-			       "journal-1413: journal_mark_dirty: j_len (%lu) is too big\n",
+		reiserfs_panic(th->t_super, "journal-1413",
+			       "j_len (%lu) is too big",
 			       journal->j_len);
 	}
 
@@ -3316,7 +3315,8 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	if (!cn) {
 		cn = get_cnode(p_s_sb);
 		if (!cn) {
-			reiserfs_panic(p_s_sb, "get_cnode failed!\n");
+			reiserfs_panic(p_s_sb, "journal-4",
+				       "get_cnode failed!");
 		}
 
 		if (th->t_blocks_logged == th->t_blocks_allocated) {
@@ -3584,8 +3584,8 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	BUG_ON(!th->t_trans_id);
 
 	if (th->t_trans_id != journal->j_trans_id) {
-		reiserfs_panic(th->t_super,
-			       "journal-1577: handle trans id %ld != current trans id %ld\n",
+		reiserfs_panic(th->t_super, "journal-1577",
+			       "handle trans id %ld != current trans id %ld",
 			       th->t_trans_id, journal->j_trans_id);
 	}
 
@@ -3664,8 +3664,8 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	}
 
 	if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
-		reiserfs_panic(p_s_sb,
-			       "journal-003: journal_end: j_start (%ld) is too high\n",
+		reiserfs_panic(p_s_sb, "journal-003",
+			       "j_start (%ld) is too high",
 			       journal->j_start);
 	}
 	return 1;
@@ -3710,8 +3710,8 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		/* set the bit for this block in the journal bitmap for this transaction */
 		jb = journal->j_current_jl->j_list_bitmap;
 		if (!jb) {
-			reiserfs_panic(p_s_sb,
-				       "journal-1702: journal_mark_freed, journal_list_bitmap is NULL\n");
+			reiserfs_panic(p_s_sb, "journal-1702",
+				       "journal_list_bitmap is NULL");
 		}
 		set_bit_in_list_bitmap(p_s_sb, blocknr, jb);
 
@@ -4066,8 +4066,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		if (buffer_journaled(cn->bh)) {
 			jl_cn = get_cnode(p_s_sb);
 			if (!jl_cn) {
-				reiserfs_panic(p_s_sb,
-					       "journal-1676, get_cnode returned NULL\n");
+				reiserfs_panic(p_s_sb, "journal-1676",
+					       "get_cnode returned NULL");
 			}
 			if (i == 0) {
 				jl->j_realblock = jl_cn;
@@ -4083,8 +4083,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 
 			if (is_block_in_log_or_reserved_area
 			    (p_s_sb, cn->bh->b_blocknr)) {
-				reiserfs_panic(p_s_sb,
-					       "journal-2332: Trying to log block %lu, which is a log block\n",
+				reiserfs_panic(p_s_sb, "journal-2332",
+					       "Trying to log block %lu, "
+					       "which is a log block",
 					       cn->bh->b_blocknr);
 			}
 			jl_cn->blocknr = cn->bh->b_blocknr;
@@ -4268,8 +4269,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	    get_list_bitmap(p_s_sb, journal->j_current_jl);
 
 	if (!(journal->j_current_jl->j_list_bitmap)) {
-		reiserfs_panic(p_s_sb,
-			       "journal-1996: do_journal_end, could not get a list bitmap\n");
+		reiserfs_panic(p_s_sb, "journal-1996",
+			       "could not get a list bitmap");
 	}
 
 	atomic_set(&(journal->j_jlock), 0);

commit 45b03d5e8e674eb6555b767e1c8eb40b671ff892
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:21 2009 -0400

    reiserfs: rework reiserfs_warning
    
    ReiserFS warnings can be somewhat inconsistent.
    In some cases:
     * a unique identifier may be associated with it
     * the function name may be included
     * the device may be printed separately
    
    This patch aims to make warnings more consistent. reiserfs_warning() prints
    the device name, so printing it a second time is not required. The function
    name for a warning is always helpful in debugging, so it is now automatically
    inserted into the output. Hans has stated that every warning should have
    a unique identifier. Some cases lack them, others really shouldn't have them.
    reiserfs_warning() now expects an id associated with each message. In the
    rare case where one isn't needed, "" will suffice.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 677bb926e7d6..88a031fafd07 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -300,8 +300,8 @@ int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 		jb->journal_list = NULL;
 		jb->bitmaps = vmalloc(mem);
 		if (!jb->bitmaps) {
-			reiserfs_warning(p_s_sb,
-					 "clm-2000, unable to allocate bitmaps for journal lists");
+			reiserfs_warning(p_s_sb, "clm-2000", "unable to "
+					 "allocate bitmaps for journal lists");
 			failed = 1;
 			break;
 		}
@@ -644,8 +644,8 @@ static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate)
 	char b[BDEVNAME_SIZE];
 
 	if (buffer_journaled(bh)) {
-		reiserfs_warning(NULL,
-				 "clm-2084: pinned buffer %lu:%s sent to disk",
+		reiserfs_warning(NULL, "clm-2084",
+				 "pinned buffer %lu:%s sent to disk",
 				 bh->b_blocknr, bdevname(bh->b_bdev, b));
 	}
 	if (uptodate)
@@ -1122,7 +1122,8 @@ static int flush_commit_list(struct super_block *s,
 			sync_dirty_buffer(tbh);
 		if (unlikely(!buffer_uptodate(tbh))) {
 #ifdef CONFIG_REISERFS_CHECK
-			reiserfs_warning(s, "journal-601, buffer write failed");
+			reiserfs_warning(s, "journal-601",
+					 "buffer write failed");
 #endif
 			retval = -EIO;
 		}
@@ -1154,14 +1155,14 @@ static int flush_commit_list(struct super_block *s,
 	 * up propagating the write error out to the filesystem. */
 	if (unlikely(!buffer_uptodate(jl->j_commit_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-		reiserfs_warning(s, "journal-615: buffer write failed");
+		reiserfs_warning(s, "journal-615", "buffer write failed");
 #endif
 		retval = -EIO;
 	}
 	bforget(jl->j_commit_bh);
 	if (journal->j_last_commit_id != 0 &&
 	    (jl->j_trans_id - journal->j_last_commit_id) != 1) {
-		reiserfs_warning(s, "clm-2200: last commit %lu, current %lu",
+		reiserfs_warning(s, "clm-2200", "last commit %lu, current %lu",
 				 journal->j_last_commit_id, jl->j_trans_id);
 	}
 	journal->j_last_commit_id = jl->j_trans_id;
@@ -1250,7 +1251,7 @@ static void remove_all_from_journal_list(struct super_block *p_s_sb,
 	while (cn) {
 		if (cn->blocknr != 0) {
 			if (debug) {
-				reiserfs_warning(p_s_sb,
+				reiserfs_warning(p_s_sb, "reiserfs-2201",
 						 "block %u, bh is %d, state %ld",
 						 cn->blocknr, cn->bh ? 1 : 0,
 						 cn->state);
@@ -1288,8 +1289,8 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 			wait_on_buffer((journal->j_header_bh));
 			if (unlikely(!buffer_uptodate(journal->j_header_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-				reiserfs_warning(p_s_sb,
-						 "journal-699: buffer write failed");
+				reiserfs_warning(p_s_sb, "journal-699",
+						 "buffer write failed");
 #endif
 				return -EIO;
 			}
@@ -1319,8 +1320,8 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 			sync_dirty_buffer(journal->j_header_bh);
 		}
 		if (!buffer_uptodate(journal->j_header_bh)) {
-			reiserfs_warning(p_s_sb,
-					 "journal-837: IO error during journal replay");
+			reiserfs_warning(p_s_sb, "journal-837",
+					 "IO error during journal replay");
 			return -EIO;
 		}
 	}
@@ -1401,8 +1402,7 @@ static int flush_journal_list(struct super_block *s,
 	BUG_ON(j_len_saved <= 0);
 
 	if (atomic_read(&journal->j_wcount) != 0) {
-		reiserfs_warning(s,
-				 "clm-2048: flush_journal_list called with wcount %d",
+		reiserfs_warning(s, "clm-2048", "called with wcount %d",
 				 atomic_read(&journal->j_wcount));
 	}
 	BUG_ON(jl->j_trans_id == 0);
@@ -1510,8 +1510,8 @@ static int flush_journal_list(struct super_block *s,
 		 ** is not marked JDirty_wait
 		 */
 		if ((!was_jwait) && !buffer_locked(saved_bh)) {
-			reiserfs_warning(s,
-					 "journal-813: BAD! buffer %llu %cdirty %cjwait, "
+			reiserfs_warning(s, "journal-813",
+					 "BAD! buffer %llu %cdirty %cjwait, "
 					 "not in a newer tranasction",
 					 (unsigned long long)saved_bh->
 					 b_blocknr, was_dirty ? ' ' : '!',
@@ -1529,8 +1529,8 @@ static int flush_journal_list(struct super_block *s,
 				unlock_buffer(saved_bh);
 			count++;
 		} else {
-			reiserfs_warning(s,
-					 "clm-2082: Unable to flush buffer %llu in %s",
+			reiserfs_warning(s, "clm-2082",
+					 "Unable to flush buffer %llu in %s",
 					 (unsigned long long)saved_bh->
 					 b_blocknr, __func__);
 		}
@@ -1541,8 +1541,8 @@ static int flush_journal_list(struct super_block *s,
 			/* we incremented this to keep others from taking the buffer head away */
 			put_bh(saved_bh);
 			if (atomic_read(&(saved_bh->b_count)) < 0) {
-				reiserfs_warning(s,
-						 "journal-945: saved_bh->b_count < 0");
+				reiserfs_warning(s, "journal-945",
+						 "saved_bh->b_count < 0");
 			}
 		}
 	}
@@ -1561,8 +1561,8 @@ static int flush_journal_list(struct super_block *s,
 				}
 				if (unlikely(!buffer_uptodate(cn->bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-					reiserfs_warning(s,
-							 "journal-949: buffer write failed\n");
+					reiserfs_warning(s, "journal-949",
+							 "buffer write failed");
 #endif
 					err = -EIO;
 				}
@@ -1623,7 +1623,7 @@ static int flush_journal_list(struct super_block *s,
 
 	if (journal->j_last_flush_id != 0 &&
 	    (jl->j_trans_id - journal->j_last_flush_id) != 1) {
-		reiserfs_warning(s, "clm-2201: last flush %lu, current %lu",
+		reiserfs_warning(s, "clm-2201", "last flush %lu, current %lu",
 				 journal->j_last_flush_id, jl->j_trans_id);
 	}
 	journal->j_last_flush_id = jl->j_trans_id;
@@ -2058,8 +2058,9 @@ static int journal_transaction_is_valid(struct super_block *p_s_sb,
 			return -1;
 		}
 		if (get_desc_trans_len(desc) > SB_JOURNAL(p_s_sb)->j_trans_max) {
-			reiserfs_warning(p_s_sb,
-					 "journal-2018: Bad transaction length %d encountered, ignoring transaction",
+			reiserfs_warning(p_s_sb, "journal-2018",
+					 "Bad transaction length %d "
+					 "encountered, ignoring transaction",
 					 get_desc_trans_len(desc));
 			return -1;
 		}
@@ -2195,8 +2196,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 		brelse(d_bh);
 		kfree(log_blocks);
 		kfree(real_blocks);
-		reiserfs_warning(p_s_sb,
-				 "journal-1169: kmalloc failed, unable to mount FS");
+		reiserfs_warning(p_s_sb, "journal-1169",
+				 "kmalloc failed, unable to mount FS");
 		return -1;
 	}
 	/* get all the buffer heads */
@@ -2218,15 +2219,18 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 						  j_realblock[i - trans_half]));
 		}
 		if (real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(p_s_sb)) {
-			reiserfs_warning(p_s_sb,
-					 "journal-1207: REPLAY FAILURE fsck required! Block to replay is outside of filesystem");
+			reiserfs_warning(p_s_sb, "journal-1207",
+					 "REPLAY FAILURE fsck required! "
+					 "Block to replay is outside of "
+					 "filesystem");
 			goto abort_replay;
 		}
 		/* make sure we don't try to replay onto log or reserved area */
 		if (is_block_in_log_or_reserved_area
 		    (p_s_sb, real_blocks[i]->b_blocknr)) {
-			reiserfs_warning(p_s_sb,
-					 "journal-1204: REPLAY FAILURE fsck required! Trying to replay onto a log block");
+			reiserfs_warning(p_s_sb, "journal-1204",
+					 "REPLAY FAILURE fsck required! "
+					 "Trying to replay onto a log block");
 		      abort_replay:
 			brelse_array(log_blocks, i);
 			brelse_array(real_blocks, i);
@@ -2242,8 +2246,9 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(log_blocks[i]);
 		if (!buffer_uptodate(log_blocks[i])) {
-			reiserfs_warning(p_s_sb,
-					 "journal-1212: REPLAY FAILURE fsck required! buffer write failed");
+			reiserfs_warning(p_s_sb, "journal-1212",
+					 "REPLAY FAILURE fsck required! "
+					 "buffer write failed");
 			brelse_array(log_blocks + i,
 				     get_desc_trans_len(desc) - i);
 			brelse_array(real_blocks, get_desc_trans_len(desc));
@@ -2266,8 +2271,9 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(real_blocks[i]);
 		if (!buffer_uptodate(real_blocks[i])) {
-			reiserfs_warning(p_s_sb,
-					 "journal-1226: REPLAY FAILURE, fsck required! buffer write failed");
+			reiserfs_warning(p_s_sb, "journal-1226",
+					 "REPLAY FAILURE, fsck required! "
+					 "buffer write failed");
 			brelse_array(real_blocks + i,
 				     get_desc_trans_len(desc) - i);
 			brelse(c_bh);
@@ -2418,8 +2424,8 @@ static int journal_read(struct super_block *p_s_sb)
 	}
 
 	if (continue_replay && bdev_read_only(p_s_sb->s_bdev)) {
-		reiserfs_warning(p_s_sb,
-				 "clm-2076: device is readonly, unable to replay log");
+		reiserfs_warning(p_s_sb, "clm-2076",
+				 "device is readonly, unable to replay log");
 		return -1;
 	}
 
@@ -2580,9 +2586,8 @@ static int release_journal_dev(struct super_block *super,
 	}
 
 	if (result != 0) {
-		reiserfs_warning(super,
-				 "sh-457: release_journal_dev: Cannot release journal device: %i",
-				 result);
+		reiserfs_warning(super, "sh-457",
+				 "Cannot release journal device: %i", result);
 	}
 	return result;
 }
@@ -2612,7 +2617,7 @@ static int journal_init_dev(struct super_block *super,
 		if (IS_ERR(journal->j_dev_bd)) {
 			result = PTR_ERR(journal->j_dev_bd);
 			journal->j_dev_bd = NULL;
-			reiserfs_warning(super, "sh-458: journal_init_dev: "
+			reiserfs_warning(super, "sh-458",
 					 "cannot init journal device '%s': %i",
 					 __bdevname(jdev, b), result);
 			return result;
@@ -2676,16 +2681,16 @@ static int check_advise_trans_params(struct super_block *p_s_sb,
 		    journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio ||
 		    SB_ONDISK_JOURNAL_SIZE(p_s_sb) / journal->j_trans_max <
 		    JOURNAL_MIN_RATIO) {
-		        reiserfs_warning(p_s_sb,
-				 "sh-462: bad transaction max size (%u). FSCK?",
-				 journal->j_trans_max);
+			reiserfs_warning(p_s_sb, "sh-462",
+					 "bad transaction max size (%u). "
+					 "FSCK?", journal->j_trans_max);
 			return 1;
 		}
 		if (journal->j_max_batch != (journal->j_trans_max) *
 		        JOURNAL_MAX_BATCH_DEFAULT/JOURNAL_TRANS_MAX_DEFAULT) {
-		        reiserfs_warning(p_s_sb,
-				"sh-463: bad transaction max batch (%u). FSCK?",
-				journal->j_max_batch);
+			reiserfs_warning(p_s_sb, "sh-463",
+					 "bad transaction max batch (%u). "
+					 "FSCK?", journal->j_max_batch);
 			return 1;
 		}
 	} else {
@@ -2693,9 +2698,11 @@ static int check_advise_trans_params(struct super_block *p_s_sb,
                    The file system was created by old version
 		   of mkreiserfs, so some fields contain zeros,
 		   and we need to advise proper values for them */
-	        if (p_s_sb->s_blocksize != REISERFS_STANDARD_BLKSIZE)
-	                reiserfs_panic(p_s_sb, "sh-464: bad blocksize (%u)",
-				       p_s_sb->s_blocksize);
+		if (p_s_sb->s_blocksize != REISERFS_STANDARD_BLKSIZE) {
+			reiserfs_warning(p_s_sb, "sh-464", "bad blocksize (%u)",
+					 p_s_sb->s_blocksize);
+			return 1;
+		}
 		journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT;
 		journal->j_max_batch = JOURNAL_MAX_BATCH_DEFAULT;
 		journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE;
@@ -2719,8 +2726,8 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 
 	journal = SB_JOURNAL(p_s_sb) = vmalloc(sizeof(struct reiserfs_journal));
 	if (!journal) {
-		reiserfs_warning(p_s_sb,
-				 "journal-1256: unable to get memory for journal structure");
+		reiserfs_warning(p_s_sb, "journal-1256",
+				 "unable to get memory for journal structure");
 		return 1;
 	}
 	memset(journal, 0, sizeof(struct reiserfs_journal));
@@ -2749,9 +2756,9 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	if (!SB_ONDISK_JOURNAL_DEVICE(p_s_sb) &&
 	    (SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) +
 	     SB_ONDISK_JOURNAL_SIZE(p_s_sb) > p_s_sb->s_blocksize * 8)) {
-		reiserfs_warning(p_s_sb,
-				 "journal-1393: journal does not fit for area "
-				 "addressed by first of bitmap blocks. It starts at "
+		reiserfs_warning(p_s_sb, "journal-1393",
+				 "journal does not fit for area addressed "
+				 "by first of bitmap blocks. It starts at "
 				 "%u and its size is %u. Block size %ld",
 				 SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb),
 				 SB_ONDISK_JOURNAL_SIZE(p_s_sb),
@@ -2760,8 +2767,8 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	}
 
 	if (journal_init_dev(p_s_sb, journal, j_dev_name) != 0) {
-		reiserfs_warning(p_s_sb,
-				 "sh-462: unable to initialize jornal device");
+		reiserfs_warning(p_s_sb, "sh-462",
+				 "unable to initialize jornal device");
 		goto free_and_return;
 	}
 
@@ -2772,8 +2779,8 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 			     SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
 			     SB_ONDISK_JOURNAL_SIZE(p_s_sb));
 	if (!bhjh) {
-		reiserfs_warning(p_s_sb,
-				 "sh-459: unable to read journal header");
+		reiserfs_warning(p_s_sb, "sh-459",
+				 "unable to read journal header");
 		goto free_and_return;
 	}
 	jh = (struct reiserfs_journal_header *)(bhjh->b_data);
@@ -2782,10 +2789,10 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	if (is_reiserfs_jr(rs)
 	    && (le32_to_cpu(jh->jh_journal.jp_journal_magic) !=
 		sb_jp_journal_magic(rs))) {
-		reiserfs_warning(p_s_sb,
-				 "sh-460: journal header magic %x "
-				 "(device %s) does not match to magic found in super "
-				 "block %x", jh->jh_journal.jp_journal_magic,
+		reiserfs_warning(p_s_sb, "sh-460",
+				 "journal header magic %x (device %s) does "
+				 "not match to magic found in super block %x",
+				 jh->jh_journal.jp_journal_magic,
 				 bdevname(journal->j_dev_bd, b),
 				 sb_jp_journal_magic(rs));
 		brelse(bhjh);
@@ -2852,7 +2859,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_must_wait = 0;
 
 	if (journal->j_cnode_free == 0) {
-        	reiserfs_warning(p_s_sb, "journal-2004: Journal cnode memory "
+		reiserfs_warning(p_s_sb, "journal-2004", "Journal cnode memory "
 		                 "allocation failed (%ld bytes). Journal is "
 		                 "too large for available memory. Usually "
 		                 "this is due to a journal that is too large.",
@@ -2864,12 +2871,13 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	jl = journal->j_current_jl;
 	jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);
 	if (!jl->j_list_bitmap) {
-		reiserfs_warning(p_s_sb,
-				 "journal-2005, get_list_bitmap failed for journal list 0");
+		reiserfs_warning(p_s_sb, "journal-2005",
+				 "get_list_bitmap failed for journal list 0");
 		goto free_and_return;
 	}
 	if (journal_read(p_s_sb) < 0) {
-		reiserfs_warning(p_s_sb, "Replay Failure, unable to mount");
+		reiserfs_warning(p_s_sb, "reiserfs-2006",
+				 "Replay Failure, unable to mount");
 		goto free_and_return;
 	}
 
@@ -3196,16 +3204,17 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 			cur_th->t_refcount++;
 			memcpy(th, cur_th, sizeof(*th));
 			if (th->t_refcount <= 1)
-				reiserfs_warning(p_s_sb,
-						 "BAD: refcount <= 1, but journal_info != 0");
+				reiserfs_warning(p_s_sb, "reiserfs-2005",
+						 "BAD: refcount <= 1, but "
+						 "journal_info != 0");
 			return 0;
 		} else {
 			/* we've ended up with a handle from a different filesystem.
 			 ** save it and restore on journal_end.  This should never
 			 ** really happen...
 			 */
-			reiserfs_warning(p_s_sb,
-					 "clm-2100: nesting info a different FS");
+			reiserfs_warning(p_s_sb, "clm-2100",
+					 "nesting info a different FS");
 			th->t_handle_save = current->journal_info;
 			current->journal_info = th;
 		}
@@ -3266,7 +3275,8 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	 ** could get to disk too early.  NOT GOOD.
 	 */
 	if (!prepared || buffer_dirty(bh)) {
-		reiserfs_warning(p_s_sb, "journal-1777: buffer %llu bad state "
+		reiserfs_warning(p_s_sb, "journal-1777",
+				 "buffer %llu bad state "
 				 "%cPREPARED %cLOCKED %cDIRTY %cJDIRTY_WAIT",
 				 (unsigned long long)bh->b_blocknr,
 				 prepared ? ' ' : '!',
@@ -3276,8 +3286,8 @@ int journal_mark_dirty(struct reiserfs_transaction_handle *th,
 	}
 
 	if (atomic_read(&(journal->j_wcount)) <= 0) {
-		reiserfs_warning(p_s_sb,
-				 "journal-1409: journal_mark_dirty returning because j_wcount was %d",
+		reiserfs_warning(p_s_sb, "journal-1409",
+				 "returning because j_wcount was %d",
 				 atomic_read(&(journal->j_wcount)));
 		return 1;
 	}
@@ -3342,8 +3352,8 @@ int journal_end(struct reiserfs_transaction_handle *th,
 		struct super_block *p_s_sb, unsigned long nblocks)
 {
 	if (!current->journal_info && th->t_refcount > 1)
-		reiserfs_warning(p_s_sb, "REISER-NESTING: th NULL, refcount %d",
-				 th->t_refcount);
+		reiserfs_warning(p_s_sb, "REISER-NESTING",
+				 "th NULL, refcount %d", th->t_refcount);
 
 	if (!th->t_trans_id) {
 		WARN_ON(1);
@@ -3413,8 +3423,8 @@ static int remove_from_transaction(struct super_block *p_s_sb,
 		clear_buffer_journal_test(bh);
 		put_bh(bh);
 		if (atomic_read(&(bh->b_count)) < 0) {
-			reiserfs_warning(p_s_sb,
-					 "journal-1752: remove from trans, b_count < 0");
+			reiserfs_warning(p_s_sb, "journal-1752",
+					 "b_count < 0");
 		}
 		ret = 1;
 	}
@@ -3734,7 +3744,8 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 						if (atomic_read
 						    (&(cn->bh->b_count)) < 0) {
 							reiserfs_warning(p_s_sb,
-									 "journal-2138: cn->bh->b_count < 0");
+								 "journal-2138",
+								 "cn->bh->b_count < 0");
 						}
 					}
 					if (cn->jlist) {	/* since we are clearing the bh, we MUST dec nonzerolen */
@@ -4137,8 +4148,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 			clear_buffer_journaled(cn->bh);
 		} else {
 			/* JDirty cleared sometime during transaction.  don't log this one */
-			reiserfs_warning(p_s_sb,
-					 "journal-2048: do_journal_end: BAD, buffer in journal hash, but not JDirty!");
+			reiserfs_warning(p_s_sb, "journal-2048",
+					 "BAD, buffer in journal hash, "
+					 "but not JDirty!");
 			brelse(cn->bh);
 		}
 		next = cn->next;

commit 600ed41675d8c384519d8f0b3c76afed39ef2f4b
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Mon Mar 30 14:02:17 2009 -0400

    reiserfs: audit transaction ids to always be unsigned ints
    
    This patch fixes up the reiserfs code such that transaction ids are
    always unsigned ints.  In places they can currently be signed ints or
    unsigned longs.
    
    The former just causes an annoying clm-2200 warning and may join a
    transaction when it should wait.
    
    The latter is just for correctness since the disk format uses a 32-bit
    transaction id.  There aren't any runtime problems that result from it
    not wrapping at the correct location since the value is truncated
    correctly even on big endian systems.  The 0 value might make it to
    disk, but the mount-time checks will bump it to 10 itself.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 9643c3bbeb3b..677bb926e7d6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -574,7 +574,7 @@ static inline void put_journal_list(struct super_block *s,
 				    struct reiserfs_journal_list *jl)
 {
 	if (jl->j_refcount < 1) {
-		reiserfs_panic(s, "trans id %lu, refcount at %d",
+		reiserfs_panic(s, "trans id %u, refcount at %d",
 			       jl->j_trans_id, jl->j_refcount);
 	}
 	if (--jl->j_refcount == 0)
@@ -599,7 +599,7 @@ static void cleanup_freed_for_journal_list(struct super_block *p_s_sb,
 }
 
 static int journal_list_still_alive(struct super_block *s,
-				    unsigned long trans_id)
+				    unsigned int trans_id)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	struct list_head *entry = &journal->j_journal_list;
@@ -933,9 +933,9 @@ static int flush_older_commits(struct super_block *s,
 	struct reiserfs_journal_list *other_jl;
 	struct reiserfs_journal_list *first_jl;
 	struct list_head *entry;
-	unsigned long trans_id = jl->j_trans_id;
-	unsigned long other_trans_id;
-	unsigned long first_trans_id;
+	unsigned int trans_id = jl->j_trans_id;
+	unsigned int other_trans_id;
+	unsigned int first_trans_id;
 
       find_first:
 	/*
@@ -1014,7 +1014,7 @@ static int flush_commit_list(struct super_block *s,
 	int i;
 	b_blocknr_t bn;
 	struct buffer_head *tbh = NULL;
-	unsigned long trans_id = jl->j_trans_id;
+	unsigned int trans_id = jl->j_trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	int barrier = 0;
 	int retval = 0;
@@ -1275,7 +1275,7 @@ static void remove_all_from_journal_list(struct super_block *p_s_sb,
 */
 static int _update_journal_header_block(struct super_block *p_s_sb,
 					unsigned long offset,
-					unsigned long trans_id)
+					unsigned int trans_id)
 {
 	struct reiserfs_journal_header *jh;
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
@@ -1329,7 +1329,7 @@ static int _update_journal_header_block(struct super_block *p_s_sb,
 
 static int update_journal_header_block(struct super_block *p_s_sb,
 				       unsigned long offset,
-				       unsigned long trans_id)
+				       unsigned int trans_id)
 {
 	return _update_journal_header_block(p_s_sb, offset, trans_id);
 }
@@ -1344,7 +1344,7 @@ static int flush_older_journal_lists(struct super_block *p_s_sb,
 	struct list_head *entry;
 	struct reiserfs_journal_list *other_jl;
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-	unsigned long trans_id = jl->j_trans_id;
+	unsigned int trans_id = jl->j_trans_id;
 
 	/* we know we are the only ones flushing things, no extra race
 	 * protection is required.
@@ -1758,13 +1758,13 @@ static int dirty_one_transaction(struct super_block *s,
 static int kupdate_transactions(struct super_block *s,
 				struct reiserfs_journal_list *jl,
 				struct reiserfs_journal_list **next_jl,
-				unsigned long *next_trans_id,
+				unsigned int *next_trans_id,
 				int num_blocks, int num_trans)
 {
 	int ret = 0;
 	int written = 0;
 	int transactions_flushed = 0;
-	unsigned long orig_trans_id = jl->j_trans_id;
+	unsigned int orig_trans_id = jl->j_trans_id;
 	struct buffer_chunk chunk;
 	struct list_head *entry;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
@@ -1833,7 +1833,7 @@ static int flush_used_journal_lists(struct super_block *s,
 	int limit = 256;
 	struct reiserfs_journal_list *tjl;
 	struct reiserfs_journal_list *flush_jl;
-	unsigned long trans_id;
+	unsigned int trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 
 	flush_jl = tjl = jl;
@@ -2023,7 +2023,7 @@ static int journal_compare_desc_commit(struct super_block *p_s_sb,
 */
 static int journal_transaction_is_valid(struct super_block *p_s_sb,
 					struct buffer_head *d_bh,
-					unsigned long *oldest_invalid_trans_id,
+					unsigned int *oldest_invalid_trans_id,
 					unsigned long *newest_mount_id)
 {
 	struct reiserfs_journal_desc *desc;
@@ -2124,18 +2124,18 @@ static void brelse_array(struct buffer_head **heads, int num)
 static int journal_read_transaction(struct super_block *p_s_sb,
 				    unsigned long cur_dblock,
 				    unsigned long oldest_start,
-				    unsigned long oldest_trans_id,
+				    unsigned int oldest_trans_id,
 				    unsigned long newest_mount_id)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 	struct reiserfs_journal_desc *desc;
 	struct reiserfs_journal_commit *commit;
-	unsigned long trans_id = 0;
+	unsigned int trans_id = 0;
 	struct buffer_head *c_bh;
 	struct buffer_head *d_bh;
 	struct buffer_head **log_blocks = NULL;
 	struct buffer_head **real_blocks = NULL;
-	unsigned long trans_offset;
+	unsigned int trans_offset;
 	int i;
 	int trans_half;
 
@@ -2356,8 +2356,8 @@ static int journal_read(struct super_block *p_s_sb)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 	struct reiserfs_journal_desc *desc;
-	unsigned long oldest_trans_id = 0;
-	unsigned long oldest_invalid_trans_id = 0;
+	unsigned int oldest_trans_id = 0;
+	unsigned int oldest_invalid_trans_id = 0;
 	time_t start;
 	unsigned long oldest_start = 0;
 	unsigned long cur_dblock = 0;
@@ -2970,7 +2970,7 @@ static void wake_queued_writers(struct super_block *s)
 		wake_up(&journal->j_join_wait);
 }
 
-static void let_transaction_grow(struct super_block *sb, unsigned long trans_id)
+static void let_transaction_grow(struct super_block *sb, unsigned int trans_id)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned long bcount = journal->j_bcount;
@@ -3001,7 +3001,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 			      int join)
 {
 	time_t now = get_seconds();
-	int old_trans_id;
+	unsigned int old_trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 	struct reiserfs_transaction_handle myth;
 	int sched_count = 0;
@@ -3824,7 +3824,7 @@ static int __commit_trans_jl(struct inode *inode, unsigned long id,
 
 int reiserfs_commit_for_inode(struct inode *inode)
 {
-	unsigned long id = REISERFS_I(inode)->i_trans_id;
+	unsigned int id = REISERFS_I(inode)->i_trans_id;
 	struct reiserfs_journal_list *jl = REISERFS_I(inode)->i_jl;
 
 	/* for the whole inode, assume unset id means it was
@@ -3938,7 +3938,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	struct reiserfs_journal_list *jl, *temp_jl;
 	struct list_head *entry, *safe;
 	unsigned long jindex;
-	unsigned long commit_trans_id;
+	unsigned int commit_trans_id;
 	int trans_half;
 
 	BUG_ON(th->t_refcount > 1);
@@ -3946,7 +3946,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 
 	/* protect flush_older_commits from doing mistakes if the
            transaction ID counter gets overflowed.  */
-	if (th->t_trans_id == ~0UL)
+	if (th->t_trans_id == ~0U)
 		flags |= FLUSH_ALL | COMMIT_NOW | WAIT;
 	flush = flags & FLUSH_ALL;
 	wait_on_commit = flags & WAIT;

commit e5eb8caa83a76191feb9705c1a0a689ca260b91e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Oct 8 13:24:05 2007 -0400

    [PATCH] remember mode of reiserfs journal
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 70b896076676..9643c3bbeb3b 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2575,7 +2575,7 @@ static int release_journal_dev(struct super_block *super,
 	if (journal->j_dev_bd != NULL) {
 		if (journal->j_dev_bd->bd_dev != super->s_dev)
 			bd_release(journal->j_dev_bd);
-		result = blkdev_put(journal->j_dev_bd, 0); /* move up */
+		result = blkdev_put(journal->j_dev_bd, journal->j_dev_mode);
 		journal->j_dev_bd = NULL;
 	}
 
@@ -2608,6 +2608,7 @@ static int journal_init_dev(struct super_block *super,
 	/* there is no "jdev" option and journal is on separate device */
 	if ((!jdev_name || !jdev_name[0])) {
 		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode);
+		journal->j_dev_mode = blkdev_mode;
 		if (IS_ERR(journal->j_dev_bd)) {
 			result = PTR_ERR(journal->j_dev_bd);
 			journal->j_dev_bd = NULL;
@@ -2628,8 +2629,9 @@ static int journal_init_dev(struct super_block *super,
 		return 0;
 	}
 
+	journal->j_dev_mode = blkdev_mode;
 	journal->j_dev_bd = open_bdev_exclusive(jdev_name,
-						FMODE_READ|FMODE_WRITE, journal);
+						blkdev_mode, journal);
 	if (IS_ERR(journal->j_dev_bd)) {
 		result = PTR_ERR(journal->j_dev_bd);
 		journal->j_dev_bd = NULL;

commit 30c40d2c01f68c7eb1a41ab3552bdaf5dbf300d4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 22 19:50:45 2008 -0500

    [PATCH] propagate mode through open_bdev_excl/close_bdev_excl
    
    replace open_bdev_excl/close_bdev_excl with variants taking fmode_t.
    superblock gets the value used to mount it stored in sb->s_mode
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 3261518478f4..70b896076676 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2628,7 +2628,8 @@ static int journal_init_dev(struct super_block *super,
 		return 0;
 	}
 
-	journal->j_dev_bd = open_bdev_excl(jdev_name, 0, journal);
+	journal->j_dev_bd = open_bdev_exclusive(jdev_name,
+						FMODE_READ|FMODE_WRITE, journal);
 	if (IS_ERR(journal->j_dev_bd)) {
 		result = PTR_ERR(journal->j_dev_bd);
 		journal->j_dev_bd = NULL;

commit 9a1c3542768b5a58e45a9216921cd10a3bae1205
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 22 20:40:24 2008 -0500

    [PATCH] pass fmode_t to blkdev_put()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b89d193a00d9..3261518478f4 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2575,7 +2575,7 @@ static int release_journal_dev(struct super_block *super,
 	if (journal->j_dev_bd != NULL) {
 		if (journal->j_dev_bd->bd_dev != super->s_dev)
 			bd_release(journal->j_dev_bd);
-		result = blkdev_put(journal->j_dev_bd);
+		result = blkdev_put(journal->j_dev_bd, 0); /* move up */
 		journal->j_dev_bd = NULL;
 	}
 
@@ -2618,7 +2618,7 @@ static int journal_init_dev(struct super_block *super,
 		} else if (jdev != super->s_dev) {
 			result = bd_claim(journal->j_dev_bd, journal);
 			if (result) {
-				blkdev_put(journal->j_dev_bd);
+				blkdev_put(journal->j_dev_bd, blkdev_mode);
 				return result;
 			}
 

commit aeb5d727062a0238a2f96c9c380fbd2be4640c6f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Sep 2 15:28:45 2008 -0400

    [PATCH] introduce fmode_t, do annotations
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c21df71943a6..b89d193a00d9 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2593,7 +2593,7 @@ static int journal_init_dev(struct super_block *super,
 {
 	int result;
 	dev_t jdev;
-	int blkdev_mode = FMODE_READ | FMODE_WRITE;
+	fmode_t blkdev_mode = FMODE_READ | FMODE_WRITE;
 	char b[BDEVNAME_SIZE];
 
 	result = 0;

commit ca5de404ff036a29b25e9a83f6919c9f606c5841
Author: Nick Piggin <npiggin@suse.de>
Date:   Sat Aug 2 12:02:13 2008 +0200

    fs: rename buffer trylock
    
    Like the page lock change, this also requires name change, so convert the
    raw test_and_set bitop to a trylock.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ce2208b27118..c21df71943a6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -855,7 +855,7 @@ static int write_ordered_buffers(spinlock_t * lock,
 		jh = JH_ENTRY(list->next);
 		bh = jh->bh;
 		get_bh(bh);
-		if (test_set_buffer_locked(bh)) {
+		if (!trylock_buffer(bh)) {
 			if (!buffer_dirty(bh)) {
 				list_move(&jh->list, &tmp);
 				goto loop_next;
@@ -3871,7 +3871,7 @@ int reiserfs_prepare_for_journal(struct super_block *p_s_sb,
 {
 	PROC_INFO_INC(p_s_sb, journal.prepare);
 
-	if (test_set_buffer_locked(bh)) {
+	if (!trylock_buffer(bh)) {
 		if (!wait)
 			return 0;
 		lock_buffer(bh);

commit 529ae9aaa08378cfe2a4350bded76f32cc8ff0ce
Author: Nick Piggin <npiggin@suse.de>
Date:   Sat Aug 2 12:01:03 2008 +0200

    mm: rename page trylock
    
    Converting page lock to new locking bitops requires a change of page flag
    operation naming, so we might as well convert it to something nicer
    (!TestSetPageLocked_Lock => trylock_page, SetPageLocked => set_page_locked).
    
    This also facilitates lockdeping of page lock.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c8f60ee183b5..ce2208b27118 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -627,7 +627,7 @@ static int journal_list_still_alive(struct super_block *s,
 static void release_buffer_page(struct buffer_head *bh)
 {
 	struct page *page = bh->b_page;
-	if (!page->mapping && !TestSetPageLocked(page)) {
+	if (!page->mapping && trylock_page(page)) {
 		page_cache_get(page);
 		put_bh(bh);
 		if (!page->mapping)

commit 90415deac75a761a25239af6f56381546f8d2201
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Jul 25 01:46:40 2008 -0700

    reiserfs: convert j_commit_lock to mutex
    
    j_commit_lock is a semaphore but uses it as if it were a mutex.  This patch
    converts it to a mutex.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Edward Shishkin <edward.shishkin@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 3cb4a562030e..c8f60ee183b5 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -34,15 +34,10 @@
 **		        from within kupdate, it will ignore the immediate flag
 */
 
-#include <asm/uaccess.h>
-#include <asm/system.h>
-
 #include <linux/time.h>
 #include <linux/semaphore.h>
-
 #include <linux/vmalloc.h>
 #include <linux/reiserfs_fs.h>
-
 #include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/fcntl.h>
@@ -54,6 +49,9 @@
 #include <linux/writeback.h>
 #include <linux/blkdev.h>
 #include <linux/backing-dev.h>
+#include <linux/uaccess.h>
+
+#include <asm/system.h>
 
 /* gets a struct reiserfs_journal_list * from a list head */
 #define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
@@ -1045,9 +1043,9 @@ static int flush_commit_list(struct super_block *s,
 	}
 
 	/* make sure nobody is trying to flush this one at the same time */
-	down(&jl->j_commit_lock);
+	mutex_lock(&jl->j_commit_mutex);
 	if (!journal_list_still_alive(s, trans_id)) {
-		up(&jl->j_commit_lock);
+		mutex_unlock(&jl->j_commit_mutex);
 		goto put_jl;
 	}
 	BUG_ON(jl->j_trans_id == 0);
@@ -1057,7 +1055,7 @@ static int flush_commit_list(struct super_block *s,
 		if (flushall) {
 			atomic_set(&(jl->j_older_commits_done), 1);
 		}
-		up(&jl->j_commit_lock);
+		mutex_unlock(&jl->j_commit_mutex);
 		goto put_jl;
 	}
 
@@ -1181,7 +1179,7 @@ static int flush_commit_list(struct super_block *s,
 	if (flushall) {
 		atomic_set(&(jl->j_older_commits_done), 1);
 	}
-	up(&jl->j_commit_lock);
+	mutex_unlock(&jl->j_commit_mutex);
       put_jl:
 	put_journal_list(s, jl);
 
@@ -2556,7 +2554,7 @@ static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
 	INIT_LIST_HEAD(&jl->j_working_list);
 	INIT_LIST_HEAD(&jl->j_tail_bh_list);
 	INIT_LIST_HEAD(&jl->j_bh_list);
-	sema_init(&jl->j_commit_lock, 1);
+	mutex_init(&jl->j_commit_mutex);
 	SB_JOURNAL(s)->j_num_lists++;
 	get_journal_list(jl);
 	return jl;
@@ -4030,7 +4028,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	 * the new transaction is fully setup, and we've already flushed the
 	 * ordered bh list
 	 */
-	down(&jl->j_commit_lock);
+	mutex_lock(&jl->j_commit_mutex);
 
 	/* save the transaction id in case we need to commit it later */
 	commit_trans_id = jl->j_trans_id;
@@ -4196,7 +4194,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		lock_kernel();
 	}
 	BUG_ON(!list_empty(&jl->j_tail_bh_list));
-	up(&jl->j_commit_lock);
+	mutex_unlock(&jl->j_commit_mutex);
 
 	/* honor the flush wishes from the caller, simple commits can
 	 ** be done outside the journal lock, they are done below

commit afe70259076fff0446001eaa1a287f615241a357
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Jul 25 01:46:39 2008 -0700

    reiserfs: convert j_flush_sem to mutex
    
    j_flush_sem is a semaphore but uses it as if it were a mutex.  This patch
    converts it to a mutex.
    
    [akpm@linux-foundation.org: fix mutex_trylock retval treatment]
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Edward Shishkin <edward.shishkin@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 0f7b1e807e60..3cb4a562030e 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1411,8 +1411,8 @@ static int flush_journal_list(struct super_block *s,
 
 	/* if flushall == 0, the lock is already held */
 	if (flushall) {
-		down(&journal->j_flush_sem);
-	} else if (!down_trylock(&journal->j_flush_sem)) {
+		mutex_lock(&journal->j_flush_mutex);
+	} else if (mutex_trylock(&journal->j_flush_mutex)) {
 		BUG();
 	}
 
@@ -1642,7 +1642,7 @@ static int flush_journal_list(struct super_block *s,
 	jl->j_state = 0;
 	put_journal_list(s, jl);
 	if (flushall)
-		up(&journal->j_flush_sem);
+		mutex_unlock(&journal->j_flush_mutex);
 	put_fs_excl();
 	return err;
 }
@@ -1772,12 +1772,12 @@ static int kupdate_transactions(struct super_block *s,
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	chunk.nr = 0;
 
-	down(&journal->j_flush_sem);
+	mutex_lock(&journal->j_flush_mutex);
 	if (!journal_list_still_alive(s, orig_trans_id)) {
 		goto done;
 	}
 
-	/* we've got j_flush_sem held, nobody is going to delete any
+	/* we've got j_flush_mutex held, nobody is going to delete any
 	 * of these lists out from underneath us
 	 */
 	while ((num_trans && transactions_flushed < num_trans) ||
@@ -1812,7 +1812,7 @@ static int kupdate_transactions(struct super_block *s,
 	}
 
       done:
-	up(&journal->j_flush_sem);
+	mutex_unlock(&journal->j_flush_mutex);
 	return ret;
 }
 
@@ -2838,7 +2838,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_first = NULL;
 	init_waitqueue_head(&(journal->j_join_wait));
 	mutex_init(&journal->j_mutex);
-	sema_init(&journal->j_flush_sem, 1);
+	mutex_init(&journal->j_flush_mutex);
 
 	journal->j_trans_id = 10;
 	journal->j_mount_id = 10;

commit f68215c4640a38d66429014e524a627bf572d26a
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Jul 25 01:46:38 2008 -0700

    reiserfs: convert j_lock to mutex
    
    j_lock is a semaphore but uses it as if it were a mutex.  This patch converts
    it to a mutex.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Edward Shishkin <edward.shishkin@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e396b2fa4743..0f7b1e807e60 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -558,13 +558,13 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 static inline void lock_journal(struct super_block *p_s_sb)
 {
 	PROC_INFO_INC(p_s_sb, journal.lock_journal);
-	down(&SB_JOURNAL(p_s_sb)->j_lock);
+	mutex_lock(&SB_JOURNAL(p_s_sb)->j_mutex);
 }
 
 /* unlock the current transaction */
 static inline void unlock_journal(struct super_block *p_s_sb)
 {
-	up(&SB_JOURNAL(p_s_sb)->j_lock);
+	mutex_unlock(&SB_JOURNAL(p_s_sb)->j_mutex);
 }
 
 static inline void get_journal_list(struct reiserfs_journal_list *jl)
@@ -2837,7 +2837,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_last = NULL;
 	journal->j_first = NULL;
 	init_waitqueue_head(&(journal->j_join_wait));
-	sema_init(&journal->j_lock, 1);
+	mutex_init(&journal->j_mutex);
 	sema_init(&journal->j_flush_sem, 1);
 
 	journal->j_trans_id = 10;

commit 86098fa0115358abf5159093d11ddb306ce4b0da
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 30 00:54:46 2008 -0700

    reiserfs: use open_bdev_excl
    
    Use the proper helper to open a blockdevice by name for filesystem use,
    this makes sure it's properly claimed (also added for open-by-number) and
    gets rid of the struct file abuse.
    
    Tested by mounting a reiserfs filesystem with external journal.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Acked-by: Edward Shishkin <edward.shishkin@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index da86042b3e03..e396b2fa4743 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2574,11 +2574,9 @@ static int release_journal_dev(struct super_block *super,
 
 	result = 0;
 
-	if (journal->j_dev_file != NULL) {
-		result = filp_close(journal->j_dev_file, NULL);
-		journal->j_dev_file = NULL;
-		journal->j_dev_bd = NULL;
-	} else if (journal->j_dev_bd != NULL) {
+	if (journal->j_dev_bd != NULL) {
+		if (journal->j_dev_bd->bd_dev != super->s_dev)
+			bd_release(journal->j_dev_bd);
 		result = blkdev_put(journal->j_dev_bd);
 		journal->j_dev_bd = NULL;
 	}
@@ -2603,7 +2601,6 @@ static int journal_init_dev(struct super_block *super,
 	result = 0;
 
 	journal->j_dev_bd = NULL;
-	journal->j_dev_file = NULL;
 	jdev = SB_ONDISK_JOURNAL_DEVICE(super) ?
 	    new_decode_dev(SB_ONDISK_JOURNAL_DEVICE(super)) : super->s_dev;
 
@@ -2620,35 +2617,34 @@ static int journal_init_dev(struct super_block *super,
 					 "cannot init journal device '%s': %i",
 					 __bdevname(jdev, b), result);
 			return result;
-		} else if (jdev != super->s_dev)
+		} else if (jdev != super->s_dev) {
+			result = bd_claim(journal->j_dev_bd, journal);
+			if (result) {
+				blkdev_put(journal->j_dev_bd);
+				return result;
+			}
+
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);
+		}
+
 		return 0;
 	}
 
-	journal->j_dev_file = filp_open(jdev_name, 0, 0);
-	if (!IS_ERR(journal->j_dev_file)) {
-		struct inode *jdev_inode = journal->j_dev_file->f_mapping->host;
-		if (!S_ISBLK(jdev_inode->i_mode)) {
-			reiserfs_warning(super, "journal_init_dev: '%s' is "
-					 "not a block device", jdev_name);
-			result = -ENOTBLK;
-			release_journal_dev(super, journal);
-		} else {
-			/* ok */
-			journal->j_dev_bd = I_BDEV(jdev_inode);
-			set_blocksize(journal->j_dev_bd, super->s_blocksize);
-			reiserfs_info(super,
-				      "journal_init_dev: journal device: %s\n",
-				      bdevname(journal->j_dev_bd, b));
-		}
-	} else {
-		result = PTR_ERR(journal->j_dev_file);
-		journal->j_dev_file = NULL;
+	journal->j_dev_bd = open_bdev_excl(jdev_name, 0, journal);
+	if (IS_ERR(journal->j_dev_bd)) {
+		result = PTR_ERR(journal->j_dev_bd);
+		journal->j_dev_bd = NULL;
 		reiserfs_warning(super,
 				 "journal_init_dev: Cannot open '%s': %i",
 				 jdev_name, result);
+		return result;
 	}
-	return result;
+
+	set_blocksize(journal->j_dev_bd, super->s_blocksize);
+	reiserfs_info(super,
+		      "journal_init_dev: journal device: %s\n",
+		      bdevname(journal->j_dev_bd, b));
+	return 0;
 }
 
 /**

commit fbe5498b3d5af44a8671800e85b2858c2ea236fa
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Mon Apr 28 02:16:22 2008 -0700

    reiserfs: replace remaining __FUNCTION__ occurrences
    
    __FUNCTION__ is gcc-specific, use __func__
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 2e87b6aaec72..da86042b3e03 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1187,7 +1187,7 @@ static int flush_commit_list(struct super_block *s,
 
 	if (retval)
 		reiserfs_abort(s, retval, "Journal write error in %s",
-			       __FUNCTION__);
+			       __func__);
 	put_fs_excl();
 	return retval;
 }
@@ -1534,7 +1534,7 @@ static int flush_journal_list(struct super_block *s,
 			reiserfs_warning(s,
 					 "clm-2082: Unable to flush buffer %llu in %s",
 					 (unsigned long long)saved_bh->
-					 b_blocknr, __FUNCTION__);
+					 b_blocknr, __func__);
 		}
 	      free_cnode:
 		last = cn;
@@ -1586,7 +1586,7 @@ static int flush_journal_list(struct super_block *s,
 	if (err)
 		reiserfs_abort(s, -EIO,
 			       "Write error while pushing transaction to disk in %s",
-			       __FUNCTION__);
+			       __func__);
       flush_older_and_return:
 
 	/* before we can update the journal header block, we _must_ flush all 
@@ -1616,7 +1616,7 @@ static int flush_journal_list(struct super_block *s,
 		if (err)
 			reiserfs_abort(s, -EIO,
 				       "Write error while updating journal header in %s",
-				       __FUNCTION__);
+				       __func__);
 	}
 	remove_all_from_journal_list(s, jl, 0);
 	list_del_init(&jl->j_list);

commit e13601bc6aa427a6483e7f66fde55ac3b5fed335
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Mon Apr 28 02:16:21 2008 -0700

    reiserfs: fix sparse warning in journal.c
    
    fs/reiserfs/journal.c:4319:2: warning: returning void-valued expression
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 060eb3f598e7..2e87b6aaec72 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -4316,5 +4316,5 @@ static void __reiserfs_journal_abort_soft(struct super_block *sb, int errno)
 
 void reiserfs_journal_abort(struct super_block *sb, int errno)
 {
-	return __reiserfs_journal_abort_soft(sb, errno);
+	__reiserfs_journal_abort_soft(sb, errno);
 }

commit 6188e10d38b8d7244ee7776d5f1f88c837b4b93f
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Fri Apr 18 22:21:05 2008 -0400

    Convert asm/semaphore.h users to linux/semaphore.h
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index bb05a3e51b93..060eb3f598e7 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -38,7 +38,7 @@
 #include <asm/system.h>
 
 #include <linux/time.h>
-#include <asm/semaphore.h>
+#include <linux/semaphore.h>
 
 #include <linux/vmalloc.h>
 #include <linux/reiserfs_fs.h>

commit cb680c1be62e9898fc2ca2a89d9fdba7c84a5c81
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Oct 18 23:39:27 2007 -0700

    reiserfs: ignore on disk s_bmap_nr value
    
    Implement support for file systems larger than 8 TiB.
    
    The reiserfs superblock contains a 16 bit value for counting the number of
    bitmap blocks.  The rest of the disk format supports file systems up to 2^32
    blocks, but the bitmap block limitation artificially limits this to 8 TiB with
    a 4KiB block size.
    
    Rather than trust the superblock's 16-bit bitmap block count, we calculate it
    dynamically based on the number of blocks in the file system.  When an
    incorrect value is observed in the superblock, it is zeroed out, ensuring that
    older kernels will not be able to mount the file system.
    
    Userspace support has already been implemented and shipped in reiserfsprogs
    3.6.20.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 0e30ba0ac489..bb05a3e51b93 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -240,7 +240,7 @@ static void cleanup_bitmap_list(struct super_block *p_s_sb,
 	if (jb->bitmaps == NULL)
 		return;
 
-	for (i = 0; i < SB_BMAP_NR(p_s_sb); i++) {
+	for (i = 0; i < reiserfs_bmap_count(p_s_sb); i++) {
 		if (jb->bitmaps[i]) {
 			free_bitmap_node(p_s_sb, jb->bitmaps[i]);
 			jb->bitmaps[i] = NULL;
@@ -2734,7 +2734,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_persistent_trans = 0;
 	if (reiserfs_allocate_list_bitmaps(p_s_sb,
 					   journal->j_list_bitmap,
-					   SB_BMAP_NR(p_s_sb)))
+					   reiserfs_bmap_count(p_s_sb)))
 		goto free_and_return;
 	allocate_bitmap_nodes(p_s_sb);
 
@@ -2742,7 +2742,7 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) = (old_format ?
 						 REISERFS_OLD_DISK_OFFSET_IN_BYTES
 						 / p_s_sb->s_blocksize +
-						 SB_BMAP_NR(p_s_sb) +
+						 reiserfs_bmap_count(p_s_sb) +
 						 1 :
 						 REISERFS_DISK_OFFSET_IN_BYTES /
 						 p_s_sb->s_blocksize + 2);

commit 3ee1667042c350003b9d3f35e5666cc8c43ce8aa
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Thu Oct 18 23:39:25 2007 -0700

    reiserfs: fix usage of signed ints for block numbers
    
    Do a quick signedness check for block numbers.  There are a number of places
    where signed integers are used for block numbers, which limits the usable file
    system size to 8 TiB.  The disk format, excepting a problem which will be
    fixed in the following patch, supports file systems up to 16 TiB in size.
    This patch cleans up those sites so that we can enable the full usable size.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4cad9e75ef56..0e30ba0ac489 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -219,11 +219,12 @@ static void allocate_bitmap_nodes(struct super_block *p_s_sb)
 	}
 }
 
-static int set_bit_in_list_bitmap(struct super_block *p_s_sb, int block,
+static int set_bit_in_list_bitmap(struct super_block *p_s_sb,
+				  b_blocknr_t block,
 				  struct reiserfs_list_bitmap *jb)
 {
-	int bmap_nr = block / (p_s_sb->s_blocksize << 3);
-	int bit_nr = block % (p_s_sb->s_blocksize << 3);
+	unsigned int bmap_nr = block / (p_s_sb->s_blocksize << 3);
+	unsigned int bit_nr = block % (p_s_sb->s_blocksize << 3);
 
 	if (!jb->bitmaps[bmap_nr]) {
 		jb->bitmaps[bmap_nr] = get_bitmap_node(p_s_sb);
@@ -289,7 +290,7 @@ static int free_bitmap_nodes(struct super_block *p_s_sb)
 */
 int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
 				   struct reiserfs_list_bitmap *jb_array,
-				   int bmap_nr)
+				   unsigned int bmap_nr)
 {
 	int i;
 	int failed = 0;
@@ -483,7 +484,7 @@ static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
 **
 */
 int reiserfs_in_journal(struct super_block *p_s_sb,
-			int bmap_nr, int bit_nr, int search_all,
+			unsigned int bmap_nr, int bit_nr, int search_all,
 			b_blocknr_t * next_zero_bit)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
@@ -1013,7 +1014,7 @@ static int flush_commit_list(struct super_block *s,
 			     struct reiserfs_journal_list *jl, int flushall)
 {
 	int i;
-	int bn;
+	b_blocknr_t bn;
 	struct buffer_head *tbh = NULL;
 	unsigned long trans_id = jl->j_trans_id;
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
@@ -2307,8 +2308,9 @@ static int journal_read_transaction(struct super_block *p_s_sb,
    Right now it is only used from journal code. But later we might use it
    from other places.
    Note: Do not use journal_getblk/sb_getblk functions here! */
-static struct buffer_head *reiserfs_breada(struct block_device *dev, int block,
-					   int bufsize, unsigned int max_block)
+static struct buffer_head *reiserfs_breada(struct block_device *dev,
+					   b_blocknr_t block, int bufsize,
+					   b_blocknr_t max_block)
 {
 	struct buffer_head *bhlist[BUFNR];
 	unsigned int blocks = BUFNR;

commit cf3d0b8182f0746dbb9ed3609e3aa0c3802f45e8
Author: Edward Shishkin <edward@namesys.com>
Date:   Tue Oct 16 23:30:30 2007 -0700

    reiserfs: do not repair wrong journal params
    
    When mounting a file system with wrong journal params do not try to repair
    them, suggest fsck instead.
    
    Signed-off-by: Edward Shishkin <edward@namesys.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <chris.mason@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 6c1d0c35f9e9..4cad9e75ef56 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2649,6 +2649,61 @@ static int journal_init_dev(struct super_block *super,
 	return result;
 }
 
+/**
+ * When creating/tuning a file system user can assign some
+ * journal params within boundaries which depend on the ratio
+ * blocksize/standard_blocksize.
+ *
+ * For blocks >= standard_blocksize transaction size should
+ * be not less then JOURNAL_TRANS_MIN_DEFAULT, and not more
+ * then JOURNAL_TRANS_MAX_DEFAULT.
+ *
+ * For blocks < standard_blocksize these boundaries should be
+ * decreased proportionally.
+ */
+#define REISERFS_STANDARD_BLKSIZE (4096)
+
+static int check_advise_trans_params(struct super_block *p_s_sb,
+				     struct reiserfs_journal *journal)
+{
+        if (journal->j_trans_max) {
+	        /* Non-default journal params.
+		   Do sanity check for them. */
+	        int ratio = 1;
+		if (p_s_sb->s_blocksize < REISERFS_STANDARD_BLKSIZE)
+		        ratio = REISERFS_STANDARD_BLKSIZE / p_s_sb->s_blocksize;
+
+		if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio ||
+		    journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio ||
+		    SB_ONDISK_JOURNAL_SIZE(p_s_sb) / journal->j_trans_max <
+		    JOURNAL_MIN_RATIO) {
+		        reiserfs_warning(p_s_sb,
+				 "sh-462: bad transaction max size (%u). FSCK?",
+				 journal->j_trans_max);
+			return 1;
+		}
+		if (journal->j_max_batch != (journal->j_trans_max) *
+		        JOURNAL_MAX_BATCH_DEFAULT/JOURNAL_TRANS_MAX_DEFAULT) {
+		        reiserfs_warning(p_s_sb,
+				"sh-463: bad transaction max batch (%u). FSCK?",
+				journal->j_max_batch);
+			return 1;
+		}
+	} else {
+		/* Default journal params.
+                   The file system was created by old version
+		   of mkreiserfs, so some fields contain zeros,
+		   and we need to advise proper values for them */
+	        if (p_s_sb->s_blocksize != REISERFS_STANDARD_BLKSIZE)
+	                reiserfs_panic(p_s_sb, "sh-464: bad blocksize (%u)",
+				       p_s_sb->s_blocksize);
+		journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT;
+		journal->j_max_batch = JOURNAL_MAX_BATCH_DEFAULT;
+		journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE;
+	}
+	return 0;
+}
+
 /*
 ** must be called once on fs mount.  calls journal_read for you
 */
@@ -2744,49 +2799,8 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	    le32_to_cpu(jh->jh_journal.jp_journal_max_commit_age);
 	journal->j_max_trans_age = JOURNAL_MAX_TRANS_AGE;
 
-	if (journal->j_trans_max) {
-		/* make sure these parameters are available, assign it if they are not */
-		__u32 initial = journal->j_trans_max;
-		__u32 ratio = 1;
-
-		if (p_s_sb->s_blocksize < 4096)
-			ratio = 4096 / p_s_sb->s_blocksize;
-
-		if (SB_ONDISK_JOURNAL_SIZE(p_s_sb) / journal->j_trans_max <
-		    JOURNAL_MIN_RATIO)
-			journal->j_trans_max =
-			    SB_ONDISK_JOURNAL_SIZE(p_s_sb) / JOURNAL_MIN_RATIO;
-		if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio)
-			journal->j_trans_max =
-			    JOURNAL_TRANS_MAX_DEFAULT / ratio;
-		if (journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio)
-			journal->j_trans_max =
-			    JOURNAL_TRANS_MIN_DEFAULT / ratio;
-
-		if (journal->j_trans_max != initial)
-			reiserfs_warning(p_s_sb,
-					 "sh-461: journal_init: wrong transaction max size (%u). Changed to %u",
-					 initial, journal->j_trans_max);
-
-		journal->j_max_batch = journal->j_trans_max *
-		    JOURNAL_MAX_BATCH_DEFAULT / JOURNAL_TRANS_MAX_DEFAULT;
-	}
-
-	if (!journal->j_trans_max) {
-		/*we have the file system was created by old version of mkreiserfs 
-		   so this field contains zero value */
-		journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT;
-		journal->j_max_batch = JOURNAL_MAX_BATCH_DEFAULT;
-		journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE;
-
-		/* for blocksize >= 4096 - max transaction size is 1024. For block size < 4096
-		   trans max size is decreased proportionally */
-		if (p_s_sb->s_blocksize < 4096) {
-			journal->j_trans_max /= (4096 / p_s_sb->s_blocksize);
-			journal->j_max_batch = (journal->j_trans_max) * 9 / 10;
-		}
-	}
-
+	if (check_advise_trans_params(p_s_sb, journal) != 0)
+	        goto free_and_return;
 	journal->j_default_max_commit_age = journal->j_max_commit_age;
 
 	if (commit_max_age != 0) {

commit 398c95bdf2c24d7866692a40ba04425aef238cdd
Author: Chris Mason <chris.mason@oracle.com>
Date:   Tue Oct 16 23:29:44 2007 -0700

    try to reap reiserfs pages left around by invalidatepage
    
    reiserfs_invalidatepage will refuse to free pages if they have been logged
    in data=journal mode, or were pinned down by a data=ordered operation.  For
    data=journal, this is fairly easy to trigger just with fsx-linux, and it
    results in a large number of pages hanging around on the LRUs with
    page->mapping == NULL.
    
    Calling try_to_free_buffers when reiserfs decides it is done with the page
    allows it to be freed earlier, and with much less VM thrashing.  Lock
    ordering rules mean that reiserfs can't call lock_page when it is releasing
    the buffers, so TestSetPageLocked is used instead.  Contention on these
    pages should be rare, so it should be sufficient most of the time.
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>
    Cc: "Vladimir V. Saveliev" <vs@namesys.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ca8d9e86571f..6c1d0c35f9e9 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -615,6 +615,31 @@ static int journal_list_still_alive(struct super_block *s,
 	return 0;
 }
 
+/*
+ * If page->mapping was null, we failed to truncate this page for
+ * some reason.  Most likely because it was truncated after being
+ * logged via data=journal.
+ *
+ * This does a check to see if the buffer belongs to one of these
+ * lost pages before doing the final put_bh.  If page->mapping was
+ * null, it tries to free buffers on the page, which should make the
+ * final page_cache_release drop the page from the lru.
+ */
+static void release_buffer_page(struct buffer_head *bh)
+{
+	struct page *page = bh->b_page;
+	if (!page->mapping && !TestSetPageLocked(page)) {
+		page_cache_get(page);
+		put_bh(bh);
+		if (!page->mapping)
+			try_to_free_buffers(page);
+		unlock_page(page);
+		page_cache_release(page);
+	} else {
+		put_bh(bh);
+	}
+}
+
 static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate)
 {
 	char b[BDEVNAME_SIZE];
@@ -628,8 +653,9 @@ static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate)
 		set_buffer_uptodate(bh);
 	else
 		clear_buffer_uptodate(bh);
+
 	unlock_buffer(bh);
-	put_bh(bh);
+	release_buffer_page(bh);
 }
 
 static void reiserfs_end_ordered_io(struct buffer_head *bh, int uptodate)
@@ -1547,9 +1573,10 @@ static int flush_journal_list(struct super_block *s,
 				BUG_ON(!test_clear_buffer_journal_dirty
 				       (cn->bh));
 
-				/* undo the inc from journal_mark_dirty */
+				/* drop one ref for us */
 				put_bh(cn->bh);
-				brelse(cn->bh);
+				/* drop one ref for journal_mark_dirty */
+				release_buffer_page(cn->bh);
 			}
 			cn = cn->next;
 		}
@@ -3709,13 +3736,8 @@ int journal_mark_freed(struct reiserfs_transaction_handle *th,
 		}
 	}
 
-	if (bh) {
-		put_bh(bh);	/* get_hash grabs the buffer */
-		if (atomic_read(&(bh->b_count)) < 0) {
-			reiserfs_warning(p_s_sb,
-					 "journal-2165: bh->b_count < 0");
-		}
-	}
+	if (bh)
+		release_buffer_page(bh); /* get_hash grabs the buffer */
 	return 0;
 }
 

commit deba0f49b9345f885a53a077623a68cef89c01d5
Author: Adrian Bunk <bunk@stusta.de>
Date:   Tue Oct 16 23:26:03 2007 -0700

    fs/reiserfs/: cleanups
    
    - remove the following no longer used functions:
      - bitmap.c: reiserfs_claim_blocks_to_be_allocated()
      - bitmap.c: reiserfs_release_claimed_blocks()
      - bitmap.c: reiserfs_can_fit_pages()
    
    - make the following functions static:
      - inode.c: restart_transaction()
      - journal.c: reiserfs_async_progress_wait()
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Acked-by: Vladimir V. Saveliev <vs@namesys.com>
    Cc: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index f25086aeef5f..ca8d9e86571f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -966,7 +966,8 @@ static int flush_older_commits(struct super_block *s,
 	}
 	return 0;
 }
-int reiserfs_async_progress_wait(struct super_block *s)
+
+static int reiserfs_async_progress_wait(struct super_block *s)
 {
 	DEFINE_WAIT(wait);
 	struct reiserfs_journal *j = SB_JOURNAL(s);

commit beb7dd86a101263bf63a78c7c6d4da3849b35bd6
Author: Robert P. J. Day <rpjday@mindspring.com>
Date:   Wed May 9 07:14:03 2007 +0200

    Fix misspellings collected by members of KJ list.
    
    Fix the misspellings of "propogate", "writting" and (oh, the shame
    :-) "kenrel" in the source tree.
    
    Signed-off-by: Robert P. J. Day <rpjday@mindspring.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e073fd86cf60..f25086aeef5f 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1110,7 +1110,7 @@ static int flush_commit_list(struct super_block *s,
 	if (!barrier) {
 		/* If there was a write error in the journal - we can't commit
 		 * this transaction - it will be invalid and, if successful,
-		 * will just end up propogating the write error out to
+		 * will just end up propagating the write error out to
 		 * the file system. */
 		if (likely(!retval && !reiserfs_is_journal_aborted (journal))) {
 			if (buffer_dirty(jl->j_commit_bh))
@@ -1125,7 +1125,7 @@ static int flush_commit_list(struct super_block *s,
 
 	/* If there was a write error in the journal - we can't commit this
 	 * transaction - it will be invalid and, if successful, will just end
-	 * up propogating the write error out to the filesystem. */
+	 * up propagating the write error out to the filesystem. */
 	if (unlikely(!buffer_uptodate(jl->j_commit_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
 		reiserfs_warning(s, "journal-615: buffer write failed");

commit 5ab2f7e0fdd04148e08348701d6bd6a292ce2d26
Author: Milind Arun Choudhary <milindchoudhary@gmail.com>
Date:   Tue May 8 00:30:51 2007 -0700

    reiserfs: use __set_current_state()
    
    use __set_current_state(TASK_*) instead of current->state = TASK_*, in
    fs/reiserfs
    
    Signed-off-by: Milind Arun Choudhary <milindchoudhary@gmail.com>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 7280a23ef344..e073fd86cf60 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2918,7 +2918,7 @@ static void queue_log_writer(struct super_block *s)
 	set_current_state(TASK_UNINTERRUPTIBLE);
 	if (test_bit(J_WRITERS_QUEUED, &journal->j_state))
 		schedule();
-	current->state = TASK_RUNNING;
+	__set_current_state(TASK_RUNNING);
 	remove_wait_queue(&journal->j_join_wait, &wait);
 }
 

commit 4c1ac1b49122b805adfa4efc620592f68dccf5db
Merge: c4028958b6ec d916faace3ef
Author: David Howells <dhowells@redhat.com>
Date:   Tue Dec 5 14:37:56 2006 +0000

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6
    
    Conflicts:
    
            drivers/infiniband/core/iwcm.c
            drivers/net/chelsio/cxgb2.c
            drivers/net/wireless/bcm43xx/bcm43xx_main.c
            drivers/net/wireless/prism54/islpci_eth.c
            drivers/usb/core/hub.h
            drivers/usb/input/hid-core.c
            net/core/netpoll.c
    
    Fix up merge failures with Linus's head and fix new compilation failures.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>

commit 0779bf2d2ecc4d9b1e9437ae659f50e6776a7666
Author: Matt LaPlante <kernel1@cyberdogtech.com>
Date:   Thu Nov 30 05:24:39 2006 +0100

    Fix misc .c/.h comment typos
    
    Fix various .c/.h typos in comments (no code changes).
    
    Signed-off-by: Matt LaPlante <kernel1@cyberdogtech.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 85ce23268302..ac93174c9639 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1464,7 +1464,7 @@ static int flush_journal_list(struct super_block *s,
 		}
 
 		/* if someone has this block in a newer transaction, just make
-		 ** sure they are commited, and don't try writing it to disk
+		 ** sure they are committed, and don't try writing it to disk
 		 */
 		if (pjl) {
 			if (atomic_read(&pjl->j_commit_left))
@@ -3384,7 +3384,7 @@ static int remove_from_transaction(struct super_block *p_s_sb,
 
 /*
 ** for any cnode in a journal list, it can only be dirtied of all the
-** transactions that include it are commited to disk.
+** transactions that include it are committed to disk.
 ** this checks through each transaction, and returns 1 if you are allowed to dirty,
 ** and 0 if you aren't
 **
@@ -3426,7 +3426,7 @@ static int can_dirty(struct reiserfs_journal_cnode *cn)
 }
 
 /* syncs the commit blocks, but does not force the real buffers to disk
-** will wait until the current transaction is done/commited before returning 
+** will wait until the current transaction is done/committed before returning 
 */
 int journal_end_sync(struct reiserfs_transaction_handle *th,
 		     struct super_block *p_s_sb, unsigned long nblocks)

commit c4028958b6ecad064b1a6303a6a5906d4fe48d73
Author: David Howells <dhowells@redhat.com>
Date:   Wed Nov 22 14:57:56 2006 +0000

    WorkStruct: make allyesconfig
    
    Fix up for make allyesconfig.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 85ce23268302..cd1bb75ceb24 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -104,7 +104,7 @@ static int release_journal_dev(struct super_block *super,
 			       struct reiserfs_journal *journal);
 static int dirty_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl);
-static void flush_async_commits(void *p);
+static void flush_async_commits(struct work_struct *work);
 static void queue_log_writer(struct super_block *s);
 
 /* values for join in do_journal_begin_r */
@@ -2836,7 +2836,8 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	if (reiserfs_mounted_fs_count <= 1)
 		commit_wq = create_workqueue("reiserfs");
 
-	INIT_WORK(&journal->j_work, flush_async_commits, p_s_sb);
+	INIT_DELAYED_WORK(&journal->j_work, flush_async_commits);
+	journal->j_work_sb = p_s_sb;
 	return 0;
       free_and_return:
 	free_journal_ram(p_s_sb);
@@ -3447,10 +3448,11 @@ int journal_end_sync(struct reiserfs_transaction_handle *th,
 /*
 ** writeback the pending async commits to disk
 */
-static void flush_async_commits(void *p)
+static void flush_async_commits(struct work_struct *work)
 {
-	struct super_block *p_s_sb = p;
-	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal *journal =
+		container_of(work, struct reiserfs_journal, j_work.work);
+	struct super_block *p_s_sb = journal->j_work_sb;
 	struct reiserfs_journal_list *jl;
 	struct list_head *entry;
 

commit 3fcfab16c5b86eaa3db3a9a31adba550c5b67141
Author: Andrew Morton <akpm@osdl.org>
Date:   Thu Oct 19 23:28:16 2006 -0700

    [PATCH] separate bdi congestion functions from queue congestion functions
    
    Separate out the concept of "queue congestion" from "backing-dev congestion".
    Congestion is a backing-dev concept, not a queue concept.
    
    The blk_* congestion functions are retained, as wrappers around the core
    backing-dev congestion functions.
    
    This proper layering is needed so that NFS can cleanly use the congestion
    functions, and so that CONFIG_BLOCK=n actually links.
    
    Cc: "Thomas Maier" <balagi@justmail.de>
    Cc: "Jens Axboe" <jens.axboe@oracle.com>
    Cc: Trond Myklebust <trond.myklebust@fys.uio.no>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Peter Osterlund <petero2@telia.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ad8cbc49883a..85ce23268302 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -53,6 +53,7 @@
 #include <linux/workqueue.h>
 #include <linux/writeback.h>
 #include <linux/blkdev.h>
+#include <linux/backing-dev.h>
 
 /* gets a struct reiserfs_journal_list * from a list head */
 #define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
@@ -970,7 +971,7 @@ int reiserfs_async_progress_wait(struct super_block *s)
 	DEFINE_WAIT(wait);
 	struct reiserfs_journal *j = SB_JOURNAL(s);
 	if (atomic_read(&j->j_async_throttle))
-		blk_congestion_wait(WRITE, HZ / 10);
+		congestion_wait(WRITE, HZ / 10);
 	return 0;
 }
 

commit 14a61442c2203d2a49f2f954bfa9259c0ddac1aa
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Tue Oct 3 23:36:38 2006 +0200

    BUG_ON conversion for fs/reiserfs
    
    This patch converts several if () BUG(); construct to BUG_ON();
    which occupies less space, uses unlikely and is safer when
    BUG() is disabled. S_ISREG() has no side effects, so the
    conversion is safe.
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index e6b5ccf23f15..ad8cbc49883a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -718,8 +718,7 @@ static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
 			spinlock_t * lock, void (fn) (struct buffer_chunk *))
 {
 	int ret = 0;
-	if (chunk->nr >= CHUNK_SIZE)
-		BUG();
+	BUG_ON(chunk->nr >= CHUNK_SIZE);
 	chunk->bh[chunk->nr++] = bh;
 	if (chunk->nr >= CHUNK_SIZE) {
 		ret = 1;
@@ -788,8 +787,7 @@ static inline int __add_jh(struct reiserfs_journal *j, struct buffer_head *bh,
 		/* buffer must be locked for __add_jh, should be able to have
 		 * two adds at the same time
 		 */
-		if (bh->b_private)
-			BUG();
+		BUG_ON(bh->b_private);
 		jh->bh = bh;
 		bh->b_private = jh;
 	}
@@ -2967,8 +2965,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
 	int retval;
 
 	reiserfs_check_lock_depth(p_s_sb, "journal_begin");
-	if (nblocks > journal->j_trans_max)
-		BUG();
+	BUG_ON(nblocks > journal->j_trans_max);
 
 	PROC_INFO_INC(p_s_sb, journal.journal_being);
 	/* set here for journal_join */
@@ -3084,9 +3081,8 @@ struct reiserfs_transaction_handle *reiserfs_persistent_transaction(struct
 	if (reiserfs_transaction_running(s)) {
 		th = current->journal_info;
 		th->t_refcount++;
-		if (th->t_refcount < 2) {
-			BUG();
-		}
+		BUG_ON(th->t_refcount < 2);
+		
 		return th;
 	}
 	th = kmalloc(sizeof(struct reiserfs_transaction_handle), GFP_NOFS);
@@ -3126,9 +3122,7 @@ static int journal_join(struct reiserfs_transaction_handle *th,
 	 ** pointer
 	 */
 	th->t_handle_save = cur_th;
-	if (cur_th && cur_th->t_refcount > 1) {
-		BUG();
-	}
+	BUG_ON(cur_th && cur_th->t_refcount > 1);
 	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_JOIN);
 }
 
@@ -3141,9 +3135,7 @@ int journal_join_abort(struct reiserfs_transaction_handle *th,
 	 ** pointer
 	 */
 	th->t_handle_save = cur_th;
-	if (cur_th && cur_th->t_refcount > 1) {
-		BUG();
-	}
+	BUG_ON(cur_th && cur_th->t_refcount > 1);
 	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_ABORT);
 }
 
@@ -3178,8 +3170,7 @@ int journal_begin(struct reiserfs_transaction_handle *th,
 		current->journal_info = th;
 	}
 	ret = do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_REG);
-	if (current->journal_info != th)
-		BUG();
+	BUG_ON(current->journal_info != th);
 
 	/* I guess this boils down to being the reciprocal of clm-2100 above.
 	 * If do_journal_begin_r fails, we need to put it back, since journal_end
@@ -3324,8 +3315,7 @@ int journal_end(struct reiserfs_transaction_handle *th,
 		/* we aren't allowed to close a nested transaction on a different
 		 ** filesystem from the one in the task struct
 		 */
-		if (cur_th->t_super != th->t_super)
-			BUG();
+		BUG_ON(cur_th->t_super != th->t_super);
 
 		if (th != cur_th) {
 			memcpy(current->journal_info, th, sizeof(*th));
@@ -3444,9 +3434,7 @@ int journal_end_sync(struct reiserfs_transaction_handle *th,
 
 	BUG_ON(!th->t_trans_id);
 	/* you can sync while nested, very, very bad */
-	if (th->t_refcount > 1) {
-		BUG();
-	}
+	BUG_ON(th->t_refcount > 1);
 	if (journal->j_len == 0) {
 		reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb),
 					     1);
@@ -3556,9 +3544,8 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 	 ** will be dealt with by next transaction that actually writes something, but should be taken
 	 ** care of in this trans
 	 */
-	if (journal->j_len == 0) {
-		BUG();
-	}
+	BUG_ON(journal->j_len == 0);
+
 	/* if wcount > 0, and we are called to with flush or commit_now,
 	 ** we wait on j_join_wait.  We will wake up when the last writer has
 	 ** finished the transaction, and started it on its way to the disk.
@@ -3592,9 +3579,8 @@ static int check_journal_end(struct reiserfs_transaction_handle *th,
 					unlock_journal(p_s_sb);
 				}
 			}
-			if (journal->j_trans_id == trans_id) {
-				BUG();
-			}
+			BUG_ON(journal->j_trans_id == trans_id);
+			
 			if (commit_now
 			    && journal_list_still_alive(p_s_sb, trans_id)
 			    && wait_on_commit) {
@@ -4074,9 +4060,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	set_commit_trans_len(commit, journal->j_len);
 
 	/* special check in case all buffers in the journal were marked for not logging */
-	if (journal->j_len == 0) {
-		BUG();
-	}
+	BUG_ON(journal->j_len == 0);
 
 	/* we're about to dirty all the log blocks, mark the description block
 	 * dirty now too.  Don't mark the commit block dirty until all the
@@ -4173,8 +4157,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 				      journal, jl, &jl->j_tail_bh_list);
 		lock_kernel();
 	}
-	if (!list_empty(&jl->j_tail_bh_list))
-		BUG();
+	BUG_ON(!list_empty(&jl->j_tail_bh_list));
 	up(&jl->j_commit_lock);
 
 	/* honor the flush wishes from the caller, simple commits can

commit a3172027148120b8f8797cbecc7d0a0b215736a1
Author: Chris Mason <mason@suse.com>
Date:   Fri Sep 29 01:59:56 2006 -0700

    [PATCH] Fix reiserfs latencies caused by data=ordered
    
    ReiserFS does periodic cleanup of old transactions in order to limit the
    length of time a journal replay may take after a crash.  Sometimes, writing
    metadata from an old (already committed) transaction may require committing
    a newer transaction, which also requires writing all data=ordered buffers.
    This can cause very long stalls on journal_begin.
    
    This patch makes sure new transactions will not need to be committed before
    trying a periodic reclaim of an old transaction.  It is low risk because if
    a bad decision is made, it just means a slightly longer journal replay
    after a crash.
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 9b3672d69367..e6b5ccf23f15 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1186,6 +1186,21 @@ static struct reiserfs_journal_list *find_newer_jl_for_cn(struct
 	return NULL;
 }
 
+static int newer_jl_done(struct reiserfs_journal_cnode *cn)
+{
+	struct super_block *sb = cn->sb;
+	b_blocknr_t blocknr = cn->blocknr;
+
+	cn = cn->hprev;
+	while (cn) {
+		if (cn->sb == sb && cn->blocknr == blocknr && cn->jlist &&
+		    atomic_read(&cn->jlist->j_commit_left) != 0)
+				    return 0;
+		cn = cn->hprev;
+	}
+	return 1;
+}
+
 static void remove_journal_hash(struct super_block *,
 				struct reiserfs_journal_cnode **,
 				struct reiserfs_journal_list *, unsigned long,
@@ -1604,6 +1619,31 @@ static int flush_journal_list(struct super_block *s,
 	return err;
 }
 
+static int test_transaction(struct super_block *s,
+                            struct reiserfs_journal_list *jl)
+{
+	struct reiserfs_journal_cnode *cn;
+
+	if (jl->j_len == 0 || atomic_read(&jl->j_nonzerolen) == 0)
+		return 1;
+
+	cn = jl->j_realblock;
+	while (cn) {
+		/* if the blocknr == 0, this has been cleared from the hash,
+		 ** skip it
+		 */
+		if (cn->blocknr == 0) {
+			goto next;
+		}
+		if (cn->bh && !newer_jl_done(cn))
+			return 0;
+	      next:
+		cn = cn->next;
+		cond_resched();
+	}
+	return 0;
+}
+
 static int write_one_transaction(struct super_block *s,
 				 struct reiserfs_journal_list *jl,
 				 struct buffer_chunk *chunk)
@@ -3433,16 +3473,6 @@ static void flush_async_commits(void *p)
 		flush_commit_list(p_s_sb, jl, 1);
 	}
 	unlock_kernel();
-	/*
-	 * this is a little racey, but there's no harm in missing
-	 * the filemap_fdata_write
-	 */
-	if (!atomic_read(&journal->j_async_throttle)
-	    && !reiserfs_is_journal_aborted(journal)) {
-		atomic_inc(&journal->j_async_throttle);
-		filemap_fdatawrite(p_s_sb->s_bdev->bd_inode->i_mapping);
-		atomic_dec(&journal->j_async_throttle);
-	}
 }
 
 /*
@@ -3844,7 +3874,9 @@ static void flush_old_journal_lists(struct super_block *s)
 		entry = journal->j_journal_list.next;
 		jl = JOURNAL_LIST_ENTRY(entry);
 		/* this check should always be run, to send old lists to disk */
-		if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4))) {
+		if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4)) &&
+		    atomic_read(&jl->j_commit_left) == 0 &&
+		    test_transaction(s, jl)) {
 			flush_used_journal_lists(s, jl);
 		} else {
 			break;

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 49d1a53dbef0..9b3672d69367 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -34,7 +34,6 @@
 **		        from within kupdate, it will ignore the immediate flag
 */
 
-#include <linux/config.h>
 #include <asm/uaccess.h>
 #include <asm/system.h>
 

commit f116629d03655adaf7832b93b03c99391d09d4a7
Author: Akinobu Mita <mita@miraclelinux.com>
Date:   Mon Jun 26 00:24:46 2006 -0700

    [PATCH] fs: use list_move()
    
    This patch converts the combination of list_del(A) and list_add(A, B) to
    list_move(A, B) under fs/.
    
    Cc: Ian Kent <raven@themaw.net>
    Acked-by: Joel Becker <joel.becker@oracle.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Cc: Hans Reiser <reiserfs-dev@namesys.com>
    Cc: Urban Widmark <urban@teststation.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Acked-by: Mark Fasheh <mark.fasheh@oracle.com>
    Signed-off-by: Akinobu Mita <mita@miraclelinux.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 1b73529b8099..49d1a53dbef0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -834,8 +834,7 @@ static int write_ordered_buffers(spinlock_t * lock,
 		get_bh(bh);
 		if (test_set_buffer_locked(bh)) {
 			if (!buffer_dirty(bh)) {
-				list_del_init(&jh->list);
-				list_add(&jh->list, &tmp);
+				list_move(&jh->list, &tmp);
 				goto loop_next;
 			}
 			spin_unlock(lock);
@@ -855,8 +854,7 @@ static int write_ordered_buffers(spinlock_t * lock,
 			ret = -EIO;
 		}
 		if (buffer_dirty(bh)) {
-			list_del_init(&jh->list);
-			list_add(&jh->list, &tmp);
+			list_move(&jh->list, &tmp);
 			add_to_chunk(&chunk, bh, lock, write_ordered_chunk);
 		} else {
 			reiserfs_free_jh(bh);

commit a44c94a7b82a425b73384c104d5cb3dd3caa075e
Author: Alexander Zarochentsev <zam@namesys.com>
Date:   Sat Mar 25 03:06:59 2006 -0800

    [PATCH] reiserfs: handle trans_id overflow
    
    Reiserfs does not handle transaction ID overflow correctly.  Transaction ID
    == 0 causes reiserfs to crash.  The patch fixes all places where the
    transaction ID is incremented.
    
    Signed-off-by: Alexander Zarochentsev <zam@namesys.com>
    Signed-off-by: Hans Reiser <reiser@namesys.com>
    Cc: Chris Mason <mason@suse.com>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 5a9d2722fa0a..1b73529b8099 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2227,6 +2227,9 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
 	journal->j_last_flush_trans_id = trans_id;
 	journal->j_trans_id = trans_id + 1;
+	/* check for trans_id overflow */
+	if (journal->j_trans_id == 0)
+		journal->j_trans_id = 10;
 	brelse(c_bh);
 	brelse(d_bh);
 	kfree(log_blocks);
@@ -2450,6 +2453,9 @@ static int journal_read(struct super_block *p_s_sb)
 		journal->j_start = le32_to_cpu(jh->j_first_unflushed_offset);
 		journal->j_trans_id =
 		    le32_to_cpu(jh->j_last_flush_trans_id) + 1;
+		/* check for trans_id overflow */
+		if (journal->j_trans_id == 0)
+			journal->j_trans_id = 10;
 		journal->j_last_flush_trans_id =
 		    le32_to_cpu(jh->j_last_flush_trans_id);
 		journal->j_mount_id = le32_to_cpu(jh->j_mount_id) + 1;
@@ -3873,8 +3879,8 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	int cur_write_start = 0;	/* start index of current log write */
 	int old_start;
 	int i;
-	int flush = flags & FLUSH_ALL;
-	int wait_on_commit = flags & WAIT;
+	int flush;
+	int wait_on_commit;
 	struct reiserfs_journal_list *jl, *temp_jl;
 	struct list_head *entry, *safe;
 	unsigned long jindex;
@@ -3884,6 +3890,13 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	BUG_ON(th->t_refcount > 1);
 	BUG_ON(!th->t_trans_id);
 
+	/* protect flush_older_commits from doing mistakes if the
+           transaction ID counter gets overflowed.  */
+	if (th->t_trans_id == ~0UL)
+		flags |= FLUSH_ALL | COMMIT_NOW | WAIT;
+	flush = flags & FLUSH_ALL;
+	wait_on_commit = flags & WAIT;
+
 	put_fs_excl();
 	current->journal_info = th->t_handle_save;
 	reiserfs_check_lock_depth(p_s_sb, "journal end");
@@ -4105,7 +4118,9 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 	journal->j_first = NULL;
 	journal->j_len = 0;
 	journal->j_trans_start_time = 0;
-	journal->j_trans_id++;
+	/* check for trans_id overflow */
+	if (++journal->j_trans_id == 0)
+		journal->j_trans_id = 10;
 	journal->j_current_jl->j_trans_id = journal->j_trans_id;
 	journal->j_must_wait = 0;
 	journal->j_len_alloc = 0;

commit c499ec24c31edf270e777a868ffd0daddcfe7ebd
Author: Vladimir V. Saveliev <vs@namesys.com>
Date:   Thu Mar 2 02:54:39 2006 -0800

    [PATCH] reiserfs: do not check if unsigned < 0
    
    This patch fixes bugs in reiserfs where unsigned integers were checked
    whether they are less then 0.
    
    Signed-off-by: Vladimir V. Saveliev <vs@namesys.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Signed-off-by: Hans Reiser <reiser@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b7a179560ab4..5a9d2722fa0a 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2319,8 +2319,7 @@ static int journal_read(struct super_block *p_s_sb)
 		return 1;
 	}
 	jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data);
-	if (le32_to_cpu(jh->j_first_unflushed_offset) >= 0 &&
-	    le32_to_cpu(jh->j_first_unflushed_offset) <
+	if (le32_to_cpu(jh->j_first_unflushed_offset) <
 	    SB_ONDISK_JOURNAL_SIZE(p_s_sb)
 	    && le32_to_cpu(jh->j_last_flush_trans_id) > 0) {
 		oldest_start =

commit 6ae1ea447d21c4fecf5df8d0e1022461274fb4e8
Author: Chris Mason <mason@suse.com>
Date:   Wed Feb 1 03:06:50 2006 -0800

    [PATCH] reiserfs: reiserfs fix journal accounting in journal_transaction_should_end
    
    reiserfs: journal_transaction_should_end should increase the count of
    blocks allocated so the transaction subsystem can keep new writers from
    creating a transaction that is too large.
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 47c9f432dea5..b7a179560ab4 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2823,6 +2823,9 @@ int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
 	    journal->j_cnode_free < (journal->j_trans_max * 3)) {
 		return 1;
 	}
+	/* protected by the BKL here */
+	journal->j_len_alloc += new_alloc;
+	th->t_blocks_allocated += new_alloc ;
 	return 0;
 }
 

commit 3d4492f81dd7b486f1be0616a1ce7f73760f406e
Author: Chris Mason <mason@suse.com>
Date:   Wed Feb 1 03:06:49 2006 -0800

    [PATCH] reiserfs: reiserfs write_ordered_buffers should not oops on dirty non-uptodate bh
    
    write_ordered_buffers should handle dirty non-uptodate buffers without a
    BUG()
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 1b2402a9a8e1..47c9f432dea5 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -846,6 +846,14 @@ static int write_ordered_buffers(spinlock_t * lock,
 			spin_lock(lock);
 			goto loop_next;
 		}
+		/* in theory, dirty non-uptodate buffers should never get here,
+		 * but the upper layer io error paths still have a few quirks.
+		 * Handle them here as gracefully as we can
+		 */
+		if (!buffer_uptodate(bh) && buffer_dirty(bh)) {
+			clear_buffer_dirty(bh);
+			ret = -EIO;
+		}
 		if (buffer_dirty(bh)) {
 			list_del_init(&jh->list);
 			list_add(&jh->list, &tmp);
@@ -1030,9 +1038,12 @@ static int flush_commit_list(struct super_block *s,
 	}
 
 	if (!list_empty(&jl->j_bh_list)) {
+		int ret;
 		unlock_kernel();
-		write_ordered_buffers(&journal->j_dirty_buffers_lock,
-				      journal, jl, &jl->j_bh_list);
+		ret = write_ordered_buffers(&journal->j_dirty_buffers_lock,
+					    journal, jl, &jl->j_bh_list);
+		if (ret < 0 && retval == 0)
+			retval = ret;
 		lock_kernel();
 	}
 	BUG_ON(!list_empty(&jl->j_bh_list));

commit e0e851cf30f1a9bd2e2a7624e9810378d6a2b072
Author: Chris Mason <mason@suse.com>
Date:   Wed Feb 1 03:06:49 2006 -0800

    [PATCH] reiserfs: reiserfs hang and performance fix for data=journal mode
    
    In data=journal mode, reiserfs writepage needs to make sure not to trigger
    transactions while being run under PF_MEMALLOC.  This patch makes sure to
    redirty the page instead of forcing a transaction start in this case.
    
    Also, calling filemap_fdata* in order to trigger io on the block device can
    cause lock inversions on the page lock.  Instead, do simple batching from
    flush_commit_list.
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index bc8fe963b3cc..1b2402a9a8e1 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -988,6 +988,7 @@ static int flush_commit_list(struct super_block *s,
 	struct reiserfs_journal *journal = SB_JOURNAL(s);
 	int barrier = 0;
 	int retval = 0;
+	int write_len;
 
 	reiserfs_check_lock_depth(s, "flush_commit_list");
 
@@ -1037,16 +1038,24 @@ static int flush_commit_list(struct super_block *s,
 	BUG_ON(!list_empty(&jl->j_bh_list));
 	/*
 	 * for the description block and all the log blocks, submit any buffers
-	 * that haven't already reached the disk
+	 * that haven't already reached the disk.  Try to write at least 256
+	 * log blocks. later on, we will only wait on blocks that correspond
+	 * to this transaction, but while we're unplugging we might as well
+	 * get a chunk of data on there.
 	 */
 	atomic_inc(&journal->j_async_throttle);
-	for (i = 0; i < (jl->j_len + 1); i++) {
+	write_len = jl->j_len + 1;
+	if (write_len < 256)
+		write_len = 256;
+	for (i = 0 ; i < write_len ; i++) {
 		bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) + (jl->j_start + i) %
 		    SB_ONDISK_JOURNAL_SIZE(s);
 		tbh = journal_find_get_block(s, bn);
-		if (buffer_dirty(tbh))	/* redundant, ll_rw_block() checks */
-			ll_rw_block(SWRITE, 1, &tbh);
-		put_bh(tbh);
+		if (tbh) {
+			if (buffer_dirty(tbh))
+			    ll_rw_block(WRITE, 1, &tbh) ;
+			put_bh(tbh) ;
+		}
 	}
 	atomic_dec(&journal->j_async_throttle);
 

commit d62b1b87a7d1c3a21dddabed4251763090be3182
Author: Chris Mason <mason@suse.com>
Date:   Wed Feb 1 03:06:47 2006 -0800

    [PATCH] resierfs: fix reiserfs_invalidatepage race against data=ordered
    
    After a transaction has closed but before it has finished commit, there is
    a window where data=ordered mode requires invalidatepage to pin pages
    instead of freeing them.  This patch fixes a race between the
    invalidatepage checks and data=ordered writeback, and it also adds a check
    to the reiserfs write_ordered_buffers routines to write any anonymous
    buffers that were dirtied after its first writeback loop.
    
    That bug works like this:
    
    proc1: transaction closes and a new one starts
    proc1: write_ordered_buffers starts processing data=ordered list
    proc1: buffer A is cleaned and written
    proc2: buffer A is dirtied by another process
    proc2: File is truncated to zero, page A goes through invalidatepage
    proc2: reiserfs_invalidatepage sees dirty buffer A with reiserfs
           journal head, pins it
    proc1: write_ordered_buffers frees the journal head on buffer A
    
    At this point, buffer A stays dirty forever
    
    Signed-off-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 2d04efb22eea..bc8fe963b3cc 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -877,6 +877,19 @@ static int write_ordered_buffers(spinlock_t * lock,
 		if (!buffer_uptodate(bh)) {
 			ret = -EIO;
 		}
+		/* ugly interaction with invalidatepage here.
+		 * reiserfs_invalidate_page will pin any buffer that has a valid
+		 * journal head from an older transaction.  If someone else sets
+		 * our buffer dirty after we write it in the first loop, and
+		 * then someone truncates the page away, nobody will ever write
+		 * the buffer. We're safe if we write the page one last time
+		 * after freeing the journal header.
+		 */
+		if (buffer_dirty(bh) && unlikely(bh->b_page->mapping == NULL)) {
+			spin_unlock(lock);
+			ll_rw_block(WRITE, 1, &bh);
+			spin_lock(lock);
+		}
 		put_bh(bh);
 		cond_resched_lock(lock);
 	}

commit 8c777cc4be1390862d053cbc002246e87572147b
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Wed Feb 1 03:06:43 2006 -0800

    [PATCH] reiserfs: use __GFP_NOFAIL instead of yield and retry loop for allocation
    
    This patch replaces yield and retry loop with __GFP_NOFAIL in
    alloc_journal_list().
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 16b526fd20b9..2d04efb22eea 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2446,12 +2446,8 @@ static int journal_read(struct super_block *p_s_sb)
 static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
 {
 	struct reiserfs_journal_list *jl;
-      retry:
-	jl = kzalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS);
-	if (!jl) {
-		yield();
-		goto retry;
-	}
+	jl = kzalloc(sizeof(struct reiserfs_journal_list),
+		     GFP_NOFS | __GFP_NOFAIL);
 	INIT_LIST_HEAD(&jl->j_list);
 	INIT_LIST_HEAD(&jl->j_working_list);
 	INIT_LIST_HEAD(&jl->j_tail_bh_list);

commit d739b42b82773206297db1fc0d96ef895a5d9688
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Wed Feb 1 03:06:43 2006 -0800

    [PATCH] reiserfs: remove kmalloc wrapper
    
    Remove kmalloc() wrapper from fs/reiserfs/.  Please note that a reiserfs
    /proc entry format is changed because kmalloc statistics is removed.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4491fcf2a0e6..16b526fd20b9 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -152,18 +152,16 @@ static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
 	struct reiserfs_bitmap_node *bn;
 	static int id;
 
-	bn = reiserfs_kmalloc(sizeof(struct reiserfs_bitmap_node), GFP_NOFS,
-			      p_s_sb);
+	bn = kmalloc(sizeof(struct reiserfs_bitmap_node), GFP_NOFS);
 	if (!bn) {
 		return NULL;
 	}
-	bn->data = reiserfs_kmalloc(p_s_sb->s_blocksize, GFP_NOFS, p_s_sb);
+	bn->data = kzalloc(p_s_sb->s_blocksize, GFP_NOFS);
 	if (!bn->data) {
-		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+		kfree(bn);
 		return NULL;
 	}
 	bn->id = id++;
-	memset(bn->data, 0, p_s_sb->s_blocksize);
 	INIT_LIST_HEAD(&bn->list);
 	return bn;
 }
@@ -197,8 +195,8 @@ static inline void free_bitmap_node(struct super_block *p_s_sb,
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 	journal->j_used_bitmap_nodes--;
 	if (journal->j_free_bitmap_nodes > REISERFS_MAX_BITMAP_NODES) {
-		reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb);
-		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+		kfree(bn->data);
+		kfree(bn);
 	} else {
 		list_add(&bn->list, &journal->j_bitmap_nodes);
 		journal->j_free_bitmap_nodes++;
@@ -276,8 +274,8 @@ static int free_bitmap_nodes(struct super_block *p_s_sb)
 	while (next != &journal->j_bitmap_nodes) {
 		bn = list_entry(next, struct reiserfs_bitmap_node, list);
 		list_del(next);
-		reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb);
-		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+		kfree(bn->data);
+		kfree(bn);
 		next = journal->j_bitmap_nodes.next;
 		journal->j_free_bitmap_nodes--;
 	}
@@ -581,7 +579,7 @@ static inline void put_journal_list(struct super_block *s,
 			       jl->j_trans_id, jl->j_refcount);
 	}
 	if (--jl->j_refcount == 0)
-		reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
+		kfree(jl);
 }
 
 /*
@@ -1818,8 +1816,7 @@ void remove_journal_hash(struct super_block *sb,
 static void free_journal_ram(struct super_block *p_s_sb)
 {
 	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-	reiserfs_kfree(journal->j_current_jl,
-		       sizeof(struct reiserfs_journal_list), p_s_sb);
+	kfree(journal->j_current_jl);
 	journal->j_num_lists--;
 
 	vfree(journal->j_cnode_free_orig);
@@ -2093,21 +2090,15 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	}
 	trans_id = get_desc_trans_id(desc);
 	/* now we know we've got a good transaction, and it was inside the valid time ranges */
-	log_blocks =
-	    reiserfs_kmalloc(get_desc_trans_len(desc) *
-			     sizeof(struct buffer_head *), GFP_NOFS, p_s_sb);
-	real_blocks =
-	    reiserfs_kmalloc(get_desc_trans_len(desc) *
-			     sizeof(struct buffer_head *), GFP_NOFS, p_s_sb);
+	log_blocks = kmalloc(get_desc_trans_len(desc) *
+			     sizeof(struct buffer_head *), GFP_NOFS);
+	real_blocks = kmalloc(get_desc_trans_len(desc) *
+			      sizeof(struct buffer_head *), GFP_NOFS);
 	if (!log_blocks || !real_blocks) {
 		brelse(c_bh);
 		brelse(d_bh);
-		reiserfs_kfree(log_blocks,
-			       get_desc_trans_len(desc) *
-			       sizeof(struct buffer_head *), p_s_sb);
-		reiserfs_kfree(real_blocks,
-			       get_desc_trans_len(desc) *
-			       sizeof(struct buffer_head *), p_s_sb);
+		kfree(log_blocks);
+		kfree(real_blocks);
 		reiserfs_warning(p_s_sb,
 				 "journal-1169: kmalloc failed, unable to mount FS");
 		return -1;
@@ -2145,12 +2136,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 			brelse_array(real_blocks, i);
 			brelse(c_bh);
 			brelse(d_bh);
-			reiserfs_kfree(log_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
-			reiserfs_kfree(real_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
+			kfree(log_blocks);
+			kfree(real_blocks);
 			return -1;
 		}
 	}
@@ -2166,12 +2153,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 			brelse_array(real_blocks, get_desc_trans_len(desc));
 			brelse(c_bh);
 			brelse(d_bh);
-			reiserfs_kfree(log_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
-			reiserfs_kfree(real_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
+			kfree(log_blocks);
+			kfree(real_blocks);
 			return -1;
 		}
 		memcpy(real_blocks[i]->b_data, log_blocks[i]->b_data,
@@ -2193,12 +2176,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 				     get_desc_trans_len(desc) - i);
 			brelse(c_bh);
 			brelse(d_bh);
-			reiserfs_kfree(log_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
-			reiserfs_kfree(real_blocks,
-				       get_desc_trans_len(desc) *
-				       sizeof(struct buffer_head *), p_s_sb);
+			kfree(log_blocks);
+			kfree(real_blocks);
 			return -1;
 		}
 		brelse(real_blocks[i]);
@@ -2217,12 +2196,8 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	journal->j_trans_id = trans_id + 1;
 	brelse(c_bh);
 	brelse(d_bh);
-	reiserfs_kfree(log_blocks,
-		       le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *),
-		       p_s_sb);
-	reiserfs_kfree(real_blocks,
-		       le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *),
-		       p_s_sb);
+	kfree(log_blocks);
+	kfree(real_blocks);
 	return 0;
 }
 
@@ -2472,13 +2447,11 @@ static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
 {
 	struct reiserfs_journal_list *jl;
       retry:
-	jl = reiserfs_kmalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS,
-			      s);
+	jl = kzalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS);
 	if (!jl) {
 		yield();
 		goto retry;
 	}
-	memset(jl, 0, sizeof(*jl));
 	INIT_LIST_HEAD(&jl->j_list);
 	INIT_LIST_HEAD(&jl->j_working_list);
 	INIT_LIST_HEAD(&jl->j_tail_bh_list);
@@ -3042,14 +3015,12 @@ struct reiserfs_transaction_handle *reiserfs_persistent_transaction(struct
 		}
 		return th;
 	}
-	th = reiserfs_kmalloc(sizeof(struct reiserfs_transaction_handle),
-			      GFP_NOFS, s);
+	th = kmalloc(sizeof(struct reiserfs_transaction_handle), GFP_NOFS);
 	if (!th)
 		return NULL;
 	ret = journal_begin(th, s, nblocks);
 	if (ret) {
-		reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle),
-			       s);
+		kfree(th);
 		return NULL;
 	}
 
@@ -3067,8 +3038,7 @@ int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
 		ret = -EIO;
 	if (th->t_refcount == 0) {
 		SB_JOURNAL(s)->j_persistent_trans--;
-		reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle),
-			       s);
+		kfree(th);
 	}
 	return ret;
 }

commit ef43bc4fc32bec8fda7bae8948b774616dc9e496
Author: Jan Kara <jack@suse.cz>
Date:   Wed Jan 11 12:17:40 2006 -0800

    [PATCH] reiserfs: fix assertion failure in reiserfs+journaled quotas
    
    Sometimes we call do_journal_end() with t_refcount == 0.  If quota is
    turned on and we happen to have some inode with preallocation bad things
    happen as we try to use the current handle for quota operations.  Checks
    for t_refcount in journal_begin() fail and we Oops.  We raise t_refcount to
    make those checks happy.  We should not cause any bad as all the needed
    quota blocks should be already attached to the transaction (they were
    attached to the transaction when we allocated those preallocation blocks).
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Jeff Mahoney <jeffm@suse.com>
    Cc: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 3f17ef844fb6..4491fcf2a0e6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -3925,10 +3925,13 @@ static int do_journal_end(struct reiserfs_transaction_handle *th,
 		flush = 1;
 	}
 #ifdef REISERFS_PREALLOCATE
-	/* quota ops might need to nest, setup the journal_info pointer for them */
+	/* quota ops might need to nest, setup the journal_info pointer for them
+	 * and raise the refcount so that it is > 0. */
 	current->journal_info = th;
+	th->t_refcount++;
 	reiserfs_discard_all_prealloc(th);	/* it should not involve new blocks into
 						 * the transaction */
+	th->t_refcount--;
 	current->journal_info = th->t_handle_save;
 #endif
 

commit 5d5e815618c4a8b53806845268c951201d14af6e
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Wed Dec 14 14:38:36 2005 -0500

    [PATCH] reiserfs: skip commit on io error
    
    This should have been part of the original io error patch, but got
    dropped somewhere along the way.
    
    It's extremely important when handling the i/o error in the journal to
    not commit the transaction with corrupt data.  This patch adds that code
    back in.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 68b7b78638ff..3f17ef844fb6 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1039,6 +1039,10 @@ static int flush_commit_list(struct super_block *s,
 	}
 	atomic_dec(&journal->j_async_throttle);
 
+	/* We're skipping the commit if there's an error */
+	if (retval || reiserfs_is_journal_aborted(journal))
+		barrier = 0;
+
 	/* wait on everything written so far before writing the commit
 	 * if we are in barrier mode, send the commit down now
 	 */
@@ -1077,10 +1081,16 @@ static int flush_commit_list(struct super_block *s,
 	BUG_ON(atomic_read(&(jl->j_commit_left)) != 1);
 
 	if (!barrier) {
-		if (buffer_dirty(jl->j_commit_bh))
-			BUG();
-		mark_buffer_dirty(jl->j_commit_bh);
-		sync_dirty_buffer(jl->j_commit_bh);
+		/* If there was a write error in the journal - we can't commit
+		 * this transaction - it will be invalid and, if successful,
+		 * will just end up propogating the write error out to
+		 * the file system. */
+		if (likely(!retval && !reiserfs_is_journal_aborted (journal))) {
+			if (buffer_dirty(jl->j_commit_bh))
+				BUG();
+			mark_buffer_dirty(jl->j_commit_bh) ;
+			sync_dirty_buffer(jl->j_commit_bh) ;
+		}
 	} else
 		wait_on_buffer(jl->j_commit_bh);
 

commit 576f6d79564d0d2c1f43088e6805674d2e122935
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Tue Nov 29 19:34:39 2005 -0800

    [PATCH] reiserfs: handle cnode allocation failure gracefully
    
    If an external device is used for a journal, by default it will use the
    entire device.  The reiserfs journal code allocates structures per journal
    block when it mounts the file system.  If the journal device is too large,
    and memory cannot be allocated for the structures, it will continue and
    ultimately panic when it can't pull one off the free list.
    
    This patch handles the allocation failure gracefully and prints an error
    message at mount time.
    
    Changes: Updated error message to be more descriptive to the user.
    
    Discussed and approved on ReiserFS Mailing List, Nov 28.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 4b15761434bc..68b7b78638ff 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2757,6 +2757,15 @@ int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
 	journal->j_cnode_used = 0;
 	journal->j_must_wait = 0;
 
+	if (journal->j_cnode_free == 0) {
+        	reiserfs_warning(p_s_sb, "journal-2004: Journal cnode memory "
+		                 "allocation failed (%ld bytes). Journal is "
+		                 "too large for available memory. Usually "
+		                 "this is due to a journal that is too large.",
+		                 sizeof (struct reiserfs_journal_cnode) * num_cnodes);
+        	goto free_and_return;
+	}
+
 	init_journal_hash(p_s_sb);
 	jl = journal->j_current_jl;
 	jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);

commit 041e0e3b1970c508dc9a95b7dd9dc86271a7d7ac
Author: Nishanth Aravamudan <nacc@us.ibm.com>
Date:   Sat Sep 10 00:27:23 2005 -0700

    [PATCH] fs: fix-up schedule_timeout() usage
    
    Use schedule_timeout_{,un}interruptible() instead of
    set_current_state()/schedule_timeout() to reduce kernel size.  Also use helper
    functions to convert between human time units and jiffies rather than constant
    HZ division to avoid rounding errors.
    
    Signed-off-by: Nishanth Aravamudan <nacc@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index a8e29e9bbbd0..4b15761434bc 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2868,8 +2868,7 @@ static void let_transaction_grow(struct super_block *sb, unsigned long trans_id)
 	struct reiserfs_journal *journal = SB_JOURNAL(sb);
 	unsigned long bcount = journal->j_bcount;
 	while (1) {
-		set_current_state(TASK_UNINTERRUPTIBLE);
-		schedule_timeout(1);
+		schedule_timeout_uninterruptible(1);
 		journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
 		while ((atomic_read(&journal->j_wcount) > 0 ||
 			atomic_read(&journal->j_jlock)) &&

commit 53778ffde601c962ad9250c4998df7de6f428246
Author: Jan Kara <jack@suse.cz>
Date:   Tue Sep 6 15:19:14 2005 -0700

    [PATCH] Change ll_rw_block() calls in Reiser
    
    We need to be sure that current data in buffer are sent to disk.  Hence we
    need to call ll_rw_block() with SWRITE.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index ca7989b04be3..a8e29e9bbbd0 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -1034,7 +1034,7 @@ static int flush_commit_list(struct super_block *s,
 		    SB_ONDISK_JOURNAL_SIZE(s);
 		tbh = journal_find_get_block(s, bn);
 		if (buffer_dirty(tbh))	/* redundant, ll_rw_block() checks */
-			ll_rw_block(WRITE, 1, &tbh);
+			ll_rw_block(SWRITE, 1, &tbh);
 		put_bh(tbh);
 	}
 	atomic_dec(&journal->j_async_throttle);
@@ -2172,7 +2172,7 @@ static int journal_read_transaction(struct super_block *p_s_sb,
 	/* flush out the real blocks */
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		set_buffer_dirty(real_blocks[i]);
-		ll_rw_block(WRITE, 1, real_blocks + i);
+		ll_rw_block(SWRITE, 1, real_blocks + i);
 	}
 	for (i = 0; i < get_desc_trans_len(desc); i++) {
 		wait_on_buffer(real_blocks[i]);

commit 77933d7276ee8fa0e2947641941a6f7a100a327b
Author: Jesper Juhl <juhl@dif.dk>
Date:   Wed Jul 27 11:46:09 2005 -0700

    [PATCH] clean up inline static vs static inline
    
    `gcc -W' likes to complain if the static keyword is not at the beginning of
    the declaration.  This patch fixes all remaining occurrences of "inline
    static" up with "static inline" in the entire kernel tree (140 occurrences in
    47 files).
    
    While making this change I came across a few lines with trailing whitespace
    that I also fixed up, I have also added or removed a blank line or two here
    and there, but there are no functional changes in the patch.
    
    Signed-off-by: Jesper Juhl <juhl-lkml@dif.dk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c66c27ec4100..ca7989b04be3 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -556,14 +556,14 @@ static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
 }
 
 /* lock the current transaction */
-inline static void lock_journal(struct super_block *p_s_sb)
+static inline void lock_journal(struct super_block *p_s_sb)
 {
 	PROC_INFO_INC(p_s_sb, journal.lock_journal);
 	down(&SB_JOURNAL(p_s_sb)->j_lock);
 }
 
 /* unlock the current transaction */
-inline static void unlock_journal(struct super_block *p_s_sb)
+static inline void unlock_journal(struct super_block *p_s_sb)
 {
 	up(&SB_JOURNAL(p_s_sb)->j_lock);
 }

commit bd4c625c061c2a38568d0add3478f59172455159
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Tue Jul 12 20:21:28 2005 -0700

    reiserfs: run scripts/Lindent on reiserfs code
    
    This was a pure indentation change, using:
    
            scripts/Lindent fs/reiserfs/*.c include/linux/reiserfs_*.h
    
    to make reiserfs match the regular Linux indentation style.  As Jeff
    Mahoney <jeffm@suse.com> writes:
    
     The ReiserFS code is a mix of a number of different coding styles, sometimes
     different even from line-to-line. Since the code has been relatively stable
     for quite some time and there are few outstanding patches to be applied, it
     is time to reformat the code to conform to the Linux style standard outlined
     in Documentation/CodingStyle.
    
     This patch contains the result of running scripts/Lindent against
     fs/reiserfs/*.c and include/linux/reiserfs_*.h. There are places where the
     code can be made to look better, but I'd rather keep those patches separate
     so that there isn't a subtle by-hand hand accident in the middle of a huge
     patch. To be clear: This patch is reformatting *only*.
    
     A number of patches may follow that continue to make the code more consistent
     with the Linux coding style.
    
     Hans wasn't particularly enthusiastic about these patches, but said he
     wouldn't really oppose them either.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index d1bcf0da6728..c66c27ec4100 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -55,7 +55,6 @@
 #include <linux/writeback.h>
 #include <linux/blkdev.h>
 
-
 /* gets a struct reiserfs_journal_list * from a list head */
 #define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
                                j_list))
@@ -69,55 +68,61 @@ static int reiserfs_mounted_fs_count;
 
 static struct workqueue_struct *commit_wq;
 
-#define JOURNAL_TRANS_HALF 1018   /* must be correct to keep the desc and commit
-				     structs at 4k */
-#define BUFNR 64 /*read ahead */
+#define JOURNAL_TRANS_HALF 1018	/* must be correct to keep the desc and commit
+				   structs at 4k */
+#define BUFNR 64		/*read ahead */
 
 /* cnode stat bits.  Move these into reiserfs_fs.h */
 
 #define BLOCK_FREED 2		/* this block was freed, and can't be written.  */
-#define BLOCK_FREED_HOLDER 3    /* this block was freed during this transaction, and can't be written */
+#define BLOCK_FREED_HOLDER 3	/* this block was freed during this transaction, and can't be written */
 
 #define BLOCK_NEEDS_FLUSH 4	/* used in flush_journal_list */
 #define BLOCK_DIRTIED 5
 
-
 /* journal list state bits */
 #define LIST_TOUCHED 1
 #define LIST_DIRTY   2
-#define LIST_COMMIT_PENDING  4		/* someone will commit this list */
+#define LIST_COMMIT_PENDING  4	/* someone will commit this list */
 
 /* flags for do_journal_end */
 #define FLUSH_ALL   1		/* flush commit and real blocks */
 #define COMMIT_NOW  2		/* end and commit this transaction */
-#define WAIT        4		/* wait for the log blocks to hit the disk*/
-
-static int do_journal_end(struct reiserfs_transaction_handle *,struct super_block *,unsigned long nblocks,int flags) ;
-static int flush_journal_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall) ;
-static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall)  ;
-static int can_dirty(struct reiserfs_journal_cnode *cn) ;
-static int journal_join(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks);
-static int release_journal_dev( struct super_block *super,
-				struct reiserfs_journal *journal );
+#define WAIT        4		/* wait for the log blocks to hit the disk */
+
+static int do_journal_end(struct reiserfs_transaction_handle *,
+			  struct super_block *, unsigned long nblocks,
+			  int flags);
+static int flush_journal_list(struct super_block *s,
+			      struct reiserfs_journal_list *jl, int flushall);
+static int flush_commit_list(struct super_block *s,
+			     struct reiserfs_journal_list *jl, int flushall);
+static int can_dirty(struct reiserfs_journal_cnode *cn);
+static int journal_join(struct reiserfs_transaction_handle *th,
+			struct super_block *p_s_sb, unsigned long nblocks);
+static int release_journal_dev(struct super_block *super,
+			       struct reiserfs_journal *journal);
 static int dirty_one_transaction(struct super_block *s,
-                                 struct reiserfs_journal_list *jl);
+				 struct reiserfs_journal_list *jl);
 static void flush_async_commits(void *p);
 static void queue_log_writer(struct super_block *s);
 
 /* values for join in do_journal_begin_r */
 enum {
-    JBEGIN_REG = 0, /* regular journal begin */
-    JBEGIN_JOIN = 1, /* join the running transaction if at all possible */
-    JBEGIN_ABORT = 2, /* called from cleanup code, ignores aborted flag */
+	JBEGIN_REG = 0,		/* regular journal begin */
+	JBEGIN_JOIN = 1,	/* join the running transaction if at all possible */
+	JBEGIN_ABORT = 2,	/* called from cleanup code, ignores aborted flag */
 };
 
 static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
-                             struct super_block * p_s_sb,
-			     unsigned long nblocks,int join);
+			      struct super_block *p_s_sb,
+			      unsigned long nblocks, int join);
 
-static void init_journal_hash(struct super_block *p_s_sb) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  memset(journal->j_hash_table, 0, JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *)) ;
+static void init_journal_hash(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	memset(journal->j_hash_table, 0,
+	       JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *));
 }
 
 /*
@@ -125,149 +130,159 @@ static void init_journal_hash(struct super_block *p_s_sb) {
 ** make schedule happen after I've freed a block.  Look at remove_from_transaction and journal_mark_freed for
 ** more details.
 */
-static int reiserfs_clean_and_file_buffer(struct buffer_head *bh) {
-  if (bh) {
-    clear_buffer_dirty(bh);
-    clear_buffer_journal_test(bh);
-  }
-  return 0 ;
+static int reiserfs_clean_and_file_buffer(struct buffer_head *bh)
+{
+	if (bh) {
+		clear_buffer_dirty(bh);
+		clear_buffer_journal_test(bh);
+	}
+	return 0;
 }
 
 static void disable_barrier(struct super_block *s)
 {
-    REISERFS_SB(s)->s_mount_opt &= ~(1 << REISERFS_BARRIER_FLUSH);
-    printk("reiserfs: disabling flush barriers on %s\n", reiserfs_bdevname(s));
-}
-
-static struct reiserfs_bitmap_node *
-allocate_bitmap_node(struct super_block *p_s_sb) {
-  struct reiserfs_bitmap_node *bn ;
-  static int id;
-
-  bn = reiserfs_kmalloc(sizeof(struct reiserfs_bitmap_node), GFP_NOFS, p_s_sb) ;
-  if (!bn) {
-    return NULL ;
-  }
-  bn->data = reiserfs_kmalloc(p_s_sb->s_blocksize, GFP_NOFS, p_s_sb) ;
-  if (!bn->data) {
-    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
-    return NULL ;
-  }
-  bn->id = id++ ;
-  memset(bn->data, 0, p_s_sb->s_blocksize) ;
-  INIT_LIST_HEAD(&bn->list) ;
-  return bn ;
-}
-
-static struct reiserfs_bitmap_node *
-get_bitmap_node(struct super_block *p_s_sb) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_bitmap_node *bn = NULL;
-  struct list_head *entry = journal->j_bitmap_nodes.next ;
-
-  journal->j_used_bitmap_nodes++ ;
-repeat:
-
-  if(entry != &journal->j_bitmap_nodes) {
-    bn = list_entry(entry, struct reiserfs_bitmap_node, list) ;
-    list_del(entry) ;
-    memset(bn->data, 0, p_s_sb->s_blocksize) ;
-    journal->j_free_bitmap_nodes-- ;
-    return bn ;
-  }
-  bn = allocate_bitmap_node(p_s_sb) ;
-  if (!bn) {
-    yield();
-    goto repeat ;
-  }
-  return bn ;
+	REISERFS_SB(s)->s_mount_opt &= ~(1 << REISERFS_BARRIER_FLUSH);
+	printk("reiserfs: disabling flush barriers on %s\n",
+	       reiserfs_bdevname(s));
+}
+
+static struct reiserfs_bitmap_node *allocate_bitmap_node(struct super_block
+							 *p_s_sb)
+{
+	struct reiserfs_bitmap_node *bn;
+	static int id;
+
+	bn = reiserfs_kmalloc(sizeof(struct reiserfs_bitmap_node), GFP_NOFS,
+			      p_s_sb);
+	if (!bn) {
+		return NULL;
+	}
+	bn->data = reiserfs_kmalloc(p_s_sb->s_blocksize, GFP_NOFS, p_s_sb);
+	if (!bn->data) {
+		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+		return NULL;
+	}
+	bn->id = id++;
+	memset(bn->data, 0, p_s_sb->s_blocksize);
+	INIT_LIST_HEAD(&bn->list);
+	return bn;
+}
+
+static struct reiserfs_bitmap_node *get_bitmap_node(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_bitmap_node *bn = NULL;
+	struct list_head *entry = journal->j_bitmap_nodes.next;
+
+	journal->j_used_bitmap_nodes++;
+      repeat:
+
+	if (entry != &journal->j_bitmap_nodes) {
+		bn = list_entry(entry, struct reiserfs_bitmap_node, list);
+		list_del(entry);
+		memset(bn->data, 0, p_s_sb->s_blocksize);
+		journal->j_free_bitmap_nodes--;
+		return bn;
+	}
+	bn = allocate_bitmap_node(p_s_sb);
+	if (!bn) {
+		yield();
+		goto repeat;
+	}
+	return bn;
 }
 static inline void free_bitmap_node(struct super_block *p_s_sb,
-                                    struct reiserfs_bitmap_node *bn) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  journal->j_used_bitmap_nodes-- ;
-  if (journal->j_free_bitmap_nodes > REISERFS_MAX_BITMAP_NODES) {
-    reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb) ;
-    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
-  } else {
-    list_add(&bn->list, &journal->j_bitmap_nodes) ;
-    journal->j_free_bitmap_nodes++ ;
-  }
-}
-
-static void allocate_bitmap_nodes(struct super_block *p_s_sb) {
-  int i ;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_bitmap_node *bn = NULL ;
-  for (i = 0 ; i < REISERFS_MIN_BITMAP_NODES ; i++) {
-    bn = allocate_bitmap_node(p_s_sb) ;
-    if (bn) {
-      list_add(&bn->list, &journal->j_bitmap_nodes) ;
-      journal->j_free_bitmap_nodes++ ;
-    } else {
-      break ; // this is ok, we'll try again when more are needed 
-    }
-  }
+				    struct reiserfs_bitmap_node *bn)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	journal->j_used_bitmap_nodes--;
+	if (journal->j_free_bitmap_nodes > REISERFS_MAX_BITMAP_NODES) {
+		reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb);
+		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+	} else {
+		list_add(&bn->list, &journal->j_bitmap_nodes);
+		journal->j_free_bitmap_nodes++;
+	}
+}
+
+static void allocate_bitmap_nodes(struct super_block *p_s_sb)
+{
+	int i;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_bitmap_node *bn = NULL;
+	for (i = 0; i < REISERFS_MIN_BITMAP_NODES; i++) {
+		bn = allocate_bitmap_node(p_s_sb);
+		if (bn) {
+			list_add(&bn->list, &journal->j_bitmap_nodes);
+			journal->j_free_bitmap_nodes++;
+		} else {
+			break;	// this is ok, we'll try again when more are needed 
+		}
+	}
 }
 
 static int set_bit_in_list_bitmap(struct super_block *p_s_sb, int block,
-                                  struct reiserfs_list_bitmap *jb) {
-  int bmap_nr = block / (p_s_sb->s_blocksize << 3) ;
-  int bit_nr = block % (p_s_sb->s_blocksize << 3) ;
+				  struct reiserfs_list_bitmap *jb)
+{
+	int bmap_nr = block / (p_s_sb->s_blocksize << 3);
+	int bit_nr = block % (p_s_sb->s_blocksize << 3);
 
-  if (!jb->bitmaps[bmap_nr]) {
-    jb->bitmaps[bmap_nr] = get_bitmap_node(p_s_sb) ;
-  }
-  set_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data) ;
-  return 0 ;
+	if (!jb->bitmaps[bmap_nr]) {
+		jb->bitmaps[bmap_nr] = get_bitmap_node(p_s_sb);
+	}
+	set_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data);
+	return 0;
 }
 
 static void cleanup_bitmap_list(struct super_block *p_s_sb,
-                                struct reiserfs_list_bitmap *jb) {
-  int i;
-  if (jb->bitmaps == NULL)
-    return;
-
-  for (i = 0 ; i < SB_BMAP_NR(p_s_sb) ; i++) {
-    if (jb->bitmaps[i]) {
-      free_bitmap_node(p_s_sb, jb->bitmaps[i]) ;
-      jb->bitmaps[i] = NULL ;
-    }
-  }
+				struct reiserfs_list_bitmap *jb)
+{
+	int i;
+	if (jb->bitmaps == NULL)
+		return;
+
+	for (i = 0; i < SB_BMAP_NR(p_s_sb); i++) {
+		if (jb->bitmaps[i]) {
+			free_bitmap_node(p_s_sb, jb->bitmaps[i]);
+			jb->bitmaps[i] = NULL;
+		}
+	}
 }
 
 /*
 ** only call this on FS unmount.
 */
 static int free_list_bitmaps(struct super_block *p_s_sb,
-                             struct reiserfs_list_bitmap *jb_array) {
-  int i ;
-  struct reiserfs_list_bitmap *jb ;
-  for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
-    jb = jb_array + i ;
-    jb->journal_list = NULL ;
-    cleanup_bitmap_list(p_s_sb, jb) ;
-    vfree(jb->bitmaps) ;
-    jb->bitmaps = NULL ;
-  }
-  return 0;
-}
-
-static int free_bitmap_nodes(struct super_block *p_s_sb) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct list_head *next = journal->j_bitmap_nodes.next ;
-  struct reiserfs_bitmap_node *bn ;
-
-  while(next != &journal->j_bitmap_nodes) {
-    bn = list_entry(next, struct reiserfs_bitmap_node, list) ;
-    list_del(next) ;
-    reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb) ;
-    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
-    next = journal->j_bitmap_nodes.next ;
-    journal->j_free_bitmap_nodes-- ;
-  }
-
-  return 0 ;
+			     struct reiserfs_list_bitmap *jb_array)
+{
+	int i;
+	struct reiserfs_list_bitmap *jb;
+	for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
+		jb = jb_array + i;
+		jb->journal_list = NULL;
+		cleanup_bitmap_list(p_s_sb, jb);
+		vfree(jb->bitmaps);
+		jb->bitmaps = NULL;
+	}
+	return 0;
+}
+
+static int free_bitmap_nodes(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct list_head *next = journal->j_bitmap_nodes.next;
+	struct reiserfs_bitmap_node *bn;
+
+	while (next != &journal->j_bitmap_nodes) {
+		bn = list_entry(next, struct reiserfs_bitmap_node, list);
+		list_del(next);
+		reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb);
+		reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb);
+		next = journal->j_bitmap_nodes.next;
+		journal->j_free_bitmap_nodes--;
+	}
+
+	return 0;
 }
 
 /*
@@ -275,59 +290,65 @@ static int free_bitmap_nodes(struct super_block *p_s_sb) {
 ** jb_array is the array to be filled in.
 */
 int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
-                                   struct reiserfs_list_bitmap *jb_array,
-				   int bmap_nr) {
-  int i ;
-  int failed = 0 ;
-  struct reiserfs_list_bitmap *jb ;
-  int mem = bmap_nr * sizeof(struct reiserfs_bitmap_node *) ;
-
-  for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
-    jb = jb_array + i ;
-    jb->journal_list = NULL ;
-    jb->bitmaps = vmalloc( mem ) ;
-    if (!jb->bitmaps) {
-      reiserfs_warning(p_s_sb, "clm-2000, unable to allocate bitmaps for journal lists") ;
-      failed = 1;   
-      break ;
-    }
-    memset(jb->bitmaps, 0, mem) ;
-  }
-  if (failed) {
-    free_list_bitmaps(p_s_sb, jb_array) ;
-    return -1 ;
-  }
-  return 0 ;
+				   struct reiserfs_list_bitmap *jb_array,
+				   int bmap_nr)
+{
+	int i;
+	int failed = 0;
+	struct reiserfs_list_bitmap *jb;
+	int mem = bmap_nr * sizeof(struct reiserfs_bitmap_node *);
+
+	for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
+		jb = jb_array + i;
+		jb->journal_list = NULL;
+		jb->bitmaps = vmalloc(mem);
+		if (!jb->bitmaps) {
+			reiserfs_warning(p_s_sb,
+					 "clm-2000, unable to allocate bitmaps for journal lists");
+			failed = 1;
+			break;
+		}
+		memset(jb->bitmaps, 0, mem);
+	}
+	if (failed) {
+		free_list_bitmaps(p_s_sb, jb_array);
+		return -1;
+	}
+	return 0;
 }
 
 /*
 ** find an available list bitmap.  If you can't find one, flush a commit list 
 ** and try again
 */
-static struct reiserfs_list_bitmap *
-get_list_bitmap(struct super_block *p_s_sb, struct reiserfs_journal_list *jl) {
-  int i,j ; 
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_list_bitmap *jb = NULL ;
-
-  for (j = 0 ; j < (JOURNAL_NUM_BITMAPS * 3) ; j++) {
-    i = journal->j_list_bitmap_index ;
-    journal->j_list_bitmap_index = (i + 1) % JOURNAL_NUM_BITMAPS ;
-    jb = journal->j_list_bitmap + i ;
-    if (journal->j_list_bitmap[i].journal_list) {
-      flush_commit_list(p_s_sb, journal->j_list_bitmap[i].journal_list, 1) ;
-      if (!journal->j_list_bitmap[i].journal_list) {
-	break ;
-      }
-    } else {
-      break ;
-    }
-  }
-  if (jb->journal_list) { /* double check to make sure if flushed correctly */
-    return NULL ;
-  }
-  jb->journal_list = jl ;
-  return jb ;
+static struct reiserfs_list_bitmap *get_list_bitmap(struct super_block *p_s_sb,
+						    struct reiserfs_journal_list
+						    *jl)
+{
+	int i, j;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_list_bitmap *jb = NULL;
+
+	for (j = 0; j < (JOURNAL_NUM_BITMAPS * 3); j++) {
+		i = journal->j_list_bitmap_index;
+		journal->j_list_bitmap_index = (i + 1) % JOURNAL_NUM_BITMAPS;
+		jb = journal->j_list_bitmap + i;
+		if (journal->j_list_bitmap[i].journal_list) {
+			flush_commit_list(p_s_sb,
+					  journal->j_list_bitmap[i].
+					  journal_list, 1);
+			if (!journal->j_list_bitmap[i].journal_list) {
+				break;
+			}
+		} else {
+			break;
+		}
+	}
+	if (jb->journal_list) {	/* double check to make sure if flushed correctly */
+		return NULL;
+	}
+	jb->journal_list = jl;
+	return jb;
 }
 
 /* 
@@ -335,104 +356,114 @@ get_list_bitmap(struct super_block *p_s_sb, struct reiserfs_journal_list *jl) {
 ** Uses the cnode->next and cnode->prev pointers
 ** returns NULL on failure
 */
-static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes) {
-  struct reiserfs_journal_cnode *head ;
-  int i ;
-  if (num_cnodes <= 0) {
-    return NULL ;
-  }
-  head = vmalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode)) ;
-  if (!head) {
-    return NULL ;
-  }
-  memset(head, 0, num_cnodes * sizeof(struct reiserfs_journal_cnode)) ;
-  head[0].prev = NULL ;
-  head[0].next = head + 1 ;
-  for (i = 1 ; i < num_cnodes; i++) {
-    head[i].prev = head + (i - 1) ;
-    head[i].next = head + (i + 1) ; /* if last one, overwrite it after the if */
-  }
-  head[num_cnodes -1].next = NULL ;
-  return head ;
+static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes)
+{
+	struct reiserfs_journal_cnode *head;
+	int i;
+	if (num_cnodes <= 0) {
+		return NULL;
+	}
+	head = vmalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode));
+	if (!head) {
+		return NULL;
+	}
+	memset(head, 0, num_cnodes * sizeof(struct reiserfs_journal_cnode));
+	head[0].prev = NULL;
+	head[0].next = head + 1;
+	for (i = 1; i < num_cnodes; i++) {
+		head[i].prev = head + (i - 1);
+		head[i].next = head + (i + 1);	/* if last one, overwrite it after the if */
+	}
+	head[num_cnodes - 1].next = NULL;
+	return head;
 }
 
 /*
 ** pulls a cnode off the free list, or returns NULL on failure 
 */
-static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb) {
-  struct reiserfs_journal_cnode *cn ;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-
-  reiserfs_check_lock_depth(p_s_sb, "get_cnode") ;
-
-  if (journal->j_cnode_free <= 0) {
-    return NULL ;
-  }
-  journal->j_cnode_used++ ;
-  journal->j_cnode_free-- ;
-  cn = journal->j_cnode_free_list ;
-  if (!cn) {
-    return cn ;
-  }
-  if (cn->next) {
-    cn->next->prev = NULL ;
-  }
-  journal->j_cnode_free_list = cn->next ;
-  memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ;
-  return cn ;
+static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal_cnode *cn;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+
+	reiserfs_check_lock_depth(p_s_sb, "get_cnode");
+
+	if (journal->j_cnode_free <= 0) {
+		return NULL;
+	}
+	journal->j_cnode_used++;
+	journal->j_cnode_free--;
+	cn = journal->j_cnode_free_list;
+	if (!cn) {
+		return cn;
+	}
+	if (cn->next) {
+		cn->next->prev = NULL;
+	}
+	journal->j_cnode_free_list = cn->next;
+	memset(cn, 0, sizeof(struct reiserfs_journal_cnode));
+	return cn;
 }
 
 /*
 ** returns a cnode to the free list 
 */
-static void free_cnode(struct super_block *p_s_sb, struct reiserfs_journal_cnode *cn) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+static void free_cnode(struct super_block *p_s_sb,
+		       struct reiserfs_journal_cnode *cn)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 
-  reiserfs_check_lock_depth(p_s_sb, "free_cnode") ;
+	reiserfs_check_lock_depth(p_s_sb, "free_cnode");
 
-  journal->j_cnode_used-- ;
-  journal->j_cnode_free++ ;
-  /* memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ; */
-  cn->next = journal->j_cnode_free_list ;
-  if (journal->j_cnode_free_list) {
-    journal->j_cnode_free_list->prev = cn ;
-  }
-  cn->prev = NULL ; /* not needed with the memset, but I might kill the memset, and forget to do this */
-  journal->j_cnode_free_list = cn ;
+	journal->j_cnode_used--;
+	journal->j_cnode_free++;
+	/* memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ; */
+	cn->next = journal->j_cnode_free_list;
+	if (journal->j_cnode_free_list) {
+		journal->j_cnode_free_list->prev = cn;
+	}
+	cn->prev = NULL;	/* not needed with the memset, but I might kill the memset, and forget to do this */
+	journal->j_cnode_free_list = cn;
 }
 
-static void clear_prepared_bits(struct buffer_head *bh) {
-  clear_buffer_journal_prepared (bh);
-  clear_buffer_journal_restore_dirty (bh);
+static void clear_prepared_bits(struct buffer_head *bh)
+{
+	clear_buffer_journal_prepared(bh);
+	clear_buffer_journal_restore_dirty(bh);
 }
 
 /* utility function to force a BUG if it is called without the big
 ** kernel lock held.  caller is the string printed just before calling BUG()
 */
-void reiserfs_check_lock_depth(struct super_block *sb, char *caller) {
+void reiserfs_check_lock_depth(struct super_block *sb, char *caller)
+{
 #ifdef CONFIG_SMP
-  if (current->lock_depth < 0) {
-    reiserfs_panic (sb, "%s called without kernel lock held", caller) ;
-  }
+	if (current->lock_depth < 0) {
+		reiserfs_panic(sb, "%s called without kernel lock held",
+			       caller);
+	}
 #else
-  ;
+	;
 #endif
 }
 
 /* return a cnode with same dev, block number and size in table, or null if not found */
-static inline struct reiserfs_journal_cnode *
-get_journal_hash_dev(struct super_block *sb,
-		     struct reiserfs_journal_cnode **table,
-		     long bl)
+static inline struct reiserfs_journal_cnode *get_journal_hash_dev(struct
+								  super_block
+								  *sb,
+								  struct
+								  reiserfs_journal_cnode
+								  **table,
+								  long bl)
 {
-  struct reiserfs_journal_cnode *cn ;
-  cn = journal_hash(table, sb, bl) ;
-  while(cn) {
-    if (cn->blocknr == bl && cn->sb == sb)
-      return cn ;
-    cn = cn->hnext ;
-  }
-  return (struct reiserfs_journal_cnode *)0 ;
+	struct reiserfs_journal_cnode *cn;
+	cn = journal_hash(table, sb, bl);
+	while (cn) {
+		if (cn->blocknr == bl && cn->sb == sb)
+			return cn;
+		cn = cn->hnext;
+	}
+	return (struct reiserfs_journal_cnode *)0;
 }
 
 /*
@@ -454,91 +485,103 @@ get_journal_hash_dev(struct super_block *sb,
 **
 */
 int reiserfs_in_journal(struct super_block *p_s_sb,
-                        int bmap_nr, int bit_nr, int search_all, 
-			b_blocknr_t *next_zero_bit) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_cnode *cn ;
-  struct reiserfs_list_bitmap *jb ;
-  int i ;
-  unsigned long bl;
-
-  *next_zero_bit = 0 ; /* always start this at zero. */
-
-  PROC_INFO_INC( p_s_sb, journal.in_journal );
-  /* If we aren't doing a search_all, this is a metablock, and it will be logged before use.
-  ** if we crash before the transaction that freed it commits,  this transaction won't
-  ** have committed either, and the block will never be written
-  */
-  if (search_all) {
-    for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
-      PROC_INFO_INC( p_s_sb, journal.in_journal_bitmap );
-      jb = journal->j_list_bitmap + i ;
-      if (jb->journal_list && jb->bitmaps[bmap_nr] &&
-          test_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data)) {
-	*next_zero_bit = find_next_zero_bit((unsigned long *)
-	                             (jb->bitmaps[bmap_nr]->data),
-	                             p_s_sb->s_blocksize << 3, bit_nr+1) ; 
-	return 1 ;
-      }
-    }
-  }
-
-  bl = bmap_nr * (p_s_sb->s_blocksize << 3) + bit_nr;
-  /* is it in any old transactions? */
-  if (search_all && (cn = get_journal_hash_dev(p_s_sb, journal->j_list_hash_table, bl))) {
-    return 1; 
-  }
-
-  /* is it in the current transaction.  This should never happen */
-  if ((cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, bl))) {
-    BUG();
-    return 1; 
-  }
-
-  PROC_INFO_INC( p_s_sb, journal.in_journal_reusable );
-  /* safe for reuse */
-  return 0 ;
+			int bmap_nr, int bit_nr, int search_all,
+			b_blocknr_t * next_zero_bit)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_cnode *cn;
+	struct reiserfs_list_bitmap *jb;
+	int i;
+	unsigned long bl;
+
+	*next_zero_bit = 0;	/* always start this at zero. */
+
+	PROC_INFO_INC(p_s_sb, journal.in_journal);
+	/* If we aren't doing a search_all, this is a metablock, and it will be logged before use.
+	 ** if we crash before the transaction that freed it commits,  this transaction won't
+	 ** have committed either, and the block will never be written
+	 */
+	if (search_all) {
+		for (i = 0; i < JOURNAL_NUM_BITMAPS; i++) {
+			PROC_INFO_INC(p_s_sb, journal.in_journal_bitmap);
+			jb = journal->j_list_bitmap + i;
+			if (jb->journal_list && jb->bitmaps[bmap_nr] &&
+			    test_bit(bit_nr,
+				     (unsigned long *)jb->bitmaps[bmap_nr]->
+				     data)) {
+				*next_zero_bit =
+				    find_next_zero_bit((unsigned long *)
+						       (jb->bitmaps[bmap_nr]->
+							data),
+						       p_s_sb->s_blocksize << 3,
+						       bit_nr + 1);
+				return 1;
+			}
+		}
+	}
+
+	bl = bmap_nr * (p_s_sb->s_blocksize << 3) + bit_nr;
+	/* is it in any old transactions? */
+	if (search_all
+	    && (cn =
+		get_journal_hash_dev(p_s_sb, journal->j_list_hash_table, bl))) {
+		return 1;
+	}
+
+	/* is it in the current transaction.  This should never happen */
+	if ((cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, bl))) {
+		BUG();
+		return 1;
+	}
+
+	PROC_INFO_INC(p_s_sb, journal.in_journal_reusable);
+	/* safe for reuse */
+	return 0;
 }
 
 /* insert cn into table
 */
-static inline void insert_journal_hash(struct reiserfs_journal_cnode **table, struct reiserfs_journal_cnode *cn) {
-  struct reiserfs_journal_cnode *cn_orig ;
+static inline void insert_journal_hash(struct reiserfs_journal_cnode **table,
+				       struct reiserfs_journal_cnode *cn)
+{
+	struct reiserfs_journal_cnode *cn_orig;
 
-  cn_orig = journal_hash(table, cn->sb, cn->blocknr) ;
-  cn->hnext = cn_orig ;
-  cn->hprev = NULL ;
-  if (cn_orig) {
-    cn_orig->hprev = cn ;
-  }
-  journal_hash(table, cn->sb, cn->blocknr) =  cn ;
+	cn_orig = journal_hash(table, cn->sb, cn->blocknr);
+	cn->hnext = cn_orig;
+	cn->hprev = NULL;
+	if (cn_orig) {
+		cn_orig->hprev = cn;
+	}
+	journal_hash(table, cn->sb, cn->blocknr) = cn;
 }
 
 /* lock the current transaction */
-inline static void lock_journal(struct super_block *p_s_sb) {
-    PROC_INFO_INC( p_s_sb, journal.lock_journal );
-    down(&SB_JOURNAL(p_s_sb)->j_lock);
+inline static void lock_journal(struct super_block *p_s_sb)
+{
+	PROC_INFO_INC(p_s_sb, journal.lock_journal);
+	down(&SB_JOURNAL(p_s_sb)->j_lock);
 }
 
 /* unlock the current transaction */
-inline static void unlock_journal(struct super_block *p_s_sb) {
-    up(&SB_JOURNAL(p_s_sb)->j_lock);
+inline static void unlock_journal(struct super_block *p_s_sb)
+{
+	up(&SB_JOURNAL(p_s_sb)->j_lock);
 }
 
 static inline void get_journal_list(struct reiserfs_journal_list *jl)
 {
-    jl->j_refcount++;
+	jl->j_refcount++;
 }
 
 static inline void put_journal_list(struct super_block *s,
-                                   struct reiserfs_journal_list *jl)
+				    struct reiserfs_journal_list *jl)
 {
-    if (jl->j_refcount < 1) {
-        reiserfs_panic (s, "trans id %lu, refcount at %d", jl->j_trans_id,
-	                                         jl->j_refcount);
-    }
-    if (--jl->j_refcount == 0)
-        reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
+	if (jl->j_refcount < 1) {
+		reiserfs_panic(s, "trans id %lu, refcount at %d",
+			       jl->j_trans_id, jl->j_refcount);
+	}
+	if (--jl->j_refcount == 0)
+		reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
 }
 
 /*
@@ -546,358 +589,375 @@ static inline void put_journal_list(struct super_block *s,
 ** it gets called by flush_commit_list, and cleans up any data stored about blocks freed during a
 ** transaction.
 */
-static void cleanup_freed_for_journal_list(struct super_block *p_s_sb, struct reiserfs_journal_list *jl) {
+static void cleanup_freed_for_journal_list(struct super_block *p_s_sb,
+					   struct reiserfs_journal_list *jl)
+{
 
-  struct reiserfs_list_bitmap *jb = jl->j_list_bitmap ;
-  if (jb) {
-    cleanup_bitmap_list(p_s_sb, jb) ;
-  }
-  jl->j_list_bitmap->journal_list = NULL ;
-  jl->j_list_bitmap = NULL ;
+	struct reiserfs_list_bitmap *jb = jl->j_list_bitmap;
+	if (jb) {
+		cleanup_bitmap_list(p_s_sb, jb);
+	}
+	jl->j_list_bitmap->journal_list = NULL;
+	jl->j_list_bitmap = NULL;
 }
 
 static int journal_list_still_alive(struct super_block *s,
-                                    unsigned long trans_id)
-{
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    struct list_head *entry = &journal->j_journal_list;
-    struct reiserfs_journal_list *jl;
-
-    if (!list_empty(entry)) {
-        jl = JOURNAL_LIST_ENTRY(entry->next);
-	if (jl->j_trans_id <= trans_id) {
-	    return 1;
-	}
-    }
-    return 0;
-}
-
-static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate) {
-    char b[BDEVNAME_SIZE];
-
-    if (buffer_journaled(bh)) {
-        reiserfs_warning(NULL, "clm-2084: pinned buffer %lu:%s sent to disk",
-	                 bh->b_blocknr, bdevname(bh->b_bdev, b)) ;
-    }
-    if (uptodate)
-    	set_buffer_uptodate(bh) ;
-    else
-    	clear_buffer_uptodate(bh) ;
-    unlock_buffer(bh) ;
-    put_bh(bh) ;
-}
-
-static void reiserfs_end_ordered_io(struct buffer_head *bh, int uptodate) {
-    if (uptodate)
-    	set_buffer_uptodate(bh) ;
-    else
-    	clear_buffer_uptodate(bh) ;
-    unlock_buffer(bh) ;
-    put_bh(bh) ;
-}
-
-static void submit_logged_buffer(struct buffer_head *bh) {
-    get_bh(bh) ;
-    bh->b_end_io = reiserfs_end_buffer_io_sync ;
-    clear_buffer_journal_new (bh);
-    clear_buffer_dirty(bh) ;
-    if (!test_clear_buffer_journal_test (bh))
-        BUG();
-    if (!buffer_uptodate(bh))
-        BUG();
-    submit_bh(WRITE, bh) ;
-}
-
-static void submit_ordered_buffer(struct buffer_head *bh) {
-    get_bh(bh) ;
-    bh->b_end_io = reiserfs_end_ordered_io;
-    clear_buffer_dirty(bh) ;
-    if (!buffer_uptodate(bh))
-        BUG();
-    submit_bh(WRITE, bh) ;
-}
-
-static int submit_barrier_buffer(struct buffer_head *bh) {
-    get_bh(bh) ;
-    bh->b_end_io = reiserfs_end_ordered_io;
-    clear_buffer_dirty(bh) ;
-    if (!buffer_uptodate(bh))
-        BUG();
-    return submit_bh(WRITE_BARRIER, bh) ;
+				    unsigned long trans_id)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	struct list_head *entry = &journal->j_journal_list;
+	struct reiserfs_journal_list *jl;
+
+	if (!list_empty(entry)) {
+		jl = JOURNAL_LIST_ENTRY(entry->next);
+		if (jl->j_trans_id <= trans_id) {
+			return 1;
+		}
+	}
+	return 0;
+}
+
+static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate)
+{
+	char b[BDEVNAME_SIZE];
+
+	if (buffer_journaled(bh)) {
+		reiserfs_warning(NULL,
+				 "clm-2084: pinned buffer %lu:%s sent to disk",
+				 bh->b_blocknr, bdevname(bh->b_bdev, b));
+	}
+	if (uptodate)
+		set_buffer_uptodate(bh);
+	else
+		clear_buffer_uptodate(bh);
+	unlock_buffer(bh);
+	put_bh(bh);
+}
+
+static void reiserfs_end_ordered_io(struct buffer_head *bh, int uptodate)
+{
+	if (uptodate)
+		set_buffer_uptodate(bh);
+	else
+		clear_buffer_uptodate(bh);
+	unlock_buffer(bh);
+	put_bh(bh);
+}
+
+static void submit_logged_buffer(struct buffer_head *bh)
+{
+	get_bh(bh);
+	bh->b_end_io = reiserfs_end_buffer_io_sync;
+	clear_buffer_journal_new(bh);
+	clear_buffer_dirty(bh);
+	if (!test_clear_buffer_journal_test(bh))
+		BUG();
+	if (!buffer_uptodate(bh))
+		BUG();
+	submit_bh(WRITE, bh);
+}
+
+static void submit_ordered_buffer(struct buffer_head *bh)
+{
+	get_bh(bh);
+	bh->b_end_io = reiserfs_end_ordered_io;
+	clear_buffer_dirty(bh);
+	if (!buffer_uptodate(bh))
+		BUG();
+	submit_bh(WRITE, bh);
+}
+
+static int submit_barrier_buffer(struct buffer_head *bh)
+{
+	get_bh(bh);
+	bh->b_end_io = reiserfs_end_ordered_io;
+	clear_buffer_dirty(bh);
+	if (!buffer_uptodate(bh))
+		BUG();
+	return submit_bh(WRITE_BARRIER, bh);
 }
 
 static void check_barrier_completion(struct super_block *s,
-                                     struct buffer_head *bh) {
-    if (buffer_eopnotsupp(bh)) {
-	clear_buffer_eopnotsupp(bh);
-	disable_barrier(s);
-	set_buffer_uptodate(bh);
-	set_buffer_dirty(bh);
-	sync_dirty_buffer(bh);
-    }
+				     struct buffer_head *bh)
+{
+	if (buffer_eopnotsupp(bh)) {
+		clear_buffer_eopnotsupp(bh);
+		disable_barrier(s);
+		set_buffer_uptodate(bh);
+		set_buffer_dirty(bh);
+		sync_dirty_buffer(bh);
+	}
 }
 
 #define CHUNK_SIZE 32
 struct buffer_chunk {
-    struct buffer_head *bh[CHUNK_SIZE];
-    int nr;
+	struct buffer_head *bh[CHUNK_SIZE];
+	int nr;
 };
 
-static void write_chunk(struct buffer_chunk *chunk) {
-    int i;
-    get_fs_excl();
-    for (i = 0; i < chunk->nr ; i++) {
-	submit_logged_buffer(chunk->bh[i]) ;
-    }
-    chunk->nr = 0;
-    put_fs_excl();
+static void write_chunk(struct buffer_chunk *chunk)
+{
+	int i;
+	get_fs_excl();
+	for (i = 0; i < chunk->nr; i++) {
+		submit_logged_buffer(chunk->bh[i]);
+	}
+	chunk->nr = 0;
+	put_fs_excl();
 }
 
-static void write_ordered_chunk(struct buffer_chunk *chunk) {
-    int i;
-    get_fs_excl();
-    for (i = 0; i < chunk->nr ; i++) {
-	submit_ordered_buffer(chunk->bh[i]) ;
-    }
-    chunk->nr = 0;
-    put_fs_excl();
+static void write_ordered_chunk(struct buffer_chunk *chunk)
+{
+	int i;
+	get_fs_excl();
+	for (i = 0; i < chunk->nr; i++) {
+		submit_ordered_buffer(chunk->bh[i]);
+	}
+	chunk->nr = 0;
+	put_fs_excl();
 }
 
 static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
-			 spinlock_t *lock,
-			 void (fn)(struct buffer_chunk *))
+			spinlock_t * lock, void (fn) (struct buffer_chunk *))
 {
-    int ret = 0;
-    if (chunk->nr >= CHUNK_SIZE)
-        BUG();
-    chunk->bh[chunk->nr++] = bh;
-    if (chunk->nr >= CHUNK_SIZE) {
-	ret = 1;
-        if (lock)
-	    spin_unlock(lock);
-        fn(chunk);
-        if (lock)
-	    spin_lock(lock);
-    }
-    return ret;
+	int ret = 0;
+	if (chunk->nr >= CHUNK_SIZE)
+		BUG();
+	chunk->bh[chunk->nr++] = bh;
+	if (chunk->nr >= CHUNK_SIZE) {
+		ret = 1;
+		if (lock)
+			spin_unlock(lock);
+		fn(chunk);
+		if (lock)
+			spin_lock(lock);
+	}
+	return ret;
 }
 
-
 static atomic_t nr_reiserfs_jh = ATOMIC_INIT(0);
-static struct reiserfs_jh *alloc_jh(void) {
-    struct reiserfs_jh *jh;
-    while(1) {
-	jh = kmalloc(sizeof(*jh), GFP_NOFS);
-	if (jh) {
-	    atomic_inc(&nr_reiserfs_jh);
-	    return jh;
+static struct reiserfs_jh *alloc_jh(void)
+{
+	struct reiserfs_jh *jh;
+	while (1) {
+		jh = kmalloc(sizeof(*jh), GFP_NOFS);
+		if (jh) {
+			atomic_inc(&nr_reiserfs_jh);
+			return jh;
+		}
+		yield();
 	}
-        yield();
-    }
 }
 
 /*
  * we want to free the jh when the buffer has been written
  * and waited on
  */
-void reiserfs_free_jh(struct buffer_head *bh) {
-    struct reiserfs_jh *jh;
-
-    jh = bh->b_private;
-    if (jh) {
-	bh->b_private = NULL;
-	jh->bh = NULL;
-	list_del_init(&jh->list);
-	kfree(jh);
-	if (atomic_read(&nr_reiserfs_jh) <= 0)
-	    BUG();
-	atomic_dec(&nr_reiserfs_jh);
-	put_bh(bh);
-    }
+void reiserfs_free_jh(struct buffer_head *bh)
+{
+	struct reiserfs_jh *jh;
+
+	jh = bh->b_private;
+	if (jh) {
+		bh->b_private = NULL;
+		jh->bh = NULL;
+		list_del_init(&jh->list);
+		kfree(jh);
+		if (atomic_read(&nr_reiserfs_jh) <= 0)
+			BUG();
+		atomic_dec(&nr_reiserfs_jh);
+		put_bh(bh);
+	}
 }
 
 static inline int __add_jh(struct reiserfs_journal *j, struct buffer_head *bh,
-                           int tail)
+			   int tail)
 {
-    struct reiserfs_jh *jh;
+	struct reiserfs_jh *jh;
 
-    if (bh->b_private) {
-	spin_lock(&j->j_dirty_buffers_lock);
-	if (!bh->b_private) {
-	    spin_unlock(&j->j_dirty_buffers_lock);
-	    goto no_jh;
+	if (bh->b_private) {
+		spin_lock(&j->j_dirty_buffers_lock);
+		if (!bh->b_private) {
+			spin_unlock(&j->j_dirty_buffers_lock);
+			goto no_jh;
+		}
+		jh = bh->b_private;
+		list_del_init(&jh->list);
+	} else {
+	      no_jh:
+		get_bh(bh);
+		jh = alloc_jh();
+		spin_lock(&j->j_dirty_buffers_lock);
+		/* buffer must be locked for __add_jh, should be able to have
+		 * two adds at the same time
+		 */
+		if (bh->b_private)
+			BUG();
+		jh->bh = bh;
+		bh->b_private = jh;
 	}
-        jh = bh->b_private;
-	list_del_init(&jh->list);
-    } else {
-no_jh:
-	get_bh(bh);
-	jh = alloc_jh();
-	spin_lock(&j->j_dirty_buffers_lock);
-	/* buffer must be locked for __add_jh, should be able to have
-	 * two adds at the same time
-	 */
-	if (bh->b_private)
-	    BUG();
-	jh->bh = bh;
-	bh->b_private = jh;
-    }
-    jh->jl = j->j_current_jl;
-    if (tail)
-	list_add_tail(&jh->list, &jh->jl->j_tail_bh_list);
-    else {
-	list_add_tail(&jh->list, &jh->jl->j_bh_list);
-    }
-    spin_unlock(&j->j_dirty_buffers_lock);
-    return 0;
+	jh->jl = j->j_current_jl;
+	if (tail)
+		list_add_tail(&jh->list, &jh->jl->j_tail_bh_list);
+	else {
+		list_add_tail(&jh->list, &jh->jl->j_bh_list);
+	}
+	spin_unlock(&j->j_dirty_buffers_lock);
+	return 0;
 }
 
-int reiserfs_add_tail_list(struct inode *inode, struct buffer_head *bh) {
-    return __add_jh(SB_JOURNAL(inode->i_sb), bh, 1);
+int reiserfs_add_tail_list(struct inode *inode, struct buffer_head *bh)
+{
+	return __add_jh(SB_JOURNAL(inode->i_sb), bh, 1);
 }
-int reiserfs_add_ordered_list(struct inode *inode, struct buffer_head *bh) {
-    return __add_jh(SB_JOURNAL(inode->i_sb), bh, 0);
+int reiserfs_add_ordered_list(struct inode *inode, struct buffer_head *bh)
+{
+	return __add_jh(SB_JOURNAL(inode->i_sb), bh, 0);
 }
 
 #define JH_ENTRY(l) list_entry((l), struct reiserfs_jh, list)
-static int write_ordered_buffers(spinlock_t *lock,
+static int write_ordered_buffers(spinlock_t * lock,
 				 struct reiserfs_journal *j,
-                                 struct reiserfs_journal_list *jl,
+				 struct reiserfs_journal_list *jl,
 				 struct list_head *list)
 {
-    struct buffer_head *bh;
-    struct reiserfs_jh *jh;
-    int ret = j->j_errno;
-    struct buffer_chunk chunk;
-    struct list_head tmp;
-    INIT_LIST_HEAD(&tmp);
-
-    chunk.nr = 0;
-    spin_lock(lock);
-    while(!list_empty(list)) {
-        jh = JH_ENTRY(list->next);
-	bh = jh->bh;
-	get_bh(bh);
-	if (test_set_buffer_locked(bh)) {
-	    if (!buffer_dirty(bh)) {
-		list_del_init(&jh->list);
-		list_add(&jh->list, &tmp);
-		goto loop_next;
-	    }
-	    spin_unlock(lock);
-	    if (chunk.nr)
+	struct buffer_head *bh;
+	struct reiserfs_jh *jh;
+	int ret = j->j_errno;
+	struct buffer_chunk chunk;
+	struct list_head tmp;
+	INIT_LIST_HEAD(&tmp);
+
+	chunk.nr = 0;
+	spin_lock(lock);
+	while (!list_empty(list)) {
+		jh = JH_ENTRY(list->next);
+		bh = jh->bh;
+		get_bh(bh);
+		if (test_set_buffer_locked(bh)) {
+			if (!buffer_dirty(bh)) {
+				list_del_init(&jh->list);
+				list_add(&jh->list, &tmp);
+				goto loop_next;
+			}
+			spin_unlock(lock);
+			if (chunk.nr)
+				write_ordered_chunk(&chunk);
+			wait_on_buffer(bh);
+			cond_resched();
+			spin_lock(lock);
+			goto loop_next;
+		}
+		if (buffer_dirty(bh)) {
+			list_del_init(&jh->list);
+			list_add(&jh->list, &tmp);
+			add_to_chunk(&chunk, bh, lock, write_ordered_chunk);
+		} else {
+			reiserfs_free_jh(bh);
+			unlock_buffer(bh);
+		}
+	      loop_next:
+		put_bh(bh);
+		cond_resched_lock(lock);
+	}
+	if (chunk.nr) {
+		spin_unlock(lock);
 		write_ordered_chunk(&chunk);
-	    wait_on_buffer(bh);
-	    cond_resched();
-	    spin_lock(lock);
-	    goto loop_next;
-        }
-	if (buffer_dirty(bh)) {
-	    list_del_init(&jh->list);
-	    list_add(&jh->list, &tmp);
-            add_to_chunk(&chunk, bh, lock, write_ordered_chunk);
-	} else {
-	    reiserfs_free_jh(bh);
-	    unlock_buffer(bh);
+		spin_lock(lock);
 	}
-loop_next:
-	put_bh(bh);
-	cond_resched_lock(lock);
-    }
-    if (chunk.nr) {
-	spin_unlock(lock);
-        write_ordered_chunk(&chunk);
-	spin_lock(lock);
-    }
-    while(!list_empty(&tmp)) {
-        jh = JH_ENTRY(tmp.prev);
-	bh = jh->bh;
-	get_bh(bh);
-	reiserfs_free_jh(bh);
-
-	if (buffer_locked(bh)) {
-	    spin_unlock(lock);
-	    wait_on_buffer(bh);
-	    spin_lock(lock);
+	while (!list_empty(&tmp)) {
+		jh = JH_ENTRY(tmp.prev);
+		bh = jh->bh;
+		get_bh(bh);
+		reiserfs_free_jh(bh);
+
+		if (buffer_locked(bh)) {
+			spin_unlock(lock);
+			wait_on_buffer(bh);
+			spin_lock(lock);
+		}
+		if (!buffer_uptodate(bh)) {
+			ret = -EIO;
+		}
+		put_bh(bh);
+		cond_resched_lock(lock);
 	}
-	if (!buffer_uptodate(bh)) {
-	    ret = -EIO;
-        }
-	put_bh(bh);
-	cond_resched_lock(lock);
-    }
-    spin_unlock(lock);
-    return ret;
-}
-
-static int flush_older_commits(struct super_block *s, struct reiserfs_journal_list *jl) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    struct reiserfs_journal_list *other_jl;
-    struct reiserfs_journal_list *first_jl;
-    struct list_head *entry;
-    unsigned long trans_id = jl->j_trans_id;
-    unsigned long other_trans_id;
-    unsigned long first_trans_id;
-
-find_first:
-    /*
-     * first we walk backwards to find the oldest uncommitted transation
-     */
-    first_jl = jl;
-    entry = jl->j_list.prev;
-    while(1) {
-	other_jl = JOURNAL_LIST_ENTRY(entry);
-	if (entry == &journal->j_journal_list ||
-	    atomic_read(&other_jl->j_older_commits_done))
-	    break;
-
-        first_jl = other_jl;
-	entry = other_jl->j_list.prev;
-    }
-
-    /* if we didn't find any older uncommitted transactions, return now */
-    if (first_jl == jl) {
-        return 0;
-    }
-
-    first_trans_id = first_jl->j_trans_id;
+	spin_unlock(lock);
+	return ret;
+}
 
-    entry = &first_jl->j_list;
-    while(1) {
-	other_jl = JOURNAL_LIST_ENTRY(entry);
-	other_trans_id = other_jl->j_trans_id;
+static int flush_older_commits(struct super_block *s,
+			       struct reiserfs_journal_list *jl)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	struct reiserfs_journal_list *other_jl;
+	struct reiserfs_journal_list *first_jl;
+	struct list_head *entry;
+	unsigned long trans_id = jl->j_trans_id;
+	unsigned long other_trans_id;
+	unsigned long first_trans_id;
+
+      find_first:
+	/*
+	 * first we walk backwards to find the oldest uncommitted transation
+	 */
+	first_jl = jl;
+	entry = jl->j_list.prev;
+	while (1) {
+		other_jl = JOURNAL_LIST_ENTRY(entry);
+		if (entry == &journal->j_journal_list ||
+		    atomic_read(&other_jl->j_older_commits_done))
+			break;
 
-	if (other_trans_id < trans_id) {
-	    if (atomic_read(&other_jl->j_commit_left) != 0) {
-		flush_commit_list(s, other_jl, 0);
+		first_jl = other_jl;
+		entry = other_jl->j_list.prev;
+	}
 
-		/* list we were called with is gone, return */
-		if (!journal_list_still_alive(s, trans_id))
-		    return 1;
+	/* if we didn't find any older uncommitted transactions, return now */
+	if (first_jl == jl) {
+		return 0;
+	}
 
-		/* the one we just flushed is gone, this means all
-		 * older lists are also gone, so first_jl is no longer
-		 * valid either.  Go back to the beginning.
-		 */
-		if (!journal_list_still_alive(s, other_trans_id)) {
-		    goto find_first;
+	first_trans_id = first_jl->j_trans_id;
+
+	entry = &first_jl->j_list;
+	while (1) {
+		other_jl = JOURNAL_LIST_ENTRY(entry);
+		other_trans_id = other_jl->j_trans_id;
+
+		if (other_trans_id < trans_id) {
+			if (atomic_read(&other_jl->j_commit_left) != 0) {
+				flush_commit_list(s, other_jl, 0);
+
+				/* list we were called with is gone, return */
+				if (!journal_list_still_alive(s, trans_id))
+					return 1;
+
+				/* the one we just flushed is gone, this means all
+				 * older lists are also gone, so first_jl is no longer
+				 * valid either.  Go back to the beginning.
+				 */
+				if (!journal_list_still_alive
+				    (s, other_trans_id)) {
+					goto find_first;
+				}
+			}
+			entry = entry->next;
+			if (entry == &journal->j_journal_list)
+				return 0;
+		} else {
+			return 0;
 		}
-	    }
-	    entry = entry->next;
-	    if (entry == &journal->j_journal_list)
-		return 0;
-	} else {
-	    return 0;
 	}
-    }
-    return 0;
+	return 0;
 }
-int reiserfs_async_progress_wait(struct super_block *s) {
-    DEFINE_WAIT(wait);
-    struct reiserfs_journal *j = SB_JOURNAL(s);
-    if (atomic_read(&j->j_async_throttle))
-    	blk_congestion_wait(WRITE, HZ/10);
-    return 0;
+int reiserfs_async_progress_wait(struct super_block *s)
+{
+	DEFINE_WAIT(wait);
+	struct reiserfs_journal *j = SB_JOURNAL(s);
+	if (atomic_read(&j->j_async_throttle))
+		blk_congestion_wait(WRITE, HZ / 10);
+	return 0;
 }
 
 /*
@@ -907,212 +967,225 @@ int reiserfs_async_progress_wait(struct super_block *s) {
 ** Before the commit block can by written, every other log block must be safely on disk
 **
 */
-static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall) {
-  int i;
-  int bn ;
-  struct buffer_head *tbh = NULL ;
-  unsigned long trans_id = jl->j_trans_id;
-  struct reiserfs_journal *journal = SB_JOURNAL (s);
-  int barrier = 0;
-  int retval = 0;
-
-  reiserfs_check_lock_depth(s, "flush_commit_list") ;
-
-  if (atomic_read(&jl->j_older_commits_done)) {
-    return 0 ;
-  }
-
-  get_fs_excl();
-
-  /* before we can put our commit blocks on disk, we have to make sure everyone older than
-  ** us is on disk too
-  */
-  BUG_ON (jl->j_len <= 0);
-  BUG_ON (trans_id == journal->j_trans_id);
-
-  get_journal_list(jl);
-  if (flushall) {
-    if (flush_older_commits(s, jl) == 1) {
-      /* list disappeared during flush_older_commits.  return */
-      goto put_jl;
-    }
-  }
-
-  /* make sure nobody is trying to flush this one at the same time */
-  down(&jl->j_commit_lock);
-  if (!journal_list_still_alive(s, trans_id)) {
-    up(&jl->j_commit_lock);
-    goto put_jl;
-  }
-  BUG_ON (jl->j_trans_id == 0);
-
-  /* this commit is done, exit */
-  if (atomic_read(&(jl->j_commit_left)) <= 0) {
-    if (flushall) {
-      atomic_set(&(jl->j_older_commits_done), 1) ;
-    }
-    up(&jl->j_commit_lock);
-    goto put_jl;
-  }
-
-  if (!list_empty(&jl->j_bh_list)) {
-      unlock_kernel();
-      write_ordered_buffers(&journal->j_dirty_buffers_lock,
-                            journal, jl, &jl->j_bh_list);
-      lock_kernel();
-  }
-  BUG_ON (!list_empty(&jl->j_bh_list));
-  /*
-   * for the description block and all the log blocks, submit any buffers
-   * that haven't already reached the disk
-   */
-  atomic_inc(&journal->j_async_throttle);
-  for (i = 0 ; i < (jl->j_len + 1) ; i++) {
-    bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) + (jl->j_start+i) %
-         SB_ONDISK_JOURNAL_SIZE(s);
-    tbh = journal_find_get_block(s, bn) ;
-    if (buffer_dirty(tbh)) /* redundant, ll_rw_block() checks */
-	ll_rw_block(WRITE, 1, &tbh) ;
-    put_bh(tbh) ;
-  }
-  atomic_dec(&journal->j_async_throttle);
-
-  /* wait on everything written so far before writing the commit
-   * if we are in barrier mode, send the commit down now
-   */
-  barrier = reiserfs_barrier_flush(s);
-  if (barrier) {
-      int ret;
-      lock_buffer(jl->j_commit_bh);
-      ret = submit_barrier_buffer(jl->j_commit_bh);
-      if (ret == -EOPNOTSUPP) {
-	  set_buffer_uptodate(jl->j_commit_bh);
-          disable_barrier(s);
-	  barrier = 0;
-      }
-  }
-  for (i = 0 ;  i < (jl->j_len + 1) ; i++) {
-    bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) +
-	 (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s) ;
-    tbh = journal_find_get_block(s, bn) ;
-    wait_on_buffer(tbh) ;
-    // since we're using ll_rw_blk above, it might have skipped over
-    // a locked buffer.  Double check here
-    //
-    if (buffer_dirty(tbh)) /* redundant, sync_dirty_buffer() checks */
-      sync_dirty_buffer(tbh);
-    if (unlikely (!buffer_uptodate(tbh))) {
+static int flush_commit_list(struct super_block *s,
+			     struct reiserfs_journal_list *jl, int flushall)
+{
+	int i;
+	int bn;
+	struct buffer_head *tbh = NULL;
+	unsigned long trans_id = jl->j_trans_id;
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	int barrier = 0;
+	int retval = 0;
+
+	reiserfs_check_lock_depth(s, "flush_commit_list");
+
+	if (atomic_read(&jl->j_older_commits_done)) {
+		return 0;
+	}
+
+	get_fs_excl();
+
+	/* before we can put our commit blocks on disk, we have to make sure everyone older than
+	 ** us is on disk too
+	 */
+	BUG_ON(jl->j_len <= 0);
+	BUG_ON(trans_id == journal->j_trans_id);
+
+	get_journal_list(jl);
+	if (flushall) {
+		if (flush_older_commits(s, jl) == 1) {
+			/* list disappeared during flush_older_commits.  return */
+			goto put_jl;
+		}
+	}
+
+	/* make sure nobody is trying to flush this one at the same time */
+	down(&jl->j_commit_lock);
+	if (!journal_list_still_alive(s, trans_id)) {
+		up(&jl->j_commit_lock);
+		goto put_jl;
+	}
+	BUG_ON(jl->j_trans_id == 0);
+
+	/* this commit is done, exit */
+	if (atomic_read(&(jl->j_commit_left)) <= 0) {
+		if (flushall) {
+			atomic_set(&(jl->j_older_commits_done), 1);
+		}
+		up(&jl->j_commit_lock);
+		goto put_jl;
+	}
+
+	if (!list_empty(&jl->j_bh_list)) {
+		unlock_kernel();
+		write_ordered_buffers(&journal->j_dirty_buffers_lock,
+				      journal, jl, &jl->j_bh_list);
+		lock_kernel();
+	}
+	BUG_ON(!list_empty(&jl->j_bh_list));
+	/*
+	 * for the description block and all the log blocks, submit any buffers
+	 * that haven't already reached the disk
+	 */
+	atomic_inc(&journal->j_async_throttle);
+	for (i = 0; i < (jl->j_len + 1); i++) {
+		bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) + (jl->j_start + i) %
+		    SB_ONDISK_JOURNAL_SIZE(s);
+		tbh = journal_find_get_block(s, bn);
+		if (buffer_dirty(tbh))	/* redundant, ll_rw_block() checks */
+			ll_rw_block(WRITE, 1, &tbh);
+		put_bh(tbh);
+	}
+	atomic_dec(&journal->j_async_throttle);
+
+	/* wait on everything written so far before writing the commit
+	 * if we are in barrier mode, send the commit down now
+	 */
+	barrier = reiserfs_barrier_flush(s);
+	if (barrier) {
+		int ret;
+		lock_buffer(jl->j_commit_bh);
+		ret = submit_barrier_buffer(jl->j_commit_bh);
+		if (ret == -EOPNOTSUPP) {
+			set_buffer_uptodate(jl->j_commit_bh);
+			disable_barrier(s);
+			barrier = 0;
+		}
+	}
+	for (i = 0; i < (jl->j_len + 1); i++) {
+		bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) +
+		    (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s);
+		tbh = journal_find_get_block(s, bn);
+		wait_on_buffer(tbh);
+		// since we're using ll_rw_blk above, it might have skipped over
+		// a locked buffer.  Double check here
+		//
+		if (buffer_dirty(tbh))	/* redundant, sync_dirty_buffer() checks */
+			sync_dirty_buffer(tbh);
+		if (unlikely(!buffer_uptodate(tbh))) {
 #ifdef CONFIG_REISERFS_CHECK
-      reiserfs_warning(s, "journal-601, buffer write failed") ;
+			reiserfs_warning(s, "journal-601, buffer write failed");
 #endif
-      retval = -EIO;
-    }
-    put_bh(tbh) ; /* once for journal_find_get_block */
-    put_bh(tbh) ;    /* once due to original getblk in do_journal_end */
-    atomic_dec(&(jl->j_commit_left)) ;
-  }
-
-  BUG_ON (atomic_read(&(jl->j_commit_left)) != 1);
-
-  if (!barrier) {
-      if (buffer_dirty(jl->j_commit_bh))
-	BUG();
-      mark_buffer_dirty(jl->j_commit_bh) ;
-      sync_dirty_buffer(jl->j_commit_bh) ;
-  } else
-      wait_on_buffer(jl->j_commit_bh);
-
-  check_barrier_completion(s, jl->j_commit_bh);
-
-  /* If there was a write error in the journal - we can't commit this
-   * transaction - it will be invalid and, if successful, will just end
-   * up propogating the write error out to the filesystem. */
-  if (unlikely (!buffer_uptodate(jl->j_commit_bh))) {
+			retval = -EIO;
+		}
+		put_bh(tbh);	/* once for journal_find_get_block */
+		put_bh(tbh);	/* once due to original getblk in do_journal_end */
+		atomic_dec(&(jl->j_commit_left));
+	}
+
+	BUG_ON(atomic_read(&(jl->j_commit_left)) != 1);
+
+	if (!barrier) {
+		if (buffer_dirty(jl->j_commit_bh))
+			BUG();
+		mark_buffer_dirty(jl->j_commit_bh);
+		sync_dirty_buffer(jl->j_commit_bh);
+	} else
+		wait_on_buffer(jl->j_commit_bh);
+
+	check_barrier_completion(s, jl->j_commit_bh);
+
+	/* If there was a write error in the journal - we can't commit this
+	 * transaction - it will be invalid and, if successful, will just end
+	 * up propogating the write error out to the filesystem. */
+	if (unlikely(!buffer_uptodate(jl->j_commit_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-    reiserfs_warning(s, "journal-615: buffer write failed") ;
+		reiserfs_warning(s, "journal-615: buffer write failed");
 #endif
-    retval = -EIO;
-  }
-  bforget(jl->j_commit_bh) ;
-  if (journal->j_last_commit_id != 0 &&
-     (jl->j_trans_id - journal->j_last_commit_id) != 1) {
-      reiserfs_warning(s, "clm-2200: last commit %lu, current %lu",
-                       journal->j_last_commit_id,
-		       jl->j_trans_id);
-  }
-  journal->j_last_commit_id = jl->j_trans_id;
-
-  /* now, every commit block is on the disk.  It is safe to allow blocks freed during this transaction to be reallocated */
-  cleanup_freed_for_journal_list(s, jl) ;
-
-  retval = retval ? retval : journal->j_errno;
-
-  /* mark the metadata dirty */
-  if (!retval)
-    dirty_one_transaction(s, jl);
-  atomic_dec(&(jl->j_commit_left)) ;
-
-  if (flushall) {
-    atomic_set(&(jl->j_older_commits_done), 1) ;
-  }
-  up(&jl->j_commit_lock);
-put_jl:
-  put_journal_list(s, jl);
-
-  if (retval)
-    reiserfs_abort (s, retval, "Journal write error in %s", __FUNCTION__);
-  put_fs_excl();
-  return retval;
+		retval = -EIO;
+	}
+	bforget(jl->j_commit_bh);
+	if (journal->j_last_commit_id != 0 &&
+	    (jl->j_trans_id - journal->j_last_commit_id) != 1) {
+		reiserfs_warning(s, "clm-2200: last commit %lu, current %lu",
+				 journal->j_last_commit_id, jl->j_trans_id);
+	}
+	journal->j_last_commit_id = jl->j_trans_id;
+
+	/* now, every commit block is on the disk.  It is safe to allow blocks freed during this transaction to be reallocated */
+	cleanup_freed_for_journal_list(s, jl);
+
+	retval = retval ? retval : journal->j_errno;
+
+	/* mark the metadata dirty */
+	if (!retval)
+		dirty_one_transaction(s, jl);
+	atomic_dec(&(jl->j_commit_left));
+
+	if (flushall) {
+		atomic_set(&(jl->j_older_commits_done), 1);
+	}
+	up(&jl->j_commit_lock);
+      put_jl:
+	put_journal_list(s, jl);
+
+	if (retval)
+		reiserfs_abort(s, retval, "Journal write error in %s",
+			       __FUNCTION__);
+	put_fs_excl();
+	return retval;
 }
 
 /*
 ** flush_journal_list frequently needs to find a newer transaction for a given block.  This does that, or 
 ** returns NULL if it can't find anything 
 */
-static struct reiserfs_journal_list *find_newer_jl_for_cn(struct reiserfs_journal_cnode *cn) {
-  struct super_block *sb = cn->sb;
-  b_blocknr_t blocknr = cn->blocknr ;
+static struct reiserfs_journal_list *find_newer_jl_for_cn(struct
+							  reiserfs_journal_cnode
+							  *cn)
+{
+	struct super_block *sb = cn->sb;
+	b_blocknr_t blocknr = cn->blocknr;
 
-  cn = cn->hprev ;
-  while(cn) {
-    if (cn->sb == sb && cn->blocknr == blocknr && cn->jlist) {
-      return cn->jlist ;
-    }
-    cn = cn->hprev ;
-  }
-  return NULL ;
+	cn = cn->hprev;
+	while (cn) {
+		if (cn->sb == sb && cn->blocknr == blocknr && cn->jlist) {
+			return cn->jlist;
+		}
+		cn = cn->hprev;
+	}
+	return NULL;
 }
 
-static void remove_journal_hash(struct super_block *, struct reiserfs_journal_cnode **,
-struct reiserfs_journal_list *, unsigned long, int);
+static void remove_journal_hash(struct super_block *,
+				struct reiserfs_journal_cnode **,
+				struct reiserfs_journal_list *, unsigned long,
+				int);
 
 /*
 ** once all the real blocks have been flushed, it is safe to remove them from the
 ** journal list for this transaction.  Aside from freeing the cnode, this also allows the
 ** block to be reallocated for data blocks if it had been deleted.
 */
-static void remove_all_from_journal_list(struct super_block *p_s_sb, struct reiserfs_journal_list *jl, int debug) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_cnode *cn, *last ;
-  cn = jl->j_realblock ;
-
-  /* which is better, to lock once around the whole loop, or
-  ** to lock for each call to remove_journal_hash?
-  */
-  while(cn) {
-    if (cn->blocknr != 0) {
-      if (debug) {
-       reiserfs_warning (p_s_sb, "block %u, bh is %d, state %ld", cn->blocknr,
-                         cn->bh ? 1: 0, cn->state) ;
-      }
-      cn->state = 0 ;
-      remove_journal_hash(p_s_sb, journal->j_list_hash_table, jl, cn->blocknr, 1) ;
-    }
-    last = cn ;
-    cn = cn->next ;
-    free_cnode(p_s_sb, last) ;
-  }
-  jl->j_realblock = NULL ;
+static void remove_all_from_journal_list(struct super_block *p_s_sb,
+					 struct reiserfs_journal_list *jl,
+					 int debug)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_cnode *cn, *last;
+	cn = jl->j_realblock;
+
+	/* which is better, to lock once around the whole loop, or
+	 ** to lock for each call to remove_journal_hash?
+	 */
+	while (cn) {
+		if (cn->blocknr != 0) {
+			if (debug) {
+				reiserfs_warning(p_s_sb,
+						 "block %u, bh is %d, state %ld",
+						 cn->blocknr, cn->bh ? 1 : 0,
+						 cn->state);
+			}
+			cn->state = 0;
+			remove_journal_hash(p_s_sb, journal->j_list_hash_table,
+					    jl, cn->blocknr, 1);
+		}
+		last = cn;
+		cn = cn->next;
+		free_cnode(p_s_sb, last);
+	}
+	jl->j_realblock = NULL;
 }
 
 /*
@@ -1122,98 +1195,107 @@ static void remove_all_from_journal_list(struct super_block *p_s_sb, struct reis
 ** called by flush_journal_list, before it calls remove_all_from_journal_list
 **
 */
-static int _update_journal_header_block(struct super_block *p_s_sb, unsigned long offset, unsigned long trans_id) {
-  struct reiserfs_journal_header *jh ;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+static int _update_journal_header_block(struct super_block *p_s_sb,
+					unsigned long offset,
+					unsigned long trans_id)
+{
+	struct reiserfs_journal_header *jh;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 
-  if (reiserfs_is_journal_aborted (journal))
-    return -EIO;
+	if (reiserfs_is_journal_aborted(journal))
+		return -EIO;
 
-  if (trans_id >= journal->j_last_flush_trans_id) {
-    if (buffer_locked((journal->j_header_bh)))  {
-      wait_on_buffer((journal->j_header_bh)) ;
-      if (unlikely (!buffer_uptodate(journal->j_header_bh))) {
+	if (trans_id >= journal->j_last_flush_trans_id) {
+		if (buffer_locked((journal->j_header_bh))) {
+			wait_on_buffer((journal->j_header_bh));
+			if (unlikely(!buffer_uptodate(journal->j_header_bh))) {
 #ifdef CONFIG_REISERFS_CHECK
-        reiserfs_warning (p_s_sb, "journal-699: buffer write failed") ;
+				reiserfs_warning(p_s_sb,
+						 "journal-699: buffer write failed");
 #endif
-        return -EIO;
-      }
-    }
-    journal->j_last_flush_trans_id = trans_id ;
-    journal->j_first_unflushed_offset = offset ;
-    jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data) ;
-    jh->j_last_flush_trans_id = cpu_to_le32(trans_id) ;
-    jh->j_first_unflushed_offset = cpu_to_le32(offset) ;
-    jh->j_mount_id = cpu_to_le32(journal->j_mount_id) ;
-
-    if (reiserfs_barrier_flush(p_s_sb)) {
-	int ret;
-	lock_buffer(journal->j_header_bh);
-	ret = submit_barrier_buffer(journal->j_header_bh);
-	if (ret == -EOPNOTSUPP) {
-	    set_buffer_uptodate(journal->j_header_bh);
-	    disable_barrier(p_s_sb);
-	    goto sync;
-	}
-	wait_on_buffer(journal->j_header_bh);
-	check_barrier_completion(p_s_sb, journal->j_header_bh);
-    } else {
-sync:
-	set_buffer_dirty(journal->j_header_bh) ;
-	sync_dirty_buffer(journal->j_header_bh) ;
-    }
-    if (!buffer_uptodate(journal->j_header_bh)) {
-      reiserfs_warning (p_s_sb, "journal-837: IO error during journal replay");
-      return -EIO ;
-    }
-  }
-  return 0 ;
-}
-
-static int update_journal_header_block(struct super_block *p_s_sb, 
-                                       unsigned long offset, 
-				       unsigned long trans_id) {
-    return _update_journal_header_block(p_s_sb, offset, trans_id);
+				return -EIO;
+			}
+		}
+		journal->j_last_flush_trans_id = trans_id;
+		journal->j_first_unflushed_offset = offset;
+		jh = (struct reiserfs_journal_header *)(journal->j_header_bh->
+							b_data);
+		jh->j_last_flush_trans_id = cpu_to_le32(trans_id);
+		jh->j_first_unflushed_offset = cpu_to_le32(offset);
+		jh->j_mount_id = cpu_to_le32(journal->j_mount_id);
+
+		if (reiserfs_barrier_flush(p_s_sb)) {
+			int ret;
+			lock_buffer(journal->j_header_bh);
+			ret = submit_barrier_buffer(journal->j_header_bh);
+			if (ret == -EOPNOTSUPP) {
+				set_buffer_uptodate(journal->j_header_bh);
+				disable_barrier(p_s_sb);
+				goto sync;
+			}
+			wait_on_buffer(journal->j_header_bh);
+			check_barrier_completion(p_s_sb, journal->j_header_bh);
+		} else {
+		      sync:
+			set_buffer_dirty(journal->j_header_bh);
+			sync_dirty_buffer(journal->j_header_bh);
+		}
+		if (!buffer_uptodate(journal->j_header_bh)) {
+			reiserfs_warning(p_s_sb,
+					 "journal-837: IO error during journal replay");
+			return -EIO;
+		}
+	}
+	return 0;
+}
+
+static int update_journal_header_block(struct super_block *p_s_sb,
+				       unsigned long offset,
+				       unsigned long trans_id)
+{
+	return _update_journal_header_block(p_s_sb, offset, trans_id);
 }
+
 /* 
 ** flush any and all journal lists older than you are 
 ** can only be called from flush_journal_list
 */
 static int flush_older_journal_lists(struct super_block *p_s_sb,
-                                     struct reiserfs_journal_list *jl)
-{
-    struct list_head *entry;
-    struct reiserfs_journal_list *other_jl ;
-    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-    unsigned long trans_id = jl->j_trans_id;
-
-    /* we know we are the only ones flushing things, no extra race
-     * protection is required.
-     */
-restart:
-    entry = journal->j_journal_list.next;
-    /* Did we wrap? */
-    if (entry == &journal->j_journal_list)
-        return 0;
-    other_jl = JOURNAL_LIST_ENTRY(entry);
-    if (other_jl->j_trans_id < trans_id) {
-        BUG_ON (other_jl->j_refcount <= 0);
-	/* do not flush all */
-	flush_journal_list(p_s_sb, other_jl, 0) ;
-
-	/* other_jl is now deleted from the list */
-	goto restart;
-    }
-    return 0 ;
+				     struct reiserfs_journal_list *jl)
+{
+	struct list_head *entry;
+	struct reiserfs_journal_list *other_jl;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	unsigned long trans_id = jl->j_trans_id;
+
+	/* we know we are the only ones flushing things, no extra race
+	 * protection is required.
+	 */
+      restart:
+	entry = journal->j_journal_list.next;
+	/* Did we wrap? */
+	if (entry == &journal->j_journal_list)
+		return 0;
+	other_jl = JOURNAL_LIST_ENTRY(entry);
+	if (other_jl->j_trans_id < trans_id) {
+		BUG_ON(other_jl->j_refcount <= 0);
+		/* do not flush all */
+		flush_journal_list(p_s_sb, other_jl, 0);
+
+		/* other_jl is now deleted from the list */
+		goto restart;
+	}
+	return 0;
 }
 
 static void del_from_work_list(struct super_block *s,
-                               struct reiserfs_journal_list *jl) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    if (!list_empty(&jl->j_working_list)) {
-	list_del_init(&jl->j_working_list);
-	journal->j_num_work_lists--;
-    }
+			       struct reiserfs_journal_list *jl)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	if (!list_empty(&jl->j_working_list)) {
+		list_del_init(&jl->j_working_list);
+		journal->j_num_work_lists--;
+	}
 }
 
 /* flush a journal list, both commit and real blocks
@@ -1225,439 +1307,461 @@ static void del_from_work_list(struct super_block *s,
 ** and the journal is locked.  That means it can only be called from 
 ** do_journal_end, or by journal_release
 */
-static int flush_journal_list(struct super_block *s, 
-                              struct reiserfs_journal_list *jl, int flushall) {
-  struct reiserfs_journal_list *pjl ;
-  struct reiserfs_journal_cnode *cn, *last ;
-  int count ;
-  int was_jwait = 0 ;
-  int was_dirty = 0 ;
-  struct buffer_head *saved_bh ; 
-  unsigned long j_len_saved = jl->j_len ;
-  struct reiserfs_journal *journal = SB_JOURNAL (s);
-  int err = 0;
-
-  BUG_ON (j_len_saved <= 0);
-
-  if (atomic_read(&journal->j_wcount) != 0) {
-    reiserfs_warning(s, "clm-2048: flush_journal_list called with wcount %d",
-                      atomic_read(&journal->j_wcount)) ;
-  }
-  BUG_ON (jl->j_trans_id == 0);
-
-  /* if flushall == 0, the lock is already held */
-  if (flushall) {
-      down(&journal->j_flush_sem);
-  } else if (!down_trylock(&journal->j_flush_sem)) {
-      BUG();
-  }
-
-  count = 0 ;
-  if (j_len_saved > journal->j_trans_max) {
-    reiserfs_panic(s, "journal-715: flush_journal_list, length is %lu, trans id %lu\n", j_len_saved, jl->j_trans_id);
-    return 0 ;
-  }
-
-  get_fs_excl();
-
-  /* if all the work is already done, get out of here */
-  if (atomic_read(&(jl->j_nonzerolen)) <= 0 && 
-      atomic_read(&(jl->j_commit_left)) <= 0) {
-    goto flush_older_and_return ;
-  } 
-
-  /* start by putting the commit list on disk.  This will also flush 
-  ** the commit lists of any olders transactions
-  */
-  flush_commit_list(s, jl, 1) ;
-
-  if (!(jl->j_state & LIST_DIRTY) && !reiserfs_is_journal_aborted (journal))
-      BUG();
-
-  /* are we done now? */
-  if (atomic_read(&(jl->j_nonzerolen)) <= 0 && 
-      atomic_read(&(jl->j_commit_left)) <= 0) {
-    goto flush_older_and_return ;
-  }
-
-  /* loop through each cnode, see if we need to write it, 
-  ** or wait on a more recent transaction, or just ignore it 
-  */
-  if (atomic_read(&(journal->j_wcount)) != 0) {
-    reiserfs_panic(s, "journal-844: panic journal list is flushing, wcount is not 0\n") ;
-  }
-  cn = jl->j_realblock ;
-  while(cn) {
-    was_jwait = 0 ;
-    was_dirty = 0 ;
-    saved_bh = NULL ;
-    /* blocknr of 0 is no longer in the hash, ignore it */
-    if (cn->blocknr == 0) {
-      goto free_cnode ;
-    }
-
-    /* This transaction failed commit. Don't write out to the disk */
-    if (!(jl->j_state & LIST_DIRTY))
-        goto free_cnode;
-
-    pjl = find_newer_jl_for_cn(cn) ;
-    /* the order is important here.  We check pjl to make sure we
-    ** don't clear BH_JDirty_wait if we aren't the one writing this
-    ** block to disk
-    */
-    if (!pjl && cn->bh) {
-      saved_bh = cn->bh ;
-
-      /* we do this to make sure nobody releases the buffer while 
-      ** we are working with it 
-      */
-      get_bh(saved_bh) ;
-
-      if (buffer_journal_dirty(saved_bh)) {
-        BUG_ON (!can_dirty (cn));
-        was_jwait = 1 ;
-        was_dirty = 1 ;
-      } else if (can_dirty(cn)) {
-        /* everything with !pjl && jwait should be writable */
-	BUG();
-      }
-    }
-
-    /* if someone has this block in a newer transaction, just make
-    ** sure they are commited, and don't try writing it to disk
-    */
-    if (pjl) {
-      if (atomic_read(&pjl->j_commit_left))
-        flush_commit_list(s, pjl, 1) ;
-      goto free_cnode ;
-    }
-
-    /* bh == NULL when the block got to disk on its own, OR, 
-    ** the block got freed in a future transaction 
-    */
-    if (saved_bh == NULL) {
-      goto free_cnode ;
-    }
-
-    /* this should never happen.  kupdate_one_transaction has this list
-    ** locked while it works, so we should never see a buffer here that
-    ** is not marked JDirty_wait
-    */
-    if ((!was_jwait) && !buffer_locked(saved_bh)) {
-	reiserfs_warning (s, "journal-813: BAD! buffer %llu %cdirty %cjwait, "
-			  "not in a newer tranasction",
-			  (unsigned long long)saved_bh->b_blocknr,
-			  was_dirty ? ' ' : '!', was_jwait ? ' ' : '!') ;
-    }
-    if (was_dirty) { 
-      /* we inc again because saved_bh gets decremented at free_cnode */
-      get_bh(saved_bh) ;
-      set_bit(BLOCK_NEEDS_FLUSH, &cn->state) ;
-      lock_buffer(saved_bh);
-      BUG_ON (cn->blocknr != saved_bh->b_blocknr);
-      if (buffer_dirty(saved_bh))
-        submit_logged_buffer(saved_bh) ;
-      else
-        unlock_buffer(saved_bh);
-      count++ ;
-    } else {
-      reiserfs_warning (s, "clm-2082: Unable to flush buffer %llu in %s",
-                        (unsigned long long)saved_bh->b_blocknr, __FUNCTION__);
-    }
-free_cnode:
-    last = cn ;
-    cn = cn->next ;
-    if (saved_bh) {
-      /* we incremented this to keep others from taking the buffer head away */
-      put_bh(saved_bh) ;
-      if (atomic_read(&(saved_bh->b_count)) < 0) {
-        reiserfs_warning (s, "journal-945: saved_bh->b_count < 0");
-      }
-    }
-  }
-  if (count > 0) {
-    cn = jl->j_realblock ;
-    while(cn) {
-      if (test_bit(BLOCK_NEEDS_FLUSH, &cn->state)) {
-	if (!cn->bh) {
-	  reiserfs_panic(s, "journal-1011: cn->bh is NULL\n") ;
-	}
-	wait_on_buffer(cn->bh) ;
-	if (!cn->bh) {
-	  reiserfs_panic(s, "journal-1012: cn->bh is NULL\n") ;
-	}
-	if (unlikely (!buffer_uptodate(cn->bh))) {
-#ifdef CONFIG_REISERFS_CHECK
-	  reiserfs_warning(s, "journal-949: buffer write failed\n") ;
-#endif
-          err = -EIO;
-  	}
-	/* note, we must clear the JDirty_wait bit after the up to date
-	** check, otherwise we race against our flushpage routine
-	*/
-        BUG_ON (!test_clear_buffer_journal_dirty (cn->bh));
-
-        /* undo the inc from journal_mark_dirty */
-	put_bh(cn->bh) ;
-        brelse(cn->bh) ;
-      }
-      cn = cn->next ;
-    }
-  }
-
-  if (err)
-    reiserfs_abort (s, -EIO, "Write error while pushing transaction to disk in %s", __FUNCTION__);
-flush_older_and_return:
-
-
-  /* before we can update the journal header block, we _must_ flush all 
-  ** real blocks from all older transactions to disk.  This is because
-  ** once the header block is updated, this transaction will not be
-  ** replayed after a crash
-  */
-  if (flushall) {
-    flush_older_journal_lists(s, jl);
-  } 
-  
-  err = journal->j_errno;
-  /* before we can remove everything from the hash tables for this 
-  ** transaction, we must make sure it can never be replayed
-  **
-  ** since we are only called from do_journal_end, we know for sure there
-  ** are no allocations going on while we are flushing journal lists.  So,
-  ** we only need to update the journal header block for the last list
-  ** being flushed
-  */
-  if (!err && flushall) {
-    err = update_journal_header_block(s, (jl->j_start + jl->j_len + 2) % SB_ONDISK_JOURNAL_SIZE(s), jl->j_trans_id) ;
-    if (err)
-        reiserfs_abort (s, -EIO, "Write error while updating journal header in %s", __FUNCTION__);
-  }
-  remove_all_from_journal_list(s, jl, 0) ;
-  list_del_init(&jl->j_list);
-  journal->j_num_lists--;
-  del_from_work_list(s, jl);
-
-  if (journal->j_last_flush_id != 0 &&
-     (jl->j_trans_id - journal->j_last_flush_id) != 1) {
-      reiserfs_warning(s, "clm-2201: last flush %lu, current %lu",
-                       journal->j_last_flush_id,
-		       jl->j_trans_id);
-  }
-  journal->j_last_flush_id = jl->j_trans_id;
-
-  /* not strictly required since we are freeing the list, but it should
-   * help find code using dead lists later on
-   */
-  jl->j_len = 0 ;
-  atomic_set(&(jl->j_nonzerolen), 0) ;
-  jl->j_start = 0 ;
-  jl->j_realblock = NULL ;
-  jl->j_commit_bh = NULL ;
-  jl->j_trans_id = 0 ;
-  jl->j_state = 0;
-  put_journal_list(s, jl);
-  if (flushall)
-    up(&journal->j_flush_sem);
-  put_fs_excl();
-  return err ;
-} 
-
-static int write_one_transaction(struct super_block *s,
-                                 struct reiserfs_journal_list *jl,
-				 struct buffer_chunk *chunk)
+static int flush_journal_list(struct super_block *s,
+			      struct reiserfs_journal_list *jl, int flushall)
 {
-    struct reiserfs_journal_cnode *cn;
-    int ret = 0 ;
-
-    jl->j_state |= LIST_TOUCHED;
-    del_from_work_list(s, jl);
-    if (jl->j_len == 0 || atomic_read(&jl->j_nonzerolen) == 0) {
-        return 0;
-    }
-
-    cn = jl->j_realblock ;
-    while(cn) {
-        /* if the blocknr == 0, this has been cleared from the hash,
-        ** skip it
-        */
-        if (cn->blocknr == 0) {
-            goto next ;
-        }
-        if (cn->bh && can_dirty(cn) && buffer_dirty(cn->bh)) {
-	    struct buffer_head *tmp_bh;
-	    /* we can race against journal_mark_freed when we try
-	     * to lock_buffer(cn->bh), so we have to inc the buffer
-	     * count, and recheck things after locking
-	     */
-	    tmp_bh = cn->bh;
-	    get_bh(tmp_bh);
-	    lock_buffer(tmp_bh);
-	    if (cn->bh && can_dirty(cn) && buffer_dirty(tmp_bh)) {
-		if (!buffer_journal_dirty(tmp_bh) ||
-		    buffer_journal_prepared(tmp_bh))
-		    BUG();
-		add_to_chunk(chunk, tmp_bh, NULL, write_chunk);
-		ret++;
-	    } else {
-		/* note, cn->bh might be null now */
-		unlock_buffer(tmp_bh);
-	    }
-	    put_bh(tmp_bh);
-        }
-next:
-        cn = cn->next ;
-	cond_resched();
-    }
-    return ret ;
-}
+	struct reiserfs_journal_list *pjl;
+	struct reiserfs_journal_cnode *cn, *last;
+	int count;
+	int was_jwait = 0;
+	int was_dirty = 0;
+	struct buffer_head *saved_bh;
+	unsigned long j_len_saved = jl->j_len;
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	int err = 0;
+
+	BUG_ON(j_len_saved <= 0);
+
+	if (atomic_read(&journal->j_wcount) != 0) {
+		reiserfs_warning(s,
+				 "clm-2048: flush_journal_list called with wcount %d",
+				 atomic_read(&journal->j_wcount));
+	}
+	BUG_ON(jl->j_trans_id == 0);
 
-/* used by flush_commit_list */
-static int dirty_one_transaction(struct super_block *s,
-                                 struct reiserfs_journal_list *jl)
-{
-    struct reiserfs_journal_cnode *cn;
-    struct reiserfs_journal_list *pjl;
-    int ret = 0 ;
-
-    jl->j_state |= LIST_DIRTY;
-    cn = jl->j_realblock ;
-    while(cn) {
-        /* look for a more recent transaction that logged this
-        ** buffer.  Only the most recent transaction with a buffer in
-        ** it is allowed to send that buffer to disk
-        */
-	pjl = find_newer_jl_for_cn(cn) ;
-        if (!pjl && cn->blocknr && cn->bh && buffer_journal_dirty(cn->bh))
-	{
-	    BUG_ON (!can_dirty(cn));
-	    /* if the buffer is prepared, it will either be logged
-	     * or restored.  If restored, we need to make sure
-	     * it actually gets marked dirty
-	     */
-            clear_buffer_journal_new (cn->bh);
-            if (buffer_journal_prepared (cn->bh)) {
-                set_buffer_journal_restore_dirty (cn->bh);
-	    } else {
-                set_buffer_journal_test (cn->bh);
-	        mark_buffer_dirty(cn->bh);
-	    }
-        } 
-        cn = cn->next ;
-    }
-    return ret ;
-}
+	/* if flushall == 0, the lock is already held */
+	if (flushall) {
+		down(&journal->j_flush_sem);
+	} else if (!down_trylock(&journal->j_flush_sem)) {
+		BUG();
+	}
 
-static int kupdate_transactions(struct super_block *s,
-                                   struct reiserfs_journal_list *jl,
-				   struct reiserfs_journal_list **next_jl,
-				   unsigned long *next_trans_id,
-				   int num_blocks,
-				   int num_trans) {
-    int ret = 0;
-    int written = 0 ;
-    int transactions_flushed = 0;
-    unsigned long orig_trans_id = jl->j_trans_id;
-    struct buffer_chunk chunk;
-    struct list_head *entry;
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    chunk.nr = 0;
-
-    down(&journal->j_flush_sem);
-    if (!journal_list_still_alive(s, orig_trans_id)) {
-	goto done;
-    }
-
-    /* we've got j_flush_sem held, nobody is going to delete any
-     * of these lists out from underneath us
-     */
-    while((num_trans && transactions_flushed < num_trans) ||
-          (!num_trans && written < num_blocks)) {
-
-	if (jl->j_len == 0 || (jl->j_state & LIST_TOUCHED) ||
-	    atomic_read(&jl->j_commit_left) || !(jl->j_state & LIST_DIRTY))
-	{
-	    del_from_work_list(s, jl);
-	    break;
-	}
-	ret = write_one_transaction(s, jl, &chunk);
-
-	if (ret < 0)
-	    goto done;
-	transactions_flushed++;
-	written += ret;
-	entry = jl->j_list.next;
-
-	/* did we wrap? */
-	if (entry == &journal->j_journal_list) {
-	    break;
-        }
-	jl = JOURNAL_LIST_ENTRY(entry);
-
-	/* don't bother with older transactions */
-	if (jl->j_trans_id <= orig_trans_id)
-	    break;
-    }
-    if (chunk.nr) {
-        write_chunk(&chunk);
-    }
-
-done:
-    up(&journal->j_flush_sem);
-    return ret;
-}
+	count = 0;
+	if (j_len_saved > journal->j_trans_max) {
+		reiserfs_panic(s,
+			       "journal-715: flush_journal_list, length is %lu, trans id %lu\n",
+			       j_len_saved, jl->j_trans_id);
+		return 0;
+	}
 
-/* for o_sync and fsync heavy applications, they tend to use
-** all the journa list slots with tiny transactions.  These
-** trigger lots and lots of calls to update the header block, which
-** adds seeks and slows things down.
-**
-** This function tries to clear out a large chunk of the journal lists
-** at once, which makes everything faster since only the newest journal
+	get_fs_excl();
+
+	/* if all the work is already done, get out of here */
+	if (atomic_read(&(jl->j_nonzerolen)) <= 0 &&
+	    atomic_read(&(jl->j_commit_left)) <= 0) {
+		goto flush_older_and_return;
+	}
+
+	/* start by putting the commit list on disk.  This will also flush 
+	 ** the commit lists of any olders transactions
+	 */
+	flush_commit_list(s, jl, 1);
+
+	if (!(jl->j_state & LIST_DIRTY)
+	    && !reiserfs_is_journal_aborted(journal))
+		BUG();
+
+	/* are we done now? */
+	if (atomic_read(&(jl->j_nonzerolen)) <= 0 &&
+	    atomic_read(&(jl->j_commit_left)) <= 0) {
+		goto flush_older_and_return;
+	}
+
+	/* loop through each cnode, see if we need to write it, 
+	 ** or wait on a more recent transaction, or just ignore it 
+	 */
+	if (atomic_read(&(journal->j_wcount)) != 0) {
+		reiserfs_panic(s,
+			       "journal-844: panic journal list is flushing, wcount is not 0\n");
+	}
+	cn = jl->j_realblock;
+	while (cn) {
+		was_jwait = 0;
+		was_dirty = 0;
+		saved_bh = NULL;
+		/* blocknr of 0 is no longer in the hash, ignore it */
+		if (cn->blocknr == 0) {
+			goto free_cnode;
+		}
+
+		/* This transaction failed commit. Don't write out to the disk */
+		if (!(jl->j_state & LIST_DIRTY))
+			goto free_cnode;
+
+		pjl = find_newer_jl_for_cn(cn);
+		/* the order is important here.  We check pjl to make sure we
+		 ** don't clear BH_JDirty_wait if we aren't the one writing this
+		 ** block to disk
+		 */
+		if (!pjl && cn->bh) {
+			saved_bh = cn->bh;
+
+			/* we do this to make sure nobody releases the buffer while 
+			 ** we are working with it 
+			 */
+			get_bh(saved_bh);
+
+			if (buffer_journal_dirty(saved_bh)) {
+				BUG_ON(!can_dirty(cn));
+				was_jwait = 1;
+				was_dirty = 1;
+			} else if (can_dirty(cn)) {
+				/* everything with !pjl && jwait should be writable */
+				BUG();
+			}
+		}
+
+		/* if someone has this block in a newer transaction, just make
+		 ** sure they are commited, and don't try writing it to disk
+		 */
+		if (pjl) {
+			if (atomic_read(&pjl->j_commit_left))
+				flush_commit_list(s, pjl, 1);
+			goto free_cnode;
+		}
+
+		/* bh == NULL when the block got to disk on its own, OR, 
+		 ** the block got freed in a future transaction 
+		 */
+		if (saved_bh == NULL) {
+			goto free_cnode;
+		}
+
+		/* this should never happen.  kupdate_one_transaction has this list
+		 ** locked while it works, so we should never see a buffer here that
+		 ** is not marked JDirty_wait
+		 */
+		if ((!was_jwait) && !buffer_locked(saved_bh)) {
+			reiserfs_warning(s,
+					 "journal-813: BAD! buffer %llu %cdirty %cjwait, "
+					 "not in a newer tranasction",
+					 (unsigned long long)saved_bh->
+					 b_blocknr, was_dirty ? ' ' : '!',
+					 was_jwait ? ' ' : '!');
+		}
+		if (was_dirty) {
+			/* we inc again because saved_bh gets decremented at free_cnode */
+			get_bh(saved_bh);
+			set_bit(BLOCK_NEEDS_FLUSH, &cn->state);
+			lock_buffer(saved_bh);
+			BUG_ON(cn->blocknr != saved_bh->b_blocknr);
+			if (buffer_dirty(saved_bh))
+				submit_logged_buffer(saved_bh);
+			else
+				unlock_buffer(saved_bh);
+			count++;
+		} else {
+			reiserfs_warning(s,
+					 "clm-2082: Unable to flush buffer %llu in %s",
+					 (unsigned long long)saved_bh->
+					 b_blocknr, __FUNCTION__);
+		}
+	      free_cnode:
+		last = cn;
+		cn = cn->next;
+		if (saved_bh) {
+			/* we incremented this to keep others from taking the buffer head away */
+			put_bh(saved_bh);
+			if (atomic_read(&(saved_bh->b_count)) < 0) {
+				reiserfs_warning(s,
+						 "journal-945: saved_bh->b_count < 0");
+			}
+		}
+	}
+	if (count > 0) {
+		cn = jl->j_realblock;
+		while (cn) {
+			if (test_bit(BLOCK_NEEDS_FLUSH, &cn->state)) {
+				if (!cn->bh) {
+					reiserfs_panic(s,
+						       "journal-1011: cn->bh is NULL\n");
+				}
+				wait_on_buffer(cn->bh);
+				if (!cn->bh) {
+					reiserfs_panic(s,
+						       "journal-1012: cn->bh is NULL\n");
+				}
+				if (unlikely(!buffer_uptodate(cn->bh))) {
+#ifdef CONFIG_REISERFS_CHECK
+					reiserfs_warning(s,
+							 "journal-949: buffer write failed\n");
+#endif
+					err = -EIO;
+				}
+				/* note, we must clear the JDirty_wait bit after the up to date
+				 ** check, otherwise we race against our flushpage routine
+				 */
+				BUG_ON(!test_clear_buffer_journal_dirty
+				       (cn->bh));
+
+				/* undo the inc from journal_mark_dirty */
+				put_bh(cn->bh);
+				brelse(cn->bh);
+			}
+			cn = cn->next;
+		}
+	}
+
+	if (err)
+		reiserfs_abort(s, -EIO,
+			       "Write error while pushing transaction to disk in %s",
+			       __FUNCTION__);
+      flush_older_and_return:
+
+	/* before we can update the journal header block, we _must_ flush all 
+	 ** real blocks from all older transactions to disk.  This is because
+	 ** once the header block is updated, this transaction will not be
+	 ** replayed after a crash
+	 */
+	if (flushall) {
+		flush_older_journal_lists(s, jl);
+	}
+
+	err = journal->j_errno;
+	/* before we can remove everything from the hash tables for this 
+	 ** transaction, we must make sure it can never be replayed
+	 **
+	 ** since we are only called from do_journal_end, we know for sure there
+	 ** are no allocations going on while we are flushing journal lists.  So,
+	 ** we only need to update the journal header block for the last list
+	 ** being flushed
+	 */
+	if (!err && flushall) {
+		err =
+		    update_journal_header_block(s,
+						(jl->j_start + jl->j_len +
+						 2) % SB_ONDISK_JOURNAL_SIZE(s),
+						jl->j_trans_id);
+		if (err)
+			reiserfs_abort(s, -EIO,
+				       "Write error while updating journal header in %s",
+				       __FUNCTION__);
+	}
+	remove_all_from_journal_list(s, jl, 0);
+	list_del_init(&jl->j_list);
+	journal->j_num_lists--;
+	del_from_work_list(s, jl);
+
+	if (journal->j_last_flush_id != 0 &&
+	    (jl->j_trans_id - journal->j_last_flush_id) != 1) {
+		reiserfs_warning(s, "clm-2201: last flush %lu, current %lu",
+				 journal->j_last_flush_id, jl->j_trans_id);
+	}
+	journal->j_last_flush_id = jl->j_trans_id;
+
+	/* not strictly required since we are freeing the list, but it should
+	 * help find code using dead lists later on
+	 */
+	jl->j_len = 0;
+	atomic_set(&(jl->j_nonzerolen), 0);
+	jl->j_start = 0;
+	jl->j_realblock = NULL;
+	jl->j_commit_bh = NULL;
+	jl->j_trans_id = 0;
+	jl->j_state = 0;
+	put_journal_list(s, jl);
+	if (flushall)
+		up(&journal->j_flush_sem);
+	put_fs_excl();
+	return err;
+}
+
+static int write_one_transaction(struct super_block *s,
+				 struct reiserfs_journal_list *jl,
+				 struct buffer_chunk *chunk)
+{
+	struct reiserfs_journal_cnode *cn;
+	int ret = 0;
+
+	jl->j_state |= LIST_TOUCHED;
+	del_from_work_list(s, jl);
+	if (jl->j_len == 0 || atomic_read(&jl->j_nonzerolen) == 0) {
+		return 0;
+	}
+
+	cn = jl->j_realblock;
+	while (cn) {
+		/* if the blocknr == 0, this has been cleared from the hash,
+		 ** skip it
+		 */
+		if (cn->blocknr == 0) {
+			goto next;
+		}
+		if (cn->bh && can_dirty(cn) && buffer_dirty(cn->bh)) {
+			struct buffer_head *tmp_bh;
+			/* we can race against journal_mark_freed when we try
+			 * to lock_buffer(cn->bh), so we have to inc the buffer
+			 * count, and recheck things after locking
+			 */
+			tmp_bh = cn->bh;
+			get_bh(tmp_bh);
+			lock_buffer(tmp_bh);
+			if (cn->bh && can_dirty(cn) && buffer_dirty(tmp_bh)) {
+				if (!buffer_journal_dirty(tmp_bh) ||
+				    buffer_journal_prepared(tmp_bh))
+					BUG();
+				add_to_chunk(chunk, tmp_bh, NULL, write_chunk);
+				ret++;
+			} else {
+				/* note, cn->bh might be null now */
+				unlock_buffer(tmp_bh);
+			}
+			put_bh(tmp_bh);
+		}
+	      next:
+		cn = cn->next;
+		cond_resched();
+	}
+	return ret;
+}
+
+/* used by flush_commit_list */
+static int dirty_one_transaction(struct super_block *s,
+				 struct reiserfs_journal_list *jl)
+{
+	struct reiserfs_journal_cnode *cn;
+	struct reiserfs_journal_list *pjl;
+	int ret = 0;
+
+	jl->j_state |= LIST_DIRTY;
+	cn = jl->j_realblock;
+	while (cn) {
+		/* look for a more recent transaction that logged this
+		 ** buffer.  Only the most recent transaction with a buffer in
+		 ** it is allowed to send that buffer to disk
+		 */
+		pjl = find_newer_jl_for_cn(cn);
+		if (!pjl && cn->blocknr && cn->bh
+		    && buffer_journal_dirty(cn->bh)) {
+			BUG_ON(!can_dirty(cn));
+			/* if the buffer is prepared, it will either be logged
+			 * or restored.  If restored, we need to make sure
+			 * it actually gets marked dirty
+			 */
+			clear_buffer_journal_new(cn->bh);
+			if (buffer_journal_prepared(cn->bh)) {
+				set_buffer_journal_restore_dirty(cn->bh);
+			} else {
+				set_buffer_journal_test(cn->bh);
+				mark_buffer_dirty(cn->bh);
+			}
+		}
+		cn = cn->next;
+	}
+	return ret;
+}
+
+static int kupdate_transactions(struct super_block *s,
+				struct reiserfs_journal_list *jl,
+				struct reiserfs_journal_list **next_jl,
+				unsigned long *next_trans_id,
+				int num_blocks, int num_trans)
+{
+	int ret = 0;
+	int written = 0;
+	int transactions_flushed = 0;
+	unsigned long orig_trans_id = jl->j_trans_id;
+	struct buffer_chunk chunk;
+	struct list_head *entry;
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	chunk.nr = 0;
+
+	down(&journal->j_flush_sem);
+	if (!journal_list_still_alive(s, orig_trans_id)) {
+		goto done;
+	}
+
+	/* we've got j_flush_sem held, nobody is going to delete any
+	 * of these lists out from underneath us
+	 */
+	while ((num_trans && transactions_flushed < num_trans) ||
+	       (!num_trans && written < num_blocks)) {
+
+		if (jl->j_len == 0 || (jl->j_state & LIST_TOUCHED) ||
+		    atomic_read(&jl->j_commit_left)
+		    || !(jl->j_state & LIST_DIRTY)) {
+			del_from_work_list(s, jl);
+			break;
+		}
+		ret = write_one_transaction(s, jl, &chunk);
+
+		if (ret < 0)
+			goto done;
+		transactions_flushed++;
+		written += ret;
+		entry = jl->j_list.next;
+
+		/* did we wrap? */
+		if (entry == &journal->j_journal_list) {
+			break;
+		}
+		jl = JOURNAL_LIST_ENTRY(entry);
+
+		/* don't bother with older transactions */
+		if (jl->j_trans_id <= orig_trans_id)
+			break;
+	}
+	if (chunk.nr) {
+		write_chunk(&chunk);
+	}
+
+      done:
+	up(&journal->j_flush_sem);
+	return ret;
+}
+
+/* for o_sync and fsync heavy applications, they tend to use
+** all the journa list slots with tiny transactions.  These
+** trigger lots and lots of calls to update the header block, which
+** adds seeks and slows things down.
+**
+** This function tries to clear out a large chunk of the journal lists
+** at once, which makes everything faster since only the newest journal
 ** list updates the header block
 */
 static int flush_used_journal_lists(struct super_block *s,
-                                    struct reiserfs_journal_list *jl) {
-    unsigned long len = 0;
-    unsigned long cur_len;
-    int ret;
-    int i;
-    int limit = 256;
-    struct reiserfs_journal_list *tjl;
-    struct reiserfs_journal_list *flush_jl;
-    unsigned long trans_id;
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-
-    flush_jl = tjl = jl;
-
-    /* in data logging mode, try harder to flush a lot of blocks */
-    if (reiserfs_data_log(s))
-	limit = 1024;
-    /* flush for 256 transactions or limit blocks, whichever comes first */
-    for(i = 0 ; i < 256 && len < limit ; i++) {
-	if (atomic_read(&tjl->j_commit_left) ||
-	    tjl->j_trans_id < jl->j_trans_id) {
-	    break;
-	}
-	cur_len = atomic_read(&tjl->j_nonzerolen);
-	if (cur_len > 0) {
-	    tjl->j_state &= ~LIST_TOUCHED;
-	}
-	len += cur_len;
-	flush_jl = tjl;
-	if (tjl->j_list.next == &journal->j_journal_list)
-	    break;
-	tjl = JOURNAL_LIST_ENTRY(tjl->j_list.next);
-    }
-    /* try to find a group of blocks we can flush across all the
-    ** transactions, but only bother if we've actually spanned
-    ** across multiple lists
-    */
-    if (flush_jl != jl) {
-        ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
-    }
-    flush_journal_list(s, flush_jl, 1);
-    return 0;
+				    struct reiserfs_journal_list *jl)
+{
+	unsigned long len = 0;
+	unsigned long cur_len;
+	int ret;
+	int i;
+	int limit = 256;
+	struct reiserfs_journal_list *tjl;
+	struct reiserfs_journal_list *flush_jl;
+	unsigned long trans_id;
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+
+	flush_jl = tjl = jl;
+
+	/* in data logging mode, try harder to flush a lot of blocks */
+	if (reiserfs_data_log(s))
+		limit = 1024;
+	/* flush for 256 transactions or limit blocks, whichever comes first */
+	for (i = 0; i < 256 && len < limit; i++) {
+		if (atomic_read(&tjl->j_commit_left) ||
+		    tjl->j_trans_id < jl->j_trans_id) {
+			break;
+		}
+		cur_len = atomic_read(&tjl->j_nonzerolen);
+		if (cur_len > 0) {
+			tjl->j_state &= ~LIST_TOUCHED;
+		}
+		len += cur_len;
+		flush_jl = tjl;
+		if (tjl->j_list.next == &journal->j_journal_list)
+			break;
+		tjl = JOURNAL_LIST_ENTRY(tjl->j_list.next);
+	}
+	/* try to find a group of blocks we can flush across all the
+	 ** transactions, but only bother if we've actually spanned
+	 ** across multiple lists
+	 */
+	if (flush_jl != jl) {
+		ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
+	}
+	flush_journal_list(s, flush_jl, 1);
+	return 0;
 }
 
 /*
@@ -1665,207 +1769,248 @@ static int flush_used_journal_lists(struct super_block *s,
 ** only touchs the hnext and hprev pointers.
 */
 void remove_journal_hash(struct super_block *sb,
-			struct reiserfs_journal_cnode **table,
-			struct reiserfs_journal_list *jl,
-			unsigned long block, int remove_freed)
-{
-  struct reiserfs_journal_cnode *cur ;
-  struct reiserfs_journal_cnode **head ;
-
-  head= &(journal_hash(table, sb, block)) ;
-  if (!head) {
-    return ;
-  }
-  cur = *head ;
-  while(cur) {
-    if (cur->blocknr == block && cur->sb == sb && (jl == NULL || jl == cur->jlist) && 
-        (!test_bit(BLOCK_FREED, &cur->state) || remove_freed)) {
-      if (cur->hnext) {
-        cur->hnext->hprev = cur->hprev ;
-      }
-      if (cur->hprev) {
-	cur->hprev->hnext = cur->hnext ;
-      } else {
-	*head = cur->hnext ;
-      }
-      cur->blocknr = 0 ;
-      cur->sb = NULL ;
-      cur->state = 0 ;
-      if (cur->bh && cur->jlist) /* anybody who clears the cur->bh will also dec the nonzerolen */
-	atomic_dec(&(cur->jlist->j_nonzerolen)) ;
-      cur->bh = NULL ;
-      cur->jlist = NULL ;
-    } 
-    cur = cur->hnext ;
-  }
-}
-
-static void free_journal_ram(struct super_block *p_s_sb) {
-  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-  reiserfs_kfree(journal->j_current_jl,
-                 sizeof(struct reiserfs_journal_list), p_s_sb);
-  journal->j_num_lists--;
-
-  vfree(journal->j_cnode_free_orig) ;
-  free_list_bitmaps(p_s_sb, journal->j_list_bitmap) ;
-  free_bitmap_nodes(p_s_sb) ; /* must be after free_list_bitmaps */
-  if (journal->j_header_bh) {
-    brelse(journal->j_header_bh) ;
-  }
-  /* j_header_bh is on the journal dev, make sure not to release the journal
-   * dev until we brelse j_header_bh
-   */
-  release_journal_dev(p_s_sb, journal);
-  vfree(journal) ;
+			 struct reiserfs_journal_cnode **table,
+			 struct reiserfs_journal_list *jl,
+			 unsigned long block, int remove_freed)
+{
+	struct reiserfs_journal_cnode *cur;
+	struct reiserfs_journal_cnode **head;
+
+	head = &(journal_hash(table, sb, block));
+	if (!head) {
+		return;
+	}
+	cur = *head;
+	while (cur) {
+		if (cur->blocknr == block && cur->sb == sb
+		    && (jl == NULL || jl == cur->jlist)
+		    && (!test_bit(BLOCK_FREED, &cur->state) || remove_freed)) {
+			if (cur->hnext) {
+				cur->hnext->hprev = cur->hprev;
+			}
+			if (cur->hprev) {
+				cur->hprev->hnext = cur->hnext;
+			} else {
+				*head = cur->hnext;
+			}
+			cur->blocknr = 0;
+			cur->sb = NULL;
+			cur->state = 0;
+			if (cur->bh && cur->jlist)	/* anybody who clears the cur->bh will also dec the nonzerolen */
+				atomic_dec(&(cur->jlist->j_nonzerolen));
+			cur->bh = NULL;
+			cur->jlist = NULL;
+		}
+		cur = cur->hnext;
+	}
+}
+
+static void free_journal_ram(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	reiserfs_kfree(journal->j_current_jl,
+		       sizeof(struct reiserfs_journal_list), p_s_sb);
+	journal->j_num_lists--;
+
+	vfree(journal->j_cnode_free_orig);
+	free_list_bitmaps(p_s_sb, journal->j_list_bitmap);
+	free_bitmap_nodes(p_s_sb);	/* must be after free_list_bitmaps */
+	if (journal->j_header_bh) {
+		brelse(journal->j_header_bh);
+	}
+	/* j_header_bh is on the journal dev, make sure not to release the journal
+	 * dev until we brelse j_header_bh
+	 */
+	release_journal_dev(p_s_sb, journal);
+	vfree(journal);
 }
 
 /*
 ** call on unmount.  Only set error to 1 if you haven't made your way out
 ** of read_super() yet.  Any other caller must keep error at 0.
 */
-static int do_journal_release(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, int error) {
-  struct reiserfs_transaction_handle myth ;
-  int flushed = 0;
-  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-
-  /* we only want to flush out transactions if we were called with error == 0
-  */
-  if (!error && !(p_s_sb->s_flags & MS_RDONLY)) {
-    /* end the current trans */
-    BUG_ON (!th->t_trans_id);
-    do_journal_end(th, p_s_sb,10, FLUSH_ALL) ;
-
-    /* make sure something gets logged to force our way into the flush code */
-    if (!journal_join(&myth, p_s_sb, 1)) {
-        reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
-        journal_mark_dirty(&myth, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
-        do_journal_end(&myth, p_s_sb,1, FLUSH_ALL) ;
-        flushed = 1;
-    }
-  }
-
-  /* this also catches errors during the do_journal_end above */
-  if (!error && reiserfs_is_journal_aborted(journal)) {
-      memset(&myth, 0, sizeof(myth));
-      if (!journal_join_abort(&myth, p_s_sb, 1)) {
-	  reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
-	  journal_mark_dirty(&myth, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
-          do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL) ;
-      }
-  }
-
-  reiserfs_mounted_fs_count-- ;
-  /* wait for all commits to finish */
-  cancel_delayed_work(&SB_JOURNAL(p_s_sb)->j_work);
-  flush_workqueue(commit_wq);
-  if (!reiserfs_mounted_fs_count) {
-    destroy_workqueue(commit_wq);
-    commit_wq = NULL;
-  }
-
-  free_journal_ram(p_s_sb) ;
-
-  return 0 ;
+static int do_journal_release(struct reiserfs_transaction_handle *th,
+			      struct super_block *p_s_sb, int error)
+{
+	struct reiserfs_transaction_handle myth;
+	int flushed = 0;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+
+	/* we only want to flush out transactions if we were called with error == 0
+	 */
+	if (!error && !(p_s_sb->s_flags & MS_RDONLY)) {
+		/* end the current trans */
+		BUG_ON(!th->t_trans_id);
+		do_journal_end(th, p_s_sb, 10, FLUSH_ALL);
+
+		/* make sure something gets logged to force our way into the flush code */
+		if (!journal_join(&myth, p_s_sb, 1)) {
+			reiserfs_prepare_for_journal(p_s_sb,
+						     SB_BUFFER_WITH_SB(p_s_sb),
+						     1);
+			journal_mark_dirty(&myth, p_s_sb,
+					   SB_BUFFER_WITH_SB(p_s_sb));
+			do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL);
+			flushed = 1;
+		}
+	}
+
+	/* this also catches errors during the do_journal_end above */
+	if (!error && reiserfs_is_journal_aborted(journal)) {
+		memset(&myth, 0, sizeof(myth));
+		if (!journal_join_abort(&myth, p_s_sb, 1)) {
+			reiserfs_prepare_for_journal(p_s_sb,
+						     SB_BUFFER_WITH_SB(p_s_sb),
+						     1);
+			journal_mark_dirty(&myth, p_s_sb,
+					   SB_BUFFER_WITH_SB(p_s_sb));
+			do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL);
+		}
+	}
+
+	reiserfs_mounted_fs_count--;
+	/* wait for all commits to finish */
+	cancel_delayed_work(&SB_JOURNAL(p_s_sb)->j_work);
+	flush_workqueue(commit_wq);
+	if (!reiserfs_mounted_fs_count) {
+		destroy_workqueue(commit_wq);
+		commit_wq = NULL;
+	}
+
+	free_journal_ram(p_s_sb);
+
+	return 0;
 }
 
 /*
 ** call on unmount.  flush all journal trans, release all alloc'd ram
 */
-int journal_release(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb) {
-  return do_journal_release(th, p_s_sb, 0) ;
+int journal_release(struct reiserfs_transaction_handle *th,
+		    struct super_block *p_s_sb)
+{
+	return do_journal_release(th, p_s_sb, 0);
 }
+
 /*
 ** only call from an error condition inside reiserfs_read_super!
 */
-int journal_release_error(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb) {
-  return do_journal_release(th, p_s_sb, 1) ;
+int journal_release_error(struct reiserfs_transaction_handle *th,
+			  struct super_block *p_s_sb)
+{
+	return do_journal_release(th, p_s_sb, 1);
 }
 
 /* compares description block with commit block.  returns 1 if they differ, 0 if they are the same */
-static int journal_compare_desc_commit(struct super_block *p_s_sb, struct reiserfs_journal_desc *desc, 
-			               struct reiserfs_journal_commit *commit) {
-  if (get_commit_trans_id (commit) != get_desc_trans_id (desc) || 
-      get_commit_trans_len (commit) != get_desc_trans_len (desc) || 
-      get_commit_trans_len (commit) > SB_JOURNAL(p_s_sb)->j_trans_max ||
-      get_commit_trans_len (commit) <= 0 
-  ) {
-    return 1 ;
-  }
-  return 0 ;
+static int journal_compare_desc_commit(struct super_block *p_s_sb,
+				       struct reiserfs_journal_desc *desc,
+				       struct reiserfs_journal_commit *commit)
+{
+	if (get_commit_trans_id(commit) != get_desc_trans_id(desc) ||
+	    get_commit_trans_len(commit) != get_desc_trans_len(desc) ||
+	    get_commit_trans_len(commit) > SB_JOURNAL(p_s_sb)->j_trans_max ||
+	    get_commit_trans_len(commit) <= 0) {
+		return 1;
+	}
+	return 0;
 }
+
 /* returns 0 if it did not find a description block  
 ** returns -1 if it found a corrupt commit block
 ** returns 1 if both desc and commit were valid 
 */
-static int journal_transaction_is_valid(struct super_block *p_s_sb, struct buffer_head *d_bh, unsigned long *oldest_invalid_trans_id, unsigned long *newest_mount_id) {
-  struct reiserfs_journal_desc *desc ;
-  struct reiserfs_journal_commit *commit ;
-  struct buffer_head *c_bh ;
-  unsigned long offset ;
-
-  if (!d_bh)
-      return 0 ;
-
-  desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
-  if (get_desc_trans_len(desc) > 0 && !memcmp(get_journal_desc_magic (d_bh), JOURNAL_DESC_MAGIC, 8)) {
-    if (oldest_invalid_trans_id && *oldest_invalid_trans_id && get_desc_trans_id(desc) > *oldest_invalid_trans_id) {
-      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-986: transaction "
-	              "is valid returning because trans_id %d is greater than "
-		      "oldest_invalid %lu", get_desc_trans_id(desc),
-		       *oldest_invalid_trans_id);
-      return 0 ;
-    }
-    if (newest_mount_id && *newest_mount_id > get_desc_mount_id (desc)) {
-      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1087: transaction "
-                     "is valid returning because mount_id %d is less than "
-		     "newest_mount_id %lu", get_desc_mount_id (desc),
-		     *newest_mount_id) ;
-      return -1 ;
-    }
-    if ( get_desc_trans_len(desc) > SB_JOURNAL(p_s_sb)->j_trans_max ) {
-      reiserfs_warning(p_s_sb, "journal-2018: Bad transaction length %d encountered, ignoring transaction", get_desc_trans_len(desc));
-      return -1 ;
-    }
-    offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
-
-    /* ok, we have a journal description block, lets see if the transaction was valid */
-    c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
-		 ((offset + get_desc_trans_len(desc) + 1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
-    if (!c_bh)
-      return 0 ;
-    commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
-    if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
-      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, 
-                     "journal_transaction_is_valid, commit offset %ld had bad "
-		     "time %d or length %d",
-		     c_bh->b_blocknr -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
-		     get_commit_trans_id (commit), 
-		     get_commit_trans_len(commit));
-      brelse(c_bh) ;
-      if (oldest_invalid_trans_id) {
-	*oldest_invalid_trans_id = get_desc_trans_id(desc) ;
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1004: "
-		       "transaction_is_valid setting oldest invalid trans_id "
-		       "to %d", get_desc_trans_id(desc)) ;
-      }
-      return -1; 
-    }
-    brelse(c_bh) ;
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1006: found valid "
-                   "transaction start offset %llu, len %d id %d",
-		   d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-		   get_desc_trans_len(desc), get_desc_trans_id(desc)) ;
-    return 1 ;
-  } else {
-    return 0 ;
-  }
-}
-
-static void brelse_array(struct buffer_head **heads, int num) {
-  int i ;
-  for (i = 0 ; i < num ; i++) {
-    brelse(heads[i]) ;
-  }
+static int journal_transaction_is_valid(struct super_block *p_s_sb,
+					struct buffer_head *d_bh,
+					unsigned long *oldest_invalid_trans_id,
+					unsigned long *newest_mount_id)
+{
+	struct reiserfs_journal_desc *desc;
+	struct reiserfs_journal_commit *commit;
+	struct buffer_head *c_bh;
+	unsigned long offset;
+
+	if (!d_bh)
+		return 0;
+
+	desc = (struct reiserfs_journal_desc *)d_bh->b_data;
+	if (get_desc_trans_len(desc) > 0
+	    && !memcmp(get_journal_desc_magic(d_bh), JOURNAL_DESC_MAGIC, 8)) {
+		if (oldest_invalid_trans_id && *oldest_invalid_trans_id
+		    && get_desc_trans_id(desc) > *oldest_invalid_trans_id) {
+			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				       "journal-986: transaction "
+				       "is valid returning because trans_id %d is greater than "
+				       "oldest_invalid %lu",
+				       get_desc_trans_id(desc),
+				       *oldest_invalid_trans_id);
+			return 0;
+		}
+		if (newest_mount_id
+		    && *newest_mount_id > get_desc_mount_id(desc)) {
+			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				       "journal-1087: transaction "
+				       "is valid returning because mount_id %d is less than "
+				       "newest_mount_id %lu",
+				       get_desc_mount_id(desc),
+				       *newest_mount_id);
+			return -1;
+		}
+		if (get_desc_trans_len(desc) > SB_JOURNAL(p_s_sb)->j_trans_max) {
+			reiserfs_warning(p_s_sb,
+					 "journal-2018: Bad transaction length %d encountered, ignoring transaction",
+					 get_desc_trans_len(desc));
+			return -1;
+		}
+		offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+
+		/* ok, we have a journal description block, lets see if the transaction was valid */
+		c_bh =
+		    journal_bread(p_s_sb,
+				  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+				  ((offset + get_desc_trans_len(desc) +
+				    1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+		if (!c_bh)
+			return 0;
+		commit = (struct reiserfs_journal_commit *)c_bh->b_data;
+		if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
+			reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+				       "journal_transaction_is_valid, commit offset %ld had bad "
+				       "time %d or length %d",
+				       c_bh->b_blocknr -
+				       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+				       get_commit_trans_id(commit),
+				       get_commit_trans_len(commit));
+			brelse(c_bh);
+			if (oldest_invalid_trans_id) {
+				*oldest_invalid_trans_id =
+				    get_desc_trans_id(desc);
+				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+					       "journal-1004: "
+					       "transaction_is_valid setting oldest invalid trans_id "
+					       "to %d",
+					       get_desc_trans_id(desc));
+			}
+			return -1;
+		}
+		brelse(c_bh);
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			       "journal-1006: found valid "
+			       "transaction start offset %llu, len %d id %d",
+			       d_bh->b_blocknr -
+			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       get_desc_trans_len(desc),
+			       get_desc_trans_id(desc));
+		return 1;
+	} else {
+		return 0;
+	}
+}
+
+static void brelse_array(struct buffer_head **heads, int num)
+{
+	int i;
+	for (i = 0; i < num; i++) {
+		brelse(heads[i]);
+	}
 }
 
 /*
@@ -1873,149 +2018,202 @@ static void brelse_array(struct buffer_head **heads, int num) {
 ** this either reads in a replays a transaction, or returns because the transaction
 ** is invalid, or too old.
 */
-static int journal_read_transaction(struct super_block *p_s_sb, unsigned long cur_dblock, unsigned long oldest_start, 
-				    unsigned long oldest_trans_id, unsigned long newest_mount_id) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_desc *desc ;
-  struct reiserfs_journal_commit *commit ;
-  unsigned long trans_id = 0 ;
-  struct buffer_head *c_bh ;
-  struct buffer_head *d_bh ;
-  struct buffer_head **log_blocks = NULL ;
-  struct buffer_head **real_blocks = NULL ;
-  unsigned long trans_offset ;
-  int i;
-  int trans_half;
-
-  d_bh = journal_bread(p_s_sb, cur_dblock) ;
-  if (!d_bh)
-    return 1 ;
-  desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
-  trans_offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
-  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1037: "
-                 "journal_read_transaction, offset %llu, len %d mount_id %d",
-		 d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-		 get_desc_trans_len(desc), get_desc_mount_id(desc)) ;
-  if (get_desc_trans_id(desc) < oldest_trans_id) {
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1039: "
-                   "journal_read_trans skipping because %lu is too old",
-		   cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)) ;
-    brelse(d_bh) ;
-    return 1 ;
-  }
-  if (get_desc_mount_id(desc) != newest_mount_id) {
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1146: "
-                   "journal_read_trans skipping because %d is != "
-		   "newest_mount_id %lu", get_desc_mount_id(desc),
-		    newest_mount_id) ;
-    brelse(d_bh) ;
-    return 1 ;
-  }
-  c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
-		((trans_offset + get_desc_trans_len(desc) + 1) % 
-		 SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
-  if (!c_bh) {
-    brelse(d_bh) ;
-    return 1 ;
-  }
-  commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
-  if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal_read_transaction, "
-                   "commit offset %llu had bad time %d or length %d",
-		   c_bh->b_blocknr -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-		   get_commit_trans_id(commit), get_commit_trans_len(commit));
-    brelse(c_bh) ;
-    brelse(d_bh) ;
-    return 1; 
-  }
-  trans_id = get_desc_trans_id(desc) ;
-  /* now we know we've got a good transaction, and it was inside the valid time ranges */
-  log_blocks = reiserfs_kmalloc(get_desc_trans_len(desc) * sizeof(struct buffer_head *), GFP_NOFS, p_s_sb) ;
-  real_blocks = reiserfs_kmalloc(get_desc_trans_len(desc) * sizeof(struct buffer_head *), GFP_NOFS, p_s_sb) ;
-  if (!log_blocks  || !real_blocks) {
-    brelse(c_bh) ;
-    brelse(d_bh) ;
-    reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-    reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-    reiserfs_warning(p_s_sb, "journal-1169: kmalloc failed, unable to mount FS") ;
-    return -1 ;
-  }
-  /* get all the buffer heads */
-  trans_half = journal_trans_half (p_s_sb->s_blocksize) ;
-  for(i = 0 ; i < get_desc_trans_len(desc) ; i++) {
-    log_blocks[i] =  journal_getblk(p_s_sb,  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + (trans_offset + 1 + i) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
-    if (i < trans_half) {
-      real_blocks[i] = sb_getblk(p_s_sb, le32_to_cpu(desc->j_realblock[i])) ;
-    } else {
-      real_blocks[i] = sb_getblk(p_s_sb, le32_to_cpu(commit->j_realblock[i - trans_half])) ;
-    }
-    if ( real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(p_s_sb) ) {
-      reiserfs_warning(p_s_sb, "journal-1207: REPLAY FAILURE fsck required! Block to replay is outside of filesystem");
-      goto abort_replay;
-    }
-    /* make sure we don't try to replay onto log or reserved area */
-    if (is_block_in_log_or_reserved_area(p_s_sb, real_blocks[i]->b_blocknr)) {
-      reiserfs_warning(p_s_sb, "journal-1204: REPLAY FAILURE fsck required! Trying to replay onto a log block") ;
-abort_replay:
-      brelse_array(log_blocks, i) ;
-      brelse_array(real_blocks, i) ;
-      brelse(c_bh) ;
-      brelse(d_bh) ;
-      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      return -1 ;
-    }
-  }
-  /* read in the log blocks, memcpy to the corresponding real block */
-  ll_rw_block(READ, get_desc_trans_len(desc), log_blocks) ;
-  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
-    wait_on_buffer(log_blocks[i]) ;
-    if (!buffer_uptodate(log_blocks[i])) {
-      reiserfs_warning(p_s_sb, "journal-1212: REPLAY FAILURE fsck required! buffer write failed") ;
-      brelse_array(log_blocks + i, get_desc_trans_len(desc) - i) ;
-      brelse_array(real_blocks, get_desc_trans_len(desc)) ;
-      brelse(c_bh) ;
-      brelse(d_bh) ;
-      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      return -1 ;
-    }
-    memcpy(real_blocks[i]->b_data, log_blocks[i]->b_data, real_blocks[i]->b_size) ;
-    set_buffer_uptodate(real_blocks[i]) ;
-    brelse(log_blocks[i]) ;
-  }
-  /* flush out the real blocks */
-  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
-    set_buffer_dirty(real_blocks[i]) ;
-    ll_rw_block(WRITE, 1, real_blocks + i) ;
-  }
-  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
-    wait_on_buffer(real_blocks[i]) ; 
-    if (!buffer_uptodate(real_blocks[i])) {
-      reiserfs_warning(p_s_sb, "journal-1226: REPLAY FAILURE, fsck required! buffer write failed") ;
-      brelse_array(real_blocks + i, get_desc_trans_len(desc) - i) ;
-      brelse(c_bh) ;
-      brelse(d_bh) ;
-      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
-      return -1 ;
-    }
-    brelse(real_blocks[i]) ;
-  }
-  cur_dblock =  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + ((trans_offset + get_desc_trans_len(desc) + 2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)) ;
-  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1095: setting journal "
-                 "start to offset %ld",
-		 cur_dblock -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)) ;
-  
-  /* init starting values for the first transaction, in case this is the last transaction to be replayed. */
-  journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
-  journal->j_last_flush_trans_id = trans_id ;
-  journal->j_trans_id = trans_id + 1;
-  brelse(c_bh) ;
-  brelse(d_bh) ;
-  reiserfs_kfree(log_blocks, le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *), p_s_sb) ;
-  reiserfs_kfree(real_blocks, le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *), p_s_sb) ;
-  return 0 ;
+static int journal_read_transaction(struct super_block *p_s_sb,
+				    unsigned long cur_dblock,
+				    unsigned long oldest_start,
+				    unsigned long oldest_trans_id,
+				    unsigned long newest_mount_id)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_desc *desc;
+	struct reiserfs_journal_commit *commit;
+	unsigned long trans_id = 0;
+	struct buffer_head *c_bh;
+	struct buffer_head *d_bh;
+	struct buffer_head **log_blocks = NULL;
+	struct buffer_head **real_blocks = NULL;
+	unsigned long trans_offset;
+	int i;
+	int trans_half;
+
+	d_bh = journal_bread(p_s_sb, cur_dblock);
+	if (!d_bh)
+		return 1;
+	desc = (struct reiserfs_journal_desc *)d_bh->b_data;
+	trans_offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1037: "
+		       "journal_read_transaction, offset %llu, len %d mount_id %d",
+		       d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		       get_desc_trans_len(desc), get_desc_mount_id(desc));
+	if (get_desc_trans_id(desc) < oldest_trans_id) {
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1039: "
+			       "journal_read_trans skipping because %lu is too old",
+			       cur_dblock -
+			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb));
+		brelse(d_bh);
+		return 1;
+	}
+	if (get_desc_mount_id(desc) != newest_mount_id) {
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1146: "
+			       "journal_read_trans skipping because %d is != "
+			       "newest_mount_id %lu", get_desc_mount_id(desc),
+			       newest_mount_id);
+		brelse(d_bh);
+		return 1;
+	}
+	c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+			     ((trans_offset + get_desc_trans_len(desc) + 1) %
+			      SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+	if (!c_bh) {
+		brelse(d_bh);
+		return 1;
+	}
+	commit = (struct reiserfs_journal_commit *)c_bh->b_data;
+	if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			       "journal_read_transaction, "
+			       "commit offset %llu had bad time %d or length %d",
+			       c_bh->b_blocknr -
+			       SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       get_commit_trans_id(commit),
+			       get_commit_trans_len(commit));
+		brelse(c_bh);
+		brelse(d_bh);
+		return 1;
+	}
+	trans_id = get_desc_trans_id(desc);
+	/* now we know we've got a good transaction, and it was inside the valid time ranges */
+	log_blocks =
+	    reiserfs_kmalloc(get_desc_trans_len(desc) *
+			     sizeof(struct buffer_head *), GFP_NOFS, p_s_sb);
+	real_blocks =
+	    reiserfs_kmalloc(get_desc_trans_len(desc) *
+			     sizeof(struct buffer_head *), GFP_NOFS, p_s_sb);
+	if (!log_blocks || !real_blocks) {
+		brelse(c_bh);
+		brelse(d_bh);
+		reiserfs_kfree(log_blocks,
+			       get_desc_trans_len(desc) *
+			       sizeof(struct buffer_head *), p_s_sb);
+		reiserfs_kfree(real_blocks,
+			       get_desc_trans_len(desc) *
+			       sizeof(struct buffer_head *), p_s_sb);
+		reiserfs_warning(p_s_sb,
+				 "journal-1169: kmalloc failed, unable to mount FS");
+		return -1;
+	}
+	/* get all the buffer heads */
+	trans_half = journal_trans_half(p_s_sb->s_blocksize);
+	for (i = 0; i < get_desc_trans_len(desc); i++) {
+		log_blocks[i] =
+		    journal_getblk(p_s_sb,
+				   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+				   (trans_offset + 1 +
+				    i) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+		if (i < trans_half) {
+			real_blocks[i] =
+			    sb_getblk(p_s_sb,
+				      le32_to_cpu(desc->j_realblock[i]));
+		} else {
+			real_blocks[i] =
+			    sb_getblk(p_s_sb,
+				      le32_to_cpu(commit->
+						  j_realblock[i - trans_half]));
+		}
+		if (real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(p_s_sb)) {
+			reiserfs_warning(p_s_sb,
+					 "journal-1207: REPLAY FAILURE fsck required! Block to replay is outside of filesystem");
+			goto abort_replay;
+		}
+		/* make sure we don't try to replay onto log or reserved area */
+		if (is_block_in_log_or_reserved_area
+		    (p_s_sb, real_blocks[i]->b_blocknr)) {
+			reiserfs_warning(p_s_sb,
+					 "journal-1204: REPLAY FAILURE fsck required! Trying to replay onto a log block");
+		      abort_replay:
+			brelse_array(log_blocks, i);
+			brelse_array(real_blocks, i);
+			brelse(c_bh);
+			brelse(d_bh);
+			reiserfs_kfree(log_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			reiserfs_kfree(real_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			return -1;
+		}
+	}
+	/* read in the log blocks, memcpy to the corresponding real block */
+	ll_rw_block(READ, get_desc_trans_len(desc), log_blocks);
+	for (i = 0; i < get_desc_trans_len(desc); i++) {
+		wait_on_buffer(log_blocks[i]);
+		if (!buffer_uptodate(log_blocks[i])) {
+			reiserfs_warning(p_s_sb,
+					 "journal-1212: REPLAY FAILURE fsck required! buffer write failed");
+			brelse_array(log_blocks + i,
+				     get_desc_trans_len(desc) - i);
+			brelse_array(real_blocks, get_desc_trans_len(desc));
+			brelse(c_bh);
+			brelse(d_bh);
+			reiserfs_kfree(log_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			reiserfs_kfree(real_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			return -1;
+		}
+		memcpy(real_blocks[i]->b_data, log_blocks[i]->b_data,
+		       real_blocks[i]->b_size);
+		set_buffer_uptodate(real_blocks[i]);
+		brelse(log_blocks[i]);
+	}
+	/* flush out the real blocks */
+	for (i = 0; i < get_desc_trans_len(desc); i++) {
+		set_buffer_dirty(real_blocks[i]);
+		ll_rw_block(WRITE, 1, real_blocks + i);
+	}
+	for (i = 0; i < get_desc_trans_len(desc); i++) {
+		wait_on_buffer(real_blocks[i]);
+		if (!buffer_uptodate(real_blocks[i])) {
+			reiserfs_warning(p_s_sb,
+					 "journal-1226: REPLAY FAILURE, fsck required! buffer write failed");
+			brelse_array(real_blocks + i,
+				     get_desc_trans_len(desc) - i);
+			brelse(c_bh);
+			brelse(d_bh);
+			reiserfs_kfree(log_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			reiserfs_kfree(real_blocks,
+				       get_desc_trans_len(desc) *
+				       sizeof(struct buffer_head *), p_s_sb);
+			return -1;
+		}
+		brelse(real_blocks[i]);
+	}
+	cur_dblock =
+	    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+	    ((trans_offset + get_desc_trans_len(desc) +
+	      2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+		       "journal-1095: setting journal " "start to offset %ld",
+		       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb));
+
+	/* init starting values for the first transaction, in case this is the last transaction to be replayed. */
+	journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+	journal->j_last_flush_trans_id = trans_id;
+	journal->j_trans_id = trans_id + 1;
+	brelse(c_bh);
+	brelse(d_bh);
+	reiserfs_kfree(log_blocks,
+		       le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *),
+		       p_s_sb);
+	reiserfs_kfree(real_blocks,
+		       le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *),
+		       p_s_sb);
+	return 0;
 }
 
 /* This function reads blocks starting from block and to max_block of bufsize
@@ -2024,39 +2222,39 @@ static int journal_read_transaction(struct super_block *p_s_sb, unsigned long cu
    Right now it is only used from journal code. But later we might use it
    from other places.
    Note: Do not use journal_getblk/sb_getblk functions here! */
-static struct buffer_head * reiserfs_breada (struct block_device *dev, int block, int bufsize,
-			    unsigned int max_block)
+static struct buffer_head *reiserfs_breada(struct block_device *dev, int block,
+					   int bufsize, unsigned int max_block)
 {
-	struct buffer_head * bhlist[BUFNR];
+	struct buffer_head *bhlist[BUFNR];
 	unsigned int blocks = BUFNR;
-	struct buffer_head * bh;
+	struct buffer_head *bh;
 	int i, j;
-	
-	bh = __getblk (dev, block, bufsize );
-	if (buffer_uptodate (bh))
-		return (bh);   
-		
+
+	bh = __getblk(dev, block, bufsize);
+	if (buffer_uptodate(bh))
+		return (bh);
+
 	if (block + BUFNR > max_block) {
 		blocks = max_block - block;
 	}
 	bhlist[0] = bh;
 	j = 1;
 	for (i = 1; i < blocks; i++) {
-		bh = __getblk (dev, block + i, bufsize);
-		if (buffer_uptodate (bh)) {
-			brelse (bh);
+		bh = __getblk(dev, block + i, bufsize);
+		if (buffer_uptodate(bh)) {
+			brelse(bh);
 			break;
-		}
-		else bhlist[j++] = bh;
+		} else
+			bhlist[j++] = bh;
 	}
-	ll_rw_block (READ, j, bhlist);
-	for(i = 1; i < j; i++) 
-		brelse (bhlist[i]);
+	ll_rw_block(READ, j, bhlist);
+	for (i = 1; i < j; i++)
+		brelse(bhlist[i]);
 	bh = bhlist[0];
-	wait_on_buffer (bh);
-	if (buffer_uptodate (bh))
+	wait_on_buffer(bh);
+	if (buffer_uptodate(bh))
 		return bh;
-	brelse (bh);
+	brelse(bh);
 	return NULL;
 }
 
@@ -2069,218 +2267,250 @@ static struct buffer_head * reiserfs_breada (struct block_device *dev, int block
 **
 ** On exit, it sets things up so the first transaction will work correctly.
 */
-static int journal_read(struct super_block *p_s_sb) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_desc *desc ;
-  unsigned long oldest_trans_id = 0;
-  unsigned long oldest_invalid_trans_id = 0 ;
-  time_t start ;
-  unsigned long oldest_start = 0;
-  unsigned long cur_dblock = 0 ;
-  unsigned long newest_mount_id = 9 ;
-  struct buffer_head *d_bh ;
-  struct reiserfs_journal_header *jh ;
-  int valid_journal_header = 0 ;
-  int replay_count = 0 ;
-  int continue_replay = 1 ;
-  int ret ;
-  char b[BDEVNAME_SIZE];
-
-  cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
-  reiserfs_info (p_s_sb, "checking transaction log (%s)\n",
-	 bdevname(journal->j_dev_bd, b));
-  start = get_seconds();
-
-  /* step 1, read in the journal header block.  Check the transaction it says 
-  ** is the first unflushed, and if that transaction is not valid, 
-  ** replay is done
-  */
-  journal->j_header_bh = journal_bread(p_s_sb,
-					   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
-					   SB_ONDISK_JOURNAL_SIZE(p_s_sb));
-  if (!journal->j_header_bh) {
-    return 1 ;
-  }
-  jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data) ;
-  if (le32_to_cpu(jh->j_first_unflushed_offset) >= 0 && 
-      le32_to_cpu(jh->j_first_unflushed_offset) < SB_ONDISK_JOURNAL_SIZE(p_s_sb) && 
-      le32_to_cpu(jh->j_last_flush_trans_id) > 0) {
-    oldest_start = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
-                       le32_to_cpu(jh->j_first_unflushed_offset) ;
-    oldest_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
-    newest_mount_id = le32_to_cpu(jh->j_mount_id);
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1153: found in "
-                   "header: first_unflushed_offset %d, last_flushed_trans_id "
-		   "%lu", le32_to_cpu(jh->j_first_unflushed_offset),
-		   le32_to_cpu(jh->j_last_flush_trans_id)) ;
-    valid_journal_header = 1 ;
-
-    /* now, we try to read the first unflushed offset.  If it is not valid, 
-    ** there is nothing more we can do, and it makes no sense to read 
-    ** through the whole log.
-    */
-    d_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + le32_to_cpu(jh->j_first_unflushed_offset)) ;
-    ret = journal_transaction_is_valid(p_s_sb, d_bh, NULL, NULL) ;
-    if (!ret) {
-      continue_replay = 0 ;
-    }
-    brelse(d_bh) ;
-    goto start_log_replay;
-  }
-
-  if (continue_replay && bdev_read_only(p_s_sb->s_bdev)) {
-    reiserfs_warning (p_s_sb,
-		      "clm-2076: device is readonly, unable to replay log") ;
-    return -1 ;
-  }
-
-  /* ok, there are transactions that need to be replayed.  start with the first log block, find
-  ** all the valid transactions, and pick out the oldest.
-  */
-  while(continue_replay && cur_dblock < (SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb))) {
-    /* Note that it is required for blocksize of primary fs device and journal
-       device to be the same */
-    d_bh = reiserfs_breada(journal->j_dev_bd, cur_dblock, p_s_sb->s_blocksize,
-			   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb)) ;
-    ret = journal_transaction_is_valid(p_s_sb, d_bh, &oldest_invalid_trans_id, &newest_mount_id) ;
-    if (ret == 1) {
-      desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
-      if (oldest_start == 0) { /* init all oldest_ values */
-        oldest_trans_id = get_desc_trans_id(desc) ;
-	oldest_start = d_bh->b_blocknr ;
-	newest_mount_id = get_desc_mount_id(desc) ;
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1179: Setting "
-	               "oldest_start to offset %llu, trans_id %lu",
-		       oldest_start - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-		       oldest_trans_id) ;
-      } else if (oldest_trans_id > get_desc_trans_id(desc)) { 
-        /* one we just read was older */
-        oldest_trans_id = get_desc_trans_id(desc) ;
-	oldest_start = d_bh->b_blocknr ;
-	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1180: Resetting "
-	               "oldest_start to offset %lu, trans_id %lu",
-			oldest_start - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-			oldest_trans_id) ;
-      }
-      if (newest_mount_id < get_desc_mount_id(desc)) {
-        newest_mount_id = get_desc_mount_id(desc) ;
+static int journal_read(struct super_block *p_s_sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_desc *desc;
+	unsigned long oldest_trans_id = 0;
+	unsigned long oldest_invalid_trans_id = 0;
+	time_t start;
+	unsigned long oldest_start = 0;
+	unsigned long cur_dblock = 0;
+	unsigned long newest_mount_id = 9;
+	struct buffer_head *d_bh;
+	struct reiserfs_journal_header *jh;
+	int valid_journal_header = 0;
+	int replay_count = 0;
+	int continue_replay = 1;
+	int ret;
+	char b[BDEVNAME_SIZE];
+
+	cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb);
+	reiserfs_info(p_s_sb, "checking transaction log (%s)\n",
+		      bdevname(journal->j_dev_bd, b));
+	start = get_seconds();
+
+	/* step 1, read in the journal header block.  Check the transaction it says 
+	 ** is the first unflushed, and if that transaction is not valid, 
+	 ** replay is done
+	 */
+	journal->j_header_bh = journal_bread(p_s_sb,
+					     SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)
+					     + SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+	if (!journal->j_header_bh) {
+		return 1;
+	}
+	jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data);
+	if (le32_to_cpu(jh->j_first_unflushed_offset) >= 0 &&
+	    le32_to_cpu(jh->j_first_unflushed_offset) <
+	    SB_ONDISK_JOURNAL_SIZE(p_s_sb)
+	    && le32_to_cpu(jh->j_last_flush_trans_id) > 0) {
+		oldest_start =
+		    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		    le32_to_cpu(jh->j_first_unflushed_offset);
+		oldest_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
+		newest_mount_id = le32_to_cpu(jh->j_mount_id);
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			       "journal-1153: found in "
+			       "header: first_unflushed_offset %d, last_flushed_trans_id "
+			       "%lu", le32_to_cpu(jh->j_first_unflushed_offset),
+			       le32_to_cpu(jh->j_last_flush_trans_id));
+		valid_journal_header = 1;
+
+		/* now, we try to read the first unflushed offset.  If it is not valid, 
+		 ** there is nothing more we can do, and it makes no sense to read 
+		 ** through the whole log.
+		 */
+		d_bh =
+		    journal_bread(p_s_sb,
+				  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+				  le32_to_cpu(jh->j_first_unflushed_offset));
+		ret = journal_transaction_is_valid(p_s_sb, d_bh, NULL, NULL);
+		if (!ret) {
+			continue_replay = 0;
+		}
+		brelse(d_bh);
+		goto start_log_replay;
+	}
+
+	if (continue_replay && bdev_read_only(p_s_sb->s_bdev)) {
+		reiserfs_warning(p_s_sb,
+				 "clm-2076: device is readonly, unable to replay log");
+		return -1;
+	}
+
+	/* ok, there are transactions that need to be replayed.  start with the first log block, find
+	 ** all the valid transactions, and pick out the oldest.
+	 */
+	while (continue_replay
+	       && cur_dblock <
+	       (SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		SB_ONDISK_JOURNAL_SIZE(p_s_sb))) {
+		/* Note that it is required for blocksize of primary fs device and journal
+		   device to be the same */
+		d_bh =
+		    reiserfs_breada(journal->j_dev_bd, cur_dblock,
+				    p_s_sb->s_blocksize,
+				    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+				    SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+		ret =
+		    journal_transaction_is_valid(p_s_sb, d_bh,
+						 &oldest_invalid_trans_id,
+						 &newest_mount_id);
+		if (ret == 1) {
+			desc = (struct reiserfs_journal_desc *)d_bh->b_data;
+			if (oldest_start == 0) {	/* init all oldest_ values */
+				oldest_trans_id = get_desc_trans_id(desc);
+				oldest_start = d_bh->b_blocknr;
+				newest_mount_id = get_desc_mount_id(desc);
+				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+					       "journal-1179: Setting "
+					       "oldest_start to offset %llu, trans_id %lu",
+					       oldest_start -
+					       SB_ONDISK_JOURNAL_1st_BLOCK
+					       (p_s_sb), oldest_trans_id);
+			} else if (oldest_trans_id > get_desc_trans_id(desc)) {
+				/* one we just read was older */
+				oldest_trans_id = get_desc_trans_id(desc);
+				oldest_start = d_bh->b_blocknr;
+				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+					       "journal-1180: Resetting "
+					       "oldest_start to offset %lu, trans_id %lu",
+					       oldest_start -
+					       SB_ONDISK_JOURNAL_1st_BLOCK
+					       (p_s_sb), oldest_trans_id);
+			}
+			if (newest_mount_id < get_desc_mount_id(desc)) {
+				newest_mount_id = get_desc_mount_id(desc);
+				reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+					       "journal-1299: Setting "
+					       "newest_mount_id to %d",
+					       get_desc_mount_id(desc));
+			}
+			cur_dblock += get_desc_trans_len(desc) + 2;
+		} else {
+			cur_dblock++;
+		}
+		brelse(d_bh);
+	}
+
+      start_log_replay:
+	cur_dblock = oldest_start;
+	if (oldest_trans_id) {
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			       "journal-1206: Starting replay "
+			       "from offset %llu, trans_id %lu",
+			       cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+			       oldest_trans_id);
+
+	}
+	replay_count = 0;
+	while (continue_replay && oldest_trans_id > 0) {
+		ret =
+		    journal_read_transaction(p_s_sb, cur_dblock, oldest_start,
+					     oldest_trans_id, newest_mount_id);
+		if (ret < 0) {
+			return ret;
+		} else if (ret != 0) {
+			break;
+		}
+		cur_dblock =
+		    SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start;
+		replay_count++;
+		if (cur_dblock == oldest_start)
+			break;
+	}
+
+	if (oldest_trans_id == 0) {
+		reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE,
+			       "journal-1225: No valid " "transactions found");
+	}
+	/* j_start does not get set correctly if we don't replay any transactions.
+	 ** if we had a valid journal_header, set j_start to the first unflushed transaction value,
+	 ** copy the trans_id from the header
+	 */
+	if (valid_journal_header && replay_count == 0) {
+		journal->j_start = le32_to_cpu(jh->j_first_unflushed_offset);
+		journal->j_trans_id =
+		    le32_to_cpu(jh->j_last_flush_trans_id) + 1;
+		journal->j_last_flush_trans_id =
+		    le32_to_cpu(jh->j_last_flush_trans_id);
+		journal->j_mount_id = le32_to_cpu(jh->j_mount_id) + 1;
+	} else {
+		journal->j_mount_id = newest_mount_id + 1;
+	}
 	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
-	              "newest_mount_id to %d", get_desc_mount_id(desc));
-      }
-      cur_dblock += get_desc_trans_len(desc) + 2 ;
-    } else {
-      cur_dblock++ ;
-    }
-    brelse(d_bh) ;
-  }
-
-start_log_replay:
-  cur_dblock = oldest_start ;
-  if (oldest_trans_id)  {
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1206: Starting replay "
-                   "from offset %llu, trans_id %lu",
-		   cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
-		   oldest_trans_id) ;
-
-  }
-  replay_count = 0 ;
-  while(continue_replay && oldest_trans_id > 0) {
-    ret = journal_read_transaction(p_s_sb, cur_dblock, oldest_start, oldest_trans_id, newest_mount_id) ;
-    if (ret < 0) {
-      return ret ;
-    } else if (ret != 0) {
-      break ;
-    }
-    cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start ;
-    replay_count++ ;
-   if (cur_dblock == oldest_start)
-        break;
-  }
-
-  if (oldest_trans_id == 0) {
-    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1225: No valid "
-                   "transactions found") ;
-  }
-  /* j_start does not get set correctly if we don't replay any transactions.
-  ** if we had a valid journal_header, set j_start to the first unflushed transaction value,
-  ** copy the trans_id from the header
-  */
-  if (valid_journal_header && replay_count == 0) { 
-    journal->j_start = le32_to_cpu(jh->j_first_unflushed_offset) ;
-    journal->j_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
-    journal->j_last_flush_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) ;
-    journal->j_mount_id = le32_to_cpu(jh->j_mount_id) + 1;
-  } else {
-    journal->j_mount_id = newest_mount_id + 1 ;
-  }
-  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
-                 "newest_mount_id to %lu", journal->j_mount_id) ;
-  journal->j_first_unflushed_offset = journal->j_start ;
-  if (replay_count > 0) {
-    reiserfs_info (p_s_sb, "replayed %d transactions in %lu seconds\n",
-		   replay_count, get_seconds() - start) ;
-  }
-  if (!bdev_read_only(p_s_sb->s_bdev) && 
-       _update_journal_header_block(p_s_sb, journal->j_start,
-                                   journal->j_last_flush_trans_id))
-  {
-      /* replay failed, caller must call free_journal_ram and abort
-      ** the mount
-      */
-      return -1 ;
-  }
-  return 0 ;
+		       "newest_mount_id to %lu", journal->j_mount_id);
+	journal->j_first_unflushed_offset = journal->j_start;
+	if (replay_count > 0) {
+		reiserfs_info(p_s_sb,
+			      "replayed %d transactions in %lu seconds\n",
+			      replay_count, get_seconds() - start);
+	}
+	if (!bdev_read_only(p_s_sb->s_bdev) &&
+	    _update_journal_header_block(p_s_sb, journal->j_start,
+					 journal->j_last_flush_trans_id)) {
+		/* replay failed, caller must call free_journal_ram and abort
+		 ** the mount
+		 */
+		return -1;
+	}
+	return 0;
 }
 
 static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
 {
-    struct reiserfs_journal_list *jl;
-retry:
-    jl = reiserfs_kmalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS, s);
-    if (!jl) {
-	yield();
-	goto retry;
-    }
-    memset(jl, 0, sizeof(*jl));
-    INIT_LIST_HEAD(&jl->j_list);
-    INIT_LIST_HEAD(&jl->j_working_list);
-    INIT_LIST_HEAD(&jl->j_tail_bh_list);
-    INIT_LIST_HEAD(&jl->j_bh_list);
-    sema_init(&jl->j_commit_lock, 1);
-    SB_JOURNAL(s)->j_num_lists++;
-    get_journal_list(jl);
-    return jl;
-}
-
-static void journal_list_init(struct super_block *p_s_sb) {
-    SB_JOURNAL(p_s_sb)->j_current_jl = alloc_journal_list(p_s_sb);
-}
-
-static int release_journal_dev( struct super_block *super,
-				struct reiserfs_journal *journal )
-{
-    int result;
-    
-    result = 0;
-
-    if( journal -> j_dev_file != NULL ) {
-	result = filp_close( journal -> j_dev_file, NULL );
-	journal -> j_dev_file = NULL;
-	journal -> j_dev_bd = NULL;
-    } else if( journal -> j_dev_bd != NULL ) {
-	result = blkdev_put( journal -> j_dev_bd );
-	journal -> j_dev_bd = NULL;
-    }
-
-    if( result != 0 ) {
-	reiserfs_warning(super, "sh-457: release_journal_dev: Cannot release journal device: %i", result );
-    }
-    return result;
-}
-
-static int journal_init_dev( struct super_block *super, 
-			     struct reiserfs_journal *journal, 
-			     const char *jdev_name )
+	struct reiserfs_journal_list *jl;
+      retry:
+	jl = reiserfs_kmalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS,
+			      s);
+	if (!jl) {
+		yield();
+		goto retry;
+	}
+	memset(jl, 0, sizeof(*jl));
+	INIT_LIST_HEAD(&jl->j_list);
+	INIT_LIST_HEAD(&jl->j_working_list);
+	INIT_LIST_HEAD(&jl->j_tail_bh_list);
+	INIT_LIST_HEAD(&jl->j_bh_list);
+	sema_init(&jl->j_commit_lock, 1);
+	SB_JOURNAL(s)->j_num_lists++;
+	get_journal_list(jl);
+	return jl;
+}
+
+static void journal_list_init(struct super_block *p_s_sb)
+{
+	SB_JOURNAL(p_s_sb)->j_current_jl = alloc_journal_list(p_s_sb);
+}
+
+static int release_journal_dev(struct super_block *super,
+			       struct reiserfs_journal *journal)
+{
+	int result;
+
+	result = 0;
+
+	if (journal->j_dev_file != NULL) {
+		result = filp_close(journal->j_dev_file, NULL);
+		journal->j_dev_file = NULL;
+		journal->j_dev_bd = NULL;
+	} else if (journal->j_dev_bd != NULL) {
+		result = blkdev_put(journal->j_dev_bd);
+		journal->j_dev_bd = NULL;
+	}
+
+	if (result != 0) {
+		reiserfs_warning(super,
+				 "sh-457: release_journal_dev: Cannot release journal device: %i",
+				 result);
+	}
+	return result;
+}
+
+static int journal_init_dev(struct super_block *super,
+			    struct reiserfs_journal *journal,
+			    const char *jdev_name)
 {
 	int result;
 	dev_t jdev;
@@ -2289,50 +2519,51 @@ static int journal_init_dev( struct super_block *super,
 
 	result = 0;
 
-	journal -> j_dev_bd = NULL;
-	journal -> j_dev_file = NULL;
-	jdev = SB_ONDISK_JOURNAL_DEVICE( super ) ?
-		new_decode_dev(SB_ONDISK_JOURNAL_DEVICE(super)) : super->s_dev;	
+	journal->j_dev_bd = NULL;
+	journal->j_dev_file = NULL;
+	jdev = SB_ONDISK_JOURNAL_DEVICE(super) ?
+	    new_decode_dev(SB_ONDISK_JOURNAL_DEVICE(super)) : super->s_dev;
 
 	if (bdev_read_only(super->s_bdev))
-	    blkdev_mode = FMODE_READ;
+		blkdev_mode = FMODE_READ;
 
 	/* there is no "jdev" option and journal is on separate device */
-	if( ( !jdev_name || !jdev_name[ 0 ] ) ) {
+	if ((!jdev_name || !jdev_name[0])) {
 		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode);
 		if (IS_ERR(journal->j_dev_bd)) {
 			result = PTR_ERR(journal->j_dev_bd);
 			journal->j_dev_bd = NULL;
-			reiserfs_warning (super, "sh-458: journal_init_dev: "
-					  "cannot init journal device '%s': %i",
-					  __bdevname(jdev, b), result );
+			reiserfs_warning(super, "sh-458: journal_init_dev: "
+					 "cannot init journal device '%s': %i",
+					 __bdevname(jdev, b), result);
 			return result;
 		} else if (jdev != super->s_dev)
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);
 		return 0;
 	}
 
-	journal -> j_dev_file = filp_open( jdev_name, 0, 0 );
-	if( !IS_ERR( journal -> j_dev_file ) ) {
+	journal->j_dev_file = filp_open(jdev_name, 0, 0);
+	if (!IS_ERR(journal->j_dev_file)) {
 		struct inode *jdev_inode = journal->j_dev_file->f_mapping->host;
-		if( !S_ISBLK( jdev_inode -> i_mode ) ) {
+		if (!S_ISBLK(jdev_inode->i_mode)) {
 			reiserfs_warning(super, "journal_init_dev: '%s' is "
-					 "not a block device", jdev_name );
+					 "not a block device", jdev_name);
 			result = -ENOTBLK;
-			release_journal_dev( super, journal );
-		} else  {
+			release_journal_dev(super, journal);
+		} else {
 			/* ok */
 			journal->j_dev_bd = I_BDEV(jdev_inode);
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);
-			reiserfs_info(super, "journal_init_dev: journal device: %s\n",
+			reiserfs_info(super,
+				      "journal_init_dev: journal device: %s\n",
 				      bdevname(journal->j_dev_bd, b));
 		}
 	} else {
-		result = PTR_ERR( journal -> j_dev_file );
-		journal -> j_dev_file = NULL;
-		reiserfs_warning (super,
-				  "journal_init_dev: Cannot open '%s': %i",
-				  jdev_name, result );
+		result = PTR_ERR(journal->j_dev_file);
+		journal->j_dev_file = NULL;
+		reiserfs_warning(super,
+				 "journal_init_dev: Cannot open '%s': %i",
+				 jdev_name, result);
 	}
 	return result;
 }
@@ -2340,193 +2571,214 @@ static int journal_init_dev( struct super_block *super,
 /*
 ** must be called once on fs mount.  calls journal_read for you
 */
-int journal_init(struct super_block *p_s_sb, const char * j_dev_name, int old_format, unsigned int commit_max_age) {
-    int num_cnodes = SB_ONDISK_JOURNAL_SIZE(p_s_sb) * 2 ;
-    struct buffer_head *bhjh;
-    struct reiserfs_super_block * rs;
-    struct reiserfs_journal_header *jh;
-    struct reiserfs_journal *journal;
-    struct reiserfs_journal_list *jl;
-    char b[BDEVNAME_SIZE];
-
-    journal = SB_JOURNAL(p_s_sb) = vmalloc(sizeof (struct reiserfs_journal)) ;
-    if (!journal) {
-	reiserfs_warning (p_s_sb, "journal-1256: unable to get memory for journal structure") ;
-	return 1 ;
-    }
-    memset(journal, 0, sizeof(struct reiserfs_journal)) ;
-    INIT_LIST_HEAD(&journal->j_bitmap_nodes) ;
-    INIT_LIST_HEAD (&journal->j_prealloc_list);
-    INIT_LIST_HEAD(&journal->j_working_list);
-    INIT_LIST_HEAD(&journal->j_journal_list);
-    journal->j_persistent_trans = 0;
-    if (reiserfs_allocate_list_bitmaps(p_s_sb,
-				       journal->j_list_bitmap,
- 				       SB_BMAP_NR(p_s_sb)))
-	goto free_and_return ;
-    allocate_bitmap_nodes(p_s_sb) ;
-
-    /* reserved for journal area support */
-    SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) = (old_format ?
-					     REISERFS_OLD_DISK_OFFSET_IN_BYTES / p_s_sb->s_blocksize +
-					     SB_BMAP_NR(p_s_sb) + 1 :
-					     REISERFS_DISK_OFFSET_IN_BYTES / p_s_sb->s_blocksize + 2); 
-    
-    /* Sanity check to see is the standard journal fitting withing first bitmap
-       (actual for small blocksizes) */
-    if ( !SB_ONDISK_JOURNAL_DEVICE( p_s_sb ) &&
-         (SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb) > p_s_sb->s_blocksize * 8) ) {
-	reiserfs_warning (p_s_sb, "journal-1393: journal does not fit for area "
-			  "addressed by first of bitmap blocks. It starts at "
-			  "%u and its size is %u. Block size %ld",
-			  SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb),
-			  SB_ONDISK_JOURNAL_SIZE(p_s_sb), p_s_sb->s_blocksize);
-	goto free_and_return;
-    }
-
-    if( journal_init_dev( p_s_sb, journal, j_dev_name ) != 0 ) {
-      reiserfs_warning (p_s_sb, "sh-462: unable to initialize jornal device");
-      goto free_and_return;
-    }
-
-     rs = SB_DISK_SUPER_BLOCK(p_s_sb);
-     
-     /* read journal header */
-     bhjh = journal_bread(p_s_sb,
-		   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb));
-     if (!bhjh) {
-	 reiserfs_warning (p_s_sb, "sh-459: unable to read journal header");
-	 goto free_and_return;
-     }
-     jh = (struct reiserfs_journal_header *)(bhjh->b_data);
-     
-     /* make sure that journal matches to the super block */
-     if (is_reiserfs_jr(rs) && (le32_to_cpu(jh->jh_journal.jp_journal_magic) != sb_jp_journal_magic(rs))) {
-	 reiserfs_warning (p_s_sb, "sh-460: journal header magic %x "
-			   "(device %s) does not match to magic found in super "
-			   "block %x",
-			   jh->jh_journal.jp_journal_magic,
-			   bdevname( journal->j_dev_bd, b),
-			   sb_jp_journal_magic(rs));
-	 brelse (bhjh);
-	 goto free_and_return;
-  }
-     
-  journal->j_trans_max      = le32_to_cpu (jh->jh_journal.jp_journal_trans_max);
-  journal->j_max_batch      = le32_to_cpu (jh->jh_journal.jp_journal_max_batch);
-  journal->j_max_commit_age = le32_to_cpu (jh->jh_journal.jp_journal_max_commit_age);
-  journal->j_max_trans_age = JOURNAL_MAX_TRANS_AGE;
-
-  if (journal->j_trans_max) {
-    /* make sure these parameters are available, assign it if they are not */
-    __u32 initial = journal->j_trans_max;
-    __u32 ratio = 1;
-    
-    if (p_s_sb->s_blocksize < 4096)
-      ratio = 4096 / p_s_sb->s_blocksize;
-    
-    if (SB_ONDISK_JOURNAL_SIZE(p_s_sb)/journal->j_trans_max < JOURNAL_MIN_RATIO)
-      journal->j_trans_max = SB_ONDISK_JOURNAL_SIZE(p_s_sb) / JOURNAL_MIN_RATIO;
-    if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio)
-      journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT / ratio;
-    if (journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio)
-      journal->j_trans_max = JOURNAL_TRANS_MIN_DEFAULT / ratio;
-    
-    if (journal->j_trans_max != initial)
-      reiserfs_warning (p_s_sb, "sh-461: journal_init: wrong transaction max size (%u). Changed to %u",
-	      initial, journal->j_trans_max);
-
-    journal->j_max_batch = journal->j_trans_max*
-      JOURNAL_MAX_BATCH_DEFAULT/JOURNAL_TRANS_MAX_DEFAULT;
-  }  
-  
-  if (!journal->j_trans_max) {
-    /*we have the file system was created by old version of mkreiserfs 
-      so this field contains zero value */
-    journal->j_trans_max      = JOURNAL_TRANS_MAX_DEFAULT ;
-    journal->j_max_batch      = JOURNAL_MAX_BATCH_DEFAULT ;
-    journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE ;
-    
-    /* for blocksize >= 4096 - max transaction size is 1024. For block size < 4096
-       trans max size is decreased proportionally */
-    if (p_s_sb->s_blocksize < 4096) {
-      journal->j_trans_max /= (4096 / p_s_sb->s_blocksize) ;
-      journal->j_max_batch = (journal->j_trans_max) * 9 / 10 ;
-    }
-  }
-
-  journal->j_default_max_commit_age = journal->j_max_commit_age;
-
-  if (commit_max_age != 0) {
-      journal->j_max_commit_age = commit_max_age;
-      journal->j_max_trans_age = commit_max_age;
-  }
-
-  reiserfs_info (p_s_sb, "journal params: device %s, size %u, "
-		 "journal first block %u, max trans len %u, max batch %u, "
-		 "max commit age %u, max trans age %u\n",
-		 bdevname( journal->j_dev_bd, b),
-		 SB_ONDISK_JOURNAL_SIZE(p_s_sb),
-		 SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
-		 journal->j_trans_max,
-		 journal->j_max_batch,
-		 journal->j_max_commit_age,
-		 journal->j_max_trans_age);
-
-  brelse (bhjh);
-     
-  journal->j_list_bitmap_index = 0 ;
-  journal_list_init(p_s_sb) ;
-
-  memset(journal->j_list_hash_table, 0, JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *)) ;
-
-  INIT_LIST_HEAD(&journal->j_dirty_buffers) ;
-  spin_lock_init(&journal->j_dirty_buffers_lock) ;
-
-  journal->j_start = 0 ;
-  journal->j_len = 0 ;
-  journal->j_len_alloc = 0 ;
-  atomic_set(&(journal->j_wcount), 0) ;
-  atomic_set(&(journal->j_async_throttle), 0) ;
-  journal->j_bcount = 0 ;
-  journal->j_trans_start_time = 0 ;
-  journal->j_last = NULL ;
-  journal->j_first = NULL ;
-  init_waitqueue_head(&(journal->j_join_wait)) ;
-  sema_init(&journal->j_lock, 1);
-  sema_init(&journal->j_flush_sem, 1);
-
-  journal->j_trans_id = 10 ;
-  journal->j_mount_id = 10 ;
-  journal->j_state = 0 ;
-  atomic_set(&(journal->j_jlock), 0) ;
-  journal->j_cnode_free_list = allocate_cnodes(num_cnodes) ;
-  journal->j_cnode_free_orig = journal->j_cnode_free_list ;
-  journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0 ;
-  journal->j_cnode_used = 0 ;
-  journal->j_must_wait = 0 ;
-
-  init_journal_hash(p_s_sb) ;
-  jl = journal->j_current_jl;
-  jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);
-  if (!jl->j_list_bitmap) {
-    reiserfs_warning(p_s_sb, "journal-2005, get_list_bitmap failed for journal list 0") ;
-    goto free_and_return;
-  }
-  if (journal_read(p_s_sb) < 0) {
-    reiserfs_warning(p_s_sb, "Replay Failure, unable to mount") ;
-    goto free_and_return;
-  }
-
-  reiserfs_mounted_fs_count++ ;
-  if (reiserfs_mounted_fs_count <= 1)
-    commit_wq = create_workqueue("reiserfs");
-
-  INIT_WORK(&journal->j_work, flush_async_commits, p_s_sb);
-  return 0 ;
-free_and_return:
-  free_journal_ram(p_s_sb);
-  return 1;
+int journal_init(struct super_block *p_s_sb, const char *j_dev_name,
+		 int old_format, unsigned int commit_max_age)
+{
+	int num_cnodes = SB_ONDISK_JOURNAL_SIZE(p_s_sb) * 2;
+	struct buffer_head *bhjh;
+	struct reiserfs_super_block *rs;
+	struct reiserfs_journal_header *jh;
+	struct reiserfs_journal *journal;
+	struct reiserfs_journal_list *jl;
+	char b[BDEVNAME_SIZE];
+
+	journal = SB_JOURNAL(p_s_sb) = vmalloc(sizeof(struct reiserfs_journal));
+	if (!journal) {
+		reiserfs_warning(p_s_sb,
+				 "journal-1256: unable to get memory for journal structure");
+		return 1;
+	}
+	memset(journal, 0, sizeof(struct reiserfs_journal));
+	INIT_LIST_HEAD(&journal->j_bitmap_nodes);
+	INIT_LIST_HEAD(&journal->j_prealloc_list);
+	INIT_LIST_HEAD(&journal->j_working_list);
+	INIT_LIST_HEAD(&journal->j_journal_list);
+	journal->j_persistent_trans = 0;
+	if (reiserfs_allocate_list_bitmaps(p_s_sb,
+					   journal->j_list_bitmap,
+					   SB_BMAP_NR(p_s_sb)))
+		goto free_and_return;
+	allocate_bitmap_nodes(p_s_sb);
+
+	/* reserved for journal area support */
+	SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) = (old_format ?
+						 REISERFS_OLD_DISK_OFFSET_IN_BYTES
+						 / p_s_sb->s_blocksize +
+						 SB_BMAP_NR(p_s_sb) +
+						 1 :
+						 REISERFS_DISK_OFFSET_IN_BYTES /
+						 p_s_sb->s_blocksize + 2);
+
+	/* Sanity check to see is the standard journal fitting withing first bitmap
+	   (actual for small blocksizes) */
+	if (!SB_ONDISK_JOURNAL_DEVICE(p_s_sb) &&
+	    (SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) +
+	     SB_ONDISK_JOURNAL_SIZE(p_s_sb) > p_s_sb->s_blocksize * 8)) {
+		reiserfs_warning(p_s_sb,
+				 "journal-1393: journal does not fit for area "
+				 "addressed by first of bitmap blocks. It starts at "
+				 "%u and its size is %u. Block size %ld",
+				 SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb),
+				 SB_ONDISK_JOURNAL_SIZE(p_s_sb),
+				 p_s_sb->s_blocksize);
+		goto free_and_return;
+	}
+
+	if (journal_init_dev(p_s_sb, journal, j_dev_name) != 0) {
+		reiserfs_warning(p_s_sb,
+				 "sh-462: unable to initialize jornal device");
+		goto free_and_return;
+	}
+
+	rs = SB_DISK_SUPER_BLOCK(p_s_sb);
+
+	/* read journal header */
+	bhjh = journal_bread(p_s_sb,
+			     SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+			     SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+	if (!bhjh) {
+		reiserfs_warning(p_s_sb,
+				 "sh-459: unable to read journal header");
+		goto free_and_return;
+	}
+	jh = (struct reiserfs_journal_header *)(bhjh->b_data);
+
+	/* make sure that journal matches to the super block */
+	if (is_reiserfs_jr(rs)
+	    && (le32_to_cpu(jh->jh_journal.jp_journal_magic) !=
+		sb_jp_journal_magic(rs))) {
+		reiserfs_warning(p_s_sb,
+				 "sh-460: journal header magic %x "
+				 "(device %s) does not match to magic found in super "
+				 "block %x", jh->jh_journal.jp_journal_magic,
+				 bdevname(journal->j_dev_bd, b),
+				 sb_jp_journal_magic(rs));
+		brelse(bhjh);
+		goto free_and_return;
+	}
+
+	journal->j_trans_max = le32_to_cpu(jh->jh_journal.jp_journal_trans_max);
+	journal->j_max_batch = le32_to_cpu(jh->jh_journal.jp_journal_max_batch);
+	journal->j_max_commit_age =
+	    le32_to_cpu(jh->jh_journal.jp_journal_max_commit_age);
+	journal->j_max_trans_age = JOURNAL_MAX_TRANS_AGE;
+
+	if (journal->j_trans_max) {
+		/* make sure these parameters are available, assign it if they are not */
+		__u32 initial = journal->j_trans_max;
+		__u32 ratio = 1;
+
+		if (p_s_sb->s_blocksize < 4096)
+			ratio = 4096 / p_s_sb->s_blocksize;
+
+		if (SB_ONDISK_JOURNAL_SIZE(p_s_sb) / journal->j_trans_max <
+		    JOURNAL_MIN_RATIO)
+			journal->j_trans_max =
+			    SB_ONDISK_JOURNAL_SIZE(p_s_sb) / JOURNAL_MIN_RATIO;
+		if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio)
+			journal->j_trans_max =
+			    JOURNAL_TRANS_MAX_DEFAULT / ratio;
+		if (journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio)
+			journal->j_trans_max =
+			    JOURNAL_TRANS_MIN_DEFAULT / ratio;
+
+		if (journal->j_trans_max != initial)
+			reiserfs_warning(p_s_sb,
+					 "sh-461: journal_init: wrong transaction max size (%u). Changed to %u",
+					 initial, journal->j_trans_max);
+
+		journal->j_max_batch = journal->j_trans_max *
+		    JOURNAL_MAX_BATCH_DEFAULT / JOURNAL_TRANS_MAX_DEFAULT;
+	}
+
+	if (!journal->j_trans_max) {
+		/*we have the file system was created by old version of mkreiserfs 
+		   so this field contains zero value */
+		journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT;
+		journal->j_max_batch = JOURNAL_MAX_BATCH_DEFAULT;
+		journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE;
+
+		/* for blocksize >= 4096 - max transaction size is 1024. For block size < 4096
+		   trans max size is decreased proportionally */
+		if (p_s_sb->s_blocksize < 4096) {
+			journal->j_trans_max /= (4096 / p_s_sb->s_blocksize);
+			journal->j_max_batch = (journal->j_trans_max) * 9 / 10;
+		}
+	}
+
+	journal->j_default_max_commit_age = journal->j_max_commit_age;
+
+	if (commit_max_age != 0) {
+		journal->j_max_commit_age = commit_max_age;
+		journal->j_max_trans_age = commit_max_age;
+	}
+
+	reiserfs_info(p_s_sb, "journal params: device %s, size %u, "
+		      "journal first block %u, max trans len %u, max batch %u, "
+		      "max commit age %u, max trans age %u\n",
+		      bdevname(journal->j_dev_bd, b),
+		      SB_ONDISK_JOURNAL_SIZE(p_s_sb),
+		      SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		      journal->j_trans_max,
+		      journal->j_max_batch,
+		      journal->j_max_commit_age, journal->j_max_trans_age);
+
+	brelse(bhjh);
+
+	journal->j_list_bitmap_index = 0;
+	journal_list_init(p_s_sb);
+
+	memset(journal->j_list_hash_table, 0,
+	       JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *));
+
+	INIT_LIST_HEAD(&journal->j_dirty_buffers);
+	spin_lock_init(&journal->j_dirty_buffers_lock);
+
+	journal->j_start = 0;
+	journal->j_len = 0;
+	journal->j_len_alloc = 0;
+	atomic_set(&(journal->j_wcount), 0);
+	atomic_set(&(journal->j_async_throttle), 0);
+	journal->j_bcount = 0;
+	journal->j_trans_start_time = 0;
+	journal->j_last = NULL;
+	journal->j_first = NULL;
+	init_waitqueue_head(&(journal->j_join_wait));
+	sema_init(&journal->j_lock, 1);
+	sema_init(&journal->j_flush_sem, 1);
+
+	journal->j_trans_id = 10;
+	journal->j_mount_id = 10;
+	journal->j_state = 0;
+	atomic_set(&(journal->j_jlock), 0);
+	journal->j_cnode_free_list = allocate_cnodes(num_cnodes);
+	journal->j_cnode_free_orig = journal->j_cnode_free_list;
+	journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0;
+	journal->j_cnode_used = 0;
+	journal->j_must_wait = 0;
+
+	init_journal_hash(p_s_sb);
+	jl = journal->j_current_jl;
+	jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);
+	if (!jl->j_list_bitmap) {
+		reiserfs_warning(p_s_sb,
+				 "journal-2005, get_list_bitmap failed for journal list 0");
+		goto free_and_return;
+	}
+	if (journal_read(p_s_sb) < 0) {
+		reiserfs_warning(p_s_sb, "Replay Failure, unable to mount");
+		goto free_and_return;
+	}
+
+	reiserfs_mounted_fs_count++;
+	if (reiserfs_mounted_fs_count <= 1)
+		commit_wq = create_workqueue("reiserfs");
+
+	INIT_WORK(&journal->j_work, flush_async_commits, p_s_sb);
+	return 0;
+      free_and_return:
+	free_journal_ram(p_s_sb);
+	return 1;
 }
 
 /*
@@ -2534,96 +2786,102 @@ int journal_init(struct super_block *p_s_sb, const char * j_dev_name, int old_fo
 ** be used by delete to make sure they don't write more than can fit inside a single
 ** transaction
 */
-int journal_transaction_should_end(struct reiserfs_transaction_handle *th, int new_alloc) {
-  struct reiserfs_journal *journal = SB_JOURNAL (th->t_super);
-  time_t now = get_seconds() ;
-  /* cannot restart while nested */
-  BUG_ON (!th->t_trans_id);
-  if (th->t_refcount > 1)
-    return 0 ;
-  if ( journal->j_must_wait > 0 ||
-       (journal->j_len_alloc + new_alloc) >= journal->j_max_batch ||
-       atomic_read(&(journal->j_jlock)) ||
-      (now - journal->j_trans_start_time) > journal->j_max_trans_age ||
-       journal->j_cnode_free < (journal->j_trans_max * 3)) {
-    return 1 ;
-  }
-  return 0 ;
+int journal_transaction_should_end(struct reiserfs_transaction_handle *th,
+				   int new_alloc)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(th->t_super);
+	time_t now = get_seconds();
+	/* cannot restart while nested */
+	BUG_ON(!th->t_trans_id);
+	if (th->t_refcount > 1)
+		return 0;
+	if (journal->j_must_wait > 0 ||
+	    (journal->j_len_alloc + new_alloc) >= journal->j_max_batch ||
+	    atomic_read(&(journal->j_jlock)) ||
+	    (now - journal->j_trans_start_time) > journal->j_max_trans_age ||
+	    journal->j_cnode_free < (journal->j_trans_max * 3)) {
+		return 1;
+	}
+	return 0;
 }
 
 /* this must be called inside a transaction, and requires the 
 ** kernel_lock to be held
 */
-void reiserfs_block_writes(struct reiserfs_transaction_handle *th) {
-    struct reiserfs_journal *journal = SB_JOURNAL (th->t_super);
-    BUG_ON (!th->t_trans_id);
-    journal->j_must_wait = 1 ;
-    set_bit(J_WRITERS_BLOCKED, &journal->j_state) ;
-    return ;
+void reiserfs_block_writes(struct reiserfs_transaction_handle *th)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(th->t_super);
+	BUG_ON(!th->t_trans_id);
+	journal->j_must_wait = 1;
+	set_bit(J_WRITERS_BLOCKED, &journal->j_state);
+	return;
 }
 
 /* this must be called without a transaction started, and does not
 ** require BKL
 */
-void reiserfs_allow_writes(struct super_block *s) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    clear_bit(J_WRITERS_BLOCKED, &journal->j_state) ;
-    wake_up(&journal->j_join_wait) ;
+void reiserfs_allow_writes(struct super_block *s)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	clear_bit(J_WRITERS_BLOCKED, &journal->j_state);
+	wake_up(&journal->j_join_wait);
 }
 
 /* this must be called without a transaction started, and does not
 ** require BKL
 */
-void reiserfs_wait_on_write_block(struct super_block *s) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    wait_event(journal->j_join_wait,
-               !test_bit(J_WRITERS_BLOCKED, &journal->j_state)) ;
-}
-
-static void queue_log_writer(struct super_block *s) {
-    wait_queue_t wait;
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    set_bit(J_WRITERS_QUEUED, &journal->j_state);
-
-    /*
-     * we don't want to use wait_event here because
-     * we only want to wait once.
-     */
-    init_waitqueue_entry(&wait, current);
-    add_wait_queue(&journal->j_join_wait, &wait);
-    set_current_state(TASK_UNINTERRUPTIBLE);
-    if (test_bit(J_WRITERS_QUEUED, &journal->j_state))
-        schedule();
-    current->state = TASK_RUNNING;
-    remove_wait_queue(&journal->j_join_wait, &wait);
-}
-
-static void wake_queued_writers(struct super_block *s) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    if (test_and_clear_bit(J_WRITERS_QUEUED, &journal->j_state))
-        wake_up(&journal->j_join_wait);
-}
-
-static void let_transaction_grow(struct super_block *sb,
-                                 unsigned long trans_id)
-{
-    struct reiserfs_journal *journal = SB_JOURNAL (sb);
-    unsigned long bcount = journal->j_bcount;
-    while(1) {
+void reiserfs_wait_on_write_block(struct super_block *s)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	wait_event(journal->j_join_wait,
+		   !test_bit(J_WRITERS_BLOCKED, &journal->j_state));
+}
+
+static void queue_log_writer(struct super_block *s)
+{
+	wait_queue_t wait;
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	set_bit(J_WRITERS_QUEUED, &journal->j_state);
+
+	/*
+	 * we don't want to use wait_event here because
+	 * we only want to wait once.
+	 */
+	init_waitqueue_entry(&wait, current);
+	add_wait_queue(&journal->j_join_wait, &wait);
 	set_current_state(TASK_UNINTERRUPTIBLE);
-	schedule_timeout(1);
-	journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
-        while ((atomic_read(&journal->j_wcount) > 0 ||
-	        atomic_read(&journal->j_jlock)) &&
-	       journal->j_trans_id == trans_id) {
-	    queue_log_writer(sb);
+	if (test_bit(J_WRITERS_QUEUED, &journal->j_state))
+		schedule();
+	current->state = TASK_RUNNING;
+	remove_wait_queue(&journal->j_join_wait, &wait);
+}
+
+static void wake_queued_writers(struct super_block *s)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	if (test_and_clear_bit(J_WRITERS_QUEUED, &journal->j_state))
+		wake_up(&journal->j_join_wait);
+}
+
+static void let_transaction_grow(struct super_block *sb, unsigned long trans_id)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	unsigned long bcount = journal->j_bcount;
+	while (1) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(1);
+		journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
+		while ((atomic_read(&journal->j_wcount) > 0 ||
+			atomic_read(&journal->j_jlock)) &&
+		       journal->j_trans_id == trans_id) {
+			queue_log_writer(sb);
+		}
+		if (journal->j_trans_id != trans_id)
+			break;
+		if (bcount == journal->j_bcount)
+			break;
+		bcount = journal->j_bcount;
 	}
-	if (journal->j_trans_id != trans_id)
-	    break;
-	if (bcount == journal->j_bcount)
-	    break;
-	bcount = journal->j_bcount;
-    }
 }
 
 /* join == true if you must join an existing transaction.
@@ -2632,224 +2890,244 @@ static void let_transaction_grow(struct super_block *sb,
 ** this will block until the transaction is joinable.  send the number of blocks you
 ** expect to use in nblocks.
 */
-static int do_journal_begin_r(struct reiserfs_transaction_handle *th, struct super_block * p_s_sb,unsigned long nblocks,int join) {
-  time_t now = get_seconds() ;
-  int old_trans_id  ;
-  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
-  struct reiserfs_transaction_handle myth;
-  int sched_count = 0;
-  int retval;
-
-  reiserfs_check_lock_depth(p_s_sb, "journal_begin") ;
-  if (nblocks > journal->j_trans_max)
-	BUG();
-
-  PROC_INFO_INC( p_s_sb, journal.journal_being );
-  /* set here for journal_join */
-  th->t_refcount = 1;
-  th->t_super = p_s_sb ;
-
-relock:
-  lock_journal(p_s_sb) ;
-  if (join != JBEGIN_ABORT && reiserfs_is_journal_aborted (journal)) {
-    unlock_journal (p_s_sb);
-    retval = journal->j_errno;
-    goto out_fail;
-  }
-  journal->j_bcount++;
-
-  if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
-    unlock_journal(p_s_sb) ;
-    reiserfs_wait_on_write_block(p_s_sb) ;
-    PROC_INFO_INC( p_s_sb, journal.journal_relock_writers );
-    goto relock ;
-  }
-  now = get_seconds();
-
-  /* if there is no room in the journal OR
-  ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning 
-  ** we don't sleep if there aren't other writers
-  */
-
-  if ( (!join && journal->j_must_wait > 0) ||
-     ( !join && (journal->j_len_alloc + nblocks + 2) >= journal->j_max_batch) ||
-     (!join && atomic_read(&journal->j_wcount) > 0 && journal->j_trans_start_time > 0 &&
-      (now - journal->j_trans_start_time) > journal->j_max_trans_age) ||
-     (!join && atomic_read(&journal->j_jlock)) ||
-     (!join && journal->j_cnode_free < (journal->j_trans_max * 3))) {
-
-    old_trans_id = journal->j_trans_id;
-    unlock_journal(p_s_sb) ; /* allow others to finish this transaction */
-
-    if (!join && (journal->j_len_alloc + nblocks + 2) >=
-        journal->j_max_batch &&
-	((journal->j_len + nblocks + 2) * 100) < (journal->j_len_alloc * 75))
-    {
-	if (atomic_read(&journal->j_wcount) > 10) {
-	    sched_count++;
-	    queue_log_writer(p_s_sb);
-	    goto relock;
-	}
-    }
-    /* don't mess with joining the transaction if all we have to do is
-     * wait for someone else to do a commit
-     */
-    if (atomic_read(&journal->j_jlock)) {
-	while (journal->j_trans_id == old_trans_id &&
-	       atomic_read(&journal->j_jlock)) {
-	    queue_log_writer(p_s_sb);
-        }
-	goto relock;
-    }
-    retval = journal_join(&myth, p_s_sb, 1) ;
-    if (retval)
-        goto out_fail;
-
-    /* someone might have ended the transaction while we joined */
-    if (old_trans_id != journal->j_trans_id) {
-        retval = do_journal_end(&myth, p_s_sb, 1, 0) ;
-    } else {
-        retval = do_journal_end(&myth, p_s_sb, 1, COMMIT_NOW) ;
-    }
-
-    if (retval)
-        goto out_fail;
-
-    PROC_INFO_INC( p_s_sb, journal.journal_relock_wcount );
-    goto relock ;
-  }
-  /* we are the first writer, set trans_id */
-  if (journal->j_trans_start_time == 0) {
-    journal->j_trans_start_time = get_seconds();
-  }
-  atomic_inc(&(journal->j_wcount)) ;
-  journal->j_len_alloc += nblocks ;
-  th->t_blocks_logged = 0 ;
-  th->t_blocks_allocated = nblocks ;
-  th->t_trans_id = journal->j_trans_id ;
-  unlock_journal(p_s_sb) ;
-  INIT_LIST_HEAD (&th->t_list);
-  get_fs_excl();
-  return 0 ;
-
-out_fail:
-  memset (th, 0, sizeof (*th));
-  /* Re-set th->t_super, so we can properly keep track of how many
-   * persistent transactions there are. We need to do this so if this
-   * call is part of a failed restart_transaction, we can free it later */
-  th->t_super = p_s_sb;
-  return retval;
-}
-
-struct reiserfs_transaction_handle *
-reiserfs_persistent_transaction(struct super_block *s, int nblocks) {
-    int ret ;
-    struct reiserfs_transaction_handle *th ;
-
-    /* if we're nesting into an existing transaction.  It will be
-    ** persistent on its own
-    */
-    if (reiserfs_transaction_running(s)) {
-        th = current->journal_info ;
-	th->t_refcount++ ;
-	if (th->t_refcount < 2) {
-	    BUG() ;
-	}
-	return th ;
-    }
-    th = reiserfs_kmalloc(sizeof(struct reiserfs_transaction_handle), GFP_NOFS, s) ;
-    if (!th)
-       return NULL;
-    ret = journal_begin(th, s, nblocks) ;
-    if (ret) {
-	reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle), s) ;
-        return NULL;
-    }
-
-    SB_JOURNAL(s)->j_persistent_trans++;
-    return th ;
-}
-
-int
-reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th) {
-    struct super_block *s = th->t_super;
-    int ret = 0;
-    if (th->t_trans_id)
-        ret = journal_end(th, th->t_super, th->t_blocks_allocated);
-    else
-        ret = -EIO;
-    if (th->t_refcount == 0) {
-        SB_JOURNAL(s)->j_persistent_trans--;
-	reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle), s) ;
-    }
-    return ret;
-}
-
-static int journal_join(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
-  struct reiserfs_transaction_handle *cur_th = current->journal_info;
-
-  /* this keeps do_journal_end from NULLing out the current->journal_info
-  ** pointer
-  */
-  th->t_handle_save = cur_th ;
-  if (cur_th && cur_th->t_refcount > 1) {
-      BUG() ;
-  }
-  return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_JOIN) ;
-}
-
-int journal_join_abort(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
-  struct reiserfs_transaction_handle *cur_th = current->journal_info;
-
-  /* this keeps do_journal_end from NULLing out the current->journal_info
-  ** pointer
-  */
-  th->t_handle_save = cur_th ;
-  if (cur_th && cur_th->t_refcount > 1) {
-      BUG() ;
-  }
-  return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_ABORT) ;
-}
-
-int journal_begin(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, unsigned long nblocks) {
-    struct reiserfs_transaction_handle *cur_th = current->journal_info ;
-    int ret ;
-
-    th->t_handle_save = NULL ;
-    if (cur_th) {
-	/* we are nesting into the current transaction */
-	if (cur_th->t_super == p_s_sb) {
-              BUG_ON (!cur_th->t_refcount);
-	      cur_th->t_refcount++ ;
-	      memcpy(th, cur_th, sizeof(*th));
-	      if (th->t_refcount <= 1)
-		      reiserfs_warning (p_s_sb, "BAD: refcount <= 1, but journal_info != 0");
-	      return 0;
+static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
+			      struct super_block *p_s_sb, unsigned long nblocks,
+			      int join)
+{
+	time_t now = get_seconds();
+	int old_trans_id;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_transaction_handle myth;
+	int sched_count = 0;
+	int retval;
+
+	reiserfs_check_lock_depth(p_s_sb, "journal_begin");
+	if (nblocks > journal->j_trans_max)
+		BUG();
+
+	PROC_INFO_INC(p_s_sb, journal.journal_being);
+	/* set here for journal_join */
+	th->t_refcount = 1;
+	th->t_super = p_s_sb;
+
+      relock:
+	lock_journal(p_s_sb);
+	if (join != JBEGIN_ABORT && reiserfs_is_journal_aborted(journal)) {
+		unlock_journal(p_s_sb);
+		retval = journal->j_errno;
+		goto out_fail;
+	}
+	journal->j_bcount++;
+
+	if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
+		unlock_journal(p_s_sb);
+		reiserfs_wait_on_write_block(p_s_sb);
+		PROC_INFO_INC(p_s_sb, journal.journal_relock_writers);
+		goto relock;
+	}
+	now = get_seconds();
+
+	/* if there is no room in the journal OR
+	 ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning 
+	 ** we don't sleep if there aren't other writers
+	 */
+
+	if ((!join && journal->j_must_wait > 0) ||
+	    (!join
+	     && (journal->j_len_alloc + nblocks + 2) >= journal->j_max_batch)
+	    || (!join && atomic_read(&journal->j_wcount) > 0
+		&& journal->j_trans_start_time > 0
+		&& (now - journal->j_trans_start_time) >
+		journal->j_max_trans_age) || (!join
+					      && atomic_read(&journal->j_jlock))
+	    || (!join && journal->j_cnode_free < (journal->j_trans_max * 3))) {
+
+		old_trans_id = journal->j_trans_id;
+		unlock_journal(p_s_sb);	/* allow others to finish this transaction */
+
+		if (!join && (journal->j_len_alloc + nblocks + 2) >=
+		    journal->j_max_batch &&
+		    ((journal->j_len + nblocks + 2) * 100) <
+		    (journal->j_len_alloc * 75)) {
+			if (atomic_read(&journal->j_wcount) > 10) {
+				sched_count++;
+				queue_log_writer(p_s_sb);
+				goto relock;
+			}
+		}
+		/* don't mess with joining the transaction if all we have to do is
+		 * wait for someone else to do a commit
+		 */
+		if (atomic_read(&journal->j_jlock)) {
+			while (journal->j_trans_id == old_trans_id &&
+			       atomic_read(&journal->j_jlock)) {
+				queue_log_writer(p_s_sb);
+			}
+			goto relock;
+		}
+		retval = journal_join(&myth, p_s_sb, 1);
+		if (retval)
+			goto out_fail;
+
+		/* someone might have ended the transaction while we joined */
+		if (old_trans_id != journal->j_trans_id) {
+			retval = do_journal_end(&myth, p_s_sb, 1, 0);
+		} else {
+			retval = do_journal_end(&myth, p_s_sb, 1, COMMIT_NOW);
+		}
+
+		if (retval)
+			goto out_fail;
+
+		PROC_INFO_INC(p_s_sb, journal.journal_relock_wcount);
+		goto relock;
+	}
+	/* we are the first writer, set trans_id */
+	if (journal->j_trans_start_time == 0) {
+		journal->j_trans_start_time = get_seconds();
+	}
+	atomic_inc(&(journal->j_wcount));
+	journal->j_len_alloc += nblocks;
+	th->t_blocks_logged = 0;
+	th->t_blocks_allocated = nblocks;
+	th->t_trans_id = journal->j_trans_id;
+	unlock_journal(p_s_sb);
+	INIT_LIST_HEAD(&th->t_list);
+	get_fs_excl();
+	return 0;
+
+      out_fail:
+	memset(th, 0, sizeof(*th));
+	/* Re-set th->t_super, so we can properly keep track of how many
+	 * persistent transactions there are. We need to do this so if this
+	 * call is part of a failed restart_transaction, we can free it later */
+	th->t_super = p_s_sb;
+	return retval;
+}
+
+struct reiserfs_transaction_handle *reiserfs_persistent_transaction(struct
+								    super_block
+								    *s,
+								    int nblocks)
+{
+	int ret;
+	struct reiserfs_transaction_handle *th;
+
+	/* if we're nesting into an existing transaction.  It will be
+	 ** persistent on its own
+	 */
+	if (reiserfs_transaction_running(s)) {
+		th = current->journal_info;
+		th->t_refcount++;
+		if (th->t_refcount < 2) {
+			BUG();
+		}
+		return th;
+	}
+	th = reiserfs_kmalloc(sizeof(struct reiserfs_transaction_handle),
+			      GFP_NOFS, s);
+	if (!th)
+		return NULL;
+	ret = journal_begin(th, s, nblocks);
+	if (ret) {
+		reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle),
+			       s);
+		return NULL;
+	}
+
+	SB_JOURNAL(s)->j_persistent_trans++;
+	return th;
+}
+
+int reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th)
+{
+	struct super_block *s = th->t_super;
+	int ret = 0;
+	if (th->t_trans_id)
+		ret = journal_end(th, th->t_super, th->t_blocks_allocated);
+	else
+		ret = -EIO;
+	if (th->t_refcount == 0) {
+		SB_JOURNAL(s)->j_persistent_trans--;
+		reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle),
+			       s);
+	}
+	return ret;
+}
+
+static int journal_join(struct reiserfs_transaction_handle *th,
+			struct super_block *p_s_sb, unsigned long nblocks)
+{
+	struct reiserfs_transaction_handle *cur_th = current->journal_info;
+
+	/* this keeps do_journal_end from NULLing out the current->journal_info
+	 ** pointer
+	 */
+	th->t_handle_save = cur_th;
+	if (cur_th && cur_th->t_refcount > 1) {
+		BUG();
+	}
+	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_JOIN);
+}
+
+int journal_join_abort(struct reiserfs_transaction_handle *th,
+		       struct super_block *p_s_sb, unsigned long nblocks)
+{
+	struct reiserfs_transaction_handle *cur_th = current->journal_info;
+
+	/* this keeps do_journal_end from NULLing out the current->journal_info
+	 ** pointer
+	 */
+	th->t_handle_save = cur_th;
+	if (cur_th && cur_th->t_refcount > 1) {
+		BUG();
+	}
+	return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_ABORT);
+}
+
+int journal_begin(struct reiserfs_transaction_handle *th,
+		  struct super_block *p_s_sb, unsigned long nblocks)
+{
+	struct reiserfs_transaction_handle *cur_th = current->journal_info;
+	int ret;
+
+	th->t_handle_save = NULL;
+	if (cur_th) {
+		/* we are nesting into the current transaction */
+		if (cur_th->t_super == p_s_sb) {
+			BUG_ON(!cur_th->t_refcount);
+			cur_th->t_refcount++;
+			memcpy(th, cur_th, sizeof(*th));
+			if (th->t_refcount <= 1)
+				reiserfs_warning(p_s_sb,
+						 "BAD: refcount <= 1, but journal_info != 0");
+			return 0;
+		} else {
+			/* we've ended up with a handle from a different filesystem.
+			 ** save it and restore on journal_end.  This should never
+			 ** really happen...
+			 */
+			reiserfs_warning(p_s_sb,
+					 "clm-2100: nesting info a different FS");
+			th->t_handle_save = current->journal_info;
+			current->journal_info = th;
+		}
 	} else {
-	    /* we've ended up with a handle from a different filesystem.
-	    ** save it and restore on journal_end.  This should never
-	    ** really happen...
-	    */
-	    reiserfs_warning(p_s_sb, "clm-2100: nesting info a different FS") ;
-	    th->t_handle_save = current->journal_info ;
-	    current->journal_info = th;
-	}
-    } else {
-	current->journal_info = th;
-    }
-    ret = do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_REG) ;
-    if (current->journal_info != th)
-        BUG() ;
+		current->journal_info = th;
+	}
+	ret = do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_REG);
+	if (current->journal_info != th)
+		BUG();
 
-    /* I guess this boils down to being the reciprocal of clm-2100 above.
-     * If do_journal_begin_r fails, we need to put it back, since journal_end
-     * won't be called to do it. */
-    if (ret)
-        current->journal_info = th->t_handle_save;
-    else
-        BUG_ON (!th->t_refcount);
+	/* I guess this boils down to being the reciprocal of clm-2100 above.
+	 * If do_journal_begin_r fails, we need to put it back, since journal_end
+	 * won't be called to do it. */
+	if (ret)
+		current->journal_info = th->t_handle_save;
+	else
+		BUG_ON(!th->t_refcount);
 
-    return ret ;
+	return ret;
 }
 
 /*
@@ -2861,129 +3139,140 @@ int journal_begin(struct reiserfs_transaction_handle *th, struct super_block  *
 ** 
 ** if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
 */
-int journal_mark_dirty(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, struct buffer_head *bh) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_cnode *cn = NULL;
-  int count_already_incd = 0 ;
-  int prepared = 0 ;
-  BUG_ON (!th->t_trans_id);
-
-  PROC_INFO_INC( p_s_sb, journal.mark_dirty );
-  if (th->t_trans_id != journal->j_trans_id) {
-    reiserfs_panic(th->t_super, "journal-1577: handle trans id %ld != current trans id %ld\n", 
-                   th->t_trans_id, journal->j_trans_id);
-  }
-
-  p_s_sb->s_dirt = 1;
-
-  prepared = test_clear_buffer_journal_prepared (bh);
-  clear_buffer_journal_restore_dirty (bh);
-  /* already in this transaction, we are done */
-  if (buffer_journaled(bh)) {
-    PROC_INFO_INC( p_s_sb, journal.mark_dirty_already );
-    return 0 ;
-  }
-
-  /* this must be turned into a panic instead of a warning.  We can't allow
-  ** a dirty or journal_dirty or locked buffer to be logged, as some changes
-  ** could get to disk too early.  NOT GOOD.
-  */
-  if (!prepared || buffer_dirty(bh)) {
-    reiserfs_warning (p_s_sb, "journal-1777: buffer %llu bad state "
-		      "%cPREPARED %cLOCKED %cDIRTY %cJDIRTY_WAIT",
-		      (unsigned long long)bh->b_blocknr, prepared ? ' ' : '!',
-			    buffer_locked(bh) ? ' ' : '!',
-			    buffer_dirty(bh) ? ' ' : '!',
-			    buffer_journal_dirty(bh) ? ' ' : '!') ;
-  }
-
-  if (atomic_read(&(journal->j_wcount)) <= 0) {
-    reiserfs_warning (p_s_sb, "journal-1409: journal_mark_dirty returning because j_wcount was %d", atomic_read(&(journal->j_wcount))) ;
-    return 1 ;
-  }
-  /* this error means I've screwed up, and we've overflowed the transaction.  
-  ** Nothing can be done here, except make the FS readonly or panic.
-  */ 
-  if (journal->j_len >= journal->j_trans_max) {
-    reiserfs_panic(th->t_super, "journal-1413: journal_mark_dirty: j_len (%lu) is too big\n", journal->j_len) ;
-  }
-
-  if (buffer_journal_dirty(bh)) {
-    count_already_incd = 1 ;
-    PROC_INFO_INC( p_s_sb, journal.mark_dirty_notjournal );
-    clear_buffer_journal_dirty (bh);
-  }
-
-  if (journal->j_len > journal->j_len_alloc) {
-    journal->j_len_alloc = journal->j_len + JOURNAL_PER_BALANCE_CNT ;
-  }
-
-  set_buffer_journaled (bh);
-
-  /* now put this guy on the end */
-  if (!cn) {
-    cn = get_cnode(p_s_sb) ;
-    if (!cn) {
-      reiserfs_panic(p_s_sb, "get_cnode failed!\n"); 
-    }
-
-    if (th->t_blocks_logged == th->t_blocks_allocated) {
-      th->t_blocks_allocated += JOURNAL_PER_BALANCE_CNT ;
-      journal->j_len_alloc += JOURNAL_PER_BALANCE_CNT ;
-    }
-    th->t_blocks_logged++ ;
-    journal->j_len++ ;
-
-    cn->bh = bh ;
-    cn->blocknr = bh->b_blocknr ;
-    cn->sb = p_s_sb;
-    cn->jlist = NULL ;
-    insert_journal_hash(journal->j_hash_table, cn) ;
-    if (!count_already_incd) {
-      get_bh(bh) ;
-    }
-  }
-  cn->next = NULL ;
-  cn->prev = journal->j_last ;
-  cn->bh = bh ;
-  if (journal->j_last) {
-    journal->j_last->next = cn ;
-    journal->j_last = cn ;
-  } else {
-    journal->j_first = cn ;
-    journal->j_last = cn ;
-  }
-  return 0 ;
-}
-
-int journal_end(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
-  if (!current->journal_info && th->t_refcount > 1)
-    reiserfs_warning (p_s_sb, "REISER-NESTING: th NULL, refcount %d",
-                      th->t_refcount);
-
-  if (!th->t_trans_id) {
-    WARN_ON (1);
-    return -EIO;
-  }
-
-  th->t_refcount--;
-  if (th->t_refcount > 0) {
-    struct reiserfs_transaction_handle *cur_th = current->journal_info ;
-
-    /* we aren't allowed to close a nested transaction on a different
-    ** filesystem from the one in the task struct
-    */
-    if (cur_th->t_super != th->t_super)
-      BUG() ;
-
-    if (th != cur_th) {
-      memcpy(current->journal_info, th, sizeof(*th));
-      th->t_trans_id = 0;
-    }
-    return 0;
-  } else {
-    return do_journal_end(th, p_s_sb, nblocks, 0) ;
-  }
+int journal_mark_dirty(struct reiserfs_transaction_handle *th,
+		       struct super_block *p_s_sb, struct buffer_head *bh)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_cnode *cn = NULL;
+	int count_already_incd = 0;
+	int prepared = 0;
+	BUG_ON(!th->t_trans_id);
+
+	PROC_INFO_INC(p_s_sb, journal.mark_dirty);
+	if (th->t_trans_id != journal->j_trans_id) {
+		reiserfs_panic(th->t_super,
+			       "journal-1577: handle trans id %ld != current trans id %ld\n",
+			       th->t_trans_id, journal->j_trans_id);
+	}
+
+	p_s_sb->s_dirt = 1;
+
+	prepared = test_clear_buffer_journal_prepared(bh);
+	clear_buffer_journal_restore_dirty(bh);
+	/* already in this transaction, we are done */
+	if (buffer_journaled(bh)) {
+		PROC_INFO_INC(p_s_sb, journal.mark_dirty_already);
+		return 0;
+	}
+
+	/* this must be turned into a panic instead of a warning.  We can't allow
+	 ** a dirty or journal_dirty or locked buffer to be logged, as some changes
+	 ** could get to disk too early.  NOT GOOD.
+	 */
+	if (!prepared || buffer_dirty(bh)) {
+		reiserfs_warning(p_s_sb, "journal-1777: buffer %llu bad state "
+				 "%cPREPARED %cLOCKED %cDIRTY %cJDIRTY_WAIT",
+				 (unsigned long long)bh->b_blocknr,
+				 prepared ? ' ' : '!',
+				 buffer_locked(bh) ? ' ' : '!',
+				 buffer_dirty(bh) ? ' ' : '!',
+				 buffer_journal_dirty(bh) ? ' ' : '!');
+	}
+
+	if (atomic_read(&(journal->j_wcount)) <= 0) {
+		reiserfs_warning(p_s_sb,
+				 "journal-1409: journal_mark_dirty returning because j_wcount was %d",
+				 atomic_read(&(journal->j_wcount)));
+		return 1;
+	}
+	/* this error means I've screwed up, and we've overflowed the transaction.  
+	 ** Nothing can be done here, except make the FS readonly or panic.
+	 */
+	if (journal->j_len >= journal->j_trans_max) {
+		reiserfs_panic(th->t_super,
+			       "journal-1413: journal_mark_dirty: j_len (%lu) is too big\n",
+			       journal->j_len);
+	}
+
+	if (buffer_journal_dirty(bh)) {
+		count_already_incd = 1;
+		PROC_INFO_INC(p_s_sb, journal.mark_dirty_notjournal);
+		clear_buffer_journal_dirty(bh);
+	}
+
+	if (journal->j_len > journal->j_len_alloc) {
+		journal->j_len_alloc = journal->j_len + JOURNAL_PER_BALANCE_CNT;
+	}
+
+	set_buffer_journaled(bh);
+
+	/* now put this guy on the end */
+	if (!cn) {
+		cn = get_cnode(p_s_sb);
+		if (!cn) {
+			reiserfs_panic(p_s_sb, "get_cnode failed!\n");
+		}
+
+		if (th->t_blocks_logged == th->t_blocks_allocated) {
+			th->t_blocks_allocated += JOURNAL_PER_BALANCE_CNT;
+			journal->j_len_alloc += JOURNAL_PER_BALANCE_CNT;
+		}
+		th->t_blocks_logged++;
+		journal->j_len++;
+
+		cn->bh = bh;
+		cn->blocknr = bh->b_blocknr;
+		cn->sb = p_s_sb;
+		cn->jlist = NULL;
+		insert_journal_hash(journal->j_hash_table, cn);
+		if (!count_already_incd) {
+			get_bh(bh);
+		}
+	}
+	cn->next = NULL;
+	cn->prev = journal->j_last;
+	cn->bh = bh;
+	if (journal->j_last) {
+		journal->j_last->next = cn;
+		journal->j_last = cn;
+	} else {
+		journal->j_first = cn;
+		journal->j_last = cn;
+	}
+	return 0;
+}
+
+int journal_end(struct reiserfs_transaction_handle *th,
+		struct super_block *p_s_sb, unsigned long nblocks)
+{
+	if (!current->journal_info && th->t_refcount > 1)
+		reiserfs_warning(p_s_sb, "REISER-NESTING: th NULL, refcount %d",
+				 th->t_refcount);
+
+	if (!th->t_trans_id) {
+		WARN_ON(1);
+		return -EIO;
+	}
+
+	th->t_refcount--;
+	if (th->t_refcount > 0) {
+		struct reiserfs_transaction_handle *cur_th =
+		    current->journal_info;
+
+		/* we aren't allowed to close a nested transaction on a different
+		 ** filesystem from the one in the task struct
+		 */
+		if (cur_th->t_super != th->t_super)
+			BUG();
+
+		if (th != cur_th) {
+			memcpy(current->journal_info, th, sizeof(*th));
+			th->t_trans_id = 0;
+		}
+		return 0;
+	} else {
+		return do_journal_end(th, p_s_sb, nblocks, 0);
+	}
 }
 
 /* removes from the current transaction, relsing and descrementing any counters.  
@@ -2993,47 +3282,51 @@ int journal_end(struct reiserfs_transaction_handle *th, struct super_block *p_s_
 **
 ** returns 1 if it cleaned and relsed the buffer. 0 otherwise
 */
-static int remove_from_transaction(struct super_block *p_s_sb, b_blocknr_t blocknr, int already_cleaned) {
-  struct buffer_head *bh ;
-  struct reiserfs_journal_cnode *cn ;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  int ret = 0;
-
-  cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr) ;
-  if (!cn || !cn->bh) {
-    return ret ;
-  }
-  bh = cn->bh ;
-  if (cn->prev) {
-    cn->prev->next = cn->next ;
-  }
-  if (cn->next) {
-    cn->next->prev = cn->prev ;
-  }
-  if (cn == journal->j_first) {
-    journal->j_first = cn->next ;
-  }
-  if (cn == journal->j_last) {
-    journal->j_last = cn->prev ;
-  }
-  if (bh)
-	remove_journal_hash(p_s_sb, journal->j_hash_table, NULL, bh->b_blocknr, 0) ;
-  clear_buffer_journaled  (bh); /* don't log this one */
-
-  if (!already_cleaned) {
-    clear_buffer_journal_dirty (bh);
-    clear_buffer_dirty(bh);
-    clear_buffer_journal_test (bh);
-    put_bh(bh) ;
-    if (atomic_read(&(bh->b_count)) < 0) {
-      reiserfs_warning (p_s_sb, "journal-1752: remove from trans, b_count < 0");
-    }
-    ret = 1 ;
-  }
-  journal->j_len-- ;
-  journal->j_len_alloc-- ;
-  free_cnode(p_s_sb, cn) ;
-  return ret ;
+static int remove_from_transaction(struct super_block *p_s_sb,
+				   b_blocknr_t blocknr, int already_cleaned)
+{
+	struct buffer_head *bh;
+	struct reiserfs_journal_cnode *cn;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	int ret = 0;
+
+	cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
+	if (!cn || !cn->bh) {
+		return ret;
+	}
+	bh = cn->bh;
+	if (cn->prev) {
+		cn->prev->next = cn->next;
+	}
+	if (cn->next) {
+		cn->next->prev = cn->prev;
+	}
+	if (cn == journal->j_first) {
+		journal->j_first = cn->next;
+	}
+	if (cn == journal->j_last) {
+		journal->j_last = cn->prev;
+	}
+	if (bh)
+		remove_journal_hash(p_s_sb, journal->j_hash_table, NULL,
+				    bh->b_blocknr, 0);
+	clear_buffer_journaled(bh);	/* don't log this one */
+
+	if (!already_cleaned) {
+		clear_buffer_journal_dirty(bh);
+		clear_buffer_dirty(bh);
+		clear_buffer_journal_test(bh);
+		put_bh(bh);
+		if (atomic_read(&(bh->b_count)) < 0) {
+			reiserfs_warning(p_s_sb,
+					 "journal-1752: remove from trans, b_count < 0");
+		}
+		ret = 1;
+	}
+	journal->j_len--;
+	journal->j_len_alloc--;
+	free_cnode(p_s_sb, cn);
+	return ret;
 }
 
 /*
@@ -3046,120 +3339,129 @@ static int remove_from_transaction(struct super_block *p_s_sb, b_blocknr_t block
 ** blocks for a given transaction on disk
 **
 */
-static int can_dirty(struct reiserfs_journal_cnode *cn) {
-  struct super_block *sb = cn->sb;
-  b_blocknr_t blocknr = cn->blocknr  ;
-  struct reiserfs_journal_cnode *cur = cn->hprev ;
-  int can_dirty = 1 ;
-  
-  /* first test hprev.  These are all newer than cn, so any node here
-  ** with the same block number and dev means this node can't be sent
-  ** to disk right now.
-  */
-  while(cur && can_dirty) {
-    if (cur->jlist && cur->bh && cur->blocknr && cur->sb == sb && 
-        cur->blocknr == blocknr) {
-      can_dirty = 0 ;
-    }
-    cur = cur->hprev ;
-  }
-  /* then test hnext.  These are all older than cn.  As long as they
-  ** are committed to the log, it is safe to write cn to disk
-  */
-  cur = cn->hnext ;
-  while(cur && can_dirty) {
-    if (cur->jlist && cur->jlist->j_len > 0 && 
-        atomic_read(&(cur->jlist->j_commit_left)) > 0 && cur->bh && 
-        cur->blocknr && cur->sb == sb && cur->blocknr == blocknr) {
-      can_dirty = 0 ;
-    }
-    cur = cur->hnext ;
-  }
-  return can_dirty ;
+static int can_dirty(struct reiserfs_journal_cnode *cn)
+{
+	struct super_block *sb = cn->sb;
+	b_blocknr_t blocknr = cn->blocknr;
+	struct reiserfs_journal_cnode *cur = cn->hprev;
+	int can_dirty = 1;
+
+	/* first test hprev.  These are all newer than cn, so any node here
+	 ** with the same block number and dev means this node can't be sent
+	 ** to disk right now.
+	 */
+	while (cur && can_dirty) {
+		if (cur->jlist && cur->bh && cur->blocknr && cur->sb == sb &&
+		    cur->blocknr == blocknr) {
+			can_dirty = 0;
+		}
+		cur = cur->hprev;
+	}
+	/* then test hnext.  These are all older than cn.  As long as they
+	 ** are committed to the log, it is safe to write cn to disk
+	 */
+	cur = cn->hnext;
+	while (cur && can_dirty) {
+		if (cur->jlist && cur->jlist->j_len > 0 &&
+		    atomic_read(&(cur->jlist->j_commit_left)) > 0 && cur->bh &&
+		    cur->blocknr && cur->sb == sb && cur->blocknr == blocknr) {
+			can_dirty = 0;
+		}
+		cur = cur->hnext;
+	}
+	return can_dirty;
 }
 
 /* syncs the commit blocks, but does not force the real buffers to disk
 ** will wait until the current transaction is done/commited before returning 
 */
-int journal_end_sync(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+int journal_end_sync(struct reiserfs_transaction_handle *th,
+		     struct super_block *p_s_sb, unsigned long nblocks)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
 
-  BUG_ON (!th->t_trans_id);
-  /* you can sync while nested, very, very bad */
-  if (th->t_refcount > 1) {
-    BUG() ;
-  }
-  if (journal->j_len == 0) {
-    reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
-    journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
-  }
-  return do_journal_end(th, p_s_sb, nblocks, COMMIT_NOW | WAIT) ;
+	BUG_ON(!th->t_trans_id);
+	/* you can sync while nested, very, very bad */
+	if (th->t_refcount > 1) {
+		BUG();
+	}
+	if (journal->j_len == 0) {
+		reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb),
+					     1);
+		journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb));
+	}
+	return do_journal_end(th, p_s_sb, nblocks, COMMIT_NOW | WAIT);
 }
 
 /*
 ** writeback the pending async commits to disk
 */
-static void flush_async_commits(void *p) {
-  struct super_block *p_s_sb = p;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_list *jl;
-  struct list_head *entry;
-
-  lock_kernel();
-  if (!list_empty(&journal->j_journal_list)) {
-      /* last entry is the youngest, commit it and you get everything */
-      entry = journal->j_journal_list.prev;
-      jl = JOURNAL_LIST_ENTRY(entry);
-      flush_commit_list(p_s_sb, jl, 1);
-  }
-  unlock_kernel();
-  /*
-   * this is a little racey, but there's no harm in missing
-   * the filemap_fdata_write
-   */
-  if (!atomic_read(&journal->j_async_throttle) && !reiserfs_is_journal_aborted (journal)) {
-      atomic_inc(&journal->j_async_throttle);
-      filemap_fdatawrite(p_s_sb->s_bdev->bd_inode->i_mapping);
-      atomic_dec(&journal->j_async_throttle);
-  }
+static void flush_async_commits(void *p)
+{
+	struct super_block *p_s_sb = p;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_list *jl;
+	struct list_head *entry;
+
+	lock_kernel();
+	if (!list_empty(&journal->j_journal_list)) {
+		/* last entry is the youngest, commit it and you get everything */
+		entry = journal->j_journal_list.prev;
+		jl = JOURNAL_LIST_ENTRY(entry);
+		flush_commit_list(p_s_sb, jl, 1);
+	}
+	unlock_kernel();
+	/*
+	 * this is a little racey, but there's no harm in missing
+	 * the filemap_fdata_write
+	 */
+	if (!atomic_read(&journal->j_async_throttle)
+	    && !reiserfs_is_journal_aborted(journal)) {
+		atomic_inc(&journal->j_async_throttle);
+		filemap_fdatawrite(p_s_sb->s_bdev->bd_inode->i_mapping);
+		atomic_dec(&journal->j_async_throttle);
+	}
 }
 
 /*
 ** flushes any old transactions to disk
 ** ends the current transaction if it is too old
 */
-int reiserfs_flush_old_commits(struct super_block *p_s_sb) {
-    time_t now ;
-    struct reiserfs_transaction_handle th ;
-    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-
-    now = get_seconds();
-    /* safety check so we don't flush while we are replaying the log during
-     * mount
-     */
-    if (list_empty(&journal->j_journal_list)) {
-	return 0  ;
-    }
-
-    /* check the current transaction.  If there are no writers, and it is
-     * too old, finish it, and force the commit blocks to disk
-     */
-    if (atomic_read(&journal->j_wcount) <= 0 &&
-        journal->j_trans_start_time > 0 &&
-        journal->j_len > 0 &&
-        (now - journal->j_trans_start_time) > journal->j_max_trans_age)
-    {
-	if (!journal_join(&th, p_s_sb, 1)) {
-            reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
-            journal_mark_dirty(&th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
-
-            /* we're only being called from kreiserfsd, it makes no sense to do
-            ** an async commit so that kreiserfsd can do it later
-            */
-            do_journal_end(&th, p_s_sb,1, COMMIT_NOW | WAIT) ;
-        }
-    }
-    return p_s_sb->s_dirt;
+int reiserfs_flush_old_commits(struct super_block *p_s_sb)
+{
+	time_t now;
+	struct reiserfs_transaction_handle th;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+
+	now = get_seconds();
+	/* safety check so we don't flush while we are replaying the log during
+	 * mount
+	 */
+	if (list_empty(&journal->j_journal_list)) {
+		return 0;
+	}
+
+	/* check the current transaction.  If there are no writers, and it is
+	 * too old, finish it, and force the commit blocks to disk
+	 */
+	if (atomic_read(&journal->j_wcount) <= 0 &&
+	    journal->j_trans_start_time > 0 &&
+	    journal->j_len > 0 &&
+	    (now - journal->j_trans_start_time) > journal->j_max_trans_age) {
+		if (!journal_join(&th, p_s_sb, 1)) {
+			reiserfs_prepare_for_journal(p_s_sb,
+						     SB_BUFFER_WITH_SB(p_s_sb),
+						     1);
+			journal_mark_dirty(&th, p_s_sb,
+					   SB_BUFFER_WITH_SB(p_s_sb));
+
+			/* we're only being called from kreiserfsd, it makes no sense to do
+			 ** an async commit so that kreiserfsd can do it later
+			 */
+			do_journal_end(&th, p_s_sb, 1, COMMIT_NOW | WAIT);
+		}
+	}
+	return p_s_sb->s_dirt;
 }
 
 /*
@@ -3173,101 +3475,108 @@ int reiserfs_flush_old_commits(struct super_block *p_s_sb) {
 ** 
 ** Note, we can't allow the journal_end to proceed while there are still writers in the log.
 */
-static int check_journal_end(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, 
-                             unsigned long nblocks, int flags) {
-
-  time_t now ;
-  int flush = flags & FLUSH_ALL ;
-  int commit_now = flags & COMMIT_NOW ;
-  int wait_on_commit = flags & WAIT ;
-  struct reiserfs_journal_list *jl;
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-
-  BUG_ON (!th->t_trans_id);
-
-  if (th->t_trans_id != journal->j_trans_id) {
-    reiserfs_panic(th->t_super, "journal-1577: handle trans id %ld != current trans id %ld\n", 
-                   th->t_trans_id, journal->j_trans_id);
-  }
-
-  journal->j_len_alloc -= (th->t_blocks_allocated - th->t_blocks_logged) ;
-  if (atomic_read(&(journal->j_wcount)) > 0) { /* <= 0 is allowed.  unmounting might not call begin */
-    atomic_dec(&(journal->j_wcount)) ;
-  }
-
-  /* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released 
-  ** will be dealt with by next transaction that actually writes something, but should be taken
-  ** care of in this trans
-  */
-  if (journal->j_len == 0) {
-    BUG();
-  }
-  /* if wcount > 0, and we are called to with flush or commit_now,
-  ** we wait on j_join_wait.  We will wake up when the last writer has
-  ** finished the transaction, and started it on its way to the disk.
-  ** Then, we flush the commit or journal list, and just return 0 
-  ** because the rest of journal end was already done for this transaction.
-  */
-  if (atomic_read(&(journal->j_wcount)) > 0) {
-    if (flush || commit_now) {
-      unsigned trans_id ;
-
-      jl = journal->j_current_jl;
-      trans_id = jl->j_trans_id;
-      if (wait_on_commit)
-        jl->j_state |= LIST_COMMIT_PENDING;
-      atomic_set(&(journal->j_jlock), 1) ;
-      if (flush) {
-        journal->j_next_full_flush = 1 ;
-      }
-      unlock_journal(p_s_sb) ;
-
-      /* sleep while the current transaction is still j_jlocked */
-      while(journal->j_trans_id == trans_id) {
-	if (atomic_read(&journal->j_jlock)) {
-	    queue_log_writer(p_s_sb);
-        } else {
-	    lock_journal(p_s_sb);
-	    if (journal->j_trans_id == trans_id) {
-	        atomic_set(&(journal->j_jlock), 1) ;
-	    }
-	    unlock_journal(p_s_sb);
-	}
-      }
-      if (journal->j_trans_id == trans_id) {
-          BUG();
-      }
-      if (commit_now && journal_list_still_alive(p_s_sb, trans_id) &&
-          wait_on_commit)
-      {
-	  flush_commit_list(p_s_sb, jl, 1) ;
-      }
-      return 0 ;
-    } 
-    unlock_journal(p_s_sb) ;
-    return 0 ;
-  }
-
-  /* deal with old transactions where we are the last writers */
-  now = get_seconds();
-  if ((now - journal->j_trans_start_time) > journal->j_max_trans_age) {
-    commit_now = 1 ;
-    journal->j_next_async_flush = 1 ;
-  }
-  /* don't batch when someone is waiting on j_join_wait */
-  /* don't batch when syncing the commit or flushing the whole trans */
-  if (!(journal->j_must_wait > 0) && !(atomic_read(&(journal->j_jlock))) && !flush && !commit_now &&
-      (journal->j_len < journal->j_max_batch)  &&
-      journal->j_len_alloc < journal->j_max_batch && journal->j_cnode_free > (journal->j_trans_max * 3)) {
-    journal->j_bcount++ ;
-    unlock_journal(p_s_sb) ;
-    return 0 ;
-  }
-
-  if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
-    reiserfs_panic(p_s_sb, "journal-003: journal_end: j_start (%ld) is too high\n", journal->j_start) ;
-  }
-  return 1 ;
+static int check_journal_end(struct reiserfs_transaction_handle *th,
+			     struct super_block *p_s_sb, unsigned long nblocks,
+			     int flags)
+{
+
+	time_t now;
+	int flush = flags & FLUSH_ALL;
+	int commit_now = flags & COMMIT_NOW;
+	int wait_on_commit = flags & WAIT;
+	struct reiserfs_journal_list *jl;
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+
+	BUG_ON(!th->t_trans_id);
+
+	if (th->t_trans_id != journal->j_trans_id) {
+		reiserfs_panic(th->t_super,
+			       "journal-1577: handle trans id %ld != current trans id %ld\n",
+			       th->t_trans_id, journal->j_trans_id);
+	}
+
+	journal->j_len_alloc -= (th->t_blocks_allocated - th->t_blocks_logged);
+	if (atomic_read(&(journal->j_wcount)) > 0) {	/* <= 0 is allowed.  unmounting might not call begin */
+		atomic_dec(&(journal->j_wcount));
+	}
+
+	/* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released 
+	 ** will be dealt with by next transaction that actually writes something, but should be taken
+	 ** care of in this trans
+	 */
+	if (journal->j_len == 0) {
+		BUG();
+	}
+	/* if wcount > 0, and we are called to with flush or commit_now,
+	 ** we wait on j_join_wait.  We will wake up when the last writer has
+	 ** finished the transaction, and started it on its way to the disk.
+	 ** Then, we flush the commit or journal list, and just return 0 
+	 ** because the rest of journal end was already done for this transaction.
+	 */
+	if (atomic_read(&(journal->j_wcount)) > 0) {
+		if (flush || commit_now) {
+			unsigned trans_id;
+
+			jl = journal->j_current_jl;
+			trans_id = jl->j_trans_id;
+			if (wait_on_commit)
+				jl->j_state |= LIST_COMMIT_PENDING;
+			atomic_set(&(journal->j_jlock), 1);
+			if (flush) {
+				journal->j_next_full_flush = 1;
+			}
+			unlock_journal(p_s_sb);
+
+			/* sleep while the current transaction is still j_jlocked */
+			while (journal->j_trans_id == trans_id) {
+				if (atomic_read(&journal->j_jlock)) {
+					queue_log_writer(p_s_sb);
+				} else {
+					lock_journal(p_s_sb);
+					if (journal->j_trans_id == trans_id) {
+						atomic_set(&(journal->j_jlock),
+							   1);
+					}
+					unlock_journal(p_s_sb);
+				}
+			}
+			if (journal->j_trans_id == trans_id) {
+				BUG();
+			}
+			if (commit_now
+			    && journal_list_still_alive(p_s_sb, trans_id)
+			    && wait_on_commit) {
+				flush_commit_list(p_s_sb, jl, 1);
+			}
+			return 0;
+		}
+		unlock_journal(p_s_sb);
+		return 0;
+	}
+
+	/* deal with old transactions where we are the last writers */
+	now = get_seconds();
+	if ((now - journal->j_trans_start_time) > journal->j_max_trans_age) {
+		commit_now = 1;
+		journal->j_next_async_flush = 1;
+	}
+	/* don't batch when someone is waiting on j_join_wait */
+	/* don't batch when syncing the commit or flushing the whole trans */
+	if (!(journal->j_must_wait > 0) && !(atomic_read(&(journal->j_jlock)))
+	    && !flush && !commit_now && (journal->j_len < journal->j_max_batch)
+	    && journal->j_len_alloc < journal->j_max_batch
+	    && journal->j_cnode_free > (journal->j_trans_max * 3)) {
+		journal->j_bcount++;
+		unlock_journal(p_s_sb);
+		return 0;
+	}
+
+	if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+		reiserfs_panic(p_s_sb,
+			       "journal-003: journal_end: j_start (%ld) is too high\n",
+			       journal->j_start);
+	}
+	return 1;
 }
 
 /*
@@ -3284,83 +3593,95 @@ static int check_journal_end(struct reiserfs_transaction_handle *th, struct supe
 **
 ** Then remove it from the current transaction, decrementing any counters and filing it on the clean list.
 */
-int journal_mark_freed(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, b_blocknr_t blocknr) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_cnode *cn = NULL ;
-  struct buffer_head *bh = NULL ;
-  struct reiserfs_list_bitmap *jb = NULL ;
-  int cleaned = 0 ;
-  BUG_ON (!th->t_trans_id);
-
-  cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
-  if (cn && cn->bh) {
-      bh = cn->bh ;
-      get_bh(bh) ;
-  }
-  /* if it is journal new, we just remove it from this transaction */
-  if (bh && buffer_journal_new(bh)) {
-    clear_buffer_journal_new (bh);
-    clear_prepared_bits(bh) ;
-    reiserfs_clean_and_file_buffer(bh) ;
-    cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned) ;
-  } else {
-    /* set the bit for this block in the journal bitmap for this transaction */
-    jb = journal->j_current_jl->j_list_bitmap;
-    if (!jb) {
-      reiserfs_panic(p_s_sb, "journal-1702: journal_mark_freed, journal_list_bitmap is NULL\n") ;
-    }
-    set_bit_in_list_bitmap(p_s_sb, blocknr, jb) ;
-
-    /* Note, the entire while loop is not allowed to schedule.  */
-
-    if (bh) {
-      clear_prepared_bits(bh) ;
-      reiserfs_clean_and_file_buffer(bh) ;
-    }
-    cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned) ;
-
-    /* find all older transactions with this block, make sure they don't try to write it out */
-    cn = get_journal_hash_dev(p_s_sb,journal->j_list_hash_table,  blocknr) ;
-    while (cn) {
-      if (p_s_sb == cn->sb && blocknr == cn->blocknr) {
-	set_bit(BLOCK_FREED, &cn->state) ;
-	if (cn->bh) {
-	  if (!cleaned) {
-	    /* remove_from_transaction will brelse the buffer if it was 
-	    ** in the current trans
-	    */
-            clear_buffer_journal_dirty (cn->bh);
-	    clear_buffer_dirty(cn->bh);
-	    clear_buffer_journal_test(cn->bh);
-	    cleaned = 1 ;
-	    put_bh(cn->bh) ;
-	    if (atomic_read(&(cn->bh->b_count)) < 0) {
-	      reiserfs_warning (p_s_sb, "journal-2138: cn->bh->b_count < 0");
-	    }
-	  }
-	  if (cn->jlist) { /* since we are clearing the bh, we MUST dec nonzerolen */
-	    atomic_dec(&(cn->jlist->j_nonzerolen)) ;
-	  }
-	  cn->bh = NULL ; 
-	} 
-      }
-      cn = cn->hnext ;
-    }
-  }
-
-  if (bh) {
-    put_bh(bh) ; /* get_hash grabs the buffer */
-    if (atomic_read(&(bh->b_count)) < 0) {
-      reiserfs_warning (p_s_sb, "journal-2165: bh->b_count < 0");
-    }
-  }
-  return 0 ;
-}
-
-void reiserfs_update_inode_transaction(struct inode *inode) {
-  struct reiserfs_journal *journal = SB_JOURNAL (inode->i_sb);
-  REISERFS_I(inode)->i_jl = journal->j_current_jl;
-  REISERFS_I(inode)->i_trans_id = journal->j_trans_id ;
+int journal_mark_freed(struct reiserfs_transaction_handle *th,
+		       struct super_block *p_s_sb, b_blocknr_t blocknr)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_cnode *cn = NULL;
+	struct buffer_head *bh = NULL;
+	struct reiserfs_list_bitmap *jb = NULL;
+	int cleaned = 0;
+	BUG_ON(!th->t_trans_id);
+
+	cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
+	if (cn && cn->bh) {
+		bh = cn->bh;
+		get_bh(bh);
+	}
+	/* if it is journal new, we just remove it from this transaction */
+	if (bh && buffer_journal_new(bh)) {
+		clear_buffer_journal_new(bh);
+		clear_prepared_bits(bh);
+		reiserfs_clean_and_file_buffer(bh);
+		cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned);
+	} else {
+		/* set the bit for this block in the journal bitmap for this transaction */
+		jb = journal->j_current_jl->j_list_bitmap;
+		if (!jb) {
+			reiserfs_panic(p_s_sb,
+				       "journal-1702: journal_mark_freed, journal_list_bitmap is NULL\n");
+		}
+		set_bit_in_list_bitmap(p_s_sb, blocknr, jb);
+
+		/* Note, the entire while loop is not allowed to schedule.  */
+
+		if (bh) {
+			clear_prepared_bits(bh);
+			reiserfs_clean_and_file_buffer(bh);
+		}
+		cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned);
+
+		/* find all older transactions with this block, make sure they don't try to write it out */
+		cn = get_journal_hash_dev(p_s_sb, journal->j_list_hash_table,
+					  blocknr);
+		while (cn) {
+			if (p_s_sb == cn->sb && blocknr == cn->blocknr) {
+				set_bit(BLOCK_FREED, &cn->state);
+				if (cn->bh) {
+					if (!cleaned) {
+						/* remove_from_transaction will brelse the buffer if it was 
+						 ** in the current trans
+						 */
+						clear_buffer_journal_dirty(cn->
+									   bh);
+						clear_buffer_dirty(cn->bh);
+						clear_buffer_journal_test(cn->
+									  bh);
+						cleaned = 1;
+						put_bh(cn->bh);
+						if (atomic_read
+						    (&(cn->bh->b_count)) < 0) {
+							reiserfs_warning(p_s_sb,
+									 "journal-2138: cn->bh->b_count < 0");
+						}
+					}
+					if (cn->jlist) {	/* since we are clearing the bh, we MUST dec nonzerolen */
+						atomic_dec(&
+							   (cn->jlist->
+							    j_nonzerolen));
+					}
+					cn->bh = NULL;
+				}
+			}
+			cn = cn->hnext;
+		}
+	}
+
+	if (bh) {
+		put_bh(bh);	/* get_hash grabs the buffer */
+		if (atomic_read(&(bh->b_count)) < 0) {
+			reiserfs_warning(p_s_sb,
+					 "journal-2165: bh->b_count < 0");
+		}
+	}
+	return 0;
+}
+
+void reiserfs_update_inode_transaction(struct inode *inode)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(inode->i_sb);
+	REISERFS_I(inode)->i_jl = journal->j_current_jl;
+	REISERFS_I(inode)->i_trans_id = journal->j_trans_id;
 }
 
 /*
@@ -3368,99 +3689,102 @@ void reiserfs_update_inode_transaction(struct inode *inode) {
  * if a transaction was actually committed and the barrier was done
  */
 static int __commit_trans_jl(struct inode *inode, unsigned long id,
-                                 struct reiserfs_journal_list *jl)
+			     struct reiserfs_journal_list *jl)
 {
-    struct reiserfs_transaction_handle th ;
-    struct super_block *sb = inode->i_sb ;
-    struct reiserfs_journal *journal = SB_JOURNAL (sb);
-    int ret = 0;
+	struct reiserfs_transaction_handle th;
+	struct super_block *sb = inode->i_sb;
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	int ret = 0;
+
+	/* is it from the current transaction, or from an unknown transaction? */
+	if (id == journal->j_trans_id) {
+		jl = journal->j_current_jl;
+		/* try to let other writers come in and grow this transaction */
+		let_transaction_grow(sb, id);
+		if (journal->j_trans_id != id) {
+			goto flush_commit_only;
+		}
 
-    /* is it from the current transaction, or from an unknown transaction? */
-    if (id == journal->j_trans_id) {
-	jl = journal->j_current_jl;
-	/* try to let other writers come in and grow this transaction */
-	let_transaction_grow(sb, id);
-	if (journal->j_trans_id != id) {
-	    goto flush_commit_only;
-	}
+		ret = journal_begin(&th, sb, 1);
+		if (ret)
+			return ret;
+
+		/* someone might have ended this transaction while we joined */
+		if (journal->j_trans_id != id) {
+			reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb),
+						     1);
+			journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb));
+			ret = journal_end(&th, sb, 1);
+			goto flush_commit_only;
+		}
 
-	ret = journal_begin(&th, sb, 1) ;
-	if (ret)
-	    return ret;
+		ret = journal_end_sync(&th, sb, 1);
+		if (!ret)
+			ret = 1;
 
-	/* someone might have ended this transaction while we joined */
-	if (journal->j_trans_id != id) {
-	    reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb), 1) ;
-	    journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb)) ;
-	    ret = journal_end(&th, sb, 1) ;
-	    goto flush_commit_only;
+	} else {
+		/* this gets tricky, we have to make sure the journal list in
+		 * the inode still exists.  We know the list is still around
+		 * if we've got a larger transaction id than the oldest list
+		 */
+	      flush_commit_only:
+		if (journal_list_still_alive(inode->i_sb, id)) {
+			/*
+			 * we only set ret to 1 when we know for sure
+			 * the barrier hasn't been started yet on the commit
+			 * block.
+			 */
+			if (atomic_read(&jl->j_commit_left) > 1)
+				ret = 1;
+			flush_commit_list(sb, jl, 1);
+			if (journal->j_errno)
+				ret = journal->j_errno;
+		}
 	}
+	/* otherwise the list is gone, and long since committed */
+	return ret;
+}
 
-	ret = journal_end_sync(&th, sb, 1) ;
-	if (!ret)
-	    ret = 1;
+int reiserfs_commit_for_inode(struct inode *inode)
+{
+	unsigned long id = REISERFS_I(inode)->i_trans_id;
+	struct reiserfs_journal_list *jl = REISERFS_I(inode)->i_jl;
 
-    } else {
-	/* this gets tricky, we have to make sure the journal list in
-	 * the inode still exists.  We know the list is still around
-	 * if we've got a larger transaction id than the oldest list
+	/* for the whole inode, assume unset id means it was
+	 * changed in the current transaction.  More conservative
 	 */
-flush_commit_only:
-	if (journal_list_still_alive(inode->i_sb, id)) {
-	    /*
-	     * we only set ret to 1 when we know for sure
-	     * the barrier hasn't been started yet on the commit
-	     * block.
-	     */
-	    if (atomic_read(&jl->j_commit_left) > 1)
-	        ret = 1;
-	    flush_commit_list(sb, jl, 1) ;
-	    if (journal->j_errno)
-		ret = journal->j_errno;
-	}
-    }
-    /* otherwise the list is gone, and long since committed */
-    return ret;
-}
-
-int reiserfs_commit_for_inode(struct inode *inode) {
-    unsigned long id = REISERFS_I(inode)->i_trans_id;
-    struct reiserfs_journal_list *jl = REISERFS_I(inode)->i_jl;
-
-    /* for the whole inode, assume unset id means it was
-     * changed in the current transaction.  More conservative
-     */
-    if (!id || !jl) {
-	reiserfs_update_inode_transaction(inode) ;
-	id = REISERFS_I(inode)->i_trans_id;
-	/* jl will be updated in __commit_trans_jl */
-    }
-
-   return __commit_trans_jl(inode, id, jl);
-}
-
-void reiserfs_restore_prepared_buffer(struct super_block *p_s_sb, 
-                                      struct buffer_head *bh) {
-    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-    PROC_INFO_INC( p_s_sb, journal.restore_prepared );
-    if (!bh) {
-	return ;
-    }
-    if (test_clear_buffer_journal_restore_dirty (bh) &&
-	buffer_journal_dirty(bh)) {
-	struct reiserfs_journal_cnode *cn;
-	cn = get_journal_hash_dev(p_s_sb,
-	                          journal->j_list_hash_table,
-				  bh->b_blocknr);
-	if (cn && can_dirty(cn)) {
-            set_buffer_journal_test (bh);
-	    mark_buffer_dirty(bh);
-        }
-    }
-    clear_buffer_journal_prepared (bh);
-}
-
-extern struct tree_balance *cur_tb ;
+	if (!id || !jl) {
+		reiserfs_update_inode_transaction(inode);
+		id = REISERFS_I(inode)->i_trans_id;
+		/* jl will be updated in __commit_trans_jl */
+	}
+
+	return __commit_trans_jl(inode, id, jl);
+}
+
+void reiserfs_restore_prepared_buffer(struct super_block *p_s_sb,
+				      struct buffer_head *bh)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	PROC_INFO_INC(p_s_sb, journal.restore_prepared);
+	if (!bh) {
+		return;
+	}
+	if (test_clear_buffer_journal_restore_dirty(bh) &&
+	    buffer_journal_dirty(bh)) {
+		struct reiserfs_journal_cnode *cn;
+		cn = get_journal_hash_dev(p_s_sb,
+					  journal->j_list_hash_table,
+					  bh->b_blocknr);
+		if (cn && can_dirty(cn)) {
+			set_buffer_journal_test(bh);
+			mark_buffer_dirty(bh);
+		}
+	}
+	clear_buffer_journal_prepared(bh);
+}
+
+extern struct tree_balance *cur_tb;
 /*
 ** before we can change a metadata block, we have to make sure it won't
 ** be written to disk while we are altering it.  So, we must:
@@ -3469,39 +3793,41 @@ extern struct tree_balance *cur_tb ;
 ** 
 */
 int reiserfs_prepare_for_journal(struct super_block *p_s_sb,
-                                  struct buffer_head *bh, int wait) {
-  PROC_INFO_INC( p_s_sb, journal.prepare );
-
-    if (test_set_buffer_locked(bh)) {
-	if (!wait)
-	    return 0;
-	lock_buffer(bh);
-    }
-    set_buffer_journal_prepared (bh);
-    if (test_clear_buffer_dirty(bh) && buffer_journal_dirty(bh))  {
-        clear_buffer_journal_test (bh);
-        set_buffer_journal_restore_dirty (bh);
-    }
-    unlock_buffer(bh);
-    return 1;
-}
-
-static void flush_old_journal_lists(struct super_block *s) {
-    struct reiserfs_journal *journal = SB_JOURNAL (s);
-    struct reiserfs_journal_list *jl;
-    struct list_head *entry;
-    time_t now = get_seconds();
-
-    while(!list_empty(&journal->j_journal_list)) {
-        entry = journal->j_journal_list.next;
-	jl = JOURNAL_LIST_ENTRY(entry);
-	/* this check should always be run, to send old lists to disk */
-	if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4))) {
-	    flush_used_journal_lists(s, jl);
-	} else {
-	    break;
+				 struct buffer_head *bh, int wait)
+{
+	PROC_INFO_INC(p_s_sb, journal.prepare);
+
+	if (test_set_buffer_locked(bh)) {
+		if (!wait)
+			return 0;
+		lock_buffer(bh);
+	}
+	set_buffer_journal_prepared(bh);
+	if (test_clear_buffer_dirty(bh) && buffer_journal_dirty(bh)) {
+		clear_buffer_journal_test(bh);
+		set_buffer_journal_restore_dirty(bh);
+	}
+	unlock_buffer(bh);
+	return 1;
+}
+
+static void flush_old_journal_lists(struct super_block *s)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(s);
+	struct reiserfs_journal_list *jl;
+	struct list_head *entry;
+	time_t now = get_seconds();
+
+	while (!list_empty(&journal->j_journal_list)) {
+		entry = journal->j_journal_list.next;
+		jl = JOURNAL_LIST_ENTRY(entry);
+		/* this check should always be run, to send old lists to disk */
+		if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4))) {
+			flush_used_journal_lists(s, jl);
+		} else {
+			break;
+		}
 	}
-    }
 }
 
 /* 
@@ -3514,375 +3840,390 @@ static void flush_old_journal_lists(struct super_block *s) {
 ** If the journal is aborted, we just clean up. Things like flushing
 ** journal lists, etc just won't happen.
 */
-static int do_journal_end(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, unsigned long nblocks, 
-		          int flags) {
-  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
-  struct reiserfs_journal_cnode *cn, *next, *jl_cn; 
-  struct reiserfs_journal_cnode *last_cn = NULL;
-  struct reiserfs_journal_desc *desc ; 
-  struct reiserfs_journal_commit *commit ; 
-  struct buffer_head *c_bh ; /* commit bh */
-  struct buffer_head *d_bh ; /* desc bh */
-  int cur_write_start = 0 ; /* start index of current log write */
-  int old_start ;
-  int i ;
-  int flush = flags & FLUSH_ALL ;
-  int wait_on_commit = flags & WAIT ;
-  struct reiserfs_journal_list *jl, *temp_jl;
-  struct list_head *entry, *safe;
-  unsigned long jindex;
-  unsigned long commit_trans_id;
-  int trans_half;
-
-  BUG_ON (th->t_refcount > 1);
-  BUG_ON (!th->t_trans_id);
-
-  put_fs_excl();
-  current->journal_info = th->t_handle_save;
-  reiserfs_check_lock_depth(p_s_sb, "journal end");
-  if (journal->j_len == 0) {
-      reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
-      journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
-  }
-
-  lock_journal(p_s_sb) ;
-  if (journal->j_next_full_flush) {
-    flags |= FLUSH_ALL ;
-    flush = 1 ;
-  }
-  if (journal->j_next_async_flush) {
-    flags |= COMMIT_NOW | WAIT;
-    wait_on_commit = 1;
-  }
-
-  /* check_journal_end locks the journal, and unlocks if it does not return 1 
-  ** it tells us if we should continue with the journal_end, or just return
-  */
-  if (!check_journal_end(th, p_s_sb, nblocks, flags)) {
-    p_s_sb->s_dirt = 1;
-    wake_queued_writers(p_s_sb);
-    reiserfs_async_progress_wait(p_s_sb);
-    goto out ;
-  }
-
-  /* check_journal_end might set these, check again */
-  if (journal->j_next_full_flush) {
-    flush = 1 ;
-  }
-
-  /*
-  ** j must wait means we have to flush the log blocks, and the real blocks for
-  ** this transaction
-  */
-  if (journal->j_must_wait > 0) {
-    flush = 1 ;
-  }
+static int do_journal_end(struct reiserfs_transaction_handle *th,
+			  struct super_block *p_s_sb, unsigned long nblocks,
+			  int flags)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+	struct reiserfs_journal_cnode *cn, *next, *jl_cn;
+	struct reiserfs_journal_cnode *last_cn = NULL;
+	struct reiserfs_journal_desc *desc;
+	struct reiserfs_journal_commit *commit;
+	struct buffer_head *c_bh;	/* commit bh */
+	struct buffer_head *d_bh;	/* desc bh */
+	int cur_write_start = 0;	/* start index of current log write */
+	int old_start;
+	int i;
+	int flush = flags & FLUSH_ALL;
+	int wait_on_commit = flags & WAIT;
+	struct reiserfs_journal_list *jl, *temp_jl;
+	struct list_head *entry, *safe;
+	unsigned long jindex;
+	unsigned long commit_trans_id;
+	int trans_half;
+
+	BUG_ON(th->t_refcount > 1);
+	BUG_ON(!th->t_trans_id);
+
+	put_fs_excl();
+	current->journal_info = th->t_handle_save;
+	reiserfs_check_lock_depth(p_s_sb, "journal end");
+	if (journal->j_len == 0) {
+		reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb),
+					     1);
+		journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb));
+	}
 
+	lock_journal(p_s_sb);
+	if (journal->j_next_full_flush) {
+		flags |= FLUSH_ALL;
+		flush = 1;
+	}
+	if (journal->j_next_async_flush) {
+		flags |= COMMIT_NOW | WAIT;
+		wait_on_commit = 1;
+	}
+
+	/* check_journal_end locks the journal, and unlocks if it does not return 1 
+	 ** it tells us if we should continue with the journal_end, or just return
+	 */
+	if (!check_journal_end(th, p_s_sb, nblocks, flags)) {
+		p_s_sb->s_dirt = 1;
+		wake_queued_writers(p_s_sb);
+		reiserfs_async_progress_wait(p_s_sb);
+		goto out;
+	}
+
+	/* check_journal_end might set these, check again */
+	if (journal->j_next_full_flush) {
+		flush = 1;
+	}
+
+	/*
+	 ** j must wait means we have to flush the log blocks, and the real blocks for
+	 ** this transaction
+	 */
+	if (journal->j_must_wait > 0) {
+		flush = 1;
+	}
 #ifdef REISERFS_PREALLOCATE
-  /* quota ops might need to nest, setup the journal_info pointer for them */
-  current->journal_info = th ;
-  reiserfs_discard_all_prealloc(th); /* it should not involve new blocks into
-				      * the transaction */
-  current->journal_info = th->t_handle_save ;
+	/* quota ops might need to nest, setup the journal_info pointer for them */
+	current->journal_info = th;
+	reiserfs_discard_all_prealloc(th);	/* it should not involve new blocks into
+						 * the transaction */
+	current->journal_info = th->t_handle_save;
 #endif
-  
-  /* setup description block */
-  d_bh = journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start) ;
-  set_buffer_uptodate(d_bh);
-  desc = (struct reiserfs_journal_desc *)(d_bh)->b_data ;
-  memset(d_bh->b_data, 0, d_bh->b_size) ;
-  memcpy(get_journal_desc_magic (d_bh), JOURNAL_DESC_MAGIC, 8) ;
-  set_desc_trans_id(desc, journal->j_trans_id) ;
-
-  /* setup commit block.  Don't write (keep it clean too) this one until after everyone else is written */
-  c_bh =  journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
-		 ((journal->j_start + journal->j_len + 1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
-  commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
-  memset(c_bh->b_data, 0, c_bh->b_size) ;
-  set_commit_trans_id(commit, journal->j_trans_id) ;
-  set_buffer_uptodate(c_bh) ;
-
-  /* init this journal list */
-  jl = journal->j_current_jl;
-
-  /* we lock the commit before doing anything because
-   * we want to make sure nobody tries to run flush_commit_list until
-   * the new transaction is fully setup, and we've already flushed the
-   * ordered bh list
-   */
-  down(&jl->j_commit_lock);
-
-  /* save the transaction id in case we need to commit it later */
-  commit_trans_id = jl->j_trans_id;
-
-  atomic_set(&jl->j_older_commits_done, 0) ;
-  jl->j_trans_id = journal->j_trans_id ;
-  jl->j_timestamp = journal->j_trans_start_time ;
-  jl->j_commit_bh = c_bh ;
-  jl->j_start = journal->j_start ;
-  jl->j_len = journal->j_len ;
-  atomic_set(&jl->j_nonzerolen, journal->j_len) ;
-  atomic_set(&jl->j_commit_left, journal->j_len + 2);
-  jl->j_realblock = NULL ;
-
-  /* The ENTIRE FOR LOOP MUST not cause schedule to occur.
-  **  for each real block, add it to the journal list hash,
-  ** copy into real block index array in the commit or desc block
-  */
-  trans_half = journal_trans_half(p_s_sb->s_blocksize);
-  for (i = 0, cn = journal->j_first ; cn ; cn = cn->next, i++) {
-    if (buffer_journaled (cn->bh)) {
-      jl_cn = get_cnode(p_s_sb) ;
-      if (!jl_cn) {
-        reiserfs_panic(p_s_sb, "journal-1676, get_cnode returned NULL\n") ;
-      }
-      if (i == 0) {
-        jl->j_realblock = jl_cn ;
-      }
-      jl_cn->prev = last_cn ;
-      jl_cn->next = NULL ;
-      if (last_cn) {
-        last_cn->next = jl_cn ;
-      }
-      last_cn = jl_cn ;
-      /* make sure the block we are trying to log is not a block 
-         of journal or reserved area */
-
-      if (is_block_in_log_or_reserved_area(p_s_sb, cn->bh->b_blocknr)) {
-        reiserfs_panic(p_s_sb, "journal-2332: Trying to log block %lu, which is a log block\n", cn->bh->b_blocknr) ;
-      }
-      jl_cn->blocknr = cn->bh->b_blocknr ; 
-      jl_cn->state = 0 ;
-      jl_cn->sb = p_s_sb;
-      jl_cn->bh = cn->bh ;
-      jl_cn->jlist = jl;
-      insert_journal_hash(journal->j_list_hash_table, jl_cn) ;
-      if (i < trans_half) {
-	desc->j_realblock[i] = cpu_to_le32(cn->bh->b_blocknr) ;
-      } else {
-	commit->j_realblock[i - trans_half] = cpu_to_le32(cn->bh->b_blocknr) ;
-      }
-    } else {
-      i-- ;
-    }
-  }
-  set_desc_trans_len(desc, journal->j_len) ;
-  set_desc_mount_id(desc, journal->j_mount_id) ;
-  set_desc_trans_id(desc, journal->j_trans_id) ;
-  set_commit_trans_len(commit, journal->j_len);
-
-  /* special check in case all buffers in the journal were marked for not logging */
-  if (journal->j_len == 0) {
-    BUG();
-  }
-
-  /* we're about to dirty all the log blocks, mark the description block
-   * dirty now too.  Don't mark the commit block dirty until all the
-   * others are on disk
-   */
-  mark_buffer_dirty(d_bh);
-
-  /* first data block is j_start + 1, so add one to cur_write_start wherever you use it */
-  cur_write_start = journal->j_start ;
-  cn = journal->j_first ;
-  jindex = 1 ; /* start at one so we don't get the desc again */
-  while(cn) {
-    clear_buffer_journal_new (cn->bh);
-    /* copy all the real blocks into log area.  dirty log blocks */
-    if (buffer_journaled (cn->bh)) {
-      struct buffer_head *tmp_bh ;
-      char *addr;
-      struct page *page;
-      tmp_bh =  journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
-		       ((cur_write_start + jindex) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
-      set_buffer_uptodate(tmp_bh);
-      page = cn->bh->b_page;
-      addr = kmap(page);
-      memcpy(tmp_bh->b_data, addr + offset_in_page(cn->bh->b_data),
-             cn->bh->b_size);
-      kunmap(page);
-      mark_buffer_dirty(tmp_bh);
-      jindex++ ;
-      set_buffer_journal_dirty (cn->bh);
-      clear_buffer_journaled (cn->bh);
-    } else {
-      /* JDirty cleared sometime during transaction.  don't log this one */
-      reiserfs_warning(p_s_sb, "journal-2048: do_journal_end: BAD, buffer in journal hash, but not JDirty!") ;
-      brelse(cn->bh) ;
-    }
-    next = cn->next ;
-    free_cnode(p_s_sb, cn) ;
-    cn = next ;
-    cond_resched();
-  }
-
-  /* we are done  with both the c_bh and d_bh, but
-  ** c_bh must be written after all other commit blocks,
-  ** so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
-  */
-
-  journal->j_current_jl = alloc_journal_list(p_s_sb);
-
-  /* now it is safe to insert this transaction on the main list */
-  list_add_tail(&jl->j_list, &journal->j_journal_list);
-  list_add_tail(&jl->j_working_list, &journal->j_working_list);
-  journal->j_num_work_lists++;
-
-  /* reset journal values for the next transaction */
-  old_start = journal->j_start ;
-  journal->j_start = (journal->j_start + journal->j_len + 2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb);
-  atomic_set(&(journal->j_wcount), 0) ;
-  journal->j_bcount = 0 ;
-  journal->j_last = NULL ;
-  journal->j_first = NULL ;
-  journal->j_len = 0 ;
-  journal->j_trans_start_time = 0 ;
-  journal->j_trans_id++ ;
-  journal->j_current_jl->j_trans_id = journal->j_trans_id;
-  journal->j_must_wait = 0 ;
-  journal->j_len_alloc = 0 ;
-  journal->j_next_full_flush = 0 ;
-  journal->j_next_async_flush = 0 ;
-  init_journal_hash(p_s_sb) ; 
-
-  // make sure reiserfs_add_jh sees the new current_jl before we
-  // write out the tails
-  smp_mb();
-
-  /* tail conversion targets have to hit the disk before we end the
-   * transaction.  Otherwise a later transaction might repack the tail
-   * before this transaction commits, leaving the data block unflushed and
-   * clean, if we crash before the later transaction commits, the data block
-   * is lost.
-   */
-  if (!list_empty(&jl->j_tail_bh_list)) {
-      unlock_kernel();
-      write_ordered_buffers(&journal->j_dirty_buffers_lock,
-			    journal, jl, &jl->j_tail_bh_list);
-      lock_kernel();
-  }
-  if (!list_empty(&jl->j_tail_bh_list))
-      BUG();
-  up(&jl->j_commit_lock);
-
-  /* honor the flush wishes from the caller, simple commits can
-  ** be done outside the journal lock, they are done below
-  **
-  ** if we don't flush the commit list right now, we put it into
-  ** the work queue so the people waiting on the async progress work
-  ** queue don't wait for this proc to flush journal lists and such.
-  */
-  if (flush) {
-    flush_commit_list(p_s_sb, jl, 1) ;
-    flush_journal_list(p_s_sb, jl, 1) ;
-  } else if (!(jl->j_state & LIST_COMMIT_PENDING))
-    queue_delayed_work(commit_wq, &journal->j_work, HZ/10);
-
-
-  /* if the next transaction has any chance of wrapping, flush 
-  ** transactions that might get overwritten.  If any journal lists are very 
-  ** old flush them as well.  
-  */
-first_jl:
-  list_for_each_safe(entry, safe, &journal->j_journal_list) {
-    temp_jl = JOURNAL_LIST_ENTRY(entry);
-    if (journal->j_start <= temp_jl->j_start) {
-      if ((journal->j_start + journal->j_trans_max + 1) >=
-          temp_jl->j_start)
-      {
-	flush_used_journal_lists(p_s_sb, temp_jl);
-	goto first_jl;
-      } else if ((journal->j_start +
-                  journal->j_trans_max + 1) <
-		  SB_ONDISK_JOURNAL_SIZE(p_s_sb))
-      {
-          /* if we don't cross into the next transaction and we don't
-	   * wrap, there is no way we can overlap any later transactions
-	   * break now
-	   */
-	  break;
-      }
-    } else if ((journal->j_start +
-                journal->j_trans_max + 1) >
-		SB_ONDISK_JOURNAL_SIZE(p_s_sb))
-    {
-      if (((journal->j_start + journal->j_trans_max + 1) %
-            SB_ONDISK_JOURNAL_SIZE(p_s_sb)) >= temp_jl->j_start)
-      {
-	flush_used_journal_lists(p_s_sb, temp_jl);
-	goto first_jl;
-      } else {
-	  /* we don't overlap anything from out start to the end of the
-	   * log, and our wrapped portion doesn't overlap anything at
-	   * the start of the log.  We can break
-	   */
-	  break;
-      }
-    }
-  }
-  flush_old_journal_lists(p_s_sb);
-
-  journal->j_current_jl->j_list_bitmap = get_list_bitmap(p_s_sb, journal->j_current_jl) ;
-
-  if (!(journal->j_current_jl->j_list_bitmap)) {
-    reiserfs_panic(p_s_sb, "journal-1996: do_journal_end, could not get a list bitmap\n") ;
-  }
-
-  atomic_set(&(journal->j_jlock), 0) ;
-  unlock_journal(p_s_sb) ;
-  /* wake up any body waiting to join. */
-  clear_bit(J_WRITERS_QUEUED, &journal->j_state);
-  wake_up(&(journal->j_join_wait)) ;
-
-  if (!flush && wait_on_commit &&
-      journal_list_still_alive(p_s_sb, commit_trans_id)) {
-	  flush_commit_list(p_s_sb, jl, 1) ;
-  }
-out:
-  reiserfs_check_lock_depth(p_s_sb, "journal end2");
-
-  memset (th, 0, sizeof (*th));
-  /* Re-set th->t_super, so we can properly keep track of how many
-   * persistent transactions there are. We need to do this so if this
-   * call is part of a failed restart_transaction, we can free it later */
-  th->t_super = p_s_sb;
-
-  return journal->j_errno;
-}
-
-static void
-__reiserfs_journal_abort_hard (struct super_block *sb)
-{
-    struct reiserfs_journal *journal = SB_JOURNAL (sb);
-    if (test_bit (J_ABORTED, &journal->j_state))
-        return;
-
-    printk (KERN_CRIT "REISERFS: Aborting journal for filesystem on %s\n",
-                      reiserfs_bdevname (sb));
-
-    sb->s_flags |= MS_RDONLY;
-    set_bit (J_ABORTED, &journal->j_state);
+
+	/* setup description block */
+	d_bh =
+	    journal_getblk(p_s_sb,
+			   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+			   journal->j_start);
+	set_buffer_uptodate(d_bh);
+	desc = (struct reiserfs_journal_desc *)(d_bh)->b_data;
+	memset(d_bh->b_data, 0, d_bh->b_size);
+	memcpy(get_journal_desc_magic(d_bh), JOURNAL_DESC_MAGIC, 8);
+	set_desc_trans_id(desc, journal->j_trans_id);
+
+	/* setup commit block.  Don't write (keep it clean too) this one until after everyone else is written */
+	c_bh = journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+			      ((journal->j_start + journal->j_len +
+				1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+	commit = (struct reiserfs_journal_commit *)c_bh->b_data;
+	memset(c_bh->b_data, 0, c_bh->b_size);
+	set_commit_trans_id(commit, journal->j_trans_id);
+	set_buffer_uptodate(c_bh);
+
+	/* init this journal list */
+	jl = journal->j_current_jl;
+
+	/* we lock the commit before doing anything because
+	 * we want to make sure nobody tries to run flush_commit_list until
+	 * the new transaction is fully setup, and we've already flushed the
+	 * ordered bh list
+	 */
+	down(&jl->j_commit_lock);
+
+	/* save the transaction id in case we need to commit it later */
+	commit_trans_id = jl->j_trans_id;
+
+	atomic_set(&jl->j_older_commits_done, 0);
+	jl->j_trans_id = journal->j_trans_id;
+	jl->j_timestamp = journal->j_trans_start_time;
+	jl->j_commit_bh = c_bh;
+	jl->j_start = journal->j_start;
+	jl->j_len = journal->j_len;
+	atomic_set(&jl->j_nonzerolen, journal->j_len);
+	atomic_set(&jl->j_commit_left, journal->j_len + 2);
+	jl->j_realblock = NULL;
+
+	/* The ENTIRE FOR LOOP MUST not cause schedule to occur.
+	 **  for each real block, add it to the journal list hash,
+	 ** copy into real block index array in the commit or desc block
+	 */
+	trans_half = journal_trans_half(p_s_sb->s_blocksize);
+	for (i = 0, cn = journal->j_first; cn; cn = cn->next, i++) {
+		if (buffer_journaled(cn->bh)) {
+			jl_cn = get_cnode(p_s_sb);
+			if (!jl_cn) {
+				reiserfs_panic(p_s_sb,
+					       "journal-1676, get_cnode returned NULL\n");
+			}
+			if (i == 0) {
+				jl->j_realblock = jl_cn;
+			}
+			jl_cn->prev = last_cn;
+			jl_cn->next = NULL;
+			if (last_cn) {
+				last_cn->next = jl_cn;
+			}
+			last_cn = jl_cn;
+			/* make sure the block we are trying to log is not a block 
+			   of journal or reserved area */
+
+			if (is_block_in_log_or_reserved_area
+			    (p_s_sb, cn->bh->b_blocknr)) {
+				reiserfs_panic(p_s_sb,
+					       "journal-2332: Trying to log block %lu, which is a log block\n",
+					       cn->bh->b_blocknr);
+			}
+			jl_cn->blocknr = cn->bh->b_blocknr;
+			jl_cn->state = 0;
+			jl_cn->sb = p_s_sb;
+			jl_cn->bh = cn->bh;
+			jl_cn->jlist = jl;
+			insert_journal_hash(journal->j_list_hash_table, jl_cn);
+			if (i < trans_half) {
+				desc->j_realblock[i] =
+				    cpu_to_le32(cn->bh->b_blocknr);
+			} else {
+				commit->j_realblock[i - trans_half] =
+				    cpu_to_le32(cn->bh->b_blocknr);
+			}
+		} else {
+			i--;
+		}
+	}
+	set_desc_trans_len(desc, journal->j_len);
+	set_desc_mount_id(desc, journal->j_mount_id);
+	set_desc_trans_id(desc, journal->j_trans_id);
+	set_commit_trans_len(commit, journal->j_len);
+
+	/* special check in case all buffers in the journal were marked for not logging */
+	if (journal->j_len == 0) {
+		BUG();
+	}
+
+	/* we're about to dirty all the log blocks, mark the description block
+	 * dirty now too.  Don't mark the commit block dirty until all the
+	 * others are on disk
+	 */
+	mark_buffer_dirty(d_bh);
+
+	/* first data block is j_start + 1, so add one to cur_write_start wherever you use it */
+	cur_write_start = journal->j_start;
+	cn = journal->j_first;
+	jindex = 1;		/* start at one so we don't get the desc again */
+	while (cn) {
+		clear_buffer_journal_new(cn->bh);
+		/* copy all the real blocks into log area.  dirty log blocks */
+		if (buffer_journaled(cn->bh)) {
+			struct buffer_head *tmp_bh;
+			char *addr;
+			struct page *page;
+			tmp_bh =
+			    journal_getblk(p_s_sb,
+					   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+					   ((cur_write_start +
+					     jindex) %
+					    SB_ONDISK_JOURNAL_SIZE(p_s_sb)));
+			set_buffer_uptodate(tmp_bh);
+			page = cn->bh->b_page;
+			addr = kmap(page);
+			memcpy(tmp_bh->b_data,
+			       addr + offset_in_page(cn->bh->b_data),
+			       cn->bh->b_size);
+			kunmap(page);
+			mark_buffer_dirty(tmp_bh);
+			jindex++;
+			set_buffer_journal_dirty(cn->bh);
+			clear_buffer_journaled(cn->bh);
+		} else {
+			/* JDirty cleared sometime during transaction.  don't log this one */
+			reiserfs_warning(p_s_sb,
+					 "journal-2048: do_journal_end: BAD, buffer in journal hash, but not JDirty!");
+			brelse(cn->bh);
+		}
+		next = cn->next;
+		free_cnode(p_s_sb, cn);
+		cn = next;
+		cond_resched();
+	}
+
+	/* we are done  with both the c_bh and d_bh, but
+	 ** c_bh must be written after all other commit blocks,
+	 ** so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
+	 */
+
+	journal->j_current_jl = alloc_journal_list(p_s_sb);
+
+	/* now it is safe to insert this transaction on the main list */
+	list_add_tail(&jl->j_list, &journal->j_journal_list);
+	list_add_tail(&jl->j_working_list, &journal->j_working_list);
+	journal->j_num_work_lists++;
+
+	/* reset journal values for the next transaction */
+	old_start = journal->j_start;
+	journal->j_start =
+	    (journal->j_start + journal->j_len +
+	     2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb);
+	atomic_set(&(journal->j_wcount), 0);
+	journal->j_bcount = 0;
+	journal->j_last = NULL;
+	journal->j_first = NULL;
+	journal->j_len = 0;
+	journal->j_trans_start_time = 0;
+	journal->j_trans_id++;
+	journal->j_current_jl->j_trans_id = journal->j_trans_id;
+	journal->j_must_wait = 0;
+	journal->j_len_alloc = 0;
+	journal->j_next_full_flush = 0;
+	journal->j_next_async_flush = 0;
+	init_journal_hash(p_s_sb);
+
+	// make sure reiserfs_add_jh sees the new current_jl before we
+	// write out the tails
+	smp_mb();
+
+	/* tail conversion targets have to hit the disk before we end the
+	 * transaction.  Otherwise a later transaction might repack the tail
+	 * before this transaction commits, leaving the data block unflushed and
+	 * clean, if we crash before the later transaction commits, the data block
+	 * is lost.
+	 */
+	if (!list_empty(&jl->j_tail_bh_list)) {
+		unlock_kernel();
+		write_ordered_buffers(&journal->j_dirty_buffers_lock,
+				      journal, jl, &jl->j_tail_bh_list);
+		lock_kernel();
+	}
+	if (!list_empty(&jl->j_tail_bh_list))
+		BUG();
+	up(&jl->j_commit_lock);
+
+	/* honor the flush wishes from the caller, simple commits can
+	 ** be done outside the journal lock, they are done below
+	 **
+	 ** if we don't flush the commit list right now, we put it into
+	 ** the work queue so the people waiting on the async progress work
+	 ** queue don't wait for this proc to flush journal lists and such.
+	 */
+	if (flush) {
+		flush_commit_list(p_s_sb, jl, 1);
+		flush_journal_list(p_s_sb, jl, 1);
+	} else if (!(jl->j_state & LIST_COMMIT_PENDING))
+		queue_delayed_work(commit_wq, &journal->j_work, HZ / 10);
+
+	/* if the next transaction has any chance of wrapping, flush 
+	 ** transactions that might get overwritten.  If any journal lists are very 
+	 ** old flush them as well.  
+	 */
+      first_jl:
+	list_for_each_safe(entry, safe, &journal->j_journal_list) {
+		temp_jl = JOURNAL_LIST_ENTRY(entry);
+		if (journal->j_start <= temp_jl->j_start) {
+			if ((journal->j_start + journal->j_trans_max + 1) >=
+			    temp_jl->j_start) {
+				flush_used_journal_lists(p_s_sb, temp_jl);
+				goto first_jl;
+			} else if ((journal->j_start +
+				    journal->j_trans_max + 1) <
+				   SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+				/* if we don't cross into the next transaction and we don't
+				 * wrap, there is no way we can overlap any later transactions
+				 * break now
+				 */
+				break;
+			}
+		} else if ((journal->j_start +
+			    journal->j_trans_max + 1) >
+			   SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+			if (((journal->j_start + journal->j_trans_max + 1) %
+			     SB_ONDISK_JOURNAL_SIZE(p_s_sb)) >=
+			    temp_jl->j_start) {
+				flush_used_journal_lists(p_s_sb, temp_jl);
+				goto first_jl;
+			} else {
+				/* we don't overlap anything from out start to the end of the
+				 * log, and our wrapped portion doesn't overlap anything at
+				 * the start of the log.  We can break
+				 */
+				break;
+			}
+		}
+	}
+	flush_old_journal_lists(p_s_sb);
+
+	journal->j_current_jl->j_list_bitmap =
+	    get_list_bitmap(p_s_sb, journal->j_current_jl);
+
+	if (!(journal->j_current_jl->j_list_bitmap)) {
+		reiserfs_panic(p_s_sb,
+			       "journal-1996: do_journal_end, could not get a list bitmap\n");
+	}
+
+	atomic_set(&(journal->j_jlock), 0);
+	unlock_journal(p_s_sb);
+	/* wake up any body waiting to join. */
+	clear_bit(J_WRITERS_QUEUED, &journal->j_state);
+	wake_up(&(journal->j_join_wait));
+
+	if (!flush && wait_on_commit &&
+	    journal_list_still_alive(p_s_sb, commit_trans_id)) {
+		flush_commit_list(p_s_sb, jl, 1);
+	}
+      out:
+	reiserfs_check_lock_depth(p_s_sb, "journal end2");
+
+	memset(th, 0, sizeof(*th));
+	/* Re-set th->t_super, so we can properly keep track of how many
+	 * persistent transactions there are. We need to do this so if this
+	 * call is part of a failed restart_transaction, we can free it later */
+	th->t_super = p_s_sb;
+
+	return journal->j_errno;
+}
+
+static void __reiserfs_journal_abort_hard(struct super_block *sb)
+{
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	if (test_bit(J_ABORTED, &journal->j_state))
+		return;
+
+	printk(KERN_CRIT "REISERFS: Aborting journal for filesystem on %s\n",
+	       reiserfs_bdevname(sb));
+
+	sb->s_flags |= MS_RDONLY;
+	set_bit(J_ABORTED, &journal->j_state);
 
 #ifdef CONFIG_REISERFS_CHECK
-    dump_stack();
+	dump_stack();
 #endif
 }
 
-static void
-__reiserfs_journal_abort_soft (struct super_block *sb, int errno)
+static void __reiserfs_journal_abort_soft(struct super_block *sb, int errno)
 {
-    struct reiserfs_journal *journal = SB_JOURNAL (sb);
-    if (test_bit (J_ABORTED, &journal->j_state))
-        return;
+	struct reiserfs_journal *journal = SB_JOURNAL(sb);
+	if (test_bit(J_ABORTED, &journal->j_state))
+		return;
 
-    if (!journal->j_errno)
-        journal->j_errno = errno;
+	if (!journal->j_errno)
+		journal->j_errno = errno;
 
-    __reiserfs_journal_abort_hard (sb);
+	__reiserfs_journal_abort_hard(sb);
 }
 
-void
-reiserfs_journal_abort (struct super_block *sb, int errno)
+void reiserfs_journal_abort(struct super_block *sb, int errno)
 {
-    return __reiserfs_journal_abort_soft (sb, errno);
+	return __reiserfs_journal_abort_soft(sb, errno);
 }

commit 22e2c507c301c3dbbcf91b4948b88f78842ee6c9
Author: Jens Axboe <axboe@suse.de>
Date:   Mon Jun 27 10:55:12 2005 +0200

    [PATCH] Update cfq io scheduler to time sliced design
    
    This updates the CFQ io scheduler to the new time sliced design (cfq
    v3).  It provides full process fairness, while giving excellent
    aggregate system throughput even for many competing processes.  It
    supports io priorities, either inherited from the cpu nice value or set
    directly with the ioprio_get/set syscalls.  The latter closely mimic
    set/getpriority.
    
    This import is based on my latest from -mm.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 7b87707acc36..d1bcf0da6728 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -645,18 +645,22 @@ struct buffer_chunk {
 
 static void write_chunk(struct buffer_chunk *chunk) {
     int i;
+    get_fs_excl();
     for (i = 0; i < chunk->nr ; i++) {
 	submit_logged_buffer(chunk->bh[i]) ;
     }
     chunk->nr = 0;
+    put_fs_excl();
 }
 
 static void write_ordered_chunk(struct buffer_chunk *chunk) {
     int i;
+    get_fs_excl();
     for (i = 0; i < chunk->nr ; i++) {
 	submit_ordered_buffer(chunk->bh[i]) ;
     }
     chunk->nr = 0;
+    put_fs_excl();
 }
 
 static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
@@ -918,6 +922,8 @@ static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list
     return 0 ;
   }
 
+  get_fs_excl();
+
   /* before we can put our commit blocks on disk, we have to make sure everyone older than
   ** us is on disk too
   */
@@ -1055,6 +1061,7 @@ static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list
 
   if (retval)
     reiserfs_abort (s, retval, "Journal write error in %s", __FUNCTION__);
+  put_fs_excl();
   return retval;
 }
 
@@ -1251,6 +1258,8 @@ static int flush_journal_list(struct super_block *s,
     return 0 ;
   }
 
+  get_fs_excl();
+
   /* if all the work is already done, get out of here */
   if (atomic_read(&(jl->j_nonzerolen)) <= 0 && 
       atomic_read(&(jl->j_commit_left)) <= 0) {
@@ -1450,6 +1459,7 @@ static int flush_journal_list(struct super_block *s,
   put_journal_list(s, jl);
   if (flushall)
     up(&journal->j_flush_sem);
+  put_fs_excl();
   return err ;
 } 
 
@@ -2719,6 +2729,7 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th, struct sup
   th->t_trans_id = journal->j_trans_id ;
   unlock_journal(p_s_sb) ;
   INIT_LIST_HEAD (&th->t_list);
+  get_fs_excl();
   return 0 ;
 
 out_fail:
@@ -3526,6 +3537,7 @@ static int do_journal_end(struct reiserfs_transaction_handle *th, struct super_b
   BUG_ON (th->t_refcount > 1);
   BUG_ON (!th->t_trans_id);
 
+  put_fs_excl();
   current->journal_info = th->t_handle_save;
   reiserfs_check_lock_depth(p_s_sb, "journal end");
   if (journal->j_len == 0) {

commit bdd5b29c6bc835dab71148afd5952f9cd278eef1
Author: Jan Kara <jack@suse.cz>
Date:   Thu Jun 23 22:01:37 2005 -0700

    [PATCH] Make reiserfs BUG on too big transaction
    
    Make reiserfs BUG() when somebody tries to start a larger transaction than
    it's allowed (currently the code just silently deadlocks).
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Acked-by: Chris Mason <mason@suse.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index 3072cfdee959..7b87707acc36 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2631,6 +2631,8 @@ static int do_journal_begin_r(struct reiserfs_transaction_handle *th, struct sup
   int retval;
 
   reiserfs_check_lock_depth(p_s_sb, "journal_begin") ;
+  if (nblocks > journal->j_trans_max)
+	BUG();
 
   PROC_INFO_INC( p_s_sb, journal.journal_being );
   /* set here for journal_join */

commit b8cc936f6295bba23513a49d858ea82f64982faf
Author: Al Viro <viro@www.linux.org.uk>
Date:   Sun May 1 08:59:18 2005 -0700

    [PATCH] reiserfs endianness: fix endianness bugs
    
    fixes for a couple of bugs exposed by the above: le32_to_cpu() used on 16bit
    value and missing conversion in comparison of host- and little-endian values.
    
    Signed-off-by: Al Viro <viro@parcelfarce.linux.theplanet.co.uk>
    Cc: <reiserfs-dev@namesys.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index b16d65acb550..3072cfdee959 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2391,7 +2391,7 @@ int journal_init(struct super_block *p_s_sb, const char * j_dev_name, int old_fo
      jh = (struct reiserfs_journal_header *)(bhjh->b_data);
      
      /* make sure that journal matches to the super block */
-     if (is_reiserfs_jr(rs) && (jh->jh_journal.jp_journal_magic != sb_jp_journal_magic(rs))) {
+     if (is_reiserfs_jr(rs) && (le32_to_cpu(jh->jh_journal.jp_journal_magic) != sb_jp_journal_magic(rs))) {
 	 reiserfs_warning (p_s_sb, "sh-460: journal header magic %x "
 			   "(device %s) does not match to magic found in super "
 			   "block %x",

commit 74f9f974a64dc3de554aa1977bf108334436e47b
Author: Edward Shishkin <edward@namesys.com>
Date:   Sun May 1 08:59:09 2005 -0700

    [PATCH] reiserfs: journal_init fix
    
    This fixes segmentation fault when specifying bad journal device via
    a mount option.
    
    Don't pass a zero pointer to bdevname() if filp_open() returns error.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
index c9ad3a7849f4..b16d65acb550 100644
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@ -2306,13 +2306,16 @@ static int journal_init_dev( struct super_block *super,
 	if( !IS_ERR( journal -> j_dev_file ) ) {
 		struct inode *jdev_inode = journal->j_dev_file->f_mapping->host;
 		if( !S_ISBLK( jdev_inode -> i_mode ) ) {
-			reiserfs_warning  (super, "journal_init_dev: '%s' is "
-					   "not a block device", jdev_name );
+			reiserfs_warning(super, "journal_init_dev: '%s' is "
+					 "not a block device", jdev_name );
 			result = -ENOTBLK;
+			release_journal_dev( super, journal );
 		} else  {
 			/* ok */
 			journal->j_dev_bd = I_BDEV(jdev_inode);
 			set_blocksize(journal->j_dev_bd, super->s_blocksize);
+			reiserfs_info(super, "journal_init_dev: journal device: %s\n",
+				      bdevname(journal->j_dev_bd, b));
 		}
 	} else {
 		result = PTR_ERR( journal -> j_dev_file );
@@ -2321,11 +2324,6 @@ static int journal_init_dev( struct super_block *super,
 				  "journal_init_dev: Cannot open '%s': %i",
 				  jdev_name, result );
 	}
-	if( result != 0 ) {
-		release_journal_dev( super, journal );
-	}
-	reiserfs_info(super, "journal_init_dev: journal device: %s\n",
-		bdevname(journal->j_dev_bd, b));
 	return result;
 }
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c
new file mode 100644
index 000000000000..c9ad3a7849f4
--- /dev/null
+++ b/fs/reiserfs/journal.c
@@ -0,0 +1,3876 @@
+/*
+** Write ahead logging implementation copyright Chris Mason 2000
+**
+** The background commits make this code very interelated, and 
+** overly complex.  I need to rethink things a bit....The major players:
+**
+** journal_begin -- call with the number of blocks you expect to log.  
+**                  If the current transaction is too
+** 		    old, it will block until the current transaction is 
+** 		    finished, and then start a new one.
+**		    Usually, your transaction will get joined in with 
+**                  previous ones for speed.
+**
+** journal_join  -- same as journal_begin, but won't block on the current 
+**                  transaction regardless of age.  Don't ever call
+**                  this.  Ever.  There are only two places it should be 
+**                  called from, and they are both inside this file.
+**
+** journal_mark_dirty -- adds blocks into this transaction.  clears any flags 
+**                       that might make them get sent to disk
+**                       and then marks them BH_JDirty.  Puts the buffer head 
+**                       into the current transaction hash.  
+**
+** journal_end -- if the current transaction is batchable, it does nothing
+**                   otherwise, it could do an async/synchronous commit, or
+**                   a full flush of all log and real blocks in the 
+**                   transaction.
+**
+** flush_old_commits -- if the current transaction is too old, it is ended and 
+**                      commit blocks are sent to disk.  Forces commit blocks 
+**                      to disk for all backgrounded commits that have been 
+**                      around too long.
+**		     -- Note, if you call this as an immediate flush from 
+**		        from within kupdate, it will ignore the immediate flag
+*/
+
+#include <linux/config.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+
+#include <linux/time.h>
+#include <asm/semaphore.h>
+
+#include <linux/vmalloc.h>
+#include <linux/reiserfs_fs.h>
+
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/stat.h>
+#include <linux/string.h>
+#include <linux/smp_lock.h>
+#include <linux/buffer_head.h>
+#include <linux/workqueue.h>
+#include <linux/writeback.h>
+#include <linux/blkdev.h>
+
+
+/* gets a struct reiserfs_journal_list * from a list head */
+#define JOURNAL_LIST_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
+                               j_list))
+#define JOURNAL_WORK_ENTRY(h) (list_entry((h), struct reiserfs_journal_list, \
+                               j_working_list))
+
+/* the number of mounted filesystems.  This is used to decide when to
+** start and kill the commit workqueue
+*/
+static int reiserfs_mounted_fs_count;
+
+static struct workqueue_struct *commit_wq;
+
+#define JOURNAL_TRANS_HALF 1018   /* must be correct to keep the desc and commit
+				     structs at 4k */
+#define BUFNR 64 /*read ahead */
+
+/* cnode stat bits.  Move these into reiserfs_fs.h */
+
+#define BLOCK_FREED 2		/* this block was freed, and can't be written.  */
+#define BLOCK_FREED_HOLDER 3    /* this block was freed during this transaction, and can't be written */
+
+#define BLOCK_NEEDS_FLUSH 4	/* used in flush_journal_list */
+#define BLOCK_DIRTIED 5
+
+
+/* journal list state bits */
+#define LIST_TOUCHED 1
+#define LIST_DIRTY   2
+#define LIST_COMMIT_PENDING  4		/* someone will commit this list */
+
+/* flags for do_journal_end */
+#define FLUSH_ALL   1		/* flush commit and real blocks */
+#define COMMIT_NOW  2		/* end and commit this transaction */
+#define WAIT        4		/* wait for the log blocks to hit the disk*/
+
+static int do_journal_end(struct reiserfs_transaction_handle *,struct super_block *,unsigned long nblocks,int flags) ;
+static int flush_journal_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall) ;
+static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall)  ;
+static int can_dirty(struct reiserfs_journal_cnode *cn) ;
+static int journal_join(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks);
+static int release_journal_dev( struct super_block *super,
+				struct reiserfs_journal *journal );
+static int dirty_one_transaction(struct super_block *s,
+                                 struct reiserfs_journal_list *jl);
+static void flush_async_commits(void *p);
+static void queue_log_writer(struct super_block *s);
+
+/* values for join in do_journal_begin_r */
+enum {
+    JBEGIN_REG = 0, /* regular journal begin */
+    JBEGIN_JOIN = 1, /* join the running transaction if at all possible */
+    JBEGIN_ABORT = 2, /* called from cleanup code, ignores aborted flag */
+};
+
+static int do_journal_begin_r(struct reiserfs_transaction_handle *th,
+                             struct super_block * p_s_sb,
+			     unsigned long nblocks,int join);
+
+static void init_journal_hash(struct super_block *p_s_sb) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  memset(journal->j_hash_table, 0, JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *)) ;
+}
+
+/*
+** clears BH_Dirty and sticks the buffer on the clean list.  Called because I can't allow refile_buffer to
+** make schedule happen after I've freed a block.  Look at remove_from_transaction and journal_mark_freed for
+** more details.
+*/
+static int reiserfs_clean_and_file_buffer(struct buffer_head *bh) {
+  if (bh) {
+    clear_buffer_dirty(bh);
+    clear_buffer_journal_test(bh);
+  }
+  return 0 ;
+}
+
+static void disable_barrier(struct super_block *s)
+{
+    REISERFS_SB(s)->s_mount_opt &= ~(1 << REISERFS_BARRIER_FLUSH);
+    printk("reiserfs: disabling flush barriers on %s\n", reiserfs_bdevname(s));
+}
+
+static struct reiserfs_bitmap_node *
+allocate_bitmap_node(struct super_block *p_s_sb) {
+  struct reiserfs_bitmap_node *bn ;
+  static int id;
+
+  bn = reiserfs_kmalloc(sizeof(struct reiserfs_bitmap_node), GFP_NOFS, p_s_sb) ;
+  if (!bn) {
+    return NULL ;
+  }
+  bn->data = reiserfs_kmalloc(p_s_sb->s_blocksize, GFP_NOFS, p_s_sb) ;
+  if (!bn->data) {
+    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
+    return NULL ;
+  }
+  bn->id = id++ ;
+  memset(bn->data, 0, p_s_sb->s_blocksize) ;
+  INIT_LIST_HEAD(&bn->list) ;
+  return bn ;
+}
+
+static struct reiserfs_bitmap_node *
+get_bitmap_node(struct super_block *p_s_sb) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_bitmap_node *bn = NULL;
+  struct list_head *entry = journal->j_bitmap_nodes.next ;
+
+  journal->j_used_bitmap_nodes++ ;
+repeat:
+
+  if(entry != &journal->j_bitmap_nodes) {
+    bn = list_entry(entry, struct reiserfs_bitmap_node, list) ;
+    list_del(entry) ;
+    memset(bn->data, 0, p_s_sb->s_blocksize) ;
+    journal->j_free_bitmap_nodes-- ;
+    return bn ;
+  }
+  bn = allocate_bitmap_node(p_s_sb) ;
+  if (!bn) {
+    yield();
+    goto repeat ;
+  }
+  return bn ;
+}
+static inline void free_bitmap_node(struct super_block *p_s_sb,
+                                    struct reiserfs_bitmap_node *bn) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  journal->j_used_bitmap_nodes-- ;
+  if (journal->j_free_bitmap_nodes > REISERFS_MAX_BITMAP_NODES) {
+    reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb) ;
+    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
+  } else {
+    list_add(&bn->list, &journal->j_bitmap_nodes) ;
+    journal->j_free_bitmap_nodes++ ;
+  }
+}
+
+static void allocate_bitmap_nodes(struct super_block *p_s_sb) {
+  int i ;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_bitmap_node *bn = NULL ;
+  for (i = 0 ; i < REISERFS_MIN_BITMAP_NODES ; i++) {
+    bn = allocate_bitmap_node(p_s_sb) ;
+    if (bn) {
+      list_add(&bn->list, &journal->j_bitmap_nodes) ;
+      journal->j_free_bitmap_nodes++ ;
+    } else {
+      break ; // this is ok, we'll try again when more are needed 
+    }
+  }
+}
+
+static int set_bit_in_list_bitmap(struct super_block *p_s_sb, int block,
+                                  struct reiserfs_list_bitmap *jb) {
+  int bmap_nr = block / (p_s_sb->s_blocksize << 3) ;
+  int bit_nr = block % (p_s_sb->s_blocksize << 3) ;
+
+  if (!jb->bitmaps[bmap_nr]) {
+    jb->bitmaps[bmap_nr] = get_bitmap_node(p_s_sb) ;
+  }
+  set_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data) ;
+  return 0 ;
+}
+
+static void cleanup_bitmap_list(struct super_block *p_s_sb,
+                                struct reiserfs_list_bitmap *jb) {
+  int i;
+  if (jb->bitmaps == NULL)
+    return;
+
+  for (i = 0 ; i < SB_BMAP_NR(p_s_sb) ; i++) {
+    if (jb->bitmaps[i]) {
+      free_bitmap_node(p_s_sb, jb->bitmaps[i]) ;
+      jb->bitmaps[i] = NULL ;
+    }
+  }
+}
+
+/*
+** only call this on FS unmount.
+*/
+static int free_list_bitmaps(struct super_block *p_s_sb,
+                             struct reiserfs_list_bitmap *jb_array) {
+  int i ;
+  struct reiserfs_list_bitmap *jb ;
+  for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
+    jb = jb_array + i ;
+    jb->journal_list = NULL ;
+    cleanup_bitmap_list(p_s_sb, jb) ;
+    vfree(jb->bitmaps) ;
+    jb->bitmaps = NULL ;
+  }
+  return 0;
+}
+
+static int free_bitmap_nodes(struct super_block *p_s_sb) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct list_head *next = journal->j_bitmap_nodes.next ;
+  struct reiserfs_bitmap_node *bn ;
+
+  while(next != &journal->j_bitmap_nodes) {
+    bn = list_entry(next, struct reiserfs_bitmap_node, list) ;
+    list_del(next) ;
+    reiserfs_kfree(bn->data, p_s_sb->s_blocksize, p_s_sb) ;
+    reiserfs_kfree(bn, sizeof(struct reiserfs_bitmap_node), p_s_sb) ;
+    next = journal->j_bitmap_nodes.next ;
+    journal->j_free_bitmap_nodes-- ;
+  }
+
+  return 0 ;
+}
+
+/*
+** get memory for JOURNAL_NUM_BITMAPS worth of bitmaps. 
+** jb_array is the array to be filled in.
+*/
+int reiserfs_allocate_list_bitmaps(struct super_block *p_s_sb,
+                                   struct reiserfs_list_bitmap *jb_array,
+				   int bmap_nr) {
+  int i ;
+  int failed = 0 ;
+  struct reiserfs_list_bitmap *jb ;
+  int mem = bmap_nr * sizeof(struct reiserfs_bitmap_node *) ;
+
+  for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
+    jb = jb_array + i ;
+    jb->journal_list = NULL ;
+    jb->bitmaps = vmalloc( mem ) ;
+    if (!jb->bitmaps) {
+      reiserfs_warning(p_s_sb, "clm-2000, unable to allocate bitmaps for journal lists") ;
+      failed = 1;   
+      break ;
+    }
+    memset(jb->bitmaps, 0, mem) ;
+  }
+  if (failed) {
+    free_list_bitmaps(p_s_sb, jb_array) ;
+    return -1 ;
+  }
+  return 0 ;
+}
+
+/*
+** find an available list bitmap.  If you can't find one, flush a commit list 
+** and try again
+*/
+static struct reiserfs_list_bitmap *
+get_list_bitmap(struct super_block *p_s_sb, struct reiserfs_journal_list *jl) {
+  int i,j ; 
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_list_bitmap *jb = NULL ;
+
+  for (j = 0 ; j < (JOURNAL_NUM_BITMAPS * 3) ; j++) {
+    i = journal->j_list_bitmap_index ;
+    journal->j_list_bitmap_index = (i + 1) % JOURNAL_NUM_BITMAPS ;
+    jb = journal->j_list_bitmap + i ;
+    if (journal->j_list_bitmap[i].journal_list) {
+      flush_commit_list(p_s_sb, journal->j_list_bitmap[i].journal_list, 1) ;
+      if (!journal->j_list_bitmap[i].journal_list) {
+	break ;
+      }
+    } else {
+      break ;
+    }
+  }
+  if (jb->journal_list) { /* double check to make sure if flushed correctly */
+    return NULL ;
+  }
+  jb->journal_list = jl ;
+  return jb ;
+}
+
+/* 
+** allocates a new chunk of X nodes, and links them all together as a list.
+** Uses the cnode->next and cnode->prev pointers
+** returns NULL on failure
+*/
+static struct reiserfs_journal_cnode *allocate_cnodes(int num_cnodes) {
+  struct reiserfs_journal_cnode *head ;
+  int i ;
+  if (num_cnodes <= 0) {
+    return NULL ;
+  }
+  head = vmalloc(num_cnodes * sizeof(struct reiserfs_journal_cnode)) ;
+  if (!head) {
+    return NULL ;
+  }
+  memset(head, 0, num_cnodes * sizeof(struct reiserfs_journal_cnode)) ;
+  head[0].prev = NULL ;
+  head[0].next = head + 1 ;
+  for (i = 1 ; i < num_cnodes; i++) {
+    head[i].prev = head + (i - 1) ;
+    head[i].next = head + (i + 1) ; /* if last one, overwrite it after the if */
+  }
+  head[num_cnodes -1].next = NULL ;
+  return head ;
+}
+
+/*
+** pulls a cnode off the free list, or returns NULL on failure 
+*/
+static struct reiserfs_journal_cnode *get_cnode(struct super_block *p_s_sb) {
+  struct reiserfs_journal_cnode *cn ;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+  reiserfs_check_lock_depth(p_s_sb, "get_cnode") ;
+
+  if (journal->j_cnode_free <= 0) {
+    return NULL ;
+  }
+  journal->j_cnode_used++ ;
+  journal->j_cnode_free-- ;
+  cn = journal->j_cnode_free_list ;
+  if (!cn) {
+    return cn ;
+  }
+  if (cn->next) {
+    cn->next->prev = NULL ;
+  }
+  journal->j_cnode_free_list = cn->next ;
+  memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ;
+  return cn ;
+}
+
+/*
+** returns a cnode to the free list 
+*/
+static void free_cnode(struct super_block *p_s_sb, struct reiserfs_journal_cnode *cn) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+  reiserfs_check_lock_depth(p_s_sb, "free_cnode") ;
+
+  journal->j_cnode_used-- ;
+  journal->j_cnode_free++ ;
+  /* memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ; */
+  cn->next = journal->j_cnode_free_list ;
+  if (journal->j_cnode_free_list) {
+    journal->j_cnode_free_list->prev = cn ;
+  }
+  cn->prev = NULL ; /* not needed with the memset, but I might kill the memset, and forget to do this */
+  journal->j_cnode_free_list = cn ;
+}
+
+static void clear_prepared_bits(struct buffer_head *bh) {
+  clear_buffer_journal_prepared (bh);
+  clear_buffer_journal_restore_dirty (bh);
+}
+
+/* utility function to force a BUG if it is called without the big
+** kernel lock held.  caller is the string printed just before calling BUG()
+*/
+void reiserfs_check_lock_depth(struct super_block *sb, char *caller) {
+#ifdef CONFIG_SMP
+  if (current->lock_depth < 0) {
+    reiserfs_panic (sb, "%s called without kernel lock held", caller) ;
+  }
+#else
+  ;
+#endif
+}
+
+/* return a cnode with same dev, block number and size in table, or null if not found */
+static inline struct reiserfs_journal_cnode *
+get_journal_hash_dev(struct super_block *sb,
+		     struct reiserfs_journal_cnode **table,
+		     long bl)
+{
+  struct reiserfs_journal_cnode *cn ;
+  cn = journal_hash(table, sb, bl) ;
+  while(cn) {
+    if (cn->blocknr == bl && cn->sb == sb)
+      return cn ;
+    cn = cn->hnext ;
+  }
+  return (struct reiserfs_journal_cnode *)0 ;
+}
+
+/*
+** this actually means 'can this block be reallocated yet?'.  If you set search_all, a block can only be allocated
+** if it is not in the current transaction, was not freed by the current transaction, and has no chance of ever
+** being overwritten by a replay after crashing.
+**
+** If you don't set search_all, a block can only be allocated if it is not in the current transaction.  Since deleting
+** a block removes it from the current transaction, this case should never happen.  If you don't set search_all, make
+** sure you never write the block without logging it.
+**
+** next_zero_bit is a suggestion about the next block to try for find_forward.
+** when bl is rejected because it is set in a journal list bitmap, we search
+** for the next zero bit in the bitmap that rejected bl.  Then, we return that
+** through next_zero_bit for find_forward to try.
+**
+** Just because we return something in next_zero_bit does not mean we won't
+** reject it on the next call to reiserfs_in_journal
+**
+*/
+int reiserfs_in_journal(struct super_block *p_s_sb,
+                        int bmap_nr, int bit_nr, int search_all, 
+			b_blocknr_t *next_zero_bit) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_cnode *cn ;
+  struct reiserfs_list_bitmap *jb ;
+  int i ;
+  unsigned long bl;
+
+  *next_zero_bit = 0 ; /* always start this at zero. */
+
+  PROC_INFO_INC( p_s_sb, journal.in_journal );
+  /* If we aren't doing a search_all, this is a metablock, and it will be logged before use.
+  ** if we crash before the transaction that freed it commits,  this transaction won't
+  ** have committed either, and the block will never be written
+  */
+  if (search_all) {
+    for (i = 0 ; i < JOURNAL_NUM_BITMAPS ; i++) {
+      PROC_INFO_INC( p_s_sb, journal.in_journal_bitmap );
+      jb = journal->j_list_bitmap + i ;
+      if (jb->journal_list && jb->bitmaps[bmap_nr] &&
+          test_bit(bit_nr, (unsigned long *)jb->bitmaps[bmap_nr]->data)) {
+	*next_zero_bit = find_next_zero_bit((unsigned long *)
+	                             (jb->bitmaps[bmap_nr]->data),
+	                             p_s_sb->s_blocksize << 3, bit_nr+1) ; 
+	return 1 ;
+      }
+    }
+  }
+
+  bl = bmap_nr * (p_s_sb->s_blocksize << 3) + bit_nr;
+  /* is it in any old transactions? */
+  if (search_all && (cn = get_journal_hash_dev(p_s_sb, journal->j_list_hash_table, bl))) {
+    return 1; 
+  }
+
+  /* is it in the current transaction.  This should never happen */
+  if ((cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, bl))) {
+    BUG();
+    return 1; 
+  }
+
+  PROC_INFO_INC( p_s_sb, journal.in_journal_reusable );
+  /* safe for reuse */
+  return 0 ;
+}
+
+/* insert cn into table
+*/
+static inline void insert_journal_hash(struct reiserfs_journal_cnode **table, struct reiserfs_journal_cnode *cn) {
+  struct reiserfs_journal_cnode *cn_orig ;
+
+  cn_orig = journal_hash(table, cn->sb, cn->blocknr) ;
+  cn->hnext = cn_orig ;
+  cn->hprev = NULL ;
+  if (cn_orig) {
+    cn_orig->hprev = cn ;
+  }
+  journal_hash(table, cn->sb, cn->blocknr) =  cn ;
+}
+
+/* lock the current transaction */
+inline static void lock_journal(struct super_block *p_s_sb) {
+    PROC_INFO_INC( p_s_sb, journal.lock_journal );
+    down(&SB_JOURNAL(p_s_sb)->j_lock);
+}
+
+/* unlock the current transaction */
+inline static void unlock_journal(struct super_block *p_s_sb) {
+    up(&SB_JOURNAL(p_s_sb)->j_lock);
+}
+
+static inline void get_journal_list(struct reiserfs_journal_list *jl)
+{
+    jl->j_refcount++;
+}
+
+static inline void put_journal_list(struct super_block *s,
+                                   struct reiserfs_journal_list *jl)
+{
+    if (jl->j_refcount < 1) {
+        reiserfs_panic (s, "trans id %lu, refcount at %d", jl->j_trans_id,
+	                                         jl->j_refcount);
+    }
+    if (--jl->j_refcount == 0)
+        reiserfs_kfree(jl, sizeof(struct reiserfs_journal_list), s);
+}
+
+/*
+** this used to be much more involved, and I'm keeping it just in case things get ugly again.
+** it gets called by flush_commit_list, and cleans up any data stored about blocks freed during a
+** transaction.
+*/
+static void cleanup_freed_for_journal_list(struct super_block *p_s_sb, struct reiserfs_journal_list *jl) {
+
+  struct reiserfs_list_bitmap *jb = jl->j_list_bitmap ;
+  if (jb) {
+    cleanup_bitmap_list(p_s_sb, jb) ;
+  }
+  jl->j_list_bitmap->journal_list = NULL ;
+  jl->j_list_bitmap = NULL ;
+}
+
+static int journal_list_still_alive(struct super_block *s,
+                                    unsigned long trans_id)
+{
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    struct list_head *entry = &journal->j_journal_list;
+    struct reiserfs_journal_list *jl;
+
+    if (!list_empty(entry)) {
+        jl = JOURNAL_LIST_ENTRY(entry->next);
+	if (jl->j_trans_id <= trans_id) {
+	    return 1;
+	}
+    }
+    return 0;
+}
+
+static void reiserfs_end_buffer_io_sync(struct buffer_head *bh, int uptodate) {
+    char b[BDEVNAME_SIZE];
+
+    if (buffer_journaled(bh)) {
+        reiserfs_warning(NULL, "clm-2084: pinned buffer %lu:%s sent to disk",
+	                 bh->b_blocknr, bdevname(bh->b_bdev, b)) ;
+    }
+    if (uptodate)
+    	set_buffer_uptodate(bh) ;
+    else
+    	clear_buffer_uptodate(bh) ;
+    unlock_buffer(bh) ;
+    put_bh(bh) ;
+}
+
+static void reiserfs_end_ordered_io(struct buffer_head *bh, int uptodate) {
+    if (uptodate)
+    	set_buffer_uptodate(bh) ;
+    else
+    	clear_buffer_uptodate(bh) ;
+    unlock_buffer(bh) ;
+    put_bh(bh) ;
+}
+
+static void submit_logged_buffer(struct buffer_head *bh) {
+    get_bh(bh) ;
+    bh->b_end_io = reiserfs_end_buffer_io_sync ;
+    clear_buffer_journal_new (bh);
+    clear_buffer_dirty(bh) ;
+    if (!test_clear_buffer_journal_test (bh))
+        BUG();
+    if (!buffer_uptodate(bh))
+        BUG();
+    submit_bh(WRITE, bh) ;
+}
+
+static void submit_ordered_buffer(struct buffer_head *bh) {
+    get_bh(bh) ;
+    bh->b_end_io = reiserfs_end_ordered_io;
+    clear_buffer_dirty(bh) ;
+    if (!buffer_uptodate(bh))
+        BUG();
+    submit_bh(WRITE, bh) ;
+}
+
+static int submit_barrier_buffer(struct buffer_head *bh) {
+    get_bh(bh) ;
+    bh->b_end_io = reiserfs_end_ordered_io;
+    clear_buffer_dirty(bh) ;
+    if (!buffer_uptodate(bh))
+        BUG();
+    return submit_bh(WRITE_BARRIER, bh) ;
+}
+
+static void check_barrier_completion(struct super_block *s,
+                                     struct buffer_head *bh) {
+    if (buffer_eopnotsupp(bh)) {
+	clear_buffer_eopnotsupp(bh);
+	disable_barrier(s);
+	set_buffer_uptodate(bh);
+	set_buffer_dirty(bh);
+	sync_dirty_buffer(bh);
+    }
+}
+
+#define CHUNK_SIZE 32
+struct buffer_chunk {
+    struct buffer_head *bh[CHUNK_SIZE];
+    int nr;
+};
+
+static void write_chunk(struct buffer_chunk *chunk) {
+    int i;
+    for (i = 0; i < chunk->nr ; i++) {
+	submit_logged_buffer(chunk->bh[i]) ;
+    }
+    chunk->nr = 0;
+}
+
+static void write_ordered_chunk(struct buffer_chunk *chunk) {
+    int i;
+    for (i = 0; i < chunk->nr ; i++) {
+	submit_ordered_buffer(chunk->bh[i]) ;
+    }
+    chunk->nr = 0;
+}
+
+static int add_to_chunk(struct buffer_chunk *chunk, struct buffer_head *bh,
+			 spinlock_t *lock,
+			 void (fn)(struct buffer_chunk *))
+{
+    int ret = 0;
+    if (chunk->nr >= CHUNK_SIZE)
+        BUG();
+    chunk->bh[chunk->nr++] = bh;
+    if (chunk->nr >= CHUNK_SIZE) {
+	ret = 1;
+        if (lock)
+	    spin_unlock(lock);
+        fn(chunk);
+        if (lock)
+	    spin_lock(lock);
+    }
+    return ret;
+}
+
+
+static atomic_t nr_reiserfs_jh = ATOMIC_INIT(0);
+static struct reiserfs_jh *alloc_jh(void) {
+    struct reiserfs_jh *jh;
+    while(1) {
+	jh = kmalloc(sizeof(*jh), GFP_NOFS);
+	if (jh) {
+	    atomic_inc(&nr_reiserfs_jh);
+	    return jh;
+	}
+        yield();
+    }
+}
+
+/*
+ * we want to free the jh when the buffer has been written
+ * and waited on
+ */
+void reiserfs_free_jh(struct buffer_head *bh) {
+    struct reiserfs_jh *jh;
+
+    jh = bh->b_private;
+    if (jh) {
+	bh->b_private = NULL;
+	jh->bh = NULL;
+	list_del_init(&jh->list);
+	kfree(jh);
+	if (atomic_read(&nr_reiserfs_jh) <= 0)
+	    BUG();
+	atomic_dec(&nr_reiserfs_jh);
+	put_bh(bh);
+    }
+}
+
+static inline int __add_jh(struct reiserfs_journal *j, struct buffer_head *bh,
+                           int tail)
+{
+    struct reiserfs_jh *jh;
+
+    if (bh->b_private) {
+	spin_lock(&j->j_dirty_buffers_lock);
+	if (!bh->b_private) {
+	    spin_unlock(&j->j_dirty_buffers_lock);
+	    goto no_jh;
+	}
+        jh = bh->b_private;
+	list_del_init(&jh->list);
+    } else {
+no_jh:
+	get_bh(bh);
+	jh = alloc_jh();
+	spin_lock(&j->j_dirty_buffers_lock);
+	/* buffer must be locked for __add_jh, should be able to have
+	 * two adds at the same time
+	 */
+	if (bh->b_private)
+	    BUG();
+	jh->bh = bh;
+	bh->b_private = jh;
+    }
+    jh->jl = j->j_current_jl;
+    if (tail)
+	list_add_tail(&jh->list, &jh->jl->j_tail_bh_list);
+    else {
+	list_add_tail(&jh->list, &jh->jl->j_bh_list);
+    }
+    spin_unlock(&j->j_dirty_buffers_lock);
+    return 0;
+}
+
+int reiserfs_add_tail_list(struct inode *inode, struct buffer_head *bh) {
+    return __add_jh(SB_JOURNAL(inode->i_sb), bh, 1);
+}
+int reiserfs_add_ordered_list(struct inode *inode, struct buffer_head *bh) {
+    return __add_jh(SB_JOURNAL(inode->i_sb), bh, 0);
+}
+
+#define JH_ENTRY(l) list_entry((l), struct reiserfs_jh, list)
+static int write_ordered_buffers(spinlock_t *lock,
+				 struct reiserfs_journal *j,
+                                 struct reiserfs_journal_list *jl,
+				 struct list_head *list)
+{
+    struct buffer_head *bh;
+    struct reiserfs_jh *jh;
+    int ret = j->j_errno;
+    struct buffer_chunk chunk;
+    struct list_head tmp;
+    INIT_LIST_HEAD(&tmp);
+
+    chunk.nr = 0;
+    spin_lock(lock);
+    while(!list_empty(list)) {
+        jh = JH_ENTRY(list->next);
+	bh = jh->bh;
+	get_bh(bh);
+	if (test_set_buffer_locked(bh)) {
+	    if (!buffer_dirty(bh)) {
+		list_del_init(&jh->list);
+		list_add(&jh->list, &tmp);
+		goto loop_next;
+	    }
+	    spin_unlock(lock);
+	    if (chunk.nr)
+		write_ordered_chunk(&chunk);
+	    wait_on_buffer(bh);
+	    cond_resched();
+	    spin_lock(lock);
+	    goto loop_next;
+        }
+	if (buffer_dirty(bh)) {
+	    list_del_init(&jh->list);
+	    list_add(&jh->list, &tmp);
+            add_to_chunk(&chunk, bh, lock, write_ordered_chunk);
+	} else {
+	    reiserfs_free_jh(bh);
+	    unlock_buffer(bh);
+	}
+loop_next:
+	put_bh(bh);
+	cond_resched_lock(lock);
+    }
+    if (chunk.nr) {
+	spin_unlock(lock);
+        write_ordered_chunk(&chunk);
+	spin_lock(lock);
+    }
+    while(!list_empty(&tmp)) {
+        jh = JH_ENTRY(tmp.prev);
+	bh = jh->bh;
+	get_bh(bh);
+	reiserfs_free_jh(bh);
+
+	if (buffer_locked(bh)) {
+	    spin_unlock(lock);
+	    wait_on_buffer(bh);
+	    spin_lock(lock);
+	}
+	if (!buffer_uptodate(bh)) {
+	    ret = -EIO;
+        }
+	put_bh(bh);
+	cond_resched_lock(lock);
+    }
+    spin_unlock(lock);
+    return ret;
+}
+
+static int flush_older_commits(struct super_block *s, struct reiserfs_journal_list *jl) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    struct reiserfs_journal_list *other_jl;
+    struct reiserfs_journal_list *first_jl;
+    struct list_head *entry;
+    unsigned long trans_id = jl->j_trans_id;
+    unsigned long other_trans_id;
+    unsigned long first_trans_id;
+
+find_first:
+    /*
+     * first we walk backwards to find the oldest uncommitted transation
+     */
+    first_jl = jl;
+    entry = jl->j_list.prev;
+    while(1) {
+	other_jl = JOURNAL_LIST_ENTRY(entry);
+	if (entry == &journal->j_journal_list ||
+	    atomic_read(&other_jl->j_older_commits_done))
+	    break;
+
+        first_jl = other_jl;
+	entry = other_jl->j_list.prev;
+    }
+
+    /* if we didn't find any older uncommitted transactions, return now */
+    if (first_jl == jl) {
+        return 0;
+    }
+
+    first_trans_id = first_jl->j_trans_id;
+
+    entry = &first_jl->j_list;
+    while(1) {
+	other_jl = JOURNAL_LIST_ENTRY(entry);
+	other_trans_id = other_jl->j_trans_id;
+
+	if (other_trans_id < trans_id) {
+	    if (atomic_read(&other_jl->j_commit_left) != 0) {
+		flush_commit_list(s, other_jl, 0);
+
+		/* list we were called with is gone, return */
+		if (!journal_list_still_alive(s, trans_id))
+		    return 1;
+
+		/* the one we just flushed is gone, this means all
+		 * older lists are also gone, so first_jl is no longer
+		 * valid either.  Go back to the beginning.
+		 */
+		if (!journal_list_still_alive(s, other_trans_id)) {
+		    goto find_first;
+		}
+	    }
+	    entry = entry->next;
+	    if (entry == &journal->j_journal_list)
+		return 0;
+	} else {
+	    return 0;
+	}
+    }
+    return 0;
+}
+int reiserfs_async_progress_wait(struct super_block *s) {
+    DEFINE_WAIT(wait);
+    struct reiserfs_journal *j = SB_JOURNAL(s);
+    if (atomic_read(&j->j_async_throttle))
+    	blk_congestion_wait(WRITE, HZ/10);
+    return 0;
+}
+
+/*
+** if this journal list still has commit blocks unflushed, send them to disk.
+**
+** log areas must be flushed in order (transaction 2 can't commit before transaction 1)
+** Before the commit block can by written, every other log block must be safely on disk
+**
+*/
+static int flush_commit_list(struct super_block *s, struct reiserfs_journal_list *jl, int flushall) {
+  int i;
+  int bn ;
+  struct buffer_head *tbh = NULL ;
+  unsigned long trans_id = jl->j_trans_id;
+  struct reiserfs_journal *journal = SB_JOURNAL (s);
+  int barrier = 0;
+  int retval = 0;
+
+  reiserfs_check_lock_depth(s, "flush_commit_list") ;
+
+  if (atomic_read(&jl->j_older_commits_done)) {
+    return 0 ;
+  }
+
+  /* before we can put our commit blocks on disk, we have to make sure everyone older than
+  ** us is on disk too
+  */
+  BUG_ON (jl->j_len <= 0);
+  BUG_ON (trans_id == journal->j_trans_id);
+
+  get_journal_list(jl);
+  if (flushall) {
+    if (flush_older_commits(s, jl) == 1) {
+      /* list disappeared during flush_older_commits.  return */
+      goto put_jl;
+    }
+  }
+
+  /* make sure nobody is trying to flush this one at the same time */
+  down(&jl->j_commit_lock);
+  if (!journal_list_still_alive(s, trans_id)) {
+    up(&jl->j_commit_lock);
+    goto put_jl;
+  }
+  BUG_ON (jl->j_trans_id == 0);
+
+  /* this commit is done, exit */
+  if (atomic_read(&(jl->j_commit_left)) <= 0) {
+    if (flushall) {
+      atomic_set(&(jl->j_older_commits_done), 1) ;
+    }
+    up(&jl->j_commit_lock);
+    goto put_jl;
+  }
+
+  if (!list_empty(&jl->j_bh_list)) {
+      unlock_kernel();
+      write_ordered_buffers(&journal->j_dirty_buffers_lock,
+                            journal, jl, &jl->j_bh_list);
+      lock_kernel();
+  }
+  BUG_ON (!list_empty(&jl->j_bh_list));
+  /*
+   * for the description block and all the log blocks, submit any buffers
+   * that haven't already reached the disk
+   */
+  atomic_inc(&journal->j_async_throttle);
+  for (i = 0 ; i < (jl->j_len + 1) ; i++) {
+    bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) + (jl->j_start+i) %
+         SB_ONDISK_JOURNAL_SIZE(s);
+    tbh = journal_find_get_block(s, bn) ;
+    if (buffer_dirty(tbh)) /* redundant, ll_rw_block() checks */
+	ll_rw_block(WRITE, 1, &tbh) ;
+    put_bh(tbh) ;
+  }
+  atomic_dec(&journal->j_async_throttle);
+
+  /* wait on everything written so far before writing the commit
+   * if we are in barrier mode, send the commit down now
+   */
+  barrier = reiserfs_barrier_flush(s);
+  if (barrier) {
+      int ret;
+      lock_buffer(jl->j_commit_bh);
+      ret = submit_barrier_buffer(jl->j_commit_bh);
+      if (ret == -EOPNOTSUPP) {
+	  set_buffer_uptodate(jl->j_commit_bh);
+          disable_barrier(s);
+	  barrier = 0;
+      }
+  }
+  for (i = 0 ;  i < (jl->j_len + 1) ; i++) {
+    bn = SB_ONDISK_JOURNAL_1st_BLOCK(s) +
+	 (jl->j_start + i) % SB_ONDISK_JOURNAL_SIZE(s) ;
+    tbh = journal_find_get_block(s, bn) ;
+    wait_on_buffer(tbh) ;
+    // since we're using ll_rw_blk above, it might have skipped over
+    // a locked buffer.  Double check here
+    //
+    if (buffer_dirty(tbh)) /* redundant, sync_dirty_buffer() checks */
+      sync_dirty_buffer(tbh);
+    if (unlikely (!buffer_uptodate(tbh))) {
+#ifdef CONFIG_REISERFS_CHECK
+      reiserfs_warning(s, "journal-601, buffer write failed") ;
+#endif
+      retval = -EIO;
+    }
+    put_bh(tbh) ; /* once for journal_find_get_block */
+    put_bh(tbh) ;    /* once due to original getblk in do_journal_end */
+    atomic_dec(&(jl->j_commit_left)) ;
+  }
+
+  BUG_ON (atomic_read(&(jl->j_commit_left)) != 1);
+
+  if (!barrier) {
+      if (buffer_dirty(jl->j_commit_bh))
+	BUG();
+      mark_buffer_dirty(jl->j_commit_bh) ;
+      sync_dirty_buffer(jl->j_commit_bh) ;
+  } else
+      wait_on_buffer(jl->j_commit_bh);
+
+  check_barrier_completion(s, jl->j_commit_bh);
+
+  /* If there was a write error in the journal - we can't commit this
+   * transaction - it will be invalid and, if successful, will just end
+   * up propogating the write error out to the filesystem. */
+  if (unlikely (!buffer_uptodate(jl->j_commit_bh))) {
+#ifdef CONFIG_REISERFS_CHECK
+    reiserfs_warning(s, "journal-615: buffer write failed") ;
+#endif
+    retval = -EIO;
+  }
+  bforget(jl->j_commit_bh) ;
+  if (journal->j_last_commit_id != 0 &&
+     (jl->j_trans_id - journal->j_last_commit_id) != 1) {
+      reiserfs_warning(s, "clm-2200: last commit %lu, current %lu",
+                       journal->j_last_commit_id,
+		       jl->j_trans_id);
+  }
+  journal->j_last_commit_id = jl->j_trans_id;
+
+  /* now, every commit block is on the disk.  It is safe to allow blocks freed during this transaction to be reallocated */
+  cleanup_freed_for_journal_list(s, jl) ;
+
+  retval = retval ? retval : journal->j_errno;
+
+  /* mark the metadata dirty */
+  if (!retval)
+    dirty_one_transaction(s, jl);
+  atomic_dec(&(jl->j_commit_left)) ;
+
+  if (flushall) {
+    atomic_set(&(jl->j_older_commits_done), 1) ;
+  }
+  up(&jl->j_commit_lock);
+put_jl:
+  put_journal_list(s, jl);
+
+  if (retval)
+    reiserfs_abort (s, retval, "Journal write error in %s", __FUNCTION__);
+  return retval;
+}
+
+/*
+** flush_journal_list frequently needs to find a newer transaction for a given block.  This does that, or 
+** returns NULL if it can't find anything 
+*/
+static struct reiserfs_journal_list *find_newer_jl_for_cn(struct reiserfs_journal_cnode *cn) {
+  struct super_block *sb = cn->sb;
+  b_blocknr_t blocknr = cn->blocknr ;
+
+  cn = cn->hprev ;
+  while(cn) {
+    if (cn->sb == sb && cn->blocknr == blocknr && cn->jlist) {
+      return cn->jlist ;
+    }
+    cn = cn->hprev ;
+  }
+  return NULL ;
+}
+
+static void remove_journal_hash(struct super_block *, struct reiserfs_journal_cnode **,
+struct reiserfs_journal_list *, unsigned long, int);
+
+/*
+** once all the real blocks have been flushed, it is safe to remove them from the
+** journal list for this transaction.  Aside from freeing the cnode, this also allows the
+** block to be reallocated for data blocks if it had been deleted.
+*/
+static void remove_all_from_journal_list(struct super_block *p_s_sb, struct reiserfs_journal_list *jl, int debug) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_cnode *cn, *last ;
+  cn = jl->j_realblock ;
+
+  /* which is better, to lock once around the whole loop, or
+  ** to lock for each call to remove_journal_hash?
+  */
+  while(cn) {
+    if (cn->blocknr != 0) {
+      if (debug) {
+       reiserfs_warning (p_s_sb, "block %u, bh is %d, state %ld", cn->blocknr,
+                         cn->bh ? 1: 0, cn->state) ;
+      }
+      cn->state = 0 ;
+      remove_journal_hash(p_s_sb, journal->j_list_hash_table, jl, cn->blocknr, 1) ;
+    }
+    last = cn ;
+    cn = cn->next ;
+    free_cnode(p_s_sb, last) ;
+  }
+  jl->j_realblock = NULL ;
+}
+
+/*
+** if this timestamp is greater than the timestamp we wrote last to the header block, write it to the header block.
+** once this is done, I can safely say the log area for this transaction won't ever be replayed, and I can start
+** releasing blocks in this transaction for reuse as data blocks.
+** called by flush_journal_list, before it calls remove_all_from_journal_list
+**
+*/
+static int _update_journal_header_block(struct super_block *p_s_sb, unsigned long offset, unsigned long trans_id) {
+  struct reiserfs_journal_header *jh ;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+  if (reiserfs_is_journal_aborted (journal))
+    return -EIO;
+
+  if (trans_id >= journal->j_last_flush_trans_id) {
+    if (buffer_locked((journal->j_header_bh)))  {
+      wait_on_buffer((journal->j_header_bh)) ;
+      if (unlikely (!buffer_uptodate(journal->j_header_bh))) {
+#ifdef CONFIG_REISERFS_CHECK
+        reiserfs_warning (p_s_sb, "journal-699: buffer write failed") ;
+#endif
+        return -EIO;
+      }
+    }
+    journal->j_last_flush_trans_id = trans_id ;
+    journal->j_first_unflushed_offset = offset ;
+    jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data) ;
+    jh->j_last_flush_trans_id = cpu_to_le32(trans_id) ;
+    jh->j_first_unflushed_offset = cpu_to_le32(offset) ;
+    jh->j_mount_id = cpu_to_le32(journal->j_mount_id) ;
+
+    if (reiserfs_barrier_flush(p_s_sb)) {
+	int ret;
+	lock_buffer(journal->j_header_bh);
+	ret = submit_barrier_buffer(journal->j_header_bh);
+	if (ret == -EOPNOTSUPP) {
+	    set_buffer_uptodate(journal->j_header_bh);
+	    disable_barrier(p_s_sb);
+	    goto sync;
+	}
+	wait_on_buffer(journal->j_header_bh);
+	check_barrier_completion(p_s_sb, journal->j_header_bh);
+    } else {
+sync:
+	set_buffer_dirty(journal->j_header_bh) ;
+	sync_dirty_buffer(journal->j_header_bh) ;
+    }
+    if (!buffer_uptodate(journal->j_header_bh)) {
+      reiserfs_warning (p_s_sb, "journal-837: IO error during journal replay");
+      return -EIO ;
+    }
+  }
+  return 0 ;
+}
+
+static int update_journal_header_block(struct super_block *p_s_sb, 
+                                       unsigned long offset, 
+				       unsigned long trans_id) {
+    return _update_journal_header_block(p_s_sb, offset, trans_id);
+}
+/* 
+** flush any and all journal lists older than you are 
+** can only be called from flush_journal_list
+*/
+static int flush_older_journal_lists(struct super_block *p_s_sb,
+                                     struct reiserfs_journal_list *jl)
+{
+    struct list_head *entry;
+    struct reiserfs_journal_list *other_jl ;
+    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+    unsigned long trans_id = jl->j_trans_id;
+
+    /* we know we are the only ones flushing things, no extra race
+     * protection is required.
+     */
+restart:
+    entry = journal->j_journal_list.next;
+    /* Did we wrap? */
+    if (entry == &journal->j_journal_list)
+        return 0;
+    other_jl = JOURNAL_LIST_ENTRY(entry);
+    if (other_jl->j_trans_id < trans_id) {
+        BUG_ON (other_jl->j_refcount <= 0);
+	/* do not flush all */
+	flush_journal_list(p_s_sb, other_jl, 0) ;
+
+	/* other_jl is now deleted from the list */
+	goto restart;
+    }
+    return 0 ;
+}
+
+static void del_from_work_list(struct super_block *s,
+                               struct reiserfs_journal_list *jl) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    if (!list_empty(&jl->j_working_list)) {
+	list_del_init(&jl->j_working_list);
+	journal->j_num_work_lists--;
+    }
+}
+
+/* flush a journal list, both commit and real blocks
+**
+** always set flushall to 1, unless you are calling from inside
+** flush_journal_list
+**
+** IMPORTANT.  This can only be called while there are no journal writers, 
+** and the journal is locked.  That means it can only be called from 
+** do_journal_end, or by journal_release
+*/
+static int flush_journal_list(struct super_block *s, 
+                              struct reiserfs_journal_list *jl, int flushall) {
+  struct reiserfs_journal_list *pjl ;
+  struct reiserfs_journal_cnode *cn, *last ;
+  int count ;
+  int was_jwait = 0 ;
+  int was_dirty = 0 ;
+  struct buffer_head *saved_bh ; 
+  unsigned long j_len_saved = jl->j_len ;
+  struct reiserfs_journal *journal = SB_JOURNAL (s);
+  int err = 0;
+
+  BUG_ON (j_len_saved <= 0);
+
+  if (atomic_read(&journal->j_wcount) != 0) {
+    reiserfs_warning(s, "clm-2048: flush_journal_list called with wcount %d",
+                      atomic_read(&journal->j_wcount)) ;
+  }
+  BUG_ON (jl->j_trans_id == 0);
+
+  /* if flushall == 0, the lock is already held */
+  if (flushall) {
+      down(&journal->j_flush_sem);
+  } else if (!down_trylock(&journal->j_flush_sem)) {
+      BUG();
+  }
+
+  count = 0 ;
+  if (j_len_saved > journal->j_trans_max) {
+    reiserfs_panic(s, "journal-715: flush_journal_list, length is %lu, trans id %lu\n", j_len_saved, jl->j_trans_id);
+    return 0 ;
+  }
+
+  /* if all the work is already done, get out of here */
+  if (atomic_read(&(jl->j_nonzerolen)) <= 0 && 
+      atomic_read(&(jl->j_commit_left)) <= 0) {
+    goto flush_older_and_return ;
+  } 
+
+  /* start by putting the commit list on disk.  This will also flush 
+  ** the commit lists of any olders transactions
+  */
+  flush_commit_list(s, jl, 1) ;
+
+  if (!(jl->j_state & LIST_DIRTY) && !reiserfs_is_journal_aborted (journal))
+      BUG();
+
+  /* are we done now? */
+  if (atomic_read(&(jl->j_nonzerolen)) <= 0 && 
+      atomic_read(&(jl->j_commit_left)) <= 0) {
+    goto flush_older_and_return ;
+  }
+
+  /* loop through each cnode, see if we need to write it, 
+  ** or wait on a more recent transaction, or just ignore it 
+  */
+  if (atomic_read(&(journal->j_wcount)) != 0) {
+    reiserfs_panic(s, "journal-844: panic journal list is flushing, wcount is not 0\n") ;
+  }
+  cn = jl->j_realblock ;
+  while(cn) {
+    was_jwait = 0 ;
+    was_dirty = 0 ;
+    saved_bh = NULL ;
+    /* blocknr of 0 is no longer in the hash, ignore it */
+    if (cn->blocknr == 0) {
+      goto free_cnode ;
+    }
+
+    /* This transaction failed commit. Don't write out to the disk */
+    if (!(jl->j_state & LIST_DIRTY))
+        goto free_cnode;
+
+    pjl = find_newer_jl_for_cn(cn) ;
+    /* the order is important here.  We check pjl to make sure we
+    ** don't clear BH_JDirty_wait if we aren't the one writing this
+    ** block to disk
+    */
+    if (!pjl && cn->bh) {
+      saved_bh = cn->bh ;
+
+      /* we do this to make sure nobody releases the buffer while 
+      ** we are working with it 
+      */
+      get_bh(saved_bh) ;
+
+      if (buffer_journal_dirty(saved_bh)) {
+        BUG_ON (!can_dirty (cn));
+        was_jwait = 1 ;
+        was_dirty = 1 ;
+      } else if (can_dirty(cn)) {
+        /* everything with !pjl && jwait should be writable */
+	BUG();
+      }
+    }
+
+    /* if someone has this block in a newer transaction, just make
+    ** sure they are commited, and don't try writing it to disk
+    */
+    if (pjl) {
+      if (atomic_read(&pjl->j_commit_left))
+        flush_commit_list(s, pjl, 1) ;
+      goto free_cnode ;
+    }
+
+    /* bh == NULL when the block got to disk on its own, OR, 
+    ** the block got freed in a future transaction 
+    */
+    if (saved_bh == NULL) {
+      goto free_cnode ;
+    }
+
+    /* this should never happen.  kupdate_one_transaction has this list
+    ** locked while it works, so we should never see a buffer here that
+    ** is not marked JDirty_wait
+    */
+    if ((!was_jwait) && !buffer_locked(saved_bh)) {
+	reiserfs_warning (s, "journal-813: BAD! buffer %llu %cdirty %cjwait, "
+			  "not in a newer tranasction",
+			  (unsigned long long)saved_bh->b_blocknr,
+			  was_dirty ? ' ' : '!', was_jwait ? ' ' : '!') ;
+    }
+    if (was_dirty) { 
+      /* we inc again because saved_bh gets decremented at free_cnode */
+      get_bh(saved_bh) ;
+      set_bit(BLOCK_NEEDS_FLUSH, &cn->state) ;
+      lock_buffer(saved_bh);
+      BUG_ON (cn->blocknr != saved_bh->b_blocknr);
+      if (buffer_dirty(saved_bh))
+        submit_logged_buffer(saved_bh) ;
+      else
+        unlock_buffer(saved_bh);
+      count++ ;
+    } else {
+      reiserfs_warning (s, "clm-2082: Unable to flush buffer %llu in %s",
+                        (unsigned long long)saved_bh->b_blocknr, __FUNCTION__);
+    }
+free_cnode:
+    last = cn ;
+    cn = cn->next ;
+    if (saved_bh) {
+      /* we incremented this to keep others from taking the buffer head away */
+      put_bh(saved_bh) ;
+      if (atomic_read(&(saved_bh->b_count)) < 0) {
+        reiserfs_warning (s, "journal-945: saved_bh->b_count < 0");
+      }
+    }
+  }
+  if (count > 0) {
+    cn = jl->j_realblock ;
+    while(cn) {
+      if (test_bit(BLOCK_NEEDS_FLUSH, &cn->state)) {
+	if (!cn->bh) {
+	  reiserfs_panic(s, "journal-1011: cn->bh is NULL\n") ;
+	}
+	wait_on_buffer(cn->bh) ;
+	if (!cn->bh) {
+	  reiserfs_panic(s, "journal-1012: cn->bh is NULL\n") ;
+	}
+	if (unlikely (!buffer_uptodate(cn->bh))) {
+#ifdef CONFIG_REISERFS_CHECK
+	  reiserfs_warning(s, "journal-949: buffer write failed\n") ;
+#endif
+          err = -EIO;
+  	}
+	/* note, we must clear the JDirty_wait bit after the up to date
+	** check, otherwise we race against our flushpage routine
+	*/
+        BUG_ON (!test_clear_buffer_journal_dirty (cn->bh));
+
+        /* undo the inc from journal_mark_dirty */
+	put_bh(cn->bh) ;
+        brelse(cn->bh) ;
+      }
+      cn = cn->next ;
+    }
+  }
+
+  if (err)
+    reiserfs_abort (s, -EIO, "Write error while pushing transaction to disk in %s", __FUNCTION__);
+flush_older_and_return:
+
+
+  /* before we can update the journal header block, we _must_ flush all 
+  ** real blocks from all older transactions to disk.  This is because
+  ** once the header block is updated, this transaction will not be
+  ** replayed after a crash
+  */
+  if (flushall) {
+    flush_older_journal_lists(s, jl);
+  } 
+  
+  err = journal->j_errno;
+  /* before we can remove everything from the hash tables for this 
+  ** transaction, we must make sure it can never be replayed
+  **
+  ** since we are only called from do_journal_end, we know for sure there
+  ** are no allocations going on while we are flushing journal lists.  So,
+  ** we only need to update the journal header block for the last list
+  ** being flushed
+  */
+  if (!err && flushall) {
+    err = update_journal_header_block(s, (jl->j_start + jl->j_len + 2) % SB_ONDISK_JOURNAL_SIZE(s), jl->j_trans_id) ;
+    if (err)
+        reiserfs_abort (s, -EIO, "Write error while updating journal header in %s", __FUNCTION__);
+  }
+  remove_all_from_journal_list(s, jl, 0) ;
+  list_del_init(&jl->j_list);
+  journal->j_num_lists--;
+  del_from_work_list(s, jl);
+
+  if (journal->j_last_flush_id != 0 &&
+     (jl->j_trans_id - journal->j_last_flush_id) != 1) {
+      reiserfs_warning(s, "clm-2201: last flush %lu, current %lu",
+                       journal->j_last_flush_id,
+		       jl->j_trans_id);
+  }
+  journal->j_last_flush_id = jl->j_trans_id;
+
+  /* not strictly required since we are freeing the list, but it should
+   * help find code using dead lists later on
+   */
+  jl->j_len = 0 ;
+  atomic_set(&(jl->j_nonzerolen), 0) ;
+  jl->j_start = 0 ;
+  jl->j_realblock = NULL ;
+  jl->j_commit_bh = NULL ;
+  jl->j_trans_id = 0 ;
+  jl->j_state = 0;
+  put_journal_list(s, jl);
+  if (flushall)
+    up(&journal->j_flush_sem);
+  return err ;
+} 
+
+static int write_one_transaction(struct super_block *s,
+                                 struct reiserfs_journal_list *jl,
+				 struct buffer_chunk *chunk)
+{
+    struct reiserfs_journal_cnode *cn;
+    int ret = 0 ;
+
+    jl->j_state |= LIST_TOUCHED;
+    del_from_work_list(s, jl);
+    if (jl->j_len == 0 || atomic_read(&jl->j_nonzerolen) == 0) {
+        return 0;
+    }
+
+    cn = jl->j_realblock ;
+    while(cn) {
+        /* if the blocknr == 0, this has been cleared from the hash,
+        ** skip it
+        */
+        if (cn->blocknr == 0) {
+            goto next ;
+        }
+        if (cn->bh && can_dirty(cn) && buffer_dirty(cn->bh)) {
+	    struct buffer_head *tmp_bh;
+	    /* we can race against journal_mark_freed when we try
+	     * to lock_buffer(cn->bh), so we have to inc the buffer
+	     * count, and recheck things after locking
+	     */
+	    tmp_bh = cn->bh;
+	    get_bh(tmp_bh);
+	    lock_buffer(tmp_bh);
+	    if (cn->bh && can_dirty(cn) && buffer_dirty(tmp_bh)) {
+		if (!buffer_journal_dirty(tmp_bh) ||
+		    buffer_journal_prepared(tmp_bh))
+		    BUG();
+		add_to_chunk(chunk, tmp_bh, NULL, write_chunk);
+		ret++;
+	    } else {
+		/* note, cn->bh might be null now */
+		unlock_buffer(tmp_bh);
+	    }
+	    put_bh(tmp_bh);
+        }
+next:
+        cn = cn->next ;
+	cond_resched();
+    }
+    return ret ;
+}
+
+/* used by flush_commit_list */
+static int dirty_one_transaction(struct super_block *s,
+                                 struct reiserfs_journal_list *jl)
+{
+    struct reiserfs_journal_cnode *cn;
+    struct reiserfs_journal_list *pjl;
+    int ret = 0 ;
+
+    jl->j_state |= LIST_DIRTY;
+    cn = jl->j_realblock ;
+    while(cn) {
+        /* look for a more recent transaction that logged this
+        ** buffer.  Only the most recent transaction with a buffer in
+        ** it is allowed to send that buffer to disk
+        */
+	pjl = find_newer_jl_for_cn(cn) ;
+        if (!pjl && cn->blocknr && cn->bh && buffer_journal_dirty(cn->bh))
+	{
+	    BUG_ON (!can_dirty(cn));
+	    /* if the buffer is prepared, it will either be logged
+	     * or restored.  If restored, we need to make sure
+	     * it actually gets marked dirty
+	     */
+            clear_buffer_journal_new (cn->bh);
+            if (buffer_journal_prepared (cn->bh)) {
+                set_buffer_journal_restore_dirty (cn->bh);
+	    } else {
+                set_buffer_journal_test (cn->bh);
+	        mark_buffer_dirty(cn->bh);
+	    }
+        } 
+        cn = cn->next ;
+    }
+    return ret ;
+}
+
+static int kupdate_transactions(struct super_block *s,
+                                   struct reiserfs_journal_list *jl,
+				   struct reiserfs_journal_list **next_jl,
+				   unsigned long *next_trans_id,
+				   int num_blocks,
+				   int num_trans) {
+    int ret = 0;
+    int written = 0 ;
+    int transactions_flushed = 0;
+    unsigned long orig_trans_id = jl->j_trans_id;
+    struct buffer_chunk chunk;
+    struct list_head *entry;
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    chunk.nr = 0;
+
+    down(&journal->j_flush_sem);
+    if (!journal_list_still_alive(s, orig_trans_id)) {
+	goto done;
+    }
+
+    /* we've got j_flush_sem held, nobody is going to delete any
+     * of these lists out from underneath us
+     */
+    while((num_trans && transactions_flushed < num_trans) ||
+          (!num_trans && written < num_blocks)) {
+
+	if (jl->j_len == 0 || (jl->j_state & LIST_TOUCHED) ||
+	    atomic_read(&jl->j_commit_left) || !(jl->j_state & LIST_DIRTY))
+	{
+	    del_from_work_list(s, jl);
+	    break;
+	}
+	ret = write_one_transaction(s, jl, &chunk);
+
+	if (ret < 0)
+	    goto done;
+	transactions_flushed++;
+	written += ret;
+	entry = jl->j_list.next;
+
+	/* did we wrap? */
+	if (entry == &journal->j_journal_list) {
+	    break;
+        }
+	jl = JOURNAL_LIST_ENTRY(entry);
+
+	/* don't bother with older transactions */
+	if (jl->j_trans_id <= orig_trans_id)
+	    break;
+    }
+    if (chunk.nr) {
+        write_chunk(&chunk);
+    }
+
+done:
+    up(&journal->j_flush_sem);
+    return ret;
+}
+
+/* for o_sync and fsync heavy applications, they tend to use
+** all the journa list slots with tiny transactions.  These
+** trigger lots and lots of calls to update the header block, which
+** adds seeks and slows things down.
+**
+** This function tries to clear out a large chunk of the journal lists
+** at once, which makes everything faster since only the newest journal
+** list updates the header block
+*/
+static int flush_used_journal_lists(struct super_block *s,
+                                    struct reiserfs_journal_list *jl) {
+    unsigned long len = 0;
+    unsigned long cur_len;
+    int ret;
+    int i;
+    int limit = 256;
+    struct reiserfs_journal_list *tjl;
+    struct reiserfs_journal_list *flush_jl;
+    unsigned long trans_id;
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+
+    flush_jl = tjl = jl;
+
+    /* in data logging mode, try harder to flush a lot of blocks */
+    if (reiserfs_data_log(s))
+	limit = 1024;
+    /* flush for 256 transactions or limit blocks, whichever comes first */
+    for(i = 0 ; i < 256 && len < limit ; i++) {
+	if (atomic_read(&tjl->j_commit_left) ||
+	    tjl->j_trans_id < jl->j_trans_id) {
+	    break;
+	}
+	cur_len = atomic_read(&tjl->j_nonzerolen);
+	if (cur_len > 0) {
+	    tjl->j_state &= ~LIST_TOUCHED;
+	}
+	len += cur_len;
+	flush_jl = tjl;
+	if (tjl->j_list.next == &journal->j_journal_list)
+	    break;
+	tjl = JOURNAL_LIST_ENTRY(tjl->j_list.next);
+    }
+    /* try to find a group of blocks we can flush across all the
+    ** transactions, but only bother if we've actually spanned
+    ** across multiple lists
+    */
+    if (flush_jl != jl) {
+        ret = kupdate_transactions(s, jl, &tjl, &trans_id, len, i);
+    }
+    flush_journal_list(s, flush_jl, 1);
+    return 0;
+}
+
+/*
+** removes any nodes in table with name block and dev as bh.
+** only touchs the hnext and hprev pointers.
+*/
+void remove_journal_hash(struct super_block *sb,
+			struct reiserfs_journal_cnode **table,
+			struct reiserfs_journal_list *jl,
+			unsigned long block, int remove_freed)
+{
+  struct reiserfs_journal_cnode *cur ;
+  struct reiserfs_journal_cnode **head ;
+
+  head= &(journal_hash(table, sb, block)) ;
+  if (!head) {
+    return ;
+  }
+  cur = *head ;
+  while(cur) {
+    if (cur->blocknr == block && cur->sb == sb && (jl == NULL || jl == cur->jlist) && 
+        (!test_bit(BLOCK_FREED, &cur->state) || remove_freed)) {
+      if (cur->hnext) {
+        cur->hnext->hprev = cur->hprev ;
+      }
+      if (cur->hprev) {
+	cur->hprev->hnext = cur->hnext ;
+      } else {
+	*head = cur->hnext ;
+      }
+      cur->blocknr = 0 ;
+      cur->sb = NULL ;
+      cur->state = 0 ;
+      if (cur->bh && cur->jlist) /* anybody who clears the cur->bh will also dec the nonzerolen */
+	atomic_dec(&(cur->jlist->j_nonzerolen)) ;
+      cur->bh = NULL ;
+      cur->jlist = NULL ;
+    } 
+    cur = cur->hnext ;
+  }
+}
+
+static void free_journal_ram(struct super_block *p_s_sb) {
+  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+  reiserfs_kfree(journal->j_current_jl,
+                 sizeof(struct reiserfs_journal_list), p_s_sb);
+  journal->j_num_lists--;
+
+  vfree(journal->j_cnode_free_orig) ;
+  free_list_bitmaps(p_s_sb, journal->j_list_bitmap) ;
+  free_bitmap_nodes(p_s_sb) ; /* must be after free_list_bitmaps */
+  if (journal->j_header_bh) {
+    brelse(journal->j_header_bh) ;
+  }
+  /* j_header_bh is on the journal dev, make sure not to release the journal
+   * dev until we brelse j_header_bh
+   */
+  release_journal_dev(p_s_sb, journal);
+  vfree(journal) ;
+}
+
+/*
+** call on unmount.  Only set error to 1 if you haven't made your way out
+** of read_super() yet.  Any other caller must keep error at 0.
+*/
+static int do_journal_release(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, int error) {
+  struct reiserfs_transaction_handle myth ;
+  int flushed = 0;
+  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+
+  /* we only want to flush out transactions if we were called with error == 0
+  */
+  if (!error && !(p_s_sb->s_flags & MS_RDONLY)) {
+    /* end the current trans */
+    BUG_ON (!th->t_trans_id);
+    do_journal_end(th, p_s_sb,10, FLUSH_ALL) ;
+
+    /* make sure something gets logged to force our way into the flush code */
+    if (!journal_join(&myth, p_s_sb, 1)) {
+        reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
+        journal_mark_dirty(&myth, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
+        do_journal_end(&myth, p_s_sb,1, FLUSH_ALL) ;
+        flushed = 1;
+    }
+  }
+
+  /* this also catches errors during the do_journal_end above */
+  if (!error && reiserfs_is_journal_aborted(journal)) {
+      memset(&myth, 0, sizeof(myth));
+      if (!journal_join_abort(&myth, p_s_sb, 1)) {
+	  reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
+	  journal_mark_dirty(&myth, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
+          do_journal_end(&myth, p_s_sb, 1, FLUSH_ALL) ;
+      }
+  }
+
+  reiserfs_mounted_fs_count-- ;
+  /* wait for all commits to finish */
+  cancel_delayed_work(&SB_JOURNAL(p_s_sb)->j_work);
+  flush_workqueue(commit_wq);
+  if (!reiserfs_mounted_fs_count) {
+    destroy_workqueue(commit_wq);
+    commit_wq = NULL;
+  }
+
+  free_journal_ram(p_s_sb) ;
+
+  return 0 ;
+}
+
+/*
+** call on unmount.  flush all journal trans, release all alloc'd ram
+*/
+int journal_release(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb) {
+  return do_journal_release(th, p_s_sb, 0) ;
+}
+/*
+** only call from an error condition inside reiserfs_read_super!
+*/
+int journal_release_error(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb) {
+  return do_journal_release(th, p_s_sb, 1) ;
+}
+
+/* compares description block with commit block.  returns 1 if they differ, 0 if they are the same */
+static int journal_compare_desc_commit(struct super_block *p_s_sb, struct reiserfs_journal_desc *desc, 
+			               struct reiserfs_journal_commit *commit) {
+  if (get_commit_trans_id (commit) != get_desc_trans_id (desc) || 
+      get_commit_trans_len (commit) != get_desc_trans_len (desc) || 
+      get_commit_trans_len (commit) > SB_JOURNAL(p_s_sb)->j_trans_max ||
+      get_commit_trans_len (commit) <= 0 
+  ) {
+    return 1 ;
+  }
+  return 0 ;
+}
+/* returns 0 if it did not find a description block  
+** returns -1 if it found a corrupt commit block
+** returns 1 if both desc and commit were valid 
+*/
+static int journal_transaction_is_valid(struct super_block *p_s_sb, struct buffer_head *d_bh, unsigned long *oldest_invalid_trans_id, unsigned long *newest_mount_id) {
+  struct reiserfs_journal_desc *desc ;
+  struct reiserfs_journal_commit *commit ;
+  struct buffer_head *c_bh ;
+  unsigned long offset ;
+
+  if (!d_bh)
+      return 0 ;
+
+  desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
+  if (get_desc_trans_len(desc) > 0 && !memcmp(get_journal_desc_magic (d_bh), JOURNAL_DESC_MAGIC, 8)) {
+    if (oldest_invalid_trans_id && *oldest_invalid_trans_id && get_desc_trans_id(desc) > *oldest_invalid_trans_id) {
+      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-986: transaction "
+	              "is valid returning because trans_id %d is greater than "
+		      "oldest_invalid %lu", get_desc_trans_id(desc),
+		       *oldest_invalid_trans_id);
+      return 0 ;
+    }
+    if (newest_mount_id && *newest_mount_id > get_desc_mount_id (desc)) {
+      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1087: transaction "
+                     "is valid returning because mount_id %d is less than "
+		     "newest_mount_id %lu", get_desc_mount_id (desc),
+		     *newest_mount_id) ;
+      return -1 ;
+    }
+    if ( get_desc_trans_len(desc) > SB_JOURNAL(p_s_sb)->j_trans_max ) {
+      reiserfs_warning(p_s_sb, "journal-2018: Bad transaction length %d encountered, ignoring transaction", get_desc_trans_len(desc));
+      return -1 ;
+    }
+    offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
+
+    /* ok, we have a journal description block, lets see if the transaction was valid */
+    c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		 ((offset + get_desc_trans_len(desc) + 1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
+    if (!c_bh)
+      return 0 ;
+    commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
+    if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
+      reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, 
+                     "journal_transaction_is_valid, commit offset %ld had bad "
+		     "time %d or length %d",
+		     c_bh->b_blocknr -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		     get_commit_trans_id (commit), 
+		     get_commit_trans_len(commit));
+      brelse(c_bh) ;
+      if (oldest_invalid_trans_id) {
+	*oldest_invalid_trans_id = get_desc_trans_id(desc) ;
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1004: "
+		       "transaction_is_valid setting oldest invalid trans_id "
+		       "to %d", get_desc_trans_id(desc)) ;
+      }
+      return -1; 
+    }
+    brelse(c_bh) ;
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1006: found valid "
+                   "transaction start offset %llu, len %d id %d",
+		   d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+		   get_desc_trans_len(desc), get_desc_trans_id(desc)) ;
+    return 1 ;
+  } else {
+    return 0 ;
+  }
+}
+
+static void brelse_array(struct buffer_head **heads, int num) {
+  int i ;
+  for (i = 0 ; i < num ; i++) {
+    brelse(heads[i]) ;
+  }
+}
+
+/*
+** given the start, and values for the oldest acceptable transactions,
+** this either reads in a replays a transaction, or returns because the transaction
+** is invalid, or too old.
+*/
+static int journal_read_transaction(struct super_block *p_s_sb, unsigned long cur_dblock, unsigned long oldest_start, 
+				    unsigned long oldest_trans_id, unsigned long newest_mount_id) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_desc *desc ;
+  struct reiserfs_journal_commit *commit ;
+  unsigned long trans_id = 0 ;
+  struct buffer_head *c_bh ;
+  struct buffer_head *d_bh ;
+  struct buffer_head **log_blocks = NULL ;
+  struct buffer_head **real_blocks = NULL ;
+  unsigned long trans_offset ;
+  int i;
+  int trans_half;
+
+  d_bh = journal_bread(p_s_sb, cur_dblock) ;
+  if (!d_bh)
+    return 1 ;
+  desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
+  trans_offset = d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
+  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1037: "
+                 "journal_read_transaction, offset %llu, len %d mount_id %d",
+		 d_bh->b_blocknr - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+		 get_desc_trans_len(desc), get_desc_mount_id(desc)) ;
+  if (get_desc_trans_id(desc) < oldest_trans_id) {
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1039: "
+                   "journal_read_trans skipping because %lu is too old",
+		   cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)) ;
+    brelse(d_bh) ;
+    return 1 ;
+  }
+  if (get_desc_mount_id(desc) != newest_mount_id) {
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1146: "
+                   "journal_read_trans skipping because %d is != "
+		   "newest_mount_id %lu", get_desc_mount_id(desc),
+		    newest_mount_id) ;
+    brelse(d_bh) ;
+    return 1 ;
+  }
+  c_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) +
+		((trans_offset + get_desc_trans_len(desc) + 1) % 
+		 SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
+  if (!c_bh) {
+    brelse(d_bh) ;
+    return 1 ;
+  }
+  commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
+  if (journal_compare_desc_commit(p_s_sb, desc, commit)) {
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal_read_transaction, "
+                   "commit offset %llu had bad time %d or length %d",
+		   c_bh->b_blocknr -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+		   get_commit_trans_id(commit), get_commit_trans_len(commit));
+    brelse(c_bh) ;
+    brelse(d_bh) ;
+    return 1; 
+  }
+  trans_id = get_desc_trans_id(desc) ;
+  /* now we know we've got a good transaction, and it was inside the valid time ranges */
+  log_blocks = reiserfs_kmalloc(get_desc_trans_len(desc) * sizeof(struct buffer_head *), GFP_NOFS, p_s_sb) ;
+  real_blocks = reiserfs_kmalloc(get_desc_trans_len(desc) * sizeof(struct buffer_head *), GFP_NOFS, p_s_sb) ;
+  if (!log_blocks  || !real_blocks) {
+    brelse(c_bh) ;
+    brelse(d_bh) ;
+    reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+    reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+    reiserfs_warning(p_s_sb, "journal-1169: kmalloc failed, unable to mount FS") ;
+    return -1 ;
+  }
+  /* get all the buffer heads */
+  trans_half = journal_trans_half (p_s_sb->s_blocksize) ;
+  for(i = 0 ; i < get_desc_trans_len(desc) ; i++) {
+    log_blocks[i] =  journal_getblk(p_s_sb,  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + (trans_offset + 1 + i) % SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+    if (i < trans_half) {
+      real_blocks[i] = sb_getblk(p_s_sb, le32_to_cpu(desc->j_realblock[i])) ;
+    } else {
+      real_blocks[i] = sb_getblk(p_s_sb, le32_to_cpu(commit->j_realblock[i - trans_half])) ;
+    }
+    if ( real_blocks[i]->b_blocknr > SB_BLOCK_COUNT(p_s_sb) ) {
+      reiserfs_warning(p_s_sb, "journal-1207: REPLAY FAILURE fsck required! Block to replay is outside of filesystem");
+      goto abort_replay;
+    }
+    /* make sure we don't try to replay onto log or reserved area */
+    if (is_block_in_log_or_reserved_area(p_s_sb, real_blocks[i]->b_blocknr)) {
+      reiserfs_warning(p_s_sb, "journal-1204: REPLAY FAILURE fsck required! Trying to replay onto a log block") ;
+abort_replay:
+      brelse_array(log_blocks, i) ;
+      brelse_array(real_blocks, i) ;
+      brelse(c_bh) ;
+      brelse(d_bh) ;
+      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      return -1 ;
+    }
+  }
+  /* read in the log blocks, memcpy to the corresponding real block */
+  ll_rw_block(READ, get_desc_trans_len(desc), log_blocks) ;
+  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
+    wait_on_buffer(log_blocks[i]) ;
+    if (!buffer_uptodate(log_blocks[i])) {
+      reiserfs_warning(p_s_sb, "journal-1212: REPLAY FAILURE fsck required! buffer write failed") ;
+      brelse_array(log_blocks + i, get_desc_trans_len(desc) - i) ;
+      brelse_array(real_blocks, get_desc_trans_len(desc)) ;
+      brelse(c_bh) ;
+      brelse(d_bh) ;
+      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      return -1 ;
+    }
+    memcpy(real_blocks[i]->b_data, log_blocks[i]->b_data, real_blocks[i]->b_size) ;
+    set_buffer_uptodate(real_blocks[i]) ;
+    brelse(log_blocks[i]) ;
+  }
+  /* flush out the real blocks */
+  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
+    set_buffer_dirty(real_blocks[i]) ;
+    ll_rw_block(WRITE, 1, real_blocks + i) ;
+  }
+  for (i = 0 ; i < get_desc_trans_len(desc) ; i++) {
+    wait_on_buffer(real_blocks[i]) ; 
+    if (!buffer_uptodate(real_blocks[i])) {
+      reiserfs_warning(p_s_sb, "journal-1226: REPLAY FAILURE, fsck required! buffer write failed") ;
+      brelse_array(real_blocks + i, get_desc_trans_len(desc) - i) ;
+      brelse(c_bh) ;
+      brelse(d_bh) ;
+      reiserfs_kfree(log_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      reiserfs_kfree(real_blocks, get_desc_trans_len(desc) * sizeof(struct buffer_head *), p_s_sb) ;
+      return -1 ;
+    }
+    brelse(real_blocks[i]) ;
+  }
+  cur_dblock =  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + ((trans_offset + get_desc_trans_len(desc) + 2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb)) ;
+  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1095: setting journal "
+                 "start to offset %ld",
+		 cur_dblock -  SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb)) ;
+  
+  /* init starting values for the first transaction, in case this is the last transaction to be replayed. */
+  journal->j_start = cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
+  journal->j_last_flush_trans_id = trans_id ;
+  journal->j_trans_id = trans_id + 1;
+  brelse(c_bh) ;
+  brelse(d_bh) ;
+  reiserfs_kfree(log_blocks, le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *), p_s_sb) ;
+  reiserfs_kfree(real_blocks, le32_to_cpu(desc->j_len) * sizeof(struct buffer_head *), p_s_sb) ;
+  return 0 ;
+}
+
+/* This function reads blocks starting from block and to max_block of bufsize
+   size (but no more than BUFNR blocks at a time). This proved to improve
+   mounting speed on self-rebuilding raid5 arrays at least.
+   Right now it is only used from journal code. But later we might use it
+   from other places.
+   Note: Do not use journal_getblk/sb_getblk functions here! */
+static struct buffer_head * reiserfs_breada (struct block_device *dev, int block, int bufsize,
+			    unsigned int max_block)
+{
+	struct buffer_head * bhlist[BUFNR];
+	unsigned int blocks = BUFNR;
+	struct buffer_head * bh;
+	int i, j;
+	
+	bh = __getblk (dev, block, bufsize );
+	if (buffer_uptodate (bh))
+		return (bh);   
+		
+	if (block + BUFNR > max_block) {
+		blocks = max_block - block;
+	}
+	bhlist[0] = bh;
+	j = 1;
+	for (i = 1; i < blocks; i++) {
+		bh = __getblk (dev, block + i, bufsize);
+		if (buffer_uptodate (bh)) {
+			brelse (bh);
+			break;
+		}
+		else bhlist[j++] = bh;
+	}
+	ll_rw_block (READ, j, bhlist);
+	for(i = 1; i < j; i++) 
+		brelse (bhlist[i]);
+	bh = bhlist[0];
+	wait_on_buffer (bh);
+	if (buffer_uptodate (bh))
+		return bh;
+	brelse (bh);
+	return NULL;
+}
+
+/*
+** read and replay the log
+** on a clean unmount, the journal header's next unflushed pointer will be to an invalid
+** transaction.  This tests that before finding all the transactions in the log, which makes normal mount times fast.
+**
+** After a crash, this starts with the next unflushed transaction, and replays until it finds one too old, or invalid.
+**
+** On exit, it sets things up so the first transaction will work correctly.
+*/
+static int journal_read(struct super_block *p_s_sb) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_desc *desc ;
+  unsigned long oldest_trans_id = 0;
+  unsigned long oldest_invalid_trans_id = 0 ;
+  time_t start ;
+  unsigned long oldest_start = 0;
+  unsigned long cur_dblock = 0 ;
+  unsigned long newest_mount_id = 9 ;
+  struct buffer_head *d_bh ;
+  struct reiserfs_journal_header *jh ;
+  int valid_journal_header = 0 ;
+  int replay_count = 0 ;
+  int continue_replay = 1 ;
+  int ret ;
+  char b[BDEVNAME_SIZE];
+
+  cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) ;
+  reiserfs_info (p_s_sb, "checking transaction log (%s)\n",
+	 bdevname(journal->j_dev_bd, b));
+  start = get_seconds();
+
+  /* step 1, read in the journal header block.  Check the transaction it says 
+  ** is the first unflushed, and if that transaction is not valid, 
+  ** replay is done
+  */
+  journal->j_header_bh = journal_bread(p_s_sb,
+					   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
+					   SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+  if (!journal->j_header_bh) {
+    return 1 ;
+  }
+  jh = (struct reiserfs_journal_header *)(journal->j_header_bh->b_data) ;
+  if (le32_to_cpu(jh->j_first_unflushed_offset) >= 0 && 
+      le32_to_cpu(jh->j_first_unflushed_offset) < SB_ONDISK_JOURNAL_SIZE(p_s_sb) && 
+      le32_to_cpu(jh->j_last_flush_trans_id) > 0) {
+    oldest_start = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
+                       le32_to_cpu(jh->j_first_unflushed_offset) ;
+    oldest_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
+    newest_mount_id = le32_to_cpu(jh->j_mount_id);
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1153: found in "
+                   "header: first_unflushed_offset %d, last_flushed_trans_id "
+		   "%lu", le32_to_cpu(jh->j_first_unflushed_offset),
+		   le32_to_cpu(jh->j_last_flush_trans_id)) ;
+    valid_journal_header = 1 ;
+
+    /* now, we try to read the first unflushed offset.  If it is not valid, 
+    ** there is nothing more we can do, and it makes no sense to read 
+    ** through the whole log.
+    */
+    d_bh = journal_bread(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + le32_to_cpu(jh->j_first_unflushed_offset)) ;
+    ret = journal_transaction_is_valid(p_s_sb, d_bh, NULL, NULL) ;
+    if (!ret) {
+      continue_replay = 0 ;
+    }
+    brelse(d_bh) ;
+    goto start_log_replay;
+  }
+
+  if (continue_replay && bdev_read_only(p_s_sb->s_bdev)) {
+    reiserfs_warning (p_s_sb,
+		      "clm-2076: device is readonly, unable to replay log") ;
+    return -1 ;
+  }
+
+  /* ok, there are transactions that need to be replayed.  start with the first log block, find
+  ** all the valid transactions, and pick out the oldest.
+  */
+  while(continue_replay && cur_dblock < (SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb))) {
+    /* Note that it is required for blocksize of primary fs device and journal
+       device to be the same */
+    d_bh = reiserfs_breada(journal->j_dev_bd, cur_dblock, p_s_sb->s_blocksize,
+			   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb)) ;
+    ret = journal_transaction_is_valid(p_s_sb, d_bh, &oldest_invalid_trans_id, &newest_mount_id) ;
+    if (ret == 1) {
+      desc = (struct reiserfs_journal_desc *)d_bh->b_data ;
+      if (oldest_start == 0) { /* init all oldest_ values */
+        oldest_trans_id = get_desc_trans_id(desc) ;
+	oldest_start = d_bh->b_blocknr ;
+	newest_mount_id = get_desc_mount_id(desc) ;
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1179: Setting "
+	               "oldest_start to offset %llu, trans_id %lu",
+		       oldest_start - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+		       oldest_trans_id) ;
+      } else if (oldest_trans_id > get_desc_trans_id(desc)) { 
+        /* one we just read was older */
+        oldest_trans_id = get_desc_trans_id(desc) ;
+	oldest_start = d_bh->b_blocknr ;
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1180: Resetting "
+	               "oldest_start to offset %lu, trans_id %lu",
+			oldest_start - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+			oldest_trans_id) ;
+      }
+      if (newest_mount_id < get_desc_mount_id(desc)) {
+        newest_mount_id = get_desc_mount_id(desc) ;
+	reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
+	              "newest_mount_id to %d", get_desc_mount_id(desc));
+      }
+      cur_dblock += get_desc_trans_len(desc) + 2 ;
+    } else {
+      cur_dblock++ ;
+    }
+    brelse(d_bh) ;
+  }
+
+start_log_replay:
+  cur_dblock = oldest_start ;
+  if (oldest_trans_id)  {
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1206: Starting replay "
+                   "from offset %llu, trans_id %lu",
+		   cur_dblock - SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb), 
+		   oldest_trans_id) ;
+
+  }
+  replay_count = 0 ;
+  while(continue_replay && oldest_trans_id > 0) {
+    ret = journal_read_transaction(p_s_sb, cur_dblock, oldest_start, oldest_trans_id, newest_mount_id) ;
+    if (ret < 0) {
+      return ret ;
+    } else if (ret != 0) {
+      break ;
+    }
+    cur_dblock = SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start ;
+    replay_count++ ;
+   if (cur_dblock == oldest_start)
+        break;
+  }
+
+  if (oldest_trans_id == 0) {
+    reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1225: No valid "
+                   "transactions found") ;
+  }
+  /* j_start does not get set correctly if we don't replay any transactions.
+  ** if we had a valid journal_header, set j_start to the first unflushed transaction value,
+  ** copy the trans_id from the header
+  */
+  if (valid_journal_header && replay_count == 0) { 
+    journal->j_start = le32_to_cpu(jh->j_first_unflushed_offset) ;
+    journal->j_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) + 1;
+    journal->j_last_flush_trans_id = le32_to_cpu(jh->j_last_flush_trans_id) ;
+    journal->j_mount_id = le32_to_cpu(jh->j_mount_id) + 1;
+  } else {
+    journal->j_mount_id = newest_mount_id + 1 ;
+  }
+  reiserfs_debug(p_s_sb, REISERFS_DEBUG_CODE, "journal-1299: Setting "
+                 "newest_mount_id to %lu", journal->j_mount_id) ;
+  journal->j_first_unflushed_offset = journal->j_start ;
+  if (replay_count > 0) {
+    reiserfs_info (p_s_sb, "replayed %d transactions in %lu seconds\n",
+		   replay_count, get_seconds() - start) ;
+  }
+  if (!bdev_read_only(p_s_sb->s_bdev) && 
+       _update_journal_header_block(p_s_sb, journal->j_start,
+                                   journal->j_last_flush_trans_id))
+  {
+      /* replay failed, caller must call free_journal_ram and abort
+      ** the mount
+      */
+      return -1 ;
+  }
+  return 0 ;
+}
+
+static struct reiserfs_journal_list *alloc_journal_list(struct super_block *s)
+{
+    struct reiserfs_journal_list *jl;
+retry:
+    jl = reiserfs_kmalloc(sizeof(struct reiserfs_journal_list), GFP_NOFS, s);
+    if (!jl) {
+	yield();
+	goto retry;
+    }
+    memset(jl, 0, sizeof(*jl));
+    INIT_LIST_HEAD(&jl->j_list);
+    INIT_LIST_HEAD(&jl->j_working_list);
+    INIT_LIST_HEAD(&jl->j_tail_bh_list);
+    INIT_LIST_HEAD(&jl->j_bh_list);
+    sema_init(&jl->j_commit_lock, 1);
+    SB_JOURNAL(s)->j_num_lists++;
+    get_journal_list(jl);
+    return jl;
+}
+
+static void journal_list_init(struct super_block *p_s_sb) {
+    SB_JOURNAL(p_s_sb)->j_current_jl = alloc_journal_list(p_s_sb);
+}
+
+static int release_journal_dev( struct super_block *super,
+				struct reiserfs_journal *journal )
+{
+    int result;
+    
+    result = 0;
+
+    if( journal -> j_dev_file != NULL ) {
+	result = filp_close( journal -> j_dev_file, NULL );
+	journal -> j_dev_file = NULL;
+	journal -> j_dev_bd = NULL;
+    } else if( journal -> j_dev_bd != NULL ) {
+	result = blkdev_put( journal -> j_dev_bd );
+	journal -> j_dev_bd = NULL;
+    }
+
+    if( result != 0 ) {
+	reiserfs_warning(super, "sh-457: release_journal_dev: Cannot release journal device: %i", result );
+    }
+    return result;
+}
+
+static int journal_init_dev( struct super_block *super, 
+			     struct reiserfs_journal *journal, 
+			     const char *jdev_name )
+{
+	int result;
+	dev_t jdev;
+	int blkdev_mode = FMODE_READ | FMODE_WRITE;
+	char b[BDEVNAME_SIZE];
+
+	result = 0;
+
+	journal -> j_dev_bd = NULL;
+	journal -> j_dev_file = NULL;
+	jdev = SB_ONDISK_JOURNAL_DEVICE( super ) ?
+		new_decode_dev(SB_ONDISK_JOURNAL_DEVICE(super)) : super->s_dev;	
+
+	if (bdev_read_only(super->s_bdev))
+	    blkdev_mode = FMODE_READ;
+
+	/* there is no "jdev" option and journal is on separate device */
+	if( ( !jdev_name || !jdev_name[ 0 ] ) ) {
+		journal->j_dev_bd = open_by_devnum(jdev, blkdev_mode);
+		if (IS_ERR(journal->j_dev_bd)) {
+			result = PTR_ERR(journal->j_dev_bd);
+			journal->j_dev_bd = NULL;
+			reiserfs_warning (super, "sh-458: journal_init_dev: "
+					  "cannot init journal device '%s': %i",
+					  __bdevname(jdev, b), result );
+			return result;
+		} else if (jdev != super->s_dev)
+			set_blocksize(journal->j_dev_bd, super->s_blocksize);
+		return 0;
+	}
+
+	journal -> j_dev_file = filp_open( jdev_name, 0, 0 );
+	if( !IS_ERR( journal -> j_dev_file ) ) {
+		struct inode *jdev_inode = journal->j_dev_file->f_mapping->host;
+		if( !S_ISBLK( jdev_inode -> i_mode ) ) {
+			reiserfs_warning  (super, "journal_init_dev: '%s' is "
+					   "not a block device", jdev_name );
+			result = -ENOTBLK;
+		} else  {
+			/* ok */
+			journal->j_dev_bd = I_BDEV(jdev_inode);
+			set_blocksize(journal->j_dev_bd, super->s_blocksize);
+		}
+	} else {
+		result = PTR_ERR( journal -> j_dev_file );
+		journal -> j_dev_file = NULL;
+		reiserfs_warning (super,
+				  "journal_init_dev: Cannot open '%s': %i",
+				  jdev_name, result );
+	}
+	if( result != 0 ) {
+		release_journal_dev( super, journal );
+	}
+	reiserfs_info(super, "journal_init_dev: journal device: %s\n",
+		bdevname(journal->j_dev_bd, b));
+	return result;
+}
+
+/*
+** must be called once on fs mount.  calls journal_read for you
+*/
+int journal_init(struct super_block *p_s_sb, const char * j_dev_name, int old_format, unsigned int commit_max_age) {
+    int num_cnodes = SB_ONDISK_JOURNAL_SIZE(p_s_sb) * 2 ;
+    struct buffer_head *bhjh;
+    struct reiserfs_super_block * rs;
+    struct reiserfs_journal_header *jh;
+    struct reiserfs_journal *journal;
+    struct reiserfs_journal_list *jl;
+    char b[BDEVNAME_SIZE];
+
+    journal = SB_JOURNAL(p_s_sb) = vmalloc(sizeof (struct reiserfs_journal)) ;
+    if (!journal) {
+	reiserfs_warning (p_s_sb, "journal-1256: unable to get memory for journal structure") ;
+	return 1 ;
+    }
+    memset(journal, 0, sizeof(struct reiserfs_journal)) ;
+    INIT_LIST_HEAD(&journal->j_bitmap_nodes) ;
+    INIT_LIST_HEAD (&journal->j_prealloc_list);
+    INIT_LIST_HEAD(&journal->j_working_list);
+    INIT_LIST_HEAD(&journal->j_journal_list);
+    journal->j_persistent_trans = 0;
+    if (reiserfs_allocate_list_bitmaps(p_s_sb,
+				       journal->j_list_bitmap,
+ 				       SB_BMAP_NR(p_s_sb)))
+	goto free_and_return ;
+    allocate_bitmap_nodes(p_s_sb) ;
+
+    /* reserved for journal area support */
+    SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) = (old_format ?
+					     REISERFS_OLD_DISK_OFFSET_IN_BYTES / p_s_sb->s_blocksize +
+					     SB_BMAP_NR(p_s_sb) + 1 :
+					     REISERFS_DISK_OFFSET_IN_BYTES / p_s_sb->s_blocksize + 2); 
+    
+    /* Sanity check to see is the standard journal fitting withing first bitmap
+       (actual for small blocksizes) */
+    if ( !SB_ONDISK_JOURNAL_DEVICE( p_s_sb ) &&
+         (SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb) > p_s_sb->s_blocksize * 8) ) {
+	reiserfs_warning (p_s_sb, "journal-1393: journal does not fit for area "
+			  "addressed by first of bitmap blocks. It starts at "
+			  "%u and its size is %u. Block size %ld",
+			  SB_JOURNAL_1st_RESERVED_BLOCK(p_s_sb),
+			  SB_ONDISK_JOURNAL_SIZE(p_s_sb), p_s_sb->s_blocksize);
+	goto free_and_return;
+    }
+
+    if( journal_init_dev( p_s_sb, journal, j_dev_name ) != 0 ) {
+      reiserfs_warning (p_s_sb, "sh-462: unable to initialize jornal device");
+      goto free_and_return;
+    }
+
+     rs = SB_DISK_SUPER_BLOCK(p_s_sb);
+     
+     /* read journal header */
+     bhjh = journal_bread(p_s_sb,
+		   SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + SB_ONDISK_JOURNAL_SIZE(p_s_sb));
+     if (!bhjh) {
+	 reiserfs_warning (p_s_sb, "sh-459: unable to read journal header");
+	 goto free_and_return;
+     }
+     jh = (struct reiserfs_journal_header *)(bhjh->b_data);
+     
+     /* make sure that journal matches to the super block */
+     if (is_reiserfs_jr(rs) && (jh->jh_journal.jp_journal_magic != sb_jp_journal_magic(rs))) {
+	 reiserfs_warning (p_s_sb, "sh-460: journal header magic %x "
+			   "(device %s) does not match to magic found in super "
+			   "block %x",
+			   jh->jh_journal.jp_journal_magic,
+			   bdevname( journal->j_dev_bd, b),
+			   sb_jp_journal_magic(rs));
+	 brelse (bhjh);
+	 goto free_and_return;
+  }
+     
+  journal->j_trans_max      = le32_to_cpu (jh->jh_journal.jp_journal_trans_max);
+  journal->j_max_batch      = le32_to_cpu (jh->jh_journal.jp_journal_max_batch);
+  journal->j_max_commit_age = le32_to_cpu (jh->jh_journal.jp_journal_max_commit_age);
+  journal->j_max_trans_age = JOURNAL_MAX_TRANS_AGE;
+
+  if (journal->j_trans_max) {
+    /* make sure these parameters are available, assign it if they are not */
+    __u32 initial = journal->j_trans_max;
+    __u32 ratio = 1;
+    
+    if (p_s_sb->s_blocksize < 4096)
+      ratio = 4096 / p_s_sb->s_blocksize;
+    
+    if (SB_ONDISK_JOURNAL_SIZE(p_s_sb)/journal->j_trans_max < JOURNAL_MIN_RATIO)
+      journal->j_trans_max = SB_ONDISK_JOURNAL_SIZE(p_s_sb) / JOURNAL_MIN_RATIO;
+    if (journal->j_trans_max > JOURNAL_TRANS_MAX_DEFAULT / ratio)
+      journal->j_trans_max = JOURNAL_TRANS_MAX_DEFAULT / ratio;
+    if (journal->j_trans_max < JOURNAL_TRANS_MIN_DEFAULT / ratio)
+      journal->j_trans_max = JOURNAL_TRANS_MIN_DEFAULT / ratio;
+    
+    if (journal->j_trans_max != initial)
+      reiserfs_warning (p_s_sb, "sh-461: journal_init: wrong transaction max size (%u). Changed to %u",
+	      initial, journal->j_trans_max);
+
+    journal->j_max_batch = journal->j_trans_max*
+      JOURNAL_MAX_BATCH_DEFAULT/JOURNAL_TRANS_MAX_DEFAULT;
+  }  
+  
+  if (!journal->j_trans_max) {
+    /*we have the file system was created by old version of mkreiserfs 
+      so this field contains zero value */
+    journal->j_trans_max      = JOURNAL_TRANS_MAX_DEFAULT ;
+    journal->j_max_batch      = JOURNAL_MAX_BATCH_DEFAULT ;
+    journal->j_max_commit_age = JOURNAL_MAX_COMMIT_AGE ;
+    
+    /* for blocksize >= 4096 - max transaction size is 1024. For block size < 4096
+       trans max size is decreased proportionally */
+    if (p_s_sb->s_blocksize < 4096) {
+      journal->j_trans_max /= (4096 / p_s_sb->s_blocksize) ;
+      journal->j_max_batch = (journal->j_trans_max) * 9 / 10 ;
+    }
+  }
+
+  journal->j_default_max_commit_age = journal->j_max_commit_age;
+
+  if (commit_max_age != 0) {
+      journal->j_max_commit_age = commit_max_age;
+      journal->j_max_trans_age = commit_max_age;
+  }
+
+  reiserfs_info (p_s_sb, "journal params: device %s, size %u, "
+		 "journal first block %u, max trans len %u, max batch %u, "
+		 "max commit age %u, max trans age %u\n",
+		 bdevname( journal->j_dev_bd, b),
+		 SB_ONDISK_JOURNAL_SIZE(p_s_sb),
+		 SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb),
+		 journal->j_trans_max,
+		 journal->j_max_batch,
+		 journal->j_max_commit_age,
+		 journal->j_max_trans_age);
+
+  brelse (bhjh);
+     
+  journal->j_list_bitmap_index = 0 ;
+  journal_list_init(p_s_sb) ;
+
+  memset(journal->j_list_hash_table, 0, JOURNAL_HASH_SIZE * sizeof(struct reiserfs_journal_cnode *)) ;
+
+  INIT_LIST_HEAD(&journal->j_dirty_buffers) ;
+  spin_lock_init(&journal->j_dirty_buffers_lock) ;
+
+  journal->j_start = 0 ;
+  journal->j_len = 0 ;
+  journal->j_len_alloc = 0 ;
+  atomic_set(&(journal->j_wcount), 0) ;
+  atomic_set(&(journal->j_async_throttle), 0) ;
+  journal->j_bcount = 0 ;
+  journal->j_trans_start_time = 0 ;
+  journal->j_last = NULL ;
+  journal->j_first = NULL ;
+  init_waitqueue_head(&(journal->j_join_wait)) ;
+  sema_init(&journal->j_lock, 1);
+  sema_init(&journal->j_flush_sem, 1);
+
+  journal->j_trans_id = 10 ;
+  journal->j_mount_id = 10 ;
+  journal->j_state = 0 ;
+  atomic_set(&(journal->j_jlock), 0) ;
+  journal->j_cnode_free_list = allocate_cnodes(num_cnodes) ;
+  journal->j_cnode_free_orig = journal->j_cnode_free_list ;
+  journal->j_cnode_free = journal->j_cnode_free_list ? num_cnodes : 0 ;
+  journal->j_cnode_used = 0 ;
+  journal->j_must_wait = 0 ;
+
+  init_journal_hash(p_s_sb) ;
+  jl = journal->j_current_jl;
+  jl->j_list_bitmap = get_list_bitmap(p_s_sb, jl);
+  if (!jl->j_list_bitmap) {
+    reiserfs_warning(p_s_sb, "journal-2005, get_list_bitmap failed for journal list 0") ;
+    goto free_and_return;
+  }
+  if (journal_read(p_s_sb) < 0) {
+    reiserfs_warning(p_s_sb, "Replay Failure, unable to mount") ;
+    goto free_and_return;
+  }
+
+  reiserfs_mounted_fs_count++ ;
+  if (reiserfs_mounted_fs_count <= 1)
+    commit_wq = create_workqueue("reiserfs");
+
+  INIT_WORK(&journal->j_work, flush_async_commits, p_s_sb);
+  return 0 ;
+free_and_return:
+  free_journal_ram(p_s_sb);
+  return 1;
+}
+
+/*
+** test for a polite end of the current transaction.  Used by file_write, and should
+** be used by delete to make sure they don't write more than can fit inside a single
+** transaction
+*/
+int journal_transaction_should_end(struct reiserfs_transaction_handle *th, int new_alloc) {
+  struct reiserfs_journal *journal = SB_JOURNAL (th->t_super);
+  time_t now = get_seconds() ;
+  /* cannot restart while nested */
+  BUG_ON (!th->t_trans_id);
+  if (th->t_refcount > 1)
+    return 0 ;
+  if ( journal->j_must_wait > 0 ||
+       (journal->j_len_alloc + new_alloc) >= journal->j_max_batch ||
+       atomic_read(&(journal->j_jlock)) ||
+      (now - journal->j_trans_start_time) > journal->j_max_trans_age ||
+       journal->j_cnode_free < (journal->j_trans_max * 3)) {
+    return 1 ;
+  }
+  return 0 ;
+}
+
+/* this must be called inside a transaction, and requires the 
+** kernel_lock to be held
+*/
+void reiserfs_block_writes(struct reiserfs_transaction_handle *th) {
+    struct reiserfs_journal *journal = SB_JOURNAL (th->t_super);
+    BUG_ON (!th->t_trans_id);
+    journal->j_must_wait = 1 ;
+    set_bit(J_WRITERS_BLOCKED, &journal->j_state) ;
+    return ;
+}
+
+/* this must be called without a transaction started, and does not
+** require BKL
+*/
+void reiserfs_allow_writes(struct super_block *s) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    clear_bit(J_WRITERS_BLOCKED, &journal->j_state) ;
+    wake_up(&journal->j_join_wait) ;
+}
+
+/* this must be called without a transaction started, and does not
+** require BKL
+*/
+void reiserfs_wait_on_write_block(struct super_block *s) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    wait_event(journal->j_join_wait,
+               !test_bit(J_WRITERS_BLOCKED, &journal->j_state)) ;
+}
+
+static void queue_log_writer(struct super_block *s) {
+    wait_queue_t wait;
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    set_bit(J_WRITERS_QUEUED, &journal->j_state);
+
+    /*
+     * we don't want to use wait_event here because
+     * we only want to wait once.
+     */
+    init_waitqueue_entry(&wait, current);
+    add_wait_queue(&journal->j_join_wait, &wait);
+    set_current_state(TASK_UNINTERRUPTIBLE);
+    if (test_bit(J_WRITERS_QUEUED, &journal->j_state))
+        schedule();
+    current->state = TASK_RUNNING;
+    remove_wait_queue(&journal->j_join_wait, &wait);
+}
+
+static void wake_queued_writers(struct super_block *s) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    if (test_and_clear_bit(J_WRITERS_QUEUED, &journal->j_state))
+        wake_up(&journal->j_join_wait);
+}
+
+static void let_transaction_grow(struct super_block *sb,
+                                 unsigned long trans_id)
+{
+    struct reiserfs_journal *journal = SB_JOURNAL (sb);
+    unsigned long bcount = journal->j_bcount;
+    while(1) {
+	set_current_state(TASK_UNINTERRUPTIBLE);
+	schedule_timeout(1);
+	journal->j_current_jl->j_state |= LIST_COMMIT_PENDING;
+        while ((atomic_read(&journal->j_wcount) > 0 ||
+	        atomic_read(&journal->j_jlock)) &&
+	       journal->j_trans_id == trans_id) {
+	    queue_log_writer(sb);
+	}
+	if (journal->j_trans_id != trans_id)
+	    break;
+	if (bcount == journal->j_bcount)
+	    break;
+	bcount = journal->j_bcount;
+    }
+}
+
+/* join == true if you must join an existing transaction.
+** join == false if you can deal with waiting for others to finish
+**
+** this will block until the transaction is joinable.  send the number of blocks you
+** expect to use in nblocks.
+*/
+static int do_journal_begin_r(struct reiserfs_transaction_handle *th, struct super_block * p_s_sb,unsigned long nblocks,int join) {
+  time_t now = get_seconds() ;
+  int old_trans_id  ;
+  struct reiserfs_journal *journal = SB_JOURNAL(p_s_sb);
+  struct reiserfs_transaction_handle myth;
+  int sched_count = 0;
+  int retval;
+
+  reiserfs_check_lock_depth(p_s_sb, "journal_begin") ;
+
+  PROC_INFO_INC( p_s_sb, journal.journal_being );
+  /* set here for journal_join */
+  th->t_refcount = 1;
+  th->t_super = p_s_sb ;
+
+relock:
+  lock_journal(p_s_sb) ;
+  if (join != JBEGIN_ABORT && reiserfs_is_journal_aborted (journal)) {
+    unlock_journal (p_s_sb);
+    retval = journal->j_errno;
+    goto out_fail;
+  }
+  journal->j_bcount++;
+
+  if (test_bit(J_WRITERS_BLOCKED, &journal->j_state)) {
+    unlock_journal(p_s_sb) ;
+    reiserfs_wait_on_write_block(p_s_sb) ;
+    PROC_INFO_INC( p_s_sb, journal.journal_relock_writers );
+    goto relock ;
+  }
+  now = get_seconds();
+
+  /* if there is no room in the journal OR
+  ** if this transaction is too old, and we weren't called joinable, wait for it to finish before beginning 
+  ** we don't sleep if there aren't other writers
+  */
+
+  if ( (!join && journal->j_must_wait > 0) ||
+     ( !join && (journal->j_len_alloc + nblocks + 2) >= journal->j_max_batch) ||
+     (!join && atomic_read(&journal->j_wcount) > 0 && journal->j_trans_start_time > 0 &&
+      (now - journal->j_trans_start_time) > journal->j_max_trans_age) ||
+     (!join && atomic_read(&journal->j_jlock)) ||
+     (!join && journal->j_cnode_free < (journal->j_trans_max * 3))) {
+
+    old_trans_id = journal->j_trans_id;
+    unlock_journal(p_s_sb) ; /* allow others to finish this transaction */
+
+    if (!join && (journal->j_len_alloc + nblocks + 2) >=
+        journal->j_max_batch &&
+	((journal->j_len + nblocks + 2) * 100) < (journal->j_len_alloc * 75))
+    {
+	if (atomic_read(&journal->j_wcount) > 10) {
+	    sched_count++;
+	    queue_log_writer(p_s_sb);
+	    goto relock;
+	}
+    }
+    /* don't mess with joining the transaction if all we have to do is
+     * wait for someone else to do a commit
+     */
+    if (atomic_read(&journal->j_jlock)) {
+	while (journal->j_trans_id == old_trans_id &&
+	       atomic_read(&journal->j_jlock)) {
+	    queue_log_writer(p_s_sb);
+        }
+	goto relock;
+    }
+    retval = journal_join(&myth, p_s_sb, 1) ;
+    if (retval)
+        goto out_fail;
+
+    /* someone might have ended the transaction while we joined */
+    if (old_trans_id != journal->j_trans_id) {
+        retval = do_journal_end(&myth, p_s_sb, 1, 0) ;
+    } else {
+        retval = do_journal_end(&myth, p_s_sb, 1, COMMIT_NOW) ;
+    }
+
+    if (retval)
+        goto out_fail;
+
+    PROC_INFO_INC( p_s_sb, journal.journal_relock_wcount );
+    goto relock ;
+  }
+  /* we are the first writer, set trans_id */
+  if (journal->j_trans_start_time == 0) {
+    journal->j_trans_start_time = get_seconds();
+  }
+  atomic_inc(&(journal->j_wcount)) ;
+  journal->j_len_alloc += nblocks ;
+  th->t_blocks_logged = 0 ;
+  th->t_blocks_allocated = nblocks ;
+  th->t_trans_id = journal->j_trans_id ;
+  unlock_journal(p_s_sb) ;
+  INIT_LIST_HEAD (&th->t_list);
+  return 0 ;
+
+out_fail:
+  memset (th, 0, sizeof (*th));
+  /* Re-set th->t_super, so we can properly keep track of how many
+   * persistent transactions there are. We need to do this so if this
+   * call is part of a failed restart_transaction, we can free it later */
+  th->t_super = p_s_sb;
+  return retval;
+}
+
+struct reiserfs_transaction_handle *
+reiserfs_persistent_transaction(struct super_block *s, int nblocks) {
+    int ret ;
+    struct reiserfs_transaction_handle *th ;
+
+    /* if we're nesting into an existing transaction.  It will be
+    ** persistent on its own
+    */
+    if (reiserfs_transaction_running(s)) {
+        th = current->journal_info ;
+	th->t_refcount++ ;
+	if (th->t_refcount < 2) {
+	    BUG() ;
+	}
+	return th ;
+    }
+    th = reiserfs_kmalloc(sizeof(struct reiserfs_transaction_handle), GFP_NOFS, s) ;
+    if (!th)
+       return NULL;
+    ret = journal_begin(th, s, nblocks) ;
+    if (ret) {
+	reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle), s) ;
+        return NULL;
+    }
+
+    SB_JOURNAL(s)->j_persistent_trans++;
+    return th ;
+}
+
+int
+reiserfs_end_persistent_transaction(struct reiserfs_transaction_handle *th) {
+    struct super_block *s = th->t_super;
+    int ret = 0;
+    if (th->t_trans_id)
+        ret = journal_end(th, th->t_super, th->t_blocks_allocated);
+    else
+        ret = -EIO;
+    if (th->t_refcount == 0) {
+        SB_JOURNAL(s)->j_persistent_trans--;
+	reiserfs_kfree(th, sizeof(struct reiserfs_transaction_handle), s) ;
+    }
+    return ret;
+}
+
+static int journal_join(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
+  struct reiserfs_transaction_handle *cur_th = current->journal_info;
+
+  /* this keeps do_journal_end from NULLing out the current->journal_info
+  ** pointer
+  */
+  th->t_handle_save = cur_th ;
+  if (cur_th && cur_th->t_refcount > 1) {
+      BUG() ;
+  }
+  return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_JOIN) ;
+}
+
+int journal_join_abort(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
+  struct reiserfs_transaction_handle *cur_th = current->journal_info;
+
+  /* this keeps do_journal_end from NULLing out the current->journal_info
+  ** pointer
+  */
+  th->t_handle_save = cur_th ;
+  if (cur_th && cur_th->t_refcount > 1) {
+      BUG() ;
+  }
+  return do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_ABORT) ;
+}
+
+int journal_begin(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, unsigned long nblocks) {
+    struct reiserfs_transaction_handle *cur_th = current->journal_info ;
+    int ret ;
+
+    th->t_handle_save = NULL ;
+    if (cur_th) {
+	/* we are nesting into the current transaction */
+	if (cur_th->t_super == p_s_sb) {
+              BUG_ON (!cur_th->t_refcount);
+	      cur_th->t_refcount++ ;
+	      memcpy(th, cur_th, sizeof(*th));
+	      if (th->t_refcount <= 1)
+		      reiserfs_warning (p_s_sb, "BAD: refcount <= 1, but journal_info != 0");
+	      return 0;
+	} else {
+	    /* we've ended up with a handle from a different filesystem.
+	    ** save it and restore on journal_end.  This should never
+	    ** really happen...
+	    */
+	    reiserfs_warning(p_s_sb, "clm-2100: nesting info a different FS") ;
+	    th->t_handle_save = current->journal_info ;
+	    current->journal_info = th;
+	}
+    } else {
+	current->journal_info = th;
+    }
+    ret = do_journal_begin_r(th, p_s_sb, nblocks, JBEGIN_REG) ;
+    if (current->journal_info != th)
+        BUG() ;
+
+    /* I guess this boils down to being the reciprocal of clm-2100 above.
+     * If do_journal_begin_r fails, we need to put it back, since journal_end
+     * won't be called to do it. */
+    if (ret)
+        current->journal_info = th->t_handle_save;
+    else
+        BUG_ON (!th->t_refcount);
+
+    return ret ;
+}
+
+/*
+** puts bh into the current transaction.  If it was already there, reorders removes the
+** old pointers from the hash, and puts new ones in (to make sure replay happen in the right order).
+**
+** if it was dirty, cleans and files onto the clean list.  I can't let it be dirty again until the
+** transaction is committed.
+** 
+** if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
+*/
+int journal_mark_dirty(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, struct buffer_head *bh) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_cnode *cn = NULL;
+  int count_already_incd = 0 ;
+  int prepared = 0 ;
+  BUG_ON (!th->t_trans_id);
+
+  PROC_INFO_INC( p_s_sb, journal.mark_dirty );
+  if (th->t_trans_id != journal->j_trans_id) {
+    reiserfs_panic(th->t_super, "journal-1577: handle trans id %ld != current trans id %ld\n", 
+                   th->t_trans_id, journal->j_trans_id);
+  }
+
+  p_s_sb->s_dirt = 1;
+
+  prepared = test_clear_buffer_journal_prepared (bh);
+  clear_buffer_journal_restore_dirty (bh);
+  /* already in this transaction, we are done */
+  if (buffer_journaled(bh)) {
+    PROC_INFO_INC( p_s_sb, journal.mark_dirty_already );
+    return 0 ;
+  }
+
+  /* this must be turned into a panic instead of a warning.  We can't allow
+  ** a dirty or journal_dirty or locked buffer to be logged, as some changes
+  ** could get to disk too early.  NOT GOOD.
+  */
+  if (!prepared || buffer_dirty(bh)) {
+    reiserfs_warning (p_s_sb, "journal-1777: buffer %llu bad state "
+		      "%cPREPARED %cLOCKED %cDIRTY %cJDIRTY_WAIT",
+		      (unsigned long long)bh->b_blocknr, prepared ? ' ' : '!',
+			    buffer_locked(bh) ? ' ' : '!',
+			    buffer_dirty(bh) ? ' ' : '!',
+			    buffer_journal_dirty(bh) ? ' ' : '!') ;
+  }
+
+  if (atomic_read(&(journal->j_wcount)) <= 0) {
+    reiserfs_warning (p_s_sb, "journal-1409: journal_mark_dirty returning because j_wcount was %d", atomic_read(&(journal->j_wcount))) ;
+    return 1 ;
+  }
+  /* this error means I've screwed up, and we've overflowed the transaction.  
+  ** Nothing can be done here, except make the FS readonly or panic.
+  */ 
+  if (journal->j_len >= journal->j_trans_max) {
+    reiserfs_panic(th->t_super, "journal-1413: journal_mark_dirty: j_len (%lu) is too big\n", journal->j_len) ;
+  }
+
+  if (buffer_journal_dirty(bh)) {
+    count_already_incd = 1 ;
+    PROC_INFO_INC( p_s_sb, journal.mark_dirty_notjournal );
+    clear_buffer_journal_dirty (bh);
+  }
+
+  if (journal->j_len > journal->j_len_alloc) {
+    journal->j_len_alloc = journal->j_len + JOURNAL_PER_BALANCE_CNT ;
+  }
+
+  set_buffer_journaled (bh);
+
+  /* now put this guy on the end */
+  if (!cn) {
+    cn = get_cnode(p_s_sb) ;
+    if (!cn) {
+      reiserfs_panic(p_s_sb, "get_cnode failed!\n"); 
+    }
+
+    if (th->t_blocks_logged == th->t_blocks_allocated) {
+      th->t_blocks_allocated += JOURNAL_PER_BALANCE_CNT ;
+      journal->j_len_alloc += JOURNAL_PER_BALANCE_CNT ;
+    }
+    th->t_blocks_logged++ ;
+    journal->j_len++ ;
+
+    cn->bh = bh ;
+    cn->blocknr = bh->b_blocknr ;
+    cn->sb = p_s_sb;
+    cn->jlist = NULL ;
+    insert_journal_hash(journal->j_hash_table, cn) ;
+    if (!count_already_incd) {
+      get_bh(bh) ;
+    }
+  }
+  cn->next = NULL ;
+  cn->prev = journal->j_last ;
+  cn->bh = bh ;
+  if (journal->j_last) {
+    journal->j_last->next = cn ;
+    journal->j_last = cn ;
+  } else {
+    journal->j_first = cn ;
+    journal->j_last = cn ;
+  }
+  return 0 ;
+}
+
+int journal_end(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
+  if (!current->journal_info && th->t_refcount > 1)
+    reiserfs_warning (p_s_sb, "REISER-NESTING: th NULL, refcount %d",
+                      th->t_refcount);
+
+  if (!th->t_trans_id) {
+    WARN_ON (1);
+    return -EIO;
+  }
+
+  th->t_refcount--;
+  if (th->t_refcount > 0) {
+    struct reiserfs_transaction_handle *cur_th = current->journal_info ;
+
+    /* we aren't allowed to close a nested transaction on a different
+    ** filesystem from the one in the task struct
+    */
+    if (cur_th->t_super != th->t_super)
+      BUG() ;
+
+    if (th != cur_th) {
+      memcpy(current->journal_info, th, sizeof(*th));
+      th->t_trans_id = 0;
+    }
+    return 0;
+  } else {
+    return do_journal_end(th, p_s_sb, nblocks, 0) ;
+  }
+}
+
+/* removes from the current transaction, relsing and descrementing any counters.  
+** also files the removed buffer directly onto the clean list
+**
+** called by journal_mark_freed when a block has been deleted
+**
+** returns 1 if it cleaned and relsed the buffer. 0 otherwise
+*/
+static int remove_from_transaction(struct super_block *p_s_sb, b_blocknr_t blocknr, int already_cleaned) {
+  struct buffer_head *bh ;
+  struct reiserfs_journal_cnode *cn ;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  int ret = 0;
+
+  cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr) ;
+  if (!cn || !cn->bh) {
+    return ret ;
+  }
+  bh = cn->bh ;
+  if (cn->prev) {
+    cn->prev->next = cn->next ;
+  }
+  if (cn->next) {
+    cn->next->prev = cn->prev ;
+  }
+  if (cn == journal->j_first) {
+    journal->j_first = cn->next ;
+  }
+  if (cn == journal->j_last) {
+    journal->j_last = cn->prev ;
+  }
+  if (bh)
+	remove_journal_hash(p_s_sb, journal->j_hash_table, NULL, bh->b_blocknr, 0) ;
+  clear_buffer_journaled  (bh); /* don't log this one */
+
+  if (!already_cleaned) {
+    clear_buffer_journal_dirty (bh);
+    clear_buffer_dirty(bh);
+    clear_buffer_journal_test (bh);
+    put_bh(bh) ;
+    if (atomic_read(&(bh->b_count)) < 0) {
+      reiserfs_warning (p_s_sb, "journal-1752: remove from trans, b_count < 0");
+    }
+    ret = 1 ;
+  }
+  journal->j_len-- ;
+  journal->j_len_alloc-- ;
+  free_cnode(p_s_sb, cn) ;
+  return ret ;
+}
+
+/*
+** for any cnode in a journal list, it can only be dirtied of all the
+** transactions that include it are commited to disk.
+** this checks through each transaction, and returns 1 if you are allowed to dirty,
+** and 0 if you aren't
+**
+** it is called by dirty_journal_list, which is called after flush_commit_list has gotten all the log
+** blocks for a given transaction on disk
+**
+*/
+static int can_dirty(struct reiserfs_journal_cnode *cn) {
+  struct super_block *sb = cn->sb;
+  b_blocknr_t blocknr = cn->blocknr  ;
+  struct reiserfs_journal_cnode *cur = cn->hprev ;
+  int can_dirty = 1 ;
+  
+  /* first test hprev.  These are all newer than cn, so any node here
+  ** with the same block number and dev means this node can't be sent
+  ** to disk right now.
+  */
+  while(cur && can_dirty) {
+    if (cur->jlist && cur->bh && cur->blocknr && cur->sb == sb && 
+        cur->blocknr == blocknr) {
+      can_dirty = 0 ;
+    }
+    cur = cur->hprev ;
+  }
+  /* then test hnext.  These are all older than cn.  As long as they
+  ** are committed to the log, it is safe to write cn to disk
+  */
+  cur = cn->hnext ;
+  while(cur && can_dirty) {
+    if (cur->jlist && cur->jlist->j_len > 0 && 
+        atomic_read(&(cur->jlist->j_commit_left)) > 0 && cur->bh && 
+        cur->blocknr && cur->sb == sb && cur->blocknr == blocknr) {
+      can_dirty = 0 ;
+    }
+    cur = cur->hnext ;
+  }
+  return can_dirty ;
+}
+
+/* syncs the commit blocks, but does not force the real buffers to disk
+** will wait until the current transaction is done/commited before returning 
+*/
+int journal_end_sync(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, unsigned long nblocks) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+  BUG_ON (!th->t_trans_id);
+  /* you can sync while nested, very, very bad */
+  if (th->t_refcount > 1) {
+    BUG() ;
+  }
+  if (journal->j_len == 0) {
+    reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
+    journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
+  }
+  return do_journal_end(th, p_s_sb, nblocks, COMMIT_NOW | WAIT) ;
+}
+
+/*
+** writeback the pending async commits to disk
+*/
+static void flush_async_commits(void *p) {
+  struct super_block *p_s_sb = p;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_list *jl;
+  struct list_head *entry;
+
+  lock_kernel();
+  if (!list_empty(&journal->j_journal_list)) {
+      /* last entry is the youngest, commit it and you get everything */
+      entry = journal->j_journal_list.prev;
+      jl = JOURNAL_LIST_ENTRY(entry);
+      flush_commit_list(p_s_sb, jl, 1);
+  }
+  unlock_kernel();
+  /*
+   * this is a little racey, but there's no harm in missing
+   * the filemap_fdata_write
+   */
+  if (!atomic_read(&journal->j_async_throttle) && !reiserfs_is_journal_aborted (journal)) {
+      atomic_inc(&journal->j_async_throttle);
+      filemap_fdatawrite(p_s_sb->s_bdev->bd_inode->i_mapping);
+      atomic_dec(&journal->j_async_throttle);
+  }
+}
+
+/*
+** flushes any old transactions to disk
+** ends the current transaction if it is too old
+*/
+int reiserfs_flush_old_commits(struct super_block *p_s_sb) {
+    time_t now ;
+    struct reiserfs_transaction_handle th ;
+    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+    now = get_seconds();
+    /* safety check so we don't flush while we are replaying the log during
+     * mount
+     */
+    if (list_empty(&journal->j_journal_list)) {
+	return 0  ;
+    }
+
+    /* check the current transaction.  If there are no writers, and it is
+     * too old, finish it, and force the commit blocks to disk
+     */
+    if (atomic_read(&journal->j_wcount) <= 0 &&
+        journal->j_trans_start_time > 0 &&
+        journal->j_len > 0 &&
+        (now - journal->j_trans_start_time) > journal->j_max_trans_age)
+    {
+	if (!journal_join(&th, p_s_sb, 1)) {
+            reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
+            journal_mark_dirty(&th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
+
+            /* we're only being called from kreiserfsd, it makes no sense to do
+            ** an async commit so that kreiserfsd can do it later
+            */
+            do_journal_end(&th, p_s_sb,1, COMMIT_NOW | WAIT) ;
+        }
+    }
+    return p_s_sb->s_dirt;
+}
+
+/*
+** returns 0 if do_journal_end should return right away, returns 1 if do_journal_end should finish the commit
+** 
+** if the current transaction is too old, but still has writers, this will wait on j_join_wait until all 
+** the writers are done.  By the time it wakes up, the transaction it was called has already ended, so it just
+** flushes the commit list and returns 0.
+**
+** Won't batch when flush or commit_now is set.  Also won't batch when others are waiting on j_join_wait.
+** 
+** Note, we can't allow the journal_end to proceed while there are still writers in the log.
+*/
+static int check_journal_end(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, 
+                             unsigned long nblocks, int flags) {
+
+  time_t now ;
+  int flush = flags & FLUSH_ALL ;
+  int commit_now = flags & COMMIT_NOW ;
+  int wait_on_commit = flags & WAIT ;
+  struct reiserfs_journal_list *jl;
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+
+  BUG_ON (!th->t_trans_id);
+
+  if (th->t_trans_id != journal->j_trans_id) {
+    reiserfs_panic(th->t_super, "journal-1577: handle trans id %ld != current trans id %ld\n", 
+                   th->t_trans_id, journal->j_trans_id);
+  }
+
+  journal->j_len_alloc -= (th->t_blocks_allocated - th->t_blocks_logged) ;
+  if (atomic_read(&(journal->j_wcount)) > 0) { /* <= 0 is allowed.  unmounting might not call begin */
+    atomic_dec(&(journal->j_wcount)) ;
+  }
+
+  /* BUG, deal with case where j_len is 0, but people previously freed blocks need to be released 
+  ** will be dealt with by next transaction that actually writes something, but should be taken
+  ** care of in this trans
+  */
+  if (journal->j_len == 0) {
+    BUG();
+  }
+  /* if wcount > 0, and we are called to with flush or commit_now,
+  ** we wait on j_join_wait.  We will wake up when the last writer has
+  ** finished the transaction, and started it on its way to the disk.
+  ** Then, we flush the commit or journal list, and just return 0 
+  ** because the rest of journal end was already done for this transaction.
+  */
+  if (atomic_read(&(journal->j_wcount)) > 0) {
+    if (flush || commit_now) {
+      unsigned trans_id ;
+
+      jl = journal->j_current_jl;
+      trans_id = jl->j_trans_id;
+      if (wait_on_commit)
+        jl->j_state |= LIST_COMMIT_PENDING;
+      atomic_set(&(journal->j_jlock), 1) ;
+      if (flush) {
+        journal->j_next_full_flush = 1 ;
+      }
+      unlock_journal(p_s_sb) ;
+
+      /* sleep while the current transaction is still j_jlocked */
+      while(journal->j_trans_id == trans_id) {
+	if (atomic_read(&journal->j_jlock)) {
+	    queue_log_writer(p_s_sb);
+        } else {
+	    lock_journal(p_s_sb);
+	    if (journal->j_trans_id == trans_id) {
+	        atomic_set(&(journal->j_jlock), 1) ;
+	    }
+	    unlock_journal(p_s_sb);
+	}
+      }
+      if (journal->j_trans_id == trans_id) {
+          BUG();
+      }
+      if (commit_now && journal_list_still_alive(p_s_sb, trans_id) &&
+          wait_on_commit)
+      {
+	  flush_commit_list(p_s_sb, jl, 1) ;
+      }
+      return 0 ;
+    } 
+    unlock_journal(p_s_sb) ;
+    return 0 ;
+  }
+
+  /* deal with old transactions where we are the last writers */
+  now = get_seconds();
+  if ((now - journal->j_trans_start_time) > journal->j_max_trans_age) {
+    commit_now = 1 ;
+    journal->j_next_async_flush = 1 ;
+  }
+  /* don't batch when someone is waiting on j_join_wait */
+  /* don't batch when syncing the commit or flushing the whole trans */
+  if (!(journal->j_must_wait > 0) && !(atomic_read(&(journal->j_jlock))) && !flush && !commit_now &&
+      (journal->j_len < journal->j_max_batch)  &&
+      journal->j_len_alloc < journal->j_max_batch && journal->j_cnode_free > (journal->j_trans_max * 3)) {
+    journal->j_bcount++ ;
+    unlock_journal(p_s_sb) ;
+    return 0 ;
+  }
+
+  if (journal->j_start > SB_ONDISK_JOURNAL_SIZE(p_s_sb)) {
+    reiserfs_panic(p_s_sb, "journal-003: journal_end: j_start (%ld) is too high\n", journal->j_start) ;
+  }
+  return 1 ;
+}
+
+/*
+** Does all the work that makes deleting blocks safe.
+** when deleting a block mark BH_JNew, just remove it from the current transaction, clean it's buffer_head and move on.
+** 
+** otherwise:
+** set a bit for the block in the journal bitmap.  That will prevent it from being allocated for unformatted nodes
+** before this transaction has finished.
+**
+** mark any cnodes for this block as BLOCK_FREED, and clear their bh pointers.  That will prevent any old transactions with
+** this block from trying to flush to the real location.  Since we aren't removing the cnode from the journal_list_hash,
+** the block can't be reallocated yet.
+**
+** Then remove it from the current transaction, decrementing any counters and filing it on the clean list.
+*/
+int journal_mark_freed(struct reiserfs_transaction_handle *th, struct super_block *p_s_sb, b_blocknr_t blocknr) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_cnode *cn = NULL ;
+  struct buffer_head *bh = NULL ;
+  struct reiserfs_list_bitmap *jb = NULL ;
+  int cleaned = 0 ;
+  BUG_ON (!th->t_trans_id);
+
+  cn = get_journal_hash_dev(p_s_sb, journal->j_hash_table, blocknr);
+  if (cn && cn->bh) {
+      bh = cn->bh ;
+      get_bh(bh) ;
+  }
+  /* if it is journal new, we just remove it from this transaction */
+  if (bh && buffer_journal_new(bh)) {
+    clear_buffer_journal_new (bh);
+    clear_prepared_bits(bh) ;
+    reiserfs_clean_and_file_buffer(bh) ;
+    cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned) ;
+  } else {
+    /* set the bit for this block in the journal bitmap for this transaction */
+    jb = journal->j_current_jl->j_list_bitmap;
+    if (!jb) {
+      reiserfs_panic(p_s_sb, "journal-1702: journal_mark_freed, journal_list_bitmap is NULL\n") ;
+    }
+    set_bit_in_list_bitmap(p_s_sb, blocknr, jb) ;
+
+    /* Note, the entire while loop is not allowed to schedule.  */
+
+    if (bh) {
+      clear_prepared_bits(bh) ;
+      reiserfs_clean_and_file_buffer(bh) ;
+    }
+    cleaned = remove_from_transaction(p_s_sb, blocknr, cleaned) ;
+
+    /* find all older transactions with this block, make sure they don't try to write it out */
+    cn = get_journal_hash_dev(p_s_sb,journal->j_list_hash_table,  blocknr) ;
+    while (cn) {
+      if (p_s_sb == cn->sb && blocknr == cn->blocknr) {
+	set_bit(BLOCK_FREED, &cn->state) ;
+	if (cn->bh) {
+	  if (!cleaned) {
+	    /* remove_from_transaction will brelse the buffer if it was 
+	    ** in the current trans
+	    */
+            clear_buffer_journal_dirty (cn->bh);
+	    clear_buffer_dirty(cn->bh);
+	    clear_buffer_journal_test(cn->bh);
+	    cleaned = 1 ;
+	    put_bh(cn->bh) ;
+	    if (atomic_read(&(cn->bh->b_count)) < 0) {
+	      reiserfs_warning (p_s_sb, "journal-2138: cn->bh->b_count < 0");
+	    }
+	  }
+	  if (cn->jlist) { /* since we are clearing the bh, we MUST dec nonzerolen */
+	    atomic_dec(&(cn->jlist->j_nonzerolen)) ;
+	  }
+	  cn->bh = NULL ; 
+	} 
+      }
+      cn = cn->hnext ;
+    }
+  }
+
+  if (bh) {
+    put_bh(bh) ; /* get_hash grabs the buffer */
+    if (atomic_read(&(bh->b_count)) < 0) {
+      reiserfs_warning (p_s_sb, "journal-2165: bh->b_count < 0");
+    }
+  }
+  return 0 ;
+}
+
+void reiserfs_update_inode_transaction(struct inode *inode) {
+  struct reiserfs_journal *journal = SB_JOURNAL (inode->i_sb);
+  REISERFS_I(inode)->i_jl = journal->j_current_jl;
+  REISERFS_I(inode)->i_trans_id = journal->j_trans_id ;
+}
+
+/*
+ * returns -1 on error, 0 if no commits/barriers were done and 1
+ * if a transaction was actually committed and the barrier was done
+ */
+static int __commit_trans_jl(struct inode *inode, unsigned long id,
+                                 struct reiserfs_journal_list *jl)
+{
+    struct reiserfs_transaction_handle th ;
+    struct super_block *sb = inode->i_sb ;
+    struct reiserfs_journal *journal = SB_JOURNAL (sb);
+    int ret = 0;
+
+    /* is it from the current transaction, or from an unknown transaction? */
+    if (id == journal->j_trans_id) {
+	jl = journal->j_current_jl;
+	/* try to let other writers come in and grow this transaction */
+	let_transaction_grow(sb, id);
+	if (journal->j_trans_id != id) {
+	    goto flush_commit_only;
+	}
+
+	ret = journal_begin(&th, sb, 1) ;
+	if (ret)
+	    return ret;
+
+	/* someone might have ended this transaction while we joined */
+	if (journal->j_trans_id != id) {
+	    reiserfs_prepare_for_journal(sb, SB_BUFFER_WITH_SB(sb), 1) ;
+	    journal_mark_dirty(&th, sb, SB_BUFFER_WITH_SB(sb)) ;
+	    ret = journal_end(&th, sb, 1) ;
+	    goto flush_commit_only;
+	}
+
+	ret = journal_end_sync(&th, sb, 1) ;
+	if (!ret)
+	    ret = 1;
+
+    } else {
+	/* this gets tricky, we have to make sure the journal list in
+	 * the inode still exists.  We know the list is still around
+	 * if we've got a larger transaction id than the oldest list
+	 */
+flush_commit_only:
+	if (journal_list_still_alive(inode->i_sb, id)) {
+	    /*
+	     * we only set ret to 1 when we know for sure
+	     * the barrier hasn't been started yet on the commit
+	     * block.
+	     */
+	    if (atomic_read(&jl->j_commit_left) > 1)
+	        ret = 1;
+	    flush_commit_list(sb, jl, 1) ;
+	    if (journal->j_errno)
+		ret = journal->j_errno;
+	}
+    }
+    /* otherwise the list is gone, and long since committed */
+    return ret;
+}
+
+int reiserfs_commit_for_inode(struct inode *inode) {
+    unsigned long id = REISERFS_I(inode)->i_trans_id;
+    struct reiserfs_journal_list *jl = REISERFS_I(inode)->i_jl;
+
+    /* for the whole inode, assume unset id means it was
+     * changed in the current transaction.  More conservative
+     */
+    if (!id || !jl) {
+	reiserfs_update_inode_transaction(inode) ;
+	id = REISERFS_I(inode)->i_trans_id;
+	/* jl will be updated in __commit_trans_jl */
+    }
+
+   return __commit_trans_jl(inode, id, jl);
+}
+
+void reiserfs_restore_prepared_buffer(struct super_block *p_s_sb, 
+                                      struct buffer_head *bh) {
+    struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+    PROC_INFO_INC( p_s_sb, journal.restore_prepared );
+    if (!bh) {
+	return ;
+    }
+    if (test_clear_buffer_journal_restore_dirty (bh) &&
+	buffer_journal_dirty(bh)) {
+	struct reiserfs_journal_cnode *cn;
+	cn = get_journal_hash_dev(p_s_sb,
+	                          journal->j_list_hash_table,
+				  bh->b_blocknr);
+	if (cn && can_dirty(cn)) {
+            set_buffer_journal_test (bh);
+	    mark_buffer_dirty(bh);
+        }
+    }
+    clear_buffer_journal_prepared (bh);
+}
+
+extern struct tree_balance *cur_tb ;
+/*
+** before we can change a metadata block, we have to make sure it won't
+** be written to disk while we are altering it.  So, we must:
+** clean it
+** wait on it.
+** 
+*/
+int reiserfs_prepare_for_journal(struct super_block *p_s_sb,
+                                  struct buffer_head *bh, int wait) {
+  PROC_INFO_INC( p_s_sb, journal.prepare );
+
+    if (test_set_buffer_locked(bh)) {
+	if (!wait)
+	    return 0;
+	lock_buffer(bh);
+    }
+    set_buffer_journal_prepared (bh);
+    if (test_clear_buffer_dirty(bh) && buffer_journal_dirty(bh))  {
+        clear_buffer_journal_test (bh);
+        set_buffer_journal_restore_dirty (bh);
+    }
+    unlock_buffer(bh);
+    return 1;
+}
+
+static void flush_old_journal_lists(struct super_block *s) {
+    struct reiserfs_journal *journal = SB_JOURNAL (s);
+    struct reiserfs_journal_list *jl;
+    struct list_head *entry;
+    time_t now = get_seconds();
+
+    while(!list_empty(&journal->j_journal_list)) {
+        entry = journal->j_journal_list.next;
+	jl = JOURNAL_LIST_ENTRY(entry);
+	/* this check should always be run, to send old lists to disk */
+	if (jl->j_timestamp < (now - (JOURNAL_MAX_TRANS_AGE * 4))) {
+	    flush_used_journal_lists(s, jl);
+	} else {
+	    break;
+	}
+    }
+}
+
+/* 
+** long and ugly.  If flush, will not return until all commit
+** blocks and all real buffers in the trans are on disk.
+** If no_async, won't return until all commit blocks are on disk.
+**
+** keep reading, there are comments as you go along
+**
+** If the journal is aborted, we just clean up. Things like flushing
+** journal lists, etc just won't happen.
+*/
+static int do_journal_end(struct reiserfs_transaction_handle *th, struct super_block  * p_s_sb, unsigned long nblocks, 
+		          int flags) {
+  struct reiserfs_journal *journal = SB_JOURNAL (p_s_sb);
+  struct reiserfs_journal_cnode *cn, *next, *jl_cn; 
+  struct reiserfs_journal_cnode *last_cn = NULL;
+  struct reiserfs_journal_desc *desc ; 
+  struct reiserfs_journal_commit *commit ; 
+  struct buffer_head *c_bh ; /* commit bh */
+  struct buffer_head *d_bh ; /* desc bh */
+  int cur_write_start = 0 ; /* start index of current log write */
+  int old_start ;
+  int i ;
+  int flush = flags & FLUSH_ALL ;
+  int wait_on_commit = flags & WAIT ;
+  struct reiserfs_journal_list *jl, *temp_jl;
+  struct list_head *entry, *safe;
+  unsigned long jindex;
+  unsigned long commit_trans_id;
+  int trans_half;
+
+  BUG_ON (th->t_refcount > 1);
+  BUG_ON (!th->t_trans_id);
+
+  current->journal_info = th->t_handle_save;
+  reiserfs_check_lock_depth(p_s_sb, "journal end");
+  if (journal->j_len == 0) {
+      reiserfs_prepare_for_journal(p_s_sb, SB_BUFFER_WITH_SB(p_s_sb), 1) ;
+      journal_mark_dirty(th, p_s_sb, SB_BUFFER_WITH_SB(p_s_sb)) ;
+  }
+
+  lock_journal(p_s_sb) ;
+  if (journal->j_next_full_flush) {
+    flags |= FLUSH_ALL ;
+    flush = 1 ;
+  }
+  if (journal->j_next_async_flush) {
+    flags |= COMMIT_NOW | WAIT;
+    wait_on_commit = 1;
+  }
+
+  /* check_journal_end locks the journal, and unlocks if it does not return 1 
+  ** it tells us if we should continue with the journal_end, or just return
+  */
+  if (!check_journal_end(th, p_s_sb, nblocks, flags)) {
+    p_s_sb->s_dirt = 1;
+    wake_queued_writers(p_s_sb);
+    reiserfs_async_progress_wait(p_s_sb);
+    goto out ;
+  }
+
+  /* check_journal_end might set these, check again */
+  if (journal->j_next_full_flush) {
+    flush = 1 ;
+  }
+
+  /*
+  ** j must wait means we have to flush the log blocks, and the real blocks for
+  ** this transaction
+  */
+  if (journal->j_must_wait > 0) {
+    flush = 1 ;
+  }
+
+#ifdef REISERFS_PREALLOCATE
+  /* quota ops might need to nest, setup the journal_info pointer for them */
+  current->journal_info = th ;
+  reiserfs_discard_all_prealloc(th); /* it should not involve new blocks into
+				      * the transaction */
+  current->journal_info = th->t_handle_save ;
+#endif
+  
+  /* setup description block */
+  d_bh = journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + journal->j_start) ;
+  set_buffer_uptodate(d_bh);
+  desc = (struct reiserfs_journal_desc *)(d_bh)->b_data ;
+  memset(d_bh->b_data, 0, d_bh->b_size) ;
+  memcpy(get_journal_desc_magic (d_bh), JOURNAL_DESC_MAGIC, 8) ;
+  set_desc_trans_id(desc, journal->j_trans_id) ;
+
+  /* setup commit block.  Don't write (keep it clean too) this one until after everyone else is written */
+  c_bh =  journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
+		 ((journal->j_start + journal->j_len + 1) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
+  commit = (struct reiserfs_journal_commit *)c_bh->b_data ;
+  memset(c_bh->b_data, 0, c_bh->b_size) ;
+  set_commit_trans_id(commit, journal->j_trans_id) ;
+  set_buffer_uptodate(c_bh) ;
+
+  /* init this journal list */
+  jl = journal->j_current_jl;
+
+  /* we lock the commit before doing anything because
+   * we want to make sure nobody tries to run flush_commit_list until
+   * the new transaction is fully setup, and we've already flushed the
+   * ordered bh list
+   */
+  down(&jl->j_commit_lock);
+
+  /* save the transaction id in case we need to commit it later */
+  commit_trans_id = jl->j_trans_id;
+
+  atomic_set(&jl->j_older_commits_done, 0) ;
+  jl->j_trans_id = journal->j_trans_id ;
+  jl->j_timestamp = journal->j_trans_start_time ;
+  jl->j_commit_bh = c_bh ;
+  jl->j_start = journal->j_start ;
+  jl->j_len = journal->j_len ;
+  atomic_set(&jl->j_nonzerolen, journal->j_len) ;
+  atomic_set(&jl->j_commit_left, journal->j_len + 2);
+  jl->j_realblock = NULL ;
+
+  /* The ENTIRE FOR LOOP MUST not cause schedule to occur.
+  **  for each real block, add it to the journal list hash,
+  ** copy into real block index array in the commit or desc block
+  */
+  trans_half = journal_trans_half(p_s_sb->s_blocksize);
+  for (i = 0, cn = journal->j_first ; cn ; cn = cn->next, i++) {
+    if (buffer_journaled (cn->bh)) {
+      jl_cn = get_cnode(p_s_sb) ;
+      if (!jl_cn) {
+        reiserfs_panic(p_s_sb, "journal-1676, get_cnode returned NULL\n") ;
+      }
+      if (i == 0) {
+        jl->j_realblock = jl_cn ;
+      }
+      jl_cn->prev = last_cn ;
+      jl_cn->next = NULL ;
+      if (last_cn) {
+        last_cn->next = jl_cn ;
+      }
+      last_cn = jl_cn ;
+      /* make sure the block we are trying to log is not a block 
+         of journal or reserved area */
+
+      if (is_block_in_log_or_reserved_area(p_s_sb, cn->bh->b_blocknr)) {
+        reiserfs_panic(p_s_sb, "journal-2332: Trying to log block %lu, which is a log block\n", cn->bh->b_blocknr) ;
+      }
+      jl_cn->blocknr = cn->bh->b_blocknr ; 
+      jl_cn->state = 0 ;
+      jl_cn->sb = p_s_sb;
+      jl_cn->bh = cn->bh ;
+      jl_cn->jlist = jl;
+      insert_journal_hash(journal->j_list_hash_table, jl_cn) ;
+      if (i < trans_half) {
+	desc->j_realblock[i] = cpu_to_le32(cn->bh->b_blocknr) ;
+      } else {
+	commit->j_realblock[i - trans_half] = cpu_to_le32(cn->bh->b_blocknr) ;
+      }
+    } else {
+      i-- ;
+    }
+  }
+  set_desc_trans_len(desc, journal->j_len) ;
+  set_desc_mount_id(desc, journal->j_mount_id) ;
+  set_desc_trans_id(desc, journal->j_trans_id) ;
+  set_commit_trans_len(commit, journal->j_len);
+
+  /* special check in case all buffers in the journal were marked for not logging */
+  if (journal->j_len == 0) {
+    BUG();
+  }
+
+  /* we're about to dirty all the log blocks, mark the description block
+   * dirty now too.  Don't mark the commit block dirty until all the
+   * others are on disk
+   */
+  mark_buffer_dirty(d_bh);
+
+  /* first data block is j_start + 1, so add one to cur_write_start wherever you use it */
+  cur_write_start = journal->j_start ;
+  cn = journal->j_first ;
+  jindex = 1 ; /* start at one so we don't get the desc again */
+  while(cn) {
+    clear_buffer_journal_new (cn->bh);
+    /* copy all the real blocks into log area.  dirty log blocks */
+    if (buffer_journaled (cn->bh)) {
+      struct buffer_head *tmp_bh ;
+      char *addr;
+      struct page *page;
+      tmp_bh =  journal_getblk(p_s_sb, SB_ONDISK_JOURNAL_1st_BLOCK(p_s_sb) + 
+		       ((cur_write_start + jindex) % SB_ONDISK_JOURNAL_SIZE(p_s_sb))) ;
+      set_buffer_uptodate(tmp_bh);
+      page = cn->bh->b_page;
+      addr = kmap(page);
+      memcpy(tmp_bh->b_data, addr + offset_in_page(cn->bh->b_data),
+             cn->bh->b_size);
+      kunmap(page);
+      mark_buffer_dirty(tmp_bh);
+      jindex++ ;
+      set_buffer_journal_dirty (cn->bh);
+      clear_buffer_journaled (cn->bh);
+    } else {
+      /* JDirty cleared sometime during transaction.  don't log this one */
+      reiserfs_warning(p_s_sb, "journal-2048: do_journal_end: BAD, buffer in journal hash, but not JDirty!") ;
+      brelse(cn->bh) ;
+    }
+    next = cn->next ;
+    free_cnode(p_s_sb, cn) ;
+    cn = next ;
+    cond_resched();
+  }
+
+  /* we are done  with both the c_bh and d_bh, but
+  ** c_bh must be written after all other commit blocks,
+  ** so we dirty/relse c_bh in flush_commit_list, with commit_left <= 1.
+  */
+
+  journal->j_current_jl = alloc_journal_list(p_s_sb);
+
+  /* now it is safe to insert this transaction on the main list */
+  list_add_tail(&jl->j_list, &journal->j_journal_list);
+  list_add_tail(&jl->j_working_list, &journal->j_working_list);
+  journal->j_num_work_lists++;
+
+  /* reset journal values for the next transaction */
+  old_start = journal->j_start ;
+  journal->j_start = (journal->j_start + journal->j_len + 2) % SB_ONDISK_JOURNAL_SIZE(p_s_sb);
+  atomic_set(&(journal->j_wcount), 0) ;
+  journal->j_bcount = 0 ;
+  journal->j_last = NULL ;
+  journal->j_first = NULL ;
+  journal->j_len = 0 ;
+  journal->j_trans_start_time = 0 ;
+  journal->j_trans_id++ ;
+  journal->j_current_jl->j_trans_id = journal->j_trans_id;
+  journal->j_must_wait = 0 ;
+  journal->j_len_alloc = 0 ;
+  journal->j_next_full_flush = 0 ;
+  journal->j_next_async_flush = 0 ;
+  init_journal_hash(p_s_sb) ; 
+
+  // make sure reiserfs_add_jh sees the new current_jl before we
+  // write out the tails
+  smp_mb();
+
+  /* tail conversion targets have to hit the disk before we end the
+   * transaction.  Otherwise a later transaction might repack the tail
+   * before this transaction commits, leaving the data block unflushed and
+   * clean, if we crash before the later transaction commits, the data block
+   * is lost.
+   */
+  if (!list_empty(&jl->j_tail_bh_list)) {
+      unlock_kernel();
+      write_ordered_buffers(&journal->j_dirty_buffers_lock,
+			    journal, jl, &jl->j_tail_bh_list);
+      lock_kernel();
+  }
+  if (!list_empty(&jl->j_tail_bh_list))
+      BUG();
+  up(&jl->j_commit_lock);
+
+  /* honor the flush wishes from the caller, simple commits can
+  ** be done outside the journal lock, they are done below
+  **
+  ** if we don't flush the commit list right now, we put it into
+  ** the work queue so the people waiting on the async progress work
+  ** queue don't wait for this proc to flush journal lists and such.
+  */
+  if (flush) {
+    flush_commit_list(p_s_sb, jl, 1) ;
+    flush_journal_list(p_s_sb, jl, 1) ;
+  } else if (!(jl->j_state & LIST_COMMIT_PENDING))
+    queue_delayed_work(commit_wq, &journal->j_work, HZ/10);
+
+
+  /* if the next transaction has any chance of wrapping, flush 
+  ** transactions that might get overwritten.  If any journal lists are very 
+  ** old flush them as well.  
+  */
+first_jl:
+  list_for_each_safe(entry, safe, &journal->j_journal_list) {
+    temp_jl = JOURNAL_LIST_ENTRY(entry);
+    if (journal->j_start <= temp_jl->j_start) {
+      if ((journal->j_start + journal->j_trans_max + 1) >=
+          temp_jl->j_start)
+      {
+	flush_used_journal_lists(p_s_sb, temp_jl);
+	goto first_jl;
+      } else if ((journal->j_start +
+                  journal->j_trans_max + 1) <
+		  SB_ONDISK_JOURNAL_SIZE(p_s_sb))
+      {
+          /* if we don't cross into the next transaction and we don't
+	   * wrap, there is no way we can overlap any later transactions
+	   * break now
+	   */
+	  break;
+      }
+    } else if ((journal->j_start +
+                journal->j_trans_max + 1) >
+		SB_ONDISK_JOURNAL_SIZE(p_s_sb))
+    {
+      if (((journal->j_start + journal->j_trans_max + 1) %
+            SB_ONDISK_JOURNAL_SIZE(p_s_sb)) >= temp_jl->j_start)
+      {
+	flush_used_journal_lists(p_s_sb, temp_jl);
+	goto first_jl;
+      } else {
+	  /* we don't overlap anything from out start to the end of the
+	   * log, and our wrapped portion doesn't overlap anything at
+	   * the start of the log.  We can break
+	   */
+	  break;
+      }
+    }
+  }
+  flush_old_journal_lists(p_s_sb);
+
+  journal->j_current_jl->j_list_bitmap = get_list_bitmap(p_s_sb, journal->j_current_jl) ;
+
+  if (!(journal->j_current_jl->j_list_bitmap)) {
+    reiserfs_panic(p_s_sb, "journal-1996: do_journal_end, could not get a list bitmap\n") ;
+  }
+
+  atomic_set(&(journal->j_jlock), 0) ;
+  unlock_journal(p_s_sb) ;
+  /* wake up any body waiting to join. */
+  clear_bit(J_WRITERS_QUEUED, &journal->j_state);
+  wake_up(&(journal->j_join_wait)) ;
+
+  if (!flush && wait_on_commit &&
+      journal_list_still_alive(p_s_sb, commit_trans_id)) {
+	  flush_commit_list(p_s_sb, jl, 1) ;
+  }
+out:
+  reiserfs_check_lock_depth(p_s_sb, "journal end2");
+
+  memset (th, 0, sizeof (*th));
+  /* Re-set th->t_super, so we can properly keep track of how many
+   * persistent transactions there are. We need to do this so if this
+   * call is part of a failed restart_transaction, we can free it later */
+  th->t_super = p_s_sb;
+
+  return journal->j_errno;
+}
+
+static void
+__reiserfs_journal_abort_hard (struct super_block *sb)
+{
+    struct reiserfs_journal *journal = SB_JOURNAL (sb);
+    if (test_bit (J_ABORTED, &journal->j_state))
+        return;
+
+    printk (KERN_CRIT "REISERFS: Aborting journal for filesystem on %s\n",
+                      reiserfs_bdevname (sb));
+
+    sb->s_flags |= MS_RDONLY;
+    set_bit (J_ABORTED, &journal->j_state);
+
+#ifdef CONFIG_REISERFS_CHECK
+    dump_stack();
+#endif
+}
+
+static void
+__reiserfs_journal_abort_soft (struct super_block *sb, int errno)
+{
+    struct reiserfs_journal *journal = SB_JOURNAL (sb);
+    if (test_bit (J_ABORTED, &journal->j_state))
+        return;
+
+    if (!journal->j_errno)
+        journal->j_errno = errno;
+
+    __reiserfs_journal_abort_hard (sb);
+}
+
+void
+reiserfs_journal_abort (struct super_block *sb, int errno)
+{
+    return __reiserfs_journal_abort_soft (sb, errno);
+}
